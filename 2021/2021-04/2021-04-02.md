## Summary for 2021-04-02, created on 2021-12-22


<details><summary><b>Type Prediction Systems</b>
<a href="https://arxiv.org/abs/2104.01207">arxiv:2104.01207</a>
&#x1F4C8; 48 <br>
<p>Sarthak Dash, Nandana Mihindukulasooriya, Alfio Gliozzo, Mustafa Canim</p></summary>
<p>

**Abstract:** Inferring semantic types for entity mentions within text documents is an important asset for many downstream NLP tasks, such as Semantic Role Labelling, Entity Disambiguation, Knowledge Base Question Answering, etc. Prior works have mostly focused on supervised solutions that generally operate on relatively small-to-medium-sized type systems. In this work, we describe two systems aimed at predicting type information for the following two tasks, namely, a TypeSuggest module, an unsupervised system designed to predict types for a set of user-entered query terms, and an Answer Type prediction module, that provides a solution for the task of determining the correct type of the answer expected to a given query. Our systems generalize to arbitrary type systems of any sizes, thereby making it a highly appealing solution to extract type information at any granularity.

</p>
</details>

<details><summary><b>Linear Systems can be Hard to Learn</b>
<a href="https://arxiv.org/abs/2104.01120">arxiv:2104.01120</a>
&#x1F4C8; 42 <br>
<p>Anastasios Tsiamis, George J. Pappas</p></summary>
<p>

**Abstract:** In this paper, we investigate when system identification is statistically easy or hard, in the finite sample regime. Statistically easy to learn linear system classes have sample complexity that is polynomial with the system dimension. Most prior research in the finite sample regime falls in this category, focusing on systems that are directly excited by process noise. Statistically hard to learn linear system classes have worst-case sample complexity that is at least exponential with the system dimension, regardless of the identification algorithm. Using tools from minimax theory, we show that classes of linear systems can be hard to learn. Such classes include, for example, under-actuated or under-excited systems with weak coupling among the states. Having classified some systems as easy or hard to learn, a natural question arises as to what system properties fundamentally affect the hardness of system identifiability. Towards this direction, we characterize how the controllability index of linear systems affects the sample complexity of identification. More specifically, we show that the sample complexity of robustly controllable linear systems is upper bounded by an exponential function of the controllability index. This implies that identification is easy for classes of linear systems with small controllability index and potentially hard if the controllability index is large. Our analysis is based on recent statistical tools for finite sample analysis of system identification as well as a novel lower bound that relates controllability index with the least singular value of the controllability Gramian.

</p>
</details>

<details><summary><b>Assem-VC: Realistic Voice Conversion by Assembling Modern Speech Synthesis Techniques</b>
<a href="https://arxiv.org/abs/2104.00931">arxiv:2104.00931</a>
&#x1F4C8; 26 <br>
<p>Kang-wook Kim, Seung-won Park, Junhyeok Lee, Myun-chul Joe</p></summary>
<p>

**Abstract:** Recent works on voice conversion (VC) focus on preserving the rhythm and the intonation as well as the linguistic content. To preserve these features from the source, we decompose current non-parallel VC systems into two encoders and one decoder. We analyze each module with several experiments and reassemble the best components to propose Assem-VC, a new state-of-the-art any-to-many non-parallel VC system. We also examine that PPG and Cotatron features are speaker-dependent, and attempt to remove speaker identity with adversarial training. Code and audio samples are available at https://github.com/mindslab-ai/assem-vc.

</p>
</details>

<details><summary><b>Query2Prod2Vec Grounded Word Embeddings for eCommerce</b>
<a href="https://arxiv.org/abs/2104.02061">arxiv:2104.02061</a>
&#x1F4C8; 23 <br>
<p>Federico Bianchi, Jacopo Tagliabue, Bingqing Yu</p></summary>
<p>

**Abstract:** We present Query2Prod2Vec, a model that grounds lexical representations for product search in product embeddings: in our model, meaning is a mapping between words and a latent space of products in a digital shop. We leverage shopping sessions to learn the underlying space and use merchandising annotations to build lexical analogies for evaluation: our experiments show that our model is more accurate than known techniques from the NLP and IR literature. Finally, we stress the importance of data efficiency for product search outside of retail giants, and highlight how Query2Prod2Vec fits with practical constraints faced by most practitioners.

</p>
</details>

<details><summary><b>Decomposing 3D Scenes into Objects via Unsupervised Volume Segmentation</b>
<a href="https://arxiv.org/abs/2104.01148">arxiv:2104.01148</a>
&#x1F4C8; 21 <br>
<p>Karl Stelzner, Kristian Kersting, Adam R. Kosiorek</p></summary>
<p>

**Abstract:** We present ObSuRF, a method which turns a single image of a scene into a 3D model represented as a set of Neural Radiance Fields (NeRFs), with each NeRF corresponding to a different object. A single forward pass of an encoder network outputs a set of latent vectors describing the objects in the scene. These vectors are used independently to condition a NeRF decoder, defining the geometry and appearance of each object. We make learning more computationally efficient by deriving a novel loss, which allows training NeRFs on RGB-D inputs without explicit ray marching. After confirming that the model performs equal or better than state of the art on three 2D image segmentation benchmarks, we apply it to two multi-object 3D datasets: A multiview version of CLEVR, and a novel dataset in which scenes are populated by ShapeNet models. We find that after training ObSuRF on RGB-D views of training scenes, it is capable of not only recovering the 3D geometry of a scene depicted in a single input image, but also to segment it into objects, despite receiving no supervision in that regard.

</p>
</details>

<details><summary><b>How Powerful are Performance Predictors in Neural Architecture Search?</b>
<a href="https://arxiv.org/abs/2104.01177">arxiv:2104.01177</a>
&#x1F4C8; 17 <br>
<p>Colin White, Arber Zela, Binxin Ru, Yang Liu, Frank Hutter</p></summary>
<p>

**Abstract:** Early methods in the rapidly developing field of neural architecture search (NAS) required fully training thousands of neural networks. To reduce this extreme computational cost, dozens of techniques have since been proposed to predict the final performance of neural architectures. Despite the success of such performance prediction methods, it is not well-understood how different families of techniques compare to one another, due to the lack of an agreed-upon evaluation metric and optimization for different constraints on the initialization time and query time. In this work, we give the first large-scale study of performance predictors by analyzing 31 techniques ranging from learning curve extrapolation, to weight-sharing, to supervised learning, to "zero-cost" proxies. We test a number of correlation- and rank-based performance measures in a variety of settings, as well as the ability of each technique to speed up predictor-based NAS frameworks. Our results act as recommendations for the best predictors to use in different settings, and we show that certain families of predictors can be combined to achieve even better predictive power, opening up promising research directions. Our code, featuring a library of 31 performance predictors, is available at https://github.com/automl/naslib.

</p>
</details>

<details><summary><b>Robust wav2vec 2.0: Analyzing Domain Shift in Self-Supervised Pre-Training</b>
<a href="https://arxiv.org/abs/2104.01027">arxiv:2104.01027</a>
&#x1F4C8; 10 <br>
<p>Wei-Ning Hsu, Anuroop Sriram, Alexei Baevski, Tatiana Likhomanenko, Qiantong Xu, Vineel Pratap, Jacob Kahn, Ann Lee, Ronan Collobert, Gabriel Synnaeve, Michael Auli</p></summary>
<p>

**Abstract:** Self-supervised learning of speech representations has been a very active research area but most work is focused on a single domain such as read audio books for which there exist large quantities of labeled and unlabeled data. In this paper, we explore more general setups where the domain of the unlabeled data for pre-training data differs from the domain of the labeled data for fine-tuning, which in turn may differ from the test data domain. Our experiments show that using target domain data during pre-training leads to large performance improvements across a variety of setups. On a large-scale competitive setup, we show that pre-training on unlabeled in-domain data reduces the gap between models trained on in-domain and out-of-domain labeled data by 66%-73%. This has obvious practical implications since it is much easier to obtain unlabeled target domain data than labeled data. Moreover, we find that pre-training on multiple domains improves generalization performance on domains not seen during training. Code and models will be made available at https://github.com/pytorch/fairseq.

</p>
</details>

<details><summary><b>An active inference model of collective intelligence</b>
<a href="https://arxiv.org/abs/2104.01066">arxiv:2104.01066</a>
&#x1F4C8; 9 <br>
<p>Rafael Kaufmann, Pranav Gupta, Jacob Taylor</p></summary>
<p>

**Abstract:** To date, formal models of collective intelligence have lacked a plausible mathematical description of the relationship between local-scale interactions between highly autonomous sub-system components (individuals) and global-scale behavior of the composite system (the collective). In this paper we use the Active Inference Formulation (AIF), a framework for explaining the behavior of any non-equilibrium steady state system at any scale, to posit a minimal agent-based model that simulates the relationship between local individual-level interaction and collective intelligence (operationalized as system-level performance). We explore the effects of providing baseline AIF agents (Model 1) with specific cognitive capabilities: Theory of Mind (Model 2); Goal Alignment (Model 3), and Theory of Mind with Goal Alignment (Model 4). These stepwise transitions in sophistication of cognitive ability are motivated by the types of advancements plausibly required for an AIF agent to persist and flourish in an environment populated by other AIF agents, and have also recently been shown to map naturally to canonical steps in human cognitive ability. Illustrative results show that stepwise cognitive transitions increase system performance by providing complementary mechanisms for alignment between agents' local and global optima. Alignment emerges endogenously from the dynamics of interacting AIF agents themselves, rather than being imposed exogenously by incentives to agents' behaviors (contra existing computational models of collective intelligence) or top-down priors for collective behavior (contra existing multiscale simulations of AIF). These results shed light on the types of generic information-theoretic patterns conducive to collective intelligence in human and other complex adaptive systems.

</p>
</details>

<details><summary><b>The CSO Classifier: Ontology-Driven Detection of Research Topics in Scholarly Articles</b>
<a href="https://arxiv.org/abs/2104.00948">arxiv:2104.00948</a>
&#x1F4C8; 8 <br>
<p>Angelo A. Salatino, Francesco Osborne, Thiviyan Thanapalasingam, Enrico Motta</p></summary>
<p>

**Abstract:** Classifying research papers according to their research topics is an important task to improve their retrievability, assist the creation of smart analytics, and support a variety of approaches for analysing and making sense of the research environment. In this paper, we present the CSO Classifier, a new unsupervised approach for automatically classifying research papers according to the Computer Science Ontology (CSO), a comprehensive ontology of re-search areas in the field of Computer Science. The CSO Classifier takes as input the metadata associated with a research paper (title, abstract, keywords) and returns a selection of research concepts drawn from the ontology. The approach was evaluated on a gold standard of manually annotated articles yielding a significant improvement over alternative methods.

</p>
</details>

<details><summary><b>Robotic needle steering in deformable tissues with extreme learning machines</b>
<a href="https://arxiv.org/abs/2104.06510">arxiv:2104.06510</a>
&#x1F4C8; 7 <br>
<p>Pedro Henrique Suruagy Perrusi, Anna Cazzaniga, Paul Baksic, Eleonora Tagliabue, Elena de Momi, Hadrien Courtecuisse</p></summary>
<p>

**Abstract:** Control strategies for robotic needle steering in soft tissues must account for complex interactions between the needle and the tissue to achieve accurate needle tip positioning. Recent findings show faster robotic command rate can improve the control stability in realistic scenarios. This study proposes the use of Extreme Learning Machines to provide fast commands for robotic needle steering. A synthetic dataset based on the inverse finite element simulation control framework is used to train the model. Results show the model is capable to infer commands 66% faster than the inverse simulation and reaches acceptable precision even on previously unseen trajectories.

</p>
</details>

<details><summary><b>Learnable Dynamic Temporal Pooling for Time Series Classification</b>
<a href="https://arxiv.org/abs/2104.02577">arxiv:2104.02577</a>
&#x1F4C8; 7 <br>
<p>Dongha Lee, Seonghyeon Lee, Hwanjo Yu</p></summary>
<p>

**Abstract:** With the increase of available time series data, predicting their class labels has been one of the most important challenges in a wide range of disciplines. Recent studies on time series classification show that convolutional neural networks (CNN) achieved the state-of-the-art performance as a single classifier. In this work, pointing out that the global pooling layer that is usually adopted by existing CNN classifiers discards the temporal information of high-level features, we present a dynamic temporal pooling (DTP) technique that reduces the temporal size of hidden representations by aggregating the features at the segment-level. For the partition of a whole series into multiple segments, we utilize dynamic time warping (DTW) to align each time point in a temporal order with the prototypical features of the segments, which can be optimized simultaneously with the network parameters of CNN classifiers. The DTP layer combined with a fully-connected layer helps to extract further discriminative features considering their temporal position within an input time series. Extensive experiments on both univariate and multivariate time series datasets show that our proposed pooling significantly improves the classification performance.

</p>
</details>

<details><summary><b>Exponential Reduction in Sample Complexity with Learning of Ising Model Dynamics</b>
<a href="https://arxiv.org/abs/2104.00995">arxiv:2104.00995</a>
&#x1F4C8; 7 <br>
<p>Arkopal Dutt, Andrey Y. Lokhov, Marc Vuffray, Sidhant Misra</p></summary>
<p>

**Abstract:** The usual setting for learning the structure and parameters of a graphical model assumes the availability of independent samples produced from the corresponding multivariate probability distribution. However, for many models the mixing time of the respective Markov chain can be very large and i.i.d. samples may not be obtained. We study the problem of reconstructing binary graphical models from correlated samples produced by a dynamical process, which is natural in many applications. We analyze the sample complexity of two estimators that are based on the interaction screening objective and the conditional likelihood loss. We observe that for samples coming from a dynamical process far from equilibrium, the sample complexity reduces exponentially compared to a dynamical process that mixes quickly.

</p>
</details>

<details><summary><b>Datacentric analysis to reduce pedestrians accidents: A case study in Colombia</b>
<a href="https://arxiv.org/abs/2104.00912">arxiv:2104.00912</a>
&#x1F4C8; 7 <br>
<p>Michael Puentes, Diana Novoa, John Delgado Nivia, Carlos Barrios Hernández, Oscar Carrillo, Frédéric Le Mouël</p></summary>
<p>

**Abstract:** Since 2012, in a case-study in Bucaramanga-Colombia, 179 pedestrians died in car accidents, and another 2873 pedestrians were injured. Each day, at least one passerby is involved in a tragedy. Knowing the causes to decrease accidents is crucial, and using system-dynamics to reproduce the collisions' events is critical to prevent further accidents. This work implements simulations to save lives by reducing the city's accidental rate and suggesting new safety policies to implement. Simulation's inputs are video recordings in some areas of the city. Deep Learning analysis of the images results in the segmentation of the different objects in the scene, and an interaction model identifies the primary reasons which prevail in the pedestrians or vehicles' behaviours. The first and most efficient safety policy to implement-validated by our simulations-would be to build speed bumps in specific places before the crossings reducing the accident rate by 80%.

</p>
</details>

<details><summary><b>Extraction of instantaneous frequencies and amplitudes in nonstationary time-series data</b>
<a href="https://arxiv.org/abs/2104.01293">arxiv:2104.01293</a>
&#x1F4C8; 6 <br>
<p>Daniel E. Shea, Rajiv Giridharagopal, David S. Ginger, Steven L. Brunton, J. Nathan Kutz</p></summary>
<p>

**Abstract:** Time-series analysis is critical for a diversity of applications in science and engineering. By leveraging the strengths of modern gradient descent algorithms, the Fourier transform, multi-resolution analysis, and Bayesian spectral analysis, we propose a data-driven approach to time-frequency analysis that circumvents many of the shortcomings of classic approaches, including the extraction of nonstationary signals with discontinuities in their behavior. The method introduced is equivalent to a {\em nonstationary Fourier mode decomposition} (NFMD) for nonstationary and nonlinear temporal signals, allowing for the accurate identification of instantaneous frequencies and their amplitudes. The method is demonstrated on a diversity of time-series data, including on data from cantilever-based electrostatic force microscopy to quantify the time-dependent evolution of charging dynamics at the nanoscale.

</p>
</details>

<details><summary><b>PATE-AAE: Incorporating Adversarial Autoencoder into Private Aggregation of Teacher Ensembles for Spoken Command Classification</b>
<a href="https://arxiv.org/abs/2104.01271">arxiv:2104.01271</a>
&#x1F4C8; 5 <br>
<p>Chao-Han Huck Yang, Sabato Marco Siniscalchi, Chin-Hui Lee</p></summary>
<p>

**Abstract:** We propose using an adversarial autoencoder (AAE) to replace generative adversarial network (GAN) in the private aggregation of teacher ensembles (PATE), a solution for ensuring differential privacy in speech applications. The AAE architecture allows us to obtain good synthetic speech leveraging upon a discriminative training of latent vectors. Such synthetic speech is used to build a privacy-preserving classifier when non-sensitive data is not sufficiently available in the public domain. This classifier follows the PATE scheme that uses an ensemble of noisy outputs to label the synthetic samples and guarantee $\varepsilon$-differential privacy (DP) on its derived classifiers. Our proposed framework thus consists of an AAE-based generator and a PATE-based classifier (PATE-AAE). Evaluated on the Google Speech Commands Dataset Version II, the proposed PATE-AAE improves the average classification accuracy by +$2.11\%$ and +$6.60\%$, respectively, when compared with alternative privacy-preserving solutions, namely PATE-GAN and DP-GAN, while maintaining a strong level of privacy target at $\varepsilon$=0.01 with a fixed $δ$=10$^{-5}$.

</p>
</details>

<details><summary><b>Fast and Accurate Randomized Algorithms for Low-rank Tensor Decompositions</b>
<a href="https://arxiv.org/abs/2104.01101">arxiv:2104.01101</a>
&#x1F4C8; 5 <br>
<p>Linjian Ma, Edgar Solomonik</p></summary>
<p>

**Abstract:** Low-rank Tucker and CP tensor decompositions are powerful tools in data analytics. The widely used alternating least squares (ALS) method, which solves a sequence of over-determined least squares subproblems, is costly for large and sparse tensors. We propose a fast and accurate sketched ALS algorithm for Tucker decomposition, which solves a sequence of sketched rank-constrained linear least squares subproblems. Theoretical sketch size upper bounds are provided to achieve $O(ε)$ relative error for each subproblem with two sketching techniques, TensorSketch and leverage score sampling. Experimental results show that this new ALS algorithm, combined with a new initialization scheme based on randomized range finder, yields up to $22.0\%$ relative decomposition residual improvement compared to the state-of-the-art sketched randomized algorithm for Tucker decomposition of various synthetic and real datasets. This Tucker-ALS algorithm is further used to accelerate CP decomposition, by using randomized Tucker compression followed by CP decomposition of the Tucker core tensor. Experimental results show that this algorithm not only converges faster, but also yields more accurate CP decompositions.

</p>
</details>

<details><summary><b>Sketch and Customize: A Counterfactual Story Generator</b>
<a href="https://arxiv.org/abs/2104.00929">arxiv:2104.00929</a>
&#x1F4C8; 5 <br>
<p>Changying Hao, Liang Pang, Yanyan Lan, Yan Wang, Jiafeng Guo, Xueqi Cheng</p></summary>
<p>

**Abstract:** Recent text generation models are easy to generate relevant and fluent text for the given text, while lack of causal reasoning ability when we change some parts of the given text. Counterfactual story rewriting is a recently proposed task to test the causal reasoning ability for text generation models, which requires a model to predict the corresponding story ending when the condition is modified to a counterfactual one. Previous works have shown that the traditional sequence-to-sequence model cannot well handle this problem, as it often captures some spurious correlations between the original and counterfactual endings, instead of the causal relations between conditions and endings. To address this issue, we propose a sketch-and-customize generation model guided by the causality implicated in the conditions and endings. In the sketch stage, a skeleton is extracted by removing words which are conflict to the counterfactual condition, from the original ending. In the customize stage, a generation model is used to fill proper words in the skeleton under the guidance of the counterfactual condition. In this way, the obtained counterfactual ending is both relevant to the original ending and consistent with the counterfactual condition. Experimental results show that the proposed model generates much better endings, as compared with the traditional sequence-to-sequence model.

</p>
</details>

<details><summary><b>Toward Generating Synthetic CT Volumes using a 3D-Conditional Generative Adversarial Network</b>
<a href="https://arxiv.org/abs/2104.02060">arxiv:2104.02060</a>
&#x1F4C8; 4 <br>
<p>Jayalakshmi Mangalagiri, David Chapman, Aryya Gangopadhyay, Yaacov Yesha, Joshua Galita, Sumeet Menon, Yelena Yesha, Babak Saboury, Michael Morris, Phuong Nguyen</p></summary>
<p>

**Abstract:** We present a novel conditional Generative Adversarial Network (cGAN) architecture that is capable of generating 3D Computed Tomography scans in voxels from noisy and/or pixelated approximations and with the potential to generate full synthetic 3D scan volumes. We believe conditional cGAN to be a tractable approach to generate 3D CT volumes, even though the problem of generating full resolution deep fakes is presently impractical due to GPU memory limitations. We present results for autoencoder, denoising, and depixelating tasks which are trained and tested on two novel COVID19 CT datasets. Our evaluation metrics, Peak Signal to Noise ratio (PSNR) range from 12.53 - 46.46 dB, and the Structural Similarity index ( SSIM) range from 0.89 to 1.

</p>
</details>

<details><summary><b>Fast Parallel Algorithms for Euclidean Minimum Spanning Tree and Hierarchical Spatial Clustering</b>
<a href="https://arxiv.org/abs/2104.01126">arxiv:2104.01126</a>
&#x1F4C8; 4 <br>
<p>Yiqiu Wang, Shangdi Yu, Yan Gu, Julian Shun</p></summary>
<p>

**Abstract:** This paper presents new parallel algorithms for generating Euclidean minimum spanning trees and spatial clustering hierarchies (known as HDBSCAN$^*$). Our approach is based on generating a well-separated pair decomposition followed by using Kruskal's minimum spanning tree algorithm and bichromatic closest pair computations. We introduce a new notion of well-separation to reduce the work and space of our algorithm for HDBSCAN$^*$. We also present a parallel approximate algorithm for OPTICS based on a recent sequential algorithm by Gan and Tao. Finally, we give a new parallel divide-and-conquer algorithm for computing the dendrogram and reachability plots, which are used in visualizing clusters of different scale that arise for both EMST and HDBSCAN$^*$. We show that our algorithms are theoretically efficient: they have work (number of operations) matching their sequential counterparts, and polylogarithmic depth (parallel time).
  We implement our algorithms and propose a memory optimization that requires only a subset of well-separated pairs to be computed and materialized, leading to savings in both space (up to 10x) and time (up to 8x). Our experiments on large real-world and synthetic data sets using a 48-core machine show that our fastest algorithms outperform the best serial algorithms for the problems by 11.13--55.89x, and existing parallel algorithms by at least an order of magnitude.

</p>
</details>

<details><summary><b>Plot2API: Recommending Graphic API from Plot via Semantic Parsing Guided Neural Network</b>
<a href="https://arxiv.org/abs/2104.01032">arxiv:2104.01032</a>
&#x1F4C8; 4 <br>
<p>Zeyu Wang, Sheng Huang, Zhongxin Liu, Meng Yan, Xin Xia, Bei Wang, Dan Yang</p></summary>
<p>

**Abstract:** Plot-based Graphic API recommendation (Plot2API) is an unstudied but meaningful issue, which has several important applications in the context of software engineering and data visualization, such as the plotting guidance of the beginner, graphic API correlation analysis, and code conversion for plotting. Plot2API is a very challenging task, since each plot is often associated with multiple APIs and the appearances of the graphics drawn by the same API can be extremely varied due to the different settings of the parameters. Additionally, the samples of different APIs also suffer from extremely imbalanced. Considering the lack of technologies in Plot2API, we present a novel deep multi-task learning approach named Semantic Parsing Guided Neural Network (SPGNN) which translates the Plot2API issue as a multi-label image classification and an image semantic parsing tasks for the solution. In SPGNN, the recently advanced Convolutional Neural Network (CNN) named EfficientNet is employed as the backbone network for API recommendation. Meanwhile, a semantic parsing module is complemented to exploit the semantic relevant visual information in feature learning and eliminate the appearance-relevant visual information which may confuse the visual-information-based API recommendation. Moreover, the recent data augmentation technique named random erasing is also applied for alleviating the imbalance of API categories. We collect plots with the graphic APIs used to drawn them from Stack Overflow, and release three new Plot2API datasets corresponding to the graphic APIs of R and Python programming languages for evaluating the effectiveness of Plot2API techniques. Extensive experimental results not only demonstrate the superiority of our method over the recent deep learning baselines but also show the practicability of our method in the recommendation of graphic APIs.

</p>
</details>

<details><summary><b>Artificial intelligence, human rights, democracy, and the rule of law: a primer</b>
<a href="https://arxiv.org/abs/2104.04147">arxiv:2104.04147</a>
&#x1F4C8; 3 <br>
<p>David Leslie, Christopher Burr, Mhairi Aitken, Josh Cowls, Michael Katell, Morgan Briggs</p></summary>
<p>

**Abstract:** In September 2019, the Council of Europe's Committee of Ministers adopted the terms of reference for the Ad Hoc Committee on Artificial Intelligence (CAHAI). The CAHAI is charged with examining the feasibility and potential elements of a legal framework for the design, development, and deployment of AI systems that accord with Council of Europe standards across the interrelated areas of human rights, democracy, and the rule of law. As a first and necessary step in carrying out this responsibility, the CAHAI's Feasibility Study, adopted by its plenary in December 2020, has explored options for an international legal response that fills existing gaps in legislation and tailors the use of binding and non-binding legal instruments to the specific risks and opportunities presented by AI systems. The Study examines how the fundamental rights and freedoms that are already codified in international human rights law can be used as the basis for such a legal framework. The purpose of this primer is to introduce the main concepts and principles presented in the CAHAI's Feasibility Study for a general, non-technical audience. It also aims to provide some background information on the areas of AI innovation, human rights law, technology policy, and compliance mechanisms covered therein. In keeping with the Council of Europe's commitment to broad multi-stakeholder consultations, outreach, and engagement, this primer has been designed to help facilitate the meaningful and informed participation of an inclusive group of stakeholders as the CAHAI seeks feedback and guidance regarding the essential issues raised by the Feasibility Study.

</p>
</details>

<details><summary><b>On the Pitfalls of Learning with Limited Data: A Facial Expression Recognition Case Study</b>
<a href="https://arxiv.org/abs/2104.02653">arxiv:2104.02653</a>
&#x1F4C8; 3 <br>
<p>Miguel Rodríguez Santander, Juan Hernández Albarracín, Adín Ramírez Rivera</p></summary>
<p>

**Abstract:** Deep learning models need large amounts of data for training. In video recognition and classification, significant advances were achieved with the introduction of new large databases. However, the creation of large-databases for training is infeasible in several scenarios. Thus, existing or small collected databases are typically joined and amplified to train these models. Nevertheless, training neural networks on limited data is not straightforward and comes with a set of problems. In this paper, we explore the effects of stacking databases, model initialization, and data amplification techniques when training with limited data on deep learning models' performance. We focused on the problem of Facial Expression Recognition from videos. We performed an extensive study with four databases at a different complexity and nine deep-learning architectures for video classification. We found that (i) complex training sets translate better to more stable test sets when trained with transfer learning and synthetically generated data, but their performance yields a high variance; (ii) training with more detailed data translates to more stable performance on novel scenarios (albeit with lower performance); (iii) merging heterogeneous data is not a straightforward improvement, as the type of augmentation and initialization is crucial; (iv) classical data augmentation cannot fill the holes created by joining largely separated datasets; and (v) inductive biases help to bridge the gap when paired with synthetic data, but this data is not enough when working with standard initialization techniques.

</p>
</details>

<details><summary><b>Multi-class motion-based semantic segmentation for ureteroscopy and laser lithotripsy</b>
<a href="https://arxiv.org/abs/2104.01268">arxiv:2104.01268</a>
&#x1F4C8; 3 <br>
<p>Soumya Gupta, Sharib Ali, Louise Goldsmith, Ben Turney, Jens Rittscher</p></summary>
<p>

**Abstract:** Kidney stones represent a considerable burden for public health-care systems. Ureteroscopy with laser lithotripsy has evolved as the most commonly used technique for the treatment of kidney stones. Automated segmentation of kidney stones and laser fiber is an important initial step to performing any automated quantitative analysis of the stones, particularly stone-size estimation, that helps the surgeon decide if the stone requires more fragmentation. Factors such as turbid fluid inside the cavity, specularities, motion blur due to kidney movements and camera motion, bleeding, and stone debris impact the quality of vision within the kidney and lead to extended operative times. To the best of our knowledge, this is the first attempt made towards multi-class segmentation in ureteroscopy and laser lithotripsy data. We propose an end-to-end CNN-based framework for the segmentation of stones and laser fiber. The proposed approach utilizes two sub-networks: HybResUNet, a version of residual U-Net, that uses residual connections in the encoder path of U-Net and a DVFNet that generates DVF predictions which are then used to prune the prediction maps. We also present ablation studies that combine dilated convolutions, recurrent and residual connections, ASPP and attention gate. We propose a compound loss function that improves our segmentation performance. We have also provided an ablation study to determine the optimal data augmentation strategy. Our qualitative and quantitative results illustrate that our proposed method outperforms SOTA methods such as UNet and DeepLabv3+ showing an improvement of 5.2% and 15.93%, respectively, for the combined mean of DSC and JI in our invivo test dataset. We also show that our proposed model generalizes better on a new clinical dataset showing a mean improvement of 25.4%, 20%, and 11% over UNet, HybResUNet, and DeepLabv3+, respectively, for the same metric.

</p>
</details>

<details><summary><b>Attention Forcing for Machine Translation</b>
<a href="https://arxiv.org/abs/2104.01264">arxiv:2104.01264</a>
&#x1F4C8; 3 <br>
<p>Qingyun Dou, Yiting Lu, Potsawee Manakul, Xixin Wu, Mark J. F. Gales</p></summary>
<p>

**Abstract:** Auto-regressive sequence-to-sequence models with attention mechanisms have achieved state-of-the-art performance in various tasks including Text-To-Speech (TTS) and Neural Machine Translation (NMT). The standard training approach, teacher forcing, guides a model with the reference output history. At inference stage, the generated output history must be used. This mismatch can impact performance. However, it is highly challenging to train the model using the generated output. Several approaches have been proposed to address this problem, normally by selectively using the generated output history. To make training stable, these approaches often require a heuristic schedule or an auxiliary classifier. This paper introduces attention forcing for NMT. This approach guides the model with the generated output history and reference attention, and can reduce the training-inference mismatch without a schedule or a classifier. Attention forcing has been successful in TTS, but its application to NMT is more challenging, due to the discrete and multi-modal nature of the output space. To tackle this problem, this paper adds a selection scheme to vanilla attention forcing, which automatically selects a suitable training approach for each pair of training data. Experiments show that attention forcing can improve the overall translation quality and the diversity of the translations.

</p>
</details>

<details><summary><b>Autonomous Driving Data Chain & Interfaces</b>
<a href="https://arxiv.org/abs/2104.01252">arxiv:2104.01252</a>
&#x1F4C8; 3 <br>
<p>Benjamin Kahl</p></summary>
<p>

**Abstract:** Recent developments in autonomous driving technology have proven that map data may be used, not only for general routing purposes, but also for to enhance and complement common sensor data. This document reviews the most commonly used interfaces and formats at each step of a selfhealing map data chain.

</p>
</details>

<details><summary><b>Defending Against Image Corruptions Through Adversarial Augmentations</b>
<a href="https://arxiv.org/abs/2104.01086">arxiv:2104.01086</a>
&#x1F4C8; 3 <br>
<p>Dan A. Calian, Florian Stimberg, Olivia Wiles, Sylvestre-Alvise Rebuffi, Andras Gyorgy, Timothy Mann, Sven Gowal</p></summary>
<p>

**Abstract:** Modern neural networks excel at image classification, yet they remain vulnerable to common image corruptions such as blur, speckle noise or fog. Recent methods that focus on this problem, such as AugMix and DeepAugment, introduce defenses that operate in expectation over a distribution of image corruptions. In contrast, the literature on $\ell_p$-norm bounded perturbations focuses on defenses against worst-case corruptions. In this work, we reconcile both approaches by proposing AdversarialAugment, a technique which optimizes the parameters of image-to-image models to generate adversarially corrupted augmented images. We theoretically motivate our method and give sufficient conditions for the consistency of its idealized version as well as that of DeepAugment. Our classifiers improve upon the state-of-the-art on common image corruption benchmarks conducted in expectation on CIFAR-10-C and improve worst-case performance against $\ell_p$-norm bounded perturbations on both CIFAR-10 and ImageNet.

</p>
</details>

<details><summary><b>Distributional Offline Continuous-Time Reinforcement Learning with Neural Physics-Informed PDEs (SciPhy RL for DOCTR-L)</b>
<a href="https://arxiv.org/abs/2104.01040">arxiv:2104.01040</a>
&#x1F4C8; 3 <br>
<p>Igor Halperin</p></summary>
<p>

**Abstract:** This paper addresses distributional offline continuous-time reinforcement learning (DOCTR-L) with stochastic policies for high-dimensional optimal control. A soft distributional version of the classical Hamilton-Jacobi-Bellman (HJB) equation is given by a semilinear partial differential equation (PDE). This `soft HJB equation' can be learned from offline data without assuming that the latter correspond to a previous optimal or near-optimal policy. A data-driven solution of the soft HJB equation uses methods of Neural PDEs and Physics-Informed Neural Networks developed in the field of Scientific Machine Learning (SciML). The suggested approach, dubbed `SciPhy RL', thus reduces DOCTR-L to solving neural PDEs from data. Our algorithm called Deep DOCTR-L converts offline high-dimensional data into an optimal policy in one step by reducing it to supervised learning, instead of relying on value iteration or policy iteration methods. The method enables a computable approach to the quality control of obtained policies in terms of both their expected returns and uncertainties about their values.

</p>
</details>

<details><summary><b>Glioma Prognosis: Segmentation of the Tumor and Survival Prediction using Shape, Geometric and Clinical Information</b>
<a href="https://arxiv.org/abs/2104.00980">arxiv:2104.00980</a>
&#x1F4C8; 3 <br>
<p>Mobarakol Islam, V Jeya Maria Jose, Hongliang Ren</p></summary>
<p>

**Abstract:** Segmentation of brain tumor from magnetic resonance imaging (MRI) is a vital process to improve diagnosis, treatment planning and to study the difference between subjects with tumor and healthy subjects. In this paper, we exploit a convolutional neural network (CNN) with hypercolumn technique to segment tumor from healthy brain tissue. Hypercolumn is the concatenation of a set of vectors which form by extracting convolutional features from multiple layers. Proposed model integrates batch normalization (BN) approach with hypercolumn. BN layers help to alleviate the internal covariate shift during stochastic gradient descent (SGD) training by zero-mean and unit variance of each mini-batch. Survival Prediction is done by first extracting features(Geometric, Fractal, and Histogram) from the segmented brain tumor data. Then, the number of days of overall survival is predicted by implementing regression on the extracted features using an artificial neural network (ANN). Our model achieves a mean dice score of 89.78%, 82.53% and 76.54% for the whole tumor, tumor core and enhancing tumor respectively in segmentation task and 67.90% in overall survival prediction task with the validation set of BraTS 2018 challenge. It obtains a mean dice accuracy of 87.315%, 77.04% and 70.22% for the whole tumor, tumor core and enhancing tumor respectively in the segmentation task and a 46.80% in overall survival prediction task in the BraTS 2018 test data set.

</p>
</details>

<details><summary><b>Variational Deep Image Denoising</b>
<a href="https://arxiv.org/abs/2104.00965">arxiv:2104.00965</a>
&#x1F4C8; 3 <br>
<p>Jae Woong Soh, Nam Ik Cho</p></summary>
<p>

**Abstract:** Convolutional neural networks (CNNs) have shown outstanding performance on image denoising with the help of large-scale datasets. Earlier methods naively trained a single CNN with many pairs of clean-noisy images. However, the conditional distribution of the clean image given a noisy one is too complicated and diverse, so that a single CNN cannot well learn such distributions. Therefore, there have also been some methods that exploit additional noise level parameters or train a separate CNN for a specific noise level parameter. These methods separate the original problem into easier sub-problems and thus have shown improved performance than the naively trained CNN. In this step, we raise two questions. The first one is whether it is an optimal approach to relate the conditional distribution only to noise level parameters. The second is what if we do not have noise level information, such as in a real-world scenario. To answer the questions and provide a better solution, we propose a novel Bayesian framework based on the variational approximation of objective functions. This enables us to separate the complicated target distribution into simpler sub-distributions. Eventually, the denoising CNN can conquer noise from each sub-distribution, which is generally an easier problem than the original. Experiments show that the proposed method provides remarkable performance on additive white Gaussian noise (AWGN) and real-noise denoising while requiring fewer parameters than recent state-of-the-art denoisers.

</p>
</details>

<details><summary><b>Using GPT-2 to Create Synthetic Data to Improve the Prediction Performance of NLP Machine Learning Classification Models</b>
<a href="https://arxiv.org/abs/2104.10658">arxiv:2104.10658</a>
&#x1F4C8; 2 <br>
<p>Dewayne Whitfield</p></summary>
<p>

**Abstract:** Classification Models use input data to predict the likelihood that the subsequent input data will fall into predetermined categories. To perform effective classifications, these models require large datasets for training. It is becoming common practice to utilize synthetic data to boost the performance of Machine Learning Models. It is reported that Shell is using synthetic data to build models to detect problems that rarely occur; for example Shell created synthetic data to help models to identify deteriorating oil lines. It is common practice for Machine Learning Practitioners to generate synthetic data by rotating, flipping, and cropping images to increase the volume of image data to train Convolutional Neural Networks. The purpose of this paper is to explore creating and utilizing synthetic NLP data to improve the performance of Natural Language Processing Machine Learning Classification Models. In this paper I used a Yelp pizza restaurant reviews dataset and transfer learning to fine-tune a pre-trained GPT-2 Transformer Model to generate synthetic pizza reviews data. I then combined this synthetic data with the original genuine data to create a new joint dataset. The new combined model significantly outperformed the original model in accuracy and precision.

</p>
</details>

<details><summary><b>Malignancy Prediction and Lesion Identification from Clinical Dermatological Images</b>
<a href="https://arxiv.org/abs/2104.02652">arxiv:2104.02652</a>
&#x1F4C8; 2 <br>
<p>Meng Xia, Meenal K. Kheterpal, Samantha C. Wong, Christine Park, William Ratliff, Lawrence Carin, Ricardo Henao</p></summary>
<p>

**Abstract:** We consider machine-learning-based malignancy prediction and lesion identification from clinical dermatological images, which can be indistinctly acquired via smartphone or dermoscopy capture. Additionally, we do not assume that images contain single lesions, thus the framework supports both focal or wide-field images. Specifically, we propose a two-stage approach in which we first identify all lesions present in the image regardless of sub-type or likelihood of malignancy, then it estimates their likelihood of malignancy, and through aggregation, it also generates an image-level likelihood of malignancy that can be used for high-level screening processes. Further, we consider augmenting the proposed approach with clinical covariates (from electronic health records) and publicly available data (the ISIC dataset). Comprehensive experiments validated on an independent test dataset demonstrate that i) the proposed approach outperforms alternative model architectures; ii) the model based on images outperforms a pure clinical model by a large margin, and the combination of images and clinical data does not significantly improves over the image-only model; and iii) the proposed framework offers comparable performance in terms of malignancy classification relative to three board certified dermatologists with different levels of experience.

</p>
</details>

<details><summary><b>Neurons learn slower than they think</b>
<a href="https://arxiv.org/abs/2104.02578">arxiv:2104.02578</a>
&#x1F4C8; 2 <br>
<p>Ilona Kulikovskikh</p></summary>
<p>

**Abstract:** Recent studies revealed complex convergence dynamics in gradient-based methods, which has been little understood so far. Changing the step size to balance between high convergence rate and small generalization error may not be sufficient: maximizing the test accuracy usually requires a larger learning rate than minimizing the training loss. To explore the dynamic bounds of convergence rate, this study introduces \textit{differential capability} into an optimization process, which measures whether the test accuracy increases as fast as a model approaches the decision boundary in a classification problem. The convergence analysis showed that: 1) a higher convergence rate leads to slower capability growth; 2) a lower convergence rate results in faster capability growth and decay; 3) regulating a convergence rate in either direction reduces differential capability.

</p>
</details>

<details><summary><b>Topological Regularization for Graph Neural Networks Augmentation</b>
<a href="https://arxiv.org/abs/2104.02478">arxiv:2104.02478</a>
&#x1F4C8; 2 <br>
<p>Rui Song, Fausto Giunchiglia, Ke Zhao, Hao Xu</p></summary>
<p>

**Abstract:** The complexity and non-Euclidean structure of graph data hinder the development of data augmentation methods similar to those in computer vision. In this paper, we propose a feature augmentation method for graph nodes based on topological regularization, in which topological structure information is introduced into end-to-end model. Specifically, we first obtain topology embedding of nodes through unsupervised representation learning method based on random walk. Then, the topological embedding as additional features and the original node features are input into a dual graph neural network for propagation, and two different high-order neighborhood representations of nodes are obtained. On this basis, we propose a regularization technique to bridge the differences between the two different node representations, eliminate the adverse effects caused by the topological features of graphs directly used, and greatly improve the performance. We have carried out extensive experiments on a large number of datasets to prove the effectiveness of our model.

</p>
</details>

<details><summary><b>End-to-end Deep Learning Pipeline for Microwave Kinetic Inductance Detector (MKID) Resonator Identification and Tuning</b>
<a href="https://arxiv.org/abs/2104.01282">arxiv:2104.01282</a>
&#x1F4C8; 2 <br>
<p>Neelay Fruitwala, Alex B Walter, John I Bailey III, Rupert Dodkins, Benjamin A Mazin</p></summary>
<p>

**Abstract:** We present the development of a machine learning based pipeline to fully automate the calibration of the frequency comb used to read out optical/IR Microwave Kinetic Inductance Detector (MKID) arrays. This process involves determining the resonant frequency and optimal drive power of every pixel (i.e. resonator) in the array, which is typically done manually. Modern optical/IR MKID arrays, such as DARKNESS (DARK-speckle Near-infrared Energy-resolving Superconducting Spectrophotometer) and MEC (MKID Exoplanet Camera), contain 10-20,000 pixels, making the calibration process extremely time consuming; each 2000 pixel feedline requires 4-6 hours of manual tuning. Here we present a pipeline which uses a single convolutional neural network (CNN) to perform both resonator identification and tuning simultaneously. We find that our pipeline has performance equal to that of the manual tuning process, and requires just twelve minutes of computational time per feedline.

</p>
</details>

<details><summary><b>Robotic Waste Sorter with Agile Manipulation and Quickly Trainable Detector</b>
<a href="https://arxiv.org/abs/2104.01260">arxiv:2104.01260</a>
&#x1F4C8; 2 <br>
<p>Takuya Kiyokawa, Hiroki Katayama, Yuya Tatsuta, Jun Takamatsu, Tsukasa Ogasawara</p></summary>
<p>

**Abstract:** Owing to human labor shortages, the automation of labor-intensive manual waste-sorting is needed. The goal of automating waste-sorting is to replace the human role of robust detection and agile manipulation of waste items with robots. To achieve this, we propose three methods. First, we provide a combined manipulation method using graspless push-and-drop and pick-and-release manipulation. Second, we provide a robotic system that can automatically collect object images to quickly train a deep neural-network model. Third, we provide a method to mitigate the differences in the appearance of target objects from two scenes: one for dataset collection and the other for waste sorting in a recycling factory. If differences exist, the performance of a trained waste detector may decrease. We address differences in illumination and background by applying object scaling, histogram matching with histogram equalization, and background synthesis to the source target-object images. Via experiments in an indoor experimental workplace for waste-sorting, we confirm that the proposed methods enable quick collection of the training image sets for three classes of waste items (i.e., aluminum can, glass bottle, and plastic bottle) and detection with higher performance than the methods that do not consider the differences. We also confirm that the proposed method enables the robot quickly manipulate the objects.

</p>
</details>

<details><summary><b>Learning Description Logic Ontologies. Five Approaches. Where Do They Stand?</b>
<a href="https://arxiv.org/abs/2104.01193">arxiv:2104.01193</a>
&#x1F4C8; 2 <br>
<p>Ana Ozaki</p></summary>
<p>

**Abstract:** The quest for acquiring a formal representation of the knowledge of a domain of interest has attracted researchers with various backgrounds into a diverse field called ontology learning. We highlight classical machine learning and data mining approaches that have been proposed for (semi-)automating the creation of description logic (DL) ontologies. These are based on association rule mining, formal concept analysis, inductive logic programming, computational learning theory, and neural networks. We provide an overview of each approach and how it has been adapted for dealing with DL ontologies. Finally, we discuss the benefits and limitations of each of them for learning DL ontologies.

</p>
</details>

<details><summary><b>Developing a New Autism Diagnosis Process Based on a Hybrid Deep Learning Architecture Through Analyzing Home Videos</b>
<a href="https://arxiv.org/abs/2104.01137">arxiv:2104.01137</a>
&#x1F4C8; 2 <br>
<p>Spencer He, Ryan Liu</p></summary>
<p>

**Abstract:** Currently, every 1 in 54 children have been diagnosed with Autism Spectrum Disorder (ASD), which is 178% higher than it was in 2000. An early diagnosis and treatment can significantly increase the chances of going off the spectrum and making a full recovery. With a multitude of physical and behavioral tests for neurological and communication skills, diagnosing ASD is very complex, subjective, time-consuming, and expensive. We hypothesize that the use of machine learning analysis on facial features and social behavior can speed up the diagnosis of ASD without compromising real-world performance. We propose to develop a hybrid architecture using both categorical data and image data to automate traditional ASD pre-screening, which makes diagnosis a quicker and easier process. We created and tested a Logistic Regression model and a Linear Support Vector Machine for Module 1, which classifies ADOS categorical data. A Convolutional Neural Network and a DenseNet network are used for module 2, which classifies video data. Finally, we combined the best performing models, a Linear SVM and DenseNet, using three data averaging strategies. We used a standard average, weighted based on number of training data, and weighted based on the number of ASD patients in the training data to average the results, thereby increasing accuracy in clinical applications. The results we obtained support our hypothesis. Our novel architecture is able to effectively automate ASD pre-screening with a maximum weighted accuracy of 84%.

</p>
</details>

<details><summary><b>What Taggers Fail to Learn, Parsers Need the Most</b>
<a href="https://arxiv.org/abs/2104.01083">arxiv:2104.01083</a>
&#x1F4C8; 2 <br>
<p>Mark Anderson, Carlos Gómez-Rodríguez</p></summary>
<p>

**Abstract:** We present an error analysis of neural UPOS taggers to evaluate why using gold standard tags has such a large positive contribution to parsing performance while using predicted UPOS tags either harms performance or offers a negligible improvement. We evaluate what neural dependency parsers implicitly learn about word types and how this relates to the errors taggers make to explain the minimal impact using predicted tags has on parsers. We also present a short analysis on what contexts result in reductions in tagging performance. We then mask UPOS tags based on errors made by taggers to tease away the contribution of UPOS tags which taggers succeed and fail to classify correctly and the impact of tagging errors.

</p>
</details>

<details><summary><b>Prediction of Tuberculosis using U-Net and segmentation techniques</b>
<a href="https://arxiv.org/abs/2104.01071">arxiv:2104.01071</a>
&#x1F4C8; 2 <br>
<p>Dennis Núñez-Fernández, Lamberto Ballan, Gabriel Jiménez-Avalos, Jorge Coronel, Patricia Sheen, Mirko Zimic</p></summary>
<p>

**Abstract:** One of the most serious public health problems in Peru and worldwide is Tuberculosis (TB), which is produced by a bacterium known as Mycobacterium tuberculosis. The purpose of this work is to facilitate and automate the diagnosis of tuberculosis using the MODS method and using lens-free microscopy, as it is easier to calibrate and easier to use by untrained personnel compared to lens microscopy. Therefore, we employed a U-Net network on our collected data set to perform automatic segmentation of cord shape bacterial accumulation and then predict tuberculosis. Our results show promising evidence for automatic segmentation of TB cords, and thus good accuracy for TB prediction.

</p>
</details>

<details><summary><b>Permutation-Invariant Subgraph Discovery</b>
<a href="https://arxiv.org/abs/2104.01063">arxiv:2104.01063</a>
&#x1F4C8; 2 <br>
<p>Raghvendra Mall, Shameem A. Parambath, Han Yufei, Ting Yu, Sanjay Chawla</p></summary>
<p>

**Abstract:** We introduce Permutation and Structured Perturbation Inference (PSPI), a new problem formulation that abstracts many graph matching tasks that arise in systems biology. PSPI can be viewed as a robust formulation of the permutation inference or graph matching, where the objective is to find a permutation between two graphs under the assumption that a set of edges may have undergone a perturbation due to an underlying cause. For example, suppose there are two gene regulatory networks X and Y from a diseased and normal tissue respectively. Then, the PSPI problem can be used to detect if there has been a structural change between the two networks which can serve as a signature of the disease. Besides the new problem formulation, we propose an ADMM algorithm (STEPD) to solve a relaxed version of the PSPI problem. An extensive case study on comparative gene regulatory networks (GRNs) is used to demonstrate that STEPD is able to accurately infer structured perturbations and thus provides a tool for computational biologists to identify novel prognostic signatures. A spectral analysis confirms that STEPD can recover small clique-like perturbations making it a useful tool for detecting permutation-invariant changes in graphs.

</p>
</details>

<details><summary><b>Effect of depth order on iterative nested named entity recognition models</b>
<a href="https://arxiv.org/abs/2104.01037">arxiv:2104.01037</a>
&#x1F4C8; 2 <br>
<p>Perceval Wajsburt, Yoann Taillé, Xavier Tannier</p></summary>
<p>

**Abstract:** This paper studies the effect of the order of depth of mention on nested named entity recognition (NER) models. NER is an essential task in the extraction of biomedical information, and nested entities are common since medical concepts can assemble to form larger entities. Conventional NER systems only predict disjointed entities. Thus, iterative models for nested NER use multiple predictions to enumerate all entities, imposing a predefined order from largest to smallest or smallest to largest. We design an order-agnostic iterative model and a procedure to choose a custom order during training and prediction. To accommodate for this task, we propose a modification of the Transformer architecture to take into account the entities predicted in the previous steps. We provide a set of experiments to study the model's capabilities and the effects of the order on performance. Finally, we show that the smallest to largest order gives the best results.

</p>
</details>

<details><summary><b>A Comparison of Similarity Based Instance Selection Methods for Cross Project Defect Prediction</b>
<a href="https://arxiv.org/abs/2104.01024">arxiv:2104.01024</a>
&#x1F4C8; 2 <br>
<p>Seyedrebvar Hosseini, Burak Turhan</p></summary>
<p>

**Abstract:** Context: Previous studies have shown that training data instance selection based on nearest neighborhood (NN) information can lead to better performance in cross project defect prediction (CPDP) by reducing heterogeneity in training datasets. However, neighborhood calculation is computationally expensive and approximate methods such as Locality Sensitive Hashing (LSH) can be as effective as exact methods. Aim: We aim at comparing instance selection methods for CPDP, namely LSH, NN-filter, and Genetic Instance Selection (GIS). Method: We conduct experiments with five base learners, optimizing their hyper parameters, on 13 datasets from PROMISE repository in order to compare the performance of LSH with benchmark instance selection methods NN-Filter and GIS. Results: The statistical tests show six distinct groups for F-measure performance. The top two group contains only LSH and GIS benchmarks whereas the bottom two groups contain only NN-Filter variants. LSH and GIS favor recall more than precision. In fact, for precision performance only three significantly distinct groups are detected by the tests where the top group is comprised of NN-Filter variants only. Recall wise, 16 different groups are identified where the top three groups contain only LSH methods, four of the next six are GIS only and the bottom five contain only NN-Filter. Finally, NN-Filter benchmarks never outperform the LSH counterparts with the same base learner, tuned or non-tuned. Further, they never even belong to the same rank group, meaning that LSH is always significantly better than NN-Filter with the same learner and settings. Conclusions: The increase in performance and the decrease in computational overhead and runtime make LSH a promising approach. However, the performance of LSH is based on high recall and in environments where precision is considered more important NN-Filter should be considered.

</p>
</details>

<details><summary><b>Learning Online from Corrective Feedback: A Meta-Algorithm for Robotics</b>
<a href="https://arxiv.org/abs/2104.01021">arxiv:2104.01021</a>
&#x1F4C8; 2 <br>
<p>Matthew Schmittle, Sanjiban Choudhury, Siddhartha S. Srinivasa</p></summary>
<p>

**Abstract:** A key challenge in Imitation Learning (IL) is that optimal state actions demonstrations are difficult for the teacher to provide. For example in robotics, providing kinesthetic demonstrations on a robotic manipulator requires the teacher to control multiple degrees of freedom at once. The difficulty of requiring optimal state action demonstrations limits the space of problems where the teacher can provide quality feedback. As an alternative to state action demonstrations, the teacher can provide corrective feedback such as their preferences or rewards. Prior work has created algorithms designed to learn from specific types of noisy feedback, but across teachers and tasks different forms of feedback may be required. Instead we propose that in order to learn from a diversity of scenarios we need to learn from a variety of feedback. To learn from a variety of feedback we make the following insight: the teacher's cost function is latent and we can model a stream of feedback as a stream of loss functions. We then use any online learning algorithm to minimize the sum of these losses. With this insight we can learn from a diversity of feedback that is weakly correlated with the teacher's true cost function. We unify prior work into a general corrective feedback meta-algorithm and show that regardless of feedback we can obtain the same regret bounds. We demonstrate our approach by learning to perform a household navigation task on a robotic racecar platform. Our results show that our approach can learn quickly from a variety of noisy feedback.

</p>
</details>

<details><summary><b>An Empirical Evaluation of Cost-based Federated SPARQL Query Processing Engines</b>
<a href="https://arxiv.org/abs/2104.00984">arxiv:2104.00984</a>
&#x1F4C8; 2 <br>
<p>Umair Qudus, Muhammad Saleem, Axel-Cyrille Ngonga Ngomo, Young-koo Lee</p></summary>
<p>

**Abstract:** Finding a good query plan is key to the optimization of query runtime. This holds in particular for cost-based federation engines, which make use of cardinality estimations to achieve this goal. A number of studies compare SPARQL federation engines across different performance metrics, including query runtime, result set completeness and correctness, number of sources selected and number of requests sent. Albeit informative, these metrics are generic and unable to quantify and evaluate the accuracy of the cardinality estimators of cost-based federation engines. To thoroughly evaluate cost-based federation engines, the effect of estimated cardinality errors on the overall query runtime performance must be measured. In this paper, we address this challenge by presenting novel evaluation metrics targeted at a fine-grained benchmarking of cost-based federated SPARQL query engines. We evaluate five cost-based federated SPARQL query engines using existing as well as novel evaluation metrics by using LargeRDFBench queries. Our results provide a detailed analysis of the experimental outcomes that reveal novel insights, useful for the development of future cost-based federated SPARQL query processing engines.

</p>
</details>

<details><summary><b>Explainable Artificial Intelligence (XAI) on TimeSeries Data: A Survey</b>
<a href="https://arxiv.org/abs/2104.00950">arxiv:2104.00950</a>
&#x1F4C8; 2 <br>
<p>Thomas Rojat, Raphaël Puget, David Filliat, Javier Del Ser, Rodolphe Gelin, Natalia Díaz-Rodríguez</p></summary>
<p>

**Abstract:** Most of state of the art methods applied on time series consist of deep learning methods that are too complex to be interpreted. This lack of interpretability is a major drawback, as several applications in the real world are critical tasks, such as the medical field or the autonomous driving field. The explainability of models applied on time series has not gather much attention compared to the computer vision or the natural language processing fields. In this paper, we present an overview of existing explainable AI (XAI) methods applied on time series and illustrate the type of explanations they produce. We also provide a reflection on the impact of these explanation methods to provide confidence and trust in the AI systems.

</p>
</details>

<details><summary><b>Efficacy of Bayesian Neural Networks in Active Learning</b>
<a href="https://arxiv.org/abs/2104.00896">arxiv:2104.00896</a>
&#x1F4C8; 2 <br>
<p>Vineeth Rakesh, Swayambhoo Jain</p></summary>
<p>

**Abstract:** Obtaining labeled data for machine learning tasks can be prohibitively expensive. Active learning mitigates this issue by exploring the unlabeled data space and prioritizing the selection of data that can best improve the model performance. A common approach to active learning is to pick a small sample of data for which the model is most uncertain. In this paper, we explore the efficacy of Bayesian neural networks for active learning, which naturally models uncertainty by learning distribution over the weights of neural networks. By performing a comprehensive set of experiments, we show that Bayesian neural networks are more efficient than ensemble based techniques in capturing uncertainty. Our findings also reveal some key drawbacks of the ensemble techniques, which was recently shown to be more effective than Monte Carlo dropouts.

</p>
</details>

<details><summary><b>Low Dose Helical CBCT denoising by using domain filtering with deep reinforcement learning</b>
<a href="https://arxiv.org/abs/2104.00889">arxiv:2104.00889</a>
&#x1F4C8; 2 <br>
<p>Wooram Kang, Mayank Patwari</p></summary>
<p>

**Abstract:** Cone Beam Computed Tomography(CBCT) is a now known method to conduct CT imaging. Especially, The Low Dose CT imaging is one of possible options to protect organs of patients when conducting CT imaging. Therefore Low Dose CT imaging can be an alternative instead of Standard dose CT imaging. However Low Dose CT imaging has a fundamental issue with noises within results compared to Standard Dose CT imaging. Currently, there are lots of attempts to erase the noises. Most of methods with artificial intelligence have many parameters and unexplained layers or a kind of black-box methods. Therefore, our research has purposes related to these issues. Our approach has less parameters than usual methods by having Iterative learn-able bilateral filtering approach with Deep reinforcement learning. And we applied The Iterative learn-able filtering approach with deep reinforcement learning to sinograms and reconstructed volume domains. The method and the results of the method can be much more explainable than The other black box AI approaches. And we applied the method to Helical Cone Beam Computed Tomography(CBCT), which is the recent CBCT trend. We tested this method with on 2 abdominal scans(L004, L014) from Mayo Clinic TCIA dataset. The results and the performances of our approach overtake the results of the other previous methods.

</p>
</details>

<details><summary><b>Federated Double Deep Q-learning for Joint Delay and Energy Minimization in IoT networks</b>
<a href="https://arxiv.org/abs/2104.11320">arxiv:2104.11320</a>
&#x1F4C8; 1 <br>
<p>Sheyda Zarandi, Hina Tabassum</p></summary>
<p>

**Abstract:** In this paper, we propose a federated deep reinforcement learning framework to solve a multi-objective optimization problem, where we consider minimizing the expected long-term task completion delay and energy consumption of IoT devices. This is done by optimizing offloading decisions, computation resource allocation, and transmit power allocation. Since the formulated problem is a mixed-integer non-linear programming (MINLP), we first cast our problem as a multi-agent distributed deep reinforcement learning (DRL) problem and address it using double deep Q-network (DDQN), where the actions are offloading decisions. The immediate cost of each agent is calculated through solving either the transmit power optimization or local computation resource optimization, based on the selected offloading decisions (actions). Then, to enhance the learning speed of IoT devices (agents), we incorporate federated learning (FDL) at the end of each episode. FDL enhances the scalability of the proposed DRL framework, creates a context for cooperation between agents, and minimizes their privacy concerns. Our numerical results demonstrate the efficacy of our proposed federated DDQN framework in terms of learning speed compared to federated deep Q network (DQN) and non-federated DDQN algorithms. In addition, we investigate the impact of batch size, network layers, DDQN target network update frequency on the learning speed of the FDL.

</p>
</details>

<details><summary><b>Solving Large Scale Quadratic Constrained Basis Pursuit</b>
<a href="https://arxiv.org/abs/2104.02475">arxiv:2104.02475</a>
&#x1F4C8; 1 <br>
<p>Jirong Yi</p></summary>
<p>

**Abstract:** Inspired by alternating direction method of multipliers and the idea of operator splitting, we propose a efficient algorithm for solving large-scale quadratically constrained basis pursuit. Experimental results show that the proposed algorithm can achieve 50~~100 times speedup when compared with the baseline interior point algorithm implemented in CVX.

</p>
</details>

<details><summary><b>Multimedia Technology Applications and Algorithms: A Survey</b>
<a href="https://arxiv.org/abs/2104.01301">arxiv:2104.01301</a>
&#x1F4C8; 1 <br>
<p>Palak Tiwary, Sanjida Ahmed</p></summary>
<p>

**Abstract:** Multimedia related research and development has evolved rapidly in the last few years with advancements in hardware, software and network infrastructures. As a result, multimedia has been integrated into domains like Healthcare and Medicine, Human facial feature extraction and tracking, pose recognition, disparity estimation, etc. This survey gives an overview of the various multimedia technologies and algorithms developed in the domains mentioned.

</p>
</details>

<details><summary><b>Designing for human-AI complementarity in K-12 education</b>
<a href="https://arxiv.org/abs/2104.01266">arxiv:2104.01266</a>
&#x1F4C8; 1 <br>
<p>Kenneth Holstein, Vincent Aleven</p></summary>
<p>

**Abstract:** Recent work has explored how complementary strengths of humans and artificial intelligence (AI) systems might be productively combined. However, successful forms of human-AI partnership have rarely been demonstrated in real-world settings. We present the iterative design and evaluation of Lumilo, smart glasses that help teachers help their students in AI-supported classrooms by presenting real-time analytics about students' learning, metacognition, and behavior. Results from a field study conducted in K-12 classrooms indicate that students learn more when teachers and AI tutors work together during class. We discuss implications of this research for the design of human-AI partnerships. We argue for more participatory approaches to research and design in this area, in which practitioners and other stakeholders are deeply, meaningfully involved throughout the process. Furthermore, we advocate for theory-building and for principled approaches to the study of human-AI decision-making in real-world contexts.

</p>
</details>

<details><summary><b>Scan Specific Artifact Reduction in K-space (SPARK) Neural Networks Synergize with Physics-based Reconstruction to Accelerate MRI</b>
<a href="https://arxiv.org/abs/2104.01188">arxiv:2104.01188</a>
&#x1F4C8; 1 <br>
<p>Yamin Arefeen, Onur Beker, Jaejin Cho, Heng Yu, Elfar Adalsteinsson, Berkin Bilgic</p></summary>
<p>

**Abstract:** Purpose: To develop a scan-specific model that estimates and corrects k-space errors made when reconstructing accelerated Magnetic Resonance Imaging (MRI) data.
  Methods: Scan-Specific Artifact Reduction in k-space (SPARK) trains a convolutional-neural-network to estimate and correct k-space errors made by an input reconstruction technique by back-propagating from the mean-squared-error loss between an auto-calibration signal (ACS) and the input technique's reconstructed ACS. First, SPARK is applied to GRAPPA and demonstrates improved robustness over other scan-specific models, such as RAKI and residual-RAKI. Subsequent experiments demonstrate that SPARK synergizes with residual-RAKI to improve reconstruction performance. SPARK also improves reconstruction quality when applied to advanced acquisition and reconstruction techniques like 2D virtual coil (VC-) GRAPPA, 2D LORAKS, 3D GRAPPA without an integrated ACS region, and 2D/3D wave-encoded images.
  Results: SPARK yields 1.5x - 2x RMSE reduction when applied to GRAPPA and improves robustness to ACS size for various acceleration rates in comparison to other scan-specific techniques. When applied to advanced reconstruction techniques such as residual-RAKI, 2D VC-GRAPPA and LORAKS, SPARK achieves up to 20% RMSE improvement. SPARK with 3D GRAPPA also improves performance by ~2x and perceived image quality without a fully sampled ACS region. Finally, SPARK synergizes with non-cartesian 2D and 3D wave-encoding imaging by reducing RMSE between 20-25% and providing qualitative improvements.
  Conclusion: SPARK synergizes with physics-based acquisition and reconstruction techniques to improve accelerated MRI by training scan-specific models to estimate and correct reconstruction errors in k-space.

</p>
</details>

<details><summary><b>Using Simulation to Aid the Design and Optimization of Intelligent User Interfaces for Quality Assurance Processes in Machine Learning</b>
<a href="https://arxiv.org/abs/2104.01129">arxiv:2104.01129</a>
&#x1F4C8; 1 <br>
<p>Yu Zhang, Martijn Tennekes, Tim de Jong, Lyana Curier, Bob Coecke, Min Chen</p></summary>
<p>

**Abstract:** Many mission-critical applications of machine learning (ML) in the real-world require a quality assurance (QA) process before the decisions or predictions of an ML model can be deployed. Because QA4ML users have to view a non-trivial amount of data and perform many input actions to correct errors made by the ML model, an optimally-designed user interface (UI) can reduce the cost of interactions significantly. A UI's effectiveness can be affected by many factors, such as the number of data objects processed concurrently, the types of commands for correcting errors, and the availability of algorithms for assisting users. We propose using simulation to aid the design and optimization of intelligent user interfaces for QA4ML processes. In particular, we focus on simulating the combined effects of human intelligence in selecting appropriate commands and algorithms, and machine intelligence in providing a collection of general-purpose algorithms for reordering data objects to be quality-assured.

</p>
</details>

<details><summary><b>ESTemd: A Distributed Processing Framework for Environmental Monitoring based on Apache Kafka Streaming Engine</b>
<a href="https://arxiv.org/abs/2104.01082">arxiv:2104.01082</a>
&#x1F4C8; 1 <br>
<p>Adeyinka Akanbi</p></summary>
<p>

**Abstract:** Distributed networks and real-time systems are becoming the most important components for the new computer age, the Internet of Things (IoT), with huge data streams or data sets generated from sensors and data generated from existing legacy systems. The data generated offers the ability to measure, infer and understand environmental indicators, from delicate ecologies and natural resources to urban environments. This can be achieved through the analysis of the heterogeneous data sources (structured and unstructured). In this paper, we propose a distributed framework Event STream Processing Engine for Environmental Monitoring Domain (ESTemd) for the application of stream processing on heterogeneous environmental data. Our work in this area demonstrates the useful role big data techniques can play in an environmental decision support system, early warning and forecasting systems. The proposed framework addresses the challenges of data heterogeneity from heterogeneous systems and real time processing of huge environmental datasets through a publish/subscribe method via a unified data pipeline with the application of Apache Kafka for real time analytics.

</p>
</details>

<details><summary><b>Blind Exploration and Exploitation of Stochastic Experts</b>
<a href="https://arxiv.org/abs/2104.01078">arxiv:2104.01078</a>
&#x1F4C8; 1 <br>
<p>Noyan C. Sevuktekin, Andrew C. Singer</p></summary>
<p>

**Abstract:** We present blind exploration and exploitation (BEE) algorithms for identifying the most reliable stochastic expert based on formulations that employ posterior sampling, upper-confidence bounds, empirical Kullback-Leibler divergence, and minmax methods for the stochastic multi-armed bandit problem. Joint sampling and consultation of experts whose opinions depend on the hidden and random state of the world becomes challenging in the unsupervised, or blind, framework as feedback from the true state is not available. We propose an empirically realizable measure of expert competence that can be inferred instantaneously using only the opinions of other experts. This measure preserves the ordering of true competences and thus enables joint sampling and consultation of stochastic experts based on their opinions on dynamically changing tasks. Statistics derived from the proposed measure is instantaneously available allowing both blind exploration-exploitation and unsupervised opinion aggregation. We discuss how the lack of supervision affects the asymptotic regret of BEE architectures that rely on UCB1, KL-UCB, MOSS, IMED, and Thompson sampling. We demonstrate the performance of different BEE algorithms empirically and compare them to their standard, or supervised, counterparts.

</p>
</details>

<details><summary><b>Information Geometry and Classical Cramér-Rao Type Inequalities</b>
<a href="https://arxiv.org/abs/2104.01061">arxiv:2104.01061</a>
&#x1F4C8; 1 <br>
<p>Kumar Vijay Mishra, M. Ashok Kumar</p></summary>
<p>

**Abstract:** We examine the role of information geometry in the context of classical Cramér-Rao (CR) type inequalities. In particular, we focus on Eguchi's theory of obtaining dualistic geometric structures from a divergence function and then applying Amari-Nagoaka's theory to obtain a CR type inequality. The classical deterministic CR inequality is derived from Kullback-Leibler (KL)-divergence. We show that this framework could be generalized to other CR type inequalities through four examples: $α$-version of CR inequality, generalized CR inequality, Bayesian CR inequality, and Bayesian $α$-CR inequality. These are obtained from, respectively, $I_α$-divergence (or relative $α$-entropy), generalized Csiszár divergence, Bayesian KL divergence, and Bayesian $I_α$-divergence.

</p>
</details>

<details><summary><b>Assessment of machine learning methods for state-to-state approaches</b>
<a href="https://arxiv.org/abs/2104.01042">arxiv:2104.01042</a>
&#x1F4C8; 1 <br>
<p>Lorenzo Campoli, Elena Kustova, Polina Maltseva</p></summary>
<p>

**Abstract:** It is well known that numerical simulations of high-speed reacting flows, in the framework of state-to-state formulations, are the most detailed but also often prohibitively computationally expensive. In this work, we start to investigate the possibilities offered by the use of machine learning methods for state-to-state approaches to alleviate such burden.
  In this regard, several tasks have been identified. Firstly, we assessed the potential of state-of-the-art data-driven regression models based on machine learning to predict the relaxation source terms which appear in the right-hand side of the state-to-state Euler system of equations for a one-dimensional reacting flow of a N$_2$/N binary mixture behind a plane shock wave. It is found that, by appropriately choosing the regressor and opportunely tuning its hyperparameters, it is possible to achieve accurate predictions compared to the full-scale state-to-state simulation in significantly shorter times.
  Secondly, we investigated different strategies to speed-up our in-house state-to-state solver by coupling it with the best-performing pre-trained machine learning algorithm. The embedding of machine learning methods into ordinary differential equations solvers may offer a speed-up of several orders of magnitude but some care should be paid for how and where such coupling is realized. Performances are found to be strongly dependent on the mutual nature of the interfaced codes.
  Finally, we aimed at inferring the full solution of the state-to-state Euler system of equations by means of a deep neural network completely by-passing the use of the state-to-state solver while relying only on data. Promising results suggest that deep neural networks appear to be a viable technology also for these tasks.

</p>
</details>

<details><summary><b>Hybrid Policy Learning for Energy-Latency Tradeoff in MEC-Assisted VR Video Service</b>
<a href="https://arxiv.org/abs/2104.01036">arxiv:2104.01036</a>
&#x1F4C8; 1 <br>
<p>Chong Zheng, Shengheng Liu, Yongming Huang, Luxi Yang</p></summary>
<p>

**Abstract:** Virtual reality (VR) is promising to fundamentally transform a broad spectrum of industry sectors and the way humans interact with virtual content. However, despite unprecedented progress, current networking and computing infrastructures are incompetent to unlock VR's full potential. In this paper, we consider delivering the wireless multi-tile VR video service over a mobile edge computing (MEC) network. The primary goal is to minimize the system latency/energy consumption and to arrive at a tradeoff thereof. To this end, we first cast the time-varying view popularity as a model-free Markov chain to effectively capture its dynamic characteristics. After jointly assessing the caching and computing capacities on both the MEC server and the VR playback device, a hybrid policy is then implemented to coordinate the dynamic caching replacement and the deterministic offloading, so as to fully utilize the system resources. The underlying multi-objective problem is reformulated as a partially observable Markov decision process, and a deep deterministic policy gradient algorithm is proposed to iteratively learn its solution, where a long short-term memory neural network is embedded to continuously predict the dynamics of the unobservable popularity. Simulation results demonstrate the superiority of the proposed scheme in achieving a trade-off between the energy efficiency and the latency reduction over the baseline methods.

</p>
</details>

<details><summary><b>White paper: The Helix Pathogenicity Prediction Platform</b>
<a href="https://arxiv.org/abs/2104.01033">arxiv:2104.01033</a>
&#x1F4C8; 1 <br>
<p>Bas Vroling, Stephan Heijl</p></summary>
<p>

**Abstract:** In this white paper we introduce Helix, an AI based solution for missense pathogenicity prediction. With recent advances in the sequencing of human genomes, massive amounts of genetic data have become available. This has shifted the burden of labor for genetic diagnostics and research from the gathering of data to its interpretation. Helix presents a state of the art platform for the prediction of pathogenicity in human missense variants. In addition to offering best-in-class predictive performance, Helix offers a platform that allows researchers to analyze and interpret variants in depth that can be accessed at helixlabs.ai.

</p>
</details>

<details><summary><b>Brain Tumor Segmentation and Survival Prediction using 3D Attention UNet</b>
<a href="https://arxiv.org/abs/2104.00985">arxiv:2104.00985</a>
&#x1F4C8; 1 <br>
<p>Mobarakol Islam, Vibashan VS, V Jeya Maria Jose, Navodini Wijethilake, Uppal Utkarsh, Hongliang Ren</p></summary>
<p>

**Abstract:** In this work, we develop an attention convolutional neural network (CNN) to segment brain tumors from Magnetic Resonance Images (MRI). Further, we predict the survival rate using various machine learning methods. We adopt a 3D UNet architecture and integrate channel and spatial attention with the decoder network to perform segmentation. For survival prediction, we extract some novel radiomic features based on geometry, location, the shape of the segmented tumor and combine them with clinical information to estimate the survival duration for each patient. We also perform extensive experiments to show the effect of each feature for overall survival (OS) prediction. The experimental results infer that radiomic features such as histogram, location, and shape of the necrosis region and clinical features like age are the most critical parameters to estimate the OS.

</p>
</details>

<details><summary><b>COVID-19 Detection in Cough, Breath and Speech using Deep Transfer Learning and Bottleneck Features</b>
<a href="https://arxiv.org/abs/2104.02477">arxiv:2104.02477</a>
&#x1F4C8; 0 <br>
<p>Madhurananda Pahar, Marisa Klopper, Robin Warren, Thomas Niesler</p></summary>
<p>

**Abstract:** We present an experimental investigation into the effectiveness of transfer learning and bottleneck feature extraction in detecting COVID-19 from audio recordings of cough, breath and speech.
  This type of screening is non-contact, does not require specialist medical expertise or laboratory facilities and can be deployed on inexpensive consumer hardware.
  We use datasets that contain recordings of coughing, sneezing, speech and other noises, but do not contain COVID-19 labels, to pre-train three deep neural networks: a CNN, an LSTM and a Resnet50.
  These pre-trained networks are subsequently either fine-tuned using smaller datasets of coughing with COVID-19 labels in the process of transfer learning, or are used as bottleneck feature extractors.
  Results show that a Resnet50 classifier trained by this transfer learning process delivers optimal or near-optimal performance across all datasets achieving areas under the receiver operating characteristic (ROC AUC) of 0.98, 0.94 and 0.92 respectively for all three sound classes (coughs, breaths and speech).
  This indicates that coughs carry the strongest COVID-19 signature, followed by breath and speech.
  Our results also show that applying transfer learning and extracting bottleneck features using the larger datasets without COVID-19 labels led not only to improve performance, but also to minimise the standard deviation of the classifier AUCs among the outer folds of the leave-$p$-out cross-validation, indicating better generalisation.
  We conclude that deep transfer learning and bottleneck feature extraction can improve COVID-19 cough, breath and speech audio classification, yielding automatic classifiers with higher accuracy.

</p>
</details>

<details><summary><b>Misclassification-Aware Gaussian Smoothing and Mixed Augmentations improves Robustness against Domain Shifts</b>
<a href="https://arxiv.org/abs/2104.01231">arxiv:2104.01231</a>
&#x1F4C8; 0 <br>
<p>Athanasios Tsiligkaridis, Theodoros Tsiligkaridis</p></summary>
<p>

**Abstract:** Deep neural networks achieve high prediction accuracy when the train and test distributions coincide. In practice though, various types of corruptions can deviate from this setup and cause severe performance degradations. Few methods have been proposed to address generalization in the presence of unforeseen domain shifts. In this paper, we propose a misclassification-aware Gaussian smoothing approach, coupled with mixed data augmentations, for improving robustness of image classifiers against a variety of corruptions while still maintaining high clean accuracy. We show that our method improves upon the state-of-the-art in robustness and uncertainty calibration on several image classification benchmarks and network architectures.

</p>
</details>


[Next Page](2021/2021-04/2021-04-01.md)
