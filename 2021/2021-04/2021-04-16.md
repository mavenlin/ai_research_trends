## Summary for 2021-04-16, created on 2021-12-22


<details><summary><b>Editing Factual Knowledge in Language Models</b>
<a href="https://arxiv.org/abs/2104.08164">arxiv:2104.08164</a>
&#x1F4C8; 44 <br>
<p>Nicola De Cao, Wilker Aziz, Ivan Titov</p></summary>
<p>

**Abstract:** The factual knowledge acquired during pre-training and stored in the parameters of Language Models (LMs) can be useful in downstream tasks (e.g., question answering or textual inference). However, some facts can be incorrectly induced or become obsolete over time. We present KnowledgeEditor, a method which can be used to edit this knowledge and, thus, fix 'bugs' or unexpected predictions without the need for expensive re-training or fine-tuning. Besides being computationally efficient, KnowledgeEditordoes not require any modifications in LM pre-training (e.g., the use of meta-learning). In our approach, we train a hyper-network with constrained optimization to modify a fact without affecting the rest of the knowledge; the trained hyper-network is then used to predict the weight update at test time. We show KnowledgeEditor's efficacy with two popular architectures and knowledge-intensive tasks: i) a BERT model fine-tuned for fact-checking, and ii) a sequence-to-sequence BART model for question answering. With our method, changing a prediction on the specific wording of a query tends to result in a consistent change in predictions also for its paraphrases. We show that this can be further encouraged by exploiting (e.g., automatically-generated) paraphrases during training. Interestingly, our hyper-network can be regarded as a 'probe' revealing which components need to be changed to manipulate factual knowledge; our analysis shows that the updates tend to be concentrated on a small subset of components. Source code available at https://github.com/nicola-decao/KnowledgeEditor

</p>
</details>

<details><summary><b>MT-Opt: Continuous Multi-Task Robotic Reinforcement Learning at Scale</b>
<a href="https://arxiv.org/abs/2104.08212">arxiv:2104.08212</a>
&#x1F4C8; 42 <br>
<p>Dmitry Kalashnikov, Jacob Varley, Yevgen Chebotar, Benjamin Swanson, Rico Jonschkowski, Chelsea Finn, Sergey Levine, Karol Hausman</p></summary>
<p>

**Abstract:** General-purpose robotic systems must master a large repertoire of diverse skills to be useful in a range of daily tasks. While reinforcement learning provides a powerful framework for acquiring individual behaviors, the time needed to acquire each skill makes the prospect of a generalist robot trained with RL daunting. In this paper, we study how a large-scale collective robotic learning system can acquire a repertoire of behaviors simultaneously, sharing exploration, experience, and representations across tasks. In this framework new tasks can be continuously instantiated from previously learned tasks improving overall performance and capabilities of the system. To instantiate this system, we develop a scalable and intuitive framework for specifying new tasks through user-provided examples of desired outcomes, devise a multi-robot collective learning system for data collection that simultaneously collects experience for multiple tasks, and develop a scalable and generalizable multi-task deep reinforcement learning method, which we call MT-Opt. We demonstrate how MT-Opt can learn a wide range of skills, including semantic picking (i.e., picking an object from a particular category), placing into various fixtures (e.g., placing a food item onto a plate), covering, aligning, and rearranging. We train and evaluate our system on a set of 12 real-world tasks with data collected from 7 robots, and demonstrate the performance of our system both in terms of its ability to generalize to structurally similar new tasks, and acquire distinct new tasks more quickly by leveraging past experience. We recommend viewing the videos at https://karolhausman.github.io/mt-opt/

</p>
</details>

<details><summary><b>Attention! Stay Focus!</b>
<a href="https://arxiv.org/abs/2104.07925">arxiv:2104.07925</a>
&#x1F4C8; 38 <br>
<p>Tu Vo</p></summary>
<p>

**Abstract:** We develop a deep convolutional neural networks(CNNs) to deal with the blurry artifacts caused by the defocus of the camera using dual-pixel images. Specifically, we develop a double attention network which consists of attentional encoders, triple locals and global local modules to effectively extract useful information from each image in the dual-pixels and select the useful information from each image and synthesize the final output image. We demonstrate the effectiveness of the proposed deblurring algorithm in terms of both qualitative and quantitative aspects by evaluating on the test set in the NTIRE 2021 Defocus Deblurring using Dual-pixel Images Challenge. The code, and trained models are available at https://github.com/tuvovan/ATTSF.

</p>
</details>

<details><summary><b>Lower Bounds on Cross-Entropy Loss in the Presence of Test-time Adversaries</b>
<a href="https://arxiv.org/abs/2104.08382">arxiv:2104.08382</a>
&#x1F4C8; 10 <br>
<p>Arjun Nitin Bhagoji, Daniel Cullina, Vikash Sehwag, Prateek Mittal</p></summary>
<p>

**Abstract:** Understanding the fundamental limits of robust supervised learning has emerged as a problem of immense interest, from both practical and theoretical standpoints. In particular, it is critical to determine classifier-agnostic bounds on the training loss to establish when learning is possible. In this paper, we determine optimal lower bounds on the cross-entropy loss in the presence of test-time adversaries, along with the corresponding optimal classification outputs. Our formulation of the bound as a solution to an optimization problem is general enough to encompass any loss function depending on soft classifier outputs. We also propose and provide a proof of correctness for a bespoke algorithm to compute this lower bound efficiently, allowing us to determine lower bounds for multiple practical datasets of interest. We use our lower bounds as a diagnostic tool to determine the effectiveness of current robust training methods and find a gap from optimality at larger budgets. Finally, we investigate the possibility of using of optimal classification outputs as soft labels to empirically improve robust training.

</p>
</details>

<details><summary><b>I Find Your Lack of Uncertainty in Computer Vision Disturbing</b>
<a href="https://arxiv.org/abs/2104.08188">arxiv:2104.08188</a>
&#x1F4C8; 10 <br>
<p>Matias Valdenegro-Toro</p></summary>
<p>

**Abstract:** Neural networks are used for many real world applications, but often they have problems estimating their own confidence. This is particularly problematic for computer vision applications aimed at making high stakes decisions with humans and their lives. In this paper we make a meta-analysis of the literature, showing that most if not all computer vision applications do not use proper epistemic uncertainty quantification, which means that these models ignore their own limitations. We describe the consequences of using models without proper uncertainty quantification, and motivate the community to adopt versions of the models they use that have proper calibrated epistemic uncertainty, in order to enable out of distribution detection. We close the paper with a summary of challenges on estimating uncertainty for computer vision applications and recommendations.

</p>
</details>

<details><summary><b>AMMU : A Survey of Transformer-based Biomedical Pretrained Language Models</b>
<a href="https://arxiv.org/abs/2105.00827">arxiv:2105.00827</a>
&#x1F4C8; 9 <br>
<p>Katikapalli Subramanyam Kalyan, Ajit Rajasekharan, Sivanesan Sangeetha</p></summary>
<p>

**Abstract:** Transformer-based pretrained language models (PLMs) have started a new era in modern natural language processing (NLP). These models combine the power of transformers, transfer learning, and self-supervised learning (SSL). Following the success of these models in the general domain, the biomedical research community has developed various in-domain PLMs starting from BioBERT to the latest BioELECTRA and BioALBERT models. We strongly believe there is a need for a survey paper that can provide a comprehensive survey of various transformer-based biomedical pretrained language models (BPLMs). In this survey, we start with a brief overview of foundational concepts like self-supervised learning, embedding layer and transformer encoder layers. We discuss core concepts of transformer-based PLMs like pretraining methods, pretraining tasks, fine-tuning methods, and various embedding types specific to biomedical domain. We introduce a taxonomy for transformer-based BPLMs and then discuss all the models. We discuss various challenges and present possible solutions. We conclude by highlighting some of the open issues which will drive the research community to further improve transformer-based BPLMs.

</p>
</details>

<details><summary><b>Flexible Instance-Specific Rationalization of NLP Models</b>
<a href="https://arxiv.org/abs/2104.08219">arxiv:2104.08219</a>
&#x1F4C8; 9 <br>
<p>George Chrysostomou, Nikolaos Aletras</p></summary>
<p>

**Abstract:** Recent research on model interpretability in natural language processing extensively uses feature scoring methods for identifying which parts of the input are the most important for a model to make a prediction (i.e. explanation or rationale). However, previous research has shown that there is no clear best scoring method across various text classification tasks while practitioners typically have to make several other ad-hoc choices regarding the length and the type of the rationale (e.g. short or long, contiguous or not). Inspired by this, we propose a simple yet effective and flexible method that allows selecting optimally for each data instance: (1) a feature scoring method; (2) the length; and (3) the type of the rationale. Our method is inspired by input erasure approaches to interpretability which assume that the most faithful rationale for a prediction should be the one with the highest difference between the model's output distribution using the full text and the text after removing the rationale as input respectively. Evaluation on four standard text classification datasets shows that our proposed method provides more faithful, comprehensive and highly sufficient explanations compared to using a fixed feature scoring method, rationale length and type. More importantly, we demonstrate that a practitioner is not required to make any ad-hoc choices in order to extract faithful rationales using our approach.

</p>
</details>

<details><summary><b>Noise-Aware Video Saliency Prediction</b>
<a href="https://arxiv.org/abs/2104.08038">arxiv:2104.08038</a>
&#x1F4C8; 9 <br>
<p>Ekta Prashnani, Orazio Gallo, Joohwan Kim, Josef Spjut, Pradeep Sen, Iuri Frosio</p></summary>
<p>

**Abstract:** We tackle the problem of predicting saliency maps for videos of dynamic scenes. We note that the accuracy of the maps reconstructed from the gaze data of a fixed number of observers varies with the frame, as it depends on the content of the scene. This issue is particularly pressing when a limited number of observers are available. In such cases, directly minimizing the discrepancy between the predicted and measured saliency maps, as traditional deep-learning methods do, results in overfitting to the noisy data. We propose a noise-aware training (NAT) paradigm that quantifies and accounts for the uncertainty arising from frame-specific gaze data inaccuracy. We show that NAT is especially advantageous when limited training data is available, with experiments across different models, loss functions, and datasets. We also introduce a video game-based saliency dataset, with rich temporal semantics, and multiple gaze attractors per frame. The dataset and source code are available at https://github.com/NVlabs/NAT-saliency.

</p>
</details>

<details><summary><b>Back to the Basics: A Quantitative Analysis of Statistical and Graph-Based Term Weighting Schemes for Keyword Extraction</b>
<a href="https://arxiv.org/abs/2104.08028">arxiv:2104.08028</a>
&#x1F4C8; 9 <br>
<p>Asahi Ushio, Federico Liberatore, Jose Camacho-Collados</p></summary>
<p>

**Abstract:** Term weighting schemes are widely used in Natural Language Processing and Information Retrieval. In particular, term weighting is the basis for keyword extraction. However, there are relatively few evaluation studies that shed light about the strengths and shortcomings of each weighting scheme. In fact, in most cases researchers and practitioners resort to the well-known tf-idf as default, despite the existence of other suitable alternatives, including graph-based models. In this paper, we perform an exhaustive and large-scale empirical comparison of both statistical and graph-based term weighting methods in the context of keyword extraction. Our analysis reveals some interesting findings such as the advantages of the less-known lexical specificity with respect to tf-idf, or the qualitative differences between statistical and graph-based methods. Finally, based on our findings we discuss and devise some suggestions for practitioners. Source code to reproduce our experimental results, including a keyword extraction library, are available in the following repository: https://github.com/asahi417/kex

</p>
</details>

<details><summary><b>Better Latent Spaces for Better Autoencoders</b>
<a href="https://arxiv.org/abs/2104.08291">arxiv:2104.08291</a>
&#x1F4C8; 8 <br>
<p>Barry M. Dillon, Tilman Plehn, Christof Sauer, Peter Sorrenson</p></summary>
<p>

**Abstract:** Autoencoders as tools behind anomaly searches at the LHC have the structural problem that they only work in one direction, extracting jets with higher complexity but not the other way around. To address this, we derive classifiers from the latent space of (variational) autoencoders, specifically in Gaussian mixture and Dirichlet latent spaces. In particular, the Dirichlet setup solves the problem and improves both the performance and the interpretability of the networks.

</p>
</details>

<details><summary><b>Fast, Effective, and Self-Supervised: Transforming Masked Language Models into Universal Lexical and Sentence Encoders</b>
<a href="https://arxiv.org/abs/2104.08027">arxiv:2104.08027</a>
&#x1F4C8; 8 <br>
<p>Fangyu Liu, Ivan Vulić, Anna Korhonen, Nigel Collier</p></summary>
<p>

**Abstract:** Pretrained Masked Language Models (MLMs) have revolutionised NLP in recent years. However, previous work has indicated that off-the-shelf MLMs are not effective as universal lexical or sentence encoders without further task-specific fine-tuning on NLI, sentence similarity, or paraphrasing tasks using annotated task data. In this work, we demonstrate that it is possible to turn MLMs into effective universal lexical and sentence encoders even without any additional data and without any supervision. We propose an extremely simple, fast and effective contrastive learning technique, termed Mirror-BERT, which converts MLMs (e.g., BERT and RoBERTa) into such encoders in 20-30 seconds without any additional external knowledge. Mirror-BERT relies on fully identical or slightly modified string pairs as positive (i.e., synonymous) fine-tuning examples, and aims to maximise their similarity during identity fine-tuning. We report huge gains over off-the-shelf MLMs with Mirror-BERT in both lexical-level and sentence-level tasks, across different domains and different languages. Notably, in the standard sentence semantic similarity (STS) tasks, our self-supervised Mirror-BERT model even matches the performance of the task-tuned Sentence-BERT models from prior work. Finally, we delve deeper into the inner workings of MLMs, and suggest some evidence on why this simple approach can yield effective universal lexical and sentence encoders.

</p>
</details>

<details><summary><b>I Only Have Eyes for You: The Impact of Masks On Convolutional-Based Facial Expression Recognition</b>
<a href="https://arxiv.org/abs/2104.08353">arxiv:2104.08353</a>
&#x1F4C8; 7 <br>
<p>Pablo Barros, Alessandra Sciutti</p></summary>
<p>

**Abstract:** The current COVID-19 pandemic has shown us that we are still facing unpredictable challenges in our society. The necessary constrain on social interactions affected heavily how we envision and prepare the future of social robots and artificial agents in general. Adapting current affective perception models towards constrained perception based on the hard separation between facial perception and affective understanding would help us to provide robust systems. In this paper, we perform an in-depth analysis of how recognizing affect from persons with masks differs from general facial expression perception. We evaluate how the recently proposed FaceChannel adapts towards recognizing facial expressions from persons with masks. In Our analysis, we evaluate different training and fine-tuning schemes to understand better the impact of masked facial expressions. We also perform specific feature-level visualization to demonstrate how the inherent capabilities of the FaceChannel to learn and combine facial features change when in a constrained social interaction scenario.

</p>
</details>

<details><summary><b>Does language help generalization in vision models?</b>
<a href="https://arxiv.org/abs/2104.08313">arxiv:2104.08313</a>
&#x1F4C8; 7 <br>
<p>Benjamin Devillers, Bhavin Choksi, Romain Bielawski, Rufin VanRullen</p></summary>
<p>

**Abstract:** Vision models trained on multimodal datasets can benefit from the wide availability of large image-caption datasets. A recent model (CLIP) was found to generalize well in zero-shot and transfer learning settings. This could imply that linguistic or "semantic grounding" confers additional generalization abilities to the visual feature space. Here, we systematically evaluate various multimodal architectures and vision-only models in terms of unsupervised clustering, few-shot learning, transfer learning and adversarial robustness. In each setting, multimodal training produced no additional generalization capability compared to standard supervised visual training. We conclude that work is still required for semantic grounding to help improve vision models.

</p>
</details>

<details><summary><b>Language Models are Few-Shot Butlers</b>
<a href="https://arxiv.org/abs/2104.07972">arxiv:2104.07972</a>
&#x1F4C8; 7 <br>
<p>Vincent Micheli, François Fleuret</p></summary>
<p>

**Abstract:** Pretrained language models demonstrate strong performance in most NLP tasks when fine-tuned on small task-specific datasets. Hence, these autoregressive models constitute ideal agents to operate in text-based environments where language understanding and generative capabilities are essential. Nonetheless, collecting expert demonstrations in such environments is a time-consuming endeavour. We introduce a two-stage procedure to learn from a small set of demonstrations and further improve by interacting with an environment. We show that language models fine-tuned with only 1.2% of the expert demonstrations and a simple reinforcement learning algorithm achieve a 51% absolute improvement in success rate over existing methods in the ALFWorld environment.

</p>
</details>

<details><summary><b>Accelerating Sparse Deep Neural Networks</b>
<a href="https://arxiv.org/abs/2104.08378">arxiv:2104.08378</a>
&#x1F4C8; 6 <br>
<p>Asit Mishra, Jorge Albericio Latorre, Jeff Pool, Darko Stosic, Dusan Stosic, Ganesh Venkatesh, Chong Yu, Paulius Micikevicius</p></summary>
<p>

**Abstract:** As neural network model sizes have dramatically increased, so has the interest in various techniques to reduce their parameter counts and accelerate their execution. An active area of research in this field is sparsity - encouraging zero values in parameters that can then be discarded from storage or computations. While most research focuses on high levels of sparsity, there are challenges in universally maintaining model accuracy as well as achieving significant speedups over modern matrix-math hardware. To make sparsity adoption practical, the NVIDIA Ampere GPU architecture introduces sparsity support in its matrix-math units, Tensor Cores. We present the design and behavior of Sparse Tensor Cores, which exploit a 2:4 (50%) sparsity pattern that leads to twice the math throughput of dense matrix units. We also describe a simple workflow for training networks that both satisfy 2:4 sparsity pattern requirements and maintain accuracy, verifying it on a wide range of common tasks and model architectures. This workflow makes it easy to prepare accurate models for efficient deployment on Sparse Tensor Cores.

</p>
</details>

<details><summary><b>Text2App: A Framework for Creating Android Apps from Text Descriptions</b>
<a href="https://arxiv.org/abs/2104.08301">arxiv:2104.08301</a>
&#x1F4C8; 6 <br>
<p>Masum Hasan, Kazi Sajeed Mehrab, Wasi Uddin Ahmad, Rifat Shahriyar</p></summary>
<p>

**Abstract:** We present Text2App -- a framework that allows users to create functional Android applications from natural language specifications. The conventional method of source code generation tries to generate source code directly, which is impractical for creating complex software. We overcome this limitation by transforming natural language into an abstract intermediate formal language representing an application with a substantially smaller number of tokens. The intermediate formal representation is then compiled into target source codes. This abstraction of programming details allows seq2seq networks to learn complex application structures with less overhead. In order to train sequence models, we introduce a data synthesis method grounded in a human survey. We demonstrate that Text2App generalizes well to unseen combination of app components and it is capable of handling noisy natural language instructions. We explore the possibility of creating applications from highly abstract instructions by coupling our system with GPT-3 -- a large pretrained language model. We perform an extensive human evaluation and identify the capabilities and limitations of our system. The source code, a ready-to-run demo notebook, and a demo video are publicly available at \url{https://github.com/text2app/Text2App}.

</p>
</details>

<details><summary><b>TalkNet 2: Non-Autoregressive Depth-Wise Separable Convolutional Model for Speech Synthesis with Explicit Pitch and Duration Prediction</b>
<a href="https://arxiv.org/abs/2104.08189">arxiv:2104.08189</a>
&#x1F4C8; 6 <br>
<p>Stanislav Beliaev, Boris Ginsburg</p></summary>
<p>

**Abstract:** We propose TalkNet, a non-autoregressive convolutional neural model for speech synthesis with explicit pitch and duration prediction. The model consists of three feed-forward convolutional networks. The first network predicts grapheme durations. An input text is expanded by repeating each symbol according to the predicted duration. The second network predicts pitch value for every mel frame. The third network generates a mel-spectrogram from the expanded text conditioned on predicted pitch. All networks are based on 1D depth-wise separable convolutional architecture. The explicit duration prediction eliminates word skipping and repeating. The quality of the generated speech nearly matches the best auto-regressive models - TalkNet trained on the LJSpeech dataset got MOS 4.08. The model has only 13.2M parameters, almost 2x less than the present state-of-the-art text-to-speech models. The non-autoregressive architecture allows for fast training and inference. The small model size and fast inference make the TalkNet an attractive candidate for embedded speech synthesis.

</p>
</details>

<details><summary><b>MetaXL: Meta Representation Transformation for Low-resource Cross-lingual Learning</b>
<a href="https://arxiv.org/abs/2104.07908">arxiv:2104.07908</a>
&#x1F4C8; 6 <br>
<p>Mengzhou Xia, Guoqing Zheng, Subhabrata Mukherjee, Milad Shokouhi, Graham Neubig, Ahmed Hassan Awadallah</p></summary>
<p>

**Abstract:** The combination of multilingual pre-trained representations and cross-lingual transfer learning is one of the most effective methods for building functional NLP systems for low-resource languages. However, for extremely low-resource languages without large-scale monolingual corpora for pre-training or sufficient annotated data for fine-tuning, transfer learning remains an under-studied and challenging task. Moreover, recent work shows that multilingual representations are surprisingly disjoint across languages, bringing additional challenges for transfer onto extremely low-resource languages. In this paper, we propose MetaXL, a meta-learning based framework that learns to transform representations judiciously from auxiliary languages to a target one and brings their representation spaces closer for effective transfer. Extensive experiments on real-world low-resource languages - without access to large-scale monolingual corpora or large amounts of labeled data - for tasks like cross-lingual sentiment analysis and named entity recognition show the effectiveness of our approach. Code for MetaXL is publicly available at github.com/microsoft/MetaXL.

</p>
</details>

<details><summary><b>BERT memorisation and pitfalls in low-resource scenarios</b>
<a href="https://arxiv.org/abs/2105.00828">arxiv:2105.00828</a>
&#x1F4C8; 5 <br>
<p>Michael Tänzer, Sebastian Ruder, Marek Rei</p></summary>
<p>

**Abstract:** State-of-the-art pre-trained models have been shown to memorise facts and perform well with limited amounts of training data. To gain a better understanding of how these models learn, we study their generalisation and memorisation capabilities in noisy and low-resource scenarios. We find that the training of these models is almost unaffected by label noise and that it is possible to reach near-optimal performances even on extremely noisy datasets. Conversely, we also find that they completely fail when tested on low-resource tasks such as few-shot learning and rare entity recognition. To mitigate such limitations, we propose a novel architecture based on BERT and prototypical networks that improves performance in low-resource named entity recognition tasks.

</p>
</details>

<details><summary><b>Shadow-Mapping for Unsupervised Neural Causal Discovery</b>
<a href="https://arxiv.org/abs/2104.08183">arxiv:2104.08183</a>
&#x1F4C8; 5 <br>
<p>Matthew J. Vowels, Necati Cihan Camgoz, Richard Bowden</p></summary>
<p>

**Abstract:** An important goal across most scientific fields is the discovery of causal structures underling a set of observations. Unfortunately, causal discovery methods which are based on correlation or mutual information can often fail to identify causal links in systems which exhibit dynamic relationships. Such dynamic systems (including the famous coupled logistic map) exhibit `mirage' correlations which appear and disappear depending on the observation window. This means not only that correlation is not causation but, perhaps counter-intuitively, that causation may occur without correlation. In this paper we describe Neural Shadow-Mapping, a neural network based method which embeds high-dimensional video data into a low-dimensional shadow representation, for subsequent estimation of causal links. We demonstrate its performance at discovering causal links from video-representations of dynamic systems.

</p>
</details>

<details><summary><b>To Share or not to Share: Predicting Sets of Sources for Model Transfer Learning</b>
<a href="https://arxiv.org/abs/2104.08078">arxiv:2104.08078</a>
&#x1F4C8; 5 <br>
<p>Lukas Lange, Jannik Strötgen, Heike Adel, Dietrich Klakow</p></summary>
<p>

**Abstract:** In low-resource settings, model transfer can help to overcome a lack of labeled data for many tasks and domains. However, predicting useful transfer sources is a challenging problem, as even the most similar sources might lead to unexpected negative transfer results. Thus, ranking methods based on task and text similarity -- as suggested in prior work -- may not be sufficient to identify promising sources. To tackle this problem, we propose a new approach to automatically determine which and how many sources should be exploited. For this, we study the effects of model transfer on sequence labeling across various domains and tasks and show that our methods based on model similarity and support vector machines are able to predict promising sources, resulting in performance increases of up to 24 F1 points.

</p>
</details>

<details><summary><b>A Novel Surrogate-assisted Evolutionary Algorithm Applied to Partition-based Ensemble Learning</b>
<a href="https://arxiv.org/abs/2104.08048">arxiv:2104.08048</a>
&#x1F4C8; 5 <br>
<p>Arkadiy Dushatskiy, Tanja Alderliesten, Peter A. N. Bosman</p></summary>
<p>

**Abstract:** We propose a novel surrogate-assisted Evolutionary Algorithm for solving expensive combinatorial optimization problems. We integrate a surrogate model, which is used for fitness value estimation, into a state-of-the-art P3-like variant of the Gene-Pool Optimal Mixing Algorithm (GOMEA) and adapt the resulting algorithm for solving non-binary combinatorial problems. We test the proposed algorithm on an ensemble learning problem. Ensembling several models is a common Machine Learning technique to achieve better performance. We consider ensembles of several models trained on disjoint subsets of a dataset. Finding the best dataset partitioning is naturally a combinatorial non-binary optimization problem. Fitness function evaluations can be extremely expensive if complex models, such as Deep Neural Networks, are used as learners in an ensemble. Therefore, the number of fitness function evaluations is typically limited, necessitating expensive optimization techniques. In our experiments we use five classification datasets from the OpenML-CC18 benchmark and Support-vector Machines as learners in an ensemble. The proposed algorithm demonstrates better performance than alternative approaches, including Bayesian optimization algorithms. It manages to find better solutions using just several thousand fitness function evaluations for an ensemble learning problem with up to 500 variables.

</p>
</details>

<details><summary><b>Joint Passage Ranking for Diverse Multi-Answer Retrieval</b>
<a href="https://arxiv.org/abs/2104.08445">arxiv:2104.08445</a>
&#x1F4C8; 4 <br>
<p>Sewon Min, Kenton Lee, Ming-Wei Chang, Kristina Toutanova, Hannaneh Hajishirzi</p></summary>
<p>

**Abstract:** We study multi-answer retrieval, an under-explored problem that requires retrieving passages to cover multiple distinct answers for a given question. This task requires joint modeling of retrieved passages, as models should not repeatedly retrieve passages containing the same answer at the cost of missing a different valid answer. In this paper, we introduce JPR, the first joint passage retrieval model for multi-answer retrieval. JPR makes use of an autoregressive reranker that selects a sequence of passages, each conditioned on previously selected passages. JPR is trained to select passages that cover new answers at each timestep and uses a tree-decoding algorithm to enable flexibility in the degree of diversity. Compared to prior approaches, JPR achieves significantly better answer coverage on three multi-answer datasets. When combined with downstream question answering, the improved retrieval enables larger answer generation models since they need to consider fewer passages, establishing a new state-of-the-art.

</p>
</details>

<details><summary><b>"BNN - BN = ?": Training Binary Neural Networks without Batch Normalization</b>
<a href="https://arxiv.org/abs/2104.08215">arxiv:2104.08215</a>
&#x1F4C8; 4 <br>
<p>Tianlong Chen, Zhenyu Zhang, Xu Ouyang, Zechun Liu, Zhiqiang Shen, Zhangyang Wang</p></summary>
<p>

**Abstract:** Batch normalization (BN) is a key facilitator and considered essential for state-of-the-art binary neural networks (BNN). However, the BN layer is costly to calculate and is typically implemented with non-binary parameters, leaving a hurdle for the efficient implementation of BNN training. It also introduces undesirable dependence between samples within each batch. Inspired by the latest advance on Batch Normalization Free (BN-Free) training, we extend their framework to training BNNs, and for the first time demonstrate that BNs can be completed removed from BNN training and inference regimes. By plugging in and customizing techniques including adaptive gradient clipping, scale weight standardization, and specialized bottleneck block, a BN-free BNN is capable of maintaining competitive accuracy compared to its BN-based counterpart. Extensive experiments validate the effectiveness of our proposal across diverse BNN backbones and datasets. For example, after removing BNs from the state-of-the-art ReActNets, it can still be trained with our proposed methodology to achieve 92.08%, 68.34%, and 68.0% accuracy on CIFAR-10, CIFAR-100, and ImageNet respectively, with marginal performance drop (0.23%~0.44% on CIFAR and 1.40% on ImageNet). Codes and pre-trained models are available at: https://github.com/VITA-Group/BNN_NoBN.

</p>
</details>

<details><summary><b>Finding Motifs in Knowledge Graphs using Compression</b>
<a href="https://arxiv.org/abs/2104.08163">arxiv:2104.08163</a>
&#x1F4C8; 4 <br>
<p>Peter Bloem</p></summary>
<p>

**Abstract:** We introduce a method to find network motifs in knowledge graphs. Network motifs are useful patterns or meaningful subunits of the graph that recur frequently. We extend the common definition of a network motif to coincide with a basic graph pattern. We introduce an approach, inspired by recent work for simple graphs, to induce these from a given knowledge graph, and show that the motifs found reflect the basic structure of the graph. Specifically, we show that in random graphs, no motifs are found, and that when we insert a motif artificially, it can be detected. Finally, we show the results of motif induction on three real-world knowledge graphs.

</p>
</details>

<details><summary><b>Fast ABC with joint generative modelling and subset simulation</b>
<a href="https://arxiv.org/abs/2104.08156">arxiv:2104.08156</a>
&#x1F4C8; 4 <br>
<p>Eliane Maalouf, David Ginsbourger, Niklas Linde</p></summary>
<p>

**Abstract:** We propose a novel approach for solving inverse-problems with high-dimensional inputs and an expensive forward mapping. It leverages joint deep generative modelling to transfer the original problem spaces to a lower dimensional latent space. By jointly modelling input and output variables and endowing the latent with a prior distribution, the fitted probabilistic model indirectly gives access to the approximate conditional distributions of interest. Since model error and observational noise with unknown distributions are common in practice, we resort to likelihood-free inference with Approximate Bayesian Computation (ABC). Our method calls on ABC by Subset Simulation to explore the regions of the latent space with dissimilarities between generated and observed outputs below prescribed thresholds. We diagnose the diversity of approximate posterior solutions by monitoring the probability content of these regions as a function of the threshold. We further analyze the curvature of the resulting diagnostic curve to propose an adequate ABC threshold. When applied to a cross-borehole tomography example from geophysics, our approach delivers promising performance without using prior knowledge of the forward nor of the noise distribution.

</p>
</details>

<details><summary><b>Probabilistic water demand forecasting using quantile regression algorithms</b>
<a href="https://arxiv.org/abs/2104.07985">arxiv:2104.07985</a>
&#x1F4C8; 4 <br>
<p>Georgia Papacharalampous, Andreas Langousis</p></summary>
<p>

**Abstract:** Machine and statistical learning algorithms can be reliably automated and applied at scale. Therefore, they can constitute a considerable asset for designing practical forecasting systems, such as those related to urban water demand. Quantile regression algorithms are statistical and machine learning algorithms that can provide probabilistic forecasts in a straightforward way, and have not been applied so far for urban water demand forecasting. In this work, we aim to fill this gap by automating and extensively comparing several quantile-regression-based practical systems for probabilistic one-day ahead urban water demand forecasting. For designing the practical systems, we use five individual algorithms (i.e., the quantile regression, linear boosting, generalized random forest, gradient boosting machine and quantile regression neural network algorithms), their mean combiner and their median combiner. The comparison is conducted by exploiting a large urban water flow dataset, as well as several types of hydrometeorological time series (which are considered as exogenous predictor variables in the forecasting setting). The results mostly favour the practical systems designed using the linear boosting algorithm, probably due to the presence of trends in the urban water flow time series. The forecasts of the mean and median combiners are also found to be skilful in general terms.

</p>
</details>

<details><summary><b>VGNMN: Video-grounded Neural Module Network to Video-Grounded Language Tasks</b>
<a href="https://arxiv.org/abs/2104.07921">arxiv:2104.07921</a>
&#x1F4C8; 4 <br>
<p>Hung Le, Nancy F. Chen, Steven C. H. Hoi</p></summary>
<p>

**Abstract:** Neural module networks (NMN) have achieved success in image-grounded tasks such as Visual Question Answering (VQA) on synthetic images. However, very limited work on NMN has been studied in the video-grounded language tasks. These tasks extend the complexity of traditional visual tasks with the additional visual temporal variance. Motivated by recent NMN approaches on image-grounded tasks, we introduce Video-grounded Neural Module Network (VGNMN) to model the information retrieval process in video-grounded language tasks as a pipeline of neural modules. VGNMN first decomposes all language components to explicitly resolve any entity references and detect corresponding action-based inputs from the question. The detected entities and actions are used as parameters to instantiate neural module networks and extract visual cues from the video. Our experiments show that VGNMN can achieve promising performance on two video-grounded language tasks: video QA and video-grounded dialogues.

</p>
</details>

<details><summary><b>Deep Chaos Synchronization</b>
<a href="https://arxiv.org/abs/2104.08436">arxiv:2104.08436</a>
&#x1F4C8; 3 <br>
<p>Majid Mobini, Georges Kaddoum</p></summary>
<p>

**Abstract:** In this study, we address the problem of chaotic synchronization over a noisy channel by introducing a novel Deep Chaos Synchronization (DCS) system using a Convolutional Neural Network (CNN). Conventional Deep Learning (DL) based communication strategies are extremely powerful but training on large data sets is usually a difficult and time-consuming procedure. To tackle this challenge, DCS does not require prior information or large data sets. In addition, we provide a novel Recurrent Neural Network (RNN)-based chaotic synchronization system for comparative analysis. The results show that the proposed DCS architecture is competitive with RNN-based synchronization in terms of robustness against noise, convergence, and training. Hence, with these features, the DCS scheme will open the door for a new class of modulator schemes and meet the robustness against noise, convergence, and training requirements of the Ultra Reliable Low Latency Communications (URLLC) and Industrial Internet of Things (IIoT).

</p>
</details>

<details><summary><b>Sync-Switch: Hybrid Parameter Synchronization for Distributed Deep Learning</b>
<a href="https://arxiv.org/abs/2104.08364">arxiv:2104.08364</a>
&#x1F4C8; 3 <br>
<p>Shijian Li, Oren Mangoubi, Lijie Xu, Tian Guo</p></summary>
<p>

**Abstract:** Stochastic Gradient Descent (SGD) has become the de facto way to train deep neural networks in distributed clusters. A critical factor in determining the training throughput and model accuracy is the choice of the parameter synchronization protocol. For example, while Bulk Synchronous Parallel (BSP) often achieves better converged accuracy, the corresponding training throughput can be negatively impacted by stragglers. In contrast, Asynchronous Parallel (ASP) can have higher throughput, but its convergence and accuracy can be impacted by stale gradients. To improve the performance of synchronization protocol, recent work often focuses on designing new protocols with a heavy reliance on hard-to-tune hyper-parameters. In this paper, we design a hybrid synchronization approach that exploits the benefits of both BSP and ASP, i.e., reducing training time while simultaneously maintaining the converged accuracy. Based on extensive empirical profiling, we devise a collection of adaptive policies that determine how and when to switch between synchronization protocols. Our policies include both offline ones that target recurring jobs and online ones for handling transient stragglers. We implement the proposed policies in a prototype system, called Sync-Switch, on top of TensorFlow, and evaluate the training performance with popular deep learning models and datasets. Our experiments show that Sync-Switch achieves up to 5.13X throughput speedup and similar converged accuracy when comparing to BSP. Further, we observe that Sync-Switch achieves 3.8% higher converged accuracy with just 1.23X the training time compared to training with ASP. Moreover, Sync-Switch can be used in settings when training with ASP leads to divergence errors. Sync-Switch achieves all of these benefits with very low overhead, e.g., the framework overhead can be as low as 1.7% of the total training time.

</p>
</details>

<details><summary><b>Learning Evolved Combinatorial Symbols with a Neuro-symbolic Generative Model</b>
<a href="https://arxiv.org/abs/2104.08274">arxiv:2104.08274</a>
&#x1F4C8; 3 <br>
<p>Matthias Hofer, Tuan Anh Le, Roger Levy, Josh Tenenbaum</p></summary>
<p>

**Abstract:** Humans have the ability to rapidly understand rich combinatorial concepts from limited data. Here we investigate this ability in the context of auditory signals, which have been evolved in a cultural transmission experiment to study the emergence of combinatorial structure in language. We propose a neuro-symbolic generative model which combines the strengths of previous approaches to concept learning. Our model performs fast inference drawing on neural network methods, while still retaining the interpretability and generalization from limited data seen in structured generative approaches. This model outperforms a purely neural network-based approach on classification as evaluated against both ground truth and human experimental classification preferences, and produces superior reproductions of observed signals as well. Our results demonstrate the power of flexible combined neural-symbolic architectures for human-like generalization in raw perceptual domains and offers a step towards developing precise computational models of inductive biases in language evolution.

</p>
</details>

<details><summary><b>Data Augmentation for Voice-Assistant NLU using BERT-based Interchangeable Rephrase</b>
<a href="https://arxiv.org/abs/2104.08268">arxiv:2104.08268</a>
&#x1F4C8; 3 <br>
<p>Akhila Yerukola, Mason Bretan, Hongxia Jin</p></summary>
<p>

**Abstract:** We introduce a data augmentation technique based on byte pair encoding and a BERT-like self-attention model to boost performance on spoken language understanding tasks. We compare and evaluate this method with a range of augmentation techniques encompassing generative models such as VAEs and performance-boosting techniques such as synonym replacement and back-translation. We show our method performs strongly on domain and intent classification tasks for a voice assistant and in a user-study focused on utterance naturalness and semantic similarity.

</p>
</details>

<details><summary><b>Open data for Moroccan license plates for OCR applications : data collection, labeling, and model construction</b>
<a href="https://arxiv.org/abs/2104.08244">arxiv:2104.08244</a>
&#x1F4C8; 3 <br>
<p>Abdelkrim Alahyane, Mohamed El Fakir, Saad Benjelloun, Ikram Chairi</p></summary>
<p>

**Abstract:** Significant number of researches have been developed recently around intelligent system for traffic management, especially, OCR based license plate recognition, as it is considered as a main step for any automatic traffic management system. Good quality data sets are increasingly needed and produced by the research community to improve the performance of those algorithms. Furthermore, a special need of data is noted for countries having special characters on their licence plates, like Morocco, where Arabic Alphabet is used. In this work, we present a labeled open data set of circulation plates taken in Morocco, for different type of vehicles, namely cars, trucks and motorcycles. This data was collected manually and consists of 705 unique and different images. Furthermore this data was labeled for plate segmentation and for matriculation number OCR. Also, As we show in this paper, the data can be enriched using data augmentation techniques to create training sets with few thousands of images for different machine leaning and AI applications. We present and compare a set of models built on this data. Also, we publish this data as an open access data to encourage innovation and applications in the field of OCR and image processing for traffic control and other applications for transportation and heterogeneous vehicle management.

</p>
</details>

<details><summary><b>Counter-Interference Adapter for Multilingual Machine Translation</b>
<a href="https://arxiv.org/abs/2104.08154">arxiv:2104.08154</a>
&#x1F4C8; 3 <br>
<p>Yaoming Zhu, Jiangtao Feng, Chengqi Zhao, Mingxuan Wang, Lei Li</p></summary>
<p>

**Abstract:** Developing a unified multilingual model has long been a pursuit for machine translation. However, existing approaches suffer from performance degradation -- a single multilingual model is inferior to separately trained bilingual ones on rich-resource languages. We conjecture that such a phenomenon is due to interference caused by joint training with multiple languages. To accommodate the issue, we propose CIAT, an adapted Transformer model with a small parameter overhead for multilingual machine translation. We evaluate CIAT on multiple benchmark datasets, including IWSLT, OPUS-100, and WMT. Experiments show that CIAT consistently outperforms strong multilingual baselines on 64 of total 66 language directions, 42 of which see above 0.5 BLEU improvement. Our code is available at \url{https://github.com/Yaoming95/CIAT}~.

</p>
</details>

<details><summary><b>Exploiting Global and Local Attentions for Heavy Rain Removal on Single Images</b>
<a href="https://arxiv.org/abs/2104.08126">arxiv:2104.08126</a>
&#x1F4C8; 3 <br>
<p>Dac Tung Vu, Juan Luis Gonzalez, Munchurl Kim</p></summary>
<p>

**Abstract:** Heavy rain removal from a single image is the task of simultaneously eliminating rain streaks and fog, which can dramatically degrade the quality of captured images. Most existing rain removal methods do not generalize well for the heavy rain case. In this work, we propose a novel network architecture consisting of three sub-networks to remove heavy rain from a single image without estimating rain streaks and fog separately. The first sub-net, a U-net-based architecture that incorporates our Spatial Channel Attention (SCA) blocks, extracts global features that provide sufficient contextual information needed to remove atmospheric distortions caused by rain and fog. The second sub-net learns the additive residues information, which is useful in removing rain streak artifacts via our proposed Residual Inception Modules (RIM). The third sub-net, the multiplicative sub-net, adopts our Channel-attentive Inception Modules (CIM) and learns the essential brighter local features which are not effectively extracted in the SCA and additive sub-nets by modulating the local pixel intensities in the derained images. Our three clean image results are then combined via an attentive blending block to generate the final clean image. Our method with SCA, RIM, and CIM significantly outperforms the previous state-of-the-art single-image deraining methods on the synthetic datasets, shows considerably cleaner and sharper derained estimates on the real image datasets. We present extensive experiments and ablation studies supporting each of our method's contributions on both synthetic and real image datasets.

</p>
</details>

<details><summary><b>A Million Tweets Are Worth a Few Points: Tuning Transformers for Customer Service Tasks</b>
<a href="https://arxiv.org/abs/2104.07944">arxiv:2104.07944</a>
&#x1F4C8; 3 <br>
<p>Amir Hadifar, Sofie Labat, Véronique Hoste, Chris Develder, Thomas Demeester</p></summary>
<p>

**Abstract:** In online domain-specific customer service applications, many companies struggle to deploy advanced NLP models successfully, due to the limited availability of and noise in their datasets. While prior research demonstrated the potential of migrating large open-domain pretrained models for domain-specific tasks, the appropriate (pre)training strategies have not yet been rigorously evaluated in such social media customer service settings, especially under multilingual conditions. We address this gap by collecting a multilingual social media corpus containing customer service conversations (865k tweets), comparing various pipelines of pretraining and finetuning approaches, applying them on 5 different end tasks. We show that pretraining a generic multilingual transformer model on our in-domain dataset, before finetuning on specific end tasks, consistently boosts performance, especially in non-English settings.

</p>
</details>

<details><summary><b>A digital score of tumour-associated stroma infiltrating lymphocytes predicts survival in head and neck squamous cell carcinoma</b>
<a href="https://arxiv.org/abs/2104.12862">arxiv:2104.12862</a>
&#x1F4C8; 2 <br>
<p>Muhammad Shaban, Shan E Ahmed Raza, Mariam Hassan, Arif Jamshed, Sajid Mushtaq, Asif Loya, Nikolaos Batis, Jill Brooks, Paul Nankivell, Neil Sharma, Max Robinson, Hisham Mehanna, Syed Ali Khurram, Nasir Rajpoot</p></summary>
<p>

**Abstract:** The infiltration of T-lymphocytes in the stroma and tumour is an indication of an effective immune response against the tumour, resulting in better survival. In this study, our aim is to explore the prognostic significance of tumour-associated stroma infiltrating lymphocytes (TASILs) in head and neck squamous cell carcinoma (HNSCC) through an AI based automated method. A deep learning based automated method was employed to segment tumour, stroma and lymphocytes in digitally scanned whole slide images of HNSCC tissue slides. The spatial patterns of lymphocytes and tumour-associated stroma were digitally quantified to compute the TASIL-score. Finally, prognostic significance of the TASIL-score for disease-specific and disease-free survival was investigated with the Cox proportional hazard analysis. Three different cohorts of Haematoxylin & Eosin (H&E) stained tissue slides of HNSCC cases (n=537 in total) were studied, including publicly available TCGA head and neck cancer cases. The TASIL-score carries prognostic significance (p=0.002) for disease-specific survival of HNSCC patients. The TASIL-score also shows a better separation between low- and high-risk patients as compared to the manual TIL scoring by pathologists for both disease-specific and disease-free survival. A positive correlation of TASIL-score with molecular estimates of CD8+ T cells was also found, which is in line with existing findings. To the best of our knowledge, this is the first study to automate the quantification of TASIL from routine H&E slides of head and neck cancer. Our TASIL-score based findings are aligned with the clinical knowledge with the added advantages of objectivity, reproducibility and strong prognostic value. A comprehensive evaluation on large multicentric cohorts is required before the proposed digital score can be adopted in clinical practice.

</p>
</details>

<details><summary><b>Structural Beauty: A Structure-based Approach to Quantifying the Beauty of an Image</b>
<a href="https://arxiv.org/abs/2104.11100">arxiv:2104.11100</a>
&#x1F4C8; 2 <br>
<p>Bin Jiang, Chris de Rijke</p></summary>
<p>

**Abstract:** To say that beauty is in the eye of the beholder means that beauty is largely subjective so varies from person to person. While the subjectivity view is commonly held, there is also an objectivity view that seeks to measure beauty or aesthetics in some quantitative manners. Christopher Alexander has long discovered that beauty or coherence highly correlates to the number of subsymmetries or substructures and demonstrated that there is a shared notion of beauty - structural beauty - among people and even different peoples, regardless of their faiths, cultures, and ethnicities. This notion of structural beauty arises directly out of living structure or wholeness, a physical and mathematical structure that underlies all space and matter. Based on the concept of living structure, this paper develops an approach for computing the structural beauty or life of an image (L) based on the number of automatically derived substructures (S) and their inherent hierarchy (H). To verify this approach, we conducted a series of case studies applied to eight pairs of images including Leonardo da Vinci's Mona Lisa and Jackson Pollock's Blue Poles. We discovered among others that Blue Poles is more structurally beautiful than the Mona Lisa, and traditional buildings are in general more structurally beautiful than their modernist counterparts. This finding implies that goodness of things or images is largely a matter of fact rather than an opinion or personal preference as conventionally conceived. The research on structural beauty has deep implications on many disciplines, where beauty or aesthetics is a major concern such as image understanding and computer vision, architecture and urban design, humanities and arts, neurophysiology, and psychology.
  Keywords: Life; wholeness; figural goodness; head/tail breaks; computer vision

</p>
</details>

<details><summary><b>EarthNet2021: A large-scale dataset and challenge for Earth surface forecasting as a guided video prediction task</b>
<a href="https://arxiv.org/abs/2104.10066">arxiv:2104.10066</a>
&#x1F4C8; 2 <br>
<p>Christian Requena-Mesa, Vitus Benson, Markus Reichstein, Jakob Runge, Joachim Denzler</p></summary>
<p>

**Abstract:** Satellite images are snapshots of the Earth surface. We propose to forecast them. We frame Earth surface forecasting as the task of predicting satellite imagery conditioned on future weather. EarthNet2021 is a large dataset suitable for training deep neural networks on the task. It contains Sentinel 2 satellite imagery at 20m resolution, matching topography and mesoscale (1.28km) meteorological variables packaged into 32000 samples. Additionally we frame EarthNet2021 as a challenge allowing for model intercomparison. Resulting forecasts will greatly improve (>x50) over the spatial resolution found in numerical models. This allows localized impacts from extreme weather to be predicted, thus supporting downstream applications such as crop yield prediction, forest health assessments or biodiversity monitoring. Find data, code, and how to participate at www.earthnet.tech

</p>
</details>

<details><summary><b>Action Advising with Advice Imitation in Deep Reinforcement Learning</b>
<a href="https://arxiv.org/abs/2104.08441">arxiv:2104.08441</a>
&#x1F4C8; 2 <br>
<p>Ercument Ilhan, Jeremy Gow, Diego Perez-Liebana</p></summary>
<p>

**Abstract:** Action advising is a peer-to-peer knowledge exchange technique built on the teacher-student paradigm to alleviate the sample inefficiency problem in deep reinforcement learning. Recently proposed student-initiated approaches have obtained promising results. However, due to being in the early stages of development, these also have some substantial shortcomings. One of the abilities that are absent in the current methods is further utilising advice by reusing, which is especially crucial in the practical settings considering the budget and cost constraints in peer-to-peer. In this study, we present an approach to enable the student agent to imitate previously acquired advice to reuse them directly in its exploration policy, without any interventions in the learning mechanism itself. In particular, we employ a behavioural cloning module to imitate the teacher policy and use dropout regularisation to have a notion of epistemic uncertainty to keep track of which state-advice pairs are actually collected. As the results of experiments we conducted in three Atari games show, advice reusing via generalisation is indeed a feasible option in deep RL and our approach can successfully achieve this while significantly improving the learning performance, even when paired with a simple early advising heuristic.

</p>
</details>

<details><summary><b>Learning on a Budget via Teacher Imitation</b>
<a href="https://arxiv.org/abs/2104.08440">arxiv:2104.08440</a>
&#x1F4C8; 2 <br>
<p>Ercument Ilhan, Jeremy Gow, Diego Perez-Liebana</p></summary>
<p>

**Abstract:** Deep Reinforcement Learning (RL) techniques can benefit greatly from leveraging prior experience, which can be either self-generated or acquired from other entities. Action advising is a framework that provides a flexible way to transfer such knowledge in the form of actions between teacher-student peers. However, due to the realistic concerns, the number of these interactions is limited with a budget; therefore, it is crucial to perform these in the most appropriate moments. There have been several promising studies recently that address this problem setting especially from the student's perspective. Despite their success, they have some shortcomings when it comes to the practical applicability and integrity as an overall solution to the learning from advice challenge. In this paper, we extend the idea of advice reusing via teacher imitation to construct a unified approach that addresses both advice collection and advice utilisation problems. We also propose a method to automatically tune the relevant hyperparameters of these components on-the-fly to make it able to adapt to any task with minimal human intervention. The experiments we performed in 5 different Atari games verify that our algorithm either surpasses or performs on-par with its top competitors while being far simpler to be employed. Furthermore, its individual components are also found to be providing significant advantages alone.

</p>
</details>

<details><summary><b>Robust Embeddings Via Distributions</b>
<a href="https://arxiv.org/abs/2104.08420">arxiv:2104.08420</a>
&#x1F4C8; 2 <br>
<p>Kira A. Selby, Yinong Wang, Ruizhe Wang, Peyman Passban, Ahmad Rashid, Mehdi Rezagholizadeh, Pascal Poupart</p></summary>
<p>

**Abstract:** Despite recent monumental advances in the field, many Natural Language Processing (NLP) models still struggle to perform adequately on noisy domains. We propose a novel probabilistic embedding-level method to improve the robustness of NLP models. Our method, Robust Embeddings via Distributions (RED), incorporates information from both noisy tokens and surrounding context to obtain distributions over embedding vectors that can express uncertainty in semantic space more fully than any deterministic method. We evaluate our method on a number of downstream tasks using existing state-of-the-art models in the presence of both natural and synthetic noise, and demonstrate a clear improvement over other embedding approaches to robustness from the literature.

</p>
</details>

<details><summary><b>LAMPRET: Layout-Aware Multimodal PreTraining for Document Understanding</b>
<a href="https://arxiv.org/abs/2104.08405">arxiv:2104.08405</a>
&#x1F4C8; 2 <br>
<p>Te-Lin Wu, Cheng Li, Mingyang Zhang, Tao Chen, Spurthi Amba Hombaiah, Michael Bendersky</p></summary>
<p>

**Abstract:** Document layout comprises both structural and visual (eg. font-sizes) information that is vital but often ignored by machine learning models. The few existing models which do use layout information only consider textual contents, and overlook the existence of contents in other modalities such as images. Additionally, spatial interactions of presented contents in a layout were never really fully exploited. To bridge this gap, we parse a document into content blocks (eg. text, table, image) and propose a novel layout-aware multimodal hierarchical framework, LAMPreT, to model the blocks and the whole document. Our LAMPreT encodes each block with a multimodal transformer in the lower-level and aggregates the block-level representations and connections utilizing a specifically designed transformer at the higher-level. We design hierarchical pretraining objectives where the lower-level model is trained similarly to multimodal grounding models, and the higher-level model is trained with our proposed novel layout-aware objectives. We evaluate the proposed model on two layout-aware tasks -- text block filling and image suggestion and show the effectiveness of our proposed hierarchical architecture as well as pretraining techniques.

</p>
</details>

<details><summary><b>Enriching a Model's Notion of Belief using a Persistent Memory</b>
<a href="https://arxiv.org/abs/2104.08401">arxiv:2104.08401</a>
&#x1F4C8; 2 <br>
<p>Nora Kassner, Oyvind Tafjord, Hinrich Schutze, Peter Clark</p></summary>
<p>

**Abstract:** Although pretrained language models (PTLMs) have been shown to contain significant amounts of world knowledge, they can still produce inconsistent answers to questions when probed, even after using specialized training techniques to reduce inconsistency. As a result, it can be hard to identify what the model actually "believes" about the world. Our goal is to reduce this problem, so systems are more globally consistent and accurate in their answers. Our approach is to add a memory component -- a BeliefBank -- that records a model's answers, and two mechanisms that use it to improve consistency among beliefs. First, a reasoning component -- a weighted SAT solver -- improves consistency by flipping answers that significantly clash with others. Second, a feedback component re-queries the model but using known beliefs as context. We show that, in a controlled experimental setting, these two mechanisms improve both accuracy and consistency. This is significant as it is a first step towards endowing models with an evolving memory, allowing them to construct a more coherent picture of the world.

</p>
</details>

<details><summary><b>Neural String Edit Distance</b>
<a href="https://arxiv.org/abs/2104.08388">arxiv:2104.08388</a>
&#x1F4C8; 2 <br>
<p>Jindřich Libovický, Alexander Fraser</p></summary>
<p>

**Abstract:** We propose the neural string edit distance model for string-pair classification and sequence generation based on learned string edit distance. We modify the original expectation-maximization learned edit distance algorithm into a differentiable loss function, allowing us to integrate it into a neural network providing a contextual representation of the input. We test the method on cognate detection, transliteration, and grapheme-to-phoneme conversion. We show that we can trade off between performance and interpretability in a single framework. Using contextual representations, which are difficult to interpret, we can match the performance of state-of-the-art string-pair classification models. Using static embeddings and a minor modification of the loss function, we can force interpretability, at the expense of an accuracy drop.

</p>
</details>

<details><summary><b>"Wikily" Supervised Neural Translation Tailored to Cross-Lingual Tasks</b>
<a href="https://arxiv.org/abs/2104.08384">arxiv:2104.08384</a>
&#x1F4C8; 2 <br>
<p>Mohammad Sadegh Rasooli, Chris Callison-Burch, Derry Tanti Wijaya</p></summary>
<p>

**Abstract:** We present a simple but effective approach for leveraging Wikipedia for neural machine translation as well as cross-lingual tasks of image captioning and dependency parsing without using any direct supervision from external parallel data or supervised models in the target language. We show that first sentences and titles of linked Wikipedia pages, as well as cross-lingual image captions, are strong signals for a seed parallel data to extract bilingual dictionaries and cross-lingual word embeddings for mining parallel text from Wikipedia. Our final model achieves high BLEU scores that are close to or sometimes higher than strong supervised baselines in low-resource languages; e.g. supervised BLEU of 4.0 versus 12.1 from our model in English-to-Kazakh. Moreover, we tailor our wikily supervised translation models to unsupervised image captioning, and cross-lingual dependency parser transfer. In image captioning, we train a multi-tasking machine translation and image captioning pipeline for Arabic and English from which the Arabic training data is a translated version of the English captioning data, using our wikily-supervised translation models. Our captioning results on Arabic are slightly better than that of its supervised model. In dependency parsing, we translate a large amount of monolingual text, and use it as artificial training data in an annotation projection framework. We show that our model outperforms recent work on cross-lingual transfer of dependency parsers.

</p>
</details>

<details><summary><b>Automated Seizure Detection and Seizure Type Classification From Electroencephalography With a Graph Neural Network and Self-Supervised Pre-Training</b>
<a href="https://arxiv.org/abs/2104.08336">arxiv:2104.08336</a>
&#x1F4C8; 2 <br>
<p>Siyi Tang, Jared A. Dunnmon, Khaled Saab, Xuan Zhang, Qianying Huang, Florian Dubost, Daniel L. Rubin, Christopher Lee-Messer</p></summary>
<p>

**Abstract:** Automated seizure detection and classification from electroencephalography (EEG) can greatly improve the diagnosis and treatment of seizures. While prior studies mainly used convolutional neural networks (CNNs) that assume image-like structure in EEG signals or spectrograms, this modeling choice does not reflect the natural geometry of or connectivity between EEG electrodes. In this study, we propose modeling EEGs as graphs and present a graph neural network for automated seizure detection and classification. In addition, we leverage unlabeled EEG data using a self-supervised pre-training strategy. Our graph model with self-supervised pre-training significantly outperforms previous state-of-the-art CNN and Long Short-Term Memory (LSTM) models by 6.3 points (7.8%) in Area Under the Receiver Operating Characteristic curve (AUROC) for seizure detection and 6.3 points (9.2%) in weighted F1-score for seizure type classification. Ablation studies show that our graph-based modeling approach significantly outperforms existing CNN or LSTM models, and that self-supervision helps further improve the model performance. Moreover, we find that self-supervised pre-training substantially improves model performance on combined tonic seizures, a low-prevalence seizure type. Furthermore, our model interpretability analysis suggests that our model is better at identifying seizure regions compared to an existing CNN. In summary, our graph-based modeling approach integrates domain knowledge about EEG, sets a new state-of-the-art for seizure detection and classification on a large public dataset (5,499 EEG files), and provides better ability to identify seizure regions.

</p>
</details>

<details><summary><b>Random and Adversarial Bit Error Robustness: Energy-Efficient and Secure DNN Accelerators</b>
<a href="https://arxiv.org/abs/2104.08323">arxiv:2104.08323</a>
&#x1F4C8; 2 <br>
<p>David Stutz, Nandhini Chandramoorthy, Matthias Hein, Bernt Schiele</p></summary>
<p>

**Abstract:** Deep neural network (DNN) accelerators received considerable attention in recent years due to the potential to save energy compared to mainstream hardware. Low-voltage operation of DNN accelerators allows to further reduce energy consumption significantly, however, causes bit-level failures in the memory storing the quantized DNN weights. Furthermore, DNN accelerators have been shown to be vulnerable to adversarial attacks on voltage controllers or individual bits. In this paper, we show that a combination of robust fixed-point quantization, weight clipping, as well as random bit error training (RandBET) or adversarial bit error training (AdvBET) improves robustness against random or adversarial bit errors in quantized DNN weights significantly. This leads not only to high energy savings for low-voltage operation as well as low-precision quantization, but also improves security of DNN accelerators. Our approach generalizes across operating voltages and accelerators, as demonstrated on bit errors from profiled SRAM arrays, and achieves robustness against both targeted and untargeted bit-level attacks. Without losing more than 0.8%/2% in test accuracy, we can reduce energy consumption on CIFAR10 by 20%/30% for 8/4-bit quantization using RandBET. Allowing up to 320 adversarial bit errors, AdvBET reduces test error from above 90% (chance level) to 26.22% on CIFAR10.

</p>
</details>

<details><summary><b>Adaptive Robust Model Predictive Control with Matched and Unmatched Uncertainty</b>
<a href="https://arxiv.org/abs/2104.08261">arxiv:2104.08261</a>
&#x1F4C8; 2 <br>
<p>Rohan Sinha, James Harrison, Spencer M. Richards, Marco Pavone</p></summary>
<p>

**Abstract:** We propose a learning-based robust predictive control algorithm that compensates for significant uncertainty in the dynamics for a class of discrete-time systems that are nominally linear with an additive nonlinear component. Such systems commonly model the nonlinear effects of an unknown environment on a nominal system. We optimize over a class of nonlinear feedback policies inspired by certainty equivalent "estimate-and-cancel" control laws pioneered in classical adaptive control to achieve significant performance improvements in the presence of uncertainties of large magnitude, a setting in which existing learning-based predictive control algorithms often struggle to guarantee safety. In contrast to previous work in robust adaptive MPC, our approach allows us to take advantage of structure (i.e., the numerical predictions) in the a priori unknown dynamics learned online through function approximation. Our approach also extends typical nonlinear adaptive control methods to systems with state and input constraints even when we cannot directly cancel the additive uncertain function from the dynamics. Moreover, we apply contemporary statistical estimation techniques to certify the system's safety through persistent constraint satisfaction with high probability. Finally, we show in simulation that our method can accommodate more significant unknown dynamics terms than existing methods.

</p>
</details>

<details><summary><b>Predicting the Binding of SARS-CoV-2 Peptides to the Major Histocompatibility Complex with Recurrent Neural Networks</b>
<a href="https://arxiv.org/abs/2104.08237">arxiv:2104.08237</a>
&#x1F4C8; 2 <br>
<p>Johanna Vielhaben, Markus Wenzel, Eva Weicken, Nils Strodthoff</p></summary>
<p>

**Abstract:** Predicting the binding of viral peptides to the major histocompatibility complex with machine learning can potentially extend the computational immunology toolkit for vaccine development, and serve as a key component in the fight against a pandemic. In this work, we adapt and extend USMPep, a recently proposed, conceptually simple prediction algorithm based on recurrent neural networks. Most notably, we combine regressors (binding affinity data) and classifiers (mass spectrometry data) from qualitatively different data sources to obtain a more comprehensive prediction tool. We evaluate the performance on a recently released SARS-CoV-2 dataset with binding stability measurements. USMPep not only sets new benchmarks on selected single alleles, but consistently turns out to be among the best-performing methods or, for some metrics, to be even the overall best-performing method for this task.

</p>
</details>

<details><summary><b>Why Machine Learning Integrated Patient Flow Simulation?</b>
<a href="https://arxiv.org/abs/2104.08203">arxiv:2104.08203</a>
&#x1F4C8; 2 <br>
<p>Tesfamariam M. Abuhay, Adane Mamuye, Stewart Robinson, Sergey V. Kovalchuk</p></summary>
<p>

**Abstract:** Patient flow analysis can be studied from a clinical and or operational perspective using simulation. Traditional statistical methods such as stochastic distribution methods have been used to construct patient flow simulation submodels such as patient inflow, Length of Stay (LoS), Cost of Treatment (CoT) and Clinical Pathway (CP) models. However, patient inflow demonstrates seasonality, trend and variation over time. LoS, CoT and CP are significantly determined by attributes of patients and clinical and laboratory test results. For this reason, patient flow simulation models constructed using traditional statistical methods are criticized for ignoring heterogeneity and their contribution to personalized and value based healthcare. On the other hand, machine learning methods have proven to be efficient to study and predict admission rate, LoS, CoT, and CP. This paper, hence, describes why coupling machine learning with patient flow simulation is important and proposes a conceptual architecture that shows how to integrate machine learning with patient flow simulation.

</p>
</details>

<details><summary><b>Spatiotemporal Deformable Models for Long-Term Complex Activity Detection</b>
<a href="https://arxiv.org/abs/2104.08194">arxiv:2104.08194</a>
&#x1F4C8; 2 <br>
<p>Salman Khan, Fabio Cuzzolin</p></summary>
<p>

**Abstract:** Long-term complex activity recognition and localisation can be crucial for the decision-making process of several autonomous systems, such as smart cars and surgical robots. Nonetheless, most current methods are designed to merely localise short-term action/activities or combinations of atomic actions that only last for a few frames or seconds. In this paper, we address the problem of long-term complex activity detection via a novel deformable, spatiotemporal parts-based model. Our framework consists of three main building blocks: (i) action tube detection, (ii) the modelling of the deformable geometry of parts, and (iii) a sparsity mechanism. Firstly, action tubes are detected in a series of snippets using an action tube detector. Next, a new 3D deformable RoI pooling layer is designed for learning the flexible, deformable geometry of the constellation of parts. Finally, a sparsity strategy differentiates between activated and deactivate features. We also provide temporal complex activity annotation for the recently released ROAD autonomous driving dataset and the SARAS-ESAD surgical action dataset, to validate our method and show the adaptability of our framework to different domains. As they both contain long videos portraying long-term activities they can be used as benchmarks for future work in this area.

</p>
</details>

<details><summary><b>Bayesian matrix completion with a spectral scaled Student prior: theoretical guarantee and efficient sampling</b>
<a href="https://arxiv.org/abs/2104.08191">arxiv:2104.08191</a>
&#x1F4C8; 2 <br>
<p>The Tien Mai</p></summary>
<p>

**Abstract:** We study the problem of matrix completion in this paper. A spectral scaled Student prior is exploited to favour the underlying low-rank structure of the data matrix. Importantly, we provide a thorough theoretical investigation for our approach, while such an analysis is hard to obtain and limited in theoretical understanding of Bayesian matrix completion. More precisely, we show that our Bayesian approach enjoys a minimax-optimal oracle inequality which guarantees that our method works well under model misspecification and under general sampling distribution. Interestingly, we also provide efficient gradient-based sampling implementations for our approach by using Langevin Monte Carlo which is novel in Bayesian matrix completion. More specifically, we show that our algorithms are significantly faster than Gibbs sampler in this problem. To illustrate the attractive features of our inference strategy, some numerical simulations are conducted and an application to image inpainting is demonstrated.

</p>
</details>

<details><summary><b>Uncertainty Surrogates for Deep Learning</b>
<a href="https://arxiv.org/abs/2104.08147">arxiv:2104.08147</a>
&#x1F4C8; 2 <br>
<p>Radhakrishna Achanta, Natasa Tagasovska</p></summary>
<p>

**Abstract:** In this paper we introduce a novel way of estimating prediction uncertainty in deep networks through the use of uncertainty surrogates. These surrogates are features of the penultimate layer of a deep network that are forced to match predefined patterns. The patterns themselves can be, among other possibilities, a known visual symbol. We show how our approach can be used for estimating uncertainty in prediction and out-of-distribution detection. Additionally, the surrogates allow for interpretability of the ability of the deep network to learn and at the same time lend robustness against adversarial attacks. Despite its simplicity, our approach is superior to the state-of-the-art approaches on standard metrics as well as computational efficiency and ease of implementation. A wide range of experiments are performed on standard datasets to prove the efficacy of our approach.

</p>
</details>

<details><summary><b>Sharp bounds for the number of regions of maxout networks and vertices of Minkowski sums</b>
<a href="https://arxiv.org/abs/2104.08135">arxiv:2104.08135</a>
&#x1F4C8; 2 <br>
<p>Guido Montúfar, Yue Ren, Leon Zhang</p></summary>
<p>

**Abstract:** We present results on the number of linear regions of the functions that can be represented by artificial feedforward neural networks with maxout units. A rank-k maxout unit is a function computing the maximum of $k$ linear functions. For networks with a single layer of maxout units, the linear regions correspond to the upper vertices of a Minkowski sum of polytopes. We obtain face counting formulas in terms of the intersection posets of tropical hypersurfaces or the number of upper faces of partial Minkowski sums, along with explicit sharp upper bounds for the number of regions for any input dimension, any number of units, and any ranks, in the cases with and without biases. Based on these results we also obtain asymptotically sharp upper bounds for networks with multiple layers.

</p>
</details>

<details><summary><b>Integrating Domain Knowledge in Data-driven Earth Observation with Process Convolutions</b>
<a href="https://arxiv.org/abs/2104.08134">arxiv:2104.08134</a>
&#x1F4C8; 2 <br>
<p>Daniel Heestermans Svendsen, Maria Piles, Jordi Muñoz-Marí, David Luengo, Luca Martino, Gustau Camps-Valls</p></summary>
<p>

**Abstract:** The modelling of Earth observation data is a challenging problem, typically approached by either purely mechanistic or purely data-driven methods. Mechanistic models encode the domain knowledge and physical rules governing the system. Such models, however, need the correct specification of all interactions between variables in the problem and the appropriate parameterization is a challenge in itself. On the other hand, machine learning approaches are flexible data-driven tools, able to approximate arbitrarily complex functions, but lack interpretability and struggle when data is scarce or in extrapolation regimes. In this paper, we argue that hybrid learning schemes that combine both approaches can address all these issues efficiently. We introduce Gaussian process (GP) convolution models for hybrid modelling in Earth observation (EO) problems. We specifically propose the use of a class of GP convolution models called latent force models (LFMs) for EO time series modelling, analysis and understanding. LFMs are hybrid models that incorporate physical knowledge encoded in differential equations into a multioutput GP model. LFMs can transfer information across time-series, cope with missing observations, infer explicit latent functions forcing the system, and learn parameterizations which are very helpful for system analysis and interpretability. We consider time series of soil moisture from active (ASCAT) and passive (SMOS, AMSR2) microwave satellites. We show how assuming a first order differential equation as governing equation, the model automatically estimates the e-folding time or decay rate related to soil moisture persistence and discovers latent forces related to precipitation. The proposed hybrid methodology reconciles the two main approaches in remote sensing parameter estimation by blending statistical learning and mechanistic modeling.

</p>
</details>

<details><summary><b>Orthogonal Features Based EEG Signals Denoising Using Fractional and Compressed One-Dimensional CNN AutoEncoder</b>
<a href="https://arxiv.org/abs/2104.08120">arxiv:2104.08120</a>
&#x1F4C8; 2 <br>
<p>Subham Nagar, Ahlad Kumar</p></summary>
<p>

**Abstract:** This paper presents a fractional one-dimensional convolutional neural network (CNN) autoencoder for denoising the Electroencephalogram (EEG) signals which often get contaminated with noise during the recording process, mostly due to muscle artifacts (MA), introduced by the movement of muscles. The existing EEG denoising methods make use of decomposition, thresholding and filtering techniques. In the proposed approach, EEG signals are first transformed to orthogonal domain using Tchebichef moments before feeding to the proposed architecture. A new hyper-parameter ($α$) is introduced which refers to the fractional order with respect to which gradients are calculated during back-propagation. It is observed that by tuning $α$, the quality of the restored signal improves significantly. Motivated by the high usage of portable low energy devices which make use of compressed deep learning architectures, the trainable parameters of the proposed architecture are compressed using randomized singular value decomposition (RSVD) algorithm. The experiments are performed on the standard EEG datasets, namely, Mendeley and Bonn. The study shows that the proposed fractional and compressed architecture performs better than existing state-of-the-art signal denoising methods.

</p>
</details>

<details><summary><b>Effect of Visual Extensions on Natural Language Understanding in Vision-and-Language Models</b>
<a href="https://arxiv.org/abs/2104.08066">arxiv:2104.08066</a>
&#x1F4C8; 2 <br>
<p>Taichi Iki, Akiko Aizawa</p></summary>
<p>

**Abstract:** A method for creating a vision-and-language (V&L) model is to extend a language model through structural modifications and V&L pre-training. Such an extension aims to make a V&L model inherit the capability of natural language understanding (NLU) from the original language model. To see how well this is achieved, we propose to evaluate V&L models using an NLU benchmark (GLUE). We compare five V&L models, including single-stream and dual-stream models, trained with the same pre-training. Dual-stream models, with their higher modality independence achieved by approximately doubling the number of parameters, are expected to preserve the NLU capability better. Our main finding is that the dual-stream scores are not much different than the single-stream scores, contrary to expectation. Further analysis shows that pre-training causes the performance drop in NLU tasks with few exceptions. These results suggest that adopting a single-stream structure and devising the pre-training could be an effective method for improving the maintenance of language knowledge in V&L extensions.

</p>
</details>

<details><summary><b>TeLCoS: OnDevice Text Localization with Clustering of Script</b>
<a href="https://arxiv.org/abs/2104.08045">arxiv:2104.08045</a>
&#x1F4C8; 2 <br>
<p>Rachit S Munjal, Manoj Goyal, Rutika Moharir, Sukumar Moharana</p></summary>
<p>

**Abstract:** Recent research in the field of text localization in a resource constrained environment has made extensive use of deep neural networks. Scene text localization and recognition on low-memory mobile devices have a wide range of applications including content extraction, image categorization and keyword based image search. For text recognition of multi-lingual localized text, the OCR systems require prior knowledge of the script of each text instance. This leads to word script identification being an essential step for text recognition. Most existing methods treat text localization, script identification and text recognition as three separate tasks. This makes script identification an overhead in the recognition pipeline. To reduce this overhead, we propose TeLCoS: OnDevice Text Localization with Clustering of Script, a multi-task dual branch lightweight CNN network that performs real-time on device Text Localization and High-level Script Clustering simultaneously. The network drastically reduces the number of calls to a separate script identification module, by grouping and identifying some majorly used scripts through a single feed-forward pass over the localization network. We also introduce a novel structural similarity based channel pruning mechanism to build an efficient network with only 1.15M parameters. Experiments on benchmark datasets suggest that our method achieves state-of-the-art performance, with execution latency of 60 ms for the entire pipeline on the Exynos 990 chipset device.

</p>
</details>

<details><summary><b>Data Generating Process to Evaluate Causal Discovery Techniques for Time Series Data</b>
<a href="https://arxiv.org/abs/2104.08043">arxiv:2104.08043</a>
&#x1F4C8; 2 <br>
<p>Andrew R. Lawrence, Marcus Kaiser, Rui Sampaio, Maksim Sipos</p></summary>
<p>

**Abstract:** Going beyond correlations, the understanding and identification of causal relationships in observational time series, an important subfield of Causal Discovery, poses a major challenge. The lack of access to a well-defined ground truth for real-world data creates the need to rely on synthetic data for the evaluation of these methods. Existing benchmarks are limited in their scope, as they either are restricted to a "static" selection of data sets, or do not allow for a granular assessment of the methods' performance when commonly made assumptions are violated. We propose a flexible and simple to use framework for generating time series data, which is aimed at developing, evaluating, and benchmarking time series causal discovery methods. In particular, the framework can be used to fine tune novel methods on vast amounts of data, without "overfitting" them to a benchmark, but rather so they perform well in real-world use cases. Using our framework, we evaluate prominent time series causal discovery methods and demonstrate a notable degradation in performance when their assumptions are invalidated and their sensitivity to choice of hyperparameters. Finally, we propose future research directions and how our framework can support both researchers and practitioners.

</p>
</details>

<details><summary><b>Implementing CNN Layers on the Manticore Cluster-Based Many-Core Architecture</b>
<a href="https://arxiv.org/abs/2104.08009">arxiv:2104.08009</a>
&#x1F4C8; 2 <br>
<p>Andreas Kurth, Fabian Schuiki, Luca Benini</p></summary>
<p>

**Abstract:** This document presents implementations of fundamental convolutional neural network (CNN) layers on the Manticore cluster-based many-core architecture and discusses their characteristics and trade-offs.

</p>
</details>

<details><summary><b>Efficient and Generic 1D Dilated Convolution Layer for Deep Learning</b>
<a href="https://arxiv.org/abs/2104.08002">arxiv:2104.08002</a>
&#x1F4C8; 2 <br>
<p>Narendra Chaudhary, Sanchit Misra, Dhiraj Kalamkar, Alexander Heinecke, Evangelos Georganas, Barukh Ziv, Menachem Adelman, Bharat Kaul</p></summary>
<p>

**Abstract:** Convolutional neural networks (CNNs) have found many applications in tasks involving two-dimensional (2D) data, such as image classification and image processing. Therefore, 2D convolution layers have been heavily optimized on CPUs and GPUs. However, in many applications - for example genomics and speech recognition, the data can be one-dimensional (1D). Such applications can benefit from optimized 1D convolution layers. In this work, we introduce our efficient implementation of a generic 1D convolution layer covering a wide range of parameters. It is optimized for x86 CPU architectures, in particular, for architectures containing Intel AVX-512 and AVX-512 BFloat16 instructions. We use the LIBXSMM library's batch-reduce General Matrix Multiplication (BRGEMM) kernel for FP32 and BFloat16 precision. We demonstrate that our implementation can achieve up to 80% efficiency on Intel Xeon Cascade Lake and Cooper Lake CPUs. Additionally, we show the generalization capability of our BRGEMM based approach by achieving high efficiency across a range of parameters. We consistently achieve higher efficiency than the 1D convolution layer with Intel oneDNN library backend for varying input tensor widths, filter widths, number of channels, filters, and dilation parameters. Finally, we demonstrate the performance of our optimized 1D convolution layer by utilizing it in the end-to-end neural network training with real genomics datasets and achieve up to 6.86x speedup over the oneDNN library-based implementation on Cascade Lake CPUs. We also demonstrate the scaling with 16 sockets of Cascade/Cooper Lake CPUs and achieve significant speedup over eight V100 GPUs using a similar power envelop. In the end-to-end training, we get a speedup of 1.41x on Cascade Lake with FP32, 1.57x on Cooper Lake with FP32, and 2.27x on Cooper Lake with BFloat16 over eight V100 GPUs with FP32.

</p>
</details>

<details><summary><b>LAI Estimation of Cucumber Crop Based on Improved Fully Convolutional Network</b>
<a href="https://arxiv.org/abs/2104.07955">arxiv:2104.07955</a>
&#x1F4C8; 2 <br>
<p>Weiqi Shu, Ling Wang, Bolong Liu, Jie Liu</p></summary>
<p>

**Abstract:** LAI (Leaf Area Index) is of great importance for crop yield estimation in agronomy. It is directly related to plant growth status, net assimilation rate, plant photosynthesis, and carbon dioxide in the environment. How to measure LAI accurately and efficiently is the key to the crop yield estimation problem. Manual measurement consumes a lot of human resources and material resources. Remote sensing technology is not suitable for near-Earth LAI measurement. Besides, methods based on traditional digital image processing are greatly affected by environmental noise and image exposure. Nowadays, deep learning is widely used in many fields. The improved FCN (Fully Convolutional Network) is proposed in our study for LAI measure task. Eighty-two cucumber images collected from our greenhouse are labeled to fine-tuning the pre-trained model. The result shows that the improved FCN model performs well on our dataset. Our method's mean IoU can reach 0.908, which is 11% better than conventional methods and 4.7% better than the basic FCN model.

</p>
</details>

<details><summary><b>Interval-censored Hawkes processes</b>
<a href="https://arxiv.org/abs/2104.07932">arxiv:2104.07932</a>
&#x1F4C8; 2 <br>
<p>Marian-Andrei Rizoiu, Alexander Soen, Shidi Li, Pio Calderon, Leanne Dong, Aditya Krishna Menon, Lexing Xie</p></summary>
<p>

**Abstract:** This work builds a novel point process and tools to use the Hawkes process with interval-censored data. Such data records the aggregated counts of events solely during specific time intervals -- such as the number of patients admitted to the hospital or the volume of vehicles passing traffic loop detectors -- and not the exact occurrence time of the events. First, we establish the Mean Behavior Poisson (MBP) process, a novel Poisson process with a direct parameter correspondence to the popular self-exciting Hawkes process. The event intensity function of the MBP is the expected intensity over all possible Hawkes realizations with the same parameter set. We fit MBP in the interval-censored setting using an interval-censored Poisson log-likelihood (IC-LL). We use the parameter equivalence to uncover the parameters of the associated Hawkes process. Second, we introduce two novel exogenous functions to distinguish the exogenous from the endogenous events. We propose the multi-impulse exogenous function when the exogenous events are observed as event time and the latent homogeneous Poisson process exogenous function when the exogenous events are presented as interval-censored volumes. Third, we provide several approximation methods to estimate the intensity and compensator function of MBP when no analytical solution exists. Fourth and finally, we connect the interval-censored loss of MBP to a broader class of Bregman divergence-based functions. Using the connection, we show that the current state of the art in popularity estimation (Hawkes Intensity Process (HIP) (Rizoiu et al.,2017b)) is a particular case of the MBP process. We verify our models through empirical testing on synthetic data and real-world data. We find that on real-world datasets that our MBP process outperforms HIP for the task of popularity prediction.

</p>
</details>

<details><summary><b>Hop-Count Based Self-Supervised Anomaly Detection on Attributed Networks</b>
<a href="https://arxiv.org/abs/2104.07917">arxiv:2104.07917</a>
&#x1F4C8; 2 <br>
<p>Tianjin Huang, Yulong Pei, Vlado Menkovski, Mykola Pechenizkiy</p></summary>
<p>

**Abstract:** Recent years have witnessed an upsurge of interest in the problem of anomaly detection on attributed networks due to its importance in both research and practice. Although various approaches have been proposed to solve this problem, two major limitations exist: (1) unsupervised approaches usually work much less efficiently due to the lack of supervisory signal, and (2) existing anomaly detection methods only use local contextual information to detect anomalous nodes, e.g., one- or two-hop information, but ignore the global contextual information. Since anomalous nodes differ from normal nodes in structures and attributes, it is intuitive that the distance between anomalous nodes and their neighbors should be larger than that between normal nodes and their neighbors if we remove the edges connecting anomalous and normal nodes. Thus, hop counts based on both global and local contextual information can be served as the indicators of anomaly. Motivated by this intuition, we propose a hop-count based model (HCM) to detect anomalies by modeling both local and global contextual information. To make better use of hop counts for anomaly identification, we propose to use hop counts prediction as a self-supervised task. We design two anomaly scores based on the hop counts prediction via HCM model to identify anomalies. Besides, we employ Bayesian learning to train HCM model for capturing uncertainty in learned parameters and avoiding overfitting. Extensive experiments on real-world attributed networks demonstrate that our proposed model is effective in anomaly detection.

</p>
</details>

<details><summary><b>An Empirical Study of Extrapolation in Text Generation with Scalar Control</b>
<a href="https://arxiv.org/abs/2104.07910">arxiv:2104.07910</a>
&#x1F4C8; 2 <br>
<p>Aashi Jain, Taylor Berg-Kirkpatrick</p></summary>
<p>

**Abstract:** We conduct an empirical evaluation of extrapolation performance when conditioning on scalar control inputs like desired output length, desired edit from an input sentence, and desired sentiment across three text generation tasks. Specifically, we examine a zero-shot setting where models are asked to generalize to ranges of control values not seen during training. We focus on evaluating popular embedding methods for scalar inputs, including both learnable and sinusoidal embeddings, as well as simpler approaches. Surprisingly, our findings indicate that the simplest strategy of using scalar inputs directly, without further encoding, most reliably allows for successful extrapolation.

</p>
</details>

<details><summary><b>An interactive dashboard for searching and comparing soccer performance scores</b>
<a href="https://arxiv.org/abs/2105.04293">arxiv:2105.04293</a>
&#x1F4C8; 1 <br>
<p>Paolo Cintia, Giovanni Mauro, Luca Pappalardo, Paolo Ferragina</p></summary>
<p>

**Abstract:** The performance of soccer players is one of most discussed aspects by many actors in the soccer industry: from supporters to journalists, from coaches to talent scouts. Unfortunately, the dashboards available online provide no effective way to compare the evolution of the performance of players or to find players behaving similarly on the field. This paper describes the design of a web dashboard that interacts via APIs with a performance evaluation algorithm and provides graphical tools that allow the user to perform many tasks, such as to search or compare players by age, role or trend of growth in their performance, find similar players based on their pitching behavior, change the algorithm's parameters to obtain customized performance scores. We also describe an example of how a talent scout can interact with the dashboard to find young, promising talents.

</p>
</details>

<details><summary><b>DEUX: An Attribute-Guided Framework for Sociable Recommendation Dialog Systems</b>
<a href="https://arxiv.org/abs/2105.00825">arxiv:2105.00825</a>
&#x1F4C8; 1 <br>
<p>Yu Li, Shirley Anugrah Hayati, Weiyan Shi, Zhou Yu</p></summary>
<p>

**Abstract:** It is important for sociable recommendation dialog systems to perform as both on-task content and social content to engage users and gain their favor. In addition to understand the user preferences and provide a satisfying recommendation, such systems must be able to generate coherent and natural social conversations to the user. Traditional dialog state tracking cannot be applied to such systems because it does not track the attributes in the social content. To address this challenge, we propose DEUX, a novel attribute-guided framework to create better user experiences while accomplishing a movie recommendation task. DEUX has a module that keeps track of the movie attributes (e.g., favorite genres, actors,etc.) in both user utterances and system responses. This allows the system to introduce new movie attributes in its social content. Then, DEUX has multiple values for the same attribute type which suits the recommendation task since a user may like multiple genres, for instance. Experiments suggest that DEUX outperforms all the baselines on being more consistent, fitting the user preferences better, and providing a more engaging chat experience. Our approach can be used for any similar problems of sociable task-oriented dialog system.

</p>
</details>

<details><summary><b>COVID-19 Modeling: A Review</b>
<a href="https://arxiv.org/abs/2104.12556">arxiv:2104.12556</a>
&#x1F4C8; 1 <br>
<p>Longbing Cao, Qing Liu</p></summary>
<p>

**Abstract:** The SARS-CoV-2 virus and COVID-19 disease have posed unprecedented and overwhelming demand, challenges and opportunities to domain, model and data driven modeling. This paper provides a comprehensive review of the challenges, tasks, methods, progress, gaps and opportunities in relation to modeling COVID-19 problems, data and objectives. It constructs a research landscape of COVID-19 modeling tasks and methods, and further categorizes, summarizes, compares and discusses the related methods and progress of modeling COVID-19 epidemic transmission processes and dynamics, case identification and tracing, infection diagnosis and medical treatments, non-pharmaceutical interventions and their effects, drug and vaccine development, psychological, economic and social influence and impact, and misinformation, etc. The modeling methods involve mathematical and statistical models, domain-driven modeling by epidemiological compartmental models, medical and biomedical analysis, AI and data science in particular shallow and deep machine learning, simulation modeling, social science methods, and hybrid modeling.

</p>
</details>

<details><summary><b>Viking: Variational Bayesian Variance Tracking</b>
<a href="https://arxiv.org/abs/2104.10777">arxiv:2104.10777</a>
&#x1F4C8; 1 <br>
<p>Joseph de Vilmarest, Olivier Wintenberger</p></summary>
<p>

**Abstract:** We consider the problem of time series forecasting in an adaptive setting. We focus on the inference of state-space models under unknown and potentially time-varying noise variances.  We introduce an augmented model in which the variances are represented as auxiliary gaussian latent variables in a tracking mode. As variances are nonnegative, a transformation is chosen and applied to these latent variables. The inference relies on the online variational Bayesian methodology, which consists in minimizing a Kullback-Leibler divergence at each time step. We observe that the minimum of the Kullback-Leibler divergence is an extension of the Kalman filter taking into account the variance uncertainty.  We design a novel algorithm, named Viking, using these optimal recursive updates. For auxiliary latent variables, we use second-order bounds whose optimum admit closed-form solutions. Experiments on synthetic data show that Viking behaves well and is robust to misspecification.

</p>
</details>

<details><summary><b>Deep Gaussian Processes for Biogeophysical Parameter Retrieval and Model Inversion</b>
<a href="https://arxiv.org/abs/2104.10638">arxiv:2104.10638</a>
&#x1F4C8; 1 <br>
<p>Daniel Heestermans Svendsen, Pablo Morales-Alvarez, Ana Belen Ruescas, Rafael Molina, Gustau Camps-Valls</p></summary>
<p>

**Abstract:** Parameter retrieval and model inversion are key problems in remote sensing and Earth observation. Currently, different approximations exist: a direct, yet costly, inversion of radiative transfer models (RTMs); the statistical inversion with in situ data that often results in problems with extrapolation outside the study area; and the most widely adopted hybrid modeling by which statistical models, mostly nonlinear and non-parametric machine learning algorithms, are applied to invert RTM simulations. We will focus on the latter. Among the different existing algorithms, in the last decade kernel based methods, and Gaussian Processes (GPs) in particular, have provided useful and informative solutions to such RTM inversion problems. This is in large part due to the confidence intervals they provide, and their predictive accuracy. However, RTMs are very complex, highly nonlinear, and typically hierarchical models, so that often a shallow GP model cannot capture complex feature relations for inversion. This motivates the use of deeper hierarchical architectures, while still preserving the desirable properties of GPs. This paper introduces the use of deep Gaussian Processes (DGPs) for bio-geo-physical model inversion. Unlike shallow GP models, DGPs account for complicated (modular, hierarchical) processes, provide an efficient solution that scales well to big datasets, and improve prediction accuracy over their single layer counterpart. In the experimental section, we provide empirical evidence of performance for the estimation of surface temperature and dew point temperature from infrared sounding data, as well as for the prediction of chlorophyll content, inorganic suspended matter, and coloured dissolved matter from multispectral data acquired by the Sentinel-3 OLCI sensor. The presented methodology allows for more expressive forms of GPs in remote sensing model inversion problems.

</p>
</details>

<details><summary><b>HTN Planning Domain for Deployment of Cloud Applications</b>
<a href="https://arxiv.org/abs/2104.10027">arxiv:2104.10027</a>
&#x1F4C8; 1 <br>
<p>Ilche Georgievski</p></summary>
<p>

**Abstract:** Cloud providers are facing a complex problem in configuring software applications ready for deployment on their infrastructures. Hierarchical Task Network (HTN) planning can provide effective means to solve such deployment problems. We present an HTN planning domain that models deployment problems as found in realistic Cloud environments.

</p>
</details>

<details><summary><b>Sequential Deconfounding for Causal Inference with Unobserved Confounders</b>
<a href="https://arxiv.org/abs/2104.09323">arxiv:2104.09323</a>
&#x1F4C8; 1 <br>
<p>Tobias Hatt, Stefan Feuerriegel</p></summary>
<p>

**Abstract:** Using observational data to estimate the effect of a treatment is a powerful tool for decision-making when randomized experiments are infeasible or costly. However, observational data often yields biased estimates of treatment effects, since treatment assignment can be confounded by unobserved variables. A remedy is offered by deconfounding methods that adjust for such unobserved confounders. In this paper, we develop the Sequential Deconfounder, a method that enables estimating individualized treatment effects over time in presence of unobserved confounders. This is the first deconfounding method that can be used in a general sequential setting (i.e., with one or more treatments assigned at each timestep). The Sequential Deconfounder uses a novel Gaussian process latent variable model to infer substitutes for the unobserved confounders, which are then used in conjunction with an outcome model to estimate treatment effects over time. We prove that using our method yields unbiased estimates of individualized treatment responses over time. Using simulated and real medical data, we demonstrate the efficacy of our method in deconfounding the estimation of treatment responses over time.

</p>
</details>

<details><summary><b>Inverse Bayesian Optimization: Learning Human Search Strategies in a Sequential Optimization Task</b>
<a href="https://arxiv.org/abs/2104.09237">arxiv:2104.09237</a>
&#x1F4C8; 1 <br>
<p>Nathan Sandholtz, Yohsuke Miyamoto, Luke Bornn, Maurice Smith</p></summary>
<p>

**Abstract:** Bayesian optimization is a popular algorithm for sequential optimization of a latent objective function when sampling from the objective is costly. The search path of the algorithm is governed by the acquisition function, which defines the agent's search strategy. Conceptually, the acquisition function characterizes how the optimizer balances exploration and exploitation when searching for the optimum of the latent objective. In this paper, we explore the inverse problem of Bayesian optimization; we seek to estimate the agent's latent acquisition function based on observed search paths. We introduce a probabilistic solution framework for the inverse problem which provides a principled framework to quantify both the variability with which the agent performs the optimization task as well as the uncertainty around their estimated acquisition function.
  We illustrate our methods by analyzing human behavior from an experiment which was designed to force subjects to balance exploration and exploitation in search of an invisible target location. We find that while most subjects demonstrate clear trends in their search behavior, there is significant variation around these trends from round to round. A wide range of search strategies are exhibited across the subjects in our study, but upper confidence bound acquisition functions offer the best fit for the majority of subjects. Finally, some subjects do not map well to any of the acquisition functions we initially consider; these subjects tend to exhibit exploration preferences beyond that of standard acquisition functions to capture. Guided by the model discrepancies, we augment the candidate acquisition functions to yield a superior fit to the human behavior in this task.

</p>
</details>

<details><summary><b>Exact imposition of boundary conditions with distance functions in physics-informed deep neural networks</b>
<a href="https://arxiv.org/abs/2104.08426">arxiv:2104.08426</a>
&#x1F4C8; 1 <br>
<p>N. Sukumar, Ankit Srivastava</p></summary>
<p>

**Abstract:** In this paper, we introduce a new approach based on distance fields to exactly impose boundary conditions in physics-informed deep neural networks. The challenges in satisfying Dirichlet boundary conditions in meshfree and particle methods are well-known. This issue is also pertinent in the development of physics informed neural networks (PINN) for the solution of partial differential equations. We introduce geometry-aware trial functions in artifical neural networks to improve the training in deep learning for partial differential equations. To this end, we use concepts from constructive solid geometry (R-functions) and generalized barycentric coordinates (mean value potential fields) to construct $φ$, an approximate distance function to the boundary of a domain. To exactly impose homogeneous Dirichlet boundary conditions, the trial function is taken as $φ$ multiplied by the PINN approximation, and its generalization via transfinite interpolation is used to a priori satisfy inhomogeneous Dirichlet (essential), Neumann (natural), and Robin boundary conditions on complex geometries. In doing so, we eliminate modeling error associated with the satisfaction of boundary conditions in a collocation method and ensure that kinematic admissibility is met pointwise in a Ritz method. We present numerical solutions for linear and nonlinear boundary-value problems over domains with affine and curved boundaries. Benchmark problems in 1D for linear elasticity, advection-diffusion, and beam bending; and in 2D for the Poisson equation, biharmonic equation, and the nonlinear Eikonal equation are considered. The approach extends to higher dimensions, and we showcase its use by solving a Poisson problem with homogeneous Dirichlet boundary conditions over the 4D hypercube. This study provides a pathway for meshfree analysis to be conducted on the exact geometry without domain discretization.

</p>
</details>

<details><summary><b>Model-Based Deep Autoencoder Networks for Nonlinear Hyperspectral Unmixing</b>
<a href="https://arxiv.org/abs/2104.08409">arxiv:2104.08409</a>
&#x1F4C8; 1 <br>
<p>Haoqing Li, Ricardo Augusto Borsoi, Tales Imbiriba, Pau Closas, José Carlos Moreira Bermudez, Deniz Erdoğmuş</p></summary>
<p>

**Abstract:** Autoencoder (AEC) networks have recently emerged as a promising approach to perform unsupervised hyperspectral unmixing (HU) by associating the latent representations with the abundances, the decoder with the mixing model and the encoder with its inverse. AECs are especially appealing for nonlinear HU since they lead to unsupervised and model-free algorithms. However, existing approaches fail to explore the fact that the encoder should invert the mixing process, which might reduce their robustness. In this paper, we propose a model-based AEC for nonlinear HU by considering the mixing model a nonlinear fluctuation over a linear mixture. Differently from previous works, we show that this restriction naturally imposes a particular structure to both the encoder and to the decoder networks. This introduces prior information in the AEC without reducing the flexibility of the mixing model. Simulations with synthetic and real data indicate that the proposed strategy improves nonlinear HU.

</p>
</details>

<details><summary><b>An Analysis of a BERT Deep Learning Strategy on a Technology Assisted Review Task</b>
<a href="https://arxiv.org/abs/2104.08340">arxiv:2104.08340</a>
&#x1F4C8; 1 <br>
<p>Alexandros Ioannidis</p></summary>
<p>

**Abstract:** Document screening is a central task within Evidenced Based Medicine, which is a clinical discipline that supplements scientific proof to back medical decisions. Given the recent advances in DL (Deep Learning) methods applied to Information Retrieval tasks, I propose a DL document classification approach with BERT or PubMedBERT embeddings and a DL similarity search path using SBERT embeddings to reduce physicians' tasks of screening and classifying immense amounts of documents to answer clinical queries. I test and evaluate the retrieval effectiveness of my DL strategy on the 2017 and 2018 CLEF eHealth collections. I find that the proposed DL strategy works, I compare it to the recently successful BM25 plus RM3 model, and conclude that the suggested method accomplishes advanced retrieval performance in the initial ranking of the articles with the aforementioned datasets, for the CLEF eHealth Technologically Assisted Reviews in Empirical Medicine Task.

</p>
</details>

<details><summary><b>Data Shapley Valuation for Efficient Batch Active Learning</b>
<a href="https://arxiv.org/abs/2104.08312">arxiv:2104.08312</a>
&#x1F4C8; 1 <br>
<p>Amirata Ghorbani, James Zou, Andre Esteva</p></summary>
<p>

**Abstract:** Annotating the right set of data amongst all available data points is a key challenge in many machine learning applications. Batch active learning is a popular approach to address this, in which batches of unlabeled data points are selected for annotation, while an underlying learning algorithm gets subsequently updated. Increasingly larger batches are particularly appealing in settings where data can be annotated in parallel, and model training is computationally expensive. A key challenge here is scale - typical active learning methods rely on diversity techniques, which select a diverse set of data points to annotate, from an unlabeled pool. In this work, we introduce Active Data Shapley (ADS) -- a filtering layer for batch active learning that significantly increases the efficiency of active learning by pre-selecting, using a linear time computation, the highest-value points from an unlabeled dataset. Using the notion of the Shapley value of data, our method estimates the value of unlabeled data points with regards to the prediction task at hand. We show that ADS is particularly effective when the pool of unlabeled data exhibits real-world caveats: noise, heterogeneity, and domain shift. We run experiments demonstrating that when ADS is used to pre-select the highest-ranking portion of an unlabeled dataset, the efficiency of state-of-the-art batch active learning methods increases by an average factor of 6x, while preserving performance effectiveness.

</p>
</details>

<details><summary><b>Neural Transfer Learning for Repairing Security Vulnerabilities in C Code</b>
<a href="https://arxiv.org/abs/2104.08308">arxiv:2104.08308</a>
&#x1F4C8; 1 <br>
<p>Zimin Chen, Steve Kommrusch, Martin Monperrus</p></summary>
<p>

**Abstract:** In this paper, we address the problem of automatic repair of software vulnerabilities with deep learning. The major problemwith data-driven vulnerability repair is that the few existing datasets of known confirmed vulnerabilities consist of only a few thousandexamples. However, training a deep learning model often requires hundreds of thousands of examples. In this work, we leverage theintuition that the bug fixing task and the vulnerability fixing task are related, and that the knowledge learned from bug fixes can betransferred to fixing vulnerabilities. In the machine learning community, this technique is called transfer learning. In this paper, wepropose an approach for repairing security vulnerabilities named VRepair which is based on transfer learning. VRepair is first trainedon a large bug fix corpus and is then tuned on a vulnerability fix dataset, which is an order of magnitude smaller. In our experiments,we show that a model trained only on a bug fix corpus can already fix some vulnerabilities. Then, we demonstrate that transfer learningimproves the ability to repair vulnerable C functions. We also show that the transfer learning model performs better than a modeltrained with a denoising task and fine-tuned on the vulnerability fixing task. To sum up, this paper shows that transfer learning workswell for repairing security vulnerabilities in C compared to learning on a small dataset.

</p>
</details>

<details><summary><b>Controlled abstention neural networks for identifying skillful predictions for classification problems</b>
<a href="https://arxiv.org/abs/2104.08281">arxiv:2104.08281</a>
&#x1F4C8; 1 <br>
<p>Elizabeth A. Barnes, Randal J. Barnes</p></summary>
<p>

**Abstract:** The earth system is exceedingly complex and often chaotic in nature, making prediction incredibly challenging: we cannot expect to make perfect predictions all of the time. Instead, we look for specific states of the system that lead to more predictable behavior than others, often termed "forecasts of opportunity." When these opportunities are not present, scientists need prediction systems that are capable of saying "I don't know." We introduce a novel loss function, termed the "NotWrong loss", that allows neural networks to identify forecasts of opportunity for classification problems. The NotWrong loss introduces an abstention class that allows the network to identify the more confident samples and abstain (say "I don't know") on the less confident samples. The abstention loss is designed to abstain on a user-defined fraction of the samples via a PID controller. Unlike many machine learning methods used to reject samples post-training, the NotWrong loss is applied during training to preferentially learn from the more confident samples. We show that the NotWrong loss outperforms other existing loss functions for multiple climate use cases. The implementation of the proposed loss function is straightforward in most network architectures designed for classification as it only requires the addition of an abstention class to the output layer and modification of the loss function.

</p>
</details>

<details><summary><b>Automatic quality control of brain T1-weighted magnetic resonance images for a clinical data warehouse</b>
<a href="https://arxiv.org/abs/2104.08131">arxiv:2104.08131</a>
&#x1F4C8; 1 <br>
<p>Simona Bottani, Ninon Burgos, Aurélien Maire, Adam Wild, Sebastian Ströer, Didier Dormont, Olivier Colliot</p></summary>
<p>

**Abstract:** Many studies on machine learning (ML) for computer-aided diagnosis have so far been mostly restricted to high-quality research data. Clinical data warehouses, gathering routine examinations from hospitals, offer great promises for training and validation of ML models in a realistic setting. However, the use of such clinical data warehouses requires quality control (QC) tools. Visual QC by experts is time-consuming and does not scale to large datasets. In this paper, we propose a convolutional neural network (CNN) for the automatic QC of 3D T1-weighted brain MRI for a large heterogeneous clinical data warehouse. To that purpose, we used the data warehouse of the hospitals of the Greater Paris area (Assistance Publique-Hôpitaux de Paris [AP-HP]). Specifically, the objectives were: 1) to identify images which are not proper T1-weighted brain MRIs; 2) to identify acquisitions for which gadolinium was injected; 3) to rate the overall image quality. We used 5000 images for training and validation and a separate set of 500 images for testing. In order to train/validate the CNN, the data were annotated by two trained raters according to a visual QC protocol that we specifically designed for application in the setting of a data warehouse. For objectives 1 and 2, our approach achieved excellent accuracy (balanced accuracy and F1-score \textgreater 90\%), similar to the human raters. For objective 3, the performance was good but substantially lower than that of human raters. Nevertheless, the automatic approach accurately identified (balanced accuracy and F1-score \textgreater 80\%) low quality images, which would typically need to be excluded. Overall, our approach shall be useful for exploiting hospital data warehouses in medical image computing.

</p>
</details>

<details><summary><b>Signed Distance Function Computation from an Implicit Surface</b>
<a href="https://arxiv.org/abs/2104.08057">arxiv:2104.08057</a>
&#x1F4C8; 1 <br>
<p>Pierre-Alain Fayolle</p></summary>
<p>

**Abstract:** We describe in this short note a technique to convert an implicit surface into a Signed Distance Function (SDF) while exactly preserving the zero level-set of the implicit. The proposed approach relies on embedding the input implicit in the final layer of a neural network, which is trained to minimize a loss function characterizing the SDF.

</p>
</details>

<details><summary><b>Holmes: An Efficient and Lightweight Semantic Based Anomalous Email Detector</b>
<a href="https://arxiv.org/abs/2104.08044">arxiv:2104.08044</a>
&#x1F4C8; 1 <br>
<p>Peilun Wu, Fan Yan, Hui Guo</p></summary>
<p>

**Abstract:** Email threat is a serious issue for enterprise security, which consists of various malicious scenarios, such as phishing, fraud, blackmail and malvertisement. Traditional anti-spam gateway commonly requires to maintain a greylist to filter out unexpected emails based on suspicious vocabularies existed in the mail subject and content. However, the signature-based approach cannot effectively discover novel and unknown suspicious emails that utilize various hot topics at present, such as COVID-19 and US election. To address the problem, in this paper, we present Holmes, an efficient and lightweight semantic based engine for anomalous email detection. Holmes can convert each event log of email to a sentence through word embedding then extract interesting items among them by novelty detection. Based on our observations, we claim that, in an enterprise environment, there is a stable relation between senders and receivers, but suspicious emails are commonly from unusual sources, which can be detected through the rareness selection. We evaluate the performance of Holmes in a real-world enterprise environment, in which it sends and receives around 5,000 emails each day. As a result, Holmes can achieve a high detection rate (output around 200 suspicious emails per day) and maintain a low false alarm rate for anomaly detection.

</p>
</details>

<details><summary><b>OpenCSI: An Open-Source Dataset for Indoor Localization Using CSI-Based Fingerprinting</b>
<a href="https://arxiv.org/abs/2104.07963">arxiv:2104.07963</a>
&#x1F4C8; 1 <br>
<p>Arthur Gassner, Claudiu Musat, Alexandru Rusu, Andreas Burg</p></summary>
<p>

**Abstract:** Many applications require accurate indoor localization. Fingerprint-based localization methods propose a solution to this problem, but rely on a radio map that is effort-intensive to acquire. We automate the radio map acquisition phase using a software-defined radio (SDR) and a wheeled robot. Furthermore, we open-source a radio map acquired with our automated tool for a 3GPP Long-Term Evolution (LTE) wireless link. To the best of our knowledge, this is the first publicly available radio map containing channel state information (CSI). Finally, we describe first localization experiments on this radio map using a convolutional neural network to regress for location coordinates.

</p>
</details>

<details><summary><b>Motion Prediction Performance Analysis for Autonomous Driving Systems and the Effects of Tracking Noise</b>
<a href="https://arxiv.org/abs/2104.08368">arxiv:2104.08368</a>
&#x1F4C8; 0 <br>
<p>Ameni Trabelsi, Ross J. Beveridge, Nathaniel Blanchard</p></summary>
<p>

**Abstract:** Autonomous driving consists of a multitude of interacting modules, where each module must contend with errors from the others. Typically, the motion prediction module depends upon a robust tracking system to capture each agent's past movement. In this work, we systematically explore the importance of the tracking module for the motion prediction task and ultimately conclude that the overall motion prediction performance is highly sensitive to the tracking module's imperfections. We explicitly compare models that use tracking information to models that do not across multiple scenarios and conditions. We find that the tracking information plays an essential role and improves motion prediction performance in noise-free conditions. However, in the presence of tracking noise, it can potentially affect the overall performance if not studied thoroughly. We thus argue practitioners should be mindful of noise when developing and testing motion/tracking modules, or that they should consider tracking free alternatives.

</p>
</details>

<details><summary><b>On the Robustness to Misspecification of $α$-Posteriors and Their Variational Approximations</b>
<a href="https://arxiv.org/abs/2104.08324">arxiv:2104.08324</a>
&#x1F4C8; 0 <br>
<p>Marco Avella Medina, José Luis Montiel Olea, Cynthia Rush, Amilcar Velez</p></summary>
<p>

**Abstract:** $α$-posteriors and their variational approximations distort standard posterior inference by downweighting the likelihood and introducing variational approximation errors. We show that such distortions, if tuned appropriately, reduce the Kullback-Leibler (KL) divergence from the true, but perhaps infeasible, posterior distribution when there is potential parametric model misspecification. To make this point, we derive a Bernstein-von Mises theorem showing convergence in total variation distance of $α$-posteriors and their variational approximations to limiting Gaussian distributions. We use these distributions to evaluate the KL divergence between true and reported posteriors. We show this divergence is minimized by choosing $α$ strictly smaller than one, assuming there is a vanishingly small probability of model misspecification. The optimized value becomes smaller as the the misspecification becomes more severe. The optimized KL divergence increases logarithmically in the degree of misspecification and not linearly as with the usual posterior.

</p>
</details>

<details><summary><b>Li$_x$CoO$_2$ phase stability studied by machine learning-enabled scale bridging between electronic structure, statistical mechanics and phase field theories</b>
<a href="https://arxiv.org/abs/2104.08318">arxiv:2104.08318</a>
&#x1F4C8; 0 <br>
<p>Gregory H. Teichert, Sambit Das, Muratahan Aykol, Chirranjeevi Gopal, Vikram Gavini, Krishna Garikipati</p></summary>
<p>

**Abstract:** Li$_xTM$O$_2$ (TM={Ni, Co, Mn}) are promising cathodes for Li-ion batteries, whose electrochemical cycling performance is strongly governed by crystal structure and phase stability as a function of Li content at the atomistic scale. Here, we use Li$_x$CoO$_2$ (LCO) as a model system to benchmark a scale-bridging framework that combines density functional theory (DFT) calculations at the atomistic scale with phase field modeling at the continuum scale to understand the impact of phase stability on microstructure evolution. This scale bridging is accomplished by incorporating traditional statistical mechanics methods with integrable deep neural networks, which allows formation energies for specific atomic configurations to be coarse-grained and incorporated in a neural network description of the free energy of the material. The resulting realistic free energy functions enable atomistically informed phase-field simulations. These computational results allow us to make connections to experimental work on LCO cathode degradation as a function of temperature, morphology and particle size.

</p>
</details>

<details><summary><b>Automatic Termination for Hyperparameter Optimization</b>
<a href="https://arxiv.org/abs/2104.08166">arxiv:2104.08166</a>
&#x1F4C8; 0 <br>
<p>Anastasia Makarova, Huibin Shen, Valerio Perrone, Aaron Klein, Jean Baptiste Faddoul, Andreas Krause, Matthias Seeger, Cedric Archambeau</p></summary>
<p>

**Abstract:** Bayesian optimization (BO) is a widely popular approach for the hyperparameter optimization (HPO) of machine learning algorithms. At its core, BO iteratively evaluates promising configurations until a user-defined budget, such as wall-clock time or number of iterations, is exhausted. While the final performance after tuning heavily depends on the provided budget, it is hard to pre-specify an optimal value in advance. In this work, we propose an effective and intuitive termination criterion for BO that automatically stops the procedure if it is sufficiently close to the global optima. Across an extensive range of real-world HPO problems, we show that our termination criterion achieves better test performance compared to existing baselines from the literature, such as stopping when the probability of improvement drops below a fixed threshold. We also provide evidence that these baselines are, compared to our method, highly sensitive to the choices of their own hyperparameters. Additionally, we find that overfitting might occur in the context of HPO, which is arguably an overlooked problem in the literature, and show that our termination criterion mitigates this phenomenon on both small and large datasets.

</p>
</details>

<details><summary><b>Supervising Model Attention with Human Explanations for Robust Natural Language Inference</b>
<a href="https://arxiv.org/abs/2104.08142">arxiv:2104.08142</a>
&#x1F4C8; 0 <br>
<p>Joe Stacey, Yonatan Belinkov, Marek Rei</p></summary>
<p>

**Abstract:** Natural Language Inference (NLI) models are known to learn from biases and artefacts within their training data, impacting how well they generalise to other unseen datasets. Existing de-biasing approaches focus on preventing the models from learning these biases, which can result in restrictive models and lower performance. We instead investigate teaching the model how a human would approach the NLI task, in order to learn features that will generalise better to previously unseen examples. Using natural language explanations, we supervise the model's attention weights to encourage more attention to be paid to the words present in the explanations, significantly improving model performance. Our experiments show that the in-distribution improvements of this method are also accompanied by out-of-distribution improvements, with the supervised models learning from features that generalise better to other NLI datasets. Analysis of the model indicates that human explanations encourage increased attention on the important words, with more attention paid to words in the premise and less attention paid to punctuation and stop-words.

</p>
</details>


[Next Page](2021/2021-04/2021-04-15.md)
