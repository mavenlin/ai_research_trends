## Summary for 2021-04-09, created on 2021-12-22


<details><summary><b>Transformers: "The End of History" for NLP?</b>
<a href="https://arxiv.org/abs/2105.00813">arxiv:2105.00813</a>
&#x1F4C8; 1070 <br>
<p>Anton Chernyavskiy, Dmitry Ilvovsky, Preslav Nakov</p></summary>
<p>

**Abstract:** Recent advances in neural architectures, such as the Transformer, coupled with the emergence of large-scale pre-trained models such as BERT, have revolutionized the field of Natural Language Processing (NLP), pushing the state of the art for a number of NLP tasks. A rich family of variations of these models has been proposed, such as RoBERTa, ALBERT, and XLNet, but fundamentally, they all remain limited in their ability to model certain kinds of information, and they cannot cope with certain information sources, which was easy for pre-existing models. Thus, here we aim to shed light on some important theoretical limitations of pre-trained BERT-style models that are inherent in the general Transformer architecture. First, we demonstrate in practice on two general types of tasks -- segmentation and segment labeling -- and on four datasets that these limitations are indeed harmful and that addressing them, even in some very simple and naive ways, can yield sizable improvements over vanilla RoBERTa and XLNet models. Then, we offer a more general discussion on desiderata for future additions to the Transformer architecture that would increase its expressiveness, which we hope could help in the design of the next generation of deep NLP architectures.

</p>
</details>

<details><summary><b>Meta-Learning Bidirectional Update Rules</b>
<a href="https://arxiv.org/abs/2104.04657">arxiv:2104.04657</a>
&#x1F4C8; 146 <br>
<p>Mark Sandler, Max Vladymyrov, Andrey Zhmoginov, Nolan Miller, Andrew Jackson, Tom Madams, Blaise Aguera y Arcas</p></summary>
<p>

**Abstract:** In this paper, we introduce a new type of generalized neural network where neurons and synapses maintain multiple states. We show that classical gradient-based backpropagation in neural networks can be seen as a special case of a two-state network where one state is used for activations and another for gradients, with update rules derived from the chain rule. In our generalized framework, networks have neither explicit notion of nor ever receive gradients. The synapses and neurons are updated using a bidirectional Hebb-style update rule parameterized by a shared low-dimensional "genome". We show that such genomes can be meta-learned from scratch, using either conventional optimization techniques, or evolutionary strategies, such as CMA-ES. Resulting update rules generalize to unseen tasks and train faster than gradient descent based optimizers for several standard computer vision and synthetic tasks.

</p>
</details>

<details><summary><b>Counter-Strike Deathmatch with Large-Scale Behavioural Cloning</b>
<a href="https://arxiv.org/abs/2104.04258">arxiv:2104.04258</a>
&#x1F4C8; 66 <br>
<p>Tim Pearce, Jun Zhu</p></summary>
<p>

**Abstract:** This paper describes an AI agent that plays the popular first-person-shooter (FPS) video game `Counter-Strike; Global Offensive' (CSGO) from pixel input. The agent, a deep neural network, matches the performance of the medium difficulty built-in AI on the deathmatch game mode, whilst adopting a humanlike play style. Unlike much prior work in games, no API is available for CSGO, so algorithms must train and run in real-time. This limits the quantity of on-policy data that can be generated, precluding many reinforcement learning algorithms. Our solution uses behavioural cloning - training on a large noisy dataset scraped from human play on online servers (4 million frames, comparable in size to ImageNet), and a smaller dataset of high-quality expert demonstrations. This scale is an order of magnitude larger than prior work on imitation learning in FPS games.

</p>
</details>

<details><summary><b>Highly Efficient Knowledge Graph Embedding Learning with Orthogonal Procrustes Analysis</b>
<a href="https://arxiv.org/abs/2104.04676">arxiv:2104.04676</a>
&#x1F4C8; 43 <br>
<p>Xutan Peng, Guanyi Chen, Chenghua Lin, Mark Stevenson</p></summary>
<p>

**Abstract:** Knowledge Graph Embeddings (KGEs) have been intensively explored in recent years due to their promise for a wide range of applications. However, existing studies focus on improving the final model performance without acknowledging the computational cost of the proposed approaches, in terms of execution time and environmental impact. This paper proposes a simple yet effective KGE framework which can reduce the training time and carbon footprint by orders of magnitudes compared with state-of-the-art approaches, while producing competitive performance. We highlight three technical innovations: full batch learning via relational matrices, closed-form Orthogonal Procrustes Analysis for KGEs, and non-negative-sampling training. In addition, as the first KGE method whose entity embeddings also store full relation information, our trained models encode rich semantics and are highly interpretable. Comprehensive experiments and ablation studies involving 13 strong baselines and two standard datasets verify the effectiveness and efficiency of our algorithm.

</p>
</details>

<details><summary><b>Bootstrapping Semantic Segmentation with Regional Contrast</b>
<a href="https://arxiv.org/abs/2104.04465">arxiv:2104.04465</a>
&#x1F4C8; 23 <br>
<p>Shikun Liu, Shuaifeng Zhi, Edward Johns, Andrew J. Davison</p></summary>
<p>

**Abstract:** We present ReCo, a contrastive learning framework designed at a regional level to assist learning in semantic segmentation. ReCo performs semi-supervised or supervised pixel-level contrastive learning on a sparse set of hard negative pixels, with minimal additional memory footprint. ReCo is easy to implement, being built on top of off-the-shelf segmentation networks, and consistently improves performance in both semi-supervised and supervised semantic segmentation methods, achieving smoother segmentation boundaries and faster convergence. The strongest effect is in semi-supervised learning with very few labels. With ReCo, we achieve 50% mIoU in the CityScapes dataset, whilst requiring only 20 labelled images, improving by 10% relative to the previous state-of-the-art. Code is available at https://github.com/lorenmt/reco.

</p>
</details>

<details><summary><b>GATSBI: Generative Agent-centric Spatio-temporal Object Interaction</b>
<a href="https://arxiv.org/abs/2104.04275">arxiv:2104.04275</a>
&#x1F4C8; 23 <br>
<p>Cheol-Hui Min, Jinseok Bae, Junho Lee, Young Min Kim</p></summary>
<p>

**Abstract:** We present GATSBI, a generative model that can transform a sequence of raw observations into a structured latent representation that fully captures the spatio-temporal context of the agent's actions. In vision-based decision-making scenarios, an agent faces complex high-dimensional observations where multiple entities interact with each other. The agent requires a good scene representation of the visual observation that discerns essential components and consistently propagates along the time horizon. Our method, GATSBI, utilizes unsupervised object-centric scene representation learning to separate an active agent, static background, and passive objects. GATSBI then models the interactions reflecting the causal relationships among decomposed entities and predicts physically plausible future states. Our model generalizes to a variety of environments where different types of robots and objects dynamically interact with each other. We show GATSBI achieves superior performance on scene decomposition and video prediction compared to its state-of-the-art counterparts.

</p>
</details>

<details><summary><b>Fast and Efficient Locomotion via Learned Gait Transitions</b>
<a href="https://arxiv.org/abs/2104.04644">arxiv:2104.04644</a>
&#x1F4C8; 20 <br>
<p>Yuxiang Yang, Tingnan Zhang, Erwin Coumans, Jie Tan, Byron Boots</p></summary>
<p>

**Abstract:** We focus on the problem of developing energy efficient controllers for quadrupedal robots. Animals can actively switch gaits at different speeds to lower their energy consumption. In this paper, we devise a hierarchical learning framework, in which distinctive locomotion gaits and natural gait transitions emerge automatically with a simple reward of energy minimization. We use evolutionary strategies (ES) to train a high-level gait policy that specifies gait patterns of each foot, while the low-level convex MPC controller optimizes the motor commands so that the robot can walk at a desired velocity using that gait pattern. We test our learning framework on a quadruped robot and demonstrate automatic gait transitions, from walking to trotting and to fly-trotting, as the robot increases its speed. We show that the learned hierarchical controller consumes much less energy across a wide range of locomotion speed than baseline controllers.

</p>
</details>

<details><summary><b>Incorporating External Knowledge to Enhance Tabular Reasoning</b>
<a href="https://arxiv.org/abs/2104.04243">arxiv:2104.04243</a>
&#x1F4C8; 12 <br>
<p>J. Neeraja, Vivek Gupta, Vivek Srikumar</p></summary>
<p>

**Abstract:** Reasoning about tabular information presents unique challenges to modern NLP approaches which largely rely on pre-trained contextualized embeddings of text. In this paper, we study these challenges through the problem of tabular natural language inference. We propose easy and effective modifications to how information is presented to a model for this task. We show via systematic experiments that these strategies substantially improve tabular inference performance.

</p>
</details>

<details><summary><b>Protein sequence design with deep generative models</b>
<a href="https://arxiv.org/abs/2104.04457">arxiv:2104.04457</a>
&#x1F4C8; 10 <br>
<p>Zachary Wu, Kadina E. Johnston, Frances H. Arnold, Kevin K. Yang</p></summary>
<p>

**Abstract:** Protein engineering seeks to identify protein sequences with optimized properties. When guided by machine learning, protein sequence generation methods can draw on prior knowledge and experimental efforts to improve this process. In this review, we highlight recent applications of machine learning to generate protein sequences, focusing on the emerging field of deep generative methods.

</p>
</details>

<details><summary><b>Relating Adversarially Robust Generalization to Flat Minima</b>
<a href="https://arxiv.org/abs/2104.04448">arxiv:2104.04448</a>
&#x1F4C8; 9 <br>
<p>David Stutz, Matthias Hein, Bernt Schiele</p></summary>
<p>

**Abstract:** Adversarial training (AT) has become the de-facto standard to obtain models robust against adversarial examples. However, AT exhibits severe robust overfitting: cross-entropy loss on adversarial examples, so-called robust loss, decreases continuously on training examples, while eventually increasing on test examples. In practice, this leads to poor robust generalization, i.e., adversarial robustness does not generalize well to new examples. In this paper, we study the relationship between robust generalization and flatness of the robust loss landscape in weight space, i.e., whether robust loss changes significantly when perturbing weights. To this end, we propose average- and worst-case metrics to measure flatness in the robust loss landscape and show a correlation between good robust generalization and flatness. For example, throughout training, flatness reduces significantly during overfitting such that early stopping effectively finds flatter minima in the robust loss landscape. Similarly, AT variants achieving higher adversarial robustness also correspond to flatter minima. This holds for many popular choices, e.g., AT-AWP, TRADES, MART, AT with self-supervision or additional unlabeled examples, as well as simple regularization techniques, e.g., AutoAugment, weight decay or label noise. For fair comparison across these approaches, our flatness measures are specifically designed to be scale-invariant and we conduct extensive experiments to validate our findings.

</p>
</details>

<details><summary><b>SI-Score: An image dataset for fine-grained analysis of robustness to object location, rotation and size</b>
<a href="https://arxiv.org/abs/2104.04191">arxiv:2104.04191</a>
&#x1F4C8; 9 <br>
<p>Jessica Yung, Rob Romijnders, Alexander Kolesnikov, Lucas Beyer, Josip Djolonga, Neil Houlsby, Sylvain Gelly, Mario Lucic, Xiaohua Zhai</p></summary>
<p>

**Abstract:** Before deploying machine learning models it is critical to assess their robustness. In the context of deep neural networks for image understanding, changing the object location, rotation and size may affect the predictions in non-trivial ways. In this work we perform a fine-grained analysis of robustness with respect to these factors of variation using SI-Score, a synthetic dataset. In particular, we investigate ResNets, Vision Transformers and CLIP, and identify interesting qualitative differences between these.

</p>
</details>

<details><summary><b>Language model fusion for streaming end to end speech recognition</b>
<a href="https://arxiv.org/abs/2104.04487">arxiv:2104.04487</a>
&#x1F4C8; 8 <br>
<p>Rodrigo Cabrera, Xiaofeng Liu, Mohammadreza Ghodsi, Zebulun Matteson, Eugene Weinstein, Anjuli Kannan</p></summary>
<p>

**Abstract:** Streaming processing of speech audio is required for many contemporary practical speech recognition tasks. Even with the large corpora of manually transcribed speech data available today, it is impossible for such corpora to cover adequately the long tail of linguistic content that's important for tasks such as open-ended dictation and voice search. We seek to address both the streaming and the tail recognition challenges by using a language model (LM) trained on unpaired text data to enhance the end-to-end (E2E) model. We extend shallow fusion and cold fusion approaches to streaming Recurrent Neural Network Transducer (RNNT), and also propose two new competitive fusion approaches that further enhance the RNNT architecture. Our results on multiple languages with varying training set sizes show that these fusion methods improve streaming RNNT performance through introducing extra linguistic features. Cold fusion works consistently better on streaming RNNT with up to a 8.5% WER improvement.

</p>
</details>

<details><summary><b>Adapting Language Models for Zero-shot Learning by Meta-tuning on Dataset and Prompt Collections</b>
<a href="https://arxiv.org/abs/2104.04670">arxiv:2104.04670</a>
&#x1F4C8; 7 <br>
<p>Ruiqi Zhong, Kristy Lee, Zheng Zhang, Dan Klein</p></summary>
<p>

**Abstract:** Large pre-trained language models (LMs) such as GPT-3 have acquired a surprising ability to perform zero-shot learning. For example, to classify sentiment without any training examples, we can "prompt" the LM with the review and the label description "Does the user like this movie?", and ask whether the next word is "yes" or "no". However, the next word prediction training objective is still misaligned with the target zero-shot learning objective. To address this weakness, we propose meta-tuning, which directly optimizes the zero-shot learning objective by fine-tuning pre-trained language models on a collection of datasets. We focus on classification tasks, and construct the meta-dataset by aggregating 43 existing datasets and annotating 441 label descriptions in a question-answering (QA) format. When evaluated on unseen tasks, meta-tuned models outperform a same-sized QA model and the previous SOTA zero-shot learning system based on natural language inference. Additionally, increasing parameter count from 220M to 770M improves AUC-ROC scores by 6.3%, and we forecast that even larger models would perform better. Therefore, measuring zero-shot learning performance on language models out-of-the-box might underestimate their true potential, and community-wide efforts on aggregating datasets and unifying their formats can help build models that answer prompts better.

</p>
</details>

<details><summary><b>Transforming Feature Space to Interpret Machine Learning Models</b>
<a href="https://arxiv.org/abs/2104.04295">arxiv:2104.04295</a>
&#x1F4C8; 7 <br>
<p>Alexander Brenning</p></summary>
<p>

**Abstract:** Model-agnostic tools for interpreting machine-learning models struggle to summarize the joint effects of strongly dependent features in high-dimensional feature spaces, which play an important role in pattern recognition, for example in remote sensing of landcover. This contribution proposes a novel approach that interprets machine-learning models through the lens of feature space transformations. It can be used to enhance unconditional as well as conditional post-hoc diagnostic tools including partial dependence plots, accumulated local effects plots, or permutation feature importance assessments. While the approach can also be applied to nonlinear transformations, we focus on linear ones, including principal component analysis (PCA) and a partial orthogonalization technique. Structured PCA and diagnostics along paths offer opportunities for representing domain knowledge. The new approach is implemented in the R package `wiml`, which can be combined with existing explainable machine-learning packages. A case study on remote-sensing landcover classification with 46 features is used to demonstrate the potential of the proposed approach for model interpretation by domain experts.

</p>
</details>

<details><summary><b>Deep Learning Identifies Neuroimaging Signatures of Alzheimer's Disease Using Structural and Synthesized Functional MRI Data</b>
<a href="https://arxiv.org/abs/2104.04672">arxiv:2104.04672</a>
&#x1F4C8; 6 <br>
<p>Nanyan Zhu, Chen Liu, Xinyang Feng, Dipika Sikka, Sabrina Gjerswold-Selleck, Scott A. Small, Jia Guo</p></summary>
<p>

**Abstract:** Current neuroimaging techniques provide paths to investigate the structure and function of the brain in vivo and have made great advances in understanding Alzheimer's disease (AD). However, the group-level analyses prevalently used for investigation and understanding of the disease are not applicable for diagnosis of individuals. More recently, deep learning, which can efficiently analyze large-scale complex patterns in 3D brain images, has helped pave the way for computer-aided individual diagnosis by providing accurate and automated disease classification. Great progress has been made in classifying AD with deep learning models developed upon increasingly available structural MRI data. The lack of scale-matched functional neuroimaging data prevents such models from being further improved by observing functional changes in pathophysiology. Here we propose a potential solution by first learning a structural-to-functional transformation in brain MRI, and further synthesizing spatially matched functional images from large-scale structural scans. We evaluated our approach by building computational models to discriminate patients with AD from healthy normal subjects and demonstrated a performance boost after combining the structural and synthesized functional brain images into the same model. Furthermore, our regional analyses identified the temporal lobe to be the most predictive structural-region and the parieto-occipital lobe to be the most predictive functional-region of our model, which are both in concordance with previous group-level neuroimaging findings. Together, we demonstrate the potential of deep learning with large-scale structural and synthesized functional MRI to impact AD classification and to identify AD's neuroimaging signatures.

</p>
</details>

<details><summary><b>Model LineUpper: Supporting Interactive Model Comparison at Multiple Levels for AutoML</b>
<a href="https://arxiv.org/abs/2104.04375">arxiv:2104.04375</a>
&#x1F4C8; 6 <br>
<p>Shweta Narkar, Yunfeng Zhang, Q. Vera Liao, Dakuo Wang, Justin D Weisz</p></summary>
<p>

**Abstract:** Automated Machine Learning (AutoML) is a rapidly growing set of technologies that automate the model development pipeline by searching model space and generating candidate models. A critical, final step of AutoML is human selection of a final model from dozens of candidates. In current AutoML systems, selection is supported only by performance metrics. Prior work has shown that in practice, people evaluate ML models based on additional criteria, such as the way a model makes predictions. Comparison may happen at multiple levels, from types of errors, to feature importance, to how the model makes predictions of specific instances. We developed \tool{} to support interactive model comparison for AutoML by integrating multiple Explainable AI (XAI) and visualization techniques. We conducted a user study in which we both evaluated the system and used it as a technology probe to understand how users perform model comparison in an AutoML system. We discuss design implications for utilizing XAI techniques for model comparison and supporting the unique needs of data scientists in comparing AutoML models.

</p>
</details>

<details><summary><b>Unified Source-Filter GAN: Unified Source-filter Network Based On Factorization of Quasi-Periodic Parallel WaveGAN</b>
<a href="https://arxiv.org/abs/2104.04668">arxiv:2104.04668</a>
&#x1F4C8; 5 <br>
<p>Reo Yoneyama, Yi-Chiao Wu, Tomoki Toda</p></summary>
<p>

**Abstract:** We propose a unified approach to data-driven source-filter modeling using a single neural network for developing a neural vocoder capable of generating high-quality synthetic speech waveforms while retaining flexibility of the source-filter model to control their voice characteristics. Our proposed network called unified source-filter generative adversarial networks (uSFGAN) is developed by factorizing quasi-periodic parallel WaveGAN (QPPWG), one of the neural vocoders based on a single neural network, into a source excitation generation network and a vocal tract resonance filtering network by additionally implementing a regularization loss. Moreover, inspired by neural source filter (NSF), only a sinusoidal waveform is additionally used as the simplest clue to generate a periodic source excitation waveform while minimizing the effect of approximations in the source filter model. The experimental results demonstrate that uSFGAN outperforms conventional neural vocoders, such as QPPWG and NSF in both speech quality and pitch controllability.

</p>
</details>

<details><summary><b>Probabilistic Box Embeddings for Uncertain Knowledge Graph Reasoning</b>
<a href="https://arxiv.org/abs/2104.04597">arxiv:2104.04597</a>
&#x1F4C8; 5 <br>
<p>Xuelu Chen, Michael Boratko, Muhao Chen, Shib Sankar Dasgupta, Xiang Lorraine Li, Andrew McCallum</p></summary>
<p>

**Abstract:** Knowledge bases often consist of facts which are harvested from a variety of sources, many of which are noisy and some of which conflict, resulting in a level of uncertainty for each triple. Knowledge bases are also often incomplete, prompting the use of embedding methods to generalize from known facts, however, existing embedding methods only model triple-level uncertainty, and reasoning results lack global consistency. To address these shortcomings, we propose BEUrRE, a novel uncertain knowledge graph embedding method with calibrated probabilistic semantics. BEUrRE models each entity as a box (i.e. axis-aligned hyperrectangle) and relations between two entities as affine transforms on the head and tail entity boxes. The geometry of the boxes allows for efficient calculation of intersections and volumes, endowing the model with calibrated probabilistic semantics and facilitating the incorporation of relational constraints. Extensive experiments on two benchmark datasets show that BEUrRE consistently outperforms baselines on confidence prediction and fact ranking due to its probabilistic calibration and ability to capture high-order dependencies among facts.

</p>
</details>

<details><summary><b>Chinese Character Decomposition for Neural MT with Multi-Word Expressions</b>
<a href="https://arxiv.org/abs/2104.04497">arxiv:2104.04497</a>
&#x1F4C8; 5 <br>
<p>Lifeng Han, Gareth J. F. Jones, Alan F. Smeaton, Paolo Bolzoni</p></summary>
<p>

**Abstract:** Chinese character decomposition has been used as a feature to enhance Machine Translation (MT) models, combining radicals into character and word level models. Recent work has investigated ideograph or stroke level embedding. However, questions remain about different decomposition levels of Chinese character representations, radical and strokes, best suited for MT. To investigate the impact of Chinese decomposition embedding in detail, i.e., radical, stroke, and intermediate levels, and how well these decompositions represent the meaning of the original character sequences, we carry out analysis with both automated and human evaluation of MT. Furthermore, we investigate if the combination of decomposed Multiword Expressions (MWEs) can enhance the model learning. MWE integration into MT has seen more than a decade of exploration. However, decomposed MWEs has not previously been explored.

</p>
</details>

<details><summary><b>Knowledge-Aware Graph-Enhanced GPT-2 for Dialogue State Tracking</b>
<a href="https://arxiv.org/abs/2104.04466">arxiv:2104.04466</a>
&#x1F4C8; 5 <br>
<p>Weizhe Lin, Bo-Hsiang Tseng, Bill Byrne</p></summary>
<p>

**Abstract:** Dialogue State Tracking is central to multi-domain task-oriented dialogue systems, responsible for extracting information from user utterances. We present a novel hybrid architecture that augments GPT-2 with representations derived from Graph Attention Networks in such a way to allow causal, sequential prediction of slot values. The model architecture captures inter-slot relationships and dependencies across domains that otherwise can be lost in sequential prediction. We report improvements in state tracking performance in MultiWOZ 2.0 against a strong GPT-2 baseline and investigate a simplified sparse training scenario in which DST models are trained only on session-level annotations but evaluated at the turn level. We further report detailed analyses to demonstrate the effectiveness of graph models in DST by showing that the proposed graph modules capture inter-slot dependencies and improve the predictions of values that are common to multiple domains.

</p>
</details>

<details><summary><b>Unsupervised Class-Incremental Learning Through Confusion</b>
<a href="https://arxiv.org/abs/2104.04450">arxiv:2104.04450</a>
&#x1F4C8; 5 <br>
<p>Shivam Khare, Kun Cao, James Rehg</p></summary>
<p>

**Abstract:** While many works on Continual Learning have shown promising results for mitigating catastrophic forgetting, they have relied on supervised training. To successfully learn in a label-agnostic incremental setting, a model must distinguish between learned and novel classes to properly include samples for training. We introduce a novelty detection method that leverages network confusion caused by training incoming data as a new class. We found that incorporating a class-imbalance during this detection method substantially enhances performance. The effectiveness of our approach is demonstrated across a set of image classification benchmarks: MNIST, SVHN, CIFAR-10, CIFAR-100, and CRIB.

</p>
</details>

<details><summary><b>Towards Fine-grained Visual Representations by Combining Contrastive Learning with Image Reconstruction and Attention-weighted Pooling</b>
<a href="https://arxiv.org/abs/2104.04323">arxiv:2104.04323</a>
&#x1F4C8; 5 <br>
<p>Jonas Dippel, Steffen Vogler, Johannes Höhne</p></summary>
<p>

**Abstract:** This paper presents Contrastive Reconstruction, ConRec - a self-supervised learning algorithm that obtains image representations by jointly optimizing a contrastive and a self-reconstruction loss. We showcase that state-of-the-art contrastive learning methods (e.g. SimCLR) have shortcomings to capture fine-grained visual features in their representations. ConRec extends the SimCLR framework by adding (1) a self-reconstruction task and (2) an attention mechanism within the contrastive learning task. This is accomplished by applying a simple encoder-decoder architecture with two heads. We show that both extensions contribute towards an improved vector representation for images with fine-grained visual features. Combining those concepts, ConRec outperforms SimCLR and SimCLR with Attention-Pooling on fine-grained classification datasets.

</p>
</details>

<details><summary><b>TransWiC at SemEval-2021 Task 2: Transformer-based Multilingual and Cross-lingual Word-in-Context Disambiguation</b>
<a href="https://arxiv.org/abs/2104.04632">arxiv:2104.04632</a>
&#x1F4C8; 4 <br>
<p>Hansi Hettiarachchi, Tharindu Ranasinghe</p></summary>
<p>

**Abstract:** Identifying whether a word carries the same meaning or different meaning in two contexts is an important research area in natural language processing which plays a significant role in many applications such as question answering, document summarisation, information retrieval and information extraction. Most of the previous work in this area rely on language-specific resources making it difficult to generalise across languages. Considering this limitation, our approach to SemEval-2021 Task 2 is based only on pretrained transformer models and does not use any language-specific processing and resources. Despite that, our best model achieves 0.90 accuracy for English-English subtask which is very compatible compared to the best result of the subtask; 0.93 accuracy. Our approach also achieves satisfactory results in other monolingual and cross-lingual language pairs as well.

</p>
</details>

<details><summary><b>Smart and Secure CAV Networks Empowered by AI-Enabled Blockchain: Next Frontier for Intelligent Safe-Driving Assessment</b>
<a href="https://arxiv.org/abs/2104.04572">arxiv:2104.04572</a>
&#x1F4C8; 4 <br>
<p>Le Xia, Yao Sun, Rafiq Swash, Lina Mohjazi, Lei Zhang, Muhammad Ali Imran</p></summary>
<p>

**Abstract:** Securing safe-driving for connected and autonomous vehicles (CAVs) continues to be a widespread concern despite various sophisticated functions delivered by artificial intelligence for in-vehicle devices. Besides, diverse malicious network attacks become ubiquitous along with the worldwide implementation of the Internet of Vehicles, which exposes a range of reliability and privacy threats for managing data in CAV networks. Combined with the fact that the capability of existing CAVs in handling intensive computation tasks is limited, this implies a need for designing an efficient assessment system to guarantee autonomous driving safety without compromising data security. Motivated by this, in this article, we propose a novel framework, namely Blockchain-enabled intElligent Safe-driving assessmenT (BEST), that offers a smart and reliable approach for conducting safe driving supervision while protecting vehicular information. Specifically, a promising solution that exploits a long short-term memory model is introduced to assess the safety level of the moving CAVs. Then, we investigate how a distributed blockchain obtains adequate trustworthiness and robustness for CAV data by adopting a byzantine fault tolerance-based delegated proof-of-stake consensus mechanism. Simulation results demonstrate that our presented BEST gains better data credibility with a higher prediction accuracy for vehicular safety assessment when compared with existing schemes. Finally, we discuss several open challenges that need to be addressed in future CAV networks.

</p>
</details>

<details><summary><b>Assessing the Impact of COVID-19 on Trade: a Machine Learning Counterfactual Analysis</b>
<a href="https://arxiv.org/abs/2104.04570">arxiv:2104.04570</a>
&#x1F4C8; 4 <br>
<p>Marco Dueñas, Víctor Ortiz, Massimo Riccaboni, Francesco Serti</p></summary>
<p>

**Abstract:** By interpreting exporters' dynamics as a complex learning process, this paper constitutes the first attempt to investigate the effectiveness of different Machine Learning (ML) techniques in predicting firms' trade status. We focus on the probability of Colombian firms surviving in the export market under two different scenarios: a COVID-19 setting and a non-COVID-19 counterfactual situation. By comparing the resulting predictions, we estimate the individual treatment effect of the COVID-19 shock on firms' outcomes. Finally, we use recursive partitioning methods to identify subgroups with differential treatment effects. We find that, besides the temporal dimension, the main factors predicting treatment heterogeneity are interactions between firm size and industry.

</p>
</details>

<details><summary><b>AdCOFE: Advanced Contextual Feature Extraction in Conversations for emotion classification</b>
<a href="https://arxiv.org/abs/2104.04517">arxiv:2104.04517</a>
&#x1F4C8; 4 <br>
<p>Vaibhav Bhat, Anita Yadav, Sonal Yadav, Dhivya Chandrasekaran, Vijay Mago</p></summary>
<p>

**Abstract:** Emotion recognition in conversations is an important step in various virtual chat bots which require opinion-based feedback, like in social media threads, online support and many more applications. Current Emotion recognition in conversations models face issues like (a) loss of contextual information in between two dialogues of a conversation, (b) failure to give appropriate importance to significant tokens in each utterance and (c) inability to pass on the emotional information from previous utterances.The proposed model of Advanced Contextual Feature Extraction (AdCOFE) addresses these issues by performing unique feature extraction using knowledge graphs, sentiment lexicons and phrases of natural language at all levels (word and position embedding) of the utterances. Experiments on the Emotion recognition in conversations dataset show that AdCOFE is beneficial in capturing emotions in conversations.

</p>
</details>

<details><summary><b>Context-self contrastive pretraining for crop type semantic segmentation</b>
<a href="https://arxiv.org/abs/2104.04310">arxiv:2104.04310</a>
&#x1F4C8; 4 <br>
<p>Michail Tarasiou, Riza Alp Guler, Stefanos Zafeiriou</p></summary>
<p>

**Abstract:** In this paper, we propose a fully supervised pre-training scheme based on contrastive learning particularly tailored to dense classification tasks. The proposed Context-Self Contrastive Loss (CSCL) learns an embedding space that makes semantic boundaries pop-up by use of a similarity metric between every location in a training sample and its local context. For crop type semantic segmentation from Satellite Image Time Series (SITS) we find performance at parcel boundaries to be a critical bottleneck and explain how CSCL tackles the underlying cause of that problem, improving the state-of-the-art performance in this task. Additionally, using images from the Sentinel-2 (S2) satellite missions we compile the largest, to our knowledge, SITS dataset densely annotated by crop type and parcel identities, which we make publicly available together with the data generation pipeline. Using that data we find CSCL, even with minimal pre-training, to improve all respective baselines and present a process for semantic segmentation at super-resolution for obtaining crop classes at a more granular level. The code and instructions to download the data can be found in https://github.com/michaeltrs/DeepSatModels.

</p>
</details>

<details><summary><b>Direct Differentiable Augmentation Search</b>
<a href="https://arxiv.org/abs/2104.04282">arxiv:2104.04282</a>
&#x1F4C8; 4 <br>
<p>Aoming Liu, Zehao Huang, Zhiwu Huang, Naiyan Wang</p></summary>
<p>

**Abstract:** Data augmentation has been an indispensable tool to improve the performance of deep neural networks, however the augmentation can hardly transfer among different tasks and datasets. Consequently, a recent trend is to adopt AutoML technique to learn proper augmentation policy without extensive hand-crafted tuning. In this paper, we propose an efficient differentiable search algorithm called Direct Differentiable Augmentation Search (DDAS). It exploits meta-learning with one-step gradient update and continuous relaxation to the expected training loss for efficient search. Our DDAS can achieve efficient augmentation search without relying on approximations such as Gumbel Softmax or second order gradient approximation. To further reduce the adverse effect of improper augmentations, we organize the search space into a two level hierarchy, in which we first decide whether to apply augmentation, and then determine the specific augmentation policy. On standard image classification benchmarks, our DDAS achieves state-of-the-art performance and efficiency tradeoff while reducing the search cost dramatically, e.g. 0.15 GPU hours for CIFAR-10. In addition, we also use DDAS to search augmentation for object detection task and achieve comparable performance with AutoAugment, while being 1000x faster.

</p>
</details>

<details><summary><b>Reversible Watermarking in Deep Convolutional Neural Networks for Integrity Authentication</b>
<a href="https://arxiv.org/abs/2104.04268">arxiv:2104.04268</a>
&#x1F4C8; 4 <br>
<p>Xiquan Guan, Huamin Feng, Weiming Zhang, Hang Zhou, Jie Zhang, Nenghai Yu</p></summary>
<p>

**Abstract:** Deep convolutional neural networks have made outstanding contributions in many fields such as computer vision in the past few years and many researchers published well-trained network for downloading. But recent studies have shown serious concerns about integrity due to model-reuse attacks and backdoor attacks. In order to protect these open-source networks, many algorithms have been proposed such as watermarking. However, these existing algorithms modify the contents of the network permanently and are not suitable for integrity authentication. In this paper, we propose a reversible watermarking algorithm for integrity authentication. Specifically, we present the reversible watermarking problem of deep convolutional neural networks and utilize the pruning theory of model compression technology to construct a host sequence used for embedding watermarking information by histogram shift. As shown in the experiments, the influence of embedding reversible watermarking on the classification performance is less than 0.5% and the parameters of the model can be fully recovered after extracting the watermarking. At the same time, the integrity of the model can be verified by applying the reversible watermarking: if the model is modified illegally, the authentication information generated by original model will be absolutely different from the extracted watermarking information.

</p>
</details>

<details><summary><b>A Framework for Ethical AI at the United Nations</b>
<a href="https://arxiv.org/abs/2104.12547">arxiv:2104.12547</a>
&#x1F4C8; 3 <br>
<p>Lambert Hogenhout</p></summary>
<p>

**Abstract:** This paper aims to provide an overview of the ethical concerns in artificial intelligence (AI) and the framework that is needed to mitigate those risks, and to suggest a practical path to ensure the development and use of AI at the United Nations (UN) aligns with our ethical values. The overview discusses how AI is an increasingly powerful tool with potential for good, albeit one with a high risk of negative side-effects that go against fundamental human rights and UN values. It explains the need for ethical principles for AI aligned with principles for data governance, as data and AI are tightly interwoven. It explores different ethical frameworks that exist and tools such as assessment lists. It recommends that the UN develop a framework consisting of ethical principles, architectural standards, assessment methods, tools and methodologies, and a policy to govern the implementation and adherence to this framework, accompanied by an education program for staff.

</p>
</details>

<details><summary><b>KI-BERT: Infusing Knowledge Context for Better Language and Domain Understanding</b>
<a href="https://arxiv.org/abs/2104.08145">arxiv:2104.08145</a>
&#x1F4C8; 3 <br>
<p>Keyur Faldu, Amit Sheth, Prashant Kikani, Hemang Akbari</p></summary>
<p>

**Abstract:** Contextualized entity representations learned by state-of-the-art transformer-based language models (TLMs) like BERT, GPT, T5, etc., leverage the attention mechanism to learn the data context from training data corpus. However, these models do not use the knowledge context. Knowledge context can be understood as semantics about entities and their relationship with neighboring entities in knowledge graphs. We propose a novel and effective technique to infuse knowledge context from multiple knowledge graphs for conceptual and ambiguous entities into TLMs during fine-tuning. It projects knowledge graph embeddings in the homogeneous vector-space, introduces new token-types for entities, aligns entity position ids, and a selective attention mechanism. We take BERT as a baseline model and implement the "Knowledge-Infused BERT" by infusing knowledge context from ConceptNet and WordNet, which significantly outperforms BERT and other recent knowledge-aware BERT variants like ERNIE, SenseBERT, and BERT_CS over eight different subtasks of GLUE benchmark. The KI-BERT-base model even significantly outperforms BERT-large for domain-specific tasks like SciTail and academic subsets of QQP, QNLI, and MNLI.

</p>
</details>

<details><summary><b>Exploration of Spanish Olive Oil Quality with a Miniaturized Low-Cost Fluorescence Sensor and Machine Learning Techniques</b>
<a href="https://arxiv.org/abs/2104.06310">arxiv:2104.06310</a>
&#x1F4C8; 3 <br>
<p>Francesca Venturini, Michela Sperti, Umberto Michelucci, Ivo Herzig, Michael Baumgartner, Josep Palau Caballero, Arturo Jimenez, and Marco Agostino Deriu</p></summary>
<p>

**Abstract:** Extra virgin olive oil (EVOO) is the highest quality of olive oil and is characterized by highly beneficial nutritional properties. The large increase in both consumption and fraud, for example through adulteration, creates new challenges and an increasing demand for developing new quality assessment methodologies that are easier and cheaper to perform. As of today, the determination of olive oil quality is performed by producers through chemical analysis and organoleptic evaluation. The chemical analysis requires the advanced equipment and chemical knowledge of certified laboratories, and has therefore a limited accessibility. In this work a minimalist, portable and low-cost sensor is presented, which can perform olive oil quality assessment using fluorescence spectroscopy. The potential of the proposed technology is explored by analyzing several olive oils of different quality levels, EVOO, virgin olive oil (VOO), and lampante olive oil (LOO). The spectral data were analyzed using a large number of machine learning methods, including artificial neural networks. The analysis performed in this work demonstrates the possibility of performing classification of olive oil in the three mentioned classes with an accuracy of 100$\%$. These results confirm that this minimalist low-cost sensor has the potential of substituting expensive and complex chemical analysis.

</p>
</details>

<details><summary><b>WLV-RIT at SemEval-2021 Task 5: A Neural Transformer Framework for Detecting Toxic Spans</b>
<a href="https://arxiv.org/abs/2104.04630">arxiv:2104.04630</a>
&#x1F4C8; 3 <br>
<p>Tharindu Ranasinghe, Diptanu Sarkar, Marcos Zampieri, Alexander Ororbia</p></summary>
<p>

**Abstract:** In recent years, the widespread use of social media has led to an increase in the generation of toxic and offensive content on online platforms. In response, social media platforms have worked on developing automatic detection methods and employing human moderators to cope with this deluge of offensive content. While various state-of-the-art statistical models have been applied to detect toxic posts, there are only a few studies that focus on detecting the words or expressions that make a post offensive. This motivates the organization of the SemEval-2021 Task 5: Toxic Spans Detection competition, which has provided participants with a dataset containing toxic spans annotation in English posts. In this paper, we present the WLV-RIT entry for the SemEval-2021 Task 5. Our best performing neural transformer model achieves an $0.68$ F1-Score. Furthermore, we develop an open-source framework for multilingual detection of offensive spans, i.e., MUDES, based on neural transformers that detect toxic spans in texts.

</p>
</details>

<details><summary><b>Accented Speech Recognition Inspired by Human Perception</b>
<a href="https://arxiv.org/abs/2104.04627">arxiv:2104.04627</a>
&#x1F4C8; 3 <br>
<p>Xiangyun Chu, Elizabeth Combs, Amber Wang, Michael Picheny</p></summary>
<p>

**Abstract:** While improvements have been made in automatic speech recognition performance over the last several years, machines continue to have significantly lower performance on accented speech than humans. In addition, the most significant improvements on accented speech primarily arise by overwhelming the problem with hundreds or even thousands of hours of data. Humans typically require much less data to adapt to a new accent. This paper explores methods that are inspired by human perception to evaluate possible performance improvements for recognition of accented speech, with a specific focus on recognizing speech with a novel accent relative to that of the training data. Our experiments are run on small, accessible datasets that are available to the research community. We explore four methodologies: pre-exposure to multiple accents, grapheme and phoneme-based pronunciations, dropout (to improve generalization to a novel accent), and the identification of the layers in the neural network that can specifically be associated with accent modeling. Our results indicate that methods based on human perception are promising in reducing WER and understanding how accented speech is modeled in neural networks for novel accents.

</p>
</details>

<details><summary><b>Deep Time Series Forecasting with Shape and Temporal Criteria</b>
<a href="https://arxiv.org/abs/2104.04610">arxiv:2104.04610</a>
&#x1F4C8; 3 <br>
<p>Vincent Le Guen, Nicolas Thome</p></summary>
<p>

**Abstract:** This paper addresses the problem of multi-step time series forecasting for non-stationary signals that can present sudden changes. Current state-of-the-art deep learning forecasting methods, often trained with variants of the MSE, lack the ability to provide sharp predictions in deterministic and probabilistic contexts. To handle these challenges, we propose to incorporate shape and temporal criteria in the training objective of deep models. We define shape and temporal similarities and dissimilarities, based on a smooth relaxation of Dynamic Time Warping (DTW) and Temporal Distortion Index (TDI), that enable to build differentiable loss functions and positive semi-definite (PSD) kernels. With these tools, we introduce DILATE (DIstortion Loss including shApe and TimE), a new objective for deterministic forecasting, that explicitly incorporates two terms supporting precise shape and temporal change detection. For probabilistic forecasting, we introduce STRIPE++ (Shape and Time diverRsIty in Probabilistic forEcasting), a framework for providing a set of sharp and diverse forecasts, where the structured shape and time diversity is enforced with a determinantal point process (DPP) diversity loss. Extensive experiments and ablations studies on synthetic and real-world datasets confirm the benefits of leveraging shape and time features in time series forecasting.

</p>
</details>

<details><summary><b>Text2Chart: A Multi-Staged Chart Generator from Natural Language Text</b>
<a href="https://arxiv.org/abs/2104.04584">arxiv:2104.04584</a>
&#x1F4C8; 3 <br>
<p>Md. Mahinur Rashid, Hasin Kawsar Jahan, Annysha Huzzat, Riyasaat Ahmed Rahul, Tamim Bin Zakir, Farhana Meem, Md. Saddam Hossain Mukta, Swakkhar Shatabda</p></summary>
<p>

**Abstract:** Generation of scientific visualization from analytical natural language text is a challenging task. In this paper, we propose Text2Chart, a multi-staged chart generator method. Text2Chart takes natural language text as input and produce visualization as two-dimensional charts. Text2Chart approaches the problem in three stages. Firstly, it identifies the axis elements of a chart from the given text known as x and y entities. Then it finds a mapping of x-entities with its corresponding y-entities. Next, it generates a chart type suitable for the given text: bar, line or pie. Combination of these three stages is capable of generating visualization from the given analytical text. We have also constructed a dataset for this problem. Experiments show that Text2Chart achieves best performances with BERT based encodings with LSTM models in the first stage to label x and y entities, Random Forest classifier for the mapping stage and fastText embedding with LSTM for the chart type prediction. In our experiments, all the stages show satisfactory results and effectiveness considering formation of charts from analytical text, achieving a commendable overall performance.

</p>
</details>

<details><summary><b>Uncovering commercial activity in informal cities</b>
<a href="https://arxiv.org/abs/2104.04545">arxiv:2104.04545</a>
&#x1F4C8; 3 <br>
<p>Daniel Straulino, Juan C. Saldarriaga, Jairo A. Gómez, Juan C. Duque, Neave O'Clery</p></summary>
<p>

**Abstract:** Knowledge of the spatial organisation of economic activity within a city is key to policy concerns. However, in developing cities with high levels of informality, this information is often unavailable. Recent progress in machine learning together with the availability of street imagery offers an affordable and easily automated solution. Here we propose an algorithm that can detect what we call 'visible firms' using street view imagery. Using Medellín, Colombia as a case study, we illustrate how this approach can be used to uncover previously unseen economic activity. Applying spatial analysis to our dataset we detect a polycentric structure with five distinct clusters located in both the established centre and peripheral areas. Comparing the density of visible and registered firms, we find that informal activity concentrates in poor but densely populated areas. Our findings highlight the large gap between what is captured in official data and the reality on the ground.

</p>
</details>

<details><summary><b>Rock Hunting With Martian Machine Vision</b>
<a href="https://arxiv.org/abs/2104.04359">arxiv:2104.04359</a>
&#x1F4C8; 3 <br>
<p>David Noever, Samantha E. Miller Noever</p></summary>
<p>

**Abstract:** The Mars Perseverance rover applies computer vision for navigation and hazard avoidance. The challenge to do onboard object recognition highlights the need for low-power, customized training, often including low-contrast backgrounds. We investigate deep learning methods for the classification and detection of Martian rocks. We report greater than 97% accuracy for binary classifications (rock vs. rover). We fine-tune a detector to render geo-located bounding boxes while counting rocks. For these models to run on microcontrollers, we shrink and quantize the neural networks' weights and demonstrate a low-power rock hunter with faster frame rates (1 frame per second) but lower accuracy (37%).

</p>
</details>

<details><summary><b>Brain Surface Reconstruction from MRI Images Based on Segmentation Networks Applying Signed Distance Maps</b>
<a href="https://arxiv.org/abs/2104.04291">arxiv:2104.04291</a>
&#x1F4C8; 3 <br>
<p>Heng Fang, Xi Yang, Taichi Kin, Takeo Igarashi</p></summary>
<p>

**Abstract:** Whole-brain surface extraction is an essential topic in medical imaging systems as it provides neurosurgeons with a broader view of surgical planning and abnormality detection. To solve the problem confronted in current deep learning skull stripping methods lacking prior shape information, we propose a new network architecture that incorporates knowledge of signed distance fields and introduce an additional Laplacian loss to ensure that the prediction results retain shape information. We validated our newly proposed method by conducting experiments on our brain magnetic resonance imaging dataset (111 patients). The evaluation results demonstrate that our approach achieves comparable dice scores and also reduces the Hausdorff distance and average symmetric surface distance, thus producing more stable and smooth brain isosurfaces.

</p>
</details>

<details><summary><b>MLF-SC: Incorporating multi-layer features to sparse coding for anomaly detection</b>
<a href="https://arxiv.org/abs/2104.04289">arxiv:2104.04289</a>
&#x1F4C8; 3 <br>
<p>Ryuji Imamura, Kohei Azuma, Atsushi Hanamoto, Atsunori Kanemura</p></summary>
<p>

**Abstract:** Anomalies in images occur in various scales from a small hole on a carpet to a large stain. However, anomaly detection based on sparse coding, one of the widely used anomaly detection methods, has an issue in dealing with anomalies that are out of the patch size employed to sparsely represent images. A large anomaly can be considered normal if seen in a small scale, but it is not easy to determine a single scale (patch size) that works well for all images. Then, we propose to incorporate multi-scale features to sparse coding and improve the performance of anomaly detection. The proposed method, multi-layer feature sparse coding (MLF-SC), employs a neural network for feature extraction, and feature maps from intermediate layers of the network are given to sparse coding, whereas the standard sparse-coding-based anomaly detection method directly works on given images. We show that MLF-SC outperforms state-of-the-art anomaly detection methods including those employing deep learning. Our target data are the texture categories of the MVTec Anomaly Detection (MVTec AD) dataset, which is a modern benchmark dataset consisting of images from the real world. Our idea can be a simple and practical option to deal with practical data.

</p>
</details>

<details><summary><b>Morpho-evolution with learning using a controller archive as an inheritance mechanism</b>
<a href="https://arxiv.org/abs/2104.04269">arxiv:2104.04269</a>
&#x1F4C8; 3 <br>
<p>Léni K. Le Goff, Edgar Buchanan, Emma Hart, Agoston E. Eiben, Wei Li, Matteo De Carlo, Alan F. Winfield, Matthew F. Hale, Robert Woolley, Mike Angus, Jon Timmis, Andy M. Tyrrell</p></summary>
<p>

**Abstract:** The joint optimisation of body-plan and control via evolutionary processes can be challenging in rich morphological spaces in which offspring can have body-plans that are very different from either of their parents. This causes a potential mismatch between the structure of an inherited controller and the new body. To address this, we propose a framework that combines an evolutionary algorithm to generate body-plans and a learning algorithm to optimise the parameters of a neural controller. The topology of this controller is created once the body-plan of each offspring body-plan is generated. The key novelty of the approach is to add an external archive for storing learned controllers that map to explicit `types' of robots (where this is defined with respect the features of the body-plan). By learning from a controller with an appropriate structure inherited from the archive, rather than from a randomly initialised one, we show that both the speed and magnitude of learning increases over time when compared to an approach that starts from scratch, using two tasks and three environments. The framework also provides new insights into the complex interactions between evolution and learning.

</p>
</details>

<details><summary><b>How rotational invariance of common kernels prevents generalization in high dimensions</b>
<a href="https://arxiv.org/abs/2104.04244">arxiv:2104.04244</a>
&#x1F4C8; 3 <br>
<p>Konstantin Donhauser, Mingqi Wu, Fanny Yang</p></summary>
<p>

**Abstract:** Kernel ridge regression is well-known to achieve minimax optimal rates in low-dimensional settings. However, its behavior in high dimensions is much less understood. Recent work establishes consistency for kernel regression under certain assumptions on the ground truth function and the distribution of the input data. In this paper, we show that the rotational invariance property of commonly studied kernels (such as RBF, inner product kernels and fully-connected NTK of any depth) induces a bias towards low-degree polynomials in high dimensions. Our result implies a lower bound on the generalization error for a wide range of distributions and various choices of the scaling for kernels with different eigenvalue decays. This lower bound suggests that general consistency results for kernel ridge regression in high dimensions require a more refined analysis that depends on the structure of the kernel beyond its eigenvalue decay.

</p>
</details>

<details><summary><b>Assessment of the influence of features on a classification problem: an application to COVID-19 patients</b>
<a href="https://arxiv.org/abs/2104.14958">arxiv:2104.14958</a>
&#x1F4C8; 2 <br>
<p>L. Davila-Pena, Ignacio García-Jurado, B. Casas-Méndez</p></summary>
<p>

**Abstract:** This paper deals with an important subject in classification problems addressed by machine learning techniques: the evaluation of the influence of each of the features on the classification of individuals. Specifically, a measure of that influence is introduced using the Shapley value of cooperative games. In addition, an axiomatic characterisation of the proposed measure is provided based on properties of efficiency and balanced contributions. Furthermore, some experiments have been designed in order to validate the appropriate performance of such measure. Finally, the methodology introduced is applied to a sample of COVID-19 patients to study the influence of certain demographic or risk factors on various events of interest related to the evolution of the disease.

</p>
</details>

<details><summary><b>Trusting small training dataset for supervised change detection</b>
<a href="https://arxiv.org/abs/2104.05443">arxiv:2104.05443</a>
&#x1F4C8; 2 <br>
<p>Sudipan Saha, Biplab Banerjee, Xiao Xiang Zhu</p></summary>
<p>

**Abstract:** Deep learning (DL) based supervised change detection (CD) models require large labeled training data. Due to the difficulty of collecting labeled multi-temporal data, unsupervised methods are preferred in the CD literature. However, unsupervised methods cannot fully exploit the potentials of data-driven deep learning and thus they are not absolute alternative to the supervised methods. This motivates us to look deeper into the supervised DL methods and investigate how they can be adopted intelligently for CD by minimizing the requirement of labeled training data. Towards this, in this work we show that geographically diverse training dataset can yield significant improvement over less diverse training datasets of the same size. We propose a simple confidence indicator for verifying the trustworthiness/confidence of supervised models trained with small labeled dataset. Moreover, we show that for the test cases where supervised CD model is found to be less confident/trustworthy, unsupervised methods often produce better result than the supervised ones.

</p>
</details>

<details><summary><b>Out-of-distribution detection in satellite image classification</b>
<a href="https://arxiv.org/abs/2104.05442">arxiv:2104.05442</a>
&#x1F4C8; 2 <br>
<p>Jakob Gawlikowski, Sudipan Saha, Anna Kruspe, Xiao Xiang Zhu</p></summary>
<p>

**Abstract:** In satellite image analysis, distributional mismatch between the training and test data may arise due to several reasons, including unseen classes in the test data and differences in the geographic area. Deep learning based models may behave in unexpected manner when subjected to test data that has such distributional shifts from the training data, also called out-of-distribution (OOD) examples. Predictive uncertainly analysis is an emerging research topic which has not been explored much in context of satellite image analysis. Towards this, we adopt a Dirichlet Prior Network based model to quantify distributional uncertainty of deep learning models for remote sensing. The approach seeks to maximize the representation gap between the in-domain and OOD examples for a better identification of unknown examples at test time. Experimental results on three exemplary test scenarios show the efficacy of the model in satellite image analysis.

</p>
</details>

<details><summary><b>Approximate Bayesian Computation of Bézier Simplices</b>
<a href="https://arxiv.org/abs/2104.04679">arxiv:2104.04679</a>
&#x1F4C8; 2 <br>
<p>Akinori Tanaka, Akiyoshi Sannai, Ken Kobayashi, Naoki Hamada</p></summary>
<p>

**Abstract:** Bézier simplex fitting algorithms have been recently proposed to approximate the Pareto set/front of multi-objective continuous optimization problems. These new methods have shown to be successful at approximating various shapes of Pareto sets/fronts when sample points exactly lie on the Pareto set/front. However, if the sample points scatter away from the Pareto set/front, those methods often likely suffer from over-fitting. To overcome this issue, in this paper, we extend the Bézier simplex model to a probabilistic one and propose a new learning algorithm of it, which falls into the framework of approximate Bayesian computation (ABC) based on the Wasserstein distance. We also study the convergence property of the Wasserstein ABC algorithm. An extensive experimental evaluation on publicly available problem instances shows that the new algorithm converges on a finite sample. Moreover, it outperforms the deterministic fitting methods on noisy instances.

</p>
</details>

<details><summary><b>On Universal Black-Box Domain Adaptation</b>
<a href="https://arxiv.org/abs/2104.04665">arxiv:2104.04665</a>
&#x1F4C8; 2 <br>
<p>Bin Deng, Yabin Zhang, Hui Tang, Changxing Ding, Kui Jia</p></summary>
<p>

**Abstract:** In this paper, we study an arguably least restrictive setting of domain adaptation in a sense of practical deployment, where only the interface of source model is available to the target domain, and where the label-space relations between the two domains are allowed to be different and unknown. We term such a setting as Universal Black-Box Domain Adaptation (UB$^2$DA). The great promise that UB$^2$DA makes, however, brings significant learning challenges, since domain adaptation can only rely on the predictions of unlabeled target data in a partially overlapped label space, by accessing the interface of source model. To tackle the challenges, we first note that the learning task can be converted as two subtasks of in-class\footnote{In this paper we use in-class (out-class) to describe the classes observed (not observed) in the source black-box model.} discrimination and out-class detection, which can be respectively learned by model distillation and entropy separation. We propose to unify them into a self-training framework, regularized by consistency of predictions in local neighborhoods of target samples. Our framework is simple, robust, and easy to be optimized. Experiments on domain adaptation benchmarks show its efficacy. Notably, by accessing the interface of source model only, our framework outperforms existing methods of universal domain adaptation that make use of source data and/or source models, with a newly proposed (and arguably more reasonable) metric of H-score, and performs on par with them with the metric of averaged class accuracy.

</p>
</details>

<details><summary><b>Towards Automated and Marker-less Parkinson Disease Assessment: Predicting UPDRS Scores using Sit-stand videos</b>
<a href="https://arxiv.org/abs/2104.04650">arxiv:2104.04650</a>
&#x1F4C8; 2 <br>
<p>Deval Mehta, Umar Asif, Tian Hao, Erhan Bilal, Stefan Von Cavallar, Stefan Harrer, Jeffrey Rogers</p></summary>
<p>

**Abstract:** This paper presents a novel deep learning enabled, video based analysis framework for assessing the Unified Parkinsons Disease Rating Scale (UPDRS) that can be used in the clinic or at home. We report results from comparing the performance of the framework to that of trained clinicians on a population of 32 Parkinsons disease (PD) patients. In-person clinical assessments by trained neurologists are used as the ground truth for training our framework and for comparing the performance. We find that the standard sit-to-stand activity can be used to evaluate the UPDRS sub-scores of bradykinesia (BRADY) and posture instability and gait disorders (PIGD). For BRADY we find F1-scores of 0.75 using our framework compared to 0.50 for the video based rater clinicians, while for PIGD we find 0.78 for the framework and 0.45 for the video based rater clinicians. We believe our proposed framework has potential to provide clinically acceptable end points of PD in greater granularity without imposing burdens on patients and clinicians, which empowers a variety of use cases such as passive tracking of PD progression in spaces such as nursing homes, in-home self-assessment, and enhanced tele-medicine.

</p>
</details>

<details><summary><b>One-class Autoencoder Approach for Optimal Electrode Set-up Identification in Wearable EEG Event Monitoring</b>
<a href="https://arxiv.org/abs/2104.04546">arxiv:2104.04546</a>
&#x1F4C8; 2 <br>
<p>Laura M. Ferrari, Guy Abi Hanna, Paolo Volpe, Esma Ismailova, François Bremond, Maria A. Zuluaga</p></summary>
<p>

**Abstract:** A limiting factor towards the wide routine use of wearables devices for continuous healthcare monitoring is their cumbersome and obtrusive nature. This is particularly true for electroencephalography (EEG) recordings, which require the placement of multiple electrodes in contact with the scalp. In this work, we propose to identify the optimal wearable EEG electrode set-up, in terms of minimal number of electrodes, comfortable location and performance, for EEG-based event detection and monitoring. By relying on the demonstrated power of autoencoder (AE) networks to learn latent representations from high-dimensional data, our proposed strategy trains an AE architecture in a one-class classification setup with different electrode set-ups as input data. The resulting models are assessed using the F-score and the best set-up is chosen according to the established optimal criteria. Using alpha wave detection as use case, we demonstrate that the proposed method allows to detect an alpha state from an optimal set-up consisting of electrodes in the forehead and behind the ear, with an average F-score of 0.78. Our results suggest that a learning-based approach can be used to enable the design and implementation of optimized wearable devices for real-life healthcare monitoring.

</p>
</details>

<details><summary><b>Behavior-Guided Actor-Critic: Improving Exploration via Learning Policy Behavior Representation for Deep Reinforcement Learning</b>
<a href="https://arxiv.org/abs/2104.04424">arxiv:2104.04424</a>
&#x1F4C8; 2 <br>
<p>Ammar Fayad, Majd Ibrahim</p></summary>
<p>

**Abstract:** In this work, we propose Behavior-Guided Actor-Critic (BAC), an off-policy actor-critic deep RL algorithm. BAC mathematically formulates the behavior of the policy through autoencoders by providing an accurate estimation of how frequently each state-action pair was visited while taking into consideration state dynamics that play a crucial role in determining the trajectories produced by the policy. The agent is encouraged to change its behavior consistently towards less-visited state-action pairs while attaining good performance by maximizing the expected discounted sum of rewards, resulting in an efficient exploration of the environment and good exploitation of all high reward regions. One prominent aspect of our approach is that it is applicable to both stochastic and deterministic actors in contrast to maximum entropy deep reinforcement learning algorithms. Results show considerably better performances of BAC when compared to several cutting-edge learning algorithms.

</p>
</details>

<details><summary><b>Implementing Fair Regression In The Real World</b>
<a href="https://arxiv.org/abs/2104.04353">arxiv:2104.04353</a>
&#x1F4C8; 2 <br>
<p>Boris Ruf, Marcin Detyniecki</p></summary>
<p>

**Abstract:** Most fair regression algorithms mitigate bias towards sensitive sub populations and therefore improve fairness at group level. In this paper, we investigate the impact of such implementation of fair regression on the individual. More precisely, we assess the evolution of continuous predictions from an unconstrained to a fair algorithm by comparing results from baseline algorithms with fair regression algorithms for the same data points. Based on our findings, we propose a set of post-processing algorithms to improve the utility of the existing fair regression approaches.

</p>
</details>

<details><summary><b>Distributed Bayesian Online Learning for Cooperative Manipulation</b>
<a href="https://arxiv.org/abs/2104.04342">arxiv:2104.04342</a>
&#x1F4C8; 2 <br>
<p>Pablo Budde gen. Dohmann, Armin Lederer, Marcel Dißemond, Sandra Hirche</p></summary>
<p>

**Abstract:** For tasks where the dynamics of multiple agents are physically coupled, e.g., in cooperative manipulation, the coordination between the individual agents becomes crucial, which requires exact knowledge of the interaction dynamics. This problem is typically addressed using centralized estimators, which can negatively impact the flexibility and robustness of the overall system. To overcome this shortcoming, we propose a novel distributed learning framework for the exemplary task of cooperative manipulation using Bayesian principles. Using only local state information each agent obtains an estimate of the object dynamics and grasp kinematics. These local estimates are combined using dynamic average consensus. Due to the strong probabilistic foundation of the method, each estimate of the object dynamics and grasp kinematics is accompanied by a measure of uncertainty, which allows to guarantee a bounded prediction error with high probability. Moreover, the Bayesian principles directly allow iterative learning with constant complexity, such that the proposed learning method can be used online in real-time applications. The effectiveness of the approach is demonstrated in a simulated cooperative manipulation task.

</p>
</details>

<details><summary><b>A Riemannian smoothing steepest descent method for non-Lipschitz optimization on submanifolds</b>
<a href="https://arxiv.org/abs/2104.04199">arxiv:2104.04199</a>
&#x1F4C8; 2 <br>
<p>Chao Zhang, Xiaojun Chen, Shiqian Ma</p></summary>
<p>

**Abstract:** In this paper, we propose a Riemannian smoothing steepest descent method to minimize a nonconvex and non-Lipschitz function on submanifolds. The generalized subdifferentials on Riemannian manifold and the Riemannian gradient sub-consistency are defined and discussed. We prove that any accumulation point of the sequence generated by the Riemannian smoothing steepest descent method is a stationary point associated with the smoothing function employed in the method, which is necessary for the local optimality of the original non-Lipschitz problem. Under the Riemannian gradient sub-consistency condition, we also prove that any accumulation point is a Riemannian limiting stationary point of the original non-Lipschitz problem. Numerical experiments are conducted to demonstrate the efficiency of the proposed method.

</p>
</details>

<details><summary><b>BERT-based Chinese Text Classification for Emergency Domain with a Novel Loss Function</b>
<a href="https://arxiv.org/abs/2104.04197">arxiv:2104.04197</a>
&#x1F4C8; 2 <br>
<p>Zhongju Wang, Long Wang, Chao Huang, Xiong Luo</p></summary>
<p>

**Abstract:** This paper proposes an automatic Chinese text categorization method for solving the emergency event report classification problem. Since bidirectional encoder representations from transformers (BERT) has achieved great success in natural language processing domain, it is employed to derive emergency text features in this study. To overcome the data imbalance problem in the distribution of emergency event categories, a novel loss function is proposed to improve the performance of the BERT-based model. Meanwhile, to avoid the impact of the extreme learning rate, the Adabound optimization algorithm that achieves a gradual smooth transition from Adam to SGD is employed to learn parameters of the model. To verify the feasibility and effectiveness of the proposed method, a Chinese emergency text dataset collected from the Internet is employed. Compared with benchmarking methods, the proposed method has achieved the best performance in terms of accuracy, weighted-precision, weighted-recall, and weighted-F1 values. Therefore, it is promising to employ the proposed method for real applications in smart emergency management systems.

</p>
</details>

<details><summary><b>Speech based Depression Severity Level Classification Using a Multi-Stage Dilated CNN-LSTM Model</b>
<a href="https://arxiv.org/abs/2104.04195">arxiv:2104.04195</a>
&#x1F4C8; 2 <br>
<p>Nadee Seneviratne, Carol Espy-Wilson</p></summary>
<p>

**Abstract:** Speech based depression classification has gained immense popularity over the recent years. However, most of the classification studies have focused on binary classification to distinguish depressed subjects from non-depressed subjects. In this paper, we formulate the depression classification task as a severity level classification problem to provide more granularity to the classification outcomes. We use articulatory coordination features (ACFs) developed to capture the changes of neuromotor coordination that happens as a result of psychomotor slowing, a necessary feature of Major Depressive Disorder. The ACFs derived from the vocal tract variables (TVs) are used to train a dilated Convolutional Neural Network based depression classification model to obtain segment-level predictions. Then, we propose a Recurrent Neural Network based approach to obtain session-level predictions from segment-level predictions. We show that strengths of the segment-wise classifier are amplified when a session-wise classifier is trained on embeddings obtained from it. The model trained on ACFs derived from TVs show relative improvement of 27.47% in Unweighted Average Recall (UAR) at the session-level classification task, compared to the ACFs derived from Mel Frequency Cepstral Coefficients (MFCCs).

</p>
</details>

<details><summary><b>INODE: Building an End-to-End Data Exploration System in Practice [Extended Vision]</b>
<a href="https://arxiv.org/abs/2104.04194">arxiv:2104.04194</a>
&#x1F4C8; 2 <br>
<p>Sihem Amer-Yahia, Georgia Koutrika, Frederic Bastian, Theofilos Belmpas, Martin Braschler, Ursin Brunner, Diego Calvanese, Maximilian Fabricius, Orest Gkini, Catherine Kosten, Davide Lanti, Antonis Litke, Hendrik Lücke-Tieke, Francesco Alessandro Massucci, Tarcisio Mendes de Farias, Alessandro Mosca, Francesco Multari, Nikolaos Papadakis, Dimitris Papadopoulos, Yogendra Patil, Aurélien Personnaz, Guillem Rull, Ana Sima, Ellery Smith, Dimitrios Skoutas</p></summary>
<p>

**Abstract:** A full-fledged data exploration system must combine different access modalities with a powerful concept of guiding the user in the exploration process, by being reactive and anticipative both for data discovery and for data linking. Such systems are a real opportunity for our community to cater to users with different domain and data science expertise. We introduce INODE -- an end-to-end data exploration system -- that leverages, on the one hand, Machine Learning and, on the other hand, semantics for the purpose of Data Management (DM). Our vision is to develop a classic unified, comprehensive platform that provides extensive access to open datasets, and we demonstrate it in three significant use cases in the fields of Cancer Biomarker Reearch, Research and Innovation Policy Making, and Astrophysics. INODE offers sustainable services in (a) data modeling and linking, (b) integrated query processing using natural language, (c) guidance, and (d) data exploration through visualization, thus facilitating the user in discovering new insights. We demonstrate that our system is uniquely accessible to a wide range of users from larger scientific communities to the public. Finally, we briefly illustrate how this work paves the way for new research opportunities in DM.

</p>
</details>

<details><summary><b>Comprehensive systematic review into combinations of artificial intelligence, human factors, and automation</b>
<a href="https://arxiv.org/abs/2104.09233">arxiv:2104.09233</a>
&#x1F4C8; 1 <br>
<p>Reza Khani-Shekarab, Alireza khani-shekarab</p></summary>
<p>

**Abstract:** Artificial intelligence (AI)-based models used to improve different fields including healthcare, and finance. One of the field that receive advantages of AI is automation. However, it is important to consider human factors in application of AI in automation. This paper reports on a systematic review of the published studies used to investigate the application of AI in PM. This comprehensive systematic review used ScienceDirect to identify relevant articles. Of the 422 articles found, 40 met the inclusion and exclusion criteria and were used in the review. Selected articles were classified based on categories of human factors and areas of application. The results indicated that application of AI in automation with respect to human factors could be divided into three areas of physical ergonomics, cognitive ergonomic and organizational ergonomics. The main areas of application in physical and cognitive ergonomics are including transportation, User experience, and human-machine interactions.

</p>
</details>

<details><summary><b>SFE-Net: EEG-based Emotion Recognition with Symmetrical Spatial Feature Extraction</b>
<a href="https://arxiv.org/abs/2104.06308">arxiv:2104.06308</a>
&#x1F4C8; 1 <br>
<p>Xiangwen Deng, Junlin Zhu, Shangming Yang</p></summary>
<p>

**Abstract:** Emotion recognition based on EEG (electroencephalography) has been widely used in human-computer interaction, distance education and health care. However, the conventional methods ignore the adjacent and symmetrical characteristics of EEG signals, which also contain salient information related to emotion. In this paper, a spatial folding ensemble network (SFE-Net) is presented for EEG feature extraction and emotion recognition. Firstly, for the undetected area between EEG electrodes, an improved Bicubic-EEG interpolation algorithm is developed for EEG channels information completion, which allows us to extract a wider range of adjacent space features. Then, motivated by the spatial symmetric mechanism of human brain, we fold the input EEG channels data with five different symmetrical strategies, which enable the proposed network to extract the information of space features of EEG signals more effectively. Finally, a 3DCNN-based spatial, temporal extraction, and a multi-voting strategy of ensemble learning are integrated to model a new neural network. With this network, the spatial features of different symmetric folding signals can be extracted simultaneously, which greatly improves the robustness and accuracy of emotion recognition. The experimental results on DEAP and SEED datasets show that the proposed algorithm has comparable performance in terms of recognition accuracy.

</p>
</details>

<details><summary><b>Deep Transformer Networks for Time Series Classification: The NPP Safety Case</b>
<a href="https://arxiv.org/abs/2104.05448">arxiv:2104.05448</a>
&#x1F4C8; 1 <br>
<p>Bing Zha, Alessandro Vanni, Yassin Hassan, Tunc Aldemir, Alper Yilmaz</p></summary>
<p>

**Abstract:** A challenging part of dynamic probabilistic risk assessment for nuclear power plants is the need for large amounts of temporal simulations given various initiating events and branching conditions from which representative feature extraction becomes complicated for subsequent applications. Artificial Intelligence techniques have been shown to be powerful tools in time-dependent sequential data processing to automatically extract and yield complex features from large data. An advanced temporal neural network referred to as the Transformer is used within a supervised learning fashion to model the time-dependent NPP simulation data and to infer whether a given sequence of events leads to core damage or not. The training and testing datasets for the Transformer are obtained by running 10,000 RELAP5-3D NPP blackout simulations with the list of variables obtained from the RAVEN software. Each simulation is classified as "OK" or "CORE DAMAGE" based on the consequence. The results show that the Transformer can learn the characteristics of the sequential data and yield promising performance with approximately 99% classification accuracy on the testing dataset.

</p>
</details>

<details><summary><b>Auto-Validate: Unsupervised Data Validation Using Data-Domain Patterns Inferred from Data Lakes</b>
<a href="https://arxiv.org/abs/2104.04659">arxiv:2104.04659</a>
&#x1F4C8; 1 <br>
<p>Jie Song, Yeye He</p></summary>
<p>

**Abstract:** Complex data pipelines are increasingly common in diverse applications such as BI reporting and ML modeling. These pipelines often recur regularly (e.g., daily or weekly), as BI reports need to be refreshed, and ML models need to be retrained. However, it is widely reported that in complex production pipelines, upstream data feeds can change in unexpected ways, causing downstream applications to break silently that are expensive to resolve.
  Data validation has thus become an important topic, as evidenced by notable recent efforts from Google and Amazon, where the objective is to catch data quality issues early as they arise in the pipelines. Our experience on production data suggests, however, that on string-valued data, these existing approaches yield high false-positive rates and frequently require human intervention. In this work, we develop a corpus-driven approach to auto-validate \emph{machine-generated data} by inferring suitable data-validation "patterns" that accurately describe the underlying data domain, which minimizes false positives while maximizing data quality issues caught. Evaluations using production data from real data lakes suggest that Auto-Validate is substantially more effective than existing methods. Part of this technology ships as an Auto-Tag feature in Microsoft Azure Purview.

</p>
</details>

<details><summary><b>Coordinate descent heuristics for the irregular strip packing problem of rasterized shapes</b>
<a href="https://arxiv.org/abs/2104.04525">arxiv:2104.04525</a>
&#x1F4C8; 1 <br>
<p>Shunji Umetani, Shohei Murakami</p></summary>
<p>

**Abstract:** We consider the irregular strip packing problem of rasterized shapes, where a given set of pieces of irregular shapes represented in pixels should be placed into a rectangular container without overlap. The rasterized shapes enable us to check overlap without any exceptional handling due to geometric issues, while they often require much memory and computational effort in high-resolution. We develop an efficient algorithm to check overlap using a pair of scanlines that reduces the complexity of rasterized shapes by merging consecutive pixels in each row and column into strips with unit width, respectively. Based on this, we develop coordinate descent heuristics that repeat a line search in the horizontal and vertical directions alternately. Computational results for test instances show that the proposed algorithm obtains sufficiently dense layouts of rasterized shapes in high-resolution within a reasonable computation time.

</p>
</details>

<details><summary><b>The Effects of Air Quality on the Spread of the COVID-19 Pandemic in Italy: An Artificial Intelligence Approach</b>
<a href="https://arxiv.org/abs/2104.12546">arxiv:2104.12546</a>
&#x1F4C8; 0 <br>
<p>Andrea Loreggia, Anna Passarelli, Maria Silvia Pini</p></summary>
<p>

**Abstract:** The COVID-19 pandemic considerably affects public health systems around the world. The lack of knowledge about the virus, the extension of this phenomenon, and the speed of the evolution of the infection are all factors that highlight the necessity of employing new approaches to study these events. Artificial intelligence techniques may be useful in analyzing data related to areas affected by the virus. The aim of this work is to investigate any possible relationships between air quality and confirmed cases of COVID-19 in Italian districts. Specifically, we report an analysis of the correlation between daily COVID-19 cases and environmental factors, such as temperature, relative humidity, and atmospheric pollutants. Our analysis confirms a significant association of some environmental parameters with the spread of the virus. This suggests that machine learning models trained on the environmental parameters to predict the number of future infected cases may be accurate. Predictive models may be useful for helping institutions in making decisions for protecting the population and contrasting the pandemic.

</p>
</details>

<details><summary><b>Image Segmentation, Compression and Reconstruction from Edge Distribution Estimation with Random Field and Random Cluster Theories</b>
<a href="https://arxiv.org/abs/2104.10762">arxiv:2104.10762</a>
&#x1F4C8; 0 <br>
<p>Robert A. Murphy</p></summary>
<p>

**Abstract:** Random field and random cluster theory are used to describe certain mathematical results concerning the probability distribution of image pixel intensities characterized as generic $2D$ integer arrays. The size of the smallest bounded region within an image is estimated for segmenting an image, from which, the equilibrium distribution of intensities can be recovered. From the estimated bounded regions, properties of the sub-optimal and equilibrium distributions of intensities are derived, which leads to an image compression methodology whereby only slightly more than half of all pixels are required for a worst-case reconstruction of the original image. A custom deep belief network and heuristic allows for the unsupervised segmentation, detection and localization of objects in an image. An example illustrates the mathematical results.

</p>
</details>

<details><summary><b>Detecting False Data Injection Attacks in Smart Grids with Modeling Errors: A Deep Transfer Learning Based Approach</b>
<a href="https://arxiv.org/abs/2104.06307">arxiv:2104.06307</a>
&#x1F4C8; 0 <br>
<p>Bowen Xu, Fanghong Guo, Changyun Wen, Ruilong Deng, Wen-An Zhang</p></summary>
<p>

**Abstract:** Most traditional false data injection attack (FDIA) detection approaches rely on a key assumption, i.e., the power system can be accurately modeled. However, the transmission line parameters are dynamic and cannot be accurately known during operation and thus the involved modeling errors should not be neglected. In this paper, an illustrative case has revealed that modeling errors in transmission lines significantly weaken the detection effectiveness of conventional FDIA approaches. To tackle this issue, we propose an FDIA detection mechanism from the perspective of transfer learning. Specifically, the simulated power system is treated as a source domain, which provides abundant simulated normal and attack data. The real world's running system whose transmission line parameters are unknown is taken as a target domain where sufficient real normal data are collected for tracking the latest system states online. The designed transfer strategy that aims at making full use of data in hand is divided into two optimization stages. In the first stage, a deep neural network (DNN) is built by simultaneously optimizing several well-designed objective terms with both simulated data and real data, and then it is fine-tuned via real data in the second stage. Several case studies on the IEEE 14-bus and 118-bus systems verify the effectiveness of the proposed mechanism.

</p>
</details>

<details><summary><b>Chest X-Ray Bone Suppression for Improving Classification of Tuberculosis-Consistent Findings</b>
<a href="https://arxiv.org/abs/2104.04518">arxiv:2104.04518</a>
&#x1F4C8; 0 <br>
<p>Sivaramakrishnan Rajaraman, Ghada Zamzmi, Les Folio, Philip Alderson, Sameer Antani</p></summary>
<p>

**Abstract:** Chest X-rays are the most commonly performed diagnostic examination to detect cardiopulmonary abnormalities. However, the presence of bony structures such as ribs and clavicles can obscure subtle abnormalities, resulting in diagnostic errors. This study aims to build a deep learning-based bone suppression model that identifies and removes these occluding bony structures in frontal CXRs to assist in reducing errors in radiological interpretation, including DL workflows, related to detecting manifestations consistent with tuberculosis (TB). Several bone suppression models with various deep architectures are trained and optimized using the proposed combined loss function and their performances are evaluated in a cross-institutional test setting. The best-performing model is used to suppress bones in the publicly available Shenzhen and Montgomery TB CXR collections. A VGG-16 model is pretrained on a large collection of publicly available CXRs. The CXR-pretrained model is then fine-tuned individually on the non-bone-suppressed and bone-suppressed CXRs of Shenzhen and Montgomery TB CXR collections to classify them as showing normal lungs or TB manifestations. The performances of these models are compared using several performance metrics, analyzed for statistical significance, and their predictions are qualitatively interpreted through class-selective relevance maps. It is observed that the models trained on bone-suppressed CXRs significantly outperformed (p<0.05) the models trained on the non-bone-suppressed CXRs. Models trained on bone-suppressed CXRs improved detection of TB-consistent findings and resulted in compact clustering of the data points in the feature space signifying that bone suppression improved the model sensitivity toward TB classification.

</p>
</details>

<details><summary><b>On Architectures and Training for Raw Waveform Feature Extraction in ASR</b>
<a href="https://arxiv.org/abs/2104.04298">arxiv:2104.04298</a>
&#x1F4C8; 0 <br>
<p>Peter Vieting, Christoph Lüscher, Wilfried Michel, Ralf Schlüter, Hermann Ney</p></summary>
<p>

**Abstract:** With the success of neural network based modeling in automatic speech recognition (ASR), many studies investigated acoustic modeling and learning of feature extractors directly based on the raw waveform. Recently, one line of research has focused on unsupervised pre-training of feature extractors on audio-only data to improve downstream ASR performance. In this work, we investigate the usefulness of one of these front-end frameworks, namely wav2vec, in a setting without additional untranscribed data for hybrid ASR systems. We compare this framework both to the manually defined standard Gammatone feature set, as well as to features extracted as part of the acoustic model of an ASR system trained supervised. We study the benefits of using the pre-trained feature extractor and explore how to additionally exploit an existing acoustic model trained with different features. Finally, we systematically examine combinations of the described features in order to further advance the performance.

</p>
</details>


[Next Page](2021/2021-04/2021-04-08.md)
