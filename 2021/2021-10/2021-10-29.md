## Summary for 2021-10-29, created on 2021-12-14


<details><summary><b>Learning to Be Cautious</b>
<a href="https://arxiv.org/abs/2110.15907">arxiv:2110.15907</a>
&#x1F4C8; 3720 <br>
<p>Montaser Mohammedalamen, Dustin Morrill, Alexander Sieusahai, Yash Satsangi, Michael Bowling</p></summary>
<p>

**Abstract:** A key challenge in the field of reinforcement learning is to develop agents that behave cautiously in novel situations. It is generally impossible to anticipate all situations that an autonomous system may face or what behavior would best avoid bad outcomes. An agent that could learn to be cautious would overcome this challenge by discovering for itself when and how to behave cautiously. In contrast, current approaches typically embed task-specific safety information or explicit cautious behaviors into the system, which is error-prone and imposes extra burdens on practitioners. In this paper, we present both a sequence of tasks where cautious behavior becomes increasingly non-obvious, as well as an algorithm to demonstrate that it is possible for a system to \emph{learn} to be cautious. The essential features of our algorithm are that it characterizes reward function uncertainty without task-specific safety information and uses this uncertainty to construct a robust policy. Specifically, we construct robust policies with a $k$-of-$N$ counterfactual regret minimization (CFR) subroutine given a learned reward function uncertainty represented by a neural network ensemble belief. These policies exhibit caution in each of our tasks without any task-specific safety tuning.

</p>
</details>

<details><summary><b>MetaICL: Learning to Learn In Context</b>
<a href="https://arxiv.org/abs/2110.15943">arxiv:2110.15943</a>
&#x1F4C8; 219 <br>
<p>Sewon Min, Mike Lewis, Luke Zettlemoyer, Hannaneh Hajishirzi</p></summary>
<p>

**Abstract:** We introduce MetaICL (Meta-training for In-Context Learning), a new meta-training framework for few-shot learning where a pretrained language model is tuned to do in-context learn-ing on a large set of training tasks. This meta-training enables the model to more effectively learn a new task in context at test time, by simply conditioning on a few training examples with no parameter updates or task-specific templates. We experiment on a large, diverse collection of tasks consisting of 142 NLP datasets including classification, question answering, natural language inference, paraphrase detection and more, across seven different meta-training/target splits. MetaICL outperforms a range of baselines including in-context learning without meta-training and multi-task learning followed by zero-shot transfer. We find that the gains are particularly significant for target tasks that have domain shifts from the meta-training tasks, and that using a diverse set of the meta-training tasks is key to improvements. We also show that MetaICL approaches (and sometimes beats) the performance of models fully finetuned on the target task training data, and outperforms much bigger models with nearly 8x parameters.

</p>
</details>

<details><summary><b>Whole Brain Segmentation with Full Volume Neural Network</b>
<a href="https://arxiv.org/abs/2110.15601">arxiv:2110.15601</a>
&#x1F4C8; 116 <br>
<p>Yeshu Li, Jonathan Cui, Yilun Sheng, Xiao Liang, Jingdong Wang, Eric I-Chao Chang, Yan Xu</p></summary>
<p>

**Abstract:** Whole brain segmentation is an important neuroimaging task that segments the whole brain volume into anatomically labeled regions-of-interest. Convolutional neural networks have demonstrated good performance in this task. Existing solutions, usually segment the brain image by classifying the voxels, or labeling the slices or the sub-volumes separately. Their representation learning is based on parts of the whole volume whereas their labeling result is produced by aggregation of partial segmentation. Learning and inference with incomplete information could lead to sub-optimal final segmentation result. To address these issues, we propose to adopt a full volume framework, which feeds the full volume brain image into the segmentation network and directly outputs the segmentation result for the whole brain volume. The framework makes use of complete information in each volume and can be implemented easily. An effective instance in this framework is given subsequently. We adopt the $3$D high-resolution network (HRNet) for learning spatially fine-grained representations and the mixed precision training scheme for memory-efficient training. Extensive experiment results on a publicly available $3$D MRI brain dataset show that our proposed model advances the state-of-the-art methods in terms of segmentation performance. Source code is publicly available at https://github.com/microsoft/VoxHRNet.

</p>
</details>

<details><summary><b>Holistic Deep Learning</b>
<a href="https://arxiv.org/abs/2110.15829">arxiv:2110.15829</a>
&#x1F4C8; 64 <br>
<p>Dimitris Bertsimas, Léonard Boussioux, Kimberly Villalobos Carballo, Michael Lingzhi Li, Alex Paskov, Ivan Paskov</p></summary>
<p>

**Abstract:** There is much interest in deep learning to solve challenges that arise in applying neural network models in real-world environments. In particular, three areas have received considerable attention: adversarial robustness, parameter sparsity, and output stability. Despite numerous attempts on solving these problems independently, there is very little work addressing the challenges simultaneously. In this paper, we address this problem of constructing holistic deep learning models by proposing a novel formulation that solves these issues in combination. Real-world experiments on both tabular and MNIST dataset show that our formulation is able to simultaneously improve the accuracy, robustness, stability, and sparsity over traditional deep learning models among many others.

</p>
</details>

<details><summary><b>Neural Networks as Kernel Learners: The Silent Alignment Effect</b>
<a href="https://arxiv.org/abs/2111.00034">arxiv:2111.00034</a>
&#x1F4C8; 49 <br>
<p>Alexander Atanasov, Blake Bordelon, Cengiz Pehlevan</p></summary>
<p>

**Abstract:** Neural networks in the lazy training regime converge to kernel machines. Can neural networks in the rich feature learning regime learn a kernel machine with a data-dependent kernel? We demonstrate that this can indeed happen due to a phenomenon we term silent alignment, which requires that the tangent kernel of a network evolves in eigenstructure while small and before the loss appreciably decreases, and grows only in overall scale afterwards. We show that such an effect takes place in homogenous neural networks with small initialization and whitened data. We provide an analytical treatment of this effect in the linear network case. In general, we find that the kernel develops a low-rank contribution in the early phase of training, and then evolves in overall scale, yielding a function equivalent to a kernel regression solution with the final network's tangent kernel. The early spectral learning of the kernel depends on the depth. We also demonstrate that non-whitened data can weaken the silent alignment effect.

</p>
</details>

<details><summary><b>ReSkin: versatile, replaceable, lasting tactile skins</b>
<a href="https://arxiv.org/abs/2111.00071">arxiv:2111.00071</a>
&#x1F4C8; 42 <br>
<p>Raunaq Bhirangi, Tess Hellebrekers, Carmel Majidi, Abhinav Gupta</p></summary>
<p>

**Abstract:** Soft sensors have continued growing interest in robotics, due to their ability to enable both passive conformal contact from the material properties and active contact data from the sensor properties. However, the same properties of conformal contact result in faster deterioration of soft sensors and larger variations in their response characteristics over time and across samples, inhibiting their ability to be long-lasting and replaceable. ReSkin is a tactile soft sensor that leverages machine learning and magnetic sensing to offer a low-cost, diverse and compact solution for long-term use. Magnetic sensing separates the electronic circuitry from the passive interface, making it easier to replace interfaces as they wear out while allowing for a wide variety of form factors. Machine learning allows us to learn sensor response models that are robust to variations across fabrication and time, and our self-supervised learning algorithm enables finer performance enhancement with small, inexpensive data collection procedures. We believe that ReSkin opens the door to more versatile, scalable and inexpensive tactile sensation modules than existing alternatives.

</p>
</details>

<details><summary><b>Diagnosing Web Data of ICTs to Provide Focused Assistance in Agricultural Adoptions</b>
<a href="https://arxiv.org/abs/2111.00052">arxiv:2111.00052</a>
&#x1F4C8; 20 <br>
<p>Ashwin Singh, Mallika Subramanian, Anmol Agarwal, Pratyush Priyadarshi, Shrey Gupta, Kiran Garimella, Sanjeev Kumar, Ritesh Kumar, Lokesh Garg, Erica Arya, Ponnurangam Kumaraguru</p></summary>
<p>

**Abstract:** The past decade has witnessed a rapid increase in technology ownership across rural areas of India, signifying the potential for ICT initiatives to empower rural households. In our work, we focus on the web infrastructure of one such ICT - Digital Green that started in 2008. Following a participatory approach for content production, Digital Green disseminates instructional agricultural videos to smallholder farmers via human mediators to improve the adoption of farming practices. Their web-based data tracker, CoCo, captures data related to these processes, storing the attendance and adoption logs of over 2.3 million farmers across three continents and twelve countries. Using this data, we model the components of the Digital Green ecosystem involving the past attendance-adoption behaviours of farmers, the content of the videos screened to them and their demographic features across five states in India. We use statistical tests to identify different factors which distinguish farmers with higher adoption rates to understand why they adopt more than others. Our research finds that farmers with higher adoption rates adopt videos of shorter duration and belong to smaller villages. The co-attendance and co-adoption networks of farmers indicate that they greatly benefit from past adopters of a video from their village and group when it comes to adopting practices from the same video. Following our analysis, we model the adoption of practices from a video as a prediction problem to identify and assist farmers who might face challenges in adoption in each of the five states. We experiment with different model architectures and achieve macro-f1 scores ranging from 79% to 89% using a Random Forest classifier. Finally, we measure the importance of different features using SHAP values and provide implications for improving the adoption rates of nearly a million farmers across five states in India.

</p>
</details>

<details><summary><b>Hyperparameter Tuning is All You Need for LISTA</b>
<a href="https://arxiv.org/abs/2110.15900">arxiv:2110.15900</a>
&#x1F4C8; 11 <br>
<p>Xiaohan Chen, Jialin Liu, Zhangyang Wang, Wotao Yin</p></summary>
<p>

**Abstract:** Learned Iterative Shrinkage-Thresholding Algorithm (LISTA) introduces the concept of unrolling an iterative algorithm and training it like a neural network. It has had great success on sparse recovery. In this paper, we show that adding momentum to intermediate variables in the LISTA network achieves a better convergence rate and, in particular, the network with instance-optimal parameters is superlinearly convergent. Moreover, our new theoretical results lead to a practical approach of automatically and adaptively calculating the parameters of a LISTA network layer based on its previous layers. Perhaps most surprisingly, such an adaptive-parameter procedure reduces the training of LISTA to tuning only three hyperparameters from data: a new record set in the context of the recent advances on trimming down LISTA complexity. We call this new ultra-light weight network HyperLISTA. Compared to state-of-the-art LISTA models, HyperLISTA achieves almost the same performance on seen data distributions and performs better when tested on unseen distributions (specifically, those with different sparsity levels and nonzero magnitudes). Code is available: https://github.com/VITA-Group/HyperLISTA.

</p>
</details>

<details><summary><b>Adversarial Robustness with Semi-Infinite Constrained Learning</b>
<a href="https://arxiv.org/abs/2110.15767">arxiv:2110.15767</a>
&#x1F4C8; 11 <br>
<p>Alexander Robey, Luiz F. O. Chamon, George J. Pappas, Hamed Hassani, Alejandro Ribeiro</p></summary>
<p>

**Abstract:** Despite strong performance in numerous applications, the fragility of deep learning to input perturbations has raised serious questions about its use in safety-critical domains. While adversarial training can mitigate this issue in practice, state-of-the-art methods are increasingly application-dependent, heuristic in nature, and suffer from fundamental trade-offs between nominal performance and robustness. Moreover, the problem of finding worst-case perturbations is non-convex and underparameterized, both of which engender a non-favorable optimization landscape. Thus, there is a gap between the theory and practice of adversarial training, particularly with respect to when and why adversarial training works. In this paper, we take a constrained learning approach to address these questions and to provide a theoretical foundation for robust learning. In particular, we leverage semi-infinite optimization and non-convex duality theory to show that adversarial training is equivalent to a statistical problem over perturbation distributions, which we characterize completely. Notably, we show that a myriad of previous robust training techniques can be recovered for particular, sub-optimal choices of these distributions. Using these insights, we then propose a hybrid Langevin Monte Carlo approach of which several common algorithms (e.g., PGD) are special cases. Finally, we show that our approach can mitigate the trade-off between nominal and robust performance, yielding state-of-the-art results on MNIST and CIFAR-10. Our code is available at: https://github.com/arobey1/advbench.

</p>
</details>

<details><summary><b>Combining Public and Private Data</b>
<a href="https://arxiv.org/abs/2111.00115">arxiv:2111.00115</a>
&#x1F4C8; 10 <br>
<p>Cecilia Ferrando, Jennifer Gillenwater, Alex Kulesza</p></summary>
<p>

**Abstract:** Differential privacy is widely adopted to provide provable privacy guarantees in data analysis. We consider the problem of combining public and private data (and, more generally, data with heterogeneous privacy needs) for estimating aggregate statistics. We introduce a mixed estimator of the mean optimized to minimize the variance. We argue that our mechanism is preferable to techniques that preserve the privacy of individuals by subsampling data proportionally to the privacy needs of users. Similarly, we present a mixed median estimator based on the exponential mechanism. We compare our mechanisms to the methods proposed in Jorgensen et al. [2015]. Our experiments provide empirical evidence that our mechanisms often outperform the baseline methods.

</p>
</details>

<details><summary><b>Variational Bayesian Optimistic Sampling</b>
<a href="https://arxiv.org/abs/2110.15688">arxiv:2110.15688</a>
&#x1F4C8; 9 <br>
<p>Brendan O'Donoghue, Tor Lattimore</p></summary>
<p>

**Abstract:** We consider online sequential decision problems where an agent must balance exploration and exploitation. We derive a set of Bayesian `optimistic' policies which, in the stochastic multi-armed bandit case, includes the Thompson sampling policy. We provide a new analysis showing that any algorithm producing policies in the optimistic set enjoys $\tilde O(\sqrt{AT})$ Bayesian regret for a problem with $A$ actions after $T$ rounds. We extend the regret analysis for optimistic policies to bilinear saddle-point problems which include zero-sum matrix games and constrained bandits as special cases. In this case we show that Thompson sampling can produce policies outside of the optimistic set and suffer linear regret in some instances. Finding a policy inside the optimistic set amounts to solving a convex optimization problem and we call the resulting algorithm `variational Bayesian optimistic sampling' (VBOS). The procedure works for any posteriors, \ie, it does not require the posterior to have any special properties, such as log-concavity, unimodality, or smoothness. The variational view of the problem has many useful properties, including the ability to tune the exploration-exploitation tradeoff, add regularization, incorporate constraints, and linearly parameterize the policy.

</p>
</details>

<details><summary><b>Xi-Learning: Successor Feature Transfer Learning for General Reward Functions</b>
<a href="https://arxiv.org/abs/2110.15701">arxiv:2110.15701</a>
&#x1F4C8; 8 <br>
<p>Chris Reinke, Xavier Alameda-Pineda</p></summary>
<p>

**Abstract:** Transfer in Reinforcement Learning aims to improve learning performance on target tasks using knowledge from experienced source tasks. Successor features (SF) are a prominent transfer mechanism in domains where the reward function changes between tasks. They reevaluate the expected return of previously learned policies in a new target task and to transfer their knowledge. A limiting factor of the SF framework is its assumption that rewards linearly decompose into successor features and a reward weight vector. We propose a novel SF mechanism, $ξ$-learning, based on learning the cumulative discounted probability of successor features. Crucially, $ξ$-learning allows to reevaluate the expected return of policies for general reward functions. We introduce two $ξ$-learning variations, prove its convergence, and provide a guarantee on its transfer performance. Experimental evaluations based on $ξ$-learning with function approximation demonstrate the prominent advantage of $ξ$-learning over available mechanisms not only for general reward functions, but also in the case of linearly decomposable reward functions.

</p>
</details>

<details><summary><b>An Effective Image Restorer: Denoising and Luminance Adjustment for Low-photon-count Imaging</b>
<a href="https://arxiv.org/abs/2110.15715">arxiv:2110.15715</a>
&#x1F4C8; 7 <br>
<p>Shansi Zhang, Edmund Y. Lam</p></summary>
<p>

**Abstract:** Imaging under photon-scarce situations introduces challenges to many applications as the captured images are with low signal-to-noise ratio and poor luminance. In this paper, we investigate the raw image restoration under low-photon-count conditions by simulating the imaging of quanta image sensor (QIS). We develop a lightweight framework, which consists of a multi-level pyramid denoising network (MPDNet) and a luminance adjustment (LA) module to achieve separate denoising and luminance enhancement. The main component of our framework is the multi-skip attention residual block (MARB), which integrates multi-scale feature fusion and attention mechanism for better feature representation. Our MPDNet adopts the idea of Laplacian pyramid to learn the small-scale noise map and larger-scale high-frequency details at different levels, and feature extractions are conducted on the multi-scale input images to encode richer contextual information. Our LA module enhances the luminance of the denoised image by estimating its illumination, which can better avoid color distortion. Extensive experimental results have demonstrated that our image restorer can achieve superior performance on the degraded images with various photon levels by suppressing noise and recovering luminance and color effectively.

</p>
</details>

<details><summary><b>IRA: A shape matching approach for recognition and comparison of generic atomic patterns</b>
<a href="https://arxiv.org/abs/2111.00939">arxiv:2111.00939</a>
&#x1F4C8; 6 <br>
<p>Miha Gunde, Nicolas Salles, Anne Hémeryck, Layla Martin-Samos</p></summary>
<p>

**Abstract:** We propose a versatile, parameter-less approach for solving the shape matching problem, specifically in the context of atomic structures when atomic assignments are not known a priori. The algorithm Iteratively suggests Rotated atom-centered reference frames and Assignments (Iterative Rotations and Assignments, IRA). The frame for which a permutationally invariant set-set distance, namely the Hausdorff distance, returns minimal value is chosen as the solution of the matching problem. IRA is able to find rigid rotations, reflections, translations, and permutations between structures with different numbers of atoms, for any atomic arrangement and pattern, periodic or not. When distortions are present between the structures, optimal rotation and translation are found by further applying a standard Singular Value Decomposition-based method. To compute the atomic assignments under the one-to-one assignment constraint, we develop our own algorithm, Constrained Shortest Distance Assignments (CShDA). The overall approach is extensively tested on several structures, including distorted structural fragments. Efficiency of the proposed algorithm is shown as a benchmark comparison against two other shape matching algorithms. We discuss the use of our approach for the identification and comparison of structures and structural fragments through two examples: a replica exchange trajectory of a cyanine molecule, in which we show how our approach could aid the exploration of relevant collective coordinates for clustering the data; and an SiO$_2$ amorphous model, in which we compute distortion scores and compare them with a classical strain-based potential. The source code and benchmark data are available at \url{https://github.com/mammasmias/IterativeRotationsAssignments}.

</p>
</details>

<details><summary><b>Generalized Proximal Policy Optimization with Sample Reuse</b>
<a href="https://arxiv.org/abs/2111.00072">arxiv:2111.00072</a>
&#x1F4C8; 6 <br>
<p>James Queeney, Ioannis Ch. Paschalidis, Christos G. Cassandras</p></summary>
<p>

**Abstract:** In real-world decision making tasks, it is critical for data-driven reinforcement learning methods to be both stable and sample efficient. On-policy methods typically generate reliable policy improvement throughout training, while off-policy methods make more efficient use of data through sample reuse. In this work, we combine the theoretically supported stability benefits of on-policy algorithms with the sample efficiency of off-policy algorithms. We develop policy improvement guarantees that are suitable for the off-policy setting, and connect these bounds to the clipping mechanism used in Proximal Policy Optimization. This motivates an off-policy version of the popular algorithm that we call Generalized Proximal Policy Optimization with Sample Reuse. We demonstrate both theoretically and empirically that our algorithm delivers improved performance by effectively balancing the competing goals of stability and sample efficiency.

</p>
</details>

<details><summary><b>A deep convolutional neural network for classification of Aedes albopictus mosquitoes</b>
<a href="https://arxiv.org/abs/2110.15956">arxiv:2110.15956</a>
&#x1F4C8; 6 <br>
<p>Gereziher Adhane, Mohammad Mahdi Dehshibi, David Masip</p></summary>
<p>

**Abstract:** Monitoring the spread of disease-carrying mosquitoes is a first and necessary step to control severe diseases such as dengue, chikungunya, Zika or yellow fever. Previous citizen science projects have been able to obtain large image datasets with linked geo-tracking information. As the number of international collaborators grows, the manual annotation by expert entomologists of the large amount of data gathered by these users becomes too time demanding and unscalable, posing a strong need for automated classification of mosquito species from images. We introduce the application of two Deep Convolutional Neural Networks in a comparative study to automate this classification task. We use the transfer learning principle to train two state-of-the-art architectures on the data provided by the Mosquito Alert project, obtaining testing accuracy of 94%. In addition, we applied explainable models based on the Grad-CAM algorithm to visualise the most discriminant regions of the classified images, which coincide with the white band stripes located at the legs, abdomen, and thorax of mosquitoes of the Aedes albopictus species. The model allows us to further analyse the classification errors. Visual Grad-CAM models show that they are linked to poor acquisition conditions and strong image occlusions.

</p>
</details>

<details><summary><b>Data-Based Models for Hurricane Evolution Prediction: A Deep Learning Approach</b>
<a href="https://arxiv.org/abs/2111.12683">arxiv:2111.12683</a>
&#x1F4C8; 5 <br>
<p>Rikhi Bose, Adam Pintar, Emil Simiu</p></summary>
<p>

**Abstract:** Fast and accurate prediction of hurricane evolution from genesis onwards is needed to reduce loss of life and enhance community resilience. In this work, a novel model development methodology for predicting storm trajectory is proposed based on two classes of Recurrent Neural Networks (RNNs). The RNN models are trained on input features available in or derived from the HURDAT2 North Atlantic hurricane database maintained by the National Hurricane Center (NHC). The models use probabilities of storms passing through any location, computed from historical data. A detailed analysis of model forecasting error shows that Many-To-One prediction models are less accurate than Many-To-Many models owing to compounded error accumulation, with the exception of $6-hr$ predictions, for which the two types of model perform comparably. Application to 75 or more test storms in the North Atlantic basin showed that, for short-term forecasting up to 12 hours, the Many-to-Many RNN storm trajectory prediction models presented herein are significantly faster than ensemble models used by the NHC, while leading to errors of comparable magnitude.

</p>
</details>

<details><summary><b>Three approaches to facilitate DNN generalization to objects in out-of-distribution orientations and illuminations: late-stopping, tuning batch normalization and invariance loss</b>
<a href="https://arxiv.org/abs/2111.00131">arxiv:2111.00131</a>
&#x1F4C8; 5 <br>
<p>Akira Sakai, Taro Sunagawa, Spandan Madan, Kanata Suzuki, Takashi Katoh, Hiromichi Kobashi, Hanspeter Pfister, Pawan Sinha, Xavier Boix, Tomotake Sasaki</p></summary>
<p>

**Abstract:** The training data distribution is often biased towards objects in certain orientations and illumination conditions. While humans have a remarkable capability of recognizing objects in out-of-distribution (OoD) orientations and illuminations, Deep Neural Networks (DNNs) severely suffer in this case, even when large amounts of training examples are available. In this paper, we investigate three different approaches to improve DNNs in recognizing objects in OoD orientations and illuminations. Namely, these are (i) training much longer after convergence of the in-distribution (InD) validation accuracy, i.e., late-stopping, (ii) tuning the momentum parameter of the batch normalization layers, and (iii) enforcing invariance of the neural activity in an intermediate layer to orientation and illumination conditions. Each of these approaches substantially improves the DNN's OoD accuracy (more than 20% in some cases). We report results in four datasets: two datasets are modified from the MNIST and iLab datasets, and the other two are novel (one of 3D rendered cars and another of objects taken from various controlled orientations and illumination conditions). These datasets allow to study the effects of different amounts of bias and are challenging as DNNs perform poorly in OoD conditions. Finally, we demonstrate that even though the three approaches focus on different aspects of DNNs, they all tend to lead to the same underlying neural mechanism to enable OoD accuracy gains -- individual neurons in the intermediate layers become more selective to a category and also invariant to OoD orientations and illuminations.

</p>
</details>

<details><summary><b>High-dimensional multi-trait GWAS by reverse prediction of genotypes</b>
<a href="https://arxiv.org/abs/2111.00108">arxiv:2111.00108</a>
&#x1F4C8; 5 <br>
<p>Muhammad Ammar Malik, Adriaan-Alexander Ludl, Tom Michoel</p></summary>
<p>

**Abstract:** Multi-trait genome-wide association studies (GWAS) use multi-variate statistical methods to identify associations between genetic variants and multiple correlated traits simultaneously, and have higher statistical power than independent univariate analysis of traits. Reverse regression, where genotypes of genetic variants are regressed on multiple traits simultaneously, has emerged as a promising approach to perform multi-trait GWAS in high-dimensional settings where the number of traits exceeds the number of samples. We extended this approach and analyzed different machine learning methods (ridge regression, random forests and support vector machines)for reverse regression in multi-trait GWAS, using genotypes, gene expression data and ground-truth transcriptional regulatory networks from the DREAM5 SysGen Challenge and from a cross between two yeast strains to evaluate methods. We found that genotype prediction performance, in terms of root mean squared error (RMSE), allowed to distinguish between genomic regions with high and low transcriptional activity. Moreover, model feature coefficients correlated with the strength of association between variants and individual traits, and were predictive of true trans-eQTL target genes, with complementary findings across methods.

</p>
</details>

<details><summary><b>Skyformer: Remodel Self-Attention with Gaussian Kernel and Nyström Method</b>
<a href="https://arxiv.org/abs/2111.00035">arxiv:2111.00035</a>
&#x1F4C8; 5 <br>
<p>Yifan Chen, Qi Zeng, Heng Ji, Yun Yang</p></summary>
<p>

**Abstract:** Transformers are expensive to train due to the quadratic time and space complexity in the self-attention mechanism. On the other hand, although kernel machines suffer from the same computation bottleneck in pairwise dot products, several approximation schemes have been successfully incorporated to considerably reduce their computational cost without sacrificing too much accuracy. In this work, we leverage the computation methods for kernel machines to alleviate the high computational cost and introduce Skyformer, which replaces the softmax structure with a Gaussian kernel to stabilize the model training and adapts the Nyström method to a non-positive semidefinite matrix to accelerate the computation. We further conduct theoretical analysis by showing that the matrix approximation error of our proposed method is small in the spectral norm. Experiments on Long Range Arena benchmark show that the proposed method is sufficient in getting comparable or even better performance than the full self-attention while requiring fewer computation resources.

</p>
</details>

<details><summary><b>Sparsely Changing Latent States for Prediction and Planning in Partially Observable Domains</b>
<a href="https://arxiv.org/abs/2110.15949">arxiv:2110.15949</a>
&#x1F4C8; 5 <br>
<p>Christian Gumbsch, Martin V. Butz, Georg Martius</p></summary>
<p>

**Abstract:** A common approach to prediction and planning in partially observable domains is to use recurrent neural networks (RNNs), which ideally develop and maintain a latent memory about hidden, task-relevant factors. We hypothesize that many of these hidden factors in the physical world are constant over time, changing only sparsely. Accordingly, we propose Gated $L_0$ Regularized Dynamics (GateL0RD), a novel recurrent architecture that incorporates the inductive bias to maintain stable, sparsely changing latent states. The bias is implemented by means of a novel internal gating function and a penalty on the $L_0$ norm of latent state changes. We demonstrate that GateL0RD can compete with or outperform state-of-the-art RNNs in a variety of partially observable prediction and control tasks. GateL0RD tends to encode the underlying generative factors of the environment, ignores spurious temporal dependencies, and generalizes better, improving sampling efficiency and prediction accuracy as well as behavior in model-based planning and reinforcement learning tasks. Moreover, we show that the developing latent states can be easily interpreted, which is a step towards better explainability in RNNs.

</p>
</details>

<details><summary><b>On the use of uncertainty in classifying Aedes Albopictus mosquitoes</b>
<a href="https://arxiv.org/abs/2110.15912">arxiv:2110.15912</a>
&#x1F4C8; 5 <br>
<p>Gereziher Adhane, Mohammad Mahdi Dehshibi, David Masip</p></summary>
<p>

**Abstract:** The re-emergence of mosquito-borne diseases (MBDs), which kill hundreds of thousands of people each year, has been attributed to increased human population, migration, and environmental changes. Convolutional neural networks (CNNs) have been used by several studies to recognise mosquitoes in images provided by projects such as Mosquito Alert to assist entomologists in identifying, monitoring, and managing MBD. Nonetheless, utilising CNNs to automatically label input samples could involve incorrect predictions, which may mislead future epidemiological studies. Furthermore, CNNs require large numbers of manually annotated data. In order to address the mentioned issues, this paper proposes using the Monte Carlo Dropout method to estimate the uncertainty scores in order to rank the classified samples to reduce the need for human supervision in recognising Aedes albopictus mosquitoes. The estimated uncertainty was also used in an active learning framework, where just a portion of the data from large training sets was manually labelled. The experimental results show that the proposed classification method with rejection outperforms the competing methods by improving overall performance and reducing entomologist annotation workload. We also provide explainable visualisations of the different regions that contribute to a set of samples' uncertainty assessment.

</p>
</details>

<details><summary><b>Path-Enhanced Multi-Relational Question Answering with Knowledge Graph Embeddings</b>
<a href="https://arxiv.org/abs/2110.15622">arxiv:2110.15622</a>
&#x1F4C8; 5 <br>
<p>Guanglin Niu, Yang Li, Chengguang Tang, Zhongkai Hu, Shibin Yang, Peng Li, Chengyu Wang, Hao Wang, Jian Sun</p></summary>
<p>

**Abstract:** The multi-relational Knowledge Base Question Answering (KBQA) system performs multi-hop reasoning over the knowledge graph (KG) to achieve the answer. Recent approaches attempt to introduce the knowledge graph embedding (KGE) technique to handle the KG incompleteness but only consider the triple facts and neglect the significant semantic correlation between paths and multi-relational questions. In this paper, we propose a Path and Knowledge Embedding-Enhanced multi-relational Question Answering model (PKEEQA), which leverages multi-hop paths between entities in the KG to evaluate the ambipolar correlation between a path embedding and a multi-relational question embedding via a customizable path representation mechanism, benefiting for achieving more accurate answers from the perspective of both the triple facts and the extra paths. Experimental results illustrate that PKEEQA improves KBQA models' performance for multi-relational question answering with explainability to some extent derived from paths.

</p>
</details>

<details><summary><b>FC2T2: The Fast Continuous Convolutional Taylor Transform with Applications in Vision and Graphics</b>
<a href="https://arxiv.org/abs/2111.00110">arxiv:2111.00110</a>
&#x1F4C8; 4 <br>
<p>Henning Lange, J. Nathan Kutz</p></summary>
<p>

**Abstract:** Series expansions have been a cornerstone of applied mathematics and engineering for centuries. In this paper, we revisit the Taylor series expansion from a modern Machine Learning perspective. Specifically, we introduce the Fast Continuous Convolutional Taylor Transform (FC2T2), a variant of the Fast Multipole Method (FMM), that allows for the efficient approximation of low dimensional convolutional operators in continuous space. We build upon the FMM which is an approximate algorithm that reduces the computational complexity of N-body problems from O(NM) to O(N+M) and finds application in e.g. particle simulations. As an intermediary step, the FMM produces a series expansion for every cell on a grid and we introduce algorithms that act directly upon this representation. These algorithms analytically but approximately compute the quantities required for the forward and backward pass of the backpropagation algorithm and can therefore be employed as (implicit) layers in Neural Networks. Specifically, we introduce a root-implicit layer that outputs surface normals and object distances as well as an integral-implicit layer that outputs a rendering of a radiance field given a 3D pose. In the context of Machine Learning, $N$ and $M$ can be understood as the number of model parameters and model evaluations respectively which entails that, for applications that require repeated function evaluations which are prevalent in Computer Vision and Graphics, unlike regular Neural Networks, the techniques introduce in this paper scale gracefully with parameters. For some applications, this results in a 200x reduction in FLOPs compared to state-of-the-art approaches at a reasonable or non-existent loss in accuracy.

</p>
</details>

<details><summary><b>DeepDoseNet: A Deep Learning model for 3D Dose Prediction in Radiation Therapy</b>
<a href="https://arxiv.org/abs/2111.00077">arxiv:2111.00077</a>
&#x1F4C8; 4 <br>
<p>Mumtaz Hussain Soomro, Victor Gabriel Leandro Alves, Hamidreza Nourzadeh, Jeffrey V. Siebers</p></summary>
<p>

**Abstract:** The DeepDoseNet 3D dose prediction model based on ResNet and Dilated DenseNet is proposed. The 340 head-and-neck datasets from the 2020 AAPM OpenKBP challenge were utilized, with 200 for training, 40 for validation, and 100 for testing. Structures include 56Gy, 63Gy, 70Gy PTVs, and brainstem, spinal cord, right parotid, left parotid, larynx, esophagus, and mandible OARs. Mean squared error (MSE) loss, mean absolute error (MAE) loss, and MAE plus dose-volume histogram (DVH) based loss functions were investigated. Each model's performance was compared using a 3D dose score, $\bar{S_{D}}$, (mean absolute difference between ground truth and predicted 3D dose distributions) and a DVH score, $\bar{S_{DVH}}$ (mean absolute difference between ground truth and predicted dose-volume metrics).Furthermore, DVH metrics Mean[Gy] and D0.1cc [Gy] for OARs and D99%, D95%, D1% for PTVs were computed. DeepDoseNet with the MAE plus DVH-based loss function had the best dose score performance of the OpenKBP entries. MAE+DVH model had the lowest prediction error (P<0.0001, Wilcoxon test) on validation and test datasets (validation: $\bar{S_{D}}$=2.3Gy, $\bar{S_{DVH}}$=1.9Gy; test: $\bar{S_{D}}$=2.0Gy, $\bar{S_{DVH}}$=1.6Gy) followed by the MAE model (validation: $\bar{S_{D}}$=3.6Gy, $\bar{S_{DVH}}$=2.4Gy; test: $\bar{S_{D}}$=3.5Gy, $\bar{S_{DVH}}$=2.3Gy). The MSE model had the highest prediction error (validation: $\bar{S_{D}}$=3.7Gy, $\bar{S_{DVH}}$=3.2Gy; test: $\bar{S_{D}}$=3.6Gy, $\bar{S_{DVH}}$=3.0Gy). No significant difference was found among models in terms of Mean [Gy], but the MAE+DVH model significantly outperformed the MAE and MSE models in terms of D0.1cc[Gy], particularly for mandible and parotids on both validation (P<0.01) and test (P<0.0001) datasets. MAE+DVH outperformed (P<0.0001) in terms of D99%, D95%, D1% for targets. MAE+DVH reduced $\bar{S_{D}}$ by ~60% and $\bar{S_{DVH}}$ by ~70%.

</p>
</details>

<details><summary><b>Symbolic Regression via Neural-Guided Genetic Programming Population Seeding</b>
<a href="https://arxiv.org/abs/2111.00053">arxiv:2111.00053</a>
&#x1F4C8; 4 <br>
<p>T. Nathan Mundhenk, Mikel Landajuela, Ruben Glatt, Claudio P. Santiago, Daniel M. Faissol, Brenden K. Petersen</p></summary>
<p>

**Abstract:** Symbolic regression is the process of identifying mathematical expressions that fit observed output from a black-box process. It is a discrete optimization problem generally believed to be NP-hard. Prior approaches to solving the problem include neural-guided search (e.g. using reinforcement learning) and genetic programming. In this work, we introduce a hybrid neural-guided/genetic programming approach to symbolic regression and other combinatorial optimization problems. We propose a neural-guided component used to seed the starting population of a random restart genetic programming component, gradually learning better starting populations. On a number of common benchmark tasks to recover underlying expressions from a dataset, our method recovers 65% more expressions than a recently published top-performing model using the same experimental setup. We demonstrate that running many genetic programming generations without interdependence on the neural-guided component performs better for symbolic regression than alternative formulations where the two are more strongly coupled. Finally, we introduce a new set of 22 symbolic regression benchmark problems with increased difficulty over existing benchmarks. Source code is provided at www.github.com/brendenpetersen/deep-symbolic-optimization.

</p>
</details>

<details><summary><b>Real-time detection of anomalies in large-scale transient surveys</b>
<a href="https://arxiv.org/abs/2111.00036">arxiv:2111.00036</a>
&#x1F4C8; 4 <br>
<p>Daniel Muthukrishna, Kaisey S. Mandel, Michelle Lochner, Sara Webb, Gautham Narayan</p></summary>
<p>

**Abstract:** New time-domain surveys, such as the Rubin Observatory Legacy Survey of Space and Time (LSST), will observe millions of transient alerts each night, making standard approaches of visually identifying new and interesting transients infeasible. We present two novel methods of automatically detecting anomalous transient light curves in real-time. Both methods are based on the simple idea that if the light curves from a known population of transients can be accurately modelled, any deviations from model predictions are likely anomalies. The first modelling approach is a probabilistic neural network built using Temporal Convolutional Networks (TCNs) and the second is an interpretable Bayesian parametric model of a transient. We demonstrate our methods' ability to provide anomaly scores as a function of time on light curves from the Zwicky Transient Facility. We show that the flexibility of neural networks, the attribute that makes them such a powerful tool for many regression tasks, is what makes them less suitable for anomaly detection when compared with our parametric model. The parametric model is able to identify anomalies with respect to common supernova classes with low false anomaly rates and high true anomaly rates achieving Area Under the Receive Operating Characteristic (ROC) Curve (AUC) scores above 0.8 for most rare classes such as kilonovae, tidal disruption events, intermediate luminosity transients, and pair-instability supernovae. Our ability to identify anomalies improves over the lifetime of the light curves. Our framework, used in conjunction with transient classifiers, will enable fast and prioritised follow-up of unusual transients from new large-scale surveys.

</p>
</details>

<details><summary><b>Improving the quality of generative models through Smirnov transformation</b>
<a href="https://arxiv.org/abs/2110.15914">arxiv:2110.15914</a>
&#x1F4C8; 4 <br>
<p>Ángel González-Prieto, Alberto Mozo, Sandra Gómez-Canaval, Edgar Talavera</p></summary>
<p>

**Abstract:** Solving the convergence issues of Generative Adversarial Networks (GANs) is one of the most outstanding problems in generative models. In this work, we propose a novel activation function to be used as output of the generator agent. This activation function is based on the Smirnov probabilistic transformation and it is specifically designed to improve the quality of the generated data. In sharp contrast with previous works, our activation function provides a more general approach that deals not only with the replication of categorical variables but with any type of data distribution (continuous or discrete). Moreover, our activation function is derivable and therefore, it can be seamlessly integrated in the backpropagation computations during the GAN training processes. To validate this approach, we evaluate our proposal against two different data sets: a) an artificially rendered data set containing a mixture of discrete and continuous variables, and b) a real data set of flow-based network traffic data containing both normal connections and cryptomining attacks. To evaluate the fidelity of the generated data, we analyze both their results in terms of quality measures of statistical nature and also regarding the use of these synthetic data to feed a nested machine learning-based classifier. The experimental results evince a clear outperformance of the GAN network tuned with this new activation function with respect to both a naïve mean-based generator and a standard GAN. The quality of the data is so high that the generated data can fully substitute real data for training the nested classifier without a fall in the obtained accuracy. This result encourages the use of GANs to produce high-quality synthetic data that are applicable in scenarios in which data privacy must be guaranteed.

</p>
</details>

<details><summary><b>Resampling Base Distributions of Normalizing Flows</b>
<a href="https://arxiv.org/abs/2110.15828">arxiv:2110.15828</a>
&#x1F4C8; 4 <br>
<p>Vincent Stimper, Bernhard Schölkopf, José Miguel Hernández-Lobato</p></summary>
<p>

**Abstract:** Normalizing flows are a popular class of models for approximating probability distributions. However, their invertible nature limits their ability to model target distributions with a complex topological structure, such as Boltzmann distributions. Several procedures have been proposed to solve this problem but many of them sacrifice invertibility and, thereby, tractability of the log-likelihood as well as other desirable properties. To address these limitations, we introduce a base distribution for normalizing flows based on learned rejection sampling, allowing the resulting normalizing flow to model complex topologies without giving up bijectivity. Furthermore, we develop suitable learning algorithms using both maximizing the log-likelihood and the optimization of the reverse Kullback-Leibler divergence, and apply them to various sample problems, i.e.\ approximating 2D densities, density estimation of tabular data, image generation, and modeling Boltzmann distributions. In these experiments our method is competitive with or outperforms the baselines.

</p>
</details>

<details><summary><b>Properties from Mechanisms: An Equivariance Perspective on Identifiable Representation Learning</b>
<a href="https://arxiv.org/abs/2110.15796">arxiv:2110.15796</a>
&#x1F4C8; 4 <br>
<p>Kartik Ahuja, Jason Hartford, Yoshua Bengio</p></summary>
<p>

**Abstract:** A key goal of unsupervised representation learning is "inverting" a data generating process to recover its latent properties. Existing work that provably achieves this goal relies on strong assumptions on relationships between the latent variables (e.g., independence conditional on auxiliary information). In this paper, we take a very different perspective on the problem and ask, "Can we instead identify latent properties by leveraging knowledge of the mechanisms that govern their evolution?" We provide a complete characterization of the sources of non-identifiability as we vary knowledge about a set of possible mechanisms. In particular, we prove that if we know the exact mechanisms under which the latent properties evolve, then identification can be achieved up to any equivariances that are shared by the underlying mechanisms. We generalize this characterization to settings where we only know some hypothesis class over possible mechanisms, as well as settings where the mechanisms are stochastic. We demonstrate the power of this mechanism-based perspective by showing that we can leverage our results to generalize existing identifiable representation learning results. These results suggest that by exploiting inductive biases on mechanisms, it is possible to design a range of new identifiable representation learning approaches.

</p>
</details>

<details><summary><b>A/B/n Testing with Control in the Presence of Subpopulations</b>
<a href="https://arxiv.org/abs/2110.15573">arxiv:2110.15573</a>
&#x1F4C8; 4 <br>
<p>Yoan Russac, Christina Katsimerou, Dennis Bohle, Olivier Cappé, Aurélien Garivier, Wouter Koolen</p></summary>
<p>

**Abstract:** Motivated by A/B/n testing applications, we consider a finite set of distributions (called \emph{arms}), one of which is treated as a \emph{control}. We assume that the population is stratified into homogeneous subpopulations. At every time step, a subpopulation is sampled and an arm is chosen: the resulting observation is an independent draw from the arm conditioned on the subpopulation. The quality of each arm is assessed through a weighted combination of its subpopulation means. We propose a strategy for sequentially choosing one arm per time step so as to discover as fast as possible which arms, if any, have higher weighted expectation than the control. This strategy is shown to be asymptotically optimal in the following sense: if $τ_δ$ is the first time when the strategy ensures that it is able to output the correct answer with probability at least $1-δ$, then $\mathbb{E}[τ_δ]$ grows linearly with $\log(1/δ)$ at the exact optimal rate. This rate is identified in the paper in three different settings: (1) when the experimenter does not observe the subpopulation information, (2) when the subpopulation of each sample is observed but not chosen, and (3) when the experimenter can select the subpopulation from which each response is sampled. We illustrate the efficiency of the proposed strategy with numerical simulations on synthetic and real data collected from an A/B/n experiment.

</p>
</details>

<details><summary><b>AI-Powered Semantic Segmentation and Fluid Volume Calculation of Lung CT images in Covid-19 Patients</b>
<a href="https://arxiv.org/abs/2110.15558">arxiv:2110.15558</a>
&#x1F4C8; 4 <br>
<p>Sabeerali K. P, Saleena T. S, Dr. Muhamed Ilyas P, Dr. Neha Mohan</p></summary>
<p>

**Abstract:** COVID-19 pandemic is a deadly disease spreading very fast. People with the confronted immune system are susceptible to many health conditions. A highly significant condition is pneumonia, which is found to be the cause of death in the majority of patients. The main purpose of this study is to find the volume of GGO and consolidation of a covid-19 patient so that the physicians can prioritize the patients. Here we used transfer learning techniques for segmentation of lung CTs with the latest libraries and techniques which reduces training time and increases the accuracy of the AI Model. This system is trained with DeepLabV3+ network architecture and model Resnet50 with Imagenet weights. We used different augmentation techniques like Gaussian Noise, Horizontal shift, color variation, etc to get to the result. Intersection over Union(IoU) is used as the performance metrics. The IoU of lung masks is predicted as 99.78% and that of infected masks is as 89.01%. Our work effectively measures the volume of infected region by calculating the volume of infected and lung mask region of the patients.

</p>
</details>

<details><summary><b>Model Fusion of Heterogeneous Neural Networks via Cross-Layer Alignment</b>
<a href="https://arxiv.org/abs/2110.15538">arxiv:2110.15538</a>
&#x1F4C8; 4 <br>
<p>Dang Nguyen, Khai Nguyen, Dinh Phung, Hung Bui, Nhat Ho</p></summary>
<p>

**Abstract:** Layer-wise model fusion via optimal transport, named OTFusion, applies soft neuron association for unifying different pre-trained networks to save computational resources. While enjoying its success, OTFusion requires the input networks to have the same number of layers. To address this issue, we propose a novel model fusion framework, named CLAFusion, to fuse neural networks with a different number of layers, which we refer to as heterogeneous neural networks, via cross-layer alignment. The cross-layer alignment problem, which is an unbalanced assignment problem, can be solved efficiently using dynamic programming. Based on the cross-layer alignment, our framework balances the number of layers of neural networks before applying layer-wise model fusion. Our synthetic experiments indicate that the fused network from CLAFusion achieves a more favorable performance compared to the individual networks trained on heterogeneous data without the need for any retraining. With an extra fine-tuning process, it improves the accuracy of residual networks on the CIFAR10 dataset. Finally, we explore its application for model compression and knowledge distillation when applying to the teacher-student setting.

</p>
</details>

<details><summary><b>Turning Traffic Monitoring Cameras into Intelligent Sensors for Traffic Density Estimation</b>
<a href="https://arxiv.org/abs/2111.00941">arxiv:2111.00941</a>
&#x1F4C8; 3 <br>
<p>Zijian Hu, William H. K. Lam, S. C. Wong, Andy H. F. Chow, Wei Ma</p></summary>
<p>

**Abstract:** Accurate traffic state information plays a pivotal role in the Intelligent Transportation Systems (ITS), and it is an essential input to various smart mobility applications such as signal coordination and traffic flow prediction. The current practice to obtain the traffic state information is through specialized sensors such as loop detectors and speed cameras. In most metropolitan areas, traffic monitoring cameras have been installed to monitor the traffic conditions on arterial roads and expressways, and the collected videos or images are mainly used for visual inspection by traffic engineers. Unfortunately, the data collected from traffic monitoring cameras are affected by the 4L characteristics: Low frame rate, Low resolution, Lack of annotated data, and Located in complex road environments. Therefore, despite the great potentials of the traffic monitoring cameras, the 4L characteristics hinder them from providing useful traffic state information (e.g., speed, flow, density). This paper focuses on the traffic density estimation problem as it is widely applicable to various traffic surveillance systems. To the best of our knowledge, there is a lack of the holistic framework for addressing the 4L characteristics and extracting the traffic density information from traffic monitoring camera data. In view of this, this paper proposes a framework for estimating traffic density using uncalibrated traffic monitoring cameras with 4L characteristics. The proposed framework consists of two major components: camera calibration and vehicle detection. The camera calibration method estimates the actual length between pixels in the images and videos, and the vehicle counts are extracted from the deep-learning-based vehicle detection method. Combining the two components, high-granular traffic density can be estimated. To validate the proposed framework, two case studies were conducted in Hong Kong and Sacramento. The results show that the Mean Absolute Error (MAE) in camera calibration is less than 0.2 meters out of 6 meters, and the accuracy of vehicle detection under various conditions is approximately 90%. Overall, the MAE for the estimated density is 9.04 veh/km/lane in Hong Kong and 1.30 veh/km/lane in Sacramento. The research outcomes can be used to calibrate the speed-density fundamental diagrams, and the proposed framework can provide accurate and real-time traffic information without installing additional sensors.

</p>
</details>

<details><summary><b>Predicting Atlantic Multidecadal Variability</b>
<a href="https://arxiv.org/abs/2111.00124">arxiv:2111.00124</a>
&#x1F4C8; 3 <br>
<p>Glenn Liu, Peidong Wang, Matthew Beveridge, Young-Oh Kwon, Iddo Drori</p></summary>
<p>

**Abstract:** Atlantic Multidecadal Variability (AMV) describes variations of North Atlantic sea surface temperature with a typical cycle of between 60 and 70 years. AMV strongly impacts local climate over North America and Europe, therefore prediction of AMV, especially the extreme values, is of great societal utility for understanding and responding to regional climate change. This work tests multiple machine learning models to improve the state of AMV prediction from maps of sea surface temperature, salinity, and sea level pressure in the North Atlantic region. We use data from the Community Earth System Model 1 Large Ensemble Project, a state-of-the-art climate model with 3,440 years of data. Our results demonstrate that all of the models we use outperform the traditional persistence forecast baseline. Predicting the AMV is important for identifying future extreme temperatures and precipitation, as well as hurricane activity, in Europe and North America up to 25 years in advance.

</p>
</details>

<details><summary><b>The Golden Rule as a Heuristic to Measure the Fairness of Texts Using Machine Learning</b>
<a href="https://arxiv.org/abs/2111.00107">arxiv:2111.00107</a>
&#x1F4C8; 3 <br>
<p>A. Izzidien, P. Romero, S. Fitz, D. Stillwell</p></summary>
<p>

**Abstract:** To treat others as one would wish to be treated is a common formulation of the golden rule (GR). Yet, despite its prevalence as an axiom throughout history, no transfer of this moral philosophy into computational systems exists. In this paper we consider how to algorithmically operationalise this rule so that it may be used to measure sentences such as the boy harmed the girl, and categorise them as fair or unfair. For the purposes of the paper, we define a fair act as one that one would be accepting of if it were done to oneself. A review and reply to criticisms of the GR is made. We share the code for the digitisation of the GR, and test it with a list of sentences. Implementing it within two language models, the USE, and ALBERT, we find F1 scores of 78.0, 85.0, respectively. A suggestion of how the technology may be implemented to avoid unfair biases in word embeddings is made - given that individuals would typically not wish to be on the receiving end of an unfair act, such as racism, irrespective of whether the corpus being used deems such discrimination as praiseworthy.

</p>
</details>

<details><summary><b>Fetal MRI by robust deep generative prior reconstruction and diffeomorphic registration: application to gestational age prediction</b>
<a href="https://arxiv.org/abs/2111.00102">arxiv:2111.00102</a>
&#x1F4C8; 3 <br>
<p>Lucilio Cordero-Grande, Juan Enrique Ortuño-Fisac, Alena Uus, Maria Deprez, Andrés Santos, Joseph V. Hajnal, María Jesús Ledesma-Carbayo</p></summary>
<p>

**Abstract:** Magnetic resonance imaging of whole fetal body and placenta is limited by different sources of motion affecting the womb. Usual scanning techniques employ single-shot multi-slice sequences where anatomical information in different slices may be subject to different deformations, contrast variations or artifacts. Volumetric reconstruction formulations have been proposed to correct for these factors, but they must accommodate a non-homogeneous and non-isotropic sampling, so regularization becomes necessary. Thus, in this paper we propose a deep generative prior for robust volumetric reconstructions integrated with a diffeomorphic volume to slice registration method. Experiments are performed to validate our contributions and compare with a state of the art method in a cohort of $72$ fetal datasets in the range of $20-36$ weeks gestational age. Results suggest improved image resolution and more accurate prediction of gestational age at scan when comparing to a state of the art reconstruction method. In addition, gestational age prediction results from our volumetric reconstructions compare favourably with existing brain-based approaches, with boosted accuracy when integrating information of organs other than the brain. Namely, a mean absolute error of $0.618$ weeks ($R^2=0.958$) is achieved when combining fetal brain and trunk information.

</p>
</details>

<details><summary><b>Deep Deterministic Uncertainty for Semantic Segmentation</b>
<a href="https://arxiv.org/abs/2111.00079">arxiv:2111.00079</a>
&#x1F4C8; 3 <br>
<p>Jishnu Mukhoti, Joost van Amersfoort, Philip H. S. Torr, Yarin Gal</p></summary>
<p>

**Abstract:** We extend Deep Deterministic Uncertainty (DDU), a method for uncertainty estimation using feature space densities, to semantic segmentation. DDU enables quantifying and disentangling epistemic and aleatoric uncertainty in a single forward pass through the model. We study the similarity of feature representations of pixels at different locations for the same class and conclude that it is feasible to apply DDU location independently, which leads to a significant reduction in memory consumption compared to pixel dependent DDU. Using the DeepLab-v3+ architecture on Pascal VOC 2012, we show that DDU improves upon MC Dropout and Deep Ensembles while being significantly faster to compute.

</p>
</details>

<details><summary><b>Generalized Data Weighting via Class-level Gradient Manipulation</b>
<a href="https://arxiv.org/abs/2111.00056">arxiv:2111.00056</a>
&#x1F4C8; 3 <br>
<p>Can Chen, Shuhao Zheng, Xi Chen, Erqun Dong, Xue Liu, Hao Liu, Dejing Dou</p></summary>
<p>

**Abstract:** Label noise and class imbalance are two major issues coexisting in real-world datasets. To alleviate the two issues, state-of-the-art methods reweight each instance by leveraging a small amount of clean and unbiased data. Yet, these methods overlook class-level information within each instance, which can be further utilized to improve performance. To this end, in this paper, we propose Generalized Data Weighting (GDW) to simultaneously mitigate label noise and class imbalance by manipulating gradients at the class level. To be specific, GDW unrolls the loss gradient to class-level gradients by the chain rule and reweights the flow of each gradient separately. In this way, GDW achieves remarkable performance improvement on both issues. Aside from the performance gain, GDW efficiently obtains class-level weights without introducing any extra computational cost compared with instance weighting methods. Specifically, GDW performs a gradient descent step on class-level weights, which only relies on intermediate gradients. Extensive experiments in various settings verify the effectiveness of GDW. For example, GDW outperforms state-of-the-art methods by $2.56\%$ under the $60\%$ uniform noise setting in CIFAR10. Our code is available at https://github.com/GGchen1997/GDW-NIPS2021.

</p>
</details>

<details><summary><b>Application of 2-D Convolutional Neural Networks for Damage Detection in Steel Frame Structures</b>
<a href="https://arxiv.org/abs/2110.15895">arxiv:2110.15895</a>
&#x1F4C8; 3 <br>
<p>Shahin Ghazvineh, Gholamreza Nouri, Seyed Hossein Hosseini Lavassani, Vahidreza Gharehbaghi, Andy Nguyen</p></summary>
<p>

**Abstract:** In this paper, we present an application of 2-D convolutional neural networks (2-D CNNs) designed to perform both feature extraction and classification stages as a single organism to solve the highlighted problems. The method uses a network of lighted CNNs instead of deep and takes raw acceleration signals as input. Using lighted CNNs, in which every one of them is optimized for a specific element, increases the accuracy and makes the network faster to perform. Also, a new framework is proposed for decreasing the data required in the training phase. We verified our method on Qatar University Grandstand Simulator (QUGS) benchmark data provided by Structural Dynamics Team. The results showed improved accuracy over other methods, and running time was adequate for real-time applications.

</p>
</details>

<details><summary><b>On the Feasibility of Predicting Questions being Forgotten in Stack Overflow</b>
<a href="https://arxiv.org/abs/2110.15789">arxiv:2110.15789</a>
&#x1F4C8; 3 <br>
<p>Thi Huyen Nguyen, Tu Nguyen, Tuan-Anh Hoang, Claudia Niederée</p></summary>
<p>

**Abstract:** For their attractiveness, comprehensiveness and dynamic coverage of relevant topics, community-based question answering sites such as Stack Overflow heavily rely on the engagement of their communities: Questions on new technologies, technology features as well as technology versions come up and have to be answered as technology evolves (and as community members gather experience with it). At the same time, other questions cease in importance over time, finally becoming irrelevant to users. Beyond filtering low-quality questions, "forgetting" questions, which have become redundant, is an important step for keeping the Stack Overflow content concise and useful. In this work, we study this managed forgetting task for Stack Overflow. Our work is based on data from more than a decade (2008 - 2019) - covering 18.1M questions, that are made publicly available by the site itself. For establishing a deeper understanding, we first analyze and characterize the set of questions about to be forgotten, i.e., questions that get a considerable number of views in the current period but become unattractive in the near future. Subsequently, we examine the capability of a wide range of features in predicting such forgotten questions in different categories. We find some categories in which those questions are more predictable. We also discover that the text-based features are surprisingly not helpful in this prediction task, while the meta information is much more predictive.

</p>
</details>

<details><summary><b>Comparing Machine Learning-Centered Approaches for Forecasting Language Patterns During Frustration in Early Childhood</b>
<a href="https://arxiv.org/abs/2110.15778">arxiv:2110.15778</a>
&#x1F4C8; 3 <br>
<p>Arnav Bhakta, Yeunjoo Kim, Pamela Cole</p></summary>
<p>

**Abstract:** When faced with self-regulation challenges, children have been known the use their language to inhibit their emotions and behaviors. Yet, to date, there has been a critical lack of evidence regarding what patterns in their speech children use during these moments of frustration. In this paper, eXtreme Gradient Boosting, Random Forest, Long Short-Term Memory Recurrent Neural Networks, and Elastic Net Regression, have all been used to forecast these language patterns in children. Based on the results of a comparative analysis between these methods, the study reveals that when dealing with high-dimensional and dense data, with very irregular and abnormal distributions, as is the case with self-regulation patterns in children, decision tree-based algorithms are able to outperform traditional regression and neural network methods in their shortcomings.

</p>
</details>

<details><summary><b>Scalable Inference in SDEs by Direct Matching of the Fokker-Planck-Kolmogorov Equation</b>
<a href="https://arxiv.org/abs/2110.15739">arxiv:2110.15739</a>
&#x1F4C8; 3 <br>
<p>Arno Solin, Ella Tamir, Prakhar Verma</p></summary>
<p>

**Abstract:** Simulation-based techniques such as variants of stochastic Runge-Kutta are the de facto approach for inference with stochastic differential equations (SDEs) in machine learning. These methods are general-purpose and used with parametric and non-parametric models, and neural SDEs. Stochastic Runge-Kutta relies on the use of sampling schemes that can be inefficient in high dimensions. We address this issue by revisiting the classical SDE literature and derive direct approximations to the (typically intractable) Fokker-Planck-Kolmogorov equation by matching moments. We show how this workflow is fast, scales to high-dimensional latent spaces, and is applicable to scarce-data applications, where a non-parametric SDE with a driving Gaussian process velocity field specifies the model.

</p>
</details>

<details><summary><b>False Positive Detection and Prediction Quality Estimation for LiDAR Point Cloud Segmentation</b>
<a href="https://arxiv.org/abs/2110.15681">arxiv:2110.15681</a>
&#x1F4C8; 3 <br>
<p>Pascal Colling, Matthias Rottmann, Lutz Roese-Koerner, Hanno Gottschalk</p></summary>
<p>

**Abstract:** We present a novel post-processing tool for semantic segmentation of LiDAR point cloud data, called LidarMetaSeg, which estimates the prediction quality segmentwise. For this purpose we compute dispersion measures based on network probability outputs as well as feature measures based on point cloud input features and aggregate them on segment level. These aggregated measures are used to train a meta classification model to predict whether a predicted segment is a false positive or not and a meta regression model to predict the segmentwise intersection over union. Both models can then be applied to semantic segmentation inferences without knowing the ground truth. In our experiments we use different LiDAR segmentation models and datasets and analyze the power of our method. We show that our results outperform other standard approaches.

</p>
</details>

<details><summary><b>Handshakes AI Research at CASE 2021 Task 1: Exploring different approaches for multilingual tasks</b>
<a href="https://arxiv.org/abs/2110.15599">arxiv:2110.15599</a>
&#x1F4C8; 3 <br>
<p>Vivek Kalyan, Paul Tan, Shaun Tan, Martin Andrews</p></summary>
<p>

**Abstract:** The aim of the CASE 2021 Shared Task 1 (Hürriyetoğlu et al., 2021) was to detect and classify socio-political and crisis event information at document, sentence, cross-sentence, and token levels in a multilingual setting, with each of these subtasks being evaluated separately in each test language. Our submission contained entries in all of the subtasks, and the scores obtained validated our research finding: That the multilingual aspect of the tasks should be embraced, so that modeling and training regimes use the multilingual nature of the tasks to their mutual benefit, rather than trying to tackle the different languages separately. Our code is available at https://github.com/HandshakesByDC/case2021/

</p>
</details>

<details><summary><b>Latent Cognizance: What Machine Really Learns</b>
<a href="https://arxiv.org/abs/2110.15548">arxiv:2110.15548</a>
&#x1F4C8; 3 <br>
<p>Pisit Nakjai, Jiradej Ponsawat, Tatpong Katanyukul</p></summary>
<p>

**Abstract:** Despite overwhelming achievements in recognition accuracy, extending an open-set capability -- ability to identify when the question is out of scope -- remains greatly challenging in a scalable machine learning inference. A recent research has discovered Latent Cognizance (LC) -- an insight on a recognition mechanism based on a new probabilistic interpretation, Bayesian theorem, and an analysis of an internal structure of a commonly-used recognition inference structure. The new interpretation emphasizes a latent assumption of an overlooked probabilistic condition on a learned inference model. Viability of LC has been shown on a task of sign language recognition, but its potential and implication can reach far beyond a specific domain and can move object recognition toward a scalable open-set recognition. However, LC new probabilistic interpretation has not been directly investigated. This article investigates the new interpretation under a traceable context. Our findings support the rationale on which LC is based and reveal a hidden mechanism underlying the learning classification inference. The ramification of these findings could lead to a simple yet effective solution to an open-set recognition.

</p>
</details>

<details><summary><b>Automatic Hand Sign Recognition: Identify Unusuality through Latent Cognizance</b>
<a href="https://arxiv.org/abs/2110.15542">arxiv:2110.15542</a>
&#x1F4C8; 3 <br>
<p>Pisit Nakjai, Tatpong Katanyukul</p></summary>
<p>

**Abstract:** Sign language is a main communication channel among hearing disability community. Automatic sign language transcription could facilitate better communication and understanding between hearing disability community and hearing majority. As a recent work in automatic sign language transcription has discussed, effectively handling or identifying a non-sign posture is one of the key issues. A non-sign posture is a posture unintended for sign reading and does not belong to any valid sign. A non-sign posture may arise during sign transition or simply from an unaware posture. Confidence ratio has been proposed to mitigate the issue. Confidence ratio is simple to compute and readily available without extra training. However, confidence ratio is reported to only partially address the problem. In addition, confidence ratio formulation is susceptible to computational instability. This article proposes alternative formulations to confidence ratio, investigates an issue of non-sign identification for Thai Finger Spelling recognition, explores potential solutions and has found a promising direction. Not only does this finding address the issue of non-sign identification, it also provide some insight behind a well-learned inference machine, revealing hidden meaning and new interpretation of the underlying mechanism. Our proposed methods are evaluated and shown to be effective for non-sign detection.

</p>
</details>

<details><summary><b>Towards Tractable Mathematical Reasoning: Challenges, Strategies, and Opportunities for Solving Math Word Problems</b>
<a href="https://arxiv.org/abs/2111.05364">arxiv:2111.05364</a>
&#x1F4C8; 2 <br>
<p>Keyur Faldu, Amit Sheth, Prashant Kikani, Manas Gaur, Aditi Avasthi</p></summary>
<p>

**Abstract:** Mathematical reasoning would be one of the next frontiers for artificial intelligence to make significant progress. The ongoing surge to solve math word problems (MWPs) and hence achieve better mathematical reasoning ability would continue to be a key line of research in the coming time. We inspect non-neural and neural methods to solve math word problems narrated in a natural language. We also highlight the ability of these methods to be generalizable, mathematically reasonable, interpretable, and explainable. Neural approaches dominate the current state of the art, and we survey them highlighting three strategies to MWP solving: (1) direct answer generation, (2) expression tree generation for inferring answers, and (3) template retrieval for answer computation. Moreover, we discuss technological approaches, review the evolution of intuitive design choices to solve MWPs, and examine them for mathematical reasoning ability. We finally identify several gaps that warrant the need for external knowledge and knowledge-infused learning, among several other opportunities in solving MWPs.

</p>
</details>

<details><summary><b>Advanced Algorithms of Collision Free Navigation and Flocking for Autonomous UAVs</b>
<a href="https://arxiv.org/abs/2111.00166">arxiv:2111.00166</a>
&#x1F4C8; 2 <br>
<p>Taha Elmokadem</p></summary>
<p>

**Abstract:** Unmanned aerial vehicles (UAVs) have become very popular for many military and civilian applications including in agriculture, construction, mining, environmental monitoring, etc. A desirable feature for UAVs is the ability to navigate and perform tasks autonomously with least human interaction. This is a very challenging problem due to several factors such as the high complexity of UAV applications, operation in harsh environments, limited payload and onboard computing power and highly nonlinear dynamics. The work presented in this report contributes towards the state-of-the-art in UAV control for safe autonomous navigation and motion coordination of multi-UAV systems. The first part of this report deals with single-UAV systems. The complex problem of three-dimensional (3D) collision-free navigation in unknown/dynamic environments is addressed. To that end, advanced 3D reactive control strategies are developed adopting the sense-and-avoid paradigm to produce quick reactions around obstacles. A special case of navigation in 3D unknown confined environments (i.e. tunnel-like) is also addressed. General 3D kinematic models are considered in the design which makes these methods applicable to different UAV types in addition to underwater vehicles. Moreover, different implementation methods for these strategies with quadrotor-type UAVs are also investigated considering UAV dynamics in the control design. Practical experiments and simulations were carried out to analyze the performance of the developed methods. The second part of this report addresses safe navigation for multi-UAV systems. Distributed motion coordination methods of multi-UAV systems for flocking and 3D area coverage are developed. These methods offer good computational cost for large-scale systems. Simulations were performed to verify the performance of these methods considering systems with different sizes.

</p>
</details>

<details><summary><b>Temporal-Spatial Feature Extraction Based on Convolutional Neural Networks for Travel Time Prediction</b>
<a href="https://arxiv.org/abs/2111.00149">arxiv:2111.00149</a>
&#x1F4C8; 2 <br>
<p>Chi-Hua Chen</p></summary>
<p>

**Abstract:** In recent years, some traffic information prediction methods have been proposed to provide the precise information of travel time, vehicle speed, and traffic flow for highways. However, big errors may be obtained by these methods for urban roads or the alternative roads of highways. Therefore, this study proposes a travel time prediction method based on convolutional neural networks to extract important factors for the improvement of traffic information prediction. In practical experimental environments, the travel time records of No. 5 Highway and the alternative roads of its were collected and used to evaluate the proposed method. The results showed that the mean absolute percentage error of the proposed method was about 5.69%. Therefore, the proposed method based on deep learning techniques can improve the accuracy of travel time prediction.

</p>
</details>

<details><summary><b>Efficient Inference Without Trading-off Regret in Bandits: An Allocation Probability Test for Thompson Sampling</b>
<a href="https://arxiv.org/abs/2111.00137">arxiv:2111.00137</a>
&#x1F4C8; 2 <br>
<p>Nina Deliu, Joseph J. Williams, Sofia S. Villar</p></summary>
<p>

**Abstract:** Using bandit algorithms to conduct adaptive randomised experiments can minimise regret, but it poses major challenges for statistical inference (e.g., biased estimators, inflated type-I error and reduced power). Recent attempts to address these challenges typically impose restrictions on the exploitative nature of the bandit algorithm$-$trading off regret$-$and require large sample sizes to ensure asymptotic guarantees. However, large experiments generally follow a successful pilot study, which is tightly constrained in its size or duration. Increasing power in such small pilot experiments, without limiting the adaptive nature of the algorithm, can allow promising interventions to reach a larger experimental phase. In this work we introduce a novel hypothesis test, uniquely based on the allocation probabilities of the bandit algorithm, and without constraining its exploitative nature or requiring a minimum experimental size. We characterise our $Allocation\ Probability\ Test$ when applied to $Thompson\ Sampling$, presenting its asymptotic theoretical properties, and illustrating its finite-sample performances compared to state-of-the-art approaches. We demonstrate the regret and inferential advantages of our approach, particularly in small samples, in both extensive simulations and in a real-world experiment on mental health aspects.

</p>
</details>

<details><summary><b>Context Meta-Reinforcement Learning via Neuromodulation</b>
<a href="https://arxiv.org/abs/2111.00134">arxiv:2111.00134</a>
&#x1F4C8; 2 <br>
<p>Eseoghene Ben-Iwhiwhu, Jeffery Dick, Nicholas A. Ketz, Praveen K. Pilly, Andrea Soltoggio</p></summary>
<p>

**Abstract:** Meta-reinforcement learning (meta-RL) algorithms enable agents to adapt quickly to tasks from few samples in dynamic environments. Such a feat is achieved through dynamic representations in an agent's policy network (obtained via reasoning about task context, model parameter updates, or both). However, obtaining rich dynamic representations for fast adaptation beyond simple benchmark problems is challenging due to the burden placed on the policy network to accommodate different policies. This paper addresses the challenge by introducing neuromodulation as a modular component to augment a standard policy network that regulates neuronal activities in order to produce efficient dynamic representations for task adaptation. The proposed extension to the policy network is evaluated across multiple discrete and continuous control environments of increasing complexity. To prove the generality and benefits of the extension in meta-RL, the neuromodulated network was applied to two state-of-the-art meta-RL algorithms (CAVIA and PEARL). The result demonstrates that meta-RL augmented with neuromodulation produces significantly better result and richer dynamic representations in comparison to the baselines.

</p>
</details>

<details><summary><b>Robust and efficient change point detection using novel multivariate rank-energy GoF test</b>
<a href="https://arxiv.org/abs/2111.00047">arxiv:2111.00047</a>
&#x1F4C8; 2 <br>
<p>Shoaib Bin Masud, Shuchin Aeron</p></summary>
<p>

**Abstract:** In this paper, we use and further develop upon a recently proposed multivariate, distribution-free Goodness-of-Fit (GoF) test based on the theory of Optimal Transport (OT) called the Rank Energy (RE) [1], for non-parametric and unsupervised Change Point Detection (CPD) in multivariate time series data. We show that directly using RE leads to high sensitivity to very small changes in distributions (causing high false alarms) and it requires large sample complexity and huge computational cost. To alleviate these drawbacks, we propose a new GoF test statistic called as soft-Rank Energy (sRE) that is based on entropy regularized OT and employ it towards CPD. We discuss the advantages of using sRE over RE and demonstrate that the proposed sRE based CPD outperforms all the existing methods in terms of Area Under the Curve (AUC) and F1-score on real and synthetic data sets.

</p>
</details>

<details><summary><b>Learning generative models for valid knockoffs using novel multivariate-rank based statistics</b>
<a href="https://arxiv.org/abs/2111.00043">arxiv:2111.00043</a>
&#x1F4C8; 2 <br>
<p>Shoaib Bin Masud, Shuchin Aeron</p></summary>
<p>

**Abstract:** We consider the problem of generating valid knockoffs for knockoff filtering which is a statistical method that provides provable false discovery rate guarantees for any model selection procedure. To this end, we are motivated by recent advances in multivariate distribution-free goodness-of-fit tests namely, the rank energy (RE), that is derived using theoretical results characterizing the optimal maps in the Monge's Optimal Transport (OT) problem. However, direct use of use RE for learning generative models is not feasible because of its high computational and sample complexity, saturation under large support discrepancy between distributions, and non-differentiability in generative parameters. To alleviate these, we begin by proposing a variant of the RE, dubbed as soft rank energy (sRE), and its kernel variant called as soft rank maximum mean discrepancy (sRMMD) using entropic regularization of Monge's OT problem. We then use sRMMD to generate deep knockoffs and show via extensive evaluation that it is a novel and effective method to produce valid knockoffs, achieving comparable, or in some cases improved tradeoffs between detection power Vs false discoveries.

</p>
</details>

<details><summary><b>Support Recovery with Stochastic Gates: Theory and Application for Linear Models</b>
<a href="https://arxiv.org/abs/2110.15960">arxiv:2110.15960</a>
&#x1F4C8; 2 <br>
<p>Soham Jana, Henry Li, Yutaro Yamada, Ofir Lindenbaum</p></summary>
<p>

**Abstract:** We analyze the problem of simultaneous support recovery and estimation of the coefficient vector ($β^*$) in a linear model with independent and identically distributed Normal errors. We apply the penalized least square estimator based on non-linear penalties of stochastic gates (STG) [YLNK20] to estimate the coefficients. Considering Gaussian design matrices we show that under reasonable conditions on dimension and sparsity of $β^*$ the STG based estimator converges to the true data generating coefficient vector and also detects its support set with high probability. We propose a new projection based algorithm for linear models setup to improve upon the existing STG estimator that was originally designed for general non-linear models. Our new procedure outperforms many classical estimators for support recovery in synthetic data analysis.

</p>
</details>

<details><summary><b>Limiting fluctuation and trajectorial stability of multilayer neural networks with mean field training</b>
<a href="https://arxiv.org/abs/2110.15954">arxiv:2110.15954</a>
&#x1F4C8; 2 <br>
<p>Huy Tuan Pham, Phan-Minh Nguyen</p></summary>
<p>

**Abstract:** The mean field (MF) theory of multilayer neural networks centers around a particular infinite-width scaling, where the learning dynamics is closely tracked by the MF limit. A random fluctuation around this infinite-width limit is expected from a large-width expansion to the next order. This fluctuation has been studied only in shallow networks, where previous works employ heavily technical notions or additional formulation ideas amenable only to that case. Treatment of the multilayer case has been missing, with the chief difficulty in finding a formulation that captures the stochastic dependency across not only time but also depth.
  In this work, we initiate the study of the fluctuation in the case of multilayer networks, at any network depth. Leveraging on the neuronal embedding framework recently introduced by Nguyen and Pham, we systematically derive a system of dynamical equations, called the second-order MF limit, that captures the limiting fluctuation distribution. We demonstrate through the framework the complex interaction among neurons in this second-order MF limit, the stochasticity with cross-layer dependency and the nonlinear time evolution inherent in the limiting fluctuation. A limit theorem is proven to relate quantitatively this limit to the fluctuation of large-width networks.
  We apply the result to show a stability property of gradient descent MF training: in the large-width regime, along the training trajectory, it progressively biases towards a solution with "minimal fluctuation" (in fact, vanishing fluctuation) in the learned output function, even after the network has been initialized at or has converged (sufficiently fast) to a global optimum. This extends a similar phenomenon previously shown only for shallow networks with a squared loss in the ERM setting, to multilayer networks with a loss function that is not necessarily convex in a more general setting.

</p>
</details>

<details><summary><b>Distributing Deep Learning Hyperparameter Tuning for 3D Medical Image Segmentation</b>
<a href="https://arxiv.org/abs/2110.15884">arxiv:2110.15884</a>
&#x1F4C8; 2 <br>
<p>Josep Lluis Berral, Oriol Aranda, Juan Luis Dominguez, Jordi Torres</p></summary>
<p>

**Abstract:** Most research on novel techniques for 3D Medical Image Segmentation (MIS) is currently done using Deep Learning with GPU accelerators. The principal challenge of such technique is that a single input can easily cope computing resources, and require prohibitive amounts of time to be processed. Distribution of deep learning and scalability over computing devices is an actual need for progressing on such research field. Conventional distribution of neural networks consist in data parallelism, where data is scattered over resources (e.g., GPUs) to parallelize the training of the model. However, experiment parallelism is also an option, where different training processes are parallelized across resources. While the first option is much more common on 3D image segmentation, the second provides a pipeline design with less dependence among parallelized processes, allowing overhead reduction and more potential scalability. In this work we present a design for distributed deep learning training pipelines, focusing on multi-node and multi-GPU environments, where the two different distribution approaches are deployed and benchmarked. We take as proof of concept the 3D U-Net architecture, using the MSD Brain Tumor Segmentation dataset, a state-of-art problem in medical image segmentation with high computing and space requirements. Using the BSC MareNostrum supercomputer as benchmarking environment, we use TensorFlow and Ray as neural network training and experiment distribution platforms. We evaluate the experiment speed-up, showing the potential for scaling out on GPUs and nodes. Also comparing the different parallelism techniques, showing how experiment distribution leverages better such resources through scaling. Finally, we provide the implementation of the design open to the community, and the non-trivial steps and methodology for adapting and deploying a MIS case as the here presented.

</p>
</details>

<details><summary><b>Towards Comparative Physical Interpretation of Spatial Variability Aware Neural Networks: A Summary of Results</b>
<a href="https://arxiv.org/abs/2110.15866">arxiv:2110.15866</a>
&#x1F4C8; 2 <br>
<p>Jayant Gupta, Carl Molnar, Gaoxiang Luo, Joe Knight, Shashi Shekhar</p></summary>
<p>

**Abstract:** Given Spatial Variability Aware Neural Networks (SVANNs), the goal is to investigate mathematical (or computational) models for comparative physical interpretation towards their transparency (e.g., simulatibility, decomposability and algorithmic transparency). This problem is important due to important use-cases such as reusability, debugging, and explainability to a jury in a court of law. Challenges include a large number of model parameters, vacuous bounds on generalization performance of neural networks, risk of overfitting, sensitivity to noise, etc., which all detract from the ability to interpret the models. Related work on either model-specific or model-agnostic post-hoc interpretation is limited due to a lack of consideration of physical constraints (e.g., mass balance) and properties (e.g., second law of geography). This work investigates physical interpretation of SVANNs using novel comparative approaches based on geographically heterogeneous features. The proposed approach on feature-based physical interpretation is evaluated using a case-study on wetland mapping. The proposed physical interpretation improves the transparency of SVANN models and the analytical results highlight the trade-off between model transparency and model performance (e.g., F1-score). We also describe an interpretation based on geographically heterogeneous processes modeled as partial differential equations (PDEs).

</p>
</details>

<details><summary><b>Adaptive Discretization in Online Reinforcement Learning</b>
<a href="https://arxiv.org/abs/2110.15843">arxiv:2110.15843</a>
&#x1F4C8; 2 <br>
<p>Sean R. Sinclair, Siddhartha Banerjee, Christina Lee Yu</p></summary>
<p>

**Abstract:** Discretization based approaches to solving online reinforcement learning problems have been studied extensively in practice on applications ranging from resource allocation to cache management. Two major questions in designing discretization-based algorithms are how to create the discretization and when to refine it. While there have been several experimental results investigating heuristic solutions to these questions, there has been little theoretical treatment. In this paper we provide a unified theoretical analysis of tree-based hierarchical partitioning methods for online reinforcement learning, providing model-free and model-based algorithms. We show how our algorithms are able to take advantage of inherent structure of the problem by providing guarantees that scale with respect to the 'zooming dimension' instead of the ambient dimension, an instance-dependent quantity measuring the benignness of the optimal $Q_h^\star$ function.
  Many applications in computing systems and operations research requires algorithms that compete on three facets: low sample complexity, mild storage requirements, and low computational burden. Our algorithms are easily adapted to operating constraints, and our theory provides explicit bounds across each of the three facets. This motivates its use in practical applications as our approach automatically adapts to underlying problem structure even when very little is known a priori about the system.

</p>
</details>

<details><summary><b>C-MADA: Unsupervised Cross-Modality Adversarial Domain Adaptation framework for medical Image Segmentation</b>
<a href="https://arxiv.org/abs/2110.15823">arxiv:2110.15823</a>
&#x1F4C8; 2 <br>
<p>Maria Baldeon-Calisto, Susana K. Lai-Yuen</p></summary>
<p>

**Abstract:** Deep learning models have obtained state-of-the-art results for medical image analysis. However, when these models are tested on an unseen domain there is a significant performance degradation. In this work, we present an unsupervised Cross-Modality Adversarial Domain Adaptation (C-MADA) framework for medical image segmentation. C-MADA implements an image- and feature-level adaptation method in a sequential manner. First, images from the source domain are translated to the target domain through an un-paired image-to-image adversarial translation with cycle-consistency loss. Then, a U-Net network is trained with the mapped source domain images and target domain images in an adversarial manner to learn domain-invariant feature representations. Furthermore, to improve the networks segmentation performance, information about the shape, texture, and con-tour of the predicted segmentation is included during the adversarial train-ing. C-MADA is tested on the task of brain MRI segmentation, obtaining competitive results.

</p>
</details>

<details><summary><b>CVAD: A generic medical anomaly detector based on Cascade VAE</b>
<a href="https://arxiv.org/abs/2110.15811">arxiv:2110.15811</a>
&#x1F4C8; 2 <br>
<p>Xiaoyuan Guo, Judy Wawira Gichoya, Saptarshi Purkayastha, Imon Banerjee</p></summary>
<p>

**Abstract:** Detecting out-of-distribution (OOD) samples in medical imaging plays an important role for downstream medical diagnosis. However, existing OOD detectors are demonstrated on natural images composed of inter-classes and have difficulty generalizing to medical images. The key issue is the granularity of OOD data in the medical domain, where intra-class OOD samples are predominant. We focus on the generalizability of OOD detection for medical images and propose a self-supervised Cascade Variational autoencoder-based Anomaly Detector (CVAD). We use a variational autoencoders' cascade architecture, which combines latent representation at multiple scales, before being fed to a discriminator to distinguish the OOD data from the in-distribution (ID) data. Finally, both the reconstruction error and the OOD probability predicted by the binary discriminator are used to determine the anomalies. We compare the performance with the state-of-the-art deep learning models to demonstrate our model's efficacy on various open-access medical imaging datasets for both intra- and inter-class OOD. Further extensive results on datasets including common natural datasets show our model's effectiveness and generalizability. The code is available at https://github.com/XiaoyuanGuo/CVAD.

</p>
</details>

<details><summary><b>ε-weakened Robustness of Deep Neural Networks</b>
<a href="https://arxiv.org/abs/2110.15764">arxiv:2110.15764</a>
&#x1F4C8; 2 <br>
<p>Pei Huang, Yuting Yang, Minghao Liu, Fuqi Jia, Feifei Ma, Jian Zhang</p></summary>
<p>

**Abstract:** This paper introduces a notation of $\varepsilon$-weakened robustness for analyzing the reliability and stability of deep neural networks (DNNs). Unlike the conventional robustness, which focuses on the "perfect" safe region in the absence of adversarial examples, $\varepsilon$-weakened robustness focuses on the region where the proportion of adversarial examples is bounded by user-specified $\varepsilon$. Smaller $\varepsilon$ means a smaller chance of failure. Under such robustness definition, we can give conclusive results for the regions where conventional robustness ignores. We prove that the $\varepsilon$-weakened robustness decision problem is PP-complete and give a statistical decision algorithm with user-controllable error bound. Furthermore, we derive an algorithm to find the maximum $\varepsilon$-weakened robustness radius. The time complexity of our algorithms is polynomial in the dimension and size of the network. So, they are scalable to large real-world networks. Besides, We also show its potential application in analyzing quality issues.

</p>
</details>

<details><summary><b>Aligned Multi-Task Gaussian Process</b>
<a href="https://arxiv.org/abs/2110.15761">arxiv:2110.15761</a>
&#x1F4C8; 2 <br>
<p>Olga Mikheeva, Ieva Kazlauskaite, Adam Hartshorne, Hedvig Kjellström, Carl Henrik Ek, Neill D. F. Campbell</p></summary>
<p>

**Abstract:** Multi-task learning requires accurate identification of the correlations between tasks. In real-world time-series, tasks are rarely perfectly temporally aligned; traditional multi-task models do not account for this and subsequent errors in correlation estimation will result in poor predictive performance and uncertainty quantification. We introduce a method that automatically accounts for temporal misalignment in a unified generative model that improves predictive performance. Our method uses Gaussian processes (GPs) to model the correlations both within and between the tasks. Building on the previous work by Kazlauskaiteet al. [2019], we include a separate monotonic warp of the input data to model temporal misalignment. In contrast to previous work, we formulate a lower bound that accounts for uncertainty in both the estimates of the warping process and the underlying functions. Also, our new take on a monotonic stochastic process, with efficient path-wise sampling for the warp functions, allows us to perform full Bayesian inference in the model rather than MAP estimates. Missing data experiments, on synthetic and real time-series, demonstrate the advantages of accounting for misalignments (vs standard unaligned method) as well as modelling the uncertainty in the warping process(vs baseline MAP alignment approach).

</p>
</details>

<details><summary><b>A Protocol for Emotions</b>
<a href="https://arxiv.org/abs/2110.15695">arxiv:2110.15695</a>
&#x1F4C8; 2 <br>
<p>Gabriele Costa</p></summary>
<p>

**Abstract:** We tend to consider emotions a manifestation of our innermost nature of human beings. Emotions characterize our lives in many ways and they chaperon every rational activity we carry out. Despite their pervasiveness, there are still many things we ignore about emotions. Among them, our understanding of how living beings transfer emotions is limited. In particular, there are highly sophisticated interactions between human beings that we would like to comprehend. For instance, think of a movie director who knows in advance the strong emotional impact that a certain scene will have on the spectators. Although many artists rely on some emotional devices, their talent and vision are still the key factors.
  In this work we analyze high-level protocols for transferring emotions between two intelligent agents. To the best of our knowledge, this is the first attempt to use communication protocols for modeling the exchange of human emotions. By means of a number of examples, we show that our protocols adequately model the engagement of the two parties. Beyond the theoretical interest, our proposal can provide a stepping stone for several applications that we also discuss in this paper.

</p>
</details>

<details><summary><b>3D-OOCS: Learning Prostate Segmentation with Inductive Bias</b>
<a href="https://arxiv.org/abs/2110.15664">arxiv:2110.15664</a>
&#x1F4C8; 2 <br>
<p>Shrajan Bhandary, Zahra Babaiee, Dejan Kostyszyn, Tobias Fechter, Constantinos Zamboglou, Anca Grosu, Radu Grosu</p></summary>
<p>

**Abstract:** Despite the great success of convolutional neural networks (CNN) in 3D medical image segmentation tasks, the methods currently in use are still not robust enough to the different protocols utilized by different scanners, and to the variety of image properties or artefacts they produce. To this end, we introduce OOCS-enhanced networks, a novel architecture inspired by the innate nature of visual processing in the vertebrates. With different 3D U-Net variants as the base, we add two 3D residual components to the second encoder blocks: on and off center-surround (OOCS). They generalise the ganglion pathways in the retina to a 3D setting. The use of 2D-OOCS in any standard CNN network complements the feedforward framework with sharp edge-detection inductive biases. The use of 3D-OOCS also helps 3D U-Nets to scrutinise and delineate anatomical structures present in 3D images with increased accuracy.We compared the state-of-the-art 3D U-Nets with their 3D-OOCS extensions and showed the superior accuracy and robustness of the latter in automatic prostate segmentation from 3D Magnetic Resonance Images (MRIs). For a fair comparison, we trained and tested all the investigated 3D U-Nets with the same pipeline, including automatic hyperparameter optimisation and data augmentation.

</p>
</details>

<details><summary><b>Unsupervised PET Reconstruction from a Bayesian Perspective</b>
<a href="https://arxiv.org/abs/2110.15568">arxiv:2110.15568</a>
&#x1F4C8; 2 <br>
<p>Chenyu Shen, Wenjun Xia, Hongwei Ye, Mingzheng Hou, Hu Chen, Yan Liu, Jiliu Zhou, Yi Zhang</p></summary>
<p>

**Abstract:** Positron emission tomography (PET) reconstruction has become an ill-posed inverse problem due to low-count projection data, and a robust algorithm is urgently required to improve imaging quality. Recently, the deep image prior (DIP) has drawn much attention and has been successfully applied in several image restoration tasks, such as denoising and inpainting, since it does not need any labels (reference image). However, overfitting is a vital defect of this framework. Hence, many methods have been proposed to mitigate this problem, and DeepRED is a typical representation that combines DIP and regularization by denoising (RED). In this article, we leverage DeepRED from a Bayesian perspective to reconstruct PET images from a single corrupted sinogram without any supervised or auxiliary information. In contrast to the conventional denoisers customarily used in RED, a DnCNN-like denoiser, which can add an adaptive constraint to DIP and facilitate the computation of derivation, is employed. Moreover, to further enhance the regularization, Gaussian noise is injected into the gradient updates, deriving a Markov chain Monte Carlo (MCMC) sampler. Experimental studies on brain and whole-body datasets demonstrate that our proposed method can achieve better performance in terms of qualitative and quantitative results compared to several classic and state-of-the-art methods.

</p>
</details>

<details><summary><b>Learning Circular Hidden Quantum Markov Models: A Tensor Network Approach</b>
<a href="https://arxiv.org/abs/2111.01536">arxiv:2111.01536</a>
&#x1F4C8; 1 <br>
<p>Mohammad Ali Javidian, Vaneet Aggarwal, Zubin Jacob</p></summary>
<p>

**Abstract:** In this paper, we propose circular Hidden Quantum Markov Models (c-HQMMs), which can be applied for modeling temporal data in quantum datasets (with classical datasets as a special case). We show that c-HQMMs are equivalent to a constrained tensor network (more precisely, circular Local Purified State with positive-semidefinite decomposition) model. This equivalence enables us to provide an efficient learning model for c-HQMMs. The proposed learning approach is evaluated on six real datasets and demonstrates the advantage of c-HQMMs on multiple datasets as compared to HQMMs, circular HMMs, and HMMs.

</p>
</details>

<details><summary><b>Uncovering IP Address Hosting Types Behind Malicious Websites</b>
<a href="https://arxiv.org/abs/2111.00142">arxiv:2111.00142</a>
&#x1F4C8; 1 <br>
<p>Nimesha Wickramasinghe, Mohamed Nabeel, Kenneth Thilakaratne, Chamath Keppitiyagama, Kasun De Zoysa</p></summary>
<p>

**Abstract:** Hundreds of thousands of malicious domains are created everyday. These malicious domains are hosted on a wide variety of network infrastructures. Traditionally, attackers utilize bullet proof hosting services (e.g. MaxiDed, Cyber Bunker) to take advantage of relatively lenient policies on what content they can host. However, these IP ranges are increasingly being blocked or the services are taken down by law enforcement. Hence, attackers are moving towards utilizing IPs from regular hosting providers while staying under the radar of these hosting providers. There are several practical advantages of accurately knowing the type of IP used to host malicious domains. If the IP is a dedicated IP (i.e. it is leased to a single entity), one may blacklist the IP to block domains hosted on those IPs as welll as use as a way to identify other malicious domains hosted the same IP. If the IP is a shared hosting IP, hosting providers may take measures to clean up such domains and maintain a high reputation for their users.

</p>
</details>

<details><summary><b>Visual Explanations for Convolutional Neural Networks via Latent Traversal of Generative Adversarial Networks</b>
<a href="https://arxiv.org/abs/2111.00116">arxiv:2111.00116</a>
&#x1F4C8; 1 <br>
<p>Amil Dravid, Aggelos K. Katsaggelos</p></summary>
<p>

**Abstract:** Lack of explainability in artificial intelligence, specifically deep neural networks, remains a bottleneck for implementing models in practice. Popular techniques such as Gradient-weighted Class Activation Mapping (Grad-CAM) provide a coarse map of salient features in an image, which rarely tells the whole story of what a convolutional neural network (CNN) learned. Using COVID-19 chest X-rays, we present a method for interpreting what a CNN has learned by utilizing Generative Adversarial Networks (GANs). Our GAN framework disentangles lung structure from COVID-19 features. Using this GAN, we can visualize the transition of a pair of COVID negative lungs in a chest radiograph to a COVID positive pair by interpolating in the latent space of the GAN, which provides fine-grained visualization of how the CNN responds to varying features within the lungs.

</p>
</details>

<details><summary><b>Evaluation of an Anomaly Detector for Routers using Parameterizable Malware in an IoT Ecosystem</b>
<a href="https://arxiv.org/abs/2111.00097">arxiv:2111.00097</a>
&#x1F4C8; 1 <br>
<p>John Carter, Spiros Mancoridis</p></summary>
<p>

**Abstract:** This work explores the evaluation of a machine learning anomaly detector using custom-made parameterizable malware in an Internet of Things (IoT) Ecosystem. It is assumed that the malware has infected, and resides on, the Linux router that serves other devices on the network, as depicted in Figure 1. This IoT Ecosystem was developed as a testbed to evaluate the efficacy of a behavior-based anomaly detector. The malware consists of three types of custom-made malware: ransomware, cryptominer, and keylogger, which all have exfiltration capabilities to the network. The parameterization of the malware gives the malware samples multiple degrees of freedom, specifically relating to the rate and size of data exfiltration. The anomaly detector uses feature sets crafted from system calls and network traffic, and uses a Support Vector Machine (SVM) for behavioral-based anomaly detection. The custom-made malware is used to evaluate the situations where the SVM is effective, as well as the situations where it is not effective.

</p>
</details>

<details><summary><b>Optimal Compression of Locally Differentially Private Mechanisms</b>
<a href="https://arxiv.org/abs/2111.00092">arxiv:2111.00092</a>
&#x1F4C8; 1 <br>
<p>Abhin Shah, Wei-Ning Chen, Johannes Balle, Peter Kairouz, Lucas Theis</p></summary>
<p>

**Abstract:** Compressing the output of ε-locally differentially private (LDP) randomizers naively leads to suboptimal utility. In this work, we demonstrate the benefits of using schemes that jointly compress and privatize the data using shared randomness. In particular, we investigate a family of schemes based on Minimal Random Coding (Havasi et al., 2019) and prove that they offer optimal privacy-accuracy-communication tradeoffs. Our theoretical and empirical findings show that our approach can compress PrivUnit (Bhowmick et al., 2018) and Subset Selection (Ye et al., 2018), the best known LDP algorithms for mean and frequency estimation, to to the order of ε-bits of communication while preserving their privacy and accuracy guarantees.

</p>
</details>

<details><summary><b>Reinforced Workload Distribution Fairness</b>
<a href="https://arxiv.org/abs/2111.00008">arxiv:2111.00008</a>
&#x1F4C8; 1 <br>
<p>Zhiyuan Yao, Zihan Ding, Thomas Heide Clausen</p></summary>
<p>

**Abstract:** Network load balancers are central components in data centers, that distributes workloads across multiple servers and thereby contribute to offering scalable services. However, when load balancers operate in dynamic environments with limited monitoring of application server loads, they rely on heuristic algorithms that require manual configurations for fairness and performance. To alleviate that, this paper proposes a distributed asynchronous reinforcement learning mechanism to-with no active load balancer state monitoring and limited network observations-improve the fairness of the workload distribution achieved by a load balancer. The performance of proposed mechanism is evaluated and compared with stateof-the-art load balancing algorithms in a simulator, under configurations with progressively increasing complexities. Preliminary results show promise in RLbased load balancing algorithms, and identify additional challenges and future research directions, including reward function design and model scalability.

</p>
</details>

<details><summary><b>Landscape analysis of an improved power method for tensor decomposition</b>
<a href="https://arxiv.org/abs/2110.15821">arxiv:2110.15821</a>
&#x1F4C8; 1 <br>
<p>Joe Kileel, Timo Klock, João M. Pereira</p></summary>
<p>

**Abstract:** In this work, we consider the optimization formulation for symmetric tensor decomposition recently introduced in the Subspace Power Method (SPM) of Kileel and Pereira. Unlike popular alternative functionals for tensor decomposition, the SPM objective function has the desirable properties that its maximal value is known in advance, and its global optima are exactly the rank-1 components of the tensor when the input is sufficiently low-rank. We analyze the non-convex optimization landscape associated with the SPM objective. Our analysis accounts for working with noisy tensors. We derive quantitative bounds such that any second-order critical point with SPM objective value exceeding the bound must equal a tensor component in the noiseless case, and must approximate a tensor component in the noisy case. For decomposing tensors of size $D^{\times m}$, we obtain a near-global guarantee up to rank $\widetilde{o}(D^{\lfloor m/2 \rfloor})$ under a random tensor model, and a global guarantee up to rank $\mathcal{O}(D)$ assuming deterministic frame conditions. This implies that SPM with suitable initialization is a provable, efficient, robust algorithm for low-rank symmetric tensor decomposition. We conclude with numerics that show a practical preferability for using the SPM functional over a more established counterpart.

</p>
</details>

<details><summary><b>On Structural Parameterizations of the Offensive Alliance Problem</b>
<a href="https://arxiv.org/abs/2110.15757">arxiv:2110.15757</a>
&#x1F4C8; 1 <br>
<p>Ajinkya Gaikwad, Soumen Maity</p></summary>
<p>

**Abstract:** The Offensive Alliance problem has been studied extensively during the last twenty years. A set $S\subseteq V$ of vertices is an offensive alliance in an undirected graph $G=(V,E)$ if each $v\in N(S)$ has at least as many neighbours in $S$ as it has neighbours (including itself) not in $S$. We study the parameterized complexity of the Offensive Alliance problem, where the aim is to find a minimum size offensive alliance. Our focus here lies on parameters that measure the structural properties of the input instance. We enhance our understanding of the problem from the viewpoint of parameterized complexity by showing that the problem is W[1]-hard parameterized by a wide range of fairly restrictive structural parameters such as the feedback vertex set number, treewidth, pathwidth, and treedepth of the input graph.

</p>
</details>

<details><summary><b>DeF-DReL: Systematic Deployment of Serverless Functions in Fog and Cloud environments using Deep Reinforcement Learning</b>
<a href="https://arxiv.org/abs/2110.15702">arxiv:2110.15702</a>
&#x1F4C8; 1 <br>
<p>Chinmaya Kumar Dehury, Shivananda Poojara, Shridhar Domanal, Satish Narayana Srirama</p></summary>
<p>

**Abstract:** Fog computing is introduced by shifting cloud resources towards the users' proximity to mitigate the limitations possessed by cloud computing. Fog environment made its limited resource available to a large number of users to deploy their serverless applications, composed of several serverless functions. One of the primary intentions behind introducing the fog environment is to fulfil the demand of latency and location-sensitive serverless applications through its limited resources. The recent research mainly focuses on assigning maximum resources to such applications from the fog node and not taking full advantage of the cloud environment. This introduces a negative impact in providing the resources to a maximum number of connected users. To address this issue, in this paper, we investigated the optimum percentage of a user's request that should be fulfilled by fog and cloud. As a result, we proposed DeF-DReL, a Systematic Deployment of Serverless Functions in Fog and Cloud environments using Deep Reinforcement Learning, using several real-life parameters, such as distance and latency of the users from nearby fog node, user's priority, the priority of the serverless applications and their resource demand, etc. The performance of the DeF-DReL algorithm is further compared with recent related algorithms. From the simulation and comparison results, its superiority over other algorithms and its applicability to the real-life scenario can be clearly observed.

</p>
</details>

<details><summary><b>Improved FRQI on superconducting processors and its restrictions in the NISQ era</b>
<a href="https://arxiv.org/abs/2110.15672">arxiv:2110.15672</a>
&#x1F4C8; 1 <br>
<p>Alexander Geng, Ali Moghiseh, Claudia Redenbach, Katja Schladitz</p></summary>
<p>

**Abstract:** In image processing, the amount of data to be processed grows rapidly, in particular when imaging methods yield images of more than two dimensions or time series of images. Thus, efficient processing is a challenge, as data sizes may push even supercomputers to their limits. Quantum image processing promises to encode images with logarithmically less qubits than classical pixels in the image. In theory, this is a huge progress, but so far not many experiments have been conducted in practice, in particular on real backends. Often, the precise conversion of classical data to quantum states, the exact implementation, and the interpretation of the measurements in the classical context are challenging. We investigate these practical questions in this paper. In particular, we study the feasibility of the Flexible Representation of Quantum Images (FRQI). Furthermore, we check experimentally what is the limit in the current noisy intermediate-scale quantum era, i.e. up to which image size an image can be encoded, both on simulators and on real backends. Finally, we propose a method for simplifying the circuits needed for the FRQI. With our alteration, the number of gates needed, especially of the error-prone controlled-NOT gates, can be reduced. As a consequence, the size of manageable images increases.

</p>
</details>

<details><summary><b>QDCNN: Quantum Dilated Convolutional Neural Network</b>
<a href="https://arxiv.org/abs/2110.15667">arxiv:2110.15667</a>
&#x1F4C8; 1 <br>
<p>Yixiong Chen</p></summary>
<p>

**Abstract:** In recent years, with rapid progress in the development of quantum technologies, quantum machine learning has attracted a lot of interest. In particular, a family of hybrid quantum-classical neural networks, consisting of classical and quantum elements, has been massively explored for the purpose of improving the performance of classical neural networks. In this paper, we propose a novel hybrid quantum-classical algorithm called quantum dilated convolutional neural networks (QDCNNs). Our method extends the concept of dilated convolution, which has been widely applied in modern deep learning algorithms, to the context of hybrid neural networks. The proposed QDCNNs are able to capture larger context during the quantum convolution process while reducing the computational cost. We perform empirical experiments on MNIST and Fashion-MNIST datasets for the task of image recognition and demonstrate that QDCNN models generally enjoy better performances in terms of both accuracy and computation efficiency compared to existing quantum convolutional neural networks (QCNNs).

</p>
</details>

<details><summary><b>A Comprehensive Study on Learning-Based PE Malware Family Classification Methods</b>
<a href="https://arxiv.org/abs/2110.15552">arxiv:2110.15552</a>
&#x1F4C8; 1 <br>
<p>Yixuan Ma, Shuang Liu, Jiajun Jiang, Guanhong Chen, Keqiu Li</p></summary>
<p>

**Abstract:** Driven by the high profit, Portable Executable (PE) malware has been consistently evolving in terms of both volume and sophistication. PE malware family classification has gained great attention and a large number of approaches have been proposed. With the rapid development of machine learning techniques and the exciting results they achieved on various tasks, machine learning algorithms have also gained popularity in the PE malware family classification task. Three mainstream approaches that use learning based algorithms, as categorized by the input format the methods take, are image-based, binary-based and disassembly-based approaches. Although a large number of approaches are published, there is no consistent comparisons on those approaches, especially from the practical industry adoption perspective. Moreover, there is no comparison in the scenario of concept drift, which is a fact for the malware classification task due to the fast evolving nature of malware. In this work, we conduct a thorough empirical study on learning-based PE malware classification approaches on 4 different datasets and consistent experiment settings. Based on the experiment results and an interview with our industry partners, we find that (1) there is no individual class of methods that significantly outperforms the others; (2) All classes of methods show performance degradation on concept drift (by an average F1-score of 32.23%); and (3) the prediction time and high memory consumption hinder existing approaches from being adopted for industry usage.

</p>
</details>

<details><summary><b>Systematic Review for AI-based Language Learning Tools</b>
<a href="https://arxiv.org/abs/2111.04455">arxiv:2111.04455</a>
&#x1F4C8; 0 <br>
<p>Jin Ha Woo, Heeyoul Choi</p></summary>
<p>

**Abstract:** The Second Language Acquisition field has been significantly impacted by a greater emphasis on individualized learning and rapid developments in artificial intelligence (AI). Although increasingly adaptive language learning tools are being developed with the application of AI to the Computer Assisted Language Learning field, there have been concerns regarding insufficient information and teacher preparation. To effectively utilize these tools, teachers need an in-depth overview on recently developed AI-based language learning tools. Therefore, this review synthesized information on AI tools that were developed between 2017 and 2020. A majority of these tools utilized machine learning and natural language processing, and were used to identify errors, provide feedback, and assess language abilities. After using these tools, learners demonstrated gains in their language abilities and knowledge. This review concludes by presenting pedagogical implications and emerging themes in the future research of AI-based language learning tools.

</p>
</details>


[Next Page](2021/2021-10/2021-10-28.md)
