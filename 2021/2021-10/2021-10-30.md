## Summary for 2021-10-30, created on 2021-12-14


<details><summary><b>Mastering Atari Games with Limited Data</b>
<a href="https://arxiv.org/abs/2111.00210">arxiv:2111.00210</a>
&#x1F4C8; 272 <br>
<p>Weirui Ye, Shaohuai Liu, Thanard Kurutach, Pieter Abbeel, Yang Gao</p></summary>
<p>

**Abstract:** Reinforcement learning has achieved great success in many applications. However, sample efficiency remains a key challenge, with prominent methods requiring millions (or even billions) of environment steps to train. Recently, there has been significant progress in sample efficient image-based RL algorithms; however, consistent human-level performance on the Atari game benchmark remains an elusive goal. We propose a sample efficient model-based visual RL algorithm built on MuZero, which we name EfficientZero. Our method achieves 194.3% mean human performance and 109.0% median performance on the Atari 100k benchmark with only two hours of real-time game experience and outperforms the state SAC in some tasks on the DMControl 100k benchmark. This is the first time an algorithm achieves super-human performance on Atari games with such little data. EfficientZero's performance is also close to DQN's performance at 200 million frames while we consume 500 times less data. EfficientZero's low sample complexity and high performance can bring RL closer to real-world applicability. We implement our algorithm in an easy-to-understand manner and it is available at https://github.com/YeWR/EfficientZero. We hope it will accelerate the research of MCTS-based RL algorithms in the wider community.

</p>
</details>

<details><summary><b>Sustainable AI: Environmental Implications, Challenges and Opportunities</b>
<a href="https://arxiv.org/abs/2111.00364">arxiv:2111.00364</a>
&#x1F4C8; 42 <br>
<p>Carole-Jean Wu, Ramya Raghavendra, Udit Gupta, Bilge Acun, Newsha Ardalani, Kiwan Maeng, Gloria Chang, Fiona Aga Behram, James Huang, Charles Bai, Michael Gschwind, Anurag Gupta, Myle Ott, Anastasia Melnikov, Salvatore Candido, David Brooks, Geeta Chauhan, Benjamin Lee, Hsien-Hsin S. Lee, Bugra Akyildiz, Maximilian Balandat, Joe Spisak, Ravi Jain, Mike Rabbat, Kim Hazelwood</p></summary>
<p>

**Abstract:** This paper explores the environmental impact of the super-linear growth trends for AI from a holistic perspective, spanning Data, Algorithms, and System Hardware. We characterize the carbon footprint of AI computing by examining the model development cycle across industry-scale machine learning use cases and, at the same time, considering the life cycle of system hardware. Taking a step further, we capture the operational and manufacturing carbon footprint of AI computing and present an end-to-end analysis for what and how hardware-software design and at-scale optimization can help reduce the overall carbon footprint of AI. Based on the industry experience and lessons learned, we share the key challenges and chart out important development directions across the many dimensions of AI. We hope the key messages and insights presented in this paper can inspire the community to advance the field of AI in an environmentally-responsible manner.

</p>
</details>

<details><summary><b>Cross-Modality Fusion Transformer for Multispectral Object Detection</b>
<a href="https://arxiv.org/abs/2111.00273">arxiv:2111.00273</a>
&#x1F4C8; 10 <br>
<p>Fang Qingyun, Han Dapeng, Wang Zhaokui</p></summary>
<p>

**Abstract:** Multispectral image pairs can provide the combined information, making object detection applications more reliable and robust in the open world. To fully exploit the different modalities, we present a simple yet effective cross-modality feature fusion approach, named Cross-Modality Fusion Transformer (CFT) in this paper. Unlike prior CNNs-based works, guided by the transformer scheme, our network learns long-range dependencies and integrates global contextual information in the feature extraction stage. More importantly, by leveraging the self attention of the transformer, the network can naturally carry out simultaneous intra-modality and inter-modality fusion, and robustly capture the latent interactions between RGB and Thermal domains, thereby significantly improving the performance of multispectral object detection. Extensive experiments and ablation studies on multiple datasets demonstrate that our approach is effective and achieves state-of-the-art detection performance. Our code and models are available at https://github.com/DocF/multispectral-object-detection.

</p>
</details>

<details><summary><b>3DP3: 3D Scene Perception via Probabilistic Programming</b>
<a href="https://arxiv.org/abs/2111.00312">arxiv:2111.00312</a>
&#x1F4C8; 7 <br>
<p>Nishad Gothoskar, Marco Cusumano-Towner, Ben Zinberg, Matin Ghavamizadeh, Falk Pollok, Austin Garrett, Joshua B. Tenenbaum, Dan Gutfreund, Vikash K. Mansinghka</p></summary>
<p>

**Abstract:** We present 3DP3, a framework for inverse graphics that uses inference in a structured generative model of objects, scenes, and images. 3DP3 uses (i) voxel models to represent the 3D shape of objects, (ii) hierarchical scene graphs to decompose scenes into objects and the contacts between them, and (iii) depth image likelihoods based on real-time graphics. Given an observed RGB-D image, 3DP3's inference algorithm infers the underlying latent 3D scene, including the object poses and a parsimonious joint parametrization of these poses, using fast bottom-up pose proposals, novel involutive MCMC updates of the scene graph structure, and, optionally, neural object detectors and pose estimators. We show that 3DP3 enables scene understanding that is aware of 3D shape, occlusion, and contact structure. Our results demonstrate that 3DP3 is more accurate at 6DoF object pose estimation from real images than deep learning baselines and shows better generalization to challenging scenes with novel viewpoints, contact, and partial observability.

</p>
</details>

<details><summary><b>Hierarchical Heterogeneous Graph Representation Learning for Short Text Classification</b>
<a href="https://arxiv.org/abs/2111.00180">arxiv:2111.00180</a>
&#x1F4C8; 7 <br>
<p>Yaqing Wang, Song Wang, Quanming Yao, Dejing Dou</p></summary>
<p>

**Abstract:** Short text classification is a fundamental task in natural language processing. It is hard due to the lack of context information and labeled data in practice. In this paper, we propose a new method called SHINE, which is based on graph neural network (GNN), for short text classification. First, we model the short text dataset as a hierarchical heterogeneous graph consisting of word-level component graphs which introduce more semantic and syntactic information. Then, we dynamically learn a short document graph that facilitates effective label propagation among similar short texts. Thus, compared with existing GNN-based methods, SHINE can better exploit interactions between nodes of the same types and capture similarities between short texts. Extensive experiments on various benchmark short text datasets show that SHINE consistently outperforms state-of-the-art methods, especially with fewer labels.

</p>
</details>

<details><summary><b>A Simple Approach to Image Tilt Correction with Self-Attention MobileNet for Smartphones</b>
<a href="https://arxiv.org/abs/2111.00398">arxiv:2111.00398</a>
&#x1F4C8; 6 <br>
<p>Siddhant Garg, Debi Prasanna Mohanty, Siva Prasad Thota, Sukumar Moharana</p></summary>
<p>

**Abstract:** The main contributions of our work are two-fold. First, we present a Self-Attention MobileNet, called SA-MobileNet Network that can model long-range dependencies between the image features instead of processing the local region as done by standard convolutional kernels. SA-MobileNet contains self-attention modules integrated with the inverted bottleneck blocks of the MobileNetV3 model which results in modeling of both channel-wise attention and spatial attention of the image features and at the same time introduce a novel self-attention architecture for low-resource devices. Secondly, we propose a novel training pipeline for the task of image tilt detection. We treat this problem in a multi-label scenario where we predict multiple angles for a tilted input image in a narrow interval of range 1-2 degrees, depending on the dataset used. This process induces an implicit correlation between labels without any computational overhead of the second or higher-order methods in multi-label learning. With the combination of our novel approach and the architecture, we present state-of-the-art results on detecting the image tilt angle on mobile devices as compared to the MobileNetV3 model. Finally, we establish that SA-MobileNet is more accurate than MobileNetV3 on SUN397, NYU-V1, and ADE20K datasets by 6.42%, 10.51%, and 9.09% points respectively, and faster by at least 4 milliseconds on Snapdragon 750 Octa-core.

</p>
</details>

<details><summary><b>EfficientWord-Net: An Open Source Hotword Detection Engine based on One-shot Learning</b>
<a href="https://arxiv.org/abs/2111.00379">arxiv:2111.00379</a>
&#x1F4C8; 6 <br>
<p>Chidhambararajan R, Aman Rangaur, Sibi Chakkaravarthy Sethuraman</p></summary>
<p>

**Abstract:** Voice assistants like Siri, Google Assistant, Alexa etc. are used widely across the globe for home automation, these require the use of special phrases also known as hotwords to wake it up and perform an action like "Hey Alexa!", "Ok Google!" and "Hey Siri!" etc. These hotwords are detected with lightweight real-time engines whose purpose is to detect the hotwords uttered by the user. This paper presents the design and implementation of a hotword detection engine based on one-shot learning which detects the hotword uttered by the user in real-time with just one or few training samples of the hotword. This approach is efficient when compared to existing implementations because the process of adding a new hotword in the existing systems requires enormous amounts of positive and negative training samples and the model needs to retrain for every hotword. This makes the existing implementations inefficient in terms of computation and cost. The architecture proposed in this paper has achieved an accuracy of 94.51%.

</p>
</details>

<details><summary><b>Overcoming Catastrophic Forgetting in Incremental Few-Shot Learning by Finding Flat Minima</b>
<a href="https://arxiv.org/abs/2111.01549">arxiv:2111.01549</a>
&#x1F4C8; 5 <br>
<p>Guangyuan Shi, Jiaxin Chen, Wenlong Zhang, Li-Ming Zhan, Xiao-Ming Wu</p></summary>
<p>

**Abstract:** This paper considers incremental few-shot learning, which requires a model to continually recognize new categories with only a few examples provided. Our study shows that existing methods severely suffer from catastrophic forgetting, a well-known problem in incremental learning, which is aggravated due to data scarcity and imbalance in the few-shot setting. Our analysis further suggests that to prevent catastrophic forgetting, actions need to be taken in the primitive stage -- the training of base classes instead of later few-shot learning sessions. Therefore, we propose to search for flat local minima of the base training objective function and then fine-tune the model parameters within the flat region on new tasks. In this way, the model can efficiently learn new classes while preserving the old ones. Comprehensive experimental results demonstrate that our approach outperforms all prior state-of-the-art methods and is very close to the approximate upper bound. The source code is available at https://github.com/moukamisama/F2M.

</p>
</details>

<details><summary><b>Backdoor Pre-trained Models Can Transfer to All</b>
<a href="https://arxiv.org/abs/2111.00197">arxiv:2111.00197</a>
&#x1F4C8; 5 <br>
<p>Lujia Shen, Shouling Ji, Xuhong Zhang, Jinfeng Li, Jing Chen, Jie Shi, Chengfang Fang, Jianwei Yin, Ting Wang</p></summary>
<p>

**Abstract:** Pre-trained general-purpose language models have been a dominating component in enabling real-world natural language processing (NLP) applications. However, a pre-trained model with backdoor can be a severe threat to the applications. Most existing backdoor attacks in NLP are conducted in the fine-tuning phase by introducing malicious triggers in the targeted class, thus relying greatly on the prior knowledge of the fine-tuning task. In this paper, we propose a new approach to map the inputs containing triggers directly to a predefined output representation of the pre-trained NLP models, e.g., a predefined output representation for the classification token in BERT, instead of a target label. It can thus introduce backdoor to a wide range of downstream tasks without any prior knowledge. Additionally, in light of the unique properties of triggers in NLP, we propose two new metrics to measure the performance of backdoor attacks in terms of both effectiveness and stealthiness. Our experiments with various types of triggers show that our method is widely applicable to different fine-tuning tasks (classification and named entity recognition) and to different models (such as BERT, XLNet, BART), which poses a severe threat. Furthermore, by collaborating with the popular online model repository Hugging Face, the threat brought by our method has been confirmed. Finally, we analyze the factors that may affect the attack performance and share insights on the causes of the success of our backdoor attack.

</p>
</details>

<details><summary><b>Progressive observation of Covid-19 vaccination effects on skin-cellular structures by use of Intelligent Laser Speckle Classification (ILSC)</b>
<a href="https://arxiv.org/abs/2111.01682">arxiv:2111.01682</a>
&#x1F4C8; 4 <br>
<p>Ahmet Orun, Fatih Kurugollu</p></summary>
<p>

**Abstract:** We have made a progressive observation of Covid-19 Astra Zeneca Vaccination effect on Skin cellular network and properties by use of well established Intelligent Laser Speckle Classification (ILSC) image based technique and managed to distinguish between three different subjects groups via their laser speckle skin image samplings such as early-vaccinated, late-vaccinated and non-vaccinated individuals. The results have proven that the ILSC technique in association with the optimised Bayesian network is capable of classifying skin changes of vaccinated and non-vaccinated individuals and also of detecting progressive development made on skin cellular properties for a month period.

</p>
</details>

<details><summary><b>Top1 Solution of QQ Browser 2021 Ai Algorithm Competition Track 1 : Multimodal Video Similarity</b>
<a href="https://arxiv.org/abs/2111.01677">arxiv:2111.01677</a>
&#x1F4C8; 4 <br>
<p>Zhuoran Ma, Majing Lou, Xuan Ouyang</p></summary>
<p>

**Abstract:** In this paper, we describe the solution to the QQ Browser 2021 Ai Algorithm Competition (AIAC) Track 1. We use the multi-modal transformer model for the video embedding extraction. In the pretrain phase, we train the model with three tasks, (1) Video Tag Classification (VTC), (2) Mask Language Modeling (MLM) and (3) Mask Frame Modeling (MFM). In the finetune phase, we train the model with video similarity based on rank normalized human labels. Our full pipeline, after ensembling several models, scores 0.852 on the leaderboard, which we achieved the 1st place in the competition. The source codes have been released at Github.

</p>
</details>

<details><summary><b>A robust single-pixel particle image velocimetry based on fully convolutional networks with cross-correlation embedded</b>
<a href="https://arxiv.org/abs/2111.00395">arxiv:2111.00395</a>
&#x1F4C8; 3 <br>
<p>Qi Gao, Hongtao Lin, Han Tu, Haoran Zhu, Runjie Wei, Guoping Zhang, Xueming Shao</p></summary>
<p>

**Abstract:** Particle image velocimetry (PIV) is essential in experimental fluid dynamics. In the current work, we propose a new velocity field estimation paradigm, which achieves a synergetic combination of the deep learning method and the traditional cross-correlation method. Specifically, the deep learning method is used to optimize and correct a coarse velocity guess to achieve a super-resolution calculation. And the cross-correlation method provides the initial velocity field based on a coarse correlation with a large interrogation window. As a reference, the coarse velocity guess helps with improving the robustness of the proposed algorithm. This fully convolutional network with embedded cross-correlation is named as CC-FCN. CC-FCN has two types of input layers, one is for the particle images, and the other is for the initial velocity field calculated using cross-correlation with a coarse resolution. Firstly, two pyramidal modules extract features of particle images and initial velocity field respectively. Then the fusion module appropriately fuses these features. Finally, CC-FCN achieves the super-resolution calculation through a series of deconvolution layers to obtain the single-pixel velocity field. As the supervised learning strategy is considered, synthetic data sets including ground-truth fluid motions are generated to train the network parameters. Synthetic and real experimental PIV data sets are used to test the trained neural network in terms of accuracy, precision, spatial resolution and robustness. The test results show that these attributes of CC-FCN are further improved compared with those of other tested PIV algorithms. The proposed model could therefore provide competitive and robust estimations for PIV experiments.

</p>
</details>

<details><summary><b>AdvCodeMix: Adversarial Attack on Code-Mixed Data</b>
<a href="https://arxiv.org/abs/2111.00350">arxiv:2111.00350</a>
&#x1F4C8; 3 <br>
<p>Sourya Dipta Das, Ayan Basak, Soumil Mandal, Dipankar Das</p></summary>
<p>

**Abstract:** Research on adversarial attacks are becoming widely popular in the recent years. One of the unexplored areas where prior research is lacking is the effect of adversarial attacks on code-mixed data. Therefore, in the present work, we have explained the first generalized framework on text perturbation to attack code-mixed classification models in a black-box setting. We rely on various perturbation techniques that preserve the semantic structures of the sentences and also obscure the attacks from the perception of a human user. The present methodology leverages the importance of a token to decide where to attack by employing various perturbation strategies. We test our strategies on various sentiment classification models trained on Bengali-English and Hindi-English code-mixed datasets, and reduce their F1-scores by nearly 51 % and 53 % respectively, which can be further reduced if a larger number of tokens are perturbed in a given sentence.

</p>
</details>

<details><summary><b>Causal Discovery in Linear Structural Causal Models with Deterministic Relations</b>
<a href="https://arxiv.org/abs/2111.00341">arxiv:2111.00341</a>
&#x1F4C8; 3 <br>
<p>Yuqin Yang, Mohamed Nafea, AmirEmad Ghassami, Negar Kiyavash</p></summary>
<p>

**Abstract:** Linear structural causal models (SCMs) -- in which each observed variable is generated by a subset of the other observed variables as well as a subset of the exogenous sources -- are pervasive in causal inference and casual discovery. However, for the task of causal discovery, existing work almost exclusively focus on the submodel where each observed variable is associated with a distinct source with non-zero variance. This results in the restriction that no observed variable can deterministically depend on other observed variables or latent confounders. In this paper, we extend the results on structure learning by focusing on a subclass of linear SCMs which do not have this property, i.e., models in which observed variables can be causally affected by any subset of the sources, and are allowed to be a deterministic function of other observed variables or latent confounders. This allows for a more realistic modeling of influence or information propagation in systems. We focus on the task of causal discovery form observational data generated from a member of this subclass. We derive a set of necessary and sufficient conditions for unique identifiability of the causal structure. To the best of our knowledge, this is the first work that gives identifiability results for causal discovery under both latent confounding and deterministic relationships. Further, we propose an algorithm for recovering the underlying causal structure when the aforementioned conditions are satisfied. We validate our theoretical results both on synthetic and real datasets.

</p>
</details>

<details><summary><b>Speaker conditioning of acoustic models using affine transformation for multi-speaker speech recognition</b>
<a href="https://arxiv.org/abs/2111.00320">arxiv:2111.00320</a>
&#x1F4C8; 3 <br>
<p>Midia Yousefi, John H. L. Hanse</p></summary>
<p>

**Abstract:** This study addresses the problem of single-channel Automatic Speech Recognition of a target speaker within an overlap speech scenario. In the proposed method, the hidden representations in the acoustic model are modulated by speaker auxiliary information to recognize only the desired speaker. Affine transformation layers are inserted into the acoustic model network to integrate speaker information with the acoustic features. The speaker conditioning process allows the acoustic model to perform computation in the context of target-speaker auxiliary information. The proposed speaker conditioning method is a general approach and can be applied to any acoustic model architecture. Here, we employ speaker conditioning on a ResNet acoustic model. Experiments on the WSJ corpus show that the proposed speaker conditioning method is an effective solution to fuse speaker auxiliary information with acoustic features for multi-speaker speech recognition, achieving +9% and +20% relative WER reduction for clean and overlap speech scenarios, respectively, compared to the original ResNet acoustic model baseline.

</p>
</details>

<details><summary><b>EmpBot: A T5-based Empathetic Chatbot focusing on Sentiments</b>
<a href="https://arxiv.org/abs/2111.00310">arxiv:2111.00310</a>
&#x1F4C8; 3 <br>
<p>Emmanouil Zaranis, Georgios Paraskevopoulos, Athanasios Katsamanis, Alexandros Potamianos</p></summary>
<p>

**Abstract:** In this paper, we introduce EmpBot: an end-to-end empathetic chatbot. Empathetic conversational agents should not only understand what is being discussed, but also acknowledge the implied feelings of the conversation partner and respond appropriately. To this end, we propose a method based on a transformer pretrained language model (T5). Specifically, during finetuning we propose to use three objectives: response language modeling, sentiment understanding, and empathy forcing. The first objective is crucial for generating relevant and coherent responses, while the next ones are significant for acknowledging the sentimental state of the conversational partner and for favoring empathetic responses. We evaluate our model on the EmpatheticDialogues dataset using both automated metrics and human evaluation. The inclusion of the sentiment understanding and empathy forcing auxiliary losses favor empathetic responses, as human evaluation results indicate, comparing with the current state-of-the-art.

</p>
</details>

<details><summary><b>A fast accurate fine-grain object detection model based on YOLOv4 deep neural network</b>
<a href="https://arxiv.org/abs/2111.00298">arxiv:2111.00298</a>
&#x1F4C8; 3 <br>
<p>Arunabha M. Roy, Rikhi Bose, Jayabrata Bhaduri</p></summary>
<p>

**Abstract:** Early identification and prevention of various plant diseases in commercial farms and orchards is a key feature of precision agriculture technology. This paper presents a high-performance real-time fine-grain object detection framework that addresses several obstacles in plant disease detection that hinder the performance of traditional methods, such as, dense distribution, irregular morphology, multi-scale object classes, textural similarity, etc. The proposed model is built on an improved version of the You Only Look Once (YOLOv4) algorithm. The modified network architecture maximizes both detection accuracy and speed by including the DenseNet in the back-bone to optimize feature transfer and reuse, two new residual blocks in the backbone and neck enhance feature extraction and reduce computing cost; the Spatial Pyramid Pooling (SPP) enhances receptive field, and a modified Path Aggregation Network (PANet) preserves fine-grain localized information and improve feature fusion. Additionally, the use of the Hard-Swish function as the primary activation improved the model's accuracy due to better nonlinear feature extraction. The proposed model is tested in detecting four different diseases in tomato plants under various challenging environments. The model outperforms the existing state-of-the-art detection models in detection accuracy and speed. At a detection rate of 70.19 FPS, the proposed model obtained a precision value of $90.33 \%$, F1-score of $93.64 \%$, and a mean average precision ($mAP$) value of $96.29 \%$. Current work provides an effective and efficient method for detecting different plant diseases in complex scenarios that can be extended to different fruit and crop detection, generic disease detection, and various automated agricultural detection processes.

</p>
</details>

<details><summary><b>Get Fooled for the Right Reason: Improving Adversarial Robustness through a Teacher-guided Curriculum Learning Approach</b>
<a href="https://arxiv.org/abs/2111.00295">arxiv:2111.00295</a>
&#x1F4C8; 3 <br>
<p>Anindya Sarkar, Anirban Sarkar, Sowrya Gali, Vineeth N Balasubramanian</p></summary>
<p>

**Abstract:** Current SOTA adversarially robust models are mostly based on adversarial training (AT) and differ only by some regularizers either at inner maximization or outer minimization steps. Being repetitive in nature during the inner maximization step, they take a huge time to train. We propose a non-iterative method that enforces the following ideas during training. Attribution maps are more aligned to the actual object in the image for adversarially robust models compared to naturally trained models. Also, the allowed set of pixels to perturb an image (that changes model decision) should be restricted to the object pixels only, which reduces the attack strength by limiting the attack space. Our method achieves significant performance gains with a little extra effort (10-20%) over existing AT models and outperforms all other methods in terms of adversarial as well as natural accuracy. We have performed extensive experimentation with CIFAR-10, CIFAR-100, and TinyImageNet datasets and reported results against many popular strong adversarial attacks to prove the effectiveness of our method.

</p>
</details>

<details><summary><b>Long-Range Route-planning for Autonomous Vehicles in the Polar Oceans</b>
<a href="https://arxiv.org/abs/2111.00293">arxiv:2111.00293</a>
&#x1F4C8; 3 <br>
<p>Maria Fox, Michael Meredith, J. Alexander Brearley, Dan Jones, Derek Long</p></summary>
<p>

**Abstract:** There is an increasing demand for piloted autonomous underwater vehicles (AUVs) to operate in polar ice conditions. At present, AUVs are deployed from ships and directly human-piloted in these regions, entailing a high carbon cost and limiting the scope of operations. A key requirement for long-term autonomous missions is a long-range route planning capability that is aware of the changing ice conditions. In this paper we address the problem of automating long-range route-planning for AUVs operating in the Southern Ocean. We present the route-planning method and results showing that efficient, ice-avoiding, long-distance traverses can be planned.

</p>
</details>

<details><summary><b>Learning Coordinated Terrain-Adaptive Locomotion by Imitating a Centroidal Dynamics Planner</b>
<a href="https://arxiv.org/abs/2111.00262">arxiv:2111.00262</a>
&#x1F4C8; 3 <br>
<p>Philemon Brakel, Steven Bohez, Leonard Hasenclever, Nicolas Heess, Konstantinos Bousmalis</p></summary>
<p>

**Abstract:** Dynamic quadruped locomotion over challenging terrains with precise foot placements is a hard problem for both optimal control methods and Reinforcement Learning (RL). Non-linear solvers can produce coordinated constraint satisfying motions, but often take too long to converge for online application. RL methods can learn dynamic reactive controllers but require carefully tuned shaping rewards to produce good gaits and can have trouble discovering precise coordinated movements. Imitation learning circumvents this problem and has been used with motion capture data to extract quadruped gaits for flat terrains. However, it would be costly to acquire motion capture data for a very large variety of terrains with height differences. In this work, we combine the advantages of trajectory optimization and learning methods and show that terrain adaptive controllers can be obtained by training policies to imitate trajectories that have been planned over procedural terrains by a non-linear solver. We show that the learned policies transfer to unseen terrains and can be fine-tuned to dynamically traverse challenging terrains that require precise foot placements and are very hard to solve with standard RL.

</p>
</details>

<details><summary><b>Two Heads are Better than One: Geometric-Latent Attention for Point Cloud Classification and Segmentation</b>
<a href="https://arxiv.org/abs/2111.00231">arxiv:2111.00231</a>
&#x1F4C8; 3 <br>
<p>Hanz Cuevas-Velasquez, Antonio Javier Gallego, Robert B. Fisher</p></summary>
<p>

**Abstract:** We present an innovative two-headed attention layer that combines geometric and latent features to segment a 3D scene into semantically meaningful subsets. Each head combines local and global information, using either the geometric or latent features, of a neighborhood of points and uses this information to learn better local relationships. This Geometric-Latent attention layer (Ge-Latto) is combined with a sub-sampling strategy to capture global features. Our method is invariant to permutation thanks to the use of shared-MLP layers, and it can also be used with point clouds with varying densities because the local attention layer does not depend on the neighbor order. Our proposal is simple yet robust, which allows it to achieve competitive results in the ShapeNetPart and ModelNet40 datasets, and the state-of-the-art when segmenting the complex dataset S3DIS, with 69.2% IoU on Area 5, and 89.7% overall accuracy using K-fold cross-validation on the 6 areas.

</p>
</details>

<details><summary><b>Unpaired Learning for High Dynamic Range Image Tone Mapping</b>
<a href="https://arxiv.org/abs/2111.00219">arxiv:2111.00219</a>
&#x1F4C8; 3 <br>
<p>Yael Vinker, Inbar Huberman-Spiegelglas, Raanan Fattal</p></summary>
<p>

**Abstract:** High dynamic range (HDR) photography is becoming increasingly popular and available by DSLR and mobile-phone cameras. While deep neural networks (DNN) have greatly impacted other domains of image manipulation, their use for HDR tone-mapping is limited due to the lack of a definite notion of ground-truth solution, which is needed for producing training data.
  In this paper we describe a new tone-mapping approach guided by the distinct goal of producing low dynamic range (LDR) renditions that best reproduce the visual characteristics of native LDR images. This goal enables the use of an unpaired adversarial training based on unrelated sets of HDR and LDR images, both of which are widely available and easy to acquire.
  In order to achieve an effective training under this minimal requirements, we introduce the following new steps and components: (i) a range-normalizing pre-process which estimates and applies a different level of curve-based compression, (ii) a loss that preserves the input content while allowing the network to achieve its goal, and (iii) the use of a more concise discriminator network, designed to promote the reproduction of low-level attributes native LDR possess.
  Evaluation of the resulting network demonstrates its ability to produce photo-realistic artifact-free tone-mapped images, and state-of-the-art performance on different image fidelity indices and visual distances.

</p>
</details>

<details><summary><b>A Comparative Review of Recent Few-Shot Object Detection Algorithms</b>
<a href="https://arxiv.org/abs/2111.00201">arxiv:2111.00201</a>
&#x1F4C8; 3 <br>
<p>Leng Jiaxu, Chen Taiyue, Gao Xinbo, Yu Yongtao, Wang Ye, Gao Feng, Wang Yue</p></summary>
<p>

**Abstract:** Few-shot object detection, learning to adapt to the novel classes with a few labeled data, is an imperative and long-lasting problem due to the inherent long-tail distribution of real-world data and the urgent demands to cut costs of data collection and annotation. Recently, some studies have explored how to use implicit cues in extra datasets without target-domain supervision to help few-shot detectors refine robust task notions. This survey provides a comprehensive overview from current classic and latest achievements for few-shot object detection to future research expectations from manifold perspectives. In particular, we first propose a data-based taxonomy of the training data and the form of corresponding supervision which are accessed during the training stage. Following this taxonomy, we present a significant review of the formal definition, main challenges, benchmark datasets, evaluation metrics, and learning strategies. In addition, we present a detailed investigation of how to interplay the object detection methods to develop this issue systematically. Finally, we conclude with the current status of few-shot object detection, along with potential research directions for this field.

</p>
</details>

<details><summary><b>Learning Continuous Representation of Audio for Arbitrary Scale Super Resolution</b>
<a href="https://arxiv.org/abs/2111.00195">arxiv:2111.00195</a>
&#x1F4C8; 3 <br>
<p>Jaechang Kim, Yunjoo Lee, Seunghoon Hong, Jungseul Ok</p></summary>
<p>

**Abstract:** Audio super resolution aims to predict the missing high resolution components of the low resolution audio signals. While audio in nature is continuous signal, current approaches treat it as discrete data (i.e., input is defined on discrete time domain), and consider the super resolution over fixed scale factor (i.e., it is required to train a new neural network to change output resolution). To obtain a continuous representation of audio and enable super resolution for arbitrary scale factor, we propose a method of neural implicit representation, coined Local Implicit representation for Super resolution of Arbitrary scale (LISA). Our method locally parameterizes a chunk of audio as a function of continuous time, and represents each chunk with the local latent codes of neighboring chunks so that the function can extrapolate the signal at any time coordinate, i.e., infinite resolution. To learn a continuous representation for audio, we design a self-supervised learning strategy to practice super resolution tasks up to the original resolution by stochastic selection. Our numerical evaluation shows that LISA outperforms the previous fixed-scale methods with a fraction of parameters, but also is capable of arbitrary scale super resolution even beyond the resolution of training data.

</p>
</details>

<details><summary><b>M2MRF: Many-to-Many Reassembly of Features for Tiny Lesion Segmentation in Fundus Images</b>
<a href="https://arxiv.org/abs/2111.00193">arxiv:2111.00193</a>
&#x1F4C8; 3 <br>
<p>Qing Liu, Haotian Liu, Wei Ke, Yixiong Liang</p></summary>
<p>

**Abstract:** Feature reassembly is an essential component in modern CNN-based segmentation approaches, which includes feature downsampling and upsampling operators. Existing operators reassemble multiple features from a small predefined region into one for each target location independently. This may result in loss of spatial information, which could vanish activations caused by tiny lesions particularly when they cluster together. In this paper, we propose a many-to-many reassembly of features (M2MRF). It reassembles features in a dimension-reduced feature space and simultaneously aggregates multiple features inside a large predefined region into multiple target features. In this way, long range spatial dependencies are captured to maintain activations on tiny lesions. Experimental results on two lesion segmentation benchmarks, i.e. DDR and IDRiD, show that (1) our M2MRF outperforms existing feature reassembly operators; (2) equipped with our M2MRF, the HRNetv2 is able to achieve significant better performance to CNN-based segmentation methods and competitive even better performance to two recent transformer-based segmentation methods. Our code is made publicly available at https://github.com/CVIU-CSU/M2MRF-Lesion-Segmentation.

</p>
</details>

<details><summary><b>How should human translation coexist with NMT? Efficient tool for building high quality parallel corpus</b>
<a href="https://arxiv.org/abs/2111.00191">arxiv:2111.00191</a>
&#x1F4C8; 3 <br>
<p>Chanjun Park, Seolhwa Lee, Hyeonseok Moon, Sugyeong Eo, Jaehyung Seo, Heuiseok Lim</p></summary>
<p>

**Abstract:** This paper proposes a tool for efficiently constructing high-quality parallel corpora with minimizing human labor and making this tool publicly available. Our proposed construction process is based on neural machine translation (NMT) to allow for it to not only coexist with human translation, but also improve its efficiency by combining data quality control with human translation in a data-centric approach.

</p>
</details>

<details><summary><b>Use of machine learning in geriatric clinical care for chronic diseases: a systematic literature review</b>
<a href="https://arxiv.org/abs/2111.08441">arxiv:2111.08441</a>
&#x1F4C8; 2 <br>
<p>Avishek Choudhury, Emily Renjilian, Onur Asan</p></summary>
<p>

**Abstract:** Objectives-Geriatric clinical care is a multidisciplinary assessment designed to evaluate older patients (age 65 years and above) functional ability, physical health, and cognitive wellbeing. The majority of these patients suffer from multiple chronic conditions and require special attention. Recently, hospitals utilize various artificial intelligence (AI) systems to improve care for elderly patients. The purpose of this systematic literature review is to understand the current use of AI systems, particularly machine learning (ML), in geriatric clinical care for chronic diseases. Materials and Methods-We restricted our search to eight databases, namely PubMed, WorldCat, MEDLINE, ProQuest, ScienceDirect, SpringerLink, Wiley, and ERIC, to analyze research articles published in English between January 2010 and June 2019. We focused on studies that used ML algorithms in the care of geriatrics patients with chronic conditions. Results-We identified 35 eligible studies and classified in three groups-psychological disorder (n=22), eye diseases (n=6), and others (n=7). This review identified the lack of standardized ML evaluation metrics and the need for data governance specific to health care applications. Conclusion- More studies and ML standardization tailored to health care applications are required to confirm whether ML could aid in improving geriatric clinical care.

</p>
</details>

<details><summary><b>A comparison of mixed-variables Bayesian optimization approaches</b>
<a href="https://arxiv.org/abs/2111.01533">arxiv:2111.01533</a>
&#x1F4C8; 2 <br>
<p>Jhouben Cuesta-Ramirez, Rodolphe Le Riche, Olivier Roustant, Guillaume Perrin, Cedric Durantin, Alain Gliere</p></summary>
<p>

**Abstract:** Most real optimization problems are defined over a mixed search space where the variables are both discrete and continuous. In engineering applications, the objective function is typically calculated with a numerically costly black-box simulation.General mixed and costly optimization problems are therefore of a great practical interest, yet their resolution remains in a large part an open scientific question. In this article, costly mixed problems are approached through Gaussian processes where the discrete variables are relaxed into continuous latent variables. The continuous space is more easily harvested by classical Bayesian optimization techniques than a mixed space would. Discrete variables are recovered either subsequently to the continuous optimization, or simultaneously with an additional continuous-discrete compatibility constraint that is handled with augmented Lagrangians. Several possible implementations of such Bayesian mixed optimizers are compared. In particular, the reformulation of the problem with continuous latent variables is put in competition with searches working directly in the mixed space. Among the algorithms involving latent variables and an augmented Lagrangian, a particular attention is devoted to the Lagrange multipliers for which a local and a global estimation techniques are studied. The comparisons are based on the repeated optimization of three analytical functions and a beam design problem.

</p>
</details>

<details><summary><b>Dual Attention Network for Heart Rate and Respiratory Rate Estimation</b>
<a href="https://arxiv.org/abs/2111.00390">arxiv:2111.00390</a>
&#x1F4C8; 2 <br>
<p>Yuzhuo Ren, Braeden Syrnyk, Niranjan Avadhanam</p></summary>
<p>

**Abstract:** Heart rate and respiratory rate measurement is a vital step for diagnosing many diseases. Non-contact camera based physiological measurement is more accessible and convenient in Telehealth nowadays than contact instruments such as fingertip oximeters since non-contact methods reduce risk of infection. However, remote physiological signal measurement is challenging due to environment illumination variations, head motion, facial expression, etc. It's also desirable to have a unified network which could estimate both heart rate and respiratory rate to reduce system complexity and latency. We propose a convolutional neural network which leverages spatial attention and channel attention, which we call it dual attention network (DAN) to jointly estimate heart rate and respiratory rate with camera video as input. Extensive experiments demonstrate that our proposed system significantly improves heart rate and respiratory rate measurement accuracy.

</p>
</details>

<details><summary><b>Functional Neural Networks for Parametric Image Restoration Problems</b>
<a href="https://arxiv.org/abs/2111.00361">arxiv:2111.00361</a>
&#x1F4C8; 2 <br>
<p>Fangzhou Luo, Xiaolin Wu, Yanhui Guo</p></summary>
<p>

**Abstract:** Almost every single image restoration problem has a closely related parameter, such as the scale factor in super-resolution, the noise level in image denoising, and the quality factor in JPEG deblocking. Although recent studies on image restoration problems have achieved great success due to the development of deep neural networks, they handle the parameter involved in an unsophisticated way. Most previous researchers either treat problems with different parameter levels as independent tasks, and train a specific model for each parameter level; or simply ignore the parameter, and train a single model for all parameter levels. The two popular approaches have their own shortcomings. The former is inefficient in computing and the latter is ineffective in performance. In this work, we propose a novel system called functional neural network (FuncNet) to solve a parametric image restoration problem with a single model. Unlike a plain neural network, the smallest conceptual element of our FuncNet is no longer a floating-point variable, but a function of the parameter of the problem. This feature makes it both efficient and effective for a parametric problem. We apply FuncNet to super-resolution, image denoising, and JPEG deblocking. The experimental results show the superiority of our FuncNet on all three parametric image restoration tasks over the state of the arts.

</p>
</details>

<details><summary><b>A Survey on the Robustness of Feature Importance and Counterfactual Explanations</b>
<a href="https://arxiv.org/abs/2111.00358">arxiv:2111.00358</a>
&#x1F4C8; 2 <br>
<p>Saumitra Mishra, Sanghamitra Dutta, Jason Long, Daniele Magazzeni</p></summary>
<p>

**Abstract:** There exist several methods that aim to address the crucial task of understanding the behaviour of AI/ML models. Arguably, the most popular among them are local explanations that focus on investigating model behaviour for individual instances. Several methods have been proposed for local analysis, but relatively lesser effort has gone into understanding if the explanations are robust and accurately reflect the behaviour of underlying models. In this work, we present a survey of the works that analysed the robustness of two classes of local explanations (feature importance and counterfactual explanations) that are popularly used in analysing AI/ML models in finance. The survey aims to unify existing definitions of robustness, introduces a taxonomy to classify different robustness approaches, and discusses some interesting results. Finally, the survey introduces some pointers about extending current robustness analysis approaches so as to identify reliable explainability methods.

</p>
</details>

<details><summary><b>Real-time Speaker counting in a cocktail party scenario using Attention-guided Convolutional Neural Network</b>
<a href="https://arxiv.org/abs/2111.00316">arxiv:2111.00316</a>
&#x1F4C8; 2 <br>
<p>Midia Yousefi, John H. L. Hansen</p></summary>
<p>

**Abstract:** Most current speech technology systems are designed to operate well even in the presence of multiple active speakers. However, most solutions assume that the number of co-current speakers is known. Unfortunately, this information might not always be available in real-world applications. In this study, we propose a real-time, single-channel attention-guided Convolutional Neural Network (CNN) to estimate the number of active speakers in overlapping speech. The proposed system extracts higher-level information from the speech spectral content using a CNN model. Next, the attention mechanism summarizes the extracted information into a compact feature vector without losing critical information. Finally, the active speakers are classified using a fully connected network. Experiments on simulated overlapping speech using WSJ corpus show that the attention solution is shown to improve the performance by almost 3% absolute over conventional temporal average pooling. The proposed Attention-guided CNN achieves 76.15% for both Weighted Accuracy and average Recall, and 75.80% Precision on speech segments as short as 20 frames (i.e., 200 ms). All the classification metrics exceed 92% for the attention-guided model in offline scenarios where the input signal is more than 100 frames long (i.e., 1s).

</p>
</details>

<details><summary><b>TargetUM: Targeted High-Utility Itemset Querying</b>
<a href="https://arxiv.org/abs/2111.00309">arxiv:2111.00309</a>
&#x1F4C8; 2 <br>
<p>Jinbao Miao, Shicheng Wan, Wensheng Gan, Jiayi Sun, Jiahui Chen</p></summary>
<p>

**Abstract:** Traditional high-utility itemset mining (HUIM) aims to determine all high-utility itemsets (HUIs) that satisfy the minimum utility threshold (\textit{minUtil}) in transaction databases. However, in most applications, not all HUIs are interesting because only specific parts are required. Thus, targeted mining based on user preferences is more important than traditional mining tasks. This paper is the first to propose a target-based HUIM problem and to provide a clear formulation of the targeted utility mining task in a quantitative transaction database. A tree-based algorithm known as Target-based high-Utility iteMset querying using (TargetUM) is proposed. The algorithm uses a lexicographic querying tree and three effective pruning strategies to improve the mining efficiency. We implemented experimental validation on several real and synthetic databases, and the results demonstrate that the performance of \textbf{TargetUM} is satisfactory, complete, and correct. Finally, owing to the lexicographic querying tree, the database no longer needs to be scanned repeatedly for multiple queries.

</p>
</details>

<details><summary><b>Intrusion Prevention through Optimal Stopping</b>
<a href="https://arxiv.org/abs/2111.00289">arxiv:2111.00289</a>
&#x1F4C8; 2 <br>
<p>Kim Hammar, Rolf Stadler</p></summary>
<p>

**Abstract:** We study automated intrusion prevention using reinforcement learning. Following a novel approach, we formulate the problem of intrusion prevention as an (optimal) multiple stopping problem. This formulation gives us insight into the structure of optimal policies, which we show to have threshold properties. For most practical cases, it is not feasible to obtain an optimal defender policy using dynamic programming. We therefore develop a reinforcement learning approach to approximate an optimal policy. Our method for learning and validating policies includes two systems: a simulation system where defender policies are incrementally learned and an emulation system where statistics are produced that drive simulation runs and where learned policies are evaluated. We show that our approach can produce effective defender policies for a practical IT infrastructure of limited size. Inspection of the learned policies confirms that they exhibit threshold properties.

</p>
</details>

<details><summary><b>Love tHy Neighbour: Remeasuring Local Structural Node Similarity in Hypergraph-Derived Networks</b>
<a href="https://arxiv.org/abs/2111.00256">arxiv:2111.00256</a>
&#x1F4C8; 2 <br>
<p>Govind Sharma, Paarth Gupta, M. Narasihma Murty</p></summary>
<p>

**Abstract:** The problem of node-similarity in networks has motivated a plethora of such measures between node-pairs, which make use of the underlying graph structure. However, higher-order relations cannot be losslessly captured by mere graphs and hence, extensions thereof viz. hypergraphs are used instead. Measuring proximity between node pairs in such a setting calls for a revision in the topological measures of similarity, lest the hypergraph structure remains under-exploited. We, in this work, propose a multitude of hypergraph-oriented similarity scores between node-pairs, thereby providing novel solutions to the link prediction problem. As a part of our proposition, we provide theoretical formulations to extend graph-topology based scores to hypergraphs. We compare our scores with graph-based scores (over clique-expansions of hypergraphs into graphs) from the state-of-the-art. Using a combination of the existing graph-based and the proposed hypergraph-based similarity scores as features for a classifier predicts links much better than using the former solely. Experiments on several real-world datasets and both quantitative as well as qualitative analyses on the same exhibit the superiority of the proposed similarity scores over the existing ones.

</p>
</details>

<details><summary><b>On Joint Learning for Solving Placement and Routing in Chip Design</b>
<a href="https://arxiv.org/abs/2111.00234">arxiv:2111.00234</a>
&#x1F4C8; 2 <br>
<p>Ruoyu Cheng, Junchi Yan</p></summary>
<p>

**Abstract:** For its advantage in GPU acceleration and less dependency on human experts, machine learning has been an emerging tool for solving the placement and routing problems, as two critical steps in modern chip design flow. Being still in its early stage, there are fundamental issues: scalability, reward design, and end-to-end learning paradigm etc. To achieve end-to-end placement learning, we first propose a joint learning method termed by DeepPlace for the placement of macros and standard cells, by the integration of reinforcement learning with a gradient based optimization scheme. To further bridge the placement with the subsequent routing task, we also develop a joint learning approach via reinforcement learning to fulfill both macro placement and routing, which is called DeepPR. One key design in our (reinforcement) learning paradigm involves a multi-view embedding model to encode both global graph level and local node level information of the input macros. Moreover, the random network distillation is devised to encourage exploration. Experiments on public chip design benchmarks show that our method can effectively learn from experience and also provides intermediate placement for the post standard cell placement, within few hours for training.

</p>
</details>

<details><summary><b>One Step at a Time: Pros and Cons of Multi-Step Meta-Gradient Reinforcement Learning</b>
<a href="https://arxiv.org/abs/2111.00206">arxiv:2111.00206</a>
&#x1F4C8; 2 <br>
<p>Clment Bonnet, Paul Caron, Thomas Barrett, Ian Davies, Alexandre Laterre</p></summary>
<p>

**Abstract:** Self-tuning algorithms that adapt the learning process online encourage more effective and robust learning. Among all the methods available, meta-gradients have emerged as a promising approach. They leverage the differentiability of the learning rule with respect to some hyper-parameters to adapt them in an online fashion. Although meta-gradients can be accumulated over multiple learning steps to avoid myopic updates, this is rarely used in practice. In this work, we demonstrate that whilst multi-step meta-gradients do provide a better learning signal in expectation, this comes at the cost of a significant increase in variance, hindering performance. In the light of this analysis, we introduce a novel method mixing multiple inner steps that enjoys a more accurate and robust meta-gradient signal, essentially trading off bias and variance in meta-gradient estimation. When applied to the Snake game, the mixing meta-gradient algorithm can cut the variance by a factor of 3 while achieving similar or higher performance.

</p>
</details>

<details><summary><b>Convergence and Optimality of Policy Gradient Methods in Weakly Smooth Settings</b>
<a href="https://arxiv.org/abs/2111.00185">arxiv:2111.00185</a>
&#x1F4C8; 2 <br>
<p>Matthew Shunshi Zhang, Murat Erdogdu, Animesh Garg</p></summary>
<p>

**Abstract:** Policy gradient methods have been frequently applied to problems in control and reinforcement learning with great success, yet existing convergence analysis still relies on non-intuitive, impractical and often opaque conditions. In particular, existing rates are achieved in limited settings, under strict smoothness and bounded conditions. In this work, we establish explicit convergence rates of policy gradient methods without relying on these conditions, instead extending the convergence regime to weakly smooth policy classes with $L_2$ integrable gradient. We provide intuitive examples to illustrate the insight behind these new conditions. We also characterize the sufficiency conditions for the ergodicity of near-linear MDPs, which represent an important class of problems. Notably, our analysis also shows that fast convergence rates are achievable for both the standard policy gradient and the natural policy gradient algorithms under these assumptions. Lastly we provide conditions and analysis for optimality of the converged policies.

</p>
</details>

<details><summary><b>Simultaneous estimation of wall and object parameters in TWR using deep neural network</b>
<a href="https://arxiv.org/abs/2111.04568">arxiv:2111.04568</a>
&#x1F4C8; 1 <br>
<p>Fardin Ghorbani, Hossein Soleimani</p></summary>
<p>

**Abstract:** This paper presents a deep learning model for simultaneously estimating target and wall parameters in Through-the-Wall Radar. In this work, we consider two modes: single-target and two-targets. In both cases, we consider the permittivity and thickness for the wall, as well as the two-dimensional coordinates of the target's center and permittivity. This means that in the case of a single target, we estimate five values, whereas, in the case of two targets, we estimate eight values simultaneously, each of which represents the mentioned parameters. We discovered that when using deep neural networks to solve the target locating problem, giving the model more parameters of the problem increases the location accuracy. As a result, we included two wall parameters in the problem and discovered that the accuracy of target locating improves while the wall parameters are estimated. We were able to estimate the parameters of wall permittivity and thickness, as well as two-dimensional coordinates and permittivity of targets in single-target and two-target modes with 99\% accuracy by using a deep neural network model.

</p>
</details>

<details><summary><b>Use of low-fidelity models with machine-learning error correction for well placement optimization</b>
<a href="https://arxiv.org/abs/2111.02960">arxiv:2111.02960</a>
&#x1F4C8; 1 <br>
<p>Haoyu Tang, Louis J. Durlofsky</p></summary>
<p>

**Abstract:** Well placement optimization is commonly performed using population-based global stochastic search algorithms. These optimizations are computationally expensive due to the large number of multiphase flow simulations that must be conducted. In this work, we present an optimization framework in which these simulations are performed with low-fidelity (LF) models. These LF models are constructed from the underlying high-fidelity (HF) geomodel using a global transmissibility upscaling procedure. Tree-based machine-learning methods, specifically random forest and light gradient boosting machine, are applied to estimate the error in objective function value (in this case net present value, NPV) associated with the LF models. In the offline (preprocessing) step, preliminary optimizations are performed using LF models, and a clustering procedure is applied to select a representative set of 100--150 well configurations to use for training. HF simulation is then performed for these configurations, and the tree-based models are trained using an appropriate set of features. In the online (runtime) step, optimization with LF models, with the machine-learning correction, is conducted. Differential evolution is used for all optimizations. Results are presented for two example cases involving the placement of vertical wells in 3D bimodal channelized geomodels. We compare the performance of our procedure to optimization using HF models. In the first case, 25 optimization runs are performed with both approaches. Our method provides an overall speedup factor of 46 relative to optimization using HF models, with the best-case NPV within 1% of the HF result. In the second case fewer HF optimization runs are conducted (consistent with actual practice), and the overall speedup factor with our approach is about 8. In this case, the best-case NPV from our procedure exceeds the HF result by 3.8%

</p>
</details>

<details><summary><b>Multi-Task Learning based Convolutional Models with Curriculum Learning for the Anisotropic Reynolds Stress Tensor in Turbulent Duct Flow</b>
<a href="https://arxiv.org/abs/2111.00328">arxiv:2111.00328</a>
&#x1F4C8; 1 <br>
<p>Haitz Sez de Ocriz Borde, David Sondak, Pavlos Protopapas</p></summary>
<p>

**Abstract:** The Reynolds-averaged Navier-Stokes (RANS) equations require accurate modeling of the anisotropic Reynolds stress tensor, for which traditional closure models only give good results in certain flow configurations. Researchers have started using machine learning approaches to address this problem. In this work we build upon recent convolutional neural network architectures used for turbulence modeling and propose a multi-task learning based fully convolutional neural network that is able to accurately predict the normalized anisotropic Reynolds stress tensor for turbulent duct flow. Furthermore, we also explore the application of curriculum learning to data-driven turbulence modeling.

</p>
</details>

<details><summary><b>Beyond Independent Measurements: General Compressed Sensing with GNN Application</b>
<a href="https://arxiv.org/abs/2111.00327">arxiv:2111.00327</a>
&#x1F4C8; 1 <br>
<p>Alireza Naderi, Yaniv Plan</p></summary>
<p>

**Abstract:** We consider the problem of recovering a structured signal $\mathbf{x} \in \mathbb{R}^{n}$ from noisy linear observations $\mathbf{y} =\mathbf{M} \mathbf{x}+\mathbf{w}$. The measurement matrix is modeled as $\mathbf{M} = \mathbf{B}\mathbf{A}$, where $\mathbf{B} \in \mathbb{R}^{l \times m}$ is arbitrary and $\mathbf{A} \in \mathbb{R}^{m \times n}$ has independent sub-gaussian rows. By varying $\mathbf{B}$, and the sub-gaussian distribution of $\mathbf{A}$, this gives a family of measurement matrices which may have heavy tails, dependent rows and columns, and singular values with a large dynamic range. When the structure is given as a possibly non-convex cone $T \subset \mathbb{R}^{n}$, an approximate empirical risk minimizer is proven to be a robust estimator if the effective number of measurements is sufficient, even in the presence of a model mismatch. In classical compressed sensing with independent (sub-)gaussian measurements, one asks how many measurements are needed to recover $\mathbf{x}$? In our setting, however, the effective number of measurements depends on the properties of $\mathbf{B}$. We show that the effective rank of $\mathbf{B}$ may be used as a surrogate for the number of measurements, and if this exceeds the squared Gaussian mean width of $(T-T) \cap \mathbb{S}^{n-1}$, then accurate recovery is guaranteed. Furthermore, we examine the special case of generative priors in detail, that is when $\mathbf{x}$ lies close to $T = \mathrm{ran}(G)$ and $G: \mathbb{R}^k \rightarrow \mathbb{R}^n$ is a Generative Neural Network (GNN) with ReLU activation functions. Our work relies on a recent result in random matrix theory by Jeong, Li, Plan, and Yilmaz arXiv:2001.10631. .

</p>
</details>

<details><summary><b>Approximation properties of Residual Neural Networks for Kolmogorov PDEs</b>
<a href="https://arxiv.org/abs/2111.00215">arxiv:2111.00215</a>
&#x1F4C8; 1 <br>
<p>Jonas Baggenstos, Diyora Salimova</p></summary>
<p>

**Abstract:** In recent years residual neural networks (ResNets) as introduced by [He, K., Zhang, X., Ren, S., and Sun, J., Proceedings of the IEEE conference on computer vision and pattern recognition (2016), 770-778] have become very popular in a large number of applications, including in image classification and segmentation. They provide a new perspective in training very deep neural networks without suffering the vanishing gradient problem. In this article we show that ResNets are able to approximate solutions of Kolmogorov partial differential equations (PDEs) with constant diffusion and possibly nonlinear drift coefficients without suffering the curse of dimensionality, which is to say the number of parameters of the approximating ResNets grows at most polynomially in the reciprocal of the approximation accuracy $\varepsilon > 0$ and the dimension of the considered PDE $d\in\mathbb{N}$. We adapt a proof in [Jentzen, A., Salimova, D., and Welti, T., Commun. Math. Sci. 19, 5 (2021), 1167-1205] - who showed a similar result for feedforward neural networks (FNNs) - to ResNets. In contrast to FNNs, the Euler-Maruyama approximation structure of ResNets simplifies the construction of the approximating ResNets substantially. Moreover, contrary to the above work, in our proof using ResNets does not require the existence of an FNN (or a ResNet) representing the identity map, which enlarges the set of applicable activation functions.

</p>
</details>


[Next Page](2021/2021-10/2021-10-29.md)
