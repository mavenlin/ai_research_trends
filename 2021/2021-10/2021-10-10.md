## Summary for 2021-10-10, created on 2021-12-15


<details><summary><b>Yuan 1.0: Large-Scale Pre-trained Language Model in Zero-Shot and Few-Shot Learning</b>
<a href="https://arxiv.org/abs/2110.04725">arxiv:2110.04725</a>
&#x1F4C8; 33 <br>
<p>Shaohua Wu, Xudong Zhao, Tong Yu, Rongguo Zhang, Chong Shen, Hongli Liu, Feng Li, Hong Zhu, Jiangang Luo, Liang Xu, Xuanwei Zhang</p></summary>
<p>

**Abstract:** Recent work like GPT-3 has demonstrated excellent performance of Zero-Shot and Few-Shot learning on many natural language processing (NLP) tasks by scaling up model size, dataset size and the amount of computation. However, training a model like GPT-3 requires huge amount of computational resources which makes it challengeable to researchers. In this work, we propose a method that incorporates large-scale distributed training performance into model architecture design. With this method, Yuan 1.0, the current largest singleton language model with 245B parameters, achieves excellent performance on thousands GPUs during training, and the state-of-the-art results on NLP tasks. A data processing method is designed to efficiently filter massive amount of raw data. The current largest high-quality Chinese corpus with 5TB high quality texts is built based on this method. In addition, a calibration and label expansion method is proposed to improve the Zero-Shot and Few-Shot performance, and steady improvement is observed on the accuracy of various tasks. Yuan 1.0 presents strong capacity of natural language generation, and the generated articles are difficult to distinguish from the human-written ones.

</p>
</details>

<details><summary><b>Omnidata: A Scalable Pipeline for Making Multi-Task Mid-Level Vision Datasets from 3D Scans</b>
<a href="https://arxiv.org/abs/2110.04994">arxiv:2110.04994</a>
&#x1F4C8; 22 <br>
<p>Ainaz Eftekhar, Alexander Sax, Roman Bachmann, Jitendra Malik, Amir Zamir</p></summary>
<p>

**Abstract:** This paper introduces a pipeline to parametrically sample and render multi-task vision datasets from comprehensive 3D scans from the real world. Changing the sampling parameters allows one to "steer" the generated datasets to emphasize specific information. In addition to enabling interesting lines of research, we show the tooling and generated data suffice to train robust vision models.
  Common architectures trained on a generated starter dataset reached state-of-the-art performance on multiple common vision tasks and benchmarks, despite having seen no benchmark or non-pipeline data. The depth estimation network outperforms MiDaS and the surface normal estimation network is the first to achieve human-level performance for in-the-wild surface normal estimation -- at least according to one metric on the OASIS benchmark.
  The Dockerized pipeline with CLI, the (mostly python) code, PyTorch dataloaders for the generated data, the generated starter dataset, download scripts and other utilities are available through our project website, https://omnidata.vision.

</p>
</details>

<details><summary><b>Rethinking Noise Synthesis and Modeling in Raw Denoising</b>
<a href="https://arxiv.org/abs/2110.04756">arxiv:2110.04756</a>
&#x1F4C8; 21 <br>
<p>Yi Zhang, Hongwei Qin, Xiaogang Wang, Hongsheng Li</p></summary>
<p>

**Abstract:** The lack of large-scale real raw image denoising dataset gives rise to challenges on synthesizing realistic raw image noise for training denoising models. However, the real raw image noise is contributed by many noise sources and varies greatly among different sensors. Existing methods are unable to model all noise sources accurately, and building a noise model for each sensor is also laborious. In this paper, we introduce a new perspective to synthesize noise by directly sampling from the sensor's real noise. It inherently generates accurate raw image noise for different camera sensors. Two efficient and generic techniques: pattern-aligned patch sampling and high-bit reconstruction help accurate synthesis of spatial-correlated noise and high-bit noise respectively. We conduct systematic experiments on SIDD and ELD datasets. The results show that (1) our method outperforms existing methods and demonstrates wide generalization on different sensors and lighting conditions. (2) Recent conclusions derived from DNN-based noise modeling methods are actually based on inaccurate noise parameters. The DNN-based methods still cannot outperform physics-based statistical methods.

</p>
</details>

<details><summary><b>Denoising Diffusion Gamma Models</b>
<a href="https://arxiv.org/abs/2110.05948">arxiv:2110.05948</a>
&#x1F4C8; 11 <br>
<p>Eliya Nachmani, Robin San Roman, Lior Wolf</p></summary>
<p>

**Abstract:** Generative diffusion processes are an emerging and effective tool for image and speech generation. In the existing methods, the underlying noise distribution of the diffusion process is Gaussian noise. However, fitting distributions with more degrees of freedom could improve the performance of such generative models. In this work, we investigate other types of noise distribution for the diffusion process. Specifically, we introduce the Denoising Diffusion Gamma Model (DDGM) and show that noise from Gamma distribution provides improved results for image and speech generation. Our approach preserves the ability to efficiently sample state in the training diffusion process while using Gamma noise.

</p>
</details>

<details><summary><b>Advances in Multi-turn Dialogue Comprehension: A Survey</b>
<a href="https://arxiv.org/abs/2110.04984">arxiv:2110.04984</a>
&#x1F4C8; 9 <br>
<p>Zhuosheng Zhang, Hai Zhao</p></summary>
<p>

**Abstract:** Training machines to understand natural language and interact with humans is an elusive and essential task of artificial intelligence. A diversity of dialogue systems has been designed with the rapid development of deep learning techniques, especially the recent pre-trained language models (PrLMs). Among these studies, the fundamental yet challenging type of task is dialogue comprehension whose role is to teach the machines to read and comprehend the dialogue context before responding. In this paper, we review the previous methods from the technical perspective of dialogue modeling for the dialogue comprehension task. We summarize the characteristics and challenges of dialogue comprehension in contrast to plain-text reading comprehension. Then, we discuss three typical patterns of dialogue modeling. In addition, we categorize dialogue-related pre-training techniques which are employed to enhance PrLMs in dialogue scenarios. Finally, we highlight the technical advances in recent years and point out the lessons from the empirical analysis and the prospects towards a new frontier of researches.

</p>
</details>

<details><summary><b>Reinforcement Learning for Systematic FX Trading</b>
<a href="https://arxiv.org/abs/2110.04745">arxiv:2110.04745</a>
&#x1F4C8; 8 <br>
<p>Gabriel Borrageiro, Nick Firoozye, Paolo Barucca</p></summary>
<p>

**Abstract:** We explore online, inductive transfer learning, with a feature representation transfer from a radial basis function network, which is formed of Gaussian mixture model hidden processing units, whose output is made available to a direct, recurrent reinforcement learning agent. This recurrent reinforcement learning agent learns a desired position, via the policy gradient reinforcement learning paradigm. This transfer learner is put to work trading the major spot market currency pairs. In our experiment, we accurately account for transaction and funding costs. These sources of profit and loss, including the price trends that occur in the currency markets, are made available to the recurrent reinforcement learner via a quadratic utility, who learns to target a position directly. We improve upon earlier work by casting the problem of learning to target a risk position, in an online transfer learning context. Our agent achieves an annualised portfolio information ratio of 0.52 with compound return of 9.3\%, net of execution and funding cost, over a 7 year test set. This is despite forcing the model to trade at the close of the trading day 5pm EST, when trading costs are statistically the most expensive.

</p>
</details>

<details><summary><b>The Skellam Mechanism for Differentially Private Federated Learning</b>
<a href="https://arxiv.org/abs/2110.04995">arxiv:2110.04995</a>
&#x1F4C8; 7 <br>
<p>Naman Agarwal, Peter Kairouz, Ziyu Liu</p></summary>
<p>

**Abstract:** We introduce the multi-dimensional Skellam mechanism, a discrete differential privacy mechanism based on the difference of two independent Poisson random variables. To quantify its privacy guarantees, we analyze the privacy loss distribution via a numerical evaluation and provide a sharp bound on the Rényi divergence between two shifted Skellam distributions. While useful in both centralized and distributed privacy applications, we investigate how it can be applied in the context of federated learning with secure aggregation under communication constraints. Our theoretical findings and extensive experimental evaluations demonstrate that the Skellam mechanism provides the same privacy-accuracy trade-offs as the continuous Gaussian mechanism, even when the precision is low. More importantly, Skellam is closed under summation and sampling from it only requires sampling from a Poisson distribution -- an efficient routine that ships with all machine learning and data analysis software packages. These features, along with its discrete nature and competitive privacy-accuracy trade-offs, make it an attractive practical alternative to the newly introduced discrete Gaussian mechanism.

</p>
</details>

<details><summary><b>Operationalizing Convolutional Neural Network Architectures for Prohibited Object Detection in X-Ray Imagery</b>
<a href="https://arxiv.org/abs/2110.04906">arxiv:2110.04906</a>
&#x1F4C8; 6 <br>
<p>Thomas W. Webb, Neelanjan Bhowmik, Yona Falinie A. Gaus, Toby P. Breckon</p></summary>
<p>

**Abstract:** The recent advancement in deep Convolutional Neural Network (CNN) has brought insight into the automation of X-ray security screening for aviation security and beyond. Here, we explore the viability of two recent end-to-end object detection CNN architectures, Cascade R-CNN and FreeAnchor, for prohibited item detection by balancing processing time and the impact of image data compression from an operational viewpoint. Overall, we achieve maximal detection performance using a FreeAnchor architecture with a ResNet50 backbone, obtaining mean Average Precision (mAP) of 87.7 and 85.8 for using the OPIXray and SIXray benchmark datasets, showing superior performance over prior work on both. With fewer parameters and less training time, FreeAnchor achieves the highest detection inference speed of ~13 fps (3.9 ms per image). Furthermore, we evaluate the impact of lossy image compression upon detector performance. The CNN models display substantial resilience to the lossy compression, resulting in only a 1.1% decrease in mAP at the JPEG compression level of 50. Additionally, a thorough evaluation of data augmentation techniques is provided, including adaptions of MixUp and CutMix strategy as well as other standard transformations, further improving the detection accuracy.

</p>
</details>

<details><summary><b>Structure learning in polynomial time: Greedy algorithms, Bregman information, and exponential families</b>
<a href="https://arxiv.org/abs/2110.04719">arxiv:2110.04719</a>
&#x1F4C8; 6 <br>
<p>Goutham Rajendran, Bohdan Kivva, Ming Gao, Bryon Aragam</p></summary>
<p>

**Abstract:** Greedy algorithms have long been a workhorse for learning graphical models, and more broadly for learning statistical models with sparse structure. In the context of learning directed acyclic graphs, greedy algorithms are popular despite their worst-case exponential runtime. In practice, however, they are very efficient. We provide new insight into this phenomenon by studying a general greedy score-based algorithm for learning DAGs. Unlike edge-greedy algorithms such as the popular GES and hill-climbing algorithms, our approach is vertex-greedy and requires at most a polynomial number of score evaluations. We then show how recent polynomial-time algorithms for learning DAG models are a special case of this algorithm, thereby illustrating how these order-based algorithms can be rigourously interpreted as score-based algorithms. This observation suggests new score functions and optimality conditions based on the duality between Bregman divergences and exponential families, which we explore in detail. Explicit sample and computational complexity bounds are derived. Finally, we provide extensive experiments suggesting that this algorithm indeed optimizes the score in a variety of settings.

</p>
</details>

<details><summary><b>Batch-Softmax Contrastive Loss for Pairwise Sentence Scoring Tasks</b>
<a href="https://arxiv.org/abs/2110.15725">arxiv:2110.15725</a>
&#x1F4C8; 5 <br>
<p>Anton Chernyavskiy, Dmitry Ilvovsky, Pavel Kalinin, Preslav Nakov</p></summary>
<p>

**Abstract:** The use of contrastive loss for representation learning has become prominent in computer vision, and it is now getting attention in Natural Language Processing (NLP). Here, we explore the idea of using a batch-softmax contrastive loss when fine-tuning large-scale pre-trained transformer models to learn better task-specific sentence embeddings for pairwise sentence scoring tasks. We introduce and study a number of variations in the calculation of the loss as well as in the overall training procedure; in particular, we find that data shuffling can be quite important. Our experimental results show sizable improvements on a number of datasets and pairwise sentence scoring tasks including classification, ranking, and regression. Finally, we offer detailed analysis and discussion, which should be useful for researchers aiming to explore the utility of contrastive loss in NLP.

</p>
</details>

<details><summary><b>Deep convolutional forest: a dynamic deep ensemble approach for spam detection in text</b>
<a href="https://arxiv.org/abs/2110.15718">arxiv:2110.15718</a>
&#x1F4C8; 5 <br>
<p>Mai A. Shaaban, Yasser F. Hassan, Shawkat K. Guirguis</p></summary>
<p>

**Abstract:** The increase in people's use of mobile messaging services has led to the spread of social engineering attacks like phishing, considering that spam text is one of the main factors in the dissemination of phishing attacks to steal sensitive data such as credit cards and passwords. In addition, rumors and incorrect medical information regarding the COVID-19 pandemic are widely shared on social media leading to people's fear and confusion. Thus, filtering spam content is vital to reduce risks and threats. Previous studies relied on machine learning and deep learning approaches for spam classification, but these approaches have two limitations. Machine learning models require manual feature engineering, whereas deep neural networks require a high computational cost. This paper introduces a dynamic deep ensemble model for spam detection that adjusts its complexity and extracts features automatically. The proposed model utilizes convolutional and pooling layers for feature extraction along with base classifiers such as random forests and extremely randomized trees for classifying texts into spam or legitimate ones. Moreover, the model employs ensemble learning procedures like boosting and bagging. As a result, the model achieved high precision, recall, f1-score and accuracy of 98.38%.

</p>
</details>

<details><summary><b>Recurrent Attention Models with Object-centric Capsule Representation for Multi-object Recognition</b>
<a href="https://arxiv.org/abs/2110.04954">arxiv:2110.04954</a>
&#x1F4C8; 5 <br>
<p>Hossein Adeli, Seoyoung Ahn, Gregory Zelinsky</p></summary>
<p>

**Abstract:** The visual system processes a scene using a sequence of selective glimpses, each driven by spatial and object-based attention. These glimpses reflect what is relevant to the ongoing task and are selected through recurrent processing and recognition of the objects in the scene. In contrast, most models treat attention selection and recognition as separate stages in a feedforward process. Here we show that using capsule networks to create an object-centric hidden representation in an encoder-decoder model with iterative glimpse attention yields effective integration of attention and recognition. We evaluate our model on three multi-object recognition tasks; highly overlapping digits, digits among distracting clutter and house numbers, and show that it learns to effectively move its glimpse window, recognize and reconstruct the objects, all with only the classification as supervision. Our work takes a step toward a general architecture for how to integrate recurrent object-centric representation into the planning of attentional glimpses.

</p>
</details>

<details><summary><b>Language Models As or For Knowledge Bases</b>
<a href="https://arxiv.org/abs/2110.04888">arxiv:2110.04888</a>
&#x1F4C8; 5 <br>
<p>Simon Razniewski, Andrew Yates, Nora Kassner, Gerhard Weikum</p></summary>
<p>

**Abstract:** Pre-trained language models (LMs) have recently gained attention for their potential as an alternative to (or proxy for) explicit knowledge bases (KBs). In this position paper, we examine this hypothesis, identify strengths and limitations of both LMs and KBs, and discuss the complementary nature of the two paradigms. In particular, we offer qualitative arguments that latent LMs are not suitable as a substitute for explicit KBs, but could play a major role for augmenting and curating KBs.

</p>
</details>

<details><summary><b>SP-GPT2: Semantics Improvement in Vietnamese Poetry Generation</b>
<a href="https://arxiv.org/abs/2110.15723">arxiv:2110.15723</a>
&#x1F4C8; 4 <br>
<p>Tuan Nguyen, Hanh Pham, Truong Bui, Tan Nguyen, Duc Luong, Phong Nguyen</p></summary>
<p>

**Abstract:** Automatic text generation has garnered growing attention in recent years as an essential step towards computer creativity. Generative Pretraining Transformer 2 (GPT2) is one of the state of the art approaches that have excellent successes. In this paper, we took the first step to investigate the power of GPT2 in traditional Vietnamese poetry generation. In the earlier time, our experiment with base GPT2 was quite good at generating the poem in the proper template. Though it can learn the patterns, including rhyme and tone rules, from the training data, like almost all other text generation approaches, the poems generated still has a topic drift and semantic inconsistency. To improve the cohesion within the poems, we proposed a new model SP-GPT2 (semantic poem GPT2) which was built on the top GPT2 model and an additional loss to constrain context throughout the entire poem. For better evaluation, we examined the methods by both automatic quantitative evaluation and human evaluation. Both automatic and human evaluation demonstrated that our approach can generate poems that have better cohesion without losing the quality due to additional loss. At the same time, we are the pioneers of this topic. We released the first computational scoring module for poems generated in the template containing the style rule dictionary. Additionally, we are the first to publish a Luc-Bat dataset, including 87609 Luc Bat poems, which is equivalent to about 2.6 million sentences, combined with about 83579 poems in other styles was also published for further exploration. The code is available at https://github.com/fsoft-ailab/Poem-Generator

</p>
</details>

<details><summary><b>LaughNet: synthesizing laughter utterances from waveform silhouettes and a single laughter example</b>
<a href="https://arxiv.org/abs/2110.04946">arxiv:2110.04946</a>
&#x1F4C8; 4 <br>
<p>Hieu-Thi Luong, Junichi Yamagishi</p></summary>
<p>

**Abstract:** Emotional and controllable speech synthesis is a topic that has received much attention. However, most studies focused on improving the expressiveness and controllability in the context of linguistic content, even though natural verbal human communication is inseparable from spontaneous non-speech expressions such as laughter, crying, or grunting. We propose a model called LaughNet for synthesizing laughter by using waveform silhouettes as inputs. The motivation is not simply synthesizing new laughter utterances but testing a novel synthesis-control paradigm that uses an abstract representation of the waveform. We conducted basic listening test experiments, and the results showed that LaughNet can synthesize laughter utterances with moderate quality and retain the characteristics of the training example. More importantly, the generated waveforms have shapes similar to the input silhouettes. For future work, we will test the same method on other types of human nonverbal expressions and integrate it into more elaborated synthesis systems.

</p>
</details>

<details><summary><b>Wav2vec-Switch: Contrastive Learning from Original-noisy Speech Pairs for Robust Speech Recognition</b>
<a href="https://arxiv.org/abs/2110.04934">arxiv:2110.04934</a>
&#x1F4C8; 4 <br>
<p>Yiming Wang, Jinyu Li, Heming Wang, Yao Qian, Chengyi Wang, Yu Wu</p></summary>
<p>

**Abstract:** The goal of self-supervised learning (SSL) for automatic speech recognition (ASR) is to learn good speech representations from a large amount of unlabeled speech for the downstream ASR task. However, most SSL frameworks do not consider noise robustness which is crucial for real-world applications. In this paper we propose wav2vec-Switch, a method to encode noise robustness into contextualized representations of speech via contrastive learning. Specifically, we feed original-noisy speech pairs simultaneously into the wav2vec 2.0 network. In addition to the existing contrastive learning task, we switch the quantized representations of the original and noisy speech as additional prediction targets of each other. By doing this, it enforces the network to have consistent predictions for the original and noisy speech, thus allows to learn contextualized representation with noise robustness. Our experiments on synthesized and real noisy data show the effectiveness of our method: it achieves 2.9--4.9% relative word error rate (WER) reduction on the synthesized noisy LibriSpeech data without deterioration on the original data, and 5.7% on CHiME-4 real 1-channel noisy data compared to a data augmentation baseline even with a strong language model for decoding. Our results on CHiME-4 can match or even surpass those with well-designed speech enhancement components.

</p>
</details>

<details><summary><b>Haar Wavelet Feature Compression for Quantized Graph Convolutional Networks</b>
<a href="https://arxiv.org/abs/2110.04824">arxiv:2110.04824</a>
&#x1F4C8; 4 <br>
<p>Moshe Eliasof, Benjamin Bodner, Eran Treister</p></summary>
<p>

**Abstract:** Graph Convolutional Networks (GCNs) are widely used in a variety of applications, and can be seen as an unstructured version of standard Convolutional Neural Networks (CNNs). As in CNNs, the computational cost of GCNs for large input graphs (such as large point clouds or meshes) can be high and inhibit the use of these networks, especially in environments with low computational resources. To ease these costs, quantization can be applied to GCNs. However, aggressive quantization of the feature maps can lead to a significant degradation in performance. On a different note, Haar wavelet transforms are known to be one of the most effective and efficient approaches to compress signals. Therefore, instead of applying aggressive quantization to feature maps, we propose to utilize Haar wavelet compression and light quantization to reduce the computations and the bandwidth involved with the network. We demonstrate that this approach surpasses aggressive feature quantization by a significant margin, for a variety of problems ranging from node classification to point cloud classification and part and semantic segmentation.

</p>
</details>

<details><summary><b>Learning to Learn End-to-End Goal-Oriented Dialog From Related Dialog Tasks</b>
<a href="https://arxiv.org/abs/2110.15724">arxiv:2110.15724</a>
&#x1F4C8; 3 <br>
<p>Janarthanan Rajendran, Jonathan K. Kummerfeld, Satinder Singh</p></summary>
<p>

**Abstract:** For each goal-oriented dialog task of interest, large amounts of data need to be collected for end-to-end learning of a neural dialog system. Collecting that data is a costly and time-consuming process. Instead, we show that we can use only a small amount of data, supplemented with data from a related dialog task. Naively learning from related data fails to improve performance as the related data can be inconsistent with the target task. We describe a meta-learning based method that selectively learns from the related dialog task data. Our approach leads to significant accuracy improvements in an example dialog task.

</p>
</details>

<details><summary><b>Designing off-sample performance metrics</b>
<a href="https://arxiv.org/abs/2110.04996">arxiv:2110.04996</a>
&#x1F4C8; 3 <br>
<p>Matthew J. Holland</p></summary>
<p>

**Abstract:** Modern machine learning systems are traditionally designed and tested with the overall goal of achieving the best possible performance on average. In this work, we consider an approach to building learning systems which treats the question of "how should we quantify good off-sample performance?" as a key design decision. We describe this proposal using a simple and general formulation, place the current dominant paradigm within the proper historical context, and then survey the literature for more recent developments that depart from tradition and can be viewed as special cases of our proposed methodology.

</p>
</details>

<details><summary><b>A Review on Part-of-Speech Technologies</b>
<a href="https://arxiv.org/abs/2110.04977">arxiv:2110.04977</a>
&#x1F4C8; 3 <br>
<p>Onyenwe Ikechukwu, Onyedikachukwu Ikechukwu-Onyenwe, Onyedinma Ebele</p></summary>
<p>

**Abstract:** Developing an automatic part-of-speech (POS) tagging for any new language is considered a necessary step for further computational linguistics methodology beyond tagging, like chunking and parsing, to be fully applied to the language. Many POS disambiguation technologies have been developed for this type of research and there are factors that influence the choice of choosing one. This could be either corpus-based or non-corpus-based. In this paper, we present a review of POS tagging technologies.

</p>
</details>

<details><summary><b>Quadratic Multiform Separation: A New Classification Model in Machine Learning</b>
<a href="https://arxiv.org/abs/2110.04925">arxiv:2110.04925</a>
&#x1F4C8; 3 <br>
<p>Ko-Hui Michael Fan, Chih-Chung Chang, Kuang-Hsiao-Yin Kongguoluo</p></summary>
<p>

**Abstract:** In this paper we present a new classification model in machine learning. Our result is threefold: 1) The model produces comparable predictive accuracy to that of most common classification models. 2) It runs significantly faster than most common classification models. 3) It has the ability to identify a portion of unseen samples for which class labels can be found with much higher predictive accuracy. Currently there are several patents pending on the proposed model.

</p>
</details>

<details><summary><b>High-dimensional Inference for Dynamic Treatment Effects</b>
<a href="https://arxiv.org/abs/2110.04924">arxiv:2110.04924</a>
&#x1F4C8; 3 <br>
<p>Jelena Bradic, Weijie Ji, Yuqian Zhang</p></summary>
<p>

**Abstract:** This paper proposes a confidence interval construction for heterogeneous treatment effects in the context of multi-stage experiments with $N$ samples and high-dimensional, $d$, confounders. Our focus is on the case of $d\gg N$, but the results obtained also apply to low-dimensional cases. We showcase that the bias of regularized estimation, unavoidable in high-dimensional covariate spaces, is mitigated with a simple double-robust score. In this way, no additional bias removal is necessary, and we obtain root-$N$ inference results while allowing multi-stage interdependency of the treatments and covariates. Memoryless property is also not assumed; treatment can possibly depend on all previous treatment assignments and all previous multi-stage confounders. Our results rely on certain sparsity assumptions of the underlying dependencies. We discover new product rate conditions necessary for robust inference with dynamic treatments.

</p>
</details>

<details><summary><b>FLAME: Facial Landmark Heatmap Activated Multimodal Gaze Estimation</b>
<a href="https://arxiv.org/abs/2110.04828">arxiv:2110.04828</a>
&#x1F4C8; 3 <br>
<p>Neelabh Sinha, Michal Balazia, François Bremond</p></summary>
<p>

**Abstract:** 3D gaze estimation is about predicting the line of sight of a person in 3D space. Person-independent models for the same lack precision due to anatomical differences of subjects, whereas person-specific calibrated techniques add strict constraints on scalability. To overcome these issues, we propose a novel technique, Facial Landmark Heatmap Activated Multimodal Gaze Estimation (FLAME), as a way of combining eye anatomical information using eye landmark heatmaps to obtain precise gaze estimation without any person-specific calibration. Our evaluation demonstrates a competitive performance of about 10% improvement on benchmark datasets ColumbiaGaze and EYEDIAP. We also conduct an ablation study to validate our method.

</p>
</details>

<details><summary><b>Self-Supervised 3D Face Reconstruction via Conditional Estimation</b>
<a href="https://arxiv.org/abs/2110.04800">arxiv:2110.04800</a>
&#x1F4C8; 3 <br>
<p>Yandong Wen, Weiyang Liu, Bhiksha Raj, Rita Singh</p></summary>
<p>

**Abstract:** We present a conditional estimation (CEST) framework to learn 3D facial parameters from 2D single-view images by self-supervised training from videos. CEST is based on the process of analysis by synthesis, where the 3D facial parameters (shape, reflectance, viewpoint, and illumination) are estimated from the face image, and then recombined to reconstruct the 2D face image. In order to learn semantically meaningful 3D facial parameters without explicit access to their labels, CEST couples the estimation of different 3D facial parameters by taking their statistical dependency into account. Specifically, the estimation of any 3D facial parameter is not only conditioned on the given image, but also on the facial parameters that have already been derived. Moreover, the reflectance symmetry and consistency among the video frames are adopted to improve the disentanglement of facial parameters. Together with a novel strategy for incorporating the reflectance symmetry and consistency, CEST can be efficiently trained with in-the-wild video clips. Both qualitative and quantitative experiments demonstrate the effectiveness of CEST.

</p>
</details>

<details><summary><b>Stepwise-Refining Speech Separation Network via Fine-Grained Encoding in High-order Latent Domain</b>
<a href="https://arxiv.org/abs/2110.04791">arxiv:2110.04791</a>
&#x1F4C8; 3 <br>
<p>Zengwei Yao, Wenjie Pei, Fanglin Chen, Guangming Lu, David Zhang</p></summary>
<p>

**Abstract:** The crux of single-channel speech separation is how to encode the mixture of signals into such a latent embedding space that the signals from different speakers can be precisely separated. Existing methods for speech separation either transform the speech signals into frequency domain to perform separation or seek to learn a separable embedding space by constructing a latent domain based on convolutional filters. While the latter type of methods learning an embedding space achieves substantial improvement for speech separation, we argue that the embedding space defined by only one latent domain does not suffice to provide a thoroughly separable encoding space for speech separation. In this paper, we propose the Stepwise-Refining Speech Separation Network (SRSSN), which follows a coarse-to-fine separation framework. It first learns a 1-order latent domain to define an encoding space and thereby performs a rough separation in the coarse phase. Then the proposed SRSSN learns a new latent domain along each basis function of the existing latent domain to obtain a high-order latent domain in the refining phase, which enables our model to perform a refining separation to achieve a more precise speech separation. We demonstrate the effectiveness of our SRSSN by conducting extensive experiments, including speech separation in a clean (noise-free) setting on WSJ0-2/3mix datasets as well as in noisy/reverberant settings on WHAM!/WHAMR! datasets. Furthermore, we also perform experiments of speech recognition on separated speech signals by our model to evaluate the performance of speech separation indirectly.

</p>
</details>

<details><summary><b>Long Expressive Memory for Sequence Modeling</b>
<a href="https://arxiv.org/abs/2110.04744">arxiv:2110.04744</a>
&#x1F4C8; 3 <br>
<p>T. Konstantin Rusch, Siddhartha Mishra, N. Benjamin Erichson, Michael W. Mahoney</p></summary>
<p>

**Abstract:** We propose a novel method called Long Expressive Memory (LEM) for learning long-term sequential dependencies. LEM is gradient-based, it can efficiently process sequential tasks with very long-term dependencies, and it is sufficiently expressive to be able to learn complicated input-output maps. To derive LEM, we consider a system of multiscale ordinary differential equations, as well as a suitable time-discretization of this system. For LEM, we derive rigorous bounds to show the mitigation of the exploding and vanishing gradients problem, a well-known challenge for gradient-based recurrent sequential learning methods. We also prove that LEM can approximate a large class of dynamical systems to high accuracy. Our empirical results, ranging from image and time-series classification through dynamical systems prediction to speech recognition and language modeling, demonstrate that LEM outperforms state-of-the-art recurrent neural networks, gated recurrent units, and long short-term memory models.

</p>
</details>

<details><summary><b>Which Samples Should be Learned First: Easy or Hard?</b>
<a href="https://arxiv.org/abs/2110.05481">arxiv:2110.05481</a>
&#x1F4C8; 2 <br>
<p>Xiaoling Zhou, Ou Wu</p></summary>
<p>

**Abstract:** An effective weighting scheme for training samples is essential for learning tasks. Numerous weighting schemes have been proposed. Some schemes take the easy-first mode, whereas some others take the hard-first one. Naturally, an interesting yet realistic question is raised. Which samples should be learned first given a new learning task, easy or hard? To answer this question, both theoretical analyses and experimental verification are conducted. First, a general optimized objective function is proposed, revealing the relationship between the difficulty distribution and the difficulty-based sample weights. Second, on the basis of the optimized objective function, theoretical answers are obtained. Besides the easy-first and hard-first modes, there are two other priority modes, namely, medium-first and two-ends-first. The prior mode does not necessarily remain unchanged during the training process. Third, an effective and universal solution is proposed to select the optimal priority mode when there is no prior knowledge or theoretical clues. The four modes, namely, easy/medium/hard/two-ends-first, can be flexibly switched in the proposed solution. Fourth, a wide range of experiments is conducted under various scenarios to further compare the weighting schemes in different modes. On the basis of these works, reasonable and comprehensive answers are obtained. Factors including the distribution of samples' learning difficulties and the validation data determine which samples should be learned first in a learning task.

</p>
</details>

<details><summary><b>Nonparametric Functional Analysis of Generalized Linear Models Under Nonlinear Constraints</b>
<a href="https://arxiv.org/abs/2110.04998">arxiv:2110.04998</a>
&#x1F4C8; 2 <br>
<p>K. P. Chowdhury</p></summary>
<p>

**Abstract:** This article introduces a novel nonparametric methodology for Generalized Linear Models which combines the strengths of the binary regression and latent variable formulations for categorical data, while overcoming their disadvantages. Requiring minimal assumptions, it extends recently published parametric versions of the methodology and generalizes it. If the underlying data generating process is asymmetric, it gives uniformly better prediction and inference performance over the parametric formulation. Furthermore, it introduces a new classification statistic utilizing which I show that overall, it has better model fit, inference and classification performance than the parametric version, and the difference in performance is statistically significant especially if the data generating process is asymmetric. In addition, the methodology can be used to perform model diagnostics for any model specification. This is a highly useful result, and it extends existing work for categorical model diagnostics broadly across the sciences. The mathematical results also highlight important new findings regarding the interplay of statistical significance and scientific significance. Finally, the methodology is applied to various real-world datasets to show that it may outperform widely used existing models, including Random Forests and Deep Neural Networks with very few iterations.

</p>
</details>

<details><summary><b>Towards Demystifying Representation Learning with Non-contrastive Self-supervision</b>
<a href="https://arxiv.org/abs/2110.04947">arxiv:2110.04947</a>
&#x1F4C8; 2 <br>
<p>Xiang Wang, Xinlei Chen, Simon S. Du, Yuandong Tian</p></summary>
<p>

**Abstract:** Non-contrastive methods of self-supervised learning (such as BYOL and SimSiam) learn representations by minimizing the distance between two views of the same image. These approaches have achieved remarkable performance in practice, but it is not well understood 1) why these methods do not collapse to the trivial solutions and 2) how the representation is learned. Tian el al. (2021) made an initial attempt on the first question and proposed DirectPred that sets the predictor directly. In our work, we analyze a generalized version of DirectPred, called DirectSet($α$). We show that in a simple linear network, DirectSet($α$) provably learns a desirable projection matrix and also reduces the sample complexity on downstream tasks. Our analysis suggests that weight decay acts as an implicit threshold that discard the features with high variance under augmentation, and keep the features with low variance. Inspired by our theory, we simplify DirectPred by removing the expensive eigen-decomposition step. On CIFAR-10, CIFAR-100, STL-10 and ImageNet, DirectCopy, our simpler and more computationally efficient algorithm, rivals or even outperforms DirectPred.

</p>
</details>

<details><summary><b>Learning Temporally-Consistent Representations for Data-Efficient Reinforcement Learning</b>
<a href="https://arxiv.org/abs/2110.04935">arxiv:2110.04935</a>
&#x1F4C8; 2 <br>
<p>Trevor McInroe, Lukas Schäfer, Stefano V. Albrecht</p></summary>
<p>

**Abstract:** Deep reinforcement learning (RL) agents that exist in high-dimensional state spaces, such as those composed of images, have interconnected learning burdens. Agents must learn an action-selection policy that completes their given task, which requires them to learn a representation of the state space that discerns between useful and useless information. The reward function is the only supervised feedback that RL agents receive, which causes a representation learning bottleneck that can manifest in poor sample efficiency. We present $k$-Step Latent (KSL), a new representation learning method that enforces temporal consistency of representations via a self-supervised auxiliary task wherein agents learn to recurrently predict action-conditioned representations of the state space. The state encoder learned by KSL produces low-dimensional representations that make optimization of the RL task more sample efficient. Altogether, KSL produces state-of-the-art results in both data efficiency and asymptotic performance in the popular PlaNet benchmark suite. Our analyses show that KSL produces encoders that generalize better to new tasks unseen during training, and its representations are more strongly tied to reward, are more invariant to perturbations in the state space, and move more smoothly through the temporal axis of the RL problem than other methods such as DrQ, RAD, CURL, and SAC-AE.

</p>
</details>

<details><summary><b>A Deep Learning Inference Scheme Based on Pipelined Matrix Multiplication Acceleration Design and Non-uniform Quantization</b>
<a href="https://arxiv.org/abs/2110.04861">arxiv:2110.04861</a>
&#x1F4C8; 2 <br>
<p>Yuyang Zhang, Dik Hin Leung, Min Guo, Yijia Xiao, Haoyue Liu, Yunfei Li, Jiyuan Zhang, Guan Wang, Zhen Chen</p></summary>
<p>

**Abstract:** Matrix multiplication is the bedrock in Deep Learning inference application. When it comes to hardware acceleration on edge computing devices, matrix multiplication often takes up a great majority of the time. To achieve better performance in edge computing, we introduce a low-power Multi-layer Perceptron (MLP) accelerator based on a pipelined matrix multiplication scheme and a nonuniform quantization methodology. The implementation is running on Field-programmable Gate Array (FPGA) devices and tested its performance on handwritten digit classification and Q-learning tasks. Results show that our method can achieve better performance with fewer power consumption.

</p>
</details>

<details><summary><b>Heavy Ball Neural Ordinary Differential Equations</b>
<a href="https://arxiv.org/abs/2110.04840">arxiv:2110.04840</a>
&#x1F4C8; 2 <br>
<p>Hedi Xia, Vai Suliafu, Hangjie Ji, Tan M. Nguyen, Andrea L. Bertozzi, Stanley J. Osher, Bao Wang</p></summary>
<p>

**Abstract:** We propose heavy ball neural ordinary differential equations (HBNODEs), leveraging the continuous limit of the classical momentum accelerated gradient descent, to improve neural ODEs (NODEs) training and inference. HBNODEs have two properties that imply practical advantages over NODEs: (i) The adjoint state of an HBNODE also satisfies an HBNODE, accelerating both forward and backward ODE solvers, thus significantly reducing the number of function evaluations (NFEs) and improving the utility of the trained models. (ii) The spectrum of HBNODEs is well structured, enabling effective learning of long-term dependencies from complex sequential data. We verify the advantages of HBNODEs over NODEs on benchmark tasks, including image classification, learning complex dynamics, and sequential modeling. Our method requires remarkably fewer forward and backward NFEs, is more accurate, and learns long-term dependencies more effectively than the other ODE-based neural network models. Code is available at \url{https://github.com/hedixia/HeavyBallNODE}.

</p>
</details>

<details><summary><b>Feature Imitating Networks</b>
<a href="https://arxiv.org/abs/2110.04831">arxiv:2110.04831</a>
&#x1F4C8; 2 <br>
<p>Sari Saba-Sadiya, Tuka Alhanai, Mohammad M Ghassemi</p></summary>
<p>

**Abstract:** In this paper, we introduce a novel approach to neural learning: the Feature-Imitating-Network (FIN). A FIN is a neural network with weights that are initialized to reliably approximate one or more closed-form statistical features, such as Shannon's entropy. In this paper, we demonstrate that FINs (and FIN ensembles) provide best-in-class performance for a variety of downstream signal processing and inference tasks, while using less data and requiring less fine-tuning compared to other networks of similar (or even greater) representational power. We conclude that FINs can help bridge the gap between domain experts and machine learning practitioners by enabling researchers to harness insights from feature-engineering to enhance the performance of contemporary representation learning approaches.

</p>
</details>

<details><summary><b>Adaptive joint distribution learning</b>
<a href="https://arxiv.org/abs/2110.04829">arxiv:2110.04829</a>
&#x1F4C8; 2 <br>
<p>Damir Filipovic, Michael Multerer, Paul Schneider</p></summary>
<p>

**Abstract:** We develop a new framework for embedding (joint) probability distributions in tensor product reproducing kernel Hilbert spaces (RKHS). This framework accommodates a low-dimensional, positive, and normalized model of a Radon-Nikodym derivative, estimated from sample sizes of up to several million data points, alleviating the inherent limitations of RKHS modeling. Well-defined normalized and positive conditional distributions are natural by-products to our approach. The embedding is fast to compute and naturally accommodates learning problems ranging from prediction to classification. The theoretical findings are supplemented by favorable numerical results.

</p>
</details>

<details><summary><b>Finding Second-Order Stationary Point for Nonconvex-Strongly-Concave Minimax Problem</b>
<a href="https://arxiv.org/abs/2110.04814">arxiv:2110.04814</a>
&#x1F4C8; 2 <br>
<p>Luo Luo, Cheng Chen</p></summary>
<p>

**Abstract:** We study the smooth minimax optimization problem of the form $\min_{\bf x}\max_{\bf y} f({\bf x},{\bf y})$, where the objective function is strongly-concave in ${\bf y}$ but possibly nonconvex in ${\bf x}$. This problem includes a lot of applications in machine learning such as regularized GAN, reinforcement learning and adversarial training. Most of existing theory related to gradient descent accent focus on establishing the convergence result for achieving the first-order stationary point of $f({\bf x},{\bf y})$ or primal function $P({\bf x})\triangleq \max_{\bf y} f({\bf x},{\bf y})$. In this paper, we design a new optimization method via cubic Newton iterations, which could find an ${\mathcal O}\left(\varepsilon,κ^{1.5}\sqrt{ρ\varepsilon}\right)$-second-order stationary point of $P({\bf x})$ with ${\mathcal O}\left(κ^{1.5}\sqrtρ\varepsilon^{-1.5}\right)$ second-order oracle calls and $\tilde{\mathcal O}\left(κ^{2}\sqrtρ\varepsilon^{-1.5}\right)$ first-order oracle calls, where $κ$ is the condition number and $ρ$ is the Hessian smoothness coefficient of $f({\bf x},{\bf y})$. For high-dimensional problems, we propose an variant algorithm to avoid expensive cost form second-order oracle, which solves the cubic sub-problem inexactly via gradient descent and matrix Chebyshev expansion. This strategy still obtains desired approximate second-order stationary point with high probability but only requires $\tilde{\mathcal O}\left(κ^{1.5}\ell\varepsilon^{-2}\right)$ Hessian-vector oracle and $\tilde{\mathcal O}\left(κ^{2}\sqrtρ\varepsilon^{-1.5}\right)$ first-order oracle calls. To the best of our knowledge, this is the first work considers non-asymptotic convergence behavior of finding second-order stationary point for minimax problem without convex-concave assumption.

</p>
</details>

<details><summary><b>Hard instance learning for quantum adiabatic prime factorization</b>
<a href="https://arxiv.org/abs/2110.04782">arxiv:2110.04782</a>
&#x1F4C8; 2 <br>
<p>Jian Lin, Zhengfeng Zhang, Junping Zhang, Xiaopeng Li</p></summary>
<p>

**Abstract:** Prime factorization is a difficult problem with classical computing, whose exponential hardness is the foundation of Rivest-Shamir-Adleman (RSA) cryptography. With programmable quantum devices, adiabatic quantum computing has been proposed as a plausible approach to solve prime factorization, having promising advantage over classical computing. Here, we find there are certain hard instances that are consistently intractable for both classical simulated annealing and un-configured adiabatic quantum computing (AQC). Aiming at an automated architecture for optimal configuration of quantum adiabatic factorization, we apply a deep reinforcement learning (RL) method to configure the AQC algorithm. By setting the success probability of the worst-case problem instances as the reward to RL, we show the AQC performance on the hard instances is dramatically improved by RL configuration. The success probability also becomes more evenly distributed over different problem instances, meaning the configured AQC is more stable as compared to the un-configured case. Through a technique of transfer learning, we find prominent evidence that the framework of AQC configuration is scalable -- the configured AQC as trained on five qubits remains working efficiently on nine qubits with a minimal amount of additional training cost.

</p>
</details>

<details><summary><b>Fitting large mixture models using stochastic component selection</b>
<a href="https://arxiv.org/abs/2110.04776">arxiv:2110.04776</a>
&#x1F4C8; 2 <br>
<p>Milan Papež, Tomáš Pevný, Václav Šmídl</p></summary>
<p>

**Abstract:** Traditional methods for unsupervised learning of finite mixture models require to evaluate the likelihood of all components of the mixture. This becomes computationally prohibitive when the number of components is large, as it is, for example, in the sum-product (transform) networks. Therefore, we propose to apply a combination of the expectation maximization and the Metropolis-Hastings algorithm to evaluate only a small number of, stochastically sampled, components, thus substantially reducing the computational cost. The Markov chain of component assignments is sequentially generated across the algorithm's iterations, having a non-stationary target distribution whose parameters vary via a gradient-descent scheme. We put emphasis on generality of our method, equipping it with the ability to train both shallow and deep mixture models which involve complex, and possibly nonlinear, transformations. The performance of our method is illustrated in a variety of synthetic and real-data contexts, considering deep models, such as mixtures of normalizing flows and sum-product (transform) networks.

</p>
</details>

<details><summary><b>Multi-task Learning with Metadata for Music Mood Classification</b>
<a href="https://arxiv.org/abs/2110.04765">arxiv:2110.04765</a>
&#x1F4C8; 2 <br>
<p>Rajnish Kumar, Manjeet Dahiya</p></summary>
<p>

**Abstract:** Mood recognition is an important problem in music informatics and has key applications in music discovery and recommendation. These applications have become even more relevant with the rise of music streaming. Our work investigates the research question of whether we can leverage audio metadata such as artist and year, which is readily available, to improve the performance of mood classification models. To this end, we propose a multi-task learning approach in which a shared model is simultaneously trained for mood and metadata prediction tasks with the goal to learn richer representations. Experimentally, we demonstrate that applying our technique on the existing state-of-the-art convolutional neural networks for mood classification improves their performances consistently. We conduct experiments on multiple datasets and report that our approach can lead to improvements in the average precision metric by up to 8.7 points.

</p>
</details>

<details><summary><b>How Robust are Limit Order Book Representations under Data Perturbation?</b>
<a href="https://arxiv.org/abs/2110.04752">arxiv:2110.04752</a>
&#x1F4C8; 2 <br>
<p>Yufei Wu, Mahmoud Mahfouz, Daniele Magazzeni, Manuela Veloso</p></summary>
<p>

**Abstract:** The success of machine learning models in the financial domain is highly reliant on the quality of the data representation. In this paper, we focus on the representation of limit order book data and discuss the opportunities and challenges for learning representations of such data. We also experimentally analyse the issues associated with existing representations and present a guideline for future research in this area.

</p>
</details>

<details><summary><b>Modeling of Pan Evaporation Based on the Development of Machine Learning Methods</b>
<a href="https://arxiv.org/abs/2110.04749">arxiv:2110.04749</a>
&#x1F4C8; 2 <br>
<p>Mustafa Al-Mukhtar</p></summary>
<p>

**Abstract:** For effective planning and management of water resources and implementation of the related strategies, it is important to ensure proper estimation of evaporation losses, especially in regions that are prone to drought. Changes in climatic factors, such as changes in temperature, wind speed, sunshine hours, humidity, and solar radiation can have a significant impact on the evaporation process. As such, evaporation is a highly non-linear, non-stationary process, and can be difficult to be modeled based on climatic factors, especially in different agro-climatic conditions. The aim of this study, therefore, is to investigate the feasibility of several machines learning (ML) models (conditional random forest regression, Multivariate Adaptive Regression Splines, Bagged Multivariate Adaptive Regression Splines, Model Tree M5, K- nearest neighbor, and the weighted K- nearest neighbor) for modeling the monthly pan evaporation estimation. This study proposes the development of newly explored ML models for modeling evaporation losses in three different locations over the Iraq region based on the available climatic data in such areas. The evaluation of the performance of the proposed model based on various evaluation criteria showed the capability of the proposed weighted K- nearest neighbor model in modeling the monthly evaporation losses in the studies areas with better accuracy when compared with the other existing models used as a benchmark in this study.

</p>
</details>

<details><summary><b>Real-time FPGA Design for OMP Targeting 8K Image Reconstruction</b>
<a href="https://arxiv.org/abs/2110.04714">arxiv:2110.04714</a>
&#x1F4C8; 2 <br>
<p>Jiayao Xu, Chen Fu, Zhiqiang Zhang, Jinjia Zhou</p></summary>
<p>

**Abstract:** During the past decade, implementing reconstruction algorithms on hardware has been at the center of much attention in the field of real-time reconstruction in Compressed Sensing (CS). Orthogonal Matching Pursuit (OMP) is the most widely used reconstruction algorithm on hardware implementation because OMP obtains good quality reconstruction results under a proper time cost. OMP includes Dot Product (DP) and Least Square Problem (LSP). These two parts have numerous division calculations and considerable vector-based multiplications, which limit the implementation of real-time reconstruction on hardware. In the theory of CS, besides the reconstruction algorithm, the choice of sensing matrix affects the quality of reconstruction. It also influences the reconstruction efficiency by affecting the hardware architecture. Thus, designing a real-time hardware architecture of OMP needs to take three factors into consideration. The choice of sensing matrix, the implementation of DP and LSP. In this paper, a sensing matrix, which is sparsity and contains zero vectors mainly, is adopted to optimize the OMP reconstruction to break the bottleneck of reconstruction efficiency. Based on the features of the chosen matrix, the DP and LSP are implemented by simple shift, add and comparing procedures. This work is implemented on the Xilinx Virtex UltraScale+ FPGA device. To reconstruct a digital signal with 1024 length under 0.25 sampling rate, the proposal method costs 0.818us while the state-of-the-art costs 238$us. Thus, this work speedups the state-of-the-art method 290 times. This work costs 0.026s to reconstruct an 8K gray image, which achieves 30FPS real-time reconstruction.

</p>
</details>

<details><summary><b>Fetal Gender Identification using Machine and Deep Learning Algorithms on Phonocardiogram Signals</b>
<a href="https://arxiv.org/abs/2110.06131">arxiv:2110.06131</a>
&#x1F4C8; 1 <br>
<p>Reza Khanmohammadi, Mitra Sadat Mirshafiee, Mohammad Mahdi Ghassemi, Tuka Alhanai</p></summary>
<p>

**Abstract:** Phonocardiogram (PCG) signal analysis is a critical, widely-studied technology to noninvasively analyze the heart's mechanical activity. Through evaluating heart sounds, this technology has been chiefly leveraged as a preliminary solution to automatically diagnose Cardiovascular diseases among adults; however, prenatal tasks such as fetal gender identification have been relatively less studied using fetal Phonocardiography (FPCG). In this work, we apply common PCG signal processing techniques on the gender-tagged Shiraz University Fetal Heart Sounds Database and study the applicability of previously proposed features in classifying fetal gender using both Machine Learning and Deep Learning models. Even though PCG data acquisition's cost-effectiveness and feasibility make it a convenient method of Fetal Heart Rate (FHR) monitoring, the contaminated nature of PCG signals with the noise of various types makes it a challenging modality. To address this problem, we experimented with both static and adaptive noise reduction techniques such as Low-pass filtering, Denoising Autoencoders, and Source Separators. We apply a wide range of previously proposed classifiers to our dataset and propose a novel ensemble method of Fetal Gender Identification (FGI). Our method substantially outperformed the baseline and reached up to 91% accuracy in classifying fetal gender of unseen subjects.

</p>
</details>

<details><summary><b>Evolving Evolutionary Algorithms with Patterns</b>
<a href="https://arxiv.org/abs/2110.05951">arxiv:2110.05951</a>
&#x1F4C8; 1 <br>
<p>Mihai Oltean</p></summary>
<p>

**Abstract:** A new model for evolving Evolutionary Algorithms (EAs) is proposed in this paper. The model is based on the Multi Expression Programming (MEP) technique. Each MEP chromosome encodes an evolutionary pattern that is repeatedly used for generating the individuals of a new generation. The evolved pattern is embedded into a standard evolutionary scheme that is used for solving a particular problem. Several evolutionary algorithms for function optimization are evolved by using the considered model. The evolved evolutionary algorithms are compared with a human-designed Genetic Algorithm. Numerical experiments show that the evolved evolutionary algorithms can compete with standard approaches for several well-known benchmarking problems.

</p>
</details>

<details><summary><b>COVID-Datathon: Biomarker identification for COVID-19 severity based on BALF scRNA-seq data</b>
<a href="https://arxiv.org/abs/2110.04986">arxiv:2110.04986</a>
&#x1F4C8; 1 <br>
<p>Seyednami Niyakan, Xiaoning Qian</p></summary>
<p>

**Abstract:** The severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) emergence began in late 2019 and has since spread rapidly worldwide. The characteristics of respiratory immune response to this emerging virus is not clear. Recently, Single-cell RNA sequencing (scRNA-seq) transcriptome profiling of Bronchoalveolar lavage fluid (BALF) cells has been done to elucidate the potential mechanisms underlying in COVID-19. With the aim of better utilizing this atlas of BALF cells in response to the virus, here we propose a bioinformatics pipeline to identify candidate biomarkers of COVID-19 severity, which may help characterize BALF cells to have better mechanistic understanding of SARS-CoV-2 infection. The proposed pipeline is implemented in R and is available at https://github.com/namini94/scBALF_Hackathon.

</p>
</details>

<details><summary><b>An Efficient Deep Learning Model for Automatic Modulation Recognition Based on Parameter Estimation and Transformation</b>
<a href="https://arxiv.org/abs/2110.04980">arxiv:2110.04980</a>
&#x1F4C8; 1 <br>
<p>Fuxin Zhang, Chunbo Luo, Jialang Xu, Yang Luo</p></summary>
<p>

**Abstract:** Automatic modulation recognition (AMR) is a promising technology for intelligent communication receivers to detect signal modulation schemes. Recently, the emerging deep learning (DL) research has facilitated high-performance DL-AMR approaches. However, most DL-AMR models only focus on recognition accuracy, leading to huge model sizes and high computational complexity, while some lightweight and low-complexity models struggle to meet the accuracy requirements. This letter proposes an efficient DL-AMR model based on phase parameter estimation and transformation, with convolutional neural network (CNN) and gated recurrent unit (GRU) as the feature extraction layers, which can achieve high recognition accuracy equivalent to the existing state-of-the-art models but reduces more than a third of the volume of their parameters. Meanwhile, our model is more competitive in training time and test time than the benchmark models with similar recognition accuracy. Moreover, we further propose to compress our model by pruning, which maintains the recognition accuracy higher than 90% while has less than 1/8 of the number of parameters comparing with state-of-the-art models.

</p>
</details>

<details><summary><b>A Deep Generative Model for Matrix Reordering</b>
<a href="https://arxiv.org/abs/2110.04971">arxiv:2110.04971</a>
&#x1F4C8; 1 <br>
<p>Oh-Hyun Kwon, Chiun-How Kao, Chun-houh Chen, Kwan-Liu Ma</p></summary>
<p>

**Abstract:** Depending on the node ordering, an adjacency matrix can highlight distinct characteristics of a graph. Deriving a "proper" node ordering is thus a critical step in visualizing a graph as an adjacency matrix. Users often try multiple matrix reorderings using different methods until they find one that meets the analysis goal. However, this trial-and-error approach is laborious and disorganized, which is especially challenging for novices. This paper presents a technique that enables users to effortlessly find a matrix reordering they want. Specifically, we design a generative model that learns a latent space of diverse matrix reorderings of the given graph. We also construct an intuitive user interface from the learned latent space by creating a map of various matrix reorderings. We demonstrate our approach through quantitative and qualitative evaluations of the generated reorderings and learned latent spaces. The results show that our model is capable of learning a latent space of diverse matrix reorderings. Most existing research in this area generally focused on developing algorithms that can compute "better" matrix reorderings for particular circumstances. This paper introduces a fundamentally new approach to matrix visualization of a graph, where a machine learning model learns to generate diverse matrix reorderings of a graph.

</p>
</details>

<details><summary><b>Convergence of Random Reshuffling Under The Kurdyka-Łojasiewicz Inequality</b>
<a href="https://arxiv.org/abs/2110.04926">arxiv:2110.04926</a>
&#x1F4C8; 1 <br>
<p>Xiao Li, Andre Milzarek, Junwen Qiu</p></summary>
<p>

**Abstract:** We study the random reshuffling (RR) method for smooth nonconvex optimization problems with a finite-sum structure. Though this method is widely utilized in practice such as the training of neural networks, its convergence behavior is only understood in several limited settings. In this paper, under the well-known Kurdyka-Lojasiewicz (KL) inequality, we establish strong limit-point convergence results for RR with appropriate diminishing step sizes, namely, the whole sequence of iterates generated by RR is convergent and converges to a single stationary point in an almost sure sense. In addition, we derive the corresponding rate of convergence, depending on the KL exponent and the suitably selected diminishing step sizes. When the KL exponent lies in $[0,\frac12]$, the convergence is at a rate of $\mathcal{O}(t^{-1})$ with $t$ counting the iteration number. When the KL exponent belongs to $(\frac12,1)$, our derived convergence rate is of the form $\mathcal{O}(t^{-q})$ with $q\in (0,1)$ depending on the KL exponent. The standard KL inequality-based convergence analysis framework only applies to algorithms with a certain descent property. Remarkably, we conduct convergence analysis for the non-descent RR with diminishing step sizes based on the KL inequality, which generalizes the standard KL analysis framework. We summarize our main steps and core ideas in an analysis framework, which is of independent interest. As a direct application of this framework, we also establish similar strong limit-point convergence results for the shuffled proximal point method.

</p>
</details>

<details><summary><b>A Hybrid Scattering Transform for Signals with Isolated Singularities</b>
<a href="https://arxiv.org/abs/2110.04910">arxiv:2110.04910</a>
&#x1F4C8; 1 <br>
<p>Michael Perlmutter, Jieqian He, Mark Iwen, Matthew Hirn</p></summary>
<p>

**Abstract:** The scattering transform is a wavelet-based model of Convolutional Neural Networks originally introduced by S. Mallat. Mallat's analysis shows that this network has desirable stability and invariance guarantees and therefore helps explain the observation that the filters learned by early layers of a Convolutional Neural Network typically resemble wavelets. Our aim is to understand what sort of filters should be used in the later layers of the network. Towards this end, we propose a two-layer hybrid scattering transform. In our first layer, we convolve the input signal with a wavelet filter transform to promote sparsity, and, in the second layer, we convolve with a Gabor filter to leverage the sparsity created by the first layer. We show that these measurements characterize information about signals with isolated singularities. We also show that the Gabor measurements used in the second layer can be used to synthesize sparse signals such as those produced by the first layer.

</p>
</details>

<details><summary><b>NormVAE: Normative Modeling on Neuroimaging Data using Variational Autoencoders</b>
<a href="https://arxiv.org/abs/2110.04903">arxiv:2110.04903</a>
&#x1F4C8; 1 <br>
<p>Sayantan Kumar, Aristeidis Sotiras</p></summary>
<p>

**Abstract:** Normative modeling is an emerging method for understanding the heterogeneous biology underlying neuropsychiatric and neurodegenerative disorders at the level of the individual participant. Deep autoencoders have been implemented as normative models, where patient-level deviations are modelled as the squared difference between the actual and reconstructed input without any uncertainty estimates in the deviations. In this study, we assessed NormVAE, a novel normative modeling based variational autoencoder (VAE) which calculates subject-level normative abnormality maps (NAM) for quantifying uncertainty in the deviations. Our experiments on brain neuroimaging data of Alzheimer's Disease (AD) patients demonstrated that the NormVAE-generated patient-level abnormality maps exhibit increased sensitivity to disease staging compared to a baseline VAE, which generates deterministic subject-level deviations without any uncertainty estimates.

</p>
</details>

<details><summary><b>Adversarial Attacks in a Multi-view Setting: An Empirical Study of the Adversarial Patches Inter-view Transferability</b>
<a href="https://arxiv.org/abs/2110.04887">arxiv:2110.04887</a>
&#x1F4C8; 1 <br>
<p>Bilel Tarchoun, Ihsen Alouani, Anouar Ben Khalifa, Mohamed Ali Mahjoub</p></summary>
<p>

**Abstract:** While machine learning applications are getting mainstream owing to a demonstrated efficiency in solving complex problems, they suffer from inherent vulnerability to adversarial attacks. Adversarial attacks consist of additive noise to an input which can fool a detector. Recently, successful real-world printable adversarial patches were proven efficient against state-of-the-art neural networks. In the transition from digital noise based attacks to real-world physical attacks, the myriad of factors affecting object detection will also affect adversarial patches. Among these factors, view angle is one of the most influential, yet under-explored. In this paper, we study the effect of view angle on the effectiveness of an adversarial patch. To this aim, we propose the first approach that considers a multi-view context by combining existing adversarial patches with a perspective geometric transformation in order to simulate the effect of view angle changes. Our approach has been evaluated on two datasets: the first dataset which contains most real world constraints of a multi-view context, and the second dataset which empirically isolates the effect of view angle. The experiments show that view angle significantly affects the performance of adversarial patches, where in some cases the patch loses most of its effectiveness. We believe that these results motivate taking into account the effect of view angles in future adversarial attacks, and open up new opportunities for adversarial defenses.

</p>
</details>

<details><summary><b>Nano Version Control and Robots of Robots: Data Driven, Regenerative Production Code</b>
<a href="https://arxiv.org/abs/2110.04755">arxiv:2110.04755</a>
&#x1F4C8; 1 <br>
<p>Lukasz Machowski, Tshilidzi Marwala</p></summary>
<p>

**Abstract:** A reflection of the Corona pandemic highlights the need for more sustainable production systems using automation. The goal is to retain automation of repetitive tasks while allowing complex parts to come together. We recognize the fragility and how hard it is to create traditional automation. We introduce a method which converts one really hard problem of producing sustainable production code into three simpler problems being data, patterns and working prototypes. We use developer seniority as a metric to measure whether the proposed method is easier. By using agent-based simulation and NanoVC repos for agent arbitration, we are able to create a simulated environment where patterns developed by people are used to transform working prototypes into templates that data can be fed through to create the robots that create the production code. Having two layers of robots allow early implementation choices to be replaced as we gather more feedback from the working system. Several benefits of this approach have been discovered, with the most notable being that the Robot of Robots encodes a legacy of the person that designed it in the form of the 3 ingredients (data, patterns and working prototypes). This method allows us to achieve our goal of reducing the fragility of the production code while removing the difficulty of getting there.

</p>
</details>

<details><summary><b>Algorithmic collusion: A critical review</b>
<a href="https://arxiv.org/abs/2110.04740">arxiv:2110.04740</a>
&#x1F4C8; 1 <br>
<p>Florian E. Dorner</p></summary>
<p>

**Abstract:** The prospect of collusive agreements being stabilized via the use of pricing algorithms is widely discussed by antitrust experts and economists. However, the literature is often lacking the perspective of computer scientists, and seems to regularly overestimate the applicability of recent progress in machine learning to the complex coordination problem firms face in forming cartels. Similarly, modelling results supporting the possibility of collusion by learning algorithms often use simple market simulations which allows them to use simple algorithms that do not produce many of the problems machine learning practitioners have to deal with in real-world problems, which could prove to be particularly detrimental to learning collusive agreements. After critically reviewing the literature on algorithmic collusion, and connecting it to results from computer science, we find that while it is likely too early to adapt antitrust law to be able to deal with self-learning algorithms colluding in real markets, other forms of algorithmic collusion, such as hub-and-spoke arrangements facilitated by centralized pricing algorithms might already warrant legislative action.

</p>
</details>

<details><summary><b>Uncertainty in Data-Driven Kalman Filtering for Partially Known State-Space Models</b>
<a href="https://arxiv.org/abs/2110.04738">arxiv:2110.04738</a>
&#x1F4C8; 1 <br>
<p>Itzik Klein, Guy Revach, Nir Shlezinger, Jonas E. Mehr, Ruud J. G. van Sloun, Yonina. C. Eldar</p></summary>
<p>

**Abstract:** Providing a metric of uncertainty alongside a state estimate is often crucial when tracking a dynamical system. Classic state estimators, such as the Kalman filter (KF), provide a time-dependent uncertainty measure from knowledge of the underlying statistics, however, deep learning based tracking systems struggle to reliably characterize uncertainty. In this paper, we investigate the ability of KalmanNet, a recently proposed hybrid model-based deep state tracking algorithm, to estimate an uncertainty measure. By exploiting the interpretable nature of KalmanNet, we show that the error covariance matrix can be computed based on its internal features, as an uncertainty measure. We demonstrate that when the system dynamics are known, KalmanNet-which learns its mapping from data without access to the statistics-provides uncertainty similar to that provided by the KF; and while in the presence of evolution model-mismatch, KalmanNet pro-vides a more accurate error estimation.

</p>
</details>

<details><summary><b>Universal Adversarial Attacks on Neural Networks for Power Allocation in a Massive MIMO System</b>
<a href="https://arxiv.org/abs/2110.04731">arxiv:2110.04731</a>
&#x1F4C8; 1 <br>
<p>Pablo Millán Santos, B. R. Manoj, Meysam Sadeghi, Erik G. Larsson</p></summary>
<p>

**Abstract:** Deep learning (DL) architectures have been successfully used in many applications including wireless systems. However, they have been shown to be susceptible to adversarial attacks. We analyze DL-based models for a regression problem in the context of downlink power allocation in massive multiple-input-multiple-output systems and propose universal adversarial perturbation (UAP)-crafting methods as white-box and black-box attacks. We benchmark the UAP performance of white-box and black-box attacks for the considered application and show that the adversarial success rate can achieve up to 60% and 40%, respectively. The proposed UAP-based attacks make a more practical and realistic approach as compared to classical white-box attacks.

</p>
</details>

<details><summary><b>Scope2Screen: Focus+Context Techniques for Pathology Tumor Assessment in Multivariate Image Data</b>
<a href="https://arxiv.org/abs/2110.04875">arxiv:2110.04875</a>
&#x1F4C8; 0 <br>
<p>Jared Jessup, Robert Krueger, Simon Warchol, John Hoffer, Jeremy Muhlich, Cecily C. Ritch, Giorgio Gaglia, Shannon Coy, Yu-An Chen, Jia-Ren Lin, Sandro Santagata, Peter K. Sorger, Hanspeter Pfister</p></summary>
<p>

**Abstract:** Inspection of tissues using a light microscope is the primary method of diagnosing many diseases, notably cancer. Highly multiplexed tissue imaging builds on this foundation, enabling the collection of up to 60 channels of molecular information plus cell and tissue morphology using antibody staining. This provides unique insight into disease biology and promises to help with the design of patient-specific therapies. However, a substantial gap remains with respect to visualizing the resulting multivariate image data and effectively supporting pathology workflows in digital environments on screen. We, therefore, developed Scope2Screen, a scalable software system for focus+context exploration and annotation of whole-slide, high-plex, tissue images. Our approach scales to analyzing 100GB images of 10^9 or more pixels per channel, containing millions of cells. A multidisciplinary team of visualization experts, microscopists, and pathologists identified key image exploration and annotation tasks involving finding, magnifying, quantifying, and organizing ROIs in an intuitive and cohesive manner. Building on a scope2screen metaphor, we present interactive lensing techniques that operate at single-cell and tissue levels. Lenses are equipped with task-specific functionality and descriptive statistics, making it possible to analyze image features, cell types, and spatial arrangements (neighborhoods) across image channels and scales. A fast sliding-window search guides users to regions similar to those under the lens; these regions can be analyzed and considered either separately or as part of a larger image collection. A novel snapshot method enables linked lens configurations and image statistics to be saved, restored, and shared. We validate our designs with domain experts and apply Scope2Screen in two case studies involving lung and colorectal cancers to discover cancer-relevant image features.

</p>
</details>

<details><summary><b>Fat-shattering dimension of $k$-fold maxima</b>
<a href="https://arxiv.org/abs/2110.04763">arxiv:2110.04763</a>
&#x1F4C8; 0 <br>
<p>Aryeh Kontorovich, Idan Attias</p></summary>
<p>

**Abstract:** We provide improved estimates on the fat-shattering dimension of the $k$-fold maximum of real-valued function classes. The latter consists of all ways of choosing $k$ functions, one from each of the $k$ classes, and computing their pointwise maximum. The bound is stated in terms of the fat-shattering dimensions of the component classes. For linear and affine function classes, we provide a considerably sharper upper bound and a matching lower bound, achieving, in particular, an optimal dependence on $k$. Along the way, we point out and correct a number of erroneous claims in the literature.

</p>
</details>


[Next Page](2021/2021-10/2021-10-09.md)
