## Summary for 2021-03-23, created on 2021-12-23


<details><summary><b>The NLP Cookbook: Modern Recipes for Transformer based Deep Learning Architectures</b>
<a href="https://arxiv.org/abs/2104.10640">arxiv:2104.10640</a>
&#x1F4C8; 65 <br>
<p>Sushant Singh, Ausif Mahmood</p></summary>
<p>

**Abstract:** In recent years, Natural Language Processing (NLP) models have achieved phenomenal success in linguistic and semantic tasks like text classification, machine translation, cognitive dialogue systems, information retrieval via Natural Language Understanding (NLU), and Natural Language Generation (NLG). This feat is primarily attributed due to the seminal Transformer architecture, leading to designs such as BERT, GPT (I, II, III), etc. Although these large-size models have achieved unprecedented performances, they come at high computational costs. Consequently, some of the recent NLP architectures have utilized concepts of transfer learning, pruning, quantization, and knowledge distillation to achieve moderate model sizes while keeping nearly similar performances as achieved by their predecessors. Additionally, to mitigate the data size challenge raised by language models from a knowledge extraction perspective, Knowledge Retrievers have been built to extricate explicit data documents from a large corpus of databases with greater efficiency and accuracy. Recent research has also focused on superior inference by providing efficient attention to longer input sequences. In this paper, we summarize and examine the current state-of-the-art (SOTA) NLP models that have been employed for numerous NLP tasks for optimal performance and efficiency. We provide a detailed understanding and functioning of the different architectures, a taxonomy of NLP designs, comparative evaluations, and future directions in NLP.

</p>
</details>

<details><summary><b>Multilingual Autoregressive Entity Linking</b>
<a href="https://arxiv.org/abs/2103.12528">arxiv:2103.12528</a>
&#x1F4C8; 63 <br>
<p>Nicola De Cao, Ledell Wu, Kashyap Popat, Mikel Artetxe, Naman Goyal, Mikhail Plekhanov, Luke Zettlemoyer, Nicola Cancedda, Sebastian Riedel, Fabio Petroni</p></summary>
<p>

**Abstract:** We present mGENRE, a sequence-to-sequence system for the Multilingual Entity Linking (MEL) problem -- the task of resolving language-specific mentions to a multilingual Knowledge Base (KB). For a mention in a given language, mGENRE predicts the name of the target entity left-to-right, token-by-token in an autoregressive fashion. The autoregressive formulation allows us to effectively cross-encode mention string and entity names to capture more interactions than the standard dot product between mention and entity vectors. It also enables fast search within a large KB even for mentions that do not appear in mention tables and with no need for large-scale vector indices. While prior MEL works use a single representation for each entity, we match against entity names of as many languages as possible, which allows exploiting language connections between source input and target name. Moreover, in a zero-shot setting on languages with no training data at all, mGENRE treats the target language as a latent variable that is marginalized at prediction time. This leads to over 50% improvements in average accuracy. We show the efficacy of our approach through extensive evaluation including experiments on three popular MEL benchmarks where mGENRE establishes new state-of-the-art results. Code and pre-trained models at https://github.com/facebookresearch/GENRE.

</p>
</details>

<details><summary><b>Generative Minimization Networks: Training GANs Without Competition</b>
<a href="https://arxiv.org/abs/2103.12685">arxiv:2103.12685</a>
&#x1F4C8; 36 <br>
<p>Paulina Grnarova, Yannic Kilcher, Kfir Y. Levy, Aurelien Lucchi, Thomas Hofmann</p></summary>
<p>

**Abstract:** Many applications in machine learning can be framed as minimization problems and solved efficiently using gradient-based techniques. However, recent applications of generative models, particularly GANs, have triggered interest in solving min-max games for which standard optimization techniques are often not suitable. Among known problems experienced by practitioners is the lack of convergence guarantees or convergence to a non-optimum cycle. At the heart of these problems is the min-max structure of the GAN objective which creates non-trivial dependencies between the players. We propose to address this problem by optimizing a different objective that circumvents the min-max structure using the notion of duality gap from game theory. We provide novel convergence guarantees on this objective and demonstrate why the obtained limit point solves the problem better than known techniques.

</p>
</details>

<details><summary><b>Policy Information Capacity: Information-Theoretic Measure for Task Complexity in Deep Reinforcement Learning</b>
<a href="https://arxiv.org/abs/2103.12726">arxiv:2103.12726</a>
&#x1F4C8; 26 <br>
<p>Hiroki Furuta, Tatsuya Matsushima, Tadashi Kozuno, Yutaka Matsuo, Sergey Levine, Ofir Nachum, Shixiang Shane Gu</p></summary>
<p>

**Abstract:** Progress in deep reinforcement learning (RL) research is largely enabled by benchmark task environments. However, analyzing the nature of those environments is often overlooked. In particular, we still do not have agreeable ways to measure the difficulty or solvability of a task, given that each has fundamentally different actions, observations, dynamics, rewards, and can be tackled with diverse RL algorithms. In this work, we propose policy information capacity (PIC) -- the mutual information between policy parameters and episodic return -- and policy-optimal information capacity (POIC) -- between policy parameters and episodic optimality -- as two environment-agnostic, algorithm-agnostic quantitative metrics for task difficulty. Evaluating our metrics across toy environments as well as continuous control benchmark tasks from OpenAI Gym and DeepMind Control Suite, we empirically demonstrate that these information-theoretic metrics have higher correlations with normalized task solvability scores than a variety of alternatives. Lastly, we show that these metrics can also be used for fast and compute-efficient optimizations of key design parameters such as reward shaping, policy architectures, and MDP properties for better solvability by RL algorithms without ever running full RL experiments.

</p>
</details>

<details><summary><b>NaturalProofs: Mathematical Theorem Proving in Natural Language</b>
<a href="https://arxiv.org/abs/2104.01112">arxiv:2104.01112</a>
&#x1F4C8; 23 <br>
<p>Sean Welleck, Jiacheng Liu, Ronan Le Bras, Hannaneh Hajishirzi, Yejin Choi, Kyunghyun Cho</p></summary>
<p>

**Abstract:** Understanding and creating mathematics using natural mathematical language - the mixture of symbolic and natural language used by humans - is a challenging and important problem for driving progress in machine learning. As a step in this direction, we develop NaturalProofs, a multi-domain corpus of mathematical statements and their proofs, written in natural mathematical language. NaturalProofs unifies broad coverage, deep coverage, and low-resource mathematical sources, allowing for evaluating both in-distribution and zero-shot generalization. Using NaturalProofs, we benchmark strong neural methods on mathematical reference retrieval and generation tasks which test a system's ability to determine key results that appear in a proof. Large-scale sequence models show promise compared to classical information retrieval methods, yet their performance and out-of-domain generalization leave substantial room for improvement. NaturalProofs opens many avenues for research on challenging mathematical tasks.

</p>
</details>

<details><summary><b>Robust and Accurate Object Detection via Adversarial Learning</b>
<a href="https://arxiv.org/abs/2103.13886">arxiv:2103.13886</a>
&#x1F4C8; 22 <br>
<p>Xiangning Chen, Cihang Xie, Mingxing Tan, Li Zhang, Cho-Jui Hsieh, Boqing Gong</p></summary>
<p>

**Abstract:** Data augmentation has become a de facto component for training high-performance deep image classifiers, but its potential is under-explored for object detection. Noting that most state-of-the-art object detectors benefit from fine-tuning a pre-trained classifier, we first study how the classifiers' gains from various data augmentations transfer to object detection. The results are discouraging; the gains diminish after fine-tuning in terms of either accuracy or robustness. This work instead augments the fine-tuning stage for object detectors by exploring adversarial examples, which can be viewed as a model-dependent data augmentation. Our method dynamically selects the stronger adversarial images sourced from a detector's classification and localization branches and evolves with the detector to ensure the augmentation policy stays current and relevant. This model-dependent augmentation generalizes to different object detectors better than AutoAugment, a model-agnostic augmentation policy searched based on one particular detector. Our approach boosts the performance of state-of-the-art EfficientDets by +1.1 mAP on the COCO object detection benchmark. It also improves the detectors' robustness against natural distortions by +3.8 mAP and against domain shift by +1.3 mAP. Models are available at https://github.com/google/automl/tree/master/efficientdet/Det-AdvProp.md

</p>
</details>

<details><summary><b>ESCORT: Ethereum Smart COntRacTs Vulnerability Detection using Deep Neural Network and Transfer Learning</b>
<a href="https://arxiv.org/abs/2103.12607">arxiv:2103.12607</a>
&#x1F4C8; 16 <br>
<p>Oliver Lutz, Huili Chen, Hossein Fereidooni, Christoph Sendner, Alexandra Dmitrienko, Ahmad Reza Sadeghi, Farinaz Koushanfar</p></summary>
<p>

**Abstract:** Ethereum smart contracts are automated decentralized applications on the blockchain that describe the terms of the agreement between buyers and sellers, reducing the need for trusted intermediaries and arbitration. However, the deployment of smart contracts introduces new attack vectors into the cryptocurrency systems. In particular, programming flaws in smart contracts can be and have already been exploited to gain enormous financial profits. It is thus an emerging yet crucial issue to detect vulnerabilities of different classes in contracts in an efficient manner. Existing machine learning-based vulnerability detection methods are limited and only inspect whether the smart contract is vulnerable, or train individual classifiers for each specific vulnerability, or demonstrate multi-class vulnerability detection without extensibility consideration. To overcome the scalability and generalization limitations of existing works, we propose ESCORT, the first Deep Neural Network (DNN)-based vulnerability detection framework for Ethereum smart contracts that support lightweight transfer learning on unseen security vulnerabilities, thus is extensible and generalizable. ESCORT leverages a multi-output NN architecture that consists of two parts: (i) A common feature extractor that learns the semantics of the input contract; (ii) Multiple branch structures where each branch learns a specific vulnerability type based on features obtained from the feature extractor. Experimental results show that ESCORT achieves an average F1-score of 95% on six vulnerability types and the detection time is 0.02 seconds per contract. When extended to new vulnerability types, ESCORT yields an average F1-score of 93%. To the best of our knowledge, ESCORT is the first framework that enables transfer learning on new vulnerability types with minimal modification of the DNN model architecture and re-training overhead.

</p>
</details>

<details><summary><b>Promoting Fairness through Hyperparameter Optimization</b>
<a href="https://arxiv.org/abs/2103.12715">arxiv:2103.12715</a>
&#x1F4C8; 15 <br>
<p>André F. Cruz, Pedro Saleiro, Catarina Belém, Carlos Soares, Pedro Bizarro</p></summary>
<p>

**Abstract:** Considerable research effort has been guided towards algorithmic fairness but real-world adoption of bias reduction techniques is still scarce. Existing methods are either metric- or model-specific, require access to sensitive attributes at inference time, or carry high development or deployment costs. This work explores the unfairness that emerges when optimizing ML models solely for predictive performance, and how to mitigate it with a simple and easily deployed intervention: fairness-aware hyperparameter optimization (HO). We propose and evaluate fairness-aware variants of three popular HO algorithms: Fair Random Search, Fair TPE, and Fairband. We validate our approach on a real-world bank account opening fraud case-study, as well as on three datasets from the fairness literature. Results show that, without extra training cost, it is feasible to find models with 111% mean fairness increase and just 6% decrease in performance when compared with fairness-blind HO.

</p>
</details>

<details><summary><b>Learning to Optimize: A Primer and A Benchmark</b>
<a href="https://arxiv.org/abs/2103.12828">arxiv:2103.12828</a>
&#x1F4C8; 12 <br>
<p>Tianlong Chen, Xiaohan Chen, Wuyang Chen, Howard Heaton, Jialin Liu, Zhangyang Wang, Wotao Yin</p></summary>
<p>

**Abstract:** Learning to optimize (L2O) is an emerging approach that leverages machine learning to develop optimization methods, aiming at reducing the laborious iterations of hand engineering. It automates the design of an optimization method based on its performance on a set of training problems. This data-driven procedure generates methods that can efficiently solve problems similar to those in the training. In sharp contrast, the typical and traditional designs of optimization methods are theory-driven, so they obtain performance guarantees over the classes of problems specified by the theory. The difference makes L2O suitable for repeatedly solving a certain type of optimization problems over a specific distribution of data, while it typically fails on out-of-distribution problems. The practicality of L2O depends on the type of target optimization, the chosen architecture of the method to learn, and the training procedure. This new paradigm has motivated a community of researchers to explore L2O and report their findings.
  This article is poised to be the first comprehensive survey and benchmark of L2O for continuous optimization. We set up taxonomies, categorize existing works and research directions, present insights, and identify open challenges. We also benchmarked many existing L2O approaches on a few but representative optimization problems. For reproducible research and fair benchmarking purposes, we released our software implementation and data in the package Open-L2O at https://github.com/VITA-Group/Open-L2O.

</p>
</details>

<details><summary><b>Distributed Visual-Inertial Cooperative Localization</b>
<a href="https://arxiv.org/abs/2103.12770">arxiv:2103.12770</a>
&#x1F4C8; 10 <br>
<p>Pengxiang Zhu, Patrick Geneva, Wei Ren, Guoquan Huang</p></summary>
<p>

**Abstract:** In this paper we present a consistent and distributed state estimator for multi-robot cooperative localization (CL) which efficiently fuses environmental features and loop-closure constraints across time and robots. In particular, we leverage covariance intersection (CI) to allow each robot to only estimate its own state and autocovariance and compensate for the unknown correlations between robots. Two novel multi-robot methods for utilizing common environmental SLAM features are introduced and evaluated in terms of accuracy and efficiency. Moreover, we adapt CI to enable drift-free estimation through the use of loop-closure measurement constraints to other robots' historical poses without a significant increase in computational cost. The proposed distributed CL estimator is validated against its non-realtime centralized counterpart extensively in both simulations and real-world experiments.

</p>
</details>

<details><summary><b>Spatial Intention Maps for Multi-Agent Mobile Manipulation</b>
<a href="https://arxiv.org/abs/2103.12710">arxiv:2103.12710</a>
&#x1F4C8; 10 <br>
<p>Jimmy Wu, Xingyuan Sun, Andy Zeng, Shuran Song, Szymon Rusinkiewicz, Thomas Funkhouser</p></summary>
<p>

**Abstract:** The ability to communicate intention enables decentralized multi-agent robots to collaborate while performing physical tasks. In this work, we present spatial intention maps, a new intention representation for multi-agent vision-based deep reinforcement learning that improves coordination between decentralized mobile manipulators. In this representation, each agent's intention is provided to other agents, and rendered into an overhead 2D map aligned with visual observations. This synergizes with the recently proposed spatial action maps framework, in which state and action representations are spatially aligned, providing inductive biases that encourage emergent cooperative behaviors requiring spatial coordination, such as passing objects to each other or avoiding collisions. Experiments across a variety of multi-agent environments, including heterogeneous robot teams with different abilities (lifting, pushing, or throwing), show that incorporating spatial intention maps improves performance for different mobile manipulation tasks while significantly enhancing cooperative behaviors.

</p>
</details>

<details><summary><b>The Road to a Successful HRI: AI, Trust and ethicS-TRAITS</b>
<a href="https://arxiv.org/abs/2103.12679">arxiv:2103.12679</a>
&#x1F4C8; 10 <br>
<p>Antonio Andriella, Alessandra Rossi, Silvia Rossi, Anouk van Maris</p></summary>
<p>

**Abstract:** The aim of this workshop is to give researchers from academia and industry the possibility to discuss the inter-and multi-disciplinary nature of the relationships between people and robots towards effective and long-lasting collaborations. This workshop will provide a forum for the HRI and robotics communities to explore successful human-robot interaction (HRI) to analyse the different aspects of HRI that impact its success. Particular focus are the AI algorithms required to implement autonomous interactions, and the factors that enhance, undermine, or recover humans' trust in robots. Finally, potential ethical and legal concerns, and how they can be addressed will be considered. Website: https://sites.google.com/view/traits-hri

</p>
</details>

<details><summary><b>Virtual Light Transport Matrices for Non-Line-Of-Sight Imaging</b>
<a href="https://arxiv.org/abs/2103.12622">arxiv:2103.12622</a>
&#x1F4C8; 10 <br>
<p>Julio Marco, Adrian Jarabo, Ji Hyun Nam, Xiaochun Liu, Miguel Ángel Cosculluela, Andreas Velten, Diego Gutierrez</p></summary>
<p>

**Abstract:** The light transport matrix (LTM) is an instrumental tool in line-of-sight (LOS) imaging, describing how light interacts with the scene and enabling applications such as relighting or separation of illumination components. We introduce a framework to estimate the LTM of non-line-of-sight (NLOS) scenarios, coupling recent virtual forward light propagation models for NLOS imaging with the LOS light transport equation. We design computational projector-camera setups, and use these virtual imaging systems to estimate the transport matrix of hidden scenes. We introduce the specific illumination functions to compute the different elements of the matrix, overcoming the challenging wide-aperture conditions of NLOS setups. Our NLOS light transport matrix allows us to (re)illuminate specific locations of a hidden scene, and separate direct, first-order indirect, and higher-order indirect illumination of complex cluttered hidden scenes, similar to existing LOS techniques.

</p>
</details>

<details><summary><b>TMR: Evaluating NER Recall on Tough Mentions</b>
<a href="https://arxiv.org/abs/2103.12312">arxiv:2103.12312</a>
&#x1F4C8; 10 <br>
<p>Jingxuan Tu, Constantine Lignos</p></summary>
<p>

**Abstract:** We propose the Tough Mentions Recall (TMR) metrics to supplement traditional named entity recognition (NER) evaluation by examining recall on specific subsets of "tough" mentions: unseen mentions, those whose tokens or token/type combination were not observed in training, and type-confusable mentions, token sequences with multiple entity types in the test data. We demonstrate the usefulness of these metrics by evaluating corpora of English, Spanish, and Dutch using five recent neural architectures. We identify subtle differences between the performance of BERT and Flair on two English NER corpora and identify a weak spot in the performance of current models in Spanish. We conclude that the TMR metrics enable differentiation between otherwise similar-scoring systems and identification of patterns in performance that would go unnoticed from overall precision, recall, and F1.

</p>
</details>

<details><summary><b>VLGrammar: Grounded Grammar Induction of Vision and Language</b>
<a href="https://arxiv.org/abs/2103.12975">arxiv:2103.12975</a>
&#x1F4C8; 9 <br>
<p>Yining Hong, Qing Li, Song-Chun Zhu, Siyuan Huang</p></summary>
<p>

**Abstract:** Cognitive grammar suggests that the acquisition of language grammar is grounded within visual structures. While grammar is an essential representation of natural language, it also exists ubiquitously in vision to represent the hierarchical part-whole structure. In this work, we study grounded grammar induction of vision and language in a joint learning framework. Specifically, we present VLGrammar, a method that uses compound probabilistic context-free grammars (compound PCFGs) to induce the language grammar and the image grammar simultaneously. We propose a novel contrastive learning framework to guide the joint learning of both modules. To provide a benchmark for the grounded grammar induction task, we collect a large-scale dataset, \textsc{PartIt}, which contains human-written sentences that describe part-level semantics for 3D objects. Experiments on the \textsc{PartIt} dataset show that VLGrammar outperforms all baselines in image grammar induction and language grammar induction. The learned VLGrammar naturally benefits related downstream tasks. Specifically, it improves the image unsupervised clustering accuracy by 30\%, and performs well in image retrieval and text retrieval. Notably, the induced grammar shows superior generalizability by easily generalizing to unseen categories.

</p>
</details>

<details><summary><b>Towards a Formal Model of Narratives</b>
<a href="https://arxiv.org/abs/2103.12872">arxiv:2103.12872</a>
&#x1F4C8; 9 <br>
<p>Louis Castricato, Stella Biderman, Rogelio E. Cardona-Rivera, David Thue</p></summary>
<p>

**Abstract:** In this paper, we propose the beginnings of a formal framework for modeling narrative \textit{qua} narrative. Our framework affords the ability to discuss key qualities of stories and their communication, including the flow of information from a Narrator to a Reader, the evolution of a Reader's story model over time, and Reader uncertainty. We demonstrate its applicability to computational narratology by giving explicit algorithms for measuring the accuracy with which information was conveyed to the Reader and two novel measurements of story coherence.

</p>
</details>

<details><summary><b>SLOE: A Faster Method for Statistical Inference in High-Dimensional Logistic Regression</b>
<a href="https://arxiv.org/abs/2103.12725">arxiv:2103.12725</a>
&#x1F4C8; 9 <br>
<p>Steve Yadlowsky, Taedong Yun, Cory McLean, Alexander D'Amour</p></summary>
<p>

**Abstract:** Logistic regression remains one of the most widely used tools in applied statistics, machine learning and data science. However, in moderately high-dimensional problems, where the number of features $d$ is a non-negligible fraction of the sample size $n$, the logistic regression maximum likelihood estimator (MLE), and statistical procedures based the large-sample approximation of its distribution, behave poorly. Recently, Sur and Candès (2019) showed that these issues can be corrected by applying a new approximation of the MLE's sampling distribution in this high-dimensional regime. Unfortunately, these corrections are difficult to implement in practice, because they require an estimate of the \emph{signal strength}, which is a function of the underlying parameters $β$ of the logistic regression. To address this issue, we propose SLOE, a fast and straightforward approach to estimate the signal strength in logistic regression. The key insight of SLOE is that the Sur and Candès (2019) correction can be reparameterized in terms of the \emph{corrupted signal strength}, which is only a function of the estimated parameters $\widehat β$. We propose an estimator for this quantity, prove that it is consistent in the relevant high-dimensional regime, and show that dimensionality correction using SLOE is accurate in finite samples. Compared to the existing ProbeFrontier heuristic, SLOE is conceptually simpler and orders of magnitude faster, making it suitable for routine use. We demonstrate the importance of routine dimensionality correction in the Heart Disease dataset from the UCI repository, and a genomics application using data from the UK Biobank. We provide an open source package for this method, available at \url{https://github.com/google-research/sloe-logistic}.

</p>
</details>

<details><summary><b>An Exponential Lower Bound for Linearly-Realizable MDPs with Constant Suboptimality Gap</b>
<a href="https://arxiv.org/abs/2103.12690">arxiv:2103.12690</a>
&#x1F4C8; 9 <br>
<p>Yuanhao Wang, Ruosong Wang, Sham M. Kakade</p></summary>
<p>

**Abstract:** A fundamental question in the theory of reinforcement learning is: suppose the optimal $Q$-function lies in the linear span of a given $d$ dimensional feature mapping, is sample-efficient reinforcement learning (RL) possible? The recent and remarkable result of Weisz et al. (2020) resolved this question in the negative, providing an exponential (in $d$) sample size lower bound, which holds even if the agent has access to a generative model of the environment. One may hope that this information theoretic barrier for RL can be circumvented by further supposing an even more favorable assumption: there exists a \emph{constant suboptimality gap} between the optimal $Q$-value of the best action and that of the second-best action (for all states). The hope is that having a large suboptimality gap would permit easier identification of optimal actions themselves, thus making the problem tractable; indeed, provided the agent has access to a generative model, sample-efficient RL is in fact possible with the addition of this more favorable assumption.
  This work focuses on this question in the standard online reinforcement learning setting, where our main result resolves this question in the negative: our hardness result shows that an exponential sample complexity lower bound still holds even if a constant suboptimality gap is assumed in addition to having a linearly realizable optimal $Q$-function. Perhaps surprisingly, this implies an exponential separation between the online RL setting and the generative model setting. Complementing our negative hardness result, we give two positive results showing that provably sample-efficient RL is possible either under an additional low-variance assumption or under a novel hypercontractivity assumption (both implicitly place stronger conditions on the underlying dynamics model).

</p>
</details>

<details><summary><b>What is the Vocabulary of Flaky Tests? An Extended Replication</b>
<a href="https://arxiv.org/abs/2103.12670">arxiv:2103.12670</a>
&#x1F4C8; 8 <br>
<p>B. H. P. Camara, M. A. G. Silva, A. T. Endo, S. R. Vergilio</p></summary>
<p>

**Abstract:** Software systems have been continuously evolved and delivered with high quality due to the widespread adoption of automated tests. A recurring issue hurting this scenario is the presence of flaky tests, a test case that may pass or fail non-deterministically. A promising, but yet lacking more empirical evidence, approach is to collect static data of automated tests and use them to predict their flakiness. In this paper, we conducted an empirical study to assess the use of code identifiers to predict test flakiness. To do so, we first replicate most parts of the previous study of Pinto~et~al.~(MSR~2020). This replication was extended by using a different ML Python platform (Scikit-learn) and adding different learning algorithms in the analyses. Then, we validated the performance of trained models using datasets with other flaky tests and from different projects. We successfully replicated the results of Pinto~et~al.~(2020), with minor differences using Scikit-learn; different algorithms had performance similar to the ones used previously. Concerning the validation, we noticed that the recall of the trained models was smaller, and classifiers presented a varying range of decreases. This was observed in both intra-project and inter-projects test flakiness prediction.

</p>
</details>

<details><summary><b>BossNAS: Exploring Hybrid CNN-transformers with Block-wisely Self-supervised Neural Architecture Search</b>
<a href="https://arxiv.org/abs/2103.12424">arxiv:2103.12424</a>
&#x1F4C8; 8 <br>
<p>Changlin Li, Tao Tang, Guangrun Wang, Jiefeng Peng, Bing Wang, Xiaodan Liang, Xiaojun Chang</p></summary>
<p>

**Abstract:** A myriad of recent breakthroughs in hand-crafted neural architectures for visual recognition have highlighted the urgent need to explore hybrid architectures consisting of diversified building blocks. Meanwhile, neural architecture search methods are surging with an expectation to reduce human efforts. However, whether NAS methods can efficiently and effectively handle diversified search spaces with disparate candidates (e.g. CNNs and transformers) is still an open question. In this work, we present Block-wisely Self-supervised Neural Architecture Search (BossNAS), an unsupervised NAS method that addresses the problem of inaccurate architecture rating caused by large weight-sharing space and biased supervision in previous methods. More specifically, we factorize the search space into blocks and utilize a novel self-supervised training scheme, named ensemble bootstrapping, to train each block separately before searching them as a whole towards the population center. Additionally, we present HyTra search space, a fabric-like hybrid CNN-transformer search space with searchable down-sampling positions. On this challenging search space, our searched model, BossNet-T, achieves up to 82.5% accuracy on ImageNet, surpassing EfficientNet by 2.4% with comparable compute time. Moreover, our method achieves superior architecture rating accuracy with 0.78 and 0.76 Spearman correlation on the canonical MBConv search space with ImageNet and on NATS-Bench size search space with CIFAR-100, respectively, surpassing state-of-the-art NAS methods. Code: https://github.com/changlin31/BossNAS

</p>
</details>

<details><summary><b>Extracting Causal Visual Features for Limited label Classification</b>
<a href="https://arxiv.org/abs/2103.12322">arxiv:2103.12322</a>
&#x1F4C8; 7 <br>
<p>Mohit Prabhushankar, Ghassan AlRegib</p></summary>
<p>

**Abstract:** Neural networks trained to classify images do so by identifying features that allow them to distinguish between classes. These sets of features are either causal or context dependent. Grad-CAM is a popular method of visualizing both sets of features. In this paper, we formalize this feature divide and provide a methodology to extract causal features from Grad-CAM. We do so by defining context features as those features that allow contrast between predicted class and any contrast class. We then apply a set theoretic approach to separate causal from contrast features for COVID-19 CT scans. We show that on average, the image regions with the proposed causal features require 15% less bits when encoded using Huffman encoding, compared to Grad-CAM, for an average increase of 3% classification accuracy, over Grad-CAM. Moreover, we validate the transfer-ability of causal features between networks and comment on the non-human interpretable causal nature of current networks.

</p>
</details>

<details><summary><b>IAIA-BL: A Case-based Interpretable Deep Learning Model for Classification of Mass Lesions in Digital Mammography</b>
<a href="https://arxiv.org/abs/2103.12308">arxiv:2103.12308</a>
&#x1F4C8; 7 <br>
<p>Alina Jade Barnett, Fides Regina Schwartz, Chaofan Tao, Chaofan Chen, Yinhao Ren, Joseph Y. Lo, Cynthia Rudin</p></summary>
<p>

**Abstract:** Interpretability in machine learning models is important in high-stakes decisions, such as whether to order a biopsy based on a mammographic exam. Mammography poses important challenges that are not present in other computer vision tasks: datasets are small, confounding information is present, and it can be difficult even for a radiologist to decide between watchful waiting and biopsy based on a mammogram alone. In this work, we present a framework for interpretable machine learning-based mammography. In addition to predicting whether a lesion is malignant or benign, our work aims to follow the reasoning processes of radiologists in detecting clinically relevant semantic features of each image, such as the characteristics of the mass margins. The framework includes a novel interpretable neural network algorithm that uses case-based reasoning for mammography. Our algorithm can incorporate a combination of data with whole image labelling and data with pixel-wise annotations, leading to better accuracy and interpretability even with a small number of images. Our interpretable models are able to highlight the classification-relevant parts of the image, whereas other methods highlight healthy tissue and confounding information. Our models are decision aids, rather than decision makers, aimed at better overall human-machine collaboration. We do not observe a loss in mass margin classification accuracy over a black box neural network trained on the same data.

</p>
</details>

<details><summary><b>Revisiting Self-Supervised Monocular Depth Estimation</b>
<a href="https://arxiv.org/abs/2103.12496">arxiv:2103.12496</a>
&#x1F4C8; 6 <br>
<p>Ue-Hwan Kim, Jong-Hwan Kim</p></summary>
<p>

**Abstract:** Self-supervised learning of depth map prediction and motion estimation from monocular video sequences is of vital importance -- since it realizes a broad range of tasks in robotics and autonomous vehicles. A large number of research efforts have enhanced the performance by tackling illumination variation, occlusions, and dynamic objects, to name a few. However, each of those efforts targets individual goals and endures as separate works. Moreover, most of previous works have adopted the same CNN architecture, not reaping architectural benefits. Therefore, the need to investigate the inter-dependency of the previous methods and the effect of architectural factors remains. To achieve these objectives, we revisit numerous previously proposed self-supervised methods for joint learning of depth and motion, perform a comprehensive empirical study, and unveil multiple crucial insights. Furthermore, we remarkably enhance the performance as a result of our study -- outperforming previous state-of-the-art performance.

</p>
</details>

<details><summary><b>On Imitation Learning of Linear Control Policies: Enforcing Stability and Robustness Constraints via LMI Conditions</b>
<a href="https://arxiv.org/abs/2103.12945">arxiv:2103.12945</a>
&#x1F4C8; 5 <br>
<p>Aaron Havens, Bin Hu</p></summary>
<p>

**Abstract:** When applying imitation learning techniques to fit a policy from expert demonstrations, one can take advantage of prior stability/robustness assumptions on the expert's policy and incorporate such control-theoretic prior knowledge explicitly into the learning process. In this paper, we formulate the imitation learning of linear policies as a constrained optimization problem, and present efficient methods which can be used to enforce stability and robustness constraints during the learning processes. Specifically, we show that one can guarantee the closed-loop stability and robustness by posing linear matrix inequality (LMI) constraints on the fitted policy. Then both the projected gradient descent method and the alternating direction method of multipliers (ADMM) method can be applied to solve the resulting constrained policy fitting problem. Finally, we provide numerical results to demonstrate the effectiveness of our methods in producing linear polices with various stability and robustness guarantees.

</p>
</details>

<details><summary><b>SETGAN: Scale and Energy Trade-off GANs for Image Applications on Mobile Platforms</b>
<a href="https://arxiv.org/abs/2103.12896">arxiv:2103.12896</a>
&#x1F4C8; 5 <br>
<p>Nitthilan Kannappan Jayakodi, Janardhan Rao Doppa, Partha Pratim Pande</p></summary>
<p>

**Abstract:** We consider the task of photo-realistic unconditional image generation (generate high quality, diverse samples that carry the same visual content as the image) on mobile platforms using Generative Adversarial Networks (GANs). In this paper, we propose a novel approach to trade-off image generation accuracy of a GAN for the energy consumed (compute) at run-time called Scale-Energy Tradeoff GAN (SETGAN). GANs usually take a long time to train and consume a huge memory hence making it difficult to run on edge devices. The key idea behind SETGAN for an image generation task is for a given input image, we train a GAN on a remote server and use the trained model on edge devices. We use SinGAN, a single image unconditional generative model, that contains a pyramid of fully convolutional GANs, each responsible for learning the patch distribution at a different scale of the image. During the training process, we determine the optimal number of scales for a given input image and the energy constraint from the target edge device. Results show that with SETGAN's unique client-server-based architecture, we were able to achieve a 56% gain in energy for a loss of 3% to 12% SSIM accuracy. Also, with the parallel multi-scale training, we obtain around 4x gain in training time on the server.

</p>
</details>

<details><summary><b>PSIMiner: A Tool for Mining Rich Abstract Syntax Trees from Code</b>
<a href="https://arxiv.org/abs/2103.12778">arxiv:2103.12778</a>
&#x1F4C8; 5 <br>
<p>Egor Spirin, Egor Bogomolov, Vladimir Kovalenko, Timofey Bryksin</p></summary>
<p>

**Abstract:** The application of machine learning algorithms to source code has grown in the past years. Since these algorithms are quite sensitive to input data, it is not surprising that researchers experiment with input representations. Nowadays, a popular starting point to represent code is abstract syntax trees (ASTs). Abstract syntax trees have been used for a long time in various software engineering domains, and in particular in IDEs. The API of modern IDEs allows to manipulate and traverse ASTs, resolve references between code elements, etc. Such algorithms can enrich ASTs with new data and therefore may be useful in ML-based code analysis. In this work, we present PSIMiner - a tool for processing PSI trees from the IntelliJ Platform. PSI trees contain code syntax trees as well as functions to work with them, and therefore can be used to enrich code representation using static analysis algorithms of modern IDEs. To showcase this idea, we use our tool to infer types of identifiers in Java ASTs and extend the code2seq model for the method name prediction problem.

</p>
</details>

<details><summary><b>Unsupervised Contextual Paraphrase Generation using Lexical Control and Reinforcement Learning</b>
<a href="https://arxiv.org/abs/2103.12777">arxiv:2103.12777</a>
&#x1F4C8; 5 <br>
<p>Sonal Garg, Sumanth Prabhu, Hemant Misra, G. Srinivasaraghavan</p></summary>
<p>

**Abstract:** Customer support via chat requires agents to resolve customer queries with minimum wait time and maximum customer satisfaction. Given that the agents as well as the customers can have varying levels of literacy, the overall quality of responses provided by the agents tend to be poor if they are not predefined. But using only static responses can lead to customer detraction as the customers tend to feel that they are no longer interacting with a human. Hence, it is vital to have variations of the static responses to reduce monotonicity of the responses. However, maintaining a list of such variations can be expensive. Given the conversation context and the agent response, we propose an unsupervised frame-work to generate contextual paraphrases using autoregressive models. We also propose an automated metric based on Semantic Similarity, Textual Entailment, Expression Diversity and Fluency to evaluate the quality of contextual paraphrases and demonstrate performance improvement with Reinforcement Learning (RL) fine-tuning using the automated metric as the reward function.

</p>
</details>

<details><summary><b>CLIP: Cheap Lipschitz Training of Neural Networks</b>
<a href="https://arxiv.org/abs/2103.12531">arxiv:2103.12531</a>
&#x1F4C8; 5 <br>
<p>Leon Bungert, René Raab, Tim Roith, Leo Schwinn, Daniel Tenbrinck</p></summary>
<p>

**Abstract:** Despite the large success of deep neural networks (DNN) in recent years, most neural networks still lack mathematical guarantees in terms of stability. For instance, DNNs are vulnerable to small or even imperceptible input perturbations, so called adversarial examples, that can cause false predictions. This instability can have severe consequences in applications which influence the health and safety of humans, e.g., biomedical imaging or autonomous driving. While bounding the Lipschitz constant of a neural network improves stability, most methods rely on restricting the Lipschitz constants of each layer which gives a poor bound for the actual Lipschitz constant.
  In this paper we investigate a variational regularization method named CLIP for controlling the Lipschitz constant of a neural network, which can easily be integrated into the training procedure. We mathematically analyze the proposed model, in particular discussing the impact of the chosen regularization parameter on the output of the network. Finally, we numerically evaluate our method on both a nonlinear regression problem and the MNIST and Fashion-MNIST classification databases, and compare our results with a weight regularization approach.

</p>
</details>

<details><summary><b>The Success of AdaBoost and Its Application in Portfolio Management</b>
<a href="https://arxiv.org/abs/2103.12345">arxiv:2103.12345</a>
&#x1F4C8; 5 <br>
<p>Yijian Chuan, Chaoyi Zhao, Zhenrui He, Lan Wu</p></summary>
<p>

**Abstract:** We develop a novel approach to explain why AdaBoost is a successful classifier. By introducing a measure of the influence of the noise points (ION) in the training data for the binary classification problem, we prove that there is a strong connection between the ION and the test error. We further identify that the ION of AdaBoost decreases as the iteration number or the complexity of the base learners increases. We confirm that it is impossible to obtain a consistent classifier without deep trees as the base learners of AdaBoost in some complicated situations. We apply AdaBoost in portfolio management via empirical studies in the Chinese market, which corroborates our theoretical propositions.

</p>
</details>

<details><summary><b>Self-supervised representation learning from 12-lead ECG data</b>
<a href="https://arxiv.org/abs/2103.12676">arxiv:2103.12676</a>
&#x1F4C8; 4 <br>
<p>Temesgen Mehari, Nils Strodthoff</p></summary>
<p>

**Abstract:** We put forward a comprehensive assessment of self-supervised representation learning from short segments of clinical 12-lead electrocardiography (ECG) data. To this end, we explore adaptations of state-of-the-art self-supervised learning algorithms from computer vision (SimCLR, BYOL, SwAV) and speech (CPC). In a first step, we learn contrastive representations and evaluate their quality based on linear evaluation performance on a downstream classification task. For the best-performing method, CPC, we find linear evaluation performances only 0.8% below supervised performance. In a second step, we analyze the impact of self-supervised pretraining on finetuned ECG classifiers as compared to purely supervised performance and find improvements in downstream performance of more than 1%, label efficiency, as well as an increased robustness against physiological noise. All experiments are carried out exclusively on publicly available datasets, the to-date largest collection used for self-supervised representation learning from ECG data, to foster reproducible research in the field of ECG representation learning.

</p>
</details>

<details><summary><b>An augmentation strategy to mimic multi-scanner variability in MRI</b>
<a href="https://arxiv.org/abs/2103.12595">arxiv:2103.12595</a>
&#x1F4C8; 4 <br>
<p>Maria Ines Meyer, Ezequiel de la Rosa, Nuno Barros, Roberto Paolella, Koen Van Leemput, Diana M. Sima</p></summary>
<p>

**Abstract:** Most publicly available brain MRI datasets are very homogeneous in terms of scanner and protocols, and it is difficult for models that learn from such data to generalize to multi-center and multi-scanner data. We propose a novel data augmentation approach with the aim of approximating the variability in terms of intensities and contrasts present in real world clinical data. We use a Gaussian Mixture Model based approach to change tissue intensities individually, producing new contrasts while preserving anatomical information. We train a deep learning model on a single scanner dataset and evaluate it on a multi-center and multi-scanner dataset. The proposed approach improves the generalization capability of the model to other scanners not present in the training data.

</p>
</details>

<details><summary><b>Assured Learning-enabled Autonomy: A Metacognitive Reinforcement Learning Framework</b>
<a href="https://arxiv.org/abs/2103.12558">arxiv:2103.12558</a>
&#x1F4C8; 4 <br>
<p>Aquib Mustafa, Majid Mazouchi, Subramanya Nageshrao, Hamidreza Modares</p></summary>
<p>

**Abstract:** Reinforcement learning (RL) agents with pre-specified reward functions cannot provide guaranteed safety across variety of circumstances that an uncertain system might encounter. To guarantee performance while assuring satisfaction of safety constraints across variety of circumstances, an assured autonomous control framework is presented in this paper by empowering RL algorithms with metacognitive learning capabilities. More specifically, adapting the reward function parameters of the RL agent is performed in a metacognitive decision-making layer to assure the feasibility of RL agent. That is, to assure that the learned policy by the RL agent satisfies safety constraints specified by signal temporal logic while achieving as much performance as possible. The metacognitive layer monitors any possible future safety violation under the actions of the RL agent and employs a higher-layer Bayesian RL algorithm to proactively adapt the reward function for the lower-layer RL agent. To minimize the higher-layer Bayesian RL intervention, a fitness function is leveraged by the metacognitive layer as a metric to evaluate success of the lower-layer RL agent in satisfaction of safety and liveness specifications, and the higher-layer Bayesian RL intervenes only if there is a risk of lower-layer RL failure. Finally, a simulation example is provided to validate the effectiveness of the proposed approach.

</p>
</details>

<details><summary><b>Watermark Faker: Towards Forgery of Digital Image Watermarking</b>
<a href="https://arxiv.org/abs/2103.12489">arxiv:2103.12489</a>
&#x1F4C8; 4 <br>
<p>Ruowei Wang, Chenguo Lin, Qijun Zhao, Feiyu Zhu</p></summary>
<p>

**Abstract:** Digital watermarking has been widely used to protect the copyright and integrity of multimedia data. Previous studies mainly focus on designing watermarking techniques that are robust to attacks of destroying the embedded watermarks. However, the emerging deep learning based image generation technology raises new open issues that whether it is possible to generate fake watermarked images for circumvention. In this paper, we make the first attempt to develop digital image watermark fakers by using generative adversarial learning. Suppose that a set of paired images of original and watermarked images generated by the targeted watermarker are available, we use them to train a watermark faker with U-Net as the backbone, whose input is an original image, and after a domain-specific preprocessing, it outputs a fake watermarked image. Our experiments show that the proposed watermark faker can effectively crack digital image watermarkers in both spatial and frequency domains, suggesting the risk of such forgery attacks.

</p>
</details>

<details><summary><b>RPATTACK: Refined Patch Attack on General Object Detectors</b>
<a href="https://arxiv.org/abs/2103.12469">arxiv:2103.12469</a>
&#x1F4C8; 4 <br>
<p>Hao Huang, Yongtao Wang, Zhaoyu Chen, Zhi Tang, Wenqiang Zhang, Kai-Kuang Ma</p></summary>
<p>

**Abstract:** Nowadays, general object detectors like YOLO and Faster R-CNN as well as their variants are widely exploited in many applications. Many works have revealed that these detectors are extremely vulnerable to adversarial patch attacks. The perturbed regions generated by previous patch-based attack works on object detectors are very large which are not necessary for attacking and perceptible for human eyes. To generate much less but more efficient perturbation, we propose a novel patch-based method for attacking general object detectors. Firstly, we propose a patch selection and refining scheme to find the pixels which have the greatest importance for attack and remove the inconsequential perturbations gradually. Then, for a stable ensemble attack, we balance the gradients of detectors to avoid over-optimizing one of them during the training phase. Our RPAttack can achieve an amazing missed detection rate of 100% for both Yolo v4 and Faster R-CNN while only modifies 0.32% pixels on VOC 2007 test set. Our code is available at https://github.com/VDIGPKU/RPAttack.

</p>
</details>

<details><summary><b>Neural Network Controller for Autonomous Pile Loading Revised</b>
<a href="https://arxiv.org/abs/2103.12379">arxiv:2103.12379</a>
&#x1F4C8; 4 <br>
<p>Wenyan Yang, Nataliya Strokina, Nikolay Serbenyuk, Joni Pajarinen, Reza Ghabcheloo, Juho Vihonen, Mohammad M. Aref, Joni-Kristian Kämäräinen</p></summary>
<p>

**Abstract:** We have recently proposed two pile loading controllers that learn from human demonstrations: a neural network (NNet) [1] and a random forest (RF) controller [2]. In the field experiments the RF controller obtained clearly better success rates. In this work, the previous findings are drastically revised by experimenting summer time trained controllers in winter conditions. The winter experiments revealed a need for additional sensors, more training data, and a controller that can take advantage of these. Therefore, we propose a revised neural controller (NNetV2) which has a more expressive structure and uses a neural attention mechanism to focus on important parts of the sensor and control signals. Using the same data and sensors to train and test the three controllers, NNetV2 achieves better robustness against drastically changing conditions and superior success rate. To the best of our knowledge, this is the first work testing a learning-based controller for a heavy-duty machine in drastically varying outdoor conditions and delivering high success rate in winter, being trained in summer.

</p>
</details>

<details><summary><b>Any Part of Bayesian Network Structure Learning</b>
<a href="https://arxiv.org/abs/2103.13810">arxiv:2103.13810</a>
&#x1F4C8; 3 <br>
<p>Zhaolong Ling, Kui Yu, Hao Wang, Lin Liu, Jiuyong Li</p></summary>
<p>

**Abstract:** We study an interesting and challenging problem, learning any part of a Bayesian network (BN) structure. In this challenge, it will be computationally inefficient using existing global BN structure learning algorithms to find an entire BN structure to achieve the part of a BN structure in which we are interested. And local BN structure learning algorithms encounter the false edge orientation problem when they are directly used to tackle this challenging problem. In this paper, we first present a new concept of Expand-Backtracking to explain why local BN structure learning methods have the false edge orientation problem, then propose APSL, an efficient and accurate Any Part of BN Structure Learning algorithm. Specifically, APSL divides the V-structures in a Markov blanket (MB) into two types: collider V-structure and non-collider V-structure, then it starts from a node of interest and recursively finds both collider V-structures and non-collider V-structures in the found MBs, until the part of a BN structure in which we are interested are oriented. To improve the efficiency of APSL, we further design the APSL-FS algorithm using Feature Selection, APSL-FS. Using six benchmark BNs, the extensive experiments have validated the efficiency and accuracy of our methods.

</p>
</details>

<details><summary><b>Automatic Cough Classification for Tuberculosis Screening in a Real-World Environment</b>
<a href="https://arxiv.org/abs/2103.13300">arxiv:2103.13300</a>
&#x1F4C8; 3 <br>
<p>Madhurananda Pahar, Marisa Klopper, Byron Reeve, Grant Theron, Rob Warren, Thomas Niesler</p></summary>
<p>

**Abstract:** Objective: The automatic discrimination between the coughing sounds produced by patients with tuberculosis (TB) and those produced by patients with other lung ailments.
  Approach: We present experiments based on a dataset of 1358 forced cough recordings obtained in a developing-world clinic from 16 patients with confirmed active pulmonary TB and 35 patients suffering from respiratory conditions suggestive of TB but confirmed to be TB negative. Using nested cross-validation, we have trained and evaluated five machine learning classifiers: logistic regression (LR), support vector machines (SVM), k-nearest neighbour (KNN), multilayer perceptrons (MLP) and convolutional neural networks (CNN).
  Main Results: Although classification is possible in all cases, the best performance is achieved using LR. In combination with feature selection by sequential forward selection (SFS), our best LR system achieves an area under the ROC curve (AUC) of 0.94 using 23 features selected from a set of 78 high-resolution mel-frequency cepstral coefficients (MFCCs). This system achieves a sensitivity of 93\% at a specificity of 95\% and thus exceeds the 90\% sensitivity at 70\% specificity specification considered by the World Health Organisation (WHO) as a minimal requirement for a community-based TB triage test.
  Significance: The automatic classification of cough audio sounds, when applied to symptomatic patients requiring investigation for TB, can meet the WHO triage specifications for the identification of patients who should undergo expensive molecular downstream testing. This makes it a promising and viable means of low cost, easily deployable frontline screening for TB, which can benefit especially developing countries with a heavy TB burden.

</p>
</details>

<details><summary><b>Counterfactual Explanation with Multi-Agent Reinforcement Learning for Drug Target Prediction</b>
<a href="https://arxiv.org/abs/2103.12983">arxiv:2103.12983</a>
&#x1F4C8; 3 <br>
<p>Tri Minh Nguyen, Thomas P Quinn, Thin Nguyen, Truyen Tran</p></summary>
<p>

**Abstract:** Motivation: Many high-performance DTA models have been proposed, but they are mostly black-box and thus lack human interpretability. Explainable AI (XAI) can make DTA models more trustworthy, and can also enable scientists to distill biological knowledge from the models. Counterfactual explanation is one popular approach to explaining the behaviour of a deep neural network, which works by systematically answering the question "How would the model output change if the inputs were changed in this way?". Most counterfactual explanation methods only operate on single input data. It remains an open problem how to extend counterfactual-based XAI methods to DTA models, which have two inputs, one for drug and one for target, that also happen to be discrete in nature.
  Methods: We propose a multi-agent reinforcement learning framework, Multi-Agent Counterfactual Drug target binding Affinity (MACDA), to generate counterfactual explanations for the drug-protein complex. Our proposed framework provides human-interpretable counterfactual instances while optimizing both the input drug and target for counterfactual generation at the same time.
  Results: We benchmark the proposed MACDA framework using the Davis dataset and find that our framework produces more parsimonious explanations with no loss in explanation validity, as measured by encoding similarity and QED. We then present a case study involving ABL1 and Nilotinib to demonstrate how MACDA can explain the behaviour of a DTA model in the underlying substructure interaction between inputs in its prediction, revealing mechanisms that align with prior domain knowledge.

</p>
</details>

<details><summary><b>Facility Reallocation on the Line</b>
<a href="https://arxiv.org/abs/2103.12894">arxiv:2103.12894</a>
&#x1F4C8; 3 <br>
<p>Bart de Keijzer, Dominik Wojtczak</p></summary>
<p>

**Abstract:** We consider a multi-stage facility reallocation problems on the real line, where a facility is being moved between time stages based on the locations reported by $n$ agents. The aim of the reallocation algorithm is to minimise the social cost, i.e., the sum over the total distance between the facility and all agents at all stages, plus the cost incurred for moving the facility. We study this problem both in the offline setting and online setting. In the offline case the algorithm has full knowledge of the agent locations in all future stages, and in the online setting the algorithm does not know these future locations and must decide the location of the facility on a stage-per-stage basis. We derive the optimal algorithm in both cases. For the online setting we show that its competitive ratio is $(n+2)/(n+1)$. As neither of these algorithms turns out to yield a strategy-proof mechanism, we propose another strategy-proof mechanism which has a competitive ratio of $(n+3)/(n+1)$ for odd $n$ and $(n+4)/n$ for even $n$, which we conjecture to be the best possible. We also consider a generalisation with multiple facilities and weighted agents, for which we show that the optimum can be computed in polynomial time for a fixed number of facilities.

</p>
</details>

<details><summary><b>Co-matching: Combating Noisy Labels by Augmentation Anchoring</b>
<a href="https://arxiv.org/abs/2103.12814">arxiv:2103.12814</a>
&#x1F4C8; 3 <br>
<p>Yangdi Lu, Yang Bo, Wenbo He</p></summary>
<p>

**Abstract:** Deep learning with noisy labels is challenging as deep neural networks have the high capacity to memorize the noisy labels. In this paper, we propose a learning algorithm called Co-matching, which balances the consistency and divergence between two networks by augmentation anchoring. Specifically, we have one network generate anchoring label from its prediction on a weakly-augmented image. Meanwhile, we force its peer network, taking the strongly-augmented version of the same image as input, to generate prediction close to the anchoring label. We then update two networks simultaneously by selecting small-loss instances to minimize both unsupervised matching loss (i.e., measure the consistency of the two networks) and supervised classification loss (i.e. measure the classification performance). Besides, the unsupervised matching loss makes our method not heavily rely on noisy labels, which prevents memorization of noisy labels. Experiments on three benchmark datasets demonstrate that Co-matching achieves results comparable to the state-of-the-art methods.

</p>
</details>

<details><summary><b>PanGEA: The Panoramic Graph Environment Annotation Toolkit</b>
<a href="https://arxiv.org/abs/2103.12703">arxiv:2103.12703</a>
&#x1F4C8; 3 <br>
<p>Alexander Ku, Peter Anderson, Jordi Pont-Tuset, Jason Baldridge</p></summary>
<p>

**Abstract:** PanGEA, the Panoramic Graph Environment Annotation toolkit, is a lightweight toolkit for collecting speech and text annotations in photo-realistic 3D environments. PanGEA immerses annotators in a web-based simulation and allows them to move around easily as they speak and/or listen. It includes database and cloud storage integration, plus utilities for automatically aligning recorded speech with manual transcriptions and the virtual pose of the annotators. Out of the box, PanGEA supports two tasks -- collecting navigation instructions and navigation instruction following -- and it could be easily adapted for annotating walking tours, finding and labeling landmarks or objects, and similar tasks. We share best practices learned from using PanGEA in a 20,000 hour annotation effort to collect the Room-Across-Room dataset. We hope that our open-source annotation toolkit and insights will both expedite future data collection efforts and spur innovation on the kinds of grounded language tasks such environments can support.

</p>
</details>

<details><summary><b>Benign Overfitting of Constant-Stepsize SGD for Linear Regression</b>
<a href="https://arxiv.org/abs/2103.12692">arxiv:2103.12692</a>
&#x1F4C8; 3 <br>
<p>Difan Zou, Jingfeng Wu, Vladimir Braverman, Quanquan Gu, Sham M. Kakade</p></summary>
<p>

**Abstract:** There is an increasing realization that algorithmic inductive biases are central in preventing overfitting; empirically, we often see a benign overfitting phenomenon in overparameterized settings for natural learning algorithms, such as stochastic gradient descent (SGD), where little to no explicit regularization has been employed. This work considers this issue in arguably the most basic setting: constant-stepsize SGD (with iterate averaging or tail averaging) for linear regression in the overparameterized regime. Our main result provides a sharp excess risk bound, stated in terms of the full eigenspectrum of the data covariance matrix, that reveals a bias-variance decomposition characterizing when generalization is possible: (i) the variance bound is characterized in terms of an effective dimension (specific for SGD) and (ii) the bias bound provides a sharp geometric characterization in terms of the location of the initial iterate (and how it aligns with the data covariance matrix). More specifically, for SGD with iterate averaging, we demonstrate the sharpness of the established excess risk bound by proving a matching lower bound (up to constant factors). For SGD with tail averaging, we show its advantage over SGD with iterate averaging by proving a better excess risk bound together with a nearly matching lower bound. Moreover, we reflect on a number of notable differences between the algorithmic regularization afforded by (unregularized) SGD in comparison to ordinary least squares (minimum-norm interpolation) and ridge regression. Experimental results on synthetic data corroborate our theoretical findings.

</p>
</details>

<details><summary><b>A News Recommender System Considering Temporal Dynamics and Diversity</b>
<a href="https://arxiv.org/abs/2103.12537">arxiv:2103.12537</a>
&#x1F4C8; 3 <br>
<p>Shaina Raza</p></summary>
<p>

**Abstract:** In a news recommender system, a reader's preferences change over time. Some preferences drift quite abruptly (short-term preferences), while others change over a longer period of time (long-term preferences). Although the existing news recommender systems consider the reader's full history, they often ignore the dynamics in the reader's behavior. Thus, they cannot meet the demand of the news readers for their time-varying preferences. In addition, the state-of-the-art news recommendation models are often focused on providing accurate predictions, which can work well in traditional recommendation scenarios. However, in a news recommender system, diversity is essential, not only to keep news readers engaged, but also to play a key role in a democratic society. In this PhD dissertation, our goal is to build a news recommender system to address these two challenges. Our system should be able to: (i) accommodate the dynamics in reader behavior; and (ii) consider both accuracy and diversity in the design of the recommendation model. Our news recommender system can also work for unprofiled, anonymous and short-term readers, by leveraging the rich side information of the news items and by including the implicit feedback in our model. We evaluate our model with multiple evaluation measures (both accuracy and diversity-oriented metrics) to demonstrate the effectiveness of our methods.

</p>
</details>

<details><summary><b>Bandits with many optimal arms</b>
<a href="https://arxiv.org/abs/2103.12452">arxiv:2103.12452</a>
&#x1F4C8; 3 <br>
<p>Rianne de Heide, James Cheshire, Pierre Ménard, Alexandra Carpentier</p></summary>
<p>

**Abstract:** We consider a stochastic bandit problem with a possibly infinite number of arms. We write $p^*$ for the proportion of optimal arms and $Δ$ for the minimal mean-gap between optimal and sub-optimal arms. We characterize the optimal learning rates both in the cumulative regret setting, and in the best-arm identification setting in terms of the problem parameters $T$ (the budget), $p^*$ and $Δ$. For the objective of minimizing the cumulative regret, we provide a lower bound of order $Ω(\log(T)/(p^*Δ))$ and a UCB-style algorithm with matching upper bound up to a factor of $\log(1/Δ)$. Our algorithm needs $p^*$ to calibrate its parameters, and we prove that this knowledge is necessary, since adapting to $p^*$ in this setting is impossible. For best-arm identification we also provide a lower bound of order $Ω(\exp(-cTΔ^2 p^*))$ on the probability of outputting a sub-optimal arm where $c>0$ is an absolute constant. We also provide an elimination algorithm with an upper bound matching the lower bound up to a factor of order $\log(T)$ in the exponential, and that does not need $p^*$ or $Δ$ as parameter. Our results apply directly to the three related problems of competing against the $j$-th best arm, identifying an $ε$ good arm, and finding an arm with mean larger than a quantile of a known order.

</p>
</details>

<details><summary><b>A New Approach To Text Rating Classification Using Sentiment Analysis</b>
<a href="https://arxiv.org/abs/2103.12368">arxiv:2103.12368</a>
&#x1F4C8; 3 <br>
<p>Thomas Konstantinovsky</p></summary>
<p>

**Abstract:** Typical use cases of sentiment analysis usually revolve around assessing the probability of a text belonging to a certain sentiment and deriving insight concerning it; little work has been done to explore further use cases derived using those probabilities in the context of rating. In this paper, we redefine the sentiment proportion values as building blocks for a triangle structure, allowing us to derive variables for a new formula for classifying text given in the form of product reviews into a group of higher and a group of lower ratings and prove a dependence exists between the sentiments and the ratings.

</p>
</details>

<details><summary><b>Contrastive Reasoning in Neural Networks</b>
<a href="https://arxiv.org/abs/2103.12329">arxiv:2103.12329</a>
&#x1F4C8; 3 <br>
<p>Mohit Prabhushankar, Ghassan AlRegib</p></summary>
<p>

**Abstract:** Neural networks represent data as projections on trained weights in a high dimensional manifold. The trained weights act as a knowledge base consisting of causal class dependencies. Inference built on features that identify these dependencies is termed as feed-forward inference. Such inference mechanisms are justified based on classical cause-to-effect inductive reasoning models. Inductive reasoning based feed-forward inference is widely used due to its mathematical simplicity and operational ease. Nevertheless, feed-forward models do not generalize well to untrained situations. To alleviate this generalization challenge, we propose using an effect-to-cause inference model that reasons abductively. Here, the features represent the change from existing weight dependencies given a certain effect. We term this change as contrast and the ensuing reasoning mechanism as contrastive reasoning. In this paper, we formalize the structure of contrastive reasoning and propose a methodology to extract a neural network's notion of contrast. We demonstrate the value of contrastive reasoning in two stages of a neural network's reasoning pipeline : in inferring and visually explaining decisions for the application of object recognition. We illustrate the value of contrastively recognizing images under distortions by reporting an improvement of 3.47%, 2.56%, and 5.48% in average accuracy under the proposed contrastive framework on CIFAR-10C, noisy STL-10, and VisDA datasets respectively.

</p>
</details>

<details><summary><b>From Semantic Retrieval to Pairwise Ranking: Applying Deep Learning in E-commerce Search</b>
<a href="https://arxiv.org/abs/2103.12982">arxiv:2103.12982</a>
&#x1F4C8; 2 <br>
<p>Rui Li, Yunjiang Jiang, Wenyun Yang, Guoyu Tang, Songlin Wang, Chaoyi Ma, Wei He, Xi Xiong, Yun Xiao, Eric Yihong Zhao</p></summary>
<p>

**Abstract:** We introduce deep learning models to the two most important stages in product search at JD.com, one of the largest e-commerce platforms in the world. Specifically, we outline the design of a deep learning system that retrieves semantically relevant items to a query within milliseconds, and a pairwise deep re-ranking system, which learns subtle user preferences. Compared to traditional search systems, the proposed approaches are better at semantic retrieval and personalized ranking, achieving significant improvements.

</p>
</details>

<details><summary><b>Meta-Learned Invariant Risk Minimization</b>
<a href="https://arxiv.org/abs/2103.12947">arxiv:2103.12947</a>
&#x1F4C8; 2 <br>
<p>Jun-Hyun Bae, Inchul Choi, Minho Lee</p></summary>
<p>

**Abstract:** Empirical Risk Minimization (ERM) based machine learning algorithms have suffered from weak generalization performance on data obtained from out-of-distribution (OOD). To address this problem, Invariant Risk Minimization (IRM) objective was suggested to find invariant optimal predictor which is less affected by the changes in data distribution. However, even with such progress, IRMv1, the practical formulation of IRM, still shows performance degradation when there are not enough training data, and even fails to generalize to OOD, if the number of spurious correlations is larger than the number of environments. In this paper, to address such problems, we propose a novel meta-learning based approach for IRM. In this method, we do not assume the linearity of classifier for the ease of optimization, and solve ideal bi-level IRM objective with Model-Agnostic Meta-Learning (MAML) framework. Our method is more robust to the data with spurious correlations and can provide an invariant optimal classifier even when data from each distribution are scarce. In experiments, we demonstrate that our algorithm not only has better OOD generalization performance than IRMv1 and all IRM variants, but also addresses the weakness of IRMv1 with improved stability.

</p>
</details>

<details><summary><b>Teacher-Explorer-Student Learning: A Novel Learning Method for Open Set Recognition</b>
<a href="https://arxiv.org/abs/2103.12871">arxiv:2103.12871</a>
&#x1F4C8; 2 <br>
<p>Jaeyeon Jang, Chang Ouk Kim</p></summary>
<p>

**Abstract:** If an unknown example that is not seen during training appears, most recognition systems usually produce overgeneralized results and determine that the example belongs to one of the known classes. To address this problem, teacher-explorer-student (T/E/S) learning, which adopts the concept of open set recognition (OSR) that aims to reject unknown samples while minimizing the loss of classification performance on known samples, is proposed in this study. In this novel learning method, overgeneralization of deep learning classifiers is significantly reduced by exploring various possibilities of unknowns. Here, the teacher network extracts some hints about unknowns by distilling the pretrained knowledge about knowns and delivers this distilled knowledge to the student. After learning the distilled knowledge, the student network shares the learned information with the explorer network. Then, the explorer network shares its exploration results by generating unknown-like samples and feeding the samples to the student network. By repeating this alternating learning process, the student network experiences a variety of synthetic unknowns, reducing overgeneralization. Extensive experiments were conducted, and the experimental results showed that each component proposed in this paper significantly contributes to the improvement in OSR performance. As a result, the proposed T/E/S learning method outperformed current state-of-the-art methods.

</p>
</details>

<details><summary><b>PAC-Bayesian theory for stochastic LTI systems</b>
<a href="https://arxiv.org/abs/2103.12866">arxiv:2103.12866</a>
&#x1F4C8; 2 <br>
<p>Deividas Eringis, John Leth, Zheng-Hua Tan, Rafal Wisniewski, Alireza Fakhrizadeh Esfahani, Mihaly Petreczky</p></summary>
<p>

**Abstract:** In this paper we derive a PAC-Bayesian error bound for autonomous stochastic LTI state-space models. The motivation for deriving such error bounds is that they will allow deriving similar error bounds for more general dynamical systems, including recurrent neural networks. In turn, PACBayesian error bounds are known to be useful for analyzing machine learning algorithms and for deriving new ones.

</p>
</details>

<details><summary><b>Integrating Novelty Detection Capabilities with MSL Mastcam Operations to Enhance Data Analysis</b>
<a href="https://arxiv.org/abs/2103.12815">arxiv:2103.12815</a>
&#x1F4C8; 2 <br>
<p>Paul Horton, Hannah R. Kerner, Samantha Jacob, Ernest Cisneros, Kiri L. Wagstaff, James Bell</p></summary>
<p>

**Abstract:** While innovations in scientific instrumentation have pushed the boundaries of Mars rover mission capabilities, the increase in data complexity has pressured Mars Science Laboratory (MSL) and future Mars rover operations staff to quickly analyze complex data sets to meet progressively shorter tactical and strategic planning timelines. MSLWEB is an internal data tracking tool used by operations staff to perform first pass analysis on MSL image sequences, a series of products taken by the Mast camera, Mastcam. Mastcam's multiband multispectral image sequences require more complex analysis compared to standard 3-band RGB images. Typically, these are analyzed using traditional methods to identify unique features within the sequence. Given the short time frame of tactical planning in which downlinked images might need to be analyzed (within 5-10 hours before the next uplink), there exists a need to triage analysis time to focus on the most important sequences and parts of a sequence. We address this need by creating products for MSLWEB that use novelty detection to help operations staff identify unusual data that might be diagnostic of new or atypical compositions or mineralogies detected within an imaging scene. This was achieved in two ways: 1) by creating products for each sequence to identify novel regions in the image, and 2) by assigning multispectral sequences a sortable novelty score. These new products provide colorized heat maps of inferred novelty that operations staff can use to rapidly review downlinked data and focus their efforts on analyzing potentially new kinds of diagnostic multispectral signatures. This approach has the potential to guide scientists to new discoveries by quickly drawing their attention to often subtle variations not detectable with simple color composites.

</p>
</details>

<details><summary><b>Towards interpretability of Mixtures of Hidden Markov Models</b>
<a href="https://arxiv.org/abs/2103.12576">arxiv:2103.12576</a>
&#x1F4C8; 2 <br>
<p>Negar Safinianaini, Henrik Boström</p></summary>
<p>

**Abstract:** Mixtures of Hidden Markov Models (MHMMs) are frequently used for clustering of sequential data. An important aspect of MHMMs, as of any clustering approach, is that they can be interpretable, allowing for novel insights to be gained from the data. However, without a proper way of measuring interpretability, the evaluation of novel contributions is difficult and it becomes practically impossible to devise techniques that directly optimize this property. In this work, an information-theoretic measure (entropy) is proposed for interpretability of MHMMs, and based on that, a novel approach to improve model interpretability is proposed, i.e., an entropy-regularized Expectation Maximization (EM) algorithm. The new approach aims for reducing the entropy of the Markov chains (involving state transition matrices) within an MHMM, i.e., assigning higher weights to common state transitions during clustering. It is argued that this entropy reduction, in general, leads to improved interpretability since the most influential and important state transitions of the clusters can be more easily identified. An empirical investigation shows that it is possible to improve the interpretability of MHMMs, as measured by entropy, without sacrificing (but rather improving) clustering performance and computational costs, as measured by the v-measure and number of EM iterations, respectively.

</p>
</details>

<details><summary><b>NNrepair: Constraint-based Repair of Neural Network Classifiers</b>
<a href="https://arxiv.org/abs/2103.12535">arxiv:2103.12535</a>
&#x1F4C8; 2 <br>
<p>Muhammad Usman, Divya Gopinath, Youcheng Sun, Yannic Noller, Corina Pasareanu</p></summary>
<p>

**Abstract:** We present NNrepair, a constraint-based technique for repairing neural network classifiers. The technique aims to fix the logic of the network at an intermediate layer or at the last layer. NNrepair first uses fault localization to find potentially faulty network parameters (such as the weights) and then performs repair using constraint solving to apply small modifications to the parameters to remedy the defects. We present novel strategies to enable precise yet efficient repair such as inferring correctness specifications to act as oracles for intermediate layer repair, and generation of experts for each class. We demonstrate the technique in the context of three different scenarios: (1) Improving the overall accuracy of a model, (2) Fixing security vulnerabilities caused by poisoning of training data and (3) Improving the robustness of the network against adversarial attacks. Our evaluation on MNIST and CIFAR-10 models shows that NNrepair can improve the accuracy by 45.56 percentage points on poisoned data and 10.40 percentage points on adversarial data. NNrepair also provides small improvement in the overall accuracy of models, without requiring new data or re-training.

</p>
</details>

<details><summary><b>Balanced Softmax Cross-Entropy for Incremental Learning</b>
<a href="https://arxiv.org/abs/2103.12532">arxiv:2103.12532</a>
&#x1F4C8; 2 <br>
<p>Quentin Jodelet, Xin Liu, Tsuyoshi Murata</p></summary>
<p>

**Abstract:** Deep neural networks are prone to catastrophic forgetting when incrementally trained on new classes or new tasks as adaptation to the new data leads to a drastic decrease of the performance on the old classes and tasks. By using a small memory for rehearsal and knowledge distillation, recent methods have proven to be effective to mitigate catastrophic forgetting. However due to the limited size of the memory, large imbalance between the amount of data available for the old and new classes still remains which results in a deterioration of the overall accuracy of the model. To address this problem, we propose the use of the Balanced Softmax Cross-Entropy loss and show that it can be combined with exiting methods for incremental learning to improve their performances while also decreasing the computational cost of the training procedure in some cases. Complete experiments on the competitive ImageNet, subImageNet and CIFAR100 datasets show states-of-the-art results.

</p>
</details>

<details><summary><b>Are Neural Language Models Good Plagiarists? A Benchmark for Neural Paraphrase Detection</b>
<a href="https://arxiv.org/abs/2103.12450">arxiv:2103.12450</a>
&#x1F4C8; 2 <br>
<p>Jan Philip Wahle, Terry Ruas, Norman Meuschke, Bela Gipp</p></summary>
<p>

**Abstract:** The rise of language models such as BERT allows for high-quality text paraphrasing. This is a problem to academic integrity, as it is difficult to differentiate between original and machine-generated content. We propose a benchmark consisting of paraphrased articles using recent language models relying on the Transformer architecture. Our contribution fosters future research of paraphrase detection systems as it offers a large collection of aligned original and paraphrased documents, a study regarding its structure, classification experiments with state-of-the-art systems, and we make our findings publicly available.

</p>
</details>

<details><summary><b>Binary disease prediction using tail quantiles of the distribution of continuous biomarkers</b>
<a href="https://arxiv.org/abs/2103.12409">arxiv:2103.12409</a>
&#x1F4C8; 2 <br>
<p>Michiel H. J. Paus, Edwin R. van den Heuvel, Marc J. M. Meddens</p></summary>
<p>

**Abstract:** In the analysis of binary disease classification, single biomarkers might not have significant discriminating power and multiple biomarkers from a large set of biomarkers should be selected. Numerous approaches exist, but they merely work well for mean differences in biomarkers between cases and controls. Biological processes are however much more heterogeneous, and differences could also occur in other distributional characteristics (e.g. variances, skewness). Many machine learning techniques are better capable of utilizing these higher order distributional differences, sometimes at cost of explainability.
  In this study we propose quantile based prediction (QBP), a binary classification method that is based on the selection of multiple continuous biomarkers. QBP generates a single score using the tails of the biomarker distributions for cases and controls. This single score can then be evaluated by ROC analysis to investigate its predictive power.
  The performance of QBP is compared to supervised learning methods using extensive simulation studies, and two case studies: major depression disorder and trisomy. Simultaneously, the classification performance of the existing techniques in relation to each other is assessed. The key strengths of QBP are the opportunity to select relevant biomarkers and the outstanding classification performance in the case biomarkers predominantly show variance differences between cases and controls. When only shifts in means were present in the biomarkers, QBP obtained an inferior performance. Lastly, QBP proved to be unbiased in case of absence of disease relevant biomarkers and outperformed the other methods on the MDD case study.
  More research is needed to further optimize QBP, since it has several opportunities to improve its performance. Here we wanted to introduce the principle of QBP and show its potential.

</p>
</details>

<details><summary><b>Diversity Regularized Interests Modeling for Recommender Systems</b>
<a href="https://arxiv.org/abs/2103.12404">arxiv:2103.12404</a>
&#x1F4C8; 2 <br>
<p>Junmei Hao, Jingcheng Shi, Qing Da, Anxiang Zeng, Yujie Dun, Xueming Qian, Qianying Lin</p></summary>
<p>

**Abstract:** With the rapid development of E-commerce and the increase in the quantity of items, users are presented with more items hence their interests broaden. It is increasingly difficult to model user intentions with traditional methods, which model the user's preference for an item by combining a single user vector and an item vector. Recently, some methods are proposed to generate multiple user interest vectors and achieve better performance compared to traditional methods. However, empirical studies demonstrate that vectors generated from these multi-interests methods are sometimes homogeneous, which may lead to sub-optimal performance. In this paper, we propose a novel method of Diversity Regularized Interests Modeling (DRIM) for Recommender Systems. We apply a capsule network in a multi-interest extractor to generate multiple user interest vectors. Each interest of the user should have a certain degree of distinction, thus we introduce three strategies as the diversity regularized separator to separate multiple user interest vectors. Experimental results on public and industrial data sets demonstrate the ability of the model to capture different interests of a user and the superior performance of the proposed approach.

</p>
</details>

<details><summary><b>The Hammer and the Nut: Is Bilevel Optimization Really Needed to Poison Linear Classifiers?</b>
<a href="https://arxiv.org/abs/2103.12399">arxiv:2103.12399</a>
&#x1F4C8; 2 <br>
<p>Antonio Emanuele Cinà, Sebastiano Vascon, Ambra Demontis, Battista Biggio, Fabio Roli, Marcello Pelillo</p></summary>
<p>

**Abstract:** One of the most concerning threats for modern AI systems is data poisoning, where the attacker injects maliciously crafted training data to corrupt the system's behavior at test time. Availability poisoning is a particularly worrisome subset of poisoning attacks where the attacker aims to cause a Denial-of-Service (DoS) attack. However, the state-of-the-art algorithms are computationally expensive because they try to solve a complex bi-level optimization problem (the "hammer"). We observed that in particular conditions, namely, where the target model is linear (the "nut"), the usage of computationally costly procedures can be avoided. We propose a counter-intuitive but efficient heuristic that allows contaminating the training set such that the target system's performance is highly compromised. We further suggest a re-parameterization trick to decrease the number of variables to be optimized. Finally, we demonstrate that, under the considered settings, our framework achieves comparable, or even better, performances in terms of the attacker's objective while being significantly more computationally efficient.

</p>
</details>

<details><summary><b>ReCU: Reviving the Dead Weights in Binary Neural Networks</b>
<a href="https://arxiv.org/abs/2103.12369">arxiv:2103.12369</a>
&#x1F4C8; 2 <br>
<p>Zihan Xu, Mingbao Lin, Jianzhuang Liu, Jie Chen, Ling Shao, Yue Gao, Yonghong Tian, Rongrong Ji</p></summary>
<p>

**Abstract:** Binary neural networks (BNNs) have received increasing attention due to their superior reductions of computation and memory. Most existing works focus on either lessening the quantization error by minimizing the gap between the full-precision weights and their binarization or designing a gradient approximation to mitigate the gradient mismatch, while leaving the "dead weights" untouched. This leads to slow convergence when training BNNs. In this paper, for the first time, we explore the influence of "dead weights" which refer to a group of weights that are barely updated during the training of BNNs, and then introduce rectified clamp unit (ReCU) to revive the "dead weights" for updating. We prove that reviving the "dead weights" by ReCU can result in a smaller quantization error. Besides, we also take into account the information entropy of the weights, and then mathematically analyze why the weight standardization can benefit BNNs. We demonstrate the inherent contradiction between minimizing the quantization error and maximizing the information entropy, and then propose an adaptive exponential scheduler to identify the range of the "dead weights". By considering the "dead weights", our method offers not only faster BNN training, but also state-of-the-art performance on CIFAR-10 and ImageNet, compared with recent methods. Code can be available at https://github.com/z-hXu/ReCU.

</p>
</details>

<details><summary><b>Joint Distribution across Representation Space for Out-of-Distribution Detection</b>
<a href="https://arxiv.org/abs/2103.12344">arxiv:2103.12344</a>
&#x1F4C8; 2 <br>
<p>JingWei Xu, Siyuan Zhu, Zenan Li, Chang Xu</p></summary>
<p>

**Abstract:** Deep neural networks (DNNs) have become a key part of many modern software applications. After training and validating, the DNN is deployed as an irrevocable component and applied in real-world scenarios. Although most DNNs are built meticulously with huge volumes of training data, data in the real world still remain unknown to the DNN model, which leads to the crucial requirement of runtime out-of-distribution (OOD) detection. However, many existing approaches 1) need OOD data for classifier training or parameter tuning, or 2) simply combine the scores of each hidden layer as an ensemble of features for OOD detection. In this paper, we present a novel outlook on in-distribution data in a generative manner, which takes their latent features generated from each hidden layer as a joint distribution across representation spaces. Since only the in-distribution latent features are comprehensively understood in representation space, the internal difference between in-distribution and OOD data can be naturally revealed without the intervention of any OOD data. Specifically, We construct a generative model, called Latent Sequential Gaussian Mixture (LSGM), to depict how the in-distribution latent features are generated in terms of the trace of DNN inference across representation spaces. We first construct the Gaussian Mixture Model (GMM) based on in-distribution latent features for each hidden layer, and then connect GMMs via the transition probabilities of the inference traces. Experimental evaluations on popular benchmark OOD datasets and models validate the superiority of the proposed method over the state-of-the-art methods in OOD detection.

</p>
</details>

<details><summary><b>Anomaly detection using principles of human perception</b>
<a href="https://arxiv.org/abs/2103.12323">arxiv:2103.12323</a>
&#x1F4C8; 2 <br>
<p>Mohammad Nassir</p></summary>
<p>

**Abstract:** In the fields of statistics and unsupervised machine learning a fundamental and well-studied problem is anomaly detection. Although anomalies are difficult to define, many algorithms have been proposed. Underlying the approaches is the nebulous understanding that anomalies are rare, unusual or inconsistent with the majority of data. The present work gives a philosophical approach to clearly define anomalies and to develop an algorithm for their efficient detection with minimal user intervention. Inspired by the Gestalt School of Psychology and the Helmholtz principle of human perception, the idea is to assume anomalies are observations that are unexpected to occur with respect to certain groupings made by the majority of the data. Thus, under appropriate random variable modelling anomalies are directly found in a set of data under a uniform and independent random assumption of the distribution of constituent elements of the observations; anomalies correspond to those observations where the expectation of occurrence of the elements in a given view is $<1$. Starting from fundamental principles of human perception an unsupervised anomaly detection algorithm is developed that is simple, real-time and parameter-free. Experiments suggest it as the prime choice for univariate data and it shows promising performance on the detection of global anomalies in multivariate data.

</p>
</details>

<details><summary><b>Learning 6DoF Grasping Using Reward-Consistent Demonstration</b>
<a href="https://arxiv.org/abs/2103.12321">arxiv:2103.12321</a>
&#x1F4C8; 2 <br>
<p>Daichi Kawakami, Ryoichi Ishikawa, Menandro Roxas, Yoshihiro Sato, Takeshi Oishi</p></summary>
<p>

**Abstract:** As the number of the robot's degrees of freedom increases, the implementation of robot motion becomes more complex and difficult. In this study, we focus on learning 6DOF-grasping motion and consider dividing the grasping motion into multiple tasks. We propose to combine imitation and reinforcement learning in order to facilitate a more efficient learning of the desired motion. In order to collect demonstration data as teacher data for the imitation learning, we created a virtual reality (VR) interface that allows humans to operate the robot intuitively. Moreover, by dividing the motion into simpler tasks, we simplify the design of reward functions for reinforcement learning and show in our experiments a reduction in the steps required to learn the grasping motion.

</p>
</details>

<details><summary><b>SuctionNet-1Billion: A Large-Scale Benchmark for Suction Grasping</b>
<a href="https://arxiv.org/abs/2103.12311">arxiv:2103.12311</a>
&#x1F4C8; 2 <br>
<p>Hanwen Cao, Hao-Shu Fang, Wenhai Liu, Cewu Lu</p></summary>
<p>

**Abstract:** Suction is an important solution for the longstanding robotic grasping problem. Compared with other kinds of grasping, suction grasping is easier to represent and often more reliable in practice. Though preferred in many scenarios, it is not fully investigated and lacks sufficient training data and evaluation benchmarks. To address that, firstly, we propose a new physical model to analytically evaluate seal formation and wrench resistance of a suction grasping, which are two key aspects of grasp success. Secondly, a two-step methodology is adopted to generate annotations on a large-scale dataset collected in real-world cluttered scenarios. Thirdly, a standard online evaluation system is proposed to evaluate suction poses in continuous operation space, which can benchmark different algorithms fairly without the need of exhaustive labeling. Real-robot experiments are conducted to show that our annotations align well with real world. Meanwhile, we propose a method to predict numerous suction poses from an RGB-D image of a cluttered scene and demonstrate our superiority against several previous methods. Result analyses are further provided to help readers better understand the challenges in this area. Data and source code are publicly available at www.graspnet.net.

</p>
</details>

<details><summary><b>CNN vs ELM for Image-Based Malware Classification</b>
<a href="https://arxiv.org/abs/2103.13820">arxiv:2103.13820</a>
&#x1F4C8; 1 <br>
<p>Mugdha Jain, William Andreopoulos, Mark Stamp</p></summary>
<p>

**Abstract:** Research in the field of malware classification often relies on machine learning models that are trained on high-level features, such as opcodes, function calls, and control flow graphs. Extracting such features is costly, since disassembly or code execution is generally required. In this paper, we conduct experiments to train and evaluate machine learning models for malware classification, based on features that can be obtained without disassembly or execution of code. Specifically, we visualize malware samples as images and employ image analysis techniques. In this context, we focus on two machine learning models, namely, Convolutional Neural Networks (CNN) and Extreme Learning Machines (ELM). Surprisingly, we find that ELMs can achieve accuracies on par with CNNs, yet ELM training requires less than~2\%\ of the time needed to train a comparable CNN.

</p>
</details>

<details><summary><b>Convergence Analysis of Nonconvex Distributed Stochastic Zeroth-order Coordinate Method</b>
<a href="https://arxiv.org/abs/2103.12954">arxiv:2103.12954</a>
&#x1F4C8; 1 <br>
<p>Shengjun Zhang, Yunlong Dong, Dong Xie, Lisha Yao, Colleen P. Bailey, Shengli Fu</p></summary>
<p>

**Abstract:** This paper investigates the stochastic distributed nonconvex optimization problem of minimizing a global cost function formed by the summation of $n$ local cost functions. We solve such a problem by involving zeroth-order (ZO) information exchange. In this paper, we propose a ZO distributed primal-dual coordinate method (ZODIAC) to solve the stochastic optimization problem. Agents approximate their own local stochastic ZO oracle along with coordinates with an adaptive smoothing parameter. We show that the proposed algorithm achieves the convergence rate of $\mathcal{O}(\sqrt{p}/\sqrt{T})$ for general nonconvex cost functions. We demonstrate the efficiency of proposed algorithms through a numerical example in comparison with the existing state-of-the-art centralized and distributed ZO algorithms.

</p>
</details>

<details><summary><b>Fully-echoed Q-routing with Simulated Annealing Inference for Flying Adhoc Networks</b>
<a href="https://arxiv.org/abs/2103.12870">arxiv:2103.12870</a>
&#x1F4C8; 1 <br>
<p>Arnau Rovira-Sugranes, Fatemeh Afghah, Junsuo Qu, Abolfazl Razi</p></summary>
<p>

**Abstract:** Current networking protocols deem inefficient in accommodating the two key challenges of Unmanned Aerial Vehicle (UAV) networks, namely the network connectivity loss and energy limitations. One approach to solve these issues is using learning-based routing protocols to make close-to-optimal local decisions by the network nodes, and Q-routing is a bold example of such protocols. However, the performance of the current implementations of Q-routing algorithms is not yet satisfactory, mainly due to the lack of adaptability to continued topology changes. In this paper, we propose a full-echo Q-routing algorithm with a self-adaptive learning rate that utilizes Simulated Annealing (SA) optimization to control the exploration rate of the algorithm through the temperature decline rate, which in turn is regulated by the experienced variation rate of the Q-values. Our results show that our method adapts to the network dynamicity without the need for manual re-initialization at transition points (abrupt network topology changes). Our method exhibits a reduction in the energy consumption ranging from 7% up to 82%, as well as a 2.6 fold gain in successful packet delivery rate}, compared to the state of the art Q-routing protocols

</p>
</details>

<details><summary><b>Multipath-based SLAM using Belief Propagation with Interacting Multiple Dynamic Models</b>
<a href="https://arxiv.org/abs/2103.12809">arxiv:2103.12809</a>
&#x1F4C8; 1 <br>
<p>Erik Leitinger, Stefan Grebien, Klaus Witrisal</p></summary>
<p>

**Abstract:** In this paper, we present a Bayesian multipath-based simultaneous localization and mapping (SLAM) algorithm that continuously adapts interacting multiple models (IMM) parameters to describe the mobile agent state dynamics. The time-evolution of the IMM parameters is described by a Markov chain and the parameters are incorporated into the factor graph structure that represents the statistical structure of the SLAM problem. The proposed belief propagation (BP)-based algorithm adapts, in an online manner, to time-varying system models by jointly inferring the model parameters along with the agent and map feature states. The performance of the proposed algorithm is finally evaluating with a simulated scenario. Our numerical simulation results show that the proposed multipath-based SLAM algorithm is able to cope with strongly changing agent state dynamics.

</p>
</details>

<details><summary><b>Can I Solve It? Identifying APIs Required to Complete OSS Task</b>
<a href="https://arxiv.org/abs/2103.12653">arxiv:2103.12653</a>
&#x1F4C8; 1 <br>
<p>Fabio Santos, Igor Wiese, Bianca Trinkenreich, Igor Steinmacher, Anita Sarma, Marco Gerosa</p></summary>
<p>

**Abstract:** Open Source Software projects add labels to open issues to help contributors choose tasks. However, manually labeling issues is time-consuming and error-prone. Current automatic approaches for creating labels are mostly limited to classifying issues as a bug/non-bug. In this paper, we investigate the feasibility and relevance of labeling issues with the domain of the APIs required to complete the tasks. We leverage the issues' description and the project history to build prediction models, which resulted in precision up to 82% and recall up to 97.8%. We also ran a user study (n=74) to assess these labels' relevancy to potential contributors. The results show that the labels were useful to participants in choosing tasks, and the API-domain labels were selected more often than the existing architecture-based labels. Our results can inspire the creation of tools to automatically label issues, helping developers to find tasks that better match their skills.

</p>
</details>

<details><summary><b>Deep Learning for fully automatic detection, segmentation, and Gleason Grade estimation of prostate cancer in multiparametric Magnetic Resonance Images</b>
<a href="https://arxiv.org/abs/2103.12650">arxiv:2103.12650</a>
&#x1F4C8; 1 <br>
<p>Oscar J. Pellicer-Valero, José L. Marenco Jiménez, Victor Gonzalez-Perez, Juan Luis Casanova Ramón-Borja, Isabel Martín García, María Barrios Benito, Paula Pelechano Gómez, José Rubio-Briones, María José Rupérez, José D. Martín-Guerrero</p></summary>
<p>

**Abstract:** The emergence of multi-parametric magnetic resonance imaging (mpMRI) has had a profound impact on the diagnosis of prostate cancers (PCa), which is the most prevalent malignancy in males in the western world, enabling a better selection of patients for confirmation biopsy. However, analyzing these images is complex even for experts, hence opening an opportunity for computer-aided diagnosis systems to seize. This paper proposes a fully automatic system based on Deep Learning that takes a prostate mpMRI from a PCa-suspect patient and, by leveraging the Retina U-Net detection framework, locates PCa lesions, segments them, and predicts their most likely Gleason grade group (GGG). It uses 490 mpMRIs for training/validation, and 75 patients for testing from two different datasets: ProstateX and IVO (Valencia Oncology Institute Foundation). In the test set, it achieves an excellent lesion-level AUC/sensitivity/specificity for the GGG$\geq$2 significance criterion of 0.96/1.00/0.79 for the ProstateX dataset, and 0.95/1.00/0.80 for the IVO dataset. Evaluated at a patient level, the results are 0.87/1.00/0.375 in ProstateX, and 0.91/1.00/0.762 in IVO. Furthermore, on the online ProstateX grand challenge, the model obtained an AUC of 0.85 (0.87 when trained only on the ProstateX data, tying up with the original winner of the challenge). For expert comparison, IVO radiologist's PI-RADS 4 sensitivity/specificity were 0.88/0.56 at a lesion level, and 0.85/0.58 at a patient level. Additional subsystems for automatic prostate zonal segmentation and mpMRI non-rigid sequence registration were also employed to produce the final fully automated system. The code for the ProstateX-trained system has been made openly available at https://github.com/OscarPellicer/prostate_lesion_detection. We hope that this will represent a landmark for future research to use, compare and improve upon.

</p>
</details>

<details><summary><b>GA-SVM for Evaluating Heroin Consumption Risk</b>
<a href="https://arxiv.org/abs/2103.12633">arxiv:2103.12633</a>
&#x1F4C8; 1 <br>
<p>Sean-Kelly Palicki, R. Muhammad Atif Azad</p></summary>
<p>

**Abstract:** There were over 70,000 drug overdose deaths in the USA in 2017. Almost half of those involved the use of Opioids such as Heroin. This research supports efforts to combat the Opioid Epidemic by further understanding factors that lead to Heroin consumption. Previous research has debated the cause of Heroin addiction, with some explaining the phenomenon as a transition from prescription Opioids, and others pointing to various psycho-social factors. This research used self-reported information about personality, demographics and drug consumption behavior to predict Heroin consumption. By applying a Support Vector Machine algorithm optimized with a Genetic Algorithm (GA-SVM Hybrid) to simultaneously identify predictive features and model parameters, this research produced several models that were more accurate in predicting Heroin use than those produced in previous studies. Although all factors had predictive power, these results showed that consumption of other drugs (both prescription and illicit) were stronger predictors of Heroin use than psycho-social factors. The use of prescription drugs as a strong predictor of Heroin use is an important though disturbing discovery but that can help combat Heroin use.

</p>
</details>

<details><summary><b>Finite Impulse Response Filters for Simplicial Complexes</b>
<a href="https://arxiv.org/abs/2103.12587">arxiv:2103.12587</a>
&#x1F4C8; 1 <br>
<p>Maosheng Yang, Elvin Isufi, Michael T. Schaub, Geert Leus</p></summary>
<p>

**Abstract:** In this paper, we study linear filters to process signals defined on simplicial complexes, i.e., signals defined on nodes, edges, triangles, etc. of a simplicial complex, thereby generalizing filtering operations for graph signals. We propose a finite impulse response filter based on the Hodge Laplacian, and demonstrate how this filter can be designed to amplify or attenuate certain spectral components of simplicial signals. Specifically, we discuss how, unlike in the case of node signals, the Fourier transform in the context of edge signals can be understood in terms of two orthogonal subspaces corresponding to the gradient-flow signals and curl-flow signals arising from the Hodge decomposition. By assigning different filter coefficients to the associated terms of the Hodge Laplacian, we develop a subspace-varying filter which enables more nuanced control over these signal types. Numerical experiments are conducted to show the potential of simplicial filters for sub-component extraction, denoising and model approximation.

</p>
</details>

<details><summary><b>Differentiable Agent-Based Simulation for Gradient-Guided Simulation-Based Optimization</b>
<a href="https://arxiv.org/abs/2103.12476">arxiv:2103.12476</a>
&#x1F4C8; 1 <br>
<p>Philipp Andelfinger</p></summary>
<p>

**Abstract:** Simulation-based optimization using agent-based models is typically carried out under the assumption that the gradient describing the sensitivity of the simulation output to the input cannot be evaluated directly. To still apply gradient-based optimization methods, which efficiently steer the optimization towards a local optimum, gradient estimation methods can be employed. However, many simulation runs are needed to obtain accurate estimates if the input dimension is large. Automatic differentiation (AD) is a family of techniques to compute gradients of general programs directly. Here, we explore the use of AD in the context of time-driven agent-based simulations. By substituting common discrete model elements such as conditional branching with smooth approximations, we obtain gradient information across discontinuities in the model logic. On the example of microscopic traffic models and an epidemics model, we study the fidelity and overhead of the differentiable models, as well as the convergence speed and solution quality achieved by gradient-based optimization compared to gradient-free methods. In traffic signal timing optimization problems with high input dimension, the gradient-based methods exhibit substantially superior performance. Finally, we demonstrate that the approach enables gradient-based training of neural network-controlled simulation entities embedded in the model logic.

</p>
</details>

<details><summary><b>Roughness Index and Roughness Distance for Benchmarking Medical Segmentation</b>
<a href="https://arxiv.org/abs/2103.12350">arxiv:2103.12350</a>
&#x1F4C8; 1 <br>
<p>Vidhiwar Singh Rathour, Kashu Yamakazi, T. Hoang Ngan Le</p></summary>
<p>

**Abstract:** Medical image segmentation is one of the most challenging tasks in medical image analysis and has been widely developed for many clinical applications. Most of the existing metrics have been first designed for natural images and then extended to medical images. While object surface plays an important role in medical segmentation and quantitative analysis i.e. analyze brain tumor surface, measure gray matter volume, most of the existing metrics are limited when it comes to analyzing the object surface, especially to tell about surface smoothness or roughness of a given volumetric object or to analyze the topological errors. In this paper, we first analysis both pros and cons of all existing medical image segmentation metrics, specially on volumetric data. We then propose an appropriate roughness index and roughness distance for medical image segmentation analysis and evaluation. Our proposed method addresses two kinds of segmentation errors, i.e. (i)topological errors on boundary/surface and (ii)irregularities on the boundary/surface. The contribution of this work is four-fold: (i) detect irregular spikes/holes on a surface, (ii) propose roughness index to measure surface roughness of a given object, (iii) propose a roughness distance to measure the distance of two boundaries/surfaces by utilizing the proposed roughness index and (iv) suggest an algorithm which helps to remove the irregular spikes/holes to smooth the surface. Our proposed roughness index and roughness distance are built upon the solid surface roughness parameter which has been successfully developed in the civil engineering.

</p>
</details>

<details><summary><b>Improved Estimation of Concentration Under $\ell_p$-Norm Distance Metrics Using Half Spaces</b>
<a href="https://arxiv.org/abs/2103.12913">arxiv:2103.12913</a>
&#x1F4C8; 0 <br>
<p>Jack Prescott, Xiao Zhang, David Evans</p></summary>
<p>

**Abstract:** Concentration of measure has been argued to be the fundamental cause of adversarial vulnerability. Mahloujifar et al. presented an empirical way to measure the concentration of a data distribution using samples, and employed it to find lower bounds on intrinsic robustness for several benchmark datasets. However, it remains unclear whether these lower bounds are tight enough to provide a useful approximation for the intrinsic robustness of a dataset. To gain a deeper understanding of the concentration of measure phenomenon, we first extend the Gaussian Isoperimetric Inequality to non-spherical Gaussian measures and arbitrary $\ell_p$-norms ($p \geq 2$). We leverage these theoretical insights to design a method that uses half-spaces to estimate the concentration of any empirical dataset under $\ell_p$-norm distance metrics. Our proposed algorithm is more efficient than Mahloujifar et al.'s, and our experiments on synthetic datasets and image benchmarks demonstrate that it is able to find much tighter intrinsic robustness bounds. These tighter estimates provide further evidence that rules out intrinsic dataset concentration as a possible explanation for the adversarial vulnerability of state-of-the-art classifiers.

</p>
</details>

<details><summary><b>Fisher Task Distance and Its Applications in Transfer Learning and Neural Architecture Search</b>
<a href="https://arxiv.org/abs/2103.12827">arxiv:2103.12827</a>
&#x1F4C8; 0 <br>
<p>Cat P. Le, Mohammadreza Soltani, Juncheng Dong, Vahid Tarokh</p></summary>
<p>

**Abstract:** We formulate an asymmetric (or non-commutative) distance between tasks based on Fisher Information Matrices. We provide proof of consistency for our distance through theorems and experiments on various classification tasks. We then apply our proposed measure of task distance in transfer learning on visual tasks in the Taskonomy dataset. Additionally, we show how the proposed distance between a target task and a set of baseline tasks can be used to reduce the neural architecture search space for the target task. The complexity reduction in search space for task-specific architectures is achieved by building on the optimized architectures for similar tasks instead of doing a full search without using this side information. Experimental results demonstrate the efficacy of the proposed approach and its improvements over other methods.

</p>
</details>

<details><summary><b>Detecting Phishing Sites -- An Overview</b>
<a href="https://arxiv.org/abs/2103.12739">arxiv:2103.12739</a>
&#x1F4C8; 0 <br>
<p>P. Kalaharsha, B. M. Mehtre</p></summary>
<p>

**Abstract:** Phishing is one of the most severe cyber-attacks where researchers are interested to find a solution. In phishing, attackers lure end-users and steal their personal in-formation. To minimize the damage caused by phishing must be detected as early as possible. There are various phishing attacks like spear phishing, whaling, vishing, smishing, pharming and so on. There are various phishing detection techniques based on white-list, black-list, content-based, URL-based, visual-similarity and machine-learning. In this paper, we discuss various kinds of phishing attacks, attack vectors and detection techniques for detecting the phishing sites. Performance comparison of 18 different models along with nine different sources of datasets are given. Challenges in phishing detection techniques are also given.

</p>
</details>

<details><summary><b>Characterizing and Improving the Robustness of Self-Supervised Learning through Background Augmentations</b>
<a href="https://arxiv.org/abs/2103.12719">arxiv:2103.12719</a>
&#x1F4C8; 0 <br>
<p>Chaitanya K. Ryali, David J. Schwab, Ari S. Morcos</p></summary>
<p>

**Abstract:** Recent progress in self-supervised learning has demonstrated promising results in multiple visual tasks. An important ingredient in high-performing self-supervised methods is the use of data augmentation by training models to place different augmented views of the same image nearby in embedding space. However, commonly used augmentation pipelines treat images holistically, ignoring the semantic relevance of parts of an image-e.g. a subject vs. a background-which can lead to the learning of spurious correlations. Our work addresses this problem by investigating a class of simple, yet highly effective "background augmentations", which encourage models to focus on semantically-relevant content by discouraging them from focusing on image backgrounds. Through a systematic investigation, we show that background augmentations lead to substantial improvements in performance across a spectrum of state-of-the-art self-supervised methods (MoCo-v2, BYOL, SwAV) on a variety of tasks, e.g. $\sim$+1-2% gains on ImageNet, enabling performance on par with the supervised baseline. Further, we find the improvement in limited-labels settings is even larger (up to 4.2%). Background augmentations also improve robustness to a number of distribution shifts, including natural adversarial examples, ImageNet-9, adversarial attacks, ImageNet-Renditions. We also make progress in completely unsupervised saliency detection, in the process of generating saliency masks used for background augmentations.

</p>
</details>

<details><summary><b>A Pseudo-Metric between Probability Distributions based on Depth-Trimmed Regions</b>
<a href="https://arxiv.org/abs/2103.12711">arxiv:2103.12711</a>
&#x1F4C8; 0 <br>
<p>Guillaume Staerman, Pavlo Mozharovskyi, Pierre Colombo, Stéphan Clémençon, Florence d'Alché-Buc</p></summary>
<p>

**Abstract:** The design of a metric between probability distributions is a longstanding problem motivated by numerous applications in Machine Learning. Focusing on continuous probability distributions on the Euclidean space $\mathbb{R}^d$, we introduce a novel pseudo-metric between probability distributions by leveraging the extension of univariate quantiles to multivariate spaces. Data depth is a nonparametric statistical tool that measures the centrality of any element $x\in\mathbb{R}^d$ with respect to (w.r.t.) a probability distribution or a data set. It is a natural median-oriented extension of the cumulative distribution function (cdf) to the multivariate case. Thus, its upper-level sets -- the depth-trimmed regions -- give rise to a definition of multivariate quantiles. The new pseudo-metric relies on the average of the Hausdorff distance between the depth-based quantile regions w.r.t. each distribution. Its good behavior w.r.t. major transformation groups, as well as its ability to factor out translations, are depicted. Robustness, an appealing feature of this pseudo-metric, is studied through the finite sample breakdown point. Moreover, we propose an efficient approximation method with linear time complexity w.r.t. the size of the data set and its dimension. The quality of this approximation as well as the performance of the proposed approach are illustrated in numerical experiments.

</p>
</details>

<details><summary><b>BoXHED2.0: Scalable boosting of dynamic survival analysis</b>
<a href="https://arxiv.org/abs/2103.12591">arxiv:2103.12591</a>
&#x1F4C8; 0 <br>
<p>Arash Pakbin, Xiaochen Wang, Bobak J. Mortazavi, Donald K. K. Lee</p></summary>
<p>

**Abstract:** Modern applications of survival analysis increasingly involve time-dependent covariates. In healthcare settings, such covariates provide dynamic patient histories that can be used to assess health risks in realtime by tracking the hazard function. Hazard learning is thus particularly useful in healthcare analytics, and the open-source package BoXHED 1.0 provides the first implementation of a gradient boosted hazard estimator that is fully nonparametric. This paper introduces BoXHED 2.0, a quantum leap over BoXHED 1.0 in several ways. Crucially, BoXHED 2.0 can deal with survival data that goes far beyond right-censoring and it also supports recurring events. To our knowledge, this is the only nonparametric machine learning implementation that is able to do so. Another major improvement is that BoXHED 2.0 is orders of magnitude more scalable, due in part to a novel data preprocessing step that sidesteps the need for explicit quadrature when dealing with time-dependent covariates. BoXHED 2.0 supports the use of GPUs and multicore CPUs, and is available from GitHub: www.github.com/BoXHED.

</p>
</details>

<details><summary><b>Improved Analysis of the Tsallis-INF Algorithm in Stochastically Constrained Adversarial Bandits and Stochastic Bandits with Adversarial Corruptions</b>
<a href="https://arxiv.org/abs/2103.12487">arxiv:2103.12487</a>
&#x1F4C8; 0 <br>
<p>Saeed Masoudian, Yevgeny Seldin</p></summary>
<p>

**Abstract:** We derive improved regret bounds for the Tsallis-INF algorithm of Zimmert and Seldin (2021). We show that in adversarial regimes with a $(Δ,C,T)$ self-bounding constraint the algorithm achieves $\mathcal{O}\left(\left(\sum_{i\neq i^*} \frac{1}{Δ_i}\right)\log_+\left(\frac{(K-1)T}{\left(\sum_{i\neq i^*} \frac{1}{Δ_i}\right)^2}\right)+\sqrt{C\left(\sum_{i\neq i^*}\frac{1}{Δ_i}\right)\log_+\left(\frac{(K-1)T}{C\sum_{i\neq i^*}\frac{1}{Δ_i}}\right)}\right)$ regret bound, where $T$ is the time horizon, $K$ is the number of arms, $Δ_i$ are the suboptimality gaps, $i^*$ is the best arm, $C$ is the corruption magnitude, and $\log_+(x) = \max\left(1,\log x\right)$. The regime includes stochastic bandits, stochastically constrained adversarial bandits, and stochastic bandits with adversarial corruptions as special cases. Additionally, we provide a general analysis, which allows to achieve the same kind of improvement for generalizations of Tsallis-INF to other settings beyond multiarmed bandits.

</p>
</details>

<details><summary><b>Explainable Machine Learning-driven Strategy for Automated Trading Pattern Extraction</b>
<a href="https://arxiv.org/abs/2103.12419">arxiv:2103.12419</a>
&#x1F4C8; 0 <br>
<p>Artur Sokolovsky, Luca Arnaboldi, Jaume Bacardit, Thomas Gross</p></summary>
<p>

**Abstract:** Financial markets are a source of non-stationary multidimensional time series which has been drawing attention for decades. Each financial instrument has its specific changing over time properties, making their analysis a complex task. Improvement of understanding and development of methods for financial time series analysis is essential for successful operation on financial markets. In this study we propose a volume-based data pre-processing method for making financial time series more suitable for machine learning pipelines. We use a statistical approach for assessing the performance of the method. Namely, we formally state the hypotheses, set up associated classification tasks, compute effect sizes with confidence intervals, and run statistical tests to validate the hypotheses. We additionally assess the trading performance of the proposed method on historical data and compare it to a previously published approach. Our analysis shows that the proposed volume-based method allows successful classification of the financial time series patterns, and also leads to better classification performance than a price action-based method, excelling specifically on more liquid financial instruments. Finally, we propose an approach for obtaining feature interactions directly from tree-based models on example of CatBoost estimator, as well as formally assess the relatedness of the proposed approach and SHAP feature interactions with a positive outcome.

</p>
</details>

<details><summary><b>Multi-Robot Task Allocation -- Complexity and Approximation</b>
<a href="https://arxiv.org/abs/2103.12370">arxiv:2103.12370</a>
&#x1F4C8; 0 <br>
<p>Haris Aziz, Hau Chan, Ágnes Cseh, Bo Li, Fahimeh Ramezani, Chenhao Wang</p></summary>
<p>

**Abstract:** Multi-robot task allocation is one of the most fundamental classes of problems in robotics and is crucial for various real-world robotic applications such as search, rescue and area exploration. We consider the Single-Task robots and Multi-Robot tasks Instantaneous Assignment (ST-MR-IA) setting where each task requires at least a certain number of robots and each robot can work on at most one task and incurs an operational cost for each task. Our aim is to consider a natural computational problem of allocating robots to complete the maximum number of tasks subject to budget constraints. We consider budget constraints of three different kinds: (1) total budget, (2) task budget, and (3) robot budget. We provide a detailed complexity analysis including results on approximations as well as polynomial-time algorithms for the general setting and important restricted settings.

</p>
</details>


[Next Page](2021/2021-03/2021-03-22.md)
