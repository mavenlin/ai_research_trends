## Summary for 2020-12-13, created on 2021-01-10


<details><summary><b>Few Shot Adaptive Normalization Driven Multi-Speaker Speech Synthesis</b>
<a href="https://arxiv.org/abs/2012.07252">arxiv:2012.07252</a>
&#x1F4C8; -1 <br>
<p>Neeraj Kumar, Srishti Goel, Ankur Narang, Brejesh Lall</p></summary>
<p>

**Abstract:** The style of the speech varies from person to person and every person exhibits his or her own style of speaking that is determined by the language, geography, culture and other factors. Style is best captured by prosody of a signal. High quality multi-speaker speech synthesis while considering prosody and in a few shot manner is an area of active research with many real-world applications. While multiple efforts have been made in this direction, it remains an interesting and challenging problem. In this paper, we present a novel few shot multi-speaker speech synthesis approach (FSM-SS) that leverages adaptive normalization architecture with a non-autoregressive multi-head attention model. Given an input text and a reference speech sample of an unseen person, FSM-SS can generate speech in that person's style in a few shot manner. Additionally, we demonstrate how the affine parameters of normalization help in capturing the prosodic features such as energy and fundamental frequency in a disentangled fashion and can be used to generate morphed speech output. We demonstrate the efficacy of our proposed architecture on multi-speaker VCTK and LibriTTS datasets, using multiple quantitative metrics that measure generated speech distortion and MoS, along with speaker embedding analysis of the generated speech vs the actual speech samples.

</p>
</details>

<details><summary><b>Neighbors From Hell: Voltage Attacks Against Deep Learning Accelerators on Multi-Tenant FPGAs</b>
<a href="https://arxiv.org/abs/2012.07242">arxiv:2012.07242</a>
&#x1F4C8; -1 <br>
<p>Andrew Boutros, Mathew Hall, Nicolas Papernot, Vaughn Betz</p></summary>
<p>

**Abstract:** Field-programmable gate arrays (FPGAs) are becoming widely used accelerators for a myriad of datacenter applications due to their flexibility and energy efficiency. Among these applications, FPGAs have shown promising results in accelerating low-latency real-time deep learning (DL) inference, which is becoming an indispensable component of many end-user applications. With the emerging research direction towards virtualized cloud FPGAs that can be shared by multiple users, the security aspect of FPGA-based DL accelerators requires careful consideration. In this work, we evaluate the security of DL accelerators against voltage-based integrity attacks in a multitenant FPGA scenario. We first demonstrate the feasibility of such attacks on a state-of-the-art Stratix 10 card using different attacker circuits that are logically and physically isolated in a separate attacker role, and cannot be flagged as malicious circuits by conventional bitstream checkers. We show that aggressive clock gating, an effective power-saving technique, can also be a potential security threat in modern FPGAs. Then, we carry out the attack on a DL accelerator running ImageNet classification in the victim role to evaluate the inherent resilience of DL models against timing faults induced by the adversary. We find that even when using the strongest attacker circuit, the prediction accuracy of the DL accelerator is not compromised when running at its safe operating frequency. Furthermore, we can achieve 1.18-1.31x higher inference performance by over-clocking the DL accelerator without affecting its prediction accuracy.

</p>
</details>

<details><summary><b>Accurate Cell Segmentation in Digital Pathology Images via Attention Enforced Networks</b>
<a href="https://arxiv.org/abs/2012.07237">arxiv:2012.07237</a>
&#x1F4C8; -1 <br>
<p>Muyi Sun, Zeyi Yao, Guanhong Zhang</p></summary>
<p>

**Abstract:** Automatic cell segmentation is an essential step in the pipeline of computer-aided diagnosis (CAD), such as the detection and grading of breast cancer. Accurate segmentation of cells can not only assist the pathologists to make a more precise diagnosis, but also save much time and labor. However, this task suffers from stain variation, cell inhomogeneous intensities, background clutters and cells from different tissues. To address these issues, we propose an Attention Enforced Network (AENet), which is built on spatial attention module and channel attention module, to integrate local features with global dependencies and weight effective channels adaptively. Besides, we introduce a feature fusion branch to bridge high-level and low-level features. Finally, the marker controlled watershed algorithm is applied to post-process the predicted segmentation maps for reducing the fragmented regions. In the test stage, we present an individual color normalization method to deal with the stain variation problem. We evaluate this model on the MoNuSeg dataset. The quantitative comparisons against several prior methods demonstrate the superiority of our approach.

</p>
</details>

<details><summary><b>Multi-Domain Multi-Task Rehearsal for Lifelong Learning</b>
<a href="https://arxiv.org/abs/2012.07236">arxiv:2012.07236</a>
&#x1F4C8; -1 <br>
<p>Fan Lyu, Shuai Wang, Wei Feng, Zihan Ye, Fuyuan Hu, Song Wang</p></summary>
<p>

**Abstract:** Rehearsal, seeking to remind the model by storing old knowledge in lifelong learning, is one of the most effective ways to mitigate catastrophic forgetting, i.e., biased forgetting of previous knowledge when moving to new tasks. However, the old tasks of the most previous rehearsal-based methods suffer from the unpredictable domain shift when training the new task. This is because these methods always ignore two significant factors. First, the Data Imbalance between the new task and old tasks that makes the domain of old tasks prone to shift. Second, the Task Isolation among all tasks will make the domain shift toward unpredictable directions; To address the unpredictable domain shift, in this paper, we propose Multi-Domain Multi-Task (MDMT) rehearsal to train the old tasks and new task parallelly and equally to break the isolation among tasks. Specifically, a two-level angular margin loss is proposed to encourage the intra-class/task compactness and inter-class/task discrepancy, which keeps the model from domain chaos. In addition, to further address domain shift of the old tasks, we propose an optional episodic distillation loss on the memory to anchor the knowledge for each old task. Experiments on benchmark datasets validate the proposed approach can effectively mitigate the unpredictable domain shift.

</p>
</details>

<details><summary><b>Theoretical Analyses of Multi-Objective Evolutionary Algorithms on Multi-Modal Objectives</b>
<a href="https://arxiv.org/abs/2012.07231">arxiv:2012.07231</a>
&#x1F4C8; -1 <br>
<p>Benjamin Doerr, Weijie Zheng</p></summary>
<p>

**Abstract:** Previous theory work on multi-objective evolutionary algorithms considers mostly easy problems that are composed of unimodal objectives. This paper takes a first step towards a deeper understanding of how evolutionary algorithms solve multi-modal multi-objective problems. We propose the OneJumpZeroJump problem, a bi-objective problem whose single objectives are isomorphic to the classic jump functions benchmark. We prove that the simple evolutionary multi-objective optimizer (SEMO) cannot compute the full Pareto front. In contrast, for all problem sizes~$n$ and all jump sizes $k \in [4..\frac n2 - 1]$, the global SEMO (GSEMO) covers the Pareto front in $Θ((n-2k)n^{k})$ iterations in expectation. To improve the performance, we combine the GSEMO with two approaches, a heavy-tailed mutation operator and a stagnation detection strategy, that showed advantages in single-objective multi-modal problems. Runtime improvements of asymptotic order at least $k^{Ω(k)}$ are shown for both strategies. Our experiments verify the {substantial} runtime gains already for moderate problem sizes. Overall, these results show that the ideas recently developed for single-objective evolutionary algorithms can be effectively employed also in multi-objective optimization.

</p>
</details>

<details><summary><b>Breaking the Expressive Bottlenecks of Graph Neural Networks</b>
<a href="https://arxiv.org/abs/2012.07219">arxiv:2012.07219</a>
&#x1F4C8; -1 <br>
<p>Mingqi Yang, Yanming Shen, Heng Qi, Baocai Yin</p></summary>
<p>

**Abstract:** Recently, the Weisfeiler-Lehman (WL) graph isomorphism test was used to measure the expressiveness of graph neural networks (GNNs), showing that the neighborhood aggregation GNNs were at most as powerful as 1-WL test in distinguishing graph structures. There were also improvements proposed in analogy to $k$-WL test ($k>1$). However, the aggregators in these GNNs are far from injective as required by the WL test, and suffer from weak distinguishing strength, making it become expressive bottlenecks. In this paper, we improve the expressiveness by exploring powerful aggregators. We reformulate aggregation with the corresponding aggregation coefficient matrix, and then systematically analyze the requirements of the aggregation coefficient matrix for building more powerful aggregators and even injective aggregators. It can also be viewed as the strategy for preserving the rank of hidden features, and implies that basic aggregators correspond to a special case of low-rank transformations. We also show the necessity of applying nonlinear units ahead of aggregation, which is different from most aggregation-based GNNs. Based on our theoretical analysis, we develop two GNN layers, ExpandingConv and CombConv. Experimental results show that our models significantly boost performance, especially for large and densely connected graphs.

</p>
</details>

<details><summary><b>D-LEMA: Deep Learning Ensembles from Multiple Annotations -- Application to Skin Lesion Segmentation</b>
<a href="https://arxiv.org/abs/2012.07206">arxiv:2012.07206</a>
&#x1F4C8; -1 <br>
<p>Zahra Mirikharaji, Kumar Abhishek, Saeed Izadi, Ghassan Hamarneh</p></summary>
<p>

**Abstract:** Medical image segmentation annotations suffer from inter/intra-observer variations even among experts due to intrinsic differences in human annotators and ambiguous boundaries. Leveraging a collection of annotators' opinions for an image is an interesting way of estimating a gold standard. Although training deep models in a supervised setting with a single annotation per image has been extensively studied, generalizing their training to work with data sets containing multiple annotations per image remains a fairly unexplored problem. In this paper, we propose an approach to handle annotators' disagreements when training a deep model. To this end, we propose an ensemble of Bayesian fully convolutional networks (FCNs) for the segmentation task by considering two major factors in the aggregation of multiple ground truth annotations: (1) handling contradictory annotations in the training data originating from inter-annotator disagreements and (2) improving confidence calibration through the fusion of base models predictions. We demonstrate the superior performance of our approach on the ISIC Archive and explore the generalization performance of our proposed method by cross-data set evaluation on the PH2 and DermoFit data sets.

</p>
</details>

<details><summary><b>Hospital Capacity Planning Using Discrete Event Simulation Under Special Consideration of the COVID-19 Pandemic</b>
<a href="https://arxiv.org/abs/2012.07188">arxiv:2012.07188</a>
&#x1F4C8; -1 <br>
<p>Thomas Bartz-Beielstein, Frederik Rehbach, Olaf Mersmann, Eva Bartz</p></summary>
<p>

**Abstract:** We present a resource-planning tool for hospitals under special consideration of the COVID-19 pandemic, called babsim.hospital. It provides many advantages for crisis teams, e.g., comparison with their own local planning, simulation of local events, simulation of several scenarios (worst / best case). There are benefits for medical professionals, e.g, analysis of the pandemic at local, regional, state and federal level, the consideration of special risk groups, tools for validating the length of stays and transition probabilities. Finally, there are potential advantages for administration, management, e.g., assessment of the situation of individual hospitals taking local events into account, consideration of relevant resources such as beds, ventilators, rooms, protective clothing, and personnel planning, e.g., medical and nursing staff. babsim.hospital combines simulation, optimization, statistics, and artificial intelligence processes in a very efficient way. The core is a discrete, event-based simulation model.

</p>
</details>

<details><summary><b>Explanation from Specification</b>
<a href="https://arxiv.org/abs/2012.07179">arxiv:2012.07179</a>
&#x1F4C8; -1 <br>
<p>Harish Naik, György Turán</p></summary>
<p>

**Abstract:** Explainable components in XAI algorithms often come from a familiar set of models, such as linear models or decision trees. We formulate an approach where the type of explanation produced is guided by a specification. Specifications are elicited from the user, possibly using interaction with the user and contributions from other areas. Areas where a specification could be obtained include forensic, medical, and scientific applications. Providing a menu of possible types of specifications in an area is an exploratory knowledge representation and reasoning task for the algorithm designer, aiming at understanding the possibilities and limitations of efficiently computable modes of explanations. Two examples are discussed: explanations for Bayesian networks using the theory of argumentation, and explanations for graph neural networks. The latter case illustrates the possibility of having a representation formalism available to the user for specifying the type of explanation requested, for example, a chemical query language for classifying molecules. The approach is motivated by a theory of explanation in the philosophy of science, and it is related to current questions in the philosophy of science on the role of machine learning.

</p>
</details>

<details><summary><b>Self-supervised Text-independent Speaker Verification using Prototypical Momentum Contrastive Learning</b>
<a href="https://arxiv.org/abs/2012.07178">arxiv:2012.07178</a>
&#x1F4C8; -1 <br>
<p>Wei Xia, Chunlei Zhang, Chao Weng, Meng Yu, Dong Yu</p></summary>
<p>

**Abstract:** In this study, we investigate self-supervised representation learning for speaker verification (SV). First, we examine a simple contrastive learning approach (SimCLR) with a momentum contrastive (MoCo) learning framework, where the MoCo speaker embedding system utilizes a queue to maintain a large set of negative examples. We show that better speaker embeddings can be learned by momentum contrastive learning. Next, alternative augmentation strategies are explored to normalize extrinsic speaker variabilities of two random segments from the same speech utterance. Specifically, augmentation in the waveform largely improves the speaker representations for SV tasks. The proposed MoCo speaker embedding is further improved when a prototypical memory bank is introduced, which encourages the speaker embeddings to be closer to their assigned prototypes with an intermediate clustering step. In addition, we generalize the self-supervised framework to a semi-supervised scenario where only a small portion of the data is labeled. Comprehensive experiments on the Voxceleb dataset demonstrate that our proposed self-supervised approach achieves competitive performance compared with existing techniques, and can approach fully supervised results with partially labeled data.

</p>
</details>

<details><summary><b>Pseudo Shots: Few-Shot Learning with Auxiliary Data</b>
<a href="https://arxiv.org/abs/2012.07176">arxiv:2012.07176</a>
&#x1F4C8; -1 <br>
<p>Reza Esfandiarpoor, Mohsen Hajabdollahi, Stephen H. Bach</p></summary>
<p>

**Abstract:** In many practical few-shot learning problems, even though labeled examples are scarce, there are abundant auxiliary data sets that potentially contain useful information. We propose a framework to address the challenges of efficiently selecting and effectively using auxiliary data in image classification. Given an auxiliary dataset and a notion of semantic similarity among classes, we automatically select pseudo shots, which are labeled examples from other classes related to the target task. We show that naively assuming that these additional examples come from the same distribution as the target task examples does not significantly improve accuracy. Instead, we propose a masking module that adjusts the features of auxiliary data to be more similar to those of the target classes. We show that this masking module can improve accuracy by up to 18 accuracy points, particularly when the auxiliary data is semantically distant from the target task. We also show that incorporating pseudo shots improves over the current state-of-the-art few-shot image classification scores by an average of 4.81 percentage points of accuracy on 1-shot tasks and an average of 0.31 percentage points on 5-shot tasks.

</p>
</details>

<details><summary><b>MSAF: Multimodal Split Attention Fusion</b>
<a href="https://arxiv.org/abs/2012.07175">arxiv:2012.07175</a>
&#x1F4C8; -1 <br>
<p>Lang Su, Chuqing Hu, Guofa Li, Dongpu Cao</p></summary>
<p>

**Abstract:** Multimodal learning mimics the reasoning process of the human multi-sensory system, which is used to perceive the surrounding world. While making a prediction, the human brain tends to relate crucial cues from multiple sources of information. In this work, we propose a novel multimodal fusion module that learns to emphasize more contributive features across all modalities. Specifically, the proposed Multimodal Split Attention Fusion (MSAF) module splits each modality into channel-wise equal feature blocks and creates a joint representation that is used to generate soft attention for each channel across the feature blocks. Further, the MSAF module is designed to be compatible with features of various spatial dimensions and sequence lengths, suitable for both CNNs and RNNs. Thus, MSAF can be easily added to fuse features of any unimodal networks and utilize existing pretrained unimodal model weights. To demonstrate the effectiveness of our fusion module, we design three multimodal networks with MSAF for emotion recognition, sentiment analysis, and action recognition tasks. Our approach achieves competitive results in each task and outperforms other application-specific networks and multimodal fusion benchmarks.

</p>
</details>

<details><summary><b>A Memory-Augmented Neural Network Model of Abstract Rule Learning</b>
<a href="https://arxiv.org/abs/2012.07172">arxiv:2012.07172</a>
&#x1F4C8; -1 <br>
<p>Ishan Sinha, Taylor W. Webb, Jonathan D. Cohen</p></summary>
<p>

**Abstract:** Human intelligence is characterized by a remarkable ability to infer abstract rules from experience and apply these rules to novel domains. As such, designing neural network algorithms with this capacity is an important step toward the development of deep learning systems with more human-like intelligence. However, doing so is a major outstanding challenge, one that some argue will require neural networks to use explicit symbol-processing mechanisms. In this work, we focus on neural networks' capacity for arbitrary role-filler binding, the ability to associate abstract "roles" to context-specific "fillers," which many have argued is an important mechanism underlying the ability to learn and apply rules abstractly. Using a simplified version of Raven's Progressive Matrices, a hallmark test of human intelligence, we introduce a sequential formulation of a visual problem-solving task that requires this form of binding. Further, we introduce the Emergent Symbol Binding Network (ESBN), a recurrent neural network model that learns to use an external memory as a binding mechanism. This mechanism enables symbol-like variable representations to emerge through the ESBN's training process without the need for explicit symbol-processing machinery. We empirically demonstrate that the ESBN successfully learns the underlying abstract rule structure of our task and perfectly generalizes this rule structure to novel fillers.

</p>
</details>

<details><summary><b>Building Cross-Sectional Systematic Strategies By Learning to Rank</b>
<a href="https://arxiv.org/abs/2012.07149">arxiv:2012.07149</a>
&#x1F4C8; -1 <br>
<p>Daniel Poh, Bryan Lim, Stefan Zohren, Stephen Roberts</p></summary>
<p>

**Abstract:** The success of a cross-sectional systematic strategy depends critically on accurately ranking assets prior to portfolio construction. Contemporary techniques perform this ranking step either with simple heuristics or by sorting outputs from standard regression or classification models, which have been demonstrated to be sub-optimal for ranking in other domains (e.g. information retrieval). To address this deficiency, we propose a framework to enhance cross-sectional portfolios by incorporating learning-to-rank algorithms, which lead to improvements of ranking accuracy by learning pairwise and listwise structures across instruments. Using cross-sectional momentum as a demonstrative case study, we show that the use of modern machine learning ranking algorithms can substantially improve the trading performance of cross-sectional strategies -- providing approximately threefold boosting of Sharpe Ratios compared to traditional approaches.

</p>
</details>

<details><summary><b>FSOCO: The Formula Student Objects in Context Dataset</b>
<a href="https://arxiv.org/abs/2012.07139">arxiv:2012.07139</a>
&#x1F4C8; -1 <br>
<p>David Dodel, Michael Schötz, Niclas Vödisch</p></summary>
<p>

**Abstract:** This paper presents the FSOCO dataset, a collaborative dataset for vision-based cone detection systems in Formula Student Driverless competitions. It contains human annotated ground truth labels for both bounding boxes and instance-wise segmentation masks. The data buy-in philosophy of FSOCO asks student teams to contribute to the database first before being granted access ensuring continuous growth. By providing clear labeling guidelines and tools for a sophisticated raw image selection, new annotations are guaranteed to meet the desired quality. The effectiveness of the approach is shown by comparing prediction results of a network trained on FSOCO and its unregulated predecessor. The FSOCO dataset can be found at fsoco-dataset.com.

</p>
</details>

<details><summary><b>Accelerating high-throughput virtual screening through molecular pool-based active learning</b>
<a href="https://arxiv.org/abs/2012.07127">arxiv:2012.07127</a>
&#x1F4C8; -1 <br>
<p>David E. Graff, Eugene I. Shakhnovich, Connor W. Coley</p></summary>
<p>

**Abstract:** Structure-based virtual screening is an important tool in early stage drug discovery that scores the interactions between a target protein and candidate ligands. As virtual libraries continue to grow (in excess of $10^8$ molecules), so too do the resources necessary to conduct exhaustive virtual screening campaigns on these libraries. However, Bayesian optimization techniques can aid in their exploration: a surrogate structure-property relationship model trained on the predicted affinities of a subset of the library can be applied to the remaining library members, allowing the least promising compounds to be excluded from evaluation. In this study, we assess various surrogate model architectures, acquisition functions, and acquisition batch sizes as applied to several protein-ligand docking datasets and observe significant reductions in computational costs, even when using a greedy acquisition strategy; for example, 87.9% of the top-50000 ligands can be found after testing only 2.4% of a 100M member library. Such model-guided searches mitigate the increasing computational costs of screening increasingly large virtual libraries and can accelerate high-throughput virtual screening campaigns with applications beyond docking.

</p>
</details>

<details><summary><b>Deliberative and Conceptual Inference in Service Robots</b>
<a href="https://arxiv.org/abs/2012.07121">arxiv:2012.07121</a>
&#x1F4C8; -1 <br>
<p>Luis A. Pineda, Noé Hernández, Arturo Rodríguez, Ricardo Cruz, Gibrán Fuentes</p></summary>
<p>

**Abstract:** Service robots need to reason to support people in daily life situations. Reasoning is an expensive resource that should be used on demand whenever the expectations of the robot do not match the situation of the world and the execution of the task is broken down; in such scenarios the robot must perform the common sense daily life inference cycle consisting on diagnosing what happened, deciding what to do about it, and inducing and executing a plan, recurring in such behavior until the service task can be resumed. Here we examine two strategies to implement this cycle: (1) a pipe-line strategy involving abduction, decision-making and planning, which we call deliberative inference and (2) the use of the knowledge and preferences stored in the robot's knowledge-base, which we call conceptual inference. The former involves an explicit definition of a problem space that is explored through heuristic search, and the latter is based on conceptual knowledge including the human user preferences, and its representation requires a non-monotonic knowledge-based system. We compare the strengths and limitations of both approaches. We also describe a service robot conceptual model and architecture capable of supporting the daily life inference cycle during the execution of a robotics service task. The model is centered in the declarative specification and interpretation of robot's communication and task structure. We also show the implementation of this framework in the fully autonomous robot Golem-III. The framework is illustrated with two demonstration scenarios.

</p>
</details>

<details><summary><b>Demystifying Deep Neural Networks Through Interpretation: A Survey</b>
<a href="https://arxiv.org/abs/2012.07119">arxiv:2012.07119</a>
&#x1F4C8; -1 <br>
<p>Giang Dao, Minwoo Lee</p></summary>
<p>

**Abstract:** Modern deep learning algorithms tend to optimize an objective metric, such as minimize a cross entropy loss on a training dataset, to be able to learn. The problem is that the single metric is an incomplete description of the real world tasks. The single metric cannot explain why the algorithm learn. When an erroneous happens, the lack of interpretability causes a hardness of understanding and fixing the error. Recently, there are works done to tackle the problem of interpretability to provide insights into neural networks behavior and thought process. The works are important to identify potential bias and to ensure algorithm fairness as well as expected performance.

</p>
</details>

<details><summary><b>Forecasting Daily Primary Three-Hour Net Load Ramps in the CAISO System</b>
<a href="https://arxiv.org/abs/2012.07117">arxiv:2012.07117</a>
&#x1F4C8; -1 <br>
<p>Ogun Yurdakul, Andreas Meyer, Fikret Sivrikaya, Sahin Albayrak</p></summary>
<p>

**Abstract:** The deepening penetration of variable energy resources creates unprecedented challenges for system operators (SOs). An issue that merits special attention is the precipitous net load ramps, which require SOs to have flexible capacity at their disposal so as to maintain the supply-demand balance at all times. In the judicious procurement and deployment of flexible capacity, a tool that forecasts net load ramps may be of great assistance to SOs. To this end, we propose a methodology to forecast the magnitude and start time of daily primary three-hour net load ramps. We perform an extensive analysis so as to identify the factors that influence net load and draw on the identified factors to develop a forecasting methodology that harnesses the long short-term memory model. We demonstrate the effectiveness of the proposed methodology on the CAISO system using comparative assessments with selected benchmarks based on various evaluation metrics.

</p>
</details>

<details><summary><b>Budgeted and Non-budgeted Causal Bandits</b>
<a href="https://arxiv.org/abs/2012.07058">arxiv:2012.07058</a>
&#x1F4C8; -1 <br>
<p>Vineet Nair, Vishakha Patil, Gaurav Sinha</p></summary>
<p>

**Abstract:** Learning good interventions in a causal graph can be modelled as a stochastic multi-armed bandit problem with side-information. First, we study this problem when interventions are more expensive than observations and a budget is specified. If there are no backdoor paths from an intervenable node to the reward node then we propose an algorithm to minimize simple regret that optimally trades-off observations and interventions based on the cost of intervention. We also propose an algorithm that accounts for the cost of interventions, utilizes causal side-information, and minimizes the expected cumulative regret without exceeding the budget. Our cumulative-regret minimization algorithm performs better than standard algorithms that do not take side-information into account. Finally, we study the problem of learning best interventions without budget constraint in general graphs and give an algorithm that achieves constant expected cumulative regret in terms of the instance parameters when the parent distribution of the reward variable for each intervention is known. Our results are experimentally validated and compared to the best-known bounds in the current literature.

</p>
</details>

<details><summary><b>Improving the Classification of Rare Chords with Unlabeled Data</b>
<a href="https://arxiv.org/abs/2012.07055">arxiv:2012.07055</a>
&#x1F4C8; -1 <br>
<p>Marcelo Bortolozzo, Rodrigo Schramm, Claudio R. Jung</p></summary>
<p>

**Abstract:** In this work, we explore techniques to improve performance for rare classes in the task of Automatic Chord Recognition (ACR). We first explored the use of the focal loss in the context of ACR, which was originally proposed to improve the classification of hard samples. In parallel, we adapted a self-learning technique originally designed for image recognition to the musical domain. Our experiments show that both approaches individually (and their combination) improve the recognition of rare chords, but using only self-learning with noise addition yields the best results.

</p>
</details>

<details><summary><b>Adaptive and Oblivious Randomized Subspace Methods for High-Dimensional Optimization: Sharp Analysis and Lower Bounds</b>
<a href="https://arxiv.org/abs/2012.07054">arxiv:2012.07054</a>
&#x1F4C8; -1 <br>
<p>Jonathan Lacotte, Mert Pilanci</p></summary>
<p>

**Abstract:** We propose novel randomized optimization methods for high-dimensional convex problems based on restrictions of variables to random subspaces. We consider oblivious and data-adaptive subspaces and study their approximation properties via convex duality and Fenchel conjugates. A suitable adaptive subspace can be generated by sampling a correlated random matrix whose second order statistics mirror the input data. We illustrate that the adaptive strategy can significantly outperform the standard oblivious sampling method, which is widely used in the recent literature. We show that the relative error of the randomized approximations can be tightly characterized in terms of the spectrum of the data matrix and Gaussian width of the dual tangent cone at optimum. We develop lower bounds for both optimization and statistical error measures based on concentration of measure and Fano's inequality. We then present the consequences of our theory with data matrices of varying spectral decay profiles. Experimental results show that the proposed approach enables significant speed ups in a wide variety of machine learning and optimization problems including logistic regression, kernel classification with random convolution layers and shallow neural networks with rectified linear units.

</p>
</details>

<details><summary><b>Adaptive Algorithms for Multi-armed Bandit with Composite and Anonymous Feedback</b>
<a href="https://arxiv.org/abs/2012.07048">arxiv:2012.07048</a>
&#x1F4C8; -1 <br>
<p>Siwei Wang, Haoyun Wang, Longbo Huang</p></summary>
<p>

**Abstract:** We study the multi-armed bandit (MAB) problem with composite and anonymous feedback. In this model, the reward of pulling an arm spreads over a period of time (we call this period as reward interval) and the player receives partial rewards of the action, convoluted with rewards from pulling other arms, successively. Existing results on this model require prior knowledge about the reward interval size as an input to their algorithms. In this paper, we propose adaptive algorithms for both the stochastic and the adversarial cases, without requiring any prior information about the reward interval. For the stochastic case, we prove that our algorithm guarantees a regret that matches the lower bounds (in order). For the adversarial case, we propose the first algorithm to jointly handle non-oblivious adversary and unknown reward interval size. We also conduct simulations based on real-world dataset. The results show that our algorithms outperform existing benchmarks.

</p>
</details>

<details><summary><b>Monitoring multimode processes: a modified PCA algorithm with continual learning ability</b>
<a href="https://arxiv.org/abs/2012.07044">arxiv:2012.07044</a>
&#x1F4C8; -1 <br>
<p>Jingxin Zhang, Donghua Zhou, Maoyin Chen</p></summary>
<p>

**Abstract:** For multimode processes, one has to establish local monitoring models corresponding to local modes. However, the significant features of previous modes may be catastrophically forgotten when a monitoring model for the current mode is built. It would result in an abrupt performance decrease. Is it possible to make local monitoring model remember the features of previous modes? Choosing the principal component analysis (PCA) as a basic monitoring model, we try to resolve this problem. A modified PCA algorithm is built with continual learning ability for monitoring multimode processes, which adopts elastic weight consolidation (EWC) to overcome catastrophic forgetting of PCA for successive modes. It is called PCA-EWC, where the significant features of previous modes are preserved when a PCA model is established for the current mode. The computational complexity and key parameters are discussed to further understand the relationship between PCA and the proposed algorithm. Numerical case study and a practical industrial system in China are employed to illustrate the effectiveness of the proposed algorithm.

</p>
</details>

<details><summary><b>Uncertainty Estimation in Deep Neural Networks for Point Cloud Segmentation in Factory Planning</b>
<a href="https://arxiv.org/abs/2012.07038">arxiv:2012.07038</a>
&#x1F4C8; -1 <br>
<p>Christina Petschnigg, Juergen Pilz</p></summary>
<p>

**Abstract:** The digital factory provides undoubtedly a great potential for future production systems in terms of efficiency and effectivity. A key aspect on the way to realize the digital copy of a real factory is the understanding of complex indoor environments on the basis of 3D data. In order to generate an accurate factory model including the major components, i.e. building parts, product assets and process details, the 3D data collected during digitalization can be processed with advanced methods of deep learning. In this work, we propose a fully Bayesian and an approximate Bayesian neural network for point cloud segmentation. This allows us to analyze how different ways of estimating uncertainty in these networks improve segmentation results on raw 3D point clouds. We achieve superior model performance for both, the Bayesian and the approximate Bayesian model compared to the frequentist one. This performance difference becomes even more striking when incorporating the networks' uncertainty in their predictions. For evaluation we use the scientific data set S3DIS as well as a data set, which was collected by the authors at a German automotive production plant. The methods proposed in this work lead to more accurate segmentation results and the incorporation of uncertainty information makes this approach especially applicable to safety critical applications.

</p>
</details>

<details><summary><b>Neural network approaches to point lattice decoding</b>
<a href="https://arxiv.org/abs/2012.07032">arxiv:2012.07032</a>
&#x1F4C8; -1 <br>
<p>Vincent Corlay, Joseph J. Boutros, Philippe Ciblat, Loïc Brunel</p></summary>
<p>

**Abstract:** We characterize the complexity of the lattice decoding problem from a neural network perspective. The notion of Voronoi-reduced basis is introduced to restrict the space of solutions to a binary set. On the one hand, this problem is shown to be equivalent to computing a continuous piecewise linear (CPWL) function restricted to the fundamental parallelotope. On the other hand, it is known that any function computed by a ReLU feed-forward neural network is CPWL. As a result, we count the number of affine pieces in the CPWL decoding function to characterize the complexity of the decoding problem. It is exponential in the space dimension $n$, which induces shallow neural networks of exponential size. For structured lattices we show that folding, a technique equivalent to using a deep neural network, enables to reduce this complexity from exponential in $n$ to polynomial in $n$. Regarding unstructured MIMO lattices, in contrary to dense lattices many pieces in the CPWL decoding function can be neglected for quasi-optimal decoding on the Gaussian channel. This makes the decoding problem easier and it explains why shallow neural networks of reasonable size are more efficient with this category of lattices (in low to moderate dimensions).

</p>
</details>

<details><summary><b>InferCode: Self-Supervised Learning of Code Representations by Predicting Subtrees</b>
<a href="https://arxiv.org/abs/2012.07023">arxiv:2012.07023</a>
&#x1F4C8; -1 <br>
<p>Nghi D. Q. Bui, Yijun Yu, Lingxiao Jiang</p></summary>
<p>

**Abstract:** Building deep learning models on source code has found many successful software engineering applications, such as code search, code comment generation, bug detection, code migration, and so on. Current learning techniques, however, have a major drawback that these models are mostly trained on datasets labeled for particular downstream tasks, and code representations may not be suitable for other tasks. While some techniques produce representations from unlabeled code, they are far from satisfactory when applied to downstream tasks. Although certain techniques generate representations from unlabeled code when applied to downstream tasks they are far from satisfactory. This paper proposes InferCode to overcome the limitation by adapting the self-supervised learning mechanism to build source code model. The key novelty lies in training code representations by predicting automatically identified subtrees from the context of the ASTs. Subtrees in ASTs are treated with InferCode as the labels for training code representations without any human labeling effort or the overhead of expensive graph construction, and the trained representations are no longer tied to any specific downstream tasks or code units. We trained an InferCode model instance using the Tree-based CNN as the encoder of a large set of Java code and applied it to downstream unsupervised tasks such as code clustering, code clone detection, cross-language code search or reused under a transfer learning scheme to continue training the model weights for supervised tasks such as code classification and method name prediction. Compared to previous code learning techniques applied to the same downstream tasks, such as Code2Vec, Code2Seq, ASTNN, higher performance results are achieved using our pre-trained InferCode model with a significant margin for most tasks including those involving different programming languages.

</p>
</details>

<details><summary><b>Process monitoring based on orthogonal locality preserving projection with maximum likelihood estimation</b>
<a href="https://arxiv.org/abs/2012.07021">arxiv:2012.07021</a>
&#x1F4C8; -1 <br>
<p>Jingxin Zhang, Maoyin Chen, Hao Chen, Xia Hong, Donghua Zhou</p></summary>
<p>

**Abstract:** By integrating two powerful methods of density reduction and intrinsic dimensionality estimation, a new data-driven method, referred to as OLPP-MLE (orthogonal locality preserving projection-maximum likelihood estimation), is introduced for process monitoring. OLPP is utilized for dimensionality reduction, which provides better locality preserving power than locality preserving projection. Then, the MLE is adopted to estimate intrinsic dimensionality of OLPP. Within the proposed OLPP-MLE, two new static measures for fault detection $T_{\scriptscriptstyle {OLPP}}^2$ and ${\rm SPE}_{\scriptscriptstyle {OLPP}}$ are defined. In order to reduce algorithm complexity and ignore data distribution, kernel density estimation is employed to compute thresholds for fault diagnosis. The effectiveness of the proposed method is demonstrated by three case studies.

</p>
</details>

<details><summary><b>Context-Enhanced Entity and Relation Embedding for Knowledge Graph Completion</b>
<a href="https://arxiv.org/abs/2012.07011">arxiv:2012.07011</a>
&#x1F4C8; -1 <br>
<p>Ziyue Qiao, Zhiyuan Ning, Yi Du, Yuanchun Zhou</p></summary>
<p>

**Abstract:** Most researches for knowledge graph completion learn representations of entities and relations to predict missing links in incomplete knowledge graphs. However, these methods fail to take full advantage of both the contextual information of entity and relation. Here, we extract contexts of entities and relations from the triplets which they compose. We propose a model named AggrE, which conducts efficient aggregations respectively on entity context and relation context in multi-hops, and learns context-enhanced entity and relation embeddings for knowledge graph completion. The experiment results show that AggrE is competitive to existing models.

</p>
</details>

<details><summary><b>DeepSweep: An Evaluation Framework for Mitigating DNN Backdoor Attacks using Data Augmentation</b>
<a href="https://arxiv.org/abs/2012.07006">arxiv:2012.07006</a>
&#x1F4C8; -1 <br>
<p>Yi Zeng, Han Qiu, Shangwei Guo, Tianwei Zhang, Meikang Qiu, Bhavani Thuraisingham</p></summary>
<p>

**Abstract:** Public resources and services (e.g., datasets, training platforms, pre-trained models) have been widely adopted to ease the development of Deep Learning-based applications. However, if the third-party providers are untrusted, they can inject poisoned samples into the datasets or embed backdoors in those models. Such an integrity breach can cause severe consequences, especially in safety- and security-critical applications. Various backdoor attack techniques have been proposed for higher effectiveness and stealthiness. Unfortunately, existing defense solutions are not practical to thwart those attacks in a comprehensive way.
  In this paper, we investigate the effectiveness of data augmentation techniques in mitigating backdoor attacks and enhancing DL models' robustness. An evaluation framework is introduced to achieve this goal. Specifically, we consider a unified defense solution, which (1) adopts a data augmentation policy to fine-tune the infected model and eliminate the effects of the embedded backdoor; (2) uses another augmentation policy to preprocess input samples and invalidate the triggers during inference. We propose a systematic approach to discover the optimal policies for defending against different backdoor attacks by comprehensively evaluating 71 state-of-the-art data augmentation functions. Extensive experiments show that our identified policy can effectively mitigate eight different kinds of backdoor attacks and outperform five existing defense methods. We envision this framework can be a good benchmark tool to advance future DNN backdoor studies.

</p>
</details>

<details><summary><b>C2C-GenDA: Cluster-to-Cluster Generation for Data Augmentation of Slot Filling</b>
<a href="https://arxiv.org/abs/2012.07004">arxiv:2012.07004</a>
&#x1F4C8; -1 <br>
<p>Yutai Hou, Sanyuan Chen, Wanxiang Che, Cheng Chen, Ting Liu</p></summary>
<p>

**Abstract:** Slot filling, a fundamental module of spoken language understanding, often suffers from insufficient quantity and diversity of training data. To remedy this, we propose a novel Cluster-to-Cluster generation framework for Data Augmentation (DA), named C2C-GenDA. It enlarges the training set by reconstructing existing utterances into alternative expressions while keeping semantic. Different from previous DA works that reconstruct utterances one by one independently, C2C-GenDA jointly encodes multiple existing utterances of the same semantics and simultaneously decodes multiple unseen expressions. Jointly generating multiple new utterances allows to consider the relations between generated instances and encourages diversity. Besides, encoding multiple existing utterances endows C2C with a wider view of existing expressions, helping to reduce generation that duplicates existing data. Experiments on ATIS and Snips datasets show that instances augmented by C2C-GenDA improve slot filling by 7.99 (11.9%) and 5.76 (13.6%) F-scores respectively, when there are only hundreds of training utterances.

</p>
</details>

<details><summary><b>Contrastive Learning for Label-Efficient Semantic Segmentation</b>
<a href="https://arxiv.org/abs/2012.06985">arxiv:2012.06985</a>
&#x1F4C8; -1 <br>
<p>Xiangyun Zhao, Raviteja Vemulapalli, Philip Mansfield, Boqing Gong, Bradley Green, Lior Shapira, Ying Wu</p></summary>
<p>

**Abstract:** Collecting labeled data for the task of semantic segmentation is expensive and time-consuming, as it requires dense pixel-level annotations. While recent Convolutional Neural Network (CNN) based semantic segmentation approaches have achieved impressive results by using large amounts of labeled training data, their performance drops significantly as the amount of labeled data decreases. This happens because deep CNNs trained with the de facto cross-entropy loss can easily overfit to small amounts of labeled data. To address this issue, we propose a simple and effective contrastive learning-based training strategy in which we first pretrain the network using a pixel-wise class label-based contrastive loss, and then fine-tune it using the cross-entropy loss. This approach increases intra-class compactness and inter-class separability thereby resulting in a better pixel classifier. We demonstrate the effectiveness of the proposed training strategy in both fully-supervised and semi-supervised settings using the Cityscapes and PASCAL VOC 2012 segmentation datasets. Our results show that pretraining with label-based contrastive loss results in large performance gains (more than 20% absolute improvement in some settings) when the amount of labeled data is limited.

</p>
</details>

<details><summary><b>Using Restricted Boltzmann Machines to Model Molecular Geometries</b>
<a href="https://arxiv.org/abs/2012.06984">arxiv:2012.06984</a>
&#x1F4C8; -1 <br>
<p>Peter Nekrasov, Jessica Freeze, Victor Batista</p></summary>
<p>

**Abstract:** Precise physical descriptions of molecules can be obtained by solving the Schrodinger equation; however, these calculations are intractable and even approximations can be cumbersome. Force fields, which estimate interatomic potentials based on empirical data, are also time-consuming. This paper proposes a new methodology for modeling a set of physical parameters by taking advantage of the restricted Boltzmann machine's fast learning capacity and representational power. By training the machine on ab initio data, we can predict new data in the distribution of molecular configurations matching the ab initio distribution. In this paper we introduce a new RBM based on the Tanh activation function, and conduct a comparison of RBMs with different activation functions, including sigmoid, Gaussian, and (Leaky) ReLU. Finally we demonstrate the ability of Gaussian RBMs to model small molecules such as water and ethane.

</p>
</details>

<details><summary><b>Radial Deformation Emplacement in Power Transformers Using Long Short-Term Memory Networks</b>
<a href="https://arxiv.org/abs/2012.06982">arxiv:2012.06982</a>
&#x1F4C8; -1 <br>
<p>Arash Moradzadeh, Kazem Pourhossein, Behnam Mohammadi-Ivatloo, Tohid Khalili, Ali Bidram</p></summary>
<p>

**Abstract:** A power transformer winding is usually subject to mechanical stress and tension because of improper transportation or operation. Radial deformation (RD) is an example of mechanical stress that can impact power transformer operation through short circuit faults and insulation damages. Frequency response analysis (FRA) is a well-known method to diagnose mechanical defects in transformers. Despite the precision of FRA, the interpretation of the calculated frequency response curves is not straightforward and requires complex calculations. In this paper, a deep learning algorithm called long short-term memory (LSTM) is used as a feature extraction technique to locate RD faults in their early stages. The experimental results verify the effectiveness of the proposed method in the diagnosis and locating of RD defects.

</p>
</details>

<details><summary><b>Active Feature Selection for the Mutual Information Criterion</b>
<a href="https://arxiv.org/abs/2012.06979">arxiv:2012.06979</a>
&#x1F4C8; -1 <br>
<p>Shachar Schnapp, Sivan Sabato</p></summary>
<p>

**Abstract:** We study active feature selection, a novel feature selection setting in which unlabeled data is available, but the budget for labels is limited, and the examples to label can be actively selected by the algorithm. We focus on feature selection using the classical mutual information criterion, which selects the $k$ features with the largest mutual information with the label. In the active feature selection setting, the goal is to use significantly fewer labels than the data set size and still find $k$ features whose mutual information with the label based on the \emph{entire} data set is large. We explain and experimentally study the choices that we make in the algorithm, and show that they lead to a successful algorithm, compared to other more naive approaches. Our design draws on insights which relate the problem of active feature selection to the study of pure-exploration multi-armed bandits settings. While we focus here on mutual information, our general methodology can be adapted to other feature-quality measures as well. The code is available at the following url: https://github.com/ShacharSchnapp/ActiveFeatureSelection.

</p>
</details>

<details><summary><b>MVFNet: Multi-View Fusion Network for Efficient Video Recognition</b>
<a href="https://arxiv.org/abs/2012.06977">arxiv:2012.06977</a>
&#x1F4C8; -1 <br>
<p>Wenhao Wu, Dongliang He, Tianwei Lin, Fu Li, Chuang Gan, Errui Ding</p></summary>
<p>

**Abstract:** Conventionally, spatiotemporal modeling network and its complexity are the two most concentrated research topics in video action recognition. Existing state-of-the-art methods have achieved excellent accuracy regardless of the complexity meanwhile efficient spatiotemporal modeling solutions are slightly inferior in performance. In this paper, we attempt to acquire both efficiency and effectiveness simultaneously. First of all, besides traditionally treating H x W x T video frames as space-time signal (viewing from the Height-Width spatial plane), we propose to also model video from the other two Height-Time and Width-Time planes, to capture the dynamics of video thoroughly. Secondly, our model is designed based on 2D CNN backbones and model complexity is well kept in mind by design. Specifically, we introduce a novel multi-view fusion (MVF) module to exploit video dynamics using separable convolution for efficiency. It is a plug-and-play module and can be inserted into off-the-shelf 2D CNNs to form a simple yet effective model called MVFNet. Moreover, MVFNet can be thought of as a generalized video modeling framework and it can specialize to be existing methods such as C2D, SlowOnly, and TSM under different settings. Extensive experiments are conducted on popular benchmarks (i.e., Something-Something V1 & V2, Kinetics, UCF-101, and HMDB-51) to show its superiority. The proposed MVFNet can achieve state-of-the-art performance with 2D CNN's complexity.

</p>
</details>

<details><summary><b>fMRI-Kernel Regression: A Kernel-based Method for Pointwise Statistical Analysis of rs-fMRI for Population Studies</b>
<a href="https://arxiv.org/abs/2012.06972">arxiv:2012.06972</a>
&#x1F4C8; -1 <br>
<p>Anand A. Joshi, Soyoung Choi, Haleh Akrami, Richard M. Leahy</p></summary>
<p>

**Abstract:** Due to the spontaneous nature of resting-state fMRI (rs-fMRI) signals, cross-subject comparison and therefore, group studies of rs-fMRI are challenging. Most existing group comparison methods use features extracted from the fMRI time series, such as connectivity features, independent component analysis (ICA), and functional connectivity density (FCD) methods. However, in group studies, especially in the case of spectrum disorders, distances to a single atlas or a representative subject do not fully reflect the differences between subjects that may lie on a multi-dimensional spectrum. Moreover, there may not exist an individual subject or even an average atlas in such cases that is representative of all subjects. Here we describe an approach that measures pairwise distances between the synchronized rs-fMRI signals of pairs of subjects instead of to a single reference point. We also present a method for fMRI data comparison that leverages this generated pairwise feature to establish a radial basis function kernel matrix. This kernel matrix is used in turn to perform kernel regression of rs-fMRI to a clinical variable such as a cognitive or neurophysiological performance score of interest. This method opens a new pointwise analysis paradigm for fMRI data. We demonstrate the application of this method by performing a pointwise analysis on the cortical surface using rs-fMRI data to identify cortical regions associated with variability in ADHD index. While pointwise analysis methods are common in anatomical studies such as cortical thickness analysis and voxel- and tensor-based morphometry and its variants, such a method is lacking for rs-fMRI and could improve the utility of rs-fMRI for group studies. The method presented in this paper is aimed at filling this gap.

</p>
</details>

<details><summary><b>Predicting Generalization in Deep Learning via Local Measures of Distortion</b>
<a href="https://arxiv.org/abs/2012.06969">arxiv:2012.06969</a>
&#x1F4C8; -1 <br>
<p>Abhejit Rajagopal, Vamshi C. Madala, Shivkumar Chandrasekaran, Peder E. Z. Larson</p></summary>
<p>

**Abstract:** We study generalization in deep learning by appealing to complexity measures originally developed in approximation and information theory. While these concepts are challenged by the high-dimensional and data-defined nature of deep learning, we show that simple vector quantization approaches such as PCA, GMMs, and SVMs capture their spirit when applied layer-wise to deep extracted features giving rise to relatively inexpensive complexity measures that correlate well with generalization performance. We discuss our results in 2020 NeurIPS PGDL challenge.

</p>
</details>

<details><summary><b>Multi-Interactive Attention Network for Fine-grained Feature Learning in CTR Prediction</b>
<a href="https://arxiv.org/abs/2012.06968">arxiv:2012.06968</a>
&#x1F4C8; -1 <br>
<p>Kai Zhang, Hao Qian, Qing Cui, Qi Liu, Longfei Li, Jun Zhou, Jianhui Ma, Enhong Chen</p></summary>
<p>

**Abstract:** In the Click-Through Rate (CTR) prediction scenario, user's sequential behaviors are well utilized to capture the user interest in the recent literature. However, despite being extensively studied, these sequential methods still suffer from three limitations. First, existing methods mostly utilize attention on the behavior of users, which is not always suitable for CTR prediction, because users often click on new products that are irrelevant to any historical behaviors. Second, in the real scenario, there exist numerous users that have operations a long time ago, but turn relatively inactive in recent times. Thus, it is hard to precisely capture user's current preferences through early behaviors. Third, multiple representations of user's historical behaviors in different feature subspaces are largely ignored. To remedy these issues, we propose a Multi-Interactive Attention Network (MIAN) to comprehensively extract the latent relationship among all kinds of fine-grained features (e.g., gender, age and occupation in user-profile). Specifically, MIAN contains a Multi-Interactive Layer (MIL) that integrates three local interaction modules to capture multiple representations of user preference through sequential behaviors and simultaneously utilize the fine-grained user-specific as well as context information. In addition, we design a Global Interaction Module (GIM) to learn the high-order interactions and balance the different impacts of multiple features. Finally, Offline experiment results from three datasets, together with an Online A/B test in a large-scale recommendation system, demonstrate the effectiveness of our proposed approach.

</p>
</details>


[Next Page](2020/2020-12/2020-12-12.md)
