
## Summary for 2020-12-11, created on 2021-01-10


<details><summary><b>Disentangling images with Lie group transformations and sparse coding</b>
<a href="https://arxiv.org/abs/2012.12071">arxiv:2012.12071</a>
&#x1F4C8; 3 <br>
<p>Ho Yin Chau, Frank Qiu, Yubei Chen, Bruno Olshausen</p></summary>
<p>

**Abstract:** Discrete spatial patterns and their continuous transformations are two important regularities contained in natural signals. Lie groups and representation theory are mathematical tools that have been used in previous works to model continuous image transformations. On the other hand, sparse coding is an important tool for learning dictionaries of patterns in natural signals. In this paper, we combine these ideas in a Bayesian generative model that learns to disentangle spatial patterns and their continuous transformations in a completely unsupervised manner. Images are modeled as a sparse superposition of shape components followed by a transformation that is parameterized by n continuous variables. The shape components and transformations are not predefined, but are instead adapted to learn the symmetries in the data, with the constraint that the transformations form a representation of an n-dimensional torus. Training the model on a dataset consisting of controlled geometric transformations of specific MNIST digits shows that it can recover these transformations along with the digits. Training on the full MNIST dataset shows that it can learn both the basic digit shapes and the natural transformations such as shearing and stretching that are contained in this data.

</p>
</details>

<details><summary><b>Do not repeat these mistakes -- a critical appraisal of applications of explainable artificial intelligence for image based COVID-19 detection</b>
<a href="https://arxiv.org/abs/2012.08333">arxiv:2012.08333</a>
&#x1F4C8; -1 <br>
<p>Weronika Hryniewska, Przemysław Bombiński, Patryk Szatkowski, Paulina Tomaszewska, Artur Przelaskowski, Przemysław Biecek</p></summary>
<p>

**Abstract:** The sudden outbreak and uncontrolled spread of COVID-19 disease is one of the most important global problems today. In a short period of time, it has led to the development of many deep neural network models for COVID-19 detection with modules for explainability. In this work, we carry out a systematic analysis of various aspects of proposed models. Our analysis revealed numerous mistakes made at different stages of data acquisition, model development, and explanation construction. In this work, we overview the approaches proposed in the surveyed ML articles and indicate typical errors emerging from the lack of deep understanding of the radiography domain. We present the perspective of both: experts in the field - radiologists, and deep learning engineers dealing with model explanations. The final result is a proposed a checklist with the minimum conditions to be met by a reliable COVID-19 diagnostic model.

</p>
</details>

<details><summary><b>Towards an Adaptive Dynamic Mode Decomposition</b>
<a href="https://arxiv.org/abs/2012.07834">arxiv:2012.07834</a>
&#x1F4C8; -1 <br>
<p>Mohammad N. Murshed, M. Monir Uddin</p></summary>
<p>

**Abstract:** Dynamic Mode Decomposition (DMD) is a data based modeling tool that identifies a matrix to map a quantity at some time instant to the same quantity in future. We design a new version which we call Adaptive Dynamic Mode Decomposition (ADMD) that utilizes time delay coordinates, projection methods and filters as per the nature of the data to create a model for the available problem. Filters are very effective in reducing the rank of high-dimensional dataset. We have incorporated 'discrete Fourier transform' and 'augmented lagrangian multiplier' as filters in our method. The proposed ADMD is tested on several datasets of varying complexities and its performance appears to be promising.

</p>
</details>

<details><summary><b>Water Level Estimation Using Sentinel-1 Synthetic Aperture Radar Imagery And Digital Elevation Models</b>
<a href="https://arxiv.org/abs/2012.07627">arxiv:2012.07627</a>
&#x1F4C8; -1 <br>
<p>Thai-Bao Duong-Nguyen, Thien-Nu Hoang, Phong Vo, Hoai-Bac Le</p></summary>
<p>

**Abstract:** Hydropower dams and reservoirs have been identified as the main factors redefining natural hydrological cycles. Therefore, monitoring water status in reservoirs plays a crucial role in planning and managing water resources, as well as forecasting drought and flood. This task has been traditionally done by installing sensor stations on the ground nearby water bodies, which has multiple disadvantages in maintenance cost, accessibility, and global coverage. And to cope with these problems, Remote Sensing, which is known as the science of obtaining information about objects or areas without making contact with them, has been actively studied for many applications. In this paper, we propose a novel water level extracting approach, which employs Sentinel-1 Synthetic Aperture Radar imagery and Digital Elevation Model data sets. Experiments show that the algorithm achieved a low average error of 0.93 meters over three reservoirs globally, proving its potential to be widely applied and furthermore studied.

</p>
</details>

<details><summary><b>On Lightweight Privacy-Preserving Collaborative Learning for Internet of Things by Independent Random Projections</b>
<a href="https://arxiv.org/abs/2012.07626">arxiv:2012.07626</a>
&#x1F4C8; -1 <br>
<p>Linshan Jiang, Rui Tan, Xin Lou, Guosheng Lin</p></summary>
<p>

**Abstract:** The Internet of Things (IoT) will be a main data generation infrastructure for achieving better system intelligence. This paper considers the design and implementation of a practical privacy-preserving collaborative learning scheme, in which a curious learning coordinator trains a better machine learning model based on the data samples contributed by a number of IoT objects, while the confidentiality of the raw forms of the training data is protected against the coordinator. Existing distributed machine learning and data encryption approaches incur significant computation and communication overhead, rendering them ill-suited for resource-constrained IoT objects. We study an approach that applies independent random projection at each IoT object to obfuscate data and trains a deep neural network at the coordinator based on the projected data from the IoT objects. This approach introduces light computation overhead to the IoT objects and moves most workload to the coordinator that can have sufficient computing resources. Although the independent projections performed by the IoT objects address the potential collusion between the curious coordinator and some compromised IoT objects, they significantly increase the complexity of the projected data. In this paper, we leverage the superior learning capability of deep learning in capturing sophisticated patterns to maintain good learning performance. The extensive comparative evaluation shows that this approach outperforms other lightweight approaches that apply additive noisification for differential privacy and/or support vector machines for learning in the applications with light to moderate data pattern complexities.

</p>
</details>

<details><summary><b>Intrinsic persistent homology via density-based metric learning</b>
<a href="https://arxiv.org/abs/2012.07621">arxiv:2012.07621</a>
&#x1F4C8; -1 <br>
<p>Eugenio Borghini, Ximena Fernández, Pablo Groisman, Gabriel Mindlin</p></summary>
<p>

**Abstract:** We address the problem of estimating intrinsic distances in a manifold from a finite sample. We prove that the metric space defined by the sample endowed with a computable metric known as sample Fermat distance converges a.s. in the sense of Gromov-Hausdorff. The limiting object is the manifold itself endowed with the population Fermat distance, an intrinsic metric that accounts for both the geometry of the manifold and the density that produces the sample. This result is applied to obtain sample persistence diagrams that converge towards an intrinsic persistence diagram. We show that this method outperforms more standard approaches based on Euclidean norm with theoretical results and computational experiments.

</p>
</details>

<details><summary><b>ALReLU: A different approach on Leaky ReLU activation function to improve Neural Networks Performance</b>
<a href="https://arxiv.org/abs/2012.07564">arxiv:2012.07564</a>
&#x1F4C8; -1 <br>
<p>Stamatis Mastromichalakis</p></summary>
<p>

**Abstract:** Despite the unresolved 'dying ReLU problem', the classical ReLU activation function (AF) has been extensively applied in Deep Neural Networks (DNN), in particular Convolutional Neural Networks (CNN), for image classification. The common gradient issues of ReLU pose challenges in applications on academy and industry sectors. Recent approaches for improvements are in a similar direction by just proposing variations of the AF, such as Leaky ReLU (LReLU), while maintaining the solution within the same unresolved gradient problems. In this paper, the Absolute Leaky ReLU (ALReLU) AF, a variation of LReLU, is proposed, as an alternative method to resolve the common 'dying ReLU problem' on NN-based algorithms for supervised learning. The experimental results demonstrate that by using the absolute values of LReLU's small negative gradient, has a significant improvement in comparison with LReLU and ReLU, on image classification of diseases such as COVID-19, text and tabular data classification tasks on five different datasets.

</p>
</details>

<details><summary><b>An End-to-End Solution for Named Entity Recognition in eCommerce Search</b>
<a href="https://arxiv.org/abs/2012.07553">arxiv:2012.07553</a>
&#x1F4C8; -1 <br>
<p>Xiang Cheng, Mitchell Bowden, Bhushan Ramesh Bhange, Priyanka Goyal, Thomas Packer, Faizan Javed</p></summary>
<p>

**Abstract:** Named entity recognition (NER) is a critical step in modern search query understanding. In the domain of eCommerce, identifying the key entities, such as brand and product type, can help a search engine retrieve relevant products and therefore offer an engaging shopping experience. Recent research shows promising results on shared benchmark NER tasks using deep learning methods, but there are still unique challenges in the industry regarding domain knowledge, training data, and model production. This paper demonstrates an end-to-end solution to address these challenges. The core of our solution is a novel model training framework "TripleLearn" which iteratively learns from three separate training datasets, instead of one training set as is traditionally done. Using this approach, the best model lifts the F1 score from 69.5 to 93.3 on the holdout test data. In our offline experiments, TripleLearn improved the model performance compared to traditional training approaches which use a single set of training data. Moreover, in the online A/B test, we see significant improvements in user engagement and revenue conversion. The model has been live on homedepot.com for more than 9 months, boosting search conversions and revenue. Beyond our application, this TripleLearn framework, as well as the end-to-end process, is model-independent and problem-independent, so it can be generalized to more industrial applications, especially to the eCommerce industry which has similar data foundations and problems.

</p>
</details>

<details><summary><b>On Duality Gap as a Measure for Monitoring GAN Training</b>
<a href="https://arxiv.org/abs/2012.06723">arxiv:2012.06723</a>
&#x1F4C8; -1 <br>
<p>Sahil Sidheekh, Aroof Aimen, Vineet Madan, Narayanan C. Krishnan</p></summary>
<p>

**Abstract:** Generative adversarial network (GAN) is among the most popular deep learning models for learning complex data distributions. However, training a GAN is known to be a challenging task. This is often attributed to the lack of correlation between the training progress and the trajectory of the generator and discriminator losses and the need for the GAN's subjective evaluation. A recently proposed measure inspired by game theory - the duality gap, aims to bridge this gap. However, as we demonstrate, the duality gap's capability remains constrained due to limitations posed by its estimation process. This paper presents a theoretical understanding of this limitation and proposes a more dependable estimation process for the duality gap. At the crux of our approach is the idea that local perturbations can help agents in a zero-sum game escape non-Nash saddle points efficiently. Through exhaustive experimentation across GAN models and datasets, we establish the efficacy of our approach in capturing the GAN training progress with minimal increase to the computational complexity. Further, we show that our estimate, with its ability to identify model convergence/divergence, is a potential performance measure that can be used to tune the hyperparameters of a GAN.

</p>
</details>

<details><summary><b>Low-Order Model of Biological Neural Networks</b>
<a href="https://arxiv.org/abs/2012.06720">arxiv:2012.06720</a>
&#x1F4C8; -1 <br>
<p>Huachuan Wang, James Ting-Ho Lo</p></summary>
<p>

**Abstract:** A biologically plausible low-order model (LOM) of biological neural networks is a recurrent hierarchical network of dendritic nodes/trees, spiking/nonspiking neurons, unsupervised/ supervised covariance/accumulative learning mechanisms, feedback connections, and a scheme for maximal generalization. These component models are motivated and necessitated by making LOM learn and retrieve easily without differentiation, optimization, or iteration, and cluster, detect and recognize multiple/hierarchical corrupted, distorted, and occluded temporal and spatial patterns.

</p>
</details>

<details><summary><b>Learning Consistent Deep Generative Models from Sparse Data via Prediction Constraints</b>
<a href="https://arxiv.org/abs/2012.06718">arxiv:2012.06718</a>
&#x1F4C8; -1 <br>
<p>Gabriel Hope, Madina Abdrakhmanova, Xiaoyin Chen, Michael C. Hughes, Michael C. Hughes, Erik B. Sudderth</p></summary>
<p>

**Abstract:** We develop a new framework for learning variational autoencoders and other deep generative models that balances generative and discriminative goals. Our framework optimizes model parameters to maximize a variational lower bound on the likelihood of observed data, subject to a task-specific prediction constraint that prevents model misspecification from leading to inaccurate predictions. We further enforce a consistency constraint, derived naturally from the generative model, that requires predictions on reconstructed data to match those on the original data. We show that these two contributions -- prediction constraints and consistency constraints -- lead to promising image classification performance, especially in the semi-supervised scenario where category labels are sparse but unlabeled data is plentiful. Our approach enables advances in generative modeling to directly boost semi-supervised classification performance, an ability we demonstrate by augmenting deep generative models with latent variables capturing spatial transformations.

</p>
</details>

<details><summary><b>Approximate Trace Reconstruction</b>
<a href="https://arxiv.org/abs/2012.06713">arxiv:2012.06713</a>
&#x1F4C8; -1 <br>
<p>Sami Davies, Miklos Z. Racz, Cyrus Rashtchian, Benjamin G. Schiffer</p></summary>
<p>

**Abstract:** In the usual trace reconstruction problem, the goal is to exactly reconstruct an unknown string of length $n$ after it passes through a deletion channel many times independently, producing a set of traces (i.e., random subsequences of the string). We consider the relaxed problem of approximate reconstruction. Here, the goal is to output a string that is close to the original one in edit distance while using much fewer traces than is needed for exact reconstruction. We present several algorithms that can approximately reconstruct strings that belong to certain classes, where the estimate is within $n/\mathrm{polylog}(n)$ edit distance, and where we only use $\mathrm{polylog}(n)$ traces (or sometimes just a single trace). These classes contain strings that require a linear number of traces for exact reconstruction and which are quite different from a typical random string. From a technical point of view, our algorithms approximately reconstruct consecutive substrings of the unknown string by aligning dense regions of traces and using a run of a suitable length to approximate each region. To complement our algorithms, we present a general black-box lower bound for approximate reconstruction, building on a lower bound for distinguishing between two candidate input strings in the worst case. In particular, this shows that approximating to within $n^{1/3 - δ}$ edit distance requires $n^{1 + 3δ/2}/\mathrm{polylog}(n)$ traces for $0< δ< 1/3$ in the worst case.

</p>
</details>

<details><summary><b>Noise-Robust End-to-End Quantum Control using Deep Autoregressive Policy Networks</b>
<a href="https://arxiv.org/abs/2012.06701">arxiv:2012.06701</a>
&#x1F4C8; -1 <br>
<p>Jiahao Yao, Paul Köttering, Hans Gundlach, Lin Lin, Marin Bukov</p></summary>
<p>

**Abstract:** Variational quantum eigensolvers have recently received increased attention, as they enable the use of quantum computing devices to find solutions to complex problems, such as the ground energy and ground state of strongly-correlated quantum many-body systems. In many applications, it is the optimization of both continuous and discrete parameters that poses a formidable challenge. Using reinforcement learning (RL), we present a hybrid policy gradient algorithm capable of simultaneously optimizing continuous and discrete degrees of freedom in an uncertainty-resilient way. The hybrid policy is modeled by a deep autoregressive neural network to capture causality. We employ the algorithm to prepare the ground state of the nonintegrable quantum Ising model in a unitary process, parametrized by a generalized quantum approximate optimization ansatz: the RL agent solves the discrete combinatorial problem of constructing the optimal sequences of unitaries out of a predefined set and, at the same time, it optimizes the continuous durations for which these unitaries are applied. We demonstrate the noise-robust features of the agent by considering three sources of uncertainty: classical and quantum measurement noise, and errors in the control unitary durations. Our work exhibits the beneficial synergy between reinforcement learning and quantum control.

</p>
</details>

<details><summary><b>TALI: Protein Structure Alignment Using Backbone Torsion Angles</b>
<a href="https://arxiv.org/abs/2012.06697">arxiv:2012.06697</a>
&#x1F4C8; -1 <br>
<p>Xijiang Miao, Michael G. Bryson, Homayoun Valafar</p></summary>
<p>

**Abstract:** This article introduces a novel protein structure alignment method (named TALI) based on the protein backbone torsion angle instead of the more traditional distance matrix. Because the structural alignment of the two proteins is based on the comparison of two sequences of numbers (backbone torsion angles), we can take advantage of a large number of well-developed methods such as Smith-Waterman or Needleman-Wunsch. Here we report the result of TALI in comparison to other structure alignment methods such as DALI, CE, and SSM ass well as sequence alignment based on PSI-BLAST. TALI demonstrated great success over all other methods in application to challenging proteins. TALI was more successful in recognizing remote structural homology. TALI also demonstrated an ability to identify structural homology between two proteins where the structural difference was due to a rotation of internal domains by nearly 180$^\circ$.

</p>
</details>

<details><summary><b>Generating Adversarial Disturbances for Controller Verification</b>
<a href="https://arxiv.org/abs/2012.06695">arxiv:2012.06695</a>
&#x1F4C8; -1 <br>
<p>Udaya Ghai, David Snyder, Anirudha Majumdar, Elad Hazan</p></summary>
<p>

**Abstract:** We consider the problem of generating maximally adversarial disturbances for a given controller assuming only blackbox access to it. We propose an online learning approach to this problem that adaptively generates disturbances based on control inputs chosen by the controller. The goal of the disturbance generator is to minimize regret versus a benchmark disturbance-generating policy class, i.e., to maximize the cost incurred by the controller as well as possible compared to the best possible disturbance generator in hindsight (chosen from a benchmark policy class). In the setting where the dynamics are linear and the costs are quadratic, we formulate our problem as an online trust region (OTR) problem with memory and present a new online learning algorithm (MOTR) for this problem. We prove that this method competes with the best disturbance generator in hindsight (chosen from a rich class of benchmark policies that includes linear-dynamical disturbance generating policies). We demonstrate our approach on two simulated examples: (i) synthetically generated linear systems, and (ii) generating wind disturbances for the popular PX4 controller in the AirSim simulator. On these examples, we demonstrate that our approach outperforms several baseline approaches, including $H_{\infty}$ disturbance generation and gradient-based methods.

</p>
</details>

<details><summary><b>Learning Representations from Temporally Smooth Data</b>
<a href="https://arxiv.org/abs/2012.06694">arxiv:2012.06694</a>
&#x1F4C8; -1 <br>
<p>Shima Rahimi Moghaddam, Fanjun Bu, Christopher J. Honey</p></summary>
<p>

**Abstract:** Events in the real world are correlated across nearby points in time, and we must learn from this temporally smooth data. However, when neural networks are trained to categorize or reconstruct single items, the common practice is to randomize the order of training items. What are the effects of temporally smooth training data on the efficiency of learning? We first tested the effects of smoothness in training data on incremental learning in feedforward nets and found that smoother data slowed learning. Moreover, sampling so as to minimize temporal smoothness produced more efficient learning than sampling randomly. If smoothness generally impairs incremental learning, then how can networks be modified to benefit from smoothness in the training data? We hypothesized that two simple brain-inspired mechanisms, leaky memory in activation units and memory-gating, could enable networks to rapidly extract useful representations from smooth data. Across all levels of data smoothness, these brain-inspired architectures achieved more efficient category learning than feedforward networks. This advantage persisted, even when leaky memory networks with gating were trained on smooth data and tested on randomly-ordered data. Finally, we investigated how these brain-inspired mechanisms altered the internal representations learned by the networks. We found that networks with multi-scale leaky memory and memory-gating could learn internal representations that un-mixed data sources which vary on fast and slow timescales across training samples. Altogether, we identified simple mechanisms enabling neural networks to learn more quickly from temporally smooth data, and to generate internal representations that separate timescales in the training signal.

</p>
</details>

<details><summary><b>Parameter Estimation with Dense and Convolutional Neural Networks Applied to the FitzHugh-Nagumo ODE</b>
<a href="https://arxiv.org/abs/2012.06691">arxiv:2012.06691</a>
&#x1F4C8; -1 <br>
<p>Johann Rudi, Julie Bessac, Amanda Lenzi</p></summary>
<p>

**Abstract:** Machine learning algorithms have been successfully used to approximate nonlinear maps under weak assumptions on the structure and properties of the maps. We present deep neural networks using dense and convolutional layers to solve an inverse problem, where we seek to estimate parameters in a FitzHugh-Nagumo model, which consists of a nonlinear system of ordinary differential equations (ODEs). We employ the neural networks to approximate reconstruction maps for model parameter estimation from observational data, where the data comes from the solution of the ODE and takes the form of a time series representing dynamically spiking membrane potential of a (biological) neuron. We target this dynamical model because of the computational challenges it poses in an inference setting, namely, having a highly nonlinear and nonconvex data misfit term and permitting only weakly informative priors on parameters. These challenges cause traditional optimization to fail and alternative algorithms to exhibit large computational costs. We quantify the predictability of model parameters obtained from the neural networks with statistical metrics and investigate the effects of network architectures and presence of noise in observational data. Our results demonstrate that deep neural networks are capable of very accurately estimating parameters in dynamical models from observational data.

</p>
</details>

<details><summary><b>Yelp Review Rating Prediction: Machine Learning and Deep Learning Models</b>
<a href="https://arxiv.org/abs/2012.06690">arxiv:2012.06690</a>
&#x1F4C8; -1 <br>
<p>Zefang Liu</p></summary>
<p>

**Abstract:** We predict restaurant ratings from Yelp reviews based on Yelp Open Dataset. Data distribution is presented, and one balanced training dataset is built. Two vectorizers are experimented for feature engineering. Four machine learning models including Naive Bayes, Logistic Regression, Random Forest, and Linear Support Vector Machine are implemented. Four transformer-based models containing BERT, DistilBERT, RoBERTa, and XLNet are also applied. Accuracy, weighted F1 score, and confusion matrix are used for model evaluation. XLNet achieves 70% accuracy for 5-star classification compared with Logistic Regression with 64% accuracy.

</p>
</details>

<details><summary><b>Faster Policy Learning with Continuous-Time Gradients</b>
<a href="https://arxiv.org/abs/2012.06684">arxiv:2012.06684</a>
&#x1F4C8; -1 <br>
<p>Samuel Ainsworth, Kendall Lowrey, John Thickstun, Zaid Harchaoui, Siddhartha Srinivasa</p></summary>
<p>

**Abstract:** We study the estimation of policy gradients for continuous-time systems with known dynamics. By reframing policy learning in continuous-time, we show that it is possible construct a more efficient and accurate gradient estimator. The standard back-propagation through time estimator (BPTT) computes exact gradients for a crude discretization of the continuous-time system. In contrast, we approximate continuous-time gradients in the original system. With the explicit goal of estimating continuous-time gradients, we are able to discretize adaptively and construct a more efficient policy gradient estimator which we call the Continuous-Time Policy Gradient (CTPG). We show that replacing BPTT policy gradients with more efficient CTPG estimates results in faster and more robust learning in a variety of control tasks and simulators.

</p>
</details>

<details><summary><b>TabTransformer: Tabular Data Modeling Using Contextual Embeddings</b>
<a href="https://arxiv.org/abs/2012.06678">arxiv:2012.06678</a>
&#x1F4C8; -1 <br>
<p>Xin Huang, Ashish Khetan, Milan Cvitkovic, Zohar Karnin</p></summary>
<p>

**Abstract:** We propose TabTransformer, a novel deep tabular data modeling architecture for supervised and semi-supervised learning. The TabTransformer is built upon self-attention based Transformers. The Transformer layers transform the embeddings of categorical features into robust contextual embeddings to achieve higher prediction accuracy. Through extensive experiments on fifteen publicly available datasets, we show that the TabTransformer outperforms the state-of-the-art deep learning methods for tabular data by at least 1.0% on mean AUC, and matches the performance of tree-based ensemble models. Furthermore, we demonstrate that the contextual embeddings learned from TabTransformer are highly robust against both missing and noisy data features, and provide better interpretability. Lastly, for the semi-supervised setting we develop an unsupervised pre-training procedure to learn data-driven contextual embeddings, resulting in an average 2.1% AUC lift over the state-of-the-art methods.

</p>
</details>

<details><summary><b>Avoiding The Double Descent Phenomenon of Random Feature Models Using Hybrid Regularization</b>
<a href="https://arxiv.org/abs/2012.06667">arxiv:2012.06667</a>
&#x1F4C8; -1 <br>
<p>Kelvin Kan, James G Nagy, Lars Ruthotto</p></summary>
<p>

**Abstract:** We demonstrate the ability of hybrid regularization methods to automatically avoid the double descent phenomenon arising in the training of random feature models (RFM). The hallmark feature of the double descent phenomenon is a spike in the regularization gap at the interpolation threshold, i.e. when the number of features in the RFM equals the number of training samples. To close this gap, the hybrid method considered in our paper combines the respective strengths of the two most common forms of regularization: early stopping and weight decay. The scheme does not require hyperparameter tuning as it automatically selects the stopping iteration and weight decay hyperparameter by using generalized cross-validation (GCV). This also avoids the necessity of a dedicated validation set. While the benefits of hybrid methods have been well-documented for ill-posed inverse problems, our work presents the first use case in machine learning. To expose the need for regularization and motivate hybrid methods, we perform detailed numerical experiments inspired by image classification. In those examples, the hybrid scheme successfully avoids the double descent phenomenon and yields RFMs whose generalization is comparable with classical regularization approaches whose hyperparameters are tuned optimally using the test data. We provide our MATLAB codes for implementing the numerical experiments in this paper at https://github.com/EmoryMLIP/HybridRFM.

</p>
</details>

<details><summary><b>Protective Policy Transfer</b>
<a href="https://arxiv.org/abs/2012.06662">arxiv:2012.06662</a>
&#x1F4C8; -1 <br>
<p>Wenhao Yu, C. Karen Liu, Greg Turk</p></summary>
<p>

**Abstract:** Being able to transfer existing skills to new situations is a key capability when training robots to operate in unpredictable real-world environments. A successful transfer algorithm should not only minimize the number of samples that the robot needs to collect in the new environment, but also prevent the robot from damaging itself or the surrounding environment during the transfer process. In this work, we introduce a policy transfer algorithm for adapting robot motor skills to novel scenarios while minimizing serious failures. Our algorithm trains two control policies in the training environment: a task policy that is optimized to complete the task of interest, and a protective policy that is dedicated to keep the robot from unsafe events (e.g. falling to the ground). To decide which policy to use during execution, we learn a safety estimator model in the training environment that estimates a continuous safety level of the robot. When used with a set of thresholds, the safety estimator becomes a classifier for switching between the protective policy and the task policy. We evaluate our approach on four simulated robot locomotion problems and a 2D navigation problem and show that our method can achieve successful transfer to notably different environments while taking the robot's safety into consideration.

</p>
</details>

<details><summary><b>DeCoAR 2.0: Deep Contextualized Acoustic Representations with Vector Quantization</b>
<a href="https://arxiv.org/abs/2012.06659">arxiv:2012.06659</a>
&#x1F4C8; -1 <br>
<p>Shaoshi Ling, Yuzong Liu</p></summary>
<p>

**Abstract:** Recent success in speech representation learning enables a new way to leverage unlabeled data to train speech recognition model. In speech representation learning, a large amount of unlabeled data is used in a self-supervised manner to learn a feature representation. Then a smaller amount of labeled data is used to train a downstream ASR system using the new feature representations. Based on our previous work DeCoAR and inspirations from other speech representation learning, we propose DeCoAR 2.0, a Deep Contextualized Acoustic Representation with vector quantization. We introduce several modifications over the DeCoAR: first, we use Transformers in encoding module instead of LSTMs; second, we introduce a vector quantization layer between encoder and reconstruction modules; third, we propose an objective that combines the reconstructive loss with vector quantization diversity loss to train speech representations. Our experiments show consistent improvements over other speech representations in different data-sparse scenarios. Without fine-tuning, a light-weight ASR model trained on 10 hours of LibriSpeech labeled data with DeCoAR 2.0 features outperforms the model trained on the full 960-hour dataset with filterbank features.

</p>
</details>

<details><summary><b>Regularizing Action Policies for Smooth Control with Reinforcement Learning</b>
<a href="https://arxiv.org/abs/2012.06644">arxiv:2012.06644</a>
&#x1F4C8; -1 <br>
<p>Siddharth Mysore, Bassel Mabsout, Renato Mancuso, Kate Saenko</p></summary>
<p>

**Abstract:** A critical problem with the practical utility of controllers trained with deep Reinforcement Learning (RL) is the notable lack of smoothness in the actions learned by the RL policies. This trend often presents itself in the form of control signal oscillation and can result in poor control, high power consumption, and undue system wear. We introduce Conditioning for Action Policy Smoothness (CAPS), an effective yet intuitive regularization on action policies, which offers consistent improvement in the smoothness of the learned state-to-action mappings of neural network controllers, reflected in the elimination of high-frequency components in the control signal. Tested on a real system, improvements in controller smoothness on a quadrotor drone resulted in an almost 80% reduction in power consumption while consistently training flight-worthy controllers. Project website: http://ai.bu.edu/caps

</p>
</details>

<details><summary><b>Reconstruction of Pairwise Interactions using Energy-Based Models</b>
<a href="https://arxiv.org/abs/2012.06625">arxiv:2012.06625</a>
&#x1F4C8; -1 <br>
<p>Christoph Feinauer, Carlo Lucibello</p></summary>
<p>

**Abstract:** Pairwise models like the Ising model or the generalized Potts model have found many successful applications in fields like physics, biology, and economics. Closely connected is the problem of inverse statistical mechanics, where the goal is to infer the parameters of such models given observed data. An open problem in this field is the question of how to train these models in the case where the data contain additional higher-order interactions that are not present in the pairwise model. In this work, we propose an approach based on Energy-Based Models and pseudolikelihood maximization to address these complications: we show that hybrid models, which combine a pairwise model and a neural network, can lead to significant improvements in the reconstruction of pairwise interactions. We show these improvements to hold consistently when compared to a standard approach using only the pairwise model and to an approach using only a neural network. This is in line with the general idea that simple interpretable models and complex black-box models are not necessarily a dichotomy: interpolating these two classes of models can allow to keep some advantages of both.

</p>
</details>

<details><summary><b>Risk & returns around FOMC press conferences: a novel perspective from computer vision</b>
<a href="https://arxiv.org/abs/2012.06573">arxiv:2012.06573</a>
&#x1F4C8; -1 <br>
<p>Alexis Marchal</p></summary>
<p>

**Abstract:** I propose a new tool to characterize the resolution of uncertainty around FOMC press conferences. It relies on the construction of a measure capturing the level of discussion complexity between the Fed Chair and reporters during the Q&A sessions. I show that complex discussions are associated with higher equity returns and a drop in realized volatility. The method creates an attention score by quantifying how much the Chair needs to rely on reading internal documents to be able to answer a question. This is accomplished by building a novel dataset of video images of the press conferences and leveraging recent deep learning algorithms from computer vision. This alternative data provides new information on nonverbal communication that cannot be extracted from the widely analyzed FOMC transcripts. This paper can be seen as a proof of concept that certain videos contain valuable information for the study of financial markets.

</p>
</details>

<details><summary><b>Glucose values prediction five years ahead with a new framework of missing responses in reproducing kernel Hilbert spaces, and the use of continuous glucose monitoring technology</b>
<a href="https://arxiv.org/abs/2012.06564">arxiv:2012.06564</a>
&#x1F4C8; -1 <br>
<p>Marcos Matabuena, Paulo Félix, Carlos Meijide-Garcia, Francisco Gude</p></summary>
<p>

**Abstract:** AEGIS study possesses unique information on longitudinal changes in circulating glucose through continuous glucose monitoring technology (CGM). However, as usual in longitudinal medical studies, there is a significant amount of missing data in the outcome variables. For example, 40 percent of glycosylated hemoglobin (A1C) biomarker data are missing five years ahead. With the purpose to reduce the impact of this issue, this article proposes a new data analysis framework based on learning in reproducing kernel Hilbert spaces (RKHS) with missing responses that allows to capture non-linear relations between variable studies in different supervised modeling tasks. First, we extend the Hilbert-Schmidt dependence measure to test statistical independence in this context introducing a new bootstrap procedure, for which we prove consistency. Next, we adapt or use existing models of variable selection, regression, and conformal inference to obtain new clinical findings about glucose changes five years ahead with the AEGIS data. The most relevant findings are summarized below: i) We identify new factors associated with long-term glucose evolution; ii) We show the clinical sensibility of CGM data to detect changes in glucose metabolism; iii) We can improve clinical interventions based on our algorithms' expected glucose changes according to patients' baseline characteristics.

</p>
</details>

<details><summary><b>OPAC: Opportunistic Actor-Critic</b>
<a href="https://arxiv.org/abs/2012.06555">arxiv:2012.06555</a>
&#x1F4C8; -1 <br>
<p>Srinjoy Roy, Saptam Bakshi, Tamal Maharaj</p></summary>
<p>

**Abstract:** Actor-critic methods, a type of model-free reinforcement learning (RL), have achieved state-of-the-art performances in many real-world domains in continuous control. Despite their success, the wide-scale deployment of these models is still a far cry. The main problems in these actor-critic methods are inefficient exploration and sub-optimal policies. Soft Actor-Critic (SAC) and Twin Delayed Deep Deterministic Policy Gradient (TD3), two cutting edge such algorithms, suffer from these issues. SAC effectively addressed the problems of sample complexity and convergence brittleness to hyper-parameters and thus outperformed all state-of-the-art algorithms including TD3 in harder tasks, whereas TD3 produced moderate results in all environments. SAC suffers from inefficient exploration owing to the Gaussian nature of its policy which causes borderline performance in simpler tasks. In this paper, we introduce Opportunistic Actor-Critic (OPAC), a novel model-free deep RL algorithm that employs better exploration policy and lesser variance. OPAC combines some of the most powerful features of TD3 and SAC and aims to optimize a stochastic policy in an off-policy way. For calculating the target Q-values, instead of two critics, OPAC uses three critics and based on the environment complexity, opportunistically chooses how the target Q-value is computed from the critics' evaluation. We have systematically evaluated the algorithm on MuJoCo environments where it achieves state-of-the-art performance and outperforms or at least equals the performance of TD3 and SAC.

</p>
</details>

<details><summary><b>AIforCOVID: predicting the clinical outcomes in patients with COVID-19 applying AI to chest-X-rays. An Italian multicentre study</b>
<a href="https://arxiv.org/abs/2012.06531">arxiv:2012.06531</a>
&#x1F4C8; -1 <br>
<p>Paolo Soda, Natascha Claudia D'Amico, Jacopo Tessadori, Giovanni Valbusa, Valerio Guarrasi, Chandra Bortolotto, Muhammad Usman Akbar, Rosa Sicilia, Ermanno Cordelli, Deborah Fazzini, Michaela Cellina, Giancarlo Oliva, Giovanni Callea, Silvia Panella, Maurizio Cariati, Diletta Cozzi, Vittorio Miele, Elvira Stellato, Gian Paolo Carrafiello, Giulia Castorani, Annalisa Simeone, Lorenzo Preda, Giulio Iannello, Alessio Del Bue, Fabio Tedoldi</p></summary>
<p>

**Abstract:** Recent epidemiological data report that worldwide more than 53 million people have been infected by SARS-CoV-2, resulting in 1.3 million deaths. The disease has been spreading very rapidly and few months after the identification of the first infected, shortage of hospital resources quickly became a problem. In this work we investigate whether chest X-ray (CXR) can be used as a possible tool for the early identification of patients at risk of severe outcome, like intensive care or death. CXR is a radiological technique that compared to computed tomography (CT) it is simpler, faster, more widespread and it induces lower radiation dose. We present a dataset including data collected from 820 patients by six Italian hospitals in spring 2020 during the first COVID-19 emergency. The dataset includes CXR images, several clinical attributes and clinical outcomes. We investigate the potential of artificial intelligence to predict the prognosis of such patients, distinguishing between severe and mild cases, thus offering a baseline reference for other researchers and practitioners. To this goal, we present three approaches that use features extracted from CXR images, either handcrafted or automatically by convolutional neuronal networks, which are then integrated with the clinical data. Exhaustive evaluation shows promising performance both in 10-fold and leave-one-centre-out cross-validation, implying that clinical data and images have the potential to provide useful information for the management of patients and hospital resources.

</p>
</details>

<details><summary><b>Dependency Decomposition and a Reject Option for Explainable Models</b>
<a href="https://arxiv.org/abs/2012.06523">arxiv:2012.06523</a>
&#x1F4C8; -1 <br>
<p>Jan Kronenberger, Anselm Haselhoff</p></summary>
<p>

**Abstract:** Deploying machine learning models in safety-related do-mains (e.g. autonomous driving, medical diagnosis) demands for approaches that are explainable, robust against adversarial attacks and aware of the model uncertainty. Recent deep learning models perform extremely well in various inference tasks, but the black-box nature of these approaches leads to a weakness regarding the three requirements mentioned above. Recent advances offer methods to visualize features, describe attribution of the input (e.g.heatmaps), provide textual explanations or reduce dimensionality. However,are explanations for classification tasks dependent or are they independent of each other? For in-stance, is the shape of an object dependent on the color? What is the effect of using the predicted class for generating explanations and vice versa? In the context of explainable deep learning models, we present the first analysis of dependencies regarding the probability distribution over the desired image classification outputs and the explaining variables (e.g. attributes, texts, heatmaps). Therefore, we perform an Explanation Dependency Decomposition (EDD). We analyze the implications of the different dependencies and propose two ways of generating the explanation. Finally, we use the explanation to verify (accept or reject) the prediction

</p>
</details>

<details><summary><b>Online Coresets for Clustering with Bregman Divergences</b>
<a href="https://arxiv.org/abs/2012.06522">arxiv:2012.06522</a>
&#x1F4C8; -1 <br>
<p>Rachit Chhaya, Jayesh Choudhari, Anirban Dasgupta, Supratim Shit</p></summary>
<p>

**Abstract:** We present algorithms that create coresets in an online setting for clustering problems according to a wide subset of Bregman divergences. Notably, our coresets have a small additive error, similar in magnitude to the lightweight coresets Bachem et. al. 2018, and take update time $O(d)$ for every incoming point where $d$ is dimension of the point. Our first algorithm gives online coresets of size $\tilde{O}(\mbox{poly}(k,d,ε,μ))$ for $k$-clusterings according to any $μ$-similar Bregman divergence. We further extend this algorithm to show existence of a non-parametric coresets, where the coreset size is independent of $k$, the number of clusters, for the same subclass of Bregman divergences. Our non-parametric coresets are larger by a factor of $O(\log n)$ ($n$ is number of points) and have similar (small) additive guarantee. At the same time our coresets also function as lightweight coresets for non-parametric versions of the Bregman clustering like DP-Means. While these coresets provide additive error guarantees, they are also significantly smaller (scaling with $O(\log n)$ as opposed to $O(d^d)$ for points in $R^d$) than the (relative-error) coresets obtained in Bachem et. al. 2015 for DP-Means. While our non-parametric coresets are existential, we give an algorithmic version under certain assumptions.

</p>
</details>

<details><summary><b>Sublinear classical and quantum algorithms for general matrix games</b>
<a href="https://arxiv.org/abs/2012.06519">arxiv:2012.06519</a>
&#x1F4C8; -1 <br>
<p>Tongyang Li, Chunhao Wang, Shouvanik Chakrabarti, Xiaodi Wu</p></summary>
<p>

**Abstract:** We investigate sublinear classical and quantum algorithms for matrix games, a fundamental problem in optimization and machine learning, with provable guarantees. Given a matrix $A\in\mathbb{R}^{n\times d}$, sublinear algorithms for the matrix game $\min_{x\in\mathcal{X}}\max_{y\in\mathcal{Y}} y^{\top} Ax$ were previously known only for two special cases: (1) $\mathcal{Y}$ being the $\ell_{1}$-norm unit ball, and (2) $\mathcal{X}$ being either the $\ell_{1}$- or the $\ell_{2}$-norm unit ball. We give a sublinear classical algorithm that can interpolate smoothly between these two cases: for any fixed $q\in (1,2]$, we solve the matrix game where $\mathcal{X}$ is a $\ell_{q}$-norm unit ball within additive error $ε$ in time $\tilde{O}((n+d)/{ε^{2}})$. We also provide a corresponding sublinear quantum algorithm that solves the same task in time $\tilde{O}((\sqrt{n}+\sqrt{d})\textrm{poly}(1/ε))$ with a quadratic improvement in both $n$ and $d$. Both our classical and quantum algorithms are optimal in the dimension parameters $n$ and $d$ up to poly-logarithmic factors. Finally, we propose sublinear classical and quantum algorithms for the approximate Carathéodory problem and the $\ell_{q}$-margin support vector machines as applications.

</p>
</details>

<details><summary><b>String Tightening as a Self-Organizing Phenomenon: Computation of Shortest Homotopic Path, Smooth Path, and Convex Hull</b>
<a href="https://arxiv.org/abs/2012.06513">arxiv:2012.06513</a>
&#x1F4C8; -1 <br>
<p>Bonny Banerjee</p></summary>
<p>

**Abstract:** The phenomenon of self-organization has been of special interest to the neural network community for decades. In this paper, we study a variant of the Self-Organizing Map (SOM) that models the phenomenon of self-organization of the particles forming a string when the string is tightened from one or both ends. The proposed variant, called the String Tightening Self-Organizing Neural Network (STON), can be used to solve certain practical problems, such as computation of shortest homotopic paths, smoothing paths to avoid sharp turns, and computation of convex hull. These problems are of considerable interest in computational geometry, robotics path planning, AI (diagrammatic reasoning), VLSI routing, and geographical information systems. Given a set of obstacles and a string with two fixed terminal points in a two dimensional space, the STON model continuously tightens the given string until the unique shortest configuration in terms of the Euclidean metric is reached. The STON minimizes the total length of a string on convergence by dynamically creating and selecting feature vectors in a competitive manner. Proof of correctness of this anytime algorithm and experimental results obtained by its deployment are presented in the paper.

</p>
</details>

<details><summary><b>Objectness-Guided Open Set Visual Search and Closed Set Detection</b>
<a href="https://arxiv.org/abs/2012.06509">arxiv:2012.06509</a>
&#x1F4C8; -1 <br>
<p>Nathan Drenkow, Philippe Burlina, Neil Fendley, Kachi Odoemene, Jared Markowitz</p></summary>
<p>

**Abstract:** Searching for small objects in large images is currently challenging for deep learning systems, but is a task with numerous applications including remote sensing and medical imaging. Thorough scanning of very large images is computationally expensive, particularly at resolutions sufficient to capture small objects. The smaller an object of interest, the more likely it is to be obscured by clutter or otherwise deemed insignificant. We examine these issues in the context of two complementary problems: closed-set object detection and open-set target search. First, we present a method for predicting pixel-level objectness from a low resolution gist image, which we then use to select regions for subsequent evaluation at high resolution. This approach has the benefit of not being fixed to a predetermined grid, allowing fewer costly high-resolution glimpses than existing methods. Second, we propose a novel strategy for open-set visual search that seeks to find all objects in an image of the same class as a given target reference image. We interpret both detection problems through a probabilistic, Bayesian lens, whereby the objectness maps produced by our method serve as priors in a maximum-a-posteriori approach to the detection step. We evaluate the end-to-end performance of both the combination of our patch selection strategy with this target search approach and the combination of our patch selection strategy with standard object detection methods. Both our patch selection and target search approaches are seen to significantly outperform baseline strategies.

</p>
</details>

<details><summary><b>Confidence Estimation via Auxiliary Models</b>
<a href="https://arxiv.org/abs/2012.06508">arxiv:2012.06508</a>
&#x1F4C8; -1 <br>
<p>Charles Corbière, Nicolas Thome, Antoine Saporta, Tuan-Hung Vu, Matthieu Cord, Patrick Pérez</p></summary>
<p>

**Abstract:** Reliably quantifying the confidence of deep neural classifiers is a challenging yet fundamental requirement for deploying such models in safety-critical applications. In this paper, we introduce a novel target criterion for model confidence, namely the true class probability (TCP). We show that TCP offers better properties for confidence estimation than standard maximum class probability (MCP). Since the true class is by essence unknown at test time, we propose to learn TCP criterion from data with an auxiliary model, introducing a specific learning scheme adapted to this context. We evaluate our approach on the task of failure prediction and of self-training with pseudo-labels for domain adaptation, which both necessitate effective confidence estimates. Extensive experiments are conducted for validating the relevance of the proposed approach in each task. We study various network architectures and experiment with small and large datasets for image classification and semantic segmentation. In every tested benchmark, our approach outperforms strong baselines.

</p>
</details>

<details><summary><b>Technical Opinion: From Animal Behaviour to Autonomous Robots</b>
<a href="https://arxiv.org/abs/2012.06492">arxiv:2012.06492</a>
&#x1F4C8; -1 <br>
<p>Chinedu Pascal Ezenkwu, Andrew Starkey</p></summary>
<p>

**Abstract:** With the rising applications of robots in unstructured real-world environments, roboticists are increasingly concerned with the problems posed by the complexity of such environments. One solution to these problems is robot autonomy. Since nature has already solved the problem of autonomy it can be a suitable model for developing autonomous robots. This paper presents a concise review on robot autonomy from the perspective of animal behaviour. It examines some state-of-the-art techniques as well as suggesting possible research directions.

</p>
</details>

<details><summary><b>Cyclic orthogonal convolutions for long-range integration of features</b>
<a href="https://arxiv.org/abs/2012.06462">arxiv:2012.06462</a>
&#x1F4C8; -1 <br>
<p>Federica Freddi, Jezabel R Garcia, Michael Bromberg, Sepehr Jalali, Da-Shan Shiu, Alvin Chua, Alberto Bernacchia</p></summary>
<p>

**Abstract:** In Convolutional Neural Networks (CNNs) information flows across a small neighbourhood of each pixel of an image, preventing long-range integration of features before reaching deep layers in the network. We propose a novel architecture that allows flexible information flow between features $z$ and locations $(x,y)$ across the entire image with a small number of layers. This architecture uses a cycle of three orthogonal convolutions, not only in $(x,y)$ coordinates, but also in $(x,z)$ and $(y,z)$ coordinates. We stack a sequence of such cycles to obtain our deep network, named CycleNet. As this only requires a permutation of the axes of a standard convolution, its performance can be directly compared to a CNN. Our model obtains competitive results at image classification on CIFAR-10 and ImageNet datasets, when compared to CNNs of similar size. We hypothesise that long-range integration favours recognition of objects by shape rather than texture, and we show that CycleNet transfers better than CNNs to stylised images. On the Pathfinder challenge, where integration of distant features is crucial, CycleNet outperforms CNNs by a large margin. We also show that even when employing a small convolutional kernel, the size of receptive fields of CycleNet reaches its maximum after one cycle, while conventional CNNs require a large number of layers.

</p>
</details>

<details><summary><b>Context Matters: Graph-based Self-supervised Representation Learning for Medical Images</b>
<a href="https://arxiv.org/abs/2012.06457">arxiv:2012.06457</a>
&#x1F4C8; -1 <br>
<p>Li Sun, Ke Yu, Kayhan Batmanghelich</p></summary>
<p>

**Abstract:** Supervised learning method requires a large volume of annotated datasets. Collecting such datasets is time-consuming and expensive. Until now, very few annotated COVID-19 imaging datasets are available. Although self-supervised learning enables us to bootstrap the training by exploiting unlabeled data, the generic self-supervised methods for natural images do not sufficiently incorporate the context. For medical images, a desirable method should be sensitive enough to detect deviation from normal-appearing tissue of each anatomical region; here, anatomy is the context. We introduce a novel approach with two levels of self-supervised representation learning objectives: one on the regional anatomical level and another on the patient-level. We use graph neural networks to incorporate the relationship between different anatomical regions. The structure of the graph is informed by anatomical correspondences between each patient and an anatomical atlas. In addition, the graph representation has the advantage of handling any arbitrarily sized image in full resolution. Experiments on large-scale Computer Tomography (CT) datasets of lung images show that our approach compares favorably to baseline methods that do not account for the context. We use the learnt embedding to quantify the clinical progression of COVID-19 and show that our method generalizes well to COVID-19 patients from different hospitals. Qualitative results suggest that our model can identify clinically relevant regions in the images.

</p>
</details>

<details><summary><b>Better call Surrogates: A hybrid Evolutionary Algorithm for Hyperparameter optimization</b>
<a href="https://arxiv.org/abs/2012.06453">arxiv:2012.06453</a>
&#x1F4C8; -1 <br>
<p>Subhodip Biswas, Adam D Cobb, Andreea Sistrunk, Naren Ramakrishnan, Brian Jalaian</p></summary>
<p>

**Abstract:** In this paper, we propose a surrogate-assisted evolutionary algorithm (EA) for hyperparameter optimization of machine learning (ML) models. The proposed STEADE model initially estimates the objective function landscape using RadialBasis Function interpolation, and then transfers the knowledge to an EA technique called Differential Evolution that is used to evolve new solutions guided by a Bayesian optimization framework. We empirically evaluate our model on the hyperparameter optimization problems as a part of the black box optimization challenge at NeurIPS 2020 and demonstrate the improvement brought about by STEADE over the vanilla EA.

</p>
</details>

<details><summary><b>A New Neural Network Architecture Invariant to the Action of Symmetry Subgroups</b>
<a href="https://arxiv.org/abs/2012.06452">arxiv:2012.06452</a>
&#x1F4C8; -1 <br>
<p>Piotr Kicki, Mete Ozay, Piotr Skrzypczyński</p></summary>
<p>

**Abstract:** We propose a computationally efficient $G$-invariant neural network that approximates functions invariant to the action of a given permutation subgroup $G \leq S_n$ of the symmetric group on input data. The key element of the proposed network architecture is a new $G$-invariant transformation module, which produces a $G$-invariant latent representation of the input data. Theoretical considerations are supported by numerical experiments, which demonstrate the effectiveness and strong generalization properties of the proposed method in comparison to other $G$-invariant neural networks.

</p>
</details>

<details><summary><b>Random Projections for Adversarial Attack Detection</b>
<a href="https://arxiv.org/abs/2012.06405">arxiv:2012.06405</a>
&#x1F4C8; -1 <br>
<p>Nathan Drenkow, Neil Fendley, Philippe Burlina</p></summary>
<p>

**Abstract:** Whilst adversarial attack detection has received considerable attention, it remains a fundamentally challenging problem from two perspectives. First, while threat models can be well-defined, attacker strategies may still vary widely within those constraints. Therefore, detection should be considered as an open-set problem, standing in contrast to most current detection strategies. These methods take a closed-set view and train binary detectors, thus biasing detection toward attacks seen during detector training. Second, information is limited at test time and confounded by nuisance factors including the label and underlying content of the image. Many of the current high-performing techniques use training sets for dealing with some of these issues, but can be limited by the overall size and diversity of those sets during the detection step. We address these challenges via a novel strategy based on random subspace analysis. We present a technique that makes use of special properties of random projections, whereby we can characterize the behavior of clean and adversarial examples across a diverse set of subspaces. We then leverage the self-consistency (or inconsistency) of model activations to discern clean from adversarial examples. Performance evaluation demonstrates that our technique outperforms ($>0.92$ AUC) competing state of the art (SOTA) attack strategies, while remaining truly agnostic to the attack method itself. It also requires significantly less training data, composed only of clean examples, when compared to competing SOTA methods, which achieve only chance performance, when evaluated in a more rigorous testing scenario.

</p>
</details>

<details><summary><b>Differential Evolution for Neural Architecture Search</b>
<a href="https://arxiv.org/abs/2012.06400">arxiv:2012.06400</a>
&#x1F4C8; -1 <br>
<p>Noor Awad, Neeratyoy Mallik, Frank Hutter</p></summary>
<p>

**Abstract:** Neural architecture search (NAS) methods rely on a search strategy for deciding which architectures to evaluate next and a performance estimation strategy for assessing their performance (e.g., using full evaluations, multi-fidelity evaluations, or the one-shot model). In this paper, we focus on the search strategy. We introduce the simple yet powerful evolutionary algorithm of differential evolution to the NAS community. Using the simplest performance evaluation strategy of full evaluations, we comprehensively compare this search strategy to regularized evolution and Bayesian optimization and demonstrate that it yields improved and more robust results for 13 tabular NAS benchmarks based on NAS-Bench-101, NAS-Bench-1Shot1, NAS-Bench-201 and NAS-HPO bench.

</p>
</details>

<details><summary><b>Closeness and Uncertainty Aware Adversarial Examples Detection in Adversarial Machine Learning</b>
<a href="https://arxiv.org/abs/2012.06390">arxiv:2012.06390</a>
&#x1F4C8; -1 <br>
<p>Omer Faruk Tuna, Ferhat Ozgur Catak, M. Taner Eskil</p></summary>
<p>

**Abstract:** Deep neural network (DNN) architectures are considered to be robust to random perturbations. Nevertheless, it was shown that they could be severely vulnerable to slight but carefully crafted perturbations of the input, which are termed as adversarial samples. In recent years, numerous studies have been conducted to increase the reliability of DNN models by distinguishing adversarial samples from regular inputs. In this work, we explore and assess the usage of 2 different groups of metrics in detecting adversarial samples: the ones which are based on the uncertainty estimation using Monte-Carlo Dropout Sampling and the ones which are based on closeness measures in the subspace of deep features extracted by the model. We also introduce a new feature for adversarial detection, and we show that the performances of all these metrics heavily depend on the strength of the attack being used.

</p>
</details>

<details><summary><b>Hardware Beyond Backpropagation: a Photonic Co-Processor for Direct Feedback Alignment</b>
<a href="https://arxiv.org/abs/2012.06373">arxiv:2012.06373</a>
&#x1F4C8; -1 <br>
<p>Julien Launay, Iacopo Poli, Kilian Müller, Gustave Pariente, Igor Carron, Laurent Daudet, Florent Krzakala, Sylvain Gigan</p></summary>
<p>

**Abstract:** The scaling hypothesis motivates the expansion of models past trillions of parameters as a path towards better performance. Recent significant developments, such as GPT-3, have been driven by this conjecture. However, as models scale-up, training them efficiently with backpropagation becomes difficult. Because model, pipeline, and data parallelism distribute parameters and gradients over compute nodes, communication is challenging to orchestrate: this is a bottleneck to further scaling. In this work, we argue that alternative training methods can mitigate these issues, and can inform the design of extreme-scale training hardware. Indeed, using a synaptically asymmetric method with a parallelizable backward pass, such as Direct Feedback Alignement, communication needs are drastically reduced. We present a photonic accelerator for Direct Feedback Alignment, able to compute random projections with trillions of parameters. We demonstrate our system on benchmark tasks, using both fully-connected and graph convolutional networks. Our hardware is the first architecture-agnostic photonic co-processor for training neural networks. This is a significant step towards building scalable hardware, able to go beyond backpropagation, and opening new avenues for deep learning.

</p>
</details>

<details><summary><b>Feature Selection Based on Sparse Neural Network Layer with Normalizing Constraints</b>
<a href="https://arxiv.org/abs/2012.06365">arxiv:2012.06365</a>
&#x1F4C8; -1 <br>
<p>Peter Bugata, Peter Drotar</p></summary>
<p>

**Abstract:** Feature selection is important step in machine learning since it has shown to improve prediction accuracy while depressing the curse of dimensionality of high dimensional data. The neural networks have experienced tremendous success in solving many nonlinear learning problems. Here, we propose new neural-network based feature selection approach that introduces two constrains, the satisfying of which leads to sparse FS layer. We have performed extensive experiments on synthetic and real world data to evaluate performance of the proposed FS. In experiments we focus on the high dimension, low sample size data since those represent the main challenge for feature selection. The results confirm that proposed Feature Selection Based on Sparse Neural Network Layer with Normalizing Constraints (SNEL-FS) is able to select the important features and yields superior performance compared to other conventional FS methods.

</p>
</details>

<details><summary><b>Beyond Occam's Razor in System Identification: Double-Descent when Modeling Dynamics</b>
<a href="https://arxiv.org/abs/2012.06341">arxiv:2012.06341</a>
&#x1F4C8; -1 <br>
<p>Antônio H. Ribeiro, Johannes N. Hendriks, Adrian G. Wills, Thomas B. Schön</p></summary>
<p>

**Abstract:** System identification aims to build models of dynamical systems from data. Traditionally, choosing the model requires the designer to balance between two goals of conflicting nature; the model must be rich enough to capture the system dynamics, but not so flexible that it learns spurious random effects from the dataset. It is typically observed that model validation performance follows a U-shaped curve as the model complexity increases. Recent developments in machine learning and statistics, however, have observed situations where a "double-descent" curve subsumes this U-shaped model-performance curve. With a second decrease in performance occurring beyond the point where the model has reached the capacity of interpolating - i.e., (near) perfectly fitting - the training data. To the best of our knowledge, however, such phenomena have not been studied within the context of the identification of dynamic systems. The present paper aims to answer the question: "Can such a phenomenon also be observed when estimating parameters of dynamic systems?" We show the answer is yes, verifying such behavior experimentally both for artificially generated and real-world datasets.

</p>
</details>

<details><summary><b>Self-Growing Spatial Graph Network for Context-Aware Pedestrian Trajectory Prediction</b>
<a href="https://arxiv.org/abs/2012.06320">arxiv:2012.06320</a>
&#x1F4C8; -1 <br>
<p>Sirin Haddad, Siew-Kei Lam</p></summary>
<p>

**Abstract:** Pedestrian trajectory prediction is an active research area with recent works undertaken to embed accurate models of pedestrians social interactions and their contextual compliance into dynamic spatial graphs. However, existing works rely on spatial assumptions about the scene and dynamics, which entails a significant challenge to adapt the graph structure in unknown environments for an online system. In addition, there is a lack of assessment approach for the relational modeling impact on prediction performance. To fill this gap, we propose Social Trajectory Recommender-Gated Graph Recurrent Neighborhood Network, (STR-GGRNN), which uses data-driven adaptive online neighborhood recommendation based on the contextual scene features and pedestrian visual cues. The neighborhood recommendation is achieved by online Nonnegative Matrix Factorization (NMF) to construct the graph adjacency matrices for predicting the pedestrians' trajectories. Experiments based on widely-used datasets show that our method outperforms the state-of-the-art. Our best performing model achieves 12 cm ADE and $\sim$15 cm FDE on ETH-UCY dataset. The proposed method takes only 0.49 seconds when sampling a total of 20K future trajectories per frame.

</p>
</details>

<details><summary><b>ADD: Augmented Disentanglement Distillation Framework for Improving Stock Trend Forecasting</b>
<a href="https://arxiv.org/abs/2012.06289">arxiv:2012.06289</a>
&#x1F4C8; -1 <br>
<p>Hongshun Tang, Lijun Wu, Weiqing Liu, Jiang Bian</p></summary>
<p>

**Abstract:** Stock trend forecasting has become a popular research direction that attracts widespread attention in the financial field. Though deep learning methods have achieved promising results, there are still many limitations, for example, how to extract clean features from the raw stock data. In this paper, we introduce an \emph{Augmented Disentanglement Distillation (ADD)} approach to remove interferential features from the noised raw data. Specifically, we present 1) a disentanglement structure to separate excess and market information from the stock data to avoid the two factors disturbing each other's own prediction. Besides, by applying 2) a dynamic self-distillation method over the disentanglement framework, other implicit interference factors can also be removed. Further, thanks to the decoder module in our framework, 3) a novel strategy is proposed to augment the training samples based on the different excess and market features to improve performance. We conduct experiments on the Chinese stock market data. Results show that our method significantly improves the stock trend forecasting performances, as well as the actual investment income through backtesting, which strongly demonstrates the effectiveness of our approach.

</p>
</details>

<details><summary><b>Analysis of Feature Representations for Anomalous Sound Detection</b>
<a href="https://arxiv.org/abs/2012.06282">arxiv:2012.06282</a>
&#x1F4C8; -1 <br>
<p>Robert Müller, Steffen Illium, Fabian Ritz, Kyrill Schmid</p></summary>
<p>

**Abstract:** In this work, we thoroughly evaluate the efficacy of pretrained neural networks as feature extractors for anomalous sound detection. In doing so, we leverage the knowledge that is contained in these neural networks to extract semantically rich features (representations) that serve as input to a Gaussian Mixture Model which is used as a density estimator to model normality. We compare feature extractors that were trained on data from various domains, namely: images, environmental sounds and music. Our approach is evaluated on recordings from factory machinery such as valves, pumps, sliders and fans. All of the evaluated representations outperform the autoencoder baseline with music based representations yielding the best performance in most cases. These results challenge the common assumption that closely matching the domain of the feature extractor and the downstream task results in better downstream task performance.

</p>
</details>

<details><summary><b>A Topic Coverage Approach to Evaluation of Topic Models</b>
<a href="https://arxiv.org/abs/2012.06274">arxiv:2012.06274</a>
&#x1F4C8; -1 <br>
<p>Damir Korenčić, Strahil Ristov, Jelena Repar, Jan Šnajder</p></summary>
<p>

**Abstract:** When topic models are used for discovery of topics in text collections, a question that arises naturally is how well the model-induced topics correspond to topics of interest to the analyst. We investigate an approach to topic model evaluation based on measuring topic coverage, and propose measures of coverage based on matching between model topics and reference topics. We demonstrate the benefits of the approach by evaluating, in a series of experiments, different types of topic models on two distinct text domains. The experiments include evaluation of model quality, analysis of coverage of distinct topic categories, and the relation between coverage and other topic model evaluation methods. The contributions of the paper include the measures of coverage and the recommendations for the use of topic models for topic discovery.

</p>
</details>

<details><summary><b>EarthNet2021: A novel large-scale dataset and challenge for forecasting localized climate impacts</b>
<a href="https://arxiv.org/abs/2012.06246">arxiv:2012.06246</a>
&#x1F4C8; -1 <br>
<p>Christian Requena-Mesa, Vitus Benson, Joachim Denzler, Jakob Runge, Markus Reichstein</p></summary>
<p>

**Abstract:** Climate change is global, yet its concrete impacts can strongly vary between different locations in the same region. Seasonal weather forecasts currently operate at the mesoscale (> 1 km). For more targeted mitigation and adaptation, modelling impacts to < 100 m is needed. Yet, the relationship between driving variables and Earth's surface at such local scales remains unresolved by current physical models. Large Earth observation datasets now enable us to create machine learning models capable of translating coarse weather information into high-resolution Earth surface forecasts. Here, we define high-resolution Earth surface forecasting as video prediction of satellite imagery conditional on mesoscale weather forecasts. Video prediction has been tackled with deep learning models. Developing such models requires analysis-ready datasets. We introduce EarthNet2021, a new, curated dataset containing target spatio-temporal Sentinel 2 satellite imagery at 20 m resolution, matched with high-resolution topography and mesoscale (1.28 km) weather variables. With over 32000 samples it is suitable for training deep neural networks. Comparing multiple Earth surface forecasts is not trivial. Hence, we define the EarthNetScore, a novel ranking criterion for models forecasting Earth surface reflectance. For model intercomparison we frame EarthNet2021 as a challenge with four tracks based on different test sets. These allow evaluation of model validity and robustness as well as model applicability to extreme events and the complete annual vegetation cycle. In addition to forecasting directly observable weather impacts through satellite-derived vegetation indices, capable Earth surface models will enable downstream applications such as crop yield prediction, forest health assessments, coastline management, or biodiversity monitoring. Find data, code, and how to participate at www.earthnet.tech .

</p>
</details>

<details><summary><b>Soft Compression for Lossless Image Coding</b>
<a href="https://arxiv.org/abs/2012.06240">arxiv:2012.06240</a>
&#x1F4C8; -1 <br>
<p>Gangtao Xin, Pingyi Fan</p></summary>
<p>

**Abstract:** Soft compression is a lossless image compression method, which is committed to eliminating coding redundancy and spatial redundancy at the same time by adopting locations and shapes of codebook to encode an image from the perspective of information theory and statistical distribution. In this paper, we propose a new concept, compressible indicator function with regard to image, which gives a threshold about the average number of bits required to represent a location and can be used for revealing the performance of soft compression. We investigate and analyze soft compression for binary image, gray image and multi-component image by using specific algorithms and compressible indicator value. It is expected that the bandwidth and storage space needed when transmitting and storing the same kind of images can be greatly reduced by applying soft compression.

</p>
</details>

<details><summary><b>Structured Policy Representation: Imposing Stability in arbitrarily conditioned dynamic systems</b>
<a href="https://arxiv.org/abs/2012.06224">arxiv:2012.06224</a>
&#x1F4C8; -1 <br>
<p>Julen Urain, Davide Tateo, Tianyu Ren, Jan Peters</p></summary>
<p>

**Abstract:** We present a new family of deep neural network-based dynamic systems. The presented dynamics are globally stable and can be conditioned with an arbitrary context state. We show how these dynamics can be used as structured robot policies. Global stability is one of the most important and straightforward inductive biases as it allows us to impose reasonable behaviors outside the region of the demonstrations.

</p>
</details>

<details><summary><b>Neural Dynamic Mode Decomposition for End-to-End Modeling of Nonlinear Dynamics</b>
<a href="https://arxiv.org/abs/2012.06191">arxiv:2012.06191</a>
&#x1F4C8; -1 <br>
<p>Tomoharu Iwata, Yoshinobu Kawahara</p></summary>
<p>

**Abstract:** Koopman spectral analysis has attracted attention for understanding nonlinear dynamical systems by which we can analyze nonlinear dynamics with a linear regime by lifting observations using a nonlinear function. For analysis, we need to find an appropriate lift function. Although several methods have been proposed for estimating a lift function based on neural networks, the existing methods train neural networks without spectral analysis. In this paper, we propose neural dynamic mode decomposition, in which neural networks are trained such that the forecast error is minimized when the dynamics is modeled based on spectral decomposition in the lifted space. With our proposed method, the forecast error is backpropagated through the neural networks and the spectral decomposition, enabling end-to-end learning of Koopman spectral analysis. When information is available on the frequencies or the growth rates of the dynamics, the proposed method can exploit it as regularizers for training. We also propose an extension of our approach when observations are influenced by exogenous control time-series. Our experiments demonstrate the effectiveness of our proposed method in terms of eigenvalue estimation and forecast performance.

</p>
</details>

<details><summary><b>Recent Theoretical Advances in Non-Convex Optimization</b>
<a href="https://arxiv.org/abs/2012.06188">arxiv:2012.06188</a>
&#x1F4C8; -1 <br>
<p>Marina Danilova, Pavel Dvurechensky, Alexander Gasnikov, Eduard Gorbunov, Sergey Guminov, Dmitry Kamzolov, Innokentiy Shibaev</p></summary>
<p>

**Abstract:** Motivated by recent increased interest in optimization algorithms for non-convex optimization in application to training deep neural networks and other optimization problems in data analysis, we give an overview of recent theoretical results on global performance guarantees of optimization algorithms for non-convex optimization. We start with classical arguments showing that general non-convex problems could not be solved efficiently in a reasonable time. Then we give a list of problems that can be solved efficiently to find the global minimizer by exploiting the structure of the problem as much as it is possible. Another way to deal with non-convexity is to relax the goal from finding the global minimum to finding a stationary point or a local minimum. For this setting, we first present known results for the convergence rates of deterministic first-order methods, which are then followed by a general theoretical analysis of optimal stochastic and randomized gradient schemes, and an overview of the stochastic first-order methods. After that, we discuss quite general classes of non-convex problems, such as minimization of $α$-weakly-quasi-convex functions and functions that satisfy Polyak--Lojasiewicz condition, which still allow obtaining theoretical convergence guarantees of first-order methods. Then we consider higher-order and zeroth-order/derivative-free methods and their convergence rates for non-convex optimization problems.

</p>
</details>

<details><summary><b>OpenHoldem: An Open Toolkit for Large-Scale Imperfect-Information Game Research</b>
<a href="https://arxiv.org/abs/2012.06168">arxiv:2012.06168</a>
&#x1F4C8; -1 <br>
<p>Kai Li, Hang Xu, Meng Zhang, Enmin Zhao, Zhe Wu, Junliang Xing, Kaiqi Huang</p></summary>
<p>

**Abstract:** Owning to the unremitting efforts by a few institutes, significant progress has recently been made in designing superhuman AIs in No-limit Texas Hold'em (NLTH), the primary testbed for large-scale imperfect-information game research. However, it remains challenging for new researchers to study this problem since there are no standard benchmarks for comparing with existing methods, which seriously hinders further developments in this research area. In this work, we present OpenHoldem, an integrated toolkit for large-scale imperfect-information game research using NLTH. OpenHoldem makes three main contributions to this research direction: 1) a standardized evaluation protocol for thoroughly evaluating different NLTH AIs, 2) three publicly available strong baselines for NLTH AI, and 3) an online testing platform with easy-to-use APIs for public NLTH AI evaluation. We have released OpenHoldem at http://holdem.ia.ac.cn/, hoping it facilitates further studies on the unsolved theoretical and computational issues in this area and cultivate crucial research problems like opponent modeling, large-scale equilibrium-finding, and human-computer interactive learning.

</p>
</details>

<details><summary><b>ParsiNLU: A Suite of Language Understanding Challenges for Persian</b>
<a href="https://arxiv.org/abs/2012.06154">arxiv:2012.06154</a>
&#x1F4C8; -1 <br>
<p>Daniel Khashabi, Arman Cohan, Siamak Shakeri, Pedram Hosseini, Pouya Pezeshkpour, Malihe Alikhani, Moin Aminnaseri, Marzieh Bitaab, Faeze Brahman, Sarik Ghazarian, Mozhdeh Gheini, Arman Kabiri, Rabeeh Karimi Mahabadi, Omid Memarrast, Ahmadreza Mosallanezhad, Erfan Noury, Shahab Raji, Mohammad Sadegh Rasooli, Sepideh Sadeghi, Erfan Sadeqi Azer, Niloofar Safi Samghabadi, Mahsa Shafaei, Saber Sheybani, Ali Tazarv, Yadollah Yaghoobzadeh</p></summary>
<p>

**Abstract:** Despite the progress made in recent years in addressing natural language understanding (NLU) challenges, the majority of this progress remains to be concentrated on resource-rich languages like English. This work focuses on Persian language, one of the widely spoken languages in the world, and yet there are few NLU datasets available for this rich language. The availability of high-quality evaluation datasets is a necessity for reliable assessment of the progress on different NLU tasks and domains. We introduce ParsiNLU, the first benchmark in Persian language that includes a range of high-level tasks -- Reading Comprehension, Textual Entailment, etc. These datasets are collected in a multitude of ways, often involving manual annotations by native speakers. This results in over 14.5$k$ new instances across 6 distinct NLU tasks. Besides, we present the first results on state-of-the-art monolingual and multi-lingual pre-trained language-models on this benchmark and compare them with human performance, which provides valuable insights into our ability to tackle natural language understanding challenges in Persian. We hope ParsiNLU fosters further research and advances in Persian language understanding.

</p>
</details>

<details><summary><b>Theory-guided hard constraint projection (HCP): a knowledge-based data-driven scientific machine learning method</b>
<a href="https://arxiv.org/abs/2012.06148">arxiv:2012.06148</a>
&#x1F4C8; -1 <br>
<p>Yuntian Chen, Dou Huang, Dongxiao Zhang, Junsheng Zeng, Nanzhe Wang, Haoran Zhang, Jinyue Yan</p></summary>
<p>

**Abstract:** Machine learning models have been successfully used in many scientific and engineering fields. However, it remains difficult for a model to simultaneously utilize domain knowledge and experimental observation data. The application of knowledge-based symbolic AI represented by an expert system is limited by the expressive ability of the model, and data-driven connectionism AI represented by neural networks is prone to produce predictions that violate physical mechanisms. In order to fully integrate domain knowledge with observations, and make full use of the prior information and the strong fitting ability of neural networks, this study proposes theory-guided hard constraint projection (HCP). This model converts physical constraints, such as governing equations, into a form that is easy to handle through discretization, and then implements hard constraint optimization through projection. Based on rigorous mathematical proofs, theory-guided HCP can ensure that model predictions strictly conform to physical mechanisms in the constraint patch. The performance of the theory-guided HCP is verified by experiments based on the heterogeneous subsurface flow problem. Due to the application of hard constraints, compared with fully connected neural networks and soft constraint models, such as theory-guided neural networks and physics-informed neural networks, theory-guided HCP requires fewer data, and achieves higher prediction accuracy and stronger robustness to noisy observations.

</p>
</details>

<details><summary><b>Exploiting Behavioral Consistence for Universal User Representation</b>
<a href="https://arxiv.org/abs/2012.06146">arxiv:2012.06146</a>
&#x1F4C8; -1 <br>
<p>Jie Gu, Feng Wang, Qinghui Sun, Zhiquan Ye, Xiaoxiao Xu, Jingmin Chen, Jun Zhang</p></summary>
<p>

**Abstract:** User modeling is critical for developing personalized services in industry. A common way for user modeling is to learn user representations that can be distinguished by their interests or preferences. In this work, we focus on developing universal user representation model. The obtained universal representations are expected to contain rich information, and be applicable to various downstream applications without further modifications (e.g., user preference prediction and user profiling). Accordingly, we can be free from the heavy work of training task-specific models for every downstream task as in previous works. In specific, we propose Self-supervised User Modeling Network (SUMN) to encode behavior data into the universal representation. It includes two key components. The first one is a new learning objective, which guides the model to fully identify and preserve valuable user information under a self-supervised learning framework. The other one is a multi-hop aggregation layer, which benefits the model capacity in aggregating diverse behaviors. Extensive experiments on benchmark datasets show that our approach can outperform state-of-the-art unsupervised representation methods, and even compete with supervised ones.

</p>
</details>

<details><summary><b>AdvantageNAS: Efficient Neural Architecture Search with Credit Assignment</b>
<a href="https://arxiv.org/abs/2012.06138">arxiv:2012.06138</a>
&#x1F4C8; -1 <br>
<p>Rei Sato, Jun Sakuma, Youhei Akimoto</p></summary>
<p>

**Abstract:** Neural architecture search (NAS) is an approach for automatically designing a neural network architecture without human effort or expert knowledge. However, the high computational cost of NAS limits its use in commercial applications. Two recent NAS paradigms, namely one-shot and sparse propagation, which reduce the time and space complexities, respectively, provide clues for solving this problem. In this paper, we propose a novel search strategy for one-shot and sparse propagation NAS, namely AdvantageNAS, which further reduces the time complexity of NAS by reducing the number of search iterations. AdvantageNAS is a gradient-based approach that improves the search efficiency by introducing credit assignment in gradient estimation for architecture updates. Experiments on the NAS-Bench-201 and PTB dataset show that AdvantageNAS discovers an architecture with higher performance under a limited time budget compared to existing sparse propagation NAS. To further reveal the reliabilities of AdvantageNAS, we investigate it theoretically and find that it monotonically improves the expected loss and thus converges.

</p>
</details>

<details><summary><b>Classifying Breast Histopathology Images with a Ductal Instance-Oriented Pipeline</b>
<a href="https://arxiv.org/abs/2012.06136">arxiv:2012.06136</a>
&#x1F4C8; -1 <br>
<p>Beibin Li, Ezgi Mercan, Sachin Mehta, Stevan Knezevich, Corey W. Arnold, Donald L. Weaver, Joann G. Elmore, Linda G. Shapiro</p></summary>
<p>

**Abstract:** In this study, we propose the Ductal Instance-Oriented Pipeline (DIOP) that contains a duct-level instance segmentation model, a tissue-level semantic segmentation model, and three-levels of features for diagnostic classification. Based on recent advancements in instance segmentation and the Mask R-CNN model, our duct-level segmenter tries to identify each ductal individual inside a microscopic image; then, it extracts tissue-level information from the identified ductal instances. Leveraging three levels of information obtained from these ductal instances and also the histopathology image, the proposed DIOP outperforms previous approaches (both feature-based and CNN-based) in all diagnostic tasks; for the four-way classification task, the DIOP achieves comparable performance to general pathologists in this unique dataset. The proposed DIOP only takes a few seconds to run in the inference time, which could be used interactively on most modern computers. More clinical explorations are needed to study the robustness and generalizability of this system in the future.

</p>
</details>

<details><summary><b>Reinforced Multi-Teacher Selection for Knowledge Distillation</b>
<a href="https://arxiv.org/abs/2012.06048">arxiv:2012.06048</a>
&#x1F4C8; -1 <br>
<p>Fei Yuan, Linjun Shou, Jian Pei, Wutao Lin, Ming Gong, Yan Fu, Daxin Jiang</p></summary>
<p>

**Abstract:** In natural language processing (NLP) tasks, slow inference speed and huge footprints in GPU usage remain the bottleneck of applying pre-trained deep models in production. As a popular method for model compression, knowledge distillation transfers knowledge from one or multiple large (teacher) models to a small (student) model. When multiple teacher models are available in distillation, the state-of-the-art methods assign a fixed weight to a teacher model in the whole distillation. Furthermore, most of the existing methods allocate an equal weight to every teacher model. In this paper, we observe that, due to the complexity of training examples and the differences in student model capability, learning differentially from teacher models can lead to better performance of student models distilled. We systematically develop a reinforced method to dynamically assign weights to teacher models for different training instances and optimize the performance of student model. Our extensive experimental results on several NLP tasks clearly verify the feasibility and effectiveness of our approach.

</p>
</details>

<details><summary><b>Gap Filling of Biophysical Parameter Time Series with Multi-Output Gaussian Processes</b>
<a href="https://arxiv.org/abs/2012.05912">arxiv:2012.05912</a>
&#x1F4C8; -1 <br>
<p>Anna Mateo-Sanchis, Jordi Munoz-Mari, Manuel Campos-Taberner, Javier Garcia-Haro, Gustau Camps-Valls</p></summary>
<p>

**Abstract:** In this work we evaluate multi-output (MO) Gaussian Process (GP) models based on the linear model of coregionalization (LMC) for estimation of biophysical parameter variables under a gap filling setup. In particular, we focus on LAI and fAPAR over rice areas. We show how this problem cannot be solved with standard single-output (SO) GP models, and how the proposed MO-GP models are able to successfully predict these variables even in high missing data regimes, by implicitly performing an across-domain information transfer.

</p>
</details>


[Next Page](2020/2020-12/2020-12-10.md)
