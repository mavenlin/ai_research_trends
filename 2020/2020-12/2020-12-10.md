
## Summary for 2020-12-10, created on 2021-01-10


<details><summary><b>Argument Mining Driven Analysis of Peer-Reviews</b>
<a href="https://arxiv.org/abs/2012.07743">arxiv:2012.07743</a>
&#x1F4C8; -1 <br>
<p>Michael Fromm, Evgeniy Faerman, Max Berrendorf, Siddharth Bhargava, Ruoxia Qi, Yao Zhang, Lukas Dennert, Sophia Selle, Yang Mao, Thomas Seidl</p></summary>
<p>

**Abstract:** Peer reviewing is a central process in modern research and essential for ensuring high quality and reliability of published work. At the same time, it is a time-consuming process and increasing interest in emerging fields often results in a high review workload, especially for senior researchers in this area. How to cope with this problem is an open question and it is vividly discussed across all major conferences. In this work, we propose an Argument Mining based approach for the assistance of editors, meta-reviewers, and reviewers. We demonstrate that the decision process in the field of scientific publications is driven by arguments and automatic argument identification is helpful in various use-cases. One of our findings is that arguments used in the peer-review process differ from arguments in other domains making the transfer of pre-trained models difficult. Therefore, we provide the community with a new peer-review dataset from different computer science conferences with annotated arguments. In our extensive empirical evaluation, we show that Argument Mining can be used to efficiently extract the most relevant parts from reviews, which are paramount for the publication decision. The process remains interpretable since the extracted arguments can be highlighted in a review without detaching them from their context.

</p>
</details>

<details><summary><b>Deep Neural Networks for COVID-19 Detection and Diagnosis using Images and Acoustic-based Techniques: A Recent Review</b>
<a href="https://arxiv.org/abs/2012.07655">arxiv:2012.07655</a>
&#x1F4C8; -1 <br>
<p>Walid Hariri, Ali Narin</p></summary>
<p>

**Abstract:** The new coronavirus disease (COVID-19) has been declared a pandemic since March 2020 by the World Health Organization. It consists of an emerging viral infection with respiratory tropism that could develop atypical pneumonia. Experts emphasize the importance of early detection of those who have the COVID-19 virus. In this way, patients will be isolated from other people and the spread of the virus can be prevented. For this reason, it has become an area of interest to develop early diagnosis and detection methods to ensure a rapid treatment process and prevent the virus from spreading. Since the standard testing system is time-consuming and not available for everyone, alternative early-screening techniques have become an urgent need. In this study, the approaches used in the detection of COVID-19 based on deep learning (DL) algorithms, which have been popular in recent years, have been comprehensively discussed. The advantages and disadvantages of different approaches used in literature are examined in detail. The Computed Tomography of the chest and X-ray images give a rich representation of the patient's lung that is less time-consuming and allows an efficient viral pneumonia detection using the DL algorithms. The first step is the pre-processing of these images to remove noise. Next, deep features are extracted using multiple types of deep models (pre-trained models, generative models, generic neural networks, etc). Finally, the classification is performed using the obtained features to decide whether the patient is infected by coronavirus or it is another lung disease. In this study, we also give a brief review of the latest applications of cough analysis to early screen the COVID-19, and human mobility estimation to limit its spread.

</p>
</details>

<details><summary><b>A Practical Approach towards Causality Mining in Clinical Text using Active Transfer Learning</b>
<a href="https://arxiv.org/abs/2012.07563">arxiv:2012.07563</a>
&#x1F4C8; -1 <br>
<p>Musarrat Hussain, Fahad Ahmed Satti, Jamil Hussain, Taqdir Ali, Syed Imran Ali, Hafiz Syed Muhammad Bilal, Gwang Hoon Park, Sungyoung Lee</p></summary>
<p>

**Abstract:** Objective: Causality mining is an active research area, which requires the application of state-of-the-art natural language processing techniques. In the healthcare domain, medical experts create clinical text to overcome the limitation of well-defined and schema driven information systems. The objective of this research work is to create a framework, which can convert clinical text into causal knowledge. Methods: A practical approach based on term expansion, phrase generation, BERT based phrase embedding and semantic matching, semantic enrichment, expert verification, and model evolution has been used to construct a comprehensive causality mining framework. This active transfer learning based framework along with its supplementary services, is able to extract and enrich, causal relationships and their corresponding entities from clinical text. Results: The multi-model transfer learning technique when applied over multiple iterations, gains performance improvements in terms of its accuracy and recall while keeping the precision constant. We also present a comparative analysis of the presented techniques with their common alternatives, which demonstrate the correctness of our approach and its ability to capture most causal relationships. Conclusion: The presented framework has provided cutting-edge results in the healthcare domain. However, the framework can be tweaked to provide causality detection in other domains, as well. Significance: The presented framework is generic enough to be utilized in any domain, healthcare services can gain massive benefits due to the voluminous and various nature of its data. This causal knowledge extraction framework can be used to summarize clinical text, create personas, discover medical knowledge, and provide evidence to clinical decision making.

</p>
</details>

<details><summary><b>Leveraging Transfer Learning for Reliable Intelligence Identification on Vietnamese SNSs (ReINTEL)</b>
<a href="https://arxiv.org/abs/2012.07557">arxiv:2012.07557</a>
&#x1F4C8; -1 <br>
<p>Trung-Hieu Tran, Long Phan, Truong-Son Nguyen, Tien-Huy Nguyen</p></summary>
<p>

**Abstract:** This paper proposed several transformer-based approaches for Reliable Intelligence Identification on Vietnamese social network sites at VLSP 2020 evaluation campaign. We exploit both of monolingual and multilingual pre-trained models. Besides, we utilize the ensemble method to improve the robustness of different approaches. Our team achieved a score of 0.9378 at ROC-AUC metric in the private test set which is competitive to other participants.

</p>
</details>

<details><summary><b>Privacy-preserving medical image analysis</b>
<a href="https://arxiv.org/abs/2012.06354">arxiv:2012.06354</a>
&#x1F4C8; -1 <br>
<p>Alexander Ziller, Jonathan Passerat-Palmbach, Théo Ryffel, Dmitrii Usynin, Andrew Trask, Ionésio Da Lima Costa Junior, Jason Mancuso, Marcus Makowski, Daniel Rueckert, Rickmer Braren, Georgios Kaissis</p></summary>
<p>

**Abstract:** The utilisation of artificial intelligence in medicine and healthcare has led to successful clinical applications in several domains. The conflict between data usage and privacy protection requirements in such systems must be resolved for optimal results as well as ethical and legal compliance. This calls for innovative solutions such as privacy-preserving machine learning (PPML). We present PriMIA (Privacy-preserving Medical Image Analysis), a software framework designed for PPML in medical imaging. In a real-life case study we demonstrate significantly better classification performance of a securely aggregated federated learning model compared to human experts on unseen datasets. Furthermore, we show an inference-as-a-service scenario for end-to-end encrypted diagnosis, where neither the data nor the model are revealed. Lastly, we empirically evaluate the framework's security against a gradient-based model inversion attack and demonstrate that no usable information can be recovered from the model.

</p>
</details>

<details><summary><b>An Empirical Review of Adversarial Defenses</b>
<a href="https://arxiv.org/abs/2012.06332">arxiv:2012.06332</a>
&#x1F4C8; -1 <br>
<p>Ayush Goel</p></summary>
<p>

**Abstract:** From face recognition systems installed in phones to self-driving cars, the field of AI is witnessing rapid transformations and is being integrated into our everyday lives at an incredible pace. Any major failure in these system's predictions could be devastating, leaking sensitive information or even costing lives (as in the case of self-driving cars). However, deep neural networks, which form the basis of such systems, are highly susceptible to a specific type of attack, called adversarial attacks. A hacker can, even with bare minimum computation, generate adversarial examples (images or data points that belong to another class, but consistently fool the model to get misclassified as genuine) and crumble the basis of such algorithms. In this paper, we compile and test numerous approaches to defend against such adversarial attacks. Out of the ones explored, we found two effective techniques, namely Dropout and Denoising Autoencoders, and show their success in preventing such attacks from fooling the model. We demonstrate that these techniques are also resistant to both higher noise levels as well as different kinds of adversarial attacks (although not tested against all). We also develop a framework for deciding the suitable defense technique to use against attacks, based on the nature of the application and resource constraints of the Deep Neural Network.

</p>
</details>

<details><summary><b>How to Train PointGoal Navigation Agents on a (Sample and Compute) Budget</b>
<a href="https://arxiv.org/abs/2012.06117">arxiv:2012.06117</a>
&#x1F4C8; -1 <br>
<p>Erik Wijmans, Irfan Essa, Dhruv Batra</p></summary>
<p>

**Abstract:** PointGoal navigation has seen significant recent interest and progress, spurred on by the Habitat platform and associated challenge. In this paper, we study PointGoal navigation under both a sample budget (75 million frames) and a compute budget (1 GPU for 1 day). We conduct an extensive set of experiments, cumulatively totaling over 50,000 GPU-hours, that let us identify and discuss a number of ostensibly minor but significant design choices -- the advantage estimation procedure (a key component in training), visual encoder architecture, and a seemingly minor hyper-parameter change. Overall, these design choices to lead considerable and consistent improvements over the baselines present in Savva et al. Under a sample budget, performance for RGB-D agents improves 8 SPL on Gibson (14% relative improvement) and 20 SPL on Matterport3D (38% relative improvement). Under a compute budget, performance for RGB-D agents improves by 19 SPL on Gibson (32% relative improvement) and 35 SPL on Matterport3D (220% relative improvement). We hope our findings and recommendations will make serve to make the community's experiments more efficient.

</p>
</details>

<details><summary><b>I-GCN: Robust Graph Convolutional Network via Influence Mechanism</b>
<a href="https://arxiv.org/abs/2012.06110">arxiv:2012.06110</a>
&#x1F4C8; -1 <br>
<p>Haoxi Zhan, Xiaobing Pei</p></summary>
<p>

**Abstract:** Deep learning models for graphs, especially Graph Convolutional Networks (GCNs), have achieved remarkable performance in the task of semi-supervised node classification. However, recent studies show that GCNs suffer from adversarial perturbations. Such vulnerability to adversarial attacks significantly decreases the stability of GCNs when being applied to security-critical applications. Defense methods such as preprocessing, attention mechanism and adversarial training have been discussed by various studies. While being able to achieve desirable performance when the perturbation rates are low, such methods are still vulnerable to high perturbation rates. Meanwhile, some defending algorithms perform poorly when the node features are not visible. Therefore, in this paper, we propose a novel mechanism called influence mechanism, which is able to enhance the robustness of the GCNs significantly. The influence mechanism divides the effect of each node into two parts: introverted influence which tries to maintain its own features and extroverted influence which exerts influences on other nodes. Utilizing the influence mechanism, we propose the Influence GCN (I-GCN) model. Extensive experiments show that our proposed model is able to achieve higher accuracy rates than state-of-the-art methods when defending against non-targeted attacks.

</p>
</details>

<details><summary><b>Smooth Bandit Optimization: Generalization to Hölder Space</b>
<a href="https://arxiv.org/abs/2012.06076">arxiv:2012.06076</a>
&#x1F4C8; -1 <br>
<p>Yusha Liu, Yining Wang, Aarti Singh</p></summary>
<p>

**Abstract:** We consider bandit optimization of a smooth reward function, where the goal is cumulative regret minimization. This problem has been studied for $α$-Hölder continuous (including Lipschitz) functions with $0<α\leq 1$. Our main result is in generalization of the reward function to Hölder space with exponent $α>1$ to bridge the gap between Lipschitz bandits and infinitely-differentiable models such as linear bandits. For Hölder continuous functions, approaches based on random sampling in bins of a discretized domain suffices as optimal. In contrast, we propose a class of two-layer algorithms that deploy misspecified linear/polynomial bandit algorithms in bins. We demonstrate that the proposed algorithm can exploit higher-order smoothness of the function by deriving a regret upper bound of $\tilde{O}(T^\frac{d+α}{d+2α})$ for when $α>1$, which matches existing lower bound. We also study adaptation to unknown function smoothness over a continuous scale of Hölder spaces indexed by $α$, with a bandit model selection approach applied with our proposed two-layer algorithms. We show that it achieves regret rate that matches the existing lower bound for adaptation within the $α\leq 1$ subset.

</p>
</details>

<details><summary><b>An algorithm for onset detection of linguistic segments in continuous electroencephalogram signals</b>
<a href="https://arxiv.org/abs/2012.06075">arxiv:2012.06075</a>
&#x1F4C8; -1 <br>
<p>Tonatiuh Hernández-Del-Toro, Carlos A. Reyes-García</p></summary>
<p>

**Abstract:** A Brain Computer Interface based on imagined words can decode the word a subject is thinking on through brain signals to control an external device. In order to build a fully asynchronous Brain Computer Interface based on imagined words in electroencephalogram signals as source, we need to solve the problem of detecting the onset of the imagined words. Although there has been some research in this field, the problem has not been fully solved. In this paper we present an approach to solve this problem by using values from statistics, information theory and chaos theory as features to correctly identify the onset of imagined words in a continuous signal. On detecting the onsets of imagined words, the highest True Positive Rate achieved by our approach was obtained using features based on the generalized Hurst exponent, this True Positive Rate was 0.69 and 0.77 with a timing error tolerance region of 3 and 4 seconds respectively.

</p>
</details>

<details><summary><b>Adaptive Submodular Meta-Learning</b>
<a href="https://arxiv.org/abs/2012.06070">arxiv:2012.06070</a>
&#x1F4C8; -1 <br>
<p>Shaojie Tang, Jing Yuan</p></summary>
<p>

**Abstract:** Meta-Learning has gained increasing attention in the machine learning and artificial intelligence communities. In this paper, we introduce and study an adaptive submodular meta-learning problem. The input of our problem is a set of items, where each item has a random state which is initially unknown. The only way to observe an item's state is to select that item. Our objective is to adaptively select a group of items that achieve the best performance over a set of tasks, where each task is represented as an adaptive monotone and submodular function that maps sets of items and their states to a real number. To reduce the computational cost while maintaining a personalized solution for each future task, we first select a initial solution set based on previously observed tasks, then adaptively add the remaining items to the initial set when a new task arrives. As compared to the solution where a brand new solution is computed for each new task, our meta-learning based approach leads to lower computational overhead at test time since the initial solution set is pre-computed in the training stage. To solve this problem, we propose a two-phase greedy policy and show that it achieves a $\frac{e-1}{2e-1}$ approximation ratio.

</p>
</details>

<details><summary><b>Deep Learning Approach for Matrix Completion Using Manifold Learning</b>
<a href="https://arxiv.org/abs/2012.06063">arxiv:2012.06063</a>
&#x1F4C8; -1 <br>
<p>Saeid Mehrdad, Mohammad Hossein Kahaei</p></summary>
<p>

**Abstract:** Matrix completion has received vast amount of attention and research due to its wide applications in various study fields. Existing methods of matrix completion consider only nonlinear (or linear) relations among entries in a data matrix and ignore linear (or nonlinear) relationships latent. This paper introduces a new latent variables model for data matrix which is a combination of linear and nonlinear models and designs a novel deep-neural-network-based matrix completion algorithm to address both linear and nonlinear relations among entries of data matrix. The proposed method consists of two branches. The first branch learns the latent representations of columns and reconstructs the columns of the partially observed matrix through a series of hidden neural network layers. The second branch does the same for the rows. In addition, based on multi-task learning principles, we enforce these two branches work together and introduce a new regularization technique to reduce over-fitting. More specifically, the missing entries of data are recovered as a main task and manifold learning is performed as an auxiliary task. The auxiliary task constrains the weights of the network so it can be considered as a regularizer, improving the main task and reducing over-fitting. Experimental results obtained on the synthetic data and several real-world data verify the effectiveness of the proposed method compared with state-of-the-art matrix completion methods.

</p>
</details>

<details><summary><b>Spatio-attentive Graphs for Human-Object Interaction Detection</b>
<a href="https://arxiv.org/abs/2012.06060">arxiv:2012.06060</a>
&#x1F4C8; -1 <br>
<p>Frederic Z. Zhang, Dylan Campbell, Stephen Gould</p></summary>
<p>

**Abstract:** We address the problem of detecting human--object interactions in images using graphical neural networks. Our network constructs a bipartite graph of nodes representing detected humans and objects, wherein messages passed between the nodes encode relative spatial and appearance information. Unlike existing approaches that separate appearance and spatial features, our method fuses these two cues within a single graphical model allowing information conditioned on both modalities to influence the prediction of interactions with neighboring nodes. Through extensive experimentation we demonstrate the advantages of fusing relative spatial information with appearance features in the computation of adjacency structure, message passing and the ultimate refined graph features. On the popular HICO-DET benchmark dataset, our model outperforms state-of-the-art with an mAP of 27.18, a 10% relative improvement.

</p>
</details>

<details><summary><b>Next Wave Artificial Intelligence: Robust, Explainable, Adaptable, Ethical, and Accountable</b>
<a href="https://arxiv.org/abs/2012.06058">arxiv:2012.06058</a>
&#x1F4C8; -1 <br>
<p>Odest Chadwicke Jenkins, Daniel Lopresti, Melanie Mitchell</p></summary>
<p>

**Abstract:** The history of AI has included several "waves" of ideas. The first wave, from the mid-1950s to the 1980s, focused on logic and symbolic hand-encoded representations of knowledge, the foundations of so-called "expert systems". The second wave, starting in the 1990s, focused on statistics and machine learning, in which, instead of hand-programming rules for behavior, programmers constructed "statistical learning algorithms" that could be trained on large datasets. In the most recent wave research in AI has largely focused on deep (i.e., many-layered) neural networks, which are loosely inspired by the brain and trained by "deep learning" methods. However, while deep neural networks have led to many successes and new capabilities in computer vision, speech recognition, language processing, game-playing, and robotics, their potential for broad application remains limited by several factors.
  A concerning limitation is that even the most successful of today's AI systems suffer from brittleness-they can fail in unexpected ways when faced with situations that differ sufficiently from ones they have been trained on. This lack of robustness also appears in the vulnerability of AI systems to adversarial attacks, in which an adversary can subtly manipulate data in a way to guarantee a specific wrong answer or action from an AI system. AI systems also can absorb biases-based on gender, race, or other factors-from their training data and further magnify these biases in their subsequent decision-making. Taken together, these various limitations have prevented AI systems such as automatic medical diagnosis or autonomous vehicles from being sufficiently trustworthy for wide deployment. The massive proliferation of AI across society will require radically new ideas to yield technology that will not sacrifice our productivity, our quality of life, or our values.

</p>
</details>

<details><summary><b>Interdisciplinary Approaches to Understanding Artificial Intelligence's Impact on Society</b>
<a href="https://arxiv.org/abs/2012.06057">arxiv:2012.06057</a>
&#x1F4C8; -1 <br>
<p>Suresh Venkatasubramanian, Nadya Bliss, Helen Nissenbaum, Melanie Moses</p></summary>
<p>

**Abstract:** Innovations in AI have focused primarily on the questions of "what" and "how"-algorithms for finding patterns in web searches, for instance-without adequate attention to the possible harms (such as privacy, bias, or manipulation) and without adequate consideration of the societal context in which these systems operate. In part, this is driven by incentives and forces in the tech industry, where a more product-driven focus tends to drown out broader reflective concerns about potential harms and misframings. But this focus on what and how is largely a reflection of the engineering and mathematics-focused training in computer science, which emphasizes the building of tools and development of computational concepts.
  As a result of this tight technical focus, and the rapid, worldwide explosion in its use, AI has come with a storm of unanticipated socio-technical problems, ranging from algorithms that act in racially or gender-biased ways, get caught in feedback loops that perpetuate inequalities, or enable unprecedented behavioral monitoring surveillance that challenges the fundamental values of free, democratic societies.
  Given that AI is no longer solely the domain of technologists but rather of society as a whole, we need tighter coupling of computer science and those disciplines that study society and societal values.

</p>
</details>

<details><summary><b>Analyzing the Performance of Smart Industry 4.0 Applications on Cloud Computing Systems</b>
<a href="https://arxiv.org/abs/2012.06054">arxiv:2012.06054</a>
&#x1F4C8; -1 <br>
<p>Razin Farhan Hussain, Alireza Pakravan, Mohsen Amini Salehi</p></summary>
<p>

**Abstract:** Cloud-based Deep Neural Network (DNN) applications that make latency-sensitive inference are becoming an indispensable part of Industry 4.0. Due to the multi-tenancy and resource heterogeneity, both inherent to the cloud computing environments, the inference time of DNN-based applications are stochastic. Such stochasticity, if not captured, can potentially lead to low Quality of Service (QoS) or even a disaster in critical sectors, such as Oil and Gas industry. To make Industry 4.0 robust, solution architects and researchers need to understand the behavior of DNN-based applications and capture the stochasticity exists in their inference times. Accordingly, in this study, we provide a descriptive analysis of the inference time from two perspectives. First, we perform an application-centric analysis and statistically model the execution time of four categorically different DNN applications on both Amazon and Chameleon clouds. Second, we take a resource-centric approach and analyze a rate-based metric in form of Million Instruction Per Second (MIPS) for heterogeneous machines in the cloud. This non-parametric modeling, achieved via Jackknife and Bootstrap re-sampling methods, provides the confidence interval of MIPS for heterogeneous cloud machines. The findings of this research can be helpful for researchers and cloud solution architects to develop solutions that are robust against the stochastic nature of the inference time of DNN applications in the cloud and can offer a higher QoS to their users and avoid unintended outcomes.

</p>
</details>

<details><summary><b>The Rise of AI-Driven Simulators: Building a New Crystal Ball</b>
<a href="https://arxiv.org/abs/2012.06049">arxiv:2012.06049</a>
&#x1F4C8; -1 <br>
<p>Ian Foster, David Parkes, Stephan Zheng</p></summary>
<p>

**Abstract:** The use of computational simulation is by now so pervasive in society that it is no exaggeration to say that continued U.S. and international prosperity, security, and health depend in part on continued improvements in simulation capabilities. What if we could predict weather two weeks out, guide the design of new drugs for new viral diseases, or manage new manufacturing processes that cut production costs and times by an order of magnitude? What if we could predict collective human behavior, for example, response to an evacuation request during a natural disaster, or labor response to fiscal stimulus? (See also the companion CCC Quad Paper on Pandemic Informatics, which discusses features that would be essential to solving large-scale problems like preparation for, and response to, the inevitable next pandemic.)
  The past decade has brought remarkable advances in complementary areas: in sensors, which can now capture enormous amounts of data about the world, and in AI methods capable of learning to extract predictive patterns from those data. These advances may lead to a new era in computational simulation, in which sensors of many kinds are used to produce vast quantities of data, AI methods identify patterns in those data, and new AI-driven simulators combine machine-learned and mathematical rules to make accurate and actionable predictions. At the same time, there are new challenges -- computers in some important regards are no longer getting faster, and in some areas we are reaching the limits of mathematical understanding, or at least of our ability to translate mathematical understanding into efficient simulation. In this paper, we lay out some themes that we envision forming part of a cohesive, multi-disciplinary, and application-inspired research agenda on AI-driven simulators.

</p>
</details>

<details><summary><b>Interactive Weak Supervision: Learning Useful Heuristics for Data Labeling</b>
<a href="https://arxiv.org/abs/2012.06046">arxiv:2012.06046</a>
&#x1F4C8; -1 <br>
<p>Benedikt Boecking, Willie Neiswanger, Eric Xing, Artur Dubrawski</p></summary>
<p>

**Abstract:** Obtaining large annotated datasets is critical for training successful machine learning models and it is often a bottleneck in practice. Weak supervision offers a promising alternative for producing labeled datasets without ground truth annotations by generating probabilistic labels using multiple noisy heuristics. This process can scale to large datasets and has demonstrated state of the art performance in diverse domains such as healthcare and e-commerce. One practical issue with learning from user-generated heuristics is that their creation requires creativity, foresight, and domain expertise from those who hand-craft them, a process which can be tedious and subjective. We develop the first framework for interactive weak supervision in which a method proposes heuristics and learns from user feedback given on each proposed heuristic. Our experiments demonstrate that only a small number of feedback iterations are needed to train models that achieve highly competitive test set performance without access to ground truth training labels. We conduct user studies, which show that users are able to effectively provide feedback on heuristics and that test set results track the performance of simulated oracles.

</p>
</details>

<details><summary><b>Artificial Intelligence & Cooperation</b>
<a href="https://arxiv.org/abs/2012.06034">arxiv:2012.06034</a>
&#x1F4C8; -1 <br>
<p>Elisa Bertino, Finale Doshi-Velez, Maria Gini, Daniel Lopresti, David Parkes</p></summary>
<p>

**Abstract:** The rise of Artificial Intelligence (AI) will bring with it an ever-increasing willingness to cede decision-making to machines. But rather than just giving machines the power to make decisions that affect us, we need ways to work cooperatively with AI systems. There is a vital need for research in "AI and Cooperation" that seeks to understand the ways in which systems of AIs and systems of AIs with people can engender cooperative behavior. Trust in AI is also key: trust that is intrinsic and trust that can only be earned over time. Here we use the term "AI" in its broadest sense, as employed by the recent 20-Year Community Roadmap for AI Research (Gil and Selman, 2019), including but certainly not limited to, recent advances in deep learning.
  With success, cooperation between humans and AIs can build society just as human-human cooperation has. Whether coming from an intrinsic willingness to be helpful, or driven through self-interest, human societies have grown strong and the human species has found success through cooperation. We cooperate "in the small" -- as family units, with neighbors, with co-workers, with strangers -- and "in the large" as a global community that seeks cooperative outcomes around questions of commerce, climate change, and disarmament. Cooperation has evolved in nature also, in cells and among animals. While many cases involving cooperation between humans and AIs will be asymmetric, with the human ultimately in control, AI systems are growing so complex that, even today, it is impossible for the human to fully comprehend their reasoning, recommendations, and actions when functioning simply as passive observers.

</p>
</details>

<details><summary><b>Reinforcement Learning Agents for Ubisoft's Roller Champions</b>
<a href="https://arxiv.org/abs/2012.06031">arxiv:2012.06031</a>
&#x1F4C8; -1 <br>
<p>Nancy Iskander, Aurelien Simoni, Eloi Alonso, Maxim Peter</p></summary>
<p>

**Abstract:** In recent years, Reinforcement Learning (RL) has seen increasing popularity in research and popular culture. However, skepticism still surrounds the practicality of RL in modern video game development. In this paper, we demonstrate by example that RL can be a great tool for Artificial Intelligence (AI) design in modern, non-trivial video games. We present our RL system for Ubisoft's Roller Champions, a 3v3 Competitive Multiplayer Sports Game played on an oval-shaped skating arena. Our system is designed to keep up with agile, fast-paced development, taking 1--4 days to train a new model following gameplay changes. The AIs are adapted for various game modes, including a 2v2 mode, a Training with Bots mode, in addition to the Classic game mode where they replace players who have disconnected. We observe that the AIs develop sophisticated co-ordinated strategies, and can aid in balancing the game as an added bonus. Please see the accompanying video at https://vimeo.com/466780171 (password: rollerRWRL2020) for examples.

</p>
</details>

<details><summary><b>Comparison of Update and Genetic Training Algorithms in a Memristor Crossbar Perceptron</b>
<a href="https://arxiv.org/abs/2012.06027">arxiv:2012.06027</a>
&#x1F4C8; -1 <br>
<p>Kyle N. Edwards, Xiao Shen</p></summary>
<p>

**Abstract:** Memristor-based computer architectures are becoming more attractive as a possible choice of hardware for the implementation of neural networks. However, at present, memristor technologies are susceptible to a variety of failure modes, a serious concern in any application where regular access to the hardware may not be expected or even possible. In this study, we investigate whether certain training algorithms may be more resilient to particular hardware failure modes, and therefore more suitable for use in those applications. We implement two training algorithms -- a local update scheme and a genetic algorithm -- in a simulated memristor crossbar, and compare their ability to train for a simple image classification task as an increasing number of memristors fail to adjust their conductance. We demonstrate that there is a clear distinction between the two algorithms in several measures of the rate of failure to train.

</p>
</details>

<details><summary><b>Exploring Deep Neural Networks and Transfer Learning for Analyzing Emotions in Tweets</b>
<a href="https://arxiv.org/abs/2012.06025">arxiv:2012.06025</a>
&#x1F4C8; -1 <br>
<p>Yasas Senarath, Uthayasanker Thayasivam</p></summary>
<p>

**Abstract:** In this paper, we present an experiment on using deep learning and transfer learning techniques for emotion analysis in tweets and suggest a method to interpret our deep learning models. The proposed approach for emotion analysis combines a Long Short Term Memory (LSTM) network with a Convolutional Neural Network (CNN). Then we extend this approach for emotion intensity prediction using transfer learning technique. Furthermore, we propose a technique to visualize the importance of each word in a tweet to get a better understanding of the model. Experimentally, we show in our analysis that the proposed models outperform the state-of-the-art in emotion classification while maintaining competitive results in predicting emotion intensity.

</p>
</details>

<details><summary><b>Robustness and Transferability of Universal Attacks on Compressed Models</b>
<a href="https://arxiv.org/abs/2012.06024">arxiv:2012.06024</a>
&#x1F4C8; -1 <br>
<p>Alberto G. Matachana, Kenneth T. Co, Luis Muñoz-González, David Martinez, Emil C. Lupu</p></summary>
<p>

**Abstract:** Neural network compression methods like pruning and quantization are very effective at efficiently deploying Deep Neural Networks (DNNs) on edge devices. However, DNNs remain vulnerable to adversarial examples-inconspicuous inputs that are specifically designed to fool these models. In particular, Universal Adversarial Perturbations (UAPs), are a powerful class of adversarial attacks which create adversarial perturbations that can generalize across a large set of inputs. In this work, we analyze the effect of various compression techniques to UAP attacks, including different forms of pruning and quantization. We test the robustness of compressed models to white-box and transfer attacks, comparing them with their uncompressed counterparts on CIFAR-10 and SVHN datasets. Our evaluations reveal clear differences between pruning methods, including Soft Filter and Post-training Pruning. We observe that UAP transfer attacks between pruned and full models are limited, suggesting that the systemic vulnerabilities across these models are different. This finding has practical implications as using different compression techniques can blunt the effectiveness of black-box transfer attacks. We show that, in some scenarios, quantization can produce gradient-masking, giving a false sense of security. Finally, our results suggest that conclusions about the robustness of compressed models to UAP attacks is application dependent, observing different phenomena in the two datasets used in our experiments.

</p>
</details>

<details><summary><b>Cost-to-Go Function Generating Networks for High Dimensional Motion Planning</b>
<a href="https://arxiv.org/abs/2012.06023">arxiv:2012.06023</a>
&#x1F4C8; -1 <br>
<p>Jinwook Huh, Volkan Isler, Daniel D. Lee</p></summary>
<p>

**Abstract:** This paper presents c2g-HOF networks which learn to generate cost-to-go functions for manipulator motion planning. The c2g-HOF architecture consists of a cost-to-go function over the configuration space represented as a neural network (c2g-network) as well as a Higher Order Function (HOF) network which outputs the weights of the c2g-network for a given input workspace. Both networks are trained end-to-end in a supervised fashion using costs computed from traditional motion planners. Once trained, c2g-HOF can generate a smooth and continuous cost-to-go function directly from workspace sensor inputs (represented as a point cloud in 3D or an image in 2D). At inference time, the weights of the c2g-network are computed very efficiently and near-optimal trajectories are generated by simply following the gradient of the cost-to-go function. We compare c2g-HOF with traditional planning algorithms for various robots and planning scenarios. The experimental results indicate that planning with c2g-HOF is significantly faster than other motion planning algorithms, resulting in orders of magnitude improvement when including collision checking. Furthermore, despite being trained from sparsely sampled trajectories in configuration space, c2g-HOF generalizes to generate smoother, and often lower cost, trajectories. We demonstrate cost-to-go based planning on a 7 DoF manipulator arm where motion planning in a complex workspace requires only 0.13 seconds for the entire trajectory.

</p>
</details>

<details><summary><b>Vision-based Price Suggestion for Online Second-hand Items</b>
<a href="https://arxiv.org/abs/2012.06009">arxiv:2012.06009</a>
&#x1F4C8; -1 <br>
<p>Liang Han, Zhaozheng Yin, Zhurong Xia, Li Guo, Mingqian Tang, Rong Jin</p></summary>
<p>

**Abstract:** Different from shopping in physical stores, where people have the opportunity to closely check a product (e.g., touching the surface of a T-shirt or smelling the scent of perfume) before making a purchase decision, online shoppers rely greatly on the uploaded product images to make any purchase decision. The decision-making is challenging when selling or purchasing second-hand items online since estimating the items' prices is not trivial. In this work, we present a vision-based price suggestion system for the online second-hand item shopping platform. The goal of vision-based price suggestion is to help sellers set effective prices for their second-hand listings with the images uploaded to the online platforms.
  First, we propose to better extract representative visual features from the images with the aid of some other image-based item information (e.g., category, brand). Then, we design a vision-based price suggestion module which takes the extracted visual features along with some statistical item features from the shopping platform as the inputs to determine whether an uploaded item image is qualified for price suggestion by a binary classification model, and provide price suggestions for items with qualified images by a regression model. According to two demands from the platform, two different objective functions are proposed to jointly optimize the classification model and the regression model. For better model training, we also propose a warm-up training strategy for the joint optimization. Extensive experiments on a large real-world dataset demonstrate the effectiveness of our vision-based price prediction system.

</p>
</details>

<details><summary><b>xRAI: Explainable Representations through AI</b>
<a href="https://arxiv.org/abs/2012.06006">arxiv:2012.06006</a>
&#x1F4C8; -1 <br>
<p>Christiann Bartelt, Sascha Marton, Heiner Stuckenschmidt</p></summary>
<p>

**Abstract:** We present xRAI an approach for extracting symbolic representations of the mathematical function a neural network was supposed to learn from the trained network. The approach is based on the idea of training a so-called interpretation network that receives the weights and biases of the trained network as input and outputs the numerical representation of the function the network was supposed to learn that can be directly translated into a symbolic representation. We show that interpretation nets for different classes of functions can be trained on synthetic data offline using Boolean functions and low-order polynomials as examples. We show that the training is rather efficient and the quality of the results are promising. Our work aims to provide a contribution to the problem of better understanding neural decision making by making the target function explicit

</p>
</details>

<details><summary><b>Overcoming Catastrophic Forgetting in Graph Neural Networks</b>
<a href="https://arxiv.org/abs/2012.06002">arxiv:2012.06002</a>
&#x1F4C8; -1 <br>
<p>Huihui Liu, Yiding Yang, Xinchao Wang</p></summary>
<p>

**Abstract:** Catastrophic forgetting refers to the tendency that a neural network "forgets" the previous learned knowledge upon learning new tasks. Prior methods have been focused on overcoming this problem on convolutional neural networks (CNNs), where the input samples like images lie in a grid domain, but have largely overlooked graph neural networks (GNNs) that handle non-grid data. In this paper, we propose a novel scheme dedicated to overcoming catastrophic forgetting problem and hence strengthen continual learning in GNNs. At the heart of our approach is a generic module, termed as topology-aware weight preserving~(TWP), applicable to arbitrary form of GNNs in a plug-and-play fashion. Unlike the main stream of CNN-based continual learning methods that rely on solely slowing down the updates of parameters important to the downstream task, TWP explicitly explores the local structures of the input graph, and attempts to stabilize the parameters playing pivotal roles in the topological aggregation. We evaluate TWP on different GNN backbones over several datasets, and demonstrate that it yields performances superior to the state of the art. Code is publicly available at \url{https://github.com/hhliu79/TWP}.

</p>
</details>

<details><summary><b>An IoT Framework for Heart Disease Prediction based on MDCNN Classifier</b>
<a href="https://arxiv.org/abs/2012.05999">arxiv:2012.05999</a>
&#x1F4C8; -1 <br>
<p>Mohammad Ayoub Khan</p></summary>
<p>

**Abstract:** Nowadays, heart disease is the leading cause of death worldwide. Predicting heart disease is a complex task since it requires experience along with advanced knowledge. Internet of Things (IoT) technology has lately been adopted in healthcare systems to collect sensor values for heart disease diagnosis and prediction. Many researchers have focused on the diagnosis of heart disease, yet the accuracy of the diagnosis results is low. To address this issue, an IoT framework is proposed to evaluate heart disease more accurately using a Modified Deep Convolutional Neural Network (MDCNN). The smartwatch and heart monitor device that is attached to the patient monitors the blood pressure and electrocardiogram (ECG). The MDCNN is utilized for classifying the received sensor data into normal and abnormal. The performance of the system is analyzed by comparing the proposed MDCNN with existing deep learning neural networks and logistic regression. The results demonstrate that the proposed MDCNN based heart disease prediction system performs better than other methods. The proposed method shows that for the maximum number of records, the MDCNN achieves an accuracy of 98.2 which is better than existing classifiers.

</p>
</details>

<details><summary><b>Towards Neural Programming Interfaces</b>
<a href="https://arxiv.org/abs/2012.05983">arxiv:2012.05983</a>
&#x1F4C8; -1 <br>
<p>Zachary C. Brown, Nathaniel Robinson, David Wingate, Nancy Fulda</p></summary>
<p>

**Abstract:** It is notoriously difficult to control the behavior of artificial neural networks such as generative neural language models. We recast the problem of controlling natural language generation as that of learning to interface with a pretrained language model, just as Application Programming Interfaces (APIs) control the behavior of programs by altering hyperparameters. In this new paradigm, a specialized neural network (called a Neural Programming Interface or NPI) learns to interface with a pretrained language model by manipulating the hidden activations of the pretrained model to produce desired outputs. Importantly, no permanent changes are made to the weights of the original model, allowing us to re-purpose pretrained models for new tasks without overwriting any aspect of the language model. We also contribute a new data set construction algorithm and GAN-inspired loss function that allows us to train NPI models to control outputs of autoregressive transformers. In experiments against other state-of-the-art approaches, we demonstrate the efficacy of our methods using OpenAI's GPT-2 model, successfully controlling noun selection, topic aversion, offensive speech filtering, and other aspects of language while largely maintaining the controlled model's fluency under deterministic settings.

</p>
</details>

<details><summary><b>CommPOOL: An Interpretable Graph Pooling Framework for Hierarchical Graph Representation Learning</b>
<a href="https://arxiv.org/abs/2012.05980">arxiv:2012.05980</a>
&#x1F4C8; -1 <br>
<p>Haoteng Tang, Guixiang Ma, Lifang He, Heng Huang, Liang Zhan</p></summary>
<p>

**Abstract:** Recent years have witnessed the emergence and flourishing of hierarchical graph pooling neural networks (HGPNNs) which are effective graph representation learning approaches for graph level tasks such as graph classification. However, current HGPNNs do not take full advantage of the graph's intrinsic structures (e.g., community structure). Moreover, the pooling operations in existing HGPNNs are difficult to be interpreted. In this paper, we propose a new interpretable graph pooling framework - CommPOOL, that can capture and preserve the hierarchical community structure of graphs in the graph representation learning process. Specifically, the proposed community pooling mechanism in CommPOOL utilizes an unsupervised approach for capturing the inherent community structure of graphs in an interpretable manner. CommPOOL is a general and flexible framework for hierarchical graph representation learning that can further facilitate various graph-level tasks. Evaluations on five public benchmark datasets and one synthetic dataset demonstrate the superior performance of CommPOOL in graph representation learning for graph classification compared to the state-of-the-art baseline methods, and its effectiveness in capturing and preserving the community structure of graphs.

</p>
</details>

<details><summary><b>Clustering multivariate functional data using unsupervised binary trees</b>
<a href="https://arxiv.org/abs/2012.05973">arxiv:2012.05973</a>
&#x1F4C8; -1 <br>
<p>Steven Golovkine, Nicolas Klutchnikoff, Valentin Patilea</p></summary>
<p>

**Abstract:** We propose a model-based clustering algorithm for a general class of functional data for which the components could be curves or images. The random functional data realizations could be measured with error at discrete, and possibly random, points in the definition domain. The idea is to build a set of binary trees by recursive splitting of the observations. The number of groups are determined in a data-driven way. The new algorithm provides easily interpretable results and fast predictions for online data sets. Results on simulated datasets reveal good performance in various complex settings. The methodology is applied to the analysis of vehicle trajectories on a German roundabout.

</p>
</details>

<details><summary><b>3D Scattering Tomography by Deep Learning with Architecture Tailored to Cloud Fields</b>
<a href="https://arxiv.org/abs/2012.05960">arxiv:2012.05960</a>
&#x1F4C8; -1 <br>
<p>Yael Sde-Chen, Yoav Y. Schechner, Vadim Holodovsky, Eshkol Eytan</p></summary>
<p>

**Abstract:** We present 3DeepCT, a deep neural network for computed tomography, which performs 3D reconstruction of scattering volumes from multi-view images. Our architecture is dictated by the stationary nature of atmospheric cloud fields. The task of volumetric scattering tomography aims at recovering a volume from its 2D projections. This problem has been studied extensively, leading, to diverse inverse methods based on signal processing and physics models. However, such techniques are typically iterative, exhibiting high computational load and long convergence time. We show that 3DeepCT outperforms physics-based inverse scattering methods in term of accuracy as well as offering a significant orders of magnitude improvement in computational time. To further improve the recovery accuracy, we introduce a hybrid model that combines 3DeepCT and physics-based method. The resultant hybrid technique enjoys fast inference time and improved recovery performance.

</p>
</details>

<details><summary><b>Super-resolution Guided Pore Detection for Fingerprint Recognition</b>
<a href="https://arxiv.org/abs/2012.05959">arxiv:2012.05959</a>
&#x1F4C8; -1 <br>
<p>Syeda Nyma Ferdous, Ali Dabouei, Jeremy Dawson, Nasser M Nasrabadi</p></summary>
<p>

**Abstract:** Performance of fingerprint recognition algorithms substantially rely on fine features extracted from fingerprints. Apart from minutiae and ridge patterns, pore features have proven to be usable for fingerprint recognition. Although features from minutiae and ridge patterns are quite attainable from low-resolution images, using pore features is practical only if the fingerprint image is of high resolution which necessitates a model that enhances the image quality of the conventional 500 ppi legacy fingerprints preserving the fine details. To find a solution for recovering pore information from low-resolution fingerprints, we adopt a joint learning-based approach that combines both super-resolution and pore detection networks. Our modified single image Super-Resolution Generative Adversarial Network (SRGAN) framework helps to reliably reconstruct high-resolution fingerprint samples from low-resolution ones assisting the pore detection network to identify pores with a high accuracy. The network jointly learns a distinctive feature representation from a real low-resolution fingerprint sample and successfully synthesizes a high-resolution sample from it. To add discriminative information and uniqueness for all the subjects, we have integrated features extracted from a deep fingerprint verifier with the SRGAN quality discriminator. We also add ridge reconstruction loss, utilizing ridge patterns to make the best use of extracted features. Our proposed method solves the recognition problem by improving the quality of fingerprint images. High recognition accuracy of the synthesized samples that is close to the accuracy achieved using the original high-resolution images validate the effectiveness of our proposed model.

</p>
</details>

<details><summary><b>A Simplistic Machine Learning Approach to Contact Tracing</b>
<a href="https://arxiv.org/abs/2012.05940">arxiv:2012.05940</a>
&#x1F4C8; -1 <br>
<p>Carlos Gómez, Niamh Belton, Boi Quach, Jack Nicholls, Devanshu Anand</p></summary>
<p>

**Abstract:** This report is based on the modified NIST challenge, Too Close For Too Long, provided by the SFI Centre for Machine Learning (ML-Labs). The modified challenge excludes the time calculation (too long) aspect. By handcrafting features from phone instrumental data we develop two machine learning models, a GBM and an MLP, to estimate distance between two phones. Our method is able to outperform the leading NIST challenge result by the Hong Kong University of Science and Technology (HKUST) by a significant margin.

</p>
</details>

<details><summary><b>A machine learning approach to galaxy properties: Joint redshift - stellar mass probability distributions with Random Forest</b>
<a href="https://arxiv.org/abs/2012.05928">arxiv:2012.05928</a>
&#x1F4C8; -1 <br>
<p>S. Mucesh, W. G. Hartley, A. Palmese, O. Lahav, L. Whiteway, A. Amon, K. Bechtol, G. M. Bernstein, A. Carnero Rosell, M. Carrasco Kind, A. Choi, K. Eckert, S. Everett, D. Gruen, R. A. Gruendl, I. Harrison, E. M. Huff, N. Kuropatkin, I. Sevilla-Noarbe, E. Sheldon, B. Yanny, M. Aguena, S. Allam, D. Bacon, E. Bertin</p></summary>
<p>

**Abstract:** We demonstrate that highly accurate joint redshift - stellar mass PDFs can be obtained using the Random Forest (RF) machine learning (ML) algorithm, even with few photometric bands available. As an example, we use the Dark Energy Survey (DES), combined with the COSMOS2015 catalogue for redshifts and stellar masses. We build two ML models: one containing deep photometry in the $griz$ bands, and the second reflecting the photometric scatter present in the main DES survey, with carefully constructed representative training data in each case. We validate our joint PDFs for $10,699$ test galaxies by utilising the copula probability integral transform (copPIT) and the Kendall distribution function, and their univariate counterparts to validate the marginals. Benchmarked against a basic set-up of the template-fitting code BAGPIPES, our ML-based method outperforms template fitting on all of our pre-defined performance metrics. In addition to accuracy, the RF is extremely fast, able to compute joint PDFs for a million galaxies in just over $2$ hours with consumer computer hardware. Such speed enables PDFs to be derived in real-time within analysis codes, solving potential storage issues. As part of this work we have developed GALPRO, a highly intuitive and efficient Python package to rapidly generate multivariate PDFs on-the-fly. GALPRO is documented and available for researchers to use in their cosmology and galaxy evolution studies at https://galpro.readthedocs.io/.

</p>
</details>

<details><summary><b>Ensemble of Discriminators for Domain Adaptation in Multiple Sound Source 2D Localization</b>
<a href="https://arxiv.org/abs/2012.05908">arxiv:2012.05908</a>
&#x1F4C8; -1 <br>
<p>Guillaume Le Moing, Don Joven Agravante, Tadanobu Inoue, Jayakorn Vongkulbhisal, Asim Munawar, Ryuki Tachibana, Phongtharin Vinayavekhin</p></summary>
<p>

**Abstract:** This paper introduces an ensemble of discriminators that improves the accuracy of a domain adaptation technique for the localization of multiple sound sources. Recently, deep neural networks have led to promising results for this task, yet they require a large amount of labeled data for training. Recording and labeling such datasets is very costly, especially because data needs to be diverse enough to cover different acoustic conditions. In this paper, we leverage acoustic simulators to inexpensively generate labeled training samples. However, models trained on synthetic data tend to perform poorly with real-world recordings due to the domain mismatch. For this, we explore two domain adaptation methods using adversarial learning for sound source localization which use labeled synthetic data and unlabeled real data. We propose a novel ensemble approach that combines discriminators applied at different feature levels of the localization model. Experiments show that our ensemble discrimination method significantly improves the localization performance without requiring any label from the real data.

</p>
</details>

<details><summary><b>Are Fewer Labels Possible for Few-shot Learning?</b>
<a href="https://arxiv.org/abs/2012.05899">arxiv:2012.05899</a>
&#x1F4C8; -1 <br>
<p>Suichan Li, Dongdong Chen, Yinpeng Chen, Lu Yuan, Lei Zhang, Qi Chu, Nenghai Yu</p></summary>
<p>

**Abstract:** Few-shot learning is challenging due to its very limited data and labels. Recent studies in big transfer (BiT) show that few-shot learning can greatly benefit from pretraining on large scale labeled dataset in a different domain. This paper asks a more challenging question: "can we use as few as possible labels for few-shot learning in both pretraining (with no labels) and fine-tuning (with fewer labels)?".
  Our key insight is that the clustering of target samples in the feature space is all we need for few-shot finetuning. It explains why the vanilla unsupervised pretraining (poor clustering) is worse than the supervised one. In this paper, we propose transductive unsupervised pretraining that achieves a better clustering by involving target data even though its amount is very limited. The improved clustering result is of great value for identifying the most representative samples ("eigen-samples") for users to label, and in return, continued finetuning with the labeled eigen-samples further improves the clustering. Thus, we propose eigen-finetuning to enable fewer shot learning by leveraging the co-evolution of clustering and eigen-samples in the finetuning. We conduct experiments on 10 different few-shot target datasets, and our average few-shot performance outperforms both vanilla inductive unsupervised transfer and supervised transfer by a large margin. For instance, when each target category only has 10 labeled samples, the mean accuracy gain over the above two baselines is 9.2% and 3.42 respectively.

</p>
</details>

<details><summary><b>Self-Supervised Learning of Lidar Segmentation for Autonomous Indoor Navigation</b>
<a href="https://arxiv.org/abs/2012.05897">arxiv:2012.05897</a>
&#x1F4C8; -1 <br>
<p>Hugues Thomas, Ben Agro, Mona Gridseth, Jian Zhang, Timothy D. Barfoot</p></summary>
<p>

**Abstract:** We present a self-supervised learning approach for the semantic segmentation of lidar frames. Our method is used to train a deep point cloud segmentation architecture without any human annotation. The annotation process is automated with the combination of simultaneous localization and mapping (SLAM) and ray-tracing algorithms. By performing multiple navigation sessions in the same environment, we are able to identify permanent structures, such as walls, and disentangle short-term and long-term movable objects, such as people and tables, respectively. New sessions can then be performed using a network trained to predict these semantic labels. We demonstrate the ability of our approach to improve itself over time, from one session to the next. With semantically filtered point clouds, our robot can navigate through more complex scenarios, which, when added to the training pool, help to improve our network predictions. We provide insights into our network predictions and show that our approach can also improve the performances of common localization techniques.

</p>
</details>

<details><summary><b>Flexible Few-Shot Learning with Contextual Similarity</b>
<a href="https://arxiv.org/abs/2012.05895">arxiv:2012.05895</a>
&#x1F4C8; -1 <br>
<p>Mengye Ren, Eleni Triantafillou, Kuan-Chieh Wang, James Lucas, Jake Snell, Xaq Pitkow, Andreas S. Tolias, Richard Zemel</p></summary>
<p>

**Abstract:** Existing approaches to few-shot learning deal with tasks that have persistent, rigid notions of classes. Typically, the learner observes data only from a fixed number of classes at training time and is asked to generalize to a new set of classes at test time. Two examples from the same class would always be assigned the same labels in any episode. In this work, we consider a realistic setting where the similarities between examples can change from episode to episode depending on the task context, which is not given to the learner. We define new benchmark datasets for this flexible few-shot scenario, where the tasks are based on images of faces (Celeb-A), shoes (Zappos50K), and general objects (ImageNet-with-Attributes). While classification baselines and episodic approaches learn representations that work well for standard few-shot learning, they suffer in our flexible tasks as novel similarity definitions arise during testing. We propose to build upon recent contrastive unsupervised learning techniques and use a combination of instance and class invariance learning, aiming to obtain general and flexible features. We find that our approach performs strongly on our new flexible few-shot learning benchmarks, demonstrating that unsupervised learning obtains more generalizable representations.

</p>
</details>

<details><summary><b>AutoSelect: Automatic and Dynamic Detection Selection for 3D Multi-Object Tracking</b>
<a href="https://arxiv.org/abs/2012.05894">arxiv:2012.05894</a>
&#x1F4C8; -1 <br>
<p>Xinshuo Weng, Kris Kitani</p></summary>
<p>

**Abstract:** 3D multi-object tracking is an important component in robotic perception systems such as self-driving vehicles. Recent work follows a tracking-by-detection pipeline, which aims to match past tracklets with detections in the current frame. To avoid matching with false positive detections, prior work filters out detections with low confidence scores via a threshold. However, finding a proper threshold is non-trivial, which requires extensive manual search via ablation study. Also, this threshold is sensitive to many factors such as target object category so we need to re-search the threshold if these factors change. To ease this process, we propose to automatically select high-quality detections and remove the efforts needed for manual threshold search. Also, prior work often uses a single threshold per data sequence, which is sub-optimal in particular frames or for certain objects. Instead, we dynamically search threshold per frame or per object to further boost performance. Through experiments on KITTI and nuScenes, our method can filter out $45.7\%$ false positives while maintaining the recall, achieving new S.O.T.A. performance and removing the need for manually threshold tuning.

</p>
</details>

<details><summary><b>Neurosymbolic AI: The 3rd Wave</b>
<a href="https://arxiv.org/abs/2012.05876">arxiv:2012.05876</a>
&#x1F4C8; -1 <br>
<p>Artur d'Avila Garcez, Luis C. Lamb</p></summary>
<p>

**Abstract:** Current advances in Artificial Intelligence (AI) and Machine Learning (ML) have achieved unprecedented impact across research communities and industry. Nevertheless, concerns about trust, safety, interpretability and accountability of AI were raised by influential thinkers. Many have identified the need for well-founded knowledge representation and reasoning to be integrated with deep learning and for sound explainability. Neural-symbolic computing has been an active area of research for many years seeking to bring together robust learning in neural networks with reasoning and explainability via symbolic representations for network models. In this paper, we relate recent and early research results in neurosymbolic AI with the objective of identifying the key ingredients of the next wave of AI systems. We focus on research that integrates in a principled way neural network-based learning with symbolic knowledge representation and logical reasoning. The insights provided by 20 years of neural-symbolic computing are shown to shed new light onto the increasingly prominent role of trust, safety, interpretability and accountability of AI. We also identify promising directions and challenges for the next decade of AI research from the perspective of neural-symbolic systems.

</p>
</details>

<details><summary><b>Hindsight and Sequential Rationality of Correlated Play</b>
<a href="https://arxiv.org/abs/2012.05874">arxiv:2012.05874</a>
&#x1F4C8; -1 <br>
<p>Dustin Morrill, Ryan D'Orazio, Reca Sarfati, Marc Lanctot, James R. Wright, Amy Greenwald, Michael Bowling</p></summary>
<p>

**Abstract:** Driven by recent successes in two-player, zero-sum game solving and playing, artificial intelligence work on games has increasingly focused on algorithms that produce equilibrium-based strategies. However, this approach has been less effective at producing competent players in general-sum games or those with more than two players than in two-player, zero-sum games. An appealing alternative is to consider adaptive algorithms that ensure strong performance in hindsight relative to what could have been achieved with modified behavior. This approach also leads to a game-theoretic analysis, but in the correlated play that arises from joint learning dynamics rather than factored agent behavior at equilibrium. We develop and advocate for this hindsight rationality framing of learning in general sequential decision-making settings. To this end, we re-examine mediated equilibrium and deviation types in extensive-form games, thereby gaining a more complete understanding and resolving past misconceptions. We present a set of examples illustrating the distinct strengths and weaknesses of each type of equilibrium in the literature, and prove that no tractable concept subsumes all others. This line of inquiry culminates in the definition of the deviation and equilibrium classes that correspond to algorithms in the counterfactual regret minimization (CFR) family, relating them to all others in the literature. Examining CFR in greater detail further leads to a new recursive definition of rationality in correlated play that extends sequential rationality in a way that naturally applies to hindsight evaluation.

</p>
</details>

<details><summary><b>Full-Glow: Fully conditional Glow for more realistic image generation</b>
<a href="https://arxiv.org/abs/2012.05846">arxiv:2012.05846</a>
&#x1F4C8; -1 <br>
<p>Moein Sorkhei, Gustav Eje Henter, Hedvig Kjellström</p></summary>
<p>

**Abstract:** Autonomous agents, such as driverless cars, require large amounts of labeled visual data for their training. A viable approach for acquiring such data is training a generative model with collected real data, and then augmenting the collected real dataset with synthetic images from the model, generated with control of the scene layout and ground truth labeling. In this paper we propose Full-Glow, a fully conditional Glow-based architecture for generating plausible and realistic images of novel street scenes given a semantic segmentation map indicating the scene layout. Benchmark comparisons show our model to outperform recent works in terms of the semantic segmentation performance of a pretrained PSPNet. This indicates that images from our model are, to a higher degree than from other models, similar to real images of the same kinds of scenes and objects, making them suitable as training data for a visual semantic segmentation or object recognition system.

</p>
</details>

<details><summary><b>A Probabilistic Graphical Model Foundation for Enabling Predictive Digital Twins at Scale</b>
<a href="https://arxiv.org/abs/2012.05841">arxiv:2012.05841</a>
&#x1F4C8; -1 <br>
<p>Michael G. Kapteyn, Jacob V. R. Pretorius, Karen E. Willcox</p></summary>
<p>

**Abstract:** A unifying mathematical formulation is needed to move from one-off digital twins built through custom implementations to robust digital twin implementations at scale. This work proposes a probabilistic graphical model as a formal mathematical representation of a digital twin and its associated physical asset. We create an abstraction of the asset-twin system as a set of coupled dynamical systems, evolving over time through their respective state-spaces and interacting via observed data and control inputs. The formal definition of this coupled system as a probabilistic graphical model enables us to draw upon well-established theory and methods from Bayesian statistics, dynamical systems, and control theory. The declarative and general nature of the proposed digital twin model make it rigorous yet flexible, enabling its application at scale in a diverse range of application areas. We demonstrate how the model is instantiated as a Bayesian network to create a structural digital twin of an unmanned aerial vehicle. The graphical model foundation ensures that the digital twin creation and updating process is principled, repeatable, and able to scale to the calibration of an entire fleet of digital twins.

</p>
</details>

<details><summary><b>Multi-expert learning of adaptive legged locomotion</b>
<a href="https://arxiv.org/abs/2012.05810">arxiv:2012.05810</a>
&#x1F4C8; -1 <br>
<p>Chuanyu Yang, Kai Yuan, Qiuguo Zhu, Wanming Yu, Zhibin Li</p></summary>
<p>

**Abstract:** Achieving versatile robot locomotion requires motor skills which can adapt to previously unseen situations. We propose a Multi-Expert Learning Architecture (MELA) that learns to generate adaptive skills from a group of representative expert skills. During training, MELA is first initialised by a distinct set of pre-trained experts, each in a separate deep neural network (DNN). Then by learning the combination of these DNNs using a Gating Neural Network (GNN), MELA can acquire more specialised experts and transitional skills across various locomotion modes. During runtime, MELA constantly blends multiple DNNs and dynamically synthesises a new DNN to produce adaptive behaviours in response to changing situations. This approach leverages the advantages of trained expert skills and the fast online synthesis of adaptive policies to generate responsive motor skills during the changing tasks. Using a unified MELA framework, we demonstrated successful multi-skill locomotion on a real quadruped robot that performed coherent trotting, steering, and fall recovery autonomously, and showed the merit of multi-expert learning generating behaviours which can adapt to unseen scenarios.

</p>
</details>

<details><summary><b>Appliance-Level Monitoring with Micro-Moment Smart Plugs</b>
<a href="https://arxiv.org/abs/2012.05787">arxiv:2012.05787</a>
&#x1F4C8; -1 <br>
<p>Abdullah Alsalemi, Yassine Himeur, Faycal Bensaali, Abbes Amira</p></summary>
<p>

**Abstract:** Human population are striving against energy-related issues that not only affects society and the development of the world, but also causes global warming. A variety of broad approaches have been developed by both industry and the research community. However, there is an ever increasing need for comprehensive, end-to-end solutions aimed at transforming human behavior rather than device metrics and benchmarks. In this paper, a micro-moment-based smart plug system is proposed as part of a larger multi-appliance energy efficiency program. The smart plug, which includes two sub-units: the power consumption unit and environmental monitoring unit collect energy consumption of appliances along with contextual information, such as temperature, humidity, luminosity and room occupancy respectively. The plug also allows home automation capability. With the accompanying mobile application, end-users can visualize energy consumption data along with ambient environmental information. Current implementation results show that the proposed system delivers cost-effective deployment while maintaining adequate computation and wireless performance.

</p>
</details>

<details><summary><b>Notes on Deep Learning Theory</b>
<a href="https://arxiv.org/abs/2012.05760">arxiv:2012.05760</a>
&#x1F4C8; -1 <br>
<p>Eugene A. Golikov</p></summary>
<p>

**Abstract:** These are the notes for the lectures that I was giving during Fall 2020 at the Moscow Institute of Physics and Technology (MIPT) and at the Yandex School of Data Analysis (YSDA). The notes cover some aspects of initialization, loss landscape, generalization, and a neural tangent kernel theory. While many other topics (e.g. expressivity, a mean-field theory, a double descent phenomenon) are missing in the current version, we plan to add them in future revisions.

</p>
</details>

<details><summary><b>Large Non-Stationary Noisy Covariance Matrices: A Cross-Validation Approach</b>
<a href="https://arxiv.org/abs/2012.05757">arxiv:2012.05757</a>
&#x1F4C8; -1 <br>
<p>Vincent W. C. Tan, Stefan Zohren</p></summary>
<p>

**Abstract:** We introduce a novel covariance estimator that exploits the heteroscedastic nature of financial time series by employing exponential weighted moving averages and shrinking the in-sample eigenvalues through cross-validation. Our estimator is model-agnostic in that we make no assumptions on the distribution of the random entries of the matrix or structure of the covariance matrix. Additionally, we show how Random Matrix Theory can provide guidance for automatic tuning of the hyperparameter which characterizes the time scale for the dynamics of the estimator. By attenuating the noise from both the cross-sectional and time-series dimensions, we empirically demonstrate the superiority of our estimator over competing estimators that are based on exponentially-weighted and uniformly-weighted covariance matrices.

</p>
</details>

<details><summary><b>Scalable and interpretable rule-based link prediction for large heterogeneous knowledge graphs</b>
<a href="https://arxiv.org/abs/2012.05750">arxiv:2012.05750</a>
&#x1F4C8; -1 <br>
<p>Simon Ott, Laura Graf, Asan Agibetov, Christian Meilicke, Matthias Samwald</p></summary>
<p>

**Abstract:** Neural embedding-based machine learning models have shown promise for predicting novel links in biomedical knowledge graphs. Unfortunately, their practical utility is diminished by their lack of interpretability. Recently, the fully interpretable, rule-based algorithm AnyBURL yielded highly competitive results on many general-purpose link prediction benchmarks. However, its applicability to large-scale prediction tasks on complex biomedical knowledge bases is limited by long inference times and difficulties with aggregating predictions made by multiple rules. We improve upon AnyBURL by introducing the SAFRAN rule application framework which aggregates rules through a scalable clustering algorithm. SAFRAN yields new state-of-the-art results for fully interpretable link prediction on the established general-purpose benchmark FB15K-237 and the large-scale biomedical benchmark OpenBioLink. Furthermore, it exceeds the results of multiple established embedding-based algorithms on FB15K-237 and narrows the gap between rule-based and embedding-based algorithms on OpenBioLink. We also show that SAFRAN increases inference speeds by up to two orders of magnitude.

</p>
</details>

<details><summary><b>3D Bounding Box Detection in Volumetric Medical Image Data: A Systematic Literature Review</b>
<a href="https://arxiv.org/abs/2012.05745">arxiv:2012.05745</a>
&#x1F4C8; -1 <br>
<p>Daria Kern, Andre Mastmeyer</p></summary>
<p>

**Abstract:** This paper discusses current methods and trends for 3D bounding box detection in volumetric medical image data. For this purpose, an overview of relevant papers from recent years is given. 2D and 3D implementations are discussed and compared. Multiple identified approaches for localizing anatomical structures are presented. The results show that most research recently focuses on Deep Learning methods, such as Convolutional Neural Networks vs. methods with manual feature engineering, e.g. Random-Regression-Forests. An overview of bounding box detection options is presented and helps researchers to select the most promising approach for their target objects.

</p>
</details>

<details><summary><b>Longitudinal Citation Prediction using Temporal Graph Neural Networks</b>
<a href="https://arxiv.org/abs/2012.05742">arxiv:2012.05742</a>
&#x1F4C8; -1 <br>
<p>Andreas Nugaard Holm, Barbara Plank, Dustin Wright, Isabelle Augenstein</p></summary>
<p>

**Abstract:** Citation count prediction is the task of predicting the number of citations a paper has gained after a period of time. Prior work viewed this as a static prediction task. As papers and their citations evolve over time, considering the dynamics of the number of citations a paper will receive would seem logical. Here, we introduce the task of sequence citation prediction, where the goal is to accurately predict the trajectory of the number of citations a scholarly work receives over time. We propose to view papers as a structured network of citations, allowing us to use topological information as a learning signal. Additionally, we learn how this dynamic citation network changes over time and the impact of paper meta-data such as authors, venues and abstracts. To approach the introduced task, we derive a dynamic citation network from Semantic Scholar which spans over 42 years. We present a model which exploits topological and temporal information using graph convolution networks paired with sequence prediction, and compare it against multiple baselines, testing the importance of topological and temporal information and analyzing model performance. Our experiments show that leveraging both the temporal and topological information greatly increases the performance of predicting citation counts over time.

</p>
</details>

<details><summary><b>R-AGNO-RPN: A LIDAR-Camera Region Deep Network for Resolution-Agnostic Detection</b>
<a href="https://arxiv.org/abs/2012.05740">arxiv:2012.05740</a>
&#x1F4C8; -1 <br>
<p>Ruddy Théodose, Dieumet Denis, Thierry Chateau, Vincent Frémont, Paul Checchin</p></summary>
<p>

**Abstract:** Current neural networks-based object detection approaches processing LiDAR point clouds are generally trained from one kind of LiDAR sensors. However, their performances decrease when they are tested with data coming from a different LiDAR sensor than the one used for training, i.e., with a different point cloud resolution. In this paper, R-AGNO-RPN, a region proposal network built on fusion of 3D point clouds and RGB images is proposed for 3D object detection regardless of point cloud resolution. As our approach is designed to be also applied on low point cloud resolutions, the proposed method focuses on object localization instead of estimating refined boxes on reduced data. The resilience to low-resolution point cloud is obtained through image features accurately mapped to Bird's Eye View and a specific data augmentation procedure that improves the contribution of the RGB images. To show the proposed network's ability to deal with different point clouds resolutions, experiments are conducted on both data coming from the KITTI 3D Object Detection and the nuScenes datasets. In addition, to assess its performances, our method is compared to PointPillars, a well-known 3D detection network. Experimental results show that even on point cloud data reduced by $80\%$ of its original points, our method is still able to deliver relevant proposals localization.

</p>
</details>

<details><summary><b>HRCenterNet: An Anchorless Approach to Chinese Character Segmentation in Historical Documents</b>
<a href="https://arxiv.org/abs/2012.05739">arxiv:2012.05739</a>
&#x1F4C8; -1 <br>
<p>Chia-Wei Tang, Chao-Lin Liu, Po-Sen Chiu</p></summary>
<p>

**Abstract:** The information provided by historical documents has always been indispensable in the transmission of human civilization, but it has also made these books susceptible to damage due to various factors. Thanks to recent technology, the automatic digitization of these documents are one of the quickest and most effective means of preservation. The main steps of automatic text digitization can be divided into two stages, mainly: character segmentation and character recognition, where the recognition results depend largely on the accuracy of segmentation. Therefore, in this study, we will only focus on the character segmentation of historical Chinese documents. In this research, we propose a model named HRCenterNet, which is combined with an anchorless object detection method and parallelized architecture. The MTHv2 dataset consists of over 3000 Chinese historical document images and over 1 million individual Chinese characters; with these enormous data, the segmentation capability of our model achieves IoU 0.81 on average with the best speed-accuracy trade-off compared to the others. Our source code is available at https://github.com/Tverous/HRCenterNet.

</p>
</details>

<details><summary><b>Interpreting Neural Networks as Gradual Argumentation Frameworks (Including Proof Appendix)</b>
<a href="https://arxiv.org/abs/2012.05738">arxiv:2012.05738</a>
&#x1F4C8; -1 <br>
<p>Nico Potyka</p></summary>
<p>

**Abstract:** We show that an interesting class of feed-forward neural networks can be understood as quantitative argumentation frameworks. This connection creates a bridge between research in Formal Argumentation and Machine Learning. We generalize the semantics of feed-forward neural networks to acyclic graphs and study the resulting computational and semantical properties in argumentation graphs. As it turns out, the semantics gives stronger guarantees than existing semantics that have been tailor-made for the argumentation setting. From a machine-learning perspective, the connection does not seem immediately helpful. While it gives intuitive meaning to some feed-forward-neural networks, they remain difficult to understand due to their size and density. However, the connection seems helpful for combining background knowledge in form of sparse argumentation networks with dense neural networks that have been trained for complementary purposes and for learning the parameters of quantitative argumentation frameworks in an end-to-end fashion from data.

</p>
</details>

<details><summary><b>Automatic Micro-sleep Detection under Car-driving Simulation Environment using Night-sleep EEG</b>
<a href="https://arxiv.org/abs/2012.05705">arxiv:2012.05705</a>
&#x1F4C8; -1 <br>
<p>Young-Seok Kweon, Gi-Hwan Shin, Heon-Gyu Kwak, Minji Lee</p></summary>
<p>

**Abstract:** A micro-sleep is a short sleep that lasts from 1 to 30 secs. Its detection during driving is crucial to prevent accidents that could claim a lot of people's lives. Electroencephalogram (EEG) is suitable to detect micro-sleep because EEG was associated with consciousness and sleep. Deep learning showed great performance in recognizing brain states, but sufficient data should be needed. However, collecting micro-sleep data during driving is inefficient and has a high risk of obtaining poor data quality due to noisy driving situations. Night-sleep data at home is easier to collect than micro-sleep data during driving. Therefore, we proposed a deep learning approach using night-sleep EEG to improve the performance of micro-sleep detection. We pre-trained the U-Net to classify the 5-class sleep stages using night-sleep EEG and used the sleep stages estimated by the U-Net to detect micro-sleep during driving. This improved micro-sleep detection performance by about 30\% compared to the traditional approach. Our approach was based on the hypothesis that micro-sleep corresponds to the early stage of non-rapid eye movement (NREM) sleep. We analyzed EEG distribution during night-sleep and micro-sleep and found that micro-sleep has a similar distribution to NREM sleep. Our results provide the possibility of similarity between micro-sleep and the early stage of NREM sleep and help prevent micro-sleep during driving.

</p>
</details>

<details><summary><b>DA-HGT: Domain Adaptive Heterogeneous Graph Transformer</b>
<a href="https://arxiv.org/abs/2012.05688">arxiv:2012.05688</a>
&#x1F4C8; -1 <br>
<p>Tiancheng Huang, Ke Xu, Donglin Wang</p></summary>
<p>

**Abstract:** Domain adaptation using graph networks is to learn label-discriminative and network-invariant node embeddings by sharing graph parameters. Most existing works focus on domain adaptation of homogeneous networks, and just a few works begin to study heterogeneous cases that only consider the shared node types but ignore the private node types in individual networks. However, for a given source and target heterogeneous networks, they generally contain shared and private node types, where private types bring an extra challenge for graph domain adaptation. In this paper, we investigate Heterogeneous Information Networks (HINs) with partial shared node types and propose a novel domain adaptive heterogeneous graph transformer (DA-HGT) to handle the domain shift between them. DA-HGT can not only align the distributions of identical-type nodes and edges in two HINs but also make full use of different-type nodes and edges to improve the performance of knowledge transfer. Extensive experiments on several datasets demonstrate that DA-HGT can outperform state-of-the-art methods in various domain adaptation tasks across heterogeneous networks.

</p>
</details>

<details><summary><b>Generative Deep Learning Techniques for Password Generation</b>
<a href="https://arxiv.org/abs/2012.05685">arxiv:2012.05685</a>
&#x1F4C8; -1 <br>
<p>David Biesner, Kostadin Cvejoski, Bogdan Georgiev, Rafet Sifa, Erik Krupicka</p></summary>
<p>

**Abstract:** Password guessing approaches via deep learning have recently been investigated with significant breakthroughs in their ability to generate novel, realistic password candidates. In the present work we study a broad collection of deep learning and probabilistic based models in the light of password guessing: attention-based deep neural networks, autoencoding mechanisms and generative adversarial networks. We provide novel generative deep-learning models in terms of variational autoencoders exhibiting state-of-art sampling performance, yielding additional latent-space features such as interpolations and targeted sampling. Lastly, we perform a thorough empirical analysis in a unified controlled framework over well-known datasets (RockYou, LinkedIn, Youku, Zomato, Pwnd). Our results not only identify the most promising schemes driven by deep neural networks, but also illustrate the strengths of each approach in terms of generation variability and sample uniqueness.

</p>
</details>

<details><summary><b>Recurrent Point Review Models</b>
<a href="https://arxiv.org/abs/2012.05684">arxiv:2012.05684</a>
&#x1F4C8; -1 <br>
<p>Kostadin Cvejoski, Ramses J. Sanchez, Bogdan Georgiev, Christian Bauckhage, Cesar Ojeda</p></summary>
<p>

**Abstract:** Deep neural network models represent the state-of-the-art methodologies for natural language processing. Here we build on top of these methodologies to incorporate temporal information and model how to review data changes with time. Specifically, we use the dynamic representations of recurrent point process models, which encode the history of how business or service reviews are received in time, to generate instantaneous language models with improved prediction capabilities. Simultaneously, our methodologies enhance the predictive power of our point process models by incorporating summarized review content representations. We provide recurrent network and temporal convolution solutions for modeling the review content. We deploy our methodologies in the context of recommender systems, effectively characterizing the change in preference and taste of users as time evolves. Source code is available at [1].

</p>
</details>

<details><summary><b>Imitating Interactive Intelligence</b>
<a href="https://arxiv.org/abs/2012.05672">arxiv:2012.05672</a>
&#x1F4C8; -1 <br>
<p>Josh Abramson, Arun Ahuja, Arthur Brussee, Federico Carnevale, Mary Cassin, Stephen Clark, Andrew Dudzik, Petko Georgiev, Aurelia Guy, Tim Harley, Felix Hill, Alden Hung, Zachary Kenton, Jessica Landon, Timothy Lillicrap, Kory Mathewson, Alistair Muldal, Adam Santoro, Nikolay Savinov, Vikrant Varma, Greg Wayne, Nathaniel Wong, Chen Yan, Rui Zhu</p></summary>
<p>

**Abstract:** A common vision from science fiction is that robots will one day inhabit our physical spaces, sense the world as we do, assist our physical labours, and communicate with us through natural language. Here we study how to design artificial agents that can interact naturally with humans using the simplification of a virtual environment. This setting nevertheless integrates a number of the central challenges of artificial intelligence (AI) research: complex visual perception and goal-directed physical control, grounded language comprehension and production, and multi-agent social interaction. To build agents that can robustly interact with humans, we would ideally train them while they interact with humans. However, this is presently impractical. Therefore, we approximate the role of the human with another learned agent, and use ideas from inverse reinforcement learning to reduce the disparities between human-human and agent-agent interactive behaviour. Rigorously evaluating our agents poses a great challenge, so we develop a variety of behavioural tests, including evaluation by humans who watch videos of agents or interact directly with them. These evaluations convincingly demonstrate that interactive training and auxiliary losses improve agent behaviour beyond what is achieved by supervised learning of actions alone. Further, we demonstrate that agent capabilities generalise beyond literal experiences in the dataset. Finally, we train evaluation models whose ratings of agents agree well with human judgement, thus permitting the evaluation of new agent models without additional effort. Taken together, our results in this virtual environment provide evidence that large-scale human behavioural imitation is a promising tool to create intelligent, interactive agents, and the challenge of reliably evaluating such agents is possible to surmount.

</p>
</details>

<details><summary><b>Factor Graph Molecule Network for Structure Elucidation</b>
<a href="https://arxiv.org/abs/2012.05665">arxiv:2012.05665</a>
&#x1F4C8; -1 <br>
<p>Hieu Le Trung, Yiqing Xu, Wee Sun Lee</p></summary>
<p>

**Abstract:** Designing a network to learn a molecule structure given its physical/chemical properties is a hard problem, but is useful for drug discovery tasks. In this paper, we incorporate higher-order relational learning of Factor Graphs with strong approximation power of Neural Networks to create a molecule-structure learning network that has strong generalization power and can enforce higher-order relationship and valence constraints. We further propose methods to tackle problems such as the efficient design of factor nodes, conditional parameter sharing among factors, and symmetry problems in molecule structure prediction. Our experiment evaluation shows that the factor learning is effective and outperforms related methods.

</p>
</details>

<details><summary><b>Effect of the regularization hyperparameter on deep learning-based segmentation in LGE-MRI</b>
<a href="https://arxiv.org/abs/2012.05661">arxiv:2012.05661</a>
&#x1F4C8; -1 <br>
<p>Olivier Rukundo</p></summary>
<p>

**Abstract:** In this work, the author aims at demonstrating the extent to which the arbitrary selection of the L2 regularization hyperparameter can affect the outcome of deep learning-based segmentation in LGE-MRI. Here, arbitrary L2 regularization values are used to create different deep learning-based segmentation networks. Also, the author adopts the manual adjustment or tunning, of other deep learning hyperparameters, to be done only when 10% of all epochs are reached before achieving the 90% validation accuracy. The experimental comparisons demonstrate that small L2 regularization values can lead to better segmentation of the myocardial boundaries.

</p>
</details>

<details><summary><b>Slimmable Generative Adversarial Networks</b>
<a href="https://arxiv.org/abs/2012.05660">arxiv:2012.05660</a>
&#x1F4C8; -1 <br>
<p>Liang Hou, Zehuan Yuan, Lei Huang, Huawei Shen, Xueqi Cheng, Changhu Wang</p></summary>
<p>

**Abstract:** Generative adversarial networks (GANs) have achieved remarkable progress in recent years, but the continuously growing scale of models make them challenging to deploy widely in practical applications. In particular, for real-time generation tasks, different devices require generators of different sizes due to varying computing power. In this paper, we introduce slimmable GANs (SlimGANs), which can flexibly switch the width of the generator to accommodate various quality-efficiency trade-offs at runtime. Specifically, we leverage multiple discriminators that share partial parameters to train the slimmable generator. To facilitate the consistency between generators of different widths, we present a stepwise inplace distillation technique that encourages narrow generators to learn from wide ones. As for class-conditional generation, we propose a sliceable conditional batch normalization that incorporates the label information into different widths. Our methods are validated, both quantitatively and qualitatively, by extensive experiments and a detailed ablation study.

</p>
</details>

<details><summary><b>Concept Generalization in Visual Representation Learning</b>
<a href="https://arxiv.org/abs/2012.05649">arxiv:2012.05649</a>
&#x1F4C8; -1 <br>
<p>Mert Bulent Sariyildiz, Yannis Kalantidis, Diane Larlus, Karteek Alahari</p></summary>
<p>

**Abstract:** Measuring concept generalization, i.e., the extent to which models trained on a set of (seen) visual concepts can be used to recognize a new set of (unseen) concepts, is a popular way of evaluating visual representations, especially when they are learned with self-supervised learning. Nonetheless, the choice of which unseen concepts to use is usually made arbitrarily, and independently from the seen concepts used to train representations, thus ignoring any semantic relationships between the two. In this paper, we argue that semantic relationships between seen and unseen concepts affect generalization performance and propose ImageNet-CoG, a novel benchmark on the ImageNet dataset that enables measuring concept generalization in a principled way. Our benchmark leverages expert knowledge that comes from WordNet in order to define a sequence of unseen ImageNet concept sets that are semantically more and more distant from the ImageNet-1K subset, a ubiquitous training set. This allows us to benchmark visual representations learned on ImageNet-1K out-of-the box: we analyse a number of such models from supervised, semi-supervised and self-supervised approaches under the prism of concept generalization, and show how our benchmark is able to uncover a number of interesting insights. We will provide resources for the benchmark at https://europe.naverlabs.com/cog-benchmark.

</p>
</details>

<details><summary><b>Learning Graphons via Structured Gromov-Wasserstein Barycenters</b>
<a href="https://arxiv.org/abs/2012.05644">arxiv:2012.05644</a>
&#x1F4C8; -1 <br>
<p>Hongteng Xu, Dixin Luo, Lawrence Carin, Hongyuan Zha</p></summary>
<p>

**Abstract:** We propose a novel and principled method to learn a nonparametric graph model called graphon, which is defined in an infinite-dimensional space and represents arbitrary-size graphs. Based on the weak regularity lemma from the theory of graphons, we leverage a step function to approximate a graphon. We show that the cut distance of graphons can be relaxed to the Gromov-Wasserstein distance of their step functions. Accordingly, given a set of graphs generated by an underlying graphon, we learn the corresponding step function as the Gromov-Wasserstein barycenter of the given graphs. Furthermore, we develop several enhancements and extensions of the basic algorithm, $e.g.$, the smoothed Gromov-Wasserstein barycenter for guaranteeing the continuity of the learned graphons and the mixed Gromov-Wasserstein barycenters for learning multiple structured graphons. The proposed approach overcomes drawbacks of prior state-of-the-art methods, and outperforms them on both synthetic and real-world data. The code is available at https://github.com/HongtengXu/SGWB-Graphon.

</p>
</details>

<details><summary><b>Asymptotic study of stochastic adaptive algorithm in non-convex landscape</b>
<a href="https://arxiv.org/abs/2012.05640">arxiv:2012.05640</a>
&#x1F4C8; -1 <br>
<p>Sébastien Gadat, Ioana Gavra</p></summary>
<p>

**Abstract:** This paper studies some asymptotic properties of adaptive algorithms widely used in optimization and machine learning, and among them Adagrad and Rmsprop, which are involved in most of the blackbox deep learning algorithms. Our setup is the non-convex landscape optimization point of view, we consider a one time scale parametrization and we consider the situation where these algorithms may be used or not with mini-batches. We adopt the point of view of stochastic algorithms and establish the almost sure convergence of these methods when using a decreasing step-size point of view towards the set of critical points of the target function. With a mild extra assumption on the noise, we also obtain the convergence towards the set of minimizer of the function. Along our study, we also obtain a "convergence rate" of the methods, in the vein of the works of \cite{GhadimiLan}.

</p>
</details>

<details><summary><b>Can we detect harmony in artistic compositions? A machine learning approach</b>
<a href="https://arxiv.org/abs/2012.05633">arxiv:2012.05633</a>
&#x1F4C8; -1 <br>
<p>Adam Vandor, Marie van Vollenhoven, Gerhard Weiss, Gerasimos Spanakis</p></summary>
<p>

**Abstract:** Harmony in visual compositions is a concept that cannot be defined or easily expressed mathematically, even by humans. The goal of the research described in this paper was to find a numerical representation of artistic compositions with different levels of harmony. We ask humans to rate a collection of grayscale images based on the harmony they convey. To represent the images, a set of special features were designed and extracted. By doing so, it became possible to assign objective measures to subjectively judged compositions. Given the ratings and the extracted features, we utilized machine learning algorithms to evaluate the efficiency of such representations in a harmony classification problem. The best performing model (SVM) achieved 80% accuracy in distinguishing between harmonic and disharmonic images, which reinforces the assumption that concept of harmony can be expressed in a mathematical way that can be assessed by humans.

</p>
</details>

<details><summary><b>A generalised log-determinant regularizer for online semi-definite programming and its applications</b>
<a href="https://arxiv.org/abs/2012.05632">arxiv:2012.05632</a>
&#x1F4C8; -1 <br>
<p>Yaxiong Liu, Ken-ichiro Moridomi, Kohei Hatano, Eiji Takimoto</p></summary>
<p>

**Abstract:** We consider a variant of online semi-definite programming problem (OSDP): The decision space consists of semi-definite matrices with bounded $Γ$-trace norm, which is a generalization of trace norm defined by a positive definite matrix $Γ.$ To solve this problem, we utilise the follow-the-regularized-leader algorithm with a $Γ$-dependent log-determinant regularizer. Then we apply our generalised setting and our proposed algorithm to online matrix completion(OMC) and online similarity prediction with side information. In particular, we reduce the online matrix completion problem to the generalised OSDP problem, and the side information is represented as the $Γ$ matrix. Hence, due to our regret bound for the generalised OSDP, we obtain an optimal mistake bound for the OMC by removing the logarithmic factor.

</p>
</details>

<details><summary><b>Performance Comparison of Balanced and Unbalanced Cancer Datasets using Pre-Trained Convolutional Neural Network</b>
<a href="https://arxiv.org/abs/2012.05585">arxiv:2012.05585</a>
&#x1F4C8; -1 <br>
<p>Ali Narin</p></summary>
<p>

**Abstract:** Cancer disease is one of the leading causes of death all over the world. Breast cancer, which is a common cancer disease especially in women, is quite common. The most important tool used for early detection of this cancer type, which requires a long process to establish a definitive diagnosis, is histopathological images taken by biopsy. These obtained images are examined by pathologists and a definitive diagnosis is made. It is quite common to detect this process with the help of a computer. Detection of benign or malignant tumors, especially by using data with different magnification rates, takes place in the literature. In this study, two different balanced and unbalanced study groups have been formed by using the histopathological data in the BreakHis data set. We have examined how the performances of balanced and unbalanced data sets change in detecting tumor type. In conclusion, in the study performed using the InceptionV3 convolution neural network model, 93.55% accuracy, 99.19% recall and 87.10% specificity values have been obtained for balanced data, while 89.75% accuracy, 82.89% recall and 91.51% specificity values have been obtained for unbalanced data. According to the results obtained in two different studies, the balance of the data increases the overall performance as well as the detection performance of both benign and malignant tumors. It can be said that the model trained with the help of data sets created in a balanced way will give pathology specialists higher and accurate results.

</p>
</details>

<details><summary><b>Debiased-CAM for bias-agnostic faithful visual explanations of deep convolutional networks</b>
<a href="https://arxiv.org/abs/2012.05567">arxiv:2012.05567</a>
&#x1F4C8; -1 <br>
<p>Wencan Zhang, Mariella Dimiccoli, Brian Y. Lim</p></summary>
<p>

**Abstract:** Class activation maps (CAMs) explain convolutional neural network predictions by identifying salient pixels, but they become misaligned and misleading when explaining predictions on images under bias, such as images blurred accidentally or deliberately for privacy protection, or images with improper white balance. Despite model fine-tuning to improve prediction performance on these biased images, we demonstrate that CAM explanations become more deviated and unfaithful with increased image bias. We present Debiased-CAM to recover explanation faithfulness across various bias types and levels by training a multi-input, multi-task model with auxiliary tasks for CAM and bias level predictions. With CAM as a prediction task, explanations are made tunable by retraining the main model layers and made faithful by self-supervised learning from CAMs of unbiased images. The model provides representative, bias-agnostic CAM explanations about the predictions on biased images as if generated from their unbiased form. In four simulation studies with different biases and prediction tasks, Debiased-CAM improved both CAM faithfulness and task performance. We further conducted two controlled user studies to validate its truthfulness and helpfulness, respectively. Quantitative and qualitative analyses of participant responses confirmed Debiased-CAM as more truthful and helpful. Debiased-CAM thus provides a basis to generate more faithful and relevant explanations for a wide range of real-world applications with various sources of bias.

</p>
</details>

<details><summary><b>Image Captioning with Context-Aware Auxiliary Guidance</b>
<a href="https://arxiv.org/abs/2012.05545">arxiv:2012.05545</a>
&#x1F4C8; -1 <br>
<p>Zeliang Song, Xiaofei Zhou, Zhendong Mao, Jianlong Tan</p></summary>
<p>

**Abstract:** Image captioning is a challenging computer vision task, which aims to generate a natural language description of an image. Most recent researches follow the encoder-decoder framework which depends heavily on the previous generated words for the current prediction. Such methods can not effectively take advantage of the future predicted information to learn complete semantics. In this paper, we propose Context-Aware Auxiliary Guidance (CAAG) mechanism that can guide the captioning model to perceive global contexts. Upon the captioning model, CAAG performs semantic attention that selectively concentrates on useful information of the global predictions to reproduce the current generation. To validate the adaptability of the method, we apply CAAG to three popular captioners and our proposal achieves competitive performance on the challenging Microsoft COCO image captioning benchmark, e.g. 132.2 CIDEr-D score on Karpathy split and 130.7 CIDEr-D (c40) score on official online evaluation server.

</p>
</details>

<details><summary><b>Approches quantitatives de l'analyse des pr{é}dictions en traduction automatique neuronale (TAN)</b>
<a href="https://arxiv.org/abs/2012.05541">arxiv:2012.05541</a>
&#x1F4C8; -1 <br>
<p>Maria Zimina-Poirot, Nicolas Ballier, Jean-Baptiste Yunès</p></summary>
<p>

**Abstract:** As part of a larger project on optimal learning conditions in neural machine translation, we investigate characteristic training phases of translation engines. All our experiments are carried out using OpenNMT-Py: the pre-processing step is implemented using the Europarl training corpus and the INTERSECT corpus is used for validation. Longitudinal analyses of training phases suggest that the progression of translations is not always linear. Following the results of textometric explorations, we identify the importance of the phenomena related to chronological progression, in order to map different processes at work in neural machine translation (NMT).

</p>
</details>

<details><summary><b>Effect of Different Batch Size Parameters on Predicting of COVID19 Cases</b>
<a href="https://arxiv.org/abs/2012.05534">arxiv:2012.05534</a>
&#x1F4C8; -1 <br>
<p>Ali Narin, Ziynet Pamuk</p></summary>
<p>

**Abstract:** The new coronavirus 2019, also known as COVID19, is a very serious epidemic that has killed thousands or even millions of people since December 2019. It was defined as a pandemic by the world health organization in March 2020. It is stated that this virus is usually transmitted by droplets caused by sneezing or coughing, or by touching infected surfaces. The presence of the virus is detected by real-time reverse transcriptase polymerase chain reaction (rRT-PCR) tests with the help of a swab taken from the nose or throat. In addition, X-ray and CT imaging methods are also used to support this method. Since it is known that the accuracy sensitivity in rRT-PCR test is low, auxiliary diagnostic methods have a very important place. Computer-aided diagnosis and detection systems are developed especially with the help of X-ray and CT images. Studies on the detection of COVID19 in the literature are increasing day by day. In this study, the effect of different batch size (BH=3, 10, 20, 30, 40, and 50) parameter values on their performance in detecting COVID19 and other classes was investigated using data belonging to 4 different (Viral Pneumonia, COVID19, Normal, Bacterial Pneumonia) classes. The study was carried out using a pre-trained ResNet50 convolutional neural network. According to the obtained results, they performed closely on the training and test data. However, it was observed that the steady state in the test data was delayed as the batch size value increased. The highest COVID19 detection was 95.17% for BH = 3, while the overall accuracy value was 97.97% with BH = 20. According to the findings, it can be said that the batch size value does not affect the overall performance significantly, but the increase in the batch size value delays obtaining stable results.

</p>
</details>

<details><summary><b>Data-Efficient Framework for Real-world Multiple Sound Source 2D Localization</b>
<a href="https://arxiv.org/abs/2012.05533">arxiv:2012.05533</a>
&#x1F4C8; -1 <br>
<p>Guillaume Le Moing, Phongtharin Vinayavekhin, Don Joven Agravante, Tadanobu Inoue, Jayakorn Vongkulbhisal, Asim Munawar, Ryuki Tachibana</p></summary>
<p>

**Abstract:** Deep neural networks have recently led to promising results for the task of multiple sound source localization. Yet, they require a lot of training data to cover a variety of acoustic conditions and microphone array layouts. One can leverage acoustic simulators to inexpensively generate labeled training data. However, models trained on synthetic data tend to perform poorly with real-world recordings due to the domain mismatch. Moreover, learning for different microphone array layouts makes the task more complicated due to the infinite number of possible layouts. We propose to use adversarial learning methods to close the gap between synthetic and real domains. Our novel ensemble-discrimination method significantly improves the localization performance without requiring any label from the real data. Furthermore, we propose a novel explicit transformation layer to be embedded in the localization architecture. It enables the model to be trained with data from specific microphone array layouts while generalizing well to unseen layouts during inference.

</p>
</details>

<details><summary><b>Detection of Covid-19 Patients with Convolutional Neural Network Based Features on Multi-class X-ray Chest Images</b>
<a href="https://arxiv.org/abs/2012.05525">arxiv:2012.05525</a>
&#x1F4C8; -1 <br>
<p>Ali Narin</p></summary>
<p>

**Abstract:** Covid-19 is a very serious deadly disease that has been announced as a pandemic by the world health organization (WHO). The whole world is working with all its might to end Covid-19 pandemic, which puts countries in serious health and economic problems, as soon as possible. The most important of these is to correctly identify those who get the Covid-19. Methods and approaches to support the reverse transcription polymerase chain reaction (RT-PCR) test have begun to take place in the literature. In this study, chest X-ray images, which can be accessed easily and quickly, were used because the covid-19 attacked the respiratory systems. Classification performances with support vector machines have been obtained by using the features extracted with residual networks (ResNet-50), one of the convolutional neural network models, from these images. While Covid-19 detection is obtained with support vector machines (SVM)-quadratic with the highest sensitivity value of 96.35% with the 5-fold cross-validation method, the highest overall performance value has been detected with both SVM-quadratic and SVM-cubic above 99%. According to these high results, it is thought that this method, which has been studied, will help radiology specialists and reduce the rate of false detection.

</p>
</details>

<details><summary><b>Explainable Link Prediction for Privacy-Preserving Contact Tracing</b>
<a href="https://arxiv.org/abs/2012.05516">arxiv:2012.05516</a>
&#x1F4C8; -1 <br>
<p>Balaji Ganesan, Hima Patel, Sameep Mehta</p></summary>
<p>

**Abstract:** Contact Tracing has been used to identify people who were in close proximity to those infected with SARS-Cov2 coronavirus. A number of digital contract tracing applications have been introduced to facilitate or complement physical contact tracing. However, there are a number of privacy issues in the implementation of contract tracing applications, which make people reluctant to install or update their infection status on these applications. In this concept paper, we present ideas from Graph Neural Networks and explainability, that could improve trust in these applications, and encourage adoption by people.

</p>
</details>

<details><summary><b>Learning Multiple Sound Source 2D Localization</b>
<a href="https://arxiv.org/abs/2012.05515">arxiv:2012.05515</a>
&#x1F4C8; -1 <br>
<p>Guillaume Le Moing, Phongtharin Vinayavekhin, Tadanobu Inoue, Jayakorn Vongkulbhisal, Asim Munawar, Ryuki Tachibana, Don Joven Agravante</p></summary>
<p>

**Abstract:** In this paper, we propose novel deep learning based algorithms for multiple sound source localization. Specifically, we aim to find the 2D Cartesian coordinates of multiple sound sources in an enclosed environment by using multiple microphone arrays. To this end, we use an encoding-decoding architecture and propose two improvements on it to accomplish the task. In addition, we also propose two novel localization representations which increase the accuracy. Lastly, new metrics are developed relying on resolution-based multiple source association which enables us to evaluate and compare different localization approaches. We tested our method on both synthetic and real world data. The results show that our method improves upon the previous baseline approach for this problem.

</p>
</details>

<details><summary><b>COVID-MTL: Multitask Learning with Shift3D and Random-weighted Loss for Automated Diagnosis and Severity Assessment of COVID-19</b>
<a href="https://arxiv.org/abs/2012.05509">arxiv:2012.05509</a>
&#x1F4C8; -1 <br>
<p>Guoqing Bao, Huai Chen, Tongliang Liu, Guanzhong Gong, Yong Yin, Lisheng Wang, Xiuying Wang</p></summary>
<p>

**Abstract:** There is an urgent need for automated methods to assist accurate and effective assessment of COVID-19. Radiology and nucleic acid test (NAT) are complementary COVID-19 diagnosis methods. In this paper, we present an end-to-end multitask learning (MTL) framework (COVID-MTL) that is capable of automated and simultaneous detection (against both radiology and NAT) and severity assessment of COVID-19. COVID-MTL learns different COVID-19 tasks in parallel through our novel random-weighted loss function, which assigns learning weights under Dirichlet distribution to prevent task dominance; our new 3D real-time augmentation algorithm (Shift3D) introduces space variances for 3D CNN components by shifting low-level feature representations of volumetric inputs in three dimensions; thereby, the MTL framework is able to accelerate convergence and improve joint learning performance compared to single-task models. By only using chest CT scans, COVID-MTL was trained on 930 CT scans and tested on separate 399 cases. COVID-MTL achieved AUCs of 0.939 and 0.846, and accuracies of 90.23% and 79.20% for detection of COVID-19 against radiology and NAT, respectively, which outperformed the state-of-the-art models. Meanwhile, COVID-MTL yielded AUC of 0.800 $\pm$ 0.020 and 0.813 $\pm$ 0.021 (with transfer learning) for classifying control/suspected, mild/regular, and severe/critically-ill cases. To decipher the recognition mechanism, we also identified high-throughput lung features that were significantly related (P < 0.001) to the positivity and severity of COVID-19.

</p>
</details>

<details><summary><b>On Shapley Credit Allocation for Interpretability</b>
<a href="https://arxiv.org/abs/2012.05506">arxiv:2012.05506</a>
&#x1F4C8; -1 <br>
<p>Debraj Basu</p></summary>
<p>

**Abstract:** We emphasize the importance of asking the right question when interpreting the decisions of a learning model. We discuss a natural extension of the theoretical machinery from Janzing et. al. 2020, which answers the question "Why did my model predict a person has cancer?" for answering a more involved question, "What caused my model to predict a person has cancer?" While the former quantifies the direct effects of variables on the model, the latter also accounts for indirect effects, thereby providing meaningful insights wherever human beings can reason in terms of cause and effect. We propose three broad categories for interpretations: observational, model-specific and causal each of which are significant in their own right. Furthermore, this paper quantifies feature relevance by weaving different natures of interpretations together with different measures as characteristic functions for Shapley symmetrization. Besides the widely used expected value of the model, we also discuss measures of statistical uncertainty and dispersion as informative candidates, and their merits in generating explanations for each data point, some of which are used in this context for the first time. These measures are not only useful for studying the influence of variables on the model output, but also on the predictive performance of the model, and for that we propose relevant characteristic functions that are also used for the first time.

</p>
</details>

<details><summary><b>Spatiotemporal Graph Neural Network based Mask Reconstruction for Video Object Segmentation</b>
<a href="https://arxiv.org/abs/2012.05499">arxiv:2012.05499</a>
&#x1F4C8; -1 <br>
<p>Daizong Liu, Shuangjie Xu, Xiao-Yang Liu, Zichuan Xu, Wei Wei, Pan Zhou</p></summary>
<p>

**Abstract:** This paper addresses the task of segmenting class-agnostic objects in semi-supervised setting. Although previous detection based methods achieve relatively good performance, these approaches extract the best proposal by a greedy strategy, which may lose the local patch details outside the chosen candidate. In this paper, we propose a novel spatiotemporal graph neural network (STG-Net) to reconstruct more accurate masks for video object segmentation, which captures the local contexts by utilizing all proposals. In the spatial graph, we treat object proposals of a frame as nodes and represent their correlations with an edge weight strategy for mask context aggregation. To capture temporal information from previous frames, we use a memory network to refine the mask of current frame by retrieving historic masks in a temporal graph. The joint use of both local patch details and temporal relationships allow us to better address the challenges such as object occlusion and missing. Without online learning and fine-tuning, our STG-Net achieves state-of-the-art performance on four large benchmarks (DAVIS, YouTube-VOS, SegTrack-v2, and YouTube-Objects), demonstrating the effectiveness of the proposed approach.

</p>
</details>

<details><summary><b>Machine learning for nocturnal diagnosis of chronic obstructive pulmonary disease using digital oximetry biomarkers</b>
<a href="https://arxiv.org/abs/2012.05492">arxiv:2012.05492</a>
&#x1F4C8; -1 <br>
<p>Jeremy Levy, Daniel Alvarez, Felix del Campo, Joachim A. Behar</p></summary>
<p>

**Abstract:** Objective: Chronic obstructive pulmonary disease (COPD) is a highly prevalent chronic condition. COPD is a major source of morbidity, mortality and healthcare costs. Spirometry is the gold standard test for a definitive diagnosis and severity grading of COPD. However, a large proportion of individuals with COPD are undiagnosed and untreated. Given the high prevalence of COPD and its clinical importance, it is critical to develop new algorithms to identify undiagnosed COPD, especially in specific groups at risk, such as those with sleep disorder breathing. To our knowledge, no research has looked at the feasibility of COPD diagnosis from the nocturnal oximetry time series. Approach: We hypothesize that patients with COPD will exert certain patterns and/or dynamics of their overnight oximetry time series that are unique to this condition. We introduce a novel approach to nocturnal COPD diagnosis using 44 oximetry digital biomarkers and 5 demographic features and assess its performance in a population sample at risk of sleep-disordered breathing. A total of n=350 unique patients polysomnography (PSG) recordings. A random forest (RF) classifier is trained using these features and evaluated using the nested cross-validation procedure. Significance: Our research makes a number of novel scientific contributions. First, we demonstrated for the first time, the feasibility of COPD diagnosis from nocturnal oximetry time series in a population sample at risk of sleep disordered breathing. We highlighted what digital oximetry biomarkers best reflect how COPD manifests overnight. The results motivate that overnight single channel oximetry is a valuable pathway for COPD diagnosis.

</p>
</details>

<details><summary><b>Urban Space Insights Extraction using Acoustic Histogram Information</b>
<a href="https://arxiv.org/abs/2012.05488">arxiv:2012.05488</a>
&#x1F4C8; -1 <br>
<p>Nipun Wijerathne, Billy Pik Lik Lau, Benny Kai Kiat Ng, Chau Yuen</p></summary>
<p>

**Abstract:** Urban data mining can be identified as a highly potential area that can enhance the smart city services towards better sustainable development especially in the urban residential activity tracking. While existing human activity tracking systems have demonstrated the capability to unveil the hidden aspects of citizens' behavior, they often come with a high implementation cost and require a large communication bandwidth. In this paper, we study the implementation of low-cost analogue sound sensors to detect outdoor activities and estimate the raining period in an urban residential area. The analogue sound sensors are transmitted to the cloud every 5 minutes in histogram format, which consists of sound data sampled every 100ms (10Hz). We then use wavelet transformation (WT) and principal component analysis (PCA) to generate a more robust and consistent feature set from the histogram. After that, we performed unsupervised clustering and attempt to understand the individual characteristics of each cluster to identify outdoor residential activities. In addition, on-site validation has been conducted to show the effectiveness of our approach.

</p>
</details>

<details><summary><b>One for More: Selecting Generalizable Samples for Generalizable ReID Model</b>
<a href="https://arxiv.org/abs/2012.05475">arxiv:2012.05475</a>
&#x1F4C8; -1 <br>
<p>Enwei Zhang, Xinyang Jiang, Hao Cheng, Ancong Wu, Fufu Yu, Ke Li, Xiaowei Guo, Feng Zheng, Wei-Shi Zheng, Xing Sun</p></summary>
<p>

**Abstract:** Current training objectives of existing person Re-IDentification (ReID) models only ensure that the loss of the model decreases on selected training batch, with no regards to the performance on samples outside the batch. It will inevitably cause the model to over-fit the data in the dominant position (e.g., head data in imbalanced class, easy samples or noisy samples). %We call the sample that updates the model towards generalizing on more data a generalizable sample. The latest resampling methods address the issue by designing specific criterion to select specific samples that trains the model generalize more on certain type of data (e.g., hard samples, tail data), which is not adaptive to the inconsistent real world ReID data distributions. Therefore, instead of simply presuming on what samples are generalizable, this paper proposes a one-for-more training objective that directly takes the generalization ability of selected samples as a loss function and learn a sampler to automatically select generalizable samples. More importantly, our proposed one-for-more based sampler can be seamlessly integrated into the ReID training framework which is able to simultaneously train ReID models and the sampler in an end-to-end fashion. The experimental results show that our method can effectively improve the ReID model training and boost the performance of ReID models.

</p>
</details>

<details><summary><b>Investigating Bias in Image Classification using Model Explanations</b>
<a href="https://arxiv.org/abs/2012.05463">arxiv:2012.05463</a>
&#x1F4C8; -1 <br>
<p>Schrasing Tong, Lalana Kagal</p></summary>
<p>

**Abstract:** We evaluated whether model explanations could efficiently detect bias in image classification by highlighting discriminating features, thereby removing the reliance on sensitive attributes for fairness calculations. To this end, we formulated important characteristics for bias detection and observed how explanations change as the degree of bias in models change. The paper identifies strengths and best practices for detecting bias using explanations, as well as three main weaknesses: explanations poorly estimate the degree of bias, could potentially introduce additional bias into the analysis, and are sometimes inefficient in terms of human effort involved.

</p>
</details>

<details><summary><b>Cold-start Sequential Recommendation via Meta Learner</b>
<a href="https://arxiv.org/abs/2012.05462">arxiv:2012.05462</a>
&#x1F4C8; -1 <br>
<p>Yujia Zheng, Siyi Liu, Zekun Li, Shu Wu</p></summary>
<p>

**Abstract:** This paper explores meta-learning in sequential recommendation to alleviate the item cold-start problem. Sequential recommendation aims to capture user's dynamic preferences based on historical behavior sequences and acts as a key component of most online recommendation scenarios. However, most previous methods have trouble recommending cold-start items, which are prevalent in those scenarios. As there is generally no side information in the setting of sequential recommendation task, previous cold-start methods could not be applied when only user-item interactions are available. Thus, we propose a Meta-learning-based Cold-Start Sequential Recommendation Framework, namely Mecos, to mitigate the item cold-start problem in sequential recommendation. This task is non-trivial as it targets at an important problem in a novel and challenging context. Mecos effectively extracts user preference from limited interactions and learns to match the target cold-start item with the potential user. Besides, our framework can be painlessly integrated with neural network-based models. Extensive experiments conducted on three real-world datasets verify the superiority of Mecos, with the average improvement up to 99%, 91%, and 70% in HR@10 over state-of-the-art baseline methods.

</p>
</details>

<details><summary><b>Neural-Swarm2: Planning and Control of Heterogeneous Multirotor Swarms using Learned Interactions</b>
<a href="https://arxiv.org/abs/2012.05457">arxiv:2012.05457</a>
&#x1F4C8; -1 <br>
<p>Guanya Shi, Wolfgang Hönig, Xichen Shi, Yisong Yue, Soon-Jo Chung</p></summary>
<p>

**Abstract:** We present Neural-Swarm2, a learning-based method for motion planning and control that allows heterogeneous multirotors in a swarm to safely fly in close proximity. Such operation for drones is challenging due to complex aerodynamic interaction forces, such as downwash generated by nearby drones and ground effect. Conventional planning and control methods neglect capturing these interaction forces, resulting in sparse swarm configuration during flight. Our approach combines a physics-based nominal dynamics model with learned Deep Neural Networks (DNNs) with strong Lipschitz properties. We evolve two techniques to accurately predict the aerodynamic interactions between heterogeneous multirotors: i) spectral normalization for stability and generalization guarantees of unseen data and ii) heterogeneous deep sets for supporting any number of heterogeneous neighbors in a permutation-invariant manner without reducing expressiveness. The learned residual dynamics benefit both the proposed interaction-aware multi-robot motion planning and the nonlinear tracking control designs because the learned interaction forces reduce the modelling errors. Experimental results demonstrate that Neural-Swarm2 is able to generalize to larger swarms beyond training cases and significantly outperforms a baseline nonlinear tracking controller with up to three times reduction in worst-case tracking errors.

</p>
</details>

<details><summary><b>T-WaveNet: Tree-Structured Wavelet Neural Network for Sensor-Based Time Series Analysis</b>
<a href="https://arxiv.org/abs/2012.05456">arxiv:2012.05456</a>
&#x1F4C8; -1 <br>
<p>Minhao Liu, Ailing Zeng, Qiuxia Lai, Qiang Xu</p></summary>
<p>

**Abstract:** Sensor-based time series analysis is an essential task for applications such as activity recognition and brain-computer interface. Recently, features extracted with deep neural networks (DNNs) are shown to be more effective than conventional hand-crafted ones. However, most of these solutions rely solely on the network to extract application-specific information carried in the sensor data. Motivated by the fact that usually a small subset of the frequency components carries the primary information for sensor data, we propose a novel tree-structured wavelet neural network for sensor data analysis, namely \emph{T-WaveNet}. To be specific, with T-WaveNet, we first conduct a power spectrum analysis for the sensor data and decompose the input signal into various frequency subbands accordingly. Then, we construct a tree-structured network, and each node on the tree (corresponding to a frequency subband) is built with an invertible neural network (INN) based wavelet transform. By doing so, T-WaveNet provides more effective representation for sensor information than existing DNN-based techniques, and it achieves state-of-the-art performance on various sensor datasets, including UCI-HAR for activity recognition, OPPORTUNITY for gesture recognition, BCICIV2a for intention recognition, and NinaPro DB1 for muscular movement recognition.

</p>
</details>

<details><summary><b>Causal-BERT : Language models for causality detection between events expressed in text</b>
<a href="https://arxiv.org/abs/2012.05453">arxiv:2012.05453</a>
&#x1F4C8; -1 <br>
<p>Vivek Khetan, Roshni Ramnani, Mayuresh Anand, Shubhashis Sengupta, Andrew E. Fano</p></summary>
<p>

**Abstract:** Causality understanding between events is a critical natural language processing task that is helpful in many areas, including health care, business risk management and finance. On close examination, one can find a huge amount of textual content both in the form of formal documents or in content arising from social media like Twitter, dedicated to communicating and exploring various types of causality in the real world. Recognizing these "Cause-Effect" relationships between natural language events continues to remain a challenge simply because it is often expressed implicitly. Implicit causality is hard to detect through most of the techniques employed in literature and can also, at times be perceived as ambiguous or vague. Also, although well-known datasets do exist for this problem, the examples in them are limited in the range and complexity of the causal relationships they depict especially when related to implicit relationships. Most of the contemporary methods are either based on lexico-semantic pattern matching or are feature-driven supervised methods. Therefore, as expected these methods are more geared towards handling explicit causal relationships leading to limited coverage for implicit relationships and are hard to generalize. In this paper, we investigate the language model's capabilities for causal association among events expressed in natural language text using sentence context combined with event information, and by leveraging masked event context with in-domain and out-of-domain data distribution. Our proposed methods achieve the state-of-art performance in three different data distributions and can be leveraged for extraction of a causal diagram and/or building a chain of events from unstructured text.

</p>
</details>
