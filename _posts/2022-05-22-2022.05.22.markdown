Prev: [2022.05.21]({{ '/2022/05/21/2022.05.21.html' | relative_url }})  Next: [2022.05.23]({{ '/2022/05/23/2022.05.23.html' | relative_url }})
{% raw %}
## Summary for 2022-05-22, created on 2022-05-29


<details><summary><b>CNNs are Myopic</b>
<a href="https://arxiv.org/abs/2205.10760">arxiv:2205.10760</a>
&#x1F4C8; 1490 <br>
<p>Vamshi C. Madala, Shivkumar Chandrasekaran</p></summary>
<p>

**Abstract:** We claim that Convolutional Neural Networks (CNNs) learn to classify images using only small seemingly unrecognizable tiles. We show experimentally that CNNs trained only using such tiles can match or even surpass the performance of CNNs trained on full images. Conversely, CNNs trained on full images show similar predictions on small tiles. We also propose the first a priori theoretical model for convolutional data sets that seems to explain this behavior. This gives additional support to the long standing suspicion that CNNs do not need to understand the global structure of images to achieve state-of-the-art accuracies. Surprisingly it also suggests that over-fitting is not needed either.

</p>
</details>

<details><summary><b>Limitations of a proposed correction for slow drifts in decision criterion</b>
<a href="https://arxiv.org/abs/2205.10912">arxiv:2205.10912</a>
&#x1F4C8; 23 <br>
<p>Diksha Gupta, Carlos D. Brody</p></summary>
<p>

**Abstract:** Trial history biases in decision-making tasks are thought to reflect systematic updates of decision variables, therefore their precise nature informs conclusions about underlying heuristic strategies and learning processes. However, random drifts in decision variables can corrupt this inference by mimicking the signatures of systematic updates. Hence, identifying the trial-by-trial evolution of decision variables requires methods that can robustly account for such drifts. Recent studies (Lak'20, Mendonça'20) have made important advances in this direction, by proposing a convenient method to correct for the influence of slow drifts in decision criterion, a key decision variable. Here we apply this correction to a variety of updating scenarios, and evaluate its performance. We show that the correction fails for a wide range of commonly assumed systematic updating strategies, distorting one's inference away from the veridical strategies towards a narrow subset. To address these limitations, we propose a model-based approach for disambiguating systematic updates from random drifts, and demonstrate its success on real and synthetic datasets. We show that this approach accurately recovers the latent trajectory of drifts in decision criterion as well as the generative systematic updates from simulated data. Our results offer recommendations for methods to account for the interactions between history biases and slow drifts, and highlight the advantages of incorporating assumptions about the generative process directly into models of decision-making.

</p>
</details>

<details><summary><b>Chain of Thought Imitation with Procedure Cloning</b>
<a href="https://arxiv.org/abs/2205.10816">arxiv:2205.10816</a>
&#x1F4C8; 21 <br>
<p>Mengjiao Yang, Dale Schuurmans, Pieter Abbeel, Ofir Nachum</p></summary>
<p>

**Abstract:** Imitation learning aims to extract high-performance policies from logged demonstrations of expert behavior. It is common to frame imitation learning as a supervised learning problem in which one fits a function approximator to the input-output mapping exhibited by the logged demonstrations (input observations to output actions). While the framing of imitation learning as a supervised input-output learning problem allows for applicability in a wide variety of settings, it is also an overly simplistic view of the problem in situations where the expert demonstrations provide much richer insight into expert behavior. For example, applications such as path navigation, robot manipulation, and strategy games acquire expert demonstrations via planning, search, or some other multi-step algorithm, revealing not just the output action to be imitated but also the procedure for how to determine this action. While these intermediate computations may use tools not available to the agent during inference (e.g., environment simulators), they are nevertheless informative as a way to explain an expert's mapping of state to actions. To properly leverage expert procedure information without relying on the privileged tools the expert may have used to perform the procedure, we propose procedure cloning, which applies supervised sequence prediction to imitate the series of expert computations. This way, procedure cloning learns not only what to do (i.e., the output action), but how and why to do it (i.e., the procedure). Through empirical analysis on navigation, simulated robotic manipulation, and game-playing environments, we show that imitating the intermediate computations of an expert's behavior enables procedure cloning to learn policies exhibiting significant generalization to unseen environment configurations, including those configurations for which running the expert's procedure directly is infeasible.

</p>
</details>

<details><summary><b>What Do Compressed Multilingual Machine Translation Models Forget?</b>
<a href="https://arxiv.org/abs/2205.10828">arxiv:2205.10828</a>
&#x1F4C8; 10 <br>
<p>Alireza Mohammadshahi, Vassilina Nikoulina, Alexandre Berard, Caroline Brun, James Henderson, Laurent Besacier</p></summary>
<p>

**Abstract:** Recently, very large pre-trained models achieve state-of-the-art results in various natural language processing (NLP) tasks, but their size makes it more challenging to apply them in resource-constrained environments. Compression techniques allow to drastically reduce the size of the model and therefore its inference time with negligible impact on top-tier metrics. However, the general performance hides a drastic performance drop on under-represented features, which could result in the amplification of biases encoded by the model. In this work, we analyze the impacts of compression methods on Multilingual Neural Machine Translation models (MNMT) for various language groups and semantic features by extensive analysis of compressed models on different NMT benchmarks, e.g. FLORES-101, MT-Gender, and DiBiMT. Our experiments show that the performance of under-represented languages drops significantly, while the average BLEU metric slightly decreases. Interestingly, the removal of noisy memorization with the compression leads to a significant improvement for some medium-resource languages. Finally, we demonstrate that the compression amplifies intrinsic gender and semantic biases, even in high-resource languages.

</p>
</details>

<details><summary><b>Language Models with Image Descriptors are Strong Few-Shot Video-Language Learners</b>
<a href="https://arxiv.org/abs/2205.10747">arxiv:2205.10747</a>
&#x1F4C8; 10 <br>
<p>Zhenhailong Wang, Manling Li, Ruochen Xu, Luowei Zhou, Jie Lei, Xudong Lin, Shuohang Wang, Ziyi Yang, Chenguang Zhu, Derek Hoiem, Shih-Fu Chang, Mohit Bansal, Heng Ji</p></summary>
<p>

**Abstract:** The goal of this work is to build flexible video-language models that can generalize to various video-to-text tasks from few examples, such as domain-specific captioning, question answering, and future event prediction. Existing few-shot video-language learners focus exclusively on the encoder, resulting in the absence of a video-to-text decoder to handle generative tasks. Video captioners have been pretrained on large-scale video-language datasets, but they rely heavily on finetuning and lack the ability to generate text for unseen tasks in a few-shot setting. We propose VidIL, a few-shot Video-language Learner via Image and Language models, which demonstrates strong performance on few-shot video-to-text tasks without the necessity of pretraining or finetuning on any video datasets. We use the image-language models to translate the video content into frame captions, object, attribute, and event phrases, and compose them into a temporal structure template. We then instruct a language model, with a prompt containing a few in-context examples, to generate a target output from the composed content. The flexibility of prompting allows the model to capture any form of text input, such as automatic speech recognition (ASR) transcripts. Our experiments demonstrate the power of language models in understanding videos on a wide variety of video-language tasks, including video captioning, video question answering, video caption retrieval, and video future event prediction. Especially, on video future event prediction, our few-shot model significantly outperforms state-of-the-art supervised models trained on large-scale video datasets. Code and resources are publicly available for research purposes at https://github.com/MikeWangWZHL/VidIL .

</p>
</details>

<details><summary><b>Do Deep Learning Models and News Headlines Outperform Conventional Prediction Techniques on Forex Data?</b>
<a href="https://arxiv.org/abs/2205.10743">arxiv:2205.10743</a>
&#x1F4C8; 9 <br>
<p>Sucharita Atha, Bharath Kumar Bolla</p></summary>
<p>

**Abstract:** Foreign Exchange (FOREX) is a decentralised global market for exchanging currencies. The Forex market is enormous, and it operates 24 hours a day. Along with country-specific factors, Forex trading is influenced by cross-country ties and a variety of global events. Recent pandemic scenarios such as COVID19 and local elections can also have a significant impact on market pricing. We tested and compared various predictions with external elements such as news items in this work. Additionally, we compared classical machine learning methods to deep learning algorithms. We also added sentiment features from news headlines using NLP-based word embeddings and compared the performance. Our results indicate that simple regression model like linear, SGD, and Bagged performed better than deep learning models such as LSTM and RNN for single-step forecasting like the next two hours, the next day, and seven days. Surprisingly, news articles failed to improve the predictions indicating domain-based and relevant information only adds value. Among the text vectorization techniques, Word2Vec and SentenceBERT perform better.

</p>
</details>

<details><summary><b>Global Extreme Heat Forecasting Using Neural Weather Models</b>
<a href="https://arxiv.org/abs/2205.10972">arxiv:2205.10972</a>
&#x1F4C8; 7 <br>
<p>Ignacio Lopez-Gomez, Amy McGovern, Shreya Agrawal, Jason Hickey</p></summary>
<p>

**Abstract:** Heat waves are projected to increase in frequency and severity with global warming. Improved warning systems would help reduce the associated loss of lives, wildfires, power disruptions, and reduction in crop yields. In this work, we explore the potential for deep learning systems trained on historical data to forecast extreme heat on short, medium and subseasonal timescales. To this purpose, we train a set of neural weather models (NWMs) with convolutional architectures to forecast surface temperature anomalies globally, 1 to 28 days ahead, at $\sim200~\mathrm{km}$ resolution and on the cubed sphere. The NWMs are trained using the ERA5 reanalysis product and a set of candidate loss functions, including the mean squared error and exponential losses targeting extremes. We find that training models to minimize custom losses tailored to emphasize extremes leads to significant skill improvements in the heat wave prediction task, compared to NWMs trained on the mean squared error loss. This improvement is accomplished with almost no skill reduction in the general temperature prediction task, and it can be efficiently realized through transfer learning, by re-training NWMs with the custom losses for a few epochs. In addition, we find that the use of a symmetric exponential loss reduces the smoothing of NWM forecasts with lead time. Our best NWM is able to outperform persistence in a regressive sense for all lead times and temperature anomaly thresholds considered, and shows positive regressive skill compared to the ECMWF subseasonal-to-seasonal control forecast within the first two forecast days and after two weeks.

</p>
</details>

<details><summary><b>Cardiomegaly Detection using Deep Convolutional Neural Network with U-Net</b>
<a href="https://arxiv.org/abs/2205.11515">arxiv:2205.11515</a>
&#x1F4C8; 5 <br>
<p>Soham S. Sarpotdar</p></summary>
<p>

**Abstract:** Cardiomegaly is indeed a medical disease in which the heart is enlarged. Cardiomegaly is better to handle if caught early, so early detection is critical. The chest X-ray, being one of the most often used radiography examinations, has been used to detect and visualize abnormalities of human organs for decades. X-ray is also a significant medical diagnosis tool for cardiomegaly. Even for domain experts, distinguishing the many types of diseases from the X-ray is a difficult and time-consuming task. Deep learning models are also most effective when used on huge data sets, yet due to privacy concerns, large datasets are rarely available inside the medical industry. A Deep learning-based customized retrained U-Net model for detecting Cardiomegaly disease is presented in this research. In the training phase, chest X-ray images from the "ChestX-ray8" open source real dataset are used. To reduce computing time, this model performs data preprocessing, picture improvement, image compression, and classification before moving on to the training step. The work used a chest x-ray image dataset to simulate and produced a diagnostic accuracy of 94%, a sensitivity of 96.2 percent, and a specificity of 92.5 percent, which beats prior pre-trained model findings for identifying Cardiomegaly disease.

</p>
</details>

<details><summary><b>muNet: Evolving Pretrained Deep Neural Networks into Scalable Auto-tuning Multitask Systems</b>
<a href="https://arxiv.org/abs/2205.10937">arxiv:2205.10937</a>
&#x1F4C8; 5 <br>
<p>Andrea Gesmundo, Jeff Dean</p></summary>
<p>

**Abstract:** Most uses of machine learning today involve training a model from scratch for a particular task, or sometimes starting with a model pretrained on a related task and then fine-tuning on a downstream task. Both approaches offer limited knowledge transfer between different tasks, time-consuming human-driven customization to individual tasks and high computational costs especially when starting from randomly initialized models. We propose a method that uses the layers of a pretrained deep neural network as building blocks to construct an ML system that can jointly solve an arbitrary number of tasks. The resulting system can leverage cross tasks knowledge transfer, while being immune from common drawbacks of multitask approaches such as catastrophic forgetting, gradients interference and negative transfer. We define an evolutionary approach designed to jointly select the prior knowledge relevant for each task, choose the subset of the model parameters to train and dynamically auto-tune its hyperparameters. Furthermore, a novel scale control method is employed to achieve quality/size trade-offs that outperform common fine-tuning techniques. Compared with standard fine-tuning on a benchmark of 10 diverse image classification tasks, the proposed model improves the average accuracy by 2.39% while using 47% less parameters per task.

</p>
</details>

<details><summary><b>Contrastive Learning of Coarse-Grained Force Fields</b>
<a href="https://arxiv.org/abs/2205.10861">arxiv:2205.10861</a>
&#x1F4C8; 5 <br>
<p>Xinqiang Ding, Bin Zhang</p></summary>
<p>

**Abstract:** Coarse-grained models have proven helpful for simulating complex systems over long timescales to provide molecular insights into various processes. Methodologies for systematic parameterization of the underlying energy function, or force field that describes the interactions among different components of the system are of great interest for ensuring simulation accuracy. We present a new method, potential contrasting, to enable efficient learning of force fields that can accurately reproduce the conformational distribution produced with all-atom simulations. Potential contrasting generalizes the noise contrastive estimation method with umbrella sampling to better learn the complex energy landscape of molecular systems. When applied to the Trp-cage protein, we found that the technique produces force fields that thoroughly capture the thermodynamics of the folding process despite the use of only $α$-Carbons in the coarse-grained model. We further showed that potential contrasting could be applied over large datasets that combine the conformational ensembles of many proteins to ensure the transferability of coarse-grained force fields. We anticipate potential contrasting to be a powerful tool for building general-purpose coarse-grained force fields.

</p>
</details>

<details><summary><b>A Graph Enhanced BERT Model for Event Prediction</b>
<a href="https://arxiv.org/abs/2205.10822">arxiv:2205.10822</a>
&#x1F4C8; 5 <br>
<p>Li Du, Xiao Ding, Yue Zhang, Kai Xiong, Ting Liu, Bing Qin</p></summary>
<p>

**Abstract:** Predicting the subsequent event for an existing event context is an important but challenging task, as it requires understanding the underlying relationship between events. Previous methods propose to retrieve relational features from event graph to enhance the modeling of event correlation. However, the sparsity of event graph may restrict the acquisition of relevant graph information, and hence influence the model performance. To address this issue, we consider automatically building of event graph using a BERT model. To this end, we incorporate an additional structured variable into BERT to learn to predict the event connections in the training process. Hence, in the test process, the connection relationship for unseen events can be predicted by the structured variable. Results on two event prediction tasks: script event prediction and story ending prediction, show that our approach can outperform state-of-the-art baseline methods.

</p>
</details>

<details><summary><b>AutoJoin: Efficient Adversarial Training for Robust Maneuvering via Denoising Autoencoder and Joint Learning</b>
<a href="https://arxiv.org/abs/2205.10933">arxiv:2205.10933</a>
&#x1F4C8; 4 <br>
<p>Michael Villarreal, Bibek Poudel, Ryan Wickman, Yu Shen, Weizi Li</p></summary>
<p>

**Abstract:** As a result of increasingly adopted machine learning algorithms and ubiquitous sensors, many 'perception-to-control' systems have been deployed in various settings. For these systems to be trustworthy, we need to improve their robustness with adversarial training being one approach. In this work, we propose a gradient-free adversarial training technique, called AutoJoin. AutoJoin is a very simple yet effective and efficient approach to produce robust models for imaged-based autonomous maneuvering. Compared to other SOTA methods with testing on over 5M perturbed and clean images, AutoJoin achieves significant performance increases up to the 40% range under perturbed datasets while improving on clean performance for almost every dataset tested. In particular, AutoJoin can triple the clean performance improvement compared to the SOTA work by Shen et al. Regarding efficiency, AutoJoin demonstrates strong advantages over other SOTA techniques by saving up to 83% time per training epoch and 90% training data. The core idea of AutoJoin is to use a decoder attachment to the original regression model creating a denoising autoencoder within the architecture. This allows the tasks 'steering' and 'denoising sensor input' to be jointly learnt and enable the two tasks to reinforce each other's performance.

</p>
</details>

<details><summary><b>Fast Instrument Learning with Faster Rates</b>
<a href="https://arxiv.org/abs/2205.10772">arxiv:2205.10772</a>
&#x1F4C8; 4 <br>
<p>Ziyu Wang, Yuhao Zhou, Jun Zhu</p></summary>
<p>

**Abstract:** We investigate nonlinear instrumental variable (IV) regression given high-dimensional instruments. We propose a simple algorithm which combines kernelized IV methods and an arbitrary, adaptive regression algorithm, accessed as a black box. Our algorithm enjoys faster-rate convergence and adapts to the dimensionality of informative latent features, while avoiding an expensive minimax optimization procedure, which has been necessary to establish similar guarantees. It further brings the benefit of flexible machine learning models to quasi-Bayesian uncertainty quantification, likelihood-based model selection, and model averaging. Simulation studies demonstrate the competitive performance of our method.

</p>
</details>

<details><summary><b>Evidence for Hypodescent in Visual Semantic AI</b>
<a href="https://arxiv.org/abs/2205.10764">arxiv:2205.10764</a>
&#x1F4C8; 4 <br>
<p>Robert Wolfe, Mahzarin R. Banaji, Aylin Caliskan</p></summary>
<p>

**Abstract:** We examine the state-of-the-art multimodal "visual semantic" model CLIP ("Contrastive Language Image Pretraining") for the rule of hypodescent, or one-drop rule, whereby multiracial people are more likely to be assigned a racial or ethnic label corresponding to a minority or disadvantaged racial or ethnic group than to the equivalent majority or advantaged group. A face morphing experiment grounded in psychological research demonstrating hypodescent indicates that, at the midway point of 1,000 series of morphed images, CLIP associates 69.7% of Black-White female images with a Black text label over a White text label, and similarly prefers Latina (75.8%) and Asian (89.1%) text labels at the midway point for Latina-White female and Asian-White female morphs, reflecting hypodescent. Additionally, assessment of the underlying cosine similarities in the model reveals that association with White is correlated with association with "person," with Pearson's rho as high as 0.82 over a 21,000-image morph series, indicating that a White person corresponds to the default representation of a person in CLIP. Finally, we show that the stereotype-congruent pleasantness association of an image correlates with association with the Black text label in CLIP, with Pearson's rho = 0.48 for 21,000 Black-White multiracial male images, and rho = 0.41 for Black-White multiracial female images. CLIP is trained on English-language text gathered using data collected from an American website (Wikipedia), and our findings demonstrate that CLIP embeds the values of American racial hierarchy, reflecting the implicit and explicit beliefs that are present in human minds. We contextualize these findings within the history and psychology of hypodescent. Overall, the data suggests that AI supervised using natural language will, unless checked, learn biases that reflect racial hierarchies.

</p>
</details>

<details><summary><b>Deep Feature Fusion via Graph Convolutional Network for Intracranial Artery Labeling</b>
<a href="https://arxiv.org/abs/2205.10757">arxiv:2205.10757</a>
&#x1F4C8; 4 <br>
<p>Yaxin Zhu, Peisheng Qian, Ziyuan Zhao, Zeng Zeng</p></summary>
<p>

**Abstract:** Intracranial arteries are critical blood vessels that supply the brain with oxygenated blood. Intracranial artery labels provide valuable guidance and navigation to numerous clinical applications and disease diagnoses. Various machine learning algorithms have been carried out for automation in the anatomical labeling of cerebral arteries. However, the task remains challenging because of the high complexity and variations of intracranial arteries. This study investigates a novel graph convolutional neural network with deep feature fusion for cerebral artery labeling. We introduce stacked graph convolutions in an encoder-core-decoder architecture, extracting high-level representations from graph nodes and their neighbors. Furthermore, we efficiently aggregate intermediate features from different hierarchies to enhance the proposed model's representation capability and labeling performance. We perform extensive experiments on public datasets, in which the results prove the superiority of our approach over baselines by a clear margin.

</p>
</details>

<details><summary><b>Body Composition Estimation Based on Multimodal Multi-task Deep Neural Network</b>
<a href="https://arxiv.org/abs/2205.11031">arxiv:2205.11031</a>
&#x1F4C8; 3 <br>
<p>Subas Chhatkuli, Iris Jiang, Kyohei Kamiyama</p></summary>
<p>

**Abstract:** In addition to body weight and Body Mass Index (BMI), body composition is an essential data point that allows people to understand their overall health and body fitness. However, body composition is largely made up of muscle, fat, bones, and water, which makes estimation not as easy and straightforward as measuring body weight. In this paper, we introduce a multimodal multi-task deep neural network to estimate body fat percentage and skeletal muscle mass by analyzing facial images in addition to a person's height, gender, age, and weight information. Using a dataset representative of demographics in Japan, we confirmed that the proposed approach performed better compared to the existing methods. Moreover, the multi-task approach implemented in this study is also able to grasp the negative correlation between body fat percentage and skeletal muscle mass gain/loss.

</p>
</details>

<details><summary><b>Flexible and Hierarchical Prior for Bayesian Nonnegative Matrix Factorization</b>
<a href="https://arxiv.org/abs/2205.11025">arxiv:2205.11025</a>
&#x1F4C8; 3 <br>
<p>Jun Lu, Xuanyu Ye</p></summary>
<p>

**Abstract:** In this paper, we introduce a probabilistic model for learning nonnegative matrix factorization (NMF) that is commonly used for predicting missing values and finding hidden patterns in the data, in which the matrix factors are latent variables associated with each data dimension. The nonnegativity constraint for the latent factors is handled by choosing priors with support on the nonnegative subspace. Bayesian inference procedure based on Gibbs sampling is employed. We evaluate the model on several real-world datasets including MovieLens 100K and MovieLens 1M with different sizes and dimensions and show that the proposed Bayesian NMF GRRN model leads to better predictions and avoids overfitting compared to existing Bayesian NMF approaches.

</p>
</details>

<details><summary><b>Efficient Reinforcement Learning from Demonstration Using Local Ensemble and Reparameterization with Split and Merge of Expert Policies</b>
<a href="https://arxiv.org/abs/2205.11019">arxiv:2205.11019</a>
&#x1F4C8; 3 <br>
<p>Yu Wang, Fang Liu</p></summary>
<p>

**Abstract:** The current work on reinforcement learning (RL) from demonstrations often assumes the demonstrations are samples from an optimal policy, an unrealistic assumption in practice. When demonstrations are generated by sub-optimal policies or have sparse state-action pairs, policy learned from sub-optimal demonstrations may mislead an agent with incorrect or non-local action decisions. We propose a new method called Local Ensemble and Reparameterization with Split and Merge of expert policies (LEARN-SAM) to improve efficiency and make better use of the sub-optimal demonstrations. First, LEARN-SAM employs a new concept, the lambda-function, based on a discrepancy measure between the current state to demonstrated states to "localize" the weights of the expert policies during learning. Second, LEARN-SAM employs a split-and-merge (SAM) mechanism by separating the helpful parts in each expert demonstration and regrouping them into new expert policies to use the demonstrations selectively. Both the lambda-function and SAM mechanism help boost the learning speed. Theoretically, we prove the invariant property of reparameterized policy before and after the SAM mechanism, providing theoretical guarantees for the convergence of the employed policy gradient method. We demonstrate the superiority of the LEARN-SAM method and its robustness with varying demonstration quality and sparsity in six experiments on complex continuous control problems of low to high dimensions, compared to existing methods on RL from demonstration.

</p>
</details>

<details><summary><b>Nonparametric learning of kernels in nonlocal operators</b>
<a href="https://arxiv.org/abs/2205.11006">arxiv:2205.11006</a>
&#x1F4C8; 3 <br>
<p>Fei Lu, Qingci An, Yue Yu</p></summary>
<p>

**Abstract:** Nonlocal operators with integral kernels have become a popular tool for designing solution maps between function spaces, due to their efficiency in representing long-range dependence and the attractive feature of being resolution-invariant. In this work, we provide a rigorous identifiability analysis and convergence study for the learning of kernels in nonlocal operators. It is found that the kernel learning is an ill-posed or even ill-defined inverse problem, leading to divergent estimators in the presence of modeling errors or measurement noises. To resolve this issue, we propose a nonparametric regression algorithm with a novel data adaptive RKHS Tikhonov regularization method based on the function space of identifiability. The method yields a noisy-robust convergent estimator of the kernel as the data resolution refines, on both synthetic and real-world datasets. In particular, the method successfully learns a homogenized model for the stress wave propagation in a heterogeneous solid, revealing the unknown governing laws from real-world data at microscale. Our regularization method outperforms baseline methods in robustness, generalizability and accuracy.

</p>
</details>

<details><summary><b>Boosting Multi-Label Image Classification with Complementary Parallel Self-Distillation</b>
<a href="https://arxiv.org/abs/2205.10986">arxiv:2205.10986</a>
&#x1F4C8; 3 <br>
<p>Jiazhi Xu, Sheng Huang, Fengtao Zhou, Luwen Huangfu, Daniel Zeng, Bo Liu</p></summary>
<p>

**Abstract:** Multi-Label Image Classification (MLIC) approaches usually exploit label correlations to achieve good performance. However, emphasizing correlation like co-occurrence may overlook discriminative features of the target itself and lead to model overfitting, thus undermining the performance. In this study, we propose a generic framework named Parallel Self-Distillation (PSD) for boosting MLIC models. PSD decomposes the original MLIC task into several simpler MLIC sub-tasks via two elaborated complementary task decomposition strategies named Co-occurrence Graph Partition (CGP) and Dis-occurrence Graph Partition (DGP). Then, the MLIC models of fewer categories are trained with these sub-tasks in parallel for respectively learning the joint patterns and the category-specific patterns of labels. Finally, knowledge distillation is leveraged to learn a compact global ensemble of full categories with these learned patterns for reconciling the label correlation exploitation and model overfitting. Extensive results on MS-COCO and NUS-WIDE datasets demonstrate that our framework can be easily plugged into many MLIC approaches and improve performances of recent state-of-the-art approaches. The explainable visual study also further validates that our method is able to learn both the category-specific and co-occurring features. The source code is released at https://github.com/Robbie-Xu/CPSD.

</p>
</details>

<details><summary><b>An Automated System for Detecting Visual Damages of Wind Turbine Blades</b>
<a href="https://arxiv.org/abs/2205.10954">arxiv:2205.10954</a>
&#x1F4C8; 3 <br>
<p>Linh Nguyen, Akshay Iyer, Shweta Khushu</p></summary>
<p>

**Abstract:** Wind energy's ability to compete with fossil fuels on a market level depends on lowering wind's high operational costs. Since damages on wind turbine blades are the leading cause for these operational problems, identifying blade damages is critical. However, recent works in visual identification of blade damages are still experimental and focus on optimizing the traditional machine learning metrics such as IoU. In this paper, we argue that pushing models to production long before achieving the "optimal" model performance can still generate real value for this use case. We discuss the performance of our damage's suggestion model in production and how this system works in coordination with humans as part of a commercialized product and how it can contribute towards lowering wind energy's operational costs.

</p>
</details>

<details><summary><b>CYRUS Soccer Simulation 2D Team Description Paper 2022</b>
<a href="https://arxiv.org/abs/2205.10953">arxiv:2205.10953</a>
&#x1F4C8; 3 <br>
<p>Nader Zare, Arad Firouzkouhi, Omid Amini, Mahtab Sarvmaili, Aref Sayareh, Saba Ramezani Rad, Stan Matwin, Amilcar Soares</p></summary>
<p>

**Abstract:** Soccer Simulation 2D League is one of the major leagues of RoboCup competitions. In a Soccer Simulation 2D (SS2D) game, two teams of 11 players and one coach compete against each other. The players are only allowed to communicate with the server that is called Soccer Simulation Server. This paper introduces the previous and current research of the CYRUS soccer simulation team, the champion of RoboCup 2021. We will present our idea about improving Unmarking Decisioning and Positioning by using Pass Prediction Deep Neural Network. Based on our experimental results, this idea proven to be effective on increasing the winning rate of Cyrus against opponents.

</p>
</details>

<details><summary><b>Deep Discriminative Direct Decoders for High-dimensional Time-series Analysis</b>
<a href="https://arxiv.org/abs/2205.10947">arxiv:2205.10947</a>
&#x1F4C8; 3 <br>
<p>Mohammad R. Rezaei, Milos R. Popovic, Milad Lankarany, Ali Yousefi</p></summary>
<p>

**Abstract:** Dynamical latent variable modeling has been significantly invested over the last couple of decades with established solutions encompassing generative processes like the state-space model (SSM) and discriminative processes like a recurrent or a deep neural network (DNN). These solutions are powerful tools with promising results; however, surprisingly they were never put together in a unified model to analyze complex multivariate time-series data. A very recent modeling approach, called the direct discriminative decoder (DDD) model, proposes a principal solution to combine SMM and DNN models, with promising results in decoding underlying latent processes, e.g. rat movement trajectory, through high-dimensional neural recordings. The DDD consists of a) a state transition process, as per the classical dynamical models, and b) a discriminative process, like DNN, in which the conditional distribution of states is defined as a function of the current observations and their recent history. Despite promising results of the DDD model, no training solutions, in the context of DNN, have been utilized for this model. Here, we propose how DNN parameters along with an optimal history term can be simultaneously estimated as a part of the DDD model. We use the D4 abbreviation for a DDD with a DNN as its discriminative process. We showed the D4 decoding performance in both simulation and (relatively) high-dimensional neural data. In both datasets, D4 performance surpasses the state-of-art decoding solutions, including those of SSM and DNNs. The key success of DDD and potentially D4 is efficient utilization of the recent history of observation along with the state-process that carries long-term information, which is not addressed in either SSM or DNN solutions. We argue that D4 can be a powerful tool for the analysis of high-dimensional time-series data.

</p>
</details>

<details><summary><b>On Elimination Strategies for Bandit Fixed-Confidence Identification</b>
<a href="https://arxiv.org/abs/2205.10936">arxiv:2205.10936</a>
&#x1F4C8; 3 <br>
<p>Andrea Tirinzoni, Rémy Degenne</p></summary>
<p>

**Abstract:** Elimination algorithms for bandit identification, which prune the plausible correct answers sequentially until only one remains, are computationally convenient since they reduce the problem size over time. However, existing elimination strategies are often not fully adaptive (they update their sampling rule infrequently) and are not easy to extend to combinatorial settings, where the set of answers is exponentially large in the problem dimension. On the other hand, most existing fully-adaptive strategies to tackle general identification problems are computationally demanding since they repeatedly test the correctness of every answer, without ever reducing the problem size. We show that adaptive methods can be modified to use elimination in both their stopping and sampling rules, hence obtaining the best of these two worlds: the algorithms (1) remain fully adaptive, (2) suffer a sample complexity that is never worse of their non-elimination counterpart, and (3) provably eliminate certain wrong answers early. We confirm these benefits experimentally, where elimination improves significantly the computational complexity of adaptive methods on common tasks like best-arm identification in linear bandits.

</p>
</details>

<details><summary><b>Argumentative Explanations for Pattern-Based Text Classifiers</b>
<a href="https://arxiv.org/abs/2205.10932">arxiv:2205.10932</a>
&#x1F4C8; 3 <br>
<p>Piyawat Lertvittayakumjorn, Francesca Toni</p></summary>
<p>

**Abstract:** Recent works in Explainable AI mostly address the transparency issue of black-box models or create explanations for any kind of models (i.e., they are model-agnostic), while leaving explanations of interpretable models largely underexplored. In this paper, we fill this gap by focusing on explanations for a specific interpretable model, namely pattern-based logistic regression (PLR) for binary text classification. We do so because, albeit interpretable, PLR is challenging when it comes to explanations. In particular, we found that a standard way to extract explanations from this model does not consider relations among the features, making the explanations hardly plausible to humans. Hence, we propose AXPLR, a novel explanation method using (forms of) computational argumentation to generate explanations (for outputs computed by PLR) which unearth model agreements and disagreements among the features. Specifically, we use computational argumentation as follows: we see features (patterns) in PLR as arguments in a form of quantified bipolar argumentation frameworks (QBAFs) and extract attacks and supports between arguments based on specificity of the arguments; we understand logistic regression as a gradual semantics for these QBAFs, used to determine the arguments' dialectic strength; and we study standard properties of gradual semantics for QBAFs in the context of our argumentative re-interpretation of PLR, sanctioning its suitability for explanatory purposes. We then show how to extract intuitive explanations (for outputs computed by PLR) from the constructed QBAFs. Finally, we conduct an empirical evaluation and two experiments in the context of human-AI collaboration to demonstrate the advantages of our resulting AXPLR method.

</p>
</details>

<details><summary><b>Fast ABC-Boost: A Unified Framework for Selecting the Base Class in Multi-Class Classification</b>
<a href="https://arxiv.org/abs/2205.10927">arxiv:2205.10927</a>
&#x1F4C8; 3 <br>
<p>Ping Li, Weijie Zhao</p></summary>
<p>

**Abstract:** The work in ICML'09 showed that the derivatives of the classical multi-class logistic regression loss function could be re-written in terms of a pre-chosen "base class" and applied the new derivatives in the popular boosting framework. In order to make use of the new derivatives, one must have a strategy to identify/choose the base class at each boosting iteration. The idea of "adaptive base class boost" (ABC-Boost) in ICML'09, adopted a computationally expensive "exhaustive search" strategy for the base class at each iteration. It has been well demonstrated that ABC-Boost, when integrated with trees, can achieve substantial improvements in many multi-class classification tasks. Furthermore, the work in UAI'10 derived the explicit second-order tree split gain formula which typically improved the classification accuracy considerably, compared with using only the fist-order information for tree-splitting, for both multi-class and binary-class classification tasks.
In this paper, we develop a unified framework for effectively selecting the base class by introducing a series of ideas to improve the computational efficiency of ABC-Boost. Our framework has parameters $(s,g,w)$. At each boosting iteration, we only search for the "$s$-worst classes" (instead of all classes) to determine the base class. We also allow a "gap" $g$ when conducting the search. That is, we only search for the base class at every $g+1$ iterations. We furthermore allow a "warm up" stage by only starting the search after $w$ boosting iterations. The parameters $s$, $g$, $w$, can be viewed as tunable parameters and certain combinations of $(s,g,w)$ may even lead to better test accuracy than the "exhaustive search" strategy. Overall, our proposed framework provides a robust and reliable scheme for implementing ABC-Boost in practice.

</p>
</details>

<details><summary><b>Weisfeiler and Leman Go Walking: Random Walk Kernels Revisited</b>
<a href="https://arxiv.org/abs/2205.10914">arxiv:2205.10914</a>
&#x1F4C8; 3 <br>
<p>Nils M. Kriege</p></summary>
<p>

**Abstract:** Random walk kernels have been introduced in seminal work on graph learning and were later largely superseded by kernels based on the Weisfeiler-Leman test for graph isomorphism. We give a unified view on both classes of graph kernels. We study walk-based node refinement methods and formally relate them to several widely-used techniques, including Morgan's algorithm for molecule canonization and the Weisfeiler-Leman test. We define corresponding walk-based kernels on nodes that allow fine-grained parameterized neighborhood comparison, reach Weisfeiler-Leman expressiveness, and are computed using the kernel trick. From this we show that classical random walk kernels with only minor modifications regarding definition and computation are as expressive as the widely-used Weisfeiler-Leman subtree kernel but support non-strict neighborhood comparison. We verify experimentally that walk-based kernels reach or even surpass the accuracy of Weisfeiler-Leman kernels in real-world classification tasks.

</p>
</details>

<details><summary><b>Improved Modeling of Persistence Diagram</b>
<a href="https://arxiv.org/abs/2205.10907">arxiv:2205.10907</a>
&#x1F4C8; 3 <br>
<p>Sarit Agami</p></summary>
<p>

**Abstract:** High-dimensional reduction methods are powerful tools for describing the main patterns in big data. One of these methods is the topological data analysis (TDA), which modeling the shape of the data in terms of topological properties. This method specifically translates the original data into two-dimensional system, which is graphically represented via the 'persistence diagram'. The outliers points on this diagram present the data pattern, whereas the other points behave as a random noise. In order to determine which points are significant outliers, replications of the original data set are needed. Once only one original data is available, replications can be created by fitting a model for the points on the persistence diagram, and then using the MCMC methods. One of such model is the RST (Replicating Statistical Topology). In this paper we suggest a modification of the RST model. Using a simulation study, we show that the modified RST improves the performance of the RST in terms of goodness of fit. We use the MCMC Metropolis-Hastings algorithm for sampling according to the fitted model.

</p>
</details>

<details><summary><b>Visual Explanations from Deep Networks via Riemann-Stieltjes Integrated Gradient-based Localization</b>
<a href="https://arxiv.org/abs/2205.10900">arxiv:2205.10900</a>
&#x1F4C8; 3 <br>
<p>Mirtha Lucas, Miguel Lerma, Jacob Furst, Daniela Raicu</p></summary>
<p>

**Abstract:** Neural networks are becoming increasingly better at tasks that involve classifying and recognizing images. At the same time techniques intended to explain the network output have been proposed. One such technique is the Gradient-based Class Activation Map (Grad-CAM), which is able to locate features of an input image at various levels of a convolutional neural network (CNN), but is sensitive to the vanishing gradients problem. There are techniques such as Integrated Gradients (IG), that are not affected by that problem, but its use is limited to the input layer of a network. Here we introduce a new technique to produce visual explanations for the predictions of a CNN. Like Grad-CAM, our method can be applied to any layer of the network, and like Integrated Gradients it is not affected by the problem of vanishing gradients. For efficiency, gradient integration is performed numerically at the layer level using a Riemann-Stieltjes sum approximation. Compared to Grad-CAM, heatmaps produced by our algorithm are better focused in the areas of interest, and their numerical computation is more stable. Our code is available at https://github.com/mlerma54/RSIGradCAM

</p>
</details>

<details><summary><b>Contextual Information-Directed Sampling</b>
<a href="https://arxiv.org/abs/2205.10895">arxiv:2205.10895</a>
&#x1F4C8; 3 <br>
<p>Botao Hao, Tor Lattimore, Chao Qin</p></summary>
<p>

**Abstract:** Information-directed sampling (IDS) has recently demonstrated its potential as a data-efficient reinforcement learning algorithm. However, it is still unclear what is the right form of information ratio to optimize when contextual information is available. We investigate the IDS design through two contextual bandit problems: contextual bandits with graph feedback and sparse linear contextual bandits. We provably demonstrate the advantage of contextual IDS over conditional IDS and emphasize the importance of considering the context distribution. The main message is that an intelligent agent should invest more on the actions that are beneficial for the future unseen contexts while the conditional IDS can be myopic. We further propose a computationally-efficient version of contextual IDS based on Actor-Critic and evaluate it empirically on a neural network contextual bandit.

</p>
</details>

<details><summary><b>Fast Gaussian Process Posterior Mean Prediction via Local Cross Validation and Precomputation</b>
<a href="https://arxiv.org/abs/2205.10879">arxiv:2205.10879</a>
&#x1F4C8; 3 <br>
<p>Alec M. Dunton, Benjamin W. Priest, Amanda Muyskens</p></summary>
<p>

**Abstract:** Gaussian processes (GPs) are Bayesian non-parametric models useful in a myriad of applications. Despite their popularity, the cost of GP predictions (quadratic storage and cubic complexity with respect to the number of training points) remains a hurdle in applying GPs to large data. We present a fast posterior mean prediction algorithm called FastMuyGPs to address this shortcoming. FastMuyGPs is based upon the MuyGPs hyperparameter estimation algorithm and utilizes a combination of leave-one-out cross-validation, batching, nearest neighbors sparsification, and precomputation to provide scalable, fast GP prediction. We demonstrate several benchmarks wherein FastMuyGPs prediction attains superior accuracy and competitive or superior runtime to both deep neural networks and state-of-the-art scalable GP algorithms.

</p>
</details>

<details><summary><b>Fusion Subspace Clustering for Incomplete Data</b>
<a href="https://arxiv.org/abs/2205.10872">arxiv:2205.10872</a>
&#x1F4C8; 3 <br>
<p>Usman Mahmood, Daniel Pimentel-Alarcón</p></summary>
<p>

**Abstract:** This paper introduces {\em fusion subspace clustering}, a novel method to learn low-dimensional structures that approximate large scale yet highly incomplete data. The main idea is to assign each datum to a subspace of its own, and minimize the distance between the subspaces of all data, so that subspaces of the same cluster get {\em fused} together. Our method allows low, high, and even full-rank data; it directly accounts for noise, and its sample complexity approaches the information-theoretic limit. In addition, our approach provides a natural model selection {\em clusterpath}, and a direct completion method. We give convergence guarantees, analyze computational complexity, and show through extensive experiments on real and synthetic data that our approach performs comparably to the state-of-the-art with complete data, and dramatically better if data is missing.

</p>
</details>

<details><summary><b>Federated Learning Aggregation: New Robust Algorithms with Guarantees</b>
<a href="https://arxiv.org/abs/2205.10864">arxiv:2205.10864</a>
&#x1F4C8; 3 <br>
<p>Adnan Ben Mansour, Gaia Carenini, Alexandre Duplessis, David Naccache</p></summary>
<p>

**Abstract:** Federated Learning has been recently proposed for distributed model training at the edge. The principle of this approach is to aggregate models learned on distributed clients to obtain a new more general "average" model (FedAvg). The resulting model is then redistributed to clients for further training. To date, the most popular federated learning algorithm uses coordinate-wise averaging of the model parameters for aggregation. In this paper, we carry out a complete general mathematical convergence analysis to evaluate aggregation strategies in a federated learning framework. From this, we derive novel aggregation algorithms which are able to modify their model architecture by differentiating client contributions according to the value of their losses. Moreover, we go beyond the assumptions introduced in theory, by evaluating the performance of these strategies and by comparing them with the one of FedAvg in classification tasks in both the IID and the Non-IID framework without additional hypothesis.

</p>
</details>

<details><summary><b>RVAE-LAMOL: Residual Variational Autoencoder to Enhance Lifelong Language Learning</b>
<a href="https://arxiv.org/abs/2205.10857">arxiv:2205.10857</a>
&#x1F4C8; 3 <br>
<p>Han Wang, Ruiliu Fu, Xuejun Zhang, Jun Zhou</p></summary>
<p>

**Abstract:** Lifelong Language Learning (LLL) aims to train a neural network to learn a stream of NLP tasks while retaining knowledge from previous tasks. However, previous works which followed data-free constraint still suffer from catastrophic forgetting issue, where the model forgets what it just learned from previous tasks. In order to alleviate catastrophic forgetting, we propose the residual variational autoencoder (RVAE) to enhance LAMOL, a recent LLL model, by mapping different tasks into a limited unified semantic space. In this space, previous tasks are easy to be correct to their own distribution by pseudo samples. Furthermore, we propose an identity task to make the model is discriminative to recognize the sample belonging to which task. For training RVAE-LAMOL better, we propose a novel training scheme Alternate Lag Training. In the experiments, we test RVAE-LAMOL on permutations of three datasets from DecaNLP. The experimental results demonstrate that RVAE-LAMOL outperforms naïve LAMOL on all permutations and generates more meaningful pseudo-samples.

</p>
</details>

<details><summary><b>Addressing Strategic Manipulation Disparities in Fair Classification</b>
<a href="https://arxiv.org/abs/2205.10842">arxiv:2205.10842</a>
&#x1F4C8; 3 <br>
<p>Vijay Keswani, L. Elisa Celis</p></summary>
<p>

**Abstract:** In real-world classification settings, individuals respond to classifier predictions by updating their features to increase their likelihood of receiving a particular (positive) decision (at a certain cost). Yet, when different demographic groups have different feature distributions or different cost functions, prior work has shown that individuals from minority groups often pay a higher cost to update their features. Fair classification aims to address such classifier performance disparities by constraining the classifiers to satisfy statistical fairness properties. However, we show that standard fairness constraints do not guarantee that the constrained classifier reduces the disparity in strategic manipulation cost. To address such biases in strategic settings and provide equal opportunities for strategic manipulation, we propose a constrained optimization framework that constructs classifiers that lower the strategic manipulation cost for the minority groups. We develop our framework by studying theoretical connections between group-specific strategic cost disparity and standard selection rate fairness metrics (e.g., statistical rate and true positive rate). Empirically, we show the efficacy of this approach over multiple real-world datasets.

</p>
</details>

<details><summary><b>Self-supervised U-net for few-shot learning of object segmentation in microscopy images</b>
<a href="https://arxiv.org/abs/2205.10840">arxiv:2205.10840</a>
&#x1F4C8; 3 <br>
<p>Arnaud Deleruyelle, Cristian Versari, John Klein</p></summary>
<p>

**Abstract:** State-of-the-art segmentation performances are achieved by deep neural networks. Training these networks from only a few training examples is challenging while producing annotated images that provide supervision is tedious. Recently, self-supervision, i.e. designing a neural pipeline providing synthetic or indirect supervision, has proved to significantly increase generalization performances of models trained on few shots. This paper introduces one such neural pipeline in the context of microscopic image segmentation. By leveraging the rather simple content of these images a trainee network can be mentored by a referee network which has been previously trained on synthetically generated pairs of corrupted/correct region masks.

</p>
</details>

<details><summary><b>Grad-CAM++ is Equivalent to Grad-CAM With Positive Gradients</b>
<a href="https://arxiv.org/abs/2205.10838">arxiv:2205.10838</a>
&#x1F4C8; 3 <br>
<p>Miguel Lerma, Mirtha Lucas</p></summary>
<p>

**Abstract:** The Grad-CAM algorithm provides a way to identify what parts of an image contribute most to the output of a classifier deep network. The algorithm is simple and widely used for localization of objects in an image, although some researchers have point out its limitations, and proposed various alternatives. One of them is Grad-CAM++, that according to its authors can provide better visual explanations for network predictions, and does a better job at locating objects even for occurrences of multiple object instances in a single image. Here we show that Grad-CAM++ is practically equivalent to a very simple variation of Grad-CAM in which gradients are replaced with positive gradients.

</p>
</details>

<details><summary><b>PAC-Wrap: Semi-Supervised PAC Anomaly Detection</b>
<a href="https://arxiv.org/abs/2205.10798">arxiv:2205.10798</a>
&#x1F4C8; 3 <br>
<p>Shuo Li, Xiayan Ji, Edgar Dobriban, Oleg Sokolsky, Insup Lee</p></summary>
<p>

**Abstract:** Anomaly detection is essential for preventing hazardous outcomes for safety-critical applications like autonomous driving. Given their safety-criticality, these applications benefit from provable bounds on various errors in anomaly detection. To achieve this goal in the semi-supervised setting, we propose to provide Probably Approximately Correct (PAC) guarantees on the false negative and false positive detection rates for anomaly detection algorithms. Our method (PAC-Wrap) can wrap around virtually any existing semi-supervised and unsupervised anomaly detection method, endowing it with rigorous guarantees. Our experiments with various anomaly detectors and datasets indicate that PAC-Wrap is broadly effective.

</p>
</details>

<details><summary><b>A Dirichlet Process Mixture of Robust Task Models for Scalable Lifelong Reinforcement Learning</b>
<a href="https://arxiv.org/abs/2205.10787">arxiv:2205.10787</a>
&#x1F4C8; 3 <br>
<p>Zhi Wang, Chunlin Chen, Daoyi Dong</p></summary>
<p>

**Abstract:** While reinforcement learning (RL) algorithms are achieving state-of-the-art performance in various challenging tasks, they can easily encounter catastrophic forgetting or interference when faced with lifelong streaming information. In the paper, we propose a scalable lifelong RL method that dynamically expands the network capacity to accommodate new knowledge while preventing past memories from being perturbed. We use a Dirichlet process mixture to model the non-stationary task distribution, which captures task relatedness by estimating the likelihood of task-to-cluster assignments and clusters the task models in a latent space. We formulate the prior distribution of the mixture as a Chinese restaurant process (CRP) that instantiates new mixture components as needed. The update and expansion of the mixture are governed by the Bayesian non-parametric framework with an expectation maximization (EM) procedure, which dynamically adapts the model complexity without explicit task boundaries or heuristics. Moreover, we use the domain randomization technique to train robust prior parameters for the initialization of each task model in the mixture, thus the resulting model can better generalize and adapt to unseen tasks. With extensive experiments conducted on robot navigation and locomotion domains, we show that our method successfully facilitates scalable lifelong RL and outperforms relevant existing methods.

</p>
</details>

<details><summary><b>A Domain-adaptive Pre-training Approach for Language Bias Detection in News</b>
<a href="https://arxiv.org/abs/2205.10773">arxiv:2205.10773</a>
&#x1F4C8; 3 <br>
<p>Jan-David Krieger, Timo Spinde, Terry Ruas, Juhi Kulshrestha, Bela Gipp</p></summary>
<p>

**Abstract:** Media bias is a multi-faceted construct influencing individual behavior and collective decision-making. Slanted news reporting is the result of one-sided and polarized writing which can occur in various forms. In this work, we focus on an important form of media bias, i.e. bias by word choice. Detecting biased word choices is a challenging task due to its linguistic complexity and the lack of representative gold-standard corpora. We present DA-RoBERTa, a new state-of-the-art transformer-based model adapted to the media bias domain which identifies sentence-level bias with an F1 score of 0.814. In addition, we also train, DA-BERT and DA-BART, two more transformer models adapted to the bias domain. Our proposed domain-adapted models outperform prior bias detection approaches on the same data.

</p>
</details>

<details><summary><b>Sequential/Session-based Recommendations: Challenges, Approaches, Applications and Opportunities</b>
<a href="https://arxiv.org/abs/2205.10759">arxiv:2205.10759</a>
&#x1F4C8; 3 <br>
<p>Shoujin Wang, Qi Zhang, Liang Hu, Xiuzhen Zhang, Yan Wang, Charu Aggarwal</p></summary>
<p>

**Abstract:** In recent years, sequential recommender systems (SRSs) and session-based recommender systems (SBRSs) have emerged as a new paradigm of RSs to capture users' short-term but dynamic preferences for enabling more timely and accurate recommendations. Although SRSs and SBRSs have been extensively studied, there are many inconsistencies in this area caused by the diverse descriptions, settings, assumptions and application domains. There is no work to provide a unified framework and problem statement to remove the commonly existing and various inconsistencies in the area of SR/SBR. There is a lack of work to provide a comprehensive and systematic demonstration of the data characteristics, key challenges, most representative and state-of-the-art approaches, typical real-world applications and important future research directions in the area. This work aims to fill in these gaps so as to facilitate further research in this exciting and vibrant area.

</p>
</details>

<details><summary><b>Residual Channel Attention Network for Brain Glioma Segmentation</b>
<a href="https://arxiv.org/abs/2205.10758">arxiv:2205.10758</a>
&#x1F4C8; 3 <br>
<p>Yiming Yao, Peisheng Qian, Ziyuan Zhao, Zeng Zeng</p></summary>
<p>

**Abstract:** A glioma is a malignant brain tumor that seriously affects cognitive functions and lowers patients' life quality. Segmentation of brain glioma is challenging because of interclass ambiguities in tumor regions. Recently, deep learning approaches have achieved outstanding performance in the automatic segmentation of brain glioma. However, existing algorithms fail to exploit channel-wise feature interdependence to select semantic attributes for glioma segmentation. In this study, we implement a novel deep neural network that integrates residual channel attention modules to calibrate intermediate features for glioma segmentation. The proposed channel attention mechanism adaptively weights feature channel-wise to optimize the latent representation of gliomas. We evaluate our method on the established dataset BraTS2017. Experimental results indicate the superiority of our method.

</p>
</details>

<details><summary><b>Covariance Matrix Adaptation MAP-Annealing</b>
<a href="https://arxiv.org/abs/2205.10752">arxiv:2205.10752</a>
&#x1F4C8; 3 <br>
<p>Matthew C. Fontaine, Stefanos Nikolaidis</p></summary>
<p>

**Abstract:** Single-objective optimization algorithms search for the single highest-quality solution with respect to an objective. In contrast, quality diversity (QD) optimization algorithms, such as Covariance Matrix Adaptation MAP-Elites (CMA-ME), search for a collection of solutions that are both high-quality with respect to an objective and diverse with respect to specified measure functions. We propose a new quality diversity algorithm, Covariance Matrix Adaptation MAP-Annealing (CMA-MAE), which bridges the gap between single-objective optimization and QD optimization. We prove that CMA-MAE smoothly blends between the Covariance Matrix Adaptation Evolution Strategy (CMA-ES) single-objective optimizer and CMA-ME by gradually annealing a discount function with a scalar learning rate. We show that CMA-MAE has better performance than the current state-of-the-art QD algorithms on several benchmark domains and that its performance is empirically invariant to the archive resolution and robust to the discount function learning rate.

</p>
</details>

<details><summary><b>Classification of Quasars, Galaxies, and Stars in the Mapping of the Universe Multi-modal Deep Learning</b>
<a href="https://arxiv.org/abs/2205.10745">arxiv:2205.10745</a>
&#x1F4C8; 3 <br>
<p>Sabeesh Ethiraj, Bharath Kumar Bolla</p></summary>
<p>

**Abstract:** In this paper, the fourth version the Sloan Digital Sky Survey (SDSS-4), Data Release 16 dataset was used to classify the SDSS dataset into galaxies, stars, and quasars using machine learning and deep learning architectures. We efficiently utilize both image and metadata in tabular format to build a novel multi-modal architecture and achieve state-of-the-art results. In addition, our experiments on transfer learning using Imagenet weights on five different architectures (Resnet-50, DenseNet-121 VGG-16, Xception, and EfficientNet) reveal that freezing all layers and adding a final trainable layer may not be an optimal solution for transfer learning. It is hypothesized that higher the number of trainable layers, higher will be the training time and accuracy of predictions. It is also hypothesized that any subsequent increase in the number of training layers towards the base layers will not increase in accuracy as the pre trained lower layers only help in low level feature extraction which would be quite similar in all the datasets. Hence the ideal level of trainable layers needs to be identified for each model in respect to the number of parameters. For the tabular data, we compared classical machine learning algorithms (Logistic Regression, Random Forest, Decision Trees, Adaboost, LightGBM etc.,) with artificial neural networks. Our works shed new light on transfer learning and multi-modal deep learning architectures. The multi-modal architecture not only resulted in higher metrics (accuracy, precision, recall, F1 score) than models using only image data or tabular data. Furthermore, multi-modal architecture achieved the best metrics in lesser training epochs and improved the metrics on all classes.

</p>
</details>

<details><summary><b>All Birds with One Stone: Multi-task Text Classification for Efficient Inference with One Forward Pass</b>
<a href="https://arxiv.org/abs/2205.10744">arxiv:2205.10744</a>
&#x1F4C8; 3 <br>
<p>Jiaxin Huang, Tianqi Liu, Jialu Liu, Adam D. Lelkes, Cong Yu, Jiawei Han</p></summary>
<p>

**Abstract:** Multi-Task Learning (MTL) models have shown their robustness, effectiveness, and efficiency for transferring learned knowledge across tasks. In real industrial applications such as web content classification, multiple classification tasks are predicted from the same input text such as a web article. However, at the serving time, the existing multitask transformer models such as prompt or adaptor based approaches need to conduct N forward passes for N tasks with O(N) computation cost. To tackle this problem, we propose a scalable method that can achieve stronger performance with close to O(1) computation cost via only one forward pass. To illustrate real application usage, we release a multitask dataset on news topic and style classification. Our experiments show that our proposed method outperforms strong baselines on both the GLUE benchmark and our news dataset. Our code and dataset are publicly available at https://bit.ly/mtop-code.

</p>
</details>

<details><summary><b>HessianFR: An Efficient Hessian-based Follow-the-Ridge Algorithm for Minimax Optimization</b>
<a href="https://arxiv.org/abs/2205.11030">arxiv:2205.11030</a>
&#x1F4C8; 2 <br>
<p>Yihang Gao, Huafeng Liu, Michael K. Ng, Mingjie Zhou</p></summary>
<p>

**Abstract:** Wide applications of differentiable two-player sequential games (e.g., image generation by GANs) have raised much interest and attention of researchers to study efficient and fast algorithms. Most of the existing algorithms are developed based on nice properties of simultaneous games, i.e., convex-concave payoff functions, but are not applicable in solving sequential games with different settings. Some conventional gradient descent ascent algorithms theoretically and numerically fail to find the local Nash equilibrium of the simultaneous game or the local minimax (i.e., local Stackelberg equilibrium) of the sequential game. In this paper, we propose the HessianFR, an efficient Hessian-based Follow-the-Ridge algorithm with theoretical guarantees. Furthermore, the convergence of the stochastic algorithm and the approximation of Hessian inverse are exploited to improve algorithm efficiency. A series of experiments of training generative adversarial networks (GANs) have been conducted on both synthetic and real-world large-scale image datasets (e.g. MNIST, CIFAR-10 and CelebA). The experimental results demonstrate that the proposed HessianFR outperforms baselines in terms of convergence and image generation quality.

</p>
</details>

<details><summary><b>Distance-Sensitive Offline Reinforcement Learning</b>
<a href="https://arxiv.org/abs/2205.11027">arxiv:2205.11027</a>
&#x1F4C8; 2 <br>
<p>Jianxiong Li, Xianyuan Zhan, Haoran Xu, Xiangyu Zhu, Jingjing Liu, Ya-Qin Zhang</p></summary>
<p>

**Abstract:** In offline reinforcement learning (RL), one detrimental issue to policy learning is the error accumulation of deep Q function in out-of-distribution (OOD) areas. Unfortunately, existing offline RL methods are often over-conservative, inevitably hurting generalization performance outside data distribution. In our study, one interesting observation is that deep Q functions approximate well inside the convex hull of training data. Inspired by this, we propose a new method, DOGE (Distance-sensitive Offline RL with better GEneralization). DOGE marries dataset geometry with deep function approximators in offline RL, and enables exploitation in generalizable OOD areas rather than strictly constraining policy within data distribution. Specifically, DOGE trains a state-conditioned distance function that can be readily plugged into standard actor-critic methods as a policy constraint. Simple yet elegant, our algorithm enjoys better generalization compared to state-of-the-art methods on D4RL benchmarks. Theoretical analysis demonstrates the superiority of our approach to existing methods that are solely based on data distribution or support constraints.

</p>
</details>

<details><summary><b>Data-Efficient Modeling for Precise Power Consumption Estimation of Quadrotor Operations Using Ensemble Learning</b>
<a href="https://arxiv.org/abs/2205.10997">arxiv:2205.10997</a>
&#x1F4C8; 2 <br>
<p>Wei Dai, Mingcheng Zhang, Kin Huat Low</p></summary>
<p>

**Abstract:** Electric Take-Off and Landing (eVTOL) aircraft is considered as the major aircraft type in the emerging urban air mobility. Accurate power consumption estimation is crucial to eVTOL, supporting advanced power management strategies and improving the efficiency and safety performance of flight operations. In this study, a framework for power consumption modeling of eVTOL aircraft was established. We employed an ensemble learning method, namely stacking, to develop a data-driven model using flight records of three different types of quadrotors. Random forest and extreme gradient boosting, showing advantages in prediction, were chosen as base-models, and a linear regression model was used as the meta-model. The established stacking model can accurately estimate the power of a quadrotor. Error analysis shows that about 80% prediction errors fall within one standard deviation interval and less than 0.5% error in the prediction for an entire flight can be expected with a confidence of more than 80%. Our model outperforms the existing models in two aspects: firstly, our model has a better prediction performance, and secondly, our model is more data-efficient, requiring a much smaller dataset. Our model provides a powerful tool for operators of eVTOL aircraft in mission management and contributes to promoting safe and energy-efficient urban air traffic.

</p>
</details>

<details><summary><b>Neural Subgraph Explorer: Reducing Noisy Information via Target-Oriented Syntax Graph Pruning</b>
<a href="https://arxiv.org/abs/2205.10970">arxiv:2205.10970</a>
&#x1F4C8; 2 <br>
<p>Bowen Xing, Ivor W. Tsang</p></summary>
<p>

**Abstract:** Recent years have witnessed the emerging success of leveraging syntax graphs for the target sentiment classification task. However, we discover that existing syntax-based models suffer from two issues: noisy information aggregation and loss of distant correlations. In this paper, we propose a novel model termed Neural Subgraph Explorer, which (1) reduces the noisy information via pruning target-irrelevant nodes on the syntax graph; (2) introduces beneficial first-order connections between the target and its related words into the obtained graph. Specifically, we design a multi-hop actions score estimator to evaluate the value of each word regarding the specific target. The discrete action sequence is sampled through Gumble-Softmax and then used for both of the syntax graph and the self-attention graph. To introduce the first-order connections between the target and its relevant words, the two pruned graphs are merged. Finally, graph convolution is conducted on the obtained unified graph to update the hidden states. And this process is stacked with multiple layers. To our knowledge, this is the first attempt of target-oriented syntax graph pruning in this task. Experimental results demonstrate the superiority of our model, which achieves new state-of-the-art performance.

</p>
</details>

<details><summary><b>Incentivizing Federated Learning</b>
<a href="https://arxiv.org/abs/2205.10951">arxiv:2205.10951</a>
&#x1F4C8; 2 <br>
<p>Shuyu Kong, You Li, Hai Zhou</p></summary>
<p>

**Abstract:** Federated Learning is an emerging distributed collaborative learning paradigm used by many of applications nowadays. The effectiveness of federated learning relies on clients' collective efforts and their willingness to contribute local data. However, due to privacy concerns and the costs of data collection and model training, clients may not always contribute all the data they possess, which would negatively affect the performance of the global model. This paper presents an incentive mechanism that encourages clients to contribute as much data as they can obtain. Unlike previous incentive mechanisms, our approach does not monetize data. Instead, we implicitly use model performance as a reward, i.e., significant contributors are paid off with better models. We theoretically prove that clients will use as much data as they can possibly possess to participate in federated learning under certain conditions with our incentive mechanism

</p>
</details>

<details><summary><b>Toward smart composites: small-scale, untethered prediction and control for soft sensor/actuator systems</b>
<a href="https://arxiv.org/abs/2205.10940">arxiv:2205.10940</a>
&#x1F4C8; 2 <br>
<p>Sarah Aguasvivas Manzano, Vani Sundaram, Artemis Xu, Khoi Ly, Mark Rentschler, Robert Shepherd, Nikolaus Correll</p></summary>
<p>

**Abstract:** We present a suite of algorithms and tools for model-predictive control of sensor/actuator systems with embedded microcontroller units (MCU). These MCUs can be colocated with sensors and actuators, thereby enabling a new class of smart composites capable of autonomous behavior that does not require an external computer. In this approach, kinematics are learned using a neural network model from offline data and compiled into MCU code using nn4mc, an open-source tool. Online Newton-Raphson optimization solves for the control input. Shallow neural network models applied to 1D sensor signals allow for reduced model sizes and increased control loop frequencies. We validate this approach on a simulated mass-spring-damper system and two experimental setups with different sensing, actuation, and computational hardware: a tendon-based platform with embedded optical lace sensors and a HASEL-based platform with magnetic sensors. Experimental results indicate effective high-bandwidth tracking of reference paths (120 Hz and higher) with a small memory footprint (less than or equal to 6.4% of available flash). The measured path following error does not exceed 2 mm in the tendon-based platform, and the predicted path following error does not exceed 1 mm in the HASEL-based platform. This controller code's mean power consumption in an ARM Cortex-M4 computer is 45.4 mW. This control approach is also compatible with Tensorflow Lite models and equivalent compilers. Embedded intelligence in composite materials enables a new class of composites that infuse intelligence into structures and systems, making them capable of responding to environmental stimuli using their proprioception.

</p>
</details>

<details><summary><b>Monitoring of Perception Systems: Deterministic, Probabilistic, and Learning-based Fault Detection and Identification</b>
<a href="https://arxiv.org/abs/2205.10906">arxiv:2205.10906</a>
&#x1F4C8; 2 <br>
<p>Pasquale Antonante, Heath Nilsen, Luca Carlone</p></summary>
<p>

**Abstract:** This paper investigates runtime monitoring of perception systems. Perception is a critical component of high-integrity applications of robotics and autonomous systems, such as self-driving cars. In these applications, failure of perception systems may put human life at risk, and a broad adoption of these technologies requires the development of methodologies to guarantee and monitor safe operation. Despite the paramount importance of perception, currently there is no formal approach for system-level perception monitoring. In this paper, we formalize the problem of runtime fault detection and identification in perception systems and present a framework to model diagnostic information using a diagnostic graph. We then provide a set of deterministic, probabilistic, and learning-based algorithms that use diagnostic graphs to perform fault detection and identification. Moreover, we investigate fundamental limits and provide deterministic and probabilistic guarantees on the fault detection and identification results. We conclude the paper with an extensive experimental evaluation, which recreates several realistic failure modes in the LGSVL open-source autonomous driving simulator, and applies the proposed system monitors to a state-of-the-art autonomous driving software stack (Baidu's Apollo Auto). The results show that the proposed system monitors outperform baselines, have the potential of preventing accidents in realistic autonomous driving scenarios, and incur a negligible computational overhead.

</p>
</details>

<details><summary><b>Nonparametric likelihood-free inference with Jensen-Shannon divergence for simulator-based models with categorical output</b>
<a href="https://arxiv.org/abs/2205.10890">arxiv:2205.10890</a>
&#x1F4C8; 2 <br>
<p>Jukka Corander, Ulpu Remes, Ida Holopainen, Timo Koski</p></summary>
<p>

**Abstract:** Likelihood-free inference for simulator-based statistical models has recently attracted a surge of interest, both in the machine learning and statistics communities. The primary focus of these research fields has been to approximate the posterior distribution of model parameters, either by various types of Monte Carlo sampling algorithms or deep neural network -based surrogate models. Frequentist inference for simulator-based models has been given much less attention to date, despite that it would be particularly amenable to applications with big data where implicit asymptotic approximation of the likelihood is expected to be accurate and can leverage computationally efficient strategies. Here we derive a set of theoretical results to enable estimation, hypothesis testing and construction of confidence intervals for model parameters using asymptotic properties of the Jensen--Shannon divergence. Such asymptotic approximation offers a rapid alternative to more computation-intensive approaches and can be attractive for diverse applications of simulator-based models. 61

</p>
</details>

<details><summary><b>Improving AMD diagnosis by the simultaneous identification of associated retinal lesions</b>
<a href="https://arxiv.org/abs/2205.10885">arxiv:2205.10885</a>
&#x1F4C8; 2 <br>
<p>José Morano, Álvaro S. Hervella, José Rouco, Jorge Novo, José I. Fernández-Vigo, Marcos Ortega</p></summary>
<p>

**Abstract:** Age-related Macular Degeneration (AMD) is the predominant cause of blindness in developed countries, specially in elderly people. Moreover, its prevalence is increasing due to the global population ageing. In this scenario, early detection is crucial to avert later vision impairment. Nonetheless, implementing large-scale screening programmes is usually not viable, since the population at-risk is large and the analysis must be performed by expert clinicians. Also, the diagnosis of AMD is considered to be particularly difficult, as it is characterized by many different lesions that, in many cases, resemble those of other macular diseases. To overcome these issues, several works have proposed automatic methods for the detection of AMD in retinography images, the most widely used modality for the screening of the disease. Nowadays, most of these works use Convolutional Neural Networks (CNNs) for the binary classification of images into AMD and non-AMD classes. In this work, we propose a novel approach based on CNNs that simultaneously performs AMD diagnosis and the classification of its potential lesions. This latter secondary task has not yet been addressed in this domain, and provides complementary useful information that improves the diagnosis performance and helps understanding the decision. A CNN model is trained using retinography images with image-level labels for both AMD and lesion presence, which are relatively easy to obtain. The experiments conducted in several public datasets show that the proposed approach improves the detection of AMD, while achieving satisfactory results in the identification of most lesions.

</p>
</details>

<details><summary><b>Memory-efficient Reinforcement Learning with Knowledge Consolidation</b>
<a href="https://arxiv.org/abs/2205.10868">arxiv:2205.10868</a>
&#x1F4C8; 2 <br>
<p>Qingfeng Lan, Yangchen Pan, Jun Luo, A. Rupam Mahmood</p></summary>
<p>

**Abstract:** Artificial neural networks are promising as general function approximators but challenging to train on non-independent and identically distributed data due to catastrophic forgetting. Experience replay, a standard component in deep reinforcement learning, is often used to reduce forgetting and improve sample efficiency by storing experiences in a large buffer and using them for training later. However, a large replay buffer results in a heavy memory burden, especially for onboard and edge devices with limited memory capacities. We propose memory-efficient reinforcement learning algorithms based on the deep Q-network algorithm to alleviate this problem. Our algorithms reduce forgetting and maintain high sample efficiency by consolidating knowledge from the target Q-network to the current Q-network. Compared to baseline methods, our algorithms achieve comparable or better performance on both feature-based and image-based tasks while easing the burden of large experience replay buffers.

</p>
</details>

<details><summary><b>Robust Quantity-Aware Aggregation for Federated Learning</b>
<a href="https://arxiv.org/abs/2205.10848">arxiv:2205.10848</a>
&#x1F4C8; 2 <br>
<p>Jingwei Yi, Fangzhao Wu, Huishuai Zhang, Bin Zhu, Tao Qi, Guangzhong Sun, Xing Xie</p></summary>
<p>

**Abstract:** Federated learning (FL) enables multiple clients to collaboratively train models without sharing their local data, and becomes an important privacy-preserving machine learning framework. However, classical FL faces serious security and robustness problem, e.g., malicious clients can poison model updates and at the same time claim large quantities to amplify the impact of their model updates in the model aggregation. Existing defense methods for FL, while all handling malicious model updates, either treat all quantities benign or simply ignore/truncate the quantities of all clients. The former is vulnerable to quantity-enhanced attack, while the latter leads to sub-optimal performance since the local data on different clients is usually in significantly different sizes. In this paper, we propose a robust quantity-aware aggregation algorithm for federated learning, called FedRA, to perform the aggregation with awareness of local data quantities while being able to defend against quantity-enhanced attacks. More specifically, we propose a method to filter malicious clients by jointly considering the uploaded model updates and data quantities from different clients, and performing quantity-aware weighted averaging on model updates from remaining clients. Moreover, as the number of malicious clients participating in the federated learning may dynamically change in different rounds, we also propose a malicious client number estimator to predict how many suspicious clients should be filtered in each round. Experiments on four public datasets demonstrate the effectiveness of our FedRA method in defending FL against quantity-enhanced attacks.

</p>
</details>

<details><summary><b>Neuro-Symbolic Artificial Intelligence (AI) for Intent based Semantic Communication</b>
<a href="https://arxiv.org/abs/2205.10768">arxiv:2205.10768</a>
&#x1F4C8; 2 <br>
<p>Christo Kurisummoottil Thomas, Walid Saad</p></summary>
<p>

**Abstract:** Intent-based networks that integrate sophisticated machine reasoning technologies will be a cornerstone of future wireless 6G systems. Intent-based communication requires the network to consider the semantics (meanings) and effectiveness (at end-user) of the data transmission. This is essential if 6G systems are to communicate reliably with fewer bits while simultaneously providing connectivity to heterogeneous users. In this paper, contrary to state of the art, which lacks explainability of data, the framework of neuro-symbolic artificial intelligence (NeSy AI) is proposed as a pillar for learning causal structure behind the observed data. In particular, the emerging concept of generative flow networks (GFlowNet) is leveraged for the first time in a wireless system to learn the probabilistic structure which generates the data. Further, a novel optimization problem for learning the optimal encoding and decoding functions is rigorously formulated with the intent of achieving higher semantic reliability. Novel analytical formulations are developed to define key metrics for semantic message transmission, including semantic distortion, semantic similarity, and semantic reliability. These semantic measure functions rely on the proposed definition of semantic content of the knowledge base and this information measure is reflective of the nodes' reasoning capabilities. Simulation results validate the ability to communicate efficiently (with less bits but same semantics) and significantly better compared to a conventional system which does not exploit the reasoning capabilities.

</p>
</details>

<details><summary><b>How sensitive are translation systems to extra contexts? Mitigating gender bias in Neural Machine Translation models through relevant contexts</b>
<a href="https://arxiv.org/abs/2205.10762">arxiv:2205.10762</a>
&#x1F4C8; 2 <br>
<p>Shanya Sharma, Manan Dey, Koustuv Sinha</p></summary>
<p>

**Abstract:** Neural Machine Translation systems built on top of Transformer-based architectures are routinely improving the state-of-the-art in translation quality according to word-overlap metrics. However, a growing number of studies also highlight the inherent gender bias that these models incorporate during training, which reflects poorly in their translations. In this work, we investigate whether these models can be instructed to fix their bias during inference using targeted, guided instructions as contexts. By translating relevant contextual sentences during inference along with the input, we observe large improvements in reducing the gender bias in translations, across three popular test suites (WinoMT, BUG, SimpleGen). We further propose a novel metric to assess several large pretrained models (OPUS-MT, M2M-100) on their sensitivity towards using contexts during translation to correct their biases. Our approach requires no fine-tuning, and thus can be used easily in production systems to de-bias translations from stereotypical gender-occupation bias. We hope our method, along with our metric, can be used to build better, bias-free translation systems.

</p>
</details>

<details><summary><b>Real Time Detection Free Tracking of Multiple Objects Via Equilibrium Optimizer</b>
<a href="https://arxiv.org/abs/2205.10756">arxiv:2205.10756</a>
&#x1F4C8; 2 <br>
<p>Djemai Charef-Khodja, Toumi Abida</p></summary>
<p>

**Abstract:** Multiple objects tracking (MOT) is a difficult task, as it usually requires special hardware and higher computation complexity. In this work, we present a new framework of MOT by using of equilibrium optimizer (EO) algorithm and reducing the resolution of the bounding boxes of the objects to solve such problems in the detection free framework. First, in the first frame the target objects are initialized and its size is computed, then its resolution is reduced if it is higher than a threshold, and then modeled by their kernel color histogram to establish a feature model. The Bhattacharya distances between the histogram of object models and other candidates are used as the fitness function to be optimized. Multiple agents are generated by EO, according to the number of the target objects to be tracked. EO algorithm is used because of its efficiency and lower computation cost compared to other algorithms in global optimization. Experimental results confirm that EO multi-object tracker achieves satisfying tracking results then other trackers.

</p>
</details>

<details><summary><b>Augmented Newton Method for Optimization: Global Linear Rate and Momentum Interpretation</b>
<a href="https://arxiv.org/abs/2205.11033">arxiv:2205.11033</a>
&#x1F4C8; 1 <br>
<p>Md Sarowar Morshed</p></summary>
<p>

**Abstract:** We propose two variants of Newton method for solving unconstrained minimization problem. Our method leverages optimization techniques such as penalty and augmented Lagrangian method to generate novel variants of the Newton method namely the Penalty Newton method and the Augmented Newton method. In doing so, we recover several well-known existing Newton method variants such as Damped Newton, Levenberg, and Levenberg-Marquardt methods as special cases. Moreover, the proposed Augmented Newton method can be interpreted as Newton method with adaptive heavy ball momentum. We provide global convergence results for the proposed methods under mild assumptions that hold for a wide variety of problems. The proposed methods can be sought as the penalty and augmented extensions of the results obtained by Karimireddy et. al [24].

</p>
</details>

<details><summary><b>From Width-Based Model Checking to Width-Based Automated Theorem Proving</b>
<a href="https://arxiv.org/abs/2205.10995">arxiv:2205.10995</a>
&#x1F4C8; 1 <br>
<p>Mateus de Oliveira Oliveira, Farhad Vadiee</p></summary>
<p>

**Abstract:** In the field of parameterized complexity theory, the study of graph width measures has been intimately connected with the development of width-based model checking algorithms for combinatorial properties on graphs. In this work, we introduce a general framework to convert a large class of width-based model-checking algorithms into algorithms that can be used to test the validity of graph-theoretic conjectures on classes of graphs of bounded width. Our framework is modular and can be applied with respect to several well-studied width measures for graphs, including treewidth and cliquewidth.
  As a quantitative application of our framework, we show that for several long-standing graph-theoretic conjectures, there exists an algorithm that takes a number $k$ as input and correctly determines in time double-exponential in $k^{O(1)}$ whether the conjecture is valid on all graphs of treewidth at most $k$. This improves significantly on upper bounds obtained using previously available techniques.

</p>
</details>

<details><summary><b>Power and accountability in reinforcement learning applications to environmental policy</b>
<a href="https://arxiv.org/abs/2205.10911">arxiv:2205.10911</a>
&#x1F4C8; 1 <br>
<p>Melissa Chapman, Caleb Scoville, Marcus Lapeyrolerie, Carl Boettiger</p></summary>
<p>

**Abstract:** Machine learning (ML) methods already permeate environmental decision-making, from processing high-dimensional data on earth systems to monitoring compliance with environmental regulations. Of the ML techniques available to address pressing environmental problems (e.g., climate change, biodiversity loss), Reinforcement Learning (RL) may both hold the greatest promise and present the most pressing perils. This paper explores how RL-driven policy refracts existing power relations in the environmental domain while also creating unique challenges to ensuring equitable and accountable environmental decision processes. We leverage examples from RL applications to climate change mitigation and fisheries management to explore how RL technologies shift the distribution of power between resource users, governing bodies, and private industry.

</p>
</details>

<details><summary><b>Positioning Fog Computing for Smart Manufacturing</b>
<a href="https://arxiv.org/abs/2205.10860">arxiv:2205.10860</a>
&#x1F4C8; 1 <br>
<p>Jaakko Harjuhahto, Vesa Hirvisalo</p></summary>
<p>

**Abstract:** We study machine learning systems for real-time industrial quality control. In many factory systems, production processes must be continuously controlled in order to maintain product quality. Especially challenging are the systems that must balance in real-time between stringent resource consumption constraints and the risk of defective end-product. There is a need for automated quality control systems as human control is tedious and error-prone. We see machine learning as a viable choice for developing automated quality control systems, but integrating such system with existing factory automation remains a challenge. In this paper we propose introducing a new fog computing layer to the standard hierarchy of automation control to meet the needs of machine learning driven quality control.

</p>
</details>

<details><summary><b>A Convolutional Dispersion Relation Preserving Scheme for the Acoustic Wave Equation</b>
<a href="https://arxiv.org/abs/2205.10825">arxiv:2205.10825</a>
&#x1F4C8; 1 <br>
<p>Oded Ovadia, Adar Kahana, Eli Turkel</p></summary>
<p>

**Abstract:** We propose an accurate numerical scheme for approximating the solution of the two dimensional acoustic wave problem. We use machine learning to find a stencil suitable even in the presence of high wavenumbers. The proposed scheme incorporates physically informed elements from the field of optimized numerical schemes into a convolutional optimization machine learning algorithm.

</p>
</details>

<details><summary><b>Deep Learning-Based Synchronization for Uplink NB-IoT</b>
<a href="https://arxiv.org/abs/2205.10805">arxiv:2205.10805</a>
&#x1F4C8; 1 <br>
<p>Fayçal Aït Aoudia, Jakob Hoydis, Sebastian Cammerer, Matthijs Van Keirsbilck, Alexander Keller</p></summary>
<p>

**Abstract:** We propose a neural network (NN)-based algorithm for device detection and time of arrival (ToA) and carrier frequency offset (CFO) estimation for the narrowband physical random-access channel (NPRACH) of narrowband internet of things (NB-IoT). The introduced NN architecture leverages residual convolutional networks as well as knowledge of the preamble structure of the 5G New Radio (5G NR) specifications. Benchmarking on a 3rd Generation Partnership Project (3GPP) urban microcell (UMi) channel model with random drops of users against a state-of-the-art baseline shows that the proposed method enables up to 8 dB gains in false negative rate (FNR) as well as significant gains in false positive rate (FPR) and ToA and CFO estimation accuracy. Moreover, our simulations indicate that the proposed algorithm enables gains over a wide range of channel conditions, CFOs, and transmission probabilities. The introduced synchronization method operates at the base station (BS) and, therefore, introduces no additional complexity on the user devices. It could lead to an extension of battery lifetime by reducing the preamble length or the transmit power.

</p>
</details>

<details><summary><b>Data-aided Active User Detection with a User Activity Extraction Network for Grant-free SCMA Systems</b>
<a href="https://arxiv.org/abs/2205.10780">arxiv:2205.10780</a>
&#x1F4C8; 1 <br>
<p>Minsig Han, Ameha T. Abebe, Chung G. Kang</p></summary>
<p>

**Abstract:** In grant-free sparse code multiple access system, joint optimization of contention resources for users and active user detection (AUD) at the receiver is a complex combinatorial problem. To this end, we propose a deep learning-based data-aided AUD scheme which extracts a priori user activity information via a novel user activity extraction network (UAEN). This is enabled by an end-to-end training of an autoencoder (AE), which simultaneously optimizes the contention resources, i.e., preamble sequences, each associated with one of the codebooks, and extraction of user activity information from both preamble and data transmission. Furthermore, we propose self-supervised pre-training scheme for the UAEN, which ensures the convergence of offline end-to-end training. Simulation results demonstrated that the proposed AUD scheme achieved 3 to 5dB gain at a target activity detection error rate of ${{10}^{-3}}$ compared to the state-of-the-art DL-based AUD schemes.

</p>
</details>

<details><summary><b>Preparing data for pathological artificial intelligence with clinical-grade performance</b>
<a href="https://arxiv.org/abs/2205.10748">arxiv:2205.10748</a>
&#x1F4C8; 1 <br>
<p>Yuanqing Yang, Kai Sun, Yanhua Gao, Kuangsong Wang, Gang Yu</p></summary>
<p>

**Abstract:** [Purpose] The pathology is decisive for disease diagnosis, but relies heavily on the experienced pathologists. Recently, pathological artificial intelligence (PAI) is thought to improve diagnostic accuracy and efficiency. However, the high performance of PAI based on deep learning in the laboratory generally cannot be reproduced in the clinic. [Methods] Because the data preparation is important for PAI, the paper has reviewed PAI-related studies in the PubMed database published from January 2017 to February 2022, and 118 studies were included. The in-depth analysis of methods for preparing data is performed, including obtaining slides of pathological tissue, cleaning, screening, and then digitizing. Expert review, image annotation, dataset division for model training and validation are also discussed. We further discuss the reasons why the high performance of PAI is not reproducible in the clinical practices and show some effective ways to improve clinical performances of PAI. [Results] The robustness of PAI depend on randomized collection of representative disease slides, including rigorous quality control and screening, correction of digital discrepancies, reasonable annotation, and the amount of data. The digital pathology is fundamental of clinical-grade PAI, and the techniques of data standardization and weakly supervised learning methods based on whole slide image (WSI) are effective ways to overcome obstacles of performance reproduction. [Conclusion] The representative data, the amount of labeling and consistency from multi-centers is the key to performance reproduction. The digital pathology for clinical diagnosis, data standardization and technique of WSI-based weakly supervised learning hopefully build clinical-grade PAI. Keywords: pathological artificial intelligence; data preparation; clinical-grade; deep learning

</p>
</details>

<details><summary><b>Responsible Artificial Intelligence -- from Principles to Practice</b>
<a href="https://arxiv.org/abs/2205.10785">arxiv:2205.10785</a>
&#x1F4C8; 0 <br>
<p>Virginia Dignum</p></summary>
<p>

**Abstract:** The impact of Artificial Intelligence does not depend only on fundamental research and technological developments, but for a large part on how these systems are introduced into society and used in everyday situations. AI is changing the way we work, live and solve challenges but concerns about fairness, transparency or privacy are also growing. Ensuring responsible, ethical AI is more than designing systems whose result can be trusted. It is about the way we design them, why we design them, and who is involved in designing them. In order to develop and use AI responsibly, we need to work towards technical, societal, institutional and legal methods and tools which provide concrete support to AI practitioners, as well as awareness and training to enable participation of all, to ensure the alignment of AI systems with our societies' principles and values.

</p>
</details>


{% endraw %}
Prev: [2022.05.21]({{ '/2022/05/21/2022.05.21.html' | relative_url }})  Next: [2022.05.23]({{ '/2022/05/23/2022.05.23.html' | relative_url }})