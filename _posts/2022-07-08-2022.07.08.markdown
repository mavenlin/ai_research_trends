Prev: [2022.07.07]({{ '/2022/07/07/2022.07.07.html' | relative_url }})  Next: [2022.07.09]({{ '/2022/07/09/2022.07.09.html' | relative_url }})
{% raw %}
## Summary for 2022-07-08, created on 2022-07-15


<details><summary><b>GT4SD: Generative Toolkit for Scientific Discovery</b>
<a href="https://arxiv.org/abs/2207.03928">arxiv:2207.03928</a>
&#x1F4C8; 38 <br>
<p>Matteo Manica, Joris Cadow, Dimitrios Christofidellis, Ashish Dave, Jannis Born, Dean Clarke, Yves Gaetan Nana Teukam, Samuel C. Hoffman, Matthew Buchan, Vijil Chenthamarakshan, Timothy Donovan, Hsiang Han Hsu, Federico Zipoli, Oliver Schilter, Giorgio Giannone, Akihiro Kishimoto, Lisa Hamada, Inkit Padhi, Karl Wehden, Lauren McHugh, Alexy Khrabrov, Payel Das, Seiji Takeda, John R. Smith</p></summary>
<p>

**Abstract:** With the growing availability of data within various scientific domains, generative models hold enormous potential to accelerate scientific discovery at every step of the scientific method. Perhaps their most valuable application lies in the speeding up of what has traditionally been the slowest and most challenging step of coming up with a hypothesis. Powerful representations are now being learned from large volumes of data to generate novel hypotheses, which is making a big impact on scientific discovery applications ranging from material design to drug discovery. The GT4SD (https://github.com/GT4SD/gt4sd-core) is an extensible open-source library that enables scientists, developers and researchers to train and use state-of-the-art generative models for hypothesis generation in scientific discovery. GT4SD supports a variety of uses of generative models across material science and drug discovery, including molecule discovery and design based on properties related to target proteins, omic profiles, scaffold distances, binding energies and more.

</p>
</details>

<details><summary><b>The Harvard USPTO Patent Dataset: A Large-Scale, Well-Structured, and Multi-Purpose Corpus of Patent Applications</b>
<a href="https://arxiv.org/abs/2207.04043">arxiv:2207.04043</a>
&#x1F4C8; 22 <br>
<p>Mirac Suzgun, Luke Melas-Kyriazi, Suproteem K. Sarkar, Scott Duke Kominers, Stuart M. Shieber</p></summary>
<p>

**Abstract:** Innovation is a major driver of economic and social development, and information about many kinds of innovation is embedded in semi-structured data from patents and patent applications. Although the impact and novelty of innovations expressed in patent data are difficult to measure through traditional means, ML offers a promising set of techniques for evaluating novelty, summarizing contributions, and embedding semantics. In this paper, we introduce the Harvard USPTO Patent Dataset (HUPD), a large-scale, well-structured, and multi-purpose corpus of English-language patent applications filed to the United States Patent and Trademark Office (USPTO) between 2004 and 2018. With more than 4.5 million patent documents, HUPD is two to three times larger than comparable corpora. Unlike previously proposed patent datasets in NLP, HUPD contains the inventor-submitted versions of patent applications--not the final versions of granted patents--thereby allowing us to study patentability at the time of filing using NLP methods for the first time. It is also novel in its inclusion of rich structured metadata alongside the text of patent filings: By providing each application's metadata along with all of its text fields, the dataset enables researchers to perform new sets of NLP tasks that leverage variation in structured covariates. As a case study on the types of research HUPD makes possible, we introduce a new task to the NLP community--namely, binary classification of patent decisions. We additionally show the structured metadata provided in the dataset enables us to conduct explicit studies of concept shifts for this task. Finally, we demonstrate how HUPD can be used for three additional tasks: multi-class classification of patent subject areas, language modeling, and summarization.

</p>
</details>

<details><summary><b>Big Learning: A Universal Machine Learning Paradigm?</b>
<a href="https://arxiv.org/abs/2207.03899">arxiv:2207.03899</a>
&#x1F4C8; 21 <br>
<p>Yulai Cong, Miaoyun Zhao</p></summary>
<p>

**Abstract:** Recent breakthroughs based on big/foundation models reveal a vague avenue for artificial intelligence, that is, bid data, big/foundation models, big learning, $\cdots$. Following that avenue, here we elaborate on the newly introduced big learning. Specifically, big learning comprehensively exploits the available information inherent in large-scale complete/incomplete data, by simultaneously learning to model many-to-all joint/conditional/marginal data distributions (thus named big learning) with one universal foundation model. We reveal that big learning is what existing foundation models are implicitly doing; accordingly, our big learning provides high-level guidance for flexible design and improvements of foundation models, accelerating the true self-learning on the Internet. Besides, big learning ($i$) is equipped with marvelous flexibility for both training data and training-task customization; ($ii$) potentially delivers all joint/conditional/marginal data capabilities after training; ($iii$) significantly reduces the training-test gap with improved model generalization; and ($iv$) unifies conventional machine learning paradigms e.g. supervised learning, unsupervised learning, generative learning, etc. and enables their flexible cooperation, manifesting a universal learning paradigm.

</p>
</details>

<details><summary><b>CoSIm: Commonsense Reasoning for Counterfactual Scene Imagination</b>
<a href="https://arxiv.org/abs/2207.03961">arxiv:2207.03961</a>
&#x1F4C8; 20 <br>
<p>Hyounghun Kim, Abhay Zala, Mohit Bansal</p></summary>
<p>

**Abstract:** As humans, we can modify our assumptions about a scene by imagining alternative objects or concepts in our minds. For example, we can easily anticipate the implications of the sun being overcast by rain clouds (e.g., the street will get wet) and accordingly prepare for that. In this paper, we introduce a new task/dataset called Commonsense Reasoning for Counterfactual Scene Imagination (CoSIm) which is designed to evaluate the ability of AI systems to reason about scene change imagination. In this task/dataset, models are given an image and an initial question-response pair about the image. Next, a counterfactual imagined scene change (in textual form) is applied, and the model has to predict the new response to the initial question based on this scene change. We collect 3.5K high-quality and challenging data instances, with each instance consisting of an image, a commonsense question with a response, a description of a counterfactual change, a new response to the question, and three distractor responses. Our dataset contains various complex scene change types (such as object addition/removal/state change, event description, environment change, etc.) that require models to imagine many different scenarios and reason about the changed scenes. We present a baseline model based on a vision-language Transformer (i.e., LXMERT) and ablation studies. Through human evaluation, we demonstrate a large human-model performance gap, suggesting room for promising future work on this challenging counterfactual, scene imagination task. Our code and dataset are publicly available at: https://github.com/hyounghk/CoSIm

</p>
</details>

<details><summary><b>End-to-End Binaural Speech Synthesis</b>
<a href="https://arxiv.org/abs/2207.03697">arxiv:2207.03697</a>
&#x1F4C8; 14 <br>
<p>Wen Chin Huang, Dejan Markovic, Alexander Richard, Israel Dejene Gebru, Anjali Menon</p></summary>
<p>

**Abstract:** In this work, we present an end-to-end binaural speech synthesis system that combines a low-bitrate audio codec with a powerful binaural decoder that is capable of accurate speech binauralization while faithfully reconstructing environmental factors like ambient noise or reverb. The network is a modified vector-quantized variational autoencoder, trained with several carefully designed objectives, including an adversarial loss. We evaluate the proposed system on an internal binaural dataset with objective metrics and a perceptual study. Results show that the proposed approach matches the ground truth data more closely than previous methods. In particular, we demonstrate the capability of the adversarial loss in capturing environment effects needed to create an authentic auditory scene.

</p>
</details>

<details><summary><b>Variational Inference of overparameterized Bayesian Neural Networks: a theoretical and empirical study</b>
<a href="https://arxiv.org/abs/2207.03859">arxiv:2207.03859</a>
&#x1F4C8; 11 <br>
<p>Tom Huix, Szymon Majewski, Alain Durmus, Eric Moulines, Anna Korba</p></summary>
<p>

**Abstract:** This paper studies the Variational Inference (VI) used for training Bayesian Neural Networks (BNN) in the overparameterized regime, i.e., when the number of neurons tends to infinity. More specifically, we consider overparameterized two-layer BNN and point out a critical issue in the mean-field VI training. This problem arises from the decomposition of the lower bound on the evidence (ELBO) into two terms: one corresponding to the likelihood function of the model and the second to the Kullback-Leibler (KL) divergence between the prior distribution and the variational posterior. In particular, we show both theoretically and empirically that there is a trade-off between these two terms in the overparameterized regime only when the KL is appropriately re-scaled with respect to the ratio between the the number of observations and neurons. We also illustrate our theoretical results with numerical experiments that highlight the critical choice of this ratio.

</p>
</details>

<details><summary><b>A Systematic Review and Thematic Analysis of Community-Collaborative Approaches to Computing Research</b>
<a href="https://arxiv.org/abs/2207.04171">arxiv:2207.04171</a>
&#x1F4C8; 9 <br>
<p>Ned Cooper, Tiffanie Horne, Gillian Hayes, Courtney Heldreth, Michal Lahav, Jess Scon Holbrook, Lauren Wilcox</p></summary>
<p>

**Abstract:** HCI researchers have been gradually shifting attention from individual users to communities when engaging in research, design, and system development. However, our field has yet to establish a cohesive, systematic understanding of the challenges, benefits, and commitments of community-collaborative approaches to research. We conducted a systematic review and thematic analysis of 47 computing research papers discussing participatory research with communities for the development of technological artifacts and systems, published over the last two decades. From this review, we identified seven themes associated with the evolution of a project: from establishing community partnerships to sustaining results. Our findings suggest that several tensions characterize these projects, many of which relate to the power and position of researchers, and the computing research environment, relative to community partners. We discuss the implications of our findings and offer methodological proposals to guide HCI, and computing research more broadly, towards practices that center communities.

</p>
</details>

<details><summary><b>Large Scale Mask Optimization Via Convolutional Fourier Neural Operator and Litho-Guided Self Training</b>
<a href="https://arxiv.org/abs/2207.04056">arxiv:2207.04056</a>
&#x1F4C8; 9 <br>
<p>Haoyu Yang, Zongyi Li, Kumara Sastry, Saumyadip Mukhopadhyay, Anima Anandkumar, Brucek Khailany, Vivek Singh, Haoxing Ren</p></summary>
<p>

**Abstract:** Machine learning techniques have been extensively studied for mask optimization problems, aiming at better mask printability, shorter turnaround time, better mask manufacturability, and so on. However, most of these researches are focusing on the initial solution generation of small design regions. To further realize the potential of machine learning techniques on mask optimization tasks, we present a Convolutional Fourier Neural Operator (CFNO) that can efficiently learn layout tile dependencies and hence promise stitch-less large-scale mask optimization with the limited intervention of legacy tools. We discover the possibility of litho-guided self-training (LGST) through a trained machine learning model when solving non-convex optimization problems, which allows iterative model and dataset update and brings significant model performance improvement. Experimental results show that, for the first time, our machine learning-based framework outperforms state-of-the-art academic numerical mask optimizers with an order of magnitude speedup.

</p>
</details>

<details><summary><b>High Performance Simulation for Scalable Multi-Agent Reinforcement Learning</b>
<a href="https://arxiv.org/abs/2207.03945">arxiv:2207.03945</a>
&#x1F4C8; 9 <br>
<p>Jordan Langham-Lopez, Sebastian M. Schmon, Patrick Cannon</p></summary>
<p>

**Abstract:** Multi-agent reinforcement learning experiments and open-source training environments are typically limited in scale, supporting tens or sometimes up to hundreds of interacting agents. In this paper we demonstrate the use of Vogue, a high performance agent based model (ABM) framework. Vogue serves as a multi-agent training environment, supporting thousands to tens of thousands of interacting agents while maintaining high training throughput by running both the environment and reinforcement learning (RL) agents on the GPU. High performance multi-agent environments at this scale have the potential to enable the learning of robust and flexible policies for use in ABMs and simulations of complex systems. We demonstrate training performance with two newly developed, large scale multi-agent training environments. Moreover, we show that these environments can train shared RL policies on time-scales of minutes and hours.

</p>
</details>

<details><summary><b>Improving Wikipedia Verifiability with AI</b>
<a href="https://arxiv.org/abs/2207.06220">arxiv:2207.06220</a>
&#x1F4C8; 7 <br>
<p>Fabio Petroni, Samuel Broscheit, Aleksandra Piktus, Patrick Lewis, Gautier Izacard, Lucas Hosseini, Jane Dwivedi-Yu, Maria Lomeli, Timo Schick, Pierre-Emmanuel Mazaré, Armand Joulin, Edouard Grave, Sebastian Riedel</p></summary>
<p>

**Abstract:** Verifiability is a core content policy of Wikipedia: claims that are likely to be challenged need to be backed by citations. There are millions of articles available online and thousands of new articles are released each month. For this reason, finding relevant sources is a difficult task: many claims do not have any references that support them. Furthermore, even existing citations might not support a given claim or become obsolete once the original source is updated or deleted. Hence, maintaining and improving the quality of Wikipedia references is an important challenge and there is a pressing need for better tools to assist humans in this effort. Here, we show that the process of improving references can be tackled with the help of artificial intelligence (AI). We develop a neural network based system, called Side, to identify Wikipedia citations that are unlikely to support their claims, and subsequently recommend better ones from the web. We train this model on existing Wikipedia references, therefore learning from the contributions and combined wisdom of thousands of Wikipedia editors. Using crowd-sourcing, we observe that for the top 10% most likely citations to be tagged as unverifiable by our system, humans prefer our system's suggested alternatives compared to the originally cited reference 70% of the time. To validate the applicability of our system, we built a demo to engage with the English-speaking Wikipedia community and find that Side's first citation recommendation collects over 60% more preferences than existing Wikipedia citations for the same top 10% most likely unverifiable claims according to Side. Our results indicate that an AI-based system could be used, in tandem with humans, to improve the verifiability of Wikipedia. More generally, we hope that our work can be used to assist fact checking efforts and increase the general trustworthiness of information online.

</p>
</details>

<details><summary><b>MACFE: A Meta-learning and Causality Based Feature Engineering Framework</b>
<a href="https://arxiv.org/abs/2207.04010">arxiv:2207.04010</a>
&#x1F4C8; 7 <br>
<p>Ivan Reyes-Amezcua, Daniel Flores-Araiza, Gilberto Ochoa-Ruiz, Andres Mendez-Vazquez, Eduardo Rodriguez-Tello</p></summary>
<p>

**Abstract:** Feature engineering has become one of the most important steps to improve model prediction performance, and to produce quality datasets. However, this process requires non-trivial domain-knowledge which involves a time-consuming process. Thereby, automating such process has become an active area of research and of interest in industrial applications. In this paper, a novel method, called Meta-learning and Causality Based Feature Engineering (MACFE), is proposed; our method is based on the use of meta-learning, feature distribution encoding, and causality feature selection. In MACFE, meta-learning is used to find the best transformations, then the search is accelerated by pre-selecting "original" features given their causal relevance. Experimental evaluations on popular classification datasets show that MACFE can improve the prediction performance across eight classifiers, outperforms the current state-of-the-art methods in average by at least 6.54%, and obtains an improvement of 2.71% over the best previous works.

</p>
</details>

<details><summary><b>FastLTS: Non-Autoregressive End-to-End Unconstrained Lip-to-Speech Synthesis</b>
<a href="https://arxiv.org/abs/2207.03800">arxiv:2207.03800</a>
&#x1F4C8; 7 <br>
<p>Yongqi Wang, Zhou Zhao</p></summary>
<p>

**Abstract:** Unconstrained lip-to-speech synthesis aims to generate corresponding speeches from silent videos of talking faces with no restriction on head poses or vocabulary. Current works mainly use sequence-to-sequence models to solve this problem, either in an autoregressive architecture or a flow-based non-autoregressive architecture. However, these models suffer from several drawbacks: 1) Instead of directly generating audios, they use a two-stage pipeline that first generates mel-spectrograms and then reconstructs audios from the spectrograms. This causes cumbersome deployment and degradation of speech quality due to error propagation; 2) The audio reconstruction algorithm used by these models limits the inference speed and audio quality, while neural vocoders are not available for these models since their output spectrograms are not accurate enough; 3) The autoregressive model suffers from high inference latency, while the flow-based model has high memory occupancy: neither of them is efficient enough in both time and memory usage. To tackle these problems, we propose FastLTS, a non-autoregressive end-to-end model which can directly synthesize high-quality speech audios from unconstrained talking videos with low latency, and has a relatively small model size. Besides, different from the widely used 3D-CNN visual frontend for lip movement encoding, we for the first time propose a transformer-based visual frontend for this task. Experiments show that our model achieves $19.76\times$ speedup for audio waveform generation compared with the current autoregressive model on input sequences of 3 seconds, and obtains superior audio quality.

</p>
</details>

<details><summary><b>TalkToModel: Understanding Machine Learning Models With Open Ended Dialogues</b>
<a href="https://arxiv.org/abs/2207.04154">arxiv:2207.04154</a>
&#x1F4C8; 6 <br>
<p>Dylan Slack, Satyapriya Krishna, Himabindu Lakkaraju, Sameer Singh</p></summary>
<p>

**Abstract:** Machine Learning (ML) models are increasingly used to make critical decisions in real-world applications, yet they have also become more complex, making them harder to understand. To this end, several techniques to explain model predictions have been proposed. However, practitioners struggle to leverage explanations because they often do not know which to use, how to interpret the results, and may have insufficient data science experience to obtain explanations. In addition, most current works focus on generating one-shot explanations and do not allow users to follow up and ask fine-grained questions about the explanations, which can be frustrating. In this work, we address these challenges by introducing TalkToModel: an open-ended dialogue system for understanding machine learning models. Specifically, TalkToModel comprises three key components: 1) a natural language interface for engaging in dialogues, making understanding ML models highly accessible, 2) a dialogue engine that adapts to any tabular model and dataset, interprets natural language, maps it to appropriate operations (e.g., feature importance explanations, counterfactual explanations, showing model errors), and generates text responses, and 3) an execution component that run the operations and ensures explanations are accurate. We carried out quantitative and human subject evaluations of TalkToModel. We found the system understands user questions on novel datasets and models with high accuracy, demonstrating the system's capacity to generalize to new situations. In human evaluations, 73% of healthcare workers (e.g., doctors and nurses) agreed they would use TalkToModel over baseline point-and-click systems, and 84.6% of ML graduate students agreed TalkToModel was easier to use.

</p>
</details>

<details><summary><b>CompoSuite: A Compositional Reinforcement Learning Benchmark</b>
<a href="https://arxiv.org/abs/2207.04136">arxiv:2207.04136</a>
&#x1F4C8; 6 <br>
<p>Jorge A. Mendez, Marcel Hussing, Meghna Gummadi, Eric Eaton</p></summary>
<p>

**Abstract:** We present CompoSuite, an open-source simulated robotic manipulation benchmark for compositional multi-task reinforcement learning (RL). Each CompoSuite task requires a particular robot arm to manipulate one individual object to achieve a task objective while avoiding an obstacle. This compositional definition of the tasks endows CompoSuite with two remarkable properties. First, varying the robot/object/objective/obstacle elements leads to hundreds of RL tasks, each of which requires a meaningfully different behavior. Second, RL approaches can be evaluated specifically for their ability to learn the compositional structure of the tasks. This latter capability to functionally decompose problems would enable intelligent agents to identify and exploit commonalities between learning tasks to handle large varieties of highly diverse problems. We benchmark existing single-task, multi-task, and compositional learning algorithms on various training settings, and assess their capability to compositionally generalize to unseen tasks. Our evaluation exposes the shortcomings of existing RL approaches with respect to compositionality and opens new avenues for investigation.

</p>
</details>

<details><summary><b>Multi-view Attention for gestational age at birth prediction</b>
<a href="https://arxiv.org/abs/2207.04130">arxiv:2207.04130</a>
&#x1F4C8; 6 <br>
<p>Mathieu Leclercq, Martin Styner, Juan Carlos Prieto</p></summary>
<p>

**Abstract:** We present our method for gestational age at birth prediction for the SLCN (surface learning for clinical neuroimaging) challenge. Our method is based on a multi-view shape analysis technique that captures 2D renderings of a 3D object from different viewpoints. We render the brain features on the surface of the sphere and then the 2D images are analyzed via 2D CNNs and an attention layer for the regression task. The regression task achieves a MAE of 1.637 +- 1.3 on the Native space and MAE of 1.38 +- 1.14 on the template space. The source code for this project is available in our github repository https://github.com/MathieuLeclercq/SLCN_challenge_UNC

</p>
</details>

<details><summary><b>A law of adversarial risk, interpolation, and label noise</b>
<a href="https://arxiv.org/abs/2207.03933">arxiv:2207.03933</a>
&#x1F4C8; 6 <br>
<p>Daniel Paleka, Amartya Sanyal</p></summary>
<p>

**Abstract:** In supervised learning, it has been shown that label noise in the data can be interpolated without penalties on test accuracy under many circumstances. We show that interpolating label noise induces adversarial vulnerability, and prove the first theorem showing the dependence of label noise and adversarial risk in terms of the data distribution. Our results are almost sharp without accounting for the inductive bias of the learning algorithm. We also show that inductive bias makes the effect of label noise much stronger.

</p>
</details>

<details><summary><b>Towards Multimodal Vision-Language Models Generating Non-Generic Text</b>
<a href="https://arxiv.org/abs/2207.04174">arxiv:2207.04174</a>
&#x1F4C8; 5 <br>
<p>Wes Robbins, Zanyar Zohourianshahzadi, Jugal Kalita</p></summary>
<p>

**Abstract:** Vision-language models can assess visual context in an image and generate descriptive text. While the generated text may be accurate and syntactically correct, it is often overly general. To address this, recent work has used optical character recognition to supplement visual information with text extracted from an image. In this work, we contend that vision-language models can benefit from additional information that can be extracted from an image, but are not used by current models. We modify previous multimodal frameworks to accept relevant information from any number of auxiliary classifiers. In particular, we focus on person names as an additional set of tokens and create a novel image-caption dataset to facilitate captioning with person names. The dataset, Politicians and Athletes in Captions (PAC), consists of captioned images of well-known people in context. By fine-tuning pretrained models with this dataset, we demonstrate a model that can naturally integrate facial recognition tokens into generated text by training on limited data. For the PAC dataset, we provide a discussion on collection and baseline benchmark scores.

</p>
</details>

<details><summary><b>Out of Distribution Detection via Neural Network Anchoring</b>
<a href="https://arxiv.org/abs/2207.04125">arxiv:2207.04125</a>
&#x1F4C8; 5 <br>
<p>Rushil Anirudh, Jayaraman J. Thiagarajan</p></summary>
<p>

**Abstract:** Our goal in this paper is to exploit heteroscedastic temperature scaling as a calibration strategy for out of distribution (OOD) detection. Heteroscedasticity here refers to the fact that the optimal temperature parameter for each sample can be different, as opposed to conventional approaches that use the same value for the entire distribution. To enable this, we propose a new training strategy called anchoring that can estimate appropriate temperature values for each sample, leading to state-of-the-art OOD detection performance across several benchmarks. Using NTK theory, we show that this temperature function estimate is closely linked to the epistemic uncertainty of the classifier, which explains its behavior. In contrast to some of the best-performing OOD detection approaches, our method does not require exposure to additional outlier datasets, custom calibration objectives, or model ensembling. Through empirical studies with different OOD detection settings -- far OOD, near OOD, and semantically coherent OOD - we establish a highly effective OOD detection approach. Code and models can be accessed here -- https://github.com/rushilanirudh/AMP

</p>
</details>

<details><summary><b>Braid-based architecture search</b>
<a href="https://arxiv.org/abs/2207.04121">arxiv:2207.04121</a>
&#x1F4C8; 5 <br>
<p>Olga Lukyanova, Oleg Nikitin, Alex Kunin</p></summary>
<p>

**Abstract:** In this article, we propose the approach to structural optimization of neural networks, based on the braid theory. The paper describes the basics of braid theory as applied to the description of graph structures of neural networks. It is shown how networks of various topologies can be built using braid structures between layers of neural networks. The operation of a neural network based on the braid theory is compared with a homogeneous deep neural network and a network with random intersections between layers that do not correspond to the ordering of the braids. Results are obtained showing the advantage of braid-based networks over comparable architectures in classification problems.

</p>
</details>

<details><summary><b>On the Need and Applicability of Causality for Fair Machine Learning</b>
<a href="https://arxiv.org/abs/2207.04053">arxiv:2207.04053</a>
&#x1F4C8; 5 <br>
<p>Rūta Binkytė, Sami Zhioua</p></summary>
<p>

**Abstract:** Causal reasoning has an indispensable role in how humans make sense of the world and come to decisions in everyday life. While $20th$ century science was reserved from making causal claims as too strong and not achievable, the $21st$ century is marked by the return of causality encouraged by the mathematization of causal notions and the introduction of the non-deterministic concept of cause~\cite{illari2011look}. Besides its common use cases in epidemiology, political, and social sciences, causality turns out to be crucial in evaluating the fairness of automated decisions, both in a legal and everyday sense. We provide arguments and examples of why causality is particularly important for fairness evaluation. In particular, we point out the social impact of non-causal predictions and the legal anti-discrimination process that relies on causal claims. We conclude with a discussion about the challenges and limitations of applying causality in practical scenarios as well as possible solutions.

</p>
</details>

<details><summary><b>Constrained Training of Neural Networks via Theorem Proving</b>
<a href="https://arxiv.org/abs/2207.03880">arxiv:2207.03880</a>
&#x1F4C8; 5 <br>
<p>Mark Chevallier, Matthew Whyte, Jacques D. Fleuriot</p></summary>
<p>

**Abstract:** We introduce a theorem proving approach to the specification and generation of temporal logical constraints for training neural networks. We formalise a deep embedding of linear temporal logic over finite traces (LTL$_f$) and an associated evaluation function characterising its semantics within the higher-order logic of the Isabelle theorem prover. We then proceed to formalise a loss function $\mathcal{L}$ that we formally prove to be sound, and differentiable to a function $d\mathcal{L}$. We subsequently use Isabelle's automatic code generation mechanism to produce OCaml versions of LTL$_f$, $\mathcal{L}$ and $d\mathcal{L}$ that we integrate with PyTorch via OCaml bindings for Python. We show that, when used for training in an existing deep learning framework for dynamic movement, our approach produces expected results for common movement specification patterns such as obstacle avoidance and patrolling. The distinctive benefit of our approach is the fully rigorous method for constrained training, eliminating many of the risks inherent to ad-hoc implementations of logical aspects directly in an "unsafe" programming language such as Python.

</p>
</details>

<details><summary><b>A Non-isotropic Probabilistic Take on Proxy-based Deep Metric Learning</b>
<a href="https://arxiv.org/abs/2207.03784">arxiv:2207.03784</a>
&#x1F4C8; 5 <br>
<p>Michael Kirchhof, Karsten Roth, Zeynep Akata, Enkelejda Kasneci</p></summary>
<p>

**Abstract:** Proxy-based Deep Metric Learning (DML) learns deep representations by embedding images close to their class representatives (proxies), commonly with respect to the angle between them. However, this disregards the embedding norm, which can carry additional beneficial context such as class- or image-intrinsic uncertainty. In addition, proxy-based DML struggles to learn class-internal structures. To address both issues at once, we introduce non-isotropic probabilistic proxy-based DML. We model images as directional von Mises-Fisher (vMF) distributions on the hypersphere that can reflect image-intrinsic uncertainties. Further, we derive non-isotropic von Mises-Fisher (nivMF) distributions for class proxies to better represent complex class-specific variances. To measure the proxy-to-image distance between these models, we develop and investigate multiple distribution-to-point and distribution-to-distribution metrics. Each framework choice is motivated by a set of ablational studies, which showcase beneficial properties of our probabilistic approach to proxy-based DML, such as uncertainty-awareness, better-behaved gradients during training, and overall improved generalization performance. The latter is especially reflected in the competitive performance on the standard DML benchmarks, where our approach compares favorably, suggesting that existing proxy-based DML can significantly benefit from a more probabilistic treatment. Code is available at github.com/ExplainableML/Probabilistic_Deep_Metric_Learning.

</p>
</details>

<details><summary><b>Hidden Schema Networks</b>
<a href="https://arxiv.org/abs/2207.03777">arxiv:2207.03777</a>
&#x1F4C8; 5 <br>
<p>Ramsés J. Sánchez, Lukas Conrads, Pascal Welke, Kostadin Cvejoski, César Ojeda</p></summary>
<p>

**Abstract:** Most modern language models infer representations that, albeit powerful, lack both compositionality and semantic interpretability. Starting from the assumption that a large proportion of semantic content is necessarily relational, we introduce a neural language model that discovers networks of symbols (schemata) from text datasets. Using a variational autoencoder (VAE) framework, our model encodes sentences into sequences of symbols (composed representation), which correspond to the nodes visited by biased random walkers on a global latent graph. Sentences are then generated back, conditioned on the selected symbol sequences. We first demonstrate that the model is able to uncover ground-truth graphs from artificially generated datasets of random token sequences. Next we leverage pretrained BERT and GPT-2 language models as encoder and decoder, respectively, to train our model on language modelling tasks. Qualitatively, our results show that the model is able to infer schema networks encoding different aspects of natural language. Quantitatively, the model achieves state-of-the-art scores on VAE language modeling benchmarks. Source code to reproduce our experiments is available at https://github.com/ramsesjsf/HiddenSchemaNetworks

</p>
</details>

<details><summary><b>Combining Deep Learning with Good Old-Fashioned Machine Learning</b>
<a href="https://arxiv.org/abs/2207.03757">arxiv:2207.03757</a>
&#x1F4C8; 5 <br>
<p>Moshe Sipper</p></summary>
<p>

**Abstract:** We present a comprehensive, stacking-based framework for combining deep learning with good old-fashioned machine learning, called Deep GOld. Our framework involves ensemble selection from 51 retrained pretrained deep networks as first-level models, and 10 machine-learning algorithms as second-level models. Enabled by today's state-of-the-art software tools and hardware platforms, Deep GOld delivers consistent improvement when tested on four image-classification datasets: Fashion MNIST, CIFAR10, CIFAR100, and Tiny ImageNet. Of 120 experiments, in all but 10 Deep GOld improved the original networks' performance.

</p>
</details>

<details><summary><b>Towards Highly Expressive Machine Learning Models of Non-Melanoma Skin Cancer</b>
<a href="https://arxiv.org/abs/2207.05749">arxiv:2207.05749</a>
&#x1F4C8; 4 <br>
<p>Simon M. Thomas, James G. Lefevre, Glenn Baxter, Nicholas A. Hamilton</p></summary>
<p>

**Abstract:** Pathologists have a rich vocabulary with which they can describe all the nuances of cellular morphology. In their world, there is a natural pairing of images and words. Recent advances demonstrate that machine learning models can now be trained to learn high-quality image features and represent them as discrete units of information. This enables natural language, which is also discrete, to be jointly modelled alongside the imaging, resulting in a description of the contents of the imaging. Here we present experiments in applying discrete modelling techniques to the problem domain of non-melanoma skin cancer, specifically, histological images of Intraepidermal Carcinoma (IEC). Implementing a VQ-GAN model to reconstruct high-resolution (256x256) images of IEC images, we trained a sequence-to-sequence transformer to generate natural language descriptions using pathologist terminology. Combined with the idea of interactive concept vectors available by using continuous generative methods, we demonstrate an additional angle of interpretability. The result is a promising means of working towards highly expressive machine learning systems which are not only useful as predictive/classification tools, but also means to further our scientific understanding of disease.

</p>
</details>

<details><summary><b>Differentiable Physics Simulations with Contacts: Do They Have Correct Gradients w.r.t. Position, Velocity and Control?</b>
<a href="https://arxiv.org/abs/2207.05060">arxiv:2207.05060</a>
&#x1F4C8; 4 <br>
<p>Yaofeng Desmond Zhong, Jiequn Han, Georgia Olympia Brikis</p></summary>
<p>

**Abstract:** In recent years, an increasing amount of work has focused on differentiable physics simulation and has produced a set of open source projects such as Tiny Differentiable Simulator, Nimble Physics, diffTaichi, Brax, Warp, Dojo and DiffCoSim. By making physics simulations end-to-end differentiable, we can perform gradient-based optimization and learning tasks. A majority of differentiable simulators consider collisions and contacts between objects, but they use different contact models for differentiability. In this paper, we overview four kinds of differentiable contact formulations - linear complementarity problems (LCP), convex optimization models, compliant models and position-based dynamics (PBD). We analyze and compare the gradients calculated by these models and show that the gradients are not always correct. We also demonstrate their ability to learn an optimal control strategy by comparing the learned strategies with the optimal strategy in an analytical form. The codebase to reproduce the experiment results is available at https://github.com/DesmondZhong/diff_sim_grads.

</p>
</details>

<details><summary><b>Few 'Zero Level Set'-Shot Learning of Shape Signed Distance Functions in Feature Space</b>
<a href="https://arxiv.org/abs/2207.04161">arxiv:2207.04161</a>
&#x1F4C8; 4 <br>
<p>Amine Ouasfi, Adnane Boukhayma</p></summary>
<p>

**Abstract:** We explore a new idea for learning based shape reconstruction from a point cloud, based on the recently popularized implicit neural shape representations. We cast the problem as a few-shot learning of implicit neural signed distance functions in feature space, that we approach using gradient based meta-learning. We use a convolutional encoder to build a feature space given the input point cloud. An implicit decoder learns to predict signed distance values given points represented in this feature space. Setting the input point cloud, i.e. samples from the target shape function's zero level set, as the support (i.e. context) in few-shot learning terms, we train the decoder such that it can adapt its weights to the underlying shape of this context with a few (5) tuning steps. We thus combine two types of implicit neural network conditioning mechanisms simultaneously for the first time, namely feature encoding and meta-learning. Our numerical and qualitative evaluation shows that in the context of implicit reconstruction from a sparse point cloud, our proposed strategy, i.e. meta-learning in feature space, outperforms existing alternatives, namely standard supervised learning in feature space, and meta-learning in euclidean space, while still providing fast inference.

</p>
</details>

<details><summary><b>Not all broken defenses are equal: The dead angles of adversarial accuracy</b>
<a href="https://arxiv.org/abs/2207.04129">arxiv:2207.04129</a>
&#x1F4C8; 4 <br>
<p>Raphael Olivier, Bhiksha Raj</p></summary>
<p>

**Abstract:** Robustness to adversarial attack is typically evaluated with adversarial accuracy. This metric is however too coarse to properly capture all robustness properties of machine learning models. Many defenses, when evaluated against a strong attack, do not provide accuracy improvements while still contributing partially to adversarial robustness. Popular certification methods suffer from the same issue, as they provide a lower bound to accuracy. To capture finer robustness properties we propose a new metric for L2 robustness, adversarial angular sparsity, which partially answers the question "how many adversarial examples are there around an input". We demonstrate its usefulness by evaluating both "strong" and "weak" defenses. We show that some state-of-the-art defenses, delivering very similar accuracy, can have very different sparsity on the inputs that they are not robust on. We also show that some weak defenses actually decrease robustness, while others strengthen it in a measure that accuracy cannot capture. These differences are predictive of how useful such defenses can become when combined with adversarial training.

</p>
</details>

<details><summary><b>Few-Example Clustering via Contrastive Learning</b>
<a href="https://arxiv.org/abs/2207.04050">arxiv:2207.04050</a>
&#x1F4C8; 4 <br>
<p>Minguk Jang, Sae-Young Chung</p></summary>
<p>

**Abstract:** We propose Few-Example Clustering (FEC), a novel algorithm that performs contrastive learning to cluster few examples. Our method is composed of the following three steps: (1) generation of candidate cluster assignments, (2) contrastive learning for each cluster assignment, and (3) selection of the best candidate. Based on the hypothesis that the contrastive learner with the ground-truth cluster assignment is trained faster than the others, we choose the candidate with the smallest training loss in the early stage of learning in step (3). Extensive experiments on the \textit{mini}-ImageNet and CUB-200-2011 datasets show that FEC outperforms other baselines by about 3.2% on average under various scenarios. FEC also exhibits an interesting learning curve where clustering performance gradually increases and then sharply drops.

</p>
</details>

<details><summary><b>Memory-free Online Change-point Detection: A Novel Neural Network Approach</b>
<a href="https://arxiv.org/abs/2207.03932">arxiv:2207.03932</a>
&#x1F4C8; 4 <br>
<p>Zahra Atashgahi, Decebal Constantin Mocanu, Raymond Veldhuis, Mykola Pechenizkiy</p></summary>
<p>

**Abstract:** Change-point detection (CPD), which detects abrupt changes in the data distribution, is recognized as one of the most significant tasks in time series analysis. Despite the extensive literature on offline CPD, unsupervised online CPD still suffers from major challenges, including scalability, hyperparameter tuning, and learning constraints. To mitigate some of these challenges, in this paper, we propose a novel deep learning approach for unsupervised online CPD from multi-dimensional time series, named Adaptive LSTM-Autoencoder Change-Point Detection (ALACPD). ALACPD exploits an LSTM-autoencoder-based neural network to perform unsupervised online CPD. It continuously adapts to the incoming samples without keeping the previously received input, thus being memory-free. We perform an extensive evaluation on several real-world time series CPD benchmarks. We show that ALACPD, on average, ranks first among state-of-the-art CPD algorithms in terms of quality of the time series segmentation, and it is on par with the best performer in terms of the accuracy of the estimated change-points. The implementation of ALACPD is available online on Github\footnote{\url{https://github.com/zahraatashgahi/ALACPD}}.

</p>
</details>

<details><summary><b>Towards Semantic Communication Protocols: A Probabilistic Logic Perspective</b>
<a href="https://arxiv.org/abs/2207.03920">arxiv:2207.03920</a>
&#x1F4C8; 4 <br>
<p>Sejin Seo, Jihong Park, Seung-Woo Ko, Jinho Choi, Mehdi Bennis, Seong-Lyun Kim</p></summary>
<p>

**Abstract:** Classical medium access control (MAC) protocols are interpretable, yet their task-agnostic control signaling messages (CMs) are ill-suited for emerging mission-critical applications. By contrast, neural network (NN) based protocol models (NPMs) learn to generate task-specific CMs, but their rationale and impact lack interpretability. To fill this void, in this article we propose, for the first time, a semantic protocol model (SPM) constructed by transforming an NPM into an interpretable symbolic graph written in the probabilistic logic programming language (ProbLog). This transformation is viable by extracting and merging common CMs and their connections while treating the NPM as a CM generator. By extensive simulations, we corroborate that the SPM tightly approximates its original NPM while occupying only 0.02% memory. By leveraging its interpretability and memory-efficiency, we demonstrate several SPM-enabled applications such as SPM reconfiguration for collision-avoidance, as well as comparing different SPMs via semantic entropy calculation and storing multiple SPMs to cope with non-stationary environments.

</p>
</details>

<details><summary><b>Storehouse: a Reinforcement Learning Environment for Optimizing Warehouse Management</b>
<a href="https://arxiv.org/abs/2207.03851">arxiv:2207.03851</a>
&#x1F4C8; 4 <br>
<p>Julen Cestero, Marco Quartulli, Alberto Maria Metelli, Marcello Restelli</p></summary>
<p>

**Abstract:** Warehouse Management Systems have been evolving and improving thanks to new Data Intelligence techniques. However, many current optimizations have been applied to specific cases or are in great need of manual interaction. Here is where Reinforcement Learning techniques come into play, providing automatization and adaptability to current optimization policies. In this paper, we present Storehouse, a customizable environment that generalizes the definition of warehouse simulations for Reinforcement Learning. We also validate this environment against state-of-the-art reinforcement learning algorithms and compare these results to human and random policies.

</p>
</details>

<details><summary><b>Graph-based Molecular Representation Learning</b>
<a href="https://arxiv.org/abs/2207.04869">arxiv:2207.04869</a>
&#x1F4C8; 3 <br>
<p>Zhichun Guo, Bozhao Nan, Yijun Tian, Olaf Wiest, Chuxu Zhang, Nitesh V. Chawla</p></summary>
<p>

**Abstract:** Molecular representation learning (MRL) is a key step to build the connection between machine learning and chemical science. In particular, it encodes molecules as numerical vectors preserving the molecular structures and features, on top of which the downstream tasks (e.g., property prediction) can be performed. Recently, MRL has achieved considerable progress, especially in deep molecular graph learning-based methods. In this survey, we systematically review these graph-based molecular representation techniques. Specifically, we first introduce the data and features of the 2D and 3D graph molecular datasets. Then we summarize the methods specially designed for MRL and categorize them into four strategies. Furthermore, we discuss some typical chemical applications supported by MRL. To facilitate studies in this fast-developing area, we also list the benchmarks and commonly used datasets in the paper. Finally, we share our thoughts on future research directions.

</p>
</details>

<details><summary><b>Supervised Machine Learning for Effective Missile Launch Based on Beyond Visual Range Air Combat Simulations</b>
<a href="https://arxiv.org/abs/2207.04188">arxiv:2207.04188</a>
&#x1F4C8; 3 <br>
<p>Joao P. A. Dantas, Andre N. Costa, Felipe L. L. Medeiros, Diego Geraldo, Marcos R. O. A. Maximo, Takashi Yoneyama</p></summary>
<p>

**Abstract:** This work compares supervised machine learning methods using reliable data from constructive simulations to estimate the most effective moment for launching missiles during air combat. We employed resampling techniques to improve the predictive model, analyzing accuracy, precision, recall, and f1-score. Indeed, we could identify the remarkable performance of the models based on decision trees and the significant sensitivity of other algorithms to resampling techniques. The models with the best f1-score brought values of 0.379 and 0.465 without and with the resampling technique, respectively, which is an increase of 22.69%. Thus, if desirable, resampling techniques can improve the model's recall and f1-score with a slight decline in accuracy and precision. Therefore, through data obtained through constructive simulations, it is possible to develop decision support tools based on machine learning models, which may improve the flight quality in BVR air combat, increasing the effectiveness of offensive missions to hit a particular target.

</p>
</details>

<details><summary><b>Domain Alignment Meets Fully Test-Time Adaptation</b>
<a href="https://arxiv.org/abs/2207.04185">arxiv:2207.04185</a>
&#x1F4C8; 3 <br>
<p>Kowshik Thopalli, Pavan Turaga, Jayaraman J. Thiagarajan</p></summary>
<p>

**Abstract:** A foundational requirement of a deployed ML model is to generalize to data drawn from a testing distribution that is different from training. A popular solution to this problem is to adapt a pre-trained model to novel domains using only unlabeled data. In this paper, we focus on a challenging variant of this problem, where access to the original source data is restricted. While fully test-time adaptation (FTTA) and unsupervised domain adaptation (UDA) are closely related, the advances in UDA are not readily applicable to TTA, since most UDA methods require access to the source data. Hence, we propose a new approach, CATTAn, that bridges UDA and FTTA, by relaxing the need to access entire source data, through a novel deep subspace alignment strategy. With a minimal overhead of storing the subspace basis set for the source data, CATTAn enables unsupervised alignment between source and target data during adaptation. Through extensive experimental evaluation on multiple 2D and 3D vision benchmarks (ImageNet-C, Office-31, OfficeHome, DomainNet, PointDA-10) and model architectures, we demonstrate significant gains in FTTA performance. Furthermore, we make a number of crucial findings on the utility of the alignment objective even with inherently robust models, pre-trained ViT representations and under low sample availability in the target domain.

</p>
</details>

<details><summary><b>Transformer Neural Processes: Uncertainty-Aware Meta Learning Via Sequence Modeling</b>
<a href="https://arxiv.org/abs/2207.04179">arxiv:2207.04179</a>
&#x1F4C8; 3 <br>
<p>Tung Nguyen, Aditya Grover</p></summary>
<p>

**Abstract:** Neural Processes (NPs) are a popular class of approaches for meta-learning. Similar to Gaussian Processes (GPs), NPs define distributions over functions and can estimate uncertainty in their predictions. However, unlike GPs, NPs and their variants suffer from underfitting and often have intractable likelihoods, which limit their applications in sequential decision making. We propose Transformer Neural Processes (TNPs), a new member of the NP family that casts uncertainty-aware meta learning as a sequence modeling problem. We learn TNPs via an autoregressive likelihood-based objective and instantiate it with a novel transformer-based architecture. The model architecture respects the inductive biases inherent to the problem structure, such as invariance to the observed data points and equivariance to the unobserved points. We further investigate knobs within the TNP framework that tradeoff expressivity of the decoding distribution with extra computation. Empirically, we show that TNPs achieve state-of-the-art performance on various benchmark problems, outperforming all previous NP variants on meta regression, image completion, contextual multi-armed bandits, and Bayesian optimization.

</p>
</details>

<details><summary><b>Seasonal Encoder-Decoder Architecture for Forecasting</b>
<a href="https://arxiv.org/abs/2207.04113">arxiv:2207.04113</a>
&#x1F4C8; 3 <br>
<p>Avinash Achar, Soumen Pachal</p></summary>
<p>

**Abstract:** Deep learning (DL) in general and Recurrent neural networks (RNNs) in particular have seen high success levels in sequence based applications. This paper pertains to RNNs for time series modelling and forecasting. We propose a novel RNN architecture capturing (stochastic) seasonal correlations intelligently while capable of accurate multi-step forecasting. It is motivated from the well-known encoder-decoder (ED) architecture and multiplicative seasonal auto-regressive model. It incorporates multi-step (multi-target) learning even in the presence (or absence) of exogenous inputs. It can be employed on single or multiple sequence data. For the multiple sequence case, we also propose a novel greedy recursive procedure to build (one or more) predictive models across sequences when per-sequence data is less. We demonstrate via extensive experiments the utility of our proposed architecture both in single sequence and multiple sequence scenarios.

</p>
</details>

<details><summary><b>Evaluating Systemic Error Detection Methods using Synthetic Images</b>
<a href="https://arxiv.org/abs/2207.04104">arxiv:2207.04104</a>
&#x1F4C8; 3 <br>
<p>Gregory Plumb, Nari Johnson, Ángel Alexander Cabrera, Marco Tulio Ribeiro, Ameet Talwalkar</p></summary>
<p>

**Abstract:** We introduce SpotCheck, a framework for generating synthetic datasets to use for evaluating methods for discovering blindspots (i.e., systemic errors) in image classifiers. We use SpotCheck to run controlled studies of how various factors influence the performance of blindspot discovery methods. Our experiments reveal several shortcomings of existing methods, such as relatively poor performance in settings with multiple blindspots and sensitivity to hyperparameters. Further, we find that a method based on dimensionality reduction, PlaneSpot, is competitive with existing methods, which has promising implications for the development of interactive tools.

</p>
</details>

<details><summary><b>StatMix: Data augmentation method that relies on image statistics in federated learning</b>
<a href="https://arxiv.org/abs/2207.04103">arxiv:2207.04103</a>
&#x1F4C8; 3 <br>
<p>Dominik Lewy, Jacek Mańdziuk, Maria Ganzha, Marcin Paprzycki</p></summary>
<p>

**Abstract:** Availability of large amount of annotated data is one of the pillars of deep learning success. Although numerous big datasets have been made available for research, this is often not the case in real life applications (e.g. companies are not able to share data due to GDPR or concerns related to intellectual property rights protection). Federated learning (FL) is a potential solution to this problem, as it enables training a global model on data scattered across multiple nodes, without sharing local data itself. However, even FL methods pose a threat to data privacy, if not handled properly. Therefore, we propose StatMix, an augmentation approach that uses image statistics, to improve results of FL scenario(s). StatMix is empirically tested on CIFAR-10 and CIFAR-100, using two neural network architectures. In all FL experiments, application of StatMix improves the average accuracy, compared to the baseline training (with no use of StatMix). Some improvement can also be observed in non-FL setups.

</p>
</details>

<details><summary><b>FAIVConf: Face enhancement for AI-based Video Conference with Low Bit-rate</b>
<a href="https://arxiv.org/abs/2207.04090">arxiv:2207.04090</a>
&#x1F4C8; 3 <br>
<p>Zhengang Li, Sheng Lin, Shan Liu, Songnan Li, Xue Lin, Wei Wang, Wei Jiang</p></summary>
<p>

**Abstract:** Recently, high-quality video conferencing with fewer transmission bits has become a very hot and challenging problem. We propose FAIVConf, a specially designed video compression framework for video conferencing, based on the effective neural human face generation techniques. FAIVConf brings together several designs to improve the system robustness in real video conference scenarios: face-swapping to avoid artifacts in background animation; facial blurring to decrease transmission bit-rate and maintain the quality of extracted facial landmarks; and dynamic source update for face view interpolation to accommodate a large range of head poses. Our method achieves a significant bit-rate reduction in the video conference and gives much better visual quality under the same bit-rate compared with H.264 and H.265 coding schemes.

</p>
</details>

<details><summary><b>Graph-based Multi-View Fusion and Local Adaptation: Mitigating Within-Household Confusability for Speaker Identification</b>
<a href="https://arxiv.org/abs/2207.04081">arxiv:2207.04081</a>
&#x1F4C8; 3 <br>
<p>Long Chen, Yixiong Meng, Venkatesh Ravichandran, Andreas Stolcke</p></summary>
<p>

**Abstract:** Speaker identification (SID) in the household scenario (e.g., for smart speakers) is an important but challenging problem due to limited number of labeled (enrollment) utterances, confusable voices, and demographic imbalances. Conventional speaker recognition systems generalize from a large random sample of speakers, causing the recognition to underperform for households drawn from specific cohorts or otherwise exhibiting high confusability. In this work, we propose a graph-based semi-supervised learning approach to improve household-level SID accuracy and robustness with locally adapted graph normalization and multi-signal fusion with multi-view graphs. Unlike other work on household SID, fairness, and signal fusion, this work focuses on speaker label inference (scoring) and provides a simple solution to realize household-specific adaptation and multi-signal fusion without tuning the embeddings or training a fusion network. Experiments on the VoxCeleb dataset demonstrate that our approach consistently improves the performance across households with different customer cohorts and degrees of confusability.

</p>
</details>

<details><summary><b>Causal Discovery using Model Invariance through Knockoff Interventions</b>
<a href="https://arxiv.org/abs/2207.04055">arxiv:2207.04055</a>
&#x1F4C8; 3 <br>
<p>Wasim Ahmad, Maha Shadaydeh, Joachim Denzler</p></summary>
<p>

**Abstract:** Cause-effect analysis is crucial to understand the underlying mechanism of a system. We propose to exploit model invariance through interventions on the predictors to infer causality in nonlinear multivariate systems of time series. We model nonlinear interactions in time series using DeepAR and then expose the model to different environments using Knockoffs-based interventions to test model invariance. Knockoff samples are pairwise exchangeable, in-distribution and statistically null variables generated without knowing the response. We test model invariance where we show that the distribution of the response residual does not change significantly upon interventions on non-causal predictors. We evaluate our method on real and synthetically generated time series. Overall our method outperforms other widely used causality methods, i.e, VAR Granger causality, VARLiNGAM and PCMCI+.

</p>
</details>

<details><summary><b>A Multi-tasking Model of Speaker-Keyword Classification for Keeping Human in the Loop of Drone-assisted Inspection</b>
<a href="https://arxiv.org/abs/2207.04027">arxiv:2207.04027</a>
&#x1F4C8; 3 <br>
<p>Yu Li, Anisha Parsan, Bill Wang, Penghao Dong, Shanshan Yao, Ruwen Qin</p></summary>
<p>

**Abstract:** Audio commands are a preferred communication medium to keep inspectors in the loop of civil infrastructure inspection performed by a semi-autonomous drone. To understand job-specific commands from a group of heterogeneous and dynamic inspectors, a model needs to be developed cost-effectively for the group and easily adapted when the group changes. This paper is motivated to build a multi-tasking deep learning model that possesses a Share-Split-Collaborate architecture. This architecture allows the two classification tasks to share the feature extractor and then split subject-specific and keyword-specific features intertwined in the extracted features through feature projection and collaborative training. A base model for a group of five authorized subjects is trained and tested on the inspection keyword dataset collected by this study. The model achieved a 95.3% or higher mean accuracy in classifying the keywords of any authorized inspectors. Its mean accuracy in speaker classification is 99.2%. Due to the richer keyword representations that the model learns from the pooled training data, adapting the base model to a new inspector requires only a little training data from that inspector, like five utterances per keyword. Using the speaker classification scores for inspector verification can achieve a success rate of at least 93.9% in verifying authorized inspectors and 76.1\% in detecting unauthorized ones. Further, the paper demonstrates the applicability of the proposed model to larger-size groups on a public dataset. This paper provides a solution to addressing challenges facing AI-assisted human-robot interaction, including worker heterogeneity, worker dynamics, and job heterogeneity.

</p>
</details>

<details><summary><b>Learning with Muscles: Benefits for Data-Efficiency and Robustness in Anthropomorphic Tasks</b>
<a href="https://arxiv.org/abs/2207.03952">arxiv:2207.03952</a>
&#x1F4C8; 3 <br>
<p>Isabell Wochner, Pierre Schumacher, Georg Martius, Dieter Büchler, Syn Schmitt, Daniel F. B. Haeufle</p></summary>
<p>

**Abstract:** Humans are able to outperform robots in terms of robustness, versatility, and learning of new tasks in a wide variety of movements. We hypothesize that highly nonlinear muscle dynamics play a large role in providing inherent stability, which is favorable to learning. While recent advances have been made in applying modern learning techniques to muscle-actuated systems both in simulation as well as in robotics, so far, no detailed analysis has been performed to show the benefits of muscles in this setting. Our study closes this gap by investigating core robotics challenges and comparing the performance of different actuator morphologies in terms of data-efficiency, hyperparameter sensitivity, and robustness.

</p>
</details>

<details><summary><b>BAST: Binaural Audio Spectrogram Transformer for Binaural Sound Localization</b>
<a href="https://arxiv.org/abs/2207.03927">arxiv:2207.03927</a>
&#x1F4C8; 3 <br>
<p>Sheng Kuang, Kiki van der Heijden, Siamak Mehrkanoon</p></summary>
<p>

**Abstract:** Accurate sound localization in a reverberation environment is essential for human auditory perception. Recently, Convolutional Neural Networks (CNNs) have been utilized to model the binaural human auditory pathway. However, CNN shows barriers in capturing the global acoustic features. To address this issue, we propose a novel end-to-end Binaural Audio Spectrogram Transformer (BAST) model to predict the sound azimuth in both anechoic and reverberation environments. Two modes of implementation, i.e. BAST-SP and BAST-NSP corresponding to BAST model with shared and non-shared parameters respectively, are explored. Our model with subtraction interaural integration and hybrid loss achieves an angular distance of 1.29 degrees and a Mean Square Error of 1e-3 at all azimuths, significantly surpassing CNN based model. The exploratory analysis of the BAST's performance on the left-right hemifields and anechoic and reverberation environments shows its generalization ability as well as the feasibility of binaural Transformers in sound localization. Furthermore, the analysis of the attention maps is provided to give additional insights on the interpretation of the localization process in a natural reverberant environment.

</p>
</details>

<details><summary><b>Interaction Pattern Disentangling for Multi-Agent Reinforcement Learning</b>
<a href="https://arxiv.org/abs/2207.03902">arxiv:2207.03902</a>
&#x1F4C8; 3 <br>
<p>Shunyu Liu, Jie Song, Yihe Zhou, Na Yu, Kaixuan Chen, Zunlei Feng, Mingli Song</p></summary>
<p>

**Abstract:** Deep cooperative multi-agent reinforcement learning has demonstrated its remarkable success over a wide spectrum of complex control tasks. However, recent advances in multi-agent learning mainly focus on value decomposition while leaving entity interactions still intertwined, which easily leads to over-fitting on noisy interactions between entities. In this work, we introduce a novel interactiOn Pattern disenTangling (OPT) method, to disentangle not only the joint value function into agent-wise value functions for decentralized execution, but also the entity interactions into interaction prototypes, each of which represents an underlying interaction pattern within a sub-group of the entities. OPT facilitates filtering the noisy interactions between irrelevant entities and thus significantly improves generalizability as well as interpretability. Specifically, OPT introduces a sparse disagreement mechanism to encourage sparsity and diversity among discovered interaction prototypes. Then the model selectively restructures these prototypes into a compact interaction pattern by an aggregator with learnable weights. To alleviate the training instability issue caused by partial observability, we propose to maximize the mutual information between the aggregation weights and the history behaviors of each agent. Experiments on both single-task and multi-task benchmarks demonstrate that the proposed method yields results superior to the state-of-the-art counterparts. Our code will be made publicly available.

</p>
</details>

<details><summary><b>Stacked Autoencoder Based Multi-Omics Data Integration for Cancer Survival Prediction</b>
<a href="https://arxiv.org/abs/2207.04878">arxiv:2207.04878</a>
&#x1F4C8; 2 <br>
<p>Xing Wu, Qiulian Fang</p></summary>
<p>

**Abstract:** Cancer survival prediction is important for developing personalized treatments and inducing disease-causing mechanisms. Multi-omics data integration is attracting widespread interest in cancer research for providing information for understanding cancer progression at multiple genetic levels. Many works, however, are limited because of the high dimensionality and heterogeneity of multi-omics data. In this paper, we propose a novel method to integrate multi-omics data for cancer survival prediction, called Stacked AutoEncoder-based Survival Prediction Neural Network (SAEsurv-net). In the cancer survival prediction for TCGA cases, SAEsurv-net addresses the curse of dimensionality with a two-stage dimensionality reduction strategy and handles multi-omics heterogeneity with a stacked autoencoder model. The two-stage dimensionality reduction strategy achieves a balance between computation complexity and information exploiting. The stacked autoencoder model removes most heterogeneities such as data's type and size in the first group of autoencoders, and integrates multiple omics data in the second autoencoder. The experiments show that SAEsurv-net outperforms models based on a single type of data as well as other state-of-the-art methods.

</p>
</details>

<details><summary><b>Stochastic approximation with decision-dependent distributions: asymptotic normality and optimality</b>
<a href="https://arxiv.org/abs/2207.04173">arxiv:2207.04173</a>
&#x1F4C8; 2 <br>
<p>Joshua Cutler, Mateo Díaz, Dmitriy Drusvyatskiy</p></summary>
<p>

**Abstract:** We analyze a stochastic approximation algorithm for decision-dependent problems, wherein the data distribution used by the algorithm evolves along the iterate sequence. The primary examples of such problems appear in performative prediction and its multiplayer extensions. We show that under mild assumptions, the deviation between the average iterate of the algorithm and the solution is asymptotically normal, with a covariance that nicely decouples the effects of the gradient noise and the distributional shift. Moreover, building on the work of Hájek and Le Cam, we show that the asymptotic performance of the algorithm is locally minimax optimal.

</p>
</details>

<details><summary><b>A Survey of Task-Based Machine Learning Content Extraction Services for VIDINT</b>
<a href="https://arxiv.org/abs/2207.04158">arxiv:2207.04158</a>
&#x1F4C8; 2 <br>
<p>Joshua Brunk, Nathan Jermann, Ryan Sharp, Carl D. Hoover</p></summary>
<p>

**Abstract:** This paper provides a comparison of current video content extraction tools with a focus on comparing commercial task-based machine learning services. Video intelligence (VIDINT) data has become a critical intelligence source in the past decade. The need for AI-based analytics and automation tools to extract and structure content from video has quickly become a priority for organizations needing to search, analyze and exploit video at scale. With rapid growth in machine learning technology, the maturity of machine transcription, machine translation, topic tagging, and object recognition tasks are improving at an exponential rate, breaking performance records in speed and accuracy as new applications evolve. Each section of this paper reviews and compares products, software resources and video analytics capabilities based on tasks relevant to extracting information from video with machine learning techniques.

</p>
</details>

<details><summary><b>Online Learning in Supply-Chain Games</b>
<a href="https://arxiv.org/abs/2207.04054">arxiv:2207.04054</a>
&#x1F4C8; 2 <br>
<p>Nicolò Cesa-Bianchi, Tommaso Cesari, Takayuki Osogami, Marco Scarsini, Segev Wasserkrug</p></summary>
<p>

**Abstract:** We study a repeated game between a supplier and a retailer who want to maximize their respective profits without full knowledge of the problem parameters. After characterizing the uniqueness of the Stackelberg equilibrium of the stage game with complete information, we show that even with partial knowledge of the joint distribution of demand and production costs, natural learning dynamics guarantee convergence of the joint strategy profile of supplier and retailer to the Stackelberg equilibrium of the stage game. We also prove finite-time bounds on the supplier's regret and asymptotic bounds on the retailer's regret, where the specific rates depend on the type of knowledge preliminarily available to the players. In the special case when the supplier is not strategic (vertical integration), we prove optimal finite-time regret bounds on the retailer's regret (or, equivalently, the social welfare) when costs and demand are adversarially generated and the demand is censored.

</p>
</details>

<details><summary><b>CoCAtt: A Cognitive-Conditioned Driver Attention Dataset (Supplementary Material)</b>
<a href="https://arxiv.org/abs/2207.04028">arxiv:2207.04028</a>
&#x1F4C8; 2 <br>
<p>Yuan Shen, Niviru Wijayaratne, Pranav Sriram, Aamir Hasan, Peter Du, Katherine Driggs-Campbell</p></summary>
<p>

**Abstract:** The task of driver attention prediction has drawn considerable interest among researchers in robotics and the autonomous vehicle industry. Driver attention prediction can play an instrumental role in mitigating and preventing high-risk events, like collisions and casualties. However, existing driver attention prediction models neglect the distraction state and intention of the driver, which can significantly influence how they observe their surroundings. To address these issues, we present a new driver attention dataset, CoCAtt (Cognitive-Conditioned Attention). Unlike previous driver attention datasets, CoCAtt includes per-frame annotations that describe the distraction state and intention of the driver. In addition, the attention data in our dataset is captured in both manual and autopilot modes using eye-tracking devices of different resolutions. Our results demonstrate that incorporating the above two driver states into attention modeling can improve the performance of driver attention prediction. To the best of our knowledge, this work is the first to provide autopilot attention data. Furthermore, CoCAtt is currently the largest and the most diverse driver attention dataset in terms of autonomy levels, eye tracker resolutions, and driving scenarios. CoCAtt is available for download at https://cocatt-dataset.github.io.

</p>
</details>

<details><summary><b>Dreamento: An open-source dream engineering toolbox utilizing sleep wearable</b>
<a href="https://arxiv.org/abs/2207.03977">arxiv:2207.03977</a>
&#x1F4C8; 2 <br>
<p>Mahdad Jafarzadeh Esfahani, Amir Hossein Daraie, Frederik D. Weber, Martin Dresler</p></summary>
<p>

**Abstract:** We introduce Dreamento (Dream engineering toolbox), an open-source Python package for dream engineering utilizing the ZMax (Hypnodyne Corp., Sofia, Bulgaria) headband sleep wearable. Dreamento main functions are (1) real-time recording, monitoring, analysis, and stimulation in a graphical user interface (GUI) (2) and offline post-processing of the resulting data. In real-time, Dreamento is capable of (1) recording data, (2) visualizing data, including power-spectrum analysis and navigation, (3) automatic sleep-scoring, (4) sensory stimulation (visual, auditory, tactile), (5) establishing text-to-speech communication, and (6) managing the annotations of automatic and manual events. The offline functionality aids in post-processing the acquired data with features to reformat the wearable data and integrate it with non-wearable recorded modalities such as electromyography. While the primary application of Dreamento was developed for (lucid) dreaming studies, it is open to being adapted for other purposes and measurement modalities.

</p>
</details>

<details><summary><b>Generalization-Memorization Machines</b>
<a href="https://arxiv.org/abs/2207.03976">arxiv:2207.03976</a>
&#x1F4C8; 2 <br>
<p>Zhen Wang, Yuan-Hai Shao</p></summary>
<p>

**Abstract:** Classifying the training data correctly without over-fitting is one of the goals in machine learning. In this paper, we propose a generalization-memorization mechanism, including a generalization-memorization decision and a memory modeling principle. Under this mechanism, error-based learning machines improve their memorization abilities of training data without over-fitting. Specifically, the generalization-memorization machines (GMM) are proposed by applying this mechanism. The optimization problems in GMM are quadratic programming problems and could be solved efficiently. It should be noted that the recently proposed generalization-memorization kernel and the corresponding support vector machines are the special cases of our GMM. Experimental results show the effectiveness of the proposed GMM both on memorization and generalization.

</p>
</details>

<details><summary><b>Black and Gray Box Learning of Amplitude Equations: Application to Phase Field Systems</b>
<a href="https://arxiv.org/abs/2207.03954">arxiv:2207.03954</a>
&#x1F4C8; 2 <br>
<p>Felix P. Kemeth, Sergio Alonso, Blas Echebarria, Ted Moldenhawer, Carsten Beta, Ioannis G. Kevrekidis</p></summary>
<p>

**Abstract:** We present a data-driven approach to learning surrogate models for amplitude equations, and illustrate its application to interfacial dynamics of phase field systems. In particular, we demonstrate learning effective partial differential equations describing the evolution of phase field interfaces from full phase field data. We illustrate this on a model phase field system, where analytical approximate equations for the dynamics of the phase field interface (a higher order eikonal equation and its approximation, the Kardar-Parisi-Zhang (KPZ) equation) are known. For this system, we discuss data-driven approaches for the identification of equations that accurately describe the front interface dynamics. When the analytical approximate models mentioned above become inaccurate, as we move beyond the region of validity of the underlying assumptions, the data-driven equations outperform them. In these regimes, going beyond black-box identification, we explore different approaches to learn data-driven corrections to the analytically approximate models, leading to effective gray box partial differential equations.

</p>
</details>

<details><summary><b>ControlBurn: Nonlinear Feature Selection with Sparse Tree Ensembles</b>
<a href="https://arxiv.org/abs/2207.03935">arxiv:2207.03935</a>
&#x1F4C8; 2 <br>
<p>Brian Liu, Miaolan Xie, Haoyue Yang, Madeleine Udell</p></summary>
<p>

**Abstract:** ControlBurn is a Python package to construct feature-sparse tree ensembles that support nonlinear feature selection and interpretable machine learning. The algorithms in this package first build large tree ensembles that prioritize basis functions with few features and then select a feature-sparse subset of these basis functions using a weighted lasso optimization criterion. The package includes visualizations to analyze the features selected by the ensemble and their impact on predictions. Hence ControlBurn offers the accuracy and flexibility of tree-ensemble models and the interpretability of sparse generalized additive models.
  ControlBurn is scalable and flexible: for example, it can use warm-start continuation to compute the regularization path (prediction error for any number of selected features) for a dataset with tens of thousands of samples and hundreds of features in seconds. For larger datasets, the runtime scales linearly in the number of samples and features (up to a log factor), and the package support acceleration using sketching. Moreover, the ControlBurn framework accommodates feature costs, feature groupings, and $\ell_0$-based regularizers. The package is user-friendly and open-source: its documentation and source code appear on https://pypi.org/project/ControlBurn/ and https://github.com/udellgroup/controlburn/.

</p>
</details>

<details><summary><b>Generative Adversarial Networks and Other Generative Models</b>
<a href="https://arxiv.org/abs/2207.03887">arxiv:2207.03887</a>
&#x1F4C8; 2 <br>
<p>Markus Wenzel</p></summary>
<p>

**Abstract:** Generative networks are fundamentally different in their aim and methods compared to CNNs for classification, segmentation, or object detection. They have initially not been meant to be an image analysis tool, but to produce naturally looking images. The adversarial training paradigm has been proposed to stabilize generative methods, and has proven to be highly successful -- though by no means from the first attempt.
  This chapter gives a basic introduction into the motivation for Generative Adversarial Networks (GANs) and traces the path of their success by abstracting the basic task and working mechanism, and deriving the difficulty of early practical approaches. Methods for a more stable training will be shown, and also typical signs for poor convergence and their reasons.
  Though this chapter focuses on GANs that are meant for image generation and image analysis, the adversarial training paradigm itself is not specific to images, and also generalizes to tasks in image analysis. Examples of architectures for image semantic segmentation and abnormality detection will be acclaimed, before contrasting GANs with further generative modeling approaches lately entering the scene. This will allow a contextualized view on the limits but also benefits of GANs.

</p>
</details>

<details><summary><b>NExG: Provable and Guided State Space Exploration of Neural Network Control Systems using Sensitivity Approximation</b>
<a href="https://arxiv.org/abs/2207.03884">arxiv:2207.03884</a>
&#x1F4C8; 2 <br>
<p>Manish Goyal, Miheer Dewaskar, Parasara Sridhar Duggirala</p></summary>
<p>

**Abstract:** We propose a new technique for performing state space exploration of closed loop control systems with neural network feedback controllers. Our approach involves approximating the sensitivity of the trajectories of the closed loop dynamics. Using such an approximator and the system simulator, we present a guided state space exploration method that can generate trajectories visiting the neighborhood of a target state at a specified time. We present a theoretical framework which establishes that our method will produce a sequence of trajectories that will reach a suitable neighborhood of the target state. We provide thorough evaluation of our approach on various systems with neural network feedback controllers of different configurations. We outperform earlier state space exploration techniques and achieve significant improvement in both the quality (explainability) and performance (convergence rate). Finally, we adopt our algorithm for the falsification of a class of temporal logic specification, assess its performance against a state-of-the-art falsification tool, and show its potential in supplementing existing falsification algorithms.

</p>
</details>

<details><summary><b>The Power of Transfer Learning in Agricultural Applications: AgriNet</b>
<a href="https://arxiv.org/abs/2207.03881">arxiv:2207.03881</a>
&#x1F4C8; 2 <br>
<p>Zahraa Al Sahili, Mariette Awad</p></summary>
<p>

**Abstract:** Advances in deep learning and transfer learning have paved the way for various automation classification tasks in agriculture, including plant diseases, pests, weeds, and plant species detection. However, agriculture automation still faces various challenges, such as the limited size of datasets and the absence of plant-domain-specific pretrained models. Domain specific pretrained models have shown state of art performance in various computer vision tasks including face recognition and medical imaging diagnosis. In this paper, we propose AgriNet dataset, a collection of 160k agricultural images from more than 19 geographical locations, several images captioning devices, and more than 423 classes of plant species and diseases. We also introduce AgriNet models, a set of pretrained models on five ImageNet architectures: VGG16, VGG19, Inception-v3, InceptionResNet-v2, and Xception. AgriNet-VGG19 achieved the highest classification accuracy of 94 % and the highest F1-score of 92%. Additionally, all proposed models were found to accurately classify the 423 classes of plant species, diseases, pests, and weeds with a minimum accuracy of 87% for the Inception-v3 model.Finally, experiments to evaluate of superiority of AgriNet models compared to ImageNet models were conducted on two external datasets: pest and plant diseases dataset from Bangladesh and a plant diseases dataset from Kashmir.

</p>
</details>

<details><summary><b>Safe reinforcement learning for multi-energy management systems with known constraint functions</b>
<a href="https://arxiv.org/abs/2207.03830">arxiv:2207.03830</a>
&#x1F4C8; 2 <br>
<p>Glenn Ceusters, Luis Ramirez Camargo, Rüdiger Franke, Ann Nowé, Maarten Messagie</p></summary>
<p>

**Abstract:** Reinforcement learning (RL) is a promising optimal control technique for multi-energy management systems. It does not require a model a priori - reducing the upfront and ongoing project-specific engineering effort and is capable of learning better representations of the underlying system dynamics. However, vanilla RL does not provide constraint satisfaction guarantees - resulting in various unsafe interactions within its safety-critical environment. In this paper, we present two novel safe RL methods, namely SafeFallback and GiveSafe, where the safety constraint formulation is decoupled from the RL formulation and which provides hard-constraint satisfaction guarantees both during training (exploration) and exploitation of the (close-to) optimal policy. In a simulated multi-energy systems case study we have shown that both methods start with a significantly higher utility (i.e. useful policy) compared to a vanilla RL benchmark (94,6% and 82,8% compared to 35,5%) and that the proposed SafeFallback method even can outperform the vanilla RL benchmark (102,9% to 100%). We conclude that both methods are viably safety constraint handling techniques capable beyond RL, as demonstrated with random agents while still providing hard-constraint guarantees. Finally, we propose fundamental future work to i.a. improve the constraint functions itself as more data becomes available.

</p>
</details>

<details><summary><b>Complementing Brightness Constancy with Deep Networks for Optical Flow Prediction</b>
<a href="https://arxiv.org/abs/2207.03790">arxiv:2207.03790</a>
&#x1F4C8; 2 <br>
<p>Vincent Le Guen, Clément Rambour, Nicolas Thome</p></summary>
<p>

**Abstract:** State-of-the-art methods for optical flow estimation rely on deep learning, which require complex sequential training schemes to reach optimal performances on real-world data. In this work, we introduce the COMBO deep network that explicitly exploits the brightness constancy (BC) model used in traditional methods. Since BC is an approximate physical model violated in several situations, we propose to train a physically-constrained network complemented with a data-driven network. We introduce a unique and meaningful flow decomposition between the physical prior and the data-driven complement, including an uncertainty quantification of the BC model. We derive a joint training scheme for learning the different components of the decomposition ensuring an optimal cooperation, in a supervised but also in a semi-supervised context. Experiments show that COMBO can improve performances over state-of-the-art supervised networks, e.g. RAFT, reaching state-of-the-art results on several benchmarks. We highlight how COMBO can leverage the BC model and adapt to its limitations. Finally, we show that our semi-supervised method can significantly simplify the training procedure.

</p>
</details>

<details><summary><b>Continuous Target-free Extrinsic Calibration of a Multi-Sensor System from a Sequence of Static Viewpoints</b>
<a href="https://arxiv.org/abs/2207.03785">arxiv:2207.03785</a>
&#x1F4C8; 2 <br>
<p>Philipp Glira, Christoph Weidinger, Johann Weichselbaum</p></summary>
<p>

**Abstract:** Mobile robotic applications need precise information about the geometric position of the individual sensors on the platform. This information is given by the extrinsic calibration parameters which define how the sensor is rotated and translated with respect to a fixed reference coordinate system. Erroneous calibration parameters have a negative impact on typical robotic estimation tasks, e.g. SLAM. In this work we propose a new method for a continuous estimation of the calibration parameters during operation of the robot. The parameter estimation is based on the matching of point clouds which are acquired by the sensors from multiple static viewpoints. Consequently, our method does not need any special calibration targets and is applicable to any sensor whose measurements can be converted to point clouds. We demonstrate the suitability of our method by calibrating a multi-sensor system composed by 2 lidar sensors, 3 cameras, and an imaging radar sensor.

</p>
</details>

<details><summary><b>Tackling Data Heterogeneity: A New Unified Framework for Decentralized SGD with Sample-induced Topology</b>
<a href="https://arxiv.org/abs/2207.03730">arxiv:2207.03730</a>
&#x1F4C8; 2 <br>
<p>Yan Huang, Ying Sun, Zehan Zhu, Changzhi Yan, Jinming Xu</p></summary>
<p>

**Abstract:** We develop a general framework unifying several gradient-based stochastic optimization methods for empirical risk minimization problems both in centralized and distributed scenarios. The framework hinges on the introduction of an augmented graph consisting of nodes modeling the samples and edges modeling both the inter-device communication and intra-device stochastic gradient computation. By designing properly the topology of the augmented graph, we are able to recover as special cases the renowned Local-SGD and DSGD algorithms, and provide a unified perspective for variance-reduction (VR) and gradient-tracking (GT) methods such as SAGA, Local-SVRG and GT-SAGA. We also provide a unified convergence analysis for smooth and (strongly) convex objectives relying on a proper structured Lyapunov function, and the obtained rate can recover the best known results for many existing algorithms. The rate results further reveal that VR and GT methods can effectively eliminate data heterogeneity within and across devices, respectively, enabling the exact convergence of the algorithm to the optimal solution. Numerical experiments confirm the findings in this paper.

</p>
</details>

<details><summary><b>Guiding the retraining of convolutional neural networks against adversarial inputs</b>
<a href="https://arxiv.org/abs/2207.03689">arxiv:2207.03689</a>
&#x1F4C8; 2 <br>
<p>Francisco Durán López, Silverio Martínez-Fernández, Michael Felderer, Xavier Franch</p></summary>
<p>

**Abstract:** Background: When using deep learning models, there are many possible vulnerabilities and some of the most worrying are the adversarial inputs, which can cause wrong decisions with minor perturbations. Therefore, it becomes necessary to retrain these models against adversarial inputs, as part of the software testing process addressing the vulnerability to these inputs. Furthermore, for an energy efficient testing and retraining, data scientists need support on which are the best guidance metrics and optimal dataset configurations.
  Aims: We examined four guidance metrics for retraining convolutional neural networks and three retraining configurations. Our goal is to improve the models against adversarial inputs regarding accuracy, resource utilization and time from the point of view of a data scientist in the context of image classification.
  Method: We conducted an empirical study in two datasets for image classification. We explore: (a) the accuracy, resource utilization and time of retraining convolutional neural networks by ordering new training set by four different guidance metrics (neuron coverage, likelihood-based surprise adequacy, distance-based surprise adequacy and random), (b) the accuracy and resource utilization of retraining convolutional neural networks with three different configurations (from scratch and augmented dataset, using weights and augmented dataset, and using weights and only adversarial inputs).
  Results: We reveal that retraining with adversarial inputs from original weights and by ordering with surprise adequacy metrics gives the best model w.r.t. the used metrics.
  Conclusions: Although more studies are necessary, we recommend data scientists to use the above configuration and metrics to deal with the vulnerability to adversarial inputs of deep learning models, as they can improve their models against adversarial inputs without using many inputs.

</p>
</details>

<details><summary><b>Lessons from Deep Learning applied to Scholarly Information Extraction: What Works, What Doesn't, and Future Directions</b>
<a href="https://arxiv.org/abs/2207.04029">arxiv:2207.04029</a>
&#x1F4C8; 1 <br>
<p>Raquib Bin Yousuf, Subhodip Biswas, Kulendra Kumar Kaushal, James Dunham, Rebecca Gelles, Sathappan Muthiah, Nathan Self, Patrick Butler, Naren Ramakrishnan</p></summary>
<p>

**Abstract:** Understanding key insights from full-text scholarly articles is essential as it enables us to determine interesting trends, give insight into the research and development, and build knowledge graphs. However, some of the interesting key insights are only available when considering full-text. Although researchers have made significant progress in information extraction from short documents, extraction of scientific entities from full-text scholarly literature remains a challenging problem. This work presents an automated End-to-end Research Entity Extractor called EneRex to extract technical facets such as dataset usage, objective task, method from full-text scholarly research articles. Additionally, we extracted three novel facets, e.g., links to source code, computing resources, programming language/libraries from full-text articles. We demonstrate how EneRex is able to extract key insights and trends from a large-scale dataset in the domain of computer science. We further test our pipeline on multiple datasets and found that the EneRex improves upon a state of the art model. We highlight how the existing datasets are limited in their capacity and how EneRex may fit into an existing knowledge graph. We also present a detailed discussion with pointers for future research. Our code and data are publicly available at https://github.com/DiscoveryAnalyticsCenter/EneRex.

</p>
</details>

<details><summary><b>On Improving the Performance of Glitch Classification for Gravitational Wave Detection by using Generative Adversarial Networks</b>
<a href="https://arxiv.org/abs/2207.04001">arxiv:2207.04001</a>
&#x1F4C8; 1 <br>
<p>Jianqi Yan, Alex P. Leung, David C. Y. Hui</p></summary>
<p>

**Abstract:** Spectrogram classification plays an important role in analyzing gravitational wave data. In this paper, we propose a framework to improve the classification performance by using Generative Adversarial Networks (GANs). As substantial efforts and expertise are required to annotate spectrograms, the number of training examples is very limited. However, it is well known that deep networks can perform well only when the sample size of the training set is sufficiently large. Furthermore, the imbalanced sample sizes in different classes can also hamper the performance. In order to tackle these problems, we propose a GAN-based data augmentation framework. While standard data augmentation methods for conventional images cannot be applied on spectrograms, we found that a variant of GANs, ProGAN, is capable of generating high-resolution spectrograms which are consistent with the quality of the high-resolution original images and provide a desirable diversity. We have validated our framework by classifying glitches in the {\it Gravity Spy} dataset with the GAN-generated spectrograms for training. We show that the proposed method can provide an alternative to transfer learning for the classification of spectrograms using deep networks, i.e. using a high-resolution GAN for data augmentation instead. Furthermore, fluctuations in classification performance with small sample sizes for training and evaluation can be greatly reduced. Using the trained network in our framework, we have also examined the spectrograms with label anomalies in {\it Gravity Spy}.

</p>
</details>

<details><summary><b>Reproducing sensory induced hallucinations via neural fields</b>
<a href="https://arxiv.org/abs/2207.03901">arxiv:2207.03901</a>
&#x1F4C8; 1 <br>
<p>Cyprien Tamekue, Dario Prandi, Yacine Chitour</p></summary>
<p>

**Abstract:** Understanding sensory-induced cortical patterns in the primary visual cortex V1 is an important challenge both for physiological motivations and for improving our understanding of human perception and visual organisation. In this work, we focus on pattern formation in the visual cortex when the cortical activity is driven by a geometric visual hallucination-like stimulus. In particular, we present a theoretical framework for sensory-induced hallucinations which allows one to reproduce novel psychophysical results such as the MacKay effect (Nature, 1957) and the Billock and Tsou experiences (PNAS, 2007).

</p>
</details>

<details><summary><b>Tightening Discretization-based MILP Models for the Pooling Problem using Upper Bounds on Bilinear Terms</b>
<a href="https://arxiv.org/abs/2207.03699">arxiv:2207.03699</a>
&#x1F4C8; 1 <br>
<p>Yifu Chen, Christos T. Maravelias, Xiaomin Zhang</p></summary>
<p>

**Abstract:** Discretization-based methods have been proposed for solving nonconvex optimization problems with bilinear terms. These methods convert the original nonconvex optimization problems into mixed-integer linear programs (MILPs). Compared to a wide range of studies related to methods to convert nonconvex optimization problems into MILPs, research on tightening the resulting MILP models is limited. In this paper, we present tightening constraints for the discretization-based MILP models for the pooling problem. Specifically, we study tightening constraints derived from upper bounds on bilinear term and exploiting the structures resulting from the discretization. We demonstrate the effectiveness of our constraints, showing computational results for MILP models derived from different formulations for (1) the pooling problem and (2) discretization-based pooling models. Computational results show that our methods reduce the computational time for MILP models on CPLEX 12.10. Finally, we note that while our methods are presented in the context of the pooling problem, they can be extended to address other nonconvex optimization problems with upper bounds on bilinear terms.

</p>
</details>

<details><summary><b>L$_0$onie: Compressing COINs with L$_0$-constraints</b>
<a href="https://arxiv.org/abs/2207.04144">arxiv:2207.04144</a>
&#x1F4C8; 0 <br>
<p>Juan Ramirez, Jose Gallego-Posada</p></summary>
<p>

**Abstract:** Advances in Implicit Neural Representations (INR) have motivated research on domain-agnostic compression techniques. These methods train a neural network to approximate an object, and then store the weights of the trained model. For example, given an image, a network is trained to learn the mapping from pixel locations to RGB values. In this paper, we propose L$_0$onie, a sparsity-constrained extension of the COIN compression method. Sparsity allows to leverage the faster learning of overparameterized networks, while retaining the desirable compression rate of smaller models. Moreover, our constrained formulation ensures that the final model respects a pre-determined compression rate, dispensing of the need for expensive architecture search.

</p>
</details>

<details><summary><b>Active Learning-based Isolation Forest (ALIF): Enhancing Anomaly Detection in Decision Support Systems</b>
<a href="https://arxiv.org/abs/2207.03934">arxiv:2207.03934</a>
&#x1F4C8; 0 <br>
<p>Elisa Marcelli, Tommaso Barbariol, Gian Antonio Susto</p></summary>
<p>

**Abstract:** The detection of anomalous behaviours is an emerging need in many applications, particularly in contexts where security and reliability are critical aspects. While the definition of anomaly strictly depends on the domain framework, it is often impractical or too time consuming to obtain a fully labelled dataset. The use of unsupervised models to overcome the lack of labels often fails to catch domain specific anomalies as they rely on general definitions of outlier. This paper suggests a new active learning based approach, ALIF, to solve this problem by reducing the number of required labels and tuning the detector towards the definition of anomaly provided by the user. The proposed approach is particularly appealing in the presence of a Decision Support System (DSS), a case that is increasingly popular in real-world scenarios. While it is common that DSS embedded with anomaly detection capabilities rely on unsupervised models, they don't have a way to improve their performance: ALIF is able to enhance the capabilities of DSS by exploiting the user feedback during common operations. ALIF is a lightweight modification of the popular Isolation Forest that proved superior performances with respect to other state-of-art algorithms in a multitude of real anomaly detection datasets.

</p>
</details>


{% endraw %}
Prev: [2022.07.07]({{ '/2022/07/07/2022.07.07.html' | relative_url }})  Next: [2022.07.09]({{ '/2022/07/09/2022.07.09.html' | relative_url }})