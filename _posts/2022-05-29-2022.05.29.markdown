Prev: [2022.05.28]({{ '/2022/05/28/2022.05.28.html' | relative_url }})  Next: [2022.05.30]({{ '/2022/05/30/2022.05.30.html' | relative_url }})
{% raw %}
## Summary for 2022-05-29, created on 2022-06-05


<details><summary><b>CogVideo: Large-scale Pretraining for Text-to-Video Generation via Transformers</b>
<a href="https://arxiv.org/abs/2205.15868">arxiv:2205.15868</a>
&#x1F4C8; 2450 <br>
<p>Wenyi Hong, Ming Ding, Wendi Zheng, Xinghan Liu, Jie Tang</p></summary>
<p>

**Abstract:** Large-scale pretrained transformers have created milestones in text (GPT-3) and text-to-image (DALL-E and CogView) generation. Its application to video generation is still facing many challenges: The potential huge computation cost makes the training from scratch unaffordable; The scarcity and weak relevance of text-video datasets hinder the model understanding complex movement semantics. In this work, we present 9B-parameter transformer CogVideo, trained by inheriting a pretrained text-to-image model, CogView2. We also propose multi-frame-rate hierarchical training strategy to better align text and video clips. As (probably) the first open-source large-scale pretrained text-to-video model, CogVideo outperforms all publicly available models at a large margin in machine and human evaluations.

</p>
</details>

<details><summary><b>Play it by Ear: Learning Skills amidst Occlusion through Audio-Visual Imitation Learning</b>
<a href="https://arxiv.org/abs/2205.14850">arxiv:2205.14850</a>
&#x1F4C8; 40 <br>
<p>Maximilian Du, Olivia Y. Lee, Suraj Nair, Chelsea Finn</p></summary>
<p>

**Abstract:** Humans are capable of completing a range of challenging manipulation tasks that require reasoning jointly over modalities such as vision, touch, and sound. Moreover, many such tasks are partially-observed; for example, taking a notebook out of a backpack will lead to visual occlusion and require reasoning over the history of audio or tactile information. While robust tactile sensing can be costly to capture on robots, microphones near or on a robot's gripper are a cheap and easy way to acquire audio feedback of contact events, which can be a surprisingly valuable data source for perception in the absence of vision. Motivated by the potential for sound to mitigate visual occlusion, we aim to learn a set of challenging partially-observed manipulation tasks from visual and audio inputs. Our proposed system learns these tasks by combining offline imitation learning from a modest number of tele-operated demonstrations and online finetuning using human provided interventions. In a set of simulated tasks, we find that our system benefits from using audio, and that by using online interventions we are able to improve the success rate of offline imitation learning by ~20%. Finally, we find that our system can complete a set of challenging, partially-observed tasks on a Franka Emika Panda robot, like extracting keys from a bag, with a 70% success rate, 50% higher than a policy that does not use audio.

</p>
</details>

<details><summary><b>BinauralGrad: A Two-Stage Conditional Diffusion Probabilistic Model for Binaural Audio Synthesis</b>
<a href="https://arxiv.org/abs/2205.14807">arxiv:2205.14807</a>
&#x1F4C8; 39 <br>
<p>Yichong Leng, Zehua Chen, Junliang Guo, Haohe Liu, Jiawei Chen, Xu Tan, Danilo Mandic, Lei He, Xiang-Yang Li, Tao Qin, Sheng Zhao, Tie-Yan Liu</p></summary>
<p>

**Abstract:** Binaural audio plays a significant role in constructing immersive augmented and virtual realities. As it is expensive to record binaural audio from the real world, synthesizing them from mono audio has attracted increasing attention. This synthesis process involves not only the basic physical warping of the mono audio, but also room reverberations and head/ear related filtrations, which, however, are difficult to accurately simulate in traditional digital signal processing. In this paper, we formulate the synthesis process from a different perspective by decomposing the binaural audio into a common part that shared by the left and right channels as well as a specific part that differs in each channel. Accordingly, we propose BinauralGrad, a novel two-stage framework equipped with diffusion models to synthesize them respectively. Specifically, in the first stage, the common information of the binaural audio is generated with a single-channel diffusion model conditioned on the mono audio, based on which the binaural audio is generated by a two-channel diffusion model in the second stage. Combining this novel perspective of two-stage synthesis with advanced generative models (i.e., the diffusion models),the proposed BinauralGrad is able to generate accurate and high-fidelity binaural audio samples. Experiment results show that on a benchmark dataset, BinauralGrad outperforms the existing baselines by a large margin in terms of both object and subject evaluation metrics (Wave L2: 0.128 vs. 0.157, MOS: 3.80 vs. 3.61). The generated audio samples are available online.

</p>
</details>

<details><summary><b>Glance to Count: Learning to Rank with Anchors for Weakly-supervised Crowd Counting</b>
<a href="https://arxiv.org/abs/2205.14659">arxiv:2205.14659</a>
&#x1F4C8; 20 <br>
<p>Zheng Xiong, Liangyu Chai, Wenxi Liu, Yongtuo Liu, Sucheng Ren, Shengfeng He</p></summary>
<p>

**Abstract:** Crowd image is arguably one of the most laborious data to annotate. In this paper, we devote to reduce the massive demand of densely labeled crowd data, and propose a novel weakly-supervised setting, in which we leverage the binary ranking of two images with high-contrast crowd counts as training guidance. To enable training under this new setting, we convert the crowd count regression problem to a ranking potential prediction problem. In particular, we tailor a Siamese Ranking Network that predicts the potential scores of two images indicating the ordering of the counts. Hence, the ultimate goal is to assign appropriate potentials for all the crowd images to ensure their orderings obey the ranking labels. On the other hand, potentials reveal the relative crowd sizes but cannot yield an exact crowd count. We resolve this problem by introducing "anchors" during the inference stage. Concretely, anchors are a few images with count labels used for referencing the corresponding counts from potential scores by a simple linear mapping function. We conduct extensive experiments to study various combinations of supervision, and we show that the proposed method outperforms existing weakly-supervised methods without additional labeling effort by a large margin.

</p>
</details>

<details><summary><b>Enhancing Sequential Recommendation with Graph Contrastive Learning</b>
<a href="https://arxiv.org/abs/2205.14837">arxiv:2205.14837</a>
&#x1F4C8; 18 <br>
<p>Yixin Zhang, Yong Liu, Yonghui Xu, Hao Xiong, Chenyi Lei, Wei He, Lizhen Cui, Chunyan Miao</p></summary>
<p>

**Abstract:** The sequential recommendation systems capture users' dynamic behavior patterns to predict their next interaction behaviors. Most existing sequential recommendation methods only exploit the local context information of an individual interaction sequence and learn model parameters solely based on the item prediction loss. Thus, they usually fail to learn appropriate sequence representations. This paper proposes a novel recommendation framework, namely Graph Contrastive Learning for Sequential Recommendation (GCL4SR). Specifically, GCL4SR employs a Weighted Item Transition Graph (WITG), built based on interaction sequences of all users, to provide global context information for each interaction and weaken the noise information in the sequence data. Moreover, GCL4SR uses subgraphs of WITG to augment the representation of each interaction sequence. Two auxiliary learning objectives have also been proposed to maximize the consistency between augmented representations induced by the same interaction sequence on WITG, and minimize the difference between the representations augmented by the global context on WITG and the local representation of the original sequence. Extensive experiments on real-world datasets demonstrate that GCL4SR consistently outperforms state-of-the-art sequential recommendation methods.

</p>
</details>

<details><summary><b>Temporal Latent Bottleneck: Synthesis of Fast and Slow Processing Mechanisms in Sequence Learning</b>
<a href="https://arxiv.org/abs/2205.14794">arxiv:2205.14794</a>
&#x1F4C8; 9 <br>
<p>Aniket Didolkar, Kshitij Gupta, Anirudh Goyal, Alex Lamb, Nan Rosemary Ke, Yoshua Bengio</p></summary>
<p>

**Abstract:** Recurrent neural networks have a strong inductive bias towards learning temporally compressed representations, as the entire history of a sequence is represented by a single vector. By contrast, Transformers have little inductive bias towards learning temporally compressed representations, as they allow for attention over all previously computed elements in a sequence. Having a more compressed representation of a sequence may be beneficial for generalization, as a high-level representation may be more easily re-used and re-purposed and will contain fewer irrelevant details. At the same time, excessive compression of representations comes at the cost of expressiveness. We propose a solution which divides computation into two streams. A slow stream that is recurrent in nature aims to learn a specialized and compressed representation, by forcing chunks of $K$ time steps into a single representation which is divided into multiple vectors. At the same time, a fast stream is parameterized as a Transformer to process chunks consisting of $K$ time-steps conditioned on the information in the slow-stream. In the proposed approach we hope to gain the expressiveness of the Transformer, while encouraging better compression and structuring of representations in the slow stream. We show the benefits of the proposed method in terms of improved sample efficiency and generalization performance as compared to various competitive baselines for visual perception and sequential decision making tasks.

</p>
</details>

<details><summary><b>A Conditional Randomization Test for Sparse Logistic Regression in High-Dimension</b>
<a href="https://arxiv.org/abs/2205.14613">arxiv:2205.14613</a>
&#x1F4C8; 7 <br>
<p>Binh T. Nguyen, Bertrand Thirion, Sylvain Arlot</p></summary>
<p>

**Abstract:** Identifying the relevant variables for a classification model with correct confidence levels is a central but difficult task in high-dimension. Despite the core role of sparse logistic regression in statistics and machine learning, it still lacks a good solution for accurate inference in the regime where the number of features $p$ is as large as or larger than the number of samples $n$. Here, we tackle this problem by improving the Conditional Randomization Test (CRT). The original CRT algorithm shows promise as a way to output p-values while making few assumptions on the distribution of the test statistics. As it comes with a prohibitive computational cost even in mildly high-dimensional problems, faster solutions based on distillation have been proposed. Yet, they rely on unrealistic hypotheses and result in low-power solutions. To improve this, we propose \emph{CRT-logit}, an algorithm that combines a variable-distillation step and a decorrelation step that takes into account the geometry of $\ell_1$-penalized logistic regression problem. We provide a theoretical analysis of this procedure, and demonstrate its effectiveness on simulations, along with experiments on large-scale brain-imaging and genomics datasets.

</p>
</details>

<details><summary><b>Joint Abductive and Inductive Neural Logical Reasoning</b>
<a href="https://arxiv.org/abs/2205.14591">arxiv:2205.14591</a>
&#x1F4C8; 7 <br>
<p>Zhenwei Tang, Shichao Pei, Xi Peng, Fuzhen Zhuang, Xiangliang Zhang, Robert Hoehndorf</p></summary>
<p>

**Abstract:** Neural logical reasoning (NLR) is a fundamental task in knowledge discovery and artificial intelligence. NLR aims at answering multi-hop queries with logical operations on structured knowledge bases based on distributed representations of queries and answers. While previous neural logical reasoners can give specific entity-level answers, i.e., perform inductive reasoning from the perspective of logic theory, they are not able to provide descriptive concept-level answers, i.e., perform abductive reasoning, where each concept is a summary of a set of entities. In particular, the abductive reasoning task attempts to infer the explanations of each query with descriptive concepts, which make answers comprehensible to users and is of great usefulness in the field of applied ontology. In this work, we formulate the problem of the joint abductive and inductive neural logical reasoning (AI-NLR), solving which needs to address challenges in incorporating, representing, and operating on concepts. We propose an original solution named ABIN for AI-NLR. Firstly, we incorporate description logic-based ontological axioms to provide the source of concepts. Then, we represent concepts and queries as fuzzy sets, i.e., sets whose elements have degrees of membership, to bridge concepts and queries with entities. Moreover, we design operators involving concepts on top of the fuzzy set representation of concepts and queries for optimization and inference. Extensive experimental results on two real-world datasets demonstrate the effectiveness of ABIN for AI-NLR.

</p>
</details>

<details><summary><b>What are People Talking about in #BackLivesMatter and #StopAsianHate? Exploring and Categorizing Twitter Topics Emerging in Online Social Movements through the Latent Dirichlet Allocation Model</b>
<a href="https://arxiv.org/abs/2205.14725">arxiv:2205.14725</a>
&#x1F4C8; 6 <br>
<p>Xin Tong, Yixuan Li, Jiayi Li, Rongqi Bei, Luyao Zhang</p></summary>
<p>

**Abstract:** Minority groups have been using social media to organize social movements that create profound social impacts. Black Lives Matter (BLM) and Stop Asian Hate (SAH) are two successful social movements that have spread on Twitter that promote protests and activities against racism and increase the public's awareness of other social challenges that minority groups face. However, previous studies have mostly conducted qualitative analyses of tweets or interviews with users, which may not comprehensively and validly represent all tweets. Very few studies have explored the Twitter topics within BLM and SAH dialogs in a rigorous, quantified and data-centered approach. Therefore, in this research, we adopted a mixed-methods approach to comprehensively analyze BLM and SAH Twitter topics. We implemented (1) the latent Dirichlet allocation model to understand the top high-level words and topics and (2) open-coding analysis to identify specific themes across the tweets. We collected more than one million tweets with the #blacklivesmatter and #stopasianhate hashtags and compared their topics. Our findings revealed that the tweets discussed a variety of influential topics in depth, and social justice, social movements, and emotional sentiments were common topics in both movements, though with unique subtopics for each movement. Our study contributes to the topic analysis of social movements on social media platforms in particular and the literature on the interplay of AI, ethics, and society in general.

</p>
</details>

<details><summary><b>Heterogeneous Data-Centric Architectures for Modern Data-Intensive Applications: Case Studies in Machine Learning and Databases</b>
<a href="https://arxiv.org/abs/2205.14664">arxiv:2205.14664</a>
&#x1F4C8; 6 <br>
<p>Geraldo F. Oliveira, Amirali Boroumand, Saugata Ghose, Juan Gómez-Luna, Onur Mutlu</p></summary>
<p>

**Abstract:** Today's computing systems require moving data back-and-forth between computing resources (e.g., CPUs, GPUs, accelerators) and off-chip main memory so that computation can take place on the data. Unfortunately, this data movement is a major bottleneck for system performance and energy consumption. One promising execution paradigm that alleviates the data movement bottleneck in modern and emerging applications is processing-in-memory (PIM), where the cost of data movement to/from main memory is reduced by placing computation capabilities close to memory.
  Naively employing PIM to accelerate data-intensive workloads can lead to sub-optimal performance due to the many design constraints PIM substrates impose. Therefore, many recent works co-design specialized PIM accelerators and algorithms to improve performance and reduce the energy consumption of (i) applications from various application domains; and (ii) various computing environments, including cloud systems, mobile systems, and edge devices.
  We showcase the benefits of co-designing algorithms and hardware in a way that efficiently takes advantage of the PIM paradigm for two modern data-intensive applications: (1) machine learning inference models for edge devices and (2) hybrid transactional/analytical processing databases for cloud systems. We follow a two-step approach in our system design. In the first step, we extensively analyze the computation and memory access patterns of each application to gain insights into its hardware/software requirements and major sources of performance and energy bottlenecks in processor-centric systems. In the second step, we leverage the insights from the first step to co-design algorithms and hardware accelerators to enable high-performance and energy-efficient data-centric architectures for each application.

</p>
</details>

<details><summary><b>Speaker Identification using Speech Recognition</b>
<a href="https://arxiv.org/abs/2205.14649">arxiv:2205.14649</a>
&#x1F4C8; 5 <br>
<p>Syeda Rabia Arshad, Syed Mujtaba Haider, Abdul Basit Mughal</p></summary>
<p>

**Abstract:** The audio data is increasing day by day throughout the globe with the increase of telephonic conversations, video conferences and voice messages. This research provides a mechanism for identifying a speaker in an audio file, based on the human voice biometric features like pitch, amplitude, frequency etc. We proposed an unsupervised learning model where the model can learn speech representation with limited dataset. Librispeech dataset was used in this research and we were able to achieve word error rate of 1.8.

</p>
</details>

<details><summary><b>Continuous Generative Neural Networks</b>
<a href="https://arxiv.org/abs/2205.14627">arxiv:2205.14627</a>
&#x1F4C8; 5 <br>
<p>Giovanni S. Alberti, Matteo Santacesaria, Silvia Sciutto</p></summary>
<p>

**Abstract:** In this work, we present and study Continuous Generative Neural Networks (CGNNs), namely, generative models in the continuous setting. The architecture is inspired by DCGAN, with one fully connected layer, several convolutional layers and nonlinear activation functions. In the continuous $L^2$ setting, the dimensions of the spaces of each layer are replaced by the scales of a multiresolution analysis of a compactly supported wavelet. We present conditions on the convolutional filters and on the nonlinearity that guarantee that a CGNN is injective. This theory finds applications to inverse problems, and allows for deriving Lipschitz stability estimates for (possibly nonlinear) infinite-dimensional inverse problems with unknowns belonging to the manifold generated by a CGNN. Several numerical simulations, including image deblurring, illustrate and validate this approach.

</p>
</details>

<details><summary><b>Mean Field inference of CRFs based on GAT</b>
<a href="https://arxiv.org/abs/2205.15312">arxiv:2205.15312</a>
&#x1F4C8; 4 <br>
<p>LingHong Xing, XiangXiang Ma, GuangSheng Luo</p></summary>
<p>

**Abstract:** In this paper we propose an improved mean-field inference algorithm for the fully connected paired CRFs model. The improved method Message Passing operation is changed from the original linear convolution to the present graph attention operation, while the process of the inference algorithm is turned into the forward process of the GAT model. Combined with the mean-field inferred label distribution, it is equivalent to the output of a classifier with only unary potential. To this end, we propose a graph attention network model with residual structure, and the model approach is applicable to all sequence annotation tasks, such as pixel-level image semantic segmentation tasks as well as text annotation tasks.

</p>
</details>

<details><summary><b>Evaluating Automated Driving Planner Robustness against Adversarial Influence</b>
<a href="https://arxiv.org/abs/2205.14697">arxiv:2205.14697</a>
&#x1F4C8; 4 <br>
<p>Andres Molina-Markham, Silvia G. Ionescu, Erin Lanus, Derek Ng, Sam Sommerer, Joseph J. Rushanan</p></summary>
<p>

**Abstract:** Evaluating the robustness of automated driving planners is a critical and challenging task. Although methodologies to evaluate vehicles are well established, they do not yet account for a reality in which vehicles with autonomous components share the road with adversarial agents. Our approach, based on probabilistic trust models, aims to help researchers assess the robustness of protections for machine learning-enabled planners against adversarial influence. In contrast with established practices that evaluate safety using the same evaluation dataset for all vehicles, we argue that adversarial evaluation fundamentally requires a process that seeks to defeat a specific protection. Hence, we propose that evaluations be based on estimating the difficulty for an adversary to determine conditions that effectively induce unsafe behavior. This type of inference requires precise statements about threats, protections, and aspects of planning decisions to be guarded. We demonstrate our approach by evaluating protections for planners relying on camera-based object detectors.

</p>
</details>

<details><summary><b>Learning Security Strategies through Game Play and Optimal Stopping</b>
<a href="https://arxiv.org/abs/2205.14694">arxiv:2205.14694</a>
&#x1F4C8; 4 <br>
<p>Kim Hammar, Rolf Stadler</p></summary>
<p>

**Abstract:** We study automated intrusion prevention using reinforcement learning. Following a novel approach, we formulate the interaction between an attacker and a defender as an optimal stopping game and let attack and defense strategies evolve through reinforcement learning and self-play. The game-theoretic perspective allows us to find defender strategies that are effective against dynamic attackers. The optimal stopping formulation gives us insight into the structure of optimal strategies, which we show to have threshold properties. To obtain the optimal defender strategies, we introduce T-FP, a fictitious self-play algorithm that learns Nash equilibria through stochastic approximation. We show that T-FP outperforms a state-of-the-art algorithm for our use case. Our overall method for learning and evaluating strategies includes two systems: a simulation system where defender strategies are incrementally learned and an emulation system where statistics are produced that drive simulation runs and where learned strategies are evaluated. We conclude that this approach can produce effective defender strategies for a practical IT infrastructure.

</p>
</details>

<details><summary><b>An adaptive granularity clustering method based on hyper-ball</b>
<a href="https://arxiv.org/abs/2205.14592">arxiv:2205.14592</a>
&#x1F4C8; 4 <br>
<p>Shu-yin Xia, Jiang Xie, Guo-yin Wang</p></summary>
<p>

**Abstract:** The purpose of cluster analysis is to classify elements according to their similarity. Its applications range from astronomy to bioinformatics and pattern recognition. Our method is based on the idea that the data with similar distribution form a hyper-ball and the adjacent hyper-balls form a cluster. Based on the cognitive law of "large scale first", this method can identify clusters without considering shape in a simple and non-parametric way. Experimental results on several datasets demonstrate the effectiveness of the algorithm.

</p>
</details>

<details><summary><b>Your Contrastive Learning Is Secretly Doing Stochastic Neighbor Embedding</b>
<a href="https://arxiv.org/abs/2205.14814">arxiv:2205.14814</a>
&#x1F4C8; 3 <br>
<p>Tianyang Hu, Zhili Liu, Fengwei Zhou, Wenjia Wang, Weiran Huang</p></summary>
<p>

**Abstract:** Contrastive learning, especially Self-Supervised Contrastive Learning (SSCL), has achieved great success in extracting powerful features from unlabeled data, enabling comparable performance to the supervised counterpart. In this work, we contribute to the theoretical understanding of SSCL and uncover its connection to the classic data visualization method, Stochastic Neighbor Embedding (SNE). In the perspective of SNE, whose goal is matching pairwise distance, SSCL can be viewed as a special case with the input space pairwise distance specified by constructed "positive" pairs from data augmentation. The established correspondence facilitates deeper theoretical understandings of learned features of SSCL, as well as methodological guidelines for practical improvement. Specifically, through the lens of SNE, not only can we re-derive the alignment and uniformity principle, but also provide novel analysis on domain-agnostic augmentations and implicit bias. To illustrate the practical advantage, we demonstrate that the modifications from SNE to $t$-SNE can also be adopted in the SSCL setting, achieving significant improvement in both in-distribution and out-of-distribution generalization.

</p>
</details>

<details><summary><b>Random Rank: The One and Only Strategyproof and Proportionally Fair Randomized Facility Location Mechanism</b>
<a href="https://arxiv.org/abs/2205.14798">arxiv:2205.14798</a>
&#x1F4C8; 3 <br>
<p>Haris Aziz, Alexander Lam, Mashbat Suzuki, Toby Walsh</p></summary>
<p>

**Abstract:** Proportionality is an attractive fairness concept that has been applied to a range of problems including the facility location problem, a classic problem in social choice. In our work, we propose a concept called Strong Proportionality, which ensures that when there are two groups of agents at different locations, both groups incur the same total cost. We show that although Strong Proportionality is a well-motivated and basic axiom, there is no deterministic strategyproof mechanism satisfying the property. We then identify a randomized mechanism called Random Rank (which uniformly selects a number $k$ between $1$ to $n$ and locates the facility at the $k$'th highest agent location) which satisfies Strong Proportionality in expectation. Our main theorem characterizes Random Rank as the unique mechanism that achieves universal truthfulness, universal anonymity, and Strong Proportionality in expectation among all randomized mechanisms. Finally, we show via the AverageOrRandomRank mechanism that even stronger ex-post fairness guarantees can be achieved by weakening universal truthfulness to strategyproofness in expectation.

</p>
</details>

<details><summary><b>6N-DoF Pose Tracking for Tensegrity Robots</b>
<a href="https://arxiv.org/abs/2205.14764">arxiv:2205.14764</a>
&#x1F4C8; 3 <br>
<p>Shiyang Lu, William R. Johnson III, Kun Wang, Xiaonan Huang, Joran Booth, Rebecca Kramer-Bottiglio, Kostas Bekris</p></summary>
<p>

**Abstract:** Tensegrity robots, which are composed of rigid compressive elements (rods) and flexible tensile elements (e.g., cables), have a variety of advantages, including flexibility, light weight, and resistance to mechanical impact. Nevertheless, the hybrid soft-rigid nature of these robots also complicates the ability to localize and track their state. This work aims to address what has been recognized as a grand challenge in this domain, i.e., the pose tracking of tensegrity robots through a markerless, vision-based method, as well as novel, onboard sensors that can measure the length of the robot's cables. In particular, an iterative optimization process is proposed to estimate the 6-DoF poses of each rigid element of a tensegrity robot from an RGB-D video as well as endcap distance measurements from the cable sensors. To ensure the pose estimates of rigid elements are physically feasible, i.e., they are not resulting in collisions between rods or with the environment, physical constraints are introduced during the optimization. Real-world experiments are performed with a 3-bar tensegrity robot, which performs locomotion gaits. Given ground truth data from a motion capture system, the proposed method achieves less than 1 cm translation error and 3 degrees rotation error, which significantly outperforms alternatives. At the same time, the approach can provide pose estimates throughout the robot's motion, while motion capture often fails due to occlusions.

</p>
</details>

<details><summary><b>CPED: A Large-Scale Chinese Personalized and Emotional Dialogue Dataset for Conversational AI</b>
<a href="https://arxiv.org/abs/2205.14727">arxiv:2205.14727</a>
&#x1F4C8; 3 <br>
<p>Yirong Chen, Weiquan Fan, Xiaofen Xing, Jianxin Pang, Minlie Huang, Wenjing Han, Qianfeng Tie, Xiangmin Xu</p></summary>
<p>

**Abstract:** Human language expression is based on the subjective construal of the situation instead of the objective truth conditions, which means that speakers' personalities and emotions after cognitive processing have an important influence on conversation. However, most existing datasets for conversational AI ignore human personalities and emotions, or only consider part of them. It's difficult for dialogue systems to understand speakers' personalities and emotions although large-scale pre-training language models have been widely used. In order to consider both personalities and emotions in the process of conversation generation, we propose CPED, a large-scale Chinese personalized and emotional dialogue dataset, which consists of multi-source knowledge related to empathy and personal characteristic. These knowledge covers gender, Big Five personality traits, 13 emotions, 19 dialogue acts and 10 scenes. CPED contains more than 12K dialogues of 392 speakers from 40 TV shows. We release the textual dataset with audio features and video features according to the copyright claims, privacy issues, terms of service of video platforms. We provide detailed description of the CPED construction process and introduce three tasks for conversational AI, including personality recognition, emotion recognition in conversations as well as personalized and emotional conversation generation. Finally, we provide baseline systems for these tasks and consider the function of speakers' personalities and emotions on conversation. Our motivation is to propose a dataset to be widely adopted by the NLP community as a new open benchmark for conversational AI research. The full dataset is available at https://github.com/scutcyr/CPED.

</p>
</details>

<details><summary><b>Heterogeneous Treatment Effects Estimation: When Machine Learning meets multiple treatment regime</b>
<a href="https://arxiv.org/abs/2205.14714">arxiv:2205.14714</a>
&#x1F4C8; 3 <br>
<p>Naoufal Acharki, Josselin Garnier, Antoine Bertoncello, Ramiro Lugo</p></summary>
<p>

**Abstract:** In many scientific and engineering domains, inferring the effect of treatment and exploring its heterogeneity is crucial for optimization and decision making. In addition to Machine Learning based models (e.g. Random Forests or Neural Networks), many meta-algorithms have been developed to estimate the Conditional Average Treatment Effect (CATE) function in the binary setting, with the main advantage of not restraining the estimation to a specific supervised learning method. However, this task becomes more challenging when the treatment is not binary. In this paper, we investigate the Rubin Causal Model under the multi-treatment regime and we focus on estimating heterogeneous treatment effects. We generalize \textit{Meta-learning} algorithms to estimate the CATE for each possible treatment value. Using synthetic and semi-synthetic simulation datasets, we assess the quality of each meta-learner in observational data, and we highlight in particular the performances of the X-learner.

</p>
</details>

<details><summary><b>On the Robustness of Safe Reinforcement Learning under Observational Perturbations</b>
<a href="https://arxiv.org/abs/2205.14691">arxiv:2205.14691</a>
&#x1F4C8; 3 <br>
<p>Zuxin Liu, Zijian Guo, Zhepeng Cen, Huan Zhang, Jie Tan, Bo Li, Ding Zhao</p></summary>
<p>

**Abstract:** Safe reinforcement learning (RL) trains a policy to maximize the task reward while satisfying safety constraints. While prior works focus on the performance optimality, we find that the optimal solutions of many safe RL problems are not robust and safe against carefully designed observational perturbations. We formally analyze the unique properties of designing effective state adversarial attackers in the safe RL setting. We show that baseline adversarial attack techniques for standard RL tasks are not always effective for safe RL and proposed two new approaches - one maximizes the cost and the other maximizes the reward. One interesting and counter-intuitive finding is that the maximum reward attack is strong, as it can both induce unsafe behaviors and make the attack stealthy by maintaining the reward. We further propose a more effective adversarial training framework for safe RL and evaluate it via comprehensive experiments. This work sheds light on the inherited connection between observational robustness and safety in RL and provides a pioneer work for future safe RL studies.

</p>
</details>

<details><summary><b>The impact of memory on learning sequence-to-sequence tasks</b>
<a href="https://arxiv.org/abs/2205.14683">arxiv:2205.14683</a>
&#x1F4C8; 3 <br>
<p>Alireza Seif, Sarah A. M. Loos, Gennaro Tucci, Édgar Roldán, Sebastian Goldt</p></summary>
<p>

**Abstract:** The recent success of neural networks in machine translation and other fields has drawn renewed attention to learning sequence-to-sequence (seq2seq) tasks. While there exists a rich literature that studies classification and regression using solvable models of neural networks, learning seq2seq tasks is significantly less studied from this perspective. Here, we propose a simple model for a seq2seq task that gives us explicit control over the degree of memory, or non-Markovianity, in the sequences -- the stochastic switching-Ornstein-Uhlenbeck (SSOU) model. We introduce a measure of non-Markovianity to quantify the amount of memory in the sequences. For a minimal auto-regressive (AR) learning model trained on this task, we identify two learning regimes corresponding to distinct phases in the stationary state of the SSOU process. These phases emerge from the interplay between two different time scales that govern the sequence statistics. Moreover, we observe that while increasing the memory of the AR model always improves performance, increasing the non-Markovianity of the input sequences can improve or degrade performance. Finally, our experiments with recurrent and convolutional neural networks show that our observations carry over to more complicated neural network architectures.

</p>
</details>

<details><summary><b>COFS: Controllable Furniture layout Synthesis</b>
<a href="https://arxiv.org/abs/2205.14657">arxiv:2205.14657</a>
&#x1F4C8; 3 <br>
<p>Wamiq Reyaz Para, Paul Guerrero, Niloy Mitra, Peter Wonka</p></summary>
<p>

**Abstract:** Scalable generation of furniture layouts is essential for many applications in virtual reality, augmented reality, game development and synthetic data generation. Many existing methods tackle this problem as a sequence generation problem which imposes a specific ordering on the elements of the layout making such methods impractical for interactive editing or scene completion. Additionally, most methods focus on generating layouts unconditionally and offer minimal control over the generated layouts. We propose COFS, an architecture based on standard transformer architecture blocks from language modeling. The proposed model is invariant to object order by design, removing the unnatural requirement of specifying an object generation order. Furthermore, the model allows for user interaction at multiple levels enabling fine grained control over the generation process. Our model consistently outperforms other methods which we verify by performing quantitative evaluations. Our method is also faster to train and sample from, compared to existing methods.

</p>
</details>

<details><summary><b>Micro-Expression Recognition Based on Attribute Information Embedding and Cross-modal Contrastive Learning</b>
<a href="https://arxiv.org/abs/2205.14643">arxiv:2205.14643</a>
&#x1F4C8; 3 <br>
<p>Yanxin Song, Jianzong Wang, Tianbo Wu, Zhangcheng Huang, Jing Xiao</p></summary>
<p>

**Abstract:** Facial micro-expressions recognition has attracted much attention recently. Micro-expressions have the characteristics of short duration and low intensity, and it is difficult to train a high-performance classifier with the limited number of existing micro-expressions. Therefore, recognizing micro-expressions is a challenge task. In this paper, we propose a micro-expression recognition method based on attribute information embedding and cross-modal contrastive learning. We use 3D CNN to extract RGB features and FLOW features of micro-expression sequences and fuse them, and use BERT network to extract text information in Facial Action Coding System. Through cross-modal contrastive loss, we embed attribute information in the visual network, thereby improving the representation ability of micro-expression recognition in the case of limited samples. We conduct extensive experiments in CASME II and MMEW databases, and the accuracy is 77.82% and 71.04%, respectively. The comparative experiments show that this method has better recognition effect than other methods for micro-expression recognition.

</p>
</details>

<details><summary><b>Perceiving the Invisible: Proposal-Free Amodal Panoptic Segmentation</b>
<a href="https://arxiv.org/abs/2205.14637">arxiv:2205.14637</a>
&#x1F4C8; 3 <br>
<p>Rohit Mohan, Abhinav Valada</p></summary>
<p>

**Abstract:** Amodal panoptic segmentation aims to connect the perception of the world to its cognitive understanding. It entails simultaneously predicting the semantic labels of visible scene regions and the entire shape of traffic participant instances, including regions that may be occluded. In this work, we formulate a proposal-free framework that tackles this task as a multi-label and multi-class problem by first assigning the amodal masks to different layers according to their relative occlusion order and then employing amodal instance regression on each layer independently while learning background semantics. We propose the \net architecture that incorporates a shared backbone and an asymmetrical dual-decoder consisting of several modules to facilitate within-scale and cross-scale feature aggregations, bilateral feature propagation between decoders, and integration of global instance-level and local pixel-level occlusion reasoning. Further, we propose the amodal mask refiner that resolves the ambiguity in complex occlusion scenarios by explicitly leveraging the embedding of unoccluded instance masks. Extensive evaluation on the BDD100K-APS and KITTI-360-APS datasets demonstrate that our approach set the new state-of-the-art on both benchmarks.

</p>
</details>

<details><summary><b>Do Residual Neural Networks discretize Neural Ordinary Differential Equations?</b>
<a href="https://arxiv.org/abs/2205.14612">arxiv:2205.14612</a>
&#x1F4C8; 3 <br>
<p>Michael E. Sander, Pierre Ablin, Gabriel Peyré</p></summary>
<p>

**Abstract:** Neural Ordinary Differential Equations (Neural ODEs) are the continuous analog of Residual Neural Networks (ResNets). We investigate whether the discrete dynamics defined by a ResNet are close to the continuous one of a Neural ODE. We first quantify the distance between the ResNet's hidden state trajectory and the solution of its corresponding Neural ODE. Our bound is tight and, on the negative side, does not go to 0 with depth N if the residual functions are not smooth with depth. On the positive side, we show that this smoothness is preserved by gradient descent for a ResNet with linear residual functions and small enough initial loss. It ensures an implicit regularization towards a limit Neural ODE at rate 1 over N, uniformly with depth and optimization time. As a byproduct of our analysis, we consider the use of a memory-free discrete adjoint method to train a ResNet by recovering the activations on the fly through a backward pass of the network, and show that this method theoretically succeeds at large depth if the residual functions are Lipschitz with the input. We then show that Heun's method, a second order ODE integration scheme, allows for better gradient estimation with the adjoint method when the residual functions are smooth with depth. We experimentally validate that our adjoint method succeeds at large depth, and that Heun method needs fewer layers to succeed. We finally use the adjoint method successfully for fine-tuning very deep ResNets without memory consumption in the residual layers.

</p>
</details>

<details><summary><b>Independent and Decentralized Learning in Markov Potential Games</b>
<a href="https://arxiv.org/abs/2205.14590">arxiv:2205.14590</a>
&#x1F4C8; 3 <br>
<p>Chinmay Maheshwari, Manxi Wu, Druv Pai, Shankar Sastry</p></summary>
<p>

**Abstract:** We propose a multi-agent reinforcement learning dynamics, and analyze its convergence properties in infinite-horizon discounted Markov potential games. We focus on the independent and decentralized setting, where players can only observe the realized state and their own reward in every stage. Players do not have knowledge of the game model, and cannot coordinate with each other. In each stage of our learning dynamics, players update their estimate of a perturbed Q-function that evaluates their total contingent payoff based on the realized one-stage reward in an asynchronous manner. Then, players independently update their policies by incorporating a smoothed optimal one-stage deviation strategy based on the estimated Q-function. A key feature of the learning dynamics is that the Q-function estimates are updated at a faster timescale than the policies. We prove that the policies induced by our learning dynamics converge to a stationary Nash equilibrium in Markov potential games with probability 1. Our results build on the theory of two timescale asynchronous stochastic approximation, and new analysis on the monotonicity of potential function along the trajectory of policy updates in Markov potential games.

</p>
</details>

<details><summary><b>3D-C2FT: Coarse-to-fine Transformer for Multi-view 3D Reconstruction</b>
<a href="https://arxiv.org/abs/2205.14575">arxiv:2205.14575</a>
&#x1F4C8; 3 <br>
<p>Leslie Ching Ow Tiong, Dick Sigmund, Andrew Beng Jin Teoh</p></summary>
<p>

**Abstract:** Recently, the transformer model has been successfully employed for the multi-view 3D reconstruction problem. However, challenges remain on designing an attention mechanism to explore the multiview features and exploit their relations for reinforcing the encoding-decoding modules. This paper proposes a new model, namely 3D coarse-to-fine transformer (3D-C2FT), by introducing a novel coarse-to-fine(C2F) attention mechanism for encoding multi-view features and rectifying defective 3D objects. C2F attention mechanism enables the model to learn multi-view information flow and synthesize 3D surface correction in a coarse to fine-grained manner. The proposed model is evaluated by ShapeNet and Multi-view Real-life datasets. Experimental results show that 3D-C2FT achieves notable results and outperforms several competing models on these datasets.

</p>
</details>

<details><summary><b>Mixture GAN For Modulation Classification Resiliency Against Adversarial Attacks</b>
<a href="https://arxiv.org/abs/2205.15743">arxiv:2205.15743</a>
&#x1F4C8; 2 <br>
<p>Eyad Shtaiwi, Ahmed El Ouadrhiri, Majid Moradikia, Salma Sultana, Ahmed Abdelhadi, Zhu Han</p></summary>
<p>

**Abstract:** Automatic modulation classification (AMC) using the Deep Neural Network (DNN) approach outperforms the traditional classification techniques, even in the presence of challenging wireless channel environments. However, the adversarial attacks cause the loss of accuracy for the DNN-based AMC by injecting a well-designed perturbation to the wireless channels. In this paper, we propose a novel generative adversarial network (GAN)-based countermeasure approach to safeguard the DNN-based AMC systems against adversarial attack examples. GAN-based aims to eliminate the adversarial attack examples before feeding to the DNN-based classifier. Specifically, we have shown the resiliency of our proposed defense GAN against the Fast-Gradient Sign method (FGSM) algorithm as one of the most potent kinds of attack algorithms to craft the perturbed signals. The existing defense-GAN has been designed for image classification and does not work in our case where the above-mentioned communication system is considered. Thus, our proposed countermeasure approach deploys GANs with a mixture of generators to overcome the mode collapsing problem in a typical GAN facing radio signal classification problem. Simulation results show the effectiveness of our proposed defense GAN so that it could enhance the accuracy of the DNN-based AMC under adversarial attacks to 81%, approximately.

</p>
</details>

<details><summary><b>Precise Learning Curves and Higher-Order Scaling Limits for Dot Product Kernel Regression</b>
<a href="https://arxiv.org/abs/2205.14846">arxiv:2205.14846</a>
&#x1F4C8; 2 <br>
<p>Lechao Xiao, Jeffrey Pennington</p></summary>
<p>

**Abstract:** As modern machine learning models continue to advance the computational frontier, it has become increasingly important to develop precise estimates for expected performance improvements under different model and data scaling regimes. Currently, theoretical understanding of the learning curves that characterize how the prediction error depends on the number of samples is restricted to either large-sample asymptotics ($m\to\infty$) or, for certain simple data distributions, to the high-dimensional asymptotics in which the number of samples scales linearly with the dimension ($m\propto d$). There is a wide gulf between these two regimes, including all higher-order scaling relations $m\propto d^r$, which are the subject of the present paper. We focus on the problem of kernel ridge regression for dot-product kernels and present precise formulas for the test error, bias, and variance, for data drawn uniformly from the sphere in the $r$th-order asymptotic scaling regime $m\to\infty$ with $m/d^r$ held constant. We observe a peak in the learning curve whenever $m \approx d^r/r!$ for any integer $r$, leading to multiple sample-wise descent and nontrivial behavior at multiple scales.

</p>
</details>

<details><summary><b>Fair and Fast Tie-Breaking for Voting</b>
<a href="https://arxiv.org/abs/2205.14838">arxiv:2205.14838</a>
&#x1F4C8; 2 <br>
<p>Lirong Xia</p></summary>
<p>

**Abstract:** We introduce a notion of fairest tie-breaking for voting w.r.t. two widely-accepted fairness criteria: anonymity (all voters being treated equally) and neutrality (all alternatives being treated equally). We proposed a polynomial-time computable fairest tie-breaking mechanism, called most-favorable-permutation (MFP) breaking, for a wide range of decision spaces, including single winners, $k$-committees, $k$-lists, and full rankings. We characterize the semi-random fairness of commonly-studied voting rules with MFP breaking, showing that it is significantly better than existing tie-breaking mechanisms, including the commonly-used lexicographic and fixed-agent mechanisms.

</p>
</details>

<details><summary><b>Temporal Multiresolution Graph Neural Networks For Epidemic Prediction</b>
<a href="https://arxiv.org/abs/2205.14831">arxiv:2205.14831</a>
&#x1F4C8; 2 <br>
<p>Truong Son Hy, Viet Bach Nguyen, Long Tran-Thanh, Risi Kondor</p></summary>
<p>

**Abstract:** In this paper, we introduce Temporal Multiresolution Graph Neural Networks (TMGNN), the first architecture that both learns to construct the multiscale and multiresolution graph structures and incorporates the time-series signals to capture the temporal changes of the dynamic graphs. We have applied our proposed model to the task of predicting future spreading of epidemic and pandemic based on the historical time-series data collected from the actual COVID-19 pandemic and chickenpox epidemic in several European countries, and have obtained competitive results in comparison to other previous state-of-the-art temporal architectures and graph learning algorithms. We have shown that capturing the multiscale and multiresolution structures of graphs is important to extract either local or global information that play a critical role in understanding the dynamic of a global pandemic such as COVID-19 which started from a local city and spread to the whole world. Our work brings a promising research direction in forecasting and mitigating future epidemics and pandemics.

</p>
</details>

<details><summary><b>Adaptive Learning for Discovery</b>
<a href="https://arxiv.org/abs/2205.14829">arxiv:2205.14829</a>
&#x1F4C8; 2 <br>
<p>Ziping Xu, Eunjae Shim, Ambuj Tewari, Paul Zimmerman</p></summary>
<p>

**Abstract:** In this paper, we study a sequential decision-making problem, called Adaptive Sampling for Discovery (ASD). Starting with a large unlabeled dataset, algorithms for ASD adaptively label the points with the goal to maximize the sum of responses.
  This problem has wide applications to real-world discovery problems, for example drug discovery with the help of machine learning models. ASD algorithms face the well-known exploration-exploitation dilemma. The algorithm needs to choose points that yield information to improve model estimates but it also needs to exploit the model. We rigorously formulate the problem and propose a general information-directed sampling (IDS) algorithm. We provide theoretical guarantees for the performance of IDS in linear, graph and low-rank models. The benefits of IDS are shown in both simulation experiments and real-data experiments for discovering chemical reaction conditions.

</p>
</details>

<details><summary><b>Excess Risk of Two-Layer ReLU Neural Networks in Teacher-Student Settings and its Superiority to Kernel Methods</b>
<a href="https://arxiv.org/abs/2205.14818">arxiv:2205.14818</a>
&#x1F4C8; 2 <br>
<p>Shunta Akiyama, Taiji Suzuki</p></summary>
<p>

**Abstract:** While deep learning has outperformed other methods for various tasks, theoretical frameworks that explain its reason have not been fully established. To address this issue, we investigate the excess risk of two-layer ReLU neural networks in a teacher-student regression model, in which a student network learns an unknown teacher network through its outputs. Especially, we consider the student network that has the same width as the teacher network and is trained in two phases: first by noisy gradient descent and then by the vanilla gradient descent. Our result shows that the student network provably reaches a near-global optimal solution and outperforms any kernel methods estimator (more generally, linear estimators), including neural tangent kernel approach, random feature model, and other kernel methods, in a sense of the minimax optimal rate. The key concept inducing this superiority is the non-convexity of the neural network models. Even though the loss landscape is highly non-convex, the student network adaptively learns the teacher neurons.

</p>
</details>

<details><summary><b>End-to-End Topology-Aware Machine Learning for Power System Reliability Assessment</b>
<a href="https://arxiv.org/abs/2205.14792">arxiv:2205.14792</a>
&#x1F4C8; 2 <br>
<p>Yongli Zhu, Chanan Singh</p></summary>
<p>

**Abstract:** Conventional power system reliability suffers from the long run time of Monte Carlo simulation and the dimension-curse of analytic enumeration methods. This paper proposes a preliminary investigation on end-to-end machine learning for directly predicting the reliability index, e.g., the Loss of Load Probability (LOLP). By encoding the system admittance matrix into the input feature, the proposed machine learning pipeline can consider the impact of specific topology changes due to regular maintenances of transmission lines. Two models (Support Vector Machine and Boosting Trees) are trained and compared. Details regarding the training data creation and preprocessing are also discussed. Finally, experiments are conducted on the IEEE RTS-79 system. Results demonstrate the applicability of the proposed end-to-end machine learning pipeline in reliability assessment.

</p>
</details>

<details><summary><b>An Optimization-based Algorithm for Non-stationary Kernel Bandits without Prior Knowledge</b>
<a href="https://arxiv.org/abs/2205.14775">arxiv:2205.14775</a>
&#x1F4C8; 2 <br>
<p>Kihyuk Hong, Yuhang Li, Ambuj Tewari</p></summary>
<p>

**Abstract:** We propose an algorithm for non-stationary kernel bandits that does not require prior knowledge of the degree of non-stationarity. The algorithm follows randomized strategies obtained by solving optimization problems that balance exploration and exploitation. It adapts to non-stationarity by restarting when a change in the reward function is detected. Our algorithm enjoys a tighter dynamic regret bound than previous work on the non-stationary kernel bandit setting. Moreover, when applied to the non-stationary linear bandit setting by using a linear kernel, our algorithm is nearly minimax optimal, solving an open problem in the non-stationary linear bandit literature. We extend our algorithm to use a neural network for dynamically adapting the feature mapping to observed data. We prove a dynamic regret bound of the extension using the neural tangent kernel theory. We demonstrate empirically that our algorithm and the extension can adapt to varying degrees of non-stationarity.

</p>
</details>

<details><summary><b>Unfooling Perturbation-Based Post Hoc Explainers</b>
<a href="https://arxiv.org/abs/2205.14772">arxiv:2205.14772</a>
&#x1F4C8; 2 <br>
<p>Zachariah Carmichael, Walter J Scheirer</p></summary>
<p>

**Abstract:** Monumental advancements in artificial intelligence (AI) have lured the interest of doctors, lenders, judges, and other professionals. While these high-stakes decision-makers are optimistic about the technology, those familiar with AI systems are wary about the lack of transparency of its decision-making processes. Perturbation-based post hoc explainers offer a model agnostic means of interpreting these systems while only requiring query-level access. However, recent work demonstrates that these explainers can be fooled adversarially. This discovery has adverse implications for auditors, regulators, and other sentinels. With this in mind, several natural questions arise - how can we audit these black box systems? And how can we ascertain that the auditee is complying with the audit in good faith? In this work, we rigorously formalize this problem and devise a defense against adversarial attacks on perturbation-based explainers. We propose algorithms for the detection (CAD-Detect) and defense (CAD-Defend) of these attacks, which are aided by our novel conditional anomaly detection approach, KNN-CAD. We demonstrate that our approach successfully detects whether a black box system adversarially conceals its decision-making process and mitigates the adversarial attack on real-world data for the prevalent explainers, LIME and SHAP.

</p>
</details>

<details><summary><b>UPB at SemEval-2022 Task 5: Enhancing UNITER with Image Sentiment and Graph Convolutional Networks for Multimedia Automatic Misogyny Identification</b>
<a href="https://arxiv.org/abs/2205.14769">arxiv:2205.14769</a>
&#x1F4C8; 2 <br>
<p>Andrei Paraschiv, Mihai Dascalu, Dumitru-Clementin Cercel</p></summary>
<p>

**Abstract:** In recent times, the detection of hate-speech, offensive, or abusive language in online media has become an important topic in NLP research due to the exponential growth of social media and the propagation of such messages, as well as their impact. Misogyny detection, even though it plays an important part in hate-speech detection, has not received the same attention. In this paper, we describe our classification systems submitted to the SemEval-2022 Task 5: MAMI - Multimedia Automatic Misogyny Identification. The shared task aimed to identify misogynous content in a multi-modal setting by analysing meme images together with their textual captions. To this end, we propose two models based on the pre-trained UNITER model, one enhanced with an image sentiment classifier, whereas the second leverages a Vocabulary Graph Convolutional Network (VGCN). Additionally, we explore an ensemble using the aforementioned models. Our best model reaches an F1-score of 71.4% in Sub-task A and 67.3% for Sub-task B positioning our team in the upper third of the leaderboard. We release the code and experiments for our models on GitHub

</p>
</details>

<details><summary><b>Modeling Disagreement in Automatic Data Labelling for Semi-Supervised Learning in Clinical Natural Language Processing</b>
<a href="https://arxiv.org/abs/2205.14761">arxiv:2205.14761</a>
&#x1F4C8; 2 <br>
<p>Hongshu Liu, Nabeel Seedat, Julia Ive</p></summary>
<p>

**Abstract:** Computational models providing accurate estimates of their uncertainty are crucial for risk management associated with decision making in healthcare contexts. This is especially true since many state-of-the-art systems are trained using the data which has been labelled automatically (self-supervised mode) and tend to overfit. In this work, we investigate the quality of uncertainty estimates from a range of current state-of-the-art predictive models applied to the problem of observation detection in radiology reports. This problem remains understudied for Natural Language Processing in the healthcare domain. We demonstrate that Gaussian Processes (GPs) provide superior performance in quantifying the risks of 3 uncertainty labels based on the negative log predictive probability (NLPP) evaluation metric and mean maximum predicted confidence levels (MMPCL), whilst retaining strong predictive performance.

</p>
</details>

<details><summary><b>A Generative Adversarial Network-based Selective Ensemble Characteristic-to-Expression Synthesis (SE-CTES) Approach and Its Applications in Healthcare</b>
<a href="https://arxiv.org/abs/2205.14751">arxiv:2205.14751</a>
&#x1F4C8; 2 <br>
<p>Yuxuan Li, Ying Lin, Chenang Liu</p></summary>
<p>

**Abstract:** Investigating the causal relationships between characteristics and expressions plays a critical role in healthcare analytics. Effective synthesis for expressions using given characteristics can make great contributions to health risk management and medical decision-making. For example, predicting the resulting physiological symptoms on patients from given treatment characteristics is helpful for the disease prevention and personalized treatment strategy design. Therefore, the objective of this study is to effectively synthesize the expressions based on given characteristics. However, the mapping from characteristics to expressions is usually from a relatively low dimension space to a high dimension space, but most of the existing methods such as regression models could not effectively handle such mapping. Besides, the relationship between characteristics and expressions may contain not only deterministic patterns, but also stochastic patterns. To address these challenges, this paper proposed a novel selective ensemble characteristic-to-expression synthesis (SE-CTES) approach inspired by generative adversarial network (GAN). The novelty of the proposed method can be summarized into three aspects: (1) GAN-based architecture for deep neural networks are incorporated to learn the relatively low dimensional mapping to high dimensional mapping containing both deterministic and stochastic patterns; (2) the weights of the two mismatching errors in the GAN-based architecture are proposed to be different to reduce the learning bias in the training process; and (3) a selective ensemble learning framework is proposed to reduce the prediction bias and improve the synthesis stability. To validate the effectiveness of the proposed approach, extensive numerical simulation studies and a real-world healthcare case study were applied and the results demonstrated that the proposed method is very promising.

</p>
</details>

<details><summary><b>L3Cube-MahaNLP: Marathi Natural Language Processing Datasets, Models, and Library</b>
<a href="https://arxiv.org/abs/2205.14728">arxiv:2205.14728</a>
&#x1F4C8; 2 <br>
<p>Raviraj Joshi</p></summary>
<p>

**Abstract:** Despite being the third most popular language in India, the Marathi language lacks useful NLP resources. Moreover, popular NLP libraries do not have support for the Marathi language. With L3Cube-MahaNLP, we aim to build resources and a library for Marathi natural language processing. We present datasets and transformer models for supervised tasks like sentiment analysis, named entity recognition, and hate speech detection. We have also published a monolingual Marathi corpus for unsupervised language modeling tasks. Overall we present MahaCorpus, MahaSent, MahaNER, and MahaHate datasets and their corresponding MahaBERT models fine-tuned on these datasets. We aim to move ahead of benchmark datasets and prepare useful resources for Marathi. The resources are available at https://github.com/l3cube-pune/MarathiNLP.

</p>
</details>

<details><summary><b>Saliency Map Based Data Augmentation</b>
<a href="https://arxiv.org/abs/2205.14686">arxiv:2205.14686</a>
&#x1F4C8; 2 <br>
<p>Jalal Al-afandi, Bálint Magyar, András Horváth</p></summary>
<p>

**Abstract:** Data augmentation is a commonly applied technique with two seemingly related advantages. With this method one can increase the size of the training set generating new samples and also increase the invariance of the network against the applied transformations. Unfortunately all images contain both relevant and irrelevant features for classification therefore this invariance has to be class specific. In this paper we will present a new method which uses saliency maps to restrict the invariance of neural networks to certain regions, providing higher test accuracy in classification tasks.

</p>
</details>

<details><summary><b>SKFlow: Learning Optical Flow with Super Kernels</b>
<a href="https://arxiv.org/abs/2205.14623">arxiv:2205.14623</a>
&#x1F4C8; 2 <br>
<p>Shangkun Sun, Yuanqi Chen, Yu Zhu, Guodong Guo, Ge Li</p></summary>
<p>

**Abstract:** Optical flow estimation is a classical yet challenging task in computer vision. One of the essential factors in accurately predicting optical flow is to alleviate occlusions between frames. However, it is still a thorny problem for current top-performing optical flow estimation methods due to insufficient local evidence to model occluded areas. In this paper, we propose Super Kernel Flow Network (SKFlow), a CNN architecture to ameliorate the impacts of occlusions on optical flow estimation. SKFlow benefits from the super kernels which bring enlarged receptive fields to complement the absent matching information and recover the occluded motions. We present efficient super kernel designs by utilizing conical connections and hybrid depth-wise convolutions. Extensive experiments demonstrate the effectiveness of SKFlow on multiple benchmarks, especially in the occluded areas. Without pre-trained backbones on ImageNet and with modest increase in computation, SKFlow achieves compelling performance and ranks $\textbf{1st}$ among current published methods on Sintel benchmark. On the challenging Sintel final pass test set, SKFlow attains the average end-point error of $2.23$, which surpasses the best published result $2.47$ by $9.72\%$.

</p>
</details>

<details><summary><b>A General Multiple Data Augmentation Based Framework for Training Deep Neural Networks</b>
<a href="https://arxiv.org/abs/2205.14606">arxiv:2205.14606</a>
&#x1F4C8; 2 <br>
<p>Binyan Hu, Yu Sun, A. K. Qin</p></summary>
<p>

**Abstract:** Deep neural networks (DNNs) often rely on massive labelled data for training, which is inaccessible in many applications. Data augmentation (DA) tackles data scarcity by creating new labelled data from available ones. Different DA methods have different mechanisms and therefore using their generated labelled data for DNN training may help improving DNN's generalisation to different degrees. Combining multiple DA methods, namely multi-DA, for DNN training, provides a way to boost generalisation. Among existing multi-DA based DNN training methods, those relying on knowledge distillation (KD) have received great attention. They leverage knowledge transfer to utilise the labelled data sets created by multiple DA methods instead of directly combining them for training DNNs. However, existing KD-based methods can only utilise certain types of DA methods, incapable of utilising the advantages of arbitrary DA methods. We propose a general multi-DA based DNN training framework capable to use arbitrary DA methods. To train a DNN, our framework replicates a certain portion in the latter part of the DNN into multiple copies, leading to multiple DNNs with shared blocks in their former parts and independent blocks in their latter parts. Each of these DNNs is associated with a unique DA and a newly devised loss that allows comprehensively learning from the data generated by all DA methods and the outputs from all DNNs in an online and adaptive way. The overall loss, i.e., the sum of each DNN's loss, is used for training the DNN. Eventually, one of the DNNs with the best validation performance is chosen for inference. We implement the proposed framework by using three distinct DA methods and apply it for training representative DNNs. Experiments on the popular benchmarks of image classification demonstrate the superiority of our method to several existing single-DA and multi-DA based training methods.

</p>
</details>

<details><summary><b>Masked Distillation with Receptive Tokens</b>
<a href="https://arxiv.org/abs/2205.14589">arxiv:2205.14589</a>
&#x1F4C8; 2 <br>
<p>Tao Huang, Yuan Zhang, Shan You, Fei Wang, Chen Qian, Jian Cao, Chang Xu</p></summary>
<p>

**Abstract:** Distilling from the feature maps can be fairly effective for dense prediction tasks since both the feature discriminability and localization priors can be well transferred. However, not every pixel contributes equally to the performance, and a good student should learn from what really matters to the teacher. In this paper, we introduce a learnable embedding dubbed receptive token to localize those pixels of interests (PoIs) in the feature map, with a distillation mask generated via pixel-wise attention. Then the distillation will be performed on the mask via pixel-wise reconstruction. In this way, a distillation mask actually indicates a pattern of pixel dependencies within feature maps of teacher. We thus adopt multiple receptive tokens to investigate more sophisticated and informative pixel dependencies to further enhance the distillation. To obtain a group of masks, the receptive tokens are learned via the regular task loss but with teacher fixed, and we also leverage a Dice loss to enrich the diversity of learned masks. Our method dubbed MasKD is simple and practical, and needs no priors of tasks in application. Experiments show that our MasKD can achieve state-of-the-art performance consistently on object detection and semantic segmentation benchmarks. Code is available at: https://github.com/hunto/MasKD .

</p>
</details>

<details><summary><b>Learning Locality and Isotropy in Dialogue Modeling</b>
<a href="https://arxiv.org/abs/2205.14583">arxiv:2205.14583</a>
&#x1F4C8; 2 <br>
<p>Han Wu, Haochen Tan, Mingjie Zhan, Gangming Zhao, Shaoqing Lu, Ding Liang, Linqi Song</p></summary>
<p>

**Abstract:** Existing dialogue modeling methods have achieved promising performance on various dialogue tasks with the aid of Transformer and the large-scale pre-trained language models. However, some recent studies revealed that the context representations produced by these methods suffer the problem of anisotropy. In this paper, we find that the generated representations are also not conversational, losing the conversation structure information during the context modeling stage. To this end, we identify two properties in dialogue modeling, i.e., locality and isotropy, and present a simple method for dialogue representation calibration, namely SimDRC, to build isotropic and conversational feature spaces. Experimental results show that our approach significantly outperforms the current state-of-the-art models on three dialogue tasks across the automatic and human evaluation metrics. More in-depth analyses further confirm the effectiveness of our proposed approach.

</p>
</details>

<details><summary><b>Feature-Aligned Video Raindrop Removal with Temporal Constraints</b>
<a href="https://arxiv.org/abs/2205.14574">arxiv:2205.14574</a>
&#x1F4C8; 2 <br>
<p>Wending Yan, Lu Xu, Wenhan Yang, Robby T. Tan</p></summary>
<p>

**Abstract:** Existing adherent raindrop removal methods focus on the detection of the raindrop locations, and then use inpainting techniques or generative networks to recover the background behind raindrops. Yet, as adherent raindrops are diverse in sizes and appearances, the detection is challenging for both single image and video. Moreover, unlike rain streaks, adherent raindrops tend to cover the same area in several frames. Addressing these problems, our method employs a two-stage video-based raindrop removal method. The first stage is the single image module, which generates initial clean results. The second stage is the multiple frame module, which further refines the initial results using temporal constraints, namely, by utilizing multiple input frames in our process and applying temporal consistency between adjacent output frames. Our single image module employs a raindrop removal network to generate initial raindrop removal results, and create a mask representing the differences between the input and initial output. Once the masks and initial results for consecutive frames are obtained, our multiple-frame module aligns the frames in both the image and feature levels and then obtains the clean background. Our method initially employs optical flow to align the frames, and then utilizes deformable convolution layers further to achieve feature-level frame alignment. To remove small raindrops and recover correct backgrounds, a target frame is predicted from adjacent frames. A series of unsupervised losses are proposed so that our second stage, which is the video raindrop removal module, can self-learn from video data without ground truths. Experimental results on real videos demonstrate the state-of-art performance of our method both quantitatively and qualitatively.

</p>
</details>

<details><summary><b>ComplexGen: CAD Reconstruction by B-Rep Chain Complex Generation</b>
<a href="https://arxiv.org/abs/2205.14573">arxiv:2205.14573</a>
&#x1F4C8; 2 <br>
<p>Haoxiang Guo, Shilin Liu, Hao Pan, Yang Liu, Xin Tong, Baining Guo</p></summary>
<p>

**Abstract:** We view the reconstruction of CAD models in the boundary representation (B-Rep) as the detection of geometric primitives of different orders, i.e. vertices, edges and surface patches, and the correspondence of primitives, which are holistically modeled as a chain complex, and show that by modeling such comprehensive structures more complete and regularized reconstructions can be achieved. We solve the complex generation problem in two steps. First, we propose a novel neural framework that consists of a sparse CNN encoder for input point cloud processing and a tri-path transformer decoder for generating geometric primitives and their mutual relationships with estimated probabilities. Second, given the probabilistic structure predicted by the neural network, we recover a definite B-Rep chain complex by solving a global optimization maximizing the likelihood under structural validness constraints and applying geometric refinements. Extensive tests on large scale CAD datasets demonstrate that the modeling of B-Rep chain complex structure enables more accurate detection for learning and more constrained reconstruction for optimization, leading to structurally more faithful and complete CAD B-Rep models than previous results.

</p>
</details>

<details><summary><b>Last-iterate convergence analysis of stochastic momentum methods for neural networks</b>
<a href="https://arxiv.org/abs/2205.14811">arxiv:2205.14811</a>
&#x1F4C8; 1 <br>
<p>Dongpo Xu, Jinlan Liu, Yinghua Lu, Jun Kong, Danilo Mandic</p></summary>
<p>

**Abstract:** The stochastic momentum method is a commonly used acceleration technique for solving large-scale stochastic optimization problems in artificial neural networks. Current convergence results of stochastic momentum methods under non-convex stochastic settings mostly discuss convergence in terms of the random output and minimum output. To this end, we address the convergence of the last iterate output (called last-iterate convergence) of the stochastic momentum methods for non-convex stochastic optimization problems, in a way conformal with traditional optimization theory. We prove the last-iterate convergence of the stochastic momentum methods under a unified framework, covering both stochastic heavy ball momentum and stochastic Nesterov accelerated gradient momentum. The momentum factors can be fixed to be constant, rather than time-varying coefficients in existing analyses. Finally, the last-iterate convergence of the stochastic momentum methods is verified on the benchmark MNIST and CIFAR-10 datasets.

</p>
</details>

<details><summary><b>TransforMAP: Transformer for Memory Access Prediction</b>
<a href="https://arxiv.org/abs/2205.14778">arxiv:2205.14778</a>
&#x1F4C8; 1 <br>
<p>Pengmiao Zhang, Ajitesh Srivastava, Anant V. Nori, Rajgopal Kannan, Viktor K. Prasanna</p></summary>
<p>

**Abstract:** Data Prefetching is a technique that can hide memory latency by fetching data before it is needed by a program. Prefetching relies on accurate memory access prediction, to which task machine learning based methods are increasingly applied. Unlike previous approaches that learn from deltas or offsets and perform one access prediction, we develop TransforMAP, based on the powerful Transformer model, that can learn from the whole address space and perform multiple cache line predictions. We propose to use the binary of memory addresses as model input, which avoids information loss and saves a token table in hardware. We design a block index bitmap to collect unordered future page offsets under the current page address as learning labels. As a result, our model can learn temporal patterns as well as spatial patterns within a page. In a practical implementation, this approach has the potential to hide prediction latency because it prefetches multiple cache lines likely to be used in a long horizon. We show that our approach achieves 35.67% MPKI improvement and 20.55% IPC improvement in simulation, higher than state-of-the-art Best-Offset prefetcher and ISB prefetcher.

</p>
</details>

<details><summary><b>Radial Spike and Slab Bayesian Neural Networks for Sparse Data in Ransomware Attacks</b>
<a href="https://arxiv.org/abs/2205.14759">arxiv:2205.14759</a>
&#x1F4C8; 1 <br>
<p>Jurijs Nazarovs, Jack W. Stokes, Melissa Turcotte, Justin Carroll, Itai Grady</p></summary>
<p>

**Abstract:** Ransomware attacks are increasing at an alarming rate, leading to large financial losses, unrecoverable encrypted data, data leakage, and privacy concerns. The prompt detection of ransomware attacks is required to minimize further damage, particularly during the encryption stage. However, the frequency and structure of the observed ransomware attack data makes this task difficult to accomplish in practice. The data corresponding to ransomware attacks represents temporal, high-dimensional sparse signals, with limited records and very imbalanced classes. While traditional deep learning models have been able to achieve state-of-the-art results in a wide variety of domains, Bayesian Neural Networks, which are a class of probabilistic models, are better suited to the issues of the ransomware data. These models combine ideas from Bayesian statistics with the rich expressive power of neural networks. In this paper, we propose the Radial Spike and Slab Bayesian Neural Network, which is a new type of Bayesian Neural network that includes a new form of the approximate posterior distribution. The model scales well to large architectures and recovers the sparse structure of target functions. We provide a theoretical justification for using this type of distribution, as well as a computationally efficient method to perform variational inference. We demonstrate the performance of our model on a real dataset of ransomware attacks and show improvement over a large number of baselines, including state-of-the-art models such as Neural ODEs (ordinary differential equations). In addition, we propose to represent low-level events as MITRE ATT\&CK tactics, techniques, and procedures (TTPs) which allows the model to better generalize to unseen ransomware attacks.

</p>
</details>

<details><summary><b>Adversarial Bandits Robust to $S$-Switch Regret</b>
<a href="https://arxiv.org/abs/2205.14839">arxiv:2205.14839</a>
&#x1F4C8; 0 <br>
<p>Jung-hun Kim, Se-Young Yun</p></summary>
<p>

**Abstract:** We study the adversarial bandit problem under $S$ number of switching best arms for unknown $S$. For handling this problem, we adopt the master-base framework using the online mirror descent method (OMD). We first provide a master-base algorithm with basic OMD, achieving $\tilde{O}(S^{1/2}K^{1/3}T^{2/3})$. For improving the regret bound with respect to $T$, we propose to use adaptive learning rates for OMD to control variance of loss estimators, and achieve $\tilde{O}(\min\{\mathbb{E}[\sqrt{SKTρ_T(h^\dagger)}],S\sqrt{KT}\})$, where $ρ_T(h^\dagger)$ is a variance term for loss estimators.

</p>
</details>

<details><summary><b>Lepton Flavour Violation Identification in Tau Decay ($τ^{-} \rightarrow μ^{-}μ^{-}μ^{+}$) Using Artificial Intelligence</b>
<a href="https://arxiv.org/abs/2205.14828">arxiv:2205.14828</a>
&#x1F4C8; 0 <br>
<p>Reymond Mesuga</p></summary>
<p>

**Abstract:** The discovery of neutrino oscillation, proving that neutrinos do have masses, reveals the misfits of particles in the current Standard Model (SM) theory. In theory, neutrinos having masses could result in lepton flavour not being a symmetry called Lepton Flavour Violation (LFV). While SM theory extensions allowed LFV processes, their branching fractions are too small, making them unobservable even with the strongest equipment up-to-date. With that, scientists in recent years have generated LFV-like processes from the combined LHCb and Monte-Carlo-Simulated data in an attempt to identify LFV using Artificial Intelligence (AI), specifically Machine Learning (ML) and Deep Learning (DL). This paper reports the contribution of the author on Flavours of Physics: Finding $τ\rightarrow μμμ$ competition on Kaggle. The performance of several algorithms in AI has been presented, such as XGBoost, LightGBM, custom 1-D Dense Block Neural Networks (DBNNs), and custom 1-D Convolutional Neural Networks (CNNs) in identifying LFV signals, specifically $τ^{-} \rightarrow μ^{-}μ^{-}μ^{+}$ decay from the combined LHCb and Monte-Carlo-Simulated data that imitates the signatures of the said decay. Kolmogorov-Smirnov (KS) and Cramer-von Mises (CvM) tests were also conducted to verify the validity of predictions for each of the trained algorithms. The result shows decent performances among algorithms, except for the LightGBM, for failing the CvM test, and a 20-layered CNN for having recorded a considerably low AUC. Meanwhile, XGBoost and a 10-layered DBNN recorded the highest AUC of 0.88. The main contribution of this paper is the extensive experiment involving custom DBNN and CNN algorithms in different layers, all of which have been rarely used in the past years in identifying LFV-like signatures, unlike GBMs and tree-based algorithms, which have been more popular in the said task.

</p>
</details>


{% endraw %}
Prev: [2022.05.28]({{ '/2022/05/28/2022.05.28.html' | relative_url }})  Next: [2022.05.30]({{ '/2022/05/30/2022.05.30.html' | relative_url }})