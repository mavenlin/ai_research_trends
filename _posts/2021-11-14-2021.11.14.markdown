## Summary for 2021-11-14, created on 2021-12-17


<details><summary><b>Free Will Belief as a consequence of Model-based Reinforcement Learning</b>
<a href="https://arxiv.org/abs/2111.08435">arxiv:2111.08435</a>
&#x1F4C8; 202 <br>
<p>Erik M. Rehn</p></summary>
<p>

**Abstract:** The debate on whether or not humans have free will has been raging for centuries. Although there are good arguments based on our current understanding of the laws of nature for the view that it is not possible for humans to have free will, most people believe they do. This discrepancy begs for an explanation. If we accept that we do not have free will, we are faced with two problems: (1) while freedom is a very commonly used concept that everyone intuitively understands, what are we actually referring to when we say that an action or choice is "free" or not? And, (2) why is the belief in free will so common? Where does this belief come from, and what is its purpose, if any? In this paper, we examine these questions from the perspective of reinforcement learning (RL). RL is a framework originally developed for training artificial intelligence agents. However, it can also be used as a computational model of human decision making and learning, and by doing so, we propose that the first problem can be answered by observing that people's common sense understanding of freedom is closely related to the information entropy of an RL agent's normalized action values, while the second can be explained by the necessity for agents to model themselves as if they could have taken decisions other than those they actually took, when dealing with the temporal credit assignment problem. Put simply, we suggest that by applying the RL framework as a model for human learning it becomes evident that in order for us to learn efficiently and be intelligent we need to view ourselves as if we have free will.

</p>
</details>

<details><summary><b>Linear, or Non-Linear, That is the Question!</b>
<a href="https://arxiv.org/abs/2111.07265">arxiv:2111.07265</a>
&#x1F4C8; 21 <br>
<p>Taeyong Kong, Taeri Kim, Jinsung Jeon, Jeongwhan Choi, Yeon-Chang Lee, Noseong Park, Sang-Wook Kim</p></summary>
<p>

**Abstract:** There were fierce debates on whether the non-linear embedding propagation of GCNs is appropriate to GCN-based recommender systems. It was recently found that the linear embedding propagation shows better accuracy than the non-linear embedding propagation. Since this phenomenon was discovered especially in recommender systems, it is required that we carefully analyze the linearity and non-linearity issue. In this work, therefore, we revisit the issues of i) which of the linear or non-linear propagation is better and ii) which factors of users/items decide the linearity/non-linearity of the embedding propagation. We propose a novel Hybrid Method of Linear and non-linEar collaborative filTering method (HMLET, pronounced as Hamlet). In our design, there exist both linear and non-linear propagation steps, when processing each user or item node, and our gating module chooses one of them, which results in a hybrid model of the linear and non-linear GCN-based collaborative filtering (CF). The proposed model yields the best accuracy in three public benchmark datasets. Moreover, we classify users/items into the following three classes depending on our gating modules' selections: Full-Non-Linearity (FNL), Partial-Non-Linearity (PNL), and Full-Linearity (FL). We found that there exist strong correlations between nodes' centrality and their class membership, i.e., important user/item nodes exhibit more preferences towards the non-linearity during the propagation steps. To our knowledge, we are the first who designs a hybrid method and reports the correlation between the graph centrality and the linearity/non-linearity of nodes. All HMLET codes and datasets are available at: https://github.com/qbxlvnf11/HMLET.

</p>
</details>

<details><summary><b>Mean-based Best Arm Identification in Stochastic Bandits under Reward Contamination</b>
<a href="https://arxiv.org/abs/2111.07458">arxiv:2111.07458</a>
&#x1F4C8; 8 <br>
<p>Arpan Mukherjee, Ali Tajer, Pin-Yu Chen, Payel Das</p></summary>
<p>

**Abstract:** This paper investigates the problem of best arm identification in $\textit{contaminated}$ stochastic multi-arm bandits. In this setting, the rewards obtained from any arm are replaced by samples from an adversarial model with probability $\varepsilon$. A fixed confidence (infinite-horizon) setting is considered, where the goal of the learner is to identify the arm with the largest mean. Owing to the adversarial contamination of the rewards, each arm's mean is only partially identifiable. This paper proposes two algorithms, a gap-based algorithm and one based on the successive elimination, for best arm identification in sub-Gaussian bandits. These algorithms involve mean estimates that achieve the optimal error guarantee on the deviation of the true mean from the estimate asymptotically. Furthermore, these algorithms asymptotically achieve the optimal sample complexity. Specifically, for the gap-based algorithm, the sample complexity is asymptotically optimal up to constant factors, while for the successive elimination-based algorithm, it is optimal up to logarithmic factors. Finally, numerical experiments are provided to illustrate the gains of the algorithms compared to the existing baselines.

</p>
</details>

<details><summary><b>Forecasting Crude Oil Price Using Event Extraction</b>
<a href="https://arxiv.org/abs/2111.09111">arxiv:2111.09111</a>
&#x1F4C8; 7 <br>
<p>Jiangwei Liu, Xiaohong Huang</p></summary>
<p>

**Abstract:** Research on crude oil price forecasting has attracted tremendous attention from scholars and policymakers due to its significant effect on the global economy. Besides supply and demand, crude oil prices are largely influenced by various factors, such as economic development, financial markets, conflicts, wars, and political events. Most previous research treats crude oil price forecasting as a time series or econometric variable prediction problem. Although recently there have been researches considering the effects of real-time news events, most of these works mainly use raw news headlines or topic models to extract text features without profoundly exploring the event information. In this study, a novel crude oil price forecasting framework, AGESL, is proposed to deal with this problem. In our approach, an open domain event extraction algorithm is utilized to extract underlying related events, and a text sentiment analysis algorithm is used to extract sentiment from massive news. Then a deep neural network integrating the news event features, sentimental features, and historical price features is built to predict future crude oil prices. Empirical experiments are performed on West Texas Intermediate (WTI) crude oil price data, and the results show that our approach obtains superior performance compared with several benchmark methods.

</p>
</details>

<details><summary><b>Textless Speech Emotion Conversion using Decomposed and Discrete Representations</b>
<a href="https://arxiv.org/abs/2111.07402">arxiv:2111.07402</a>
&#x1F4C8; 7 <br>
<p>Felix Kreuk, Adam Polyak, Jade Copet, Eugene Kharitonov, Tu-Anh Nguyen, Morgane Rivi√®re, Wei-Ning Hsu, Abdelrahman Mohamed, Emmanuel Dupoux, Yossi Adi</p></summary>
<p>

**Abstract:** Speech emotion conversion is the task of modifying the perceived emotion of a speech utterance while preserving the lexical content and speaker identity. In this study, we cast the problem of emotion conversion as a spoken language translation task. We decompose speech into discrete and disentangled learned representations, consisting of content units, F0, speaker, and emotion. First, we modify the speech content by translating the content units to a target emotion, and then predict the prosodic features based on these units. Finally, the speech waveform is generated by feeding the predicted representations into a neural vocoder. Such a paradigm allows us to go beyond spectral and parametric changes of the signal, and model non-verbal vocalizations, such as laughter insertion, yawning removal, etc. We demonstrate objectively and subjectively that the proposed method is superior to the baselines in terms of perceived emotion and audio quality. We rigorously evaluate all components of such a complex system and conclude with an extensive model analysis and ablation study to better emphasize the architectural choices, strengths and weaknesses of the proposed method. Samples and code will be publicly available under the following link: https://speechbot.github.io/emotion.

</p>
</details>

<details><summary><b>An Embarrassingly Pragmatic Introduction to Vision-based Autonomous Robots</b>
<a href="https://arxiv.org/abs/2112.05534">arxiv:2112.05534</a>
&#x1F4C8; 6 <br>
<p>Marcos V. Conde</p></summary>
<p>

**Abstract:** Autonomous robots are currently one of the most popular Artificial Intelligence problems, having experienced significant advances in the last decade, from Self-driving cars and humanoids to delivery robots and drones. Part of the problem is to get a robot to emulate the perception of human beings, our sense of sight, replacing the eyes with cameras and the brain with mathematical models such as Neural Networks. Developing an AI able to drive a car without human intervention and a small robot to deliver packages in the city may seem like different problems, nevertheless from the point of view of perception and vision, both problems have several similarities. The main solutions we currently find focus on the environment perception through visual information using Computer Vision techniques, Machine Learning, and various algorithms to make the robot understand the environment or scene, move, adapt its trajectory and perform its tasks (maintenance, exploration, etc.) without the need for human intervention. In this work, we develop a small-scale autonomous vehicle from scratch, capable of understanding the scene using only visual information, navigating through industrial environments, detecting people and obstacles, or performing simple maintenance tasks. We review the state-of-the-art of fundamental problems and demonstrate that many methods employed at small-scale are similar to the ones employed in real Self-driving cars from companies like Tesla or Lyft. Finally, we discuss the current state of Robotics and autonomous driving and the technological and ethical limitations that we can find in this field.

</p>
</details>

<details><summary><b>Intelligent Trading Systems: A Sentiment-Aware Reinforcement Learning Approach</b>
<a href="https://arxiv.org/abs/2112.02095">arxiv:2112.02095</a>
&#x1F4C8; 6 <br>
<p>Francisco Caio Lima Paiva, Leonardo Kanashiro Felizardo, Reinaldo Augusto da Costa Bianchi, Anna Helena Reali Costa</p></summary>
<p>

**Abstract:** The feasibility of making profitable trades on a single asset on stock exchanges based on patterns identification has long attracted researchers. Reinforcement Learning (RL) and Natural Language Processing have gained notoriety in these single-asset trading tasks, but only a few works have explored their combination. Moreover, some issues are still not addressed, such as extracting market sentiment momentum through the explicit capture of sentiment features that reflect the market condition over time and assessing the consistency and stability of RL results in different situations. Filling this gap, we propose the Sentiment-Aware RL (SentARL) intelligent trading system that improves profit stability by leveraging market mood through an adaptive amount of past sentiment features drawn from textual news. We evaluated SentARL across twenty assets, two transaction costs, and five different periods and initializations to show its consistent effectiveness against baselines. Subsequently, this thorough assessment allowed us to identify the boundary between news coverage and market sentiment regarding the correlation of price-time series above which SentARL's effectiveness is outstanding.

</p>
</details>

<details><summary><b>Human-error-potential Estimation based on Wearable Biometric Sensors</b>
<a href="https://arxiv.org/abs/2111.08502">arxiv:2111.08502</a>
&#x1F4C8; 6 <br>
<p>Hiroki Ohashi, Hiroto Nagayoshi</p></summary>
<p>

**Abstract:** This study tackles on a new problem of estimating human-error potential on a shop floor on the basis of wearable sensors. Unlike existing studies that utilize biometric sensing technology to estimate people's internal state such as fatigue and mental stress, we attempt to estimate the human-error potential in a situation where a target person does not stay calm, which is much more difficult as sensor noise significantly increases. We propose a novel formulation, in which the human-error-potential estimation problem is reduced to a classification problem, and introduce a new method that can be used for solving the classification problem even with noisy sensing data. The key ideas are to model the process of calculating biometric indices probabilistically so that the prior knowledge on the biometric indices can be integrated, and to utilize the features that represent the movement of target persons in combination with biometric features. The experimental analysis showed that our method effectively estimates the human-error potential.

</p>
</details>

<details><summary><b>Learning Multi-Stage Tasks with One Demonstration via Self-Replay</b>
<a href="https://arxiv.org/abs/2111.07447">arxiv:2111.07447</a>
&#x1F4C8; 6 <br>
<p>Norman Di Palo, Edward Johns</p></summary>
<p>

**Abstract:** In this work, we introduce a novel method to learn everyday-like multi-stage tasks from a single human demonstration, without requiring any prior object knowledge. Inspired by the recent Coarse-to-Fine Imitation Learning method, we model imitation learning as a learned object reaching phase followed by an open-loop replay of the demonstrator's actions. We build upon this for multi-stage tasks where, following the human demonstration, the robot can autonomously collect image data for the entire multi-stage task, by reaching the next object in the sequence and then replaying the demonstration, and then repeating in a loop for all stages of the task. We evaluate with real-world experiments on a set of everyday-like multi-stage tasks, which we show that our method can solve from a single demonstration. Videos and supplementary material can be found at https://www.robot-learning.uk/self-replay.

</p>
</details>

<details><summary><b>Scalable Intervention Target Estimation in Linear Models</b>
<a href="https://arxiv.org/abs/2111.07512">arxiv:2111.07512</a>
&#x1F4C8; 5 <br>
<p>Burak Varici, Karthikeyan Shanmugam, Prasanna Sattigeri, Ali Tajer</p></summary>
<p>

**Abstract:** This paper considers the problem of estimating the unknown intervention targets in a causal directed acyclic graph from observational and interventional data. The focus is on soft interventions in linear structural equation models (SEMs). Current approaches to causal structure learning either work with known intervention targets or use hypothesis testing to discover the unknown intervention targets even for linear SEMs. This severely limits their scalability and sample complexity. This paper proposes a scalable and efficient algorithm that consistently identifies all intervention targets. The pivotal idea is to estimate the intervention sites from the difference between the precision matrices associated with the observational and interventional datasets. It involves repeatedly estimating such sites in different subsets of variables. The proposed algorithm can be used to also update a given observational Markov equivalence class into the interventional Markov equivalence class. Consistency, Markov equivalency, and sample complexity are established analytically. Finally, simulation results on both real and synthetic data demonstrate the gains of the proposed approach for scalable causal structure recovery. Implementation of the algorithm and the code to reproduce the simulation results are available at \url{https://github.com/bvarici/intervention-estimation}.

</p>
</details>

<details><summary><b>Question Answering for Complex Electronic Health Records Database using Unified Encoder-Decoder Architecture</b>
<a href="https://arxiv.org/abs/2111.14703">arxiv:2111.14703</a>
&#x1F4C8; 4 <br>
<p>Seongsu Bae, Daeyoung Kim, Jiho Kim, Edward Choi</p></summary>
<p>

**Abstract:** An intelligent machine that can answer human questions based on electronic health records (EHR-QA) has a great practical value, such as supporting clinical decisions, managing hospital administration, and medical chatbots. Previous table-based QA studies focusing on translating natural questions into table queries (NLQ2SQL), however, suffer from the unique nature of EHR data due to complex and specialized medical terminology, hence increased decoding difficulty. In this paper, we design UniQA, a unified encoder-decoder architecture for EHR-QA where natural language questions are converted to queries such as SQL or SPARQL. We also propose input masking (IM), a simple and effective method to cope with complex medical terms and various typos and better learn the SQL/SPARQL syntax. Combining the unified architecture with an effective auxiliary training objective, UniQA demonstrated a significant performance improvement against the previous state-of-the-art model for MIMICSQL* (14.2% gain), the most complex NLQ2SQL dataset in the EHR domain, and its typo-ridden versions (approximately 28.8% gain). In addition, we confirmed consistent results for the graph-based EHR-QA dataset, MIMICSPARQL*.

</p>
</details>

<details><summary><b>Spatio-Temporal Split Learning for Autonomous Aerial Surveillance using Urban Air Mobility (UAM) Networks</b>
<a href="https://arxiv.org/abs/2111.11856">arxiv:2111.11856</a>
&#x1F4C8; 4 <br>
<p>Yoo Jeong Ha, Soyi Jung, Jae-Hyun Kim, Marco Levorato, Joongheon Kim</p></summary>
<p>

**Abstract:** Autonomous surveillance unmanned aerial vehicles (UAVs) are deployed to observe the streets of the city for any suspicious activities. This paper utilizes surveillance UAVs for the purpose of detecting the presence of a fire in the streets. An extensive database is collected from UAV surveillance drones. With the aid of artificial intelligence (AI), fire stations can swiftly identify the presence of a fire emerging in the neighborhood. Spatio-temporal split learning is applied to this scenario to preserve privacy and globally train a fire classification model. Fires are hazardous natural disasters that can spread very quickly. Swift identification of fire is required to deploy firefighters to the scene. In order to do this, strong communication between the UAV and the central server where the deep learning process occurs is required. Improving communication resilience is integral to enhancing a safe experience on the roads. Therefore, this paper explores the adequate number of clients and data ratios for split learning in this UAV setting, as well as the required network infrastructure.

</p>
</details>

<details><summary><b>Uncertainty quantification and inverse modeling for subsurface flow in 3D heterogeneous formations using a theory-guided convolutional encoder-decoder network</b>
<a href="https://arxiv.org/abs/2111.08691">arxiv:2111.08691</a>
&#x1F4C8; 4 <br>
<p>Rui Xu, Dongxiao Zhang, Nanzhe Wang</p></summary>
<p>

**Abstract:** We build surrogate models for dynamic 3D subsurface single-phase flow problems with multiple vertical producing wells. The surrogate model provides efficient pressure estimation of the entire formation at any timestep given a stochastic permeability field, arbitrary well locations and penetration lengths, and a timestep matrix as inputs. The well production rate or bottom hole pressure can then be determined based on Peaceman's formula. The original surrogate modeling task is transformed into an image-to-image regression problem using a convolutional encoder-decoder neural network architecture. The residual of the governing flow equation in its discretized form is incorporated into the loss function to impose theoretical guidance on the model training process. As a result, the accuracy and generalization ability of the trained surrogate models are significantly improved compared to fully data-driven models. They are also shown to have flexible extrapolation ability to permeability fields with different statistics. The surrogate models are used to conduct uncertainty quantification considering a stochastic permeability field, as well as to infer unknown permeability information based on limited well production data and observation data of formation properties. Results are shown to be in good agreement with traditional numerical simulation tools, but computational efficiency is dramatically improved.

</p>
</details>

<details><summary><b>A layer-stress learning framework universally augments deep neural network tasks</b>
<a href="https://arxiv.org/abs/2111.08597">arxiv:2111.08597</a>
&#x1F4C8; 4 <br>
<p>Shihao Shao, Yong Liu, Qinghua Cui</p></summary>
<p>

**Abstract:** Deep neural networks (DNN) such as Multi-Layer Perception (MLP) and Convolutional Neural Networks (CNN) represent one of the most established deep learning algorithms. Given the tremendous effects of the number of hidden layers on network architecture and performance, it is very important to choose the number of hidden layers but still a serious challenge. More importantly, the current network architectures can only process the information from the last layer of the feature extractor, which greatly limited us to further improve its performance. Here we presented a layer-stress deep learning framework (x-NN) which implemented automatic and wise depth decision on shallow or deep feature map in a deep network through firstly designing enough number of layers and then trading off them by Multi-Head Attention Block. The x-NN can make use of features from various depth layers through attention allocation and then help to make final decision as well. As a result, x-NN showed outstanding prediction ability in the Alzheimer's Disease Classification Technique Challenge PRCV 2021, in which it won the top laurel and outperformed all other AI models. Moreover, the performance of x-NN was verified by one more AD neuroimaging dataset and other AI tasks.

</p>
</details>

<details><summary><b>Scrutinizing XAI using linear ground-truth data with suppressor variables</b>
<a href="https://arxiv.org/abs/2111.07473">arxiv:2111.07473</a>
&#x1F4C8; 4 <br>
<p>Rick Wilming, C√©line Budding, Klaus-Robert M√ºller, Stefan Haufe</p></summary>
<p>

**Abstract:** Machine learning (ML) is increasingly often used to inform high-stakes decisions. As complex ML models (e.g., deep neural networks) are often considered black boxes, a wealth of procedures has been developed to shed light on their inner workings and the ways in which their predictions come about, defining the field of 'explainable AI' (XAI). Saliency methods rank input features according to some measure of 'importance'. Such methods are difficult to validate since a formal definition of feature importance is, thus far, lacking. It has been demonstrated that some saliency methods can highlight features that have no statistical association with the prediction target (suppressor variables). To avoid misinterpretations due to such behavior, we propose the actual presence of such an association as a necessary condition and objective preliminary definition for feature importance. We carefully crafted a ground-truth dataset in which all statistical dependencies are well-defined and linear, serving as a benchmark to study the problem of suppressor variables. We evaluate common explanation methods including LRP, DTD, PatternNet, PatternAttribution, LIME, Anchors, SHAP, and permutation-based methods with respect to our objective definition. We show that most of these methods are unable to distinguish important features from suppressors in this setting.

</p>
</details>

<details><summary><b>Unsupervised Action Localization Crop in Video Retargeting for 3D ConvNets</b>
<a href="https://arxiv.org/abs/2111.07426">arxiv:2111.07426</a>
&#x1F4C8; 4 <br>
<p>Prithwish Jana, Swarnabja Bhaumik, Partha Pratim Mohanta</p></summary>
<p>

**Abstract:** Untrimmed videos on social media or those captured by robots and surveillance cameras are of varied aspect ratios. However, 3D CNNs usually require as input a square-shaped video, whose spatial dimension is smaller than the original. Random- or center-cropping may leave out the video's subject altogether. To address this, we propose an unsupervised video cropping approach by shaping this as a retargeting and video-to-video synthesis problem. The synthesized video maintains a 1:1 aspect ratio, is smaller in size and is targeted at video-subject(s) throughout the entire duration. First, action localization is performed on each frame by identifying patches with homogeneous motion patterns. Thus, a single salient patch is pinpointed per frame. But to avoid viewpoint jitters and flickering, any inter-frame scale or position changes among the patches should be performed gradually over time. This issue is addressed with a polyBezier fitting in 3D space that passes through some chosen pivot timestamps and whose shape is influenced by the in-between control timestamps. To corroborate the effectiveness of the proposed method, we evaluate the video classification task by comparing our dynamic cropping technique with random cropping on three benchmark datasets, viz. UCF-101, HMDB-51 and ActivityNet v1.3. The clip and top-1 accuracy for video classification after our cropping, outperform 3D CNN performances for same-sized random-crop inputs, also surpassing some larger random-crop sizes.

</p>
</details>

<details><summary><b>Generating Band-Limited Adversarial Surfaces Using Neural Networks</b>
<a href="https://arxiv.org/abs/2111.07424">arxiv:2111.07424</a>
&#x1F4C8; 4 <br>
<p>Roee Ben-Shlomo, Yevgeniy Men, Ido Imanuel</p></summary>
<p>

**Abstract:** Generating adversarial examples is the art of creating a noise that is added to an input signal of a classifying neural network, and thus changing the network's classification, while keeping the noise as tenuous as possible. While the subject is well-researched in the 2D regime, it is lagging behind in the 3D regime, i.e. attacking a classifying network that works on 3D point-clouds or meshes and, for example, classifies the pose of people's 3D scans. As of now, the vast majority of papers that describe adversarial attacks in this regime work by methods of optimization. In this technical report we suggest a neural network that generates the attacks. This network utilizes PointNet's architecture with some alterations. While the previous articles on which we based our work on have to optimize each shape separately, i.e. tailor an attack from scratch for each individual input without any learning, we attempt to create a unified model that can deduce the needed adversarial example with a single forward run.

</p>
</details>

<details><summary><b>Estimation of Acetabular Version from Anteroposterior Pelvic Radiograph Employing Deep Learning</b>
<a href="https://arxiv.org/abs/2111.07369">arxiv:2111.07369</a>
&#x1F4C8; 4 <br>
<p>Ata Jodeiri, Hadi Seyedarabi, Fatemeh Shahbazi, Seyed Mohammad Mahdi Hashemi, Seyyedhossein Shafiei</p></summary>
<p>

**Abstract:** Background and Objective: The Acetabular version, an essential factor in total hip arthroplasty, is measured by CT scan as the gold standard. The dose of radiation and expensiveness of CT make anterior-posterior pelvic radiograph an appropriate alternative procedure. In this study, we applied a deep learning approach on anteroposterior pelvic X-rays to measure anatomical version, eliminating the necessity of using Computed tomography scan. Methods: The right and left acetabular version angles of the hips of 300 patients are computed using their CT images. The proposed deep learning model, Attention on Pretrained-VGG16 for Bone Age, is applied to the AP images of the included population. The age and gender of these people are added as two other inputs to the last fully connected layer of attention mechanism. As the output, the angles of both hips are predicted. Results: The angles of hips computed on CT increase as people get older with the mean values of 16.54 and 16.11 (right and left angles) for men and 20.61 and 19.55 for women in our dataset. The predicted errors in the estimation of right and left angles using the proposed method of deep learning are in the accurate region of error (<=3 degrees) which shows the ability of the proposed method in measuring anatomical version based on AP images. Conclusion: The suggested algorithm, applying pre-trained vgg16 on the AP images of the pelvis of patients followed by an attention model considering age and gender of patients, can assess version accurately using only AP radiographs while obviating the need for CT scan. The applied technique of estimation of anatomical acetabular version based on AP pelvic images using DL approaches, to the best of authors' knowledge, has not been published yet.

</p>
</details>

<details><summary><b>Automatic evaluation of scientific abstracts through natural language processing</b>
<a href="https://arxiv.org/abs/2112.01842">arxiv:2112.01842</a>
&#x1F4C8; 3 <br>
<p>Lucas G. O. Lopes, Thales M. A. Vieira, William W. M. Lira</p></summary>
<p>

**Abstract:** This work presents a framework to classify and evaluate distinct research abstract texts which are focused on the description of processes and their applications. In this context, this paper proposes natural language processing algorithms to classify, segment and evaluate the results of scientific work. Initially, the proposed framework categorize the abstract texts into according to the problems intended to be solved by employing a text classification approach. Then, the abstract text is segmented into problem description, methodology and results. Finally, the methodology of the abstract is ranked based on the sentiment analysis of its results. The proposed framework allows us to quickly rank the best methods to solve specific problems. To validate the proposed framework, oil production anomaly abstracts were experimented and achieved promising results.

</p>
</details>

<details><summary><b>Meta-Auto-Decoder for Solving Parametric Partial Differential Equations</b>
<a href="https://arxiv.org/abs/2111.08823">arxiv:2111.08823</a>
&#x1F4C8; 3 <br>
<p>Xiang Huang, Zhanhong Ye, Hongsheng Liu, Beiji Shi, Zidong Wang, Kang Yang, Yang Li, Bingya Weng, Min Wang, Haotian Chu, Jing Zhou, Fan Yu, Bei Hua, Lei Chen, Bin Dong</p></summary>
<p>

**Abstract:** Partial Differential Equations (PDEs) are ubiquitous in many disciplines of science and engineering and notoriously difficult to solve. In general, closed-form solutions of PDEs are unavailable and numerical approximation methods are computationally expensive. The parameters of PDEs are variable in many applications, such as inverse problems, control and optimization, risk assessment, and uncertainty quantification. In these applications, our goal is to solve parametric PDEs rather than one instance of them. Our proposed approach, called Meta-Auto-Decoder (MAD), treats solving parametric PDEs as a meta-learning problem and utilizes the Auto-Decoder structure in \cite{park2019deepsdf} to deal with different tasks/PDEs. Physics-informed losses induced from the PDE governing equations and boundary conditions is used as the training losses for different tasks. The goal of MAD is to learn a good model initialization that can generalize across different tasks, and eventually enables the unseen task to be learned faster. The inspiration of MAD comes from (conjectured) low-dimensional structure of parametric PDE solutions and we explain our approach from the perspective of manifold learning. Finally, we demonstrate the power of MAD though extensive numerical studies, including Burgers' equation, Laplace's equation and time-domain Maxwell's equations. MAD exhibits faster convergence speed without losing the accuracy compared with other deep learning methods.

</p>
</details>

<details><summary><b>Towards Lightweight Controllable Audio Synthesis with Conditional Implicit Neural Representations</b>
<a href="https://arxiv.org/abs/2111.08462">arxiv:2111.08462</a>
&#x1F4C8; 3 <br>
<p>Jan Zuiderveld, Marco Federici, Erik J. Bekkers</p></summary>
<p>

**Abstract:** The high temporal resolution of audio and our perceptual sensitivity to small irregularities in waveforms make synthesizing at high sampling rates a complex and computationally intensive task, prohibiting real-time, controllable synthesis within many approaches. In this work we aim to shed light on the potential of Conditional Implicit Neural Representations (CINRs) as lightweight backbones in generative frameworks for audio synthesis.
  Our experiments show that small Periodic Conditional INRs (PCINRs) learn faster and generally produce quantitatively better audio reconstructions than Transposed Convolutional Neural Networks with equal parameter counts. However, their performance is very sensitive to activation scaling hyperparameters. When learning to represent more uniform sets, PCINRs tend to introduce artificial high-frequency components in reconstructions. We validate this noise can be minimized by applying standard weight regularization during training or decreasing the compositional depth of PCINRs, and suggest directions for future research.

</p>
</details>

<details><summary><b>Public Policymaking for International Agricultural Trade using Association Rules and Ensemble Machine Learning</b>
<a href="https://arxiv.org/abs/2111.07508">arxiv:2111.07508</a>
&#x1F4C8; 3 <br>
<p>Feras A. Batarseh, Munisamy Gopinath, Anderson Monken, Zhengrong Gu</p></summary>
<p>

**Abstract:** International economics has a long history of improving our understanding of factors causing trade, and the consequences of free flow of goods and services across countries. The recent shocks to the free trade regime, especially trade disputes among major economies, as well as black swan events, such as trade wars and pandemics, raise the need for improved predictions to inform policy decisions. AI methods are allowing economists to solve such prediction problems in new ways. In this manuscript, we present novel methods that predict and associate food and agricultural commodities traded internationally. Association Rules (AR) analysis has been deployed successfully for economic scenarios at the consumer or store level, such as for market basket analysis. In our work however, we present analysis of imports and exports associations and their effects on commodity trade flows. Moreover, Ensemble Machine Learning methods are developed to provide improved agricultural trade predictions, outlier events' implications, and quantitative pointers to policy makers.

</p>
</details>

<details><summary><b>Measuring Outcomes in Healthcare Economics using Artificial Intelligence: with Application to Resource Management</b>
<a href="https://arxiv.org/abs/2111.07503">arxiv:2111.07503</a>
&#x1F4C8; 3 <br>
<p>Chih-Hao Huang, Feras A. Batarseh, Adel Boueiz, Ajay Kulkarni, Po-Hsuan Su, Jahan Aman</p></summary>
<p>

**Abstract:** The quality of service in healthcare is constantly challenged by outlier events such as pandemics (i.e. Covid-19) and natural disasters (such as hurricanes and earthquakes). In most cases, such events lead to critical uncertainties in decision making, as well as in multiple medical and economic aspects at a hospital. External (geographic) or internal factors (medical and managerial), lead to shifts in planning and budgeting, but most importantly, reduces confidence in conventional processes. In some cases, support from other hospitals proves necessary, which exacerbates the planning aspect. This manuscript presents three data-driven methods that provide data-driven indicators to help healthcare managers organize their economics and identify the most optimum plan for resources allocation and sharing. Conventional decision-making methods fall short in recommending validated policies for managers. Using reinforcement learning, genetic algorithms, traveling salesman, and clustering, we experimented with different healthcare variables and presented tools and outcomes that could be applied at health institutes. Experiments are performed; the results are recorded, evaluated, and presented.

</p>
</details>

<details><summary><b>Distribution-Free Models for Community Detection</b>
<a href="https://arxiv.org/abs/2111.07495">arxiv:2111.07495</a>
&#x1F4C8; 3 <br>
<p>Huan Qing</p></summary>
<p>

**Abstract:** Community detection for un-weighted networks has been widely studied in network analysis, but the case of weighted networks remains a challenge. In this paper, a Distribution-Free Models (DFM) is proposed for networks in which nodes are partitioned into different communities. DFM is a general, interpretable and identifiable model for both un-weighted networks and weighted networks. The proposed model does not require prior knowledge on a specific distribution for elements of adjacency matrix but only the expected value. The distribution-free property of DFM even allows adjacency matrix to have negative elements. We develop an efficient spectral algorithm to fit DFM. By introducing a noise matrix, we build a theoretic framework on perturbation analysis to show that the proposed algorithm stably yields consistent community detection under DFM. Numerical experiments on both synthetic networks and two social networks from literature are used to illustrate the algorithm.

</p>
</details>

<details><summary><b>Decoding Causality by Fictitious VAR Modeling</b>
<a href="https://arxiv.org/abs/2111.07465">arxiv:2111.07465</a>
&#x1F4C8; 3 <br>
<p>Xingwei Hu</p></summary>
<p>

**Abstract:** In modeling multivariate time series for either forecast or policy analysis, it would be beneficial to have figured out the cause-effect relations within the data. Regression analysis, however, is generally for correlation relation, and very few researches have focused on variance analysis for causality discovery. We first set up an equilibrium for the cause-effect relations using a fictitious vector autoregressive model. In the equilibrium, long-run relations are identified from noise, and spurious ones are negligibly close to zero. The solution, called causality distribution, measures the relative strength causing the movement of all series or specific affected ones. If a group of exogenous data affects the others but not vice versa, then, in theory, the causality distribution for other variables is necessarily zero. The hypothesis test of zero causality is the rule to decide a variable is endogenous or not. Our new approach has high accuracy in identifying the true cause-effect relations among the data in the simulation studies. We also apply the approach to estimating the causal factors' contribution to climate change.

</p>
</details>

<details><summary><b>HAD-Net: Hybrid Attention-based Diffusion Network for Glucose Level Forecast</b>
<a href="https://arxiv.org/abs/2111.07455">arxiv:2111.07455</a>
&#x1F4C8; 3 <br>
<p>Quentin Blampey, Mehdi Rahim</p></summary>
<p>

**Abstract:** Data-driven models for glucose level forecast often do not provide meaningful insights despite accurate predictions. Yet, context understanding in medicine is crucial, in particular for diabetes management. In this paper, we introduce HAD-Net: a hybrid model that distills knowledge into a deep neural network from physiological models. It models glucose, insulin and carbohydrates diffusion through a biologically inspired deep learning architecture tailored with a recurrent attention network constrained by ODE expert models. We apply HAD-Net for glucose level forecast of patients with type-2 diabetes. It achieves competitive performances while providing plausible measurements of insulin and carbohydrates diffusion over time.

</p>
</details>

<details><summary><b>A distributed, plug-n-play algorithm for multi-robot applications with a priori non-computable objective functions</b>
<a href="https://arxiv.org/abs/2111.07441">arxiv:2111.07441</a>
&#x1F4C8; 3 <br>
<p>Athanasios Ch. Kapoutsis, Savvas A. Chatzichristofis, Elias B. Kosmatopoulos</p></summary>
<p>

**Abstract:** This paper presents a distributed algorithm applicable to a wide range of practical multi-robot applications. In such multi-robot applications, the user-defined objectives of the mission can be cast as a general optimization problem, without explicit guidelines of the subtasks per different robot. Owing to the unknown environment, unknown robot dynamics, sensor nonlinearities, etc., the analytic form of the optimization cost function is not available a priori. Therefore, standard gradient-descent-like algorithms are not applicable to these problems. To tackle this, we introduce a new algorithm that carefully designs each robot's subcost function, the optimization of which can accomplish the overall team objective. Upon this transformation, we propose a distributed methodology based on the cognitive-based adaptive optimization (CAO) algorithm, that is able to approximate the evolution of each robot's cost function and to adequately optimize its decision variables (robot actions). The latter can be achieved by online learning only the problem-specific characteristics that affect the accomplishment of mission objectives. The overall, low-complexity algorithm can straightforwardly incorporate any kind of operational constraint, is fault tolerant, and can appropriately tackle time-varying cost functions. A cornerstone of this approach is that it shares the same convergence characteristics as those of block coordinate descent algorithms. The proposed algorithm is evaluated in three heterogeneous simulation set-ups under multiple scenarios, against both general-purpose and problem-specific algorithms. Source code is available at \url{https://github.com/athakapo/A-distributed-plug-n-play-algorithm-for-multi-robot-applications}.

</p>
</details>

<details><summary><b>Learning a Shared Model for Motorized Prosthetic Joints to Predict Ankle-Joint Motion</b>
<a href="https://arxiv.org/abs/2111.07419">arxiv:2111.07419</a>
&#x1F4C8; 3 <br>
<p>Sharmita Dey, Sabri Boughorbel, Arndt F. Schilling</p></summary>
<p>

**Abstract:** Control strategies for active prostheses or orthoses use sensor inputs to recognize the user's locomotive intention and generate corresponding control commands for producing the desired locomotion. In this paper, we propose a learning-based shared model for predicting ankle-joint motion for different locomotion modes like level-ground walking, stair ascent, stair descent, slope ascent, and slope descent without the need to classify between them. Features extracted from hip and knee joint angular motion are used to continuously predict the ankle angles and moments using a Feed-Forward Neural Network-based shared model. We show that the shared model is adequate for predicting the ankle angles and moments for different locomotion modes without explicitly classifying between the modes. The proposed strategy shows the potential for devising a high-level controller for an intelligent prosthetic ankle that can adapt to different locomotion modes.

</p>
</details>

<details><summary><b>Adaptive Cost-Sensitive Learning in Neural Networks for Misclassification Cost Problems</b>
<a href="https://arxiv.org/abs/2111.07382">arxiv:2111.07382</a>
&#x1F4C8; 3 <br>
<p>Ohad Volk, Gonen Singer</p></summary>
<p>

**Abstract:** We design a new adaptive learning algorithm for misclassification cost problems that attempt to reduce the cost of misclassified instances derived from the consequences of various errors. Our algorithm (adaptive cost sensitive learning - AdaCSL) adaptively adjusts the loss function such that the classifier bridges the difference between the class distributions between subgroups of samples in the training and test data sets with similar predicted probabilities (i.e., local training-test class distribution mismatch). We provide some theoretical performance guarantees on the proposed algorithm and present empirical evidence that a deep neural network used with the proposed AdaCSL algorithm yields better cost results on several binary classification data sets that have class-imbalanced and class-balanced distributions compared to other alternative approaches.

</p>
</details>

<details><summary><b>TEA: A Sequential Recommendation Framework via Temporally Evolving Aggregations</b>
<a href="https://arxiv.org/abs/2111.07378">arxiv:2111.07378</a>
&#x1F4C8; 3 <br>
<p>Zijian Li, Ruichu Cai, Fengzhu Wu, Sili Zhang, Hao Gu, Yuexing Hao,  Yuguang</p></summary>
<p>

**Abstract:** Sequential recommendation aims to choose the most suitable items for a user at a specific timestamp given historical behaviors. Existing methods usually model the user behavior sequence based on the transition-based methods like Markov Chain. However, these methods also implicitly assume that the users are independent of each other without considering the influence between users. In fact, this influence plays an important role in sequence recommendation since the behavior of a user is easily affected by others. Therefore, it is desirable to aggregate both user behaviors and the influence between users, which are evolved temporally and involved in the heterogeneous graph of users and items. In this paper, we incorporate dynamic user-item heterogeneous graphs to propose a novel sequential recommendation framework. As a result, the historical behaviors as well as the influence between users can be taken into consideration. To achieve this, we firstly formalize sequential recommendation as a problem to estimate conditional probability given temporal dynamic heterogeneous graphs and user behavior sequences. After that, we exploit the conditional random field to aggregate the heterogeneous graphs and user behaviors for probability estimation, and employ the pseudo-likelihood approach to derive a tractable objective function. Finally, we provide scalable and flexible implementations of the proposed framework. Experimental results on three real-world datasets not only demonstrate the effectiveness of our proposed method but also provide some insightful discoveries on sequential recommendation.

</p>
</details>

<details><summary><b>Towards Privacy-Preserving Affect Recognition: A Two-Level Deep Learning Architecture</b>
<a href="https://arxiv.org/abs/2111.07344">arxiv:2111.07344</a>
&#x1F4C8; 3 <br>
<p>Jimiama M. Mase, Natalie Leesakul, Fan Yang, Grazziela P. Figueredo, Mercedes Torres Torres</p></summary>
<p>

**Abstract:** Automatically understanding and recognising human affective states using images and computer vision can improve human-computer and human-robot interaction. However, privacy has become an issue of great concern, as the identities of people used to train affective models can be exposed in the process. For instance, malicious individuals could exploit images from users and assume their identities. In addition, affect recognition using images can lead to discriminatory and algorithmic bias, as certain information such as race, gender, and age could be assumed based on facial features. Possible solutions to protect the privacy of users and avoid misuse of their identities are to: (1) extract anonymised facial features, namely action units (AU) from a database of images, discard the images and use AUs for processing and training, and (2) federated learning (FL) i.e. process raw images in users' local machines (local processing) and send the locally trained models to the main processing machine for aggregation (central processing). In this paper, we propose a two-level deep learning architecture for affect recognition that uses AUs in level 1 and FL in level 2 to protect users' identities. The architecture consists of recurrent neural networks to capture the temporal relationships amongst the features and predict valence and arousal affective states. In our experiments, we evaluate the performance of our privacy-preserving architecture using different variations of recurrent neural networks on RECOLA, a comprehensive multimodal affective database. Our results show state-of-the-art performance of $0.426$ for valence and $0.401$ for arousal using the Concordance Correlation Coefficient evaluation metric, demonstrating the feasibility of developing models for affect recognition that are both accurate and ensure privacy.

</p>
</details>

<details><summary><b>Relative Distributed Formation and Obstacle Avoidance with Multi-agent Reinforcement Learning</b>
<a href="https://arxiv.org/abs/2111.07334">arxiv:2111.07334</a>
&#x1F4C8; 3 <br>
<p>Yuzi Yan, Xiaoxiang Li, Xinyou Qiu, Jiantao Qiu, Jian Wang, Yu Wang, Yuan Shen</p></summary>
<p>

**Abstract:** Multi-agent formation as well as obstacle avoidance is one of the most actively studied topics in the field of multi-agent systems. Although some classic controllers like model predictive control (MPC) and fuzzy control achieve a certain measure of success, most of them require precise global information which is not accessible in harsh environments. On the other hand, some reinforcement learning (RL) based approaches adopt the leader-follower structure to organize different agents' behaviors, which sacrifices the collaboration between agents thus suffering from bottlenecks in maneuverability and robustness. In this paper, we propose a distributed formation and obstacle avoidance method based on multi-agent reinforcement learning (MARL). Agents in our system only utilize local and relative information to make decisions and control themselves distributively. Agent in the multi-agent system will reorganize themselves into a new topology quickly in case that any of them is disconnected. Our method achieves better performance regarding formation error, formation convergence rate and on-par success rate of obstacle avoidance compared with baselines (both classic control methods and another RL-based method). The feasibility of our method is verified by both simulation and hardware implementation with Ackermann-steering vehicles.

</p>
</details>

<details><summary><b>Simulating Diffusion Bridges with Score Matching</b>
<a href="https://arxiv.org/abs/2111.07243">arxiv:2111.07243</a>
&#x1F4C8; 3 <br>
<p>Valentin De Bortoli, Arnaud Doucet, Jeremy Heng, James Thornton</p></summary>
<p>

**Abstract:** We consider the problem of simulating diffusion bridges, i.e. diffusion processes that are conditioned to initialize and terminate at two given states. Diffusion bridge simulation has applications in diverse scientific fields and plays a crucial role for statistical inference of discretely-observed diffusions. This is known to be a challenging problem that has received much attention in the last two decades. In this work, we first show that the time-reversed diffusion bridge process can be simulated if one can time-reverse the unconditioned diffusion process. We introduce a variational formulation to learn this time-reversal that relies on a score matching method to circumvent intractability. We then consider another iteration of our proposed methodology to approximate the Doob's $h$-transform defining the diffusion bridge process. As our approach is generally applicable under mild assumptions on the underlying diffusion process, it can easily be used to improve the proposal bridge process within existing methods and frameworks. We discuss algorithmic considerations and extensions, and present some numerical results.

</p>
</details>

<details><summary><b>Comparative Study of Speech Analysis Methods to Predict Parkinson's Disease</b>
<a href="https://arxiv.org/abs/2111.10207">arxiv:2111.10207</a>
&#x1F4C8; 2 <br>
<p>Adedolapo Aishat Toye, Suryaprakash Kompalli</p></summary>
<p>

**Abstract:** One of the symptoms observed in the early stages of Parkinson's Disease (PD) is speech impairment. Speech disorders can be used to detect this disease before it degenerates. This work analyzes speech features and machine learning approaches to predict PD. Acoustic features such as shimmer and jitter variants, and Mel Frequency Cepstral Coefficients (MFCC) are extracted from speech signals. We use two datasets in this work: the MDVR-KCL and the Italian Parkinson's Voice and Speech database. To separate PD and non-PD speech signals, seven classification models were implemented: K-Nearest Neighbor, Decision Trees, Support Vector Machines, Naive Bayes, Logistic Regression, Gradient Boosting, Random Forests. Three feature sets were used for each of the models: (a) Acoustic features only, (b) All the acoustic features and MFCC, (c) Selected subset of features from acoustic features and MFCC. Using all the acoustic features and MFCC, together with SVM produced the highest performance with an accuracy of 98% and F1-Score of 99%. When compared with prior art, this shows a better performance. Our code and related documentation is available in a public domain repository.

</p>
</details>

<details><summary><b>A Comparative Study on Basic Elements of Deep Learning Models for Spatial-Temporal Traffic Forecasting</b>
<a href="https://arxiv.org/abs/2111.07513">arxiv:2111.07513</a>
&#x1F4C8; 2 <br>
<p>Yuyol Shin, Yoonjin Yoon</p></summary>
<p>

**Abstract:** Traffic forecasting plays a crucial role in intelligent transportation systems. The spatial-temporal complexities in transportation networks make the problem especially challenging. The recently suggested deep learning models share basic elements such as graph convolution, graph attention, recurrent units, and/or attention mechanism. In this study, we designed an in-depth comparative study for four deep neural network models utilizing different basic elements. For base models, one RNN-based model and one attention-based model were chosen from previous literature. Then, the spatial feature extraction layers in the models were substituted with graph convolution and graph attention. To analyze the performance of each element in various environments, we conducted experiments on four real-world datasets - highway speed, highway flow, urban speed from a homogeneous road link network, and urban speed from a heterogeneous road link network. The results demonstrate that the RNN-based model and the attention-based model show a similar level of performance for short-term prediction, and the attention-based model outperforms the RNN in longer-term predictions. The choice of graph convolution and graph attention makes a larger difference in the RNN-based models. Also, our modified version of GMAN shows comparable performance with the original with less memory consumption.

</p>
</details>

<details><summary><b>Contrastive Clustering: Toward Unsupervised Bias Reduction for Emotion and Sentiment Classification</b>
<a href="https://arxiv.org/abs/2111.07448">arxiv:2111.07448</a>
&#x1F4C8; 2 <br>
<p>Jared Mowery</p></summary>
<p>

**Abstract:** Background: When neural network emotion and sentiment classifiers are used in public health informatics studies, biases present in the classifiers could produce inadvertently misleading results.
  Objective: This study assesses the impact of bias on COVID-19 topics, and demonstrates an automatic algorithm for reducing bias when applied to COVID-19 social media texts. This could help public health informatics studies produce more timely results during crises, with a reduced risk of misleading results.
  Methods: Emotion and sentiment classifiers were applied to COVID-19 data before and after debiasing the classifiers using unsupervised contrastive clustering. Contrastive clustering approximates the degree to which tokens exhibit a causal versus correlational relationship with emotion or sentiment, by contrasting the tokens' relative salience to topics versus emotions or sentiments.
  Results: Contrastive clustering distinguishes correlation from causation for tokens with an F1 score of 0.753. Masking bias prone tokens from the classifier input decreases the classifier's overall F1 score by 0.02 (anger) and 0.033 (negative sentiment), but improves the F1 score for sentences annotated as bias prone by 0.155 (anger) and 0.103 (negative sentiment). Averaging across topics, debiasing reduces anger estimates by 14.4% and negative sentiment estimates by 8.0%.
  Conclusions: Contrastive clustering reduces algorithmic bias in emotion and sentiment classification for social media text pertaining to the COVID-19 pandemic. Public health informatics studies should account for bias, due to its prevalence across a range of topics. Further research is needed to improve bias reduction techniques and to explore the adverse impact of bias on public health informatics analyses.

</p>
</details>

<details><summary><b>Improving Compound Activity Classification via Deep Transfer and Representation Learning</b>
<a href="https://arxiv.org/abs/2111.07439">arxiv:2111.07439</a>
&#x1F4C8; 2 <br>
<p>Vishal Dey, Raghu Machiraju, Xia Ning</p></summary>
<p>

**Abstract:** Recent advances in molecular machine learning, especially deep neural networks such as Graph Neural Networks (GNNs) for predicting structure activity relationships (SAR) have shown tremendous potential in computer-aided drug discovery. However, the applicability of such deep neural networks are limited by the requirement of large amounts of training data. In order to cope with limited training data for a target task, transfer learning for SAR modeling has been recently adopted to leverage information from data of related tasks. In this work, in contrast to the popular parameter-based transfer learning such as pretraining, we develop novel deep transfer learning methods TAc and TAc-fc to leverage source domain data and transfer useful information to the target domain. TAc learns to generate effective molecular features that can generalize well from one domain to another, and increase the classification performance in the target domain. Additionally, TAc-fc extends TAc by incorporating novel components to selectively learn feature-wise and compound-wise transferability. We used the bioassay screening data from PubChem, and identified 120 pairs of bioassays such that the active compounds in each pair are more similar to each other compared to its inactive compounds. Overall, TAc achieves the best performance with average ROC-AUC of 0.801; it significantly improves ROC-AUC of 83% target tasks with average task-wise performance improvement of 7.102%, compared to the best baseline FCN-dmpna (DT). Our experiments clearly demonstrate that TAc achieves significant improvement over all baselines across a large number of target tasks. Furthermore, although TAc-fc achieves slightly worse ROC-AUC on average compared to TAc (0.798 vs 0.801), TAc-fc still achieves the best performance on more tasks in terms of PR-AUC and F1 compared to other methods.

</p>
</details>

<details><summary><b>A Machine Learning Approach for Recruitment Prediction in Clinical Trial Design</b>
<a href="https://arxiv.org/abs/2111.07407">arxiv:2111.07407</a>
&#x1F4C8; 2 <br>
<p>Jingshu Liu, Patricia J Allen, Luke Benz, Daniel Blickstein, Evon Okidi, Xiao Shi</p></summary>
<p>

**Abstract:** Significant advancements have been made in recent years to optimize patient recruitment for clinical trials, however, improved methods for patient recruitment prediction are needed to support trial site selection and to estimate appropriate enrollment timelines in the trial design stage. In this paper, using data from thousands of historical clinical trials, we explore machine learning methods to predict the number of patients enrolled per month at a clinical trial site over the course of a trial's enrollment duration. We show that these methods can reduce the error that is observed with current industry standards and propose opportunities for further improvement.

</p>
</details>

<details><summary><b>DEEP: DEnoising Entity Pre-training for Neural Machine Translation</b>
<a href="https://arxiv.org/abs/2111.07393">arxiv:2111.07393</a>
&#x1F4C8; 2 <br>
<p>Junjie Hu, Hiroaki Hayashi, Kyunghyun Cho, Graham Neubig</p></summary>
<p>

**Abstract:** It has been shown that machine translation models usually generate poor translations for named entities that are infrequent in the training corpus. Earlier named entity translation methods mainly focus on phonetic transliteration, which ignores the sentence context for translation and is limited in domain and language coverage. To address this limitation, we propose DEEP, a DEnoising Entity Pre-training method that leverages large amounts of monolingual data and a knowledge base to improve named entity translation accuracy within sentences. Besides, we investigate a multi-task learning strategy that finetunes a pre-trained neural machine translation model on both entity-augmented monolingual data and parallel data to further improve entity translation. Experimental results on three language pairs demonstrate that \method results in significant improvements over strong denoising auto-encoding baselines, with a gain of up to 1.3 BLEU and up to 9.2 entity accuracy points for English-Russian translation.

</p>
</details>

<details><summary><b>Interpretable ECG classification via a query-based latent space traversal (qLST)</b>
<a href="https://arxiv.org/abs/2111.07386">arxiv:2111.07386</a>
&#x1F4C8; 2 <br>
<p>Melle B. Vessies, Sharvaree P. Vadgama, Rutger R. van de Leur, Pieter A. Doevendans, Rutger J. Hassink, Erik Bekkers, Ren√© van Es</p></summary>
<p>

**Abstract:** Electrocardiography (ECG) is an effective and non-invasive diagnostic tool that measures the electrical activity of the heart. Interpretation of ECG signals to detect various abnormalities is a challenging task that requires expertise. Recently, the use of deep neural networks for ECG classification to aid medical practitioners has become popular, but their black box nature hampers clinical implementation. Several saliency-based interpretability techniques have been proposed, but they only indicate the location of important features and not the actual features. We present a novel interpretability technique called qLST, a query-based latent space traversal technique that is able to provide explanations for any ECG classification model. With qLST, we train a neural network that learns to traverse in the latent space of a variational autoencoder trained on a large university hospital dataset with over 800,000 ECGs annotated for 28 diseases. We demonstrate through experiments that we can explain different black box classifiers by generating ECGs through these traversals.

</p>
</details>

<details><summary><b>On equivalence between linear-chain conditional random fields and hidden Markov chains</b>
<a href="https://arxiv.org/abs/2111.07376">arxiv:2111.07376</a>
&#x1F4C8; 2 <br>
<p>Elie Azeraf, Emmanuel Monfrini, Wojciech Pieczynski</p></summary>
<p>

**Abstract:** Practitioners successfully use hidden Markov chains (HMCs) in different problems for about sixty years. HMCs belong to the family of generative models and they are often compared to discriminative models, like conditional random fields (CRFs). Authors usually consider CRFs as quite different from HMCs, and CRFs are often presented as interesting alternative to HMCs. In some areas, like natural language processing (NLP), discriminative models have completely supplanted generative models. However, some recent results show that both families of models are not so different, and both of them can lead to identical processing power. In this paper we compare the simple linear-chain CRFs to the basic HMCs. We show that HMCs are identical to CRFs in that for each CRF we explicitly construct an HMC having the same posterior distribution. Therefore, HMCs and linear-chain CRFs are not different but just differently parametrized models.

</p>
</details>

<details><summary><b>Fracture Detection in Wrist X-ray Images Using Deep Learning-Based Object Detection Models</b>
<a href="https://arxiv.org/abs/2111.07355">arxiv:2111.07355</a>
&#x1F4C8; 2 <br>
<p>Fƒ±rat Hardala√ß, Fatih Uysal, Ozan Peker, Murat √ái√ßeklidaƒü, Tolga Tolunay, Nil Tokg√∂z, Uƒüurhan Kutbay, Boran Demirciler, Fatih Mert</p></summary>
<p>

**Abstract:** Wrist fractures are common cases in hospitals, particularly in emergency services. Physicians need images from various medical devices, and patients medical history and physical examination to diagnose these fractures correctly and apply proper treatment. This study aims to perform fracture detection using deep learning on wrist Xray images to assist physicians not specialized in the field, working in emergency services in particular, in diagnosis of fractures. For this purpose, 20 different detection procedures were performed using deep learning based object detection models on dataset of wrist Xray images obtained from Gazi University Hospital. DCN, Dynamic R_CNN, Faster R_CNN, FSAF, Libra R_CNN, PAA, RetinaNet, RegNet and SABL deep learning based object detection models with various backbones were used herein. To further improve detection procedures in the study, 5 different ensemble models were developed, which were later used to reform an ensemble model to develop a detection model unique to our study, titled wrist fracture detection combo (WFD_C). Based on detection of 26 different fractures in total, the highest result of detection was 0.8639 average precision (AP50) in WFD_C model developed. This study is supported by Huawei Turkey R&D Center within the scope of the ongoing cooperation project coded 071813 among Gazi University, Huawei and Medskor.

</p>
</details>

<details><summary><b>Improving usual Naive Bayes classifier performances with Neural Naive Bayes based models</b>
<a href="https://arxiv.org/abs/2111.07307">arxiv:2111.07307</a>
&#x1F4C8; 2 <br>
<p>Elie Azeraf, Emmanuel Monfrini, Wojciech Pieczynski</p></summary>
<p>

**Abstract:** Naive Bayes is a popular probabilistic model appreciated for its simplicity and interpretability. However, the usual form of the related classifier suffers from two major problems. First, as caring about the observations' law, it cannot consider complex features. Moreover, it considers the conditional independence of the observations given the hidden variable. This paper introduces the original Neural Naive Bayes, modeling the parameters of the classifier induced from the Naive Bayes with neural network functions. This allows to correct the first problem. We also introduce new Neural Pooled Markov Chain models, alleviating the independence condition. We empirically study the benefits of these models for Sentiment Analysis, dividing the error rate of the usual classifier by 4.5 on the IMDB dataset with the FastText embedding.

</p>
</details>

<details><summary><b>Energy Efficient Learning with Low Resolution Stochastic Domain Wall Synapse Based Deep Neural Networks</b>
<a href="https://arxiv.org/abs/2111.07284">arxiv:2111.07284</a>
&#x1F4C8; 2 <br>
<p>Walid A. Misba, Mark Lozano, Damien Querlioz, Jayasimha Atulasimha</p></summary>
<p>

**Abstract:** We demonstrate that extremely low resolution quantized (nominally 5-state) synapses with large stochastic variations in Domain Wall (DW) position can be both energy efficient and achieve reasonably high testing accuracies compared to Deep Neural Networks (DNNs) of similar sizes using floating precision synaptic weights. Specifically, voltage controlled DW devices demonstrate stochastic behavior as modeled rigorously with micromagnetic simulations and can only encode limited states; however, they can be extremely energy efficient during both training and inference. We show that by implementing suitable modifications to the learning algorithms, we can address the stochastic behavior as well as mitigate the effect of their low-resolution to achieve high testing accuracies. In this study, we propose both in-situ and ex-situ training algorithms, based on modification of the algorithm proposed by Hubara et al. [1] which works well with quantization of synaptic weights. We train several 5-layer DNNs on MNIST dataset using 2-, 3- and 5-state DW device as synapse. For in-situ training, a separate high precision memory unit is adopted to preserve and accumulate the weight gradients, which are then quantized to program the low precision DW devices. Moreover, a sizeable noise tolerance margin is used during the training to address the intrinsic programming noise. For ex-situ training, a precursor DNN is first trained based on the characterized DW device model and a noise tolerance margin, which is similar to the in-situ training. Remarkably, for in-situ inference the energy dissipation to program the devices is only 13 pJ per inference given that the training is performed over the entire MNIST dataset for 10 epochs.

</p>
</details>

<details><summary><b>Deep Joint Demosaicing and High Dynamic Range Imaging within a Single Shot</b>
<a href="https://arxiv.org/abs/2111.07281">arxiv:2111.07281</a>
&#x1F4C8; 2 <br>
<p>Yilun Xu, Ziyang Liu, Xingming Wu, Weihai Chen, Changyun Wen, Zhengguo Li</p></summary>
<p>

**Abstract:** Spatially varying exposure (SVE) is a promising choice for high-dynamic-range (HDR) imaging (HDRI). The SVE-based HDRI, which is called single-shot HDRI, is an efficient solution to avoid ghosting artifacts. However, it is very challenging to restore a full-resolution HDR image from a real-world image with SVE because: a) only one-third of pixels with varying exposures are captured by camera in a Bayer pattern, b) some of the captured pixels are over- and under-exposed. For the former challenge, a spatially varying convolution (SVC) is designed to process the Bayer images carried with varying exposures. For the latter one, an exposure-guidance method is proposed against the interference from over- and under-exposed pixels. Finally, a joint demosaicing and HDRI deep learning framework is formalized to include the two novel components and to realize an end-to-end single-shot HDRI. Experiments indicate that the proposed end-to-end framework avoids the problem of cumulative errors and surpasses the related state-of-the-art methods.

</p>
</details>

<details><summary><b>CDM: Combining Extraction and Generation for Definition Modeling</b>
<a href="https://arxiv.org/abs/2111.07267">arxiv:2111.07267</a>
&#x1F4C8; 2 <br>
<p>Jie Huang, Hanyin Shao, Kevin Chen-Chuan Chang</p></summary>
<p>

**Abstract:** Definitions are essential for term understanding. Recently, there is an increasing interest in extracting and generating definitions of terms automatically. However, existing approaches for this task are either extractive or abstractive - definitions are either extracted from a corpus or generated by a language generation model. In this paper, we propose to combine extraction and generation for definition modeling: first extract self- and correlative definitional information of target terms from the Web and then generate the final definitions by incorporating the extracted definitional information. Experiments demonstrate our framework can generate high-quality definitions for technical terms and outperform state-of-the-art models for definition modeling significantly.

</p>
</details>

<details><summary><b>BioLeaF: A Bio-plausible Learning Framework for Training of Spiking Neural Networks</b>
<a href="https://arxiv.org/abs/2111.13188">arxiv:2111.13188</a>
&#x1F4C8; 1 <br>
<p>Yukun Yang, Peng Li</p></summary>
<p>

**Abstract:** Our brain consists of biological neurons encoding information through accurate spike timing, yet both the architecture and learning rules of our brain remain largely unknown. Comparing to the recent development of backpropagation-based (BP-based) methods that are able to train spiking neural networks (SNNs) with high accuracy, biologically plausible methods are still in their infancy. In this work, we wish to answer the question of whether it is possible to attain comparable accuracy of SNNs trained by BP-based rules with bio-plausible mechanisms. We propose a new bio-plausible learning framework, consisting of two components: a new architecture, and its supporting learning rules. With two types of cells and four types of synaptic connections, the proposed local microcircuit architecture can compute and propagate error signals through local feedback connections and support training of multi-layers SNNs with a globally defined spiking error function. Under our microcircuit architecture, we employ the Spike-Timing-Dependent-Plasticity (STDP) rule operating in local compartments to update synaptic weights and achieve supervised learning in a biologically plausible manner. Finally, We interpret the proposed framework from an optimization point of view and show the equivalence between it and the BP-based rules under a special circumstance. Our experiments show that the proposed framework demonstrates learning accuracy comparable to BP-based rules and may provide new insights on how learning is orchestrated in biological systems.

</p>
</details>

<details><summary><b>Interpretability Aware Model Training to Improve Robustness against Out-of-Distribution Magnetic Resonance Images in Alzheimer's Disease Classification</b>
<a href="https://arxiv.org/abs/2111.08701">arxiv:2111.08701</a>
&#x1F4C8; 1 <br>
<p>Merel Kuijs, Catherine R. Jutzeler, Bastian Rieck, Sarah C. Br√ºningk</p></summary>
<p>

**Abstract:** Owing to its pristine soft-tissue contrast and high resolution, structural magnetic resonance imaging (MRI) is widely applied in neurology, making it a valuable data source for image-based machine learning (ML) and deep learning applications. The physical nature of MRI acquisition and reconstruction, however, causes variations in image intensity, resolution, and signal-to-noise ratio. Since ML models are sensitive to such variations, performance on out-of-distribution data, which is inherent to the setting of a deployed healthcare ML application, typically drops below acceptable levels. We propose an interpretability aware adversarial training regime to improve robustness against out-of-distribution samples originating from different MRI hardware. The approach is applied to 1.5T and 3T MRIs obtained from the Alzheimer's Disease Neuroimaging Initiative database. We present preliminary results showing promising performance on out-of-distribution samples.

</p>
</details>

<details><summary><b>Deep-Learning Inversion Method for the Interpretation of Noisy Logging-While-Drilling Resistivity Measurements</b>
<a href="https://arxiv.org/abs/2111.07490">arxiv:2111.07490</a>
&#x1F4C8; 1 <br>
<p>Kyubo Noh, David Pardo, Carlos Torres-Verdin</p></summary>
<p>

**Abstract:** Deep Learning (DL) inversion is a promising method for real time interpretation of logging while drilling (LWD) resistivity measurements for well navigation applications. In this context, measurement noise may significantly affect inversion results. Existing publications examining the effects of measurement noise on DL inversion results are scarce. We develop a method to generate training data sets and construct DL architectures that enhance the robustness of DL inversion methods in the presence of noisy LWD resistivity measurements. We use two synthetic resistivity models to test three approaches that explicitly consider the presence of noise: (1) adding noise to the measurements in the training set, (2) augmenting the training set by replicating it and adding varying noise realizations, and (3) adding a noise layer in the DL architecture. Numerical results confirm that the three approaches produce a denoising effect, yielding better inversion results in both predicted earth model and measurements compared not only to the basic DL inversion but also to traditional gradient based inversion results. A combination of the second and third approaches delivers the best results. The proposed methods can be readily generalized to multi dimensional DL inversion.

</p>
</details>

<details><summary><b>Physics in the Machine: Integrating Physical Knowledge in Autonomous Phase-Mapping</b>
<a href="https://arxiv.org/abs/2111.07478">arxiv:2111.07478</a>
&#x1F4C8; 1 <br>
<p>A. Gilad Kusne, Austin McDannald, Brian DeCost, Corey Oses, Cormac Toher, Stefano Curtarolo, Apurva Mehta, Ichiro Takeuchi</p></summary>
<p>

**Abstract:** Application of artificial intelligence (AI), and more specifically machine learning, to the physical sciences has expanded significantly over the past decades. In particular, science-informed AI or scientific AI has grown from a focus on data analysis to now controlling experiment design, simulation, execution and analysis in closed-loop autonomous systems. The CAMEO (closed-loop autonomous materials exploration and optimization) algorithm employs scientific AI to address two tasks: learning a material system's composition-structure relationship and identifying materials compositions with optimal functional properties. By integrating these, accelerated materials screening across compositional phase diagrams was demonstrated, resulting in the discovery of a best-in-class phase change memory material. Key to this success is the ability to guide subsequent measurements to maximize knowledge of the composition-structure relationship, or phase map. In this work we investigate the benefits of incorporating varying levels of prior physical knowledge into CAMEO's autonomous phase-mapping. This includes the use of ab-initio phase boundary data from the AFLOW repositories, which has been shown to optimize CAMEO's search when used as a prior.

</p>
</details>

<details><summary><b>Neural Capacity Estimators: How Reliable Are They?</b>
<a href="https://arxiv.org/abs/2111.07401">arxiv:2111.07401</a>
&#x1F4C8; 1 <br>
<p>Farhad Mirkarimi, Stefano Rini, Nariman Farsad</p></summary>
<p>

**Abstract:** Recently, several methods have been proposed for estimating the mutual information from sample data using deep neural networks and without the knowing closed form distribution of the data. This class of estimators is referred to as neural mutual information estimators. Although very promising, such techniques have yet to be rigorously bench-marked so as to establish their efficacy, ease of implementation, and stability for capacity estimation which is joint maximization frame-work. In this paper, we compare the different techniques proposed in the literature for estimating capacity and provide a practitioner perspective on their effectiveness. In particular, we study the performance of mutual information neural estimator (MINE), smoothed mutual information lower-bound estimator (SMILE), and directed information neural estimator (DINE) and provide insights on InfoNCE. We evaluated these algorithms in terms of their ability to learn the input distributions that are capacity approaching for the AWGN channel, the optical intensity channel, and peak power-constrained AWGN channel. For both scenarios, we provide insightful comments on various aspects of the training process, such as stability, sensitivity to initialization.

</p>
</details>

<details><summary><b>Edge-Native Intelligence for 6G Communications Driven by Federated Learning: A Survey of Trends and Challenges</b>
<a href="https://arxiv.org/abs/2111.07392">arxiv:2111.07392</a>
&#x1F4C8; 1 <br>
<p>Mohammad Al-Quraan, Lina Mohjazi, Lina Bariah, Anthony Centeno, Ahmed Zoha, Sami Muhaidat, M√©rouane Debbah, Muhammad Ali Imran</p></summary>
<p>

**Abstract:** The unprecedented surge of data volume in wireless networks empowered with artificial intelligence (AI) opens up new horizons for providing ubiquitous data-driven intelligent services. Traditional cloud-centric machine learning (ML)-based services are implemented by collecting datasets and training models centrally. However, this conventional training technique encompasses two challenges: (i) high communication and energy cost due to increased data communication, (ii) threatened data privacy by allowing untrusted parties to utilise this information. Recently, in light of these limitations, a new emerging technique, coined as federated learning (FL), arose to bring ML to the edge of wireless networks. FL can extract the benefits of data silos by training a global model in a distributed manner, orchestrated by the FL server. FL exploits both decentralised datasets and computing resources of participating clients to develop a generalised ML model without compromising data privacy. In this article, we introduce a comprehensive survey of the fundamentals and enabling technologies of FL. Moreover, an extensive study is presented detailing various applications of FL in wireless networks and highlighting their challenges and limitations. The efficacy of FL is further explored with emerging prospective beyond fifth generation (B5G) and sixth generation (6G) communication systems. The purpose of this survey is to provide an overview of the state-of-the-art of FL applications in key wireless technologies that will serve as a foundation to establish a firm understanding of the topic. Lastly, we offer a road forward for future research directions.

</p>
</details>

<details><summary><b>A Study on the Efficient Product Search Service for the Damaged Image Information</b>
<a href="https://arxiv.org/abs/2111.07346">arxiv:2111.07346</a>
&#x1F4C8; 1 <br>
<p>Yonghyun Kim</p></summary>
<p>

**Abstract:** With the development of Information and Communication Technologies and the dissemination of smartphones, especially now that image search is possible through the internet, e-commerce markets are more activating purchasing services for a wide variety of products. However, it often happens that the image of the desired product is impaired and that the search engine does not recognize it properly. The idea of this study is to help search for products through image restoration using an image pre-processing and image inpainting algorithm for damaged images. It helps users easily purchase the items they want by providing a more accurate image search system. Besides, the system has the advantage of efficiently showing information by category, so that enables efficient sales of registered information.

</p>
</details>

<details><summary><b>$p$-Laplacian Based Graph Neural Networks</b>
<a href="https://arxiv.org/abs/2111.07337">arxiv:2111.07337</a>
&#x1F4C8; 1 <br>
<p>Guoji Fu, Peilin Zhao, Yatao Bian</p></summary>
<p>

**Abstract:** Graph neural networks (GNNs) have demonstrated superior performance for semi-supervised node classification on graphs, as a result of their ability to exploit node features and topological information simultaneously. However, most GNNs implicitly assume that the labels of nodes and their neighbors in a graph are the same or consistent, which does not hold in heterophilic graphs, where the labels of linked nodes are likely to differ. Hence, when the topology is non-informative for label prediction, ordinary GNNs may work significantly worse than simply applying multi-layer perceptrons (MLPs) on each node. To tackle the above problem, we propose a new $p$-Laplacian based GNN model, termed as $^p$GNN, whose message passing mechanism is derived from a discrete regularization framework and could be theoretically explained as an approximation of a polynomial graph filter defined on the spectral domain of $p$-Laplacians. The spectral analysis shows that the new message passing mechanism works simultaneously as low-pass and high-pass filters, thus making $^p$GNNs are effective on both homophilic and heterophilic graphs. Empirical studies on real-world and synthetic datasets validate our findings and demonstrate that $^p$GNNs significantly outperform several state-of-the-art GNN architectures on heterophilic benchmarks while achieving competitive performance on homophilic benchmarks. Moreover, $^p$GNNs can adaptively learn aggregation weights and are robust to noisy edges.

</p>
</details>

<details><summary><b>What Should We Optimize in Participatory Budgeting? An Experimental Study</b>
<a href="https://arxiv.org/abs/2111.07308">arxiv:2111.07308</a>
&#x1F4C8; 1 <br>
<p>Ariel Rosenfeld, Nimrod Talmon</p></summary>
<p>

**Abstract:** Participatory Budgeting (PB) is a process in which voters decide how to allocate a common budget; most commonly it is done by ordinary people -- in particular, residents of some municipality -- to decide on a fraction of the municipal budget. From a social choice perspective, existing research on PB focuses almost exclusively on designing computationally-efficient aggregation methods that satisfy certain axiomatic properties deemed "desirable" by the research community. Our work complements this line of research through a user study (N = 215) involving several experiments aimed at identifying what potential voters (i.e., non-experts) deem fair or desirable in simple PB settings. Our results show that some modern PB aggregation techniques greatly differ from users' expectations, while other, more standard approaches, provide more aligned results. We also identify a few possible discrepancies between what non-experts consider \say{desirable} and how they perceive the notion of "fairness" in the PB context. Taken jointly, our results can be used to help the research community identify appropriate PB aggregation methods to use in practice.

</p>
</details>

<details><summary><b>Moment Transform-Based Compressive Sensing in Image Processing</b>
<a href="https://arxiv.org/abs/2111.07254">arxiv:2111.07254</a>
&#x1F4C8; 1 <br>
<p>T. Kalampokas, G. A. Papakostas</p></summary>
<p>

**Abstract:** Over the last decades, images have become an important source of information in many domains, thus their high quality has become necessary to acquire better information. One of the important issues that arise is image denoising, which means recovering a signal from inaccurately and/or partially measured samples. This interpretation is highly correlated to the compressive sensing theory, which is a revolutionary technology and implies that if a signal is sparse then the original signal can be obtained from a few measured values, which are much less, than the ones suggested by other used theories like Shannon's sampling theories. A strong factor in Compressive Sensing (CS) theory to achieve the sparsest solution and the noise removal from the corrupted image is the selection of the basis dictionary. In this paper, Discrete Cosine Transform (DCT) and moment transform (Tchebichef, Krawtchouk) are compared in order to achieve image denoising of Gaussian additive white noise based on compressive sensing and sparse approximation theory. The experimental results revealed that the basis dictionaries constructed by the moment transform perform competitively to the traditional DCT. The latter transform shows a higher PSNR of 30.82 dB and the same 0.91 SSIM value as the Tchebichef transform. Moreover, from the sparsity point of view, Krawtchouk moments provide approximately 20-30% more sparse results than DCT.

</p>
</details>

<details><summary><b>Explicit Explore, Exploit, or Escape ($E^4$): near-optimal safety-constrained reinforcement learning in polynomial time</b>
<a href="https://arxiv.org/abs/2111.07395">arxiv:2111.07395</a>
&#x1F4C8; 0 <br>
<p>David M. Bossens, Nicholas Bishop</p></summary>
<p>

**Abstract:** In reinforcement learning (RL), an agent must explore an initially unknown environment in order to learn a desired behaviour. When RL agents are deployed in real world environments, safety is of primary concern. Constrained Markov decision processes (CMDPs) can provide long-term safety constraints; however, the agent may violate the constraints in an effort to explore its environment. This paper proposes a model-based RL algorithm called Explicit Explore, Exploit, or Escape ($E^{4}$), which extends the Explicit Explore or Exploit ($E^{3}$) algorithm to a robust CMDP setting. $E^4$ explicitly separates exploitation, exploration, and escape CMDPs, allowing targeted policies for policy improvement across known states, discovery of unknown states, as well as safe return to known states. $E^4$ robustly optimises these policies on the worst-case CMDP from a set of CMDP models consistent with the empirical observations of the deployment environment. Theoretical results show that $E^4$ finds a near-optimal constraint-satisfying policy in polynomial time whilst satisfying safety constraints throughout the learning process. We discuss robust-constrained offline optimisation algorithms as well as how to incorporate uncertainty in transition dynamics of unknown states based on empirical inference and prior knowledge.

</p>
</details>

<details><summary><b>TMS-Crossbars with Tactile Sensing</b>
<a href="https://arxiv.org/abs/2111.07280">arxiv:2111.07280</a>
&#x1F4C8; 0 <br>
<p>R. Chithra, A. R. Aswani, A. P. James</p></summary>
<p>

**Abstract:** The first stage of tactile sensing is data acquisition using tactile sensors and the sensed data is transmitted to the central unit for neuromorphic computing. The memristive crossbars were proposed to use as synapses in neuromorphic computing but device intelligence at the sensor level are not investigated in literature. We propose the concept of Transistor Memristor Sensor (TMS)-crossbar by including sensor to memristor crossbar array configuration in the input layer of the neural network architecture. 2 possible cell configurations of TMS crossbar arrays: 1 Transistor 1 Memristor 1 Sensor (1T1M1S) and 2 Transistor 1 Memristor 1 Sensor (2T1M1S) are presented. We verified the proposed TMS-crossbar in the practical design of analog neural networks based Braille character recognition system. The proposed design is verified with SPICE simulations using circuit equivalent of FLX-A501 force sensor, TiO$_2$ memristors and low power 22nm high-k CMOS transistors. The proposed analog neuromorphic computing system presents a scalable solution and is possible to encode 125 symbols with good accuracy in comparison with other Braille character recognition systems in the literature. The benefits of analog implementation of the TMS crossbar arrays is substantiated with results of accuracy, area and power requirements in comparison with the binary counterparts.

</p>
</details>


[Next Page](2021/2021-11/2021-11-13.md)
