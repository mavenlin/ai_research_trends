Prev: [2022.08.30]({{ '/2022/08/30/2022.08.30.html' | relative_url }})  Next: [2022.09.01]({{ '/2022/09/01/2022.09.01.html' | relative_url }})
{% raw %}
## Summary for 2022-08-31, created on 2022-09-04


<details><summary><b>Ant Colony Optimization for Mining Gradual Patterns</b>
<a href="https://arxiv.org/abs/2208.14795">arxiv:2208.14795</a>
&#x1F4C8; 9 <br>
<p>Dickson Odhiambo Owuor, Thomas Runkler, Anne Laurent, Joseph Orero, Edmond Menya</p></summary>
<p>

**Abstract:** Gradual pattern extraction is a field in (KDD) Knowledge Discovery in Databases that maps correlations between attributes of a data set as gradual dependencies. A gradual dependency may take a form of "the more Attribute K , the less Attribute L". In this paper, we propose an ant colony optimization technique that uses a probabilistic approach to learn and extract frequent gradual patterns. Through computational experiments on real-world data sets, we compared the performance of our ant-based algorithm to an existing gradual item set extraction algorithm and we found out that our algorithm outperforms the later especially when dealing with large data sets.

</p>
</details>

<details><summary><b>Cluster-based Sampling in Hindsight Experience Replay for Robot Control</b>
<a href="https://arxiv.org/abs/2208.14741">arxiv:2208.14741</a>
&#x1F4C8; 8 <br>
<p>Taeyoung Kim, Dongsoo Har</p></summary>
<p>

**Abstract:** In multi-goal reinforcement learning in an environment, agents learn policies to achieve multiple goals by using experiences gained from interactions with the environment. With a sparse binary reward, training agents is particularly challenging, due to a lack of successful experiences. To solve this problem, hindsight experience replay (HER) generates successful experiences from unsuccessful experiences. However, generating successful experiences without consideration of the property of achieved goals is less efficient. In this paper, a novel cluster-based sampling strategy exploiting the property of achieved goals is proposed. The proposed sampling strategy groups episodes with different achieved goals and samples experiences in the manner of HER. For the grouping, K-means clustering algorithm is used. The centroids of the clusters are obtained from the distribution of failed goals defined as the original goals not achieved. The proposed method is validated by experiments with three robotic control tasks of the OpenAI Gym. The results of experiments demonstrate that the proposed method significantly reduces the number of epochs required for convergence in two of the three tasks and marginally increases the success rates in the remaining one. It is also shown that the proposed method can be combined with other sampling strategies for HER.

</p>
</details>

<details><summary><b>NeurIPS'22 Cross-Domain MetaDL competition: Design and baseline results</b>
<a href="https://arxiv.org/abs/2208.14686">arxiv:2208.14686</a>
&#x1F4C8; 7 <br>
<p>Dustin Carrión-Ojeda, Hong Chen, Adrian El Baz, Sergio Escalera, Chaoyu Guan, Isabelle Guyon, Ihsan Ullah, Xin Wang, Wenwu Zhu</p></summary>
<p>

**Abstract:** We present the design and baseline results for a new challenge in the ChaLearn meta-learning series, accepted at NeurIPS'22, focusing on "cross-domain" meta-learning. Meta-learning aims to leverage experience gained from previous tasks to solve new tasks efficiently (i.e., with better performance, little training data, and/or modest computational resources). While previous challenges in the series focused on within-domain few-shot learning problems, with the aim of learning efficiently N-way k-shot tasks (i.e., N class classification problems with k training examples), this competition challenges the participants to solve "any-way" and "any-shot" problems drawn from various domains (healthcare, ecology, biology, manufacturing, and others), chosen for their humanitarian and societal impact. To that end, we created Meta-Album, a meta-dataset of 40 image classification datasets from 10 domains, from which we carve out tasks with any number of "ways" (within the range 2-20) and any number of "shots" (within the range 1-20). The competition is with code submission, fully blind-tested on the CodaLab challenge platform. The code of the winners will be open-sourced, enabling the deployment of automated machine learning solutions for few-shot image classification across several domains.

</p>
</details>

<details><summary><b>Federated Learning with Label Distribution Skew via Logits Calibration</b>
<a href="https://arxiv.org/abs/2209.00189">arxiv:2209.00189</a>
&#x1F4C8; 6 <br>
<p>Jie Zhang, Zhiqi Li, Bo Li, Jianghe Xu, Shuang Wu, Shouhong Ding, Chao Wu</p></summary>
<p>

**Abstract:** Traditional federated optimization methods perform poorly with heterogeneous data (ie, accuracy reduction), especially for highly skewed data. In this paper, we investigate the label distribution skew in FL, where the distribution of labels varies across clients. First, we investigate the label distribution skew from a statistical view. We demonstrate both theoretically and empirically that previous methods based on softmax cross-entropy are not suitable, which can result in local models heavily overfitting to minority classes and missing classes. Additionally, we theoretically introduce a deviation bound to measure the deviation of the gradient after local update. At last, we propose FedLC (\textbf {Fed} erated learning via\textbf {L} ogits\textbf {C} alibration), which calibrates the logits before softmax cross-entropy according to the probability of occurrence of each class. FedLC applies a fine-grained calibrated cross-entropy loss to local update by adding a pairwise label margin. Extensive experiments on federated datasets and real-world datasets demonstrate that FedLC leads to a more accurate global model and much improved performance. Furthermore, integrating other FL methods into our approach can further enhance the performance of the global model.

</p>
</details>

<details><summary><b>Style-Agnostic Reinforcement Learning</b>
<a href="https://arxiv.org/abs/2208.14863">arxiv:2208.14863</a>
&#x1F4C8; 6 <br>
<p>Juyong Lee, Seokjun Ahn, Jaesik Park</p></summary>
<p>

**Abstract:** We present a novel method of learning style-agnostic representation using both style transfer and adversarial learning in the reinforcement learning framework. The style, here, refers to task-irrelevant details such as the color of the background in the images, where generalizing the learned policy across environments with different styles is still a challenge. Focusing on learning style-agnostic representations, our method trains the actor with diverse image styles generated from an inherent adversarial style perturbation generator, which plays a min-max game between the actor and the generator, without demanding expert knowledge for data augmentation or additional class labels for adversarial training. We verify that our method achieves competitive or better performances than the state-of-the-art approaches on Procgen and Distracting Control Suite benchmarks, and further investigate the features extracted from our model, showing that the model better captures the invariants and is less distracted by the shifted style. The code is available at https://github.com/POSTECH-CVLab/style-agnostic-RL.

</p>
</details>

<details><summary><b>Let us Build Bridges: Understanding and Extending Diffusion Generative Models</b>
<a href="https://arxiv.org/abs/2208.14699">arxiv:2208.14699</a>
&#x1F4C8; 6 <br>
<p>Xingchao Liu, Lemeng Wu, Mao Ye, Qiang Liu</p></summary>
<p>

**Abstract:** Diffusion-based generative models have achieved promising results recently, but raise an array of open questions in terms of conceptual understanding, theoretical analysis, algorithm improvement and extensions to discrete, structured, non-Euclidean domains. This work tries to re-exam the overall framework, in order to gain better theoretical understandings and develop algorithmic extensions for data from arbitrary domains. By viewing diffusion models as latent variable models with unobserved diffusion trajectories and applying maximum likelihood estimation (MLE) with latent trajectories imputed from an auxiliary distribution, we show that both the model construction and the imputation of latent trajectories amount to constructing diffusion bridge processes that achieve deterministic values and constraints at end point, for which we provide a systematic study and a suit of tools. Leveraging our framework, we present 1) a first theoretical error analysis for learning diffusion generation models, and 2) a simple and unified approach to learning on data from different discrete and constrained domains. Experiments show that our methods perform superbly on generating images, semantic segments and 3D point clouds.

</p>
</details>

<details><summary><b>Computational design of antimicrobial active surfaces via automated Bayesian optimization</b>
<a href="https://arxiv.org/abs/2209.00055">arxiv:2209.00055</a>
&#x1F4C8; 5 <br>
<p>Hanfeng Zhai, Jingjie Yeo</p></summary>
<p>

**Abstract:** Biofilms pose significant problems for engineers in diverse fields, such as marine science, bioenergy, and biomedicine, where effective biofilm control is a long-term goal. The adhesion and surface mechanics of biofilms play crucial roles in generating and removing biofilm. Designing customized nano-surfaces with different surface topologies can alter the adhesive properties to remove biofilms more easily and greatly improve long-term biofilm control. To rapidly design such topologies, we employ individual-based modeling and Bayesian optimization to automate the design process and generate different active surfaces for effective biofilm removal. Our framework successfully generated ideal nano-surfaces for biofilm removal through applied shear and vibration. Densely distributed short pillar topography is the optimal geometry to prevent biofilm formation. Under fluidic shearing, the optimal topography is to sparsely distribute tall, slim, pillar-like structures. When subjected to either vertical or lateral vibrations, thick trapezoidal cones are found to be optimal. Optimizing the vibrational loading indicates a small vibration magnitude with relatively low frequencies is more efficient in removing biofilm. Our results provide insights into various engineering fields that require surface-mediated biofilm control. Our framework can also be applied to more general materials design and optimization.

</p>
</details>

<details><summary><b>LANIT: Language-Driven Image-to-Image Translation for Unlabeled Data</b>
<a href="https://arxiv.org/abs/2208.14889">arxiv:2208.14889</a>
&#x1F4C8; 5 <br>
<p>Jihye Park, Soohyun Kim, Sunwoo Kim, Jaejun Yoo, Youngjung Uh, Seungryong Kim</p></summary>
<p>

**Abstract:** Existing techniques for image-to-image translation commonly have suffered from two critical problems: heavy reliance on per-sample domain annotation and/or inability of handling multiple attributes per image. Recent methods adopt clustering approaches to easily provide per-sample annotations in an unsupervised manner. However, they cannot account for the real-world setting; one sample may have multiple attributes. In addition, the semantics of the clusters are not easily coupled to human understanding. To overcome these, we present a LANguage-driven Image-to-image Translation model, dubbed LANIT. We leverage easy-to-obtain candidate domain annotations given in texts for a dataset and jointly optimize them during training. The target style is specified by aggregating multi-domain style vectors according to the multi-hot domain assignments. As the initial candidate domain texts might be inaccurate, we set the candidate domain texts to be learnable and jointly fine-tune them during training. Furthermore, we introduce a slack domain to cover samples that are not covered by the candidate domains. Experiments on several standard benchmarks demonstrate that LANIT achieves comparable or superior performance to the existing model.

</p>
</details>

<details><summary><b>Hierarchical Local-Global Transformer for Temporal Sentence Grounding</b>
<a href="https://arxiv.org/abs/2208.14882">arxiv:2208.14882</a>
&#x1F4C8; 5 <br>
<p>Xiang Fang, Daizong Liu, Pan Zhou, Zichuan Xu, Ruixuan Li</p></summary>
<p>

**Abstract:** This paper studies the multimedia problem of temporal sentence grounding (TSG), which aims to accurately determine the specific video segment in an untrimmed video according to a given sentence query. Traditional TSG methods mainly follow the top-down or bottom-up framework and are not end-to-end. They severely rely on time-consuming post-processing to refine the grounding results. Recently, some transformer-based approaches are proposed to efficiently and effectively model the fine-grained semantic alignment between video and query. Although these methods achieve significant performance to some extent, they equally take frames of the video and words of the query as transformer input for correlating, failing to capture their different levels of granularity with distinct semantics. To address this issue, in this paper, we propose a novel Hierarchical Local-Global Transformer (HLGT) to leverage this hierarchy information and model the interactions between different levels of granularity and different modalities for learning more fine-grained multi-modal representations. Specifically, we first split the video and query into individual clips and phrases to learn their local context (adjacent dependency) and global correlation (long-range dependency) via a temporal transformer. Then, a global-local transformer is introduced to learn the interactions between the local-level and global-level semantics for better multi-modal reasoning. Besides, we develop a new cross-modal cycle-consistency loss to enforce interaction between two modalities and encourage the semantic alignment between them. Finally, we design a brand-new cross-modal parallel transformer decoder to integrate the encoded visual and textual features for final grounding. Extensive experiments on three challenging datasets show that our proposed HLGT achieves a new state-of-the-art performance.

</p>
</details>

<details><summary><b>Accelerating Deep Unrolling Networks via Dimensionality Reduction</b>
<a href="https://arxiv.org/abs/2208.14784">arxiv:2208.14784</a>
&#x1F4C8; 5 <br>
<p>Junqi Tang, Subhadip Mukherjee, Carola-Bibiane Schönlieb</p></summary>
<p>

**Abstract:** In this work we propose a new paradigm for designing efficient deep unrolling networks using dimensionality reduction schemes, including minibatch gradient approximation and operator sketching. The deep unrolling networks are currently the state-of-the-art solutions for imaging inverse problems. However, for high-dimensional imaging tasks, especially X-ray CT and MRI imaging, the deep unrolling schemes typically become inefficient both in terms of memory and computation, due to the need of computing multiple times the high-dimensional forward and adjoint operators. Recently researchers have found that such limitations can be partially addressed by unrolling the stochastic gradient descent (SGD), inspired by the success of stochastic first-order optimization. In this work, we explore further this direction and propose first a more expressive and practical stochastic primal-dual unrolling, based on the state-of-the-art Learned Primal-Dual (LPD) network, and also a further acceleration upon stochastic primal-dual unrolling, using sketching techniques to approximate products in the high-dimensional image space. The operator sketching can be jointly applied with stochastic unrolling for the best acceleration and compression performance. Our numerical experiments on X-ray CT image reconstruction demonstrate the remarkable effectiveness of our accelerated unrolling schemes.

</p>
</details>

<details><summary><b>Generating Intermediate Steps for NLI with Next-Step Supervision</b>
<a href="https://arxiv.org/abs/2208.14641">arxiv:2208.14641</a>
&#x1F4C8; 5 <br>
<p>Deepanway Ghosal, Somak Aditya, Monojit Choudhury</p></summary>
<p>

**Abstract:** The Natural Language Inference (NLI) task often requires reasoning over multiple steps to reach the conclusion. While the necessity of generating such intermediate steps (instead of a summary explanation) has gained popular support, it is unclear how to generate such steps without complete end-to-end supervision and how such generated steps can be further utilized. In this work, we train a sequence-to-sequence model to generate only the next step given an NLI premise and hypothesis pair (and previous steps); then enhance it with external knowledge and symbolic search to generate intermediate steps with only next-step supervision. We show the correctness of such generated steps through automated and human verification. Furthermore, we show that such generated steps can help improve end-to-end NLI task performance using simple data augmentation strategies, across multiple public NLI datasets.

</p>
</details>

<details><summary><b>Hermes: Accelerating Long-Latency Load Requests via Perceptron-Based Off-Chip Load Prediction</b>
<a href="https://arxiv.org/abs/2209.00188">arxiv:2209.00188</a>
&#x1F4C8; 4 <br>
<p>Rahul Bera, Konstantinos Kanellopoulos, Shankar Balachandran, David Novo, Ataberk Olgun, Mohammad Sadrosadati, Onur Mutlu</p></summary>
<p>

**Abstract:** Long-latency load requests continue to limit the performance of high-performance processors. To increase the latency tolerance of a processor, architects have primarily relied on two key techniques: sophisticated data prefetchers and large on-chip caches. In this work, we show that: 1) even a sophisticated state-of-the-art prefetcher can only predict half of the off-chip load requests on average across a wide range of workloads, and 2) due to the increasing size and complexity of on-chip caches, a large fraction of the latency of an off-chip load request is spent accessing the on-chip cache hierarchy. The goal of this work is to accelerate off-chip load requests by removing the on-chip cache access latency from their critical path. To this end, we propose a new technique called Hermes, whose key idea is to: 1) accurately predict which load requests might go off-chip, and 2) speculatively fetch the data required by the predicted off-chip loads directly from the main memory, while also concurrently accessing the cache hierarchy for such loads. To enable Hermes, we develop a new lightweight, perceptron-based off-chip load prediction technique that learns to identify off-chip load requests using multiple program features (e.g., sequence of program counters). For every load request, the predictor observes a set of program features to predict whether or not the load would go off-chip. If the load is predicted to go off-chip, Hermes issues a speculative request directly to the memory controller once the load's physical address is generated. If the prediction is correct, the load eventually misses the cache hierarchy and waits for the ongoing speculative request to finish, thus hiding the on-chip cache hierarchy access latency from the critical path of the off-chip load. Our evaluation shows that Hermes significantly improves performance of a state-of-the-art baseline. We open-source Hermes.

</p>
</details>

<details><summary><b>Evaluating generative audio systems and their metrics</b>
<a href="https://arxiv.org/abs/2209.00130">arxiv:2209.00130</a>
&#x1F4C8; 4 <br>
<p>Ashvala Vinay, Alexander Lerch</p></summary>
<p>

**Abstract:** Recent years have seen considerable advances in audio synthesis with deep generative models. However, the state-of-the-art is very difficult to quantify; different studies often use different evaluation methodologies and different metrics when reporting results, making a direct comparison to other systems difficult if not impossible. Furthermore, the perceptual relevance and meaning of the reported metrics in most cases unknown, prohibiting any conclusive insights with respect to practical usability and audio quality. This paper presents a study that investigates state-of-the-art approaches side-by-side with (i) a set of previously proposed objective metrics for audio reconstruction, and with (ii) a listening study. The results indicate that currently used objective metrics are insufficient to describe the perceptual quality of current systems.

</p>
</details>

<details><summary><b>Inverse Propensity Score based offline estimator for deterministic ranking lists using position bias</b>
<a href="https://arxiv.org/abs/2208.14980">arxiv:2208.14980</a>
&#x1F4C8; 4 <br>
<p>Nick Wood, Sumit Sidana</p></summary>
<p>

**Abstract:** In this work, we present a novel way of computing IPS using a position-bias model for deterministic logging policies. This technique significantly widens the policies on which OPE can be used. We validate this technique using two different experiments on industry-scale data. The OPE results are clearly strongly correlated with the online results, with some constant bias. The estimator requires the examination model to be a reasonably accurate approximation of real user behaviour.

</p>
</details>

<details><summary><b>A Realism Metric for Generated LiDAR Point Clouds</b>
<a href="https://arxiv.org/abs/2208.14958">arxiv:2208.14958</a>
&#x1F4C8; 4 <br>
<p>Larissa T. Triess, Christoph B. Rist, David Peter, J. Marius Zöllner</p></summary>
<p>

**Abstract:** A considerable amount of research is concerned with the generation of realistic sensor data. LiDAR point clouds are generated by complex simulations or learned generative models. The generated data is usually exploited to enable or improve downstream perception algorithms. Two major questions arise from these procedures: First, how to evaluate the realism of the generated data? Second, does more realistic data also lead to better perception performance? This paper addresses both questions and presents a novel metric to quantify the realism of LiDAR point clouds. Relevant features are learned from real-world and synthetic point clouds by training on a proxy classification task. In a series of experiments, we demonstrate the application of our metric to determine the realism of generated LiDAR data and compare the realism estimation of our metric to the performance of a segmentation model. We confirm that our metric provides an indication for the downstream segmentation performance.

</p>
</details>

<details><summary><b>Cell-Free Latent Go-Explore</b>
<a href="https://arxiv.org/abs/2208.14928">arxiv:2208.14928</a>
&#x1F4C8; 4 <br>
<p>Quentin Gallouédec, Emmanuel Dellandréa</p></summary>
<p>

**Abstract:** In this paper, we introduce Latent Go-Explore (LGE), a simple and general approach based on the Go-Explore paradigm for exploration in reinforcement learning (RL). Go-Explore was initially introduced with a strong domain knowledge constraint for partitioning the state space into cells. However, in most real-world scenarios, drawing domain knowledge from raw observations is complex and tedious. If the cell partitioning is not informative enough, Go-Explore can completely fail to explore the environment. We argue that the Go-Explore approach can be generalized to any environment without domain knowledge and without cells by exploiting a learned latent representation. Thus, we show that LGE can be flexibly combined with any strategy for learning a latent representation. We show that LGE, although simpler than Go-Explore, is more robust and outperforms all state-of-the-art algorithms in terms of pure exploration on multiple hard-exploration environments. The LGE implementation is available as open-source at https://github.com/qgallouedec/lge.

</p>
</details>

<details><summary><b>Feature Alignment by Uncertainty and Self-Training for Source-Free Unsupervised Domain Adaptation</b>
<a href="https://arxiv.org/abs/2208.14888">arxiv:2208.14888</a>
&#x1F4C8; 4 <br>
<p>JoonHo Lee, Gyemin Lee</p></summary>
<p>

**Abstract:** Most unsupervised domain adaptation (UDA) methods assume that labeled source images are available during model adaptation. However, this assumption is often infeasible owing to confidentiality issues or memory constraints on mobile devices. To address these problems, we propose a simple yet effective source-free UDA method that uses only a pre-trained source model and unlabeled target images. Our method captures the aleatoric uncertainty by incorporating data augmentation and trains the feature generator with two consistency objectives. The feature generator is encouraged to learn consistent visual features away from the decision boundaries of the head classifier. Inspired by self-supervised learning, our method promotes inter-space alignment between the prediction space and the feature space while incorporating intra-space consistency within the feature space to reduce the domain gap between the source and target domains. We also consider epistemic uncertainty to boost the model adaptation performance. Extensive experiments on popular UDA benchmarks demonstrate that the performance of our approach is comparable or even superior to vanilla UDA methods without using source images or network modifications.

</p>
</details>

<details><summary><b>GRILLBot: An Assistant for Real-World Tasks with Neural Semantic Parsing and Graph-Based Representations</b>
<a href="https://arxiv.org/abs/2208.14884">arxiv:2208.14884</a>
&#x1F4C8; 4 <br>
<p>Carlos Gemmell, Iain Mackie, Paul Owoicho, Federico Rossetto, Sophie Fischer, Jeffrey Dalton</p></summary>
<p>

**Abstract:** GRILLBot is the winning system in the 2022 Alexa Prize TaskBot Challenge, moving towards the next generation of multimodal task assistants. It is a voice assistant to guide users through complex real-world tasks in the domains of cooking and home improvement. These are long-running and complex tasks that require flexible adjustment and adaptation. The demo highlights the core aspects, including a novel Neural Decision Parser for contextualized semantic parsing, a new "TaskGraph" state representation that supports conditional execution, knowledge-grounded chit-chat, and automatic enrichment of tasks with images and videos.

</p>
</details>

<details><summary><b>NestedFormer: Nested Modality-Aware Transformer for Brain Tumor Segmentation</b>
<a href="https://arxiv.org/abs/2208.14876">arxiv:2208.14876</a>
&#x1F4C8; 4 <br>
<p>Zhaohu Xing, Lequan Yu, Liang Wan, Tong Han, Lei Zhu</p></summary>
<p>

**Abstract:** Multi-modal MR imaging is routinely used in clinical practice to diagnose and investigate brain tumors by providing rich complementary information. Previous multi-modal MRI segmentation methods usually perform modal fusion by concatenating multi-modal MRIs at an early/middle stage of the network, which hardly explores non-linear dependencies between modalities. In this work, we propose a novel Nested Modality-Aware Transformer (NestedFormer) to explicitly explore the intra-modality and inter-modality relationships of multi-modal MRIs for brain tumor segmentation. Built on the transformer-based multi-encoder and single-decoder structure, we perform nested multi-modal fusion for high-level representations of different modalities and apply modality-sensitive gating (MSG) at lower scales for more effective skip connections. Specifically, the multi-modal fusion is conducted in our proposed Nested Modality-aware Feature Aggregation (NMaFA) module, which enhances long-term dependencies within individual modalities via a tri-orientated spatial-attention transformer, and further complements key contextual information among modalities via a cross-modality attention transformer. Extensive experiments on BraTS2020 benchmark and a private meningiomas segmentation (MeniSeg) dataset show that the NestedFormer clearly outperforms the state-of-the-arts. The code is available at https://github.com/920232796/NestedFormer.

</p>
</details>

<details><summary><b>Unifying Evaluation of Machine Learning Safety Monitors</b>
<a href="https://arxiv.org/abs/2208.14660">arxiv:2208.14660</a>
&#x1F4C8; 4 <br>
<p>Joris Guerin, Raul Sena Ferreira, Kevin Delmas, Jérémie Guiochet</p></summary>
<p>

**Abstract:** With the increasing use of Machine Learning (ML) in critical autonomous systems, runtime monitors have been developed to detect prediction errors and keep the system in a safe state during operations. Monitors have been proposed for different applications involving diverse perception tasks and ML models, and specific evaluation procedures and metrics are used for different contexts. This paper introduces three unified safety-oriented metrics, representing the safety benefits of the monitor (Safety Gain), the remaining safety gaps after using it (Residual Hazard), and its negative impact on the system's performance (Availability Cost). To compute these metrics, one requires to define two return functions, representing how a given ML prediction will impact expected future rewards and hazards. Three use-cases (classification, drone landing, and autonomous driving) are used to demonstrate how metrics from the literature can be expressed in terms of the proposed metrics. Experimental results on these examples show how different evaluation choices impact the perceived performance of a monitor. As our formalism requires us to formulate explicit safety assumptions, it allows us to ensure that the evaluation conducted matches the high-level system requirements.

</p>
</details>

<details><summary><b>An Empirical Study and Analysis of Learning Generalizable Manipulation Skill in the SAPIEN Simulator</b>
<a href="https://arxiv.org/abs/2208.14646">arxiv:2208.14646</a>
&#x1F4C8; 4 <br>
<p>Kun Liu, Huiyuan Fu, Zheng Zhang, Huanpu Yin</p></summary>
<p>

**Abstract:** This paper provides a brief overview of our submission to the no interaction track of SAPIEN ManiSkill Challenge 2021. Our approach follows an end-to-end pipeline which mainly consists of two steps: we first extract the point cloud features of multiple objects; then we adopt these features to predict the action score of the robot simulators through a deep and wide transformer-based network. More specially, %to give guidance for future work, to open up avenues for exploitation of learning manipulation skill, we present an empirical study that includes a bag of tricks and abortive attempts. Finally, our method achieves a promising ranking on the leaderboard. All code of our solution is available at https://github.com/liu666666/bigfish\_codes.

</p>
</details>

<details><summary><b>Physically-primed deep-neural-networks for generalized undersampled MRI reconstruction</b>
<a href="https://arxiv.org/abs/2209.00462">arxiv:2209.00462</a>
&#x1F4C8; 3 <br>
<p>Nitzan Avidan, Moti Freiman</p></summary>
<p>

**Abstract:** A plethora of deep-neural-networks (DNN) based methods were proposed over the past few years to address the challenging ill-posed inverse problem of MRI reconstruction from undersampled "k-space" (Fourier domain) data. However, instability against variations in the acquisition process and the anatomical distribution, indicates a poor generalization of the relevant physical models by the DNN architectures compared to their classical counterparts. The poor generalization effectively precludes DNN applicability for undersampled MRI reconstruction in the clinical setting. We improve the generalization capacity of DNN methods for undersampled MRI reconstruction by introducing a physically-primed DNN architecture and training approach. Our architecture encodes the undersampling mask in addition to the observed data in the model architecture and employs an appropriate training approach that uses data generated with various undersampling masks to encourage the model to generalize the undersampled MRI reconstruction problem. We demonstrated the added-value of our approach through extensive experimentation with the publicly available Fast-MRI dataset. Our physically-primed approach achieved an enhanced generalization capacity which resulted in significantly improved robustness against variations in the acquisition process and in the anatomical distribution, especially in pathological regions, compared to both vanilla DNN methods and DNN trained with undersampling mask augmentation. Trained models and code to replicate our experiments will become available for research purposes upon acceptance.

</p>
</details>

<details><summary><b>An Ion Exchange Mechanism Inspired Story Ending Generator for Different Characters</b>
<a href="https://arxiv.org/abs/2209.00200">arxiv:2209.00200</a>
&#x1F4C8; 3 <br>
<p>Xinyu Jiang, Qi Zhang, Chongyang Shi, Kaiying Jiang, Liang Hu, Shoujin Wang</p></summary>
<p>

**Abstract:** Story ending generation aims at generating reasonable endings for a given story context. Most existing studies in this area focus on generating coherent or diversified story endings, while they ignore that different characters may lead to different endings for a given story. In this paper, we propose a Character-oriented Story Ending Generator (CoSEG) to customize an ending for each character in a story. Specifically, we first propose a character modeling module to learn the personalities of characters from their descriptive experiences extracted from the story context. Then, inspired by the ion exchange mechanism in chemical reactions, we design a novel vector breaking/forming module to learn the intrinsic interactions between each character and the corresponding context through an analogical information exchange procedure. Finally, we leverage the attention mechanism to learn effective character-specific interactions and feed each interaction into a decoder to generate character-orient endings. Extensive experimental results and case studies demonstrate that CoSEG achieves significant improvements in the quality of generated endings compared with state-of-the-art methods, and it effectively customizes the endings for different characters.

</p>
</details>

<details><summary><b>An evaluation framework for comparing causal inference models</b>
<a href="https://arxiv.org/abs/2209.00115">arxiv:2209.00115</a>
&#x1F4C8; 3 <br>
<p>Niki Kiriakidou, Christos Diou</p></summary>
<p>

**Abstract:** Estimation of causal effects is the core objective of many scientific disciplines. However, it remains a challenging task, especially when the effects are estimated from observational data. Recently, several promising machine learning models have been proposed for causal effect estimation. The evaluation of these models has been based on the mean values of the error of the Average Treatment Effect (ATE) as well as of the Precision in Estimation of Heterogeneous Effect (PEHE). In this paper, we propose to complement the evaluation of causal inference models using concrete statistical evidence, including the performance profiles of Dolan and Mor{é}, as well as non-parametric and post-hoc statistical tests. The main motivation behind this approach is the elimination of the influence of a small number of instances or simulation on the benchmarking process, which in some cases dominate the results. We use the proposed evaluation methodology to compare several state-of-the-art causal effect estimation models.

</p>
</details>

<details><summary><b>A DeepParticle method for learning and generating aggregation patterns in multi-dimensional Keller-Segel chemotaxis systems</b>
<a href="https://arxiv.org/abs/2209.00109">arxiv:2209.00109</a>
&#x1F4C8; 3 <br>
<p>Zhongjian Wang, Jack Xin, Zhiwen Zhang</p></summary>
<p>

**Abstract:** We study a regularized interacting particle method for computing aggregation patterns and near singular solutions of a Keller-Segal (KS) chemotaxis system in two and three space dimensions, then further develop DeepParticle (DP) method to learn and generate solutions under variations of physical parameters. The KS solutions are approximated as empirical measures of particles which self-adapt to the high gradient part of solutions. We utilize the expressiveness of deep neural networks (DNNs) to represent the transform of samples from a given initial (source) distribution to a target distribution at finite time T prior to blowup without assuming invertibility of the transforms. In the training stage, we update the network weights by minimizing a discrete 2-Wasserstein distance between the input and target empirical measures. To reduce computational cost, we develop an iterative divide-and-conquer algorithm to find the optimal transition matrix in the Wasserstein distance. We present numerical results of DP framework for successful learning and generation of KS dynamics in the presence of laminar and chaotic flows. The physical parameter in this work is either the small diffusivity of chemo-attractant or the reciprocal of the flow amplitude in the advection-dominated regime.

</p>
</details>

<details><summary><b>Incorporating Task-specific Concept Knowledge into Script Learning</b>
<a href="https://arxiv.org/abs/2209.00068">arxiv:2209.00068</a>
&#x1F4C8; 3 <br>
<p>Chenkai Sun, Tie Xu, ChengXiang Zhai, Heng ji</p></summary>
<p>

**Abstract:** In this paper, we present Tetris, a new task of Goal-Oriented Script Completion. Unlike previous work, it considers a more realistic and more general setting, where the input includes not only the goal but also additional user context, including preferences and history. To address the problem using a knowledge-based approach, we introduce Task Concept Graph, an automatically constructed knowledge base from instructional websites. Different from Commonsense Knowledge Base like ConceptNet, the task concept graph schema introduces various types of noun phrases-based nodes specifically for accomplishing a task. To integrate such graphs into script learning, we devise two methods that acquire concepts from the knowledge base as prompts to downstream script completion. On our WikiHow-based dataset, we find that incorporating concepts from the Task Concept Graph consistently improves performance, demonstrating the benefit of Task Concept Graph for this task. Furthermore, the model with gold-standard concepts as prompt outperforms the baseline significantly, further confirming the need for task-specific knowledge in goal-oriented script completion. The dataset, repository, models, and demo will be publicly available to facilitate further research on this new task.

</p>
</details>

<details><summary><b>Stationary Kernels and Gaussian Processes on Lie Groups and their Homogeneous Spaces I: the Compact Case</b>
<a href="https://arxiv.org/abs/2208.14960">arxiv:2208.14960</a>
&#x1F4C8; 3 <br>
<p>Iskander Azangulov, Andrei Smolensky, Alexander Terenin, Viacheslav Borovitskiy</p></summary>
<p>

**Abstract:** Gaussian processes are arguably the most important model class in spatial statistics. They encode prior information about the modeled function and can be used for exact or approximate Bayesian inference. In many applications, particularly in physical sciences and engineering, but also in areas such as geostatistics and neuroscience, invariance to symmetries is one of the most fundamental forms of prior information one can consider. The invariance of a Gaussian process' covariance to such symmetries gives rise to the most natural generalization of the concept of stationarity to such spaces. In this work, we develop constructive and practical techniques for building stationary Gaussian processes on a very large class of non-Euclidean spaces arising in the context of symmetries. Our techniques make it possible to (i) calculate covariance kernels and (ii) sample from prior and posterior Gaussian processes defined on such spaces, both in a practical manner. This work is split into two parts, each involving different technical considerations: part I studies compact spaces, while part II studies non-compact spaces possessing certain structure. Our contributions make the non-Euclidean Gaussian process models we study compatible with well-understood computational techniques available in standard Gaussian process software packages, thereby making them accessible to practitioners.

</p>
</details>

<details><summary><b>ARMA Cell: A Modular and Effective Approach for Neural Autoregressive Modeling</b>
<a href="https://arxiv.org/abs/2208.14919">arxiv:2208.14919</a>
&#x1F4C8; 3 <br>
<p>Philipp Schiele, Christoph Berninger, David Rügamer</p></summary>
<p>

**Abstract:** The autoregressive moving average (ARMA) model is a classical, and arguably one of the most studied approaches to model time series data. It has compelling theoretical properties and is widely used among practitioners. More recent deep learning approaches popularize recurrent neural networks (RNNs) and, in particular, long short-term memory (LSTM) cells that have become one of the best performing and most common building blocks in neural time series modeling. While advantageous for time series data or sequences with long-term effects, complex RNN cells are not always a must and can sometimes even be inferior to simpler recurrent approaches. In this work, we introduce the ARMA cell, a simpler, modular, and effective approach for time series modeling in neural networks. This cell can be used in any neural network architecture where recurrent structures are present and naturally handles multivariate time series using vector autoregression. We also introduce the ConvARMA cell as a natural successor for spatially-correlated time series. Our experiments show that the proposed methodology is competitive with popular alternatives in terms of performance while being more robust and compelling due to its simplicity.

</p>
</details>

<details><summary><b>Batch-Size Independent Regret Bounds for Combinatorial Semi-Bandits with Probabilistically Triggered Arms or Independent Arms</b>
<a href="https://arxiv.org/abs/2208.14837">arxiv:2208.14837</a>
&#x1F4C8; 3 <br>
<p>Xutong Liu, Jinhang Zuo, Siwei Wang, Carlee Joe-Wong, John C. S. Lui, Wei Chen</p></summary>
<p>

**Abstract:** In this paper, we study the combinatorial semi-bandits (CMAB) and focus on reducing the dependency of the batch-size $K$ in the regret bound, where $K$ is the total number of arms that can be pulled or triggered in each round. First, for the setting of CMAB with probabilistically triggered arms (CMAB-T), we discover a novel (directional) triggering probability and variance modulated (TPVM) condition that can replace the previously-used smoothness condition for various applications, such as cascading bandits, online network exploration and online influence maximization. Under this new condition, we propose a BCUCB-T algorithm with variance-aware confidence intervals and conduct regret analysis which reduces the $O(K)$ factor to $O(\log K)$ or $O(\log^2 K)$ in the regret bound, significantly improving the regret bounds for the above applications. Second, for the setting of non-triggering CMAB with independent arms, we propose a SESCB algorithm which leverages on the non-triggering version of the TPVM condition and completely removes the dependency on $K$ in the leading regret. As a valuable by-product, the regret analysis used in this paper can improve several existing results by a factor of $O(\log K)$. Finally, experimental evaluations show our superior performance compared with benchmark algorithms in different applications.

</p>
</details>

<details><summary><b>PyTorch Image Quality: Metrics for Image Quality Assessment</b>
<a href="https://arxiv.org/abs/2208.14818">arxiv:2208.14818</a>
&#x1F4C8; 3 <br>
<p>Sergey Kastryulin, Jamil Zakirov, Denis Prokopenko, Dmitry V. Dylov</p></summary>
<p>

**Abstract:** Image Quality Assessment (IQA) metrics are widely used to quantitatively estimate the extent of image degradation following some forming, restoring, transforming, or enhancing algorithms. We present PyTorch Image Quality (PIQ), a usability-centric library that contains the most popular modern IQA algorithms, guaranteed to be correctly implemented according to their original propositions and thoroughly verified. In this paper, we detail the principles behind the foundation of the library, describe the evaluation strategy that makes it reliable, provide the benchmarks that showcase the performance-time trade-offs, and underline the benefits of GPU acceleration given the library is used within the PyTorch backend. PyTorch Image Quality is an open source software: https://github.com/photosynthesis-team/piq/.

</p>
</details>

<details><summary><b>Let Me Check the Examples: Enhancing Demonstration Learning via Explicit Imitation</b>
<a href="https://arxiv.org/abs/2209.00455">arxiv:2209.00455</a>
&#x1F4C8; 2 <br>
<p>Sirui Wang, Kaiwen Wei, Hongzhi Zhang, Yuntao Li, Wei Wu</p></summary>
<p>

**Abstract:** Demonstration learning aims to guide the prompt prediction via providing answered demonstrations in the few shot settings. Despite achieving promising results, existing work only concatenates the answered examples as demonstrations to the prompt template (including the raw context) without any additional operation, neglecting the prompt-demonstration dependencies. Besides, prior research found that randomly replacing the labels of demonstrations marginally hurts performance, illustrating that the model could not properly learn the knowledge brought by the demonstrations. Inspired by the human learning process, in this paper, we introduce Imitation DEMOnstration Learning (Imitation-Demo) to strengthen demonstration learning via explicitly imitating human review behaviour, which includes: (1) contrastive learning mechanism to concentrate on the similar demonstrations. (2) demonstration-label re-prediction method to consolidate known knowledge. Experiment results show that our proposed method achieves state-of-the-art performance on 11 out of 14 classification corpora. Further studies also prove that Imitation-Demo strengthen the association between prompt and demonstrations, which could provide the basis for exploring how demonstration learning works.

</p>
</details>

<details><summary><b>A Transferable Multi-stage Model with Cycling Discrepancy Learning for Lithium-ion Battery State of Health Estimation</b>
<a href="https://arxiv.org/abs/2209.00190">arxiv:2209.00190</a>
&#x1F4C8; 2 <br>
<p>Yan Qin, Chau Yuen, Xunyuan Yin, Biao Huang</p></summary>
<p>

**Abstract:** As a significant ingredient regarding health status, data-driven state-of-health (SOH) estimation has become dominant for lithium-ion batteries (LiBs). To handle data discrepancy across batteries, current SOH estimation models engage in transfer learning (TL), which reserves apriori knowledge gained through reusing partial structures of the offline trained model. However, multiple degradation patterns of a complete life cycle of a battery make it challenging to pursue TL. The concept of the stage is introduced to describe the collection of continuous cycles that present a similar degradation pattern. A transferable multi-stage SOH estimation model is proposed to perform TL across batteries in the same stage, consisting of four steps. First, with identified stage information, raw cycling data from the source battery are reconstructed into the phase space with high dimensions, exploring hidden dynamics with limited sensors. Next, domain invariant representation across cycles in each stage is proposed through cycling discrepancy subspace with reconstructed data. Third, considering the unbalanced discharge cycles among different stages, a switching estimation strategy composed of a lightweight model with the long short-term memory network and a powerful model with the proposed temporal capsule network is proposed to boost estimation accuracy. Lastly, an updating scheme compensates for estimation errors when the cycling consistency of target batteries drifts. The proposed method outperforms its competitive algorithms in various transfer tasks for a run-to-failure benchmark with three batteries.

</p>
</details>

<details><summary><b>SketchBetween: Video-to-Video Synthesis for Sprite Animation via Sketches</b>
<a href="https://arxiv.org/abs/2209.00185">arxiv:2209.00185</a>
&#x1F4C8; 2 <br>
<p>Dagmar Lukka Loftsdóttir, Matthew Guzdial</p></summary>
<p>

**Abstract:** 2D animation is a common factor in game development, used for characters, effects and background art. It involves work that takes both skill and time, but parts of which are repetitive and tedious. Automated animation approaches exist, but are designed without animators in mind. The focus is heavily on real-life video, which follows strict laws of how objects move, and does not account for the stylistic movement often present in 2D animation. We propose a problem formulation that more closely adheres to the standard workflow of animation. We also demonstrate a model, SketchBetween, which learns to map between keyframes and sketched in-betweens to rendered sprite animations. We demonstrate that our problem formulation provides the required information for the task and that our model outperforms an existing method.

</p>
</details>

<details><summary><b>The Infinitesimal Jackknife and Combinations of Models</b>
<a href="https://arxiv.org/abs/2209.00147">arxiv:2209.00147</a>
&#x1F4C8; 2 <br>
<p>Indrayudh Ghosal, Yunzhe Zhou, Giles Hooker</p></summary>
<p>

**Abstract:** The Infinitesimal Jackknife is a general method for estimating variances of parametric models, and more recently also for some ensemble methods. In this paper we extend the Infinitesimal Jackknife to estimate the covariance between any two models. This can be used to quantify uncertainty for combinations of models, or to construct test statistics for comparing different models or ensembles of models fitted using the same training dataset. Specific examples in this paper use boosted combinations of models like random forests and M-estimators. We also investigate its application on neural networks and ensembles of XGBoost models. We illustrate the efficacy of variance estimates through extensive simulations and its application to the Beijing Housing data, and demonstrate the theoretical consistency of the Infinitesimal Jackknife covariance estimate.

</p>
</details>

<details><summary><b>Feynman on Artificial Intelligence and Machine Learning, with Updates</b>
<a href="https://arxiv.org/abs/2209.00083">arxiv:2209.00083</a>
&#x1F4C8; 2 <br>
<p>Eric Mjolsness</p></summary>
<p>

**Abstract:** I present my recollections of Richard Feynman's mid-1980s interest in artificial intelligence and neural networks, set in the technical context of the physics-related approaches to neural networks of that time. I attempt to evaluate his ideas in the light of the substantial advances in the field since then, and vice versa. There are aspects of Feynman's interests that I think have been largely achieved and others that remain excitingly open, notably in computational science, and potentially including the revival of symbolic methods therein.

</p>
</details>

<details><summary><b>Zero-day DDoS Attack Detection</b>
<a href="https://arxiv.org/abs/2208.14971">arxiv:2208.14971</a>
&#x1F4C8; 2 <br>
<p>Cameron Boeder, Troy Januchowski</p></summary>
<p>

**Abstract:** The ability to detect zero-day (novel) attacks has become essential in the network security industry. Due to ever evolving attack signatures, existing network intrusion detection systems often fail to detect these threats. This project aims to solve the task of detecting zero-day DDoS (distributed denial-of-service) attacks by utilizing network traffic that is captured before entering a private network. Modern feature extraction techniques are used in conjunction with neural networks to determine if a network packet is either benign or malicious.

</p>
</details>

<details><summary><b>Membership Inference Attacks by Exploiting Loss Trajectory</b>
<a href="https://arxiv.org/abs/2208.14933">arxiv:2208.14933</a>
&#x1F4C8; 2 <br>
<p>Yiyong Liu, Zhengyu Zhao, Michael Backes, Yang Zhang</p></summary>
<p>

**Abstract:** Machine learning models are vulnerable to membership inference attacks in which an adversary aims to predict whether or not a particular sample was contained in the target model's training dataset. Existing attack methods have commonly exploited the output information (mostly, losses) solely from the given target model. As a result, in practical scenarios where both the member and non-member samples yield similarly small losses, these methods are naturally unable to differentiate between them. To address this limitation, in this paper, we propose a new attack method, called \system, which can exploit the membership information from the whole training process of the target model for improving the attack performance. To mount the attack in the common black-box setting, we leverage knowledge distillation, and represent the membership information by the losses evaluated on a sequence of intermediate models at different distillation epochs, namely \emph{distilled loss trajectory}, together with the loss from the given target model. Experimental results over different datasets and model architectures demonstrate the great advantage of our attack in terms of different metrics. For example, on CINIC-10, our attack achieves at least 6$\times$ higher true-positive rate at a low false-positive rate of 0.1\% than existing methods. Further analysis demonstrates the general effectiveness of our attack in more strict scenarios.

</p>
</details>

<details><summary><b>Open Challenges in Musical Metacreation</b>
<a href="https://arxiv.org/abs/2208.14734">arxiv:2208.14734</a>
&#x1F4C8; 2 <br>
<p>Filippo Carnovalini</p></summary>
<p>

**Abstract:** Musical Metacreation tries to obtain creative behaviors from computers algorithms composing music. In this paper I briefly analyze how this field evolved from algorithmic composition to be focused on the search for creativity, and I point out some issues in pursuing this goal. Finally, I argue that hybridization of algorithms can be a useful direction for research.

</p>
</details>

<details><summary><b>Segmentation-guided Domain Adaptation and Data Harmonization of Multi-device Retinal Optical Coherence Tomography using Cycle-Consistent Generative Adversarial Networks</b>
<a href="https://arxiv.org/abs/2208.14635">arxiv:2208.14635</a>
&#x1F4C8; 2 <br>
<p>Shuo Chen, Da Ma, Sieun Lee, Timothy T. L. Yu, Gavin Xu, Donghuan Lu, Karteek Popuri, Myeong Jin Ju, Marinko V. Sarunic, Mirza Faisal Beg</p></summary>
<p>

**Abstract:** Optical Coherence Tomography(OCT) is a non-invasive technique capturing cross-sectional area of the retina in micro-meter resolutions. It has been widely used as a auxiliary imaging reference to detect eye-related pathology and predict longitudinal progression of the disease characteristics. Retina layer segmentation is one of the crucial feature extraction techniques, where the variations of retinal layer thicknesses and the retinal layer deformation due to the presence of the fluid are highly correlated with multiple epidemic eye diseases like Diabetic Retinopathy(DR) and Age-related Macular Degeneration (AMD). However, these images are acquired from different devices, which have different intensity distribution, or in other words, belong to different imaging domains. This paper proposes a segmentation-guided domain-adaptation method to adapt images from multiple devices into single image domain, where the state-of-art pre-trained segmentation model is available. It avoids the time consumption of manual labelling for the upcoming new dataset and the re-training of the existing network. The semantic consistency and global feature consistency of the network will minimize the hallucination effect that many researchers reported regarding Cycle-Consistent Generative Adversarial Networks(CycleGAN) architecture.

</p>
</details>

<details><summary><b>Classification of Electroencephalograms during Mathematical Calculations Using Deep Learning</b>
<a href="https://arxiv.org/abs/2209.00627">arxiv:2209.00627</a>
&#x1F4C8; 1 <br>
<p>Umang Goenka, Param Patil, Kush Gosalia, Aaryan Jagetia</p></summary>
<p>

**Abstract:** Classifying Electroencephalogram(EEG) signals helps in understanding Brain-Computer Interface (BCI). EEG signals are vital in studying how the human mind functions. In this paper, we have used an Arithmetic Calculation dataset consisting of Before Calculation Signals (BCS) and During Calculation Signals (DCS). The dataset consisted of 36 participants. In order to understand the functioning of neurons in the brain, we classified BCS vs DCS. For this classification, we extracted various features such as Mutual Information (MI), Phase Locking Value (PLV), and Entropy namely Permutation entropy, Spectral entropy, Singular value decomposition entropy, Approximate entropy, Sample entropy. The classification of these features was done using RNN-based classifiers such as LSTM, BLSTM, ConvLSTM, and CNN-LSTM. The model achieved an accuracy of 99.72% when entropy was used as a feature and ConvLSTM as a classifier.

</p>
</details>

<details><summary><b>A Genetic Algorithm-based Framework for Learning Statistical Power Manifold</b>
<a href="https://arxiv.org/abs/2209.00215">arxiv:2209.00215</a>
&#x1F4C8; 1 <br>
<p>Abhishek K. Umrawal, Sean P. Lane, Erin P. Hennes</p></summary>
<p>

**Abstract:** Statistical power is a measure of the goodness/strength of a hypothesis test. Formally, it is the probability of detecting an effect, if there is a true effect present to detect. Hence, optimizing statistical power as a function of some parameters of a hypothesis test is desirable. However, for most hypothesis tests, the explicit functional form of statistical power as a function of those parameters is unknown but calculating statistical power for a given set of values of those parameters is possible using simulated experiments. These simulated experiments are usually computationally expensive. Hence, developing the entire statistical power manifold using simulations can be very time-consuming. Motivated by this, we propose a novel genetic algorithm-based framework for learning statistical power manifold. For a multiple linear regression $F$-test, we show that the proposed algorithm/framework learns the statistical power manifold much faster as compared to a brute-force approach as the number of queries to the power oracle is significantly reduced. We also show that the quality of learning the manifold improves as the number of iterations increases for the genetic algorithm.

</p>
</details>

<details><summary><b>CPS Attack Detection under Limited Local Information in Cyber Security: A Multi-node Multi-class Classification Ensemble Approach</b>
<a href="https://arxiv.org/abs/2209.00170">arxiv:2209.00170</a>
&#x1F4C8; 1 <br>
<p>Junyi Liu, Yifu Tang, Haimeng Zhao, Xieheng Wang, Fangyu Li, Jingyi Zhang</p></summary>
<p>

**Abstract:** Cybersecurity breaches are the common anomalies for distributed cyber-physical systems (CPS). However, the cyber security breach classification is still a difficult problem, even using cutting-edge artificial intelligence (AI) approaches. In this paper, we study the multi-class classification problem in cyber security for attack detection. A challenging multi-node data-censoring case is considered. In such a case, data within each data center/node cannot be shared while the local data is incomplete. Particularly, local nodes contain only a part of the multiple classes. In order to train a global multi-class classifier without sharing the raw data across all nodes, the main result of our study is designing a multi-node multi-class classification ensemble approach. By gathering the estimated parameters of the binary classifiers and data densities from each local node, the missing information for each local node is completed to build the global multi-class classifier. Numerical experiments are given to validate the effectiveness of the proposed approach under the multi-node data-censoring case. Under such a case, we even show the out-performance of the proposed approach over the full-data approach.

</p>
</details>

<details><summary><b>Tree-Based Adaptive Model Learning</b>
<a href="https://arxiv.org/abs/2209.00122">arxiv:2209.00122</a>
&#x1F4C8; 1 <br>
<p>Tiago Ferreira, Gerco van Heerdt, Alexandra Silva</p></summary>
<p>

**Abstract:** We extend the Kearns-Vazirani learning algorithm to be able to handle systems that change over time. We present a new learning algorithm that can reuse and update previously learned behavior, implement it in the LearnLib library, and evaluate it on large examples, to which we make small adjustments between two runs of the algorithm. In these experiments our algorithm significantly outperforms both the classic Kearns-Vazirani learning algorithm and the current state-of-the-art adaptive algorithm.

</p>
</details>

<details><summary><b>RecLight: A Recurrent Neural Network Accelerator with Integrated Silicon Photonics</b>
<a href="https://arxiv.org/abs/2209.00084">arxiv:2209.00084</a>
&#x1F4C8; 1 <br>
<p>Febin Sunny, Mahdi Nikdast, Sudeep Pasricha</p></summary>
<p>

**Abstract:** Recurrent Neural Networks (RNNs) are used in applications that learn dependencies in data sequences, such as speech recognition, human activity recognition, and anomaly detection. In recent years, newer RNN variants, such as GRUs and LSTMs, have been used for implementing these applications. As many of these applications are employed in real-time scenarios, accelerating RNN/LSTM/GRU inference is crucial. In this paper, we propose a novel photonic hardware accelerator called RecLight for accelerating simple RNNs, GRUs, and LSTMs. Simulation results indicate that RecLight achieves 37x lower energy-per-bit and 10% better throughput compared to the state-of-the-art.

</p>
</details>

<details><summary><b>Discovering Conservation Laws using Optimal Transport and Manifold Learning</b>
<a href="https://arxiv.org/abs/2208.14995">arxiv:2208.14995</a>
&#x1F4C8; 1 <br>
<p>Peter Y. Lu, Rumen Dangovski, Marin Soljačić</p></summary>
<p>

**Abstract:** Conservation laws are key theoretical and practical tools for understanding, characterizing, and modeling nonlinear dynamical systems. However, for many complex dynamical systems, the corresponding conserved quantities are difficult to identify, making it hard to analyze their dynamics and build efficient, stable predictive models. Current approaches for discovering conservation laws often depend on detailed dynamical information, such as the equation of motion or fine-grained time measurements, with many recent proposals also relying on black box parametric deep learning methods. We instead reformulate this task as a manifold learning problem and propose a non-parametric approach, combining the Wasserstein metric from optimal transport with diffusion maps, to discover conserved quantities that vary across trajectories sampled from a dynamical system. We test this new approach on a variety of physical systems$\unicode{x2014}$including conservative Hamiltonian systems, dissipative systems, and spatiotemporal systems$\unicode{x2014}$and demonstrate that our manifold learning method is able to both identify the number of conserved quantities and extract their values. Using tools from optimal transport theory and manifold learning, our proposed method provides a direct geometric approach to identifying conservation laws that is both robust and interpretable without requiring an explicit model of the system nor accurate time information.

</p>
</details>

<details><summary><b>Multiscale Non-stationary Causal Structure Learning from Time Series Data</b>
<a href="https://arxiv.org/abs/2208.14989">arxiv:2208.14989</a>
&#x1F4C8; 1 <br>
<p>Gabriele D'Acunto, Gianmarco De Francisci Morales, Paolo Bajardi, Francesco Bonchi</p></summary>
<p>

**Abstract:** This paper introduces a new type of causal structure, namely multiscale non-stationary directed acyclic graph (MN-DAG), that generalizes DAGs to the time-frequency domain. Our contribution is twofold. First, by leveraging results from spectral and causality theories, we expose a novel probabilistic generative model, which allows to sample an MN-DAG according to user-specified priors concerning the time-dependence and multiscale properties of the causal graph. Second, we devise a Bayesian method for the estimation of MN-DAGs, by means of stochastic variational inference (SVI), called Multiscale Non-Stationary Causal Structure Learner (MN-CASTLE). In addition to direct observations, MN-CASTLE exploits information from the decomposition of the total power spectrum of time series over different time resolutions. In our experiments, we first use the proposed model to generate synthetic data according to a latent MN-DAG, showing that the data generated reproduces well-known features of time series in different domains. Then we compare our learning method MN-CASTLE against baseline models on synthetic data generated with different multiscale and non-stationary settings, confirming the good performance of MN-CASTLE. Finally, we show some insights derived from the application of MN-CASTLE to study the causal structure of 7 global equity markets during the Covid-19 pandemic.

</p>
</details>

<details><summary><b>Cadence Detection in Symbolic Classical Music using Graph Neural Networks</b>
<a href="https://arxiv.org/abs/2208.14819">arxiv:2208.14819</a>
&#x1F4C8; 1 <br>
<p>Emmanouil Karystinaios, Gerhard Widmer</p></summary>
<p>

**Abstract:** Cadences are complex structures that have been driving music from the beginning of contrapuntal polyphony until today. Detecting such structures is vital for numerous MIR tasks such as musicological analysis, key detection, or music segmentation. However, automatic cadence detection remains challenging mainly because it involves a combination of high-level musical elements like harmony, voice leading, and rhythm. In this work, we present a graph representation of symbolic scores as an intermediate means to solve the cadence detection task. We approach cadence detection as an imbalanced node classification problem using a Graph Convolutional Network. We obtain results that are roughly on par with the state of the art, and we present a model capable of making predictions at multiple levels of granularity, from individual notes to beats, thanks to the fine-grained, note-by-note representation. Moreover, our experiments suggest that graph convolution can learn non-local features that assist in cadence detection, freeing us from the need of having to devise specialized features that encode non-local context. We argue that this general approach to modeling musical scores and classification tasks has a number of potential advantages, beyond the specific recognition task presented here.

</p>
</details>

<details><summary><b>Sparsification of the regularized magnetic Laplacian with multi-type spanning forests</b>
<a href="https://arxiv.org/abs/2208.14797">arxiv:2208.14797</a>
&#x1F4C8; 1 <br>
<p>Michaël Fanuel, Rémi Bardenet</p></summary>
<p>

**Abstract:** In this paper, we consider a ${\rm U}(1)$-connection graph, that is, a graph where each oriented edge is endowed with a unit modulus complex number which is simply conjugated under orientation flip. A natural replacement for the combinatorial Laplacian is then the so-called magnetic Laplacian, an Hermitian matrix that includes information about the graph's connection. Connection graphs and magnetic Laplacians appear, e.g., in the problem of angular synchronization. In the context of large and dense graphs, we study here sparsifiers of the magnetic Laplacian, i.e., spectral approximations based on subgraphs with few edges. Our approach relies on sampling multi-type spanning forests (MTSFs) using a custom determinantal point process, a distribution over edges that favours diversity. In a word, an MTSF is a spanning subgraph whose connected components are either trees or cycle-rooted trees. The latter partially capture the angular inconsistencies of the connection graph, and thus provide a way to compress information contained in the connection. Interestingly, when this connection graph has weakly inconsistent cycles, samples of this distribution can be obtained by using a random walk with cycle popping. We provide statistical guarantees for a choice of natural estimators of the connection Laplacian, and investigate the practical application of our sparsifiers in two applications.

</p>
</details>

<details><summary><b>A stabilizing reinforcement learning approach for sampled systems with partially unknown models</b>
<a href="https://arxiv.org/abs/2208.14714">arxiv:2208.14714</a>
&#x1F4C8; 1 <br>
<p>Lukas Beckenbach, Pavel Osinenko, Stefan Streif</p></summary>
<p>

**Abstract:** Reinforcement learning is commonly associated with training of reward-maximizing (or cost-minimizing) agents, in other words, controllers. It can be applied in model-free or model-based fashion, using a priori or online collected system data to train involved parametric architectures. In general, online reinforcement learning does not guarantee closed loop stability unless special measures are taken, for instance, through learning constraints or tailored training rules. Particularly promising are hybrids of reinforcement learning with "classical" control approaches. In this work, we suggest a method to guarantee practical stability of the system-controller closed loop in a purely online learning setting, i.e., without offline training. Moreover, we assume only partial knowledge of the system model. To achieve the claimed results, we employ techniques of classical adaptive control. The implementation of the overall control scheme is provided explicitly in a digital, sampled setting. That is, the controller receives the state of the system and computes the control action at discrete, specifically, equidistant moments in time. The method is tested in adaptive traction control and cruise control where it proved to significantly reduce the cost.

</p>
</details>

<details><summary><b>Deep Reinforcement Learning for Uplink Multi-Carrier Non-Orthogonal Multiple Access Resource Allocation Using Buffer State Information</b>
<a href="https://arxiv.org/abs/2208.14689">arxiv:2208.14689</a>
&#x1F4C8; 1 <br>
<p>Eike-Manuel Bansbach, Yigit Kiyak, Laurent Schmalen</p></summary>
<p>

**Abstract:** For orthogonal multiple access (OMA) systems, the number of served user equipments (UEs) is limited to the number of available orthogonal resources. On the other hand, non-orthogonal multiple access (NOMA) schemes allow multiple UEs to use the same orthogonal resource. This extra degree of freedom introduces new challenges for resource allocation. Buffer state information (BSI), like the size and age of packets waiting for transmission, can be used to improve scheduling in OMA systems. In this paper, we investigate the impact of BSI on the performance of a centralized scheduler in an uplink multi-carrier NOMA scenario with UEs having various data rate and latency requirements. To handle the large combinatorial space of allocating UEs to the resources, we propose a novel scheduler based on actor-critic reinforcement learning incorporating BSI. Training and evaluation are carried out using Nokia's "wireless suite". We propose various novel techniques to both stabilize and speed up training. The proposed scheduler outperforms benchmark schedulers.

</p>
</details>

<details><summary><b>Learning Tree Structures from Leaves For Particle Decay Reconstruction</b>
<a href="https://arxiv.org/abs/2208.14924">arxiv:2208.14924</a>
&#x1F4C8; 0 <br>
<p>James Kahn, Ilias Tsaklidis, Oskar Taubert, Lea Reuter, Giulio Dujany, Tobias Boeckh, Arthur Thaller, Pablo Goldenzweig, Florian Bernlochner, Achim Streit, Markus Götz</p></summary>
<p>

**Abstract:** In this work, we present a neural approach to reconstructing rooted tree graphs describing hierarchical interactions, using a novel representation we term the Lowest Common Ancestor Generations (LCAG) matrix. This compact formulation is equivalent to the adjacency matrix, but enables learning a tree's structure from its leaves alone without the prior assumptions required if using the adjacency matrix directly. Employing the LCAG therefore enables the first end-to-end trainable solution which learns the hierarchical structure of varying tree sizes directly, using only the terminal tree leaves to do so. In the case of high-energy particle physics, a particle decay forms a hierarchical tree structure of which only the final products can be observed experimentally, and the large combinatorial space of possible trees makes an analytic solution intractable. We demonstrate the use of the LCAG as a target in the task of predicting simulated particle physics decay structures using both a Transformer encoder and a Neural Relational Inference encoder Graph Neural Network. With this approach, we are able to correctly predict the LCAG purely from leaf features for a maximum tree-depth of $8$ in $92.5\%$ of cases for trees up to $6$ leaves (including) and $59.7\%$ for trees up to $10$ in our simulated dataset.

</p>
</details>

<details><summary><b>Formalising the Robustness of Counterfactual Explanations for Neural Networks</b>
<a href="https://arxiv.org/abs/2208.14878">arxiv:2208.14878</a>
&#x1F4C8; 0 <br>
<p>Junqi Jiang, Francesco Leofante, Antonio Rago, Francesca Toni</p></summary>
<p>

**Abstract:** The use of counterfactual explanations (CFXs) is an increasingly popular explanation strategy for machine learning models. However, recent studies have shown that these explanations may not be robust to changes in the underlying model (e.g., following retraining), which raises questions about their reliability in real-world applications. Existing attempts towards solving this problem are heuristic, and the robustness to model changes of the resulting CFXs is evaluated with only a small number of retrained models, failing to provide exhaustive guarantees. To remedy this, we propose the first notion to formally and deterministically assess the robustness (to model changes) of CFXs for neural networks, that we call Δ-robustness. We introduce an abstraction framework based on interval neural networks to verify the Δ-robustness of CFXs against a possibly infinite set of changes to the model parameters, i.e., weights and biases. We then demonstrate the utility of this approach in two distinct ways. First, we analyse the Δ-robustness of a number of CFX generation methods from the literature and show that they unanimously host significant deficiencies in this regard. Second, we demonstrate how embedding Δ-robustness within existing methods can provide CFXs which are provably robust.

</p>
</details>

<details><summary><b>Intelligent Closed-loop RAN Control with xApps in OpenRAN Gym</b>
<a href="https://arxiv.org/abs/2208.14877">arxiv:2208.14877</a>
&#x1F4C8; 0 <br>
<p>Leonardo Bonati, Michele Polese, Salvatore D'Oro, Stefano Basagni, Tommaso Melodia</p></summary>
<p>

**Abstract:** Softwarization, programmable network control and the use of all-encompassing controllers acting at different timescales are heralded as the key drivers for the evolution to next-generation cellular networks. These technologies have fostered newly designed intelligent data-driven solutions for managing large sets of diverse cellular functionalities, basically impossible to implement in traditionally closed cellular architectures. Despite the evident interest of industry on Artificial Intelligence (AI) and Machine Learning (ML) solutions for closed-loop control of the Radio Access Network (RAN), and several research works in the field, their design is far from mainstream, and it is still a sophisticated and often overlooked operation. In this paper, we discuss how to design AI/ML solutions for the intelligent closed-loop control of the Open RAN, providing guidelines and insights based on exemplary solutions with high-performance record. We then show how to embed these solutions into xApps instantiated on the O-RAN near-real-time RAN Intelligent Controller (RIC) through OpenRAN Gym, the first publicly available toolbox for data-driven O-RAN experimentation at scale. We showcase a use case of an xApp developed with OpenRAN Gym and tested on a cellular network with 7 base stations and 42 users deployed on the Colosseum wireless network emulator. Our demonstration shows the high degree of flexibility of the OpenRAN Gym-based xApp development environment, which is independent of deployment scenarios and traffic demand.

</p>
</details>

<details><summary><b>Negative Human Rights as a Basis for Long-term AI Safety and Regulation</b>
<a href="https://arxiv.org/abs/2208.14788">arxiv:2208.14788</a>
&#x1F4C8; 0 <br>
<p>Ondrej Bajgar, Jan Horenovsky</p></summary>
<p>

**Abstract:** If future AI systems are to be reliably safe in novel situations, they will need to incorporate general principles guiding them to robustly recognize which outcomes and behaviours would be harmful. Such principles may need to be supported by a binding system of regulation, which would need the underlying principles to be widely accepted. They should also be specific enough for technical implementation. Drawing inspiration from law, this article explains how negative human rights could fulfil the role of such principles and serve as a foundation both for an international regulatory system and for building technical safety constraints for future AI systems.

</p>
</details>

<details><summary><b>Enhancing Early Lung Cancer Detection on Chest Radiographs with AI-assistance: A Multi-Reader Study</b>
<a href="https://arxiv.org/abs/2208.14742">arxiv:2208.14742</a>
&#x1F4C8; 0 <br>
<p>Gaetan Dissez, Nicole Tay, Tom Dyer, Matthew Tam, Richard Dittrich, David Doyne, James Hoare, Jackson J. Pat, Stephanie Patterson, Amanda Stockham, Qaiser Malik, Tom Naunton Morgan, Paul Williams, Liliana Garcia-Mondragon, Jordan Smith, George Pearse, Simon Rasalingham</p></summary>
<p>

**Abstract:** Objectives: The present study evaluated the impact of a commercially available explainable AI algorithm in augmenting the ability of clinicians to identify lung cancer on chest X-rays (CXR).
  Design: This retrospective study evaluated the performance of 11 clinicians for detecting lung cancer from chest radiographs, with and without assistance from a commercially available AI algorithm (red dot, Behold.ai) that predicts suspected lung cancer from CXRs. Clinician performance was evaluated against clinically confirmed diagnoses.
  Setting: The study analysed anonymised patient data from an NHS hospital; the dataset consisted of 400 chest radiographs from adult patients (18 years and above) who had a CXR performed in 2020, with corresponding clinical text reports.
  Participants: A panel of readers consisting of 11 clinicians (consultant radiologists, radiologist trainees and reporting radiographers) participated in this study.
  Main outcome measures: Overall accuracy, sensitivity, specificity and precision for detecting lung cancer on CXRs by clinicians, with and without AI input. Agreement rates between clinicians and performance standard deviation were also evaluated, with and without AI input.
  Results: The use of the AI algorithm by clinicians led to an improved overall performance for lung tumour detection, achieving an overall increase of 17.4% of lung cancers being identified on CXRs which would have otherwise been missed, an overall increase in detection of smaller tumours, a 24% and 13% increased detection of stage 1 and stage 2 lung cancers respectively, and standardisation of clinician performance.
  Conclusions: This study showed great promise in the clinical utility of AI algorithms in improving early lung cancer diagnosis and promoting health equity through overall improvement in reader performances, without impacting downstream imaging resources.

</p>
</details>

<details><summary><b>Classical-to-quantum convolutional neural network transfer learning</b>
<a href="https://arxiv.org/abs/2208.14708">arxiv:2208.14708</a>
&#x1F4C8; 0 <br>
<p>Juhyeon Kim, Joonsuk Huh, Daniel K. Park</p></summary>
<p>

**Abstract:** Machine learning using quantum convolutional neural networks (QCNNs) has demonstrated success in both quantum and classical data classification. In previous studies, QCNNs attained a higher classification accuracy than their classical counterparts under the same training conditions in the few-parameter regime. However, the general performance of large-scale quantum models is difficult to examine because of the limited size of quantum circuits, which can be reliably implemented in the near future. We propose transfer learning as an effective strategy for utilizing small QCNNs in the noisy intermediate-scale quantum era to the full extent. In the classical-to-quantum transfer learning framework, a QCNN can solve complex classification problems without requiring a large-scale quantum circuit by utilizing a pre-trained classical convolutional neural network (CNN). We perform numerical simulations of QCNN models with various sets of quantum convolution and pooling operations for MNIST data classification under transfer learning, in which a classical CNN is trained with Fashion-MNIST data. The results show that transfer learning from classical to quantum CNN performs considerably better than purely classical transfer learning models under similar training conditions.

</p>
</details>

<details><summary><b>XCAT -- Lightweight Quantized Single Image Super-Resolution using Heterogeneous Group Convolutions and Cross Concatenation</b>
<a href="https://arxiv.org/abs/2208.14655">arxiv:2208.14655</a>
&#x1F4C8; 0 <br>
<p>Mustafa Ayazoglu, Bahri Batuhan Bilecen</p></summary>
<p>

**Abstract:** We propose a lightweight, single image super-resolution network for mobile devices, named XCAT. XCAT introduces Heterogeneous Group Convolution Blocks with Cross Concatenations (HXBlock). The heterogeneous split of the input channels to the group convolution blocks reduces the number of operations, and cross concatenation allows for information flow between the intermediate input tensors of cascaded HXBlocks. Cross concatenations inside HXBlocks can also avoid using more expensive operations like 1x1 convolutions. To further prev ent expensive tensor copy operations, XCAT utilizes non-trainable convolution kernels to apply up sampling operations. Designed with integer quantization in mind, XCAT also utilizes several techniques on training, like intensity-based data augmentation. Integer quantized XCAT operates in real time on Mali-G71 MP2 GPU with 320ms, and on Synaptics Dolphin NPU with 30ms (NCHW) and 8.8ms (NHWC), suitable for real-time applications.

</p>
</details>


{% endraw %}
Prev: [2022.08.30]({{ '/2022/08/30/2022.08.30.html' | relative_url }})  Next: [2022.09.01]({{ '/2022/09/01/2022.09.01.html' | relative_url }})