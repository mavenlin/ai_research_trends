Prev: [2021.02.26]({{ '/2021/02/26/2021.02.26.html' | relative_url }})  Next: [2021.02.28]({{ '/2021/02/28/2021.02.28.html' | relative_url }})
{% raw %}
## Summary for 2021-02-27, created on 2021-12-24


<details><summary><b>Walk2Map: Extracting Floor Plans from Indoor Walk Trajectories</b>
<a href="https://arxiv.org/abs/2103.00262">arxiv:2103.00262</a>
&#x1F4C8; 50 <br>
<p>Claudio Mura, Renato Pajarola, Konrad Schindler, Niloy Mitra</p></summary>
<p>

**Abstract:** Recent years have seen a proliferation of new digital products for the efficient management of indoor spaces, with important applications like emergency management, virtual property showcasing and interior design. These products rely on accurate 3D models of the environments considered, including information on both architectural and non-permanent elements. These models must be created from measured data such as RGB-D images or 3D point clouds, whose capture and consolidation involves lengthy data workflows. This strongly limits the rate at which 3D models can be produced, preventing the adoption of many digital services for indoor space management. We provide an alternative to such data-intensive procedures by presenting Walk2Map, a data-driven approach to generate floor plans only from trajectories of a person walking inside the rooms. Thanks to recent advances in data-driven inertial odometry, such minimalistic input data can be acquired from the IMU readings of consumer-level smartphones, which allows for an effortless and scalable mapping of real-world indoor spaces. Our work is based on learning the latent relation between an indoor walk trajectory and the information represented in a floor plan: interior space footprint, portals, and furniture. We distinguish between recovering area-related (interior footprint, furniture) and wall-related (doors) information and use two different neural architectures for the two tasks: an image-based Encoder-Decoder and a Graph Convolutional Network, respectively. We train our networks using scanned 3D indoor models and apply them in a cascaded fashion on an indoor walk trajectory at inference time. We perform a qualitative and quantitative evaluation using both simulated and measured, real-world trajectories, and compare against a baseline method for image-to-image translation. The experiments confirm the feasibility of our approach.

</p>
</details>

<details><summary><b>Meta-Learning with Graph Neural Networks: Methods and Applications</b>
<a href="https://arxiv.org/abs/2103.00137">arxiv:2103.00137</a>
&#x1F4C8; 23 <br>
<p>Debmalya Mandal, Sourav Medya, Brian Uzzi, Charu Aggarwal</p></summary>
<p>

**Abstract:** Graph Neural Networks (GNNs), a generalization of deep neural networks on graph data have been widely used in various domains, ranging from drug discovery to recommender systems. However, GNNs on such applications are limited when there are few available samples. Meta-learning has been an important framework to address the lack of samples in machine learning, and in recent years, researchers have started to apply meta-learning to GNNs. In this work, we provide a comprehensive survey of different meta-learning approaches involving GNNs on various graph problems showing the power of using these two approaches together. We categorize the literature based on proposed architectures, shared representations, and applications. Finally, we discuss several exciting future research directions and open problems.

</p>
</details>

<details><summary><b>SUM: A Benchmark Dataset of Semantic Urban Meshes</b>
<a href="https://arxiv.org/abs/2103.00355">arxiv:2103.00355</a>
&#x1F4C8; 15 <br>
<p>Weixiao Gao, Liangliang Nan, Bas Boom, Hugo Ledoux</p></summary>
<p>

**Abstract:** Recent developments in data acquisition technology allow us to collect 3D texture meshes quickly. Those can help us understand and analyse the urban environment, and as a consequence are useful for several applications like spatial analysis and urban planning. Semantic segmentation of texture meshes through deep learning methods can enhance this understanding, but it requires a lot of labelled data. The contributions of this work are threefold: (1) a new benchmark dataset of semantic urban meshes, (2) a novel semi-automatic annotation framework, and (3) an annotation tool for 3D meshes. In particular, our dataset covers about 4 km2 in Helsinki (Finland), with six classes, and we estimate that we save about 600 hours of labelling work using our annotation framework, which includes initial segmentation and interactive refinement. We also compare the performance of several state-of-theart 3D semantic segmentation methods on the new benchmark dataset. Other researchers can use our results to train their networks: the dataset is publicly available, and the annotation tool is released as open-source.

</p>
</details>

<details><summary><b>Neural Network Approach to Construction of Classical Integrable Systems</b>
<a href="https://arxiv.org/abs/2103.00372">arxiv:2103.00372</a>
&#x1F4C8; 10 <br>
<p>Fumihiro Ishikawa, Hidemaro Suwa, Synge Todo</p></summary>
<p>

**Abstract:** Integrable systems have provided various insights into physical phenomena and mathematics. The way of constructing many-body integrable systems is limited to few ansatzes for the Lax pair, except for highly inventive findings of conserved quantities. Machine learning techniques have recently been applied to broad physics fields and proven powerful for building non-trivial transformations and potential functions. We here propose a machine learning approach to a systematic construction of classical integrable systems. Given the Hamiltonian or samples in latent space, our neural network simultaneously learns the corresponding natural Hamiltonian in real space and the canonical transformation between the latent space and the real space variables. We also propose a loss function for building integrable systems and demonstrate successful unsupervised learning for the Toda lattice. Our approach enables exploring new integrable systems without any prior knowledge about the canonical transformation or any ansatz for the Lax pair.

</p>
</details>

<details><summary><b>Transform Network Architectures for Deep Learning based End-to-End Image/Video Coding in Subsampled Color Spaces</b>
<a href="https://arxiv.org/abs/2103.01760">arxiv:2103.01760</a>
&#x1F4C8; 9 <br>
<p>Hilmi E. Egilmez, Ankitesh K. Singh, Muhammed Coban, Marta Karczewicz, Yinhao Zhu, Yang Yang, Amir Said, Taco S. Cohen</p></summary>
<p>

**Abstract:** Most of the existing deep learning based end-to-end image/video coding (DLEC) architectures are designed for non-subsampled RGB color format. However, in order to achieve a superior coding performance, many state-of-the-art block-based compression standards such as High Efficiency Video Coding (HEVC/H.265) and Versatile Video Coding (VVC/H.266) are designed primarily for YUV 4:2:0 format, where U and V components are subsampled by considering the human visual system. This paper investigates various DLEC designs to support YUV 4:2:0 format by comparing their performance against the main profiles of HEVC and VVC standards under a common evaluation framework. Moreover, a new transform network architecture is proposed to improve the efficiency of coding YUV 4:2:0 data. The experimental results on YUV 4:2:0 datasets show that the proposed architecture significantly outperforms naive extensions of existing architectures designed for RGB format and achieves about 10% average BD-rate improvement over the intra-frame coding in HEVC.

</p>
</details>

<details><summary><b>High-Dimensional Bayesian Optimization with Sparse Axis-Aligned Subspaces</b>
<a href="https://arxiv.org/abs/2103.00349">arxiv:2103.00349</a>
&#x1F4C8; 8 <br>
<p>David Eriksson, Martin Jankowiak</p></summary>
<p>

**Abstract:** Bayesian optimization (BO) is a powerful paradigm for efficient optimization of black-box objective functions. High-dimensional BO presents a particular challenge, in part because the curse of dimensionality makes it difficult to define -- as well as do inference over -- a suitable class of surrogate models. We argue that Gaussian process surrogate models defined on sparse axis-aligned subspaces offer an attractive compromise between flexibility and parsimony. We demonstrate that our approach, which relies on Hamiltonian Monte Carlo for inference, can rapidly identify sparse subspaces relevant to modeling the unknown objective function, enabling sample-efficient high-dimensional BO. In an extensive suite of experiments comparing to existing methods for high-dimensional BO we demonstrate that our algorithm, Sparse Axis-Aligned Subspace BO (SAASBO), achieves excellent performance on several synthetic and real-world problems without the need to set problem-specific hyperparameters.

</p>
</details>

<details><summary><b>Towards Continual, Online, Unsupervised Depth</b>
<a href="https://arxiv.org/abs/2103.00369">arxiv:2103.00369</a>
&#x1F4C8; 7 <br>
<p>Muhammad Umar Karim Khan</p></summary>
<p>

**Abstract:** Although depth extraction with passive sensors has seen remarkable improvement with deep learning, these approaches may fail to obtain correct depth if they are exposed to environments not observed during training. Online adaptation, where the neural network trains while deployed, with unsupervised learning provides a convenient solution. However, online adaptation causes a neural network to forget the past. Thus, past training is wasted and the network is not able to provide good results if it observes past scenes. This work deals with practical online-adaptation where the input is online and temporally-correlated, and training is completely unsupervised. Regularization and replay-based methods without task boundaries are proposed to avoid catastrophic forgetting while adapting to online data. Experiments are performed on different datasets with both structure-from-motion and stereo. Results of forgetting as well as adaptation are provided, which are superior to recent methods. The proposed approach is more inline with the artificial general intelligence paradigm as the neural network learns the scene where it is deployed without any supervision (target labels and tasks) and without forgetting about the past. Code is available at github.com/umarKarim/cou_stereo and github.com/umarKarim/cou_sfm.

</p>
</details>

<details><summary><b>Transformers with Competitive Ensembles of Independent Mechanisms</b>
<a href="https://arxiv.org/abs/2103.00336">arxiv:2103.00336</a>
&#x1F4C8; 7 <br>
<p>Alex Lamb, Di He, Anirudh Goyal, Guolin Ke, Chien-Feng Liao, Mirco Ravanelli, Yoshua Bengio</p></summary>
<p>

**Abstract:** An important development in deep learning from the earliest MLPs has been a move towards architectures with structural inductive biases which enable the model to keep distinct sources of information and routes of processing well-separated. This structure is linked to the notion of independent mechanisms from the causality literature, in which a mechanism is able to retain the same processing as irrelevant aspects of the world are changed. For example, convnets enable separation over positions, while attention-based architectures (especially Transformers) learn which combination of positions to process dynamically. In this work we explore a way in which the Transformer architecture is deficient: it represents each position with a large monolithic hidden representation and a single set of parameters which are applied over the entire hidden representation. This potentially throws unrelated sources of information together, and limits the Transformer's ability to capture independent mechanisms. To address this, we propose Transformers with Independent Mechanisms (TIM), a new Transformer layer which divides the hidden representation and parameters into multiple mechanisms, which only exchange information through attention. Additionally, we propose a competition mechanism which encourages these mechanisms to specialize over time steps, and thus be more independent. We study TIM on a large-scale BERT model, on the Image Transformer, and on speech enhancement and find evidence for semantically meaningful specialization as well as improved performance.

</p>
</details>

<details><summary><b>Predicting post-operative right ventricular failure using video-based deep learning</b>
<a href="https://arxiv.org/abs/2103.00364">arxiv:2103.00364</a>
&#x1F4C8; 6 <br>
<p>Rohan Shad, Nicolas Quach, Robyn Fong, Patpilai Kasinpila, Cayley Bowles, Miguel Castro, Ashrith Guha, Eddie Suarez, Stefan Jovinge, Sangjin Lee, Theodore Boeve, Myriam Amsallem, Xiu Tang, Francois Haddad, Yasuhiro Shudo, Y. Joseph Woo, Jeffrey Teuteberg, John P. Cunningham, Curt P. Langlotz, William Hiesinger</p></summary>
<p>

**Abstract:** Non-invasive and cost effective in nature, the echocardiogram allows for a comprehensive assessment of the cardiac musculature and valves. Despite progressive improvements over the decades, the rich temporally resolved data in echocardiography videos remain underutilized. Human reads of echocardiograms reduce the complex patterns of cardiac wall motion, to a small list of measurements of heart function. Furthermore, all modern echocardiography artificial intelligence (AI) systems are similarly limited by design - automating measurements of the same reductionist metrics rather than utilizing the wealth of data embedded within each echo study. This underutilization is most evident in situations where clinical decision making is guided by subjective assessments of disease acuity, and tools that predict disease onset within clinically actionable timeframes are unavailable. Predicting the likelihood of developing post-operative right ventricular failure (RV failure) in the setting of mechanical circulatory support is one such clinical example. To address this, we developed a novel video AI system trained to predict post-operative right ventricular failure (RV failure), using the full spatiotemporal density of information from pre-operative echocardiography scans. We achieve an AUC of 0.729, specificity of 52% at 80% sensitivity and 46% sensitivity at 80% specificity. Furthermore, we show that our ML system significantly outperforms a team of human experts tasked with predicting RV failure on independent clinical evaluation. Finally, the methods we describe are generalizable to any cardiac clinical decision support application where treatment or patient selection is guided by qualitative echocardiography assessments.

</p>
</details>

<details><summary><b>Cognitive Homeostatic Agents</b>
<a href="https://arxiv.org/abs/2103.03359">arxiv:2103.03359</a>
&#x1F4C8; 5 <br>
<p>Amol Kelkar</p></summary>
<p>

**Abstract:** Human brain has been used as an inspiration for building autonomous agents, but it is not obvious what level of computational description of the brain one should use. This has led to overly opinionated symbolic approaches and overly unstructured connectionist approaches. We propose that using homeostasis as the computational description provides a good compromise. Similar to how physiological homeostasis is the regulation of certain homeostatic variables, cognition can be interpreted as the regulation of certain 'cognitive homeostatic variables'. We present an outline of a Cognitive Homeostatic Agent, built as a hierarchy of physiological and cognitive homeostatic subsystems and describe structures and processes to guide future exploration. We expect this to be a fruitful line of investigation towards building sophisticated artificial agents that can act flexibly in complex environments, and produce behaviors indicating planning, thinking and feelings.

</p>
</details>

<details><summary><b>Generalization Through Hand-Eye Coordination: An Action Space for Learning Spatially-Invariant Visuomotor Control</b>
<a href="https://arxiv.org/abs/2103.00375">arxiv:2103.00375</a>
&#x1F4C8; 5 <br>
<p>Chen Wang, Rui Wang, Ajay Mandlekar, Li Fei-Fei, Silvio Savarese, Danfei Xu</p></summary>
<p>

**Abstract:** Imitation Learning (IL) is an effective framework to learn visuomotor skills from offline demonstration data. However, IL methods often fail to generalize to new scene configurations not covered by training data. On the other hand, humans can manipulate objects in varying conditions. Key to such capability is hand-eye coordination, a cognitive ability that enables humans to adaptively direct their movements at task-relevant objects and be invariant to the objects' absolute spatial location. In this work, we present a learnable action space, Hand-eye Action Networks (HAN), that can approximate human's hand-eye coordination behaviors by learning from human teleoperated demonstrations. Through a set of challenging multi-stage manipulation tasks, we show that a visuomotor policy equipped with HAN is able to inherit the key spatial invariance property of hand-eye coordination and achieve zero-shot generalization to new scene configurations. Additional materials available at https://sites.google.com/stanford.edu/han

</p>
</details>

<details><summary><b>Confronting Machine Learning With Financial Research</b>
<a href="https://arxiv.org/abs/2103.00366">arxiv:2103.00366</a>
&#x1F4C8; 5 <br>
<p>Kristof Lommers, Ouns El Harzli, Jack Kim</p></summary>
<p>

**Abstract:** This study aims to examine the challenges and applications of machine learning for financial research. Machine learning algorithms have been developed for certain data environments which substantially differ from the one we encounter in finance. Not only do difficulties arise due to some of the idiosyncrasies of financial markets, there is a fundamental tension between the underlying paradigm of machine learning and the research philosophy in financial economics. Given the peculiar features of financial markets and the empirical framework within social science, various adjustments have to be made to the conventional machine learning methodology. We discuss some of the main challenges of machine learning in finance and examine how these could be accounted for. Despite some of the challenges, we argue that machine learning could be unified with financial research to become a robust complement to the econometrician's toolbox. Moreover, we discuss the various applications of machine learning in the research process such as estimation, empirical discovery, testing, causal inference and prediction.

</p>
</details>

<details><summary><b>BiconNet: An Edge-preserved Connectivity-based Approach for Salient Object Detection</b>
<a href="https://arxiv.org/abs/2103.00334">arxiv:2103.00334</a>
&#x1F4C8; 5 <br>
<p>Ziyun Yang, Somayyeh Soltanian-Zadeh, Sina Farsiu</p></summary>
<p>

**Abstract:** Salient object detection (SOD) is viewed as a pixel-wise saliency modeling task by traditional deep learning-based methods. A limitation of current SOD models is insufficient utilization of inter-pixel information, which usually results in imperfect segmentation near edge regions and low spatial coherence. As we demonstrate, using a saliency mask as the only label is suboptimal. To address this limitation, we propose a connectivity-based approach called bilateral connectivity network (BiconNet), which uses connectivity masks together with saliency masks as labels for effective modeling of inter-pixel relationships and object saliency. Moreover, we propose a bilateral voting module to enhance the output connectivity map, and a novel edge feature enhancement method that efficiently utilizes edge-specific features. Through comprehensive experiments on five benchmark datasets, we demonstrate that our proposed method can be plugged into any existing state-of-the-art saliency-based SOD framework to improve its performance with negligible parameter increase.

</p>
</details>

<details><summary><b>DeepBLE: Generalizing RSSI-based Localization Across Different Devices</b>
<a href="https://arxiv.org/abs/2103.00252">arxiv:2103.00252</a>
&#x1F4C8; 5 <br>
<p>Harsh Agarwal, Navyata Sanghvi, Vivek Roy, Kris Kitani</p></summary>
<p>

**Abstract:** Accurate smartphone localization (< 1-meter error) for indoor navigation using only RSSI received from a set of BLE beacons remains a challenging problem, due to the inherent noise of RSSI measurements. To overcome the large variance in RSSI measurements, we propose a data-driven approach that uses a deep recurrent network, DeepBLE, to localize the smartphone using RSSI measured from multiple beacons in an environment. In particular, we focus on the ability of our approach to generalize across many smartphone brands (e.g., Apple, Samsung) and models (e.g., iPhone 8, S10). Towards this end, we collect a large-scale dataset of 15 hours of smartphone data, which consists of over 50,000 BLE beacon RSSI measurements collected from 47 beacons in a single building using 15 different popular smartphone models, along with precise 2D location annotations. Our experiments show that there is a very high variability of RSSI measurements across smartphone models (especially across brand), making it very difficult to apply supervised learning using only a subset of smartphone models. To address this challenge, we propose a novel statistic similarity loss (SSL) which enables our model to generalize to unseen phones using a semi-supervised learning approach. For known phones, the iPhone XR achieves the best mean distance error of 0.84 meters. For unknown phones, the Huawei Mate20 Pro shows the greatest improvement, cutting error by over 38\% from 2.62 meters to 1.63 meters error using our semi-supervised adaptation method.

</p>
</details>

<details><summary><b>Incorporating Domain Knowledge into Deep Neural Networks</b>
<a href="https://arxiv.org/abs/2103.00180">arxiv:2103.00180</a>
&#x1F4C8; 5 <br>
<p>Tirtharaj Dash, Sharad Chitlangia, Aditya Ahuja, Ashwin Srinivasan</p></summary>
<p>

**Abstract:** We present a survey of ways in which domain-knowledge has been included when constructing models with neural networks. The inclusion of domain-knowledge is of special interest not just to constructing scientific assistants, but also, many other areas that involve understanding data using human-machine collaboration. In many such instances, machine-based model construction may benefit significantly from being provided with human-knowledge of the domain encoded in a sufficiently precise form. This paper examines two broad approaches to encode such knowledge--as logical and numerical constraints--and describes techniques and results obtained in several sub-categories under each of these approaches.

</p>
</details>

<details><summary><b>Super-resolution-based Change Detection Network with Stacked Attention Module for Images with Different Resolutions</b>
<a href="https://arxiv.org/abs/2103.00188">arxiv:2103.00188</a>
&#x1F4C8; 4 <br>
<p>Mengxi Liu, Qian Shi, Andrea Marinoni, Da He, Xiaoping Liu, Liangpei Zhang</p></summary>
<p>

**Abstract:** Change detection, which aims to distinguish surface changes based on bi-temporal images, plays a vital role in ecological protection and urban planning. Since high resolution (HR) images cannot be typically acquired continuously over time, bi-temporal images with different resolutions are often adopted for change detection in practical applications. Traditional subpixel-based methods for change detection using images with different resolutions may lead to substantial error accumulation when HR images are employed; this is because of intraclass heterogeneity and interclass similarity. Therefore, it is necessary to develop a novel method for change detection using images with different resolutions, that is more suitable for HR images. To this end, we propose a super-resolution-based change detection network (SRCDNet) with a stacked attention module. The SRCDNet employs a super resolution (SR) module containing a generator and a discriminator to directly learn SR images through adversarial learning and overcome the resolution difference between bi-temporal images. To enhance the useful information in multi-scale features, a stacked attention module consisting of five convolutional block attention modules (CBAMs) is integrated to the feature extractor. The final change map is obtained through a metric learning-based change decision module, wherein a distance map between bi-temporal features is calculated. The experimental results demonstrate the superiority of the proposed method, which not only outperforms all baselines -with the highest F1 scores of 87.40% on the building change detection dataset and 92.94% on the change detection dataset -but also obtains the best accuracies on experiments performed with images having a 4x and 8x resolution difference. The source code of SRCDNet will be available at https://github.com/liumency/SRCDNet.

</p>
</details>

<details><summary><b>Inferring Unobserved Events in Systems With Shared Resources and Queues</b>
<a href="https://arxiv.org/abs/2103.00167">arxiv:2103.00167</a>
&#x1F4C8; 4 <br>
<p>Dirk Fahland, Vadim Denisov, Wil. M. P. van der Aalst</p></summary>
<p>

**Abstract:** To identify the causes of performance problems or to predict process behavior, it is essential to have correct and complete event data. This is particularly important for distributed systems with shared resources, e.g., one case can block another case competing for the same machine, leading to inter-case dependencies in performance. However, due to a variety of reasons, real-life systems often record only a subset of all events taking place. To understand and analyze the behavior and performance of processes with shared resources, we aim to reconstruct bounds for timestamps of events in a case that must have happened but were not recorded by inference over events in other cases in the system. We formulate and solve the problem by systematically introducing multi-entity concepts in event logs and process models. We introduce a partial-order based model of a multi-entity event log and a corresponding compositional model for multi-entity processes. We define PQR-systems as a special class of multi-entity processes with shared resources and queues. We then study the problem of inferring from an incomplete event log unobserved events and their timestamps that are globally consistent with a PQR-system. We solve the problem by reconstructing unobserved traces of resources and queues according to the PQR-model and derive bounds for their timestamps using a linear program. While the problem is illustrated for material handling systems like baggage handling systems in airports, the approach can be applied to other settings where recording is incomplete. The ideas have been implemented in ProM and were evaluated using both synthetic and real-life event logs.

</p>
</details>

<details><summary><b>Scalable Causal Domain Adaptation</b>
<a href="https://arxiv.org/abs/2103.00139">arxiv:2103.00139</a>
&#x1F4C8; 4 <br>
<p>Mohammad Ali Javidian, Om Pandey, Pooyan Jamshidi</p></summary>
<p>

**Abstract:** One of the most critical problems in transfer learning is the task of domain adaptation, where the goal is to apply an algorithm trained in one or more source domains to a different (but related) target domain. This paper deals with domain adaptation in the presence of covariate shift while invariances exist across domains. One of the main limitations of existing causal inference methods for solving this problem is scalability. To overcome this difficulty, we propose SCTL, an algorithm that avoids an exhaustive search and identifies invariant causal features across source and target domains based on Markov blanket discovery. SCTL does not require having prior knowledge of the causal structure, the type of interventions, or the intervention targets. There is an intrinsic locality associated with SCTL that makes it practically scalable and robust because local causal discovery increases the power of computational independence tests and makes the task of domain adaptation computationally tractable. We show the scalability and robustness of SCTL for domain adaptation using synthetic and real data sets in low-dimensional and high-dimensional settings.

</p>
</details>

<details><summary><b>Incorporating Causal Graphical Prior Knowledge into Predictive Modeling via Simple Data Augmentation</b>
<a href="https://arxiv.org/abs/2103.00136">arxiv:2103.00136</a>
&#x1F4C8; 4 <br>
<p>Takeshi Teshima, Masashi Sugiyama</p></summary>
<p>

**Abstract:** Causal graphs (CGs) are compact representations of the knowledge of the data generating processes behind the data distributions. When a CG is available, e.g., from the domain knowledge, we can infer the conditional independence (CI) relations that should hold in the data distribution. However, it is not straightforward how to incorporate this knowledge into predictive modeling. In this work, we propose a model-agnostic data augmentation method that allows us to exploit the prior knowledge of the CI encoded in a CG for supervised machine learning. We theoretically justify the proposed method by providing an excess risk bound indicating that the proposed method suppresses overfitting by reducing the apparent complexity of the predictor hypothesis class. Using real-world data with CGs provided by domain experts, we experimentally show that the proposed method is effective in improving the prediction accuracy, especially in the small-data regime.

</p>
</details>

<details><summary><b>Hierarchical Inducing Point Gaussian Process for Inter-domain Observations</b>
<a href="https://arxiv.org/abs/2103.00393">arxiv:2103.00393</a>
&#x1F4C8; 3 <br>
<p>Luhuan Wu, Andrew Miller, Lauren Anderson, Geoff Pleiss, David Blei, John Cunningham</p></summary>
<p>

**Abstract:** We examine the general problem of inter-domain Gaussian Processes (GPs): problems where the GP realization and the noisy observations of that realization lie on different domains. When the mapping between those domains is linear, such as integration or differentiation, inference is still closed form. However, many of the scaling and approximation techniques that our community has developed do not apply to this setting. In this work, we introduce the hierarchical inducing point GP (HIP-GP), a scalable inter-domain GP inference method that enables us to improve the approximation accuracy by increasing the number of inducing points to the millions. HIP-GP, which relies on inducing points with grid structure and a stationary kernel assumption, is suitable for low-dimensional problems. In developing HIP-GP, we introduce (1) a fast whitening strategy, and (2) a novel preconditioner for conjugate gradients which can be helpful in general GP settings. Our code is available at https: //github.com/cunningham-lab/hipgp.

</p>
</details>

<details><summary><b>LRG at TREC 2020: Document Ranking with XLNet-Based Models</b>
<a href="https://arxiv.org/abs/2103.00380">arxiv:2103.00380</a>
&#x1F4C8; 3 <br>
<p>Abheesht Sharma, Harshit Pandey</p></summary>
<p>

**Abstract:** Establishing a good information retrieval system in popular mediums of entertainment is a quickly growing area of investigation for companies and researchers alike. We delve into the domain of information retrieval for podcasts. In Spotify's Podcast Challenge, we are given a user's query with a description to find the most relevant short segment from the given dataset having all the podcasts. Previous techniques that include solely classical Information Retrieval (IR) techniques, perform poorly when descriptive queries are presented. On the other hand, models which exclusively rely on large neural networks tend to perform better. The downside to this technique is that a considerable amount of time and computing power are required to infer the result. We experiment with two hybrid models which first filter out the best podcasts based on user's query with a classical IR technique, and then perform re-ranking on the shortlisted documents based on the detailed description using a transformer-based model.

</p>
</details>

<details><summary><b>Towards Efficient Local Causal Structure Learning</b>
<a href="https://arxiv.org/abs/2103.00378">arxiv:2103.00378</a>
&#x1F4C8; 3 <br>
<p>Shuai Yang, Hao Wang, Kui Yu, Fuyuan Cao, Xindong Wu</p></summary>
<p>

**Abstract:** Local causal structure learning aims to discover and distinguish direct causes (parents) and direct effects (children) of a variable of interest from data. While emerging successes have been made, existing methods need to search a large space to distinguish direct causes from direct effects of a target variable T. To tackle this issue, we propose a novel Efficient Local Causal Structure learning algorithm, named ELCS. Specifically, we first propose the concept of N-structures, then design an efficient Markov Blanket (MB) discovery subroutine to integrate MB learning with N-structures to learn the MB of T and simultaneously distinguish direct causes from direct effects of T. With the proposed MB subroutine, ELCS starts from the target variable, sequentially finds MBs of variables connected to the target variable and simultaneously constructs local causal structures over MBs until the direct causes and direct effects of the target variable have been distinguished. Using eight Bayesian networks the extensive experiments have validated that ELCS achieves better accuracy and efficiency than the state-of-the-art algorithms.

</p>
</details>

<details><summary><b>Tiny Adversarial Mulit-Objective Oneshot Neural Architecture Search</b>
<a href="https://arxiv.org/abs/2103.00363">arxiv:2103.00363</a>
&#x1F4C8; 3 <br>
<p>Guoyang Xie, Jinbao Wang, Guo Yu, Feng Zheng, Yaochu Jin</p></summary>
<p>

**Abstract:** Due to limited computational cost and energy consumption, most neural network models deployed in mobile devices are tiny. However, tiny neural networks are commonly very vulnerable to attacks. Current research has proved that larger model size can improve robustness, but little research focuses on how to enhance the robustness of tiny neural networks. Our work focuses on how to improve the robustness of tiny neural networks without seriously deteriorating of clean accuracy under mobile-level resources. To this end, we propose a multi-objective oneshot network architecture search (NAS) algorithm to obtain the best trade-off networks in terms of the adversarial accuracy, the clean accuracy and the model size. Specifically, we design a novel search space based on new tiny blocks and channels to balance model size and adversarial performance. Moreover, since the supernet significantly affects the performance of subnets in our NAS algorithm, we reveal the insights into how the supernet helps to obtain the best subnet under white-box adversarial attacks. Concretely, we explore a new adversarial training paradigm by analyzing the adversarial transferability, the width of the supernet and the difference between training the subnets from scratch and fine-tuning. Finally, we make a statistical analysis for the layer-wise combination of certain blocks and channels on the first non-dominated front, which can serve as a guideline to design tiny neural network architectures for the resilience of adversarial perturbations.

</p>
</details>

<details><summary><b>Constrained Differentially Private Federated Learning for Low-bandwidth Devices</b>
<a href="https://arxiv.org/abs/2103.00342">arxiv:2103.00342</a>
&#x1F4C8; 3 <br>
<p>Raouf Kerkouche, Gergely Ács, Claude Castelluccia, Pierre Genevès</p></summary>
<p>

**Abstract:** Federated learning becomes a prominent approach when different entities want to learn collaboratively a common model without sharing their training data. However, Federated learning has two main drawbacks. First, it is quite bandwidth inefficient as it involves a lot of message exchanges between the aggregating server and the participating entities. This bandwidth and corresponding processing costs could be prohibitive if the participating entities are, for example, mobile devices. Furthermore, although federated learning improves privacy by not sharing data, recent attacks have shown that it still leaks information about the training data. This paper presents a novel privacy-preserving federated learning scheme. The proposed scheme provides theoretical privacy guarantees, as it is based on Differential Privacy. Furthermore, it optimizes the model accuracy by constraining the model learning phase on few selected weights. Finally, as shown experimentally, it reduces the upstream and downstream bandwidth by up to 99.9% compared to standard federated learning, making it practical for mobile systems.

</p>
</details>

<details><summary><b>Machine Learning Techniques to Construct Patched Analog Ensembles for Data Assimilation</b>
<a href="https://arxiv.org/abs/2103.00318">arxiv:2103.00318</a>
&#x1F4C8; 3 <br>
<p>Lucia Minah Yang, Ian Grooms</p></summary>
<p>

**Abstract:** Using generative models from the machine learning literature to create artificial ensemble members for use within data assimilation schemes has been introduced in [Grooms QJRMS, 2020] as constructed analog ensemble optimal interpolation (cAnEnOI). Specifically, we study general and variational autoencoders for the machine learning component of this method, and combine the ideas of constructed analogs and ensemble optimal interpolation in the data assimilation piece. To extend the scalability of cAnEnOI for use in data assimilation on complex dynamical models, we propose using patching schemes to divide the global spatial domain into digestible chunks. Using patches makes training the generative models possible and has the added benefit of being able to exploit parallelism during the generative step. Testing this new algorithm on a 1D toy model, we find that larger patch sizes make it harder to train an accurate generative model (i.e. a model whose reconstruction error is small), while conversely the data assimilation performance improves at larger patch sizes. There is thus a sweet spot where the patch size is large enough to enable good data assimilation performance, but not so large that it becomes difficult to train an accurate generative model. In our tests the new patched cAnEnOI method outperforms the original (unpatched) cAnEnOI, as well as the ensemble square root filter results from [Grooms QJRMS, 2020].

</p>
</details>

<details><summary><b>Object affordance as a guide for grasp-type recognition</b>
<a href="https://arxiv.org/abs/2103.00268">arxiv:2103.00268</a>
&#x1F4C8; 3 <br>
<p>Naoki Wake, Daichi Saito, Kazuhiro Sasabuchi, Hideki Koike, Katsushi Ikeuchi</p></summary>
<p>

**Abstract:** Recognizing human grasping strategies is an important factor in robot teaching as these strategies contain the implicit knowledge necessary to perform a series of manipulations smoothly. This study analyzed the effects of object affordance-a prior distribution of grasp types for each object-on convolutional neural network (CNN)-based grasp-type recognition. To this end, we created datasets of first-person grasping-hand images labeled with grasp types and object names, and tested a recognition pipeline leveraging object affordance. We evaluated scenarios with real and illusory objects to be grasped, to consider a teaching condition in mixed reality where the lack of visual object information can make the CNN recognition challenging. The results show that object affordance guided the CNN in both scenarios, increasing the accuracy by 1) excluding unlikely grasp types from the candidates and 2) enhancing likely grasp types. In addition, the "enhancing effect" was more pronounced with high degrees of grasp-type heterogeneity. These results indicate the effectiveness of object affordance for guiding grasp-type recognition in robot teaching applications.

</p>
</details>

<details><summary><b>Variational Laplace for Bayesian neural networks</b>
<a href="https://arxiv.org/abs/2103.00222">arxiv:2103.00222</a>
&#x1F4C8; 3 <br>
<p>Ali Unlu, Laurence Aitchison</p></summary>
<p>

**Abstract:** We develop variational Laplace for Bayesian neural networks (BNNs) which exploits a local approximation of the curvature of the likelihood to estimate the ELBO without the need for stochastic sampling of the neural-network weights. The Variational Laplace objective is simple to evaluate, as it is (in essence) the log-likelihood, plus weight-decay, plus a squared-gradient regularizer. Variational Laplace gave better test performance and expected calibration errors than maximum a-posteriori inference and standard sampling-based variational inference, despite using the same variational approximate posterior. Finally, we emphasise care needed in benchmarking standard VI as there is a risk of stopping before the variance parameters have converged. We show that early-stopping can be avoided by increasing the learning rate for the variance parameters.

</p>
</details>

<details><summary><b>Open-set Intersection Intention Prediction for Autonomous Driving</b>
<a href="https://arxiv.org/abs/2103.00140">arxiv:2103.00140</a>
&#x1F4C8; 3 <br>
<p>Fei Li, Xiangxu Li, Jun Luo, Shiwei Fan, Hongbo Zhang</p></summary>
<p>

**Abstract:** Intention prediction is a crucial task for Autonomous Driving (AD). Due to the variety of size and layout of intersections, it is challenging to predict intention of human driver at different intersections, especially unseen and irregular intersections. In this paper, we formulate the prediction of intention at intersections as an open-set prediction problem that requires context specific matching of the target vehicle state and the diverse intersection configurations that are in principle unbounded. We capture map-centric features that correspond to intersection structures under a spatial-temporal graph representation, and use two MAAMs (mutually auxiliary attention module) that cover respectively lane-level and exitlevel intentions to predict a target that best matches intersection elements in map-centric feature space. Under our model, attention scores estimate the probability distribution of the openset intentions that are contextually defined by the structure of the current intersection. The proposed model is trained and evaluated on simulated dataset. Furthermore, the model, trained on simulated dataset and without any fine tuning, is directly validated on in-house real-world dataset collected at 98 realworld intersections and exhibits satisfactory performance,demonstrating the practical viability of our approach.

</p>
</details>

<details><summary><b>Did Chatbots Miss Their 'Apollo Moment'? A Survey of the Potential, Gaps and Lessons from Using Collaboration Assistants During COVID-19</b>
<a href="https://arxiv.org/abs/2103.05561">arxiv:2103.05561</a>
&#x1F4C8; 2 <br>
<p>Biplav Srivastava</p></summary>
<p>

**Abstract:** Artificial Intelligence (AI) technologies have long been positioned as a tool to provide crucial data-driven decision support to people. In this survey paper, we look at how AI in general, and collaboration assistants (CAs or chatbots for short) in particular, have been used during a true global exigency - the COVID-19 pandemic. The key observation is that chatbots missed their "Apollo moment" when they could have really provided contextual, personalized, reliable decision support at scale that the state-of-the-art makes possible. We review the existing capabilities that are feasible and methods, identify the potential that chatbots could have met, the use-cases they were deployed on, the challenges they faced and gaps that persisted, and draw lessons that, if implemented, would make them more relevant in future health emergencies.

</p>
</details>

<details><summary><b>Convergence of Gaussian-smoothed optimal transport distance with sub-gamma distributions and dependent samples</b>
<a href="https://arxiv.org/abs/2103.00394">arxiv:2103.00394</a>
&#x1F4C8; 2 <br>
<p>Yixing Zhang, Xiuyuan Cheng, Galen Reeves</p></summary>
<p>

**Abstract:** The Gaussian-smoothed optimal transport (GOT) framework, recently proposed by Goldfeld et al., scales to high dimensions in estimation and provides an alternative to entropy regularization. This paper provides convergence guarantees for estimating the GOT distance under more general settings. For the Gaussian-smoothed $p$-Wasserstein distance in $d$ dimensions, our results require only the existence of a moment greater than $d + 2p$. For the special case of sub-gamma distributions, we quantify the dependence on the dimension $d$ and establish a phase transition with respect to the scale parameter. We also prove convergence for dependent samples, only requiring a condition on the pairwise dependence of the samples measured by the covariance of the feature map of a kernel space.
  A key step in our analysis is to show that the GOT distance is dominated by a family of kernel maximum mean discrepancy (MMD) distances with a kernel that depends on the cost function as well as the amount of Gaussian smoothing. This insight provides further interpretability for the GOT framework and also introduces a class of kernel MMD distances with desirable properties. The theoretical results are supported by numerical experiments.

</p>
</details>

<details><summary><b>Adaptive Regularized Submodular Maximization</b>
<a href="https://arxiv.org/abs/2103.00384">arxiv:2103.00384</a>
&#x1F4C8; 2 <br>
<p>Shaojie Tang, Jing Yuan</p></summary>
<p>

**Abstract:** In this paper, we study the problem of maximizing the difference between an adaptive submodular (revenue) function and an non-negative modular (cost) function under the adaptive setting. The input of our problem is a set of $n$ items, where each item has a particular state drawn from some known prior distribution $p$. The revenue function $g$ is defined over items and states, and the cost function $c$ is defined over items, i.e., each item has a fixed cost. The state of each item is unknown initially, one must select an item in order to observe its realized state. A policy $π$ specifies which item to pick next based on the observations made so far. Denote by $g_{avg}(π)$ the expected revenue of $π$ and let $c_{avg}(π)$ denote the expected cost of $π$. Our objective is to identify the best policy $π^o\in \arg\max_πg_{avg}(π)-c_{avg}(π)$ under a $k$-cardinality constraint. Since our objective function can take on both negative and positive values, the existing results of submodular maximization may not be applicable. To overcome this challenge, we develop a series of effective solutions with performance grantees. Let $π^o$ denote the optimal policy. For the case when $g$ is adaptive monotone and adaptive submodular, we develop an effective policy $π^l$ such that $g_{avg}(π^l) - c_{avg}(π^l) \geq (1-\frac{1}{e}-ε)g_{avg}(π^o) - c_{avg}(π^o)$, using only $O(nε^{-2}\log ε^{-1})$ value oracle queries. For the case when $g$ is adaptive submodular, we present a randomized policy $π^r$ such that $g_{avg}(π^r) - c_{avg}(π^r) \geq \frac{1}{e}g_{avg}(π^o) - c_{avg}(π^o)$.

</p>
</details>

<details><summary><b>Brain Signals to Rescue Aphasia, Apraxia and Dysarthria Speech Recognition</b>
<a href="https://arxiv.org/abs/2103.00383">arxiv:2103.00383</a>
&#x1F4C8; 2 <br>
<p>Gautam Krishna, Mason Carnahan, Shilpa Shamapant, Yashitha Surendranath, Saumya Jain, Arundhati Ghosh, Co Tran, Jose del R Millan, Ahmed H Tewfik</p></summary>
<p>

**Abstract:** In this paper, we propose a deep learning-based algorithm to improve the performance of automatic speech recognition (ASR) systems for aphasia, apraxia, and dysarthria speech by utilizing electroencephalography (EEG) features recorded synchronously with aphasia, apraxia, and dysarthria speech. We demonstrate a significant decoding performance improvement by more than 50\% during test time for isolated speech recognition task and we also provide preliminary results indicating performance improvement for the more challenging continuous speech recognition task by utilizing EEG features. The results presented in this paper show the first step towards demonstrating the possibility of utilizing non-invasive neural signals to design a real-time robust speech prosthetic for stroke survivors recovering from aphasia, apraxia, and dysarthria. Our aphasia, apraxia, and dysarthria speech-EEG data set will be released to the public to help further advance this interesting and crucial research.

</p>
</details>

<details><summary><b>Adversarial Information Bottleneck</b>
<a href="https://arxiv.org/abs/2103.00381">arxiv:2103.00381</a>
&#x1F4C8; 2 <br>
<p>Penglong Zhai, Shihua Zhang</p></summary>
<p>

**Abstract:** The information bottleneck (IB) principle has been adopted to explain deep learning in terms of information compression and prediction, which are balanced by a trade-off hyperparameter. How to optimize the IB principle for better robustness and figure out the effects of compression through the trade-off hyperparameter are two challenging problems. Previous methods attempted to optimize the IB principle by introducing random noise into learning the representation and achieved state-of-the-art performance in the nuisance information compression and semantic information extraction. However, their performance on resisting adversarial perturbations is far less impressive. To this end, we propose an adversarial information bottleneck (AIB) method without any explicit assumptions about the underlying distribution of the representations, which can be optimized effectively by solving a Min-Max optimization problem. Numerical experiments on synthetic and real-world datasets demonstrate its effectiveness on learning more invariant representations and mitigating adversarial perturbations compared to several competing IB methods. In addition, we analyse the adversarial robustness of diverse IB methods contrasting with their IB curves, and reveal that IB models with the hyperparameter $β$ corresponding to the knee point in the IB curve achieve the best trade-off between compression and prediction, and has best robustness against various attacks.

</p>
</details>

<details><summary><b>Communication-efficient Byzantine-robust distributed learning with statistical guarantee</b>
<a href="https://arxiv.org/abs/2103.00373">arxiv:2103.00373</a>
&#x1F4C8; 2 <br>
<p>Xingcai Zhou, Le Chang, Pengfei Xu, Shaogao Lv</p></summary>
<p>

**Abstract:** Communication efficiency and robustness are two major issues in modern distributed learning framework. This is due to the practical situations where some computing nodes may have limited communication power or may behave adversarial behaviors. To address the two issues simultaneously, this paper develops two communication-efficient and robust distributed learning algorithms for convex problems. Our motivation is based on surrogate likelihood framework and the median and trimmed mean operations. Particularly, the proposed algorithms are provably robust against Byzantine failures, and also achieve optimal statistical rates for strong convex losses and convex (non-smooth) penalties. For typical statistical models such as generalized linear models, our results show that statistical errors dominate optimization errors in finite iterations. Simulated and real data experiments are conducted to demonstrate the numerical performance of our algorithms.

</p>
</details>

<details><summary><b>The Labeled Multiple Canonical Correlation Analysis for Information Fusion</b>
<a href="https://arxiv.org/abs/2103.00359">arxiv:2103.00359</a>
&#x1F4C8; 2 <br>
<p>Lei Gao, Rui Zhang, Lin Qi, Enqing Chen, Ling Guan</p></summary>
<p>

**Abstract:** The objective of multimodal information fusion is to mathematically analyze information carried in different sources and create a new representation which will be more effectively utilized in pattern recognition and other multimedia information processing tasks. In this paper, we introduce a new method for multimodal information fusion and representation based on the Labeled Multiple Canonical Correlation Analysis (LMCCA). By incorporating class label information of the training samples,the proposed LMCCA ensures that the fused features carry discriminative characteristics of the multimodal information representations, and are capable of providing superior recognition performance. We implement a prototype of LMCCA to demonstrate its effectiveness on handwritten digit recognition,face recognition and object recognition utilizing multiple features,bimodal human emotion recognition involving information from both audio and visual domains. The generic nature of LMCCA allows it to take as input features extracted by any means,including those by deep learning (DL) methods. Experimental results show that the proposed method enhanced the performance of both statistical machine learning (SML) methods, and methods based on DL.

</p>
</details>

<details><summary><b>Online Behavioral Analysis with Application to Emotion State Identification</b>
<a href="https://arxiv.org/abs/2103.00356">arxiv:2103.00356</a>
&#x1F4C8; 2 <br>
<p>Lei Gao, Lin Qi, Ling Guan</p></summary>
<p>

**Abstract:** In this paper, we propose a novel discriminative model for online behavioral analysis with application to emotion state identification. The proposed model is able to extract more discriminative characteristics from behavioral data effectively and find the direction of optimal projection efficiently to satisfy requirements of online data analysis, leading to better utilization of the behavioral information to produce more accurate recognition results.

</p>
</details>

<details><summary><b>End-to-end Uncertainty-based Mitigation of Adversarial Attacks to Automated Lane Centering</b>
<a href="https://arxiv.org/abs/2103.00345">arxiv:2103.00345</a>
&#x1F4C8; 2 <br>
<p>Ruochen Jiao, Hengyi Liang, Takami Sato, Junjie Shen, Qi Alfred Chen, Qi Zhu</p></summary>
<p>

**Abstract:** In the development of advanced driver-assistance systems (ADAS) and autonomous vehicles, machine learning techniques that are based on deep neural networks (DNNs) have been widely used for vehicle perception. These techniques offer significant improvement on average perception accuracy over traditional methods, however, have been shown to be susceptible to adversarial attacks, where small perturbations in the input may cause significant errors in the perception results and lead to system failure. Most prior works addressing such adversarial attacks focus only on the sensing and perception modules. In this work, we propose an end-to-end approach that addresses the impact of adversarial attacks throughout perception, planning, and control modules. In particular, we choose a target ADAS application, the automated lane centering system in OpenPilot, quantify the perception uncertainty under adversarial attacks, and design a robust planning and control module accordingly based on the uncertainty analysis. We evaluate our proposed approach using both the public dataset and production-grade autonomous driving simulator. The experiment results demonstrate that our approach can effectively mitigate the impact of adversarial attacks and can achieve 55% to 90% improvement over the original OpenPilot.

</p>
</details>

<details><summary><b>A Novel Adaptive Deep Network for Building Footprint Segmentation</b>
<a href="https://arxiv.org/abs/2103.00286">arxiv:2103.00286</a>
&#x1F4C8; 2 <br>
<p>A. Ziaee, R. Dehbozorgi, M. Döller</p></summary>
<p>

**Abstract:** Building footprint segmentations for high resolution images are increasingly demanded for many remote sensing applications. By the emerging deep learning approaches, segmentation networks have made significant advances in the semantic segmentation of objects. However, these advances and the increased access to satellite images require the generation of accurate object boundaries in satellite images. In the current paper, we propose a novel network-based on Pix2Pix methodology to solve the problem of inaccurate boundaries obtained by converting satellite images into maps using segmentation networks in order to segment building footprints. To define the new network named G2G, our framework includes two generators where the first generator extracts localization features in order to merge them with the boundary features extracted from the second generator to segment all detailed building edges. Moreover, different strategies are implemented to enhance the quality of the proposed networks' results, implying that the proposed network outperforms state-of-the-art networks in segmentation accuracy with a large margin for all evaluation metrics. The implementation is available at https://github.com/A2Amir/A-Novel-Adaptive-Deep-Network-for-Building-Footprint-Segmentation.

</p>
</details>

<details><summary><b>Neural Architecture Search From Task Similarity Measure</b>
<a href="https://arxiv.org/abs/2103.00241">arxiv:2103.00241</a>
&#x1F4C8; 2 <br>
<p>Cat P. Le, Mohammadreza Soltani, Robert Ravier, Vahid Tarokh</p></summary>
<p>

**Abstract:** In this paper, we propose a neural architecture search framework based on a similarity measure between some baseline tasks and a target task. We first define the notion of the task similarity based on the log-determinant of the Fisher Information matrix. Next, we compute the task similarity from each of the baseline tasks to the target task. By utilizing the relation between a target and a set of learned baseline tasks, the search space of architectures for the target task can be significantly reduced, making the discovery of the best candidates in the set of possible architectures tractable and efficient, in terms of GPU days. This method eliminates the requirement for training the networks from scratch for a given target task as well as introducing the bias in the initialization of the search space from the human domain.

</p>
</details>

<details><summary><b>EDS-MEMBED: Multi-sense embeddings based on enhanced distributional semantic structures via a graph walk over word senses</b>
<a href="https://arxiv.org/abs/2103.00232">arxiv:2103.00232</a>
&#x1F4C8; 2 <br>
<p>Eniafe Festus Ayetiran, Petr Sojka, Vít Novotný</p></summary>
<p>

**Abstract:** Several language applications often require word semantics as a core part of their processing pipeline, either as precise meaning inference or semantic similarity. Multi-sense embeddings (M-SE) can be exploited for this important requirement. M-SE seeks to represent each word by their distinct senses in order to resolve the conflation of meanings of words as used in different contexts. Previous works usually approach this task by training a model on a large corpus and often ignore the effect and usefulness of the semantic relations offered by lexical resources. However, even with large training data, coverage of all possible word senses is still an issue. In addition, a considerable percentage of contextual semantic knowledge are never learned because a huge amount of possible distributional semantic structures are never explored. In this paper, we leverage the rich semantic structures in WordNet using a graph-theoretic walk technique over word senses to enhance the quality of multi-sense embeddings. This algorithm composes enriched texts from the original texts. Furthermore, we derive new distributional semantic similarity measures for M-SE from prior ones. We adapt these measures to word sense disambiguation (WSD) aspect of our experiment. We report evaluation results on 11 benchmark datasets involving WSD and Word Similarity tasks and show that our method for enhancing distributional semantic structures improves embeddings quality on the baselines. Despite the small training data, it achieves state-of-the-art performance on some of the datasets.

</p>
</details>

<details><summary><b>COVID-19 Tweets Analysis through Transformer Language Models</b>
<a href="https://arxiv.org/abs/2103.00199">arxiv:2103.00199</a>
&#x1F4C8; 2 <br>
<p>Abdul Hameed Azeemi, Adeel Waheed</p></summary>
<p>

**Abstract:** Understanding the public sentiment and perception in a healthcare crisis is essential for developing appropriate crisis management techniques. While some studies have used Twitter data for predictive modelling during COVID-19, fine-grained sentiment analysis of the opinion of people on social media during this pandemic has not yet been done. In this study, we perform an in-depth, fine-grained sentiment analysis of tweets in COVID-19. For this purpose, we perform supervised training of four transformer language models on the downstream task of multi-label classification of tweets into seven tone classes: [confident, anger, fear, joy, sadness, analytical, tentative]. We achieve a LRAP (Label Ranking Average Precision) score of 0.9267 through RoBERTa. This trained transformer model is able to correctly predict, with high accuracy, the tone of a tweet. We then leverage this model for predicting tones for 200,000 tweets on COVID-19. We then perform a country-wise analysis of the tone of tweets, and extract useful indicators of the psychological condition about the people in this pandemic.

</p>
</details>

<details><summary><b>Disentangling Geometric Deformation Spaces in Generative Latent Shape Models</b>
<a href="https://arxiv.org/abs/2103.00142">arxiv:2103.00142</a>
&#x1F4C8; 2 <br>
<p>Tristan Aumentado-Armstrong, Stavros Tsogkas, Sven Dickinson, Allan Jepson</p></summary>
<p>

**Abstract:** A complete representation of 3D objects requires characterizing the space of deformations in an interpretable manner, from articulations of a single instance to changes in shape across categories. In this work, we improve on a prior generative model of geometric disentanglement for 3D shapes, wherein the space of object geometry is factorized into rigid orientation, non-rigid pose, and intrinsic shape. The resulting model can be trained from raw 3D shapes, without correspondences, labels, or even rigid alignment, using a combination of classical spectral geometry and probabilistic disentanglement of a structured latent representation space. Our improvements include more sophisticated handling of rotational invariance and the use of a diffeomorphic flow network to bridge latent and spectral space. The geometric structuring of the latent space imparts an interpretable characterization of the deformation space of an object. Furthermore, it enables tasks like pose transfer and pose-aware retrieval without requiring supervision. We evaluate our model on its generative modelling, representation learning, and disentanglement performance, showing improved rotation invariance and intrinsic-extrinsic factorization quality over the prior model.

</p>
</details>

<details><summary><b>Optimal control of point-to-point navigation in turbulent time-dependent flows using Reinforcement Learning</b>
<a href="https://arxiv.org/abs/2103.00329">arxiv:2103.00329</a>
&#x1F4C8; 1 <br>
<p>Michele Buzzicotti, Luca Biferale, Fabio Bonaccorso, Patricio Clark di Leoni, Kristian Gustavsson</p></summary>
<p>

**Abstract:** We present theoretical and numerical results concerning the problem to find the path that minimizes the time to navigate between two given points in a complex fluid under realistic navigation constraints. We contrast deterministic Optimal Navigation (ON) control with stochastic policies obtained by Reinforcement Learning (RL) algorithms. We show that Actor-Critic RL algorithms are able to find quasi-optimal solutions in the presence of either time-independent or chaotically evolving flow configurations. For our application, ON solutions develop unstable behavior within the typical duration of the navigation process, and are therefore not useful in practice. We first explore navigation of turbulent flow using a constant propulsion speed. Based on a discretized phase-space, the propulsion direction is adjusted with the aim to minimize the time spent to reach the target. Further, we explore a case where additional control is obtained by allowing the engine to power off. Exploiting advection of the underlying flow, allows the target to be reached with less energy consumption. In this case, we optimize a linear combination between the total navigation time and the total time the engine is switched off. Our approach can be generalized to other setups, for example, navigation under imperfect environmental forecast or with different models for the moving vessel.

</p>
</details>

<details><summary><b>Terahertz-Band Joint Ultra-Massive MIMO Radar-Communications: Model-Based and Model-Free Hybrid Beamforming</b>
<a href="https://arxiv.org/abs/2103.00328">arxiv:2103.00328</a>
&#x1F4C8; 1 <br>
<p>Ahmet M. Elbir, Kumar Vijay Mishra, Symeon Chatzinotas</p></summary>
<p>

**Abstract:** Wireless communications and sensing at terahertz (THz) band are increasingly investigated as promising short-range technologies because of the availability of high operational bandwidth at THz. In order to address the extremely high attenuation at THz, ultra-massive multiple-input multiple-output (MIMO) antenna systems have been proposed for THz communications to compensate propagation losses. However, the cost and power associated with fully digital beamformers of these huge antenna arrays are prohibitive. In this paper, we develop wideband hybrid beamformers based on both model-based and model-free techniques for a new group-of-subarrays (GoSA) ultra-massive MIMO structure in low-THz band. Further, driven by the recent developments to save the spectrum, we propose beamformers for a joint ultra-massive MIMO radar-communications system, wherein the base station serves multi-antenna user equipment (RX), and tracks radar targets by generating multiple beams toward both RX and the targets. We formulate the GoSA beamformer design as an optimization problem to provide a trade-off between the unconstrained communications beamformers and the desired radar beamformers. To mitigate the beam split effect at THz band arising from frequency-independent analog beamformers, we propose a phase correction technique to align the beams of multiple subcarriers toward a single physical direction. To further decrease the ultra-massive MIMO computational complexity and enhance robustness, we also implement deep learning solutions to the proposed model-based hybrid beamformers. Numerical experiments demonstrate that both techniques outperform the conventional approaches in terms of spectral efficiency and radar beampatterns, as well as exhibiting less hardware cost and computation time.

</p>
</details>

<details><summary><b>Automatic evaluation of human oocyte developmental potential from microscopy images</b>
<a href="https://arxiv.org/abs/2103.00302">arxiv:2103.00302</a>
&#x1F4C8; 1 <br>
<p>Denis Baručić, Jan Kybic, Olga Teplá, Zinovij Topurko, Irena Kratochvílová</p></summary>
<p>

**Abstract:** Infertility is becoming an issue for an increasing number of couples. The most common solution, in vitro fertilization, requires embryologists to carefully examine light microscopy images of human oocytes to determine their developmental potential. We propose an automatic system to improve the speed, repeatability, and accuracy of this process. We first localize individual oocytes and identify their principal components using CNN (U-Net) segmentation. Next, we calculate several descriptors based on geometry and texture. The final step is an SVM classifier. Both the segmentation and classification training is based on expert annotations. The presented approach leads to a classification accuracy of 70%.

</p>
</details>

<details><summary><b>A Parameter-free Algorithm for Convex-concave Min-max Problems</b>
<a href="https://arxiv.org/abs/2103.00284">arxiv:2103.00284</a>
&#x1F4C8; 1 <br>
<p>Mingrui Liu, Francesco Orabona</p></summary>
<p>

**Abstract:** Parameter-free optimization algorithms refer to algorithms whose convergence rate is optimal with respect to the initial point without any learning rate to tune. They are proposed and well-studied in the online convex optimization literature. However, all the existing parameter-free algorithms can only be used for convex minimization problems. It remains unclear how to design a parameter-free algorithm for convex-concave min-max problems. In fact, the best known convergence rates of the algorithms for solving these problems depend on the size of the domain, rather than on the distance between initial point and the optimal solution. In this paper, we provide the first parameter-free algorithm for several classes of convex-concave problems and establish corresponding state-of-the-art convergence rates, including strictly-convex-strictly-concave min-max problems and min-max problems with non-Euclidean geometry. As a by-product, we utilize the parameter-free algorithm as a subroutine to design a new algorithm, which obtains fast rates for min-max problems with a growth condition. Extensive experiments are conducted to verify our theoretical findings and demonstrate the effectiveness of the proposed algorithm.

</p>
</details>

<details><summary><b>PA-ResSeg: A Phase Attention Residual Network for Liver Tumor Segmentation from Multi-phase CT Images</b>
<a href="https://arxiv.org/abs/2103.00274">arxiv:2103.00274</a>
&#x1F4C8; 1 <br>
<p>Yingying Xu, Ming Cai, Lanfen Lin, Yue Zhang, Hongjie Hu, Zhiyi Peng, Qiaowei Zhang, Qingqing Chen, Xiongwei Mao, Yutaro Iwamoto, Xian-Hua Han, Yen-Wei Chen, Ruofeng Tong</p></summary>
<p>

**Abstract:** In this paper, we propose a phase attention residual network (PA-ResSeg) to model multi-phase features for accurate liver tumor segmentation, in which a phase attention (PA) is newly proposed to additionally exploit the images of arterial (ART) phase to facilitate the segmentation of portal venous (PV) phase. The PA block consists of an intra-phase attention (Intra-PA) module and an inter-phase attention (Inter-PA) module to capture channel-wise self-dependencies and cross-phase interdependencies, respectively. Thus it enables the network to learn more representative multi-phase features by refining the PV features according to the channel dependencies and recalibrating the ART features based on the learned interdependencies between phases. We propose a PA-based multi-scale fusion (MSF) architecture to embed the PA blocks in the network at multiple levels along the encoding path to fuse multi-scale features from multi-phase images. Moreover, a 3D boundary-enhanced loss (BE-loss) is proposed for training to make the network more sensitive to boundaries. To evaluate the performance of our proposed PA-ResSeg, we conducted experiments on a multi-phase CT dataset of focal liver lesions (MPCT-FLLs). Experimental results show the effectiveness of the proposed method by achieving a dice per case (DPC) of 0.77.87, a dice global (DG) of 0.8682, a volumetric overlap error (VOE) of 0.3328 and a relative volume difference (RVD) of 0.0443 on the MPCT-FLLs. Furthermore, to validate the effectiveness and robustness of PA-ResSeg, we conducted extra experiments on another multi-phase liver tumor dataset and obtained a DPC of 0.8290, a DG of 0.9132, a VOE of 0.2637 and a RVD of 0.0163. The proposed method shows its robustness and generalization capability in different datasets and different backbones.

</p>
</details>

<details><summary><b>Towards Intelligent RAN Slicing for B5G: Opportunities and Challenges</b>
<a href="https://arxiv.org/abs/2103.00227">arxiv:2103.00227</a>
&#x1F4C8; 1 <br>
<p>EmadElDin A Mazied, Lingjia Liu, Scott F. Midkiff</p></summary>
<p>

**Abstract:** To meet the diverse demands for wireless communication, fifth-generation (5G) networks and beyond (B5G) embrace the concept of network slicing by forging virtual instances (slices) of its physical infrastructure. While network slicing constitutes dynamic allocation of core network and radio access network (RAN) resources, this article emphasizes RAN slicing (RAN-S) design. Forming on-demand RAN-S that can be flexibly (re)-configured while ensuring slice isolation is challenging. A variety of machine learning (ML) techniques have been recently introduced for traffic forecasting and classification, resource usage prediction, admission control, scheduling, and dynamic resource allocation in RAN-S. Albeit these approaches grant opportunities towards intelligent RAN-S design, they raise critical challenges that need to be examined. This article underlines the opportunities and the challenges of incorporating ML into RAN-S by reviewing the cutting-edge ML-based techniques for RAN-S. It also draws few directions for future research towards intelligent RAN-S (iRAN-S).

</p>
</details>

<details><summary><b>ProbLP: A framework for low-precision probabilistic inference</b>
<a href="https://arxiv.org/abs/2103.00216">arxiv:2103.00216</a>
&#x1F4C8; 1 <br>
<p>Nimish Shah, Laura I. Galindez Olascoaga, Wannes Meert, Marian Verhelst</p></summary>
<p>

**Abstract:** Bayesian reasoning is a powerful mechanism for probabilistic inference in smart edge-devices. During such inferences, a low-precision arithmetic representation can enable improved energy efficiency. However, its impact on inference accuracy is not yet understood. Furthermore, general-purpose hardware does not natively support low-precision representation. To address this, we propose ProbLP, a framework that automates the analysis and design of low-precision probabilistic inference hardware. It automatically chooses an appropriate energy-efficient representation based on worst-case error-bounds and hardware energy-models. It generates custom hardware for the resulting inference network exploiting parallelism, pipelining and low-precision operation. The framework is validated on several embedded-sensing benchmarks.

</p>
</details>

<details><summary><b>Characterization of Neural Networks Automatically Mapped on Automotive-grade Microcontrollers</b>
<a href="https://arxiv.org/abs/2103.00201">arxiv:2103.00201</a>
&#x1F4C8; 1 <br>
<p>Giulia Crocioni, Giambattista Gruosso, Danilo Pau, Davide Denaro, Luigi Zambrano, Giuseppe di Giore</p></summary>
<p>

**Abstract:** Nowadays, Neural Networks represent a major expectation for the realization of powerful Deep Learning algorithms, which can determine several physical systems' behaviors and operations. Computational resources required for model, training, and running are large, especially when related to the amount of data that Neural Networks typically need to generalize. The latest TinyML technologies allow integrating pre-trained models on embedded systems, allowing making computing at the edge faster, cheaper, and safer. Although these technologies originated in the consumer and industrial worlds, many sectors can greatly benefit from them, such as the automotive industry. In this paper, we present a framework for implementing Neural Network-based models on a family of automotive Microcontrollers, showing their efficiency in two case studies applied to vehicles: intrusion detection on the Controller Area Network bus and residual capacity estimation in Lithium-Ion batteries, widely used in Electric Vehicles.

</p>
</details>

<details><summary><b>Axiomatic Explanations for Visual Search, Retrieval, and Similarity Learning</b>
<a href="https://arxiv.org/abs/2103.00370">arxiv:2103.00370</a>
&#x1F4C8; 0 <br>
<p>Mark Hamilton, Scott Lundberg, Lei Zhang, Stephanie Fu, William T. Freeman</p></summary>
<p>

**Abstract:** Visual search, recommendation, and contrastive similarity learning power a wide breadth of technologies that impact billions of users across the world. The best-performing approaches are often complex and difficult to interpret, and there are several competing techniques one can use to explain a search engine's behavior. We show that the theory of fair credit assignment provides a unique axiomatic solution that generalizes several existing recommendation- and metric-explainability techniques in the literature. Using this formalism, we are able to determine in what regimes existing approaches fall short of fairness and provide variations that are fair in more situations and handle counterfactual information. More specifically, we show existing approaches implicitly approximate second-order Shapley-Taylor indices and use this perspective to extend CAM, GradCAM, LIME, SHAP, SBSM, and other methods to search engines. These extensions can extract pairwise correspondences between images from trained black-box models. We also introduce a fast kernel-based method for estimating Shapley-Taylor indices that require orders of magnitude fewer function evaluations to converge. Finally, we evaluate these methods and show that these game-theoretic measures yield more consistent explanations for image similarity architectures.

</p>
</details>

<details><summary><b>Expert Decision Support System for aeroacoustic source type identification using clustering</b>
<a href="https://arxiv.org/abs/2103.00255">arxiv:2103.00255</a>
&#x1F4C8; 0 <br>
<p>Armin Goudarzi, Carsten Spehr, Steffen Herbold</p></summary>
<p>

**Abstract:** This paper presents an Expert Decision Support System for the identification of time-invariant, aeroacoustic source types. The system comprises two steps: first, acoustic properties are calculated based on spectral and spatial information. Second, clustering is performed based on these properties. The clustering aims at helping and guiding an expert for quick identification of different source types, providing an understanding of how sources differ. This supports the expert in determining similar or atypical behavior. A variety of features are proposed for capturing the characteristics of the sources. These features represent aeroacoustic properties that can be interpreted by both the machine and by experts. The features are independent of the absolute Mach number which enables the proposed method to cluster data measured at different flow configurations. The method is evaluated on deconvolved beamforming data from two scaled airframe half-model measurements. For this exemplary data, the proposed support system method results in clusters that mostly correspond to the source types identified by the authors. The clustering also provides the mean feature values and the cluster hierarchy for each cluster and for each cluster member a clustering confidence. This additional information makes the results transparent and allows the expert to understand the clustering choices.

</p>
</details>


{% endraw %}
Prev: [2021.02.26]({{ '/2021/02/26/2021.02.26.html' | relative_url }})  Next: [2021.02.28]({{ '/2021/02/28/2021.02.28.html' | relative_url }})