Prev: [2022.02.05]({{ '/2022/02/05/2022.02.05.html' | relative_url }})  Next: [2022.02.07]({{ '/2022/02/07/2022.02.07.html' | relative_url }})
{% raw %}
## Summary for 2022-02-06, created on 2022-02-16


<details><summary><b>RECOVER: sequential model optimization platform for combination drug repurposing identifies novel synergistic compounds in vitro</b>
<a href="https://arxiv.org/abs/2202.04202">arxiv:2202.04202</a>
&#x1F4C8; 71 <br>
<p>Paul Bertin, Jarrid Rector-Brooks, Deepak Sharma, Thomas Gaudelet, Andrew Anighoro, Torsten Gross, Francisco Martinez-Pena, Eileen L. Tang, Suraj M S, Cristian Regep, Jeremy Hayter, Maksym Korablyov, Nicholas Valiante, Almer van der Sloot, Mike Tyers, Charles Roberts, Michael M. Bronstein, Luke L. Lairson, Jake P. Taylor-King, Yoshua Bengio</p></summary>
<p>

**Abstract:** Selecting optimal drug repurposing combinations for further preclinical development is a challenging technical feat. Due to the toxicity of many therapeutic agents (e.g., chemotherapy), practitioners have favoured selection of synergistic compounds whereby lower doses can be used whilst maintaining high efficacy. For a fixed small molecule library, an exhaustive combinatorial chemical screen becomes infeasible to perform for academic and industry laboratories alike. Deep learning models have achieved state-of-the-art results in silico for the prediction of synergy scores. However, databases of drug combinations are highly biased towards synergistic agents and these results do not necessarily generalise out of distribution. We employ a sequential model optimization search applied to a deep learning model to quickly discover highly synergistic drug combinations active against a cancer cell line, while requiring substantially less screening than an exhaustive evaluation. Through iteratively adapting the model to newly acquired data, after only 3 rounds of ML-guided experimentation (including a calibration round), we find that the set of combinations queried by our model is enriched for highly synergistic combinations. Remarkably, we rediscovered a synergistic drug combination that was later confirmed to be under study within clinical trials.

</p>
</details>

<details><summary><b>Learning Features with Parameter-Free Layers</b>
<a href="https://arxiv.org/abs/2202.02777">arxiv:2202.02777</a>
&#x1F4C8; 65 <br>
<p>Dongyoon Han, YoungJoon Yoo, Beomyoung Kim, Byeongho Heo</p></summary>
<p>

**Abstract:** Trainable layers such as convolutional building blocks are the standard network design choices by learning parameters to capture the global context through successive spatial operations. When designing an efficient network, trainable layers such as the depthwise convolution is the source of efficiency in the number of parameters and FLOPs, but there was little improvement to the model speed in practice. This paper argues that simple built-in parameter-free operations can be a favorable alternative to the efficient trainable layers replacing spatial operations in a network architecture. We aim to break the stereotype of organizing the spatial operations of building blocks into trainable layers. Extensive experimental analyses based on layer-level studies with fully-trained models and neural architecture searches are provided to investigate whether parameter-free operations such as the max-pool are functional. The studies eventually give us a simple yet effective idea for redesigning network architectures, where the parameter-free operations are heavily used as the main building block without sacrificing the model accuracy as much. Experimental results on the ImageNet dataset demonstrate that the network architectures with parameter-free operations could enjoy the advantages of further efficiency in terms of model speed, the number of the parameters, and FLOPs. Code and ImageNet pretrained models are available at https://github.com/naver-ai/PfLayer.

</p>
</details>

<details><summary><b>CheXstray: Real-time Multi-Modal Data Concordance for Drift Detection in Medical Imaging AI</b>
<a href="https://arxiv.org/abs/2202.02833">arxiv:2202.02833</a>
&#x1F4C8; 21 <br>
<p>Arjun Soin, Jameson Merkow, Jin Long, Joesph Paul Cohen, Smitha Saligrama, Stephen Kaiser, Steven Borg, Ivan Tarapov, Matthew P Lungren</p></summary>
<p>

**Abstract:** Rapidly expanding Clinical AI applications worldwide have the potential to impact to all areas of medical practice. Medical imaging applications constitute a vast majority of approved clinical AI applications. Though healthcare systems are eager to adopt AI solutions a fundamental question remains: \textit{what happens after the AI model goes into production?} We use the CheXpert and PadChest public datasets to build and test a medical imaging AI drift monitoring workflow that tracks data and model drift without contemporaneous ground truth. We simulate drift in multiple experiments to compare model performance with our novel multi-modal drift metric, which uses DICOM metadata, image appearance representation from a variational autoencoder (VAE), and model output probabilities as input. Through experimentation, we demonstrate a strong proxy for ground truth performance using unsupervised distributional shifts in relevant metadata, predicted probabilities, and VAE latent representation. Our key contributions include (1) proof-of-concept for medical imaging drift detection including use of VAE and domain specific statistical methods (2) a multi-modal methodology for measuring and unifying drift metrics (3) new insights into the challenges and solutions for observing deployed medical imaging AI (4) creation of open-source tools enabling others to easily run their own workflows or scenarios. This work has important implications for addressing the translation gap related to continuous medical imaging AI model monitoring in dynamic healthcare environments.

</p>
</details>

<details><summary><b>Deep Learning-Aided Spatial Multiplexing with Index Modulation</b>
<a href="https://arxiv.org/abs/2202.02856">arxiv:2202.02856</a>
&#x1F4C8; 14 <br>
<p>Merve Turhan, Ersin Ozturk, Hakan Ali Cirpan</p></summary>
<p>

**Abstract:** In this paper, deep learning (DL)-aided data detection of spatial multiplexing (SMX) multiple-input multiple-output (MIMO) transmission with index modulation (IM) (Deep-SMX-IM) has been proposed. Deep-SMX-IM has been constructed by combining a zero-forcing (ZF) detector and DL technique. The proposed method uses the significant advantages of DL techniques to learn transmission characteristics of the frequency and spatial domains. Furthermore, thanks to using subblockbased detection provided by IM, Deep-SMX-IM is a straightforward method, which eventually reveals reduced complexity. It has been shown that Deep-SMX-IM has significant error performance gains compared to ZF detector without increasing computational complexity for different system configurations.

</p>
</details>

<details><summary><b>Causal Inference Using Tractable Circuits</b>
<a href="https://arxiv.org/abs/2202.02891">arxiv:2202.02891</a>
&#x1F4C8; 10 <br>
<p>Adnan Darwiche</p></summary>
<p>

**Abstract:** The aim of this paper is to discuss a recent result which shows that probabilistic inference in the presence of (unknown) causal mechanisms can be tractable for models that have traditionally been viewed as intractable. This result was reported recently to facilitate model-based supervised learning but it can be interpreted in a causality context as follows. One can compile a non-parametric causal graph into an arithmetic circuit that supports inference in time linear in the circuit size. The circuit is also non-parametric so it can be used to estimate parameters from data and to further reason (in linear time) about the causal graph parametrized by these estimates. Moreover, the circuit size can sometimes be bounded even when the treewidth of the causal graph is not, leading to tractable inference on models that have been deemed intractable previously. This has been enabled by a new technique that can exploit causal mechanisms computationally but without needing to know their identities (the classical setup in causal inference). Our goal is to provide a causality-oriented exposure to these new results and to speculate on how they may potentially contribute to more scalable and versatile causal inference.

</p>
</details>

<details><summary><b>Anticorrelated Noise Injection for Improved Generalization</b>
<a href="https://arxiv.org/abs/2202.02831">arxiv:2202.02831</a>
&#x1F4C8; 10 <br>
<p>Antonio Orvieto, Hans Kersting, Frank Proske, Francis Bach, Aurelien Lucchi</p></summary>
<p>

**Abstract:** Injecting artificial noise into gradient descent (GD) is commonly employed to improve the performance of machine learning models. Usually, uncorrelated noise is used in such perturbed gradient descent (PGD) methods. It is, however, not known if this is optimal or whether other types of noise could provide better generalization performance. In this paper, we zoom in on the problem of correlating the perturbations of consecutive PGD steps. We consider a variety of objective functions for which we find that GD with anticorrelated perturbations ("Anti-PGD") generalizes significantly better than GD and standard (uncorrelated) PGD. To support these experimental findings, we also derive a theoretical analysis that demonstrates that Anti-PGD moves to wider minima, while GD and PGD remain stuck in suboptimal regions or even diverge. This new connection between anticorrelated noise and generalization opens the field to novel ways to exploit noise for training machine learning models.

</p>
</details>

<details><summary><b>Speech Emotion Recognition using Self-Supervised Features</b>
<a href="https://arxiv.org/abs/2202.03896">arxiv:2202.03896</a>
&#x1F4C8; 7 <br>
<p>Edmilson Morais, Ron Hoory, Weizhong Zhu, Itai Gat, Matheus Damasceno, Hagai Aronowitz</p></summary>
<p>

**Abstract:** Self-supervised pre-trained features have consistently delivered state-of-art results in the field of natural language processing (NLP); however, their merits in the field of speech emotion recognition (SER) still need further investigation. In this paper we introduce a modular End-to- End (E2E) SER system based on an Upstream + Downstream architecture paradigm, which allows easy use/integration of a large variety of self-supervised features. Several SER experiments for predicting categorical emotion classes from the IEMOCAP dataset are performed. These experiments investigate interactions among fine-tuning of self-supervised feature models, aggregation of frame-level features into utterance-level features and back-end classification networks. The proposed monomodal speechonly based system not only achieves SOTA results, but also brings light to the possibility of powerful and well finetuned self-supervised acoustic features that reach results similar to the results achieved by SOTA multimodal systems using both Speech and Text modalities.

</p>
</details>

<details><summary><b>Riemannian Score-Based Generative Modeling</b>
<a href="https://arxiv.org/abs/2202.02763">arxiv:2202.02763</a>
&#x1F4C8; 7 <br>
<p>Valentin De Bortoli, Emile Mathieu, Michael Hutchinson, James Thornton, Yee Whye Teh, Arnaud Doucet</p></summary>
<p>

**Abstract:** Score-based generative models (SGMs) are a novel class of generative models demonstrating remarkable empirical performance. One uses a diffusion to add progressively Gaussian noise to the data, while the generative model is a "denoising" process obtained by approximating the time-reversal of this "noising" diffusion. However, current SGMs make the underlying assumption that the data is supported on a Euclidean manifold with flat geometry. This prevents the use of these models for applications in robotics, geoscience or protein modeling which rely on distributions defined on Riemannian manifolds. To overcome this issue, we introduce Riemannian Score-based Generative Models (RSGMs) which extend current SGMs to the setting of compact Riemannian manifolds. We illustrate our approach with earth and climate science data and show how RSGMs can be accelerated by solving a Schrödinger bridge problem on manifolds.

</p>
</details>

<details><summary><b>Hierarchical Risk Parity and Minimum Variance Portfolio Design on NIFTY 50 Stocks</b>
<a href="https://arxiv.org/abs/2202.02728">arxiv:2202.02728</a>
&#x1F4C8; 7 <br>
<p>Jaydip Sen, Sidra Mehtab, Abhishek Dutta, Saikat Mondal</p></summary>
<p>

**Abstract:** Portfolio design and optimization have been always an area of research that has attracted a lot of attention from researchers from the finance domain. Designing an optimum portfolio is a complex task since it involves accurate forecasting of future stock returns and risks and making a suitable tradeoff between them. This paper proposes a systematic approach to designing portfolios using two algorithms, the critical line algorithm, and the hierarchical risk parity algorithm on eight sectors of the Indian stock market. While the portfolios are designed using the stock price data from Jan 1, 2016, to Dec 31, 2020, they are tested on the data from Jan 1, 2021, to Aug 26, 2021. The backtesting results of the portfolios indicate while the performance of the CLA algorithm is superior on the training data, the HRP algorithm has outperformed the CLA algorithm on the test data.

</p>
</details>

<details><summary><b>Portfolio Optimization on NIFTY Thematic Sector Stocks Using an LSTM Model</b>
<a href="https://arxiv.org/abs/2202.02723">arxiv:2202.02723</a>
&#x1F4C8; 5 <br>
<p>Jaydip Sen, Saikat Mondal, Sidra Mehtab</p></summary>
<p>

**Abstract:** Portfolio optimization has been a broad and intense area of interest for quantitative and statistical finance researchers and financial analysts. It is a challenging task to design a portfolio of stocks to arrive at the optimized values of the return and risk. This paper presents an algorithmic approach for designing optimum risk and eigen portfolios for five thematic sectors of the NSE of India. The prices of the stocks are extracted from the web from Jan 1, 2016, to Dec 31, 2020. Optimum risk and eigen portfolios for each sector are designed based on ten critical stocks from the sector. An LSTM model is designed for predicting future stock prices. Seven months after the portfolios were formed, on Aug 3, 2021, the actual returns of the portfolios are compared with the LSTM-predicted returns. The predicted and the actual returns indicate a very high-level accuracy of the LSTM model.

</p>
</details>

<details><summary><b>A Reliable Data-transmission Mechanism using Blockchain in Edge Computing Scenarios</b>
<a href="https://arxiv.org/abs/2202.03428">arxiv:2202.03428</a>
&#x1F4C8; 4 <br>
<p>Peiying Zhang, Xue Pang, Neeraj Kumar, Gagangeet Singh Aujla, Haotong Cao</p></summary>
<p>

**Abstract:** With the advent of the Internet of things (IoT) era, more and more devices are connected to the IoT. Under the traditional cloud-thing centralized management mode, the transmission of massive data is facing many difficulties, and the reliability of data is difficult to be guaranteed. As emerging technologies, blockchain technology and edge computing (EC) technology have attracted the attention of academia in improving the reliability, privacy and invariability of IoT technology. In this paper, we combine the characteristics of the EC and blockchain to ensure the reliability of data transmission in the IoT. First of all, we propose a data transmission mechanism based on blockchain, which uses the distributed architecture of blockchain to ensure that the data is not tampered with; secondly, we introduce the three-tier structure in the architecture in turn; finally, we introduce the four working steps of the mechanism, which are similar to the working mechanism of blockchain. In the end, the simulation results show that the proposed scheme can ensure the reliability of data transmission in the Internet of things to a great extent.

</p>
</details>

<details><summary><b>On Using Transformers for Speech-Separation</b>
<a href="https://arxiv.org/abs/2202.02884">arxiv:2202.02884</a>
&#x1F4C8; 4 <br>
<p>Cem Subakan, Mirco Ravanelli, Samuele Cornell, Francois Grondin, Mirko Bronzi</p></summary>
<p>

**Abstract:** Transformers have enabled major improvements in deep learning. They often outperform recurrent and convolutional models in many tasks while taking advantage of parallel processing. Recently, we have proposed SepFormer, which uses self-attention and obtains state-of-the art results on WSJ0-2/3 Mix datasets for speech separation. In this paper, we extend our previous work by providing results on more datasets including LibriMix, and WHAM!, WHAMR! which include noisy and noisy-reverberant conditions. Moreover we provide denoising, and denoising+dereverberation results in the context of speech enhancement, respectively on WHAM! and WHAMR! datasets. We also investigate incorporating recently proposed efficient self-attention mechanisms inside the SepFormer model, and show that by using efficient self-attention mechanisms it is possible to reduce the memory requirements significantly while performing better than the popular convtasnet model on WSJ0-2Mix dataset.

</p>
</details>

<details><summary><b>Differentiable Economics for Randomized Affine Maximizer Auctions</b>
<a href="https://arxiv.org/abs/2202.02872">arxiv:2202.02872</a>
&#x1F4C8; 4 <br>
<p>Michael Curry, Tuomas Sandholm, John Dickerson</p></summary>
<p>

**Abstract:** A recent approach to automated mechanism design, differentiable economics, represents auctions by rich function approximators and optimizes their performance by gradient descent. The ideal auction architecture for differentiable economics would be perfectly strategyproof, support multiple bidders and items, and be rich enough to represent the optimal (i.e. revenue-maximizing) mechanism. So far, such an architecture does not exist. There are single-bidder approaches (MenuNet, RochetNet) which are always strategyproof and can represent optimal mechanisms. RegretNet is multi-bidder and can approximate any mechanism, but is only approximately strategyproof. We present an architecture that supports multiple bidders and is perfectly strategyproof, but cannot necessarily represent the optimal mechanism. This architecture is the classic affine maximizer auction (AMA), modified to offer lotteries. By using the gradient-based optimization tools of differentiable economics, we can now train lottery AMAs, competing with or outperforming prior approaches in revenue.

</p>
</details>

<details><summary><b>BEAS: Blockchain Enabled Asynchronous & Secure Federated Machine Learning</b>
<a href="https://arxiv.org/abs/2202.02817">arxiv:2202.02817</a>
&#x1F4C8; 4 <br>
<p>Arup Mondal, Harpreet Virk, Debayan Gupta</p></summary>
<p>

**Abstract:** Federated Learning (FL) enables multiple parties to distributively train a ML model without revealing their private datasets. However, it assumes trust in the centralized aggregator which stores and aggregates model updates. This makes it prone to gradient tampering and privacy leakage by a malicious aggregator. Malicious parties can also introduce backdoors into the joint model by poisoning the training data or model gradients. To address these issues, we present BEAS, the first blockchain-based framework for N-party FL that provides strict privacy guarantees of training data using gradient pruning (showing improved differential privacy compared to existing noise and clipping based techniques). Anomaly detection protocols are used to minimize the risk of data-poisoning attacks, along with gradient pruning that is further used to limit the efficacy of model-poisoning attacks. We also define a novel protocol to prevent premature convergence in heterogeneous learning environments. We perform extensive experiments on multiple datasets with promising results: BEAS successfully prevents privacy leakage from dataset reconstruction attacks, and minimizes the efficacy of poisoning attacks. Moreover, it achieves an accuracy similar to centralized frameworks, and its communication and computation overheads scale linearly with the number of participants.

</p>
</details>

<details><summary><b>A Topology-Attention ConvLSTM Network and Its Application to EM Images</b>
<a href="https://arxiv.org/abs/2202.03430">arxiv:2202.03430</a>
&#x1F4C8; 3 <br>
<p>Jiaqi Yang, Xiaoling Hu, Chao Chen, Chialing Tsai</p></summary>
<p>

**Abstract:** Structural accuracy of segmentation is important for finescale structures in biomedical images. We propose a novel TopologyAttention ConvLSTM Network (TACNet) for 3D image segmentation in order to achieve high structural accuracy for 3D segmentation tasks. Specifically, we propose a Spatial Topology-Attention (STA) module to process a 3D image as a stack of 2D image slices and adopt ConvLSTM to leverage contextual structure information from adjacent slices. In order to effectively transfer topology-critical information across slices, we propose an Iterative-Topology Attention (ITA) module that provides a more stable topology-critical map for segmentation. Quantitative and qualitative results show that our proposed method outperforms various baselines in terms of topology-aware evaluation metrics.

</p>
</details>

<details><summary><b>Performance Evaluation of Infrared Image Enhancement Techniques</b>
<a href="https://arxiv.org/abs/2202.03427">arxiv:2202.03427</a>
&#x1F4C8; 3 <br>
<p>Rania Gaber, AbdElmgied Ali, Kareem Ahmed</p></summary>
<p>

**Abstract:** Infrared (IR) images are widely used in many fields such as medical imaging, object tracking, astronomy and military purposes for securing borders. Infrared images can be captured day or night based on the type of capturing device. The capturing devices use electromagnetic radiation with longer wavelengths. There are several types of IR radiation based on the range of wavelength and corresponding frequency. Due to noising and other artifacts, IR images are not clearly visible. In this paper, we present a complete up-todate survey on IR imaging enhancement techniques. The survey includes IR radiation types and devices and existing IR datasets. The survey covers spatial enhancement techniques, frequency-domain based enhancement techniques and Deep learning-based techniques.

</p>
</details>

<details><summary><b>Dataset Condensation with Contrastive Signals</b>
<a href="https://arxiv.org/abs/2202.02916">arxiv:2202.02916</a>
&#x1F4C8; 3 <br>
<p>Saehyung Lee, Sanghyuk Chun, Sangwon Jung, Sangdoo Yun, Sungroh Yoon</p></summary>
<p>

**Abstract:** Recent studies have demonstrated that gradient matching-based dataset synthesis, or dataset condensation (DC), methods can achieve state-of-the-art performance when applied to data-efficient learning tasks. However, in this study, we prove that the existing DC methods can perform worse than the random selection method when task-irrelevant information forms a significant part of the training dataset. We attribute this to the lack of participation of the contrastive signals between the classes resulting from the class-wise gradient matching strategy. To address this problem, we propose Dataset Condensation with Contrastive signals (DCC) by modifying the loss function to enable the DC methods to effectively capture the differences between classes. In addition, we analyze the new loss function in terms of training dynamics by tracking the kernel velocity. Furthermore, we introduce a bi-level warm-up strategy to stabilize the optimization. Our experimental results indicate that while the existing methods are ineffective for fine-grained image classification tasks, the proposed method can successfully generate informative synthetic datasets for the same tasks. Moreover, we demonstrate that the proposed method outperforms the baselines even on benchmark datasets such as SVHN, CIFAR-10, and CIFAR-100. Finally, we demonstrate the high applicability of the proposed method by applying it to continual learning tasks.

</p>
</details>

<details><summary><b>Inter-subject Contrastive Learning for Subject Adaptive EEG-based Visual Recognition</b>
<a href="https://arxiv.org/abs/2202.02901">arxiv:2202.02901</a>
&#x1F4C8; 3 <br>
<p>Pilhyeon Lee, Sunhee Hwang, Jewook Lee, Minjung Shin, Seogkyu Jeon, Hyeran Byun</p></summary>
<p>

**Abstract:** This paper tackles the problem of subject adaptive EEG-based visual recognition. Its goal is to accurately predict the categories of visual stimuli based on EEG signals with only a handful of samples for the target subject during training. The key challenge is how to appropriately transfer the knowledge obtained from abundant data of source subjects to the subject of interest. To this end, we introduce a novel method that allows for learning subject-independent representation by increasing the similarity of features sharing the same class but coming from different subjects. With the dedicated sampling principle, our model effectively captures the common knowledge shared across different subjects, thereby achieving promising performance for the target subject even under harsh problem settings with limited data. Specifically, on the EEG-ImageNet40 benchmark, our model records the top-1 / top-3 test accuracy of 72.6% / 91.6% when using only five EEG samples per class for the target subject. Our code is available at https://github.com/DeepBCI/Deep-BCI/tree/master/1_Intelligent_BCI/Inter_Subject_Contrastive_Learning_for_EEG.

</p>
</details>

<details><summary><b>A new similarity measure for covariate shift with applications to nonparametric regression</b>
<a href="https://arxiv.org/abs/2202.02837">arxiv:2202.02837</a>
&#x1F4C8; 3 <br>
<p>Reese Pathak, Cong Ma, Martin J. Wainwright</p></summary>
<p>

**Abstract:** We study covariate shift in the context of nonparametric regression. We introduce a new measure of distribution mismatch between the source and target distributions that is based on the integrated ratio of probabilities of balls at a given radius. We use the scaling of this measure with respect to the radius to characterize the minimax rate of estimation over a family of Hölder continuous functions under covariate shift. In comparison to the recently proposed notion of transfer exponent, this measure leads to a sharper rate of convergence and is more fine-grained. We accompany our theory with concrete instances of covariate shift that illustrate this sharp difference.

</p>
</details>

<details><summary><b>Wave-Encoded Model-based Deep Learning for Highly Accelerated Imaging with Joint Reconstruction</b>
<a href="https://arxiv.org/abs/2202.02814">arxiv:2202.02814</a>
&#x1F4C8; 3 <br>
<p>Jaejin Cho, Borjan Gagoski, Taehyung Kim, Qiyuan Tian, Stephen Robert Frost, Itthi Chatnuntawech, Berkin Bilgic</p></summary>
<p>

**Abstract:** Purpose: To propose a wave-encoded model-based deep learning (wave-MoDL) strategy for highly accelerated 3D imaging and joint multi-contrast image reconstruction, and further extend this to enable rapid quantitative imaging using an interleaved look-locker acquisition sequence with T2 preparation pulse (3D-QALAS).
  Method: Recently introduced MoDL technique successfully incorporates convolutional neural network (CNN)-based regularizers into physics-based parallel imaging reconstruction using a small number of network parameters. Wave-CAIPI is an emerging parallel imaging method that accelerates the imaging speed by employing sinusoidal gradients in the phase- and slice-encoding directions during the readout to take better advantage of 3D coil sensitivity profiles. In wave-MoDL, we propose to combine the wave-encoding strategy with unrolled network constraints to accelerate the acquisition speed while enforcing wave-encoded data consistency. We further extend wave-MoDL to reconstruct multi-contrast data with controlled aliasing in parallel imaging (CAIPI) sampling patterns to leverage similarity between multiple images to improve the reconstruction quality.
  Result: Wave-MoDL enables a 47-second MPRAGE acquisition at 1 mm resolution at 16-fold acceleration. For quantitative imaging, wave-MoDL permits a 2-minute acquisition for T1, T2, and proton density mapping at 1 mm resolution at 12-fold acceleration, from which contrast weighted images can be synthesized as well.
  Conclusion: Wave-MoDL allows rapid MR acquisition and high-fidelity image reconstruction and may facilitate clinical and neuroscientific applications by incorporating unrolled neural networks into wave-CAIPI reconstruction.

</p>
</details>

<details><summary><b>Memory Efficient Tries for Sequential Pattern Mining</b>
<a href="https://arxiv.org/abs/2202.06834">arxiv:2202.06834</a>
&#x1F4C8; 2 <br>
<p>Amin Hosseininasab, Willem-Jan van Hoeve, Andre A. Cire</p></summary>
<p>

**Abstract:** The rapid and continuous growth of data has increased the need for scalable mining algorithms in unsupervised learning and knowledge discovery. In this paper, we focus on Sequential Pattern Mining (SPM), a fundamental topic in knowledge discovery that faces a well-known memory bottleneck. We examine generic dataset modeling techniques and show how they can be used to improve SPM algorithms in time and memory usage. In particular, we develop trie-based dataset models and associated mining algorithms that can represent as well as effectively mine orders of magnitude larger datasets compared to the state of the art. Numerical results on real-life large-size test instances show that our algorithms are also faster and more memory efficient in practice.

</p>
</details>

<details><summary><b>Towards Micro-video Thumbnail Selection via a Multi-label Visual-semantic Embedding Model</b>
<a href="https://arxiv.org/abs/2202.02930">arxiv:2202.02930</a>
&#x1F4C8; 2 <br>
<p>Liu Bo</p></summary>
<p>

**Abstract:** The thumbnail, as the first sight of a micro-video, plays a pivotal role in attracting users to click and watch. While in the real scenario, the more the thumbnails satisfy the users, the more likely the micro-videos will be clicked. In this paper, we aim to select the thumbnail of a given micro-video that meets most users` interests. Towards this end, we present a multi-label visual-semantic embedding model to estimate the similarity between the pair of each frame and the popular topics that users are interested in. In this model, the visual and textual information is embedded into a shared semantic space, whereby the similarity can be measured directly, even the unseen words. Moreover, to compare the frame to all words from the popular topics, we devise an attention embedding space associated with the semantic-attention projection. With the help of these two embedding spaces, the popularity score of a frame, which is defined by the sum of similarity scores over the corresponding visual information and popular topic pairs, is achieved. Ultimately, we fuse the visual representation score and the popularity score of each frame to select the attractive thumbnail for the given micro-video. Extensive experiments conducted on a real-world dataset have well-verified that our model significantly outperforms several state-of-the-art baselines.

</p>
</details>

<details><summary><b>Soft Actor-Critic with Inhibitory Networks for Faster Retraining</b>
<a href="https://arxiv.org/abs/2202.02918">arxiv:2202.02918</a>
&#x1F4C8; 2 <br>
<p>Jaime S. Ide, Daria Mićović, Michael J. Guarino, Kevin Alcedo, David Rosenbluth, Adrian P. Pope</p></summary>
<p>

**Abstract:** Reusing previously trained models is critical in deep reinforcement learning to speed up training of new agents. However, it is unclear how to acquire new skills when objectives and constraints are in conflict with previously learned skills. Moreover, when retraining, there is an intrinsic conflict between exploiting what has already been learned and exploring new skills. In soft actor-critic (SAC) methods, a temperature parameter can be dynamically adjusted to weight the action entropy and balance the explore $\times$ exploit trade-off. However, controlling a single coefficient can be challenging within the context of retraining, even more so when goals are contradictory. In this work, inspired by neuroscience research, we propose a novel approach using inhibitory networks to allow separate and adaptive state value evaluations, as well as distinct automatic entropy tuning. Ultimately, our approach allows for controlling inhibition to handle conflict between exploiting less risky, acquired behaviors and exploring novel ones to overcome more challenging tasks. We validate our method through experiments in OpenAI Gym environments.

</p>
</details>

<details><summary><b>Universality of parametric Coupling Flows over parametric diffeomorphisms</b>
<a href="https://arxiv.org/abs/2202.02906">arxiv:2202.02906</a>
&#x1F4C8; 2 <br>
<p>Junlong Lyu, Zhitang Chen, Chang Feng, Wenjing Cun, Shengyu Zhu, Yanhui Geng, Zhijie Xu, Yongwei Chen</p></summary>
<p>

**Abstract:** Invertible neural networks based on Coupling Flows CFlows) have various applications such as image synthesis and data compression. The approximation universality for CFlows is of paramount importance to ensure the model expressiveness. In this paper, we prove that CFlows can approximate any diffeomorphism in C^k-norm if its layers can approximate certain single-coordinate transforms. Specifically, we derive that a composition of affine coupling layers and invertible linear transforms achieves this universality. Furthermore, in parametric cases where the diffeomorphism depends on some extra parameters, we prove the corresponding approximation theorems for our proposed parametric coupling flows named Para-CFlows. In practice, we apply Para-CFlows as a neural surrogate model in contextual Bayesian optimization tasks, to demonstrate its superiority over other neural surrogate models in terms of optimization performance.

</p>
</details>

<details><summary><b>Redactor: Targeted Disinformation Generation using Probabilistic Decision Boundaries</b>
<a href="https://arxiv.org/abs/2202.02902">arxiv:2202.02902</a>
&#x1F4C8; 2 <br>
<p>Geon Heo, Steven Euijong Whang</p></summary>
<p>

**Abstract:** Information leakage is becoming a critical problem as various information becomes publicly available by mistake, and machine learning models train on that data to provide services. As a result, one's private information could easily be memorized by such trained models. Unfortunately, deleting information is out of the question as the data is already exposed to the Web or third-party platforms. Moreover, we cannot necessarily control the labeling process and the model trainings by other parties either. In this setting, we study the problem of targeted disinformation where the goal is to lower the accuracy of inference attacks on a specific target (e.g., a person's profile) only using data insertion. While our problem is related to data privacy and defenses against exploratory attacks, our techniques are inspired by targeted data poisoning attacks with some key differences. We show that our problem is best solved by finding the closest points to the target in the input space that will be labeled as a different class. Since we do not control the labeling process, we instead conservatively estimate the labels probabilistically by combining decision boundaries of multiple classifiers using data programming techniques. We also propose techniques for making the disinformation realistic. Our experiments show that a probabilistic decision boundary can be a good proxy for labelers, and that our approach outperforms other targeted poisoning methods when using end-to-end training on real datasets.

</p>
</details>

<details><summary><b>Evaluation Methods and Measures for Causal Learning Algorithms</b>
<a href="https://arxiv.org/abs/2202.02896">arxiv:2202.02896</a>
&#x1F4C8; 2 <br>
<p>Lu Cheng, Ruocheng Guo, Raha Moraffah, Paras Sheth, K. Selcuk Candan, Huan Liu</p></summary>
<p>

**Abstract:** The convenient access to copious multi-faceted data has encouraged machine learning researchers to reconsider correlation-based learning and embrace the opportunity of causality-based learning, i.e., causal machine learning (causal learning). Recent years have therefore witnessed great effort in developing causal learning algorithms aiming to help AI achieve human-level intelligence. Due to the lack-of ground-truth data, one of the biggest challenges in current causal learning research is algorithm evaluations. This largely impedes the cross-pollination of AI and causal inference, and hinders the two fields to benefit from the advances of the other. To bridge from conventional causal inference (i.e., based on statistical methods) to causal learning with big data (i.e., the intersection of causal inference and machine learning), in this survey, we review commonly-used datasets, evaluation methods, and measures for causal learning using an evaluation pipeline similar to conventional machine learning. We focus on the two fundamental causal-inference tasks and causality-aware machine learning tasks. Limitations of current evaluation procedures are also discussed. We then examine popular causal inference tools/packages and conclude with primary challenges and opportunities for benchmarking causal learning algorithms in the era of big data. The survey seeks to bring to the forefront the urgency of developing publicly available benchmarks and consensus-building standards for causal learning evaluation with observational data. In doing so, we hope to broaden the discussions and facilitate collaboration to advance the innovation and application of causal learning.

</p>
</details>

<details><summary><b>Trusted Approximate Policy Iteration with Bisimulation Metrics</b>
<a href="https://arxiv.org/abs/2202.02881">arxiv:2202.02881</a>
&#x1F4C8; 2 <br>
<p>Mete Kemertas, Allan Jepson</p></summary>
<p>

**Abstract:** Bisimulation metrics define a distance measure between states of a Markov decision process (MDP) based on a comparison of reward sequences. Due to this property they provide theoretical guarantees in value function approximation. In this work we first prove that bisimulation metrics can be defined via any $p$-Wasserstein metric for $p\geq 1$. Then we describe an approximate policy iteration (API) procedure that uses $ε$-aggregation with $π$-bisimulation and prove performance bounds for continuous state spaces. We bound the difference between $π$-bisimulation metrics in terms of the change in the policies themselves. Based on these theoretical results, we design an API($α$) procedure that employs conservative policy updates and enjoys better performance bounds than the naive API approach. In addition, we propose a novel trust region approach which circumvents the requirement to explicitly solve a constrained optimization problem. Finally, we provide experimental evidence of improved stability compared to non-conservative alternatives in simulated continuous control.

</p>
</details>

<details><summary><b>HARFE: Hard-Ridge Random Feature Expansion</b>
<a href="https://arxiv.org/abs/2202.02877">arxiv:2202.02877</a>
&#x1F4C8; 2 <br>
<p>Esha Saha, Hayden Schaeffer, Giang Tran</p></summary>
<p>

**Abstract:** We propose a random feature model for approximating high-dimensional sparse additive functions called the hard-ridge random feature expansion method (HARFE). This method utilizes a hard-thresholding pursuit-based algorithm applied to the sparse ridge regression (SRR) problem to approximate the coefficients with respect to the random feature matrix. The SRR formulation balances between obtaining sparse models that use fewer terms in their representation and ridge-based smoothing that tend to be robust to noise and outliers. In addition, we use a random sparse connectivity pattern in the random feature matrix to match the additive function assumption. We prove that the HARFE method is guaranteed to converge with a given error bound depending on the noise and the parameters of the sparse ridge regression model. Based on numerical results on synthetic data as well as on real datasets, the HARFE approach obtains lower (or comparable) error than other state-of-the-art algorithms.

</p>
</details>

<details><summary><b>Deep Convolutional Learning-Aided Detector for Generalized Frequency Division Multiplexing with Index Modulation</b>
<a href="https://arxiv.org/abs/2202.02876">arxiv:2202.02876</a>
&#x1F4C8; 2 <br>
<p>Merve Turhan, Ersin Öztürk, Hakan Ali Çırpan</p></summary>
<p>

**Abstract:** In this paper, a deep convolutional neural network-based symbol detection and demodulation is proposed for generalized frequency division multiplexing with index modulation (GFDM-IM) scheme in order to improve the error performance of the system. The proposed method first pre-processes the received signal by using a zero-forcing (ZF) detector and then uses a neural network consisting of a convolutional neural network (CNN) followed by a fully-connected neural network (FCNN). The FCNN part uses only two fully-connected layers, which can be adapted to yield a trade-off between complexity and bit error rate (BER) performance. This two-stage approach prevents the getting stuck of neural network in a saddle point and enables IM blocks processing independently. It has been demonstrated that the proposed deep convolutional neural network-based detection and demodulation scheme provides better BER performance compared to ZF detector with a reasonable complexity increase. We conclude that non-orthogonal waveforms combined with IM schemes with the help of deep learning is a promising physical layer (PHY) scheme for future wireless networks

</p>
</details>

<details><summary><b>Evaluating natural language processing models with generalization metrics that do not need access to any training or testing data</b>
<a href="https://arxiv.org/abs/2202.02842">arxiv:2202.02842</a>
&#x1F4C8; 2 <br>
<p>Yaoqing Yang, Ryan Theisen, Liam Hodgkinson, Joseph E. Gonzalez, Kannan Ramchandran, Charles H. Martin, Michael W. Mahoney</p></summary>
<p>

**Abstract:** The search for effective and robust generalization metrics has been the focus of recent theoretical and empirical work.
  In this paper, we discuss the performance of natural language processing (NLP) models, and we evaluate various existing and novel generalization metrics.
  Compared to prior studies, we
  (i) focus on NLP instead of computer vision (CV),
  (ii) focus on generalization metrics that predict test error instead of the generalization gap,
  (iii) focus on generalization metrics that do not need the access to data, and
  (iv) focus on the heavy-tail (HT) phenomenon that has received comparatively less attention in the study of deep neural networks (NNs).
  We extend recent HT-based work which focuses on power law (PL) distributions, and we study exponential (EXP) and exponentially truncated power law (E-TPL) fitting to the empirical spectral densities (ESDs) of weight matrices.
  Our detailed empirical studies show that
  (i) \emph{shape metrics}, or the metrics obtained from fitting the shape of the ESDs, perform uniformly better at predicting generalization performance than \emph{scale metrics} commonly studied in the literature, as measured by the \emph{average} rank correlations with the generalization performance for all of our experiments;
  (ii) among forty generalization metrics studied in our paper, the \RANDDISTANCE metric, a new shape metric invented in this paper that measures the distance between empirical eigenvalues of weight matrices and those of randomly initialized weight matrices, achieves the highest worst-case rank correlation with generalization performance under a variety of training settings; and
  (iii) among the three HT distributions considered in our paper, the E-TPL fitting of ESDs performs the most robustly.

</p>
</details>

<details><summary><b>Discovering Personalized Semantics for Soft Attributes in Recommender Systems using Concept Activation Vectors</b>
<a href="https://arxiv.org/abs/2202.02830">arxiv:2202.02830</a>
&#x1F4C8; 2 <br>
<p>Christina Göpfert, Yinlam Chow, Chih-wei Hsu, Ivan Vendrov, Tyler Lu, Deepak Ramachandran, Craig Boutilier</p></summary>
<p>

**Abstract:** Interactive recommender systems (RSs) allow users to express intent, preferences and contexts in a rich fashion, often using natural language. One challenge in using such feedback is inferring a user's semantic intent from the open-ended terms used to describe an item, and using it to refine recommendation results. Leveraging concept activation vectors (CAVs) [21], we develop a framework to learn a representation that captures the semantics of such attributes and connects them to user preferences and behaviors in RSs. A novel feature of our approach is its ability to distinguish objective and subjective attributes and associate different senses with different users. Using synthetic and real-world datasets, we show that our CAV representation accurately interprets users' subjective semantics, and can improve recommendations via interactive critiquing

</p>
</details>

<details><summary><b>Block shuffling learning for Deepfake Detection</b>
<a href="https://arxiv.org/abs/2202.02819">arxiv:2202.02819</a>
&#x1F4C8; 2 <br>
<p>Sitong Liu, Zhichao Lian, Siqi Gu, Liang Xiao</p></summary>
<p>

**Abstract:** Although the deepfake detection based on convolutional neural network has achieved good results, the detection results show that these detectors show obvious performance degradation when the input images undergo some common transformations (like resizing, blurring), which indicates that the generalization ability of the detector is insufficient. In this paper, we propose a novel block shuffling learning method to solve this problem. Specifically, we divide the images into blocks and then introduce the random shuffling to intra-block and inter-block. Intra-block shuffling increases the robustness of the detector and we also propose an adversarial loss algorithm to overcome the over-fitting problem brought by the noise introduced by shuffling. Moreover, we encourage the detector to focus on finding differences among the local features through inter-block shuffling, and reconstruct the spatial layout of the blocks to model the semantic associations between them. Especially, our method can be easily integrated with various CNN models. Extensive experiments show that our proposed method achieves state-of-the-art performance in forgery face detection, including good generalization ability in the face of common image transformations.

</p>
</details>

<details><summary><b>Low-confidence Samples Matter for Domain Adaptation</b>
<a href="https://arxiv.org/abs/2202.02802">arxiv:2202.02802</a>
&#x1F4C8; 2 <br>
<p>Yixin Zhang, Junjie Li, Zilei Wang</p></summary>
<p>

**Abstract:** Domain adaptation (DA) aims to transfer knowledge from a label-rich source domain to a related but label-scarce target domain. The conventional DA strategy is to align the feature distributions of the two domains. Recently, increasing researches have focused on self-training or other semi-supervised algorithms to explore the data structure of the target domain. However, the bulk of them depend largely on confident samples in order to build reliable pseudo labels, prototypes or cluster centers. Representing the target data structure in such a way would overlook the huge low-confidence samples, resulting in sub-optimal transferability that is biased towards the samples similar to the source domain. To overcome this issue, we propose a novel contrastive learning method by processing low-confidence samples, which encourages the model to make use of the target data structure through the instance discrimination process. To be specific, we create positive and negative pairs only using low-confidence samples, and then re-represent the original features with the classifier weights rather than directly utilizing them, which can better encode the task-specific semantic information. Furthermore, we combine cross-domain mixup to augment the proposed contrastive loss. Consequently, the domain gap can be well bridged through contrastive learning of intermediate representations across domains. We evaluate the proposed method in both unsupervised and semi-supervised DA settings, and extensive experimental results on benchmarks reveal that our method is effective and achieves state-of-the-art performance. The code can be found in https://github.com/zhyx12/MixLRCo.

</p>
</details>

<details><summary><b>SFMGNet: A Physics-based Neural Network To Predict Pedestrian Trajectories</b>
<a href="https://arxiv.org/abs/2202.02791">arxiv:2202.02791</a>
&#x1F4C8; 2 <br>
<p>Sakif Hossain, Fatema T. Johora, Jörg P. Müller, Sven Hartmann, Andreas Reinhardt</p></summary>
<p>

**Abstract:** Autonomous robots and vehicles are expected to soon become an integral part of our environment. Unsatisfactory issues regarding interaction with existing road users, performance in mixed-traffic areas and lack of interpretable behavior remain key obstacles. To address these, we present a physics-based neural network, based on a hybrid approach combining a social force model extended by group force (SFMG) with Multi-Layer Perceptron (MLP) to predict pedestrian trajectories considering its interaction with static obstacles, other pedestrians and pedestrian groups. We quantitatively and qualitatively evaluate the model with respect to realistic prediction, prediction performance and prediction "interpretability". Initial results suggest, the model even when solely trained on a synthetic dataset, can predict realistic and interpretable trajectories with better than state-of-the-art accuracy.

</p>
</details>

<details><summary><b>Learning Synthetic Environments and Reward Networks for Reinforcement Learning</b>
<a href="https://arxiv.org/abs/2202.02790">arxiv:2202.02790</a>
&#x1F4C8; 2 <br>
<p>Fabio Ferreira, Thomas Nierhoff, Andreas Saelinger, Frank Hutter</p></summary>
<p>

**Abstract:** We introduce Synthetic Environments (SEs) and Reward Networks (RNs), represented by neural networks, as proxy environment models for training Reinforcement Learning (RL) agents. We show that an agent, after being trained exclusively on the SE, is able to solve the corresponding real environment. While an SE acts as a full proxy to a real environment by learning about its state dynamics and rewards, an RN is a partial proxy that learns to augment or replace rewards. We use bi-level optimization to evolve SEs and RNs: the inner loop trains the RL agent, and the outer loop trains the parameters of the SE / RN via an evolution strategy. We evaluate our proposed new concept on a broad range of RL algorithms and classic control environments. In a one-to-one comparison, learning an SE proxy requires more interactions with the real environment than training agents only on the real environment. However, once such an SE has been learned, we do not need any interactions with the real environment to train new agents. Moreover, the learned SE proxies allow us to train agents with fewer interactions while maintaining the original task performance. Our empirical results suggest that SEs achieve this result by learning informed representations that bias the agents towards relevant states. Moreover, we find that these proxies are robust against hyperparameter variation and can also transfer to unseen agents.

</p>
</details>

<details><summary><b>Energy awareness in low precision neural networks</b>
<a href="https://arxiv.org/abs/2202.02783">arxiv:2202.02783</a>
&#x1F4C8; 2 <br>
<p>Nurit Spingarn Eliezer, Ron Banner, Elad Hoffer, Hilla Ben-Yaakov, Tomer Michaeli</p></summary>
<p>

**Abstract:** Power consumption is a major obstacle in the deployment of deep neural networks (DNNs) on end devices. Existing approaches for reducing power consumption rely on quite general principles, including avoidance of multiplication operations and aggressive quantization of weights and activations. However, these methods do not take into account the precise power consumed by each module in the network, and are therefore not optimal. In this paper we develop accurate power consumption models for all arithmetic operations in the DNN, under various working conditions. We reveal several important factors that have been overlooked to date. Based on our analysis, we present PANN (power-aware neural network), a simple approach for approximating any full-precision network by a low-power fixed-precision variant. Our method can be applied to a pre-trained network, and can also be used during training to achieve improved performance. In contrast to previous methods, PANN incurs only a minor degradation in accuracy w.r.t. the full-precision version of the network, even when working at the power-budget of a 2-bit quantized variant. In addition, our scheme enables to seamlessly traverse the power-accuracy trade-off at deployment time, which is a major advantage over existing quantization methods that are constrained to specific bit widths.

</p>
</details>

<details><summary><b>Human rights, democracy, and the rule of law assurance framework for AI systems: A proposal</b>
<a href="https://arxiv.org/abs/2202.02776">arxiv:2202.02776</a>
&#x1F4C8; 2 <br>
<p>David Leslie, Christopher Burr, Mhairi Aitken, Michael Katell, Morgan Briggs, Cami Rincon</p></summary>
<p>

**Abstract:** Following on from the publication of its Feasibility Study in December 2020, the Council of Europe's Ad Hoc Committee on Artificial Intelligence (CAHAI) and its subgroups initiated efforts to formulate and draft its Possible Elements of a Legal Framework on Artificial Intelligence, based on the Council of Europe's standards on human rights, democracy, and the rule of law. This document was ultimately adopted by the CAHAI plenary in December 2021. To support this effort, The Alan Turing Institute undertook a programme of research that explored the governance processes and practical tools needed to operationalise the integration of human right due diligence with the assurance of trustworthy AI innovation practices.
  The resulting framework was completed and submitted to the Council of Europe in September 2021. It presents an end-to-end approach to the assurance of AI project lifecycles that integrates context-based risk analysis and appropriate stakeholder engagement with comprehensive impact assessment, and transparent risk management, impact mitigation, and innovation assurance practices. Taken together, these interlocking processes constitute a Human Rights, Democracy and the Rule of Law Assurance Framework (HUDERAF). The HUDERAF combines the procedural requirements for principles-based human rights due diligence with the governance mechanisms needed to set up technical and socio-technical guardrails for responsible and trustworthy AI innovation practices. Its purpose is to provide an accessible and user-friendly set of mechanisms for facilitating compliance with a binding legal framework on artificial intelligence, based on the Council of Europe's standards on human rights, democracy, and the rule of law, and to ensure that AI innovation projects are carried out with appropriate levels of public accountability, transparency, and democratic governance.

</p>
</details>

<details><summary><b>On Smart Gaze based Annotation of Histopathology Images for Training of Deep Convolutional Neural Networks</b>
<a href="https://arxiv.org/abs/2202.02764">arxiv:2202.02764</a>
&#x1F4C8; 2 <br>
<p>Komal Mariam, Osama Mohammed Afzal, Wajahat Hussain, Muhammad Umar Javed, Amber Kiyani, Nasir Rajpoot, Syed Ali Khurram, Hassan Aqeel Khan</p></summary>
<p>

**Abstract:** Unavailability of large training datasets is a bottleneck that needs to be overcome to realize the true potential of deep learning in histopathology applications. Although slide digitization via whole slide imaging scanners has increased the speed of data acquisition, labeling of virtual slides requires a substantial time investment from pathologists. Eye gaze annotations have the potential to speed up the slide labeling process. This work explores the viability and timing comparisons of eye gaze labeling compared to conventional manual labeling for training object detectors. Challenges associated with gaze based labeling and methods to refine the coarse data annotations for subsequent object detection are also discussed. Results demonstrate that gaze tracking based labeling can save valuable pathologist time and delivers good performance when employed for training a deep object detector. Using the task of localization of Keratin Pearls in cases of oral squamous cell carcinoma as a test case, we compare the performance gap between deep object detectors trained using hand-labelled and gaze-labelled data. On average, compared to `Bounding-box' based hand-labeling, gaze-labeling required $57.6\%$ less time per label and compared to `Freehand' labeling, gaze-labeling required on average $85\%$ less time per label.

</p>
</details>

<details><summary><b>Energy-Aware Edge Association for Cluster-based Personalized Federated Learning</b>
<a href="https://arxiv.org/abs/2202.02727">arxiv:2202.02727</a>
&#x1F4C8; 2 <br>
<p>Y. Li, X. Qin, H. Chen, K. Han, P. Zhang</p></summary>
<p>

**Abstract:** Federated Learning (FL) over wireless network enables data-conscious services by leveraging the ubiquitous intelligence at network edge for privacy-preserving model training. As the proliferation of context-aware services, the diversified personal preferences causes disagreeing conditional distributions among user data, which leads to poor inference performance. In this sense, clustered federated learning is proposed to group user devices with similar preference and provide each cluster with a personalized model. This calls for innovative design in edge association that involves user clustering and also resource management optimization. We formulate an accuracy-cost trade-off optimization problem by jointly considering model accuracy, communication resource allocation and energy consumption. To comply with parameter encryption techniques in FL, we propose an iterative solution procedure which employs deep reinforcement learning based approach at cloud server for edge association. The reward function consists of minimized energy consumption at each base station and the averaged model accuracy of all users. Under our proposed solution, multiple edge base station are fully exploited to realize cost efficient personalized federated learning without any prior knowledge on model parameters. Simulation results show that our proposed strategy outperforms existing strategies in achieving accurate learning at low energy cost.

</p>
</details>

<details><summary><b>A Multi-Domain VNE Algorithm based on Load Balancing in the IoT networks</b>
<a href="https://arxiv.org/abs/2202.05667">arxiv:2202.05667</a>
&#x1F4C8; 1 <br>
<p>Peiying Zhang, Fanglin Liu, Chunxiao Jiang, Abderrahim Benslimane, Juan-Luis Gorricho, Joan Serrat-Fernacute</p></summary>
<p>

**Abstract:** Virtual network embedding is one of the key problems of network virtualization. Since virtual network mapping is an NP-hard problem, a lot of research has focused on the evolutionary algorithm's masterpiece genetic algorithm. However, the parameter setting in the traditional method is too dependent on experience, and its low flexibility makes it unable to adapt to increasingly complex network environments. In addition, link-mapping strategies that do not consider load balancing can easily cause link blocking in high-traffic environments. In the IoT environment involving medical, disaster relief, life support and other equipment, network performance and stability are particularly important. Therefore, how to provide a more flexible virtual network mapping service in a heterogeneous network environment with large traffic is an urgent problem. Aiming at this problem, a virtual network mapping strategy based on hybrid genetic algorithm is proposed. This strategy uses a dynamically calculated cross-probability and pheromone-based mutation gene selection strategy to improve the flexibility of the algorithm. In addition, a weight update mechanism based on load balancing is introduced to reduce the probability of mapping failure while balancing the load. Simulation results show that the proposed method performs well in a number of performance metrics including mapping average quotation, link load balancing, mapping cost-benefit ratio, acceptance rate and running time.

</p>
</details>

<details><summary><b>SUMO: Advanced sleep spindle identification with neural networks</b>
<a href="https://arxiv.org/abs/2202.05158">arxiv:2202.05158</a>
&#x1F4C8; 1 <br>
<p>Lars Kaulen, Justus T. C. Schwabedal, Jules Schneider, Philipp Ritter, Stephan Bialonski</p></summary>
<p>

**Abstract:** Sleep spindles are neurophysiological phenomena that appear to be linked to memory formation and other functions of the central nervous system, and that can be observed in electroencephalographic recordings (EEG) during sleep. Manually identified spindle annotations in EEG recordings suffer from substantial intra- and inter-rater variability, even if raters have been highly trained, which reduces the reliability of spindle measures as a research and diagnostic tool. The Massive Online Data Annotation (MODA) project has recently addressed this problem by forming a consensus from multiple such rating experts, thus providing a corpus of spindle annotations of enhanced quality. Based on this dataset, we present a U-Net-type deep neural network model to automatically detect sleep spindles. Our model's performance exceeds that of the state-of-the-art detector and of most experts in the MODA dataset. We observed improved detection accuracy in subjects of all ages, including older individuals whose spindles are particularly challenging to detect reliably. Our results underline the potential of automated methods to do repetitive cumbersome tasks with super-human performance.

</p>
</details>

<details><summary><b>The application of Evolutionary and Nature Inspired Algorithms in Data Science and Data Analytics</b>
<a href="https://arxiv.org/abs/2202.03859">arxiv:2202.03859</a>
&#x1F4C8; 1 <br>
<p>Farid Ghareh Mohammadi, Farzan Shenavarmasouleh, Khaled Rasheed, Thiab Taha, M. Hadi Amini, Hamid R. Arabnia</p></summary>
<p>

**Abstract:** In the past 30 years, scientists have searched nature, including animals and insects, and biology in order to discover, understand, and model solutions for solving large-scale science challenges. The study of bionics reveals that how the biological structures, functions found in nature have improved our modern technologies. In this study, we present our discovery of evolutionary and nature-inspired algorithms applications in Data Science and Data Analytics in three main topics of pre-processing, supervised algorithms, and unsupervised algorithms. Among all applications, in this study, we aim to investigate four optimization algorithms that have been performed using the evolutionary and nature-inspired algorithms within data science and analytics. Feature selection optimization in pre-processing section, Hyper-parameter tuning optimization, and knowledge discovery optimization in supervised algorithms, and clustering optimization in the unsupervised algorithms.

</p>
</details>

<details><summary><b>VNE Strategy based on Chaotic Hybrid Flower Pollination Algorithm Considering Multi-criteria Decision Making</b>
<a href="https://arxiv.org/abs/2202.03429">arxiv:2202.03429</a>
&#x1F4C8; 1 <br>
<p>Peiying Zhang, Fanglin Liu, Gagangeet Singh Aujla, Sahil Vashist</p></summary>
<p>

**Abstract:** With the development of science and technology and the need for Multi-Criteria Decision-Making (MCDM), the optimization problem to be solved becomes extremely complex. The theoretically accurate and optimal solutions are often difficult to obtain. Therefore, meta-heuristic algorithms based on multi-point search have received extensive attention. Aiming at these problems, the design strategy of hybrid flower pollination algorithm for Virtual Network Embedding (VNE) problem is discussed. Combining the advantages of the Genetic Algorithm (GA) and FPA, the algorithm is optimized for the characteristics of discrete optimization problems. The cross operation is used to replace the cross-pollination operation to complete the global search and replace the mutation operation with self-pollination operation to enhance the ability of local search. Moreover, a life cycle mechanism is introduced as a complement to the traditional fitness-based selection strategy to avoid premature convergence. A chaotic optimization strategy is introduced to replace the random sequence-guided crossover process to strengthen the global search capability and reduce the probability of producing invalid individuals.

</p>
</details>

<details><summary><b>ABG: A Multi-Party Mixed Protocol Framework for Privacy-Preserving Cooperative Learning</b>
<a href="https://arxiv.org/abs/2202.02928">arxiv:2202.02928</a>
&#x1F4C8; 1 <br>
<p>Hao Wang, Zhi Li, Chunpeng Ge, Willy Susilo</p></summary>
<p>

**Abstract:** Cooperative learning, that enables two or more data owners to jointly train a model, has been widely adopted to solve the problem of insufficient training data in machine learning. Nowadays, there is an urgent need for institutions and organizations to train a model cooperatively while keeping each other's data privately. To address the issue of privacy-preserving in collaborative learning, secure outsourced computation and federated learning are two typical methods. Nevertheless, there are many drawbacks for these two methods when they are leveraged in cooperative learning. For secure outsourced computation, semi-honest servers need to be introduced. Once the outsourced servers collude or perform other active attacks, the privacy of data will be disclosed. For federated learning, it is difficult to apply to the scenarios where vertically partitioned data are distributed over multiple parties. In this work, we propose a multi-party mixed protocol framework, ABG$^n$, which effectively implements arbitrary conversion between Arithmetic sharing (A), Boolean sharing (B) and Garbled-Circuits sharing (G) for $n$-party scenarios. Based on ABG$^n$, we design a privacy-preserving multi-party cooperative learning system, which allows different data owners to cooperate in machine learning in terms of data security and privacy-preserving. Additionally, we design specific privacy-preserving computation protocols for some typical machine learning methods such as logistic regression and neural networks. Compared with previous work, the proposed method has a wider scope of application and does not need to rely on additional servers. Finally, we evaluate the performance of ABG$^n$ on the local setting and on the public cloud setting. The experiments indicate that ABG$^n$ has excellent performance, especially in the network environment with low latency.

</p>
</details>

<details><summary><b>Learning under Storage and Privacy Constraints</b>
<a href="https://arxiv.org/abs/2202.02892">arxiv:2202.02892</a>
&#x1F4C8; 1 <br>
<p>Berivan Isik, Tsachy Weissman</p></summary>
<p>

**Abstract:** Storage-efficient privacy-guaranteed learning is crucial due to enormous amounts of sensitive user data required for increasingly many learning tasks. We propose a framework for reducing the storage cost while at the same time providing privacy guarantees, without essential loss in the utility of the data for learning. Our method comprises noise injection followed by lossy compression. We show that, when appropriately matching the lossy compression to the distribution of the added noise, the compressed examples converge, in distribution, to that of the noise-free training data. In this sense, the utility of the data for learning is essentially maintained, while reducing storage and privacy leakage by quantifiable amounts. We present experimental results on the CelebA dataset for gender classification and find that our suggested pipeline delivers in practice on the promise of the theory: the individuals in the images are unrecognizable (or less recognizable, depending on the noise level), overall storage of the data is substantially reduced, with no essential loss of the classification accuracy. As an added bonus, our experiments suggest that our method yields a substantial boost to robustness in the face of adversarial test data.

</p>
</details>

<details><summary><b>Machine Learning Aided Holistic Handover Optimization for Emerging Networks</b>
<a href="https://arxiv.org/abs/2202.02851">arxiv:2202.02851</a>
&#x1F4C8; 1 <br>
<p>Muhammad Umar Bin Farooq, Marvin Manalastas, Syed Muhammad Asad Zaidi, Adnan Abu-Dayya, Ali Imran</p></summary>
<p>

**Abstract:** In the wake of network densification and multi-band operation in emerging cellular networks, mobility and handover management is becoming a major bottleneck. The problem is further aggravated by the fact that holistic mobility management solutions for different types of handovers, namely inter-frequency and intra-frequency handovers, remain scarce. This paper presents a first mobility management solution that concurrently optimizes inter-frequency related A5 parameters and intra-frequency related A3 parameters. We analyze and optimize five parameters namely A5-time to trigger (TTT), A5-threshold1, A5-threshold2, A3-TTT, and A3-offset to jointly maximize three critical key performance indicators (KPIs): edge user reference signal received power (RSRP), handover success rate (HOSR) and load between frequency bands. In the absence of tractable analytical models due to system level complexity, we leverage machine learning to quantify the KPIs as a function of the mobility parameters. An XGBoost based model has the best performance for edge RSRP and HOSR while random forest outperforms others for load prediction. An analysis of the mobility parameters provides several insights: 1) there exists a strong coupling between A3 and A5 parameters; 2) an optimal set of parameters exists for each KPI; and 3) the optimal parameters vary for different KPIs. We also perform a SHAP based sensitivity to help resolve the parametric conflict between the KPIs. Finally, we formulate a maximization problem, show it is non-convex, and solve it utilizing simulated annealing (SA). Results indicate that ML-based SA-aided solution is more than 14x faster than the brute force approach with a slight loss in optimality.

</p>
</details>

<details><summary><b>A Novel Micro-service Based Platform for Composition, Deployment and Execution of BDA Applications</b>
<a href="https://arxiv.org/abs/2202.02845">arxiv:2202.02845</a>
&#x1F4C8; 1 <br>
<p>Davide Profeta, Nicola Masi, Domenico Messina, Davide Dalle Carbonare, Susanna Bonura, Vito Morreale</p></summary>
<p>

**Abstract:** Big Data are growing at an exponential rate and it becomes necessary the use of tools and technologies to manage, process and visualize them in order to extract value. In this paper a micro-service based platform is presented for the composition, deployment and execution of Big Data Analytics (BDA) application workflows in several domains and scenarios is presented. ALIDA is a result coming from previous research activities by ENGINEERING. It aims to achieve a unified platform that allows both BDA application developers and data analysts to interact with it. Developers will be able to register new BDA applications through the exposed API and/or through the web user interface. Data analysts will be able to use the BDA applications provided to create batch/stream workflows through a dashboard user interface to manipulate and subsequently visualize results from one or more sources. The platform also supports the auto-tuning of Big Data frameworks deployment properties to improve metrics for analytics application. ALIDA has been properly extended and integrated into a software solution for the analysis of large amounts of data from the avionic industries. A use case within this context is then presented.

</p>
</details>

<details><summary><b>Detecting Melanoma Fairly: Skin Tone Detection and Debiasing for Skin Lesion Classification</b>
<a href="https://arxiv.org/abs/2202.02832">arxiv:2202.02832</a>
&#x1F4C8; 1 <br>
<p>Peter J. Bevan, Amir Atapour-Abarghouei</p></summary>
<p>

**Abstract:** Convolutional Neural Networks have demonstrated human-level performance in the classification of melanoma and other skin lesions, but evident performance disparities between differing skin tones should be addressed before widespread deployment. In this work, we utilise a modified variational autoencoder to uncover skin tone bias in datasets commonly used as benchmarks. We propose an efficient yet effective algorithm for automatically labelling the skin tone of lesion images, and use this to annotate the benchmark ISIC dataset. We subsequently use two leading bias unlearning techniques to mitigate skin tone bias. Our experimental results provide evidence that our skin tone detection algorithm outperforms existing solutions and that unlearning skin tone improves generalisation and can reduce the performance disparity between melanoma detection in lighter and darker skin tones.

</p>
</details>

<details><summary><b>Learning Sparse Graphs via Majorization-Minimization for Smooth Node Signals</b>
<a href="https://arxiv.org/abs/2202.02815">arxiv:2202.02815</a>
&#x1F4C8; 1 <br>
<p>Ghania Fatima, Aakash Arora, Prabhu Babu, Petre Stoica</p></summary>
<p>

**Abstract:** In this letter, we propose an algorithm for learning a sparse weighted graph by estimating its adjacency matrix under the assumption that the observed signals vary smoothly over the nodes of the graph. The proposed algorithm is based on the principle of majorization-minimization (MM), wherein we first obtain a tight surrogate function for the graph learning objective and then solve the resultant surrogate problem which has a simple closed form solution. The proposed algorithm does not require tuning of any hyperparameter and it has the desirable feature of eliminating the inactive variables in the course of the iterations - which can help speeding up the algorithm. The numerical simulations conducted using both synthetic and real world (brain-network) data show that the proposed algorithm converges faster, in terms of the average number of iterations, than several existing methods in the literature.

</p>
</details>

<details><summary><b>Perceptual Coding for Compressed Video Understanding: A New Framework and Benchmark</b>
<a href="https://arxiv.org/abs/2202.02813">arxiv:2202.02813</a>
&#x1F4C8; 1 <br>
<p>Yuan Tian, Guo Lu, Yichao Yan, Guangtao Zhai, Li Chen, Zhiyong Gao</p></summary>
<p>

**Abstract:** Most video understanding methods are learned on high-quality videos. However, in most real-world scenarios, the videos are first compressed before the transportation and then decompressed for understanding. The decompressed videos are degraded in terms of perceptual quality, which may degenerate the downstream tasks. To address this issue, we propose the first coding framework for compressed video understanding, where another learnable perceptual bitstream is introduced and simultaneously transported with the video bitstream. With the sophisticatedly designed optimization target and network architectures, this new stream largely boosts the perceptual quality of the decoded videos yet with a small bit cost. Our framework can enjoy the best of both two worlds, (1) highly efficient content-coding of industrial video codec and (2) flexible perceptual-coding of neural networks (NNs). Finally, we build a rigorous benchmark for compressed video understanding over four different compression levels, six large-scale datasets, and two popular tasks. The proposed Dual-bitstream Perceptual Video Coding framework Dual-PVC consistently demonstrates significantly stronger performances than the baseline codec under the same bitrate level.

</p>
</details>

<details><summary><b>Optimal Algorithms for Decentralized Stochastic Variational Inequalities</b>
<a href="https://arxiv.org/abs/2202.02771">arxiv:2202.02771</a>
&#x1F4C8; 1 <br>
<p>Dmitry Kovalev, Aleksandr Beznosikov, Abdurakhmon Sadiev, Michael Persiianov, Peter Richtárik, Alexander Gasnikov</p></summary>
<p>

**Abstract:** Variational inequalities are a formalism that includes games, minimization, saddle point, and equilibrium problems as special cases. Methods for variational inequalities are therefore universal approaches for many applied tasks, including machine learning problems. This work concentrates on the decentralized setting, which is increasingly important but not well understood. In particular, we consider decentralized stochastic (sum-type) variational inequalities over fixed and time-varying networks. We present lower complexity bounds for both communication and local iterations and construct optimal algorithms that match these lower bounds. Our algorithms are the best among the available literature not only in the decentralized stochastic case, but also in the decentralized deterministic and non-distributed stochastic cases. Experimental results confirm the effectiveness of the presented algorithms.

</p>
</details>

<details><summary><b>Pushing the Efficiency-Regret Pareto Frontier for Online Learning of Portfolios and Quantum States</b>
<a href="https://arxiv.org/abs/2202.02765">arxiv:2202.02765</a>
&#x1F4C8; 1 <br>
<p>Julian Zimmert, Naman Agarwal, Satyen Kale</p></summary>
<p>

**Abstract:** We revisit the classical online portfolio selection problem. It is widely assumed that a trade-off between computational complexity and regret is unavoidable, with Cover's Universal Portfolios algorithm, SOFT-BAYES and ADA-BARRONS currently constituting its state-of-the-art Pareto frontier. In this paper, we present the first efficient algorithm, BISONS, that obtains polylogarithmic regret with memory and per-step running time requirements that are polynomial in the dimension, displacing ADA-BARRONS from the Pareto frontier. Additionally, we resolve a COLT 2020 open problem by showing that a certain Follow-The-Regularized-Leader algorithm with log-barrier regularization suffers an exponentially larger dependence on the dimension than previously conjectured. Thus, we rule out this algorithm as a candidate for the Pareto frontier. We also extend our algorithm and analysis to a more general problem than online portfolio selection, viz. online learning of quantum states with log loss. This algorithm, called SCHRODINGER'S BISONS, is the first efficient algorithm with polylogarithmic regret for this more general problem.

</p>
</details>

<details><summary><b>Estimating the Euclidean Quantum Propagator with Deep Generative Modelling of Feynman paths</b>
<a href="https://arxiv.org/abs/2202.02750">arxiv:2202.02750</a>
&#x1F4C8; 1 <br>
<p>Yanming Che, Clemens Gneiting, Franco Nori</p></summary>
<p>

**Abstract:** Feynman path integrals provide an elegant, classically-inspired representation for the quantum propagator and the quantum dynamics, through summing over a huge manifold of all possible paths. From computational and simulational perspectives, the ergodic tracking of the whole path manifold is a hard problem. Machine learning can help, in an efficient manner, to identify the relevant subspace and the intrinsic structure residing at a small fraction of the vast path manifold. In this work, we propose the concept of Feynman path generator, which efficiently generates Feynman paths with fixed endpoints from a (low-dimensional) latent space, by targeting a desired density of paths in the Euclidean space-time. With such path generators, the Euclidean propagator as well as the ground state wave function can be estimated efficiently for a generic potential energy. Our work leads to a fresh approach for calculating the quantum propagator, paves the way toward generative modelling of Feynman paths, and may also provide a future new perspective to understand the quantum-classical correspondence through deep learning.

</p>
</details>

<details><summary><b>Enhancing variational generation through self-decomposition</b>
<a href="https://arxiv.org/abs/2202.02738">arxiv:2202.02738</a>
&#x1F4C8; 1 <br>
<p>Andrea Asperti, Laura Bugo, Daniele Filippini</p></summary>
<p>

**Abstract:** In this article we introduce the notion of Split Variational Autoencoder (SVAE), whose output $\hat{x}$ is obtained as a weighted sum $σ\odot \hat{x_1} + (1-σ) \odot \hat{x_2}$ of two generated images $\hat{x_1},\hat{x_2}$, and $σ$ is a learned compositional map. The network is trained as a usual Variational Autoencoder with a negative loglikelihood loss between training and reconstructed images. The decomposition is nondeterministic, but follows two main schemes, that we may roughly categorize as either "syntactic" or "semantic". In the first case, the map tends to exploit the strong correlation between adjacent pixels, splitting the image in two complementary high frequency sub-images. In the second case, the map typically focuses on the contours of objects, splitting the image in interesting variations of its content, with more marked and distinctive features. In this case, the Fréchet Inception Distance (FID) of $\hat{x_1}$ and $\hat{x_2}$ is usually lower (hence better) than that of $\hat{x}$, that clearly suffers from being the average of the formers. In a sense, a SVAE forces the Variational Autoencoder to {\em make choices}, in contrast with its intrinsic tendency to average between alternatives with the aim to minimize the reconstruction loss towards a specific sample. According to the FID metric, our technique, tested on typical datasets such as Mnist, Cifar10 and Celeba, allows us to outperform all previous purely variational architectures (not relying on normalization flows).

</p>
</details>


{% endraw %}
Prev: [2022.02.05]({{ '/2022/02/05/2022.02.05.html' | relative_url }})  Next: [2022.02.07]({{ '/2022/02/07/2022.02.07.html' | relative_url }})