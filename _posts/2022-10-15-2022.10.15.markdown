Prev: [2022.10.14]({{ '/2022/10/14/2022.10.14.html' | relative_url }})  Next: [2022.10.16]({{ '/2022/10/16/2022.10.16.html' | relative_url }})
{% raw %}
## Summary for 2022-10-15, created on 2022-10-19


<details><summary><b>LAION-5B: An open large-scale dataset for training next generation image-text models</b>
<a href="https://arxiv.org/abs/2210.08402">arxiv:2210.08402</a>
&#x1F4C8; 5840 <br>
<p>Christoph Schuhmann, Romain Beaumont, Richard Vencu, Cade Gordon, Ross Wightman, Mehdi Cherti, Theo Coombes, Aarush Katta, Clayton Mullis, Mitchell Wortsman, Patrick Schramowski, Srivatsa Kundurthy, Katherine Crowson, Ludwig Schmidt, Robert Kaczmarczyk, Jenia Jitsev</p></summary>
<p>

**Abstract:** Groundbreaking language-vision architectures like CLIP and DALL-E proved the utility of training on large amounts of noisy image-text data, without relying on expensive accurate labels used in standard vision unimodal supervised learning. The resulting models showed capabilities of strong text-guided image generation and transfer to downstream tasks, while performing remarkably at zero-shot classification with noteworthy out-of-distribution robustness. Since then, large-scale language-vision models like ALIGN, BASIC, GLIDE, Flamingo and Imagen made further improvements. Studying the training and capabilities of such models requires datasets containing billions of image-text pairs. Until now, no datasets of this size have been made openly available for the broader research community. To address this problem and democratize research on large-scale multi-modal models, we present LAION-5B - a dataset consisting of 5.85 billion CLIP-filtered image-text pairs, of which 2.32B contain English language. We show successful replication and fine-tuning of foundational models like CLIP, GLIDE and Stable Diffusion using the dataset, and discuss further experiments enabled with an openly available dataset of this scale. Additionally we provide several nearest neighbor indices, an improved web-interface for dataset exploration and subset generation, and detection scores for watermark, NSFW, and toxic content detection. Announcement page https://laion.ai/laion-5b-a-new-era-of-open-large-scale-multi-modal-datasets/

</p>
</details>

<details><summary><b>PI-QT-Opt: Predictive Information Improves Multi-Task Robotic Reinforcement Learning at Scale</b>
<a href="https://arxiv.org/abs/2210.08217">arxiv:2210.08217</a>
&#x1F4C8; 130 <br>
<p>Kuang-Huei Lee, Ted Xiao, Adrian Li, Paul Wohlhart, Ian Fischer, Yao Lu</p></summary>
<p>

**Abstract:** The predictive information, the mutual information between the past and future, has been shown to be a useful representation learning auxiliary loss for training reinforcement learning agents, as the ability to model what will happen next is critical to success on many control tasks. While existing studies are largely restricted to training specialist agents on single-task settings in simulation, in this work, we study modeling the predictive information for robotic agents and its importance for general-purpose agents that are trained to master a large repertoire of diverse skills from large amounts of data. Specifically, we introduce Predictive Information QT-Opt (PI-QT-Opt), a QT-Opt agent augmented with an auxiliary loss that learns representations of the predictive information to solve up to 297 vision-based robot manipulation tasks in simulation and the real world with a single set of parameters. We demonstrate that modeling the predictive information significantly improves success rates on the training tasks and leads to better zero-shot transfer to unseen novel tasks. Finally, we evaluate PI-QT-Opt on real robots, achieving substantial and consistent improvement over QT-Opt in multiple experimental settings of varying environments, skills, and multi-task configurations.

</p>
</details>

<details><summary><b>MGNNI: Multiscale Graph Neural Networks with Implicit Layers</b>
<a href="https://arxiv.org/abs/2210.08353">arxiv:2210.08353</a>
&#x1F4C8; 4 <br>
<p>Juncheng Liu, Bryan Hooi, Kenji Kawaguchi, Xiaokui Xiao</p></summary>
<p>

**Abstract:** Recently, implicit graph neural networks (GNNs) have been proposed to capture long-range dependencies in underlying graphs. In this paper, we introduce and justify two weaknesses of implicit GNNs: the constrained expressiveness due to their limited effective range for capturing long-range dependencies, and their lack of ability to capture multiscale information on graphs at multiple resolutions. To show the limited effective range of previous implicit GNNs, We first provide a theoretical analysis and point out the intrinsic relationship between the effective range and the convergence of iterative equations used in these models. To mitigate the mentioned weaknesses, we propose a multiscale graph neural network with implicit layers (MGNNI) which is able to model multiscale structures on graphs and has an expanded effective range for capturing long-range dependencies. We conduct comprehensive experiments for both node classification and graph classification to show that MGNNI outperforms representative baselines and has a better ability for multiscale modeling and capturing of long-range dependencies.

</p>
</details>

<details><summary><b>When to Update Your Model: Constrained Model-based Reinforcement Learning</b>
<a href="https://arxiv.org/abs/2210.08349">arxiv:2210.08349</a>
&#x1F4C8; 4 <br>
<p>Tianying Ji, Yu Luo, Fuchun Sun, Mingxuan Jing, Fengxiang He, Wenbing Huang</p></summary>
<p>

**Abstract:** Designing and analyzing model-based RL (MBRL) algorithms with guaranteed monotonic improvement has been challenging, mainly due to the interdependence between policy optimization and model learning. Existing discrepancy bounds generally ignore the impacts of model shifts, and their corresponding algorithms are prone to degrade performance by drastic model updating. In this work, we first propose a novel and general theoretical scheme for a non-decreasing performance guarantee of MBRL. Our follow-up derived bounds reveal the relationship between model shifts and performance improvement. These discoveries encourage us to formulate a constrained lower-bound optimization problem to permit the monotonicity of MBRL. A further example demonstrates that learning models from a dynamically-varying number of explorations benefit the eventual returns. Motivated by these analyses, we design a simple but effective algorithm CMLO (Constrained Model-shift Lower-bound Optimization), by introducing an event-triggered mechanism that flexibly determines when to update the model. Experiments show that CMLO surpasses other state-of-the-art methods and produces a boost when various policy optimization methods are employed.

</p>
</details>

<details><summary><b>A Policy-Guided Imitation Approach for Offline Reinforcement Learning</b>
<a href="https://arxiv.org/abs/2210.08323">arxiv:2210.08323</a>
&#x1F4C8; 3 <br>
<p>Haoran Xu, Li Jiang, Jianxiong Li, Xianyuan Zhan</p></summary>
<p>

**Abstract:** Offline reinforcement learning (RL) methods can generally be categorized into two types: RL-based and Imitation-based. RL-based methods could in principle enjoy out-of-distribution generalization but suffer from erroneous off-policy evaluation. Imitation-based methods avoid off-policy evaluation but are too conservative to surpass the dataset. In this study, we propose an alternative approach, inheriting the training stability of imitation-style methods while still allowing logical out-of-distribution generalization. We decompose the conventional reward-maximizing policy in offline RL into a guide-policy and an execute-policy. During training, the guide-poicy and execute-policy are learned using only data from the dataset, in a supervised and decoupled manner. During evaluation, the guide-policy guides the execute-policy by telling where it should go so that the reward can be maximized, serving as the \textit{Prophet}. By doing so, our algorithm allows \textit{state-compositionality} from the dataset, rather than \textit{action-compositionality} conducted in prior imitation-style methods. We dumb this new approach Policy-guided Offline RL (\texttt{POR}). \texttt{POR} demonstrates the state-of-the-art performance on D4RL, a standard benchmark for offline RL. We also highlight the benefits of \texttt{POR} in terms of improving with supplementary suboptimal data and easily adapting to new tasks by only changing the guide-poicy.

</p>
</details>

<details><summary><b>Learning-based Motion Planning in Dynamic Environments Using GNNs and Temporal Encoding</b>
<a href="https://arxiv.org/abs/2210.08408">arxiv:2210.08408</a>
&#x1F4C8; 2 <br>
<p>Ruipeng Zhang, Chenning Yu, Jingkai Chen, Chuchu Fan, Sicun Gao</p></summary>
<p>

**Abstract:** Learning-based methods have shown promising performance for accelerating motion planning, but mostly in the setting of static environments. For the more challenging problem of planning in dynamic environments, such as multi-arm assembly tasks and human-robot interaction, motion planners need to consider the trajectories of the dynamic obstacles and reason about temporal-spatial interactions in very large state spaces. We propose a GNN-based approach that uses temporal encoding and imitation learning with data aggregation for learning both the embeddings and the edge prioritization policies. Experiments show that the proposed methods can significantly accelerate online planning over state-of-the-art complete dynamic planning algorithms. The learned models can often reduce costly collision checking operations by more than 1000x, and thus accelerating planning by up to 95%, while achieving high success rates on hard instances as well.

</p>
</details>

<details><summary><b>Taxonomy of A Decision Support System for Adaptive Experimental Design in Field Robotics</b>
<a href="https://arxiv.org/abs/2210.08397">arxiv:2210.08397</a>
&#x1F4C8; 2 <br>
<p>Jason M. Gregory, Sarah Al-Hussaini, Ali-akbar Agha-mohammadi, Satyandra K. Gupta</p></summary>
<p>

**Abstract:** Experimental design in field robotics is an adaptive human-in-the-loop decision-making process in which an experimenter learns about system performance and limitations through interactions with a robot in the form of constructed experiments. This can be challenging because of system complexity, the need to operate in unstructured environments, and the competing objectives of maximizing information gain while simultaneously minimizing experimental costs. Based on the successes in other domains, we propose the use of a Decision Support System (DSS) to amplify the human's decision-making abilities, overcome their inherent shortcomings, and enable principled decision-making in field experiments. In this work, we propose common terminology and a six-stage taxonomy of DSSs specifically for adaptive experimental design of more informative tests and reduced experimental costs. We construct and present our taxonomy using examples and trends from DSS literature, including works involving artificial intelligence and Intelligent DSSs. Finally, we identify critical technical gaps and opportunities for future research to direct the scientific community in the pursuit of next-generation DSSs for experimental design.

</p>
</details>

<details><summary><b>Active Learning with Neural Networks: Insights from Nonparametric Statistics</b>
<a href="https://arxiv.org/abs/2210.08367">arxiv:2210.08367</a>
&#x1F4C8; 2 <br>
<p>Yinglun Zhu, Robert Nowak</p></summary>
<p>

**Abstract:** Deep neural networks have great representation power, but typically require large numbers of training examples. This motivates deep active learning methods that can significantly reduce the amount of labeled training data. Empirical successes of deep active learning have been recently reported in the literature, however, rigorous label complexity guarantees of deep active learning have remained elusive. This constitutes a significant gap between theory and practice. This paper tackles this gap by providing the first near-optimal label complexity guarantees for deep active learning. The key insight is to study deep active learning from the nonparametric classification perspective. Under standard low noise conditions, we show that active learning with neural networks can provably achieve the minimax label complexity, up to disagreement coefficient and other logarithmic terms. When equipped with an abstention option, we further develop an efficient deep active learning algorithm that achieves $\mathsf{polylog}(\frac{1}ε)$ label complexity, without any low noise assumptions. We also provide extensions of our results beyond the commonly studied Sobolev/Hölder spaces and develop label complexity guarantees for learning in Radon $\mathsf{BV}^2$ spaces, which have recently been proposed as natural function spaces associated with neural networks.

</p>
</details>

<details><summary><b>HUDD: A tool to debug DNNs for safety analysis</b>
<a href="https://arxiv.org/abs/2210.08356">arxiv:2210.08356</a>
&#x1F4C8; 2 <br>
<p>Hazem Fahmy, Fabrizio Pastore, Lionel Briand</p></summary>
<p>

**Abstract:** We present HUDD, a tool that supports safety analysis practices for systems enabled by Deep Neural Networks (DNNs) by automatically identifying the root causes for DNN errors and retraining the DNN. HUDD stands for Heatmap-based Unsupervised Debugging of DNNs, it automatically clusters error-inducing images whose results are due to common subsets of DNN neurons. The intent is for the generated clusters to group error-inducing images having common characteristics, that is, having a common root cause. HUDD identifies root causes by applying a clustering algorithm to matrices (i.e., heatmaps) capturing the relevance of every DNN neuron on the DNN outcome. Also, HUDD retrains DNNs with images that are automatically selected based on their relatedness to the identified image clusters. Our empirical evaluation with DNNs from the automotive domain have shown that HUDD automatically identifies all the distinct root causes of DNN errors, thus supporting safety analysis. Also, our retraining approach has shown to be more effective at improving DNN accuracy than existing approaches. A demo video of HUDD is available at https://youtu.be/drjVakP7jdU.

</p>
</details>

<details><summary><b>Mini-Batch Learning Strategies for modeling long term temporal dependencies: A study in environmental applications</b>
<a href="https://arxiv.org/abs/2210.08347">arxiv:2210.08347</a>
&#x1F4C8; 2 <br>
<p>Shaoming Xu, Ankush Khandelwal, Xiang Li, Xiaowei Jia, Licheng Liu, Jared Willard, Rahul Ghosh, Kelly Cutler, Michael Steinbach, Christopher Duffy, John Nieber, Vipin Kumar</p></summary>
<p>

**Abstract:** In many environmental applications, recurrent neural networks (RNNs) are often used to model physical variables with long temporal dependencies. However, due to mini-batch training, temporal relationships between training segments within the batch (intra-batch) as well as between batches (inter-batch) are not considered, which can lead to limited performance. Stateful RNNs aim to address this issue by passing hidden states between batches. Since Stateful RNNs ignore intra-batch temporal dependency, there exists a trade-off between training stability and capturing temporal dependency. In this paper, we provide a quantitative comparison of different Stateful RNN modeling strategies, and propose two strategies to enforce both intra- and inter-batch temporal dependency. First, we extend Stateful RNNs by defining a batch as a temporally ordered set of training segments, which enables intra-batch sharing of temporal information. While this approach significantly improves the performance, it leads to much larger training times due to highly sequential training. To address this issue, we further propose a new strategy which augments a training segment with an initial value of the target variable from the timestep right before the starting of the training segment. In other words, we provide an initial value of the target variable as additional input so that the network can focus on learning changes relative to that initial value. By using this strategy, samples can be passed in any order (mini-batch training) which significantly reduces the training time while maintaining the performance. In demonstrating our approach in hydrological modeling, we observe that the most significant gains in predictive accuracy occur when these methods are applied to state variables whose values change more slowly, such as soil water and snowpack, rather than continuously moving flux variables such as streamflow.

</p>
</details>

<details><summary><b>Augmentation-Free Graph Contrastive Learning of Invariant-Discriminative Representations</b>
<a href="https://arxiv.org/abs/2210.08345">arxiv:2210.08345</a>
&#x1F4C8; 2 <br>
<p>Haifeng Li, Jun Cao, Jiawei Zhu, Qinyao Luo, Silu He, Xuyin Wang</p></summary>
<p>

**Abstract:** The pretasks are mainly built on mutual information estimation, which requires data augmentation to construct positive samples with similar semantics to learn invariant signals and negative samples with dissimilar semantics in order to empower representation discriminability. However, an appropriate data augmentation configuration depends heavily on lots of empirical trials such as choosing the compositions of data augmentation techniques and the corresponding hyperparameter settings. We propose an augmentation-free graph contrastive learning method, invariant-discriminative graph contrastive learning (iGCL), that does not intrinsically require negative samples. iGCL designs the invariant-discriminative loss (ID loss) to learn invariant and discriminative representations. On the one hand, ID loss learns invariant signals by directly minimizing the mean square error between the target samples and positive samples in the representation space. On the other hand, ID loss ensures that the representations are discriminative by an orthonormal constraint forcing the different dimensions of representations to be independent of each other. This prevents representations from collapsing to a point or subspace. Our theoretical analysis explains the effectiveness of ID loss from the perspectives of the redundancy reduction criterion, canonical correlation analysis, and information bottleneck principle. The experimental results demonstrate that iGCL outperforms all baselines on 5 node classification benchmark datasets. iGCL also shows superior performance for different label ratios and is capable of resisting graph attacks, which indicates that iGCL has excellent generalization and robustness.

</p>
</details>

<details><summary><b>Robot Navigation Anticipative Strategies in Deep Reinforcement Motion Planning</b>
<a href="https://arxiv.org/abs/2210.08280">arxiv:2210.08280</a>
&#x1F4C8; 2 <br>
<p>Óscar Gil, Alberto Sanfeliu</p></summary>
<p>

**Abstract:** The navigation of robots in dynamic urban environments, requires elaborated anticipative strategies for the robot to avoid collisions with dynamic objects, like bicycles or pedestrians, and to be human aware. We have developed and analyzed three anticipative strategies in motion planning taking into account the future motion of the mobile objects that can move up to 18 km/h. First, we have used our hybrid policy resulting from a Deep Deterministic Policy Gradient (DDPG) training and the Social Force Model (SFM), and we have tested it in simulation in four complex map scenarios with many pedestrians. Second, we have used these anticipative strategies in real-life experiments using the hybrid motion planning method and the ROS Navigation Stack with Dynamic Windows Approach (NS-DWA). The results in simulations and real-life experiments show very good results in open environments and also in mixed scenarios with narrow spaces.

</p>
</details>

<details><summary><b>Model Criticism for Long-Form Text Generation</b>
<a href="https://arxiv.org/abs/2210.08444">arxiv:2210.08444</a>
&#x1F4C8; 1 <br>
<p>Yuntian Deng, Volodymyr Kuleshov, Alexander M. Rush</p></summary>
<p>

**Abstract:** Language models have demonstrated the ability to generate highly fluent text; however, it remains unclear whether their output retains coherent high-level structure (e.g., story progression). Here, we propose to apply a statistical tool, model criticism in latent space, to evaluate the high-level structure of the generated text. Model criticism compares the distributions between real and generated data in a latent space obtained according to an assumptive generative process. Different generative processes identify specific failure modes of the underlying model. We perform experiments on three representative aspects of high-level discourse -- coherence, coreference, and topicality -- and find that transformer-based language models are able to capture topical structures but have a harder time maintaining structural coherence or modeling coreference.

</p>
</details>

<details><summary><b>Navigating Memory Construction by Global Pseudo-Task Simulation for Continual Learning</b>
<a href="https://arxiv.org/abs/2210.08442">arxiv:2210.08442</a>
&#x1F4C8; 1 <br>
<p>Yejia Liu, Wang Zhu, Shaolei Ren</p></summary>
<p>

**Abstract:** Continual learning faces a crucial challenge of catastrophic forgetting. To address this challenge, experience replay (ER) that maintains a tiny subset of samples from previous tasks has been commonly used. Existing ER works usually focus on refining the learning objective for each task with a static memory construction policy. In this paper, we formulate the dynamic memory construction in ER as a combinatorial optimization problem, which aims at directly minimizing the global loss across all experienced tasks. We first apply three tactics to solve the problem in the offline setting as a starting point. To provide an approximate solution to this problem in the online continual learning setting, we further propose the Global Pseudo-task Simulation (GPS), which mimics future catastrophic forgetting of the current task by permutation. Our empirical results and analyses suggest that the GPS consistently improves accuracy across four commonly used vision benchmarks. We have also shown that our GPS can serve as the unified framework for integrating various memory construction policies in existing ER works.

</p>
</details>

<details><summary><b>Explainable Causal Analysis of Mental Health on Social Media Data</b>
<a href="https://arxiv.org/abs/2210.08430">arxiv:2210.08430</a>
&#x1F4C8; 1 <br>
<p>Chandni Saxena, Muskan Garg, Gunjan Saxena</p></summary>
<p>

**Abstract:** With recent developments in Social Computing, Natural Language Processing and Clinical Psychology, the social NLP research community addresses the challenge of automation in mental illness on social media. A recent extension to the problem of multi-class classification of mental health issues is to identify the cause behind the user's intention. However, multi-class causal categorization for mental health issues on social media has a major challenge of wrong prediction due to the overlapping problem of causal explanations. There are two possible mitigation techniques to solve this problem: (i) Inconsistency among causal explanations/ inappropriate human-annotated inferences in the dataset, (ii) in-depth analysis of arguments and stances in self-reported text using discourse analysis. In this research work, we hypothesise that if there exists the inconsistency among F1 scores of different classes, there must be inconsistency among corresponding causal explanations as well. In this task, we fine tune the classifiers and find explanations for multi-class causal categorization of mental illness on social media with LIME and Integrated Gradient (IG) methods. We test our methods with CAMS dataset and validate with annotated interpretations. A key contribution of this research work is to find the reason behind inconsistency in accuracy of multi-class causal categorization. The effectiveness of our methods is evident with the results obtained having category-wise average scores of $81.29 \%$ and $0.906$ using cosine similarity and word mover's distance, respectively.

</p>
</details>

<details><summary><b>A cusp-capturing PINN for elliptic interface problems</b>
<a href="https://arxiv.org/abs/2210.08424">arxiv:2210.08424</a>
&#x1F4C8; 1 <br>
<p>Yu-Hau Tseng, Te-Sheng Lin, Wei-Fan Hu, Ming-Chih Lai</p></summary>
<p>

**Abstract:** In this paper, we propose a cusp-capturing physics-informed neural network (PINN) to solve variable-coefficient elliptic interface problems whose solution is continuous but has discontinuous first derivatives on the interface. To find such a solution using neural network representation, we introduce a cusp-enforced level set function as an additional feature input to the network to retain the inherent solution properties, capturing the solution cusps (where the derivatives are discontinuous) sharply. In addition, the proposed neural network has the advantage of being mesh-free, so it can easily handle problems in irregular domains. We train the network using the physics-informed framework in which the loss function comprises the residual of the differential equation together with a certain interface and boundary conditions. We conduct a series of numerical experiments to demonstrate the effectiveness of the cusp-capturing technique and the accuracy of the present network model. Numerical results show that even a one-hidden-layer (shallow) network with a moderate number of neurons ($40-60$) and sufficient training data points, the present network model can achieve high prediction accuracy (relative $L^2$ errors in the order of $10^{-5}-10^{-6}$), which outperforms several existing neural network models and traditional grid-based methods in the literature.

</p>
</details>

<details><summary><b>Using Virtual Reality to Simulate Human-Robot Emergency Evacuation Scenarios</b>
<a href="https://arxiv.org/abs/2210.08414">arxiv:2210.08414</a>
&#x1F4C8; 1 <br>
<p>Alan R. Wagner, Colin Holbrook, Daniel Holman, Brett Sheeran, Vidullan Surendran, Jared Armagost, Savanna Spazak, Yinxuan Yin</p></summary>
<p>

**Abstract:** This paper describes our recent effort to use virtual reality to simulate threatening emergency evacuation scenarios in which a robot guides a person to an exit. Our prior work has demonstrated that people will follow a robot's guidance, even when the robot is faulty, during an emergency evacuation. Yet, because physical in-person emergency evacuation experiments are difficult and costly to conduct and because we would like to evaluate many different factors, we are motivated to develop a system that immerses people in the simulation environment to encourage genuine subject reactions. We are working to complete experiments verifying the validity of our approach.

</p>
</details>

<details><summary><b>Semantic Segmentation with Active Semi-Supervised Representation Learning</b>
<a href="https://arxiv.org/abs/2210.08403">arxiv:2210.08403</a>
&#x1F4C8; 1 <br>
<p>Aneesh Rangnekar, Christopher Kanan, Matthew Hoffman</p></summary>
<p>

**Abstract:** Obtaining human per-pixel labels for semantic segmentation is incredibly laborious, often making labeled dataset construction prohibitively expensive. Here, we endeavor to overcome this problem with a novel algorithm that combines semi-supervised and active learning, resulting in the ability to train an effective semantic segmentation algorithm with significantly lesser labeled data. To do this, we extend the prior state-of-the-art S4AL algorithm by replacing its mean teacher approach for semi-supervised learning with a self-training approach that improves learning with noisy labels. We further boost the neural network's ability to query useful data by adding a contrastive learning head, which leads to better understanding of the objects in the scene, and hence, better queries for active learning. We evaluate our method on CamVid and CityScapes datasets, the de-facto standards for active learning for semantic segmentation. We achieve more than 95% of the network's performance on CamVid and CityScapes datasets, utilizing only 12.1% and 15.1% of the labeled data, respectively. We also benchmark our method across existing stand-alone semi-supervised learning methods on the CityScapes dataset and achieve superior performance without any bells or whistles.

</p>
</details>

<details><summary><b>SPIDR: SDF-based Neural Point Fields for Illumination and Deformation</b>
<a href="https://arxiv.org/abs/2210.08398">arxiv:2210.08398</a>
&#x1F4C8; 1 <br>
<p>Ruofan Liang, Jiahao Zhang, Haoda Li, Chen Yang, Nandita Vijaykumar</p></summary>
<p>

**Abstract:** Implicit neural representations such as neural radiance fields (NeRFs) have recently emerged as a promising approach for 3D reconstruction and novel view synthesis. However, NeRF-based methods encode shape, reflectance, and illumination implicitly in their neural representations, and this makes it challenging for users to manipulate these properties in the rendered images explicitly. Existing approaches only enable limited editing of the scene and deformation of the geometry. Furthermore, no existing work enables accurate scene illumination after object deformation. In this work, we introduce SPIDR, a new hybrid neural SDF representation. SPIDR combines point cloud and neural implicit representations to enable the reconstruction of higher quality meshes and surfaces for object deformation and lighting estimation. To more accurately capture environment illumination for scene relighting, we propose a novel neural implicit model to learn environment light. To enable accurate illumination updates after deformation, we use the shadow mapping technique to efficiently approximate the light visibility updates caused by geometry editing. We demonstrate the effectiveness of SPIDR in enabling high quality geometry editing and deformation with accurate updates to the illumination of the scene. In comparison to prior work, we demonstrate significantly better rendering quality after deformation and lighting estimation.

</p>
</details>

<details><summary><b>SOCIALMAPF: Optimal and Efficient Multi-Agent Path Finding with Strategic Agents for Social Navigation</b>
<a href="https://arxiv.org/abs/2210.08390">arxiv:2210.08390</a>
&#x1F4C8; 1 <br>
<p>Rohan Chandra, Rahul Maligi, Arya Anantula, Joydeep Biswas</p></summary>
<p>

**Abstract:** We propose an extension to the MAPF formulation, called SocialMAPF, to account for private incentives of agents in constrained environments such as doorways, narrow hallways, and corridor intersections. SocialMAPF is able to, for instance, accurately reason about the urgent incentive of an agent rushing to the hospital over another agent's less urgent incentive of going to a grocery store; MAPF ignores such agent-specific incentives. Our proposed formulation addresses the open problem of optimal and efficient path planning for agents with private incentives. To solve SocialMAPF, we propose a new class of algorithms that use mechanism design during conflict resolution to simultaneously optimize agents' private local utilities and the global system objective. We perform an extensive array of experiments that show that optimal search-based MAPF techniques lead to collisions and increased time-to-goal in SocialMAPF compared to our proposed method using mechanism design. Furthermore, we empirically demonstrate that mechanism design results in models that maximizes agent utility and minimizes the overall time-to-goal of the entire system. We further showcase the capabilities of mechanism design-based planning by successfully deploying it in environments with static obstacles. To conclude, we briefly list several research directions using the SocialMAPF formulation, such as exploring motion planning in the continuous domain for agents with private incentives.

</p>
</details>

<details><summary><b>Machine-Learning Love: classifying the equation of state of neutron stars with Transformers</b>
<a href="https://arxiv.org/abs/2210.08382">arxiv:2210.08382</a>
&#x1F4C8; 1 <br>
<p>Gonçalo Gonçalves, Márcio Ferreira, João Aveiro, Antonio Onofre, Felipe F. Freitas, Constança Providência, José A. Font</p></summary>
<p>

**Abstract:** The use of the Audio Spectrogram Transformer (AST) model for gravitational-wave data analysis is investigated. The AST machine-learning model is a convolution-free classifier that captures long-range global dependencies through a purely attention-based mechanism. In this paper a model is applied to a simulated dataset of inspiral gravitational wave signals from binary neutron star coalescences, built from five distinct, cold equations of state (EOS) of nuclear matter. From the analysis of the mass dependence of the tidal deformability parameter for each EOS class it is shown that the AST model achieves a promising performance in correctly classifying the EOS purely from the gravitational wave signals, especially when the component masses of the binary system are in the range $[1,1.5]M_{\odot}$. Furthermore, the generalization ability of the model is investigated by using gravitational-wave signals from a new EOS not used during the training of the model, achieving fairly satisfactory results. Overall, the results, obtained using the simplified setup of noise-free waveforms, show that the AST model, once trained, might allow for the instantaneous inference of the cold nuclear matter EOS directly from the inspiral gravitational-wave signals produced in binary neutron star coalescences.

</p>
</details>

<details><summary><b>Self-Improving SLAM in Dynamic Environments: Learning When to Mask</b>
<a href="https://arxiv.org/abs/2210.08350">arxiv:2210.08350</a>
&#x1F4C8; 1 <br>
<p>Adrian Bojko, Romain Dupont, Mohamed Tamaazousti, Hervé Le Borgne</p></summary>
<p>

**Abstract:** Visual SLAM -- Simultaneous Localization and Mapping -- in dynamic environments typically relies on identifying and masking image features on moving objects to prevent them from negatively affecting performance. Current approaches are suboptimal: they either fail to mask objects when needed or, on the contrary, mask objects needlessly. Thus, we propose a novel SLAM that learns when masking objects improves its performance in dynamic scenarios. Given a method to segment objects and a SLAM, we give the latter the ability of Temporal Masking, i.e., to infer when certain classes of objects should be masked to maximize any given SLAM metric. We do not make any priors on motion: our method learns to mask moving objects by itself. To prevent high annotations costs, we created an automatic annotation method for self-supervised training. We constructed a new dataset, named ConsInv, which includes challenging real-world dynamic sequences respectively indoors and outdoors. Our method reaches the state of the art on the TUM RGB-D dataset and outperforms it on KITTI and ConsInv datasets.

</p>
</details>

<details><summary><b>How Mask Matters: Towards Theoretical Understandings of Masked Autoencoders</b>
<a href="https://arxiv.org/abs/2210.08344">arxiv:2210.08344</a>
&#x1F4C8; 1 <br>
<p>Qi Zhang, Yifei Wang, Yisen Wang</p></summary>
<p>

**Abstract:** Masked Autoencoders (MAE) based on a reconstruction task have risen to be a promising paradigm for self-supervised learning (SSL) and achieve state-of-the-art performance across different benchmark datasets. However, despite its impressive empirical success, there is still limited theoretical understanding of it. In this paper, we propose a theoretical understanding of how masking matters for MAE to learn meaningful features. We establish a close connection between MAE and contrastive learning, which shows that MAE implicit aligns the mask-induced positive pairs. Built upon this connection, we develop the first downstream guarantees for MAE methods, and analyze the effect of mask ratio. Besides, as a result of the implicit alignment, we also point out the dimensional collapse issue of MAE, and propose a Uniformity-enhanced MAE (U-MAE) loss that can effectively address this issue and bring significant improvements on real-world datasets, including CIFAR-10, ImageNet-100, and ImageNet-1K. Code is available at (https://github.com/zhangq327/U-MAE).

</p>
</details>

<details><summary><b>Aplicación de redes neuronales convolucionales profundas al diagnóstico asistido de la enfermedad de Alzheimer</b>
<a href="https://arxiv.org/abs/2210.08330">arxiv:2210.08330</a>
&#x1F4C8; 1 <br>
<p>Ángel de la Vega Jiménez</p></summary>
<p>

**Abstract:** Currently, the diagnosis of Alzheimer's disease is a complex and error-prone process. Improving this diagnosis could allow earlier detection of the disease and improve the quality of life of patients and their families. For this work, we will use 249 brain images from two modalities: PET and MRI, taken from the ADNI database, and labelled into three classes according to the degree of development of Alzheimer's disease. We propose the development of a convolutional neural network to perform the classification of these images, during which, we will study the appropriate depth of the networks for this problem, the importance of pre-processing medical images, the use of transfer learning and data augmentation techniques as tools to reduce the effects of the problem of having too little data, and the simultaneous use of multiple medical imaging modalities. We also propose the application of an evaluation method that guarantees a good degree of repeatability of the results even when using a small dataset. Following this evaluation method, our best final model, which makes use of transfer learning with COVID-19 data, achieves an accuracy d 68\%. In addition, in an independent test set, this same model achieves 70\% accuracy, a promising result given the small size of our dataset. We further conclude that augmenting the depth of the networks helps with this problem, that image pre-processing is a fundamental process to address this type of medical problem, and that the use of data augmentation and the use of pre-trained networks with images of other diseases can provide significant improvements.

</p>
</details>

<details><summary><b>Distributionally Robust Causal Inference with Observational Data</b>
<a href="https://arxiv.org/abs/2210.08326">arxiv:2210.08326</a>
&#x1F4C8; 1 <br>
<p>Dimitris Bertsimas, Kosuke Imai, Michael Lingzhi Li</p></summary>
<p>

**Abstract:** We consider the estimation of average treatment effects in observational studies without the standard assumption of unconfoundedness. We propose a new framework of robust causal inference under the general observational study setting with the possible existence of unobserved confounders. Our approach is based on the method of distributionally robust optimization and proceeds in two steps. We first specify the maximal degree to which the distribution of unobserved potential outcomes may deviate from that of obsered outcomes. We then derive sharp bounds on the average treatment effects under this assumption. Our framework encompasses the popular marginal sensitivity model as a special case and can be extended to the difference-in-difference and regression discontinuity designs as well as instrumental variables. Through simulation and empirical studies, we demonstrate the applicability of the proposed methodology to real-world settings.

</p>
</details>

<details><summary><b>A Scalable Reinforcement Learning Approach for Attack Allocation in Swarm to Swarm Engagement Problems</b>
<a href="https://arxiv.org/abs/2210.08319">arxiv:2210.08319</a>
&#x1F4C8; 1 <br>
<p>Umut Demir, Nazim Kemal Ure</p></summary>
<p>

**Abstract:** In this work we propose a reinforcement learning (RL) framework that controls the density of a large-scale swarm for engaging with adversarial swarm attacks. Although there is a significant amount of existing work in applying artificial intelligence methods to swarm control, analysis of interactions between two adversarial swarms is a rather understudied area. Most of the existing work in this subject develop strategies by making hard assumptions regarding the strategy and dynamics of the adversarial swarm. Our main contribution is the formulation of the swarm to swarm engagement problem as a Markov Decision Process and development of RL algorithms that can compute engagement strategies without the knowledge of strategy/dynamics of the adversarial swarm. Simulation results show that the developed framework can handle a wide array of large-scale engagement scenarios in an efficient manner.

</p>
</details>

<details><summary><b>Improving Radiology Summarization with Radiograph and Anatomy Prompts</b>
<a href="https://arxiv.org/abs/2210.08303">arxiv:2210.08303</a>
&#x1F4C8; 1 <br>
<p>Jinpeng Hu, Zhihong Chen, Yang Liu, Xiang Wan, Tsung-Hui Chang</p></summary>
<p>

**Abstract:** The impression is crucial for the referring physicians to grasp key information since it is concluded from the findings and reasoning of radiologists. To alleviate the workload of radiologists and reduce repetitive human labor in impression writing, many researchers have focused on automatic impression generation. However, recent works on this task mainly summarize the corresponding findings and pay less attention to the radiology images. In clinical, radiographs can provide more detailed valuable observations to enhance radiologists' impression writing, especially for complicated cases. Besides, each sentence in findings usually focuses on single anatomy, so they only need to be matched to corresponding anatomical regions instead of the whole image, which is beneficial for textual and visual features alignment. Therefore, we propose a novel anatomy-enhanced multimodal model to promote impression generation. In detail, we first construct a set of rules to extract anatomies and put these prompts into each sentence to highlight anatomy characteristics. Then, two separate encoders are applied to extract features from the radiograph and findings. Afterward, we utilize a contrastive learning module to align these two representations at the overall level and use a co-attention to fuse them at the sentence level with the help of anatomy-enhanced sentence representation. Finally, the decoder takes the fused information as the input to generate impressions. The experimental results on two benchmark datasets confirm the effectiveness of the proposed method, which achieves state-of-the-art results.

</p>
</details>

<details><summary><b>A Secure Federated Data-Driven Evolutionary Multi-objective Optimization Algorithm</b>
<a href="https://arxiv.org/abs/2210.08295">arxiv:2210.08295</a>
&#x1F4C8; 1 <br>
<p>Qiqi Liu, Yuping Yan, Peter Ligeti, Yaochu Jin</p></summary>
<p>

**Abstract:** Data-driven evolutionary algorithms usually aim to exploit the information behind a limited amount of data to perform optimization, which have proved to be successful in solving many complex real-world optimization problems. However, most data-driven evolutionary algorithms are centralized, causing privacy and security concerns. Existing federated Bayesian algorithms and data-driven evolutionary algorithms mainly protect the raw data on each client. To address this issue, this paper proposes a secure federated data-driven evolutionary multi-objective optimization algorithm to protect both the raw data and the newly infilled solutions obtained by optimizing the acquisition function conducted on the server. We select the query points on a randomly selected client at each round of surrogate update by calculating the acquisition function values of the unobserved points on this client, thereby reducing the risk of leaking the information about the solution to be sampled. In addition, since the predicted objective values of each client may contain sensitive information, we mask the objective values with Diffie-Hellmann-based noise, and then send only the masked objective values of other clients to the selected client via the server. Since the calculation of the acquisition function also requires both the predicted objective value and the uncertainty of the prediction, the predicted mean objective and uncertainty are normalized to reduce the influence of noise. Experimental results on a set of widely used multi-objective optimization benchmarks show that the proposed algorithm can protect privacy and enhance security with only negligible sacrifice in the performance of federated data-driven evolutionary optimization.

</p>
</details>

<details><summary><b>AI-powered tiebreak mechanisms: An application to chess</b>
<a href="https://arxiv.org/abs/2210.08289">arxiv:2210.08289</a>
&#x1F4C8; 1 <br>
<p>Nejat Anbarci, Mehmet S. Ismail</p></summary>
<p>

**Abstract:** In this paper, we propose that AI systems serve as a judge in the event of a draw in games such as chess and in the event of a tie in tournaments. More specifically, we introduce a family of AI-based scoring mechanisms and the concept of "tiebreak strategyproofness" in $n$-person zero-sum games. A mechanism is called tiebreak strategyproof (TSP) if it is always in the best interest of every player to choose the "best" action according to a given AI system. As such, we introduce a practicable scoring mechanism in chess and show that it is TSP, i.e., it is never in the interest of a player to deliberately play a worse move to increase their advantage in case the game goes to the tiebreak. In other words, TSP mechanisms are immune to such strategic manipulations. We also show that the current "speed-chess" tiebreaks are not TSP or immune to manipulation with an example from 2018 world chess championship between Carlsen and Caruana.

</p>
</details>

<details><summary><b>MenuAI: Restaurant Food Recommendation System via a Transformer-based Deep Learning Model</b>
<a href="https://arxiv.org/abs/2210.08266">arxiv:2210.08266</a>
&#x1F4C8; 1 <br>
<p>Xinwei Ju, Frank Po Wen Lo, Jianing Qiu, Peilun Shi, Jiachuan Peng, Benny Lo</p></summary>
<p>

**Abstract:** Food recommendation system has proven as an effective technology to provide guidance on dietary choices, and this is especially important for patients suffering from chronic diseases. Unlike other multimedia recommendations, such as books and movies, food recommendation task is highly relied on the context at the moment, since users' food preference can be highly dynamic over time. For example, individuals tend to eat more calories earlier in the day and eat a little less at dinner. However, there are still limited research works trying to incorporate both current context and nutritional knowledge for food recommendation. Thus, a novel restaurant food recommendation system is proposed in this paper to recommend food dishes to users according to their special nutritional needs. Our proposed system utilises Optical Character Recognition (OCR) technology and a transformer-based deep learning model, Learning to Rank (LTR) model, to conduct food recommendation. Given a single RGB image of the menu, the system is then able to rank the food dishes in terms of the input search key (e.g., calorie, protein level). Due to the property of the transformer, our system can also rank unseen food dishes. Comprehensive experiments are conducted to validate our methods on a self-constructed menu dataset, known as MenuRank dataset. The promising results, with accuracy ranging from 77.2% to 99.5%, have demonstrated the great potential of LTR model in addressing food recommendation problems.

</p>
</details>

<details><summary><b>DI-NIDS: Domain Invariant Network Intrusion Detection System</b>
<a href="https://arxiv.org/abs/2210.08252">arxiv:2210.08252</a>
&#x1F4C8; 1 <br>
<p>Siamak Layeghy, Mahsa Baktashmotlagh, Marius Portmann</p></summary>
<p>

**Abstract:** The performance of machine learning based network intrusion detection systems (NIDSs) severely degrades when deployed on a network with significantly different feature distributions from the ones of the training dataset. In various applications, such as computer vision, domain adaptation techniques have been successful in mitigating the gap between the distributions of the training and test data. In the case of network intrusion detection however, the state-of-the-art domain adaptation approaches have had limited success. According to recent studies, as well as our own results, the performance of an NIDS considerably deteriorates when the `unseen' test dataset does not follow the training dataset distribution. In some cases, swapping the train and test datasets makes this even more severe. In order to enhance the generalisibility of machine learning based network intrusion detection systems, we propose to extract domain invariant features using adversarial domain adaptation from multiple network domains, and then apply an unsupervised technique for recognising abnormalities, i.e., intrusions. More specifically, we train a domain adversarial neural network on labelled source domains, extract the domain invariant features, and train a One-Class SVM (OSVM) model to detect anomalies. At test time, we feedforward the unlabeled test data to the feature extractor network to project it into a domain invariant space, and then apply OSVM on the extracted features to achieve our final goal of detecting intrusions. Our extensive experiments on the NIDS benchmark datasets of NFv2-CIC-2018 and NFv2-UNSW-NB15 show that our proposed setup demonstrates superior cross-domain performance in comparison to the previous approaches.

</p>
</details>

<details><summary><b>Learned Video Compression for YUV 4:2:0 Content Using Flow-based Conditional Inter-frame Coding</b>
<a href="https://arxiv.org/abs/2210.08225">arxiv:2210.08225</a>
&#x1F4C8; 1 <br>
<p>Yung-Han Ho, Chih-Hsuan Lin, Peng-Yu Chen, Mu-Jung Chen, Chih-Peng Chang, Wen-Hsiao Peng, Hsueh-Ming Hang</p></summary>
<p>

**Abstract:** This paper proposes a learning-based video compression framework for variable-rate coding on YUV 4:2:0 content. Most existing learning-based video compression models adopt the traditional hybrid-based coding architecture, which involves temporal prediction followed by residual coding. However, recent studies have shown that residual coding is sub-optimal from the information-theoretic perspective. In addition, most existing models are optimized with respect to RGB content. Furthermore, they require separate models for variable-rate coding. To address these issues, this work presents an attempt to incorporate the conditional inter-frame coding for YUV 4:2:0 content. We introduce a conditional flow-based inter-frame coder to improve the inter-frame coding efficiency. To adapt our codec to YUV 4:2:0 content, we adopt a simple strategy of using space-to-depth and depth-to-space conversions. Lastly, we employ a rate-adaption net to achieve variable-rate coding without training multiple models. Experimental results show that our model performs better than x265 on UVG and MCL-JCV datasets in terms of PSNR-YUV. However, on the more challenging datasets from ISCAS'22 GC, there is still ample room for improvement. This insufficient performance is due to the lack of inter-frame coding capability at a large GOP size and can be mitigated by increasing the model capacity and applying an error propagation-aware training strategy.

</p>
</details>

<details><summary><b>D.MCA: Outlier Detection with Explicit Micro-Cluster Assignments</b>
<a href="https://arxiv.org/abs/2210.08212">arxiv:2210.08212</a>
&#x1F4C8; 1 <br>
<p>Shuli Jiang, Robson Leonardo Ferreira Cordeiro, Leman Akoglu</p></summary>
<p>

**Abstract:** How can we detect outliers, both scattered and clustered, and also explicitly assign them to respective micro-clusters, without knowing apriori how many micro-clusters exist? How can we perform both tasks in-house, i.e., without any post-hoc processing, so that both detection and assignment can benefit simultaneously from each other? Presenting outliers in separate micro-clusters is informative to analysts in many real-world applications. However, a naïve solution based on post-hoc clustering of the outliers detected by any existing method suffers from two main drawbacks: (a) appropriate hyperparameter values are commonly unknown for clustering, and most algorithms struggle with clusters of varying shapes and densities; (b) detection and assignment cannot benefit from one another. In this paper, we propose D.MCA to $\underline{D}$etect outliers with explicit $\underline{M}$icro-$\underline{C}$luster $\underline{A}$ssignment. Our method performs both detection and assignment iteratively, and in-house, by using a novel strategy that prunes entire micro-clusters out of the training set to improve the performance of the detection. It also benefits from a novel strategy that avoids clustered outliers to mask each other, which is a well-known problem in the literature. Also, D.MCA is designed to be robust to a critical hyperparameter by employing a hyperensemble "warm up" phase. Experiments performed on 16 real-world and synthetic datasets demonstrate that D.MCA outperforms 8 state-of-the-art competitors, especially on the explicit outlier micro-cluster assignment task.

</p>
</details>

<details><summary><b>Distributionally Robust Multiclass Classification and Applications in Deep Image Classifiers</b>
<a href="https://arxiv.org/abs/2210.08198">arxiv:2210.08198</a>
&#x1F4C8; 1 <br>
<p>Ruidi Chen, Boran Hao, Ioannis Ch. Paschalidis</p></summary>
<p>

**Abstract:** We develop a Distributionally Robust Optimization (DRO) formulation for Multiclass Logistic Regression (MLR), which could tolerate data contaminated by outliers. The DRO framework uses a probabilistic ambiguity set defined as a ball of distributions that are close to the empirical distribution of the training set in the sense of the Wasserstein metric. We relax the DRO formulation into a regularized learning problem whose regularizer is a norm of the coefficient matrix. We establish out-of-sample performance guarantees for the solutions to our model, offering insights on the role of the regularizer in controlling the prediction error. We apply the proposed method in rendering deep Vision Transformer (ViT)-based image classifiers robust to random and adversarial attacks. Specifically, using the MNIST and CIFAR-10 datasets, we demonstrate reductions in test error rate by up to 83.5% and loss by up to 91.3% compared with baseline methods, by adopting a novel random training method.

</p>
</details>

<details><summary><b>RoS-KD: A Robust Stochastic Knowledge Distillation Approach for Noisy Medical Imaging</b>
<a href="https://arxiv.org/abs/2210.08388">arxiv:2210.08388</a>
&#x1F4C8; 0 <br>
<p>Ajay Jaiswal, Kumar Ashutosh, Justin F Rousseau, Yifan Peng, Zhangyang Wang, Ying Ding</p></summary>
<p>

**Abstract:** AI-powered Medical Imaging has recently achieved enormous attention due to its ability to provide fast-paced healthcare diagnoses. However, it usually suffers from a lack of high-quality datasets due to high annotation cost, inter-observer variability, human annotator error, and errors in computer-generated labels. Deep learning models trained on noisy labelled datasets are sensitive to the noise type and lead to less generalization on the unseen samples. To address this challenge, we propose a Robust Stochastic Knowledge Distillation (RoS-KD) framework which mimics the notion of learning a topic from multiple sources to ensure deterrence in learning noisy information. More specifically, RoS-KD learns a smooth, well-informed, and robust student manifold by distilling knowledge from multiple teachers trained on overlapping subsets of training data. Our extensive experiments on popular medical imaging classification tasks (cardiopulmonary disease and lesion classification) using real-world datasets, show the performance benefit of RoS-KD, its ability to distill knowledge from many popular large networks (ResNet-50, DenseNet-121, MobileNet-V2) in a comparatively small network, and its robustness to adversarial attacks (PGD, FSGM). More specifically, RoS-KD achieves >2% and >4% improvement on F1-score for lesion classification and cardiopulmonary disease classification tasks, respectively, when the underlying student is ResNet-18 against recent competitive knowledge distillation baseline. Additionally, on cardiopulmonary disease classification task, RoS-KD outperforms most of the SOTA baselines by ~1% gain in AUC score.

</p>
</details>

<details><summary><b>Revisiting the Roles of "Text" in Text Games</b>
<a href="https://arxiv.org/abs/2210.08384">arxiv:2210.08384</a>
&#x1F4C8; 0 <br>
<p>Yi Gu, Shunyu Yao, Chuang Gan, Joshua B. Tenenbaum, Mo Yu</p></summary>
<p>

**Abstract:** Text games present opportunities for natural language understanding (NLU) methods to tackle reinforcement learning (RL) challenges. However, recent work has questioned the necessity of NLU by showing random text hashes could perform decently. In this paper, we pursue a fine-grained investigation into the roles of text in the face of different RL challenges, and reconcile that semantic and non-semantic language representations could be complementary rather than contrasting. Concretely, we propose a simple scheme to extract relevant contextual information into an approximate state hash as extra input for an RNN-based text agent. Such a lightweight plug-in achieves competitive performance with state-of-the-art text agents using advanced NLU techniques such as knowledge graph and passage retrieval, suggesting non-NLU methods might suffice to tackle the challenge of partial observability. However, if we remove RNN encoders and use approximate or even ground-truth state hash alone, the model performs miserably, which confirms the importance of semantic function approximation to tackle the challenge of combinatorially large observation and action spaces. Our findings and analysis provide new insights for designing better text game task setups and agents.

</p>
</details>

<details><summary><b>Variant Parallelism: Lightweight Deep Convolutional Models for Distributed Inference on IoT Devices</b>
<a href="https://arxiv.org/abs/2210.08376">arxiv:2210.08376</a>
&#x1F4C8; 0 <br>
<p>Navidreza Asadi, Maziar Goudarzi</p></summary>
<p>

**Abstract:** Two major techniques are commonly used to meet real-time inference limitations when distributing models across resource-constrained IoT devices: (1) model parallelism (MP) and (2) class parallelism (CP). In MP, transmitting bulky intermediate data (orders of magnitude larger than input) between devices imposes huge communication overhead. Although CP solves this problem, it has limitations on the number of sub-models. In addition, both solutions are fault intolerant, an issue when deployed on edge devices. We propose variant parallelism (VP), an ensemble-based deep learning distribution method where different variants of a main model are generated and can be deployed on separate machines. We design a family of lighter models around the original model, and train them simultaneously to improve accuracy over single models. Our experimental results on six common mid-sized object recognition datasets demonstrate that our models can have 5.8-7.1x fewer parameters, 4.3-31x fewer multiply-accumulations (MACs), and 2.5-13.2x less response time on atomic inputs compared to MobileNetV2 while achieving comparable or higher accuracy. Our technique easily generates several variants of the base architecture. Each variant returns only 2k outputs 1 <= k <= (#classes/2), representing Top-k classes, instead of tons of floating point values required in MP. Since each variant provides a full-class prediction, our approach maintains higher availability compared with MP and CP in presence of failure.

</p>
</details>

<details><summary><b>Improving the Intra-class Long-tail in 3D Detection via Rare Example Mining</b>
<a href="https://arxiv.org/abs/2210.08375">arxiv:2210.08375</a>
&#x1F4C8; 0 <br>
<p>Chiyu Max Jiang, Mahyar Najibi, Charles R. Qi, Yin Zhou, Dragomir Anguelov</p></summary>
<p>

**Abstract:** Continued improvements in deep learning architectures have steadily advanced the overall performance of 3D object detectors to levels on par with humans for certain tasks and datasets, where the overall performance is mostly driven by common examples. However, even the best performing models suffer from the most naive mistakes when it comes to rare examples that do not appear frequently in the training data, such as vehicles with irregular geometries. Most studies in the long-tail literature focus on class-imbalanced classification problems with known imbalanced label counts per class, but they are not directly applicable to the intra-class long-tail examples in problems with large intra-class variations such as 3D object detection, where instances with the same class label can have drastically varied properties such as shapes and sizes. Other works propose to mitigate this problem using active learning based on the criteria of uncertainty, difficulty, or diversity. In this study, we identify a new conceptual dimension - rareness - to mine new data for improving the long-tail performance of models. We show that rareness, as opposed to difficulty, is the key to data-centric improvements for 3D detectors, since rareness is the result of a lack in data support while difficulty is related to the fundamental ambiguity in the problem. We propose a general and effective method to identify the rareness of objects based on density estimation in the feature space using flow models, and propose a principled cost-aware formulation for mining rare object tracks, which improves overall model performance, but more importantly - significantly improves the performance for rare objects (by 30.97\%

</p>
</details>

<details><summary><b>Reachable Polyhedral Marching (RPM): An Exact Analysis Tool for Deep-Learned Control Systems</b>
<a href="https://arxiv.org/abs/2210.08339">arxiv:2210.08339</a>
&#x1F4C8; 0 <br>
<p>Joseph A. Vincent, Mac Schwager</p></summary>
<p>

**Abstract:** We present a tool for computing exact forward and backward reachable sets of deep neural networks with rectified linear unit (ReLU) activation. We then develop algorithms using this tool to compute invariant sets and regions of attraction (ROAs) for control systems with neural networks in the feedback loop. Our algorithm is unique in that it builds the reachable sets by incrementally enumerating polyhedral regions in the input space, rather than iterating layer-by-layer through the network as in other methods. When performing safety verification, if an unsafe region is found, our algorithm can return this result without completing the full reachability computation, thus giving an anytime property that accelerates safety verification. Furthermore, we introduce a method to accelerate the computation of ROAs in the case that deep learned components are homeomorphisms, which we find is surprisingly common in practice. We demonstrate our tool in several test cases. We compute a ROA for a learned van der Pol oscillator model. We find a control invariant set for a learned torque-controlled pendulum model. We also verify specific safety properties for multiple deep networks related to the ACAS Xu aircraft collision advisory system. Finally, we apply our algorithm to find ROAs for an image-based aircraft runway taxi problem. Algorithm source code: https://github.com/StanfordMSL/Neural-Network-Reach .

</p>
</details>

<details><summary><b>Code Recommendation for Open Source Software Developers</b>
<a href="https://arxiv.org/abs/2210.08332">arxiv:2210.08332</a>
&#x1F4C8; 0 <br>
<p>Yiqiao Jin, Yunsheng Bai, Yanqiao Zhu, Yizhou Sun, Wei Wang</p></summary>
<p>

**Abstract:** Open Source Software (OSS) is forming the spines of technology infrastructures, attracting millions of talents to contribute. Notably, it is challenging and critical to consider both the developers' interests and the semantic features of the project code to recommend appropriate development tasks to OSS developers. In this paper, we formulate the novel problem of code recommendation, whose purpose is to predict the future contribution behaviors of developers given their interaction history, the semantic features of source code, and the hierarchical file structures of projects. Considering the complex interactions among multiple parties within the system, we propose CODER, a novel graph-based code recommendation framework for open source software developers. CODER jointly models microscopic user-code interactions and macroscopic user-project interactions via a heterogeneous graph and further bridges the two levels of information through aggregation on file-structure graphs that reflect the project hierarchy. Moreover, due to the lack of reliable benchmarks, we construct three large-scale datasets to facilitate future research in this direction. Extensive experiments show that our CODER framework achieves superior performance under various experimental settings, including intra-project, cross-project, and cold-start recommendation. We will release all the datasets, code, and utilities for data retrieval upon the acceptance of this work.

</p>
</details>

<details><summary><b>CoRe: An Automated Pipeline for The Prediction of Liver Resection Complexity from Preoperative CT Scans</b>
<a href="https://arxiv.org/abs/2210.08318">arxiv:2210.08318</a>
&#x1F4C8; 0 <br>
<p>Omar Ali, Alexandre Bone, Caterina Accardo, Omar Belkouchi, Marc-Michel Rohe, Eric Vibert, Irene Vignon-Clementel</p></summary>
<p>

**Abstract:** Surgical resections are the most prevalent curative treatment for primary liver cancer. Tumors located in critical positions are known to complexify liver resections (LR). While experienced surgeons in specialized medical centers may have the necessary expertise to accurately anticipate LR complexity, and prepare accordingly, an objective method able to reproduce this behavior would have the potential to improve the standard routine of care, and avoid intra- and postoperative complications. In this article, we propose CoRe, an automated medical image processing pipeline for the prediction of postoperative LR complexity from preoperative CT scans, using imaging biomarkers. The CoRe pipeline first segments the liver, lesions, and vessels with two deep learning networks. The liver vasculature is then pruned based on a topological criterion to define the hepatic central zone (HCZ), a convex volume circumscribing the major liver vessels, from which a new imaging biomarker, BHCZ is derived. Additional biomarkers are extracted and leveraged to train and evaluate a LR complexity prediction model. An ablation study shows the HCZ-based biomarker as the central feature in predicting LR complexity. The best predictive model reaches an accuracy, F1, and AUC of 77.3, 75.4, and 84.1% respectively.

</p>
</details>

<details><summary><b>Classification of Web Phishing Kits for early detection by platform providers</b>
<a href="https://arxiv.org/abs/2210.08273">arxiv:2210.08273</a>
&#x1F4C8; 0 <br>
<p>Andrea Venturi, Michele Colajanni, Marco Ramilli, Giorgio Valenziano Santangelo</p></summary>
<p>

**Abstract:** Phishing kits are tools that dark side experts provide to the community of criminal phishers to facilitate the construction of malicious Web sites. As these kits evolve in sophistication, providers of Web-based services need to keep pace with continuous complexity. We present an original classification of a corpus of over 2000 recent phishing kits according to their adopted evasion and obfuscation functions. We carry out an initial deterministic analysis of the source code of the kits to extract the most discriminant features and information about their principal authors. We then integrate this initial classification through supervised machine learning models. Thanks to the ground-truth achieved in the first step, we can demonstrate whether and which machine learning models are able to suitably classify even the kits adopting novel evasion and obfuscation techniques that were unseen during the training phase. We compare different algorithms and evaluate their robustness in the realistic case in which only a small number of phishing kits are available for training. This paper represents an initial but important step to support Web service providers and analysts in improving early detection mechanisms and intelligence operations for the phishing kits that might be installed on their platforms.

</p>
</details>

<details><summary><b>Providing Error Detection for Deep Learning Image Classifiers Using Self-Explainability</b>
<a href="https://arxiv.org/abs/2210.08210">arxiv:2210.08210</a>
&#x1F4C8; 0 <br>
<p>Mohammad Mahdi Karimi, Azin Heidarshenas, William W. Edmonson</p></summary>
<p>

**Abstract:** This paper proposes a self-explainable Deep Learning (SE-DL) system for an image classification problem that performs self-error detection. The self-error detection is key to improving the DL system's safe operation, especially in safety-critical applications such as automotive systems. A SE-DL system outputs both the class prediction and an explanation for that prediction, which provides insight into how the system makes its predictions for humans. Additionally, we leverage the explanation of the proposed SE-DL system to detect potential class prediction errors of the system. The proposed SE-DL system uses a set of concepts to generate the explanation. The concepts are human-understandable lower-level image features in each input image relevant to the higher-level class of that image. We present a concept selection methodology for scoring all concepts and selecting a subset of them based on their contribution to the error detection performance of the proposed SE-DL system. Finally, we present different error detection schemes using the proposed SE-DL system to compare them against an error detection scheme without any SE-DL system.

</p>
</details>


{% endraw %}
Prev: [2022.10.14]({{ '/2022/10/14/2022.10.14.html' | relative_url }})  Next: [2022.10.16]({{ '/2022/10/16/2022.10.16.html' | relative_url }})