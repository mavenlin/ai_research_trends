## Summary for 2021-07-22, created on 2021-12-19


<details><summary><b>Real-ESRGAN: Training Real-World Blind Super-Resolution with Pure Synthetic Data</b>
<a href="https://arxiv.org/abs/2107.10833">arxiv:2107.10833</a>
&#x1F4C8; 114 <br>
<p>Xintao Wang, Liangbin Xie, Chao Dong, Ying Shan</p></summary>
<p>

**Abstract:** Though many attempts have been made in blind super-resolution to restore low-resolution images with unknown and complex degradations, they are still far from addressing general real-world degraded images. In this work, we extend the powerful ESRGAN to a practical restoration application (namely, Real-ESRGAN), which is trained with pure synthetic data. Specifically, a high-order degradation modeling process is introduced to better simulate complex real-world degradations. We also consider the common ringing and overshoot artifacts in the synthesis process. In addition, we employ a U-Net discriminator with spectral normalization to increase discriminator capability and stabilize the training dynamics. Extensive comparisons have shown its superior visual performance than prior works on various real datasets. We also provide efficient implementations to synthesize training pairs on the fly.

</p>
</details>

<details><summary><b>QuantumNAS: Noise-Adaptive Search for Robust Quantum Circuits</b>
<a href="https://arxiv.org/abs/2107.10845">arxiv:2107.10845</a>
&#x1F4C8; 47 <br>
<p>Hanrui Wang, Yongshan Ding, Jiaqi Gu, Zirui Li, Yujun Lin, David Z. Pan, Frederic T. Chong, Song Han</p></summary>
<p>

**Abstract:** Quantum noise is the key challenge in Noisy Intermediate-Scale Quantum (NISQ) computers. Previous work for mitigating noise has primarily focused on gate-level or pulse-level noise-adaptive compilation. However, limited research efforts have explored a higher level of optimization by making the quantum circuits themselves resilient to noise.
  We propose QuantumNAS, a comprehensive framework for noise-adaptive co-search of the variational circuit and qubit mapping. Variational quantum circuits are a promising approach for constructing QML and quantum simulation. However, finding the best variational circuit and its optimal parameters is challenging due to the large design space and parameter training cost. We propose to decouple the circuit search and parameter training by introducing a novel SuperCircuit. The SuperCircuit is constructed with multiple layers of pre-defined parameterized gates and trained by iteratively sampling and updating the parameter subsets (SubCircuits) of it. It provides an accurate estimation of SubCircuits performance trained from scratch. Then we perform an evolutionary co-search of SubCircuit and its qubit mapping. The SubCircuit performance is estimated with parameters inherited from SuperCircuit and simulated with real device noise models. Finally, we perform iterative gate pruning and finetuning to remove redundant gates.
  Extensively evaluated with 12 QML and VQE benchmarks on 10 quantum comput, QuantumNAS significantly outperforms baselines. For QML, QuantumNAS is the first to demonstrate over 95% 2-class, 85% 4-class, and 32% 10-class classification accuracy on real QC. It also achieves the lowest eigenvalue for VQE tasks on H2, H2O, LiH, CH4, BeH2 compared with UCCSD. We also open-source torchquantum (https://github.com/mit-han-lab/pytorch-quantum) for fast training of parameterized quantum circuits to facilitate future research.

</p>
</details>

<details><summary><b>Neural Variational Gradient Descent</b>
<a href="https://arxiv.org/abs/2107.10731">arxiv:2107.10731</a>
&#x1F4C8; 29 <br>
<p>Lauro Langosco di Langosco, Vincent Fortuin, Heiko Strathmann</p></summary>
<p>

**Abstract:** Particle-based approximate Bayesian inference approaches such as Stein Variational Gradient Descent (SVGD) combine the flexibility and convergence guarantees of sampling methods with the computational benefits of variational inference. In practice, SVGD relies on the choice of an appropriate kernel function, which impacts its ability to model the target distribution -- a challenging problem with only heuristic solutions. We propose Neural Variational Gradient Descent (NVGD), which is based on parameterizing the witness function of the Stein discrepancy by a deep neural network whose parameters are learned in parallel to the inference, mitigating the necessity to make any kernel choices whatsoever. We empirically evaluate our method on popular synthetic inference problems, real-world Bayesian linear regression, and Bayesian neural network inference.

</p>
</details>

<details><summary><b>LARGE: Latent-Based Regression through GAN Semantics</b>
<a href="https://arxiv.org/abs/2107.11186">arxiv:2107.11186</a>
&#x1F4C8; 28 <br>
<p>Yotam Nitzan, Rinon Gal, Ofir Brenner, Daniel Cohen-Or</p></summary>
<p>

**Abstract:** We propose a novel method for solving regression tasks using few-shot or weak supervision. At the core of our method is the fundamental observation that GANs are incredibly successful at encoding semantic information within their latent space, even in a completely unsupervised setting. For modern generative frameworks, this semantic encoding manifests as smooth, linear directions which affect image attributes in a disentangled manner. These directions have been widely used in GAN-based image editing. We show that such directions are not only linear, but that the magnitude of change induced on the respective attribute is approximately linear with respect to the distance traveled along them. By leveraging this observation, our method turns a pre-trained GAN into a regression model, using as few as two labeled samples. This enables solving regression tasks on datasets and attributes which are difficult to produce quality supervision for. Additionally, we show that the same latent-distances can be used to sort collections of images by the strength of given attributes, even in the absence of explicit supervision. Extensive experimental evaluations demonstrate that our method can be applied across a wide range of domains, leverage multiple latent direction discovery frameworks, and achieve state-of-the-art results in few-shot and low-supervision settings, even when compared to methods designed to tackle a single task.

</p>
</details>

<details><summary><b>Efficient Neural Causal Discovery without Acyclicity Constraints</b>
<a href="https://arxiv.org/abs/2107.10483">arxiv:2107.10483</a>
&#x1F4C8; 22 <br>
<p>Phillip Lippe, Taco Cohen, Efstratios Gavves</p></summary>
<p>

**Abstract:** Learning the structure of a causal graphical model using both observational and interventional data is a fundamental problem in many scientific fields. A promising direction is continuous optimization for score-based methods, which efficiently learn the causal graph in a data-driven manner. However, to date, those methods require constrained optimization to enforce acyclicity or lack convergence guarantees. In this paper, we present ENCO, an efficient structure learning method for directed, acyclic causal graphs leveraging observational and interventional data. ENCO formulates the graph search as an optimization of independent edge likelihoods, with the edge orientation being modeled as a separate parameter. Consequently, we can provide convergence guarantees of ENCO under mild conditions without constraining the score function with respect to acyclicity. In experiments, we show that ENCO can efficiently recover graphs with hundreds of nodes, an order of magnitude larger than what was previously possible, while handling deterministic variables and latent confounders.

</p>
</details>

<details><summary><b>Typing assumptions improve identification in causal discovery</b>
<a href="https://arxiv.org/abs/2107.10703">arxiv:2107.10703</a>
&#x1F4C8; 12 <br>
<p>Philippe Brouillard, Perouz Taslakian, Alexandre Lacoste, Sebastien Lachapelle, Alexandre Drouin</p></summary>
<p>

**Abstract:** Causal discovery from observational data is a challenging task to which an exact solution cannot always be identified. Under assumptions about the data-generative process, the causal graph can often be identified up to an equivalence class. Proposing new realistic assumptions to circumscribe such equivalence classes is an active field of research. In this work, we propose a new set of assumptions that constrain possible causal relationships based on the nature of the variables. We thus introduce typed directed acyclic graphs, in which variable types are used to determine the validity of causal relationships. We demonstrate, both theoretically and empirically, that the proposed assumptions can result in significant gains in the identification of the causal graph.

</p>
</details>

<details><summary><b>Recovering lost and absent information in temporal networks</b>
<a href="https://arxiv.org/abs/2107.10835">arxiv:2107.10835</a>
&#x1F4C8; 7 <br>
<p>James P. Bagrow, Sune Lehmann</p></summary>
<p>

**Abstract:** The full range of activity in a temporal network is captured in its edge activity data -- time series encoding the tie strengths or on-off dynamics of each edge in the network. However, in many practical applications, edge-level data are unavailable, and the network analyses must rely instead on node activity data which aggregates the edge-activity data and thus is less informative. This raises the question: Is it possible to use the static network to recover the richer edge activities from the node activities? Here we show that recovery is possible, often with a surprising degree of accuracy given how much information is lost, and that the recovered data are useful for subsequent network analysis tasks. Recovery is more difficult when network density increases, either topologically or dynamically, but exploiting dynamical and topological sparsity enables effective solutions to the recovery problem. We formally characterize the difficulty of the recovery problem both theoretically and empirically, proving the conditions under which recovery errors can be bounded and showing that, even when these conditions are not met, good quality solutions can still be derived. Effective recovery carries both promise and peril, as it enables deeper scientific study of complex systems but in the context of social systems also raises privacy concerns when social information can be aggregated across multiple data sources.

</p>
</details>

<details><summary><b>Implicit Rate-Constrained Optimization of Non-decomposable Objectives</b>
<a href="https://arxiv.org/abs/2107.10960">arxiv:2107.10960</a>
&#x1F4C8; 6 <br>
<p>Abhishek Kumar, Harikrishna Narasimhan, Andrew Cotter</p></summary>
<p>

**Abstract:** We consider a popular family of constrained optimization problems arising in machine learning that involve optimizing a non-decomposable evaluation metric with a certain thresholded form, while constraining another metric of interest. Examples of such problems include optimizing the false negative rate at a fixed false positive rate, optimizing precision at a fixed recall, optimizing the area under the precision-recall or ROC curves, etc. Our key idea is to formulate a rate-constrained optimization that expresses the threshold parameter as a function of the model parameters via the Implicit Function theorem. We show how the resulting optimization problem can be solved using standard gradient based methods. Experiments on benchmark datasets demonstrate the effectiveness of our proposed method over existing state-of-the art approaches for these problems. The code for the proposed method is available at https://github.com/google-research/google-research/tree/master/implicit_constrained_optimization .

</p>
</details>

<details><summary><b>What are you optimizing for? Aligning Recommender Systems with Human Values</b>
<a href="https://arxiv.org/abs/2107.10939">arxiv:2107.10939</a>
&#x1F4C8; 6 <br>
<p>Jonathan Stray, Ivan Vendrov, Jeremy Nixon, Steven Adler, Dylan Hadfield-Menell</p></summary>
<p>

**Abstract:** We describe cases where real recommender systems were modified in the service of various human values such as diversity, fairness, well-being, time well spent, and factual accuracy. From this we identify the current practice of values engineering: the creation of classifiers from human-created data with value-based labels. This has worked in practice for a variety of issues, but problems are addressed one at a time, and users and other stakeholders have seldom been involved. Instead, we look to AI alignment work for approaches that could learn complex values directly from stakeholders, and identify four major directions: useful measures of alignment, participatory design and operation, interactive value learning, and informed deliberative judgments.

</p>
</details>

<details><summary><b>Structured second-order methods via natural gradient descent</b>
<a href="https://arxiv.org/abs/2107.10884">arxiv:2107.10884</a>
&#x1F4C8; 6 <br>
<p>Wu Lin, Frank Nielsen, Mohammad Emtiyaz Khan, Mark Schmidt</p></summary>
<p>

**Abstract:** In this paper, we propose new structured second-order methods and structured adaptive-gradient methods obtained by performing natural-gradient descent on structured parameter spaces. Natural-gradient descent is an attractive approach to design new algorithms in many settings such as gradient-free, adaptive-gradient, and second-order methods. Our structured methods not only enjoy a structural invariance but also admit a simple expression. Finally, we test the efficiency of our proposed methods on both deterministic non-convex problems and deep learning problems.

</p>
</details>

<details><summary><b>cCorrGAN: Conditional Correlation GAN for Learning Empirical Conditional Distributions in the Elliptope</b>
<a href="https://arxiv.org/abs/2107.10606">arxiv:2107.10606</a>
&#x1F4C8; 6 <br>
<p>Gautier Marti, Victor Goubet, Frank Nielsen</p></summary>
<p>

**Abstract:** We propose a methodology to approximate conditional distributions in the elliptope of correlation matrices based on conditional generative adversarial networks. We illustrate the methodology with an application from quantitative finance: Monte Carlo simulations of correlated returns to compare risk-based portfolio construction methods. Finally, we discuss about current limitations and advocate for further exploration of the elliptope geometry to improve results.

</p>
</details>

<details><summary><b>Resource Efficient Mountainous Skyline Extraction using Shallow Learning</b>
<a href="https://arxiv.org/abs/2107.10997">arxiv:2107.10997</a>
&#x1F4C8; 5 <br>
<p>Touqeer Ahmad, Ebrahim Emami, Martin Čadík, George Bebis</p></summary>
<p>

**Abstract:** Skyline plays a pivotal role in mountainous visual geo-localization and localization/navigation of planetary rovers/UAVs and virtual/augmented reality applications. We present a novel mountainous skyline detection approach where we adapt a shallow learning approach to learn a set of filters to discriminate between edges belonging to sky-mountain boundary and others coming from different regions. Unlike earlier approaches, which either rely on extraction of explicit feature descriptors and their classification, or fine-tuning general scene parsing deep networks for sky segmentation, our approach learns linear filters based on local structure analysis. At test time, for every candidate edge pixel, a single filter is chosen from the set of learned filters based on pixel's structure tensor, and then applied to the patch around it. We then employ dynamic programming to solve the shortest path problem for the resultant multistage graph to get the sky-mountain boundary. The proposed approach is computationally faster than earlier methods while providing comparable performance and is more suitable for resource constrained platforms e.g., mobile devices, planetary rovers and UAVs. We compare our proposed approach against earlier skyline detection methods using four different data sets. Our code is available at \url{https://github.com/TouqeerAhmad/skyline_detection}.

</p>
</details>

<details><summary><b>FNetAR: Mixing Tokens with Autoregressive Fourier Transforms</b>
<a href="https://arxiv.org/abs/2107.10932">arxiv:2107.10932</a>
&#x1F4C8; 5 <br>
<p>Tim Lou, Michael Park, Mohammad Ramezanali, Vincent Tang</p></summary>
<p>

**Abstract:** In this note we examine the autoregressive generalization of the FNet algorithm, in which self-attention layers from the standard Transformer architecture are substituted with a trivial sparse-uniformsampling procedure based on Fourier transforms. Using the Wikitext-103 benchmark, we demonstratethat FNetAR retains state-of-the-art performance (25.8 ppl) on the task of causal language modelingcompared to a Transformer-XL baseline (24.2 ppl) with only half the number self-attention layers,thus providing further evidence for the superfluity of deep neural networks with heavily compoundedattention mechanisms. The autoregressive Fourier transform could likely be used for parameterreduction on most Transformer-based time-series prediction models.

</p>
</details>

<details><summary><b>Domain Generalization under Conditional and Label Shifts via Variational Bayesian Inference</b>
<a href="https://arxiv.org/abs/2107.10931">arxiv:2107.10931</a>
&#x1F4C8; 5 <br>
<p>Xiaofeng Liu, Bo Hu, Linghao Jin, Xu Han, Fangxu Xing, Jinsong Ouyang, Jun Lu, Georges EL Fakhri, Jonghye Woo</p></summary>
<p>

**Abstract:** In this work, we propose a domain generalization (DG) approach to learn on several labeled source domains and transfer knowledge to a target domain that is inaccessible in training. Considering the inherent conditional and label shifts, we would expect the alignment of $p(x|y)$ and $p(y)$. However, the widely used domain invariant feature learning (IFL) methods relies on aligning the marginal concept shift w.r.t. $p(x)$, which rests on an unrealistic assumption that $p(y)$ is invariant across domains. We thereby propose a novel variational Bayesian inference framework to enforce the conditional distribution alignment w.r.t. $p(x|y)$ via the prior distribution matching in a latent space, which also takes the marginal label shift w.r.t. $p(y)$ into consideration with the posterior alignment. Extensive experiments on various benchmarks demonstrate that our framework is robust to the label shift and the cross-domain accuracy is significantly improved, thereby achieving superior performance over the conventional IFL counterparts.

</p>
</details>

<details><summary><b>AD-GAN: End-to-end Unsupervised Nuclei Segmentation with Aligned Disentangling Training</b>
<a href="https://arxiv.org/abs/2107.11022">arxiv:2107.11022</a>
&#x1F4C8; 4 <br>
<p>Kai Yao, Kaizhu Huang, Jie Sun, Curran Jude</p></summary>
<p>

**Abstract:** We consider unsupervised cell nuclei segmentation in this paper. Exploiting the recently-proposed unpaired image-to-image translation between cell nuclei images and randomly synthetic masks, existing approaches, e.g., CycleGAN, have achieved encouraging results. However, these methods usually take a two-stage pipeline and fail to learn end-to-end in cell nuclei images. More seriously, they could lead to the lossy transformation problem, i.e., the content inconsistency between the original images and the corresponding segmentation output. To address these limitations, we propose a novel end-to-end unsupervised framework called Aligned Disentangling Generative Adversarial Network (AD-GAN). Distinctively, AD-GAN introduces representation disentanglement to separate content representation (the underling spatial structure) from style representation (the rendering of the structure). With this framework, spatial structure can be preserved explicitly, enabling a significant reduction of macro-level lossy transformation. We also propose a novel training algorithm able to align the disentangled content in the latent space to reduce micro-level lossy transformation. Evaluations on real-world 2D and 3D datasets show that AD-GAN substantially outperforms the other comparison methods and the professional software both quantitatively and qualitatively. Specifically, the proposed AD-GAN leads to significant improvement over the current best unsupervised methods by an average 17.8% relatively (w.r.t. the metric DICE) on four cell nuclei datasets. As an unsupervised method, AD-GAN even performs competitive with the best supervised models, taking a further leap towards end-to-end unsupervised nuclei segmentation.

</p>
</details>

<details><summary><b>Photon-Starved Scene Inference using Single Photon Cameras</b>
<a href="https://arxiv.org/abs/2107.11001">arxiv:2107.11001</a>
&#x1F4C8; 4 <br>
<p>Bhavya Goyal, Mohit Gupta</p></summary>
<p>

**Abstract:** Scene understanding under low-light conditions is a challenging problem. This is due to the small number of photons captured by the camera and the resulting low signal-to-noise ratio (SNR). Single-photon cameras (SPCs) are an emerging sensing modality that are capable of capturing images with high sensitivity. Despite having minimal read-noise, images captured by SPCs in photon-starved conditions still suffer from strong shot noise, preventing reliable scene inference. We propose photon scale-space a collection of high-SNR images spanning a wide range of photons-per-pixel (PPP) levels (but same scene content) as guides to train inference model on low photon flux images. We develop training techniques that push images with different illumination levels closer to each other in feature representation space. The key idea is that having a spectrum of different brightness levels during training enables effective guidance, and increases robustness to shot noise even in extreme noise cases. Based on the proposed approach, we demonstrate, via simulations and real experiments with a SPAD camera, high-performance on various inference tasks such as image classification and monocular depth estimation under ultra low-light, down to < 1 PPP.

</p>
</details>

<details><summary><b>SAGE: A Split-Architecture Methodology for Efficient End-to-End Autonomous Vehicle Control</b>
<a href="https://arxiv.org/abs/2107.10895">arxiv:2107.10895</a>
&#x1F4C8; 4 <br>
<p>Arnav Malawade, Mohanad Odema, Sebastien Lajeunesse-DeGroot, Mohammad Abdullah Al Faruque</p></summary>
<p>

**Abstract:** Autonomous vehicles (AV) are expected to revolutionize transportation and improve road safety significantly. However, these benefits do not come without cost; AVs require large Deep-Learning (DL) models and powerful hardware platforms to operate reliably in real-time, requiring between several hundred watts to one kilowatt of power. This power consumption can dramatically reduce vehicles' driving range and affect emissions. To address this problem, we propose SAGE: a methodology for selectively offloading the key energy-consuming modules of DL architectures to the cloud to optimize edge energy usage while meeting real-time latency constraints. Furthermore, we leverage Head Network Distillation (HND) to introduce efficient bottlenecks within the DL architecture in order to minimize the network overhead costs of offloading with almost no degradation in the model's performance. We evaluate SAGE using an Nvidia Jetson TX2 and an industry-standard Nvidia Drive PX2 as the AV edge devices and demonstrate that our offloading strategy is practical for a wide range of DL models and internet connection bandwidths on 3G, 4G LTE, and WiFi technologies. Compared to edge-only computation, SAGE reduces energy consumption by an average of 36.13%, 47.07%, and 55.66% for an AV with one low-resolution camera, one high-resolution camera, and three high-resolution cameras, respectively. SAGE also reduces upload data size by up to 98.40% compared to direct camera offloading.

</p>
</details>

<details><summary><b>On the Certified Robustness for Ensemble Models and Beyond</b>
<a href="https://arxiv.org/abs/2107.10873">arxiv:2107.10873</a>
&#x1F4C8; 4 <br>
<p>Zhuolin Yang, Linyi Li, Xiaojun Xu, Bhavya Kailkhura, Tao Xie, Bo Li</p></summary>
<p>

**Abstract:** Recent studies show that deep neural networks (DNN) are vulnerable to adversarial examples, which aim to mislead DNNs by adding perturbations with small magnitude. To defend against such attacks, both empirical and theoretical defense approaches have been extensively studied for a single ML model. In this work, we aim to analyze and provide the certified robustness for ensemble ML models, together with the sufficient and necessary conditions of robustness for different ensemble protocols. Although ensemble models are shown more robust than a single model empirically; surprisingly, we find that in terms of the certified robustness the standard ensemble models only achieve marginal improvement compared to a single model. Thus, to explore the conditions that guarantee to provide certifiably robust ensemble ML models, we first prove that diversified gradient and large confidence margin are sufficient and necessary conditions for certifiably robust ensemble models under the model-smoothness assumption. We then provide the bounded model-smoothness analysis based on the proposed Ensemble-before-Smoothing strategy. We also prove that an ensemble model can always achieve higher certified robustness than a single base model under mild conditions. Inspired by the theoretical findings, we propose the lightweight Diversity Regularized Training (DRT) to train certifiably robust ensemble ML models. Extensive experiments show that our DRT enhanced ensembles can consistently achieve higher certified robustness than existing single and ensemble ML models, demonstrating the state-of-the-art certified L2-robustness on MNIST, CIFAR-10, and ImageNet datasets.

</p>
</details>

<details><summary><b>Fast Low-Rank Tensor Decomposition by Ridge Leverage Score Sampling</b>
<a href="https://arxiv.org/abs/2107.10654">arxiv:2107.10654</a>
&#x1F4C8; 4 <br>
<p>Matthew Fahrbach, Mehrdad Ghadiri, Thomas Fu</p></summary>
<p>

**Abstract:** Low-rank tensor decomposition generalizes low-rank matrix approximation and is a powerful technique for discovering low-dimensional structure in high-dimensional data. In this paper, we study Tucker decompositions and use tools from randomized numerical linear algebra called ridge leverage scores to accelerate the core tensor update step in the widely-used alternating least squares (ALS) algorithm. Updating the core tensor, a severe bottleneck in ALS, is a highly-structured ridge regression problem where the design matrix is a Kronecker product of the factor matrices. We show how to use approximate ridge leverage scores to construct a sketched instance for any ridge regression problem such that the solution vector for the sketched problem is a $(1+\varepsilon)$-approximation to the original instance. Moreover, we show that classical leverage scores suffice as an approximation, which then allows us to exploit the Kronecker structure and update the core tensor in time that depends predominantly on the rank and the sketching parameters (i.e., sublinear in the size of the input tensor). We also give upper bounds for ridge leverage scores as rows are removed from the design matrix (e.g., if the tensor has missing entries), and we demonstrate the effectiveness of our approximate ridge regressioni algorithm for large, low-rank Tucker decompositions on both synthetic and real-world data.

</p>
</details>

<details><summary><b>3D Shape Generation with Grid-based Implicit Functions</b>
<a href="https://arxiv.org/abs/2107.10607">arxiv:2107.10607</a>
&#x1F4C8; 4 <br>
<p>Moritz Ibing, Isaak Lim, Leif Kobbelt</p></summary>
<p>

**Abstract:** Previous approaches to generate shapes in a 3D setting train a GAN on the latent space of an autoencoder (AE). Even though this produces convincing results, it has two major shortcomings. As the GAN is limited to reproduce the dataset the AE was trained on, we cannot reuse a trained AE for novel data. Furthermore, it is difficult to add spatial supervision into the generation process, as the AE only gives us a global representation. To remedy these issues, we propose to train the GAN on grids (i.e. each cell covers a part of a shape). In this representation each cell is equipped with a latent vector provided by an AE. This localized representation enables more expressiveness (since the cell-based latent vectors can be combined in novel ways) as well as spatial control of the generation process (e.g. via bounding boxes). Our method outperforms the current state of the art on all established evaluation measures, proposed for quantitatively evaluating the generative capabilities of GANs. We show limitations of these measures and propose the adaptation of a robust criterion from statistical analysis as an alternative.

</p>
</details>

<details><summary><b>Abstract Reasoning via Logic-guided Generation</b>
<a href="https://arxiv.org/abs/2107.10493">arxiv:2107.10493</a>
&#x1F4C8; 4 <br>
<p>Sihyun Yu, Sangwoo Mo, Sungsoo Ahn, Jinwoo Shin</p></summary>
<p>

**Abstract:** Abstract reasoning, i.e., inferring complicated patterns from given observations, is a central building block of artificial general intelligence. While humans find the answer by either eliminating wrong candidates or first constructing the answer, prior deep neural network (DNN)-based methods focus on the former discriminative approach. This paper aims to design a framework for the latter approach and bridge the gap between artificial and human intelligence. To this end, we propose logic-guided generation (LoGe), a novel generative DNN framework that reduces abstract reasoning as an optimization problem in propositional logic. LoGe is composed of three steps: extract propositional variables from images, reason the answer variables with a logic layer, and reconstruct the answer image from the variables. We demonstrate that LoGe outperforms the black box DNN frameworks for generative abstract reasoning under the RAVEN benchmark, i.e., reconstructing answers based on capturing correct rules of various attributes from observations.

</p>
</details>

<details><summary><b>Artificial Intelligence in Achieving Sustainable Development Goals</b>
<a href="https://arxiv.org/abs/2107.13966">arxiv:2107.13966</a>
&#x1F4C8; 3 <br>
<p>Hoe-Han Goh</p></summary>
<p>

**Abstract:** This perspective illustrates some of the AI applications that can accelerate the achievement of SDGs and also highlights some of the considerations that could hinder the efforts towards them. This emphasizes the importance of establishing standard AI guidelines and regulations for the beneficial applications of AI.

</p>
</details>

<details><summary><b>Regularising Inverse Problems with Generative Machine Learning Models</b>
<a href="https://arxiv.org/abs/2107.11191">arxiv:2107.11191</a>
&#x1F4C8; 3 <br>
<p>Margaret Duff, Neill D. F. Campbell, Matthias J. Ehrhardt</p></summary>
<p>

**Abstract:** Deep neural network approaches to inverse imaging problems have produced impressive results in the last few years. In this paper, we consider the use of generative models in a variational regularisation approach to inverse problems. The considered regularisers penalise images that are far from the range of a generative model that has learned to produce images similar to a training dataset. We name this family \textit{generative regularisers}. The success of generative regularisers depends on the quality of the generative model and so we propose a set of desired criteria to assess models and guide future research. In our numerical experiments, we evaluate three common generative models, autoencoders, variational autoencoders and generative adversarial networks, against our desired criteria. We also test three different generative regularisers on the inverse problems of deblurring, deconvolution, and tomography. We show that the success of solutions restricted to lie exactly in the range of the generator is highly dependent on the ability of the generative model but that allowing small deviations from the range of the generator produces more consistent results.

</p>
</details>

<details><summary><b>Pruning Ternary Quantization</b>
<a href="https://arxiv.org/abs/2107.10998">arxiv:2107.10998</a>
&#x1F4C8; 3 <br>
<p>Dan Liu, Xi Chen, Jie Fu, Xue Liu</p></summary>
<p>

**Abstract:** We propose pruning ternary quantization (PTQ), a simple, yet effective, symmetric ternary quantization method. The method significantly compresses neural network weights to a sparse ternary of [-1,0,1] and thus reduces computational, storage, and memory footprints. We show that PTQ can convert regular weights to ternary orthonormal bases by simply using pruning and L2 projection. In addition, we introduce a refined straight-through estimator to finalize and stabilize the quantized weights. Our method can provide at most 46x compression ratio on the ResNet-18 structure, with an acceptable accuracy of 65.36%, outperforming leading methods. Furthermore, PTQ can compress a ResNet-18 model from 46 MB to 955KB (~48x) and a ResNet-50 model from 99 MB to 3.3MB (~30x), while the top-1 accuracy on ImageNet drops slightly from 69.7% to 65.3% and from 76.15% to 74.47%, respectively. Our method unifies pruning and quantization and thus provides a range of size-accuracy trade-off.

</p>
</details>

<details><summary><b>Compositional Models: Multi-Task Learning and Knowledge Transfer with Modular Networks</b>
<a href="https://arxiv.org/abs/2107.10963">arxiv:2107.10963</a>
&#x1F4C8; 3 <br>
<p>Andrey Zhmoginov, Dina Bashkirova, Mark Sandler</p></summary>
<p>

**Abstract:** Conditional computation and modular networks have been recently proposed for multitask learning and other problems as a way to decompose problem solving into multiple reusable computational blocks. We propose a new approach for learning modular networks based on the isometric version of ResNet with all residual blocks having the same configuration and the same number of parameters. This architectural choice allows adding, removing and changing the order of residual blocks. In our method, the modules can be invoked repeatedly and allow knowledge transfer to novel tasks by adjusting the order of computation. This allows soft weight sharing between tasks with only a small increase in the number of parameters. We show that our method leads to interpretable self-organization of modules in case of multi-task learning, transfer learning and domain adaptation while achieving competitive results on those tasks. From practical perspective, our approach allows to: (a) reuse existing modules for learning new task by adjusting the computation order, (b) use it for unsupervised multi-source domain adaptation to illustrate that adaptation to unseen data can be achieved by only manipulating the order of pretrained modules, (c) show how our approach can be used to increase accuracy of existing architectures for image classification tasks such as ImageNet, without any parameter increase, by reusing the same block multiple times.

</p>
</details>

<details><summary><b>A Logic of Expertise</b>
<a href="https://arxiv.org/abs/2107.10832">arxiv:2107.10832</a>
&#x1F4C8; 3 <br>
<p>Joseph Singleton</p></summary>
<p>

**Abstract:** In this paper we introduce a simple modal logic framework to reason about the expertise of an information source. In the framework, a source is an expert on a proposition $p$ if they are able to correctly determine the truth value of $p$ in any possible world. We also consider how information may be false, but true after accounting for the lack of expertise of the source. This is relevant for modelling situations in which information sources make claims beyond their domain of expertise. We use non-standard semantics for the language based on an expertise set with certain closure properties. It turns out there is a close connection between our semantics and S5 epistemic logic, so that expertise can be expressed in terms of knowledge at all possible states. We use this connection to obtain a sound and complete axiomatisation.

</p>
</details>

<details><summary><b>Segmentation of Cardiac Structures via Successive Subspace Learning with Saab Transform from Cine MRI</b>
<a href="https://arxiv.org/abs/2107.10718">arxiv:2107.10718</a>
&#x1F4C8; 3 <br>
<p>Xiaofeng Liu, Fangxu Xing, Hanna K. Gaggin, Weichung Wang, C. -C. Jay Kuo, Georges El Fakhri, Jonghye Woo</p></summary>
<p>

**Abstract:** Assessment of cardiovascular disease (CVD) with cine magnetic resonance imaging (MRI) has been used to non-invasively evaluate detailed cardiac structure and function. Accurate segmentation of cardiac structures from cine MRI is a crucial step for early diagnosis and prognosis of CVD, and has been greatly improved with convolutional neural networks (CNN). There, however, are a number of limitations identified in CNN models, such as limited interpretability and high complexity, thus limiting their use in clinical practice. In this work, to address the limitations, we propose a lightweight and interpretable machine learning model, successive subspace learning with the subspace approximation with adjusted bias (Saab) transform, for accurate and efficient segmentation from cine MRI. Specifically, our segmentation framework is comprised of the following steps: (1) sequential expansion of near-to-far neighborhood at different resolutions; (2) channel-wise subspace approximation using the Saab transform for unsupervised dimension reduction; (3) class-wise entropy guided feature selection for supervised dimension reduction; (4) concatenation of features and pixel-wise classification with gradient boost; and (5) conditional random field for post-processing. Experimental results on the ACDC 2017 segmentation database, showed that our framework performed better than state-of-the-art U-Net models with 200$\times$ fewer parameters in delineating the left ventricle, right ventricle, and myocardium, thus showing its potential to be used in clinical practice.

</p>
</details>

<details><summary><b>Bandit Quickest Changepoint Detection</b>
<a href="https://arxiv.org/abs/2107.10492">arxiv:2107.10492</a>
&#x1F4C8; 3 <br>
<p>Aditya Gopalan, Venkatesh Saligrama, Braghadeesh Lakshminarayanan</p></summary>
<p>

**Abstract:** Many industrial and security applications employ a suite of sensors for detecting abrupt changes in temporal behavior patterns. These abrupt changes typically manifest locally, rendering only a small subset of sensors informative. Continuous monitoring of every sensor can be expensive due to resource constraints, and serves as a motivation for the bandit quickest changepoint detection problem, where sensing actions (or sensors) are sequentially chosen, and only measurements corresponding to chosen actions are observed. We derive an information-theoretic lower bound on the detection delay for a general class of finitely parameterized probability distributions. We then propose a computationally efficient online sensing scheme, which seamlessly balances the need for exploration of different sensing options with exploitation of querying informative actions. We derive expected delay bounds for the proposed scheme and show that these bounds match our information-theoretic lower bounds at low false alarm rates, establishing optimality of the proposed method. We then perform a number of experiments on synthetic and real datasets demonstrating the effectiveness of our proposed method.

</p>
</details>

<details><summary><b>Unsupervised Detection of Adversarial Examples with Model Explanations</b>
<a href="https://arxiv.org/abs/2107.10480">arxiv:2107.10480</a>
&#x1F4C8; 3 <br>
<p>Gihyuk Ko, Gyumin Lim</p></summary>
<p>

**Abstract:** Deep Neural Networks (DNNs) have shown remarkable performance in a diverse range of machine learning applications. However, it is widely known that DNNs are vulnerable to simple adversarial perturbations, which causes the model to incorrectly classify inputs. In this paper, we propose a simple yet effective method to detect adversarial examples, using methods developed to explain the model's behavior. Our key observation is that adding small, humanly imperceptible perturbations can lead to drastic changes in the model explanations, resulting in unusual or irregular forms of explanations. From this insight, we propose an unsupervised detection of adversarial examples using reconstructor networks trained only on model explanations of benign examples. Our evaluations with MNIST handwritten dataset show that our method is capable of detecting adversarial examples generated by the state-of-the-art algorithms with high confidence. To the best of our knowledge, this work is the first in suggesting unsupervised defense method using model explanations.

</p>
</details>

<details><summary><b>Improving Polyphonic Sound Event Detection on Multichannel Recordings with the Sørensen-Dice Coefficient Loss and Transfer Learning</b>
<a href="https://arxiv.org/abs/2107.10471">arxiv:2107.10471</a>
&#x1F4C8; 3 <br>
<p>Karn N. Watcharasupat, Thi Ngoc Tho Nguyen, Ngoc Khanh Nguyen, Zhen Jian Lee, Douglas L. Jones, Woon Seng Gan</p></summary>
<p>

**Abstract:** The Sørensen--Dice Coefficient has recently seen rising popularity as a loss function (also known as Dice loss) due to its robustness in tasks where the number of negative samples significantly exceeds that of positive samples, such as semantic segmentation, natural language processing, and sound event detection. Conventional training of polyphonic sound event detection systems with binary cross-entropy loss often results in suboptimal detection performance as the training is often overwhelmed by updates from negative samples. In this paper, we investigated the effect of the Dice loss, intra- and inter-modal transfer learning, data augmentation, and recording formats, on the performance of polyphonic sound event detection systems with multichannel inputs. Our analysis showed that polyphonic sound event detection systems trained with Dice loss consistently outperformed those trained with cross-entropy loss across different training settings and recording formats in terms of F1 score and error rate. We achieved further performance gains via the use of transfer learning and an appropriate combination of different data augmentation techniques.

</p>
</details>

<details><summary><b>What Makes Sound Event Localization and Detection Difficult? Insights from Error Analysis</b>
<a href="https://arxiv.org/abs/2107.10469">arxiv:2107.10469</a>
&#x1F4C8; 3 <br>
<p>Thi Ngoc Tho Nguyen, Karn N. Watcharasupat, Zhen Jian Lee, Ngoc Khanh Nguyen, Douglas L. Jones, Woon Seng Gan</p></summary>
<p>

**Abstract:** Sound event localization and detection (SELD) is an emerging research topic that aims to unify the tasks of sound event detection and direction-of-arrival estimation. As a result, SELD inherits the challenges of both tasks, such as noise, reverberation, interference, polyphony, and non-stationarity of sound sources. Furthermore, SELD often faces an additional challenge of assigning correct correspondences between the detected sound classes and directions of arrival to multiple overlapping sound events. Previous studies have shown that unknown interferences in reverberant environments often cause major degradation in the performance of SELD systems. To further understand the challenges of the SELD task, we performed a detailed error analysis on two of our SELD systems, which both ranked second in the team category of DCASE SELD Challenge, one in 2020 and one in 2021. Experimental results indicate polyphony as the main challenge in SELD, due to the difficulty in detecting all sound events of interest. In addition, the SELD systems tend to make fewer errors for the polyphonic scenario that is dominant in the training set.

</p>
</details>

<details><summary><b>Toward AI Assistants That Let Designers Design</b>
<a href="https://arxiv.org/abs/2107.13074">arxiv:2107.13074</a>
&#x1F4C8; 2 <br>
<p>Sebastiaan De Peuter, Antti Oulasvirta, Samuel Kaski</p></summary>
<p>

**Abstract:** AI for supporting designers needs to be rethought. It should aim to cooperate, not automate, by supporting and leveraging the creativity and problem-solving of designers. The challenge for such AI is how to infer designers' goals and then help them without being needlessly disruptive. We present AI-assisted design: a framework for creating such AI, built around generative user models which enable reasoning about designers' goals, reasoning, and capabilities.

</p>
</details>

<details><summary><b>Generating Large-scale Dynamic Optimization Problem Instances Using the Generalized Moving Peaks Benchmark</b>
<a href="https://arxiv.org/abs/2107.11019">arxiv:2107.11019</a>
&#x1F4C8; 2 <br>
<p>Mohammad Nabi Omidvar, Danial Yazdani, Juergen Branke, Xiaodong Li, Shengxiang Yang, Xin Yao</p></summary>
<p>

**Abstract:** This document describes the generalized moving peaks benchmark (GMPB) and how it can be used to generate problem instances for continuous large-scale dynamic optimization problems. It presents a set of 15 benchmark problems, the relevant source code, and a performance indicator, designed for comparative studies and competitions in large-scale dynamic optimization. Although its primary purpose is to provide a coherent basis for running competitions, its generality allows the interested reader to use this document as a guide to design customized problem instances to investigate issues beyond the scope of the presented benchmark suite. To this end, we explain the modular structure of the GMPB and how its constituents can be assembled to form problem instances with a variety of controllable characteristics ranging from unimodal to highly multimodal, symmetric to highly asymmetric, smooth to highly irregular, and various degrees of variable interaction and ill-conditioning.

</p>
</details>

<details><summary><b>3D Brain Reconstruction by Hierarchical Shape-Perception Network from a Single Incomplete Image</b>
<a href="https://arxiv.org/abs/2107.11010">arxiv:2107.11010</a>
&#x1F4C8; 2 <br>
<p>Bowen Hu, Baiying Lei, Shuqiang Wang, Yong Liu, Bingchuan Wang, Min Gan, Yanyan Shen</p></summary>
<p>

**Abstract:** 3D shape reconstruction is essential in the navigation of minimally-invasive and auto robot-guided surgeries whose operating environments are indirect and narrow, and there have been some works that focused on reconstructing the 3D shape of the surgical organ through limited 2D information available. However, the lack and incompleteness of such information caused by intraoperative emergencies (such as bleeding) and risk control conditions have not been considered. In this paper, a novel hierarchical shape-perception network (HSPN) is proposed to reconstruct the 3D point clouds (PCs) of specific brains from one single incomplete image with low latency. A branching predictor and several hierarchical attention pipelines are constructed to generate point clouds that accurately describe the incomplete images and then complete these point clouds with high quality. Meanwhile, attention gate blocks (AGBs) are designed to efficiently aggregate geometric local features of incomplete PCs transmitted by hierarchical attention pipelines and internal features of reconstructing point clouds. With the proposed HSPN, 3D shape perception and completion can be achieved spontaneously. Comprehensive results measured by Chamfer distance and PC-to-PC error demonstrate that the performance of the proposed HSPN outperforms other competitive methods in terms of qualitative displays, quantitative experiment, and classification evaluation.

</p>
</details>

<details><summary><b>SuperCaustics: Real-time, open-source simulation of transparent objects for deep learning applications</b>
<a href="https://arxiv.org/abs/2107.11008">arxiv:2107.11008</a>
&#x1F4C8; 2 <br>
<p>Mehdi Mousavi, Rolando Estrada</p></summary>
<p>

**Abstract:** Transparent objects are a very challenging problem in computer vision. They are hard to segment or classify due to their lack of precise boundaries, and there is limited data available for training deep neural networks. As such, current solutions for this problem employ rigid synthetic datasets, which lack flexibility and lead to severe performance degradation when deployed on real-world scenarios. In particular, these synthetic datasets omit features such as refraction, dispersion and caustics due to limitations in the rendering pipeline. To address this issue, we present SuperCaustics, a real-time, open-source simulation of transparent objects designed for deep learning applications. SuperCaustics features extensive modules for stochastic environment creation; uses hardware ray-tracing to support caustics, dispersion, and refraction; and enables generating massive datasets with multi-modal, pixel-perfect ground truth annotations. To validate our proposed system, we trained a deep neural network from scratch to segment transparent objects in difficult lighting scenarios. Our neural network achieved performance comparable to the state-of-the-art on a real-world dataset using only 10% of the training data and in a fraction of the training time. Further experiments show that a model trained with SuperCaustics can segment different types of caustics, even in images with multiple overlapping transparent objects. To the best of our knowledge, this is the first such result for a model trained on synthetic data. Both our open-source code and experimental data are freely available online.

</p>
</details>

<details><summary><b>Learning Quadruped Locomotion Policies with Reward Machines</b>
<a href="https://arxiv.org/abs/2107.10969">arxiv:2107.10969</a>
&#x1F4C8; 2 <br>
<p>David DeFazio, Shiqi Zhang</p></summary>
<p>

**Abstract:** Legged robots have been shown to be effective in navigating unstructured environments. Although there has been much success in learning locomotion policies for quadruped robots, there is little research on how to incorporate human knowledge to facilitate this learning process. In this paper, we demonstrate that human knowledge in the form of LTL formulas can be applied to quadruped locomotion learning within a Reward Machine (RM) framework. Experimental results in simulation show that our RM-based approach enables easily defining diverse locomotion styles, and efficiently learning locomotion policies of the defined styles.

</p>
</details>

<details><summary><b>Linear Polytree Structural Equation Models: Structural Learning and Inverse Correlation Estimation</b>
<a href="https://arxiv.org/abs/2107.10955">arxiv:2107.10955</a>
&#x1F4C8; 2 <br>
<p>Xingmei Lou, Yu Hu, Xiaodong Li</p></summary>
<p>

**Abstract:** We are interested in the problem of learning the directed acyclic graph (DAG) when data are generated from a linear structural equation model (SEM) and the causal structure can be characterized by a polytree. Specially, under both Gaussian and sub-Gaussian models, we study the sample size conditions for the well-known Chow-Liu algorithm to exactly recover the equivalence class of the polytree, which is uniquely represented by a CPDAG. We also study the error rate for the estimation of the inverse correlation matrix under such models. Our theoretical findings are illustrated by comprehensive numerical simulations, and experiments on benchmark data also demonstrate the robustness of the method when the ground truth graphical structure can only be approximated by a polytree.

</p>
</details>

<details><summary><b>Explainable artificial intelligence (XAI) in deep learning-based medical image analysis</b>
<a href="https://arxiv.org/abs/2107.10912">arxiv:2107.10912</a>
&#x1F4C8; 2 <br>
<p>Bas H. M. van der Velden, Hugo J. Kuijf, Kenneth G. A. Gilhuijs, Max A. Viergever</p></summary>
<p>

**Abstract:** With an increase in deep learning-based methods, the call for explainability of such methods grows, especially in high-stakes decision making areas such as medical image analysis. This survey presents an overview of eXplainable Artificial Intelligence (XAI) used in deep learning-based medical image analysis. A framework of XAI criteria is introduced to classify deep learning-based medical image analysis methods. Papers on XAI techniques in medical image analysis are then surveyed and categorized according to the framework and according to anatomical location. The paper concludes with an outlook of future opportunities for XAI in medical image analysis.

</p>
</details>

<details><summary><b>A reinforcement learning approach to resource allocation in genomic selection</b>
<a href="https://arxiv.org/abs/2107.10901">arxiv:2107.10901</a>
&#x1F4C8; 2 <br>
<p>Saba Moeinizade, Guiping Hu, Lizhi Wang</p></summary>
<p>

**Abstract:** Genomic selection (GS) is a technique that plant breeders use to select individuals to mate and produce new generations of species. Allocation of resources is a key factor in GS. At each selection cycle, breeders are facing the choice of budget allocation to make crosses and produce the next generation of breeding parents. Inspired by recent advances in reinforcement learning for AI problems, we develop a reinforcement learning-based algorithm to automatically learn to allocate limited resources across different generations of breeding. We mathematically formulate the problem in the framework of Markov Decision Process (MDP) by defining state and action spaces. To avoid the explosion of the state space, an integer linear program is proposed that quantifies the trade-off between resources and time. Finally, we propose a value function approximation method to estimate the action-value function and then develop a greedy policy improvement technique to find the optimal resources. We demonstrate the effectiveness of the proposed method in enhancing genetic gain using a case study with realistic data.

</p>
</details>

<details><summary><b>DeltaCharger: Charging Robot with Inverted Delta Mechanism and CNN-driven High Fidelity Tactile Perception for Precise 3D Positioning</b>
<a href="https://arxiv.org/abs/2107.10710">arxiv:2107.10710</a>
&#x1F4C8; 2 <br>
<p>Iaroslav Okunevich, Daria Trinitatova, Pavel Kopanev, Dzmitry Tsetserukou</p></summary>
<p>

**Abstract:** DeltaCharger is a novel charging robot with an Inverted Delta structure for 3D positioning of electrodes to achieve robust and safe transferring energy between two mobile robots. The embedded high-fidelity tactile sensors allow to estimate the angular, vertical and horizontal misalignments between electrodes on the charger mechanism and electrodes on the target robot using pressure data on the contact surfaces. This is crucial for preventing a short circuit. In this paper, the mechanism of the developed prototype and evaluation study of different machine learning models for misalignment prediction are presented. The experimental results showed that the proposed system can measure the angle, vertical and horizontal values of misalignment from pressure data with an accuracy of 95.46%, 98.2%, and 86.9%, respectively, using a Convolutional Neural Network (CNN). DeltaCharger can potentially bring a new level of charging systems and improve the prevalence of mobile autonomous robots.

</p>
</details>

<details><summary><b>A Framework for Imbalanced Time-series Forecasting</b>
<a href="https://arxiv.org/abs/2107.10709">arxiv:2107.10709</a>
&#x1F4C8; 2 <br>
<p>Luis P. Silvestrin, Leonardos Pantiskas, Mark Hoogendoorn</p></summary>
<p>

**Abstract:** Time-series forecasting plays an important role in many domains. Boosted by the advances in Deep Learning algorithms, it has for instance been used to predict wind power for eolic energy production, stock market fluctuations, or motor overheating. In some of these tasks, we are interested in predicting accurately some particular moments which often are underrepresented in the dataset, resulting in a problem known as imbalanced regression. In the literature, while recognized as a challenging problem, limited attention has been devoted on how to handle the problem in a practical setting. In this paper, we put forward a general approach to analyze time-series forecasting problems focusing on those underrepresented moments to reduce imbalances. Our approach has been developed based on a case study in a large industrial company, which we use to exemplify the approach.

</p>
</details>

<details><summary><b>Dialogue Object Search</b>
<a href="https://arxiv.org/abs/2107.10653">arxiv:2107.10653</a>
&#x1F4C8; 2 <br>
<p>Monica Roy, Kaiyu Zheng, Jason Liu, Stefanie Tellex</p></summary>
<p>

**Abstract:** We envision robots that can collaborate and communicate seamlessly with humans. It is necessary for such robots to decide both what to say and how to act, while interacting with humans. To this end, we introduce a new task, dialogue object search: A robot is tasked to search for a target object (e.g. fork) in a human environment (e.g., kitchen), while engaging in a "video call" with a remote human who has additional but inexact knowledge about the target's location. That is, the robot conducts speech-based dialogue with the human, while sharing the image from its mounted camera. This task is challenging at multiple levels, from data collection, algorithm and system development,to evaluation. Despite these challenges, we believe such a task blocks the path towards more intelligent and collaborative robots. In this extended abstract, we motivate and introduce the dialogue object search task and analyze examples collected from a pilot study. We then discuss our next steps and conclude with several challenges on which we hope to receive feedback.

</p>
</details>

<details><summary><b>Hash-Based Tree Similarity and Simplification in Genetic Programming for Symbolic Regression</b>
<a href="https://arxiv.org/abs/2107.10640">arxiv:2107.10640</a>
&#x1F4C8; 2 <br>
<p>Bogdan Burlacu, Lukas Kammerer, Michael Affenzeller, Gabriel Kronberger</p></summary>
<p>

**Abstract:** We introduce in this paper a runtime-efficient tree hashing algorithm for the identification of isomorphic subtrees, with two important applications in genetic programming for symbolic regression: fast, online calculation of population diversity and algebraic simplification of symbolic expression trees. Based on this hashing approach, we propose a simple diversity-preservation mechanism with promising results on a collection of symbolic regression benchmark problems.

</p>
</details>

<details><summary><b>An overcome of far-distance limitation on tunnel CCTV-based accident detection in AI deep-learning frameworks</b>
<a href="https://arxiv.org/abs/2107.10567">arxiv:2107.10567</a>
&#x1F4C8; 2 <br>
<p>Kyu-Beom Lee, Hyu-Soung Shin</p></summary>
<p>

**Abstract:** Tunnel CCTVs are installed to low height and long-distance interval. However, because of the limitation of installation height, severe perspective effect in distance occurs, and it is almost impossible to detect vehicles in far distance from the CCTV in the existing tunnel CCTV-based accident detection system (Pflugfelder 2005). To overcome the limitation, a vehicle object is detected through an object detection algorithm based on an inverse perspective transform by re-setting the region of interest (ROI). It can detect vehicles that are far away from the CCTV. To verify this process, this paper creates each dataset consisting of images and bounding boxes based on the original and warped images of the CCTV at the same time, and then compares performance of the deep learning object detection models trained with the two datasets. As a result, the model that trained the warped image was able to detect vehicle objects more accurately at the position far from the CCTV compared to the model that trained the original image.

</p>
</details>

<details><summary><b>External-Memory Networks for Low-Shot Learning of Targets in Forward-Looking-Sonar Imagery</b>
<a href="https://arxiv.org/abs/2107.10504">arxiv:2107.10504</a>
&#x1F4C8; 2 <br>
<p>Isaac J. Sledge, Christopher D. Toole, Joseph A. Maestri, Jose C. Principe</p></summary>
<p>

**Abstract:** We propose a memory-based framework for real-time, data-efficient target analysis in forward-looking-sonar (FLS) imagery. Our framework relies on first removing non-discriminative details from the imagery using a small-scale DenseNet-inspired network. Doing so simplifies ensuing analyses and permits generalizing from few labeled examples. We then cascade the filtered imagery into a novel NeuralRAM-based convolutional matching network, NRMN, for low-shot target recognition. We employ a small-scale FlowNet, LFN to align and register FLS imagery across local temporal scales. LFN enables target label consensus voting across images and generally improves target detection and recognition rates.
  We evaluate our framework using real-world FLS imagery with multiple broad target classes that have high intra-class variability and rich sub-class structure. We show that few-shot learning, with anywhere from ten to thirty class-specific exemplars, performs similarly to supervised deep networks trained on hundreds of samples per class. Effective zero-shot learning is also possible. High performance is realized from the inductive-transfer properties of NRMNs when distractor elements are removed.

</p>
</details>

<details><summary><b>Neural Ordinary Differential Equation Model for Evolutionary Subspace Clustering and Its Applications</b>
<a href="https://arxiv.org/abs/2107.10484">arxiv:2107.10484</a>
&#x1F4C8; 2 <br>
<p>Mingyuan Bai, S. T. Boris Choy, Junping Zhang, Junbin Gao</p></summary>
<p>

**Abstract:** The neural ordinary differential equation (neural ODE) model has attracted increasing attention in time series analysis for its capability to process irregular time steps, i.e., data are not observed over equally-spaced time intervals. In multi-dimensional time series analysis, a task is to conduct evolutionary subspace clustering, aiming at clustering temporal data according to their evolving low-dimensional subspace structures. Many existing methods can only process time series with regular time steps while time series are unevenly sampled in many situations such as missing data. In this paper, we propose a neural ODE model for evolutionary subspace clustering to overcome this limitation and a new objective function with subspace self-expressiveness constraint is introduced. We demonstrate that this method can not only interpolate data at any time step for the evolutionary subspace clustering task, but also achieve higher accuracy than other state-of-the-art evolutionary subspace clustering methods. Both synthetic and real-world data are used to illustrate the efficacy of our proposed method.

</p>
</details>

<details><summary><b>Back-Translated Task Adaptive Pretraining: Improving Accuracy and Robustness on Text Classification</b>
<a href="https://arxiv.org/abs/2107.10474">arxiv:2107.10474</a>
&#x1F4C8; 2 <br>
<p>Junghoon Lee, Jounghee Kim, Pilsung Kang</p></summary>
<p>

**Abstract:** Language models (LMs) pretrained on a large text corpus and fine-tuned on a downstream text corpus and fine-tuned on a downstream task becomes a de facto training strategy for several natural language processing (NLP) tasks. Recently, an adaptive pretraining method retraining the pretrained language model with task-relevant data has shown significant performance improvements. However, current adaptive pretraining methods suffer from underfitting on the task distribution owing to a relatively small amount of data to re-pretrain the LM. To completely use the concept of adaptive pretraining, we propose a back-translated task-adaptive pretraining (BT-TAPT) method that increases the amount of task-specific data for LM re-pretraining by augmenting the task data using back-translation to generalize the LM to the target task domain. The experimental results show that the proposed BT-TAPT yields improved classification accuracy on both low- and high-resource data and better robustness to noise than the conventional adaptive pretraining method.

</p>
</details>

<details><summary><b>Membership Inference Attack and Defense for Wireless Signal Classifiers with Deep Learning</b>
<a href="https://arxiv.org/abs/2107.12173">arxiv:2107.12173</a>
&#x1F4C8; 1 <br>
<p>Yi Shi, Yalin E. Sagduyu</p></summary>
<p>

**Abstract:** An over-the-air membership inference attack (MIA) is presented to leak private information from a wireless signal classifier. Machine learning (ML) provides powerful means to classify wireless signals, e.g., for PHY-layer authentication. As an adversarial machine learning attack, the MIA infers whether a signal of interest has been used in the training data of a target classifier. This private information incorporates waveform, channel, and device characteristics, and if leaked, can be exploited by an adversary to identify vulnerabilities of the underlying ML model (e.g., to infiltrate the PHY-layer authentication). One challenge for the over-the-air MIA is that the received signals and consequently the RF fingerprints at the adversary and the intended receiver differ due to the discrepancy in channel conditions. Therefore, the adversary first builds a surrogate classifier by observing the spectrum and then launches the black-box MIA on this classifier. The MIA results show that the adversary can reliably infer signals (and potentially the radio and channel information) used to build the target classifier. Therefore, a proactive defense is developed against the MIA by building a shadow MIA model and fooling the adversary. This defense can successfully reduce the MIA accuracy and prevent information leakage from the wireless signal classifier.

</p>
</details>

<details><summary><b>VisMCA: A Visual Analytics System for Misclassification Correction and Analysis. VAST Challenge 2020, Mini-Challenge 2 Award: Honorable Mention for Detailed Analysis of Patterns of Misclassification</b>
<a href="https://arxiv.org/abs/2107.11181">arxiv:2107.11181</a>
&#x1F4C8; 1 <br>
<p>Huyen N. Nguyen, Jake Gonzalez, Jian Guo, Ngan V. T. Nguyen, Tommy Dang</p></summary>
<p>

**Abstract:** This paper presents VisMCA, an interactive visual analytics system that supports deepening understanding in ML results, augmenting users' capabilities in correcting misclassification, and providing an analysis of underlying patterns, in response to the VAST Challenge 2020 Mini-Challenge 2. VisMCA facilitates tracking provenance and provides a comprehensive view of object detection results, easing re-labeling, and producing reliable, corrected data for future training. Our solution implements multiple analytical views on visual analysis to offer a deep insight for underlying pattern discovery.

</p>
</details>

<details><summary><b>Distributed Saddle-Point Problems Under Similarity</b>
<a href="https://arxiv.org/abs/2107.10706">arxiv:2107.10706</a>
&#x1F4C8; 1 <br>
<p>Aleksandr Beznosikov, Gesualdo Scutari, Alexander Rogozin, Alexander Gasnikov</p></summary>
<p>

**Abstract:** We study solution methods for (strongly-)convex-(strongly)-concave Saddle-Point Problems (SPPs) over networks of two type - master/workers (thus centralized) architectures and meshed (thus decentralized) networks. The local functions at each node are assumed to be similar, due to statistical data similarity or otherwise. We establish lower complexity bounds for a fairly general class of algorithms solving the SPP. We show that a given suboptimality $ε>0$ is achieved over master/workers networks in $Ω\big(Δ\cdot δ/μ\cdot \log (1/\varepsilon)\big)$ rounds of communications, where $δ>0$ measures the degree of similarity of the local functions, $μ$ is their strong convexity constant, and $Δ$ is the diameter of the network. The lower communication complexity bound over meshed networks reads $Ω\big(1/{\sqrtρ} \cdot δ/μ\cdot\log (1/\varepsilon)\big)$, where $ρ$ is the (normalized) eigengap of the gossip matrix used for the communication between neighbouring nodes. We then propose algorithms matching the lower bounds over either types of networks (up to log-factors). We assess the effectiveness of the proposed algorithms on a robust logistic regression problem.

</p>
</details>

<details><summary><b>CNN-based Realized Covariance Matrix Forecasting</b>
<a href="https://arxiv.org/abs/2107.10602">arxiv:2107.10602</a>
&#x1F4C8; 1 <br>
<p>Yanwen Fang, Philip L. H. Yu, Yaohua Tang</p></summary>
<p>

**Abstract:** It is well known that modeling and forecasting realized covariance matrices of asset returns play a crucial role in the field of finance. The availability of high frequency intraday data enables the modeling of the realized covariance matrices directly. However, most of the models available in the literature depend on strong structural assumptions and they often suffer from the curse of dimensionality. We propose an end-to-end trainable model built on the CNN and Convolutional LSTM (ConvLSTM) which does not require to make any distributional or structural assumption but could handle high-dimensional realized covariance matrices consistently. The proposed model focuses on local structures and spatiotemporal correlations. It learns a nonlinear mapping that connect the historical realized covariance matrices to the future one. Our empirical studies on synthetic and real-world datasets demonstrate its excellent forecasting ability compared with several advanced volatility models.

</p>
</details>

<details><summary><b>Fristograms: Revealing and Exploiting Light Field Internals</b>
<a href="https://arxiv.org/abs/2107.10563">arxiv:2107.10563</a>
&#x1F4C8; 1 <br>
<p>Thorsten Herfet, Kelvin Chelli, Tobias Lange, Robin Kremer</p></summary>
<p>

**Abstract:** In recent years, light field (LF) capture and processing has become an integral part of media production. The richness of information available in LFs has enabled novel applications like post-capture depth-of-field editing, 3D reconstruction, segmentation and matting, saliency detection, object detection and recognition, and mixed reality. The efficacy of such applications depends on certain underlying requirements, which are often ignored. For example, some operations such as noise-reduction, or hyperfan-filtering are only possible if a scene point Lambertian radiator. Some other operations such as the removal of obstacles or looking behind objects are only possible if there is at least one ray capturing the required scene point. Consequently, the ray distribution representing a certain scene point is an important characteristic for evaluating processing possibilities. The primary idea in this paper is to establish a relation between the capturing setup and the rays of the LF. To this end, we discretize the view frustum. Traditionally, a uniform discretization of the view frustum results in voxels that represents a single sample on a regularly spaced, 3-D grid. Instead, we use frustum-shaped voxels (froxels), by using depth and capturing-setup dependent discretization of the view frustum. Based on such discretization, we count the number of rays mapping to the same pixel on the capturing device(s). By means of this count, we propose histograms of ray-counts over the froxels (fristograms). Fristograms can be used as a tool to analyze and reveal interesting aspects of the underlying LF, like the number of rays originating from a scene point and the color distribution of these rays. As an example, we show its ability by significantly reducing the number of rays which enables noise reduction while maintaining the realistic rendering of non-Lambertian or partially occluded regions.

</p>
</details>

<details><summary><b>Out of the Shadows: Analyzing Anonymous' Twitter Resurgence during the 2020 Black Lives Matter Protests</b>
<a href="https://arxiv.org/abs/2107.10554">arxiv:2107.10554</a>
&#x1F4C8; 1 <br>
<p>Keenan Jones, Jason R. C. Nurse, Shujun Li</p></summary>
<p>

**Abstract:** Recently, there had been little notable activity from the once prominent hacktivist group, Anonymous. The group, responsible for activist-based cyber attacks on major businesses and governments, appeared to have fragmented after key members were arrested in 2013. In response to the major Black Lives Matter (BLM) protests that occurred after the killing of George Floyd, however, reports indicated that the group was back. To examine this apparent resurgence, we conduct a large-scale study of Anonymous affiliates on Twitter. To this end, we first use machine learning to identify a significant network of more than 33,000 Anonymous accounts. Through topic modelling of tweets collected from these accounts, we find evidence of sustained interest in topics related to BLM. We then use sentiment analysis on tweets focused on these topics, finding evidence of a united approach amongst the group, with positive tweets typically being used to express support towards BLM, and negative tweets typically being used to criticize police actions. Finally, we examine the presence of automation in the network, identifying indications of bot-like behavior across the majority of Anonymous accounts. These findings show that whilst the group has seen a resurgence during the protests, bot activity may be responsible for exaggerating the extent of this resurgence.

</p>
</details>

<details><summary><b>Multiple Query Optimization using a Hybrid Approach of Classical and Quantum Computing</b>
<a href="https://arxiv.org/abs/2107.10508">arxiv:2107.10508</a>
&#x1F4C8; 1 <br>
<p>Tobias Fankhauser, Marc E. Solèr, Rudolf M. Füchslin, Kurt Stockinger</p></summary>
<p>

**Abstract:** Quantum computing promises to solve difficult optimization problems in chemistry, physics and mathematics more efficiently than classical computers, but requires fault-tolerant quantum computers with millions of qubits. To overcome errors introduced by today's quantum computers, hybrid algorithms combining classical and quantum computers are used. In this paper we tackle the multiple query optimization problem (MQO) which is an important NP-hard problem in the area of data-intensive problems. We propose a novel hybrid classical-quantum algorithm to solve the MQO on a gate-based quantum computer. We perform a detailed experimental evaluation of our algorithm and compare its performance against a competing approach that employs a quantum annealer -- another type of quantum computer. Our experimental results demonstrate that our algorithm currently can only handle small problem sizes due to the limited number of qubits available on a gate-based quantum computer compared to a quantum computer based on quantum annealing. However, our algorithm shows a qubit efficiency of close to 99% which is almost a factor of 2 higher compared to the state of the art implementation. Finally, we analyze how our algorithm scales with larger problem sizes and conclude that our approach shows promising results for near-term quantum computers.

</p>
</details>

<details><summary><b>A Deep Learning-based Quality Assessment and Segmentation System with a Large-scale Benchmark Dataset for Optical Coherence Tomographic Angiography Image</b>
<a href="https://arxiv.org/abs/2107.10476">arxiv:2107.10476</a>
&#x1F4C8; 1 <br>
<p>Yufei Wang, Yiqing Shen, Meng Yuan, Jing Xu, Bin Yang, Chi Liu, Wenjia Cai, Weijing Cheng, Wei Wang</p></summary>
<p>

**Abstract:** Optical Coherence Tomography Angiography (OCTA) is a non-invasive and non-contacting imaging technique providing visualization of microvasculature of retina and optic nerve head in human eyes in vivo. The adequate image quality of OCTA is the prerequisite for the subsequent quantification of retinal microvasculature. Traditionally, the image quality score based on signal strength is used for discriminating low quality. However, it is insufficient for identifying artefacts such as motion and off-centration, which rely specialized knowledge and need tedious and time-consuming manual identification. One of the most primary issues in OCTA analysis is to sort out the foveal avascular zone (FAZ) region in the retina, which highly correlates with any visual acuity disease. However, the variations in OCTA visual quality affect the performance of deep learning in any downstream marginally. Moreover, filtering the low-quality OCTA images out is both labor-intensive and time-consuming. To address these issues, we develop an automated computer-aided OCTA image processing system using deep neural networks as the classifier and segmentor to help ophthalmologists in clinical diagnosis and research. This system can be an assistive tool as it can process OCTA images of different formats to assess the quality and segment the FAZ area. The source code is freely available at https://github.com/shanzha09/COIPS.git.
  Another major contribution is the large-scale OCTA dataset, namely OCTA-25K-IQA-SEG we publicize for performance evaluation. It is comprised of four subsets, namely sOCTA-3$\times$3-10k, sOCTA-6$\times$6-14k, sOCTA-3$\times$3-1.1k-seg, and dOCTA-6$\times$6-1.1k-seg, which contains a total number of 25,665 images. The large-scale OCTA dataset is available at https://doi.org/10.5281/zenodo.5111975, https://doi.org/10.5281/zenodo.5111972.

</p>
</details>

<details><summary><b>A new step for computing</b>
<a href="https://arxiv.org/abs/2108.03997">arxiv:2108.03997</a>
&#x1F4C8; 0 <br>
<p>Xavier Vasques</p></summary>
<p>

**Abstract:** The data center of tomorrow is a data center made up of heterogeneous systems, which will run heterogeneous workloads. The systems will be located as close as possible to the data. Heterogeneous systems will be equipped with binary, biological inspired and quantum accelerators. These architectures will be the foundations to address challenges.  Like an orchestra conductor, the hybrid cloud will make it possible to set these systems to music thanks to a layer of security and intelligent automation.

</p>
</details>

<details><summary><b>Dynamic Proximal Unrolling Network for Compressive Imaging</b>
<a href="https://arxiv.org/abs/2107.11007">arxiv:2107.11007</a>
&#x1F4C8; 0 <br>
<p>Yixiao Yang, Ran Tao, Kaixuan Wei, Ying Fu</p></summary>
<p>

**Abstract:** Compressive imaging aims to recover a latent image from under-sampled measurements, suffering from a serious ill-posed inverse problem. Recently, deep neural networks have been applied to this problem with superior results, owing to the learned advanced image priors. These approaches, however, require training separate models for different imaging modalities and sampling ratios, leading to overfitting to specific settings. In this paper, a dynamic proximal unrolling network (dubbed DPUNet) was proposed, which can handle a variety of measurement matrices via one single model without retraining. Specifically, DPUNet can exploit both the embedded observation model via gradient descent and imposed image priors by learned dynamic proximal operators, achieving joint reconstruction. A key component of DPUNet is a dynamic proximal mapping module, whose parameters can be dynamically adjusted at the inference stage and make it adapt to different imaging settings. Experimental results demonstrate that the proposed DPUNet can effectively handle multiple compressive imaging modalities under varying sampling ratios and noise levels via only one trained model, and outperform the state-of-the-art approaches.

</p>
</details>

<details><summary><b>The decomposition of the higher-order homology embedding constructed from the $k$-Laplacian</b>
<a href="https://arxiv.org/abs/2107.10970">arxiv:2107.10970</a>
&#x1F4C8; 0 <br>
<p>Yu-Chia Chen, Marina Meilă</p></summary>
<p>

**Abstract:** The null space of the $k$-th order Laplacian $\mathbf{\mathcal L}_k$, known as the {\em $k$-th homology vector space}, encodes the non-trivial topology of a manifold or a network. Understanding the structure of the homology embedding can thus disclose geometric or topological information from the data. The study of the null space embedding of the graph Laplacian $\mathbf{\mathcal L}_0$ has spurred new research and applications, such as spectral clustering algorithms with theoretical guarantees and estimators of the Stochastic Block Model. In this work, we investigate the geometry of the $k$-th homology embedding and focus on cases reminiscent of spectral clustering. Namely, we analyze the {\em connected sum} of manifolds as a perturbation to the direct sum of their homology embeddings. We propose an algorithm to factorize the homology embedding into subspaces corresponding to a manifold's simplest topological components. The proposed framework is applied to the {\em shortest homologous loop detection} problem, a problem known to be NP-hard in general. Our spectral loop detection algorithm scales better than existing methods and is effective on diverse data such as point clouds and images.

</p>
</details>

<details><summary><b>HARP-Net: Hyper-Autoencoded Reconstruction Propagation for Scalable Neural Audio Coding</b>
<a href="https://arxiv.org/abs/2107.10843">arxiv:2107.10843</a>
&#x1F4C8; 0 <br>
<p>Darius Petermann, Seungkwon Beack, Minje Kim</p></summary>
<p>

**Abstract:** An autoencoder-based codec employs quantization to turn its bottleneck layer activation into bitstrings, a process that hinders information flow between the encoder and decoder parts. To circumvent this issue, we employ additional skip connections between the corresponding pair of encoder-decoder layers. The assumption is that, in a mirrored autoencoder topology, a decoder layer reconstructs the intermediate feature representation of its corresponding encoder layer. Hence, any additional information directly propagated from the corresponding encoder layer helps the reconstruction. We implement this kind of skip connections in the form of additional autoencoders, each of which is a small codec that compresses the massive data transfer between the paired encoder-decoder layers. We empirically verify that the proposed hyper-autoencoded architecture improves perceptual audio quality compared to an ordinary autoencoder baseline.

</p>
</details>

<details><summary><b>Self-transfer learning via patches: A prostate cancer triage approach based on bi-parametric MRI</b>
<a href="https://arxiv.org/abs/2107.10806">arxiv:2107.10806</a>
&#x1F4C8; 0 <br>
<p>Alvaro Fernandez-Quilez, Trygve Eftestøl, Morten Goodwin, Svein Reidar Kjosavik, Ketil Oppedal</p></summary>
<p>

**Abstract:** Prostate cancer (PCa) is the second most common cancer diagnosed among men worldwide. The current PCa diagnostic pathway comes at the cost of substantial overdiagnosis, leading to unnecessary treatment and further testing. Bi-parametric magnetic resonance imaging (bp-MRI) based on apparent diffusion coefficient maps (ADC) and T2-weighted (T2w) sequences has been proposed as a triage test to differentiate between clinically significant (cS) and non-clinically significant (ncS) prostate lesions. However, analysis of the sequences relies on expertise, requires specialized training, and suffers from inter-observer variability. Deep learning (DL) techniques hold promise in tasks such as classification and detection. Nevertheless, they rely on large amounts of annotated data which is not common in the medical field. In order to palliate such issues, existing works rely on transfer learning (TL) and ImageNet pre-training, which has been proven to be sub-optimal for the medical imaging domain. In this paper, we present a patch-based pre-training strategy to distinguish between cS and ncS lesions which exploit the region of interest (ROI) of the patched source domain to efficiently train a classifier in the full-slice target domain which does not require annotations by making use of transfer learning (TL). We provide a comprehensive comparison between several CNNs architectures and different settings which are presented as a baseline. Moreover, we explore cross-domain TL which exploits both MRI modalities and improves single modality results. Finally, we show how our approaches outperform the standard approaches by a considerable margin

</p>
</details>

<details><summary><b>Semantic Text-to-Face GAN -ST^2FG</b>
<a href="https://arxiv.org/abs/2107.10756">arxiv:2107.10756</a>
&#x1F4C8; 0 <br>
<p>Manan Oza, Sukalpa Chanda, David Doermann</p></summary>
<p>

**Abstract:** Faces generated using generative adversarial networks (GANs) have reached unprecedented realism. These faces, also known as "Deep Fakes", appear as realistic photographs with very little pixel-level distortions. While some work has enabled the training of models that lead to the generation of specific properties of the subject, generating a facial image based on a natural language description has not been fully explored. For security and criminal identification, the ability to provide a GAN-based system that works like a sketch artist would be incredibly useful. In this paper, we present a novel approach to generate facial images from semantic text descriptions. The learned model is provided with a text description and an outline of the type of face, which the model uses to sketch the features. Our models are trained using an Affine Combination Module (ACM) mechanism to combine the text embedding from BERT and the GAN latent space using a self-attention matrix. This avoids the loss of features due to inadequate "attention", which may happen if text embedding and latent vector are simply concatenated. Our approach is capable of generating images that are very accurately aligned to the exhaustive textual descriptions of faces with many fine detail features of the face and helps in generating better images. The proposed method is also capable of making incremental changes to a previously generated image if it is provided with additional textual descriptions or sentences.

</p>
</details>

<details><summary><b>Physics-informed neural networks for solving Reynolds-averaged Navier$\unicode{x2013}$Stokes equations</b>
<a href="https://arxiv.org/abs/2107.10711">arxiv:2107.10711</a>
&#x1F4C8; 0 <br>
<p>Hamidreza Eivazi, Mojtaba Tahani, Philipp Schlatter, Ricardo Vinuesa</p></summary>
<p>

**Abstract:** Physics-informed neural networks (PINNs) are successful machine-learning methods for the solution and identification of partial differential equations (PDEs). We employ PINNs for solving the Reynolds-averaged Navier$\unicode{x2013}$Stokes (RANS) equations for incompressible turbulent flows without any specific model or assumption for turbulence, and by taking only the data on the domain boundaries. We first show the applicability of PINNs for solving the Navier$\unicode{x2013}$Stokes equations for laminar flows by solving the Falkner$\unicode{x2013}$Skan boundary layer. We then apply PINNs for the simulation of four turbulent-flow cases, i.e., zero-pressure-gradient boundary layer, adverse-pressure-gradient boundary layer, and turbulent flows over a NACA4412 airfoil and the periodic hill. Our results show the excellent applicability of PINNs for laminar flows with strong pressure gradients, where predictions with less than 1% error can be obtained. For turbulent flows, we also obtain very good accuracy on simulation results even for the Reynolds-stress components.

</p>
</details>

<details><summary><b>MobileCharger: an Autonomous Mobile Robot with Inverted Delta Actuator for Robust and Safe Robot Charging</b>
<a href="https://arxiv.org/abs/2107.10585">arxiv:2107.10585</a>
&#x1F4C8; 0 <br>
<p>Iaroslav Okunevich, Daria Trinitatova, Pavel Kopanev, Dzmitry Tsetserukou</p></summary>
<p>

**Abstract:** MobileCharger is a novel mobile charging robot with an Inverted Delta actuator for safe and robust energy transfer between two mobile robots. The RGB-D camera-based computer vision system allows to detect the electrodes on the target mobile robot using a convolutional neural network (CNN). The embedded high-fidelity tactile sensors are applied to estimate the misalignment between the electrodes on the charger mechanism and the electrodes on the main robot using CNN based on pressure data on the contact surfaces. Thus, the developed vision-tactile perception system allows precise positioning of the end effector of the actuator and ensures a reliable connection between the electrodes of the two robots. The experimental results showed high average precision (84.2%) for electrode detection using CNN. The percentage of successful trials of the CNN-based electrode search algorithm reached 83% and the average execution time accounted for 60 s. MobileCharger could introduce a new level of charging systems and increase the prevalence of autonomous mobile robots.

</p>
</details>

<details><summary><b>Improving the Authentication with Built-in Camera Protocol Using Built-in Motion Sensors: A Deep Learning Solution</b>
<a href="https://arxiv.org/abs/2107.10536">arxiv:2107.10536</a>
&#x1F4C8; 0 <br>
<p>Cezara Benegui, Radu Tudor Ionescu</p></summary>
<p>

**Abstract:** We propose an enhanced version of the Authentication with Built-in Camera (ABC) protocol by employing a deep learning solution based on built-in motion sensors. The standard ABC protocol identifies mobile devices based on the photo-response non-uniformity (PRNU) of the camera sensor, while also considering QR-code-based meta-information. During authentication, the user is required to take two photos that contain two QR codes presented on a screen. The presented QR code images also contain a unique probe signal, similar to a camera fingerprint, generated by the protocol. During verification, the server computes the fingerprint of the received photos and authenticates the user if (i) the probe signal is present, (ii) the metadata embedded in the QR codes is correct and (iii) the camera fingerprint is identified correctly. However, the protocol is vulnerable to forgery attacks when the attacker can compute the camera fingerprint from external photos, as shown in our preliminary work. In this context, we propose an enhancement for the ABC protocol based on motion sensor data, as an additional and passive authentication layer. Smartphones can be identified through their motion sensor data, which, unlike photos, is never posted by users on social media platforms, thus being more secure than using photographs alone. To this end, we transform motion signals into embedding vectors produced by deep neural networks, applying Support Vector Machines for the smartphone identification task. Our change to the ABC protocol results in a multi-modal protocol that lowers the false acceptance rate for the attack proposed in our previous work to a percentage as low as 0.07%.

</p>
</details>

<details><summary><b>Copy and Paste method based on Pose for Re-identification</b>
<a href="https://arxiv.org/abs/2107.10479">arxiv:2107.10479</a>
&#x1F4C8; 0 <br>
<p>Cheng Yang</p></summary>
<p>

**Abstract:** The aim of re-identification is to match objects in surveillance cameras with different viewpoints. Although ReID is developing at a considerably rapid pace, there is currently no processing method for the ReID task in multiple scenarios. However, such processing method is required in real life scenarios, such as those involving security. In the present study, a new ReID scenario was explored, which differs in terms of perspective, background, and pose(walking or cycling). Obviously, ordinary ReID processing methods cannot effectively handle such a scenario, with the introduction of image datasets being the optimal solution, in addition to being considerably expensive.
  To solve the aforementioned problem, a simple and effective method to generate images in several new scenarios was proposed, which is names the Copy and Paste method based on Pose(CPP). The CPP method is based on key point detection, using copy as paste, to composite a new semantic image dataset in two different semantic image datasets. As an example, pedestrains and bicycles can be used to generate several images that show the same person riding on different bicycles. The CPP method is suitable for ReID tasks in new scenarios and outperforms the traditional methods when applied to the original datasets in original ReID tasks. To be specific, the CPP method can also perform better in terms of generalization for third-party public dataset. The Code and datasets composited by the CPP method will be available in the future.

</p>
</details>


[Next Page]({{ '/2021/07/21/2021.07.21.html' | relative_url }})
