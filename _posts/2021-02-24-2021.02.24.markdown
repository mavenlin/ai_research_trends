Prev: [2021.02.23]({{ '/2021/02/23/2021.02.23.html' | relative_url }})  Next: [2021.02.25]({{ '/2021/02/25/2021.02.25.html' | relative_url }})
{% raw %}
## Summary for 2021-02-24, created on 2021-12-24


<details><summary><b>Zero-Shot Text-to-Image Generation</b>
<a href="https://arxiv.org/abs/2102.12092">arxiv:2102.12092</a>
&#x1F4C8; 379 <br>
<p>Aditya Ramesh, Mikhail Pavlov, Gabriel Goh, Scott Gray, Chelsea Voss, Alec Radford, Mark Chen, Ilya Sutskever</p></summary>
<p>

**Abstract:** Text-to-image generation has traditionally focused on finding better modeling assumptions for training on a fixed dataset. These assumptions might involve complex architectures, auxiliary losses, or side information such as object part labels or segmentation masks supplied during training. We describe a simple approach for this task based on a transformer that autoregressively models the text and image tokens as a single stream of data. With sufficient data and scale, our approach is competitive with previous domain-specific models when evaluated in a zero-shot fashion.

</p>
</details>

<details><summary><b>When Attention Meets Fast Recurrence: Training Language Models with Reduced Compute</b>
<a href="https://arxiv.org/abs/2102.12459">arxiv:2102.12459</a>
&#x1F4C8; 79 <br>
<p>Tao Lei</p></summary>
<p>

**Abstract:** Large language models have become increasingly difficult to train because of the growing computation time and cost. In this work, we present SRU++, a highly-efficient architecture that combines fast recurrence and attention for sequence modeling. SRU++ exhibits strong modeling capacity and training efficiency. On standard language modeling tasks such as Enwik8, Wiki-103 and Billion Word datasets, our model obtains better bits-per-character and perplexity while using 3x-10x less training cost compared to top-performing Transformer models. For instance, our model achieves a state-of-the-art result on the Enwik8 dataset using 1.6 days of training on an 8-GPU machine. We further demonstrate that SRU++ requires minimal attention for near state-of-the-art performance. Our results suggest jointly leveraging fast recurrence with little attention as a promising direction for accelerating model training and inference.

</p>
</details>

<details><summary><b>Modern Koopman Theory for Dynamical Systems</b>
<a href="https://arxiv.org/abs/2102.12086">arxiv:2102.12086</a>
&#x1F4C8; 45 <br>
<p>Steven L. Brunton, Marko Budišić, Eurika Kaiser, J. Nathan Kutz</p></summary>
<p>

**Abstract:** The field of dynamical systems is being transformed by the mathematical tools and algorithms emerging from modern computing and data science. First-principles derivations and asymptotic reductions are giving way to data-driven approaches that formulate models in operator theoretic or probabilistic frameworks. Koopman spectral theory has emerged as a dominant perspective over the past decade, in which nonlinear dynamics are represented in terms of an infinite-dimensional linear operator acting on the space of all possible measurement functions of the system. This linear representation of nonlinear dynamics has tremendous potential to enable the prediction, estimation, and control of nonlinear systems with standard textbook methods developed for linear systems. However, obtaining finite-dimensional coordinate systems and embeddings in which the dynamics appear approximately linear remains a central open challenge. The success of Koopman analysis is due primarily to three key factors: 1) there exists rigorous theory connecting it to classical geometric approaches for dynamical systems, 2) the approach is formulated in terms of measurements, making it ideal for leveraging big-data and machine learning techniques, and 3) simple, yet powerful numerical algorithms, such as the dynamic mode decomposition (DMD), have been developed and extended to reduce Koopman theory to practice in real-world applications. In this review, we provide an overview of modern Koopman operator theory, describing recent theoretical and algorithmic developments and highlighting these methods with a diverse range of applications. We also discuss key advances and challenges in the rapidly growing field of machine learning that are likely to drive future developments and significantly transform the theoretical landscape of dynamical systems.

</p>
</details>

<details><summary><b>AniGAN: Style-Guided Generative Adversarial Networks for Unsupervised Anime Face Generation</b>
<a href="https://arxiv.org/abs/2102.12593">arxiv:2102.12593</a>
&#x1F4C8; 23 <br>
<p>Bing Li, Yuanlue Zhu, Yitong Wang, Chia-Wen Lin, Bernard Ghanem, Linlin Shen</p></summary>
<p>

**Abstract:** In this paper, we propose a novel framework to translate a portrait photo-face into an anime appearance. Our aim is to synthesize anime-faces which are style-consistent with a given reference anime-face. However, unlike typical translation tasks, such anime-face translation is challenging due to complex variations of appearances among anime-faces. Existing methods often fail to transfer the styles of reference anime-faces, or introduce noticeable artifacts/distortions in the local shapes of their generated faces. We propose AniGAN, a novel GAN-based translator that synthesizes high-quality anime-faces. Specifically, a new generator architecture is proposed to simultaneously transfer color/texture styles and transform local facial shapes into anime-like counterparts based on the style of a reference anime-face, while preserving the global structure of the source photo-face. We propose a double-branch discriminator to learn both domain-specific distributions and domain-shared distributions, helping generate visually pleasing anime-faces and effectively mitigate artifacts. Extensive experiments on selfie2anime and a new face2anime dataset qualitatively and quantitatively demonstrate the superiority of our method over state-of-the-art methods. The new dataset is available at https://github.com/bing-li-ai/AniGAN .

</p>
</details>

<details><summary><b>Classification with abstention but without disparities</b>
<a href="https://arxiv.org/abs/2102.12258">arxiv:2102.12258</a>
&#x1F4C8; 22 <br>
<p>Nicolas Schreuder, Evgenii Chzhen</p></summary>
<p>

**Abstract:** Classification with abstention has gained a lot of attention in recent years as it allows to incorporate human decision-makers in the process. Yet, abstention can potentially amplify disparities and lead to discriminatory predictions. The goal of this work is to build a general purpose classification algorithm, which is able to abstain from prediction, while avoiding disparate impact. We formalize this problem as risk minimization under fairness and abstention constraints for which we derive the form of the optimal classifier. Building on this result, we propose a post-processing classification algorithm, which is able to modify any off-the-shelf score-based classifier using only unlabeled sample. We establish finite sample risk, fairness, and abstention guarantees for the proposed algorithm. In particular, it is shown that fairness and abstention constraints can be achieved independently from the initial classifier as long as sufficiently many unlabeled data is available. The risk guarantee is established in terms of the quality of the initial classifier. Our post-processing scheme reduces to a sparse linear program allowing for an efficient implementation, which we provide. Finally, we validate our method empirically showing that moderate abstention rates allow to bypass the risk-fairness trade-off.

</p>
</details>

<details><summary><b>A Framework for Integrating Gesture Generation Models into Interactive Conversational Agents</b>
<a href="https://arxiv.org/abs/2102.12302">arxiv:2102.12302</a>
&#x1F4C8; 21 <br>
<p>Rajmund Nagy, Taras Kucherenko, Birger Moell, André Pereira, Hedvig Kjellström, Ulysses Bernardet</p></summary>
<p>

**Abstract:** Embodied conversational agents (ECAs) benefit from non-verbal behavior for natural and efficient interaction with users. Gesticulation - hand and arm movements accompanying speech - is an essential part of non-verbal behavior. Gesture generation models have been developed for several decades: starting with rule-based and ending with mainly data-driven methods. To date, recent end-to-end gesture generation methods have not been evaluated in a real-time interaction with users. We present a proof-of-concept framework, which is intended to facilitate evaluation of modern gesture generation models in interaction.
  We demonstrate an extensible open-source framework that contains three components: 1) a 3D interactive agent; 2) a chatbot backend; 3) a gesticulating system. Each component can be replaced, making the proposed framework applicable for investigating the effect of different gesturing models in real-time interactions with different communication modalities, chatbot backends, or different agent appearances. The code and video are available at the project page https://nagyrajmund.github.io/project/gesturebot.

</p>
</details>

<details><summary><b>Directional Bias Amplification</b>
<a href="https://arxiv.org/abs/2102.12594">arxiv:2102.12594</a>
&#x1F4C8; 20 <br>
<p>Angelina Wang, Olga Russakovsky</p></summary>
<p>

**Abstract:** Mitigating bias in machine learning systems requires refining our understanding of bias propagation pathways: from societal structures to large-scale data to trained models to impact on society. In this work, we focus on one aspect of the problem, namely bias amplification: the tendency of models to amplify the biases present in the data they are trained on. A metric for measuring bias amplification was introduced in the seminal work by Zhao et al. (2017); however, as we demonstrate, this metric suffers from a number of shortcomings including conflating different types of bias amplification and failing to account for varying base rates of protected attributes. We introduce and analyze a new, decoupled metric for measuring bias amplification, $\text{BiasAmp}_{\rightarrow}$ (Directional Bias Amplification). We thoroughly analyze and discuss both the technical assumptions and normative implications of this metric. We provide suggestions about its measurement by cautioning against predicting sensitive attributes, encouraging the use of confidence intervals due to fluctuations in the fairness of models across runs, and discussing the limitations of what this metric captures. Throughout this paper, we work to provide an interrogative look at the technical measurement of bias amplification, guided by our normative ideas of what we want it to encompass. Code is located at https://github.com/princetonvisualai/directional-bias-amp

</p>
</details>

<details><summary><b>The Promises and Pitfalls of Deep Kernel Learning</b>
<a href="https://arxiv.org/abs/2102.12108">arxiv:2102.12108</a>
&#x1F4C8; 20 <br>
<p>Sebastian W. Ober, Carl E. Rasmussen, Mark van der Wilk</p></summary>
<p>

**Abstract:** Deep kernel learning (DKL) and related techniques aim to combine the representational power of neural networks with the reliable uncertainty estimates of Gaussian processes. One crucial aspect of these models is an expectation that, because they are treated as Gaussian process models optimized using the marginal likelihood, they are protected from overfitting. However, we identify situations where this is not the case. We explore this behavior, explain its origins and consider how it applies to real datasets. Through careful experimentation on the UCI, CIFAR-10, and the UTKFace datasets, we find that the overfitting from overparameterized maximum marginal likelihood, in which the model is "somewhat Bayesian", can in certain scenarios be worse than that from not being Bayesian at all. We explain how and when DKL can still be successful by investigating optimization dynamics. We also find that failures of DKL can be rectified by a fully Bayesian treatment, which leads to the desired performance improvements over standard neural networks and Gaussian processes.

</p>
</details>

<details><summary><b>AGENT: A Benchmark for Core Psychological Reasoning</b>
<a href="https://arxiv.org/abs/2102.12321">arxiv:2102.12321</a>
&#x1F4C8; 14 <br>
<p>Tianmin Shu, Abhishek Bhandwaldar, Chuang Gan, Kevin A. Smith, Shari Liu, Dan Gutfreund, Elizabeth Spelke, Joshua B. Tenenbaum, Tomer D. Ullman</p></summary>
<p>

**Abstract:** For machine agents to successfully interact with humans in real-world settings, they will need to develop an understanding of human mental life. Intuitive psychology, the ability to reason about hidden mental variables that drive observable actions, comes naturally to people: even pre-verbal infants can tell agents from objects, expecting agents to act efficiently to achieve goals given constraints. Despite recent interest in machine agents that reason about other agents, it is not clear if such agents learn or hold the core psychology principles that drive human reasoning. Inspired by cognitive development studies on intuitive psychology, we present a benchmark consisting of a large dataset of procedurally generated 3D animations, AGENT (Action, Goal, Efficiency, coNstraint, uTility), structured around four scenarios (goal preferences, action efficiency, unobserved constraints, and cost-reward trade-offs) that probe key concepts of core intuitive psychology. We validate AGENT with human-ratings, propose an evaluation protocol emphasizing generalization, and compare two strong baselines built on Bayesian inverse planning and a Theory of Mind neural network. Our results suggest that to pass the designed tests of core intuitive psychology at human levels, a model must acquire or have built-in representations of how agents plan, combining utility computations and core knowledge of objects and physics.

</p>
</details>

<details><summary><b>Identifying Untrustworthy Predictions in Neural Networks by Geometric Gradient Analysis</b>
<a href="https://arxiv.org/abs/2102.12196">arxiv:2102.12196</a>
&#x1F4C8; 12 <br>
<p>Leo Schwinn, An Nguyen, René Raab, Leon Bungert, Daniel Tenbrinck, Dario Zanca, Martin Burger, Bjoern Eskofier</p></summary>
<p>

**Abstract:** The susceptibility of deep neural networks to untrustworthy predictions, including out-of-distribution (OOD) data and adversarial examples, still prevent their widespread use in safety-critical applications. Most existing methods either require a re-training of a given model to achieve robust identification of adversarial attacks or are limited to out-of-distribution sample detection only. In this work, we propose a geometric gradient analysis (GGA) to improve the identification of untrustworthy predictions without retraining of a given model. GGA analyzes the geometry of the loss landscape of neural networks based on the saliency maps of their respective input. To motivate the proposed approach, we provide theoretical connections between gradients' geometrical properties and local minima of the loss function. Furthermore, we demonstrate that the proposed method outperforms prior approaches in detecting OOD data and adversarial attacks, including state-of-the-art and adaptive attacks.

</p>
</details>

<details><summary><b>Community Detection in Weighted Multilayer Networks with Ambient Noise</b>
<a href="https://arxiv.org/abs/2103.00486">arxiv:2103.00486</a>
&#x1F4C8; 8 <br>
<p>Mark He, Dylan Lu, Jason Xu, Rose Mary Xavier</p></summary>
<p>

**Abstract:** We introduce a novel class of stochastic blockmodel for multilayer weighted networks that accounts for the presence of a global ambient noise governing between-block interactions. We induce a hierarchy of classifications in weighted multilayer networks by assuming that all but one cluster (block) are governed by unique local signals, while a single block behaves identically as interactions across differing blocks (ambient noise). Hierarchical variational inference is employed to jointly detect and typologize blocks as signal or noise. We call this model for multilayer weighted networks the Stochastic Block (with) Ambient Noise Model(SBANM) and develop an associated community detection algorithm. Then we apply this method to subjects in the Philadelphia Neurodevelopmental Cohort to discover communities of subjects with similar psychopathological symptoms in relation to psychosis.

</p>
</details>

<details><summary><b>Deep learning based electrical noise removal enables high spectral optoacoustic contrast in deep tissue</b>
<a href="https://arxiv.org/abs/2102.12960">arxiv:2102.12960</a>
&#x1F4C8; 8 <br>
<p>Christoph Dehner, Ivan Olefir, Kaushik Basak Chowdhury, Dominik Jüstel, Vasilis Ntziachristos</p></summary>
<p>

**Abstract:** Image contrast in multispectral optoacoustic tomography (MSOT) can be severely reduced by electrical noise and interference in the acquired optoacoustic signals. Signal processing techniques have proven insufficient to remove the effects of electrical noise because they typically rely on simplified models and fail to capture complex characteristics of signal and noise. Moreover, they often involve time-consuming processing steps that are unsuited for real-time imaging applications. In this work, we develop and demonstrate a discriminative deep learning (DL) approach to separate electrical noise from optoacoustic signals prior to image reconstruction. The proposed DL algorithm is based on two key features. First, it learns spatiotemporal correlations in both noise and signal by using the entire optoacoustic sinogram as input. Second, it employs training based on a large dataset of experimentally acquired pure noise and synthetic optoacoustic signals. We validated the ability of the trained model to accurately remove electrical noise on synthetic data and on optoacoustic images of a phantom and the human breast. We demonstrate significant enhancements of morphological and spectral optoacoustic images reaching 19% higher blood vessel contrast and localized spectral contrast at depths of more than 2 cm for images acquired in vivo. We discuss how the proposed denoising framework is applicable to clinical multispectral optoacoustic tomography and suitable for real-time operation.

</p>
</details>

<details><summary><b>Nonlinear Invariant Risk Minimization: A Causal Approach</b>
<a href="https://arxiv.org/abs/2102.12353">arxiv:2102.12353</a>
&#x1F4C8; 8 <br>
<p>Chaochao Lu, Yuhuai Wu, Jośe Miguel Hernández-Lobato, Bernhard Schölkopf</p></summary>
<p>

**Abstract:** Due to spurious correlations, machine learning systems often fail to generalize to environments whose distributions differ from the ones used at training time. Prior work addressing this, either explicitly or implicitly, attempted to find a data representation that has an invariant relationship with the target. This is done by leveraging a diverse set of training environments to reduce the effect of spurious features and build an invariant predictor. However, these methods have generalization guarantees only when both data representation and classifiers come from a linear model class. We propose invariant Causal Representation Learning (iCaRL), an approach that enables out-of-distribution (OOD) generalization in the nonlinear setting (i.e., nonlinear representations and nonlinear classifiers). It builds upon a practical and general assumption: the prior over the data representation (i.e., a set of latent variables encoding the data) given the target and the environment belongs to general exponential family distributions. Based on this, we show that it is possible to identify the data representation up to simple transformations. We also prove that all direct causes of the target can be fully discovered, which further enables us to obtain generalization guarantees in the nonlinear setting. Extensive experiments on both synthetic and real-world datasets show that our approach outperforms a variety of baseline methods. Finally, in the discussion, we further explore the aforementioned assumption and propose a more general hypothesis, called the Agnostic Hypothesis: there exist a set of hidden causal factors affecting both inputs and outcomes. The Agnostic Hypothesis can provide a unifying view of machine learning. More importantly, it can inspire a new direction to explore a general theory for identifying hidden causal factors, which is key to enabling the OOD generalization guarantees.

</p>
</details>

<details><summary><b>Distributionally Robust Federated Averaging</b>
<a href="https://arxiv.org/abs/2102.12660">arxiv:2102.12660</a>
&#x1F4C8; 7 <br>
<p>Yuyang Deng, Mohammad Mahdi Kamani, Mehrdad Mahdavi</p></summary>
<p>

**Abstract:** In this paper, we study communication efficient distributed algorithms for distributionally robust federated learning via periodic averaging with adaptive sampling. In contrast to standard empirical risk minimization, due to the minimax structure of the underlying optimization problem, a key difficulty arises from the fact that the global parameter that controls the mixture of local losses can only be updated infrequently on the global stage. To compensate for this, we propose a Distributionally Robust Federated Averaging (DRFA) algorithm that employs a novel snapshotting scheme to approximate the accumulation of history gradients of the mixing parameter. We analyze the convergence rate of DRFA in both convex-linear and nonconvex-linear settings. We also generalize the proposed idea to objectives with regularization on the mixture parameter and propose a proximal variant, dubbed as DRFA-Prox, with provable convergence rates. We also analyze an alternative optimization method for regularized cases in strongly-convex-strongly-concave and non-convex (under PL condition)-strongly-concave settings. To the best of our knowledge, this paper is the first to solve distributionally robust federated learning with reduced communication, and to analyze the efficiency of local descent methods on distributed minimax problems. We give corroborating experimental evidence for our theoretical results in federated learning settings.

</p>
</details>

<details><summary><b>Triplet loss based embeddings for forensic speaker identification in Spanish</b>
<a href="https://arxiv.org/abs/2102.12564">arxiv:2102.12564</a>
&#x1F4C8; 7 <br>
<p>Emmanuel Maqueda, Javier Alvarez-Jimenez, Carlos Mena, Ivan Meza</p></summary>
<p>

**Abstract:** With the advent of digital technology, it is more common that committed crimes or legal disputes involve some form of speech recording where the identity of a speaker is questioned [1]. In face of this situation, the field of forensic speaker identification has been looking to shed light on the problem by quantifying how much a speech recording belongs to a particular person in relation to a population. In this work, we explore the use of speech embeddings obtained by training a CNN using the triplet loss. In particular, we focus on the Spanish language which has not been extensively studies. We propose extracting the embeddings from speech spectrograms samples, then explore several configurations of such spectrograms, and finally, quantify the embeddings quality. We also show some limitations of our data setting which is predominantly composed by male speakers. At the end, we propose two approaches to calculate the Likelihood Radio given out speech embeddings and we show that triplet loss is a good alternative to create speech embeddings for forensic speaker identification.

</p>
</details>

<details><summary><b>Stochastic Aggregation in Graph Neural Networks</b>
<a href="https://arxiv.org/abs/2102.12648">arxiv:2102.12648</a>
&#x1F4C8; 6 <br>
<p>Yuanqing Wang, Theofanis Karaletsos</p></summary>
<p>

**Abstract:** Graph neural networks (GNNs) manifest pathologies including over-smoothing and limited discriminating power as a result of suboptimally expressive aggregating mechanisms. We herein present a unifying framework for stochastic aggregation (STAG) in GNNs, where noise is (adaptively) injected into the aggregation process from the neighborhood to form node embeddings. We provide theoretical arguments that STAG models, with little overhead, remedy both of the aforementioned problems. In addition to fixed-noise models, we also propose probabilistic versions of STAG models and a variational inference framework to learn the noise posterior. We conduct illustrative experiments clearly targeting oversmoothing and multiset aggregation limitations. Furthermore, STAG enhances general performance of GNNs demonstrated by competitive performance in common citation and molecule graph benchmark datasets.

</p>
</details>

<details><summary><b>Sequential Learning-based IaaS Composition</b>
<a href="https://arxiv.org/abs/2102.12598">arxiv:2102.12598</a>
&#x1F4C8; 6 <br>
<p>Sajib Mistry, Sheik Mohammad Mostakim Fattah, Athman Bouguettaya</p></summary>
<p>

**Abstract:** We propose a novel IaaS composition framework that selects an optimal set of consumer requests according to the provider's qualitative preferences on long-term service provisions. Decision variables are included in the temporal conditional preference networks (TempCP-net) to represent qualitative preferences for both short-term and long-term consumers. The global preference ranking of a set of requests is computed using a \textit{k}-d tree indexing based temporal similarity measure approach. We propose an extended three-dimensional Q-learning approach to maximize the global preference ranking. We design the on-policy based sequential selection learning approach that applies the length of request to accept or reject requests in a composition. The proposed on-policy based learning method reuses historical experiences or policies of sequential optimization using an agglomerative clustering approach. Experimental results prove the feasibility of the proposed framework.

</p>
</details>

<details><summary><b>The Logical Options Framework</b>
<a href="https://arxiv.org/abs/2102.12571">arxiv:2102.12571</a>
&#x1F4C8; 6 <br>
<p>Brandon Araki, Xiao Li, Kiran Vodrahalli, Jonathan DeCastro, Micah J. Fry, Daniela Rus</p></summary>
<p>

**Abstract:** Learning composable policies for environments with complex rules and tasks is a challenging problem. We introduce a hierarchical reinforcement learning framework called the Logical Options Framework (LOF) that learns policies that are satisfying, optimal, and composable. LOF efficiently learns policies that satisfy tasks by representing the task as an automaton and integrating it into learning and planning. We provide and prove conditions under which LOF will learn satisfying, optimal policies. And lastly, we show how LOF's learned policies can be composed to satisfy unseen tasks with only 10-50 retraining steps. We evaluate LOF on four tasks in discrete and continuous domains, including a 3D pick-and-place environment.

</p>
</details>

<details><summary><b>Perspective: Purposeful Failure in Artificial Life and Artificial Intelligence</b>
<a href="https://arxiv.org/abs/2102.12076">arxiv:2102.12076</a>
&#x1F4C8; 6 <br>
<p>Lana Sinapayen</p></summary>
<p>

**Abstract:** Complex systems fail. I argue that failures can be a blueprint characterizing living organisms and biological intelligence, a control mechanism to increase complexity in evolutionary simulations, and an alternative to classical fitness optimization. Imitating biological successes in Artificial Life and Artificial Intelligence can be misleading; imitating failures offers a path towards understanding and emulating life it in artificial systems.

</p>
</details>

<details><summary><b>LET: Linguistic Knowledge Enhanced Graph Transformer for Chinese Short Text Matching</b>
<a href="https://arxiv.org/abs/2102.12671">arxiv:2102.12671</a>
&#x1F4C8; 5 <br>
<p>Boer Lyu, Lu Chen, Su Zhu, Kai Yu</p></summary>
<p>

**Abstract:** Chinese short text matching is a fundamental task in natural language processing. Existing approaches usually take Chinese characters or words as input tokens. They have two limitations: 1) Some Chinese words are polysemous, and semantic information is not fully utilized. 2) Some models suffer potential issues caused by word segmentation. Here we introduce HowNet as an external knowledge base and propose a Linguistic knowledge Enhanced graph Transformer (LET) to deal with word ambiguity. Additionally, we adopt the word lattice graph as input to maintain multi-granularity information. Our model is also complementary to pre-trained language models. Experimental results on two Chinese datasets show that our models outperform various typical text matching approaches. Ablation study also indicates that both semantic information and multi-granularity information are important for text matching modeling.

</p>
</details>

<details><summary><b>Prior Image-Constrained Reconstruction using Style-Based Generative Models</b>
<a href="https://arxiv.org/abs/2102.12525">arxiv:2102.12525</a>
&#x1F4C8; 5 <br>
<p>Varun A. Kelkar, Mark A. Anastasio</p></summary>
<p>

**Abstract:** Obtaining a useful estimate of an object from highly incomplete imaging measurements remains a holy grail of imaging science. Deep learning methods have shown promise in learning object priors or constraints to improve the conditioning of an ill-posed imaging inverse problem. In this study, a framework for estimating an object of interest that is semantically related to a known prior image, is proposed. An optimization problem is formulated in the disentangled latent space of a style-based generative model, and semantically meaningful constraints are imposed using the disentangled latent representation of the prior image. Stable recovery from incomplete measurements with the help of a prior image is theoretically analyzed. Numerical experiments demonstrating the superior performance of our approach as compared to related methods are presented.

</p>
</details>

<details><summary><b>Image Augmentation for Multitask Few-Shot Learning: Agricultural Domain Use-Case</b>
<a href="https://arxiv.org/abs/2102.12295">arxiv:2102.12295</a>
&#x1F4C8; 5 <br>
<p>Sergey Nesteruk, Dmitrii Shadrin, Mariia Pukalchik</p></summary>
<p>

**Abstract:** Large datasets' availability is catalyzing a rapid expansion of deep learning in general and computer vision in particular. At the same time, in many domains, a sufficient amount of training data is lacking, which may become an obstacle to the practical application of computer vision techniques. This paper challenges small and imbalanced datasets based on the example of a plant phenomics domain. We introduce an image augmentation framework, which enables us to extremely enlarge the number of training samples while providing the data for such tasks as object detection, semantic segmentation, instance segmentation, object counting, image denoising, and classification. We prove that our augmentation method increases model performance when only a few training samples are available. In our experiment, we use the DeepLabV3 model on semantic segmentation tasks with Arabidopsis and Nicotiana tabacum image dataset. The obtained result shows a 9% relative increase in model performance compared to the basic image augmentation techniques.

</p>
</details>

<details><summary><b>LRG at SemEval-2021 Task 4: Improving Reading Comprehension with Abstract Words using Augmentation, Linguistic Features and Voting</b>
<a href="https://arxiv.org/abs/2102.12255">arxiv:2102.12255</a>
&#x1F4C8; 5 <br>
<p>Abheesht Sharma, Harshit Pandey, Gunjan Chhablani, Yash Bhartia, Tirtharaj Dash</p></summary>
<p>

**Abstract:** In this article, we present our methodologies for SemEval-2021 Task-4: Reading Comprehension of Abstract Meaning. Given a fill-in-the-blank-type question and a corresponding context, the task is to predict the most suitable word from a list of 5 options. There are three sub-tasks within this task: Imperceptibility (subtask-I), Non-Specificity (subtask-II), and Intersection (subtask-III). We use encoders of transformers-based models pre-trained on the masked language modelling (MLM) task to build our Fill-in-the-blank (FitB) models. Moreover, to model imperceptibility, we define certain linguistic features, and to model non-specificity, we leverage information from hypernyms and hyponyms provided by a lexical database. Specifically, for non-specificity, we try out augmentation techniques, and other statistical techniques. We also propose variants, namely Chunk Voting and Max Context, to take care of input length restrictions for BERT, etc. Additionally, we perform a thorough ablation study, and use Integrated Gradients to explain our predictions on a few samples. Our best submissions achieve accuracies of 75.31% and 77.84%, on the test sets for subtask-I and subtask-II, respectively. For subtask-III, we achieve accuracies of 65.64% and 62.27%.

</p>
</details>

<details><summary><b>Learning to Shift Attention for Motion Generation</b>
<a href="https://arxiv.org/abs/2102.12141">arxiv:2102.12141</a>
&#x1F4C8; 5 <br>
<p>You Zhou, Jianfeng Gao, Tamim Asfour</p></summary>
<p>

**Abstract:** One challenge of motion generation using robot learning from demonstration techniques is that human demonstrations follow a distribution with multiple modes for one task query. Previous approaches fail to capture all modes or tend to average modes of the demonstrations and thus generate invalid trajectories. The other difficulty is the small number of demonstrations that cannot cover the entire working space. To overcome this problem, a motion generation model with extrapolation ability is needed. Previous works restrict task queries as local frames and learn representations in local frames. We propose a model to solve both problems. For multiple modes, we suggest to learn local latent representations of motion trajectories with a density estimation method based on real-valued non-volume preserving (RealNVP) transformations that provides a set of powerful, stably invertible, and learnable transformations. To improve the extrapolation ability, we propose to shift the attention of the robot from one local frame to another during the task execution. In experiments, we consider the docking problem used also in previous works where a trajectory has to be generated to connect two dockers without collision. We increase complexity of the task and show that the proposed method outperforms other approaches. In addition, we evaluate the approach in real robot experiments.

</p>
</details>

<details><summary><b>Generalized and Transferable Patient Language Representation for Phenotyping with Limited Data</b>
<a href="https://arxiv.org/abs/2103.00482">arxiv:2103.00482</a>
&#x1F4C8; 4 <br>
<p>Yuqi Si, Elmer V Bernstam, Kirk Roberts</p></summary>
<p>

**Abstract:** The paradigm of representation learning through transfer learning has the potential to greatly enhance clinical natural language processing. In this work, we propose a multi-task pre-training and fine-tuning approach for learning generalized and transferable patient representations from medical language. The model is first pre-trained with different but related high-prevalence phenotypes and further fine-tuned on downstream target tasks. Our main contribution focuses on the impact this technique can have on low-prevalence phenotypes, a challenging task due to the dearth of data. We validate the representation from pre-training, and fine-tune the multi-task pre-trained models on low-prevalence phenotypes including 38 circulatory diseases, 23 respiratory diseases, and 17 genitourinary diseases. We find multi-task pre-training increases learning efficiency and achieves consistently high performance across the majority of phenotypes. Most important, the multi-task pre-training is almost always either the best-performing model or performs tolerably close to the best-performing model, a property we refer to as robust. All these results lead us to conclude that this multi-task transfer learning architecture is a robust approach for developing generalized and transferable patient language representations for numerous phenotypes.

</p>
</details>

<details><summary><b>Beyond Fine-Tuning: Transferring Behavior in Reinforcement Learning</b>
<a href="https://arxiv.org/abs/2102.13515">arxiv:2102.13515</a>
&#x1F4C8; 4 <br>
<p>Víctor Campos, Pablo Sprechmann, Steven Hansen, Andre Barreto, Steven Kapturowski, Alex Vitvitskyi, Adrià Puigdomènech Badia, Charles Blundell</p></summary>
<p>

**Abstract:** Designing agents that acquire knowledge autonomously and use it to solve new tasks efficiently is an important challenge in reinforcement learning. Knowledge acquired during an unsupervised pre-training phase is often transferred by fine-tuning neural network weights once rewards are exposed, as is common practice in supervised domains. Given the nature of the reinforcement learning problem, we argue that standard fine-tuning strategies alone are not enough for efficient transfer in challenging domains. We introduce Behavior Transfer (BT), a technique that leverages pre-trained policies for exploration and that is complementary to transferring neural network weights. Our experiments show that, when combined with large-scale pre-training in the absence of rewards, existing intrinsic motivation objectives can lead to the emergence of complex behaviors. These pre-trained policies can then be leveraged by BT to discover better solutions than without pre-training, and combining BT with standard fine-tuning strategies results in additional benefits. The largest gains are generally observed in domains requiring structured exploration, including settings where the behavior of the pre-trained policies is misaligned with the downstream task.

</p>
</details>

<details><summary><b>Modular Object-Oriented Games: A Task Framework for Reinforcement Learning, Psychology, and Neuroscience</b>
<a href="https://arxiv.org/abs/2102.12616">arxiv:2102.12616</a>
&#x1F4C8; 4 <br>
<p>Nicholas Watters, Joshua Tenenbaum, Mehrdad Jazayeri</p></summary>
<p>

**Abstract:** In recent years, trends towards studying simulated games have gained momentum in the fields of artificial intelligence, cognitive science, psychology, and neuroscience. The intersections of these fields have also grown recently, as researchers increasing study such games using both artificial agents and human or animal subjects. However, implementing games can be a time-consuming endeavor and may require a researcher to grapple with complex codebases that are not easily customized. Furthermore, interdisciplinary researchers studying some combination of artificial intelligence, human psychology, and animal neurophysiology face additional challenges, because existing platforms are designed for only one of these domains. Here we introduce Modular Object-Oriented Games, a Python task framework that is lightweight, flexible, customizable, and designed for use by machine learning, psychology, and neurophysiology researchers.

</p>
</details>

<details><summary><b>Dynamic Social Media Monitoring for Fast-Evolving Online Discussions</b>
<a href="https://arxiv.org/abs/2102.12596">arxiv:2102.12596</a>
&#x1F4C8; 4 <br>
<p>Maya Srikanth, Anqi Liu, Nicholas Adams-Cohen, Jian Cao, R. Michael Alvarez, Anima Anandkumar</p></summary>
<p>

**Abstract:** Tracking and collecting fast-evolving online discussions provides vast data for studying social media usage and its role in people's public lives. However, collecting social media data using a static set of keywords fails to satisfy the growing need to monitor dynamic conversations and to study fast-changing topics. We propose a dynamic keyword search method to maximize the coverage of relevant information in fast-evolving online discussions. The method uses word embedding models to represent the semantic relations between keywords and predictive models to forecast the future time series. We also implement a visual user interface to aid in the decision-making process in each round of keyword updates. This allows for both human-assisted tracking and fully-automated data collection. In simulations using historical #MeToo data in 2017, our human-assisted tracking method outperforms the traditional static baseline method significantly, with 37.1% higher F-1 score than traditional static monitors in tracking the top trending keywords. We conduct a contemporary case study to cover dynamic conversations about the recent Presidential Inauguration and to test the dynamic data collection system. Our case studies reflect the effectiveness of our process and also points to the potential challenges in future deployment.

</p>
</details>

<details><summary><b>PsiPhi-Learning: Reinforcement Learning with Demonstrations using Successor Features and Inverse Temporal Difference Learning</b>
<a href="https://arxiv.org/abs/2102.12560">arxiv:2102.12560</a>
&#x1F4C8; 4 <br>
<p>Angelos Filos, Clare Lyle, Yarin Gal, Sergey Levine, Natasha Jaques, Gregory Farquhar</p></summary>
<p>

**Abstract:** We study reinforcement learning (RL) with no-reward demonstrations, a setting in which an RL agent has access to additional data from the interaction of other agents with the same environment. However, it has no access to the rewards or goals of these agents, and their objectives and levels of expertise may vary widely. These assumptions are common in multi-agent settings, such as autonomous driving. To effectively use this data, we turn to the framework of successor features. This allows us to disentangle shared features and dynamics of the environment from agent-specific rewards and policies. We propose a multi-task inverse reinforcement learning (IRL) algorithm, called \emph{inverse temporal difference learning} (ITD), that learns shared state features, alongside per-agent successor features and preference vectors, purely from demonstrations without reward labels. We further show how to seamlessly integrate ITD with learning from online environment interactions, arriving at a novel algorithm for reinforcement learning with demonstrations, called $ΨΦ$-learning (pronounced `Sci-Fi'). We provide empirical evidence for the effectiveness of $ΨΦ$-learning as a method for improving RL, IRL, imitation, and few-shot transfer, and derive worst-case bounds for its performance in zero-shot transfer to new tasks.

</p>
</details>

<details><summary><b>Entanglement Diagnostics for Efficient Quantum Computation</b>
<a href="https://arxiv.org/abs/2102.12534">arxiv:2102.12534</a>
&#x1F4C8; 4 <br>
<p>Joonho Kim, Yaron Oz</p></summary>
<p>

**Abstract:** We consider information spreading measures in randomly initialized variational quantum circuits and introduce entanglement diagnostics for efficient variational quantum/classical computations. We establish a robust connection between entanglement measures and optimization accuracy by solving two eigensolver problems for Ising Hamiltonians with nearest-neighbor and long-range spin interactions. As the circuit depth affects the average entanglement of random circuit states, the entanglement diagnostics can identify a high-performing depth range for optimization tasks encoded in local Hamiltonians. We argue, based on an eigensolver problem for the Sachdev-Ye-Kitaev model, that entanglement alone is insufficient as a diagnostic to the approximation of volume-law entangled target states and that a large number of circuit parameters is needed for such an optimization task.

</p>
</details>

<details><summary><b>A generative, predictive model for menstrual cycle lengths that accounts for potential self-tracking artifacts in mobile health data</b>
<a href="https://arxiv.org/abs/2102.12439">arxiv:2102.12439</a>
&#x1F4C8; 4 <br>
<p>Kathy Li, Iñigo Urteaga, Amanda Shea, Virginia J. Vitzthum, Chris H. Wiggins, Noémie Elhadad</p></summary>
<p>

**Abstract:** Mobile health (mHealth) apps such as menstrual trackers provide a rich source of self-tracked health observations that can be leveraged for health-relevant research. However, such data streams have questionable reliability since they hinge on user adherence to the app. Therefore, it is crucial for researchers to separate true behavior from self-tracking artifacts. By taking a machine learning approach to modeling self-tracked cycle lengths, we can both make more informed predictions and learn the underlying structure of the observed data. In this work, we propose and evaluate a hierarchical, generative model for predicting next cycle length based on previously-tracked cycle lengths that accounts explicitly for the possibility of users skipping tracking their period. Our model offers several advantages: 1) accounting explicitly for self-tracking artifacts yields better prediction accuracy as likelihood of skipping increases; 2) because it is a generative model, predictions can be updated online as a given cycle evolves, and we can gain interpretable insight into how these predictions change over time; and 3) its hierarchical nature enables modeling of an individual's cycle length history while incorporating population-level information. Our experiments using mHealth cycle length data encompassing over 186,000 menstruators with over 2 million natural menstrual cycles show that our method yields state-of-the-art performance against neural network-based and summary statistic-based baselines, while providing insights on disentangling menstrual patterns from self-tracking artifacts. This work can benefit users, mHealth app developers, and researchers in better understanding cycle patterns and user adherence.

</p>
</details>

<details><summary><b>Noisy Gradient Descent Converges to Flat Minima for Nonconvex Matrix Factorization</b>
<a href="https://arxiv.org/abs/2102.12430">arxiv:2102.12430</a>
&#x1F4C8; 4 <br>
<p>Tianyi Liu, Yan Li, Song Wei, Enlu Zhou, Tuo Zhao</p></summary>
<p>

**Abstract:** Numerous empirical evidences have corroborated the importance of noise in nonconvex optimization problems. The theory behind such empirical observations, however, is still largely unknown. This paper studies this fundamental problem through investigating the nonconvex rectangular matrix factorization problem, which has infinitely many global minima due to rotation and scaling invariance. Hence, gradient descent (GD) can converge to any optimum, depending on the initialization. In contrast, we show that a perturbed form of GD with an arbitrary initialization converges to a global optimum that is uniquely determined by the injected noise. Our result implies that the noise imposes implicit bias towards certain optima. Numerical experiments are provided to support our theory.

</p>
</details>

<details><summary><b>Re-Evaluating GermEval17 Using German Pre-Trained Language Models</b>
<a href="https://arxiv.org/abs/2102.12330">arxiv:2102.12330</a>
&#x1F4C8; 4 <br>
<p>M. Aßenmacher, A. Corvonato, C. Heumann</p></summary>
<p>

**Abstract:** The lack of a commonly used benchmark data set (collection) such as (Super-)GLUE (Wang et al., 2018, 2019) for the evaluation of non-English pre-trained language models is a severe shortcoming of current English-centric NLP-research. It concentrates a large part of the research on English, neglecting the uncertainty when transferring conclusions found for the English language to other languages. We evaluate the performance of the German and multilingual BERT-based models currently available via the huggingface transformers library on the four tasks of the GermEval17 workshop. We compare them to pre-BERT architectures (Wojatzki et al., 2017; Schmitt et al., 2018; Attia et al., 2018) as well as to an ELMo-based architecture (Biesialska et al., 2020) and a BERT-based approach (Guhr et al., 2020). The observed improvements are put in relation to those for similar tasks and similar models (pre-BERT vs. BERT-based) for the English language in order to draw tentative conclusions about whether the observed improvements are transferable to German or potentially other related languages.

</p>
</details>

<details><summary><b>Inductive Bias of Multi-Channel Linear Convolutional Networks with Bounded Weight Norm</b>
<a href="https://arxiv.org/abs/2102.12238">arxiv:2102.12238</a>
&#x1F4C8; 4 <br>
<p>Meena Jagadeesan, Ilya Razenshteyn, Suriya Gunasekar</p></summary>
<p>

**Abstract:** We study the function space characterization of the inductive bias resulting from controlling the $\ell_2$ norm of the weights in linear convolutional networks. We view this in terms of an induced regularizer in the function space given by the minimum norm of weights required to realize a linear function. For two layer linear convolutional networks with $C$ output channels and kernel size $K$, we show the following: (a) If the inputs to the network have a single channel, the induced regularizer for any $K$ is a norm given by a semidefinite program (SDP) that is independent of the number of output channels $C$. (b) In contrast, for networks with multi-channel inputs, multiple output channels can be necessary to merely realize all matrix-valued linear functions and thus the inductive bias does depend on $C$. Further, for sufficiently large $C$, the induced regularizer for $K=1$ and $K=D$ are the nuclear norm and the $\ell_{2,1}$ group-sparse norm, respectively, of the Fourier coefficients. (c) Complementing our theoretical results, we show through experiments on MNIST and CIFAR-10 that our key findings extend to implicit biases from gradient descent in overparameterized networks.

</p>
</details>

<details><summary><b>Abelian Neural Networks</b>
<a href="https://arxiv.org/abs/2102.12232">arxiv:2102.12232</a>
&#x1F4C8; 4 <br>
<p>Kenshin Abe, Takanori Maehara, Issei Sato</p></summary>
<p>

**Abstract:** We study the problem of modeling a binary operation that satisfies some algebraic requirements. We first construct a neural network architecture for Abelian group operations and derive a universal approximation property. Then, we extend it to Abelian semigroup operations using the characterization of associative symmetric polynomials. Both models take advantage of the analytic invertibility of invertible neural networks. For each case, by repeating the binary operations, we can represent a function for multiset input thanks to the algebraic structure. Naturally, our multiset architecture has size-generalization ability, which has not been obtained in existing methods. Further, we present modeling the Abelian group operation itself is useful in a word analogy task. We train our models over fixed word embeddings and demonstrate improved performance over the original word2vec and another naive learning method.

</p>
</details>

<details><summary><b>Multi-Task Attentive Residual Networks for Argument Mining</b>
<a href="https://arxiv.org/abs/2102.12227">arxiv:2102.12227</a>
&#x1F4C8; 4 <br>
<p>Andrea Galassi, Marco Lippi, Paolo Torroni</p></summary>
<p>

**Abstract:** We explore the use of residual networks and neural attention for argument mining and in particular link prediction. The method we propose makes no assumptions on document or argument structure. We propose a residual architecture that exploits attention, multi-task learning, and makes use of ensemble. We evaluate it on a challenging data set consisting of user-generated comments, as well as on two other datasets consisting of scientific publications. On the user-generated content dataset, our model outperforms state-of-the-art methods that rely on domain knowledge. On the scientific literature datasets it achieves results comparable to those yielded by BERT-based approaches but with a much smaller model size.

</p>
</details>

<details><summary><b>PADA: A Prompt-based Autoregressive Approach for Adaptation to Unseen Domains</b>
<a href="https://arxiv.org/abs/2102.12206">arxiv:2102.12206</a>
&#x1F4C8; 4 <br>
<p>Eyal Ben-David, Nadav Oved, Roi Reichart</p></summary>
<p>

**Abstract:** Natural Language Processing algorithms have made incredible progress, but they still struggle when applied to out-of-distribution examples. We address a challenging and underexplored version of this domain adaptation problem, where an algorithm is trained on several source domains, and then applied to examples from an unseen domain that is unknown at training time. Particularly, no examples, labeled or unlabeled, or any other knowledge about the target domain are available to the algorithm at training time. We present PADA: A Prompt-based Autoregressive Domain Adaptation algorithm, based on the T5 model. Given a test example, PADA first generates a unique prompt and then, conditioned on this prompt, labels the example with respect to the NLP task. The prompt is a sequence of unrestricted length, consisting of pre-defined Domain Related Features (DRFs) that characterize each of the source domains. Intuitively, the prompt is a unique signature that maps the test example to the semantic space spanned by the source domains. In experiments with 3 tasks (text classification and sequence tagging), for a total of 14 multi-source adaptation scenarios, PADA substantially outperforms strong baselines.

</p>
</details>

<details><summary><b>Interpreting the Latent Space of Generative Adversarial Networks using Supervised Learning</b>
<a href="https://arxiv.org/abs/2102.12139">arxiv:2102.12139</a>
&#x1F4C8; 4 <br>
<p>Toan Pham Van, Tam Minh Nguyen, Ngoc N. Tran, Hoai Viet Nguyen, Linh Bao Doan, Huy Quang Dao, Thanh Ta Minh</p></summary>
<p>

**Abstract:** With great progress in the development of Generative Adversarial Networks (GANs), in recent years, the quest for insights in understanding and manipulating the latent space of GAN has gained more and more attention due to its wide range of applications. While most of the researches on this task have focused on unsupervised learning method, which induces difficulties in training and limitation in results, our work approaches another direction, encoding human's prior knowledge to discover more about the hidden space of GAN. With this supervised manner, we produce promising results, demonstrated by accurate manipulation of generated images. Even though our model is more suitable for task-specific problems, we hope that its ease in implementation, preciseness, robustness, and the allowance of richer set of properties (compared to other approaches) for image manipulation can enhance the result of many current applications.

</p>
</details>

<details><summary><b>Highly Efficient Representation and Active Learning Framework for Imbalanced Data and its Application to COVID-19 X-Ray Classification</b>
<a href="https://arxiv.org/abs/2103.05109">arxiv:2103.05109</a>
&#x1F4C8; 3 <br>
<p>Heng Hao, Sima Didari, Jae Oh Woo, Hankyu Moon, Patrick Bangert</p></summary>
<p>

**Abstract:** We propose a highly data-efficient classification and active learning framework for classifying chest X-rays. It is based on (1) unsupervised representation learning of a Convolutional Neural Network and (2) the Gaussian Process method. The unsupervised representation learning employs self-supervision that does not require class labels, and the learned features are proven to achieve label-efficient classification. GP is a kernel-based Bayesian approach that also leads to data-efficient predictions with the added benefit of estimating each decision's uncertainty. Our novel framework combines these two elements in sequence to achieve highly data and label efficient classifications. Moreover, both elements are less sensitive to the prevalent and challenging class imbalance issue, thanks to the (1) feature learned without labels and (2) the Bayesian nature of GP. The GP-provided uncertainty estimates enable active learning by ranking samples based on the uncertainty and selectively labeling samples showing higher uncertainty. We apply this novel combination to the data-deficient and severely imbalanced case of COVID-19 chest X-ray classification. We demonstrate that only $\sim 10\%$ of the labeled data is needed to reach the accuracy from training all available labels. Its application to the COVID-19 data in a fully supervised classification scenario shows that our model, with a generic ResNet backbone, outperforms (COVID-19 case by 4\%) the state-of-the-art model with a highly tuned architecture. Our model architecture and proposed framework are general and straightforward to apply to a broader class of datasets, with expected success.

</p>
</details>

<details><summary><b>The INTERSPEECH 2021 Computational Paralinguistics Challenge: COVID-19 Cough, COVID-19 Speech, Escalation & Primates</b>
<a href="https://arxiv.org/abs/2102.13468">arxiv:2102.13468</a>
&#x1F4C8; 3 <br>
<p>Björn W. Schuller, Anton Batliner, Christian Bergler, Cecilia Mascolo, Jing Han, Iulia Lefter, Heysem Kaya, Shahin Amiriparian, Alice Baird, Lukas Stappen, Sandra Ottl, Maurice Gerczuk, Panagiotis Tzirakis, Chloë Brown, Jagmohan Chauhan, Andreas Grammenos, Apinan Hasthanasombat, Dimitris Spathis, Tong Xia, Pietro Cicuta, Leon J. M. Rothkrantz, Joeri Zwerts, Jelle Treep, Casper Kaandorp</p></summary>
<p>

**Abstract:** The INTERSPEECH 2021 Computational Paralinguistics Challenge addresses four different problems for the first time in a research competition under well-defined conditions: In the COVID-19 Cough and COVID-19 Speech Sub-Challenges, a binary classification on COVID-19 infection has to be made based on coughing sounds and speech; in the Escalation SubChallenge, a three-way assessment of the level of escalation in a dialogue is featured; and in the Primates Sub-Challenge, four species vs background need to be classified. We describe the Sub-Challenges, baseline feature extraction, and classifiers based on the 'usual' COMPARE and BoAW features as well as deep unsupervised representation learning using the AuDeep toolkit, and deep feature extraction from pre-trained CNNs using the Deep Spectrum toolkit; in addition, we add deep end-to-end sequential modelling, and partially linguistic analysis.

</p>
</details>

<details><summary><b>Credit Assignment with Meta-Policy Gradient for Multi-Agent Reinforcement Learning</b>
<a href="https://arxiv.org/abs/2102.12957">arxiv:2102.12957</a>
&#x1F4C8; 3 <br>
<p>Jianzhun Shao, Hongchang Zhang, Yuhang Jiang, Shuncheng He, Xiangyang Ji</p></summary>
<p>

**Abstract:** Reward decomposition is a critical problem in centralized training with decentralized execution~(CTDE) paradigm for multi-agent reinforcement learning. To take full advantage of global information, which exploits the states from all agents and the related environment for decomposing Q values into individual credits, we propose a general meta-learning-based Mixing Network with Meta Policy Gradient~(MNMPG) framework to distill the global hierarchy for delicate reward decomposition. The excitation signal for learning global hierarchy is deduced from the episode reward difference between before and after "exercise updates" through the utility network. Our method is generally applicable to the CTDE method using a monotonic mixing network. Experiments on the StarCraft II micromanagement benchmark demonstrate that our method just with a simple utility network is able to outperform the current state-of-the-art MARL algorithms on 4 of 5 super hard scenarios. Better performance can be further achieved when combined with a role-based utility network.

</p>
</details>

<details><summary><b>Real-Time Ellipse Detection for Robotics Applications</b>
<a href="https://arxiv.org/abs/2102.12670">arxiv:2102.12670</a>
&#x1F4C8; 3 <br>
<p>Azarakhsh Keipour, Guilherme A. S. Pereira, Sebastian Scherer</p></summary>
<p>

**Abstract:** We propose a new algorithm for real-time detection and tracking of elliptic patterns suitable for real-world robotics applications. The method fits ellipses to each contour in the image frame and rejects ellipses that do not yield a good fit. The resulting detection and tracking method is lightweight enough to be used on robots' resource-limited onboard computers, can deal with lighting variations and detect the pattern even when the view is partial. The method is tested on an example application of an autonomous UAV landing on a fast-moving vehicle to show its performance indoors, outdoors, and in simulation on a real-world robotics task. The comparison with other well-known ellipse detection methods shows that our proposed algorithm outperforms other methods with the F1 score of 0.981 on a dataset with over 1500 frames. The videos of experiments, the source codes, and the collected dataset are provided with the paper at https://theairlab.org/landing-on-vehicle .

</p>
</details>

<details><summary><b>Provable Compressed Sensing with Generative Priors via Langevin Dynamics</b>
<a href="https://arxiv.org/abs/2102.12643">arxiv:2102.12643</a>
&#x1F4C8; 3 <br>
<p>Thanh V. Nguyen, Gauri Jagatap, Chinmay Hegde</p></summary>
<p>

**Abstract:** Deep generative models have emerged as a powerful class of priors for signals in various inverse problems such as compressed sensing, phase retrieval and super-resolution. Here, we assume an unknown signal to lie in the range of some pre-trained generative model. A popular approach for signal recovery is via gradient descent in the low-dimensional latent space. While gradient descent has achieved good empirical performance, its theoretical behavior is not well understood. In this paper, we introduce the use of stochastic gradient Langevin dynamics (SGLD) for compressed sensing with a generative prior. Under mild assumptions on the generative model, we prove the convergence of SGLD to the true signal. We also demonstrate competitive empirical performance to standard gradient descent.

</p>
</details>

<details><summary><b>Improved Regret Bound and Experience Replay in Regularized Policy Iteration</b>
<a href="https://arxiv.org/abs/2102.12611">arxiv:2102.12611</a>
&#x1F4C8; 3 <br>
<p>Nevena Lazic, Dong Yin, Yasin Abbasi-Yadkori, Csaba Szepesvari</p></summary>
<p>

**Abstract:** In this work, we study algorithms for learning in infinite-horizon undiscounted Markov decision processes (MDPs) with function approximation. We first show that the regret analysis of the Politex algorithm (a version of regularized policy iteration) can be sharpened from $O(T^{3/4})$ to $O(\sqrt{T})$ under nearly identical assumptions, and instantiate the bound with linear function approximation. Our result provides the first high-probability $O(\sqrt{T})$ regret bound for a computationally efficient algorithm in this setting. The exact implementation of Politex with neural network function approximation is inefficient in terms of memory and computation. Since our analysis suggests that we need to approximate the average of the action-value functions of past policies well, we propose a simple efficient implementation where we train a single Q-function on a replay buffer with past data. We show that this often leads to superior performance over other implementation choices, especially in terms of wall-clock time. Our work also provides a novel theoretical justification for using experience replay within policy iteration algorithms.

</p>
</details>

<details><summary><b>Learning Emergent Discrete Message Communication for Cooperative Reinforcement Learning</b>
<a href="https://arxiv.org/abs/2102.12550">arxiv:2102.12550</a>
&#x1F4C8; 3 <br>
<p>Sheng Li, Yutai Zhou, Ross Allen, Mykel J. Kochenderfer</p></summary>
<p>

**Abstract:** Communication is a important factor that enables agents work cooperatively in multi-agent reinforcement learning (MARL). Most previous work uses continuous message communication whose high representational capacity comes at the expense of interpretability. Allowing agents to learn their own discrete message communication protocol emerged from a variety of domains can increase the interpretability for human designers and other agents.This paper proposes a method to generate discrete messages analogous to human languages, and achieve communication by a broadcast-and-listen mechanism based on self-attention. We show that discrete message communication has performance comparable to continuous message communication but with much a much smaller vocabulary size.Furthermore, we propose an approach that allows humans to interactively send discrete messages to agents.

</p>
</details>

<details><summary><b>Auto-Detection of Tibial Plateau Angle in Canine Radiographs Using a Deep Learning Approach</b>
<a href="https://arxiv.org/abs/2102.12544">arxiv:2102.12544</a>
&#x1F4C8; 3 <br>
<p>Masuda Akter Tonima, F M Anim Hossain, Austin DeHart, Youmin Zhang</p></summary>
<p>

**Abstract:** Stifle joint issues are a major cause of lameness in dogs and it can be a significant marker for various forms of diseases or injuries. A known Tibial Plateau Angle (TPA) helps in the reduction of the diagnosis time of the cause. With the state of the art object detection algorithm YOLO, and its variants, this paper delves into identifying joints, their centroids and other regions of interest to draw multiple line axes and finally calculating the TPA. The methods investigated predicts successfully the TPA within the normal range for 80 percent of the images.

</p>
</details>

<details><summary><b>No-Regret Algorithms for Private Gaussian Process Bandit Optimization</b>
<a href="https://arxiv.org/abs/2102.12467">arxiv:2102.12467</a>
&#x1F4C8; 3 <br>
<p>Abhimanyu Dubey</p></summary>
<p>

**Abstract:** The widespread proliferation of data-driven decision-making has ushered in a recent interest in the design of privacy-preserving algorithms. In this paper, we consider the ubiquitous problem of gaussian process (GP) bandit optimization from the lens of privacy-preserving statistics. We propose a solution for differentially private GP bandit optimization that combines a uniform kernel approximator with random perturbations, providing a generic framework to create differentially-private (DP) Gaussian process bandit algorithms. For two specific DP settings - joint and local differential privacy, we provide algorithms based on efficient quadrature Fourier feature approximators, that are computationally efficient and provably no-regret for popular stationary kernel functions. Our algorithms maintain differential privacy throughout the optimization procedure and critically do not rely explicitly on the sample path for prediction, making the parameters straightforward to release as well.

</p>
</details>

<details><summary><b>Generating and Blending Game Levels via Quality-Diversity in the Latent Space of a Variational Autoencoder</b>
<a href="https://arxiv.org/abs/2102.12463">arxiv:2102.12463</a>
&#x1F4C8; 3 <br>
<p>Anurag Sarkar, Seth Cooper</p></summary>
<p>

**Abstract:** Several works have demonstrated the use of variational autoencoders (VAEs) for generating levels in the style of existing games and blending levels across different games. Further, quality-diversity (QD) algorithms have also become popular for generating varied game content by using evolution to explore a search space while focusing on both variety and quality. To reap the benefits of both these approaches, we present a level generation and game blending approach that combines the use of VAEs and QD algorithms. Specifically, we train VAEs on game levels and run the MAP-Elites QD algorithm using the learned latent space of the VAE as the search space. The latent space captures the properties of the games whose levels we want to generate and blend, while MAP-Elites searches this latent space to find a diverse set of levels optimizing a given objective such as playability. We test our method using models for 5 different platformer games as well as a blended domain spanning 3 of these games. We refer to using MAP-Elites for blending as Blend-Elites. Our results show that MAP-Elites in conjunction with VAEs enables the generation of a diverse set of playable levels not just for each individual game but also for the blended domain while illuminating game-specific regions of the blended latent space.

</p>
</details>

<details><summary><b>Deep Reinforcement Learning for Safe Landing Site Selection with Concurrent Consideration of Divert Maneuvers</b>
<a href="https://arxiv.org/abs/2102.12432">arxiv:2102.12432</a>
&#x1F4C8; 3 <br>
<p>Keidai Iiyama, Kento Tomita, Bhavi A. Jagatia, Tatsuwaki Nakagawa, Koki Ho</p></summary>
<p>

**Abstract:** This research proposes a new integrated framework for identifying safe landing locations and planning in-flight divert maneuvers. The state-of-the-art algorithms for landing zone selection utilize local terrain features such as slopes and roughness to judge the safety and priority of the landing point. However, when there are additional chances of observation and diverting in the future, these algorithms are not able to evaluate the safety of the decision itself to target the selected landing point considering the overall descent trajectory. In response to this challenge, we propose a reinforcement learning framework that optimizes a landing site selection strategy concurrently with a guidance and control strategy to the target landing site. The trained agent could evaluate and select landing sites with explicit consideration of the terrain features, quality of future observations, and control to achieve a safe and efficient landing trajectory at a system-level. The proposed framework was able to achieve 94.8 $\%$ of successful landing in highly challenging landing sites where over 80$\%$ of the area around the initial target lading point is hazardous, by effectively updating the target landing site and feedback control gain during descent.

</p>
</details>

<details><summary><b>Designing Explanations for Group Recommender Systems</b>
<a href="https://arxiv.org/abs/2102.12413">arxiv:2102.12413</a>
&#x1F4C8; 3 <br>
<p>A. Felfernig, N. Tintarev, T. N. T. Trang, M. Stettinger</p></summary>
<p>

**Abstract:** Explanations are used in recommender systems for various reasons. Users have to be supported in making (high-quality) decisions more quickly. Developers of recommender systems want to convince users to purchase specific items. Users should better understand how the recommender system works and why a specific item has been recommended. Users should also develop a more in-depth understanding of the item domain. Consequently, explanations are designed in order to achieve specific \emph{goals} such as increasing the transparency of a recommendation or increasing a user's trust in the recommender system. In this paper, we provide an overview of existing research related to explanations in recommender systems, and specifically discuss aspects relevant to group recommendation scenarios. In this context, we present different ways of explaining and visualizing recommendations determined on the basis of preference aggregation strategies.

</p>
</details>

<details><summary><b>Computing Differential Privacy Guarantees for Heterogeneous Compositions Using FFT</b>
<a href="https://arxiv.org/abs/2102.12412">arxiv:2102.12412</a>
&#x1F4C8; 3 <br>
<p>Antti Koskela, Antti Honkela</p></summary>
<p>

**Abstract:** The recently proposed Fast Fourier Transform (FFT)-based accountant for evaluating $(\varepsilon,δ)$-differential privacy guarantees using the privacy loss distribution formalism has been shown to give tighter bounds than commonly used methods such as Rényi accountants when applied to homogeneous compositions, i.e., to compositions of identical mechanisms. In this paper, we extend this approach to heterogeneous compositions. We carry out a full error analysis that allows choosing the parameters of the algorithm such that a desired accuracy is obtained. The analysis also extends previous results by taking into account all the parameters of the algorithm. Using the error analysis, we also give a bound for the computational complexity in terms of the error which is analogous to and slightly tightens the one given by Murtagh and Vadhan (2018). We also show how to speed up the evaluation of tight privacy guarantees using the Plancherel theorem at the cost of increased pre-computation and memory usage.

</p>
</details>

<details><summary><b>On the Impact of Interpretability Methods in Active Image Augmentation Method</b>
<a href="https://arxiv.org/abs/2102.12354">arxiv:2102.12354</a>
&#x1F4C8; 3 <br>
<p>Flavio Santos, Cleber Zanchettin, Leonardo Matos, Paulo Novais</p></summary>
<p>

**Abstract:** Robustness is a significant constraint in machine learning models. The performance of the algorithms must not deteriorate when training and testing with slightly different data. Deep neural network models achieve awe-inspiring results in a wide range of applications of computer vision. Still, in the presence of noise or region occlusion, some models exhibit inaccurate performance even with data handled in training. Besides, some experiments suggest deep learning models sometimes use incorrect parts of the input information to perform inference. Activate Image Augmentation (ADA) is an augmentation method that uses interpretability methods to augment the training data and improve its robustness to face the described problems. Although ADA presented interesting results, its original version only used the Vanilla Backpropagation interpretability to train the U-Net model. In this work, we propose an extensive experimental analysis of the interpretability method's impact on ADA. We use five interpretability methods: Vanilla Backpropagation, Guided Backpropagation, GradCam, Guided GradCam, and InputXGradient. The results show that all methods achieve similar performance at the ending of training, but when combining ADA with GradCam, the U-Net model presented an impressive fast convergence.

</p>
</details>

<details><summary><b>AutoAI-TS: AutoAI for Time Series Forecasting</b>
<a href="https://arxiv.org/abs/2102.12347">arxiv:2102.12347</a>
&#x1F4C8; 3 <br>
<p>Syed Yousaf Shah, Dhaval Patel, Long Vu, Xuan-Hong Dang, Bei Chen, Peter Kirchner, Horst Samulowitz, David Wood, Gregory Bramble, Wesley M. Gifford, Giridhar Ganapavarapu, Roman Vaculin, Petros Zerfos</p></summary>
<p>

**Abstract:** A large number of time series forecasting models including traditional statistical models, machine learning models and more recently deep learning have been proposed in the literature. However, choosing the right model along with good parameter values that performs well on a given data is still challenging. Automatically providing a good set of models to users for a given dataset saves both time and effort from using trial-and-error approaches with a wide variety of available models along with parameter optimization. We present AutoAI for Time Series Forecasting (AutoAI-TS) that provides users with a zero configuration (zero-conf ) system to efficiently train, optimize and choose best forecasting model among various classes of models for the given dataset. With its flexible zero-conf design, AutoAI-TS automatically performs all the data preparation, model creation, parameter optimization, training and model selection for users and provides a trained model that is ready to use. For given data, AutoAI-TS utilizes a wide variety of models including classical statistical models, Machine Learning (ML) models, statistical-ML hybrid models and deep learning models along with various transformations to create forecasting pipelines. It then evaluates and ranks pipelines using the proposed T-Daub mechanism to choose the best pipeline. The paper describe in detail all the technical aspects of AutoAI-TS along with extensive benchmarking on a variety of real world data sets for various use-cases. Benchmark results show that AutoAI-TS, with no manual configuration from the user, automatically trains and selects pipelines that on average outperform existing state-of-the-art time series forecasting toolkits.

</p>
</details>

<details><summary><b>Similarity measure for sparse time course data based on Gaussian processes</b>
<a href="https://arxiv.org/abs/2102.12342">arxiv:2102.12342</a>
&#x1F4C8; 3 <br>
<p>Zijing Liu, Mauricio Barahona</p></summary>
<p>

**Abstract:** We propose a similarity measure for sparsely sampled time course data in the form of a log-likelihood ratio of Gaussian processes (GP). The proposed GP similarity is similar to a Bayes factor and provides enhanced robustness to noise in sparse time series, such as those found in various biological settings, e.g., gene transcriptomics. We show that the GP measure is equivalent to the Euclidean distance when the noise variance in the GP is negligible compared to the noise variance of the signal. Our numerical experiments on both synthetic and real data show improved performance of the GP similarity when used in conjunction with two distance-based clustering methods.

</p>
</details>

<details><summary><b>"Train one, Classify one, Teach one" -- Cross-surgery transfer learning for surgical step recognition</b>
<a href="https://arxiv.org/abs/2102.12308">arxiv:2102.12308</a>
&#x1F4C8; 3 <br>
<p>Daniel Neimark, Omri Bar, Maya Zohar, Gregory D. Hager, Dotan Asselmann</p></summary>
<p>

**Abstract:** Prior work demonstrated the ability of machine learning to automatically recognize surgical workflow steps from videos. However, these studies focused on only a single type of procedure. In this work, we analyze, for the first time, surgical step recognition on four different laparoscopic surgeries: Cholecystectomy, Right Hemicolectomy, Sleeve Gastrectomy, and Appendectomy. Inspired by the traditional apprenticeship model, in which surgical training is based on the Halstedian method, we paraphrase the "see one, do one, teach one" approach for the surgical intelligence domain as "train one, classify one, teach one". In machine learning, this approach is often referred to as transfer learning. To analyze the impact of transfer learning across different laparoscopic procedures, we explore various time-series architectures and examine their performance on each target domain. We introduce a new architecture, the Time-Series Adaptation Network (TSAN), an architecture optimized for transfer learning of surgical step recognition, and we show how TSAN can be pre-trained using self-supervised learning on a Sequence Sorting task. Such pre-training enables TSAN to learn workflow steps of a new laparoscopic procedure type from only a small number of labeled samples from the target procedure. Our proposed architecture leads to better performance compared to other possible architectures, reaching over 90% accuracy when transferring from laparoscopic Cholecystectomy to the other three procedure types.

</p>
</details>

<details><summary><b>Density Sketches for Sampling and Estimation</b>
<a href="https://arxiv.org/abs/2102.12301">arxiv:2102.12301</a>
&#x1F4C8; 3 <br>
<p>Aditya Desai, Benjamin Coleman, Anshumali Shrivastava</p></summary>
<p>

**Abstract:** We introduce Density sketches (DS): a succinct online summary of the data distribution. DS can accurately estimate point wise probability density. Interestingly, DS also provides a capability to sample unseen novel data from the underlying data distribution. Thus, analogous to popular generative models, DS allows us to succinctly replace the real-data in almost all machine learning pipelines with synthetic examples drawn from the same distribution as the original data. However, unlike generative models, which do not have any statistical guarantees, DS leads to theoretically sound asymptotically converging consistent estimators of the underlying density function. Density sketches also have many appealing properties making them ideal for large-scale distributed applications. DS construction is an online algorithm. The sketches are additive, i.e., the sum of two sketches is the sketch of the combined data. These properties allow data to be collected from distributed sources, compressed into a density sketch, efficiently transmitted in the sketch form to a central server, merged, and re-sampled into a synthetic database for modeling applications. Thus, density sketches can potentially revolutionize how we store, communicate, and distribute data.

</p>
</details>

<details><summary><b>Two-way kernel matrix puncturing: towards resource-efficient PCA and spectral clustering</b>
<a href="https://arxiv.org/abs/2102.12293">arxiv:2102.12293</a>
&#x1F4C8; 3 <br>
<p>Romain Couillet, Florent Chatelain, Nicolas Le Bihan</p></summary>
<p>

**Abstract:** The article introduces an elementary cost and storage reduction method for spectral clustering and principal component analysis. The method consists in randomly "puncturing" both the data matrix $X\in\mathbb{C}^{p\times n}$ (or $\mathbb{R}^{p\times n}$) and its corresponding kernel (Gram) matrix $K$ through Bernoulli masks: $S\in\{0,1\}^{p\times n}$ for $X$ and $B\in\{0,1\}^{n\times n}$ for $K$. The resulting "two-way punctured" kernel is thus given by $K=\frac{1}{p}[(X \odot S)^{\sf H} (X \odot S)] \odot B$. We demonstrate that, for $X$ composed of independent columns drawn from a Gaussian mixture model, as $n,p\to\infty$ with $p/n\to c_0\in(0,\infty)$, the spectral behavior of $K$ -- its limiting eigenvalue distribution, as well as its isolated eigenvalues and eigenvectors -- is fully tractable and exhibits a series of counter-intuitive phenomena. We notably prove, and empirically confirm on GAN-generated image databases, that it is possible to drastically puncture the data, thereby providing possibly huge computational and storage gains, for a virtually constant (clustering of PCA) performance. This preliminary study opens as such the path towards rethinking, from a large dimensional standpoint, computational and storage costs in elementary machine learning models.

</p>
</details>

<details><summary><b>Automatic Feature Extraction for Heartbeat Anomaly Detection</b>
<a href="https://arxiv.org/abs/2102.12289">arxiv:2102.12289</a>
&#x1F4C8; 3 <br>
<p>Robert-George Colt, Csongor-Huba Várady, Riccardo Volpi, Luigi Malagò</p></summary>
<p>

**Abstract:** We focus on automatic feature extraction for raw audio heartbeat sounds, aimed at anomaly detection applications in healthcare. We learn features with the help of an autoencoder composed by a 1D non-causal convolutional encoder and a WaveNet decoder trained with a modified objective based on variational inference, employing the Maximum Mean Discrepancy (MMD). Moreover we model the latent distribution using a Gaussian chain graphical model to capture temporal correlations which characterize the encoded signals. After training the autoencoder on the reconstruction task in a unsupervised manner, we test the significance of the learned latent representations by training an SVM to predict anomalies. We evaluate the methods on a problem proposed by the PASCAL Classifying Heart Sounds Challenge and we compare with results in the literature.

</p>
</details>

<details><summary><b>NLRG at SemEval-2021 Task 5: Toxic Spans Detection Leveraging BERT-based Token Classification and Span Prediction Techniques</b>
<a href="https://arxiv.org/abs/2102.12254">arxiv:2102.12254</a>
&#x1F4C8; 3 <br>
<p>Gunjan Chhablani, Abheesht Sharma, Harshit Pandey, Yash Bhartia, Shan Suthaharan</p></summary>
<p>

**Abstract:** Toxicity detection of text has been a popular NLP task in the recent years. In SemEval-2021 Task-5 Toxic Spans Detection, the focus is on detecting toxic spans within passages. Most state-of-the-art span detection approaches employ various techniques, each of which can be broadly classified into Token Classification or Span Prediction approaches. In our paper, we explore simple versions of both of these approaches and their performance on the task. Specifically, we use BERT-based models -- BERT, RoBERTa, and SpanBERT for both approaches. We also combine these approaches and modify them to bring improvements for Toxic Spans prediction. To this end, we investigate results on four hybrid approaches -- Multi-Span, Span+Token, LSTM-CRF, and a combination of predicted offsets using union/intersection. Additionally, we perform a thorough ablative analysis and analyze our observed results. Our best submission -- a combination of SpanBERT Span Predictor and RoBERTa Token Classifier predictions -- achieves an F1 score of 0.6753 on the test set. Our best post-eval F1 score is 0.6895 on intersection of predicted offsets from top-3 RoBERTa Token Classification checkpoints. These approaches improve the performance by 3% on average than those of the shared baseline models -- RNNSL and SpaCy NER.

</p>
</details>

<details><summary><b>Combining Off and On-Policy Training in Model-Based Reinforcement Learning</b>
<a href="https://arxiv.org/abs/2102.12194">arxiv:2102.12194</a>
&#x1F4C8; 3 <br>
<p>Alexandre Borges, Arlindo Oliveira</p></summary>
<p>

**Abstract:** The combination of deep learning and Monte Carlo Tree Search (MCTS) has shown to be effective in various domains, such as board and video games. AlphaGo represented a significant step forward in our ability to learn complex board games, and it was rapidly followed by significant advances, such as AlphaGo Zero and AlphaZero. Recently, MuZero demonstrated that it is possible to master both Atari games and board games by directly learning a model of the environment, which is then used with MCTS to decide what move to play in each position. During tree search, the algorithm simulates games by exploring several possible moves and then picks the action that corresponds to the most promising trajectory. When training, limited use is made of these simulated games since none of their trajectories are directly used as training examples. Even if we consider that not all trajectories from simulated games are useful, there are thousands of potentially useful trajectories that are discarded. Using information from these trajectories would provide more training data, more quickly, leading to faster convergence and higher sample efficiency. Recent work introduced an off-policy value target for AlphaZero that uses data from simulated games. In this work, we propose a way to obtain off-policy targets using data from simulated games in MuZero. We combine these off-policy targets with the on-policy targets already used in MuZero in several ways, and study the impact of these targets and their combinations in three environments with distinct characteristics. When used in the right combinations, our results show that these targets can speed up the training process and lead to faster convergence and higher rewards than the ones obtained by MuZero.

</p>
</details>

<details><summary><b>Parameterized Temperature Scaling for Boosting the Expressive Power in Post-Hoc Uncertainty Calibration</b>
<a href="https://arxiv.org/abs/2102.12182">arxiv:2102.12182</a>
&#x1F4C8; 3 <br>
<p>Christian Tomani, Daniel Cremers, Florian Buettner</p></summary>
<p>

**Abstract:** We address the problem of uncertainty calibration and introduce a novel calibration method, Parametrized Temperature Scaling (PTS). Standard deep neural networks typically yield uncalibrated predictions, which can be transformed into calibrated confidence scores using post-hoc calibration methods. In this contribution, we demonstrate that the performance of accuracy-preserving state-of-the-art post-hoc calibrators is limited by their intrinsic expressive power. We generalize temperature scaling by computing prediction-specific temperatures, parameterized by a neural network. We show with extensive experiments that our novel accuracy-preserving approach consistently outperforms existing algorithms across a large number of model architectures, datasets and metrics.

</p>
</details>

<details><summary><b>Learning to Generate Wasserstein Barycenters</b>
<a href="https://arxiv.org/abs/2102.12178">arxiv:2102.12178</a>
&#x1F4C8; 3 <br>
<p>Julien Lacombe, Julie Digne, Nicolas Courty, Nicolas Bonneel</p></summary>
<p>

**Abstract:** Optimal transport is a notoriously difficult problem to solve numerically, with current approaches often remaining intractable for very large scale applications such as those encountered in machine learning. Wasserstein barycenters -- the problem of finding measures in-between given input measures in the optimal transport sense -- is even more computationally demanding as it requires to solve an optimization problem involving optimal transport distances. By training a deep convolutional neural network, we improve by a factor of 60 the computational speed of Wasserstein barycenters over the fastest state-of-the-art approach on the GPU, resulting in milliseconds computational times on $512\times512$ regular grids. We show that our network, trained on Wasserstein barycenters of pairs of measures, generalizes well to the problem of finding Wasserstein barycenters of more than two measures. We demonstrate the efficiency of our approach for computing barycenters of sketches and transferring colors between multiple images.

</p>
</details>

<details><summary><b>Efficient Palm-Line Segmentation with U-Net Context Fusion Module</b>
<a href="https://arxiv.org/abs/2102.12127">arxiv:2102.12127</a>
&#x1F4C8; 3 <br>
<p>Toan Pham Van, Son Trung Nguyen, Linh Bao Doan, Ngoc N. Tran, Ta Minh Thanh</p></summary>
<p>

**Abstract:** Many cultures around the world believe that palm reading can be used to predict the future life of a person. Palmistry uses features of the hand such as palm lines, hand shape, or fingertip position. However, the research on palm-line detection is still scarce, many of them applied traditional image processing techniques. In most real-world scenarios, images usually are not in well-conditioned, causing these methods to severely under-perform. In this paper, we propose an algorithm to extract principle palm lines from an image of a person's hand. Our method applies deep learning networks (DNNs) to improve performance. Another challenge of this problem is the lack of training data. To deal with this issue, we handcrafted a dataset from scratch. From this dataset, we compare the performance of readily available methods with ours. Furthermore, based on the UNet segmentation neural network architecture and the knowledge of attention mechanism, we propose a highly efficient architecture to detect palm-lines. We proposed the Context Fusion Module to capture the most important context feature, which aims to improve segmentation accuracy. The experimental results show that it outperforms the other methods with the highest F1 Score about 99.42% and mIoU is 0.584 for the same dataset.

</p>
</details>

<details><summary><b>Fast Approximate Solutions using Reinforcement Learning for Dynamic Capacitated Vehicle Routing with Time Windows</b>
<a href="https://arxiv.org/abs/2102.12088">arxiv:2102.12088</a>
&#x1F4C8; 3 <br>
<p>Nazneen N Sultana, Vinita Baniwal, Ansuma Basumatary, Piyush Mittal, Supratim Ghosh, Harshad Khadilkar</p></summary>
<p>

**Abstract:** This paper develops an inherently parallelised, fast, approximate learning-based solution to the generic class of Capacitated Vehicle Routing Problems with Time Windows and Dynamic Routing (CVRP-TWDR). Considering vehicles in a fleet as decentralised agents, we postulate that using reinforcement learning (RL) based adaptation is a key enabler for real-time route formation in a dynamic environment. The methodology allows each agent (vehicle) to independently evaluate the value of serving each customer, and uses a centralised allocation heuristic to finalise the allocations based on the generated values. We show that the solutions produced by this method are significantly faster than exact formulations and state-of-the-art meta-heuristics, while being reasonably close to optimal in terms of solution quality. We describe experiments in both the static case (when all customer demands and time windows are known in advance) as well as the dynamic case (where customers can pop up at any time during execution). The results with a single trained model on large, out-of-distribution test data demonstrate the scalability and flexibility of the proposed approach.

</p>
</details>

<details><summary><b>SocialNLP EmotionGIF 2020 Challenge Overview: Predicting Reaction GIF Categories on Social Media</b>
<a href="https://arxiv.org/abs/2102.12073">arxiv:2102.12073</a>
&#x1F4C8; 3 <br>
<p>Boaz Shmueli, Lun-Wei Ku, Soumya Ray</p></summary>
<p>

**Abstract:** We present an overview of the EmotionGIF2020 Challenge, held at the 8th International Workshop on Natural Language Processing for Social Media (SocialNLP), in conjunction with ACL 2020. The challenge required predicting affective reactions to online texts, and included the EmotionGIF dataset, with tweets labeled for the reaction categories. The novel dataset included 40K tweets with their reaction GIFs. Due to the special circumstances of year 2020, two rounds of the competition were conducted. A total of 84 teams registered for the task. Of these, 25 teams success-fully submitted entries to the evaluation phase in the first round, while 13 teams participated successfully in the second round. Of the top participants, five teams presented a technical report and shared their code. The top score of the winning team using the Recall@K metric was 62.47%.

</p>
</details>

<details><summary><b>Spatio-Temporal Look-Ahead Trajectory Prediction using Memory Neural Network</b>
<a href="https://arxiv.org/abs/2102.12070">arxiv:2102.12070</a>
&#x1F4C8; 3 <br>
<p>Nishanth Rao, Suresh Sundaram</p></summary>
<p>

**Abstract:** Prognostication of vehicle trajectories in unknown environments is intrinsically a challenging and difficult problem to solve. The behavior of such vehicles is highly influenced by surrounding traffic, road conditions, and rogue participants present in the environment. Moreover, the presence of pedestrians, traffic lights, stop signs, etc., makes it much harder to infer the behavior of various traffic agents. This paper attempts to solve the problem of Spatio-temporal look-ahead trajectory prediction using a novel recurrent neural network called the Memory Neuron Network. The Memory Neuron Network (MNN) attempts to capture the input-output relationship between the past positions and the future positions of the traffic agents. The proposed model is computationally less intensive and has a simple architecture as compared to other deep learning models that utilize LSTMs and GRUs. It is then evaluated on the publicly available NGSIM dataset and its performance is compared with several state-of-art algorithms. Additionally, the performance is also evaluated on a custom synthetic dataset generated from the CARLA simulator. It is seen that the proposed model outperforms the existing state-of-art algorithms. Finally, the model is integrated with the CARLA simulator to test its robustness in real-time traffic scenarios.

</p>
</details>

<details><summary><b>Reservoir Computing as a Tool for Climate Predictability Studies</b>
<a href="https://arxiv.org/abs/2103.06206">arxiv:2103.06206</a>
&#x1F4C8; 2 <br>
<p>B. T. Nadiga</p></summary>
<p>

**Abstract:** Reduced-order dynamical models play a central role in developing our understanding of predictability of climate irrespective of whether we are dealing with the actual climate system or surrogate climate-models. In this context, the Linear-Inverse-Modeling (LIM) approach, by capturing a few essential interactions between dynamical components of the full system, has proven valuable in providing insights into predictability of the full system. We demonstrate that Reservoir Computing (RC), a form of learning suitable for systems with chaotic dynamics, provides an alternative nonlinear approach that improves on the predictive skill of the LIM approach. We do this in the example setting of predicting sea-surface-temperature in the North Atlantic in the pre-industrial control simulation of a popular earth system model, the Community-Earth-System-Model so that we can compare the performance of the new RC based approach with the traditional LIM approach both when learning data is plentiful and when such data is more limited. The improved predictive skill of the RC approach over a wide range of conditions -- larger number of retained EOF coefficients, extending well into the limited data regime, etc. -- suggests that this machine-learning technique may have a use in climate predictability studies. While the possibility of developing a climate emulator -- the ability to continue the evolution of the system on the attractor long after failing to be able to track the reference trajectory -- is demonstrated in the Lorenz-63 system, it is suggested that further development of the RC approach may permit such uses of the new approach in more realistic predictability studies.

</p>
</details>

<details><summary><b>Semantically Constrained Memory Allocation (SCMA) for Embedding in Efficient Recommendation Systems</b>
<a href="https://arxiv.org/abs/2103.06124">arxiv:2103.06124</a>
&#x1F4C8; 2 <br>
<p>Aditya Desai, Yanzhou Pan, Kuangyuan Sun, Li Chou, Anshumali Shrivastava</p></summary>
<p>

**Abstract:** Deep learning-based models are utilized to achieve state-of-the-art performance for recommendation systems. A key challenge for these models is to work with millions of categorical classes or tokens. The standard approach is to learn end-to-end, dense latent representations or embeddings for each token. The resulting embeddings require large amounts of memory that blow up with the number of tokens. Training and inference with these models create storage, and memory bandwidth bottlenecks leading to significant computing and energy consumption when deployed in practice. To this end, we present the problem of \textit{Memory Allocation} under budget for embeddings and propose a novel formulation of memory shared embedding, where memory is shared in proportion to the overlap in semantic information. Our formulation admits a practical and efficient randomized solution with Locality sensitive hashing based Memory Allocation (LMA). We demonstrate a significant reduction in the memory footprint while maintaining performance. In particular, our LMA embeddings achieve the same performance compared to standard embeddings with a 16$\times$ reduction in memory footprint. Moreover, LMA achieves an average improvement of over 0.003 AUC across different memory regimes than standard DLRM models on Criteo and Avazu datasets

</p>
</details>

<details><summary><b>Hybrid Car-Following Strategy based on Deep Deterministic Policy Gradient and Cooperative Adaptive Cruise Control</b>
<a href="https://arxiv.org/abs/2103.03796">arxiv:2103.03796</a>
&#x1F4C8; 2 <br>
<p>Ruidong Yan, Rui Jiang, Bin Jia, Diange Yang, Jin Huang</p></summary>
<p>

**Abstract:** Deep deterministic policy gradient (DDPG) based car-following strategy can break through the constraints of the differential equation model due to the ability of exploration on complex environments. However, the car-following performance of DDPG is usually degraded by unreasonable reward function design, insufficient training and low sampling efficiency. In order to solve this kind of problem, a hybrid car-following strategy based on DDPG and cooperative adaptive cruise control (CACC) is proposed. Firstly, the car-following process is modeled as markov decision process to calculate CACC and DDPG simultaneously at each frame. Given a current state, two actions are obtained from CACC and DDPG, respectively. Then an optimal action, corresponding to the one offering a larger reward, is chosen as the output of the hybrid strategy. Meanwhile, a rule is designed to ensure that the change rate of acceleration is smaller than the desired value. Therefore, the proposed strategy not only guarantees the basic performance of car-following through CACC, but also makes full use of the advantages of exploration on complex environments via DDPG. Finally, simulation results show that the car-following performance of proposed strategy is improved significantly as compared with that of DDPG and CACC in the whole state space.

</p>
</details>

<details><summary><b>Automatic Cell Counting in Flourescent Microscopy Using Deep Learning</b>
<a href="https://arxiv.org/abs/2103.01141">arxiv:2103.01141</a>
&#x1F4C8; 2 <br>
<p>R. Morelli, L. Clissa, M. Dalla, M. Luppi, L. Rinaldi, A. Zoccoli</p></summary>
<p>

**Abstract:** Counting cells in fluorescent microscopy is a tedious, time-consuming task that researchers have to accomplish to assess the effects of different experimental conditions on biological structures of interest. Although such objects are generally easy to identify, the process of manually annotating cells is sometimes subject to arbitrariness due to the operator's interpretation of the borderline cases.
  We propose a Machine Learning approach that exploits a fully-convolutional network in a binary segmentation fashion to localize the objects of interest. Counts are then retrieved as the number of detected items.
  Specifically, we adopt a UNet-like architecture leveraging residual units and an extended bottleneck for enlarging the field-of-view. In addition, we make use of weighted maps that penalize the errors on cells boundaries increasingly with overcrowding. These changes provide more context and force the model to focus on relevant features during pixel-wise classification. As a result, the model performance is enhanced, especially in presence of clumping cells, artifacts and confounding biological structures. Posterior assessment of the results with domain experts confirms that the model detects cells of interest correctly. The model demonstrates a human-level ability inasmuch even erroneous predictions seem to fall within the limits of operator interpretation. This qualitative assessment is also corroborated by quantitative metrics as an ${F_1}$ score of 0.87.
  Despite some difficulties in interpretation, results are also satisfactory with respect to the counting task, as testified by mean and median absolute error of, respectively, 0.8 and 1.

</p>
</details>

<details><summary><b>Variational Selective Autoencoder: Learning from Partially-Observed Heterogeneous Data</b>
<a href="https://arxiv.org/abs/2102.12679">arxiv:2102.12679</a>
&#x1F4C8; 2 <br>
<p>Yu Gong, Hossein Hajimirsadeghi, Jiawei He, Thibaut Durand, Greg Mori</p></summary>
<p>

**Abstract:** Learning from heterogeneous data poses challenges such as combining data from various sources and of different types. Meanwhile, heterogeneous data are often associated with missingness in real-world applications due to heterogeneity and noise of input sources. In this work, we propose the variational selective autoencoder (VSAE), a general framework to learn representations from partially-observed heterogeneous data. VSAE learns the latent dependencies in heterogeneous data by modeling the joint distribution of observed data, unobserved data, and the imputation mask which represents how the data are missing. It results in a unified model for various downstream tasks including data generation and imputation. Evaluation on both low-dimensional and high-dimensional heterogeneous datasets for these two tasks shows improvement over state-of-the-art models.

</p>
</details>

<details><summary><b>Railway Anomaly detection model using synthetic defect images generated by CycleGAN</b>
<a href="https://arxiv.org/abs/2102.12595">arxiv:2102.12595</a>
&#x1F4C8; 2 <br>
<p>Takuro Hoshi, Yohei Baba, Gaurang Gavai</p></summary>
<p>

**Abstract:** Although training data is essential for machine learning, railway companies are facing difficulties in gathering adequate images of defective equipment due to their proactive replacement of would be defective equipment. Nevertheless, proactive replacement is indispensable for safe and undisturbed operation of public transport. In this research, we have developed a model using CycleGAN to generate artificial images of defective equipment instead of real images. By adopting these generated images as training data, we verified that these images are indistinguishable from real images and they play a vital role in enhancing the accuracy of the defect detection models.

</p>
</details>

<details><summary><b>Robust SleepNets</b>
<a href="https://arxiv.org/abs/2102.12555">arxiv:2102.12555</a>
&#x1F4C8; 2 <br>
<p>Yigit Alparslan, Edward Kim</p></summary>
<p>

**Abstract:** State-of-the-art convolutional neural networks excel in machine learning tasks such as face recognition, and object classification but suffer significantly when adversarial attacks are present. It is crucial that machine critical systems, where machine learning models are deployed, utilize robust models to handle a wide range of variability in the real world and malicious actors that may use adversarial attacks. In this study, we investigate eye closedness detection to prevent vehicle accidents related to driver disengagements and driver drowsiness. Specifically, we focus on adversarial attacks in this application domain, but emphasize that the methodology can be applied to many other domains. We develop two models to detect eye closedness: first model on eye images and a second model on face images. We adversarially attack the models with Projected Gradient Descent, Fast Gradient Sign and DeepFool methods and report adversarial success rate. We also study the effect of training data augmentation. Finally, we adversarially train the same models on perturbed images and report the success rate for the defense against these attacks. We hope our study sets up the work to prevent potential vehicle accidents by capturing drivers' face images and alerting them in case driver's eyes are closed due to drowsiness.

</p>
</details>

<details><summary><b>On the Validity of Modeling SGD with Stochastic Differential Equations (SDEs)</b>
<a href="https://arxiv.org/abs/2102.12470">arxiv:2102.12470</a>
&#x1F4C8; 2 <br>
<p>Zhiyuan Li, Sadhika Malladi, Sanjeev Arora</p></summary>
<p>

**Abstract:** It is generally recognized that finite learning rate (LR), in contrast to infinitesimal LR, is important for good generalization in real-life deep nets. Most attempted explanations propose approximating finite-LR SGD with Ito Stochastic Differential Equations (SDEs), but formal justification for this approximation (e.g., (Li et al., 2019)) only applies to SGD with tiny LR. Experimental verification of the approximation appears computationally infeasible. The current paper clarifies the picture with the following contributions: (a) An efficient simulation algorithm SVAG that provably converges to the conventionally used Ito SDE approximation. (b) A theoretically motivated testable necessary condition for the SDE approximation and its most famous implication, the linear scaling rule (Goyal et al., 2017), to hold. (c) Experiments using this simulation to demonstrate that the previously proposed SDE approximation can meaningfully capture the training and generalization properties of common deep nets.

</p>
</details>

<details><summary><b>MAPFAST: A Deep Algorithm Selector for Multi Agent Path Finding using Shortest Path Embeddings</b>
<a href="https://arxiv.org/abs/2102.12461">arxiv:2102.12461</a>
&#x1F4C8; 2 <br>
<p>Jingyao Ren, Vikraman Sathiyanarayanan, Eric Ewing, Baskin Senbaslar, Nora Ayanian</p></summary>
<p>

**Abstract:** Solving the Multi-Agent Path Finding (MAPF) problem optimally is known to be NP-Hard for both make-span and total arrival time minimization. While many algorithms have been developed to solve MAPF problems, there is no dominating optimal MAPF algorithm that works well in all types of problems and no standard guidelines for when to use which algorithm. In this work, we develop the deep convolutional network MAPFAST (Multi-Agent Path Finding Algorithm SelecTor), which takes a MAPF problem instance and attempts to select the fastest algorithm to use from a portfolio of algorithms. We improve the performance of our model by including single-agent shortest paths in the instance embedding given to our model and by utilizing supplemental loss functions in addition to a classification loss. We evaluate our model on a large and diverse dataset of MAPF instances, showing that it outperforms all individual algorithms in its portfolio as well as the state-of-the-art optimal MAPF algorithm selector. We also provide an analysis of algorithm behavior in our dataset to gain a deeper understanding of optimal MAPF algorithms' strengths and weaknesses to help other researchers leverage different heuristics in algorithm designs.

</p>
</details>

<details><summary><b>Rigid and non-rigid motion compensation in weight-bearing cone-beam CT of the knee using (noisy) inertial measurements</b>
<a href="https://arxiv.org/abs/2102.12418">arxiv:2102.12418</a>
&#x1F4C8; 2 <br>
<p>Jennifer Maier, Marlies Nitschke, Jang-Hwan Choi, Garry Gold, Rebecca Fahrig, Bjoern M. Eskofier, Andreas Maier</p></summary>
<p>

**Abstract:** Involuntary subject motion is the main source of artifacts in weight-bearing cone-beam CT of the knee. To achieve image quality for clinical diagnosis, the motion needs to be compensated. We propose to use inertial measurement units (IMUs) attached to the leg for motion estimation. We perform a simulation study using real motion recorded with an optical tracking system. Three IMU-based correction approaches are evaluated, namely rigid motion correction, non-rigid 2D projection deformation and non-rigid 3D dynamic reconstruction. We present an initialization process based on the system geometry. With an IMU noise simulation, we investigate the applicability of the proposed methods in real applications. All proposed IMU-based approaches correct motion at least as good as a state-of-the-art marker-based approach. The structural similarity index and the root mean squared error between motion-free and motion corrected volumes are improved by 24-35% and 78-85%, respectively, compared with the uncorrected case. The noise analysis shows that the noise levels of commercially available IMUs need to be improved by a factor of $10^5$ which is currently only achieved by specialized hardware not robust enough for the application. The presented study confirms the feasibility of this novel approach and defines improvements necessary for a real application.

</p>
</details>

<details><summary><b>Balancing Rational and Other-Regarding Preferences in Cooperative-Competitive Environments</b>
<a href="https://arxiv.org/abs/2102.12307">arxiv:2102.12307</a>
&#x1F4C8; 2 <br>
<p>Dmitry Ivanov, Vladimir Egorov, Aleksei Shpilman</p></summary>
<p>

**Abstract:** Recent reinforcement learning studies extensively explore the interplay between cooperative and competitive behaviour in mixed environments. Unlike cooperative environments where agents strive towards a common goal, mixed environments are notorious for the conflicts of selfish and social interests. As a consequence, purely rational agents often struggle to achieve and maintain cooperation. A prevalent approach to induce cooperative behaviour is to assign additional rewards based on other agents' well-being. However, this approach suffers from the issue of multi-agent credit assignment, which can hinder performance. This issue is efficiently alleviated in cooperative setting with such state-of-the-art algorithms as QMIX and COMA. Still, when applied to mixed environments, these algorithms may result in unfair allocation of rewards. We propose BAROCCO, an extension of these algorithms capable to balance individual and social incentives. The mechanism behind BAROCCO is to train two distinct but interwoven components that jointly affect each agent's decisions. Our meta-algorithm is compatible with both Q-learning and Actor-Critic frameworks. We experimentally confirm the advantages over the existing methods and explore the behavioural aspects of BAROCCO in two mixed multi-agent setups.

</p>
</details>

<details><summary><b>DeepCervix: A Deep Learning-based Framework for the Classification of Cervical Cells Using Hybrid Deep Feature Fusion Techniques</b>
<a href="https://arxiv.org/abs/2102.12191">arxiv:2102.12191</a>
&#x1F4C8; 2 <br>
<p>Md Mamunur Rahaman, Chen Li, Yudong Yao, Frank Kulwa, Xiangchen Wu, Xiaoyan Li, Qian Wang</p></summary>
<p>

**Abstract:** Cervical cancer, one of the most common fatal cancers among women, can be prevented by regular screening to detect any precancerous lesions at early stages and treat them. Pap smear test is a widely performed screening technique for early detection of cervical cancer, whereas this manual screening method suffers from high false-positive results because of human errors. To improve the manual screening practice, machine learning (ML) and deep learning (DL) based computer-aided diagnostic (CAD) systems have been investigated widely to classify cervical pap cells. Most of the existing researches require pre-segmented images to obtain good classification results, whereas accurate cervical cell segmentation is challenging because of cell clustering. Some studies rely on handcrafted features, which cannot guarantee the classification stage's optimality. Moreover, DL provides poor performance for a multiclass classification task when there is an uneven distribution of data, which is prevalent in the cervical cell dataset. This investigation has addressed those limitations by proposing DeepCervix, a hybrid deep feature fusion (HDFF) technique based on DL to classify the cervical cells accurately. Our proposed method uses various DL models to capture more potential information to enhance classification performance. Our proposed HDFF method is tested on the publicly available SIPAKMED dataset and compared the performance with base DL models and the LF method. For the SIPAKMED dataset, we have obtained the state-of-the-art classification accuracy of 99.85%, 99.38%, and 99.14% for 2-class, 3-class, and 5-class classification. Moreover, our method is tested on the Herlev dataset and achieves an accuracy of 98.32% for binary class and 90.32% for 7-class classification.

</p>
</details>

<details><summary><b>From Universal Language Model to Downstream Task: Improving RoBERTa-Based Vietnamese Hate Speech Detection</b>
<a href="https://arxiv.org/abs/2102.12162">arxiv:2102.12162</a>
&#x1F4C8; 2 <br>
<p>Quang Huu Pham, Viet Anh Nguyen, Linh Bao Doan, Ngoc N. Tran, Ta Minh Thanh</p></summary>
<p>

**Abstract:** Natural language processing is a fast-growing field of artificial intelligence. Since the Transformer was introduced by Google in 2017, a large number of language models such as BERT, GPT, and ELMo have been inspired by this architecture. These models were trained on huge datasets and achieved state-of-the-art results on natural language understanding. However, fine-tuning a pre-trained language model on much smaller datasets for downstream tasks requires a carefully-designed pipeline to mitigate problems of the datasets such as lack of training data and imbalanced data. In this paper, we propose a pipeline to adapt the general-purpose RoBERTa language model to a specific text classification task: Vietnamese Hate Speech Detection. We first tune the PhoBERT on our dataset by re-training the model on the Masked Language Model task; then, we employ its encoder for text classification. In order to preserve pre-trained weights while learning new feature representations, we further utilize different training techniques: layer freezing, block-wise learning rate, and label smoothing. Our experiments proved that our proposed pipeline boosts the performance significantly, achieving a new state-of-the-art on Vietnamese Hate Speech Detection campaign with 0.7221 F1 score.

</p>
</details>

<details><summary><b>Deep Learning Approach for Singer Voice Classification of Vietnamese Popular Music</b>
<a href="https://arxiv.org/abs/2102.12111">arxiv:2102.12111</a>
&#x1F4C8; 2 <br>
<p>Toan Pham Van, Ngoc N. Tran, Ta Minh Thanh</p></summary>
<p>

**Abstract:** Singer voice classification is a meaningful task in the digital era. With a huge number of songs today, identifying a singer is very helpful for music information retrieval, music properties indexing, and so on. In this paper, we propose a new method to identify the singer's name based on analysis of Vietnamese popular music. We employ the use of vocal segment detection and singing voice separation as the pre-processing steps. The purpose of these steps is to extract the singer's voice from the mixture sound. In order to build a singer classifier, we propose a neural network architecture working with Mel Frequency Cepstral Coefficient as extracted input features from said vocal. To verify the accuracy of our methods, we evaluate on a dataset of 300 Vietnamese songs from 18 famous singers. We achieve an accuracy of 92.84% with 5-fold stratified cross-validation, the best result compared to other methods on the same data set.

</p>
</details>

<details><summary><b>GraphBreak: Tool for Network Community based Regulatory Medicine, Gene co-expression, Linkage Disequilibrium analysis, functional annotation and more</b>
<a href="https://arxiv.org/abs/2103.06145">arxiv:2103.06145</a>
&#x1F4C8; 1 <br>
<p>Abhishek Narain Singh</p></summary>
<p>

**Abstract:** Graph network science is becoming increasingly popular, notably in big-data perspective where understanding individual entities for individual functional roles is complex and time consuming. It is likely when a set of genes are regulated by a set of genetic variants, the genes set is recruited for a common or related functional purpose. Grouping and extracting communities from network of associations becomes critical to understand system complexity, thus prioritizing genes for dis-ease and functional associations. Workload is reduced when studying entities one at a time. For this, we present GraphBreak, a suite of tools for community detection application, such as for gene co-expression, protein interaction, regulation network, etc.Although developed for use case of eQTLs regulatory genomic net-work community study -- results shown with our analysis with sample eQTL data. Graphbreak can be deployed for other studies if input data has been fed in requisite format, including but not limited to gene co-expression networks, protein-protein interaction network, signaling pathway and metabolic network. Graph-Break showed critical use case value in its downstream analysis for disease association of communities detected. If all independent steps of community detection and analysis are a step-by-step sub-part of the algorithm, GraphBreak can be considered a new algorithm for community based functional characterization. Combination of various algorithmic implementation modules into a single script for this purpose illustrates GraphBreak novelty. Compared to other similar tools, with GraphBreak we can better detect communities with over-representation of its member genes for statistical association with diseases, therefore target genes which can be prioritized for drug-positioning or drug-re-positioning as the case be.

</p>
</details>

<details><summary><b>A Memory Optimized Data Structure for Binary Chromosomes in Genetic Algorithm</b>
<a href="https://arxiv.org/abs/2103.04751">arxiv:2103.04751</a>
&#x1F4C8; 1 <br>
<p>Avijit Basak</p></summary>
<p>

**Abstract:** This paper presents a memory-optimized metadata-based data structure for implementation of binary chromosome in Genetic Algorithm. In GA different types of genotypes are used depending on the problem domain. Among these, binary genotype is the most popular one for non-enumerated encoding owing to its representational and computational simplicity. This paper proposes a memory-optimized implementation approach of binary genotype. The approach improves the memory utilization as well as capacity of retaining alleles. Mathematical proof has been provided to establish the same.

</p>
</details>

<details><summary><b>Learning to Make Compiler Optimizations More Effective</b>
<a href="https://arxiv.org/abs/2102.13514">arxiv:2102.13514</a>
&#x1F4C8; 1 <br>
<p>Rahim Mammadli, Marija Selakovic, Felix Wolf, Michael Pradel</p></summary>
<p>

**Abstract:** Because loops execute their body many times, compiler developers place much emphasis on their optimization. Nevertheless, in view of highly diverse source code and hardware, compilers still struggle to produce optimal target code. The sheer number of possible loop optimizations, including their combinations, exacerbates the problem further. Today's compilers use hard-coded heuristics to decide when, whether, and which of a limited set of optimizations to apply. Often, this leads to highly unstable behavior, making the success of compiler optimizations dependent on the precise way a loop has been written. This paper presents LoopLearner, which addresses the problem of compiler instability by predicting which way of writing a loop will lead to efficient compiled code. To this end, we train a neural network to find semantically invariant source-level transformations for loops that help the compiler generate more efficient code. Our model learns to extract useful features from the raw source code and predicts the speedup that a given transformation is likely to yield. We evaluate LoopLearner with 1,895 loops from various performance-relevant benchmarks. Applying the transformations that our model deems most favorable prior to compilation yields an average speedup of 1.14x. When trying the top-3 suggested transformations, the average speedup even increases to 1.29x. Comparing the approach with an exhaustive search through all available code transformations shows that LoopLearner helps to identify the most beneficial transformations in several orders of magnitude less time.

</p>
</details>

<details><summary><b>Bayesian OOD detection with aleatoric uncertainty and outlier exposure</b>
<a href="https://arxiv.org/abs/2102.12959">arxiv:2102.12959</a>
&#x1F4C8; 1 <br>
<p>Xi Wang, Laurence Aitchison</p></summary>
<p>

**Abstract:** Typical Bayesian approaches to OOD detection use epistemic uncertainty. Surprisingly from the Bayesian perspective, there are a number of methods that successfully use aleatoric uncertainty to detect OOD points (e.g. Hendryks et al. 2018). In addition, it is difficult to use outlier exposure to improve a Bayesian OOD detection model, as it is not clear whether it is possible or desirable to increase posterior (epistemic) uncertainty at outlier points. We show that a generative model of data curation provides a principled account of aleatoric uncertainty for OOD detection. In particular, aleatoric uncertainty signals a specific type of OOD point: one without a well-defined class-label, and our model of data curation gives a likelihood for these points, giving us a mechanism for conditioning on outlier points and thus performing principled Bayesian outlier exposure. Our principled Bayesian approach, combining aleatoric and epistemic uncertainty with outlier exposure performs better than methods using aleatoric or epistemic alone.

</p>
</details>

<details><summary><b>Learning-based Robust Motion Planning with Guaranteed Stability: A Contraction Theory Approach</b>
<a href="https://arxiv.org/abs/2102.12668">arxiv:2102.12668</a>
&#x1F4C8; 1 <br>
<p>Hiroyasu Tsukamoto, Soon-Jo Chung</p></summary>
<p>

**Abstract:** This paper presents Learning-based Autonomous Guidance with RObustness and Stability guarantees (LAG-ROS), which provides machine learning-based nonlinear motion planners with formal robustness and stability guarantees, by designing a differential Lyapunov function using contraction theory. LAG-ROS utilizes a neural network to model a robust tracking controller independently of a target trajectory, for which we show that the Euclidean distance between the target and controlled trajectories is exponentially bounded linearly in the learning error, even under the existence of bounded external disturbances. We also present a convex optimization approach that minimizes the steady-state bound of the tracking error to construct the robust control law for neural network training. In numerical simulations, it is demonstrated that the proposed method indeed possesses superior properties of robustness and nonlinear stability resulting from contraction theory, whilst retaining the computational efficiency of existing learning-based motion planners.

</p>
</details>

<details><summary><b>Maximum Likelihood Constraint Inference from Stochastic Demonstrations</b>
<a href="https://arxiv.org/abs/2102.12554">arxiv:2102.12554</a>
&#x1F4C8; 1 <br>
<p>David L. McPherson, Kaylene C. Stocking, S. Shankar Sastry</p></summary>
<p>

**Abstract:** When an expert operates a perilous dynamic system, ideal constraint information is tacitly contained in their demonstrated trajectories and controls. The likelihood of these demonstrations can be computed, given the system dynamics and task objective, and the maximum likelihood constraints can be identified. Prior constraint inference work has focused mainly on deterministic models. Stochastic models, however, can capture the uncertainty and risk tolerance that are often present in real systems of interest.
  This paper extends maximum likelihood constraint inference to stochastic applications by using maximum causal entropy likelihoods. Furthermore, we propose an efficient algorithm that computes constraint likelihood and risk tolerance in a unified Bellman backup, allowing us to generalize to stochastic systems without increasing computational complexity.

</p>
</details>

<details><summary><b>Using Inverse Optimization to Learn Cost Functions in Generalized Nash Games</b>
<a href="https://arxiv.org/abs/2102.12415">arxiv:2102.12415</a>
&#x1F4C8; 1 <br>
<p>Stephanie Allen, John P. Dickerson, Steven A. Gabriel</p></summary>
<p>

**Abstract:** As demonstrated by Ratliff et al. (2014), inverse optimization can be used to recover the objective function parameters of players in multi-player Nash games. These games involve the optimization problems of multiple players in which the players can affect each other in their objective functions. In generalized Nash equilibrium problems (GNEPs), a player's set of feasible actions is also impacted by the actions taken by other players in the game; see Facchinei and Kanzow (2010) for more background on this problem. One example of such impact comes in the form of joint/"coupled" constraints as referenced by Rosen (1965), Harker (1991), and Facchinei et al. (2007) which involve other players' variables in the constraints of the feasible region. We extend the framework of Ratliff et al. (2014) to find inverse optimization solutions for the class of GNEPs with joint constraints. The resulting formulation is then applied to a simulated multi-player transportation problem on a road network. Also, we provide some theoretical results related to this transportation problem regarding runtime of the extended framework as well as uniqueness and non-uniqueness of solutions to our simulation experiments. We see that our model recovers parameterizations that produce the same flow patterns as the original parameterizations and that this holds true across multiple networks, different assumptions regarding players' perceived costs, and the majority of restrictive capacity settings and the associated numbers of players. Code for the project can be found at: https://github.com/sallen7/IO_GNEP.

</p>
</details>

<details><summary><b>Wirelessly Powered Federated Edge Learning: Optimal Tradeoffs Between Convergence and Power Transfer</b>
<a href="https://arxiv.org/abs/2102.12357">arxiv:2102.12357</a>
&#x1F4C8; 1 <br>
<p>Qunsong Zeng, Yuqing Du, Kaibin Huang</p></summary>
<p>

**Abstract:** Federated edge learning (FEEL) is a widely adopted framework for training an artificial intelligence (AI) model distributively at edge devices to leverage their data while preserving their data privacy. The execution of a power-hungry learning task at energy-constrained devices is a key challenge confronting the implementation of FEEL. To tackle the challenge, we propose the solution of powering devices using wireless power transfer (WPT). To derive guidelines on deploying the resultant wirelessly powered FEEL (WP-FEEL) system, this work aims at the derivation of the tradeoff between the model convergence and the settings of power sources in two scenarios: 1) the transmission power and density of power-beacons (dedicated charging stations) if they are deployed, or otherwise 2) the transmission power of a server (access-point). The development of the proposed analytical framework relates the accuracy of distributed stochastic gradient estimation to the WPT settings, the randomness in both communication and WPT links, and devices' computation capacities. Furthermore, the local-computation at devices (i.e., mini-batch size and processor clock frequency) is optimized to efficiently use the harvested energy for gradient estimation. The resultant learning-WPT tradeoffs reveal the simple scaling laws of the model-convergence rate with respect to the transferred energy as well as the devices' computational energy efficiencies. The results provide useful guidelines on WPT provisioning to provide a guaranteer on learning performance. They are corroborated by experimental results using a real dataset.

</p>
</details>

<details><summary><b>An Overview of Direct Diagnosis and Repair Techniques in the WeeVis Recommendation Environment</b>
<a href="https://arxiv.org/abs/2102.12327">arxiv:2102.12327</a>
&#x1F4C8; 1 <br>
<p>Alexander Felfernig, Stefan Reiterer, Martin Stettinger, Michael Jeran</p></summary>
<p>

**Abstract:** Constraint-based recommenders support users in the identification of items (products) fitting their wishes and needs. Example domains are financial services and electronic equipment. In this paper we show how divide-and-conquer based (direct) diagnosis algorithms (no conflict detection is needed) can be exploited in constraint-based recommendation scenarios. In this context, we provide an overview of the MediaWiki-based recommendation environment WeeVis.

</p>
</details>

<details><summary><b>Hyperspectral Denoising Using Unsupervised Disentangled Spatio-Spectral Deep Priors</b>
<a href="https://arxiv.org/abs/2102.12310">arxiv:2102.12310</a>
&#x1F4C8; 1 <br>
<p>Yu-Chun Miao, Xi-Le Zhao, Xiao Fu, Jian-Li Wang, Yu-Bang Zheng</p></summary>
<p>

**Abstract:** Image denoising is often empowered by accurate prior information. In recent years, data-driven neural network priors have shown promising performance for RGB natural image denoising. Compared to classic handcrafted priors (e.g., sparsity and total variation), the "deep priors" are learned using a large number of training samples -- which can accurately model the complex image generating process. However, data-driven priors are hard to acquire for hyperspectral images (HSIs) due to the lack of training data. A remedy is to use the so-called unsupervised deep image prior (DIP). Under the unsupervised DIP framework, it is hypothesized and empirically demonstrated that proper neural network structures are reasonable priors of certain types of images, and the network weights can be learned without training data. Nonetheless, the most effective unsupervised DIP structures were proposed for natural images instead of HSIs. The performance of unsupervised DIP-based HSI denoising is limited by a couple of serious challenges, namely, network structure design and network complexity. This work puts forth an unsupervised DIP framework that is based on the classic spatio-spectral decomposition of HSIs. Utilizing the so-called linear mixture model of HSIs, two types of unsupervised DIPs, i.e., U-Net-like network and fully-connected networks, are employed to model the abundance maps and endmembers contained in the HSIs, respectively. This way, empirically validated unsupervised DIP structures for natural images can be easily incorporated for HSI denoising. Besides, the decomposition also substantially reduces network complexity. An efficient alternating optimization algorithm is proposed to handle the formulated denoising problem. Semi-real and real data experiments are employed to showcase the effectiveness of the proposed approach.

</p>
</details>

<details><summary><b>Gaussian boson sampling and multi-particle event optimization by machine learning in the quantum phase space</b>
<a href="https://arxiv.org/abs/2102.12142">arxiv:2102.12142</a>
&#x1F4C8; 1 <br>
<p>Claudio Conti</p></summary>
<p>

**Abstract:** We use neural networks to represent the characteristic function of many-body Gaussian states in the quantum phase space. By a pullback mechanism, we model transformations due to unitary operators as linear layers that can be cascaded to simulate complex multi-particle processes. We use the layered neural networks for non-classical light propagation in random interferometers, and compute boson pattern probabilities by automatic differentiation. We also demonstrate that multi-particle events in Gaussian boson sampling can be optimized by a proper design and training of the neural network weights. The results are potentially useful to the creation of new sources and complex circuits for quantum technologies.

</p>
</details>

<details><summary><b>FIXAR: A Fixed-Point Deep Reinforcement Learning Platform with Quantization-Aware Training and Adaptive Parallelism</b>
<a href="https://arxiv.org/abs/2102.12103">arxiv:2102.12103</a>
&#x1F4C8; 1 <br>
<p>Je Yang, Seongmin Hong, Joo-Young Kim</p></summary>
<p>

**Abstract:** In this paper, we present a deep reinforcement learning platform named FIXAR which employs fixed-point data types and arithmetic units for the first time using a SW/HW co-design approach. Starting from 32-bit fixed-point data, Quantization-Aware Training (QAT) reduces its data precision based on the range of activations and performs retraining to minimize the reward degradation. FIXAR proposes the adaptive array processing core composed of configurable processing elements to support both intra-layer parallelism and intra-batch parallelism for high-throughput inference and training. Finally, FIXAR was implemented on Xilinx U50 and achieves 25293.3 inferences per second (IPS) training throughput and 2638.0 IPS/W accelerator efficiency, which is 2.7 times faster and 15.4 times more energy efficient than those of the CPU-GPU platform without any accuracy degradation.

</p>
</details>

<details><summary><b>Lossless Compression of Efficient Private Local Randomizers</b>
<a href="https://arxiv.org/abs/2102.12099">arxiv:2102.12099</a>
&#x1F4C8; 1 <br>
<p>Vitaly Feldman, Kunal Talwar</p></summary>
<p>

**Abstract:** Locally Differentially Private (LDP) Reports are commonly used for collection of statistics and machine learning in the federated setting. In many cases the best known LDP algorithms require sending prohibitively large messages from the client device to the server (such as when constructing histograms over large domain or learning a high-dimensional model). This has led to significant efforts on reducing the communication cost of LDP algorithms.
  At the same time LDP reports are known to have relatively little information about the user's data due to randomization. Several schemes are known that exploit this fact to design low-communication versions of LDP algorithm but all of them do so at the expense of a significant loss in utility. Here we demonstrate a general approach that, under standard cryptographic assumptions, compresses every efficient LDP algorithm with negligible loss in privacy and utility guarantees. The practical implication of our result is that in typical applications the message can be compressed to the size of the server's pseudo-random generator seed. More generally, we relate the properties of an LDP randomizer to the power of a pseudo-random generator that suffices for compressing the LDP randomizer. From this general approach we derive low-communication algorithms for the problems of frequency estimation and high-dimensional mean estimation. Our algorithms are simpler and more accurate than existing low-communication LDP algorithms for these well-studied problems.

</p>
</details>

<details><summary><b>Learning optimal multigrid smoothers via neural networks</b>
<a href="https://arxiv.org/abs/2102.12071">arxiv:2102.12071</a>
&#x1F4C8; 1 <br>
<p>Ru Huang, Ruipeng Li, Yuanzhe Xi</p></summary>
<p>

**Abstract:** Multigrid methods are one of the most efficient techniques for solving linear systems arising from Partial Differential Equations (PDEs) and graph Laplacians from machine learning applications. One of the key components of multigrid is smoothing, which aims at reducing high-frequency errors on each grid level. However, finding optimal smoothing algorithms is problem-dependent and can impose challenges for many problems. In this paper, we propose an efficient adaptive framework for learning optimized smoothers from operator stencils in the form of convolutional neural networks (CNNs). The CNNs are trained on small-scale problems from a given type of PDEs based on a supervised loss function derived from multigrid convergence theories, and can be applied to large-scale problems of the same class of PDEs. Numerical results on anisotropic rotated Laplacian problems demonstrate improved convergence rates and solution time compared with classical hand-crafted relaxation methods.

</p>
</details>

<details><summary><b>Online Policy Gradient for Model Free Learning of Linear Quadratic Regulators with $\sqrt{T}$ Regret</b>
<a href="https://arxiv.org/abs/2102.12608">arxiv:2102.12608</a>
&#x1F4C8; 0 <br>
<p>Asaf Cassel, Tomer Koren</p></summary>
<p>

**Abstract:** We consider the task of learning to control a linear dynamical system under fixed quadratic costs, known as the Linear Quadratic Regulator (LQR) problem. While model-free approaches are often favorable in practice, thus far only model-based methods, which rely on costly system identification, have been shown to achieve regret that scales with the optimal dependence on the time horizon T. We present the first model-free algorithm that achieves similar regret guarantees. Our method relies on an efficient policy gradient scheme, and a novel and tighter analysis of the cost of exploration in policy space in this setting.

</p>
</details>

<details><summary><b>Memory-based Deep Reinforcement Learning for POMDPs</b>
<a href="https://arxiv.org/abs/2102.12344">arxiv:2102.12344</a>
&#x1F4C8; 0 <br>
<p>Lingheng Meng, Rob Gorbet, Dana Kulić</p></summary>
<p>

**Abstract:** A promising characteristic of Deep Reinforcement Learning (DRL) is its capability to learn optimal policy in an end-to-end manner without relying on feature engineering. However, most approaches assume a fully observable state space, i.e. fully observable Markov Decision Processes (MDPs). In real-world robotics, this assumption is unpractical, because of issues such as sensor sensitivity limitations and sensor noise, and the lack of knowledge about whether the observation design is complete or not. These scenarios lead to Partially Observable MDPs (POMDPs). In this paper, we propose Long-Short-Term-Memory-based Twin Delayed Deep Deterministic Policy Gradient (LSTM-TD3) by introducing a memory component to TD3, and compare its performance with other DRL algorithms in both MDPs and POMDPs. Our results demonstrate the significant advantages of the memory component in addressing POMDPs, including the ability to handle missing and noisy observation data.

</p>
</details>

<details><summary><b>Set-valued classification -- overview via a unified framework</b>
<a href="https://arxiv.org/abs/2102.12318">arxiv:2102.12318</a>
&#x1F4C8; 0 <br>
<p>Evgenii Chzhen, Christophe Denis, Mohamed Hebiri, Titouan Lorieul</p></summary>
<p>

**Abstract:** Multi-class classification problem is among the most popular and well-studied statistical frameworks. Modern multi-class datasets can be extremely ambiguous and single-output predictions fail to deliver satisfactory performance. By allowing predictors to predict a set of label candidates, set-valued classification offers a natural way to deal with this ambiguity. Several formulations of set-valued classification are available in the literature and each of them leads to different prediction strategies. The present survey aims to review popular formulations using a unified statistical framework. The proposed framework encompasses previously considered and leads to new formulations as well as it allows to understand underlying trade-offs of each formulation. We provide infinite sample optimal set-valued classification strategies and review a general plug-in principle to construct data-driven algorithms. The exposition is supported by examples and pointers to both theoretical and practical contributions. Finally, we provide experiments on real-world datasets comparing these approaches in practice and providing general practical guidelines.

</p>
</details>


{% endraw %}
Prev: [2021.02.23]({{ '/2021/02/23/2021.02.23.html' | relative_url }})  Next: [2021.02.25]({{ '/2021/02/25/2021.02.25.html' | relative_url }})