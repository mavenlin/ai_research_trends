## Summary for 2021-07-24, created on 2021-12-19


<details><summary><b>Stress Test Evaluation of Biomedical Word Embeddings</b>
<a href="https://arxiv.org/abs/2107.11652">arxiv:2107.11652</a>
&#x1F4C8; 6 <br>
<p>Vladimir Araujo, Andr√©s Carvallo, Carlos Aspillaga, Camilo Thorne, Denis Parra</p></summary>
<p>

**Abstract:** The success of pretrained word embeddings has motivated their use in the biomedical domain, with contextualized embeddings yielding remarkable results in several biomedical NLP tasks. However, there is a lack of research on quantifying their behavior under severe "stress" scenarios. In this work, we systematically evaluate three language models with adversarial examples -- automatically constructed tests that allow us to examine how robust the models are. We propose two types of stress scenarios focused on the biomedical named entity recognition (NER) task, one inspired by spelling errors and another based on the use of synonyms for medical terms. Our experiments with three benchmarks show that the performance of the original models decreases considerably, in addition to revealing their weaknesses and strengths. Finally, we show that adversarial training causes the models to improve their robustness and even to exceed the original performance in some cases.

</p>
</details>

<details><summary><b>Efficient inference of interventional distributions</b>
<a href="https://arxiv.org/abs/2107.11712">arxiv:2107.11712</a>
&#x1F4C8; 4 <br>
<p>Arnab Bhattacharyya, Sutanu Gayen, Saravanan Kandasamy, Vedant Raval, N. V. Vinodchandran</p></summary>
<p>

**Abstract:** We consider the problem of efficiently inferring interventional distributions in a causal Bayesian network from a finite number of observations. Let $\mathcal{P}$ be a causal model on a set $\mathbf{V}$ of observable variables on a given causal graph $G$. For sets $\mathbf{X},\mathbf{Y}\subseteq \mathbf{V}$, and setting ${\bf x}$ to $\mathbf{X}$, let $P_{\bf x}(\mathbf{Y})$ denote the interventional distribution on $\mathbf{Y}$ with respect to an intervention ${\bf x}$ to variables ${\bf x}$. Shpitser and Pearl (AAAI 2006), building on the work of Tian and Pearl (AAAI 2001), gave an exact characterization of the class of causal graphs for which the interventional distribution $P_{\bf x}({\mathbf{Y}})$ can be uniquely determined. We give the first efficient version of the Shpitser-Pearl algorithm. In particular, under natural assumptions, we give a polynomial-time algorithm that on input a causal graph $G$ on observable variables $\mathbf{V}$, a setting ${\bf x}$ of a set $\mathbf{X} \subseteq \mathbf{V}$ of bounded size, outputs succinct descriptions of both an evaluator and a generator for a distribution $\hat{P}$ that is $\varepsilon$-close (in total variation distance) to $P_{\bf x}({\mathbf{Y}})$ where $Y=\mathbf{V}\setminus \mathbf{X}$, if $P_{\bf x}(\mathbf{Y})$ is identifiable. We also show that when $\mathbf{Y}$ is an arbitrary set, there is no efficient algorithm that outputs an evaluator of a distribution that is $\varepsilon$-close to $P_{\bf x}({\mathbf{Y}})$ unless all problems that have statistical zero-knowledge proofs, including the Graph Isomorphism problem, have efficient randomized algorithms.

</p>
</details>

<details><summary><b>The USYD-JD Speech Translation System for IWSLT 2021</b>
<a href="https://arxiv.org/abs/2107.11572">arxiv:2107.11572</a>
&#x1F4C8; 4 <br>
<p>Liang Ding, Di Wu, Dacheng Tao</p></summary>
<p>

**Abstract:** This paper describes the University of Sydney& JD's joint submission of the IWSLT 2021 low resource speech translation task. We participated in the Swahili-English direction and got the best scareBLEU (25.3) score among all the participants. Our constrained system is based on a pipeline framework, i.e. ASR and NMT. We trained our models with the officially provided ASR and MT datasets. The ASR system is based on the open-sourced tool Kaldi and this work mainly explores how to make the most of the NMT models. To reduce the punctuation errors generated by the ASR model, we employ our previous work SlotRefine to train a punctuation correction model. To achieve better translation performance, we explored the most recent effective strategies, including back translation, knowledge distillation, multi-feature reranking and transductive finetuning. For model structure, we tried auto-regressive and non-autoregressive models, respectively. In addition, we proposed two novel pre-train approaches, i.e. \textit{de-noising training} and \textit{bidirectional training} to fully exploit the data. Extensive experiments show that adding the above techniques consistently improves the BLEU scores, and the final submission system outperforms the baseline (Transformer ensemble model trained with the original parallel data) by approximately 10.8 BLEU score, achieving the SOTA performance.

</p>
</details>

<details><summary><b>Learning Risk-aware Costmaps for Traversability in Challenging Environments</b>
<a href="https://arxiv.org/abs/2107.11722">arxiv:2107.11722</a>
&#x1F4C8; 3 <br>
<p>David D. Fan, Ali-akbar Agha-mohammadi, Evangelos A. Theodorou</p></summary>
<p>

**Abstract:** One of the main challenges in autonomous robotic exploration and navigation in unknown and unstructured environments is determining where the robot can or cannot safely move. A significant source of difficulty in this determination arises from stochasticity and uncertainty, coming from localization error, sensor sparsity and noise, difficult-to-model robot-ground interactions, and disturbances to the motion of the vehicle. Classical approaches to this problem rely on geometric analysis of the surrounding terrain, which can be prone to modeling errors and can be computationally expensive. Moreover, modeling the distribution of uncertain traversability costs is a difficult task, compounded by the various error sources mentioned above. In this work, we take a principled learning approach to this problem. We introduce a neural network architecture for robustly learning the distribution of traversability costs. Because we are motivated by preserving the life of the robot, we tackle this learning problem from the perspective of learning tail-risks, i.e. the Conditional Value-at-Risk (CVaR). We show that this approach reliably learns the expected tail risk given a desired probability risk threshold between 0 and 1, producing a traversability costmap which is more robust to outliers, more accurately captures tail risks, and is more computationally efficient, when compared against baselines. We validate our method on data collected a legged robot navigating challenging, unstructured environments including an abandoned subway, limestone caves, and lava tube caves.

</p>
</details>

<details><summary><b>Graph Convolutional Network with Generalized Factorized Bilinear Aggregation</b>
<a href="https://arxiv.org/abs/2107.11666">arxiv:2107.11666</a>
&#x1F4C8; 3 <br>
<p>Hao Zhu, Piotr Koniusz</p></summary>
<p>

**Abstract:** Although Graph Convolutional Networks (GCNs) have demonstrated their power in various applications, the graph convolutional layers, as the most important component of GCN, are still using linear transformations and a simple pooling step. In this paper, we propose a novel generalization of Factorized Bilinear (FB) layer to model the feature interactions in GCNs. FB performs two matrix-vector multiplications, that is, the weight matrix is multiplied with the outer product of the vector of hidden features from both sides. However, the FB layer suffers from the quadratic number of coefficients, overfitting and the spurious correlations due to correlations between channels of hidden representations that violate the i.i.d. assumption. Thus, we propose a compact FB layer by defining a family of summarizing operators applied over the quadratic term. We analyze proposed pooling operators and motivate their use. Our experimental results on multiple datasets demonstrate that the GFB-GCN is competitive with other methods for text classification.

</p>
</details>

<details><summary><b>Clustering by Maximizing Mutual Information Across Views</b>
<a href="https://arxiv.org/abs/2107.11635">arxiv:2107.11635</a>
&#x1F4C8; 3 <br>
<p>Kien Do, Truyen Tran, Svetha Venkatesh</p></summary>
<p>

**Abstract:** We propose a novel framework for image clustering that incorporates joint representation learning and clustering. Our method consists of two heads that share the same backbone network - a "representation learning" head and a "clustering" head. The "representation learning" head captures fine-grained patterns of objects at the instance level which serve as clues for the "clustering" head to extract coarse-grain information that separates objects into clusters. The whole model is trained in an end-to-end manner by minimizing the weighted sum of two sample-oriented contrastive losses applied to the outputs of the two heads. To ensure that the contrastive loss corresponding to the "clustering" head is optimal, we introduce a novel critic function called "log-of-dot-product". Extensive experimental results demonstrate that our method significantly outperforms state-of-the-art single-stage clustering methods across a variety of image datasets, improving over the best baseline by about 5-7% in accuracy on CIFAR10/20, STL10, and ImageNet-Dogs. Further, the "two-stage" variant of our method also achieves better results than baselines on three challenging ImageNet subsets.

</p>
</details>

<details><summary><b>A Model-Agnostic Algorithm for Bayes Error Determination in Binary Classification</b>
<a href="https://arxiv.org/abs/2107.11609">arxiv:2107.11609</a>
&#x1F4C8; 3 <br>
<p>Umberto Michelucci, Michela Sperti, Dario Piga, Francesca Venturini, Marco A. Deriu</p></summary>
<p>

**Abstract:** This paper presents the intrinsic limit determination algorithm (ILD Algorithm), a novel technique to determine the best possible performance, measured in terms of the AUC (area under the ROC curve) and accuracy, that can be obtained from a specific dataset in a binary classification problem with categorical features {\sl regardless} of the model used. This limit, namely the Bayes error, is completely independent of any model used and describes an intrinsic property of the dataset. The ILD algorithm thus provides important information regarding the prediction limits of any binary classification algorithm when applied to the considered dataset. In this paper the algorithm is described in detail, its entire mathematical framework is presented and the pseudocode is given to facilitate its implementation. Finally, an example with a real dataset is given.

</p>
</details>

<details><summary><b>Significance of Speaker Embeddings and Temporal Context for Depression Detection</b>
<a href="https://arxiv.org/abs/2107.13969">arxiv:2107.13969</a>
&#x1F4C8; 2 <br>
<p>Sri Harsha Dumpala, Sebastian Rodriguez, Sheri Rempel, Rudolf Uher, Sageev Oore</p></summary>
<p>

**Abstract:** Depression detection from speech has attracted a lot of attention in recent years. However, the significance of speaker-specific information in depression detection has not yet been explored. In this work, we analyze the significance of speaker embeddings for the task of depression detection from speech. Experimental results show that the speaker embeddings provide important cues to achieve state-of-the-art performance in depression detection. We also show that combining conventional OpenSMILE and COVAREP features, which carry complementary information, with speaker embeddings further improves the depression detection performance. The significance of temporal context in the training of deep learning models for depression detection is also analyzed in this paper.

</p>
</details>

<details><summary><b>Invariance-based Multi-Clustering of Latent Space Embeddings for Equivariant Learning</b>
<a href="https://arxiv.org/abs/2107.11717">arxiv:2107.11717</a>
&#x1F4C8; 2 <br>
<p>Chandrajit Bajaj, Avik Roy, Haoran Zhang</p></summary>
<p>

**Abstract:** Variational Autoencoders (VAEs) have been shown to be remarkably effective in recovering model latent spaces for several computer vision tasks. However, currently trained VAEs, for a number of reasons, seem to fall short in learning invariant and equivariant clusters in latent space. Our work focuses on providing solutions to this problem and presents an approach to disentangle equivariance feature maps in a Lie group manifold by enforcing deep, group-invariant learning. Simultaneously implementing a novel separation of semantic and equivariant variables of the latent space representation, we formulate a modified Evidence Lower BOund (ELBO) by using a mixture model pdf like Gaussian mixtures for invariant cluster embeddings that allows superior unsupervised variational clustering. Our experiments show that this model effectively learns to disentangle the invariant and equivariant representations with significant improvements in the learning rate and an observably superior image recognition and canonical state reconstruction compared to the currently best deep learning models.

</p>
</details>

<details><summary><b>Boosting Video Captioning with Dynamic Loss Network</b>
<a href="https://arxiv.org/abs/2107.11707">arxiv:2107.11707</a>
&#x1F4C8; 2 <br>
<p> Nasibullah, Partha Pratim Mohanta</p></summary>
<p>

**Abstract:** Video captioning is one of the challenging problems at the intersection of vision and language, having many real-life applications in video retrieval, video surveillance, assisting visually challenged people, Human-machine interface, and many more. Recent deep learning-based methods have shown promising results but are still on the lower side than other vision tasks (such as image classification, object detection). A significant drawback with existing video captioning methods is that they are optimized over cross-entropy loss function, which is uncorrelated to the de facto evaluation metrics (BLEU, METEOR, CIDER, ROUGE).In other words, cross-entropy is not a proper surrogate of the true loss function for video captioning. This paper addresses the drawback by introducing a dynamic loss network (DLN), which provides an additional feedback signal that directly reflects the evaluation metrics. Our results on Microsoft Research Video Description Corpus (MSVD) and MSR-Video to Text (MSRVTT) datasets outperform previous methods.

</p>
</details>

<details><summary><b>Adversarial training may be a double-edged sword</b>
<a href="https://arxiv.org/abs/2107.11671">arxiv:2107.11671</a>
&#x1F4C8; 2 <br>
<p>Ali Rahmati, Seyed-Mohsen Moosavi-Dezfooli, Huaiyu Dai</p></summary>
<p>

**Abstract:** Adversarial training has been shown as an effective approach to improve the robustness of image classifiers against white-box attacks. However, its effectiveness against black-box attacks is more nuanced. In this work, we demonstrate that some geometric consequences of adversarial training on the decision boundary of deep networks give an edge to certain types of black-box attacks. In particular, we define a metric called robustness gain to show that while adversarial training is an effective method to dramatically improve the robustness in white-box scenarios, it may not provide such a good robustness gain against the more realistic decision-based black-box attacks. Moreover, we show that even the minimal perturbation white-box attacks can converge faster against adversarially-trained neural networks compared to the regular ones.

</p>
</details>

<details><summary><b>Inference of collective Gaussian hidden Markov models</b>
<a href="https://arxiv.org/abs/2107.11662">arxiv:2107.11662</a>
&#x1F4C8; 2 <br>
<p>Rahul Singh, Yongxin Chen</p></summary>
<p>

**Abstract:** We consider inference problems for a class of continuous state collective hidden Markov models, where the data is recorded in aggregate (collective) form generated by a large population of individuals following the same dynamics. We propose an aggregate inference algorithm called collective Gaussian forward-backward algorithm, extending recently proposed Sinkhorn belief propagation algorithm to models characterized by Gaussian densities. Our algorithm enjoys convergence guarantee. In addition, it reduces to the standard Kalman filter when the observations are generated by a single individual. The efficacy of the proposed algorithm is demonstrated through multiple experiments.

</p>
</details>

<details><summary><b>Deep Machine Learning Based Egyptian Vehicle License Plate Recognition Systems</b>
<a href="https://arxiv.org/abs/2107.11640">arxiv:2107.11640</a>
&#x1F4C8; 2 <br>
<p>Mohamed Shehata, Mohamed Taha Abou-Kreisha, Hany Elnashar</p></summary>
<p>

**Abstract:** Automated Vehicle License Plate (VLP) detection and recognition have ended up being a significant research issue as of late. VLP localization and recognition are some of the most essential techniques for managing traffic using digital techniques. In this paper, four smart systems are developed to recognize Egyptian vehicles license plates. Two systems are based on character recognition, which are (System1, Characters Recognition with Classical Machine Learning) and (System2, Characters Recognition with Deep Machine Learning). The other two systems are based on the whole plate recognition which are (System3, Whole License Plate Recognition with Classical Machine Learning) and (System4, Whole License Plate Recognition with Deep Machine Learning). We use object detection algorithms, and machine learning based object recognition algorithms. The performance of the developed systems has been tested on real images, and the experimental results demonstrate that the best detection accuracy rate for VLP is provided by using the deep learning method. Where the VLP detection accuracy rate is better than the classical system by 32%. However, the best detection accuracy rate for Vehicle License Plate Arabic Character (VLPAC) is provided by using the classical method. Where VLPAC detection accuracy rate is better than the deep learning-based system by 6%. Also, the results show that deep learning is better than the classical technique used in VLP recognition processes. Where the recognition accuracy rate is better than the classical system by 8%. Finally, the paper output recommends a robust VLP recognition system based on both statistical and deep machine learning.

</p>
</details>

<details><summary><b>Detecting Adversarial Examples Is (Nearly) As Hard As Classifying Them</b>
<a href="https://arxiv.org/abs/2107.11630">arxiv:2107.11630</a>
&#x1F4C8; 2 <br>
<p>Florian Tram√®r</p></summary>
<p>

**Abstract:** Making classifiers robust to adversarial examples is hard. Thus, many defenses tackle the seemingly easier task of detecting perturbed inputs. We show a barrier towards this goal. We prove a general hardness reduction between detection and classification of adversarial examples: given a robust detector for attacks at distance Œµ (in some metric), we can build a similarly robust (but inefficient) classifier for attacks at distance Œµ/2. Our reduction is computationally inefficient, and thus cannot be used to build practical classifiers. Instead, it is a useful sanity check to test whether empirical detection results imply something much stronger than the authors presumably anticipated. To illustrate, we revisit 13 detector defenses. For 11/13 cases, we show that the claimed detection results would imply an inefficient classifier with robustness far beyond the state-of-the-art.

</p>
</details>

<details><summary><b>Accelerating Atmospheric Turbulence Simulation via Learned Phase-to-Space Transform</b>
<a href="https://arxiv.org/abs/2107.11627">arxiv:2107.11627</a>
&#x1F4C8; 2 <br>
<p>Zhiyuan Mao, Nicholas Chimitt, Stanley H. Chan</p></summary>
<p>

**Abstract:** Fast and accurate simulation of imaging through atmospheric turbulence is essential for developing turbulence mitigation algorithms. Recognizing the limitations of previous approaches, we introduce a new concept known as the phase-to-space (P2S) transform to significantly speed up the simulation. P2S is build upon three ideas: (1) reformulating the spatially varying convolution as a set of invariant convolutions with basis functions, (2) learning the basis function via the known turbulence statistics models, (3) implementing the P2S transform via a light-weight network that directly convert the phase representation to spatial representation. The new simulator offers 300x -- 1000x speed up compared to the mainstream split-step simulators while preserving the essential turbulence statistics.

</p>
</details>

<details><summary><b>FedLab: A Flexible Federated Learning Framework</b>
<a href="https://arxiv.org/abs/2107.11621">arxiv:2107.11621</a>
&#x1F4C8; 2 <br>
<p>Dun Zeng, Siqi Liang, Xiangjing Hu, Zenglin Xu</p></summary>
<p>

**Abstract:** Federated learning (FL) is a machine learning field in which researchers try to facilitate model learning process among multiparty without violating privacy protection regulations. Considerable effort has been invested in FL optimization and communication related researches. In this work, we introduce FedLab, a lightweight open-source framework for FL simulation. The design of FedLab focuses on FL algorithm effectiveness and communication efficiency. Also, FedLab is scalable in different deployment scenario. We hope FedLab could provide flexible API as well as reliable baseline implementations, and relieve the burden of implementing novel approaches for researchers in FL community.

</p>
</details>

<details><summary><b>Automatic tempered posterior distributions for Bayesian inversion problems</b>
<a href="https://arxiv.org/abs/2107.11614">arxiv:2107.11614</a>
&#x1F4C8; 2 <br>
<p>L. Martino, F. Llorente, E. Curbelo, J. Lopez-Santiago, J. Miguez</p></summary>
<p>

**Abstract:** We propose a novel adaptive importance sampling scheme for Bayesian inversion problems where the inference of the variables of interest and the power of the data noise is split. More specifically, we consider a Bayesian analysis for the variables of interest (i.e., the parameters of the model to invert), whereas we employ a maximum likelihood approach for the estimation of the noise power. The whole technique is implemented by means of an iterative procedure, alternating sampling and optimization steps. Moreover, the noise power is also used as a tempered parameter for the posterior distribution of the the variables of interest. Therefore, a sequence of tempered posterior densities is generated, where the tempered parameter is automatically selected according to the actual estimation of the noise power. A complete Bayesian study over the model parameters and the scale parameter can be also performed. Numerical experiments show the benefits of the proposed approach.

</p>
</details>

<details><summary><b>Combining Graph Neural Networks with Expert Knowledge for Smart Contract Vulnerability Detection</b>
<a href="https://arxiv.org/abs/2107.11598">arxiv:2107.11598</a>
&#x1F4C8; 2 <br>
<p>Zhenguang Liu, Peng Qian, Xiaoyang Wang, Yuan Zhuang, Lin Qiu, Xun Wang</p></summary>
<p>

**Abstract:** Smart contract vulnerability detection draws extensive attention in recent years due to the substantial losses caused by hacker attacks. Existing efforts for contract security analysis heavily rely on rigid rules defined by experts, which are labor-intensive and non-scalable. More importantly, expert-defined rules tend to be error-prone and suffer the inherent risk of being cheated by crafty attackers. Recent researches focus on the symbolic execution and formal analysis of smart contracts for vulnerability detection, yet to achieve a precise and scalable solution. Although several methods have been proposed to detect vulnerabilities in smart contracts, there is still a lack of effort that considers combining expert-defined security patterns with deep neural networks. In this paper, we explore using graph neural networks and expert knowledge for smart contract vulnerability detection. Specifically, we cast the rich control- and data- flow semantics of the source code into a contract graph. To highlight the critical nodes in the graph, we further design a node elimination phase to normalize the graph. Then, we propose a novel temporal message propagation network to extract the graph feature from the normalized graph, and combine the graph feature with designed expert patterns to yield a final detection system. Extensive experiments are conducted on all the smart contracts that have source code in Ethereum and VNT Chain platforms. Empirical results show significant accuracy improvements over the state-of-the-art methods on three types of vulnerabilities, where the detection accuracy of our method reaches 89.15%, 89.02%, and 83.21% for reentrancy, timestamp dependence, and infinite loop vulnerabilities, respectively.

</p>
</details>

<details><summary><b>Two Headed Dragons: Multimodal Fusion and Cross Modal Transactions</b>
<a href="https://arxiv.org/abs/2107.11585">arxiv:2107.11585</a>
&#x1F4C8; 2 <br>
<p>Rupak Bose, Shivam Pande, Biplab Banerjee</p></summary>
<p>

**Abstract:** As the field of remote sensing is evolving, we witness the accumulation of information from several modalities, such as multispectral (MS), hyperspectral (HSI), LiDAR etc. Each of these modalities possess its own distinct characteristics and when combined synergistically, perform very well in the recognition and classification tasks. However, fusing multiple modalities in remote sensing is cumbersome due to highly disparate domains. Furthermore, the existing methods do not facilitate cross-modal interactions. To this end, we propose a novel transformer based fusion method for HSI and LiDAR modalities. The model is composed of stacked auto encoders that harness the cross key-value pairs for HSI and LiDAR, thus establishing a communication between the two modalities, while simultaneously using the CNNs to extract the spectral and spatial information from HSI and LiDAR. We test our model on Houston (Data Fusion Contest - 2013) and MUUFL Gulfport datasets and achieve competitive results.

</p>
</details>

<details><summary><b>Reconstructing Images of Two Adjacent Objects through Scattering Medium Using Generative Adversarial Network</b>
<a href="https://arxiv.org/abs/2107.11574">arxiv:2107.11574</a>
&#x1F4C8; 2 <br>
<p>Xuetian Lai, Qiongyao Li, Ziyang Chen, Xiaopeng Shao, Jixiong Pu</p></summary>
<p>

**Abstract:** Reconstruction of image by using convolutional neural networks (CNNs) has been vigorously studied in the last decade. Until now, there have being developed several techniques for imaging of a single object through scattering medium by using neural networks, however how to reconstruct images of more than one object simultaneously seems hard to realize. In this paper, we demonstrate an approach by using generative adversarial network (GAN) to reconstruct images of two adjacent objects through scattering media. We construct an imaging system for imaging of two adjacent objects behind the scattering media. In general, as the light field of two adjacent object images pass through the scattering slab, a speckle pattern is obtained. The designed adversarial network, which is called as YGAN, is employed to reconstruct the images simultaneously. It is shown that based on the trained YGAN, we can reconstruct images of two adjacent objects from one speckle pattern with high fidelity. In addition, we study the influence of the object image types, and the distance between the two adjacent objects on the fidelity of the reconstructed images. Moreover even if another scattering medium is inserted between the two objects, we can also reconstruct the images of two objects from a speckle with high quality. The technique presented in this work can be used for applications in areas of medical image analysis, such as medical image classification, segmentation, and studies of multi-object scattering imaging etc.

</p>
</details>

<details><summary><b>Combining Online Learning and Offline Learning for Contextual Bandits with Deficient Support</b>
<a href="https://arxiv.org/abs/2107.11533">arxiv:2107.11533</a>
&#x1F4C8; 2 <br>
<p>Hung Tran-The, Sunil Gupta, Thanh Nguyen-Tang, Santu Rana, Svetha Venkatesh</p></summary>
<p>

**Abstract:** We address policy learning with logged data in contextual bandits. Current offline-policy learning algorithms are mostly based on inverse propensity score (IPS) weighting requiring the logging policy to have \emph{full support} i.e. a non-zero probability for any context/action of the evaluation policy. However, many real-world systems do not guarantee such logging policies, especially when the action space is large and many actions have poor or missing rewards. With such \emph{support deficiency}, the offline learning fails to find optimal policies. We propose a novel approach that uses a hybrid of offline learning with online exploration. The online exploration is used to explore unsupported actions in the logged data whilst offline learning is used to exploit supported actions from the logged data avoiding unnecessary explorations. Our approach determines an optimal policy with theoretical guarantees using the minimal number of online explorations. We demonstrate our algorithms' effectiveness empirically on a diverse collection of datasets.

</p>
</details>

<details><summary><b>Modifications of FastICA in Convolutive Blind Source Separation</b>
<a href="https://arxiv.org/abs/2107.14135">arxiv:2107.14135</a>
&#x1F4C8; 1 <br>
<p>YunPeng Li</p></summary>
<p>

**Abstract:** Convolutive blind source separation (BSS) is intended to recover the unknown components from their convolutive mixtures. Contrary to the contrast functions used in instantaneous cases, the spatial-temporal prewhitening stage and the para-unitary filters constraint are difficult to implement in a convolutive context. In this paper, we propose several modifications of FastICA to alleviate these difficulties. Our method performs the simple prewhitening step on convolutive mixtures prior to the separation and optimizes the contrast function under the diagonalization constraint implemented by single value decomposition (SVD). Numerical simulations are implemented to verify the performance of the proposed method.

</p>
</details>

<details><summary><b>A Real Use Case of Semi-Supervised Learning for Mammogram Classification in a Local Clinic of Costa Rica</b>
<a href="https://arxiv.org/abs/2107.11696">arxiv:2107.11696</a>
&#x1F4C8; 1 <br>
<p>Saul Calderon-Ramirez, Diego Murillo-Hernandez, Kevin Rojas-Salazar, David Elizondo, Shengxiang Yang, Miguel Molina-Cabello</p></summary>
<p>

**Abstract:** The implementation of deep learning based computer aided diagnosis systems for the classification of mammogram images can help in improving the accuracy, reliability, and cost of diagnosing patients. However, training a deep learning model requires a considerable amount of labeled images, which can be expensive to obtain as time and effort from clinical practitioners is required. A number of publicly available datasets have been built with data from different hospitals and clinics. However, using models trained on these datasets for later work on images sampled from a different hospital or clinic might result in lower performance. This is due to the distribution mismatch of the datasets, which include different patient populations and image acquisition protocols. The scarcity of labeled data can also bring a challenge towards the application of transfer learning with models trained using these source datasets. In this work, a real world scenario is evaluated where a novel target dataset sampled from a private Costa Rican clinic is used, with few labels and heavily imbalanced data. The use of two popular and publicly available datasets (INbreast and CBIS-DDSM) as source data, to train and test the models on the novel target dataset, is evaluated. The use of the semi-supervised deep learning approach known as MixMatch, to leverage the usage of unlabeled data from the target dataset, is proposed and evaluated. In the tests, the performance of models is extensively measured, using different metrics to assess the performance of a classifier under heavy data imbalance conditions. It is shown that the use of semi-supervised deep learning combined with fine-tuning can provide a meaningful advantage when using scarce labeled observations. We make available the novel dataset for the benefit of the community.

</p>
</details>

<details><summary><b>Efficient QUBO transformation for Higher Degree Pseudo Boolean Functions</b>
<a href="https://arxiv.org/abs/2107.11695">arxiv:2107.11695</a>
&#x1F4C8; 1 <br>
<p>Amit Verma, Mark Lewis, Gary Kochenberger</p></summary>
<p>

**Abstract:** Quadratic Unconstrained Binary Optimization (QUBO) is recognized as a unifying framework for modeling a wide range of problems. Problems can be solved with commercial solvers customized for solving QUBO and since QUBO have degree two, it is useful to have a method for transforming higher degree pseudo-Boolean problems to QUBO format. The standard transformation approach requires additional auxiliary variables supported by penalty terms for each higher degree term. This paper improves on the existing cubic-to-quadratic transformation approach by minimizing the number of additional variables as well as penalty coefficient. Extensive experimental testing on Max 3-SAT modeled as QUBO shows a near 100% reduction in the subproblem size used for minimization of the number of auxiliary variables.

</p>
</details>

<details><summary><b>Deep-learning-driven Reliable Single-pixel Imaging with Uncertainty Approximation</b>
<a href="https://arxiv.org/abs/2107.11678">arxiv:2107.11678</a>
&#x1F4C8; 1 <br>
<p>Ruibo Shang, Mikaela A. O'Brien, Geoffrey P. Luke</p></summary>
<p>

**Abstract:** Single-pixel imaging (SPI) has the advantages of high-speed acquisition over a broad wavelength range and system compactness, which are difficult to achieve by conventional imaging sensors. However, a common challenge is low image quality arising from undersampling. Deep learning (DL) is an emerging and powerful tool in computational imaging for many applications and researchers have applied DL in SPI to achieve higher image quality than conventional reconstruction approaches. One outstanding challenge, however, is that the accuracy of DL predictions in SPI cannot be assessed in practical applications where the ground truths are unknown. Here, we propose the use of the Bayesian convolutional neural network (BCNN) to approximate the uncertainty (coming from finite training data and network model) of the DL predictions in SPI. Each pixel in the predicted result from BCNN represents the parameter of a probability distribution rather than the image intensity value. Then, the uncertainty can be approximated with BCNN by minimizing a negative log-likelihood loss function in the training stage and Monte Carlo dropout in the prediction stage. The results show that the BCNN can reliably approximate the uncertainty of the DL predictions in SPI with varying compression ratios and noise levels. The predicted uncertainty from BCNN in SPI reveals that most of the reconstruction errors in deep-learning-based SPI come from the edges of the image features. The results show that the proposed BCNN can provide a reliable tool to approximate the uncertainty of DL predictions in SPI and can be widely used in many applications of SPI.

</p>
</details>

<details><summary><b>Tail of Distribution GAN (TailGAN): Generative- Adversarial-Network-Based Boundary Formation</b>
<a href="https://arxiv.org/abs/2107.11658">arxiv:2107.11658</a>
&#x1F4C8; 1 <br>
<p>Nikolaos Dionelis</p></summary>
<p>

**Abstract:** Generative Adversarial Networks (GAN) are a powerful methodology and can be used for unsupervised anomaly detection, where current techniques have limitations such as the accurate detection of anomalies near the tail of a distribution. GANs generally do not guarantee the existence of a probability density and are susceptible to mode collapse, while few GANs use likelihood to reduce mode collapse. In this paper, we create a GAN-based tail formation model for anomaly detection, the Tail of distribution GAN (TailGAN), to generate samples on the tail of the data distribution and detect anomalies near the support boundary. Using TailGAN, we leverage GANs for anomaly detection and use maximum entropy regularization. Using GANs that learn the probability of the underlying distribution has advantages in improving the anomaly detection methodology by allowing us to devise a generator for boundary samples, and use this model to characterize anomalies. TailGAN addresses supports with disjoint components and achieves competitive performance on images. We evaluate TailGAN for identifying Out-of-Distribution (OoD) data and its performance evaluated on MNIST, CIFAR-10, Baggage X-Ray, and OoD data shows competitiveness compared to methods from the literature.

</p>
</details>

<details><summary><b>Dual-Attention Enhanced BDense-UNet for Liver Lesion Segmentation</b>
<a href="https://arxiv.org/abs/2107.11645">arxiv:2107.11645</a>
&#x1F4C8; 1 <br>
<p>Wenming Cao, Philip L. H. Yu, Gilbert C. S. Lui, Keith W. H. Chiu, Ho-Ming Cheng, Yanwen Fang, Man-Fung Yuen, Wai-Kay Seto</p></summary>
<p>

**Abstract:** In this work, we propose a new segmentation network by integrating DenseUNet and bidirectional LSTM together with attention mechanism, termed as DA-BDense-UNet. DenseUNet allows learning enough diverse features and enhancing the representative power of networks by regulating the information flow. Bidirectional LSTM is responsible to explore the relationships between the encoded features and the up-sampled features in the encoding and decoding paths. Meanwhile, we introduce attention gates (AG) into DenseUNet to diminish responses of unrelated background regions and magnify responses of salient regions progressively. Besides, the attention in bidirectional LSTM takes into account the contribution differences of the encoded features and the up-sampled features in segmentation improvement, which can in turn adjust proper weights for these two kinds of features. We conduct experiments on liver CT image data sets collected from multiple hospitals by comparing them with state-of-the-art segmentation models. Experimental results indicate that our proposed method DA-BDense-UNet has achieved comparative performance in terms of dice coefficient, which demonstrates its effectiveness.

</p>
</details>

<details><summary><b>Accelerating Federated Edge Learning via Optimized Probabilistic Device Scheduling</b>
<a href="https://arxiv.org/abs/2107.11588">arxiv:2107.11588</a>
&#x1F4C8; 1 <br>
<p>Maojun Zhang, Guangxu Zhu, Shuai Wang, Jiamo Jiang, Caijun Zhong, Shuguang Cui</p></summary>
<p>

**Abstract:** The popular federated edge learning (FEEL) framework allows privacy-preserving collaborative model training via frequent learning-updates exchange between edge devices and server. Due to the constrained bandwidth, only a subset of devices can upload their updates at each communication round. This has led to an active research area in FEEL studying the optimal device scheduling policy for minimizing communication time. However, owing to the difficulty in quantifying the exact communication time, prior work in this area can only tackle the problem partially by considering either the communication rounds or per-round latency, while the total communication time is determined by both metrics. To close this gap, we make the first attempt in this paper to formulate and solve the communication time minimization problem. We first derive a tight bound to approximate the communication time through cross-disciplinary effort involving both learning theory for convergence analysis and communication theory for per-round latency analysis. Building on the analytical result, an optimized probabilistic scheduling policy is derived in closed-form by solving the approximate communication time minimization problem. It is found that the optimized policy gradually turns its priority from suppressing the remaining communication rounds to reducing per-round latency as the training process evolves. The effectiveness of the proposed scheme is demonstrated via a use case on collaborative 3D objective detection in autonomous driving.

</p>
</details>


[Next Page]({{ '/2021/07/23/2021.07.23.html' | relative_url }})
