## Summary for 2021-10-25, created on 2021-12-14


<details><summary><b>Parameter Prediction for Unseen Deep Architectures</b>
<a href="https://arxiv.org/abs/2110.13100">arxiv:2110.13100</a>
&#x1F4C8; 253 <br>
<p>Boris Knyazev, Michal Drozdzal, Graham W. Taylor, Adriana Romero-Soriano</p></summary>
<p>

**Abstract:** Deep learning has been successful in automating the design of features in machine learning pipelines. However, the algorithms optimizing neural network parameters remain largely hand-designed and computationally inefficient. We study if we can use deep learning to directly predict these parameters by exploiting the past knowledge of training other networks. We introduce a large-scale dataset of diverse computational graphs of neural architectures - DeepNets-1M - and use it to explore parameter prediction on CIFAR-10 and ImageNet. By leveraging advances in graph neural networks, we propose a hypernetwork that can predict performant parameters in a single forward pass taking a fraction of a second, even on a CPU. The proposed model achieves surprisingly good performance on unseen and diverse networks. For example, it is able to predict all 24 million parameters of a ResNet-50 achieving a 60% accuracy on CIFAR-10. On ImageNet, top-5 accuracy of some of our networks approaches 50%. Our task along with the model and results can potentially lead to a new, more computationally efficient paradigm of training networks. Our model also learns a strong representation of neural architectures enabling their analysis.

</p>
</details>

<details><summary><b>The Efficiency Misnomer</b>
<a href="https://arxiv.org/abs/2110.12894">arxiv:2110.12894</a>
&#x1F4C8; 106 <br>
<p>Mostafa Dehghani, Anurag Arnab, Lucas Beyer, Ashish Vaswani, Yi Tay</p></summary>
<p>

**Abstract:** Model efficiency is a critical aspect of developing and deploying machine learning models. Inference time and latency directly affect the user experience, and some applications have hard requirements. In addition to inference costs, model training also have direct financial and environmental impacts. Although there are numerous well-established metrics (cost indicators) for measuring model efficiency, researchers and practitioners often assume that these metrics are correlated with each other and report only few of them. In this paper, we thoroughly discuss common cost indicators, their advantages and disadvantages, and how they can contradict each other. We demonstrate how incomplete reporting of cost indicators can lead to partial conclusions and a blurred or incomplete picture of the practical considerations of different models. We further present suggestions to improve reporting of efficiency metrics.

</p>
</details>

<details><summary><b>Variational Gaussian Processes: A Functional Analysis View</b>
<a href="https://arxiv.org/abs/2110.12798">arxiv:2110.12798</a>
&#x1F4C8; 81 <br>
<p>Veit Wild, George Wynne</p></summary>
<p>

**Abstract:** Variational Gaussian process (GP) approximations have become a standard tool in fast GP inference. This technique requires a user to select variational features to increase efficiency. So far the common choices in the literature are disparate and lacking generality. We propose to view the GP as lying in a Banach space which then facilitates a unified perspective. This is used to understand the relationship between existing features and to draw a connection between kernel ridge regression and variational GP approximations.

</p>
</details>

<details><summary><b>Deep Learning Tools for Audacity: Helping Researchers Expand the Artist's Toolkit</b>
<a href="https://arxiv.org/abs/2110.13323">arxiv:2110.13323</a>
&#x1F4C8; 68 <br>
<p>Hugo Flores Garcia, Aldo Aguilar, Ethan Manilow, Dmitry Vedenko, Bryan Pardo</p></summary>
<p>

**Abstract:** We present a software framework that integrates neural networks into the popular open-source audio editing software, Audacity, with a minimal amount of developer effort. In this paper, we showcase some example use cases for both end-users and neural network developers. We hope that this work fosters a new level of interactivity between deep learning practitioners and end-users.

</p>
</details>

<details><summary><b>Self-Consistent Models and Values</b>
<a href="https://arxiv.org/abs/2110.12840">arxiv:2110.12840</a>
&#x1F4C8; 67 <br>
<p>Gregory Farquhar, Kate Baumli, Zita Marinho, Angelos Filos, Matteo Hessel, Hado van Hasselt, David Silver</p></summary>
<p>

**Abstract:** Learned models of the environment provide reinforcement learning (RL) agents with flexible ways of making predictions about the environment. In particular, models enable planning, i.e. using more computation to improve value functions or policies, without requiring additional environment interactions. In this work, we investigate a way of augmenting model-based RL, by additionally encouraging a learned model and value function to be jointly \emph{self-consistent}. Our approach differs from classic planning methods such as Dyna, which only update values to be consistent with the model. We propose multiple self-consistency updates, evaluate these in both tabular and function approximation settings, and find that, with appropriate choices, self-consistency helps both policy evaluation and control.

</p>
</details>

<details><summary><b>Unsupervised Source Separation By Steering Pretrained Music Models</b>
<a href="https://arxiv.org/abs/2110.13071">arxiv:2110.13071</a>
&#x1F4C8; 26 <br>
<p>Ethan Manilow, Patrick O'Reilly, Prem Seetharaman, Bryan Pardo</p></summary>
<p>

**Abstract:** We showcase an unsupervised method that repurposes deep models trained for music generation and music tagging for audio source separation, without any retraining. An audio generation model is conditioned on an input mixture, producing a latent encoding of the audio used to generate audio. This generated audio is fed to a pretrained music tagger that creates source labels. The cross-entropy loss between the tag distribution for the generated audio and a predefined distribution for an isolated source is used to guide gradient ascent in the (unchanging) latent space of the generative model. This system does not update the weights of the generative model or the tagger, and only relies on moving through the generative model's latent space to produce separated sources. We use OpenAI's Jukebox as the pretrained generative model, and we couple it with four kinds of pretrained music taggers (two architectures and two tagging datasets). Experimental results on two source separation datasets, show this approach can produce separation estimates for a wider variety of sources than any tested supervised or unsupervised system. This work points to the vast and heretofore untapped potential of large pretrained music models for audio-to-audio tasks like source separation.

</p>
</details>

<details><summary><b>Minimizing Energy Consumption Leads to the Emergence of Gaits in Legged Robots</b>
<a href="https://arxiv.org/abs/2111.01674">arxiv:2111.01674</a>
&#x1F4C8; 23 <br>
<p>Zipeng Fu, Ashish Kumar, Jitendra Malik, Deepak Pathak</p></summary>
<p>

**Abstract:** Legged locomotion is commonly studied and expressed as a discrete set of gait patterns, like walk, trot, gallop, which are usually treated as given and pre-programmed in legged robots for efficient locomotion at different speeds. However, fixing a set of pre-programmed gaits limits the generality of locomotion. Recent animal motor studies show that these conventional gaits are only prevalent in ideal flat terrain conditions while real-world locomotion is unstructured and more like bouts of intermittent steps. What principles could lead to both structured and unstructured patterns across mammals and how to synthesize them in robots? In this work, we take an analysis-by-synthesis approach and learn to move by minimizing mechanical energy. We demonstrate that learning to minimize energy consumption plays a key role in the emergence of natural locomotion gaits at different speeds in real quadruped robots. The emergent gaits are structured in ideal terrains and look similar to that of horses and sheep. The same approach leads to unstructured gaits in rough terrains which is consistent with the findings in animal motor control. We validate our hypothesis in both simulation and real hardware across natural terrains. Videos at https://energy-locomotion.github.io

</p>
</details>

<details><summary><b>Quantum machine learning beyond kernel methods</b>
<a href="https://arxiv.org/abs/2110.13162">arxiv:2110.13162</a>
&#x1F4C8; 22 <br>
<p>Sofiene Jerbi, Lukas J. Fiderer, Hendrik Poulsen Nautrup, Jonas M. K체bler, Hans J. Briegel, Vedran Dunjko</p></summary>
<p>

**Abstract:** With noisy intermediate-scale quantum computers showing great promise for near-term applications, a number of machine learning algorithms based on parametrized quantum circuits have been suggested as possible means to achieve learning advantages. Yet, our understanding of how these quantum machine learning models compare, both to existing classical models and to each other, remains limited. A big step in this direction has been made by relating them to so-called kernel methods from classical machine learning. By building on this connection, previous works have shown that a systematic reformulation of many quantum machine learning models as kernel models was guaranteed to improve their training performance. In this work, we first extend the applicability of this result to a more general family of parametrized quantum circuit models called data re-uploading circuits. Secondly, we show, through simple constructions and numerical simulations, that models defined and trained variationally can exhibit a critically better generalization performance than their kernel formulations, which is the true figure of merit of machine learning tasks. Our results constitute another step towards a more comprehensive theory of quantum machine learning models next to kernel formulations.

</p>
</details>

<details><summary><b>What Would Jiminy Cricket Do? Towards Agents That Behave Morally</b>
<a href="https://arxiv.org/abs/2110.13136">arxiv:2110.13136</a>
&#x1F4C8; 15 <br>
<p>Dan Hendrycks, Mantas Mazeika, Andy Zou, Sahil Patel, Christine Zhu, Jesus Navarro, Dawn Song, Bo Li, Jacob Steinhardt</p></summary>
<p>

**Abstract:** When making everyday decisions, people are guided by their conscience, an internal sense of right and wrong. By contrast, artificial agents are currently not endowed with a moral sense. As a consequence, they may learn to behave immorally when trained on environments that ignore moral concerns, such as violent video games. With the advent of generally capable agents that pretrain on many environments, it will become necessary to mitigate inherited biases from environments that teach immoral behavior. To facilitate the development of agents that avoid causing wanton harm, we introduce Jiminy Cricket, an environment suite of 25 text-based adventure games with thousands of diverse, morally salient scenarios. By annotating every possible game state, the Jiminy Cricket environments robustly evaluate whether agents can act morally while maximizing reward. Using models with commonsense moral knowledge, we create an elementary artificial conscience that assesses and guides agents. In extensive experiments, we find that the artificial conscience approach can steer agents towards moral behavior without sacrificing performance.

</p>
</details>

<details><summary><b>Seeing biodiversity: perspectives in machine learning for wildlife conservation</b>
<a href="https://arxiv.org/abs/2110.12951">arxiv:2110.12951</a>
&#x1F4C8; 15 <br>
<p>Devis Tuia, Benjamin Kellenberger, Sara Beery, Blair R. Costelloe, Silvia Zuffi, Benjamin Risse, Alexander Mathis, Mackenzie W. Mathis, Frank van Langevelde, Tilo Burghardt, Roland Kays, Holger Klinck, Martin Wikelski, Iain D. Couzin, Grant van Horn, Margaret C. Crofoot, Charles V. Stewart, Tanya Berger-Wolf</p></summary>
<p>

**Abstract:** Data acquisition in animal ecology is rapidly accelerating due to inexpensive and accessible sensors such as smartphones, drones, satellites, audio recorders and bio-logging devices. These new technologies and the data they generate hold great potential for large-scale environmental monitoring and understanding, but are limited by current data processing approaches which are inefficient in how they ingest, digest, and distill data into relevant information. We argue that machine learning, and especially deep learning approaches, can meet this analytic challenge to enhance our understanding, monitoring capacity, and conservation of wildlife species. Incorporating machine learning into ecological workflows could improve inputs for population and behavior models and eventually lead to integrated hybrid modeling tools, with ecological models acting as constraints for machine learning models and the latter providing data-supported insights. In essence, by combining new machine learning approaches with ecological domain knowledge, animal ecologists can capitalize on the abundance of data generated by modern sensor technologies in order to reliably estimate population abundances, study animal behavior and mitigate human/wildlife conflicts. To succeed, this approach will require close collaboration and cross-disciplinary education between the computer science and animal ecology communities in order to ensure the quality of machine learning approaches and train a new generation of data scientists in ecology and conservation.

</p>
</details>

<details><summary><b>Identifying and Benchmarking Natural Out-of-Context Prediction Problems</b>
<a href="https://arxiv.org/abs/2110.13223">arxiv:2110.13223</a>
&#x1F4C8; 10 <br>
<p>David Madras, Richard Zemel</p></summary>
<p>

**Abstract:** Deep learning systems frequently fail at out-of-context (OOC) prediction, the problem of making reliable predictions on uncommon or unusual inputs or subgroups of the training distribution. To this end, a number of benchmarks for measuring OOC performance have recently been introduced. In this work, we introduce a framework unifying the literature on OOC performance measurement, and demonstrate how rich auxiliary information can be leveraged to identify candidate sets of OOC examples in existing datasets. We present NOOCh: a suite of naturally-occurring "challenge sets", and show how varying notions of context can be used to probe specific OOC failure modes. Experimentally, we explore the tradeoffs between various learning approaches on these challenge sets and demonstrate how the choices made in designing OOC benchmarks can yield varying conclusions.

</p>
</details>

<details><summary><b>History Aware Multimodal Transformer for Vision-and-Language Navigation</b>
<a href="https://arxiv.org/abs/2110.13309">arxiv:2110.13309</a>
&#x1F4C8; 8 <br>
<p>Shizhe Chen, Pierre-Louis Guhur, Cordelia Schmid, Ivan Laptev</p></summary>
<p>

**Abstract:** Vision-and-language navigation (VLN) aims to build autonomous visual agents that follow instructions and navigate in real scenes. To remember previously visited locations and actions taken, most approaches to VLN implement memory using recurrent states. Instead, we introduce a History Aware Multimodal Transformer (HAMT) to incorporate a long-horizon history into multimodal decision making. HAMT efficiently encodes all the past panoramic observations via a hierarchical vision transformer (ViT), which first encodes individual images with ViT, then models spatial relation between images in a panoramic observation and finally takes into account temporal relation between panoramas in the history. It, then, jointly combines text, history and current observation to predict the next action. We first train HAMT end-to-end using several proxy tasks including single step action prediction and spatial relation prediction, and then use reinforcement learning to further improve the navigation policy. HAMT achieves new state of the art on a broad range of VLN tasks, including VLN with fine-grained instructions (R2R, RxR), high-level instructions (R2R-Last, REVERIE), dialogs (CVDN) as well as long-horizon VLN (R4R, R2R-Back). We demonstrate HAMT to be particularly effective for navigation tasks with longer trajectories.

</p>
</details>

<details><summary><b>IconQA: A New Benchmark for Abstract Diagram Understanding and Visual Language Reasoning</b>
<a href="https://arxiv.org/abs/2110.13214">arxiv:2110.13214</a>
&#x1F4C8; 8 <br>
<p>Pan Lu, Liang Qiu, Jiaqi Chen, Tony Xia, Yizhou Zhao, Wei Zhang, Zhou Yu, Xiaodan Liang, Song-Chun Zhu</p></summary>
<p>

**Abstract:** Current visual question answering (VQA) tasks mainly consider answering human-annotated questions for natural images. However, aside from natural images, abstract diagrams with semantic richness are still understudied in visual understanding and reasoning research. In this work, we introduce a new challenge of Icon Question Answering (IconQA) with the goal of answering a question in an icon image context. We release IconQA, a large-scale dataset that consists of 107,439 questions and three sub-tasks: multi-image-choice, multi-text-choice, and filling-in-the-blank. The IconQA dataset is inspired by real-world diagram word problems that highlight the importance of abstract diagram understanding and comprehensive cognitive reasoning. Thus, IconQA requires not only perception skills like object recognition and text understanding, but also diverse cognitive reasoning skills, such as geometric reasoning, commonsense reasoning, and arithmetic reasoning. To facilitate potential IconQA models to learn semantic representations for icon images, we further release an icon dataset Icon645 which contains 645,687 colored icons on 377 classes. We conduct extensive user studies and blind experiments and reproduce a wide range of advanced VQA methods to benchmark the IconQA task. Also, we develop a strong IconQA baseline Patch-TRM that applies a pyramid cross-modal Transformer with input diagram embeddings pre-trained on the icon dataset. IconQA and Icon645 are available at https://iconqa.github.io.

</p>
</details>

<details><summary><b>Transportation Scenario Planning with Graph Neural Networks</b>
<a href="https://arxiv.org/abs/2110.13202">arxiv:2110.13202</a>
&#x1F4C8; 8 <br>
<p>Ana Alice Peregrino, Soham Pradhan, Zhicheng Liu, Nivan Ferreira, Fabio Miranda</p></summary>
<p>

**Abstract:** Providing efficient human mobility services and infrastructure is one of the major concerns of most mid-sized to large cities around the world. A proper understanding of the dynamics of commuting flows is, therefore, a requisite to better plan urban areas. In this context, an important task is to study hypothetical scenarios in which possible future changes are evaluated. For instance, how the increase in residential units or transportation modes in a neighborhood will change the commuting flows to or from that region? In this paper, we propose to leverage GMEL, a recently introduced graph neural network model, to evaluate changes in commuting flows taking into account different land use and infrastructure scenarios. We validate the usefulness of our methodology through real-world case studies set in two large cities in Brazil.

</p>
</details>

<details><summary><b>Towards Realistic Market Simulations: a Generative Adversarial Networks Approach</b>
<a href="https://arxiv.org/abs/2110.13287">arxiv:2110.13287</a>
&#x1F4C8; 7 <br>
<p>Andrea Coletta, Matteo Prata, Michele Conti, Emanuele Mercanti, Novella Bartolini, Aymeric Moulin, Svitlana Vyetrenko, Tucker Balch</p></summary>
<p>

**Abstract:** Simulated environments are increasingly used by trading firms and investment banks to evaluate trading strategies before approaching real markets. Backtesting, a widely used approach, consists of simulating experimental strategies while replaying historical market scenarios. Unfortunately, this approach does not capture the market response to the experimental agents' actions. In contrast, multi-agent simulation presents a natural bottom-up approach to emulating agent interaction in financial markets. It allows to set up pools of traders with diverse strategies to mimic the financial market trader population, and test the performance of new experimental strategies. Since individual agent-level historical data is typically proprietary and not available for public use, it is difficult to calibrate multiple market agents to obtain the realism required for testing trading strategies. To addresses this challenge we propose a synthetic market generator based on Conditional Generative Adversarial Networks (CGANs) trained on real aggregate-level historical data. A CGAN-based "world" agent can generate meaningful orders in response to an experimental agent. We integrate our synthetic market generator into ABIDES, an open source simulator of financial markets. By means of extensive simulations we show that our proposal outperforms previous work in terms of stylized facts reflecting market responsiveness and realism.

</p>
</details>

<details><summary><b>Rotation Equivariant Deforestation Segmentation and Driver Classification</b>
<a href="https://arxiv.org/abs/2110.13097">arxiv:2110.13097</a>
&#x1F4C8; 6 <br>
<p>Joshua Mitton, Roderick Murray-Smith</p></summary>
<p>

**Abstract:** Deforestation has become a significant contributing factor to climate change and, due to this, both classifying the drivers and predicting segmentation maps of deforestation has attracted significant interest. In this work, we develop a rotation equivariant convolutional neural network model to predict the drivers and generate segmentation maps of deforestation events from Landsat 8 satellite images. This outperforms previous methods in classifying the drivers and predicting the segmentation map of deforestation, offering a 9% improvement in classification accuracy and a 7% improvement in segmentation map accuracy. In addition, this method predicts stable segmentation maps under rotation of the input image, which ensures that predicted regions of deforestation are not dependent upon the rotational orientation of the satellite.

</p>
</details>

<details><summary><b>Transferring Domain-Agnostic Knowledge in Video Question Answering</b>
<a href="https://arxiv.org/abs/2110.13395">arxiv:2110.13395</a>
&#x1F4C8; 5 <br>
<p>Tianran Wu, Noa Garcia, Mayu Otani, Chenhui Chu, Yuta Nakashima, Haruo Takemura</p></summary>
<p>

**Abstract:** Video question answering (VideoQA) is designed to answer a given question based on a relevant video clip. The current available large-scale datasets have made it possible to formulate VideoQA as the joint understanding of visual and language information. However, this training procedure is costly and still less competent with human performance. In this paper, we investigate a transfer learning method by the introduction of domain-agnostic knowledge and domain-specific knowledge. First, we develop a novel transfer learning framework, which finetunes the pre-trained model by applying domain-agnostic knowledge as the medium. Second, we construct a new VideoQA dataset with 21,412 human-generated question-answer samples for comparable transfer of knowledge. Our experiments show that: (i) domain-agnostic knowledge is transferable and (ii) our proposed transfer learning framework can boost VideoQA performance effectively.

</p>
</details>

<details><summary><b>Negotiating Networks in Oligopoly Markets for Price-Sensitive Products</b>
<a href="https://arxiv.org/abs/2110.13303">arxiv:2110.13303</a>
&#x1F4C8; 5 <br>
<p>Naman Shukla, Kartik Yellepeddi</p></summary>
<p>

**Abstract:** We present a novel framework to learn functions that estimate decisions of sellers and buyers simultaneously in an oligopoly market for a price-sensitive product. In this setting, the aim of the seller network is to come up with a price for a given context such that the expected revenue is maximized by considering the buyer's satisfaction as well. On the other hand, the aim of the buyer network is to assign probability of purchase to the offered price to mimic the real world buyers' responses while also showing price sensitivity through its action. In other words, rejecting the unnecessarily high priced products. Similar to generative adversarial networks, this framework corresponds to a minimax two-player game. In our experiments with simulated and real-world transaction data, we compared our framework with the baseline model and demonstrated its potential through proposed evaluation metrics.

</p>
</details>

<details><summary><b>Dual Skip Connections Minimize the False Positive Rate of Lung Nodule Detection in CT images</b>
<a href="https://arxiv.org/abs/2110.13036">arxiv:2110.13036</a>
&#x1F4C8; 5 <br>
<p>Jiahua Xu, Philipp Ernst, Tung Lung Liu, Andreas N체rnberger</p></summary>
<p>

**Abstract:** Pulmonary cancer is one of the most commonly diagnosed and fatal cancers and is often diagnosed by incidental findings on computed tomography. Automated pulmonary nodule detection is an essential part of computer-aided diagnosis, which is still facing great challenges and difficulties to quickly and accurately locate the exact nodules' positions. This paper proposes a dual skip connection upsampling strategy based on Dual Path network in a U-Net structure generating multiscale feature maps, which aims to minimize the ratio of false positives and maximize the sensitivity for lesion detection of nodules. The results show that our new upsampling strategy improves the performance by having 85.3% sensitivity at 4 FROC per image compared to 84.2% for the regular upsampling strategy or 81.2% for VGG16-based Faster-R-CNN.

</p>
</details>

<details><summary><b>Generative Residual Attention Network for Disease Detection</b>
<a href="https://arxiv.org/abs/2110.12984">arxiv:2110.12984</a>
&#x1F4C8; 5 <br>
<p>Euyoung Kim, Soochahn Lee, Kyoung Mu Lee</p></summary>
<p>

**Abstract:** Accurate identification and localization of abnormalities from radiology images serve as a critical role in computer-aided diagnosis (CAD) systems. Building a highly generalizable system usually requires a large amount of data with high-quality annotations, including disease-specific global and localization information. However, in medical images, only a limited number of high-quality images and annotations are available due to annotation expenses. In this paper, we explore this problem by presenting a novel approach for disease generation in X-rays using a conditional generative adversarial learning. Specifically, given a chest X-ray image from a source domain, we generate a corresponding radiology image in a target domain while preserving the identity of the patient. We then use the generated X-ray image in the target domain to augment our training to improve the detection performance. We also present a unified framework that simultaneously performs disease generation and localization.We evaluate the proposed approach on the X-ray image dataset provided by the Radiological Society of North America (RSNA), surpassing the state-of-the-art baseline detection algorithms.

</p>
</details>

<details><summary><b>Quantum Boosting using Domain-Partitioning Hypotheses</b>
<a href="https://arxiv.org/abs/2110.12793">arxiv:2110.12793</a>
&#x1F4C8; 5 <br>
<p>Debajyoti Bera, Sagnik Chatterjee</p></summary>
<p>

**Abstract:** Boosting is an ensemble learning method that converts a weak learner into a strong learner in the PAC learning framework. Freund and Schapire gave the first classical boosting algorithm for binary hypothesis known as AdaBoost, and this was recently adapted into a quantum boosting algorithm by Arunachalam et al. Their quantum boosting algorithm (which we refer to as Q-AdaBoost) is quadratically faster than the classical version in terms of the VC-dimension of the hypothesis class of the weak learner but polynomially worse in the bias of the weak learner.
  In this work we design a different quantum boosting algorithm that uses domain partitioning hypotheses that are significantly more flexible than those used in prior quantum boosting algorithms in terms of margin calculations. Our algorithm Q-RealBoost is inspired by the "Real AdaBoost" (aka. RealBoost) extension to the original AdaBoost algorithm. Further, we show that Q-RealBoost provides a polynomial speedup over Q-AdaBoost in terms of both the bias of the weak learner and the time taken by the weak learner to learn the target concept class.

</p>
</details>

<details><summary><b>"So You Think You're Funny?": Rating the Humour Quotient in Standup Comedy</b>
<a href="https://arxiv.org/abs/2110.12765">arxiv:2110.12765</a>
&#x1F4C8; 5 <br>
<p>Anirudh Mittal, Pranav Jeevan, Prerak Gandhi, Diptesh Kanojia, Pushpak Bhattacharyya</p></summary>
<p>

**Abstract:** Computational Humour (CH) has attracted the interest of Natural Language Processing and Computational Linguistics communities. Creating datasets for automatic measurement of humour quotient is difficult due to multiple possible interpretations of the content. In this work, we create a multi-modal humour-annotated dataset ($\sim$40 hours) using stand-up comedy clips. We devise a novel scoring mechanism to annotate the training data with a humour quotient score using the audience's laughter. The normalized duration (laughter duration divided by the clip duration) of laughter in each clip is used to compute this humour coefficient score on a five-point scale (0-4). This method of scoring is validated by comparing with manually annotated scores, wherein a quadratic weighted kappa of 0.6 is obtained. We use this dataset to train a model that provides a "funniness" score, on a five-point scale, given the audio and its corresponding text. We compare various neural language models for the task of humour-rating and achieve an accuracy of $0.813$ in terms of Quadratic Weighted Kappa (QWK). Our "Open Mic" dataset is released for further research along with the code.

</p>
</details>

<details><summary><b>Pediatric Otoscopy Video Screening with Shift Contrastive Anomaly Detection</b>
<a href="https://arxiv.org/abs/2110.13254">arxiv:2110.13254</a>
&#x1F4C8; 4 <br>
<p>Weiyao Wang, Aniruddha Tamhane, Christine Santos, John R. Rzasa, James H. Clark, Therese L. Canares, Mathias Unberath</p></summary>
<p>

**Abstract:** Ear related concerns and symptoms represents the leading indication for seeking pediatric healthcare attention. Despite the high incidence of such encounters, the diagnostic process of commonly encountered disease of the middle and external presents significant challenge. Much of this challenge stems from the lack of cost effective diagnostic testing, which necessitating the presence or absence of ear pathology to be determined clinically. Research has however demonstrated considerable variation among clinicians in their ability to accurately diagnose and consequently manage ear pathology. With recent advances in computer vision and machine learning, there is an increasing interest in helping clinicians to accurately diagnose middle and external ear pathology with computer-aided systems. It has been shown that AI has the capacity to analyse a single clinical image captured during examination of the ear canal and eardrum from which it can determine the likelihood of a pathognomonic pattern for a specific diagnosis being present. The capture of such an image can however be challenging especially to inexperienced clinicians. To help mitigate this technical challenge we have developed and tested a method using video sequences. We present a two stage method that first, identifies valid frames by detecting and extracting ear drum patches from the video sequence, and second, performs the proposed shift contrastive anomaly detection to flag the otoscopy video sequences as normal or abnormal. Our method achieves an AUROC of 88.0% on the patient-level and also outperforms the average of a group of 25 clinicians in a comparative study, which is the largest of such published to date. We conclude that the presented method achieves a promising first step towards automated analysis of otoscopy video.

</p>
</details>

<details><summary><b>Demystifying and Generalizing BinaryConnect</b>
<a href="https://arxiv.org/abs/2110.13220">arxiv:2110.13220</a>
&#x1F4C8; 4 <br>
<p>Tim Dockhorn, Yaoliang Yu, Eyy체b Sari, Mahdi Zolnouri, Vahid Partovi Nia</p></summary>
<p>

**Abstract:** BinaryConnect (BC) and its many variations have become the de facto standard for neural network quantization. However, our understanding of the inner workings of BC is still quite limited. We attempt to close this gap in four different aspects: (a) we show that existing quantization algorithms, including post-training quantization, are surprisingly similar to each other; (b) we argue for proximal maps as a natural family of quantizers that is both easy to design and analyze; (c) we refine the observation that BC is a special case of dual averaging, which itself is a special case of the generalized conditional gradient algorithm; (d) consequently, we propose ProxConnect (PC) as a generalization of BC and we prove its convergence properties by exploiting the established connections. We conduct experiments on CIFAR-10 and ImageNet, and verify that PC achieves competitive performance.

</p>
</details>

<details><summary><b>Spectral unmixing of Raman microscopic images of single human cells using Independent Component Analysis</b>
<a href="https://arxiv.org/abs/2110.13189">arxiv:2110.13189</a>
&#x1F4C8; 4 <br>
<p>M. Hamed Mozaffari, Li-Lin Tay</p></summary>
<p>

**Abstract:** Application of independent component analysis (ICA) as an unmixing and image clustering technique for high spatial resolution Raman maps is reported. A hyperspectral map of a fixed human cell was collected by a Raman micro spectrometer in a raster pattern on a 0.5um grid. Unlike previously used unsupervised machine learning techniques such as principal component analysis, ICA is based on non-Gaussianity and statistical independence of data which is the case for mixture Raman spectra. Hence, ICA is a great candidate for assembling pseudo-colour maps from the spectral hypercube of Raman spectra. Our experimental results revealed that ICA is capable of reconstructing false colour maps of Raman hyperspectral data of human cells, showing the nuclear region constituents as well as subcellular organelle in the cytoplasm and distribution of mitochondria in the perinuclear region. Minimum preprocessing requirements and label-free nature of the ICA method make it a great unmixed method for extraction of endmembers in Raman hyperspectral maps of living cells.

</p>
</details>

<details><summary><b>Multi-Task Meta-Learning Modification with Stochastic Approximation</b>
<a href="https://arxiv.org/abs/2110.13188">arxiv:2110.13188</a>
&#x1F4C8; 4 <br>
<p>Andrei Boiarov, Konstantin Khabarlak, Igor Yastrebov</p></summary>
<p>

**Abstract:** Meta-learning methods aim to build learning algorithms capable of quickly adapting to new tasks in low-data regime. One of the main benchmarks of such an algorithms is a few-shot learning problem. In this paper we investigate the modification of standard meta-learning pipeline that takes a multi-task approach during training. The proposed method simultaneously utilizes information from several meta-training tasks in a common loss function. The impact of each of these tasks in the loss function is controlled by the corresponding weight. Proper optimization of these weights can have a big influence on training of the entire model and might improve the quality on test time tasks. In this work we propose and investigate the use of methods from the family of simultaneous perturbation stochastic approximation (SPSA) approaches for meta-train tasks weights optimization. We have also compared the proposed algorithms with gradient-based methods and found that stochastic approximation demonstrates the largest quality boost in test time. Proposed multi-task modification can be applied to almost all methods that use meta-learning pipeline. In this paper we study applications of this modification on Prototypical Networks and Model-Agnostic Meta-Learning algorithms on CIFAR-FS, FC100, tieredImageNet and miniImageNet few-shot learning benchmarks. During these experiments, multi-task modification has demonstrated improvement over original methods. The proposed SPSA-Tracking algorithm shows the largest accuracy boost that is competitive against the state-of-the-art meta-learning methods. Our code is available online.

</p>
</details>

<details><summary><b>Latent-Insensitive autoencoders for Anomaly Detection</b>
<a href="https://arxiv.org/abs/2110.13101">arxiv:2110.13101</a>
&#x1F4C8; 4 <br>
<p>Muhammad S. Battikh, Artem A. Lenskiy</p></summary>
<p>

**Abstract:** Reconstruction-based approaches to anomaly detection tend to fall short when applied to complex datasets with target classes that possess high inter-class variance. Similar to the idea of self-taught learning used in transfer learning, many domains are rich with similar unlabelled datasets that could be leveraged as a proxy for out-of-distribution samples. In this paper we introduce Latent-Insensitive autoencoder (LIS-AE) where unlabeled data from a similar domain is utilized as negative examples to shape the latent layer (bottleneck) of a regular autoencoder such that it is only capable of reconstructing one task. We provide theoretical justification for the proposed training process and loss functions along with an extensive ablation study highlighting important aspects of our model. We test our model in multiple anomaly detection settings presenting quantitative and qualitative analysis showcasing the significant performance improvement of our model for anomaly detection tasks.

</p>
</details>

<details><summary><b>AutoMTL: A Programming Framework for Automated Multi-Task Learning</b>
<a href="https://arxiv.org/abs/2110.13076">arxiv:2110.13076</a>
&#x1F4C8; 4 <br>
<p>Lijun Zhang, Xiao Liu, Hui Guan</p></summary>
<p>

**Abstract:** Multi-task learning (MTL) jointly learns a set of tasks. It is a promising approach to reduce the training and inference time and storage costs while improving prediction accuracy and generalization performance for many computer vision tasks. However, a major barrier preventing the widespread adoption of MTL is the lack of systematic support for developing compact multi-task models given a set of tasks. In this paper, we aim to remove the barrier by developing the first programming framework AutoMTL that automates MTL model development. AutoMTL takes as inputs an arbitrary backbone convolutional neural network and a set of tasks to learn, then automatically produce a multi-task model that achieves high accuracy and has small memory footprint simultaneously. As a programming framework, AutoMTL could facilitate the development of MTL-enabled computer vision applications and even further improve task performance. Code of AutoMTL will be available at https://github.com/zhanglijun95/AutoMTL

</p>
</details>

<details><summary><b>Safely Bridging Offline and Online Reinforcement Learning</b>
<a href="https://arxiv.org/abs/2110.13060">arxiv:2110.13060</a>
&#x1F4C8; 4 <br>
<p>Wanqiao Xu, Kan Xu, Hamsa Bastani, Osbert Bastani</p></summary>
<p>

**Abstract:** A key challenge to deploying reinforcement learning in practice is exploring safely. We propose a natural safety property -- \textit{uniformly} outperforming a conservative policy (adaptively estimated from all data observed thus far), up to a per-episode exploration budget. We then design an algorithm that uses a UCB reinforcement learning policy for exploration, but overrides it as needed to ensure safety with high probability. We experimentally validate our results on a sepsis treatment task, demonstrating that our algorithm can learn while ensuring good performance compared to the baseline policy for every patient.

</p>
</details>

<details><summary><b>Logsig-RNN: a novel network for robust and efficient skeleton-based action recognition</b>
<a href="https://arxiv.org/abs/2110.13008">arxiv:2110.13008</a>
&#x1F4C8; 4 <br>
<p>Shujian Liao, Terry Lyons, Weixin Yang, Kevin Schlegel, Hao Ni</p></summary>
<p>

**Abstract:** This paper contributes to the challenge of skeleton-based human action recognition in videos. The key step is to develop a generic network architecture to extract discriminative features for the spatio-temporal skeleton data. In this paper, we propose a novel module, namely Logsig-RNN, which is the combination of the log-signature layer and recurrent type neural networks (RNNs). The former one comes from the mathematically principled technology of signatures and log-signatures as representations for streamed data, which can manage high sample rate streams, non-uniform sampling and time series of variable length. It serves as an enhancement of the recurrent layer, which can be conveniently plugged into neural networks. Besides we propose two path transformation layers to significantly reduce path dimension while retaining the essential information fed into the Logsig-RNN module. Finally, numerical results demonstrate that replacing the RNN module by the Logsig-RNN module in SOTA networks consistently improves the performance on both Chalearn gesture data and NTU RGB+D 120 action data in terms of accuracy and robustness. In particular, we achieve the state-of-the-art accuracy on Chalearn2013 gesture data by combining simple path transformation layers with the Logsig-RNN. Codes are available at https://github.com/steveliao93/GCN_LogsigRNN.

</p>
</details>

<details><summary><b>Neural Relightable Participating Media Rendering</b>
<a href="https://arxiv.org/abs/2110.12993">arxiv:2110.12993</a>
&#x1F4C8; 4 <br>
<p>Quan Zheng, Gurprit Singh, Hans-Peter Seidel</p></summary>
<p>

**Abstract:** Learning neural radiance fields of a scene has recently allowed realistic novel view synthesis of the scene, but they are limited to synthesize images under the original fixed lighting condition. Therefore, they are not flexible for the eagerly desired tasks like relighting, scene editing and scene composition. To tackle this problem, several recent methods propose to disentangle reflectance and illumination from the radiance field. These methods can cope with solid objects with opaque surfaces but participating media are neglected. Also, they take into account only direct illumination or at most one-bounce indirect illumination, thus suffer from energy loss due to ignoring the high-order indirect illumination. We propose to learn neural representations for participating media with a complete simulation of global illumination. We estimate direct illumination via ray tracing and compute indirect illumination with spherical harmonics. Our approach avoids computing the lengthy indirect bounces and does not suffer from energy loss. Our experiments on multiple scenes show that our approach achieves superior visual quality and numerical performance compared to state-of-the-art methods, and it can generalize to deal with solid objects with opaque surfaces as well.

</p>
</details>

<details><summary><b>Persona Authentication through Generative Dialogue</b>
<a href="https://arxiv.org/abs/2110.12949">arxiv:2110.12949</a>
&#x1F4C8; 4 <br>
<p>Fengyi Tang, Lifan Zeng, Fei Wang, Jiayu Zhou</p></summary>
<p>

**Abstract:** In this paper we define and investigate the problem of \emph{persona authentication}: learning a conversational policy to verify the consistency of persona models. We propose a learning objective and prove (under some mild assumptions) that local density estimators trained under this objective maximize the mutual information between persona information and dialog trajectory. Based on the proposed objective, we develop a method of learning an authentication model that adaptively outputs personalized questions to reveal the underlying persona of its partner throughout the course of multi-turn conversation. Experiments show that our authentication method discovers effective question sequences that generalize to unseen persona profiles.

</p>
</details>

<details><summary><b>Restore from Restored: Single-image Inpainting</b>
<a href="https://arxiv.org/abs/2110.12822">arxiv:2110.12822</a>
&#x1F4C8; 4 <br>
<p>Eunhye Lee, Jeongmu Kim, Jisu Kim, Tae Hyun Kim</p></summary>
<p>

**Abstract:** Recent image inpainting methods have shown promising results due to the power of deep learning, which can explore external information available from the large training dataset. However, many state-of-the-art inpainting networks are still limited in exploiting internal information available in the given input image at test time. To mitigate this problem, we present a novel and efficient self-supervised fine-tuning algorithm that can adapt the parameters of fully pre-trained inpainting networks without using ground-truth target images. We update the parameters of the pre-trained state-of-the-art inpainting networks by utilizing existing self-similar patches (i.e., self-exemplars) within the given input image without changing the network architecture and improve the inpainting quality by a large margin. Qualitative and quantitative experimental results demonstrate the superiority of the proposed algorithm, and we achieve state-of-the-art inpainting results on publicly available benchmark datasets.

</p>
</details>

<details><summary><b>A Deep Reinforcement Learning Approach for Audio-based Navigation and Audio Source Localization in Multi-speaker Environments</b>
<a href="https://arxiv.org/abs/2110.12778">arxiv:2110.12778</a>
&#x1F4C8; 4 <br>
<p>Petros Giannakopoulos, Aggelos Pikrakis, Yannis Cotronis</p></summary>
<p>

**Abstract:** In this work we apply deep reinforcement learning to the problems of navigating a three-dimensional environment and inferring the locations of human speaker audio sources within, in the case where the only available information is the raw sound from the environment, as a simulated human listener placed in the environment would hear it. For this purpose we create two virtual environments using the Unity game engine, one presenting an audio-based navigation problem and one presenting an audio source localization problem. We also create an autonomous agent based on PPO online reinforcement learning algorithm and attempt to train it to solve these environments. Our experiments show that our agent achieves adequate performance and generalization ability in both environments, measured by quantitative metrics, even when a limited amount of training data are available or the environment parameters shift in ways not encountered during training. We also show that a degree of agent knowledge transfer is possible between the environments.

</p>
</details>

<details><summary><b>ZerO Initialization: Initializing Residual Networks with only Zeros and Ones</b>
<a href="https://arxiv.org/abs/2110.12661">arxiv:2110.12661</a>
&#x1F4C8; 4 <br>
<p>Jiawei Zhao, Florian Sch채fer, Anima Anandkumar</p></summary>
<p>

**Abstract:** Deep neural networks are usually initialized with random weights, with adequately selected initial variance to ensure stable signal propagation during training. However, there is no consensus on how to select the variance, and this becomes challenging especially as the number of layers grows. In this work, we replace the widely used random weight initialization with a fully deterministic initialization scheme ZerO, which initializes residual networks with only zeros and ones. By augmenting the standard ResNet architectures with a few extra skip connections and Hadamard transforms, ZerO allows us to start the training from zeros and ones entirely. This has many benefits such as improving reproducibility (by reducing the variance over different experimental runs) and allowing network training without batch normalization. Surprisingly, we find that ZerO achieves state-of-the-art performance over various image classification datasets, including ImageNet, which suggests random weights may be unnecessary for modern network initialization.

</p>
</details>

<details><summary><b>Differentiable NAS Framework and Application to Ads CTR Prediction</b>
<a href="https://arxiv.org/abs/2110.14812">arxiv:2110.14812</a>
&#x1F4C8; 3 <br>
<p>Ravi Krishna, Aravind Kalaiah, Bichen Wu, Maxim Naumov, Dheevatsa Mudigere, Misha Smelyanskiy, Kurt Keutzer</p></summary>
<p>

**Abstract:** Neural architecture search (NAS) methods aim to automatically find the optimal deep neural network (DNN) architecture as measured by a given objective function, typically some combination of task accuracy and inference efficiency. For many areas, such as computer vision and natural language processing, this is a critical, yet still time consuming process. New NAS methods have recently made progress in improving the efficiency of this process. We implement an extensible and modular framework for Differentiable Neural Architecture Search (DNAS) to help solve this problem. We include an overview of the major components of our codebase and how they interact, as well as a section on implementing extensions to it (including a sample), in order to help users adopt our framework for their applications across different categories of deep learning models. To assess the capabilities of our methodology and implementation, we apply DNAS to the problem of ads click-through rate (CTR) prediction, arguably the highest-value and most worked on AI problem at hyperscalers today. We develop and tailor novel search spaces to a Deep Learning Recommendation Model (DLRM) backbone for CTR prediction, and report state-of-the-art results on the Criteo Kaggle CTR prediction dataset.

</p>
</details>

<details><summary><b>Generative Flows as a General Purpose Solution for Inverse Problems</b>
<a href="https://arxiv.org/abs/2110.13285">arxiv:2110.13285</a>
&#x1F4C8; 3 <br>
<p>Jos챕 A. Ch찼vez</p></summary>
<p>

**Abstract:** Due to the success of generative flows to model data distributions, they have been explored in inverse problems. Given a pre-trained generative flow, previous work proposed to minimize the 2-norm of the latent variables as a regularization term in the main objective. The intuition behind it was to ensure high likelihood latent variables, however this does not ensure the generation of realistic samples as we show in our experiments. We therefore propose a regularization term to directly produce high likelihood reconstructions. Our hypothesis is that our method could make generative flows a general-purpose solver for inverse problems. We evaluate our method in image denoising, image deblurring, image inpainting, and image colorization. We observe a compelling improvement of our method over prior works in the PSNR and SSIM metrics.

</p>
</details>

<details><summary><b>RBSRICNN: Raw Burst Super-Resolution through Iterative Convolutional Neural Network</b>
<a href="https://arxiv.org/abs/2110.13217">arxiv:2110.13217</a>
&#x1F4C8; 3 <br>
<p>Rao Muhammad Umer, Christian Micheloni</p></summary>
<p>

**Abstract:** Modern digital cameras and smartphones mostly rely on image signal processing (ISP) pipelines to produce realistic colored RGB images. However, compared to DSLR cameras, low-quality images are usually obtained in many portable mobile devices with compact camera sensors due to their physical limitations. The low-quality images have multiple degradations i.e., sub-pixel shift due to camera motion, mosaick patterns due to camera color filter array, low-resolution due to smaller camera sensors, and the rest information are corrupted by the noise. Such degradations limit the performance of current Single Image Super-resolution (SISR) methods in recovering high-resolution (HR) image details from a single low-resolution (LR) image. In this work, we propose a Raw Burst Super-Resolution Iterative Convolutional Neural Network (RBSRICNN) that follows the burst photography pipeline as a whole by a forward (physical) model. The proposed Burst SR scheme solves the problem with classical image regularization, convex optimization, and deep learning techniques, compared to existing black-box data-driven methods. The proposed network produces the final output by an iterative refinement of the intermediate SR estimates. We demonstrate the effectiveness of our proposed approach in quantitative and qualitative experiments that generalize robustly to real LR burst inputs with onl synthetic burst data available for training.

</p>
</details>

<details><summary><b>Self-supervised similarity search for large scientific datasets</b>
<a href="https://arxiv.org/abs/2110.13151">arxiv:2110.13151</a>
&#x1F4C8; 3 <br>
<p>George Stein, Peter Harrington, Jacqueline Blaum, Tomislav Medan, Zarija Lukic</p></summary>
<p>

**Abstract:** We present the use of self-supervised learning to explore and exploit large unlabeled datasets. Focusing on 42 million galaxy images from the latest data release of the Dark Energy Spectroscopic Instrument (DESI) Legacy Imaging Surveys, we first train a self-supervised model to distill low-dimensional representations that are robust to symmetries, uncertainties, and noise in each image. We then use the representations to construct and publicly release an interactive semantic similarity search tool. We demonstrate how our tool can be used to rapidly discover rare objects given only a single example, increase the speed of crowd-sourcing campaigns, and construct and improve training sets for supervised applications. While we focus on images from sky surveys, the technique is straightforward to apply to any scientific dataset of any dimensionality. The similarity search web app can be found at https://github.com/georgestein/galaxy_search

</p>
</details>

<details><summary><b>An Embedded System for Image-based Crack Detection by using Fine-Tuning model of Adaptive Structural Learning of Deep Belief Network</b>
<a href="https://arxiv.org/abs/2110.13145">arxiv:2110.13145</a>
&#x1F4C8; 3 <br>
<p>Shin Kamada, Takumi Ichimura</p></summary>
<p>

**Abstract:** Deep learning has been a successful model which can effectively represent several features of input space and remarkably improve image recognition performance on the deep architectures. In our research, an adaptive structural learning method of Restricted Boltzmann Machine (Adaptive RBM) and Deep Belief Network (Adaptive DBN) have been developed as a deep learning model. The models have a self-organize function which can discover an optimal number of hidden neurons for given input data in a RBM by neuron generation-annihilation algorithm, and can obtain an appropriate number of RBM as hidden layers in the trained DBN. The proposed method was applied to a concrete image benchmark data set SDNET 2018 for crack detection. The dataset contains about 56,000 crack images for three types of concrete structures: bridge decks, walls, and paved roads. The fine-tuning method of the Adaptive DBN can show 99.7%, 99.7%, and 99.4% classification accuracy for test dataset of three types of structures. In this paper, our developed Adaptive DBN was embedded to a tiny PC with GPU for real-time inference on a drone. For fast inference, the fine tuning algorithm also removed some inactivated hidden neurons to make a small model and then the model was able to improve not only classification accuracy but also inference speed simultaneously. The inference speed and running time of portable battery charger were evaluated on three kinds of Nvidia embedded systems; Jetson Nano, AGX Xavier, and Xavier NX.

</p>
</details>

<details><summary><b>Exploiting Redundancy: Separable Group Convolutional Networks on Lie Groups</b>
<a href="https://arxiv.org/abs/2110.13059">arxiv:2110.13059</a>
&#x1F4C8; 3 <br>
<p>David M. Knigge, David W. Romero, Erik J. Bekkers</p></summary>
<p>

**Abstract:** Group convolutional neural networks (G-CNNs) have been shown to increase parameter efficiency and model accuracy by incorporating geometric inductive biases. In this work, we investigate the properties of representations learned by regular G-CNNs, and show considerable parameter redundancy in group convolution kernels. This finding motivates further weight-tying by sharing convolution kernels over subgroups. To this end, we introduce convolution kernels that are separable over the subgroup and channel dimensions. In order to obtain equivariance to arbitrary affine Lie groups we provide a continuous parameterisation of separable convolution kernels. We evaluate our approach across several vision datasets, and show that our weight sharing leads to improved performance and computational efficiency. In many settings, separable G-CNNs outperform their non-separable counterpart, while only using a fraction of their training time. In addition, thanks to the increase in computational efficiency, we are able to implement G-CNNs equivariant to the $\mathrm{Sim(2)}$ group; the group of dilations, rotations and translations. $\mathrm{Sim(2)}$-equivariance further improves performance on all tasks considered.

</p>
</details>

<details><summary><b>Stable Neural ODE with Lyapunov-Stable Equilibrium Points for Defending Against Adversarial Attacks</b>
<a href="https://arxiv.org/abs/2110.12976">arxiv:2110.12976</a>
&#x1F4C8; 3 <br>
<p>Qiyu Kang, Yang Song, Qinxu Ding, Wee Peng Tay</p></summary>
<p>

**Abstract:** Deep neural networks (DNNs) are well-known to be vulnerable to adversarial attacks, where malicious human-imperceptible perturbations are included in the input to the deep network to fool it into making a wrong classification. Recent studies have demonstrated that neural Ordinary Differential Equations (ODEs) are intrinsically more robust against adversarial attacks compared to vanilla DNNs. In this work, we propose a stable neural ODE with Lyapunov-stable equilibrium points for defending against adversarial attacks (SODEF). By ensuring that the equilibrium points of the ODE solution used as part of SODEF is Lyapunov-stable, the ODE solution for an input with a small perturbation converges to the same solution as the unperturbed input. We provide theoretical results that give insights into the stability of SODEF as well as the choice of regularizers to ensure its stability. Our analysis suggests that our proposed regularizers force the extracted feature points to be within a neighborhood of the Lyapunov-stable equilibrium points of the ODE. SODEF is compatible with many defense methods and can be applied to any neural network's final regressor layer to enhance its stability against adversarial attacks.

</p>
</details>

<details><summary><b>Automatic segmentation of novel coronavirus pneumonia lesions in CT images utilizing deep-supervised ensemble learning network</b>
<a href="https://arxiv.org/abs/2110.12827">arxiv:2110.12827</a>
&#x1F4C8; 3 <br>
<p>Yuanyuan Peng, Zixu Zhang, Hongbin Tu, Xiong Li</p></summary>
<p>

**Abstract:** Background: The 2019 novel coronavirus disease (COVID-19) has been spread widely in the world, causing a huge threat to people's living environment. Objective: Under computed tomography (CT) imaging, the structure features of COVID-19 lesions are complicated and varied greatly in different cases. To accurately locate COVID-19 lesions and assist doctors to make the best diagnosis and treatment plan, a deep-supervised ensemble learning network is presented for COVID-19 lesion segmentation in CT images. Methods: Considering the fact that a large number of COVID-19 CT images and the corresponding lesion annotations are difficult to obtained, a transfer learning strategy is employed to make up for the shortcoming and alleviate the overfitting problem. Based on the reality that traditional single deep learning framework is difficult to extract COVID-19 lesion features effectively, which may cause some lesions to be undetected. To overcome the problem, a deep-supervised ensemble learning network is presented to combine with local and global features for COVID-19 lesion segmentation. Results: The performance of the proposed method was validated in experiments with a publicly available dataset. Compared with manual annotations, the proposed method acquired a high intersection over union (IoU) of 0.7279. Conclusion: A deep-supervised ensemble learning network was presented for coronavirus pneumonia lesion segmentation in CT images. The effectiveness of the proposed method was verified by visual inspection and quantitative evaluation. Experimental results shown that the proposed mehtod has a perfect performance in COVID-19 lesion segmentation.

</p>
</details>

<details><summary><b>Raw Bayer Pattern Image Synthesis with Conditional GAN</b>
<a href="https://arxiv.org/abs/2110.12823">arxiv:2110.12823</a>
&#x1F4C8; 3 <br>
<p>Zhou Wei</p></summary>
<p>

**Abstract:** In this paper, we propose a method to generate Bayer pattern images by Generative adversarial network (GANs). It is shown theoretically that using the transformed data in GANs training is able to improve the generator learning of the original data distribution, owing to the invariant of Jensen Shannon(JS) divergence between two distributions under invertible and differentiable transformation. The Bayer pattern images can be generated by configuring the transformation as demosaicing, by converting the existing standard color datasets to Bayer domain, the proposed method is promising in the applications such as to find the optimal ISP configuration for computer vision tasks, in the in sensor or near sensor computing, even in photography. Experiments show that the images generated by our proposed method outperform the original Pix2PixHD model in FID score, PSNR, and SSIM, and the training process is more stable. For the situation similar to in sensor or near sensor computing for object detection, by using our proposed method, the model performance can be improved without the modification to the image sensor.

</p>
</details>

<details><summary><b>Domain Adaptation in Multi-View Embedding for Cross-Modal Video Retrieval</b>
<a href="https://arxiv.org/abs/2110.12812">arxiv:2110.12812</a>
&#x1F4C8; 3 <br>
<p>Jonathan Munro, Michael Wray, Diane Larlus, Gabriela Csurka, Dima Damen</p></summary>
<p>

**Abstract:** Given a gallery of uncaptioned video sequences, this paper considers the task of retrieving videos based on their relevance to an unseen text query. To compensate for the lack of annotations, we rely instead on a related video gallery composed of video-caption pairs, termed the source gallery, albeit with a domain gap between its videos and those in the target gallery. We thus introduce the problem of Unsupervised Domain Adaptation for Cross-modal Video Retrieval, along with a new benchmark on fine-grained actions. We propose a novel iterative domain alignment method by means of pseudo-labelling target videos and cross-domain (i.e. source-target) ranking. Our approach adapts the embedding space to the target gallery, consistently outperforming source-only as well as marginal and conditional alignment methods.

</p>
</details>

<details><summary><b>Fast Gradient Non-sign Methods</b>
<a href="https://arxiv.org/abs/2110.12734">arxiv:2110.12734</a>
&#x1F4C8; 3 <br>
<p>Yaya Cheng, Xiaosu Zhu, Qilong Zhang, Lianli Gao, Jingkuan Song</p></summary>
<p>

**Abstract:** Adversarial attacks make their success in \enquote{fooling} DNNs and among them, gradient-based algorithms become one of the mainstreams. Based on the linearity hypothesis~\cite{fgsm}, under $\ell_\infty$ constraint, $sign$ operation applied to the gradients is a good choice for generating perturbations. However, the side-effect from such operation exists since it leads to the bias of direction between the real gradients and the perturbations. In other words, current methods contain a gap between real gradients and actual noises, which leads to biased and inefficient attacks. Therefore in this paper, based on the Taylor expansion, the bias is analyzed theoretically and the correction of $\sign$, \ie, Fast Gradient Non-sign Method (FGNM), is further proposed. Notably, FGNM is a general routine, which can seamlessly replace the conventional $sign$ operation in gradient-based attacks with negligible extra computational cost. Extensive experiments demonstrate the effectiveness of our methods. Specifically, ours outperform them by \textbf{27.5\%} at most and \textbf{9.5\%} on average. Our anonymous code is publicly available: \url{https://git.io/mm-fgnm}.

</p>
</details>

<details><summary><b>Fine-tuning of Pre-trained Transformers for Hate, Offensive, and Profane Content Detection in English and Marathi</b>
<a href="https://arxiv.org/abs/2110.12687">arxiv:2110.12687</a>
&#x1F4C8; 3 <br>
<p>Anna Glazkova, Michael Kadantsev, Maksim Glazkov</p></summary>
<p>

**Abstract:** This paper describes neural models developed for the Hate Speech and Offensive Content Identification in English and Indo-Aryan Languages Shared Task 2021. Our team called neuro-utmn-thales participated in two tasks on binary and fine-grained classification of English tweets that contain hate, offensive, and profane content (English Subtasks A & B) and one task on identification of problematic content in Marathi (Marathi Subtask A). For English subtasks, we investigate the impact of additional corpora for hate speech detection to fine-tune transformer models. We also apply a one-vs-rest approach based on Twitter-RoBERTa to discrimination between hate, profane and offensive posts. Our models ranked third in English Subtask A with the F1-score of 81.99% and ranked second in English Subtask B with the F1-score of 65.77%. For the Marathi tasks, we propose a system based on the Language-Agnostic BERT Sentence Embedding (LaBSE). This model achieved the second result in Marathi Subtask A obtaining an F1 of 88.08%.

</p>
</details>

<details><summary><b>Mixture-of-Variational-Experts for Continual Learning</b>
<a href="https://arxiv.org/abs/2110.12667">arxiv:2110.12667</a>
&#x1F4C8; 3 <br>
<p>Heinke Hihn, Daniel A. Braun</p></summary>
<p>

**Abstract:** One significant shortcoming of machine learning is the poor ability of models to solve new problems quicker and without forgetting acquired knowledge. To better understand this issue, continual learning has emerged to systematically investigate learning protocols where the model sequentially observes samples generated by a series of tasks. First, we propose an optimality principle that facilitates a trade-off between learning and forgetting. We derive this principle from an information-theoretic formulation of bounded rationality and show its connections to other continual learning methods. Second, based on this principle, we propose a neural network layer for continual learning, called Mixture-of-Variational-Experts (MoVE), that alleviates forgetting while enabling the beneficial transfer of knowledge to new tasks. Our experiments on variants of the MNIST and CIFAR10 datasets demonstrate the competitive performance of MoVE layers when compared to state-of-the-art approaches.

</p>
</details>

<details><summary><b>Operator Augmentation for Model-based Policy Evaluation</b>
<a href="https://arxiv.org/abs/2110.12658">arxiv:2110.12658</a>
&#x1F4C8; 3 <br>
<p>Xun Tang, Lexing Ying, Yuhua Zhu</p></summary>
<p>

**Abstract:** In model-based reinforcement learning, the transition matrix and reward vector are often estimated from random samples subject to noise. Even if the estimated model is an unbiased estimate of the true underlying model, the value function computed from the estimated model is biased. We introduce an operator augmentation method for reducing the error introduced by the estimated model. When the error is in the residual norm, we prove that the augmentation factor is always positive and upper bounded by $1 + O (1/n)$, where n is the number of samples used in learning each row of the transition matrix. We also propose a practical numerical algorithm for implementing the operator augmentation.

</p>
</details>

<details><summary><b>Kernel density estimation-based sampling for neural network classification</b>
<a href="https://arxiv.org/abs/2110.12644">arxiv:2110.12644</a>
&#x1F4C8; 3 <br>
<p>Firuz Kamalov, Ashraf Elnagar</p></summary>
<p>

**Abstract:** Imbalanced data occurs in a wide range of scenarios. The skewed distribution of the target variable elicits bias in machine learning algorithms. One of the popular methods to combat imbalanced data is to artificially balance the data through resampling. In this paper, we compare the efficacy of a recently proposed kernel density estimation (KDE) sampling technique in the context of artificial neural networks. We benchmark the KDE sampling method against two base sampling techniques and perform comparative experiments using 8 datasets and 3 neural networks architectures. The results show that KDE sampling produces the best performance on 6 out of 8 datasets. However, it must be used with caution on image datasets. We conclude that KDE sampling is capable of significantly improving the performance of neural networks.

</p>
</details>

<details><summary><b>Bolt: Bridging the Gap between Auto-tuners and Hardware-native Performance</b>
<a href="https://arxiv.org/abs/2110.15238">arxiv:2110.15238</a>
&#x1F4C8; 2 <br>
<p>Jiarong Xing, Leyuan Wang, Shang Zhang, Jack Chen, Ang Chen, Yibo Zhu</p></summary>
<p>

**Abstract:** Today's auto-tuners (e.g., AutoTVM, Ansor) generate efficient tensor programs by navigating a large search space to identify effective implementations, but they do so with opaque hardware details. Thus, their performance could fall behind that of hardware-native libraries (e.g., cuBLAS, cuDNN), which are hand-optimized by device vendors to extract high performance. On the other hand, these vendor libraries have a fixed set of supported functions and lack the customization and automation support afforded by auto-tuners. Bolt is based on the recent trend that vendor libraries are increasingly modularized and reconfigurable via declarative control (e.g., CUTLASS). It enables a novel approach that bridges this gap and achieves the best of both worlds, via hardware-native templated search. Bolt provides new opportunities to rethink end-to-end tensor optimizations at the graph, operator, and model levels. Bolt demonstrates this concept by prototyping on a popular auto-tuner in TVM and a class of widely-used platforms (i.e., NVIDIA GPUs) -- both in large deployment in our production environment. Bolt improves the inference speed of common convolutional neural networks by 2.5x on average over the state of the art, and it auto-tunes these models within 20 minutes.

</p>
</details>

<details><summary><b>Ensemble Federated Adversarial Training with Non-IID data</b>
<a href="https://arxiv.org/abs/2110.14814">arxiv:2110.14814</a>
&#x1F4C8; 2 <br>
<p>Shuang Luo, Didi Zhu, Zexi Li, Chao Wu</p></summary>
<p>

**Abstract:** Despite federated learning endows distributed clients with a cooperative training mode under the premise of protecting data privacy and security, the clients are still vulnerable when encountering adversarial samples due to the lack of robustness. The adversarial samples can confuse and cheat the client models to achieve malicious purposes via injecting elaborate noise into normal input. In this paper, we introduce a novel Ensemble Federated Adversarial Training Method, termed as EFAT, that enables an efficacious and robust coupled training mechanism. Our core idea is to enhance the diversity of adversarial examples through expanding training data with different disturbances generated from other participated clients, which helps adversarial training perform well in Non-IID settings. Experimental results on different Non-IID situations, including feature distribution skew and label distribution skew, show that our proposed method achieves promising results compared with solely combining federated learning with adversarial approaches.

</p>
</details>

<details><summary><b>HSVI fo zs-POSGs using Concavity, Convexity and Lipschitz Properties</b>
<a href="https://arxiv.org/abs/2110.14529">arxiv:2110.14529</a>
&#x1F4C8; 2 <br>
<p>Aur챕lien Delage, Olivier Buffet, Jilles Dibangoye</p></summary>
<p>

**Abstract:** Dynamic programming and heuristic search are at the core of state-of-the-art solvers for sequential decision-making problems. In partially observable or collaborative settings (\eg, POMDPs and Dec-POMDPs), this requires introducing an appropriate statistic that induces a fully observable problem as well as bounding (convex) approximators of the optimal value function. This approach has succeeded in some subclasses of 2-player zero-sum partially observable stochastic games (zs-POSGs) as well, but failed in the general case despite known concavity and convexity properties, which only led to heuristic algorithms with poor convergence guarantees. We overcome this issue, leveraging on these properties to derive bounding approximators and efficient update and selection operators, before deriving a prototypical solver inspired by HSVI that provably converges to an $琯$-optimal solution in finite time, and which we empirically evaluate. This opens the door to a novel family of promising approaches complementing those relying on linear programming or iterative methods.

</p>
</details>

<details><summary><b>Unified Instance and Knowledge Alignment Pretraining for Aspect-based Sentiment Analysis</b>
<a href="https://arxiv.org/abs/2110.13398">arxiv:2110.13398</a>
&#x1F4C8; 2 <br>
<p>Juhua Liu, Qihuang Zhong, Liang Ding, Hua Jin, Bo Du, Dacheng Tao</p></summary>
<p>

**Abstract:** Aspect-based Sentiment Analysis (ABSA) aims to determine the sentiment polarity towards an aspect. Because of the expensive and limited labelled data, the pretraining strategy has become the de-facto standard for ABSA. However, there always exists severe domain shift between the pretraining and downstream ABSA datasets, hindering the effective knowledge transfer when directly finetuning and making the downstream task performs sub-optimal. To mitigate such domain shift, we introduce a unified alignment pretraining framework into the vanilla pretrain-finetune pipeline with both instance- and knowledge-level alignments. Specifically, we first devise a novel coarse-to-fine retrieval sampling approach to select target domain-related instances from the large-scale pretraining dataset, thus aligning the instances between pretraining and target domains (\textit{First Stage}). Then, we introduce a knowledge guidance-based strategy to further bridge the domain gap at the knowledge level. In practice, we formulate the model pretrained on the sampled instances into a knowledge guidance model and a learner model, respectively. On the target dataset, we design an on-the-fly teacher-student joint fine-tuning approach to progressively transfer the knowledge from the knowledge guidance model to the learner model (\textit{Second Stage}). Thereby, the learner model can maintain more domain-invariant knowledge when learning new knowledge from the target dataset. In the \textit{Third Stage,} the learner model is finetuned to better adapt its learned knowledge to the target dataset. Extensive experiments and analyses on several ABSA benchmarks demonstrate the effectiveness and universality of our proposed pretraining framework. Notably, our pretraining framework pushes several strong baseline models up to the new state-of-the-art records. We release our code and models.

</p>
</details>

<details><summary><b>Self-Denoising Neural Networks for Few Shot Learning</b>
<a href="https://arxiv.org/abs/2110.13386">arxiv:2110.13386</a>
&#x1F4C8; 2 <br>
<p>Steven Schwarcz, Sai Saketh Rambhatla, Rama Chellappa</p></summary>
<p>

**Abstract:** In this paper, we introduce a new architecture for few shot learning, the task of teaching a neural network from as few as one or five labeled examples. Inspired by the theoretical results of Alaine et al that Denoising Autoencoders refine features to lie closer to the true data manifold, we present a new training scheme that adds noise at multiple stages of an existing neural architecture while simultaneously learning to be robust to this added noise. This architecture, which we call a Self-Denoising Neural Network (SDNN), can be applied easily to most modern convolutional neural architectures, and can be used as a supplement to many existing few-shot learning techniques. We empirically show that SDNNs out-perform previous state-of-the-art methods for few shot image recognition using the Wide-ResNet architecture on the \textit{mini}ImageNet, tiered-ImageNet, and CIFAR-FS few shot learning datasets. We also perform a series of ablation experiments to empirically justify the construction of the SDNN architecture. Finally, we show that SDNNs even improve few shot performance on the task of human action detection in video using experiments on the ActEV SDL Surprise Activities challenge.

</p>
</details>

<details><summary><b>An Automatic Detection Method Of Cerebral Aneurysms In Time-Of-Flight Magnetic Resonance Angiography Images Based On Attention 3D U-Net</b>
<a href="https://arxiv.org/abs/2110.13367">arxiv:2110.13367</a>
&#x1F4C8; 2 <br>
<p>Chen Geng, Meng Chen, Ruoyu Di, Dongdong Wang, Liqin Yang, Wei Xia, Yuxin Li, Daoying Geng</p></summary>
<p>

**Abstract:** Background:Subarachnoid hemorrhage caused by ruptured cerebral aneurysm often leads to fatal consequences.However,if the aneurysm can be found and treated during asymptomatic periods,the probability of rupture can be greatly reduced.At present,time-of-flight magnetic resonance angiography is one of the most commonly used non-invasive screening techniques for cerebral aneurysm,and the application of deep learning technology in aneurysm detection can effectively improve the screening effect of aneurysm.Existing studies have found that three-dimensional features play an important role in aneurysm detection,but they require a large amount of training data and have problems such as a high false positive rate. Methods:This paper proposed a novel method for aneurysm detection.First,a fully automatic cerebral artery segmentation algorithm without training data was used to extract the volume of interest,and then the 3D U-Net was improved by the 3D SENet module to establish an aneurysm detection model.Eventually a set of fully automated,end-to-end aneurysm detection methods have been formed. Results:A total of 231 magnetic resonance angiography image data were used in this study,among which 132 were training sets,34 were internal test sets and 65 were external test sets.The presented method obtained 97.89% sensitivity in the five-fold cross-validation and obtained 91.0% sensitivity with 2.48 false positives/case in the detection of the external test sets. Conclusions:Compared with the results of our previous studies and other studies,the method in this paper achieves a very competitive sensitivity with less training data and maintains a low false positive rate.As the only method currently using 3D U-Net for aneurysm detection,it proves the feasibility and superior performance of this network in aneurysm detection,and also explores the potential of the channel attention mechanism in this task.

</p>
</details>

<details><summary><b>Physics-Informed Neural Networks (PINNs) for Parameterized PDEs: A Metalearning Approach</b>
<a href="https://arxiv.org/abs/2110.13361">arxiv:2110.13361</a>
&#x1F4C8; 2 <br>
<p>Michael Penwarden, Shandian Zhe, Akil Narayan, Robert M. Kirby</p></summary>
<p>

**Abstract:** Physics-informed neural networks (PINNs) as a means of discretizing partial differential equations (PDEs) are garnering much attention in the Computational Science and Engineering (CS&E) world. At least two challenges exist for PINNs at present: an understanding of accuracy and convergence characteristics with respect to tunable parameters and identification of optimization strategies that make PINNs as efficient as other computational science tools. The cost of PINNs training remains a major challenge of Physics-informed Machine Learning (PiML) -- and, in fact, machine learning (ML) in general. This paper is meant to move towards addressing the latter through the study of PINNs for parameterized PDEs. Following the ML world, we introduce metalearning of PINNs for parameterized PDEs. By introducing metalearning and transfer learning concepts, we can greatly accelerate the PINNs optimization process. We present a survey of model-agnostic metalearning, and then discuss our model-aware metalearning applied to PINNs. We provide theoretically motivated and empirically backed assumptions that make our metalearning approach possible. We then test our approach on various canonical forward parameterized PDEs that have been presented in the emerging PINNs literature.

</p>
</details>

<details><summary><b>Privacy-Preserving Multi-Target Multi-Domain Recommender Systems with Assisted AutoEncoders</b>
<a href="https://arxiv.org/abs/2110.13340">arxiv:2110.13340</a>
&#x1F4C8; 2 <br>
<p>Enmao Diao, Vahid Tarokh, Jie Ding</p></summary>
<p>

**Abstract:** A long-standing challenge in Recommender Systems (RCs) is the data sparsity problem that often arises when users rate very few items. Multi-Target Multi-Domain Recommender Systems (MTMDR) aim to improve the recommendation performance in multiple domains simultaneously. The existing works assume that the data of different domains can be fully shared, and the computation can be performed in a centralized manner. However, in many realistic scenarios, separate recommender systems are operated by different organizations, which do not allow the sharing of private data, models, and recommendation tasks. This work proposes an MTMDR based on Assisted AutoEncoders (AAE) and Multi-Target Assisted Learning (MTAL) to help organizational learners improve their recommendation performance simultaneously without sharing sensitive assets. Moreover, AAE has a broad application scope since it allows explicit or implicit feedback, user- or item-based alignment, and with or without side information. Extensive experiments demonstrate that our method significantly outperforms the case where each domain is locally trained, and it performs competitively with the centralized training where all data are shared. As a result, AAE can effectively integrate organizations from different domains to form a community of shared interest.

</p>
</details>

<details><summary><b>Robust Learning of Physics Informed Neural Networks</b>
<a href="https://arxiv.org/abs/2110.13330">arxiv:2110.13330</a>
&#x1F4C8; 2 <br>
<p>Chandrajit Bajaj, Luke McLennan, Timothy Andeen, Avik Roy</p></summary>
<p>

**Abstract:** Physics-informed Neural Networks (PINNs) have been shown to be effective in solving partial differential equations by capturing the physics induced constraints as a part of the training loss function. This paper shows that a PINN can be sensitive to errors in training data and overfit itself in dynamically propagating these errors over the domain of the solution of the PDE. It also shows how physical regularizations based on continuity criteria and conservation laws fail to address this issue and rather introduce problems of their own causing the deep network to converge to a physics-obeying local minimum instead of the global minimum. We introduce Gaussian Process (GP) based smoothing that recovers the performance of a PINN and promises a robust architecture against noise/errors in measurements. Additionally, we illustrate an inexpensive method of quantifying the evolution of uncertainty based on the variance estimation of GPs on boundary data. Robust PINN performance is also shown to be achievable by choice of sparse sets of inducing points based on sparsely induced GPs. We demonstrate the performance of our proposed methods and compare the results from existing benchmark models in literature for time-dependent Schr철dinger and Burgers' equations.

</p>
</details>

<details><summary><b>Exploring System Performance of Continual Learning for Mobile and Embedded Sensing Applications</b>
<a href="https://arxiv.org/abs/2110.13290">arxiv:2110.13290</a>
&#x1F4C8; 2 <br>
<p>Young D. Kwon, Jagmohan Chauhan, Abhishek Kumar, Pan Hui, Cecilia Mascolo</p></summary>
<p>

**Abstract:** Continual learning approaches help deep neural network models adapt and learn incrementally by trying to solve catastrophic forgetting. However, whether these existing approaches, applied traditionally to image-based tasks, work with the same efficacy to the sequential time series data generated by mobile or embedded sensing systems remains an unanswered question.
  To address this void, we conduct the first comprehensive empirical study that quantifies the performance of three predominant continual learning schemes (i.e., regularization, replay, and replay with examples) on six datasets from three mobile and embedded sensing applications in a range of scenarios having different learning complexities. More specifically, we implement an end-to-end continual learning framework on edge devices. Then we investigate the generalizability, trade-offs between performance, storage, computational costs, and memory footprint of different continual learning methods.
  Our findings suggest that replay with exemplars-based schemes such as iCaRL has the best performance trade-offs, even in complex scenarios, at the expense of some storage space (few MBs) for training examples (1% to 5%). We also demonstrate for the first time that it is feasible and practical to run continual learning on-device with a limited memory budget. In particular, the latency on two types of mobile and embedded devices suggests that both incremental learning time (few seconds - 4 minutes) and training time (1 - 75 minutes) across datasets are acceptable, as training could happen on the device when the embedded device is charging thereby ensuring complete data privacy. Finally, we present some guidelines for practitioners who want to apply a continual learning paradigm for mobile sensing tasks.

</p>
</details>

<details><summary><b>Variational framework for partially-measured physical system control: examples of vision neuroscience and optical random media</b>
<a href="https://arxiv.org/abs/2110.13228">arxiv:2110.13228</a>
&#x1F4C8; 2 <br>
<p>Babak Rahmani, Demetri Psaltis, Christophe Moser</p></summary>
<p>

**Abstract:** To characterize a physical system to behave as desired, either its underlying governing rules must be known a priori or the system itself be accurately measured. The complexity of full measurements of the system scales with its size. When exposed to real-world conditions, such as perturbations or time-varying settings, the system calibrated for a fixed working condition might require non-trivial re-calibration, a process that could be prohibitively expensive, inefficient and impractical for real-world use cases. In this work, we propose a learning procedure to obtain a desired target output from a physical system. We use Variational Auto-Encoders (VAE) to provide a generative model of the system function and use this model to obtain the required input of the system that produces the target output. We showcase the applicability of our method for two datasets in optical physics and neuroscience.

</p>
</details>

<details><summary><b>Which Model To Trust: Assessing the Influence of Models on the Performance of Reinforcement Learning Algorithms for Continuous Control Tasks</b>
<a href="https://arxiv.org/abs/2110.13079">arxiv:2110.13079</a>
&#x1F4C8; 2 <br>
<p>Giacomo Arcieri, David W철lfle, Eleni Chatzi</p></summary>
<p>

**Abstract:** The need for algorithms able to solve Reinforcement Learning (RL) problems with few trials has motivated the advent of model-based RL methods. The reported performance of model-based algorithms has dramatically increased within recent years. However, it is not clear how much of the recent progress is due to improved algorithms or due to improved models. While different modeling options are available to choose from when applying a model-based approach, the distinguishing traits and particular strengths of different models are not clear. The main contribution of this work lies precisely in assessing the model influence on the performance of RL algorithms. A set of commonly adopted models is established for the purpose of model comparison. These include Neural Networks (NNs), ensembles of NNs, two different approximations of Bayesian NNs (BNNs), that is, the Concrete Dropout NN and the Anchored Ensembling, and Gaussian Processes (GPs). The model comparison is evaluated on a suite of continuous control benchmarking tasks. Our results reveal that significant differences in model performance do exist. The Concrete Dropout NN reports persistently superior performance. We summarize these differences for the benefit of the modeler and suggest that the model choice is tailored to the standards required by each specific application.

</p>
</details>

<details><summary><b>Can Q-Learning be Improved with Advice?</b>
<a href="https://arxiv.org/abs/2110.13052">arxiv:2110.13052</a>
&#x1F4C8; 2 <br>
<p>Noah Golowich, Ankur Moitra</p></summary>
<p>

**Abstract:** Despite rapid progress in theoretical reinforcement learning (RL) over the last few years, most of the known guarantees are worst-case in nature, failing to take advantage of structure that may be known a priori about a given RL problem at hand. In this paper we address the question of whether worst-case lower bounds for regret in online learning of Markov decision processes (MDPs) can be circumvented when information about the MDP, in the form of predictions about its optimal $Q$-value function, is given to the algorithm. We show that when the predictions about the optimal $Q$-value function satisfy a reasonably weak condition we call distillation, then we can improve regret bounds by replacing the set of state-action pairs with the set of state-action pairs on which the predictions are grossly inaccurate. This improvement holds for both uniform regret bounds and gap-based ones. Further, we are able to achieve this property with an algorithm that achieves sublinear regret when given arbitrary predictions (i.e., even those which are not a distillation). Our work extends a recent line of work on algorithms with predictions, which has typically focused on simple online problems such as caching and scheduling, to the more complex and general problem of reinforcement learning.

</p>
</details>

<details><summary><b>Nonuniform Negative Sampling and Log Odds Correction with Rare Events Data</b>
<a href="https://arxiv.org/abs/2110.13048">arxiv:2110.13048</a>
&#x1F4C8; 2 <br>
<p>HaiYing Wang, Aonan Zhang, Chong Wang</p></summary>
<p>

**Abstract:** We investigate the issue of parameter estimation with nonuniform negative sampling for imbalanced data. We first prove that, with imbalanced data, the available information about unknown parameters is only tied to the relatively small number of positive instances, which justifies the usage of negative sampling. However, if the negative instances are subsampled to the same level of the positive cases, there is information loss. To maintain more information, we derive the asymptotic distribution of a general inverse probability weighted (IPW) estimator and obtain the optimal sampling probability that minimizes its variance. To further improve the estimation efficiency over the IPW method, we propose a likelihood-based estimator by correcting log odds for the sampled data and prove that the improved estimator has the smallest asymptotic variance among a large class of estimators. It is also more robust to pilot misspecification. We validate our approach on simulated data as well as a real click-through rate dataset with more than 0.3 trillion instances, collected over a period of a month. Both theoretical and empirical results demonstrate the effectiveness of our method.

</p>
</details>

<details><summary><b>Gradient-based Quadratic Multiform Separation</b>
<a href="https://arxiv.org/abs/2110.13006">arxiv:2110.13006</a>
&#x1F4C8; 2 <br>
<p>Wen-Teng Chang</p></summary>
<p>

**Abstract:** Classification as a supervised learning concept is an important content in machine learning. It aims at categorizing a set of data into classes. There are several commonly-used classification methods nowadays such as k-nearest neighbors, random forest, and support vector machine. Each of them has its own pros and cons, and none of them is invincible for all kinds of problems. In this thesis, we focus on Quadratic Multiform Separation (QMS), a classification method recently proposed by Michael Fan et al. (2019). Its fresh concept, rich mathematical structure, and innovative definition of loss function set it apart from the existing classification methods. Inspired by QMS, we propose utilizing a gradient-based optimization method, Adam, to obtain a classifier that minimizes the QMS-specific loss function. In addition, we provide suggestions regarding model tuning through explorations of the relationships between hyperparameters and accuracies. Our empirical result shows that QMS performs as good as most classification methods in terms of accuracy. Its superior performance is almost comparable to those of gradient boosting algorithms that win massive machine learning competitions.

</p>
</details>

<details><summary><b>Goal-Aware Cross-Entropy for Multi-Target Reinforcement Learning</b>
<a href="https://arxiv.org/abs/2110.12985">arxiv:2110.12985</a>
&#x1F4C8; 2 <br>
<p>Kibeom Kim, Min Whoo Lee, Yoonsung Kim, Je-Hwan Ryu, Minsu Lee, Byoung-Tak Zhang</p></summary>
<p>

**Abstract:** Learning in a multi-target environment without prior knowledge about the targets requires a large amount of samples and makes generalization difficult. To solve this problem, it is important to be able to discriminate targets through semantic understanding. In this paper, we propose goal-aware cross-entropy (GACE) loss, that can be utilized in a self-supervised way using auto-labeled goal states alongside reinforcement learning. Based on the loss, we then devise goal-discriminative attention networks (GDAN) which utilize the goal-relevant information to focus on the given instruction. We evaluate the proposed methods on visual navigation and robot arm manipulation tasks with multi-target environments and show that GDAN outperforms the state-of-the-art methods in terms of task success ratio, sample efficiency, and generalization. Additionally, qualitative analyses demonstrate that our proposed method can help the agent become aware of and focus on the given instruction clearly, promoting goal-directed behavior.

</p>
</details>

<details><summary><b>Stochastic Rounding for Image Interpolation and Scan Conversion</b>
<a href="https://arxiv.org/abs/2110.12983">arxiv:2110.12983</a>
&#x1F4C8; 2 <br>
<p>Olivier Rukundo</p></summary>
<p>

**Abstract:** The stochastic rounding (SR) function is introduced to demonstrate the effects of stochastically rounding row and column subscripts on image interpolation quality in nearest neighbor interpolation (NNI). The introduced SR function is based on a pseudorandom number that enables the pseudorandom rounding up or down of any non-integer row and column subscripts. Also, the SR function exceptionally enables rounding up of any possible cases of subscript inputs that are inferior to a pseudorandom number - especially at a high interpolation scaling ratio. The quality of NNI-SR interpolated images is evaluated against the quality of reference images - before and after applying smoothing and sharpening filters, mentioned. The quality of NNI-SR interpolated scan conversion video frames is evaluated without using any references - focusing on the quality of one frame after every 78-milliseconds for 10 000 milliseconds. Relevant experimental simulation results, discussions, and recommendations are also provided.

</p>
</details>

<details><summary><b>Optimal Model Averaging: Towards Personalized Collaborative Learning</b>
<a href="https://arxiv.org/abs/2110.12946">arxiv:2110.12946</a>
&#x1F4C8; 2 <br>
<p>Felix Grimberg, Mary-Anne Hartley, Sai P. Karimireddy, Martin Jaggi</p></summary>
<p>

**Abstract:** In federated learning, differences in the data or objectives between the participating nodes motivate approaches to train a personalized machine learning model for each node. One such approach is weighted averaging between a locally trained model and the global model. In this theoretical work, we study weighted model averaging for arbitrary scalar mean estimation problems under minimal assumptions on the distributions. In a variant of the bias-variance trade-off, we find that there is always some positive amount of model averaging that reduces the expected squared error compared to the local model, provided only that the local model has a non-zero variance. Further, we quantify the (possibly negative) benefit of weighted model averaging as a function of the weight used and the optimal weight. Taken together, this work formalizes an approach to quantify the value of personalization in collaborative learning and provides a framework for future research to test the findings in multivariate parameter estimation and under a range of assumptions.

</p>
</details>

<details><summary><b>Interactive Segmentation via Deep Learning and B-Spline Explicit Active Surfaces</b>
<a href="https://arxiv.org/abs/2110.12939">arxiv:2110.12939</a>
&#x1F4C8; 2 <br>
<p>Helena Williams, Jo찾o Pedrosa, Laura Cattani, Susanne Housmans, Tom Vercauteren, Jan Deprest, Jan D'hooge</p></summary>
<p>

**Abstract:** Automatic medical image segmentation via convolutional neural networks (CNNs) has shown promising results. However, they may not always be robust enough for clinical use. Sub-optimal segmentation would require clinician's to manually delineate the target object, causing frustration. To address this problem, a novel interactive CNN-based segmentation framework is proposed in this work. The aim is to represent the CNN segmentation contour as B-splines by utilising B-spline explicit active surfaces (BEAS). The interactive element of the framework allows the user to precisely edit the contour in real-time, and by utilising BEAS it ensures the final contour is smooth and anatomically plausible. This framework was applied to the task of 2D segmentation of the levator hiatus from 2D ultrasound (US) images, and compared to the current clinical tools used in pelvic floor disorder clinic (4DView, GE Healthcare; Zipf, Austria). Experimental results show that: 1) the proposed framework is more robust than current state-of-the-art CNNs; 2) the perceived workload calculated via the NASA-TLX index was reduced more than half for the proposed approach in comparison to current clinical tools; and 3) the proposed tool requires at least 13 seconds less user time than the clinical tools, which was significant (p=0.001).

</p>
</details>

<details><summary><b>On quantitative Laplace-type convergence results for some exponential probability measures, with two applications</b>
<a href="https://arxiv.org/abs/2110.12922">arxiv:2110.12922</a>
&#x1F4C8; 2 <br>
<p>Valentin De Bortoli, Agn챔s Desolneux</p></summary>
<p>

**Abstract:** Laplace-type results characterize the limit of sequence of measures $(_\varepsilon)_{\varepsilon >0}$ with density w.r.t the Lebesgue measure $(\mathrm{d} _\varepsilon / \mathrm{d} \mathrm{Leb})(x) \propto \exp[-U(x)/\varepsilon]$ when the temperature $\varepsilon>0$ converges to $0$. If a limiting distribution $_0$ exists, it concentrates on the minimizers of the potential $U$. Classical results require the invertibility of the Hessian of $U$ in order to establish such asymptotics. In this work, we study the particular case of norm-like potentials $U$ and establish quantitative bounds between $_\varepsilon$ and $_0$ w.r.t. the Wasserstein distance of order $1$ under an invertibility condition of a generalized Jacobian. One key element of our proof is the use of geometric measure theory tools such as the coarea formula. We apply our results to the study of maximum entropy models (microcanonical/macrocanonical distributions) and to the convergence of the iterates of the Stochastic Gradient Langevin Dynamics (SGLD) algorithm at low temperatures for non-convex minimization.

</p>
</details>

<details><summary><b>On Slowly-varying Non-stationary Bandits</b>
<a href="https://arxiv.org/abs/2110.12916">arxiv:2110.12916</a>
&#x1F4C8; 2 <br>
<p>Ramakrishnan Krishnamurthy, Aditya Gopalan</p></summary>
<p>

**Abstract:** We consider minimisation of dynamic regret in non-stationary bandits with a slowly varying property. Namely, we assume that arms' rewards are stochastic and independent over time, but that the absolute difference between the expected rewards of any arm at any two consecutive time-steps is at most a drift limit $灌> 0$. For this setting that has not received enough attention in the past, we give a new algorithm which extends naturally the well-known Successive Elimination algorithm to the non-stationary bandit setting. We establish the first instance-dependent regret upper bound for slowly varying non-stationary bandits. The analysis in turn relies on a novel characterization of the instance as a detectable gap profile that depends on the expected arm reward differences. We also provide the first minimax regret lower bound for this problem, enabling us to show that our algorithm is essentially minimax optimal. Also, this lower bound we obtain matches that of the more general total variation-budgeted bandits problem, establishing that the seemingly easier former problem is at least as hard as the more general latter problem in the minimax sense. We complement our theoretical results with experimental illustrations.

</p>
</details>

<details><summary><b>Revealing unforeseen diagnostic image features with deep learning by detecting cardiovascular diseases from apical four-chamber ultrasounds</b>
<a href="https://arxiv.org/abs/2110.12915">arxiv:2110.12915</a>
&#x1F4C8; 2 <br>
<p>Li-Hsin Cheng, Pablo B. J. Bosch, Rutger F. H. Hofman, Timo B. Brakenhoff, Eline F. Bruggemans, Rob J. van der Geest, Eduard R. Holman</p></summary>
<p>

**Abstract:** Background. With the rise of highly portable, wireless, and low-cost ultrasound devices and automatic ultrasound acquisition techniques, an automated interpretation method requiring only a limited set of views as input could make preliminary cardiovascular disease diagnoses more accessible. In this study, we developed a deep learning (DL) method for automated detection of impaired left ventricular (LV) function and aortic valve (AV) regurgitation from apical four-chamber (A4C) ultrasound cineloops and investigated which anatomical structures or temporal frames provided the most relevant information for the DL model to enable disease classification.
  Methods and Results. A4C ultrasounds were extracted from 3,554 echocardiograms of patients with either impaired LV function (n=928), AV regurgitation (n=738), or no significant abnormalities (n=1,888). Two convolutional neural networks (CNNs) were trained separately to classify the respective disease cases against normal cases. The overall classification accuracy of the impaired LV function detection model was 86%, and that of the AV regurgitation detection model was 83%. Feature importance analyses demonstrated that the LV myocardium and mitral valve were important for detecting impaired LV function, while the tip of the mitral valve anterior leaflet, during opening, was considered important for detecting AV regurgitation.
  Conclusion. The proposed method demonstrated the feasibility of a 3D CNN approach in detection of impaired LV function and AV regurgitation using A4C ultrasound cineloops. The current research shows that DL methods can exploit large training data to detect diseases in a different way than conventionally agreed upon methods, and potentially reveal unforeseen diagnostic image features.

</p>
</details>

<details><summary><b>DECAF: Generating Fair Synthetic Data Using Causally-Aware Generative Networks</b>
<a href="https://arxiv.org/abs/2110.12884">arxiv:2110.12884</a>
&#x1F4C8; 2 <br>
<p>Boris van Breugel, Trent Kyono, Jeroen Berrevoets, Mihaela van der Schaar</p></summary>
<p>

**Abstract:** Machine learning models have been criticized for reflecting unfair biases in the training data. Instead of solving for this by introducing fair learning algorithms directly, we focus on generating fair synthetic data, such that any downstream learner is fair. Generating fair synthetic data from unfair data - while remaining truthful to the underlying data-generating process (DGP) - is non-trivial. In this paper, we introduce DECAF: a GAN-based fair synthetic data generator for tabular data. With DECAF we embed the DGP explicitly as a structural causal model in the input layers of the generator, allowing each variable to be reconstructed conditioned on its causal parents. This procedure enables inference time debiasing, where biased edges can be strategically removed for satisfying user-defined fairness requirements. The DECAF framework is versatile and compatible with several popular definitions of fairness. In our experiments, we show that DECAF successfully removes undesired bias and - in contrast to existing methods - is capable of generating high-quality synthetic data. Furthermore, we provide theoretical guarantees on the generator's convergence and the fairness of downstream models.

</p>
</details>

<details><summary><b>Actions Speak Louder than Listening: Evaluating Music Style Transfer based on Editing Experience</b>
<a href="https://arxiv.org/abs/2110.12855">arxiv:2110.12855</a>
&#x1F4C8; 2 <br>
<p>Wei-Tsung Lu, Meng-Hsuan Wu, Yuh-Ming Chiu, Li Su</p></summary>
<p>

**Abstract:** The subjective evaluation of music generation techniques has been mostly done with questionnaire-based listening tests while ignoring the perspectives from music composition, arrangement, and soundtrack editing. In this paper, we propose an editing test to evaluate users' editing experience of music generation models in a systematic way. To do this, we design a new music style transfer model combining the non-chronological inference architecture, autoregressive models and the Transformer, which serves as an improvement from the baseline model on the same style transfer task. Then, we compare the performance of the two models with a conventional listening test and the proposed editing test, in which the quality of generated samples is assessed by the amount of effort (e.g., the number of required keyboard and mouse actions) spent by users to polish a music clip. Results on two target styles indicate that the improvement over the baseline model can be reflected by the editing test quantitatively. Also, the editing test provides profound insights which are not accessible from usual listening tests. The major contribution of this paper is the systematic presentation of the editing test and the corresponding insights, while the proposed music style transfer model based on state-of-the-art neural networks represents another contribution.

</p>
</details>

<details><summary><b>DP-XGBoost: Private Machine Learning at Scale</b>
<a href="https://arxiv.org/abs/2110.12770">arxiv:2110.12770</a>
&#x1F4C8; 2 <br>
<p>Nicolas Grislain, Joan Gonzalvez</p></summary>
<p>

**Abstract:** The big-data revolution announced ten years ago does not seem to have fully happened at the expected scale. One of the main obstacle to this, has been the lack of data circulation. And one of the many reasons people and organizations did not share as much as expected is the privacy risk associated with data sharing operations. There has been many works on practical systems to compute statistical queries with Differential Privacy (DP). There have also been practical implementations of systems to train Neural Networks with DP, but relatively little efforts have been dedicated to designing scalable classical Machine Learning (ML) models providing DP guarantees. In this work we describe and implement a DP fork of a battle tested ML model: XGBoost. Our approach beats by a large margin previous attempts at the task, in terms of accuracy achieved for a given privacy budget. It is also the only DP implementation of boosted trees that scales to big data and can run in distributed environments such as: Kubernetes, Dask or Apache Spark.

</p>
</details>

<details><summary><b>Maximum Correntropy Criterion Regression models with tending-to-zero scale parameters</b>
<a href="https://arxiv.org/abs/2110.12751">arxiv:2110.12751</a>
&#x1F4C8; 2 <br>
<p>Ying Jing, Lianqiang Yang</p></summary>
<p>

**Abstract:** Maximum correntropy criterion regression (MCCR) models have been well studied within the frame of statistical learning when the scale parameters take fixed values or go to infinity. This paper studies the MCCR models with tending-to-zero scale parameters. It is revealed that the optimal learning rate of MCCR models is ${\mathcal{O}}(n^{-1})$ in the asymptotic sense when the sample size $n$ goes to infinity. In the case of finite samples, the performances on robustness of MCCR, Huber and the least square regression models are compared. The applications of these three methods on real data are also displayed.

</p>
</details>

<details><summary><b>Practical Galaxy Morphology Tools from Deep Supervised Representation Learning</b>
<a href="https://arxiv.org/abs/2110.12735">arxiv:2110.12735</a>
&#x1F4C8; 2 <br>
<p>Mike Walmsley, Anna M. M. Scaife, Chris Lintott, Michelle Lochner, Verlon Etsebeth, Tobias G챕ron, Hugh Dickinson, Lucy Fortson, Sandor Kruk, Karen L. Masters, Kameswara Bharadwaj Mantha, Brooke D. Simmons</p></summary>
<p>

**Abstract:** Astronomers have typically set out to solve supervised machine learning problems by creating their own representations from scratch. We show that deep learning models trained to answer every Galaxy Zoo DECaLS question learn meaningful semantic representations of galaxies that are useful for new tasks on which the models were never trained. We exploit these representations to outperform existing approaches at several practical tasks crucial for investigating large galaxy samples. The first task is identifying galaxies of similar morphology to a query galaxy. Given a single galaxy assigned a free text tag by humans (e.g. `#diffuse'), we can find galaxies matching that tag for most tags. The second task is identifying the most interesting anomalies to a particular researcher. Our approach is 100\% accurate at identifying the most interesting 100 anomalies (as judged by Galaxy Zoo 2 volunteers). The third task is adapting a model to solve a new task using only a small number of newly-labelled galaxies. Models fine-tuned from our representation are better able to identify ring galaxies than models fine-tuned from terrestrial images (ImageNet) or trained from scratch. We solve each task with very few new labels; either one (for the similarity search) or several hundred (for anomaly detection or fine-tuning). This challenges the longstanding view that deep supervised methods require new large labelled datasets for practical use in astronomy. To help the community benefit from our pretrained models, we release our fine-tuning code zoobot. Zoobot is accessible to researchers with no prior experience in deep learning.

</p>
</details>

<details><summary><b>Learning Stochastic Shortest Path with Linear Function Approximation</b>
<a href="https://arxiv.org/abs/2110.12727">arxiv:2110.12727</a>
&#x1F4C8; 2 <br>
<p>Yifei Min, Jiafan He, Tianhao Wang, Quanquan Gu</p></summary>
<p>

**Abstract:** We study the stochastic shortest path (SSP) problem in reinforcement learning with linear function approximation, where the transition kernel is represented as a linear mixture of unknown models. We call this class of SSP problems the linear mixture SSP. We propose a novel algorithm for learning the linear mixture SSP, which can attain a $\tilde O(d B_{\star}^{1.5}\sqrt{K/c_{\min}})$ regret. Here $K$ is the number of episodes, $d$ is the dimension of the feature mapping in the mixture model, $B_{\star}$ bounds the expected cumulative cost of the optimal policy, and $c_{\min}>0$ is the lower bound of the cost function. Our algorithm also applies to the case when $c_{\min} = 0$, where a $\tilde O(K^{2/3})$ regret is guaranteed. To the best of our knowledge, this is the first algorithm with a sublinear regret guarantee for learning linear mixture SSP. In complement to the regret upper bounds, we also prove a lower bound of $廓(d B_{\star} \sqrt{K})$, which nearly matches our upper bound.

</p>
</details>

<details><summary><b>A Distillation Learning Model of Adaptive Structural Deep Belief Network for AffectNet: Facial Expression Image Database</b>
<a href="https://arxiv.org/abs/2110.12717">arxiv:2110.12717</a>
&#x1F4C8; 2 <br>
<p>Takumi Ichimura, Shin Kamada</p></summary>
<p>

**Abstract:** Deep Learning has a hierarchical network architecture to represent the complicated feature of input patterns. We have developed the adaptive structure learning method of Deep Belief Network (DBN) that can discover an optimal number of hidden neurons for given input data in a Restricted Boltzmann Machine (RBM) by neuron generation-annihilation algorithm, and can obtain the appropriate number of hidden layers in DBN. In this paper, our model is applied to a facial expression image data set, AffectNet. The system has higher classification capability than the traditional CNN. However, our model was not able to classify some test cases correctly because human emotions contain many ambiguous features or patterns leading wrong answer by two or more annotators who have different subjective judgment for a facial image. In order to represent such cases, this paper investigated a distillation learning model of Adaptive DBN. The original trained model can be seen as a parent model and some child models are trained for some mis-classified cases. For the difference between the parent model and the child one, KL divergence is monitored and then some appropriate new neurons at the parent model are generated according to KL divergence to improve classification accuracy. In this paper, the classification accuracy was improved from 78.4% to 91.3% by the proposed method.

</p>
</details>

<details><summary><b>An Adaptive Structural Learning of Deep Belief Network for Image-based Crack Detection in Concrete Structures Using SDNET2018</b>
<a href="https://arxiv.org/abs/2110.12700">arxiv:2110.12700</a>
&#x1F4C8; 2 <br>
<p>Shin Kamada, Takumi Ichimura, Takashi Iwasaki</p></summary>
<p>

**Abstract:** We have developed an adaptive structural Deep Belief Network (Adaptive DBN) that finds an optimal network structure in a self-organizing manner during learning. The Adaptive DBN is the hierarchical architecture where each layer employs Adaptive Restricted Boltzmann Machine (Adaptive RBM). The Adaptive RBM can find the appropriate number of hidden neurons during learning. The proposed method was applied to a concrete image benchmark data set SDNET2018 for crack detection. The dataset contains about 56,000 crack images for three types of concrete structures: bridge decks, walls, and paved roads. The fine-tuning method of the Adaptive DBN can show 99.7%, 99.7%, and 99.4% classification accuracy for three types of structures. However, we found the database included some wrong annotated data which cannot be judged from images by human experts. This paper discusses consideration that purses the major factor for the wrong cases and the removal of the adversarial examples from the dataset.

</p>
</details>

<details><summary><b>Automatic Extraction of Road Networks from Satellite Images by using Adaptive Structural Deep Belief Network</b>
<a href="https://arxiv.org/abs/2110.12684">arxiv:2110.12684</a>
&#x1F4C8; 2 <br>
<p>Shin Kamada, Takumi Ichimura</p></summary>
<p>

**Abstract:** In our research, an adaptive structural learning method of Restricted Boltzmann Machine (RBM) and Deep Belief Network (DBN) has been developed as one of prominent deep learning models. The neuron generation-annihilation in RBM and layer generation algorithms in DBN make an optimal network structure for given input during the learning. In this paper, our model is applied to an automatic recognition method of road network system, called RoadTracer. RoadTracer can generate a road map on the ground surface from aerial photograph data. In the iterative search algorithm, a CNN is trained to find network graph connectivities between roads with high detection capability. However, the system takes a long calculation time for not only the training phase but also the inference phase, then it may not realize high accuracy. In order to improve the accuracy and the calculation time, our Adaptive DBN was implemented on the RoadTracer instead of the CNN. The performance of our developed model was evaluated on a satellite image in the suburban area, Japan. Our Adaptive DBN had an advantage of not only the detection accuracy but also the inference time compared with the conventional CNN in the experiment results.

</p>
</details>

<details><summary><b>TODSum: Task-Oriented Dialogue Summarization with State Tracking</b>
<a href="https://arxiv.org/abs/2110.12680">arxiv:2110.12680</a>
&#x1F4C8; 2 <br>
<p>Lulu Zhao, Fujia Zheng, Keqing He, Weihao Zeng, Yuejie Lei, Huixing Jiang, Wei Wu, Weiran Xu, Jun Guo, Fanyu Meng</p></summary>
<p>

**Abstract:** Previous dialogue summarization datasets mainly focus on open-domain chitchat dialogues, while summarization datasets for the broadly used task-oriented dialogue haven't been explored yet. Automatically summarizing such task-oriented dialogues can help a business collect and review needs to improve the service. Besides, previous datasets pay more attention to generate good summaries with higher ROUGE scores, but they hardly understand the structured information of dialogues and ignore the factuality of summaries. In this paper, we introduce a large-scale public Task-Oriented Dialogue Summarization dataset, TODSum, which aims to summarize the key points of the agent completing certain tasks with the user. Compared to existing work, TODSum suffers from severe scattered information issues and requires strict factual consistency, which makes it hard to directly apply recent dialogue summarization models. Therefore, we introduce additional dialogue state knowledge for TODSum to enhance the faithfulness of generated summaries. We hope a better understanding of conversational content helps summarization models generate concise and coherent summaries. Meanwhile, we establish a comprehensive benchmark for TODSum and propose a state-aware structured dialogue summarization model to integrate dialogue state information and dialogue history. Exhaustive experiments and qualitative analysis prove the effectiveness of dialogue structure guidance. Finally, we discuss the current issues of TODSum and potential development directions for future work.

</p>
</details>

<details><summary><b>Mlr3spatiotempcv: Spatiotemporal resampling methods for machine learning in R</b>
<a href="https://arxiv.org/abs/2110.12674">arxiv:2110.12674</a>
&#x1F4C8; 2 <br>
<p>Patrick Schratz, Marc Becker, Michel Lang, Alexander Brenning</p></summary>
<p>

**Abstract:** Spatial and spatiotemporal machine-learning models require a suitable framework for their model assessment, model selection, and hyperparameter tuning, in order to avoid error estimation bias and over-fitting. This contribution reviews the state-of-the-art in spatial and spatiotemporal CV, and introduces the \proglang{R} package mlr3spatiotempcv as an extension package of the machine-learning framework \textbf{mlr3}. Currently various \proglang{R} packages implementing different spatiotemporal partitioning strategies exist: \pkg{blockCV}, \pkg{CAST}, \pkg{kmeans} and \pkg{sperrorest}. The goal of \pkg{mlr3spatiotempcv} is to gather the available spatiotemporal resampling methods in \proglang{R} and make them available to users through a simple and common interface. This is made possible by integrating the package directly into the \pkg{mlr3} machine-learning framework, which already has support for generic non-spatiotemporal resampling methods such as random partitioning. One advantage is the use of a consistent nomenclature in an overarching machine-learning toolkit instead of a varying package-specific syntax, making it easier for users to choose from a variety of spatiotemporal resampling methods. This package avoids giving recommendations which method to use in practice as this decision depends on the predictive task at hand, the autocorrelation within the data, and the spatial structure of the sampling design or geographic objects being studied.

</p>
</details>

<details><summary><b>Sampling-Based Robust Control of Autonomous Systems with Non-Gaussian Noise</b>
<a href="https://arxiv.org/abs/2110.12662">arxiv:2110.12662</a>
&#x1F4C8; 2 <br>
<p>Thom S. Badings, Alessandro Abate, Nils Jansen, David Parker, Hasan A. Poonawala, Marielle Stoelinga</p></summary>
<p>

**Abstract:** Controllers for autonomous systems that operate in safety-critical settings must account for stochastic disturbances. Such disturbances are often modelled as process noise, and common assumptions are that the underlying distributions are known and/or Gaussian. In practice, however, these assumptions may be unrealistic and can lead to poor approximations of the true noise distribution. We present a novel planning method that does not rely on any explicit representation of the noise distributions. In particular, we address the problem of computing a controller that provides probabilistic guarantees on safely reaching a target. First, we abstract the continuous system into a discrete-state model that captures noise by probabilistic transitions between states. As a key contribution, we adapt tools from the scenario approach to compute probably approximately correct (PAC) bounds on these transition probabilities, based on a finite number of samples of the noise. We capture these bounds in the transition probability intervals of a so-called interval Markov decision process (iMDP). This iMDP is robust against uncertainty in the transition probabilities, and the tightness of the probability intervals can be controlled through the number of samples. We use state-of-the-art verification techniques to provide guarantees on the iMDP, and compute a controller for which these guarantees carry over to the autonomous system. Realistic benchmarks show the practical applicability of our method, even when the iMDP has millions of states or transitions.

</p>
</details>

<details><summary><b>Medium Access Control protocol for Collaborative Spectrum Learning in Wireless Networks</b>
<a href="https://arxiv.org/abs/2111.12581">arxiv:2111.12581</a>
&#x1F4C8; 1 <br>
<p>Tomer Boyarski, Amir Leshem</p></summary>
<p>

**Abstract:** In recent years there is a growing effort to provide learning algorithms for spectrum collaboration. In this paper we present a medium access control protocol which allows spectrum collaboration with minimal regret and high spectral efficiency in highly loaded networks. We present a fully-distributed algorithm for spectrum collaboration in congested ad-hoc networks. The algorithm jointly solves both the channel allocation and access scheduling problems. We prove that the algorithm has an optimal logarithmic regret. Based on the algorithm we provide a medium access control protocol which allows distributed implementation of the algorithm in ad-hoc networks. The protocol utilizes single-channel opportunistic carrier sensing to carry out a low-complexity distributed auction in time and frequency. We also discuss practical implementation issues such as bounded frame size and speed of convergence. Computer simulations comparing the algorithm to state-of-the-art distributed medium access control protocols show the significant advantage of the proposed scheme.

</p>
</details>

<details><summary><b>The Invisible COVID-19 Crisis: Post-Traumatic Stress Disorder Risk Among Frontline Physicians Treating COVID-19 Patients</b>
<a href="https://arxiv.org/abs/2111.04441">arxiv:2111.04441</a>
&#x1F4C8; 1 <br>
<p>Sayanti Mukherjee, Lance Rintamaki, Janet L. Shucard, Zhiyuan Wei, Lindsey E. Carlasare, Christine A. Sinsky</p></summary>
<p>

**Abstract:** This study evaluated post traumatic stress disorder (PTSD) among frontline US physicians (treating COVID-19 patients) in comparison with second-line physicians (not treating COVID-19 patients), and identified the significance and patterns of factors associated with higher PTSD risk. A cross-sectional, web-based survey was deployed during August and September, 2020, to practicing physicians in the 18 states with the largest COVID-19 cases. Among 1,478 responding physicians, 1,017 completed the PTSD Checklist (PCL-5). First, the PCL-5 was used to compare symptom endorsement between the two physician groups. A greater percentage of frontline than second-line physicians had clinically significant endorsement of PCL-5 symptoms and higher PCL-5 scores. Second, logistic regression and seven nonlinear machine learning (ML) algorithms were leveraged to identify potential predictors of PTSD risk by analyzing variable importance and partial dependence plots. Predictors of PTSD risk included cognitive/psychological measures, occupational characteristics, work experiences, social support, demographics, and workplace characteristics. Importantly, the final ML model random forest, identified patterns of both damaging and protective predictors of PTSD risk among frontline physicians. Key damaging factors included depression, burnout, negative coping, fears of contracting/transmitting COVID-19, perceived stigma, and insufficient resources to treat COVID-19 patients. Protective factors included resilience and support from employers/friends/family/significant others. This study underscores the value of ML algorithms to uncover nonlinear relationships among protective/damaging risk factors for PTSD in frontline physicians, which may better inform interventions to prepare healthcare systems for future epidemics/pandemics.

</p>
</details>

<details><summary><b>Modeling Category-Selective Cortical Regions with Topographic Variational Autoencoders</b>
<a href="https://arxiv.org/abs/2110.13911">arxiv:2110.13911</a>
&#x1F4C8; 1 <br>
<p>T. Anderson Keller, Qinghe Gao, Max Welling</p></summary>
<p>

**Abstract:** Category-selectivity in the brain describes the observation that certain spatially localized areas of the cerebral cortex tend to respond robustly and selectively to stimuli from specific limited categories. One of the most well known examples of category-selectivity is the Fusiform Face Area (FFA), an area of the inferior temporal cortex in primates which responds preferentially to images of faces when compared with objects or other generic stimuli. In this work, we leverage the newly introduced Topographic Variational Autoencoder to model of the emergence of such localized category-selectivity in an unsupervised manner. Experimentally, we demonstrate our model yields spatially dense neural clusters selective to faces, bodies, and places through visualized maps of Cohen's d metric. We compare our model with related supervised approaches, namely the TDANN, and discuss both theoretical and empirical similarities. Finally, we show preliminary results suggesting that our model yields a nested spatial hierarchy of increasingly abstract categories, analogous to observations from the human ventral temporal cortex.

</p>
</details>

<details><summary><b>CLLD: Contrastive Learning with Label Distance for Text Classificatioin</b>
<a href="https://arxiv.org/abs/2110.13656">arxiv:2110.13656</a>
&#x1F4C8; 1 <br>
<p>Jinhe Lan, Qingyuan Zhan, Chenhao Jiang, Kunping Yuan, Desheng Wang</p></summary>
<p>

**Abstract:** Existed pre-trained models have achieved state-of-the-art performance on various text classification tasks. These models have proven to be useful in learning universal language representations. However, the semantic discrepancy between similar texts cannot be effectively distinguished by advanced pre-trained models, which have a great influence on the performance of hard-to-distinguish classes. To address this problem, we propose a novel Contrastive Learning with Label Distance (CLLD) in this work. Inspired by recent advances in contrastive learning, we specifically design a classification method with label distance for learning contrastive classes. CLLD ensures the flexibility within the subtle differences that lead to different label assignments, and generates the distinct representations for each class having similarity simultaneously. Extensive experiments on public benchmarks and internal datasets demonstrate that our method improves the performance of pre-trained models on classification tasks. Importantly, our experiments suggest that the learned label distance relieve the adversarial nature of interclasses.

</p>
</details>

<details><summary><b>Revisiting randomized choices in isolation forests</b>
<a href="https://arxiv.org/abs/2110.13402">arxiv:2110.13402</a>
&#x1F4C8; 1 <br>
<p>David Cortes</p></summary>
<p>

**Abstract:** Isolation forest or "iForest" is an intuitive and widely used algorithm for anomaly detection that follows a simple yet effective idea: in a given data distribution, if a threshold (split point) is selected uniformly at random within the range of some variable and data points are divided according to whether they are greater or smaller than this threshold, outlier points are more likely to end up alone or in the smaller partition. The original procedure suggested the choice of variable to split and split point within a variable to be done uniformly at random at each step, but this paper shows that "clustered" diverse outliers - oftentimes a more interesting class of outliers than others - can be more easily identified by applying a non-uniformly-random choice of variables and/or thresholds. Different split guiding criteria are compared and some are found to result in significantly better outlier discrimination for certain classes of outliers.

</p>
</details>

<details><summary><b>Scale-Free Adversarial Multi-Armed Bandit with Arbitrary Feedback Delays</b>
<a href="https://arxiv.org/abs/2110.13400">arxiv:2110.13400</a>
&#x1F4C8; 1 <br>
<p>Jiatai Huang, Yan Dai, Longbo Huang</p></summary>
<p>

**Abstract:** We consider the Scale-Free Adversarial Multi Armed Bandit (MAB) problem with unrestricted feedback delays. In contrast to the standard assumption that all losses are $[0,1]$-bounded, in our setting, losses can fall in a general bounded interval $[-L, L]$, unknown to the agent before-hand. Furthermore, the feedback of each arm pull can experience arbitrary delays. We propose an algorithm named \texttt{SFBanker} for this novel setting, which combines a recent banker online mirror descent technique and elaborately designed doubling tricks. We show that \texttt{SFBanker} achieves $\mathcal O(\sqrt{K(D+T)}L)\cdot {\rm polylog}(T, L)$ total regret, where $T$ is the total number of steps and $D$ is the total feedback delay. \texttt{SFBanker} also outperforms existing algorithm for non-delayed (i.e., $D=0$) scale-free adversarial MAB problem instances. We also present a variant of \texttt{SFBanker} for problem instances with non-negative losses (i.e., they range in $[0, L]$ for some unknown $L$), achieving an $\tilde{\mathcal O}(\sqrt{K(D+T)}L)$ total regret, which is near-optimal compared to the $廓(\sqrt{KT}+\sqrt{D\log K}L)$ lower-bound ([Cesa-Bianchi et al., 2016]).

</p>
</details>

<details><summary><b>Physics Informed Machine Learning of SPH: Machine Learning Lagrangian Turbulence</b>
<a href="https://arxiv.org/abs/2110.13311">arxiv:2110.13311</a>
&#x1F4C8; 1 <br>
<p>Michael Woodward, Yifeng Tian, Criston Hyett, Chris Fryer, Daniel Livescu, Mikhail Stepanov, Michael Chertkov</p></summary>
<p>

**Abstract:** Smoothed particle hydrodynamics (SPH) is a mesh-free Lagrangian method for obtaining approximate numerical solutions of the equations of fluid dynamics; which has been widely applied to weakly- and strongly compressible turbulence in astrophysics and engineering applications. We present a learn-able hierarchy of parameterized and "physics-explainable" SPH informed fluid simulators using both physics based parameters and Neural Networks (NNs) as universal function approximators. Our learning algorithm develops a mixed mode approach, mixing forward and reverse mode automatic differentiation with forward and adjoint based sensitivity analyses to efficiently perform gradient based optimization. We show that our physics informed learning method is capable of: (a) solving inverse problems over the physically interpretable parameter space, as well as over the space of NN parameters; (b) learning Lagrangian statistics of turbulence (interpolation); (c) combining Lagrangian trajectory based, probabilistic, and Eulerian field based loss functions; and (d) extrapolating beyond training sets into more complex regimes of interest. Furthermore, this hierarchy of models gradually introduces more physical structure, which we show improves interpretability, generalizability (over larger ranges of time scales and Reynolds numbers), preservation of physical symmetries, and requires less training data.

</p>
</details>

<details><summary><b>On the Second-order Convergence Properties of Random Search Methods</b>
<a href="https://arxiv.org/abs/2110.13265">arxiv:2110.13265</a>
&#x1F4C8; 1 <br>
<p>Aurelien Lucchi, Antonio Orvieto, Adamos Solomou</p></summary>
<p>

**Abstract:** We study the theoretical convergence properties of random-search methods when optimizing non-convex objective functions without having access to derivatives. We prove that standard random-search methods that do not rely on second-order information converge to a second-order stationary point. However, they suffer from an exponential complexity in terms of the input dimension of the problem. In order to address this issue, we propose a novel variant of random search that exploits negative curvature by only relying on function evaluations. We prove that this approach converges to a second-order stationary point at a much faster rate than vanilla methods: namely, the complexity in terms of the number of function evaluations is only linear in the problem dimension. We test our algorithm empirically and find good agreements with our theoretical results.

</p>
</details>

<details><summary><b>Integrative Clustering of Multi-View Data by Nonnegative Matrix Factorization</b>
<a href="https://arxiv.org/abs/2110.13240">arxiv:2110.13240</a>
&#x1F4C8; 1 <br>
<p>Shuo Shuo Liu, Lin Lin</p></summary>
<p>

**Abstract:** Learning multi-view data is an emerging problem in machine learning research, and nonnegative matrix factorization (NMF) is a popular dimensionality-reduction method for integrating information from multiple views. These views often provide not only consensus but also diverse information. However, most multi-view NMF algorithms assign equal weight to each view or tune the weight via line search empirically, which can be computationally expensive or infeasible without any prior knowledge of the views. In this paper, we propose a weighted multi-view NMF (WM-NMF) algorithm. In particular, we aim to address the critical technical gap, which is to learn both view-specific and observation-specific weights to quantify each view's information content. The introduced weighting scheme can alleviate unnecessary views' adverse effects and enlarge the positive effects of the important views by assigning smaller and larger weights, respectively. In addition, we provide theoretical investigations about the convergence, perturbation analysis, and generalization error of the WM-NMF algorithm. Experimental results confirm the effectiveness and advantages of the proposed algorithm in terms of achieving better clustering performance and dealing with the corrupted data compared to the existing algorithms.

</p>
</details>

<details><summary><b>Decomposed Inductive Procedure Learning</b>
<a href="https://arxiv.org/abs/2110.13233">arxiv:2110.13233</a>
&#x1F4C8; 1 <br>
<p>Daniel Weitekamp, Christopher MacLellan, Erik Harpstead, Kenneth Koedinger</p></summary>
<p>

**Abstract:** Recent advances in machine learning have made it possible to train artificially intelligent agents that perform with super-human accuracy on a great diversity of complex tasks. However, the process of training these capabilities often necessitates millions of annotated examples -- far more than humans typically need in order to achieve a passing level of mastery on similar tasks. Thus, while contemporary methods in machine learning can produce agents that exhibit super-human performance, their rate of learning per opportunity in many domains is decidedly lower than human-learning. In this work we formalize a theory of Decomposed Inductive Procedure Learning (DIPL) that outlines how different forms of inductive symbolic learning can be used in combination to build agents that learn educationally relevant tasks such as mathematical, and scientific procedures, at a rate similar to human learners. We motivate the construction of this theory along Marr's concepts of the computational, algorithmic, and implementation levels of cognitive modeling, and outline at the computational-level six learning capacities that must be achieved to accurately model human learning. We demonstrate that agents built along the DIPL theory are amenable to satisfying these capacities, and demonstrate, both empirically and theoretically, that DIPL enables the creation of agents that exhibit human-like learning performance.

</p>
</details>

<details><summary><b>Probabilistic Hierarchical Forecasting with Deep Poisson Mixtures</b>
<a href="https://arxiv.org/abs/2110.13179">arxiv:2110.13179</a>
&#x1F4C8; 1 <br>
<p>Kin G. Olivares, O. Nganba Meetei, Ruijun Ma, Rohan Reddy, Mengfei Cao, Lee Dicker</p></summary>
<p>

**Abstract:** Hierarchical forecasting problems arise when time series have a natural group structure, and predictions at multiple levels of aggregation and disaggregation across the groups are needed. In such problems, it is often desired to satisfy the aggregation constraints in a given hierarchy, referred to as hierarchical coherence in the literature. Maintaining hierarchical coherence while producing accurate forecasts can be a challenging problem, especially in the case of probabilistic forecasting. We present a novel method capable of accurate and coherent probabilistic forecasts for hierarchical time series. We call it Deep Poisson Mixture Network (DPMN). It relies on the combination of neural networks and a statistical model for the joint distribution of the hierarchical multivariate time series structure. By construction, the model guarantees hierarchical coherence and provides simple rules for aggregation and disaggregation of the predictive distributions. We perform an extensive empirical evaluation comparing the DPMN to other state-of-the-art methods which produce hierarchically coherent probabilistic forecasts on multiple public datasets. Compared to existing coherent probabilistic models, we obtained a relative improvement in the overall Continuous Ranked Probability Score (CRPS) of 17.1% on Australian domestic tourism data, 24.2 on the Favorita grocery sales dataset, and 6.9% on a San Francisco Bay Area highway traffic dataset.

</p>
</details>

<details><summary><b>Faster Perturbed Stochastic Gradient Methods for Finding Local Minima</b>
<a href="https://arxiv.org/abs/2110.13144">arxiv:2110.13144</a>
&#x1F4C8; 1 <br>
<p>Zixiang Chen, Dongruo Zhou, Quanquan Gu</p></summary>
<p>

**Abstract:** Escaping from saddle points and finding local minima is a central problem in nonconvex optimization. Perturbed gradient methods are perhaps the simplest approach for this problem. However, to find $(琯, \sqrt琯)$-approximate local minima, the existing best stochastic gradient complexity for this type of algorithms is $\tilde O(琯^{-3.5})$, which is not optimal. In this paper, we propose \texttt{Pullback}, a faster perturbed stochastic gradient framework for finding local minima. We show that Pullback with stochastic gradient estimators such as SARAH/SPIDER and STORM can find $(琯, 琯_{H})$-approximate local minima within $\tilde O(琯^{-3} + 琯_{H}^{-6})$ stochastic gradient evaluations (or $\tilde O(琯^{-3})$ when $琯_H = \sqrt琯$). The core idea of our framework is a step-size ``pullback'' scheme to control the average movement of the iterates, which leads to faster convergence to the local minima. Experiments on matrix factorization problems corroborate our theory.

</p>
</details>

<details><summary><b>Learning-Augmented Dynamic Power Management with Multiple States via New Ski Rental Bounds</b>
<a href="https://arxiv.org/abs/2110.13116">arxiv:2110.13116</a>
&#x1F4C8; 1 <br>
<p>Antonios Antoniadis, Christian Coester, Marek Eli찼큄, Adam Polak, Bertrand Simon</p></summary>
<p>

**Abstract:** We study the online problem of minimizing power consumption in systems with multiple power-saving states. During idle periods of unknown lengths, an algorithm has to choose between power-saving states of different energy consumption and wake-up costs. We develop a learning-augmented online algorithm that makes decisions based on (potentially inaccurate) predicted lengths of the idle periods. The algorithm's performance is near-optimal when predictions are accurate and degrades gracefully with increasing prediction error, with a worst-case guarantee almost identical to the optimal classical online algorithm for the problem. A key ingredient in our approach is a new algorithm for the online ski rental problem in the learning augmented setting with tight dependence on the prediction error. We support our theoretical findings with experiments.

</p>
</details>

<details><summary><b>Shift of Pairwise Similarities for Data Clustering</b>
<a href="https://arxiv.org/abs/2110.13103">arxiv:2110.13103</a>
&#x1F4C8; 1 <br>
<p>Morteza Haghir Chehreghani</p></summary>
<p>

**Abstract:** Several clustering methods (e.g., Normalized Cut and Ratio Cut) divide the Min Cut cost function by a cluster-dependent factor (e.g., the size or the degree of the clusters), in order to yield a more balanced partitioning. We, instead, investigate adding such regularizations to the original cost function. We first consider the case where the regularization term is the sum of the squared size of the clusters, and then generalize it to adaptive regularization of the pairwise similarities. This leads to shifting (adaptively) the pairwise similarities which might make some of them negative. We then study the connection of this method to Correlation Clustering and then propose an efficient local search optimization algorithm with fast theoretical convergence rate to solve the new clustering problem. In the following, we investigate the shift of pairwise similarities on some common clustering methods, and finally, we demonstrate the superior performance of the method by extensive experiments on different datasets.

</p>
</details>

<details><summary><b>Quantum Algorithms and Lower Bounds for Linear Regression with Norm Constraints</b>
<a href="https://arxiv.org/abs/2110.13086">arxiv:2110.13086</a>
&#x1F4C8; 1 <br>
<p>Yanlin Chen, Ronald de Wolf</p></summary>
<p>

**Abstract:** Lasso and Ridge are important minimization problems in machine learning and statistics. They are versions of linear regression with squared loss where the vector $罐\in\mathbb{R}^d$ of coefficients is constrained in either $\ell_1$-norm (for Lasso) or in $\ell_2$-norm (for Ridge). We study the complexity of quantum algorithms for finding $\varepsilon$-minimizers for these minimization problems. We show that for Lasso we can get a quadratic quantum speedup in terms of $d$ by speeding up the cost-per-iteration of the Frank-Wolfe algorithm, while for Ridge the best quantum algorithms are linear in $d$, as are the best classical algorithms.

</p>
</details>

<details><summary><b>Evolutionary Optimization of High-Coverage Budgeted Classifiers</b>
<a href="https://arxiv.org/abs/2110.13067">arxiv:2110.13067</a>
&#x1F4C8; 1 <br>
<p>Nolan H. Hamilton, Errin W. Fulp</p></summary>
<p>

**Abstract:** Classifiers are often utilized in time-constrained settings where labels must be assigned to inputs quickly. To address these scenarios, budgeted multi-stage classifiers (MSC) process inputs through a sequence of partial feature acquisition and evaluation steps with early-exit options until a confident prediction can be made. This allows for fast evaluation that can prevent expensive, unnecessary feature acquisition in time-critical instances. However, performance of MSCs is highly sensitive to several design aspects -- making optimization of these systems an important but difficult problem.
  To approximate an initially intractable combinatorial problem, current approaches to MSC configuration rely on well-behaved surrogate loss functions accounting for two primary objectives (processing cost, error). These approaches have proven useful in many scenarios but are limited by analytic constraints (convexity, smoothness, etc.) and do not manage additional performance objectives. Notably, such methods do not explicitly account for an important aspect of real-time detection systems -- the ratio of "accepted" predictions satisfying some confidence criterion imposed by a risk-averse monitor.
  This paper proposes a problem-specific genetic algorithm, EMSCO, that incorporates a terminal reject option for indecisive predictions and treats MSC design as an evolutionary optimization problem with distinct objectives (accuracy, cost, coverage). The algorithm's design emphasizes Pareto efficiency while respecting a notion of aggregated performance via a unique scalarization. Experiments are conducted to demonstrate EMSCO's ability to find global optima in a variety of Theta(k^n) solution spaces, and multiple experiments show EMSCO is competitive with alternative budgeted approaches.

</p>
</details>

<details><summary><b>Debiasing Credit Scoring using Evolutionary Algorithms</b>
<a href="https://arxiv.org/abs/2110.12838">arxiv:2110.12838</a>
&#x1F4C8; 1 <br>
<p>Nigel Kingsman</p></summary>
<p>

**Abstract:** This paper investigates the application of machine learning when training a credit decision model over real, publicly available data whilst accounting for "bias objectives". We use the term "bias objective" to describe the requirement that a trained model displays discriminatory bias against a given groups of individuals that doesn't exceed a prescribed level, where such level can be zero. This research presents an empirical study examining the tension between competing model training objectives which in all cases include one or more bias objectives.
  This work is motivated by the observation that the parties associated with creditworthiness models have requirements that can not certainly be fully met simultaneously. The research herein seeks to highlight the impracticality of satisfying all parties' objectives, demonstrating the need for "trade-offs" to be made. The results and conclusions presented by this paper are of particular importance for all stakeholders within the credit scoring industry that rely upon artificial intelligence (AI) models as part of the decision-making process when determining the creditworthiness of individuals. This paper provides an exposition of the difficulty of training AI models that are able to simultaneously satisfy multiple bias objectives whilst maintaining acceptable levels of accuracy. Stakeholders should be aware of this difficulty and should acknowledge that some degree of discriminatory bias, across a number of protected characteristics and formulations of bias, cannot be avoided.

</p>
</details>

<details><summary><b>Learning What to Memorize: Using Intrinsic Motivation to Form Useful Memory in Partially Observable Reinforcement Learning</b>
<a href="https://arxiv.org/abs/2110.12810">arxiv:2110.12810</a>
&#x1F4C8; 1 <br>
<p>Alper Demir</p></summary>
<p>

**Abstract:** Reinforcement Learning faces an important challenge in partial observable environments that has long-term dependencies. In order to learn in an ambiguous environment, an agent has to keep previous perceptions in a memory. Earlier memory based approaches use a fixed method to determine what to keep in the memory, which limits them to certain problems. In this study, we follow the idea of giving the control of the memory to the agent by allowing it to have memory-changing actions. This learning mechanism is supported by an intrinsic motivation to memorize rare observations that can help the agent to disambiguate its state in the environment. Our approach is experimented and analyzed on several partial observable tasks with long-term dependencies and compared with other memory based methods.

</p>
</details>

<details><summary><b>Algorithms for the Communication of Samples</b>
<a href="https://arxiv.org/abs/2110.12805">arxiv:2110.12805</a>
&#x1F4C8; 1 <br>
<p>Lucas Theis, Noureldin Yosri</p></summary>
<p>

**Abstract:** We consider the problem of reverse channel coding, that is, how to simulate a noisy channel over a digital channel efficiently. We propose two new coding schemes with practical advantages over previous approaches. First, we introduce ordered random coding (ORC) which uses a simple trick to reduce the coding cost of previous approaches based on importance sampling. Our derivation also illuminates a connection between these schemes and the so-called Poisson functional representation. Second, we describe a hybrid coding scheme which uses dithered quantization to efficiently communicate samples from distributions with bounded support.

</p>
</details>

<details><summary><b>Dictionary Learning Using Rank-One Atomic Decomposition (ROAD)</b>
<a href="https://arxiv.org/abs/2110.12786">arxiv:2110.12786</a>
&#x1F4C8; 1 <br>
<p>Cheng Cheng, Wei Dai</p></summary>
<p>

**Abstract:** Dictionary learning aims at seeking a dictionary under which the training data can be sparsely represented. Methods in the literature typically formulate the dictionary learning problem as an optimization w.r.t. two variables, i.e., dictionary and sparse coefficients, and solve it by alternating between two stages: sparse coding and dictionary update. The key contribution of this work is a Rank-One Atomic Decomposition (ROAD) formulation where dictionary learning is cast as an optimization w.r.t. a single variable which is a set of rank one matrices. The resulting algorithm is hence single-stage. Compared with two-stage algorithms, ROAD minimizes the sparsity of the coefficients whilst keeping the data consistency constraint throughout the whole learning process. An alternating direction method of multipliers (ADMM) is derived to solve the optimization problem and the lower bound of the penalty parameter is computed to guarantees a global convergence despite non-convexity of the optimization formulation. From practical point of view, ROAD reduces the number of tuning parameters required in other benchmark algorithms. Numerical tests demonstrate that ROAD outperforms other benchmark algorithms for both synthetic data and real data, especially when the number of training samples is small.

</p>
</details>

<details><summary><b>SSMF: Shifting Seasonal Matrix Factorization</b>
<a href="https://arxiv.org/abs/2110.12763">arxiv:2110.12763</a>
&#x1F4C8; 1 <br>
<p>Koki Kawabata, Siddharth Bhatia, Rui Liu, Mohit Wadhwa, Bryan Hooi</p></summary>
<p>

**Abstract:** Given taxi-ride counts information between departure and destination locations, how can we forecast their future demands? In general, given a data stream of events with seasonal patterns that innovate over time, how can we effectively and efficiently forecast future events? In this paper, we propose Shifting Seasonal Matrix Factorization approach, namely SSMF, that can adaptively learn multiple seasonal patterns (called regimes), as well as switching between them. Our proposed method has the following properties: (a) it accurately forecasts future events by detecting regime shifts in seasonal patterns as the data stream evolves; (b) it works in an online setting, i.e., processes each observation in constant time and memory; (c) it effectively realizes regime shifts without human intervention by using a lossless data compression scheme. We demonstrate that our algorithm outperforms state-of-the-art baseline methods by accurately forecasting upcoming events on three real-world data streams.

</p>
</details>

<details><summary><b>DaRE: A Cross-Domain Recommender System with Domain-aware Feature Extraction and Review Encoder</b>
<a href="https://arxiv.org/abs/2110.12648">arxiv:2110.12648</a>
&#x1F4C8; 1 <br>
<p>Yoonhyuk Choi, Jiho Choi, Taewook Ko, Chongkwon Kim</p></summary>
<p>

**Abstract:** Recent advent in recommender systems, especially text-aided methods and CDR (Cross-Domain Recommendation) leads to promising results in solving data-sparsity and cold-start problems. Despite such progress, prior algorithms either require user overlapping or ignore domain-aware feature extraction. In addition, text-aided methods exceedingly emphasize aggregated documents and fail to capture the specifics embedded in individual reviews. To overcome such limitations, we propose a novel method, named DaRE (Domainaware Feature Extraction and Review Encoder), a comprehensive solution that consists of three key components; text-based representation learning, domain-aware feature extraction, and a review encoder. DaRE debilitate noises by separating domain-invariant features from domain-specific features through selective adversarial training. DaRE extracts features from aggregated documents, and the review encoder fine-tunes the representations by aligning them with the features extracted from individual reviews. Experiments on four real-world datasets show the superiority of DaRE over state-ofthe-art single-domain and cross-domain methodologies, achieving 9.2 % and 3.6 % improvements, respectively. We upload our implementations (https://anonymous.4open.science/r/DaRE-9CC9/) for a reproducibility

</p>
</details>

<details><summary><b>Task-Aware Meta Learning-based Siamese Neural Network for Classifying Obfuscated Malware</b>
<a href="https://arxiv.org/abs/2110.13409">arxiv:2110.13409</a>
&#x1F4C8; 0 <br>
<p>Jinting Zhu, Julian Jang-Jaccard, Amardeep Singh, Paul A. Watters, Seyit Camtepe</p></summary>
<p>

**Abstract:** Malware authors apply different obfuscation techniques on the generic feature of malware (i.e., unique malware signature) to create new variants to avoid detection. Existing Siamese Neural Network (SNN) based malware detection methods fail to correctly classify different malware families when similar generic features are shared across multiple malware variants resulting in high false-positive rates. To address this issue, we propose a novel Task-Aware Meta Learning-based Siamese Neural Network resilient against obfuscated malware while able to detect malware trained with one or a few training samples. Using entropy features of each malware signature alongside image features as task inputs, our task-aware meta leaner generates the parameters for the feature layers to more accurately adjust the feature embedding for different malware families. In addition, our model utilizes meta-learning with the extracted features of a pre-trained network (e.g., VGG-16) to avoid the bias typically associated with a model trained with a limited number of training samples. Our proposed approach is highly effective in recognizing unique malware signatures, thus correctly classifying malware samples that belong to the same malware family even in the presence of obfuscation technique applied to malware. Our experimental results, validated with N-way on N-shot learning, show that our model is highly effective in classification accuracy exceeding the rate>91% compared to other similar methods.

</p>
</details>

<details><summary><b>Memory visualization tool for training neural network</b>
<a href="https://arxiv.org/abs/2110.13264">arxiv:2110.13264</a>
&#x1F4C8; 0 <br>
<p>Mahendran N</p></summary>
<p>

**Abstract:** Software developed helps world a better place ranging from system software, open source, application software and so on. Software engineering does have neural network models applied to code suggestion, bug report summarizing and so on to demonstrate their effectiveness at a real SE task. Software and machine learning algorithms combine to make software give better solutions and understanding of environment. In software, there are both generalized applications which helps solve problems for entire world and also some specific applications which helps one particular community. To address the computational challenge in deep learning, many tools exploit hardware features such as multi-core CPUs and many-core GPUs to shorten the training time. Machine learning algorithms have a greater impact in the world but there is a considerable amount of memory utilization during the process. We propose a new tool for analysis of memory utilized for developing and training deep learning models. Our tool results in visual utilization of memory concurrently. Various parameters affecting the memory utilization are analysed while training. This tool helps in knowing better idea of processes or models which consumes more memory.

</p>
</details>

<details><summary><b>On Learning Prediction-Focused Mixtures</b>
<a href="https://arxiv.org/abs/2110.13221">arxiv:2110.13221</a>
&#x1F4C8; 0 <br>
<p>Abhishek Sharma, Catherine Zeng, Sanjana Narayanan, Sonali Parbhoo, Finale Doshi-Velez</p></summary>
<p>

**Abstract:** Probabilistic models help us encode latent structures that both model the data and are ideally also useful for specific downstream tasks. Among these, mixture models and their time-series counterparts, hidden Markov models, identify discrete components in the data. In this work, we focus on a constrained capacity setting, where we want to learn a model with relatively few components (e.g. for interpretability purposes). To maintain prediction performance, we introduce prediction-focused modeling for mixtures, which automatically selects the dimensions relevant to the prediction task. Our approach identifies relevant signal from the input, outperforms models that are not prediction-focused, and is easy to optimize; we also characterize when prediction-focused modeling can be expected to work.

</p>
</details>

<details><summary><b>2nd Place Solution for SODA10M Challenge 2021 -- Continual Detection Track</b>
<a href="https://arxiv.org/abs/2110.13064">arxiv:2110.13064</a>
&#x1F4C8; 0 <br>
<p>Manoj Acharya, Christopher Kanan</p></summary>
<p>

**Abstract:** In this technical report, we present our approaches for the continual object detection track of the SODA10M challenge. We adapt ResNet50-FPN as the baseline and try several improvements for the final submission model. We find that task-specific replay scheme, learning rate scheduling, model calibration, and using original image scale helps to improve performance for both large and small objects in images. Our team `hypertune28' secured the second position among 52 participants in the challenge. This work will be presented at the ICCV 2021 Workshop on Self-supervised Learning for Next-Generation Industry-level Autonomous Driving (SSLAD).

</p>
</details>

<details><summary><b>Where were my keys? -- Aggregating Spatial-Temporal Instances of Objects for Efficient Retrieval over Long Periods of Time</b>
<a href="https://arxiv.org/abs/2110.13061">arxiv:2110.13061</a>
&#x1F4C8; 0 <br>
<p>Ifrah Idrees, Zahid Hasan, Steven P. Reiss, Stefanie Tellex</p></summary>
<p>

**Abstract:** Robots equipped with situational awareness can help humans efficiently find their lost objects by leveraging spatial and temporal structure. Existing approaches to video and image retrieval do not take into account the unique constraints imposed by a moving camera with a partial view of the environment. We present a Detection-based 3-level hierarchical Association approach, D3A, to create an efficient query-able spatial-temporal representation of unique object instances in an environment. D3A performs online incremental and hierarchical learning to identify keyframes that best represent the unique objects in the environment. These keyframes are learned based on both spatial and temporal features and once identified their corresponding spatial-temporal information is organized in a key-value database. D3A allows for a variety of query patterns such as querying for objects with/without the following: 1) specific attributes, 2) spatial relationships with other objects, and 3) time slices. For a given set of 150 queries, D3A returns a small set of candidate keyframes (which occupy only 0.17% of the total sensory data) with 81.98\% mean accuracy in 11.7 ms. This is 47x faster and 33% more accurate than a baseline that naively stores the object matches (detections) in the database without associating spatial-temporal information.

</p>
</details>

<details><summary><b>AxoNN: An asynchronous, message-driven parallel framework for extreme-scale deep learning</b>
<a href="https://arxiv.org/abs/2110.13005">arxiv:2110.13005</a>
&#x1F4C8; 0 <br>
<p>Siddharth Singh, Abhinav Bhatele</p></summary>
<p>

**Abstract:** In the last few years, the memory requirements to train state-of-the-art neural networks have far exceeded the DRAM capacities of modern hardware accelerators. This has necessitated the development of efficient algorithms to train these neural networks in parallel on large-scale GPU-based clusters. Since computation is relatively inexpensive on modern GPUs, designing and implementing extremely efficient communication in these parallel training algorithms is critical for extracting the maximum performance. This paper presents AxoNN, a parallel deep learning framework that exploits asynchrony and message-driven execution to schedule neural network operations on each GPU, thereby reducing GPU idle time and maximizing hardware efficiency. By using the CPU memory as a scratch space for offloading data periodically during training, AxoNN is able to reduce GPU memory consumption by four times. This allows us to increase the number of parameters per GPU by four times, thus reducing the amount of communication and increasing performance by over 13%. When tested against large transformer models with 12-100 billion parameters on 48-384 NVIDIA Tesla V100 GPUs, AxoNN achieves a per-GPU throughput of 49.4-54.78% of theoretical peak and reduces the training time by 22-37 days (15-25% speedup) as compared to the state-of-the-art.

</p>
</details>

<details><summary><b>Neural ODE and DAE Modules for Power System Dynamic Modeling</b>
<a href="https://arxiv.org/abs/2110.12981">arxiv:2110.12981</a>
&#x1F4C8; 0 <br>
<p>Tannan Xiao, Ying Chen, Tirui He, Huizhe Guan</p></summary>
<p>

**Abstract:** The time-domain simulation is the fundamental tool for power system transient stability analysis. Accurate and reliable simulations rely on accurate dynamic component modeling. In practical power systems, dynamic component modeling has long faced the challenges of model determination and model calibration, especially with the rapid development of renewable generation and power electronics. In this paper, based on the general framework of neural ordinary differential equations (ODEs), a modified neural ODE module and a neural differential-algebraic equations (DAEs) module for power system dynamic component modeling are proposed. The modules adopt an autoencoder to raise the dimension of state variables, model the dynamics of components with artificial neural networks (ANNs), and keep the numerical integration structure. In the neural DAE module, an additional ANN is used to calculate injection currents. The neural models can be easily integrated into time-domain simulations. With datasets consisting of sampled curves of input variables and output variables, the proposed modules can be used to fulfill the tasks of parameter inference, physics-data-integrated modeling, black-box modeling, etc., and can be easily integrated into power system dynamic simulations. Some simple numerical tests are carried out in the IEEE-39 system and prove the validity and potentiality of the proposed modules.

</p>
</details>

<details><summary><b>Normative Epistemology for Lethal Autonomous Weapons Systems</b>
<a href="https://arxiv.org/abs/2110.12935">arxiv:2110.12935</a>
&#x1F4C8; 0 <br>
<p>Susannah Kate Devitt</p></summary>
<p>

**Abstract:** The rise of human-information systems, cybernetic systems, and increasingly autonomous systems requires the application of epistemic frameworks to machines and human-machine teams. This chapter discusses higher-order design principles to guide the design, evaluation, deployment, and iteration of Lethal Autonomous Weapons Systems (LAWS) based on epistemic models. Epistemology is the study of knowledge. Epistemic models consider the role of accuracy, likelihoods, beliefs, competencies, capabilities, context, and luck in the justification of actions and the attribution of knowledge. The aim is not to provide ethical justification for or against LAWS, but to illustrate how epistemological frameworks can be used in conjunction with moral apparatus to guide the design and deployment of future systems. The models discussed in this chapter aim to make Article 36 reviews of LAWS systematic, expedient, and evaluable. A Bayesian virtue epistemology is proposed to enable justified actions under uncertainty that meet the requirements of the Laws of Armed Conflict and International Humanitarian Law. Epistemic concepts can provide some of the apparatus to meet explainability and transparency requirements in the development, evaluation, deployment, and review of ethical AI.

</p>
</details>

<details><summary><b>CoProtector: Protect Open-Source Code against Unauthorized Training Usage with Data Poisoning</b>
<a href="https://arxiv.org/abs/2110.12925">arxiv:2110.12925</a>
&#x1F4C8; 0 <br>
<p>Zhensu Sun, Xiaoning Du, Fu Song, Mingze Ni, Li Li</p></summary>
<p>

**Abstract:** Github Copilot, trained on billions of lines of public code, has recently become the buzzword in the computer science research and practice community. Although it is designed to provide powerful intelligence to help developers implement safe and effective code, practitioners and researchers raise concerns about its ethical and security problems, e.g., should the copyleft licensed code be freely leveraged or insecure code be considered for training in the first place? These problems pose a significant impact on Copilot and other similar products that aim to learn knowledge from large-scale source code through deep learning models, which are inevitably on the rise with the fast development of artificial intelligence. To mitigate such impacts, we argue that there is a need to invent effective mechanisms for protecting open-source code from being exploited by deep learning models. To this end, we design and implement a prototype, CoProtector, which utilizes data poisoning techniques to arm source code repositories for defending against such exploits. Our large-scale experiments empirically show that CoProtector is effective in achieving its purpose, significantly reducing the performance of Copilot-like deep learning models while being able to stably reveal the secretly embedded watermark backdoors.

</p>
</details>

<details><summary><b>Anatomical and Diagnostic Bayesian Segmentation in Prostate MRI $-$Should Different Clinical Objectives Mandate Different Loss Functions?</b>
<a href="https://arxiv.org/abs/2110.12889">arxiv:2110.12889</a>
&#x1F4C8; 0 <br>
<p>Anindo Saha, Joeran Bosma, Jasper Linmans, Matin Hosseinzadeh, Henkjan Huisman</p></summary>
<p>

**Abstract:** We hypothesize that probabilistic voxel-level classification of anatomy and malignancy in prostate MRI, although typically posed as near-identical segmentation tasks via U-Nets, require different loss functions for optimal performance due to inherent differences in their clinical objectives. We investigate distribution, region and boundary-based loss functions for both tasks across 200 patient exams from the publicly-available ProstateX dataset. For evaluation, we conduct a thorough comparative analysis of model predictions and calibration, measured with respect to multi-class volume segmentation of the prostate anatomy (whole-gland, transitional zone, peripheral zone), as well as, patient-level diagnosis and lesion-level detection of clinically significant prostate cancer. Notably, we find that distribution-based loss functions (in particular, focal loss) are well-suited for diagnostic or panoptic segmentation tasks such as lesion detection, primarily due to their implicit property of inducing better calibration. Meanwhile, (with the exception of focal loss) both distribution and region/boundary-based loss functions perform equally well for anatomical or semantic segmentation tasks, such as quantification of organ shape, size and boundaries.

</p>
</details>

<details><summary><b>Optimal Auction Design for the Gradual Procurement of Strategic Service Provider Agents</b>
<a href="https://arxiv.org/abs/2110.12846">arxiv:2110.12846</a>
&#x1F4C8; 0 <br>
<p>Farzaneh Farhadi, Maria Chli, Nicholas R. Jennings</p></summary>
<p>

**Abstract:** We consider an outsourcing problem where a software agent procures multiple services from providers with uncertain reliabilities to complete a computational task before a strict deadline. The service consumer requires a procurement strategy that achieves the optimal balance between success probability and invocation cost. However, the service providers are self-interested and may misrepresent their private cost information if it benefits them. For such settings, we design a novel procurement auction that provides the consumer with the highest possible revenue, while giving sufficient incentives to providers to tell the truth about their costs. This auction creates a contingent plan for gradual service procurement that suggests recruiting a new provider only when the success probability of the already hired providers drops below a time-dependent threshold. To make this auction incentive compatible, we propose a novel weighted threshold payment scheme which pays the minimum among all truthful mechanisms. Using the weighted payment scheme, we also design a low-complexity near-optimal auction that reduces the computational complexity of the optimal mechanism by 99% with only marginal performance loss (less than 1%). We demonstrate the effectiveness and strength of our proposed auctions through both game theoretical and numerical analysis. The experiment results confirm that the proposed auctions exhibit 59% improvement in performance over the current state-of-the-art, by increasing success probability up to 79% and reducing invocation cost by up to 11%.

</p>
</details>


[Next Page]({{ '/2021/10/24/2021.10.24.html' | relative_url }})
