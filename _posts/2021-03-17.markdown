## Summary for 2021-03-17, created on 2021-12-23


<details><summary><b>Learning to Resize Images for Computer Vision Tasks</b>
<a href="https://arxiv.org/abs/2103.09950">arxiv:2103.09950</a>
&#x1F4C8; 54 <br>
<p>Hossein Talebi, Peyman Milanfar</p></summary>
<p>

**Abstract:** For all the ways convolutional neural nets have revolutionized computer vision in recent years, one important aspect has received surprisingly little attention: the effect of image size on the accuracy of tasks being trained for. Typically, to be efficient, the input images are resized to a relatively small spatial resolution (e.g. 224x224), and both training and inference are carried out at this resolution. The actual mechanism for this re-scaling has been an afterthought: Namely, off-the-shelf image resizers such as bilinear and bicubic are commonly used in most machine learning software frameworks. But do these resizers limit the on task performance of the trained networks? The answer is yes. Indeed, we show that the typical linear resizer can be replaced with learned resizers that can substantially improve performance. Importantly, while the classical resizers typically result in better perceptual quality of the downscaled images, our proposed learned resizers do not necessarily give better visual quality, but instead improve task performance. Our learned image resizer is jointly trained with a baseline vision model. This learned CNN-based resizer creates machine friendly visual manipulations that lead to a consistent improvement of the end task metric over the baseline model. Specifically, here we focus on the classification task with the ImageNet dataset, and experiment with four different models to learn resizers adapted to each model. Moreover, we show that the proposed resizer can also be useful for fine-tuning the classification baselines for other vision tasks. To this end, we experiment with three different baselines to develop image quality assessment (IQA) models on the AVA dataset.

</p>
</details>

<details><summary><b>Training GANs with Stronger Augmentations via Contrastive Discriminator</b>
<a href="https://arxiv.org/abs/2103.09742">arxiv:2103.09742</a>
&#x1F4C8; 40 <br>
<p>Jongheon Jeong, Jinwoo Shin</p></summary>
<p>

**Abstract:** Recent works in Generative Adversarial Networks (GANs) are actively revisiting various data augmentation techniques as an effective way to prevent discriminator overfitting. It is still unclear, however, that which augmentations could actually improve GANs, and in particular, how to apply a wider range of augmentations in training. In this paper, we propose a novel way to address these questions by incorporating a recent contrastive representation learning scheme into the GAN discriminator, coined ContraD. This "fusion" enables the discriminators to work with much stronger augmentations without increasing their training instability, thereby preventing the discriminator overfitting issue in GANs more effectively. Even better, we observe that the contrastive learning itself also benefits from our GAN training, i.e., by maintaining discriminative features between real and fake samples, suggesting a strong coherence between the two worlds: good contrastive representations are also good for GAN discriminators, and vice versa. Our experimental results show that GANs with ContraD consistently improve FID and IS compared to other recent techniques incorporating data augmentations, still maintaining highly discriminative features in the discriminator in terms of the linear evaluation. Finally, as a byproduct, we also show that our GANs trained in an unsupervised manner (without labels) can induce many conditional generative models via a simple latent sampling, leveraging the learned features of ContraD. Code is available at https://github.com/jh-jeong/ContraD.

</p>
</details>

<details><summary><b>A Practical Guide to Multi-Objective Reinforcement Learning and Planning</b>
<a href="https://arxiv.org/abs/2103.09568">arxiv:2103.09568</a>
&#x1F4C8; 30 <br>
<p>Conor F. Hayes, Roxana Rădulescu, Eugenio Bargiacchi, Johan Källström, Matthew Macfarlane, Mathieu Reymond, Timothy Verstraeten, Luisa M. Zintgraf, Richard Dazeley, Fredrik Heintz, Enda Howley, Athirai A. Irissappane, Patrick Mannion, Ann Nowé, Gabriel Ramos, Marcello Restelli, Peter Vamplew, Diederik M. Roijers</p></summary>
<p>

**Abstract:** Real-world decision-making tasks are generally complex, requiring trade-offs between multiple, often conflicting, objectives. Despite this, the majority of research in reinforcement learning and decision-theoretic planning either assumes only a single objective, or that multiple objectives can be adequately handled via a simple linear combination. Such approaches may oversimplify the underlying problem and hence produce suboptimal results. This paper serves as a guide to the application of multi-objective methods to difficult problems, and is aimed at researchers who are already familiar with single-objective reinforcement learning and planning methods who wish to adopt a multi-objective perspective on their research, as well as practitioners who encounter multi-objective decision problems in practice. It identifies the factors that may influence the nature of the desired solution, and illustrates by example how these influence the design of multi-objective decision-making systems for complex problems.

</p>
</details>

<details><summary><b>Implicit Normalizing Flows</b>
<a href="https://arxiv.org/abs/2103.09527">arxiv:2103.09527</a>
&#x1F4C8; 20 <br>
<p>Cheng Lu, Jianfei Chen, Chongxuan Li, Qiuhao Wang, Jun Zhu</p></summary>
<p>

**Abstract:** Normalizing flows define a probability distribution by an explicit invertible transformation $\boldsymbol{\mathbf{z}}=f(\boldsymbol{\mathbf{x}})$. In this work, we present implicit normalizing flows (ImpFlows), which generalize normalizing flows by allowing the mapping to be implicitly defined by the roots of an equation $F(\boldsymbol{\mathbf{z}}, \boldsymbol{\mathbf{x}})= \boldsymbol{\mathbf{0}}$. ImpFlows build on residual flows (ResFlows) with a proper balance between expressiveness and tractability. Through theoretical analysis, we show that the function space of ImpFlow is strictly richer than that of ResFlows. Furthermore, for any ResFlow with a fixed number of blocks, there exists some function that ResFlow has a non-negligible approximation error. However, the function is exactly representable by a single-block ImpFlow. We propose a scalable algorithm to train and draw samples from ImpFlows. Empirically, we evaluate ImpFlow on several classification and density modeling tasks, and ImpFlow outperforms ResFlow with a comparable amount of parameters on all the benchmarks.

</p>
</details>

<details><summary><b>STYLER: Style Factor Modeling with Rapidity and Robustness via Speech Decomposition for Expressive and Controllable Neural Text to Speech</b>
<a href="https://arxiv.org/abs/2103.09474">arxiv:2103.09474</a>
&#x1F4C8; 17 <br>
<p>Keon Lee, Kyumin Park, Daeyoung Kim</p></summary>
<p>

**Abstract:** Previous works on neural text-to-speech (TTS) have been addressed on limited speed in training and inference time, robustness for difficult synthesis conditions, expressiveness, and controllability. Although several approaches resolve some limitations, there has been no attempt to solve all weaknesses at once. In this paper, we propose STYLER, an expressive and controllable TTS framework with high-speed and robust synthesis. Our novel audio-text aligning method called Mel Calibrator and excluding autoregressive decoding enable rapid training and inference and robust synthesis on unseen data. Also, disentangled style factor modeling under supervision enlarges the controllability in synthesizing process leading to expressive TTS. On top of it, a novel noise modeling pipeline using domain adversarial training and Residual Decoding empowers noise-robust style transfer, decomposing the noise without any additional label. Various experiments demonstrate that STYLER is more effective in speed and robustness than expressive TTS with autoregressive decoding and more expressive and controllable than reading style non-autoregressive TTS. Synthesis samples and experiment results are provided via our demo page, and code is available publicly.

</p>
</details>

<details><summary><b>PredRNN: A Recurrent Neural Network for Spatiotemporal Predictive Learning</b>
<a href="https://arxiv.org/abs/2103.09504">arxiv:2103.09504</a>
&#x1F4C8; 14 <br>
<p>Yunbo Wang, Haixu Wu, Jianjin Zhang, Zhifeng Gao, Jianmin Wang, Philip S. Yu, Mingsheng Long</p></summary>
<p>

**Abstract:** The predictive learning of spatiotemporal sequences aims to generate future images by learning from the historical context, where the visual dynamics are believed to have modular structures that can be learned with compositional subsystems. This paper models these structures by presenting PredRNN, a new recurrent network, in which a pair of memory cells are explicitly decoupled, operate in nearly independent transition manners, and finally form unified representations of the complex environment. Concretely, besides the original memory cell of LSTM, this network is featured by a zigzag memory flow that propagates in both bottom-up and top-down directions across all layers, enabling the learned visual dynamics at different levels of RNNs to communicate. It also leverages a memory decoupling loss to keep the memory cells from learning redundant features. We further propose a new curriculum learning strategy to force PredRNN to learn long-term dynamics from context frames, which can be generalized to most sequence-to-sequence models. We provide detailed ablation studies to verify the effectiveness of each component. Our approach is shown to obtain highly competitive results on five datasets for both action-free and action-conditioned predictive learning scenarios.

</p>
</details>

<details><summary><b>Set-to-Sequence Methods in Machine Learning: a Review</b>
<a href="https://arxiv.org/abs/2103.09656">arxiv:2103.09656</a>
&#x1F4C8; 10 <br>
<p>Mateusz Jurewicz, Leon Strømberg-Derczynski</p></summary>
<p>

**Abstract:** Machine learning on sets towards sequential output is an important and ubiquitous task, with applications ranging from language modeling and meta-learning to multi-agent strategy games and power grid optimization. Combining elements of representation learning and structured prediction, its two primary challenges include obtaining a meaningful, permutation invariant set representation and subsequently utilizing this representation to output a complex target permutation. This paper provides a comprehensive introduction to the field as well as an overview of important machine learning methods tackling both of these key challenges, with a detailed qualitative comparison of selected model architectures.

</p>
</details>

<details><summary><b>Code-Mixing on Sesame Street: Dawn of the Adversarial Polyglots</b>
<a href="https://arxiv.org/abs/2103.09593">arxiv:2103.09593</a>
&#x1F4C8; 9 <br>
<p>Samson Tan, Shafiq Joty</p></summary>
<p>

**Abstract:** Multilingual models have demonstrated impressive cross-lingual transfer performance. However, test sets like XNLI are monolingual at the example level. In multilingual communities, it is common for polyglots to code-mix when conversing with each other. Inspired by this phenomenon, we present two strong black-box adversarial attacks (one word-level, one phrase-level) for multilingual models that push their ability to handle code-mixed sentences to the limit. The former uses bilingual dictionaries to propose perturbations and translations of the clean example for sense disambiguation. The latter directly aligns the clean example with its translations before extracting phrases as perturbations. Our phrase-level attack has a success rate of 89.75% against XLM-R-large, bringing its average accuracy of 79.85 down to 8.18 on XNLI. Finally, we propose an efficient adversarial training scheme that trains in the same number of steps as the original model and show that it improves model accuracy.

</p>
</details>

<details><summary><b>CheXbreak: Misclassification Identification for Deep Learning Models Interpreting Chest X-rays</b>
<a href="https://arxiv.org/abs/2103.09957">arxiv:2103.09957</a>
&#x1F4C8; 8 <br>
<p>Emma Chen, Andy Kim, Rayan Krishnan, Jin Long, Andrew Y. Ng, Pranav Rajpurkar</p></summary>
<p>

**Abstract:** A major obstacle to the integration of deep learning models for chest x-ray interpretation into clinical settings is the lack of understanding of their failure modes. In this work, we first investigate whether there are patient subgroups that chest x-ray models are likely to misclassify. We find that patient age and the radiographic finding of lung lesion, pneumothorax or support devices are statistically relevant features for predicting misclassification for some chest x-ray models. Second, we develop misclassification predictors on chest x-ray models using their outputs and clinical features. We find that our best performing misclassification identifier achieves an AUROC close to 0.9 for most diseases. Third, employing our misclassification identifiers, we develop a corrective algorithm to selectively flip model predictions that have high likelihood of misclassification at inference time. We observe F1 improvement on the prediction of Consolidation (0.008 [95% CI 0.005, 0.010]) and Edema (0.003, [95% CI 0.001, 0.006]). By carrying out our investigation on ten distinct and high-performing chest x-ray models, we are able to derive insights across model architectures and offer a generalizable framework applicable to other medical imaging tasks.

</p>
</details>

<details><summary><b>Infinite-Horizon Offline Reinforcement Learning with Linear Function Approximation: Curse of Dimensionality and Algorithm</b>
<a href="https://arxiv.org/abs/2103.09847">arxiv:2103.09847</a>
&#x1F4C8; 8 <br>
<p>Lin Chen, Bruno Scherrer, Peter L. Bartlett</p></summary>
<p>

**Abstract:** In this paper, we investigate the sample complexity of policy evaluation in infinite-horizon offline reinforcement learning (also known as the off-policy evaluation problem) with linear function approximation. We identify a hard regime $dγ^{2}>1$, where $d$ is the dimension of the feature vector and $γ$ is the discount rate. In this regime, for any $q\in[γ^{2},1]$, we can construct a hard instance such that the smallest eigenvalue of its feature covariance matrix is $q/d$ and it requires $Ω\left(\frac{d}{γ^{2}\left(q-γ^{2}\right)\varepsilon^{2}}\exp\left(Θ\left(dγ^{2}\right)\right)\right)$ samples to approximate the value function up to an additive error $\varepsilon$. Note that the lower bound of the sample complexity is exponential in $d$. If $q=γ^{2}$, even infinite data cannot suffice. Under the low distribution shift assumption, we show that there is an algorithm that needs at most $O\left(\max\left\{ \frac{\left\Vert θ^π\right\Vert _{2}^{4}}{\varepsilon^{4}}\log\frac{d}δ,\frac{1}{\varepsilon^{2}}\left(d+\log\frac{1}δ\right)\right\} \right)$ samples ($θ^π$ is the parameter of the policy in linear function approximation) and guarantees approximation to the value function up to an additive error of $\varepsilon$ with probability at least $1-δ$.

</p>
</details>

<details><summary><b>Generating Annotated Training Data for 6D Object Pose Estimation in Operational Environments with Minimal User Interaction</b>
<a href="https://arxiv.org/abs/2103.09696">arxiv:2103.09696</a>
&#x1F4C8; 8 <br>
<p>Paul Koch, Marian Schlüter, Serge Thill</p></summary>
<p>

**Abstract:** Recently developed deep neural networks achieved state-of-the-art results in the subject of 6D object pose estimation for robot manipulation. However, those supervised deep learning methods require expensive annotated training data. Current methods for reducing those costs frequently use synthetic data from simulations, but rely on expert knowledge and suffer from the "domain gap" when shifting to the real world. Here, we present a proof of concept for a novel approach of autonomously generating annotated training data for 6D object pose estimation. This approach is designed for learning new objects in operational environments while requiring little interaction and no expertise on the part of the user. We evaluate our autonomous data generation approach in two grasping experiments, where we archive a similar grasping success rate as related work on a non autonomously generated data set.

</p>
</details>

<details><summary><b>Gradient Projection Memory for Continual Learning</b>
<a href="https://arxiv.org/abs/2103.09762">arxiv:2103.09762</a>
&#x1F4C8; 7 <br>
<p>Gobinda Saha, Isha Garg, Kaushik Roy</p></summary>
<p>

**Abstract:** The ability to learn continually without forgetting the past tasks is a desired attribute for artificial learning systems. Existing approaches to enable such learning in artificial neural networks usually rely on network growth, importance based weight update or replay of old data from the memory. In contrast, we propose a novel approach where a neural network learns new tasks by taking gradient steps in the orthogonal direction to the gradient subspaces deemed important for the past tasks. We find the bases of these subspaces by analyzing network representations (activations) after learning each task with Singular Value Decomposition (SVD) in a single shot manner and store them in the memory as Gradient Projection Memory (GPM). With qualitative and quantitative analyses, we show that such orthogonal gradient descent induces minimum to no interference with the past tasks, thereby mitigates forgetting. We evaluate our algorithm on diverse image classification datasets with short and long sequences of tasks and report better or on-par performance compared to the state-of-the-art approaches.

</p>
</details>

<details><summary><b>Few-Shot Visual Grounding for Natural Human-Robot Interaction</b>
<a href="https://arxiv.org/abs/2103.09720">arxiv:2103.09720</a>
&#x1F4C8; 7 <br>
<p>Giorgos Tziafas, Hamidreza Kasaei</p></summary>
<p>

**Abstract:** Natural Human-Robot Interaction (HRI) is one of the key components for service robots to be able to work in human-centric environments. In such dynamic environments, the robot needs to understand the intention of the user to accomplish a task successfully. Towards addressing this point, we propose a software architecture that segments a target object from a crowded scene, indicated verbally by a human user. At the core of our system, we employ a multi-modal deep neural network for visual grounding. Unlike most grounding methods that tackle the challenge using pre-trained object detectors via a two-stepped process, we develop a single stage zero-shot model that is able to provide predictions in unseen data. We evaluate the performance of the proposed model on real RGB-D data collected from public scene datasets. Experimental results showed that the proposed model performs well in terms of accuracy and speed, while showcasing robustness to variation in the natural language input.

</p>
</details>

<details><summary><b>Cyber Intrusion Detection by Using Deep Neural Networks with Attack-sharing Loss</b>
<a href="https://arxiv.org/abs/2103.09713">arxiv:2103.09713</a>
&#x1F4C8; 6 <br>
<p>Boxiang Dong,  Hui,  Wang, Aparna S. Varde, Dawei Li, Bharath K. Samanthula, Weifeng Sun, Liang Zhao</p></summary>
<p>

**Abstract:** Cyber attacks pose crucial threats to computer system security, and put digital treasuries at excessive risks. This leads to an urgent call for an effective intrusion detection system that can identify the intrusion attacks with high accuracy. It is challenging to classify the intrusion events due to the wide variety of attacks. Furthermore, in a normal network environment, a majority of the connections are initiated by benign behaviors. The class imbalance issue in intrusion detection forces the classifier to be biased toward the majority/benign class, thus leave many attack incidents undetected. Spurred by the success of deep neural networks in computer vision and natural language processing, in this paper, we design a new system named DeepIDEA that takes full advantage of deep learning to enable intrusion detection and classification. To achieve high detection accuracy on imbalanced data, we design a novel attack-sharing loss function that can effectively move the decision boundary towards the attack classes and eliminates the bias towards the majority/benign class. By using this loss function, DeepIDEA respects the fact that the intrusion mis-classification should receive higher penalty than the attack mis-classification. Extensive experimental results on three benchmark datasets demonstrate the high detection accuracy of DeepIDEA. In particular, compared with eight state-of-the-art approaches, DeepIDEA always provides the best class-balanced accuracy.

</p>
</details>

<details><summary><b>Code Word Detection in Fraud Investigations using a Deep-Learning Approach</b>
<a href="https://arxiv.org/abs/2103.09606">arxiv:2103.09606</a>
&#x1F4C8; 6 <br>
<p>Youri van der Zee, Jan C. Scholtes, Marcel Westerhoud, Julien Rossi</p></summary>
<p>

**Abstract:** In modern litigation, fraud investigators often face an overwhelming number of documents that must be reviewed throughout a matter. In the majority of legal cases, fraud investigators do not know beforehand, exactly what they are looking for, nor where to find it. In addition, fraudsters may use deception to hide their behaviour and intentions by using code words. Effectively, this means fraud investigators are looking for a needle in the haystack without knowing what the needle looks like.
  As part of a larger research program, we use a framework to expedite the investigation process applying text-mining and machine learning techniques. We structure this framework using three well-known methods in fraud investigations: (i) the fraud triangle (ii) the golden ("W") investigation questions, and (iii) the analysis of competing hypotheses. With this framework, it is possible to automatically organize investigative data, so it is easier for investigators to find answers to typical investigative questions.
  In this research, we focus on one of the components of this framework: the identification of the usage of code words by fraudsters. Here for, a novel (annotated) synthetic data set is created containing such code words, hidden in normal email communication. Subsequently, a range of machine learning techniques are employed to detect such code words. We show that the state-of-the-art BERT model significantly outperforms other methods on this task. With this result, we demonstrate that deep neural language models can reliably (F1 score of 0.9) be applied in fraud investigations for the detection of code words.

</p>
</details>

<details><summary><b>Theoretical bounds on data requirements for the ray-based classification</b>
<a href="https://arxiv.org/abs/2103.09577">arxiv:2103.09577</a>
&#x1F4C8; 6 <br>
<p>Brian J. Weber, Sandesh S. Kalantre, Thomas McJunkin, Jacob M. Taylor, Justyna P. Zwolak</p></summary>
<p>

**Abstract:** The problem of classifying high-dimensional shapes in real-world data grows in complexity as the dimension of the space increases. For the case of identifying convex shapes of different geometries, a new classification framework has recently been proposed in which the intersections of a set of one-dimensional representations, called rays, with the boundaries of the shape are used to identify the specific geometry. This ray-based classification (RBC) has been empirically verified using a synthetic dataset of two- and three-dimensional shapes (Zwolak et al. in Proceedings of Third Workshop on Machine Learning and the Physical Sciences (NeurIPS 2020), Vancouver, Canada [December 11, 2020], arXiv:2010.00500, 2020) and, more recently, has also been validated experimentally (Zwolak et al., PRX Quantum 2:020335, 2021). Here, we establish a bound on the number of rays necessary for shape classification, defined by key angular metrics, for arbitrary convex shapes. For two dimensions, we derive a lower bound on the number of rays in terms of the shape's length, diameter, and exterior angles. For convex polytopes in $\mathbb{R}^N$, we generalize this result to a similar bound given as a function of the dihedral angle and the geometrical parameters of polygonal faces. This result enables a different approach for estimating high-dimensional shapes using substantially fewer data elements than volumetric or surface-based approaches.

</p>
</details>

<details><summary><b>Adversarial Attacks on Camera-LiDAR Models for 3D Car Detection</b>
<a href="https://arxiv.org/abs/2103.09448">arxiv:2103.09448</a>
&#x1F4C8; 6 <br>
<p>Mazen Abdelfattah, Kaiwen Yuan, Z. Jane Wang, Rabab Ward</p></summary>
<p>

**Abstract:** Most autonomous vehicles (AVs) rely on LiDAR and RGB camera sensors for perception. Using these point cloud and image data, perception models based on deep neural nets (DNNs) have achieved state-of-the-art performance in 3D detection. The vulnerability of DNNs to adversarial attacks has been heavily investigated in the RGB image domain and more recently in the point cloud domain, but rarely in both domains simultaneously. Multi-modal perception systems used in AVs can be divided into two broad types: cascaded models which use each modality independently, and fusion models which learn from different modalities simultaneously. We propose a universal and physically realizable adversarial attack for each type, and study and contrast their respective vulnerabilities to attacks. We place a single adversarial object with specific shape and texture on top of a car with the objective of making this car evade detection. Evaluating on the popular KITTI benchmark, our adversarial object made the host vehicle escape detection by each model type more than 50% of the time. The dense RGB input contributed more to the success of the adversarial attacks on both cascaded and fusion models.

</p>
</details>

<details><summary><b>Machine Vision based Sample-Tube Localization for Mars Sample Return</b>
<a href="https://arxiv.org/abs/2103.09942">arxiv:2103.09942</a>
&#x1F4C8; 5 <br>
<p>Shreyansh Daftry, Barry Ridge, William Seto, Tu-Hoa Pham, Peter Ilhardt, Gerard Maggiolino, Mark Van der Merwe, Alex Brinkman, John Mayo, Eric Kulczyski, Renaud Detry</p></summary>
<p>

**Abstract:** A potential Mars Sample Return (MSR) architecture is being jointly studied by NASA and ESA. As currently envisioned, the MSR campaign consists of a series of 3 missions: sample cache, fetch and return to Earth. In this paper, we focus on the fetch part of the MSR, and more specifically the problem of autonomously detecting and localizing sample tubes deposited on the Martian surface. Towards this end, we study two machine-vision based approaches: First, a geometry-driven approach based on template matching that uses hard-coded filters and a 3D shape model of the tube; and second, a data-driven approach based on convolutional neural networks (CNNs) and learned features. Furthermore, we present a large benchmark dataset of sample-tube images, collected in representative outdoor environments and annotated with ground truth segmentation masks and locations. The dataset was acquired systematically across different terrain, illumination conditions and dust-coverage; and benchmarking was performed to study the feasibility of each approach, their relative strengths and weaknesses, and robustness in the presence of adverse environmental conditions.

</p>
</details>

<details><summary><b>Self-Supervised Learning of Audio Representations from Permutations with Differentiable Ranking</b>
<a href="https://arxiv.org/abs/2103.09879">arxiv:2103.09879</a>
&#x1F4C8; 5 <br>
<p>Andrew N Carr, Quentin Berthet, Mathieu Blondel, Olivier Teboul, Neil Zeghidour</p></summary>
<p>

**Abstract:** Self-supervised pre-training using so-called "pretext" tasks has recently shown impressive performance across a wide range of modalities. In this work, we advance self-supervised learning from permutations, by pre-training a model to reorder shuffled parts of the spectrogram of an audio signal, to improve downstream classification performance. We make two main contributions. First, we overcome the main challenges of integrating permutation inversions into an end-to-end training scheme, using recent advances in differentiable ranking. This was heretofore sidestepped by casting the reordering task as classification, fundamentally reducing the space of permutations that can be exploited. Our experiments validate that learning from all possible permutations improves the quality of the pre-trained representations over using a limited, fixed set. Second, we show that inverting permutations is a meaningful pretext task for learning audio representations in an unsupervised fashion. In particular, we improve instrument classification and pitch estimation of musical notes by reordering spectrogram patches in the time-frequency space.

</p>
</details>

<details><summary><b>On the Whitney extension problem for near isometries and beyond</b>
<a href="https://arxiv.org/abs/2103.09748">arxiv:2103.09748</a>
&#x1F4C8; 5 <br>
<p>Steven B. Damelin</p></summary>
<p>

**Abstract:** In this memoir, we develop a general framework which allows for a simultaneous study of labeled and unlabeled near alignment data problems in $\mathbb R^D$ and the Whitney near isometry extension problem for discrete and non-discrete subsets of $\mathbb R^D$ with certain geometries. Connections of this work to clustering, dimension reduction, manifold learning, vision as well as minimal energy partitions, discrepancy and min-max optimization are discussed. Numerous open problems in harmonic analysis, computer vision, manifold learning and signal processing connected to our work are given.
  A significant portion of the work in this memoir is based on joint research with Charles Fefferman in the papers [48], [49], [50], [51].

</p>
</details>

<details><summary><b>Quantitative Effectiveness Assessment and Role Categorization of Individual Units in Convolutional Neural Networks</b>
<a href="https://arxiv.org/abs/2103.09716">arxiv:2103.09716</a>
&#x1F4C8; 5 <br>
<p>Yang Zhao, Hao Zhang</p></summary>
<p>

**Abstract:** Identifying the roles of individual units is critical for understanding the mechanism of convolutional neural networks (CNNs). However, it is challenging to give the fully automatic and quantitative measures for effectiveness assessment of individual units in CNN. To this end, we propose a novel method for quantitatively clarifying the status and usefulness of single unit of CNN in image classification tasks. The technical substance of our method is ranking the importance of unit for each class in classification based on calculation of specifically defined entropy using algebraic topological tools. It could be implemented totally by machine without any human intervention. Some interesting phenomena including certain kind of phase transition are observed via the evolution of accuracy and loss of network in the successive ablation process of units. All of the network units are divided into four categories according to their performance on training and testing data. The role categorization is excellent startpoint for network construction and simplification. The diverse utility and contribution to the network generalization of units in classification tasks are thoroughly illustrated by extensive experiments on network (VGG) and dataset (ImageNet) with considerable scale. It is easy for our method to have extensional applications on other network models and tasks without essential difficulties.

</p>
</details>

<details><summary><b>Interpretable Distance Metric Learning for Handwritten Chinese Character Recognition</b>
<a href="https://arxiv.org/abs/2103.09714">arxiv:2103.09714</a>
&#x1F4C8; 5 <br>
<p>Boxiang Dong, Aparna S. Varde, Danilo Stevanovic, Jiayin Wang, Liang Zhao</p></summary>
<p>

**Abstract:** Handwriting recognition is of crucial importance to both Human Computer Interaction (HCI) and paperwork digitization. In the general field of Optical Character Recognition (OCR), handwritten Chinese character recognition faces tremendous challenges due to the enormously large character sets and the amazing diversity of writing styles. Learning an appropriate distance metric to measure the difference between data inputs is the foundation of accurate handwritten character recognition. Existing distance metric learning approaches either produce unacceptable error rates, or provide little interpretability in the results. In this paper, we propose an interpretable distance metric learning approach for handwritten Chinese character recognition. The learned metric is a linear combination of intelligible base metrics, and thus provides meaningful insights to ordinary users. Our experimental results on a benchmark dataset demonstrate the superior efficiency, accuracy and interpretability of our proposed approach.

</p>
</details>

<details><summary><b>ENCONTER: Entity Constrained Progressive Sequence Generation via Insertion-based Transformer</b>
<a href="https://arxiv.org/abs/2103.09548">arxiv:2103.09548</a>
&#x1F4C8; 5 <br>
<p>Lee-Hsun Hsieh, Yang-Yin Lee, Ee-Peng Lim</p></summary>
<p>

**Abstract:** Pretrained using large amount of data, autoregressive language models are able to generate high quality sequences. However, these models do not perform well under hard lexical constraints as they lack fine control of content generation process. Progressive insertion-based transformers can overcome the above limitation and efficiently generate a sequence in parallel given some input tokens as constraint. These transformers however may fail to support hard lexical constraints as their generation process is more likely to terminate prematurely. The paper analyses such early termination problems and proposes the Entity-constrained insertion transformer (ENCONTER), a new insertion transformer that addresses the above pitfall without compromising much generation efficiency. We introduce a new training strategy that considers predefined hard lexical constraints (e.g., entities to be included in the generated sequence). Our experiments show that ENCONTER outperforms other baseline models in several performance metrics rendering it more suitable in practical applications. Our code is available at https://github.com/LARC-CMU-SMU/Enconter

</p>
</details>

<details><summary><b>Towards Few-Shot Fact-Checking via Perplexity</b>
<a href="https://arxiv.org/abs/2103.09535">arxiv:2103.09535</a>
&#x1F4C8; 5 <br>
<p>Nayeon Lee, Yejin Bang, Andrea Madotto, Madian Khabsa, Pascale Fung</p></summary>
<p>

**Abstract:** Few-shot learning has drawn researchers' attention to overcome the problem of data scarcity. Recently, large pre-trained language models have shown great performance in few-shot learning for various downstream tasks, such as question answering and machine translation. Nevertheless, little exploration has been made to achieve few-shot learning for the fact-checking task. However, fact-checking is an important problem, especially when the amount of information online is growing exponentially every day. In this paper, we propose a new way of utilizing the powerful transfer learning ability of a language model via a perplexity score. The most notable strength of our methodology lies in its capability in few-shot learning. With only two training samples, our methodology can already outperform the Major Class baseline by more than absolute 10% on the F1-Macro metric across multiple datasets. Through experiments, we empirically verify the plausibility of the rather surprising usage of the perplexity score in the context of fact-checking and highlight the strength of our few-shot methodology by comparing it to strong fine-tuning-based baseline models. Moreover, we construct and publicly release two new fact-checking datasets related to COVID-19.

</p>
</details>

<details><summary><b>Decentralized Reinforcement Learning for Multi-Target Search and Detection by a Team of Drones</b>
<a href="https://arxiv.org/abs/2103.09520">arxiv:2103.09520</a>
&#x1F4C8; 5 <br>
<p>Roi Yehoshua, Juan Heredia-Juesas, Yushu Wu, Christopher Amato, Jose Martinez-Lorenzo</p></summary>
<p>

**Abstract:** Targets search and detection encompasses a variety of decision problems such as coverage, surveillance, search, observing and pursuit-evasion along with others. In this paper we develop a multi-agent deep reinforcement learning (MADRL) method to coordinate a group of aerial vehicles (drones) for the purpose of locating a set of static targets in an unknown area. To that end, we have designed a realistic drone simulator that replicates the dynamics and perturbations of a real experiment, including statistical inferences taken from experimental data for its modeling. Our reinforcement learning method, which utilized this simulator for training, was able to find near-optimal policies for the drones. In contrast to other state-of-the-art MADRL methods, our method is fully decentralized during both learning and execution, can handle high-dimensional and continuous observation spaces, and does not require tuning of additional hyperparameters.

</p>
</details>

<details><summary><b>Code Completion by Modeling Flattened Abstract Syntax Trees as Graphs</b>
<a href="https://arxiv.org/abs/2103.09499">arxiv:2103.09499</a>
&#x1F4C8; 5 <br>
<p>Yanlin Wang, Hui Li</p></summary>
<p>

**Abstract:** Code completion has become an essential component of integrated development environments. Contemporary code completion methods rely on the abstract syntax tree (AST) to generate syntactically correct code. However, they cannot fully capture the sequential and repetitive patterns of writing code and the structural information of the AST. To alleviate these problems, we propose a new code completion approach named CCAG, which models the flattened sequence of a partial AST as an AST graph. CCAG uses our proposed AST Graph Attention Block to capture different dependencies in the AST graph for representation learning in code completion. The sub-tasks of code completion are optimized via multi-task learning in CCAG, and the task balance is automatically achieved using uncertainty without the need to tune task weights. The experimental results show that CCAG has superior performance than state-of-the-art approaches and it is able to provide intelligent code completion.

</p>
</details>

<details><summary><b>Evolutional Deep Neural Network</b>
<a href="https://arxiv.org/abs/2103.09959">arxiv:2103.09959</a>
&#x1F4C8; 4 <br>
<p>Yifan Du, Tamer A. Zaki</p></summary>
<p>

**Abstract:** The notion of an Evolutional Deep Neural Network (EDNN) is introduced for the solution of partial differential equations (PDE). The parameters of the network are trained to represent the initial state of the system only, and are subsequently updated dynamically, without any further training, to provide an accurate prediction of the evolution of the PDE system. In this framework, the network parameters are treated as functions with respect to the appropriate coordinate and are numerically updated using the governing equations. By marching the neural network weights in the parameter space, EDNN can predict state-space trajectories that are indefinitely long, which is difficult for other neural network approaches. Boundary conditions of the PDEs are treated as hard constraints, are embedded into the neural network, and are therefore exactly satisfied throughout the entire solution trajectory. Several applications including the heat equation, the advection equation, the Burgers equation, the Kuramoto Sivashinsky equation and the Navier-Stokes equations are solved to demonstrate the versatility and accuracy of EDNN. The application of EDNN to the incompressible Navier-Stokes equation embeds the divergence-free constraint into the network design so that the projection of the momentum equation to solenoidal space is implicitly achieved. The numerical results verify the accuracy of EDNN solutions relative to analytical and benchmark numerical solutions, both for the transient dynamics and statistics of the system.

</p>
</details>

<details><summary><b>Understanding Generalization in Adversarial Training via the Bias-Variance Decomposition</b>
<a href="https://arxiv.org/abs/2103.09947">arxiv:2103.09947</a>
&#x1F4C8; 4 <br>
<p>Yaodong Yu, Zitong Yang, Edgar Dobriban, Jacob Steinhardt, Yi Ma</p></summary>
<p>

**Abstract:** Adversarially trained models exhibit a large generalization gap: they can interpolate the training set even for large perturbation radii, but at the cost of large test error on clean samples. To investigate this gap, we decompose the test risk into its bias and variance components and study their behavior as a function of adversarial training perturbation radii ($\varepsilon$). We find that the bias increases monotonically with $\varepsilon$ and is the dominant term in the risk. Meanwhile, the variance is unimodal as a function of $\varepsilon$, peaking near the interpolation threshold for the training set. This characteristic behavior occurs robustly across different datasets and also for other robust training procedures such as randomized smoothing. It thus provides a test for proposed explanations of the generalization gap. We find that some existing explanations fail this test--for instance, by predicting a monotonically increasing variance curve. This underscores the power of bias-variance decompositions in modern settings-by providing two measurements instead of one, they can rule out more explanations than test accuracy alone. We also show that bias and variance can provide useful guidance for scalably reducing the generalization gap, highlighting pre-training and unlabeled data as promising routes.

</p>
</details>

<details><summary><b>Transformer-based ASR Incorporating Time-reduction Layer and Fine-tuning with Self-Knowledge Distillation</b>
<a href="https://arxiv.org/abs/2103.09903">arxiv:2103.09903</a>
&#x1F4C8; 4 <br>
<p>Md Akmal Haidar, Chao Xing, Mehdi Rezagholizadeh</p></summary>
<p>

**Abstract:** End-to-end automatic speech recognition (ASR), unlike conventional ASR, does not have modules to learn the semantic representation from speech encoder. Moreover, the higher frame-rate of speech representation prevents the model to learn the semantic representation properly. Therefore, the models that are constructed by the lower frame-rate of speech encoder lead to better performance. For Transformer-based ASR, the lower frame-rate is not only important for learning better semantic representation but also for reducing the computational complexity due to the self-attention mechanism which has O(n^2) order of complexity in both training and inference. In this paper, we propose a Transformer-based ASR model with the time reduction layer, in which we incorporate time reduction layer inside transformer encoder layers in addition to traditional sub-sampling methods to input features that further reduce the frame-rate. This can help in reducing the computational cost of the self-attention process for training and inference with performance improvement. Moreover, we introduce a fine-tuning approach for pre-trained ASR models using self-knowledge distillation (S-KD) which further improves the performance of our ASR model. Experiments on LibriSpeech datasets show that our proposed methods outperform all other Transformer-based ASR systems. Furthermore, with language model (LM) fusion, we achieve new state-of-the-art word error rate (WER) results for Transformer-based ASR models with just 30 million parameters trained without any external data.

</p>
</details>

<details><summary><b>Characterizing Technical Debt and Antipatterns in AI-Based Systems: A Systematic Mapping Study</b>
<a href="https://arxiv.org/abs/2103.09783">arxiv:2103.09783</a>
&#x1F4C8; 4 <br>
<p>Justus Bogner, Roberto Verdecchia, Ilias Gerostathopoulos</p></summary>
<p>

**Abstract:** Background: With the rising popularity of Artificial Intelligence (AI), there is a growing need to build large and complex AI-based systems in a cost-effective and manageable way. Like with traditional software, Technical Debt (TD) will emerge naturally over time in these systems, therefore leading to challenges and risks if not managed appropriately. The influence of data science and the stochastic nature of AI-based systems may also lead to new types of TD or antipatterns, which are not yet fully understood by researchers and practitioners. Objective: The goal of our study is to provide a clear overview and characterization of the types of TD (both established and new ones) that appear in AI-based systems, as well as the antipatterns and related solutions that have been proposed. Method: Following the process of a systematic mapping study, 21 primary studies are identified and analyzed. Results: Our results show that (i) established TD types, variations of them, and four new TD types (data, model, configuration, and ethics debt) are present in AI-based systems, (ii) 72 antipatterns are discussed in the literature, the majority related to data and model deficiencies, and (iii) 46 solutions have been proposed, either to address specific TD types, antipatterns, or TD in general. Conclusions: Our results can support AI professionals with reasoning about and communicating aspects of TD present in their systems. Additionally, they can serve as a foundation for future research to further our understanding of TD in AI-based systems.

</p>
</details>

<details><summary><b>Investigating Monolingual and Multilingual BERTModels for Vietnamese Aspect Category Detection</b>
<a href="https://arxiv.org/abs/2103.09519">arxiv:2103.09519</a>
&#x1F4C8; 4 <br>
<p>Dang Van Thin, Lac Si Le, Vu Xuan Hoang, Ngan Luu-Thuy Nguyen</p></summary>
<p>

**Abstract:** Aspect category detection (ACD) is one of the challenging tasks in the Aspect-based sentiment Analysis problem. The purpose of this task is to identify the aspect categories mentioned in user-generated reviews from a set of pre-defined categories. In this paper, we investigate the performance of various monolingual pre-trained language models compared with multilingual models on the Vietnamese aspect category detection problem. We conduct the experiments on two benchmark datasets for the restaurant and hotel domain. The experimental results demonstrated the effectiveness of the monolingual PhoBERT model than others on two datasets. We also evaluate the performance of the multilingual model based on the combination of whole SemEval-2016 datasets in other languages with the Vietnamese dataset. To the best of our knowledge, our research study is the first attempt at performing various available pre-trained language models on aspect category detection task and utilize the datasets from other languages based on multilingual models.

</p>
</details>

<details><summary><b>Virtual Dress Swap Using Landmark Detection</b>
<a href="https://arxiv.org/abs/2103.09475">arxiv:2103.09475</a>
&#x1F4C8; 4 <br>
<p>Odar Zeynal, Saber Malekzadeh</p></summary>
<p>

**Abstract:** Online shopping has gained popularity recently. This paper addresses one crucial problem of buying dress online, which has not been solved yet. This research tries to implement the idea of clothes swapping with the help of DeepFashion dataset where 6,223 images with eight landmarks each used. Deep Convolutional Neural Network has been built for Landmark detection.

</p>
</details>

<details><summary><b>Learning with Group Noise</b>
<a href="https://arxiv.org/abs/2103.09468">arxiv:2103.09468</a>
&#x1F4C8; 4 <br>
<p>Qizhou Wang, Jiangchao Yao, Chen Gong, Tongliang Liu, Mingming Gong, Hongxia Yang, Bo Han</p></summary>
<p>

**Abstract:** Machine learning in the context of noise is a challenging but practical setting to plenty of real-world applications. Most of the previous approaches in this area focus on the pairwise relation (casual or correlational relationship) with noise, such as learning with noisy labels. However, the group noise, which is parasitic on the coarse-grained accurate relation with the fine-grained uncertainty, is also universal and has not been well investigated. The challenge under this setting is how to discover true pairwise connections concealed by the group relation with its fine-grained noise. To overcome this issue, we propose a novel Max-Matching method for learning with group noise. Specifically, it utilizes a matching mechanism to evaluate the relation confidence of each object w.r.t. the target, meanwhile considering the Non-IID characteristics among objects in the group. Only the most confident object is considered to learn the model, so that the fine-grained noise is mostly dropped. The performance on arange of real-world datasets in the area of several learning paradigms demonstrates the effectiveness of Max-Matching

</p>
</details>

<details><summary><b>FBCNet: A Multi-view Convolutional Neural Network for Brain-Computer Interface</b>
<a href="https://arxiv.org/abs/2104.01233">arxiv:2104.01233</a>
&#x1F4C8; 3 <br>
<p>Ravikiran Mane, Effie Chew, Karen Chua, Kai Keng Ang, Neethu Robinson, A. P. Vinod, Seong-Whan Lee, Cuntai Guan</p></summary>
<p>

**Abstract:** Lack of adequate training samples and noisy high-dimensional features are key challenges faced by Motor Imagery (MI) decoding algorithms for electroencephalogram (EEG) based Brain-Computer Interface (BCI). To address these challenges, inspired from neuro-physiological signatures of MI, this paper proposes a novel Filter-Bank Convolutional Network (FBCNet) for MI classification. FBCNet employs a multi-view data representation followed by spatial filtering to extract spectro-spatially discriminative features. This multistage approach enables efficient training of the network even when limited training data is available. More significantly, in FBCNet, we propose a novel Variance layer that effectively aggregates the EEG time-domain information. With this design, we compare FBCNet with state-of-the-art (SOTA) BCI algorithm on four MI datasets: The BCI competition IV dataset 2a (BCIC-IV-2a), the OpenBMI dataset, and two large datasets from chronic stroke patients. The results show that, by achieving 76.20% 4-class classification accuracy, FBCNet sets a new SOTA for BCIC-IV-2a dataset. On the other three datasets, FBCNet yields up to 8% higher binary classification accuracies. Additionally, using explainable AI techniques we present one of the first reports about the differences in discriminative EEG features between healthy subjects and stroke patients. Also, the FBCNet source code is available at https://github.com/ravikiran-mane/FBCNet.

</p>
</details>

<details><summary><b>Linear Iterative Feature Embedding: An Ensemble Framework for Interpretable Model</b>
<a href="https://arxiv.org/abs/2103.09983">arxiv:2103.09983</a>
&#x1F4C8; 3 <br>
<p>Agus Sudjianto, Jinwen Qiu, Miaoqi Li, Jie Chen</p></summary>
<p>

**Abstract:** A new ensemble framework for interpretable model called Linear Iterative Feature Embedding (LIFE) has been developed to achieve high prediction accuracy, easy interpretation and efficient computation simultaneously. The LIFE algorithm is able to fit a wide single-hidden-layer neural network (NN) accurately with three steps: defining the subsets of a dataset by the linear projections of neural nodes, creating the features from multiple narrow single-hidden-layer NNs trained on the different subsets of the data, combining the features with a linear model. The theoretical rationale behind LIFE is also provided by the connection to the loss ambiguity decomposition of stack ensemble methods. Both simulation and empirical experiments confirm that LIFE consistently outperforms directly trained single-hidden-layer NNs and also outperforms many other benchmark models, including multi-layers Feed Forward Neural Network (FFNN), Xgboost, and Random Forest (RF) in many experiments. As a wide single-hidden-layer NN, LIFE is intrinsically interpretable. Meanwhile, both variable importance and global main and interaction effects can be easily created and visualized. In addition, the parallel nature of the base learner building makes LIFE computationally efficient by leveraging parallel computing.

</p>
</details>

<details><summary><b>Decision Theoretic Bootstrapping</b>
<a href="https://arxiv.org/abs/2103.09982">arxiv:2103.09982</a>
&#x1F4C8; 3 <br>
<p>Peyman Tavallali, Hamed Hamze Bajgiran, Danial J. Esaid, Houman Owhadi</p></summary>
<p>

**Abstract:** The design and testing of supervised machine learning models combine two fundamental distributions: (1) the training data distribution (2) the testing data distribution. Although these two distributions are identical and identifiable when the data set is infinite; they are imperfectly known (and possibly distinct) when the data is finite (and possibly corrupted) and this uncertainty must be taken into account for robust Uncertainty Quantification (UQ). We present a general decision-theoretic bootstrapping solution to this problem: (1) partition the available data into a training subset and a UQ subset (2) take $m$ subsampled subsets of the training set and train $m$ models (3) partition the UQ set into $n$ sorted subsets and take a random fraction of them to define $n$ corresponding empirical distributions $μ_{j}$ (4) consider the adversarial game where Player I selects a model $i\in\left\{ 1,\ldots,m\right\} $, Player II selects the UQ distribution $μ_{j}$ and Player I receives a loss defined by evaluating the model $i$ against data points sampled from $μ_{j}$ (5) identify optimal mixed strategies (probability distributions over models and UQ distributions) for both players. These randomized optimal mixed strategies provide optimal model mixtures and UQ estimates given the adversarial uncertainty of the training and testing distributions represented by the game. The proposed approach provides (1) some degree of robustness to distributional shift in both the distribution of training data and that of the testing data (2) conditional probability distributions on the output space forming aleatory representations of the uncertainty on the output as a function of the input variable.

</p>
</details>

<details><summary><b>The Untapped Potential of Off-the-Shelf Convolutional Neural Networks</b>
<a href="https://arxiv.org/abs/2103.09891">arxiv:2103.09891</a>
&#x1F4C8; 3 <br>
<p>Matthew Inkawhich, Nathan Inkawhich, Eric Davis, Hai Li, Yiran Chen</p></summary>
<p>

**Abstract:** Over recent years, a myriad of novel convolutional network architectures have been developed to advance state-of-the-art performance on challenging recognition tasks. As computational resources improve, a great deal of effort has been placed in efficiently scaling up existing designs and generating new architectures with Neural Architecture Search (NAS) algorithms. While network topology has proven to be a critical factor for model performance, we show that significant gains are being left on the table by keeping topology static at inference-time. Due to challenges such as scale variation, we should not expect static models configured to perform well across a training dataset to be optimally configured to handle all test data. In this work, we seek to expose the exciting potential of inference-time-dynamic models. By allowing just four layers to dynamically change configuration at inference-time, we show that existing off-the-shelf models like ResNet-50 are capable of over 95% accuracy on ImageNet. This level of performance currently exceeds that of models with over 20x more parameters and significantly more complex training procedures.

</p>
</details>

<details><summary><b>Near Optimal Policy Optimization via REPS</b>
<a href="https://arxiv.org/abs/2103.09756">arxiv:2103.09756</a>
&#x1F4C8; 3 <br>
<p>Aldo Pacchiano, Jonathan Lee, Peter Bartlett, Ofir Nachum</p></summary>
<p>

**Abstract:** Since its introduction a decade ago, \emph{relative entropy policy search} (REPS) has demonstrated successful policy learning on a number of simulated and real-world robotic domains, not to mention providing algorithmic components used by many recently proposed reinforcement learning (RL) algorithms. While REPS is commonly known in the community, there exist no guarantees on its performance when using stochastic and gradient-based solvers. In this paper we aim to fill this gap by providing guarantees and convergence rates for the sub-optimality of a policy learned using first-order optimization methods applied to the REPS objective. We first consider the setting in which we are given access to exact gradients and demonstrate how near-optimality of the objective translates to near-optimality of the policy. We then consider the practical setting of stochastic gradients, and introduce a technique that uses \emph{generative} access to the underlying Markov decision process to compute parameter updates that maintain favorable convergence to the optimal regularized policy.

</p>
</details>

<details><summary><b>Trans-SVNet: Accurate Phase Recognition from Surgical Videos via Hybrid Embedding Aggregation Transformer</b>
<a href="https://arxiv.org/abs/2103.09712">arxiv:2103.09712</a>
&#x1F4C8; 3 <br>
<p>Xiaojie Gao, Yueming Jin, Yonghao Long, Qi Dou, Pheng-Ann Heng</p></summary>
<p>

**Abstract:** Real-time surgical phase recognition is a fundamental task in modern operating rooms. Previous works tackle this task relying on architectures arranged in spatio-temporal order, however, the supportive benefits of intermediate spatial features are not considered. In this paper, we introduce, for the first time in surgical workflow analysis, Transformer to reconsider the ignored complementary effects of spatial and temporal features for accurate surgical phase recognition. Our hybrid embedding aggregation Transformer fuses cleverly designed spatial and temporal embeddings by allowing for active queries based on spatial information from temporal embedding sequences. More importantly, our framework processes the hybrid embeddings in parallel to achieve a high inference speed. Our method is thoroughly validated on two large surgical video datasets, i.e., Cholec80 and M2CAI16 Challenge datasets, and outperforms the state-of-the-art approaches at a processing speed of 91 fps.

</p>
</details>

<details><summary><b>On the Role of Images for Analyzing Claims in Social Media</b>
<a href="https://arxiv.org/abs/2103.09602">arxiv:2103.09602</a>
&#x1F4C8; 3 <br>
<p>Gullal S. Cheema, Sherzod Hakimov, Eric Müller-Budack, Ralph Ewerth</p></summary>
<p>

**Abstract:** Fake news is a severe problem in social media. In this paper, we present an empirical study on visual, textual, and multimodal models for the tasks of claim, claim check-worthiness, and conspiracy detection, all of which are related to fake news detection. Recent work suggests that images are more influential than text and often appear alongside fake text. To this end, several multimodal models have been proposed in recent years that use images along with text to detect fake news on social media sites like Twitter. However, the role of images is not well understood for claim detection, specifically using transformer-based textual and multimodal models. We investigate state-of-the-art models for images, text (Transformer-based), and multimodal information for four different datasets across two languages to understand the role of images in the task of claim and conspiracy detection.

</p>
</details>

<details><summary><b>Automatic Generation of Contrast Sets from Scene Graphs: Probing the Compositional Consistency of GQA</b>
<a href="https://arxiv.org/abs/2103.09591">arxiv:2103.09591</a>
&#x1F4C8; 3 <br>
<p>Yonatan Bitton, Gabriel Stanovsky, Roy Schwartz, Michael Elhadad</p></summary>
<p>

**Abstract:** Recent works have shown that supervised models often exploit data artifacts to achieve good test scores while their performance severely degrades on samples outside their training distribution. Contrast sets (Gardneret al., 2020) quantify this phenomenon by perturbing test samples in a minimal way such that the output label is modified. While most contrast sets were created manually, requiring intensive annotation effort, we present a novel method which leverages rich semantic input representation to automatically generate contrast sets for the visual question answering task. Our method computes the answer of perturbed questions, thus vastly reducing annotation cost and enabling thorough evaluation of models' performance on various semantic aspects (e.g., spatial or relational reasoning). We demonstrate the effectiveness of our approach on the GQA dataset and its semantic scene graph image representation. We find that, despite GQA's compositionality and carefully balanced label distribution, two high-performing models drop 13-17% in accuracy compared to the original test set. Finally, we show that our automatic perturbation can be applied to the training set to mitigate the degradation in performance, opening the door to more robust models.

</p>
</details>

<details><summary><b>An Efficient Method for the Classification of Croplands in Scarce-Label Regions</b>
<a href="https://arxiv.org/abs/2103.09588">arxiv:2103.09588</a>
&#x1F4C8; 3 <br>
<p>Houtan Ghaffari</p></summary>
<p>

**Abstract:** Two of the main challenges for cropland classification by satellite time-series images are insufficient ground-truth data and inaccessibility of high-quality hyperspectral images for under-developed areas. Unlabeled medium-resolution satellite images are abundant, but how to benefit from them is an open question. We will show how to leverage their potential for cropland classification using self-supervised tasks. Self-supervision is an approach where we provide simple training signals for the samples, which are apparent from the data's structure. Hence, they are cheap to acquire and explain a simple concept about the data. We introduce three self-supervised tasks for cropland classification. They reduce epistemic uncertainty, and the resulting model shows superior accuracy in a wide range of settings compared to SVM and Random Forest. Subsequently, we use the self-supervised tasks to perform unsupervised domain adaptation and benefit from the labeled samples in other regions. It is crucial to know what information to transfer to avoid degrading the performance. We show how to automate the information selection and transfer process in cropland classification even when the source and target areas have a very different feature distribution. We improved the model by about 24% compared to a baseline architecture without any labeled sample in the target domain. Our method is amenable to gradual improvement, works with medium-resolution satellite images, and does not require complicated models. Code and data are available.

</p>
</details>

<details><summary><b>Revisiting the Loss Weight Adjustment in Object Detection</b>
<a href="https://arxiv.org/abs/2103.09488">arxiv:2103.09488</a>
&#x1F4C8; 3 <br>
<p>Wenxin Yu, Xueling Shen, Jiajie Hu, Dong Yin</p></summary>
<p>

**Abstract:** Object detection is a typical multi-task learning application, which optimizes classification and regression simultaneously. However, classification loss always dominates the multi-task loss in anchor-based methods, hampering the consistent and balanced optimization of the tasks. In this paper, we find that shifting the bounding boxes can change the division of positive and negative samples in classification, meaning classification depends on regression. Moreover, we summarize three important conclusions about fine-tuning loss weights, considering different datasets, optimizers and regression loss functions. Based on the above conclusions, we propose Adaptive Loss Weight Adjustment(ALWA) to solve the imbalance in optimizing anchor-based methods according to statistical characteristics of losses. By incorporating ALWA into previous state-of-the-art detectors, we achieve a significant performance gain on PASCAL VOC and MS COCO, even with L1, SmoothL1 and CIoU loss. The code is available at https://github.com/ywx-hub/ALWA.

</p>
</details>

<details><summary><b>A Novel Solution of Using Mixed Reality in Bowel and Oral and Maxillofacial Surgical Telepresence: 3D Mean Value Cloning algorithm</b>
<a href="https://arxiv.org/abs/2104.06316">arxiv:2104.06316</a>
&#x1F4C8; 2 <br>
<p>Arjina Maharjan, Abeer Alsadoon, P. W. C. Prasad, Nada AlSallami, Tarik A. Rashid, Ahmad Alrubaie, Sami Haddad</p></summary>
<p>

**Abstract:** Background and aim: Most of the Mixed Reality models used in the surgical telepresence are suffering from discrepancies in the boundary area and spatial-temporal inconsistency due to the illumination variation in the video frames. The aim behind this work is to propose a new solution that helps produce the composite video by merging the augmented video of the surgery site and the virtual hand of the remote expertise surgeon. The purpose of the proposed solution is to decrease the processing time and enhance the accuracy of merged video by decreasing the overlay and visualization error and removing occlusion and artefacts. Methodology: The proposed system enhanced the mean value cloning algorithm that helps to maintain the spatial-temporal consistency of the final composite video. The enhanced algorithm includes the 3D mean value coordinates and improvised mean value interpolant in the image cloning process, which helps to reduce the sawtooth, smudging and discolouration artefacts around the blending region. Results: As compared to the state of the art solution, the accuracy in terms of overlay error of the proposed solution is improved from 1.01mm to 0.80mm whereas the accuracy in terms of visualization error is improved from 98.8% to 99.4%. The processing time is reduced to 0.173 seconds from 0.211 seconds. Conclusion: Our solution helps make the object of interest consistent with the light intensity of the target image by adding the space distance that helps maintain the spatial consistency in the final merged video.

</p>
</details>

<details><summary><b>Towards an Open Global Air Quality Monitoring Platform to Assess Children's Exposure to Air Pollutants in the Light of COVID-19 Lockdowns</b>
<a href="https://arxiv.org/abs/2103.12505">arxiv:2103.12505</a>
&#x1F4C8; 2 <br>
<p>Christina Last, Prithviraj Pramanik, Nikita Saini, Akash Smaran Majety, Do-Hyung Kim, Manuel García-Herranz, Subhabrata Majumdar</p></summary>
<p>

**Abstract:** This ongoing work attempts to understand and address the requirements of UNICEF, a leading organization working in children's welfare, where they aim to tackle the problem of air quality for children at a global level. We are motivated by the lack of a proper model to account for heavily fluctuating air quality levels across the world in the wake of the COVID-19 pandemic, leading to uncertainty among public health professionals on the exact levels of children's exposure to air pollutants. We create an initial model as per the agency's requirement to generate insights through a combination of virtual meetups and online presentations. Our research team comprised of UNICEF's researchers and a group of volunteer data scientists. The presentations were delivered to a number of scientists and domain experts from UNICEF and community champions working with open data. We highlight their feedback and possible avenues to develop this research further.

</p>
</details>

<details><summary><b>Augmenting Supervised Learning by Meta-learning Unsupervised Local Rules</b>
<a href="https://arxiv.org/abs/2103.10252">arxiv:2103.10252</a>
&#x1F4C8; 2 <br>
<p>Jeffrey Cheng, Ari Benjamin, Benjamin Lansdell, Konrad Paul Kordin</p></summary>
<p>

**Abstract:** The brain performs unsupervised learning and (perhaps) simultaneous supervised learning. This raises the question as to whether a hybrid of supervised and unsupervised methods will produce better learning. Inspired by the rich space of Hebbian learning rules, we set out to directly learn the unsupervised learning rule on local information that best augments a supervised signal. We present the Hebbian-augmented training algorithm (HAT) for combining gradient-based learning with an unsupervised rule on pre-synpatic activity, post-synaptic activities, and current weights. We test HAT's effect on a simple problem (Fashion-MNIST) and find consistently higher performance than supervised learning alone. This finding provides empirical evidence that unsupervised learning on synaptic activities provides a strong signal that can be used to augment gradient-based methods.
  We further find that the meta-learned update rule is a time-varying function; thus, it is difficult to pinpoint an interpretable Hebbian update rule that aids in training. We do find that the meta-learner eventually degenerates into a non-Hebbian rule that preserves important weights so as not to disturb the learner's convergence.

</p>
</details>

<details><summary><b>Human-Inspired Multi-Agent Navigation using Knowledge Distillation</b>
<a href="https://arxiv.org/abs/2103.10000">arxiv:2103.10000</a>
&#x1F4C8; 2 <br>
<p>Pei Xu, Ioannis Karamouzas</p></summary>
<p>

**Abstract:** Despite significant advancements in the field of multi-agent navigation, agents still lack the sophistication and intelligence that humans exhibit in multi-agent settings. In this paper, we propose a framework for learning a human-like general collision avoidance policy for agent-agent interactions in fully decentralized, multi-agent environments. Our approach uses knowledge distillation with reinforcement learning to shape the reward function based on expert policies extracted from human trajectory demonstrations through behavior cloning. We show that agents trained with our approach can take human-like trajectories in collision avoidance and goal-directed steering tasks not provided by the demonstrations, outperforming the experts as well as learning-based agents trained without knowledge distillation.

</p>
</details>

<details><summary><b>MS*: A New Exact Algorithm for Multi-agent Simultaneous Multi-goal Sequencing and Path Finding</b>
<a href="https://arxiv.org/abs/2103.09979">arxiv:2103.09979</a>
&#x1F4C8; 2 <br>
<p>Zhongqiang Ren, Sivakumar Rathinam, Howie Choset</p></summary>
<p>

**Abstract:** In multi-agent applications such as surveillance and logistics, fleets of mobile agents are often expected to coordinate and safely visit a large number of goal locations as efficiently as possible. The multi-agent planning problem in these applications involves allocating and sequencing goals for each agent while simultaneously producing conflict-free paths for the agents. In this article, we introduce a new algorithm called MS* which computes an optimal solution for this multi-agent problem by fusing and advancing state of the art solvers for multi-agent path finding (MAPF) and multiple travelling salesman problem (mTSP). MS* leverages our prior subdimensional expansion approach for MAPF and embeds the mTSP solvers to optimally allocate and sequence goals for agents. Numerical results show that our new algorithm can solve the multi-agent problem with 20 agents and 50 goals in a minute of CPU time on a standard laptop.

</p>
</details>

<details><summary><b>TSTNN: Two-stage Transformer based Neural Network for Speech Enhancement in the Time Domain</b>
<a href="https://arxiv.org/abs/2103.09963">arxiv:2103.09963</a>
&#x1F4C8; 2 <br>
<p>Kai Wang, Bengbeng He, Wei-Ping Zhu</p></summary>
<p>

**Abstract:** In this paper, we propose a transformer-based architecture, called two-stage transformer neural network (TSTNN) for end-to-end speech denoising in the time domain. The proposed model is composed of an encoder, a two-stage transformer module (TSTM), a masking module and a decoder. The encoder maps input noisy speech into feature representation. The TSTM exploits four stacked two-stage transformer blocks to efficiently extract local and global information from the encoder output stage by stage. The masking module creates a mask which will be multiplied with the encoder output. Finally, the decoder uses the masked encoder feature to reconstruct the enhanced speech. Experimental results on the benchmark dataset show that the TSTNN outperforms most state-of-the-art models in time or frequency domain while having significantly lower model complexity.

</p>
</details>

<details><summary><b>What's in My LiDAR Odometry Toolbox?</b>
<a href="https://arxiv.org/abs/2103.09708">arxiv:2103.09708</a>
&#x1F4C8; 2 <br>
<p>Pierre Dellenbach, Jean-Emmanuel Deschaud, Bastien Jacquet, François Goulette</p></summary>
<p>

**Abstract:** With the democratization of 3D LiDAR sensors, precise LiDAR odometries and SLAM are in high demand. New methods regularly appear, proposing solutions ranging from small variations in classical algorithms to radically new paradigms based on deep learning. Yet it is often difficult to compare these methods, notably due to the few datasets on which the methods can be evaluated and compared. Furthermore, their weaknesses are rarely examined, often letting the user discover the hard way whether a method would be appropriate for a use case. In this paper, we review and organize the main 3D LiDAR odometries into distinct categories. We implemented several approaches (geometric based, deep learning based, and hybrid methods) to conduct an in-depth analysis of their strengths and weaknesses on multiple datasets, guiding the reader through the different LiDAR odometries available. Implementation of the methods has been made publicly available at https://github.com/Kitware/pyLiDAR-SLAM.

</p>
</details>

<details><summary><b>DoubleML -- An Object-Oriented Implementation of Double Machine Learning in R</b>
<a href="https://arxiv.org/abs/2103.09603">arxiv:2103.09603</a>
&#x1F4C8; 2 <br>
<p>Philipp Bach, Victor Chernozhukov, Malte S. Kurz, Martin Spindler</p></summary>
<p>

**Abstract:** The R package DoubleML implements the double/debiased machine learning framework of Chernozhukov et al. (2018). It provides functionalities to estimate parameters in causal models based on machine learning methods. The double machine learning framework consist of three key ingredients: Neyman orthogonality, high-quality machine learning estimation and sample splitting. Estimation of nuisance components can be performed by various state-of-the-art machine learning methods that are available in the mlr3 ecosystem. DoubleML makes it possible to perform inference in a variety of causal models, including partially linear and interactive regression models and their extensions to instrumental variable estimation. The object-oriented implementation of DoubleML enables a high flexibility for the model specification and makes it easily extendable. This paper serves as an introduction to the double machine learning framework and the R package DoubleML. In reproducible code examples with simulated and real data sets, we demonstrate how DoubleML users can perform valid inference based on machine learning methods.

</p>
</details>

<details><summary><b>Glioblastoma Multiforme Prognosis: MRI Missing Modality Generation, Segmentation and Radiogenomic Survival Prediction</b>
<a href="https://arxiv.org/abs/2104.01149">arxiv:2104.01149</a>
&#x1F4C8; 1 <br>
<p>Mobarakol Islam, Navodini Wijethilake, Hongliang Ren</p></summary>
<p>

**Abstract:** The accurate prognosis of Glioblastoma Multiforme (GBM) plays an essential role in planning correlated surgeries and treatments. The conventional models of survival prediction rely on radiomic features using magnetic resonance imaging (MRI). In this paper, we propose a radiogenomic overall survival (OS) prediction approach by incorporating gene expression data with radiomic features such as shape, geometry, and clinical information. We exploit TCGA (The Cancer Genomic Atlas) dataset and synthesize the missing MRI modalities using a fully convolutional network (FCN) in a conditional Generative Adversarial Network (cGAN). Meanwhile, the same FCN architecture enables the tumor segmentation from the available and the synthesized MRI modalities. The proposed FCN architecture comprises octave convolution (OctConv) and a novel decoder, with skip connections in spatial and channel squeeze & excitation (skip-scSE) block. The OctConv can process low and high-frequency features individually and improve model efficiency by reducing channel-wise redundancy. Skip-scSE applies spatial and channel-wise excitation to signify the essential features and reduces the sparsity in deeper layers learning parameters using skip connections. The proposed approaches are evaluated by comparative experiments with state-of-the-art models in synthesis, segmentation, and overall survival (OS) prediction. We observe that adding missing MRI modality improves the segmentation prediction, and expression levels of gene markers have a high contribution in the GBM prognosis prediction, and fused radiogenomic features boost the OS estimation.

</p>
</details>

<details><summary><b>Capturing Knowledge of Emerging Entities From Extended Search Snippets</b>
<a href="https://arxiv.org/abs/2104.01105">arxiv:2104.01105</a>
&#x1F4C8; 1 <br>
<p>Sunday C. Ngwobia, Saeedeh Shekarpour, Faisal Alshargi</p></summary>
<p>

**Abstract:** Google and other search engines feature the entity search by representing a knowledge card summarizing related facts about the user-supplied entity. However, the knowledge card is limited to certain entities that have a Wiki page or an entry in encyclopedias such as Freebase. The current encyclopedias are limited to highly popular entities, which are far fewer compared with the emerging entities. Despite the availability of knowledge about the emerging entities on the search results, yet there are no approaches to capture, abstract, summerize, fuse, and validate fragmented pieces of knowledge about them. Thus, in this paper, we develop approaches to capture two types of knowledge about the emerging entities from a corpus extended from top-n search snippets of a given emerging entity. The first kind of knowledge identifies the role(s) of the emerging entity as, e.g., who is s/he? The second kind captures the entities closely associated with the emerging entity. As the testbed, we considered a collection of 20 emerging entities and 20 popular entities as the ground truth. Our approach is an unsupervised approach based on text analysis and entity embeddings. Our experimental studies show promising results as the accuracy of more than $87\%$ for recognizing entities and $75\%$ for ranking them. Besides $87\%$ of the entailed types were recognizable. Our testbed and source code is available on Github https://github.com/sunnyUD/research_source_code.

</p>
</details>

<details><summary><b>Neural Network Attribution Methods for Problems in Geoscience: A Novel Synthetic Benchmark Dataset</b>
<a href="https://arxiv.org/abs/2103.10005">arxiv:2103.10005</a>
&#x1F4C8; 1 <br>
<p>Antonios Mamalakis, Imme Ebert-Uphoff, Elizabeth A. Barnes</p></summary>
<p>

**Abstract:** Despite the increasingly successful application of neural networks to many problems in the geosciences, their complex and nonlinear structure makes the interpretation of their predictions difficult, which limits model trust and does not allow scientists to gain physical insights about the problem at hand. Many different methods have been introduced in the emerging field of eXplainable Artificial Intelligence (XAI), which aim at attributing the network's prediction to specific features in the input domain. XAI methods are usually assessed by using benchmark datasets (like MNIST or ImageNet for image classification), or through deletion/insertion techniques. In either case, however, an objective, theoretically-derived ground truth for the attribution is lacking, making the assessment of XAI in many cases subjective. Also, benchmark datasets for problems in geosciences are rare. Here, we provide a framework, based on the use of additively separable functions, to generate attribution benchmark datasets for regression problems for which the ground truth of the attribution is known a priori. We generate a long benchmark dataset and train a fully-connected network to learn the underlying function that was used for simulation. We then compare estimated attribution heatmaps from different XAI methods to the ground truth in order to identify examples where specific XAI methods perform well or poorly. We believe that attribution benchmarks as the ones introduced herein are of great importance for further application of neural networks in the geosciences, and for accurate implementation of XAI methods, which will increase model trust and assist in discovering new science.

</p>
</details>

<details><summary><b>IRLI: Iterative Re-partitioning for Learning to Index</b>
<a href="https://arxiv.org/abs/2103.09944">arxiv:2103.09944</a>
&#x1F4C8; 1 <br>
<p>Gaurav Gupta, Tharun Medini, Anshumali Shrivastava, Alexander J Smola</p></summary>
<p>

**Abstract:** Neural models have transformed the fundamental information retrieval problem of mapping a query to a giant set of items. However, the need for efficient and low latency inference forces the community to reconsider efficient approximate near-neighbor search in the item space. To this end, learning to index is gaining much interest in recent times. Methods have to trade between obtaining high accuracy while maintaining load balance and scalability in distributed settings. We propose a novel approach called IRLI (pronounced `early'), which iteratively partitions the items by learning the relevant buckets directly from the query-item relevance data. Furthermore, IRLI employs a superior power-of-$k$-choices based load balancing strategy. We mathematically show that IRLI retrieves the correct item with high probability under very natural assumptions and provides superior load balancing. IRLI surpasses the best baseline's precision on multi-label classification while being $5x$ faster on inference. For near-neighbor search tasks, the same method outperforms the state-of-the-art Learned Hashing approach NeuralLSH by requiring only ~ {1/6}^th of the candidates for the same recall. IRLI is both data and model parallel, making it ideal for distributed GPU implementation. We demonstrate this advantage by indexing 100 million dense vectors and surpassing the popular FAISS library by >10% on recall.

</p>
</details>

<details><summary><b>Environment and Person Independent Activity Recognition with a Commodity IEEE 802.11ac Access Point</b>
<a href="https://arxiv.org/abs/2103.09924">arxiv:2103.09924</a>
&#x1F4C8; 1 <br>
<p>Francesca Meneghello, Domenico Garlisi, Nicolò Dal Fabbro, Ilenia Tinnirello, Michele Rossi</p></summary>
<p>

**Abstract:** Here, we propose an original approach for human activity recognition (HAR) with commercial IEEE 802.11ac (WiFi) devices, which generalizes across different persons, days and environments. To achieve this, we devise a technique to extract, clean and process the received phases from the channel frequency response (CFR) of the WiFi channel, obtaining an estimate of the Doppler shift at the receiver of the communication link. The Doppler shift reveals the presence of moving scatterers in the environment, while not being affected by (environment specific) static objects. The proposed HAR framework is trained on data collected as a person performs four different activities and is tested on unseen setups, to assess its performance as the person, the day and/or the environment change with respect to those considered at training time. In the worst case scenario, the proposed HAR technique reaches an average accuracy higher than 95%, validating the effectiveness of the extracted Doppler information, used in conjunction with a learning algorithm based on a neural network, in recognizing human activities in a subject and environment independent fashion.

</p>
</details>

<details><summary><b>Bias-Free FedGAN: A Federated Approach to Generate Bias-Free Datasets</b>
<a href="https://arxiv.org/abs/2103.09876">arxiv:2103.09876</a>
&#x1F4C8; 1 <br>
<p>Vaikkunth Mugunthan, Vignesh Gokul, Lalana Kagal, Shlomo Dubnov</p></summary>
<p>

**Abstract:** Federated Generative Adversarial Network (FedGAN) is a communication-efficient approach to train a GAN across distributed clients without clients having to share their sensitive training data. In this paper, we experimentally show that FedGAN generates biased data points under non-independent-and-identically-distributed (non-iid) settings. Also, we propose Bias-Free FedGAN, an approach to generate bias-free synthetic datasets using FedGAN. Our approach generates metadata at the aggregator using the models received from clients and retrains the federated model to achieve bias-free results for image synthesis. Bias-Free FedGAN has the same communication cost as that of FedGAN. Experimental results on image datasets (MNIST and FashionMNIST) validate our claims.

</p>
</details>

<details><summary><b>An Overflow/Underflow-Free Fixed-Point Bit-Width Optimization Method for OS-ELM Digital Circuit</b>
<a href="https://arxiv.org/abs/2103.09791">arxiv:2103.09791</a>
&#x1F4C8; 1 <br>
<p>Mineto Tsukada, Hiroki Matsutani</p></summary>
<p>

**Abstract:** Currently there has been increasing demand for real-time training on resource-limited IoT devices such as smart sensors, which realizes standalone online adaptation for streaming data without data transfers to remote servers. OS-ELM (Online Sequential Extreme Learning Machine) has been one of promising neural-network-based online algorithms for on-chip learning because it can perform online training at low computational cost and is easy to implement as a digital circuit. Existing OS-ELM digital circuits employ fixed-point data format and the bit-widths are often manually tuned, however, this may cause overflow or underflow which can lead to unexpected behavior of the circuit. For on-chip learning systems, an overflow/underflow-free design has a great impact since online training is continuously performed and the intervals of intermediate variables will dynamically change as time goes by. In this paper, we propose an overflow/underflow-free bit-width optimization method for fixed-point digital circuits of OS-ELM. Experimental results show that our method realizes overflow/underflow-free OS-ELM digital circuits with 1.0x - 1.5x more area cost compared to the baseline simulation method where overflow or underflow can happen.

</p>
</details>

<details><summary><b>COVIDx-US -- An open-access benchmark dataset of ultrasound imaging data for AI-driven COVID-19 analytics</b>
<a href="https://arxiv.org/abs/2103.10003">arxiv:2103.10003</a>
&#x1F4C8; 0 <br>
<p>Ashkan Ebadi, Pengcheng Xi, Alexander MacLean, Stéphane Tremblay, Sonny Kohli, Alexander Wong</p></summary>
<p>

**Abstract:** The COVID-19 pandemic continues to have a devastating effect on the health and well-being of the global population. Apart from the global health crises, the pandemic has also caused significant economic and financial difficulties and socio-physiological implications. Effective screening, triage, treatment planning, and prognostication of outcome plays a key role in controlling the pandemic. Recent studies have highlighted the role of point-of-care ultrasound imaging for COVID-19 screening and prognosis, particularly given that it is non-invasive, globally available, and easy-to-sanitize. Motivated by these attributes and the promise of artificial intelligence tools to aid clinicians, we introduce COVIDx-US, an open-access benchmark dataset of COVID-19 related ultrasound imaging data. The COVIDx-US dataset was curated from multiple sources and its current version, i.e., v1.2., consists of 150 lung ultrasound videos and 12,943 processed images of patients infected with COVID-19 infection, non-COVID-19 infection, other lung diseases/conditions, as well as normal control cases. The COVIDx-US is the largest open-access fully-curated dataset of its kind that has been systematically curated, processed, and validated specifically for the purpose of building and evaluating artificial intelligence algorithms and models.

</p>
</details>

<details><summary><b>SILT: Efficient transformer training for inter-lingual inference</b>
<a href="https://arxiv.org/abs/2103.09635">arxiv:2103.09635</a>
&#x1F4C8; 0 <br>
<p>Javier Huertas-Tato, Alejandro Martín, David Camacho</p></summary>
<p>

**Abstract:** The ability of transformers to perform precision tasks such as question answering, Natural Language Inference (NLI) or summarising, have enabled them to be ranked as one of the best paradigm to address Natural Language Processing (NLP) tasks. NLI is one of the best scenarios to test these architectures, due to the knowledge required to understand complex sentences and established relationships between a hypothesis and a premise. Nevertheless, these models suffer from incapacity to generalise to other domains or difficulties to face multilingual and interlingual scenarios. The leading pathway in the literature to address these issues involve designing and training extremely large architectures, which leads to unpredictable behaviours and to establish barriers which impede broad access and fine tuning. In this paper, we propose a new architecture called Siamese Inter-Lingual Transformer (SILT), to efficiently align multilingual embeddings for Natural Language Inference, allowing for unmatched language pairs to be processed. SILT leverages siamese pre-trained multi-lingual transformers with frozen weights where the two input sentences attend each other to later be combined through a matrix alignment method. The experimental results carried out in this paper evidence that SILT allows to reduce drastically the number of trainable parameters while allowing for inter-lingual NLI and achieving state-of-the-art performance on common benchmarks.
  We make our code and dataset available at https://github.com/jahuerta92/siamese-inter-lingual-transformer.

</p>
</details>

<details><summary><b>The U-Net based GLOW for Optical-Flow-free Video Interframe Generation</b>
<a href="https://arxiv.org/abs/2103.09576">arxiv:2103.09576</a>
&#x1F4C8; 0 <br>
<p>Saem Park, Donghoon Han, Nojun Kwak</p></summary>
<p>

**Abstract:** Video frame interpolation is the task of creating an interframe between two adjacent frames along the time axis. So, instead of simply averaging two adjacent frames to create an intermediate image, this operation should maintain semantic continuity with the adjacent frames. Most conventional methods use optical flow, and various tools such as occlusion handling and object smoothing are indispensable. Since the use of these various tools leads to complex problems, we tried to tackle the video interframe generation problem without using problematic optical flow . To enable this , we have tried to use a deep neural network with an invertible structure, and developed an U-Net based Generative Flow which is a modified normalizing flow. In addition, we propose a learning method with a new consistency loss in the latent space to maintain semantic temporal consistency between frames. The resolution of the generated image is guaranteed to be identical to that of the original images by using an invertible network. Furthermore, as it is not a random image like the ones by generative models, our network guarantees stable outputs without flicker. Through experiments, we \sam {confirmed the feasibility of the proposed algorithm and would like to suggest the U-Net based Generative Flow as a new possibility for baseline in video frame interpolation. This paper is meaningful in that it is the world's first attempt to use invertible networks instead of optical flows for video interpolation.

</p>
</details>

<details><summary><b>Big Plastic Masses Detection using Sentinel 2 Images</b>
<a href="https://arxiv.org/abs/2103.09560">arxiv:2103.09560</a>
&#x1F4C8; 0 <br>
<p>Fernando Martin-Rodriguez</p></summary>
<p>

**Abstract:** This communication describes a preliminary research on detection of big masses of plastic (marine litter) on the oceans and seas using EO (Earth Observation) satellite systems. Free images from the Sentinel 2 (Copernicus Project) platform are used. To develop a plastic recognizer, we start with an image where we can find a big accumulation of "nonfloating" plastic: Almería greenhouses. We made a test using remote sensing differential indexes, but we got much better results using all available wavelengths (thirteen frequency bands) and applying Neural Networks to that feature vector.

</p>
</details>


[Next Page](2021/2021-03/2021-03-16.md)
