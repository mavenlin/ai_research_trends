## Summary for 2021-04-27, created on 2021-12-22


<details><summary><b>Geometric Deep Learning: Grids, Groups, Graphs, Geodesics, and Gauges</b>
<a href="https://arxiv.org/abs/2104.13478">arxiv:2104.13478</a>
&#x1F4C8; 119 <br>
<p>Michael M. Bronstein, Joan Bruna, Taco Cohen, Petar Veličković</p></summary>
<p>

**Abstract:** The last decade has witnessed an experimental revolution in data science and machine learning, epitomised by deep learning methods. Indeed, many high-dimensional learning tasks previously thought to be beyond reach -- such as computer vision, playing Go, or protein folding -- are in fact feasible with appropriate computational scale. Remarkably, the essence of deep learning is built from two simple algorithmic principles: first, the notion of representation or feature learning, whereby adapted, often hierarchical, features capture the appropriate notion of regularity for each task, and second, learning by local gradient-descent type methods, typically implemented as backpropagation.
  While learning generic functions in high dimensions is a cursed estimation problem, most tasks of interest are not generic, and come with essential pre-defined regularities arising from the underlying low-dimensionality and structure of the physical world. This text is concerned with exposing these regularities through unified geometric principles that can be applied throughout a wide spectrum of applications.
  Such a 'geometric unification' endeavour, in the spirit of Felix Klein's Erlangen Program, serves a dual purpose: on one hand, it provides a common mathematical framework to study the most successful neural network architectures, such as CNNs, RNNs, GNNs, and Transformers. On the other hand, it gives a constructive procedure to incorporate prior physical knowledge into neural architectures and provide principled way to build future architectures yet to be invented.

</p>
</details>

<details><summary><b>From Human Explanation to Model Interpretability: A Framework Based on Weight of Evidence</b>
<a href="https://arxiv.org/abs/2104.13299">arxiv:2104.13299</a>
&#x1F4C8; 99 <br>
<p>David Alvarez-Melis, Harmanpreet Kaur, Hal Daumé III, Hanna Wallach, Jennifer Wortman Vaughan</p></summary>
<p>

**Abstract:** We take inspiration from the study of human explanation to inform the design and evaluation of interpretability methods in machine learning. First, we survey the literature on human explanation in philosophy, cognitive science, and the social sciences, and propose a list of design principles for machine-generated explanations that are meaningful to humans. Using the concept of weight of evidence from information theory, we develop a method for generating explanations that adhere to these principles. We show that this method can be adapted to handle high-dimensional, multi-class settings, yielding a flexible framework for generating explanations. We demonstrate that these explanations can be estimated accurately from finite samples and are robust to small perturbations of the inputs. We also evaluate our method through a qualitative user study with machine learning practitioners, where we observe that the resulting explanations are usable despite some participants struggling with background concepts like prior class probabilities. Finally, we conclude by surfacing~design~implications for interpretability tools in general.

</p>
</details>

<details><summary><b>Explaining in Style: Training a GAN to explain a classifier in StyleSpace</b>
<a href="https://arxiv.org/abs/2104.13369">arxiv:2104.13369</a>
&#x1F4C8; 88 <br>
<p>Oran Lang, Yossi Gandelsman, Michal Yarom, Yoav Wald, Gal Elidan, Avinatan Hassidim, William T. Freeman, Phillip Isola, Amir Globerson, Michal Irani, Inbar Mosseri</p></summary>
<p>

**Abstract:** Image classification models can depend on multiple different semantic attributes of the image. An explanation of the decision of the classifier needs to both discover and visualize these properties. Here we present StylEx, a method for doing this, by training a generative model to specifically explain multiple attributes that underlie classifier decisions. A natural source for such attributes is the StyleSpace of StyleGAN, which is known to generate semantically meaningful dimensions in the image. However, because standard GAN training is not dependent on the classifier, it may not represent these attributes which are important for the classifier decision, and the dimensions of StyleSpace may represent irrelevant attributes. To overcome this, we propose a training procedure for a StyleGAN, which incorporates the classifier model, in order to learn a classifier-specific StyleSpace. Explanatory attributes are then selected from this space. These can be used to visualize the effect of changing multiple attributes per image, thus providing image-specific explanations. We apply StylEx to multiple domains, including animals, leaves, faces and retinal images. For these, we show how an image can be modified in different ways to change its classifier output. Our results show that the method finds attributes that align well with semantic ones, generate meaningful image-specific explanations, and are human-interpretable as measured in user-studies.

</p>
</details>

<details><summary><b>AMSS-Net: Audio Manipulation on User-Specified Sources with Textual Queries</b>
<a href="https://arxiv.org/abs/2104.13553">arxiv:2104.13553</a>
&#x1F4C8; 16 <br>
<p>Woosung Choi, Minseok Kim, Marco A. Martínez Ramírez, Jaehwa Chung, Soonyoung Jung</p></summary>
<p>

**Abstract:** This paper proposes a neural network that performs audio transformations to user-specified sources (e.g., vocals) of a given audio track according to a given description while preserving other sources not mentioned in the description. Audio Manipulation on a Specific Source (AMSS) is challenging because a sound object (i.e., a waveform sample or frequency bin) is `transparent'; it usually carries information from multiple sources, in contrast to a pixel in an image. To address this challenging problem, we propose AMSS-Net, which extracts latent sources and selectively manipulates them while preserving irrelevant sources. We also propose an evaluation benchmark for several AMSS tasks, and we show that AMSS-Net outperforms baselines on several AMSS tasks via objective metrics and empirical verification.

</p>
</details>

<details><summary><b>Policy Manifold Search: Exploring the Manifold Hypothesis for Diversity-based Neuroevolution</b>
<a href="https://arxiv.org/abs/2104.13424">arxiv:2104.13424</a>
&#x1F4C8; 16 <br>
<p>Nemanja Rakicevic, Antoine Cully, Petar Kormushev</p></summary>
<p>

**Abstract:** Neuroevolution is an alternative to gradient-based optimisation that has the potential to avoid local minima and allows parallelisation. The main limiting factor is that usually it does not scale well with parameter space dimensionality. Inspired by recent work examining neural network intrinsic dimension and loss landscapes, we hypothesise that there exists a low-dimensional manifold, embedded in the policy network parameter space, around which a high-density of diverse and useful policies are located. This paper proposes a novel method for diversity-based policy search via Neuroevolution, that leverages learned representations of the policy network parameters, by performing policy search in this learned representation space. Our method relies on the Quality-Diversity (QD) framework which provides a principled approach to policy search, and maintains a collection of diverse policies, used as a dataset for learning policy representations. Further, we use the Jacobian of the inverse-mapping function to guide the search in the representation space. This ensures that the generated samples remain in the high-density regions, after mapping back to the original space. Finally, we evaluate our contributions on four continuous-control tasks in simulated environments, and compare to diversity-based baselines.

</p>
</details>

<details><summary><b>Sifting out the features by pruning: Are convolutional networks the winning lottery ticket of fully connected ones?</b>
<a href="https://arxiv.org/abs/2104.13343">arxiv:2104.13343</a>
&#x1F4C8; 10 <br>
<p>Franco Pellegrini, Giulio Biroli</p></summary>
<p>

**Abstract:** Pruning methods can considerably reduce the size of artificial neural networks without harming their performance. In some cases, they can even uncover sub-networks that, when trained in isolation, match or surpass the test accuracy of their dense counterparts. Here we study the inductive bias that pruning imprints in such "winning lottery tickets". Focusing on visual tasks, we analyze the architecture resulting from iterative magnitude pruning of a simple fully connected network (FCN). We show that the surviving node connectivity is local in input space, and organized in patterns reminiscent of the ones found in convolutional networks (CNN). We investigate the role played by data and tasks in shaping the architecture of pruned sub-networks. Our results show that the winning lottery tickets of FCNs display the key features of CNNs. The ability of such automatic network-simplifying procedure to recover the key features "hand-crafted" in the design of CNNs suggests interesting applications to other datasets and tasks, in order to discover new and efficient architectural inductive biases.

</p>
</details>

<details><summary><b>Meta-evaluation of Conversational Search Evaluation Metrics</b>
<a href="https://arxiv.org/abs/2104.13453">arxiv:2104.13453</a>
&#x1F4C8; 9 <br>
<p>Zeyang Liu, Ke Zhou, Max L. Wilson</p></summary>
<p>

**Abstract:** Conversational search systems, such as Google Assistant and Microsoft Cortana, enable users to interact with search systems in multiple rounds through natural language dialogues. Evaluating such systems is very challenging given that any natural language responses could be generated, and users commonly interact for multiple semantically coherent rounds to accomplish a search task. Although prior studies proposed many evaluation metrics, the extent of how those measures effectively capture user preference remains to be investigated. In this paper, we systematically meta-evaluate a variety of conversational search metrics. We specifically study three perspectives on those metrics: (1) reliability: the ability to detect "actual" performance differences as opposed to those observed by chance; (2) fidelity: the ability to agree with ultimate user preference; and (3) intuitiveness: the ability to capture any property deemed important: adequacy, informativeness, and fluency in the context of conversational search. By conducting experiments on two test collections, we find that the performance of different metrics varies significantly across different scenarios whereas consistent with prior studies, existing metrics only achieve a weak correlation with ultimate user preference and satisfaction. METEOR is, comparatively speaking, the best existing single-turn metric considering all three perspectives. We also demonstrate that adapted session-based evaluation metrics can be used to measure multi-turn conversational search, achieving moderate concordance with user satisfaction. To our knowledge, our work establishes the most comprehensive meta-evaluation for conversational search to date.

</p>
</details>

<details><summary><b>End-to-End Video-To-Speech Synthesis using Generative Adversarial Networks</b>
<a href="https://arxiv.org/abs/2104.13332">arxiv:2104.13332</a>
&#x1F4C8; 9 <br>
<p>Rodrigo Mira, Konstantinos Vougioukas, Pingchuan Ma, Stavros Petridis, Björn W. Schuller, Maja Pantic</p></summary>
<p>

**Abstract:** Video-to-speech is the process of reconstructing the audio speech from a video of a spoken utterance. Previous approaches to this task have relied on a two-step process where an intermediate representation is inferred from the video, and is then decoded into waveform audio using a vocoder or a waveform reconstruction algorithm. In this work, we propose a new end-to-end video-to-speech model based on Generative Adversarial Networks (GANs) which translates spoken video to waveform end-to-end without using any intermediate representation or separate waveform synthesis algorithm. Our model consists of an encoder-decoder architecture that receives raw video as input and generates speech, which is then fed to a waveform critic and a power critic. The use of an adversarial loss based on these two critics enables the direct synthesis of raw audio waveform and ensures its realism. In addition, the use of our three comparative losses helps establish direct correspondence between the generated audio and the input video. We show that this model is able to reconstruct speech with remarkable realism for constrained datasets such as GRID, and that it is the first end-to-end model to produce intelligible speech for LRW (Lip Reading in the Wild), featuring hundreds of speakers recorded entirely `in the wild'. We evaluate the generated samples in two different scenarios -- seen and unseen speakers -- using four objective metrics which measure the quality and intelligibility of artificial speech. We demonstrate that the proposed approach outperforms all previous works in most metrics on GRID and LRW.

</p>
</details>

<details><summary><b>Do Feature Attribution Methods Correctly Attribute Features?</b>
<a href="https://arxiv.org/abs/2104.14403">arxiv:2104.14403</a>
&#x1F4C8; 8 <br>
<p>Yilun Zhou, Serena Booth, Marco Tulio Ribeiro, Julie Shah</p></summary>
<p>

**Abstract:** Feature attribution methods are popular in interpretable machine learning. These methods compute the attribution of each input feature to represent its importance, but there is no consensus on the definition of "attribution", leading to many competing methods with little systematic evaluation, complicated in particular by the lack of ground truth attribution. To address this, we propose a dataset modification procedure to induce such ground truth. Using this procedure, we evaluate three common methods: saliency maps, rationales, and attentions. We identify several deficiencies and add new perspectives to the growing body of evidence questioning the correctness and reliability of these methods applied on datasets in the wild. We further discuss possible avenues for remedy and recommend new attribution methods to be tested against ground truth before deployment. The code is available at https://github.com/YilunZhou/feature-attribution-evaluation

</p>
</details>

<details><summary><b>SpikE: spike-based embeddings for multi-relational graph data</b>
<a href="https://arxiv.org/abs/2104.13398">arxiv:2104.13398</a>
&#x1F4C8; 8 <br>
<p>Dominik Dold, Josep Soler Garrido</p></summary>
<p>

**Abstract:** Despite the recent success of reconciling spike-based coding with the error backpropagation algorithm, spiking neural networks are still mostly applied to tasks stemming from sensory processing, operating on traditional data structures like visual or auditory data. A rich data representation that finds wide application in industry and research is the so-called knowledge graph - a graph-based structure where entities are depicted as nodes and relations between them as edges. Complex systems like molecules, social networks and industrial factory systems can be described using the common language of knowledge graphs, allowing the usage of graph embedding algorithms to make context-aware predictions in these information-packed environments. We propose a spike-based algorithm where nodes in a graph are represented by single spike times of neuron populations and relations as spike time differences between populations. Learning such spike-based embeddings only requires knowledge about spike times and spike time differences, compatible with recently proposed frameworks for training spiking neural networks. The presented model is easily mapped to current neuromorphic hardware systems and thereby moves inference on knowledge graphs into a domain where these architectures thrive, unlocking a promising industrial application area for this technology.

</p>
</details>

<details><summary><b>Visually grounded models of spoken language: A survey of datasets, architectures and evaluation techniques</b>
<a href="https://arxiv.org/abs/2104.13225">arxiv:2104.13225</a>
&#x1F4C8; 7 <br>
<p>Grzegorz Chrupała</p></summary>
<p>

**Abstract:** This survey provides an overview of the evolution of visually grounded models of spoken language over the last 20 years. Such models are inspired by the observation that when children pick up a language, they rely on a wide range of indirect and noisy clues, crucially including signals from the visual modality co-occurring with spoken utterances. Several fields have made important contributions to this approach to modeling or mimicking the process of learning language: Machine Learning, Natural Language and Speech Processing, Computer Vision and Cognitive Science. The current paper brings together these contributions in order to provide a useful introduction and overview for practitioners in all these areas. We discuss the central research questions addressed, the timeline of developments, and the datasets which enabled much of this work. We then summarize the main modeling architectures and offer an exhaustive overview of the evaluation metrics and analysis techniques.

</p>
</details>

<details><summary><b>The Hessian Screening Rule</b>
<a href="https://arxiv.org/abs/2104.13026">arxiv:2104.13026</a>
&#x1F4C8; 7 <br>
<p>Johan Larsson, Jonas Wallin</p></summary>
<p>

**Abstract:** Predictor screening rules, which discard predictors from the design matrix before fitting a model, have had sizable impacts on the speed with which $\ell_1$-regularized regression problems, such as the lasso, can be solved. Current state-of-the-art screening rules, however, have difficulties in dealing with highly-correlated predictors, often becoming too conservative. In this paper, we present a new screening rule to deal with this issue: the Hessian Screening Rule. The rule uses second-order information from the model in order to provide more accurate screening as well as higher-quality warm starts. In our experiments on $\ell_1$-regularized least-squares (the lasso) and logistic regression, we show that the rule outperforms all other alternatives in simulated experiments with high correlation, as well as in the majority of real datasets that we study.

</p>
</details>

<details><summary><b>Towards Fair Federated Learning with Zero-Shot Data Augmentation</b>
<a href="https://arxiv.org/abs/2104.13417">arxiv:2104.13417</a>
&#x1F4C8; 6 <br>
<p>Weituo Hao, Mostafa El-Khamy, Jungwon Lee, Jianyi Zhang, Kevin J Liang, Changyou Chen, Lawrence Carin</p></summary>
<p>

**Abstract:** Federated learning has emerged as an important distributed learning paradigm, where a server aggregates a global model from many client-trained models while having no access to the client data. Although it is recognized that statistical heterogeneity of the client local data yields slower global model convergence, it is less commonly recognized that it also yields a biased federated global model with a high variance of accuracy across clients. In this work, we aim to provide federated learning schemes with improved fairness. To tackle this challenge, we propose a novel federated learning system that employs zero-shot data augmentation on under-represented data to mitigate statistical heterogeneity and encourage more uniform accuracy performance across clients in federated networks. We study two variants of this scheme, Fed-ZDAC (federated learning with zero-shot data augmentation at the clients) and Fed-ZDAS (federated learning with zero-shot data augmentation at the server). Empirical results on a suite of datasets demonstrate the effectiveness of our methods on simultaneously improving the test accuracy and fairness.

</p>
</details>

<details><summary><b>SrvfNet: A Generative Network for Unsupervised Multiple Diffeomorphic Shape Alignment</b>
<a href="https://arxiv.org/abs/2104.13449">arxiv:2104.13449</a>
&#x1F4C8; 5 <br>
<p>Elvis Nunez, Andrew Lizarraga, Shantanu H. Joshi</p></summary>
<p>

**Abstract:** We present SrvfNet, a generative deep learning framework for the joint multiple alignment of large collections of functional data comprising square-root velocity functions (SRVF) to their templates. Our proposed framework is fully unsupervised and is capable of aligning to a predefined template as well as jointly predicting an optimal template from data while simultaneously achieving alignment. Our network is constructed as a generative encoder-decoder architecture comprising fully-connected layers capable of producing a distribution space of the warping functions. We demonstrate the strength of our framework by validating it on synthetic data as well as diffusion profiles from magnetic resonance imaging (MRI) data.

</p>
</details>

<details><summary><b>Fast Distributionally Robust Learning with Variance Reduced Min-Max Optimization</b>
<a href="https://arxiv.org/abs/2104.13326">arxiv:2104.13326</a>
&#x1F4C8; 5 <br>
<p>Yaodong Yu, Tianyi Lin, Eric Mazumdar, Michael I. Jordan</p></summary>
<p>

**Abstract:** Distributionally robust supervised learning (DRSL) is emerging as a key paradigm for building reliable machine learning systems for real-world applications -- reflecting the need for classifiers and predictive models that are robust to the distribution shifts that arise from phenomena such as selection bias or nonstationarity. Existing algorithms for solving Wasserstein DRSL -- one of the most popular DRSL frameworks based around robustness to perturbations in the Wasserstein distance -- involve solving complex subproblems or fail to make use of stochastic gradients, limiting their use in large-scale machine learning problems. We revisit Wasserstein DRSL through the lens of min-max optimization and derive scalable and efficiently implementable stochastic extra-gradient algorithms which provably achieve faster convergence rates than existing approaches. We demonstrate their effectiveness on synthetic and real data when compared to existing DRSL approaches. Key to our results is the use of variance reduction and random reshuffling to accelerate stochastic min-max optimization, the analysis of which may be of independent interest.

</p>
</details>

<details><summary><b>Semi-supervised Superpixel-based Multi-Feature Graph Learning for Hyperspectral Image Data</b>
<a href="https://arxiv.org/abs/2104.13268">arxiv:2104.13268</a>
&#x1F4C8; 5 <br>
<p>Madeleine Kotzagiannidis, Carola-Bibiane Schönlieb</p></summary>
<p>

**Abstract:** Graphs naturally lend themselves to model the complexities of Hyperspectral Image (HSI) data as well as to serve as semi-supervised classifiers by propagating given labels among nearest neighbours. In this work, we present a novel framework for the classification of HSI data in light of a very limited amount of labelled data, inspired by multi-view graph learning and graph signal processing. Given an a priori superpixel-segmented hyperspectral image, we seek a robust and efficient graph construction and label propagation method to conduct semi-supervised learning (SSL). Since the graph is paramount to the success of the subsequent classification task, particularly in light of the intrinsic complexity of HSI data, we consider the problem of finding the optimal graph to model such data. Our contribution is two-fold: firstly, we propose a multi-stage edge-efficient semi-supervised graph learning framework for HSI data which exploits given label information through pseudo-label features embedded in the graph construction. Secondly, we examine and enhance the contribution of multiple superpixel features embedded in the graph on the basis of pseudo-labels in an extension of the previous framework, which is less reliant on excessive parameter tuning. Ultimately, we demonstrate the superiority of our approaches in comparison with state-of-the-art methods through extensive numerical experiments.

</p>
</details>

<details><summary><b>Multi-view Deep One-class Classification: A Systematic Exploration</b>
<a href="https://arxiv.org/abs/2104.13000">arxiv:2104.13000</a>
&#x1F4C8; 5 <br>
<p>Siqi Wang, Jiyuan Liu, Guang Yu, Xinwang Liu, Sihang Zhou, En Zhu, Yuexiang Yang, Jianping Yin</p></summary>
<p>

**Abstract:** One-class classification (OCC), which models one single positive class and distinguishes it from the negative class, has been a long-standing topic with pivotal application to realms like anomaly detection. As modern society often deals with massive high-dimensional complex data spawned by multiple sources, it is natural to consider OCC from the perspective of multi-view deep learning. However, it has not been discussed by the literature and remains an unexplored topic. Motivated by this blank, this paper makes four-fold contributions: First, to our best knowledge, this is the first work that formally identifies and formulates the multi-view deep OCC problem. Second, we take recent advances in relevant areas into account and systematically devise eleven different baseline solutions for multi-view deep OCC, which lays the foundation for research on multi-view deep OCC. Third, to remedy the problem that limited benchmark datasets are available for multi-view deep OCC, we extensively collect existing public data and process them into more than 30 new multi-view benchmark datasets via multiple means, so as to provide a publicly available evaluation platform for multi-view deep OCC. Finally, by comprehensively evaluating the devised solutions on benchmark datasets, we conduct a thorough analysis on the effectiveness of the designed baselines, and hopefully provide other researchers with beneficial guidance and insight to multi-view deep OCC. Our data and codes are opened at https://github.com/liujiyuan13/MvDOCC-datasets and https://github.com/liujiyuan13/MvDOCC-code respectively to facilitate future research.

</p>
</details>

<details><summary><b>Detection of Signal in the Spiked Rectangular Models</b>
<a href="https://arxiv.org/abs/2104.13517">arxiv:2104.13517</a>
&#x1F4C8; 4 <br>
<p>Ji Hyung Jung, Hye Won Chung, Ji Oon Lee</p></summary>
<p>

**Abstract:** We consider the problem of detecting signals in the rank-one signal-plus-noise data matrix models that generalize the spiked Wishart matrices. We show that the principal component analysis can be improved by pre-transforming the matrix entries if the noise is non-Gaussian. As an intermediate step, we prove a sharp phase transition of the largest eigenvalues of spiked rectangular matrices, which extends the Baik-Ben Arous-Péché (BBP) transition. We also propose a hypothesis test to detect the presence of signal with low computational complexity, based on the linear spectral statistics, which minimizes the sum of the Type-I and Type-II errors when the noise is Gaussian.

</p>
</details>

<details><summary><b>Text Generation with Deep Variational GAN</b>
<a href="https://arxiv.org/abs/2104.13488">arxiv:2104.13488</a>
&#x1F4C8; 4 <br>
<p>Mahmoud Hossam, Trung Le, Michael Papasimeon, Viet Huynh, Dinh Phung</p></summary>
<p>

**Abstract:** Generating realistic sequences is a central task in many machine learning applications. There has been considerable recent progress on building deep generative models for sequence generation tasks. However, the issue of mode-collapsing remains a main issue for the current models. In this paper we propose a GAN-based generic framework to address the problem of mode-collapse in a principled approach. We change the standard GAN objective to maximize a variational lower-bound of the log-likelihood while minimizing the Jensen-Shanon divergence between data and model distributions. We experiment our model with text generation task and show that it can generate realistic text with high diversity.

</p>
</details>

<details><summary><b>MULTIMODAL ANALYSIS: Informed content estimation and audio source separation</b>
<a href="https://arxiv.org/abs/2104.13276">arxiv:2104.13276</a>
&#x1F4C8; 4 <br>
<p>Gabriel Meseguer-Brocal</p></summary>
<p>

**Abstract:** This dissertation proposes the study of multimodal learning in the context of musical signals. Throughout, we focus on the interaction between audio signals and text information. Among the many text sources related to music that can be used (e.g. reviews, metadata, or social network feedback), we concentrate on lyrics. The singing voice directly connects the audio signal and the text information in a unique way, combining melody and lyrics where a linguistic dimension complements the abstraction of musical instruments. Our study focuses on the audio and lyrics interaction for targeting source separation and informed content estimation.

</p>
</details>

<details><summary><b>A Scalable and Reproducible System-on-Chip Simulation for Reinforcement Learning</b>
<a href="https://arxiv.org/abs/2104.13187">arxiv:2104.13187</a>
&#x1F4C8; 4 <br>
<p>Tegg Taekyong Sung, Bo Ryu</p></summary>
<p>

**Abstract:** Deep Reinforcement Learning (DRL) underlies in a simulated environment and optimizes objective goals. By extending the conventional interaction scheme, this paper proffers gym-ds3, a scalable and reproducible open environment tailored for a high-fidelity Domain-Specific System-on-Chip (DSSoC) application. The simulation corroborates to schedule hierarchical jobs onto heterogeneous System-on-Chip (SoC) processors and bridges the system to reinforcement learning research. We systematically analyze the representative SoC simulator and discuss the primary challenging aspects that the system (1) continuously generates indefinite jobs at a rapid injection rate, (2) optimizes complex objectives, and (3) operates in steady-state scheduling. We provide exemplary snippets and experimentally demonstrate the run-time performances on different schedulers that successfully mimic results achieved from the standard DS3 framework and real-world embedded systems.

</p>
</details>

<details><summary><b>Initializing LSTM internal states via manifold learning</b>
<a href="https://arxiv.org/abs/2104.13101">arxiv:2104.13101</a>
&#x1F4C8; 4 <br>
<p>Felix P. Kemeth, Tom Bertalan, Nikolaos Evangelou, Tianqi Cui, Saurabh Malani, Ioannis G. Kevrekidis</p></summary>
<p>

**Abstract:** We present an approach, based on learning an intrinsic data manifold, for the initialization of the internal state values of LSTM recurrent neural networks, ensuring consistency with the initial observed input data. Exploiting the generalized synchronization concept, we argue that the converged, "mature" internal states constitute a function on this learned manifold. The dimension of this manifold then dictates the length of observed input time series data required for consistent initialization. We illustrate our approach through a partially observed chemical model system, where initializing the internal LSTM states in this fashion yields visibly improved performance. Finally, we show that learning this data manifold enables the transformation of partially observed dynamics into fully observed ones, facilitating alternative identification paths for nonlinear dynamical systems.

</p>
</details>

<details><summary><b>Graph Neural Networks for Traffic Forecasting</b>
<a href="https://arxiv.org/abs/2104.13096">arxiv:2104.13096</a>
&#x1F4C8; 4 <br>
<p>João Rico, José Barateiro, Arlindo Oliveira</p></summary>
<p>

**Abstract:** The significant increase in world population and urbanisation has brought several important challenges, in particular regarding the sustainability, maintenance and planning of urban mobility. At the same time, the exponential increase of computing capability and of available sensor and location data have offered the potential for innovative solutions to these challenges. In this work, we focus on the challenge of traffic forecasting and review the recent development and application of graph neural networks (GNN) to this problem. GNNs are a class of deep learning methods that directly process the input as graph data. This leverages more directly the spatial dependencies of traffic data and makes use of the advantages of deep learning producing state-of-the-art results. We introduce and review the emerging topic of GNNs, including their most common variants, with a focus on its application to traffic forecasting. We address the different ways of modelling traffic forecasting as a (temporal) graph, the different approaches developed so far to combine the graph and temporal learning components, as well as current limitations and research opportunities.

</p>
</details>

<details><summary><b>Using Radio Archives for Low-Resource Speech Recognition: Towards an Intelligent Virtual Assistant for Illiterate Users</b>
<a href="https://arxiv.org/abs/2104.13083">arxiv:2104.13083</a>
&#x1F4C8; 4 <br>
<p>Moussa Doumbouya, Lisa Einstein, Chris Piech</p></summary>
<p>

**Abstract:** For many of the 700 million illiterate people around the world, speech recognition technology could provide a bridge to valuable information and services. Yet, those most in need of this technology are often the most underserved by it. In many countries, illiterate people tend to speak only low-resource languages, for which the datasets necessary for speech technology development are scarce. In this paper, we investigate the effectiveness of unsupervised speech representation learning on noisy radio broadcasting archives, which are abundant even in low-resource languages. We make three core contributions. First, we release two datasets to the research community. The first, West African Radio Corpus, contains 142 hours of audio in more than 10 languages with a labeled validation subset. The second, West African Virtual Assistant Speech Recognition Corpus, consists of 10K labeled audio clips in four languages. Next, we share West African wav2vec, a speech encoder trained on the noisy radio corpus, and compare it with the baseline Facebook speech encoder trained on six times more data of higher quality. We show that West African wav2vec performs similarly to the baseline on a multilingual speech recognition task, and significantly outperforms the baseline on a West African language identification task. Finally, we share the first-ever speech recognition models for Maninka, Pular and Susu, languages spoken by a combined 10 million people in over seven countries, including six where the majority of the adult population is illiterate. Our contributions offer a path forward for ethical AI research to serve the needs of those most disadvantaged by the digital divide.

</p>
</details>

<details><summary><b>Unsupervised Deep Manifold Attributed Graph Embedding</b>
<a href="https://arxiv.org/abs/2104.13048">arxiv:2104.13048</a>
&#x1F4C8; 4 <br>
<p>Zelin Zang, Siyuan Li, Di Wu, Jianzhu Guo, Yongjie Xu, Stan Z. Li</p></summary>
<p>

**Abstract:** Unsupervised attributed graph representation learning is challenging since both structural and feature information are required to be represented in the latent space. Existing methods concentrate on learning latent representation via reconstruction tasks, but cannot directly optimize representation and are prone to oversmoothing, thus limiting the applications on downstream tasks. To alleviate these issues, we propose a novel graph embedding framework named Deep Manifold Attributed Graph Embedding (DMAGE). A node-to-node geodesic similarity is proposed to compute the inter-node similarity between the data space and the latent space and then use Bergman divergence as loss function to minimize the difference between them. We then design a new network structure with fewer aggregation to alleviate the oversmoothing problem and incorporate graph structure augmentation to improve the representation's stability. Our proposed DMAGE surpasses state-of-the-art methods by a significant margin on three downstream tasks: unsupervised visualization, node clustering, and link prediction across four popular datasets.

</p>
</details>

<details><summary><b>Improved and Efficient Text Adversarial Attacks using Target Information</b>
<a href="https://arxiv.org/abs/2104.13484">arxiv:2104.13484</a>
&#x1F4C8; 3 <br>
<p>Mahmoud Hossam, Trung Le, He Zhao, Viet Huynh, Dinh Phung</p></summary>
<p>

**Abstract:** There has been recently a growing interest in studying adversarial examples on natural language models in the black-box setting. These methods attack natural language classifiers by perturbing certain important words until the classifier label is changed. In order to find these important words, these methods rank all words by importance by querying the target model word by word for each input sentence, resulting in high query inefficiency. A new interesting approach was introduced that addresses this problem through interpretable learning to learn the word ranking instead of previous expensive search. The main advantage of using this approach is that it achieves comparable attack rates to the state-of-the-art methods, yet faster and with fewer queries, where fewer queries are desirable to avoid suspicion towards the attacking agent. Nonetheless, this approach sacrificed the useful information that could be leveraged from the target classifier for that sake of query efficiency. In this paper we study the effect of leveraging the target model outputs and data on both attack rates and average number of queries, and we show that both can be improved, with a limited overhead of additional queries.

</p>
</details>

<details><summary><b>TRECVID 2020: A comprehensive campaign for evaluating video retrieval tasks across multiple application domains</b>
<a href="https://arxiv.org/abs/2104.13473">arxiv:2104.13473</a>
&#x1F4C8; 3 <br>
<p>George Awad, Asad A. Butt, Keith Curtis, Jonathan Fiscus, Afzal Godil, Yooyoung Lee, Andrew Delgado, Jesse Zhang, Eliot Godard, Baptiste Chocot, Lukas Diduch, Jeffrey Liu, Alan F. Smeaton, Yvette Graham, Gareth J. F. Jones, Wessel Kraaij, Georges Quenot</p></summary>
<p>

**Abstract:** The TREC Video Retrieval Evaluation (TRECVID) is a TREC-style video analysis and retrieval evaluation with the goal of promoting progress in research and development of content-based exploitation and retrieval of information from digital video via open, metrics-based evaluation. Over the last twenty years this effort has yielded a better understanding of how systems can effectively accomplish such processing and how one can reliably benchmark their performance. TRECVID has been funded by NIST (National Institute of Standards and Technology) and other US government agencies. In addition, many organizations and individuals worldwide contribute significant time and effort. TRECVID 2020 represented a continuation of four tasks and the addition of two new tasks. In total, 29 teams from various research organizations worldwide completed one or more of the following six tasks: 1. Ad-hoc Video Search (AVS), 2. Instance Search (INS), 3. Disaster Scene Description and Indexing (DSDI), 4. Video to Text Description (VTT), 5. Activities in Extended Video (ActEV), 6. Video Summarization (VSUM). This paper is an introduction to the evaluation framework, tasks, data, and measures used in the evaluation campaign.

</p>
</details>

<details><summary><b>The Role of General Intelligence in Mathematical Reasoning</b>
<a href="https://arxiv.org/abs/2104.13468">arxiv:2104.13468</a>
&#x1F4C8; 3 <br>
<p>Aviv Keren</p></summary>
<p>

**Abstract:** Objects are a centerpiece of the mathematical realm and our interaction with and reasoning about it, just as they are of the physical one (if not more). And humans' mathematical reasoning must ultimately be grounded in our general intelligence. Yet in contemporary cognitive science and A.I., the physical and mathematical domains are customarily explored separately, which allows for baking in assumptions for what objects are for the system - and missing potential connections.
  In this paper, I put the issue into its philosophical and cognitive context. I then describe an abstract theoretical framework for learning object representations, that makes room for mathematical objects on par with non-mathematical ones. Finally, I describe a case study that builds on that view to show how our general ability for integrating different aspects of objects effects our conception of the natural numbers.

</p>
</details>

<details><summary><b>Deep 3D-to-2D Watermarking: Embedding Messages in 3D Meshes and Extracting Them from 2D Renderings</b>
<a href="https://arxiv.org/abs/2104.13450">arxiv:2104.13450</a>
&#x1F4C8; 3 <br>
<p>Innfarn Yoo, Huiwen Chang, Xiyang Luo, Ondrej Stava, Ce Liu, Peyman Milanfar, Feng Yang</p></summary>
<p>

**Abstract:** Digital watermarking is widely used for copyright protection. Traditional 3D watermarking approaches or commercial software are typically designed to embed messages into 3D meshes, and later retrieve the messages directly from distorted/undistorted watermarked 3D meshes. Retrieving messages from 2D renderings of such meshes, however, is still challenging and underexplored. We introduce a novel end-to-end learning framework to solve this problem through: 1) an encoder to covertly embed messages in both mesh geometry and textures; 2) a differentiable renderer to render watermarked 3D objects from different camera angles and under varied lighting conditions; 3) a decoder to recover the messages from 2D rendered images. From extensive experiments, we show that our models learn to embed information visually imperceptible to humans, and to reconstruct the embedded information from 2D renderings robust to 3D distortions. In addition, we demonstrate that our method can be generalized to work with different renderers, such as ray tracers and real-time renderers.

</p>
</details>

<details><summary><b>Contrastive Spatial Reasoning on Multi-View Line Drawings</b>
<a href="https://arxiv.org/abs/2104.13433">arxiv:2104.13433</a>
&#x1F4C8; 3 <br>
<p>Siyuan Xiang, Anbang Yang, Yanfei Xue, Yaoqing Yang, Chen Feng</p></summary>
<p>

**Abstract:** Spatial reasoning on multi-view line drawings by state-of-the-art supervised deep networks is recently shown with puzzling low performances on the SPARE3D dataset. To study the reason behind the low performance and to further our understandings of these tasks, we design controlled experiments on both input data and network designs. Guided by the hindsight from these experiment results, we propose a simple contrastive learning approach along with other network modifications to improve the baseline performance. Our approach uses a self-supervised binary classification network to compare the line drawing differences between various views of any two similar 3D objects. It enables deep networks to effectively learn detail-sensitive yet view-invariant line drawing representations of 3D objects. Experiments show that our method could significantly increase the baseline performance in SPARE3D, while some popular self-supervised learning methods cannot.

</p>
</details>

<details><summary><b>Adaptive Adversarial Training for Meta Reinforcement Learning</b>
<a href="https://arxiv.org/abs/2104.13302">arxiv:2104.13302</a>
&#x1F4C8; 3 <br>
<p>Shiqi Chen, Zhengyu Chen, Donglin Wang</p></summary>
<p>

**Abstract:** Meta Reinforcement Learning (MRL) enables an agent to learn from a limited number of past trajectories and extrapolate to a new task. In this paper, we attempt to improve the robustness of MRL. We build upon model-agnostic meta-learning (MAML) and propose a novel method to generate adversarial samples for MRL by using Generative Adversarial Network (GAN). That allows us to enhance the robustness of MRL to adversal attacks by leveraging these attacks during meta training process.

</p>
</details>

<details><summary><b>Quantum circuit synthesis of Bell and GHZ states using projective simulation in the NISQ era</b>
<a href="https://arxiv.org/abs/2104.13297">arxiv:2104.13297</a>
&#x1F4C8; 3 <br>
<p>O. M. Pires, E. I. Duzzioni, J. Marchi, R. Santiago</p></summary>
<p>

**Abstract:** Quantum Computing has been evolving in the last years. Although nowadays quantum algorithms performance has shown superior to their classical counterparts, quantum decoherence and additional auxiliary qubits needed for error tolerance routines have been huge barriers for quantum algorithms efficient use. These restrictions lead us to search for ways to minimize algorithms costs, i.e the number of quantum logical gates and the depth of the circuit. For this, quantum circuit synthesis and quantum circuit optimization techniques are explored. We studied the viability of using Projective Simulation, a reinforcement learning technique, to tackle the problem of quantum circuit synthesis for noise quantum computers with limited number of qubits. The agent had the task of creating quantum circuits up to 5 qubits to generate GHZ states in the IBM Tenerife (IBM QX4) quantum processor. Our simulations demonstrated that the agent had a good performance but its capacity for learning new circuits decreased as the number of qubits increased.

</p>
</details>

<details><summary><b>Evidential segmentation of 3D PET/CT images</b>
<a href="https://arxiv.org/abs/2104.13293">arxiv:2104.13293</a>
&#x1F4C8; 3 <br>
<p>Ling Huang, Su Ruan, Pierre Decazes, Thierry Denoeux</p></summary>
<p>

**Abstract:** PET and CT are two modalities widely used in medical image analysis. Accurately detecting and segmenting lymphomas from these two imaging modalities are critical tasks for cancer staging and radiotherapy planning. However, this task is still challenging due to the complexity of PET/CT images, and the computation cost to process 3D data. In this paper, a segmentation method based on belief functions is proposed to segment lymphomas in 3D PET/CT images. The architecture is composed of a feature extraction module and an evidential segmentation (ES) module. The ES module outputs not only segmentation results (binary maps indicating the presence or absence of lymphoma in each voxel) but also uncertainty maps quantifying the classification uncertainty. The whole model is optimized by minimizing Dice and uncertainty loss functions to increase segmentation accuracy. The method was evaluated on a database of 173 patients with diffuse large b-cell lymphoma. Quantitative and qualitative results show that our method outperforms the state-of-the-art methods.

</p>
</details>

<details><summary><b>A Dual Process Model for Optimizing Cross Entropy in Neural Networks</b>
<a href="https://arxiv.org/abs/2104.13277">arxiv:2104.13277</a>
&#x1F4C8; 3 <br>
<p>Stefan Jaeger</p></summary>
<p>

**Abstract:** Minimizing cross-entropy is a widely used method for training artificial neural networks. Many training procedures based on backpropagation use cross-entropy directly as their loss function. Instead, this theoretical essay investigates a dual process model with two processes, in which one process minimizes the Kullback-Leibler divergence while its dual counterpart minimizes the Shannon entropy. Postulating that learning consists of two dual processes complementing each other, the model defines an equilibrium state for both processes in which the loss function assumes its minimum. An advantage of the proposed model is that it allows deriving the optimal learning rate and momentum weight to update network weights for backpropagation. Furthermore, the model introduces the golden ratio and complex numbers as important new concepts in machine learning.

</p>
</details>

<details><summary><b>SocialAI 0.1: Towards a Benchmark to Stimulate Research on Socio-Cognitive Abilities in Deep Reinforcement Learning Agents</b>
<a href="https://arxiv.org/abs/2104.13207">arxiv:2104.13207</a>
&#x1F4C8; 3 <br>
<p>Grgur Kovač, Rémy Portelas, Katja Hofmann, Pierre-Yves Oudeyer</p></summary>
<p>

**Abstract:** Building embodied autonomous agents capable of participating in social interactions with humans is one of the main challenges in AI. This problem motivated many research directions on embodied language use. Current approaches focus on language as a communication tool in very simplified and non diverse social situations: the "naturalness" of language is reduced to the concept of high vocabulary size and variability. In this paper, we argue that aiming towards human-level AI requires a broader set of key social skills: 1) language use in complex and variable social contexts; 2) beyond language, complex embodied communication in multimodal settings within constantly evolving social worlds. In this work we explain how concepts from cognitive sciences could help AI to draw a roadmap towards human-like intelligence, with a focus on its social dimensions. We then study the limits of a recent SOTA Deep RL approach when tested on a first grid-world environment from the upcoming SocialAI, a benchmark to assess the social skills of Deep RL agents. Videos and code are available at https://sites.google.com/view/socialai01 .

</p>
</details>

<details><summary><b>Extending Isolation Forest for Anomaly Detection in Big Data via K-Means</b>
<a href="https://arxiv.org/abs/2104.13190">arxiv:2104.13190</a>
&#x1F4C8; 3 <br>
<p>Md Tahmid Rahman Laskar, Jimmy Huang, Vladan Smetana, Chris Stewart, Kees Pouw, Aijun An, Stephen Chan, Lei Liu</p></summary>
<p>

**Abstract:** Industrial Information Technology (IT) infrastructures are often vulnerable to cyberattacks. To ensure security to the computer systems in an industrial environment, it is required to build effective intrusion detection systems to monitor the cyber-physical systems (e.g., computer networks) in the industry for malicious activities. This paper aims to build such intrusion detection systems to protect the computer networks from cyberattacks. More specifically, we propose a novel unsupervised machine learning approach that combines the K-Means algorithm with the Isolation Forest for anomaly detection in industrial big data scenarios. Since our objective is to build the intrusion detection system for the big data scenario in the industrial domain, we utilize the Apache Spark framework to implement our proposed model which was trained in large network traffic data (about 123 million instances of network traffic) stored in Elasticsearch. Moreover, we evaluate our proposed model on the live streaming data and find that our proposed system can be used for real-time anomaly detection in the industrial setup. In addition, we address different challenges that we face while training our model on large datasets and explicitly describe how these issues were resolved. Based on our empirical evaluation in different use-cases for anomaly detection in real-world network traffic data, we observe that our proposed system is effective to detect anomalies in big data scenarios. Finally, we evaluate our proposed model on several academic datasets to compare with other models and find that it provides comparable performance with other state-of-the-art approaches.

</p>
</details>

<details><summary><b>Generating Lead Sheets with Affect: A Novel Conditional seq2seq Framework</b>
<a href="https://arxiv.org/abs/2104.13056">arxiv:2104.13056</a>
&#x1F4C8; 3 <br>
<p>Dimos Makris, Kat R. Agres, Dorien Herremans</p></summary>
<p>

**Abstract:** The field of automatic music composition has seen great progress in the last few years, much of which can be attributed to advances in deep neural networks. There are numerous studies that present different strategies for generating sheet music from scratch. The inclusion of high-level musical characteristics (e.g., perceived emotional qualities), however, as conditions for controlling the generation output remains a challenge. In this paper, we present a novel approach for calculating the valence (the positivity or negativity of the perceived emotion) of a chord progression within a lead sheet, using pre-defined mood tags proposed by music experts. Based on this approach, we propose a novel strategy for conditional lead sheet generation that allows us to steer the music generation in terms of valence, phrasing, and time signature. Our approach is similar to a Neural Machine Translation (NMT) problem, as we include high-level conditions in the encoder part of the sequence-to-sequence architectures used (i.e., long-short term memory networks, and a Transformer network). We conducted experiments to thoroughly analyze these two architectures. The results show that the proposed strategy is able to generate lead sheets in a controllable manner, resulting in distributions of musical attributes similar to those of the training dataset. We also verified through a subjective listening test that our approach is effective in controlling the valence of a generated chord progression.

</p>
</details>

<details><summary><b>Simple yet Sharp Sensitivity Analysis for Unmeasured Confounding</b>
<a href="https://arxiv.org/abs/2104.13020">arxiv:2104.13020</a>
&#x1F4C8; 3 <br>
<p>Jose M. Peña</p></summary>
<p>

**Abstract:** We present a method for assessing the sensitivity of the true causal effect to unmeasured confounding. The method requires the analyst to set two intuitive parameters. Otherwise, the method is assumption-free. The method returns an interval that contains the true causal effect, and whose bounds are sharp, i.e. attainable. We show experimentally that our bounds can be sharper than those obtained by the method of Ding and VanderWeele (2016a) which, moreover, requires to set one more parameter than our method. Finally, we extend our method to bound the natural direct and indirect effects when there are measured mediators and unmeasured exposure-outcome confounding.

</p>
</details>

<details><summary><b>Morphological classification of astronomical images with limited labelling</b>
<a href="https://arxiv.org/abs/2105.02958">arxiv:2105.02958</a>
&#x1F4C8; 2 <br>
<p>Andrey Soroka, Alex Meshcheryakov, Sergey Gerasimov</p></summary>
<p>

**Abstract:** The task of morphological classification is complex for simple parameterization, but important for research in the galaxy evolution field. Future galaxy surveys (e.g. EUCLID) will collect data about more than a $10^9$ galaxies. To obtain morphological information one needs to involve people to mark up galaxy images, which requires either a considerable amount of money or a huge number of volunteers. We propose an effective semi-supervised approach for galaxy morphology classification task, based on active learning of adversarial autoencoder (AAE) model. For a binary classification problem (top level question of Galaxy Zoo 2 decision tree) we achieved accuracy 93.1% on the test part with only 0.86 millions markup actions, this model can easily scale up on any number of images. Our best model with additional markup achieves accuracy of 95.5%. To the best of our knowledge it is a first time AAE semi-supervised learning model used in astronomy.

</p>
</details>

<details><summary><b>Identifying Hubs in Undergraduate Course Networks Based on Scaled Co-Enrollments: Extended Version</b>
<a href="https://arxiv.org/abs/2104.14500">arxiv:2104.14500</a>
&#x1F4C8; 2 <br>
<p>Gary M. Weiss, Nam Nguyen, Karla Dominguez, Daniel D. Leeds</p></summary>
<p>

**Abstract:** Understanding course enrollment patterns is valuable to predict upcoming demands for future courses, and to provide student with realistic courses to pursue given their current backgrounds. This study uses undergraduate student enrollment data to form networks of courses where connections are based on student co-enrollments. The course networks generated in this paper are based on eight years of undergraduate course enrollment data from a large metropolitan university. The networks are analyzed to identify "hub" courses often taken with many other courses. Two notions of hubs are considered: one focused on raw popularity across all students, and one focused on proportional likelihoods of co-enrollment with other courses. A variety of network metrics are calculated to evaluate the course networks. Academic departments and high-level academic categories, such as Humanities vs STEM, are studied for their influence over course groupings. The identification of hub courses has practical applications, since it can help better predict the impact of changes in course offerings and in course popularity, and in the case of interdisciplinary hub courses, can be used to increase or decrease interest and enrollments in specific academic departments and areas.

</p>
</details>

<details><summary><b>Multi-class Text Classification using BERT-based Active Learning</b>
<a href="https://arxiv.org/abs/2104.14289">arxiv:2104.14289</a>
&#x1F4C8; 2 <br>
<p>Sumanth Prabhu, Moosa Mohamed, Hemant Misra</p></summary>
<p>

**Abstract:** Text Classification finds interesting applications in the pickup and delivery services industry where customers require one or more items to be picked up from a location and delivered to a certain destination. Classifying these customer transactions into multiple categories helps understand the market needs for different customer segments. Each transaction is accompanied by a text description provided by the customer to describe the products being picked up and delivered which can be used to classify the transaction. BERT-based models have proven to perform well in Natural Language Understanding. However, the product descriptions provided by the customers tend to be short, incoherent and code-mixed (Hindi-English) text which demands fine-tuning of such models with manually labelled data to achieve high accuracy. Collecting this labelled data can prove to be expensive. In this paper, we explore Active Learning strategies to label transaction descriptions cost effectively while using BERT to train a transaction classification model. On TREC-6, AG's News Corpus and an internal dataset, we benchmark the performance of BERT across different Active Learning strategies in Multi-Class Text Classification.

</p>
</details>

<details><summary><b>Interpretable Embedding Procedure Knowledge Transfer via Stacked Principal Component Analysis and Graph Neural Network</b>
<a href="https://arxiv.org/abs/2104.13561">arxiv:2104.13561</a>
&#x1F4C8; 2 <br>
<p>Seunghyun Lee, Byung Cheol Song</p></summary>
<p>

**Abstract:** Knowledge distillation (KD) is one of the most useful techniques for light-weight neural networks. Although neural networks have a clear purpose of embedding datasets into the low-dimensional space, the existing knowledge was quite far from this purpose and provided only limited information. We argue that good knowledge should be able to interpret the embedding procedure. This paper proposes a method of generating interpretable embedding procedure (IEP) knowledge based on principal component analysis, and distilling it based on a message passing neural network. Experimental results show that the student network trained by the proposed KD method improves 2.28% in the CIFAR100 dataset, which is higher performance than the state-of-the-art (SOTA) method. We also demonstrate that the embedding procedure knowledge is interpretable via visualization of the proposed KD process. The implemented code is available at https://github.com/sseung0703/IEPKT.

</p>
</details>

<details><summary><b>Multi-scale Deep Learning Architecture for Nucleus Detection in Renal Cell Carcinoma Microscopy Image</b>
<a href="https://arxiv.org/abs/2104.13557">arxiv:2104.13557</a>
&#x1F4C8; 2 <br>
<p>Shiba Kuanar, Vassilis Athitsos, Dwarikanath Mahapatra, Anand Rajan</p></summary>
<p>

**Abstract:** Clear cell renal cell carcinoma (ccRCC) is one of the most common forms of intratumoral heterogeneity in the study of renal cancer. ccRCC originates from the epithelial lining of proximal convoluted renal tubules. These cells undergo abnormal mutations in the presence of Ki67 protein and create a lump-like structure through cell proliferation. Manual counting of tumor cells in the tissue-affected sections is one of the strongest prognostic markers for renal cancer. However, this procedure is time-consuming and also prone to subjectivity. These assessments are based on the physical cell appearance and suffer wide intra-observer variations. Therefore, better cell nucleus detection and counting techniques can be an important biomarker for the assessment of tumor cell proliferation in routine pathological investigations. In this paper, we introduce a deep learning-based detection model for cell classification on IHC stained histology images. These images are classified into binary classes to find the presence of Ki67 protein in cancer-affected nucleus regions. Our model maps the multi-scale pyramid features and saliency information from local bounded regions and predicts the bounding box coordinates through regression. Our method validates the impact of Ki67 expression across a cohort of four hundred histology images treated with localized ccRCC and compares our results with the existing state-of-the-art nucleus detection methods. The precision and recall scores of the proposed method are computed and compared on the clinical data sets. The experimental results demonstrate that our model improves the F1 score up to 86.3% and an average area under the Precision-Recall curve as 85.73%.

</p>
</details>

<details><summary><b>Learning Fair Canonical Polyadical Decompositions using a Kernel Independence Criterion</b>
<a href="https://arxiv.org/abs/2104.13504">arxiv:2104.13504</a>
&#x1F4C8; 2 <br>
<p>Kevin Kim, Alex Gittens</p></summary>
<p>

**Abstract:** This work proposes to learn fair low-rank tensor decompositions by regularizing the Canonical Polyadic Decomposition factorization with the kernel Hilbert-Schmidt independence criterion (KHSIC). It is shown, theoretically and empirically, that a small KHSIC between a latent factor and the sensitive features guarantees approximate statistical parity. The proposed algorithm surpasses the state-of-the-art algorithm, FATR (Zhu et al., 2018), in controlling the trade-off between fairness and residual fit on synthetic and real data sets.

</p>
</details>

<details><summary><b>Towards Clinical Encounter Summarization: Learning to Compose Discharge Summaries from Prior Notes</b>
<a href="https://arxiv.org/abs/2104.13498">arxiv:2104.13498</a>
&#x1F4C8; 2 <br>
<p>Han-Chin Shing, Chaitanya Shivade, Nima Pourdamghani, Feng Nan, Philip Resnik, Douglas Oard, Parminder Bhatia</p></summary>
<p>

**Abstract:** The records of a clinical encounter can be extensive and complex, thus placing a premium on tools that can extract and summarize relevant information. This paper introduces the task of generating discharge summaries for a clinical encounter. Summaries in this setting need to be faithful, traceable, and scale to multiple long documents, motivating the use of extract-then-abstract summarization cascades. We introduce two new measures, faithfulness and hallucination rate for evaluation in this task, which complement existing measures for fluency and informativeness. Results across seven medical sections and five models show that a summarization architecture that supports traceability yields promising results, and that a sentence-rewriting approach performs consistently on the measure used for faithfulness (faithfulness-adjusted $F_3$) over a diverse range of generated sections.

</p>
</details>

<details><summary><b>Phenotyping OSA: a time series analysis using fuzzy clustering and persistent homology</b>
<a href="https://arxiv.org/abs/2104.13479">arxiv:2104.13479</a>
&#x1F4C8; 2 <br>
<p>Prachi Loliencar, Giseon Heo</p></summary>
<p>

**Abstract:** Sleep apnea is a disorder that has serious consequences for the pediatric population. There has been recent concern that traditional diagnosis of the disorder using the apnea-hypopnea index may be ineffective in capturing its multi-faceted outcomes. In this work, we take a first step in addressing this issue by phenotyping patients using a clustering analysis of airflow time series. This is approached in three ways: using feature-based fuzzy clustering in the time and frequency domains, and using persistent homology to study the signal from a topological perspective. The fuzzy clusters are analyzed in a novel manner using a Dirichlet regression analysis, while the topological approach leverages Takens embedding theorem to study the periodicity properties of the signals.

</p>
</details>

<details><summary><b>An optical neural network using less than 1 photon per multiplication</b>
<a href="https://arxiv.org/abs/2104.13467">arxiv:2104.13467</a>
&#x1F4C8; 2 <br>
<p>Tianyu Wang, Shi-Yuan Ma, Logan G. Wright, Tatsuhiro Onodera, Brian Richard, Peter L. McMahon</p></summary>
<p>

**Abstract:** Deep learning has rapidly become a widespread tool in both scientific and commercial endeavors. Milestones of deep learning exceeding human performance have been achieved for a growing number of tasks over the past several years, across areas as diverse as game-playing, natural-language translation, and medical-image analysis. However, continued progress is increasingly hampered by the high energy costs associated with training and running deep neural networks on electronic processors. Optical neural networks have attracted attention as an alternative physical platform for deep learning, as it has been theoretically predicted that they can fundamentally achieve higher energy efficiency than neural networks deployed on conventional digital computers. Here, we experimentally demonstrate an optical neural network achieving 99% accuracy on handwritten-digit classification using ~3.2 detected photons per weight multiplication and ~90% accuracy using ~0.64 photons (~$2.4 \times 10^{-19}$ J of optical energy) per weight multiplication. This performance was achieved using a custom free-space optical processor that executes matrix-vector multiplications in a massively parallel fashion, with up to ~0.5 million scalar (weight) multiplications performed at the same time. Using commercially available optical components and standard neural-network training methods, we demonstrated that optical neural networks can operate near the standard quantum limit with extremely low optical powers and still achieve high accuracy. Our results provide a proof-of-principle for low-optical-power operation, and with careful system design including the surrounding electronics used for data storage and control, open up a path to realizing optical processors that require only $10^{-16}$ J total energy per scalar multiplication -- which is orders of magnitude more efficient than current digital processors.

</p>
</details>

<details><summary><b>Robust Classification via Support Vector Machines</b>
<a href="https://arxiv.org/abs/2104.13458">arxiv:2104.13458</a>
&#x1F4C8; 2 <br>
<p>Vali Asimit, Ioannis Kyriakou, Simone Santoni, Salvatore Scognamiglio, Rui Zhu</p></summary>
<p>

**Abstract:** The loss function choice for any Support Vector Machine classifier has raised great interest in the literature due to the lack of robustness of the Hinge loss, which is the standard loss choice. In this paper, we plan to robustify the binary classifier by maintaining the overall advantages of the Hinge loss, rather than modifying this standard choice. We propose two robust classifiers under data uncertainty. The first is called Single Perturbation SVM (SP-SVM) and provides a constructive method by allowing a controlled perturbation to one feature of the data. The second method is called Extreme Empirical Loss SVM (EEL-SVM) and is based on a new empirical loss estimate, namely, the Extreme Empirical Loss (EEL), that puts more emphasis on extreme violations of the classification hyper-plane, rather than taking the usual sample average with equal importance for all hyper-plane violations. Extensive numerical investigation reveals the advantages of the two robust classifiers on simulated data and well-known real datasets.

</p>
</details>

<details><summary><b>Incident Detection on Junctions Using Image Processing</b>
<a href="https://arxiv.org/abs/2104.13437">arxiv:2104.13437</a>
&#x1F4C8; 2 <br>
<p>Murat Tulgaç, Enes Yüncü,  Mohamad-Alhaddad, Ceylan Yozgatlıgil</p></summary>
<p>

**Abstract:** In traffic management, it is a very important issue to shorten the response time by detecting the incidents (accident, vehicle breakdown, an object falling on the road, etc.) and informing the corresponding personnel. In this study, an anomaly detection framework for road junctions is proposed. The final judgment is based on the trajectories followed by the vehicles. Trajectory information is provided by vehicle detection and tracking algorithms on visual data streamed from a fisheye camera. Deep learning algorithms are used for vehicle detection, and Kalman Filter is used for tracking. To observe the trajectories more accurately, the detected vehicle coordinates are transferred to the bird's eye view coordinates using the lens distortion model prediction algorithm. The system determines whether there is an abnormality in trajectories by comparing historical trajectory data and instantaneous incoming data. The proposed system has achieved 84.6% success in vehicle detection and 96.8% success in abnormality detection on synthetic data. The system also works with a 97.3% success rate in detecting abnormalities on real data.

</p>
</details>

<details><summary><b>DASEE A Synthetic Database of Domestic Acoustic Scenes and Events in Dementia Patients Environment</b>
<a href="https://arxiv.org/abs/2104.13423">arxiv:2104.13423</a>
&#x1F4C8; 2 <br>
<p>Abigail Copiaco, Christian Ritz, Stefano Fasciani, Nidhal Abdulaziz</p></summary>
<p>

**Abstract:** Access to informative databases is a crucial part of notable research developments. In the field of domestic audio classification, there have been significant advances in recent years. Although several audio databases exist, these can be limited in terms of the amount of information they provide, such as the exact location of the sound sources, and the associated noise levels. In this work, we detail our approach on generating an unbiased synthetic domestic audio database, consisting of sound scenes and events, emulated in both quiet and noisy environments. Data is carefully curated such that it reflects issues commonly faced in a dementia patients environment, and recreate scenarios that could occur in real-world settings. Similarly, the room impulse response generated is based on a typical one-bedroom apartment at Hebrew SeniorLife Facility. As a result, we present an 11-class database containing excerpts of clean and noisy signals at 5-seconds duration each, uniformly sampled at 16 kHz. Using our baseline model using Continues Wavelet Transform Scalograms and AlexNet, this yielded a weighted F1-score of 86.24 percent.

</p>
</details>

<details><summary><b>FrameExit: Conditional Early Exiting for Efficient Video Recognition</b>
<a href="https://arxiv.org/abs/2104.13400">arxiv:2104.13400</a>
&#x1F4C8; 2 <br>
<p>Amir Ghodrati, Babak Ehteshami Bejnordi, Amirhossein Habibian</p></summary>
<p>

**Abstract:** In this paper, we propose a conditional early exiting framework for efficient video recognition. While existing works focus on selecting a subset of salient frames to reduce the computation costs, we propose to use a simple sampling strategy combined with conditional early exiting to enable efficient recognition. Our model automatically learns to process fewer frames for simpler videos and more frames for complex ones. To achieve this, we employ a cascade of gating modules to automatically determine the earliest point in processing where an inference is sufficiently reliable. We generate on-the-fly supervision signals to the gates to provide a dynamic trade-off between accuracy and computational cost. Our proposed model outperforms competing methods on three large-scale video benchmarks. In particular, on ActivityNet1.3 and mini-kinetics, we outperform the state-of-the-art efficient video recognition methods with 1.3$\times$ and 2.1$\times$ less GFLOPs, respectively. Additionally, our method sets a new state of the art for efficient video understanding on the HVU benchmark.

</p>
</details>

<details><summary><b>Towards On-Device Federated Learning: A Direct Acyclic Graph-based Blockchain Approach</b>
<a href="https://arxiv.org/abs/2104.13092">arxiv:2104.13092</a>
&#x1F4C8; 2 <br>
<p>Mingrui Cao, Long Zhang, Bin Cao</p></summary>
<p>

**Abstract:** Due to the distributed characteristics of Federated Learning (FL), the vulnerability of global model and coordination of devices are the main obstacle. As a promising solution of decentralization, scalability and security, leveraging blockchain in FL has attracted much attention in recent years. However, the traditional consensus mechanisms designed for blockchain like Proof of Work (PoW) would cause extreme resource consumption, which reduces the efficiency of FL greatly, especially when the participating devices are wireless and resource-limited. In order to address device asynchrony and anomaly detection in FL while avoiding the extra resource consumption caused by blockchain, this paper introduces a framework for empowering FL using Direct Acyclic Graph (DAG)-based blockchain systematically (DAG-FL). Accordingly, DAG-FL is first introduced from a three-layer architecture in details, and then two algorithms DAG-FL Controlling and DAG-FL Updating are designed running on different nodes to elaborate the operation of DAG-FL consensus mechanism. After that, a Poisson process model is formulated to discuss that how to set deployment parameters to maintain DAG-FL stably in different federated learning tasks. The extensive simulations and experiments show that DAG-FL can achieve better performance in terms of training efficiency and model accuracy compared with the typical existing on-device federated learning systems as the benchmarks.

</p>
</details>

<details><summary><b>Property Inference Attacks on Convolutional Neural Networks: Influence and Implications of Target Model's Complexity</b>
<a href="https://arxiv.org/abs/2104.13061">arxiv:2104.13061</a>
&#x1F4C8; 2 <br>
<p>Mathias P. M. Parisot, Balazs Pejo, Dayana Spagnuelo</p></summary>
<p>

**Abstract:** Machine learning models' goal is to make correct predictions for specific tasks by learning important properties and patterns from data. By doing so, there is a chance that the model learns properties that are unrelated to its primary task. Property Inference Attacks exploit this and aim to infer from a given model (\ie the target model) properties about the training dataset seemingly unrelated to the model's primary goal. If the training data is sensitive, such an attack could lead to privacy leakage. This paper investigates the influence of the target model's complexity on the accuracy of this type of attack, focusing on convolutional neural network classifiers. We perform attacks on models that are trained on facial images to predict whether someone's mouth is open. Our attacks' goal is to infer whether the training dataset is balanced gender-wise. Our findings reveal that the risk of a privacy breach is present independently of the target model's complexity: for all studied architectures, the attack's accuracy is clearly over the baseline. We discuss the implication of the property inference on personal data in the light of Data Protection Regulations and Guidelines.

</p>
</details>

<details><summary><b>Deep Learning of the Eddington Tensor in the Core-collapse Supernova Simulation</b>
<a href="https://arxiv.org/abs/2104.13039">arxiv:2104.13039</a>
&#x1F4C8; 2 <br>
<p>Akira Harada, Shota Nishikawa, Shoichi Yamada</p></summary>
<p>

**Abstract:** We trained deep neural networks (DNNs) as a function of the neutrino energy density, flux, and the fluid velocity to reproduce the Eddington tensor for neutrinos obtained in our first-principles core-collapse supernova (CCSN) simulations. Although the moment method, which is one of the most popular approximations for neutrino transport, requires a closure relation, none of the analytical closure relations commonly employed in the literature captures all aspects of the neutrino angular distribution in momentum space. In this paper, we developed a closure relation by using the DNN that takes the neutrino energy density, flux, and the fluid velocity as the input and the Eddington tensor as the output. We consider two kinds of DNNs: a conventional DNN named a component-wise neural network (CWNN) and a tensor-basis neural network (TBNN). We found that the diagonal component of the Eddington tensor is reproduced better by the DNNs than the M1-closure relation especially for low to intermediate energies. For the off-diagonal component, the DNNs agree better with the Boltzmann solver than the M1 closure at large radii. In the comparison between the two DNNs, the TBNN has slightly better performance than the CWNN. With the new closure relations at hand based on the DNNs that well reproduce the Eddington tensor with much smaller costs, we opened up a new possibility for the moment method.

</p>
</details>

<details><summary><b>Dynamic Cat Swarm Optimization Algorithm for Backboard Wiring Problem</b>
<a href="https://arxiv.org/abs/2107.08908">arxiv:2107.08908</a>
&#x1F4C8; 1 <br>
<p>Aram Ahmed, Tarik A. Rashid, Soran Saeed</p></summary>
<p>

**Abstract:** This paper presents a powerful swarm intelligence meta-heuristic optimization algorithm called Dynamic Cat Swarm Optimization. The formulation is through modifying the existing Cat Swarm Optimization. The original Cat Swarm Optimization suffers from the shortcoming of 'premature convergence', which is the possibility of entrapment in local optima which usually happens due to the off-balance between exploration and exploitation phases. Therefore, the proposed algorithm suggests a new method to provide a proper balance between these phases by modifying the selection scheme and the seeking mode of the algorithm. To evaluate the performance of the proposed algorithm, 23 classical test functions, 10 modern test functions (CEC 2019) and a real world scenario are used. In addition, the Dimension-wise diversity metric is used to measure the percentage of the exploration and exploitation phases. The optimization results show the effectiveness of the proposed algorithm, which ranks first compared to several well-known algorithms available in the literature. Furthermore, statistical methods and graphs are also used to further confirm the outperformance of the algorithm. Finally, the conclusion as well as future directions to further improve the algorithm are discussed.

</p>
</details>

<details><summary><b>Discovering nonlinear resonances through physics-informed machine learning</b>
<a href="https://arxiv.org/abs/2104.13471">arxiv:2104.13471</a>
&#x1F4C8; 1 <br>
<p>G. D. Barmparis, G. P. Tsironis</p></summary>
<p>

**Abstract:** For an ensemble of nonlinear systems that model, for instance, molecules or photonic systems, we propose a method that finds efficiently the configuration that has prescribed transfer properties. Specifically, we use physics-informed machine-learning (PIML) techniques to find the parameters for the efficient transfer of an electron (or photon) to a targeted state in a non-linear dimer. We create a machine learning model containing two variables, $χ_D$, and $χ_A$, representing the non-linear terms in the donor and acceptor target system states. We then introduce a data-free physics-informed loss function as $1.0 - P_j$, where $P_j$ is the probability, the electron being in the targeted state, $j$. By minimizing the loss function, we maximize the occupation probability to the targeted state. The method recovers known results in the Targeted Energy Transfer (TET) model, and it is then applied to a more complex system with an additional intermediate state. In this trimer configuration, the PIML approach discovers desired resonant paths from the donor to acceptor units. The proposed PIML method is general and may be used in the chemical design of molecular complexes or engineering design of quantum or photonic systems.

</p>
</details>

<details><summary><b>Deep Two-Stage High-Resolution Image Inpainting</b>
<a href="https://arxiv.org/abs/2104.13464">arxiv:2104.13464</a>
&#x1F4C8; 1 <br>
<p>Andrey Moskalenko, Mikhail Erofeev, Dmitriy Vatolin</p></summary>
<p>

**Abstract:** In recent years, the field of image inpainting has developed rapidly, learning based approaches show impressive results in the task of filling missing parts in an image. But most deep methods are strongly tied to the resolution of the images on which they were trained. A slight resolution increase leads to serious artifacts and unsatisfactory filling quality. These methods are therefore unsuitable for interactive image processing. In this article, we propose a method that solves the problem of inpainting arbitrary-size images. We also describe a way to better restore texture fragments in the filled area. For this, we propose to use information from neighboring pixels by shifting the original image in four directions. Moreover, this approach can work with existing inpainting models, making them almost resolution independent without the need for retraining. We also created a GIMP plugin that implements our technique. The plugin, code, and model weights are available at https://github.com/a-mos/High_Resolution_Image_Inpainting.

</p>
</details>

<details><summary><b>Inductive Program Synthesis over Noisy Datasets using Abstraction Refinement Based Optimization</b>
<a href="https://arxiv.org/abs/2104.13315">arxiv:2104.13315</a>
&#x1F4C8; 1 <br>
<p>Shivam Handa, Martin Rinard</p></summary>
<p>

**Abstract:** We present a new synthesis algorithm to solve program synthesis over noisy datasets, i.e., data that may contain incorrect/corrupted input-output examples. Our algorithm uses an abstraction refinement based optimization process to synthesize programs which optimize the tradeoff between the loss over the noisy dataset and the complexity of the synthesized program. The algorithm uses abstractions to divide the search space of programs into subspaces by computing an abstract value that represents outputs for all programs in a subspace. The abstract value allows our algorithm to compute, for each subspace, a sound approximate lower bound of the loss over all programs in the subspace. It iteratively refines these abstractions to further subdivide the space into smaller subspaces, prune subspaces that do not contain an optimal program, and eventually synthesize an optimal program.
  We implemented this algorithm in a tool called Rose. We compare Rose to a current state-of-the-art noisy program synthesis system using the SyGuS 2018 benchmark suite. Our evaluation demonstrates that Rose significantly outperforms this previous system: on two noisy benchmark program synthesis problems sets drawn from the SyGus 2018 benchmark suite, Rose delivers speedups of up to 1587 and 81.7, with median speedups of 20.5 and 81.7. Rose also terminates on 20 (out of 54) and 4 (out of 11) more benchmark problems than the previous system. Both Rose and the previous system synthesize programs that are optimal over the provided noisy data sets. For the majority of the problems in the benchmark sets ($272$ out of $286$), the synthesized programs also produce correct outputs for all inputs in the original (unseen) noise-free data set. These results highlight the benefits that Rose can deliver for effective noisy program synthesis.

</p>
</details>

<details><summary><b>Proceedings - AI/ML for Cybersecurity: Challenges, Solutions, and Novel Ideas at SIAM Data Mining 2021</b>
<a href="https://arxiv.org/abs/2104.13254">arxiv:2104.13254</a>
&#x1F4C8; 1 <br>
<p>John Emanuello, Kimberly Ferguson-Walter, Erik Hemberg, Una-May O Reilly, Ahmad Ridley, Dennis Ross, Diane Staheli, William Streilein</p></summary>
<p>

**Abstract:** Malicious cyber activity is ubiquitous and its harmful effects have dramatic and often irreversible impacts on society. Given the shortage of cybersecurity professionals, the ever-evolving adversary, the massive amounts of data which could contain evidence of an attack, and the speed at which defensive actions must be taken, innovations which enable autonomy in cybersecurity must continue to expand, in order to move away from a reactive defense posture and towards a more proactive one.
  The challenges in this space are quite different from those associated with applying AI in other domains such as computer vision. The environment suffers from an incredibly high degree of uncertainty, stemming from the intractability of ingesting all the available data, as well as the possibility that malicious actors are manipulating the data. Another unique challenge in this space is the dynamism of the adversary causes the indicators of compromise to change frequently and without warning.
  In spite of these challenges, machine learning has been applied to this domain and has achieved some success in the realm of detection. While this aspect of the problem is far from solved, a growing part of the commercial sector is providing ML-enhanced capabilities as a service. Many of these entities also provide platforms which facilitate the deployment of these automated solutions. Academic research in this space is growing and continues to influence current solutions, as well as strengthen foundational knowledge which will make autonomous agents in this space a possibility.

</p>
</details>

<details><summary><b>Controlling earthquake-like instabilities using artificial intelligence</b>
<a href="https://arxiv.org/abs/2104.13180">arxiv:2104.13180</a>
&#x1F4C8; 1 <br>
<p>Efthymios Papachristos, Ioannis Stefanou</p></summary>
<p>

**Abstract:** Earthquakes are lethal and costly. This study aims at avoiding these catastrophic events by the application of injection policies retrieved through reinforcement learning. With the rapid growth of artificial intelligence, prediction-control problems are all the more tackled by function approximation models that learn how to control a specific task, even for systems with unmodeled/unknown dynamics and important uncertainties. Here, we show for the first time the possibility of controlling earthquake-like instabilities using state-of-the-art deep reinforcement learning techniques. The controller is trained using a reduced model of the physical system, i.e, the spring-slider model, which embodies the main dynamics of the physical problem for a given earthquake magnitude. Its robustness to unmodeled dynamics is explored through a parametric study. Our study is a first step towards minimizing seismicity in industrial projects (geothermal energy, hydrocarbons production, CO2 sequestration) while, in a second step for inspiring techniques for natural earthquakes control and prevention.

</p>
</details>

<details><summary><b>Secure and Efficient Federated Learning Through Layering and Sharding Blockchain</b>
<a href="https://arxiv.org/abs/2104.13130">arxiv:2104.13130</a>
&#x1F4C8; 1 <br>
<p>Shuo Yuan, Bin Cao, Yao Sun, Mugen Peng</p></summary>
<p>

**Abstract:** Federated learning (FL) has emerged as a promising master/slave learning paradigm to alleviate systemic privacy risks and communication costs incurred by cloud-centric machine learning methods. However, it is very challenging to resist the single point of failure of the master aggregator and attacks from malicious participants while guaranteeing model convergence speed and accuracy. Recently, blockchain has been brought into FL systems transforming the paradigm to a decentralized manner thus further improve the system security and learning reliability. Unfortunately, the traditional consensus mechanism and architecture of blockchain systems can hardly handle the large-scale FL task due to the huge resource consumption, limited transaction throughput, and high communication complexity. To address these issues, this paper proposes a two-layer blockchaindriven FL framework, called as ChainsFL, which is composed of multiple subchain networks (subchain layer) and a direct acyclic graph (DAG)-based mainchain (mainchain layer). In ChainsFL, the subchain layer limits the scale of each shard for a small range of information exchange, and the mainchain layer allows each shard to share and validate the learning model in parallel and asynchronously to improve the efficiency of cross-shard validation. Furthermore, the FL procedure is customized to deeply integrate with blockchain technology, and the modified DAG consensus mechanism is proposed to mitigate the distortion caused by abnormal models. In order to provide a proof-ofconcept implementation and evaluation, multiple subchains base on Hyperledger Fabric are deployed as the subchain layer, and the self-developed DAG-based mainchain is deployed as the mainchain layer. The experimental results show that ChainsFL provides acceptable and sometimes better training efficiency and stronger robustness compared with the typical existing FL systems.

</p>
</details>

<details><summary><b>A Survey on Neural Recommendation: From Collaborative Filtering to Information-rich Recommendation</b>
<a href="https://arxiv.org/abs/2104.13030">arxiv:2104.13030</a>
&#x1F4C8; 0 <br>
<p>Le Wu, Xiangnan He, Xiang Wang, Kun Zhang, Meng Wang</p></summary>
<p>

**Abstract:** Influenced by the great success of deep learning in computer vision and language understanding, research in recommendation has shifted to inventing new recommender models based on neural networks. In recent years, we have witnessed significant progress in developing neural recommender models, which generalize and surpass traditional recommender models owing to the strong representation power of neural networks. In this survey paper, we conduct a systematic review on neural recommender models from the perspective of recommendation modeling with the accuracy goal, aiming to summarize this field to facilitate researchers and practitioners working on recommender systems. Specifically, based on the data usage during recommendation modeling we divide the work into collaborative filtering and information-rich recommendation: 1) collaborative filtering, which leverages the key source of user-item interaction data; 2) content enriched recommendation, which additionally utilizes the side information associated with users and items, like user profile and item knowledge graph; and 3) temporal/sequential recommendation, which accounts for the contextual information associated with an interaction, such as time, location, and the past interactions. After reviewing representative work for each type, we finally discuss some promising directions in this field. We have also summarized the related papers at https://github.com/lmcRS/AWS-recommendation-papers.

</p>
</details>


[Next Page]({{ '/2021/04/26/2021.04.26.html' | relative_url }})
