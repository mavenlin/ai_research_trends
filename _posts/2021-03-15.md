## Summary for 2021-03-15, created on 2021-12-23


<details><summary><b>Autonomous Drone Racing with Deep Reinforcement Learning</b>
<a href="https://arxiv.org/abs/2103.08624">arxiv:2103.08624</a>
&#x1F4C8; 87 <br>
<p>Yunlong Song, Mats Steinweg, Elia Kaufmann, Davide Scaramuzza</p></summary>
<p>

**Abstract:** In many robotic tasks, such as autonomous drone racing, the goal is to travel through a set of waypoints as fast as possible. A key challenge for this task is planning the time-optimal trajectory, which is typically solved by assuming perfect knowledge of the waypoints to pass in advance. The resulting solution is either highly specialized for a single-track layout, or suboptimal due to simplifying assumptions about the platform dynamics. In this work, a new approach to near-time-optimal trajectory generation for quadrotors is presented. Leveraging deep reinforcement learning and relative gate observations, our approach can compute near-time-optimal trajectories and adapt the trajectory to environment changes. Our method exhibits computational advantages over approaches based on trajectory optimization for non-trivial track configurations. The proposed approach is evaluated on a set of race tracks in simulation and the real world, achieving speeds of up to 60 km/h with a physical quadrotor.

</p>
</details>

<details><summary><b>Get Your Vitamin C! Robust Fact Verification with Contrastive Evidence</b>
<a href="https://arxiv.org/abs/2103.08541">arxiv:2103.08541</a>
&#x1F4C8; 10 <br>
<p>Tal Schuster, Adam Fisch, Regina Barzilay</p></summary>
<p>

**Abstract:** Typical fact verification models use retrieved written evidence to verify claims. Evidence sources, however, often change over time as more information is gathered and revised. In order to adapt, models must be sensitive to subtle differences in supporting evidence. We present VitaminC, a benchmark infused with challenging cases that require fact verification models to discern and adjust to slight factual changes. We collect over 100,000 Wikipedia revisions that modify an underlying fact, and leverage these revisions, together with additional synthetically constructed ones, to create a total of over 400,000 claim-evidence pairs. Unlike previous resources, the examples in VitaminC are contrastive, i.e., they contain evidence pairs that are nearly identical in language and content, with the exception that one supports a given claim while the other does not. We show that training using this design increases robustness -- improving accuracy by 10% on adversarial fact verification and 6% on adversarial natural language inference (NLI). Moreover, the structure of VitaminC leads us to define additional tasks for fact-checking resources: tagging relevant words in the evidence for verifying the claim, identifying factual revisions, and providing automatic edits via factually consistent text generation.

</p>
</details>

<details><summary><b>Fairness and Transparency in Recommendation: The Users' Perspective</b>
<a href="https://arxiv.org/abs/2103.08786">arxiv:2103.08786</a>
&#x1F4C8; 9 <br>
<p>Nasim Sonboli, Jessie J. Smith, Florencia Cabral Berenfus, Robin Burke, Casey Fiesler</p></summary>
<p>

**Abstract:** Though recommender systems are defined by personalization, recent work has shown the importance of additional, beyond-accuracy objectives, such as fairness. Because users often expect their recommendations to be purely personalized, these new algorithmic objectives must be communicated transparently in a fairness-aware recommender system. While explanation has a long history in recommender systems research, there has been little work that attempts to explain systems that use a fairness objective. Even though the previous work in other branches of AI has explored the use of explanations as a tool to increase fairness, this work has not been focused on recommendation. Here, we consider user perspectives of fairness-aware recommender systems and techniques for enhancing their transparency. We describe the results of an exploratory interview study that investigates user perceptions of fairness, recommender systems, and fairness-aware objectives. We propose three features -- informed by the needs of our participants -- that could improve user understanding of and trust in fairness-aware recommender systems.

</p>
</details>

<details><summary><b>LightningDOT: Pre-training Visual-Semantic Embeddings for Real-Time Image-Text Retrieval</b>
<a href="https://arxiv.org/abs/2103.08784">arxiv:2103.08784</a>
&#x1F4C8; 9 <br>
<p>Siqi Sun, Yen-Chun Chen, Linjie Li, Shuohang Wang, Yuwei Fang, Jingjing Liu</p></summary>
<p>

**Abstract:** Multimodal pre-training has propelled great advancement in vision-and-language research. These large-scale pre-trained models, although successful, fatefully suffer from slow inference speed due to enormous computation cost mainly from cross-modal attention in Transformer architecture. When applied to real-life applications, such latency and computation demand severely deter the practical use of pre-trained models. In this paper, we study Image-text retrieval (ITR), the most mature scenario of V+L application, which has been widely studied even prior to the emergence of recent pre-trained models. We propose a simple yet highly effective approach, LightningDOT that accelerates the inference time of ITR by thousands of times, without sacrificing accuracy. LightningDOT removes the time-consuming cross-modal attention by pre-training on three novel learning objectives, extracting feature indexes offline, and employing instant dot-product matching with further re-ranking, which significantly speeds up retrieval process. In fact, LightningDOT achieves new state of the art across multiple ITR benchmarks such as Flickr30k, COCO and Multi30K, outperforming existing pre-trained models that consume 1000x magnitude of computational hours. Code and pre-training checkpoints are available at https://github.com/intersun/LightningDOT.

</p>
</details>

<details><summary><b>Towards Indirect Top-Down Road Transport Emissions Estimation</b>
<a href="https://arxiv.org/abs/2103.08829">arxiv:2103.08829</a>
&#x1F4C8; 8 <br>
<p>Ryan Mukherjee, Derek Rollend, Gordon Christie, Armin Hadzic, Sally Matson, Anshu Saksena, Marisa Hughes</p></summary>
<p>

**Abstract:** Road transportation is one of the largest sectors of greenhouse gas (GHG) emissions affecting climate change. Tackling climate change as a global community will require new capabilities to measure and inventory road transport emissions. However, the large scale and distributed nature of vehicle emissions make this sector especially challenging for existing inventory methods. In this work, we develop machine learning models that use satellite imagery to perform indirect top-down estimation of road transport emissions. Our initial experiments focus on the United States, where a bottom-up inventory was available for training our models. We achieved a mean absolute error (MAE) of 39.5 kg CO$_{2}$ of annual road transport emissions, calculated on a pixel-by-pixel (100 m$^{2}$) basis in Sentinel-2 imagery. We also discuss key model assumptions and challenges that need to be addressed to develop models capable of generalizing to global geography. We believe this work is the first published approach for automated indirect top-down estimation of road transport sector emissions using visual imagery and represents a critical step towards scalable, global, near-real-time road transportation emissions inventories that are measured both independently and objectively.

</p>
</details>

<details><summary><b>Flow-based Self-supervised Density Estimation for Anomalous Sound Detection</b>
<a href="https://arxiv.org/abs/2103.08801">arxiv:2103.08801</a>
&#x1F4C8; 8 <br>
<p>Kota Dohi, Takashi Endo, Harsh Purohit, Ryo Tanabe, Yohei Kawaguchi</p></summary>
<p>

**Abstract:** To develop a machine sound monitoring system, a method for detecting anomalous sound is proposed. Exact likelihood estimation using Normalizing Flows is a promising technique for unsupervised anomaly detection, but it can fail at out-of-distribution detection since the likelihood is affected by the smoothness of the data. To improve the detection performance, we train the model to assign higher likelihood to target machine sounds and lower likelihood to sounds from other machines of the same machine type. We demonstrate that this enables the model to incorporate a self-supervised classification-based approach. Experiments conducted using the DCASE 2020 Challenge Task2 dataset showed that the proposed method improves the AUC by 4.6% on average when using Masked Autoregressive Flow (MAF) and by 5.8% when using Glow, which is a significant improvement over the previous method.

</p>
</details>

<details><summary><b>GSVNet: Guided Spatially-Varying Convolution for Fast Semantic Segmentation on Video</b>
<a href="https://arxiv.org/abs/2103.08834">arxiv:2103.08834</a>
&#x1F4C8; 7 <br>
<p>Shih-Po Lee, Si-Cun Chen, Wen-Hsiao Peng</p></summary>
<p>

**Abstract:** This paper addresses fast semantic segmentation on video.Video segmentation often calls for real-time, or even fasterthan real-time, processing. One common recipe for conserving computation arising from feature extraction is to propagate features of few selected keyframes. However, recent advances in fast image segmentation make these solutions less attractive. To leverage fast image segmentation for furthering video segmentation, we propose a simple yet efficient propagation framework. Specifically, we perform lightweight flow estimation in 1/8-downscaled image space for temporal warping in segmentation outpace space. Moreover, we introduce a guided spatially-varying convolution for fusing segmentations derived from the previous and current frames, to mitigate propagation error and enable lightweight feature extraction on non-keyframes. Experimental results on Cityscapes and CamVid show that our scheme achieves the state-of-the-art accuracy-throughput trade-off on video segmentation.

</p>
</details>

<details><summary><b>Category Aware Explainable Conversational Recommendation</b>
<a href="https://arxiv.org/abs/2103.08733">arxiv:2103.08733</a>
&#x1F4C8; 7 <br>
<p>Nikolaos Kondylidis, Jie Zou, Evangelos Kanoulas</p></summary>
<p>

**Abstract:** Most conversational recommendation approaches are either not explainable, or they require external user's knowledge for explaining or their explanations cannot be applied in real time due to computational limitations. In this work, we present a real time category based conversational recommendation approach, which can provide concise explanations without prior user knowledge being required. We first perform an explainable user model in the form of preferences over the items' categories, and then use the category preferences to recommend items. The user model is performed by applying a BERT-based neural architecture on the conversation. Then, we translate the user model into item recommendation scores using a Feed Forward Network. User preferences during the conversation in our approach are represented by category vectors which are directly interpretable. The experimental results on the real conversational recommendation dataset ReDial demonstrate comparable performance to the state-of-the-art, while our approach is explainable. We also show the potential power of our framework by involving an oracle setting of category preference prediction.

</p>
</details>

<details><summary><b>Is Medical Chest X-ray Data Anonymous?</b>
<a href="https://arxiv.org/abs/2103.08562">arxiv:2103.08562</a>
&#x1F4C8; 7 <br>
<p>Kai Packhäuser, Sebastian Gündel, Nicolas Münster, Christopher Syben, Vincent Christlein, Andreas Maier</p></summary>
<p>

**Abstract:** With the rise and ever-increasing potential of deep learning techniques in recent years, publicly available medical datasets became a key factor to enable reproducible development of diagnostic algorithms in the medical domain. Medical data contains sensitive patient-related information and is therefore usually anonymized by removing patient identifiers, e.g., patient names before publication. To the best of our knowledge, we are the first to show that a well-trained deep learning system is able to recover the patient identity from chest X-ray data. We demonstrate this using the publicly available large-scale ChestX-ray14 dataset, a collection of 112,120 frontal-view chest X-ray images from 30,805 unique patients. Our verification system is able to identify whether two frontal chest X-ray images are from the same person with an AUC of 0.9940 and a classification accuracy of 95.55%. We further highlight that the proposed system is able to reveal the same person even ten and more years after the initial scan. When pursuing a retrieval approach, we observe an mAP@R of 0.9748 and a precision@1 of 0.9963. Furthermore, we achieve an AUC of up to 0.9870 and a precision@1 of up to 0.9444 when evaluating our trained networks on CheXpert and the COVID-19 Image Data Collection. Based on this high identification rate, a potential attacker may leak patient-related information and additionally cross-reference images to obtain more information. Thus, there is a great risk of sensitive content falling into unauthorized hands or being disseminated against the will of the concerned patients. Especially during the COVID-19 pandemic, numerous chest X-ray datasets have been published to advance research. Therefore, such data may be vulnerable to potential attacks by deep learning-based re-identification algorithms.

</p>
</details>

<details><summary><b>RAWLSNET: Altering Bayesian Networks to Encode Rawlsian Fair Equality of Opportunity</b>
<a href="https://arxiv.org/abs/2104.03909">arxiv:2104.03909</a>
&#x1F4C8; 6 <br>
<p>David Liu, Zohair Shafi, William Fleisher, Tina Eliassi-Rad, Scott Alfeld</p></summary>
<p>

**Abstract:** We present RAWLSNET, a system for altering Bayesian Network (BN) models to satisfy the Rawlsian principle of fair equality of opportunity (FEO). RAWLSNET's BN models generate aspirational data distributions: data generated to reflect an ideally fair, FEO-satisfying society. FEO states that everyone with the same talent and willingness to use it should have the same chance of achieving advantageous social positions (e.g., employment), regardless of their background circumstances (e.g., socioeconomic status). Satisfying FEO requires alterations to social structures such as school assignments. Our paper describes RAWLSNET, a method which takes as input a BN representation of an FEO application and alters the BN's parameters so as to satisfy FEO when possible, and minimize deviation from FEO otherwise. We also offer guidance for applying RAWLSNET, including on recognizing proper applications of FEO. We demonstrate the use of our system with publicly available data sets. RAWLSNET's altered BNs offer the novel capability of generating aspirational data for FEO-relevant tasks. Aspirational data are free from the biases of real-world data, and thus are useful for recognizing and detecting sources of unfairness in machine learning algorithms besides biased data.

</p>
</details>

<details><summary><b>A Study of Automatic Metrics for the Evaluation of Natural Language Explanations</b>
<a href="https://arxiv.org/abs/2103.08545">arxiv:2103.08545</a>
&#x1F4C8; 6 <br>
<p>Miruna Clinciu, Arash Eshghi, Helen Hastie</p></summary>
<p>

**Abstract:** As transparency becomes key for robotics and AI, it will be necessary to evaluate the methods through which transparency is provided, including automatically generated natural language (NL) explanations. Here, we explore parallels between the generation of such explanations and the much-studied field of evaluation of Natural Language Generation (NLG). Specifically, we investigate which of the NLG evaluation measures map well to explanations. We present the ExBAN corpus: a crowd-sourced corpus of NL explanations for Bayesian Networks. We run correlations comparing human subjective ratings with NLG automatic measures. We find that embedding-based automatic NLG evaluation methods, such as BERTScore and BLEURT, have a higher correlation with human ratings, compared to word-overlap metrics, such as BLEU and ROUGE. This work has implications for Explainable AI and transparent robotic and autonomous systems.

</p>
</details>

<details><summary><b>Lasry-Lions Envelopes and Nonconvex Optimization: A Homotopy Approach</b>
<a href="https://arxiv.org/abs/2103.08533">arxiv:2103.08533</a>
&#x1F4C8; 6 <br>
<p>Miguel Simões, Andreas Themelis, Panagiotis Patrinos</p></summary>
<p>

**Abstract:** In large-scale optimization, the presence of nonsmooth and nonconvex terms in a given problem typically makes it hard to solve. A popular approach to address nonsmooth terms in convex optimization is to approximate them with their respective Moreau envelopes. In this work, we study the use of Lasry-Lions double envelopes to approximate nonsmooth terms that are also not convex. These envelopes are an extension of the Moreau ones but exhibit an additional smoothness property that makes them amenable to fast optimization algorithms. Lasry-Lions envelopes can also be seen as an "intermediate" between a given function and its convex envelope, and we make use of this property to develop a method that builds a sequence of approximate subproblems that are easier to solve than the original problem. We discuss convergence properties of this method when used to address composite minimization problems; additionally, based on a number of experiments, we discuss settings where it may be more useful than classical alternatives in two domains: signal decoding and spectral unmixing.

</p>
</details>

<details><summary><b>Learning Frequency-aware Dynamic Network for Efficient Super-Resolution</b>
<a href="https://arxiv.org/abs/2103.08357">arxiv:2103.08357</a>
&#x1F4C8; 6 <br>
<p>Wenbin Xie, Dehua Song, Chang Xu, Chunjing Xu, Hui Zhang, Yunhe Wang</p></summary>
<p>

**Abstract:** Deep learning based methods, especially convolutional neural networks (CNNs) have been successfully applied in the field of single image super-resolution (SISR). To obtain better fidelity and visual quality, most of existing networks are of heavy design with massive computation. However, the computation resources of modern mobile devices are limited, which cannot easily support the expensive cost. To this end, this paper explores a novel frequency-aware dynamic network for dividing the input into multiple parts according to its coefficients in the discrete cosine transform (DCT) domain. In practice, the high-frequency part will be processed using expensive operations and the lower-frequency part is assigned with cheap operations to relieve the computation burden. Since pixels or image patches belong to low-frequency areas contain relatively few textural details, this dynamic network will not affect the quality of resulting super-resolution images. In addition, we embed predictors into the proposed dynamic network to end-to-end fine-tune the handcrafted frequency-aware masks. Extensive experiments conducted on benchmark SISR models and datasets show that the frequency-aware dynamic network can be employed for various SISR neural architectures to obtain the better tradeoff between visual quality and computational complexity. For instance, we can reduce the FLOPs of SR models by approximate 50% while preserving state-of-the-art SISR performance.

</p>
</details>

<details><summary><b>Mention-centered Graph Neural Network for Document-level Relation Extraction</b>
<a href="https://arxiv.org/abs/2103.08200">arxiv:2103.08200</a>
&#x1F4C8; 6 <br>
<p>Jiaxin Pan, Min Peng, Yiyan Zhang</p></summary>
<p>

**Abstract:** Document-level relation extraction aims to discover relations between entities across a whole document. How to build the dependency of entities from different sentences in a document remains to be a great challenge. Current approaches either leverage syntactic trees to construct document-level graphs or aggregate inference information from different sentences. In this paper, we build cross-sentence dependencies by inferring compositional relations between inter-sentence mentions. Adopting aggressive linking strategy, intermediate relations are reasoned on the document-level graphs by mention convolution. We further notice the generalization problem of NA instances, which is caused by incomplete annotation and worsened by fully-connected mention pairs. An improved ranking loss is proposed to attend this problem. Experiments show the connections between different mentions are crucial to document-level relation extraction, which enables the model to extract more meaningful higher-level compositional relations.

</p>
</details>

<details><summary><b>Predicting Opioid Use Disorder from Longitudinal Healthcare Data using Multi-stream Transformer</b>
<a href="https://arxiv.org/abs/2103.08800">arxiv:2103.08800</a>
&#x1F4C8; 5 <br>
<p>Sajjad Fouladvand, Jeffery Talbert, Linda P. Dwoskin, Heather Bush, Amy Lynn Meadows, Lars E. Peterson, Ramakanth Kavuluru, Jin Chen</p></summary>
<p>

**Abstract:** Opioid Use Disorder (OUD) is a public health crisis costing the US billions of dollars annually in healthcare, lost workplace productivity, and crime. Analyzing longitudinal healthcare data is critical in addressing many real-world problems in healthcare. Leveraging the real-world longitudinal healthcare data, we propose a novel multi-stream transformer model called MUPOD for OUD identification. MUPOD is designed to simultaneously analyze multiple types of healthcare data streams, such as medications and diagnoses, by attending to segments within and across these data streams. Our model tested on the data from 392,492 patients with long-term back pain problems showed significantly better performance than the traditional models and recently developed deep learning models.

</p>
</details>

<details><summary><b>Domain-Incremental Continual Learning for Mitigating Bias in Facial Expression and Action Unit Recognition</b>
<a href="https://arxiv.org/abs/2103.08637">arxiv:2103.08637</a>
&#x1F4C8; 5 <br>
<p>Nikhil Churamani, Ozgur Kara, Hatice Gunes</p></summary>
<p>

**Abstract:** As Facial Expression Recognition (FER) systems become integrated into our daily lives, these systems need to prioritise making fair decisions instead of aiming at higher individual accuracy scores. Ranging from surveillance systems to diagnosing mental and emotional health conditions of individuals, these systems need to balance the accuracy vs fairness trade-off to make decisions that do not unjustly discriminate against specific under-represented demographic groups. Identifying bias as a critical problem in facial analysis systems, different methods have been proposed that aim to mitigate bias both at data and algorithmic levels. In this work, we propose the novel usage of Continual Learning (CL), in particular, using Domain-Incremental Learning (Domain-IL) settings, as a potent bias mitigation method to enhance the fairness of FER systems while guarding against biases arising from skewed data distributions. We compare different non-CL-based and CL-based methods for their classification accuracy and fairness scores on expression recognition and Action Unit (AU) detection tasks using two popular benchmarks, the RAF-DB and BP4D datasets, respectively. Our experimental results show that CL-based methods, on average, outperform other popular bias mitigation techniques on both accuracy and fairness metrics.

</p>
</details>

<details><summary><b>Sampling-free Variational Inference for Neural Networks with Multiplicative Activation Noise</b>
<a href="https://arxiv.org/abs/2103.08497">arxiv:2103.08497</a>
&#x1F4C8; 5 <br>
<p>Jannik Schmitt, Stefan Roth</p></summary>
<p>

**Abstract:** To adopt neural networks in safety critical domains, knowing whether we can trust their predictions is crucial. Bayesian neural networks (BNNs) provide uncertainty estimates by averaging predictions with respect to the posterior weight distribution. Variational inference methods for BNNs approximate the intractable weight posterior with a tractable distribution, yet mostly rely on sampling from the variational distribution during training and inference. Recent sampling-free approaches offer an alternative, but incur a significant parameter overhead. We here propose a more efficient parameterization of the posterior approximation for sampling-free variational inference that relies on the distribution induced by multiplicative Gaussian activation noise. This allows us to combine parameter efficiency with the benefits of sampling-free variational inference. Our approach yields competitive results for standard regression problems and scales well to large-scale image classification tasks including ImageNet.

</p>
</details>

<details><summary><b>Probabilistic Grammatical Evolution</b>
<a href="https://arxiv.org/abs/2103.08389">arxiv:2103.08389</a>
&#x1F4C8; 5 <br>
<p>Jessica Mégane, Nuno Lourenço, Penousal Machado</p></summary>
<p>

**Abstract:** Grammatical Evolution (GE) is one of the most popular Genetic Programming (GP) variants, and it has been used with success in several problem domains. Since the original proposal, many enhancements have been proposed to GE in order to address some of its main issues and improve its performance.
  In this paper we propose Probabilistic Grammatical Evolution (PGE), which introduces a new genotypic representation and new mapping mechanism for GE. Specifically, we resort to a Probabilistic Context-Free Grammar (PCFG) where its probabilities are adapted during the evolutionary process, taking into account the productions chosen to construct the fittest individual. The genotype is a list of real values, where each value represents the likelihood of selecting a derivation rule. We evaluate the performance of PGE in two regression problems and compare it with GE and Structured Grammatical Evolution (SGE).
  The results show that PGE has a a better performance than GE, with statistically significant differences, and achieved similar performance when comparing with SGE.

</p>
</details>

<details><summary><b>DeepOPG: Improving Orthopantomogram Finding Summarization with Weak Supervision</b>
<a href="https://arxiv.org/abs/2103.08290">arxiv:2103.08290</a>
&#x1F4C8; 5 <br>
<p>Tzu-Ming Harry Hsu, Yin-Chih Chelsea Wang</p></summary>
<p>

**Abstract:** Clinical finding summaries from an orthopantomogram, or a dental panoramic radiograph, have significant potential to improve patient communication and speed up clinical judgments. While orthopantomogram is a first-line tool for dental examinations, no existing work has explored the summarization of findings from it. A finding summary has to find teeth in the imaging study and label the teeth with several types of past treatments. To tackle the problem, we developDeepOPG that breaks the summarization process into functional segmentation and tooth localization, the latter of which is further refined by a novel dental coherence module. We also leverage weak supervision labels to improve detection results in a reinforcement learning scenario. Experiments show high efficacy of DeepOPG on finding summarization, achieving an overall AUC of 88.2% in detecting six types of findings. The proposed dental coherence and weak supervision both are shown to improve DeepOPG by adding 5.9% and 0.4% to AP@IoU=0.5.

</p>
</details>

<details><summary><b>Sample-efficient Reinforcement Learning Representation Learning with Curiosity Contrastive Forward Dynamics Model</b>
<a href="https://arxiv.org/abs/2103.08255">arxiv:2103.08255</a>
&#x1F4C8; 5 <br>
<p>Thanh Nguyen, Tung M. Luu, Thang Vu, Chang D. Yoo</p></summary>
<p>

**Abstract:** Developing an agent in reinforcement learning (RL) that is capable of performing complex control tasks directly from high-dimensional observation such as raw pixels is yet a challenge as efforts are made towards improving sample efficiency and generalization. This paper considers a learning framework for Curiosity Contrastive Forward Dynamics Model (CCFDM) in achieving a more sample-efficient RL based directly on raw pixels. CCFDM incorporates a forward dynamics model (FDM) and performs contrastive learning to train its deep convolutional neural network-based image encoder (IE) to extract conducive spatial and temporal information for achieving a more sample efficiency for RL. In addition, during training, CCFDM provides intrinsic rewards, produced based on FDM prediction error, encourages the curiosity of the RL agent to improve exploration. The diverge and less-repetitive observations provide by both our exploration strategy and data augmentation available in contrastive learning improve not only the sample efficiency but also the generalization. Performance of existing model-free RL methods such as Soft Actor-Critic built on top of CCFDM outperforms prior state-of-the-art pixel-based RL methods on the DeepMind Control Suite benchmark.

</p>
</details>

<details><summary><b>Towards Fair Affective Robotics: Continual Learning for Mitigating Bias in Facial Expression and Action Unit Recognition</b>
<a href="https://arxiv.org/abs/2103.09233">arxiv:2103.09233</a>
&#x1F4C8; 4 <br>
<p>Ozgur Kara, Nikhil Churamani, Hatice Gunes</p></summary>
<p>

**Abstract:** As affective robots become integral in human life, these agents must be able to fairly evaluate human affective expressions without discriminating against specific demographic groups. Identifying bias in Machine Learning (ML) systems as a critical problem, different approaches have been proposed to mitigate such biases in the models both at data and algorithmic levels. In this work, we propose Continual Learning (CL) as an effective strategy to enhance fairness in Facial Expression Recognition (FER) systems, guarding against biases arising from imbalances in data distributions. We compare different state-of-the-art bias mitigation approaches with CL-based strategies for fairness on expression recognition and Action Unit (AU) detection tasks using popular benchmarks for each; RAF-DB and BP4D. Our experiments show that CL-based methods, on average, outperform popular bias mitigation techniques, strengthening the need for further investigation into CL for the development of fairer FER algorithms.

</p>
</details>

<details><summary><b>Multi-Robot Routing with Time Windows: A Column Generation Approach</b>
<a href="https://arxiv.org/abs/2103.08835">arxiv:2103.08835</a>
&#x1F4C8; 4 <br>
<p>Naveed Haghani, Jiaoyang Li, Sven Koenig, Gautam Kunapuli, Claudio Contardo, Amelia Regan, Julian Yarkony</p></summary>
<p>

**Abstract:** Robots performing tasks in warehouses provide the first example of wide-spread adoption of autonomous vehicles in transportation and logistics. The efficiency of these operations, which can vary widely in practice, are a key factor in the success of supply chains. In this work we consider the problem of coordinating a fleet of robots performing picking operations in a warehouse so as to maximize the net profit achieved within a time period while respecting problem- and robot-specific constraints. We formulate the problem as a weighted set packing problem where the elements in consideration are items on the warehouse floor that can be picked up and delivered within specified time windows. We enforce the constraint that robots must not collide, that each item is picked up and delivered by at most one robot, and that the number of robots active at any time does not exceed the total number available. Since the set of routes is exponential in the size of the input, we attack optimization of the resulting integer linear program using column generation, where pricing amounts to solving an elementary resource-constrained shortest-path problem. We propose an efficient optimization scheme that avoids consideration of every increment within the time windows. We also propose a heuristic pricing algorithm that can efficiently solve the pricing subproblem. While this itself is an important problem, the insights gained from solving these problems effectively can lead to new advances in other time-widow constrained vehicle routing problems.

</p>
</details>

<details><summary><b>EX-RAY: Distinguishing Injected Backdoor from Natural Features in Neural Networks by Examining Differential Feature Symmetry</b>
<a href="https://arxiv.org/abs/2103.08820">arxiv:2103.08820</a>
&#x1F4C8; 4 <br>
<p>Yingqi Liu, Guangyu Shen, Guanhong Tao, Zhenting Wang, Shiqing Ma, Xiangyu Zhang</p></summary>
<p>

**Abstract:** Backdoor attack injects malicious behavior to models such that inputs embedded with triggers are misclassified to a target label desired by the attacker. However, natural features may behave like triggers, causing misclassification once embedded. While they are inevitable, mis-recognizing them as injected triggers causes false warnings in backdoor scanning. A prominent challenge is hence to distinguish natural features and injected backdoors. We develop a novel symmetric feature differencing method that identifies a smallest set of features separating two classes. A backdoor is considered injected if the corresponding trigger consists of features different from the set of features distinguishing the victim and target classes. We evaluate the technique on thousands of models, including both clean and trojaned models, from the TrojAI rounds 2-4 competitions and a number of models on ImageNet. Existing backdoor scanning techniques may produce hundreds of false positives (i.e., clean models recognized as trojaned). Our technique removes 78-100% of the false positives (by a state-of-the-art scanner ABS) with a small increase of false negatives by 0-30%, achieving 17-41% overall accuracy improvement, and facilitates achieving top performance on the leaderboard. It also boosts performance of other scanners. It outperforms false positive removal methods using L2 distance and attribution techniques. We also demonstrate its potential in detecting a number of semantic backdoor attacks.

</p>
</details>

<details><summary><b>Data-driven Thermal Anomaly Detection for Batteries using Unsupervised Shape Clustering</b>
<a href="https://arxiv.org/abs/2103.08796">arxiv:2103.08796</a>
&#x1F4C8; 4 <br>
<p>Xiaojun Li, Jianwei Li, Ali Abdollahi, Trevor Jones</p></summary>
<p>

**Abstract:** For electric vehicles (EV) and energy storage (ES) batteries, thermal runaway is a critical issue as it can lead to uncontrollable fires or even explosions. Thermal anomaly detection can identify problematic battery packs that may eventually undergo thermal runaway. However, there are common challenges like data unavailability, environment and configuration variations, and battery aging. We propose a data-driven method to detect battery thermal anomaly based on comparing shape-similarity between thermal measurements. Based on their shapes, the measurements are continuously being grouped into different clusters. Anomaly is detected by monitoring deviations within the clusters. Unlike model-based or other data-driven methods, the proposed method is robust to data loss and requires minimal reference data for different pack configurations. As the initial experimental results show, the method not only can be more accurate than the onboard BMS and but also can detect unforeseen anomalies at the early stage.

</p>
</details>

<details><summary><b>Visualizing Data Velocity using DSNE</b>
<a href="https://arxiv.org/abs/2103.08509">arxiv:2103.08509</a>
&#x1F4C8; 4 <br>
<p>Songting Shi</p></summary>
<p>

**Abstract:** We present a new technique called "DSNE" which learns the velocity embeddings of low dimensional map points when given the high-dimensional data points with its velocities. The technique is a variation of Stochastic Neighbor Embedding, which uses the Euclidean distance on the unit sphere between the unit-length velocity of the point and the unit-length direction from the point to its near neighbors to define similarities, and try to match the two kinds of similarities in the high dimension space and low dimension space to find the velocity embeddings on the low dimension space. DSNE can help to visualize how the data points move in the high dimension space by presenting the movements in two or three dimensions space. It is helpful for understanding the mechanism of cell differentiation and embryo development.

</p>
</details>

<details><summary><b>Geometric Change Detection in Digital Twins using 3D Machine Learning</b>
<a href="https://arxiv.org/abs/2103.08201">arxiv:2103.08201</a>
&#x1F4C8; 4 <br>
<p>Tiril Sundby, Julia Maria Graham, Adil Rasheed, Mandar Tabib, Omer San</p></summary>
<p>

**Abstract:** Digital twins are meant to bridge the gap between real-world physical systems and virtual representations. Both stand-alone and descriptive digital twins incorporate 3D geometric models, which are the physical representations of objects in the digital replica. Digital twin applications are required to rapidly update internal parameters with the evolution of their physical counterpart. Due to an essential need for having high-quality geometric models for accurate physical representations, the storage and bandwidth requirements for storing 3D model information can quickly exceed the available storage and bandwidth capacity. In this work, we demonstrate a novel approach to geometric change detection in the context of a digital twin. We address the issue through a combined solution of Dynamic Mode Decomposition (DMD) for motion detection, YOLOv5 for object detection, and 3D machine learning for pose estimation. DMD is applied for background subtraction, enabling detection of moving foreground objects in real-time. The video frames containing detected motion are extracted and used as input to the change detection network. The object detection algorithm YOLOv5 is applied to extract the bounding boxes of detected objects in the video frames. Furthermore, the rotational pose of each object is estimated in a 3D pose estimation network. A series of convolutional neural networks conducts feature extraction from images and 3D model shapes. Then, the network outputs the estimated Euler angles of the camera orientation with respect to the object in the input image. By only storing data associated with a detected change in pose, we minimize necessary storage and bandwidth requirements while still being able to recreate the 3D scene on demand.

</p>
</details>

<details><summary><b>Bayesian Model Averaging for Causality Estimation and its Approximation based on Gaussian Scale Mixture Distributions</b>
<a href="https://arxiv.org/abs/2103.08195">arxiv:2103.08195</a>
&#x1F4C8; 4 <br>
<p>Shunsuke Horii</p></summary>
<p>

**Abstract:** In the estimation of the causal effect under linear Structural Causal Models (SCMs), it is common practice to first identify the causal structure, estimate the probability distributions, and then calculate the causal effect. However, if the goal is to estimate the causal effect, it is not necessary to fix a single causal structure or probability distributions. In this paper, we first show from a Bayesian perspective that it is Bayes optimal to weight (average) the causal effects estimated under each model rather than estimating the causal effect under a fixed single model. This idea is also known as Bayesian model averaging. Although the Bayesian model averaging is optimal, as the number of candidate models increases, the weighting calculations become computationally hard. We develop an approximation to the Bayes optimal estimator by using Gaussian scale mixture distributions.

</p>
</details>

<details><summary><b>Modeling and forecasting Spread of COVID-19 epidemic in Iran until Sep 22, 2021, based on deep learning</b>
<a href="https://arxiv.org/abs/2103.08178">arxiv:2103.08178</a>
&#x1F4C8; 4 <br>
<p>Jafar Abdollahi, Amir Jalili Irani, Babak Nouri-Moghaddam</p></summary>
<p>

**Abstract:** The recent global outbreak of covid-19 is affecting many countries around the world. Due to the growing number of newly infected individuals and the health-care system bottlenecks, it will be useful to predict the upcoming number of patients. This study aims to efficiently forecast the is used to estimate new cases, number of deaths, and number of recovered patients in Iran for 180 days, using the official dataset of the Iranian Ministry of Health and Medical Education and the impact of control measures on the spread of COVID-19. Four different types of forecasting techniques, time series, and machine learning algorithms, are developed and the best performing method for the given case study is determined. Under the time series, we consider the four algorithms including Prophet, Long short-term memory, Autoregressive, Autoregressive Integrated Moving Average models. On comparing the different techniques, we found that deep learning methods yield better results than time series forecasting algorithms. More specifically, the least value of the error measures is observed in seasonal ANN and LSTM models. Our findings showed that if precautionary measures are taken seriously, the number of new cases and deaths will decrease, and the number of deaths in September 2021 will reach zero.

</p>
</details>

<details><summary><b>Constrained plasticity reserve as a natural way to control frequency and weights in spiking neural networks</b>
<a href="https://arxiv.org/abs/2103.08143">arxiv:2103.08143</a>
&#x1F4C8; 4 <br>
<p>Oleg Nikitin, Olga Lukyanova, Alex Kunin</p></summary>
<p>

**Abstract:** Biological neurons have adaptive nature and perform complex computations involving the filtering of redundant information. However, most common neural cell models, including biologically plausible, such as Hodgkin-Huxley or Izhikevich, do not possess predictive dynamics on a single-cell level. Moreover, the modern rules of synaptic plasticity or interconnections weights adaptation also do not provide grounding for the ability of neurons to adapt to the ever-changing input signal intensity. While natural neuron synaptic growth is precisely controlled and restricted by protein supply and recycling, weight correction rules such as widely used STDP are efficiently unlimited in change rate and scale. The present article introduces new mechanics of interconnection between neuron firing rate homeostasis and weight change through STDP growth bounded by abstract protein reserve, controlled by the intracellular optimization algorithm. We show how these cellular dynamics help neurons filter out the intense noise signals to help neurons keep a stable firing rate. We also examine that such filtering does not affect the ability of neurons to recognize the correlated inputs in unsupervised mode. Such an approach might be used in the machine learning domain to improve the robustness of AI systems.

</p>
</details>

<details><summary><b>dictNN: A Dictionary-Enhanced CNN Approach for Classifying Hate Speech on Twitter</b>
<a href="https://arxiv.org/abs/2103.08780">arxiv:2103.08780</a>
&#x1F4C8; 3 <br>
<p>Maximilian Kupi, Michael Bodnar, Nikolas Schmidt, Carlos Eduardo Posada</p></summary>
<p>

**Abstract:** Hate speech on social media is a growing concern, and automated methods have so far been sub-par at reliably detecting it. A major challenge lies in the potentially evasive nature of hate speech due to the ambiguity and fast evolution of natural language. To tackle this, we introduce a vectorisation based on a crowd-sourced and continuously updated dictionary of hate words and propose fusing this approach with standard word embedding in order to improve the classification performance of a CNN model. To train and test our model we use a merge of two established datasets (110,748 tweets in total). By adding the dictionary-enhanced input, we are able to increase the CNN model's predictive power and increase the F1 macro score by seven percentage points.

</p>
</details>

<details><summary><b>Online Learning with Radial Basis Function Networks</b>
<a href="https://arxiv.org/abs/2103.08414">arxiv:2103.08414</a>
&#x1F4C8; 3 <br>
<p>Gabriel Borrageiro, Nick Firoozye, Paolo Barucca</p></summary>
<p>

**Abstract:** We investigate the benefits of feature selection, nonlinear modelling and online learning when forecasting in financial time series. We consider the sequential and continual learning sub-genres of online learning. The experiments we conduct show that there is a benefit to online transfer learning, beyond the sequential updating of recursive least-squares models. We show that feature representation transfer via radial basis function networks, which make use of clustering algorithms to construct a kernel Gram matrix, are more beneficial than treating each training vector as separate basis functions, as occurs with kernel Ridge regression. We also demonstrate quantitative procedures to determine the very structure of the networks. Finally, we conduct experiments on the log returns of financial time series and show that these online transfer learning models are able to outperform a random walk baseline, whereas the offline learning models struggle to do so.

</p>
</details>

<details><summary><b>Neural Networks and Denotation</b>
<a href="https://arxiv.org/abs/2103.08315">arxiv:2103.08315</a>
&#x1F4C8; 3 <br>
<p>Eric E. Allen</p></summary>
<p>

**Abstract:** We introduce a framework for reasoning about what meaning is captured by the neurons in a trained neural network. We provide a strategy for discovering meaning by training a second model (referred to as an observer model) to classify the state of the model it observes (an object model) in relation to attributes of the underlying dataset. We implement and evaluate observer models in the context of a specific set of classification problems, employ heat maps for visualizing the relevance of components of an object model in the context of linear observer models, and use these visualizations to extract insights about the manner in which neural networks identify salient characteristics of their inputs. We identify important properties captured decisively in trained neural networks; some of these properties are denoted by individual neurons. Finally, we observe that the label proportion of a property denoted by a neuron is dependent on the depth of a neuron within a network; we analyze these dependencies, and provide an interpretation of them.

</p>
</details>

<details><summary><b>AI Fairness via Domain Adaptation</b>
<a href="https://arxiv.org/abs/2104.01109">arxiv:2104.01109</a>
&#x1F4C8; 2 <br>
<p>Neil Joshi, Phil Burlina</p></summary>
<p>

**Abstract:** While deep learning (DL) approaches are reaching human-level performance for many tasks, including for diagnostics AI, the focus is now on challenges possibly affecting DL deployment, including AI privacy, domain generalization, and fairness. This last challenge is addressed in this study. Here we look at a novel method for ensuring AI fairness with respect to protected or sensitive factors. This method uses domain adaptation via training set enhancement to tackle bias-causing training data imbalance. More specifically, it uses generative models that allow the generation of more synthetic training samples for underrepresented populations. This paper applies this method to the use case of detection of age related macular degeneration (AMD). Our experiments show that starting with an originally biased AMD diagnostics model the method has the ability to improve fairness.

</p>
</details>

<details><summary><b>Automatic detection of impact craters on Al foils from the Stardust interstellar dust collector using convolutional neural networks</b>
<a href="https://arxiv.org/abs/2103.09673">arxiv:2103.09673</a>
&#x1F4C8; 2 <br>
<p>Logan Jaeger, Anna L. Butterworth, Zack Gainsforth, Robert Lettieri, Augusto Ardizzone, Michael Capraro, Mark Burchell, Penny Wozniakiewicz, Ryan C. Ogliore, Bradley T. De Gregorio, Rhonda M. Stroud, Andrew J. Westphal</p></summary>
<p>

**Abstract:** NASA's Stardust mission utilized a sample collector composed of aerogel and aluminum foil to return cometary and interstellar particles to Earth. Analysis of the aluminum foil begins with locating craters produced by hypervelocity impacts of cometary and interstellar dust. Interstellar dust craters are typically less than one micrometer in size and are sparsely distributed, making them difficult to find. In this paper, we describe a convolutional neural network based on the VGG16 architecture that achieves high specificity and sensitivity in locating impact craters in the Stardust interstellar collector foils. We evaluate its implications for current and future analyses of Stardust samples.

</p>
</details>

<details><summary><b>Physics-Informed Neural Network Method for Solving One-Dimensional Advection Equation Using PyTorch</b>
<a href="https://arxiv.org/abs/2103.09662">arxiv:2103.09662</a>
&#x1F4C8; 2 <br>
<p>Shashank Reddy Vadyala, Sai Nethra Betgeri</p></summary>
<p>

**Abstract:** Numerical solutions to the equation for advection are determined using different finite-difference approximations and physics-informed neural networks (PINNs) under conditions that allow an analytical solution. Their accuracy is examined by comparing them to the analytical solution. We used a machine learning framework like PyTorch to implement PINNs. PINNs approach allows training neural networks while respecting the PDEs as a strong constraint in the optimization as apposed to making them part of the loss function. In standard small-scale circulation simulations, it is shown that the conventional approach incorporates a pseudo diffusive effect that is almost as large as the effect of the turbulent diffusion model; hence the numerical solution is rendered inconsistent with the PDEs. This oscillation causes inaccuracy and computational uncertainty. Of all the schemes tested, only the PINNs approximation accurately predicted the outcome. We assume that the PINNs approach can transform the physics simulation area by allowing real-time physics simulation and geometry optimization without costly and time-consuming simulations on large supercomputers.

</p>
</details>

<details><summary><b>Soft and subspace robust multivariate rank tests based on entropy regularized optimal transport</b>
<a href="https://arxiv.org/abs/2103.08811">arxiv:2103.08811</a>
&#x1F4C8; 2 <br>
<p>Shoaib Bin Masud, Boyang Lyu, Shuchin Aeron</p></summary>
<p>

**Abstract:** In this paper, we extend the recently proposed multivariate rank energy distance, based on the theory of optimal transport, for statistical testing of distributional similarity, to soft rank energy distance. Being differentiable, this in turn allows us to extend the rank energy to a subspace robust rank energy distance, dubbed Projected soft-Rank Energy distance, which can be computed via optimization over the Stiefel manifold. We show via experiments that using projected soft rank energy one can trade-off the detection power vs the false alarm via projections onto an appropriately selected low dimensional subspace. We also show the utility of the proposed tests on unsupervised change point detection in multivariate time series data. All codes are publicly available at the link provided in the experiment section.

</p>
</details>

<details><summary><b>Deep Reinforcement Learning for Band Selection in Hyperspectral Image Classification</b>
<a href="https://arxiv.org/abs/2103.08741">arxiv:2103.08741</a>
&#x1F4C8; 2 <br>
<p>Lichao Mou, Sudipan Saha, Yuansheng Hua, Francesca Bovolo, Lorenzo Bruzzone, Xiao Xiang Zhu</p></summary>
<p>

**Abstract:** Band selection refers to the process of choosing the most relevant bands in a hyperspectral image. By selecting a limited number of optimal bands, we aim at speeding up model training, improving accuracy, or both. It reduces redundancy among spectral bands while trying to preserve the original information of the image. By now many efforts have been made to develop unsupervised band selection approaches, of which the majority are heuristic algorithms devised by trial and error. In this paper, we are interested in training an intelligent agent that, given a hyperspectral image, is capable of automatically learning policy to select an optimal band subset without any hand-engineered reasoning. To this end, we frame the problem of unsupervised band selection as a Markov decision process, propose an effective method to parameterize it, and finally solve the problem by deep reinforcement learning. Once the agent is trained, it learns a band-selection policy that guides the agent to sequentially select bands by fully exploiting the hyperspectral image and previously picked bands. Furthermore, we propose two different reward schemes for the environment simulation of deep reinforcement learning and compare them in experiments. This, to the best of our knowledge, is the first study that explores a deep reinforcement learning model for hyperspectral image analysis, thus opening a new door for future research and showcasing the great potential of deep reinforcement learning in remote sensing applications. Extensive experiments are carried out on four hyperspectral data sets, and experimental results demonstrate the effectiveness of the proposed method.

</p>
</details>

<details><summary><b>A Central Limit Theorem for Differentially Private Query Answering</b>
<a href="https://arxiv.org/abs/2103.08721">arxiv:2103.08721</a>
&#x1F4C8; 2 <br>
<p>Jinshuo Dong, Weijie J. Su, Linjun Zhang</p></summary>
<p>

**Abstract:** Perhaps the single most important use case for differential privacy is to privately answer numerical queries, which is usually achieved by adding noise to the answer vector. The central question, therefore, is to understand which noise distribution optimizes the privacy-accuracy trade-off, especially when the dimension of the answer vector is high. Accordingly, extensive literature has been dedicated to the question and the upper and lower bounds have been matched up to constant factors [BUV18, SU17]. In this paper, we take a novel approach to address this important optimality question. We first demonstrate an intriguing central limit theorem phenomenon in the high-dimensional regime. More precisely, we prove that a mechanism is approximately Gaussian Differentially Private [DRS21] if the added noise satisfies certain conditions. In particular, densities proportional to $\mathrm{e}^{-\|x\|_p^α}$, where $\|x\|_p$ is the standard $\ell_p$-norm, satisfies the conditions. Taking this perspective, we make use of the Cramer--Rao inequality and show an "uncertainty principle"-style result: the product of the privacy parameter and the $\ell_2$-loss of the mechanism is lower bounded by the dimension. Furthermore, the Gaussian mechanism achieves the constant-sharp optimal privacy-accuracy trade-off among all such noises. Our findings are corroborated by numerical experiments.

</p>
</details>

<details><summary><b>Deep Learning for Chest X-ray Analysis: A Survey</b>
<a href="https://arxiv.org/abs/2103.08700">arxiv:2103.08700</a>
&#x1F4C8; 2 <br>
<p>Ecem Sogancioglu, Erdi Çallı, Bram van Ginneken, Kicky G. van Leeuwen, Keelin Murphy</p></summary>
<p>

**Abstract:** Recent advances in deep learning have led to a promising performance in many medical image analysis tasks. As the most commonly performed radiological exam, chest radiographs are a particularly important modality for which a variety of applications have been researched. The release of multiple, large, publicly available chest X-ray datasets in recent years has encouraged research interest and boosted the number of publications. In this paper, we review all studies using deep learning on chest radiographs, categorizing works by task: image-level prediction (classification and regression), segmentation, localization, image generation and domain adaptation. Commercially available applications are detailed, and a comprehensive discussion of the current state of the art and potential future directions are provided.

</p>
</details>

<details><summary><b>Discriminative Learning for Probabilistic Context-Free Grammars based on Generalized H-Criterion</b>
<a href="https://arxiv.org/abs/2103.08656">arxiv:2103.08656</a>
&#x1F4C8; 2 <br>
<p>Mauricio Maca, José Miguel Benedí, Joan Andreu Sánchez</p></summary>
<p>

**Abstract:** We present a formal framework for the development of a family of discriminative learning algorithms for Probabilistic Context-Free Grammars (PCFGs) based on a generalization of criterion-H. First of all, we propose the H-criterion as the objective function and the Growth Transformations as the optimization method, which allows us to develop the final expressions for the estimation of the parameters of the PCFGs. And second, we generalize the H-criterion to take into account the set of reference interpretations and the set of competing interpretations, and we propose a new family of objective functions that allow us to develop the expressions of the estimation transformations for PCFGs.

</p>
</details>

<details><summary><b>DHASP: Differentiable Hearing Aid Speech Processing</b>
<a href="https://arxiv.org/abs/2103.08569">arxiv:2103.08569</a>
&#x1F4C8; 2 <br>
<p>Zehai Tu, Ning Ma, Jon Barker</p></summary>
<p>

**Abstract:** Hearing aids are expected to improve speech intelligibility for listeners with hearing impairment. An appropriate amplification fitting tuned for the listener's hearing disability is critical for good performance. The developments of most prescriptive fittings are based on data collected in subjective listening experiments, which are usually expensive and time-consuming. In this paper, we explore an alternative approach to finding the optimal fitting by introducing a hearing aid speech processing framework, in which the fitting is optimised in an automated way using an intelligibility objective function based on the HASPI physiological auditory model. The framework is fully differentiable, thus can employ the back-propagation algorithm for efficient, data-driven optimisation. Our initial objective experiments show promising results for noise-free speech amplification, where the automatically optimised processors outperform one of the well recognised hearing aid prescriptions.

</p>
</details>

<details><summary><b>Which K-Space Sampling Schemes is good for Motion Artifact Detection in Magnetic Resonance Imaging?</b>
<a href="https://arxiv.org/abs/2103.08516">arxiv:2103.08516</a>
&#x1F4C8; 2 <br>
<p>Mohammad Reza Mohebbian, Ekta Walia, Khan A. Wahid</p></summary>
<p>

**Abstract:** Motion artifacts are a common occurrence in the Magnetic Resonance Imaging (MRI) exam. Motion during acquisition has a profound impact on workflow efficiency, often requiring a repeat of sequences. Furthermore, motion artifacts may escape notice by technologists, only to be revealed at the time of reading by the radiologists, affecting their diagnostic quality. Designing a computer-aided tool for automatic motion detection and elimination can improve the diagnosis, however, it needs a deep understanding of motion characteristics. Motion artifacts in MRI have a complex nature and it is directly related to the k-space sampling scheme. In this study we investigate the effect of three conventional k-space samplers, including Cartesian, Uniform Spiral and Radial on motion induced image distortion. In this regard, various synthetic motions with different trajectories of displacement and rotation are applied to T1 and T2-weighted MRI images, and a convolutional neural network is trained to show the difficulty of motion classification. The results show that the spiral k-space sampling method get less effect of motion artifact in image space as compared to radial k-space sampled images, and radial k-space sampled images are more robust than Cartesian ones. Cartesian samplers, on the other hand, are the best in terms of deep learning motion detection because they can better reflect motion.

</p>
</details>

<details><summary><b>Deep Consensus Learning</b>
<a href="https://arxiv.org/abs/2103.08475">arxiv:2103.08475</a>
&#x1F4C8; 2 <br>
<p>Wei Sun, Tianfu Wu</p></summary>
<p>

**Abstract:** Both generative learning and discriminative learning have recently witnessed remarkable progress using Deep Neural Networks (DNNs). For structured input synthesis and structured output prediction problems (e.g., layout-to-image synthesis and image semantic segmentation respectively), they often are studied separately. This paper proposes deep consensus learning (DCL) for joint layout-to-image synthesis and weakly-supervised image semantic segmentation. The former is realized by a recently proposed LostGAN approach, and the latter by introducing an inference network as the third player joining the two-player game of LostGAN. Two deep consensus mappings are exploited to facilitate training the three networks end-to-end: Given an input layout (a list of object bounding boxes), the generator generates a mask (label map) and then use it to help synthesize an image. The inference network infers the mask for the synthesized image. Then, the latent consensus is measured between the mask generated by the generator and the one inferred by the inference network. For the real image corresponding to the input layout, its mask also is computed by the inference network, and then used by the generator to reconstruct the real image. Then, the data consensus is measured between the real image and its reconstructed image. The discriminator still plays the role of an adversary by computing the realness scores for a real image, its reconstructed image and a synthesized image. In experiments, our DCL is tested in the COCO-Stuff dataset. It obtains compelling layout-to-image synthesis results and weakly-supervised image semantic segmentation results.

</p>
</details>

<details><summary><b>Deep Dynamic Neural Network to trade-off between Accuracy and Diversity in a News Recommender System</b>
<a href="https://arxiv.org/abs/2103.08458">arxiv:2103.08458</a>
&#x1F4C8; 2 <br>
<p>Shaina Raza, Chen Ding</p></summary>
<p>

**Abstract:** The news recommender systems are marked by a few unique challenges specific to the news domain. These challenges emerge from rapidly evolving readers' interests over dynamically generated news items that continuously change over time. News reading is also driven by a blend of a reader's long-term and short-term interests. In addition, diversity is required in a news recommender system, not only to keep the reader engaged in the reading process but to get them exposed to different views and opinions. In this paper, we propose a deep neural network that jointly learns informative news and readers' interests into a unified framework. We learn the news representation (features) from the headlines, snippets (body) and taxonomy (category, subcategory) of news. We learn a reader's long-term interests from the reader's click history, short-term interests from the recent clicks via LSTMSs and the diversified reader's interests through the attention mechanism. We also apply different levels of attention to our model. We conduct extensive experiments on two news datasets to demonstrate the effectiveness of our approach.

</p>
</details>

<details><summary><b>Gradient Policy on "CartPole" game and its' expansibility to F1Tenth Autonomous Vehicles</b>
<a href="https://arxiv.org/abs/2103.08396">arxiv:2103.08396</a>
&#x1F4C8; 2 <br>
<p>Mingwei Shi</p></summary>
<p>

**Abstract:** Policy gradient is an effective way to estimate continuous action on the environment. This paper, it about explaining the mathematical formula and code implementation. In the end, comparing between the rotation angle of the stick on CartPole , and the angle of the Autonomous vehicle when turning, and utilizing the Bicycle Model, a simple Kinematic dynamic model, are the purpose to discover the similarity between these two models, so as to facilitate the model transfer from CartPole to the F1tenth Autonomous vehicle.

</p>
</details>

<details><summary><b>Sent2Matrix: Folding Character Sequences in Serpentine Manifolds for Two-Dimensional Sentence</b>
<a href="https://arxiv.org/abs/2103.08387">arxiv:2103.08387</a>
&#x1F4C8; 2 <br>
<p>Hongyang Gao, Yi Liu, Xuan Zhang, Shuiwang Ji</p></summary>
<p>

**Abstract:** We study text representation methods using deep models. Current methods, such as word-level embedding and character-level embedding schemes, treat texts as either a sequence of atomic words or a sequence of characters. These methods either ignore word morphologies or word boundaries. To overcome these limitations, we propose to convert texts into 2-D representations and develop the Sent2Matrix method. Our method allows for the explicit incorporation of both word morphologies and boundaries. When coupled with a novel serpentine padding method, our Sent2Matrix method leads to an interesting visualization in which 1-D character sequences are folded into 2-D serpentine manifolds. Notably, our method is the first attempt to represent texts in 2-D formats. Experimental results on text classification tasks shown that our method consistently outperforms prior embedding methods.

</p>
</details>

<details><summary><b>Lower Complexity Bounds of Finite-Sum Optimization Problems: The Results and Construction</b>
<a href="https://arxiv.org/abs/2103.08280">arxiv:2103.08280</a>
&#x1F4C8; 2 <br>
<p>Yuze Han, Guangzeng Xie, Zhihua Zhang</p></summary>
<p>

**Abstract:** The contribution of this paper includes two aspects. First, we study the lower bound complexity for the minimax optimization problem whose objective function is the average of $n$ individual smooth component functions. We consider Proximal Incremental First-order (PIFO) algorithms which have access to gradient and proximal oracle for each individual component. We develop a novel approach for constructing adversarial problems, which partitions the tridiagonal matrix of classical examples into $n$ groups. This construction is friendly to the analysis of incremental gradient and proximal oracle. With this approach, we demonstrate the lower bounds of first-order algorithms for finding an $\varepsilon$-suboptimal point and an $\varepsilon$-stationary point in different settings. Second, we also derive the lower bounds of minimization optimization with PIFO algorithms from our approach, which can cover the results in \citep{woodworth2016tight} and improve the results in \citep{zhou2019lower}.

</p>
</details>

<details><summary><b>Representation Theorem for Matrix Product States</b>
<a href="https://arxiv.org/abs/2103.08277">arxiv:2103.08277</a>
&#x1F4C8; 2 <br>
<p>Erdong Guo, David Draper</p></summary>
<p>

**Abstract:** In this work, we investigate the universal representation capacity of the Matrix Product States (MPS) from the perspective of boolean functions and continuous functions. We show that MPS can accurately realize arbitrary boolean functions by providing a construction method of the corresponding MPS structure for an arbitrarily given boolean gate. Moreover, we prove that the function space of MPS with the scale-invariant sigmoidal activation is dense in the space of continuous functions defined on a compact subspace of the $n$-dimensional real coordinate space $\mathbb{R^{n}}$. We study the relation between MPS and neural networks and show that the MPS with a scale-invariant sigmoidal function is equivalent to a one-hidden-layer neural network equipped with a kernel function. We construct the equivalent neural networks for several specific MPS models and show that non-linear kernels such as the polynomial kernel which introduces the couplings between different components of the input into the model appear naturally in the equivalent neural networks. At last, we discuss the realization of the Gaussian Process (GP) with infinitely wide MPS by studying their equivalent neural networks.

</p>
</details>

<details><summary><b>The QXS-SAROPT Dataset for Deep Learning in SAR-Optical Data Fusion</b>
<a href="https://arxiv.org/abs/2103.08259">arxiv:2103.08259</a>
&#x1F4C8; 2 <br>
<p>Meiyu Huang, Yao Xu, Lixin Qian, Weili Shi, Yaqin Zhang, Wei Bao, Nan Wang, Xuejiao Liu, Xueshuang Xiang</p></summary>
<p>

**Abstract:** Deep learning techniques have made an increasing impact on the field of remote sensing. However, deep neural networks based fusion of multimodal data from different remote sensors with heterogenous characteristics has not been fully explored, due to the lack of availability of big amounts of perfectly aligned multi-sensor image data with diverse scenes of high resolutions, especially for synthetic aperture radar (SAR) data and optical imagery. To promote the development of deep learning based SAR-optical fusion approaches, we release the QXS-SAROPT dataset, which contains 20,000 pairs of SAR-optical image patches. We obtain the SAR patches from SAR satellite GaoFen-3 images and the optical patches from Google Earth images. These images cover three port cities: San Diego, Shanghai and Qingdao. Here, we present a detailed introduction of the construction of the dataset, and show its two representative exemplary applications, namely SAR-optical image matching and SAR ship detection boosted by cross-modal information from optical images. As a large open SAR-optical dataset with multiple scenes of a high resolution, we believe QXS-SAROPT will be of potential value for further research in SAR-optical data fusion technology based on deep learning.

</p>
</details>

<details><summary><b>Boosting ship detection in SAR images with complementary pretraining techniques</b>
<a href="https://arxiv.org/abs/2103.08251">arxiv:2103.08251</a>
&#x1F4C8; 2 <br>
<p>Wei Bao, Meiyu Huang, Yaqin Zhang, Yao Xu, Xuejiao Liu, Xueshuang Xiang</p></summary>
<p>

**Abstract:** Deep learning methods have made significant progress in ship detection in synthetic aperture radar (SAR) images. The pretraining technique is usually adopted to support deep neural networks-based SAR ship detectors due to the scarce labeled SAR images. However, directly leveraging ImageNet pretraining is hardly to obtain a good ship detector because of different imaging perspective and geometry. In this paper, to resolve the problem of inconsistent imaging perspective between ImageNet and earth observations, we propose an optical ship detector (OSD) pretraining technique, which transfers the characteristics of ships in earth observations to SAR images from a large-scale aerial image dataset. On the other hand, to handle the problem of different imaging geometry between optical and SAR images, we propose an optical-SAR matching (OSM) pretraining technique, which transfers plentiful texture features from optical images to SAR images by common representation learning on the optical-SAR matching task. Finally, observing that the OSD pretraining based SAR ship detector has a better recall on sea area while the OSM pretraining based SAR ship detector can reduce false alarms on land area, we combine the predictions of the two detectors through weighted boxes fusion to further improve detection results. Extensive experiments on four SAR ship detection datasets and two representative CNN-based detection benchmarks are conducted to show the effectiveness and complementarity of the two proposed detectors, and the state-of-the-art performance of the combination of the two detectors. The proposed method won the sixth place of ship detection in SAR images in 2020 Gaofen challenge.

</p>
</details>

<details><summary><b>Emergence of Self-Reproducing Metabolisms as Recursive Algorithms in an Artificial Chemistry</b>
<a href="https://arxiv.org/abs/2103.08245">arxiv:2103.08245</a>
&#x1F4C8; 2 <br>
<p>Germán Kruszewski, Tomas Mikolov</p></summary>
<p>

**Abstract:** One of the main goals of Artificial Life is to research the conditions for the emergence of life, not necessarily as it is, but as it could be. Artificial Chemistries are one of the most important tools for this purpose because they provide us with a basic framework to investigate under which conditions metabolisms capable of reproducing themselves, and ultimately, of evolving, can emerge. While there have been successful attempts at producing examples of emergent self-reproducing metabolisms, the set of rules involved remain too complex to shed much light on the underlying principles at work. In this paper, we hypothesize that the key property needed for self-reproducing metabolisms to emerge is the existence of an auto-catalyzed subset of Turing-complete reactions. We validate this hypothesis with a minimalistic Artificial Chemistry with conservation laws, which is based on a Turing-complete rewriting system called Combinatory Logic. Our experiments show that a single run of this chemistry, starting from a tabula rasa state, discovers -- with no external intervention -- a wide range of emergent structures including ones that self-reproduce in each cycle. All of these structures take the form of recursive algorithms that acquire basic constituents from the environment and decompose them in a process that is remarkably similar to biological metabolisms.

</p>
</details>

<details><summary><b>Generating Synthetic Handwritten Historical Documents With OCR Constrained GANs</b>
<a href="https://arxiv.org/abs/2103.08236">arxiv:2103.08236</a>
&#x1F4C8; 2 <br>
<p>Lars Vögtlin, Manuel Drazyk, Vinaychandran Pondenkandath, Michele Alberti, Rolf Ingold</p></summary>
<p>

**Abstract:** We present a framework to generate synthetic historical documents with precise ground truth using nothing more than a collection of unlabeled historical images. Obtaining large labeled datasets is often the limiting factor to effectively use supervised deep learning methods for Document Image Analysis (DIA). Prior approaches towards synthetic data generation either require expertise or result in poor accuracy in the synthetic documents. To achieve high precision transformations without requiring expertise, we tackle the problem in two steps. First, we create template documents with user-specified content and structure. Second, we transfer the style of a collection of unlabeled historical images to these template documents while preserving their text and layout. We evaluate the use of our synthetic historical documents in a pre-training setting and find that we outperform the baselines (randomly initialized and pre-trained). Additionally, with visual examples, we demonstrate a high-quality synthesis that makes it possible to generate large labeled historical document datasets with precise ground truth.

</p>
</details>

<details><summary><b>Robust MAML: Prioritization task buffer with adaptive learning process for model-agnostic meta-learning</b>
<a href="https://arxiv.org/abs/2103.08233">arxiv:2103.08233</a>
&#x1F4C8; 2 <br>
<p>Thanh Nguyen, Tung Luu, Trung Pham, Sanzhar Rakhimkul, Chang D. Yoo</p></summary>
<p>

**Abstract:** Model agnostic meta-learning (MAML) is a popular state-of-the-art meta-learning algorithm that provides good weight initialization of a model given a variety of learning tasks. The model initialized by provided weight can be fine-tuned to an unseen task despite only using a small amount of samples and within a few adaptation steps. MAML is simple and versatile but requires costly learning rate tuning and careful design of the task distribution which affects its scalability and generalization. This paper proposes a more robust MAML based on an adaptive learning scheme and a prioritization task buffer(PTB) referred to as Robust MAML (RMAML) for improving scalability of training process and alleviating the problem of distribution mismatch. RMAML uses gradient-based hyper-parameter optimization to automatically find the optimal learning rate and uses the PTB to gradually adjust train-ing task distribution toward testing task distribution over the course of training. Experimental results on meta reinforcement learning environments demonstrate a substantial performance gain as well as being less sensitive to hyper-parameter choice and robust to distribution mismatch.

</p>
</details>

<details><summary><b>Double Articulation Analyzer with Prosody for Unsupervised Word and Phoneme Discovery</b>
<a href="https://arxiv.org/abs/2103.08199">arxiv:2103.08199</a>
&#x1F4C8; 2 <br>
<p>Yasuaki Okuda, Ryo Ozaki, Tadahiro Taniguchi</p></summary>
<p>

**Abstract:** Infants acquire words and phonemes from unsegmented speech signals using segmentation cues, such as distributional, prosodic, and co-occurrence cues. Many pre-existing computational models that represent the process tend to focus on distributional or prosodic cues. This paper proposes a nonparametric Bayesian probabilistic generative model called the prosodic hierarchical Dirichlet process-hidden language model (Prosodic HDP-HLM). Prosodic HDP-HLM, an extension of HDP-HLM, considers both prosodic and distributional cues within a single integrative generative model. We conducted three experiments on different types of datasets, and demonstrate the validity of the proposed method. The results show that the Prosodic DAA successfully uses prosodic cues and outperforms a method that solely uses distributional cues. The main contributions of this study are as follows: 1) We develop a probabilistic generative model for time series data including prosody that potentially has a double articulation structure; 2) We propose the Prosodic DAA by deriving the inference procedure for Prosodic HDP-HLM and show that Prosodic DAA can discover words directly from continuous human speech signals using statistical information and prosodic information in an unsupervised manner; 3) We show that prosodic cues contribute to word segmentation more in naturally distributed case words, i.e., they follow Zipf's law.

</p>
</details>

<details><summary><b>Hybrid stacked ensemble combined with genetic algorithms for Prediction of Diabetes</b>
<a href="https://arxiv.org/abs/2103.08186">arxiv:2103.08186</a>
&#x1F4C8; 2 <br>
<p>Jafar Abdollahi, Babak Nouri-Moghaddam</p></summary>
<p>

**Abstract:** Diabetes is currently one of the most common, dangerous, and costly diseases in the world that is caused by an increase in blood sugar or a decrease in insulin in the body. Diabetes can have detrimental effects on people's health if diagnosed late. Today, diabetes has become one of the challenges for health and government officials. Prevention is a priority, and taking care of people's health without compromising their comfort is an essential need. In this study, the Ensemble training methodology based on genetic algorithms are used to accurately diagnose and predict the outcomes of diabetes mellitus. In this study, we use the experimental data, real data on Indian diabetics on the University of California website. Current developments in ICT, such as the Internet of Things, machine learning, and data mining, allow us to provide health strategies with more intelligent capabilities to accurately predict the outcomes of the disease in daily life and the hospital and prevent the progression of this disease and its many complications. The results show the high performance of the proposed method in diagnosing the disease, which has reached 98.8%, and 99% accuracy in this study.

</p>
</details>

<details><summary><b>Deep Neural Network Based Ensemble learning Algorithms for the healthcare system (diagnosis of chronic diseases)</b>
<a href="https://arxiv.org/abs/2103.08182">arxiv:2103.08182</a>
&#x1F4C8; 2 <br>
<p>Jafar Abdollahi, Babak Nouri-Moghaddam, Mehdi Ghazanfari</p></summary>
<p>

**Abstract:** learning algorithms. In this paper, we review the classification algorithms used in the health care system (chronic diseases) and present the neural network-based Ensemble learning method. We briefly describe the commonly used algorithms and describe their critical properties. Materials and Methods: In this study, modern classification algorithms used in healthcare, examine the principles of these methods and guidelines, and to accurately diagnose and predict chronic diseases, superior machine learning algorithms with the neural network-based ensemble learning Is used. To do this, we use experimental data, real data on chronic patients (diabetes, heart, cancer) available on the UCI site. Results: We found that group algorithms designed to diagnose chronic diseases can be more effective than baseline algorithms. It also identifies several challenges to further advancing the classification of machine learning in the diagnosis of chronic diseases. Conclusion: The results show the high performance of the neural network-based Ensemble learning approach for the diagnosis and prediction of chronic diseases, which in this study reached 98.5, 99, and 100% accuracy, respectively.

</p>
</details>

<details><summary><b>Feature selection for medical diagnosis: Evaluation for using a hybrid Stacked-Genetic approach in the diagnosis of heart disease</b>
<a href="https://arxiv.org/abs/2103.08175">arxiv:2103.08175</a>
&#x1F4C8; 2 <br>
<p>Jafar Abdollahi, Babak Nouri-Moghaddam</p></summary>
<p>

**Abstract:** Background and purpose: Heart disease has been one of the most important causes of death in the last 10 years, so the use of classification methods to diagnose and predict heart disease is very important. If this disease is predicted before menstruation, it is possible to prevent high mortality of the disease and provide more accurate and efficient treatment methods. Materials and Methods: Due to the selection of input features, the use of basic algorithms can be very time-consuming. Reducing dimensions or choosing a good subset of features, without risking accuracy, has great importance for basic algorithms for successful use in the region. In this paper, we propose an ensemble-genetic learning method using wrapper feature reduction to select features in disease classification. Findings: The development of a medical diagnosis system based on ensemble learning to predict heart disease provides a more accurate diagnosis than the traditional method and reduces the cost of treatment. Conclusion: The results showed that Thallium Scan and vascular occlusion were the most important features in the diagnosis of heart disease and can distinguish between sick and healthy people with 97.57% accuracy.

</p>
</details>

<details><summary><b>DMN4: Few-shot Learning via Discriminative Mutual Nearest Neighbor Neural Network</b>
<a href="https://arxiv.org/abs/2103.08160">arxiv:2103.08160</a>
&#x1F4C8; 2 <br>
<p>Yang Liu, Tu Zheng, Jie Song, Deng Cai, Xiaofei He</p></summary>
<p>

**Abstract:** Few-shot learning (FSL) aims to classify images under low-data regimes, where the conventional pooled global feature is likely to lose useful local characteristics. Recent work has achieved promising performances by using deep descriptors. They generally take all deep descriptors from neural networks into consideration while ignoring that some of them are useless in classification due to their limited receptive field, e.g., task-irrelevant descriptors could be misleading and multiple aggregative descriptors from background clutter could even overwhelm the object's presence. In this paper, we argue that a Mutual Nearest Neighbor (MNN) relation should be established to explicitly select the query descriptors that are most relevant to each task and discard less relevant ones from aggregative clutters in FSL. Specifically, we propose Discriminative Mutual Nearest Neighbor Neural Network (DMN4) for FSL. Extensive experiments demonstrate that our method outperforms the existing state-of-the-arts on both fine-grained and generalized datasets.

</p>
</details>

<details><summary><b>Cloth Manipulation Planning on Basis of Mesh Representations with Incomplete Domain Knowledge and Voxel-to-Mesh Estimation</b>
<a href="https://arxiv.org/abs/2103.08137">arxiv:2103.08137</a>
&#x1F4C8; 2 <br>
<p>Solvi Arnold, Daisuke Tanaka, Kimitoshi Yamazaki</p></summary>
<p>

**Abstract:** We consider the problem of open-goal planning for robotic cloth manipulation. Core of our system is a neural network trained as a forward model of cloth behaviour under manipulation, with planning performed through backpropagation. We introduce a neural network-based routine for estimating mesh representations from voxel input, and perform planning in mesh format internally. We address the problem of planning with incomplete domain knowledge by means of an explicit epistemic uncertainty signal. This signal is calculated from prediction divergence between two instances of the forward model network and used to avoid epistemic uncertainty during planning. Finally, we introduce logic for handling restriction of grasp points to a discrete set of candidates, in order to accommodate graspability constraints imposed by robotic hardware. We evaluate the system's mesh estimation, prediction, and planning ability on simulated cloth for sequences of one to three manipulations. Comparative experiments confirm that planning on basis of estimated meshes improves accuracy compared to voxel-based planning, and that epistemic uncertainty avoidance improves performance under conditions of incomplete domain knowledge. Planning time cost is a few seconds. We additionally present qualitative results on robot hardware.

</p>
</details>

<details><summary><b>Regenerativity of Viterbi process for pairwise Markov models</b>
<a href="https://arxiv.org/abs/2103.11821">arxiv:2103.11821</a>
&#x1F4C8; 1 <br>
<p>Jüri Lember, Joonas Sova</p></summary>
<p>

**Abstract:** For hidden Markov models one of the most popular estimates of the hidden chain is the Viterbi path -- the path maximising the posterior probability. We consider a more general setting, called the pairwise Markov model (PMM), where the joint process consisting of finite-state hidden process and observation process is assumed to be a Markov chain. It has been recently proven that under some conditions the Viterbi path of the PMM can almost surely be extended to infinity, thereby defining the infinite Viterbi decoding of the observation sequence, called the Viterbi process. This was done by constructing a block of observations, called a barrier, which ensures that the Viterbi path goes trough a given state whenever this block occurs in the observation sequence. In this paper we prove that the joint process consisting of Viterbi process and PMM is regenerative. The proof involves a delicate construction of regeneration times which coincide with the occurrences of barriers. As one possible application of our theory, some results on the asymptotics of the Viterbi training algorithm are derived.

</p>
</details>

<details><summary><b>Machine learning initialization to accelerate Stokes profile inversions</b>
<a href="https://arxiv.org/abs/2103.09651">arxiv:2103.09651</a>
&#x1F4C8; 1 <br>
<p>R. Gafeira, D. Orozco Suárez, I. Milic, C. Quintero Noda, B. Ruiz Cobo, H. Uitenbroek</p></summary>
<p>

**Abstract:** In this work, we discuss the application of convolutional neural networks (CNNs) as a tool to advantageously initialize Stokes profile inversions. To demonstrate the usefulness of CNNs, we concentrate in this paper on the inversion of LTE Stokes profiles. We use observations taken with the spectropolarimeter onboard the Hinode spacecraft as a test benchmark. First, we carefully analyze the data with the SIR inversion code using a given initial atmospheric model. The code provides a set of atmospheric models that reproduce the observations. These models are then used to train a CNN. Afterwards, the same data are again inverted with SIR but using the trained CNN to provide the initial guess atmospheric models for SIR. The CNNs allow us to significantly reduce the number of inversion cycles when used to compute initial guess model atmospheres, decreasing the computational time for LTE inversions by a factor of two to four. CNN's alone are much faster than assisted inversions, but the latter are more robust and accurate. The advantages and limitations of machine learning techniques for estimating optimum initial atmospheric models for spectral line inversions are discussed. Finally, we describe a python wrapper for the SIR and DeSIRe codes that allows for the easy setup of parallel inversions. The assisted inversions can speed up the inversion process, but the efficiency and accuracy of the inversion results depend strongly on the solar scene and the data used for the CNN training. This method (assisted inversions) will not obviate the need for analyzing individual events with the utmost care but will provide solar scientists with a much better opportunity to sample large amounts of inverted data, which will undoubtedly broaden the physical discovery space.

</p>
</details>

<details><summary><b>A Novel Paper Recommendation Method Empowered by Knowledge Graph: for Research Beginners</b>
<a href="https://arxiv.org/abs/2103.08819">arxiv:2103.08819</a>
&#x1F4C8; 1 <br>
<p>Bangchao Wang, Ziyang Weng, Yanping Wang</p></summary>
<p>

**Abstract:** Searching for papers from different academic databases is the most commonly used method by research beginners to obtain cross-domain technical solutions. However, it is usually inefficient and sometimes even useless because traditional search methods neither consider knowledge heterogeneity in different domains nor build the bottom layer of search, including but not limited to the characteristic description text of target solutions and solutions to be excluded. To alleviate this problem, a novel paper recommendation method is proposed herein by introducing "master-slave" domain knowledge graphs, which not only help users express their requirements more accurately but also helps the recommendation system better express knowledge. Specifically, it is not restricted by the cold start problem and is a challenge-oriented method. To identify the rationality and usefulness of the proposed method, we selected two cross-domains and three different academic databases for verification. The experimental results demonstrate the feasibility of obtaining new technical papers in the cross-domain scenario by research beginners using the proposed method. Further, a new research paradigm for research beginners in the early stages is proposed herein.

</p>
</details>

<details><summary><b>Parareal Neural Networks Emulating a Parallel-in-time Algorithm</b>
<a href="https://arxiv.org/abs/2103.08802">arxiv:2103.08802</a>
&#x1F4C8; 1 <br>
<p>Chang-Ock Lee, Youngkyu Lee, Jongho Park</p></summary>
<p>

**Abstract:** As deep neural networks (DNNs) become deeper, the training time increases. In this perspective, multi-GPU parallel computing has become a key tool in accelerating the training of DNNs. In this paper, we introduce a novel methodology to construct a parallel neural network that can utilize multiple GPUs simultaneously from a given DNN. We observe that layers of DNN can be interpreted as the time step of a time-dependent problem and can be parallelized by emulating a parallel-in-time algorithm called parareal. The parareal algorithm consists of fine structures which can be implemented in parallel and a coarse structure which gives suitable approximations to the fine structures. By emulating it, the layers of DNN are torn to form a parallel structure which is connected using a suitable coarse network. We report accelerated and accuracy-preserved results of the proposed methodology applied to VGG-16 and ResNet-1001 on several datasets.

</p>
</details>

<details><summary><b>Embedding Code Contexts for Cryptographic API Suggestion:New Methodologies and Comparisons</b>
<a href="https://arxiv.org/abs/2103.08747">arxiv:2103.08747</a>
&#x1F4C8; 1 <br>
<p>Ya Xiao, Salman Ahmed, Wenjia Song, Xinyang Ge, Bimal Viswanath, Danfeng Yao</p></summary>
<p>

**Abstract:** Despite recent research efforts, the vision of automatic code generation through API recommendation has not been realized. Accuracy and expressiveness challenges of API recommendation needs to be systematically addressed. We present a new neural network-based approach, Multi-HyLSTM for API recommendation --targeting cryptography-related code. Multi-HyLSTM leverages program analysis to guide the API embedding and recommendation. By analyzing the data dependence paths of API methods, we train embedding and specialize a multi-path neural network architecture for API recommendation tasks that accurately predict the next API method call. We address two previously unreported programming language-specific challenges, differentiating functionally similar APIs and capturing low-frequency long-range influences. Our results confirm the effectiveness of our design choices, including program-analysis-guided embedding, multi-path code suggestion architecture, and low-frequency long-range-enhanced sequence learning, with high accuracy on top-1 recommendations. We achieve a top-1 accuracy of 91.41% compared with 77.44% from the state-of-the-art tool SLANG. In an analysis of 245 test cases, compared with the commercial tool Codota, we achieve a top-1 recommendation accuracy of 88.98%, which is significantly better than Codota's accuracy of 64.90%. We publish our data and code as a large Java cryptographic code dataset.

</p>
</details>

<details><summary><b>Tomography of time-dependent quantum spin networks with machine learning</b>
<a href="https://arxiv.org/abs/2103.08645">arxiv:2103.08645</a>
&#x1F4C8; 1 <br>
<p>Chen-Di Han, Bryan Glaz, Mulugeta Haile, Ying-Cheng Lai</p></summary>
<p>

**Abstract:** Interacting spin networks are fundamental to quantum computing. Data-based tomography of time-independent spin networks has been achieved, but an open challenge is to ascertain the structures of time-dependent spin networks using time series measurements taken locally from a small subset of the spins. Physically, the dynamical evolution of a spin network under time-dependent driving or perturbation is described by the Heisenberg equation of motion. Motivated by this basic fact, we articulate a physics-enhanced machine learning framework whose core is Heisenberg neural networks. In particular, we develop a deep learning algorithm according to some physics motivated loss function based on the Heisenberg equation, which "forces" the neural network to follow the quantum evolution of the spin variables. We demonstrate that, from local measurements, not only the local Hamiltonian can be recovered but the Hamiltonian reflecting the interacting structure of the whole system can also be faithfully reconstructed. We test our Heisenberg neural machine on spin networks of a variety of structures. In the extreme case where measurements are taken from only one spin, the achieved tomography fidelity values can reach about 90%. The developed machine learning framework is applicable to any time-dependent systems whose quantum dynamical evolution is governed by the Heisenberg equation of motion.

</p>
</details>

<details><summary><b>DiaRet: A browser-based application for the grading of Diabetic Retinopathy with Integrated Gradients</b>
<a href="https://arxiv.org/abs/2103.08501">arxiv:2103.08501</a>
&#x1F4C8; 1 <br>
<p>Shaswat Patel, Maithili Lohakare, Samyak Prajapati, Shaanya Singh, Nancy Patel</p></summary>
<p>

**Abstract:** Patients with long-standing diabetes often fall prey to Diabetic Retinopathy (DR) resulting in changes in the retina of the human eye, which may lead to loss of vision in extreme cases. The aim of this study is two-fold: (a) create deep learning models that were trained to grade degraded retinal fundus images and (b) to create a browser-based application that will aid in diagnostic procedures by highlighting the key features of the fundus image. In this research work, we have emulated the images plagued by distortions by degrading the images based on multiple different combinations of Light Transmission Disturbance, Image Blurring and insertion of Retinal Artifacts. InceptionV3, ResNet-50 and InceptionResNetV2 were trained and used to classify retinal fundus images based on their severity level and then further used in the creation of a browser-based application, which implements the Integration Gradient (IG) Attribution Mask on the input image and demonstrates the predictions made by the model and the probability associated with each class.

</p>
</details>

<details><summary><b>Automatically Lock Your Neural Networks When You're Away</b>
<a href="https://arxiv.org/abs/2103.08472">arxiv:2103.08472</a>
&#x1F4C8; 1 <br>
<p>Ge Ren, Jun Wu, Gaolei Li, Shenghong Li</p></summary>
<p>

**Abstract:** The smartphone and laptop can be unlocked by face or fingerprint recognition, while neural networks which confront numerous requests every day have little capability to distinguish between untrustworthy and credible users. It makes model risky to be traded as a commodity. Existed research either focuses on the intellectual property rights ownership of the commercialized model, or traces the source of the leak after pirated models appear. Nevertheless, active identifying users legitimacy before predicting output has not been considered yet. In this paper, we propose Model-Lock (M-LOCK) to realize an end-to-end neural network with local dynamic access control, which is similar to the automatic locking function of the smartphone to prevent malicious attackers from obtaining available performance actively when you are away. Three kinds of model training strategy are essential to achieve the tremendous performance divergence between certified and suspect input in one neural network. Extensive experiments based on MNIST, FashionMNIST, CIFAR10, CIFAR100, SVHN and GTSRB datasets demonstrated the feasibility and effectiveness of the proposed scheme.

</p>
</details>

<details><summary><b>A machine learning approach to itinerary-level booking prediction in competitive airline markets</b>
<a href="https://arxiv.org/abs/2103.08405">arxiv:2103.08405</a>
&#x1F4C8; 1 <br>
<p>Daniel Hopman, Ger Koole, Rob van der Mei</p></summary>
<p>

**Abstract:** Demand forecasting is extremely important in revenue management. After all, it is one of the inputs to an optimisation method which aim is to maximize revenue. Most, if not all, forecasting methods use historical data to forecast the future, disregarding the "why". In this paper, we combine data from multiple sources, including competitor data, pricing, social media, safety and airline reviews. Next, we study five competitor pricing movements that, we hypothesize, affect customer behavior when presented a set of itineraries. Using real airline data for ten different OD-pairs and by means of Extreme Gradient Boosting, we show that customer behavior can be categorized into price-sensitive, schedule-sensitive and comfort ODs. Through a simulation study, we show that this model produces forecasts that result in higher revenue than traditional, time series forecasts.

</p>
</details>

<details><summary><b>Assessment of image generation by quantum annealer</b>
<a href="https://arxiv.org/abs/2103.08373">arxiv:2103.08373</a>
&#x1F4C8; 1 <br>
<p>Takehito Sato, Masayuki Ohzeki, Kazuyuki Tanaka</p></summary>
<p>

**Abstract:** Quantum annealing was originally proposed as an approach for solving combinatorial optimisation problems using quantum effects. D-Wave Systems has released a production model of quantum annealing hardware. However, the inherent noise and various environmental factors in the hardware hamper the determination of optimal solutions. In addition, the freezing effect in regions with weak quantum fluctuations generates outputs approximately following a Gibbs--Boltzmann distribution at an extremely low temperature. Thus, a quantum annealer may also serve as a fast sampler for the Ising spin-glass problem, and several studies have investigated Boltzmann machine learning using a quantum annealer. Previous developments have focused on comparing the performance in the standard distance of the resulting distributions between conventional methods in classical computers and sampling by a quantum annealer. In this study, we focused on the performance of a quantum annealer as a generative model. To evaluate its performance, we prepared a discriminator given by a neural network trained on an a priori dataset. The evaluation results show a higher performance of quantum annealing compared with the classical approach for Boltzmann machine learning.

</p>
</details>

<details><summary><b>I-Nema: A Biological Image Dataset for Nematode Recognition</b>
<a href="https://arxiv.org/abs/2103.08335">arxiv:2103.08335</a>
&#x1F4C8; 1 <br>
<p>Xuequan Lu, Yihao Wang, Sheldon Fung, Xue Qing</p></summary>
<p>

**Abstract:** Nematode worms are one of most abundant metazoan groups on the earth, occupying diverse ecological niches. Accurate recognition or identification of nematodes are of great importance for pest control, soil ecology, bio-geography, habitat conservation and against climate changes. Computer vision and image processing have witnessed a few successes in species recognition of nematodes; however, it is still in great demand. In this paper, we identify two main bottlenecks: (1) the lack of a publicly available imaging dataset for diverse species of nematodes (especially the species only found in natural environment) which requires considerable human resources in field work and experts in taxonomy, and (2) the lack of a standard benchmark of state-of-the-art deep learning techniques on this dataset which demands the discipline background in computer science. With these in mind, we propose an image dataset consisting of diverse nematodes (both laboratory cultured and naturally isolated), which, to our knowledge, is the first time in the community. We further set up a species recognition benchmark by employing state-of-the-art deep learning networks on this dataset. We discuss the experimental results, compare the recognition accuracy of different networks, and show the challenges of our dataset. We make our dataset publicly available at: https://github.com/xuequanlu/I-Nema

</p>
</details>

<details><summary><b>Function approximation by deep neural networks with parameters $\{0,\pm \frac{1}{2}, \pm 1, 2\}$</b>
<a href="https://arxiv.org/abs/2103.08659">arxiv:2103.08659</a>
&#x1F4C8; 0 <br>
<p>Aleksandr Beknazaryan</p></summary>
<p>

**Abstract:** In this paper it is shown that $C_β$-smooth functions can be approximated by deep neural networks with ReLU activation function and with parameters $\{0,\pm \frac{1}{2}, \pm 1, 2\}$. The $l_0$ and $l_1$ parameter norms of considered networks are thus equivalent. The depth, width and the number of active parameters of the constructed networks have, up to a logarithmic factor, the same dependence on the approximation error as the networks with parameters in $[-1,1]$. In particular, this means that the nonparametric regression estimation with the constructed networks attains the same convergence rate as with sparse networks with parameters in $[-1,1]$.

</p>
</details>

<details><summary><b>iWarded: A System for Benchmarking Datalog+/- Reasoning (technical report)</b>
<a href="https://arxiv.org/abs/2103.08588">arxiv:2103.08588</a>
&#x1F4C8; 0 <br>
<p>Teodoro Baldazzi, Luigi Bellomarini, Emanuel Sallinger, Paolo Atzeni</p></summary>
<p>

**Abstract:** Recent years have seen increasing popularity of logic-based reasoning systems, with research and industrial interest as well as many flourishing applications in the area of Knowledge Graphs. Despite that, one can observe a substantial lack of specific tools able to generate nontrivial reasoning settings and benchmark scenarios. As a consequence, evaluating, analysing and comparing reasoning systems is a complex task, especially when they embody sophisticated optimizations and execution techniques that leverage the theoretical underpinnings of the adopted logic fragment. In this paper, we aim at filling this gap by introducing iWarded, a system that can generate very large, complex, realistic reasoning settings to be used for the benchmarking of logic-based reasoning systems adopting Datalog+/-, a family of extensions of Datalog that has seen a resurgence in the last few years. In particular, iWarded generates reasoning settings for Warded Datalog+/-, a language with a very good tradeoff between computational complexity and expressive power. In the paper, we present the iWarded system and a set of novel theoretical results adopted to generate effective scenarios. As Datalog-based languages are of general interest and see increasing adoption, we believe that iWarded is a step forward in the empirical evaluation of current and future systems.

</p>
</details>

<details><summary><b>Stack of discriminative autoencoders for multiclass anomaly detection in endoscopy images</b>
<a href="https://arxiv.org/abs/2103.08508">arxiv:2103.08508</a>
&#x1F4C8; 0 <br>
<p>Mohammad Reza Mohebbian, Khan A. Wahid, Paul Babyn</p></summary>
<p>

**Abstract:** Wireless Capsule Endoscopy (WCE) helps physicians examine the gastrointestinal (GI) tract noninvasively. There are few studies that address pathological assessment of endoscopy images in multiclass classification and most of them are based on binary anomaly detection or aim to detect a specific type of anomaly. Multiclass anomaly detection is challenging, especially when the dataset is poorly sampled or imbalanced. Many available datasets in endoscopy field, such as KID2, suffer from an imbalance issue, which makes it difficult to train a high-performance model. Additionally, increasing the number of classes makes classification more difficult. We proposed a multiclass classification algorithm that is extensible to any number of classes and can handle an imbalance issue. The proposed method uses multiple autoencoders where each one is trained on one class to extract features with the most discrimination from other classes. The loss function of autoencoders is set based on reconstruction, compactness, distance from other classes, and Kullback-Leibler (KL) divergence. The extracted features are clustered and then classified using an ensemble of support vector data descriptors. A total of 1,778 normal, 227 inflammation, 303 vascular, and 44 polyp images from the KID2 dataset are used for evaluation. The entire algorithm ran 5 times and achieved F1-score of 96.3 +- 0.2% and 85.0 +- 0.4% on the test set for binary and multiclass anomaly detection, respectively. The impact of each step of the algorithm was investigated by various ablation studies and the results were compared with published works. The suggested approach is a competitive option for detecting multiclass anomalies in the GI field.

</p>
</details>

<details><summary><b>Distance Metric-Based Learning with Interpolated Latent Features for Location Classification in Endoscopy Image and Video</b>
<a href="https://arxiv.org/abs/2103.08504">arxiv:2103.08504</a>
&#x1F4C8; 0 <br>
<p>Mohammad Reza Mohebbian, Khan A. Wahid, Anh Dinh, Paul Babyn</p></summary>
<p>

**Abstract:** Conventional Endoscopy (CE) and Wireless Capsule Endoscopy (WCE) are known tools for diagnosing gastrointestinal (GI) tract disorders. Detecting the anatomical location of GI tract can help clinicians to determine a more appropriate treatment plan, can reduce repetitive endoscopy and is important in drug-delivery. There are few research that address detecting anatomical location of WCE and CE images using classification, mainly because of difficulty in collecting data and anotating them. In this study, we present a few-shot learning method based on distance metric learning which combines transfer-learning and manifold mixup scheme for localizing endoscopy frames and can be trained on few samples. The manifold mixup process improves few-shot learning by increasing the number of training epochs while reducing overfitting, as well as providing more accurate decision boundaries. A dataset is collected from 10 different anatomical positions of human GI tract. Two models were trained using only 78 CE and 27 WCE annotated frames to predict the location of 25700 and 1825 video frames from CE and WCE, respectively. In addition, we performed subjective evaluation using nine gastroenterologists to show the necessaity of having an AI system for localization. Various ablation studies and interpretations are performed to show the importance of each step, such effect of transfer-learning approach, and impact of manifold mixup on performance. The proposed method is also compared with various methods trained on categorical cross-entropy loss and produced better results which show that proposed method has potential to be used for endoscopy image classification.

</p>
</details>

<details><summary><b>Quantum federated learning through blind quantum computing</b>
<a href="https://arxiv.org/abs/2103.08403">arxiv:2103.08403</a>
&#x1F4C8; 0 <br>
<p>Weikang Li, Sirui Lu, Dong-Ling Deng</p></summary>
<p>

**Abstract:** Private distributed learning studies the problem of how multiple distributed entities collaboratively train a shared deep network with their private data unrevealed. With the security provided by the protocols of blind quantum computation, the cooperation between quantum physics and machine learning may lead to unparalleled prospect for solving private distributed learning tasks. In this paper, we introduce a quantum protocol for distributed learning that is able to utilize the computational power of the remote quantum servers while keeping the private data safe. For concreteness, we first introduce a protocol for private single-party delegated training of variational quantum classifiers based on blind quantum computing and then extend this protocol to multiparty private distributed learning incorporated with differential privacy. We carry out extensive numerical simulations with different real-life datasets and encoding strategies to benchmark the effectiveness of our protocol. We find that our protocol is robust to experimental imperfections and is secure under the gradient attack after the incorporation of differential privacy. Our results show the potential for handling computationally expensive distributed learning tasks with privacy guarantees, thus providing a valuable guide for exploring quantum advantages from the security perspective in the field of machine learning with real-life applications.

</p>
</details>

<details><summary><b>Hierarchical forecasting with a top-down alignment of independent level forecasts</b>
<a href="https://arxiv.org/abs/2103.08250">arxiv:2103.08250</a>
&#x1F4C8; 0 <br>
<p>Matthias Anderer, Feng Li</p></summary>
<p>

**Abstract:** Hierarchical forecasting with intermittent time series is a challenge in both research and empirical studies. Vast research focuses on improving the accuracy of each hierarchy, especially the intermittent time series at bottom levels. It then reconciles forecasts at each hierarchy to further improve the overall performance. In this paper, we present a forecasting with hierarchical alignment approach that treats the bottom level forecasts as mutable to ensure higher forecasting accuracy on the upper levels of the hierarchy. We employ a pure deep learning forecasting approach N-BEATS for continuous time series on top levels and a widely used tree-based algorithm LightGBM for the bottom level intermittent time series. The hierarchical forecasting with alignment approach is a simple yet effective variant of the bottom-up method, which accounts for biases that are difficult to observe at the bottom level. It allows suboptimal forecasts at the lower level to retain a higher overall performance. The approach in this empirical study was developed by the first author during the M5 Forecasting Accuracy competition, ranking the second place. The approach is also business orientated and could be beneficial for business strategic planning.

</p>
</details>


[Next Page](2021/2021-03/2021-03-14.md)
