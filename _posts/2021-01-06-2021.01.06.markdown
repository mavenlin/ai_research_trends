Prev: [2021.01.05]({{ '/2021/01/05/2021.01.05.html' | relative_url }})  Next: [2021.01.07]({{ '/2021/01/07/2021.01.07.html' | relative_url }})
{% raw %}
## Summary for 2021-01-06, created on 2021-12-24


<details><summary><b>User Ex Machina : Simulation as a Design Probe in Human-in-the-Loop Text Analytics</b>
<a href="https://arxiv.org/abs/2101.02244">arxiv:2101.02244</a>
&#x1F4C8; 90 <br>
<p>Anamaria Crisan, Michael Correll</p></summary>
<p>

**Abstract:** Topic models are widely used analysis techniques for clustering documents and surfacing thematic elements of text corpora. These models remain challenging to optimize and often require a "human-in-the-loop" approach where domain experts use their knowledge to steer and adjust. However, the fragility, incompleteness, and opacity of these models means even minor changes could induce large and potentially undesirable changes in resulting model. In this paper we conduct a simulation-based analysis of human-centered interactions with topic models, with the objective of measuring the sensitivity of topic models to common classes of user actions. We find that user interactions have impacts that differ in magnitude but often negatively affect the quality of the resulting modelling in a way that can be difficult for the user to evaluate. We suggest the incorporation of sensitivity and "multiverse" analyses to topic model interfaces to surface and overcome these deficiencies.

</p>
</details>

<details><summary><b>Adversarial Robustness by Design through Analog Computing and Synthetic Gradients</b>
<a href="https://arxiv.org/abs/2101.02115">arxiv:2101.02115</a>
&#x1F4C8; 59 <br>
<p>Alessandro Cappelli, Ruben Ohana, Julien Launay, Laurent Meunier, Iacopo Poli, Florent Krzakala</p></summary>
<p>

**Abstract:** We propose a new defense mechanism against adversarial attacks inspired by an optical co-processor, providing robustness without compromising natural accuracy in both white-box and black-box settings. This hardware co-processor performs a nonlinear fixed random transformation, where the parameters are unknown and impossible to retrieve with sufficient precision for large enough dimensions. In the white-box setting, our defense works by obfuscating the parameters of the random projection. Unlike other defenses relying on obfuscated gradients, we find we are unable to build a reliable backward differentiable approximation for obfuscated parameters. Moreover, while our model reaches a good natural accuracy with a hybrid backpropagation - synthetic gradient method, the same approach is suboptimal if employed to generate adversarial examples. We find the combination of a random projection and binarization in the optical system also improves robustness against various types of black-box attacks. Finally, our hybrid training method builds robust features against transfer attacks. We demonstrate our approach on a VGG-like architecture, placing the defense on top of the convolutional features, on CIFAR-10 and CIFAR-100. Code is available at https://github.com/lightonai/adversarial-robustness-by-design.

</p>
</details>

<details><summary><b>The Interplay of Demographic Variables and Social Distancing Scores in Deep Prediction of U.S. COVID-19 Cases</b>
<a href="https://arxiv.org/abs/2101.02113">arxiv:2101.02113</a>
&#x1F4C8; 47 <br>
<p>Francesca Tang, Yang Feng, Hamza Chiheb, Jianqing Fan</p></summary>
<p>

**Abstract:** With the severity of the COVID-19 outbreak, we characterize the nature of the growth trajectories of counties in the United States using a novel combination of spectral clustering and the correlation matrix. As the U.S. and the rest of the world are experiencing a severe second wave of infections, the importance of assigning growth membership to counties and understanding the determinants of the growth are increasingly evident. Subsequently, we select the demographic features that are most statistically significant in distinguishing the communities. Lastly, we effectively predict the future growth of a given county with an LSTM using three social distancing scores. This comprehensive study captures the nature of counties' growth in cases at a very micro-level using growth communities, demographic factors, and social distancing performance to help government agencies utilize known information to make appropriate decisions regarding which potential counties to target resources and funding to.

</p>
</details>

<details><summary><b>Interspeech 2021 Deep Noise Suppression Challenge</b>
<a href="https://arxiv.org/abs/2101.01902">arxiv:2101.01902</a>
&#x1F4C8; 47 <br>
<p>Chandan K A Reddy, Harishchandra Dubey, Kazuhito Koishida, Arun Nair, Vishak Gopal, Ross Cutler, Sebastian Braun, Hannes Gamper, Robert Aichner, Sriram Srinivasan</p></summary>
<p>

**Abstract:** The Deep Noise Suppression (DNS) challenge is designed to foster innovation in the area of noise suppression to achieve superior perceptual speech quality. We recently organized a DNS challenge special session at INTERSPEECH and ICASSP 2020. We open-sourced training and test datasets for the wideband scenario. We also open-sourced a subjective evaluation framework based on ITU-T standard P.808, which was also used to evaluate participants of the challenge. Many researchers from academia and industry made significant contributions to push the field forward, yet even the best noise suppressor was far from achieving superior speech quality in challenging scenarios. In this version of the challenge organized at INTERSPEECH 2021, we are expanding both our training and test datasets to accommodate full band scenarios. The two tracks in this challenge will focus on real-time denoising for (i) wide band, and(ii) full band scenarios. We are also making available a reliable non-intrusive objective speech quality metric called DNSMOS for the participants to use during their development phase.

</p>
</details>

<details><summary><b>Adaptive Synthetic Characters for Military Training</b>
<a href="https://arxiv.org/abs/2101.02185">arxiv:2101.02185</a>
&#x1F4C8; 45 <br>
<p>Volkan Ustun, Rajay Kumar, Adam Reilly, Seyed Sajjadi, Andrew Miller</p></summary>
<p>

**Abstract:** Behaviors of the synthetic characters in current military simulations are limited since they are generally generated by rule-based and reactive computational models with minimal intelligence. Such computational models cannot adapt to reflect the experience of the characters, resulting in brittle intelligence for even the most effective behavior models devised via costly and labor-intensive processes. Observation-based behavior model adaptation that leverages machine learning and the experience of synthetic entities in combination with appropriate prior knowledge can address the issues in the existing computational behavior models to create a better training experience in military training simulations. In this paper, we introduce a framework that aims to create autonomous synthetic characters that can perform coherent sequences of believable behavior while being aware of human trainees and their needs within a training simulation. This framework brings together three mutually complementary components. The first component is a Unity-based simulation environment - Rapid Integration and Development Environment (RIDE) - supporting One World Terrain (OWT) models and capable of running and supporting machine learning experiments. The second is Shiva, a novel multi-agent reinforcement and imitation learning framework that can interface with a variety of simulation environments, and that can additionally utilize a variety of learning algorithms. The final component is the Sigma Cognitive Architecture that will augment the behavior models with symbolic and probabilistic reasoning capabilities. We have successfully created proof-of-concept behavior models leveraging this framework on realistic terrain as an essential step towards bringing machine learning into military simulations.

</p>
</details>

<details><summary><b>Deep Reinforcement Learning with Quantum-inspired Experience Replay</b>
<a href="https://arxiv.org/abs/2101.02034">arxiv:2101.02034</a>
&#x1F4C8; 39 <br>
<p>Qing Wei, Hailan Ma, Chunlin Chen, Daoyi Dong</p></summary>
<p>

**Abstract:** In this paper, a novel training paradigm inspired by quantum computation is proposed for deep reinforcement learning (DRL) with experience replay. In contrast to traditional experience replay mechanism in DRL, the proposed deep reinforcement learning with quantum-inspired experience replay (DRL-QER) adaptively chooses experiences from the replay buffer according to the complexity and the replayed times of each experience (also called transition), to achieve a balance between exploration and exploitation. In DRL-QER, transitions are first formulated in quantum representations, and then the preparation operation and the depreciation operation are performed on the transitions. In this progress, the preparation operation reflects the relationship between the temporal difference errors (TD-errors) and the importance of the experiences, while the depreciation operation is taken into account to ensure the diversity of the transitions. The experimental results on Atari 2600 games show that DRL-QER outperforms state-of-the-art algorithms such as DRL-PER and DCRL on most of these games with improved training efficiency, and is also applicable to such memory-based DRL approaches as double network and dueling network.

</p>
</details>

<details><summary><b>Do We Really Need Deep Learning Models for Time Series Forecasting?</b>
<a href="https://arxiv.org/abs/2101.02118">arxiv:2101.02118</a>
&#x1F4C8; 37 <br>
<p>Shereen Elsayed, Daniela Thyssens, Ahmed Rashed, Hadi Samer Jomaa, Lars Schmidt-Thieme</p></summary>
<p>

**Abstract:** Time series forecasting is a crucial task in machine learning, as it has a wide range of applications including but not limited to forecasting electricity consumption, traffic, and air quality. Traditional forecasting models rely on rolling averages, vector auto-regression and auto-regressive integrated moving averages. On the other hand, deep learning and matrix factorization models have been recently proposed to tackle the same problem with more competitive performance. However, one major drawback of such models is that they tend to be overly complex in comparison to traditional techniques. In this paper, we report the results of prominent deep learning models with respect to a well-known machine learning baseline, a Gradient Boosting Regression Tree (GBRT) model. Similar to the deep neural network (DNN) models, we transform the time series forecasting task into a window-based regression problem. Furthermore, we feature-engineered the input and output structure of the GBRT model, such that, for each training window, the target values are concatenated with external features, and then flattened to form one input instance for a multi-output GBRT model. We conducted a comparative study on nine datasets for eight state-of-the-art deep-learning models that were presented at top-level conferences in the last years. The results demonstrate that the window-based input transformation boosts the performance of a simple GBRT model to levels that outperform all state-of-the-art DNN models evaluated in this paper.

</p>
</details>

<details><summary><b>Federated Learning over Noisy Channels: Convergence Analysis and Design Examples</b>
<a href="https://arxiv.org/abs/2101.02198">arxiv:2101.02198</a>
&#x1F4C8; 32 <br>
<p>Xizixiang Wei, Cong Shen</p></summary>
<p>

**Abstract:** Does Federated Learning (FL) work when both uplink and downlink communications have errors? How much communication noise can FL handle and what is its impact to the learning performance? This work is devoted to answering these practically important questions by explicitly incorporating both uplink and downlink noisy channels in the FL pipeline. We present several novel convergence analyses of FL over simultaneous uplink and downlink noisy communication channels, which encompass full and partial clients participation, direct model and model differential transmissions, and non-independent and identically distributed (IID) local datasets. These analyses characterize the sufficient conditions for FL over noisy channels to have the same convergence behavior as the ideal case of no communication error. More specifically, in order to maintain the O(1/T) convergence rate of FedAvg with perfect communications, the uplink and downlink signal-to-noise ratio (SNR) for direct model transmissions should be controlled such that they scale as O(t^2) where t is the index of communication rounds, but can stay constant for model differential transmissions. The key insight of these theoretical results is a "flying under the radar" principle - stochastic gradient descent (SGD) is an inherent noisy process and uplink/downlink communication noises can be tolerated as long as they do not dominate the time-varying SGD noise. We exemplify these theoretical findings with two widely adopted communication techniques - transmit power control and diversity combining - and further validating their performance advantages over the standard methods via extensive numerical experiments using several real-world FL tasks.

</p>
</details>

<details><summary><b>Comparing Classification Models on Kepler Data</b>
<a href="https://arxiv.org/abs/2101.01904">arxiv:2101.01904</a>
&#x1F4C8; 30 <br>
<p>Rohan Saha</p></summary>
<p>

**Abstract:** Even though the original Kepler mission ended due to mechanical failures, the Kepler satellite continues to collect data. Using classification models, we can understand the features exoplanets possess and then use those features to investigate further for any more information on the candidate planet. Based on the classification model, the idea is to find out the probability of the planet under observation being a candidate for an exoplanet or a false positive. If the model predicts that the observation is a candidate for being an exoplanet, then the further investigation can be conducted. From the model, we can narrow down the features that might explain the difference between a candidate and a false-positive which ultimately helps us to increase the efficiency of any model and fine-tune the model and ultimately the process of searching for any future exoplanets. The model comparison is supported by McNemar's test for checking significance.

</p>
</details>

<details><summary><b>End-2-End COVID-19 Detection from Breath & Cough Audio</b>
<a href="https://arxiv.org/abs/2102.08359">arxiv:2102.08359</a>
&#x1F4C8; 27 <br>
<p>Harry Coppock, Alexander Gaskell, Panagiotis Tzirakis, Alice Baird, Lyn Jones, Björn W. Schuller</p></summary>
<p>

**Abstract:** Our main contributions are as follows: (I) We demonstrate the first attempt to diagnose COVID-19 using end-to-end deep learning from a crowd-sourced dataset of audio samples, achieving ROC-AUC of 0.846; (II) Our model, the COVID-19 Identification ResNet, (CIdeR), has potential for rapid scalability, minimal cost and improving performance as more data becomes available. This could enable regular COVID-19 testing at apopulation scale; (III) We introduce a novel modelling strategy using a custom deep neural network to diagnose COVID-19 from a joint breath and cough representation; (IV) We release our four stratified folds for cross parameter optimisation and validation on a standard public corpus and details on the models for reproducibility and future reference.

</p>
</details>

<details><summary><b>The data synergy effects of time-series deep learning models in hydrology</b>
<a href="https://arxiv.org/abs/2101.01876">arxiv:2101.01876</a>
&#x1F4C8; 27 <br>
<p>Kuai Fang, Daniel Kifer, Kathryn Lawson, Dapeng Feng, Chaopeng Shen</p></summary>
<p>

**Abstract:** When fitting statistical models to variables in geoscientific disciplines such as hydrology, it is a customary practice to regionalize - to divide a large spatial domain into multiple regions and study each region separately - instead of fitting a single model on the entire data (also known as unification). Traditional wisdom in these fields suggests that models built for each region separately will have higher performance because of homogeneity within each region. However, by partitioning the training data, each model has access to fewer data points and cannot learn from commonalities between regions. Here, through two hydrologic examples (soil moisture and streamflow), we argue that unification can often significantly outperform regionalization in the era of big data and deep learning (DL). Common DL architectures, even without bespoke customization, can automatically build models that benefit from regional commonality while accurately learning region-specific differences. We highlight an effect we call data synergy, where the results of the DL models improved when data were pooled together from characteristically different regions. In fact, the performance of the DL models benefited from more diverse rather than more homogeneous training data. We hypothesize that DL models automatically adjust their internal representations to identify commonalities while also providing sufficient discriminatory information to the model. The results here advocate for pooling together larger datasets, and suggest the academic community should place greater emphasis on data sharing and compilation.

</p>
</details>

<details><summary><b>Deep Neural Network Based Relation Extraction: An Overview</b>
<a href="https://arxiv.org/abs/2101.01907">arxiv:2101.01907</a>
&#x1F4C8; 23 <br>
<p>Hailin Wang, Ke Qin, Rufai Yusuf Zakari, Guoming Lu, Jin Yin</p></summary>
<p>

**Abstract:** Knowledge is a formal way of understanding the world, providing a human-level cognition and intelligence for the next-generation artificial intelligence (AI). One of the representations of knowledge is semantic relations between entities. An effective way to automatically acquire this important knowledge, called Relation Extraction (RE), a sub-task of information extraction, plays a vital role in Natural Language Processing (NLP). Its purpose is to identify semantic relations between entities from natural language text. To date, there are several studies for RE in previous works, which have documented these techniques based on Deep Neural Networks (DNNs) become a prevailing technique in this research. Especially, the supervised and distant supervision methods based on DNNs are the most popular and reliable solutions for RE. This article 1) introduces some general concepts, and further 2) gives a comprehensive overview of DNNs in RE from two points of view: supervised RE, which attempts to improve the standard RE systems, and distant supervision RE, which adopts DNNs to design sentence encoder and de-noise method. We further 3) cover some novel methods and recent trends as well as discuss possible future research directions for this task.

</p>
</details>

<details><summary><b>Provably Efficient Reinforcement Learning with Linear Function Approximation Under Adaptivity Constraints</b>
<a href="https://arxiv.org/abs/2101.02195">arxiv:2101.02195</a>
&#x1F4C8; 19 <br>
<p>Tianhao Wang, Dongruo Zhou, Quanquan Gu</p></summary>
<p>

**Abstract:** We study reinforcement learning (RL) with linear function approximation under the adaptivity constraint. We consider two popular limited adaptivity models: batch learning model and rare policy switch model, and propose two efficient online RL algorithms for linear Markov decision processes. In specific, for the batch learning model, our proposed LSVI-UCB-Batch algorithm achieves an $\tilde O(\sqrt{d^3H^3T} + dHT/B)$ regret, where $d$ is the dimension of the feature mapping, $H$ is the episode length, $T$ is the number of interactions and $B$ is the number of batches. Our result suggests that it suffices to use only $\sqrt{T/dH}$ batches to obtain $\tilde O(\sqrt{d^3H^3T})$ regret. For the rare policy switch model, our proposed LSVI-UCB-RareSwitch algorithm enjoys an $\tilde O(\sqrt{d^3H^3T[1+T/(dH)]^{dH/B}})$ regret, which implies that $dH\log T$ policy switches suffice to obtain the $\tilde O(\sqrt{d^3H^3T})$ regret. Our algorithms achieve the same regret as the LSVI-UCB algorithm (Jin et al., 2019), yet with a substantially smaller amount of adaptivity.

</p>
</details>

<details><summary><b>Curriculum-Meta Learning for Order-Robust Continual Relation Extraction</b>
<a href="https://arxiv.org/abs/2101.01926">arxiv:2101.01926</a>
&#x1F4C8; 12 <br>
<p>Tongtong Wu, Xuekai Li, Yuan-Fang Li, Reza Haffari, Guilin Qi, Yujin Zhu, Guoqiang Xu</p></summary>
<p>

**Abstract:** Continual relation extraction is an important task that focuses on extracting new facts incrementally from unstructured text. Given the sequential arrival order of the relations, this task is prone to two serious challenges, namely catastrophic forgetting and order-sensitivity. We propose a novel curriculum-meta learning method to tackle the above two challenges in continual relation extraction. We combine meta learning and curriculum learning to quickly adapt model parameters to a new task and to reduce interference of previously seen tasks on the current task. We design a novel relation representation learning method through the distribution of domain and range types of relations. Such representations are utilized to quantify the difficulty of tasks for the construction of curricula. Moreover, we also present novel difficulty-based metrics to quantitatively measure the extent of order-sensitivity of a given model, suggesting new ways to evaluate model robustness. Our comprehensive experiments on three benchmark datasets show that our proposed method outperforms the state-of-the-art techniques. The code is available at the anonymous GitHub repository: https://github.com/wutong8023/AAAI_CML.

</p>
</details>

<details><summary><b>DeepPoison: Feature Transfer Based Stealthy Poisoning Attack</b>
<a href="https://arxiv.org/abs/2101.02562">arxiv:2101.02562</a>
&#x1F4C8; 10 <br>
<p>Jinyin Chen, Longyuan Zhang, Haibin Zheng, Xueke Wang, Zhaoyan Ming</p></summary>
<p>

**Abstract:** Deep neural networks are susceptible to poisoning attacks by purposely polluted training data with specific triggers. As existing episodes mainly focused on attack success rate with patch-based samples, defense algorithms can easily detect these poisoning samples. We propose DeepPoison, a novel adversarial network of one generator and two discriminators, to address this problem. Specifically, the generator automatically extracts the target class' hidden features and embeds them into benign training samples. One discriminator controls the ratio of the poisoning perturbation. The other discriminator works as the target model to testify the poisoning effects. The novelty of DeepPoison lies in that the generated poisoned training samples are indistinguishable from the benign ones by both defensive methods and manual visual inspection, and even benign test samples can achieve the attack. Extensive experiments have shown that DeepPoison can achieve a state-of-the-art attack success rate, as high as 91.74%, with only 7% poisoned samples on publicly available datasets LFW and CASIA. Furthermore, we have experimented with high-performance defense algorithms such as autodecoder defense and DBSCAN cluster detection and showed the resilience of DeepPoison.

</p>
</details>

<details><summary><b>Phishing Attacks and Websites Classification Using Machine Learning and Multiple Datasets (A Comparative Analysis)</b>
<a href="https://arxiv.org/abs/2101.02552">arxiv:2101.02552</a>
&#x1F4C8; 10 <br>
<p>Sohail Ahmed Khan, Wasiq Khan, Abir Hussain</p></summary>
<p>

**Abstract:** Phishing attacks are the most common type of cyber-attacks used to obtain sensitive information and have been affecting individuals as well as organisations across the globe. Various techniques have been proposed to identify the phishing attacks specifically, deployment of machine intelligence in recent years. However, the deployed algorithms and discriminating factors are very diverse in existing works. In this study, we present a comprehensive analysis of various machine learning algorithms to evaluate their performances over multiple datasets. We further investigate the most significant features within multiple datasets and compare the classification performance with the reduced dimensional datasets. The statistical results indicate that random forest and artificial neural network outperform other classification algorithms, achieving over 97% accuracy using the identified features.

</p>
</details>

<details><summary><b>User Response Prediction in Online Advertising</b>
<a href="https://arxiv.org/abs/2101.02342">arxiv:2101.02342</a>
&#x1F4C8; 10 <br>
<p>Zhabiz Gharibshah, Xingquan Zhu</p></summary>
<p>

**Abstract:** Online advertising, as the vast market, has gained significant attention in various platforms ranging from search engines, third-party websites, social media, and mobile apps. The prosperity of online campaigns is a challenge in online marketing and is usually evaluated by user response through different metrics, such as clicks on advertisement (ad) creatives, subscriptions to products, purchases of items, or explicit user feedback through online surveys. Recent years have witnessed a significant increase in the number of studies using computational approaches, including machine learning methods, for user response prediction. However, existing literature mainly focuses on algorithmic-driven designs to solve specific challenges, and no comprehensive review exists to answer many important questions. What are the parties involved in the online digital advertising eco-systems? What type of data are available for user response prediction? How to predict user response in a reliable and/or transparent way? In this survey, we provide a comprehensive review of user response prediction in online advertising and related recommender applications. Our essential goal is to provide a thorough understanding of online advertising platforms, stakeholders, data availability, and typical ways of user response prediction. We propose a taxonomy to categorize state-of-the-art user response prediction methods, primarily focus on the current progress of machine learning methods used in different online platforms. In addition, we also review applications of user response prediction, benchmark datasets, and open-source codes in the field.

</p>
</details>

<details><summary><b>Demand Forecasting for Platelet Usage: from Univariate Time Series to Multivariate Models</b>
<a href="https://arxiv.org/abs/2101.02305">arxiv:2101.02305</a>
&#x1F4C8; 10 <br>
<p>Maryam Motamedi, Na Li, Douglas G. Down, Nancy M. Heddle</p></summary>
<p>

**Abstract:** Platelet products are both expensive and have very short shelf lives. As usage rates for platelets are highly variable, the effective management of platelet demand and supply is very important yet challenging. The primary goal of this paper is to present an efficient forecasting model for platelet demand at Canadian Blood Services (CBS). To accomplish this goal, four different demand forecasting methods, ARIMA (Auto Regressive Moving Average), Prophet, lasso regression (least absolute shrinkage and selection operator) and LSTM (Long Short-Term Memory) networks are utilized and evaluated. We use a large clinical dataset for a centralized blood distribution centre for four hospitals in Hamilton, Ontario, spanning from 2010 to 2018 and consisting of daily platelet transfusions along with information such as the product specifications, the recipients' characteristics, and the recipients' laboratory test results. This study is the first to utilize different methods from statistical time series models to data-driven regression and a machine learning technique for platelet transfusion using clinical predictors and with different amounts of data. We find that the multivariate approaches have the highest accuracy in general, however, if sufficient data are available, a simpler time series approach such as ARIMA appears to be sufficient. We also comment on the approach to choose clinical indicators (inputs) for the multivariate models.

</p>
</details>

<details><summary><b>Cauchy-Schwarz Regularized Autoencoder</b>
<a href="https://arxiv.org/abs/2101.02149">arxiv:2101.02149</a>
&#x1F4C8; 10 <br>
<p>Linh Tran, Maja Pantic, Marc Peter Deisenroth</p></summary>
<p>

**Abstract:** Recent work in unsupervised learning has focused on efficient inference and learning in latent variables models. Training these models by maximizing the evidence (marginal likelihood) is typically intractable. Thus, a common approximation is to maximize the Evidence Lower BOund (ELBO) instead. Variational autoencoders (VAE) are a powerful and widely-used class of generative models that optimize the ELBO efficiently for large datasets. However, the VAE's default Gaussian choice for the prior imposes a strong constraint on its ability to represent the true posterior, thereby degrading overall performance. A Gaussian mixture model (GMM) would be a richer prior, but cannot be handled efficiently within the VAE framework because of the intractability of the Kullback-Leibler divergence for GMMs. We deviate from the common VAE framework in favor of one with an analytical solution for Gaussian mixture prior. To perform efficient inference for GMM priors, we introduce a new constrained objective based on the Cauchy-Schwarz divergence, which can be computed analytically for GMMs. This new objective allows us to incorporate richer, multi-modal priors into the autoencoding framework. We provide empirical studies on a range of datasets and show that our objective improves upon variational auto-encoding models in density estimation, unsupervised clustering, semi-supervised learning, and face analysis.

</p>
</details>

<details><summary><b>Model Extraction and Defenses on Generative Adversarial Networks</b>
<a href="https://arxiv.org/abs/2101.02069">arxiv:2101.02069</a>
&#x1F4C8; 10 <br>
<p>Hailong Hu, Jun Pang</p></summary>
<p>

**Abstract:** Model extraction attacks aim to duplicate a machine learning model through query access to a target model. Early studies mainly focus on discriminative models. Despite the success, model extraction attacks against generative models are less well explored. In this paper, we systematically study the feasibility of model extraction attacks against generative adversarial networks (GANs). Specifically, we first define accuracy and fidelity on model extraction attacks against GANs. Then we study model extraction attacks against GANs from the perspective of accuracy extraction and fidelity extraction, according to the adversary's goals and background knowledge. We further conduct a case study where an adversary can transfer knowledge of the extracted model which steals a state-of-the-art GAN trained with more than 3 million images to new domains to broaden the scope of applications of model extraction attacks. Finally, we propose effective defense techniques to safeguard GANs, considering a trade-off between the utility and security of GAN models.

</p>
</details>

<details><summary><b>RANK: AI-assisted End-to-End Architecture for Detecting Persistent Attacks in Enterprise Networks</b>
<a href="https://arxiv.org/abs/2101.02573">arxiv:2101.02573</a>
&#x1F4C8; 9 <br>
<p>Hazem M. Soliman, Geoff Salmon, Dušan Sovilj, Mohan Rao</p></summary>
<p>

**Abstract:** Advanced Persistent Threats (APTs) are sophisticated multi-step attacks, planned and executed by skilled adversaries targeting modern government and enterprise networks. Intrusion Detection Systems (IDSs) and User and Entity Behavior Analytics (UEBA) are commonly employed to aid a security analyst in the detection of APTs. The prolonged nature of APTs, combined with the granular focus of UEBA and IDS, results in overwhelming the analyst with an increasingly impractical number of alerts. Consequent to this abundance of data, and together with the crucial importance of the problem as well as the high cost of the skilled personnel involved, the problem of APT detection becomes a perfect candidate for automation through Artificial Intelligence (AI). In this paper, we provide, up to our knowledge, the first study and implementation of an end-to-end AI-assisted architecture for detecting APTs -- RANK. The goal of the system is not to replace the analyst, rather, it is to automate the complete pipeline from data sources to a final set of incidents for analyst review. The architecture is composed of four consecutive steps: 1) alert templating and merging, 2) alert graph construction, 3) alert graph partitioning into incidents, and 4) incident scoring and ordering. We evaluate our architecture against the 2000 DARPA Intrusion Detection dataset, as well as a read-world private dataset from a medium-scale enterprise. Extensive results are provided showing a three order of magnitude reduction in the amount of data to be reviewed by the analyst, innovative extraction of incidents and security-wise scoring of extracted incidents.

</p>
</details>

<details><summary><b>Exploring Text-transformers in AAAI 2021 Shared Task: COVID-19 Fake News Detection in English</b>
<a href="https://arxiv.org/abs/2101.02359">arxiv:2101.02359</a>
&#x1F4C8; 9 <br>
<p>Xiangyang Li, Yu Xia, Xiang Long, Zheng Li, Sujian Li</p></summary>
<p>

**Abstract:** In this paper, we describe our system for the AAAI 2021 shared task of COVID-19 Fake News Detection in English, where we achieved the 3rd position with the weighted F1 score of 0.9859 on the test set. Specifically, we proposed an ensemble method of different pre-trained language models such as BERT, Roberta, Ernie, etc. with various training strategies including warm-up,learning rate schedule and k-fold cross-validation. We also conduct an extensive analysis of the samples that are not correctly classified. The code is available at:https://github.com/archersama/3rd-solution-COVID19-Fake-News-Detection-in-English.

</p>
</details>

<details><summary><b>Low-cost and high-performance data augmentation for deep-learning-based skin lesion classification</b>
<a href="https://arxiv.org/abs/2101.02353">arxiv:2101.02353</a>
&#x1F4C8; 9 <br>
<p>Shuwei Shen, Mengjuan Xu, Fan Zhang, Pengfei Shao, Honghong Liu, Liang Xu, Chi Zhang, Peng Liu, Zhihong Zhang, Peng Yao, Ronald X. Xu</p></summary>
<p>

**Abstract:** Although deep convolutional neural networks (DCNNs) have achieved significant accuracy in skin lesion classification comparable or even superior to those of dermatologists, practical implementation of these models for skin cancer screening in low resource settings is hindered by their limitations in computational cost and training dataset. To overcome these limitations, we propose a low-cost and high-performance data augmentation strategy that includes two consecutive stages of augmentation search and network search. At the augmentation search stage, the augmentation strategy is optimized in the search space of Low-Cost-Augment (LCA) under the criteria of balanced accuracy (BACC) with 5-fold cross validation. At the network search stage, the DCNNs are fine-tuned with the full training set in order to select the model with the highest BACC. The efficiency of the proposed data augmentation strategy is verified on the HAM10000 dataset using EfficientNets as a baseline. With the proposed strategy, we are able to reduce the search space to 60 and achieve a high BACC of 0.853 by using a single DCNN model without external database, suitable to be implemented in mobile devices for DCNN-based skin lesion detection in low resource settings.

</p>
</details>

<details><summary><b>Single Shot Multitask Pedestrian Detection and Behavior Prediction</b>
<a href="https://arxiv.org/abs/2101.02232">arxiv:2101.02232</a>
&#x1F4C8; 9 <br>
<p>Prateek Agrawal, Pratik Prabhanjan Brahma</p></summary>
<p>

**Abstract:** Detecting and predicting the behavior of pedestrians is extremely crucial for self-driving vehicles to plan and interact with them safely. Although there have been several research works in this area, it is important to have fast and memory efficient models such that it can operate in embedded hardware in these autonomous machines. In this work, we propose a novel architecture using spatial-temporal multi-tasking to do camera based pedestrian detection and intention prediction. Our approach significantly reduces the latency by being able to detect and predict all pedestrians' intention in a single shot manner while also being able to attain better accuracy by sharing features with relevant object level information and interactions.

</p>
</details>

<details><summary><b>The Shapley Value of Classifiers in Ensemble Games</b>
<a href="https://arxiv.org/abs/2101.02153">arxiv:2101.02153</a>
&#x1F4C8; 9 <br>
<p>Benedek Rozemberczki, Rik Sarkar</p></summary>
<p>

**Abstract:** What is the value of an individual model in an ensemble of binary classifiers? We answer this question by introducing a class of transferable utility cooperative games called \textit{ensemble games}. In machine learning ensembles, pre-trained models cooperate to make classification decisions. To quantify the importance of models in these ensemble games, we define \textit{Troupe} -- an efficient algorithm which allocates payoffs based on approximate Shapley values of the classifiers. We argue that the Shapley value of models in these games is an effective decision metric for choosing a high performing subset of models from the ensemble. Our analytical findings prove that our Shapley value estimation scheme is precise and scalable; its performance increases with size of the dataset and ensemble. Empirical results on real world graph classification tasks demonstrate that our algorithm produces high quality estimates of the Shapley value. We find that Shapley values can be utilized for ensemble pruning, and that adversarial models receive a low valuation. Complex classifiers are frequently found to be responsible for both correct and incorrect classification decisions.

</p>
</details>

<details><summary><b>Connecting ansatz expressibility to gradient magnitudes and barren plateaus</b>
<a href="https://arxiv.org/abs/2101.02138">arxiv:2101.02138</a>
&#x1F4C8; 9 <br>
<p>Zoë Holmes, Kunal Sharma, M. Cerezo, Patrick J. Coles</p></summary>
<p>

**Abstract:** Parameterized quantum circuits serve as ansätze for solving variational problems and provide a flexible paradigm for programming near-term quantum computers. Ideally, such ansätze should be highly expressive so that a close approximation of the desired solution can be accessed. On the other hand, the ansatz must also have sufficiently large gradients to allow for training. Here, we derive a fundamental relationship between these two essential properties: expressibility and trainability. This is done by extending the well established barren plateau phenomenon, which holds for ansätze that form exact 2-designs, to arbitrary ansätze. Specifically, we calculate the variance in the cost gradient in terms of the expressibility of the ansatz, as measured by its distance from being a 2-design. Our resulting bounds indicate that highly expressive ansätze exhibit flatter cost landscapes and therefore will be harder to train. Furthermore, we provide numerics illustrating the effect of expressiblity on gradient scalings, and we discuss the implications for designing strategies to avoid barren plateaus.

</p>
</details>

<details><summary><b>A unified view for unsupervised representation learning with density ratio estimation: Maximization of mutual information, nonlinear ICA and nonlinear subspace estimation</b>
<a href="https://arxiv.org/abs/2101.02083">arxiv:2101.02083</a>
&#x1F4C8; 9 <br>
<p>Hiroaki Sasaki, Takashi Takenouchi</p></summary>
<p>

**Abstract:** Unsupervised representation learning is one of the most important problems in machine learning. Recent promising methods are based on contrastive learning. However, contrastive learning often relies on heuristic ideas, and therefore it is not easy to understand what contrastive learning is doing. This paper emphasizes that density ratio estimation is a promising goal for unsupervised representation learning, and promotes understanding to contrastive learning. Our primal contribution is to theoretically show that density ratio estimation unifies three frameworks for unsupervised representation learning: Maximization of mutual information (MI), nonlinear independent component analysis (ICA) and a novel framework for estimation of a lower-dimensional nonlinear subspace proposed in this paper. This unified view clarifies under what conditions contrastive learning can be regarded as maximizing MI, performing nonlinear ICA or estimating the lower-dimensional nonlinear subspace in the proposed framework. Furthermore, we also make theoretical contributions in each of the three frameworks: We show that MI can be maximized through density ratio estimation under certain conditions, while our analysis for nonlinear ICA reveals a novel insight for recovery of the latent source components, which is clearly supported by numerical experiments. In addition, some theoretical conditions are also established to estimate a nonlinear subspace in the proposed framework. Based on the unified view, we propose two practical methods for unsupervised representation learning through density ratio estimation: The first method is an outlier-robust method for representation learning, while the second one is a sample-efficient nonlinear ICA method. Finally, we numerically demonstrate usefulness of the proposed methods in nonlinear ICA and through application to a downstream task for classification.

</p>
</details>

<details><summary><b>Exploring Semi-Supervised Learning for Predicting Listener Backchannels</b>
<a href="https://arxiv.org/abs/2101.01899">arxiv:2101.01899</a>
&#x1F4C8; 9 <br>
<p>Vidit Jain, Maitree Leekha, Rajiv Ratn Shah, Jainendra Shukla</p></summary>
<p>

**Abstract:** Developing human-like conversational agents is a prime area in HCI research and subsumes many tasks. Predicting listener backchannels is one such actively-researched task. While many studies have used different approaches for backchannel prediction, they all have depended on manual annotations for a large dataset. This is a bottleneck impacting the scalability of development. To this end, we propose using semi-supervised techniques to automate the process of identifying backchannels, thereby easing the annotation process. To analyze our identification module's feasibility, we compared the backchannel prediction models trained on (a) manually-annotated and (b) semi-supervised labels. Quantitative analysis revealed that the proposed semi-supervised approach could attain 95% of the former's performance. Our user-study findings revealed that almost 60% of the participants found the backchannel responses predicted by the proposed model more natural. Finally, we also analyzed the impact of personality on the type of backchannel signals and validated our findings in the user-study.

</p>
</details>

<details><summary><b>Learning Temporal Dynamics from Cycles in Narrated Video</b>
<a href="https://arxiv.org/abs/2101.02337">arxiv:2101.02337</a>
&#x1F4C8; 8 <br>
<p>Dave Epstein, Jiajun Wu, Cordelia Schmid, Chen Sun</p></summary>
<p>

**Abstract:** Learning to model how the world changes as time elapses has proven a challenging problem for the computer vision community. We propose a self-supervised solution to this problem using temporal cycle consistency jointly in vision and language, training on narrated video. Our model learns modality-agnostic functions to predict forward and backward in time, which must undo each other when composed. This constraint leads to the discovery of high-level transitions between moments in time, since such transitions are easily inverted and shared across modalities. We justify the design of our model with an ablation study on different configurations of the cycle consistency problem. We then show qualitatively and quantitatively that our approach yields a meaningful, high-level model of the future and past. We apply the learned dynamics model without further training to various tasks, such as predicting future action and temporally ordering sets of images. Project page: https://dave.ml/mmcc

</p>
</details>

<details><summary><b>Fairness with Continuous Optimal Transport</b>
<a href="https://arxiv.org/abs/2101.02084">arxiv:2101.02084</a>
&#x1F4C8; 8 <br>
<p>Silvia Chiappa, Aldo Pacchiano</p></summary>
<p>

**Abstract:** Whilst optimal transport (OT) is increasingly being recognized as a powerful and flexible approach for dealing with fairness issues, current OT fairness methods are confined to the use of discrete OT. In this paper, we leverage recent advances from the OT literature to introduce a stochastic-gradient fairness method based on a dual formulation of continuous OT. We show that this method gives superior performance to discrete OT methods when little data is available to solve the OT problem, and similar performance otherwise. We also show that both continuous and discrete OT methods are able to continually adjust the model parameters to adapt to different levels of unfairness that might occur in real-world applications of ML systems.

</p>
</details>

<details><summary><b>Predicting Forest Fire Using Remote Sensing Data And Machine Learning</b>
<a href="https://arxiv.org/abs/2101.01975">arxiv:2101.01975</a>
&#x1F4C8; 8 <br>
<p>Suwei Yang, Massimo Lupascu, Kuldeep S. Meel</p></summary>
<p>

**Abstract:** Over the last few decades, deforestation and climate change have caused increasing number of forest fires. In Southeast Asia, Indonesia has been the most affected country by tropical peatland forest fires. These fires have a significant impact on the climate resulting in extensive health, social and economic issues. Existing forest fire prediction systems, such as the Canadian Forest Fire Danger Rating System, are based on handcrafted features and require installation and maintenance of expensive instruments on the ground, which can be a challenge for developing countries such as Indonesia. We propose a novel, cost-effective, machine-learning based approach that uses remote sensing data to predict forest fires in Indonesia. Our prediction model achieves more than 0.81 area under the receiver operator characteristic (ROC) curve, performing significantly better than the baseline approach which never exceeds 0.70 area under ROC curve on the same tasks. Our model's performance remained above 0.81 area under ROC curve even when evaluated with reduced data. The results support our claim that machine-learning based approaches can lead to reliable and cost-effective forest fire prediction systems.

</p>
</details>

<details><summary><b>Cross-Validation and Uncertainty Determination for Randomized Neural Networks with Applications to Mobile Sensors</b>
<a href="https://arxiv.org/abs/2101.01990">arxiv:2101.01990</a>
&#x1F4C8; 7 <br>
<p>Ansgar Steland, Bart E. Pieters</p></summary>
<p>

**Abstract:** Randomized artificial neural networks such as extreme learning machines provide an attractive and efficient method for supervised learning under limited computing ressources and green machine learning. This especially applies when equipping mobile devices (sensors) with weak artificial intelligence. Results are discussed about supervised learning with such networks and regression methods in terms of consistency and bounds for the generalization and prediction error. Especially, some recent results are reviewed addressing learning with data sampled by moving sensors leading to non-stationary and dependent samples.
  As randomized networks lead to random out-of-sample performance measures, we study a cross-validation approach to handle the randomness and make use of it to improve out-of-sample performance. Additionally, a computationally efficient approach to determine the resulting uncertainty in terms of a confidence interval for the mean out-of-sample prediction error is discussed based on two-stage estimation. The approach is applied to a prediction problem arising in vehicle integrated photovoltaics.

</p>
</details>

<details><summary><b>Phase Transitions in Transfer Learning for High-Dimensional Perceptrons</b>
<a href="https://arxiv.org/abs/2101.01918">arxiv:2101.01918</a>
&#x1F4C8; 7 <br>
<p>Oussama Dhifallah, Yue M. Lu</p></summary>
<p>

**Abstract:** Transfer learning seeks to improve the generalization performance of a target task by exploiting the knowledge learned from a related source task. Central questions include deciding what information one should transfer and when transfer can be beneficial. The latter question is related to the so-called negative transfer phenomenon, where the transferred source information actually reduces the generalization performance of the target task. This happens when the two tasks are sufficiently dissimilar. In this paper, we present a theoretical analysis of transfer learning by studying a pair of related perceptron learning tasks. Despite the simplicity of our model, it reproduces several key phenomena observed in practice. Specifically, our asymptotic analysis reveals a phase transition from negative transfer to positive transfer as the similarity of the two tasks moves past a well-defined threshold.

</p>
</details>

<details><summary><b>IPLS : A Framework for Decentralized Federated Learning</b>
<a href="https://arxiv.org/abs/2101.01901">arxiv:2101.01901</a>
&#x1F4C8; 7 <br>
<p>Christodoulos Pappas, Dimitris Chatzopoulos, Spyros Lalis, Manolis Vavalis</p></summary>
<p>

**Abstract:** The proliferation of resourceful mobile devices that store rich, multidimensional and privacy-sensitive user data motivate the design of federated learning (FL), a machine-learning (ML) paradigm that enables mobile devices to produce an ML model without sharing their data. However, the majority of the existing FL frameworks rely on centralized entities. In this work, we introduce IPLS, a fully decentralized federated learning framework that is partially based on the interplanetary file system (IPFS). By using IPLS and connecting into the corresponding private IPFS network, any party can initiate the training process of an ML model or join an ongoing training process that has already been started by another party. IPLS scales with the number of participants, is robust against intermittent connectivity and dynamic participant departures/arrivals, requires minimal resources, and guarantees that the accuracy of the trained model quickly converges to that of a centralized FL framework with an accuracy drop of less than one per thousand.

</p>
</details>

<details><summary><b>HAVANA: Hierarchical and Variation-Normalized Autoencoder for Person Re-identification</b>
<a href="https://arxiv.org/abs/2101.02568">arxiv:2101.02568</a>
&#x1F4C8; 6 <br>
<p>Jiawei Ren, Xiao Ma, Chen Xu, Haiyu Zhao, Shuai Yi</p></summary>
<p>

**Abstract:** Person Re-Identification (Re-ID) is of great importance to the many video surveillance systems. Learning discriminative features for Re-ID remains a challenge due to the large variations in the image space, e.g., continuously changing human poses, illuminations and point of views. In this paper, we propose HAVANA, a novel extensible, light-weight HierArchical and VAriation-Normalized Autoencoder that learns features robust to intra-class variations. In contrast to existing generative approaches that prune the variations with heavy extra supervised signals, HAVANA suppresses the intra-class variations with a Variation-Normalized Autoencoder trained with no additional supervision. We also introduce a novel Jensen-Shannon triplet loss for contrastive distribution learning in Re-ID. In addition, we present Hierarchical Variation Distiller, a hierarchical VAE to factorize the latent representation and explicitly model the variations. To the best of our knowledge, HAVANA is the first VAE-based framework for person ReID.

</p>
</details>

<details><summary><b>OAAE: Adversarial Autoencoders for Novelty Detection in Multi-modal Normality Case via Orthogonalized Latent Space</b>
<a href="https://arxiv.org/abs/2101.02358">arxiv:2101.02358</a>
&#x1F4C8; 6 <br>
<p>Sungkwon An, Jeonghoon Kim, Myungjoo Kang, Shahbaz Razaei, Xin Liu</p></summary>
<p>

**Abstract:** Novelty detection using deep generative models such as autoencoder, generative adversarial networks mostly takes image reconstruction error as novelty score function. However, image data, high dimensional as it is, contains a lot of different features other than class information which makes models hard to detect novelty data. The problem gets harder in multi-modal normality case. To address this challenge, we propose a new way of measuring novelty score in multi-modal normality cases using orthogonalized latent space. Specifically, we employ orthogonal low-rank embedding in the latent space to disentangle the features in the latent space using mutual class information. With the orthogonalized latent space, novelty score is defined by the change of each latent vector. Proposed algorithm was compared to state-of-the-art novelty detection algorithms using GAN such as RaPP and OCGAN, and experimental results show that ours outperforms those algorithms.

</p>
</details>

<details><summary><b>Hyperboost: Hyperparameter Optimization by Gradient Boosting surrogate models</b>
<a href="https://arxiv.org/abs/2101.02289">arxiv:2101.02289</a>
&#x1F4C8; 5 <br>
<p>Jeroen van Hoof, Joaquin Vanschoren</p></summary>
<p>

**Abstract:** Bayesian Optimization is a popular tool for tuning algorithms in automatic machine learning (AutoML) systems. Current state-of-the-art methods leverage Random Forests or Gaussian processes to build a surrogate model that predicts algorithm performance given a certain set of hyperparameter settings. In this paper, we propose a new surrogate model based on gradient boosting, where we use quantile regression to provide optimistic estimates of the performance of an unobserved hyperparameter setting, and combine this with a distance metric between unobserved and observed hyperparameter settings to help regulate exploration. We demonstrate empirically that the new method is able to outperform some state-of-the art techniques across a reasonable sized set of classification problems.

</p>
</details>

<details><summary><b>Controlling Synthetic Characters in Simulations: A Case for Cognitive Architectures and Sigma</b>
<a href="https://arxiv.org/abs/2101.02231">arxiv:2101.02231</a>
&#x1F4C8; 5 <br>
<p>Volkan Ustun, Paul S. Rosenbloom, Seyed Sajjadi, Jeremy Nuttal</p></summary>
<p>

**Abstract:** Simulations, along with other similar applications like virtual worlds and video games, require computational models of intelligence that generate realistic and credible behavior for the participating synthetic characters. Cognitive architectures, which are models of the fixed structure underlying intelligent behavior in both natural and artificial systems, provide a conceptually valid common basis, as evidenced by the current efforts towards a standard model of the mind, to generate human-like intelligent behavior for these synthetic characters. Sigma is a cognitive architecture and system that strives to combine what has been learned from four decades of independent work on symbolic cognitive architectures, probabilistic graphical models, and more recently neural models, under its graphical architecture hypothesis. Sigma leverages an extended form of factor graphs towards a uniform grand unification of not only traditional cognitive capabilities but also key non-cognitive aspects, creating unique opportunities for the construction of new kinds of cognitive models that possess a Theory-of-Mind and that are perceptual, autonomous, interactive, affective, and adaptive. In this paper, we will introduce Sigma along with its diverse capabilities and then use three distinct proof-of-concept Sigma models to highlight combinations of these capabilities: (1) Distributional reinforcement learning models in; (2) A pair of adaptive and interactive agent models that demonstrate rule-based, probabilistic, and social reasoning; and (3) A knowledge-free exploration model in which an agent leverages only architectural appraisal variables, namely attention and curiosity, to locate an item while building up a map in a Unity environment.

</p>
</details>

<details><summary><b>Text analysis in financial disclosures</b>
<a href="https://arxiv.org/abs/2101.04480">arxiv:2101.04480</a>
&#x1F4C8; 4 <br>
<p>Sridhar Ravula</p></summary>
<p>

**Abstract:** Financial disclosure analysis and Knowledge extraction is an important financial analysis problem. Prevailing methods depend predominantly on quantitative ratios and techniques, which suffer from limitations like window dressing and past focus. Most of the information in a firm's financial disclosures is in unstructured text and contains valuable information about its health. Humans and machines fail to analyze it satisfactorily due to the enormous volume and unstructured nature, respectively. Researchers have started analyzing text content in disclosures recently. This paper covers the previous work in unstructured data analysis in Finance and Accounting. It also explores the state of art methods in computational linguistics and reviews the current methodologies in Natural Language Processing (NLP). Specifically, it focuses on research related to text source, linguistic attributes, firm attributes, and mathematical models employed in the text analysis approach. This work contributes to disclosure analysis methods by highlighting the limitations of the current focus on sentiment metrics and highlighting broader future research areas

</p>
</details>

<details><summary><b>DICE: Deep Significance Clustering for Outcome-Aware Stratification</b>
<a href="https://arxiv.org/abs/2101.02344">arxiv:2101.02344</a>
&#x1F4C8; 4 <br>
<p>Yufang Huang, Kelly M. Axsom, John Lee, Lakshminarayanan Subramanian, Yiye Zhang</p></summary>
<p>

**Abstract:** We present deep significance clustering (DICE), a framework for jointly performing representation learning and clustering for "outcome-aware" stratification. DICE is intended to generate cluster membership that may be used to categorize a population by individual risk level for a targeted outcome. Following the representation learning and clustering steps, we embed the objective function in DICE with a constraint which requires a statistically significant association between the outcome and cluster membership of learned representations. DICE further includes a neural architecture search step to maximize both the likelihood of representation learning and outcome classification accuracy with cluster membership as the predictor. To demonstrate its utility in medicine for patient risk-stratification, the performance of DICE was evaluated using two datasets with different outcome ratios extracted from real-world electronic health records. Outcomes are defined as acute kidney injury (30.4\%) among a cohort of COVID-19 patients, and discharge disposition (36.8\%) among a cohort of heart failure patients, respectively. Extensive results demonstrate that DICE has superior performance as measured by the difference in outcome distribution across clusters, Silhouette score, Calinski-Harabasz index, and Davies-Bouldin index for clustering, and Area under the ROC Curve (AUC) for outcome classification compared to several baseline approaches.

</p>
</details>

<details><summary><b>Identification of Latent Variables From Graphical Model Residuals</b>
<a href="https://arxiv.org/abs/2101.02332">arxiv:2101.02332</a>
&#x1F4C8; 4 <br>
<p>Boris Hayete, Fred Gruber, Anna Decker, Raymond Yan</p></summary>
<p>

**Abstract:** Graph-based causal discovery methods aim to capture conditional independencies consistent with the observed data and differentiate causal relationships from indirect or induced ones. Successful construction of graphical models of data depends on the assumption of causal sufficiency: that is, that all confounding variables are measured. When this assumption is not met, learned graphical structures may become arbitrarily incorrect and effects implied by such models may be wrongly attributed, carry the wrong magnitude, or mis-represent direction of correlation. Wide application of graphical models to increasingly less curated "big data" draws renewed attention to the unobserved confounder problem.
  We present a novel method that aims to control for the latent space when estimating a DAG by iteratively deriving proxies for the latent space from the residuals of the inferred model. Under mild assumptions, our method improves structural inference of Gaussian graphical models and enhances identifiability of the causal effect. In addition, when the model is being used to predict outcomes, it un-confounds the coefficients on the parents of the outcomes and leads to improved predictive performance when out-of-sample regime is very different from the training data. We show that any improvement of prediction of an outcome is intrinsically capped and cannot rise beyond a certain limit as compared to the confounded model. We extend our methodology beyond GGMs to ordinal variables and nonlinear cases. Our R package provides both PCA and autoencoder implementations of the methodology, suitable for GGMs with some guarantees and for better performance in general cases but without such guarantees.

</p>
</details>

<details><summary><b>A design of human-like robust AI machines in object identification</b>
<a href="https://arxiv.org/abs/2101.02327">arxiv:2101.02327</a>
&#x1F4C8; 4 <br>
<p>Bao-Gang Hu, Wei-Ming Dong</p></summary>
<p>

**Abstract:** This is a perspective paper inspired from the study of Turing Test proposed by A.M. Turing (23 June 1912 - 7 June 1954) in 1950. Following one important implication of Turing Test for enabling a machine with a human-like behavior or performance, we define human-like robustness (HLR) for AI machines. The objective of the new definition aims to enforce AI machines with HLR, including to evaluate them in terms of HLR. A specific task is discussed only on object identification, because it is the most common task for every person in daily life. Similar to the perspective, or design, position by Turing, we provide a solution of how to achieve HLR AI machines without constructing them and conducting real experiments. The solution should consists of three important features in the machines. The first feature of HLR machines is to utilize common sense from humans for realizing a causal inference. The second feature is to make a decision from a semantic space for having interpretations to the decision. The third feature is to include a "human-in-the-loop" setting for advancing HLR machines. We show an "identification game" using proposed design of HLR machines. The present paper shows an attempt to learn and explore further from Turing Test towards the design of human-like AI machines.

</p>
</details>

<details><summary><b>Taxonomy Completion via Triplet Matching Network</b>
<a href="https://arxiv.org/abs/2101.01896">arxiv:2101.01896</a>
&#x1F4C8; 4 <br>
<p>Jieyu Zhang, Xiangchen Song, Ying Zeng, Jiaze Chen, Jiaming Shen, Yuning Mao, Lei Li</p></summary>
<p>

**Abstract:** Automatically constructing taxonomy finds many applications in e-commerce and web search. One critical challenge is as data and business scope grow in real applications, new concepts are emerging and needed to be added to the existing taxonomy. Previous approaches focus on the taxonomy expansion, i.e. finding an appropriate hypernym concept from the taxonomy for a new query concept. In this paper, we formulate a new task, "taxonomy completion", by discovering both the hypernym and hyponym concepts for a query. We propose Triplet Matching Network (TMN), to find the appropriate <hypernym, hyponym> pairs for a given query concept. TMN consists of one primal scorer and multiple auxiliary scorers. These auxiliary scorers capture various fine-grained signals (e.g., query to hypernym or query to hyponym semantics), and the primal scorer makes a holistic prediction on <query, hypernym, hyponym> triplet based on the internal feature representations of all auxiliary scorers. Also, an innovative channel-wise gating mechanism that retains task-specific information in concept representations is introduced to further boost model performance. Experiments on four real-world large-scale datasets show that TMN achieves the best performance on both taxonomy completion task and the previous taxonomy expansion task, outperforming existing methods.

</p>
</details>

<details><summary><b>Order Embeddings from Merged Ontologies using Sketching</b>
<a href="https://arxiv.org/abs/2101.02158">arxiv:2101.02158</a>
&#x1F4C8; 3 <br>
<p>Kenneth L. Clarkson, Sanjana Sahayaraj</p></summary>
<p>

**Abstract:** We give a simple, low resource method to produce order embeddings from ontologies. Such embeddings map words to vectors so that order relations on the words, such as hypernymy/hyponymy, are represented in a direct way. Our method uses sketching techniques, in particular countsketch, for dimensionality reduction. We also study methods to merge ontologies, in particular those in medical domains, so that order relations are preserved. We give computational results for medical ontologies and for wordnet, showing that our merging techniques are effective and our embedding yields an accurate representation in both generic and specialised domains.

</p>
</details>

<details><summary><b>Ensemble and Random Collaborative Representation-Based Anomaly Detector for Hyperspectral Imagery</b>
<a href="https://arxiv.org/abs/2101.01976">arxiv:2101.01976</a>
&#x1F4C8; 3 <br>
<p>Rong Wang, Yihang Lu, Qianrong Zhang, Feiping Nie, Zhen Wang, Xuelong Li</p></summary>
<p>

**Abstract:** In recent years, hyperspectral anomaly detection (HAD) has become an active topic and plays a significant role in military and civilian fields. As a classic HAD method, the collaboration representation-based detector (CRD) has attracted extensive attention and in-depth research. Despite the good performance of the CRD method, its computational cost mainly arising from the sliding dual window strategy is too high for wide applications. Moreover, it takes multiple repeated tests to determine the size of the dual window, which needs to be reset once the dataset changes and cannot be identified in advance with prior knowledge. To alleviate this problem, we proposed a novel ensemble and random collaborative representation-based detector (ERCRD) for HAD, which comprises two closely related stages. Firstly, we process the random sub-sampling on CRD (RCRD) to gain several detection results instead of the sliding dual window strategy, which significantly reduces the computational complexity and makes it more feasible in practical applications. Secondly, ensemble learning is employed to refine the multiple results of RCRD, which act as various "experts" providing abundant complementary information to better target different anomalies. Such two stages form an organic and theoretical detector, which can not only improve the accuracy and stability of HAD methods but also enhance its generalization ability. Experiments on four real hyperspectral datasets exhibit the accuracy and efficiency of this proposed ERCRD method compared with ten state-of-the-art HAD methods.

</p>
</details>

<details><summary><b>On Satisficing in Quantitative Games</b>
<a href="https://arxiv.org/abs/2101.02594">arxiv:2101.02594</a>
&#x1F4C8; 2 <br>
<p>Suguman Bansal, Krishnendu Chatterjee, Moshe Y. Vardi</p></summary>
<p>

**Abstract:** Several problems in planning and reactive synthesis can be reduced to the analysis of two-player quantitative graph games. {\em Optimization} is one form of analysis. We argue that in many cases it may be better to replace the optimization problem with the {\em satisficing problem}, where instead of searching for optimal solutions, the goal is to search for solutions that adhere to a given threshold bound.
  This work defines and investigates the satisficing problem on a two-player graph game with the discounted-sum cost model. We show that while the satisficing problem can be solved using numerical methods just like the optimization problem, this approach does not render compelling benefits over optimization. When the discount factor is, however, an integer, we present another approach to satisficing, which is purely based on automata methods. We show that this approach is algorithmically more performant -- both theoretically and empirically -- and demonstrates the broader applicability of satisficing overoptimization.

</p>
</details>

<details><summary><b>Max-Affine Spline Insights Into Deep Network Pruning</b>
<a href="https://arxiv.org/abs/2101.02338">arxiv:2101.02338</a>
&#x1F4C8; 2 <br>
<p>Randall Balestriero, Haoran You, Zhihan Lu, Yutong Kou, Huihong Shi, Yingyan Lin, Richard Baraniuk</p></summary>
<p>

**Abstract:** In this paper, we study the importance of pruning in Deep Networks (DNs) and the yin & yang relationship between (1) pruning highly overparametrized DNs that have been trained from random initialization and (2) training small DNs that have been "cleverly" initialized. As in most cases practitioners can only resort to random initialization, there is a strong need to develop a grounded understanding of DN pruning. Current literature remains largely empirical, lacking a theoretical understanding of how pruning affects DNs' decision boundary, how to interpret pruning, and how to design corresponding principled pruning techniques. To tackle those questions, we propose to employ recent advances in the theoretical analysis of Continuous Piecewise Affine (CPA) DNs. From this perspective, we will be able to detect the early-bird (EB) ticket phenomenon, provide interpretability into current pruning techniques, and develop a principled pruning strategy. In each step of our study, we conduct extensive experiments supporting our claims and results; while our main goal is to enhance the current understanding towards DN pruning instead of developing a new pruning method, our spline pruning criteria in terms of layerwise and global pruning is on par with or even outperforms state-of-the-art pruning methods.

</p>
</details>

<details><summary><b>Infinitely Wide Tensor Networks as Gaussian Process</b>
<a href="https://arxiv.org/abs/2101.02333">arxiv:2101.02333</a>
&#x1F4C8; 2 <br>
<p>Erdong Guo, David Draper</p></summary>
<p>

**Abstract:** Gaussian Process is a non-parametric prior which can be understood as a distribution on the function space intuitively. It is known that by introducing appropriate prior to the weights of the neural networks, Gaussian Process can be obtained by taking the infinite-width limit of the Bayesian neural networks from a Bayesian perspective. In this paper, we explore the infinitely wide Tensor Networks and show the equivalence of the infinitely wide Tensor Networks and the Gaussian Process. We study the pure Tensor Network and another two extended Tensor Network structures: Neural Kernel Tensor Network and Tensor Network hidden layer Neural Network and prove that each one will converge to the Gaussian Process as the width of each model goes to infinity. (We note here that Gaussian Process can also be obtained by taking the infinite limit of at least one of the bond dimensions $α_{i}$ in the product of tensor nodes, and the proofs can be done with the same ideas in the proofs of the infinite-width cases.) We calculate the mean function (mean vector) and the covariance function (covariance matrix) of the finite dimensional distribution of the induced Gaussian Process by the infinite-width tensor network with a general set-up. We study the properties of the covariance function and derive the approximation of the covariance function when the integral in the expectation operator is intractable. In the numerical experiments, we implement the Gaussian Process corresponding to the infinite limit tensor networks and plot the sample paths of these models. We study the hyperparameters and plot the sample path families in the induced Gaussian Process by varying the standard deviations of the prior distributions. As expected, the parameters in the prior distribution namely the hyper-parameters in the induced Gaussian Process controls the characteristic lengthscales of the Gaussian Process.

</p>
</details>

<details><summary><b>Copula Quadrant Similarity for Anomaly Scores</b>
<a href="https://arxiv.org/abs/2101.02330">arxiv:2101.02330</a>
&#x1F4C8; 2 <br>
<p>Matthew Davidow, David Matteson</p></summary>
<p>

**Abstract:** Practical anomaly detection requires applying numerous approaches due to the inherent difficulty of unsupervised learning. Direct comparison between complex or opaque anomaly detection algorithms is intractable; we instead propose a framework for associating the scores of multiple methods. Our aim is to answer the question: how should one measure the similarity between anomaly scores generated by different methods? The scoring crux is the extremes, which identify the most anomalous observations. A pair of algorithms are defined here to be similar if they assign their highest scores to roughly the same small fraction of observations. To formalize this, we propose a measure based on extremal similarity in scoring distributions through a novel upper quadrant modeling approach, and contrast it with tail and other dependence measures. We illustrate our method with simulated and real experiments, applying spectral methods to cluster multiple anomaly detection methods and to contrast our similarity measure with others. We demonstrate that our method is able to detect the clusters of anomaly detection algorithms to achieve an accurate and robust ensemble algorithm.

</p>
</details>

<details><summary><b>Learn Dynamic-Aware State Embedding for Transfer Learning</b>
<a href="https://arxiv.org/abs/2101.02230">arxiv:2101.02230</a>
&#x1F4C8; 2 <br>
<p>Kaige Yang</p></summary>
<p>

**Abstract:** Transfer reinforcement learning aims to improve the sample efficiency of solving unseen new tasks by leveraging experiences obtained from previous tasks. We consider the setting where all tasks (MDPs) share the same environment dynamic except reward function. In this setting, the MDP dynamic is a good knowledge to transfer, which can be inferred by uniformly random policy. However, trajectories generated by uniform random policy are not useful for policy improvement, which impairs the sample efficiency severely. Instead, we observe that the binary MDP dynamic can be inferred from trajectories of any policy which avoids the need of uniform random policy. As the binary MDP dynamic contains the state structure shared over all tasks we believe it is suitable to transfer. Built on this observation, we introduce a method to infer the binary MDP dynamic on-line and at the same time utilize it to guide state embedding learning, which is then transferred to new tasks. We keep state embedding learning and policy learning separately. As a result, the learned state embedding is task and policy agnostic which makes it ideal for transfer learning. In addition, to facilitate the exploration over the state space, we propose a novel intrinsic reward based on the inferred binary MDP dynamic. Our method can be used out-of-box in combination with model-free RL algorithms. We show two instances on the basis of \algo{DQN} and \algo{A2C}. Empirical results of intensive experiments show the advantage of our proposed method in various transfer learning tasks.

</p>
</details>

<details><summary><b>Explainable Systematic Analysis for Synthetic Aperture Sonar Imagery</b>
<a href="https://arxiv.org/abs/2101.03134">arxiv:2101.03134</a>
&#x1F4C8; 1 <br>
<p>Sarah Walker, Joshua Peeples, Jeff Dale, James Keller, Alina Zare</p></summary>
<p>

**Abstract:** In this work, we present an in-depth and systematic analysis using tools such as local interpretable model-agnostic explanations (LIME) (arXiv:1602.04938) and divergence measures to analyze what changes lead to improvement in performance in fine tuned models for synthetic aperture sonar (SAS) data. We examine the sensitivity to factors in the fine tuning process such as class imbalance. Our findings show not only an improvement in seafloor texture classification, but also provide greater insight into what features play critical roles in improving performance as well as a knowledge of the importance of balanced data for fine tuning deep learning models for seafloor classification in SAS imagery.

</p>
</details>

<details><summary><b>Analyzing the Stability of Non-coplanar Circumbinary Planets using Machine Learning</b>
<a href="https://arxiv.org/abs/2101.02316">arxiv:2101.02316</a>
&#x1F4C8; 1 <br>
<p>Zhihui Kong, Jonathan H. Jiang, Zong-Hong Zhu, Kristen A. Fahy, Remo Burn</p></summary>
<p>

**Abstract:** Exoplanet detection in the past decade by efforts including NASA's Kepler and TESS missions has discovered many worlds that differ substantially from planets in our own Solar system, including more than 400 exoplanets orbiting binary or multi-star systems. This not only broadens our understanding of the diversity of exoplanets, but also promotes our study of exoplanets in the complex binary and multi-star systems and provides motivation to explore their habitability. In this study, we analyze orbital stability of exoplanets in non-coplanar circumbinary systems using a numerical simulation method, with which a large number of circumbinary planet samples are generated in order to quantify the effects of various orbital parameters on orbital stability. We also train a machine learning model that can quickly determine the stability of the circumbinary planetary systems. Our results indicate that larger inclinations of the planet tend to increase the stability of its orbit, but change in the planet's mass range between Earth and Jupiter has little effect on the stability of the system. In addition, we find that Deep Neural Networks (DNNs) have higher accuracy and precision than other machine learning algorithms.

</p>
</details>

<details><summary><b>A Note on Rough Set Algebra and Core Regular Double Stone Algebras</b>
<a href="https://arxiv.org/abs/2101.02313">arxiv:2101.02313</a>
&#x1F4C8; 1 <br>
<p>Daniel J. Clouse</p></summary>
<p>

**Abstract:** Given an approximation space $\langle U,θ\rangle$, assume that $E$ is the indexing set for the equivalence classes of $θ$ and let $R_θ$ denote the collection of rough sets of the form $\langle\underline{X},\overline{X}\rangle$ as a regular double Stone algebra and what I. Dunstch referred to as a Katrinak algebra.[7],[8] We give an alternate proof from the one given in [1] of the fact that if $|θ_u| > 1\ \forall\ u \in U$ then $R_θ$ is a core regular double Stone algebra. Further let $C_3$ denote the 3 element chain as a core regular double Stone algebra and $TP_U$ denote the collection of ternary partitions over the set $U$. In our Main Theorem we show $R_θ$ with $|θ_u| > 1\ \forall\ u \in U$ to be isomorphic to $TP_E$ and $C_3^E$, with $E$ is an indexing set for $θ$, and that the three CRDSA's are complete and atomic. We feel this could be very useful when dealing with a specific $R_θ$ in an application. In our Main Corollary we show explicitly how we can embed such $R_θ$ in $TP_U$, $C_3^U$, respectively, $φ\circ α_r:R_θ\hookrightarrow TP_U\hookrightarrow C_3^U$, and hence identify it with its specific images. Following in the footsteps of Theorem 3. and Corollary 2.4 of [7], we show $C_3^J \cong R_θ$ for $\langle U,θ\rangle$ the approximation space given by $U = J \times \{0,1\}$, $θ= \{(j0),(j1)\} : j \in J\}$ and every CRDSA is isomorphic to a subalgebra of a principal rough set algebra, $R_θ$, for some approximation space $\langle U,θ\rangle$. Finally, we demonstrate this and our Main Theorem by expanding an example from [1]. Further, we know a little more about the subalgebras of $TP_U$ and $C_3^U$ in general as they must exist for every $E$ that is an indexing set for the equivalence classes of any equivalence relation $θ$ on $U$ satisfying $|θ_u| > 1\ \forall\ u \in U$.

</p>
</details>

<details><summary><b>Regularization-Agnostic Compressed Sensing MRI Reconstruction with Hypernetworks</b>
<a href="https://arxiv.org/abs/2101.02194">arxiv:2101.02194</a>
&#x1F4C8; 1 <br>
<p>Alan Q. Wang, Adrian V. Dalca, Mert R. Sabuncu</p></summary>
<p>

**Abstract:** Reconstructing under-sampled k-space measurements in Compressed Sensing MRI (CS-MRI) is classically solved with regularized least-squares. Recently, deep learning has been used to amortize this optimization by training reconstruction networks on a dataset of under-sampled measurements. Here, a crucial design choice is the regularization function(s) and corresponding weight(s). In this paper, we explore a novel strategy of using a hypernetwork to generate the parameters of a separate reconstruction network as a function of the regularization weight(s), resulting in a regularization-agnostic reconstruction model. At test time, for a given under-sampled image, our model can rapidly compute reconstructions with different amounts of regularization. We analyze the variability of these reconstructions, especially in situations when the overall quality is similar. Finally, we propose and empirically demonstrate an efficient and data-driven way of maximizing reconstruction performance given limited hypernetwork capacity. Our code is publicly available at https://github.com/alanqrwang/RegAgnosticCSMRI.

</p>
</details>

<details><summary><b>A New Weighting Scheme for Fan-beam and Circle Cone-beam CT Reconstructions</b>
<a href="https://arxiv.org/abs/2101.01886">arxiv:2101.01886</a>
&#x1F4C8; 1 <br>
<p>Wei Wang, Xiang-Gen Xia, Chuanjiang He, Zemin Ren, Jian Lu, Tianfu Wang, Baiying Lei</p></summary>
<p>

**Abstract:** In this paper, we first present an arc based algorithm for fan-beam computed tomography (CT) reconstruction via applying Katsevich's helical CT formula to 2D fan-beam CT reconstruction. Then, we propose a new weighting function to deal with the redundant projection data. By extending the weighted arc based fan-beam algorithm to circle cone-beam geometry, we also obtain a new FDK-similar algorithm for circle cone-beam CT reconstruction. Experiments show that our methods can obtain higher PSNR and SSIM compared to the Parker-weighted conventional fan-beam algorithm and the FDK algorithm for super-short-scan trajectories.

</p>
</details>

<details><summary><b>MSD: Saliency-aware Knowledge Distillation for Multimodal Understanding</b>
<a href="https://arxiv.org/abs/2101.01881">arxiv:2101.01881</a>
&#x1F4C8; 1 <br>
<p>Woojeong Jin, Maziar Sanjabi, Shaoliang Nie, Liang Tan, Xiang Ren, Hamed Firooz</p></summary>
<p>

**Abstract:** To reduce a model size but retain performance, we often rely on knowledge distillation (KD) which transfers knowledge from a large "teacher" model to a smaller "student" model. However, KD on multimodal datasets such as vision-language tasks is relatively unexplored, and digesting multimodal information is challenging since different modalities present different types of information. In this paper, we perform a large-scale empirical study to investigate the importance and effects of each modality in knowledge distillation. Furthermore, we introduce a multimodal knowledge distillation framework, modality-specific distillation (MSD), to transfer knowledge from a teacher on multimodal tasks by learning the teacher's behavior within each modality. The idea aims at mimicking a teacher's modality-specific predictions by introducing auxiliary loss terms for each modality. Furthermore, because each modality has different saliency for predictions, we define saliency scores for each modality and investigate saliency-based weighting schemes for the auxiliary losses. We further study a weight learning approach to learn the optimal weights on these loss terms. In our empirical analysis, we examine the saliency of each modality in KD, demonstrate the effectiveness of the weighting scheme in MSD, and show that it achieves better performance than KD on four multimodal datasets.

</p>
</details>

<details><summary><b>Directed mixed membership stochastic blockmodel</b>
<a href="https://arxiv.org/abs/2101.02307">arxiv:2101.02307</a>
&#x1F4C8; 0 <br>
<p>Huan Qing, Jingli Wang</p></summary>
<p>

**Abstract:** Mixed membership problem for undirected network has been well studied in network analysis recent years. However, the more general case of mixed membership for directed network remains a challenge. Here, we propose an interpretable and identifiable model: directed mixed membership stochastic blockmodel (DiMMSB for short) for directed mixed membership networks. DiMMSB allows that row nodes and column nodes of the adjacency matrix can be different and these nodes may have distinct community structure in a directed network. We also develop an efficient spectral algorithm called DiSP designed based on simplex structures inherent in the left and right singular vectors of the population adjacency matrix to estimate the mixed memberships for both row nodes and column nodes in a directed network. We show that DiSP is asymptotically consistent under mild conditions by providing error bounds for the inferred membership vectors of each row node and each column node using delicate spectral analysis. We demonstrate the advantages of DiSP with applications to simulated directed mixed membership network, the directed Political blogs network and the Papers Citation network.

</p>
</details>

<details><summary><b>Maximum a Posteriori Inference of Random Dot Product Graphs via Conic Programming</b>
<a href="https://arxiv.org/abs/2101.02180">arxiv:2101.02180</a>
&#x1F4C8; 0 <br>
<p>David Wu, David R. Palmer, Daryl R. Deford</p></summary>
<p>

**Abstract:** We present a convex cone program to infer the latent probability matrix of a random dot product graph (RDPG). The optimization problem maximizes the Bernoulli maximum likelihood function with an added nuclear norm regularization term. The dual problem has a particularly nice form, related to the well-known semidefinite program relaxation of the MaxCut problem. Using the primal-dual optimality conditions, we bound the entries and rank of the primal and dual solutions. Furthermore, we bound the optimal objective value and prove asymptotic consistency of the probability estimates of a slightly modified model under mild technical assumptions. Our experiments on synthetic RDPGs not only recover natural clusters, but also reveal the underlying low-dimensional geometry of the original data. We also demonstrate that the method recovers latent structure in the Karate Club Graph and synthetic U.S. Senate vote graphs and is scalable to graphs with up to a few hundred nodes.

</p>
</details>


{% endraw %}
Prev: [2021.01.05]({{ '/2021/01/05/2021.01.05.html' | relative_url }})  Next: [2021.01.07]({{ '/2021/01/07/2021.01.07.html' | relative_url }})