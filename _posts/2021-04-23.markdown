## Summary for 2021-04-23, created on 2021-12-22


<details><summary><b>Grouped Feature Importance and Combined Features Effect Plot</b>
<a href="https://arxiv.org/abs/2104.11688">arxiv:2104.11688</a>
&#x1F4C8; 45 <br>
<p>Quay Au, Julia Herbinger, Clemens Stachl, Bernd Bischl, Giuseppe Casalicchio</p></summary>
<p>

**Abstract:** Interpretable machine learning has become a very active area of research due to the rising popularity of machine learning algorithms and their inherently challenging interpretability. Most work in this area has been focused on the interpretation of single features in a model. However, for researchers and practitioners, it is often equally important to quantify the importance or visualize the effect of feature groups. To address this research gap, we provide a comprehensive overview of how existing model-agnostic techniques can be defined for feature groups to assess the grouped feature importance, focusing on permutation-based, refitting, and Shapley-based methods. We also introduce an importance-based sequential procedure that identifies a stable and well-performing combination of features in the grouped feature space. Furthermore, we introduce the combined features effect plot, which is a technique to visualize the effect of a group of features based on a sparse, interpretable linear combination of features. We used simulation studies and a real data example from computational psychology to analyze, compare, and discuss these methods.

</p>
</details>

<details><summary><b>Skip-Convolutions for Efficient Video Processing</b>
<a href="https://arxiv.org/abs/2104.11487">arxiv:2104.11487</a>
&#x1F4C8; 28 <br>
<p>Amirhossein Habibian, Davide Abati, Taco S. Cohen, Babak Ehteshami Bejnordi</p></summary>
<p>

**Abstract:** We propose Skip-Convolutions to leverage the large amount of redundancies in video streams and save computations. Each video is represented as a series of changes across frames and network activations, denoted as residuals. We reformulate standard convolution to be efficiently computed on residual frames: each layer is coupled with a binary gate deciding whether a residual is important to the model prediction,~\eg foreground regions, or it can be safely skipped, e.g. background regions. These gates can either be implemented as an efficient network trained jointly with convolution kernels, or can simply skip the residuals based on their magnitude. Gating functions can also incorporate block-wise sparsity structures, as required for efficient implementation on hardware platforms. By replacing all convolutions with Skip-Convolutions in two state-of-the-art architectures, namely EfficientDet and HRNet, we reduce their computational cost consistently by a factor of 3~4x for two different tasks, without any accuracy drop. Extensive comparisons with existing model compression, as well as image and video efficiency methods demonstrate that Skip-Convolutions set a new state-of-the-art by effectively exploiting the temporal redundancies in videos.

</p>
</details>

<details><summary><b>DisCo RL: Distribution-Conditioned Reinforcement Learning for General-Purpose Policies</b>
<a href="https://arxiv.org/abs/2104.11707">arxiv:2104.11707</a>
&#x1F4C8; 21 <br>
<p>Soroush Nasiriany, Vitchyr H. Pong, Ashvin Nair, Alexander Khazatsky, Glen Berseth, Sergey Levine</p></summary>
<p>

**Abstract:** Can we use reinforcement learning to learn general-purpose policies that can perform a wide range of different tasks, resulting in flexible and reusable skills? Contextual policies provide this capability in principle, but the representation of the context determines the degree of generalization and expressivity. Categorical contexts preclude generalization to entirely new tasks. Goal-conditioned policies may enable some generalization, but cannot capture all tasks that might be desired. In this paper, we propose goal distributions as a general and broadly applicable task representation suitable for contextual policies. Goal distributions are general in the sense that they can represent any state-based reward function when equipped with an appropriate distribution class, while the particular choice of distribution class allows us to trade off expressivity and learnability. We develop an off-policy algorithm called distribution-conditioned reinforcement learning (DisCo RL) to efficiently learn these policies. We evaluate DisCo RL on a variety of robot manipulation tasks and find that it significantly outperforms prior methods on tasks that require generalization to new goal distributions.

</p>
</details>

<details><summary><b>Playing Lottery Tickets with Vision and Language</b>
<a href="https://arxiv.org/abs/2104.11832">arxiv:2104.11832</a>
&#x1F4C8; 14 <br>
<p>Zhe Gan, Yen-Chun Chen, Linjie Li, Tianlong Chen, Yu Cheng, Shuohang Wang, Jingjing Liu, Lijuan Wang, Zicheng Liu</p></summary>
<p>

**Abstract:** Large-scale pre-training has recently revolutionized vision-and-language (VL) research. Models such as LXMERT and UNITER have significantly lifted the state of the art over a wide range of VL tasks. However, the large number of parameters in such models hinders their application in practice. In parallel, work on the lottery ticket hypothesis (LTH) has shown that deep neural networks contain small matching subnetworks that can achieve on par or even better performance than the dense networks when trained in isolation. In this work, we perform the first empirical study to assess whether such trainable subnetworks also exist in pre-trained VL models. We use UNITER as the main testbed (also test on LXMERT and ViLT), and consolidate 7 representative VL tasks for experiments, including visual question answering, visual commonsense reasoning, visual entailment, referring expression comprehension, image-text retrieval, GQA, and NLVR$^2$. Through comprehensive analysis, we summarize our main findings as follows. ($i$) It is difficult to find subnetworks that strictly match the performance of the full model. However, we can find "relaxed" winning tickets at 50%-70% sparsity that maintain 99% of the full accuracy. ($ii$) Subnetworks found by task-specific pruning transfer reasonably well to the other tasks, while those found on the pre-training tasks at 60%/70% sparsity transfer universally, matching 98%/96% of the full accuracy on average over all the tasks. ($iii$) Besides UNITER, other models such as LXMERT and ViLT can also play lottery tickets. However, the highest sparsity we can achieve for ViLT is far lower than LXMERT and UNITER (30% vs. 70%). ($iv$) LTH also remains relevant when using other training methods (e.g., adversarial training).

</p>
</details>

<details><summary><b>Co-training for Deep Object Detection: Comparing Single-modal and Multi-modal Approaches</b>
<a href="https://arxiv.org/abs/2104.11619">arxiv:2104.11619</a>
&#x1F4C8; 10 <br>
<p>Jose L. Gómez, Gabriel Villalonga, Antonio M. López</p></summary>
<p>

**Abstract:** Top-performing computer vision models are powered by convolutional neural networks (CNNs). Training an accurate CNN highly depends on both the raw sensor data and their associated ground truth (GT). Collecting such GT is usually done through human labeling, which is time-consuming and does not scale as we wish. This data labeling bottleneck may be intensified due to domain shifts among image sensors, which could force per-sensor data labeling. In this paper, we focus on the use of co-training, a semi-supervised learning (SSL) method, for obtaining self-labeled object bounding boxes (BBs), i.e., the GT to train deep object detectors. In particular, we assess the goodness of multi-modal co-training by relying on two different views of an image, namely, appearance (RGB) and estimated depth (D). Moreover, we compare appearance-based single-modal co-training with multi-modal. Our results suggest that in a standard SSL setting (no domain shift, a few human-labeled data) and under virtual-to-real domain shift (many virtual-world labeled data, no human-labeled data) multi-modal co-training outperforms single-modal. In the latter case, by performing GAN-based domain translation both co-training modalities are on pair; at least, when using an off-the-shelf depth estimation model not specifically trained on the translated images.

</p>
</details>

<details><summary><b>DeepfakeUCL: Deepfake Detection via Unsupervised Contrastive Learning</b>
<a href="https://arxiv.org/abs/2104.11507">arxiv:2104.11507</a>
&#x1F4C8; 9 <br>
<p>Sheldon Fung, Xuequan Lu, Chao Zhang, Chang-Tsun Li</p></summary>
<p>

**Abstract:** Face deepfake detection has seen impressive results recently. Nearly all existing deep learning techniques for face deepfake detection are fully supervised and require labels during training. In this paper, we design a novel deepfake detection method via unsupervised contrastive learning. We first generate two different transformed versions of an image and feed them into two sequential sub-networks, i.e., an encoder and a projection head. The unsupervised training is achieved by maximizing the correspondence degree of the outputs of the projection head. To evaluate the detection performance of our unsupervised method, we further use the unsupervised features to train an efficient linear classification network. Extensive experiments show that our unsupervised learning method enables comparable detection performance to state-of-the-art supervised techniques, in both the intra- and inter-dataset settings. We also conduct ablation studies for our method.

</p>
</details>

<details><summary><b>Graph Neural Network Reinforcement Learning for Autonomous Mobility-on-Demand Systems</b>
<a href="https://arxiv.org/abs/2104.11434">arxiv:2104.11434</a>
&#x1F4C8; 9 <br>
<p>Daniele Gammelli, Kaidi Yang, James Harrison, Filipe Rodrigues, Francisco C. Pereira, Marco Pavone</p></summary>
<p>

**Abstract:** Autonomous mobility-on-demand (AMoD) systems represent a rapidly developing mode of transportation wherein travel requests are dynamically handled by a coordinated fleet of robotic, self-driving vehicles. Given a graph representation of the transportation network - one where, for example, nodes represent areas of the city, and edges the connectivity between them - we argue that the AMoD control problem is naturally cast as a node-wise decision-making problem. In this paper, we propose a deep reinforcement learning framework to control the rebalancing of AMoD systems through graph neural networks. Crucially, we demonstrate that graph neural networks enable reinforcement learning agents to recover behavior policies that are significantly more transferable, generalizable, and scalable than policies learned through other approaches. Empirically, we show how the learned policies exhibit promising zero-shot transfer capabilities when faced with critical portability tasks such as inter-city generalization, service area expansion, and adaptation to potentially complex urban topologies.

</p>
</details>

<details><summary><b>Deep Learning Based Assessment of Synthetic Speech Naturalness</b>
<a href="https://arxiv.org/abs/2104.11673">arxiv:2104.11673</a>
&#x1F4C8; 8 <br>
<p>Gabriel Mittag, Sebastian Möller</p></summary>
<p>

**Abstract:** In this paper, we present a new objective prediction model for synthetic speech naturalness. It can be used to evaluate Text-To-Speech or Voice Conversion systems and works language independently. The model is trained end-to-end and based on a CNN-LSTM network that previously showed to give good results for speech quality estimation. We trained and tested the model on 16 different datasets, such as from the Blizzard Challenge and the Voice Conversion Challenge. Further, we show that the reliability of deep learning-based naturalness prediction can be improved by transfer learning from speech quality prediction models that are trained on objective POLQA scores. The proposed model is made publicly available and can, for example, be used to evaluate different TTS system configurations.

</p>
</details>

<details><summary><b>Online recognition of unsegmented actions with hierarchical SOM architecture</b>
<a href="https://arxiv.org/abs/2104.11637">arxiv:2104.11637</a>
&#x1F4C8; 8 <br>
<p>Zahra Gharaee</p></summary>
<p>

**Abstract:** Automatic recognition of an online series of unsegmented actions requires a method for segmentation that determines when an action starts and when it ends. In this paper, a novel approach for recognizing unsegmented actions in online test experiments is proposed. The method uses self-organizing neural networks to build a three-layer cognitive architecture. The unique features of an action sequence are represented as a series of elicited key activations by the first-layer self-organizing map. An average length of a key activation vector is calculated for all action sequences in a training set and adjusted in learning trials to generate input patterns to the second-layer self-organizing map. The pattern vectors are clustered in the second layer, and the clusters are then labeled by an action identity in the third layer neural network. The experiment results show that although the performance drops slightly in online experiments compared to the offline tests, the ability of the proposed architecture to deal with the unsegmented action sequences as well as the online performance makes the system more plausible and practical in real-case scenarios.

</p>
</details>

<details><summary><b>DeepSpectrumLite: A Power-Efficient Transfer Learning Framework for Embedded Speech and Audio Processing from Decentralised Data</b>
<a href="https://arxiv.org/abs/2104.11629">arxiv:2104.11629</a>
&#x1F4C8; 7 <br>
<p>Shahin Amiriparian, Tobias Hübner, Maurice Gerczuk, Sandra Ottl, Björn W. Schuller</p></summary>
<p>

**Abstract:** Deep neural speech and audio processing systems have a large number of trainable parameters, a relatively complex architecture, and require a vast amount of training data and computational power. These constraints make it more challenging to integrate such systems into embedded devices and utilise them for real-time, real-world applications. We tackle these limitations by introducing DeepSpectrumLite, an open-source, lightweight transfer learning framework for on-device speech and audio recognition using pre-trained image convolutional neural networks (CNNs). The framework creates and augments Mel-spectrogram plots on-the-fly from raw audio signals which are then used to finetune specific pre-trained CNNs for the target classification task. Subsequently, the whole pipeline can be run in real-time with a mean inference lag of 242.0 ms when a DenseNet121 model is used on a consumer-grade Motorola moto e7 plus smartphone. DeepSpectrumLite operates decentralised, eliminating the need for data upload for further processing. By obtaining state-of-the-art results on a set of paralinguistics tasks, we demonstrate the suitability of the proposed transfer learning approach for embedded audio signal processing, even when data is scarce. We provide an extensive command-line interface for users and developers which is comprehensively documented and publicly available at https://github.com/DeepSpectrum/DeepSpectrumLite.

</p>
</details>

<details><summary><b>GuideBP: Guiding Backpropagation Through Weaker Pathways of Parallel Logits</b>
<a href="https://arxiv.org/abs/2104.11620">arxiv:2104.11620</a>
&#x1F4C8; 7 <br>
<p>Bodhisatwa Mandal, Swarnendu Ghosh, Teresa Gonçalves, Paulo Quaresma, Mita Nasipuri, Nibaran Das</p></summary>
<p>

**Abstract:** Convolutional neural networks often generate multiple logits and use simple techniques like addition or averaging for loss computation. But this allows gradients to be distributed equally among all paths. The proposed approach guides the gradients of backpropagation along weakest concept representations. A weakness scores defines the class specific performance of individual pathways which is then used to create a logit that would guide gradients along the weakest pathways. The proposed approach has been shown to perform better than traditional column merging techniques and can be used in several application scenarios. Not only can the proposed model be used as an efficient technique for training multiple instances of a model parallely, but also CNNs with multiple output branches have been shown to perform better with the proposed upgrade. Various experiments establish the flexibility of the learning technique which is simple yet effective in various multi-objective scenarios both empirically and statistically.

</p>
</details>

<details><summary><b>Learning in Deep Neural Networks Using a Biologically Inspired Optimizer</b>
<a href="https://arxiv.org/abs/2104.11604">arxiv:2104.11604</a>
&#x1F4C8; 7 <br>
<p>Giorgia Dellaferrera, Stanislaw Wozniak, Giacomo Indiveri, Angeliki Pantazi, Evangelos Eleftheriou</p></summary>
<p>

**Abstract:** Plasticity circuits in the brain are known to be influenced by the distribution of the synaptic weights through the mechanisms of synaptic integration and local regulation of synaptic strength. However, the complex interplay of stimulation-dependent plasticity with local learning signals is disregarded by most of the artificial neural network training algorithms devised so far. Here, we propose a novel biologically inspired optimizer for artificial (ANNs) and spiking neural networks (SNNs) that incorporates key principles of synaptic integration observed in dendrites of cortical neurons: GRAPES (Group Responsibility for Adjusting the Propagation of Error Signals). GRAPES implements a weight-distribution dependent modulation of the error signal at each node of the neural network. We show that this biologically inspired mechanism leads to a systematic improvement of the convergence rate of the network, and substantially improves classification accuracy of ANNs and SNNs with both feedforward and recurrent architectures. Furthermore, we demonstrate that GRAPES supports performance scalability for models of increasing complexity and mitigates catastrophic forgetting by enabling networks to generalize to unseen tasks based on previously acquired knowledge. The local characteristics of GRAPES minimize the required memory resources, making it optimally suited for dedicated hardware implementations. Overall, our work indicates that reconciling neurophysiology insights with machine intelligence is key to boosting the performance of neural networks.

</p>
</details>

<details><summary><b>Robust Federated Learning by Mixture of Experts</b>
<a href="https://arxiv.org/abs/2104.11700">arxiv:2104.11700</a>
&#x1F4C8; 6 <br>
<p>Saeedeh Parsaeefard, Sayed Ehsan Etesami, Alberto Leon Garcia</p></summary>
<p>

**Abstract:** We present a novel weighted average model based on the mixture of experts (MoE) concept to provide robustness in Federated learning (FL) against the poisoned/corrupted/outdated local models. These threats along with the non-IID nature of data sets can considerably diminish the accuracy of the FL model. Our proposed MoE-FL setup relies on the trust between users and the server where the users share a portion of their public data sets with the server. The server applies a robust aggregation method by solving the optimization problem or the Softmax method to highlight the outlier cases and to reduce their adverse effect on the FL process. Our experiments illustrate that MoE-FL outperforms the performance of the traditional aggregation approach for high rate of poisoned data from attackers.

</p>
</details>

<details><summary><b>The Influence of Audio on Video Memorability with an Audio Gestalt Regulated Video Memorability System</b>
<a href="https://arxiv.org/abs/2104.11568">arxiv:2104.11568</a>
&#x1F4C8; 6 <br>
<p>Lorin Sweeney, Graham Healy, Alan F. Smeaton</p></summary>
<p>

**Abstract:** Memories are the tethering threads that tie us to the world, and memorability is the measure of their tensile strength. The threads of memory are spun from fibres of many modalities, obscuring the contribution of a single fibre to a thread's overall tensile strength. Unfurling these fibres is the key to understanding the nature of their interaction, and how we can ultimately create more meaningful media content. In this paper, we examine the influence of audio on video recognition memorability, finding evidence to suggest that it can facilitate overall video recognition memorability rich in high-level (gestalt) audio features. We introduce a novel multimodal deep learning-based late-fusion system that uses audio gestalt to estimate the influence of a given video's audio on its overall short-term recognition memorability, and selectively leverages audio features to make a prediction accordingly. We benchmark our audio gestalt based system on the Memento10k short-term video memorability dataset, achieving top-2 state-of-the-art results.

</p>
</details>

<details><summary><b>Class-Incremental Experience Replay for Continual Learning under Concept Drift</b>
<a href="https://arxiv.org/abs/2104.11861">arxiv:2104.11861</a>
&#x1F4C8; 5 <br>
<p>Łukasz Korycki, Bartosz Krawczyk</p></summary>
<p>

**Abstract:** Modern machine learning systems need to be able to cope with constantly arriving and changing data. Two main areas of research dealing with such scenarios are continual learning and data stream mining. Continual learning focuses on accumulating knowledge and avoiding forgetting, assuming information once learned should be stored. Data stream mining focuses on adaptation to concept drift and discarding outdated information, assuming that only the most recent data is relevant. While these two areas are mainly being developed in separation, they offer complementary views on the problem of learning from dynamic data. There is a need for unifying them, by offering architectures capable of both learning and storing new information, as well as revisiting and adapting to changes in previously seen concepts. We propose a novel continual learning approach that can handle both tasks. Our experience replay method is fueled by a centroid-driven memory storing diverse instances of incrementally arriving classes. This is enhanced with a reactive subspace buffer that tracks concept drift occurrences in previously seen classes and adapts clusters accordingly. The proposed architecture is thus capable of both remembering valid and forgetting outdated information, offering a holistic framework for continual learning under concept drift.

</p>
</details>

<details><summary><b>DeepCAT: Deep Category Representation for Query Understanding in E-commerce Search</b>
<a href="https://arxiv.org/abs/2104.11760">arxiv:2104.11760</a>
&#x1F4C8; 5 <br>
<p>Ali Ahmadvand, Surya Kallumadi, Faizan Javed, Eugene Agichtein</p></summary>
<p>

**Abstract:** Mapping a search query to a set of relevant categories in the product taxonomy is a significant challenge in e-commerce search for two reasons: 1) Training data exhibits severe class imbalance problem due to biased click behavior, and 2) queries with little customer feedback (e.g., tail queries) are not well-represented in the training set, and cause difficulties for query understanding. To address these problems, we propose a deep learning model, DeepCAT, which learns joint word-category representations to enhance the query understanding process. We believe learning category interactions helps to improve the performance of category mapping on minority classes, tail and torso queries. DeepCAT contains a novel word-category representation model that trains the category representations based on word-category co-occurrences in the training set. The category representation is then leveraged to introduce a new loss function to estimate the category-category co-occurrences for refining joint word-category embeddings. To demonstrate our model's effectiveness on minority categories and tail queries, we conduct two sets of experiments. The results show that DeepCAT reaches a 10% improvement on minority classes and a 7.1% improvement on tail queries over a state-of-the-art label embedding model. Our findings suggest a promising direction for improving e-commerce search by semantic modeling of taxonomy hierarchies.

</p>
</details>

<details><summary><b>Optimal Dynamic Regret in Exp-Concave Online Learning</b>
<a href="https://arxiv.org/abs/2104.11824">arxiv:2104.11824</a>
&#x1F4C8; 4 <br>
<p>Dheeraj Baby, Yu-Xiang Wang</p></summary>
<p>

**Abstract:** We consider the problem of the Zinkevich (2003)-style dynamic regret minimization in online learning with exp-concave losses. We show that whenever improper learning is allowed, a Strongly Adaptive online learner achieves the dynamic regret of $\tilde O^*(n^{1/3}C_n^{2/3} \vee 1)$ where $C_n$ is the total variation (a.k.a. path length) of the an arbitrary sequence of comparators that may not be known to the learner ahead of time. Achieving this rate was highly nontrivial even for squared losses in 1D where the best known upper bound was $O(\sqrt{nC_n} \vee \log n)$ (Yuan and Lamperski, 2019). Our new proof techniques make elegant use of the intricate structures of the primal and dual variables imposed by the KKT conditions and could be of independent interest. Finally, we apply our results to the classical statistical problem of locally adaptive non-parametric regression (Mammen, 1991; Donoho and Johnstone, 1998) and obtain a stronger and more flexible algorithm that do not require any statistical assumptions or any hyperparameter tuning.

</p>
</details>

<details><summary><b>Ensembles of GANs for synthetic training data generation</b>
<a href="https://arxiv.org/abs/2104.11797">arxiv:2104.11797</a>
&#x1F4C8; 4 <br>
<p>Gabriel Eilertsen, Apostolia Tsirikoglou, Claes Lundström, Jonas Unger</p></summary>
<p>

**Abstract:** Insufficient training data is a major bottleneck for most deep learning practices, not least in medical imaging where data is difficult to collect and publicly available datasets are scarce due to ethics and privacy. This work investigates the use of synthetic images, created by generative adversarial networks (GANs), as the only source of training data. We demonstrate that for this application, it is of great importance to make use of multiple GANs to improve the diversity of the generated data, i.e. to sufficiently cover the data distribution. While a single GAN can generate seemingly diverse image content, training on this data in most cases lead to severe over-fitting. We test the impact of ensembled GANs on synthetic 2D data as well as common image datasets (SVHN and CIFAR-10), and using both DCGANs and progressively growing GANs. As a specific use case, we focus on synthesizing digital pathology patches to provide anonymized training data.

</p>
</details>

<details><summary><b>Exact marginal prior distributions of finite Bayesian neural networks</b>
<a href="https://arxiv.org/abs/2104.11734">arxiv:2104.11734</a>
&#x1F4C8; 4 <br>
<p>Jacob A. Zavatone-Veth, Cengiz Pehlevan</p></summary>
<p>

**Abstract:** Bayesian neural networks are theoretically well-understood only in the infinite-width limit, where Gaussian priors over network weights yield Gaussian priors over network outputs. Recent work has suggested that finite Bayesian networks may outperform their infinite counterparts, but their non-Gaussian function space priors have been characterized only though perturbative approaches. Here, we derive exact solutions for the function space priors for individual input examples of a class of finite fully-connected feedforward Bayesian neural networks. For deep linear networks, the prior has a simple expression in terms of the Meijer $G$-function. The prior of a finite ReLU network is a mixture of the priors of linear networks of smaller widths, corresponding to different numbers of active units in each layer. Our results unify previous descriptions of finite network priors in terms of their tail decay and large-width behavior.

</p>
</details>

<details><summary><b>A Picture is Worth a Collaboration: Accumulating Design Knowledge for Computer-Vision-based Hybrid Intelligence Systems</b>
<a href="https://arxiv.org/abs/2104.11600">arxiv:2104.11600</a>
&#x1F4C8; 4 <br>
<p>Patrick Zschech, Jannis Walk, Kai Heinrich, Michael Vössing, Niklas Kühl</p></summary>
<p>

**Abstract:** Computer vision (CV) techniques try to mimic human capabilities of visual perception to support labor-intensive and time-consuming tasks like the recognition and localization of critical objects. Nowadays, CV increasingly relies on artificial intelligence (AI) to automatically extract useful information from images that can be utilized for decision support and business process automation. However, the focus of extant research is often exclusively on technical aspects when designing AI-based CV systems while neglecting socio-technical facets, such as trust, control, and autonomy. For this purpose, we consider the design of such systems from a hybrid intelligence (HI) perspective and aim to derive prescriptive design knowledge for CV-based HI systems. We apply a reflective, practice-inspired design science approach and accumulate design knowledge from six comprehensive CV projects. As a result, we identify four design-related mechanisms (i.e., automation, signaling, modification, and collaboration) that inform our derived meta-requirements and design principles. This can serve as a basis for further socio-technical research on CV-based HI systems.

</p>
</details>

<details><summary><b>Supervised Video Summarization via Multiple Feature Sets with Parallel Attention</b>
<a href="https://arxiv.org/abs/2104.11530">arxiv:2104.11530</a>
&#x1F4C8; 4 <br>
<p>Junaid Ahmed Ghauri, Sherzod Hakimov, Ralph Ewerth</p></summary>
<p>

**Abstract:** The assignment of importance scores to particular frames or (short) segments in a video is crucial for summarization, but also a difficult task. Previous work utilizes only one source of visual features. In this paper, we suggest a novel model architecture that combines three feature sets for visual content and motion to predict importance scores. The proposed architecture utilizes an attention mechanism before fusing motion features and features representing the (static) visual content, i.e., derived from an image classification model. Comprehensive experimental evaluations are reported for two well-known datasets, SumMe and TVSum. In this context, we identify methodological issues on how previous work used these benchmark datasets, and present a fair evaluation scheme with appropriate data splits that can be used in future work. When using static and motion features with parallel attention mechanism, we improve state-of-the-art results for SumMe, while being on par with the state of the art for the other dataset.

</p>
</details>

<details><summary><b>Time Series Forecasting via Learning Convolutionally Low-Rank Models</b>
<a href="https://arxiv.org/abs/2104.11510">arxiv:2104.11510</a>
&#x1F4C8; 4 <br>
<p>Guangcan Liu</p></summary>
<p>

**Abstract:** Recently, Liu and Zhang studied the rather challenging problem of time series forecasting from the perspective of compressed sensing. They proposed a no-learning method, named Convolution Nuclear Norm Minimization (CNNM), and proved that CNNM can exactly recover the future part of a series from its observed part, provided that the series is convolutionally low-rank. While impressive, the convolutional low-rankness condition may not be satisfied whenever the series is far from being seasonal, and is in fact brittle to the presence of trends and dynamics. This paper tries to approach the issues by integrating a learnable, orthonormal transformation into CNNM, with the purpose for converting the series of involute structures into regular signals of convolutionally low-rank. We prove that the resultant model, termed Learning-Based CNNM (LbCNNM), strictly succeeds in identifying the future part of a series, as long as the transform of the series is convolutionally low-rank. To learn proper transformations that may meet the required success conditions, we devise an interpretable method based on Principal Component Pursuit (PCP). Equipped with this learning method and some elaborate data argumentation skills, LbCNNM not only can handle well the major components of time series (including trends, seasonality and dynamics), but also can make use of the forecasts provided by some other forecasting methods; this means LbCNNM can be used as a general tool for model combination. Extensive experiments on 100,452 real-world time series from Time Series Data Library (TSDL) and M4 Competition (M4) demonstrate the superior performance of LbCNNM.

</p>
</details>

<details><summary><b>Probabilistic Rainfall Estimation from Automotive Lidar</b>
<a href="https://arxiv.org/abs/2104.11467">arxiv:2104.11467</a>
&#x1F4C8; 4 <br>
<p>Robin Karlsson, David Robert Wong, Kazunari Kawabata, Simon Thompson, Naoki Sakai</p></summary>
<p>

**Abstract:** Robust sensing and perception in adverse weather conditions remains one of the biggest challenges for realizing reliable autonomous vehicle mobility services. Prior work has established that rainfall rate is a useful measure for adversity of atmospheric weather conditions. This work presents a probabilistic hierarchical Bayesian model that infers rainfall rate from automotive lidar point cloud sequences with high accuracy and reliability. The model is a hierarchical mixture of expert model, or a probabilistic decision tree, with gating and expert nodes consisting of variational logistic and linear regression models. Experimental data used to train and evaluate the model is collected in a large-scale rainfall experiment facility from both stationary and moving vehicle platforms. The results show prediction accuracy comparable to the measurement resolution of a disdrometer, and the soundness and usefulness of the uncertainty estimation. The model achieves RMSE 2.42 mm/h after filtering out uncertain predictions. The error is comparable to the mean rainfall rate change of 3.5 mm/h between measurements. Model parameter studies show how predictive performance changes with tree depth, sampling duration, and crop box dimension. A second experiment demonstrate the predictability of higher rainfall above 300 mm/h using a different lidar sensor, demonstrating sensor independence.

</p>
</details>

<details><summary><b>Do All MobileNets Quantize Poorly? Gaining Insights into the Effect of Quantization on Depthwise Separable Convolutional Networks Through the Eyes of Multi-scale Distributional Dynamics</b>
<a href="https://arxiv.org/abs/2104.11849">arxiv:2104.11849</a>
&#x1F4C8; 3 <br>
<p>Stone Yun, Alexander Wong</p></summary>
<p>

**Abstract:** As the "Mobile AI" revolution continues to grow, so does the need to understand the behaviour of edge-deployed deep neural networks. In particular, MobileNets are the go-to family of deep convolutional neural networks (CNN) for mobile. However, they often have significant accuracy degradation under post-training quantization. While studies have introduced quantization-aware training and other methods to tackle this challenge, there is limited understanding into why MobileNets (and potentially depthwise-separable CNNs (DWSCNN) in general) quantize so poorly compared to other CNN architectures. Motivated to gain deeper insights into this phenomenon, we take a different strategy and study the multi-scale distributional dynamics of MobileNet-V1, a set of smaller DWSCNNs, and regular CNNs. Specifically, we investigate the impact of quantization on the weight and activation distributional dynamics as information propagates from layer to layer, as well as overall changes in distributional dynamics at the network level. This fine-grained analysis revealed significant dynamic range fluctuations and a "distributional mismatch" between channelwise and layerwise distributions in DWSCNNs that lead to increasing quantized degradation and distributional shift during information propagation. Furthermore, analysis of the activation quantization errors show that there is greater quantization error accumulation in DWSCNN compared to regular CNNs. The hope is that such insights can lead to innovative strategies for reducing such distributional dynamics changes and improve post-training quantization for mobile.

</p>
</details>

<details><summary><b>Eccentric Regularization: Minimizing Hyperspherical Energy without explicit projection</b>
<a href="https://arxiv.org/abs/2104.11610">arxiv:2104.11610</a>
&#x1F4C8; 3 <br>
<p>Xuefeng Li, Alan Blair</p></summary>
<p>

**Abstract:** Several regularization methods have recently been introduced which force the latent activations of an autoencoder or deep neural network to conform to either a Gaussian or hyperspherical distribution, or to minimize the implicit rank of the distribution in latent space. In the present work, we introduce a novel regularizing loss function which simulates a pairwise repulsive force between items and an attractive force of each item toward the origin. We show that minimizing this loss function in isolation achieves a hyperspherical distribution. Moreover, when used as a regularizing term, the scaling factor can be adjusted to allow greater flexibility and tolerance of eccentricity, thus allowing the latent variables to be stratified according to their relative importance, while still promoting diversity. We apply this method of Eccentric Regularization to an autoencoder, and demonstrate its effectiveness in image generation, representation learning and downstream classification tasks.

</p>
</details>

<details><summary><b>Consistent and symmetry preserving data-driven interface reconstruction for the level-set method</b>
<a href="https://arxiv.org/abs/2104.11578">arxiv:2104.11578</a>
&#x1F4C8; 3 <br>
<p>Aaron B. Buhendwa, Deniz A. Bezgin, Nikolaus Adams</p></summary>
<p>

**Abstract:** Recently, machine learning has been used to substitute parts of conventional computational fluid dynamics, e.g. the cell-face reconstruction in finite-volume solvers or the curvature computation in the Volume-of-Fluid (VOF) method. The latter showed improvements in terms of accuracy for coarsely resolved interfaces, however at the expense of convergence and symmetry. In this work, a combined approach is proposed, adressing the aforementioned shortcomings. We focus on interface reconstruction (IR) in the level-set method, i.e. the computation of the volume fraction and apertures. The combined model consists of a classification neural network, that chooses between the conventional (linear) IR and the neural network IR depending on the local interface resolution. The proposed approach improves accuracy for coarsely resolved interfaces and recovers the conventional IR for high resolutions, yielding first order overall convergence. Symmetry is preserved by mirroring and rotating the input level-set grid and subsequently averaging the predictions. The combined model is implemented into a CFD solver and demonstrated for two-phase flows. Furthermore, we provide details of floating point symmetric implementation and computational efficiency.

</p>
</details>

<details><summary><b>Weakly-supervised Multi-task Learning for Multimodal Affect Recognition</b>
<a href="https://arxiv.org/abs/2104.11560">arxiv:2104.11560</a>
&#x1F4C8; 3 <br>
<p>Wenliang Dai, Samuel Cahyawijaya, Yejin Bang, Pascale Fung</p></summary>
<p>

**Abstract:** Multimodal affect recognition constitutes an important aspect for enhancing interpersonal relationships in human-computer interaction. However, relevant data is hard to come by and notably costly to annotate, which poses a challenging barrier to build robust multimodal affect recognition systems. Models trained on these relatively small datasets tend to overfit and the improvement gained by using complex state-of-the-art models is marginal compared to simple baselines. Meanwhile, there are many different multimodal affect recognition datasets, though each may be small. In this paper, we propose to leverage these datasets using weakly-supervised multi-task learning to improve the generalization performance on each of them. Specifically, we explore three multimodal affect recognition tasks: 1) emotion recognition; 2) sentiment analysis; and 3) sarcasm recognition. Our experimental results show that multi-tasking can benefit all these tasks, achieving an improvement up to 2.9% accuracy and 3.3% F1-score. Furthermore, our method also helps to improve the stability of model performance. In addition, our analysis suggests that weak supervision can provide a comparable contribution to strong supervision if the tasks are highly correlated.

</p>
</details>

<details><summary><b>Generating abstractive summaries of Lithuanian news articles using a transformer model</b>
<a href="https://arxiv.org/abs/2105.03279">arxiv:2105.03279</a>
&#x1F4C8; 2 <br>
<p>Lukas Stankevičius, Mantas Lukoševičius</p></summary>
<p>

**Abstract:** In this work, we train the first monolingual Lithuanian transformer model on a relatively large corpus of Lithuanian news articles and compare various output decoding algorithms for abstractive news summarization. We achieve an average ROUGE-2 score 0.163, generated summaries are coherent and look impressive at first glance. However, some of them contain misleading information that is not so easy to spot. We describe all the technical details and share our trained model and accompanying code in an online open-source repository, as well as some characteristic samples of the generated summaries.

</p>
</details>

<details><summary><b>A Multi-Size Neural Network with Attention Mechanism for Answer Selection</b>
<a href="https://arxiv.org/abs/2105.03278">arxiv:2105.03278</a>
&#x1F4C8; 2 <br>
<p>Jie Huang</p></summary>
<p>

**Abstract:** Semantic matching is of central significance to the answer selection task which aims to select correct answers for a given question from a candidate answer pool. A useful method is to employ neural networks with attention to generate sentences representations in a way that information from pair sentences can mutually influence the computation of representations. In this work, an effective architecture,multi-size neural network with attention mechanism (AM-MSNN),is introduced into the answer selection task. This architecture captures more levels of language granularities in parallel, because of the various sizes of filters comparing with single-layer CNN and multi-layer CNNs. Meanwhile it extends the sentence representations by attention mechanism, thus containing more information for different types of questions. The empirical study on three various benchmark tasks of answer selection demonstrates the efficacy of the proposed model in all the benchmarks and its superiority over competitors. The experimental results show that (1) multi-size neural network (MSNN) is a more useful method to capture abstract features on different levels of granularities than single/multi-layer CNNs; (2) the attention mechanism (AM) is a better strategy to derive more informative representations; (3) AM-MSNN is a better architecture for the answer selection task for the moment.

</p>
</details>

<details><summary><b>Music Embedding: A Tool for Incorporating Music Theory into Computational Music Applications</b>
<a href="https://arxiv.org/abs/2104.11880">arxiv:2104.11880</a>
&#x1F4C8; 2 <br>
<p>SeyyedPooya HekmatiAthar, Mohd Anwar</p></summary>
<p>

**Abstract:** Advancements in the digital technologies have enabled researchers to develop a variety of Computational Music applications. Such applications are required to capture, process, and generate data related to music. Therefore, it is important to digitally represent music in a music theoretic and concise manner. Existing approaches for representing music are ineffective in terms of utilizing music theory. In this paper, we address the disjoint of music theory and computational music by developing an opensource representation tool based on music theory. Through the wide range of use cases, we run an analysis on the classical music pieces to show the usefulness of the developed music embedding.

</p>
</details>

<details><summary><b>Selecting a number of voters for a voting ensemble</b>
<a href="https://arxiv.org/abs/2104.11833">arxiv:2104.11833</a>
&#x1F4C8; 2 <br>
<p>Eric Bax</p></summary>
<p>

**Abstract:** For a voting ensemble that selects an odd-sized subset of the ensemble classifiers at random for each example, applies them to the example, and returns the majority vote, we show that any number of voters may minimize the error rate over an out-of-sample distribution. The optimal number of voters depends on the out-of-sample distribution of the number of classifiers in error. To select a number of voters to use, estimating that distribution then inferring error rates for numbers of voters gives lower-variance estimates than directly estimating those error rates.

</p>
</details>

<details><summary><b>Partitioning sparse deep neural networks for scalable training and inference</b>
<a href="https://arxiv.org/abs/2104.11805">arxiv:2104.11805</a>
&#x1F4C8; 2 <br>
<p>Gunduz Vehbi Demirci, Hakan Ferhatosmanoglu</p></summary>
<p>

**Abstract:** The state-of-the-art deep neural networks (DNNs) have significant computational and data management requirements. The size of both training data and models continue to increase. Sparsification and pruning methods are shown to be effective in removing a large fraction of connections in DNNs. The resulting sparse networks present unique challenges to further improve the computational efficiency of training and inference in deep learning. Both the feedforward (inference) and backpropagation steps in stochastic gradient descent (SGD) algorithm for training sparse DNNs involve consecutive sparse matrix-vector multiplications (SpMVs). We first introduce a distributed-memory parallel SpMV-based solution for the SGD algorithm to improve its scalability. The parallelization approach is based on row-wise partitioning of weight matrices that represent neuron connections between consecutive layers. We then propose a novel hypergraph model for partitioning weight matrices to reduce the total communication volume and ensure computational load-balance among processors. Experiments performed on sparse DNNs demonstrate that the proposed solution is highly efficient and scalable. By utilizing the proposed matrix partitioning scheme, the performance of our solution is further improved significantly.

</p>
</details>

<details><summary><b>Establishing phone-pair co-usage by comparing mobility patterns</b>
<a href="https://arxiv.org/abs/2104.11683">arxiv:2104.11683</a>
&#x1F4C8; 2 <br>
<p>Wauter Bosma, Sander Dalm, Erwin van Eijk, Rachid el Harchaoui, Edwin Rijgersberg, Hannah Tereza Tops, Alle Veenstra, Rolf Ypma</p></summary>
<p>

**Abstract:** In forensic investigations it is often of value to establish whether two phones were used by the same person during a given time period. We present a method that uses time and location of cell tower registrations of mobile phones to assess the strength of evidence that any pair of phones were used by the same person. The method is transparent as it uses logistic regression to discriminate between the hypotheses of same and different user, and a standard kernel density estimation to quantify the weight of evidence in terms of a likelihood ratio. We further add to previous theoretical work by training and validating our method on real world data, paving the way for application in practice. The method shows good performance under different modeling choices and robustness under lower quantity or quality of data. We discuss practical usage in court.

</p>
</details>

<details><summary><b>Optimizing small BERTs trained for German NER</b>
<a href="https://arxiv.org/abs/2104.11559">arxiv:2104.11559</a>
&#x1F4C8; 2 <br>
<p>Jochen Zöllner, Konrad Sperfeld, Christoph Wick, Roger Labahn</p></summary>
<p>

**Abstract:** Currently, the most widespread neural network architecture for training language models is the so called BERT which led to improvements in various Natural Language Processing (NLP) tasks. In general, the larger the number of parameters in a BERT model, the better the results obtained in these NLP tasks. Unfortunately, the memory consumption and the training duration drastically increases with the size of these models. In this article, we investigate various training techniques of smaller BERT models: We combine different methods from other BERT variants like ALBERT, RoBERTa, and relative positional encoding. In addition, we propose two new fine-tuning modifications leading to better performance: Class-Start-End tagging and a modified form of Linear Chain Conditional Random Fields. Furthermore, we introduce Whole-Word Attention which reduces BERTs memory usage and leads to a small increase in performance compared to classical Multi-Head-Attention. We evaluate these techniques on five public German Named Entity Recognition (NER) tasks of which two are introduced by this article.

</p>
</details>

<details><summary><b>Autonomous Vehicles that Alert Humans to Take-Over Controls: Modeling with Real-World Data</b>
<a href="https://arxiv.org/abs/2104.11489">arxiv:2104.11489</a>
&#x1F4C8; 2 <br>
<p>Akshay Rangesh, Nachiket Deo, Ross Greer, Pujitha Gunaratne, Mohan M. Trivedi</p></summary>
<p>

**Abstract:** With increasing automation in passenger vehicles, the study of safe and smooth occupant-vehicle interaction and control transitions is key. In this study, we focus on the development of contextual, semantically meaningful representations of the driver state, which can then be used to determine the appropriate timing and conditions for transfer of control between driver and vehicle. To this end, we conduct a large-scale real-world controlled data study where participants are instructed to take-over control from an autonomous agent under different driving conditions while engaged in a variety of distracting activities. These take-over events are captured using multiple driver-facing cameras, which when labelled result in a dataset of control transitions and their corresponding take-over times (TOTs). We then develop and train TOT models that operate sequentially on mid to high-level features produced by computer vision algorithms operating on different driver-facing camera views. The proposed TOT model produces continuous predictions of take-over times without delay, and shows promising qualitative and quantitative results in complex real-world scenarios.

</p>
</details>

<details><summary><b>Birds of a Feather Flock Together: A Close Look at Cooperation Emergence via Multi-Agent RL</b>
<a href="https://arxiv.org/abs/2104.11455">arxiv:2104.11455</a>
&#x1F4C8; 2 <br>
<p>Heng Dong, Tonghan Wang, Jiayuan Liu, Chi Han, Chongjie Zhang</p></summary>
<p>

**Abstract:** How cooperation emerges is a long-standing and interdisciplinary problem. Game-theoretical studies on social dilemmas reveal that altruistic incentives are critical to the emergence of cooperation but their analyses are limited to stateless games. For more realistic scenarios, multi-agent reinforcement learning has been used to study sequential social dilemmas (SSDs). Recent works show that learning to incentivize other agents can promote cooperation in SSDs. However, we find that, with these incentivizing mechanisms, the team cooperation level does not converge and regularly oscillates between cooperation and defection during learning. We show that a second-order social dilemma resulting from the incentive mechanisms is the main reason for such fragile cooperation. We formally analyze the dynamics of second-order social dilemmas and find that a typical tendency of humans, called homophily, provides a promising solution. We propose a novel learning framework to encourage homophilic incentives and show that it achieves stable cooperation in both SSDs of public goods and tragedy of the commons.

</p>
</details>

<details><summary><b>Regularized Nonlinear Regression for Simultaneously Selecting and Estimating Key Model Parameters</b>
<a href="https://arxiv.org/abs/2104.11426">arxiv:2104.11426</a>
&#x1F4C8; 2 <br>
<p>Kyubaek Yoon, Hojun You, Wei-Ying Wu, Chae Young Lim, Jongeun Choi, Connor Boss, Ahmed Ramadan, John M. Popovich Jr., Jacek Cholewicki, N. Peter Reeves, Clark J. Radcliffe</p></summary>
<p>

**Abstract:** In system identification, estimating parameters of a model using limited observations results in poor identifiability. To cope with this issue, we propose a new method to simultaneously select and estimate sensitive parameters as key model parameters and fix the remaining parameters to a set of typical values. Our method is formulated as a nonlinear least squares estimator with L1-regularization on the deviation of parameters from a set of typical values. First, we provide consistency and oracle properties of the proposed estimator as a theoretical foundation. Second, we provide a novel approach based on Levenberg-Marquardt optimization to numerically find the solution to the formulated problem. Third, to show the effectiveness, we present an application identifying a biomechanical parametric model of a head position tracking task for 10 human subjects from limited data. In a simulation study, the variances of estimated parameters are decreased by 96.1% as compared to that of the estimated parameters without L1-regularization. In an experimental study, our method improves the model interpretation by reducing the number of parameters to be estimated while maintaining variance accounted for (VAF) at above 82.5%. Moreover, the variances of estimated parameters are reduced by 71.1% as compared to that of the estimated parameters without L1-regularization. Our method is 54 times faster than the standard simplex-based optimization to solve the regularized nonlinear regression.

</p>
</details>

<details><summary><b>Predicting Distant Metastases in Soft-Tissue Sarcomas from PET-CT scans using Constrained Hierarchical Multi-Modality Feature Learning</b>
<a href="https://arxiv.org/abs/2104.11416">arxiv:2104.11416</a>
&#x1F4C8; 2 <br>
<p>Yige Peng, Lei Bi, Ashnil Kumar, Michael Fulham, Dagan Feng, Jinman Kim</p></summary>
<p>

**Abstract:** Distant metastases (DM) refer to the dissemination of tumors, usually, beyond the organ where the tumor originated. They are the leading cause of death in patients with soft-tissue sarcomas (STSs). Positron emission tomography-computed tomography (PET-CT) is regarded as the imaging modality of choice for the management of STSs. It is difficult to determine from imaging studies which STS patients will develop metastases. 'Radiomics' refers to the extraction and analysis of quantitative features from medical images and it has been employed to help identify such tumors. The state-of-the-art in radiomics is based on convolutional neural networks (CNNs). Most CNNs are designed for single-modality imaging data (CT or PET alone) and do not exploit the information embedded in PET-CT where there is a combination of an anatomical and functional imaging modality. Furthermore, most radiomic methods rely on manual input from imaging specialists for tumor delineation, definition and selection of radiomic features. This approach, however, may not be scalable to tumors with complex boundaries and where there are multiple other sites of disease. We outline a new 3D CNN to help predict DM in STS patients from PET-CT data. The 3D CNN uses a constrained feature learning module and a hierarchical multi-modality feature learning module that leverages the complementary information from the modalities to focus on semantically important regions. Our results on a public PET-CT dataset of STS patients show that multi-modal information improves the ability to identify those patients who develop DM. Further our method outperformed all other related state-of-the-art methods.

</p>
</details>

<details><summary><b>Learning Hamiltonian dynamics by reservoir computer</b>
<a href="https://arxiv.org/abs/2104.14474">arxiv:2104.14474</a>
&#x1F4C8; 1 <br>
<p>Han Zhang, Huawei Fan, Liang Wang, Xingang Wang</p></summary>
<p>

**Abstract:** Reconstructing the KAM dynamics diagram of Hamiltonian system from the time series of a limited number of parameters is an outstanding question in nonlinear science, especially when the Hamiltonian governing the system dynamics are unknown. Here, we demonstrate that this question can be addressed by the machine learning approach knowing as reservoir computer (RC). Specifically, we show that without prior knowledge about the Hamilton's equations of motion, the trained RC is able to not only predict the short-term evolution of the system state, but also replicate the long-term ergodic properties of the system dynamics. Furthermore, by the architecture of parameter-aware RC, we also show that the RC trained by the time series acquired at a handful parameters is able to reconstruct the entire KAM dynamics diagram with a high precision by tuning a control parameter externally. The feasibility and efficiency of the learning techniques are demonstrated in two classical nonlinear Hamiltonian systems, namely the double-pendulum oscillator and the standard map. Our study indicates that, as a complex dynamical system, RC is able to learn from data the Hamiltonian.

</p>
</details>

<details><summary><b>Predicting Adversary Lateral Movement Patterns with Deep Learning</b>
<a href="https://arxiv.org/abs/2104.13195">arxiv:2104.13195</a>
&#x1F4C8; 1 <br>
<p>Nathan Danneman, James Hyde</p></summary>
<p>

**Abstract:** This paper develops a predictive model for which host, in an enterprise network, an adversary is likely to compromise next in the course of a campaign. Such a model might support dynamic monitoring or defenses. We generate data for this model using simulated networks, with hosts, users, and adversaries as first-class entities. We demonstrate the predictive accuracy of the model on out-of-sample simulated data, and validate the findings against data captured from a Red Team event on a live enterprise network

</p>
</details>

<details><summary><b>Scalable Microservice Forensics and Stability Assessment Using Variational Autoencoders</b>
<a href="https://arxiv.org/abs/2104.13193">arxiv:2104.13193</a>
&#x1F4C8; 1 <br>
<p>Prakhar Sharma, Phillip Porras, Steven Cheung, James Carpenter, Vinod Yegneswaran</p></summary>
<p>

**Abstract:** We present a deep learning based approach to containerized application runtime stability analysis, and an intelligent publishing algorithm that can dynamically adjust the depth of process-level forensics published to a backend incident analysis repository. The approach applies variational autoencoders (VAEs) to learn the stable runtime patterns of container images, and then instantiates these container-specific VAEs to implement stability detection and adaptive forensics publishing. In performance comparisons using a 50-instance container workload, a VAE-optimized service versus a conventional eBPF-based forensic publisher demonstrates 2 orders of magnitude (OM) CPU performance improvement, a 3 OM reduction in network transport volume, and a 4 OM reduction in Elasticsearch storage costs. We evaluate the VAE-based stability detection technique against two attacks, CPUMiner and HTTP-flood attack, finding that it is effective in isolating both anomalies. We believe this technique provides a novel approach to integrating fine-grained process monitoring and digital-forensic services into large container ecosystems that today simply cannot be monitored by conventional techniques

</p>
</details>

<details><summary><b>High-dimensional near-optimal experiment design for drug discovery via Bayesian sparse sampling</b>
<a href="https://arxiv.org/abs/2104.11834">arxiv:2104.11834</a>
&#x1F4C8; 1 <br>
<p>Hannes Eriksson, Christos Dimitrakakis, Lars Carlsson</p></summary>
<p>

**Abstract:** We study the problem of performing automated experiment design for drug screening through Bayesian inference and optimisation. In particular, we compare and contrast the behaviour of linear-Gaussian models and Gaussian processes, when used in conjunction with upper confidence bound algorithms, Thompson sampling, or bounded horizon tree search. We show that non-myopic sophisticated exploration techniques using sparse tree search have a distinct advantage over methods such as Thompson sampling or upper confidence bounds in this setting. We demonstrate the significant superiority of the approach over existing and synthetic datasets of drug toxicity.

</p>
</details>

<details><summary><b>Realising Active Inference in Variational Message Passing: the Outcome-blind Certainty Seeker</b>
<a href="https://arxiv.org/abs/2104.11798">arxiv:2104.11798</a>
&#x1F4C8; 1 <br>
<p>Théophile Champion, Marek Grześ, Howard Bowman</p></summary>
<p>

**Abstract:** Active inference is a state-of-the-art framework in neuroscience that offers a unified theory of brain function. It is also proposed as a framework for planning in AI. Unfortunately, the complex mathematics required to create new models -- can impede application of active inference in neuroscience and AI research. This paper addresses this problem by providing a complete mathematical treatment of the active inference framework -- in discrete time and state spaces -- and the derivation of the update equations for any new model. We leverage the theoretical connection between active inference and variational message passing as describe by John Winn and Christopher M. Bishop in 2005. Since, variational message passing is a well-defined methodology for deriving Bayesian belief update equations, this paper opens the door to advanced generative models for active inference. We show that using a fully factorized variational distribution simplifies the expected free energy -- that furnishes priors over policies -- so that agents seek unambiguous states. Finally, we consider future extensions that support deep tree searches for sequential policy optimisation -- based upon structure learning and belief propagation.

</p>
</details>

<details><summary><b>On the Role of Sensor Fusion for Object Detection in Future Vehicular Networks</b>
<a href="https://arxiv.org/abs/2104.11785">arxiv:2104.11785</a>
&#x1F4C8; 1 <br>
<p>Valentina Rossi, Paolo Testolina, Marco Giordani, Michele Zorzi</p></summary>
<p>

**Abstract:** Fully autonomous driving systems require fast detection and recognition of sensitive objects in the environment. In this context, intelligent vehicles should share their sensor data with computing platforms and/or other vehicles, to detect objects beyond their own sensors' fields of view. However, the resulting huge volumes of data to be exchanged can be challenging to handle for standard communication technologies. In this paper, we evaluate how using a combination of different sensors affects the detection of the environment in which the vehicles move and operate. The final objective is to identify the optimal setup that would minimize the amount of data to be distributed over the channel, with negligible degradation in terms of object detection accuracy. To this aim, we extend an already available object detection algorithm so that it can consider, as an input, camera images, LiDAR point clouds, or a combination of the two, and compare the accuracy performance of the different approaches using two realistic datasets. Our results show that, although sensor fusion always achieves more accurate detections, LiDAR only inputs can obtain similar results for large objects while mitigating the burden on the channel.

</p>
</details>

<details><summary><b>Active Learning of Sequential Transducers with Side Information about the Domain</b>
<a href="https://arxiv.org/abs/2104.11758">arxiv:2104.11758</a>
&#x1F4C8; 1 <br>
<p>Raphaël Berthon, Adrien Boiret, Guillermo A. Perez, Jean-François Raskin</p></summary>
<p>

**Abstract:** Active learning is a setting in which a student queries a teacher, through membership and equivalence queries, in order to learn a language. Performance on these algorithms is often measured in the number of queries required to learn a target, with an emphasis on costly equivalence queries. In graybox learning, the learning process is accelerated by foreknowledge of some information on the target. Here, we consider graybox active learning of subsequential string transducers, where a regular overapproximation of the domain is known by the student. We show that there exists an algorithm using string equation solvers that uses this knowledge to learn subsequential string transducers with a better guarantee on the required number of equivalence queries than classical active learning.

</p>
</details>

<details><summary><b>Automating Cyber Threat Hunting Using NLP, Automated Query Generation, and Genetic Perturbation</b>
<a href="https://arxiv.org/abs/2104.11576">arxiv:2104.11576</a>
&#x1F4C8; 1 <br>
<p>Prakruthi Karuna, Erik Hemberg, Una-May O'Reilly, Nick Rutar</p></summary>
<p>

**Abstract:** Scaling the cyber hunt problem poses several key technical challenges. Detecting and characterizing cyber threats at scale in large enterprise networks is hard because of the vast quantity and complexity of the data that must be analyzed as adversaries deploy varied and evolving tactics to accomplish their goals. There is a great need to automate all aspects, and, indeed, the workflow of cyber hunting. AI offers many ways to support this. We have developed the WILEE system that automates cyber threat hunting by translating high-level threat descriptions into many possible concrete implementations. Both the (high-level) abstract and (low-level) concrete implementations are represented using a custom domain specific language (DSL). WILEE uses the implementations along with other logic, also written in the DSL, to automatically generate queries to confirm (or refute) any hypotheses tied to the potential adversarial workflows represented at various layers of abstraction.

</p>
</details>

<details><summary><b>Research on the Detection Method of Breast Cancer Deep Convolutional Neural Network Based on Computer Aid</b>
<a href="https://arxiv.org/abs/2104.11551">arxiv:2104.11551</a>
&#x1F4C8; 1 <br>
<p>Mengfan Li</p></summary>
<p>

**Abstract:** Traditional breast cancer image classification methods require manual extraction of features from medical images, which not only require professional medical knowledge, but also have problems such as time-consuming and labor-intensive and difficulty in extracting high-quality features. Therefore, the paper proposes a computer-based feature fusion Convolutional neural network breast cancer image classification and detection method. The paper pre-trains two convolutional neural networks with different structures, and then uses the convolutional neural network to automatically extract the characteristics of features, fuse the features extracted from the two structures, and finally use the classifier classifies the fused features. The experimental results show that the accuracy of this method in the classification of breast cancer image data sets is 89%, and the classification accuracy of breast cancer images is significantly improved compared with traditional methods.

</p>
</details>

<details><summary><b>Learning from Ambiguous Labels for Lung Nodule Malignancy Prediction</b>
<a href="https://arxiv.org/abs/2104.11436">arxiv:2104.11436</a>
&#x1F4C8; 1 <br>
<p>Zehui Liao, Yutong Xie, Shishuai Hu, Yong Xia</p></summary>
<p>

**Abstract:** Lung nodule malignancy prediction is an essential step in the early diagnosis of lung cancer. Besides the difficulties commonly discussed, the challenges of this task also come from the ambiguous labels provided by annotators, since deep learning models may learn, even amplify, the bias embedded in them. In this paper, we propose a multi-view "divide-and-rule" (MV-DAR) model to learn from both reliable and ambiguous annotations for lung nodule malignancy prediction. According to the consistency and reliability of their annotations, we divide nodules into three sets: a consistent and reliable set (CR-Set), an inconsistent set (IC-Set), and a low reliable set (LR-Set). The nodule in IC-Set is annotated by multiple radiologists inconsistently, and the nodule in LR-Set is annotated by only one radiologist. The proposed MV-DAR contains three DAR submodels to characterize a lung nodule from three orthographic views. Each DAR consists of a prediction network (Prd-Net), a counterfactual network (CF-Net), and a low reliable network (LR-Net), learning on CR-Set, IC-Set, and LR-Set, respectively. The image representation ability learned by CF-Net and LR-Net is then transferred to Prd-Net by negative-attention module (NA-Module) and consistent-attention module (CA-Module), aiming to boost the prediction ability of Prd-Net. The MV-DAR model has been evaluated on the LIDC-IDRI dataset and LUNGx dataset. Our results indicate not only the effectiveness of the proposed MV-DAR model in learning from ambiguous labels but also its superiority over present noisy label-learning models in lung nodule malignancy prediction.

</p>
</details>

<details><summary><b>UnrealROX+: An Improved Tool for Acquiring Synthetic Data from Virtual 3D Environments</b>
<a href="https://arxiv.org/abs/2104.11776">arxiv:2104.11776</a>
&#x1F4C8; 0 <br>
<p>Pablo Martinez-Gonzalez, Sergiu Oprea, John Alejandro Castro-Vargas, Alberto Garcia-Garcia, Sergio Orts-Escolano, Jose Garcia-Rodriguez, Markus Vincze</p></summary>
<p>

**Abstract:** Synthetic data generation has become essential in last years for feeding data-driven algorithms, which surpassed traditional techniques performance in almost every computer vision problem. Gathering and labelling the amount of data needed for these data-hungry models in the real world may become unfeasible and error-prone, while synthetic data give us the possibility of generating huge amounts of data with pixel-perfect annotations. However, most synthetic datasets lack from enough realism in their rendered images. In that context UnrealROX generation tool was presented in 2019, allowing to generate highly realistic data, at high resolutions and framerates, with an efficient pipeline based on Unreal Engine, a cutting-edge videogame engine. UnrealROX enabled robotic vision researchers to generate realistic and visually plausible data with full ground truth for a wide variety of problems such as class and instance semantic segmentation, object detection, depth estimation, visual grasping, and navigation. Nevertheless, its workflow was very tied to generate image sequences from a robotic on-board camera, making hard to generate data for other purposes. In this work, we present UnrealROX+, an improved version of UnrealROX where its decoupled and easy-to-use data acquisition system allows to quickly design and generate data in a much more flexible and customizable way. Moreover, it is packaged as an Unreal plug-in, which makes it more comfortable to use with already existing Unreal projects, and it also includes new features such as generating albedo or a Python API for interacting with the virtual environment from Deep Learning frameworks.

</p>
</details>

<details><summary><b>CapillaryNet: An Automated System to Quantify Skin Capillary Density and Red Blood Cell Velocity from Handheld Vital Microscopy</b>
<a href="https://arxiv.org/abs/2104.11574">arxiv:2104.11574</a>
&#x1F4C8; 0 <br>
<p>Maged Helmy, Anastasiya Dykyy, Tuyen Trung Truong, Paulo Ferreira, Eric Jul</p></summary>
<p>

**Abstract:** Capillaries are the smallest vessels in the body responsible for the delivery of oxygen and nutrients to the surrounding cells. Various diseases have been shown to alter the density of nutritive capillaries and the flow velocity of erythrocytes. In previous studies, capillary density and flow velocity have been assessed manually by trained specialists. Manual analysis of a standard 20-second long microvascular video takes on average 20 minutes and requires extensive training. Several studies have reported that manual analysis hinders the application of microvascular microscopy in a clinical setting. In this paper, we present a fully automated state-of-the-art system, called CapillaryNet, that can quantify skin nutritive capillary density and red blood cell velocity from handheld microscopy videos. Moreover, CapillaryNet measures several novel microvascular parameters that researchers were previously unable to quantify, i.e. capillary hematocrit and Intra-capillary flow velocity heterogeneity. Our system has been used to analyze skin microcirculation videos from various patient groups (COVID-19, pancreatitis, and acute heart diseases). Our proposed system excels from existing capillary detection systems as it combines the speed of traditional computer vision algorithms and the accuracy of convolutional neural networks.

</p>
</details>


[Next Page](2021/2021-04/2021-04-22.md)
