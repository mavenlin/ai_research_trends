Prev: [2022.06.25]({{ '/2022/06/25/2022.06.25.html' | relative_url }})  Next: [2022.06.27]({{ '/2022/06/27/2022.06.27.html' | relative_url }})
{% raw %}
## Summary for 2022-06-26, created on 2022-07-06


<details><summary><b>A General Recipe for Likelihood-free Bayesian Optimization</b>
<a href="https://arxiv.org/abs/2206.13035">arxiv:2206.13035</a>
&#x1F4C8; 10 <br>
<p>Jiaming Song, Lantao Yu, Willie Neiswanger, Stefano Ermon</p></summary>
<p>

**Abstract:** The acquisition function, a critical component in Bayesian optimization (BO), can often be written as the expectation of a utility function under a surrogate model. However, to ensure that acquisition functions are tractable to optimize, restrictions must be placed on the surrogate model and utility function. To extend BO to a broader class of models and utilities, we propose likelihood-free BO (LFBO), an approach based on likelihood-free inference. LFBO directly models the acquisition function without having to separately perform inference with a probabilistic surrogate model. We show that computing the acquisition function in LFBO can be reduced to optimizing a weighted classification problem, where the weights correspond to the utility being chosen. By choosing the utility function for expected improvement (EI), LFBO outperforms various state-of-the-art black-box optimization methods on several real-world optimization problems. LFBO can also effectively leverage composite structures of the objective function, which further improves its regret by several orders of magnitude.

</p>
</details>

<details><summary><b>Detecting Schizophrenia with 3D Structural Brain MRI Using Deep Learning</b>
<a href="https://arxiv.org/abs/2206.12980">arxiv:2206.12980</a>
&#x1F4C8; 8 <br>
<p>Junhao Zhang, Vishwanatha M. Rao, Ye Tian, Yanting Yang, Nicolas Acosta, Zihan Wan, Pin-Yu Lee, Chloe Zhang, Lawrence S. Kegeles, Scott A. Small, Jia Guo</p></summary>
<p>

**Abstract:** Schizophrenia is a chronic neuropsychiatric disorder that causes distinct structural alterations within the brain. We hypothesize that deep learning applied to a structural neuroimaging dataset could detect disease-related alteration and improve classification and diagnostic accuracy. We tested this hypothesis using a single, widely available, and conventional T1-weighted MRI scan, from which we extracted the 3D whole-brain structure using standard post-processing methods. A deep learning model was then developed, optimized, and evaluated on three open datasets with T1-weighted MRI scans of patients with schizophrenia. Our proposed model outperformed the benchmark model, which was also trained with structural MR images using a 3D CNN architecture. Our model is capable of almost perfectly (area under the ROC curve = 0.987) distinguishing schizophrenia patients from healthy controls on unseen structural MRI scans. Regional analysis localized subcortical regions and ventricles as the most predictive brain regions. Subcortical structures serve a pivotal role in cognitive, affective, and social functions in humans, and structural abnormalities of these regions have been associated with schizophrenia. Our finding corroborates that schizophrenia is associated with widespread alterations in subcortical brain structure and the subcortical structural information provides prominent features in diagnostic classification. Together, these results further demonstrate the potential of deep learning to improve schizophrenia diagnosis and identify its structural neuroimaging signatures from a single, standard T1-weighted brain MRI.

</p>
</details>

<details><summary><b>Adversarially Robust Learning of Real-Valued Functions</b>
<a href="https://arxiv.org/abs/2206.12977">arxiv:2206.12977</a>
&#x1F4C8; 8 <br>
<p>Idan Attias, Steve Hanneke</p></summary>
<p>

**Abstract:** We study robustness to test-time adversarial attacks in the regression setting with $\ell_p$ losses and arbitrary perturbation sets. We address the question of which function classes are PAC learnable in this setting. We show that classes of finite fat-shattering dimension are learnable. Moreover, for convex function classes, they are even properly learnable. In contrast, some non-convex function classes provably require improper learning algorithms. We also discuss extensions to agnostic learning. Our main technique is based on a construction of an adversarially robust sample compression scheme of a size determined by the fat-shattering dimension.

</p>
</details>

<details><summary><b>Probabilistic PolarGMM: Unsupervised Cluster Learning of Very Noisy Projection Images of Unknown Pose</b>
<a href="https://arxiv.org/abs/2206.12959">arxiv:2206.12959</a>
&#x1F4C8; 8 <br>
<p>Supawit Chockchowwat, Chandrajit L. Bajaj</p></summary>
<p>

**Abstract:** A crucial step in single particle analysis (SPA) of cryogenic electron microscopy (Cryo-EM), 2D classification and alignment takes a collection of noisy particle images to infer orientations and group similar images together. Averaging these aligned and clustered noisy images produces a set of clean images, ready for further analysis such as 3D reconstruction. Fourier-Bessel steerable principal component analysis (FBsPCA) enables an efficient, adaptable, low-rank rotation operator. We extend the FBsPCA to additionally handle translations. In this extended FBsPCA representation, we use a probabilistic polar-coordinate Gaussian mixture model to learn soft clusters in an unsupervised fashion using an expectation maximization (EM) algorithm. The obtained rotational clusters are thus additionally robust to the presence of pairwise alignment imperfections. Multiple benchmarks from simulated Cryo-EM datasets show probabilistic PolarGMM's improved performance in comparisons with standard single-particle Cryo-EM tools, EMAN2 and RELION, in terms of various clustering metrics and alignment errors.

</p>
</details>

<details><summary><b>Class Impression for Data-free Incremental Learning</b>
<a href="https://arxiv.org/abs/2207.00005">arxiv:2207.00005</a>
&#x1F4C8; 7 <br>
<p>Sana Ayromlou, Purang Abolmaesumi, Teresa Tsang, Xiaoxiao Li</p></summary>
<p>

**Abstract:** Standard deep learning-based classification approaches require collecting all samples from all classes in advance and are trained offline. This paradigm may not be practical in real-world clinical applications, where new classes are incrementally introduced through the addition of new data. Class incremental learning is a strategy allowing learning from such data. However, a major challenge is catastrophic forgetting, i.e., performance degradation on previous classes when adapting a trained model to new data. Prior methodologies to alleviate this challenge save a portion of training data require perpetual storage of such data that may introduce privacy issues. Here, we propose a novel data-free class incremental learning framework that first synthesizes data from the model trained on previous classes to generate a \ours. Subsequently, it updates the model by combining the synthesized data with new class data. Furthermore, we incorporate a cosine normalized Cross-entropy loss to mitigate the adverse effects of the imbalance, a margin loss to increase separation among previous classes and new ones, and an intra-domain contrastive loss to generalize the model trained on the synthesized data to real data. We compare our proposed framework with state-of-the-art methods in class incremental learning, where we demonstrate improvement in accuracy for the classification of 11,062 echocardiography cine series of patients.

</p>
</details>

<details><summary><b>Towards Harnessing Feature Embedding for Robust Learning with Noisy Labels</b>
<a href="https://arxiv.org/abs/2206.13025">arxiv:2206.13025</a>
&#x1F4C8; 5 <br>
<p>Chuang Zhang, Li Shen, Jian Yang, Chen Gong</p></summary>
<p>

**Abstract:** The memorization effect of deep neural networks (DNNs) plays a pivotal role in recent label noise learning methods. To exploit this effect, the model prediction-based methods have been widely adopted, which aim to exploit the outputs of DNNs in the early stage of learning to correct noisy labels. However, we observe that the model will make mistakes during label prediction, resulting in unsatisfactory performance. By contrast, the produced features in the early stage of learning show better robustness. Inspired by this observation, in this paper, we propose a novel feature embedding-based method for deep learning with label noise, termed LabEl NoiseDilution (LEND). To be specific, we first compute a similarity matrix based on current embedded features to capture the local structure of training data. Then, the noisy supervision signals carried by mislabeled data are overwhelmed by nearby correctly labeled ones (\textit{i.e.}, label noise dilution), of which the effectiveness is guaranteed by the inherent robustness of feature embedding. Finally, the training data with diluted labels are further used to train a robust classifier. Empirically, we conduct extensive experiments on both synthetic and real-world noisy datasets by comparing our LEND with several representative robust learning approaches. The results verify the effectiveness of our LEND.

</p>
</details>

<details><summary><b>FlowX: Towards Explainable Graph Neural Networks via Message Flows</b>
<a href="https://arxiv.org/abs/2206.12987">arxiv:2206.12987</a>
&#x1F4C8; 5 <br>
<p>Shurui Gui, Hao Yuan, Jie Wang, Qicheng Lao, Kang Li, Shuiwang Ji</p></summary>
<p>

**Abstract:** We investigate the explainability of graph neural networks (GNNs) as a step towards elucidating their working mechanisms. While most current methods focus on explaining graph nodes, edges, or features, we argue that, as the inherent functional mechanism of GNNs, message flows are more natural for performing explainability. To this end, we propose a novel method here, known as FlowX, to explain GNNs by identifying important message flows. To quantify the importance of flows, we propose to follow the philosophy of Shapley values from cooperative game theory. To tackle the complexity of computing all coalitions' marginal contributions, we propose an approximation scheme to compute Shapley-like values as initial assessments of further redistribution training. We then propose a learning algorithm to train flow scores and improve explainability. Experimental studies on both synthetic and real-world datasets demonstrate that our proposed FlowX leads to improved explainability of GNNs.

</p>
</details>

<details><summary><b>Explainable and High-Performance Hate and Offensive Speech Detection</b>
<a href="https://arxiv.org/abs/2206.12983">arxiv:2206.12983</a>
&#x1F4C8; 5 <br>
<p>Marzieh Babaeianjelodar, Gurram Poorna Prudhvi, Stephen Lorenz, Keyu Chen, Sumona Mondal, Soumyabrata Dey, Navin Kumar</p></summary>
<p>

**Abstract:** The spread of information through social media platforms can create environments possibly hostile to vulnerable communities and silence certain groups in society. To mitigate such instances, several models have been developed to detect hate and offensive speech. Since detecting hate and offensive speech in social media platforms could incorrectly exclude individuals from social media platforms, which can reduce trust, there is a need to create explainable and interpretable models. Thus, we build an explainable and interpretable high performance model based on the XGBoost algorithm, trained on Twitter data. For unbalanced Twitter data, XGboost outperformed the LSTM, AutoGluon, and ULMFiT models on hate speech detection with an F1 score of 0.75 compared to 0.38 and 0.37, and 0.38 respectively. When we down-sampled the data to three separate classes of approximately 5000 tweets, XGBoost performed better than LSTM, AutoGluon, and ULMFiT; with F1 scores for hate speech detection of 0.79 vs 0.69, 0.77, and 0.66 respectively. XGBoost also performed better than LSTM, AutoGluon, and ULMFiT in the down-sampled version for offensive speech detection with F1 score of 0.83 vs 0.88, 0.82, and 0.79 respectively. We use Shapley Additive Explanations (SHAP) on our XGBoost models' outputs to makes it explainable and interpretable compared to LSTM, AutoGluon and ULMFiT that are black-box models.

</p>
</details>

<details><summary><b>$k$-Median Clustering via Metric Embedding: Towards Better Initialization with Differential Privacy</b>
<a href="https://arxiv.org/abs/2206.12895">arxiv:2206.12895</a>
&#x1F4C8; 5 <br>
<p>Chenglin Fan, Ping Li, Xiaoyun Li</p></summary>
<p>

**Abstract:** When designing clustering algorithms, the choice of initial centers is crucial for the quality of the learned clusters. In this paper, we develop a new initialization scheme, called HST initialization, for the $k$-median problem in the general metric space (e.g., discrete space induced by graphs), based on the construction of metric embedding tree structure of the data. From the tree, we propose a novel and efficient search algorithm, for good initial centers that can be used subsequently for the local search algorithm. Our proposed HST initialization can produce initial centers achieving lower errors than those from another popular initialization method, $k$-median++, with comparable efficiency. The HST initialization can also be extended to the setting of differential privacy (DP) to generate private initial centers. We show that the error from applying DP local search followed by our private HST initialization improves previous results on the approximation error, and approaches the lower bound within a small factor. Experiments justify the theory and demonstrate the effectiveness of our proposed method. Our approach can also be extended to the $k$-means problem.

</p>
</details>

<details><summary><b>fETSmcs: Feature-based ETS model component selection</b>
<a href="https://arxiv.org/abs/2206.12882">arxiv:2206.12882</a>
&#x1F4C8; 5 <br>
<p>Lingzhi Qi, Xixi Li, Qiang Wang, Suling Jia</p></summary>
<p>

**Abstract:** The well-developed ETS (ExponenTial Smoothing or Error, Trend, Seasonality) method incorporating a family of exponential smoothing models in state space representation has been widely used for automatic forecasting. The existing ETS method uses information criteria for model selection by choosing an optimal model with the smallest information criterion among all models fitted to a given time series. The ETS method under such a model selection scheme suffers from computational complexity when applied to large-scale time series data. To tackle this issue, we propose an efficient approach for ETS model selection by training classifiers on simulated data to predict appropriate model component forms for a given time series. We provide a simulation study to show the model selection ability of the proposed approach on simulated data. We evaluate our approach on the widely used forecasting competition data set M4, in terms of both point forecasts and prediction intervals. To demonstrate the practical value of our method, we showcase the performance improvements from our approach on a monthly hospital data set.

</p>
</details>

<details><summary><b>Semantic Role Aware Correlation Transformer for Text to Video Retrieval</b>
<a href="https://arxiv.org/abs/2206.12849">arxiv:2206.12849</a>
&#x1F4C8; 5 <br>
<p>Burak Satar, Hongyuan Zhu, Xavier Bresson, Joo Hwee Lim</p></summary>
<p>

**Abstract:** With the emergence of social media, voluminous video clips are uploaded every day, and retrieving the most relevant visual content with a language query becomes critical. Most approaches aim to learn a joint embedding space for plain textual and visual contents without adequately exploiting their intra-modality structures and inter-modality correlations. This paper proposes a novel transformer that explicitly disentangles the text and video into semantic roles of objects, spatial contexts and temporal contexts with an attention scheme to learn the intra- and inter-role correlations among the three roles to discover discriminative features for matching at different levels. The preliminary results on popular YouCook2 indicate that our approach surpasses a current state-of-the-art method, with a high margin in all metrics. It also overpasses two SOTA methods in terms of two metrics.

</p>
</details>

<details><summary><b>APPFLChain: A Privacy Protection Distributed Artificial-Intelligence Architecture Based on Federated Learning and Consortium Blockchain</b>
<a href="https://arxiv.org/abs/2206.12790">arxiv:2206.12790</a>
&#x1F4C8; 5 <br>
<p>Jun-Teng Yang, Wen-Yuan Chen, Che-Hua Li, Scott C. -H. Huang, Hsiao-Chun Wu</p></summary>
<p>

**Abstract:** Recent research in Internet of things has been widely applied for industrial practices, fostering the exponential growth of data and connected devices. Henceforth, data-driven AI models would be accessed by different parties through certain data-sharing policies. However, most of the current training procedures rely on the centralized data-collection strategy and a single computational server. However, such a centralized scheme may lead to many issues. Customer data stored in a centralized database may be tampered with so the provenance and authenticity of data cannot be justified. Once the aforementioned security concerns occur, the credibility of the trained AI models would be questionable and even unfavorable outcomes might be produced at the test stage. Lately, blockchain and AI, the two core technologies in Industry 4.0 and Web 3.0, have been explored to facilitate the decentralized AI training strategy. To serve on this very purpose, we propose a new system architecture called APPFLChain, namely an integrated architecture of a Hyperledger Fabric-based blockchain and a federated-learning paradigm. Our proposed new system allows different parties to jointly train AI models and their customers or stakeholders are connected by a consortium blockchain-based network. Our new system can maintain a high degree of security and privacy as users do not need to share sensitive personal information to the server. For numerical evaluation, we simulate a real-world scenario to illustrate the whole operational process of APPFLChain. Simulation results show that taking advantage of the characteristics of consortium blockchain and federated learning, APPFLChain can demonstrate favorable properties including untamperability, traceability, privacy protection, and reliable decision-making.

</p>
</details>

<details><summary><b>Two-Stage Neural Contextual Bandits for Personalised News Recommendation</b>
<a href="https://arxiv.org/abs/2206.14648">arxiv:2206.14648</a>
&#x1F4C8; 4 <br>
<p>Mengyan Zhang, Thanh Nguyen-Tang, Fangzhao Wu, Zhenyu He, Xing Xie, Cheng Soon Ong</p></summary>
<p>

**Abstract:** We consider the problem of personalised news recommendation where each user consumes news in a sequential fashion. Existing personalised news recommendation methods focus on exploiting user interests and ignores exploration in recommendation, which leads to biased feedback loops and hurt recommendation quality in the long term. We build on contextual bandits recommendation strategies which naturally address the exploitation-exploration trade-off. The main challenges are the computational efficiency for exploring the large-scale item space and utilising the deep representations with uncertainty. We propose a two-stage hierarchical topic-news deep contextual bandits framework to efficiently learn user preferences when there are many news items. We use deep learning representations for users and news, and generalise the neural upper confidence bound (UCB) policies to generalised additive UCB and bilinear UCB. Empirical results on a large-scale news recommendation dataset show that our proposed policies are efficient and outperform the baseline bandit policies.

</p>
</details>

<details><summary><b>Automated Systems For Diagnosis of Dysgraphia in Children: A Survey and Novel Framework</b>
<a href="https://arxiv.org/abs/2206.13043">arxiv:2206.13043</a>
&#x1F4C8; 4 <br>
<p>Jayakanth Kunhoth, Somaya Al-Maadeed, Suchithra Kunhoth, Younus Akbari</p></summary>
<p>

**Abstract:** Learning disabilities, which primarily interfere with the basic learning skills such as reading, writing and math, are known to affect around 10% of children in the world. The poor motor skills and motor coordination as part of the neurodevelopmental disorder can become a causative factor for the difficulty in learning to write (dysgraphia), hindering the academic track of an individual. The signs and symptoms of dysgraphia include but are not limited to irregular handwriting, improper handling of writing medium, slow or labored writing, unusual hand position, etc. The widely accepted assessment criterion for all the types of learning disabilities is the examination performed by medical experts. The few available artificial intelligence-powered screening systems for dysgraphia relies on the distinctive features of handwriting from the corresponding images.This work presents a review of the existing automated dysgraphia diagnosis systems for children in the literature. The main focus of the work is to review artificial intelligence-based systems for dysgraphia diagnosis in children. This work discusses the data collection method, important handwriting features, machine learning algorithms employed in the literature for the diagnosis of dysgraphia. Apart from that, this article discusses some of the non-artificial intelligence-based automated systems also. Furthermore, this article discusses the drawbacks of existing systems and proposes a novel framework for dysgraphia diagnosis.

</p>
</details>

<details><summary><b>Monitoring Shortcut Learning using Mutual Information</b>
<a href="https://arxiv.org/abs/2206.13034">arxiv:2206.13034</a>
&#x1F4C8; 4 <br>
<p>Mohammed Adnan, Yani Ioannou, Chuan-Yung Tsai, Angus Galloway, H. R. Tizhoosh, Graham W. Taylor</p></summary>
<p>

**Abstract:** The failure of deep neural networks to generalize to out-of-distribution data is a well-known problem and raises concerns about the deployment of trained networks in safety-critical domains such as healthcare, finance and autonomous vehicles. We study a particular kind of distribution shift $\unicode{x2013}$ shortcuts or spurious correlations in the training data. Shortcut learning is often only exposed when models are evaluated on real-world data that does not contain the same spurious correlations, posing a serious dilemma for AI practitioners to properly assess the effectiveness of a trained model for real-world applications. In this work, we propose to use the mutual information (MI) between the learned representation and the input as a metric to find where in training, the network latches onto shortcuts. Experiments demonstrate that MI can be used as a domain-agnostic metric for monitoring shortcut learning.

</p>
</details>

<details><summary><b>Normalized/Clipped SGD with Perturbation for Differentially Private Non-Convex Optimization</b>
<a href="https://arxiv.org/abs/2206.13033">arxiv:2206.13033</a>
&#x1F4C8; 4 <br>
<p>Xiaodong Yang, Huishuai Zhang, Wei Chen, Tie-Yan Liu</p></summary>
<p>

**Abstract:** By ensuring differential privacy in the learning algorithms, one can rigorously mitigate the risk of large models memorizing sensitive training data. In this paper, we study two algorithms for this purpose, i.e., DP-SGD and DP-NSGD, which first clip or normalize \textit{per-sample} gradients to bound the sensitivity and then add noise to obfuscate the exact information. We analyze the convergence behavior of these two algorithms in the non-convex optimization setting with two common assumptions and achieve a rate $\mathcal{O}\left(\sqrt[4]{\frac{d\log(1/δ)}{N^2ε^2}}\right)$ of the gradient norm for a $d$-dimensional model, $N$ samples and $(ε,δ)$-DP, which improves over previous bounds under much weaker assumptions. Specifically, we introduce a regularizing factor in DP-NSGD and show that it is crucial in the convergence proof and subtly controls the bias and noise trade-off. Our proof deliberately handles the per-sample gradient clipping and normalization that are specified for the private setting. Empirically, we demonstrate that these two algorithms achieve similar best accuracy while DP-NSGD is comparatively easier to tune than DP-SGD and hence may help further save the privacy budget when accounting the tuning effort.

</p>
</details>

<details><summary><b>Gradient-based Neuromorphic Learning on Dynamical RRAM Arrays</b>
<a href="https://arxiv.org/abs/2206.12992">arxiv:2206.12992</a>
&#x1F4C8; 4 <br>
<p>Peng Zhou, Jason K. Eshraghian, Dong-Uk Choi, Wei D. Lu, Sung-Mo Kang</p></summary>
<p>

**Abstract:** We present MEMprop, the adoption of gradient-based learning to train fully memristive spiking neural networks (MSNNs). Our approach harnesses intrinsic device dynamics to trigger naturally arising voltage spikes. These spikes emitted by memristive dynamics are analog in nature, and thus fully differentiable, which eliminates the need for surrogate gradient methods that are prevalent in the spiking neural network (SNN) literature. Memristive neural networks typically either integrate memristors as synapses that map offline-trained networks, or otherwise rely on associative learning mechanisms to train networks of memristive neurons. We instead apply the backpropagation through time (BPTT) training algorithm directly on analog SPICE models of memristive neurons and synapses. Our implementation is fully memristive, in that synaptic weights and spiking neurons are both integrated on resistive RAM (RRAM) arrays without the need for additional circuits to implement spiking dynamics, e.g., analog-to-digital converters (ADCs) or thresholded comparators. As a result, higher-order electrophysical effects are fully exploited to use the state-driven dynamics of memristive neurons at run time. By moving towards non-approximate gradient-based learning, we obtain highly competitive accuracy amongst previously reported lightweight dense fully MSNNs on several benchmarks.

</p>
</details>

<details><summary><b>Self-Healing Robust Neural Networks via Closed-Loop Control</b>
<a href="https://arxiv.org/abs/2206.12963">arxiv:2206.12963</a>
&#x1F4C8; 4 <br>
<p>Zhuotong Chen, Qianxiao Li, Zheng Zhang</p></summary>
<p>

**Abstract:** Despite the wide applications of neural networks, there have been increasing concerns about their vulnerability issue. While numerous attack and defense techniques have been developed, this work investigates the robustness issue from a new angle: can we design a self-healing neural network that can automatically detect and fix the vulnerability issue by itself? A typical self-healing mechanism is the immune system of a human body. This biology-inspired idea has been used in many engineering designs but is rarely investigated in deep learning. This paper considers the post-training self-healing of a neural network, and proposes a closed-loop control formulation to automatically detect and fix the errors caused by various attacks or perturbations. We provide a margin-based analysis to explain how this formulation can improve the robustness of a classifier. To speed up the inference of the proposed self-healing network, we solve the control problem via improving the Pontryagin Maximum Principle-based solver. Lastly, we present an error estimation of the proposed framework for neural networks with nonlinear activation functions. We validate the performance on several network architectures against various perturbations. Since the self-healing method does not need a-priori information about data perturbations/attacks, it can handle a broad class of unforeseen perturbations.

</p>
</details>

<details><summary><b>Improving the Training Recipe for a Robust Conformer-based Hybrid Model</b>
<a href="https://arxiv.org/abs/2206.12955">arxiv:2206.12955</a>
&#x1F4C8; 4 <br>
<p>Mohammad Zeineldeen, Jingjing Xu, Christoph Lüscher, Ralf Schlüter, Hermann Ney</p></summary>
<p>

**Abstract:** Speaker adaptation is important to build robust automatic speech recognition (ASR) systems. In this work, we investigate various methods for speaker adaptive training (SAT) based on feature-space approaches for a conformer-based acoustic model (AM) on the Switchboard 300h dataset. We propose a method, called Weighted-Simple-Add, which adds weighted speaker information vectors to the input of the multi-head self-attention module of the conformer AM. Using this method for SAT, we achieve 3.5% and 4.5% relative improvement in terms of WER on the CallHome part of Hub5'00 and Hub5'01 respectively. Moreover, we build on top of our previous work where we proposed a novel and competitive training recipe for a conformer-based hybrid AM. We extend and improve this recipe where we achieve 11% relative improvement in terms of word-error-rate (WER) on Switchboard 300h Hub5'00 dataset. We also make this recipe efficient by reducing the total number of parameters by 34% relative.

</p>
</details>

<details><summary><b>Nonwatertight Mesh Reconstruction</b>
<a href="https://arxiv.org/abs/2206.12952">arxiv:2206.12952</a>
&#x1F4C8; 4 <br>
<p>Partha Ghosh</p></summary>
<p>

**Abstract:** Reconstructing 3D non-watertight mesh from an unoriented point cloud is an unexplored area in computer vision and computer graphics. In this project, we tried to tackle this problem by extending the learning-based watertight mesh reconstruction pipeline presented in the paper 'Shape as Points'. The core of our approach is to cast the problem as a semantic segmentation problem that identifies the region in the 3D volume where the mesh surface lies and extracts the surfaces from the detected regions. Our approach achieves compelling results compared to the baseline techniques.

</p>
</details>

<details><summary><b>Noise-aware Physics-informed Machine Learning for Robust PDE Discovery</b>
<a href="https://arxiv.org/abs/2206.12901">arxiv:2206.12901</a>
&#x1F4C8; 4 <br>
<p>Pongpisit Thanasutives, Takashi Morita, Masayuki Numao, Ken-ichi Fukui</p></summary>
<p>

**Abstract:** This work is concerned with discovering the governing partial differential equation (PDE) of a physical system. Existing methods have demonstrated the PDE identification from finite observations but failed to maintain satisfying performance against noisy data, partly owing to suboptimal estimated derivatives and found PDE coefficients. We address the issues by introducing a noise-aware physics-informed machine learning (nPIML) framework to discover the governing PDE from data following arbitrary distributions. Our proposals are twofold. First, we propose a couple of neural networks, namely solver and preselector, which yield an interpretable neural representation of the hidden physical constraint. After they are jointly trained, the solver network approximates potential candidates, e.g., partial derivatives, which are then fed to the sparse regression algorithm that initially unveils the most likely parsimonious PDE, decided according to the information criterion. Second, we propose the denoising physics-informed neural networks (dPINNs), based on Discrete Fourier Transform (DFT), to deliver a set of the optimal finetuned PDE coefficients respecting the noise-reduced variables. The denoising PINNs' structures are compartmentalized into forefront projection networks and a PINN, by which the formerly learned solver initializes. Our extensive experiments on five canonical PDEs affirm that the proposed framework presents a robust and interpretable approach for PDE discovery, applicable to a wide range of systems, possibly complicated by noise.

</p>
</details>

<details><summary><b>Prediction Errors for Penalized Regressions based on Generalized Approximate Message Passing</b>
<a href="https://arxiv.org/abs/2206.12832">arxiv:2206.12832</a>
&#x1F4C8; 4 <br>
<p>Ayaka Sakata</p></summary>
<p>

**Abstract:** We discuss the prediction accuracy of assumed statistical models in terms of prediction errors for the generalized linear model and penalized maximum likelihood methods. We derive the forms of estimators for the prediction errors: $C_p$ criterion, information criteria, and leave-one-out cross validation (LOOCV) error, using the generalized approximate message passing (GAMP) algorithm and replica method. These estimators coincide with each other when the number of model parameters is sufficiently small; however, there is a discrepancy between them in particular in the overparametrized region where the number of model parameters is larger than the data dimension. In this paper, we review the prediction errors and corresponding estimators, and discuss their differences. In the framework of GAMP, we show that the information criteria can be expressed by using the variance of the estimates. Further, we demonstrate how to approach LOOCV error from the information criteria by utilizing the expression provided by GAMP.

</p>
</details>

<details><summary><b>Cross-Silo Federated Learning: Challenges and Opportunities</b>
<a href="https://arxiv.org/abs/2206.12949">arxiv:2206.12949</a>
&#x1F4C8; 3 <br>
<p>Chao Huang, Jianwei Huang, Xin Liu</p></summary>
<p>

**Abstract:** Federated learning (FL) is an emerging technology that enables the training of machine learning models from multiple clients while keeping the data distributed and private. Based on the participating clients and the model training scale, federated learning can be classified into two types: cross-device FL where clients are typically mobile devices and the client number can reach up to a scale of millions; cross-silo FL where clients are organizations or companies and the client number is usually small (e.g., within a hundred). While existing studies mainly focus on cross-device FL, this paper aims to provide an overview of the cross-silo FL. More specifically, we first discuss applications of cross-silo FL and outline its major challenges. We then provide a systematic overview of the existing approaches to the challenges in cross-silo FL by focusing on their connections and differences to cross-device FL. Finally, we discuss future directions and open issues that merit research efforts from the community.

</p>
</details>

<details><summary><b>FAIR-BFL: Flexible and Incentive Redesign for Blockchain-based Federated Learning</b>
<a href="https://arxiv.org/abs/2206.12899">arxiv:2206.12899</a>
&#x1F4C8; 3 <br>
<p>Rongxin Xu, Shiva Raj Pokhrel, Qiujun Lan, Gang Li</p></summary>
<p>

**Abstract:** Vanilla Federated learning (FL) relies on the centralized global aggregation mechanism and assumes that all clients are honest. This makes it a challenge for FL to alleviate the single point of failure and dishonest clients. These impending challenges in the design philosophy of FL call for blockchain-based federated learning (BFL) due to the benefits of coupling FL and blockchain (e.g., democracy, incentive, and immutability). However, one problem in vanilla BFL is that its capabilities do not follow adopters' needs in a dynamic fashion. Besides, vanilla BFL relies on unverifiable clients' self-reported contributions like data size because checking clients' raw data is not allowed in FL for privacy concerns. We design and evaluate a novel BFL framework, and resolve the identified challenges in vanilla BFL with greater flexibility and incentive mechanism called FAIR-BFL. In contrast to existing works, FAIR-BFL offers unprecedented flexibility via the modular design, allowing adopters to adjust its capabilities following business demands in a dynamic fashion. Our design accounts for BFL's ability to quantify each client's contribution to the global learning process. Such quantification provides a rational metric for distributing the rewards among federated clients and helps discover malicious participants that may poison the global model.

</p>
</details>

<details><summary><b>FingerGAN: A Constrained Fingerprint Generation Scheme for Latent Fingerprint Enhancement</b>
<a href="https://arxiv.org/abs/2206.12885">arxiv:2206.12885</a>
&#x1F4C8; 3 <br>
<p>Yanming Zhu, Xuefei Yin, Jiankun Hu</p></summary>
<p>

**Abstract:** Latent fingerprint enhancement is an essential pre-processing step for latent fingerprint identification. Most latent fingerprint enhancement methods try to restore corrupted gray ridges/valleys. In this paper, we propose a new method that formulates the latent fingerprint enhancement as a constrained fingerprint generation problem within a generative adversarial network (GAN) framework. We name the proposed network as FingerGAN. It can enforce its generated fingerprint (i.e, enhanced latent fingerprint) indistinguishable from the corresponding ground-truth instance in terms of the fingerprint skeleton map weighted by minutia locations and the orientation field regularized by the FOMFE model. Because minutia is the primary feature for fingerprint recognition and minutia can be retrieved directly from the fingerprint skeleton map, we offer a holistic framework which can perform latent fingerprint enhancement in the context of directly optimizing minutia information. This will help improve latent fingerprint identification performance significantly. Experimental results on two public latent fingerprint databases demonstrate that our method outperforms the state of the arts significantly. The codes will be available for non-commercial purposes from \url{https://github.com/HubYZ/LatentEnhancement}.

</p>
</details>

<details><summary><b>Data Augmentation for Dementia Detection in Spoken Language</b>
<a href="https://arxiv.org/abs/2206.12879">arxiv:2206.12879</a>
&#x1F4C8; 3 <br>
<p>Anna Hlédiková, Dominika Woszczyk, Alican Acman, Soteris Demetriou, Björn Schuller</p></summary>
<p>

**Abstract:** Dementia is a growing problem as our society ages, and detection methods are often invasive and expensive. Recent deep-learning techniques can offer a faster diagnosis and have shown promising results. However, they require large amounts of labelled data which is not easily available for the task of dementia detection. One effective solution to sparse data problems is data augmentation, though the exact methods need to be selected carefully. To date, there has been no empirical study of data augmentation on Alzheimer's disease (AD) datasets for NLP and speech processing. In this work, we investigate data augmentation techniques for the task of AD detection and perform an empirical evaluation of the different approaches on two kinds of models for both the text and audio domains. We use a transformer-based model for both domains, and SVM and Random Forest models for the text and audio domains, respectively. We generate additional samples using traditional as well as deep learning based methods and show that data augmentation improves performance for both the text- and audio-based models and that such results are comparable to state-of-the-art results on the popular ADReSS set, with carefully crafted architectures and features.

</p>
</details>

<details><summary><b>Contextual embedding and model weighting by fusing domain knowledge on Biomedical Question Answering</b>
<a href="https://arxiv.org/abs/2206.12866">arxiv:2206.12866</a>
&#x1F4C8; 3 <br>
<p>Yuxuan Lu, Jingya Yan, Zhixuan Qi, Zhongzheng Ge, Yongping Du</p></summary>
<p>

**Abstract:** Biomedical Question Answering aims to obtain an answer to the given question from the biomedical domain. Due to its high requirement of biomedical domain knowledge, it is difficult for the model to learn domain knowledge from limited training data. We propose a contextual embedding method that combines open-domain QA model \aoa and \biobert model pre-trained on biomedical domain data. We adopt unsupervised pre-training on large biomedical corpus and supervised fine-tuning on biomedical question answering dataset. Additionally, we adopt an MLP-based model weighting layer to automatically exploit the advantages of two models to provide the correct answer. The public dataset \biomrc constructed from PubMed corpus is used to evaluate our method. Experimental results show that our model outperforms state-of-the-art system by a large margin.

</p>
</details>

<details><summary><b>RoME: Role-aware Mixture-of-Expert Transformer for Text-to-Video Retrieval</b>
<a href="https://arxiv.org/abs/2206.12845">arxiv:2206.12845</a>
&#x1F4C8; 3 <br>
<p>Burak Satar, Hongyuan Zhu, Hanwang Zhang, Joo Hwee Lim</p></summary>
<p>

**Abstract:** Seas of videos are uploaded daily with the popularity of social channels; thus, retrieving the most related video contents with user textual queries plays a more crucial role. Most methods consider only one joint embedding space between global visual and textual features without considering the local structures of each modality. Some other approaches consider multiple embedding spaces consisting of global and local features separately, ignoring rich inter-modality correlations.
  We propose a novel mixture-of-expert transformer RoME that disentangles the text and the video into three levels; the roles of spatial contexts, temporal contexts, and object contexts. We utilize a transformer-based attention mechanism to fully exploit visual and text embeddings at both global and local levels with mixture-of-experts for considering inter-modalities and structures' correlations. The results indicate that our method outperforms the state-of-the-art methods on the YouCook2 and MSR-VTT datasets, given the same visual backbone without pre-training. Finally, we conducted extensive ablation studies to elucidate our design choices.

</p>
</details>

<details><summary><b>On Comparison of Encoders for Attention based End to End Speech Recognition in Standalone and Rescoring Mode</b>
<a href="https://arxiv.org/abs/2206.12829">arxiv:2206.12829</a>
&#x1F4C8; 3 <br>
<p>Raviraj Joshi, Subodh Kumar</p></summary>
<p>

**Abstract:** The streaming automatic speech recognition (ASR) models are more popular and suitable for voice-based applications. However, non-streaming models provide better performance as they look at the entire audio context. To leverage the benefits of the non-streaming model in streaming applications like voice search, it is commonly used in second pass re-scoring mode. The candidate hypothesis generated using steaming models is re-scored using a non-streaming model. In this work, we evaluate the non-streaming attention-based end-to-end ASR models on the Flipkart voice search task in both standalone and re-scoring modes. These models are based on Listen-Attend-Spell (LAS) encoder-decoder architecture. We experiment with different encoder variations based on LSTM, Transformer, and Conformer. We compare the latency requirements of these models along with their performance. Overall we show that the Transformer model offers acceptable WER with the lowest latency requirements. We report a relative WER improvement of around 16% with the second pass LAS re-scoring with latency overhead under 5ms. We also highlight the importance of CNN front-end with Transformer architecture to achieve comparable word error rates (WER). Moreover, we observe that in the second pass re-scoring mode all the encoders provide similar benefits whereas the difference in performance is prominent in standalone text generation mode.

</p>
</details>

<details><summary><b>Memory-Guided Multi-View Multi-Domain Fake News Detection</b>
<a href="https://arxiv.org/abs/2206.12808">arxiv:2206.12808</a>
&#x1F4C8; 3 <br>
<p>Yongchun Zhu, Qiang Sheng, Juan Cao, Qiong Nan, Kai Shu, Minghui Wu, Jindong Wang, Fuzhen Zhuang</p></summary>
<p>

**Abstract:** The wide spread of fake news is increasingly threatening both individuals and society. Great efforts have been made for automatic fake news detection on a single domain (e.g., politics). However, correlations exist commonly across multiple news domains, and thus it is promising to simultaneously detect fake news of multiple domains. Based on our analysis, we pose two challenges in multi-domain fake news detection: 1) domain shift, caused by the discrepancy among domains in terms of words, emotions, styles, etc. 2) domain labeling incompleteness, stemming from the real-world categorization that only outputs one single domain label, regardless of topic diversity of a news piece. In this paper, we propose a Memory-guided Multi-view Multi-domain Fake News Detection Framework (M$^3$FEND) to address these two challenges. We model news pieces from a multi-view perspective, including semantics, emotion, and style. Specifically, we propose a Domain Memory Bank to enrich domain information which could discover potential domain labels based on seen news pieces and model domain characteristics. Then, with enriched domain information as input, a Domain Adapter could adaptively aggregate discriminative information from multiple views for news in various domains. Extensive offline experiments on English and Chinese datasets demonstrate the effectiveness of M$^3$FEND, and online tests verify its superiority in practice. Our code is available at https://github.com/ICTMCG/M3FEND.

</p>
</details>

<details><summary><b>Calibrated Nonparametric Scan Statistics for Anomalous Pattern Detection in Graphs</b>
<a href="https://arxiv.org/abs/2206.12786">arxiv:2206.12786</a>
&#x1F4C8; 3 <br>
<p>Chunpai Wang, Daniel B. Neill, Feng Chen</p></summary>
<p>

**Abstract:** We propose a new approach, the calibrated nonparametric scan statistic (CNSS), for more accurate detection of anomalous patterns in large-scale, real-world graphs. Scan statistics identify connected subgraphs that are interesting or unexpected through maximization of a likelihood ratio statistic; in particular, nonparametric scan statistics (NPSSs) identify subgraphs with a higher than expected proportion of individually significant nodes. However, we show that recently proposed NPSS methods are miscalibrated, failing to account for the maximization of the statistic over the multiplicity of subgraphs. This results in both reduced detection power for subtle signals, and low precision of the detected subgraph even for stronger signals. Thus we develop a new statistical approach to recalibrate NPSSs, correctly adjusting for multiple hypothesis testing and taking the underlying graph structure into account. While the recalibration, based on randomization testing, is computationally expensive, we propose both an efficient (approximate) algorithm and new, closed-form lower bounds (on the expected maximum proportion of significant nodes for subgraphs of a given size, under the null hypothesis of no anomalous patterns). These advances, along with the integration of recent core-tree decomposition methods, enable CNSS to scale to large real-world graphs, with substantial improvement in the accuracy of detected subgraphs. Extensive experiments on both semi-synthetic and real-world datasets are demonstrated to validate the effectiveness of our proposed methods, in comparison with state-of-the-art counterparts.

</p>
</details>

<details><summary><b>State of the Art of Audio- and Video-Based Solutions for AA</b>
<a href="https://arxiv.org/abs/2207.01487">arxiv:2207.01487</a>
&#x1F4C8; 2 <br>
<p>Slavisa Aleksic, Michael Atanasov, Jean Calleja Agius, Kenneth Camilleri, Anto Cartolovni, Pau Climent-Peerez, Sara Colantonio, Stefania Cristina, Vladimir Despotovic, Hazim Kemal Ekenel, Ekrem Erakin, Francisco Florez-Revuelta, Danila Germanese, Nicole Grech, Steinunn Gróa Sigurðardóttir, Murat Emirzeoglu, Ivo Iliev, Mladjan Jovanovic, Martin Kampel, William Kearns, Andrzej Klimczuk, Lambros Lambrinos, Jennifer Lumetzberger, Wiktor Mucha, Sophie Noiret</p></summary>
<p>

**Abstract:** The report illustrates the state of the art of the most successful AAL applications and functions based on audio and video data, namely (i) lifelogging and self-monitoring, (ii) remote monitoring of vital signs, (iii) emotional state recognition, (iv) food intake monitoring, activity and behaviour recognition, (v) activity and personal assistance, (vi) gesture recognition, (vii) fall detection and prevention, (viii) mobility assessment and frailty recognition, and (ix) cognitive and motor rehabilitation. For these application scenarios, the report illustrates the state of play in terms of scientific advances, available products and research project. The open challenges are also highlighted.

</p>
</details>

<details><summary><b>PROTOtypical Logic Tensor Networks (PROTO-LTN) for Zero Shot Learning</b>
<a href="https://arxiv.org/abs/2207.00433">arxiv:2207.00433</a>
&#x1F4C8; 2 <br>
<p>Simone Martone, Francesco Manigrasso, Lamberti Fabrizio, Lia Morra</p></summary>
<p>

**Abstract:** Semantic image interpretation can vastly benefit from approaches that combine sub-symbolic distributed representation learning with the capability to reason at a higher level of abstraction. Logic Tensor Networks (LTNs) are a class of neuro-symbolic systems based on a differentiable, first-order logic grounded into a deep neural network. LTNs replace the classical concept of training set with a knowledge base of fuzzy logical axioms. By defining a set of differentiable operators to approximate the role of connectives, predicates, functions and quantifiers, a loss function is automatically specified so that LTNs can learn to satisfy the knowledge base. We focus here on the subsumption or \texttt{isOfClass} predicate, which is fundamental to encode most semantic image interpretation tasks. Unlike conventional LTNs, which rely on a separate predicate for each class (e.g., dog, cat), each with its own set of learnable weights, we propose a common \texttt{isOfClass} predicate, whose level of truth is a function of the distance between an object embedding and the corresponding class prototype. The PROTOtypical Logic Tensor Networks (PROTO-LTN) extend the current formulation by grounding abstract concepts as parametrized class prototypes in a high-dimensional embedding space, while reducing the number of parameters required to ground the knowledge base. We show how this architecture can be effectively trained in the few and zero-shot learning scenarios. Experiments on Generalized Zero Shot Learning benchmarks validate the proposed implementation as a competitive alternative to traditional embedding-based approaches. The proposed formulation opens up new opportunities in zero shot learning settings, as the LTN formalism allows to integrate background knowledge in the form of logical axioms to compensate for the lack of labelled examples.

</p>
</details>

<details><summary><b>Explaining the root causes of unit-level changes</b>
<a href="https://arxiv.org/abs/2206.12986">arxiv:2206.12986</a>
&#x1F4C8; 2 <br>
<p>Kailash Budhathoki, George Michailidis, Dominik Janzing</p></summary>
<p>

**Abstract:** Existing methods of explainable AI and interpretable ML cannot explain change in the values of an output variable for a statistical unit in terms of the change in the input values and the change in the "mechanism" (the function transforming input to output). We propose two methods based on counterfactuals for explaining unit-level changes at various input granularities using the concept of Shapley values from game theory. These methods satisfy two key axioms desirable for any unit-level change attribution method. Through simulations, we study the reliability and the scalability of the proposed methods. We get sensible results from a case study on identifying the drivers of the change in the earnings for individuals in the US.

</p>
</details>

<details><summary><b>Object Detection and Tracking with Autonomous UAV</b>
<a href="https://arxiv.org/abs/2206.12941">arxiv:2206.12941</a>
&#x1F4C8; 2 <br>
<p>A. Huzeyfe Demir, Berke Yavas, Mehmet Yazici, Dogukan Aksu, M. Ali Aydin</p></summary>
<p>

**Abstract:** In this paper, a combat Unmanned Air Vehicle (UAV) is modeled in the simulation environment. The rotary wing UAV is successfully performed various tasks such as locking on the targets, tracking, and sharing the relevant data with surrounding vehicles. Different software technologies such as API communication, ground control station configuration, autonomous movement algorithms, computer vision, and deep learning are employed.

</p>
</details>

<details><summary><b>Checking Trustworthiness of Probabilistic Computations in a Typed Natural Deduction System</b>
<a href="https://arxiv.org/abs/2206.12934">arxiv:2206.12934</a>
&#x1F4C8; 2 <br>
<p>Fabio Aurelio D'Asaro, Giuseppe Primiero</p></summary>
<p>

**Abstract:** In this paper we present the probabilistic typed natural deduction calculus TPTND, designed to reason about and derive trustworthiness properties of probabilistic computational processes, like those underlying current AI applications. Derivability in TPTND is interpreted as the process of extracting $n$ samples of outputs with a certain frequency from a given categorical distribution. We formalize trust within our framework as a form of hypothesis testing on the distance between such frequency and the intended probability. The main advantage of the calculus is to render such notion of trustworthiness checkable. We present the proof-theoretic semantics of TPTND and illustrate structural and metatheoretical properties, with particular focus on safety. We motivate its use in the verification of algorithms for automatic classification.

</p>
</details>

<details><summary><b>Learning neural state-space models: do we need a state estimator?</b>
<a href="https://arxiv.org/abs/2206.12928">arxiv:2206.12928</a>
&#x1F4C8; 2 <br>
<p>Marco Forgione, Manas Mejari, Dario Piga</p></summary>
<p>

**Abstract:** In recent years, several algorithms for system identification with neural state-space models have been introduced. Most of the proposed approaches are aimed at reducing the computational complexity of the learning problem, by splitting the optimization over short sub-sequences extracted from a longer training dataset. Different sequences are then processed simultaneously within a minibatch, taking advantage of modern parallel hardware for deep learning. An issue arising in these methods is the need to assign an initial state for each of the sub-sequences, which is required to run simulations and thus to evaluate the fitting loss. In this paper, we provide insights for calibration of neural state-space training algorithms based on extensive experimentation and analyses performed on two recognized system identification benchmarks. Particular focus is given to the choice and the role of the initial state estimation. We demonstrate that advanced initial state estimation techniques are really required to achieve high performance on certain classes of dynamical systems, while for asymptotically stable ones basic procedures such as zero or random initialization already yield competitive performance.

</p>
</details>

<details><summary><b>Vision Transformer for Contrastive Clustering</b>
<a href="https://arxiv.org/abs/2206.12925">arxiv:2206.12925</a>
&#x1F4C8; 2 <br>
<p>Hua-Bao Ling, Bowen Zhu, Dong Huang, Ding-Hua Chen, Chang-Dong Wang, Jian-Huang Lai</p></summary>
<p>

**Abstract:** Vision Transformer (ViT) has shown its advantages over the convolutional neural network (CNN) with its ability to capture global long-range dependencies for visual representation learning. Besides ViT, contrastive learning is another popular research topic recently. While previous contrastive learning works are mostly based on CNNs, some latest studies have attempted to jointly model the ViT and the contrastive learning for enhanced self-supervised learning. Despite the considerable progress, these combinations of ViT and contrastive learning mostly focus on the instance-level contrastiveness, which often overlook the contrastiveness of the global clustering structures and also lack the ability to directly learn the clustering result (e.g., for images). In view of this, this paper presents an end-to-end deep image clustering approach termed Vision Transformer for Contrastive Clustering (VTCC), which for the first time, to the best of our knowledge, unifies the Transformer and the contrastive learning for the image clustering task. Specifically, with two random augmentations performed on each image in a mini-batch, we utilize a ViT encoder with two weight-sharing views as the backbone to learn the representations for the augmented samples. To remedy the potential instability of the ViT, we incorporate a convolutional stem, which uses multiple stacked small convolutions instead of a big convolution in the patch projection layer, to split each augmented sample into a sequence of patches. With representations learned via the backbone, an instance projector and a cluster projector are further utilized for the instance-level contrastive learning and the global clustering structure learning, respectively. Extensive experiments on eight image datasets demonstrate the stability (during the training-from-scratch) and the superiority (in clustering performance) of VTCC over the state-of-the-art.

</p>
</details>

<details><summary><b>TAM: Topology-Aware Margin Loss for Class-Imbalanced Node Classification</b>
<a href="https://arxiv.org/abs/2206.12917">arxiv:2206.12917</a>
&#x1F4C8; 2 <br>
<p>Jaeyun Song, Joonhyung Park, Eunho Yang</p></summary>
<p>

**Abstract:** Learning unbiased node representations under class-imbalanced graph data is challenging due to interactions between adjacent nodes. Existing studies have in common that they compensate the minor class nodes `as a group' according to their overall quantity (ignoring node connections in graph), which inevitably increase the false positive cases for major nodes. We hypothesize that the increase in these false positive cases is highly affected by the label distribution around each node and confirm it experimentally. In addition, in order to handle this issue, we propose Topology-Aware Margin (TAM) to reflect local topology on the learning objective. Our method compares the connectivity pattern of each node with the class-averaged counter-part and adaptively adjusts the margin accordingly based on that. Our method consistently exhibits superiority over the baselines on various node classification benchmark datasets with representative GNN architectures.

</p>
</details>

<details><summary><b>Video Anomaly Detection via Prediction Network with Enhanced Spatio-Temporal Memory Exchange</b>
<a href="https://arxiv.org/abs/2206.12914">arxiv:2206.12914</a>
&#x1F4C8; 2 <br>
<p>Guodong Shen, Yuqi Ouyang, Victor Sanchez</p></summary>
<p>

**Abstract:** Video anomaly detection is a challenging task because most anomalies are scarce and non-deterministic. Many approaches investigate the reconstruction difference between normal and abnormal patterns, but neglect that anomalies do not necessarily correspond to large reconstruction errors. To address this issue, we design a Convolutional LSTM Auto-Encoder prediction framework with enhanced spatio-temporal memory exchange using bi-directionalilty and a higher-order mechanism. The bi-directional structure promotes learning the temporal regularity through forward and backward predictions. The unique higher-order mechanism further strengthens spatial information interaction between the encoder and the decoder. Considering the limited receptive fields in Convolutional LSTMs, we also introduce an attention module to highlight informative features for prediction. Anomalies are eventually identified by comparing the frames with their corresponding predictions. Evaluations on three popular benchmarks show that our framework outperforms most existing prediction-based anomaly detection methods.

</p>
</details>

<details><summary><b>Batch-Ensemble Stochastic Neural Networks for Out-of-Distribution Detection</b>
<a href="https://arxiv.org/abs/2206.12911">arxiv:2206.12911</a>
&#x1F4C8; 2 <br>
<p>Xiongjie Chen, Yunpeng Li, Yongxin Yang</p></summary>
<p>

**Abstract:** Out-of-distribution (OOD) detection has recently received much attention from the machine learning community due to its importance in deploying machine learning models in real-world applications. In this paper we propose an uncertainty quantification approach by modelling the distribution of features. We further incorporate an efficient ensemble mechanism, namely batch-ensemble, to construct the batch-ensemble stochastic neural networks (BE-SNNs) and overcome the feature collapse problem. We compare the performance of the proposed BE-SNNs with the other state-of-the-art approaches and show that BE-SNNs yield superior performance on several OOD benchmarks, such as the Two-Moons dataset, the FashionMNIST vs MNIST dataset, FashionMNIST vs NotMNIST dataset, and the CIFAR10 vs SVHN dataset.

</p>
</details>

<details><summary><b>Breast Cancer Classification using Deep Learned Features Boosted with Handcrafted Features</b>
<a href="https://arxiv.org/abs/2206.12815">arxiv:2206.12815</a>
&#x1F4C8; 2 <br>
<p>Unaiza Sajid, Dr. Rizwan Ahmed Khan, Dr. Shahid Munir Shah, Dr. Sheeraz Arif</p></summary>
<p>

**Abstract:** Breast cancer is one of the leading causes of death among women across the globe. It is difficult to treat if detected at advanced stages, however, early detection can significantly increase chances of survival and improves lives of millions of women. Given the widespread prevalence of breast cancer, it is of utmost importance for the research community to come up with the framework for early detection, classification and diagnosis. Artificial intelligence research community in coordination with medical practitioners are developing such frameworks to automate the task of detection. With the surge in research activities coupled with availability of large datasets and enhanced computational powers, it expected that AI framework results will help even more clinicians in making correct predictions. In this article, a novel framework for classification of breast cancer using mammograms is proposed. The proposed framework combines robust features extracted from novel Convolutional Neural Network (CNN) features with handcrafted features including HOG (Histogram of Oriented Gradients) and LBP (Local Binary Pattern). The obtained results on CBIS-DDSM dataset exceed state of the art.

</p>
</details>

<details><summary><b>CTMQ: Cyclic Training of Convolutional Neural Networks with Multiple Quantization Steps</b>
<a href="https://arxiv.org/abs/2206.12794">arxiv:2206.12794</a>
&#x1F4C8; 2 <br>
<p>HyunJin Kim, Jungwoo Shin, Alberto A. Del Barrio</p></summary>
<p>

**Abstract:** This paper proposes a training method having multiple cyclic training for achieving enhanced performance in low-bit quantized convolutional neural networks (CNNs). Quantization is a popular method for obtaining lightweight CNNs, where the initialization with a pretrained model is widely used to overcome degraded performance in low-resolution quantization. However, large quantization errors between real values and their low-bit quantized ones cause difficulties in achieving acceptable performance for complex networks and large datasets. The proposed training method softly delivers the knowledge of pretrained models to low-bit quantized models in multiple quantization steps. In each quantization step, the trained weights of a model are used to initialize the weights of the next model with the quantization bit depth reduced by one. With small change of the quantization bit depth, the performance gap can be bridged, thus providing better weight initialization. In cyclic training, after training a low-bit quantized model, its trained weights are used in the initialization of its accurate model to be trained. By using better training ability of the accurate model in an iterative manner, the proposed method can produce enhanced trained weights for the low-bit quantized model in each cycle. Notably, the training method can advance Top-1 and Top-5 accuracies of the binarized ResNet-18 on the ImageNet dataset by 5.80% and 6.85%, respectively.

</p>
</details>

<details><summary><b>Knowledge Distillation with Representative Teacher Keys Based on Attention Mechanism for Image Classification Model Compression</b>
<a href="https://arxiv.org/abs/2206.12788">arxiv:2206.12788</a>
&#x1F4C8; 2 <br>
<p>Jun-Teng Yang, Sheng-Che Kao, Scott C. -H. Huang</p></summary>
<p>

**Abstract:** With the improvement of AI chips (e.g., GPU, TPU, and NPU) and the fast development of internet of things (IoTs), some powerful deep neural networks (DNNs) are usually composed of millions or even hundreds of millions of parameters, which may not be suitable to be directly deployed on low computation and low capacity units (e.g., edge devices). Recently, knowledge distillation (KD) has been recognized as one of the effective method of model compression to decrease the model parameters. The main concept of KD is to extract useful information from the feature maps of a large model (i.e., teacher model) as a reference to successfully train a small model (i.e., student model) which model size is much smaller than the teacher one. Although many KD-based methods have been proposed to utilize the information from the feature maps of intermediate layers in teacher model, however, most of them did not consider the similarity of feature maps between teacher model and student model, which may let student model learn useless information. Inspired by attention mechanism, we propose a novel KD method called representative teacher key (RTK) that not only consider the similarity of feature maps but also filter out the useless information to improve the performance of the target student model. In the experiments, we validate our proposed method with several backbone networks (e.g., ResNet and WideResNet) and datasets (e.g., CIFAR10, CIFAR100, SVHN, and CINIC10). The results show that our proposed RTK can effectively improve the classification accuracy of the state-of-the-art attention-based KD method.

</p>
</details>

<details><summary><b>RF Signal Classification with Synthetic Training Data and its Real-World Performance</b>
<a href="https://arxiv.org/abs/2206.12967">arxiv:2206.12967</a>
&#x1F4C8; 1 <br>
<p>Stefan Scholl</p></summary>
<p>

**Abstract:** Neural nets are a powerful method for the classification of radio signals in the electromagnetic spectrum. These neural nets are often trained with synthetically generated data due to the lack of diverse and plentiful real RF data. However, it is often unclear how neural nets trained on synthetic data perform in real-world applications. This paper investigates the impact of different RF signal impairments (such as phase, frequency and sample rate offsets, receiver filters, noise and channel models) modeled in synthetic training data with respect to the real-world performance. For that purpose, this paper trains neural nets with various synthetic training datasets with different signal impairments. After training, the neural nets are evaluated against real-world RF data collected by a software defined radio receiver in the field. This approach reveals which modeled signal impairments should be included in carefully designed synthetic datasets. The investigated showcase example can classify RF signals into one of 20 different radio signal types from the shortwave bands. It achieves an accuracy of up to 95 % in real-world operation by using carefully designed synthetic training data only.

</p>
</details>

<details><summary><b>Towards KAB2S: Learning Key Knowledge from Single-Objective Problems to Multi-Objective Problem</b>
<a href="https://arxiv.org/abs/2206.12906">arxiv:2206.12906</a>
&#x1F4C8; 1 <br>
<p>Xu Wendi, Wang Xianpeng, Guo Qingxin, Song Xiangman, Zhao Ren, Zhao Guodong, Yang Yang, Xu Te, He Dakuo</p></summary>
<p>

**Abstract:** As "a new frontier in evolutionary computation research", evolutionary transfer optimization(ETO) will overcome the traditional paradigm of zero reuse of related experience and knowledge from solved past problems in researches of evolutionary computation. In scheduling applications via ETO, a quite appealing and highly competitive framework "meeting" between them could be formed for both intelligent scheduling and green scheduling, especially for international pledge of "carbon neutrality" from China. To the best of our knowledge, our paper on scheduling here, serves as the 1st work of a class of ETO frameworks when multiobjective optimization problem "meets" single-objective optimization problems in discrete case (not multitasking optimization). More specifically, key knowledge conveyed for industrial applications, like positional building blocks with genetic algorithm based settings, could be used via the new core transfer mechanism and learning techniques for permutation flow shop scheduling problem(PFSP). Extensive studies on well-studied benchmarks validate firm effectiveness and great universality of our proposed ETO-PFSP framework empirically. Our investigations (1) enrich the ETO frameworks, (2) contribute to the classical and fundamental theory of building block for genetic algorithms and memetic algorithms, and (3) head towards the paradigm shift of evolutionary scheduling via learning by proposal and practice of paradigm of "knowledge and building-block based scheduling" (KAB2S) for "industrial intelligence" in China.

</p>
</details>

<details><summary><b>ETO Meets Scheduling: Learning Key Knowledge from Single-Objective Problems to Multi-Objective Problem</b>
<a href="https://arxiv.org/abs/2206.12902">arxiv:2206.12902</a>
&#x1F4C8; 1 <br>
<p>Wendi Xu, Xianpeng Wang</p></summary>
<p>

**Abstract:** Evolutionary transfer optimization(ETO) serves as "a new frontier in evolutionary computation research", which will avoid zero reuse of experience and knowledge from solved problems in traditional evolutionary computation. In scheduling applications via ETO, a highly competitive "meeting" framework between them could be constituted towards both intelligent scheduling and green scheduling, especially for carbon neutrality within the context of China. To the best of our knowledge, our study on scheduling here, is the 1st work of ETO for complex optimization when multiobjective problem "meets" single-objective problems in combinatorial case (not multitasking optimization). More specifically, key knowledge like positional building blocks clustered, could be learned and transferred for permutation flow shop scheduling problem (PFSP). Empirical studies on well-studied benchmarks validate relatively firm effectiveness and great potential of our proposed ETO-PFSP framework.

</p>
</details>

<details><summary><b>A Comparison of AIS, X-Band Marine Radar Systems and Camera Surveillance Systems in the Collection of Tracking Data</b>
<a href="https://arxiv.org/abs/2206.12809">arxiv:2206.12809</a>
&#x1F4C8; 1 <br>
<p>Yassir Zardoua, Abdelali Astito, Mohammed Boulaala</p></summary>
<p>

**Abstract:** Maritime traffic has increased in recent years, especially in terms of seaborne trade. To ensure safety, security, and protection of the marine environment, several systems have been deployed. To overcome some of their inconveniences, the collected data is typically fused. The fused data is used for various purposes, one of our interest is target tracking. The most relevant systems in that context are AIS and X-band marine radar. Many works consider that visual data provided by camera surveillance systems enable additional advantages. Therefore, many tracking algorithms using visual data (images) have been developed. Yet, there is little emphasis on the reasons making the integration of camera systems important. Thus, our main aim in this paper is to analyze the aforementioned surveillance systems for target tracking and conclude some of the maritime security improvements resulted from the integration of cameras to the overall maritime surveillance system.

</p>
</details>

<details><summary><b>Bounding the Width of Neural Networks via Coupled Initialization -- A Worst Case Analysis</b>
<a href="https://arxiv.org/abs/2206.12802">arxiv:2206.12802</a>
&#x1F4C8; 0 <br>
<p>Alexander Munteanu, Simon Omlor, Zhao Song, David P. Woodruff</p></summary>
<p>

**Abstract:** A common method in training neural networks is to initialize all the weights to be independent Gaussian vectors. We observe that by instead initializing the weights into independent pairs, where each pair consists of two identical Gaussian vectors, we can significantly improve the convergence analysis. While a similar technique has been studied for random inputs [Daniely, NeurIPS 2020], it has not been analyzed with arbitrary inputs. Using this technique, we show how to significantly reduce the number of neurons required for two-layer ReLU networks, both in the under-parameterized setting with logistic loss, from roughly $γ^{-8}$ [Ji and Telgarsky, ICLR 2020] to $γ^{-2}$, where $γ$ denotes the separation margin with a Neural Tangent Kernel, as well as in the over-parameterized setting with squared loss, from roughly $n^4$ [Song and Yang, 2019] to $n^2$, implicitly also improving the recent running time bound of [Brand, Peng, Song and Weinstein, ITCS 2021]. For the under-parameterized setting we also prove new lower bounds that improve upon prior work, and that under certain assumptions, are best possible.

</p>
</details>


{% endraw %}
Prev: [2022.06.25]({{ '/2022/06/25/2022.06.25.html' | relative_url }})  Next: [2022.06.27]({{ '/2022/06/27/2022.06.27.html' | relative_url }})