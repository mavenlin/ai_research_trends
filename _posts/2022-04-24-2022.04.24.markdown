Prev: [2022.04.23]({{ '/2022/04/23/2022.04.23.html' | relative_url }})  Next: [2022.04.25]({{ '/2022/04/25/2022.04.25.html' | relative_url }})
{% raw %}
## Summary for 2022-04-24, created on 2022-05-01


<details><summary><b>Heterogeneous Information Network based Default Analysis on Banking Micro and Small Enterprise Users</b>
<a href="https://arxiv.org/abs/2204.11849">arxiv:2204.11849</a>
&#x1F4C8; 6 <br>
<p>Zheng Zhang, Yingsheng Ji, Jiachen Shen, Xi Zhang, Guangwen Yang</p></summary>
<p>

**Abstract:** Risk assessment is a substantial problem for financial institutions that has been extensively studied both for its methodological richness and its various practical applications. With the expansion of inclusive finance, recent attentions are paid to micro and small-sized enterprises (MSEs). Compared with large companies, MSEs present a higher exposure rate to default owing to their insecure financial stability. Conventional efforts learn classifiers from historical data with elaborate feature engineering. However, the main obstacle for MSEs involves severe deficiency in credit-related information, which may degrade the performance of prediction. Besides, financial activities have diverse explicit and implicit relations, which have not been fully exploited for risk judgement in commercial banks. In particular, the observations on real data show that various relationships between company users have additional power in financial risk analysis. In this paper, we consider a graph of banking data, and propose a novel HIDAM model for the purpose. Specifically, we attempt to incorporate heterogeneous information network with rich attributes on multi-typed nodes and links for modeling the scenario of business banking service. To enhance feature representation of MSEs, we extract interactive information through meta-paths and fully exploit path information. Furthermore, we devise a hierarchical attention mechanism respectively to learn the importance of contents inside each meta-path and the importance of different metapahs. Experimental results verify that HIDAM outperforms state-of-the-art competitors on real-world banking data.

</p>
</details>

<details><summary><b>Improved far-field speech recognition using Joint Variational Autoencoder</b>
<a href="https://arxiv.org/abs/2204.11286">arxiv:2204.11286</a>
&#x1F4C8; 6 <br>
<p>Shashi Kumar, Shakti P. Rath, Abhishek Pandey</p></summary>
<p>

**Abstract:** Automatic Speech Recognition (ASR) systems suffer considerably when source speech is corrupted with noise or room impulse responses (RIR). Typically, speech enhancement is applied in both mismatched and matched scenario training and testing. In matched setting, acoustic model (AM) is trained on dereverberated far-field features while in mismatched setting, AM is fixed. In recent past, mapping speech features from far-field to close-talk using denoising autoencoder (DA) has been explored. In this paper, we focus on matched scenario training and show that the proposed joint VAE based mapping achieves a significant improvement over DA. Specifically, we observe an absolute improvement of 2.5% in word error rate (WER) compared to DA based enhancement and 3.96% compared to AM trained directly on far-field filterbank features.

</p>
</details>

<details><summary><b>Unsupervised Hierarchical Semantic Segmentation with Multiview Cosegmentation and Clustering Transformers</b>
<a href="https://arxiv.org/abs/2204.11432">arxiv:2204.11432</a>
&#x1F4C8; 5 <br>
<p>Tsung-Wei Ke, Jyh-Jing Hwang, Yunhui Guo, Xudong Wang, Stella X. Yu</p></summary>
<p>

**Abstract:** Unsupervised semantic segmentation aims to discover groupings within and across images that capture object and view-invariance of a category without external supervision. Grouping naturally has levels of granularity, creating ambiguity in unsupervised segmentation. Existing methods avoid this ambiguity and treat it as a factor outside modeling, whereas we embrace it and desire hierarchical grouping consistency for unsupervised segmentation.
  We approach unsupervised segmentation as a pixel-wise feature learning problem. Our idea is that a good representation shall reveal not just a particular level of grouping, but any level of grouping in a consistent and predictable manner. We enforce spatial consistency of grouping and bootstrap feature learning with co-segmentation among multiple views of the same image, and enforce semantic consistency across the grouping hierarchy with clustering transformers between coarse- and fine-grained features.
  We deliver the first data-driven unsupervised hierarchical semantic segmentation method called Hierarchical Segment Grouping (HSG). Capturing visual similarity and statistical co-occurrences, HSG also outperforms existing unsupervised segmentation methods by a large margin on five major object- and scene-centric benchmarks. Our code is publicly available at https://github.com/twke18/HSG .

</p>
</details>

<details><summary><b>Joint Feature Distribution Alignment Learning for NIR-VIS and VIS-VIS Face Recognition</b>
<a href="https://arxiv.org/abs/2204.11434">arxiv:2204.11434</a>
&#x1F4C8; 4 <br>
<p>Takaya Miyamoto, Hiroshi Hashimoto, Akihiro Hayasaka, Akinori F. Ebihara, Hitoshi Imaoka</p></summary>
<p>

**Abstract:** Face recognition for visible light (VIS) images achieve high accuracy thanks to the recent development of deep learning. However, heterogeneous face recognition (HFR), which is a face matching in different domains, is still a difficult task due to the domain discrepancy and lack of large HFR dataset. Several methods have attempted to reduce the domain discrepancy by means of fine-tuning, which causes significant degradation of the performance in the VIS domain because it loses the highly discriminative VIS representation. To overcome this problem, we propose joint feature distribution alignment learning (JFDAL) which is a joint learning approach utilizing knowledge distillation. It enables us to achieve high HFR performance with retaining the original performance for the VIS domain. Extensive experiments demonstrate that our proposed method delivers statistically significantly better performances compared with the conventional fine-tuning approach on a public HFR dataset Oulu-CASIA NIR&VIS and popular verification datasets in VIS domain such as FLW, CFP, AgeDB. Furthermore, comparative experiments with existing state-of-the-art HFR methods show that our method achieves a comparable HFR performance on the Oulu-CASIA NIR&VIS dataset with less degradation of VIS performance.

</p>
</details>

<details><summary><b>BCI: Breast Cancer Immunohistochemical Image Generation through Pyramid Pix2pix</b>
<a href="https://arxiv.org/abs/2204.11425">arxiv:2204.11425</a>
&#x1F4C8; 4 <br>
<p>Shengjie Liu, Chuang Zhu, Feng Xu, Xinyu Jia, Zhongyue Shi, Mulan Jin</p></summary>
<p>

**Abstract:** The evaluation of human epidermal growth factor receptor 2 (HER2) expression is essential to formulate a precise treatment for breast cancer. The routine evaluation of HER2 is conducted with immunohistochemical techniques (IHC), which is very expensive. Therefore, for the first time, we propose a breast cancer immunohistochemical (BCI) benchmark attempting to synthesize IHC data directly with the paired hematoxylin and eosin (HE) stained images. The dataset contains 4870 registered image pairs, covering a variety of HER2 expression levels. Based on BCI, as a minor contribution, we further build a pyramid pix2pix image generation method, which achieves better HE to IHC translation results than the other current popular algorithms. Extensive experiments demonstrate that BCI poses new challenges to the existing image translation research. Besides, BCI also opens the door for future pathology studies in HER2 expression evaluation based on the synthesized IHC images. BCI dataset can be downloaded from https://bupt-ai-cz.github.io/BCI.

</p>
</details>

<details><summary><b>Riemannian Hamiltonian methods for min-max optimization on manifolds</b>
<a href="https://arxiv.org/abs/2204.11418">arxiv:2204.11418</a>
&#x1F4C8; 4 <br>
<p>Andi Han, Bamdev Mishra, Pratik Jawanpuria, Pawan Kumar, Junbin Gao</p></summary>
<p>

**Abstract:** In this paper, we study the min-max optimization problems on Riemannian manifolds. We introduce a Riemannian Hamiltonian function, minimization of which serves as a proxy for solving the original min-max problems. Under the Riemannian Polyak--≈Åojasiewicz (PL) condition on the Hamiltonian function, its minimizer corresponds to the desired min-max saddle point. We also provide cases where this condition is satisfied. To minimize the Hamiltonian function, we propose Riemannian Hamiltonian methods (RHM) and present their convergence analysis. We extend RHM to include a consensus regularization and to the stochastic setting. We illustrate the efficacy of the proposed RHM in applications such as subspace robust Wasserstein distance, robust training of neural networks, and generative adversarial networks.

</p>
</details>

<details><summary><b>Real-time Speech Emotion Recognition Based on Syllable-Level Feature Extraction</b>
<a href="https://arxiv.org/abs/2204.11382">arxiv:2204.11382</a>
&#x1F4C8; 4 <br>
<p>Abdul Rehman, Zhen-Tao Liu, Min Wu, Wei-Hua Cao, Cheng-Shan Jiang</p></summary>
<p>

**Abstract:** Speech emotion recognition systems have high prediction latency because of the high computational requirements for deep learning models and low generalizability mainly because of the poor reliability of emotional measurements across multiple corpora. To solve these problems, we present a speech emotion recognition system based on a reductionist approach of decomposing and analyzing syllable-level features. Mel-spectrogram of an audio stream is decomposed into syllable-level components, which are then analyzed to extract statistical features. The proposed method uses formant attention, noise-gate filtering, and rolling normalization contexts to increase feature processing speed and tolerance to adversity. A set of syllable-level formant features is extracted and fed into a single hidden layer neural network that makes predictions for each syllable as opposed to the conventional approach of using a sophisticated deep learner to make sentence-wide predictions. The syllable level predictions help to achieve the real-time latency and lower the aggregated error in utterance level cross-corpus predictions. The experiments on IEMOCAP (IE), MSP-Improv (MI), and RAVDESS (RA) databases show that the method archives real-time latency while predicting with state-of-the-art cross-corpus unweighted accuracy of 47.6% for IE to MI and 56.2% for MI to IE.

</p>
</details>

<details><summary><b>Dictionary Attacks on Speaker Verification</b>
<a href="https://arxiv.org/abs/2204.11304">arxiv:2204.11304</a>
&#x1F4C8; 4 <br>
<p>Mirko Marras, Pawel Korus, Anubhav Jain, Nasir Memon</p></summary>
<p>

**Abstract:** In this paper, we propose dictionary attacks against speaker verification - a novel attack vector that aims to match a large fraction of speaker population by chance. We introduce a generic formulation of the attack that can be used with various speech representations and threat models. The attacker uses adversarial optimization to maximize raw similarity of speaker embeddings between a seed speech sample and a proxy population. The resulting master voice successfully matches a non-trivial fraction of people in an unknown population. Adversarial waveforms obtained with our approach can match on average 69% of females and 38% of males enrolled in the target system at a strict decision threshold calibrated to yield false alarm rate of 1%. By using the attack with a black-box voice cloning system, we obtain master voices that are effective in the most challenging conditions and transferable between speaker encoders. We also show that, combined with multiple attempts, this attack opens even more to serious issues on the security of these systems.

</p>
</details>

<details><summary><b>Facility Location with Entrance Fees</b>
<a href="https://arxiv.org/abs/2204.11282">arxiv:2204.11282</a>
&#x1F4C8; 4 <br>
<p>Mengfan Ma, Mingyu Xiao, Tian Bai, Bakh Khoussainov</p></summary>
<p>

**Abstract:** In mechanism design, the facility location game is an extensively studied problem. In the classical model, the cost of each agent is her distance to the nearest facility. In this paper, we consider a new model, where there is a location-dependent entrance fee to the facility. Thus, in our model, the cost of each agent is the sum of the distance to the facility and the entrance fee of the facility. This is a refined generalization of the classical model. We study the model and design strategyproof mechanisms. For one and two facilities, we provide upper and lower bounds for the approximation ratio given by deterministic and randomized mechanisms, with respect to the utilitarian objective and the egalitarian objective. Most of our bounds are tight and these bounds are independent of the entrance fee functions. Our results are as general as possible because the entrance fee function we consider is arbitrary.

</p>
</details>

<details><summary><b>RealNet: Combining Optimized Object Detection with Information Fusion Depth Estimation Co-Design Method on IoT</b>
<a href="https://arxiv.org/abs/2204.11216">arxiv:2204.11216</a>
&#x1F4C8; 4 <br>
<p>Zhuohao Li, Fandi Gou, Qixin De, Leqi Ding, Yuanhang Zhang, Yunze Cai</p></summary>
<p>

**Abstract:** Depth Estimation and Object Detection Recognition play an important role in autonomous driving technology under the guidance of deep learning artificial intelligence. We propose a hybrid structure called RealNet: a co-design method combining the model-streamlined recognition algorithm, the depth estimation algorithm with information fusion, and deploying them on the Jetson-Nano for unmanned vehicles with monocular vision sensors. We use ROS for experiment. The method proposed in this paper is suitable for mobile platforms with high real-time request. Innovation of our method is using information fusion to compensate the problem of insufficient frame rate of output image, and improve the robustness of target detection and depth estimation under monocular vision.Object Detection is based on YOLO-v5. We have simplified the network structure of its DarkNet53 and realized a prediction speed up to 0.01s. Depth Estimation is based on the VNL Depth Estimation, which considers multiple geometric constraints in 3D global space. It calculates the loss function by calculating the deviation of the virtual normal vector VN and the label, which can obtain deeper depth information. We use PnP fusion algorithm to solve the problem of insufficient frame rate of depth map output. It solves the motion estimation depth from three-dimensional target to two-dimensional point based on corner feature matching, which is faster than VNL calculation. We interpolate VNL output and PnP output to achieve information fusion. Experiments show that this can effectively eliminate the jitter of depth information and improve robustness. At the control end, this method combines the results of target detection and depth estimation to calculate the target position, and uses a pure tracking control algorithm to track it.

</p>
</details>

<details><summary><b>Tensorial tomographic differential phase-contrast microscopy</b>
<a href="https://arxiv.org/abs/2204.11397">arxiv:2204.11397</a>
&#x1F4C8; 3 <br>
<p>Shiqi Xu, Xiang Dai, Xi Yang, Kevin C. Zhou, Kanghyun Kim, Vinayak Pathak, Carolyn Glass, Roarke Horstmeyer</p></summary>
<p>

**Abstract:** We report Tensorial Tomographic Differential Phase-Contrast microscopy (T2DPC), a quantitative label-free tomographic imaging method for simultaneous measurement of phase and anisotropy. T2DPC extends differential phase-contrast microscopy, a quantitative phase imaging technique, to highlight the vectorial nature of light. The method solves for permittivity tensor of anisotropic samples from intensity measurements acquired with a standard microscope equipped with an LED matrix, a circular polarizer, and a polarization-sensitive camera. We demonstrate accurate volumetric reconstructions of refractive index, birefringence, and orientation for various validation samples, and show that the reconstructed polarization structures of a biological specimen are predictive of pathology.

</p>
</details>

<details><summary><b>Deep Reinforcement Learning Using a Low-Dimensional Observation Filter for Visual Complex Video Game Playing</b>
<a href="https://arxiv.org/abs/2204.11370">arxiv:2204.11370</a>
&#x1F4C8; 3 <br>
<p>Victor Augusto Kich, Junior Costa de Jesus, Ricardo Bedin Grando, Alisson Henrique Kolling, Gabriel Vin√≠cius Heisler, Rodrigo da Silva Guerra</p></summary>
<p>

**Abstract:** Deep Reinforcement Learning (DRL) has produced great achievements since it was proposed, including the possibility of processing raw vision input data. However, training an agent to perform tasks based on image feedback remains a challenge. It requires the processing of large amounts of data from high-dimensional observation spaces, frame by frame, and the agent's actions are computed according to deep neural network policies, end-to-end. Image pre-processing is an effective way of reducing these high dimensional spaces, eliminating unnecessary information present in the scene, supporting the extraction of features and their representations in the agent's neural network. Modern video-games are examples of this type of challenge for DRL algorithms because of their visual complexity. In this paper, we propose a low-dimensional observation filter that allows a deep Q-network agent to successfully play in a visually complex and modern video-game, called Neon Drive.

</p>
</details>

<details><summary><b>Deep Learning for Medical Image Registration: A Comprehensive Review</b>
<a href="https://arxiv.org/abs/2204.11341">arxiv:2204.11341</a>
&#x1F4C8; 3 <br>
<p>Subrato Bharati, M. Rubaiyat Hossain Mondal, Prajoy Podder, V. B. Surya Prasath</p></summary>
<p>

**Abstract:** Image registration is a critical component in the applications of various medical image analyses. In recent years, there has been a tremendous surge in the development of deep learning (DL)-based medical image registration models. This paper provides a comprehensive review of medical image registration. Firstly, a discussion is provided for supervised registration categories, for example, fully supervised, dual supervised, and weakly supervised registration. Next, similarity-based as well as generative adversarial network (GAN)-based registration are presented as part of unsupervised registration. Deep iterative registration is then described with emphasis on deep similarity-based and reinforcement learning-based registration. Moreover, the application areas of medical image registration are reviewed. This review focuses on monomodal and multimodal registration and associated imaging, for instance, X-ray, CT scan, ultrasound, and MRI. The existing challenges are highlighted in this review, where it is shown that a major challenge is the absence of a training dataset with known transformations. Finally, a discussion is provided on the promising future research areas in the field of DL-based medical image registration.

</p>
</details>

<details><summary><b>Towards the Semantic Weak Generalization Problem in Generative Zero-Shot Learning: Ante-hoc and Post-hoc</b>
<a href="https://arxiv.org/abs/2204.11280">arxiv:2204.11280</a>
&#x1F4C8; 3 <br>
<p>Dubing Chen, Yuming Shen, Haofeng Zhang, Philip H. S. Torr</p></summary>
<p>

**Abstract:** In this paper, we present a simple and effective strategy lowering the previously unexplored factors that limit the performance ceiling of generative Zero-Shot Learning (ZSL). We begin by formally defining semantic generalization, then look into approaches for reducing the semantic weak generalization problem and minimizing its negative influence on classifier training. In the ante-hoc phase, we augment the generator's semantic input, as well as relax the fitting target of the generator. In the post-hoc phase (after generating simulated unseen samples), we derive from the gradient of the loss function to minimize the gradient increment on seen classifier weights carried by biased unseen distribution, which tends to cause misleading on intra-seen class decision boundaries. Without complicated designs, our approach hit the essential problem and significantly outperform the state-of-the-art on four widely used ZSL datasets.

</p>
</details>

<details><summary><b>Lesion Localization in OCT by Semi-Supervised Object Detection</b>
<a href="https://arxiv.org/abs/2204.11227">arxiv:2204.11227</a>
&#x1F4C8; 3 <br>
<p>Yue Wu, Yang Zhou, Jianchun Zhao, Jingyuan Yang, Weihong Yu, Youxin Chen, Xirong Li</p></summary>
<p>

**Abstract:** Over 300 million people worldwide are affected by various retinal diseases. By noninvasive Optical Coherence Tomography (OCT) scans, a number of abnormal structural changes in the retina, namely retinal lesions, can be identified. Automated lesion localization in OCT is thus important for detecting retinal diseases at their early stage. To conquer the lack of manual annotation for deep supervised learning, this paper presents a first study on utilizing semi-supervised object detection (SSOD) for lesion localization in OCT images. To that end, we develop a taxonomy to provide a unified and structured viewpoint of the current SSOD methods, and consequently identify key modules in these methods. To evaluate the influence of these modules in the new task, we build OCT-SS, a new dataset consisting of over 1k expert-labeled OCT B-scan images and over 13k unlabeled B-scans. Extensive experiments on OCT-SS identify Unbiased Teacher (UnT) as the best current SSOD method for lesion localization. Moreover, we improve over this strong baseline, with mAP increased from 49.34 to 50.86.

</p>
</details>

<details><summary><b>Empowering Next POI Recommendation with Multi-Relational Modeling</b>
<a href="https://arxiv.org/abs/2204.12288">arxiv:2204.12288</a>
&#x1F4C8; 2 <br>
<p>Zheng Huang, Jing Ma, Yushun Dong, Natasha Zhang Foutz, Jundong Li</p></summary>
<p>

**Abstract:** With the wide adoption of mobile devices and web applications, location-based social networks (LBSNs) offer large-scale individual-level location-related activities and experiences. Next point-of-interest (POI) recommendation is one of the most important tasks in LBSNs, aiming to make personalized recommendations of next suitable locations to users by discovering preferences from users' historical activities. Noticeably, LBSNs have offered unparalleled access to abundant heterogeneous relational information about users and POIs (including user-user social relations, such as families or colleagues; and user-POI visiting relations). Such relational information holds great potential to facilitate the next POI recommendation. However, most existing methods either focus on merely the user-POI visits, or handle different relations based on over-simplified assumptions while neglecting relational heterogeneities. To fill these critical voids, we propose a novel framework, MEMO, which effectively utilizes the heterogeneous relations with a multi-network representation learning module, and explicitly incorporates the inter-temporal user-POI mutual influence with the coupled recurrent neural networks. Extensive experiments on real-world LBSN data validate the superiority of our framework over the state-of-the-art next POI recommendation methods.

</p>
</details>

<details><summary><b>Memory Efficient Invertible Neural Networks for 3D Photoacoustic Imaging</b>
<a href="https://arxiv.org/abs/2204.11850">arxiv:2204.11850</a>
&#x1F4C8; 2 <br>
<p>Rafael Orozco, Mathias Louboutin, Felix J. Herrmann</p></summary>
<p>

**Abstract:** Photoacoustic imaging (PAI) can image high-resolution structures of clinical interest such as vascularity in cancerous tumor monitoring. When imaging human subjects, geometric restrictions force limited-view data retrieval causing imaging artifacts. Iterative physical model based approaches reduce artifacts but require prohibitively time consuming PDE solves. Machine learning (ML) has accelerated PAI by combining physical models and learned networks. However, the depth and overall power of ML methods is limited by memory intensive training. We propose using invertible neural networks (INNs) to alleviate memory pressure. We demonstrate INNs can image 3D photoacoustic volumes in the setting of limited-view, noisy, and subsampled data. The frugal constant memory usage of INNs enables us to train an arbitrary depth of learned layers on a consumer GPU with 16GB RAM.

</p>
</details>

<details><summary><b>Efficient Neural Neighborhood Search for Pickup and Delivery Problems</b>
<a href="https://arxiv.org/abs/2204.11399">arxiv:2204.11399</a>
&#x1F4C8; 2 <br>
<p>Yining Ma, Jingwen Li, Zhiguang Cao, Wen Song, Hongliang Guo, Yuejiao Gong, Yeow Meng Chee</p></summary>
<p>

**Abstract:** We present an efficient Neural Neighborhood Search (N2S) approach for pickup and delivery problems (PDPs). In specific, we design a powerful Synthesis Attention that allows the vanilla self-attention to synthesize various types of features regarding a route solution. We also exploit two customized decoders that automatically learn to perform removal and reinsertion of a pickup-delivery node pair to tackle the precedence constraint. Additionally, a diversity enhancement scheme is leveraged to further ameliorate the performance. Our N2S is generic, and extensive experiments on two canonical PDP variants show that it can produce state-of-the-art results among existing neural methods. Moreover, it even outstrips the well-known LKH3 solver on the more constrained PDP variant. Our implementation for N2S is available online.

</p>
</details>

<details><summary><b>An empirical study of the effect of background data size on the stability of SHapley Additive exPlanations (SHAP) for deep learning models</b>
<a href="https://arxiv.org/abs/2204.11351">arxiv:2204.11351</a>
&#x1F4C8; 2 <br>
<p>Han Yuan, Mingxuan Liu, Lican Kang, Chenkui Miao, Ying Wu</p></summary>
<p>

**Abstract:** Nowadays, the interpretation of why a machine learning (ML) model makes certain inferences is as crucial as the accuracy of such inferences. Some ML models like the decision tree possess inherent interpretability that can be directly comprehended by humans. Others like artificial neural networks (ANN), however, rely on external methods to uncover the deduction mechanism. SHapley Additive exPlanations (SHAP) is one of such external methods, which requires a background dataset when interpreting ANNs. Generally, a background dataset consists of instances randomly sampled from the training dataset. However, the sampling size and its effect on SHAP remain to be unexplored. In our empirical study on the MIMIC-III dataset, we show that the two core explanations - SHAP values and variable rankings fluctuate when using different background datasets acquired from random sampling, indicating that users cannot unquestioningly trust the one-shot interpretation from SHAP. Luckily, such fluctuation decreases with the increase of the background dataset size. Also, we notice an U-shape in the stability assessment of SHAP variable rankings, demonstrating that SHAP is more reliable in ranking the most and least important variables compared to moderately important ones. Overall, our results suggest that users should take into account how background data affects SHAP results, with improved SHAP stability as the background sample size increases.

</p>
</details>

<details><summary><b>Collaborative Auto-Curricula Multi-Agent Reinforcement Learning with Graph Neural Network Communication Layer for Open-ended Wildfire-Management Resource Distribution</b>
<a href="https://arxiv.org/abs/2204.11350">arxiv:2204.11350</a>
&#x1F4C8; 2 <br>
<p>Philipp Dominic Siedler</p></summary>
<p>

**Abstract:** Most real-world domains can be formulated as multi-agent (MA) systems. Intentionality sharing agents can solve more complex tasks by collaborating, possibly in less time. True cooperative actions are beneficial for egoistic and collective reasons. However, teaching individual agents to sacrifice egoistic benefits for a better collective performance seems challenging. We build on a recently proposed Multi-Agent Reinforcement Learning (MARL) mechanism with a Graph Neural Network (GNN) communication layer. Rarely chosen communication actions were marginally beneficial. Here we propose a MARL system in which agents can help collaborators perform better while risking low individual performance. We conduct our study in the context of resource distribution for wildfire management. Communicating environmental features and partially observable fire occurrence help the agent collective to pre-emptively distribute resources. Furthermore, we introduce a procedural training environment accommodating auto-curricula and open-endedness towards better generalizability. Our MA communication proposal outperforms a Greedy Heuristic Baseline and a Single-Agent (SA) setup. We further demonstrate how auto-curricula and openendedness improves generalizability of our MA proposal.

</p>
</details>

<details><summary><b>Farmer's Assistant: A Machine Learning Based Application for Agricultural Solutions</b>
<a href="https://arxiv.org/abs/2204.11340">arxiv:2204.11340</a>
&#x1F4C8; 2 <br>
<p>Shloka Gupta, Akshay Chopade, Nishit Jain, Aparna Bhonde</p></summary>
<p>

**Abstract:** Farmers face several challenges when growing crops like uncertain irrigation, poor soil quality, etc. Especially in India, a major fraction of farmers do not have the knowledge to select appropriate crops and fertilizers. Moreover, crop failure due to disease causes a significant loss to the farmers, as well as the consumers. While there have been recent developments in the automated detection of these diseases using Machine Learning techniques, the utilization of Deep Learning has not been fully explored. Additionally, such models are not easy to use because of the high-quality data used in their training, lack of computational power, and poor generalizability of the models. To this end, we create an open-source easy-to-use web application to address some of these issues which may help improve crop production. In particular, we support crop recommendation, fertilizer recommendation, plant disease prediction, and an interactive news-feed. In addition, we also use interpretability techniques in an attempt to explain the prediction made by our disease detection model.

</p>
</details>

<details><summary><b>Colorectal cancer survival prediction using deep distribution based multiple-instance learning</b>
<a href="https://arxiv.org/abs/2204.11294">arxiv:2204.11294</a>
&#x1F4C8; 2 <br>
<p>Xingyu Li, Jitendra Jonnagaddala, Min Cen, Hong Zhang, Xu Steven Xu</p></summary>
<p>

**Abstract:** Several deep learning algorithms have been developed to predict survival of cancer patients using whole slide images (WSIs).However, identification of image phenotypes within the WSIs that are relevant to patient survival and disease progression is difficult for both clinicians, and deep learning algorithms. Most deep learning based Multiple Instance Learning (MIL) algorithms for survival prediction use either top instances (e.g., maxpooling) or top/bottom instances (e.g., MesoNet) to identify image phenotypes. In this study, we hypothesize that wholistic information of the distribution of the patch scores within a WSI can predict the cancer survival better. We developed a distribution based multiple-instance survival learning algorithm (DeepDisMISL) to validate this hypothesis. We designed and executed experiments using two large international colorectal cancer WSIs datasets - MCO CRC and TCGA COAD-READ. Our results suggest that the more information about the distribution of the patch scores for a WSI, the better is the prediction performance. Including multiple neighborhood instances around each selected distribution location (e.g., percentiles) could further improve the prediction. DeepDisMISL demonstrated superior predictive ability compared to other recently published, state-of-the-art algorithms. Furthermore, our algorithm is interpretable and could assist in understanding the relationship between cancer morphological phenotypes and patients cancer survival risk.

</p>
</details>

<details><summary><b>Unsupervised Learning Discriminative MIG Detectors in Nonhomogeneous Clutter</b>
<a href="https://arxiv.org/abs/2204.11278">arxiv:2204.11278</a>
&#x1F4C8; 2 <br>
<p>Xiaoqiang Hua, Yusuke Ono, Linyu Peng, Yuting Xu</p></summary>
<p>

**Abstract:** Principal component analysis (PCA) is a common used pattern analysis method that maps high-dimensional data into a lower-dimensional space maximizing the data variance, that results in the promotion of separability of data. Inspired by the principle of PCA, a novel type of learning discriminative matrix information geometry (MIG) detectors in the unsupervised scenario are developed, and applied to signal detection in nonhomogeneous environments. Hermitian positive-definite (HPD) matrices can be used to model the sample data, while the clutter covariance matrix is estimated by the geometric mean of a set of secondary HPD matrices. We define a projection that maps the HPD matrices in a high-dimensional manifold to a low-dimensional and more discriminative one to increase the degree of separation of HPD matrices by maximizing the data variance. Learning a mapping can be formulated as a two-step mini-max optimization problem in Riemannian manifolds, which can be solved by the Riemannian gradient descent algorithm. Three discriminative MIG detectors are illustrated with respect to different geometric measures, i.e., the Log-Euclidean metric, the Jensen--Bregman LogDet divergence and the symmetrized Kullback--Leibler divergence. Simulation results show that performance improvements of the novel MIG detectors can be achieved compared with the conventional detectors and their state-of-the-art counterparts within nonhomogeneous environments.

</p>
</details>

<details><summary><b>Piecewise-Linear Activations or Analytic Activation Functions: Which Produce More Expressive Neural Networks?</b>
<a href="https://arxiv.org/abs/2204.11231">arxiv:2204.11231</a>
&#x1F4C8; 2 <br>
<p>Anastasis Kratsios, Behnoosh Zamanlooy</p></summary>
<p>

**Abstract:** Many currently available universal approximation theorems affirm that deep feedforward networks defined using any suitable activation function can approximate any integrable function locally in $L^1$-norm. Though different approximation rates are available for deep neural networks defined using other classes of activation functions, there is little explanation for the empirically confirmed advantage that ReLU networks exhibit over their classical (e.g. sigmoidal) counterparts. Our main result demonstrates that deep networks with piecewise linear activation (e.g. ReLU or PReLU) are fundamentally more expressive than deep feedforward networks with analytic (e.g. sigmoid, Swish, GeLU, or Softplus). More specifically, we construct a strict refinement of the topology on the space $L^1_{\operatorname{loc}}(\mathbb{R}^d,\mathbb{R}^D)$ of locally Lebesgue-integrable functions, in which the set of deep ReLU networks with (bilinear) pooling $\operatorname{NN}^{\operatorname{ReLU} + \operatorname{Pool}}$ is dense (i.e. universal) but the set of deep feedforward networks defined using any combination of analytic activation functions with (or without) pooling layers $\operatorname{NN}^{œâ+\operatorname{Pool}}$ is not dense (i.e. not universal). Our main result is further explained by \textit{quantitatively} demonstrating that this "separation phenomenon" between the networks in $\operatorname{NN}^{\operatorname{ReLU}+\operatorname{Pool}}$ and those in $\operatorname{NN}^{œâ+\operatorname{Pool}}$ by showing that the networks in $\operatorname{NN}^{\operatorname{ReLU}}$ are capable of approximate any compactly supported Lipschitz function while \textit{simultaneously} approximating its essential support; whereas, the networks in $\operatorname{NN}^{œâ+\operatorname{pool}}$ cannot.

</p>
</details>

<details><summary><b>Bounding the Effects of Continuous Treatments for Hidden Confounders</b>
<a href="https://arxiv.org/abs/2204.11206">arxiv:2204.11206</a>
&#x1F4C8; 2 <br>
<p>Myrl G. Marmarelis, Greg Ver Steeg, Aram Galstyan</p></summary>
<p>

**Abstract:** Causal inference involves the disentanglement of effects due to a treatment variable from those of confounders, observed as covariates or not. Since one outcome is ever observed at a time, the problem turns into one of predicting counterfactuals on every individual in the dataset. Observational studies complicate this endeavor by permitting dependencies between the treatment and other variables in the sample. If the covariates influence the propensity of treatment, then one suffers from covariate shift. Should the outcome and the treatment be affected by another variable even after accounting for the covariates, there is also hidden confounding. That is immeasurable by definition. Rather, one must study the worst possible consequences of bounded levels of hidden confounding on downstream decision-making. We explore this problem in the case of continuous treatments. We develop a framework to compute ignorance intervals on the partially identified dose-response curves, which enable us to quantify the susceptibility of our inference to hidden confounders. Our method is supported by simulations as well as empirical tests based on two observational studies.

</p>
</details>

<details><summary><b>Signal Recovery with Non-Expansive Generative Network Priors</b>
<a href="https://arxiv.org/abs/2204.13599">arxiv:2204.13599</a>
&#x1F4C8; 1 <br>
<p>Jorio Cocola</p></summary>
<p>

**Abstract:** We study compressive sensing with a deep generative network prior. Initial theoretical guarantees for efficient recovery from compressed linear measurements have been developed for signals in the range of a ReLU network with Gaussian weights and logarithmic expansivity: that is when each layer is larger than the previous one by a logarithmic factor. It was later shown that constant expansivity is sufficient for recovery. It has remained open whether the expansivity can be relaxed allowing for networks with contractive layers, as often the case of real generators. In this work we answer this question, proving that a signal in the range of a Gaussian generative network can be recovered from a few linear measurements provided that the width of the layers is proportional to the input layer size (up to log factors). This condition allows the generative network to have contractive layers. Our result is based on showing that Gaussian matrices satisfy a matrix concentration inequality, which we term Range Restricted Weight Distribution Condition (R2WDC), and weakens the Weight Distribution Condition (WDC) upon which previous theoretical guarantees were based on. The WDC has also been used to analyze other signal recovery problems with generative network priors. By replacing the WDC with the R2WDC, we are able to extend previous results for signal recovery with expansive generative network priors to non-expansive ones. We discuss these extensions for phase retrieval, denoising, and spiked matrix recovery.

</p>
</details>

<details><summary><b>Accelerated Multiplicative Weights Update Avoids Saddle Points almost always</b>
<a href="https://arxiv.org/abs/2204.11407">arxiv:2204.11407</a>
&#x1F4C8; 1 <br>
<p>Yi Feng, Ioannis Panageas, Xiao Wang</p></summary>
<p>

**Abstract:** We consider non-convex optimization problems with constraint that is a product of simplices. A commonly used algorithm in solving this type of problem is the Multiplicative Weights Update (MWU), an algorithm that is widely used in game theory, machine learning and multi-agent systems. Despite it has been known that MWU avoids saddle points, there is a question that remains unaddressed:"Is there an accelerated version of MWU that avoids saddle points provably?" In this paper we provide a positive answer to above question. We provide an accelerated MWU based on Riemannian Accelerated Gradient Descent, and prove that the Riemannian Accelerated Gradient Descent, thus the accelerated MWU, almost always avoid saddle points.

</p>
</details>

<details><summary><b>Adaptive cognitive fit: Artificial intelligence augmented management of information facets and representations</b>
<a href="https://arxiv.org/abs/2204.11405">arxiv:2204.11405</a>
&#x1F4C8; 1 <br>
<p>Jim Samuel, Rajiv Kashyap, Yana Samuel, Alexander Pelaez</p></summary>
<p>

**Abstract:** Explosive growth in big data technologies and artificial intelligence [AI] applications have led to increasing pervasiveness of information facets and a rapidly growing array of information representations. Information facets, such as equivocality and veracity, can dominate and significantly influence human perceptions of information and consequently affect human performance. Extant research in cognitive fit, which preceded the big data and AI era, focused on the effects of aligning information representation and task on performance, without sufficient consideration to information facets and attendant cognitive challenges. Therefore, there is a compelling need to understand the interplay of these dominant information facets with information representations and tasks, and their influence on human performance. We suggest that artificially intelligent technologies that can adapt information representations to overcome cognitive limitations are necessary for these complex information environments. To this end, we propose and test a novel *Adaptive Cognitive Fit* [ACF] framework that explains the influence of information facets and AI-augmented information representations on human performance. We draw on information processing theory and cognitive dissonance theory to advance the ACF framework and a set of propositions. We empirically validate the ACF propositions with an economic experiment that demonstrates the influence of information facets, and a machine learning simulation that establishes the viability of using AI to improve human performance.

</p>
</details>

<details><summary><b>Numerical Computation of Partial Differential Equations by Hidden-Layer Concatenated Extreme Learning Machine</b>
<a href="https://arxiv.org/abs/2204.11375">arxiv:2204.11375</a>
&#x1F4C8; 1 <br>
<p>Naxian Ni, Suchuan Dong</p></summary>
<p>

**Abstract:** The extreme learning machine (ELM) method can yield highly accurate solutions to linear/nonlinear partial differential equations (PDEs), but requires the last hidden layer of the neural network to be wide to achieve a high accuracy. If the last hidden layer is narrow, the accuracy of the existing ELM method will be poor, irrespective of the rest of the network configuration. In this paper we present a modified ELM method, termed HLConcELM (hidden-layer concatenated ELM), to overcome the above drawback of the conventional ELM method. The HLConcELM method can produce highly accurate solutions to linear/nonlinear PDEs when the last hidden layer of the network is narrow and when it is wide. The new method is based on a type of modified feedforward neural networks (FNN), termed HLConcFNN (hidden-layer concatenated FNN), which incorporates a logical concatenation of the hidden layers in the network and exposes all the hidden nodes to the output-layer nodes. We show that HLConcFNNs have the remarkable property that, given a network architecture, when additional hidden layers are appended to the network or when extra nodes are added to the existing hidden layers, the approximation capacity of the HLConcFNN associated with the new architecture is guaranteed to be not smaller than that of the original network architecture. We present ample benchmark tests with linear/nonlinear PDEs to demonstrate the computational accuracy and performance of the HLConcELM method and the superiority of this method to the conventional ELM from previous works.

</p>
</details>

<details><summary><b>Learning to Attack Powergrids with DERs</b>
<a href="https://arxiv.org/abs/2204.11352">arxiv:2204.11352</a>
&#x1F4C8; 1 <br>
<p>Eric MSP Veith, Nils Wenninghoff, Stephan Balduin, Thomas Wolgast, Sebastian Lehnhoff</p></summary>
<p>

**Abstract:** In the past years, power grids have become a valuable target for cyber-attacks. Especially the attacks on the Ukrainian power grid has sparked numerous research into possible attack vectors, their extent, and possible mitigations. However, many fail to consider realistic scenarios in which time series are incorporated into simulations to reflect the transient behaviour of independent generators and consumers. Moreover, very few consider the limited sensory input of a potential attacker. In this paper, we describe a reactive power attack based on a well-understood scenario. We show that independent agents can learn to use the dynamics of the power grid against it and that the attack works even in the face of other generator and consumer nodes acting independently.

</p>
</details>

<details><summary><b>Predicting Sleeping Quality using Convolutional Neural Networks</b>
<a href="https://arxiv.org/abs/2204.13584">arxiv:2204.13584</a>
&#x1F4C8; 0 <br>
<p>Vidya Rohini Konanur Sathish, Wai Lok Woo, Edmond S. L. Ho</p></summary>
<p>

**Abstract:** Identifying sleep stages and patterns is an essential part of diagnosing and treating sleep disorders. With the advancement of smart technologies, sensor data related to sleeping patterns can be captured easily. In this paper, we propose a Convolution Neural Network (CNN) architecture that improves the classification performance. In particular, we benchmark the classification performance from different methods, including traditional machine learning methods such as Logistic Regression (LR), Decision Trees (DT), k-Nearest Neighbour (k-NN), Naive Bayes (NB) and Support Vector Machine (SVM), on 3 publicly available sleep datasets. The accuracy, sensitivity, specificity, precision, recall, and F-score are reported and will serve as a baseline to simulate the research in this direction in the future.

</p>
</details>

<details><summary><b>Uncoupled Learning Dynamics with $O(\log T)$ Swap Regret in Multiplayer Games</b>
<a href="https://arxiv.org/abs/2204.11417">arxiv:2204.11417</a>
&#x1F4C8; 0 <br>
<p>Ioannis Anagnostides, Gabriele Farina, Christian Kroer, Chung-Wei Lee, Haipeng Luo, Tuomas Sandholm</p></summary>
<p>

**Abstract:** In this paper we establish efficient and \emph{uncoupled} learning dynamics so that, when employed by all players in a general-sum multiplayer game, the \emph{swap regret} of each player after $T$ repetitions of the game is bounded by $O(\log T)$, improving over the prior best bounds of $O(\log^4 (T))$. At the same time, we guarantee optimal $O(\sqrt{T})$ swap regret in the adversarial regime as well. To obtain these results, our primary contribution is to show that when all players follow our dynamics with a \emph{time-invariant} learning rate, the \emph{second-order path lengths} of the dynamics up to time $T$ are bounded by $O(\log T)$, a fundamental property which could have further implications beyond near-optimally bounding the (swap) regret. Our proposed learning dynamics combine in a novel way \emph{optimistic} regularized learning with the use of \emph{self-concordant barriers}. Further, our analysis is remarkably simple, bypassing the cumbersome framework of higher-order smoothness recently developed by Daskalakis, Fishelson, and Golowich (NeurIPS'21).

</p>
</details>

<details><summary><b>Robust Self-Augmentation for Named Entity Recognition with Meta Reweighting</b>
<a href="https://arxiv.org/abs/2204.11406">arxiv:2204.11406</a>
&#x1F4C8; 0 <br>
<p>Linzhi Wu, Pengjun Xie, Jie Zhou, Meishan Zhang, Chunping Ma, Guangwei Xu, Min Zhang</p></summary>
<p>

**Abstract:** Self-augmentation has been received increasing research interest recently to improve named entity recognition (NER) performance in low-resource scenarios. Token substitution and mixup are two feasible heterogeneous self-augmentation techniques for NER that can achieve effective performance with certain specialized efforts. Noticeably, self-augmentation may introduce potentially noisy augmented data. Prior research has mainly resorted to heuristic rule based constraints to reduce the noise for specific self-augmentation individually. In this paper, we revisit the two self-augmentation methods for NER, and propose a unified meta-reweighting strategy for these heterogeneous methods to achieve a natural integration. Our method is easily extensible, imposing little effort on a specific self-augmentation method. Experiments on different Chinese and English NER benchmarks demonstrate that our token substitution and mixup method, as well as their integration, can obtain effective performance improvement. Based on the meta-reweighting mechanism, we can enhance the advantages of the self-augmentation techniques without extra efforts.

</p>
</details>


{% endraw %}
Prev: [2022.04.23]({{ '/2022/04/23/2022.04.23.html' | relative_url }})  Next: [2022.04.25]({{ '/2022/04/25/2022.04.25.html' | relative_url }})