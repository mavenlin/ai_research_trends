## Summary for 2021-03-20, created on 2021-12-23


<details><summary><b>MonteFloor: Extending MCTS for Reconstructing Accurate Large-Scale Floor Plans</b>
<a href="https://arxiv.org/abs/2103.11161">arxiv:2103.11161</a>
&#x1F4C8; 22 <br>
<p>Sinisa Stekovic, Mahdi Rad, Friedrich Fraundorfer, Vincent Lepetit</p></summary>
<p>

**Abstract:** We propose a novel method for reconstructing floor plans from noisy 3D point clouds. Our main contribution is a principled approach that relies on the Monte Carlo Tree Search (MCTS) algorithm to maximize a suitable objective function efficiently despite the complexity of the problem. Like previous work, we first project the input point cloud to a top view to create a density map and extract room proposals from it. Our method selects and optimizes the polygonal shapes of these room proposals jointly to fit the density map and outputs an accurate vectorized floor map even for large complex scenes. To do this, we adapted MCTS, an algorithm originally designed to learn to play games, to select the room proposals by maximizing an objective function combining the fitness with the density map as predicted by a deep network and regularizing terms on the room shapes. We also introduce a refinement step to MCTS that adjusts the shape of the room proposals. For this step, we propose a novel differentiable method for rendering the polygonal shapes of these proposals. We evaluate our method on the recent and challenging Structured3D and Floor-SP datasets and show a significant improvement over the state-of-the-art, without imposing any hard constraints nor assumptions on the floor plan configurations.

</p>
</details>

<details><summary><b>The Effectiveness of Morphology-aware Segmentation in Low-Resource Neural Machine Translation</b>
<a href="https://arxiv.org/abs/2103.11189">arxiv:2103.11189</a>
&#x1F4C8; 9 <br>
<p>Jonne Sälevä, Constantine Lignos</p></summary>
<p>

**Abstract:** This paper evaluates the performance of several modern subword segmentation methods in a low-resource neural machine translation setting. We compare segmentations produced by applying BPE at the token or sentence level with morphologically-based segmentations from LMVR and MORSEL. We evaluate translation tasks between English and each of Nepali, Sinhala, and Kazakh, and predict that using morphologically-based segmentation methods would lead to better performance in this setting. However, comparing to BPE, we find that no consistent and reliable differences emerge between the segmentation methods. While morphologically-based methods outperform BPE in a few cases, what performs best tends to vary across tasks, and the performance of segmentation methods is often statistically indistinguishable.

</p>
</details>

<details><summary><b>Unsupervised Feature Learning for Manipulation with Contrastive Domain Randomization</b>
<a href="https://arxiv.org/abs/2103.11144">arxiv:2103.11144</a>
&#x1F4C8; 9 <br>
<p>Carmel Rabinovitz, Niko Grupen, Aviv Tamar</p></summary>
<p>

**Abstract:** Robotic tasks such as manipulation with visual inputs require image features that capture the physical properties of the scene, e.g., the position and configuration of objects. Recently, it has been suggested to learn such features in an unsupervised manner from simulated, self-supervised, robot interaction; the idea being that high-level physical properties are well captured by modern physical simulators, and their representation from visual inputs may transfer well to the real world. In particular, learning methods based on noise contrastive estimation have shown promising results. To robustify the simulation-to-real transfer, domain randomization (DR) was suggested for learning features that are invariant to irrelevant visual properties such as textures or lighting. In this work, however, we show that a naive application of DR to unsupervised learning based on contrastive estimation does not promote invariance, as the loss function maximizes mutual information between the features and both the relevant and irrelevant visual properties. We propose a simple modification of the contrastive loss to fix this, exploiting the fact that we can control the simulated randomization of visual properties. Our approach learns physical features that are significantly more robust to visual domain variation, as we demonstrate using both rigid and non-rigid objects.

</p>
</details>

<details><summary><b>Temporally-Weighted Hierarchical Clustering for Unsupervised Action Segmentation</b>
<a href="https://arxiv.org/abs/2103.11264">arxiv:2103.11264</a>
&#x1F4C8; 7 <br>
<p>M. Saquib Sarfraz, Naila Murray, Vivek Sharma, Ali Diba, Luc Van Gool, Rainer Stiefelhagen</p></summary>
<p>

**Abstract:** Action segmentation refers to inferring boundaries of semantically consistent visual concepts in videos and is an important requirement for many video understanding tasks. For this and other video understanding tasks, supervised approaches have achieved encouraging performance but require a high volume of detailed frame-level annotations. We present a fully automatic and unsupervised approach for segmenting actions in a video that does not require any training. Our proposal is an effective temporally-weighted hierarchical clustering algorithm that can group semantically consistent frames of the video. Our main finding is that representing a video with a 1-nearest neighbor graph by taking into account the time progression is sufficient to form semantically and temporally consistent clusters of frames where each cluster may represent some action in the video. Additionally, we establish strong unsupervised baselines for action segmentation and show significant performance improvements over published unsupervised methods on five challenging action segmentation datasets. Our code is available at https://github.com/ssarfraz/FINCH-Clustering/tree/master/TW-FINCH

</p>
</details>

<details><summary><b>Paying Attention to Multiscale Feature Maps in Multimodal Image Matching</b>
<a href="https://arxiv.org/abs/2103.11247">arxiv:2103.11247</a>
&#x1F4C8; 6 <br>
<p>Aviad Moreshet, Yosi Keller</p></summary>
<p>

**Abstract:** We propose an attention-based approach for multimodal image patch matching using a Transformer encoder attending to the feature maps of a multiscale Siamese CNN. Our encoder is shown to efficiently aggregate multiscale image embeddings while emphasizing task-specific appearance-invariant image cues. We also introduce an attention-residual architecture, using a residual connection bypassing the encoder. This additional learning signal facilitates end-to-end training from scratch. Our approach is experimentally shown to achieve new state-of-the-art accuracy on both multimodal and single modality benchmarks, illustrating its general applicability. To the best of our knowledge, this is the first successful implementation of the Transformer encoder architecture to the multimodal image patch matching task.

</p>
</details>

<details><summary><b>Artificial intelligence for detection and quantification of rust and leaf miner in coffee crop</b>
<a href="https://arxiv.org/abs/2103.11241">arxiv:2103.11241</a>
&#x1F4C8; 5 <br>
<p>Alvaro Leandro Cavalcante Carneiro, Lucas de Brito Silva, Marisa Silveira Almeida Renaud Faulin</p></summary>
<p>

**Abstract:** Pest and disease control plays a key role in agriculture since the damage caused by these agents are responsible for a huge economic loss every year. Based on this assumption, we create an algorithm capable of detecting rust (Hemileia vastatrix) and leaf miner (Leucoptera coffeella) in coffee leaves (Coffea arabica) and quantify disease severity using a mobile application as a high-level interface for the model inferences. We used different convolutional neural network architectures to create the object detector, besides the OpenCV library, k-means, and three treatments: the RGB and value to quantification, and the AFSoft software, in addition to the analysis of variance, where we compare the three methods. The results show an average precision of 81,5% in the detection and that there was no significant statistical difference between treatments to quantify the severity of coffee leaves, proposing a computationally less costly method. The application, together with the trained model, can detect the pest and disease over different image conditions and infection stages and also estimate the disease infection stage.

</p>
</details>

<details><summary><b>Learning Continuous Cost-to-Go Functions for Non-holonomic Systems</b>
<a href="https://arxiv.org/abs/2103.11168">arxiv:2103.11168</a>
&#x1F4C8; 5 <br>
<p>Jinwook Huh, Daniel D. Lee, Volkan Isler</p></summary>
<p>

**Abstract:** This paper presents a supervised learning method to generate continuous cost-to-go functions of non-holonomic systems directly from the workspace description. Supervision from informative examples reduces training time and improves network performance. The manifold representing the optimal trajectories of a non-holonomic system has high-curvature regions which can not be efficiently captured with uniform sampling. To address this challenge, we present an adaptive sampling method which makes use of sampling-based planners along with local, closed-form solutions to generate training samples. The cost-to-go function over a specific workspace is represented as a neural network whose weights are generated by a second, higher order network. The networks are trained in an end-to-end fashion. In our previous work, this architecture was shown to successfully learn to generate the cost-to-go functions of holonomic systems using uniform sampling. In this work, we show that uniform sampling fails for non-holonomic systems. However, with the proposed adaptive sampling methodology, our network can generate near-optimal trajectories for non-holonomic systems while avoiding obstacles. Experiments show that our method is two orders of magnitude faster compared to traditional approaches in cluttered environments.

</p>
</details>

<details><summary><b>High precision control and deep learning-based corn stand counting algorithms for agricultural robot</b>
<a href="https://arxiv.org/abs/2103.11276">arxiv:2103.11276</a>
&#x1F4C8; 4 <br>
<p>Zhongzhong Zhang, Erkan Kayacan, Benjamin Thompson, Girish Chowdhary</p></summary>
<p>

**Abstract:** This paper presents high precision control and deep learning-based corn stand counting algorithms for a low-cost, ultra-compact 3D printed and autonomous field robot for agricultural operations. Currently, plant traits, such as emergence rate, biomass, vigor, and stand counting, are measured manually. This is highly labor-intensive and prone to errors. The robot, termed TerraSentia, is designed to automate the measurement of plant traits for efficient phenotyping as an alternative to manual measurements. In this paper, we formulate a Nonlinear Moving Horizon Estimator (NMHE) that identifies key terrain parameters using onboard robot sensors and a learning-based Nonlinear Model Predictive Control (NMPC) that ensures high precision path tracking in the presence of unknown wheel-terrain interaction. Moreover, we develop a machine vision algorithm designed to enable an ultra-compact ground robot to count corn stands by driving through the fields autonomously. The algorithm leverages a deep network to detect corn plants in images, and a visual tracking model to re-identify detected objects at different time steps. We collected data from 53 corn plots in various fields for corn plants around 14 days after emergence (stage V3 - V4). The robot predictions have agreed well with the ground truth with $C_{robot}=1.02 \times C_{human}-0.86$ and a correlation coefficient $R=0.96$. The mean relative error given by the algorithm is $-3.78\%$, and the standard deviation is $6.76\%$. These results indicate a first and significant step towards autonomous robot-based real-time phenotyping using low-cost, ultra-compact ground robots for corn and potentially other crops.

</p>
</details>

<details><summary><b>Adaptive deep density approximation for Fokker-Planck equations</b>
<a href="https://arxiv.org/abs/2103.11181">arxiv:2103.11181</a>
&#x1F4C8; 4 <br>
<p>Kejun Tang, Xiaoliang Wan, Qifeng Liao</p></summary>
<p>

**Abstract:** In this paper we present an adaptive deep density approximation strategy based on KRnet (ADDA-KR) for solving the steady-state Fokker-Planck (F-P) equations. F-P equations are usually high-dimensional and defined on an unbounded domain, which limits the application of traditional grid based numerical methods. With the Knothe-Rosenblatt rearrangement, our newly proposed flow-based generative model, called KRnet, provides a family of probability density functions to serve as effective solution candidates for the Fokker-Planck equations, which has a weaker dependence on dimensionality than traditional computational approaches and can efficiently estimate general high-dimensional density functions. To obtain effective stochastic collocation points for the approximation of the F-P equation, we develop an adaptive sampling procedure, where samples are generated iteratively using the approximate density function at each iteration. We present a general framework of ADDA-KR, validate its accuracy and demonstrate its efficiency with numerical experiments.

</p>
</details>

<details><summary><b>NCoRE: Neural Counterfactual Representation Learning for Combinations of Treatments</b>
<a href="https://arxiv.org/abs/2103.11175">arxiv:2103.11175</a>
&#x1F4C8; 4 <br>
<p>Sonali Parbhoo, Stefan Bauer, Patrick Schwab</p></summary>
<p>

**Abstract:** Estimating an individual's potential response to interventions from observational data is of high practical relevance for many domains, such as healthcare, public policy or economics. In this setting, it is often the case that combinations of interventions may be applied simultaneously, for example, multiple prescriptions in healthcare or different fiscal and monetary measures in economics. However, existing methods for counterfactual inference are limited to settings in which actions are not used simultaneously. Here, we present Neural Counterfactual Relation Estimation (NCoRE), a new method for learning counterfactual representations in the combination treatment setting that explicitly models cross-treatment interactions. NCoRE is based on a novel branched conditional neural representation that includes learnt treatment interaction modulators to infer the potential causal generative process underlying the combination of multiple treatments. Our experiments show that NCoRE significantly outperforms existing state-of-the-art methods for counterfactual treatment effect estimation that do not account for the effects of combining multiple treatments across several synthetic, semi-synthetic and real-world benchmarks.

</p>
</details>

<details><summary><b>Your Classifier can Secretly Suffice Multi-Source Domain Adaptation</b>
<a href="https://arxiv.org/abs/2103.11169">arxiv:2103.11169</a>
&#x1F4C8; 4 <br>
<p>Naveen Venkat, Jogendra Nath Kundu, Durgesh Kumar Singh, Ambareesh Revanur, R. Venkatesh Babu</p></summary>
<p>

**Abstract:** Multi-Source Domain Adaptation (MSDA) deals with the transfer of task knowledge from multiple labeled source domains to an unlabeled target domain, under a domain-shift. Existing methods aim to minimize this domain-shift using auxiliary distribution alignment objectives. In this work, we present a different perspective to MSDA wherein deep models are observed to implicitly align the domains under label supervision. Thus, we aim to utilize implicit alignment without additional training objectives to perform adaptation. To this end, we use pseudo-labeled target samples and enforce a classifier agreement on the pseudo-labels, a process called Self-supervised Implicit Alignment (SImpAl). We find that SImpAl readily works even under category-shift among the source domains. Further, we propose classifier agreement as a cue to determine the training convergence, resulting in a simple training algorithm. We provide a thorough evaluation of our approach on five benchmarks, along with detailed insights into each component of our approach.

</p>
</details>

<details><summary><b>Data-driven Aerodynamic Analysis of Structures using Gaussian Processes</b>
<a href="https://arxiv.org/abs/2103.13877">arxiv:2103.13877</a>
&#x1F4C8; 3 <br>
<p>Igor Kavrakov, Allan McRobie, Guido Morgenthal</p></summary>
<p>

**Abstract:** An abundant amount of data gathered during wind tunnel testing and health monitoring of structures inspires the use of machine learning methods to replicate the wind forces. These forces are critical for both the design and life-cycle assessment of lifeline structures such as bridges. This paper presents a data-driven Gaussian Process-Nonlinear Finite Impulse Response (GP-NFIR) model of the nonlinear self-excited forces acting on bridges. Constructed in a nondimensional form, the model takes the effective wind angle of attack as lagged exogenous input and outputs a probability distribution of the aerodynamic forces. The nonlinear latent function, mapping the input to the output, is modeled by a GP regression. Consequently, the model is nonparametric, and as such, it avoids setting up the latent function's structure a priori. The training input is designed as band-limited random harmonic motion that consists of vertical and rotational displacements. Once trained, the model can predict the aerodynamic forces for both prescribed input motion and coupled aeroelastic analysis. The presented concept is first verified for a flat plate's analytical, linear solution by predicting the self-excited forces and flutter velocity. Finally, the framework is applied to a streamlined and bluff bridge deck based on Computational Fluid Dynamics (CFD) data. Here, the model's ability to predict nonlinear aerodynamic forces, critical flutter limit, and post-flutter behavior are highlighted. Further applications of the presented framework are foreseen in the design and online real-time monitoring of slender line-like structures.

</p>
</details>

<details><summary><b>MetaHDR: Model-Agnostic Meta-Learning for HDR Image Reconstruction</b>
<a href="https://arxiv.org/abs/2103.12545">arxiv:2103.12545</a>
&#x1F4C8; 3 <br>
<p>Edwin Pan, Anthony Vento</p></summary>
<p>

**Abstract:** Capturing scenes with a high dynamic range is crucial to reproducing images that appear similar to those seen by the human visual system. Despite progress in developing data-driven deep learning approaches for converting low dynamic range images to high dynamic range images, existing approaches are limited by the assumption that all conversions are governed by the same nonlinear mapping. To address this problem, we propose "Model-Agnostic Meta-Learning for HDR Image Reconstruction" (MetaHDR), which applies meta-learning to the LDR-to-HDR conversion problem using existing HDR datasets. Our key novelty is the reinterpretation of LDR-to-HDR conversion scenes as independently sampled tasks from a common LDR-to-HDR conversion task distribution. Naturally, we use a meta-learning framework that learns a set of meta-parameters which capture the common structure consistent across all LDR-to-HDR conversion tasks. Finally, we perform experimentation with MetaHDR to demonstrate its capacity to tackle challenging LDR-to-HDR image conversions. Code and pretrained models are available at https://github.com/edwin-pan/MetaHDR.

</p>
</details>

<details><summary><b>Geo-Spatiotemporal Features and Shape-Based Prior Knowledge for Fine-grained Imbalanced Data Classification</b>
<a href="https://arxiv.org/abs/2103.11285">arxiv:2103.11285</a>
&#x1F4C8; 3 <br>
<p>Charles A. Kantor, Marta Skreta, Brice Rauby, Léonard Boussioux, Emmanuel Jehanno, Alexandra Luccioni, David Rolnick, Hugues Talbot</p></summary>
<p>

**Abstract:** Fine-grained classification aims at distinguishing between items with similar global perception and patterns, but that differ by minute details. Our primary challenges come from both small inter-class variations and large intra-class variations. In this article, we propose to combine several innovations to improve fine-grained classification within the use-case of wildlife, which is of practical interest for experts. We utilize geo-spatiotemporal data to enrich the picture information and further improve the performance. We also investigate state-of-the-art methods for handling the imbalanced data issue.

</p>
</details>

<details><summary><b>Self-Supervised Test-Time Learning for Reading Comprehension</b>
<a href="https://arxiv.org/abs/2103.11263">arxiv:2103.11263</a>
&#x1F4C8; 3 <br>
<p>Pratyay Banerjee, Tejas Gokhale, Chitta Baral</p></summary>
<p>

**Abstract:** Recent work on unsupervised question answering has shown that models can be trained with procedurally generated question-answer pairs and can achieve performance competitive with supervised methods. In this work, we consider the task of unsupervised reading comprehension and present a method that performs "test-time learning" (TTL) on a given context (text passage), without requiring training on large-scale human-authored datasets containing \textit{context-question-answer} triplets. This method operates directly on a single test context, uses self-supervision to train models on synthetically generated question-answer pairs, and then infers answers to unseen human-authored questions for this context. Our method achieves accuracies competitive with fully supervised methods and significantly outperforms current unsupervised methods. TTL methods with a smaller model are also competitive with the current state-of-the-art in unsupervised reading comprehension.

</p>
</details>

<details><summary><b>Interpretable Machine Learning: Fundamental Principles and 10 Grand Challenges</b>
<a href="https://arxiv.org/abs/2103.11251">arxiv:2103.11251</a>
&#x1F4C8; 3 <br>
<p>Cynthia Rudin, Chaofan Chen, Zhi Chen, Haiyang Huang, Lesia Semenova, Chudi Zhong</p></summary>
<p>

**Abstract:** Interpretability in machine learning (ML) is crucial for high stakes decisions and troubleshooting. In this work, we provide fundamental principles for interpretable ML, and dispel common misunderstandings that dilute the importance of this crucial topic. We also identify 10 technical challenge areas in interpretable machine learning and provide history and background on each problem. Some of these problems are classically important, and some are recent problems that have arisen in the last few years. These problems are: (1) Optimizing sparse logical models such as decision trees; (2) Optimization of scoring systems; (3) Placing constraints into generalized additive models to encourage sparsity and better interpretability; (4) Modern case-based reasoning, including neural networks and matching for causal inference; (5) Complete supervised disentanglement of neural networks; (6) Complete or even partial unsupervised disentanglement of neural networks; (7) Dimensionality reduction for data visualization; (8) Machine learning models that can incorporate physics and other generative or causal constraints; (9) Characterization of the "Rashomon set" of good models; and (10) Interpretable reinforcement learning. This survey is suitable as a starting point for statisticians and computer scientists interested in working in interpretable machine learning.

</p>
</details>

<details><summary><b>Markov Modeling of Time-Series Data using Symbolic Analysis</b>
<a href="https://arxiv.org/abs/2103.11238">arxiv:2103.11238</a>
&#x1F4C8; 3 <br>
<p>Devesh K. Jha</p></summary>
<p>

**Abstract:** Markov models are often used to capture the temporal patterns of sequential data for statistical learning applications. While the Hidden Markov modeling-based learning mechanisms are well studied in literature, we analyze a symbolic-dynamics inspired approach. Under this umbrella, Markov modeling of time-series data consists of two major steps -- discretization of continuous attributes followed by estimating the size of temporal memory of the discretized sequence. These two steps are critical for the accurate and concise representation of time-series data in the discrete space. Discretization governs the information content of the resultant discretized sequence. On the other hand, memory estimation of the symbolic sequence helps to extract the predictive patterns in the discretized data. Clearly, the effectiveness of signal representation as a discrete Markov process depends on both these steps. In this paper, we will review the different techniques for discretization and memory estimation for discrete stochastic processes. In particular, we will focus on the individual problems of discretization and order estimation for discrete stochastic process. We will present some results from literature on partitioning from dynamical systems theory and order estimation using concepts of information theory and statistical learning. The paper also presents some related problem formulations which will be useful for machine learning and statistical learning application using the symbolic framework of data analysis. We present some results of statistical analysis of a complex thermoacoustic instability phenomenon during lean-premixed combustion in jet-turbine engines using the proposed Markov modeling method.

</p>
</details>

<details><summary><b>A Deep Neural Network Surrogate Modeling Benchmark for Temperature Field Prediction of Heat Source Layout</b>
<a href="https://arxiv.org/abs/2103.11177">arxiv:2103.11177</a>
&#x1F4C8; 3 <br>
<p>Xianqi Chen, Xiaoyu Zhao, Zhiqiang Gong, Jun Zhang, Weien Zhou, Xiaoqian Chen, Wen Yao</p></summary>
<p>

**Abstract:** Thermal issue is of great importance during layout design of heat source components in systems engineering, especially for high functional-density products. Thermal analysis generally needs complex simulation, which leads to an unaffordable computational burden to layout optimization as it iteratively evaluates different schemes. Surrogate modeling is an effective way to alleviate computation complexity. However, temperature field prediction (TFP) with complex heat source layout (HSL) input is an ultra-high dimensional nonlinear regression problem, which brings great difficulty to traditional regression models. The Deep neural network (DNN) regression method is a feasible way for its good approximation performance. However, it faces great challenges in both data preparation for sample diversity and uniformity in the layout space with physical constraints, and proper DNN model selection and training for good generality, which necessitates efforts of both layout designer and DNN experts. To advance this cross-domain research, this paper proposes a DNN based HSL-TFP surrogate modeling task benchmark. With consideration for engineering applicability, sample generation, dataset evaluation, DNN model, and surrogate performance metrics, are thoroughly studied. Experiments are conducted with ten representative state-of-the-art DNN models. Detailed discussion on baseline results is provided and future prospects are analyzed for DNN based HSL-TFP tasks.

</p>
</details>

<details><summary><b>Recognizing Predictive Substructures with Subgraph Information Bottleneck</b>
<a href="https://arxiv.org/abs/2103.11155">arxiv:2103.11155</a>
&#x1F4C8; 3 <br>
<p>Junchi Yu, Tingyang Xu, Yu Rong, Yatao Bian, Junzhou Huang, Ran He</p></summary>
<p>

**Abstract:** The emergence of Graph Convolutional Network (GCN) has greatly boosted the progress of graph learning. However, two disturbing factors, noise and redundancy in graph data, and lack of interpretation for prediction results, impede further development of GCN. One solution is to recognize a predictive yet compressed subgraph to get rid of the noise and redundancy and obtain the interpretable part of the graph. This setting of subgraph is similar to the information bottleneck (IB) principle, which is less studied on graph-structured data and GCN. Inspired by the IB principle, we propose a novel subgraph information bottleneck (SIB) framework to recognize such subgraphs, named IB-subgraph. However, the intractability of mutual information and the discrete nature of graph data makes the objective of SIB notoriously hard to optimize. To this end, we introduce a bilevel optimization scheme coupled with a mutual information estimator for irregular graphs. Moreover, we propose a continuous relaxation for subgraph selection with a connectivity loss for stabilization. We further theoretically prove the error bound of our estimation scheme for mutual information and the noise-invariant nature of IB-subgraph. Extensive experiments on graph learning and large-scale point cloud tasks demonstrate the superior property of IB-subgraph.

</p>
</details>

<details><summary><b>On Subspace Approximation and Subset Selection in Fewer Passes by MCMC Sampling</b>
<a href="https://arxiv.org/abs/2103.11107">arxiv:2103.11107</a>
&#x1F4C8; 3 <br>
<p>Amit Deshpande, Rameshwar Pratap</p></summary>
<p>

**Abstract:** We consider the problem of subset selection for $\ell_{p}$ subspace approximation, i.e., given $n$ points in $d$ dimensions, we need to pick a small, representative subset of the given points such that its span gives $(1+ε)$ approximation to the best $k$-dimensional subspace that minimizes the sum of $p$-th powers of distances of all the points to this subspace. Sampling-based subset selection techniques require adaptive sampling iterations with multiple passes over the data. Matrix sketching techniques give a single-pass $(1+ε)$ approximation for $\ell_{p}$ subspace approximation but require additional passes for subset selection.
  In this work, we propose an MCMC algorithm to reduce the number of passes required by previous subset selection algorithms based on adaptive sampling. For $p=2$, our algorithm gives subset selection of nearly optimal size in only $2$ passes, whereas the number of passes required in previous work depend on $k$. Our algorithm picks a subset of size $\mathrm{poly}(k/ε)$ that gives $(1+ε)$ approximation to the optimal subspace. The running time of the algorithm is $nd + d~\mathrm{poly}(k/ε)$. We extend our results to the case when outliers are present in the datasets, and suggest a two pass algorithm for the same. Our ideas also extend to give a reduction in the number of passes required by adaptive sampling algorithms for $\ell_{p}$ subspace approximation and subset selection, for $p \geq 2$.

</p>
</details>

<details><summary><b>Projection-free Distributed Online Learning with Strongly Convex Losses</b>
<a href="https://arxiv.org/abs/2103.11102">arxiv:2103.11102</a>
&#x1F4C8; 3 <br>
<p>Yuanyu Wan, Guanghui Wang, Lijun Zhang</p></summary>
<p>

**Abstract:** To efficiently solve distributed online learning problems with complicated constraints, previous studies have proposed several distributed projection-free algorithms. The state-of-the-art one achieves the $O({T}^{3/4})$ regret bound with $O(\sqrt{T})$ communication complexity. In this paper, we further exploit the strong convexity of loss functions to improve the regret bound and communication complexity. Specifically, we first propose a distributed projection-free algorithm for strongly convex loss functions, which enjoys a better regret bound of $O(T^{2/3}\log T)$ with smaller communication complexity of $O(T^{1/3})$. Furthermore, we demonstrate that the regret of distributed online algorithms with $C$ communication rounds has a lower bound of $Ω(T/C)$, even when the loss functions are strongly convex. This lower bound implies that the $O(T^{1/3})$ communication complexity of our algorithm is nearly optimal for obtaining the $O(T^{2/3}\log T)$ regret bound up to polylogarithmic factors. Finally, we extend our algorithm into the bandit setting and obtain similar theoretical guarantees.

</p>
</details>

<details><summary><b>Insight-centric Visualization Recommendation</b>
<a href="https://arxiv.org/abs/2103.11297">arxiv:2103.11297</a>
&#x1F4C8; 2 <br>
<p>Camille Harris, Ryan A. Rossi, Sana Malik, Jane Hoffswell, Fan Du, Tak Yeon Lee, Eunyee Koh, Handong Zhao</p></summary>
<p>

**Abstract:** Visualization recommendation systems simplify exploratory data analysis (EDA) and make understanding data more accessible to users of all skill levels by automatically generating visualizations for users to explore. However, most existing visualization recommendation systems focus on ranking all visualizations into a single list or set of groups based on particular attributes or encodings. This global ranking makes it difficult and time-consuming for users to find the most interesting or relevant insights. To address these limitations, we introduce a novel class of visualization recommendation systems that automatically rank and recommend both groups of related insights as well as the most important insights within each group. Our proposed approach combines results from many different learning-based methods to discover insights automatically. A key advantage is that this approach generalizes to a wide variety of attribute types such as categorical, numerical, and temporal, as well as complex non-trivial combinations of these different attribute types. To evaluate the effectiveness of our approach, we implemented a new insight-centric visualization recommendation system, SpotLight, which generates and ranks annotated visualizations to explain each insight. We conducted a user study with 12 participants and two datasets which showed that users are able to quickly understand and find relevant insights in unfamiliar data.

</p>
</details>

<details><summary><b>Structural Textile Pattern Recognition and Processing Based on Hypergraphs</b>
<a href="https://arxiv.org/abs/2103.11271">arxiv:2103.11271</a>
&#x1F4C8; 2 <br>
<p>Vuong M. Ngo, Sven Helmer, Nhien-An Le-Khac, M-Tahar Kechadi</p></summary>
<p>

**Abstract:** The humanities, like many other areas of society, are currently undergoing major changes in the wake of digital transformation. However, in order to make collection of digitised material in this area easily accessible, we often still lack adequate search functionality. For instance, digital archives for textiles offer keyword search, which is fairly well understood, and arrange their content following a certain taxonomy, but search functionality at the level of thread structure is still missing. To facilitate the clustering and search, we introduce an approach for recognising similar weaving patterns based on their structures for textile archives. We first represent textile structures using hypergraphs and extract multisets of k-neighbourhoods describing weaving patterns from these graphs. Then, the resulting multisets are clustered using various distance measures and various clustering algorithms (K-Means for simplicity and hierarchical agglomerative algorithms for precision). We evaluate the different variants of our approach experimentally, showing that this can be implemented efficiently (meaning it has linear complexity), and demonstrate its quality to query and cluster datasets containing large textile samples. As, to the est of our knowledge, this is the first practical approach for explicitly modelling complex and irregular weaving patterns usable for retrieval, we aim at establishing a solid baseline.

</p>
</details>

<details><summary><b>Development and Validation of a Deep Learning Model for Prediction of Severe Outcomes in Suspected COVID-19 Infection</b>
<a href="https://arxiv.org/abs/2103.11269">arxiv:2103.11269</a>
&#x1F4C8; 2 <br>
<p>Varun Buch, Aoxiao Zhong, Xiang Li, Marcio Aloisio Bezerra Cavalcanti Rockenbach, Dufan Wu, Hui Ren, Jiahui Guan, Andrew Liteplo, Sayon Dutta, Ittai Dayan, Quanzheng Li</p></summary>
<p>

**Abstract:** COVID-19 patient triaging with predictive outcome of the patients upon first present to emergency department (ED) is crucial for improving patient prognosis, as well as better hospital resources management and cross-infection control. We trained a deep feature fusion model to predict patient outcomes, where the model inputs were EHR data including demographic information, co-morbidities, vital signs and laboratory measurements, plus patient's CXR images. The model output was patient outcomes defined as the most insensitive oxygen therapy required. For patients without CXR images, we employed Random Forest method for the prediction. Predictive risk scores for COVID-19 severe outcomes ("CO-RISK" score) were derived from model output and evaluated on the testing dataset, as well as compared to human performance. The study's dataset (the "MGB COVID Cohort") was constructed from all patients presenting to the Mass General Brigham (MGB) healthcare system from March 1st to June 1st, 2020. ED visits with incomplete or erroneous data were excluded. Patients with no test order for COVID or confirmed negative test results were excluded. Patients under the age of 15 were also excluded. Finally, electronic health record (EHR) data from a total of 11060 COVID-19 confirmed or suspected patients were used in this study. Chest X-ray (CXR) images were also collected from each patient if available. Results show that CO-RISK score achieved area under the Curve (AUC) of predicting MV/death (i.e. severe outcomes) in 24 hours of 0.95, and 0.92 in 72 hours on the testing dataset. The model shows superior performance to the commonly used risk scores in ED (CURB-65 and MEWS). Comparing with physician's decisions, CO-RISK score has demonstrated superior performance to human in making ICU/floor decisions.

</p>
</details>

<details><summary><b>Robust Models Are More Interpretable Because Attributions Look Normal</b>
<a href="https://arxiv.org/abs/2103.11257">arxiv:2103.11257</a>
&#x1F4C8; 2 <br>
<p>Zifan Wang, Matt Fredrikson, Anupam Datta</p></summary>
<p>

**Abstract:** Recent work has found that adversarially-robust deep networks used for image classification are more interpretable: their feature attributions tend to be sharper, and are more concentrated on the objects associated with the image's ground-truth class. We show that smooth decision boundaries play an important role in this enhanced interpretability, as the model's input gradients around data points will more closely align with boundaries' normal vectors when they are smooth. Thus, because robust models have smoother boundaries, the results of gradient-based attribution methods, like Integrated Gradients and DeepLift, will capture more accurate information about nearby decision boundaries. This understanding of robust interpretability leads to our second contribution: \emph{boundary attributions}, which aggregate information about the normal vectors of local decision boundaries to explain a classification outcome. We show that by leveraging the key factors underpinning robust interpretability, boundary attributions produce sharper, more concentrated visual explanations -- even on non-robust models. Any example implementation can be found at \url{https://github.com/zifanw/boundary}.

</p>
</details>

<details><summary><b>Round and Communication Balanced Protocols for Oblivious Evaluation of Finite State Machines</b>
<a href="https://arxiv.org/abs/2103.11240">arxiv:2103.11240</a>
&#x1F4C8; 2 <br>
<p>Rafael Dowsley, Caleb Horst, Anderson C. A. Nascimento</p></summary>
<p>

**Abstract:** We propose protocols for obliviously evaluating finite-state machines, i.e., the evaluation is shared between the provider of the finite-state machine and the provider of the input string in such a manner that neither party learns the other's input, and the states being visited are hidden from both. For alphabet size $|Σ|$, number of states $|Q|$, and input length $n$, previous solutions have either required a number of rounds linear in $n$ or communication $Ω(n|Σ||Q|\log|Q|)$. Our solutions require 2 rounds with communication $O(n(|Σ|+|Q|\log|Q|))$. We present two different solutions to this problem, a two-party one and a setting with an untrusted but non-colluding helper.

</p>
</details>

<details><summary><b>Multi Camera Placement via Z-buffer Rendering for the Optimization of the Coverage and the Visual Hull</b>
<a href="https://arxiv.org/abs/2103.11211">arxiv:2103.11211</a>
&#x1F4C8; 2 <br>
<p>Maria L. Hänel, Johannes Völkel, Dominik Henrich</p></summary>
<p>

**Abstract:** We can only allow human-robot-cooperation in a common work cell if the human integrity is guaranteed. A surveillance system with multiple cameras can detect collisions without contact to the human collaborator. A failure safe system needs to optimally cover the important areas of the robot work cell with safety overlap. We propose an efficient algorithm for optimally placing and orienting the cameras in a 3D CAD model of the work cell. In order to evaluate the quality of the camera constellation in each step, our method simulates the vision system using a z-buffer rendering technique for image acquisition, a voxel space for the overlap and a refined visual hull method for a conservative human reconstruction. The simulation allows to evaluate the quality with respect to the distortion of images and advanced image analysis in the presence of static and dynamic visual obstacles such as tables, racks, walls, robots and people. Our method is ideally suited for maximizing the coverage of multiple cameras or minimizing an error made by the visual hull and can be extended to probabilistic space carving.

</p>
</details>

<details><summary><b>Efficient Spatialtemporal Context Modeling for Action Recognition</b>
<a href="https://arxiv.org/abs/2103.11190">arxiv:2103.11190</a>
&#x1F4C8; 2 <br>
<p>Congqi Cao, Yue Lu, Yifan Zhang, Dongmei Jiang, Yanning Zhang</p></summary>
<p>

**Abstract:** Contextual information plays an important role in action recognition. Local operations have difficulty to model the relation between two elements with a long-distance interval. However, directly modeling the contextual information between any two points brings huge cost in computation and memory, especially for action recognition, where there is an additional temporal dimension. Inspired from 2D criss-cross attention used in segmentation task, we propose a recurrent 3D criss-cross attention (RCCA-3D) module to model the dense long-range spatiotemporal contextual information in video for action recognition. The global context is factorized into sparse relation maps. We model the relationship between points in the same line along the direction of horizon, vertical and depth at each time, which forms a 3D criss-cross structure, and duplicate the same operation with recurrent mechanism to transmit the relation between points in a line to a plane finally to the whole spatiotemporal space. Compared with the non-local method, the proposed RCCA-3D module reduces the number of parameters and FLOPs by 25% and 30% for video context modeling. We evaluate the performance of RCCA-3D with two latest action recognition networks on three datasets and make a thorough analysis of the architecture, obtaining the optimal way to factorize and fuse the relation maps. Comparisons with other state-of-the-art methods demonstrate the effectiveness and efficiency of our model.

</p>
</details>

<details><summary><b>Explaining decisions made with AI: A workbook (Use case 1: AI-assisted recruitment tool)</b>
<a href="https://arxiv.org/abs/2104.03906">arxiv:2104.03906</a>
&#x1F4C8; 1 <br>
<p>David Leslie, Morgan Briggs</p></summary>
<p>

**Abstract:** Over the last two years, The Alan Turing Institute and the Information Commissioner's Office (ICO) have been working together to discover ways to tackle the difficult issues surrounding explainable AI. The ultimate product of this joint endeavour, Explaining decisions made with AI, published in May 2020, is the most comprehensive practical guidance on AI explanation produced anywhere to date. We have put together this workbook to help support the uptake of that guidance. The goal of the workbook is to summarise some of main themes from Explaining decisions made with AI and then to provide the materials for a workshop exercise that has been built around a use case created to help you gain a flavour of how to put the guidance into practice. In the first three sections, we run through the basics of Explaining decisions made with AI. We provide a precis of the four principles of AI explainability, the typology of AI explanations, and the tasks involved in the explanation-aware design, development, and use of AI/ML systems. We then provide some reflection questions, which are intended to be a launching pad for group discussion, and a starting point for the case-study-based exercise that we have included as Appendix B. In Appendix A, we go into more detailed suggestions about how to organise the workshop. These recommendations are based on two workshops we had the privilege of co-hosting with our colleagues from the ICO and Manchester Metropolitan University in January 2021. The participants of these workshops came from both the private and public sectors, and we are extremely grateful to them for their energy, enthusiasm, and tremendous insight. This workbook would simply not exist without the commitment and keenness of all our collaborators and workshop participants.

</p>
</details>

<details><summary><b>Using Molecular Embeddings in QSAR Modeling: Does it Make a Difference?</b>
<a href="https://arxiv.org/abs/2104.02604">arxiv:2104.02604</a>
&#x1F4C8; 1 <br>
<p>María Virginia Sabando, Ignacio Ponzoni, Evangelos E. Milios, Axel J. Soto</p></summary>
<p>

**Abstract:** With the consolidation of deep learning in drug discovery, several novel algorithms for learning molecular representations have been proposed. Despite the interest of the community in developing new methods for learning molecular embeddings and their theoretical benefits, comparing molecular embeddings with each other and with traditional representations is not straightforward, which in turn hinders the process of choosing a suitable representation for QSAR modeling. A reason behind this issue is the difficulty of conducting a fair and thorough comparison of the different existing embedding approaches, which requires numerous experiments on various datasets and training scenarios. To close this gap, we reviewed the literature on methods for molecular embeddings and reproduced three unsupervised and two supervised molecular embedding techniques recently proposed in the literature. We compared these five methods concerning their performance in QSAR scenarios using different classification and regression datasets. We also compared these representations to traditional molecular representations, namely molecular descriptors and fingerprints. As opposed to the expected outcome, our experimental setup consisting of over 25,000 trained models and statistical tests revealed that the predictive performance using molecular embeddings did not significantly surpass that of traditional representations. While supervised embeddings yielded competitive results compared to those using traditional molecular representations, unsupervised embeddings tended to perform worse than traditional representations. Our results highlight the need for conducting a careful comparison and analysis of the different embedding techniques prior to using them in drug design tasks, and motivate a discussion about the potential of molecular embeddings in computer-aided drug design.

</p>
</details>

<details><summary><b>Common Sense Knowledge, Ontology and Text Mining for Implicit Requirements</b>
<a href="https://arxiv.org/abs/2103.11302">arxiv:2103.11302</a>
&#x1F4C8; 1 <br>
<p>Onyeka Emebo, Aparna S. Varde, Olawande Daramola</p></summary>
<p>

**Abstract:** The ability of a system to meet its requirements is a strong determinant of success. Thus effective requirements specification is crucial. Explicit Requirements are well-defined needs for a system to execute. IMplicit Requirements (IMRs) are assumed needs that a system is expected to fulfill though not elicited during requirements gathering. Studies have shown that a major factor in the failure of software systems is the presence of unhandled IMRs. Since relevance of IMRs is important for efficient system functionality, there are methods developed to aid the identification and management of IMRs. In this paper, we emphasize that Common Sense Knowledge, in the field of Knowledge Representation in AI, would be useful to automatically identify and manage IMRs. This paper is aimed at identifying the sources of IMRs and also proposing an automated support tool for managing IMRs within an organizational context. Since this is found to be a present gap in practice, our work makes a contribution here. We propose a novel approach for identifying and managing IMRs based on combining three core technologies: common sense knowledge, text mining and ontology. We claim that discovery and handling of unknown and non-elicited requirements would reduce risks and costs in software development.

</p>
</details>

<details><summary><b>Learning Optimal Fronthauling and Decentralized Edge Computation in Fog Radio Access Networks</b>
<a href="https://arxiv.org/abs/2103.11284">arxiv:2103.11284</a>
&#x1F4C8; 1 <br>
<p>Hoon Lee, Junbeom Kim, Seok-Hwan Park</p></summary>
<p>

**Abstract:** Fog radio access networks (F-RANs), which consist of a cloud and multiple edge nodes (ENs) connected via fronthaul links, have been regarded as promising network architectures. The F-RAN entails a joint optimization of cloud and edge computing as well as fronthaul interactions, which is challenging for traditional optimization techniques. This paper proposes a Cloud-Enabled Cooperation-Inspired Learning (CECIL) framework, a structural deep learning mechanism for handling a generic F-RAN optimization problem. The proposed solution mimics cloud-aided cooperative optimization policies by including centralized computing at the cloud, distributed decision at the ENs, and their uplink-downlink fronthaul interactions. A group of deep neural networks (DNNs) are employed for characterizing computations of the cloud and ENs. The forwardpass of the DNNs is carefully designed such that the impacts of the practical fronthaul links, such as channel noise and signling overheads, can be included in a training step. As a result, operations of the cloud and ENs can be jointly trained in an end-to-end manner, whereas their real-time inferences are carried out in a decentralized manner by means of the fronthaul coordination. To facilitate fronthaul cooperation among multiple ENs, the optimal fronthaul multiple access schemes are designed. Training algorithms robust to practical fronthaul impairments are also presented. Numerical results validate the effectiveness of the proposed approaches.

</p>
</details>

<details><summary><b>Sliding Mode Learning Control of Uncertain Nonlinear Systems with Lyapunov Stability Analysis</b>
<a href="https://arxiv.org/abs/2103.11274">arxiv:2103.11274</a>
&#x1F4C8; 1 <br>
<p>Erkan Kayacan</p></summary>
<p>

**Abstract:** This paper addresses to Sliding Mode Learning Control (SMLC) of uncertain nonlinear systems with Lyapunov stability analysis. In the control scheme, a conventional control term is used to provide the system stability in compact space while a Type-2 Neuro-Fuzzy Controller (T2NFC) learns system behavior so that the T2NFC takes the overall control of the system completely in a very short time period. The stability of the sliding mode learning algorithm was proven in literature; however, it is so restrictive for systems without the overall system stability. To address this shortcoming, a novel control structure with a novel sliding surface is proposed in this paper and the stability of the overall system is proven for nth-order uncertain nonlinear systems. To investigate the capability and effectiveness of the proposed learning and control algorithms, the simulation studies have been achieved under noisy conditions. The simulation results confirm that the developed SMLC algorithm can learn the system behavior in the absence of any mathematical model knowledge and exhibit robust control performance against external disturbances.

</p>
</details>

<details><summary><b>SELM: Software Engineering of Machine Learning Models</b>
<a href="https://arxiv.org/abs/2103.11249">arxiv:2103.11249</a>
&#x1F4C8; 1 <br>
<p>Nafiseh Jafari, Mohammad Reza Besharati, Mohammad Izadi, Maryam Hourali</p></summary>
<p>

**Abstract:** One of the pillars of any machine learning model is its concepts. Using software engineering, we can engineer these concepts and then develop and expand them. In this article, we present a SELM framework for Software Engineering of machine Learning Models. We then evaluate this framework through a case study. Using the SELM framework, we can improve a machine learning process efficiency and provide more accuracy in learning with less processing hardware resources and a smaller training dataset. This issue highlights the importance of an interdisciplinary approach to machine learning. Therefore, in this article, we have provided interdisciplinary teams' proposals for machine learning.

</p>
</details>

<details><summary><b>Uncertainty Estimation in SARS-CoV-2 B-cell Epitope Prediction for Vaccine Development</b>
<a href="https://arxiv.org/abs/2103.11214">arxiv:2103.11214</a>
&#x1F4C8; 1 <br>
<p>Bhargab Ghoshal, Biraja Ghoshal, Stephen Swift, Allan Tucker</p></summary>
<p>

**Abstract:** B-cell epitopes play a key role in stimulating B-cells, triggering the primary immune response which results in antibody production as well as the establishment of long-term immunity in the form of memory cells. Consequently, being able to accurately predict appropriate linear B-cell epitope regions would pave the way for the development of new protein-based vaccines. Knowing how much confidence there is in a prediction is also essential for gaining clinicians' trust in the technology. In this article, we propose a calibrated uncertainty estimation in deep learning to approximate variational Bayesian inference using MC-DropWeights to predict epitope regions using the data from the immune epitope database. Having applied this onto SARS-CoV-2, it can more reliably predict B-cell epitopes than standard methods. This will be able to identify safe and effective vaccine candidates against Covid-19.

</p>
</details>

<details><summary><b>Overprotective Training Environments Fall Short at Testing Time: Let Models Contribute to Their Own Training</b>
<a href="https://arxiv.org/abs/2103.11145">arxiv:2103.11145</a>
&#x1F4C8; 1 <br>
<p>Alberto Testoni, Raffaella Bernardi</p></summary>
<p>

**Abstract:** Despite important progress, conversational systems often generate dialogues that sound unnatural to humans. We conjecture that the reason lies in their different training and testing conditions: agents are trained in a controlled "lab" setting but tested in the "wild". During training, they learn to generate an utterance given the human dialogue history. On the other hand, during testing, they must interact with each other, and hence deal with noisy data. We propose to fill this gap by training the model with mixed batches containing both samples of human and machine-generated dialogues. We assess the validity of the proposed method on GuessWhat?!, a visual referential game.

</p>
</details>

<details><summary><b>Preprocessing power weighted shortest path data using a s-Well Separated Pair Decomposition</b>
<a href="https://arxiv.org/abs/2103.11216">arxiv:2103.11216</a>
&#x1F4C8; 0 <br>
<p>Gurpreet S. Kalsi, Steven B. Damelin</p></summary>
<p>

**Abstract:** For $s$ $>$ 0, we consider an algorithm that computes all $s$-well separated pairs in certain point sets in $\mathbb{R}^{n}$, $n$ $>1$. For an integer $K$ $>1$, we also consider an algorithm that is a permutation of Dijkstra's algorithm, that computes $K$-nearest neighbors using a certain power weighted shortest path metric in $\mathbb{R}^{n}$, $n$ $>$ $1$. We describe each algorithm and their respective dependencies on the input data. We introduce a way to combine both algorithms into a fused algorithm. Several open problems are given for future research.

</p>
</details>

<details><summary><b>Efficient Density Ratio-Guided Subsampling of Conditional GANs, With Conditioning on a Class or a Continuous Variable</b>
<a href="https://arxiv.org/abs/2103.11166">arxiv:2103.11166</a>
&#x1F4C8; 0 <br>
<p>Xin Ding, Yongwei Wang, Z. Jane Wang, William J. Welch</p></summary>
<p>

**Abstract:** Recently, subsampling or refining images generated from unconditional generative adversarial networks (GANs) has been actively studied to improve the overall image quality. Unfortunately, these methods are often observed less effective or inefficient in handling conditional GANs (cGANs) -- conditioning on a class (aka class-conditional GANs) or a continuous variable (aka continuous cGANs or CcGANs). In this work, we introduce an effective and efficient subsampling scheme, named conditional density ratio-guided rejection sampling (cDR-RS), to sample high-quality images from cGANs. Specifically, we first develop a novel conditional density ratio estimation method, termed cDRE-F-cSP, by proposing the conditional Softplus (cSP) loss and an improved feature extraction mechanism. We then derive the error bound of a density ratio model trained with the cSP loss. Finally, we accept or reject a fake image in terms of its estimated conditional density ratio. A filtering scheme is also developed to increase fake images' label consistency without losing diversity when sampling from CcGANs. We extensively test the effectiveness and efficiency of cDR-RS in sampling from both class-conditional GANs and CcGANs on five benchmark datasets. When sampling from class-conditional GANs, cDR-RS outperforms modern state-of-the-art methods by a large margin (except DRE-F-SP+RS) in terms of effectiveness. Although the effectiveness of cDR-RS is often comparable to that of DRE-F-SP+RS, cDR-RS is substantially more efficient. When sampling from CcGANs, the superiority of cDR-RS is even more noticeable in terms of both effectiveness and efficiency. Notably, with the consumption of reasonable computational resources, cDR-RS can substantially reduce Label Score without decreasing the diversity of CcGAN-generated images, while other methods often need to trade much diversity for slightly improved Label Score.

</p>
</details>

<details><summary><b>Low Dimensional Landscape Hypothesis is True: DNNs can be Trained in Tiny Subspaces</b>
<a href="https://arxiv.org/abs/2103.11154">arxiv:2103.11154</a>
&#x1F4C8; 0 <br>
<p>Tao Li, Lei Tan, Qinghua Tao, Yipeng Liu, Xiaolin Huang</p></summary>
<p>

**Abstract:** Deep neural networks (DNNs) usually contain massive parameters, but there is redundancy such that it is guessed that the DNNs could be trained in low-dimensional subspaces. In this paper, we propose a Dynamic Linear Dimensionality Reduction (DLDR) based on low-dimensional properties of the training trajectory. The reduction is efficient, which is supported by comprehensive experiments: optimization in 40 dimensional spaces can achieve comparable performance as regular training over thousands or even millions of parameters. Since there are only a few optimization variables, we develop a quasi-Newton-based algorithm and also obtain robustness against label noises, which are two follow-up experiments to show the advantages of finding low-dimensional subspaces.

</p>
</details>

<details><summary><b>Predictive Maintenance -- Bridging Artificial Intelligence and IoT</b>
<a href="https://arxiv.org/abs/2103.11148">arxiv:2103.11148</a>
&#x1F4C8; 0 <br>
<p>G. G. Samatas, S. S. Moumgiakmas, G. A. Papakostas</p></summary>
<p>

**Abstract:** This paper highlights the trends in the field of predictive maintenance with the use of machine learning. With the continuous development of the Fourth Industrial Revolution, through IoT, the technologies that use artificial intelligence are evolving. As a result, industries have been using these technologies to optimize their production. Through scientific research conducted for this paper, conclusions were drawn about the trends in Predictive Maintenance applications with the use of machine learning bridging Artificial Intelligence and IoT. These trends are related to the types of industries in which Predictive Maintenance was applied, the models of artificial intelligence were implemented, mainly of machine learning and the types of sensors that are applied through the IoT to the applications. Six sectors were presented and the production sector was dominant as it accounted for 54.54% of total publications. In terms of artificial intelligence models, the most prevalent among ten were the Artificial Neural Networks, Support Vector Machine and Random Forest with 27.84%, 17.72% and 13.92% respectively. Finally, twelve categories of sensors emerged, of which the most widely used were the sensors of temperature and vibration with percentages of 60.71% and 46.42% correspondingly.

</p>
</details>

<details><summary><b>MogFace: Towards a Deeper Appreciation on Face Detection</b>
<a href="https://arxiv.org/abs/2103.11139">arxiv:2103.11139</a>
&#x1F4C8; 0 <br>
<p>Yang Liu, Fei Wang, Baigui Sun, Hao Li</p></summary>
<p>

**Abstract:** Benefiting from the pioneering design of generic object detectors, significant achievements have been made in the field of face detection. Typically, the architectures of the backbone, feature pyramid layer and detection head module within the face detector all assimilate the excellent experience from general object detectors. However, several effective methods, including label assignment and scale-level data augmentation strategy \footnote{enriches the scale distribution of the training data to resolve scale variance challenge.}, fail to maintain consistent superiority when applying on the face detector directly. Concretely, the former strategy involves a vast body of hyper-parameters and the latter one suffers from the challenge of scale distribution bias between different detection tasks, which both limit their generalization abilities. Furthermore, in order to provide accurate face bounding boxes for facial down-stream tasks, the face detector imperatively requires the elimination of false alarms. As a result, practical solutions on label assignment, scale-level data augmentation and reducing false alarms are necessary for advancing face detector. In this paper, we focus on resolving three aforementioned challenges that exiting methods are difficult to finish off and present a novel face detector, termed as MogFace. In our Mogface, three key components, Adaptive Online Incremental Anchor Mining Strategy, Selective Scale Enhancement Strategy and Hierarchical Context-Aware Module, are separately proposed to boost the performance of face detection. Finally, to the best of our knowledge, our MogFace is the best face detector on the Wider Face leader-board, achieving all champions across different testing scenarios. The code is available at https://github.com/idstcv/MogFace

</p>
</details>


[Next Page]({{ '/2021/03/19/2021.03.19.html' | relative_url }})
