## Summary for 2021-08-26, created on 2021-12-19


<details><summary><b>Harms of Gender Exclusivity and Challenges in Non-Binary Representation in Language Technologies</b>
<a href="https://arxiv.org/abs/2108.12084">arxiv:2108.12084</a>
&#x1F4C8; 93 <br>
<p>Sunipa Dev, Masoud Monajatipoor, Anaelia Ovalle, Arjun Subramonian, Jeff M Phillips, Kai-Wei Chang</p></summary>
<p>

**Abstract:** Gender is widely discussed in the context of language tasks and when examining the stereotypes propagated by language models. However, current discussions primarily treat gender as binary, which can perpetuate harms such as the cyclical erasure of non-binary gender identities. These harms are driven by model and dataset biases, which are consequences of the non-recognition and lack of understanding of non-binary genders in society. In this paper, we explain the complexity of gender and language around it, and survey non-binary persons to understand harms associated with the treatment of gender as binary in English language technologies. We also detail how current language representations (e.g., GloVe, BERT) capture and perpetuate these harms and related challenges that need to be acknowledged and addressed for representations to equitably encode gender information.

</p>
</details>

<details><summary><b>The Devil is in the Detail: Simple Tricks Improve Systematic Generalization of Transformers</b>
<a href="https://arxiv.org/abs/2108.12284">arxiv:2108.12284</a>
&#x1F4C8; 49 <br>
<p>Róbert Csordás, Kazuki Irie, Jürgen Schmidhuber</p></summary>
<p>

**Abstract:** Recently, many datasets have been proposed to test the systematic generalization ability of neural networks. The companion baseline Transformers, typically trained with default hyper-parameters from standard tasks, are shown to fail dramatically. Here we demonstrate that by revisiting model configurations as basic as scaling of embeddings, early stopping, relative positional embedding, and Universal Transformer variants, we can drastically improve the performance of Transformers on systematic generalization. We report improvements on five popular datasets: SCAN, CFQ, PCFG, COGS, and Mathematics dataset. Our models improve accuracy from 50% to 85% on the PCFG productivity split, and from 35% to 81% on COGS. On SCAN, relative positional embedding largely mitigates the EOS decision problem (Newman et al., 2020), yielding 100% accuracy on the length split with a cutoff at 26. Importantly, performance differences between these models are typically invisible on the IID data split. This calls for proper generalization validation sets for developing neural networks that generalize systematically. We publicly release the code to reproduce our results.

</p>
</details>

<details><summary><b>An Introduction to Hamiltonian Monte Carlo Method for Sampling</b>
<a href="https://arxiv.org/abs/2108.12107">arxiv:2108.12107</a>
&#x1F4C8; 30 <br>
<p>Nisheeth K. Vishnoi</p></summary>
<p>

**Abstract:** The goal of this article is to introduce the Hamiltonian Monte Carlo (HMC) method -- a Hamiltonian dynamics-inspired algorithm for sampling from a Gibbs density $π(x) \propto e^{-f(x)}$. We focus on the "idealized" case, where one can compute continuous trajectories exactly. We show that idealized HMC preserves $π$ and we establish its convergence when $f$ is strongly convex and smooth.

</p>
</details>

<details><summary><b>Few-shot Visual Relationship Co-localization</b>
<a href="https://arxiv.org/abs/2108.11618">arxiv:2108.11618</a>
&#x1F4C8; 23 <br>
<p>Revant Teotia, Vaibhav Mishra, Mayank Maheshwari, Anand Mishra</p></summary>
<p>

**Abstract:** In this paper, given a small bag of images, each containing a common but latent predicate, we are interested in localizing visual subject-object pairs connected via the common predicate in each of the images. We refer to this novel problem as visual relationship co-localization or VRC as an abbreviation. VRC is a challenging task, even more so than the well-studied object co-localization task. This becomes further challenging when using just a few images, the model has to learn to co-localize visual subject-object pairs connected via unseen predicates. To solve VRC, we propose an optimization framework to select a common visual relationship in each image of the bag. The goal of the optimization framework is to find the optimal solution by learning visual relationship similarity across images in a few-shot setting. To obtain robust visual relationship representation, we utilize a simple yet effective technique that learns relationship embedding as a translation vector from visual subject to visual object in a shared space. Further, to learn visual relationship similarity, we utilize a proven meta-learning technique commonly used for few-shot classification tasks. Finally, to tackle the combinatorial complexity challenge arising from an exponential number of feasible solutions, we use a greedy approximation inference algorithm that selects approximately the best solution.
  We extensively evaluate our proposed framework on variations of bag sizes obtained from two challenging public datasets, namely VrR-VG and VG-150, and achieve impressive visual co-localization performance.

</p>
</details>

<details><summary><b>Bilateral Denoising Diffusion Models</b>
<a href="https://arxiv.org/abs/2108.11514">arxiv:2108.11514</a>
&#x1F4C8; 23 <br>
<p>Max W. Y. Lam, Jun Wang, Rongjie Huang, Dan Su, Dong Yu</p></summary>
<p>

**Abstract:** Denoising diffusion probabilistic models (DDPMs) have emerged as competitive generative models yet brought challenges to efficient sampling. In this paper, we propose novel bilateral denoising diffusion models (BDDMs), which take significantly fewer steps to generate high-quality samples. From a bilateral modeling objective, BDDMs parameterize the forward and reverse processes with a score network and a scheduling network, respectively. We show that a new lower bound tighter than the standard evidence lower bound can be derived as a surrogate objective for training the two networks. In particular, BDDMs are efficient, simple-to-train, and capable of further improving any pre-trained DDPM by optimizing the inference noise schedules. Our experiments demonstrated that BDDMs can generate high-fidelity samples with as few as 3 sampling steps and produce comparable or even higher quality samples than DDPMs using 1000 steps with only 16 sampling steps (a 62x speedup).

</p>
</details>

<details><summary><b>Weisfeiler-Leman in the BAMBOO: Novel AMR Graph Metrics and a Benchmark for AMR Graph Similarity</b>
<a href="https://arxiv.org/abs/2108.11949">arxiv:2108.11949</a>
&#x1F4C8; 22 <br>
<p>Juri Opitz, Angel Daza, Anette Frank</p></summary>
<p>

**Abstract:** Several metrics have been proposed for assessing the similarity of (abstract) meaning representations (AMRs), but little is known about how they relate to human similarity ratings. Moreover, the current metrics have complementary strengths and weaknesses: some emphasize speed, while others make the alignment of graph structures explicit, at the price of a costly alignment step.
  In this work we propose new Weisfeiler-Leman AMR similarity metrics that unify the strengths of previous metrics, while mitigating their weaknesses. Specifically, our new metrics are able to match contextualized substructures and induce n:m alignments between their nodes. Furthermore, we introduce a Benchmark for AMR Metrics based on Overt Objectives (BAMBOO), the first benchmark to support empirical assessment of graph-based MR similarity metrics. BAMBOO maximizes the interpretability of results by defining multiple overt objectives that range from sentence similarity objectives to stress tests that probe a metric's robustness against meaning-altering and meaning-preserving graph transformations. We show the benefits of BAMBOO by profiling previous metrics and our own metrics. Results indicate that our novel metrics may serve as a strong baseline for future work.

</p>
</details>

<details><summary><b>Segmentation of Shoulder Muscle MRI Using a New Region and Edge based Deep Auto-Encoder</b>
<a href="https://arxiv.org/abs/2108.11720">arxiv:2108.11720</a>
&#x1F4C8; 22 <br>
<p>Saddam Hussain Khan, Asifullah Khan, Yeon Soo Lee, Mehdi Hassan, Woong Kyo jeong</p></summary>
<p>

**Abstract:** Automatic segmentation of shoulder muscle MRI is challenging due to the high variation in muscle size, shape, texture, and spatial position of tears. Manual segmentation of tear and muscle portion is hard, time-consuming, and subjective to pathological expertise. This work proposes a new Region and Edge-based Deep Auto-Encoder (RE-DAE) for shoulder muscle MRI segmentation. The proposed RE-DAE harmoniously employs average and max-pooling operation in the encoder and decoder blocks of the Convolutional Neural Network (CNN). Region-based segmentation incorporated in the Deep Auto-Encoder (DAE) encourages the network to extract smooth and homogenous regions. In contrast, edge-based segmentation tries to learn the boundary and anatomical information. These two concepts, systematically combined in a DAE, generate a discriminative and sparse hybrid feature space (exploiting both region homogeneity and boundaries). Moreover, the concept of static attention is exploited in the proposed RE-DAE that helps in effectively learning the tear region. The performances of the proposed MRI segmentation based DAE architectures have been tested using a 3D MRI shoulder muscle dataset using the hold-out cross-validation technique. The MRI data has been collected from the Korea University Anam Hospital, Seoul, South Korea. Experimental comparisons have been conducted by employing innovative custom-made and existing pre-trained CNN architectures both using transfer learning and fine-tuning. Objective evaluation on the muscle datasets using the proposed SA-RE-DAE showed a dice similarity of 85.58% and 87.07%, an accuracy of 81.57% and 95.58% for tear and muscle regions, respectively. The high visual quality and the objective result suggest that the proposed SA-RE-DAE is able to correctly segment tear and muscle regions in shoulder muscle MRI for better clinical decisions.

</p>
</details>

<details><summary><b>Convolutional Neural Networks Demystified: A Matched Filtering Perspective Based Tutorial</b>
<a href="https://arxiv.org/abs/2108.11663">arxiv:2108.11663</a>
&#x1F4C8; 20 <br>
<p>Ljubisa Stankovic, Danilo Mandic</p></summary>
<p>

**Abstract:** Deep Neural Networks (DNN) and especially Convolutional Neural Networks (CNN) are a de-facto standard for the analysis of large volumes of signals and images. Yet, their development and underlying principles have been largely performed in an ad-hoc and black box fashion. To help demystify CNNs, we revisit their operation from first principles and a matched filtering perspective. We establish that the convolution operation within CNNs, their very backbone, represents a matched filter which examines the input signal/image for the presence of pre-defined features. This perspective is shown to be physically meaningful, and serves as a basis for a step-by-step tutorial on the operation of CNNs, including pooling, zero padding, various ways of dimensionality reduction. Starting from first principles, both the feed-forward pass and the learning stage (via back-propagation) are illuminated in detail, both through a worked-out numerical example and the corresponding visualizations. It is our hope that this tutorial will help shed new light and physical intuition into the understanding and further development of deep neural networks.

</p>
</details>

<details><summary><b>Continual learning under domain transfer with sparse synaptic bursting</b>
<a href="https://arxiv.org/abs/2108.12056">arxiv:2108.12056</a>
&#x1F4C8; 10 <br>
<p>Shawn L. Beaulieu, Jeff Clune, Nick Cheney</p></summary>
<p>

**Abstract:** Existing machines are functionally specific tools that were made for easy prediction and control. Tomorrow's machines may be closer to biological systems in their mutability, resilience, and autonomy. But first they must be capable of learning, and retaining, new information without repeated exposure to it. Past efforts to engineer such systems have sought to build or regulate artificial neural networks using task-specific modules with constrained circumstances of application. This has not yet enabled continual learning over long sequences of previously unseen data without corrupting existing knowledge: a problem known as catastrophic forgetting. In this paper, we introduce a system that can learn sequentially over previously unseen datasets (ImageNet, CIFAR-100) with little forgetting over time. This is accomplished by regulating the activity of weights in a convolutional neural network on the basis of inputs using top-down modulation generated by a second feed-forward neural network. We find that our method learns continually under domain transfer with sparse bursts of activity in weights that are recycled across tasks, rather than by maintaining task-specific modules. Sparse synaptic bursting is found to balance enhanced and diminished activity in a way that facilitates adaptation to new inputs without corrupting previously acquired functions. This behavior emerges during a prior meta-learning phase in which regulated synapses are selectively disinhibited, or grown, from an initial state of uniform suppression.

</p>
</details>

<details><summary><b>SASRA: Semantically-aware Spatio-temporal Reasoning Agent for Vision-and-Language Navigation in Continuous Environments</b>
<a href="https://arxiv.org/abs/2108.11945">arxiv:2108.11945</a>
&#x1F4C8; 10 <br>
<p>Muhammad Zubair Irshad, Niluthpol Chowdhury Mithun, Zachary Seymour, Han-Pang Chiu, Supun Samarasekera, Rakesh Kumar</p></summary>
<p>

**Abstract:** This paper presents a novel approach for the Vision-and-Language Navigation (VLN) task in continuous 3D environments, which requires an autonomous agent to follow natural language instructions in unseen environments. Existing end-to-end learning-based VLN methods struggle at this task as they focus mostly on utilizing raw visual observations and lack the semantic spatio-temporal reasoning capabilities which is crucial in generalizing to new environments. In this regard, we present a hybrid transformer-recurrence model which focuses on combining classical semantic mapping techniques with a learning-based method. Our method creates a temporal semantic memory by building a top-down local ego-centric semantic map and performs cross-modal grounding to align map and language modalities to enable effective learning of VLN policy. Empirical results in a photo-realistic long-horizon simulation environment show that the proposed approach outperforms a variety of state-of-the-art methods and baselines with over 22% relative improvement in SPL in prior unseen environments.

</p>
</details>

<details><summary><b>Spatio-Temporal Graph Contrastive Learning</b>
<a href="https://arxiv.org/abs/2108.11873">arxiv:2108.11873</a>
&#x1F4C8; 9 <br>
<p>Xu Liu, Yuxuan Liang, Yu Zheng, Bryan Hooi, Roger Zimmermann</p></summary>
<p>

**Abstract:** Deep learning models are modern tools for spatio-temporal graph (STG) forecasting. Despite their effectiveness, they require large-scale datasets to achieve better performance and are vulnerable to noise perturbation. To alleviate these limitations, an intuitive idea is to use the popular data augmentation and contrastive learning techniques. However, existing graph contrastive learning methods cannot be directly applied to STG forecasting due to three reasons. First, we empirically discover that the forecasting task is unable to benefit from the pretrained representations derived from contrastive learning. Second, data augmentations that are used for defeating noise are less explored for STG data. Third, the semantic similarity of samples has been overlooked. In this paper, we propose a Spatio-Temporal Graph Contrastive Learning framework (STGCL) to tackle these issues. Specifically, we improve the performance by integrating the forecasting loss with an auxiliary contrastive loss rather than using a pretrained paradigm. We elaborate on four types of data augmentations, which disturb data in terms of graph structure, time domain, and frequency domain. We also extend the classic contrastive loss through a rule-based strategy that filters out the most semantically similar negatives. Our framework is evaluated across three real-world datasets and four state-of-the-art models. The consistent improvements demonstrate that STGCL can be used as an off-the-shelf plug-in for existing deep models.

</p>
</details>

<details><summary><b>A Hierarchical Assessment of Adversarial Severity</b>
<a href="https://arxiv.org/abs/2108.11785">arxiv:2108.11785</a>
&#x1F4C8; 9 <br>
<p>Guillaume Jeanneret, Juan C Perez, Pablo Arbelaez</p></summary>
<p>

**Abstract:** Adversarial Robustness is a growing field that evidences the brittleness of neural networks. Although the literature on adversarial robustness is vast, a dimension is missing in these studies: assessing how severe the mistakes are. We call this notion "Adversarial Severity" since it quantifies the downstream impact of adversarial corruptions by computing the semantic error between the misclassification and the proper label. We propose to study the effects of adversarial noise by measuring the Robustness and Severity into a large-scale dataset: iNaturalist-H. Our contributions are: (i) we introduce novel Hierarchical Attacks that harness the rich structured space of labels to create adversarial examples. (ii) These attacks allow us to benchmark the Adversarial Robustness and Severity of classification models. (iii) We enhance the traditional adversarial training with a simple yet effective Hierarchical Curriculum Training to learn these nodes gradually within the hierarchical tree. We perform extensive experiments showing that hierarchical defenses allow deep models to boost the adversarial Robustness by 1.85% and reduce the severity of all attacks by 0.17, on average.

</p>
</details>

<details><summary><b>Benchmarking high-fidelity pedestrian tracking systems for research, real-time monitoring and crowd control</b>
<a href="https://arxiv.org/abs/2108.11719">arxiv:2108.11719</a>
&#x1F4C8; 9 <br>
<p>Caspar A. S. Pouw, Joris Willems, Frank van Schadewijk, Jasmin Thurau, Federico Toschi, Alessandro Corbetta</p></summary>
<p>

**Abstract:** High-fidelity pedestrian tracking in real-life conditions has been an important tool in fundamental crowd dynamics research allowing to quantify statistics of relevant observables including walking velocities, mutual distances and body orientations. As this technology advances, it is becoming increasingly useful also in society. In fact, continued urbanization is overwhelming existing pedestrian infrastructures such as transportation hubs and stations, generating an urgent need for real-time highly-accurate usage data, aiming both at flow monitoring and dynamics understanding. To successfully employ pedestrian tracking techniques in research and technology, it is crucial to validate and benchmark them for accuracy. This is not only necessary to guarantee data quality, but also to identify systematic errors.
  In this contribution, we present and discuss a benchmark suite, towards an open standard in the community, for privacy-respectful pedestrian tracking techniques. The suite is technology-independent and is applicable to academic and commercial pedestrian tracking systems, operating both in lab environments and real-life conditions. The benchmark suite consists of 5 tests addressing specific aspects of pedestrian tracking quality, including accurate crowd flux estimation, density estimation, position detection and trajectory accuracy. The output of the tests are quality factors expressed as single numbers. We provide the benchmark results for two tracking systems, both operating in real-life, one commercial, and the other based on overhead depth-maps developed at TU Eindhoven. We discuss the results on the basis of the quality factors and report on the typical sensor and algorithmic performance. This enables us to highlight the current state-of-the-art, its limitations and provide installation recommendations, with specific attention to multi-sensor setups and data stitching.

</p>
</details>

<details><summary><b>Geometry Based Machining Feature Retrieval with Inductive Transfer Learning</b>
<a href="https://arxiv.org/abs/2108.11838">arxiv:2108.11838</a>
&#x1F4C8; 8 <br>
<p>N S Kamal, Barathi Ganesh HB, Sajith Variyar VV, Sowmya V, Soman KP</p></summary>
<p>

**Abstract:** Manufacturing industries have widely adopted the reuse of machine parts as a method to reduce costs and as a sustainable manufacturing practice. Identification of reusable features from the design of the parts and finding their similar features from the database is an important part of this process. In this project, with the help of fully convolutional geometric features, we are able to extract and learn the high level semantic features from CAD models with inductive transfer learning. The extracted features are then compared with that of other CAD models from the database using Frobenius norm and identical features are retrieved. Later we passed the extracted features to a deep convolutional neural network with a spatial pyramid pooling layer and the performance of the feature retrieval increased significantly. It was evident from the results that the model could effectively capture the geometrical elements from machining features.

</p>
</details>

<details><summary><b>Deep learning based dictionary learning and tomographic image reconstruction</b>
<a href="https://arxiv.org/abs/2108.11730">arxiv:2108.11730</a>
&#x1F4C8; 8 <br>
<p>Jevgenija Rudzusika, Thomas Koehler, Ozan Öktem</p></summary>
<p>

**Abstract:** This work presents an approach for image reconstruction in clinical low-dose tomography that combines principles from sparse signal processing with ideas from deep learning. First, we describe sparse signal representation in terms of dictionaries from a statistical perspective and interpret dictionary learning as a process of aligning distribution that arises from a generative model with empirical distribution of true signals. As a result we can see that sparse coding with learned dictionaries resembles a specific variational autoencoder, where the decoder is a linear function and the encoder is a sparse coding algorithm. Next, we show that dictionary learning can also benefit from computational advancements introduced in the context of deep learning, such as parallelism and as stochastic optimization. Finally, we show that regularization by dictionaries achieves competitive performance in computed tomography (CT) reconstruction comparing to state-of-the-art model based and data driven approaches.

</p>
</details>

<details><summary><b>User-Centric Semi-Automated Infographics Authoring and Recommendation</b>
<a href="https://arxiv.org/abs/2108.11914">arxiv:2108.11914</a>
&#x1F4C8; 7 <br>
<p>Anjul Tyagi, Jian Zhao, Pushkar Patel, Swasti Khurana, Klaus Mueller</p></summary>
<p>

**Abstract:** Designing infographics can be a tedious process for non-experts and time-consuming even for professional designers. Based on the literature and a formative study, we propose a flexible framework for automated and semi-automated infographics design. This framework captures the main design components in infographics and streamlines the generation workflow into three steps, allowing users to control and optimize each aspect independently. Based on the framework, we also propose an interactive tool, \name{}, for assisting novice designers with creating high-quality infographics from an input in a markdown format by offering recommendations of different design components of infographics. Simultaneously, more experienced designers can provide custom designs and layout ideas to the tool using a canvas to control the automated generation process partially. As part of our work, we also contribute an individual visual group (VG) and connection designs dataset (in SVG), along with a 1k complete infographic image dataset with segmented VGs. This dataset plays a crucial role in diversifying the infographic designs created by our framework. We evaluate our approach with a comparison against similar tools, a user study with novice and expert designers, and a case study. Results confirm that our framework and \name{} excel in creating customized infographics and exploring a large variety of designs.

</p>
</details>

<details><summary><b>Classification of Emotions and Evaluation of Customer Satisfaction from Speech in Real World Acoustic Environments</b>
<a href="https://arxiv.org/abs/2108.11981">arxiv:2108.11981</a>
&#x1F4C8; 6 <br>
<p>Luis Felipe Parra-Gallego, Juan Rafael Orozco-Arroyave</p></summary>
<p>

**Abstract:** This paper focuses on finding suitable features to robustly recognize emotions and evaluate customer satisfaction from speech in real acoustic scenarios. The classification of emotions is based on standard and well-known corpora and the evaluation of customer satisfaction is based on recordings of real opinions given by customers about the received service during phone calls with call-center agents. The feature sets considered in this study include two speaker models, namely x-vectors and i-vectors, and also the well known feature set introduced in the Interspeech 2010 Paralinguistics Challenge (I2010PC). Additionally, we introduce the use of phonation, articulation and prosody features extracted with the DisVoice framework as alternative feature sets to robustly model emotions and customer satisfaction from speech. The results indicate that the I2010PC feature set is the best approach to classify emotions in the standard databases typically used in the literature. When considering the recordings collected in the call-center, without any control over the acoustic conditions, the best results are obtained with our articulation features. The I2010PC feature set includes 1584 measures while the articulation approach only includes 488 measures. We think that the proposed approach is more suitable for real-world applications where the acoustic conditions are not controlled and also it is potentially more convenient for industrial applications.

</p>
</details>

<details><summary><b>When should agents explore?</b>
<a href="https://arxiv.org/abs/2108.11811">arxiv:2108.11811</a>
&#x1F4C8; 6 <br>
<p>Miruna Pîslar, David Szepesvari, Georg Ostrovski, Diana Borsa, Tom Schaul</p></summary>
<p>

**Abstract:** Exploration remains a central challenge for reinforcement learning (RL). Virtually all existing methods share the feature of a monolithic behaviour policy that changes only gradually (at best). In contrast, the exploratory behaviours of animals and humans exhibit a rich diversity, namely including forms of switching between modes. This paper presents an initial study of mode-switching, non-monolithic exploration for RL. We investigate different modes to switch between, at what timescales it makes sense to switch, and what signals make for good switching triggers. We also propose practical algorithmic components that make the switching mechanism adaptive and robust, which enables flexibility without an accompanying hyper-parameter-tuning burden. Finally, we report a promising and detailed analysis on Atari, using two-mode exploration and switching at sub-episodic time-scales.

</p>
</details>

<details><summary><b>Fine-tuning Pretrained Language Models with Label Attention for Explainable Biomedical Text Classification</b>
<a href="https://arxiv.org/abs/2108.11809">arxiv:2108.11809</a>
&#x1F4C8; 6 <br>
<p>Bruce Nguyen, Shaoxiong Ji</p></summary>
<p>

**Abstract:** The massive growth of digital biomedical data is making biomedical text indexing and classification increasingly important. Accordingly, previous research has devised numerous deep learning techniques focused on using feedforward, convolutional or recurrent neural architectures. More recently, fine-tuned transformers-based pretrained models (PTMs) have demonstrated superior performance compared to such models in many natural language processing tasks. However, the direct use of PTMs in the biomedical domain is only limited to the target documents, ignoring the rich semantic information in the label descriptions. In this paper, we develop an improved label attention-based architecture to inject semantic label description into the fine-tuning process of PTMs. Results on two public medical datasets show that the proposed fine-tuning scheme outperforms the conventionally fine-tuned PTMs and prior state-of-the-art models. Furthermore, we show that fine-tuning with the label attention mechanism is interpretable in the interpretability study.

</p>
</details>

<details><summary><b>Identification of Vehicle Dynamics Parameters Using Simulation-based Inference</b>
<a href="https://arxiv.org/abs/2108.12114">arxiv:2108.12114</a>
&#x1F4C8; 5 <br>
<p>Ali Boyali, Simon Thompson, David Robert Wong</p></summary>
<p>

**Abstract:** Identifying tire and vehicle parameters is an essential step in designing control and planning algorithms for autonomous vehicles. This paper proposes a new method: Simulation-Based Inference (SBI), a modern interpretation of Approximate Bayesian Computation methods (ABC) for parameter identification. The simulation-based inference is an emerging method in the machine learning literature and has proven to yield accurate results for many parameter sets in complex problems. We demonstrate in this paper that it can handle the identification of highly nonlinear vehicle dynamics parameters and gives accurate estimates of the parameters for the governing equations.

</p>
</details>

<details><summary><b>Predicting Stable Configurations for Semantic Placement of Novel Objects</b>
<a href="https://arxiv.org/abs/2108.12062">arxiv:2108.12062</a>
&#x1F4C8; 5 <br>
<p>Chris Paxton, Chris Xie, Tucker Hermans, Dieter Fox</p></summary>
<p>

**Abstract:** Human environments contain numerous objects configured in a variety of arrangements. Our goal is to enable robots to repose previously unseen objects according to learned semantic relationships in novel environments. We break this problem down into two parts: (1) finding physically valid locations for the objects and (2) determining if those poses satisfy learned, high-level semantic relationships. We build our models and training from the ground up to be tightly integrated with our proposed planning algorithm for semantic placement of unknown objects. We train our models purely in simulation, with no fine-tuning needed for use in the real world. Our approach enables motion planning for semantic rearrangement of unknown objects in scenes with varying geometry from only RGB-D sensing. Our experiments through a set of simulated ablations demonstrate that using a relational classifier alone is not sufficient for reliable planning. We further demonstrate the ability of our planner to generate and execute diverse manipulation plans through a set of real-world experiments with a variety of objects.

</p>
</details>

<details><summary><b>Learning Disentangled Representations in the Imaging Domain</b>
<a href="https://arxiv.org/abs/2108.12043">arxiv:2108.12043</a>
&#x1F4C8; 5 <br>
<p>Xiao Liu, Pedro Sanchez, Spyridon Thermos, Alison Q. O'Neil, Sotirios A. Tsaftaris</p></summary>
<p>

**Abstract:** Disentangled representation learning has been proposed as an approach to learning general representations even in the absence of, or with limited, supervision. A good general representation can be fine-tuned for new target tasks using modest amounts of data, or used directly in unseen domains achieving remarkable performance in the corresponding task. This alleviation of the data and annotation requirements offers tantalising prospects for applications in computer vision and healthcare. In this tutorial paper, we motivate the need for disentangled representations, present key theory, and detail practical building blocks and criteria for learning such representations. We discuss applications in medical imaging and computer vision emphasising choices made in exemplar key works. We conclude by presenting remaining challenges and opportunities.

</p>
</details>

<details><summary><b>PoissonSeg: Semi-Supervised Few-Shot Medical Image Segmentation via Poisson Learning</b>
<a href="https://arxiv.org/abs/2108.11694">arxiv:2108.11694</a>
&#x1F4C8; 5 <br>
<p>Xiaoang Shen, Guokai Zhang, Huilin Lai, Jihao Luo, Jianwei Lu, Ye Luo</p></summary>
<p>

**Abstract:** The application of deep learning to medical image segmentation has been hampered due to the lack of abundant pixel-level annotated data. Few-shot Semantic Segmentation (FSS) is a promising strategy for breaking the deadlock. However, a high-performing FSS model still requires sufficient pixel-level annotated classes for training to avoid overfitting, which leads to its performance bottleneck in medical image segmentation due to the unmet need for annotations. Thus, semi-supervised FSS for medical images is accordingly proposed to utilize unlabeled data for further performance improvement. Nevertheless, existing semi-supervised FSS methods has two obvious defects: (1) neglecting the relationship between the labeled and unlabeled data; (2) using unlabeled data directly for end-to-end training leads to degenerated representation learning. To address these problems, we propose a novel semi-supervised FSS framework for medical image segmentation. The proposed framework employs Poisson learning for modeling data relationship and propagating supervision signals, and Spatial Consistency Calibration for encouraging the model to learn more coherent representations. In this process, unlabeled samples do not involve in end-to-end training, but provide supervisory information for query image segmentation through graph-based learning. We conduct extensive experiments on three medical image segmentation datasets (i.e. ISIC skin lesion segmentation, abdominal organs segmentation for MRI and abdominal organs segmentation for CT) to demonstrate the state-of-the-art performance and broad applicability of the proposed framework.

</p>
</details>

<details><summary><b>Network Module Detection from Multi-Modal Node Features with a Greedy Decision Forest for Actionable Explainable AI</b>
<a href="https://arxiv.org/abs/2108.11674">arxiv:2108.11674</a>
&#x1F4C8; 5 <br>
<p>Bastian Pfeifer, Anna Saranti, Andreas Holzinger</p></summary>
<p>

**Abstract:** Network-based algorithms are used in most domains of research and industry in a wide variety of applications and are of great practical use. In this work, we demonstrate subnetwork detection based on multi-modal node features using a new Greedy Decision Forest for better interpretability. The latter will be a crucial factor in retaining experts and gaining their trust in such algorithms in the future. To demonstrate a concrete application example, we focus in this paper on bioinformatics and systems biology with a special focus on biomedicine. However, our methodological approach is applicable in many other domains as well. Systems biology serves as a very good example of a field in which statistical data-driven machine learning enables the analysis of large amounts of multi-modal biomedical data. This is important to reach the future goal of precision medicine, where the complexity of patients is modeled on a system level to best tailor medical decisions, health practices and therapies to the individual patient. Our glass-box approach could help to uncover disease-causing network modules from multi-omics data to better understand diseases such as cancer.

</p>
</details>

<details><summary><b>StressNAS: Affect State and Stress Detection Using Neural Architecture Search</b>
<a href="https://arxiv.org/abs/2108.12502">arxiv:2108.12502</a>
&#x1F4C8; 4 <br>
<p>Lam Huynh, Tri Nguyen, Thu Nguyen, Susanna Pirttikangas, Pekka Siirtola</p></summary>
<p>

**Abstract:** Smartwatches have rapidly evolved towards capabilities to accurately capture physiological signals. As an appealing application, stress detection attracts many studies due to its potential benefits to human health. It is propitious to investigate the applicability of deep neural networks (DNN) to enhance human decision-making through physiological signals. However, manually engineering DNN proves a tedious task especially in stress detection due to the complex nature of this phenomenon. To this end, we propose an optimized deep neural network training scheme using neural architecture search merely using wrist-worn data from WESAD. Experiments show that our approach outperforms traditional ML methods by 8.22% and 6.02% in the three-state and two-state classifiers, respectively, using the combination of WESAD wrist signals. Moreover, the proposed method can minimize the need for human-design DNN while improving performance by 4.39% (three-state) and 8.99% (binary).

</p>
</details>

<details><summary><b>Targeting Underrepresented Populations in Precision Medicine: A Federated Transfer Learning Approach</b>
<a href="https://arxiv.org/abs/2108.12112">arxiv:2108.12112</a>
&#x1F4C8; 4 <br>
<p>Sai Li, Tianxi Cai, Rui Duan</p></summary>
<p>

**Abstract:** The limited representation of minorities and disadvantaged populations in large-scale clinical and genomics research has become a barrier to translating precision medicine research into practice. Due to heterogeneity across populations, risk prediction models are often found to be underperformed in these underrepresented populations, and therefore may further exacerbate known health disparities. In this paper, we propose a two-way data integration strategy that integrates heterogeneous data from diverse populations and from multiple healthcare institutions via a federated transfer learning approach. The proposed method can handle the challenging setting where sample sizes from different populations are highly unbalanced. With only a small number of communications across participating sites, the proposed method can achieve performance comparable to the pooled analysis where individual-level data are directly pooled together. We show that the proposed method improves the estimation and prediction accuracy in underrepresented populations, and reduces the gap of model performance across populations. Our theoretical analysis reveals how estimation accuracy is influenced by communication budgets, privacy restrictions, and heterogeneity across populations. We demonstrate the feasibility and validity of our methods through numerical experiments and a real application to a multi-center study, in which we construct polygenic risk prediction models for Type II diabetes in AA population.

</p>
</details>

<details><summary><b>4-bit Quantization of LSTM-based Speech Recognition Models</b>
<a href="https://arxiv.org/abs/2108.12074">arxiv:2108.12074</a>
&#x1F4C8; 4 <br>
<p>Andrea Fasoli, Chia-Yu Chen, Mauricio Serrano, Xiao Sun, Naigang Wang, Swagath Venkataramani, George Saon, Xiaodong Cui, Brian Kingsbury, Wei Zhang, Zoltán Tüske, Kailash Gopalakrishnan</p></summary>
<p>

**Abstract:** We investigate the impact of aggressive low-precision representations of weights and activations in two families of large LSTM-based architectures for Automatic Speech Recognition (ASR): hybrid Deep Bidirectional LSTM - Hidden Markov Models (DBLSTM-HMMs) and Recurrent Neural Network - Transducers (RNN-Ts). Using a 4-bit integer representation, a naïve quantization approach applied to the LSTM portion of these models results in significant Word Error Rate (WER) degradation. On the other hand, we show that minimal accuracy loss is achievable with an appropriate choice of quantizers and initializations. In particular, we customize quantization schemes depending on the local properties of the network, improving recognition performance while limiting computational time. We demonstrate our solution on the Switchboard (SWB) and CallHome (CH) test sets of the NIST Hub5-2000 evaluation. DBLSTM-HMMs trained with 300 or 2000 hours of SWB data achieves $<$0.5% and $<$1% average WER degradation, respectively. On the more challenging RNN-T models, our quantization strategy limits degradation in 4-bit inference to 1.3%.

</p>
</details>

<details><summary><b>Using GAN-based models to sentimental analysis on imbalanced datasets in education domain</b>
<a href="https://arxiv.org/abs/2108.12061">arxiv:2108.12061</a>
&#x1F4C8; 4 <br>
<p>Ru Yang, Maryam Edalati</p></summary>
<p>

**Abstract:** While the whole world is still struggling with the COVID-19 pandemic, online learning and home office become more common. Many schools transfer their courses teaching to the online classroom. Therefore, it is significant to mine the students' feedback and opinions from their reviews towards studies so that both schools and teachers can know where they need to improve. This paper trains machine learning and deep learning models using both balanced and imbalanced datasets for sentiment classification. Two SOTA category-aware text generation GAN models: CatGAN and SentiGAN, are utilized to synthesize text used to balance the highly imbalanced dataset. Results on three datasets with different imbalance degree from distinct domains show that when using generated text to balance the dataset, the F1-score of machine learning and deep learning model on sentiment classification increases 2.79% ~ 9.28%. Also, the results indicate that the average growth degree for CR100k is higher than CR23k, the average growth degree for deep learning is more increased than machine learning algorithms, and the average growth degree for more complex deep learning models is more increased than simpler deep learning models in experiments.

</p>
</details>

<details><summary><b>Ultrafast Focus Detection for Automated Microscopy</b>
<a href="https://arxiv.org/abs/2108.12050">arxiv:2108.12050</a>
&#x1F4C8; 4 <br>
<p>Maksim Levental, Ryan Chard, Gregg A. Wildenberg</p></summary>
<p>

**Abstract:** Recent advances in scientific instruments have resulted in dramatic increase in the volumes and velocities of data being generated in every-day laboratories. Scanning electron microscopy is one such example where technological advancements are now overwhelming scientists with critical data for montaging, alignment, and image segmentation -- key practices for many scientific domains, including, for example, neuroscience, where they are used to derive the anatomical relationships of the brain. These instruments now necessitate equally advanced computing resources and techniques to realize their full potential. Here we present a fast out-of-focus detection algorithm for electron microscopy images collected serially and demonstrate that it can be used to provide near-real time quality control for neurology research. Our technique, Multi-scale Histologic Feature Detection, adapts classical computer vision techniques and is based on detecting various fine-grained histologic features. We further exploit the inherent parallelism in the technique by employing GPGPU primitives in order to accelerate characterization. Tests are performed that demonstrate near-real-time detection of out-of-focus conditions. We deploy these capabilities as a funcX function and show that it can be applied as data are collected using an automated pipeline . We discuss extensions that enable scaling out to support multi-beam microscopes and integration with existing focus systems for purposes of implementing auto-focus.

</p>
</details>

<details><summary><b>Evaluating Transformer-based Semantic Segmentation Networks for Pathological Image Segmentation</b>
<a href="https://arxiv.org/abs/2108.11993">arxiv:2108.11993</a>
&#x1F4C8; 4 <br>
<p>Cam Nguyen, Zuhayr Asad, Yuankai Huo</p></summary>
<p>

**Abstract:** Histopathology has played an essential role in cancer diagnosis. With the rapid advances in convolutional neural networks (CNN). Various CNN-based automated pathological image segmentation approaches have been developed in computer-assisted pathological image analysis. In the past few years, Transformer neural networks (Transformer) have shown the unique merit of capturing the global long-distance dependencies across the entire image as a new deep learning paradigm. Such merit is appealing for exploring spatially heterogeneous pathological images. However, there have been very few, if any, studies that have systematically evaluated the current Transformer-based approaches in pathological image segmentation. To assess the performance of Transformer segmentation models on whole slide images (WSI), we quantitatively evaluated six prevalent transformer-based models on tumor segmentation, using the widely used PAIP liver histopathological dataset. For a more comprehensive analysis, we also compare the transformer-based models with six major traditional CNN-based models. The results show that the Transformer-based models exhibit a general superior performance over the CNN-based models. In particular, Segmenter, Swin-Transformer and TransUNet-all transformer-based-came out as the best performers among the twelve evaluated models.

</p>
</details>

<details><summary><b>Machine Learning for Mediation in Armed Conflicts</b>
<a href="https://arxiv.org/abs/2108.11942">arxiv:2108.11942</a>
&#x1F4C8; 4 <br>
<p>M. Arana-Catania, F. A. Van Lier, Rob Procter</p></summary>
<p>

**Abstract:** Today's conflicts are becoming increasingly complex, fluid and fragmented, often involving a host of national and international actors with multiple and often divergent interests. This development poses significant challenges for conflict mediation, as mediators struggle to make sense of conflict dynamics, such as the range of conflict parties and the evolution of their political positions, the distinction between relevant and less relevant actors in peace making, or the identification of key conflict issues and their interdependence. International peace efforts appear increasingly ill-equipped to successfully address these challenges. While technology is being increasingly used in a range of conflict related fields, such as conflict predicting or information gathering, less attention has been given to how technology can contribute to conflict mediation. This case study is the first to apply state-of-the-art machine learning technologies to data from an ongoing mediation process. Using dialogue transcripts from peace negotiations in Yemen, this study shows how machine-learning tools can effectively support international mediators by managing knowledge and offering additional conflict analysis tools to assess complex information. Apart from illustrating the potential of machine learning tools in conflict mediation, the paper also emphasises the importance of interdisciplinary and participatory research design for the development of context-sensitive and targeted tools and to ensure meaningful and responsible implementation.

</p>
</details>

<details><summary><b>Sketches for Time-Dependent Machine Learning</b>
<a href="https://arxiv.org/abs/2108.11923">arxiv:2108.11923</a>
&#x1F4C8; 4 <br>
<p>Jesus Antonanzas, Marta Arias, Albert Bifet</p></summary>
<p>

**Abstract:** Time series data can be subject to changes in the underlying process that generates them and, because of these changes, models built on old samples can become obsolete or perform poorly. In this work, we present a way to incorporate information about the current data distribution and its evolution across time into machine learning algorithms. Our solution is based on efficiently maintaining statistics, particularly the mean and the variance, of data features at different time resolutions. These data summarisations can be performed over the input attributes, in which case they can then be fed into the model as additional input features, or over latent representations learned by models, such as those of Recurrent Neural Networks. In classification tasks, the proposed techniques can significantly outperform the prediction capabilities of equivalent architectures with no feature / latent summarisations. Furthermore, these modifications do not introduce notable computational and memory overhead when properly adjusted.

</p>
</details>

<details><summary><b>A spatio-temporal LSTM model to forecast across multiple temporal and spatial scales</b>
<a href="https://arxiv.org/abs/2108.11875">arxiv:2108.11875</a>
&#x1F4C8; 4 <br>
<p>Yihao Hu, Fearghal O'Donncha, Paulito Palmes, Meredith Burke, Ramon Filgueira, Jon Grant</p></summary>
<p>

**Abstract:** This paper presents a novel spatio-temporal LSTM (SPATIAL) architecture for time series forecasting applied to environmental datasets. The framework was evaluated across multiple sensors and for three different oceanic variables: current speed, temperature, and dissolved oxygen. Network implementation proceeded in two directions that are nominally separated but connected as part of a natural environmental system -- across the spatial (between individual sensors) and temporal components of the sensor data. Data from four sensors sampling current speed, and eight measuring both temperature and dissolved oxygen evaluated the framework. Results were compared against RF and XGB baseline models that learned on the temporal signal of each sensor independently by extracting the date-time features together with the past history of data using sliding window matrix. Results demonstrated ability to accurately replicate complex signals and provide comparable performance to state-of-the-art benchmarks. Notably, the novel framework provided a simpler pre-processing and training pipeline that handles missing values via a simple masking layer. Enabling learning across the spatial and temporal directions, this paper addresses two fundamental challenges of ML applications to environmental science: 1) data sparsity and the challenges and costs of collecting measurements of environmental conditions such as ocean dynamics, and 2) environmental datasets are inherently connected in the spatial and temporal directions while classical ML approaches only consider one of these directions. Furthermore, sharing of parameters across all input steps makes SPATIAL a fast, scalable, and easily-parameterized forecasting framework.

</p>
</details>

<details><summary><b>Consistent Relative Confidence and Label-Free Model Selection for Convolutional Neural Networks</b>
<a href="https://arxiv.org/abs/2108.11845">arxiv:2108.11845</a>
&#x1F4C8; 4 <br>
<p>Bin Liu</p></summary>
<p>

**Abstract:** This paper is concerned with image classification based on deep convolutional neural networks (CNNs). The focus is centered around the following question: given a set of candidate CNN models, how to select the right one that has the best generalization property for the current task? Present model selection methods require access to a batch of labeled data for defining a performance metric, such as the cross-entropy loss, the classification error rate, the negative log-likelihood, and so on. In many practical cases, however, labeled data are not available in time as labeling itself is a time-consuming and expensive task. To this end, this paper presents an approach to CNN model selection using only unlabeled data. This method is developed based on a principle termed consistent relative confidence (CRC). The effectiveness and efficiency of the presented method are demonstrated by extensive experimental studies based on datasets MNIST and FasionMNIST.

</p>
</details>

<details><summary><b>AI at work -- Mitigating safety and discriminatory risk with technical standards</b>
<a href="https://arxiv.org/abs/2108.11844">arxiv:2108.11844</a>
&#x1F4C8; 4 <br>
<p>Nikolas Becker, Pauline Junginger, Lukas Martinez, Daniel Krupka, Leonie Beining</p></summary>
<p>

**Abstract:** The use of artificial intelligence (AI) and AI methods in the workplace holds both great opportunities as well as risks to occupational safety and discrimination. In addition to legal regulation, technical standards will play a key role in mitigating such risk by defining technical requirements for development and testing of AI systems. This paper provides an overview and assessment of existing international, European and German standards as well as those currently under development. The paper is part of the research project "ExamAI - Testing and Auditing of AI systems" and focusses on the use of AI in an industrial production environment as well as in the realm of human resource management (HR).

</p>
</details>

<details><summary><b>Human readable network troubleshooting based on anomaly detection and feature scoring</b>
<a href="https://arxiv.org/abs/2108.11807">arxiv:2108.11807</a>
&#x1F4C8; 4 <br>
<p>Jose M. Navarro, Alexis Huet, Dario Rossi</p></summary>
<p>

**Abstract:** Network troubleshooting is still a heavily human-intensive process. To reduce the time spent by human operators in the diagnosis process, we present a system based on (i) unsupervised learning methods for detecting anomalies in the time domain, (ii) an attention mechanism to rank features in the feature space and finally (iii) an expert knowledge module able to seamlessly incorporate previously collected domain-knowledge. In this paper, we thoroughly evaluate the performance of the full system and of its individual building blocks: particularly, we consider (i) 10 anomaly detection algorithms as well as (ii) 10 attention mechanisms, that comprehensively represent the current state of the art in the respective fields. Leveraging a unique collection of expert-labeled datasets worth several months of real router telemetry data, we perform a thorough performance evaluation contrasting practical results in constrained stream-mode settings, with the results achievable by an ideal oracle in academic settings. Our experimental evaluation shows that (i) the proposed system is effective in achieving high levels of agreement with the expert, and (ii) that even a simple statistical approach is able to extract useful information from expert knowledge gained in past cases, significantly improving troubleshooting performance.

</p>
</details>

<details><summary><b>Multiple Sclerosis Lesions Identification/Segmentation in Magnetic Resonance Imaging using Ensemble CNN and Uncertainty Classification</b>
<a href="https://arxiv.org/abs/2108.11791">arxiv:2108.11791</a>
&#x1F4C8; 4 <br>
<p>Giuseppe Placidi, Luigi Cinque, Filippo Mignosi, Matteo Polsinelli</p></summary>
<p>

**Abstract:** To date, several automated strategies for identification/segmentation of Multiple Sclerosis (MS) lesions with the use of Magnetic Resonance Imaging (MRI) have been presented but they are either outperformed by human experts or perform differently from them. This is mainly due to the ambiguity originated by MRI instabilities, peculiar variability of MS and unspecific nature of MRI with respect to MS. Physicians partially manage the uncertainty generated by ambiguity relying on their personal radiological/clinical/anatomical background and experience. We present an automated framework based on three pivotal concepts to better emulate human reasoning: 1. the modelling of uncertainty; 2. the proposal of two, separately trained, CNN, one optimized with respect to lesions themselves and the other to the environment surrounding lesions, respectively repeated for axial, coronal and sagittal directions; 3. the definition of an ensemble classifier to merge the information collected by all CNN. The proposed framework is trained, validated and tested on the 2016 MSSEG benchmark public data set from a single imaging modality, the FLuid-Attenuated Inversion Recovery (FLAIR). The comparison, made with the consensus (the ground-truth) between 7 human raters and with each of the 7 human raters, proves that there is no significant difference between the automated and the human raters. The results of our framework concerning the uncertainty are also reported, even if a comparison with the raters is impossible because they don't recognize this class.

</p>
</details>

<details><summary><b>Improving the Reliability of Semantic Segmentation of Medical Images by Uncertainty Modeling with Bayesian Deep Networks and Curriculum Learning</b>
<a href="https://arxiv.org/abs/2108.11693">arxiv:2108.11693</a>
&#x1F4C8; 4 <br>
<p>Sora Iwamoto, Bisser Raytchev, Toru Tamaki, Kazufumi Kaneda</p></summary>
<p>

**Abstract:** In this paper we propose a novel method which leverages the uncertainty measures provided by Bayesian deep networks through curriculum learning so that the uncertainty estimates are fed back to the system to resample the training data more densely in areas where uncertainty is high. We show in the concrete setting of a semantic segmentation task (iPS cell colony segmentation) that the proposed system is able to increase significantly the reliability of the model.

</p>
</details>

<details><summary><b>Training a discrete variational autoencoder for generative chemistry and drug design on a quantum annealer</b>
<a href="https://arxiv.org/abs/2108.11644">arxiv:2108.11644</a>
&#x1F4C8; 4 <br>
<p>A. I. Gircha, A. S. Boev, K. Avchaciov, P. O. Fedichev, A. K. Fedorov</p></summary>
<p>

**Abstract:** Deep generative chemistry models emerge as powerful tools to expedite drug discovery. However, the immense size and complexity of the structural space of all possible drug-like molecules pose significant obstacles, which could be overcome with hybrid architectures combining quantum computers with deep classical networks. We built a compact discrete variational autoencoder (DVAE) with a Restricted Boltzmann Machine (RBM) of reduced size in its latent layer. The size of the proposed model was small enough to fit on a state-of-the-art D-Wave quantum annealer and allowed training on a subset of the ChEMBL dataset of biologically active compounds. Finally, we generated $4290$ novel chemical structures with medicinal chemistry and synthetic accessibility properties in the ranges typical for molecules from ChEMBL. The experimental results point towards the feasibility of using already existing quantum annealing devices for drug discovery problems, which opens the way to building quantum generative models for practically relevant applications.

</p>
</details>

<details><summary><b>CoMPM: Context Modeling with Speaker's Pre-trained Memory Tracking for Emotion Recognition in Conversation</b>
<a href="https://arxiv.org/abs/2108.11626">arxiv:2108.11626</a>
&#x1F4C8; 4 <br>
<p>Joosung Lee, Wooin Lee</p></summary>
<p>

**Abstract:** As the use of interactive machines grow, the task of Emotion Recognition in Conversation (ERC) became more important. If the machine generated sentences reflect emotion, more human-like sympathetic conversations are possible. Since emotion recognition in conversation is inaccurate if the previous utterances are not taken into account, many studies reflect the dialogue context to improve the performances. We introduce CoMPM, a context embedding module (CoM) combined with a pre-trained memory module (PM) that tracks memory of the speaker's previous utterances within the context, and show that the pre-trained memory significantly improves the final accuracy of emotion recognition. We experimented on both the multi-party datasets (MELD, EmoryNLP) and the dyadic-party datasets (IEMOCAP, DailyDialog), showing that our approach achieve competitive performance on all datasets.

</p>
</details>

<details><summary><b>Modeling Item Response Theory with Stochastic Variational Inference</b>
<a href="https://arxiv.org/abs/2108.11579">arxiv:2108.11579</a>
&#x1F4C8; 4 <br>
<p>Mike Wu, Richard L. Davis, Benjamin W. Domingue, Chris Piech, Noah Goodman</p></summary>
<p>

**Abstract:** Item Response Theory (IRT) is a ubiquitous model for understanding human behaviors and attitudes based on their responses to questions. Large modern datasets offer opportunities to capture more nuances in human behavior, potentially improving psychometric modeling leading to improved scientific understanding and public policy. However, while larger datasets allow for more flexible approaches, many contemporary algorithms for fitting IRT models may also have massive computational demands that forbid real-world application. To address this bottleneck, we introduce a variational Bayesian inference algorithm for IRT, and show that it is fast and scalable without sacrificing accuracy. Applying this method to five large-scale item response datasets from cognitive science and education yields higher log likelihoods and higher accuracy in imputing missing data than alternative inference algorithms. Using this new inference approach we then generalize IRT with expressive Bayesian models of responses, leveraging recent advances in deep learning to capture nonlinear item characteristic curves (ICC) with neural networks. Using an eigth-grade mathematics test from TIMSS, we show our nonlinear IRT models can capture interesting asymmetric ICCs. The algorithm implementation is open-source, and easily usable.

</p>
</details>

<details><summary><b>Stop Throwing Away Discriminators! Re-using Adversaries for Test-Time Training</b>
<a href="https://arxiv.org/abs/2108.12280">arxiv:2108.12280</a>
&#x1F4C8; 3 <br>
<p>Gabriele Valvano, Andrea Leo, Sotirios A. Tsaftaris</p></summary>
<p>

**Abstract:** Thanks to their ability to learn data distributions without requiring paired data, Generative Adversarial Networks (GANs) have become an integral part of many computer vision methods, including those developed for medical image segmentation. These methods jointly train a segmentor and an adversarial mask discriminator, which provides a data-driven shape prior. At inference, the discriminator is discarded, and only the segmentor is used to predict label maps on test images. But should we discard the discriminator? Here, we argue that the life cycle of adversarial discriminators should not end after training. On the contrary, training stable GANs produces powerful shape priors that we can use to correct segmentor mistakes at inference. To achieve this, we develop stable mask discriminators that do not overfit or catastrophically forget. At test time, we fine-tune the segmentor on each individual test instance until it satisfies the learned shape prior. Our method is simple to implement and increases model performance. Moreover, it opens new directions for re-using mask discriminators at inference. We release the code used for the experiments at https://vios-s.github.io/adversarial-test-time-training.

</p>
</details>

<details><summary><b>An Automatic Image Content Retrieval Method for better Mobile Device Display User Experiences</b>
<a href="https://arxiv.org/abs/2108.12068">arxiv:2108.12068</a>
&#x1F4C8; 3 <br>
<p>Alessandro Bruno</p></summary>
<p>

**Abstract:** A growing number of commercially available mobile phones come with integrated high-resolution digital cameras. That enables a new class of dedicated applications to image analysis such as mobile visual search, image cropping, object detection, content-based image retrieval, image classification. In this paper, a new mobile application for image content retrieval and classification for mobile device display is proposed to enrich the visual experience of users. The mobile application can extract a certain number of images based on the content of an image with visual saliency methods aiming at detecting the most critical regions in a given image from a perceptual viewpoint. First, the most critical areas from a perceptual perspective are extracted using the local maxima of a 2D saliency function. Next, a salient region is cropped using the bounding box centred on the local maxima of the thresholded Saliency Map of the image. Then, each image crop feds into an Image Classification system based on SVM and SIFT descriptors to detect the class of object present in the image. ImageNet repository was used as the reference for semantic category classification. Android platform was used to implement the mobile application on a client-server architecture. A mobile client sends the photo taken by the camera to the server, which processes the image and returns the results (image contents such as image crops and related target classes) to the mobile client. The application was run on thousands of pictures and showed encouraging results towards a better user visual experience with mobile displays.

</p>
</details>

<details><summary><b>Machine Learning for Discovering Effective Interaction Kernels between Celestial Bodies from Ephemerides</b>
<a href="https://arxiv.org/abs/2108.11894">arxiv:2108.11894</a>
&#x1F4C8; 3 <br>
<p>Ming Zhong, Jason Miller, Mauro Maggioni</p></summary>
<p>

**Abstract:** Building accurate and predictive models of the underlying mechanisms of celestial motion has inspired fundamental developments in theoretical physics. Candidate theories seek to explain observations and predict future positions of planets, stars, and other astronomical bodies as faithfully as possible. We use a data-driven learning approach, extending that developed in Lu et al. ($2019$) and extended in Zhong et al. ($2020$), to a derive stable and accurate model for the motion of celestial bodies in our Solar System. Our model is based on a collective dynamics framework, and is learned from the NASA Jet Propulsion Lab's development ephemerides. By modeling the major astronomical bodies in the Solar System as pairwise interacting agents, our learned model generate extremely accurate dynamics that preserve not only intrinsic geometric properties of the orbits, but also highly sensitive features of the dynamics, such as perihelion precession rates. Our learned model can provide a unified explanation to the observation data, especially in terms of reproducing the perihelion precession of Mars, Mercury, and the Moon. Moreover, Our model outperforms Newton's Law of Universal Gravitation in all cases and performs similarly to, and exceeds on the Moon, the Einstein-Infeld-Hoffman equations derived from Einstein's theory of general relativity.

</p>
</details>

<details><summary><b>Federated Reinforcement Learning: Techniques, Applications, and Open Challenges</b>
<a href="https://arxiv.org/abs/2108.11887">arxiv:2108.11887</a>
&#x1F4C8; 3 <br>
<p>Jiaju Qi, Qihao Zhou, Lei Lei, Kan Zheng</p></summary>
<p>

**Abstract:** This paper presents a comprehensive survey of Federated Reinforcement Learning (FRL), an emerging and promising field in Reinforcement Learning (RL). Starting with a tutorial of Federated Learning (FL) and RL, we then focus on the introduction of FRL as a new method with great potential by leveraging the basic idea of FL to improve the performance of RL while preserving data-privacy. According to the distribution characteristics of the agents in the framework, FRL algorithms can be divided into two categories, i.e. Horizontal Federated Reinforcement Learning (HFRL) and Vertical Federated Reinforcement Learning (VFRL). We provide the detailed definitions of each category by formulas, investigate the evolution of FRL from a technical perspective, and highlight its advantages over previous RL algorithms. In addition, the existing works on FRL are summarized by application fields, including edge computing, communication, control optimization, and attack detection. Finally, we describe and discuss several key research directions that are crucial to solving the open problems within FRL.

</p>
</details>

<details><summary><b>Comparing Classes of Estimators: When does Gradient Descent Beat Ridge Regression in Linear Models?</b>
<a href="https://arxiv.org/abs/2108.11872">arxiv:2108.11872</a>
&#x1F4C8; 3 <br>
<p>Dominic Richards, Edgar Dobriban, Patrick Rebeschini</p></summary>
<p>

**Abstract:** Modern methods for learning from data depend on many tuning parameters, such as the stepsize for optimization methods, and the regularization strength for regularized learning methods. Since performance can depend strongly on these parameters, it is important to develop comparisons between \emph{classes of methods}, not just for particularly tuned ones. Here, we take aim to compare classes of estimators via the relative performance of the \emph{best method in the class}. This allows us to rigorously quantify the tuning sensitivity of learning algorithms. As an illustration, we investigate the statistical estimation performance of ridge regression with a uniform grid of regularization parameters, and of gradient descent iterates with a fixed stepsize, in the standard linear model with a random isotropic ground truth parameter.
  (1) For orthogonal designs, we find the \emph{exact minimax optimal classes of estimators}, showing they are equal to gradient descent with a polynomially decaying learning rate. We find the exact suboptimalities of ridge regression and gradient descent with a fixed stepsize, showing that they decay as either $1/k$ or $1/k^2$ for specific ranges of $k$ estimators.
  (2) For general designs with a large number of non-zero eigenvalues, we find that gradient descent outperforms ridge regression when the eigenvalues decay slowly, as a power law with exponent less than unity. If instead the eigenvalues decay quickly, as a power law with exponent greater than unity or exponentially, we find that ridge regression outperforms gradient descent.
  Our results highlight the importance of tuning parameters. In particular, while optimally tuned ridge regression is the best estimator in our case, it can be outperformed by gradient descent when both are restricted to being tuned over a finite regularization grid.

</p>
</details>

<details><summary><b>Subgradient methods near active manifolds: saddle point avoidance, local convergence, and asymptotic normality</b>
<a href="https://arxiv.org/abs/2108.11832">arxiv:2108.11832</a>
&#x1F4C8; 3 <br>
<p>Damek Davis, Dmitriy Drusvyatskiy, Liwei Jiang</p></summary>
<p>

**Abstract:** Nonsmooth optimization problems arising in practice tend to exhibit beneficial smooth substructure: their domains stratify into "active manifolds" of smooth variation, which common proximal algorithms "identify" in finite time. Identification then entails a transition to smooth dynamics, and accommodates second-order acceleration techniques. While identification is clearly useful algorithmically, empirical evidence suggests that even those algorithms that do not identify the active manifold in finite time -- notably the subgradient method -- are nonetheless affected by it. This work seeks to explain this phenomenon, asking: how do active manifolds impact the subgradient method in nonsmooth optimization?
  In this work, we answer this question by introducing two algorithmically useful properties -- aiming and subgradient approximation -- that fully expose the smooth substructure of the problem. We show that these properties imply that the shadow of the (stochastic) subgradient method along the active manifold is precisely an inexact Riemannian gradient method with an implicit retraction. We prove that these properties hold for a wide class of problems, including cone reducible/decomposable functions and generic semialgebraic problems. Moreover, we develop a thorough calculus, proving such properties are preserved under smooth deformations and spectral lifts. This viewpoint then leads to several algorithmic consequences that parallel results in smooth optimization, despite the nonsmoothness of the problem: local rates of convergence, asymptotic normality, and saddle point avoidance. The asymptotic normality results appear to be new even in the most classical setting of stochastic nonlinear programming. The results culminate in the following observation: the perturbed subgradient method on generic, Clarke regular semialgebraic problems, converges only to local minimizers.

</p>
</details>

<details><summary><b>On the use of test smells for prediction of flaky tests</b>
<a href="https://arxiv.org/abs/2108.11781">arxiv:2108.11781</a>
&#x1F4C8; 3 <br>
<p>B. H. P. Camara, M. A. G. Silva, A. T. Endo, S. R. Vergilio</p></summary>
<p>

**Abstract:** Regression testing is an important phase to deliver software with quality. However, flaky tests hamper the evaluation of test results and can increase costs. This is because a flaky test may pass or fail non-deterministically and to identify properly the flakiness of a test requires rerunning the test suite multiple times. To cope with this challenge, approaches have been proposed based on prediction models and machine learning. Existing approaches based on the use of the test case vocabulary may be context-sensitive and prone to overfitting, presenting low performance when executed in a cross-project scenario. To overcome these limitations, we investigate the use of test smells as predictors of flaky tests. We conducted an empirical study to understand if test smells have good performance as a classifier to predict the flakiness in the cross-project context, and analyzed the information gain of each test smell. We also compared the test smell-based approach with the vocabulary-based one. As a result, we obtained a classifier that had a reasonable performance (Random Forest, 0.83) to predict the flakiness in the testing phase. This classifier presented better performance than vocabulary-based model for cross-project prediction. The Assertion Roulette and Sleepy Test test smell types are the ones associated with the best information gain values.

</p>
</details>

<details><summary><b>Parallelised Diffeomorphic Sampling-based Motion Planning</b>
<a href="https://arxiv.org/abs/2108.11775">arxiv:2108.11775</a>
&#x1F4C8; 3 <br>
<p>Tin Lai, Weiming Zhi, Tucker Hermans, Fabio Ramos</p></summary>
<p>

**Abstract:** We propose Parallelised Diffeomorphic Sampling-based Motion Planning (PDMP). PDMP is a novel parallelised framework that uses bijective and differentiable mappings, or diffeomorphisms, to transform sampling distributions of sampling-based motion planners, in a manner akin to normalising flows. Unlike normalising flow models which use invertible neural network structures to represent these diffeomorphisms, we develop them from gradient information of desired costs, and encode desirable behaviour, such as obstacle avoidance. These transformed sampling distributions can then be used for sampling-based motion planning. A particular example is when we wish to imbue the sampling distribution with knowledge of the environment geometry, such that drawn samples are less prone to be in collisions. To this end, we propose to learn a continuous occupancy representation from environment occupancy data, such that gradients of the representation defines a valid diffeomorphism and is amenable to fast parallel evaluation. We use this to "morph" the sampling distribution to draw far fewer collision-prone samples. PDMP is able to leverage gradient information of costs, to inject specifications, in a manner similar to optimisation-based motion planning methods, but relies on drawing from a sampling distribution, retaining the tendency to find more global solutions, thereby bridging the gap between trajectory optimisation and sampling-based planning methods.

</p>
</details>

<details><summary><b>Byzantine Fault-Tolerance in Federated Local SGD under 2f-Redundancy</b>
<a href="https://arxiv.org/abs/2108.11769">arxiv:2108.11769</a>
&#x1F4C8; 3 <br>
<p>Nirupam Gupta, Thinh T. Doan, Nitin Vaidya</p></summary>
<p>

**Abstract:** We consider the problem of Byzantine fault-tolerance in federated machine learning. In this problem, the system comprises multiple agents each with local data, and a trusted centralized coordinator. In fault-free setting, the agents collaborate with the coordinator to find a minimizer of the aggregate of their local cost functions defined over their local data. We consider a scenario where some agents ($f$ out of $N$) are Byzantine faulty. Such agents need not follow a prescribed algorithm correctly, and may communicate arbitrary incorrect information to the coordinator. In the presence of Byzantine agents, a more reasonable goal for the non-faulty agents is to find a minimizer of the aggregate cost function of only the non-faulty agents. This particular goal is commonly referred as exact fault-tolerance. Recent work has shown that exact fault-tolerance is achievable if only if the non-faulty agents satisfy the property of $2f$-redundancy. Now, under this property, techniques are known to impart exact fault-tolerance to the distributed implementation of the classical stochastic gradient-descent (SGD) algorithm. However, we do not know of any such techniques for the federated local SGD algorithm - a more commonly used method for federated machine learning. To address this issue, we propose a novel technique named comparative elimination (CE). We show that, under $2f$-redundancy, the federated local SGD algorithm with CE can indeed obtain exact fault-tolerance in the deterministic setting when the non-faulty agents can accurately compute gradients of their local cost functions. In the general stochastic case, when agents can only compute unbiased noisy estimates of their local gradients, our algorithm achieves approximate fault-tolerance with approximation error proportional to the variance of stochastic gradients and the fraction of Byzantine agents.

</p>
</details>

<details><summary><b>The Number of Steps Needed for Nonconvex Optimization of a Deep Learning Optimizer is a Rational Function of Batch Size</b>
<a href="https://arxiv.org/abs/2108.11713">arxiv:2108.11713</a>
&#x1F4C8; 3 <br>
<p>Hideaki Iiduka</p></summary>
<p>

**Abstract:** Recently, convergence as well as convergence rate analyses of deep learning optimizers for nonconvex optimization have been widely studied. Meanwhile, numerical evaluations for the optimizers have precisely clarified the relationship between batch size and the number of steps needed for training deep neural networks. The main contribution of this paper is to show theoretically that the number of steps needed for nonconvex optimization of each of the optimizers can be expressed as a rational function of batch size. Having these rational functions leads to two particularly important facts, which were validated numerically in previous studies. The first fact is that there exists an optimal batch size such that the number of steps needed for nonconvex optimization is minimized. This implies that using larger batch sizes than the optimal batch size does not decrease the number of steps needed for nonconvex optimization. The second fact is that the optimal batch size depends on the optimizer. In particular, it is shown theoretically that momentum and Adam-type optimizers can exploit larger optimal batches and further reduce the minimum number of steps needed for nonconvex optimization than can the stochastic gradient descent optimizer.

</p>
</details>

<details><summary><b>Estimation of Riemannian distances between covariance operators and Gaussian processes</b>
<a href="https://arxiv.org/abs/2108.11683">arxiv:2108.11683</a>
&#x1F4C8; 3 <br>
<p>Ha Quang Minh</p></summary>
<p>

**Abstract:** In this work we study two Riemannian distances between infinite-dimensional positive definite Hilbert-Schmidt operators, namely affine-invariant Riemannian and Log-Hilbert-Schmidt distances, in the context of covariance operators associated with functional stochastic processes, in particular Gaussian processes. Our first main results show that both distances converge in the Hilbert-Schmidt norm. Using concentration results for Hilbert space-valued random variables, we then show that both distances can be consistently and efficiently estimated from (i) sample covariance operators, (ii) finite, normalized covariance matrices, and (iii) finite samples generated by the given processes, all with dimension-independent convergence. Our theoretical analysis exploits extensively the methodology of reproducing kernel Hilbert space (RKHS) covariance and cross-covariance operators. The theoretical formulation is illustrated with numerical experiments on covariance operators of Gaussian processes.

</p>
</details>

<details><summary><b>Self-Attention for Audio Super-Resolution</b>
<a href="https://arxiv.org/abs/2108.11637">arxiv:2108.11637</a>
&#x1F4C8; 3 <br>
<p>Nathanaël Carraz Rakotonirina</p></summary>
<p>

**Abstract:** Convolutions operate only locally, thus failing to model global interactions. Self-attention is, however, able to learn representations that capture long-range dependencies in sequences. We propose a network architecture for audio super-resolution that combines convolution and self-attention. Attention-based Feature-Wise Linear Modulation (AFiLM) uses self-attention mechanism instead of recurrent neural networks to modulate the activations of the convolutional model. Extensive experiments show that our model outperforms existing approaches on standard benchmarks. Moreover, it allows for more parallelization resulting in significantly faster training.

</p>
</details>

<details><summary><b>Unsupervised Dense Deformation Embedding Network for Template-Free Shape Correspondence</b>
<a href="https://arxiv.org/abs/2108.11609">arxiv:2108.11609</a>
&#x1F4C8; 3 <br>
<p>Ronghan Chen, Yang Cong, Jiahua Dong</p></summary>
<p>

**Abstract:** Shape correspondence from 3D deformation learning has attracted appealing academy interests recently. Nevertheless, current deep learning based methods require the supervision of dense annotations to learn per-point translations, which severely overparameterize the deformation process. Moreover, they fail to capture local geometric details of original shape via global feature embedding. To address these challenges, we develop a new Unsupervised Dense Deformation Embedding Network (i.e., UD^2E-Net), which learns to predict deformations between non-rigid shapes from dense local features. Since it is non-trivial to match deformation-variant local features for deformation prediction, we develop an Extrinsic-Intrinsic Autoencoder to frst encode extrinsic geometric features from source into intrinsic coordinates in a shared canonical shape, with which the decoder then synthesizes corresponding target features. Moreover, a bounded maximum mean discrepancy loss is developed to mitigate the distribution divergence between the synthesized and original features. To learn natural deformation without dense supervision, we introduce a coarse parameterized deformation graph, for which a novel trace and propagation algorithm is proposed to improve both the quality and effciency of the deformation. Our UD^2E-Net outperforms state-of-the-art unsupervised methods by 24% on Faust Inter challenge and even supervised methods by 13% on Faust Intra challenge.

</p>
</details>

<details><summary><b>Identification of the Resting Position Based on EGG, ECG, Respiration Rate and SpO2 Using Stacked Ensemble Learning</b>
<a href="https://arxiv.org/abs/2108.11604">arxiv:2108.11604</a>
&#x1F4C8; 3 <br>
<p>Md. Mohsin Sarker Raihan, Muhammad Muinul Islam, Fariha Fairoz, Abdullah Bin Shams</p></summary>
<p>

**Abstract:** Rest is essential for a high-level physiological and psychological performance. It is also necessary for the muscles to repair, rebuild, and strengthen. There is a significant correlation between the quality of rest and the resting posture. Therefore, identification of the resting position is of paramount importance to maintain a healthy life. Resting postures can be classified into four basic categories: Lying on the back (supine), facing of the left / right sides and free-fall position. The later position is already considered to be an unhealthy posture by researchers equivocally and hence can be eliminated. In this paper, we analyzed the other three states of resting position based on the data collected from the physiological parameters: Electrogastrogram (EGG), Electrocardiogram (ECG), Respiration Rate, Heart Rate, and Oxygen Saturation (SpO2). Based on these parameters, the resting position is classified using a hybrid stacked ensemble machine learning model designed using the Decision tree, Random Forest, and Xgboost algorithms. Our study demonstrates a 100% accurate prediction of the resting position using the hybrid model. The proposed method of identifying the resting position based on physiological parameters has the potential to be integrated into wearable devices. This is a low cost, highly accurate and autonomous technique to monitor the body posture while maintaining the user privacy by eliminating the use of RGB camera conventionally used to conduct the polysomnography (sleep Monitoring) or resting position studies.

</p>
</details>

<details><summary><b>Online Optimization of Stimulation Speed in an Auditory Brain-Computer Interface under Time Constraints</b>
<a href="https://arxiv.org/abs/2109.06011">arxiv:2109.06011</a>
&#x1F4C8; 2 <br>
<p>Jan Sosulski, David Hübner, Aaron Klein, Michael Tangermann</p></summary>
<p>

**Abstract:** The decoding of brain signals recorded via, e.g., an electroencephalogram, using machine learning is key to brain-computer interfaces (BCIs). Stimulation parameters or other experimental settings of the BCI protocol typically are chosen according to the literature. The decoding performance directly depends on the choice of parameters, as they influence the elicited brain signals and optimal parameters are subject-dependent. Thus a fast and automated selection procedure for experimental parameters could greatly improve the usability of BCIs.
  We evaluate a standalone random search and a combined Bayesian optimization with random search in a closed-loop auditory event-related potential protocol. We aimed at finding the individually best stimulation speed -- also known as stimulus onset asynchrony (SOA) -- that maximizes the classification performance of a regularized linear discriminant analysis. To make the Bayesian optimization feasible under noise and the time pressure posed by an online BCI experiment, we first used offline simulations to initialize and constrain the internal optimization model. Then we evaluated our approach online with 13 healthy subjects.
  We could show that for 8 out of 13 subjects, the proposed approach using Bayesian optimization succeeded to select the individually optimal SOA out of multiple evaluated SOA values. Our data suggests, however, that subjects were influenced to very different degrees by the SOA parameter. This makes the automatic parameter selection infeasible for subjects where the influence is limited.
  Our work proposes an approach to exploit the benefits of individualized experimental protocols and evaluated it in an auditory BCI. When applied to other experimental parameters our approach could enhance the usability of BCI for different target groups -- specifically if an individual disease progress may prevent the use of standard parameters.

</p>
</details>

<details><summary><b>Full Attention Bidirectional Deep Learning Structure for Single Channel Speech Enhancement</b>
<a href="https://arxiv.org/abs/2108.12105">arxiv:2108.12105</a>
&#x1F4C8; 2 <br>
<p>Yuzi Yan, Wei-Qiang Zhang, Michael T. Johnson</p></summary>
<p>

**Abstract:** As the cornerstone of other important technologies, such as speech recognition and speech synthesis, speech enhancement is a critical area in audio signal processing. In this paper, a new deep learning structure for speech enhancement is demonstrated. The model introduces a "full" attention mechanism to a bidirectional sequence-to-sequence method to make use of latent information after each focal frame. This is an extension of the previous attention-based RNN method. The proposed bidirectional attention-based architecture achieves better performance in terms of speech quality (PESQ), compared with OM-LSA, CNN-LSTM, T-GSA and the unidirectional attention-based LSTM baseline.

</p>
</details>

<details><summary><b>Learning to Give Checkable Answers with Prover-Verifier Games</b>
<a href="https://arxiv.org/abs/2108.12099">arxiv:2108.12099</a>
&#x1F4C8; 2 <br>
<p>Cem Anil, Guodong Zhang, Yuhuai Wu, Roger Grosse</p></summary>
<p>

**Abstract:** Our ability to know when to trust the decisions made by machine learning systems has not kept up with the staggering improvements in their performance, limiting their applicability in high-stakes domains. We introduce Prover-Verifier Games (PVGs), a game-theoretic framework to encourage learning agents to solve decision problems in a verifiable manner. The PVG consists of two learners with competing objectives: a trusted verifier network tries to choose the correct answer, and a more powerful but untrusted prover network attempts to persuade the verifier of a particular answer, regardless of its correctness. The goal is for a reliable justification protocol to emerge from this game. We analyze variants of the framework, including simultaneous and sequential games, and narrow the space down to a subset of games which provably have the desired equilibria. We develop instantiations of the PVG for two algorithmic tasks, and show that in practice, the verifier learns a robust decision rule that is able to receive useful and reliable information from an untrusted prover. Importantly, the protocol still works even when the verifier is frozen and the prover's messages are directly optimized to convince the verifier.

</p>
</details>

<details><summary><b>Deep Denoising Method for Side Scan Sonar Images without High-quality Reference Data</b>
<a href="https://arxiv.org/abs/2108.12083">arxiv:2108.12083</a>
&#x1F4C8; 2 <br>
<p>Xiaoteng Zhou, Changli Yu, Xin Yuan, Citong Luo</p></summary>
<p>

**Abstract:** Subsea images measured by the side scan sonars (SSSs) are necessary visual data in the process of deep-sea exploration by using the autonomous underwater vehicles (AUVs). They could vividly reflect the topography of the seabed, but usually accompanied by complex and severe noise. This paper proposes a deep denoising method for SSS images without high-quality reference data, which uses one single noise SSS image to perform self-supervised denoising. Compared with the classical artificially designed filters, the deep denoising method shows obvious advantages. The denoising experiments are performed on the real seabed SSS images, and the results demonstrate that our proposed method could effectively reduce the noise on the SSS image while minimizing the image quality and detail loss.

</p>
</details>

<details><summary><b>Semantic-Based Self-Critical Training For Question Generation</b>
<a href="https://arxiv.org/abs/2108.12026">arxiv:2108.12026</a>
&#x1F4C8; 2 <br>
<p> Loïc, Kwate Dassi</p></summary>
<p>

**Abstract:** Question generation is a conditioned language generation task that consists in generating a context-aware question given a context and the targeted answer. Train language modelling with a mere likelihood maximization has been widely used while suffering from exposure bias and the discordance between the training and the test metrics. In the way of addressing this issue, The presented work portrays a fully Transformer-based reinforcement learning generator-evaluation architecture for neural question generation. To edge the flexibility of the generation, a semantic-based reward score was externally infused during the training to drive the training of the language model. The global architecture is laid out in a generator-evaluator fashion optimized directly to n-gram and semantic-based metrics. Evaluation metrics for language modelling only based on n-gram overlapping do not consider semantic relations between reference and candidate sequences. To improve the evaluation step, a two-fold evaluation was carried out. On the one side, an n-gram overlapping evaluation using the BLEU score. On the other side, a semantic-based assessment using BERTScore and NUBIA. The results were corroborated by a binary human evaluation of the semantic relatedness of the generated question and the ground truth. The results obtained showed that use a semantic-based REINFORCE algorithm for the question generation syntactically reshapes the generated questions while preserving their underlying semantic meaning. Many downstream applications can be drawn from a successful question generation including the enlargement of question answering datasets, the improvement of conversational systems, the enhancement of autonomous educational assessment systems, and so forth.

</p>
</details>

<details><summary><b>Understanding the Logit Distributions of Adversarially-Trained Deep Neural Networks</b>
<a href="https://arxiv.org/abs/2108.12001">arxiv:2108.12001</a>
&#x1F4C8; 2 <br>
<p>Landan Seguin, Anthony Ndirango, Neeli Mishra, SueYeon Chung, Tyler Lee</p></summary>
<p>

**Abstract:** Adversarial defenses train deep neural networks to be invariant to the input perturbations from adversarial attacks. Almost all defense strategies achieve this invariance through adversarial training i.e. training on inputs with adversarial perturbations. Although adversarial training is successful at mitigating adversarial attacks, the behavioral differences between adversarially-trained (AT) models and standard models are still poorly understood. Motivated by a recent study on learning robustness without input perturbations by distilling an AT model, we explore what is learned during adversarial training by analyzing the distribution of logits in AT models. We identify three logit characteristics essential to learning adversarial robustness. First, we provide a theoretical justification for the finding that adversarial training shrinks two important characteristics of the logit distribution: the max logit values and the "logit gaps" (difference between the logit max and next largest values) are on average lower for AT models. Second, we show that AT and standard models differ significantly on which samples are high or low confidence, then illustrate clear qualitative differences by visualizing samples with the largest confidence difference. Finally, we find learning information about incorrect classes to be essential to learning robustness by manipulating the non-max logit information during distillation and measuring the impact on the student's robustness. Our results indicate that learning some adversarial robustness without input perturbations requires a model to learn specific sample-wise confidences and incorrect class orderings that follow complex distributions.

</p>
</details>

<details><summary><b>A New Sentence Ordering Method Using BERT Pretrained Model</b>
<a href="https://arxiv.org/abs/2108.11994">arxiv:2108.11994</a>
&#x1F4C8; 2 <br>
<p>Melika Golestani, Seyedeh Zahra Razavi, Heshaam Faili</p></summary>
<p>

**Abstract:** Building systems with capability of natural language understanding (NLU) has been one of the oldest areas of AI. An essential component of NLU is to detect logical succession of events contained in a text. The task of sentence ordering is proposed to learn succession of events with applications in AI tasks. The performance of previous works employing statistical methods is poor, while the neural networks-based approaches are in serious need of large corpora for model learning. In this paper, we propose a method for sentence ordering which does not need a training phase and consequently a large corpus for learning. To this end, we generate sentence embedding using BERT pre-trained model and measure sentence similarity using cosine similarity score. We suggest this score as an indicator of sequential events' level of coherence. We finally sort the sentences through brute-force search to maximize overall similarities of the sequenced sentences. Our proposed method outperformed other baselines on ROCStories, a corpus of 5-sentence human-made stories. The method is specifically more efficient than neural network-based methods when no huge corpus is available. Among other advantages of this method are its interpretability and needlessness to linguistic knowledge.

</p>
</details>

<details><summary><b>Human operator cognitive availability aware Mixed-Initiative control</b>
<a href="https://arxiv.org/abs/2108.11885">arxiv:2108.11885</a>
&#x1F4C8; 2 <br>
<p>Giannis Petousakis, Manolis Chiou, Grigoris Nikolaou, Rustam Stolkin</p></summary>
<p>

**Abstract:** This paper presents a Cognitive Availability Aware Mixed-Initiative Controller for remotely operated mobile robots. The controller enables dynamic switching between different levels of autonomy (LOA), initiated by either the AI or the human operator. The controller leverages a state-of-the-art computer vision method and an off-the-shelf web camera to infer the cognitive availability of the operator and inform the AI-initiated LOA switching. This constitutes a qualitative advancement over previous Mixed-Initiative (MI) controllers. The controller is evaluated in a disaster response experiment, in which human operators have to conduct an exploration task with a remote robot. MI systems are shown to effectively assist the operators, as demonstrated by quantitative and qualitative results in performance and workload. Additionally, some insights into the experimental difficulties of evaluating complex MI controllers are presented.

</p>
</details>

<details><summary><b>Magnetic Field Sensing for Pedestrian and Robot Indoor Positioning</b>
<a href="https://arxiv.org/abs/2108.11824">arxiv:2108.11824</a>
&#x1F4C8; 2 <br>
<p>Leonid Antsfeld, Boris Chidlovskii</p></summary>
<p>

**Abstract:** In this paper we address the problem of indoor localization using magnetic field data in two setups, when data is collected by (i) human-held mobile phone and (ii) by localization robots that perturb magnetic data with their own electromagnetic field. For the first setup, we revise the state of the art approaches and propose a novel extended pipeline to benefit from the presence of magnetic anomalies in indoor environment created by different ferromagnetic objects. We capture changes of the Earth's magnetic field due to indoor magnetic anomalies and transform them in multi-variate times series. We then convert temporal patterns into visual ones. We use methods of Recurrence Plots, Gramian Angular Fields and Markov Transition Fields to represent magnetic field time series as image sequences. We regress the continuous values of user position in a deep neural network that combines convolutional and recurrent layers. For the second setup, we analyze how magnetic field data get perturbed by robots' electromagnetic field. We add an alignment step to the main pipeline, in order to compensate the mismatch between train and test sets obtained by different robots. We test our methods on two public (MagPie and IPIN'20) and one proprietary (Hyundai department store) datasets. We report evaluation results and show that our methods outperform the state of the art methods by a large margin.

</p>
</details>

<details><summary><b>PAENet: A Progressive Attention-Enhanced Network for 3D to 2D Retinal Vessel Segmentation</b>
<a href="https://arxiv.org/abs/2108.11695">arxiv:2108.11695</a>
&#x1F4C8; 2 <br>
<p>Zhuojie Wu, Zijian Wang, Wenxuan Zou, Fan Ji, Hao Dang, Wanting Zhou, Muyi Sun</p></summary>
<p>

**Abstract:** 3D to 2D retinal vessel segmentation is a challenging problem in Optical Coherence Tomography Angiography (OCTA) images. Accurate retinal vessel segmentation is important for the diagnosis and prevention of ophthalmic diseases. However, making full use of the 3D data of OCTA volumes is a vital factor for obtaining satisfactory segmentation results. In this paper, we propose a Progressive Attention-Enhanced Network (PAENet) based on attention mechanisms to extract rich feature representation. Specifically, the framework consists of two main parts, the three-dimensional feature learning path and the two-dimensional segmentation path. In the three-dimensional feature learning path, we design a novel Adaptive Pooling Module (APM) and propose a new Quadruple Attention Module (QAM). The APM captures dependencies along the projection direction of volumes and learns a series of pooling coefficients for feature fusion, which efficiently reduces feature dimension. In addition, the QAM reweights the features by capturing four-group cross-dimension dependencies, which makes maximum use of 4D feature tensors. In the two-dimensional segmentation path, to acquire more detailed information, we propose a Feature Fusion Module (FFM) to inject 3D information into the 2D path. Meanwhile, we adopt the Polarized Self-Attention (PSA) block to model the semantic interdependencies in spatial and channel dimensions respectively. Experimentally, our extensive experiments on the OCTA-500 dataset show that our proposed algorithm achieves state-of-the-art performance compared with previous methods.

</p>
</details>

<details><summary><b>Web Image Context Extraction with Graph Neural Networks and Sentence Embeddings on the DOM tree</b>
<a href="https://arxiv.org/abs/2108.11629">arxiv:2108.11629</a>
&#x1F4C8; 2 <br>
<p>Chen Dang, Hicham Randrianarivo, Raphaël Fournier-S'Niehotta, Nicolas Audebert</p></summary>
<p>

**Abstract:** Web Image Context Extraction (WICE) consists in obtaining the textual information describing an image using the content of the surrounding webpage. A common preprocessing step before performing WICE is to render the content of the webpage. When done at a large scale (e.g., for search engine indexation), it may become very computationally costly (up to several seconds per page). To avoid this cost, we introduce a novel WICE approach that combines Graph Neural Networks (GNNs) and Natural Language Processing models. Our method relies on a graph model containing both node types and text as features. The model is fed through several blocks of GNNs to extract the textual context. Since no labeled WICE dataset with ground truth exists, we train and evaluate the GNNs on a proxy task that consists in finding the semantically closest text to the image caption. We then interpret importance weights to find the most relevant text nodes and define them as the image context. Thanks to GNNs, our model is able to encode both structural and semantic information from the webpage. We show that our approach gives promising results to help address the large-scale WICE problem using only HTML data.

</p>
</details>

<details><summary><b>Photos Are All You Need for Reciprocal Recommendation in Online Dating</b>
<a href="https://arxiv.org/abs/2108.11714">arxiv:2108.11714</a>
&#x1F4C8; 1 <br>
<p>James Neve, Ryan McConville</p></summary>
<p>

**Abstract:** Recommender Systems are algorithms that predict a user's preference for an item. Reciprocal Recommenders are a subset of recommender systems, where the items in question are people, and the objective is therefore to predict a bidirectional preference relation. They are used in settings such as online dating services and social networks. In particular, images provided by users are a crucial part of user preference, and one that is not exploited much in the literature. We present a novel method of interpreting user image preference history and using this to make recommendations. We train a recurrent neural network to learn a user's preferences and make predictions of reciprocal preference relations that can be used to make recommendations that satisfy both users. We show that our proposed system achieves an F1 score of 0.87 when using only photographs to produce reciprocal recommendations on a large real world online dating dataset. Our system significantly outperforms on the state of the art in both content-based and collaborative filtering systems.

</p>
</details>

<details><summary><b>Disentangled generative models for robust dynamical system prediction</b>
<a href="https://arxiv.org/abs/2108.11684">arxiv:2108.11684</a>
&#x1F4C8; 1 <br>
<p>Stathi Fotiadis, Shunlong Hu, Mario Lino, Chris Cantwell, Anil Bharath</p></summary>
<p>

**Abstract:** Deep neural networks have become increasingly of interest in dynamical system prediction, but out-of-distribution generalization and long-term stability still remains challenging. In this work, we treat the domain parameters of dynamical systems as factors of variation of the data generating process. By leveraging ideas from supervised disentanglement and causal factorization, we aim to separate the domain parameters from the dynamics in the latent space of generative models. In our experiments we model dynamics both in phase space and in video sequences and conduct rigorous OOD evaluations. Results indicate that disentangled VAEs adapt better to domain parameters spaces that were not present in the training data. At the same time, disentanglement can improve the long-term and out-of-distribution predictions of state-of-the-art models in video sequences.

</p>
</details>

<details><summary><b>PTRAIL -- A python package for parallel trajectory data preprocessing</b>
<a href="https://arxiv.org/abs/2108.13202">arxiv:2108.13202</a>
&#x1F4C8; 0 <br>
<p>Salman Haidri, Yaksh J. Haranwala, Vania Bogorny, Chiara Renso, Vinicius Prado da Fonseca, Amilcar Soares</p></summary>
<p>

**Abstract:** Trajectory data represent a trace of an object that changes its position in space over time. This kind of data is complex to handle and analyze, since it is generally produced in huge quantities, often prone to errors generated by the geolocation device, human mishandling, or area coverage limitation. Therefore, there is a need for software specifically tailored to preprocess trajectory data. In this work we propose PTRAIL, a python package offering several trajectory preprocessing steps, including filtering, feature extraction, and interpolation. PTRAIL uses parallel computation and vectorization, being suitable for large datasets and fast compared to other python libraries.

</p>
</details>

<details><summary><b>Gene Transformer: Transformers for the Gene Expression-based Classification of Lung Cancer Subtypes</b>
<a href="https://arxiv.org/abs/2108.11833">arxiv:2108.11833</a>
&#x1F4C8; 0 <br>
<p>Anwar Khan, Boreom Lee</p></summary>
<p>

**Abstract:** Adenocarcinoma and squamous cell carcinoma constitute approximately 40% and 30% of all lung cancer subtypes, respectively, and display broad heterogeneity in terms of clinical and molecular responses to therapy. Molecular subtyping has enabled precision medicine to overcome these challenges and provide significant biological insights to predict prognosis and improve clinical decision making. Over the past decade, conventional ML algorithms and DL-based CNNs have been espoused for the classification of cancer subtypes from gene expression datasets. However, these methods are potentially biased toward identification of cancer biomarkers. Recently proposed transformer-based architectures that leverage the self-attention mechanism encode high throughput gene expressions and learn representations that are computationally complex and parametrically expensive. However, compared to the datasets for natural language processing applications, gene expression consists of several hundreds of thousands of genes from a limited number of observations, making it difficult to efficiently train transformers for bioinformatics applications. Hence, we propose an end-to-end deep learning approach, Gene Transformer, which addresses the complexity of high-dimensional gene expression with a multi-head self-attention module by identifying relevant biomarkers across multiple cancer subtypes without requiring feature selection as a prerequisite for the current classification algorithms. The proposed architecture achieved an overall improved performance for all evaluation metrics and had fewer misclassification errors than the commonly used traditional classification algorithms. The classification results show that Gene Transformer can be an efficient approach for classifying cancer subtypes, indicating that any improvement in deep learning models in computational biology can also be reflected well in this domain.

</p>
</details>

<details><summary><b>Efficient Out-of-Distribution Detection Using Latent Space of $β$-VAE for Cyber-Physical Systems</b>
<a href="https://arxiv.org/abs/2108.11800">arxiv:2108.11800</a>
&#x1F4C8; 0 <br>
<p>Shreyas Ramakrishna, Zahra Rahiminasab, Gabor Karsai, Arvind Easwaran, Abhishek Dubey</p></summary>
<p>

**Abstract:** Deep Neural Networks are actively being used in the design of autonomous Cyber-Physical Systems (CPSs). The advantage of these models is their ability to handle high-dimensional state-space and learn compact surrogate representations of the operational state spaces. However, the problem is that the sampled observations used for training the model may never cover the entire state space of the physical environment, and as a result, the system will likely operate in conditions that do not belong to the training distribution. These conditions that do not belong to training distribution are referred to as Out-of-Distribution (OOD). Detecting OOD conditions at runtime is critical for the safety of CPS. In addition, it is also desirable to identify the context or the feature(s) that are the source of OOD to select an appropriate control action to mitigate the consequences that may arise because of the OOD condition. In this paper, we study this problem as a multi-labeled time series OOD detection problem over images, where the OOD is defined both sequentially across short time windows (change points) as well as across the training data distribution. A common approach to solving this problem is the use of multi-chained one-class classifiers. However, this approach is expensive for CPSs that have limited computational resources and require short inference times. Our contribution is an approach to design and train a single $β$-Variational Autoencoder detector with a partially disentangled latent space sensitive to variations in image features. We use the feature sensitive latent variables in the latent space to detect OOD images and identify the most likely feature(s) responsible for the OOD. We demonstrate our approach using an Autonomous Vehicle in the CARLA simulator and a real-world automotive dataset called nuImages.

</p>
</details>


[Next Page]({{ '/2021/08/25/2021.08.25.html' | relative_url }})
