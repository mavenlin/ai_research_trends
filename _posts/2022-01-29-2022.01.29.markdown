Prev: [2022.01.28]({{ '/2022/01/28/2022.01.28.html' | relative_url }})  Next: [2022.01.30]({{ '/2022/01/30/2022.01.30.html' | relative_url }})
{% raw %}
## Summary for 2022-01-29, created on 2022-02-08


<details><summary><b>Deep Contrastive Learning is Provably (almost) Principal Component Analysis</b>
<a href="https://arxiv.org/abs/2201.12680">arxiv:2201.12680</a>
&#x1F4C8; 36 <br>
<p>Yuandong Tian</p></summary>
<p>

**Abstract:** We show that Contrastive Learning (CL) under a family of loss functions (including InfoNCE) has a game-theoretical formulation, where the \emph{max player} finds representation to maximize contrastiveness, and the \emph{min player} puts weights on pairs of samples with similar representation. We show that the max player who does \emph{representation learning} reduces to Principal Component Analysis for deep linear network, and almost all local minima are global, recovering optimal PCA solutions. Experiments show that the formulation yields comparable (or better) performance on CIFAR10 and STL-10 when extending beyond InfoNCE, yielding novel contrastive losses. Furthermore, we extend our theoretical analysis to 2-layer ReLU networks, showing its difference from linear ones, and proving that feature composition is preferred over picking single dominant feature under strong augmentation.

</p>
</details>

<details><summary><b>Learning Fast, Learning Slow: A General Continual Learning Method based on Complementary Learning System</b>
<a href="https://arxiv.org/abs/2201.12604">arxiv:2201.12604</a>
&#x1F4C8; 22 <br>
<p>Elahe Arani, Fahad Sarfraz, Bahram Zonooz</p></summary>
<p>

**Abstract:** Humans excel at continually learning from an ever-changing environment whereas it remains a challenge for deep neural networks which exhibit catastrophic forgetting. The complementary learning system (CLS) theory suggests that the interplay between rapid instance-based learning and slow structured learning in the brain is crucial for accumulating and retaining knowledge. Here, we propose CLS-ER, a novel dual memory experience replay (ER) method which maintains short-term and long-term semantic memories that interact with the episodic memory. Our method employs an effective replay mechanism whereby new knowledge is acquired while aligning the decision boundaries with the semantic memories. CLS-ER does not utilize the task boundaries or make any assumption about the distribution of the data which makes it versatile and suited for "general continual learning". Our approach achieves state-of-the-art performance on standard benchmarks as well as more realistic general continual learning settings.

</p>
</details>

<details><summary><b>Error Rates for Kernel Classification under Source and Capacity Conditions</b>
<a href="https://arxiv.org/abs/2201.12655">arxiv:2201.12655</a>
&#x1F4C8; 11 <br>
<p>Hugo Cui, Bruno Loureiro, Florent Krzakala, Lenka Zdeborová</p></summary>
<p>

**Abstract:** In this manuscript, we consider the problem of kernel classification under the Gaussian data design, and under source and capacity assumptions on the dataset. While the decay rates of the prediction error have been extensively studied under much more generic assumptions for kernel ridge regression, deriving decay rates for the classification problem has been hitherto considered a much more challenging task. In this work we leverage recent analytical results for learning curves of linear classification with generic loss function to derive the rates of decay of the misclassification (prediction) error with the sample complexity for two standard classification settings, namely margin-maximizing Support Vector Machines (SVM) and ridge classification. Using numerical and analytical arguments, we derive the error rates as a function of the source and capacity coefficients, and contrast the two methods.

</p>
</details>

<details><summary><b>Fair ranking: a critical review, challenges, and future directions</b>
<a href="https://arxiv.org/abs/2201.12662">arxiv:2201.12662</a>
&#x1F4C8; 9 <br>
<p>Gourab K Patro, Lorenzo Porcaro, Laura Mitchell, Qiuyue Zhang, Meike Zehlike, Nikhil Garg</p></summary>
<p>

**Abstract:** Ranking, recommendation, and retrieval systems are widely used in online platforms and other societal systems, including e-commerce, media-streaming, admissions, gig platforms, and hiring. In the recent past, a large "fair ranking" research literature has been developed around making these systems fair to the individuals, providers, or content that are being ranked. Most of this literature defines fairness for a single instance of retrieval, or as a simple additive notion for multiple instances of retrievals over time. This work provides a critical overview of this literature, detailing the often context-specific concerns that such an approach misses: the gap between high ranking placements and true provider utility, spillovers and compounding effects over time, induced strategic incentives, and the effect of statistical uncertainty. We then provide a path forward for a more holistic and impact-oriented fair ranking research agenda, including methodological lessons from other fields and the role of the broader stakeholder community in overcoming data bottlenecks and designing effective regulatory environments.

</p>
</details>

<details><summary><b>Incorporating Commonsense Knowledge into Story Ending Generation via Heterogeneous Graph Networks</b>
<a href="https://arxiv.org/abs/2201.12538">arxiv:2201.12538</a>
&#x1F4C8; 9 <br>
<p>Jiaan Wang, Beiqi Zou, Zhixu Li, Jianfeng Qu, Pengpeng Zhao, An Liu, Lei Zhao</p></summary>
<p>

**Abstract:** Story ending generation is an interesting and challenging task, which aims to generate a coherent and reasonable ending given a story context. The key challenges of the task lie in how to comprehend the story context sufficiently and handle the implicit knowledge behind story clues effectively, which are still under-explored by previous work. In this paper, we propose a Story Heterogeneous Graph Network (SHGN) to explicitly model both the information of story context at different granularity levels and the multi-grained interactive relations among them. In detail, we consider commonsense knowledge, words and sentences as three types of nodes. To aggregate non-local information, a global node is also introduced. Given this heterogeneous graph network, the node representations are updated through graph propagation, which adequately utilizes commonsense knowledge to facilitate story comprehension. Moreover, we design two auxiliary tasks to implicitly capture the sentiment trend and key events lie in the context. The auxiliary tasks are jointly optimized with the primary story ending generation task in a multi-task learning strategy. Extensive experiments on the ROCStories Corpus show that the developed model achieves new state-of-the-art performances. Human study further demonstrates that our model generates more reasonable story endings.

</p>
</details>

<details><summary><b>Stochastic Neural Networks with Infinite Width are Deterministic</b>
<a href="https://arxiv.org/abs/2201.12724">arxiv:2201.12724</a>
&#x1F4C8; 8 <br>
<p>Liu Ziyin, Hanlin Zhang, Xiangming Meng, Yuting Lu, Eric Xing, Masahito Ueda</p></summary>
<p>

**Abstract:** This work theoretically studies stochastic neural networks, a main type of neural network in use. Specifically, we prove that as the width of an optimized stochastic neural network tends to infinity, its predictive variance on the training set decreases to zero. Two common examples that our theory applies to are neural networks with dropout and variational autoencoders. Our result helps better understand how stochasticity affects the learning of neural networks and thus design better architectures for practical problems.

</p>
</details>

<details><summary><b>Win the Lottery Ticket via Fourier Analysis: Frequencies Guided Network Pruning</b>
<a href="https://arxiv.org/abs/2201.12712">arxiv:2201.12712</a>
&#x1F4C8; 6 <br>
<p>Yuzhang Shang, Bin Duan, Ziliang Zong, Liqiang Nie, Yan Yan</p></summary>
<p>

**Abstract:** With the remarkable success of deep learning recently, efficient network compression algorithms are urgently demanded for releasing the potential computational power of edge devices, such as smartphones or tablets. However, optimal network pruning is a non-trivial task which mathematically is an NP-hard problem. Previous researchers explain training a pruned network as buying a lottery ticket. In this paper, we investigate the Magnitude-Based Pruning (MBP) scheme and analyze it from a novel perspective through Fourier analysis on the deep learning model to guide model designation. Besides explaining the generalization ability of MBP using Fourier transform, we also propose a novel two-stage pruning approach, where one stage is to obtain the topological structure of the pruned network and the other stage is to retrain the pruned network to recover the capacity using knowledge distillation from lower to higher on the frequency domain. Extensive experiments on CIFAR-10 and CIFAR-100 demonstrate the superiority of our novel Fourier analysis based MBP compared to other traditional MBP algorithms.

</p>
</details>

<details><summary><b>Hand Gesture Recognition of Dumb Person Using one Against All Neural Network</b>
<a href="https://arxiv.org/abs/2201.12622">arxiv:2201.12622</a>
&#x1F4C8; 5 <br>
<p>Muhammad Asim Khan, Lan Hong, Sajjad Ahmed</p></summary>
<p>

**Abstract:** We propose a new technique for recognition of dumb person hand gesture in real world environment. In this technique, the hand image containing the gesture is preprocessed and then hand region is segmented by convergent the RGB color image to L.a.b color space. Only few statistical features are used to classify the segmented image to different classes. Artificial Neural Network is trained in sequential manner using one against all. When the system gets trained, it becomes capable of recognition of each class in parallel manner. The result of proposed technique is much better than existing techniques.

</p>
</details>

<details><summary><b>The KFIoU Loss for Rotated Object Detection</b>
<a href="https://arxiv.org/abs/2201.12558">arxiv:2201.12558</a>
&#x1F4C8; 5 <br>
<p>Xue Yang, Yue Zhou, Gefan Zhang, Jirui Yang, Wentao Wang, Junchi Yan, Xiaopeng Zhang, Qi Tian</p></summary>
<p>

**Abstract:** Differing from the well-developed horizontal object detection area whereby the computing-friendly IoU based loss is readily adopted and well fits with the detection metrics. In contrast, rotation detectors often involve a more complicated loss based on SkewIoU which is unfriendly to gradient-based training. In this paper, we argue that one effective alternative is to devise an approximate loss who can achieve trend-level alignment with SkewIoU loss instead of the strict value-level identity. Specifically, we model the objects as Gaussian distribution and adopt Kalman filter to inherently mimic the mechanism of SkewIoU by its definition, and show its alignment with the SkewIoU at trend-level. This is in contrast to recent Gaussian modeling based rotation detectors e.g. GWD, KLD that involves a human-specified distribution distance metric which requires additional hyperparameter tuning. The resulting new loss called KFIoU is easier to implement and works better compared with exact SkewIoU, thanks to its full differentiability and ability to handle the non-overlapping cases. We further extend our technique to the 3-D case which also suffers from the same issues as 2-D detection. Extensive results on various public datasets (2-D/3-D, aerial/text/face images) with different base detectors show the effectiveness of our approach.

</p>
</details>

<details><summary><b>BREAK: Bronchi Reconstruction by gEodesic transformation And sKeleton embedding</b>
<a href="https://arxiv.org/abs/2202.00002">arxiv:2202.00002</a>
&#x1F4C8; 4 <br>
<p>Weihao Yu, Hao Zheng, Minghui Zhang, Hanxiao Zhang, Jiayuan Sun, Jie Yang</p></summary>
<p>

**Abstract:** Airway segmentation is critical for virtual bronchoscopy and computer-aided pulmonary disease analysis. In recent years, convolutional neural networks (CNNs) have been widely used to delineate the bronchial tree. However, the segmentation results of the CNN-based methods usually include many discontinuous branches, which need manual repair in clinical use. A major reason for the breakages is that the appearance of the airway wall can be affected by the lung disease as well as the adjacency of the vessels, while the network tends to overfit to these special patterns in the training set. To learn robust features for these areas, we design a multi-branch framework that adopts the geodesic distance transform to capture the intensity changes between airway lumen and wall. Another reason for the breakages is the intra-class imbalance. Since the volume of the peripheral bronchi may be much smaller than the large branches in an input patch, the common segmentation loss is not sensitive to the breakages among the distal branches. Therefore, in this paper, a breakage-sensitive regularization term is designed and can be easily combined with other loss functions. Extensive experiments are conducted on publicly available datasets. Compared with state-of-the-art methods, our framework can detect more branches while maintaining competitive segmentation performance.

</p>
</details>

<details><summary><b>Geometry- and Accuracy-Preserving Random Forest Proximities</b>
<a href="https://arxiv.org/abs/2201.12682">arxiv:2201.12682</a>
&#x1F4C8; 4 <br>
<p>Jake S. Rhodes, Adele Cutler, Kevin R. Moon</p></summary>
<p>

**Abstract:** Random forests are considered one of the best out-of-the-box classification and regression algorithms due to their high level of predictive performance with relatively little tuning. Pairwise proximities can be computed from a trained random forest which measure the similarity between data points relative to the supervised task. Random forest proximities have been used in many applications including the identification of variable importance, data imputation, outlier detection, and data visualization. However, existing definitions of random forest proximities do not accurately reflect the data geometry learned by the random forest. In this paper, we introduce a novel definition of random forest proximities called Random Forest-Geometry- and Accuracy-Preserving proximities (RF-GAP). We prove that the proximity-weighted sum (regression) or majority vote (classification) using RF-GAP exactly match the out-of-bag random forest prediction, thus capturing the data geometry learned by the random forest. We empirically show that this improved geometric representation outperforms traditional random forest proximities in tasks such as data imputation and provides outlier detection and visualization results consistent with the learned data geometry.

</p>
</details>

<details><summary><b>Distributed SLIDE: Enabling Training Large Neural Networks on Low Bandwidth and Simple CPU-Clusters via Model Parallelism and Sparsity</b>
<a href="https://arxiv.org/abs/2201.12667">arxiv:2201.12667</a>
&#x1F4C8; 4 <br>
<p>Minghao Yan, Nicholas Meisburger, Tharun Medini, Anshumali Shrivastava</p></summary>
<p>

**Abstract:** More than 70% of cloud computing is paid for but sits idle. A large fraction of these idle compute are cheap CPUs with few cores that are not utilized during the less busy hours. This paper aims to enable those CPU cycles to train heavyweight AI models. Our goal is against mainstream frameworks, which focus on leveraging expensive specialized ultra-high bandwidth interconnect to address the communication bottleneck in distributed neural network training. This paper presents a distributed model-parallel training framework that enables training large neural networks on small CPU clusters with low Internet bandwidth. We build upon the adaptive sparse training framework introduced by the SLIDE algorithm. By carefully deploying sparsity over distributed nodes, we demonstrate several orders of magnitude faster model parallel training than Horovod, the main engine behind most commercial software. We show that with reduced communication, due to sparsity, we can train close to a billion parameter model on simple 4-16 core CPU nodes connected by basic low bandwidth interconnect. Moreover, the training time is at par with some of the best hardware accelerators.

</p>
</details>

<details><summary><b>A Deep CNN Architecture with Novel Pooling Layer Applied to Two Sudanese Arabic Sentiment Datasets</b>
<a href="https://arxiv.org/abs/2201.12664">arxiv:2201.12664</a>
&#x1F4C8; 4 <br>
<p>Mustafa Mhamed, Richard Sutcliffe, Xia Sun, Jun Feng, Eiad Almekhlafi, Ephrem A. Retta</p></summary>
<p>

**Abstract:** Arabic sentiment analysis has become an important research field in recent years. Initially, work focused on Modern Standard Arabic (MSA), which is the most widely-used form. Since then, work has been carried out on several different dialects, including Egyptian, Levantine and Moroccan. Moreover, a number of datasets have been created to support such work. However, up until now, less work has been carried out on Sudanese Arabic, a dialect which has 32 million speakers. In this paper, two new publicly available datasets are introduced, the 2-Class Sudanese Sentiment Dataset (SudSenti2) and the 3-Class Sudanese Sentiment Dataset (SudSenti3). Furthermore, a CNN architecture, SCM, is proposed, comprising five CNN layers together with a novel pooling layer, MMA, to extract the best features. This SCM+MMA model is applied to SudSenti2 and SudSenti3 with accuracies of 92.75% and 84.39%. Next, the model is compared to other deep learning classifiers and shown to be superior on these new datasets. Finally, the proposed model is applied to the existing Saudi Sentiment Dataset and to the MSA Hotel Arabic Review Dataset with accuracies 85.55% and 90.01%.

</p>
</details>

<details><summary><b>Robust Imitation Learning from Corrupted Demonstrations</b>
<a href="https://arxiv.org/abs/2201.12594">arxiv:2201.12594</a>
&#x1F4C8; 4 <br>
<p>Liu Liu, Ziyang Tang, Lanqing Li, Dijun Luo</p></summary>
<p>

**Abstract:** We consider offline Imitation Learning from corrupted demonstrations where a constant fraction of data can be noise or even arbitrary outliers. Classical approaches such as Behavior Cloning assumes that demonstrations are collected by an presumably optimal expert, hence may fail drastically when learning from corrupted demonstrations. We propose a novel robust algorithm by minimizing a Median-of-Means (MOM) objective which guarantees the accurate estimation of policy, even in the presence of constant fraction of outliers. Our theoretical analysis shows that our robust method in the corrupted setting enjoys nearly the same error scaling and sample complexity guarantees as the classical Behavior Cloning in the expert demonstration setting. Our experiments on continuous-control benchmarks validate that our method exhibits the predicted robustness and effectiveness, and achieves competitive results compared to existing imitation learning methods.

</p>
</details>

<details><summary><b>Continual Learning with Recursive Gradient Optimization</b>
<a href="https://arxiv.org/abs/2201.12522">arxiv:2201.12522</a>
&#x1F4C8; 4 <br>
<p>Hao Liu, Huaping Liu</p></summary>
<p>

**Abstract:** Learning multiple tasks sequentially without forgetting previous knowledge, called Continual Learning(CL), remains a long-standing challenge for neural networks. Most existing methods rely on additional network capacity or data replay. In contrast, we introduce a novel approach which we refer to as Recursive Gradient Optimization(RGO). RGO is composed of an iteratively updated optimizer that modifies the gradient to minimize forgetting without data replay and a virtual Feature Encoding Layer(FEL) that represents different long-term structures with only task descriptors. Experiments demonstrate that RGO has significantly better performance on popular continual classification benchmarks when compared to the baselines and achieves new state-of-the-art performance on 20-split-CIFAR100(82.22%) and 20-split-miniImageNet(72.63%). With higher average accuracy than Single-Task Learning(STL), this method is flexible and reliable to provide continual learning capabilities for learning models that rely on gradient descent.

</p>
</details>

<details><summary><b>You Only Demonstrate Once: Category-Level Manipulation from Single Visual Demonstration</b>
<a href="https://arxiv.org/abs/2201.12716">arxiv:2201.12716</a>
&#x1F4C8; 3 <br>
<p>Bowen Wen, Wenzhao Lian, Kostas Bekris, Stefan Schaal</p></summary>
<p>

**Abstract:** Promising results have been achieved recently in category-level manipulation that generalizes across object instances. Nevertheless, it often requires expensive real-world data collection and manual specification of semantic keypoints for each object category and task. Additionally, coarse keypoint predictions and ignoring intermediate action sequences hinder adoption in complex manipulation tasks beyond pick-and-place. This work proposes a novel, category-level manipulation framework that leverages an object-centric, category-level representation and model-free 6 DoF motion tracking. The canonical object representation is learned solely in simulation and then used to parse a category-level, task trajectory from a single demonstration video. The demonstration is reprojected to a target trajectory tailored to a novel object via the canonical representation. During execution, the manipulation horizon is decomposed into long-range, collision-free motion and last-inch manipulation. For the latter part, a category-level behavior cloning (CatBC) method leverages motion tracking to perform closed-loop control. CatBC follows the target trajectory, projected from the demonstration and anchored to a dynamically selected category-level coordinate frame. The frame is automatically selected along the manipulation horizon by a local attention mechanism. This framework allows to teach different manipulation strategies by solely providing a single demonstration, without complicated manual programming. Extensive experiments demonstrate its efficacy in a range of challenging industrial tasks in high-precision assembly, which involve learning complex, long-horizon policies. The process exhibits robustness against uncertainty due to dynamics as well as generalization across object instances and scene configurations.

</p>
</details>

<details><summary><b>Tensor Recovery Based on Tensor Equivalent Minimax-Concave Penalty</b>
<a href="https://arxiv.org/abs/2201.12709">arxiv:2201.12709</a>
&#x1F4C8; 3 <br>
<p>Hongbing Zhang, Xinyi Liu, Hongtao Fan, Yajing Li, Yinlin Ye</p></summary>
<p>

**Abstract:** Tensor recovery is an important problem in computer vision and machine learning. It usually uses the convex relaxation of tensor rank and $l_{0}$ norm, i.e., the nuclear norm and $l_{1}$ norm respectively, to solve the problem. It is well known that convex approximations produce biased estimators. In order to overcome this problem, a corresponding non-convex regularizer has been proposed to solve it. Inspired by matrix equivalent Minimax-Concave Penalty (EMCP), we propose and prove theorems of tensor equivalent Minimax-Concave Penalty (TEMCP). The tensor equivalent MCP (TEMCP) as a non-convex regularizer and the equivalent weighted tensor $γ$ norm (EWTGN) which can represent the low-rank part are obtained. Both of them can realize weight adaptive. At the same time, we propose two corresponding adaptive models for two classical tensor recovery problems, low-rank tensor completion (LRTC) and tensor robust principal component analysis (TRPCA), and the optimization algorithm is based on alternating direction multiplier (ADMM). This novel iterative adaptive algorithm can produce more accurate tensor recovery effect. For the tensor completion model, multispectral image (MSI), magnetic resonance imaging (MRI) and color video (CV) data sets are considered, while for the tensor robust principal component analysis model, hyperspectral image (HSI) denoising under gaussian noise plus salt and pepper noise is considered. The proposed algorithm is superior to the state-of-arts method, and the algorithm is guaranteed to meet the reduction and convergence through experiments.

</p>
</details>

<details><summary><b>Robustness of Deep Recommendation Systems to Untargeted Interaction Perturbations</b>
<a href="https://arxiv.org/abs/2201.12686">arxiv:2201.12686</a>
&#x1F4C8; 3 <br>
<p>Sejoon Oh, Srijan Kumar</p></summary>
<p>

**Abstract:** While deep learning-based sequential recommender systems are widely used in practice, their sensitivity to untargeted training data perturbations is unknown. Untargeted perturbations aim to modify ranked recommendation lists for all users at test time, by inserting imperceptible input perturbations during training time. Existing perturbation methods are mostly targeted attacks optimized to change ranks of target items, but not suitable for untargeted scenarios. In this paper, we develop a novel framework in which user-item training interactions are perturbed in unintentional and adversarial settings. First, through comprehensive experiments on four datasets, we show that four popular recommender models are unstable against even one random perturbation. Second, we establish a cascading effect in which minor manipulations of early training interactions can cause extensive changes to the model and the generated recommendations for all users. Leveraging this effect, we propose an adversarial perturbation method CASPER which identifies and perturbs an interaction that induces the maximal cascading effect. Experimentally, we demonstrate that CASPER reduces the stability of recommendation models the most, compared to several baselines and state-of-the-art methods. Finally, we show the runtime and success of CASPER scale near-linearly with the dataset size and the number of perturbations, respectively.

</p>
</details>

<details><summary><b>A Stochastic Bundle Method for Interpolating Networks</b>
<a href="https://arxiv.org/abs/2201.12678">arxiv:2201.12678</a>
&#x1F4C8; 3 <br>
<p>Alasdair Paren, Leonard Berrada, Rudra P. K. Poudel, M. Pawan Kumar</p></summary>
<p>

**Abstract:** We propose a novel method for training deep neural networks that are capable of interpolation, that is, driving the empirical loss to zero. At each iteration, our method constructs a stochastic approximation of the learning objective. The approximation, known as a bundle, is a pointwise maximum of linear functions. Our bundle contains a constant function that lower bounds the empirical loss. This enables us to compute an automatic adaptive learning rate, thereby providing an accurate solution. In addition, our bundle includes linear approximations computed at the current iterate and other linear estimates of the DNN parameters. The use of these additional approximations makes our method significantly more robust to its hyperparameters. Based on its desirable empirical properties, we term our method Bundle Optimisation for Robust and Accurate Training (BORAT). In order to operationalise BORAT, we design a novel algorithm for optimising the bundle approximation efficiently at each iteration. We establish the theoretical convergence of BORAT in both convex and non-convex settings. Using standard publicly available data sets, we provide a thorough comparison of BORAT to other single hyperparameter optimisation algorithms. Our experiments demonstrate BORAT matches the state-of-the-art generalisation performance for these methods and is the most robust.

</p>
</details>

<details><summary><b>ADC-Net: An Open-Source Deep Learning Network for Automated Dispersion Compensation in Optical Coherence Tomography</b>
<a href="https://arxiv.org/abs/2201.12625">arxiv:2201.12625</a>
&#x1F4C8; 3 <br>
<p>Shaiban Ahmed, David Le, Taeyoon Son, Tobiloba Adejumo, Xincheng Yao, Department of Biomedical Engineering, University of Illinois at Chicago, Department of Ophthalmology, Visual Science, University of Illinois at Chicago</p></summary>
<p>

**Abstract:** Chromatic dispersion is a common problem to degrade the system resolution in optical coherence tomography (OCT). This study is to develop a deep learning network for automated dispersion compensation (ADC-Net) in OCT. The ADC-Net is based on a redesigned UNet architecture which employs an encoder-decoder pipeline. The input section encompasses partially compensated OCT B-scans with individual retinal layers optimized. Corresponding output is a fully compensated OCT B-scans with all retinal layers optimized. Two numeric parameters, i.e., peak signal to noise ratio (PSNR) and structural similarity index metric computed at multiple scales (MS-SSIM), were used for objective assessment of the ADC-Net performance. Comparative analysis of training models, including single, three, five, seven and nine input channels were implemented. The five-input channels implementation was observed as the optimal mode for ADC-Net training to achieve robust dispersion compensation in OCT

</p>
</details>

<details><summary><b>AntBO: Towards Real-World Automated Antibody Design with Combinatorial Bayesian Optimisation</b>
<a href="https://arxiv.org/abs/2201.12570">arxiv:2201.12570</a>
&#x1F4C8; 3 <br>
<p>Asif Khan, Alexander I. Cowen-Rivers, Derrick-Goh-Xin Deik, Antoine Grosnit, Kamil Dreczkowski, Philippe A. Robert, Victor Greiff, Rasul Tutunov, Dany Bou-Ammar, Jun Wang, Haitham Bou-Ammar</p></summary>
<p>

**Abstract:** Antibodies are canonically Y-shaped multimeric proteins capable of highly specific molecular recognition. The CDRH3 region located at the tip of variable chains of an antibody dominates antigen-binding specificity. Therefore, it is a priority to design optimal antigen-specific CDRH3 regions to develop therapeutic antibodies to combat harmful pathogens. However, the combinatorial nature of CDRH3 sequence space makes it impossible to search for an optimal binding sequence exhaustively and efficiently, especially not experimentally. Here, we present AntBO: a Combinatorial Bayesian Optimisation framework enabling efficient in silico design of the CDRH3 region. Ideally, antibodies should bind to their target antigen and be free from any harmful outcomes. Therefore, we introduce the CDRH3 trust region that restricts the search to sequences with feasible developability scores. To benchmark AntBO, we use the Absolut! software suite as a black-box oracle because it can score the target specificity and affinity of designed antibodies in silico in an unconstrained fashion. The results across 188 antigens demonstrate the benefit of AntBO in designing CDRH3 regions with diverse biophysical properties. In under 200 protein designs, AntBO can suggest antibody sequences that outperform the best binding sequence drawn from 6.9 million experimentally obtained CDRH3s and a commonly used genetic algorithm baseline. Additionally, AntBO finds very-high affinity CDRH3 sequences in only 38 protein designs whilst requiring no domain knowledge. We conclude AntBO brings automated antibody design methods closer to what is practically viable for in vitro experimentation.

</p>
</details>

<details><summary><b>Bellman Meets Hawkes: Model-Based Reinforcement Learning via Temporal Point Processes</b>
<a href="https://arxiv.org/abs/2201.12569">arxiv:2201.12569</a>
&#x1F4C8; 3 <br>
<p>Chao Qu, Xiaoyu Tan, Siqiao Xue, Xiaoming Shi, James Zhang, Hongyuan Mei</p></summary>
<p>

**Abstract:** We consider a sequential decision making problem where the agent faces the environment characterized by the stochastic discrete events and seeks an optimal intervention policy such that its long-term reward is maximized. This problem exists ubiquitously in social media, finance and health informatics but is rarely investigated by the conventional research in reinforcement learning. To this end, we present a novel framework of the model-based reinforcement learning where the agent's actions and observations are asynchronous stochastic discrete events occurring in continuous-time. We model the dynamics of the environment by Hawkes process with external intervention control term and develop an algorithm to embed such process in the Bellman equation which guides the direction of the value gradient. We demonstrate the superiority of our method in both synthetic simulator and real-world problem.

</p>
</details>

<details><summary><b>Fast Differentiable Matrix Square Root and Inverse Square Root</b>
<a href="https://arxiv.org/abs/2201.12543">arxiv:2201.12543</a>
&#x1F4C8; 3 <br>
<p>Yue Song, Nicu Sebe, Wei Wang</p></summary>
<p>

**Abstract:** Computing the matrix square root and its inverse in a differentiable manner is important in a variety of computer vision tasks. Previous methods either adopt the Singular Value Decomposition (SVD) to explicitly factorize the matrix or use the Newton-Schulz iteration (NS iteration) to derive the approximate solution. However, both methods are not computationally efficient enough in either the forward pass or the backward pass. In this paper, we propose two more efficient variants to compute the differentiable matrix square root and the inverse square root. For the forward propagation, one method is to use Matrix Taylor Polynomial (MTP), and the other method is to use Matrix Padé Approximants (MPA). The backward gradient is computed by iteratively solving the continuous-time Lyapunov equation using the matrix sign function. A series of numerical tests show that both methods yield considerable speed-up compared with the SVD or the NS iteration. Moreover, we validate the effectiveness of our methods in several real-world applications, including de-correlated batch normalization, second-order vision transformer, global covariance pooling for large-scale and fine-grained recognition, attentive covariance pooling for video recognition, and neural style transfer. The experimental results demonstrate that our methods can also achieve competitive and even slightly better performances. The Pytorch implementation is available at \href{https://github.com/KingJamesSong/FastDifferentiableMatSqrt}{https://github.com/KingJamesSong/FastDifferentiableMatSqrt}.

</p>
</details>

<details><summary><b>Zeroth-Order Actor-Critic</b>
<a href="https://arxiv.org/abs/2201.12518">arxiv:2201.12518</a>
&#x1F4C8; 3 <br>
<p>Yuheng Lei, Jianyu Chen, Shengbo Eben Li, Sifa Zheng</p></summary>
<p>

**Abstract:** Zeroth-order optimization methods and policy gradient based first-order methods are two promising alternatives to solve reinforcement learning (RL) problems with complementary advantages. The former work with arbitrary policies, drive state-dependent and temporally-extended exploration, possess robustness-seeking property, but suffer from high sample complexity, while the latter are more sample efficient but restricted to differentiable policies and the learned policies are less robust. We propose Zeroth-Order Actor-Critic algorithm (ZOAC) that unifies these two methods into an on-policy actor-critic architecture to preserve the advantages from both. ZOAC conducts rollouts collection with timestep-wise perturbation in parameter space, first-order policy evaluation (PEV) and zeroth-order policy improvement (PIM) alternately in each iteration. We evaluate our proposed method on a range of challenging continuous control benchmarks using different types of policies, where ZOAC outperforms zeroth-order and first-order baseline algorithms.

</p>
</details>

<details><summary><b>Maximum Batch Frobenius Norm for Multi-Domain Text Classification</b>
<a href="https://arxiv.org/abs/2202.00537">arxiv:2202.00537</a>
&#x1F4C8; 2 <br>
<p>Yuan Wu, Diana Inkpen, Ahmed El-Roby</p></summary>
<p>

**Abstract:** Multi-domain text classification (MDTC) has obtained remarkable achievements due to the advent of deep learning. Recently, many endeavors are devoted to applying adversarial learning to extract domain-invariant features to yield state-of-the-art results. However, these methods still face one challenge: transforming original features to be domain-invariant distorts the distributions of the original features, degrading the discriminability of the learned features. To address this issue, we first investigate the structure of the batch classification output matrix and theoretically justify that the discriminability of the learned features has a positive correlation with the Frobenius norm of the batch output matrix. Based on this finding, we propose a maximum batch Frobenius norm (MBF) method to boost the feature discriminability for MDTC. Experiments on two MDTC benchmarks show that our MBF approach can effectively advance the performance of the state-of-the-art.

</p>
</details>

<details><summary><b>Communication-Efficient Consensus Mechanism for Federated Reinforcement Learning</b>
<a href="https://arxiv.org/abs/2201.12718">arxiv:2201.12718</a>
&#x1F4C8; 2 <br>
<p>Xing Xu, Rongpeng Li, Zhifeng Zhao, Honggang Zhang</p></summary>
<p>

**Abstract:** The paper considers independent reinforcement learning (IRL) for multi-agent decision-making process in the paradigm of federated learning (FL). We show that FL can clearly improve the policy performance of IRL in terms of training efficiency and stability. However, since the policy parameters are trained locally and aggregated iteratively through a central server in FL, frequent information exchange incurs a large amount of communication overheads. To reach a good balance between improving the model's convergence performance and reducing the required communication and computation overheads, this paper proposes a system utility function and develops a consensus-based optimization scheme on top of the periodic averaging method, which introduces the consensus algorithm into FL for the exchange of a model's local gradients. This paper also provides novel convergence guarantees for the developed method, and demonstrates its superior effectiveness and efficiency in improving the system utility value through theoretical analyses and numerical simulation results.

</p>
</details>

<details><summary><b>DearFSAC: An Approach to Optimizing Unreliable Federated Learning via Deep Reinforcement Learning</b>
<a href="https://arxiv.org/abs/2201.12701">arxiv:2201.12701</a>
&#x1F4C8; 2 <br>
<p>Chenghao Huang, Weilong Chen, Yuxi Chen, Shunji Yang, Yanru Zhang</p></summary>
<p>

**Abstract:** In federated learning (FL), model aggregation has been widely adopted for data privacy. In recent years, assigning different weights to local models has been used to alleviate the FL performance degradation caused by differences between local datasets. However, when various defects make the FL process unreliable, most existing FL approaches expose weak robustness. In this paper, we propose the DEfect-AwaRe federated soft actor-critic (DearFSAC) to dynamically assign weights to local models to improve the robustness of FL. The deep reinforcement learning algorithm soft actor-critic is adopted for near-optimal performance and stable convergence. Besides, an auto-encoder is trained to output low-dimensional embedding vectors that are further utilized to evaluate model quality. In the experiments, DearFSAC outperforms three existing approaches on four datasets for both independent and identically distributed (IID) and non-IID settings under defective scenarios.

</p>
</details>

<details><summary><b>Coordinated Attacks against Contextual Bandits: Fundamental Limits and Defense Mechanisms</b>
<a href="https://arxiv.org/abs/2201.12700">arxiv:2201.12700</a>
&#x1F4C8; 2 <br>
<p>Jeongyeol Kwon, Yonathan Efroni, Constantine Caramanis, Shie Mannor</p></summary>
<p>

**Abstract:** Motivated by online recommendation systems, we propose the problem of finding the optimal policy in multitask contextual bandits when a small fraction $α< 1/2$ of tasks (users) are arbitrary and adversarial. The remaining fraction of good users share the same instance of contextual bandits with $S$ contexts and $A$ actions (items). Naturally, whether a user is good or adversarial is not known in advance. The goal is to robustly learn the policy that maximizes rewards for good users with as few user interactions as possible. Without adversarial users, established results in collaborative filtering show that $O(1/ε^2)$ per-user interactions suffice to learn a good policy, precisely because information can be shared across users. This parallelization gain is fundamentally altered by the presence of adversarial users: unless there are super-polynomial number of users, we show a lower bound of $\tildeΩ(\min(S,A) \cdot α^2 / ε^2)$ {\it per-user} interactions to learn an $ε$-optimal policy for the good users. We then show we can achieve an $\tilde{O}(\min(S,A)\cdot α/ε^2)$ upper-bound, by employing efficient robust mean estimators for both uni-variate and high-dimensional random variables. We also show that this can be improved depending on the distributions of contexts.

</p>
</details>

<details><summary><b>Why the Rich Get Richer? On the Balancedness of Random Partition Models</b>
<a href="https://arxiv.org/abs/2201.12697">arxiv:2201.12697</a>
&#x1F4C8; 2 <br>
<p>Changwoo J. Lee, Huiyan Sang</p></summary>
<p>

**Abstract:** Random partition models are widely used in Bayesian methods for various clustering tasks, such as mixture models, topic models, and community detection problems. While the number of clusters induced by random partition models has been studied extensively, another important model property regarding the balancedness of cluster sizes has been largely neglected. We formulate a framework to define and theoretically study the balancedness of exchangeable random partition models, by analyzing how a model assigns probabilities to partitions with different levels of balancedness. We demonstrate that the "rich-get-richer" characteristic of many existing popular random partition models is an inevitable consequence of two common assumptions: product-form exchangeability and projectivity. We propose a principled way to compare the balancedness of random partition models, which gives a better understanding of what model works better and what doesn't for different applications. We also introduce the "rich-get-poorer" random partition models and illustrate their application to entity resolution tasks.

</p>
</details>

<details><summary><b>Coordinate Descent Methods for Fractional Minimization</b>
<a href="https://arxiv.org/abs/2201.12691">arxiv:2201.12691</a>
&#x1F4C8; 2 <br>
<p>Ganzhao Yuan</p></summary>
<p>

**Abstract:** We consider a class of structured fractional minimization problems, in which the numerator part of the objective is the sum of a differentiable convex function and a convex nonsmooth function, while the denominator part is a concave or convex function. This problem is difficult to solve since it is nonconvex. By exploiting the structure of the problem, we propose two Coordinate Descent (CD) methods for solving this problem. One is applied to the original fractional function, the other is based on the associated parametric problem. The proposed methods iteratively solve a one-dimensional subproblem \textit{globally}, and they are guaranteed to converge to coordinate-wise stationary points. In the case of a convex denominator, we prove that the proposed CD methods using sequential nonconvex approximation find stronger stationary points than existing methods. Under suitable conditions, CD methods with an appropriate initialization converge linearly to the optimal point (also the coordinate-wise stationary point). In the case of a concave denominator, we show that the resulting problem is quasi-convex, and any critical point is a global minimum. We prove that the algorithms converge to the global optimal solution with a sublinear convergence rate. We demonstrate the applicability of the proposed methods to some machine learning and signal processing models. Our experiments on real-world data have shown that our method significantly and consistently outperforms existing methods in terms of accuracy.

</p>
</details>

<details><summary><b>A Priori Denoising Strategies for Sparse Identification of Nonlinear Dynamical Systems: A Comparative Study</b>
<a href="https://arxiv.org/abs/2201.12683">arxiv:2201.12683</a>
&#x1F4C8; 2 <br>
<p>Alexandre Cortiella, Kwang-Chun Park, Alireza Doostan</p></summary>
<p>

**Abstract:** In recent years, identification of nonlinear dynamical systems from data has become increasingly popular. Sparse regression approaches, such as Sparse Identification of Nonlinear Dynamics (SINDy), fostered the development of novel governing equation identification algorithms assuming the state variables are known a priori and the governing equations lend themselves to sparse, linear expansions in a (nonlinear) basis of the state variables. In the context of the identification of governing equations of nonlinear dynamical systems, one faces the problem of identifiability of model parameters when state measurements are corrupted by noise. Measurement noise affects the stability of the recovery process yielding incorrect sparsity patterns and inaccurate estimation of coefficients of the governing equations. In this work, we investigate and compare the performance of several local and global smoothing techniques to a priori denoise the state measurements and numerically estimate the state time-derivatives to improve the accuracy and robustness of two sparse regression methods to recover governing equations: Sequentially Thresholded Least Squares (STLS) and Weighted Basis Pursuit Denoising (WBPDN) algorithms. We empirically show that, in general, global methods, which use the entire measurement data set, outperform local methods, which employ a neighboring data subset around a local point. We additionally compare Generalized Cross Validation (GCV) and Pareto curve criteria as model selection techniques to automatically estimate near optimal tuning parameters, and conclude that Pareto curves yield better results. The performance of the denoising strategies and sparse regression methods is empirically evaluated through well-known benchmark problems of nonlinear dynamical systems.

</p>
</details>

<details><summary><b>SMGRL: A Scalable Multi-resolution Graph Representation Learning Framework</b>
<a href="https://arxiv.org/abs/2201.12670">arxiv:2201.12670</a>
&#x1F4C8; 2 <br>
<p>Reza Namazi, Elahe Ghalebi, Sinead Williamson, Hamidreza Mahyar</p></summary>
<p>

**Abstract:** Graph convolutional networks (GCNs) allow us to learn topologically-aware node embeddings, which can be useful for classification or link prediction. However, by construction, they lack positional awareness and are unable to capture long-range dependencies without adding additional layers -- which in turn leads to over-smoothing and increased time and space complexity. Further, the complex dependencies between nodes make mini-batching challenging, limiting their applicability to large graphs.
  This paper proposes a Scalable Multi-resolution Graph Representation Learning (SMGRL) framework that enables us to learn multi-resolution node embeddings efficiently. Our framework is model-agnostic and can be applied to any existing GCN model. We dramatically reduce training costs by training only on a reduced-dimension coarsening of the original graph, then exploit self-similarity to apply the resulting algorithm at multiple resolutions. Inference of these multi-resolution embeddings can be distributed across multiple machines to reduce computational and memory requirements further. The resulting multi-resolution embeddings can be aggregated to yield high-quality node embeddings that capture both long- and short-range dependencies between nodes. Our experiments show that this leads to improved classification accuracy, without incurring high computational costs.

</p>
</details>

<details><summary><b>Learning to Coordinate with Humans using Action Features</b>
<a href="https://arxiv.org/abs/2201.12658">arxiv:2201.12658</a>
&#x1F4C8; 2 <br>
<p>Mingwei Ma, Jizhou Liu, Samuel Sokota, Max Kleiman-Weiner, Jakob Foerster</p></summary>
<p>

**Abstract:** An unaddressed challenge in human-AI coordination is to enable AI agents to exploit the semantic relationships between the features of actions and the features of observations. Humans take advantage of these relationships in highly intuitive ways. For instance, in the absence of a shared language, we might point to the object we desire or hold up our fingers to indicate how many objects we want. To address this challenge, we investigate the effect of network architecture on the propensity of learning algorithms to exploit these semantic relationships. Across a procedurally generated coordination task, we find that attention-based architectures that jointly process a featurized representation of observations and actions have a better inductive bias for zero-shot coordination. Through fine-grained evaluation and scenario analysis, we show that the resulting policies are human-interpretable. Moreover, such agents coordinate with people without training on any human data.

</p>
</details>

<details><summary><b>Prediction of terephthalic acid (TPA) yield in aqueous hydrolysis of polyethylene terephthalate (PET)</b>
<a href="https://arxiv.org/abs/2201.12657">arxiv:2201.12657</a>
&#x1F4C8; 2 <br>
<p>Hossein Abedsoltan, Zeinab Zoghi, Amir H. Mohammadi</p></summary>
<p>

**Abstract:** Aqueous hydrolysis is used to chemically recycle polyethylene terephthalate (PET) due to the production of high-quality terephthalic acid (TPA), the PET monomer. PET hydrolysis depends on various reaction conditions including PET size, catalyst concentration, reaction temperature, etc. So, modeling PET hydrolysis by considering the effective factors can provide useful information for material scientists to specify how to design and run these reactions. It will save time, energy, and materials by optimizing the hydrolysis conditions. Machine learning algorithms enable to design models to predict output results. For the first time, 381 experimental data were gathered to model the aqueous hydrolysis of PET. Effective reaction conditions on PET hydrolysis were connected to TPA yield. The logistic regression was applied to rank the reaction conditions. Two algorithms were proposed, artificial neural network multilayer perceptron (ANN-MLP) and adaptive network-based fuzzy inference system (ANFIS). The dataset was divided into training and testing sets to train and test the models, respectively. The models predicted TPA yield sufficiently where the ANFIS model outperformed. R-squared (R2) and Root Mean Square Error (RMSE) loss functions were employed to measure the efficiency of the models and evaluate their performance.

</p>
</details>

<details><summary><b>Self Semi Supervised Neural Architecture Search for Semantic Segmentation</b>
<a href="https://arxiv.org/abs/2201.12646">arxiv:2201.12646</a>
&#x1F4C8; 2 <br>
<p>Loïc Pauletto, Massih-Reza Amini, Nicolas Winckler</p></summary>
<p>

**Abstract:** In this paper, we propose a Neural Architecture Search strategy based on self supervision and semi-supervised learning for the task of semantic segmentation. Our approach builds an optimized neural network (NN) model for this task by jointly solving a jigsaw pretext task discovered with self-supervised learning over unlabeled training data, and, exploiting the structure of the unlabeled data with semi-supervised learning. The search of the architecture of the NN model is performed by dynamic routing using a gradient descent algorithm. Experiments on the Cityscapes and PASCAL VOC 2012 datasets demonstrate that the discovered neural network is more efficient than a state-of-the-art hand-crafted NN model with four times less floating operations.

</p>
</details>

<details><summary><b>Image Classification using Graph Neural Network and Multiscale Wavelet Superpixels</b>
<a href="https://arxiv.org/abs/2201.12633">arxiv:2201.12633</a>
&#x1F4C8; 2 <br>
<p>Varun Vasudevan, Maxime Bassenne, Md Tauhidul Islam, Lei Xing</p></summary>
<p>

**Abstract:** Prior studies using graph neural networks (GNNs) for image classification have focused on graphs generated from a regular grid of pixels or similar-sized superpixels. In the latter, a single target number of superpixels is defined for an entire dataset irrespective of differences across images and their intrinsic multiscale structure. On the contrary, this study investigates image classification using graphs generated from an image-specific number of multiscale superpixels. We propose WaveMesh, a new wavelet-based superpixeling algorithm, where the number and sizes of superpixels in an image are systematically computed based on its content. WaveMesh superpixel graphs are structurally different from similar-sized superpixel graphs. We use SplineCNN, a state-of-the-art network for image graph classification, to compare WaveMesh and similar-sized superpixels. Using SplineCNN, we perform extensive experiments on three benchmark datasets under three local-pooling settings: 1) no pooling, 2) GraclusPool, and 3) WavePool, a novel spatially heterogeneous pooling scheme tailored to WaveMesh superpixels. Our experiments demonstrate that SplineCNN learns from multiscale WaveMesh superpixels on-par with similar-sized superpixels. In all WaveMesh experiments, GraclusPool performs poorer than no pooling / WavePool, indicating that poor choice of pooling can result in inferior performance while learning from multiscale superpixels.

</p>
</details>

<details><summary><b>Hyperparameter-free deep active learning for regression problems via query synthesis</b>
<a href="https://arxiv.org/abs/2201.12632">arxiv:2201.12632</a>
&#x1F4C8; 2 <br>
<p>Simiao Ren, Yang Deng, Willie J. Padilla, Jordan Malof</p></summary>
<p>

**Abstract:** In the past decade, deep active learning (DAL) has heavily focused upon classification problems, or problems that have some 'valid' data manifolds, such as natural languages or images. As a result, existing DAL methods are not applicable to a wide variety of important problems -- such as many scientific computing problems -- that involve regression on relatively unstructured input spaces. In this work we propose the first DAL query-synthesis approach for regression problems. We frame query synthesis as an inverse problem and use the recently-proposed neural-adjoint (NA) solver to efficiently find points in the continuous input domain that optimize the query-by-committee (QBC) criterion. Crucially, the resulting NA-QBC approach removes the one sensitive hyperparameter of the classical QBC active learning approach - the "pool size"- making NA-QBC effectively hyperparameter free. This is significant because DAL methods can be detrimental, even compared to random sampling, if the wrong hyperparameters are chosen. We evaluate Random, QBC and NA-QBC sampling strategies on four regression problems, including two contemporary scientific computing problems. We find that NA-QBC achieves better average performance than random sampling on every benchmark problem, while QBC can be detrimental if the wrong hyperparameters are chosen.

</p>
</details>

<details><summary><b>Assessing Cross-dataset Generalization of Pedestrian Crossing Predictors</b>
<a href="https://arxiv.org/abs/2201.12626">arxiv:2201.12626</a>
&#x1F4C8; 2 <br>
<p>Joseph Gesnouin, Steve Pechberti, Bogdan Stanciulescu, Fabien Moutarde</p></summary>
<p>

**Abstract:** Pedestrian crossing prediction has been a topic of active research, resulting in many new algorithmic solutions. While measuring the overall progress of those solutions over time tends to be more and more established due to the new publicly available benchmark and standardized evaluation procedures, knowing how well existing predictors react to unseen data remains an unanswered question. This evaluation is imperative as serviceable crossing behavior predictors should be set to work in various scenarii without compromising pedestrian safety due to misprediction. To this end, we conduct a study based on direct cross-dataset evaluation. Our experiments show that current state-of-the-art pedestrian behavior predictors generalize poorly in cross-dataset evaluation scenarii, regardless of their robustness during a direct training-test set evaluation setting. In the light of what we observe, we argue that the future of pedestrian crossing prediction, e.g. reliable and generalizable implementations, should not be about tailoring models, trained with very little available data, and tested in a classical train-test scenario with the will to infer anything about their behavior in real life. It should be about evaluating models in a cross-dataset setting while considering their uncertainty estimates under domain shift.

</p>
</details>

<details><summary><b>ApolloRL: a Reinforcement Learning Platform for Autonomous Driving</b>
<a href="https://arxiv.org/abs/2201.12609">arxiv:2201.12609</a>
&#x1F4C8; 2 <br>
<p>Fei Gao, Peng Geng, Jiaqi Guo, Yuan Liu, Dingfeng Guo, Yabo Su, Jie Zhou, Xiao Wei, Jin Li, Xu Liu</p></summary>
<p>

**Abstract:** We introduce ApolloRL, an open platform for research in reinforcement learning for autonomous driving. The platform provides a complete closed-loop pipeline with training, simulation, and evaluation components. It comes with 300 hours of real-world data in driving scenarios and popular baselines such as Proximal Policy Optimization (PPO) and Soft Actor-Critic (SAC) agents. We elaborate in this paper on the architecture and the environment defined in the platform. In addition, we discuss the performance of the baseline agents in the ApolloRL environment.

</p>
</details>

<details><summary><b>DeepRNG: Towards Deep Reinforcement Learning-Assisted Generative Testing of Software</b>
<a href="https://arxiv.org/abs/2201.12602">arxiv:2201.12602</a>
&#x1F4C8; 2 <br>
<p>Chuan-Yung Tsai, Graham W. Taylor</p></summary>
<p>

**Abstract:** Although machine learning (ML) has been successful in automating various software engineering needs, software testing still remains a highly challenging topic. In this paper, we aim to improve the generative testing of software by directly augmenting the random number generator (RNG) with a deep reinforcement learning (RL) agent using an efficient, automatically extractable state representation of the software under test. Using the Cosmos SDK as the testbed, we show that the proposed DeepRNG framework provides a statistically significant improvement to the testing of the highly complex software library with over 350,000 lines of code. The source code of the DeepRNG framework is publicly available online.

</p>
</details>

<details><summary><b>MVP: Multi-Stage Vision-Language Pre-Training via Multi-Level Semantic Alignment</b>
<a href="https://arxiv.org/abs/2201.12596">arxiv:2201.12596</a>
&#x1F4C8; 2 <br>
<p>Zejun Li, Zhihao Fan, Huaixiao Tou, Zhongyu Wei</p></summary>
<p>

**Abstract:** In this paper, we propose a Multi-stage Vision-language Pre-training (MVP) framework to learn cross-modality representation via multi-level semantic alignment. We introduce concepts in both modalities to construct two-level semantic representations for language and vision. Based on the multi-level input, we train the cross-modality model in two stages, namely, uni-modal learning and cross-modal learning. The former stage enforces within-modality interactions to learn multi-level semantics for each single modality. The latter stage enforces interactions across modalities via both coarse-grain and fine-grain semantic alignment tasks. Image-text matching and masked language modeling are then used to further optimize the pre-training model. Our model generates the-state-of-the-art results on several vision and language tasks.

</p>
</details>

<details><summary><b>Task-Balanced Batch Normalization for Exemplar-based Class-Incremental Learning</b>
<a href="https://arxiv.org/abs/2201.12559">arxiv:2201.12559</a>
&#x1F4C8; 2 <br>
<p>Sungmin Cha, Soonwon Hong, Moontae Lee, Taesup Moon</p></summary>
<p>

**Abstract:** Batch Normalization (BN) is an essential layer for training neural network models in various computer vision tasks. It has been widely used in continual learning scenarios with little discussion, but we find that BN should be carefully applied, particularly for the exemplar memory based class incremental learning (CIL). We first analyze that the empirical mean and variance obtained for normalization in a BN layer become highly biased toward the current task. To tackle its significant problems in training and test phases, we propose Task-Balanced Batch Normalization (TBBN). Given each mini-batch imbalanced between the current and previous tasks, TBBN first reshapes and repeats the batch, calculating near task-balanced mean and variance. Second, we show that when the affine transformation parameters of BN are learned from a reshaped feature map, they become less-biased toward the current task. Based on our extensive CIL experiments with CIFAR-100 and ImageNet-100 datasets, we demonstrate that our TBBN is easily applicable to most of existing exemplar-based CIL algorithms, improving their performance by decreasing the forgetting on the previous tasks.

</p>
</details>

<details><summary><b>Validation and Generalizability of Self-Supervised Image Reconstruction Methods for Undersampled MRI</b>
<a href="https://arxiv.org/abs/2201.12535">arxiv:2201.12535</a>
&#x1F4C8; 2 <br>
<p>Thomas Yu, Tom Hilbert, Gian Franco Piredda, Arun Joseph, Gabriele Bonanno, Salim Zenkhri, Patrick Omoumi, Meritxell Bach Cuadra, Erick Jorge Canales-Rodríguez, Tobias Kober, Jean-Philippe Thiran</p></summary>
<p>

**Abstract:** Purpose: To investigate aspects of the validation of self-supervised algorithms for reconstruction of undersampled MR images: quantitative evaluation of prospective reconstructions, potential differences between prospective and retrospective reconstructions, suitability of commonly used quantitative metrics, and generalizability.
  Theory and Methods: Two self-supervised algorithms based on self-supervised denoising and neural network image priors were investigated. These methods are compared to a least squares fitting and a compressed sensing reconstruction using in-vivo and phantom data. Their generalizability was tested with prospectively under-sampled data from experimental conditions different to the training.
  Results: Prospective reconstructions can exhibit significant distortion relative to retrospective reconstructions/ground truth. Pixel-wise quantitative metrics may not capture differences in perceptual quality accurately, in contrast to a perceptual metric. All methods showed potential for generalization; generalizability is more affected by changes in anatomy/contrast than other changes. No-reference image metrics correspond well with human rating of image quality for studying generalizability. Compressed Sensing and learned denoising perform similarly well on all data.
  Conclusion: Self-supervised methods show promising results for accelerating image reconstruction in clinical routines. Nonetheless, more work is required to investigate standardized methods to validate reconstruction algorithms for future clinical use.

</p>
</details>

<details><summary><b>Rethinking Adjacent Dependency in Session-based Recommendations</b>
<a href="https://arxiv.org/abs/2201.12532">arxiv:2201.12532</a>
&#x1F4C8; 2 <br>
<p>Qian Zhang, Shoujin Wang, Wenpeng Lu, Chong Feng, Xueping Peng, Qingxiang Wang</p></summary>
<p>

**Abstract:** Session-based recommendations (SBRs) recommend the next item for an anonymous user by modeling the dependencies between items in a session. Benefiting from the superiority of graph neural networks (GNN) in learning complex dependencies, GNN-based SBRs have become the main stream of SBRs in recent years. Most GNN-based SBRs are based on a strong assumption of adjacent dependency, which means any two adjacent items in a session are necessarily dependent here. However, based on our observation, the adjacency does not necessarily indicate dependency due to the uncertainty and complexity of user behaviours. Therefore, the aforementioned assumption does not always hold in the real-world cases and thus easily leads to two deficiencies: (1) the introduction of false dependencies between items which are adjacent in a session but are not really dependent, and (2) the missing of true dependencies between items which are not adjacent but are actually dependent. Such deficiencies significantly downgrade accurate dependency learning and thus reduce the recommendation performance. Aiming to address these deficiencies, we propose a novel review-refined inter-item graph neural network (RI-GNN), which utilizes the topic information extracted from items' reviews to refine dependencies between items. Experiments on two public real-world datasets demonstrate that RI-GNN outperforms the state-of-the-art methods.

</p>
</details>

<details><summary><b>Few-Shot Transfer Learning for Device-Free Fingerprinting Indoor Localization</b>
<a href="https://arxiv.org/abs/2201.12656">arxiv:2201.12656</a>
&#x1F4C8; 1 <br>
<p>Bing-Jia Chen, Ronald Y. Chang</p></summary>
<p>

**Abstract:** Device-free wireless indoor localization is an essential technology for the Internet of Things (IoT), and fingerprint-based methods are widely used. A common challenge to fingerprint-based methods is data collection and labeling. This paper proposes a few-shot transfer learning system that uses only a small amount of labeled data from the current environment and reuses a large amount of existing labeled data previously collected in other environments, thereby significantly reducing the data collection and labeling cost for localization in each new environment. The core method lies in graph neural network (GNN) based few-shot transfer learning and its modifications. Experimental results conducted on real-world environments show that the proposed system achieves comparable performance to a convolutional neural network (CNN) model, with 40 times fewer labeled data.

</p>
</details>

<details><summary><b>Learning Stochastic Graph Neural Networks with Constrained Variance</b>
<a href="https://arxiv.org/abs/2201.12611">arxiv:2201.12611</a>
&#x1F4C8; 1 <br>
<p>Zhan Gao, Elvin Isufi</p></summary>
<p>

**Abstract:** Stochastic graph neural networks (SGNNs) are information processing architectures that learn representations from data over random graphs. SGNNs are trained with respect to the expected performance, which comes with no guarantee about deviations of particular output realizations around the optimal expectation. To overcome this issue, we propose a variance-constrained optimization problem for SGNNs, balancing the expected performance and the stochastic deviation. An alternating primal-dual learning procedure is undertaken that solves the problem by updating the SGNN parameters with gradient descent and the dual variable with gradient ascent. To characterize the explicit effect of the variance-constrained learning, we conduct a theoretical analysis on the variance of the SGNN output and identify a trade-off between the stochastic robustness and the discrimination power. We further analyze the duality gap of the variance-constrained optimization problem and the converging behavior of the primal-dual learning procedure. The former indicates the optimality loss induced by the dual transformation and the latter characterizes the limiting error of the iterative algorithm, both of which guarantee the performance of the variance-constrained learning. Through numerical simulations, we corroborate our theoretical findings and observe a strong expected performance with a controllable standard deviation.

</p>
</details>

<details><summary><b>FedMed-ATL: Misaligned Unpaired Brain Image Synthesis via Affine Transform Loss</b>
<a href="https://arxiv.org/abs/2201.12589">arxiv:2201.12589</a>
&#x1F4C8; 1 <br>
<p>Guoyang Xie, Jinbao Wang, Yawen Huang, Yefeng Zheng, Feng Zheng, Yaochu Jin</p></summary>
<p>

**Abstract:** The existence of completely aligned and paired multi-modal neuroimaging data has proved its effectiveness in the diagnosis of brain diseases. However, collecting the full set of well-aligned and paired data is impractical or even luxurious, since the practical difficulties may include high cost, long time acquisition, image corruption, and privacy issues. Previously, the misaligned unpaired neuroimaging data (termed as MUD) are generally treated as noisy label. However, such a noisy label-based method could not work very well when misaligned data occurs distortions severely, for example, different angles of rotation. In this paper, we propose a novel federated self-supervised learning (FedMed) for brain image synthesis. An affine transform loss (ATL) was formulated to make use of severely distorted images without violating privacy legislation for the hospital. We then introduce a new data augmentation procedure for self-supervised training and fed it into three auxiliary heads, namely auxiliary rotation, auxiliary translation, and auxiliary scaling heads. The proposed method demonstrates advanced performance in both the quality of synthesized results under a severely misaligned and unpaired data setting, and better stability than other GAN-based algorithms. The proposed method also reduces the demand for deformable registration while encouraging to realize the usage of those misaligned and unpaired data. Experimental results verify the outstanding ability of our learning paradigm compared to other state-of-the-art approaches. Our code is available on the website: https://github.com/FedMed-Meta/FedMed-ATL

</p>
</details>

<details><summary><b>Convolutional Filtering in Simplicial Complexes</b>
<a href="https://arxiv.org/abs/2201.12584">arxiv:2201.12584</a>
&#x1F4C8; 1 <br>
<p>Elvin Isufi, Maosheng Yang</p></summary>
<p>

**Abstract:** This paper proposes convolutional filtering for data whose structure can be modeled by a simplicial complex (SC). SCs are mathematical tools that not only capture pairwise relationships as graphs but account also for higher-order network structures. These filters are built by following the shift-and-sum principle of the convolution operation and rely on the Hodge-Laplacians to shift the signal within the simplex. But since in SCs we have also inter-simplex coupling, we use the incidence matrices to transfer the signal in adjacent simplices and build a filter bank to jointly filter signals from different levels. We prove some interesting properties for the proposed filter bank, including permutation and orientation equivariance, a computational complexity that is linear in the SC dimension, and a spectral interpretation using the simplicial Fourier transform. We illustrate the proposed approach with numerical experiments.

</p>
</details>

<details><summary><b>A Novel Matrix-Encoding Method for Privacy-Preserving Neural Networks (Inference)</b>
<a href="https://arxiv.org/abs/2201.12577">arxiv:2201.12577</a>
&#x1F4C8; 1 <br>
<p>John Chiang</p></summary>
<p>

**Abstract:** In this work, we present $\texttt{Volley Revolver}$, a novel matrix-encoding method that is particularly convenient for privacy-preserving neural networks to make predictions, and use it to implement a CNN for handwritten image classification. Based on this encoding method, we develop several additional operations for putting into practice the secure matrix multiplication over encrypted data matrices. For two matrices $A$ and $B$ to perform multiplication $A \times B$, the main idea is, in a simple version, to encrypt matrix $A$ and the transposition of the matrix $B$ into two ciphertexts respectively. Along with the additional operations, the homomorphic matrix multiplication $A \times B$ can be calculated over encrypted data matrices efficiently. For the convolution operation in CNN, on the basis of the $\texttt{Volley Revolver}$ encoding method, we develop a feasible and efficient evaluation strategy for performing the convolution operation. We in advance span each convolution kernel of CNN to a matrix space of the same size as the input image so as to generate several ciphertexts, each of which is later used together with the input image for calculating some part of the final convolution result. We accumulate all these part results of convolution operation and thus obtain the final convolution result.

</p>
</details>

<details><summary><b>Blind ECG Restoration by Operational Cycle-GANs</b>
<a href="https://arxiv.org/abs/2202.00589">arxiv:2202.00589</a>
&#x1F4C8; 0 <br>
<p>Serkan Kiranyaz, Ozer Can Devecioglu, Turker Ince, Junaid Malik, Muhammad Chowdhury, Tahir Hamid, Rashid Mazhar, Amith Khandakar, Anas Tahir, Tawsifur Rahman, Moncef Gabbouj</p></summary>
<p>

**Abstract:** Continuous long-term monitoring of electrocardiography (ECG) signals is crucial for the early detection of cardiac abnormalities such as arrhythmia. Non-clinical ECG recordings acquired by Holter and wearable ECG sensors often suffer from severe artifacts such as baseline wander, signal cuts, motion artifacts, variations on QRS amplitude, noise, and other interferences. Usually, a set of such artifacts occur on the same ECG signal with varying severity and duration, and this makes an accurate diagnosis by machines or medical doctors extremely difficult. Despite numerous studies that have attempted ECG denoising, they naturally fail to restore the actual ECG signal corrupted with such artifacts due to their simple and naive noise model. In this study, we propose a novel approach for blind ECG restoration using cycle-consistent generative adversarial networks (Cycle-GANs) where the quality of the signal can be improved to a clinical level ECG regardless of the type and severity of the artifacts corrupting the signal. To further boost the restoration performance, we propose 1D operational Cycle-GANs with the generative neuron model. The proposed approach has been evaluated extensively using one of the largest benchmark ECG datasets from the China Physiological Signal Challenge (CPSC-2020) with more than one million beats. Besides the quantitative and qualitative evaluations, a group of cardiologists performed medical evaluations to validate the quality and usability of the restored ECG, especially for an accurate arrhythmia diagnosis.

</p>
</details>


{% endraw %}
Prev: [2022.01.28]({{ '/2022/01/28/2022.01.28.html' | relative_url }})  Next: [2022.01.30]({{ '/2022/01/30/2022.01.30.html' | relative_url }})