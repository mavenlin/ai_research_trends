Prev: [2022.07.01]({{ '/2022/07/01/2022.07.01.html' | relative_url }})  Next: [2022.07.03]({{ '/2022/07/03/2022.07.03.html' | relative_url }})
{% raw %}
## Summary for 2022-07-02, created on 2022-07-12


<details><summary><b>Object Representations as Fixed Points: Training Iterative Refinement Algorithms with Implicit Differentiation</b>
<a href="https://arxiv.org/abs/2207.00787">arxiv:2207.00787</a>
&#x1F4C8; 78 <br>
<p>Michael Chang, Thomas L. Griffiths, Sergey Levine</p></summary>
<p>

**Abstract:** Iterative refinement -- start with a random guess, then iteratively improve the guess -- is a useful paradigm for representation learning because it offers a way to break symmetries among equally plausible explanations for the data. This property enables the application of such methods to infer representations of sets of entities, such as objects in physical scenes, structurally resembling clustering algorithms in latent space. However, most prior works differentiate through the unrolled refinement process, which can make optimization challenging. We observe that such methods can be made differentiable by means of the implicit function theorem, and develop an implicit differentiation approach that improves the stability and tractability of training by decoupling the forward and backward passes. This connection enables us to apply advances in optimizing implicit layers to not only improve the optimization of the slot attention module in SLATE, a state-of-the-art method for learning entity representations, but do so with constant space and time complexity in backpropagation and only one additional line of code.

</p>
</details>

<details><summary><b>Biological Robots: Perspectives on an Emerging Interdisciplinary Field</b>
<a href="https://arxiv.org/abs/2207.00880">arxiv:2207.00880</a>
&#x1F4C8; 65 <br>
<p>D. Blackiston, S. Kriegman, J. Bongard, M. Levin</p></summary>
<p>

**Abstract:** Advances in science and engineering often reveal the limitations of classical approaches initially used to understand, predict, and control phenomena. With progress, conceptual categories must often be re-evaluated to better track recently discovered invariants across disciplines. It is essential to refine frameworks and resolve conflicting boundaries between disciplines such that they better facilitate, not restrict, experimental approaches and capabilities. In this essay, we discuss issues at the intersection of developmental biology, computer science, and robotics. In the context of biological robots, we explore changes across concepts and previously distinct fields that are driven by recent advances in materials, information, and life sciences. Herein, each author provides their own perspective on the subject, framed by their own disciplinary training. We argue that as with computation, certain aspects of developmental biology and robotics are not tied to specific materials; rather, the consilience of these fields can help to shed light on issues of multi-scale control, self-assembly, and relationships between form and function. We hope new fields can emerge as boundaries arising from technological limitations are overcome, furthering practical applications from regenerative medicine to useful synthetic living machines.

</p>
</details>

<details><summary><b>Speech Emotion: Investigating Model Representations, Multi-Task Learning and Knowledge Distillation</b>
<a href="https://arxiv.org/abs/2207.03334">arxiv:2207.03334</a>
&#x1F4C8; 9 <br>
<p>Vikramjit Mitra, Hsiang-Yun Sherry Chien, Vasudha Kowtha, Joseph Yitan Cheng, Erdrin Azemi</p></summary>
<p>

**Abstract:** Estimating dimensional emotions, such as activation, valence and dominance, from acoustic speech signals has been widely explored over the past few years. While accurate estimation of activation and dominance from speech seem to be possible, the same for valence remains challenging. Previous research has shown that the use of lexical information can improve valence estimation performance. Lexical information can be obtained from pre-trained acoustic models, where the learned representations can improve valence estimation from speech. We investigate the use of pre-trained model representations to improve valence estimation from acoustic speech signal. We also explore fusion of representations to improve emotion estimation across all three emotion dimensions: activation, valence and dominance. Additionally, we investigate if representations from pre-trained models can be distilled into models trained with low-level features, resulting in models with a less number of parameters. We show that fusion of pre-trained model embeddings result in a 79% relative improvement in concordance correlation coefficient CCC on valence estimation compared to standard acoustic feature baseline (mel-filterbank energies), while distillation from pre-trained model embeddings to lower-dimensional representations yielded a relative 12% improvement. Such performance gains were observed over two evaluation sets, indicating that our proposed architecture generalizes across those evaluation sets. We report new state-of-the-art "text-free" acoustic-only dimensional emotion estimation $CCC$ values on two MSP-Podcast evaluation sets.

</p>
</details>

<details><summary><b>The Linguistic Blind Spot of Value-Aligned Agency, Natural and Artificial</b>
<a href="https://arxiv.org/abs/2207.00868">arxiv:2207.00868</a>
&#x1F4C8; 9 <br>
<p>Travis LaCroix</p></summary>
<p>

**Abstract:** The value-alignment problem for artificial intelligence (AI) asks how we can ensure that the 'values' (i.e., objective functions) of artificial systems are aligned with the values of humanity. In this paper, I argue that linguistic communication (natural language) is a necessary condition for robust value alignment. I discuss the consequences that the truth of this claim would have for research programmes that attempt to ensure value alignment for AI systems; or, more loftily, designing robustly beneficial or ethical artificial agents.

</p>
</details>

<details><summary><b>Less Is More: A Comparison of Active Learning Strategies for 3D Medical Image Segmentation</b>
<a href="https://arxiv.org/abs/2207.00845">arxiv:2207.00845</a>
&#x1F4C8; 9 <br>
<p>Josafat-Mattias Burmeister, Marcel Fernandez Rosas, Johannes Hagemann, Jonas Kordt, Jasper Blum, Simon Shabo, Benjamin Bergner, Christoph Lippert</p></summary>
<p>

**Abstract:** Since labeling medical image data is a costly and labor-intensive process, active learning has gained much popularity in the medical image segmentation domain in recent years. A variety of active learning strategies have been proposed in the literature, but their effectiveness is highly dependent on the dataset and training scenario. To facilitate the comparison of existing strategies and provide a baseline for evaluating novel strategies, we evaluate the performance of several well-known active learning strategies on three datasets from the Medical Segmentation Decathlon. Additionally, we consider a strided sampling strategy specifically tailored to 3D image data. We demonstrate that both random and strided sampling act as strong baselines and discuss the advantages and disadvantages of the studied methods. To allow other researchers to compare their work to our results, we provide an open-source framework for benchmarking active learning strategies on a variety of medical segmentation datasets.

</p>
</details>

<details><summary><b>M-Adapter: Modality Adaptation for End-to-End Speech-to-Text Translation</b>
<a href="https://arxiv.org/abs/2207.00952">arxiv:2207.00952</a>
&#x1F4C8; 7 <br>
<p>Jinming Zhao, Hao Yang, Ehsan Shareghi, Gholamreza Haffari</p></summary>
<p>

**Abstract:** End-to-end speech-to-text translation models are often initialized with pre-trained speech encoder and pre-trained text decoder. This leads to a significant training gap between pre-training and fine-tuning, largely due to the modality differences between speech outputs from the encoder and text inputs to the decoder. In this work, we aim to bridge the modality gap between speech and text to improve translation quality. We propose M-Adapter, a novel Transformer-based module, to adapt speech representations to text. While shrinking the speech sequence, M-Adapter produces features desired for speech-to-text translation via modelling global and local dependencies of a speech sequence. Our experimental results show that our model outperforms a strong baseline by up to 1 BLEU score on the Must-C En$\rightarrow$DE dataset.\footnote{Our code is available at https://github.com/mingzi151/w2v2-st.}

</p>
</details>

<details><summary><b>Test-time Adaptation with Calibration of Medical Image Classification Nets for Label Distribution Shift</b>
<a href="https://arxiv.org/abs/2207.00769">arxiv:2207.00769</a>
&#x1F4C8; 6 <br>
<p>Wenao Ma, Cheng Chen, Shuang Zheng, Jing Qin, Huimao Zhang, Qi Dou</p></summary>
<p>

**Abstract:** Class distribution plays an important role in learning deep classifiers. When the proportion of each class in the test set differs from the training set, the performance of classification nets usually degrades. Such a label distribution shift problem is common in medical diagnosis since the prevalence of disease vary over location and time. In this paper, we propose the first method to tackle label shift for medical image classification, which effectively adapt the model learned from a single training label distribution to arbitrary unknown test label distribution. Our approach innovates distribution calibration to learn multiple representative classifiers, which are capable of handling different one-dominating-class distributions. When given a test image, the diverse classifiers are dynamically aggregated via the consistency-driven test-time adaptation, to deal with the unknown test label distribution. We validate our method on two important medical image classification tasks including liver fibrosis staging and COVID-19 severity prediction. Our experiments clearly show the decreased model performance under label shift. With our method, model performance significantly improves on all the test datasets with different label shifts for both medical image diagnosis tasks.

</p>
</details>

<details><summary><b>FRAME: Evaluating Simulatability Metrics for Free-Text Rationales</b>
<a href="https://arxiv.org/abs/2207.00779">arxiv:2207.00779</a>
&#x1F4C8; 5 <br>
<p>Aaron Chan, Shaoliang Nie, Liang Tan, Xiaochang Peng, Hamed Firooz, Maziar Sanjabi, Xiang Ren</p></summary>
<p>

**Abstract:** Free-text rationales aim to explain neural language model (LM) behavior more flexibly and intuitively via natural language. To ensure rationale quality, it is important to have metrics for measuring rationales' faithfulness (reflects LM's actual behavior) and plausibility (convincing to humans). All existing free-text rationale metrics are based on simulatability (association between rationale and LM's predicted label), but there is no protocol for assessing such metrics' reliability. To investigate this, we propose FRAME, a framework for evaluating free-text rationale simulatability metrics. FRAME is based on three axioms: (1) good metrics should yield highest scores for reference rationales, which maximize rationale-label association by construction; (2) good metrics should be appropriately sensitive to semantic perturbation of rationales; and (3) good metrics should be robust to variation in the LM's task performance. Across three text classification datasets, we show that existing simulatability metrics cannot satisfy all three FRAME axioms, since they are implemented via model pretraining which muddles the metric's signal. We introduce a non-pretraining simulatability variant that improves performance on (1) and (3) by an average of 41.7% and 42.9%, respectively, while performing competitively on (2).

</p>
</details>

<details><summary><b>Unsupervised Symbolic Music Segmentation using Ensemble Temporal Prediction Errors</b>
<a href="https://arxiv.org/abs/2207.00760">arxiv:2207.00760</a>
&#x1F4C8; 5 <br>
<p>Shahaf Bassan, Yossi Adi, Jeffrey S. Rosenschein</p></summary>
<p>

**Abstract:** Symbolic music segmentation is the process of dividing symbolic melodies into smaller meaningful groups, such as melodic phrases. We proposed an unsupervised method for segmenting symbolic music. The proposed model is based on an ensemble of temporal prediction error models. During training, each model predicts the next token to identify musical phrase changes. While at test time, we perform a peak detection algorithm to select segment candidates. Finally, we aggregate the predictions of each of the models participating in the ensemble to predict the final segmentation. Results suggest the proposed method reaches state-of-the-art performance on the Essen Folksong dataset under the unsupervised setting when considering F-Score and R-value. We additionally provide an ablation study to better assess the contribution of each of the model components to the final results. As expected, the proposed method is inferior to the supervised setting, which leaves room for improvement in future research considering closing the gap between unsupervised and supervised methods.

</p>
</details>

<details><summary><b>A Graph Isomorphism Network with Weighted Multiple Aggregators for Speech Emotion Recognition</b>
<a href="https://arxiv.org/abs/2207.00940">arxiv:2207.00940</a>
&#x1F4C8; 4 <br>
<p>Ying Hu, Yuwu Tang, Hao Huang, Liang He</p></summary>
<p>

**Abstract:** Speech emotion recognition (SER) is an essential part of human-computer interaction. In this paper, we propose an SER network based on a Graph Isomorphism Network with Weighted Multiple Aggregators (WMA-GIN), which can effectively handle the problem of information confusion when neighbour nodes' features are aggregated together in GIN structure. Moreover, a Full-Adjacent (FA) layer is adopted for alleviating the over-squashing problem, which is existed in all Graph Neural Network (GNN) structures, including GIN. Furthermore, a multi-phase attention mechanism and multi-loss training strategy are employed to avoid missing the useful emotional information in the stacked WMA-GIN layers. We evaluated the performance of our proposed WMA-GIN on the popular IEMOCAP dataset. The experimental results show that WMA-GIN outperforms other GNN-based methods and is comparable to some advanced non-graph-based methods by achieving 72.48% of weighted accuracy (WA) and 67.72% of unweighted accuracy (UA).

</p>
</details>

<details><summary><b>Interpretable by Design: Learning Predictors by Composing Interpretable Queries</b>
<a href="https://arxiv.org/abs/2207.00938">arxiv:2207.00938</a>
&#x1F4C8; 4 <br>
<p>Aditya Chattopadhyay, Stewart Slocum, Benjamin D. Haeffele, Rene Vidal, Donald Geman</p></summary>
<p>

**Abstract:** There is a growing concern about typically opaque decision-making with high-performance machine learning algorithms. Providing an explanation of the reasoning process in domain-specific terms can be crucial for adoption in risk-sensitive domains such as healthcare. We argue that machine learning algorithms should be interpretable by design and that the language in which these interpretations are expressed should be domain- and task-dependent. Consequently, we base our model's prediction on a family of user-defined and task-specific binary functions of the data, each having a clear interpretation to the end-user. We then minimize the expected number of queries needed for accurate prediction on any given input. As the solution is generally intractable, following prior work, we choose the queries sequentially based on information gain. However, in contrast to previous work, we need not assume the queries are conditionally independent. Instead, we leverage a stochastic generative model (VAE) and an MCMC algorithm (Unadjusted Langevin) to select the most informative query about the input based on previous query-answers. This enables the online determination of a query chain of whatever depth is required to resolve prediction ambiguities. Finally, experiments on vision and NLP tasks demonstrate the efficacy of our approach and its superiority over post-hoc explanations.

</p>
</details>

<details><summary><b>Combinatory Adjoints and Differentiation</b>
<a href="https://arxiv.org/abs/2207.00847">arxiv:2207.00847</a>
&#x1F4C8; 4 <br>
<p>Martin Elsman, Fritz Henglein, Robin Kaarsgaard, Mikkel Kragh Mathiesen, Robert Schenck</p></summary>
<p>

**Abstract:** We develop a compositional approach for automatic and symbolic differentiation based on categorical constructions in functional analysis where derivatives are linear functions on abstract vectors rather than being limited to scalars, vectors, matrices or tensors represented as multi-dimensional arrays. We show that both symbolic and automatic differentiation can be performed using a differential calculus for generating linear functions representing Fréchet derivatives based on rules for primitive, constant, linear and bilinear functions as well as their sequential and parallel composition. Linear functions are represented in a combinatory domain-specific language. Finally, we provide a calculus for symbolically computing the adjoint of a derivative without using matrices, which are too inefficient to use on high-dimensional spaces. The resulting symbolic representation of a derivative retains the data-parallel operations from the input program. The combination of combinatory differentiation and computing formal adjoints turns out to be behaviorally equivalent to reverse-mode automatic differentiation. In particular, it provides opportunities for optimizations where matrices are too inefficient to represent linear functions.

</p>
</details>

<details><summary><b>ANEC: An Amharic Named Entity Corpus and Transformer Based Recognizer</b>
<a href="https://arxiv.org/abs/2207.00785">arxiv:2207.00785</a>
&#x1F4C8; 4 <br>
<p>Ebrahim Chekol Jibril, A. Cüneyd Tantğ</p></summary>
<p>

**Abstract:** Named Entity Recognition is an information extraction task that serves as a preprocessing step for other natural language processing tasks, such as machine translation, information retrieval, and question answering. Named entity recognition enables the identification of proper names as well as temporal and numeric expressions in an open domain text. For Semitic languages such as Arabic, Amharic, and Hebrew, the named entity recognition task is more challenging due to the heavily inflected structure of these languages. In this paper, we present an Amharic named entity recognition system based on bidirectional long short-term memory with a conditional random fields layer. We annotate a new Amharic named entity recognition dataset (8,070 sentences, which has 182,691 tokens) and apply Synthetic Minority Over-sampling Technique to our dataset to mitigate the imbalanced classification problem. Our named entity recognition system achieves an F_1 score of 93%, which is the new state-of-the-art result for Amharic named entity recognition.

</p>
</details>

<details><summary><b>Backdoor Attack is A Devil in Federated GAN-based Medical Image Synthesis</b>
<a href="https://arxiv.org/abs/2207.00762">arxiv:2207.00762</a>
&#x1F4C8; 4 <br>
<p>Ruinan Jin, Xiaoxiao Li</p></summary>
<p>

**Abstract:** Deep Learning-based image synthesis techniques have been applied in healthcare research for generating medical images to support open research. Training generative adversarial neural networks (GAN) usually requires large amounts of training data. Federated learning (FL) provides a way of training a central model using distributed data from different medical institutions while keeping raw data locally. However, FL is vulnerable to backdoor attack, an adversarial by poisoning training data, given the central server cannot access the original data directly. Most backdoor attack strategies focus on classification models and centralized domains. In this study, we propose a way of attacking federated GAN (FedGAN) by treating the discriminator with a commonly used data poisoning strategy in backdoor attack classification models. We demonstrate that adding a small trigger with size less than 0.5 percent of the original image size can corrupt the FL-GAN model. Based on the proposed attack, we provide two effective defense strategies: global malicious detection and local training regularization. We show that combining the two defense strategies yields a robust medical image generation.

</p>
</details>

<details><summary><b>Deep Learning for Systemic Risk Measures</b>
<a href="https://arxiv.org/abs/2207.00739">arxiv:2207.00739</a>
&#x1F4C8; 4 <br>
<p>Yichen Feng, Ming Min, Jean-Pierre Fouque</p></summary>
<p>

**Abstract:** The aim of this paper is to study a new methodological framework for systemic risk measures by applying deep learning method as a tool to compute the optimal strategy of capital allocations. Under this new framework, systemic risk measures can be interpreted as the minimal amount of cash that secures the aggregated system by allocating capital to the single institutions before aggregating the individual risks. This problem has no explicit solution except in very limited situations. Deep learning is increasingly receiving attention in financial modelings and risk management and we propose our deep learning based algorithms to solve both the primal and dual problems of the risk measures, and thus to learn the fair risk allocations. In particular, our method for the dual problem involves the training philosophy inspired by the well-known Generative Adversarial Networks (GAN) approach and a newly designed direct estimation of Radon-Nikodym derivative. We close the paper with substantial numerical studies of the subject and provide interpretations of the risk allocations associated to the systemic risk measures. In the particular case of exponential preferences, numerical experiments demonstrate excellent performance of the proposed algorithm, when compared with the optimal explicit solution as a benchmark.

</p>
</details>

<details><summary><b>SKIPP'D: a SKy Images and Photovoltaic Power Generation Dataset for Short-term Solar Forecasting</b>
<a href="https://arxiv.org/abs/2207.00913">arxiv:2207.00913</a>
&#x1F4C8; 3 <br>
<p>Yuhao Nie, Xiatong Li, Andea Scott, Yuchi Sun, Vignesh Venugopal, Adam Brandt</p></summary>
<p>

**Abstract:** Large-scale integration of photovoltaics (PV) into electricity grids is challenged by the intermittent nature of solar power. Sky-image-based solar forecasting using deep learning has been recognized as a promising approach to predicting the short-term fluctuations. However, there are few publicly available standardized benchmark datasets for image-based solar forecasting, which limits the comparison of different forecasting models and the exploration of forecasting methods. To fill these gaps, we introduce SKIPP'D -- a SKy Images and Photovoltaic Power Generation Dataset. The dataset contains three years (2017-2019) of quality-controlled down-sampled sky images and PV power generation data that is ready-to-use for short-term solar forecasting using deep learning. In addition, to support the flexibility in research, we provide the high resolution, high frequency sky images and PV power generation data as well as the concurrent sky video footage. We also include a code base containing data processing scripts and baseline model implementations for researchers to reproduce our previous work and accelerate their research in solar forecasting.

</p>
</details>

<details><summary><b>Tree ensemble kernels for Bayesian optimization with known constraints over mixed-feature spaces</b>
<a href="https://arxiv.org/abs/2207.00879">arxiv:2207.00879</a>
&#x1F4C8; 3 <br>
<p>Alexander Thebelt, Calvin Tsay, Robert M. Lee, Nathan Sudermann-Merx, David Walz, Behrang Shafei, Ruth Misener</p></summary>
<p>

**Abstract:** Tree ensembles can be well-suited for black-box optimization tasks such as algorithm tuning and neural architecture search, as they achieve good predictive performance with little to no manual tuning, naturally handle discrete feature spaces, and are relatively insensitive to outliers in the training data. Two well-known challenges in using tree ensembles for black-box optimization are (i) effectively quantifying model uncertainty for exploration and (ii) optimizing over the piece-wise constant acquisition function. To address both points simultaneously, we propose using the kernel interpretation of tree ensembles as a Gaussian Process prior to obtain model variance estimates, and we develop a compatible optimization formulation for the acquisition function. The latter further allows us to seamlessly integrate known constraints to improve sampling efficiency by considering domain-knowledge in engineering settings and modeling search space symmetries, e.g., hierarchical relationships in neural architecture search. Our framework performs as well as state-of-the-art methods for unconstrained black-box optimization over continuous/discrete features and outperforms competing methods for problems combining mixed-variable feature spaces and known input constraints.

</p>
</details>

<details><summary><b>Domain-Adaptive 3D Medical Image Synthesis: An Efficient Unsupervised Approach</b>
<a href="https://arxiv.org/abs/2207.00844">arxiv:2207.00844</a>
&#x1F4C8; 3 <br>
<p>Qingqiao Hu, Hongwei Li, Jianguo Zhang</p></summary>
<p>

**Abstract:** Medical image synthesis has attracted increasing attention because it could generate missing image data, improving diagnosis and benefits many downstream tasks. However, so far the developed synthesis model is not adaptive to unseen data distribution that presents domain shift, limiting its applicability in clinical routine. This work focuses on exploring domain adaptation (DA) of 3D image-to-image synthesis models. First, we highlight the technical difference in DA between classification, segmentation and synthesis models. Second, we present a novel efficient adaptation approach based on 2D variational autoencoder which approximates 3D distributions. Third, we present empirical studies on the effect of the amount of adaptation data and the key hyper-parameters. Our results show that the proposed approach can significantly improve the synthesis accuracy on unseen domains in a 3D setting. The code is publicly available at https://github.com/WinstonHuTiger/2D_VAE_UDA_for_3D_sythesis

</p>
</details>

<details><summary><b>GOF-TTE: Generative Online Federated Learning Framework for Travel Time Estimation</b>
<a href="https://arxiv.org/abs/2207.00838">arxiv:2207.00838</a>
&#x1F4C8; 3 <br>
<p>Zhiwen Zhang, Hongjun Wang, Jiyuan Chen, Zipei Fan, Xuan Song, Ryosuke Shibasaki</p></summary>
<p>

**Abstract:** Estimating the travel time of a path is an essential topic for intelligent transportation systems. It serves as the foundation for real-world applications, such as traffic monitoring, route planning, and taxi dispatching. However, building a model for such a data-driven task requires a large amount of users' travel information, which directly relates to their privacy and thus is less likely to be shared. The non-Independent and Identically Distributed (non-IID) trajectory data across data owners also make a predictive model extremely challenging to be personalized if we directly apply federated learning. Finally, previous work on travel time estimation does not consider the real-time traffic state of roads, which we argue can significantly influence the prediction. To address the above challenges, we introduce GOF-TTE for the mobile user group, Generative Online Federated Learning Framework for Travel Time Estimation, which I) utilizes the federated learning approach, allowing private data to be kept on client devices while training, and designs the global model as an online generative model shared by all clients to infer the real-time road traffic state. II) apart from sharing a base model at the server, adapts a fine-tuned personalized model for every client to study their personal driving habits, making up for the residual error made by localized global model prediction. % III) designs the global model as an online generative model shared by all clients to infer the real-time road traffic state. We also employ a simple privacy attack to our framework and implement the differential privacy mechanism to further guarantee privacy safety. Finally, we conduct experiments on two real-world public taxi datasets of DiDi Chengdu and Xi'an. The experimental results demonstrate the effectiveness of our proposed framework.

</p>
</details>

<details><summary><b>A Multi-Task BERT Model for Schema-Guided Dialogue State Tracking</b>
<a href="https://arxiv.org/abs/2207.00828">arxiv:2207.00828</a>
&#x1F4C8; 3 <br>
<p>Eleftherios Kapelonis, Efthymios Georgiou, Alexandros Potamianos</p></summary>
<p>

**Abstract:** Task-oriented dialogue systems often employ a Dialogue State Tracker (DST) to successfully complete conversations. Recent state-of-the-art DST implementations rely on schemata of diverse services to improve model robustness and handle zero-shot generalization to new domains [1], however such methods [2, 3] typically require multiple large scale transformer models and long input sequences to perform well. We propose a single multi-task BERT-based model that jointly solves the three DST tasks of intent prediction, requested slot prediction and slot filling. Moreover, we propose an efficient and parsimonious encoding of the dialogue history and service schemata that is shown to further improve performance. Evaluation on the SGD dataset shows that our approach outperforms the baseline SGP-DST by a large margin and performs well compared to the state-of-the-art, while being significantly more computationally efficient. Extensive ablation studies are performed to examine the contributing factors to the success of our model.

</p>
</details>

<details><summary><b>PGMG: A Pharmacophore-Guided Deep Learning Approach for Bioactive Molecular Generation</b>
<a href="https://arxiv.org/abs/2207.00821">arxiv:2207.00821</a>
&#x1F4C8; 3 <br>
<p>Huimin Zhu, Renyi Zhou, Jing Tang, Min Li</p></summary>
<p>

**Abstract:** The rational design of novel molecules with desired bioactivity is a critical but challenging task in drug discovery, especially when treating a novel target family or understudied targets. Here, we propose PGMG, a pharmacophore-guided deep learning approach for bioactivate molecule generation. Through the guidance of pharmacophore, PGMG provides a flexible strategy to generate bioactive molecules with structural diversity in various scenarios using a trained variational autoencoder. We show that PGMG can generate molecules matching given pharmacophore models while maintaining a high level of validity, uniqueness, and novelty. In the case studies, we demonstrate the application of PGMG to generate bioactive molecules in ligand-based and structure-based drug de novo design, as well as in lead optimization scenarios. Overall, the flexibility and effectiveness of PGMG make it a useful tool for accelerating the drug discovery process.

</p>
</details>

<details><summary><b>On the modern deep learning approaches for precipitation downscaling</b>
<a href="https://arxiv.org/abs/2207.00808">arxiv:2207.00808</a>
&#x1F4C8; 3 <br>
<p>Bipin Kumar, Kaustubh Atey, Bhupendra Bahadur Singh, Rajib Chattopadhyay, Nachiket Acharya, Manmeet Singh, Ravi S. Nanjundiah, Suryachandra A. Rao</p></summary>
<p>

**Abstract:** Deep Learning (DL) based downscaling has become a popular tool in earth sciences recently. Increasingly, different DL approaches are being adopted to downscale coarser precipitation data and generate more accurate and reliable estimates at local (~few km or even smaller) scales. Despite several studies adopting dynamical or statistical downscaling of precipitation, the accuracy is limited by the availability of ground truth. A key challenge to gauge the accuracy of such methods is to compare the downscaled data to point-scale observations which are often unavailable at such small scales. In this work, we carry out the DL-based downscaling to estimate the local precipitation data from the India Meteorological Department (IMD), which was created by approximating the value from station location to a grid point. To test the efficacy of different DL approaches, we apply four different methods of downscaling and evaluate their performance. The considered approaches are (i) Deep Statistical Downscaling (DeepSD), augmented Convolutional Long Short Term Memory (ConvLSTM), fully convolutional network (U-NET), and Super-Resolution Generative Adversarial Network (SR-GAN). A custom VGG network, used in the SR-GAN, is developed in this work using precipitation data. The results indicate that SR-GAN is the best method for precipitation data downscaling. The downscaled data is validated with precipitation values at IMD station. This DL method offers a promising alternative to statistical downscaling.

</p>
</details>

<details><summary><b>Pair-Relationship Modeling for Latent Fingerprint Recognition</b>
<a href="https://arxiv.org/abs/2207.00587">arxiv:2207.00587</a>
&#x1F4C8; 3 <br>
<p>Yanming Zhu, Xuefei Yin, Xiuping Jia, Jiankun Hu</p></summary>
<p>

**Abstract:** Latent fingerprints are important for identifying criminal suspects. However, recognizing a latent fingerprint in a collection of reference fingerprints remains a challenge. Most, if not all, of existing methods would extract representation features of each fingerprint independently and then compare the similarity of these representation features for recognition in a different process. Without the supervision of similarity for the feature extraction process, the extracted representation features are hard to optimally reflect the similarity of the two compared fingerprints which is the base for matching decision making. In this paper, we propose a new scheme that can model the pair-relationship of two fingerprints directly as the similarity feature for recognition. The pair-relationship is modeled by a hybrid deep network which can handle the difficulties of random sizes and corrupted areas of latent fingerprints. Experimental results on two databases show that the proposed method outperforms the state of the art.

</p>
</details>

<details><summary><b>Comparing the Utility and Disclosure Risk of Synthetic Data with Samples of Microdata</b>
<a href="https://arxiv.org/abs/2207.03339">arxiv:2207.03339</a>
&#x1F4C8; 2 <br>
<p>Claire Little, Mark Elliot, Richard Allmendinger</p></summary>
<p>

**Abstract:** Most statistical agencies release randomly selected samples of Census microdata, usually with sample fractions under 10% and with other forms of statistical disclosure control (SDC) applied. An alternative to SDC is data synthesis, which has been attracting growing interest, yet there is no clear consensus on how to measure the associated utility and disclosure risk of the data. The ability to produce synthetic Census microdata, where the utility and associated risks are clearly understood, could mean that more timely and wider-ranging access to microdata would be possible.
  This paper follows on from previous work by the authors which mapped synthetic Census data on a risk-utility (R-U) map. The paper presents a framework to measure the utility and disclosure risk of synthetic data by comparing it to samples of the original data of varying sample fractions, thereby identifying the sample fraction which has equivalent utility and risk to the synthetic data. Three commonly used data synthesis packages are compared with some interesting results. Further work is needed in several directions but the methodology looks very promising.

</p>
</details>

<details><summary><b>Wireless Channel Prediction in Partially Observed Environments</b>
<a href="https://arxiv.org/abs/2207.00934">arxiv:2207.00934</a>
&#x1F4C8; 2 <br>
<p>Mingsheng Yin, Yaqi Hu, Tommy Azzino, Seongjoon Kang, Marco Mezzavilla, Sundeep Rangan</p></summary>
<p>

**Abstract:** Site-specific radio frequency (RF) propagation prediction increasingly relies on models built from visual data such as cameras and LIDAR sensors. When operating in dynamic settings, the environment may only be partially observed. This paper introduces a method to extract statistical channel models, given partial observations of the surrounding environment. We propose a simple heuristic algorithm that performs ray tracing on the partial environment and then uses machine-learning trained predictors to estimate the channel and its uncertainty from features extracted from the partial ray tracing results. It is shown that the proposed method can interpolate between fully statistical models when no partial information is available and fully deterministic models when the environment is completely observed. The method can also capture the degree of uncertainty of the propagation predictions depending on the amount of region that has been explored. The methodology is demonstrated in a robotic navigation application simulated on a set of indoor maps with detailed models constructed using state-of-the-art navigation, simultaneous localization and mapping (SLAM), and computer vision methods.

</p>
</details>

<details><summary><b>An AlphaZero-Inspired Approach to Solving Search Problems</b>
<a href="https://arxiv.org/abs/2207.00919">arxiv:2207.00919</a>
&#x1F4C8; 2 <br>
<p>Evgeny Dantsin, Vladik Kreinovich, Alexander Wolpert</p></summary>
<p>

**Abstract:** AlphaZero and its extension MuZero are computer programs that use machine-learning techniques to play at a superhuman level in chess, go, and a few other games. They achieved this level of play solely with reinforcement learning from self-play, without any domain knowledge except the game rules. It is a natural idea to adapt the methods and techniques used in AlphaZero for solving search problems such as the Boolean satisfiability problem (in its search version). Given a search problem, how to represent it for an AlphaZero-inspired solver? What are the "rules of solving" for this search problem? We describe possible representations in terms of easy-instance solvers and self-reductions, and we give examples of such representations for the satisfiability problem. We also describe a version of Monte Carlo tree search adapted for search problems.

</p>
</details>

<details><summary><b>Local Max-Entropy and Free Energy Principles Solved by Belief Propagation</b>
<a href="https://arxiv.org/abs/2207.00841">arxiv:2207.00841</a>
&#x1F4C8; 2 <br>
<p>Olivier Peltre</p></summary>
<p>

**Abstract:** A statistical system is classically defined on a set of microstates $E$ by a global energy function $H : E \to \mathbb{R}$, yielding Gibbs probability measures (softmins) $ρ^β(H)$ for every inverse temperature $β= T^{-1}$. Gibbs states are simultaneously characterized by free energy principles and the max-entropy principle, with dual constraints on inverse temperature $β$ and mean energy ${\cal U}(β) = \mathbb{E}_{ρ^β}[H]$ respectively. The Legendre transform relates these diverse variational principles which are unfortunately not tractable in high dimension.
  The global energy is generally given as a sum $H(x) = \sum_{\rm a \subset Ω} h_{\rm a}(x_{|\rm a})$ of local short-range interactions $h_{\rm a} : E_{\rm a} \to \mathbb{R}$ indexed by bounded subregions ${\rm a} \subset Ω$, and this local structure can be used to design good approximation schemes on thermodynamic functionals. We show that the generalized belief propagation (GBP) algorithm solves a collection of local variational principles, by converging to critical points of Bethe-Kikuchi approximations of the free energy $F(β)$, the Shannon entropy $S(\cal U)$, and the variational free energy ${\cal F}(β) = {\cal U} - β^{-1} S(\cal U)$, extending an initial correspondence by Yedidia et al. This local form of Legendre duality yields a possible degenerate relationship between mean energy ${\cal U}$ and $β$.

</p>
</details>

<details><summary><b>Firenze: Model Evaluation Using Weak Signals</b>
<a href="https://arxiv.org/abs/2207.00827">arxiv:2207.00827</a>
&#x1F4C8; 2 <br>
<p>Bhavna Soman, Ali Torkamani, Michael J. Morais, Jeffrey Bickford, Baris Coskun</p></summary>
<p>

**Abstract:** Data labels in the security field are frequently noisy, limited, or biased towards a subset of the population. As a result, commonplace evaluation methods such as accuracy, precision and recall metrics, or analysis of performance curves computed from labeled datasets do not provide sufficient confidence in the real-world performance of a machine learning (ML) model. This has slowed the adoption of machine learning in the field. In the industry today, we rely on domain expertise and lengthy manual evaluation to build this confidence before shipping a new model for security applications. In this paper, we introduce Firenze, a novel framework for comparative evaluation of ML models' performance using domain expertise, encoded into scalable functions called markers. We show that markers computed and combined over select subsets of samples called regions of interest can provide a robust estimate of their real-world performances. Critically, we use statistical hypothesis testing to ensure that observed differences-and therefore conclusions emerging from our framework-are more prominent than that observable from the noise alone. Using simulations and two real-world datasets for malware and domain-name-service reputation detection, we illustrate our approach's effectiveness, limitations, and insights. Taken together, we propose Firenze as a resource for fast, interpretable, and collaborative model development and evaluation by mixed teams of researchers, domain experts, and business owners.

</p>
</details>

<details><summary><b>Biologically-informed deep learning models for cancer: fundamental trends for encoding and interpreting oncology data</b>
<a href="https://arxiv.org/abs/2207.00812">arxiv:2207.00812</a>
&#x1F4C8; 2 <br>
<p>Magdalena Wysocka, Oskar Wysocki, Marie Zufferey, Dónal Landers, André Freitas</p></summary>
<p>

**Abstract:** In this paper we provide a structured literature analysis focused on Deep Learning (DL) models used to support inference in cancer biology with a particular emphasis on multi-omics analysis. The work focuses on how existing models address the need for better dialogue with prior knowledge, biological plausibility and interpretability, fundamental properties in the biomedical domain. We discuss the recent evolutionary arch of DL models in the direction of integrating prior biological relational and network knowledge to support better generalisation (e.g. pathways or Protein-Protein-Interaction networks) and interpretability. This represents a fundamental functional shift towards models which can integrate mechanistic and statistical inference aspects. We discuss representational methodologies for the integration of domain prior knowledge in such models. The paper also provides a critical outlook into contemporary methods for explainability and interpretabiltiy. This analysis points in the direction of a convergence between encoding prior knowledge and improved interpretability.

</p>
</details>

<details><summary><b>Eliciting and Learning with Soft Labels from Every Annotator</b>
<a href="https://arxiv.org/abs/2207.00810">arxiv:2207.00810</a>
&#x1F4C8; 2 <br>
<p>Katherine M. Collins, Umang Bhatt, Adrian Weller</p></summary>
<p>

**Abstract:** The labels used to train machine learning (ML) models are of paramount importance. Typically for ML classification tasks, datasets contain hard labels, yet learning using soft labels has been shown to yield benefits for model generalization, robustness, and calibration. Earlier work found success in forming soft labels from multiple annotators' hard labels; however, this approach may not converge to the best labels and necessitates many annotators, which can be expensive and inefficient. We focus on efficiently eliciting soft labels from individual annotators. We collect and release a dataset of soft labels for CIFAR-10 via a crowdsourcing study ($N=242$). We demonstrate that learning with our labels achieves comparable model performance to prior approaches while requiring far fewer annotators. Our elicitation methodology therefore shows promise towards enabling practitioners to enjoy the benefits of improved model performance and reliability with fewer annotators, and serves as a guide for future dataset curators on the benefits of leveraging richer information, such as categorical uncertainty, from individual annotators.

</p>
</details>

<details><summary><b>An AIoT-enabled Autonomous Dementia Monitoring System</b>
<a href="https://arxiv.org/abs/2207.00804">arxiv:2207.00804</a>
&#x1F4C8; 2 <br>
<p>Xingyu Wu, Jinyang Li</p></summary>
<p>

**Abstract:** An autonomous Artificial Internet of Things (AIoT) system for elderly dementia patients monitoring in a smart home is presented. The system mainly implements two functions based on the activity inference of the sensor data, which are real time abnormal activity monitoring and trend prediction of disease related activities. Specifically, CASAS dataset is employed to train a Random Forest (RF) model for activity inference. Then, another RF model trained by the output data of activity inference is used for abnormal activity monitoring. Particularly, RF is chosen for these tasks because of its balanced trade offs between accuracy, time efficiency, flexibility, and interpretability. Moreover, Long Short Term Memory (LSTM) is utilised to forecast the disease related activity trend of a patient. Consequently, the accuracy of two RF classifiers designed for activity inference and abnormal activity detection is greater than 99 percent and 94 percent, respectively. Furthermore, using the duration of sleep as an example, the LSTM model achieves accurate and evident future trends prediction.

</p>
</details>

<details><summary><b>Learning fast and agile quadrupedal locomotion over complex terrain</b>
<a href="https://arxiv.org/abs/2207.00797">arxiv:2207.00797</a>
&#x1F4C8; 2 <br>
<p>Xu Chang, Zhitong Zhang, Honglei An, Hongxu Ma, Qing Wei</p></summary>
<p>

**Abstract:** In this paper, we propose a robust controller that achieves natural and stably fast locomotion on a real blind quadruped robot. With only proprioceptive information, the quadruped robot can move at a maximum speed of 10 times its body length, and has the ability to pass through various complex terrains. The controller is trained in the simulation environment by model-free reinforcement learning. In this paper, the proposed loose neighborhood control architecture not only guarantees the learning rate, but also obtains an action network that is easy to transfer to a real quadruped robot. Our research finds that there is a problem of data symmetry loss during training, which leads to unbalanced performance of the learned controller on the left-right symmetric quadruped robot structure, and proposes a mirror-world neural network to solve the performance problem. The learned controller composed of the mirror-world network can make the robot achieve excellent anti-disturbance ability. No specific human knowledge such as a foot trajectory generator are used in the training architecture. The learned controller can coordinate the robot's gait frequency and locomotion speed, and the locomotion pattern is more natural and reasonable than the artificially designed controller. Our controller has excellent anti-disturbance performance, and has good generalization ability to reach locomotion speeds it has never learned and traverse terrains it has never seen before.

</p>
</details>

<details><summary><b>Unsupervised Recurrent Federated Learning for Edge Popularity Prediction in Privacy-Preserving Mobile Edge Computing Networks</b>
<a href="https://arxiv.org/abs/2207.00755">arxiv:2207.00755</a>
&#x1F4C8; 2 <br>
<p>Chong Zheng, Shengheng Liu, Yongming Huang, Wei Zhang, Luxi Yang</p></summary>
<p>

**Abstract:** Nowadays wireless communication is rapidly reshaping entire industry sectors. In particular, mobile edge computing (MEC) as an enabling technology for industrial Internet of things (IIoT) brings powerful computing/storage infrastructure closer to the mobile terminals and, thereby, significant lowers the response latency. To reap the benefit of proactive caching at the network edge, precise knowledge on the popularity pattern among the end devices is essential. However, the complex and dynamic nature of the content popularity over space and time as well as the data-privacy requirements in many IIoT scenarios pose tough challenges to its acquisition. In this article, we propose an unsupervised and privacy-preserving popularity prediction framework for MEC-enabled IIoT. The concepts of local and global popularities are introduced and the time-varying popularity of each user is modelled as a model-free Markov chain. On this basis, a novel unsupervised recurrent federated learning (URFL) algorithm is proposed to predict the distributed popularity while achieve privacy preservation and unsupervised training. Simulations indicate that the proposed framework can enhance the prediction accuracy in terms of a reduced root-mean-squared error by up to $60.5\%-68.7\%$. Additionally, manual labeling and violation of users' data privacy are both avoided.

</p>
</details>

<details><summary><b>PhilaeX: Explaining the Failure and Success of AI Models in Malware Detection</b>
<a href="https://arxiv.org/abs/2207.00740">arxiv:2207.00740</a>
&#x1F4C8; 2 <br>
<p>Zhi Lu, Vrizlynn L. L. Thing</p></summary>
<p>

**Abstract:** The explanation to an AI model's prediction used to support decision making in cyber security, is of critical importance. It is especially so when the model's incorrect prediction can lead to severe damages or even losses to lives and critical assets. However, most existing AI models lack the ability to provide explanations on their prediction results, despite their strong performance in most scenarios. In this work, we propose a novel explainable AI method, called PhilaeX, that provides the heuristic means to identify the optimized subset of features to form the complete explanations of AI models' predictions. It identifies the features that lead to the model's borderline prediction, and those with positive individual contributions are extracted. The feature attributions are then quantified through the optimization of a Ridge regression model. We verify the explanation fidelity through two experiments. First, we assess our method's capability in correctly identifying the activated features in the adversarial samples of Android malwares, through the features attribution values from PhilaeX. Second, the deduction and augmentation tests, are used to assess the fidelity of the explanations. The results show that PhilaeX is able to explain different types of classifiers correctly, with higher fidelity explanations, compared to the state-of-the-arts methods such as LIME and SHAP.

</p>
</details>

<details><summary><b>Accelerating System-Level Debug Using Rule Learning and Subgroup Discovery Techniques</b>
<a href="https://arxiv.org/abs/2207.00622">arxiv:2207.00622</a>
&#x1F4C8; 2 <br>
<p>Zurab Khasidashvili</p></summary>
<p>

**Abstract:** We propose a root-causing procedure for accelerating system-level debug using rule-based techniques. We describe the procedure and how it provides high quality debug hints for reducing the debug effort. This includes the heuristics for engineering features from logs of many tests, and the data analytics techniques for generating powerful debug hints. As a case study, we used these techniques for root-causing failures of the Power Management (PM) design feature Package-C8 and showed their effectiveness. Furthermore, we propose an approach for mining the root-causing experience and results for reuse, to accelerate future debug activities and reduce dependency on validation experts. We believe that these techniques are beneficial also for other validation activities at different levels of abstraction, for complex hardware, software and firmware systems, both pre-silicon and post-silicon.

</p>
</details>

<details><summary><b>A Structured Sparse Neural Network and Its Matrix Calculations Algorithm</b>
<a href="https://arxiv.org/abs/2207.00903">arxiv:2207.00903</a>
&#x1F4C8; 1 <br>
<p>Seyyed Mostafa Mousavi Janbeh Sarayi, Mansour Nikkhah Bahrami</p></summary>
<p>

**Abstract:** Gradient descent optimizations and backpropagation are the most common methods for training neural networks, but they are computationally expensive for real time applications, need high memory resources, and are difficult to converge for many networks and large datasets. [Pseudo]inverse models for training neural network have emerged as powerful tools to overcome these issues. In order to effectively implement these methods, structured pruning maybe be applied to produce sparse neural networks. Although sparse neural networks are efficient in memory usage, most of their algorithms use the same fully loaded matrix calculation methods which are not efficient for sparse matrices. Tridiagonal matrices are one of the frequently used candidates for structuring neural networks, but they are not flexible enough to handle underfitting and overfitting problems as well as generalization properties. In this paper, we introduce a nonsymmetric, tridiagonal matrix with offdiagonal sparse entries and offset sub and super-diagonals as well algorithms for its [pseudo]inverse and determinant calculations. Traditional algorithms for matrix calculations, specifically inversion and determinant, of these forms are not efficient specially for large matrices, e.g. larger datasets or deeper networks. A decomposition for lower triangular matrices is developed and the original matrix is factorized into a set of matrices where their inverse matrices are calculated. For the cases where the matrix inverse does not exist, a least square type pseudoinverse is provided. The present method is a direct routine, i.e., executes in a predictable number of operations which is tested for randomly generated matrices with varying size. The results show significant improvement in computational costs specially when the size of matrix increases.

</p>
</details>

<details><summary><b>Reinforcement Learning Approaches for the Orienteering Problem with Stochastic and Dynamic Release Dates</b>
<a href="https://arxiv.org/abs/2207.00885">arxiv:2207.00885</a>
&#x1F4C8; 1 <br>
<p>Yuanyuan Li, Claudia Archetti, Ivana Ljubic</p></summary>
<p>

**Abstract:** In this paper, we study a sequential decision making problem faced by e-commerce carriers related to when to send out a vehicle from the central depot to serve customer requests, and in which order to provide the service, under the assumption that the time at which parcels arrive at the depot is stochastic and dynamic. The objective is to maximize the number of parcels that can be delivered during the service hours. We propose two reinforcement learning approaches for solving this problem, one based on a policy function approximation (PFA) and the second on a value function approximation (VFA). Both methods are combined with a look-ahead strategy, in which future release dates are sampled in a Monte-Carlo fashion and a tailored batch approach is used to approximate the value of future states. Our PFA and VFA make a good use of branch-and-cut-based exact methods to improve the quality of decisions. We also establish sufficient conditions for partial characterization of optimal policy and integrate them into PFA/VFA. In an empirical study based on 720 benchmark instances, we conduct a competitive analysis using upper bounds with perfect information and we show that PFA and VFA greatly outperform two alternative myopic approaches. Overall, PFA provides best solutions, while VFA (which benefits from a two-stage stochastic optimization model) achieves a better tradeoff between solution quality and computing time.

</p>
</details>

<details><summary><b>Abstraction and Refinement: Towards Scalable and Exact Verification of Neural Networks</b>
<a href="https://arxiv.org/abs/2207.00759">arxiv:2207.00759</a>
&#x1F4C8; 1 <br>
<p>Jiaxiang Liu, Yunhan Xing, Xiaomu Shi, Fu Song, Zhiwu Xu, Zhong Ming</p></summary>
<p>

**Abstract:** As a new programming paradigm, deep neural networks (DNNs) have been increasingly deployed in practice, but the lack of robustness hinders their applications in safety-critical domains. While there are techniques for verifying DNNs with formal guarantees, they are limited in scalability and accuracy. In this paper, we present a novel abstraction-refinement approach for scalable and exact DNN verification. Specifically, we propose a novel abstraction to break down the size of DNNs by over-approximation. The result of verifying the abstract DNN is always conclusive if no spurious counterexample is reported. To eliminate spurious counterexamples introduced by abstraction, we propose a novel counterexample-guided refinement that refines the abstract DNN to exclude a given spurious counterexample while still over-approximating the original one. Our approach is orthogonal to and can be integrated with many existing verification techniques. For demonstration, we implement our approach using two promising and exact tools Marabou and Planet as the underlying verification engines, and evaluate on widely-used benchmarks ACAS Xu, MNIST and CIFAR-10. The results show that our approach can boost their performance by solving more problems and reducing up to 86.3% and 78.0% verification time, respectively. Compared to the most relevant abstraction-refinement approach, our approach is 11.6-26.6 times faster.

</p>
</details>

<details><summary><b>PS$^2$F: Polarized Spiral Point Spread Function for Single-Shot 3D Sensing</b>
<a href="https://arxiv.org/abs/2207.00945">arxiv:2207.00945</a>
&#x1F4C8; 0 <br>
<p>Bhargav Ghanekar, Vishwanath Saragadam, Dushyant Mehra, Anna-Karin Gustavsson, Aswin Sankaranarayanan, Ashok Veeraraghavan</p></summary>
<p>

**Abstract:** We propose a compact snapshot monocular depth estimation technique that relies on an engineered point spread function (PSF). Traditional approaches used in microscopic super-resolution imaging, such as the Double-Helix PSF (DHPSF), are ill-suited for scenes that are more complex than a sparse set of point light sources. We show, using the Cramér-Rao lower bound (CRLB), that separating the two lobes of the DHPSF and thereby capturing two separate images leads to a dramatic increase in depth accuracy. A unique property of the phase mask used for generating the DHPSF is that a separation of the phase mask into two halves leads to a spatial separation of the two lobes. We leverage this property to build a compact polarization-based optical setup, where we place two orthogonal linear polarizers on each half of the DHPSF phase mask and then capture the resulting image with a polarization sensitive camera. Results from simulations and a lab prototype demonstrate that our technique achieves up to $50\%$ lower depth error compared to state-of-the-art designs including the DHPSF, and the Tetrapod PSF, with little to no loss in spatial resolution.

</p>
</details>

<details><summary><b>Computer-assisted Pronunciation Training -- Speech synthesis is almost all you need</b>
<a href="https://arxiv.org/abs/2207.00774">arxiv:2207.00774</a>
&#x1F4C8; 0 <br>
<p>Daniel Korzekwa, Jaime Lorenzo-Trueba, Thomas Drugman, Bozena Kostek</p></summary>
<p>

**Abstract:** The research community has long studied computer-assisted pronunciation training (CAPT) methods in non-native speech. Researchers focused on studying various model architectures, such as Bayesian networks and deep learning methods, as well as on the analysis of different representations of the speech signal. Despite significant progress in recent years, existing CAPT methods are not able to detect pronunciation errors with high accuracy (only 60\% precision at 40\%-80\% recall). One of the key problems is the low availability of mispronounced speech that is needed for the reliable training of pronunciation error detection models. If we had a generative model that could mimic non-native speech and produce any amount of training data, then the task of detecting pronunciation errors would be much easier. We present three innovative techniques based on phoneme-to-phoneme (P2P), text-to-speech (T2S), and speech-to-speech (S2S) conversion to generate correctly pronounced and mispronounced synthetic speech. We show that these techniques not only improve the accuracy of three machine learning models for detecting pronunciation errors but also help establish a new state-of-the-art in the field. Earlier studies have used simple speech generation techniques such as P2P conversion, but only as an additional mechanism to improve the accuracy of pronunciation error detection. We, on the other hand, consider speech generation to be the first-class method of detecting pronunciation errors. The effectiveness of these techniques is assessed in the tasks of detecting pronunciation and lexical stress errors. Non-native English speech corpora of German, Italian, and Polish speakers are used in the evaluations. The best proposed S2S technique improves the accuracy of detecting pronunciation errors in AUC metric by 41\% from 0.528 to 0.749 compared to the state-of-the-art approach.

</p>
</details>


{% endraw %}
Prev: [2022.07.01]({{ '/2022/07/01/2022.07.01.html' | relative_url }})  Next: [2022.07.03]({{ '/2022/07/03/2022.07.03.html' | relative_url }})