Prev: [2022.08.12]({{ '/2022/08/12/2022.08.12.html' | relative_url }})  Next: [2022.08.14]({{ '/2022/08/14/2022.08.14.html' | relative_url }})
{% raw %}
## Summary for 2022-08-13, created on 2022-08-17


<details><summary><b>Modeling Network-level Traffic Flow Transitions on Sparse Data</b>
<a href="https://arxiv.org/abs/2208.06646">arxiv:2208.06646</a>
&#x1F4C8; 5 <br>
<p>Xiaoliang Lei, Hao Mei, Bin Shi, Hua Wei</p></summary>
<p>

**Abstract:** Modeling how network-level traffic flow changes in the urban environment is useful for decision-making in transportation, public safety and urban planning. The traffic flow system can be viewed as a dynamic process that transits between states (e.g., traffic volumes on each road segment) over time. In the real-world traffic system with traffic operation actions like traffic signal control or reversible lane changing, the system's state is influenced by both the historical states and the actions of traffic operations. In this paper, we consider the problem of modeling network-level traffic flow under a real-world setting, where the available data is sparse (i.e., only part of the traffic system is observed). We present DTIGNN, an approach that can predict network-level traffic flows from sparse data. DTIGNN models the traffic system as a dynamic graph influenced by traffic signals, learns the transition models grounded by fundamental transition equations from transportation, and predicts future traffic states with imputation in the process. Through comprehensive experiments, we demonstrate that our method outperforms state-of-the-art methods and can better support decision-making in transportation.

</p>
</details>

<details><summary><b>TL;DW? Summarizing Instructional Videos with Task Relevance & Cross-Modal Saliency</b>
<a href="https://arxiv.org/abs/2208.06773">arxiv:2208.06773</a>
&#x1F4C8; 3 <br>
<p>Medhini Narasimhan, Arsha Nagrani, Chen Sun, Michael Rubinstein, Trevor Darrell, Anna Rohrbach, Cordelia Schmid</p></summary>
<p>

**Abstract:** YouTube users looking for instructions for a specific task may spend a long time browsing content trying to find the right video that matches their needs. Creating a visual summary (abridged version of a video) provides viewers with a quick overview and massively reduces search time. In this work, we focus on summarizing instructional videos, an under-explored area of video summarization. In comparison to generic videos, instructional videos can be parsed into semantically meaningful segments that correspond to important steps of the demonstrated task. Existing video summarization datasets rely on manual frame-level annotations, making them subjective and limited in size. To overcome this, we first automatically generate pseudo summaries for a corpus of instructional videos by exploiting two key assumptions: (i) relevant steps are likely to appear in multiple videos of the same task (Task Relevance), and (ii) they are more likely to be described by the demonstrator verbally (Cross-Modal Saliency). We propose an instructional video summarization network that combines a context-aware temporal video encoder and a segment scoring transformer. Using pseudo summaries as weak supervision, our network constructs a visual summary for an instructional video given only video and transcribed speech. To evaluate our model, we collect a high-quality test set, WikiHow Summaries, by scraping WikiHow articles that contain video demonstrations and visual depictions of steps allowing us to obtain the ground-truth summaries. We outperform several baselines and a state-of-the-art video summarization model on this new benchmark.

</p>
</details>

<details><summary><b>Machine Learning Based Radiomics for Glial Tumor Classification and Comparison with Volumetric Analysis</b>
<a href="https://arxiv.org/abs/2208.06739">arxiv:2208.06739</a>
&#x1F4C8; 3 <br>
<p>Sevcan Turk, Kaya Oguz, Mehmet Orman, Emre Caliskan, Yesim Ertan, Erkin Ozgiray, Taner Akalin, Ashok Srinivasan, Omer Kitis</p></summary>
<p>

**Abstract:** Purpose; The purpose of this study is to classify glial tumors into grade II, III and IV categories noninvasively by application of machine learning to multi-modal MRI features in comparison with volumetric analysis. Methods; We retrospectively studied 57 glioma patients with pre and postcontrast T1 weighted, T2 weighted, FLAIR images, and ADC maps acquired on a 3T MRI. The tumors were segmented into enhancing and nonenhancing portions, tumor necrosis, cyst and edema using semiautomated segmentation of ITK-SNAP open source tool. We measured total tumor volume, enhancing-nonenhancing tumor, edema, necrosis volume and the ratios to the total tumor volume. Training of a support vector machine (SVM) classifier and artificial neural network (ANN) was performed with labeled data designed to answer the question of interest. Specificity, sensitivity, and AUC of the predictions were computed by means of ROC analysis. Differences in continuous measures between groups were assessed by using Kruskall Wallis, with post hoc Dunn correction for multiple comparisons. Results; When we compared the volume ratios between groups, there was statistically significant difference between grade IV and grade II-III glial tumors. Edema and tumor necrosis volume ratios for grade IV glial tumors were higher than that of grade II and III. Volumetric ratio analysis could not distinguish grade II and III tumors successfully. However, SVM and ANN correctly classified each group with accuracies up to 98% and 96%. Conclusion; Application of machine learning methods to MRI features can be used to classify brain tumors noninvasively and more readily in clinical settings.

</p>
</details>

<details><summary><b>Learning Linear Non-Gaussian Polytree Models</b>
<a href="https://arxiv.org/abs/2208.06701">arxiv:2208.06701</a>
&#x1F4C8; 3 <br>
<p>Daniele Tramontano, Anthea Monod, Mathias Drton</p></summary>
<p>

**Abstract:** In the context of graphical causal discovery, we adapt the versatile framework of linear non-Gaussian acyclic models (LiNGAMs) to propose new algorithms to efficiently learn graphs that are polytrees. Our approach combines the Chow--Liu algorithm, which first learns the undirected tree structure, with novel schemes to orient the edges. The orientation schemes assess algebraic relations among moments of the data-generating distribution and are computationally inexpensive. We establish high-dimensional consistency results for our approach and compare different algorithmic versions in numerical experiments.

</p>
</details>

<details><summary><b>Combating Label Distribution Shift for Active Domain Adaptation</b>
<a href="https://arxiv.org/abs/2208.06604">arxiv:2208.06604</a>
&#x1F4C8; 3 <br>
<p>Sehyun Hwang, Sohyun Lee, Sungyeon Kim, Jungseul Ok, Suha Kwak</p></summary>
<p>

**Abstract:** We consider the problem of active domain adaptation (ADA) to unlabeled target data, of which subset is actively selected and labeled given a budget constraint. Inspired by recent analysis on a critical issue from label distribution mismatch between source and target in domain adaptation, we devise a method that addresses the issue for the first time in ADA. At its heart lies a novel sampling strategy, which seeks target data that best approximate the entire target distribution as well as being representative, diverse, and uncertain. The sampled target data are then used not only for supervised learning but also for matching label distributions of source and target domains, leading to remarkable performance improvement. On four public benchmarks, our method substantially outperforms existing methods in every adaptation scenario.

</p>
</details>

<details><summary><b>Predicting skull fractures via CNN with classification algorithms</b>
<a href="https://arxiv.org/abs/2208.06756">arxiv:2208.06756</a>
&#x1F4C8; 2 <br>
<p>Md Moniruzzaman Emon, Tareque Rahman Ornob, Moqsadur Rahman</p></summary>
<p>

**Abstract:** Computer Tomography (CT) images have become quite important to diagnose diseases. CT scan slice contains a vast amount of data that may not be properly examined with the requisite precision and speed using normal visual inspection. A computer-assisted skull fracture classification expert system is needed to assist physicians. Convolutional Neural Networks (CNNs) are the most extensively used deep learning models for image categorization since most often time they outperform other models in terms of accuracy and results. The CNN models were then developed and tested, and several convolutional neural network (CNN) architectures were compared. ResNet50, which was used for feature extraction combined with a gradient boosted decision tree machine learning algorithm to act as a classifier for the categorization of skull fractures from brain CT scans into three fracture categories, had the best overall F1-score of 96%, Hamming Score of 95%, Balanced accuracy Score of 94% & ROC AUC curve of 96% for the classification of skull fractures.

</p>
</details>

<details><summary><b>An Empirical Comparison of Explainable Artificial Intelligence Methods for Clinical Data: A Case Study on Traumatic Brain Injury</b>
<a href="https://arxiv.org/abs/2208.06717">arxiv:2208.06717</a>
&#x1F4C8; 2 <br>
<p>Amin Nayebi, Sindhu Tipirneni, Brandon Foreman, Chandan K. Reddy, Vignesh Subbian</p></summary>
<p>

**Abstract:** A longstanding challenge surrounding deep learning algorithms is unpacking and understanding how they make their decisions. Explainable Artificial Intelligence (XAI) offers methods to provide explanations of internal functions of algorithms and reasons behind their decisions in ways that are interpretable and understandable to human users. . Numerous XAI approaches have been developed thus far, and a comparative analysis of these strategies seems necessary to discern their relevance to clinical prediction models. To this end, we first implemented two prediction models for short- and long-term outcomes of traumatic brain injury (TBI) utilizing structured tabular as well as time-series physiologic data, respectively. Six different interpretation techniques were used to describe both prediction models at the local and global levels. We then performed a critical analysis of merits and drawbacks of each strategy, highlighting the implications for researchers who are interested in applying these methodologies. The implemented methods were compared to one another in terms of several XAI characteristics such as understandability, fidelity, and stability. Our findings show that SHAP is the most stable with the highest fidelity but falls short of understandability. Anchors, on the other hand, is the most understandable approach, but it is only applicable to tabular data and not time series data.

</p>
</details>

<details><summary><b>UAV-CROWD: Violent and non-violent crowd activity simulator from the perspective of UAV</b>
<a href="https://arxiv.org/abs/2208.06702">arxiv:2208.06702</a>
&#x1F4C8; 2 <br>
<p>Mahieyin Rahmun, Tonmoay Deb, Shahriar Ali Bijoy, Mayamin Hamid Raha</p></summary>
<p>

**Abstract:** Unmanned Aerial Vehicle (UAV) has gained significant traction in the recent years, particularly the context of surveillance. However, video datasets that capture violent and non-violent human activity from aerial point-of-view is scarce. To address this issue, we propose a novel, baseline simulator which is capable of generating sequences of photo-realistic synthetic images of crowds engaging in various activities that can be categorized as violent or non-violent. The crowd groups are annotated with bounding boxes that are automatically computed using semantic segmentation. Our simulator is capable of generating large, randomized urban environments and is able to maintain an average of 25 frames per second on a mid-range computer with 150 concurrent crowd agents interacting with each other. We also show that when synthetic data from the proposed simulator is augmented with real world data, binary video classification accuracy is improved by 5% on average across two different models.

</p>
</details>

<details><summary><b>ULDGNN: A Fragmented UI Layer Detector Based on Graph Neural Networks</b>
<a href="https://arxiv.org/abs/2208.06658">arxiv:2208.06658</a>
&#x1F4C8; 2 <br>
<p>Jiazhi Li, Tingting Zhou, Yunnong Chen, Yanfang Chang, Yankun Zhen, Lingyun Sun, Liuqing Chen</p></summary>
<p>

**Abstract:** While some work attempt to generate front-end code intelligently from UI screenshots, it may be more convenient to utilize UI design drafts in Sketch which is a popular UI design software, because we can access multimodal UI information directly such as layers type, position, size, and visual images. However, fragmented layers could degrade the code quality without being merged into a whole part if all of them are involved in the code generation. In this paper, we propose a pipeline to merge fragmented layers automatically. We first construct a graph representation for the layer tree of a UI draft and detect all fragmented layers based on the visual features and graph neural networks. Then a rule-based algorithm is designed to merge fragmented layers. Through experiments on a newly constructed dataset, our approach can retrieve most fragmented layers in UI design drafts, and achieve 87% accuracy in the detection task, and the post-processing algorithm is developed to cluster associative layers under simple and general circumstances.

</p>
</details>

<details><summary><b>Imputation Strategies Under Clinical Presence: Impact on Algorithmic Fairness</b>
<a href="https://arxiv.org/abs/2208.06648">arxiv:2208.06648</a>
&#x1F4C8; 2 <br>
<p>Vincent Jeanselme, Maria De-Arteaga, Zhe Zhang, Jessica Barrett, Brian Tom</p></summary>
<p>

**Abstract:** Biases have marked medical history, leading to unequal care affecting marginalised groups. The patterns of missingness in observational data often reflect these group discrepancies, but the algorithmic fairness implications of group-specific missingness are not well understood. Despite its potential impact, imputation is too often a forgotten preprocessing step. At best, practitioners guide imputation choice by optimising overall performance, ignoring how this preprocessing can reinforce inequities. Our work questions this choice by studying how imputation affects downstream algorithmic fairness. First, we provide a structured view of the relationship between clinical presence mechanisms and group-specific missingness patterns. Then, through simulations and real-world experiments, we demonstrate that the imputation choice influences marginalised group performance and that no imputation strategy consistently reduces disparities. Importantly, our results show that current practices may endanger health equity as similarly performing imputation strategies at the population level can affect marginalised groups in different ways. Finally, we propose recommendations for mitigating inequity stemming from a neglected step of the machine learning pipeline.

</p>
</details>

<details><summary><b>Riemannian accelerated gradient methods via extrapolation</b>
<a href="https://arxiv.org/abs/2208.06619">arxiv:2208.06619</a>
&#x1F4C8; 2 <br>
<p>Andi Han, Bamdev Mishra, Pratik Jawanpuria, Junbin Gao</p></summary>
<p>

**Abstract:** In this paper, we propose a simple acceleration scheme for Riemannian gradient methods by extrapolating iterates on manifolds. We show when the iterates are generated from Riemannian gradient descent method, the accelerated scheme achieves the optimal convergence rate asymptotically and is computationally more favorable than the recently proposed Riemannian Nesterov accelerated gradient methods. Our experiments verify the practical benefit of the novel acceleration strategy.

</p>
</details>

<details><summary><b>Self-supervised Matting-specific Portrait Enhancement and Generation</b>
<a href="https://arxiv.org/abs/2208.06601">arxiv:2208.06601</a>
&#x1F4C8; 2 <br>
<p>Yangyang Xu Zeyang Zhou, Shengfeng He</p></summary>
<p>

**Abstract:** We resolve the ill-posed alpha matting problem from a completely different perspective. Given an input portrait image, instead of estimating the corresponding alpha matte, we focus on the other end, to subtly enhance this input so that the alpha matte can be easily estimated by any existing matting models. This is accomplished by exploring the latent space of GAN models. It is demonstrated that interpretable directions can be found in the latent space and they correspond to semantic image transformations. We further explore this property in alpha matting. Particularly, we invert an input portrait into the latent code of StyleGAN, and our aim is to discover whether there is an enhanced version in the latent space which is more compatible with a reference matting model. We optimize multi-scale latent vectors in the latent spaces under four tailored losses, ensuring matting-specificity and subtle modifications on the portrait. We demonstrate that the proposed method can refine real portrait images for arbitrary matting models, boosting the performance of automatic alpha matting by a large margin. In addition, we leverage the generative property of StyleGAN, and propose to generate enhanced portrait data which can be treated as the pseudo GT. It addresses the problem of expensive alpha matte annotation, further augmenting the matting performance of existing models. Code is available at~\url{https://github.com/cnnlstm/StyleGAN_Matting}.

</p>
</details>

<details><summary><b>Link-Backdoor: Backdoor Attack on Link Prediction via Node Injection</b>
<a href="https://arxiv.org/abs/2208.06776">arxiv:2208.06776</a>
&#x1F4C8; 1 <br>
<p>Haibin Zheng, Haiyang Xiong, Haonan Ma, Guohan Huang, Jinyin Chen</p></summary>
<p>

**Abstract:** Link prediction, inferring the undiscovered or potential links of the graph, is widely applied in the real-world. By facilitating labeled links of the graph as the training data, numerous deep learning based link prediction methods have been studied, which have dominant prediction accuracy compared with non-deep methods. However,the threats of maliciously crafted training graph will leave a specific backdoor in the deep model, thus when some specific examples are fed into the model, it will make wrong prediction, defined as backdoor attack. It is an important aspect that has been overlooked in the current literature. In this paper, we prompt the concept of backdoor attack on link prediction, and propose Link-Backdoor to reveal the training vulnerability of the existing link prediction methods. Specifically, the Link-Backdoor combines the fake nodes with the nodes of the target link to form a trigger. Moreover, it optimizes the trigger by the gradient information from the target model. Consequently, the link prediction model trained on the backdoored dataset will predict the link with trigger to the target state. Extensive experiments on five benchmark datasets and five well-performing link prediction models demonstrate that the Link-Backdoor achieves the state-of-the-art attack success rate under both white-box (i.e., available of the target model parameter)and black-box (i.e., unavailable of the target model parameter) scenarios. Additionally, we testify the attack under defensive circumstance, and the results indicate that the Link-Backdoor still can construct successful attack on the well-performing link prediction methods. The code and data are available at https://github.com/Seaocn/Link-Backdoor.

</p>
</details>

<details><summary><b>Feasibility Layer Aided Machine Learning Approach for Day-Ahead Operations</b>
<a href="https://arxiv.org/abs/2208.06742">arxiv:2208.06742</a>
&#x1F4C8; 1 <br>
<p>Arun Venkatesh Ramesh, Xingpeng Li</p></summary>
<p>

**Abstract:** Day-ahead operations involves a complex and computationally intensive optimization process to determine the generator commitment schedule and dispatch. The optimization process is a mixed-integer linear program (MILP) also known as security-constrained unit commitment (SCUC). Independent system operators (ISOs) run SCUC daily and require state-of-the-art algorithms to speed up the process. Existing patterns in historical information can be leveraged for model reduction of SCUC, which can provide significant time savings. In this paper, machine learning (ML) based classification approaches, namely logistic regression, neural networks, random forest and K-nearest neighbor, were studied for model reduction of SCUC. The ML was then aided with a feasibility layer (FL) and post-process technique to ensure high-quality solutions. The proposed approach is validated on several test systems namely, IEEE 24-Bus system, IEEE-73 Bus system, IEEE 118-Bus system, 500-Bus system, and Polish 2383-Bus system. Moreover, model reduction of a stochastic SCUC (SSCUC) was demonstrated utilizing a modified IEEE 24-Bus system with renewable generation. Simulation results demonstrate a high training accuracy to identify commitment schedule while FL and post-process ensure ML predictions do not lead to infeasible solutions with minimal loss in solution quality.

</p>
</details>

<details><summary><b>A Near-Optimal Algorithm for Univariate Zeroth-Order Budget Convex Optimization</b>
<a href="https://arxiv.org/abs/2208.06720">arxiv:2208.06720</a>
&#x1F4C8; 1 <br>
<p>Fran√ßois Bachoc, Tommaso Cesari, Roberto Colomboni, Andrea Paudice</p></summary>
<p>

**Abstract:** This paper studies a natural generalization of the problem of minimizing a univariate convex function $f$ by querying its values sequentially. At each time-step $t$, the optimizer can invest a budget $b_t$ in a query point $X_t$ of their choice to obtain a fuzzy evaluation of $f$ at $X_t$ whose accuracy depends on the amount of budget invested in $X_t$ across times. This setting is motivated by the minimization of objectives whose values can only be determined approximately through lengthy or expensive computations. We design an any-time parameter-free algorithm called Dyadic Search, for which we prove near-optimal optimization error guarantees. As a byproduct of our analysis, we show that the classical dependence on the global Lipschitz constant in the error bounds is an artifact of the granularity of the budget. Finally, we illustrate our theoretical findings with numerical simulations.

</p>
</details>

<details><summary><b>BinBert: Binary Code Understanding with a Fine-tunable and Execution-aware Transformer</b>
<a href="https://arxiv.org/abs/2208.06692">arxiv:2208.06692</a>
&#x1F4C8; 1 <br>
<p>Fiorella Artuso, Marco Mormando, Giuseppe A. Di Luna, Leonardo Querzoni</p></summary>
<p>

**Abstract:** A recent trend in binary code analysis promotes the use of neural solutions based on instruction embedding models. An instruction embedding model is a neural network that transforms sequences of assembly instructions into embedding vectors. If the embedding network is trained such that the translation from code to vectors partially preserves the semantic, the network effectively represents an assembly code model.
  In this paper we present BinBert, a novel assembly code model. BinBert is built on a transformer pre-trained on a huge dataset of both assembly instruction sequences and symbolic execution information. BinBert can be applied to assembly instructions sequences and it is fine-tunable, i.e. it can be re-trained as part of a neural architecture on task-specific data. Through fine-tuning, BinBert learns how to apply the general knowledge acquired with pre-training to the specific task.
  We evaluated BinBert on a multi-task benchmark that we specifically designed to test the understanding of assembly code. The benchmark is composed of several tasks, some taken from the literature, and a few novel tasks that we designed, with a mix of intrinsic and downstream tasks.
  Our results show that BinBert outperforms state-of-the-art models for binary instruction embedding, raising the bar for binary code understanding.

</p>
</details>

<details><summary><b>Revisiting Adversarial Attacks on Graph Neural Networks for Graph Classification</b>
<a href="https://arxiv.org/abs/2208.06651">arxiv:2208.06651</a>
&#x1F4C8; 1 <br>
<p>Beini Xie, Heng Chang, Xin Wang, Tian Bian, Shiji Zhou, Daixin Wang, Zhiqiang Zhang, Wenwu Zhu</p></summary>
<p>

**Abstract:** Graph neural networks (GNNs) have achieved tremendous success in the task of graph classification and diverse downstream real-world applications. Despite their success, existing approaches are either limited to structure attacks or restricted to local information. This calls for a more general attack framework on graph classification, which faces significant challenges due to the complexity of generating local-node-level adversarial examples using the global-graph-level information. To address this "global-to-local" problem, we present a general framework CAMA to generate adversarial examples by manipulating graph structure and node features in a hierarchical style. Specifically, we make use of Graph Class Activation Mapping and its variant to produce node-level importance corresponding to the graph classification task. Then through a heuristic design of algorithms, we can perform both feature and structure attacks under unnoticeable perturbation budgets with the help of both node-level and subgraph-level importance. Experiments towards attacking four state-of-the-art graph classification models on six real-world benchmarks verify the flexibility and effectiveness of our framework.

</p>
</details>

<details><summary><b>Medical image analysis based on transformer: A Review</b>
<a href="https://arxiv.org/abs/2208.06643">arxiv:2208.06643</a>
&#x1F4C8; 1 <br>
<p>Zhaoshan Liu, Lei Shen</p></summary>
<p>

**Abstract:** The transformer has dominated the natural language processing (NLP) field for a long time. Recently, the transformer-based method is adopt into the computer vision (CV) field and shows promising results. As an important branch of the CV field, medical image analysis joins the wave of the transformer-based method rightfully. In this paper, we illustrate the principle of the attention mechanism, and the detailed structures of the transformer, and depict how the transformer is adopted into the CV field. We organize the transformer-based medical image analysis applications in the sequence of different CV tasks, including classification, segmentation, synthesis, registration, localization, detection, captioning, and denoising. For the mainstream classification and segmentation tasks, we further divided the corresponding works based on different medical imaging modalities. We include thirteen modalities and more than twenty objects in our work. We also visualize the proportion that each modality and object occupy to give the readers an intuitive impression. We hope our work can contribute to the development of transformer-based medical image analysis in the future.

</p>
</details>

<details><summary><b>Online Refinement of a Scene Recognition Model for Mobile Robots by Observing Human's Interaction with Environments</b>
<a href="https://arxiv.org/abs/2208.06636">arxiv:2208.06636</a>
&#x1F4C8; 1 <br>
<p>Shigemichi Matsuzaki, Hiroaki Masuzawa, Jun Miura</p></summary>
<p>

**Abstract:** This paper describes a method of online refinement of a scene recognition model for robot navigation considering traversable plants, flexible plant parts which a robot can push aside while moving. In scene recognition systems that consider traversable plants growing out to the paths, misclassification may lead the robot to getting stuck due to the traversable plants recognized as obstacles. Yet, misclassification is inevitable in any estimation methods. In this work, we propose a framework that allows for refining a semantic segmentation model on the fly during the robot's operation. We introduce a few-shot segmentation based on weight imprinting for online model refinement without fine-tuning. Training data are collected via observation of a human's interaction with the plant parts. We propose novel robust weight imprinting to mitigate the effect of noise included in the masks generated by the interaction. The proposed method was evaluated through experiments using real-world data and shown to outperform an ordinary weight imprinting and provide competitive results to fine-tuning with model distillation while requiring less computational cost.

</p>
</details>

<details><summary><b>Opinion Market Model: Stemming Far-Right Opinion Spread using Positive Interventions</b>
<a href="https://arxiv.org/abs/2208.06620">arxiv:2208.06620</a>
&#x1F4C8; 1 <br>
<p>Pio Calderon, Rohit Ram, Marian-Andrei Rizoiu</p></summary>
<p>

**Abstract:** Recent years have seen the rise of extremist views in the opinion ecosystem we call social media. Allowing online extremism to persist has dire societal consequences, and efforts to mitigate it are continuously explored. Positive interventions, controlled signals that add attention to the opinion ecosystem with the aim of boosting certain opinions, are one such pathway for mitigation. This work proposes a platform to test the effectiveness of positive interventions, through the Opinion Market Model (OMM), a two-tier model of the online opinion ecosystem jointly accounting for both inter-opinion interactions and the role of positive interventions. The first tier models the size of the opinion attention market using the multivariate discrete-time Hawkes process; the second tier leverages the market share attraction model to model opinions cooperating and competing for market share given limited attention. On a synthetic dataset, we show the convergence of our proposed estimation scheme. On a dataset of Facebook and Twitter discussions containing moderate and far-right opinions about bushfires and climate change, we show superior predictive performance over the state-of-the-art and the ability to uncover latent opinion interactions. Lastly, we use OMM to demonstrate the effectiveness of mainstream media coverage as a positive intervention in suppressing far-right opinions.

</p>
</details>

<details><summary><b>Confidence Matters: Inspecting Backdoors in Deep Neural Networks via Distribution Transfer</b>
<a href="https://arxiv.org/abs/2208.06592">arxiv:2208.06592</a>
&#x1F4C8; 1 <br>
<p>Tong Wang, Yuan Yao, Feng Xu, Miao Xu, Shengwei An, Ting Wang</p></summary>
<p>

**Abstract:** Backdoor attacks have been shown to be a serious security threat against deep learning models, and detecting whether a given model has been backdoored becomes a crucial task. Existing defenses are mainly built upon the observation that the backdoor trigger is usually of small size or affects the activation of only a few neurons. However, the above observations are violated in many cases especially for advanced backdoor attacks, hindering the performance and applicability of the existing defenses. In this paper, we propose a backdoor defense DTInspector built upon a new observation. That is, an effective backdoor attack usually requires high prediction confidence on the poisoned training samples, so as to ensure that the trained model exhibits the targeted behavior with a high probability. Based on this observation, DTInspector first learns a patch that could change the predictions of most high-confidence data, and then decides the existence of backdoor by checking the ratio of prediction changes after applying the learned patch on the low-confidence data. Extensive evaluations on five backdoor attacks, four datasets, and three advanced attacking types demonstrate the effectiveness of the proposed defense.

</p>
</details>


{% endraw %}
Prev: [2022.08.12]({{ '/2022/08/12/2022.08.12.html' | relative_url }})  Next: [2022.08.14]({{ '/2022/08/14/2022.08.14.html' | relative_url }})