## Summary for 2021-03-21, created on 2021-12-23


<details><summary><b>MoViNets: Mobile Video Networks for Efficient Video Recognition</b>
<a href="https://arxiv.org/abs/2103.11511">arxiv:2103.11511</a>
&#x1F4C8; 24 <br>
<p>Dan Kondratyuk, Liangzhe Yuan, Yandong Li, Li Zhang, Mingxing Tan, Matthew Brown, Boqing Gong</p></summary>
<p>

**Abstract:** We present Mobile Video Networks (MoViNets), a family of computation and memory efficient video networks that can operate on streaming video for online inference. 3D convolutional neural networks (CNNs) are accurate at video recognition but require large computation and memory budgets and do not support online inference, making them difficult to work on mobile devices. We propose a three-step approach to improve computational efficiency while substantially reducing the peak memory usage of 3D CNNs. First, we design a video network search space and employ neural architecture search to generate efficient and diverse 3D CNN architectures. Second, we introduce the Stream Buffer technique that decouples memory from video clip duration, allowing 3D CNNs to embed arbitrary-length streaming video sequences for both training and inference with a small constant memory footprint. Third, we propose a simple ensembling technique to improve accuracy further without sacrificing efficiency. These three progressive techniques allow MoViNets to achieve state-of-the-art accuracy and efficiency on the Kinetics, Moments in Time, and Charades video action recognition datasets. For instance, MoViNet-A5-Stream achieves the same accuracy as X3D-XL on Kinetics 600 while requiring 80% fewer FLOPs and 65% less memory. Code will be made available at https://github.com/tensorflow/models/tree/master/official/vision.

</p>
</details>

<details><summary><b>Policy-Guided Heuristic Search with Guarantees</b>
<a href="https://arxiv.org/abs/2103.11505">arxiv:2103.11505</a>
&#x1F4C8; 10 <br>
<p>Laurent Orseau, Levi H. S. Lelis</p></summary>
<p>

**Abstract:** The use of a policy and a heuristic function for guiding search can be quite effective in adversarial problems, as demonstrated by AlphaGo and its successors, which are based on the PUCT search algorithm. While PUCT can also be used to solve single-agent deterministic problems, it lacks guarantees on its search effort and it can be computationally inefficient in practice. Combining the A* algorithm with a learned heuristic function tends to work better in these domains, but A* and its variants do not use a policy. Moreover, the purpose of using A* is to find solutions of minimum cost, while we seek instead to minimize the search loss (e.g., the number of search steps). LevinTS is guided by a policy and provides guarantees on the number of search steps that relate to the quality of the policy, but it does not make use of a heuristic function. In this work we introduce Policy-guided Heuristic Search (PHS), a novel search algorithm that uses both a heuristic function and a policy and has theoretical guarantees on the search loss that relates to both the quality of the heuristic and of the policy. We show empirically on the sliding-tile puzzle, Sokoban, and a puzzle from the commercial game `The Witness' that PHS enables the rapid learning of both a policy and a heuristic function and compares favorably with A*, Weighted A*, Greedy Best-First Search, LevinTS, and PUCT in terms of number of problems solved and search time in all three domains tested.

</p>
</details>

<details><summary><b>TextFlint: Unified Multilingual Robustness Evaluation Toolkit for Natural Language Processing</b>
<a href="https://arxiv.org/abs/2103.11441">arxiv:2103.11441</a>
&#x1F4C8; 10 <br>
<p>Tao Gui, Xiao Wang, Qi Zhang, Qin Liu, Yicheng Zou, Xin Zhou, Rui Zheng, Chong Zhang, Qinzhuo Wu, Jiacheng Ye, Zexiong Pang, Yongxin Zhang, Zhengyan Li, Ruotian Ma, Zichu Fei, Ruijian Cai, Jun Zhao, Xingwu Hu, Zhiheng Yan, Yiding Tan, Yuan Hu, Qiyuan Bian, Zhihua Liu, Bolin Zhu, Shan Qin</p></summary>
<p>

**Abstract:** Various robustness evaluation methodologies from different perspectives have been proposed for different natural language processing (NLP) tasks. These methods have often focused on either universal or task-specific generalization capabilities. In this work, we propose a multilingual robustness evaluation platform for NLP tasks (TextFlint) that incorporates universal text transformation, task-specific transformation, adversarial attack, subpopulation, and their combinations to provide comprehensive robustness analysis. TextFlint enables practitioners to automatically evaluate their models from all aspects or to customize their evaluations as desired with just a few lines of code. To guarantee user acceptability, all the text transformations are linguistically based, and we provide a human evaluation for each one. TextFlint generates complete analytical reports as well as targeted augmented data to address the shortcomings of the model's robustness. To validate TextFlint's utility, we performed large-scale empirical evaluations (over 67,000 evaluations) on state-of-the-art deep learning models, classic supervised methods, and real-world systems. Almost all models showed significant performance degradation, including a decline of more than 50% of BERT's prediction accuracy on tasks such as aspect-level sentiment classification, named entity recognition, and natural language inference. Therefore, we call for the robustness to be included in the model evaluation, so as to promote the healthy development of NLP technology.

</p>
</details>

<details><summary><b>Instant-Teaching: An End-to-End Semi-Supervised Object Detection Framework</b>
<a href="https://arxiv.org/abs/2103.11402">arxiv:2103.11402</a>
&#x1F4C8; 10 <br>
<p>Qiang Zhou, Chaohui Yu, Zhibin Wang, Qi Qian, Hao Li</p></summary>
<p>

**Abstract:** Supervised learning based object detection frameworks demand plenty of laborious manual annotations, which may not be practical in real applications. Semi-supervised object detection (SSOD) can effectively leverage unlabeled data to improve the model performance, which is of great significance for the application of object detection models. In this paper, we revisit SSOD and propose Instant-Teaching, a completely end-to-end and effective SSOD framework, which uses instant pseudo labeling with extended weak-strong data augmentations for teaching during each training iteration. To alleviate the confirmation bias problem and improve the quality of pseudo annotations, we further propose a co-rectify scheme based on Instant-Teaching, denoted as Instant-Teaching$^*$. Extensive experiments on both MS-COCO and PASCAL VOC datasets substantiate the superiority of our framework. Specifically, our method surpasses state-of-the-art methods by 4.2 mAP on MS-COCO when using $2\%$ labeled data. Even with full supervised information of MS-COCO, the proposed method still outperforms state-of-the-art methods by about 1.0 mAP. On PASCAL VOC, we can achieve more than 5 mAP improvement by applying VOC07 as labeled data and VOC12 as unlabeled data.

</p>
</details>

<details><summary><b>Deep ROC Analysis and AUC as Balanced Average Accuracy to Improve Model Selection, Understanding and Interpretation</b>
<a href="https://arxiv.org/abs/2103.11357">arxiv:2103.11357</a>
&#x1F4C8; 9 <br>
<p>Andr√© M. Carrington, Douglas G. Manuel, Paul W. Fieguth, Tim Ramsay, Venet Osmani, Bernhard Wernly, Carol Bennett, Steven Hawken, Matthew McInnes, Olivia Magwood, Yusuf Sheikh, Andreas Holzinger</p></summary>
<p>

**Abstract:** Optimal performance is critical for decision-making tasks from medicine to autonomous driving, however common performance measures may be too general or too specific. For binary classifiers, diagnostic tests or prognosis at a timepoint, measures such as the area under the receiver operating characteristic curve, or the area under the precision recall curve, are too general because they include unrealistic decision thresholds. On the other hand, measures such as accuracy, sensitivity or the F1 score are measures at a single threshold that reflect an individual single probability or predicted risk, rather than a range of individuals or risk. We propose a method in between, deep ROC analysis, that examines groups of probabilities or predicted risks for more insightful analysis. We translate esoteric measures into familiar terms: AUC and the normalized concordant partial AUC are balanced average accuracy (a new finding); the normalized partial AUC is average sensitivity; and the normalized horizontal partial AUC is average specificity. Along with post-test measures, we provide a method that can improve model selection in some cases and provide interpretation and assurance for patients in each risk group. We demonstrate deep ROC analysis in two case studies and provide a toolkit in Python.

</p>
</details>

<details><summary><b>Homophily Outlier Detection in Non-IID Categorical Data</b>
<a href="https://arxiv.org/abs/2103.11516">arxiv:2103.11516</a>
&#x1F4C8; 7 <br>
<p>Guansong Pang, Longbing Cao, Ling Chen</p></summary>
<p>

**Abstract:** Most of existing outlier detection methods assume that the outlier factors (i.e., outlierness scoring measures) of data entities (e.g., feature values and data objects) are Independent and Identically Distributed (IID). This assumption does not hold in real-world applications where the outlierness of different entities is dependent on each other and/or taken from different probability distributions (non-IID). This may lead to the failure of detecting important outliers that are too subtle to be identified without considering the non-IID nature. The issue is even intensified in more challenging contexts, e.g., high-dimensional data with many noisy features. This work introduces a novel outlier detection framework and its two instances to identify outliers in categorical data by capturing non-IID outlier factors. Our approach first defines and incorporates distribution-sensitive outlier factors and their interdependence into a value-value graph-based representation. It then models an outlierness propagation process in the value graph to learn the outlierness of feature values. The learned value outlierness allows for either direct outlier detection or outlying feature selection. The graph representation and mining approach is employed here to well capture the rich non-IID characteristics. Our empirical results on 15 real-world data sets with different levels of data complexities show that (i) the proposed outlier detection methods significantly outperform five state-of-the-art methods at the 95%/99% confidence level, achieving 10%-28% AUC improvement on the 10 most complex data sets; and (ii) the proposed feature selection methods significantly outperform three competing methods in enabling subsequent outlier detection of two different existing detectors.

</p>
</details>

<details><summary><b>A deep learning approach to data-driven model-free pricing and to martingale optimal transport</b>
<a href="https://arxiv.org/abs/2103.11435">arxiv:2103.11435</a>
&#x1F4C8; 7 <br>
<p>Ariel Neufeld, Julian Sester</p></summary>
<p>

**Abstract:** We introduce a novel and highly tractable supervised learning approach based on neural networks that can be applied for the computation of model-free price bounds of, potentially high-dimensional, financial derivatives and for the determination of optimal hedging strategies attaining these bounds. In particular, our methodology allows to train a single neural network offline and then to use it online for the fast determination of model-free price bounds of a whole class of financial derivatives with current market data. We show the applicability of this approach and highlight its accuracy in several examples involving real market data. Further, we show how a neural network can be trained to solve martingale optimal transport problems involving fixed marginal distributions instead of financial market data.

</p>
</details>

<details><summary><b>Non-Autoregressive Translation by Learning Target Categorical Codes</b>
<a href="https://arxiv.org/abs/2103.11405">arxiv:2103.11405</a>
&#x1F4C8; 7 <br>
<p>Yu Bao, Shujian Huang, Tong Xiao, Dongqi Wang, Xinyu Dai, Jiajun Chen</p></summary>
<p>

**Abstract:** Non-autoregressive Transformer is a promising text generation model. However, current non-autoregressive models still fall behind their autoregressive counterparts in translation quality. We attribute this accuracy gap to the lack of dependency modeling among decoder inputs. In this paper, we propose CNAT, which learns implicitly categorical codes as latent variables into the non-autoregressive decoding. The interaction among these categorical codes remedies the missing dependencies and improves the model capacity. Experiment results show that our model achieves comparable or better performance in machine translation tasks, compared with several strong baselines.

</p>
</details>

<details><summary><b>Collaborative Agent Gameplay in the Pandemic Board Game</b>
<a href="https://arxiv.org/abs/2103.11388">arxiv:2103.11388</a>
&#x1F4C8; 7 <br>
<p>Konstantinos Sfikas, Antonios Liapis</p></summary>
<p>

**Abstract:** While artificial intelligence has been applied to control players' decisions in board games for over half a century, little attention is given to games with no player competition. Pandemic is an exemplar collaborative board game where all players coordinate to overcome challenges posed by events occurring during the game's progression. This paper proposes an artificial agent which controls all players' actions and balances chances of winning versus risk of losing in this highly stochastic environment. The agent applies a Rolling Horizon Evolutionary Algorithm on an abstraction of the game-state that lowers the branching factor and simulates the game's stochasticity. Results show that the proposed algorithm can find winning strategies more consistently in different games of varying difficulty. The impact of a number of state evaluation metrics is explored, balancing between optimistic strategies that favor winning and pessimistic strategies that guard against losing.

</p>
</details>

<details><summary><b>Stock price forecast with deep learning</b>
<a href="https://arxiv.org/abs/2103.14081">arxiv:2103.14081</a>
&#x1F4C8; 5 <br>
<p>Firuz Kamalov, Linda Smail, Ikhlaas Gurrib</p></summary>
<p>

**Abstract:** In this paper, we compare various approaches to stock price prediction using neural networks. We analyze the performance fully connected, convolutional, and recurrent architectures in predicting the next day value of S&P 500 index based on its previous values. We further expand our analysis by including three different optimization techniques: Stochastic Gradient Descent, Root Mean Square Propagation, and Adaptive Moment Estimation. The numerical experiments reveal that a single layer recurrent neural network with RMSprop optimizer produces optimal results with validation and test Mean Absolute Error of 0.0150 and 0.0148 respectively.

</p>
</details>

<details><summary><b>Forecasting with Deep Learning: S&P 500 index</b>
<a href="https://arxiv.org/abs/2103.14080">arxiv:2103.14080</a>
&#x1F4C8; 5 <br>
<p>Firuz Kamalov, Linda Smail, Ikhlaas Gurrib</p></summary>
<p>

**Abstract:** Stock price prediction has been the focus of a large amount of research but an acceptable solution has so far escaped academics. Recent advances in deep learning have motivated researchers to apply neural networks to stock prediction. In this paper, we propose a convolution-based neural network model for predicting the future value of the S&P 500 index. The proposed model is capable of predicting the next-day direction of the index based on the previous values of the index. Experiments show that our model outperforms a number of benchmarks achieving an accuracy rate of over 55%.

</p>
</details>

<details><summary><b>Grey-box Adversarial Attack And Defence For Sentiment Classification</b>
<a href="https://arxiv.org/abs/2103.11576">arxiv:2103.11576</a>
&#x1F4C8; 5 <br>
<p>Ying Xu, Xu Zhong, Antonio Jimeno Yepes, Jey Han Lau</p></summary>
<p>

**Abstract:** We introduce a grey-box adversarial attack and defence framework for sentiment classification. We address the issues of differentiability, label preservation and input reconstruction for adversarial attack and defence in one unified framework. Our results show that once trained, the attacking model is capable of generating high-quality adversarial examples substantially faster (one order of magnitude less in time) than state-of-the-art attacking methods. These examples also preserve the original sentiment according to human evaluation. Additionally, our framework produces an improved classifier that is robust in defending against multiple adversarial attacking methods. Code is available at: https://github.com/ibm-aur-nlp/adv-def-text-dist.

</p>
</details>

<details><summary><b>Learn-to-Race: A Multimodal Control Environment for Autonomous Racing</b>
<a href="https://arxiv.org/abs/2103.11575">arxiv:2103.11575</a>
&#x1F4C8; 4 <br>
<p>James Herman, Jonathan Francis, Siddha Ganju, Bingqing Chen, Anirudh Koul, Abhinav Gupta, Alexey Skabelkin, Ivan Zhukov, Max Kumskoy, Eric Nyberg</p></summary>
<p>

**Abstract:** Existing research on autonomous driving primarily focuses on urban driving, which is insufficient for characterising the complex driving behaviour underlying high-speed racing. At the same time, existing racing simulation frameworks struggle in capturing realism, with respect to visual rendering, vehicular dynamics, and task objectives, inhibiting the transfer of learning agents to real-world contexts. We introduce a new environment, where agents Learn-to-Race (L2R) in simulated competition-style racing, using multimodal information--from virtual cameras to a comprehensive array of inertial measurement sensors. Our environment, which includes a simulator and an interfacing training framework, accurately models vehicle dynamics and racing conditions. In this paper, we release the Arrival simulator for autonomous racing. Next, we propose the L2R task with challenging metrics, inspired by learning-to-drive challenges, Formula-style racing, and multimodal trajectory prediction for autonomous driving. Additionally, we provide the L2R framework suite, facilitating simulated racing on high-precision models of real-world tracks. Finally, we provide an official L2R task dataset of expert demonstrations, as well as a series of baseline experiments and reference implementations. We make all code available: https://github.com/learn-to-race/l2r.

</p>
</details>

<details><summary><b>RadarLoc: Learning to Relocalize in FMCW Radar</b>
<a href="https://arxiv.org/abs/2103.11562">arxiv:2103.11562</a>
&#x1F4C8; 4 <br>
<p>Wei Wang, Pedro P. B. de Gusmo, Bo Yang, Andrew Markham, Niki Trigoni</p></summary>
<p>

**Abstract:** Relocalization is a fundamental task in the field of robotics and computer vision. There is considerable work in the field of deep camera relocalization, which directly estimates poses from raw images. However, learning-based methods have not yet been applied to the radar sensory data. In this work, we investigate how to exploit deep learning to predict global poses from Emerging Frequency-Modulated Continuous Wave (FMCW) radar scans. Specifically, we propose a novel end-to-end neural network with self-attention, termed RadarLoc, which is able to estimate 6-DoF global poses directly. We also propose to improve the localization performance by utilizing geometric constraints between radar scans. We validate our approach on the recently released challenging outdoor dataset Oxford Radar RobotCar. Comprehensive experiments demonstrate that the proposed method outperforms radar-based localization and deep camera relocalization methods by a significant margin.

</p>
</details>

<details><summary><b>Unsupervised and self-adaptative techniques for cross-domain person re-identification</b>
<a href="https://arxiv.org/abs/2103.11520">arxiv:2103.11520</a>
&#x1F4C8; 4 <br>
<p>Gabriel Bertocco, Fernanda Andal√≥, Anderson Rocha</p></summary>
<p>

**Abstract:** Person Re-Identification (ReID) across non-overlapping cameras is a challenging task and, for this reason, most works in the prior art rely on supervised feature learning from a labeled dataset to match the same person in different views. However, it demands the time-consuming task of labeling the acquired data, prohibiting its fast deployment, specially in forensic scenarios. Unsupervised Domain Adaptation (UDA) emerges as a promising alternative, as it performs feature-learning adaptation from a model trained on a source to a target domain without identity-label annotation. However, most UDA-based algorithms rely upon a complex loss function with several hyper-parameters, which hinders the generalization to different scenarios. Moreover, as UDA depends on the translation between domains, it is important to select the most reliable data from the unseen domain, thus avoiding error propagation caused by noisy examples on the target data -- an often overlooked problem. In this sense, we propose a novel UDA-based ReID method that optimizes a simple loss function with only one hyper-parameter and that takes advantage of triplets of samples created by a new offline strategy based on the diversity of cameras within a cluster. This new strategy adapts the model and also regularizes it, avoiding overfitting on the target domain. We also introduce a new self-ensembling strategy, in which weights from different iterations are aggregated to create a final model combining knowledge from distinct moments of the adaptation. For evaluation, we consider three well-known deep learning architectures and combine them for final decision-making. The proposed method does not use person re-ranking nor any label on the target domain, and outperforms the state of the art, with a much simpler setup, on the Market to Duke, the challenging Market1501 to MSMT17, and Duke to MSMT17 adaptation scenarios.

</p>
</details>

<details><summary><b>UCB-based Algorithms for Multinomial Logistic Regression Bandits</b>
<a href="https://arxiv.org/abs/2103.11489">arxiv:2103.11489</a>
&#x1F4C8; 4 <br>
<p>Sanae Amani, Christos Thrampoulidis</p></summary>
<p>

**Abstract:** Out of the rich family of generalized linear bandits, perhaps the most well studied ones are logisitc bandits that are used in problems with binary rewards: for instance, when the learner/agent tries to maximize the profit over a user that can select one of two possible outcomes (e.g., `click' vs `no-click'). Despite remarkable recent progress and improved algorithms for logistic bandits, existing works do not address practical situations where the number of outcomes that can be selected by the user is larger than two (e.g., `click', `show me later', `never show again', `no click'). In this paper, we study such an extension. We use multinomial logit (MNL) to model the probability of each one of $K+1\geq 2$ possible outcomes (+1 stands for the `not click' outcome): we assume that for a learner's action $\mathbf{x}_t$, the user selects one of $K+1\geq 2$ outcomes, say outcome $i$, with a multinomial logit (MNL) probabilistic model with corresponding unknown parameter $\bar{\boldsymbolŒ∏}_{\ast i}$. Each outcome $i$ is also associated with a revenue parameter $œÅ_i$ and the goal is to maximize the expected revenue. For this problem, we present MNL-UCB, an upper confidence bound (UCB)-based algorithm, that achieves regret $\tilde{\mathcal{O}}(dK\sqrt{T})$ with small dependency on problem-dependent constants that can otherwise be arbitrarily large and lead to loose regret bounds. We present numerical simulations that corroborate our theoretical results.

</p>
</details>

<details><summary><b>Deep Distribution-preserving Incomplete Clustering with Optimal Transport</b>
<a href="https://arxiv.org/abs/2103.11424">arxiv:2103.11424</a>
&#x1F4C8; 4 <br>
<p>Mingjie Luo, Siwei Wang, Xinwang Liu, Wenxuan Tu, Yi Zhang, Xifeng Guo, Sihang Zhou, En Zhu</p></summary>
<p>

**Abstract:** Clustering is a fundamental task in the computer vision and machine learning community. Although various methods have been proposed, the performance of existing approaches drops dramatically when handling incomplete high-dimensional data (which is common in real world applications). To solve the problem, we propose a novel deep incomplete clustering method, named Deep Distribution-preserving Incomplete Clustering with Optimal Transport (DDIC-OT). To avoid insufficient sample utilization in existing methods limited by few fully-observed samples, we propose to measure distribution distance with the optimal transport for reconstruction evaluation instead of traditional pixel-wise loss function. Moreover, the clustering loss of the latent feature is introduced to regularize the embedding with more discrimination capability. As a consequence, the network becomes more robust against missing features and the unified framework which combines clustering and sample imputation enables the two procedures to negotiate to better serve for each other. Extensive experiments demonstrate that the proposed network achieves superior and stable clustering performance improvement against existing state-of-the-art incomplete clustering methods over different missing ratios.

</p>
</details>

<details><summary><b>ScanMix: Learning from Severe Label Noise via Semantic Clustering and Semi-Supervised Learning</b>
<a href="https://arxiv.org/abs/2103.11395">arxiv:2103.11395</a>
&#x1F4C8; 4 <br>
<p>Ragav Sachdeva, Filipe R Cordeiro, Vasileios Belagiannis, Ian Reid, Gustavo Carneiro</p></summary>
<p>

**Abstract:** In this paper, we address the problem of training deep neural networks in the presence of severe label noise. Our proposed training algorithm ScanMix, combines semantic clustering with semi-supervised learning (SSL) to improve the feature representations and enable an accurate identification of noisy samples, even in severe label noise scenarios. To be specific, ScanMix is designed based on the expectation maximisation (EM) framework, where the E-step estimates the value of a latent variable to cluster the training images based on their appearance representations and classification results, and the M-step optimises the SSL classification and learns effective feature representations via semantic clustering. In our evaluations, we show state-of-the-art results on standard benchmarks for symmetric, asymmetric and semantic label noise on CIFAR-10 and CIFAR-100, as well as large scale real label noise on WebVision. Most notably, for the benchmarks contaminated with large noise rates (80% and above), our results are up to 27% better than the related work. The code is available at https://github.com/ragavsachdeva/ScanMix.

</p>
</details>

<details><summary><b>Natural Perturbed Training for General Robustness of Neural Network Classifiers</b>
<a href="https://arxiv.org/abs/2103.11372">arxiv:2103.11372</a>
&#x1F4C8; 4 <br>
<p>Sadaf Gulshad, Arnold Smeulders</p></summary>
<p>

**Abstract:** We focus on the robustness of neural networks for classification. To permit a fair comparison between methods to achieve robustness, we first introduce a standard based on the mensuration of a classifier's degradation. Then, we propose natural perturbed training to robustify the network. Natural perturbations will be encountered in practice: the difference of two images of the same object may be approximated by an elastic deformation (when they have slightly different viewing angles), by occlusions (when they hide differently behind objects), or by saturation, Gaussian noise etc. Training some fraction of the epochs on random versions of such variations will help the classifier to learn better. We conduct extensive experiments on six datasets of varying sizes and granularity. Natural perturbed learning show better and much faster performance than adversarial training on clean, adversarial as well as natural perturbed images. It even improves general robustness on perturbations not seen during the training. For Cifar-10 and STL-10 natural perturbed training even improves the accuracy for clean data and reaches the state of the art performance. Ablation studies verify the effectiveness of natural perturbed training.

</p>
</details>

<details><summary><b>Self adversarial attack as an augmentation method for immunohistochemical stainings</b>
<a href="https://arxiv.org/abs/2103.11362">arxiv:2103.11362</a>
&#x1F4C8; 4 <br>
<p>Jelica Vasiljeviƒá, Friedrich Feuerhake, C√©dric Wemmert, Thomas Lampert</p></summary>
<p>

**Abstract:** It has been shown that unpaired image-to-image translation methods constrained by cycle-consistency hide the information necessary for accurate input reconstruction as imperceptible noise. We demonstrate that, when applied to histopathology data, this hidden noise appears to be related to stain specific features and show that this is the case with two immunohistochemical stainings during translation to Periodic acid- Schiff (PAS), a histochemical staining method commonly applied in renal pathology. Moreover, by perturbing this hidden information, the translation models produce different, plausible outputs. We demonstrate that this property can be used as an augmentation method which, in a case of supervised glomeruli segmentation, leads to improved performance.

</p>
</details>

<details><summary><b>Unsupervised Learning of Depth Estimation and Visual Odometry for Sparse Light Field Cameras</b>
<a href="https://arxiv.org/abs/2103.11322">arxiv:2103.11322</a>
&#x1F4C8; 4 <br>
<p>S. Tejaswi Digumarti, Joseph Daniel, Ahalya Ravendran, Donald G. Dansereau</p></summary>
<p>

**Abstract:** While an exciting diversity of new imaging devices is emerging that could dramatically improve robotic perception, the challenges of calibrating and interpreting these cameras have limited their uptake in the robotics community. In this work we generalise techniques from unsupervised learning to allow a robot to autonomously interpret new kinds of cameras. We consider emerging sparse light field (LF) cameras, which capture a subset of the 4D LF function describing the set of light rays passing through a plane. We introduce a generalised encoding of sparse LFs that allows unsupervised learning of odometry and depth. We demonstrate the proposed approach outperforming monocular and conventional techniques for dealing with 4D imagery, yielding more accurate odometry and depth maps and delivering these with metric scale. We anticipate our technique to generalise to a broad class of LF and sparse LF cameras, and to enable unsupervised recalibration for coping with shifts in camera behaviour over the lifetime of a robot. This work represents a first step toward streamlining the integration of new kinds of imaging devices in robotics applications.

</p>
</details>

<details><summary><b>An Unsupervised Sampling Approach for Image-Sentence Matching Using Document-Level Structural Information</b>
<a href="https://arxiv.org/abs/2104.02605">arxiv:2104.02605</a>
&#x1F4C8; 3 <br>
<p>Zejun Li, Zhongyu Wei, Zhihao Fan, Haijun Shan, Xuanjing Huang</p></summary>
<p>

**Abstract:** In this paper, we focus on the problem of unsupervised image-sentence matching. Existing research explores to utilize document-level structural information to sample positive and negative instances for model training. Although the approach achieves positive results, it introduces a sampling bias and fails to distinguish instances with high semantic similarity. To alleviate the bias, we propose a new sampling strategy to select additional intra-document image-sentence pairs as positive or negative samples. Furthermore, to recognize the complex pattern in intra-document samples, we propose a Transformer based model to capture fine-grained features and implicitly construct a graph for each document, where concepts in a document are introduced to bridge the representation learning of images and sentences in the context of a document. Experimental results show the effectiveness of our approach to alleviate the bias and learn well-aligned multimodal representations.

</p>
</details>

<details><summary><b>MONAIfbs: MONAI-based fetal brain MRI deep learning segmentation</b>
<a href="https://arxiv.org/abs/2103.13314">arxiv:2103.13314</a>
&#x1F4C8; 3 <br>
<p>Marta B. M. Ranzini, Lucas Fidon, S√©bastien Ourselin, Marc Modat, Tom Vercauteren</p></summary>
<p>

**Abstract:** In fetal Magnetic Resonance Imaging, Super Resolution Reconstruction (SRR) algorithms are becoming popular tools to obtain high-resolution 3D volume reconstructions from low-resolution stacks of 2D slices, acquired at different orientations. To be effective, these algorithms often require accurate segmentation of the region of interest, such as the fetal brain in suspected pathological cases. In the case of Spina Bifida, Ebner, Wang et al. (NeuroImage, 2020) combined their SRR algorithm with a 2-step segmentation pipeline (2D localisation followed by a 2D segmentation network). However, if the localisation step fails, the second network is not able to recover a correct brain mask, thus requiring manual corrections for an effective SRR. In this work, we aim at improving the fetal brain segmentation for SRR in Spina Bifida. We hypothesise that a well-trained single-step UNet can achieve accurate performance, avoiding the need of a 2-step approach. We propose a new tool for fetal brain segmentation called MONAIfbs, which takes advantage of the Medical Open Network for Artificial Intelligence (MONAI) framework. Our network is based on the dynamic UNet (dynUNet), an adaptation of the nnU-Net framework. When compared to the original 2-step approach proposed in Ebner-Wang, and the same Ebner-Wang approach retrained with the expanded dataset available for this work, the dynUNet showed to achieve higher performance using a single step only. It also showed to reduce the number of outliers, as only 28 stacks obtained Dice score less than 0.9, compared to 68 for Ebner-Wang and 53 Ebner-Wang expanded. The proposed dynUNet model thus provides an improvement of the state-of-the-art fetal brain segmentation techniques, reducing the need for manual correction in automated SRR pipelines. Our code and our trained model are made publicly available at https://github.com/gift-surg/MONAIfbs.

</p>
</details>

<details><summary><b>Provably Correct Optimization and Exploration with Non-linear Policies</b>
<a href="https://arxiv.org/abs/2103.11559">arxiv:2103.11559</a>
&#x1F4C8; 3 <br>
<p>Fei Feng, Wotao Yin, Alekh Agarwal, Lin F. Yang</p></summary>
<p>

**Abstract:** Policy optimization methods remain a powerful workhorse in empirical Reinforcement Learning (RL), with a focus on neural policies that can easily reason over complex and continuous state and/or action spaces. Theoretical understanding of strategic exploration in policy-based methods with non-linear function approximation, however, is largely missing. In this paper, we address this question by designing ENIAC, an actor-critic method that allows non-linear function approximation in the critic. We show that under certain assumptions, e.g., a bounded eluder dimension $d$ for the critic class, the learner finds a near-optimal policy in $O(\poly(d))$ exploration rounds. The method is robust to model misspecification and strictly extends existing works on linear function approximation. We also develop some computational optimizations of our approach with slightly worse statistical guarantees and an empirical adaptation building on existing deep RL tools. We empirically evaluate this adaptation and show that it outperforms prior heuristics inspired by linear methods, establishing the value via correctly reasoning about the agent's uncertainty under non-linear function approximation.

</p>
</details>

<details><summary><b>The Discovery of Dynamics via Linear Multistep Methods and Deep Learning: Error Estimation</b>
<a href="https://arxiv.org/abs/2103.11488">arxiv:2103.11488</a>
&#x1F4C8; 3 <br>
<p>Qiang Du, Yiqi Gu, Haizhao Yang, Chao Zhou</p></summary>
<p>

**Abstract:** Identifying hidden dynamics from observed data is a significant and challenging task in a wide range of applications. Recently, the combination of linear multistep methods (LMMs) and deep learning has been successfully employed to discover dynamics, whereas a complete convergence analysis of this approach is still under development. In this work, we consider the deep network-based LMMs for the discovery of dynamics. We put forward error estimates for these methods using the approximation property of deep networks. It indicates, for certain families of LMMs, that the $\ell^2$ grid error is bounded by the sum of $O(h^p)$ and the network approximation error, where $h$ is the time step size and $p$ is the local truncation error order. Numerical results of several physically relevant examples are provided to demonstrate our theory.

</p>
</details>

<details><summary><b>L3CubeMahaSent: A Marathi Tweet-based Sentiment Analysis Dataset</b>
<a href="https://arxiv.org/abs/2103.11408">arxiv:2103.11408</a>
&#x1F4C8; 3 <br>
<p>Atharva Kulkarni, Meet Mandhane, Manali Likhitkar, Gayatri Kshirsagar, Raviraj Joshi</p></summary>
<p>

**Abstract:** Sentiment analysis is one of the most fundamental tasks in Natural Language Processing. Popular languages like English, Arabic, Russian, Mandarin, and also Indian languages such as Hindi, Bengali, Tamil have seen a significant amount of work in this area. However, the Marathi language which is the third most popular language in India still lags behind due to the absence of proper datasets. In this paper, we present the first major publicly available Marathi Sentiment Analysis Dataset - L3CubeMahaSent. It is curated using tweets extracted from various Maharashtrian personalities' Twitter accounts. Our dataset consists of ~16,000 distinct tweets classified in three broad classes viz. positive, negative, and neutral. We also present the guidelines using which we annotated the tweets. Finally, we present the statistics of our dataset and baseline classification results using CNN, LSTM, ULMFiT, and BERT-based deep learning models.

</p>
</details>

<details><summary><b>Detecting Label Noise via Leave-One-Out Cross-Validation</b>
<a href="https://arxiv.org/abs/2103.11352">arxiv:2103.11352</a>
&#x1F4C8; 3 <br>
<p>Yu-Hang Tang, Yuanran Zhu, Wibe A. de Jong</p></summary>
<p>

**Abstract:** We present a simple algorithm for identifying and correcting real-valued noisy labels from a mixture of clean and corrupted sample points using Gaussian process regression. A heteroscedastic noise model is employed, in which additive Gaussian noise terms with independent variances are associated with each and all of the observed labels. Optimizing the noise model using maximum likelihood estimation leads to the containment of the GPR model's predictive error by the posterior standard deviation in leave-one-out cross-validation. A multiplicative update scheme is proposed for solving the maximum likelihood estimation problem under non-negative constraints. While we provide proof of convergence for certain special cases, the multiplicative scheme has empirically demonstrated monotonic convergence behavior in virtually all our numerical experiments. We show that the presented method can pinpoint corrupted sample points and lead to better regression models when trained on synthetic and real-world scientific data sets.

</p>
</details>

<details><summary><b>Mining GIS Data to Predict Urban Sprawl</b>
<a href="https://arxiv.org/abs/2103.11338">arxiv:2103.11338</a>
&#x1F4C8; 3 <br>
<p>Anita Pampoore-Thampi, Aparna S. Varde, Danlin Yu</p></summary>
<p>

**Abstract:** This paper addresses the interesting problem of processing and analyzing data in geographic information systems (GIS) to achieve a clear perspective on urban sprawl. The term urban sprawl refers to overgrowth and expansion of low-density areas with issues such as car dependency and segregation between residential versus commercial use. Sprawl has impacts on the environment and public health. In our work, spatiotemporal features related to real GIS data on urban sprawl such as population growth and demographics are mined to discover knowledge for decision support. We adapt data mining algorithms, Apriori for association rule mining and J4.8 for decision tree classification to geospatial analysis, deploying the ArcGIS tool for mapping. Knowledge discovered by mining this spatiotemporal data is used to implement a prototype spatial decision support system (SDSS). This SDSS predicts whether urban sprawl is likely to occur. Further, it estimates the values of pertinent variables to understand how the variables impact each other. The SDSS can help decision-makers identify problems and create solutions for avoiding future sprawl occurrence and conducting urban planning where sprawl already occurs, thus aiding sustainable development. This work falls in the broad realm of geospatial intelligence and sets the stage for designing a large scale SDSS to process big data in complex environments, which constitutes part of our future work.

</p>
</details>

<details><summary><b>A new public Alsat-2B dataset for single-image super-resolution</b>
<a href="https://arxiv.org/abs/2103.12547">arxiv:2103.12547</a>
&#x1F4C8; 2 <br>
<p>Achraf Djerida, Khelifa Djerriri, Moussa Sofiane Karoui, Mohammed El Amin larabi</p></summary>
<p>

**Abstract:** Currently, when reliable training datasets are available, deep learning methods dominate the proposed solutions for image super-resolution. However, for remote sensing benchmarks, it is very expensive to obtain high spatial resolution images. Most of the super-resolution methods use down-sampling techniques to simulate low and high spatial resolution pairs and construct the training samples. To solve this issue, the paper introduces a novel public remote sensing dataset (Alsat2B) of low and high spatial resolution images (10m and 2.5m respectively) for the single-image super-resolution task. The high-resolution images are obtained through pan-sharpening. Besides, the performance of some super-resolution methods on the dataset is assessed based on common criteria. The obtained results reveal that the proposed scheme is promising and highlight the challenges in the dataset which shows the need for advanced methods to grasp the relationship between the low and high-resolution patches.

</p>
</details>

<details><summary><b>Machine learning based in situ quality estimation by molten pool condition-quality relations modeling using experimental data</b>
<a href="https://arxiv.org/abs/2103.12066">arxiv:2103.12066</a>
&#x1F4C8; 2 <br>
<p>Noopur Jamnikar, Sen Liu, Craig Brice, Xiaoli Zhang</p></summary>
<p>

**Abstract:** The advancement of machine learning promises the ability to accelerate the adoption of new processes and property designs for metal additive manufacturing. The molten pool geometry and molten pool temperature are the significant indicators for the final part's geometric shape and microstructural properties for the Wire-feed laser direct energy deposition process. Thus, the molten pool condition-property relations are of preliminary importance for in situ quality assurance. To enable in situ quality monitoring of bead geometry and characterization properties, we need to continuously monitor the sensor's data for molten pool dimensions and temperature for the Wire-feed laser additive manufacturing (WLAM) system. We first develop a machine learning convolutional neural network (CNN) model for establishing the correlations from the measurable molten pool image and temperature data directly to the geometric shape and microstructural properties. The multi-modality network receives both the camera image and temperature measurement as inputs, yielding the corresponding characterization properties of the final build part (e.g., fusion zone depth, alpha lath thickness). The performance of the CNN model is compared with the regression model as a baseline. The developed models enable molten pool condition-quality relations mapping for building quantitative and collaborative in situ quality estimation and assurance framework.

</p>
</details>

<details><summary><b>Smart Scheduling based on Deep Reinforcement Learning for Cellular Networks</b>
<a href="https://arxiv.org/abs/2103.11542">arxiv:2103.11542</a>
&#x1F4C8; 2 <br>
<p>Jian Wang, Chen Xu, Rong Li, Yiqun Ge, Jun Wang</p></summary>
<p>

**Abstract:** To improve the system performance towards the Shannon limit, advanced radio resource management mechanisms play a fundamental role. In particular, scheduling should receive much attention, because it allocates radio resources among different users in terms of their channel conditions and QoS requirements. The difficulties of scheduling algorithms are the tradeoffs need to be made among multiple objectives, such as throughput, fairness and packet drop rate. We propose a smart scheduling scheme based on deep reinforcement learning (DRL). We not only verify the performance gain achieved, but also provide implementation-friend designs, i.e., a scalable neural network design for the agent and a virtual environment training framework. With the scalable neural network design, the DRL agent can easily handle the cases when the number of active users is time-varying without the need to redesign and retrain the DRL agent. Training the DRL agent in a virtual environment offline first and using it as the initial version in the practical usage helps to prevent the system from suffering from performance and robustness degradation due to the time-consuming training. Through both simulations and field tests, we show that the DRL-based smart scheduling outperforms the conventional scheduling method and can be adopted in practical systems.

</p>
</details>

<details><summary><b>How to Design Sample and Computationally Efficient VQA Models</b>
<a href="https://arxiv.org/abs/2103.11537">arxiv:2103.11537</a>
&#x1F4C8; 2 <br>
<p>Karan Samel, Zelin Zhao, Binghong Chen, Kuan Wang, Robin Luo, Le Song</p></summary>
<p>

**Abstract:** In multi-modal reasoning tasks, such as visual question answering (VQA), there have been many modeling and training paradigms tested. Previous models propose different methods for the vision and language tasks, but which ones perform the best while being sample and computationally efficient? Based on our experiments, we find that representing the text as probabilistic programs and images as object-level scene graphs best satisfy these desiderata. We extend existing models to leverage these soft programs and scene graphs to train on question answer pairs in an end-to-end manner. Empirical results demonstrate that this differentiable end-to-end program executor is able to maintain state-of-the-art accuracy while being sample and computationally efficient.

</p>
</details>

<details><summary><b>Conditional Frechet Inception Distance</b>
<a href="https://arxiv.org/abs/2103.11521">arxiv:2103.11521</a>
&#x1F4C8; 2 <br>
<p>Michael Soloveitchik, Tzvi Diskin, Efrat Morin, Ami Wiesel</p></summary>
<p>

**Abstract:** We consider distance functions between conditional distributions functions. We focus on the Wasserstein metric and its Gaussian case known as the Frechet Inception Distance (FID).We develop conditional versions of these metrics, and analyze their relations. Then, we numerically compare the metrics inthe context of performance evaluation of conditional generative models. Our results show that the metrics are similar in classical models which are less susceptible to conditional collapse. But the conditional distances are more informative in modern unsuper-vised, semisupervised and unpaired models where learning the relations between the inputs and outputs is the main challenge.

</p>
</details>

<details><summary><b>Paying Attention to Activation Maps in Camera Pose Regression</b>
<a href="https://arxiv.org/abs/2103.11477">arxiv:2103.11477</a>
&#x1F4C8; 2 <br>
<p>Yoli Shavit, Ron Ferens, Yosi Keller</p></summary>
<p>

**Abstract:** Camera pose regression methods apply a single forward pass to the query image to estimate the camera pose. As such, they offer a fast and light-weight alternative to traditional localization schemes based on image retrieval. Pose regression approaches simultaneously learn two regression tasks, aiming to jointly estimate the camera position and orientation using a single embedding vector computed by a convolutional backbone. We propose an attention-based approach for pose regression, where the convolutional activation maps are used as sequential inputs. Transformers are applied to encode the sequential activation maps as latent vectors, used for camera pose regression. This allows us to pay attention to spatially-varying deep features. Using two Transformer heads, we separately focus on the features for camera position and orientation, based on how informative they are per task. Our proposed approach is shown to compare favorably to contemporary pose regressors schemes and achieves state-of-the-art accuracy across multiple outdoor and indoor benchmarks. In particular, to the best of our knowledge, our approach is the only method to attain sub-meter average accuracy across outdoor scenes. We make our code publicly available from here.

</p>
</details>

<details><summary><b>NeBula: Quest for Robotic Autonomy in Challenging Environments; TEAM CoSTAR at the DARPA Subterranean Challenge</b>
<a href="https://arxiv.org/abs/2103.11470">arxiv:2103.11470</a>
&#x1F4C8; 2 <br>
<p>Ali Agha, Kyohei Otsu, Benjamin Morrell, David D. Fan, Rohan Thakker, Angel Santamaria-Navarro, Sung-Kyun Kim, Amanda Bouman, Xianmei Lei, Jeffrey Edlund, Muhammad Fadhil Ginting, Kamak Ebadi, Matthew Anderson, Torkom Pailevanian, Edward Terry, Michael Wolf, Andrea Tagliabue, Tiago Stegun Vaquero, Matteo Palieri, Scott Tepsuporn, Yun Chang, Arash Kalantari, Fernando Chavez, Brett Lopez, Nobuhiro Funabiki</p></summary>
<p>

**Abstract:** This paper presents and discusses algorithms, hardware, and software architecture developed by the TEAM CoSTAR (Collaborative SubTerranean Autonomous Robots), competing in the DARPA Subterranean Challenge. Specifically, it presents the techniques utilized within the Tunnel (2019) and Urban (2020) competitions, where CoSTAR achieved 2nd and 1st place, respectively. We also discuss CoSTAR's demonstrations in Martian-analog surface and subsurface (lava tubes) exploration. The paper introduces our autonomy solution, referred to as NeBula (Networked Belief-aware Perceptual Autonomy). NeBula is an uncertainty-aware framework that aims at enabling resilient and modular autonomy solutions by performing reasoning and decision making in the belief space (space of probability distributions over the robot and world states). We discuss various components of the NeBula framework, including: (i) geometric and semantic environment mapping; (ii) a multi-modal positioning system; (iii) traversability analysis and local planning; (iv) global motion planning and exploration behavior; (i) risk-aware mission planning; (vi) networking and decentralized reasoning; and (vii) learning-enabled adaptation. We discuss the performance of NeBula on several robot types (e.g. wheeled, legged, flying), in various environments. We discuss the specific results and lessons learned from fielding this solution in the challenging courses of the DARPA Subterranean Challenge competition.

</p>
</details>

<details><summary><b>Robust Cell-Load Learning with a Small Sample Set</b>
<a href="https://arxiv.org/abs/2103.11467">arxiv:2103.11467</a>
&#x1F4C8; 2 <br>
<p>Daniyal Amir Awan, Renato L. G. Cavalcante, Slawomir Stanczak</p></summary>
<p>

**Abstract:** Learning of the cell-load in radio access networks (RANs) has to be performed within a short time period. Therefore, we propose a learning framework that is robust against uncertainties resulting from the need for learning based on a relatively small training sample set. To this end, we incorporate prior knowledge about the cell-load in the learning framework. For example, an inherent property of the cell-load is that it is monotonic in downlink (data) rates. To obtain additional prior knowledge we first study the feasible rate region, i.e., the set of all vectors of user rates that can be supported by the network. We prove that the feasible rate region is compact. Moreover, we show the existence of a Lipschitz function that maps feasible rate vectors to cell-load vectors. With these results in hand, we present a learning technique that guarantees a minimum approximation error in the worst-case scenario by using prior knowledge and a small training sample set. Simulations in the network simulator NS3 demonstrate that the proposed method exhibits better robustness and accuracy than standard multivariate learning techniques, especially for small training sample sets.

</p>
</details>

<details><summary><b>SEMIE: SEMantically Infused Embeddings with Enhanced Interpretability for Domain-specific Small Corpus</b>
<a href="https://arxiv.org/abs/2103.11431">arxiv:2103.11431</a>
&#x1F4C8; 2 <br>
<p>Rishabh Gupta, Rajesh N Rao</p></summary>
<p>

**Abstract:** Word embeddings are a basic building block of modern NLP pipelines. Efforts have been made to learn rich, efficient, and interpretable embeddings for large generic datasets available in the public domain. However, these embeddings have limited applicability for small corpora from specific domains such as automotive, manufacturing, maintenance and support, etc. In this work, we present a comprehensive notion of interpretability for word embeddings and propose a novel method to generate highly interpretable and efficient embeddings for a domain-specific small corpus. We report the evaluation results of our resulting word embeddings and demonstrate their novel features for enhanced interpretability.

</p>
</details>

<details><summary><b>ProgressiveSpinalNet architecture for FC layers</b>
<a href="https://arxiv.org/abs/2103.11373">arxiv:2103.11373</a>
&#x1F4C8; 2 <br>
<p>Praveen Chopra</p></summary>
<p>

**Abstract:** In deeplearning models the FC (fully connected) layer has biggest important role for classification of the input based on the learned features from previous layers. The FC layers has highest numbers of parameters and fine-tuning these large numbers of parameters, consumes most of the computational resources, so in this paper it is aimed to reduce these large numbers of parameters significantly with improved performance. The motivation is inspired from SpinalNet and other biological architecture. The proposed architecture has a gradient highway between input to output layers and this solves the problem of diminishing gradient in deep networks. In this all the layers receives the input from previous layers as well as the CNN layer output and this way all layers contribute in decision making with last layer. This approach has improved classification performance over the SpinalNet architecture and has SOTA performance on many datasets such as Caltech101, KMNIST, QMNIST and EMNIST. The source code is available at https://github.com/praveenchopra/ProgressiveSpinalNet.

</p>
</details>

<details><summary><b>Structural block driven - enhanced convolutional neural representation for relation extraction</b>
<a href="https://arxiv.org/abs/2103.11356">arxiv:2103.11356</a>
&#x1F4C8; 2 <br>
<p>Dongsheng Wang, Prayag Tiwari, Sahil Garg, Hongyin Zhu, Peter Bruza</p></summary>
<p>

**Abstract:** In this paper, we propose a novel lightweight relation extraction approach of structural block driven - convolutional neural learning. Specifically, we detect the essential sequential tokens associated with entities through dependency analysis, named as a structural block, and only encode the block on a block-wise and an inter-block-wise representation, utilizing multi-scale CNNs. This is to 1) eliminate the noisy from irrelevant part of a sentence; meanwhile 2) enhance the relevant block representation with both block-wise and inter-block-wise semantically enriched representation. Our method has the advantage of being independent of long sentence context since we only encode the sequential tokens within a block boundary. Experiments on two datasets i.e., SemEval2010 and KBP37, demonstrate the significant advantages of our method. In particular, we achieve the new state-of-the-art performance on the KBP37 dataset; and comparable performance with the state-of-the-art on the SemEval2010 dataset.

</p>
</details>

<details><summary><b>Neighbor Embedding Variational Autoencoder</b>
<a href="https://arxiv.org/abs/2103.11349">arxiv:2103.11349</a>
&#x1F4C8; 2 <br>
<p>Renfei Tu, Yang Liu, Yongzeng Xue, Cheng Wang, Maozu Guo</p></summary>
<p>

**Abstract:** Being one of the most popular generative framework, variational autoencoders(VAE) are known to suffer from a phenomenon termed posterior collapse, i.e. the latent variational distributions collapse to the prior, especially when a strong decoder network is used. In this work, we analyze the latent representation of collapsed VAEs, and proposed a novel model, neighbor embedding VAE(NE-VAE), which explicitly constraints the encoder to encode inputs close in the input space to be close in the latent space. We observed that for VAE variants that report similar ELBO, KL divergence or even mutual information scores may still behave quite differently in the latent organization. In our experiments, NE-VAE can produce qualitatively different latent representations with majority of the latent dimensions remained active, which may benefit downstream latent space optimization tasks. NE-VAE can prevent posterior collapse to a much greater extent than it's predecessors, and can be easily plugged into any autoencoder framework, without introducing addition model components and complex training routines.

</p>
</details>

<details><summary><b>Integrating Electrochemical Modeling with Machine Learning for Lithium-Ion Batteries</b>
<a href="https://arxiv.org/abs/2103.11580">arxiv:2103.11580</a>
&#x1F4C8; 1 <br>
<p>Hao Tu, Scott Moura, Huazhen Fang</p></summary>
<p>

**Abstract:** Mathematical modeling of lithium-ion batteries (LiBs) is a central challenge in advanced battery management. This paper presents a new approach to integrate a physics-based model with machine learning to achieve high-precision modeling for LiBs. This approach uniquely proposes to inform the machine learning model of the dynamic state of the physical model, enabling a deep integration between physics and machine learning. We propose two hybrid physics-machine learning models based on the approach, which blend a single particle model with thermal dynamics (SPMT) with a feedforward neural network (FNN) to perform physics-informed learning of a LiB's dynamic behavior. The proposed models are relatively parsimonious in structure and can provide considerable predictive accuracy even at high C-rates, as shown by extensive simulations.

</p>
</details>

<details><summary><b>Towards Improving the Trustworthiness of Hardware based Malware Detector using Online Uncertainty Estimation</b>
<a href="https://arxiv.org/abs/2103.11519">arxiv:2103.11519</a>
&#x1F4C8; 1 <br>
<p>Harshit Kumar, Nikhil Chawla, Saibal Mukhopadhyay</p></summary>
<p>

**Abstract:** Hardware-based Malware Detectors (HMDs) using Machine Learning (ML) models have shown promise in detecting malicious workloads. However, the conventional black-box based machine learning (ML) approach used in these HMDs fail to address the uncertain predictions, including those made on zero-day malware. The ML models used in HMDs are agnostic to the uncertainty that determines whether the model "knows what it knows," severely undermining its trustworthiness. We propose an ensemble-based approach that quantifies uncertainty in predictions made by ML models of an HMD, when it encounters an unknown workload than the ones it was trained on. We test our approach on two different HMDs that have been proposed in the literature. We show that the proposed uncertainty estimator can detect >90% of unknown workloads for the Power-management based HMD, and conclude that the overlapping benign and malware classes undermine the trustworthiness of the Performance Counter-based HMD.

</p>
</details>

<details><summary><b>Scatter Correction in X-ray CT by Physics-Inspired Deep Learning</b>
<a href="https://arxiv.org/abs/2103.11509">arxiv:2103.11509</a>
&#x1F4C8; 1 <br>
<p>Berk Iskender, Yoram Bresler</p></summary>
<p>

**Abstract:** A fundamental problem in X-ray Computed Tomography (CT) is the scatter due to interaction of photons with the imaged object. Unless corrected, scatter manifests itself as degradations in the reconstructions in the form of various artifacts. Scatter correction is therefore critical for reconstruction quality. Scatter correction methods can be divided into two categories: hardware-based; and software-based. Despite success in specific settings, hardware-based methods require modification in the hardware, or increase in the scan time or dose. This makes software-based methods attractive. In this context, Monte-Carlo based scatter estimation, analytical-numerical, and kernel-based methods were developed. Furthermore, data-driven approaches to tackle this problem were recently demonstrated. In this work, two novel physics-inspired deep-learning-based methods, PhILSCAT and OV-PhILSCAT, are proposed. The methods estimate and correct for the scatter in the acquired projection measurements. They incorporate both an initial reconstruction of the object of interest and the scatter-corrupted measurements related to it. They use a common deep neural network architecture and cost function, both tailored to the problem. Numerical experiments with data obtained by Monte-Carlo simulations of the imaging of phantoms reveal significant improvement over a recent purely projection-domain deep neural network scatter correction method.

</p>
</details>

<details><summary><b>Set-Theoretic Learning for Detection in Cell-Less C-RAN Systems</b>
<a href="https://arxiv.org/abs/2103.11456">arxiv:2103.11456</a>
&#x1F4C8; 1 <br>
<p>Daniyal Amir Awan, Renato L. G. Cavalcante, Zoran Utkovski, Slawomir Stanczak</p></summary>
<p>

**Abstract:** Cloud-radio access network (C-RAN) can enable cell-less operation by connecting distributed remote radio heads (RRHs) via fronthaul links to a powerful central unit. In conventional C-RAN, baseband signals are forwarded after quantization/ compression to the central unit for centralized processing to keep the complexity of the RRHs low. However, the limited capacity of the fronthaul is thought to be a significant bottleneck in the ability of C-RAN to support large systems (e.g. massive machine-type communications (mMTC)). Therefore, in contrast to the conventional C-RAN, we propose a learning-based system in which the detection is performed locally at each RRH and only the likelihood information is conveyed to the CU. To this end, we develop a general set-theoretic learningmethod to estimate likelihood functions. The method can be used to extend existing detection methods to the C-RAN setting.

</p>
</details>

<details><summary><b>Quantum Machine Learning with HQC Architectures using non-Classically Simulable Feature Maps</b>
<a href="https://arxiv.org/abs/2103.11381">arxiv:2103.11381</a>
&#x1F4C8; 1 <br>
<p>Syed Farhan Ahmad, Raghav Rawat, Minal Moharir</p></summary>
<p>

**Abstract:** Hybrid Quantum-Classical (HQC) Architectures are used in near-term NISQ Quantum Computers for solving Quantum Machine Learning problems. The quantum advantage comes into picture due to the exponential speedup offered over classical computing. One of the major challenges in implementing such algorithms is the choice of quantum embeddings and the use of a functionally correct quantum variational circuit. In this paper, we present an application of QSVM (Quantum Support Vector Machines) to predict if a person will require mental health treatment in the tech world in the future using the dataset from OSMI Mental Health Tech Surveys. We achieve this with non-classically simulable feature maps and prove that NISQ HQC Architectures for Quantum Machine Learning can be used alternatively to create good performance models in near-term real-world applications.

</p>
</details>

<details><summary><b>BigCarl: Mining frequent subnets from a single large Petri net</b>
<a href="https://arxiv.org/abs/2103.11342">arxiv:2103.11342</a>
&#x1F4C8; 1 <br>
<p>Ruqian Lu, Shuhan Zhang</p></summary>
<p>

**Abstract:** While there have been lots of work studying frequent subgraph mining, very rare publications have discussed frequent subnet mining from more complicated data structures such as Petri nets. This paper studies frequent subnets mining from a single large Petri net. We follow the idea of transforming a Petri net in net graph form and to mine frequent sub-net graphs to avoid high complexity. Technically, we take a minimal traversal approach to produce a canonical label of the big net graph. We adapted the maximal independent embedding set approach to the net graph representation and proposed an incremental pattern growth (independent embedding set reduction) way for discovering frequent sub-net graphs from the single large net graph, which are finally transformed back to frequent subnets. Extensive performance studies made on a single large Petri net, which contains 10K events, 40K conditions and 30 K arcs, showed that our approach is correct and the complexity is reasonable.

</p>
</details>

<details><summary><b>ANITA: An Optimal Loopless Accelerated Variance-Reduced Gradient Method</b>
<a href="https://arxiv.org/abs/2103.11333">arxiv:2103.11333</a>
&#x1F4C8; 1 <br>
<p>Zhize Li</p></summary>
<p>

**Abstract:** In this paper, we propose a novel accelerated gradient method called ANITA for solving the fundamental finite-sum optimization problems. Concretely, we consider both general convex and strongly convex settings: i) For general convex finite-sum problems, ANITA improves previous state-of-the-art result given by Varag (Lan et al., 2019). In particular, for large-scale problems or the target error is not very small, i.e., $n \geq \frac{1}{Œµ^2}$, ANITA obtains the \emph{first} optimal result $O(n)$, matching the lower bound $Œ©(n)$ provided by Woodworth and Srebro (2016), while previous results are $O(n \log \frac{1}Œµ)$ of Varag (Lan et al., 2019) and $O(\frac{n}{\sqrtŒµ})$ of Katyusha (Allen-Zhu, 2017). ii) For strongly convex finite-sum problems, we also show that ANITA can achieve the optimal convergence rate $O\big((n+\sqrt{\frac{nL}Œº})\log\frac{1}Œµ\big)$ matching the lower bound $Œ©\big((n+\sqrt{\frac{nL}Œº})\log\frac{1}Œµ\big)$ provided by Lan and Zhou (2015). Besides, ANITA enjoys a simpler loopless algorithmic structure unlike previous accelerated algorithms such as Varag (Lan et al., 2019) and Katyusha (Allen-Zhu, 2017) where they use an inconvenient double-loop structure. Moreover, by exploiting the loopless structure of ANITA, we provide a new \emph{dynamic multi-stage convergence analysis}, which is the key technical part for improving previous results to the optimal rates. Finally, the numerical experiments show that ANITA converges faster than the previous state-of-the-art Varag (Lan et al., 2019), validating our theoretical results and confirming the practical superiority of ANITA. We believe that our new theoretical rates and convergence analysis for this fundamental finite-sum problem will directly lead to key improvements for many other related problems, such as distributed/federated/decentralized optimization problems.

</p>
</details>


[Next Page]({{ '/2021/03/20/2021.03.20.html' | relative_url }})
