## Summary for 2021-09-24, created on 2021-12-18


<details><summary><b>Learning to Walk in Minutes Using Massively Parallel Deep Reinforcement Learning</b>
<a href="https://arxiv.org/abs/2109.11978">arxiv:2109.11978</a>
&#x1F4C8; 149 <br>
<p>Nikita Rudin, David Hoeller, Philipp Reist, Marco Hutter</p></summary>
<p>

**Abstract:** In this work, we present and study a training set-up that achieves fast policy generation for real-world robotic tasks by using massive parallelism on a single workstation GPU. We analyze and discuss the impact of different training algorithm components in the massively parallel regime on the final policy performance and training times. In addition, we present a novel game-inspired curriculum that is well suited for training with thousands of simulated robots in parallel. We evaluate the approach by training the quadrupedal robot ANYmal to walk on challenging terrain. The parallel approach allows training policies for flat terrain in under four minutes, and in twenty minutes for uneven terrain. This represents a speedup of multiple orders of magnitude compared to previous work. Finally, we transfer the policies to the real robot to validate the approach. We open-source our training code to help accelerate further research in the field of learned legged locomotion.

</p>
</details>

<details><summary><b>CLIPort: What and Where Pathways for Robotic Manipulation</b>
<a href="https://arxiv.org/abs/2109.12098">arxiv:2109.12098</a>
&#x1F4C8; 107 <br>
<p>Mohit Shridhar, Lucas Manuelli, Dieter Fox</p></summary>
<p>

**Abstract:** How can we imbue robots with the ability to manipulate objects precisely but also to reason about them in terms of abstract concepts? Recent works in manipulation have shown that end-to-end networks can learn dexterous skills that require precise spatial reasoning, but these methods often fail to generalize to new goals or quickly learn transferable concepts across tasks. In parallel, there has been great progress in learning generalizable semantic representations for vision and language by training on large-scale internet data, however these representations lack the spatial understanding necessary for fine-grained manipulation. To this end, we propose a framework that combines the best of both worlds: a two-stream architecture with semantic and spatial pathways for vision-based manipulation. Specifically, we present CLIPort, a language-conditioned imitation-learning agent that combines the broad semantic understanding (what) of CLIP [1] with the spatial precision (where) of Transporter [2]. Our end-to-end framework is capable of solving a variety of language-specified tabletop tasks from packing unseen objects to folding cloths, all without any explicit representations of object poses, instance segmentations, memory, symbolic states, or syntactic structures. Experiments in simulated and real-world settings show that our approach is data efficient in few-shot settings and generalizes effectively to seen and unseen semantic concepts. We even learn one multi-task policy for 10 simulated and 9 real-world tasks that is better or comparable to single-task policies.

</p>
</details>

<details><summary><b>Sample Efficient Model Evaluation</b>
<a href="https://arxiv.org/abs/2109.12043">arxiv:2109.12043</a>
&#x1F4C8; 87 <br>
<p>Emine Yilmaz, Peter Hayes, Raza Habib, Jordan Burgess, David Barber</p></summary>
<p>

**Abstract:** Labelling data is a major practical bottleneck in training and testing classifiers. Given a collection of unlabelled data points, we address how to select which subset to label to best estimate test metrics such as accuracy, $F_1$ score or micro/macro $F_1$. We consider two sampling based approaches, namely the well-known Importance Sampling and we introduce a novel application of Poisson Sampling. For both approaches we derive the minimal error sampling distributions and how to approximate and use them to form estimators and confidence intervals. We show that Poisson Sampling outperforms Importance Sampling both theoretically and experimentally.

</p>
</details>

<details><summary><b>Visual Scene Graphs for Audio Source Separation</b>
<a href="https://arxiv.org/abs/2109.11955">arxiv:2109.11955</a>
&#x1F4C8; 73 <br>
<p>Moitreya Chatterjee, Jonathan Le Roux, Narendra Ahuja, Anoop Cherian</p></summary>
<p>

**Abstract:** State-of-the-art approaches for visually-guided audio source separation typically assume sources that have characteristic sounds, such as musical instruments. These approaches often ignore the visual context of these sound sources or avoid modeling object interactions that may be useful to better characterize the sources, especially when the same object class may produce varied sounds from distinct interactions. To address this challenging problem, we propose Audio Visual Scene Graph Segmenter (AVSGS), a novel deep learning model that embeds the visual structure of the scene as a graph and segments this graph into subgraphs, each subgraph being associated with a unique sound obtained by co-segmenting the audio spectrogram. At its core, AVSGS uses a recursive neural network that emits mutually-orthogonal sub-graph embeddings of the visual graph using multi-head attention. These embeddings are used for conditioning an audio encoder-decoder towards source separation. Our pipeline is trained end-to-end via a self-supervised task consisting of separating audio sources using the visual graph from artificially mixed sounds. In this paper, we also introduce an "in the wild'' video dataset for sound source separation that contains multiple non-musical sources, which we call Audio Separation in the Wild (ASIW). This dataset is adapted from the AudioCaps dataset, and provides a challenging, natural, and daily-life setting for source separation. Thorough experiments on the proposed ASIW and the standard MUSIC datasets demonstrate state-of-the-art sound separation performance of our method against recent prior approaches.

</p>
</details>

<details><summary><b>Separating Retention from Extraction in the Evaluation of End-to-end Relation Extraction</b>
<a href="https://arxiv.org/abs/2109.12008">arxiv:2109.12008</a>
&#x1F4C8; 45 <br>
<p>Bruno Taillé, Vincent Guigue, Geoffrey Scoutheeten, Patrick Gallinari</p></summary>
<p>

**Abstract:** State-of-the-art NLP models can adopt shallow heuristics that limit their generalization capability (McCoy et al., 2019). Such heuristics include lexical overlap with the training set in Named-Entity Recognition (Taillé et al., 2020) and Event or Type heuristics in Relation Extraction (Rosenman et al., 2020). In the more realistic end-to-end RE setting, we can expect yet another heuristic: the mere retention of training relation triples. In this paper, we propose several experiments confirming that retention of known facts is a key factor of performance on standard benchmarks. Furthermore, one experiment suggests that a pipeline model able to use intermediate type representations is less prone to over-rely on retention.

</p>
</details>

<details><summary><b>AI Explainability 360: Impact and Design</b>
<a href="https://arxiv.org/abs/2109.12151">arxiv:2109.12151</a>
&#x1F4C8; 44 <br>
<p>Vijay Arya, Rachel K. E. Bellamy, Pin-Yu Chen, Amit Dhurandhar, Michael Hind, Samuel C. Hoffman, Stephanie Houde, Q. Vera Liao, Ronny Luss, Aleksandra Mojsilovic, Sami Mourad, Pablo Pedemonte, Ramya Raghavendra, John Richards, Prasanna Sattigeri, Karthikeyan Shanmugam, Moninder Singh, Kush R. Varshney, Dennis Wei, Yunfeng Zhang</p></summary>
<p>

**Abstract:** As artificial intelligence and machine learning algorithms become increasingly prevalent in society, multiple stakeholders are calling for these algorithms to provide explanations. At the same time, these stakeholders, whether they be affected citizens, government regulators, domain experts, or system developers, have different explanation needs. To address these needs, in 2019, we created AI Explainability 360 (Arya et al. 2020), an open source software toolkit featuring ten diverse and state-of-the-art explainability methods and two evaluation metrics. This paper examines the impact of the toolkit with several case studies, statistics, and community feedback. The different ways in which users have experienced AI Explainability 360 have resulted in multiple types of impact and improvements in multiple metrics, highlighted by the adoption of the toolkit by the independent LF AI & Data Foundation. The paper also describes the flexible design of the toolkit, examples of its use, and the significant educational material and documentation available to its users.

</p>
</details>

<details><summary><b>Detecting Harmful Memes and Their Targets</b>
<a href="https://arxiv.org/abs/2110.00413">arxiv:2110.00413</a>
&#x1F4C8; 40 <br>
<p>Shraman Pramanick, Dimitar Dimitrov, Rituparna Mukherjee, Shivam Sharma, Md. Shad Akhtar, Preslav Nakov, Tanmoy Chakraborty</p></summary>
<p>

**Abstract:** Among the various modes of communication in social media, the use of Internet memes has emerged as a powerful means to convey political, psychological, and socio-cultural opinions. Although memes are typically humorous in nature, recent days have witnessed a proliferation of harmful memes targeted to abuse various social entities. As most harmful memes are highly satirical and abstruse without appropriate contexts, off-the-shelf multimodal models may not be adequate to understand their underlying semantics. In this work, we propose two novel problem formulations: detecting harmful memes and the social entities that these harmful memes target. To this end, we present HarMeme, the first benchmark dataset, containing 3,544 memes related to COVID-19. Each meme went through a rigorous two-stage annotation process. In the first stage, we labeled a meme as very harmful, partially harmful, or harmless; in the second stage, we further annotated the type of target(s) that each harmful meme points to: individual, organization, community, or society/general public/other. The evaluation results using ten unimodal and multimodal models highlight the importance of using multimodal signals for both tasks. We further discuss the limitations of these models and we argue that more research is needed to address these problems.

</p>
</details>

<details><summary><b>Beyond Distillation: Task-level Mixture-of-Experts for Efficient Inference</b>
<a href="https://arxiv.org/abs/2110.03742">arxiv:2110.03742</a>
&#x1F4C8; 24 <br>
<p>Sneha Kudugunta, Yanping Huang, Ankur Bapna, Maxim Krikun, Dmitry Lepikhin, Minh-Thang Luong, Orhan Firat</p></summary>
<p>

**Abstract:** Sparse Mixture-of-Experts (MoE) has been a successful approach for scaling multilingual translation models to billions of parameters without a proportional increase in training computation. However, MoE models are prohibitively large and practitioners often resort to methods such as distillation for serving. In this work, we investigate routing strategies at different granularity (token, sentence, task) in MoE models to bypass distillation. Experiments on WMT and a web-scale dataset suggest that task-level routing (task-MoE) enables us to extract smaller, ready-to-deploy sub-networks from large sparse models. On WMT, our task-MoE with 32 experts (533M parameters) outperforms the best performing token-level MoE model (token-MoE) by +1.0 BLEU on average across 30 language pairs. The peak inference throughput is also improved by a factor of 1.9x when we route by tasks instead of tokens. While distilling a token-MoE to a smaller dense model preserves only 32% of the BLEU gains, our sub-network task-MoE, by design, preserves all the gains with the same inference cost as the distilled student model. Finally, when scaling up to 200 language pairs, our 128-expert task-MoE (13B parameters) performs competitively with a token-level counterpart, while improving the peak inference throughput by a factor of 2.6x.

</p>
</details>

<details><summary><b>Pythia: A Customizable Hardware Prefetching Framework Using Online Reinforcement Learning</b>
<a href="https://arxiv.org/abs/2109.12021">arxiv:2109.12021</a>
&#x1F4C8; 17 <br>
<p>Rahul Bera, Konstantinos Kanellopoulos, Anant V. Nori, Taha Shahroodi, Sreenivas Subramoney, Onur Mutlu</p></summary>
<p>

**Abstract:** Past research has proposed numerous hardware prefetching techniques, most of which rely on exploiting one specific type of program context information (e.g., program counter, cacheline address) to predict future memory accesses. These techniques either completely neglect a prefetcher's undesirable effects (e.g., memory bandwidth usage) on the overall system, or incorporate system-level feedback as an afterthought to a system-unaware prefetch algorithm. We show that prior prefetchers often lose their performance benefit over a wide range of workloads and system configurations due to their inherent inability to take multiple different types of program context and system-level feedback information into account while prefetching. In this paper, we make a case for designing a holistic prefetch algorithm that learns to prefetch using multiple different types of program context and system-level feedback information inherent to its design.
  To this end, we propose Pythia, which formulates the prefetcher as a reinforcement learning agent. For every demand request, Pythia observes multiple different types of program context information to make a prefetch decision. For every prefetch decision, Pythia receives a numerical reward that evaluates prefetch quality under the current memory bandwidth usage. Pythia uses this reward to reinforce the correlation between program context information and prefetch decision to generate highly accurate, timely, and system-aware prefetch requests in the future. Our extensive evaluations using simulation and hardware synthesis show that Pythia outperforms multiple state-of-the-art prefetchers over a wide range of workloads and system configurations, while incurring only 1.03% area overhead over a desktop-class processor and no software changes in workloads. The source code of Pythia can be freely downloaded from https://github.com/CMU-SAFARI/Pythia.

</p>
</details>

<details><summary><b>RuleBert: Teaching Soft Rules to Pre-trained Language Models</b>
<a href="https://arxiv.org/abs/2109.13006">arxiv:2109.13006</a>
&#x1F4C8; 10 <br>
<p>Mohammed Saeed, Naser Ahmadi, Preslav Nakov, Paolo Papotti</p></summary>
<p>

**Abstract:** While pre-trained language models (PLMs) are the go-to solution to tackle many natural language processing problems, they are still very limited in their ability to capture and to use common-sense knowledge. In fact, even if information is available in the form of approximate (soft) logical rules, it is not clear how to transfer it to a PLM in order to improve its performance for deductive reasoning tasks. Here, we aim to bridge this gap by teaching PLMs how to reason with soft Horn rules. We introduce a classification task where, given facts and soft rules, the PLM should return a prediction with a probability for a given hypothesis. We release the first dataset for this task, and we propose a revised loss function that enables the PLM to learn how to predict precise probabilities for the task. Our evaluation results show that the resulting fine-tuned models achieve very high performance, even on logical rules that were unseen at training. Moreover, we demonstrate that logical notions expressed by the rules are transferred to the fine-tuned model, yielding state-of-the-art results on external datasets.

</p>
</details>

<details><summary><b>Optimal policy evaluation using kernel-based temporal difference methods</b>
<a href="https://arxiv.org/abs/2109.12002">arxiv:2109.12002</a>
&#x1F4C8; 9 <br>
<p>Yaqi Duan, Mengdi Wang, Martin J. Wainwright</p></summary>
<p>

**Abstract:** We study methods based on reproducing kernel Hilbert spaces for estimating the value function of an infinite-horizon discounted Markov reward process (MRP). We study a regularized form of the kernel least-squares temporal difference (LSTD) estimate; in the population limit of infinite data, it corresponds to the fixed point of a projected Bellman operator defined by the associated reproducing kernel Hilbert space. The estimator itself is obtained by computing the projected fixed point induced by a regularized version of the empirical operator; due to the underlying kernel structure, this reduces to solving a linear system involving kernel matrices. We analyze the error of this estimate in the $L^2(μ)$-norm, where $μ$ denotes the stationary distribution of the underlying Markov chain. Our analysis imposes no assumptions on the transition operator of the Markov chain, but rather only conditions on the reward function and population-level kernel LSTD solutions. We use empirical process theory techniques to derive a non-asymptotic upper bound on the error with explicit dependence on the eigenvalues of the associated kernel operator, as well as the instance-dependent variance of the Bellman residual error. In addition, we prove minimax lower bounds over sub-classes of MRPs, which shows that our rate is optimal in terms of the sample size $n$ and the effective horizon $H = (1 - γ)^{-1}$. Whereas existing worst-case theory predicts cubic scaling ($H^3$) in the effective horizon, our theory reveals that there is in fact a much wider range of scalings, depending on the kernel, the stationary distribution, and the variance of the Bellman residual error. Notably, it is only parametric and near-parametric problems that can ever achieve the worst-case cubic scaling.

</p>
</details>

<details><summary><b>Is the Number of Trainable Parameters All That Actually Matters?</b>
<a href="https://arxiv.org/abs/2109.11928">arxiv:2109.11928</a>
&#x1F4C8; 9 <br>
<p>Amélie Chatelain, Amine Djeghri, Daniel Hesslow, Julien Launay, Iacopo Poli</p></summary>
<p>

**Abstract:** Recent work has identified simple empirical scaling laws for language models, linking compute budget, dataset size, model size, and autoregressive modeling loss. The validity of these simple power laws across orders of magnitude in model scale provides compelling evidence that larger models are also more capable models. However, scaling up models under the constraints of hardware and infrastructure is no easy feat, and rapidly becomes a hard and expensive engineering problem. We investigate ways to tentatively cheat scaling laws, and train larger models for cheaper. We emulate an increase in effective parameters, using efficient approximations: either by doping the models with frozen random parameters, or by using fast structured transforms in place of dense linear layers. We find that the scaling relationship between test loss and compute depends only on the actual number of trainable parameters; scaling laws cannot be deceived by spurious parameters.

</p>
</details>

<details><summary><b>An animated picture says at least a thousand words: Selecting Gif-based Replies in Multimodal Dialog</b>
<a href="https://arxiv.org/abs/2109.12212">arxiv:2109.12212</a>
&#x1F4C8; 8 <br>
<p>Xingyao Wang, David Jurgens</p></summary>
<p>

**Abstract:** Online conversations include more than just text. Increasingly, image-based responses such as memes and animated gifs serve as culturally recognized and often humorous responses in conversation. However, while NLP has broadened to multimodal models, conversational dialog systems have largely focused only on generating text replies. Here, we introduce a new dataset of 1.56M text-gif conversation turns and introduce a new multimodal conversational model Pepe the King Prawn for selecting gif-based replies. We demonstrate that our model produces relevant and high-quality gif responses and, in a large randomized control trial of multiple models replying to real users, we show that our model replies with gifs that are significantly better received by the community.

</p>
</details>

<details><summary><b>Adversarial Domain Feature Adaptation for Bronchoscopic Depth Estimation</b>
<a href="https://arxiv.org/abs/2109.11798">arxiv:2109.11798</a>
&#x1F4C8; 8 <br>
<p>Mert Asim Karaoglu, Nikolas Brasch, Marijn Stollenga, Wolfgang Wein, Nassir Navab, Federico Tombari, Alexander Ladikos</p></summary>
<p>

**Abstract:** Depth estimation from monocular images is an important task in localization and 3D reconstruction pipelines for bronchoscopic navigation. Various supervised and self-supervised deep learning-based approaches have proven themselves on this task for natural images. However, the lack of labeled data and the bronchial tissue's feature-scarce texture make the utilization of these methods ineffective on bronchoscopic scenes. In this work, we propose an alternative domain-adaptive approach. Our novel two-step structure first trains a depth estimation network with labeled synthetic images in a supervised manner; then adopts an unsupervised adversarial domain feature adaptation scheme to improve the performance on real images. The results of our experiments show that the proposed method improves the network's performance on real images by a considerable margin and can be employed in 3D reconstruction pipelines.

</p>
</details>

<details><summary><b>Explanation Strategies as an Empirical-Analytical Lens for Socio-Technical Contextualization of Machine Learning Interpretability</b>
<a href="https://arxiv.org/abs/2109.11849">arxiv:2109.11849</a>
&#x1F4C8; 7 <br>
<p>Jesse Josua Benjamin, Christoph Kinkeldey, Claudia Müller-Birn, Tim Korjakow, Eva-Maria Herbst</p></summary>
<p>

**Abstract:** During a research project in which we developed a machine learning (ML) driven visualization system for non-ML experts, we reflected on interpretability research in ML, computer-supported collaborative work and human-computer interaction. We found that while there are manifold technical approaches, these often focus on ML experts and are evaluated in decontextualized empirical studies. We hypothesized that participatory design research may support the understanding of stakeholders' situated sense-making in our project, yet, found guidance regarding ML interpretability inexhaustive. Building on philosophy of technology, we formulated explanation strategies as an empirical-analytical lens explicating how technical explanations mediate the contextual preferences concerning people's interpretations. In this paper, we contribute a report of our proof-of-concept use of explanation strategies to analyze a co-design workshop with non-ML experts, methodological implications for participatory design research, design implications for explanations for non-ML experts and suggest further investigation of technological mediation theories in the ML interpretability space.

</p>
</details>

<details><summary><b>SIM2REALVIZ: Visualizing the Sim2Real Gap in Robot Ego-Pose Estimation</b>
<a href="https://arxiv.org/abs/2109.11801">arxiv:2109.11801</a>
&#x1F4C8; 7 <br>
<p>Theo Jaunet, Guillaume Bono, Romain Vuillemot, Christian Wolf</p></summary>
<p>

**Abstract:** The Robotics community has started to heavily rely on increasingly realistic 3D simulators for large-scale training of robots on massive amounts of data. But once robots are deployed in the real world, the simulation gap, as well as changes in the real world (e.g. lights, objects displacements) lead to errors. In this paper, we introduce Sim2RealViz, a visual analytics tool to assist experts in understanding and reducing this gap for robot ego-pose estimation tasks, i.e. the estimation of a robot's position using trained models. Sim2RealViz displays details of a given model and the performance of its instances in both simulation and real-world. Experts can identify environment differences that impact model predictions at a given location and explore through direct interactions with the model hypothesis to fix it. We detail the design of the tool, and case studies related to the exploit of the regression to the mean bias and how it can be addressed, and how models are perturbed by the vanish of landmarks such as bikes.

</p>
</details>

<details><summary><b>BiTr-Unet: a CNN-Transformer Combined Network for MRI Brain Tumor Segmentation</b>
<a href="https://arxiv.org/abs/2109.12271">arxiv:2109.12271</a>
&#x1F4C8; 6 <br>
<p>Qiran Jia, Hai Shu</p></summary>
<p>

**Abstract:** Convolutional neural networks (CNNs) have recently achieved remarkable success in automatically identifying organs or lesions on 3D medical images. Meanwhile, vision transformer networks have exhibited exceptional performance in 2D image classification tasks. Compared with CNNs, transformer networks have an obvious advantage of extracting long-range features due to their self-attention algorithm. Therefore, in this paper we present a CNN-Transformer combined model called BiTr-Unet for brain tumor segmentation on multi-modal MRI scans. The proposed BiTr-Unet achieves good performance on the BraTS 2021 validation dataset with mean Dice score 0.9076, 0.8392 and 0.8231, and mean Hausdorff distance 4.5322, 13.4592 and 14.9963 for the whole tumor, tumor core, and enhancing tumor, respectively.

</p>
</details>

<details><summary><b>MLIM: Vision-and-Language Model Pre-training with Masked Language and Image Modeling</b>
<a href="https://arxiv.org/abs/2109.12178">arxiv:2109.12178</a>
&#x1F4C8; 6 <br>
<p>Tarik Arici, Mehmet Saygin Seyfioglu, Tal Neiman, Yi Xu, Son Train, Trishul Chilimbi, Belinda Zeng, Ismail Tutar</p></summary>
<p>

**Abstract:** Vision-and-Language Pre-training (VLP) improves model performance for downstream tasks that require image and text inputs. Current VLP approaches differ on (i) model architecture (especially image embedders), (ii) loss functions, and (iii) masking policies. Image embedders are either deep models like ResNet or linear projections that directly feed image-pixels into the transformer. Typically, in addition to the Masked Language Modeling (MLM) loss, alignment-based objectives are used for cross-modality interaction, and RoI feature regression and classification tasks for Masked Image-Region Modeling (MIRM). Both alignment and MIRM objectives mostly do not have ground truth. Alignment-based objectives require pairings of image and text and heuristic objective functions. MIRM relies on object detectors. Masking policies either do not take advantage of multi-modality or are strictly coupled with alignments generated by other models. In this paper, we present Masked Language and Image Modeling (MLIM) for VLP. MLIM uses two loss functions: Masked Language Modeling (MLM) loss and image reconstruction (RECON) loss. We propose Modality Aware Masking (MAM) to boost cross-modality interaction and take advantage of MLM and RECON losses that separately capture text and image reconstruction quality. Using MLM + RECON tasks coupled with MAM, we present a simplified VLP methodology and show that it has better downstream task performance on a proprietary e-commerce multi-modal dataset.

</p>
</details>

<details><summary><b>The Mirror Langevin Algorithm Converges with Vanishing Bias</b>
<a href="https://arxiv.org/abs/2109.12077">arxiv:2109.12077</a>
&#x1F4C8; 6 <br>
<p>Ruilin Li, Molei Tao, Santosh S. Vempala, Andre Wibisono</p></summary>
<p>

**Abstract:** The technique of modifying the geometry of a problem from Euclidean to Hessian metric has proved to be quite effective in optimization, and has been the subject of study for sampling. The Mirror Langevin Diffusion (MLD) is a sampling analogue of mirror flow in continuous time, and it has nice convergence properties under log-Sobolev or Poincare inequalities relative to the Hessian metric, as shown by Chewi et al. (2020). In discrete time, a simple discretization of MLD is the Mirror Langevin Algorithm (MLA) studied by Zhang et al. (2020), who showed a biased convergence bound with a non-vanishing bias term (does not go to zero as step size goes to zero). This raised the question of whether we need a better analysis or a better discretization to achieve a vanishing bias. Here we study the basic Mirror Langevin Algorithm and show it indeed has a vanishing bias. We apply mean-square analysis based on Li et al. (2019) and Li et al. (2021) to show the mixing time bound for MLA under the modified self-concordance condition introduced by Zhang et al. (2020).

</p>
</details>

<details><summary><b>Towards A Measure Of General Machine Intelligence</b>
<a href="https://arxiv.org/abs/2109.12075">arxiv:2109.12075</a>
&#x1F4C8; 6 <br>
<p>Gautham Venkatasubramanian, Sibesh Kar, Abhimanyu Singh, Shubham Mishra, Dushyant Yadav, Shreyansh Chandak</p></summary>
<p>

**Abstract:** To build general-purpose artificial intelligence systems that can deal with unknown variables across unknown domains, we need benchmarks that measure how well these systems perform on tasks they have never seen before. A prerequisite for this is a measure of a task's generalization difficulty, or how dissimilar it is from the system's prior knowledge and experience. If the skill of an intelligence system in a particular domain is defined as it's ability to consistently generate a set of instructions (or programs) to solve tasks in that domain, current benchmarks do not quantitatively measure the efficiency of acquiring new skills, making it possible to brute-force skill acquisition by training with unlimited amounts of data and compute power. With this in mind, we first propose a common language of instruction, a programming language that allows the expression of programs in the form of directed acyclic graphs across a wide variety of real-world domains and computing platforms. Using programs generated in this language, we demonstrate a match-based method to both score performance and calculate the generalization difficulty of any given set of tasks. We use these to define a numeric benchmark called the generalization index, or the g-index, to measure and compare the skill-acquisition efficiency of any intelligence system on a set of real-world tasks. Finally, we evaluate the suitability of some well-known models as general intelligence systems by calculating their g-index scores.

</p>
</details>

<details><summary><b>Integrating Deep Event-Level and Script-Level Information for Script Event Prediction</b>
<a href="https://arxiv.org/abs/2110.15706">arxiv:2110.15706</a>
&#x1F4C8; 5 <br>
<p>Long Bai, Saiping Guan, Jiafeng Guo, Zixuan Li, Xiaolong Jin, Xueqi Cheng</p></summary>
<p>

**Abstract:** Scripts are structured sequences of events together with the participants, which are extracted from the texts.Script event prediction aims to predict the subsequent event given the historical events in the script. Two kinds of information facilitate this task, namely, the event-level information and the script-level information. At the event level, existing studies view an event as a verb with its participants, while neglecting other useful properties, such as the state of the participants. At the script level, most existing studies only consider a single event sequence corresponding to one common protagonist. In this paper, we propose a Transformer-based model, called MCPredictor, which integrates deep event-level and script-level information for script event prediction. At the event level, MCPredictor utilizes the rich information in the text to obtain more comprehensive event semantic representations. At the script-level, it considers multiple event sequences corresponding to different participants of the subsequent event. The experimental results on the widely-used New York Times corpus demonstrate the effectiveness and superiority of the proposed model.

</p>
</details>

<details><summary><b>Pushing on Text Readability Assessment: A Transformer Meets Handcrafted Linguistic Features</b>
<a href="https://arxiv.org/abs/2109.12258">arxiv:2109.12258</a>
&#x1F4C8; 5 <br>
<p>Bruce W. Lee, Yoo Sung Jang, Jason Hyung-Jong Lee</p></summary>
<p>

**Abstract:** We report two essential improvements in readability assessment: 1. three novel features in advanced semantics and 2. the timely evidence that traditional ML models (e.g. Random Forest, using handcrafted features) can combine with transformers (e.g. RoBERTa) to augment model performance. First, we explore suitable transformers and traditional ML models. Then, we extract 255 handcrafted linguistic features using self-developed extraction software. Finally, we assemble those to create several hybrid models, achieving state-of-the-art (SOTA) accuracy on popular datasets in readability assessment. The use of handcrafted features help model performance on smaller datasets. Notably, our RoBERTA-RF-T1 hybrid achieves the near-perfect classification accuracy of 99%, a 20.3% increase from the previous SOTA.

</p>
</details>

<details><summary><b>Long-Range Transformers for Dynamic Spatiotemporal Forecasting</b>
<a href="https://arxiv.org/abs/2109.12218">arxiv:2109.12218</a>
&#x1F4C8; 5 <br>
<p>Jake Grigsby, Zhe Wang, Yanjun Qi</p></summary>
<p>

**Abstract:** Multivariate Time Series Forecasting (TSF) focuses on the prediction of future values based on historical context. In these problems, dependent variables provide additional information or early warning signs of changes in future behavior. State-of-the-art forecasting models rely on neural attention between timesteps. This allows for temporal learning but fails to consider distinct spatial relationships between variables. This paper addresses the problem by translating multivariate TSF into a novel spatiotemporal sequence formulation where each input token represents the value of a single variable at a given timestep. Long-Range Transformers can then learn interactions between space, time, and value information jointly along this extended sequence. Our method, which we call Spacetimeformer, scales to high dimensional forecasting problems dominated by Graph Neural Networks that rely on predefined variable graphs. We achieve competitive results on benchmarks from traffic forecasting to electricity demand and weather prediction while learning spatial and temporal relationships purely from data.

</p>
</details>

<details><summary><b>Use of the Deep Learning Approach to Measure Alveolar Bone Level</b>
<a href="https://arxiv.org/abs/2109.12115">arxiv:2109.12115</a>
&#x1F4C8; 5 <br>
<p>Chun-Teh Lee, Tanjida Kabir, Jiman Nelson, Sally Sheng, Hsiu-Wan Meng, Thomas E. Van Dyke, Muhammad F. Walji, Xiaoqian Jiang, Shayan Shams</p></summary>
<p>

**Abstract:** Abstract:
  Aim: The goal was to use a Deep Convolutional Neural Network to measure the radiographic alveolar bone level to aid periodontal diagnosis.
  Material and methods: A Deep Learning (DL) model was developed by integrating three segmentation networks (bone area, tooth, cementoenamel junction) and image analysis to measure the radiographic bone level and assign radiographic bone loss (RBL) stages. The percentage of RBL was calculated to determine the stage of RBL for each tooth. A provisional periodontal diagnosis was assigned using the 2018 periodontitis classification. RBL percentage, staging, and presumptive diagnosis were compared to the measurements and diagnoses made by the independent examiners.
  Results: The average Dice Similarity Coefficient (DSC) for segmentation was over 0.91. There was no significant difference in RBL percentage measurements determined by DL and examiners (p=0.65). The Area Under the Receiver Operating Characteristics Curve of RBL stage assignment for stage I, II and III was 0.89, 0.90 and 0.90, respectively. The accuracy of the case diagnosis was 0.85.
  Conclusion: The proposed DL model provides reliable RBL measurements and image-based periodontal diagnosis using periapical radiographic images. However, this model has to be further optimized and validated by a larger number of images to facilitate its application.

</p>
</details>

<details><summary><b>Identifying Women with Mammographically-Occult Breast Cancer Leveraging GAN-Simulated Mammograms</b>
<a href="https://arxiv.org/abs/2109.12113">arxiv:2109.12113</a>
&#x1F4C8; 5 <br>
<p>Juhun Lee, Robert M. Nishikawa</p></summary>
<p>

**Abstract:** Our objective is to show the feasibility of using simulated mammograms to detect mammographically-occult (MO) cancer in women with dense breasts and a normal screening mammogram who could be triaged for additional screening with magnetic resonance imaging (MRI) or ultrasound. We developed a Conditional Generative Adversarial Network (CGAN) to simulate a mammogram with normal appearance using the opposite mammogram as the condition. We used a Convolutional Neural Network (CNN) trained on Radon Cumulative Distribution Transform (RCDT) processed mammograms to detect MO cancer. For training CGAN, we used screening mammograms of 1366 women. For MO cancer detection, we used screening mammograms of 333 women (97 MO cancer) with dense breasts. We simulated the right mammogram for normal controls and the cancer side for MO cancer cases. We created two RCDT images, one from a real mammogram pair and another from a real-simulated mammogram pair. We finetuned a VGG16 on resulting RCDT images to classify the women with MO cancer. We compared the classification performance of the CNN trained on fused RCDT images, CNN_{Fused} to that of trained only on real RCDT images, CNN_{Real}, and to that of trained only on simulated RCDT images, CNN_{Simulated}. The test AUC for CNN_{Fused} was 0.77 with a 95% confidence interval (95CI) of [0.71, 0.83], which was statistically better (p-value < 0.02) than the CNN_{Real} AUC of 0.70 with a 95CI of [0.64, 0.77] and CNN_{Simulated} AUC of 0.68 with a 95CI of [0.62, 0.75]. It showed that CGAN simulated mammograms can help MO cancer detection.

</p>
</details>

<details><summary><b>ImplicitVol: Sensorless 3D Ultrasound Reconstruction with Deep Implicit Representation</b>
<a href="https://arxiv.org/abs/2109.12108">arxiv:2109.12108</a>
&#x1F4C8; 5 <br>
<p>Pak-Hei Yeung, Linde Hesse, Moska Aliasi, Monique Haak, the INTERGROWTH-21st Consortium, Weidi Xie, Ana I. L. Namburete</p></summary>
<p>

**Abstract:** The objective of this work is to achieve sensorless reconstruction of a 3D volume from a set of 2D freehand ultrasound images with deep implicit representation. In contrast to the conventional way that represents a 3D volume as a discrete voxel grid, we do so by parameterizing it as the zero level-set of a continuous function, i.e. implicitly representing the 3D volume as a mapping from the spatial coordinates to the corresponding intensity values. Our proposed model, termed as ImplicitVol, takes a set of 2D scans and their estimated locations in 3D as input, jointly re?fing the estimated 3D locations and learning a full reconstruction of the 3D volume. When testing on real 2D ultrasound images, novel cross-sectional views that are sampled from ImplicitVol show significantly better visual quality than those sampled from existing reconstruction approaches, outperforming them by over 30% (NCC and SSIM), between the output and ground-truth on the 3D volume testing data. The code will be made publicly available.

</p>
</details>

<details><summary><b>Learning Relative Interactions through Imitation</b>
<a href="https://arxiv.org/abs/2109.12013">arxiv:2109.12013</a>
&#x1F4C8; 5 <br>
<p>Giorgia Adorni, Elia Cereda</p></summary>
<p>

**Abstract:** In this project we trained a neural network to perform specific interactions between a robot and objects in the environment, through imitation learning. In particular, we tackle the task of moving the robot to a fixed pose with respect to a certain object and later extend our method to handle any arbitrary pose around this object. We show that a simple network, with relatively little training data, is able to reach very good performance on the fixed-pose task, while more work is needed to perform the arbitrary-pose task satisfactorily. We also explore the effect of ambiguities in the sensor readings, in particular caused by symmetries in the target object, on the behaviour of the learned controller.

</p>
</details>

<details><summary><b>NanoBatch DPSGD: Exploring Differentially Private learning on ImageNet with low batch sizes on the IPU</b>
<a href="https://arxiv.org/abs/2109.12191">arxiv:2109.12191</a>
&#x1F4C8; 4 <br>
<p>Edward H. Lee, Mario Michael Krell, Alexander Tsyplikhin, Victoria Rege, Errol Colak, Kristen W. Yeom</p></summary>
<p>

**Abstract:** Differentially private SGD (DPSGD) has recently shown promise in deep learning. However, compared to non-private SGD, the DPSGD algorithm places computational overheads that can undo the benefit of batching in GPUs. Microbatching is a standard method to alleviate this and is fully supported in the TensorFlow Privacy library (TFDP). However, this technique, while improving training times also reduces the quality of the gradients and degrades the classification accuracy. Recent works that for example use the JAX framework show promise in also alleviating this but still show degradation in throughput from non-private to private SGD on CNNs, and have not yet shown ImageNet implementations. In our work, we argue that low batch sizes using group normalization on ResNet-50 can yield high accuracy and privacy on Graphcore IPUs. This enables DPSGD training of ResNet-50 on ImageNet in just 6 hours (100 epochs) on an IPU-POD16 system.

</p>
</details>

<details><summary><b>Leveraging Pretrained Models for Automatic Summarization of Doctor-Patient Conversations</b>
<a href="https://arxiv.org/abs/2109.12174">arxiv:2109.12174</a>
&#x1F4C8; 4 <br>
<p>Longxiang Zhang, Renato Negrinho, Arindam Ghosh, Vasudevan Jagannathan, Hamid Reza Hassanzadeh, Thomas Schaaf, Matthew R. Gormley</p></summary>
<p>

**Abstract:** Fine-tuning pretrained models for automatically summarizing doctor-patient conversation transcripts presents many challenges: limited training data, significant domain shift, long and noisy transcripts, and high target summary variability. In this paper, we explore the feasibility of using pretrained transformer models for automatically summarizing doctor-patient conversations directly from transcripts. We show that fluent and adequate summaries can be generated with limited training data by fine-tuning BART on a specially constructed dataset. The resulting models greatly surpass the performance of an average human annotator and the quality of previous published work for the task. We evaluate multiple methods for handling long conversations, comparing them to the obvious baseline of truncating the conversation to fit the pretrained model length limit. We introduce a multistage approach that tackles the task by learning two fine-tuned models: one for summarizing conversation chunks into partial summaries, followed by one for rewriting the collection of partial summaries into a complete summary. Using a carefully chosen fine-tuning dataset, this method is shown to be effective at handling longer conversations, improving the quality of generated summaries. We conduct both an automatic evaluation (through ROUGE and two concept-based metrics focusing on medical findings) and a human evaluation (through qualitative examples from literature, assessing hallucination, generalization, fluency, and general quality of the generated summaries).

</p>
</details>

<details><summary><b>NICE: Robust Scheduling through Reinforcement Learning-Guided Integer Programming</b>
<a href="https://arxiv.org/abs/2109.12171">arxiv:2109.12171</a>
&#x1F4C8; 4 <br>
<p>Luke Kenworthy, Siddharth Nayak, Christopher Chin, Hamsa Balakrishnan</p></summary>
<p>

**Abstract:** Integer programs provide a powerful abstraction for representing a wide range of real-world scheduling problems. Despite their ability to model general scheduling problems, solving large-scale integer programs (IP) remains a computational challenge in practice. The incorporation of more complex objectives such as robustness to disruptions further exacerbates the computational challenge. We present NICE (Neural network IP Coefficient Extraction), a novel technique that combines reinforcement learning and integer programming to tackle the problem of robust scheduling. More specifically, NICE uses reinforcement learning to approximately represent complex objectives in an integer programming formulation. We use NICE to determine assignments of pilots to a flight crew schedule so as to reduce the impact of disruptions. We compare NICE with (1) a baseline integer programming formulation that produces a feasible crew schedule, and (2) a robust integer programming formulation that explicitly tries to minimize the impact of disruptions. Our experiments show that, across a variety of scenarios, NICE produces schedules resulting in 33\% to 48\% fewer disruptions than the baseline formulation. Moreover, in more severely constrained scheduling scenarios in which the robust integer program fails to produce a schedule within 90 minutes, NICE is able to build robust schedules in less than 2 seconds on average.

</p>
</details>

<details><summary><b>Unsupervised Cross-Modality Domain Adaptation for Segmenting Vestibular Schwannoma and Cochlea with Data Augmentation and Model Ensemble</b>
<a href="https://arxiv.org/abs/2109.12169">arxiv:2109.12169</a>
&#x1F4C8; 4 <br>
<p>Hao Li, Dewei Hu, Qibang Zhu, Kathleen E. Larson, Huahong Zhang, Ipek Oguz</p></summary>
<p>

**Abstract:** Magnetic resonance images (MRIs) are widely used to quantify vestibular schwannoma and the cochlea. Recently, deep learning methods have shown state-of-the-art performance for segmenting these structures. However, training segmentation models may require manual labels in target domain, which is expensive and time-consuming. To overcome this problem, domain adaptation is an effective way to leverage information from source domain to obtain accurate segmentations without requiring manual labels in target domain. In this paper, we propose an unsupervised learning framework to segment the VS and cochlea. Our framework leverages information from contrast-enhanced T1-weighted (ceT1-w) MRIs and its labels, and produces segmentations for T2-weighted MRIs without any labels in the target domain. We first applied a generator to achieve image-to-image translation. Next, we ensemble outputs from an ensemble of different models to obtain final segmentations. To cope with MRIs from different sites/scanners, we applied various 'online' augmentations during training to better capture the geometric variability and the variability in image appearance and quality. Our method is easy to build and produces promising segmentations, with a mean Dice score of 0.7930 and 0.7432 for VS and cochlea respectively in the validation set.

</p>
</details>

<details><summary><b>Airfoil's Aerodynamic Coefficients Prediction using Artificial Neural Network</b>
<a href="https://arxiv.org/abs/2109.12149">arxiv:2109.12149</a>
&#x1F4C8; 4 <br>
<p>Hassan Moin, Hafiz Zeeshan Iqbal Khan, Surrayya Mobeen, Jamshed Riaz</p></summary>
<p>

**Abstract:** Figuring out the right airfoil is a crucial step in the preliminary stage of any aerial vehicle design, as its shape directly affects the overall aerodynamic characteristics of the aircraft or rotorcraft. Besides being a measure of performance, the aerodynamic coefficients are used to design additional subsystems such as a flight control system, or predict complex dynamic phenomena such as aeroelastic instability. The coefficients in question can either be obtained experimentally through wind tunnel testing or, depending upon the accuracy requirements, by numerically simulating the underlying fundamental equations of fluid dynamics. In this paper, the feasibility of applying Artificial Neural Networks (ANNs) to estimate the aerodynamic coefficients of differing airfoil geometries at varying Angle of Attack, Mach and Reynolds number is investigated. The ANNs are computational entities that have the ability to learn highly nonlinear spatial and temporal patterns. Therefore, they are increasingly being used to approximate complex real-world phenomenon. However, despite their significant breakthrough in the past few years, ANNs' spreading in the field of Computational Fluid Dynamics (CFD) is fairly recent, and many applications within this field remain unexplored. This study thus compares different network architectures and training datasets in an attempt to gain insight as to how the network perceives the given airfoil geometries, while producing an acceptable neuronal model for faster and easier prediction of lift, drag and moment coefficients in steady state, incompressible flow regimes. This data-driven method produces sufficiently accurate results, with the added benefit of saving high computational and experimental costs.

</p>
</details>

<details><summary><b>A spatiotemporal machine learning approach to forecasting COVID-19 incidence at the county level in the United States</b>
<a href="https://arxiv.org/abs/2109.12094">arxiv:2109.12094</a>
&#x1F4C8; 4 <br>
<p>Benjamin Lucas, Behzad Vahedi, Morteza Karimzadeh</p></summary>
<p>

**Abstract:** With COVID-19 affecting every country globally and changing everyday life, the ability to forecast the spread of the disease is more important than any previous epidemic. The conventional methods of disease-spread modeling, compartmental models, are based on the assumption of spatiotemporal homogeneity of the spread of the virus, which may cause forecasting to underperform, especially at high spatial resolutions. In this paper we approach the forecasting task with an alternative technique - spatiotemporal machine learning. We present COVID-LSTM, a data-driven model based on a Long Short-term Memory deep learning architecture for forecasting COVID-19 incidence at the county-level in the US. We use the weekly number of new positive cases as temporal input, and hand-engineered spatial features from Facebook movement and connectedness datasets to capture the spread of the disease in time and space. COVID-LSTM outperforms the COVID-19 Forecast Hub's Ensemble model (COVIDhub-ensemble) on our 17-week evaluation period, making it the first model to be more accurate than the COVIDhub-ensemble over one or more forecast periods. Over the 4-week forecast horizon, our model is on average 50 cases per county more accurate than the COVIDhub-ensemble. We highlight that the underutilization of data-driven forecasting of disease spread prior to COVID-19 is likely due to the lack of sufficient data available for previous diseases, in addition to the recent advances in machine learning methods for spatiotemporal forecasting. We discuss the impediments to the wider uptake of data-driven forecasting, and whether it is likely that more deep learning-based models will be used in the future.

</p>
</details>

<details><summary><b>Quantitative Matching of Forensic Evidence Fragments Utilizing 3D Microscopy Analysis of Fracture Surface Replicas</b>
<a href="https://arxiv.org/abs/2109.11972">arxiv:2109.11972</a>
&#x1F4C8; 4 <br>
<p>Bishoy Dawood, Carlos Llosa-Vite, Geoffrey Z. Thompson, Barbara K. Lograsso, Lauren K. Claytor, John Vanderkolk, William Meeker, Ranjan Maitra, Ashraf Bastawros</p></summary>
<p>

**Abstract:** Fractured surfaces carry unique details that can provide an accurate quantitative comparison to support comparative forensic analysis of those fractured surfaces. In this study, a statistical analysis comparison protocol was applied to a set of 3D topological images of fractured surface pairs and their replicas to provide confidence in the quantitative statistical comparison between fractured items and their replicas. A set of 10 fractured stainless steel samples was fractured from the same metal rod under controlled conditions and were cast using a standard forensic casting technique. Six 3D topological maps with 50% overlap were acquired for each fractured pair. Spectral analysis was utilized to identify the correlation between topological surface features at different length scales of the surface topology. We selected two frequency bands over the critical wavelength (which is greater than two-grain diameters) for statistical comparison. Our statistical model utilized a matrix-variate-$t$ distribution that accounts for the image-overlap to model the match and non-match population densities. A decision rule was developed to identify the probability of matched and unmatched pairs of surfaces. The proposed methodology correctly classified the fractured steel surfaces and their replicas with a posterior probability of match exceeding 99.96%. Moreover, the replication technique shows the potential to accurately replicate fracture surface topological details with a wavelength greater than 20$μ$m, which far exceeds the range for comparison of most metallic alloys of 50-200$μ$m. The developed framework establishes the basis of forensic comparison of fractured articles and their replicas while providing a reliable quantitative statistical forensic comparison, utilizing fracture mechanics-based analysis of the fracture surface topology.

</p>
</details>

<details><summary><b>Rethinking Crowd Sourcing for Semantic Similarity</b>
<a href="https://arxiv.org/abs/2109.11969">arxiv:2109.11969</a>
&#x1F4C8; 4 <br>
<p>Shaul Solomon, Adam Cohn, Hernan Rosenblum, Chezi Hershkovitz, Ivan P. Yamshchikov</p></summary>
<p>

**Abstract:** Estimation of semantic similarity is crucial for a variety of natural language processing (NLP) tasks. In the absence of a general theory of semantic information, many papers rely on human annotators as the source of ground truth for semantic similarity estimation. This paper investigates the ambiguities inherent in crowd-sourced semantic labeling. It shows that annotators that treat semantic similarity as a binary category (two sentences are either similar or not similar and there is no middle ground) play the most important role in the labeling. The paper offers heuristics to filter out unreliable annotators and stimulates further discussions on human perception of semantic similarity.

</p>
</details>

<details><summary><b>Sinkhorn Distributionally Robust Optimization</b>
<a href="https://arxiv.org/abs/2109.11926">arxiv:2109.11926</a>
&#x1F4C8; 4 <br>
<p>Jie Wang, Rui Gao, Yao Xie</p></summary>
<p>

**Abstract:** We study distributionally robust optimization with Sinkorn distance -- a variant of Wasserstein distance based on entropic regularization. We derive convex programming dual reformulations when the nominal distribution is an empirical distribution and a general distribution, respectively. Compared with Wasserstein DRO, it is computationally tractable for a larger class of loss functions, and its worst-case distribution is more reasonable. To solve the dual reformulation, we propose an efficient batch gradient descent with a bisection search algorithm. Finally, we provide various numerical examples using both synthetic and real data to demonstrate its competitive performance.

</p>
</details>

<details><summary><b>Graph-based Approximate Message Passing Iterations</b>
<a href="https://arxiv.org/abs/2109.11905">arxiv:2109.11905</a>
&#x1F4C8; 4 <br>
<p>Cédric Gerbelot, Raphaël Berthier</p></summary>
<p>

**Abstract:** Approximate-message passing (AMP) algorithms have become an important element of high-dimensional statistical inference, mostly due to their adaptability and concentration properties, the state evolution (SE) equations. This is demonstrated by the growing number of new iterations proposed for increasingly complex problems, ranging from multi-layer inference to low-rank matrix estimation with elaborate priors. In this paper, we address the following questions: is there a structure underlying all AMP iterations that unifies them in a common framework? Can we use such a structure to give a modular proof of state evolution equations, adaptable to new AMP iterations without reproducing each time the full argument ? We propose an answer to both questions, showing that AMP instances can be generically indexed by an oriented graph. This enables to give a unified interpretation of these iterations, independent from the problem they solve, and a way of composing them arbitrarily. We then show that all AMP iterations indexed by such a graph admit rigorous SE equations, extending the reach of previous proofs, and proving a number of recent heuristic derivations of those equations. Our proof naturally includes non-separable functions and we show how existing refinements, such as spatial coupling or matrix-valued variables, can be combined with our framework.

</p>
</details>

<details><summary><b>How Does Knowledge Graph Embedding Extrapolate to Unseen Data: a Semantic Evidence View</b>
<a href="https://arxiv.org/abs/2109.11800">arxiv:2109.11800</a>
&#x1F4C8; 4 <br>
<p>Ren Li, Yanan Cao, Qiannan Zhu, Guanqun Bi, Fang Fang, Yi Liu, Qian Li</p></summary>
<p>

**Abstract:** Knowledge Graph Embedding (KGE) aims to learn representations for entities and relations. Most KGE models have gained great success, especially on extrapolation scenarios. Specifically, given an unseen triple (h, r, t), a trained model can still correctly predict t from (h, r, ?), or h from (?, r, t), such extrapolation ability is impressive. However, most existing KGE works focus on the design of delicate triple modeling function, which mainly tell us how to measure the plausibility of observed triples, but we have limited understanding of why the methods can extrapolate to unseen data, and what are the important factors to help KGE extrapolate. Therefore in this work, we attempt to, from a data relevant view, study KGE extrapolation of two problems: 1. How does KGE extrapolate to unseen data? 2. How to design the KGE model with better extrapolation ability? For the problem 1, we first discuss the impact factors for extrapolation and from relation, entity and triple level respectively, propose three Semantic Evidences (SEs), which can be observed from training set and provide important semantic information for extrapolation to unseen data. Then we verify the effectiveness of SEs through extensive experiments on several typical KGE methods, and demonstrate that SEs serve as an important role for understanding the extrapolation ability of KGE. For the problem 2, to make better use of the SE information for more extrapolative knowledge representation, we propose a novel GNN-based KGE model, called Semantic Evidence aware Graph Neural Network (SE-GNN). Finally, through extensive experiments on FB15k-237 and WN18RR datasets, we show that SE-GNN achieves state-of-the-art performance on Knowledge Graph Completion task and perform a better extrapolation ability.

</p>
</details>

<details><summary><b>Learning Dual Dynamic Representations on Time-Sliced User-Item Interaction Graphs for Sequential Recommendation</b>
<a href="https://arxiv.org/abs/2109.11790">arxiv:2109.11790</a>
&#x1F4C8; 4 <br>
<p>Zeyuan Chen, Wei Zhang, Junchi Yan, Gang Wang, Jianyong Wang</p></summary>
<p>

**Abstract:** Sequential Recommendation aims to recommend items that a target user will interact with in the near future based on the historically interacted items. While modeling temporal dynamics is crucial for sequential recommendation, most of the existing studies concentrate solely on the user side while overlooking the sequential patterns existing in the counterpart, i.e., the item side. Although a few studies investigate the dynamics involved in the dual sides, the complex user-item interactions are not fully exploited from a global perspective to derive dynamic user and item representations. In this paper, we devise a novel Dynamic Representation Learning model for Sequential Recommendation (DRL-SRe). To better model the user-item interactions for characterizing the dynamics from both sides, the proposed model builds a global user-item interaction graph for each time slice and exploits time-sliced graph neural networks to learn user and item representations. Moreover, to enable the model to capture fine-grained temporal information, we propose an auxiliary temporal prediction task over consecutive time slices based on temporal point process. Comprehensive experiments on three public real-world datasets demonstrate DRL-SRe outperforms the state-of-the-art sequential recommendation models with a large margin.

</p>
</details>

<details><summary><b>A Proposal of Automatic Error Correction in Text</b>
<a href="https://arxiv.org/abs/2112.01846">arxiv:2112.01846</a>
&#x1F4C8; 3 <br>
<p>Wulfrano A. Luna-Ramírez, Carlos R. Jaimez-González</p></summary>
<p>

**Abstract:** The great amount of information that can be stored in electronic media is growing up daily. Many of them is got mainly by typing, such as the huge of information obtained from web 2.0 sites; or scaned and processing by an Optical Character Recognition software, like the texts of libraries and goverment offices. Both processes introduce error in texts, so it is difficult to use the data for other purposes than just to read it, i.e. the processing of those texts by other applications like e-learning, learning of languages, electronic tutorials, data minning, information retrieval and even more specialized systems such as tiflologic software, specifically blinded people-oriented applications like automatic reading, where the text would be error free as possible in order to make easier the text to speech task, and so on. In this paper it is showed an application of automatic recognition and correction of ortographic errors in electronic texts. This task is composed of three stages: a) error detection; b) candidate corrections generation; and c) correction -selection of the best candidate. The proposal is based in part of speech text categorization, word similarity, word diccionaries, statistical measures, morphologic analisys and n-grams based language model of Spanish.

</p>
</details>

<details><summary><b>Go-Blend behavior and affect</b>
<a href="https://arxiv.org/abs/2109.13388">arxiv:2109.13388</a>
&#x1F4C8; 3 <br>
<p>Matthew Barthet, Antonios Liapis, Georgios N. Yannakakis</p></summary>
<p>

**Abstract:** This paper proposes a paradigm shift for affective computing by viewing the affect modeling task as a reinforcement learning process. According to our proposed framework the context (environment) and the actions of an agent define the common representation that interweaves behavior and affect. To realise this framework we build on recent advances in reinforcement learning and use a modified version of the Go-Explore algorithm which has showcased supreme performance in hard exploration tasks. In this initial study, we test our framework in an arcade game by training Go-Explore agents to both play optimally and attempt to mimic human demonstrations of arousal. We vary the degree of importance between optimal play and arousal imitation and create agents that can effectively display a palette of affect and behavioral patterns. Our Go-Explore implementation not only introduces a new paradigm for affect modeling; it empowers believable AI-based game testing by providing agents that can blend and express a multitude of behavioral and affective patterns.

</p>
</details>

<details><summary><b>Learning Stereopsis from Geometric Synthesis for 6D Object Pose Estimation</b>
<a href="https://arxiv.org/abs/2109.12266">arxiv:2109.12266</a>
&#x1F4C8; 3 <br>
<p>Jun Wu, Lilu Liu, Yue Wang, Rong Xiong</p></summary>
<p>

**Abstract:** Current monocular-based 6D object pose estimation methods generally achieve less competitive results than RGBD-based methods, mostly due to the lack of 3D information. To make up this gap, this paper proposes a 3D geometric volume based pose estimation method with a short baseline two-view setting. By constructing a geometric volume in the 3D space, we combine the features from two adjacent images to the same 3D space. Then a network is trained to learn the distribution of the position of object keypoints in the volume, and a robust soft RANSAC solver is deployed to solve the pose in closed form. To balance accuracy and cost, we propose a coarse-to-fine framework to improve the performance in an iterative way. The experiments show that our method outperforms state-of-the-art monocular-based methods, and is robust in different objects and scenes, especially in serious occlusion situations.

</p>
</details>

<details><summary><b>An embarrassingly simple comparison of machine learning algorithms for indoor scene classification</b>
<a href="https://arxiv.org/abs/2109.12261">arxiv:2109.12261</a>
&#x1F4C8; 3 <br>
<p>Bhanuka Manesha Samarasekara Vitharana Gamage</p></summary>
<p>

**Abstract:** With the emergence of autonomous indoor robots, the computer vision task of indoor scene recognition has gained the spotlight. Indoor scene recognition is a challenging problem in computer vision that relies on local and global features in a scene. This study aims to compare the performance of five machine learning algorithms on the task of indoor scene classification to identify the pros and cons of each classifier. It also provides a comparison of low latency feature extractors versus enormous feature extractors to understand the performance effects. Finally, a simple MnasNet based indoor classification system is proposed, which can achieve 72% accuracy at 23 ms latency.

</p>
</details>

<details><summary><b>Tensor Full Feature Measure and Its Nonconvex Relaxation Applications to Tensor Recovery</b>
<a href="https://arxiv.org/abs/2109.12257">arxiv:2109.12257</a>
&#x1F4C8; 3 <br>
<p>Hongbing Zhang, Xinyi Liu, Hongtao Fan, Yajing Li, Yinlin Ye</p></summary>
<p>

**Abstract:** Tensor sparse modeling as a promising approach, in the whole of science and engineering has been a huge success. As is known to all, various data in practical application are often generated by multiple factors, so the use of tensors to represent the data containing the internal structure of multiple factors came into being. However, different from the matrix case, constructing reasonable sparse measure of tensor is a relatively difficult and very important task. Therefore, in this paper, we propose a new tensor sparsity measure called Tensor Full Feature Measure (FFM). It can simultaneously describe the feature information of each dimension of the tensor and the related features between two dimensions, and connect the Tucker rank with the tensor tube rank. This measurement method can describe the sparse features of the tensor more comprehensively. On this basis, we establish its non-convex relaxation, and apply FFM to low rank tensor completion (LRTC) and tensor robust principal component analysis (TRPCA). LRTC and TRPCA models based on FFM are proposed, and two efficient Alternating Direction Multiplier Method (ADMM) algorithms are developed to solve the proposed model. A variety of real numerical experiments substantiate the superiority of the proposed methods beyond state-of-the-arts.

</p>
</details>

<details><summary><b>Long-Range Feature Propagating for Natural Image Matting</b>
<a href="https://arxiv.org/abs/2109.12252">arxiv:2109.12252</a>
&#x1F4C8; 3 <br>
<p>Qinglin Liu, Haozhe Xie, Shengping Zhang, Bineng Zhong, Rongrong Ji</p></summary>
<p>

**Abstract:** Natural image matting estimates the alpha values of unknown regions in the trimap. Recently, deep learning based methods propagate the alpha values from the known regions to unknown regions according to the similarity between them. However, we find that more than 50\% pixels in the unknown regions cannot be correlated to pixels in known regions due to the limitation of small effective reception fields of common convolutional neural networks, which leads to inaccurate estimation when the pixels in the unknown regions cannot be inferred only with pixels in the reception fields. To solve this problem, we propose Long-Range Feature Propagating Network (LFPNet), which learns the long-range context features outside the reception fields for alpha matte estimation. Specifically, we first design the propagating module which extracts the context features from the downsampled image. Then, we present Center-Surround Pyramid Pooling (CSPP) that explicitly propagates the context features from the surrounding context image patch to the inner center image patch. Finally, we use the matting module which takes the image, trimap and context features to estimate the alpha matte. Experimental results demonstrate that the proposed method performs favorably against the state-of-the-art methods on the AlphaMatting and Adobe Image Matting datasets.

</p>
</details>

<details><summary><b>Accelerated nonlinear primal-dual hybrid gradient algorithms with applications to machine learning</b>
<a href="https://arxiv.org/abs/2109.12222">arxiv:2109.12222</a>
&#x1F4C8; 3 <br>
<p>Jérôme Darbon, Gabriel Provencher Langlois</p></summary>
<p>

**Abstract:** The primal-dual hybrid gradient (PDHG) algorithm is a first-order method that splits convex optimization problems with saddle-point structure into smaller subproblems. Those subproblems, unlike those obtained from most other splitting methods, can generally be solved efficiently because they involve simple operations such as matrix-vector multiplications or proximal mappings that are easy to evaluate. In order to work fast, however, the PDHG algorithm requires stepsize parameters fine-tuned for the problem at hand. Unfortunately, the stepsize parameters must often be estimated from quantities that are prohibitively expensive to compute for large-scale optimization problems, such as those in machine learning. In this paper, we introduce accelerated nonlinear variants of the PDHG algorithm that can achieve, for a broad class of optimization problems relevant to machine learning, an optimal rate of convergence with stepsize parameters that are simple to compute. We prove rigorous convergence results, including for problems posed on infinite-dimensional reflexive Banach spaces. We also provide practical implementations of accelerated nonlinear PDHG algorithms for solving several regression tasks in machine learning, including support vector machines without offset, kernel ridge regression, elastic net regularized linear regression, and the least absolute shrinkage selection operator.

</p>
</details>

<details><summary><b>Deep Neural Networks for Blind Image Quality Assessment: Addressing the Data Challenge</b>
<a href="https://arxiv.org/abs/2109.12161">arxiv:2109.12161</a>
&#x1F4C8; 3 <br>
<p>Shahrukh Athar, Zhongling Wang, Zhou Wang</p></summary>
<p>

**Abstract:** The enormous space and diversity of natural images is usually represented by a few small-scale human-rated image quality assessment (IQA) datasets. This casts great challenges to deep neural network (DNN) based blind IQA (BIQA), which requires large-scale training data that is representative of the natural image distribution. It is extremely difficult to create human-rated IQA datasets composed of millions of images due to constraints of subjective testing. While a number of efforts have focused on design innovations to enhance the performance of DNN based BIQA, attempts to address the scarcity of labeled IQA data remain surprisingly missing. To address this data challenge, we construct so far the largest IQA database, namely Waterloo Exploration-II, which contains 3,570 pristine reference and around 3.45 million singly and multiply distorted images. Since subjective testing for such a large dataset is nearly impossible, we develop a novel mechanism that synthetically assigns perceptual quality labels to the distorted images. We construct a DNN-based BIQA model called EONSS, train it on Waterloo Exploration-II, and test it on nine subject-rated IQA datasets, without any retraining or fine-tuning. The results show that with a straightforward DNN architecture, EONSS is able to outperform the very state-of-the-art in BIQA, both in terms of quality prediction performance and execution speed. This study strongly supports the view that the quantity and quality of meaningfully annotated training data, rather than a sophisticated network architecture or training strategy, is the dominating factor that determines the performance of DNN-based BIQA models. (Note: Since this is an ongoing project, the final versions of Waterloo Exploration-II database, quality annotations, and EONSS, will be made publicly available in the future when it culminates.)

</p>
</details>

<details><summary><b>Automatic Map Update Using Dashcam Videos</b>
<a href="https://arxiv.org/abs/2109.12131">arxiv:2109.12131</a>
&#x1F4C8; 3 <br>
<p>Aziza Zhanabatyrova, Clayton Souza Leite, Yu Xiao</p></summary>
<p>

**Abstract:** Autonomous driving requires 3D maps that provide accurate and up-to-date information about semantic landmarks. Due to the wider availability and lower cost of cameras compared with laser scanners, vision-based mapping has attracted much attention from academia and industry. Among the existing solutions, Structure-from-Motion (SfM) technology has proved to be feasible for building 3D maps from crowdsourced data, since it allows unordered images as input. Previous works on SfM have mainly focused on issues related to building 3D point clouds and calculating camera poses, leaving the issues of automatic change detection and localization open.
  We propose in this paper an SfM-based solution for automatic map update, with a focus on real-time change detection and localization. Our solution builds on comparison of semantic map data (e.g. types and locations of traffic signs). Through a novel design of the pixel-wise 3D localization algorithm, our system can locate the objects detected from 2D images in a 3D space, utilizing sparse SfM point clouds. Experiments with dashcam videos collected from two urban areas prove that the system is able to locate visible traffic signs in front along the driving direction with a median distance error of 1.52 meters. Moreover, it can detect up to 80\% of the changes with a median distance error of 2.21 meters. The result analysis also shows the potential of significantly improving the system performance in the future by increasing the accuracy of the background technology in use, including in particularly the object detection and point cloud geo-registration algorithms.

</p>
</details>

<details><summary><b>MCTS Based Agents for Multistage Single-Player Card Game</b>
<a href="https://arxiv.org/abs/2109.12112">arxiv:2109.12112</a>
&#x1F4C8; 3 <br>
<p>Konrad Godlewski, Bartosz Sawicki</p></summary>
<p>

**Abstract:** The article presents the use of Monte Carlo Tree Search algorithms for the card game Lord of the Rings. The main challenge was the complexity of the game mechanics, in which each round consists of 5 decision stages and 2 random stages. To test various decision-making algorithms, a game simulator has been implemented. The research covered an agent based on expert rules, using flat Monte-Carlo search, as well as complete MCTS-UCB. Moreover different playout strategies has been compared. As a result of experiments, an optimal (assuming a limited time) combination of algorithms were formulated. The developed MCTS based method have demonstrated a advantage over agent with expert knowledge.

</p>
</details>

<details><summary><b>A Generative Federated Learning Framework for Differential Privacy</b>
<a href="https://arxiv.org/abs/2109.12062">arxiv:2109.12062</a>
&#x1F4C8; 3 <br>
<p>Eugenio Lomurno, Leonardo Di Perna, Lorenzo Cazzella, Stefano Samele, Matteo Matteucci</p></summary>
<p>

**Abstract:** In machine learning, differential privacy and federated learning concepts are gaining more and more importance in an increasingly interconnected world. While the former refers to the sharing of private data characterized by strict security rules to protect individual privacy, the latter refers to distributed learning techniques in which a central server exchanges information with different clients for machine learning purposes. In recent years, many studies have shown the possibility of bypassing the privacy shields of these systems and exploiting the vulnerabilities of machine learning models, making them leak the information with which they have been trained. In this work, we present the 3DGL framework, an alternative to the current federated learning paradigms. Its goal is to share generative models with high levels of $\varepsilon$-differential privacy. In addition, we propose DDP-$β$VAE, a deep generative model capable of generating synthetic data with high levels of utility and safety for the individual. We evaluate the 3DGL framework based on DDP-$β$VAE, showing how the overall system is resilient to the principal attacks in federated learning and improves the performance of distributed learning algorithms.

</p>
</details>

<details><summary><b>Parameterized Channel Normalization for Far-field Deep Speaker Verification</b>
<a href="https://arxiv.org/abs/2109.12056">arxiv:2109.12056</a>
&#x1F4C8; 3 <br>
<p>Xuechen Liu, Md Sahidullah, Tomi Kinnunen</p></summary>
<p>

**Abstract:** We address far-field speaker verification with deep neural network (DNN) based speaker embedding extractor, where mismatch between enrollment and test data often comes from convolutive effects (e.g. room reverberation) and noise. To mitigate these effects, we focus on two parametric normalization methods: per-channel energy normalization (PCEN) and parameterized cepstral mean normalization (PCMN). Both methods contain differentiable parameters and thus can be conveniently integrated to, and jointly optimized with the DNN using automatic differentiation methods. We consider both fixed and trainable (data-driven) variants of each method. We evaluate the performance on Hi-MIA, a recent large-scale far-field speech corpus, with varied microphone and positional settings. Our methods outperform conventional mel filterbank features, with maximum of 33.5% and 39.5% relative improvement on equal error rate under matched microphone and mismatched microphone conditions, respectively.

</p>
</details>

<details><summary><b>Optimization-based Causal Estimation from Heterogenous Environments</b>
<a href="https://arxiv.org/abs/2109.11990">arxiv:2109.11990</a>
&#x1F4C8; 3 <br>
<p>Mingzhang Yin, Yixin Wang, David M. Blei</p></summary>
<p>

**Abstract:** This paper presents a new optimization approach to causal estimation. Given data that contains covariates and an outcome, which covariates are causes of the outcome, and what is the strength of the causality? In classical machine learning (ML), the goal of optimization is to maximize predictive accuracy. However, some covariates might exhibit a non-causal association to the outcome. Such spurious associations provide predictive power for classical ML, but they prevent us from causally interpreting the result. This paper proposes CoCo, an optimization algorithm that bridges the gap between pure prediction and causal inference. CoCo leverages the recently-proposed idea of environments, datasets of covariates/response where the causal relationships remain invariant but where the distribution of the covariates changes from environment to environment. Given datasets from multiple environments -- and ones that exhibit sufficient heterogeneity -- CoCo maximizes an objective for which the only solution is the causal solution. We describe the theoretical foundations of this approach and demonstrate its effectiveness on simulated and real datasets. Compared to classical ML and existing methods, CoCo provides more accurate estimates of the causal model.

</p>
</details>

<details><summary><b>A dynamic programming algorithm for informative measurements and near-optimal path-planning</b>
<a href="https://arxiv.org/abs/2109.11808">arxiv:2109.11808</a>
&#x1F4C8; 3 <br>
<p>Peter N. Loxley, Ka Wai Cheung</p></summary>
<p>

**Abstract:** An informative measurement is the most efficient way to gain information about an unknown state. We give a first-principles derivation of a general-purpose dynamic programming algorithm that returns a sequence of informative measurements by sequentially maximizing the entropy of possible measurement outcomes. This algorithm can be used by an autonomous agent or robot to decide where best to measure next, planning a path corresponding to an optimal sequence of informative measurements. This algorithm is applicable to states and controls that are continuous or discrete, and agent dynamics that is either stochastic or deterministic; including Markov decision processes. Recent results from approximate dynamic programming and reinforcement learning, including on-line approximations such as rollout and Monte Carlo tree search, allow an agent or robot to solve the measurement task in real-time. The resulting near-optimal solutions include non-myopic paths and measurement sequences that can generally outperform, sometimes substantially, commonly-used greedy heuristics such as maximizing the entropy of each measurement outcome. This is demonstrated for a global search problem, where on-line planning with an extended local search is found to reduce the number of measurements in the search by half.

</p>
</details>

<details><summary><b>Regularization Guarantees Generalization in Bayesian Reinforcement Learning through Algorithmic Stability</b>
<a href="https://arxiv.org/abs/2109.11792">arxiv:2109.11792</a>
&#x1F4C8; 3 <br>
<p>Aviv Tamar, Daniel Soudry, Ev Zisselman</p></summary>
<p>

**Abstract:** In the Bayesian reinforcement learning (RL) setting, a prior distribution over the unknown problem parameters -- the rewards and transitions -- is assumed, and a policy that optimizes the (posterior) expected return is sought. A common approximation, which has been recently popularized as meta-RL, is to train the agent on a sample of $N$ problem instances from the prior, with the hope that for large enough $N$, good generalization behavior to an unseen test instance will be obtained. In this work, we study generalization in Bayesian RL under the probably approximately correct (PAC) framework, using the method of algorithmic stability. Our main contribution is showing that by adding regularization, the optimal policy becomes stable in an appropriate sense. Most stability results in the literature build on strong convexity of the regularized loss -- an approach that is not suitable for RL as Markov decision processes (MDPs) are not convex. Instead, building on recent results of fast convergence rates for mirror descent in regularized MDPs, we show that regularized MDPs satisfy a certain quadratic growth criterion, which is sufficient to establish stability. This result, which may be of independent interest, allows us to study the effect of regularization on generalization in the Bayesian RL setting.

</p>
</details>

<details><summary><b>Parameter-Free Deterministic Reduction of the Estimation Bias in Continuous Control</b>
<a href="https://arxiv.org/abs/2109.11788">arxiv:2109.11788</a>
&#x1F4C8; 3 <br>
<p>Baturay Saglam, Enes Duran, Dogan C. Cicek, Furkan B. Mutlu, Suleyman S. Kozat</p></summary>
<p>

**Abstract:** Approximation of the value functions in value-based deep reinforcement learning systems induces overestimation bias, resulting in suboptimal policies. We show that when the reinforcement signals received by the agents have a high variance, deep actor-critic approaches that overcome the overestimation bias lead to a substantial underestimation bias. We introduce a parameter-free, novel deep Q-learning variant to reduce this underestimation bias for continuous control. By obtaining fixed weights in computing the critic objective as a linear combination of the approximate critic functions, our Q-value update rule integrates the concepts of Clipped Double Q-learning and Maxmin Q-learning. We test the performance of our improvement on a set of MuJoCo and Box2D continuous control tasks and find that it improves the state-of-the-art and outperforms the baseline algorithms in the majority of the environments.

</p>
</details>

<details><summary><b>Integrating Recurrent Neural Networks with Data Assimilation for Scalable Data-Driven State Estimation</b>
<a href="https://arxiv.org/abs/2109.12269">arxiv:2109.12269</a>
&#x1F4C8; 2 <br>
<p>Stephen G. Penny, Timothy A. Smith, Tse-Chun Chen, Jason A. Platt, Hsin-Yi Lin, Michael Goodliff, Henry D. I. Abarbanel</p></summary>
<p>

**Abstract:** Data assimilation (DA) is integrated with machine learning in order to perform entirely data-driven online state estimation. To achieve this, recurrent neural networks (RNNs) are implemented as surrogate models to replace key components of the DA cycle in numerical weather prediction (NWP), including the conventional numerical forecast model, the forecast error covariance matrix, and the tangent linear and adjoint models. It is shown how these RNNs can be initialized using DA methods to directly update the hidden/reservoir state with observations of the target system. The results indicate that these techniques can be applied to estimate the state of a system for the repeated initialization of short-term forecasts, even in the absence of a traditional numerical forecast model. Further, it is demonstrated how these integrated RNN-DA methods can scale to higher dimensions by applying domain localization and parallelization, providing a path for practical applications in NWP.

</p>
</details>

<details><summary><b>More Than Reading Comprehension: A Survey on Datasets and Metrics of Textual Question Answering</b>
<a href="https://arxiv.org/abs/2109.12264">arxiv:2109.12264</a>
&#x1F4C8; 2 <br>
<p>Yang Bai, Daisy Zhe Wang</p></summary>
<p>

**Abstract:** Textual Question Answering (QA) aims to provide precise answers to user's questions in natural language using unstructured data. One of the most popular approaches to this goal is machine reading comprehension(MRC). In recent years, many novel datasets and evaluation metrics based on classical MRC tasks have been proposed for broader textual QA tasks. In this paper, we survey 47 recent textual QA benchmark datasets and propose a new taxonomy from an application point of view. In addition, We summarize 8 evaluation metrics of textual QA tasks. Finally, we discuss current trends in constructing textual QA benchmarks and suggest directions for future work.

</p>
</details>

<details><summary><b>On the Fairness of Swarm Learning in Skin Lesion Classification</b>
<a href="https://arxiv.org/abs/2109.12176">arxiv:2109.12176</a>
&#x1F4C8; 2 <br>
<p>Di Fan, Yifan Wu, Xiaoxiao Li</p></summary>
<p>

**Abstract:** in healthcare. However, the existing AI model may be biased in its decision marking. The bias induced by data itself, such as collecting data in subgroups only, can be mitigated by including more diversified data. Distributed and collaborative learning is an approach to involve training models in massive, heterogeneous, and distributed data sources, also known as nodes. In this work, we target on examining the fairness issue in Swarm Learning (SL), a recent edge-computing based decentralized machine learning approach, which is designed for heterogeneous illnesses detection in precision medicine. SL has achieved high performance in clinical applications, but no attempt has been made to evaluate if SL can improve fairness. To address the problem, we present an empirical study by comparing the fairness among single (node) training, SL, centralized training. Specifically, we evaluate on large public available skin lesion dataset, which contains samples from various subgroups. The experiments demonstrate that SL does not exacerbate the fairness problem compared to centralized training and improves both performance and fairness compared to single training. However, there still exists biases in SL model and the implementation of SL is more complex than the alternative two strategies.

</p>
</details>

<details><summary><b>MLIMC: Machine learning-based implicit-solvent Monte Carlo</b>
<a href="https://arxiv.org/abs/2109.12100">arxiv:2109.12100</a>
&#x1F4C8; 2 <br>
<p>Jiahui Chen, Weihua Geng, Guo-Wei Wei</p></summary>
<p>

**Abstract:** Monte Carlo (MC) methods are important computational tools for molecular structure optimizations and predictions. When solvent effects are explicitly considered, MC methods become very expensive due to the large degree of freedom associated with the water molecules and mobile ions. Alternatively implicit-solvent MC can largely reduce the computational cost by applying a mean field approximation to solvent effects and meanwhile maintains the atomic detail of the target molecule. The two most popular implicit-solvent models are the Poisson-Boltzmann (PB) model and the Generalized Born (GB) model in a way such that the GB model is an approximation to the PB model but is much faster in simulation time. In this work, we develop a machine learning-based implicit-solvent Monte Carlo (MLIMC) method by combining the advantages of both implicit solvent models in accuracy and efficiency. Specifically, the MLIMC method uses a fast and accurate PB-based machine learning (PBML) scheme to compute the electrostatic solvation free energy at each step. We validate our MLIMC method by using a benzene-water system and a protein-water system. We show that the proposed MLIMC method has great advantages in speed and accuracy for molecular structure optimization and prediction.

</p>
</details>

<details><summary><b>SAIS: Supervising and Augmenting Intermediate Steps for Document-Level Relation Extraction</b>
<a href="https://arxiv.org/abs/2109.12093">arxiv:2109.12093</a>
&#x1F4C8; 2 <br>
<p>Yuxin Xiao, Zecheng Zhang, Yuning Mao, Carl Yang, Jiawei Han</p></summary>
<p>

**Abstract:** Stepping from sentence-level to document-level relation extraction, the research community confronts increasing text length and more complicated entity interactions. Consequently, it is more challenging to encode the key sources of information--relevant contexts and entity types. However, existing methods only implicitly learn to model these critical information sources while being trained for relation extraction. As a result, they suffer the problems of ineffective supervision and uninterpretable model predictions. In contrast, we propose to explicitly teach the model to capture relevant contexts and entity types by supervising and augmenting intermediate steps (SAIS) for relation extraction. Based on a broad spectrum of carefully designed tasks, our proposed SAIS method not only extracts relations of better quality due to more effective supervision, but also retrieves the corresponding supporting evidence more accurately so as to enhance interpretability. By assessing model uncertainty, SAIS further boosts the performance via evidence-based data augmentation and ensemble inference while reducing the computational cost. Eventually, SAIS delivers state-of-the-art relation extraction results on three benchmarks (DocRED, CDR, and GDA) and achieves 5.04% relative gains in F1 score compared to the runner-up in evidence retrieval on DocRED.

</p>
</details>

<details><summary><b>A Graph Policy Network Approach for Volt-Var Control in Power Distribution Systems</b>
<a href="https://arxiv.org/abs/2109.12073">arxiv:2109.12073</a>
&#x1F4C8; 2 <br>
<p>Xian Yeow Lee, Soumik Sarkar, Yubo Wang</p></summary>
<p>

**Abstract:** Volt-var control (VVC) is the problem of operating power distribution systems within healthy regimes by controlling actuators in power systems. Existing works have mostly adopted the conventional routine of representing the power systems (a graph with tree topology) as vectors to train deep reinforcement learning (RL) policies. We propose a framework that combines RL with graph neural networks and study the benefits and limitations of graph-based policy in the VVC setting. Our results show that graph-based policies converge to the same rewards asymptotically however at a slower rate when compared to vector representation counterpart. We conduct further analysis on the impact of both observations and actions: on the observation end, we examine the robustness of graph-based policy on two typical data acquisition errors in power systems, namely sensor communication failure and measurement misalignment. On the action end, we show that actuators have various impacts on the system, thus using a graph representation induced by power systems topology may not be the optimal choice. In the end, we conduct a case study to demonstrate that the choice of readout function architecture and graph augmentation can further improve training performance and robustness.

</p>
</details>

<details><summary><b>DeepStroke: An Efficient Stroke Screening Framework for Emergency Rooms with Multimodal Adversarial Deep Learning</b>
<a href="https://arxiv.org/abs/2109.12065">arxiv:2109.12065</a>
&#x1F4C8; 2 <br>
<p>Tongan Cai, Haomiao Ni, Mingli Yu, Xiaolei Huang, Kelvin Wong, John Volpi, James Z. Wang, Stephen T. C. Wong</p></summary>
<p>

**Abstract:** In an emergency room (ER) setting, the diagnosis of stroke is a common challenge. Due to excessive execution time and cost, an MRI scan is usually not available in the ER. Clinical tests are commonly referred to in stroke screening, but neurologists may not be immediately available. We propose a novel multimodal deep learning framework, DeepStroke, to achieve computer-aided stroke presence assessment by recognizing the patterns of facial motion incoordination and speech inability for patients with suspicion of stroke in an acute setting. Our proposed DeepStroke takes video data for local facial paralysis detection and audio data for global speech disorder analysis. It further leverages a multi-modal lateral fusion to combine the low- and high-level features and provides mutual regularization for joint training. A novel adversarial training loss is also introduced to obtain identity-independent and stroke-discriminative features. Experiments on our video-audio dataset with actual ER patients show that the proposed approach outperforms state-of-the-art models and achieves better performance than ER doctors, attaining a 6.60% higher sensitivity and maintaining 4.62% higher accuracy when specificity is aligned. Meanwhile, each assessment can be completed in less than 6 minutes, demonstrating the framework's great potential for clinical implementation.

</p>
</details>

<details><summary><b>Optimized Power Normalized Cepstral Coefficients towards Robust Deep Speaker Verification</b>
<a href="https://arxiv.org/abs/2109.12058">arxiv:2109.12058</a>
&#x1F4C8; 2 <br>
<p>Xuechen Liu, Md Sahidullah, Tomi Kinnunen</p></summary>
<p>

**Abstract:** After their introduction to robust speech recognition, power normalized cepstral coefficient (PNCC) features were successfully adopted to other tasks, including speaker verification. However, as a feature extractor with long-term operations on the power spectrogram, its temporal processing and amplitude scaling steps dedicated on environmental compensation may be redundant. Further, they might suppress intrinsic speaker variations that are useful for speaker verification based on deep neural networks (DNN). Therefore, in this study, we revisit and optimize PNCCs by ablating its medium-time processor and by introducing channel energy normalization. Experimental results with a DNN-based speaker verification system indicate substantial improvement over baseline PNCCs on both in-domain and cross-domain scenarios, reflected by relatively 5.8% and 61.2% maximum lower equal error rate on VoxCeleb1 and VoxMovies, respectively.

</p>
</details>

<details><summary><b>Combining Discrete Choice Models and Neural Networks through Embeddings: Formulation, Interpretability and Performance</b>
<a href="https://arxiv.org/abs/2109.12042">arxiv:2109.12042</a>
&#x1F4C8; 2 <br>
<p>Ioanna Arkoudi, Carlos Lima Azevedo, Francisco C. Pereira</p></summary>
<p>

**Abstract:** This study proposes a novel approach that combines theory and data-driven choice models using Artificial Neural Networks (ANNs). In particular, we use continuous vector representations, called embeddings, for encoding categorical or discrete explanatory variables with a special focus on interpretability and model transparency. Although embedding representations within the logit framework have been conceptualized by Pereira (2019), their dimensions do not have an absolute definitive meaning, hence offering limited behavioral insights in this earlier work. The novelty of our work lies in enforcing interpretability to the embedding vectors by formally associating each of their dimensions to a choice alternative. Thus, our approach brings benefits much beyond a simple parsimonious representation improvement over dummy encoding, as it provides behaviorally meaningful outputs that can be used in travel demand analysis and policy decisions. Additionally, in contrast to previously suggested ANN-based Discrete Choice Models (DCMs) that either sacrifice interpretability for performance or are only partially interpretable, our models preserve interpretability of the utility coefficients for all the input variables despite being based on ANN principles. The proposed models were tested on two real world datasets and evaluated against benchmark and baseline models that use dummy-encoding. The results of the experiments indicate that our models deliver state-of-the-art predictive performance, outperforming existing ANN-based models while drastically reducing the number of required network parameters.

</p>
</details>

<details><summary><b>From images in the wild to video-informed image classification</b>
<a href="https://arxiv.org/abs/2109.12040">arxiv:2109.12040</a>
&#x1F4C8; 2 <br>
<p>Marc Böhlen, Varun Chandola, Wawan Sujarwo, Raunaq Jain</p></summary>
<p>

**Abstract:** Image classifiers work effectively when applied on structured images, yet they often fail when applied on images with very high visual complexity. This paper describes experiments applying state-of-the-art object classifiers toward a unique set of images in the wild with high visual complexity collected on the island of Bali. The text describes differences between actual images in the wild and images from Imagenet, and then discusses a novel approach combining informational cues particular to video with an ensemble of imperfect classifiers in order to improve classification results on video sourced images of plants in the wild.

</p>
</details>

<details><summary><b>Identifying Distributional Differences in Convective Evolution Prior to Rapid Intensification in Tropical Cyclones</b>
<a href="https://arxiv.org/abs/2109.12029">arxiv:2109.12029</a>
&#x1F4C8; 2 <br>
<p>Trey McNeely, Galen Vincent, Rafael Izbicki, Kimberly M. Wood, Ann B. Lee</p></summary>
<p>

**Abstract:** Tropical cyclone (TC) intensity forecasts are issued by human forecasters who evaluate spatio-temporal observations (e.g., satellite imagery) and model output (e.g., numerical weather prediction, statistical models) to produce forecasts every 6 hours. Within these time constraints, it can be challenging to draw insight from such data. While high-capacity machine learning methods are well suited for prediction problems with complex sequence data, extracting interpretable scientific information with such methods is difficult. Here we leverage powerful AI prediction algorithms and classical statistical inference to identify patterns in the evolution of TC convective structure leading up to the rapid intensification of a storm, hence providing forecasters and scientists with key insight into TC behavior.

</p>
</details>

<details><summary><b>A data acquisition setup for data driven acoustic design</b>
<a href="https://arxiv.org/abs/2109.12014">arxiv:2109.12014</a>
&#x1F4C8; 2 <br>
<p>Romana Rust, Achilleas Xydis, Kurt Heutschi, Nathanaël Perraudin, Gonzalo Casas, Chaoyu Du, Jürgen Strauss, Kurt Eggenschwiler, Fernando Perez-Cruz, Fabio Gramazio, Matthias Kohler</p></summary>
<p>

**Abstract:** In this paper, we present a novel interdisciplinary approach to study the relationship between diffusive surface structures and their acoustic performance. Using computational design, surface structures are iteratively generated and 3D printed at 1:10 model scale. They originate from different fabrication typologies and are designed to have acoustic diffusion and absorption effects. An automated robotic process measures the impulse responses of these surfaces by positioning a microphone and a speaker at multiple locations. The collected data serves two purposes: first, as an exploratory catalogue of different spatio-temporal-acoustic scenarios and second, as data set for predicting the acoustic response of digitally designed surface geometries using machine learning. In this paper, we present the automated data acquisition setup, the data processing and the computational generation of diffusive surface structures. We describe first results of comparative studies of measured surface panels and conclude with steps of future research.

</p>
</details>

<details><summary><b>Discovering PDEs from Multiple Experiments</b>
<a href="https://arxiv.org/abs/2109.11939">arxiv:2109.11939</a>
&#x1F4C8; 2 <br>
<p>Georges Tod, Gert-Jan Both, Remy Kusters</p></summary>
<p>

**Abstract:** Automated model discovery of partial differential equations (PDEs) usually considers a single experiment or dataset to infer the underlying governing equations. In practice, experiments have inherent natural variability in parameters, initial and boundary conditions that cannot be simply averaged out. We introduce a randomised adaptive group Lasso sparsity estimator to promote grouped sparsity and implement it in a deep learning based PDE discovery framework. It allows to create a learning bias that implies the a priori assumption that all experiments can be explained by the same underlying PDE terms with potentially different coefficients. Our experimental results show more generalizable PDEs can be found from multiple highly noisy datasets, by this grouped sparsity promotion rather than simply performing independent model discoveries.

</p>
</details>

<details><summary><b>Towards Autonomous Crop-Agnostic Visual Navigation in Arable Fields</b>
<a href="https://arxiv.org/abs/2109.11936">arxiv:2109.11936</a>
&#x1F4C8; 2 <br>
<p>Alireza Ahmadi, Michael Halstead, Chris McCool</p></summary>
<p>

**Abstract:** Autonomous navigation of a robot in agricultural fields is essential for every task from crop monitoring through to weed management and fertilizer application. Many current approaches rely on accurate GPS, however, such technology is expensive and also prone to failure~(e.g. through lack of coverage). As such, navigation through sensors that can interpret their environment (such as cameras) is important to achieve the goal of autonomy in agriculture. In this paper, we introduce a purely vision-based navigation scheme which is able to reliably guide the robot through row-crop fields. Independent of any global localization or mapping, this approach is able to accurately follow the crop-rows and switch between the rows, only using on-board cameras. With the help of a novel crop-row detection and a novel crop-row switching technique, our navigation scheme can be deployed in a wide range of fields with different canopy types in various growth stages. We have extensively tested our approach in five different fields under various illumination conditions using our agricultural robotic platform (BonnBot-I). And our evaluations show that we have achieved a navigation accuracy of 3.82cm over five different crop fields.

</p>
</details>

<details><summary><b>Learning-based Noise Component Map Estimation for Image Denoising</b>
<a href="https://arxiv.org/abs/2109.11877">arxiv:2109.11877</a>
&#x1F4C8; 2 <br>
<p>Sheyda Ghanbaralizadeh Bahnemiri, Mykola Ponomarenko, Karen Egiazarian</p></summary>
<p>

**Abstract:** A problem of image denoising when images are corrupted by a non-stationary noise is considered in this paper. Since in practice no a priori information on noise is available, noise statistics should be pre-estimated for image denoising. In this paper, deep convolutional neural network (CNN) based method for estimation of a map of local, patch-wise, standard deviations of noise (so-called sigma-map) is proposed. It achieves the state-of-the-art performance in accuracy of estimation of sigma-map for the case of non-stationary noise, as well as estimation of noise variance for the case of additive white Gaussian noise. Extensive experiments on image denoising using estimated sigma-maps demonstrate that our method outperforms recent CNN-based blind image denoising methods by up to 6 dB in PSNR, as well as other state-of-the-art methods based on sigma-map estimation by up to 0.5 dB, providing same time better usage flexibility. Comparison with the ideal case, when denoising is applied using ground-truth sigma-map, shows that a difference of corresponding PSNR values for most of noise levels is within 0.1-0.2 dB and does not exceeds 0.6 dB.

</p>
</details>

<details><summary><b>Training dataset generation for bridge game registration</b>
<a href="https://arxiv.org/abs/2109.11861">arxiv:2109.11861</a>
&#x1F4C8; 2 <br>
<p>Piotr Wzorek, Tomasz Kryjak</p></summary>
<p>

**Abstract:** This paper presents a method for automatic generation of a training dataset for a deep convolutional neural network used for playing card detection. The solution allows to skip the time-consuming processes of manual image collecting and labelling recognised objects. The YOLOv4 network trained on the generated dataset achieved an efficiency of 99.8% in the cards detection task. The proposed method is a part of a project that aims to automate the process of broadcasting duplicate bridge competitions using a vision system and neural networks.

</p>
</details>

<details><summary><b>Unbiased Gradient Estimation with Balanced Assignments for Mixtures of Experts</b>
<a href="https://arxiv.org/abs/2109.11817">arxiv:2109.11817</a>
&#x1F4C8; 2 <br>
<p>Wouter Kool, Chris J. Maddison, Andriy Mnih</p></summary>
<p>

**Abstract:** Training large-scale mixture of experts models efficiently on modern hardware requires assigning datapoints in a batch to different experts, each with a limited capacity. Recently proposed assignment procedures lack a probabilistic interpretation and use biased estimators for training. As an alternative, we propose two unbiased estimators based on principled stochastic assignment procedures: one that skips datapoints which exceed expert capacity, and one that samples perfectly balanced assignments using an extension of the Gumbel-Matching distribution [29]. Both estimators are unbiased, as they correct for the used sampling procedure. On a toy experiment, we find the `skip'-estimator is more effective than the balanced sampling one, and both are more robust in solving the task than biased alternatives.

</p>
</details>

<details><summary><b>Few-shot Learning Based on Multi-stage Transfer and Class-Balanced Loss for Diabetic Retinopathy Grading</b>
<a href="https://arxiv.org/abs/2109.11806">arxiv:2109.11806</a>
&#x1F4C8; 2 <br>
<p>Lei Shi, Junxing Zhang</p></summary>
<p>

**Abstract:** Diabetic retinopathy (DR) is one of the major blindness-causing diseases current-ly known. Automatic grading of DR using deep learning methods not only speeds up the diagnosis of the disease but also reduces the rate of misdiagnosis. However, problems such as insufficient samples and imbalanced class distribu-tion in DR datasets have constrained the improvement of grading performance. In this paper, we introduce the idea of multi-stage transfer into the grading task of DR. The new transfer learning technique leverages multiple datasets with differ-ent scales to enable the model to learn more feature representation information. Meanwhile, to cope with imbalanced DR datasets, we present a class-balanced loss function that performs well in natural image classification tasks, and adopt a simple and easy-to-implement training method for it. The experimental results show that the application of multi-stage transfer and class-balanced loss function can effectively improve the grading performance metrics such as accuracy and quadratic weighted kappa. In fact, our method has outperformed two state-of-the-art methods and achieved the best result on the DR grading task of IDRiD Sub-Challenge 2.

</p>
</details>

<details><summary><b>Edge but not Least: Cross-View Graph Pooling</b>
<a href="https://arxiv.org/abs/2109.11796">arxiv:2109.11796</a>
&#x1F4C8; 2 <br>
<p>Xiaowei Zhou, Jie Yin, Ivor W. Tsang</p></summary>
<p>

**Abstract:** Graph neural networks have emerged as a powerful model for graph representation learning to undertake graph-level prediction tasks. Various graph pooling methods have been developed to coarsen an input graph into a succinct graph-level representation through aggregating node embeddings obtained via graph convolution. However, most graph pooling methods are heavily node-centric and are unable to fully leverage the crucial information contained in global graph structure. This paper presents a cross-view graph pooling (Co-Pooling) method to better exploit crucial graph structure information. The proposed Co-Pooling fuses pooled representations learnt from both node view and edge view. Through cross-view interaction, edge-view pooling and node-view pooling seamlessly reinforce each other to learn more informative graph-level representations. Co-Pooling has the advantage of handling various graphs with different types of node attributes. Extensive experiments on a total of 15 graph benchmark datasets validate the effectiveness of our proposed method, demonstrating its superior performance over state-of-the-art pooling methods on both graph classification and graph regression tasks.

</p>
</details>

<details><summary><b>Non-Euclidean Self-Organizing Maps</b>
<a href="https://arxiv.org/abs/2109.11769">arxiv:2109.11769</a>
&#x1F4C8; 2 <br>
<p>Dorota Celińska-Kopczyńska Eryk Kopczyński</p></summary>
<p>

**Abstract:** Self-Organizing Maps (SOMs, Kohonen networks) belong to neural network models of the unsupervised class. In this paper, we present the generalized setup for non-Euclidean SOMs. Most data analysts take it for granted to use some subregions of a flat space as their data model; however, by the assumption that the underlying geometry is non-Euclidean we obtain a new degree of freedom for the techniques that translate the similarities into spatial neighborhood relationships. We improve the traditional SOM algorithm by introducing topology-related extensions. Our proposition can be successfully applied to dimension reduction, clustering or finding similarities in big data (both hierarchical and non-hierarchical).

</p>
</details>

<details><summary><b>Dimension Reduction for Data with Heterogeneous Missingness</b>
<a href="https://arxiv.org/abs/2109.11765">arxiv:2109.11765</a>
&#x1F4C8; 2 <br>
<p>Yurong Ling, Zijing Liu, Jing-Hao Xue</p></summary>
<p>

**Abstract:** Dimension reduction plays a pivotal role in analysing high-dimensional data. However, observations with missing values present serious difficulties in directly applying standard dimension reduction techniques. As a large number of dimension reduction approaches are based on the Gram matrix, we first investigate the effects of missingness on dimension reduction by studying the statistical properties of the Gram matrix with or without missingness, and then we present a bias-corrected Gram matrix with nice statistical properties under heterogeneous missingness. Extensive empirical results, on both simulated and publicly available real datasets, show that the proposed unbiased Gram matrix can significantly improve a broad spectrum of representative dimension reduction approaches.

</p>
</details>

<details><summary><b>Lacking the embedding of a word? Look it up into a traditional dictionary</b>
<a href="https://arxiv.org/abs/2109.11763">arxiv:2109.11763</a>
&#x1F4C8; 2 <br>
<p>Elena Sofia Ruzzetti, Leonardo Ranaldi, Michele Mastromattei, Francesca Fallucchi, Fabio Massimo Zanzotto</p></summary>
<p>

**Abstract:** Word embeddings are powerful dictionaries, which may easily capture language variations. However, these dictionaries fail to give sense to rare words, which are surprisingly often covered by traditional dictionaries. In this paper, we propose to use definitions retrieved in traditional dictionaries to produce word embeddings for rare words. For this purpose, we introduce two methods: Definition Neural Network (DefiNNet) and Define BERT (DefBERT). In our experiments, DefiNNet and DefBERT significantly outperform state-of-the-art as well as baseline methods devised for producing embeddings of unknown words. In fact, DefiNNet significantly outperforms FastText, which implements a method for the same task-based on n-grams, and DefBERT significantly outperforms the BERT method for OOV words. Then, definitions in traditional dictionaries are useful to build word embeddings for rare words.

</p>
</details>

<details><summary><b>Multi-View Video-Based 3D Hand Pose Estimation</b>
<a href="https://arxiv.org/abs/2109.11747">arxiv:2109.11747</a>
&#x1F4C8; 2 <br>
<p>Leyla Khaleghi, Alireza Sepas Moghaddam, Joshua Marshall, Ali Etemad</p></summary>
<p>

**Abstract:** Hand pose estimation (HPE) can be used for a variety of human-computer interaction applications such as gesture-based control for physical or virtual/augmented reality devices. Recent works have shown that videos or multi-view images carry rich information regarding the hand, allowing for the development of more robust HPE systems. In this paper, we present the Multi-View Video-Based 3D Hand (MuViHand) dataset, consisting of multi-view videos of the hand along with ground-truth 3D pose labels. Our dataset includes more than 402,000 synthetic hand images available in 4,560 videos. The videos have been simultaneously captured from six different angles with complex backgrounds and random levels of dynamic lighting. The data has been captured from 10 distinct animated subjects using 12 cameras in a semi-circle topology where six tracking cameras only focus on the hand and the other six fixed cameras capture the entire body. Next, we implement MuViHandNet, a neural pipeline consisting of image encoders for obtaining visual embeddings of the hand, recurrent learners to learn both temporal and angular sequential information, and graph networks with U-Net architectures to estimate the final 3D pose information. We perform extensive experiments and show the challenging nature of this new dataset as well as the effectiveness of our proposed method. Ablation studies show the added value of each component in MuViHandNet, as well as the benefit of having temporal and sequential information in the dataset.

</p>
</details>

<details><summary><b>Towards a Multi-Agent System Architecture for Supply Chain Management</b>
<a href="https://arxiv.org/abs/2110.08125">arxiv:2110.08125</a>
&#x1F4C8; 1 <br>
<p>Carlos R. Jaimez-González, Wulfrano A. Luna-Ramírez</p></summary>
<p>

**Abstract:** Individual business processes have been changing since the Internet was created, and they are now oriented towards a more distributed and collaborative business model, in an e-commerce environment that adapts itself to the competitive and changing market conditions. This paper presents a multi-agent system architecture for supply chain management, which explores different strategies and offers solutions in a distributed e-commerce environment. The system is designed to support different types of interfaces, which allow interoperating with other business models already developed. In order to show how the entire multi-agent system is being developed, the implementation of a collaborative agent is presented and explained.

</p>
</details>

<details><summary><b>Adaptive Sampling Quasi-Newton Methods for Zeroth-Order Stochastic Optimization</b>
<a href="https://arxiv.org/abs/2109.12213">arxiv:2109.12213</a>
&#x1F4C8; 1 <br>
<p>Raghu Bollapragada, Stefan M. Wild</p></summary>
<p>

**Abstract:** We consider unconstrained stochastic optimization problems with no available gradient information. Such problems arise in settings from derivative-free simulation optimization to reinforcement learning. We propose an adaptive sampling quasi-Newton method where we estimate the gradients of a stochastic function using finite differences within a common random number framework. We develop modified versions of a norm test and an inner product quasi-Newton test to control the sample sizes used in the stochastic approximations and provide global convergence results to the neighborhood of the optimal solution. We present numerical experiments on simulation optimization problems to illustrate the performance of the proposed algorithm. When compared with classical zeroth-order stochastic gradient methods, we observe that our strategies of adapting the sample sizes significantly improve performance in terms of the number of stochastic function evaluations required.

</p>
</details>

<details><summary><b>MIIDL: a Python package for microbial biomarkers identification powered by interpretable deep learning</b>
<a href="https://arxiv.org/abs/2109.12204">arxiv:2109.12204</a>
&#x1F4C8; 1 <br>
<p>Jian Jiang</p></summary>
<p>

**Abstract:** Detecting microbial biomarkers used to predict disease phenotypes and clinical outcomes is crucial for disease early-stage screening and diagnosis. Most methods for biomarker identification are linear-based, which is very limited as biological processes are rarely fully linear. The introduction of machine learning to this field tends to bring a promising solution. However, identifying microbial biomarkers in an interpretable, data-driven and robust manner remains challenging. We present MIIDL, a Python package for the identification of microbial biomarkers based on interpretable deep learning. MIIDL innovatively applies convolutional neural networks, a variety of interpretability algorithms and plenty of pre-processing methods to provide a one-stop and robust pipeline for microbial biomarkers identification from high-dimensional and sparse data sets.

</p>
</details>

<details><summary><b>POSSE: Patterns of Systems During Software Encryption</b>
<a href="https://arxiv.org/abs/2109.12162">arxiv:2109.12162</a>
&#x1F4C8; 1 <br>
<p>David Noever, Samantha Miller Noever</p></summary>
<p>

**Abstract:** This research recasts ransomware detection using performance monitoring and statistical machine learning. The work builds a test environment with 41 input variables to label and compares three computing states: idle, encryption and compression. A common goal of this behavioral detector seeks to anticipate and short-circuit the final step of hard-drive locking with encryption and the demand for payment to return the file system to its baseline. Comparing machine learning techniques, linear regression outperforms random forest, decision trees, and support vector machines (SVM). All algorithms classified the 3 possible classes (idle, encryption, and compression) with greater than 91% accuracy.

</p>
</details>

<details><summary><b>Evaluating X-vector-based Speaker Anonymization under White-box Assessment</b>
<a href="https://arxiv.org/abs/2109.11946">arxiv:2109.11946</a>
&#x1F4C8; 1 <br>
<p>Pierre Champion, Denis Jouvet, Anthony Larcher</p></summary>
<p>

**Abstract:** In the scenario of the Voice Privacy challenge, anonymization is achieved by converting all utterances from a source speaker to match the same target identity; this identity being randomly selected. In this context, an attacker with maximum knowledge about the anonymization system can not infer the target identity. This article proposed to constrain the target selection to a specific identity, i.e., removing the random selection of identity, to evaluate the extreme threat under a whitebox assessment (the attacker has complete knowledge about the system). Targeting a unique identity also allows us to investigate whether some target's identities are better than others to anonymize a given speaker.

</p>
</details>

<details><summary><b>A Bayesian Optimization Approach for Attenuation Correction in SPECT Brain Imaging</b>
<a href="https://arxiv.org/abs/2109.11920">arxiv:2109.11920</a>
&#x1F4C8; 1 <br>
<p>Loizos Koutsantonis, Ayman Makki, Tiago Carneiro, Emmanuel Kieffer, Pascal Bouvry</p></summary>
<p>

**Abstract:** Photon attenuation and scatter are the two main physical factors affecting the diagnostic quality of SPECT in its applications in brain imaging. In this work, we present a novel Bayesian Optimization approach for Attenuation Correction (BOAC) in SPECT brain imaging. BOAC utilizes a prior model parametrizing the head geometry and exploits High Performance Computing (HPC) to reconstruct attenuation corrected images without requiring prior anatomical information from complementary CT scans. BOAC is demonstrated in SPECT brain imaging using noisy and attenuated sinograms, simulated from numerical phantoms. The quality of the tomographic images obtained with the proposed method are compared to those obtained without attenuation correction by employing the appropriate image quality metrics. The quantitative results show the capacity of BOAC to provide images exhibiting higher contrast and less background artifacts as compared to the non-attenuation corrected MLEM images.

</p>
</details>

<details><summary><b>Adaptive Clustering-based Reduced-Order Modeling Framework: Fast and accurate modeling of localized history-dependent phenomena</b>
<a href="https://arxiv.org/abs/2109.11897">arxiv:2109.11897</a>
&#x1F4C8; 1 <br>
<p>Bernardo P. Ferreira, F. M. Andrade Pires, Miguel A. Bessa</p></summary>
<p>

**Abstract:** This paper proposes a novel Adaptive Clustering-based Reduced-Order Modeling (ACROM) framework to significantly improve and extend the recent family of clustering-based reduced-order models (CROMs). This adaptive framework enables the clustering-based domain decomposition to evolve dynamically throughout the problem solution, ensuring optimum refinement in regions where the relevant fields present steeper gradients. It offers a new route to fast and accurate material modeling of history-dependent nonlinear problems involving highly localized plasticity and damage phenomena. The overall approach is composed of three main building blocks: target clusters selection criterion, adaptive cluster analysis, and computation of cluster interaction tensors. In addition, an adaptive clustering solution rewinding procedure and a dynamic adaptivity split factor strategy are suggested to further enhance the adaptive process. The coined Adaptive Self-Consistent Clustering Analysis (ASCA) is shown to perform better than its static counterpart when capturing the multi-scale elasto-plastic behavior of a particle-matrix composite and predicting the associated fracture and toughness. Given the encouraging results shown in this paper, the ACROM framework sets the stage and opens new avenues to explore adaptivity in the context of CROMs.

</p>
</details>

<details><summary><b>The More, the Better? A Study on Collaborative Machine Learning for DGA Detection</b>
<a href="https://arxiv.org/abs/2109.11830">arxiv:2109.11830</a>
&#x1F4C8; 1 <br>
<p>Arthur Drichel, Benedikt Holmes, Justus von Brandt, Ulrike Meyer</p></summary>
<p>

**Abstract:** Domain generation algorithms (DGAs) prevent the connection between a botnet and its master from being blocked by generating a large number of domain names. Promising single-data-source approaches have been proposed for separating benign from DGA-generated domains. Collaborative machine learning (ML) can be used in order to enhance a classifier's detection rate, reduce its false positive rate (FPR), and to improve the classifier's generalization capability to different networks. In this paper, we complement the research area of DGA detection by conducting a comprehensive collaborative learning study, including a total of 13,440 evaluation runs. In two real-world scenarios we evaluate a total of eleven different variations of collaborative learning using three different state-of-the-art classifiers. We show that collaborative ML can lead to a reduction in FPR by up to 51.7%. However, while collaborative ML is beneficial for DGA detection, not all approaches and classifier types profit equally. We round up our comprehensive study with a thorough discussion of the privacy threats implicated by the different collaborative ML approaches.

</p>
</details>

<details><summary><b>Predicting pigging operations in oil pipelines</b>
<a href="https://arxiv.org/abs/2109.11812">arxiv:2109.11812</a>
&#x1F4C8; 1 <br>
<p>Riccardo Angelo Giro, Giancarlo Bernasconi, Giuseppe Giunta, Simone Cesari</p></summary>
<p>

**Abstract:** This paper presents an innovative machine learning methodology that leverages on long-term vibroacoustic measurements to perform automated predictions of the needed pigging operations in crude oil trunklines. Historical pressure signals have been collected by Eni (e-vpms monitoring system) for two years on discrete points at a relative distance of 30-35 km along an oil pipeline (100 km length, 16 inch diameter pipes) located in Northern Italy. In order to speed up the activity and to check the operation logs, a tool has been implemented to automatically highlight the historical pig operations performed on the line. Such a tool is capable of detecting, in the observed pressure measurements, the acoustic noise generated by the travelling pig. All the data sets have been reanalyzed and exploited by using field data validations to guide a decision tree regressor (DTR). Several statistical indicators, computed from pressure head loss between line segments, are fed to the DTR, which automatically outputs probability values indicating the possible need for pigging the pipeline. The procedure is applied to the vibroacoustic signals of each pair of consecutive monitoring stations, such that the proposed predictive maintenance strategy is capable of tracking the conditions of individual pipeline sections, thus determining which portion of the conduit is subject to the highest occlusion levels in order to optimize the clean-up operations. Prediction accuracy is assessed by evaluating the typical metrics used in statistical analysis of regression problems, such as the Root Mean Squared Error (RMSE).

</p>
</details>

<details><summary><b>Exploring Multi-dimensional Hierarchical Network Topologies for Efficient Distributed Training of Trillion Parameter DL Models</b>
<a href="https://arxiv.org/abs/2109.11762">arxiv:2109.11762</a>
&#x1F4C8; 1 <br>
<p>William Won, Saeed Rashidi, Sudarshan Srinivasan, Tushar Krishna</p></summary>
<p>

**Abstract:** Deep Neural Networks have gained significant attraction due to their wide applicability in different domains. DNN sizes and training samples are constantly growing, making training of such workloads more challenging. Distributed training is a solution to reduce the training time. High-performance distributed training platforms should leverage multi-dimensional hierarchical networks, which interconnect accelerators through different levels of the network, to dramatically reduce expensive NICs required for the scale-out network. However, it comes at the expense of communication overhead between distributed accelerators to exchange gradients or input/output activation. In order to allow for further scaling of the workloads, communication overhead needs to be minimized. In this paper, we motivate the fact that in training platforms, adding more intermediate network dimensions is beneficial for efficiently mitigating the excessive use of expensive NIC resources. Further, we address different challenges of the DNN training on hierarchical networks. We discuss when designing the interconnect, how to distribute network bandwidth resources across different dimensions in order to (i) maximize BW utilization of all dimensions, and (ii) minimizing the overall training time for the target workload. We then implement a framework that, for a given workload, determines the best network configuration that maximizes performance, or performance-per-cost.

</p>
</details>

<details><summary><b>Indoor Localization Using Smartphone Magnetic with Multi-Scale TCN and LSTM</b>
<a href="https://arxiv.org/abs/2109.11750">arxiv:2109.11750</a>
&#x1F4C8; 1 <br>
<p>Mingyang Zhang, Jie Jia, Jian Chen</p></summary>
<p>

**Abstract:** A novel multi-scale temporal convolutional network (TCN) and long short-term memory network (LSTM) based magnetic localization approach is proposed. To enhance the discernibility of geomagnetic signals, the time-series preprocessing approach is constructed at first. Next, the TCN is invoked to expand the feature dimensions on the basis of keeping the time-series characteristics of LSTM model. Then, a multi-scale time-series layer is constructed with multiple TCNs of different dilation factors to address the problem of inconsistent time-series speed between localization model and mobile users. A stacking framework of multi-scale TCN and LSTM is eventually proposed for indoor magnetic localization. Experiment results demonstrate the effectiveness of the proposed algorithm in indoor localization.

</p>
</details>

<details><summary><b>Data-Assemble: Leveraging Multiple Datasets with Partial Labels</b>
<a href="https://arxiv.org/abs/2109.12265">arxiv:2109.12265</a>
&#x1F4C8; 0 <br>
<p>Mintong Kang, Yongyi Lu, Alan L. Yuille, Zongwei Zhou</p></summary>
<p>

**Abstract:** The success of deep learning relies heavily on large and diverse datasets with extensive labels, but we often only have access to several small datasets associated with partial labels. In this paper, we start a new initiative, "Data-Assemble", that aims to unleash the full potential of partially labeled data from an assembly of public datasets. Specifically, we introduce a new dynamic adapter to encode different visual tasks, which addresses the challenges of incomparable, heterogeneous, or even conflicting labeling protocols. We also employ pseudo-labeling and consistency constraints to harness data with missing labels and to mitigate the domain gap across datasets. From rigorous evaluations on three natural imaging and six medical imaging tasks, we discover that learning from "negative examples" facilitates both classification and segmentation of classes of interest. This sheds new light on the computer-aided diagnosis of rare diseases and emerging pandemics, wherein "positive examples" are hard to collect, yet "negative examples" are relatively easier to assemble. Apart from exceeding prior arts in the ChestXray benchmark, our model is particularly strong in identifying diseases of minority classes, yielding over 3-point improvement on average. Remarkably, when using existing partial labels, our model performance is on-par with that using full labels, eliminating the need for an additional 40% of annotation costs. Code will be made available at https://github.com/MrGiovanni/DataAssemble.

</p>
</details>

<details><summary><b>Influence of Mobility Restrictions on Transmission of COVID-19 in the state of Maryland -- the USA</b>
<a href="https://arxiv.org/abs/2109.12219">arxiv:2109.12219</a>
&#x1F4C8; 0 <br>
<p>Nandini Raghuraman, Kartik Kaushik</p></summary>
<p>

**Abstract:** Background: The novel coronavirus, COVID-19, was first detected in the United States in January 2020. To curb the spread of the disease in mid-March, different states issued mandatory stay-at-home (SAH) orders. These nonpharmaceutical interventions were mandated based on prior experiences, such as the 1918 influenza epidemic. Hence, we decided to study the impact of restrictions on mobility on reducing COVID-19 transmission. Methods: We designed an ecological time series study with our exposure variable as Mobility patterns in the state of Maryland for March- December 2020 and our outcome variable as the COVID-19 hospitalizations for the same period. We built an Extreme Gradient Boosting (XGBoost) ensemble machine learning model and regressed the lagged COVID-19 hospitalizations with Mobility volume for different regions of Maryland. Results: We found an 18% increase in COVID-19 hospitalizations when mobility was increased by a factor of five, similarly a 43% increase when mobility was further increased by a factor of ten. Conclusion: The findings of our study demonstrated a positive linear relationship between mobility and the incidence of COVID-19 cases. These findings are partially consistent with other studies suggesting the benefits of mobility restrictions. Although more detailed approach is needed to precisely understand the benefits and limitations of mobility restrictions as part of a response to the COVID-19 pandemic.

</p>
</details>

<details><summary><b>GERNERMED -- An Open German Medical NER Model</b>
<a href="https://arxiv.org/abs/2109.12104">arxiv:2109.12104</a>
&#x1F4C8; 0 <br>
<p>Johann Frei, Frank Kramer</p></summary>
<p>

**Abstract:** The current state of adoption of well-structured electronic health records and integration of digital methods for storing medical patient data in structured formats can often considered as inferior compared to the use of traditional, unstructured text based patient data documentation. Data mining in the field of medical data analysis often needs to rely solely on processing of unstructured data to retrieve relevant data. In natural language processing (NLP), statistical models have been shown successful in various tasks like part-of-speech tagging, relation extraction (RE) and named entity recognition (NER). In this work, we present GERNERMED, the first open, neural NLP model for NER tasks dedicated to detect medical entity types in German text data. Here, we avoid the conflicting goals of protection of sensitive patient data from training data extraction and the publication of the statistical model weights by training our model on a custom dataset that was translated from publicly available datasets in foreign language by a pretrained neural machine translation model. The sample code and the statistical model is available at: https://github.com/frankkramer-lab/GERNERMED

</p>
</details>

<details><summary><b>Understanding Spending Behavior: Recurrent Neural Network Explanation and Interpretation</b>
<a href="https://arxiv.org/abs/2109.11871">arxiv:2109.11871</a>
&#x1F4C8; 0 <br>
<p>Charl Maree, Christian W. Omlin</p></summary>
<p>

**Abstract:** Micro-segmentation of customers in the finance sector is a non-trivial task and has been an atypical omission from recent scientific literature. Where traditional segmentation classifies customers based on coarse features such as demographics, micro-segmentation depicts more nuanced differences between individuals, bringing forth several advantages including the potential for improved personalization in financial services. AI and representation learning offer a unique opportunity to solve the problem of micro-segmentation. Although ubiquitous in many industries, the proliferation of AI in sensitive industries such as finance has become contingent on the explainability of deep models. We had previously solved the micro-segmentation problem by extracting temporal features from the state space of a recurrent neural network (RNN). However, due to the inherent opacity of RNNs our solution lacked an explanation. In this study, we address this issue by extracting a symbolic explanation for our model and providing an interpretation of our temporal features. For the explanation, we use a linear regression model to reconstruct the features in the state space with high fidelity. We show that our linear regression coefficients have not only learned the rules used to recreate the features, but have also learned the relationships that were not directly evident in the raw data. Finally, we propose a novel method to interpret the dynamics of the state space by using the principles of inverse regression and dynamical systems to locate and label a set of attractors.

</p>
</details>

<details><summary><b>The $f$-Divergence Reinforcement Learning Framework</b>
<a href="https://arxiv.org/abs/2109.11867">arxiv:2109.11867</a>
&#x1F4C8; 0 <br>
<p>Chen Gong, Qiang He, Yunpeng Bai, Zhou Yang, Xiaoyu Chen, Xinwen Hou, Xianjie Zhang, Yu Liu, Guoliang Fan</p></summary>
<p>

**Abstract:** The framework of deep reinforcement learning (DRL) provides a powerful and widely applicable mathematical formalization for sequential decision-making. This paper present a novel DRL framework, termed \emph{$f$-Divergence Reinforcement Learning (FRL)}. In FRL, the policy evaluation and policy improvement phases are simultaneously performed by minimizing the $f$-divergence between the learning policy and sampling policy, which is distinct from conventional DRL algorithms that aim to maximize the expected cumulative rewards. We theoretically prove that minimizing such $f$-divergence can make the learning policy converge to the optimal policy. Besides, we convert the process of training agents in FRL framework to a saddle-point optimization problem with a specific $f$ function through Fenchel conjugate, which forms new methods for policy evaluation and policy improvement. Through mathematical proofs and empirical evaluation, we demonstrate that the FRL framework has two advantages: (1) policy evaluation and policy improvement processes are performed simultaneously and (2) the issues of overestimating value function are naturally alleviated. To evaluate the effectiveness of the FRL framework, we conduct experiments on Atari 2600 video games and show that agents trained in the FRL framework match or surpass the baseline DRL algorithms.

</p>
</details>


[Next Page]({{ '/2021/09/23/2021.09.23.html' | relative_url }})
