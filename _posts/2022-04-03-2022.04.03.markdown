Prev: [2022.04.02]({{ '/2022/04/02/2022.04.02.html' | relative_url }})  Next: [2022.04.04]({{ '/2022/04/04/2022.04.04.html' | relative_url }})
{% raw %}
## Summary for 2022-04-03, created on 2022-04-13


<details><summary><b>MLPro: A System for Hosting Crowdsourced Machine Learning Challenges for Open-Ended Research Problems</b>
<a href="https://arxiv.org/abs/2204.01216">arxiv:2204.01216</a>
&#x1F4C8; 70 <br>
<p>Peter Washington, Aayush Nandkeolyar, Sam Yang</p></summary>
<p>

**Abstract:** The task of developing a machine learning (ML) model for a particular problem is inherently open-ended, and there is an unbounded set of possible solutions. Steps of the ML development pipeline, such as feature engineering, loss function specification, data imputation, and dimensionality reduction, require the engineer to consider an extensive and often infinite array of possibilities. Successfully identifying high-performing solutions for an unfamiliar dataset or problem requires a mix of mathematical prowess and creativity applied towards inventing and repurposing novel ML methods. Here, we explore the feasibility of hosting crowdsourced ML challenges to facilitate a breadth-first exploration of open-ended research problems, thereby expanding the search space of problem solutions beyond what a typical ML team could viably investigate. We develop MLPro, a system which combines the notion of open-ended ML coding problems with the concept of an automatic online code judging platform. To conduct a pilot evaluation of this paradigm, we crowdsource several open-ended ML challenges to ML and data science practitioners. We describe results from two separate challenges. We find that for sufficiently unconstrained and complex problems, many experts submit similar solutions, but some experts provide unique solutions which outperform the "typical" solution class. We suggest that automated expert crowdsourcing systems such as MLPro have the potential to accelerate ML engineering creativity.

</p>
</details>

<details><summary><b>Understanding the unstable convergence of gradient descent</b>
<a href="https://arxiv.org/abs/2204.01050">arxiv:2204.01050</a>
&#x1F4C8; 36 <br>
<p>Kwangjun Ahn, Jingzhao Zhang, Suvrit Sra</p></summary>
<p>

**Abstract:** Most existing analyses of (stochastic) gradient descent rely on the condition that for $L$-smooth cost, the step size is less than $2/L$. However, many works have observed that in machine learning applications step sizes often do not fulfill this condition, yet (stochastic) gradient descent converges, albeit in an unstable manner. We investigate this unstable convergence phenomenon from first principles, and elucidate key causes behind it. We also identify its main characteristics, and how they interrelate, offering a transparent view backed by both theory and experiments.

</p>
</details>

<details><summary><b>Revisiting Sliced Wasserstein on Images: From Vectorization to Convolution</b>
<a href="https://arxiv.org/abs/2204.01188">arxiv:2204.01188</a>
&#x1F4C8; 8 <br>
<p>Khai Nguyen, Nhat Ho</p></summary>
<p>

**Abstract:** The conventional sliced Wasserstein is defined between two probability measures that have realizations as vectors. When comparing two probability measures over images, practitioners first need to vectorize images and then project them to one-dimensional space by using matrix multiplication between the sample matrix and the projection matrix. After that, the sliced Wasserstein is evaluated by averaging the two corresponding one-dimensional projected probability measures. However, this approach has two limitations. The first limitation is that the spatial structure of images is not captured efficiently by the vectorization step; therefore, the later slicing process becomes harder to gather the discrepancy information. The second limitation is memory inefficiency since each slicing direction is a vector that has the same dimension as the images. To address these limitations, we propose novel slicing methods for sliced Wasserstein between probability measures over images that are based on the convolution operators. We derive convolution sliced Wasserstein (CSW) and its variants via incorporating stride, dilation, and non-linear activation function into the convolution operators. We investigate the metricity of CSW as well as its sample complexity, its computational complexity, and its connection to conventional sliced Wasserstein distances. Finally, we demonstrate the favorable performance of CSW over the conventional sliced Wasserstein in comparing probability measures over images and in training deep generative modeling on images.

</p>
</details>

<details><summary><b>Data Cards: Purposeful and Transparent Dataset Documentation for Responsible AI</b>
<a href="https://arxiv.org/abs/2204.01075">arxiv:2204.01075</a>
&#x1F4C8; 6 <br>
<p>Mahima Pushkarna, Andrew Zaldivar, Oddur Kjartansson</p></summary>
<p>

**Abstract:** As research and industry moves towards large-scale models capable of numerous downstream tasks, the complexity of understanding multi-modal datasets that give nuance to models rapidly increases. A clear and thorough understanding of a dataset's origins, development, intent, ethical considerations and evolution becomes a necessary step for the responsible and informed deployment of models, especially those in people-facing contexts and high-risk domains. However, the burden of this understanding often falls on the intelligibility, conciseness, and comprehensiveness of the documentation. It requires consistency and comparability across the documentation of all datasets involved, and as such documentation must be treated as a user-centric product in and of itself. In this paper, we propose Data Cards for fostering transparent, purposeful and human-centered documentation of datasets within the practical contexts of industry and research. Data Cards are structured summaries of essential facts about various aspects of ML datasets needed by stakeholders across a dataset's lifecycle for responsible AI development. These summaries provide explanations of processes and rationales that shape the data and consequently the models, such as upstream sources, data collection and annotation methods; training and evaluation methods, intended use; or decisions affecting model performance. We also present frameworks that ground Data Cards in real-world utility and human-centricity. Using two case studies, we report on desirable characteristics that support adoption across domains, organizational structures, and audience groups. Finally, we present lessons learned from deploying over 20 Data Cards.

</p>
</details>

<details><summary><b>Multilingual and Multimodal Abuse Detection</b>
<a href="https://arxiv.org/abs/2204.02263">arxiv:2204.02263</a>
&#x1F4C8; 5 <br>
<p>Rini Sharon, Heet Shah, Debdoot Mukherjee, Vikram Gupta</p></summary>
<p>

**Abstract:** The presence of abusive content on social media platforms is undesirable as it severely impedes healthy and safe social media interactions. While automatic abuse detection has been widely explored in textual domain, audio abuse detection still remains unexplored. In this paper, we attempt abuse detection in conversational audio from a multimodal perspective in a multilingual social media setting. Our key hypothesis is that along with the modelling of audio, incorporating discriminative information from other modalities can be highly beneficial for this task. Our proposed method, MADA, explicitly focuses on two modalities other than the audio itself, namely, the underlying emotions expressed in the abusive audio and the semantic information encapsulated in the corresponding textual form. Observations prove that MADA demonstrates gains over audio-only approaches on the ADIMA dataset. We test the proposed approach on 10 different languages and observe consistent gains in the range 0.6%-5.2% by leveraging multiple modalities. We also perform extensive ablation experiments for studying the contributions of every modality and observe the best results while leveraging all the modalities together. Additionally, we perform experiments to empirically confirm that there is a strong correlation between underlying emotions and abusive behaviour.

</p>
</details>

<details><summary><b>Proactive Anomaly Detection for Robot Navigation with Multi-Sensor Fusion</b>
<a href="https://arxiv.org/abs/2204.01146">arxiv:2204.01146</a>
&#x1F4C8; 5 <br>
<p>Tianchen Ji, Arun Narenthiran Sivakumar, Girish Chowdhary, Katherine Driggs-Campbell</p></summary>
<p>

**Abstract:** Despite the rapid advancement of navigation algorithms, mobile robots often produce anomalous behaviors that can lead to navigation failures. The ability to detect such anomalous behaviors is a key component in modern robots to achieve high-levels of autonomy. Reactive anomaly detection methods identify anomalous task executions based on the current robot state and thus lack the ability to alert the robot before an actual failure occurs. Such an alert delay is undesirable due to the potential damage to both the robot and the surrounding objects. We propose a proactive anomaly detection network (PAAD) for robot navigation in unstructured and uncertain environments. PAAD predicts the probability of future failure based on the planned motions from the predictive controller and the current observation from the perception module. Multi-sensor signals are fused effectively to provide robust anomaly detection in the presence of sensor occlusion as seen in field environments. Our experiments on field robot data demonstrates superior failure identification performance than previous methods, and that our model can capture anomalous behaviors in real-time while maintaining a low false detection rate in cluttered fields. Code, dataset, and video are available at https://github.com/tianchenji/PAAD

</p>
</details>

<details><summary><b>Virtual Relational Knowledge Graphs for Recommendation</b>
<a href="https://arxiv.org/abs/2204.01089">arxiv:2204.01089</a>
&#x1F4C8; 5 <br>
<p>Lingyun Lu, Bang Wang, Zizhuo Zhang, Shenghao Liu, Han Xu</p></summary>
<p>

**Abstract:** Incorporating knowledge graph as side information has become a new trend in recommendation systems. Recent studies regard items as entities of a knowledge graph and leverage graph neural networks to assist item encoding, yet by considering each relation type individually. However, relation types are often too many and sometimes one relation type involves too few entities. We argue that it is not efficient nor effective to use every relation type for item encoding. In this paper, we propose a VRKG4Rec model (Virtual Relational Knowledge Graphs for Recommendation), which explicitly distinguish the influence of different relations for item representation learning. We first construct virtual relational graphs (VRKGs) by an unsupervised learning scheme. We also design a local weighted smoothing (LWS) mechanism for encoding nodes, which iteratively updates a node embedding only depending on the embedding of its own and its neighbors, but involve no additional training parameters. We also employ the LWS mechanism on a user-item bipartite graph for user representation learning, which utilizes encodings of items with relational knowledge to help training representations of users. Experiment results on two public datasets validate that our VRKG4Rec model outperforms the state-of-the-art methods.

</p>
</details>

<details><summary><b>Deep Clustering via Center-Oriented Margin Free-Triplet Loss for Skin Lesion Detection in Highly Imbalanced Datasets</b>
<a href="https://arxiv.org/abs/2204.02275">arxiv:2204.02275</a>
&#x1F4C8; 4 <br>
<p>Saban Ozturk, Tolga Cukur</p></summary>
<p>

**Abstract:** Melanoma is a fatal skin cancer that is curable and has dramatically increasing survival rate when diagnosed at early stages. Learning-based methods hold significant promise for the detection of melanoma from dermoscopic images. However, since melanoma is a rare disease, existing databases of skin lesions predominantly contain highly imbalanced numbers of benign versus malignant samples. In turn, this imbalance introduces substantial bias in classification models due to the statistical dominance of the majority class. To address this issue, we introduce a deep clustering approach based on the latent-space embedding of dermoscopic images. Clustering is achieved using a novel center-oriented margin-free triplet loss (COM-Triplet) enforced on image embeddings from a convolutional neural network backbone. The proposed method aims to form maximally-separated cluster centers as opposed to minimizing classification error, so it is less sensitive to class imbalance. To avoid the need for labeled data, we further propose to implement COM-Triplet based on pseudo-labels generated by a Gaussian mixture model. Comprehensive experiments show that deep clustering with COM-Triplet loss outperforms clustering with triplet loss, and competing classifiers in both supervised and unsupervised settings.

</p>
</details>

<details><summary><b>Meta-Learning Approaches for a One-Shot Collective-Decision Aggregation: Correctly Choosing how to Choose Correctly</b>
<a href="https://arxiv.org/abs/2204.01721">arxiv:2204.01721</a>
&#x1F4C8; 4 <br>
<p>Hilla Shinitzky, Yuval Shahar, Ortal Parpara, Michal Ezrets, Raz Klein</p></summary>
<p>

**Abstract:** Aggregating successfully the choices regarding a given decision problem made by the multiple collective members into a single solution is essential for exploiting the collective's intelligence and for effective crowdsourcing. There are various aggregation techniques, some of which come down to a simple and sometimes effective deterministic aggregation rule. However, it has been shown that the efficiency of those techniques is unstable under varying conditions and within different domains. Other methods mainly rely on learning from the decision-makers previous responses or the availability of additional information about them. In this study, we present two one-shot machine-learning-based aggregation approaches. The first predicts, given multiple features about the collective's choices, including meta-cognitive ones, which aggregation method will be best for a given case. The second directly predicts which decision is optimal, given, among other things, the selection made by each method. We offer a meta-cognitive feature-engineering approach for characterizing a collective decision-making case in a context-sensitive fashion. In addition, we offer a new aggregation method, the Devil's-Advocate aggregator, to deal with cases in which standard aggregation methods are predicted to fail. Experimental results show that using either of our proposed approaches increases the percentage of successfully aggregated cases (i.e., cases in which the correct answer is returned) significantly, compared to the uniform application of each rule-based aggregation method. We also demonstrate the importance of the Devil's Advocate aggregator.

</p>
</details>

<details><summary><b>Pragmatic constraints and pronoun reference disambiguation: the possible and the impossible</b>
<a href="https://arxiv.org/abs/2204.01166">arxiv:2204.01166</a>
&#x1F4C8; 4 <br>
<p>Ernest Davis</p></summary>
<p>

**Abstract:** Pronoun disambiguation in understanding text and discourse often requires the application of both general pragmatic knowledge and context-specific information. In AI and linguistics research, this has mostly been studied in cases where the referent is explicitly stated in the preceding text nearby. However, pronouns in natural text often refer to entities, collections, or events that are only implicitly mentioned previously; in those cases the need to use pragmatic knowledge to disambiguate becomes much more acute and the characterization of the knowledge becomes much more difficult. Extended literary texts at times employ both extremely complex patterns of reference and extremely rich and subtle forms of knowledge. Indeed, it is occasionally possible to have a pronoun that is far separated from its referent in a text. In the opposite direction, pronoun use is affected by considerations of focus of attention and by formal constraints such as a preference for parallel syntactic structures; these can be so strong that no pragmatic knowledge suffices to overrule them.

</p>
</details>

<details><summary><b>Byzantine-Robust Federated Linear Bandits</b>
<a href="https://arxiv.org/abs/2204.01155">arxiv:2204.01155</a>
&#x1F4C8; 4 <br>
<p>Ali Jadbabaie, Haochuan Li, Jian Qian, Yi Tian</p></summary>
<p>

**Abstract:** In this paper, we study a linear bandit optimization problem in a federated setting where a large collection of distributed agents collaboratively learn a common linear bandit model. Standard federated learning algorithms applied to this setting are vulnerable to Byzantine attacks on even a small fraction of agents. We propose a novel algorithm with a robust aggregation oracle that utilizes the geometric median. We prove that our proposed algorithm is robust to Byzantine attacks on fewer than half of agents and achieves a sublinear $\tilde{\mathcal{O}}({T^{3/4}})$ regret with $\mathcal{O}(\sqrt{T})$ steps of communication in $T$ steps. Moreover, we make our algorithm differentially private via a tree-based mechanism. Finally, if the level of corruption is known to be small, we show that using the geometric median of mean oracle for robust aggregation further improves the regret bound.

</p>
</details>

<details><summary><b>Proceedings of TDA: Applications of Topological Data Analysis to Data Science, Artificial Intelligence, and Machine Learning Workshop at SDM 2022</b>
<a href="https://arxiv.org/abs/2204.01142">arxiv:2204.01142</a>
&#x1F4C8; 4 <br>
<p>R. W. R. Darling, John A. Emanuello, Emilie Purvine, Ahmad Ridley</p></summary>
<p>

**Abstract:** Topological Data Analysis (TDA) is a rigorous framework that borrows techniques from geometric and algebraic topology, category theory, and combinatorics in order to study the "shape" of such complex high-dimensional data. Research in this area has grown significantly over the last several years bringing a deeply rooted theory to bear on practical applications in areas such as genomics, natural language processing, medicine, cybersecurity, energy, and climate change. Within some of these areas, TDA has also been used to augment AI and ML techniques.
  We believe there is further utility to be gained in this space that can be facilitated by a workshop bringing together experts (both theorists and practitioners) and non-experts. Currently there is an active community of pure mathematicians with research interests in developing and exploring the theoretical and computational aspects of TDA. Applied mathematicians and other practitioners are also present in community but do not represent a majority. This speaks to the primary aim of this workshop which is to grow a wider community of interest in TDA. By fostering meaningful exchanges between these groups, from across the government, academia, and industry, we hope to create new synergies that can only come through building a mutual comprehensive awareness of the problem and solution spaces.

</p>
</details>

<details><summary><b>Forward Signal Propagation Learning</b>
<a href="https://arxiv.org/abs/2204.01723">arxiv:2204.01723</a>
&#x1F4C8; 3 <br>
<p>Adam Kohan, Edward A. Rietman, Hava T. Siegelmann</p></summary>
<p>

**Abstract:** We propose a new learning algorithm for propagating a learning signal and updating neural network parameters via a forward pass, as an alternative to backpropagation. In forward signal propagation learning (sigprop), there is only the forward path for learning and inference, so there are no additional structural or computational constraints on learning, such as feedback connectivity, weight transport, or a backward pass, which exist under backpropagation. Sigprop enables global supervised learning with only a forward path. This is ideal for parallel training of layers or modules. In biology, this explains how neurons without feedback connections can still receive a global learning signal. In hardware, this provides an approach for global supervised learning without backward connectivity. Sigprop by design has better compatibility with models of learning in the brain and in hardware than backpropagation and alternative approaches to relaxing learning constraints. We also demonstrate that sigprop is more efficient in time and memory than they are. To further explain the behavior of sigprop, we provide evidence that sigprop provides useful learning signals in context to backpropagation. To further support relevance to biological and hardware learning, we use sigprop to train continuous time neural networks with Hebbian updates and train spiking neural networks without surrogate functions.

</p>
</details>

<details><summary><b>RestoreX-AI: A Contrastive Approach towards Guiding Image Restoration via Explainable AI Systems</b>
<a href="https://arxiv.org/abs/2204.01719">arxiv:2204.01719</a>
&#x1F4C8; 3 <br>
<p>Aboli Marathe, Pushkar Jain, Rahee Walambe, Ketan Kotecha</p></summary>
<p>

**Abstract:** Modern applications such as self-driving cars and drones rely heavily upon robust object detection techniques. However, weather corruptions can hinder the object detectability and pose a serious threat to their navigation and reliability. Thus, there is a need for efficient denoising, deraining, and restoration techniques. Generative adversarial networks and transformers have been widely adopted for image restoration. However, the training of these methods is often unstable and time-consuming. Furthermore, when used for object detection (OD), the output images generated by these methods may provide unsatisfactory results despite image clarity. In this work, we propose a contrastive approach towards mitigating this problem, by evaluating images generated by restoration models during and post training. This approach leverages OD scores combined with attention maps for predicting the usefulness of restored images for the OD task. We conduct experiments using two novel use-cases of conditional GANs and two transformer methods that probe the robustness of the proposed approach on multi-weather corruptions in the OD task. Our approach achieves an averaged 178 percent increase in mAP between the input and restored images under adverse weather conditions like dust tornadoes and snowfall. We report unique cases where greater denoising does not improve OD performance and conversely where noisy generated images demonstrate good results. We conclude the need for explainability frameworks to bridge the gap between human and machine perception, especially in the context of robust object detection for autonomous vehicles.

</p>
</details>

<details><summary><b>Analysis of Joint Speech-Text Embeddings for Semantic Matching</b>
<a href="https://arxiv.org/abs/2204.01235">arxiv:2204.01235</a>
&#x1F4C8; 3 <br>
<p>Muhammad Huzaifah, Ivan Kukanov</p></summary>
<p>

**Abstract:** Embeddings play an important role in many recent end-to-end solutions for language processing problems involving more than one data modality. Although there has been some effort to understand the properties of single-modality embedding spaces, particularly that of text, their cross-modal counterparts are less understood. In this work, we study a joint speech-text embedding space trained for semantic matching by minimizing the distance between paired utterance and transcription inputs. This was done through dual encoders in a teacher-student model setup, with a pretrained language model acting as the teacher and a transformer-based speech encoder as the student. We extend our method to incorporate automatic speech recognition through both pretraining and multitask scenarios and found that both approaches improve semantic matching. Multiple techniques were utilized to analyze and evaluate cross-modal semantic alignment of the embeddings: a quantitative retrieval accuracy metric, zero-shot classification to investigate generalizability, and probing of the encoders to observe the extent of knowledge transfer from one modality to another.

</p>
</details>

<details><summary><b>Capturing positive utilities during the estimation of recursive logit models: A prism-based approach</b>
<a href="https://arxiv.org/abs/2204.01215">arxiv:2204.01215</a>
&#x1F4C8; 3 <br>
<p>Yuki Oyama</p></summary>
<p>

**Abstract:** Although the recursive logit (RL) model has been recently popular and has led to many applications and extensions, an important numerical issue with respect to the evaluation of value functions remains unsolved. This issue is particularly significant for model estimation, during which the parameters are updated every iteration and may violate the model feasible condition. To solve this numerical issue, this paper proposes a prism-constrained RL (Prism-RL) model that implicitly restricts the path set by the prism constraint defined based upon a state-extended network representation. Providing a set of numerical experiments, we show that the Prism-RL model succeeds in the stable estimation regardless of the initial and true parameter values and is able to capture positive utilities. In the real application to a pedestrian network, we found the positive effect of street green presence on pedestrians. Moreover, the Prism-RL model achieved higher goodness of fit than the RL model, implying that the Prism-RL model can also describe more realistic route choice behavior.

</p>
</details>

<details><summary><b>Learning Linear Symmetries in Data Using Moment Matching</b>
<a href="https://arxiv.org/abs/2204.01213">arxiv:2204.01213</a>
&#x1F4C8; 3 <br>
<p>Colin Hagemeyer</p></summary>
<p>

**Abstract:** It is common in machine learning and statistics to use symmetries derived from expert knowledge to simplify problems or improve performance, using methods like data augmentation or penalties. In this paper we consider the unsupervised and semi-supervised problems of learning such symmetries in a distribution directly from data in a model-free fashion. We show that in the worst case this problem is as difficult as the graph automorphism problem. However, if we restrict to the case where the covariance matrix has unique eigenvalues, then the eigenvectors will also be eigenvectors of the symmetry transformation. If we further restrict to finding orthogonal symmetries, then the eigenvalues will be either be 1 or -1, and the problem reduces to determining which eigenvectors are which. We develop and compare theoretically and empirically the effectiveness of different methods of selecting which eigenvectors should have eigenvalue -1 in the symmetry transformation, and discuss how to extend this approach to non-orthogonal cases where we have labels

</p>
</details>

<details><summary><b>A Novel Mask R-CNN Model to Segment Heterogeneous Brain Tumors through Image Subtraction</b>
<a href="https://arxiv.org/abs/2204.01201">arxiv:2204.01201</a>
&#x1F4C8; 3 <br>
<p>Sanskriti Singh</p></summary>
<p>

**Abstract:** The segmentation of diseases is a popular topic explored by researchers in the field of machine learning. Brain tumors are extremely dangerous and require the utmost precision to segment for a successful surgery. Patients with tumors usually take 4 MRI scans, T1, T1gd, T2, and FLAIR, which are then sent to radiologists to segment and analyze for possible future surgery. To create a second segmentation, it would be beneficial to both radiologists and patients in being more confident in their conclusions. We propose using a method performed by radiologists called image segmentation and applying it to machine learning models to prove a better segmentation. Using Mask R-CNN, its ResNet backbone being pre-trained on the RSNA pneumonia detection challenge dataset, we can train a model on the Brats2020 Brain Tumor dataset. Center for Biomedical Image Computing & Analytics provides MRI data on patients with and without brain tumors and the corresponding segmentations. We can see how well the method of image subtraction works by comparing it to models without image subtraction through DICE coefficient (F1 score), recall, and precision on the untouched test set. Our model performed with a DICE coefficient of 0.75 in comparison to 0.69 without image subtraction. To further emphasize the usefulness of image subtraction, we compare our final model to current state-of-the-art models to segment tumors from MRI scans.

</p>
</details>

<details><summary><b>Why Exposure Bias Matters: An Imitation Learning Perspective of Error Accumulation in Language Generation</b>
<a href="https://arxiv.org/abs/2204.01171">arxiv:2204.01171</a>
&#x1F4C8; 3 <br>
<p>Kushal Arora, Layla El Asri, Hareesh Bahuleyan, Jackie Chi Kit Cheung</p></summary>
<p>

**Abstract:** Current language generation models suffer from issues such as repetition, incoherence, and hallucinations. An often-repeated hypothesis is that this brittleness of generation models is caused by the training and the generation procedure mismatch, also referred to as exposure bias. In this paper, we verify this hypothesis by analyzing exposure bias from an imitation learning perspective. We show that exposure bias leads to an accumulation of errors, analyze why perplexity fails to capture this accumulation, and empirically show that this accumulation results in poor generation quality. Source code to reproduce these experiments is available at https://github.com/kushalarora/quantifying_exposure_bias

</p>
</details>

<details><summary><b>Fitting an immersed submanifold to data via Sussmann's orbit theorem</b>
<a href="https://arxiv.org/abs/2204.01119">arxiv:2204.01119</a>
&#x1F4C8; 3 <br>
<p>Joshua Hanson, Maxim Raginsky</p></summary>
<p>

**Abstract:** This paper describes an approach for fitting an immersed submanifold of a finite-dimensional Euclidean space to random samples. The reconstruction mapping from the ambient space to the desired submanifold is implemented as a composition of an encoder that maps each point to a tuple of (positive or negative) times and a decoder given by a composition of flows along finitely many vector fields starting from a fixed initial point. The encoder supplies the times for the flows. The encoder-decoder map is obtained by empirical risk minimization, and a high-probability bound is given on the excess risk relative to the minimum expected reconstruction error over a given class of encoder-decoder maps. The proposed approach makes fundamental use of Sussmann's orbit theorem, which guarantees that the image of the reconstruction map is indeed contained in an immersed submanifold.

</p>
</details>

<details><summary><b>Adversarially robust segmentation models learn perceptually-aligned gradients</b>
<a href="https://arxiv.org/abs/2204.01099">arxiv:2204.01099</a>
&#x1F4C8; 3 <br>
<p>Pedro Sandoval-Segura</p></summary>
<p>

**Abstract:** The effects of adversarial training on semantic segmentation networks has not been thoroughly explored. While previous work has shown that adversarially-trained image classifiers can be used to perform image synthesis, we have yet to understand how best to leverage an adversarially-trained segmentation network to do the same. Using a simple optimizer, we demonstrate that adversarially-trained semantic segmentation networks can be used to perform image inpainting and generation. Our experiments demonstrate that adversarially-trained segmentation networks are more robust and indeed exhibit perceptually-aligned gradients which help in producing plausible image inpaintings. We seek to place additional weight behind the hypothesis that adversarially robust models exhibit gradients that are more perceptually-aligned with human vision. Through image synthesis, we argue that perceptually-aligned gradients promote a better understanding of a neural network's learned representations and aid in making neural networks more interpretable.

</p>
</details>

<details><summary><b>A sequence-to-sequence approach for document-level relation extraction</b>
<a href="https://arxiv.org/abs/2204.01098">arxiv:2204.01098</a>
&#x1F4C8; 3 <br>
<p>John Giorgi, Gary D. Bader, Bo Wang</p></summary>
<p>

**Abstract:** Motivated by the fact that many relations cross the sentence boundary, there has been increasing interest in document-level relation extraction (DocRE). DocRE requires integrating information within and across sentences, capturing complex interactions between mentions of entities. Most existing methods are pipeline-based, requiring entities as input. However, jointly learning to extract entities and relations can improve performance and be more efficient due to shared parameters and training steps. In this paper, we develop a sequence-to-sequence approach, seq2rel, that can learn the subtasks of DocRE (entity extraction, coreference resolution and relation extraction) end-to-end, replacing a pipeline of task-specific components. Using a simple strategy we call entity hinting, we compare our approach to existing pipeline-based methods on several popular biomedical datasets, in some cases exceeding their performance. We also report the first end-to-end results on these datasets for future comparison. Finally, we demonstrate that, under our model, an end-to-end approach outperforms a pipeline-based approach. Our code, data and trained models are available at {\url{https://github.com/johngiorgi/seq2rel}}. An online demo is available at {\url{https://share.streamlit.io/johngiorgi/seq2rel/main/demo.py}}.

</p>
</details>

<details><summary><b>Faces: AI Blitz XIII Solutions</b>
<a href="https://arxiv.org/abs/2204.01081">arxiv:2204.01081</a>
&#x1F4C8; 3 <br>
<p>Andrew Melnik, Eren Akbulut, Jannik Sheikh, Kira Loos, Michael Buettner, Tobias Lenze</p></summary>
<p>

**Abstract:** AI Blitz XIII Faces challenge hosted on www.aicrowd.com platform consisted of five problems: Sentiment Classification, Age Prediction, Mask Prediction, Face Recognition, and Face De-Blurring. Our team GLaDOS took second place. Here we present our solutions and results. Code implementation: https://github.com/ndrwmlnk/ai-blitz-xiii

</p>
</details>

<details><summary><b>Correlation Functions in Random Fully Connected Neural Networks at Finite Width</b>
<a href="https://arxiv.org/abs/2204.01058">arxiv:2204.01058</a>
&#x1F4C8; 3 <br>
<p>Boris Hanin</p></summary>
<p>

**Abstract:** This article considers fully connected neural networks with Gaussian random weights and biases and $L$ hidden layers, each of width proportional to a large parameter $n$. For polynomially bounded non-linearities we give sharp estimates in powers of $1/n$ for the joint correlation functions of the network output and its derivatives. Moreover, we obtain exact layerwise recursions for these correlation functions and solve a number of special cases for classes of non-linearities including $\mathrm{ReLU}$ and $\tanh$. We find in both cases that the depth-to-width ratio $L/n$ plays the role of an effective network depth, controlling both the scale of fluctuations at individual neurons and the size of inter-neuron correlations. We use this to study a somewhat simplified version of the so-called exploding and vanishing gradient problem, proving that this particular variant occurs if and only if $L/n$ is large. Several of the key ideas in this article were first developed at a physics level of rigor in a recent monograph with Roberts and Yaida.

</p>
</details>

<details><summary><b>Selective Kernel Attention for Robust Speaker Verification</b>
<a href="https://arxiv.org/abs/2204.01005">arxiv:2204.01005</a>
&#x1F4C8; 3 <br>
<p>Sung Hwan Mun, Jee-weon Jung, Nam Soo Kim</p></summary>
<p>

**Abstract:** Recent state-of-the-art speaker verification architectures adopt multi-scale processing and frequency-channel attention techniques. However, their full potential may not have been exploited because these techniques' receptive fields are fixed where most convolutional layers operate with specified kernel sizes such as 1, 3 or 5. We aim to further improve this line of research by introducing a selective kernel attention (SKA) mechanism. The SKA mechanism allows each convolutional layer to adaptively select the kernel size in a data-driven fashion based on an attention mechanism that exploits both frequency and channel domain using the previous layer's output. We propose three module variants using the SKA mechanism whereby two modules are applied in front of an ECAPA-TDNN model, and the other is combined with the Res2Net backbone block. Experimental results demonstrate that our proposed model consistently outperforms the conventional counterpart on the three different evaluation protocols in terms of both equal error rate and minimum detection cost function. In addition, we present a detailed analysis that helps understand how the SKA module works.

</p>
</details>

<details><summary><b>Bi-fidelity Modeling of Uncertain and Partially Unknown Systems using DeepONets</b>
<a href="https://arxiv.org/abs/2204.00997">arxiv:2204.00997</a>
&#x1F4C8; 3 <br>
<p>Subhayan De, Malik Hassanaly, Matthew Reynolds, Ryan N. King, Alireza Doostan</p></summary>
<p>

**Abstract:** Recent advances in modeling large-scale complex physical systems have shifted research focuses towards data-driven techniques. However, generating datasets by simulating complex systems can require significant computational resources. Similarly, acquiring experimental datasets can prove difficult as well. For these systems, often computationally inexpensive, but in general inaccurate, models, known as the low-fidelity models, are available. In this paper, we propose a bi-fidelity modeling approach for complex physical systems, where we model the discrepancy between the true system's response and low-fidelity response in the presence of a small training dataset from the true system's response using a deep operator network (DeepONet), a neural network architecture suitable for approximating nonlinear operators. We apply the approach to model systems that have parametric uncertainty and are partially unknown. Three numerical examples are used to show the efficacy of the proposed approach to model uncertain and partially unknown complex physical systems.

</p>
</details>

<details><summary><b>Continuous Variable Quantum MNIST Classifiers</b>
<a href="https://arxiv.org/abs/2204.01194">arxiv:2204.01194</a>
&#x1F4C8; 2 <br>
<p>Sophie Choe</p></summary>
<p>

**Abstract:** In this paper, classical and continuous variable (CV) quantum neural network hybrid multiclassifiers are presented using the MNIST dataset. The combination of cutoff dimension and probability measurement method in the CV model allows a quantum circuit to produce output vectors of size equal to n raised to the power of n where n represents cutoff dimension and m, the number of qumodes. They are then translated as one-hot encoded labels, padded with an appropriate number of zeros. The total of eight different classifiers are built using 2,3,...,8 qumodes, based on the binary classifier architecture proposed in Continuous variable quantum neural networks. The displacement gate and the Kerr gate in the CV model allow for the bias addition and nonlinear activation components of classical neural networks to quantum. The classifiers are composed of a classical feedforward neural network, a quantum data encoding circuit, and a CV quantum neural network circuit. On a truncated MNIST dataset of 600 samples, a 4 qumode hybrid classifier achieves 100% training accuracy.

</p>
</details>

<details><summary><b>Few Shot Protein Generation</b>
<a href="https://arxiv.org/abs/2204.01168">arxiv:2204.01168</a>
&#x1F4C8; 2 <br>
<p>Soumya Ram, Tristan Bepler</p></summary>
<p>

**Abstract:** We present the MSA-to-protein transformer, a generative model of protein sequences conditioned on protein families represented by multiple sequence alignments (MSAs). Unlike existing approaches to learning generative models of protein families, the MSA-to-protein transformer conditions sequence generation directly on a learned encoding of the multiple sequence alignment, circumventing the need for fitting dedicated family models. By training on a large set of well-curated multiple sequence alignments in Pfam, our MSA-to-protein transformer generalizes well to protein families not observed during training and outperforms conventional family modeling approaches, especially when MSAs are small. Our generative approach accurately models epistasis and indels and allows for exact inference and efficient sampling unlike other approaches. We demonstrate the protein sequence modeling capabilities of our MSA-to-protein transformer and compare it with alternative sequence modeling approaches in comprehensive benchmark experiments.

</p>
</details>

<details><summary><b>Best-Response Bayesian Reinforcement Learning with Bayes-adaptive POMDPs for Centaurs</b>
<a href="https://arxiv.org/abs/2204.01160">arxiv:2204.01160</a>
&#x1F4C8; 2 <br>
<p>Mustafa Mert Ã‡elikok, Frans A. Oliehoek, Samuel Kaski</p></summary>
<p>

**Abstract:** Centaurs are half-human, half-AI decision-makers where the AI's goal is to complement the human. To do so, the AI must be able to recognize the goals and constraints of the human and have the means to help them. We present a novel formulation of the interaction between the human and the AI as a sequential game where the agents are modelled using Bayesian best-response models. We show that in this case the AI's problem of helping bounded-rational humans make better decisions reduces to a Bayes-adaptive POMDP. In our simulated experiments, we consider an instantiation of our framework for humans who are subjectively optimistic about the AI's future behaviour. Our results show that when equipped with a model of the human, the AI can infer the human's bounds and nudge them towards better decisions. We discuss ways in which the machine can learn to improve upon its own limitations as well with the help of the human. We identify a novel trade-off for centaurs in partially observable tasks: for the AI's actions to be acceptable to the human, the machine must make sure their beliefs are sufficiently aligned, but aligning beliefs might be costly. We present a preliminary theoretical analysis of this trade-off and its dependence on task structure.

</p>
</details>

<details><summary><b>Task2Dial: A Novel Task and Dataset for Commonsense enhanced Task-based Dialogue Grounded in Documents</b>
<a href="https://arxiv.org/abs/2204.01061">arxiv:2204.01061</a>
&#x1F4C8; 2 <br>
<p>Carl Strathearn, Dimitra Gkatzia</p></summary>
<p>

**Abstract:** This paper proposes a novel task on commonsense-enhanced task-based dialogue grounded in documents and describes the Task2Dial dataset, a novel dataset of document-grounded task-based dialogues, where an Information Giver (IG) provides instructions (by consulting a document) to an Information Follower (IF), so that the latter can successfully complete the task. In this unique setting, the IF can ask clarification questions which may not be grounded in the underlying document and require commonsense knowledge to be answered. The Task2Dial dataset poses new challenges: (1) its human reference texts show more lexical richness and variation than other document-grounded dialogue datasets; (2) generating from this set requires paraphrasing as instructional responses might have been modified from the underlying document; (3) requires commonsense knowledge, since questions might not necessarily be grounded in the document; (4) generating requires planning based on context, as task steps need to be provided in order. The Task2Dial dataset contains dialogues with an average $18.15$ number of turns and 19.79 tokens per turn, as compared to 12.94 and 12 respectively in existing datasets. As such, learning from this dataset promises more natural, varied and less template-like system utterances.

</p>
</details>

<details><summary><b>Learning-Based Approaches for Graph Problems: A Survey</b>
<a href="https://arxiv.org/abs/2204.01057">arxiv:2204.01057</a>
&#x1F4C8; 2 <br>
<p>Kai Siong Yow, Siqiang Luo</p></summary>
<p>

**Abstract:** Over the years, many graph problems specifically those in NP-complete are studied by a wide range of researchers. Some famous examples include graph colouring, travelling salesman problem and subgraph isomorphism. Most of these problems are typically addressed by exact algorithms, approximate algorithms and heuristics. There are however some drawback for each of these methods. Recent studies have employed learning-based frameworks such as machine learning techniques in solving these problems, given that they are useful in discovering new patterns in structured data that can be represented using graphs. This research direction has successfully attracted a considerable amount of attention. In this survey, we provide a systematic review mainly on classic graph problems in which learning-based approaches have been proposed in addressing the problems. We discuss the overview of each framework, and provide analyses based on the design and performance of the framework. Some potential research questions are also suggested. Ultimately, this survey gives a clearer insight and can be used as a stepping stone to the research community in studying problems in this field.

</p>
</details>

<details><summary><b>On Efficiently Acquiring Annotations for Multilingual Models</b>
<a href="https://arxiv.org/abs/2204.01016">arxiv:2204.01016</a>
&#x1F4C8; 2 <br>
<p>Joel Ruben Antony Moniz, Barun Patra, Matthew R. Gormley</p></summary>
<p>

**Abstract:** When tasked with supporting multiple languages for a given problem, two approaches have arisen: training a model for each language with the annotation budget divided equally among them, and training on a high-resource language followed by zero-shot transfer to the remaining languages. In this work, we show that the strategy of joint learning across multiple languages using a single model performs substantially better than the aforementioned alternatives. We also demonstrate that active learning provides additional, complementary benefits. We show that this simple approach enables the model to be data efficient by allowing it to arbitrate its annotation budget to query languages it is less certain on. We illustrate the effectiveness of our proposed method on a diverse set of tasks: a classification task with 4 languages, a sequence tagging task with 4 languages and a dependency parsing task with 5 languages. Our proposed method, whilst simple, substantially outperforms the other viable alternatives for building a model in a multilingual setting under constrained budgets.

</p>
</details>

<details><summary><b>Gastrointestinal Polyps and Tumors Detection Based on Multi-scale Feature-fusion with WCE Sequences</b>
<a href="https://arxiv.org/abs/2204.01012">arxiv:2204.01012</a>
&#x1F4C8; 2 <br>
<p>Zhuo Falin, Liu Haihua, Pan Ning</p></summary>
<p>

**Abstract:** Wireless Capsule Endoscopy(WCE) has been widely used for the screening of gastrointestinal(GI) diseases, especially the small intestine, due to its advantages of non-invasive and painless imaging of the entire digestive tract.However, the huge amount of image data captured by WCE makes manual reading a process that requires a huge amount of tasks and can easily lead to missed detection and false detection of lesions.Therefore, In this paper, we propose a \textbf{T}wo-stage \textbf{M}ulti-scale \textbf{F}eature-fusion learning network(\textbf{TMFNet}) to automatically detect small intestinal polyps and tumors in WCE image sequences. Specifically, TMFNet consists of lesion detection network and lesion identification network. Among them, the former improves the feature extraction module and detection module based on the traditional Faster R-CNN network, and readjusts the parameters of the anchor in the region proposal network(RPN) module;the latter combines residual structure and feature pyramid structure are used to build a small intestinal lesion recognition network based on feature fusion, for reducing the false positive rate of the former and improve the overall accuracy.We used 22,335 WCE images in the experiment, with a total of 123,092 lesion regions used to train the detection framework of this paper. In the experiment, the detection framework is trained and tested on the real WCE image dataset provided by the hospital gastroenterology department. The sensitivity, false positive and accuracy of the final model on the RPM are 98.81$\%$, 7.43$\%$ and 92.57$\%$, respectively.Meanwhile,the corresponding results on the lesion images were 98.75$\%$, 5.62$\%$ and 94.39$\%$. The algorithm model proposed in this paper is obviously superior to other detection algorithms in detection effect and performance

</p>
</details>

<details><summary><b>A Computational Analysis of Pitch Drift in Unaccompanied Solo Singing using DBSCAN Clustering</b>
<a href="https://arxiv.org/abs/2204.01009">arxiv:2204.01009</a>
&#x1F4C8; 2 <br>
<p>Sepideh Shafiei, S. Hakam</p></summary>
<p>

**Abstract:** Unaccompanied vocalists usually change the tuning unintentionally and end up with a higher or lower pitch than the starting point during a long performance. This phenomenon is called pitch drift, which is dependent on various elements, such as the skill of the performer, and the length and difficulty of the performance. In this paper, we propose a computational method for measuring pitch drift in the course of an unaccompanied vocal performance, using pitch histogram and DBSCAN clustering.

</p>
</details>

<details><summary><b>AutoOpt: A Methodological Framework of Automatically Designing Metaheuristics for Optimization Problems</b>
<a href="https://arxiv.org/abs/2204.00998">arxiv:2204.00998</a>
&#x1F4C8; 2 <br>
<p>Qi Zhao, Bai Yan, Yuhui Shi</p></summary>
<p>

**Abstract:** Metaheuristics are gradient-free and problem-independent search algorithms. They have gained huge success in solving various optimization problems in academia and industry. Automated metaheuristic design is a promising alternative to human-made design. This paper proposes a general and comprehensive methodological framework, AutoOpt, for automatically designing metaheuristics for various optimization problems. AutoOpt consists of: (1) a bi-level criterion to evaluate the designed algorithms' performance; (2) a general schema of the decision space from where the algorithms will be designed; (3) a mixed graph- and real number-based representation to represent the designed algorithms; and (4) a model-free method to conduct the design process. AutoOpt benefits academic researchers and practical users struggling to design metaheuristics for optimization problems. A real-world case study demonstrates AutoOpt's effectiveness and efficiency.

</p>
</details>

<details><summary><b>Explicit and Implicit Pattern Relation Analysis for Discovering Actionable Negative Sequences</b>
<a href="https://arxiv.org/abs/2204.03571">arxiv:2204.03571</a>
&#x1F4C8; 1 <br>
<p>Wei Wang, Longbing Cao</p></summary>
<p>

**Abstract:** Real-life events, behaviors and interactions produce sequential data. An important but rarely explored problem is to analyze those nonoccurring (also called negative) yet important sequences, forming negative sequence analysis (NSA). A typical NSA area is to discover negative sequential patterns (NSPs) consisting of important non-occurring and occurring elements and patterns. The limited existing work on NSP mining relies on frequentist and downward closure property-based pattern selection, producing large and highly redundant NSPs, nonactionable for business decision-making. This work makes the first attempt for actionable NSP discovery. It builds an NSP graph representation, quantify both explicit occurrence and implicit non-occurrence-based element and pattern relations, and then discover significant, diverse and informative NSPs in the NSP graph to represent the entire NSP set for discovering actionable NSPs. A DPP-based NSP representation and actionable NSP discovery method EINSP introduces novel and significant contributions for NSA and sequence analysis: (1) it represents NSPs by a determinantal point process (DPP) based graph; (2) it quantifies actionable NSPs in terms of their statistical significance, diversity, and strength of explicit/implicit element/pattern relations; and (3) it models and measures both explicit and implicit element/pattern relations in the DPP-based NSP graph to represent direct and indirect couplings between NSP items, elements and patterns. We substantially analyze the effectiveness of EINSP in terms of various theoretical and empirical aspects including complexity, item/pattern coverage, pattern size and diversity, implicit pattern relation strength, and data factors.

</p>
</details>

<details><summary><b>A System for Interactive Examination of Learned Security Policies</b>
<a href="https://arxiv.org/abs/2204.01126">arxiv:2204.01126</a>
&#x1F4C8; 1 <br>
<p>Kim Hammar, Rolf Stadler</p></summary>
<p>

**Abstract:** We present a system for interactive examination of learned security policies. It allows a user to traverse episodes of Markov decision processes in a controlled manner and to track the actions triggered by security policies. Similar to a software debugger, a user can continue or or halt an episode at any time step and inspect parameters and probability distributions of interest. The system enables insight into the structure of a given policy and in the behavior of a policy in edge cases. We demonstrate the system with a network intrusion use case. We examine the evolution of an IT infrastructure's state and the actions prescribed by security policies while an attack occurs. The policies for the demonstration have been obtained through a reinforcement learning approach that includes a simulation system where policies are incrementally learned and an emulation system that produces statistics that drive the simulation runs.

</p>
</details>

<details><summary><b>A Differentially Private Framework for Deep Learning with Convexified Loss Functions</b>
<a href="https://arxiv.org/abs/2204.01049">arxiv:2204.01049</a>
&#x1F4C8; 1 <br>
<p>Zhigang Lu, Hassan Jameel Asghar, Mohamed Ali Kaafar, Darren Webb, Peter Dickinson</p></summary>
<p>

**Abstract:** Differential privacy (DP) has been applied in deep learning for preserving privacy of the underlying training sets. Existing DP practice falls into three categories - objective perturbation, gradient perturbation and output perturbation. They suffer from three main problems. First, conditions on objective functions limit objective perturbation in general deep learning tasks. Second, gradient perturbation does not achieve a satisfactory privacy-utility trade-off due to over-injected noise in each epoch. Third, high utility of the output perturbation method is not guaranteed because of the loose upper bound on the global sensitivity of the trained model parameters as the noise scale parameter. To address these problems, we analyse a tighter upper bound on the global sensitivity of the model parameters. Under a black-box setting, based on this global sensitivity, to control the overall noise injection, we propose a novel output perturbation framework by injecting DP noise into a randomly sampled neuron (via the exponential mechanism) at the output layer of a baseline non-private neural network trained with a convexified loss function. We empirically compare the privacy-utility trade-off, measured by accuracy loss to baseline non-private models and the privacy leakage against black-box membership inference (MI) attacks, between our framework and the open-source differentially private stochastic gradient descent (DP-SGD) approaches on six commonly used real-world datasets. The experimental evaluations show that, when the baseline models have observable privacy leakage under MI attacks, our framework achieves a better privacy-utility trade-off than existing DP-SGD implementations, given an overall privacy budget $Îµ\leq 1$ for a large number of queries.

</p>
</details>


{% endraw %}
Prev: [2022.04.02]({{ '/2022/04/02/2022.04.02.html' | relative_url }})  Next: [2022.04.04]({{ '/2022/04/04/2022.04.04.html' | relative_url }})