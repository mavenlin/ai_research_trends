## Summary for 2021-07-21, created on 2021-12-19


<details><summary><b>HistoCartography: A Toolkit for Graph Analytics in Digital Pathology</b>
<a href="https://arxiv.org/abs/2107.10073">arxiv:2107.10073</a>
&#x1F4C8; 78 <br>
<p>Guillaume Jaume, Pushpak Pati, Valentin Anklin, Antonio Foncubierta, Maria Gabrani</p></summary>
<p>

**Abstract:** Advances in entity-graph based analysis of histopathology images have brought in a new paradigm to describe tissue composition, and learn the tissue structure-to-function relationship. Entity-graphs offer flexible and scalable representations to characterize tissue organization, while allowing the incorporation of prior pathological knowledge to further support model interpretability and explainability. However, entity-graph analysis requires prerequisites for image-to-graph translation and knowledge of state-of-the-art machine learning algorithms applied to graph-structured data, which can potentially hinder their adoption. In this work, we aim to alleviate these issues by developing HistoCartography, a standardized python API with necessary preprocessing, machine learning and explainability tools to facilitate graph-analytics in computational pathology. Further, we have benchmarked the computational time and performance on multiple datasets across different imaging types and histopathology tasks to highlight the applicability of the API for building computational pathology workflows.

</p>
</details>

<details><summary><b>Neural Fixed-Point Acceleration for Convex Optimization</b>
<a href="https://arxiv.org/abs/2107.10254">arxiv:2107.10254</a>
&#x1F4C8; 25 <br>
<p>Shobha Venkataraman, Brandon Amos</p></summary>
<p>

**Abstract:** Fixed-point iterations are at the heart of numerical computing and are often a computational bottleneck in real-time applications that typically need a fast solution of moderate accuracy. We present neural fixed-point acceleration which combines ideas from meta-learning and classical acceleration methods to automatically learn to accelerate fixed-point problems that are drawn from a distribution. We apply our framework to SCS, the state-of-the-art solver for convex cone programming, and design models and loss functions to overcome the challenges of learning over unrolled optimization and acceleration instabilities. Our work brings neural acceleration into any optimization problem expressible with CVXPY. The source code behind this paper is available at https://github.com/facebookresearch/neural-scs

</p>
</details>

<details><summary><b>StarGANv2-VC: A Diverse, Unsupervised, Non-parallel Framework for Natural-Sounding Voice Conversion</b>
<a href="https://arxiv.org/abs/2107.10394">arxiv:2107.10394</a>
&#x1F4C8; 13 <br>
<p>Yinghao Aaron Li, Ali Zare, Nima Mesgarani</p></summary>
<p>

**Abstract:** We present an unsupervised non-parallel many-to-many voice conversion (VC) method using a generative adversarial network (GAN) called StarGAN v2. Using a combination of adversarial source classifier loss and perceptual loss, our model significantly outperforms previous VC models. Although our model is trained only with 20 English speakers, it generalizes to a variety of voice conversion tasks, such as any-to-many, cross-lingual, and singing conversion. Using a style encoder, our framework can also convert plain reading speech into stylistic speech, such as emotional and falsetto speech. Subjective and objective evaluation experiments on a non-parallel many-to-many voice conversion task revealed that our model produces natural sounding voices, close to the sound quality of state-of-the-art text-to-speech (TTS) based voice conversion methods without the need for text labels. Moreover, our model is completely convolutional and with a faster-than-real-time vocoder such as Parallel WaveGAN can perform real-time voice conversion.

</p>
</details>

<details><summary><b>Learning a Large Neighborhood Search Algorithm for Mixed Integer Programs</b>
<a href="https://arxiv.org/abs/2107.10201">arxiv:2107.10201</a>
&#x1F4C8; 13 <br>
<p>Nicolas Sonnerat, Pengming Wang, Ira Ktena, Sergey Bartunov, Vinod Nair</p></summary>
<p>

**Abstract:** Large Neighborhood Search (LNS) is a combinatorial optimization heuristic that starts with an assignment of values for the variables to be optimized, and iteratively improves it by searching a large neighborhood around the current assignment. In this paper we consider a learning-based LNS approach for mixed integer programs (MIPs). We train a Neural Diving model to represent a probability distribution over assignments, which, together with an off-the-shelf MIP solver, generates an initial assignment. Formulating the subsequent search steps as a Markov Decision Process, we train a Neural Neighborhood Selection policy to select a search neighborhood at each step, which is searched using a MIP solver to find the next assignment. The policy network is trained using imitation learning. We propose a target policy for imitation that, given enough compute resources, is guaranteed to select the neighborhood containing the optimal next assignment amongst all possible choices for the neighborhood of a specified size. Our approach matches or outperforms all the baselines on five real-world MIP datasets with large-scale instances from diverse applications, including two production applications at Google. It achieves $2\times$ to $37.8\times$ better average primal gap than the best baseline on three of the datasets at large running times.

</p>
</details>

<details><summary><b>CL4AC: A Contrastive Loss for Audio Captioning</b>
<a href="https://arxiv.org/abs/2107.09990">arxiv:2107.09990</a>
&#x1F4C8; 13 <br>
<p>Xubo Liu, Qiushi Huang, Xinhao Mei, Tom Ko, H Lilian Tang, Mark D. Plumbley, Wenwu Wang</p></summary>
<p>

**Abstract:** Automated Audio captioning (AAC) is a cross-modal translation task that aims to use natural language to describe the content of an audio clip. As shown in the submissions received for Task 6 of the DCASE 2021 Challenges, this problem has received increasing interest in the community. The existing AAC systems are usually based on an encoder-decoder architecture, where the audio signal is encoded into a latent representation, and aligned with its corresponding text descriptions, then a decoder is used to generate the captions. However, training of an AAC system often encounters the problem of data scarcity, which may lead to inaccurate representation and audio-text alignment. To address this problem, we propose a novel encoder-decoder framework called Contrastive Loss for Audio Captioning (CL4AC). In CL4AC, the self-supervision signals derived from the original audio-text paired data are used to exploit the correspondences between audio and texts by contrasting samples, which can improve the quality of latent representation and the alignment between audio and texts, while trained with limited data. Experiments are performed on the Clotho dataset to show the effectiveness of our proposed approach.

</p>
</details>

<details><summary><b>Digital Einstein Experience: Fast Text-to-Speech for Conversational AI</b>
<a href="https://arxiv.org/abs/2107.10658">arxiv:2107.10658</a>
&#x1F4C8; 9 <br>
<p>Joanna Rownicka, Kilian Sprenkamp, Antonio Tripiana, Volodymyr Gromoglasov, Timo P Kunz</p></summary>
<p>

**Abstract:** We describe our approach to create and deliver a custom voice for a conversational AI use-case. More specifically, we provide a voice for a Digital Einstein character, to enable human-computer interaction within the digital conversation experience. To create the voice which fits the context well, we first design a voice character and we produce the recordings which correspond to the desired speech attributes. We then model the voice. Our solution utilizes Fastspeech 2 for log-scaled mel-spectrogram prediction from phonemes and Parallel WaveGAN to generate the waveforms. The system supports a character input and gives a speech waveform at the output. We use a custom dictionary for selected words to ensure their proper pronunciation. Our proposed cloud architecture enables for fast voice delivery, making it possible to talk to the digital version of Albert Einstein in real-time.

</p>
</details>

<details><summary><b>Demonstration-Guided Reinforcement Learning with Learned Skills</b>
<a href="https://arxiv.org/abs/2107.10253">arxiv:2107.10253</a>
&#x1F4C8; 9 <br>
<p>Karl Pertsch, Youngwoon Lee, Yue Wu, Joseph J. Lim</p></summary>
<p>

**Abstract:** Demonstration-guided reinforcement learning (RL) is a promising approach for learning complex behaviors by leveraging both reward feedback and a set of target task demonstrations. Prior approaches for demonstration-guided RL treat every new task as an independent learning problem and attempt to follow the provided demonstrations step-by-step, akin to a human trying to imitate a completely unseen behavior by following the demonstrator's exact muscle movements. Naturally, such learning will be slow, but often new behaviors are not completely unseen: they share subtasks with behaviors we have previously learned. In this work, we aim to exploit this shared subtask structure to increase the efficiency of demonstration-guided RL. We first learn a set of reusable skills from large offline datasets of prior experience collected across many tasks. We then propose Skill-based Learning with Demonstrations (SkiLD), an algorithm for demonstration-guided RL that efficiently leverages the provided demonstrations by following the demonstrated skills instead of the primitive actions, resulting in substantial performance improvements over prior demonstration-guided RL approaches. We validate the effectiveness of our approach on long-horizon maze navigation and complex robot manipulation tasks.

</p>
</details>

<details><summary><b>Multi-Stream Transformers</b>
<a href="https://arxiv.org/abs/2107.10342">arxiv:2107.10342</a>
&#x1F4C8; 8 <br>
<p>Mikhail Burtsev, Anna Rumshisky</p></summary>
<p>

**Abstract:** Transformer-based encoder-decoder models produce a fused token-wise representation after every encoder layer. We investigate the effects of allowing the encoder to preserve and explore alternative hypotheses, combined at the end of the encoding process. To that end, we design and examine a $\textit{Multi-stream Transformer}$ architecture and find that splitting the Transformer encoder into multiple encoder streams and allowing the model to merge multiple representational hypotheses improves performance, with further improvement obtained by adding a skip connection between the first and the final encoder layer.

</p>
</details>

<details><summary><b>Quantum Pattern Recognition in Photonic Circuits</b>
<a href="https://arxiv.org/abs/2107.09961">arxiv:2107.09961</a>
&#x1F4C8; 8 <br>
<p>Rui Wang, Carlos Hernani-Morales, José D. Martín-Guerrero, Enrique Solano, Francisco Albarrán-Arriagada</p></summary>
<p>

**Abstract:** This paper proposes a machine learning method to characterize photonic states via a simple optical circuit and data processing of photon number distributions, such as photonic patterns. The input states consist of two coherent states used as references and a two-mode unknown state to be studied. We successfully trained supervised learning algorithms that can predict the degree of entanglement in the two-mode state as well as perform the full tomography of one photonic mode, obtaining satisfactory values in the considered regression metrics.

</p>
</details>

<details><summary><b>Interpreting diffusion score matching using normalizing flow</b>
<a href="https://arxiv.org/abs/2107.10072">arxiv:2107.10072</a>
&#x1F4C8; 7 <br>
<p>Wenbo Gong, Yingzhen Li</p></summary>
<p>

**Abstract:** Scoring matching (SM), and its related counterpart, Stein discrepancy (SD) have achieved great success in model training and evaluations. However, recent research shows their limitations when dealing with certain types of distributions. One possible fix is incorporating the original score matching (or Stein discrepancy) with a diffusion matrix, which is called diffusion score matching (DSM) (or diffusion Stein discrepancy (DSD)). However, the lack of interpretation of the diffusion limits its usage within simple distributions and manually chosen matrix. In this work, we plan to fill this gap by interpreting the diffusion matrix using normalizing flows. Specifically, we theoretically prove that DSM (or DSD) is equivalent to the original score matching (or Stein discrepancy) evaluated in the transformed space defined by the normalizing flow, where the diffusion matrix is the inverse of the flow's Jacobian matrix. In addition, we also build its connection to Riemannian manifolds and further extend it to continuous flows, where the change of DSM is characterized by an ODE.

</p>
</details>

<details><summary><b>Learning Sparse Fixed-Structure Gaussian Bayesian Networks</b>
<a href="https://arxiv.org/abs/2107.10450">arxiv:2107.10450</a>
&#x1F4C8; 6 <br>
<p>Arnab Bhattacharyya, Davin Choo, Rishikesh Gajjala, Sutanu Gayen, Yuhao Wang</p></summary>
<p>

**Abstract:** Gaussian Bayesian networks (a.k.a. linear Gaussian structural equation models) are widely used to model causal interactions among continuous variables. In this work, we study the problem of learning a fixed-structure Gaussian Bayesian network up to a bounded error in total variation distance. We analyze the commonly used node-wise least squares regression (LeastSquares) and prove that it has a near-optimal sample complexity. We also study a couple of new algorithms for the problem:
  - BatchAvgLeastSquares takes the average of several batches of least squares solutions at each node, so that one can interpolate between the batch size and the number of batches. We show that BatchAvgLeastSquares also has near-optimal sample complexity.
  - CauchyEst takes the median of solutions to several batches of linear systems at each node. We show that the algorithm specialized to polytrees, CauchyEstTree, has near-optimal sample complexity.
  Experimentally, we show that for uncontaminated, realizable data, the LeastSquares algorithm performs best, but in the presence of contamination or DAG misspecification, CauchyEst/CauchyEstTree and BatchAvgLeastSquares respectively perform better.

</p>
</details>

<details><summary><b>Memorization in Deep Neural Networks: Does the Loss Function matter?</b>
<a href="https://arxiv.org/abs/2107.09957">arxiv:2107.09957</a>
&#x1F4C8; 6 <br>
<p>Deep Patel, P. S. Sastry</p></summary>
<p>

**Abstract:** Deep Neural Networks, often owing to the overparameterization, are shown to be capable of exactly memorizing even randomly labelled data. Empirical studies have also shown that none of the standard regularization techniques mitigate such overfitting. We investigate whether the choice of the loss function can affect this memorization. We empirically show, with benchmark data sets MNIST and CIFAR-10, that a symmetric loss function, as opposed to either cross-entropy or squared error loss, results in significant improvement in the ability of the network to resist such overfitting. We then provide a formal definition for robustness to memorization and provide a theoretical explanation as to why the symmetric losses provide this robustness. Our results clearly bring out the role loss functions alone can play in this phenomenon of memorization.

</p>
</details>

<details><summary><b>Efficient Algorithms for Learning Depth-2 Neural Networks with General ReLU Activations</b>
<a href="https://arxiv.org/abs/2107.10209">arxiv:2107.10209</a>
&#x1F4C8; 5 <br>
<p>Pranjal Awasthi, Alex Tang, Aravindan Vijayaraghavan</p></summary>
<p>

**Abstract:** We present polynomial time and sample efficient algorithms for learning an unknown depth-2 feedforward neural network with general ReLU activations, under mild non-degeneracy assumptions. In particular, we consider learning an unknown network of the form $f(x) = {a}^{\mathsf{T}}σ({W}^\mathsf{T}x+b)$, where $x$ is drawn from the Gaussian distribution, and $σ(t) := \max(t,0)$ is the ReLU activation. Prior works for learning networks with ReLU activations assume that the bias $b$ is zero. In order to deal with the presence of the bias terms, our proposed algorithm consists of robustly decomposing multiple higher order tensors arising from the Hermite expansion of the function $f(x)$. Using these ideas we also establish identifiability of the network parameters under minimal assumptions.

</p>
</details>

<details><summary><b>MarsExplorer: Exploration of Unknown Terrains via Deep Reinforcement Learning and Procedurally Generated Environments</b>
<a href="https://arxiv.org/abs/2107.09996">arxiv:2107.09996</a>
&#x1F4C8; 5 <br>
<p>Dimitrios I. Koutras, Athanasios Ch. Kapoutsis, Angelos A. Amanatiadis, Elias B. Kosmatopoulos</p></summary>
<p>

**Abstract:** This paper is an initial endeavor to bridge the gap between powerful Deep Reinforcement Learning methodologies and the problem of exploration/coverage of unknown terrains. Within this scope, MarsExplorer, an openai-gym compatible environment tailored to exploration/coverage of unknown areas, is presented. MarsExplorer translates the original robotics problem into a Reinforcement Learning setup that various off-the-shelf algorithms can tackle. Any learned policy can be straightforwardly applied to a robotic platform without an elaborate simulation model of the robot's dynamics to apply a different learning/adaptation phase. One of its core features is the controllable multi-dimensional procedural generation of terrains, which is the key for producing policies with strong generalization capabilities. Four different state-of-the-art RL algorithms (A3C, PPO, Rainbow, and SAC) are trained on the MarsExplorer environment, and a proper evaluation of their results compared to the average human-level performance is reported. In the follow-up experimental analysis, the effect of the multi-dimensional difficulty setting on the learning capabilities of the best-performing algorithm (PPO) is analyzed. A milestone result is the generation of an exploration policy that follows the Hilbert curve without providing this information to the environment or rewarding directly or indirectly Hilbert-curve-like trajectories. The experimental analysis is concluded by evaluating PPO learned policy algorithm side-by-side with frontier-based exploration strategies. A study on the performance curves revealed that PPO-based policy was capable of performing adaptive-to-the-unknown-terrain sweeping without leaving expensive-to-revisit areas uncovered, underlying the capability of RL-based methodologies to tackle exploration tasks efficiently. The source code can be found at: https://github.com/dimikout3/MarsExplorer.

</p>
</details>

<details><summary><b>Predicting Issue Types on GitHub</b>
<a href="https://arxiv.org/abs/2107.09936">arxiv:2107.09936</a>
&#x1F4C8; 5 <br>
<p>Rafael Kallis, Andrea Di Sorbo, Gerardo Canfora, Sebastiano Panichella</p></summary>
<p>

**Abstract:** Software maintenance and evolution involves critical activities for the success of software projects. To support such activities and keep code up-to-date and error-free, software communities make use of issue trackers, i.e., tools for signaling, handling, and addressing the issues occurring in software systems. However, in popular projects, tens or hundreds of issue reports are daily submitted. In this context, identifying the type of each submitted report (e.g., bug report, feature request, etc.) would facilitate the management and the prioritization of the issues to address. To support issue handling activities, in this paper, we propose Ticket Tagger, a GitHub app analyzing the issue title and description through machine learning techniques to automatically recognize the types of reports submitted on GitHub and assign labels to each issue accordingly. We empirically evaluated the tool's prediction performance on about 30,000 GitHub issues. Our results show that the Ticket Tagger can identify the correct labels to assign to GitHub issues with reasonably high effectiveness. Considering these results and the fact that the tool is designed to be easily integrated in the GitHub issue management process, Ticket Tagger consists in a useful solution for developers.

</p>
</details>

<details><summary><b>Evaluation of In-Person Counseling Strategies To Develop Physical Activity Chatbot for Women</b>
<a href="https://arxiv.org/abs/2107.10410">arxiv:2107.10410</a>
&#x1F4C8; 4 <br>
<p>Kai-Hui Liang, Patrick Lange, Yoo Jung Oh, Jingwen Zhang, Yoshimi Fukuoka, Zhou Yu</p></summary>
<p>

**Abstract:** Artificial intelligence chatbots are the vanguard in technology-based intervention to change people's behavior. To develop intervention chatbots, the first step is to understand natural language conversation strategies in human conversation. This work introduces an intervention conversation dataset collected from a real-world physical activity intervention program for women. We designed comprehensive annotation schemes in four dimensions (domain, strategy, social exchange, and task-focused exchange) and annotated a subset of dialogs. We built a strategy classifier with context information to detect strategies from both trainers and participants based on the annotation. To understand how human intervention induces effective behavior changes, we analyzed the relationships between the intervention strategies and the participants' changes in the barrier and social support for physical activity. We also analyzed how participant's baseline weight correlates to the amount of occurrence of the corresponding strategy. This work lays the foundation for developing a personalized physical activity intervention bot. The dataset and code are available at https://github.com/KaihuiLiang/physical-activity-counseling

</p>
</details>

<details><summary><b>Machine Learning Characterization of Cancer Patients-Derived Extracellular Vesicles using Vibrational Spectroscopies</b>
<a href="https://arxiv.org/abs/2107.10332">arxiv:2107.10332</a>
&#x1F4C8; 4 <br>
<p>Abicumaran Uthamacumaran, Samir Elouatik, Mohamed Abdouh, Michael Berteau-Rainville, Zu-hua Gao, Goffredo Arena</p></summary>
<p>

**Abstract:** The early detection of cancer is a challenging problem in medicine. The blood sera of cancer patients are enriched with heterogeneous secretory lipid bound extracellular vesicles (EVs), which present a complex repertoire of information and biomarkers, representing their cell of origin, that are being currently studied in the field of liquid biopsy and cancer screening. Vibrational spectroscopies provide non-invasive approaches for the assessment of structural and biophysical properties in complex biological samples. In this pilot study, multiple Raman spectroscopy measurements were performed on the EVs extracted from the blood sera of 9 patients consisting of four different cancer subtypes (colorectal cancer, hepatocellular carcinoma, breast cancer and pancreatic cancer) and five healthy patients (controls). FTIR (Fourier Transform Infrared) spectroscopy measurements were performed as a complementary approach to Raman analysis, on two of the four cancer subtypes.
  The AdaBoost Random Forest Classifier, Decision Trees, and Support Vector Machines (SVM) distinguished the baseline corrected Raman spectra of cancer EVs from those of healthy controls (18 spectra) with a classification accuracy of above 90 percent when reduced to a spectral frequency range of 1800 to 1940 inverse cm and subjected to a 50:50 training: testing split. FTIR classification accuracy on 14 spectra showed an 80 percent classification accuracy. Our findings demonstrate that basic machine learning algorithms are powerful applied intelligence tools to distinguish the complex vibrational spectra of cancer patient EVs from those of healthy patients. These experimental methods hold promise as valid and efficient liquid biopsy for artificial intelligence-assisted early cancer screening.

</p>
</details>

<details><summary><b>Differentiable Annealed Importance Sampling and the Perils of Gradient Noise</b>
<a href="https://arxiv.org/abs/2107.10211">arxiv:2107.10211</a>
&#x1F4C8; 4 <br>
<p>Guodong Zhang, Kyle Hsu, Jianing Li, Chelsea Finn, Roger Grosse</p></summary>
<p>

**Abstract:** Annealed importance sampling (AIS) and related algorithms are highly effective tools for marginal likelihood estimation, but are not fully differentiable due to the use of Metropolis-Hastings correction steps. Differentiability is a desirable property as it would admit the possibility of optimizing marginal likelihood as an objective using gradient-based methods. To this end, we propose Differentiable AIS (DAIS), a variant of AIS which ensures differentiability by abandoning the Metropolis-Hastings corrections. As a further advantage, DAIS allows for mini-batch gradients. We provide a detailed convergence analysis for Bayesian linear regression which goes beyond previous analyses by explicitly accounting for the sampler not having reached equilibrium. Using this analysis, we prove that DAIS is consistent in the full-batch setting and provide a sublinear convergence rate. Furthermore, motivated by the problem of learning from large-scale datasets, we study a stochastic variant of DAIS that uses mini-batch gradients. Surprisingly, stochastic DAIS can be arbitrarily bad due to a fundamental incompatibility between the goals of last-iterate convergence to the posterior and elimination of the accumulated stochastic error. This is in stark contrast with other settings such as gradient-based optimization and Langevin dynamics, where the effect of gradient noise can be washed out by taking smaller steps. This indicates that annealing-based marginal likelihood estimation with stochastic gradients may require new ideas.

</p>
</details>

<details><summary><b>Distribution of Classification Margins: Are All Data Equal?</b>
<a href="https://arxiv.org/abs/2107.10199">arxiv:2107.10199</a>
&#x1F4C8; 4 <br>
<p>Andrzej Banburski, Fernanda De La Torre, Nishka Pant, Ishana Shastri, Tomaso Poggio</p></summary>
<p>

**Abstract:** Recent theoretical results show that gradient descent on deep neural networks under exponential loss functions locally maximizes classification margin, which is equivalent to minimizing the norm of the weight matrices under margin constraints. This property of the solution however does not fully characterize the generalization performance. We motivate theoretically and show empirically that the area under the curve of the margin distribution on the training set is in fact a good measure of generalization. We then show that, after data separation is achieved, it is possible to dynamically reduce the training set by more than 99% without significant loss of performance. Interestingly, the resulting subset of "high capacity" features is not consistent across different training runs, which is consistent with the theoretical claim that all training points should converge to the same asymptotic margin under SGD and in the presence of both batch normalization and weight decay.

</p>
</details>

<details><summary><b>Conditional Sound Generation Using Neural Discrete Time-Frequency Representation Learning</b>
<a href="https://arxiv.org/abs/2107.09998">arxiv:2107.09998</a>
&#x1F4C8; 4 <br>
<p>Xubo Liu, Turab Iqbal, Jinzheng Zhao, Qiushi Huang, Mark D. Plumbley, Wenwu Wang</p></summary>
<p>

**Abstract:** Deep generative models have recently achieved impressive performance in speech and music synthesis. However, compared to the generation of those domain-specific sounds, generating general sounds (such as siren, gunshots) has received less attention, despite their wide applications. In previous work, the SampleRNN method was considered for sound generation in the time domain. However, SampleRNN is potentially limited in capturing long-range dependencies within sounds as it only back-propagates through a limited number of samples. In this work, we propose a method for generating sounds via neural discrete time-frequency representation learning, conditioned on sound classes. This offers an advantage in efficiently modelling long-range dependencies and retaining local fine-grained structures within sound clips. We evaluate our approach on the UrbanSound8K dataset, compared to SampleRNN, with the performance metrics measuring the quality and diversity of generated sounds. Experimental results show that our method offers comparable performance in quality and significantly better performance in diversity.

</p>
</details>

<details><summary><b>High-Resolution Pelvic MRI Reconstruction Using a Generative Adversarial Network with Attention and Cyclic Loss</b>
<a href="https://arxiv.org/abs/2107.09989">arxiv:2107.09989</a>
&#x1F4C8; 4 <br>
<p>Guangyuan Li, Jun Lv, Xiangrong Tong, Chengyan Wang, Guang Yang</p></summary>
<p>

**Abstract:** Magnetic resonance imaging (MRI) is an important medical imaging modality, but its acquisition speed is quite slow due to the physiological limitations. Recently, super-resolution methods have shown excellent performance in accelerating MRI. In some circumstances, it is difficult to obtain high-resolution images even with prolonged scan time. Therefore, we proposed a novel super-resolution method that uses a generative adversarial network (GAN) with cyclic loss and attention mechanism to generate high-resolution MR images from low-resolution MR images by a factor of 2. We implemented our model on pelvic images from healthy subjects as training and validation data, while those data from patients were used for testing. The MR dataset was obtained using different imaging sequences, including T2, T2W SPAIR, and mDIXON-W. Four methods, i.e., BICUBIC, SRCNN, SRGAN, and EDSR were used for comparison. Structural similarity, peak signal to noise ratio, root mean square error, and variance inflation factor were used as calculation indicators to evaluate the performances of the proposed method. Various experimental results showed that our method can better restore the details of the high-resolution MR image as compared to the other methods. In addition, the reconstructed high-resolution MR image can provide better lesion textures in the tumor patients, which is promising to be used in clinical diagnosis.

</p>
</details>

<details><summary><b>Towards Lower-Dose PET using Physics-Based Uncertainty-Aware Multimodal Learning with Robustness to Out-of-Distribution Data</b>
<a href="https://arxiv.org/abs/2107.09892">arxiv:2107.09892</a>
&#x1F4C8; 4 <br>
<p>Viswanath P. Sudarshan, Uddeshya Upadhyay, Gary F. Egan, Zhaolin Chen, Suyash P. Awate</p></summary>
<p>

**Abstract:** Radiation exposure in positron emission tomography (PET) imaging limits its usage in the studies of radiation-sensitive populations, e.g., pregnant women, children, and adults that require longitudinal imaging. Reducing the PET radiotracer dose or acquisition time reduces photon counts, which can deteriorate image quality. Recent deep-neural-network (DNN) based methods for image-to-image translation enable the mapping of low-quality PET images (acquired using substantially reduced dose), coupled with the associated magnetic resonance imaging (MRI) images, to high-quality PET images. However, such DNN methods focus on applications involving test data that match the statistical characteristics of the training data very closely and give little attention to evaluating the performance of these DNNs on new out-of-distribution (OOD) acquisitions. We propose a novel DNN formulation that models the (i) underlying sinogram-based physics of the PET imaging system and (ii) the uncertainty in the DNN output through the per-voxel heteroscedasticity of the residuals between the predicted and the high-quality reference images. Our sinogram-based uncertainty-aware DNN framework, namely, suDNN, estimates a standard-dose PET image using multimodal input in the form of (i) a low-dose/low-count PET image and (ii) the corresponding multi-contrast MRI images, leading to improved robustness of suDNN to OOD acquisitions. Results on in vivo simultaneous PET-MRI, and various forms of OOD data in PET-MRI, show the benefits of suDNN over the current state of the art, quantitatively and qualitatively.

</p>
</details>

<details><summary><b>Strategic Mitigation of Agent Inattention in Drivers with Open-Quantum Cognition Models</b>
<a href="https://arxiv.org/abs/2107.09888">arxiv:2107.09888</a>
&#x1F4C8; 4 <br>
<p>Qizi Zhang, Venkata Sriram Siddhardh Nadendla, S. N. Balakrishnan, Jerome Busemeyer</p></summary>
<p>

**Abstract:** State-of-the-art driver-assist systems have failed to effectively mitigate driver inattention and had minimal impacts on the ever-growing number of road mishaps (e.g. life loss, physical injuries due to accidents caused by various factors that lead to driver inattention). This is because traditional human-machine interaction settings are modeled in classical and behavioral game-theoretic domains which are technically appropriate to characterize strategic interaction between either two utility maximizing agents, or human decision makers. Therefore, in an attempt to improve the persuasive effectiveness of driver-assist systems, we develop a novel strategic and personalized driver-assist system which adapts to the driver's mental state and choice behavior. First, we propose a novel equilibrium notion in human-system interaction games, where the system maximizes its expected utility and human decisions can be characterized using any general decision model. Then we use this novel equilibrium notion to investigate the strategic driver-vehicle interaction game where the car presents a persuasive recommendation to steer the driver towards safer driving decisions. We assume that the driver employs an open-quantum system cognition model, which captures complex aspects of human decision making such as violations to classical law of total probability and incompatibility of certain mental representations of information. We present closed-form expressions for players' final responses to each other's strategies so that we can numerically compute both pure and mixed equilibria. Numerical results are presented to illustrate both kinds of equilibria.

</p>
</details>

<details><summary><b>Temporal-Relational Hypergraph Tri-Attention Networks for Stock Trend Prediction</b>
<a href="https://arxiv.org/abs/2107.14033">arxiv:2107.14033</a>
&#x1F4C8; 3 <br>
<p>Chaoran Cui, Xiaojie Li, Juan Du, Chunyun Zhang, Xiushan Nie, Meng Wang, Yilong Yin</p></summary>
<p>

**Abstract:** Predicting the future price trends of stocks is a challenging yet intriguing problem given its critical role to help investors make profitable decisions. In this paper, we present a collaborative temporal-relational modeling framework for end-to-end stock trend prediction. The temporal dynamics of stocks is firstly captured with an attention-based recurrent neural network. Then, different from existing studies relying on the pairwise correlations between stocks, we argue that stocks are naturally connected as a collective group, and introduce the hypergraph structures to jointly characterize the stock group-wise relationships of industry-belonging and fund-holding. A novel hypergraph tri-attention network (HGTAN) is proposed to augment the hypergraph convolutional networks with a hierarchical organization of intra-hyperedge, inter-hyperedge, and inter-hypergraph attention modules. In this manner, HGTAN adaptively determines the importance of nodes, hyperedges, and hypergraphs during the information propagation among stocks, so that the potential synergies between stock movements can be fully exploited. Extensive experiments on real-world data demonstrate the effectiveness of our approach. Also, the results of investment simulation show that our approach can achieve a more desirable risk-adjusted return. The data and codes of our work have been released at https://github.com/lixiaojieff/HGTAN.

</p>
</details>

<details><summary><b>Improve Learning from Crowds via Generative Augmentation</b>
<a href="https://arxiv.org/abs/2107.10449">arxiv:2107.10449</a>
&#x1F4C8; 3 <br>
<p>Zhendong Chu, Hongning Wang</p></summary>
<p>

**Abstract:** Crowdsourcing provides an efficient label collection schema for supervised machine learning. However, to control annotation cost, each instance in the crowdsourced data is typically annotated by a small number of annotators. This creates a sparsity issue and limits the quality of machine learning models trained on such data. In this paper, we study how to handle sparsity in crowdsourced data using data augmentation. Specifically, we propose to directly learn a classifier by augmenting the raw sparse annotations. We implement two principles of high-quality augmentation using Generative Adversarial Networks: 1) the generated annotations should follow the distribution of authentic ones, which is measured by a discriminator; 2) the generated annotations should have high mutual information with the ground-truth labels, which is measured by an auxiliary network. Extensive experiments and comparisons against an array of state-of-the-art learning from crowds methods on three real-world datasets proved the effectiveness of our data augmentation framework. It shows the potential of our algorithm for low-budget crowdsourcing in general.

</p>
</details>

<details><summary><b>Shedding some light on Light Up with Artificial Intelligence</b>
<a href="https://arxiv.org/abs/2107.10429">arxiv:2107.10429</a>
&#x1F4C8; 3 <br>
<p>Libo Sun, James Browning, Roberto Perera</p></summary>
<p>

**Abstract:** The Light-Up puzzle, also known as the AKARI puzzle, has never been solved using modern artificial intelligence (AI) methods. Currently, the most widely used computational technique to autonomously develop solutions involve evolution theory algorithms. This project is an effort to apply new AI techniques for solving the Light-up puzzle faster and more computationally efficient. The algorithms explored for producing optimal solutions include hill climbing, simulated annealing, feed-forward neural network (FNN), and convolutional neural network (CNN). Two algorithms were developed for hill climbing and simulated annealing using 2 actions (add and remove light bulb) versus 3 actions(add, remove, or move light-bulb to a different cell). Both hill climbing and simulated annealing algorithms showed a higher accuracy for the case of 3 actions. The simulated annealing showed to significantly outperform hill climbing, FNN, CNN, and an evolutionary theory algorithm achieving 100% accuracy in 30 unique board configurations. Lastly, while FNN and CNN algorithms showed low accuracies, computational times were significantly faster compared to the remaining algorithms. The GitHub repository for this project can be found at https://github.com/rperera12/AKARI-LightUp-GameSolver-with-DeepNeuralNetworks-and-HillClimb-or-SimulatedAnnealing.

</p>
</details>

<details><summary><b>A Sparsity Algorithm with Applications to Corporate Credit Rating</b>
<a href="https://arxiv.org/abs/2107.10306">arxiv:2107.10306</a>
&#x1F4C8; 3 <br>
<p>Dan Wang, Zhi Chen, Ionut Florescu</p></summary>
<p>

**Abstract:** In Artificial Intelligence, interpreting the results of a Machine Learning technique often termed as a black box is a difficult task. A counterfactual explanation of a particular "black box" attempts to find the smallest change to the input values that modifies the prediction to a particular output, other than the original one. In this work we formulate the problem of finding a counterfactual explanation as an optimization problem. We propose a new "sparsity algorithm" which solves the optimization problem, while also maximizing the sparsity of the counterfactual explanation. We apply the sparsity algorithm to provide a simple suggestion to publicly traded companies in order to improve their credit ratings. We validate the sparsity algorithm with a synthetically generated dataset and we further apply it to quarterly financial statements from companies in financial, healthcare and IT sectors of the US market. We provide evidence that the counterfactual explanation can capture the nature of the real statement features that changed between the current quarter and the following quarter when ratings improved. The empirical results show that the higher the rating of a company the greater the "effort" required to further improve credit rating.

</p>
</details>

<details><summary><b>Online structural kernel selection for mobile health</b>
<a href="https://arxiv.org/abs/2107.09949">arxiv:2107.09949</a>
&#x1F4C8; 3 <br>
<p>Eura Shin, Pedja Klasnja, Susan Murphy, Finale Doshi-Velez</p></summary>
<p>

**Abstract:** Motivated by the need for efficient and personalized learning in mobile health, we investigate the problem of online kernel selection for Gaussian Process regression in the multi-task setting. We propose a novel generative process on the kernel composition for this purpose. Our method demonstrates that trajectories of kernel evolutions can be transferred between users to improve learning and that the kernels themselves are meaningful for an mHealth prediction goal.

</p>
</details>

<details><summary><b>The Effectiveness of Intermediate-Task Training for Code-Switched Natural Language Understanding</b>
<a href="https://arxiv.org/abs/2107.09931">arxiv:2107.09931</a>
&#x1F4C8; 3 <br>
<p>Archiki Prasad, Mohammad Ali Rehan, Shreya Pathak, Preethi Jyothi</p></summary>
<p>

**Abstract:** While recent benchmarks have spurred a lot of new work on improving the generalization of pretrained multilingual language models on multilingual tasks, techniques to improve code-switched natural language understanding tasks have been far less explored. In this work, we propose the use of bilingual intermediate pretraining as a reliable technique to derive large and consistent performance gains on three different NLP tasks using code-switched text. We achieve substantial absolute improvements of 7.87%, 20.15%, and 10.99%, on the mean accuracies and F1 scores over previous state-of-the-art systems for Hindi-English Natural Language Inference (NLI), Question Answering (QA) tasks, and Spanish-English Sentiment Analysis (SA) respectively. We show consistent performance gains on four different code-switched language-pairs (Hindi-English, Spanish-English, Tamil-English and Malayalam-English) for SA. We also present a code-switched masked language modelling (MLM) pretraining technique that consistently benefits SA compared to standard MLM pretraining using real code-switched text.

</p>
</details>

<details><summary><b>Economic Recession Prediction Using Deep Neural Network</b>
<a href="https://arxiv.org/abs/2107.10980">arxiv:2107.10980</a>
&#x1F4C8; 2 <br>
<p>Zihao Wang, Kun Li, Steve Q. Xia, Hongfu Liu</p></summary>
<p>

**Abstract:** We investigate the effectiveness of different machine learning methodologies in predicting economic cycles. We identify the deep learning methodology of Bi-LSTM with Autoencoder as the most accurate model to forecast the beginning and end of economic recessions in the U.S. We adopt commonly-available macro and market-condition features to compare the ability of different machine learning models to generate good predictions both in-sample and out-of-sample. The proposed model is flexible and dynamic when both predictive variables and model coefficients vary over time. It provided good out-of-sample predictions for the past two recessions and early warning about the COVID-19 recession.

</p>
</details>

<details><summary><b>Multi-modal Residual Perceptron Network for Audio-Video Emotion Recognition</b>
<a href="https://arxiv.org/abs/2107.10742">arxiv:2107.10742</a>
&#x1F4C8; 2 <br>
<p>Xin Chang, Władysław Skarbek</p></summary>
<p>

**Abstract:** Audio-Video Emotion Recognition is now attacked with Deep Neural Network modeling tools. In published papers, as a rule, the authors show only cases of the superiority in multi-modality over audio-only or video-only modality. However, there are cases superiority in uni-modality can be found. In our research, we hypothesize that for fuzzy categories of emotional events, the within-modal and inter-modal noisy information represented indirectly in the parameters of the modeling neural network impedes better performance in the existing late fusion and end-to-end multi-modal network training strategies. To take advantage and overcome the deficiencies in both solutions, we define a Multi-modal Residual Perceptron Network which performs end-to-end learning from multi-modal network branches, generalizing better multi-modal feature representation. For the proposed Multi-modal Residual Perceptron Network and the novel time augmentation for streaming digital movies, the state-of-art average recognition rate was improved to 91.4% for The Ryerson Audio-Visual Database of Emotional Speech and Song dataset and to 83.15% for Crowd-sourced Emotional multi-modal Actors dataset. Moreover, the Multi-modal Residual Perceptron Network concept shows its potential for multi-modal applications dealing with signal sources not only of optical and acoustical types.

</p>
</details>

<details><summary><b>Fed-ensemble: Improving Generalization through Model Ensembling in Federated Learning</b>
<a href="https://arxiv.org/abs/2107.10663">arxiv:2107.10663</a>
&#x1F4C8; 2 <br>
<p>Naichen Shi, Fan Lai, Raed Al Kontar, Mosharaf Chowdhury</p></summary>
<p>

**Abstract:** In this paper we propose Fed-ensemble: a simple approach that bringsmodel ensembling to federated learning (FL). Instead of aggregating localmodels to update a single global model, Fed-ensemble uses random permutations to update a group of K models and then obtains predictions through model averaging. Fed-ensemble can be readily utilized within established FL methods and does not impose a computational overhead as it only requires one of the K models to be sent to a client in each communication round. Theoretically, we show that predictions on newdata from all K models belong to the same predictive posterior distribution under a neural tangent kernel regime. This result in turn sheds light onthe generalization advantages of model averaging. We also illustrate thatFed-ensemble has an elegant Bayesian interpretation. Empirical results show that our model has superior performance over several FL algorithms,on a wide range of data sets, and excels in heterogeneous settings often encountered in FL applications.

</p>
</details>

<details><summary><b>Spinning Sequence-to-Sequence Models with Meta-Backdoors</b>
<a href="https://arxiv.org/abs/2107.10443">arxiv:2107.10443</a>
&#x1F4C8; 2 <br>
<p>Eugene Bagdasaryan, Vitaly Shmatikov</p></summary>
<p>

**Abstract:** We investigate a new threat to neural sequence-to-sequence (seq2seq) models: training-time attacks that cause models to "spin" their output and support a certain sentiment when the input contains adversary-chosen trigger words. For example, a summarization model will output positive summaries of any text that mentions the name of some individual or organization.
  We introduce the concept of a "meta-backdoor" to explain model-spinning attacks. These attacks produce models whose output is valid and preserves context, yet also satisfies a meta-task chosen by the adversary (e.g., positive sentiment). Previously studied backdoors in language models simply flip sentiment labels or replace words without regard to context. Their outputs are incorrect on inputs with the trigger. Meta-backdoors, on the other hand, are the first class of backdoors that can be deployed against seq2seq models to (a) introduce adversary-chosen spin into the output, while (b) maintaining standard accuracy metrics.
  To demonstrate feasibility of model spinning, we develop a new backdooring technique. It stacks the adversarial meta-task (e.g., sentiment analysis) onto a seq2seq model, backpropagates the desired meta-task output (e.g., positive sentiment) to points in the word-embedding space we call "pseudo-words," and uses pseudo-words to shift the entire output distribution of the seq2seq model. Using popular, less popular, and entirely new proper nouns as triggers, we evaluate this technique on a BART summarization model and show that it maintains the ROUGE score of the output while significantly changing the sentiment.
  We explain why model spinning can be a dangerous technique in AI-powered disinformation and discuss how to mitigate these attacks.

</p>
</details>

<details><summary><b>MFGNet: Dynamic Modality-Aware Filter Generation for RGB-T Tracking</b>
<a href="https://arxiv.org/abs/2107.10433">arxiv:2107.10433</a>
&#x1F4C8; 2 <br>
<p>Xiao Wang, Xiujun Shu, Shiliang Zhang, Bo Jiang, Yaowei Wang, Yonghong Tian, Feng Wu</p></summary>
<p>

**Abstract:** Many RGB-T trackers attempt to attain robust feature representation by utilizing an adaptive weighting scheme (or attention mechanism). Different from these works, we propose a new dynamic modality-aware filter generation module (named MFGNet) to boost the message communication between visible and thermal data by adaptively adjusting the convolutional kernels for various input images in practical tracking. Given the image pairs as input, we first encode their features with the backbone network. Then, we concatenate these feature maps and generate dynamic modality-aware filters with two independent networks. The visible and thermal filters will be used to conduct a dynamic convolutional operation on their corresponding input feature maps respectively. Inspired by residual connection, both the generated visible and thermal feature maps will be summarized with input feature maps. The augmented feature maps will be fed into the RoI align module to generate instance-level features for subsequent classification. To address issues caused by heavy occlusion, fast motion, and out-of-view, we propose to conduct a joint local and global search by exploiting a new direction-aware target-driven attention mechanism. The spatial and temporal recurrent neural network is used to capture the direction-aware context for accurate global attention prediction. Extensive experiments on three large-scale RGB-T tracking benchmark datasets validated the effectiveness of our proposed algorithm. The project page of this paper is available at https://sites.google.com/view/mfgrgbttrack/.

</p>
</details>

<details><summary><b>Design of a Graphical User Interface for Few-Shot Machine Learning Classification of Electron Microscopy Data</b>
<a href="https://arxiv.org/abs/2107.10387">arxiv:2107.10387</a>
&#x1F4C8; 2 <br>
<p>Christina Doty, Shaun Gallagher, Wenqi Cui, Wenya Chen, Shweta Bhushan, Marjolein Oostrom, Sarah Akers, Steven R. Spurgeon</p></summary>
<p>

**Abstract:** The recent growth in data volumes produced by modern electron microscopes requires rapid, scalable, and flexible approaches to image segmentation and analysis. Few-shot machine learning, which can richly classify images from a handful of user-provided examples, is a promising route to high-throughput analysis. However, current command-line implementations of such approaches can be slow and unintuitive to use, lacking the real-time feedback necessary to perform effective classification. Here we report on the development of a Python-based graphical user interface that enables end users to easily conduct and visualize the output of few-shot learning models. This interface is lightweight and can be hosted locally or on the web, providing the opportunity to reproducibly conduct, share, and crowd-source few-shot analyses.

</p>
</details>

<details><summary><b>Online-Learning Deep Neuro-Adaptive Dynamic Inversion Controller for Model Free Control</b>
<a href="https://arxiv.org/abs/2107.10383">arxiv:2107.10383</a>
&#x1F4C8; 2 <br>
<p>Nathan Lutes, K. Krishnamurthy, Venkata Sriram Siddhardh Nadendla, S. N. Balakrishnan</p></summary>
<p>

**Abstract:** Adaptive methods are popular within the control literature due to the flexibility and forgiveness they offer in the area of modelling. Neural network adaptive control is favorable specifically for the powerful nature of the machine learning algorithm to approximate unknown functions and for the ability to relax certain constraints within traditional adaptive control. Deep neural networks are large framework networks with vastly superior approximation characteristics than their shallow counterparts. However, implementing a deep neural network can be difficult due to size specific complications such as vanishing/exploding gradients in training. In this paper, a neuro-adaptive controller is implemented featuring a deep neural network trained on a new weight update law that escapes the vanishing/exploding gradient problem by only incorporating the sign of the gradient. The type of controller designed is an adaptive dynamic inversion controller utilizing a modified state observer in a secondary estimation loop to train the network. The deep neural network learns the entire plant model on-line, creating a controller that is completely model free. The controller design is tested in simulation on a 2 link planar robot arm. The controller is able to learn the nonlinear plant quickly and displays good performance in the tracking control problem.

</p>
</details>

<details><summary><b>Uncertainty-Aware Task Allocation for Distributed Autonomous Robots</b>
<a href="https://arxiv.org/abs/2107.10350">arxiv:2107.10350</a>
&#x1F4C8; 2 <br>
<p>Liang Sun, Leonardo Escamilla</p></summary>
<p>

**Abstract:** This paper addresses task-allocation problems with uncertainty in situational awareness for distributed autonomous robots (DARs). The uncertainty propagation over a task-allocation process is done by using the Unscented transform that uses the Sigma-Point sampling mechanism. It has great potential to be employed for generic task-allocation schemes, in the sense that there is no need to modify an existing task-allocation method that has been developed without considering the uncertainty in the situational awareness. The proposed framework was tested in a simulated environment where the decision-maker needs to determine an optimal allocation of multiple locations assigned to multiple mobile flying robots whose locations come as random variables of known mean and covariance. The simulation result shows that the proposed stochastic task allocation approach generates an assignment with 30% less overall cost than the one without considering the uncertainty.

</p>
</details>

<details><summary><b>COfEE: A Comprehensive Ontology for Event Extraction from text</b>
<a href="https://arxiv.org/abs/2107.10326">arxiv:2107.10326</a>
&#x1F4C8; 2 <br>
<p>Ali Balali, Masoud Asadpour, Seyed Hossein Jafari</p></summary>
<p>

**Abstract:** Data is published on the web over time in great volumes, but majority of the data is unstructured, making it hard to understand and difficult to interpret. Information Extraction (IE) methods obtain structured information from unstructured data. One of the challenging IE tasks is Event Extraction (EE) which seeks to derive information about specific incidents and their actors from the text. EE is useful in many domains such as building a knowledge base, information retrieval and summarization. In the past decades, some event ontologies like ACE, CAMEO and ICEWS were developed to define event forms, actors and dimensions of events observed in the text. These event ontologies still have some shortcomings such as covering only a few topics like political events, having inflexible structure in defining argument roles and insufficient gold-standard data. To address these concerns, we propose an event ontology, namely COfEE, that incorporates both expert domain knowledge and a data-driven approach for identifying events from text. COfEE consists of two hierarchy levels (event types and event sub-types) that include new categories relating to environmental issues, cyberspace and criminal activity which need to be monitored instantly. Also, dynamic roles according to each event sub-type are defined to capture various dimensions of events. In a follow-up experiment, the proposed ontology is evaluated on Wikipedia events, and it is shown to be general and comprehensive. Moreover, in order to facilitate the preparation of gold-standard data for event extraction, a language-independent online tool is presented based on COfEE. A gold-standard dataset annotated by 10 human experts is also prepared consisting 24K news articles in Persian language. Finally, we present a supervised method based on deep learning techniques to automatically extract relevant events and corresponding actors.

</p>
</details>

<details><summary><b>JEFL: Joint Embedding of Formal Proof Libraries</b>
<a href="https://arxiv.org/abs/2107.10188">arxiv:2107.10188</a>
&#x1F4C8; 2 <br>
<p>Qingxiang Wang, Cezary Kaliszyk</p></summary>
<p>

**Abstract:** The heterogeneous nature of the logical foundations used in different interactive proof assistant libraries has rendered discovery of similar mathematical concepts among them difficult. In this paper, we compare a previously proposed algorithm for matching concepts across libraries with our unsupervised embedding approach that can help us retrieve similar concepts. Our approach is based on the fasttext implementation of Word2Vec, on top of which a tree traversal module is added to adapt its algorithm to the representation format of our data export pipeline. We compare the explainability, customizability, and online-servability of the approaches and argue that the neural embedding approach has more potential to be integrated into an interactive proof assistant.

</p>
</details>

<details><summary><b>Answer-Set Programs for Reasoning about Counterfactual Interventions and Responsibility Scores for Classification</b>
<a href="https://arxiv.org/abs/2107.10159">arxiv:2107.10159</a>
&#x1F4C8; 2 <br>
<p>Leopoldo Bertossi, Gabriela Reyes</p></summary>
<p>

**Abstract:** We describe how answer-set programs can be used to declaratively specify counterfactual interventions on entities under classification, and reason about them. In particular, they can be used to define and compute responsibility scores as attribution-based explanations for outcomes from classification models. The approach allows for the inclusion of domain knowledge and supports query answering. A detailed example with a naive-Bayes classifier is presented.

</p>
</details>

<details><summary><b>A Deep Reinforcement Learning Approach for Fair Traffic Signal Control</b>
<a href="https://arxiv.org/abs/2107.10146">arxiv:2107.10146</a>
&#x1F4C8; 2 <br>
<p>Majid Raeis, Alberto Leon-Garcia</p></summary>
<p>

**Abstract:** Traffic signal control is one of the most effective methods of traffic management in urban areas. In recent years, traffic control methods based on deep reinforcement learning (DRL) have gained attention due to their ability to exploit real-time traffic data, which is often poorly used by the traditional hand-crafted methods. While most recent DRL-based methods have focused on maximizing the throughput or minimizing the average travel time of the vehicles, the fairness of the traffic signal controllers has often been neglected. This is particularly important as neglecting fairness can lead to situations where some vehicles experience extreme waiting times, or where the throughput of a particular traffic flow is highly impacted by the fluctuations of another conflicting flow at the intersection. In order to address these issues, we introduce two notions of fairness: delay-based and throughput-based fairness, which correspond to the two issues mentioned above. Furthermore, we propose two DRL-based traffic signal control methods for implementing these fairness notions, that can achieve a high throughput as well. We evaluate the performance of our proposed methods using three traffic arrival distributions, and find that our methods outperform the baselines in the tested scenarios.

</p>
</details>

<details><summary><b>On the Memorization Properties of Contrastive Learning</b>
<a href="https://arxiv.org/abs/2107.10143">arxiv:2107.10143</a>
&#x1F4C8; 2 <br>
<p>Ildus Sadrtdinov, Nadezhda Chirkova, Ekaterina Lobacheva</p></summary>
<p>

**Abstract:** Memorization studies of deep neural networks (DNNs) help to understand what patterns and how do DNNs learn, and motivate improvements to DNN training approaches. In this work, we investigate the memorization properties of SimCLR, a widely used contrastive self-supervised learning approach, and compare them to the memorization of supervised learning and random labels training. We find that both training objects and augmentations may have different complexity in the sense of how SimCLR learns them. Moreover, we show that SimCLR is similar to random labels training in terms of the distribution of training objects complexity.

</p>
</details>

<details><summary><b>S4T: Source-free domain adaptation for semantic segmentation via self-supervised selective self-training</b>
<a href="https://arxiv.org/abs/2107.10140">arxiv:2107.10140</a>
&#x1F4C8; 2 <br>
<p>Viraj Prabhu, Shivam Khare, Deeksha Kartik, Judy Hoffman</p></summary>
<p>

**Abstract:** Most modern approaches for domain adaptive semantic segmentation rely on continued access to source data during adaptation, which may be infeasible due to computational or privacy constraints. We focus on source-free domain adaptation for semantic segmentation, wherein a source model must adapt itself to a new target domain given only unlabeled target data. We propose Self-Supervised Selective Self-Training (S4T), a source-free adaptation algorithm that first uses the model's pixel-level predictive consistency across diverse views of each target image along with model confidence to classify pixel predictions as either reliable or unreliable. Next, the model is self-trained, using predicted pseudolabels for reliable predictions and pseudolabels inferred via a selective interpolation strategy for unreliable ones. S4T matches or improves upon the state-of-the-art in source-free adaptation on 3 standard benchmarks for semantic segmentation within a single epoch of adaptation.

</p>
</details>

<details><summary><b>A variational approximate posterior for the deep Wishart process</b>
<a href="https://arxiv.org/abs/2107.10125">arxiv:2107.10125</a>
&#x1F4C8; 2 <br>
<p>Sebastian W. Ober, Laurence Aitchison</p></summary>
<p>

**Abstract:** Recent work introduced deep kernel processes as an entirely kernel-based alternative to NNs (Aitchison et al. 2020). Deep kernel processes flexibly learn good top-layer representations by alternately sampling the kernel from a distribution over positive semi-definite matrices and performing nonlinear transformations. A particular deep kernel process, the deep Wishart process (DWP), is of particular interest because its prior can be made equivalent to deep Gaussian process (DGP) priors for kernels that can be expressed entirely in terms of Gram matrices. However, inference in DWPs has not yet been possible due to the lack of sufficiently flexible distributions over positive semi-definite matrices. Here, we give a novel approach to obtaining flexible distributions over positive semi-definite matrices by generalising the Bartlett decomposition of the Wishart probability density. We use this new distribution to develop an approximate posterior for the DWP that includes dependency across layers. We develop a doubly-stochastic inducing-point inference scheme for the DWP and show experimentally that inference in the DWP can improve performance over doing inference in a DGP with the equivalent prior.

</p>
</details>

<details><summary><b>Training Electric Vehicle Charging Controllers with Imitation Learning</b>
<a href="https://arxiv.org/abs/2107.10111">arxiv:2107.10111</a>
&#x1F4C8; 2 <br>
<p>Martin Pilát</p></summary>
<p>

**Abstract:** The problem of coordinating the charging of electric vehicles gains more importance as the number of such vehicles grows. In this paper, we develop a method for the training of controllers for the coordination of EV charging. In contrast to most existing works on this topic, we require the controllers to preserve the privacy of the users, therefore we do not allow any communication from the controller to any third party.
  In order to train the controllers, we use the idea of imitation learning -- we first find an optimum solution for a relaxed version of the problem using quadratic optimization and then train the controllers to imitate this solution. We also investigate the effects of regularization of the optimum solution on the performance of the controllers. The method is evaluated on realistic data and shows improved performance and training speed compared to similar controllers trained using evolutionary algorithms.

</p>
</details>

<details><summary><b>On the Convergence of Prior-Guided Zeroth-Order Optimization Algorithms</b>
<a href="https://arxiv.org/abs/2107.10110">arxiv:2107.10110</a>
&#x1F4C8; 2 <br>
<p>Shuyu Cheng, Guoqiang Wu, Jun Zhu</p></summary>
<p>

**Abstract:** Zeroth-order (ZO) optimization is widely used to handle challenging tasks, such as query-based black-box adversarial attacks and reinforcement learning. Various attempts have been made to integrate prior information into the gradient estimation procedure based on finite differences, with promising empirical results. However, their convergence properties are not well understood. This paper makes an attempt to fill up this gap by analyzing the convergence of prior-guided ZO algorithms under a greedy descent framework with various gradient estimators. We provide a convergence guarantee for the prior-guided random gradient-free (PRGF) algorithms. Moreover, to further accelerate over greedy descent methods, we present a new accelerated random search (ARS) algorithm that incorporates prior information, together with a convergence analysis. Finally, our theoretical results are confirmed by experiments on several numerical benchmarks as well as adversarial attacks.

</p>
</details>

<details><summary><b>Adaptive Inducing Points Selection For Gaussian Processes</b>
<a href="https://arxiv.org/abs/2107.10066">arxiv:2107.10066</a>
&#x1F4C8; 2 <br>
<p>Théo Galy-Fajou, Manfred Opper</p></summary>
<p>

**Abstract:** Gaussian Processes (\textbf{GPs}) are flexible non-parametric models with strong probabilistic interpretation. While being a standard choice for performing inference on time series, GPs have few techniques to work in a streaming setting. \cite{bui2017streaming} developed an efficient variational approach to train online GPs by using sparsity techniques: The whole set of observations is approximated by a smaller set of inducing points (\textbf{IPs}) and moved around with new data. Both the number and the locations of the IPs will affect greatly the performance of the algorithm. In addition to optimizing their locations, we propose to adaptively add new points, based on the properties of the GP and the structure of the data.

</p>
</details>

<details><summary><b>KalmanNet: Neural Network Aided Kalman Filtering for Partially Known Dynamics</b>
<a href="https://arxiv.org/abs/2107.10043">arxiv:2107.10043</a>
&#x1F4C8; 2 <br>
<p>Guy Revach, Nir Shlezinger, Xiaoyong Ni, Adria Lopez Escoriza, Ruud J. G. van Sloun, Yonina C. Eldar</p></summary>
<p>

**Abstract:** Real-time state estimation of dynamical systems is a fundamental task in signal processing and control. For systems that are well-represented by a fully known linear Gaussian state space (SS) model, the celebrated Kalman filter (KF) is a low complexity optimal solution. However, both linearity of the underlying SS model and accurate knowledge of it are often not encountered in practice. Here, we present KalmanNet, a real-time state estimator that learns from data to carry out Kalman filtering under non-linear dynamics with partial information. By incorporating the structural SS model with a dedicated recurrent neural network module in the flow of the KF, we retain data efficiency and interpretability of the classic algorithm while implicitly learning complex dynamics from data. We numerically demonstrate that KalmanNet overcomes nonlinearities and model mismatch, outperforming classic filtering methods operating with both mismatched and accurate domain knowledge.

</p>
</details>

<details><summary><b>Learning Theorem Proving Components</b>
<a href="https://arxiv.org/abs/2107.10034">arxiv:2107.10034</a>
&#x1F4C8; 2 <br>
<p>Karel Chvalovský, Jan Jakubův, Miroslav Olšák, Josef Urban</p></summary>
<p>

**Abstract:** Saturation-style automated theorem provers (ATPs) based on the given clause procedure are today the strongest general reasoners for classical first-order logic. The clause selection heuristics in such systems are, however, often evaluating clauses in isolation, ignoring other clauses. This has changed recently by equipping the E/ENIGMA system with a graph neural network (GNN) that chooses the next given clause based on its evaluation in the context of previously selected clauses. In this work, we describe several algorithms and experiments with ENIGMA, advancing the idea of contextual evaluation based on learning important components of the graph of clauses.

</p>
</details>

<details><summary><b>Differentiable Feature Selection, a Reparameterization Approach</b>
<a href="https://arxiv.org/abs/2107.10030">arxiv:2107.10030</a>
&#x1F4C8; 2 <br>
<p>Jérémie Dona, Patrick Gallinari</p></summary>
<p>

**Abstract:** We consider the task of feature selection for reconstruction which consists in choosing a small subset of features from which whole data instances can be reconstructed. This is of particular importance in several contexts involving for example costly physical measurements, sensor placement or information compression. To break the intrinsic combinatorial nature of this problem, we formulate the task as optimizing a binary mask distribution enabling an accurate reconstruction. We then face two main challenges. One concerns differentiability issues due to the binary distribution. The second one corresponds to the elimination of redundant information by selecting variables in a correlated fashion which requires modeling the covariance of the binary distribution. We address both issues by introducing a relaxation of the problem via a novel reparameterization of the logitNormal distribution. We demonstrate that the proposed method provides an effective exploration scheme and leads to efficient feature selection for reconstruction through evaluation on several high dimensional image benchmarks. We show that the method leverages the intrinsic geometry of the data, facilitating reconstruction.

</p>
</details>

<details><summary><b>An artificial intelligence natural language processing pipeline for information extraction in neuroradiology</b>
<a href="https://arxiv.org/abs/2107.10021">arxiv:2107.10021</a>
&#x1F4C8; 2 <br>
<p>Henry Watkins, Robert Gray, Ashwani Jha, Parashkev Nachev</p></summary>
<p>

**Abstract:** The use of electronic health records in medical research is difficult because of the unstructured format. Extracting information within reports and summarising patient presentations in a way amenable to downstream analysis would be enormously beneficial for operational and clinical research. In this work we present a natural language processing pipeline for information extraction of radiological reports in neurology. Our pipeline uses a hybrid sequence of rule-based and artificial intelligence models to accurately extract and summarise neurological reports. We train and evaluate a custom language model on a corpus of 150000 radiological reports from National Hospital for Neurology and Neurosurgery, London MRI imaging. We also present results for standard NLP tasks on domain-specific neuroradiology datasets. We show our pipeline, called `neuroNLP', can reliably extract clinically relevant information from these reports, enabling downstream modelling of reports and associated imaging on a heretofore unprecedented scale.

</p>
</details>

<details><summary><b>Delving Into Deep Walkers: A Convergence Analysis of Random-Walk-Based Vertex Embeddings</b>
<a href="https://arxiv.org/abs/2107.10014">arxiv:2107.10014</a>
&#x1F4C8; 2 <br>
<p>Dominik Kloepfer, Angelica I. Aviles-Rivero, Daniel Heydecker</p></summary>
<p>

**Abstract:** Graph vertex embeddings based on random walks have become increasingly influential in recent years, showing good performance in several tasks as they efficiently transform a graph into a more computationally digestible format while preserving relevant information. However, the theoretical properties of such algorithms, in particular the influence of hyperparameters and of the graph structure on their convergence behaviour, have so far not been well-understood. In this work, we provide a theoretical analysis for random-walks based embeddings techniques. Firstly, we prove that, under some weak assumptions, vertex embeddings derived from random walks do indeed converge both in the single limit of the number of random walks $N \to \infty$ and in the double limit of both $N$ and the length of each random walk $L\to\infty$. Secondly, we derive concentration bounds quantifying the converge rate of the corpora for the single and double limits. Thirdly, we use these results to derive a heuristic for choosing the hyperparameters $N$ and $L$. We validate and illustrate the practical importance of our findings with a range of numerical and visual experiments on several graphs drawn from real-world applications.

</p>
</details>

<details><summary><b>Optimal Operation of Power Systems with Energy Storage under Uncertainty: A Scenario-based Method with Strategic Sampling</b>
<a href="https://arxiv.org/abs/2107.10013">arxiv:2107.10013</a>
&#x1F4C8; 2 <br>
<p>Ren Hu, Qifeng Li</p></summary>
<p>

**Abstract:** The multi-period dynamics of energy storage (ES), intermittent renewable generation and uncontrollable power loads, make the optimization of power system operation (PSO) challenging. A multi-period optimal PSO under uncertainty is formulated using the chance-constrained optimization (CCO) modeling paradigm, where the constraints include the nonlinear energy storage and AC power flow models. Based on the emerging scenario optimization method which does not rely on pre-known probability distribution functions, this paper develops a novel solution method for this challenging CCO problem. The proposed meth-od is computationally effective for mainly two reasons. First, the original AC power flow constraints are approximated by a set of learning-assisted quadratic convex inequalities based on a generalized least absolute shrinkage and selection operator. Second, considering the physical patterns of data and motived by learning-based sampling, the strategic sampling method is developed to significantly reduce the required number of scenarios through different sampling strategies. The simulation results on IEEE standard systems indicate that 1) the proposed strategic sampling significantly improves the computational efficiency of the scenario-based approach for solving the chance-constrained optimal PSO problem, 2) the data-driven convex approximation of power flow can be promising alternatives of nonlinear and nonconvex AC power flow.

</p>
</details>

<details><summary><b>Window Detection In Facade Imagery: A Deep Learning Approach Using Mask R-CNN</b>
<a href="https://arxiv.org/abs/2107.10006">arxiv:2107.10006</a>
&#x1F4C8; 2 <br>
<p>Nils Nordmark, Mola Ayenew</p></summary>
<p>

**Abstract:** The parsing of windows in building facades is a long-desired but challenging task in computer vision. It is crucial to urban analysis, semantic reconstruction, lifecycle analysis, digital twins, and scene parsing amongst other building-related tasks that require high-quality semantic data. This article investigates the usage of the mask R-CNN framework to be used for window detection of facade imagery input. We utilize transfer learning to train our proposed method on COCO weights with our own collected dataset of street view images of facades to produce instance segmentations of our new window class. Experimental results show that our suggested approach with a relatively small dataset trains the network only with transfer learning and augmentation achieves results on par with prior state-of-the-art window detection approaches, even without post-optimization techniques.

</p>
</details>

<details><summary><b>Deep Iterative 2D/3D Registration</b>
<a href="https://arxiv.org/abs/2107.10004">arxiv:2107.10004</a>
&#x1F4C8; 2 <br>
<p>Srikrishna Jaganathan, Jian Wang, Anja Borsdorf, Karthik Shetty, Andreas Maier</p></summary>
<p>

**Abstract:** Deep Learning-based 2D/3D registration methods are highly robust but often lack the necessary registration accuracy for clinical application. A refinement step using the classical optimization-based 2D/3D registration method applied in combination with Deep Learning-based techniques can provide the required accuracy. However, it also increases the runtime. In this work, we propose a novel Deep Learning driven 2D/3D registration framework that can be used end-to-end for iterative registration tasks without relying on any further refinement step. We accomplish this by learning the update step of the 2D/3D registration framework using Point-to-Plane Correspondences. The update step is learned using iterative residual refinement-based optical flow estimation, in combination with the Point-to-Plane correspondence solver embedded as a known operator. Our proposed method achieves an average runtime of around 8s, a mean re-projection distance error of 0.60 $\pm$ 0.40 mm with a success ratio of 97 percent and a capture range of 60 mm. The combination of high registration accuracy, high robustness, and fast runtime makes our solution ideal for clinical applications.

</p>
</details>

<details><summary><b>A Point Cloud Generative Model via Tree-Structured Graph Convolutions for 3D Brain Shape Reconstruction</b>
<a href="https://arxiv.org/abs/2107.09923">arxiv:2107.09923</a>
&#x1F4C8; 2 <br>
<p>Bowen Hu, Baiying Lei, Yanyan Shen, Yong Liu, Shuqiang Wang</p></summary>
<p>

**Abstract:** Fusing medical images and the corresponding 3D shape representation can provide complementary information and microstructure details to improve the operational performance and accuracy in brain surgery. However, compared to the substantial image data, it is almost impossible to obtain the intraoperative 3D shape information by using physical methods such as sensor scanning, especially in minimally invasive surgery and robot-guided surgery. In this paper, a general generative adversarial network (GAN) architecture based on graph convolutional networks is proposed to reconstruct the 3D point clouds (PCs) of brains by using one single 2D image, thus relieving the limitation of acquiring 3D shape data during surgery. Specifically, a tree-structured generative mechanism is constructed to use the latent vector effectively and transfer features between hidden layers accurately. With the proposed generative model, a spontaneous image-to-PC conversion is finished in real-time. Competitive qualitative and quantitative experimental results have been achieved on our model. In multiple evaluation methods, the proposed model outperforms another common point cloud generative model PointOutNet.

</p>
</details>

<details><summary><b>Design of Experiments for Stochastic Contextual Linear Bandits</b>
<a href="https://arxiv.org/abs/2107.09912">arxiv:2107.09912</a>
&#x1F4C8; 2 <br>
<p>Andrea Zanette, Kefan Dong, Jonathan Lee, Emma Brunskill</p></summary>
<p>

**Abstract:** In the stochastic linear contextual bandit setting there exist several minimax procedures for exploration with policies that are reactive to the data being acquired. In practice, there can be a significant engineering overhead to deploy these algorithms, especially when the dataset is collected in a distributed fashion or when a human in the loop is needed to implement a different policy. Exploring with a single non-reactive policy is beneficial in such cases. Assuming some batch contexts are available, we design a single stochastic policy to collect a good dataset from which a near-optimal policy can be extracted. We present a theoretical analysis as well as numerical experiments on both synthetic and real-world datasets.

</p>
</details>

<details><summary><b>Brain Inspired Computing Approach for the Optimization of the Thin Film Thickness of Polystyrene on the Glass Substrates</b>
<a href="https://arxiv.org/abs/2107.12156">arxiv:2107.12156</a>
&#x1F4C8; 1 <br>
<p>Akshansh Mishra, Devarrishi Dixit</p></summary>
<p>

**Abstract:** Advent in machine learning is leaving a deep impact on various sectors including the material science domain. The present paper highlights the application of various supervised machine learning regression algorithms such as polynomial regression, decision tree regression algorithm, random forest algorithm, support vector regression algorithm, and artificial neural network algorithm to determine the thin film thickness of Polystyrene on the glass substrates. The results showed that the polynomial regression machine learning algorithm outperforms all other machine learning models by yielding the coefficient of determination of 0.96 approximately and mean square error of 0.04 respectively.

</p>
</details>

<details><summary><b>High Frequency EEG Artifact Detection with Uncertainty via Early Exit Paradigm</b>
<a href="https://arxiv.org/abs/2107.10746">arxiv:2107.10746</a>
&#x1F4C8; 1 <br>
<p>Lorena Qendro, Alexander Campbell, Pietro Liò, Cecilia Mascolo</p></summary>
<p>

**Abstract:** Electroencephalography (EEG) is crucial for the monitoring and diagnosis of brain disorders. However, EEG signals suffer from perturbations caused by non-cerebral artifacts limiting their efficacy. Current artifact detection pipelines are resource-hungry and rely heavily on hand-crafted features. Moreover, these pipelines are deterministic in nature, making them unable to capture predictive uncertainty. We propose E4G, a deep learning framework for high frequency EEG artifact detection. Our framework exploits the early exit paradigm, building an implicit ensemble of models capable of capturing uncertainty. We evaluate our approach on the Temple University Hospital EEG Artifact Corpus (v2.0) achieving state-of-the-art classification results. In addition, E4G provides well-calibrated uncertainty metrics comparable to sampling techniques like Monte Carlo dropout in just a single forward pass. E4G opens the door to uncertainty-aware artifact detection supporting clinicians-in-the-loop frameworks.

</p>
</details>

<details><summary><b>mmPose-NLP: A Natural Language Processing Approach to Precise Skeletal Pose Estimation using mmWave Radars</b>
<a href="https://arxiv.org/abs/2107.10327">arxiv:2107.10327</a>
&#x1F4C8; 1 <br>
<p>Arindam Sengupta, Siyang Cao</p></summary>
<p>

**Abstract:** In this paper we presented mmPose-NLP, a novel Natural Language Processing (NLP) inspired Sequence-to-Sequence (Seq2Seq) skeletal key-point estimator using millimeter-wave (mmWave) radar data. To the best of the author's knowledge, this is the first method to precisely estimate upto 25 skeletal key-points using mmWave radar data alone. Skeletal pose estimation is critical in several applications ranging from autonomous vehicles, traffic monitoring, patient monitoring, gait analysis, to defense security forensics, and aid both preventative and actionable decision making. The use of mmWave radars for this task, over traditionally employed optical sensors, provide several advantages, primarily its operational robustness to scene lighting and adverse weather conditions, where optical sensor performance degrade significantly. The mmWave radar point-cloud (PCL) data is first voxelized (analogous to tokenization in NLP) and $N$ frames of the voxelized radar data (analogous to a text paragraph in NLP) is subjected to the proposed mmPose-NLP architecture, where the voxel indices of the 25 skeletal key-points (analogous to keyword extraction in NLP) are predicted. The voxel indices are converted back to real world 3-D coordinates using the voxel dictionary used during the tokenization process. Mean Absolute Error (MAE) metrics were used to measure the accuracy of the proposed system against the ground truth, with the proposed mmPose-NLP offering <3 cm localization errors in the depth, horizontal and vertical axes. The effect of the number of input frames vs performance/accuracy was also studied for N = {1,2,..,10}. A comprehensive methodology, results, discussions and limitations are presented in this paper. All the source codes and results are made available on GitHub for furthering research and development in this critical yet emerging domain of skeletal key-point estimation using mmWave radars.

</p>
</details>

<details><summary><b>Bridging the Gap between Spatial and Spectral Domains: A Unified Framework for Graph Neural Networks</b>
<a href="https://arxiv.org/abs/2107.10234">arxiv:2107.10234</a>
&#x1F4C8; 1 <br>
<p>Zhiqian Chen, Fanglan Chen, Lei Zhang, Taoran Ji, Kaiqun Fu, Liang Zhao, Feng Chen, Lingfei Wu, Charu Aggarwal, Chang-Tien Lu</p></summary>
<p>

**Abstract:** Deep learning's performance has been extensively recognized recently. Graph neural networks (GNNs) are designed to deal with graph-structural data that classical deep learning does not easily manage. Since most GNNs were created using distinct theories, direct comparisons are impossible. Prior research has primarily concentrated on categorizing existing models, with little attention paid to their intrinsic connections. The purpose of this study is to establish a unified framework that integrates GNNs based on spectral graph and approximation theory. The framework incorporates a strong integration between spatial- and spectral-based GNNs while tightly associating approaches that exist within each respective domain.

</p>
</details>

<details><summary><b>Objective video quality metrics application to video codecs comparisons: choosing the best for subjective quality estimation</b>
<a href="https://arxiv.org/abs/2107.10220">arxiv:2107.10220</a>
&#x1F4C8; 1 <br>
<p>Anastasia Antsiferova, Alexander Yakovenko, Nickolay Safonov, Dmitriy Kulikov, Alexander Gushin, Dmitriy Vatolin</p></summary>
<p>

**Abstract:** Quality assessment plays a key role in creating and comparing video compression algorithms. Despite the development of a large number of new methods for assessing quality, generally accepted and well-known codecs comparisons mainly use the classical methods like PSNR, SSIM and new method VMAF. These methods can be calculated following different rules: they can use different frame-by-frame averaging techniques or different summation of color components. In this paper, a fundamental comparison of various versions of generally accepted metrics is carried out to find the most relevant and recommended versions of video quality metrics to be used in codecs comparisons. For comparison, we used a set of videos encoded with video codecs of different standards, and visual quality scores collected for the resulting set of streams since 2018 until 2021

</p>
</details>

<details><summary><b>3D fluorescence microscopy data synthesis for segmentation and benchmarking</b>
<a href="https://arxiv.org/abs/2107.10180">arxiv:2107.10180</a>
&#x1F4C8; 1 <br>
<p>Dennis Eschweiler, Malte Rethwisch, Mareike Jarchow, Simon Koppers, Johannes Stegmaier</p></summary>
<p>

**Abstract:** Automated image processing approaches are indispensable for many biomedical experiments and help to cope with the increasing amount of microscopy image data in a fast and reproducible way. Especially state-of-the-art deep learning-based approaches most often require large amounts of annotated training data to produce accurate and generalist outputs, but they are often compromised by the general lack of those annotated data sets. In this work, we propose how conditional generative adversarial networks can be utilized to generate realistic image data for 3D fluorescence microscopy from annotation masks of 3D cellular structures. In combination with mask simulation approaches, we demonstrate the generation of fully-annotated 3D microscopy data sets that we make publicly available for training or benchmarking. An additional positional conditioning of the cellular structures enables the reconstruction of position-dependent intensity characteristics and allows to generate image data of different quality levels. A patch-wise working principle and a subsequent full-size reassemble strategy is used to generate image data of arbitrary size and different organisms. We present this as a proof-of-concept for the automated generation of fully-annotated training data sets requiring only a minimum of manual interaction to alleviate the need of manual annotations.

</p>
</details>

<details><summary><b>Predicting trajectory behaviour via machine-learned invariant manifolds</b>
<a href="https://arxiv.org/abs/2107.10154">arxiv:2107.10154</a>
&#x1F4C8; 1 <br>
<p>Vladimír Krajňák, Shibabrat Naik, Stephen Wiggins</p></summary>
<p>

**Abstract:** In this paper we use support vector machines (SVM) to develop a machine learning framework to discover the phase space structure that can distinguish between distinct reaction pathways. The machine learning model is trained using data from trajectories of Hamilton's equations but lends itself for use in molecular dynamics simulation. The framework is specifically designed to require minimal a priori knowledge of the dynamics in a system. We benchmark our approach with a model Hamiltonian for the reaction of an ion and a molecule due to Chesnavich consisting of two parts: a rigid, symmetric top representing the $\text{CH}_3^{+}$ ion, and a mobile $\text{H}$ atom. We begin with trajectories and use support vector machines to determine the boundaries between initial conditions corresponding to different classes of trajectories. We then show that these boundaries between different classes of trajectories approximate invariant phase space structures of the same type observed in earlier analyses of Chesnavich's model. Our approach is designed with extensions to higher-dimensional applications in mind. SVM is known to work well even with small amounts of data, therefore our approach is computationally better suited than existing methods for high-dimensional systems and systems where integrating trajectories is expensive.

</p>
</details>

<details><summary><b>Peer Selection with Noisy Assessments</b>
<a href="https://arxiv.org/abs/2107.10121">arxiv:2107.10121</a>
&#x1F4C8; 1 <br>
<p>Omer Lev, Nicholas Mattei, Paolo Turrini, Stanislav Zhydkov</p></summary>
<p>

**Abstract:** In the peer selection problem a group of agents must select a subset of themselves as winners for, e.g., peer-reviewed grants or prizes. Here, we take a Condorcet view of this aggregation problem, i.e., that there is a ground-truth ordering over the agents and we wish to select the best set of agents, subject to the noisy assessments of the peers. Given this model, some agents may be unreliable, while others might be self-interested, attempting to influence the outcome in their favour. In this paper we extend PeerNomination, the most accurate peer reviewing algorithm to date, into WeightedPeerNomination, which is able to handle noisy and inaccurate agents. To do this, we explicitly formulate assessors' reliability weights in a way that does not violate strategyproofness, and use this information to reweight their scores. We show analytically that a weighting scheme can improve the overall accuracy of the selection significantly. Finally, we implement several instances of reweighting methods and show empirically that our methods are robust in the face of noisy assessments.

</p>
</details>

<details><summary><b>Disentanglement via Mechanism Sparsity Regularization: A New Principle for Nonlinear ICA</b>
<a href="https://arxiv.org/abs/2107.10098">arxiv:2107.10098</a>
&#x1F4C8; 1 <br>
<p>Sébastien Lachapelle, Pau Rodríguez López, Yash Sharma, Katie Everett, Rémi Le Priol, Alexandre Lacoste, Simon Lacoste-Julien</p></summary>
<p>

**Abstract:** This work introduces a novel principle we call disentanglement via mechanism sparsity regularization, based on the idea that the dynamics of high-level concepts are often sparse. We propose a representation learning method that induces disentanglement by simultaneously learning the latent factors and the sparse causal graphical model that relates them. We develop a rigorous identifiability theory, building on recent nonlinear independent component analysis (ICA) results, that formalizes this principle and shows how the latent variables can be recovered up to permutation if one regularizes the latent mechanisms to be sparse and if some graph connectivity criterion is satisfied by the data generating process. As a special case of our framework, we show how one can leverage unknown-target interventions on the latent factors to disentangle them, thereby drawing further connections between ICA and causality. We also propose a VAE-based method in which the latent mechanisms are learned and regularized via binary masks, and validate our theory by showing it learns disentangled representations in simulations.

</p>
</details>

<details><summary><b>Boundary of Distribution Support Generator (BDSG): Sample Generation on the Boundary</b>
<a href="https://arxiv.org/abs/2107.09950">arxiv:2107.09950</a>
&#x1F4C8; 1 <br>
<p>Nikolaos Dionelis</p></summary>
<p>

**Abstract:** Generative models, such as Generative Adversarial Networks (GANs), have been used for unsupervised anomaly detection. While performance keeps improving, several limitations exist particularly attributed to difficulties at capturing multimodal supports and to the ability to approximate the underlying distribution closer to the tails, i.e. the boundary of the distribution's support. This paper proposes an approach that attempts to alleviate such shortcomings. We propose an invertible-residual-network-based model, the Boundary of Distribution Support Generator (BDSG). GANs generally do not guarantee the existence of a probability distribution and here, we use the recently developed Invertible Residual Network (IResNet) and Residual Flow (ResFlow), for density estimation. These models have not yet been used for anomaly detection. We leverage IResNet and ResFlow for Out-of-Distribution (OoD) sample detection and for sample generation on the boundary using a compound loss function that forces the samples to lie on the boundary. The BDSG addresses non-convex support, disjoint components, and multimodal distributions. Results on synthetic data and data from multimodal distributions, such as MNIST and CIFAR-10, demonstrate competitive performance compared to methods from the literature.

</p>
</details>

<details><summary><b>Composite Time-Frequency Analysis and Siamese Neural Network based Compound Interference Identification for Hopping Frequency System</b>
<a href="https://arxiv.org/abs/2108.10056">arxiv:2108.10056</a>
&#x1F4C8; 0 <br>
<p>Weiheng Jiang, Wanxin Yu, Jiangtian Nie, Zehui Xiong, Xiaogang Wu</p></summary>
<p>

**Abstract:** In a hostile environment, interference identification plays an important role in protecting the authorized communication system and avoiding its performance degradation. In this paper, the interference identification problem for the frequency hopping communication system is discussed. Considering presence of multiple and compound interference in the frequency hopping system, in order to fully extracted effective features of the interferences from the received signals, a composite time-frequency analysis method based on both the linear and bilinear transform is proposed. The time-frequency spectrograms obtained from the time-frequency analysis are constructed as matching pairs and input into the deep neural network for identification. In particular, the Siamese neural network is adopted as the classifier to perform the interference identification. That is, the paired spectrograms are input into the two sub-networks of the Siamese neural network to extract the features of the paired spectrograms. The Siamese neural network is trained and tested by calculating the gap between the generated features, and the interference type identification is realized by the trained Siamese neural network. The simulation results confirm that the proposed algorithm can obtain higher identification accuracy than both traditional single time-frequency representation based approach and the AlexNet transfer learning or convolutional neural network based methods.

</p>
</details>

<details><summary><b>Iterative Distillation for Better Uncertainty Estimates in Multitask Emotion Recognition</b>
<a href="https://arxiv.org/abs/2108.04228">arxiv:2108.04228</a>
&#x1F4C8; 0 <br>
<p>Didan Deng, Liang Wu, Bertram E. Shi</p></summary>
<p>

**Abstract:** When recognizing emotions, subtle nuances in displays of emotion generate ambiguity or uncertainty in emotion perception. Emotion uncertainty has been previously interpreted as inter-rater disagreement among multiple annotators. In this paper, we consider a more common and challenging scenario: modeling emotion uncertainty when only single emotion labels are available. From a Bayesian perspective, we propose to use deep ensembles to capture uncertainty for multiple emotion descriptors, i.e., action units, discrete expression labels and continuous descriptors. We further apply iterative self-distillation. Iterative distillation over multiple generations significantly improves performance in both emotion recognition and uncertainty estimation. Our method generates single student models that provide accurate estimates of uncertainty for in-domain samples and a student ensemble that can detect out-of-domain samples. Our experiments on emotion recognition and uncertainty estimation using the Aff-wild2 dataset demonstrate that our algorithm gives more reliable uncertainty estimates than both Temperature Scaling and Monte Carol Dropout.

</p>
</details>

<details><summary><b>Rethinking Trajectory Forecasting Evaluation</b>
<a href="https://arxiv.org/abs/2107.10297">arxiv:2107.10297</a>
&#x1F4C8; 0 <br>
<p>Boris Ivanovic, Marco Pavone</p></summary>
<p>

**Abstract:** Forecasting the behavior of other agents is an integral part of the modern robotic autonomy stack, especially in safety-critical scenarios with human-robot interaction, such as autonomous driving. In turn, there has been a significant amount of interest and research in trajectory forecasting, resulting in a wide variety of approaches. Common to all works, however, is the use of the same few accuracy-based evaluation metrics, e.g., displacement error and log-likelihood. While these metrics are informative, they are task-agnostic and predictions that are evaluated as equal can lead to vastly different outcomes, e.g., in downstream planning and decision making. In this work, we take a step back and critically evaluate current trajectory forecasting metrics, proposing task-aware metrics as a better measure of performance in systems where prediction is being deployed. We additionally present one example of such a metric, incorporating planning-awareness within existing trajectory forecasting metrics.

</p>
</details>

<details><summary><b>Correspondence-Free Point Cloud Registration with SO(3)-Equivariant Implicit Shape Representations</b>
<a href="https://arxiv.org/abs/2107.10296">arxiv:2107.10296</a>
&#x1F4C8; 0 <br>
<p>Minghan Zhu, Maani Ghaffari, Huei Peng</p></summary>
<p>

**Abstract:** This paper proposes a correspondence-free method for point cloud rotational registration. We learn an embedding for each point cloud in a feature space that preserves the SO(3)-equivariance property, enabled by recent developments in equivariant neural networks. The proposed shape registration method achieves three major advantages through combining equivariant feature learning with implicit shape models. First, the necessity of data association is removed because of the permutation-invariant property in network architectures similar to PointNet. Second, the registration in feature space can be solved in closed-form using Horn's method due to the SO(3)-equivariance property. Third, the registration is robust to noise in the point cloud because of the joint training of registration and implicit shape reconstruction. The experimental results show superior performance compared with existing correspondence-free deep registration methods.

</p>
</details>

<details><summary><b>How to Tell Deep Neural Networks What We Know: A Review of Methods for Inclusion of Domain-Knowledge</b>
<a href="https://arxiv.org/abs/2107.10295">arxiv:2107.10295</a>
&#x1F4C8; 0 <br>
<p>Tirtharaj Dash, Sharad Chitlangia, Aditya Ahuja, Ashwin Srinivasan</p></summary>
<p>

**Abstract:** We present a short survey of ways in which existing scientific knowledge are included when constructing models with neural networks. The inclusion of domain-knowledge is of special interest not just to constructing scientific assistants, but also, many other areas that involve understanding data using human-machine collaboration. In many such instances, machine-based model construction may benefit significantly from being provided with human-knowledge of the domain encoded in a sufficiently precise form. This paper examines the inclusion of domain-knowledge by means of changes to: the input, the loss-function, and the architecture of deep networks. The categorisation is for ease of exposition: in practice we expect a combination of such changes will be employed. In each category, we describe techniques that have been shown to yield significant changes in network performance.

</p>
</details>

<details><summary><b>Conditional GANs with Auxiliary Discriminative Classifier</b>
<a href="https://arxiv.org/abs/2107.10060">arxiv:2107.10060</a>
&#x1F4C8; 0 <br>
<p>Liang Hou, Qi Cao, Huawei Shen, Xueqi Cheng</p></summary>
<p>

**Abstract:** Conditional generative models aim to learn the underlying joint distribution of data and labels, and thus realize conditional generation. Among them, auxiliary classifier generative adversarial networks (AC-GAN) have been widely used, but suffer from the problem of low intra-class diversity on generated samples. In this paper, we point out that the fundamental reason is that the classifier of AC-GAN is generator-agnostic, and therefore cannot provide informative guidance to the generator to approximate the target distribution, resulting in minimization of conditional entropy that decreases the intra-class diversity. Motivated by this observation, we propose a novel conditional GAN with auxiliary \textit{discriminative} classifier (ADC-GAN) to resolve the problem of AC-GAN. Specifically, the proposed auxiliary \textit{discriminative} classifier becomes generator-aware by recognizing the labels of the real data and the generated data \textit{discriminatively}. Our theoretical analysis reveals that the generator can faithfully replicate the target distribution even without the original discriminator, making the proposed ADC-GAN robust to the hyper-parameter and stable on the training process. Extensive experimental results on synthetic and real-world datasets demonstrate the superiority of ADC-GAN on conditional generative modeling compared with competing methods.

</p>
</details>


[Next Page](2021/2021-07/2021-07-20.md)
