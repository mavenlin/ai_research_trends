Prev: [2022.06.10]({{ '/2022/06/10/2022.06.10.html' | relative_url }})  Next: [2022.06.12]({{ '/2022/06/12/2022.06.12.html' | relative_url }})
{% raw %}
## Summary for 2022-06-11, created on 2022-06-18


<details><summary><b>A Unified Continuous Learning Framework for Multi-modal Knowledge Discovery and Pre-training</b>
<a href="https://arxiv.org/abs/2206.05555">arxiv:2206.05555</a>
&#x1F4C8; 7 <br>
<p>Zhihao Fan, Zhongyu Wei, Jingjing Chen, Siyuan Wang, Zejun Li, Jiarong Xu, Xuanjing Huang</p></summary>
<p>

**Abstract:** Multi-modal pre-training and knowledge discovery are two important research topics in multi-modal machine learning. Nevertheless, none of existing works make attempts to link knowledge discovery with knowledge guided multi-modal pre-training. In this paper, we propose to unify them into a continuous learning framework for mutual improvement. Taking the open-domain uni-modal datasets of images and texts as input, we maintain a knowledge graph as the foundation to support these two tasks. For knowledge discovery, a pre-trained model is used to identify cross-modal links on the graph. For model pre-training, the knowledge graph is used as the external knowledge to guide the model updating. These two steps are iteratively performed in our framework for continuous learning. The experimental results on MS-COCO and Flickr30K with respect to both knowledge discovery and the pre-trained model validate the effectiveness of our framework.

</p>
</details>

<details><summary><b>Hierarchical Conditional Variational Autoencoder Based Acoustic Anomaly Detection</b>
<a href="https://arxiv.org/abs/2206.05460">arxiv:2206.05460</a>
&#x1F4C8; 6 <br>
<p>Harsh Purohit, Takashi Endo, Masaaki Yamamoto, Yohei Kawaguchi</p></summary>
<p>

**Abstract:** This paper aims to develop an acoustic signal-based unsupervised anomaly detection method for automatic machine monitoring. Existing approaches such as deep autoencoder (DAE), variational autoencoder (VAE), conditional variational autoencoder (CVAE) etc. have limited representation capabilities in the latent space and, hence, poor anomaly detection performance. Different models have to be trained for each different kind of machines to accurately perform the anomaly detection task. To solve this issue, we propose a new method named as hierarchical conditional variational autoencoder (HCVAE). This method utilizes available taxonomic hierarchical knowledge about industrial facility to refine the latent space representation. This knowledge helps model to improve the anomaly detection performance as well. We demonstrated the generalization capability of a single HCVAE model for different types of machines by using appropriate conditions. Additionally, to show the practicability of the proposed approach, (i) we evaluated HCVAE model on different domain and (ii) we checked the effect of partial hierarchical knowledge. Our results show that HCVAE method validates both of these points, and it outperforms the baseline system on anomaly detection task by utmost 15 % on the AUC score metric.

</p>
</details>

<details><summary><b>A Review on Plastic Artificial Neural Networks: Exploring the Intersection between Neural Architecture Search and Continual Learning</b>
<a href="https://arxiv.org/abs/2206.05625">arxiv:2206.05625</a>
&#x1F4C8; 5 <br>
<p>Mohamed Shahawy, Elhadj Benkhelifa, David White</p></summary>
<p>

**Abstract:** Despite the significant advances achieved in Artificial Neural Networks (ANNs), their design process remains notoriously tedious, depending primarily on intuition, experience and trial-and-error. This human-dependent process is often time-consuming and prone to errors. Furthermore, the models are generally bound to their training contexts, with no considerations of changes to their surrounding environments. Continual adaptability and automation of neural networks is of paramount importance to several domains where model accessibility is limited after deployment (e.g IoT devices, self-driving vehicles, etc). Additionally, even accessible models require frequent maintenance post-deployment to overcome issues such as Concept/Data Drift, which can be cumbersome and restrictive. The current state of the art on adaptive ANNs is still a premature area of research; nevertheless, Neural Architecture Search (NAS), a form of AutoML, and Continual Learning (CL) have recently gained an increasing momentum in the Deep Learning research field, aiming to provide more robust and adaptive ANN development frameworks. This study is the first extensive review on the intersection between AutoML and CL, outlining research directions for the different methods that can facilitate full automation and lifelong plasticity in ANNs.

</p>
</details>

<details><summary><b>A Theoretical Understanding of Neural Network Compression from Sparse Linear Approximation</b>
<a href="https://arxiv.org/abs/2206.05604">arxiv:2206.05604</a>
&#x1F4C8; 5 <br>
<p>Wenjing Yang, Ganghua Wang, Enmao Diao, Vahid Tarokh, Jie Ding, Yuhong Yang</p></summary>
<p>

**Abstract:** The goal of model compression is to reduce the size of a large neural network while retaining a comparable performance. As a result, computation and memory costs in resource-limited applications may be significantly reduced by dropping redundant weights, neurons, or layers. There have been many model compression algorithms proposed that provide impressive empirical success. However, a theoretical understanding of model compression is still limited. One problem is understanding if a network is more compressible than another of the same structure. Another problem is quantifying how much one can prune a network with theoretically guaranteed accuracy degradation. In this work, we propose to use the sparsity-sensitive $\ell_q$-norm ($0<q<1$) to characterize compressibility and provide a relationship between soft sparsity of the weights in the network and the degree of compression with a controlled accuracy degradation bound. We also develop adaptive algorithms for pruning each neuron in the network informed by our theory. Numerical studies demonstrate the promising performance of the proposed methods compared with standard pruning algorithms.

</p>
</details>

<details><summary><b>Learning to Generate Levels by Imitating Evolution</b>
<a href="https://arxiv.org/abs/2206.05497">arxiv:2206.05497</a>
&#x1F4C8; 5 <br>
<p>Ahmed Khalifa, Michael Cerny Green, Julian Togelius</p></summary>
<p>

**Abstract:** Search-based procedural content generation (PCG) is a well-known method used for level generation in games. Its key advantage is that it is generic and able to satisfy functional constraints. However, due to the heavy computational costs to run these algorithms online, search-based PCG is rarely utilized for real-time generation. In this paper, we introduce a new type of iterative level generator using machine learning. We train a model to imitate the evolutionary process and use the model to generate levels. This trained model is able to modify noisy levels sequentially to create better levels without the need for a fitness function during inference. We evaluate our trained models on a 2D maze generation task. We compare several different versions of the method: training the models either at the end of evolution (normal evolution) or every 100 generations (assisted evolution) and using the model as a mutation function during evolution. Using the assisted evolution process, the final trained models are able to generate mazes with a success rate of 99% and high diversity of 86%. This work opens the door to a new way of learning level generators guided by the evolutionary process and perhaps will increase the adoption of search-based PCG in the game industry.

</p>
</details>

<details><summary><b>NeuGuard: Lightweight Neuron-Guided Defense against Membership Inference Attacks</b>
<a href="https://arxiv.org/abs/2206.05565">arxiv:2206.05565</a>
&#x1F4C8; 4 <br>
<p>Nuo Xu, Binghui Wang, Ran Ran, Wujie Wen, Parv Venkitasubramaniam</p></summary>
<p>

**Abstract:** Membership inference attacks (MIAs) against machine learning models can lead to serious privacy risks for the training dataset used in the model training. In this paper, we propose a novel and effective Neuron-Guided Defense method named NeuGuard against membership inference attacks (MIAs). We identify a key weakness in existing defense mechanisms against MIAs wherein they cannot simultaneously defend against two commonly used neural network based MIAs, indicating that these two attacks should be separately evaluated to assure the defense effectiveness. We propose NeuGuard, a new defense approach that jointly controls the output and inner neurons' activation with the object to guide the model output of training set and testing set to have close distributions. NeuGuard consists of class-wise variance minimization targeting restricting the final output neurons and layer-wise balanced output control aiming to constrain the inner neurons in each layer. We evaluate NeuGuard and compare it with state-of-the-art defenses against two neural network based MIAs, five strongest metric based MIAs including the newly proposed label-only MIA on three benchmark datasets. Results show that NeuGuard outperforms the state-of-the-art defenses by offering much improved utility-privacy trade-off, generality, and overhead.

</p>
</details>

<details><summary><b>TileGen: Tileable, Controllable Material Generation and Capture</b>
<a href="https://arxiv.org/abs/2206.05649">arxiv:2206.05649</a>
&#x1F4C8; 3 <br>
<p>Xilong Zhou, Miloš Hašan, Valentin Deschaintre, Paul Guerrero, Kalyan Sunkavalli, Nima Kalantari</p></summary>
<p>

**Abstract:** Recent methods (e.g. MaterialGAN) have used unconditional GANs to generate per-pixel material maps, or as a prior to reconstruct materials from input photographs. These models can generate varied random material appearance, but do not have any mechanism to constrain the generated material to a specific category or to control the coarse structure of the generated material, such as the exact brick layout on a brick wall. Furthermore, materials reconstructed from a single input photo commonly have artifacts and are generally not tileable, which limits their use in practical content creation pipelines. We propose TileGen, a generative model for SVBRDFs that is specific to a material category, always tileable, and optionally conditional on a provided input structure pattern. TileGen is a variant of StyleGAN whose architecture is modified to always produce tileable (periodic) material maps. In addition to the standard "style" latent code, TileGen can optionally take a condition image, giving a user direct control over the dominant spatial (and optionally color) features of the material. For example, in brick materials, the user can specify a brick layout and the brick color, or in leather materials, the locations of wrinkles and folds. Our inverse rendering approach can find a material perceptually matching a single target photograph by optimization. This reconstruction can also be conditional on a user-provided pattern. The resulting materials are tileable, can be larger than the target image, and are editable by varying the condition.

</p>
</details>

<details><summary><b>Density Regression and Uncertainty Quantification with Bayesian Deep Noise Neural Networks</b>
<a href="https://arxiv.org/abs/2206.05643">arxiv:2206.05643</a>
&#x1F4C8; 3 <br>
<p>Daiwei Zhang, Tianci Liu, Jian Kang</p></summary>
<p>

**Abstract:** Deep neural network (DNN) models have achieved state-of-the-art predictive accuracy in a wide range of supervised learning applications. However, accurately quantifying the uncertainty in DNN predictions remains a challenging task. For continuous outcome variables, an even more difficult problem is to estimate the predictive density function, which not only provides a natural quantification of the predictive uncertainty, but also fully captures the random variation in the outcome. In this work, we propose the Bayesian Deep Noise Neural Network (B-DeepNoise), which generalizes standard Bayesian DNNs by extending the random noise variable from the output layer to all hidden layers. The latent random noise equips B-DeepNoise with the flexibility to approximate highly complex predictive distributions and accurately quantify predictive uncertainty. For posterior computation, the unique structure of B-DeepNoise leads to a closed-form Gibbs sampling algorithm that iteratively simulates from the posterior full conditional distributions of the model parameters, circumventing computationally intensive Metropolis-Hastings methods. A theoretical analysis of B-DeepNoise establishes a recursive representation of the predictive distribution and decomposes the predictive variance with respect to the latent parameters. We evaluate B-DeepNoise against existing methods on benchmark regression datasets, demonstrating its superior performance in terms of prediction accuracy, uncertainty quantification accuracy, and uncertainty quantification efficiency. To illustrate our method's usefulness in scientific studies, we apply B-DeepNoise to predict general intelligence from neuroimaging features in the Adolescent Brain Cognitive Development (ABCD) project.

</p>
</details>

<details><summary><b>An Unsupervised Deep-Learning Method for Bone Age Assessment</b>
<a href="https://arxiv.org/abs/2206.05641">arxiv:2206.05641</a>
&#x1F4C8; 3 <br>
<p>Hao Zhu, Wan-Jing Nie, Yue-Jie Hou, Qi-Meng Du, Si-Jing Li, Chi-Chun Zhou</p></summary>
<p>

**Abstract:** The bone age, reflecting the degree of development of the bones, can be used to predict the adult height and detect endocrine diseases of children. Both examinations of radiologists and variability of operators have a significant impact on bone age assessment. To decrease human intervention , machine learning algorithms are used to assess the bone age automatically. However, conventional supervised deep-learning methods need pre-labeled data. In this paper, based on the convolutional auto-encoder with constraints (CCAE), an unsupervised deep-learning model proposed in the classification of the fingerprint, we propose this model for the classification of the bone age and baptize it BA-CCAE. In the proposed BA-CCAE model, the key regions of the raw X-ray images of the bone age are encoded, yielding the latent vectors. The K-means clustering algorithm is used to obtain the final classifications by grouping the latent vectors of the bone images. A set of experiments on the Radiological Society of North America pediatric bone age dataset (RSNA) show that the accuracy of classifications at 48-month intervals is 76.15%. Although the accuracy now is lower than most of the existing supervised models, the proposed BA-CCAE model can establish the classification of bone age without any pre-labeled data, and to the best of our knowledge, the proposed BA-CCAE is one of the few trails using the unsupervised deep-learning method for the bone age assessment.

</p>
</details>

<details><summary><b>Synthetic PET via Domain Translation of 3D MRI</b>
<a href="https://arxiv.org/abs/2206.05618">arxiv:2206.05618</a>
&#x1F4C8; 3 <br>
<p>Abhejit Rajagopal, Yutaka Natsuaki, Kristen Wangerin, Mahdjoub Hamdi, Hongyu An, John J. Sunderland, Richard Laforest, Paul E. Kinahan, Peder E. Z. Larson, Thomas A. Hope</p></summary>
<p>

**Abstract:** Historically, patient datasets have been used to develop and validate various reconstruction algorithms for PET/MRI and PET/CT. To enable such algorithm development, without the need for acquiring hundreds of patient exams, in this paper we demonstrate a deep learning technique to generate synthetic but realistic whole-body PET sinograms from abundantly-available whole-body MRI. Specifically, we use a dataset of 56 $^{18}$F-FDG-PET/MRI exams to train a 3D residual UNet to predict physiologic PET uptake from whole-body T1-weighted MRI. In training we implemented a balanced loss function to generate realistic uptake across a large dynamic range and computed losses along tomographic lines of response to mimic the PET acquisition. The predicted PET images are forward projected to produce synthetic PET time-of-flight (ToF) sinograms that can be used with vendor-provided PET reconstruction algorithms, including using CT-based attenuation correction (CTAC) and MR-based attenuation correction (MRAC). The resulting synthetic data recapitulates physiologic $^{18}$F-FDG uptake, e.g. high uptake localized to the brain and bladder, as well as uptake in liver, kidneys, heart and muscle. To simulate abnormalities with high uptake, we also insert synthetic lesions. We demonstrate that this synthetic PET data can be used interchangeably with real PET data for the PET quantification task of comparing CT and MR-based attenuation correction methods, achieving $\leq 7.6\%$ error in mean-SUV compared to using real data. These results together show that the proposed synthetic PET data pipeline can be reasonably used for development, evaluation, and validation of PET/MRI reconstruction methods.

</p>
</details>

<details><summary><b>Federated Learning with Research Prototypes for Multi-Center MRI-based Detection of Prostate Cancer with Diverse Histopathology</b>
<a href="https://arxiv.org/abs/2206.05617">arxiv:2206.05617</a>
&#x1F4C8; 3 <br>
<p>Abhejit Rajagopal, Ekaterina Redekop, Anil Kemisetti, Rushi Kulkarni, Steven Raman, Kirti Magudia, Corey W. Arnold, Peder E. Z. Larson</p></summary>
<p>

**Abstract:** Early prostate cancer detection and staging from MRI are extremely challenging tasks for both radiologists and deep learning algorithms, but the potential to learn from large and diverse datasets remains a promising avenue to increase their generalization capability both within- and across clinics. To enable this for prototype-stage algorithms, where the majority of existing research remains, in this paper we introduce a flexible federated learning framework for cross-site training, validation, and evaluation of deep prostate cancer detection algorithms. Our approach utilizes an abstracted representation of the model architecture and data, which allows unpolished prototype deep learning models to be trained without modification using the NVFlare federated learning framework. Our results show increases in prostate cancer detection and classification accuracy using a specialized neural network model and diverse prostate biopsy data collected at two University of California research hospitals, demonstrating the efficacy of our approach in adapting to different datasets and improving MR-biomarker discovery. We open-source our FLtools system, which can be easily adapted to other deep learning projects for medical imaging.

</p>
</details>

<details><summary><b>Machine learning approaches for COVID-19 detection from chest X-ray imaging: A Systematic Review</b>
<a href="https://arxiv.org/abs/2206.05615">arxiv:2206.05615</a>
&#x1F4C8; 3 <br>
<p>Harold Brayan Arteaga-Arteaga, Melissa delaPava, Alejandro Mora-Rubio, Mario Alejandro Bravo-Ortíz, Jesus Alejandro Alzate-Grisales, Daniel Arias-Garzón, Luis Humberto López-Murillo, Felipe Buitrago-Carmona, Juan Pablo Villa-Pulgarín, Esteban Mercado-Ruiz, Simon Orozco-Arias, M. Hassaballah, Maria de la Iglesia-Vaya, Oscar Cardona-Morales, Reinel Tabares-Soto</p></summary>
<p>

**Abstract:** There is a necessity to develop affordable, and reliable diagnostic tools, which allow containing the COVID-19 spreading. Machine Learning (ML) algorithms have been proposed to design support decision-making systems to assess chest X-ray images, which have proven to be useful to detect and evaluate disease progression. Many research articles are published around this subject, which makes it difficult to identify the best approaches for future work. This paper presents a systematic review of ML applied to COVID-19 detection using chest X-ray images, aiming to offer a baseline for researchers in terms of methods, architectures, databases, and current limitations.

</p>
</details>

<details><summary><b>MammoDL: Mammographic Breast Density Estimation using Federated Learning</b>
<a href="https://arxiv.org/abs/2206.05575">arxiv:2206.05575</a>
&#x1F4C8; 3 <br>
<p>Keshava Katti, Ramya Muthukrishnan, Angelina Heyler, Sarthak Pati, Aprupa Alahari, Michael Sanborn, Emily F. Conant, Christopher Scott, Stacey Winham, Celine Vachon, Pratik Chaudhari, Despina Kontos, Spyridon Bakas</p></summary>
<p>

**Abstract:** Assessing breast cancer risk from imaging remains a subjective process, in which radiologists employ computer aided detection (CAD) systems or qualitative visual assessment to estimate breast percent density (PD). More advanced machine learning (ML) models have become the most promising way to quantify breast cancer risk for early, accurate, and equitable diagnoses, but training such models in medical research is often restricted to small, single-institution data. Since patient demographics and imaging characteristics may vary considerably across imaging sites, models trained on single-institution data tend not to generalize well. In response to this problem, MammoDL is proposed, an open-source software tool that leverages UNet architecture to accurately estimate breast PD and complexity from digital mammography (DM). With the Open Federated Learning (OpenFL) library, this solution enables secure training on datasets across multiple institutions. MammoDL is a leaner, more flexible model than its predecessors, boasting improved generalization due to federation-enabled training on larger, more representative datasets.

</p>
</details>

<details><summary><b>A Simplified Un-Supervised Learning Based Approach for Ink Mismatch Detection in Handwritten Hyper-Spectral Document Images</b>
<a href="https://arxiv.org/abs/2206.05539">arxiv:2206.05539</a>
&#x1F4C8; 3 <br>
<p>Muhammad Farhan Humayun, Hassan Waseem Malik, Ahmed Ahsan Alvi</p></summary>
<p>

**Abstract:** Hyper-spectral imaging has become the latest trend in the field of optical imaging systems. Among various other applications, hyper-spectral imaging has been widely used for analysis of printed and handwritten documents. This paper proposes an efficient technique for estimating the number of different but visibly similar inks present in a Hyper spectral Document Image. Our approach is based on un-supervised learning and does not require any prior knowledge of the dataset. The algorithm was tested on the iVision HHID dataset and has achieved comparable results with the state of the algorithms present in the literature. This work can prove to be effective when employed during the early stages of forgery detection in Hyper-spectral Document Images.

</p>
</details>

<details><summary><b>Bridging the Gap Between Training and Inference of Bayesian Controllable Language Models</b>
<a href="https://arxiv.org/abs/2206.05519">arxiv:2206.05519</a>
&#x1F4C8; 3 <br>
<p>Han Liu, Bingning Wang, Ting Yao, Haijin Liang, Jianjin Xu, Xiaolin Hu</p></summary>
<p>

**Abstract:** Large-scale pre-trained language models have achieved great success on natural language generation tasks. However, it is difficult to control the pre-trained language models to generate sentences with the desired attribute such as topic and sentiment, etc. Recently, Bayesian Controllable Language Models (BCLMs) have been shown to be efficient in controllable language generation. Rather than fine-tuning the parameters of pre-trained language models, BCLMs use external discriminators to guide the generation of pre-trained language models. However, the mismatch between training and inference of BCLMs limits the performance of the models. To address the problem, in this work we propose a "Gemini Discriminator" for controllable language generation which alleviates the mismatch problem with a small computational cost. We tested our method on two controllable language generation tasks: sentiment control and topic control. On both tasks, our method reached achieved new state-of-the-art results in automatic and human evaluations.

</p>
</details>

<details><summary><b>A Review of Causality for Learning Algorithms in Medical Image Analysis</b>
<a href="https://arxiv.org/abs/2206.05498">arxiv:2206.05498</a>
&#x1F4C8; 3 <br>
<p>Athanasios Vlontzos, Daniel Rueckert, Bernhard Kainz</p></summary>
<p>

**Abstract:** Medical image analysis is a vibrant research area that offers doctors and medical practitioners invaluable insight and the ability to accurately diagnose and monitor disease. Machine learning provides an additional boost for this area. However, machine learning for medical image analysis is particularly vulnerable to natural biases like domain shifts that affect algorithmic performance and robustness. In this paper we analyze machine learning for medical image analysis within the framework of Technology Readiness Levels and review how causal analysis methods can fill a gap when creating robust and adaptable medical image analysis algorithms. We review methods using causality in medical imaging AI/ML and find that causal analysis has the potential to mitigate critical problems for clinical translation but that uptake and clinical downstream research has been limited so far.

</p>
</details>

<details><summary><b>Kaggle Kinship Recognition Challenge: Introduction of Convolution-Free Model to boost conventional</b>
<a href="https://arxiv.org/abs/2206.05488">arxiv:2206.05488</a>
&#x1F4C8; 3 <br>
<p>Mingchuan Tian, Guangway Teng, Yipeng Bao</p></summary>
<p>

**Abstract:** This work aims to explore a convolution-free base classifier that can be used to widen the variations of the conventional ensemble classifier. Specifically, we propose Vision Transformers as base classifiers to combine with CNNs for a unique ensemble solution in Kaggle kinship recognition. In this paper, we verify our proposed idea by implementing and optimizing variants of the Vision Transformer model on top of the existing CNN models. The combined models achieve better scores than conventional ensemble classifiers based solely on CNN variants. We demonstrate that highly optimized CNN ensembles publicly available on the Kaggle Discussion board can easily achieve a significant boost in ROC score by simply ensemble with variants of the Vision Transformer model due to low correlation.

</p>
</details>

<details><summary><b>Svadhyaya system for the Second Diagnosing COVID-19 using Acoustics Challenge 2021</b>
<a href="https://arxiv.org/abs/2206.05462">arxiv:2206.05462</a>
&#x1F4C8; 3 <br>
<p>Deepak Mittal, Amir H. Poorjam, Debottam Dutta, Debarpan Bhattacharya, Zemin Yu, Sriram Ganapathy, Maneesh Singh</p></summary>
<p>

**Abstract:** This report describes the system used for detecting COVID-19 positives using three different acoustic modalities, namely speech, breathing, and cough in the second DiCOVA challenge. The proposed system is based on the combination of 4 different approaches, each focusing more on one aspect of the problem, and reaches the blind test AUCs of 86.41, 77.60, and 84.55, in the breathing, cough, and speech tracks, respectively, and the AUC of 85.37 in the fusion of these three tracks.

</p>
</details>

<details><summary><b>Learned reconstruction with convergence guarantees</b>
<a href="https://arxiv.org/abs/2206.05431">arxiv:2206.05431</a>
&#x1F4C8; 3 <br>
<p>Subhadip Mukherjee, Andreas Hauptmann, Ozan Öktem, Marcelo Pereyra, Carola-Bibiane Schönlieb</p></summary>
<p>

**Abstract:** In recent years, deep learning has achieved remarkable empirical success for image reconstruction. This has catalyzed an ongoing quest for precise characterization of correctness and reliability of data-driven methods in critical use-cases, for instance in medical imaging. Notwithstanding the excellent performance and efficacy of deep learning-based methods, concerns have been raised regarding their stability, or lack thereof, with serious practical implications. Significant advances have been made in recent years to unravel the inner workings of data-driven image recovery methods, challenging their widely perceived black-box nature. In this article, we will specify relevant notions of convergence for data-driven image reconstruction, which will form the basis of a survey of learned methods with mathematically rigorous reconstruction guarantees. An example that is highlighted is the role of ICNN, offering the possibility to combine the power of deep learning with classical convex regularization theory for devising methods that are provably convergent.
  This survey article is aimed at both methodological researchers seeking to advance the frontiers of our understanding of data-driven image reconstruction methods as well as practitioners, by providing an accessible description of convergence concepts and by placing some of the existing empirical practices on a solid mathematical foundation.

</p>
</details>

<details><summary><b>DeepEmotex: Classifying Emotion in Text Messages using Deep Transfer Learning</b>
<a href="https://arxiv.org/abs/2206.06775">arxiv:2206.06775</a>
&#x1F4C8; 2 <br>
<p>Maryam Hasan, Elke Rundensteiner, Emmanuel Agu</p></summary>
<p>

**Abstract:** Transfer learning has been widely used in natural language processing through deep pretrained language models, such as Bidirectional Encoder Representations from Transformers and Universal Sentence Encoder. Despite the great success, language models get overfitted when applied to small datasets and are prone to forgetting when fine-tuned with a classifier. To remedy this problem of forgetting in transferring deep pretrained language models from one domain to another domain, existing efforts explore fine-tuning methods to forget less. We propose DeepEmotex an effective sequential transfer learning method to detect emotion in text. To avoid forgetting problem, the fine-tuning step is instrumented by a large amount of emotion-labeled data collected from Twitter. We conduct an experimental study using both curated Twitter data sets and benchmark data sets. DeepEmotex models achieve over 91% accuracy for multi-class emotion classification on test dataset. We evaluate the performance of the fine-tuned DeepEmotex models in classifying emotion in EmoInt and Stimulus benchmark datasets. The models correctly classify emotion in 73% of the instances in the benchmark datasets. The proposed DeepEmotex-BERT model outperforms Bi-LSTM result on the benchmark datasets by 23%. We also study the effect of the size of the fine-tuning dataset on the accuracy of our models. Our evaluation results show that fine-tuning with a large set of emotion-labeled data improves both the robustness and effectiveness of the resulting target task model.

</p>
</details>

<details><summary><b>Variational Bayes Deep Operator Network: A data-driven Bayesian solver for parametric differential equations</b>
<a href="https://arxiv.org/abs/2206.05655">arxiv:2206.05655</a>
&#x1F4C8; 2 <br>
<p>Shailesh Garg, Souvik Chakraborty</p></summary>
<p>

**Abstract:** Neural network based data-driven operator learning schemes have shown tremendous potential in computational mechanics. DeepONet is one such neural network architecture which has gained widespread appreciation owing to its excellent prediction capabilities. Having said that, being set in a deterministic framework exposes DeepONet architecture to the risk of overfitting, poor generalization and in its unaltered form, it is incapable of quantifying the uncertainties associated with its predictions. We propose in this paper, a Variational Bayes DeepONet (VB-DeepONet) for operator learning, which can alleviate these limitations of DeepONet architecture to a great extent and give user additional information regarding the associated uncertainty at the prediction stage. The key idea behind neural networks set in Bayesian framework is that, the weights and bias of the neural network are treated as probability distributions instead of point estimates and, Bayesian inference is used to update their prior distribution. Now, to manage the computational cost associated with approximating the posterior distribution, the proposed VB-DeepONet uses \textit{variational inference}. Unlike Markov Chain Monte Carlo schemes, variational inference has the capacity to take into account high dimensional posterior distributions while keeping the associated computational cost low. Different examples covering mechanics problems like diffusion reaction, gravity pendulum, advection diffusion have been shown to illustrate the performance of the proposed VB-DeepONet and comparisons have also been drawn against DeepONet set in deterministic framework.

</p>
</details>

<details><summary><b>Preprocessing Enhanced Image Compression for Machine Vision</b>
<a href="https://arxiv.org/abs/2206.05650">arxiv:2206.05650</a>
&#x1F4C8; 2 <br>
<p>Guo Lu, Xingtong Ge, Tianxiong Zhong, Jing Geng, Qiang Hu</p></summary>
<p>

**Abstract:** Recently, more and more images are compressed and sent to the back-end devices for the machine analysis tasks~(\textit{e.g.,} object detection) instead of being purely watched by humans. However, most traditional or learned image codecs are designed to minimize the distortion of the human visual system without considering the increased demand from machine vision systems. In this work, we propose a preprocessing enhanced image compression method for machine vision tasks to address this challenge. Instead of relying on the learned image codecs for end-to-end optimization, our framework is built upon the traditional non-differential codecs, which means it is standard compatible and can be easily deployed in practical applications. Specifically, we propose a neural preprocessing module before the encoder to maintain the useful semantic information for the downstream tasks and suppress the irrelevant information for bitrate saving. Furthermore, our neural preprocessing module is quantization adaptive and can be used in different compression ratios. More importantly, to jointly optimize the preprocessing module with the downstream machine vision tasks, we introduce the proxy network for the traditional non-differential codecs in the back-propagation stage. We provide extensive experiments by evaluating our compression method for two representative downstream tasks with different backbone networks. Experimental results show our method achieves a better trade-off between the coding bitrate and the performance of the downstream machine vision tasks by saving about 20% bitrate.

</p>
</details>

<details><summary><b>A Fast Alternating Minimization Algorithm for Coded Aperture Snapshot Spectral Imaging Based on Sparsity and Deep Image Priors</b>
<a href="https://arxiv.org/abs/2206.05647">arxiv:2206.05647</a>
&#x1F4C8; 2 <br>
<p>Qile Zhao, Xianhong Zhao, Xu Ma, Xudong Chen, Gonzalo R. Arce</p></summary>
<p>

**Abstract:** Coded aperture snapshot spectral imaging (CASSI) is a technique used to reconstruct three-dimensional hyperspectral images (HSIs) from one or several two-dimensional projection measurements. However, fewer projection measurements or more spectral channels leads to a severly ill-posed problem, in which case regularization methods have to be applied. In order to significantly improve the accuracy of reconstruction, this paper proposes a fast alternating minimization algorithm based on the sparsity and deep image priors (Fama-SDIP) of natural images. By integrating deep image prior (DIP) into the principle of compressive sensing (CS) reconstruction, the proposed algorithm can achieve state-of-the-art results without any training dataset. Extensive experiments show that Fama-SDIP method significantly outperforms prevailing leading methods on simulation and real HSI datasets.

</p>
</details>

<details><summary><b>Gradient Boosting Performs Low-Rank Gaussian Process Inference</b>
<a href="https://arxiv.org/abs/2206.05608">arxiv:2206.05608</a>
&#x1F4C8; 2 <br>
<p>Aleksei Ustimenko, Artem Beliakov, Liudmila Prokhorenkova</p></summary>
<p>

**Abstract:** This paper shows that gradient boosting based on symmetric decision trees can be equivalently reformulated as a kernel method that converges to the solution of a certain Kernel Ridgeless Regression problem. Thus, for low-rank kernels, we obtain the convergence to a Gaussian Process' posterior mean, which, in turn, allows us to easily transform gradient boosting into a sampler from the posterior to provide better knowledge uncertainty estimates through Monte-Carlo estimation of the posterior variance. We show that the proposed sampler allows for better knowledge uncertainty estimates leading to improved out-of-domain detection.

</p>
</details>

<details><summary><b>Federated Offline Reinforcement Learning</b>
<a href="https://arxiv.org/abs/2206.05581">arxiv:2206.05581</a>
&#x1F4C8; 2 <br>
<p>Doudou Zhou, Yufeng Zhang, Aaron Sonabend-W, Zhaoran Wang, Junwei Lu, Tianxi Cai</p></summary>
<p>

**Abstract:** Evidence-based or data-driven dynamic treatment regimes are essential for personalized medicine, which can benefit from offline reinforcement learning (RL). Although massive healthcare data are available across medical institutions, they are prohibited from sharing due to privacy constraints. Besides, heterogeneity exists in different sites. As a result, federated offline RL algorithms are necessary and promising to deal with the problems. In this paper, we propose a multi-site Markov decision process model which allows both homogeneous and heterogeneous effects across sites. The proposed model makes the analysis of the site-level features possible. We design the first federated policy optimization algorithm for offline RL with sample complexity. The proposed algorithm is communication-efficient and privacy-preserving, which requires only a single round of communication interaction by exchanging summary statistics. We give a theoretical guarantee for the proposed algorithm without the assumption of sufficient action coverage, where the suboptimality for the learned policies is comparable to the rate as if data is not distributed. Extensive simulations demonstrate the effectiveness of the proposed algorithm. The method is applied to a sepsis data set in multiple sites to illustrate its use in clinical settings.

</p>
</details>

<details><summary><b>Parameter Convex Neural Networks</b>
<a href="https://arxiv.org/abs/2206.05562">arxiv:2206.05562</a>
&#x1F4C8; 2 <br>
<p>Jingcheng Zhou, Wei Wei, Xing Li, Bowen Pang, Zhiming Zheng</p></summary>
<p>

**Abstract:** Deep learning utilizing deep neural networks (DNNs) has achieved a lot of success recently in many important areas such as computer vision, natural language processing, and recommendation systems. The lack of convexity for DNNs has been seen as a major disadvantage of many optimization methods, such as stochastic gradient descent, which greatly reduces the genelization of neural network applications. We realize that the convexity make sense in the neural network and propose the exponential multilayer neural network (EMLP), a class of parameter convex neural network (PCNN) which is convex with regard to the parameters of the neural network under some conditions that can be realized. Besides, we propose the convexity metric for the two-layer EGCN and test the accuracy when the convexity metric changes. For late experiments, we use the same architecture to make the exponential graph convolutional network (EGCN) and do the experiment on the graph classificaion dataset in which our model EGCN performs better than the graph convolutional network (GCN) and the graph attention network (GAT).

</p>
</details>

<details><summary><b>Model-based Offline Imitation Learning with Non-expert Data</b>
<a href="https://arxiv.org/abs/2206.05521">arxiv:2206.05521</a>
&#x1F4C8; 2 <br>
<p>Jeongwon Park, Lin Yang</p></summary>
<p>

**Abstract:** Although Behavioral Cloning (BC) in theory suffers compounding errors, its scalability and simplicity still makes it an attractive imitation learning algorithm. In contrast, imitation approaches with adversarial training typically does not share the same problem, but necessitates interactions with the environment. Meanwhile, most imitation learning methods only utilises optimal datasets, which could be significantly more expensive to obtain than its suboptimal counterpart. A question that arises is, can we utilise the suboptimal dataset in a principled manner, which otherwise would have been idle? We propose a scalable model-based offline imitation learning algorithmic framework that leverages datasets collected by both suboptimal and optimal policies, and show that its worst case suboptimality becomes linear in the time horizon with respect to the expert samples. We empirically validate our theoretical results and show that the proposed method \textit{always} outperforms BC in the low data regime on simulated continuous control domains

</p>
</details>

<details><summary><b>Deep Learning-Based MR Image Re-parameterization</b>
<a href="https://arxiv.org/abs/2206.05516">arxiv:2206.05516</a>
&#x1F4C8; 2 <br>
<p>Abhijeet Narang, Abhigyan Raj, Mihaela Pop, Mehran Ebrahimi</p></summary>
<p>

**Abstract:** Magnetic resonance (MR) image re-parameterization refers to the process of generating via simulations of an MR image with a new set of MRI scanning parameters. Different parameter values generate distinct contrast between different tissues, helping identify pathologic tissue. Typically, more than one scan is required for diagnosis; however, acquiring repeated scans can be costly, time-consuming, and difficult for patients. Thus, using MR image re-parameterization to predict and estimate the contrast in these imaging scans can be an effective alternative. In this work, we propose a novel deep learning (DL) based convolutional model for MRI re-parameterization. Based on our preliminary results, DL-based techniques hold the potential to learn the non-linearities that govern the re-parameterization.

</p>
</details>

<details><summary><b>DRAformer: Differentially Reconstructed Attention Transformer for Time-Series Forecasting</b>
<a href="https://arxiv.org/abs/2206.05495">arxiv:2206.05495</a>
&#x1F4C8; 2 <br>
<p>Benhan Li, Shengdong Du, Tianrui Li, Jie Hu, Zhen Jia</p></summary>
<p>

**Abstract:** Time-series forecasting plays an important role in many real-world scenarios, such as equipment life cycle forecasting, weather forecasting, and traffic flow forecasting. It can be observed from recent research that a variety of transformer-based models have shown remarkable results in time-series forecasting. However, there are still some issues that limit the ability of transformer-based models on time-series forecasting tasks: (i) learning directly on raw data is susceptible to noise due to its complex and unstable feature representation; (ii) the self-attention mechanisms pay insufficient attention to changing features and temporal dependencies. In order to solve these two problems, we propose a transformer-based differentially reconstructed attention model DRAformer. Specifically, DRAformer has the following innovations: (i) learning against differenced sequences, which preserves clear and stable sequence features by differencing and highlights the changing properties of sequences; (ii) the reconstructed attention: integrated distance attention exhibits sequential distance through a learnable Gaussian kernel, distributed difference attention calculates distribution difference by mapping the difference sequence to the adaptive feature space, and the combination of the two effectively focuses on the sequences with prominent associations; (iii) the reconstructed decoder input, which extracts sequence features by integrating variation information and temporal correlations, thereby obtaining a more comprehensive sequence representation. Extensive experiments on four large-scale datasets demonstrate that DRAformer outperforms state-of-the-art baselines.

</p>
</details>

<details><summary><b>Scientific Inference With Interpretable Machine Learning: Analyzing Models to Learn About Real-World Phenomena</b>
<a href="https://arxiv.org/abs/2206.05487">arxiv:2206.05487</a>
&#x1F4C8; 2 <br>
<p>Timo Freiesleben, Gunnar König, Christoph Molnar, Alvaro Tejero-Cantero</p></summary>
<p>

**Abstract:** Interpretable machine learning (IML) is concerned with the behavior and the properties of machine learning models. Scientists, however, are only interested in the model as a gateway to understanding the modeled phenomenon. We show how to develop IML methods such that they allow insight into relevant phenomenon properties. We argue that current IML research conflates two goals of model-analysis -- model audit and scientific inference. Thereby, it remains unclear if model interpretations have corresponding phenomenon interpretation. Building on statistical decision theory, we show that ML model analysis allows to describe relevant aspects of the joint data probability distribution. We provide a five-step framework for constructing IML descriptors that can help in addressing scientific questions, including a natural way to quantify epistemic uncertainty. Our phenomenon-centric approach to IML in science clarifies: the opportunities and limitations of IML for inference; that conditional not marginal sampling is required; and, the conditions under which we can trust IML methods.

</p>
</details>

<details><summary><b>CodeS: A Distribution Shift Benchmark Dataset for Source Code Learning</b>
<a href="https://arxiv.org/abs/2206.05480">arxiv:2206.05480</a>
&#x1F4C8; 2 <br>
<p>Qiang Hu, Yuejun Guo, Xiaofei Xie, Maxime Cordy, Lei Ma, Mike Papadakis, Yves Le Traon</p></summary>
<p>

**Abstract:** Over the past few years, deep learning (DL) has been continuously expanding its applications and becoming a driving force for large-scale source code analysis in the big code era. Distribution shift, where the test set follows a different distribution from the training set, has been a longstanding challenge for the reliable deployment of DL models due to the unexpected accuracy degradation. Although recent progress on distribution shift benchmarking has been made in domains such as computer vision and natural language process. Limited progress has been made on distribution shift analysis and benchmarking for source code tasks, on which there comes a strong demand due to both its volume and its important role in supporting the foundations of almost all industrial sectors. To fill this gap, this paper initiates to propose CodeS, a distribution shift benchmark dataset, for source code learning. Specifically, CodeS supports 2 programming languages (i.e., Java and Python) and 5 types of code distribution shifts (i.e., task, programmer, time-stamp, token, and CST). To the best of our knowledge, we are the first to define the code representation-based distribution shifts. In the experiments, we first evaluate the effectiveness of existing out-of-distribution detectors and the reasonability of the distribution shift definitions and then measure the model generalization of popular code learning models (e.g., CodeBERT) on classification task. The results demonstrate that 1) only softmax score-based OOD detectors perform well on CodeS, 2) distribution shift causes the accuracy degradation in all code classification models, 3) representation-based distribution shifts have a higher impact on the model than others, and 4) pre-trained models are more resistant to distribution shifts. We make CodeS publicly available, enabling follow-up research on the quality assessment of code learning models.

</p>
</details>

<details><summary><b>Differentiable Projection from Optical Coherence Tomography B-Scan without Retinal Layer Segmentation Supervision</b>
<a href="https://arxiv.org/abs/2206.05472">arxiv:2206.05472</a>
&#x1F4C8; 2 <br>
<p>Dingyi Rong, Jiancheng Yang, Bingbing Ni, Bilian Ke</p></summary>
<p>

**Abstract:** Projection map (PM) from optical coherence tomography (OCT) B-scan is an important tool to diagnose retinal diseases, which typically requires retinal layer segmentation. In this study, we present a novel end-to-end framework to predict PMs from B-scans. Instead of segmenting retinal layers explicitly, we represent them implicitly as predicted coordinates. By pixel interpolation on uniformly sampled coordinates between retinal layers, the corresponding PMs could be easily obtained with pooling. Notably, all the operators are differentiable; therefore, this Differentiable Projection Module (DPM) enables end-to-end training with the ground truth of PMs rather than retinal layer segmentation. Our framework produces high-quality PMs, significantly outperforming baselines, including a vanilla CNN without DPM and an optimization-based DPM without a deep prior. Furthermore, the proposed DPM, as a novel neural representation of areas/volumes between curves/surfaces, could be of independent interest for geometric deep learning.

</p>
</details>

<details><summary><b>A General framework for PAC-Bayes Bounds for Meta-Learning</b>
<a href="https://arxiv.org/abs/2206.05454">arxiv:2206.05454</a>
&#x1F4C8; 2 <br>
<p>Arezou Rezazadeh</p></summary>
<p>

**Abstract:** Meta learning automatically infers an inductive bias, that includes the hyperparameter of the base-learning algorithm, by observing data from a finite number of related tasks. This paper studies PAC-Bayes bounds on meta generalization gap. The meta-generalization gap comprises two sources of generalization gaps: the environment-level and task-level gaps resulting from observation of a finite number of tasks and data samples per task, respectively. In this paper, by upper bounding arbitrary convex functions, which link the expected and empirical losses at the environment and also per-task levels, we obtain new PAC-Bayes bounds. Using these bounds, we develop new PAC-Bayes meta-learning algorithms. Numerical examples demonstrate the merits of the proposed novel bounds and algorithm in comparison to prior PAC-Bayes bounds for meta-learning.

</p>
</details>

<details><summary><b>Enhancing Explainability of Hyperparameter Optimization via Bayesian Algorithm Execution</b>
<a href="https://arxiv.org/abs/2206.05447">arxiv:2206.05447</a>
&#x1F4C8; 2 <br>
<p>Julia Moosbauer, Giuseppe Casalicchio, Marius Lindauer, Bernd Bischl</p></summary>
<p>

**Abstract:** Despite all the benefits of automated hyperparameter optimization (HPO), most modern HPO algorithms are black-boxes themselves. This makes it difficult to understand the decision process which lead to the selected configuration, reduces trust in HPO, and thus hinders its broad adoption. Here, we study the combination of HPO with interpretable machine learning (IML) methods such as partial dependence plots. However, if such methods are naively applied to the experimental data of the HPO process in a post-hoc manner, the underlying sampling bias of the optimizer can distort interpretations. We propose a modified HPO method which efficiently balances the search for the global optimum w.r.t. predictive performance and the reliable estimation of IML explanations of an underlying black-box function by coupling Bayesian optimization and Bayesian Algorithm Execution. On benchmark cases of both synthetic objectives and HPO of a neural network, we demonstrate that our method returns more reliable explanations of the underlying black-box without a loss of optimization performance.

</p>
</details>

<details><summary><b>ACMP: Allen-Cahn Message Passing for Graph Neural Networks with Particle Phase Transition</b>
<a href="https://arxiv.org/abs/2206.05437">arxiv:2206.05437</a>
&#x1F4C8; 2 <br>
<p>Yuelin Wang, Kai Yi, Xinliang Liu, Yu Guang Wang, Shi Jin</p></summary>
<p>

**Abstract:** Neural message passing is a basic feature extraction unit for graph-structured data that takes account of the impact of neighboring node features in network propagation from one layer to the next. We model such process by an interacting particle system with attractive and repulsive forces and the Allen-Cahn force arising in the modeling of phase transition. The system is a reaction-diffusion process which can separate particles to different clusters. This induces an Allen-Cahn message passing (ACMP) for graph neural networks where the numerical iteration for the solution constitutes the message passing propagation. The mechanism behind ACMP is phase transition of particles which enables the formation of multi-clusters and thus GNNs prediction for node classification. ACMP can propel the network depth to hundreds of layers with theoretically proven strictly positive lower bound of the Dirichlet energy. It thus provides a deep model of GNNs which circumvents the common GNN problem of oversmoothing. Experiments for various real node classification datasets, with possible high homophily difficulty, show the GNNs with ACMP can achieve state of the art performance with no decay of Dirichlet energy.

</p>
</details>

<details><summary><b>PhML-DyR: A Physics-Informed ML framework for Dynamic Reconfiguration in Power Systems</b>
<a href="https://arxiv.org/abs/2206.06789">arxiv:2206.06789</a>
&#x1F4C8; 1 <br>
<p>Rabab Haider, Anuradha M. Annaswamy</p></summary>
<p>

**Abstract:** A transformation of the US electricity sector is underway with aggressive targets to achieve 100% carbon pollution-free electricity by 2035. To achieve this objective while maintaining a safe and reliable power grid, new operating paradigms are needed, of computationally fast and accurate decision making in a dynamic and uncertain environment. We propose a novel physics-informed machine learning framework for the decision of dynamic grid reconfiguration (PhML-DyR), a key task in power systems. Dynamic reconfiguration (DyR) is a process by which switch-states are dynamically set so as to lead to an optimal grid topology that minimizes line losses. To address the underlying computational complexities of NP-hardness due to the mixed nature of the decision variables, we propose the use of physics-informed ML (PhML) which integrates both operating constraints and topological and connectivity constraints into a neural network framework. Our PhML approach learns to simultaneously optimize grid topology and generator dispatch to meet loads, increase efficiency, and remain within safe operating limits. We demonstrate the effectiveness of PhML-DyR on a canonical grid, showing a reduction in electricity loss by 23%, and improved voltage profiles. We also show a reduction in constraint violations by an order of magnitude as well as in training time using PhML-DyR.

</p>
</details>

<details><summary><b>Physics-driven Deep Learning for PET/MRI</b>
<a href="https://arxiv.org/abs/2206.06788">arxiv:2206.06788</a>
&#x1F4C8; 1 <br>
<p>Abhejit Rajagopal, Andrew P. Leynes, Nicholas Dwork, Jessica E. Scholey, Thomas A. Hope, Peder E. Z. Larson</p></summary>
<p>

**Abstract:** In this paper, we review physics- and data-driven reconstruction techniques for simultaneous positron emission tomography (PET) / magnetic resonance imaging (MRI) systems, which have significant advantages for clinical imaging of cancer, neurological disorders, and heart disease. These reconstruction approaches utilize priors, either structural or statistical, together with a physics-based description of the PET system response. However, due to the nested representation of the forward problem, direct PET/MRI reconstruction is a nonlinear problem. We elucidate how a multi-faceted approach accommodates hybrid data- and physics-driven machine learning for reconstruction of 3D PET/MRI, summarizing important deep learning developments made in the last 5 years to address attenuation correction, scattering, low photon counts, and data consistency. We also describe how applications of these multi-modality approaches extend beyond PET/MRI to improving accuracy in radiation therapy planning. We conclude by discussing opportunities for extending the current state-of-the-art following the latest trends in physics- and deep learning-based computational imaging and next-generation detector hardware.

</p>
</details>

<details><summary><b>Optimal Solutions for Joint Beamforming and Antenna Selection: From Branch and Bound to Machine Learning</b>
<a href="https://arxiv.org/abs/2206.05576">arxiv:2206.05576</a>
&#x1F4C8; 1 <br>
<p>Sagar Shrestha, Xiao Fu, Mingyi Hong</p></summary>
<p>

**Abstract:** This work revisits the joint beamforming (BF) and antenna selection (AS) problem, as well as its robust beamforming (RBF) version under imperfect channel state information (CSI). Such problems arise in scenarios where the number of the radio frequency (RF) chains is smaller than that of the antenna elements at the transmitter, which has become a critical consideration in the era of large-scale arrays. The joint (R)BF\&AS problem is a mixed integer and nonlinear program, and thus finding {\it optimal solutions} is often costly, if not outright impossible. The vast majority of the prior works tackled these problems using continuous optimization-based approximations -- yet these approximations do not ensure optimality or even feasibility of the solutions. The main contribution of this work is threefold. First, an effective {\it branch and bound} (B\&B) framework for solving the problems of interest is proposed. Leveraging existing BF and RBF solvers, it is shown that the B\&B framework guarantees global optimality of the considered problems. Second, to expedite the potentially costly B\&B algorithm, a machine learning (ML)-based scheme is proposed to help skip intermediate states of the B\&B search tree. The learning model features a {\it graph neural network} (GNN)-based design that is resilient to a commonly encountered challenge in wireless communications, namely, the change of problem size (e.g., the number of users) across the training and test stages. Third, comprehensive performance characterizations are presented, showing that the GNN-based method retains the global optimality of B\&B with provably reduced complexity, under reasonable conditions. Numerical simulations also show that the ML-based acceleration can often achieve an order-of-magnitude speedup relative to B\&B.

</p>
</details>

<details><summary><b>Monitoring and Proactive Management of QoS Levels in Pervasive Applications</b>
<a href="https://arxiv.org/abs/2206.05478">arxiv:2206.05478</a>
&#x1F4C8; 1 <br>
<p>Georgios Boulougaris, Kostas Kolomvatsos</p></summary>
<p>

**Abstract:** The advent of Edge Computing (EC) as a promising paradigm that provides multiple computation and analytics capabilities close to data sources opens new pathways for novel applications. Nonetheless, the limited computational capabilities of EC nodes and the expectation of ensuring high levels of QoS during tasks execution impose strict requirements for innovative management approaches. Motivated by the need of maintaining a minimum level of QoS during EC nodes functioning, we elaborate a distributed and intelligent decision-making approach for tasks scheduling. Our aim is to enhance the behavior of EC nodes making them capable of securing high QoS levels. We propose that nodes continuously monitor QoS levels and systematically evaluate the probability of violating them to proactively decide some tasks to be offloaded to peer nodes or Cloud. We present, describe and evaluate the proposed scheme through multiple experimental scenarios revealing its performance and the benefits of the envisioned monitoring mechanism when serving processing requests in very dynamic environments like the EC.

</p>
</details>


{% endraw %}
Prev: [2022.06.10]({{ '/2022/06/10/2022.06.10.html' | relative_url }})  Next: [2022.06.12]({{ '/2022/06/12/2022.06.12.html' | relative_url }})