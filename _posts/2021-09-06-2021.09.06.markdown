## Summary for 2021-09-06, created on 2021-12-18


<details><summary><b>A Farewell to the Bias-Variance Tradeoff? An Overview of the Theory of Overparameterized Machine Learning</b>
<a href="https://arxiv.org/abs/2109.02355">arxiv:2109.02355</a>
&#x1F4C8; 145 <br>
<p>Yehuda Dar, Vidya Muthukumar, Richard G. Baraniuk</p></summary>
<p>

**Abstract:** The rapid recent progress in machine learning (ML) has raised a number of scientific questions that challenge the longstanding dogma of the field. One of the most important riddles is the good empirical generalization of overparameterized models. Overparameterized models are excessively complex with respect to the size of the training dataset, which results in them perfectly fitting (i.e., interpolating) the training data, which is usually noisy. Such interpolation of noisy data is traditionally associated with detrimental overfitting, and yet a wide range of interpolating models -- from simple linear models to deep neural networks -- have recently been observed to generalize extremely well on fresh test data. Indeed, the recently discovered double descent phenomenon has revealed that highly overparameterized models often improve over the best underparameterized model in test performance.
  Understanding learning in this overparameterized regime requires new theory and foundational empirical studies, even for the simplest case of the linear model. The underpinnings of this understanding have been laid in very recent analyses of overparameterized linear regression and related statistical learning tasks, which resulted in precise analytic characterizations of double descent. This paper provides a succinct overview of this emerging theory of overparameterized ML (henceforth abbreviated as TOPML) that explains these recent findings through a statistical signal processing perspective. We emphasize the unique aspects that define the TOPML research area as a subfield of modern ML theory and outline interesting open questions that remain.

</p>
</details>

<details><summary><b>General-Purpose Question-Answering with Macaw</b>
<a href="https://arxiv.org/abs/2109.02593">arxiv:2109.02593</a>
&#x1F4C8; 70 <br>
<p>Oyvind Tafjord, Peter Clark</p></summary>
<p>

**Abstract:** Despite the successes of pretrained language models, there are still few high-quality, general-purpose QA systems that are freely available. In response, we present Macaw, a versatile, generative question-answering (QA) system that we are making available to the community. Macaw is built on UnifiedQA, itself built on T5, and exhibits strong performance, zero-shot, on a wide variety of topics, including outperforming GPT-3 by over 10% (absolute) on Challenge300, a suite of 300 challenge questions, despite being an order of magnitude smaller (11 billion vs. 175 billion parameters). In addition, Macaw allows different permutations ("angles") of its inputs and outputs to be used, for example Macaw can take a question and produce an answer; or take an answer and produce a question; or take an answer and question, and produce multiple-choice options. We describe the system, and illustrate a variety of question types where it produces surprisingly good answers, well outside the training setup. We also identify question classes where it still appears to struggle, offering insights into the limitations of pretrained language models. Macaw is freely available, and we hope that it proves useful to the community. Macaw is available at https://github.com/allenai/macaw

</p>
</details>

<details><summary><b>Self-adaptive deep neural network: Numerical approximation to functions and PDEs</b>
<a href="https://arxiv.org/abs/2109.02839">arxiv:2109.02839</a>
&#x1F4C8; 65 <br>
<p>Zhiqiang Cai, Jingshuang Chen, Min Liu</p></summary>
<p>

**Abstract:** Designing an optimal deep neural network for a given task is important and challenging in many machine learning applications. To address this issue, we introduce a self-adaptive algorithm: the adaptive network enhancement (ANE) method, written as loops of the form train, estimate and enhance. Starting with a small two-layer neural network (NN), the step train is to solve the optimization problem at the current NN; the step estimate is to compute a posteriori estimator/indicators using the solution at the current NN; the step enhance is to add new neurons to the current NN.
  Novel network enhancement strategies based on the computed estimator/indicators are developed in this paper to determine how many new neurons and when a new layer should be added to the current NN. The ANE method provides a natural process for obtaining a good initialization in training the current NN; in addition, we introduce an advanced procedure on how to initialize newly added neurons for a better approximation. We demonstrate that the ANE method can automatically design a nearly minimal NN for learning functions exhibiting sharp transitional layers as well as discontinuous solutions of hyperbolic partial differential equations.

</p>
</details>

<details><summary><b>GPT-3 Models are Poor Few-Shot Learners in the Biomedical Domain</b>
<a href="https://arxiv.org/abs/2109.02555">arxiv:2109.02555</a>
&#x1F4C8; 48 <br>
<p>Milad Moradi, Kathrin Blagec, Florian Haberl, Matthias Samwald</p></summary>
<p>

**Abstract:** Deep neural language models have set new breakthroughs in many tasks of Natural Language Processing (NLP). Recent work has shown that deep transformer language models (pretrained on large amounts of texts) can achieve high levels of task-specific few-shot performance comparable to state-of-the-art models. However, the ability of these large language models in few-shot transfer learning has not yet been explored in the biomedical domain. We investigated the performance of two powerful transformer language models, i.e. GPT-3 and BioBERT, in few-shot settings on various biomedical NLP tasks. The experimental results showed that, to a great extent, both the models underperform a language model fine-tuned on the full training data. Although GPT-3 had already achieved near state-of-the-art results in few-shot knowledge transfer on open-domain NLP tasks, it could not perform as effectively as BioBERT, which is orders of magnitude smaller than GPT-3. Regarding that BioBERT was already pretrained on large biomedical text corpora, our study suggests that language models may largely benefit from in-domain pretraining in task-specific few-shot learning. However, in-domain pretraining seems not to be sufficient; novel pretraining and few-shot learning strategies are required in the biomedical NLP domain.

</p>
</details>

<details><summary><b>The Animation Transformer: Visual Correspondence via Segment Matching</b>
<a href="https://arxiv.org/abs/2109.02614">arxiv:2109.02614</a>
&#x1F4C8; 47 <br>
<p>Evan Casey, Víctor Pérez, Zhuoru Li, Harry Teitelman, Nick Boyajian, Tim Pulver, Mike Manh, William Grisaitis</p></summary>
<p>

**Abstract:** Visual correspondence is a fundamental building block on the way to building assistive tools for hand-drawn animation. However, while a large body of work has focused on learning visual correspondences at the pixel-level, few approaches have emerged to learn correspondence at the level of line enclosures (segments) that naturally occur in hand-drawn animation. Exploiting this structure in animation has numerous benefits: it avoids the intractable memory complexity of attending to individual pixels in high resolution images and enables the use of real-world animation datasets that contain correspondence information at the level of per-segment colors. To that end, we propose the Animation Transformer (AnT) which uses a transformer-based architecture to learn the spatial and visual relationships between segments across a sequence of images. AnT enables practical ML-assisted colorization for professional animation workflows and is publicly accessible as a creative tool in Cadmium.

</p>
</details>

<details><summary><b>Learning Neural Causal Models with Active Interventions</b>
<a href="https://arxiv.org/abs/2109.02429">arxiv:2109.02429</a>
&#x1F4C8; 43 <br>
<p>Nino Scherrer, Olexa Bilaniuk, Yashas Annadani, Anirudh Goyal, Patrick Schwab, Bernhard Schölkopf, Michael C. Mozer, Yoshua Bengio, Stefan Bauer, Nan Rosemary Ke</p></summary>
<p>

**Abstract:** Discovering causal structures from data is a challenging inference problem of fundamental importance in all areas of science. The appealing scaling properties of neural networks have recently led to a surge of interest in differentiable neural network-based methods for learning causal structures from data. So far differentiable causal discovery has focused on static datasets of observational or interventional origin. In this work, we introduce an active intervention-targeting mechanism which enables a quick identification of the underlying causal structure of the data-generating process. Our method significantly reduces the required number of interactions compared with random intervention targeting and is applicable for both discrete and continuous optimization formulations of learning the underlying directed acyclic graph (DAG) from data. We examine the proposed method across a wide range of settings and demonstrate superior performance on multiple benchmarks from simulated to real-world data.

</p>
</details>

<details><summary><b>STaCK: Sentence Ordering with Temporal Commonsense Knowledge</b>
<a href="https://arxiv.org/abs/2109.02247">arxiv:2109.02247</a>
&#x1F4C8; 20 <br>
<p>Deepanway Ghosal, Navonil Majumder, Rada Mihalcea, Soujanya Poria</p></summary>
<p>

**Abstract:** Sentence order prediction is the task of finding the correct order of sentences in a randomly ordered document. Correctly ordering the sentences requires an understanding of coherence with respect to the chronological sequence of events described in the text. Document-level contextual understanding and commonsense knowledge centered around these events are often essential in uncovering this coherence and predicting the exact chronological order. In this paper, we introduce STaCK -- a framework based on graph neural networks and temporal commonsense knowledge to model global information and predict the relative order of sentences. Our graph network accumulates temporal evidence using knowledge of `past' and `future' and formulates sentence ordering as a constrained edge classification problem. We report results on five different datasets, and empirically show that the proposed method is naturally suitable for order prediction. The implementation of this work is publicly available at: https://github.com/declare-lab/sentence-ordering.

</p>
</details>

<details><summary><b>3D Human Texture Estimation from a Single Image with Transformers</b>
<a href="https://arxiv.org/abs/2109.02563">arxiv:2109.02563</a>
&#x1F4C8; 17 <br>
<p>Xiangyu Xu, Chen Change Loy</p></summary>
<p>

**Abstract:** We propose a Transformer-based framework for 3D human texture estimation from a single image. The proposed Transformer is able to effectively exploit the global information of the input image, overcoming the limitations of existing methods that are solely based on convolutional neural networks. In addition, we also propose a mask-fusion strategy to combine the advantages of the RGB-based and texture-flow-based models. We further introduce a part-style loss to help reconstruct high-fidelity colors without introducing unpleasant artifacts. Extensive experiments demonstrate the effectiveness of the proposed method against state-of-the-art 3D human texture estimation approaches both quantitatively and qualitatively.

</p>
</details>

<details><summary><b>Visual Recognition with Deep Learning from Biased Image Datasets</b>
<a href="https://arxiv.org/abs/2109.02357">arxiv:2109.02357</a>
&#x1F4C8; 10 <br>
<p>Robin Vogel, Stephan Clémençon, Pierre Laforgue</p></summary>
<p>

**Abstract:** In practice, and more especially when training deep neural networks, visual recognition rules are often learned based on various sources of information. On the other hand, the recent deployment of facial recognition systems with uneven predictive performances on different population segments highlights the representativeness issues possibly induced by a naive aggregation of image datasets. Indeed, sampling bias does not vanish simply by considering larger datasets, and ignoring its impact may completely jeopardize the generalization capacity of the learned prediction rules. In this paper, we show how biasing models, originally introduced for nonparametric estimation in (Gill et al., 1988), and recently revisited from the perspective of statistical learning theory in (Laforgue and Clémençon, 2019), can be applied to remedy these problems in the context of visual recognition. Based on the (approximate) knowledge of the biasing mechanisms at work, our approach consists in reweighting the observations, so as to form a nearly debiased estimator of the target distribution. One key condition for our method to be theoretically valid is that the supports of the distributions generating the biased datasets at disposal must overlap, and cover the support of the target distribution. In order to meet this requirement in practice, we propose to use a low dimensional image representation, shared across the image databases. Finally, we provide numerical experiments highlighting the relevance of our approach whenever the biasing functions are appropriately chosen.

</p>
</details>

<details><summary><b>Enhancing Visual Dialog Questioner with Entity-based Strategy Learning and Augmented Guesser</b>
<a href="https://arxiv.org/abs/2109.02297">arxiv:2109.02297</a>
&#x1F4C8; 10 <br>
<p>Duo Zheng, Zipeng Xu, Fandong Meng, Xiaojie Wang, Jiaan Wang, Jie Zhou</p></summary>
<p>

**Abstract:** Considering the importance of building a good Visual Dialog (VD) Questioner, many researchers study the topic under a Q-Bot-A-Bot image-guessing game setting, where the Questioner needs to raise a series of questions to collect information of an undisclosed image. Despite progress has been made in Supervised Learning (SL) and Reinforcement Learning (RL), issues still exist. Firstly, previous methods do not provide explicit and effective guidance for Questioner to generate visually related and informative questions. Secondly, the effect of RL is hampered by an incompetent component, i.e., the Guesser, who makes image predictions based on the generated dialogs and assigns rewards accordingly. To enhance VD Questioner: 1) we propose a Related entity enhanced Questioner (ReeQ) that generates questions under the guidance of related entities and learns entity-based questioning strategy from human dialogs; 2) we propose an Augmented Guesser (AugG) that is strong and is optimized for the VD setting especially. Experimental results on the VisDial v1.0 dataset show that our approach achieves state-of-theart performance on both image-guessing task and question diversity. Human study further proves that our model generates more visually related, informative and coherent questions.

</p>
</details>

<details><summary><b>Training Deep Networks from Zero to Hero: avoiding pitfalls and going beyond</b>
<a href="https://arxiv.org/abs/2109.02752">arxiv:2109.02752</a>
&#x1F4C8; 8 <br>
<p>Moacir Antonelli Ponti, Fernando Pereira dos Santos, Leo Sampaio Ferraz Ribeiro, Gabriel Biscaro Cavallari</p></summary>
<p>

**Abstract:** Training deep neural networks may be challenging in real world data. Using models as black-boxes, even with transfer learning, can result in poor generalization or inconclusive results when it comes to small datasets or specific applications. This tutorial covers the basic steps as well as more recent options to improve models, in particular, but not restricted to, supervised learning. It can be particularly useful in datasets that are not as well-prepared as those in challenges, and also under scarce annotation and/or small data. We describe basic procedures: as data preparation, optimization and transfer learning, but also recent architectural choices such as use of transformer modules, alternative convolutional layers, activation functions, wide and deep networks, as well as training procedures including as curriculum, contrastive and self-supervised learning.

</p>
</details>

<details><summary><b>Zero-Shot Open Set Detection by Extending CLIP</b>
<a href="https://arxiv.org/abs/2109.02748">arxiv:2109.02748</a>
&#x1F4C8; 8 <br>
<p>Sepideh Esmaeilpour, Bing Liu, Eric Robertson, Lei Shu</p></summary>
<p>

**Abstract:** In a regular open set detection problem, samples of known classes (also called closed set classes) are used to train a special classifier. In testing, the classifier can (1) classify the test samples of known classes to their respective classes and (2) also detect samples that do not belong to any of the known classes (we say they belong to some unknown or open set classes). This paper studies the problem of zero-shot open-set detection, which still performs the same two tasks in testing but has no training except using the given known class names. This paper proposes a novel and yet simple method (called ZO-CLIP) to solve the problem. ZO-CLIP builds on top of the recent advances in zero-shot classification through multi-modal representation learning. It first extends the pre-trained multi-modal model CLIP by training a text-based image description generator on top of CLIP. In testing, it uses the extended model to generate some candidate unknown class names for each test sample and computes a confidence score based on both the known class names and candidate unknown class names for zero-shot open set detection. Experimental results on 5 benchmark datasets for open set detection confirm that ZO-CLIP outperforms the baselines by a large margin.

</p>
</details>

<details><summary><b>Graph Attention Layer Evolves Semantic Segmentation for Road Pothole Detection: A Benchmark and Algorithms</b>
<a href="https://arxiv.org/abs/2109.02711">arxiv:2109.02711</a>
&#x1F4C8; 8 <br>
<p>Rui Fan, Hengli Wang, Yuan Wang, Ming Liu, Ioannis Pitas</p></summary>
<p>

**Abstract:** Existing road pothole detection approaches can be classified as computer vision-based or machine learning-based. The former approaches typically employ 2-D image analysis/understanding or 3-D point cloud modeling and segmentation algorithms to detect road potholes from vision sensor data. The latter approaches generally address road pothole detection using convolutional neural networks (CNNs) in an end-to-end manner. However, road potholes are not necessarily ubiquitous and it is challenging to prepare a large well-annotated dataset for CNN training. In this regard, while computer vision-based methods were the mainstream research trend in the past decade, machine learning-based methods were merely discussed. Recently, we published the first stereo vision-based road pothole detection dataset and a novel disparity transformation algorithm, whereby the damaged and undamaged road areas can be highly distinguished. However, there are no benchmarks currently available for state-of-the-art (SoTA) CNNs trained using either disparity images or transformed disparity images. Therefore, in this paper, we first discuss the SoTA CNNs designed for semantic segmentation and evaluate their performance for road pothole detection with extensive experiments. Additionally, inspired by graph neural network (GNN), we propose a novel CNN layer, referred to as graph attention layer (GAL), which can be easily deployed in any existing CNN to optimize image feature representations for semantic segmentation. Our experiments compare GAL-DeepLabv3+, our best-performing implementation, with nine SoTA CNNs on three modalities of training data: RGB images, disparity images, and transformed disparity images. The experimental results suggest that our proposed GAL-DeepLabv3+ achieves the best overall pothole detection accuracy on all training data modalities.

</p>
</details>

<details><summary><b>Symbolic Computation in Software Science: My Personal View</b>
<a href="https://arxiv.org/abs/2109.02806">arxiv:2109.02806</a>
&#x1F4C8; 7 <br>
<p>Bruno Buchberger</p></summary>
<p>

**Abstract:** In this note, I develop my personal view on the scope and relevance of symbolic computation in software science. For this, I discuss the interaction and differences between symbolic computation, software science, automatic programming, mathematical knowledge management, artificial intelligence, algorithmic intelligence, numerical computation, and machine learning. In the discussion of these notions, I allow myself to refer also to papers (1982, 1985, 2001, 2003, 2013) of mine in which I expressed my views on these areas at early stages of some of these fields.

</p>
</details>

<details><summary><b>Image In painting Applied to Art Completing Escher's Print Gallery</b>
<a href="https://arxiv.org/abs/2109.02536">arxiv:2109.02536</a>
&#x1F4C8; 7 <br>
<p>Lucia Cipolina-Kun, Simone Caenazzo, Gaston Mazzei, Aditya Srinivas Menon</p></summary>
<p>

**Abstract:** This extended abstract presents the first stages of a research on in-painting suited for art reconstruction. We introduce M.C Eschers Print Gallery lithography as a use case example. This artwork presents a void on its center and additionally, it follows a challenging mathematical structure that needs to be preserved by the in-painting method. We present our work so far and our future line of research.

</p>
</details>

<details><summary><b>GCsT: Graph Convolutional Skeleton Transformer for Action Recognition</b>
<a href="https://arxiv.org/abs/2109.02860">arxiv:2109.02860</a>
&#x1F4C8; 6 <br>
<p>Ruwen Bai, Min Li, Bo Meng, Fengfa Li, Junxing Ren, Miao Jiang, Degang Sun</p></summary>
<p>

**Abstract:** Graph convolutional networks (GCNs) achieve promising performance for skeleton-based action recognition. However, in most GCN-based methods, the spatial-temporal graph convolution is strictly restricted by the graph topology while only captures the short-term temporal context, thus lacking the flexibility of feature extraction. In this work, we present a novel architecture, named Graph Convolutional skeleton Transformer (GCsT), which addresses limitations in GCNs by introducing Transformer. Our GCsT employs all the benefits of Transformer (i.e. dynamical attention and global context) while keeps the advantages of GCNs (i.e. hierarchy and local topology structure). In GCsT, the spatial-temporal GCN forces the capture of local dependencies while Transformer dynamically extracts global spatial-temporal relationships. Furthermore, the proposed GCsT shows stronger expressive capability by adding additional information present in skeleton sequences. Incorporating the Transformer allows that information to be introduced into the model almost effortlessly. We validate the proposed GCsT by conducting extensive experiments, which achieves the state-of-the-art performance on NTU RGB+D, NTU RGB+D 120 and Northwestern-UCLA datasets.

</p>
</details>

<details><summary><b>Binaural SoundNet: Predicting Semantics, Depth and Motion with Binaural Sounds</b>
<a href="https://arxiv.org/abs/2109.02763">arxiv:2109.02763</a>
&#x1F4C8; 6 <br>
<p>Dengxin Dai, Arun Balajee Vasudevan, Jiri Matas, Luc Van Gool</p></summary>
<p>

**Abstract:** Humans can robustly recognize and localize objects by using visual and/or auditory cues. While machines are able to do the same with visual data already, less work has been done with sounds. This work develops an approach for scene understanding purely based on binaural sounds. The considered tasks include predicting the semantic masks of sound-making objects, the motion of sound-making objects, and the depth map of the scene. To this aim, we propose a novel sensor setup and record a new audio-visual dataset of street scenes with eight professional binaural microphones and a 360-degree camera. The co-existence of visual and audio cues is leveraged for supervision transfer. In particular, we employ a cross-modal distillation framework that consists of multiple vision teacher methods and a sound student method -- the student method is trained to generate the same results as the teacher methods do. This way, the auditory system can be trained without using human annotations. To further boost the performance, we propose another novel auxiliary task, coined Spatial Sound Super-Resolution, to increase the directional resolution of sounds. We then formulate the four tasks into one end-to-end trainable multi-tasking network aiming to boost the overall performance. Experimental results show that 1) our method achieves good results for all four tasks, 2) the four tasks are mutually beneficial -- training them together achieves the best performance, 3) the number and orientation of microphones are both important, and 4) features learned from the standard spectrogram and features obtained by the classic signal processing pipeline are complementary for auditory perception tasks. The data and code are released.

</p>
</details>

<details><summary><b>Data Science Kitchen at GermEval 2021: A Fine Selection of Hand-Picked Features, Delivered Fresh from the Oven</b>
<a href="https://arxiv.org/abs/2109.02383">arxiv:2109.02383</a>
&#x1F4C8; 6 <br>
<p>Niclas Hildebrandt, Benedikt Boenninghoff, Dennis Orth, Christopher Schymura</p></summary>
<p>

**Abstract:** This paper presents the contribution of the Data Science Kitchen at GermEval 2021 shared task on the identification of toxic, engaging, and fact-claiming comments. The task aims at extending the identification of offensive language, by including additional subtasks that identify comments which should be prioritized for fact-checking by moderators and community managers. Our contribution focuses on a feature-engineering approach with a conventional classification backend. We combine semantic and writing style embeddings derived from pre-trained deep neural networks with additional numerical features, specifically designed for this task. Ensembles of Logistic Regression classifiers and Support Vector Machines are used to derive predictions for each subtask via a majority voting scheme. Our best submission achieved macro-averaged F1-scores of 66.8%, 69.9% and 72.5% for the identification of toxic, engaging, and fact-claiming comments.

</p>
</details>

<details><summary><b>PermuteFormer: Efficient Relative Position Encoding for Long Sequences</b>
<a href="https://arxiv.org/abs/2109.02377">arxiv:2109.02377</a>
&#x1F4C8; 6 <br>
<p>Peng Chen</p></summary>
<p>

**Abstract:** A recent variation of Transformer, Performer, scales Transformer to longer sequences with a linear attention mechanism. However, it is not compatible with relative position encoding, which has advantages over absolute position encoding. In this paper, we discuss possible ways to add relative position encoding to Performer. Based on the analysis, we propose PermuteFormer, a Performer-based model with relative position encoding that scales linearly on long sequences. PermuteFormer applies position-dependent transformation on queries and keys to encode positional information into the attention module. This transformation is carefully crafted so that the final output of self-attention is not affected by absolute positions of tokens. PermuteFormer introduces negligible computational overhead by design that it runs as fast as Performer. We evaluate PermuteFormer on Long-Range Arena, a dataset for long sequences, as well as WikiText-103, a language modeling dataset. The experiments show that PermuteFormer uniformly improves the performance of Performer with almost no computational overhead and outperforms vanilla Transformer on most of the tasks.

</p>
</details>

<details><summary><b>From Alignment to Assignment: Frustratingly Simple Unsupervised Entity Alignment</b>
<a href="https://arxiv.org/abs/2109.02363">arxiv:2109.02363</a>
&#x1F4C8; 6 <br>
<p>Xin Mao, Wenting Wang, Yuanbin Wu, Man Lan</p></summary>
<p>

**Abstract:** Cross-lingual entity alignment (EA) aims to find the equivalent entities between crosslingual KGs, which is a crucial step for integrating KGs. Recently, many GNN-based EA methods are proposed and show decent performance improvements on several public datasets. Meanwhile, existing GNN-based EA methods inevitably inherit poor interpretability and low efficiency from neural networks. Motivated by the isomorphic assumption of GNNbased methods, we successfully transform the cross-lingual EA problem into the assignment problem. Based on this finding, we propose a frustratingly Simple but Effective Unsupervised entity alignment method (SEU) without neural networks. Extensive experiments show that our proposed unsupervised method even beats advanced supervised methods across all public datasets and has high efficiency, interpretability, and stability.

</p>
</details>

<details><summary><b>Fruit-CoV: An Efficient Vision-based Framework for Speedy Detection and Diagnosis of SARS-CoV-2 Infections Through Recorded Cough Sounds</b>
<a href="https://arxiv.org/abs/2109.03219">arxiv:2109.03219</a>
&#x1F4C8; 5 <br>
<p>Long H. Nguyen, Nhat Truong Pham, Van Huong Do, Liu Tai Nguyen, Thanh Tin Nguyen, Van Dung Do, Hai Nguyen, Ngoc Duy Nguyen</p></summary>
<p>

**Abstract:** SARS-CoV-2 is colloquially known as COVID-19 that had an initial outbreak in December 2019. The deadly virus has spread across the world, taking part in the global pandemic disease since March 2020. In addition, a recent variant of SARS-CoV-2 named Delta is intractably contagious and responsible for more than four million deaths over the world. Therefore, it is vital to possess a self-testing service of SARS-CoV-2 at home. In this study, we introduce Fruit-CoV, a two-stage vision framework, which is capable of detecting SARS-CoV-2 infections through recorded cough sounds. Specifically, we convert sounds into Log-Mel Spectrograms and use the EfficientNet-V2 network to extract its visual features in the first stage. In the second stage, we use 14 convolutional layers extracted from the large-scale Pretrained Audio Neural Networks for audio pattern recognition (PANNs) and the Wavegram-Log-Mel-CNN to aggregate feature representations of the Log-Mel Spectrograms. Finally, we use the combined features to train a binary classifier. In this study, we use a dataset provided by the AICovidVN 115M Challenge, which includes a total of 7371 recorded cough sounds collected throughout Vietnam, India, and Switzerland. Experimental results show that our proposed model achieves an AUC score of 92.8% and ranks the 1st place on the leaderboard of the AICovidVN Challenge. More importantly, our proposed framework can be integrated into a call center or a VoIP system to speed up detecting SARS-CoV-2 infections through online/recorded cough sounds.

</p>
</details>

<details><summary><b>FastAudio: A Learnable Audio Front-End for Spoof Speech Detection</b>
<a href="https://arxiv.org/abs/2109.02774">arxiv:2109.02774</a>
&#x1F4C8; 5 <br>
<p>Quchen Fu, Zhongwei Teng, Jules White, Maria Powell, Douglas C. Schmidt</p></summary>
<p>

**Abstract:** Voice assistants, such as smart speakers, have exploded in popularity. It is currently estimated that the smart speaker adoption rate has exceeded 35% in the US adult population. Manufacturers have integrated speaker identification technology, which attempts to determine the identity of the person speaking, to provide personalized services to different members of the same family. Speaker identification can also play an important role in controlling how the smart speaker is used. For example, it is not critical to correctly identify the user when playing music. However, when reading the user's email out loud, it is critical to correctly verify the speaker that making the request is the authorized user. Speaker verification systems, which authenticate the speaker identity, are therefore needed as a gatekeeper to protect against various spoofing attacks that aim to impersonate the enrolled user. This paper compares popular learnable front-ends which learn the representations of audio by joint training with downstream tasks (End-to-End). We categorize the front-ends by defining two generic architectures and then analyze the filtering stages of both types in terms of learning constraints. We propose replacing fixed filterbanks with a learnable layer that can better adapt to anti-spoofing tasks. The proposed FastAudio front-end is then tested with two popular back-ends to measure the performance on the LA track of the ASVspoof 2019 dataset. The FastAudio front-end achieves a relative improvement of 27% when compared with fixed front-ends, outperforming all other learnable front-ends on this task.

</p>
</details>

<details><summary><b>Machine Learning: Challenges, Limitations, and Compatibility for Audio Restoration Processes</b>
<a href="https://arxiv.org/abs/2109.02692">arxiv:2109.02692</a>
&#x1F4C8; 5 <br>
<p>Owen Casey, Rushit Dave, Naeem Seliya, Evelyn R Sowells Boone</p></summary>
<p>

**Abstract:** In this paper machine learning networks are explored for their use in restoring degraded and compressed speech audio. The project intent is to build a new trained model from voice data to learn features of compression artifacting distortion introduced by data loss from lossy compression and resolution loss with an existing algorithm presented in SEGAN: Speech Enhancement Generative Adversarial Network. The resulting generator from the model was then to be used to restore degraded speech audio. This paper details an examination of the subsequent compatibility and operational issues presented by working with deprecated code, which obstructed the trained model from successfully being developed. This paper further serves as an examination of the challenges, limitations, and compatibility in the current state of machine learning.

</p>
</details>

<details><summary><b>Automatic Segmentation of the Optic Nerve Head Region in Optical Coherence Tomography: A Methodological Review</b>
<a href="https://arxiv.org/abs/2109.02322">arxiv:2109.02322</a>
&#x1F4C8; 5 <br>
<p>Rita Marques, Danilo Andrade De Jesus, João Barbosa Breda, Jan Van Eijgen, Ingeborg Stalmans, Theo van Walsum, Stefan Klein, Pedro G. Vaz, Luisa Sánchez Brea</p></summary>
<p>

**Abstract:** The optic nerve head represents the intraocular section of the optic nerve (ONH), which is prone to damage by intraocular pressure. The advent of optical coherence tomography (OCT) has enabled the evaluation of novel optic nerve head parameters, namely the depth and curvature of the lamina cribrosa (LC). Together with the Bruch's membrane opening minimum-rim-width, these seem to be promising optic nerve head parameters for diagnosis and monitoring of retinal diseases such as glaucoma. Nonetheless, these optical coherence tomography derived biomarkers are mostly extracted through manual segmentation, which is time-consuming and prone to bias, thus limiting their usability in clinical practice. The automatic segmentation of optic nerve head in OCT scans could further improve the current clinical management of glaucoma and other diseases.
  This review summarizes the current state-of-the-art in automatic segmentation of the ONH in OCT. PubMed and Scopus were used to perform a systematic review. Additional works from other databases (IEEE, Google Scholar and ARVO IOVS) were also included, resulting in a total of 27 reviewed studies.
  For each algorithm, the methods, the size and type of dataset used for validation, and the respective results were carefully analyzed. The results show that deep learning-based algorithms provide the highest accuracy, sensitivity and specificity for segmenting the different structures of the ONH including the LC. However, a lack of consensus regarding the definition of segmented regions, extracted parameters and validation approaches has been observed, highlighting the importance and need of standardized methodologies for ONH segmentation.

</p>
</details>

<details><summary><b>Improving Numerical Reasoning Skills in the Modular Approach for Complex Question Answering on Text</b>
<a href="https://arxiv.org/abs/2109.02289">arxiv:2109.02289</a>
&#x1F4C8; 5 <br>
<p>Xiao-Yu Guo, Yuan-Fang Li, Gholamreza Haffari</p></summary>
<p>

**Abstract:** Numerical reasoning skills are essential for complex question answering (CQA) over text. It requires opertaions including counting, comparison, addition and subtraction. A successful approach to CQA on text, Neural Module Networks (NMNs), follows the programmer-interpreter paradigm and leverages specialised modules to perform compositional reasoning. However, the NMNs framework does not consider the relationship between numbers and entities in both questions and paragraphs. We propose effective techniques to improve NMNs' numerical reasoning capabilities by making the interpreter question-aware and capturing the relationship between entities and numbers. On the same subset of the DROP dataset for CQA on text, experimental results show that our additions outperform the original NMNs by 3.0 points for the overall F1 score.

</p>
</details>

<details><summary><b>Estimating Leaf Water Content using Remotely Sensed Hyperspectral Data</b>
<a href="https://arxiv.org/abs/2109.02250">arxiv:2109.02250</a>
&#x1F4C8; 5 <br>
<p>Vishal Vinod, Rahul Raj, Rohit Pingale, Adinarayana Jagarlapudi</p></summary>
<p>

**Abstract:** Plant water stress may occur due to the limited availability of water to the roots/soil or due to increased transpiration. These factors adversely affect plant physiology and photosynthetic ability to the extent that it has been shown to have inhibitory effects in both growth and yield [18]. Early identification of plant water stress status enables suitable corrective measures to be applied to obtain the expected crop yield. Further, improving crop yield through precision agriculture methods is a key component of climate policy and the UN sustainable development goals [1]. Leaf water content (LWC) is a measure that can be used to estimate water content and identify stressed plants. LWC during the early crop growth stages is an important indicator of plant productivity and yield. The effect of water stress can be instantaneous [15], affecting gaseous exchange or long-term, significantly reducing [9, 18, 22]. It is thus necessary to identify potential plant water stress during the early stages of growth [15] to introduce corrective irrigation and alleviate stress. LWC is also useful for identifying plant genotypes that are tolerant to water stress and salinity by measuring the stability of LWC even under artificially induced water stress [18, 25]. Such experiments generally employ destructive procedures to obtain the LWC, which is time-consuming and labor intensive. Accordingly, this research has developed a non-destructive method to estimate LWC from UAV-based hyperspectral data.

</p>
</details>

<details><summary><b>Knowledge Graph Question Answering via SPARQL Silhouette Generation</b>
<a href="https://arxiv.org/abs/2109.09475">arxiv:2109.09475</a>
&#x1F4C8; 4 <br>
<p>Sukannya Purkayastha, Saswati Dana, Dinesh Garg, Dinesh Khandelwal, G P Shrivatsa Bhargav</p></summary>
<p>

**Abstract:** Knowledge Graph Question Answering (KGQA) has become a prominent area in natural language processing due to the emergence of large-scale Knowledge Graphs (KGs). Recently Neural Machine Translation based approaches are gaining momentum that translates natural language queries to structured query languages thereby solving the KGQA task. However, most of these methods struggle with out-of-vocabulary words where test entities and relations are not seen during training time. In this work, we propose a modular two-stage neural architecture to solve the KGQA task.
  The first stage generates a sketch of the target SPARQL called SPARQL silhouette for the input question. This comprises of (1) Noise simulator to facilitate out-of-vocabulary words and to reduce vocabulary size (2) seq2seq model for text to SPARQL silhouette generation. The second stage is a Neural Graph Search Module. SPARQL silhouette generated in the first stage is distilled in the second stage by substituting precise relation in the predicted structure. We simulate ideal and realistic scenarios by designing a noise simulator. Experimental results show that the quality of generated SPARQL silhouette in the first stage is outstanding for the ideal scenarios but for realistic scenarios (i.e. noisy linker), the quality of the resulting SPARQL silhouette drops drastically. However, our neural graph search module recovers it considerably. We show that our method can achieve reasonable performance improving the state-of-art by a margin of 3.72% F1 for the LC-QuAD-1 dataset. We believe, our proposed approach is novel and will lead to dynamic KGQA solutions that are suited for practical applications.

</p>
</details>

<details><summary><b>Few-shot Learning via Dependency Maximization and Instance Discriminant Analysis</b>
<a href="https://arxiv.org/abs/2109.02820">arxiv:2109.02820</a>
&#x1F4C8; 4 <br>
<p>Zejiang Hou, Sun-Yuan Kung</p></summary>
<p>

**Abstract:** We study the few-shot learning (FSL) problem, where a model learns to recognize new objects with extremely few labeled training data per category. Most of previous FSL approaches resort to the meta-learning paradigm, where the model accumulates inductive bias through learning many training tasks so as to solve a new unseen few-shot task. In contrast, we propose a simple approach to exploit unlabeled data accompanying the few-shot task for improving few-shot performance. Firstly, we propose a Dependency Maximization method based on the Hilbert-Schmidt norm of the cross-covariance operator, which maximizes the statistical dependency between the embedded feature of those unlabeled data and their label predictions, together with the supervised loss over the support set. We then use the obtained model to infer the pseudo-labels for those unlabeled data. Furthermore, we propose anInstance Discriminant Analysis to evaluate the credibility of each pseudo-labeled example and select the most faithful ones into an augmented support set to retrain the model as in the first step. We iterate the above process until the pseudo-labels for the unlabeled data becomes stable. Following the standard transductive and semi-supervised FSL setting, our experiments show that the proposed method out-performs previous state-of-the-art methods on four widely used benchmarks, including mini-ImageNet, tiered-ImageNet, CUB, and CIFARFS.

</p>
</details>

<details><summary><b>A Scalable AI Approach for Clinical Trial Cohort Optimization</b>
<a href="https://arxiv.org/abs/2109.02808">arxiv:2109.02808</a>
&#x1F4C8; 4 <br>
<p>Xiong Liu, Cheng Shi, Uday Deore, Yingbo Wang, Myah Tran, Iya Khalil, Murthy Devarakonda</p></summary>
<p>

**Abstract:** FDA has been promoting enrollment practices that could enhance the diversity of clinical trial populations, through broadening eligibility criteria. However, how to broaden eligibility remains a significant challenge. We propose an AI approach to Cohort Optimization (AICO) through transformer-based natural language processing of the eligibility criteria and evaluation of the criteria using real-world data. The method can extract common eligibility criteria variables from a large set of relevant trials and measure the generalizability of trial designs to real-world patients. It overcomes the scalability limits of existing manual methods and enables rapid simulation of eligibility criteria design for a disease of interest. A case study on breast cancer trial design demonstrates the utility of the method in improving trial generalizability.

</p>
</details>

<details><summary><b>Puzzle Solving without Search or Human Knowledge: An Unnatural Language Approach</b>
<a href="https://arxiv.org/abs/2109.02797">arxiv:2109.02797</a>
&#x1F4C8; 4 <br>
<p>David Noever, Ryerson Burdick</p></summary>
<p>

**Abstract:** The application of Generative Pre-trained Transformer (GPT-2) to learn text-archived game notation provides a model environment for exploring sparse reward gameplay. The transformer architecture proves amenable to training on solved text archives describing mazes, Rubik's Cube, and Sudoku solvers. The method benefits from fine-tuning the transformer architecture to visualize plausible strategies derived outside any guidance from human heuristics or domain expertise. The large search space ($>10^{19}$) for the games provides a puzzle environment in which the solution has few intermediate rewards and a final move that solves the challenge.

</p>
</details>

<details><summary><b>Robustness and Generalization via Generative Adversarial Training</b>
<a href="https://arxiv.org/abs/2109.02765">arxiv:2109.02765</a>
&#x1F4C8; 4 <br>
<p>Omid Poursaeed, Tianxing Jiang, Harry Yang, Serge Belongie, SerNam Lim</p></summary>
<p>

**Abstract:** While deep neural networks have achieved remarkable success in various computer vision tasks, they often fail to generalize to new domains and subtle variations of input images. Several defenses have been proposed to improve the robustness against these variations. However, current defenses can only withstand the specific attack used in training, and the models often remain vulnerable to other input variations. Moreover, these methods often degrade performance of the model on clean images and do not generalize to out-of-domain samples. In this paper we present Generative Adversarial Training, an approach to simultaneously improve the model's generalization to the test set and out-of-domain samples as well as its robustness to unseen adversarial attacks. Instead of altering a low-level pre-defined aspect of images, we generate a spectrum of low-level, mid-level and high-level changes using generative models with a disentangled latent space. Adversarial training with these examples enable the model to withstand a wide range of attacks by observing a variety of input alterations during training. We show that our approach not only improves performance of the model on clean images and out-of-domain samples but also makes it robust against unforeseen attacks and outperforms prior work. We validate effectiveness of our method by demonstrating results on various tasks such as classification, segmentation and object detection.

</p>
</details>

<details><summary><b>Scikit-dimension: a Python package for intrinsic dimension estimation</b>
<a href="https://arxiv.org/abs/2109.02596">arxiv:2109.02596</a>
&#x1F4C8; 4 <br>
<p>Jonathan Bac, Evgeny M. Mirkes, Alexander N. Gorban, Ivan Tyukin, Andrei Zinovyev</p></summary>
<p>

**Abstract:** Dealing with uncertainty in applications of machine learning to real-life data critically depends on the knowledge of intrinsic dimensionality (ID). A number of methods have been suggested for the purpose of estimating ID, but no standard package to easily apply them one by one or all at once has been implemented in Python. This technical note introduces \texttt{scikit-dimension}, an open-source Python package for intrinsic dimension estimation. \texttt{scikit-dimension} package provides a uniform implementation of most of the known ID estimators based on scikit-learn application programming interface to evaluate global and local intrinsic dimension, as well as generators of synthetic toy and benchmark datasets widespread in the literature. The package is developed with tools assessing the code quality, coverage, unit testing and continuous integration. We briefly describe the package and demonstrate its use in a large-scale (more than 500 datasets) benchmarking of methods for ID estimation in real-life and synthetic data. The source code is available from https://github.com/j-bac/scikit-dimension , the documentation is available from https://scikit-dimension.readthedocs.io .

</p>
</details>

<details><summary><b>Active Learning for Automated Visual Inspection of Manufactured Products</b>
<a href="https://arxiv.org/abs/2109.02469">arxiv:2109.02469</a>
&#x1F4C8; 4 <br>
<p>Elena Trajkova, Jože M. Rožanec, Paulien Dam, Blaž Fortuna, Dunja Mladenić</p></summary>
<p>

**Abstract:** Quality control is a key activity performed by manufacturing enterprises to ensure products meet quality standards and avoid potential damage to the brand's reputation. The decreased cost of sensors and connectivity enabled an increasing digitalization of manufacturing. In addition, artificial intelligence enables higher degrees of automation, reducing overall costs and time required for defect inspection. In this research, we compare three active learning approaches and five machine learning algorithms applied to visual defect inspection with real-world data provided by Philips Consumer Lifestyle BV. Our results show that active learning reduces the data labeling effort without detriment to the models' performance.

</p>
</details>

<details><summary><b>Improved RAMEN: Towards Domain Generalization for Visual Question Answering</b>
<a href="https://arxiv.org/abs/2109.02370">arxiv:2109.02370</a>
&#x1F4C8; 4 <br>
<p>Bhanuka Manesha Samarasekara Vitharana Gamage, Lim Chern Hong</p></summary>
<p>

**Abstract:** Currently nearing human-level performance, Visual Question Answering (VQA) is an emerging area in artificial intelligence.
  Established as a multi-disciplinary field in machine learning, both computer vision and natural language processing communities are working together to achieve state-of-the-art (SOTA) performance.
  However, there is a gap between the SOTA results and real world applications.
  This is due to the lack of model generalisation.
  The RAMEN model \cite{Shrestha2019} aimed to achieve domain generalization by obtaining the highest score across two main types of VQA datasets.
  This study provides two major improvements to the early/late fusion module and aggregation module of the RAMEN architecture, with the objective of further strengthening domain generalization.
  Vector operations based fusion strategies are introduced for the fusion module and the transformer architecture is introduced for the aggregation module.
  Improvements of up to five VQA datasets from the experiments conducted are evident.
  Following the results, this study analyses the effects of both the improvements on the domain generalization problem.
  The code is available on GitHub though the following link \url{https://github.com/bhanukaManesha/ramen}.

</p>
</details>

<details><summary><b>Tensor Normalization and Full Distribution Training</b>
<a href="https://arxiv.org/abs/2109.02345">arxiv:2109.02345</a>
&#x1F4C8; 4 <br>
<p>Wolfgang Fuhl</p></summary>
<p>

**Abstract:** In this work, we introduce pixel wise tensor normalization, which is inserted after rectifier linear units and, together with batch normalization, provides a significant improvement in the accuracy of modern deep neural networks. In addition, this work deals with the robustness of networks. We show that the factorized superposition of images from the training set and the reformulation of the multi class problem into a multi-label problem yields significantly more robust networks. The reformulation and the adjustment of the multi class log loss also improves the results compared to the overlay with only one class as label. https://atreus.informatik.uni-tuebingen.de/seafile/d/8e2ab8c3fdd444e1a135/?p=%2FTNandFDT&mode=list

</p>
</details>

<details><summary><b>Information Theory-Guided Heuristic Progressive Multi-View Coding</b>
<a href="https://arxiv.org/abs/2109.02344">arxiv:2109.02344</a>
&#x1F4C8; 4 <br>
<p>Jiangmeng Li, Wenwen Qiang, Hang Gao, Bing Su, Farid Razzak, Jie Hu, Changwen Zheng, Hui Xiong</p></summary>
<p>

**Abstract:** Multi-view representation learning captures comprehensive information from multiple views of a shared context. Recent works intuitively apply contrastive learning (CL) to learn representations, regarded as a pairwise manner, which is still scalable: view-specific noise is not filtered in learning view-shared representations; the fake negative pairs, where the negative terms are actually within the same class as the positive, and the real negative pairs are coequally treated; and evenly measuring the similarities between terms might interfere with optimization. Importantly, few works research the theoretical framework of generalized self-supervised multi-view learning, especially for more than two views. To this end, we rethink the existing multi-view learning paradigm from the information theoretical perspective and then propose a novel information theoretical framework for generalized multi-view learning. Guided by it, we build a multi-view coding method with a three-tier progressive architecture, namely Information theory-guided heuristic Progressive Multi-view Coding (IPMC). In the distribution-tier, IPMC aligns the distribution between views to reduce view-specific noise. In the set-tier, IPMC builds self-adjusted pools for contrasting, which utilizes a view filter to adaptively modify the pools. Lastly, in the instance-tier, we adopt a designed unified loss to learn discriminative representations and reduce the gradient interference. Theoretically and empirically, we demonstrate the superiority of IPMC over state-of-the-art methods.

</p>
</details>

<details><summary><b>Hindsight Reward Tweaking via Conditional Deep Reinforcement Learning</b>
<a href="https://arxiv.org/abs/2109.02332">arxiv:2109.02332</a>
&#x1F4C8; 4 <br>
<p>Ning Wei, Jiahua Liang, Di Xie, Shiliang Pu</p></summary>
<p>

**Abstract:** Designing optimal reward functions has been desired but extremely difficult in reinforcement learning (RL). When it comes to modern complex tasks, sophisticated reward functions are widely used to simplify policy learning yet even a tiny adjustment on them is expensive to evaluate due to the drastically increasing cost of training. To this end, we propose a hindsight reward tweaking approach by designing a novel paradigm for deep reinforcement learning to model the influences of reward functions within a near-optimal space. We simply extend the input observation with a condition vector linearly correlated with the effective environment reward parameters and train the model in a conventional manner except for randomizing reward configurations, obtaining a hyper-policy whose characteristics are sensitively regulated over the condition space. We demonstrate the feasibility of this approach and study one of its potential application in policy performance boosting with multiple MuJoCo tasks.

</p>
</details>

<details><summary><b>Data-Driven Learning of 3-Point Correlation Functions as Microstructure Representations</b>
<a href="https://arxiv.org/abs/2109.02255">arxiv:2109.02255</a>
&#x1F4C8; 4 <br>
<p>Sheng Cheng, Yang Jiao, Yi Ren</p></summary>
<p>

**Abstract:** This paper considers the open challenge of identifying complete, concise, and explainable quantitative microstructure representations for disordered heterogeneous material systems. Completeness and conciseness have been achieved through existing data-driven methods, e.g., deep generative models, which, however, do not provide mathematically explainable latent representations. This study investigates representations composed of three-point correlation functions, which are a special type of spatial convolutions. We show that a variety of microstructures can be characterized by a concise subset of three-point correlations, and the identification of such subsets can be achieved by Bayesian optimization. Lastly, we show that the proposed representation can directly be used to compute material properties based on the effective medium theory.

</p>
</details>

<details><summary><b>Generative Models Improve Radiomics Performance in Different Tasks and Different Datasets: An Experimental Study</b>
<a href="https://arxiv.org/abs/2109.02252">arxiv:2109.02252</a>
&#x1F4C8; 4 <br>
<p>Junhua Chen, Inigo Bermejo, Andre Dekker, Leonard Wee</p></summary>
<p>

**Abstract:** Radiomics is an active area of research focusing on high throughput feature extraction from medical images with a wide array of applications in clinical practice, such as clinical decision support in oncology. However, noise in low dose computed tomography (CT) scans can impair the accurate extraction of radiomic features. In this article, we investigate the possibility of using deep learning generative models to improve the performance of radiomics from low dose CTs. We used two datasets of low dose CT scans -NSCLC Radiogenomics and LIDC-IDRI - as test datasets for two tasks - pre-treatment survival prediction and lung cancer diagnosis. We used encoder-decoder networks and conditional generative adversarial networks (CGANs) trained in a previous study as generative models to transform low dose CT images into full dose CT images. Radiomic features extracted from the original and improved CT scans were used to build two classifiers - a support vector machine (SVM) and a deep attention based multiple instance learning model - for survival prediction and lung cancer diagnosis respectively. Finally, we compared the performance of the models derived from the original and improved CT scans. Encoder-decoder networks and CGANs improved the area under the curve (AUC) of survival prediction from 0.52 to 0.57 (p-value<0.01). On the other hand, Encoder-decoder network and CGAN can improve the AUC of lung cancer diagnosis from 0.84 to 0.88 and 0.89 respectively (p-value<0.01). Moreover, there are no statistically significant differences in improving AUC by using encoder-decoder network and CGAN (p-value=0.34) when networks trained at 75 and 100 epochs. Generative models can improve the performance of low dose CT-based radiomics in different tasks. Hence, denoising using generative models seems to be a necessary pre-processing step for calculating radiomic features from low dose CTs.

</p>
</details>

<details><summary><b>External knowledge transfer deployment inside a simple double agent Viterbi algorithm</b>
<a href="https://arxiv.org/abs/2110.00433">arxiv:2110.00433</a>
&#x1F4C8; 3 <br>
<p>Zied Baklouti</p></summary>
<p>

**Abstract:** We consider in this paper deploying external knowledge transfer inside a simple double agent Viterbi algorithm which is an algorithm firstly introduced by the author in his preprint "Hidden Markov Based Mathematical Model dedicated to Extract Ingredients from Recipe Text". The key challenge of this work lies in discovering the reason why our old model does have bad performances when it is confronted with estimating ingredient state for unknown words and see if deploying external knowledge transfer directly on calculating state matrix could be the solution instead of deploying it only on back propagating step.

</p>
</details>

<details><summary><b>Hyper Meta-Path Contrastive Learning for Multi-Behavior Recommendation</b>
<a href="https://arxiv.org/abs/2109.02859">arxiv:2109.02859</a>
&#x1F4C8; 3 <br>
<p>Haoran Yang, Hongxu Chen, Lin Li, Philip S. Yu, Guandong Xu</p></summary>
<p>

**Abstract:** User purchasing prediction with multi-behavior information remains a challenging problem for current recommendation systems. Various methods have been proposed to address it via leveraging the advantages of graph neural networks (GNNs) or multi-task learning. However, most existing works do not take the complex dependencies among different behaviors of users into consideration. They utilize simple and fixed schemes, like neighborhood information aggregation or mathematical calculation of vectors, to fuse the embeddings of different user behaviors to obtain a unified embedding to represent a user's behavioral patterns which will be used in downstream recommendation tasks. To tackle the challenge, in this paper, we first propose the concept of hyper meta-path to construct hyper meta-paths or hyper meta-graphs to explicitly illustrate the dependencies among different behaviors of a user. How to obtain a unified embedding for a user from hyper meta-paths and avoid the previously mentioned limitations simultaneously is critical. Thanks to the recent success of graph contrastive learning, we leverage it to learn embeddings of user behavior patterns adaptively instead of assigning a fixed scheme to understand the dependencies among different behaviors. A new graph contrastive learning based framework is proposed by coupling with hyper meta-paths, namely HMG-CR, which consistently and significantly outperforms all baselines in extensive comparison experiments.

</p>
</details>

<details><summary><b>Safety-Critical Learning of Robot Control with Temporal Logic Specifications</b>
<a href="https://arxiv.org/abs/2109.02791">arxiv:2109.02791</a>
&#x1F4C8; 3 <br>
<p>Mingyu Cai, Cristian-Ioan Vasile</p></summary>
<p>

**Abstract:** Reinforcement learning (RL) is a promising approach. However, success is limited towards real-world applications, because ensuring safe exploration and facilitating adequate exploitation is a challenge for controlling robotic systems with unknown models and measurement uncertainties. The learning problem becomes even more difficult for complex tasks over continuous state-space and action-space. In this paper, we propose a learning-based robotic control framework consisting of several aspects: (1) we leverage Linear Temporal Logic (LTL) to express complex tasks over an infinite horizons that are translated to a novel automaton structure; (2) we detail an innovative reward scheme for LTL satisfaction with probabilistic guarantee. Then, by applying a reward shaping technique, we develop a modular policy-gradient architecture exploiting the benefits of the automaton structure to decompose overall tasks and enhance the performance of learned controllers; (3) by incorporating Gaussian Processes (GPs) to estimate the uncertain dynamic systems, we synthesize a model-based safe exploration during learning process using Exponential Control Barrier Functions (ECBFs) for systems with high-order relative degrees. (4) to further improve the efficiency of exploration, we utilize the properties of LTL automata and ECBFs to propose a safe guiding process. Finally, we demonstrate the effectiveness of the framework via several robotic environments. We show an ECBF-based modular deep RL algorithm that achieves near-perfect success rates and safety guarding with high probability confidence during training.

</p>
</details>

<details><summary><b>Deep SIMBAD: Active Landmark-based Self-localization Using Ranking -based Scene Descriptor</b>
<a href="https://arxiv.org/abs/2109.02786">arxiv:2109.02786</a>
&#x1F4C8; 3 <br>
<p>Tanaka Kanji</p></summary>
<p>

**Abstract:** Landmark-based robot self-localization has recently garnered interest as a highly-compressive domain-invariant approach for performing visual place recognition (VPR) across domains (e.g., time of day, weather, and season). However, landmark-based self-localization can be an ill-posed problem for a passive observer (e.g., manual robot control), as many viewpoints may not provide an effective landmark view. In this study, we consider an active self-localization task by an active observer and present a novel reinforcement learning (RL)-based next-best-view (NBV) planner. Our contributions are as follows. (1) SIMBAD-based VPR: We formulate the problem of landmark-based compact scene description as SIMBAD (similarity-based pattern recognition) and further present its deep learning extension. (2) VPR-to-NBV knowledge transfer: We address the challenge of RL under uncertainty (i.e., active self-localization) by transferring the state recognition ability of VPR to the NBV. (3) NNQL-based NBV: We regard the available VPR as the experience database by adapting nearest-neighbor approximation of Q-learning (NNQL). The result shows an extremely compact data structure that compresses both the VPR and NBV into a single incremental inverted index. Experiments using the public NCLT dataset validated the effectiveness of the proposed approach.

</p>
</details>

<details><summary><b>Complementing Handcrafted Features with Raw Waveform Using a Light-weight Auxiliary Model</b>
<a href="https://arxiv.org/abs/2109.02773">arxiv:2109.02773</a>
&#x1F4C8; 3 <br>
<p>Zhongwei Teng, Quchen Fu, Jules White, Maria Powell, Douglas C. Schmidt</p></summary>
<p>

**Abstract:** An emerging trend in audio processing is capturing low-level speech representations from raw waveforms. These representations have shown promising results on a variety of tasks, such as speech recognition and speech separation. Compared to handcrafted features, learning speech features via backpropagation provides the model greater flexibility in how it represents data for different tasks theoretically. However, results from empirical study shows that, in some tasks, such as voice spoof detection, handcrafted features are more competitive than learned features. Instead of evaluating handcrafted features and raw waveforms independently, this paper proposes an Auxiliary Rawnet model to complement handcrafted features with features learned from raw waveforms. A key benefit of the approach is that it can improve accuracy at a relatively low computational cost. The proposed Auxiliary Rawnet model is tested using the ASVspoof 2019 dataset and the results from this dataset indicate that a light-weight waveform encoder can potentially boost the performance of handcrafted-features-based encoders in exchange for a small amount of additional computational work.

</p>
</details>

<details><summary><b>Crash Report Data Analysis for Creating Scenario-Wise, Spatio-Temporal Attention Guidance to Support Computer Vision-based Perception of Fatal Crash Risks</b>
<a href="https://arxiv.org/abs/2109.02710">arxiv:2109.02710</a>
&#x1F4C8; 3 <br>
<p>Yu Li, Muhammad Monjurul Karim, Ruwen Qin</p></summary>
<p>

**Abstract:** Reducing traffic fatalities and serious injuries is a top priority of the US Department of Transportation. The computer vision (CV)-based crash anticipation in the near-crash phase is receiving growing attention. The ability to perceive fatal crash risks earlier is also critical because it will improve the reliability of crash anticipation. Yet, annotated image data for training a reliable AI model for the early visual perception of crash risks are not abundant. The Fatality Analysis Reporting System contains big data of fatal crashes. It is a reliable data source for learning the relationship between driving scene characteristics and fatal crashes to compensate for the limitation of CV. Therefore, this paper develops a data analytics model, named scenario-wise, Spatio-temporal attention guidance, from fatal crash report data, which can estimate the relevance of detected objects to fatal crashes from their environment and context information. First, the paper identifies five sparse variables that allow for decomposing the 5-year fatal crash dataset to develop scenario-wise attention guidance. Then, exploratory analysis of location- and time-related variables of the crash report data suggests reducing fatal crashes to spatially defined groups. The group's temporal pattern is an indicator of the similarity of fatal crashes in the group. Hierarchical clustering and K-means clustering merge the spatially defined groups into six clusters according to the similarity of their temporal patterns. After that, association rule mining discovers the statistical relationship between the temporal information of driving scenes with crash features, for each cluster. The paper shows how the developed attention guidance supports the design and implementation of a preliminary CV model that can identify objects of a possibility to involve in fatal crashes from their environment and context information.

</p>
</details>

<details><summary><b>Intelligent Motion Planning for a Cost-effective Object Follower Mobile Robotic System with Obstacle Avoidance</b>
<a href="https://arxiv.org/abs/2109.02700">arxiv:2109.02700</a>
&#x1F4C8; 3 <br>
<p>Sai Nikhil Gona, Prithvi Raj Bandhakavi</p></summary>
<p>

**Abstract:** There are few industries which use manually controlled robots for carrying material and this cannot be used all the time in all the places. So, it is very tranquil to have robots which can follow a specific human by following the unique coloured object held by that person. So, we propose a robotic system which uses robot vision and deep learning to get the required linear and angular velocities which are ν and ω, respectively. Which in turn makes the robot to avoid obstacles when following the unique coloured object held by the human. The novel methodology that we are proposing is accurate in detecting the position of the unique coloured object in any kind of lighting and tells us the horizontal pixel value where the robot is present and also tells if the object is close to or far from the robot. Moreover, the artificial neural networks that we have used in this problem gave us a meagre error in linear and angular velocity prediction and the PI controller which was used to control the linear and angular velocities, which in turn controls the position of the robot gave us impressive results and this methodology outperforms all other methodologies.

</p>
</details>

<details><summary><b>SS-BERT: Mitigating Identity Terms Bias in Toxic Comment Classification by Utilising the Notion of "Subjectivity" and "Identity Terms"</b>
<a href="https://arxiv.org/abs/2109.02691">arxiv:2109.02691</a>
&#x1F4C8; 3 <br>
<p>Zhixue Zhao, Ziqi Zhang, Frank Hopfgartner</p></summary>
<p>

**Abstract:** Toxic comment classification models are often found biased toward identity terms which are terms characterizing a specific group of people such as "Muslim" and "black". Such bias is commonly reflected in false-positive predictions, i.e. non-toxic comments with identity terms. In this work, we propose a novel approach to tackle such bias in toxic comment classification, leveraging the notion of subjectivity level of a comment and the presence of identity terms. We hypothesize that when a comment is made about a group of people that is characterized by an identity term, the likelihood of that comment being toxic is associated with the subjectivity level of the comment, i.e. the extent to which the comment conveys personal feelings and opinions. Building upon the BERT model, we propose a new structure that is able to leverage these features, and thoroughly evaluate our model on 4 datasets of varying sizes and representing different social media platforms. The results show that our model can consistently outperform BERT and a SOTA model devised to address identity term bias in a different way, with a maximum improvement in F1 of 2.43% and 1.91% respectively.

</p>
</details>

<details><summary><b>Knowledge Graph Enhanced Event Extraction in Financial Documents</b>
<a href="https://arxiv.org/abs/2109.02592">arxiv:2109.02592</a>
&#x1F4C8; 3 <br>
<p>Kaihao Guo, Tianpei Jiang, Haipeng Zhang</p></summary>
<p>

**Abstract:** Event extraction is a classic task in natural language processing with wide use in handling large amount of yet rapidly growing financial, legal, medical, and government documents which often contain multiple events with their elements scattered and mixed across the documents, making the problem much more difficult. Though the underlying relations between event elements to be extracted provide helpful contextual information, they are somehow overlooked in prior studies. We showcase the enhancement to this task brought by utilizing the knowledge graph that captures entity relations and their attributes. We propose a first event extraction framework that embeds a knowledge graph through a Graph Neural Network and integrates the embedding with regular features, all at document-level. Specifically, for extracting events from Chinese financial announcements, our method outperforms the state-of-the-art method by 5.3% in F1-score.

</p>
</details>

<details><summary><b>Estimation of Bivariate Structural Causal Models by Variational Gaussian Process Regression Under Likelihoods Parametrised by Normalising Flows</b>
<a href="https://arxiv.org/abs/2109.02521">arxiv:2109.02521</a>
&#x1F4C8; 3 <br>
<p>Nico Reick, Felix Wiewel, Alexander Bartler, Bin Yang</p></summary>
<p>

**Abstract:** One major drawback of state-of-the-art artificial intelligence is its lack of explainability. One approach to solve the problem is taking causality into account. Causal mechanisms can be described by structural causal models. In this work, we propose a method for estimating bivariate structural causal models using a combination of normalising flows applied to density estimation and variational Gaussian process regression for post-nonlinear models. It facilitates causal discovery, i.e. distinguishing cause and effect, by either the independence of cause and residual or a likelihood ratio test. Our method which estimates post-nonlinear models can better explain a variety of real-world cause-effect pairs than a simple additive noise model. Though it remains difficult to exploit this benefit regarding all pairs from the Tübingen benchmark database, we demonstrate that combining the additive noise model approach with our method significantly enhances causal discovery.

</p>
</details>

<details><summary><b>Proto: A Neural Cocktail for Generating Appealing Conversations</b>
<a href="https://arxiv.org/abs/2109.02513">arxiv:2109.02513</a>
&#x1F4C8; 3 <br>
<p>Sougata Saha, Souvik Das, Elizabeth Soper, Erin Pacquetet, Rohini K. Srihari</p></summary>
<p>

**Abstract:** In this paper, we present our Alexa Prize Grand Challenge 4 socialbot: Proto. Leveraging diverse sources of world knowledge, and powered by a suite of neural and rule-based natural language understanding modules, state-of-the-art neural generators, novel state-based deterministic generators, an ensemble of neural re-rankers, a robust post-processing algorithm, and an efficient overall conversation strategy, Proto strives to be able to converse coherently about a diverse range of topics of interest to humans, and provide a memorable experience to the user. In this paper we dissect and analyze the different components and conversation strategies implemented by our socialbot, which enables us to generate colloquial, empathetic, engaging, self-rectifying, factually correct, and on-topic response, which has helped us achieve consistent scores throughout the competition.

</p>
</details>

<details><summary><b>Learning to Perform Downlink Channel Estimation in Massive MIMO Systems</b>
<a href="https://arxiv.org/abs/2109.02463">arxiv:2109.02463</a>
&#x1F4C8; 3 <br>
<p>Amin Ghazanfari, Trinh Van Chien, Emil Björnson, Erik G. Larsson</p></summary>
<p>

**Abstract:** We study downlink (DL) channel estimation in a multi-cell Massive multiple-input multiple-output (MIMO) system operating in a time-division duplex. The users must know their effective channel gains to decode their received DL data signals. A common approach is to use the mean value as the estimate, motivated by channel hardening, but this is associated with a substantial performance loss in non-isotropic scattering environments. We propose two novel estimation methods. The first method is model-aided and utilizes asymptotic arguments to identify a connection between the effective channel gain and the average received power during a coherence block. The second one is a deep-learning-based approach that uses a neural network to identify a mapping between the available information and the effective channel gain. We compare the proposed methods against other benchmarks in terms of normalized mean-squared error and spectral efficiency (SE). The proposed methods provide substantial improvements, with the learning-based solution being the best of the considered estimators.

</p>
</details>

<details><summary><b>Detection of Insider Threats using Artificial Intelligence and Visualisation</b>
<a href="https://arxiv.org/abs/2109.02417">arxiv:2109.02417</a>
&#x1F4C8; 3 <br>
<p>Vasileios Koutsouvelis, Stavros Shiaeles, Bogdan Ghita, Gueltoum Bendiab</p></summary>
<p>

**Abstract:** Insider threats are one of the most damaging risk factors for the IT systems and infrastructure of a company or an organization; identification of insider threats has prompted the interest of the world academic research community, with several solutions having been proposed to alleviate their potential impact. For the implementation of the experimental stage described in this study, the Convolutional Neural Network (from now on CNN) algorithm was used and implemented via the Google TensorFlow program, which was trained to identify potential threats from images produced by the available dataset. From the examination of the images that were produced and with the help of Machine Learning, the question of whether the activity of each user is classified as malicious or not for the Information System was answered.

</p>
</details>

<details><summary><b>Evaluation of Convolutional Neural Networks for COVID-19 Classification on Chest X-Rays</b>
<a href="https://arxiv.org/abs/2109.02415">arxiv:2109.02415</a>
&#x1F4C8; 3 <br>
<p>Felipe André Zeiser, Cristiano André da Costa, Gabriel de Oliveira Ramos, Henrique Bohn, Ismael Santos, Rodrigo da Rosa Righi</p></summary>
<p>

**Abstract:** Early identification of patients with COVID-19 is essential to enable adequate treatment and to reduce the burden on the health system. The gold standard for COVID-19 detection is the use of RT-PCR tests. However, due to the high demand for tests, these can take days or even weeks in some regions of Brazil. Thus, an alternative for detecting COVID-19 is the analysis of Digital Chest X-rays (XR). Changes due to COVID-19 can be detected in XR, even in asymptomatic patients. In this context, models based on deep learning have great potential to be used as support systems for diagnosis or as screening tools. In this paper, we propose the evaluation of convolutional neural networks to identify pneumonia due to COVID-19 in XR. The proposed methodology consists of a preprocessing step of the XR, data augmentation, and classification by the convolutional architectures DenseNet121, InceptionResNetV2, InceptionV3, MovileNetV2, ResNet50, and VGG16 pre-trained with the ImageNet dataset. The obtained results demonstrate that the VGG16 architecture obtained superior performance in the classification of XR for the evaluation metrics using the methodology proposed in this article. The obtained results for our methodology demonstrate that the VGG16 architecture presented a superior performance in the classification of XR, with an Accuracy of 85.11%, Sensitivity of 85.25%, Specificity of $85.16%, F1-score of $85.03%, and an AUC of 0.9758.

</p>
</details>

<details><summary><b>Less is More: Lighter and Faster Deep Neural Architecture for Tomato Leaf Disease Classification</b>
<a href="https://arxiv.org/abs/2109.02394">arxiv:2109.02394</a>
&#x1F4C8; 3 <br>
<p>Sabbir Ahmed, Md. Bakhtiar Hasan, Tasnim Ahmed, Redwan Karim Sony, Md. Hasanul Kabir</p></summary>
<p>

**Abstract:** To ensure global food security and the overall profit of stakeholders, the importance of correctly detecting and classifying plant diseases is paramount. In this connection, the emergence of deep learning-based image classification has introduced a substantial number of solutions. However, the applicability of these solutions in low-end devices requires fast, accurate, and computationally inexpensive systems. This work proposes a lightweight transfer learning-based approach for detecting diseases from tomato leaves. It utilizes an effective preprocessing method to enhance the leaf images with illumination correction for improved classification. Our system extracts features using a combined model consisting of a pretrained MobileNetV2 architecture and a classifier network for effective prediction. Traditional augmentation approaches are replaced by runtime augmentation to avoid data leakage and address the class imbalance issue. Evaluation on tomato leaf images from the PlantVillage dataset shows that the proposed architecture achieves 99.30% accuracy with a model size of 9.60MB and 4.87M floating-point operations, making it a suitable choice for real-life applications in low-end devices. Our codes and models will be made available upon publication.

</p>
</details>

<details><summary><b>Comparing the Machine Readability of Traffic Sign Pictograms in Austria and Germany</b>
<a href="https://arxiv.org/abs/2109.02362">arxiv:2109.02362</a>
&#x1F4C8; 3 <br>
<p>Alexander Maletzky, Stefan Thumfart, Christoph Wruß</p></summary>
<p>

**Abstract:** We compare the machine readability of pictograms found on Austrian and German traffic signs. To that end, we train classification models on synthetic data sets and evaluate their classification accuracy in a controlled setting. In particular, we focus on differences between currently deployed pictograms in the two countries, and a set of new pictograms designed to increase human readability. Besides other results, we find that machine-learning models generalize poorly to data sets with pictogram designs they have not been trained on. We conclude that manufacturers of advanced driver-assistance systems (ADAS) must take special care to properly address small visual differences between current and newly designed traffic sign pictograms, as well as between pictograms from different countries.

</p>
</details>

<details><summary><b>Fair Federated Learning for Heterogeneous Face Data</b>
<a href="https://arxiv.org/abs/2109.02351">arxiv:2109.02351</a>
&#x1F4C8; 3 <br>
<p>Samhita Kanaparthy, Manisha Padala, Sankarshan Damle, Ravi Kiran Sarvadevabhatla, Sujit Gujar</p></summary>
<p>

**Abstract:** We consider the problem of achieving fair classification in Federated Learning (FL) under data heterogeneity. Most of the approaches proposed for fair classification require diverse data that represent the different demographic groups involved. In contrast, it is common for each client to own data that represents only a single demographic group. Hence the existing approaches cannot be adopted for fair classification models at the client level. To resolve this challenge, we propose several aggregation techniques. We empirically validate these techniques by comparing the resulting fairness metrics and accuracy on CelebA, UTK, and FairFace datasets.

</p>
</details>

<details><summary><b>LightTag: Text Annotation Platform</b>
<a href="https://arxiv.org/abs/2109.02320">arxiv:2109.02320</a>
&#x1F4C8; 3 <br>
<p>Tal Perry</p></summary>
<p>

**Abstract:** Text annotation tools assume that their user's goal is to create a labeled corpus. However, users view annotation as a necessary evil on the way to deliver business value through NLP. Thus an annotation tool should optimize for the throughput of the global NLP process, not only the productivity of individual annotators. LightTag is a text annotation tool designed and built on that principle. This paper shares our design rationale, data modeling choices, and user interface decisions then illustrates how those choices serve the full NLP lifecycle.

</p>
</details>

<details><summary><b>Does Melania Trump have a body double from the perspective of automatic face recognition?</b>
<a href="https://arxiv.org/abs/2109.02283">arxiv:2109.02283</a>
&#x1F4C8; 3 <br>
<p>Khawla Mallat, Fabiola Becerra-Riera, Annette Morales-González, Heydi Méndez-Vázquez, Jean-Luc Dugelay</p></summary>
<p>

**Abstract:** In this paper, we explore whether automatic face recognition can help in verifying widespread misinformation on social media, particularly conspiracy theories that are based on the existence of body doubles. The conspiracy theory addressed in this paper is the case of the Melania Trump body double. We employed four different state-of-the-art descriptors for face recognition to verify the integrity of the claim of the studied conspiracy theory. In addition, we assessed the impact of different image quality metrics on the variation of face recognition results. Two sets of image quality metrics were considered: acquisition-related metrics and subject-related metrics.

</p>
</details>

<details><summary><b>MONITOR: A Multimodal Fusion Framework to Assess Message Veracity in Social Networks</b>
<a href="https://arxiv.org/abs/2109.02271">arxiv:2109.02271</a>
&#x1F4C8; 3 <br>
<p>Abderrazek Azri, Cécile Favre, Nouria Harbi, Jérôme Darmont, Camille Noûs</p></summary>
<p>

**Abstract:** Users of social networks tend to post and share content with little restraint. Hence, rumors and fake news can quickly spread on a huge scale. This may pose a threat to the credibility of social media and can cause serious consequences in real life. Therefore, the task of rumor detection and verification has become extremely important. Assessing the veracity of a social media message (e.g., by fact checkers) involves analyzing the text of the message, its context and any multimedia attachment. This is a very time-consuming task that can be much helped by machine learning. In the literature, most message veracity verification methods only exploit textual contents and metadata. Very few take both textual and visual contents, and more particularly images, into account. In this paper, we second the hypothesis that exploiting all of the components of a social media post enhances the accuracy of veracity detection. To further the state of the art, we first propose using a set of advanced image features that are inspired from the field of image quality assessment, which effectively contributes to rumor detection. These metrics are good indicators for the detection of fake images, even for those generated by advanced techniques like generative adversarial networks (GANs). Then, we introduce the Multimodal fusiON framework to assess message veracIty in social neTwORks (MONITOR), which exploits all message features (i.e., text, social context, and image features) by supervised machine learning. Such algorithms provide interpretability and explainability in the decisions taken, which we believe is particularly important in the context of rumor verification. Experimental results show that MONITOR can detect rumors with an accuracy of 96% and 89% on the MediaEval benchmark and the FakeNewsNet dataset, respectively. These results are significantly better than those of state-of-the-art machine learning baselines.

</p>
</details>

<details><summary><b>An N-gram based approach to auto-extracting topics from research articles</b>
<a href="https://arxiv.org/abs/2110.11879">arxiv:2110.11879</a>
&#x1F4C8; 2 <br>
<p>Linkai Zhu, Maoyi Huang, Maomao Chen, Wennan Wang</p></summary>
<p>

**Abstract:** A lot of manual work goes into identifying a topic for an article. With a large volume of articles, the manual process can be exhausting. Our approach aims to address this issue by automatically extracting topics from the text of large Numbers of articles. This approach takes into account the efficiency of the process. Based on existing N-gram analysis, our research examines how often certain words appear in documents in order to support automatic topic extraction. In order to improve efficiency, we apply custom filtering standards to our research. Additionally, delete as many noncritical or irrelevant phrases as possible. In this way, we can ensure we are selecting unique keyphrases for each article, which capture its core idea. For our research, we chose to center on the autonomous vehicle domain, since the research is relevant to our daily lives. We have to convert the PDF versions of most of the research papers into editable types of files such as TXT. This is because most of the research papers are only in PDF format. To test our proposed idea of automating, numerous articles on robotics have been selected. Next, we evaluate our approach by comparing the result with that obtained manually.

</p>
</details>

<details><summary><b>Deep Convolutional Generative Modeling for Artificial Microstructure Development of Aluminum-Silicon Alloy</b>
<a href="https://arxiv.org/abs/2109.06635">arxiv:2109.06635</a>
&#x1F4C8; 2 <br>
<p>Akshansh Mishra, Tarushi Pathak</p></summary>
<p>

**Abstract:** Machine learning which is a sub-domain of an Artificial Intelligence which is finding various applications in manufacturing and material science sectors. In the present study, Deep Generative Modeling which a type of unsupervised machine learning technique has been adapted for the constructing the artificial microstructure of Aluminium-Silicon alloy. Deep Generative Adversarial Networks has been used for developing the artificial microstructure of the given microstructure image dataset. The results obtained showed that the developed models had learnt to replicate the lining near the certain images of the microstructures.

</p>
</details>

<details><summary><b>Besov Function Approximation and Binary Classification on Low-Dimensional Manifolds Using Convolutional Residual Networks</b>
<a href="https://arxiv.org/abs/2109.02832">arxiv:2109.02832</a>
&#x1F4C8; 2 <br>
<p>Hao Liu, Minshuo Chen, Tuo Zhao, Wenjing Liao</p></summary>
<p>

**Abstract:** Most of existing statistical theories on deep neural networks have sample complexities cursed by the data dimension and therefore cannot well explain the empirical success of deep learning on high-dimensional data. To bridge this gap, we propose to exploit low-dimensional geometric structures of the real world data sets. We establish theoretical guarantees of convolutional residual networks (ConvResNet) in terms of function approximation and statistical estimation for binary classification. Specifically, given the data lying on a $d$-dimensional manifold isometrically embedded in $\mathbb{R}^D$, we prove that if the network architecture is properly chosen, ConvResNets can (1) approximate Besov functions on manifolds with arbitrary accuracy, and (2) learn a classifier by minimizing the empirical logistic risk, which gives an excess risk in the order of $n^{-\frac{s}{2s+2(s\vee d)}}$, where $s$ is a smoothness parameter. This implies that the sample complexity depends on the intrinsic dimension $d$, instead of the data dimension $D$. Our results demonstrate that ConvResNets are adaptive to low-dimensional structures of data sets.

</p>
</details>

<details><summary><b>Robot Sound Interpretation: Learning Visual-Audio Representations for Voice-Controlled Robots</b>
<a href="https://arxiv.org/abs/2109.02823">arxiv:2109.02823</a>
&#x1F4C8; 2 <br>
<p>Peixin Chang, Shuijing Liu, Katherine Driggs-Campbell</p></summary>
<p>

**Abstract:** Inspired by sensorimotor theory, we propose a novel pipeline for voice-controlled robots. Previous work relies on explicit labels of sounds and images as well as extrinsic reward functions. Not only do such approaches have little resemblance to human sensorimotor development, but also require hand-tuning rewards and extensive human labor. To address these problems, we learn a representation that associates images and sound commands with minimal supervision. Using this representation, we generate an intrinsic reward function to learn robotic tasks with reinforcement learning. We demonstrate our approach on three robot platforms, a TurtleBot3, a Kuka-IIWA arm, and a Kinova Gen3 robot, which hear a command word, identify the associated target object, and perform precise control to approach the target. We show that our method outperforms previous work across various sound types and robotic tasks empirically. We successfully deploy the policy learned in simulator to a real-world Kinova Gen3.

</p>
</details>

<details><summary><b>Large-Scale System Identification Using a Randomized SVD</b>
<a href="https://arxiv.org/abs/2109.02703">arxiv:2109.02703</a>
&#x1F4C8; 2 <br>
<p>Han Wang, James Anderson</p></summary>
<p>

**Abstract:** Learning a dynamical system from input/output data is a fundamental task in the control design pipeline. In the partially observed setting there are two components to identification: parameter estimation to learn the Markov parameters, and system realization to obtain a state space model. In both sub-problems it is implicitly assumed that standard numerical algorithms such as the singular value decomposition (SVD) can be easily and reliably computed. When trying to fit a high-dimensional model to data, for example in the cyber-physical system setting, even computing an SVD is intractable. In this work we show that an approximate matrix factorization obtained using randomized methods can replace the standard SVD in the realization algorithm while maintaining the non-asymptotic (in data-set size) performance and robustness guarantees of classical methods. Numerical examples illustrate that for large system models, this is the only method capable of producing a model.

</p>
</details>

<details><summary><b>Backpropagation and fuzzy algorithm Modelling to Resolve Blood Supply Chain Issues in the Covid-19 Pandemic</b>
<a href="https://arxiv.org/abs/2109.02645">arxiv:2109.02645</a>
&#x1F4C8; 2 <br>
<p>Aan Erlansari, Rusdi Effendi, Funny Farady C, Andang Wijanarko, Boko Susilo, Reza Hardiansyah</p></summary>
<p>

**Abstract:** Bloodstock shortages and its uncertain demand has become a major problem for all countries worldwide. Therefore, this study aims to provide solution to the issues of blood distribution during the Covid-19 Pandemic at Bengkulu, Indonesia. The Backpropagation algorithm was used to improve the possibility of discovering available and potential donors. Furthermore, the distances, age, and length of donation were measured to obtain the right person to donate blood when it needed. The Backpropagation uses three input layers to classify eligible donors, namely age, body, weight, and bias. In addition, the system through its query automatically counts the variables via the Fuzzy Tahani and simultaneously access the vast database.

</p>
</details>

<details><summary><b>Delving into Macro Placement with Reinforcement Learning</b>
<a href="https://arxiv.org/abs/2109.02587">arxiv:2109.02587</a>
&#x1F4C8; 2 <br>
<p>Zixuan Jiang, Ebrahim Songhori, Shen Wang, Anna Goldie, Azalia Mirhoseini, Joe Jiang, Young-Joon Lee, David Z. Pan</p></summary>
<p>

**Abstract:** In physical design, human designers typically place macros via trial and error, which is a Markov decision process. Reinforcement learning (RL) methods have demonstrated superhuman performance on the macro placement. In this paper, we propose an extension to this prior work (Mirhoseini et al., 2020). We first describe the details of the policy and value network architecture. We replace the force-directed method with DREAMPlace for placing standard cells in the RL environment. We also compare our improved method with other academic placers on public benchmarks.

</p>
</details>

<details><summary><b>Insider Detection using Deep Autoencoder and Variational Autoencoder Neural Networks</b>
<a href="https://arxiv.org/abs/2109.02568">arxiv:2109.02568</a>
&#x1F4C8; 2 <br>
<p>Efthimios Pantelidis, Gueltoum Bendiab, Stavros Shiaeles, Nicholas Kolokotronis</p></summary>
<p>

**Abstract:** Insider attacks are one of the most challenging cybersecurity issues for companies, businesses and critical infrastructures. Despite the implemented perimeter defences, the risk of this kind of attack is still very high. In fact, the detection of insider attacks is a very complicated security task and presents a serious challenge to the research community. In this paper, we aim to address this issue by using deep learning algorithms Autoencoder and Variational Autoencoder deep. We will especially investigate the usefulness of applying these algorithms to automatically defend against potential internal threats, without human intervention. The effectiveness of these two models is evaluated on the public dataset CERT dataset (CERT r4.2). This version of the CERT Insider Threat Test dataset includes both benign and malicious activities generated from 1000 simulated users. The comparison results with other models show that the Variational Autoencoder neural network provides the best overall performance with a greater detection accuracy and a reasonable false positive rate

</p>
</details>

<details><summary><b>Online Learning of Independent Cascade Models with Node-level Feedback</b>
<a href="https://arxiv.org/abs/2109.02519">arxiv:2109.02519</a>
&#x1F4C8; 2 <br>
<p>Shuoguang Yang, Van-Anh Truong</p></summary>
<p>

**Abstract:** We propose a detailed analysis of the online-learning problem for Independent Cascade (IC) models under node-level feedback. These models have widespread applications in modern social networks. Existing works for IC models have only shed light on edge-level feedback models, where the agent knows the explicit outcome of every observed edge. Little is known about node-level feedback models, where only combined outcomes for sets of edges are observed; in other words, the realization of each edge is censored. This censored information, together with the nonlinear form of the aggregated influence probability, make both parameter estimation and algorithm design challenging. We establish the first confidence-region result under this setting. We also develop an online algorithm achieving a cumulative regret of $\mathcal{O}( \sqrt{T})$, matching the theoretical regret bound for IC models with edge-level feedback.

</p>
</details>

<details><summary><b>A Decoupled Uncertainty Model for MRI Segmentation Quality Estimation</b>
<a href="https://arxiv.org/abs/2109.02413">arxiv:2109.02413</a>
&#x1F4C8; 2 <br>
<p>Richard Shaw, Carole H. Sudre, Sebastien Ourselin, M. Jorge Cardoso, Hugh G. Pemberton</p></summary>
<p>

**Abstract:** Quality control (QC) of MR images is essential to ensure that downstream analyses such as segmentation can be performed successfully. Currently, QC is predominantly performed visually and subjectively, at significant time and operator cost. We aim to automate the process using a probabilistic network that estimates segmentation uncertainty through a heteroscedastic noise model, providing a measure of task-specific quality. By augmenting training images with k-space artefacts, we propose a novel CNN architecture to decouple sources of uncertainty related to the task and different k-space artefacts in a self-supervised manner. This enables the prediction of separate uncertainties for different types of data degradation. While the uncertainty predictions reflect the presence and severity of artefacts, the network provides more robust and generalisable segmentation predictions given the quality of the data. We show that models trained with artefact augmentation provide informative measures of uncertainty on both simulated artefacts and problematic real-world images identified by human raters, both qualitatively and quantitatively in the form of error bars on volume measurements. Relating artefact uncertainty to segmentation Dice scores, we observe that our uncertainty predictions provide a better estimate of MRI quality from the point of view of the task (gray matter segmentation) compared to commonly used metrics of quality including signal-to-noise ratio (SNR) and contrast-to-noise ratio (CNR), hence providing a real-time quality metric indicative of segmentation quality.

</p>
</details>

<details><summary><b>Optimal Prediction of Unmeasured Output from Measurable Outputs In LTI Systems</b>
<a href="https://arxiv.org/abs/2109.02384">arxiv:2109.02384</a>
&#x1F4C8; 2 <br>
<p>Deividas Eringis, John Leth, Zheng-Hua Tan, Rafal Wisniewski, Mihaly Petreczky</p></summary>
<p>

**Abstract:** In this short article, we showcase the derivation of an optimal predictor, when one part of system's output is not measured but is able to be predicted from the rest of the system's output which is measured. According to author's knowledge, similar derivations have been done before but not in state-space representation.

</p>
</details>

<details><summary><b>Pointspectrum: Equivariance Meets Laplacian Filtering for Graph Representation Learning</b>
<a href="https://arxiv.org/abs/2109.02358">arxiv:2109.02358</a>
&#x1F4C8; 2 <br>
<p>Marinos Poiitis, Pavlos Sermpezis, Athena Vakali</p></summary>
<p>

**Abstract:** Graph Representation Learning (GRL) has become essential for modern graph data mining and learning tasks. GRL aims to capture the graph's structural information and exploit it in combination with node and edge attributes to compute low-dimensional representations. While Graph Neural Networks (GNNs) have been used in state-of-the-art GRL architectures, they have been shown to suffer from over smoothing when many GNN layers need to be stacked. In a different GRL approach, spectral methods based on graph filtering have emerged addressing over smoothing; however, up to now, they employ traditional neural networks that cannot efficiently exploit the structure of graph data. Motivated by this, we propose PointSpectrum, a spectral method that incorporates a set equivariant network to account for a graph's structure. PointSpectrum enhances the efficiency and expressiveness of spectral methods, while it outperforms or competes with state-of-the-art GRL methods. Overall, PointSpectrum addresses over smoothing by employing a graph filter and captures a graph's structure through set equivariance, lying on the intersection of GNNs and spectral methods. Our findings are promising for the benefits and applicability of this architectural shift for spectral methods and GRL.

</p>
</details>

<details><summary><b>Automated Cardiac Resting Phase Detection Targeted on the Right Coronary Artery</b>
<a href="https://arxiv.org/abs/2109.02342">arxiv:2109.02342</a>
&#x1F4C8; 2 <br>
<p>Seung Su Yoon, Elisabeth Preuhs, Michaela Schmidt, Christoph Forman, Teodora Chitiboi, Puneet Sharma, Juliano Lara Fernandes, Christoph Tillmanns, Jens Wetzl, Andreas Maier</p></summary>
<p>

**Abstract:** Purpose: Static cardiac imaging such as late gadolinium enhancement, mapping, or 3-D coronary angiography require prior information, e.g., the phase during a cardiac cycle with least motion, called resting phase (RP). The purpose of this work is to propose a fully automated framework that allows the detection of the right coronary artery (RCA) RP within CINE series. Methods: The proposed prototype system consists of three main steps. First, the localization of the regions of interest (ROI) is performed. Second, as CINE series are time-resolved, the cropped ROI series over all time points are taken for tracking motions quantitatively. Third, the output motion values are used to classify RPs. In this work, we focused on the detection of the area with the outer edge of the cross-section of the RCA as our target. The proposed framework was evaluated on 102 clinically acquired dataset at 1.5T and 3T. The automatically classified RPs were compared with the ground truth RPs annotated manually by a medical expert for testing the robustness and feasibility of the framework. Results: The predicted RCA RPs showed high agreement with the experts annotated RPs with 92.7% accuracy, 90.5% sensitivity and 95.0% specificity for the unseen study dataset. The mean absolute difference of the start and end RP was 13.6 ${\pm}$ 18.6 ms for the validation study dataset (n=102). Conclusion: In this work, automated RP detection has been introduced by the proposed framework and demonstrated feasibility, robustness, and applicability for diverse static imaging acquisitions.

</p>
</details>

<details><summary><b>Postulating Exoplanetary Habitability via a Novel Anomaly Detection Method</b>
<a href="https://arxiv.org/abs/2109.02273">arxiv:2109.02273</a>
&#x1F4C8; 2 <br>
<p>Jyotirmoy Sarkar, Kartik Bhatia, Snehanshu Saha, Margarita Safonova, Santonu Sarkar</p></summary>
<p>

**Abstract:** A profound shift in the study of cosmology came with the discovery of thousands of exoplanets and the possibility of the existence of billions of them in our Galaxy. The biggest goal in these searches is whether there are other life-harbouring planets. However, the question which of these detected planets are habitable, potentially-habitable, or maybe even inhabited, is still not answered. Some potentially habitable exoplanets have been hypothesized, but since Earth is the only known habitable planet, measures of habitability are necessarily determined with Earth as the reference. Several recent works introduced new habitability metrics based on optimization methods. Classification of potentially habitable exoplanets using supervised learning is another emerging area of study. However, both modeling and supervised learning approaches suffer from drawbacks. We propose an anomaly detection method, the Multi-Stage Memetic Algorithm (MSMA), to detect anomalies and extend it to an unsupervised clustering algorithm MSMVMCA to use it to detect potentially habitable exoplanets as anomalies. The algorithm is based on the postulate that Earth is an anomaly, with the possibility of existence of few other anomalies among thousands of data points. We describe an MSMA-based clustering approach with a novel distance function to detect habitable candidates as anomalies (including Earth). The results are cross-matched with the habitable exoplanet catalog (PHL-HEC) of the Planetary Habitability Laboratory (PHL) with both optimistic and conservative lists of potentially habitable exoplanets.

</p>
</details>

<details><summary><b>Detection of Epileptic Seizures on EEG Signals Using ANFIS Classifier, Autoencoders and Fuzzy Entropies</b>
<a href="https://arxiv.org/abs/2109.04364">arxiv:2109.04364</a>
&#x1F4C8; 1 <br>
<p>Afshin Shoeibi, Navid Ghassemi, Marjane Khodatars, Parisa Moridian, Roohallah Alizadehsani, Assef Zare, Abbas Khosravi, Abdulhamit Subasi, U. Rajendra Acharya, J. Manuel Gorriz</p></summary>
<p>

**Abstract:** Epileptic seizures are one of the most crucial neurological disorders, and their early diagnosis will help the clinicians to provide accurate treatment for the patients. The electroencephalogram (EEG) signals are widely used for epileptic seizures detection, which provides specialists with substantial information about the functioning of the brain. In this paper, a novel diagnostic procedure using fuzzy theory and deep learning techniques is introduced. The proposed method is evaluated on the Bonn University dataset with six classification combinations and also on the Freiburg dataset. The tunable-Q wavelet transform (TQWT) is employed to decompose the EEG signals into different sub-bands. In the feature extraction step, 13 different fuzzy entropies are calculated from different sub-bands of TQWT, and their computational complexities are calculated to help researchers choose the best set for various tasks. In the following, an autoencoder (AE) with six layers is employed for dimensionality reduction. Finally, the standard adaptive neuro-fuzzy inference system (ANFIS), and also its variants with grasshopper optimization algorithm (ANFIS-GOA), particle swarm optimization (ANFIS-PSO), and breeding swarm optimization (ANFIS-BS) methods are used for classification. Using our proposed method, ANFIS-BS method has obtained an accuracy of 99.74% in classifying into two classes and an accuracy of 99.46% in ternary classification on the Bonn dataset and 99.28% on the Freiburg dataset, reaching state-of-the-art performances on both of them.

</p>
</details>

<details><summary><b>Conjectures, Tests and Proofs: An Overview of Theory Exploration</b>
<a href="https://arxiv.org/abs/2109.03721">arxiv:2109.03721</a>
&#x1F4C8; 1 <br>
<p>Moa Johansson, Nicholas Smallbone</p></summary>
<p>

**Abstract:** A key component of mathematical reasoning is the ability to formulate interesting conjectures about a problem domain at hand. In this paper, we give a brief overview of a theory exploration system called QuickSpec, which is able to automatically discover interesting conjectures about a given set of functions. QuickSpec works by interleaving term generation with random testing to form candidate conjectures. This is made tractable by starting from small sizes and ensuring that only terms that are irreducible with respect to already discovered conjectures are considered. QuickSpec has been successfully applied to generate lemmas for automated inductive theorem proving as well as to generate specifications of functional programs. We give an overview of typical use-cases of QuickSpec, as well as demonstrating how to easily connect it to a theorem prover of the user's choice.

</p>
</details>

<details><summary><b>FaBiAN: A Fetal Brain magnetic resonance Acquisition Numerical phantom</b>
<a href="https://arxiv.org/abs/2109.03624">arxiv:2109.03624</a>
&#x1F4C8; 1 <br>
<p>Hélène Lajous, Christopher W. Roy, Tom Hilbert, Priscille de Dumast, Sébastien Tourbier, Yasser Alemán-Gómez, Jérôme Yerly, Thomas Yu, Hamza Kebiri, Kelly Payette, Jean-Baptiste Ledoux, Reto Meuli, Patric Hagmann, Andras Jakab, Vincent Dunet, Mériam Koob, Tobias Kober, Matthias Stuber, Meritxell Bach Cuadra</p></summary>
<p>

**Abstract:** Accurate characterization of in utero human brain maturation is critical as it involves complex and interconnected structural and functional processes that may influence health later in life. Magnetic resonance imaging is a powerful tool to investigate equivocal neurological patterns during fetal development. However, the number of acquisitions of satisfactory quality available in this cohort of sensitive subjects remains scarce, thus hindering the validation of advanced image processing techniques. Numerical phantoms can mitigate these limitations by providing a controlled environment with a known ground truth. In this work, we present FaBiAN, an open-source Fetal Brain magnetic resonance Acquisition Numerical phantom that simulates clinical T2-weighted fast spin echo sequences of the fetal brain. This unique tool is based on a general, flexible and realistic setup that includes stochastic fetal movements, thus providing images of the fetal brain throughout maturation comparable to clinical acquisitions. We demonstrate its value to evaluate the robustness and optimize the accuracy of an algorithm for super-resolution fetal brain magnetic resonance imaging from simulated motion-corrupted 2D low-resolution series as compared to a synthetic high-resolution reference volume. We also show that the images generated can complement clinical datasets to support data-intensive deep learning methods for fetal brain tissue segmentation.

</p>
</details>

<details><summary><b>ArGoT: A Glossary of Terms extracted from the arXiv</b>
<a href="https://arxiv.org/abs/2109.02801">arxiv:2109.02801</a>
&#x1F4C8; 1 <br>
<p>Luis Berlioz</p></summary>
<p>

**Abstract:** We introduce ArGoT, a data set of mathematical terms extracted from  the articles hosted on the arXiv website.  A term is any mathematical concept defined in an article. Using labels in the article's source code and examples from other popular math websites, we mine all the terms in the arXiv data and compile a comprehensive vocabulary of mathematical terms. Each term can be then organized in a dependency graph by using the term's definitions and the arXiv's metadata. Using both hyperbolic and standard word embeddings, we demonstrate how  this structure is reflected in the text's vector representation and how they capture relations of entailment in mathematical concepts. This data set is part of an ongoing effort to align natural mathematical text with existing Interactive Theorem Prover  Libraries (ITPs) of formally verified statements.

</p>
</details>

<details><summary><b>Motion Artifact Reduction In Photoplethysmography For Reliable Signal Selection</b>
<a href="https://arxiv.org/abs/2109.02755">arxiv:2109.02755</a>
&#x1F4C8; 1 <br>
<p>Runyu Mao, Mackenzie Tweardy, Stephan W. Wegerich, Craig J. Goergen, George R. Wodicka, Fengqing Zhu</p></summary>
<p>

**Abstract:** Photoplethysmography (PPG) is a non-invasive and economical technique to extract vital signs of the human body. Although it has been widely used in consumer and research grade wrist devices to track a user's physiology, the PPG signal is very sensitive to motion which can corrupt the signal's quality. Existing Motion Artifact (MA) reduction techniques have been developed and evaluated using either synthetic noisy signals or signals collected during high-intensity activities - both of which are difficult to generalize for real-life scenarios. Therefore, it is valuable to collect realistic PPG signals while performing Activities of Daily Living (ADL) to develop practical signal denoising and analysis methods. In this work, we propose an automatic pseudo clean PPG generation process for reliable PPG signal selection. For each noisy PPG segment, the corresponding pseudo clean PPG reduces the MAs and contains rich temporal details depicting cardiac features. Our experimental results show that 71% of the pseudo clean PPG collected from ADL can be considered as high quality segment where the derived MAE of heart rate and respiration rate are 1.46 BPM and 3.93 BrPM, respectively. Therefore, our proposed method can determine the reliability of the raw noisy PPG by considering quality of the corresponding pseudo clean PPG signal.

</p>
</details>

<details><summary><b>OKSP: A Novel Deep Learning Automatic Event Detection Pipeline for Seismic Monitoringin Costa Rica</b>
<a href="https://arxiv.org/abs/2109.02723">arxiv:2109.02723</a>
&#x1F4C8; 1 <br>
<p>Leonardo van der Laat, Ronald J. L. Baldares, Esteban J. Chaves, Esteban Meneses</p></summary>
<p>

**Abstract:** Small magnitude earthquakes are the most abundant but the most difficult to locate robustly and well due to their low amplitudes and high frequencies usually obscured by heterogeneous noise sources. They highlight crucial information about the stress state and the spatio-temporal behavior of fault systems during the earthquake cycle, therefore, its full characterization is then crucial for improving earthquake hazard assessment. Modern DL algorithms along with the increasing computational power are exploiting the continuously growing seismological databases, allowing scientists to improve the completeness for earthquake catalogs, systematically detecting smaller magnitude earthquakes and reducing the errors introduced mainly by human intervention. In this work, we introduce OKSP, a novel automatic earthquake detection pipeline for seismic monitoring in Costa Rica. Using Kabre supercomputer from the Costa Rica High Technology Center, we applied OKSP to the day before and the first 5 days following the Puerto Armuelles, M6.5, earthquake that occurred on 26 June, 2019, along the Costa Rica-Panama border and found 1100 more earthquakes previously unidentified by the Volcanological and Seismological Observatory of Costa Rica. From these events, a total of 23 earthquakes with magnitudes below 1.0 occurred a day to hours prior to the mainshock, shedding light about the rupture initiation and earthquake interaction leading to the occurrence of this productive seismic sequence. Our observations show that for the study period, the model was 100% exhaustive and 82% precise, resulting in an F1 score of 0.90. This effort represents the very first attempt for automatically detecting earthquakes in Costa Rica using deep learning methods and demonstrates that, in the near future, earthquake monitoring routines will be carried out entirely by AI algorithms.

</p>
</details>

<details><summary><b>Intrusion Detection using Network Traffic Profiling and Machine Learning for IoT</b>
<a href="https://arxiv.org/abs/2109.02544">arxiv:2109.02544</a>
&#x1F4C8; 1 <br>
<p>Joseph Rose, Matthew Swann, Gueltoum Bendiab, Stavros Shiaeles, Nicholas Kolokotronis</p></summary>
<p>

**Abstract:** The rapid increase in the use of IoT devices brings many benefits to the digital society, ranging from improved efficiency to higher productivity. However, the limited resources and the open nature of these devices make them vulnerable to various cyber threats. A single compromised device can have an impact on the whole network and lead to major security and physical damages. This paper explores the potential of using network profiling and machine learning to secure IoT against cyber-attacks. The proposed anomaly-based intrusion detection solution dynamically and actively profiles and monitors all networked devices for the detection of IoT device tampering attempts as well as suspicious network transactions. Any deviation from the defined profile is considered to be an attack and is subject to further analysis. Raw traffic is also passed on to the machine learning classifier for examination and identification of potential attacks. Performance assessment of the proposed methodology is conducted on the Cyber-Trust testbed using normal and malicious network traffic. The experimental results show that the proposed anomaly detection system delivers promising results with an overall accuracy of 98.35% and 0.98% of false-positive alarms.

</p>
</details>

<details><summary><b>Proceedings of the 9th International Symposium on Symbolic Computation in Software Science</b>
<a href="https://arxiv.org/abs/2109.02501">arxiv:2109.02501</a>
&#x1F4C8; 1 <br>
<p>Temur Kutsia</p></summary>
<p>

**Abstract:** This volume contains papers presented at the Ninth International Symposium on Symbolic Computation in Software Science, SCSS 2021. 
  Symbolic Computation is the science of computing with symbolic objects (terms, formulae, programs, representations of algebraic objects, etc.). Powerful algorithms have been developed during the past decades for the major subareas of symbolic computation: computer algebra and computational logic. These algorithms and methods are successfully applied in various fields, including software science, which covers a broad range of topics about software construction and analysis.
  Meanwhile, artificial intelligence methods and machine learning algorithms are widely used nowadays in various domains and, in particular, combined with symbolic computation. Several approaches mix artificial intelligence and symbolic methods and tools deployed over large corpora to create what is known as cognitive systems. Cognitive computing focuses on building systems that interact with humans naturally by reasoning, aiming at learning at scale.
  The purpose of SCSS is to promote research on theoretical and practical aspects of symbolic computation in software science, combined with modern artificial intelligence techniques. These proceedings contain the keynote paper by Bruno Buchberger and ten contributed papers. Besides, the conference program included three invited talks, nine short and work-in-progress papers, and a special session on computer algebra and computational logic. Due to the COVID-19 pandemic, the symposium was held completely online. It was organized by the Research Institute for Symbolic Computation (RISC) of the Johannes Kepler University Linz on September 8--10, 2021.

</p>
</details>

<details><summary><b>Reconfigurable Intelligent Surface Empowered Over-the-Air Federated Edge Learning</b>
<a href="https://arxiv.org/abs/2109.02353">arxiv:2109.02353</a>
&#x1F4C8; 1 <br>
<p>Hang Liu, Zehong Lin, Xiaojun Yuan, Ying-Jun Angela Zhang</p></summary>
<p>

**Abstract:** Federated edge learning (FEEL) has emerged as a revolutionary paradigm to develop AI services at the edge of 6G wireless networks as it supports collaborative model training at a massive number of mobile devices. However, model communication over wireless channels, especially in uplink model uploading of FEEL, has been widely recognized as a bottleneck that critically limits the efficiency of FEEL. Although over-the-air computation can alleviate the excessive cost of radio resources in FEEL model uploading, practical implementations of over-the-air FEEL still suffer from several challenges, including strong straggler issues, large communication overheads, and potential privacy leakage. In this article, we study these challenges in over-the-air FEEL and leverage reconfigurable intelligent surface (RIS), a key enabler of future wireless systems, to address these challenges. We study the state-of-the-art solutions on RIS-empowered FEEL and explore the promising research opportunities for adopting RIS to enhance FEEL performance.

</p>
</details>

<details><summary><b>Attention based Sequence to Sequence Learning for Machine Translation of Low Resourced Indic Languages -- A case of Sanskrit to Hindi</b>
<a href="https://arxiv.org/abs/2110.00435">arxiv:2110.00435</a>
&#x1F4C8; 0 <br>
<p>Vishvajit Bakarola, Jitendra Nasriwala</p></summary>
<p>

**Abstract:** Deep Learning techniques are powerful in mimicking humans in a particular set of problems. They have achieved a remarkable performance in complex learning tasks. Deep learning inspired Neural Machine Translation (NMT) is a proficient technique that outperforms traditional machine translation. Performing machine-aided translation on Indic languages has always been a challenging task considering their rich and diverse grammar. The neural machine translation has shown quality results compared to the traditional machine translation approaches. The fully automatic machine translation becomes problematic when it comes to low-resourced languages, especially with Sanskrit. This paper presents attention mechanism based neural machine translation by selectively focusing on a particular part of language sentences during translation. The work shows the construction of Sanskrit to Hindi bilingual parallel corpus with nearly 10K samples and having 178,000 tokens. The neural translation model equipped with an attention mechanism has been trained on Sanskrit to Hindi parallel corpus. The approach has shown the significance of attention mechanisms to overcome long-term dependencies, primarily associated with low resources Indic languages. The paper shows the attention plots on testing data to demonstrate the alignment between source and translated words. For the evaluation of the translated sentences, manual score based human evaluation and automatic evaluation metric based techniques have been adopted. The attention mechanism based neural translation has achieved 88% accuracy in human evaluation and a BLEU score of 0.92 on Sanskrit to Hindi translation.

</p>
</details>

<details><summary><b>Quantum-Classical Hybrid Machine Learning for Image Classification (ICCAD Special Session Paper)</b>
<a href="https://arxiv.org/abs/2109.02862">arxiv:2109.02862</a>
&#x1F4C8; 0 <br>
<p>Mahabubul Alam, Satwik Kundu, Rasit Onur Topaloglu, Swaroop Ghosh</p></summary>
<p>

**Abstract:** Image classification is a major application domain for conventional deep learning (DL). Quantum machine learning (QML) has the potential to revolutionize image classification. In any typical DL-based image classification, we use convolutional neural network (CNN) to extract features from the image and multi-layer perceptron network (MLP) to create the actual decision boundaries. On one hand, QML models can be useful in both of these tasks. Convolution with parameterized quantum circuits (Quanvolution) can extract rich features from the images. On the other hand, quantum neural network (QNN) models can create complex decision boundaries. Therefore, Quanvolution and QNN can be used to create an end-to-end QML model for image classification. Alternatively, we can extract image features separately using classical dimension reduction techniques such as, Principal Components Analysis (PCA) or Convolutional Autoencoder (CAE) and use the extracted features to train a QNN. We review two proposals on quantum-classical hybrid ML models for image classification namely, Quanvolutional Neural Network and dimension reduction using a classical algorithm followed by QNN. Particularly, we make a case for trainable filters in Quanvolution and CAE-based feature extraction for image datasets (instead of dimension reduction using linear transformations such as, PCA). We discuss various design choices, potential opportunities, and drawbacks of these models. We also release a Python-based framework to create and explore these hybrid models with a variety of design choices.

</p>
</details>

<details><summary><b>Pano3D: A Holistic Benchmark and a Solid Baseline for $360^o$ Depth Estimation</b>
<a href="https://arxiv.org/abs/2109.02749">arxiv:2109.02749</a>
&#x1F4C8; 0 <br>
<p>Georgios Albanis, Nikolaos Zioulis, Petros Drakoulis, Vasileios Gkitsas, Vladimiros Sterzentsenko, Federico Alvarez, Dimitrios Zarpalas, Petros Daras</p></summary>
<p>

**Abstract:** Pano3D is a new benchmark for depth estimation from spherical panoramas. It aims to assess performance across all depth estimation traits, the primary direct depth estimation performance targeting precision and accuracy, and also the secondary traits, boundary preservation, and smoothness. Moreover, Pano3D moves beyond typical intra-dataset evaluation to inter-dataset performance assessment. By disentangling the capacity to generalize to unseen data into different test splits, Pano3D represents a holistic benchmark for $360^o$ depth estimation. We use it as a basis for an extended analysis seeking to offer insights into classical choices for depth estimation. This results in a solid baseline for panoramic depth that follow-up works can build upon to steer future progress.

</p>
</details>

<details><summary><b>Dual camera snapshot hyperspectral imaging system via physics informed learning</b>
<a href="https://arxiv.org/abs/2109.02643">arxiv:2109.02643</a>
&#x1F4C8; 0 <br>
<p>Hui Xie, Zhuang Zhao, Jing Han, Yi Zhang, Lianfa Bai, Jun Lu</p></summary>
<p>

**Abstract:** We consider using the system's optical imaging process with convolutional neural networks (CNNs) to solve the snapshot hyperspectral imaging reconstruction problem, which uses a dual-camera system to capture the three-dimensional hyperspectral images (HSIs) in a compressed way. Various methods using CNNs have been developed in recent years to reconstruct HSIs, but most of the supervised deep learning methods aimed to fit a brute-force mapping relationship between the captured compressed image and standard HSIs. Thus, the learned mapping would be invalid when the observation data deviate from the training data. Especially, we usually don't have ground truth in real-life scenarios. In this paper, we present a self-supervised dual-camera equipment with an untrained physics-informed CNNs framework. Extensive simulation and experimental results show that our method without training can be adapted to a wide imaging environment with good performance. Furthermore, compared with the training-based methods, our system can be constantly fine-tuned and self-improved in real-life scenarios.

</p>
</details>


[Next Page]({{ '/2021/09/05/2021.09.05.html' | relative_url }})
