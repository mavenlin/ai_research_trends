Prev: [2022.09.18]({{ '/2022/09/18/2022.09.18.html' | relative_url }})  Next: [2022.09.20]({{ '/2022/09/20/2022.09.20.html' | relative_url }})
{% raw %}
## Summary for 2022-09-19, created on 2022-09-26


<details><summary><b>In progress</b>
<a href="https://arxiv.org/abs/2209.08860">arxiv:2209.08860</a>
&#x1F4C8; 10100000 <br>
<p>Zongyu Li, Zhenfeng Zhu, Zhenyu Guo</p></summary>
<p>

**Abstract:** The concept of causality plays an important role in human cognition . In the past few decades, causal inference has been well developed in many fields, such as computer science, medicine, economics, and education. With the advancement of deep learning techniques, it has been increasingly used in causal inference against counterfactual data. Typically, deep causal models map the characteristics of covariates to a representation space and then design various objective optimization functions to estimate counterfactual data unbiasedly based on the different optimization methods. This paper focuses on the survey of the deep causal models, and its core contributions are as follows: 1) we provide relevant metrics under multiple treatments and continuous-dose treatment; 2) we incorporate a comprehensive overview of deep causal models from both temporal development and method classification perspectives; 3) we assist a detailed and comprehensive classification and analysis of relevant datasets and source code.

</p>
</details>

<details><summary><b>Exponential advantage on noisy quantum computers</b>
<a href="https://arxiv.org/abs/2209.09371">arxiv:2209.09371</a>
&#x1F4C8; 487 <br>
<p>Ismail Yunus Akhalwaya, Shashanka Ubaru, Kenneth L. Clarkson, Mark S. Squillante, Vishnu Jejjala, Yang-Hui He, Kugendran Naidoo, Vasileios Kalantzis, Lior Horesh</p></summary>
<p>

**Abstract:** Quantum computing offers the potential of exponential speedup over classical computation for certain problems. However, many of the existing algorithms with provable speedups require currently unavailable fault-tolerant quantum computers. We present NISQ-TDA, the first fully implemented quantum machine learning algorithm with provable exponential speedup on arbitrary classical (non-handcrafted) data and needing only a linear circuit depth. We report the successful execution of our NISQ-TDA algorithm, applied to small datasets run on quantum computing devices, as well as on noisy quantum simulators. We empirically confirm that the algorithm is robust to noise, and provide target depths and noise levels to realize near-term, non-fault-tolerant quantum advantage on real-world problems. Our unique data-loading projection method is the main source of noise robustness, introducing a new self-correcting data-loading approach.

</p>
</details>

<details><summary><b>Understanding reinforcement learned crowds</b>
<a href="https://arxiv.org/abs/2209.09344">arxiv:2209.09344</a>
&#x1F4C8; 31 <br>
<p>Ariel Kwiatkowski, Vicky Kalogeiton, Julien Pettré, Marie-Paule Cani</p></summary>
<p>

**Abstract:** Simulating trajectories of virtual crowds is a commonly encountered task in Computer Graphics. Several recent works have applied Reinforcement Learning methods to animate virtual agents, however they often make different design choices when it comes to the fundamental simulation setup. Each of these choices comes with a reasonable justification for its use, so it is not obvious what is their real impact, and how they affect the results. In this work, we analyze some of these arbitrary choices in terms of their impact on the learning performance, as well as the quality of the resulting simulation measured in terms of the energy efficiency. We perform a theoretical analysis of the properties of the reward function design, and empirically evaluate the impact of using certain observation and action spaces on a variety of scenarios, with the reward function and energy usage as metrics. We show that directly using the neighboring agents' information as observation generally outperforms the more widely used raycasting. Similarly, using nonholonomic controls with egocentric observations tends to produce more efficient behaviors than holonomic controls with absolute observations. Each of these choices has a significant, and potentially nontrivial impact on the results, and so researchers should be mindful about choosing and reporting them in their work.

</p>
</details>

<details><summary><b>Accelerating Neural Network Inference with Processing-in-DRAM: From the Edge to the Cloud</b>
<a href="https://arxiv.org/abs/2209.08938">arxiv:2209.08938</a>
&#x1F4C8; 28 <br>
<p>Geraldo F. Oliveira, Juan Gómez-Luna, Saugata Ghose, Amirali Boroumand, Onur Mutlu</p></summary>
<p>

**Abstract:** Neural networks (NNs) are growing in importance and complexity. A neural network's performance (and energy efficiency) can be bound either by computation or memory resources. The processing-in-memory (PIM) paradigm, where computation is placed near or within memory arrays, is a viable solution to accelerate memory-bound NNs. However, PIM architectures vary in form, where different PIM approaches lead to different trade-offs. Our goal is to analyze, discuss, and contrast DRAM-based PIM architectures for NN performance and energy efficiency. To do so, we analyze three state-of-the-art PIM architectures: (1) UPMEM, which integrates processors and DRAM arrays into a single 2D chip; (2) Mensa, a 3D-stack-based PIM architecture tailored for edge devices; and (3) SIMDRAM, which uses the analog principles of DRAM to execute bit-serial operations. Our analysis reveals that PIM greatly benefits memory-bound NNs: (1) UPMEM provides 23x the performance of a high-end GPU when the GPU requires memory oversubscription for a general matrix-vector multiplication kernel; (2) Mensa improves energy efficiency and throughput by 3.0x and 3.1x over the Google Edge TPU for 24 Google edge NN models; and (3) SIMDRAM outperforms a CPU/GPU by 16.7x/1.4x for three binary NNs. We conclude that the ideal PIM architecture for NN models depends on a model's distinct attributes, due to the inherent architectural design choices.

</p>
</details>

<details><summary><b>Neural Collapse with Normalized Features: A Geometric Analysis over the Riemannian Manifold</b>
<a href="https://arxiv.org/abs/2209.09211">arxiv:2209.09211</a>
&#x1F4C8; 24 <br>
<p>Can Yaras, Peng Wang, Zhihui Zhu, Laura Balzano, Qing Qu</p></summary>
<p>

**Abstract:** When training overparameterized deep networks for classification tasks, it has been widely observed that the learned features exhibit a so-called "neural collapse" phenomenon. More specifically, for the output features of the penultimate layer, for each class the within-class features converge to their means, and the means of different classes exhibit a certain tight frame structure, which is also aligned with the last layer's classifier. As feature normalization in the last layer becomes a common practice in modern representation learning, in this work we theoretically justify the neural collapse phenomenon for normalized features. Based on an unconstrained feature model, we simplify the empirical loss function in a multi-class classification task into a nonconvex optimization problem over the Riemannian manifold by constraining all features and classifiers over the sphere. In this context, we analyze the nonconvex landscape of the Riemannian optimization problem over the product of spheres, showing a benign global landscape in the sense that the only global minimizers are the neural collapse solutions while all other critical points are strict saddles with negative curvature. Experimental results on practical deep networks corroborate our theory and demonstrate that better representations can be learned faster via feature normalization.

</p>
</details>

<details><summary><b>Space-time tradeoffs of lenses and optics via higher category theory</b>
<a href="https://arxiv.org/abs/2209.09351">arxiv:2209.09351</a>
&#x1F4C8; 20 <br>
<p>Bruno Gavranović</p></summary>
<p>

**Abstract:** Optics and lenses are abstract categorical gadgets that model systems with bidirectional data flow. In this paper we observe that the denotational definition of optics - identifying two optics as equivalent by observing their behaviour from the outside - is not suitable for operational, software oriented approaches where optics are not merely observed, but built with their internal setups in mind. We identify operational differences between denotationally isomorphic categories of cartesian optics and lenses: their different composition rule and corresponding space-time tradeoffs, positioning them at two opposite ends of a spectrum. With these motivations we lift the existing categorical constructions and their relationships to the 2-categorical level, showing that the relevant operational concerns become visible. We define the 2-category $\textbf{2-Optic}(\mathcal{C})$ whose 2-cells explicitly track optics' internal configuration. We show that the 1-category $\textbf{Optic}(\mathcal{C})$ arises by locally quotienting out the connected components of this 2-category. We show that the embedding of lenses into cartesian optics gets weakened from a functor to an oplax functor whose oplaxator now detects the different composition rule. We determine the difficulties in showing this functor forms a part of an adjunction in any of the standard 2-categories. We establish a conjecture that the well-known isomorphism between cartesian lenses and optics arises out of the lax 2-adjunction between their double-categorical counterparts. In addition to presenting new research, this paper is also meant to be an accessible introduction to the topic.

</p>
</details>

<details><summary><b>A Zero-Shot Adaptive Quadcopter Controller</b>
<a href="https://arxiv.org/abs/2209.09232">arxiv:2209.09232</a>
&#x1F4C8; 10 <br>
<p>Dingqi Zhang, Antonio Loquercio, Xiangyu Wu, Ashish Kumar, Jitendra Malik, Mark W. Mueller</p></summary>
<p>

**Abstract:** This paper proposes a universal adaptive controller for quadcopters, which can be deployed zero-shot to quadcopters of very different mass, arm lengths and motor constants, and also shows rapid adaptation to unknown disturbances during runtime. The core algorithmic idea is to learn a single policy that can adapt online at test time not only to the disturbances applied to the drone, but also to the robot dynamics and hardware in the same framework. We achieve this by training a neural network to estimate a latent representation of the robot and environment parameters, which is used to condition the behaviour of the controller, also represented as a neural network. We train both networks exclusively in simulation with the goal of flying the quadcopters to goal positions and avoiding crashes to the ground. We directly deploy the same controller trained in the simulation without any modifications on two quadcopters with differences in mass, inertia, and maximum motor speed of up to 4 times. In addition, we show rapid adaptation to sudden and large disturbances (up to 35.7%) in the mass and inertia of the quadcopters. We perform an extensive evaluation in both simulation and the physical world, where we outperform a state-of-the-art learning-based adaptive controller and a traditional PID controller specifically tuned to each platform individually. Video results can be found at https://dz298.github.io/universal-drone-controller/.

</p>
</details>

<details><summary><b>3D Cross Pseudo Supervision (3D-CPS): A semi-supervised nnU-Net architecture for abdominal organ segmentation</b>
<a href="https://arxiv.org/abs/2209.08939">arxiv:2209.08939</a>
&#x1F4C8; 10 <br>
<p>Yongzhi Huang, Hanwen Zhang, Yan Yan, Haseeb Hassan, Bingding Huang</p></summary>
<p>

**Abstract:** Large curated datasets are necessary, but annotating medical images is a time-consuming, laborious, and expensive process. Therefore, recent supervised methods are focusing on utilizing a large amount of unlabeled data. However, to do so, is a challenging task. To address this problem, we propose a new 3D Cross Pseudo Supervision (3D-CPS) method, a semi-supervised network architecture based on nnU-Net with the Cross Pseudo Supervision method. We design a new nnU-Net based preprocessing method and adopt the forced spacing settings strategy in the inference stage to speed up the inference time. In addition, we set the semi-supervised loss weights to expand linearity with each epoch to prevent the model from low-quality pseudo-labels in the early training process. Our proposed method achieves an average dice similarity coefficient (DSC) of 0.881 and an average normalized surface distance (NSD) of 0.913 on the MICCAI FLARE2022 validation set (20 cases).

</p>
</details>

<details><summary><b>The Biased Artist: Exploiting Cultural Biases via Homoglyphs in Text-Guided Image Generation Models</b>
<a href="https://arxiv.org/abs/2209.08891">arxiv:2209.08891</a>
&#x1F4C8; 10 <br>
<p>Lukas Struppek, Dominik Hintersdorf, Kristian Kersting</p></summary>
<p>

**Abstract:** Text-guided image generation models, such as DALL-E 2 and Stable Diffusion, have recently received much attention from academia and the general public. Provided with textual descriptions, these models are capable of generating high-quality images depicting various concepts and styles. However, such models are trained on large amounts of public data and implicitly learn relationships from their training data that are not immediately apparent. We demonstrate that common multimodal models implicitly learned cultural biases that can be triggered and injected into the generated images by simply replacing single characters in the textual description with visually similar non-Latin characters. These so-called homoglyph replacements enable malicious users or service providers to induce biases into the generated images and even render the whole generation process useless. We practically illustrate such attacks on DALL-E 2 and Stable Diffusion as text-guided image generation models and further show that CLIP also behaves similarly. Our results further indicate that text encoders trained on multilingual data provide a way to mitigate the effects of homoglyph replacements.

</p>
</details>

<details><summary><b>Probabilistic Generative Transformer Language models for Generative Design of Molecules</b>
<a href="https://arxiv.org/abs/2209.09406">arxiv:2209.09406</a>
&#x1F4C8; 9 <br>
<p>Lai Wei, Nihang Fu, Yuqi Song, Qian Wang, Jianjun Hu</p></summary>
<p>

**Abstract:** Self-supervised neural language models have recently found wide applications in generative design of organic molecules and protein sequences as well as representation learning for downstream structure classification and functional prediction. However, most of the existing deep learning models for molecule design usually require a big dataset and have a black-box architecture, which makes it difficult to interpret their design logic. Here we propose Generative Molecular Transformer (GMTransformer), a probabilistic neural network model for generative design of molecules. Our model is built on the blank filling language model originally developed for text processing, which has demonstrated unique advantages in learning the "molecules grammars" with high-quality generation, interpretability, and data efficiency. Benchmarked on the MOSES datasets, our models achieve high novelty and Scaf compared to other baselines. The probabilistic generation steps have the potential in tinkering molecule design due to their capability of recommending how to modify existing molecules with explanation, guided by the learned implicit molecule chemistry. The source code and datasets can be accessed freely at https://github.com/usccolumbia/GMTransformer

</p>
</details>

<details><summary><b>Learning to Walk by Steering: Perceptive Quadrupedal Locomotion in Dynamic Environments</b>
<a href="https://arxiv.org/abs/2209.09233">arxiv:2209.09233</a>
&#x1F4C8; 9 <br>
<p>Mingyo Seo, Ryan Gupta, Yifeng Zhu, Alexy Skoutnev, Luis Sentis, Yuke Zhu</p></summary>
<p>

**Abstract:** We tackle the problem of perceptive locomotion in dynamic environments. In this problem, a quadrupedal robot must exhibit robust and agile walking behaviors in response to environmental clutter and moving obstacles. We present a hierarchical learning framework, named PRELUDE, which decomposes the problem of perceptive locomotion into high-level decision-making to predict navigation commands and low-level gait generation to realize the target commands. In this framework, we train the high-level navigation controller with imitation learning on human demonstrations collected on a steerable cart and the low-level gait controller with reinforcement learning (RL). Therefore, our method can acquire complex navigation behaviors from human supervision and discover versatile gaits from trial and error. We demonstrate the effectiveness of our approach in simulation and with hardware experiments. Video and code can be found on https://ut-austin-rpl.github.io/PRELUDE.

</p>
</details>

<details><summary><b>Machine Learning based Extraction of Boundary Conditions from Doppler Echo Images for Patient Specific Coarctation of the Aorta: Computational Fluid Dynamics Study</b>
<a href="https://arxiv.org/abs/2209.09139">arxiv:2209.09139</a>
&#x1F4C8; 8 <br>
<p>Vincent Milimo Masilokwa Punabantu, Malebogo Ngoepe, Amit Kumar Mishra, Thomas Aldersley, John Lawrenson, Liesl Zuhlke</p></summary>
<p>

**Abstract:** Purpose- Coarctation of the Aorta (CoA) patient-specific computational fluid dynamics (CFD) studies in resource constrained settings are limited by the available imaging modalities for geometry and velocity data acquisition. Doppler echocardiography has been seen as a suitable velocity acquisition modality due to its higher availability and safety. This study aimed to investigate the application of classical machine learning (ML) methods to create an adequate and robust approach for obtaining boundary conditions (BCs) from Doppler Echocardiography images, for haemodynamic modeling using CFD.
  Methods- Our proposed approach combines ML and CFD to model haemodynamic flow within the region of interest. With the key feature of the approach being the use of ML models to calibrate the inlet and outlet boundary conditions (BCs) of the CFD model. The key input variable for the ML model was the patients heart rate as this was the parameter that varied in time across the measured vessels within the study. ANSYS Fluent was used for the CFD component of the study whilst the scikit-learn python library was used for the ML component.
  Results- We validated our approach against a real clinical case of severe CoA before intervention. The maximum coarctation velocity of our simulations were compared to the measured maximum coarctation velocity obtained from the patient whose geometry is used within the study. Of the 5 ML models used to obtain BCs the top model was within 5\% of the measured maximum coarctation velocity.
  Conclusion- The framework demonstrated that it was capable of taking variations of the patients heart rate between measurements into account. Thus, enabling the calculation of BCs that were physiologically realistic when the heart rate was scaled across each vessel whilst providing a reasonably accurate solution.

</p>
</details>

<details><summary><b>EcoFormer: Energy-Saving Attention with Linear Complexity</b>
<a href="https://arxiv.org/abs/2209.09004">arxiv:2209.09004</a>
&#x1F4C8; 8 <br>
<p>Jing Liu, Zizheng Pan, Haoyu He, Jianfei Cai, Bohan Zhuang</p></summary>
<p>

**Abstract:** Transformer is a transformative framework that models sequential data and has achieved remarkable performance on a wide range of tasks, but with high computational and energy cost. To improve its efficiency, a popular choice is to compress the models via binarization which constrains the floating-point values into binary ones to save resource consumption owing to cheap bitwise operations significantly. However, existing binarization methods only aim at minimizing the information loss for the input distribution statistically, while ignoring the pairwise similarity modeling at the core of the attention mechanism. To this end, we propose a new binarization paradigm customized to high-dimensional softmax attention via kernelized hashing, called EcoFormer, to map the original queries and keys into low-dimensional binary codes in Hamming space. The kernelized hash functions are learned to match the ground-truth similarity relations extracted from the attention map in a self-supervised way. Based on the equivalence between the inner product of binary codes and the Hamming distance as well as the associative property of matrix multiplication, we can approximate the attention in linear complexity by expressing it as a dot-product of binary codes. Moreover, the compact binary representations of queries and keys enable us to replace most of the expensive multiply-accumulate operations in attention with simple accumulations to save considerable on-chip energy footprint on edge devices. Extensive experiments on both vision and language tasks show that EcoFormer consistently achieves comparable performance with standard attentions while consuming much fewer resources. For example, based on PVTv2-B0 and ImageNet-1K, Ecoformer achieves a 73% energy footprint reduction with only a 0.33% performance drop compared to the standard attention. Code is available at https://github.com/ziplab/EcoFormer.

</p>
</details>

<details><summary><b>Latent Plans for Task-Agnostic Offline Reinforcement Learning</b>
<a href="https://arxiv.org/abs/2209.08959">arxiv:2209.08959</a>
&#x1F4C8; 8 <br>
<p>Erick Rosete-Beas, Oier Mees, Gabriel Kalweit, Joschka Boedecker, Wolfram Burgard</p></summary>
<p>

**Abstract:** Everyday tasks of long-horizon and comprising a sequence of multiple implicit subtasks still impose a major challenge in offline robot control. While a number of prior methods aimed to address this setting with variants of imitation and offline reinforcement learning, the learned behavior is typically narrow and often struggles to reach configurable long-horizon goals. As both paradigms have complementary strengths and weaknesses, we propose a novel hierarchical approach that combines the strengths of both methods to learn task-agnostic long-horizon policies from high-dimensional camera observations. Concretely, we combine a low-level policy that learns latent skills via imitation learning and a high-level policy learned from offline reinforcement learning for skill-chaining the latent behavior priors. Experiments in various simulated and real robot control tasks show that our formulation enables producing previously unseen combinations of skills to reach temporally extended goals by "stitching" together latent skills through goal chaining with an order-of-magnitude improvement in performance upon state-of-the-art baselines. We even learn one multi-task visuomotor policy for 25 distinct manipulation tasks in the real world which outperforms both imitation learning and offline reinforcement learning techniques.

</p>
</details>

<details><summary><b>Improving Fake News Detection of Influential Domain via Domain- and Instance-Level Transfer</b>
<a href="https://arxiv.org/abs/2209.08902">arxiv:2209.08902</a>
&#x1F4C8; 8 <br>
<p>Qiong Nan, Danding Wang, Yongchun Zhu, Qiang Sheng, Yuhui Shi, Juan Cao, Jintao Li</p></summary>
<p>

**Abstract:** Both real and fake news in various domains, such as politics, health, and entertainment are spread via online social media every day, necessitating fake news detection for multiple domains. Among them, fake news in specific domains like politics and health has more serious potential negative impacts on the real world (e.g., the infodemic led by COVID-19 misinformation). Previous studies focus on multi-domain fake news detection, by equally mining and modeling the correlation between domains. However, these multi-domain methods suffer from a seesaw problem: the performance of some domains is often improved at the cost of hurting the performance of other domains, which could lead to an unsatisfying performance in specific domains. To address this issue, we propose a Domain- and Instance-level Transfer Framework for Fake News Detection (DITFEND), which could improve the performance of specific target domains. To transfer coarse-grained domain-level knowledge, we train a general model with data of all domains from the meta-learning perspective. To transfer fine-grained instance-level knowledge and adapt the general model to a target domain, we train a language model on the target domain to evaluate the transferability of each data instance in source domains and re-weigh each instance's contribution. Offline experiments on two datasets demonstrate the effectiveness of DITFEND. Online experiments show that DITFEND brings additional improvements over the base models in a real-world scenario.

</p>
</details>

<details><summary><b>A Joint Imitation-Reinforcement Learning Framework for Reduced Baseline Regret</b>
<a href="https://arxiv.org/abs/2209.09446">arxiv:2209.09446</a>
&#x1F4C8; 7 <br>
<p>Sheelabhadra Dey, Sumedh Pendurkar, Guni Sharon, Josiah P. Hanna</p></summary>
<p>

**Abstract:** In various control task domains, existing controllers provide a baseline level of performance that -- though possibly suboptimal -- should be maintained. Reinforcement learning (RL) algorithms that rely on extensive exploration of the state and action space can be used to optimize a control policy. However, fully exploratory RL algorithms may decrease performance below a baseline level during training. In this paper, we address the issue of online optimization of a control policy while minimizing regret w.r.t a baseline policy performance. We present a joint imitation-reinforcement learning framework, denoted JIRL. The learning process in JIRL assumes the availability of a baseline policy and is designed with two objectives in mind \textbf{(a)} leveraging the baseline's online demonstrations to minimize the regret w.r.t the baseline policy during training, and \textbf{(b)} eventually surpassing the baseline performance. JIRL addresses these objectives by initially learning to imitate the baseline policy and gradually shifting control from the baseline to an RL agent. Experimental results show that JIRL effectively accomplishes the aforementioned objectives in several, continuous action-space domains. The results demonstrate that JIRL is comparable to a state-of-the-art algorithm in its final performance while incurring significantly lower baseline regret during training in all of the presented domains. Moreover, the results show a reduction factor of up to $21$ in baseline regret over a state-of-the-art baseline regret minimization approach.

</p>
</details>

<details><summary><b>PolyMPCNet: Towards ReLU-free Neural Architecture Search in Two-party Computation Based Private Inference</b>
<a href="https://arxiv.org/abs/2209.09424">arxiv:2209.09424</a>
&#x1F4C8; 6 <br>
<p>Hongwu Peng, Shanglin Zhou, Yukui Luo, Shijin Duan, Nuo Xu, Ran Ran, Shaoyi Huang, Chenghong Wang, Tong Geng, Ang Li, Wujie Wen, Xiaolin Xu, Caiwen Ding</p></summary>
<p>

**Abstract:** The rapid growth and deployment of deep learning (DL) has witnessed emerging privacy and security concerns. To mitigate these issues, secure multi-party computation (MPC) has been discussed, to enable the privacy-preserving DL computation. In practice, they often come at very high computation and communication overhead, and potentially prohibit their popularity in large scale systems. Two orthogonal research trends have attracted enormous interests in addressing the energy efficiency in secure deep learning, i.e., overhead reduction of MPC comparison protocol, and hardware acceleration. However, they either achieve a low reduction ratio and suffer from high latency due to limited computation and communication saving, or are power-hungry as existing works mainly focus on general computing platforms such as CPUs and GPUs.
  In this work, as the first attempt, we develop a systematic framework, PolyMPCNet, of joint overhead reduction of MPC comparison protocol and hardware acceleration, by integrating hardware latency of the cryptographic building block into the DNN loss function to achieve high energy efficiency, accuracy, and security guarantee. Instead of heuristically checking the model sensitivity after a DNN is well-trained (through deleting or dropping some non-polynomial operators), our key design principle is to em enforce exactly what is assumed in the DNN design -- training a DNN that is both hardware efficient and secure, while escaping the local minima and saddle points and maintaining high accuracy. More specifically, we propose a straight through polynomial activation initialization method for cryptographic hardware friendly trainable polynomial activation function to replace the expensive 2P-ReLU operator. We develop a cryptographic hardware scheduler and the corresponding performance model for Field Programmable Gate Arrays (FPGA) platform.

</p>
</details>

<details><summary><b>Deep Linear Networks can Benignly Overfit when Shallow Ones Do</b>
<a href="https://arxiv.org/abs/2209.09315">arxiv:2209.09315</a>
&#x1F4C8; 6 <br>
<p>Niladri S. Chatterji, Philip M. Long</p></summary>
<p>

**Abstract:** We bound the excess risk of interpolating deep linear networks trained using gradient flow. In a setting previously used to establish risk bounds for the minimum $\ell_2$-norm interpolant, we show that randomly initialized deep linear networks can closely approximate or even match known bounds for the minimum $\ell_2$-norm interpolant. Our analysis also reveals that interpolating deep linear models have exactly the same conditional variance as the minimum $\ell_2$-norm solution. Since the noise affects the excess risk only through the conditional variance, this implies that depth does not improve the algorithm's ability to "hide the noise". Our simulations verify that aspects of our bounds reflect typical behavior for simple data distributions. We also find that similar phenomena are seen in simulations with ReLU networks, although the situation there is more nuanced.

</p>
</details>

<details><summary><b>On the Theoretical Properties of Noise Correlation in Stochastic Optimization</b>
<a href="https://arxiv.org/abs/2209.09162">arxiv:2209.09162</a>
&#x1F4C8; 6 <br>
<p>Aurelien Lucchi, Frank Proske, Antonio Orvieto, Francis Bach, Hans Kersting</p></summary>
<p>

**Abstract:** Studying the properties of stochastic noise to optimize complex non-convex functions has been an active area of research in the field of machine learning. Prior work has shown that the noise of stochastic gradient descent improves optimization by overcoming undesirable obstacles in the landscape. Moreover, injecting artificial Gaussian noise has become a popular idea to quickly escape saddle points. Indeed, in the absence of reliable gradient information, the noise is used to explore the landscape, but it is unclear what type of noise is optimal in terms of exploration ability. In order to narrow this gap in our knowledge, we study a general type of continuous-time non-Markovian process, based on fractional Brownian motion, that allows for the increments of the process to be correlated. This generalizes processes based on Brownian motion, such as the Ornstein-Uhlenbeck process. We demonstrate how to discretize such processes which gives rise to the new algorithm fPGD. This method is a generalization of the known algorithms PGD and Anti-PGD. We study the properties of fPGD both theoretically and empirically, demonstrating that it possesses exploration abilities that, in some cases, are favorable over PGD and Anti-PGD. These results open the field to novel ways to exploit noise for training machine learning models.

</p>
</details>

<details><summary><b>SOCRATES: A Stereo Camera Trap for Monitoring of Biodiversity</b>
<a href="https://arxiv.org/abs/2209.09070">arxiv:2209.09070</a>
&#x1F4C8; 6 <br>
<p>Timm Haucke, Hjalmar Kühl, Volker Steinhage</p></summary>
<p>

**Abstract:** The development and application of modern technology is an essential basis for the efficient monitoring of species in natural habitats and landscapes to trace the development of ecosystems, species communities, and populations, and to analyze reasons of changes. For estimating animal abundance using methods such as camera trap distance sampling, spatial information of natural habitats in terms of 3D (three-dimensional) measurements is crucial. Additionally, 3D information improves the accuracy of animal detection using camera trapping. This study presents a novel approach to 3D camera trapping featuring highly optimized hardware and software. This approach employs stereo vision to infer 3D information of natural habitats and is designated as StereO CameRA Trap for monitoring of biodivErSity (SOCRATES). A comprehensive evaluation of SOCRATES shows not only a $3.23\%$ improvement in animal detection (bounding box $\text{mAP}_{75}$) but also its superior applicability for estimating animal abundance using camera trap distance sampling. The software and documentation of SOCRATES is provided at https://github.com/timmh/socrates

</p>
</details>

<details><summary><b>Comparative Study of Q-Learning and NeuroEvolution of Augmenting Topologies for Self Driving Agents</b>
<a href="https://arxiv.org/abs/2209.09007">arxiv:2209.09007</a>
&#x1F4C8; 6 <br>
<p>Arhum Ishtiaq, Maheen Anees, Sara Mahmood, Neha Jafry</p></summary>
<p>

**Abstract:** Autonomous driving vehicles have been of keen interest ever since automation of various tasks started. Humans are prone to exhaustion and have a slow response time on the road, and on top of that driving is already quite a dangerous task with around 1.35 million road traffic incident deaths each year. It is expected that autonomous driving can reduce the number of driving accidents around the world which is why this problem has been of keen interest for researchers. Currently, self-driving vehicles use different algorithms for various sub-problems in making the vehicle autonomous. We will focus reinforcement learning algorithms, more specifically Q-learning algorithms and NeuroEvolution of Augment Topologies (NEAT), a combination of evolutionary algorithms and artificial neural networks, to train a model agent to learn how to drive on a given path. This paper will focus on drawing a comparison between the two aforementioned algorithms.

</p>
</details>

<details><summary><b>EDO-Net: Learning Elastic Properties of Deformable Objects from Graph Dynamics</b>
<a href="https://arxiv.org/abs/2209.08996">arxiv:2209.08996</a>
&#x1F4C8; 6 <br>
<p>Alberta Longhini, Marco Moletta, Alfredo Reichlin, Michael C. Welle, David Held, Zackory Erickson, Danica Kragic</p></summary>
<p>

**Abstract:** We study the problem of learning graph dynamics of deformable objects which generalize to unknown physical properties. In particular, we leverage a latent representation of elastic physical properties of cloth-like deformable objects which we explore through a pulling interaction. We propose EDO-Net (Elastic Deformable Object - Net), a model trained in a self-supervised fashion on a large variety of samples with different elastic properties. EDO-Net jointly learns an adaptation module, responsible for extracting a latent representation of the physical properties of the object, and a forward-dynamics module, which leverages the latent representation to predict future states of cloth-like objects, represented as graphs. We evaluate EDO-Net both in simulation and real world, assessing its capabilities of: 1) generalizing to unknown physical properties of cloth-like deformable objects, 2) transferring the learned representation to new downstream tasks.

</p>
</details>

<details><summary><b>A model-agnostic approach for generating Saliency Maps to explain inferred decisions of Deep Learning Models</b>
<a href="https://arxiv.org/abs/2209.08906">arxiv:2209.08906</a>
&#x1F4C8; 6 <br>
<p>Savvas Karatsiolis, Andreas Kamilaris</p></summary>
<p>

**Abstract:** The widespread use of black-box AI models has raised the need for algorithms and methods that explain the decisions made by these models. In recent years, the AI research community is increasingly interested in models' explainability since black-box models take over more and more complicated and challenging tasks. Explainability becomes critical considering the dominance of deep learning techniques for a wide range of applications, including but not limited to computer vision. In the direction of understanding the inference process of deep learning models, many methods that provide human comprehensible evidence for the decisions of AI models have been developed, with the vast majority relying their operation on having access to the internal architecture and parameters of these models (e.g., the weights of neural networks). We propose a model-agnostic method for generating saliency maps that has access only to the output of the model and does not require additional information such as gradients. We use Differential Evolution (DE) to identify which image pixels are the most influential in a model's decision-making process and produce class activation maps (CAMs) whose quality is comparable to the quality of CAMs created with model-specific algorithms. DE-CAM achieves good performance without requiring access to the internal details of the model's architecture at the cost of more computational complexity.

</p>
</details>

<details><summary><b>Adversarial Color Projection: A Projector-Based Physical Attack to DNNs</b>
<a href="https://arxiv.org/abs/2209.09652">arxiv:2209.09652</a>
&#x1F4C8; 5 <br>
<p>Chengyin Hu, Weiwen Shi</p></summary>
<p>

**Abstract:** Recent advances have shown that deep neural networks (DNNs) are susceptible to adversarial perturbations. Therefore, it is necessary to evaluate the robustness of advanced DNNs using adversarial attacks. However, traditional physical attacks that use stickers as perturbations are more vulnerable than recent light-based physical attacks. In this work, we propose a projector-based physical attack called adversarial color projection (AdvCP), which performs an adversarial attack by manipulating the physical parameters of the projected light. Experiments show the effectiveness of our method in both digital and physical environments. The experimental results demonstrate that the proposed method has excellent attack transferability, which endows AdvCP with effective blackbox attack. We prospect AdvCP threats to future vision-based systems and applications and propose some ideas for light-based physical attacks.

</p>
</details>

<details><summary><b>Locally Constrained Representations in Reinforcement Learning</b>
<a href="https://arxiv.org/abs/2209.09441">arxiv:2209.09441</a>
&#x1F4C8; 5 <br>
<p>Somjit Nath, Samira Ebrahimi Kahou</p></summary>
<p>

**Abstract:** The success of Reinforcement Learning (RL) heavily relies on the ability to learn robust representations from the observations of the environment. In most cases, the representations learned purely by the reinforcement learning loss can differ vastly across states depending on how the value functions change. However, the representations learned need not be very specific to the task at hand. Relying only on the RL objective may yield representations that vary greatly across successive time steps. In addition, since the RL loss has a changing target, the representations learned would depend on how good the current values/policies are. Thus, disentangling the representations from the main task would allow them to focus more on capturing transition dynamics which can improve generalization. To this end, we propose locally constrained representations, where an auxiliary loss forces the state representations to be predictable by the representations of the neighbouring states. This encourages the representations to be driven not only by the value/policy learning but also self-supervised learning, which constrains the representations from changing too rapidly. We evaluate the proposed method on several known benchmarks and observe strong performance. Especially in continuous control tasks, our experiments show a significant advantage over a strong baseline.

</p>
</details>

<details><summary><b>A Machine Learning Approach to Solving Large Bilevel and Stochastic Programs: Application to Cycling Network Design</b>
<a href="https://arxiv.org/abs/2209.09404">arxiv:2209.09404</a>
&#x1F4C8; 5 <br>
<p>Timothy C. Y. Chan, Bo Lin, Shoshanna Saxe</p></summary>
<p>

**Abstract:** We present a novel machine learning-based approach to solving bilevel programs that involve a large number of independent followers, which as a special case include two-stage stochastic programming. We propose an optimization model that explicitly considers a sampled subset of followers and exploits a machine learning model to estimate the objective values of unsampled followers. Unlike existing approaches, we embed machine learning model training into the optimization problem, which allows us to employ general follower features that can not be represented using leader decisions. We prove bounds on the optimality gap of the generated leader decision as measured by the original objective function that considers the full follower set. We then develop follower sampling algorithms to tighten the bounds and a representation learning approach to learn follower features, which can be used as inputs to the embedded machine learning model. Using synthetic instances of a cycling network design problem, we compare the computational performance of our approach versus baseline methods. Our approach provides more accurate predictions for follower objective values, and more importantly, generates leader decisions of higher quality. Finally, we perform a real-world case study on cycling infrastructure planning, where we apply our approach to solve a network design problem with over one million followers. Our approach presents favorable performance compared to the current cycling network expansion practices.

</p>
</details>

<details><summary><b>Polynomial-Time Reachability for LTI Systems with Two-Level Lattice Neural Network Controllers</b>
<a href="https://arxiv.org/abs/2209.09400">arxiv:2209.09400</a>
&#x1F4C8; 5 <br>
<p>James Ferlez, Yasser Shoukry</p></summary>
<p>

**Abstract:** In this paper, we consider the computational complexity of bounding the reachable set of a Linear Time-Invariant (LTI) system controlled by a Rectified Linear Unit (ReLU) Two-Level Lattice (TLL) Neural Network (NN) controller. In particular, we show that for such a system and controller, it is possible to compute the exact one-step reachable set in polynomial time in the size of the size of the TLL NN controller (number of neurons). Additionally, we show that it is possible to obtain a tight bounding box of the reachable set via two polynomial-time methods: one with polynomial complexity in the size of the TLL and the other with polynomial complexity in the Lipschitz constant of the controller and other problem parameters. Crucially, the smaller of the two can be decided in polynomial time for non-degenerate TLL NNs. Finally, we propose a pragmatic algorithm that adaptively combines the benefits of (semi-)exact reachability and approximate reachability, which we call L-TLLBox. We evaluate L-TLLBox with an empirical comparison to a state-of-the-art NN controller reachability tool. In these experiments, L-TLLBox was able to complete reachability analysis as much as 5000x faster than this tool on the same network/system, while producing reach boxes that were from 0.08 to 1.42 times the area.

</p>
</details>

<details><summary><b>Gesture2Path: Imitation Learning for Gesture-aware Navigation</b>
<a href="https://arxiv.org/abs/2209.09375">arxiv:2209.09375</a>
&#x1F4C8; 5 <br>
<p>Catie Cuan, Edward Lee, Emre Fisher, Anthony Francis, Leila Takayama, Tingnan Zhang, Alexander Toshev, Sören Pirk</p></summary>
<p>

**Abstract:** As robots increasingly enter human-centered environments, they must not only be able to navigate safely around humans, but also adhere to complex social norms. Humans often rely on non-verbal communication through gestures and facial expressions when navigating around other people, especially in densely occupied spaces. Consequently, robots also need to be able to interpret gestures as part of solving social navigation tasks. To this end, we present Gesture2Path, a novel social navigation approach that combines image-based imitation learning with model-predictive control. Gestures are interpreted based on a neural network that operates on streams of images, while we use a state-of-the-art model predictive control algorithm to solve point-to-point navigation tasks. We deploy our method on real robots and showcase the effectiveness of our approach for the four gestures-navigation scenarios: left/right, follow me, and make a circle. Our experiments indicate that our method is able to successfully interpret complex human gestures and to use them as a signal to generate socially compliant trajectories for navigation tasks. We validated our method based on in-situ ratings of participants interacting with the robots.

</p>
</details>

<details><summary><b>TimberTrek: Exploring and Curating Sparse Decision Trees with Interactive Visualization</b>
<a href="https://arxiv.org/abs/2209.09227">arxiv:2209.09227</a>
&#x1F4C8; 5 <br>
<p>Zijie J. Wang, Chudi Zhong, Rui Xin, Takuya Takagi, Zhi Chen, Duen Horng Chau, Cynthia Rudin, Margo Seltzer</p></summary>
<p>

**Abstract:** Given thousands of equally accurate machine learning (ML) models, how can users choose among them? A recent ML technique enables domain experts and data scientists to generate a complete Rashomon set for sparse decision trees--a huge set of almost-optimal interpretable ML models. To help ML practitioners identify models with desirable properties from this Rashomon set, we develop TimberTrek, the first interactive visualization system that summarizes thousands of sparse decision trees at scale. Two usage scenarios highlight how TimberTrek can empower users to easily explore, compare, and curate models that align with their domain knowledge and values. Our open-source tool runs directly in users' computational notebooks and web browsers, lowering the barrier to creating more responsible ML models. TimberTrek is available at the following public demo link: https://poloclub.github.io/timbertrek.

</p>
</details>

<details><summary><b>Deep Variation Prior: Joint Image Denoising and Noise Variance Estimation without Clean Data</b>
<a href="https://arxiv.org/abs/2209.09214">arxiv:2209.09214</a>
&#x1F4C8; 5 <br>
<p>Rihuan Ke</p></summary>
<p>

**Abstract:** With recent deep learning based approaches showing promising results in removing noise from images, the best denoising performance has been reported in a supervised learning setup that requires a large set of paired noisy images and ground truth for training. The strong data requirement can be mitigated by unsupervised learning techniques, however, accurate modelling of images or noise variance is still crucial for high-quality solutions. The learning problem is ill-posed for unknown noise distributions. This paper investigates the tasks of image denoising and noise variance estimation in a single, joint learning framework. To address the ill-posedness of the problem, we present deep variation prior (DVP), which states that the variation of a properly learnt denoiser with respect to the change of noise satisfies some smoothness properties, as a key criterion for good denoisers. Building upon DVP, an unsupervised deep learning framework, that simultaneously learns a denoiser and estimates noise variances, is developed. Our method does not require any clean training images or an external step of noise estimation, and instead, approximates the minimum mean squared error denoisers using only a set of noisy images. With the two underlying tasks being considered in a single framework, we allow them to be optimised for each other. The experimental results show a denoising quality comparable to that of supervised learning and accurate noise variance estimates.

</p>
</details>

<details><summary><b>Deep Metric Learning with Chance Constraints</b>
<a href="https://arxiv.org/abs/2209.09060">arxiv:2209.09060</a>
&#x1F4C8; 5 <br>
<p>Yeti Z. Gurbuz, Ogul Can, A. Aydin Alatan</p></summary>
<p>

**Abstract:** Deep metric learning (DML) aims to minimize empirical expected loss of the pairwise intra-/inter- class proximity violations in the embedding image. We relate DML to feasibility problem of finite chance constraints. We show that minimizer of proxy-based DML satisfies certain chance constraints, and that the worst case generalization performance of the proxy-based methods can be characterized by the radius of the smallest ball around a class proxy to cover the entire domain of the corresponding class samples, suggesting multiple proxies per class helps performance. To provide a scalable algorithm as well as exploiting more proxies, we consider the chance constraints implied by the minimizers of proxy-based DML instances and reformulate DML as finding a feasible point in intersection of such constraints, resulting in a problem to be approximately solved by iterative projections. Simply put, we repeatedly train a regularized proxy-based loss and re-initialize the proxies with the embeddings of the deliberately selected new samples. We apply our method with the well-accepted losses and evaluate on four popular benchmark datasets for image retrieval. Outperforming state-of-the-art, our method consistently improves the performance of the applied losses. Code is available at: https://github.com/yetigurbuz/ccp-dml

</p>
</details>

<details><summary><b>MSA-GCN:Multiscale Adaptive Graph Convolution Network for Gait Emotion Recognition</b>
<a href="https://arxiv.org/abs/2209.08988">arxiv:2209.08988</a>
&#x1F4C8; 5 <br>
<p>Yunfei Yin, Li Jing, Faliang Huang, Guangchao Yang, Zhuowei Wang</p></summary>
<p>

**Abstract:** Gait emotion recognition plays a crucial role in the intelligent system. Most of the existing methods recognize emotions by focusing on local actions over time. However, they ignore that the effective distances of different emotions in the time domain are different, and the local actions during walking are quite similar. Thus, emotions should be represented by global states instead of indirect local actions. To address these issues, a novel Multi Scale Adaptive Graph Convolution Network (MSA-GCN) is presented in this work through constructing dynamic temporal receptive fields and designing multiscale information aggregation to recognize emotions. In our model, a adaptive selective spatial-temporal graph convolution is designed to select the convolution kernel dynamically to obtain the soft spatio-temporal features of different emotions. Moreover, a Cross-Scale mapping Fusion Mechanism (CSFM) is designed to construct an adaptive adjacency matrix to enhance information interaction and reduce redundancy. Compared with previous state-of-the-art methods, the proposed method achieves the best performance on two public datasets, improving the mAP by 2\%. We also conduct extensive ablations studies to show the effectiveness of different components in our methods.

</p>
</details>

<details><summary><b>Rethinking Knowledge Graph Evaluation Under the Open-World Assumption</b>
<a href="https://arxiv.org/abs/2209.08858">arxiv:2209.08858</a>
&#x1F4C8; 5 <br>
<p>Haotong Yang, Zhouchen Lin, Muhan Zhang</p></summary>
<p>

**Abstract:** Most knowledge graphs (KGs) are incomplete, which motivates one important research topic on automatically complementing knowledge graphs. However, evaluation of knowledge graph completion (KGC) models often ignores the incompleteness -- facts in the test set are ranked against all unknown triplets which may contain a large number of missing facts not included in the KG yet. Treating all unknown triplets as false is called the closed-world assumption. This closed-world assumption might negatively affect the fairness and consistency of the evaluation metrics. In this paper, we study KGC evaluation under a more realistic setting, namely the open-world assumption, where unknown triplets are considered to include many missing facts not included in the training or test sets. For the currently most used metrics such as mean reciprocal rank (MRR) and Hits@K, we point out that their behavior may be unexpected under the open-world assumption. Specifically, with not many missing facts, their numbers show a logarithmic trend with respect to the true strength of the model, and thus, the metric increase could be insignificant in terms of reflecting the true model improvement. Further, considering the variance, we show that the degradation in the reported numbers may result in incorrect comparisons between different models, where stronger models may have lower metric numbers. We validate the phenomenon both theoretically and experimentally. Finally, we suggest possible causes and solutions for this problem. Our code and data are available at https://github.com/GraphPKU/Open-World-KG .

</p>
</details>

<details><summary><b>Two-stage Modeling for Prediction with Confidence</b>
<a href="https://arxiv.org/abs/2209.08848">arxiv:2209.08848</a>
&#x1F4C8; 5 <br>
<p>Dangxing Chen</p></summary>
<p>

**Abstract:** The use of neural networks has been very successful in a wide variety of applications. However, it has recently been observed that it is difficult to generalize the performance of neural networks under the condition of distributional shift. Several efforts have been made to identify potential out-of-distribution inputs. Although existing literature has made significant progress with regard to images and textual data, finance has been overlooked. The aim of this paper is to investigate the distribution shift in the credit scoring problem, one of the most important applications of finance. For the potential distribution shift problem, we propose a novel two-stage model. Using the out-of-distribution detection method, data is first separated into confident and unconfident sets. As a second step, we utilize the domain knowledge with a mean-variance optimization in order to provide reliable bounds for unconfident samples. Using empirical results, we demonstrate that our model offers reliable predictions for the vast majority of datasets. It is only a small portion of the dataset that is inherently difficult to judge, and we leave them to the judgment of human beings. Based on the two-stage model, highly confident predictions have been made and potential risks associated with the model have been significantly reduced.

</p>
</details>

<details><summary><b>AutoLV: Automatic Lecture Video Generator</b>
<a href="https://arxiv.org/abs/2209.08795">arxiv:2209.08795</a>
&#x1F4C8; 5 <br>
<p>Wenbin Wang, Yang Song, Sanjay Jha</p></summary>
<p>

**Abstract:** We propose an end-to-end lecture video generation system that can generate realistic and complete lecture videos directly from annotated slides, instructor's reference voice and instructor's reference portrait video. Our system is primarily composed of a speech synthesis module with few-shot speaker adaptation and an adversarial learning-based talking-head generation module. It is capable of not only reducing instructors' workload but also changing the language and accent which can help the students follow the lecture more easily and enable a wider dissemination of lecture contents. Our experimental results show that the proposed model outperforms other current approaches in terms of authenticity, naturalness and accuracy. Here is a video demonstration of how our system works, and the outcomes of the evaluation and comparison: https://youtu.be/cY6TYkI0cog.

</p>
</details>

<details><summary><b>D&D: Learning Human Dynamics from Dynamic Camera</b>
<a href="https://arxiv.org/abs/2209.08790">arxiv:2209.08790</a>
&#x1F4C8; 5 <br>
<p>Jiefeng Li, Siyuan Bian, Chao Xu, Gang Liu, Gang Yu, Cewu Lu</p></summary>
<p>

**Abstract:** 3D human pose estimation from a monocular video has recently seen significant improvements. However, most state-of-the-art methods are kinematics-based, which are prone to physically implausible motions with pronounced artifacts. Current dynamics-based methods can predict physically plausible motion but are restricted to simple scenarios with static camera view. In this work, we present D&D (Learning Human Dynamics from Dynamic Camera), which leverages the laws of physics to reconstruct 3D human motion from the in-the-wild videos with a moving camera. D&D introduces inertial force control (IFC) to explain the 3D human motion in the non-inertial local frame by considering the inertial forces of the dynamic camera. To learn the ground contact with limited annotations, we develop probabilistic contact torque (PCT), which is computed by differentiable sampling from contact probabilities and used to generate motions. The contact state can be weakly supervised by encouraging the model to generate correct motions. Furthermore, we propose an attentive PD controller that adjusts target pose states using temporal information to obtain smooth and accurate pose control. Our approach is entirely neural-based and runs without offline optimization or simulation in physics engines. Experiments on large-scale 3D human motion benchmarks demonstrate the effectiveness of D&D, where we exhibit superior performance against both state-of-the-art kinematics-based and dynamics-based methods. Code is available at https://github.com/Jeffsjtu/DnD

</p>
</details>

<details><summary><b>TANDEM3D: Active Tactile Exploration for 3D Object Recognition</b>
<a href="https://arxiv.org/abs/2209.08772">arxiv:2209.08772</a>
&#x1F4C8; 5 <br>
<p>Jingxi Xu, Han Lin, Shuran Song, Matei Ciocarlie</p></summary>
<p>

**Abstract:** Tactile recognition of 3D objects remains a challenging task. Compared to 2D shapes, the complex geometry of 3D surfaces requires richer tactile signals, more dexterous actions, and more advanced encoding techniques. In this work, we propose TANDEM3D, a method that applies a co-training framework for exploration and decision making to 3D object recognition with tactile signals. Starting with our previous work, which introduced a co-training paradigm for 2D recognition problems, we introduce a number of advances that enable us to scale up to 3D. TANDEM3D is based on a novel encoder that builds 3D object representation from contact positions and normals using PointNet++. Furthermore, by enabling 6DOF movement, TANDEM3D explores and collects discriminative touch information with high efficiency. Our method is trained entirely in simulation and validated with real-world experiments. Compared to state-of-the-art baselines, TANDEM3D achieves higher accuracy and a lower number of actions in recognizing 3D objects and is also shown to be more robust to different types and amounts of sensor noise. Video is available at https://jxu.ai/tandem3d.

</p>
</details>

<details><summary><b>Cross Project Software Vulnerability Detection via Domain Adaptation and Max-Margin Principle</b>
<a href="https://arxiv.org/abs/2209.10406">arxiv:2209.10406</a>
&#x1F4C8; 4 <br>
<p>Van Nguyen, Trung Le, Chakkrit Tantithamthavorn, John Grundy, Hung Nguyen, Dinh Phung</p></summary>
<p>

**Abstract:** Software vulnerabilities (SVs) have become a common, serious and crucial concern due to the ubiquity of computer software. Many machine learning-based approaches have been proposed to solve the software vulnerability detection (SVD) problem. However, there are still two open and significant issues for SVD in terms of i) learning automatic representations to improve the predictive performance of SVD, and ii) tackling the scarcity of labeled vulnerabilities datasets that conventionally need laborious labeling effort by experts. In this paper, we propose a novel end-to-end approach to tackle these two crucial issues. We first exploit the automatic representation learning with deep domain adaptation for software vulnerability detection. We then propose a novel cross-domain kernel classifier leveraging the max-margin principle to significantly improve the transfer learning process of software vulnerabilities from labeled projects into unlabeled ones. The experimental results on real-world software datasets show the superiority of our proposed method over state-of-the-art baselines. In short, our method obtains a higher performance on F1-measure, the most important measure in SVD, from 1.83% to 6.25% compared to the second highest method in the used datasets. Our released source code samples are publicly available at https://github.com/vannguyennd/dam2p

</p>
</details>

<details><summary><b>Lazy vs hasty: linearization in deep networks impacts learning schedule based on example difficulty</b>
<a href="https://arxiv.org/abs/2209.09658">arxiv:2209.09658</a>
&#x1F4C8; 4 <br>
<p>Thomas George, Guillaume Lajoie, Aristide Baratin</p></summary>
<p>

**Abstract:** Among attempts at giving a theoretical account of the success of deep neural networks, a recent line of work has identified a so-called `lazy' regime in which the network can be well approximated by its linearization around initialization. Here we investigate the comparative effect of the lazy (linear) and feature learning (non-linear) regimes on subgroups of examples based on their difficulty. Specifically, we show that easier examples are given more weight in feature learning mode, resulting in faster training compared to more difficult ones. In other words, the non-linear dynamics tends to sequentialize the learning of examples of increasing difficulty. We illustrate this phenomenon across different ways to quantify example difficulty, including c-score, label noise, and in the presence of spurious correlations. Our results reveal a new understanding of how deep networks prioritize resources across example difficulty.

</p>
</details>

<details><summary><b>A Closer Look at Novel Class Discovery from the Labeled Set</b>
<a href="https://arxiv.org/abs/2209.09120">arxiv:2209.09120</a>
&#x1F4C8; 4 <br>
<p>Ziyun Li, Jona Otholt, Ben Dai, Di hu, Christoph Meinel, Haojin Yang</p></summary>
<p>

**Abstract:** Novel class discovery (NCD) aims to infer novel categories in an unlabeled dataset leveraging prior knowledge of a labeled set comprising disjoint but related classes. Existing research focuses primarily on utilizing the labeled set at the methodological level, with less emphasis on the analysis of the labeled set itself. Thus, in this paper, we rethink novel class discovery from the labeled set and focus on two core questions: (i) Given a specific unlabeled set, what kind of labeled set can best support novel class discovery? (ii) A fundamental premise of NCD is that the labeled set must be related to the unlabeled set, but how can we measure this relation? For (i), we propose and substantiate the hypothesis that NCD could benefit more from a labeled set with a large degree of semantic similarity to the unlabeled set. Specifically, we establish an extensive and large-scale benchmark with varying degrees of semantic similarity between labeled/unlabeled datasets on ImageNet by leveraging its hierarchical class structure. As a sharp contrast, the existing NCD benchmarks are developed based on labeled sets with different number of categories and images, and completely ignore the semantic relation. For (ii), we introduce a mathematical definition for quantifying the semantic similarity between labeled and unlabeled sets. In addition, we use this metric to confirm the validity of our proposed benchmark and demonstrate that it highly correlates with NCD performance. Furthermore, without quantitative analysis, previous works commonly believe that label information is always beneficial. However, counterintuitively, our experimental results show that using labels may lead to sub-optimal outcomes in low-similarity settings.

</p>
</details>

<details><summary><b>MSVIPER: Improved Policy Distillation for Reinforcement-Learning-Based Robot Navigation</b>
<a href="https://arxiv.org/abs/2209.09079">arxiv:2209.09079</a>
&#x1F4C8; 4 <br>
<p>Aaron M. Roth, Jing Liang, Ram Sriram, Elham Tabassi, Dinesh Manocha</p></summary>
<p>

**Abstract:** We present Multiple Scenario Verifiable Reinforcement Learning via Policy Extraction (MSVIPER), a new method for policy distillation to decision trees for improved robot navigation. MSVIPER learns an "expert" policy using any Reinforcement Learning (RL) technique involving learning a state-action mapping and then uses imitation learning to learn a decision-tree policy from it. We demonstrate that MSVIPER results in efficient decision trees and can accurately mimic the behavior of the expert policy. Moreover, we present efficient policy distillation and tree-modification techniques that take advantage of the decision tree structure to allow improvements to a policy without retraining. We use our approach to improve the performance of RL-based robot navigation algorithms for indoor and outdoor scenes. We demonstrate the benefits in terms of reduced freezing and oscillation behaviors (by up to 95\% reduction) for mobile robots navigating among dynamic obstacles and reduced vibrations and oscillation (by up to 17\%) for outdoor robot navigation on complex, uneven terrains.

</p>
</details>

<details><summary><b>The Royalflush System for VoxCeleb Speaker Recognition Challenge 2022</b>
<a href="https://arxiv.org/abs/2209.09010">arxiv:2209.09010</a>
&#x1F4C8; 4 <br>
<p>Jingguang Tian, Xinhui Hu, Xinkang Xu</p></summary>
<p>

**Abstract:** In this technical report, we describe the Royalflush submissions for the VoxCeleb Speaker Recognition Challenge 2022 (VoxSRC-22). Our submissions contain track 1, which is for supervised speaker verification and track 3, which is for semi-supervised speaker verification. For track 1, we develop a powerful U-Net-based speaker embedding extractor with a symmetric architecture. The proposed system achieves 2.06% in EER and 0.1293 in MinDCF on the validation set. Compared with the state-of-the-art ECAPA-TDNN, it obtains a relative improvement of 20.7% in EER and 22.70% in MinDCF. For track 3, we employ the joint training of source domain supervision and target domain self-supervision to get a speaker embedding extractor. The subsequent clustering process can obtain target domain pseudo-speaker labels. We adapt the speaker embedding extractor using all source and target domain data in a supervised manner, where it can fully leverage both domain information. Moreover, clustering and supervised domain adaptation can be repeated until the performance converges on the validation set. Our final submission is a fusion of 10 models and achieves 7.75% EER and 0.3517 MinDCF on the validation set.

</p>
</details>

<details><summary><b>Playing Technique Detection by Fusing Note Onset Information in Guzheng Performance</b>
<a href="https://arxiv.org/abs/2209.08774">arxiv:2209.08774</a>
&#x1F4C8; 4 <br>
<p>Dichucheng Li, Yulun Wu, Qinyu Li, Jiahao Zhao, Yi Yu, Fan Xia, Wei Li</p></summary>
<p>

**Abstract:** The Guzheng is a kind of traditional Chinese instruments with diverse playing techniques. Instrument playing techniques (IPT) play an important role in musical performance. However, most of the existing works for IPT detection show low efficiency for variable-length audio and provide no assurance in the generalization as they rely on a single sound bank for training and testing. In this study, we propose an end-to-end Guzheng playing technique detection system using Fully Convolutional Networks that can be applied to variable-length audio. Because each Guzheng playing technique is applied to a note, a dedicated onset detector is trained to divide an audio into several notes and its predictions are fused with frame-wise IPT predictions. During fusion, we add the IPT predictions frame by frame inside each note and get the IPT with the highest probability within each note as the final output of that note. We create a new dataset named GZ_IsoTech from multiple sound banks and real-world recordings for Guzheng performance analysis. Our approach achieves 87.97% in frame-level accuracy and 80.76% in note-level F1-score, outperforming existing works by a large margin, which indicates the effectiveness of our proposed method in IPT detection.

</p>
</details>

<details><summary><b>CofeNet: Context and Former-Label Enhanced Net for Complicated Quotation Extraction</b>
<a href="https://arxiv.org/abs/2209.09432">arxiv:2209.09432</a>
&#x1F4C8; 3 <br>
<p>Yequan Wang, Xiang Li, Aixin Sun, Xuying Meng, Huaming Liao, Jiafeng Guo</p></summary>
<p>

**Abstract:** Quotation extraction aims to extract quotations from written text. There are three components in a quotation: source refers to the holder of the quotation, cue is the trigger word(s), and content is the main body. Existing solutions for quotation extraction mainly utilize rule-based approaches and sequence labeling models. While rule-based approaches often lead to low recalls, sequence labeling models cannot well handle quotations with complicated structures. In this paper, we propose the Context and Former-Label Enhanced Net (CofeNet) for quotation extraction. CofeNet is able to extract complicated quotations with components of variable lengths and complicated structures. On two public datasets (i.e., PolNeAR and Riqua) and one proprietary dataset (i.e., PoliticsZH), we show that our CofeNet achieves state-of-the-art performance on complicated quotation extraction.

</p>
</details>

<details><summary><b>Multi-armed Bandit Learning on a Graph</b>
<a href="https://arxiv.org/abs/2209.09419">arxiv:2209.09419</a>
&#x1F4C8; 3 <br>
<p>Tianpeng Zhang, Kasper Johansson, Na Li</p></summary>
<p>

**Abstract:** The multi-armed bandit(MAB) problem is a simple yet powerful framework that has been extensively studied in the context of decision-making under uncertainty. In many real-world applications, such as robotic applications, selecting an arm corresponds to a physical action that constrains the choices of the next available arms (actions). Motivated by this, we study an extension of MAB called the graph bandit, where an agent travels over a graph trying to maximize the reward collected from different nodes. The graph defines the freedom of the agent in selecting the next available nodes at each step. We assume the graph structure is fully available, but the reward distributions are unknown. Built upon an offline graph-based planning algorithm and the principle of optimism, we design an online learning algorithm that balances long-term exploration-exploitation using the principle of optimism. We show that our proposed algorithm achieves $O(|S|\sqrt{T}\log(T)+D|S|\log T)$ learning regret, where $|S|$ is the number of nodes and $D$ is the diameter of the graph, which is superior compared to the best-known reinforcement learning algorithms under similar settings. Numerical experiments confirm that our algorithm outperforms several benchmarks. Finally, we present a synthetic robotic application modeled by the graph bandit framework, where a robot moves on a network of rural/suburban locations to provide high-speed internet access using our proposed algorithm.

</p>
</details>

<details><summary><b>Automatic Label Sequence Generation for Prompting Sequence-to-sequence Models</b>
<a href="https://arxiv.org/abs/2209.09401">arxiv:2209.09401</a>
&#x1F4C8; 3 <br>
<p>Zichun Yu, Tianyu Gao, Zhengyan Zhang, Yankai Lin, Zhiyuan Liu, Maosong Sun, Jie Zhou</p></summary>
<p>

**Abstract:** Prompting, which casts downstream applications as language modeling tasks, has shown to be sample efficient compared to standard fine-tuning with pre-trained models. However, one pitfall of prompting is the need of manually-designed patterns, whose outcome can be unintuitive and requires large validation sets to tune. To tackle the challenge, we propose AutoSeq, a fully automatic prompting method: (1) We adopt natural language prompts on sequence-to-sequence models, enabling free-form generation and larger label search space; (2) We propose label sequences -- phrases with indefinite lengths to verbalize the labels -- which eliminate the need of manual templates and are more expressive than single label words; (3) We use beam search to automatically generate a large amount of label sequence candidates and propose contrastive re-ranking to get the best combinations. AutoSeq significantly outperforms other no-manual-design methods, such as soft prompt tuning, adapter tuning, and automatic search on single label words; the generated label sequences are even better than curated manual ones on a variety of tasks. Our method reveals the potential of sequence-to-sequence models in few-shot learning and sheds light on a path to generic and automatic prompting. The source code of this paper can be obtained from https://github.com/thunlp/Seq2Seq-Prompt.

</p>
</details>

<details><summary><b>Development of a Modular and Submersible Soft Robotic Arm and Corresponding Learned Kinematics Models</b>
<a href="https://arxiv.org/abs/2209.09358">arxiv:2209.09358</a>
&#x1F4C8; 3 <br>
<p>W. David Null,  YZ</p></summary>
<p>

**Abstract:** Most soft-body organisms found in nature exist in underwater environments. It is helpful to study the motion and control of soft robots underwater as well. However, a readily available underwater soft robotic system is not available for researchers to use because they are difficult to design, fabricate, and waterproof. Furthermore, submersible robots usually do not have configurable components because of the need for sealed electronics packages. This work presents the development of a submersible soft robotic arm driven by hydraulic actuators which consists of mostly 3D printable parts which can be assembled in a short amount of time. Also, its modular design enables multiple shape configurations and easy swapping of soft actuators. As a first step to exploring machine learning control algorithms on this system, two deep neural network models were developed, trained, and evaluated to estimate the robot's forward and inverse kinematics. The techniques developed for controlling this underwater soft robotic arm can help advance understanding on how to control soft robotic systems in general.

</p>
</details>

<details><summary><b>Visible-Infrared Person Re-Identification Using Privileged Intermediate Information</b>
<a href="https://arxiv.org/abs/2209.09348">arxiv:2209.09348</a>
&#x1F4C8; 3 <br>
<p>Mahdi Alehdaghi, Arthur Josi, Rafael M. O. Cruz, Eric Granger</p></summary>
<p>

**Abstract:** Visible-infrared person re-identification (ReID) aims to recognize a same person of interest across a network of RGB and IR cameras. Some deep learning (DL) models have directly incorporated both modalities to discriminate persons in a joint representation space. However, this cross-modal ReID problem remains challenging due to the large domain shift in data distributions between RGB and IR modalities. %
This paper introduces a novel approach for a creating intermediate virtual domain that acts as bridges between the two main domains (i.e., RGB and IR modalities) during training. This intermediate domain is considered as privileged information (PI) that is unavailable at test time, and allows formulating this cross-modal matching task as a problem in learning under privileged information (LUPI). We devised a new method to generate images between visible and infrared domains that provide additional information to train a deep ReID model through an intermediate domain adaptation. In particular, by employing color-free and multi-step triplet loss objectives during training, our method provides common feature representation spaces that are robust to large visible-infrared domain shifts. %
Experimental results on challenging visible-infrared ReID datasets indicate that our proposed approach consistently improves matching accuracy, without any computational overhead at test time. The code is available at: \href{https://github.com/alehdaghi/Cross-Modal-Re-ID-via-LUPI}{https://github.com/alehdaghi/Cross-Modal-Re-ID-via-LUPI}

</p>
</details>

<details><summary><b>Meta-Reinforcement Learning for Adaptive Control of Second Order Systems</b>
<a href="https://arxiv.org/abs/2209.09301">arxiv:2209.09301</a>
&#x1F4C8; 3 <br>
<p>Daniel G. McClement, Nathan P. Lawrence, Michael G. Forbes, Philip D. Loewen, Johan U. Backström, R. Bhushan Gopaluni</p></summary>
<p>

**Abstract:** Meta-learning is a branch of machine learning which aims to synthesize data from a distribution of related tasks to efficiently solve new ones. In process control, many systems have similar and well-understood dynamics, which suggests it is feasible to create a generalizable controller through meta-learning. In this work, we formulate a meta reinforcement learning (meta-RL) control strategy that takes advantage of known, offline information for training, such as a model structure. The meta-RL agent is trained over a distribution of model parameters, rather than a single model, enabling the agent to automatically adapt to changes in the process dynamics while maintaining performance. A key design element is the ability to leverage model-based information offline during training, while maintaining a model-free policy structure for interacting with new environments. Our previous work has demonstrated how this approach can be applied to the industrially-relevant problem of tuning proportional-integral controllers to control first order processes. In this work, we briefly reintroduce our methodology and demonstrate how it can be extended to proportional-integral-derivative controllers and second order systems.

</p>
</details>

<details><summary><b>Interpreting mechanism of Synergism of drug combinations using attention based hierarchical graph pooling</b>
<a href="https://arxiv.org/abs/2209.09245">arxiv:2209.09245</a>
&#x1F4C8; 3 <br>
<p>Zehao Dong, Yixin Chen, Philip Payne, Fuhai Li</p></summary>
<p>

**Abstract:** The synergistic drug combinations provide huge potentials to enhance therapeutic efficacy and to reduce adverse reactions. However, effective and synergistic drug combination prediction remains an open question because of the unknown causal disease signaling pathways. Though various deep learning (AI) models have been proposed to quantitatively predict the synergism of drug combinations. The major limitation of existing deep learning methods is that they are inherently not interpretable, which makes the conclusion of AI models un-transparent to human experts, henceforth limiting the robustness of the model conclusion and the implementation ability of these models in the real-world human-AI healthcare. In this paper, we develop an interpretable graph neural network (GNN) that reveals the underlying essential therapeutic targets and mechanism of the synergy (MoS) by mining the sub-molecular network of great importance. The key point of the interpretable GNN prediction model is a novel graph pooling layer, Self-Attention based Node and Edge pool (henceforth SANEpool), that can compute the attention score (importance) of nodes and edges based on the node features and the graph topology. As such, the proposed GNN model provides a systematic way to predict and interpret the drug combination synergism based on the detected crucial sub-molecular network. We evaluate SANEpool on molecular networks formulated by genes from 46 core cancer signaling pathways and drug combinations from NCI ALMANAC drug combination screening data. The experimental results indicate that 1) SANEpool can achieve the current state-of-art performance among other popular graph neural networks; and 2) the sub-molecular network detected by SANEpool are self-explainable and salient for identifying synergistic drug combinations.

</p>
</details>

<details><summary><b>Active Inference for Autonomous Decision-Making with Contextual Multi-Armed Bandits</b>
<a href="https://arxiv.org/abs/2209.09185">arxiv:2209.09185</a>
&#x1F4C8; 3 <br>
<p>Shohei Wakayama, Nisar Ahmed</p></summary>
<p>

**Abstract:** In autonomous robotic decision-making under uncertainty, the tradeoff between exploitation and exploration of available options must be considered. If secondary information associated with options can be utilized, such decision-making problems can often be formulated as a contextual multi-armed bandits (CMABs). In this study, we apply active inference, which has been actively studied in the field of neuroscience in recent years, as an alternative action selection strategy for CMABs. Unlike conventional action selection strategies, it is possible to rigorously evaluate the uncertainty of each option when calculating the expected free energy (EFE) associated with the decision agent's probabilistic model, as derived from the free-energy principle. We specifically address the case where a categorical observation likelihood function is used, such that EFE values are analytically intractable. We introduce new approximation methods for computing the EFE based on variational and Laplace approximations. Extensive simulation study results demonstrate that, compared to other strategies, active inference generally requires far fewer iterations to identify optimal options and generally achieves superior cumulative regret, for relatively low extra computational cost.

</p>
</details>

<details><summary><b>Active Predicting Coding: Brain-Inspired Reinforcement Learning for Sparse Reward Robotic Control Problems</b>
<a href="https://arxiv.org/abs/2209.09174">arxiv:2209.09174</a>
&#x1F4C8; 3 <br>
<p>Alexander Ororbia, Ankur Mali</p></summary>
<p>

**Abstract:** In this article, we propose a backpropagation-free approach to robotic control through the neuro-cognitive computational framework of neural generative coding (NGC), designing an agent built completely from powerful predictive coding/processing circuits that facilitate dynamic, online learning from sparse rewards, embodying the principles of planning-as-inference. Concretely, we craft an adaptive agent system, which we call active predictive coding (ActPC), that balances an internally-generated epistemic signal (meant to encourage intelligent exploration) with an internally-generated instrumental signal (meant to encourage goal-seeking behavior) to ultimately learn how to control various simulated robotic systems as well as a complex robotic arm using a realistic robotics simulator, i.e., the Surreal Robotics Suite, for the block lifting task and can pick-and-place problems. Notably, our experimental results demonstrate that our proposed ActPC agent performs well in the face of sparse (extrinsic) reward signals and is competitive with or outperforms several powerful backprop-based RL approaches.

</p>
</details>

<details><summary><b>Application of Neural Network in the Prediction of NOx Emissions from Degrading Gas Turbine</b>
<a href="https://arxiv.org/abs/2209.09168">arxiv:2209.09168</a>
&#x1F4C8; 3 <br>
<p>Zhenkun Zheng, Alan Rezazadeh</p></summary>
<p>

**Abstract:** This paper is aiming to apply neural network algorithm for predicting the process response (NOx emissions) from degrading natural gas turbines. Nine different process variables, or predictors, are considered in the predictive modelling. It is found out that the model trained by neural network algorithm should use part of recent data in the training and validation sets accounting for the impact of the system degradation. R-Square values of the training and validation sets demonstrate the validity of the model. The residue plot, without any clear pattern, shows the model is appropriate. The ranking of the importance of the process variables are demonstrated and the prediction profile confirms the significance of the process variables. The model trained by using neural network algorithm manifests the optimal settings of the process variables to reach the minimum value of NOx emissions from the degrading gas turbine system.

</p>
</details>

<details><summary><b>"Guess what I'm doing": Extending legibility to sequential decision tasks</b>
<a href="https://arxiv.org/abs/2209.09141">arxiv:2209.09141</a>
&#x1F4C8; 3 <br>
<p>Miguel Faria, Francisco S. Melo, Ana Paiva</p></summary>
<p>

**Abstract:** In this paper we investigate the notion of legibility in sequential decision tasks under uncertainty. Previous works that extend legibility to scenarios beyond robot motion either focus on deterministic settings or are computationally too expensive. Our proposed approach, dubbed PoL-MDP, is able to handle uncertainty while remaining computationally tractable. We establish the advantages of our approach against state-of-the-art approaches in several simulated scenarios of different complexity. We also showcase the use of our legible policies as demonstrations for an inverse reinforcement learning agent, establishing their superiority against the commonly used demonstrations based on the optimal policy. Finally, we assess the legibility of our computed policies through a user study where people are asked to infer the goal of a mobile robot following a legible policy by observing its actions.

</p>
</details>

<details><summary><b>Measuring Interventional Robustness in Reinforcement Learning</b>
<a href="https://arxiv.org/abs/2209.09058">arxiv:2209.09058</a>
&#x1F4C8; 3 <br>
<p>Katherine Avery, Jack Kenney, Pracheta Amaranath, Erica Cai, David Jensen</p></summary>
<p>

**Abstract:** Recent work in reinforcement learning has focused on several characteristics of learned policies that go beyond maximizing reward. These properties include fairness, explainability, generalization, and robustness. In this paper, we define interventional robustness (IR), a measure of how much variability is introduced into learned policies by incidental aspects of the training procedure, such as the order of training data or the particular exploratory actions taken by agents. A training procedure has high IR when the agents it produces take very similar actions under intervention, despite variation in these incidental aspects of the training procedure. We develop an intuitive, quantitative measure of IR and calculate it for eight algorithms in three Atari environments across dozens of interventions and states. From these experiments, we find that IR varies with the amount of training and type of algorithm and that high performance does not imply high IR, as one might expect.

</p>
</details>

<details><summary><b>Concept Embedding Models</b>
<a href="https://arxiv.org/abs/2209.09056">arxiv:2209.09056</a>
&#x1F4C8; 3 <br>
<p>Mateo Espinosa Zarlenga, Pietro Barbiero, Gabriele Ciravegna, Giuseppe Marra, Francesco Giannini, Michelangelo Diligenti, Zohreh Shams, Frederic Precioso, Stefano Melacci, Adrian Weller, Pietro Lio, Mateja Jamnik</p></summary>
<p>

**Abstract:** Deploying AI-powered systems requires trustworthy models supporting effective human interactions, going beyond raw prediction accuracy. Concept bottleneck models promote trustworthiness by conditioning classification tasks on an intermediate level of human-like concepts. This enables human interventions which can correct mispredicted concepts to improve the model's performance. However, existing concept bottleneck models are unable to find optimal compromises between high task accuracy, robust concept-based explanations, and effective interventions on concepts -- particularly in real-world conditions where complete and accurate concept supervisions are scarce. To address this, we propose Concept Embedding Models, a novel family of concept bottleneck models which goes beyond the current accuracy-vs-interpretability trade-off by learning interpretable high-dimensional concept representations. Our experiments demonstrate that Concept Embedding Models (1) attain better or competitive task accuracy w.r.t. standard neural models without concepts, (2) provide concept representations capturing meaningful semantics including and beyond their ground truth labels, (3) support test-time concept interventions whose effect in test accuracy surpasses that in standard concept bottleneck models, and (4) scale to real-world conditions where complete concept supervisions are scarce.

</p>
</details>

<details><summary><b>A Transferable and Automatic Tuning of Deep Reinforcement Learning for Cost Effective Phishing Detection</b>
<a href="https://arxiv.org/abs/2209.09033">arxiv:2209.09033</a>
&#x1F4C8; 3 <br>
<p>Orel Lavie, Asaf Shabtai, Gilad Katz</p></summary>
<p>

**Abstract:** Many challenging real-world problems require the deployment of ensembles multiple complementary learning models to reach acceptable performance levels. While effective, applying the entire ensemble to every sample is costly and often unnecessary. Deep Reinforcement Learning (DRL) offers a cost-effective alternative, where detectors are dynamically chosen based on the output of their predecessors, with their usefulness weighted against their computational cost. Despite their potential, DRL-based solutions are not widely used in this capacity, partly due to the difficulties in configuring the reward function for each new task, the unpredictable reactions of the DRL agent to changes in the data, and the inability to use common performance metrics (e.g., TPR/FPR) to guide the algorithm's performance. In this study we propose methods for fine-tuning and calibrating DRL-based policies so that they can meet multiple performance goals. Moreover, we present a method for transferring effective security policies from one dataset to another. Finally, we demonstrate that our approach is highly robust against adversarial attacks.

</p>
</details>

<details><summary><b>A Causal Intervention Scheme for Semantic Segmentation of Quasi-periodic Cardiovascular Signals</b>
<a href="https://arxiv.org/abs/2209.09018">arxiv:2209.09018</a>
&#x1F4C8; 3 <br>
<p>Xingyao Wang, Yuwen Li, Hongxiang Gao, Xianghong Cheng, Jianqing Li, Chengyu Liu</p></summary>
<p>

**Abstract:** Precise segmentation is a vital first step to analyze semantic information of cardiac cycle and capture anomaly with cardiovascular signals. However, in the field of deep semantic segmentation, inference is often unilaterally confounded by the individual attribute of data. Towards cardiovascular signals, quasi-periodicity is the essential characteristic to be learned, regarded as the synthesize of the attributes of morphology (Am) and rhythm (Ar). Our key insight is to suppress the over-dependence on Am or Ar while the generation process of deep representations. To address this issue, we establish a structural causal model as the foundation to customize the intervention approaches on Am and Ar, respectively. In this paper, we propose contrastive causal intervention (CCI) to form a novel training paradigm under a frame-level contrastive framework. The intervention can eliminate the implicit statistical bias brought by the single attribute and lead to more objective representations. We conduct comprehensive experiments with the controlled condition for QRS location and heart sound segmentation. The final results indicate that our approach can evidently improve the performance by up to 0.41% for QRS location and 2.73% for heart sound segmentation. The efficiency of the proposed method is generalized to multiple databases and noisy signals.

</p>
</details>

<details><summary><b>Enforcing the consensus between Trajectory Optimization and Policy Learning for precise robot control</b>
<a href="https://arxiv.org/abs/2209.09006">arxiv:2209.09006</a>
&#x1F4C8; 3 <br>
<p>Quentin Le Lidec, Wilson Jallet, Ivan Laptev, Cordelia Schmid, Justin Carpentier</p></summary>
<p>

**Abstract:** Reinforcement learning (RL) and trajectory optimization (TO) present strong complementary advantages. On one hand, RL approaches are able to learn global control policies directly from data, but generally require large sample sizes to properly converge towards feasible policies. On the other hand, TO methods are able to exploit gradient-based information extracted from simulators to quickly converge towards a locally optimal control trajectory which is only valid within the vicinity of the solution. Over the past decade, several approaches have aimed to adequately combine the two classes of methods in order to obtain the best of both worlds. Following on from this line of research, we propose several improvements on top of these approaches to learn global control policies quicker, notably by leveraging sensitivity information stemming from TO methods via Sobolev learning, and augmented Lagrangian techniques to enforce the consensus between TO and policy learning. We evaluate the benefits of these improvements on various classical tasks in robotics through comparison with existing approaches in the literature.

</p>
</details>

<details><summary><b>Age of Semantics in Cooperative Communications: To Expedite Simulation Towards Real via Offline Reinforcement Learning</b>
<a href="https://arxiv.org/abs/2209.08947">arxiv:2209.08947</a>
&#x1F4C8; 3 <br>
<p>Xianfu Chen, Zhifeng Zhao, Shiwen Mao, Celimuge Wu, Honggang Zhang, Mehdi Bennis</p></summary>
<p>

**Abstract:** The age of information metric fails to correctly describe the intrinsic semantics of a status update. In an intelligent reflecting surface-aided cooperative relay communication system, we propose the age of semantics (AoS) for measuring semantics freshness of the status updates. Specifically, we focus on the status updating from a source node (SN) to the destination, which is formulated as a Markov decision process (MDP). The objective of the SN is to maximize the expected satisfaction of AoS and energy consumption under the maximum transmit power constraint. To seek the optimal control policy, we first derive an online deep actor-critic (DAC) learning scheme under the on-policy temporal difference learning framework. However, implementing the online DAC in practice poses the key challenge in infinitely repeated interactions between the SN and the system, which can be dangerous particularly during the exploration. We then put forward a novel offline DAC scheme, which estimates the optimal control policy from a previously collected dataset without any further interactions with the system. Numerical experiments verify the theoretical results and show that our offline DAC scheme significantly outperforms the online DAC scheme and the most representative baselines in terms of mean utility, demonstrating strong robustness to dataset quality.

</p>
</details>

<details><summary><b>A novel approach for wafer defect pattern classification based on topological data analysis</b>
<a href="https://arxiv.org/abs/2209.08945">arxiv:2209.08945</a>
&#x1F4C8; 3 <br>
<p>Seungchan Ko, Dowan Koo</p></summary>
<p>

**Abstract:** In semiconductor manufacturing, wafer map defect pattern provides critical information for facility maintenance and yield management, so the classification of defect patterns is one of the most important tasks in the manufacturing process. In this paper, we propose a novel way to represent the shape of the defect pattern as a finite-dimensional vector, which will be used as an input for a neural network algorithm for classification. The main idea is to extract the topological features of each pattern by using the theory of persistent homology from topological data analysis (TDA). Through some experiments with a simulated dataset, we show that the proposed method is faster and much more efficient in training with higher accuracy, compared with the method using convolutional neural networks (CNN) which is the most common approach for wafer map defect pattern classification. Moreover, our method outperforms the CNN-based method when the number of training data is not enough and is imbalanced.

</p>
</details>

<details><summary><b>Estimating Brain Age with Global and Local Dependencies</b>
<a href="https://arxiv.org/abs/2209.08933">arxiv:2209.08933</a>
&#x1F4C8; 3 <br>
<p>Yanwu Yang, Xutao Guo, Zhikai Chang, Chenfei Ye, Yang Xiang, Haiyan Lv, Ting Ma</p></summary>
<p>

**Abstract:** The brain age has been proven to be a phenotype of relevance to cognitive performance and brain disease. Achieving accurate brain age prediction is an essential prerequisite for optimizing the predicted brain-age difference as a biomarker. As a comprehensive biological characteristic, the brain age is hard to be exploited accurately with models using feature engineering and local processing such as local convolution and recurrent operations that process one local neighborhood at a time. Instead, Vision Transformers learn global attentive interaction of patch tokens, introducing less inductive bias and modeling long-range dependencies. In terms of this, we proposed a novel network for learning brain age interpreting with global and local dependencies, where the corresponding representations are captured by Successive Permuted Transformer (SPT) and convolution blocks. The SPT brings computation efficiency and locates the 3D spatial information indirectly via continuously encoding 2D slices from different views. Finally, we collect a large cohort of 22645 subjects with ages ranging from 14 to 97 and our network performed the best among a series of deep learning methods, yielding a mean absolute error (MAE) of 2.855 in validation set, and 2.911 in an independent test set.

</p>
</details>

<details><summary><b>Global Optimization for Cardinality-constrained Minimum Sum-of-Squares Clustering via Semidefinite Programming</b>
<a href="https://arxiv.org/abs/2209.08901">arxiv:2209.08901</a>
&#x1F4C8; 3 <br>
<p>Veronica Piccialli, Antonio M. Sudoso</p></summary>
<p>

**Abstract:** The minimum sum-of-squares clustering (MSSC), or k-means type clustering, has been recently extended to exploit prior knowledge on the cardinality of each cluster. Such knowledge is used to increase performance as well as solution quality. In this paper, we propose an exact approach based on the branch-and-cut technique to solve the cardinality-constrained MSSC. For the lower bound routine, we use the semidefinite programming (SDP) relaxation recently proposed by Rujeerapaiboon et al. [SIAM J. Optim. 29(2), 1211-1239, (2019)]. However, this relaxation can be used in a branch-and-cut method only for small-size instances. Therefore, we derive a new SDP relaxation that scales better with the instance size and the number of clusters. In both cases, we strengthen the bound by adding polyhedral cuts. Benefiting from a tailored branching strategy which enforces pairwise constraints, we reduce the complexity of the problems arising in the children nodes. For the upper bound, instead, we present a local search procedure that exploits the solution of the SDP relaxation solved at each node. Computational results show that the proposed algorithm globally solves, for the first time, real-world instances of size 10 times larger than those solved by state-of-the-art exact methods.

</p>
</details>

<details><summary><b>Batch Layer Normalization, A new normalization layer for CNNs and RNN</b>
<a href="https://arxiv.org/abs/2209.08898">arxiv:2209.08898</a>
&#x1F4C8; 3 <br>
<p>Amir Ziaee, Erion Çano</p></summary>
<p>

**Abstract:** This study introduces a new normalization layer termed Batch Layer Normalization (BLN) to reduce the problem of internal covariate shift in deep neural network layers. As a combined version of batch and layer normalization, BLN adaptively puts appropriate weight on mini-batch and feature normalization based on the inverse size of mini-batches to normalize the input to a layer during the learning process. It also performs the exact computation with a minor change at inference times, using either mini-batch statistics or population statistics. The decision process to either use statistics of mini-batch or population gives BLN the ability to play a comprehensive role in the hyper-parameter optimization process of models. The key advantage of BLN is the support of the theoretical analysis of being independent of the input data, and its statistical configuration heavily depends on the task performed, the amount of training data, and the size of batches. Test results indicate the application potential of BLN and its faster convergence than batch normalization and layer normalization in both Convolutional and Recurrent Neural Networks. The code of the experiments is publicly available online (https://github.com/A2Amir/Batch-Layer-Normalization).

</p>
</details>

<details><summary><b>Causal Effect Estimation with Global Probabilistic Forecasting: A Case Study of the Impact of Covid-19 Lockdowns on Energy Demand</b>
<a href="https://arxiv.org/abs/2209.08885">arxiv:2209.08885</a>
&#x1F4C8; 3 <br>
<p>Ankitha Nandipura Prasanna, Priscila Grecov, Angela Dieyu Weng, Christoph Bergmeir</p></summary>
<p>

**Abstract:** The electricity industry is heavily implementing smart grid technologies to improve reliability, availability, security, and efficiency. This implementation needs technological advancements, the development of standards and regulations, as well as testing and planning. Smart grid load forecasting and management are critical for reducing demand volatility and improving the market mechanism that connects generators, distributors, and retailers. During policy implementations or external interventions, it is necessary to analyse the uncertainty of their impact on the electricity demand to enable a more accurate response of the system to fluctuating demand. This paper analyses the uncertainties of external intervention impacts on electricity demand. It implements a framework that combines probabilistic and global forecasting models using a deep learning approach to estimate the causal impact distribution of an intervention. The causal effect is assessed by predicting the counterfactual distribution outcome for the affected instances and then contrasting it to the real outcomes. We consider the impact of Covid-19 lockdowns on energy usage as a case study to evaluate the non-uniform effect of this intervention on the electricity demand distribution. We could show that during the initial lockdowns in Australia and some European countries, there was often a more significant decrease in the troughs than in the peaks, while the mean remained almost unaffected.

</p>
</details>

<details><summary><b>An Information-Theoretic and Contrastive Learning-based Approach for Identifying Code Statements Causing Software Vulnerability</b>
<a href="https://arxiv.org/abs/2209.10414">arxiv:2209.10414</a>
&#x1F4C8; 2 <br>
<p>Van Nguyen, Trung Le, Chakkrit Tantithamthavorn, John Grundy, Hung Nguyen, Seyit Camtepe, Paul Quirk, Dinh Phung</p></summary>
<p>

**Abstract:** Software vulnerabilities existing in a program or function of computer systems are a serious and crucial concern. Typically, in a program or function consisting of hundreds or thousands of source code statements, there are only few statements causing the corresponding vulnerabilities. Vulnerability labeling is currently done on a function or program level by experts with the assistance of machine learning tools. Extending this approach to the code statement level is much more costly and time-consuming and remains an open problem. In this paper we propose a novel end-to-end deep learning-based approach to identify the vulnerability-relevant code statements of a specific function. Inspired by the specific structures observed in real world vulnerable code, we first leverage mutual information for learning a set of latent variables representing the relevance of the source code statements to the corresponding function's vulnerability. We then propose novel clustered spatial contrastive learning in order to further improve the representation learning and the robust selection process of vulnerability-relevant code statements. Experimental results on real-world datasets of 200k+ C/C++ functions show the superiority of our method over other state-of-the-art baselines. In general, our method obtains a higher performance in VCP, VCA, and Top-10 ACC measures of between 3\% to 14\% over the baselines when running on real-world datasets in an unsupervised setting. Our released source code samples are publicly available at \href{https://github.com/vannguyennd/livuitcl}{https://github.com/vannguyennd/livuitcl.}

</p>
</details>

<details><summary><b>NeurOLight: A Physics-Agnostic Neural Operator Enabling Parametric Photonic Device Simulation</b>
<a href="https://arxiv.org/abs/2209.10098">arxiv:2209.10098</a>
&#x1F4C8; 2 <br>
<p>Jiaqi Gu, Zhengqi Gao, Chenghao Feng, Hanqing Zhu, Ray T. Chen, Duane S. Boning, David Z. Pan</p></summary>
<p>

**Abstract:** Optical computing is an emerging technology for next-generation efficient artificial intelligence (AI) due to its ultra-high speed and efficiency. Electromagnetic field simulation is critical to the design, optimization, and validation of photonic devices and circuits. However, costly numerical simulation significantly hinders the scalability and turn-around time in the photonic circuit design loop. Recently, physics-informed neural networks have been proposed to predict the optical field solution of a single instance of a partial differential equation (PDE) with predefined parameters. Their complicated PDE formulation and lack of efficient parametrization mechanisms limit their flexibility and generalization in practical simulation scenarios. In this work, for the first time, a physics-agnostic neural operator-based framework, dubbed NeurOLight, is proposed to learn a family of frequency-domain Maxwell PDEs for ultra-fast parametric photonic device simulation. We balance the efficiency and generalization of NeurOLight via several novel techniques. Specifically, we discretize different devices into a unified domain, represent parametric PDEs with a compact wave prior, and encode the incident light via masked source modeling. We design our model with parameter-efficient cross-shaped NeurOLight blocks and adopt superposition-based augmentation for data-efficient learning. With these synergistic approaches, NeurOLight generalizes to a large space of unseen simulation settings, demonstrates 2-orders-of-magnitude faster simulation speed than numerical solvers, and outperforms prior neural network models by ~54% lower prediction error with ~44% fewer parameters. Our code is available at https://github.com/JeremieMelo/NeurOLight.

</p>
</details>

<details><summary><b>Documenting use cases in the affective computing domain using Unified Modeling Language</b>
<a href="https://arxiv.org/abs/2209.09666">arxiv:2209.09666</a>
&#x1F4C8; 2 <br>
<p>Isabelle Hupont, Emilia Gomez</p></summary>
<p>

**Abstract:** The study of the ethical impact of AI and the design of trustworthy systems needs the analysis of the scenarios where AI systems are used, which is related to the software engineering concept of "use case" and the "intended purpose" legal term. However, there is no standard methodology for use case documentation covering the context of use, scope, functional requirements and risks of an AI system. In this work, we propose a novel documentation methodology for AI use cases, with a special focus on the affective computing domain. Our approach builds upon an assessment of use case information needs documented in the research literature and the recently proposed European regulatory framework for AI. From this assessment, we adopt and adapt the Unified Modeling Language (UML), which has been used in the last two decades mostly by software engineers. Each use case is then represented by an UML diagram and a structured table, and we provide a set of examples illustrating its application to several affective computing scenarios.

</p>
</details>

<details><summary><b>Autonomous Visual Navigation A Biologically Inspired Approach</b>
<a href="https://arxiv.org/abs/2209.09663">arxiv:2209.09663</a>
&#x1F4C8; 2 <br>
<p>Sotirios Athanasoulias, Andy Philippides</p></summary>
<p>

**Abstract:** Inspired by the navigational behavior observed in the animal kingdom and especially the navigational behavior of the ants, we attempt to simulate it in an artificial environment by implementing different kinds of biomimetic algorithms.

</p>
</details>

<details><summary><b>SleePyCo: Automatic Sleep Scoring with Feature Pyramid and Contrastive Learning</b>
<a href="https://arxiv.org/abs/2209.09452">arxiv:2209.09452</a>
&#x1F4C8; 2 <br>
<p>Seongju Lee, Yeonguk Yu, Seunghyeok Back, Hogeon Seo, Kyoobin Lee</p></summary>
<p>

**Abstract:** Automatic sleep scoring is essential for the diagnosis and treatment of sleep disorders and enables longitudinal sleep tracking in home environments. Conventionally, learning-based automatic sleep scoring on single-channel electroencephalogram (EEG) is actively studied because obtaining multi-channel signals during sleep is difficult. However, learning representation from raw EEG signals is challenging owing to the following issues: 1) sleep-related EEG patterns occur on different temporal and frequency scales and 2) sleep stages share similar EEG patterns. To address these issues, we propose a deep learning framework named SleePyCo that incorporates 1) a feature pyramid and 2) supervised contrastive learning for automatic sleep scoring. For the feature pyramid, we propose a backbone network named SleePyCo-backbone to consider multiple feature sequences on different temporal and frequency scales. Supervised contrastive learning allows the network to extract class discriminative features by minimizing the distance between intra-class features and simultaneously maximizing that between inter-class features. Comparative analyses on four public datasets demonstrate that SleePyCo consistently outperforms existing frameworks based on single-channel EEG. Extensive ablation experiments show that SleePyCo exhibits enhanced overall performance, with significant improvements in discrimination between the N1 and rapid eye movement (REM) stages.

</p>
</details>

<details><summary><b>Modeling sequential annotations for sequence labeling with crowds</b>
<a href="https://arxiv.org/abs/2209.09430">arxiv:2209.09430</a>
&#x1F4C8; 2 <br>
<p>Xiaolei Lu, Tommy W. S. Chow</p></summary>
<p>

**Abstract:** Crowd sequential annotations can be an efficient and cost-effective way to build large datasets for sequence labeling. Different from tagging independent instances, for crowd sequential annotations the quality of label sequence relies on the expertise level of annotators in capturing internal dependencies for each token in the sequence. In this paper, we propose Modeling sequential annotation for sequence labeling with crowds (SA-SLC). First, a conditional probabilistic model is developed to jointly model sequential data and annotators' expertise, in which categorical distribution is introduced to estimate the reliability of each annotator in capturing local and non-local label dependency for sequential annotation. To accelerate the marginalization of the proposed model, a valid label sequence inference (VLSE) method is proposed to derive the valid ground-truth label sequences from crowd sequential annotations. VLSE derives possible ground-truth labels from the token-wise level and further prunes sub-paths in the forward inference for label sequence decoding. VLSE reduces the number of candidate label sequences and improves the quality of possible ground-truth label sequences. The experimental results on several sequence labeling tasks of Natural Language Processing show the effectiveness of the proposed model.

</p>
</details>

<details><summary><b>Weak Disambiguation for Partial Structured Output Learning</b>
<a href="https://arxiv.org/abs/2209.09410">arxiv:2209.09410</a>
&#x1F4C8; 2 <br>
<p>Xiaolei Lu, Tommy W. S. Chow</p></summary>
<p>

**Abstract:** Existing disambiguation strategies for partial structured output learning just cannot generalize well to solve the problem that there are some candidates which can be false positive or similar to the ground-truth label. In this paper, we propose a novel weak disambiguation for partial structured output learning (WD-PSL). First, a piecewise large margin formulation is generalized to partial structured output learning, which effectively avoids handling large number of candidate structured outputs for complex structures. Second, in the proposed weak disambiguation strategy, each candidate label is assigned with a confidence value indicating how likely it is the true label, which aims to reduce the negative effects of wrong ground-truth label assignment in the learning process. Then two large margins are formulated to combine two types of constraints which are the disambiguation between candidates and non-candidates, and the weak disambiguation for candidates. In the framework of alternating optimization, a new 2n-slack variables cutting plane algorithm is developed to accelerate each iteration of optimization. The experimental results on several sequence labeling tasks of Natural Language Processing show the effectiveness of the proposed model.

</p>
</details>

<details><summary><b>Analyzing Machine Learning Models for Credit Scoring with Explainable AI and Optimizing Investment Decisions</b>
<a href="https://arxiv.org/abs/2209.09362">arxiv:2209.09362</a>
&#x1F4C8; 2 <br>
<p>Swati Tyagi</p></summary>
<p>

**Abstract:** This paper examines two different yet related questions related to explainable AI (XAI) practices. Machine learning (ML) is increasingly important in financial services, such as pre-approval, credit underwriting, investments, and various front-end and back-end activities. Machine Learning can automatically detect non-linearities and interactions in training data, facilitating faster and more accurate credit decisions. However, machine learning models are opaque and hard to explain, which are critical elements needed for establishing a reliable technology. The study compares various machine learning models, including single classifiers (logistic regression, decision trees, LDA, QDA), heterogeneous ensembles (AdaBoost, Random Forest), and sequential neural networks. The results indicate that ensemble classifiers and neural networks outperform. In addition, two advanced post-hoc model agnostic explainability techniques - LIME and SHAP are utilized to assess ML-based credit scoring models using the open-access datasets offered by US-based P2P Lending Platform, Lending Club. For this study, we are also using machine learning algorithms to develop new investment models and explore portfolio strategies that can maximize profitability while minimizing risk.

</p>
</details>

<details><summary><b>Physics-Informed Machine Learning of Dynamical Systems for Efficient Bayesian Inference</b>
<a href="https://arxiv.org/abs/2209.09349">arxiv:2209.09349</a>
&#x1F4C8; 2 <br>
<p>Somayajulu L. N. Dhulipala, Yifeng Che, Michael D. Shields</p></summary>
<p>

**Abstract:** Although the no-u-turn sampler (NUTS) is a widely adopted method for performing Bayesian inference, it requires numerous posterior gradients which can be expensive to compute in practice. Recently, there has been a significant interest in physics-based machine learning of dynamical (or Hamiltonian) systems and Hamiltonian neural networks (HNNs) is a noteworthy architecture. But these types of architectures have not been applied to solve Bayesian inference problems efficiently. We propose the use of HNNs for performing Bayesian inference efficiently without requiring numerous posterior gradients. We introduce latent variable outputs to HNNs (L-HNNs) for improved expressivity and reduced integration errors. We integrate L-HNNs in NUTS and further propose an online error monitoring scheme to prevent sampling degeneracy in regions where L-HNNs may have little training data. We demonstrate L-HNNs in NUTS with online error monitoring considering several complex high-dimensional posterior densities and compare its performance to NUTS.

</p>
</details>

<details><summary><b>Training an Assassin AI for The Resistance: Avalon</b>
<a href="https://arxiv.org/abs/2209.09331">arxiv:2209.09331</a>
&#x1F4C8; 2 <br>
<p>Robert Chuchro</p></summary>
<p>

**Abstract:** The Resistance: Avalon is a partially observable social deduction game. This area of AI game playing is fairly undeveloped. Implementing an AI for this game involves multiple components specific to each phase as well as role in the game. In this paper, we plan to iteratively develop the required components for each role/phase by first addressing the Assassination phase which can be modeled as a machine learning problem. Using a publicly available dataset from an online version of the game, we train classifiers that emulate an Assassin. After trying various classification techniques, we are able to achieve above average human performance using a simple linear support vector classifier. The eventual goal of this project is to pursue developing an intelligent and complete Avalon player that can play through each phase of the game as any role.

</p>
</details>

<details><summary><b>MAN: Multi-Action Networks Learning</b>
<a href="https://arxiv.org/abs/2209.09329">arxiv:2209.09329</a>
&#x1F4C8; 2 <br>
<p>Keqin Wang, Alison Bartsch, Amir Barati Farimani</p></summary>
<p>

**Abstract:** Learning control policies with large action spaces is a challenging problem in the field of reinforcement learning due to present inefficiencies in exploration. In this work, we introduce a Deep Reinforcement Learning (DRL) algorithm call Multi-Action Networks (MAN) Learning that addresses the challenge of large discrete action spaces. We propose separating the action space into two components, creating a Value Neural Network for each sub-action. Then, MAN uses temporal-difference learning to train the networks synchronously, which is simpler than training a single network with a large action output directly. To evaluate the proposed method, we test MAN on a block stacking task, and then extend MAN to handle 12 games from the Atari Arcade Learning environment with 18 action spaces. Our results indicate that MAN learns faster than both Deep Q-Learning and Double Deep Q-Learning, implying our method is a better performing synchronous temporal difference algorithm than those currently available for large action spaces.

</p>
</details>

<details><summary><b>Sparse Interaction Additive Networks via Feature Interaction Detection and Sparse Selection</b>
<a href="https://arxiv.org/abs/2209.09326">arxiv:2209.09326</a>
&#x1F4C8; 2 <br>
<p>James Enouen, Yan Liu</p></summary>
<p>

**Abstract:** There is currently a large gap in performance between the statistically rigorous methods like linear regression or additive splines and the powerful deep methods using neural networks. Previous works attempting to close this gap have failed to fully investigate the exponentially growing number of feature combinations which deep networks consider automatically during training. In this work, we develop a tractable selection algorithm to efficiently identify the necessary feature combinations by leveraging techniques in feature interaction detection. Our proposed Sparse Interaction Additive Networks (SIAN) construct a bridge from these simple and interpretable models to fully connected neural networks. SIAN achieves competitive performance against state-of-the-art methods across multiple large-scale tabular datasets and consistently finds an optimal tradeoff between the modeling capacity of neural networks and the generalizability of simpler methods.

</p>
</details>

<details><summary><b>Stability and Generalization Analysis of Gradient Methods for Shallow Neural Networks</b>
<a href="https://arxiv.org/abs/2209.09298">arxiv:2209.09298</a>
&#x1F4C8; 2 <br>
<p>Yunwen Lei, Rong Jin, Yiming Ying</p></summary>
<p>

**Abstract:** While significant theoretical progress has been achieved, unveiling the generalization mystery of overparameterized neural networks still remains largely elusive. In this paper, we study the generalization behavior of shallow neural networks (SNNs) by leveraging the concept of algorithmic stability. We consider gradient descent (GD) and stochastic gradient descent (SGD) to train SNNs, for both of which we develop consistent excess risk bounds by balancing the optimization and generalization via early-stopping. As compared to existing analysis on GD, our new analysis requires a relaxed overparameterization assumption and also applies to SGD. The key for the improvement is a better estimation of the smallest eigenvalues of the Hessian matrices of the empirical risks and the loss function along the trajectories of GD and SGD by providing a refined estimation of their iterates.

</p>
</details>

<details><summary><b>Weak-signal extraction enabled by deep-neural-network denoising of diffraction data</b>
<a href="https://arxiv.org/abs/2209.09247">arxiv:2209.09247</a>
&#x1F4C8; 2 <br>
<p>Jens Oppliger, Michael M. Denner, Julia Küspert, Ruggero Frison, Qisi Wang, Alexander Morawietz, Oleh Ivashko, Ann-Christin Dippel, Martin von Zimmermann, Niels B. Christensen, Tohru Kurosawa, Naoki Momono, Migaku Oda, Fabian D. Natterer, Mark H. Fischer, Titus Neupert, Johan Chang</p></summary>
<p>

**Abstract:** Removal or cancellation of noise has wide-spread applications for imaging and acoustics. In every-day-life applications, denoising may even include generative aspects which are unfaithful to the ground truth. For scientific applications, however, denoising must reproduce the ground truth accurately. Here, we show how data can be denoised via a deep convolutional neural network such that weak signals appear with quantitative accuracy. In particular, we study X-ray diffraction on crystalline materials. We demonstrate that weak signals stemming from charge ordering, insignificant in the noisy data, become visible and accurate in the denoised data. This success is enabled by supervised training of a deep neural network with pairs of measured low- and high-noise data. This way, the neural network learns about the statistical properties of the noise. We demonstrate that using artificial noise (such as Poisson and Gaussian) does not yield such quantitatively accurate results. Our approach thus illustrates a practical strategy for noise filtering that can be applied to challenging acquisition problems.

</p>
</details>

<details><summary><b>Flexible Neural Image Compression via Code Editing</b>
<a href="https://arxiv.org/abs/2209.09244">arxiv:2209.09244</a>
&#x1F4C8; 2 <br>
<p>Chenjian Gao, Tongda Xu, Dailan He, Hongwei Qin, Yan Wang</p></summary>
<p>

**Abstract:** Neural image compression (NIC) has outperformed traditional image codecs in rate-distortion (R-D) performance. However, it usually requires a dedicated encoder-decoder pair for each point on R-D curve, which greatly hinders its practical deployment. While some recent works have enabled bitrate control via conditional coding, they impose strong prior during training and provide limited flexibility. In this paper we propose Code Editing, a highly flexible coding method for NIC based on semi-amortized inference and adaptive quantization. Our work is a new paradigm for variable bitrate NIC. Furthermore, experimental results show that our method surpasses existing variable-rate methods, and achieves ROI coding and multi-distortion trade-off with a single decoder.

</p>
</details>

<details><summary><b>Physics-Constrained Neural Network for the Analysis and Feature-Based Optimization of Woven Composites</b>
<a href="https://arxiv.org/abs/2209.09154">arxiv:2209.09154</a>
&#x1F4C8; 2 <br>
<p>Haotian Feng, Sabarinathan P Subramaniyan, Pavana Prabhakar</p></summary>
<p>

**Abstract:** Woven composites are produced by interlacing warp and weft fibers in a pattern or weave style. By changing the pattern or material, the mechanical properties of woven composites can be significantly changed; however, the role of woven composite architecture (pattern, material) on the mechanical properties is not well understood. In this paper, we explore the relationship between woven composite architectures (weave pattern, weave material sequence) and the corresponding modulus through our proposed Physics-Constrained Neural Network (PCNN). Furthermore, we apply statistical learning methods to optimize the woven composite architecture to improve mechanical responses. Our results show that PCNN can effectively predict woven architecture for the desired modulus with much higher accuracy than several baseline models. PCNN can be further combined with feature-based optimization to determine the optimal woven composite architecture at the initial design stage. In addition to relating woven composite architecture to its mechanical responses, our research also provides an in-depth understanding of how architectural features govern mechanical responses. We anticipate our proposed frameworks will primarily facilitate the woven composite analysis and optimization process and be a starting point to introduce Physics knowledge-guided Neural Networks into the complex structural analysis.

</p>
</details>

<details><summary><b>Computing Anti-Derivatives using Deep Neural Networks</b>
<a href="https://arxiv.org/abs/2209.09084">arxiv:2209.09084</a>
&#x1F4C8; 2 <br>
<p>D. Chakraborty, S. Gopalakrishnan</p></summary>
<p>

**Abstract:** This paper presents a novel algorithm to obtain the closed-form anti-derivative of a function using Deep Neural Network architecture. In the past, mathematicians have developed several numerical techniques to approximate the values of definite integrals, but primitives or indefinite integrals are often non-elementary. Anti-derivatives are necessarily required when there are several parameters in an integrand and the integral obtained is a function of those parameters. There is no theoretical method that can do this for any given function. Some existing ways to get around this are primarily based on either curve fitting or infinite series approximation of the integrand, which is then integrated theoretically. Curve fitting approximations are inaccurate for highly non-linear functions and require a different approach for every problem. On the other hand, the infinite series approach does not give a closed-form solution, and their truncated forms are often inaccurate. We claim that using a single method for all integrals, our algorithm can approximate anti-derivatives to any required accuracy. We have used this algorithm to obtain the anti-derivatives of several functions, including non-elementary and oscillatory integrals. This paper also shows the applications of our method to get the closed-form expressions of elliptic integrals, Fermi-Dirac integrals, and cumulative distribution functions and decrease the computation time of the Galerkin method for differential equations.

</p>
</details>

<details><summary><b>The GenCol algorithm for high-dimensional optimal transport: general formulation and application to barycenters and Wasserstein splines</b>
<a href="https://arxiv.org/abs/2209.09081">arxiv:2209.09081</a>
&#x1F4C8; 2 <br>
<p>Gero Friesecke, Maximilian Penka</p></summary>
<p>

**Abstract:** We extend the recently introduced genetic column generation algorithm for high-dimensional multi-marginal optimal transport from symmetric to general problems. We use the algorithm to calculate accurate mesh-free Wasserstein barycenters and cubic Wasserstein splines.

</p>
</details>

<details><summary><b>ALEXSIS-PT: A New Resource for Portuguese Lexical Simplification</b>
<a href="https://arxiv.org/abs/2209.09034">arxiv:2209.09034</a>
&#x1F4C8; 2 <br>
<p>Kai North, Marcos Zampieri, Tharindu Ranasinghe</p></summary>
<p>

**Abstract:** Lexical simplification (LS) is the task of automatically replacing complex words for easier ones making texts more accessible to various target populations (e.g. individuals with low literacy, individuals with learning disabilities, second language learners). To train and test models, LS systems usually require corpora that feature complex words in context along with their candidate substitutions. To continue improving the performance of LS systems we introduce ALEXSIS-PT, a novel multi-candidate dataset for Brazilian Portuguese LS containing 9,605 candidate substitutions for 387 complex words. ALEXSIS-PT has been compiled following the ALEXSIS protocol for Spanish opening exciting new avenues for cross-lingual models. ALEXSIS-PT is the first LS multi-candidate dataset that contains Brazilian newspaper articles. We evaluated four models for substitute generation on this dataset, namely mDistilBERT, mBERT, XLM-R, and BERTimbau. BERTimbau achieved the highest performance across all evaluation metrics.

</p>
</details>

<details><summary><b>SMIXS: Novel efficient algorithm for non-parametric mixture regression-based clustering</b>
<a href="https://arxiv.org/abs/2209.09030">arxiv:2209.09030</a>
&#x1F4C8; 2 <br>
<p>Peter Mlakar, Tapio Nummi, Polona Oblak, Jana Faganeli Pucer</p></summary>
<p>

**Abstract:** We investigate a novel non-parametric regression-based clustering algorithm for longitudinal data analysis. Combining natural cubic splines with Gaussian mixture models (GMM), the algorithm can produce smooth cluster means that describe the underlying data well. However, there are some shortcomings in the algorithm: high computational complexity in the parameter estimation procedure and a numerically unstable variance estimator. Therefore, to further increase the usability of the method, we incorporated approaches to reduce its computational complexity, we developed a new, more stable variance estimator, and we developed a new smoothing parameter estimation procedure. We show that the developed algorithm, SMIXS, performs better than GMM on a synthetic dataset in terms of clustering and regression performance. We demonstrate the impact of the computational speed-ups, which we formally prove in the new framework. Finally, we perform a case study by using SMIXS to cluster vertical atmospheric measurements to determine different weather regimes.

</p>
</details>

<details><summary><b>RAMP-Net: A Robust Adaptive MPC for Quadrotors via Physics-informed Neural Network</b>
<a href="https://arxiv.org/abs/2209.09025">arxiv:2209.09025</a>
&#x1F4C8; 2 <br>
<p>Sourav Sanyal, Kaushik Roy</p></summary>
<p>

**Abstract:** Model Predictive Control (MPC) is a state-of-the-art (SOTA) control technique which requires solving hard constrained optimization problems iteratively. For uncertain dynamics, analytical model based robust MPC imposes additional constraints, increasing the hardness of the problem. The problem exacerbates in performance-critical applications, when more compute is required in lesser time. Data-driven regression methods such as Neural Networks have been proposed in the past to approximate system dynamics. However, such models rely on high volumes of labeled data, in the absence of symbolic analytical priors. This incurs non-trivial training overheads. Physics-informed Neural Networks (PINNs) have gained traction for approximating non-linear system of ordinary differential equations (ODEs), with reasonable accuracy. In this work, we propose a Robust Adaptive MPC framework via PINNs (RAMP-Net), which uses a neural network trained partly from simple ODEs and partly from data. A physics loss is used to learn simple ODEs representing ideal dynamics. Having access to analytical functions inside the loss function acts as a regularizer, enforcing robust behavior for parametric uncertainties. On the other hand, a regular data loss is used for adapting to residual disturbances (non-parametric uncertainties), unaccounted during mathematical modelling. Experiments are performed in a simulated environment for trajectory tracking of a quadrotor. We report 7.8% to 43.2% and 8.04% to 61.5% reduction in tracking errors for speeds ranging from 0.5 to 1.75 m/s compared to two SOTA regression based MPC methods.

</p>
</details>

<details><summary><b>Will It Blend? Mixing Training Paradigms & Prompting for Argument Quality Prediction</b>
<a href="https://arxiv.org/abs/2209.08966">arxiv:2209.08966</a>
&#x1F4C8; 2 <br>
<p>Michiel van der Meer, Myrthe Reuver, Urja Khurana, Lea Krause, Selene Báez Santamaría</p></summary>
<p>

**Abstract:** This paper describes our contributions to the Shared Task of the 9th Workshop on Argument Mining (2022). Our approach uses Large Language Models for the task of Argument Quality Prediction. We perform prompt engineering using GPT-3, and also investigate the training paradigms multi-task learning, contrastive learning, and intermediate-task training. We find that a mixed prediction setup outperforms single models. Prompting GPT-3 works best for predicting argument validity, and argument novelty is best estimated by a model trained using all three training paradigms.

</p>
</details>

<details><summary><b>Learning Symbolic Model-Agnostic Loss Functions via Meta-Learning</b>
<a href="https://arxiv.org/abs/2209.08907">arxiv:2209.08907</a>
&#x1F4C8; 2 <br>
<p>Christian Raymond, Qi Chen, Bing Xue, Mengjie Zhang</p></summary>
<p>

**Abstract:** In this paper, we develop upon the emerging topic of loss function learning, which aims to learn loss functions that significantly improve the performance of the models trained under them. Specifically, we propose a new meta-learning framework for learning model-agnostic loss functions via a hybrid neuro-symbolic search approach. The framework first uses evolution-based methods to search the space of primitive mathematical operations to find a set of symbolic loss functions. Second, the set of learned loss functions are subsequently parameterized and optimized via an end-to-end gradient-based training procedure. The versatility of the proposed framework is empirically validated on a diverse set of supervised learning tasks. Results show that the meta-learned loss functions discovered by the newly proposed method outperform both the cross-entropy loss and state-of-the-art loss function learning methods on a diverse range of neural network architectures and datasets.

</p>
</details>

<details><summary><b>Rewarding Episodic Visitation Discrepancy for Exploration in Reinforcement Learning</b>
<a href="https://arxiv.org/abs/2209.08842">arxiv:2209.08842</a>
&#x1F4C8; 2 <br>
<p>Mingqi Yuan, Bo Li, Xin Jin, Wenjun Zeng</p></summary>
<p>

**Abstract:** Exploration is critical for deep reinforcement learning in complex environments with high-dimensional observations and sparse rewards. To address this problem, recent approaches proposed to leverage intrinsic rewards to improve exploration, such as novelty-based exploration and prediction-based exploration. However, many intrinsic reward modules require sophisticated structures and representation learning, resulting in prohibitive computational complexity and unstable performance. In this paper, we propose Rewarding Episodic Visitation Discrepancy (REVD), a computation-efficient and quantified exploration method. More specifically, REVD provides intrinsic rewards by evaluating the Rényi divergence-based visitation discrepancy between episodes. To make efficient divergence estimation, a k-nearest neighbor estimator is utilized with a randomly-initialized state encoder. Finally, the REVD is tested on PyBullet Robotics Environments and Atari games. Extensive experiments demonstrate that REVD can significantly improves the sample efficiency of reinforcement learning algorithms and outperforms the benchmarking methods.

</p>
</details>

<details><summary><b>NL2INTERFACE: Interactive Visualization Interface Generation from Natural Language Queries</b>
<a href="https://arxiv.org/abs/2209.08834">arxiv:2209.08834</a>
&#x1F4C8; 2 <br>
<p>Yiru Chen, Ryan Li, Austin Mac, Tianbao Xie, Tao Yu, Eugene Wu</p></summary>
<p>

**Abstract:** We develop NL2INTERFACE to explore the potential of generating usable interactive multi-visualization interfaces from natural language queries. With NL2INTERFACE, users can directly write natural language queries to automatically generate a fully interactive multi-visualization interface without any extra effort of learning a tool or programming language. Further, users can interact with the interfaces to easily transform the data and quickly see the results in the visualizations.

</p>
</details>

<details><summary><b>LGC-Net: A Lightweight Gyroscope Calibration Network for Efficient Attitude Estimation</b>
<a href="https://arxiv.org/abs/2209.08816">arxiv:2209.08816</a>
&#x1F4C8; 2 <br>
<p>Yaohua Liu, Wei Liang, Jinqiang Cui</p></summary>
<p>

**Abstract:** This paper presents a lightweight, efficient calibration neural network model for denoising low-cost microelectromechanical system (MEMS) gyroscope and estimating the attitude of a robot in real-time. The key idea is extracting local and global features from the time window of inertial measurement units (IMU) measurements to regress the output compensation components for the gyroscope dynamically. Following a carefully deduced mathematical calibration model, LGC-Net leverages the depthwise separable convolution to capture the sectional features and reduce the network model parameters. The Large kernel attention is designed to learn the long-range dependencies and feature representation better. The proposed algorithm is evaluated in the EuRoC and TUM-VI datasets and achieves state-of-the-art on the (unseen) test sequences with a more lightweight model structure. The estimated orientation with our LGC-Net is comparable with the top-ranked visual-inertial odometry systems, although it does not adopt vision sensors. We make our method open-source at: https://github.com/huazai665/LGC-Net

</p>
</details>

<details><summary><b>Hybrid Parallel Imaging and Compressed Sensing MRI Reconstruction with GRAPPA Integrated Multi-loss Supervised GAN</b>
<a href="https://arxiv.org/abs/2209.08807">arxiv:2209.08807</a>
&#x1F4C8; 2 <br>
<p>Farhan Sadik, Md. Kamrul Hasan</p></summary>
<p>

**Abstract:** Objective: Parallel imaging accelerates the acquisition of magnetic resonance imaging (MRI) data by acquiring additional sensitivity information with an array of receiver coils resulting in reduced phase encoding steps. Compressed sensing magnetic resonance imaging (CS-MRI) has achieved popularity in the field of medical imaging because of its less data requirement than parallel imaging. Parallel imaging and compressed sensing (CS) both speed up traditional MRI acquisition by minimizing the amount of data captured in the k-space. As acquisition time is inversely proportional to the number of samples, the inverse formation of an image from reduced k-space samples leads to faster acquisition but with aliasing artifacts. This paper proposes a novel Generative Adversarial Network (GAN) namely RECGAN-GR supervised with multi-modal losses for de-aliasing the reconstructed image. Methods: In contrast to existing GAN networks, our proposed method introduces a novel generator network namely RemU-Net integrated with dual-domain loss functions including weighted magnitude and phase loss functions along with parallel imaging-based loss i.e., GRAPPA consistency loss. A k-space correction block is proposed as refinement learning to make the GAN network self-resistant to generating unnecessary data which drives the convergence of the reconstruction process faster. Results: Comprehensive results show that the proposed RECGAN-GR achieves a 4 dB improvement in the PSNR among the GAN-based methods and a 2 dB improvement among conventional state-of-the-art CNN methods available in the literature. Conclusion and significance: The proposed work contributes to significant improvement in the image quality for low retained data leading to 5x or 10x faster acquisition.

</p>
</details>

<details><summary><b>Probing Spurious Correlations in Popular Event-Based Rumor Detection Benchmarks</b>
<a href="https://arxiv.org/abs/2209.08799">arxiv:2209.08799</a>
&#x1F4C8; 2 <br>
<p>Jiaying Wu, Bryan Hooi</p></summary>
<p>

**Abstract:** As social media becomes a hotbed for the spread of misinformation, the crucial task of rumor detection has witnessed promising advances fostered by open-source benchmark datasets. Despite being widely used, we find that these datasets suffer from spurious correlations, which are ignored by existing studies and lead to severe overestimation of existing rumor detection performance. The spurious correlations stem from three causes: (1) event-based data collection and labeling schemes assign the same veracity label to multiple highly similar posts from the same underlying event; (2) merging multiple data sources spuriously relates source identities to veracity labels; and (3) labeling bias. In this paper, we closely investigate three of the most popular rumor detection benchmark datasets (i.e., Twitter15, Twitter16 and PHEME), and propose event-separated rumor detection as a solution to eliminate spurious cues. Under the event-separated setting, we observe that the accuracy of existing state-of-the-art models drops significantly by over 40%, becoming only comparable to a simple neural classifier. To better address this task, we propose Publisher Style Aggregation (PSA), a generalizable approach that aggregates publisher posting records to learn writing style and veracity stance. Extensive experiments demonstrate that our method outperforms existing baselines in terms of effectiveness, efficiency and generalizability.

</p>
</details>

<details><summary><b>Walk-and-Relate: A Random-Walk-based Algorithm for Representation Learning on Sparse Knowledge Graphs</b>
<a href="https://arxiv.org/abs/2209.08769">arxiv:2209.08769</a>
&#x1F4C8; 2 <br>
<p>Saurav Manchanda</p></summary>
<p>

**Abstract:** Knowledge graph (KG) embedding techniques use structured relationships between entities to learn low-dimensional representations of entities and relations. The traditional KG embedding techniques (such as TransE and DistMult) estimate these embeddings via simple models developed over observed KG triplets. These approaches differ in their triplet scoring loss functions. As these models only use the observed triplets to estimate the embeddings, they are prone to suffer through data sparsity that usually occurs in the real-world knowledge graphs, i.e., the lack of enough triplets per entity. To settle this issue, we propose an efficient method to augment the number of triplets to address the problem of data sparsity. We use random walks to create additional triplets, such that the relations carried by these introduced triplets entail the metapath induced by the random walks. We also provide approaches to accurately and efficiently filter out informative metapaths from the possible set of metapaths, induced by the random walks. The proposed approaches are model-agnostic, and the augmented training dataset can be used with any KG embedding approach out of the box. Experimental results obtained on the benchmark datasets show the advantages of the proposed approach.

</p>
</details>

<details><summary><b>Decentralized Vehicle Coordination: The Berkeley DeepDrive Drone Dataset</b>
<a href="https://arxiv.org/abs/2209.08763">arxiv:2209.08763</a>
&#x1F4C8; 2 <br>
<p>Fangyu Wu, Dequan Wang, Minjune Hwang, Chenhui Hao, Jiawei Lu, Jiamu Zhang, Christopher Chou, Trevor Darrell, Alexandre Bayen</p></summary>
<p>

**Abstract:** Decentralized multiagent planning has been an important field of research in robotics. An interesting and impactful application in the field is decentralized vehicle coordination in understructured road environments. For example, in an intersection, it is useful yet difficult to deconflict multiple vehicles of intersecting paths in absence of a central coordinator. We learn from common sense that, for a vehicle to navigate through such understructured environments, the driver must understand and conform to the implicit "social etiquette" observed by nearby drivers. To study this implicit driving protocol, we collect the Berkeley DeepDrive Drone dataset. The dataset contains 1) a set of aerial videos recording understructured driving, 2) a collection of images and annotations to train vehicle detection models, and 3) a kit of development scripts for illustrating typical usages. We believe that the dataset is of primary interest for studying decentralized multiagent planning employed by human drivers and, of secondary interest, for computer vision in remote sensing settings.

</p>
</details>

<details><summary><b>U-Sleep: resilient to AASM guidelines</b>
<a href="https://arxiv.org/abs/2209.11173">arxiv:2209.11173</a>
&#x1F4C8; 1 <br>
<p>Luigi Fiorillo, Giuliana Monachino, Julia van der Meer, Marco Pesce, Jan Warncke, Markus H. Schmidt, Claudio L. A. Bassetti, Athina Tzovara, Paolo Favaro, Francesca D. Faraci</p></summary>
<p>

**Abstract:** AASM guidelines are the results of decades of efforts to try to standardize the sleep scoring procedure as to have a commonly used methodology. The guidelines cover several aspects from the technical/digital specifications, e.g., recommended EEG derivations, to the sleep scoring rules, e.g., different rules for adults, children and infants. In the context of sleep scoring automation, in the last decades, deep learning has demonstrated better performance compared to many other approaches. In most of the cases, clinical knowledge and guidelines have been exploited to support the automated sleep scoring algorithms in solving the task. In this paper we show that, actually, a deep learning based sleep scoring algorithm may not need to fully exploit the clinical knowledge or to strictly follow the AASM guidelines. Specifically, we demonstrate that U-Sleep, a state-of-the-art sleep scoring algorithm, can be strong enough to solve the scoring task even using clinically non-recommended or non-conventional derivations, and with no need to exploit information about the chronological age of the subjects. We finally strengthen a well-known finding that using data from multiple data centers always results in a better performing model compared with training on a single cohort. Indeed, we show that this latter statement is still valid even by increasing the size and the heterogeneity of the single data cohort. In all our experiments we used 28528 polysomnography studies from 13 different clinical studies.

</p>
</details>

<details><summary><b>On the benefits of self-taught learning for brain decoding</b>
<a href="https://arxiv.org/abs/2209.10099">arxiv:2209.10099</a>
&#x1F4C8; 1 <br>
<p>Elodie Germani, Elisa Fromont, Camille Maumet</p></summary>
<p>

**Abstract:** We study the benefits of using a large public neuroimaging database composed of fMRI statistic maps, in a self-taught learning framework, for improving brain decoding on new tasks. First, we leverage the NeuroVault database to train, on a selection of relevant statistic maps, a convolutional autoencoder to reconstruct these maps. Then, we use this trained encoder to initialize a supervised convolutional neural network to classify tasks or cognitive processes of unseen statistic maps from large collections of the NeuroVault database. We show that such a self-taught learning process always improves the performance of the classifiers but the magnitude of the benefits strongly depends on the number of data available both for pre-training and finetuning the models and on the complexity of the targeted downstream task.

</p>
</details>

<details><summary><b>Machine Learning Class Numbers of Real Quadratic Fields</b>
<a href="https://arxiv.org/abs/2209.09283">arxiv:2209.09283</a>
&#x1F4C8; 1 <br>
<p>Malik Amir, Yang-Hui He, Kyu-Hwan Lee, Thomas Oliver, Eldar Sultanow</p></summary>
<p>

**Abstract:** We implement and interpret various supervised learning experiments involving real quadratic fields with class numbers 1, 2 and 3. We quantify the relative difficulties in separating class numbers of matching/different parity from a data-scientific perspective, apply the methodology of feature analysis and principal component analysis, and use symbolic classification to develop machine-learned formulas for class numbers 1, 2 and 3 that apply to our dataset.

</p>
</details>

<details><summary><b>Generalization Bounds for Stochastic Gradient Descent via Localized $\varepsilon$-Covers</b>
<a href="https://arxiv.org/abs/2209.08951">arxiv:2209.08951</a>
&#x1F4C8; 0 <br>
<p>Sejun Park, Umut Şimşekli, Murat A. Erdogdu</p></summary>
<p>

**Abstract:** In this paper, we propose a new covering technique localized for the trajectories of SGD. This localization provides an algorithm-specific complexity measured by the covering number, which can have dimension-independent cardinality in contrast to standard uniform covering arguments that result in exponential dimension dependency. Based on this localized construction, we show that if the objective function is a finite perturbation of a piecewise strongly convex and smooth function with $P$ pieces, i.e. non-convex and non-smooth in general, the generalization error can be upper bounded by $O(\sqrt{(\log n\log(nP))/n})$, where $n$ is the number of data samples. In particular, this rate is independent of dimension and does not require early stopping and decaying step size. Finally, we employ these results in various contexts and derive generalization bounds for multi-index linear models, multi-class support vector machines, and $K$-means clustering for both hard and soft label setups, improving the known state-of-the-art rates.

</p>
</details>

<details><summary><b>Gradient Norm Minimization of Nesterov Acceleration: $o(1/k^3)$</b>
<a href="https://arxiv.org/abs/2209.08862">arxiv:2209.08862</a>
&#x1F4C8; 0 <br>
<p>Shuo Chen, Bin Shi, Ya-xiang Yuan</p></summary>
<p>

**Abstract:** In the history of first-order algorithms, Nesterov's accelerated gradient descent (NAG) is one of the milestones. However, the cause of the acceleration has been a mystery for a long time. It has not been revealed with the existence of gradient correction until the high-resolution differential equation framework proposed in [Shi et al., 2021]. In this paper, we continue to investigate the acceleration phenomenon. First, we provide a significantly simplified proof based on precise observation and a tighter inequality for $L$-smooth functions. Then, a new implicit-velocity high-resolution differential equation framework, as well as the corresponding implicit-velocity version of phase-space representation and Lyapunov function, is proposed to investigate the convergence behavior of the iterative sequence $\{x_k\}_{k=0}^{\infty}$ of NAG. Furthermore, from two kinds of phase-space representations, we find that the role played by gradient correction is equivalent to that by velocity included implicitly in the gradient, where the only difference comes from the iterative sequence $\{y_{k}\}_{k=0}^{\infty}$ replaced by $\{x_k\}_{k=0}^{\infty}$. Finally, for the open question of whether the gradient norm minimization of NAG has a faster rate $o(1/k^3)$, we figure out a positive answer with its proof. Meanwhile, a faster rate of objective value minimization $o(1/k^2)$ is shown for the case $r > 2$.

</p>
</details>

<details><summary><b>Active Visual Search in the Wild</b>
<a href="https://arxiv.org/abs/2209.08803">arxiv:2209.08803</a>
&#x1F4C8; 0 <br>
<p>Jeongeun Park, Taerim Yoon, Jejoon Hong, Youngjae Yu, Matthew Pan, Sungjoon Choi</p></summary>
<p>

**Abstract:** In this paper, we focus on the problem of efficiently locating a target object described with free-form language using a mobile robot equipped with vision sensors (e.g., an RGBD camera). Conventional active visual search predefines a set of objects to search for, rendering these techniques restrictive in practice. To provide added flexibility in active visual searching, we propose a system where a user can enter target commands using free-form language; we call this system Active Visual Search in the Wild (AVSW). AVSW detects and plans to search for a target object inputted by a user through a semantic grid map represented by static landmarks (e.g., desk or bed). For efficient planning of object search patterns, AVSW considers commonsense knowledge-based co-occurrence and predictive uncertainty while deciding which landmarks to visit first. We validate the proposed method with respect to SR (success rate) and SPL (success weighted by path length) in both simulated and real-world environments. The proposed method outperforms previous methods in terms of SPL in simulated scenarios with an average gap of 0.283. We further demonstrate AVSW with a Pioneer-3AT robot in real-world studies.

</p>
</details>


{% endraw %}
Prev: [2022.09.18]({{ '/2022/09/18/2022.09.18.html' | relative_url }})  Next: [2022.09.20]({{ '/2022/09/20/2022.09.20.html' | relative_url }})