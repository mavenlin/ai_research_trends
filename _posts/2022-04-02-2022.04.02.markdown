Prev: [2022.04.01]({{ '/2022/04/01/2022.04.01.html' | relative_url }})  Next: [2022.04.03]({{ '/2022/04/03/2022.04.03.html' | relative_url }})
{% raw %}
## Summary for 2022-04-02, created on 2022-04-12


<details><summary><b>Single Image Internal Distribution Measurement Using Non-Local Variational Autoencoder</b>
<a href="https://arxiv.org/abs/2204.01711">arxiv:2204.01711</a>
&#x1F4C8; 8 <br>
<p>Yeahia Sarker, Abdullah-Al-Zubaer Imran, Md Hafiz Ahamed, Ripon K. Chakrabortty, Michael J. Ryan, Sajal K. Das</p></summary>
<p>

**Abstract:** Deep learning-based super-resolution methods have shown great promise, especially for single image super-resolution (SISR) tasks. Despite the performance gain, these methods are limited due to their reliance on copious data for model training. In addition, supervised SISR solutions rely on local neighbourhood information focusing only on the feature learning processes for the reconstruction of low-dimensional images. Moreover, they fail to capitalize on global context due to their constrained receptive field. To combat these challenges, this paper proposes a novel image-specific solution, namely non-local variational autoencoder (\texttt{NLVAE}), to reconstruct a high-resolution (HR) image from a single low-resolution (LR) image without the need for any prior training. To harvest maximum details for various receptive regions and high-quality synthetic images, \texttt{NLVAE} is introduced as a self-supervised strategy that reconstructs high-resolution images using disentangled information from the non-local neighbourhood. Experimental results from seven benchmark datasets demonstrate the effectiveness of the \texttt{NLVAE} model. Moreover, our proposed model outperforms a number of baseline and state-of-the-art methods as confirmed through extensive qualitative and quantitative evaluations.

</p>
</details>

<details><summary><b>A Dynamic Meta-Learning Model for Time-Sensitive Cold-Start Recommendations</b>
<a href="https://arxiv.org/abs/2204.00970">arxiv:2204.00970</a>
&#x1F4C8; 8 <br>
<p>Krishna Prasad Neupane, Ervine Zheng, Yu Kong, Qi Yu</p></summary>
<p>

**Abstract:** We present a novel dynamic recommendation model that focuses on users who have interactions in the past but turn relatively inactive recently. Making effective recommendations to these time-sensitive cold-start users is critical to maintain the user base of a recommender system. Due to the sparse recent interactions, it is challenging to capture these users' current preferences precisely. Solely relying on their historical interactions may also lead to outdated recommendations misaligned with their recent interests. The proposed model leverages historical and current user-item interactions and dynamically factorizes a user's (latent) preference into time-specific and time-evolving representations that jointly affect user behaviors. These latent factors further interact with an optimized item embedding to achieve accurate and timely recommendations. Experiments over real-world data help demonstrate the effectiveness of the proposed time-sensitive cold-start recommendation model.

</p>
</details>

<details><summary><b>Histogram of Oriented Gradients Meet Deep Learning: A Novel Multi-task Deep Network for Medical Image Semantic Segmentation</b>
<a href="https://arxiv.org/abs/2204.01712">arxiv:2204.01712</a>
&#x1F4C8; 6 <br>
<p>Binod Bhattarai, Ronast Subedi, Rebati Raman Gaire, Eduard Vazquez, Danail Stoyanov</p></summary>
<p>

**Abstract:** We present our novel deep multi-task learning method for medical image segmentation. Existing multi-task methods demand ground truth annotations for both the primary and auxiliary tasks. Contrary to it, we propose to generate the pseudo-labels of an auxiliary task in an unsupervised manner. To generate the pseudo-labels, we leverage Histogram of Oriented Gradients (HOGs), one of the most widely used and powerful hand-crafted features for detection. Together with the ground truth semantic segmentation masks for the primary task and pseudo-labels for the auxiliary task, we learn the parameters of the deep network to minimise the loss of both the primary task and the auxiliary task jointly. We employed our method on two powerful and widely used semantic segmentation networks: UNet and U2Net to train in a multi-task setup. To validate our hypothesis, we performed experiments on two different medical image segmentation data sets. From the extensive quantitative and qualitative results, we observe that our method consistently improves the performance compared to the counter-part method. Moreover, our method is the winner of FetReg Endovis Sub-challenge on Semantic Segmentation organised in conjunction with MICCAI 2021.

</p>
</details>

<details><summary><b>Rotated Object Detection via Scale-invariant Mahalanobis Distance in Aerial Images</b>
<a href="https://arxiv.org/abs/2204.00840">arxiv:2204.00840</a>
&#x1F4C8; 6 <br>
<p>Siyang Wen, Wei Guo, Yi Liu, Ruijie Wu</p></summary>
<p>

**Abstract:** Rotated object detection in aerial images is a meaningful yet challenging task as objects are densely arranged and have arbitrary orientations. The eight-parameter (coordinates of box vectors) methods in rotated object detection usually use ln-norm losses (L1 loss, L2 loss, and smooth L1 loss) as loss functions. As ln-norm losses are mainly based on non-scale-invariant Minkowski distance, using ln-norm losses will lead to inconsistency with the detection metric rotational Intersection-over-Union (IoU) and training instability. To address the problems, we use Mahalanobis distance to calculate loss between the predicted and the target box vertices' vectors, proposing a new loss function called Mahalanobis Distance Loss (MDL) for eight-parameter rotated object detection. As Mahalanobis distance is scale-invariant, MDL is more consistent with detection metric and more stable during training than ln-norm losses. To alleviate the problem of boundary discontinuity like all other eight-parameter methods, we further take the minimum loss value to make MDL continuous at boundary cases. We achieve state-of-art performance on DOTA-v1.0 with the proposed method MDL. Furthermore, compared to the experiment that uses smooth L1 loss, we find that MDL performs better in rotated object detection.

</p>
</details>

<details><summary><b>Exemplar Learning for Medical Image Segmentation</b>
<a href="https://arxiv.org/abs/2204.01713">arxiv:2204.01713</a>
&#x1F4C8; 5 <br>
<p>Qing En, Yuhong Guo</p></summary>
<p>

**Abstract:** Medical image annotation typically requires expert knowledge and hence incurs time-consuming and expensive data annotation costs. To reduce this burden, we propose a novel learning scenario, Exemplar Learning (EL), to explore automated learning processes for medical image segmentation from a single annotated image example. This innovative learning task is particularly suitable for medical image segmentation, where all categories of organs can be presented in one single image for annotation all at once. To address this challenging EL task, we propose an Exemplar Learning-based Synthesis Net (ELSNet) framework for medical image segmentation that enables innovative exemplar-based data synthesis, pixel-prototype based contrastive embedding learning, and pseudo-label based exploitation of the unlabeled data. Specifically, ELSNet introduces two new modules for image segmentation: an exemplar-guided synthesis module, which enriches and diversifies the training set by synthesizing annotated samples from the given exemplar, and a pixel-prototype based contrastive embedding module, which enhances the discriminative capacity of the base segmentation model via contrastive self-supervised learning. Moreover, we deploy a two-stage process for segmentation model training, which exploits the unlabeled data with predicted pseudo segmentation labels. To evaluate this new learning framework, we conduct extensive experiments on several organ segmentation datasets and present an in-depth analysis. The empirical results show that the proposed exemplar learning framework produces effective segmentation results.

</p>
</details>

<details><summary><b>Model-Free and Model-Based Policy Evaluation when Causality is Uncertain</b>
<a href="https://arxiv.org/abs/2204.00956">arxiv:2204.00956</a>
&#x1F4C8; 5 <br>
<p>David Bruns-Smith</p></summary>
<p>

**Abstract:** When decision-makers can directly intervene, policy evaluation algorithms give valid causal estimates. In off-policy evaluation (OPE), there may exist unobserved variables that both impact the dynamics and are used by the unknown behavior policy. These "confounders" will introduce spurious correlations and naive estimates for a new policy will be biased. We develop worst-case bounds to assess sensitivity to these unobserved confounders in finite horizons when confounders are drawn iid each period. We demonstrate that a model-based approach with robust MDPs gives sharper lower bounds by exploiting domain knowledge about the dynamics. Finally, we show that when unobserved confounders are persistent over time, OPE is far more difficult and existing techniques produce extremely conservative bounds.

</p>
</details>

<details><summary><b>Dimensionless machine learning: Imposing exact units equivariance</b>
<a href="https://arxiv.org/abs/2204.00887">arxiv:2204.00887</a>
&#x1F4C8; 5 <br>
<p>Soledad Villar, Weichi Yao, David W. Hogg, Ben Blum-Smith, Bianca Dumitrascu</p></summary>
<p>

**Abstract:** Units equivariance is the exact symmetry that follows from the requirement that relationships among measured quantities of physics relevance must obey self-consistent dimensional scalings. Here, we employ dimensional analysis and ideas from equivariant machine learning to provide a two stage learning procedure for units-equivariant machine learning. For a given learning task, we first construct a dimensionless version of its inputs using classic results from dimensional analysis, and then perform inference in the dimensionless space. Our approach can be used to impose units equivariance across a broad range of machine learning methods which are equivariant to rotations and other groups. We discuss the in-sample and out-of-sample prediction accuracy gains one can obtain in contexts like symbolic regression and emulation, where symmetry is important. We illustrate our approach with simple numerical examples involving dynamical systems in physics and ecology.

</p>
</details>

<details><summary><b>Introduction to the Artificial Intelligence that can be applied to the Network Automation Journey</b>
<a href="https://arxiv.org/abs/2204.00800">arxiv:2204.00800</a>
&#x1F4C8; 5 <br>
<p>Gilbert Moisio, Alexandre Gonzalvez, Noam Zeitoun</p></summary>
<p>

**Abstract:** The computer network world is changing and the NetDevOps approach has brought the dynamics of applications and systems into the field of communication infrastructure. Businesses are changing and businesses are faced with difficulties related to the diversity of hardware and software that make up those infrastructures. The "Intent-Based Networking - Concepts and Definitions" document describes the different parts of the ecosystem that could be involved in NetDevOps. The recognize, generate intent, translate and refine features need a new way to implement algorithms. This is where artificial intelligence comes in.

</p>
</details>

<details><summary><b>Convolutional Neural Networks for Image Spam Detection</b>
<a href="https://arxiv.org/abs/2204.01710">arxiv:2204.01710</a>
&#x1F4C8; 4 <br>
<p>Tazmina Sharmin, Fabio Di Troia, Katerina Potika, Mark Stamp</p></summary>
<p>

**Abstract:** Spam can be defined as unsolicited bulk email. In an effort to evade text-based filters, spammers sometimes embed spam text in an image, which is referred to as image spam. In this research, we consider the problem of image spam detection, based on image analysis. We apply convolutional neural networks (CNN) to this problem, we compare the results obtained using CNNs to other machine learning techniques, and we compare our results to previous related work. We consider both real-world image spam and challenging image spam-like datasets. Our results improve on previous work by employing CNNs based on a novel feature set consisting of a combination of the raw image and Canny edges.

</p>
</details>

<details><summary><b>Forestry digital twin with machine learning in Landsat 7 data</b>
<a href="https://arxiv.org/abs/2204.01709">arxiv:2204.01709</a>
&#x1F4C8; 4 <br>
<p>Xuetao Jiang, Meiyu Jiang, YuChun Gou, Qian Li, Qingguo Zhou</p></summary>
<p>

**Abstract:** Modeling forests using historical data allows for more accurately evolution analysis, thus providing an important basis for other studies. As a recognized and effective tool, remote sensing plays an important role in forestry analysis. We can use it to derive information about the forest, including tree type, coverage and canopy density. There are many forest time series modeling studies using statistic values, but few using remote sensing images. Image prediction digital twin is an implementation of digital twin, which aims to predict future images bases on historical data. In this paper, we propose an LSTM-based digital twin approach for forest modeling, using Landsat 7 remote sensing image within 20 years. The experimental results show that the prediction twin method in this paper can effectively predict the future images of study area.

</p>
</details>

<details><summary><b>CTRLEval: An Unsupervised Reference-Free Metric for Evaluating Controlled Text Generation</b>
<a href="https://arxiv.org/abs/2204.00862">arxiv:2204.00862</a>
&#x1F4C8; 4 <br>
<p>Pei Ke, Hao Zhou, Yankai Lin, Peng Li, Jie Zhou, Xiaoyan Zhu, Minlie Huang</p></summary>
<p>

**Abstract:** Existing reference-free metrics have obvious limitations for evaluating controlled text generation models. Unsupervised metrics can only provide a task-agnostic evaluation result which correlates weakly with human judgments, whereas supervised ones may overfit task-specific data with poor generalization ability to other datasets. In this paper, we propose an unsupervised reference-free metric called CTRLEval, which evaluates controlled text generation from different aspects by formulating each aspect into multiple text infilling tasks. On top of these tasks, the metric assembles the generation probabilities from a pre-trained language model without any model training. Experimental results show that our metric has higher correlations with human judgments than other baselines, while obtaining better generalization of evaluating generated texts from different models and with different qualities.

</p>
</details>

<details><summary><b>Efficient comparison of sentence embeddings</b>
<a href="https://arxiv.org/abs/2204.00820">arxiv:2204.00820</a>
&#x1F4C8; 4 <br>
<p>Spyros Zoupanos, Stratis Kolovos, Athanasios Kanavos, Orestis Papadimitriou, Manolis Maragoudakis</p></summary>
<p>

**Abstract:** The domain of natural language processing (NLP), which has greatly evolved over the last years, has highly benefited from the recent developments in word and sentence embeddings. Such embeddings enable the transformation of complex NLP tasks, like semantic similarity or Question and Answering (Q\&A), into much simpler to perform vector comparisons. However, such a problem transformation raises new challenges like the efficient comparison of embeddings and their manipulation. In this work, we will discuss about various word and sentence embeddings algorithms, we will select a sentence embedding algorithm, BERT, as our algorithm of choice and we will evaluate the performance of two vector comparison approaches, FAISS and Elasticsearch, in the specific problem of sentence embeddings. According to the results, FAISS outperforms Elasticsearch when used in a centralized environment with only one node, especially when big datasets are included.

</p>
</details>

<details><summary><b>HLDC: Hindi Legal Documents Corpus</b>
<a href="https://arxiv.org/abs/2204.00806">arxiv:2204.00806</a>
&#x1F4C8; 4 <br>
<p>Arnav Kapoor, Mudit Dhawan, Anmol Goel, T. H. Arjun, Akshala Bhatnagar, Vibhu Agrawal, Amul Agrawal, Arnab Bhattacharya, Ponnurangam Kumaraguru, Ashutosh Modi</p></summary>
<p>

**Abstract:** Many populous countries including India are burdened with a considerable backlog of legal cases. Development of automated systems that could process legal documents and augment legal practitioners can mitigate this. However, there is a dearth of high-quality corpora that is needed to develop such data-driven systems. The problem gets even more pronounced in the case of low resource languages such as Hindi. In this resource paper, we introduce the Hindi Legal Documents Corpus (HLDC), a corpus of more than 900K legal documents in Hindi. Documents are cleaned and structured to enable the development of downstream applications. Further, as a use-case for the corpus, we introduce the task of bail prediction. We experiment with a battery of models and propose a Multi-Task Learning (MTL) based model for the same. MTL models use summarization as an auxiliary task along with bail prediction as the main task. Experiments with different models are indicative of the need for further research in this area. We release the corpus and model implementation code with this paper: https://github.com/Exploration-Lab/HLDC

</p>
</details>

<details><summary><b>Estimating Fine-Grained Noise Model via Contrastive Learning</b>
<a href="https://arxiv.org/abs/2204.01716">arxiv:2204.01716</a>
&#x1F4C8; 3 <br>
<p>Yunhao Zou, Ying Fu</p></summary>
<p>

**Abstract:** Image denoising has achieved unprecedented progress as great efforts have been made to exploit effective deep denoisers. To improve the denoising performance in realworld, two typical solutions are used in recent trends: devising better noise models for the synthesis of more realistic training data, and estimating noise level function to guide non-blind denoisers. In this work, we combine both noise modeling and estimation, and propose an innovative noise model estimation and noise synthesis pipeline for realistic noisy image generation. Specifically, our model learns a noise estimation model with fine-grained statistical noise model in a contrastive manner. Then, we use the estimated noise parameters to model camera-specific noise distribution, and synthesize realistic noisy training data. The most striking thing for our work is that by calibrating noise models of several sensors, our model can be extended to predict other cameras. In other words, we can estimate cameraspecific noise models for unknown sensors with only testing images, without laborious calibration frames or paired noisy/clean data. The proposed pipeline endows deep denoisers with competitive performances with state-of-the-art real noise modeling methods.

</p>
</details>

<details><summary><b>MRI-based Multi-task Decoupling Learning for Alzheimer's Disease Detection and MMSE Score Prediction: A Multi-site Validation</b>
<a href="https://arxiv.org/abs/2204.01708">arxiv:2204.01708</a>
&#x1F4C8; 3 <br>
<p>Xu Tian, Jin Liu, Hulin Kuang, Yu Sheng, Jianxin Wang, The Alzheimer's Disease Neuroimaging Initiative</p></summary>
<p>

**Abstract:** Accurately detecting Alzheimer's disease (AD) and predicting mini-mental state examination (MMSE) score are important tasks in elderly health by magnetic resonance imaging (MRI). Most of the previous methods on these two tasks are based on single-task learning and rarely consider the correlation between them. Since the MMSE score, which is an important basis for AD diagnosis, can also reflect the progress of cognitive impairment, some studies have begun to apply multi-task learning methods to these two tasks. However, how to exploit feature correlation remains a challenging problem for these methods. To comprehensively address this challenge, we propose a MRI-based multi-task decoupled learning method for AD detection and MMSE score prediction. First, a multi-task learning network is proposed to implement AD detection and MMSE score prediction, which exploits feature correlation by adding three multi-task interaction layers between the backbones of the two tasks. Each multi-task interaction layer contains two feature decoupling modules and one feature interaction module. Furthermore, to enhance the generalization between tasks of the features selected by the feature decoupling module, we propose the feature consistency loss constrained feature decoupling module. Finally, in order to exploit the specific distribution information of MMSE score in different groups, a distribution loss is proposed to further enhance the model performance. We evaluate our proposed method on multi-site datasets. Experimental results show that our proposed multi-task decoupled representation learning method achieves good performance, outperforming single-task learning and other existing state-of-the-art methods.

</p>
</details>

<details><summary><b>Moment-based Adversarial Training for Embodied Language Comprehension</b>
<a href="https://arxiv.org/abs/2204.00889">arxiv:2204.00889</a>
&#x1F4C8; 3 <br>
<p>Shintaro Ishikawa, Komei Sugiura</p></summary>
<p>

**Abstract:** In this paper, we focus on a vision-and-language task in which a robot is instructed to execute household tasks. Given an instruction such as "Rinse off a mug and place it in the coffee maker," the robot is required to locate the mug, wash it, and put it in the coffee maker. This is challenging because the robot needs to break down the instruction sentences into subgoals and execute them in the correct order. On the ALFRED benchmark, the performance of state-of-the-art methods is still far lower than that of humans. This is partially because existing methods sometimes fail to infer subgoals that are not explicitly specified in the instruction sentences. We propose Moment-based Adversarial Training (MAT), which uses two types of moments for perturbation updates in adversarial training. We introduce MAT to the embedding spaces of the instruction, subgoals, and state representations to handle their varieties. We validated our method on the ALFRED benchmark, and the results demonstrated that our method outperformed the baseline method for all the metrics on the benchmark.

</p>
</details>

<details><summary><b>Accurate Online Posterior Alignments for Principled Lexically-Constrained Decoding</b>
<a href="https://arxiv.org/abs/2204.00871">arxiv:2204.00871</a>
&#x1F4C8; 3 <br>
<p>Soumya Chatterjee, Sunita Sarawagi, Preethi Jyothi</p></summary>
<p>

**Abstract:** Online alignment in machine translation refers to the task of aligning a target word to a source word when the target sequence has only been partially decoded. Good online alignments facilitate important applications such as lexically constrained translation where user-defined dictionaries are used to inject lexical constraints into the translation model. We propose a novel posterior alignment technique that is truly online in its execution and superior in terms of alignment error rates compared to existing methods. Our proposed inference technique jointly considers alignment and token probabilities in a principled manner and can be seamlessly integrated within existing constrained beam-search decoding algorithms. On five language pairs, including two distant language pairs, we achieve consistent drop in alignment error rates. When deployed on seven lexically constrained translation tasks, we achieve significant improvements in BLEU specifically around the constrained positions.

</p>
</details>

<details><summary><b>Speaker adaptation for Wav2vec2 based dysarthric ASR</b>
<a href="https://arxiv.org/abs/2204.00770">arxiv:2204.00770</a>
&#x1F4C8; 3 <br>
<p>Murali Karthick Baskar, Tim Herzig, Diana Nguyen, Mireia Diez, Tim Polzehl, Lukáš Burget, Jan "Honza'' Černocký</p></summary>
<p>

**Abstract:** Dysarthric speech recognition has posed major challenges due to lack of training data and heavy mismatch in speaker characteristics. Recent ASR systems have benefited from readily available pretrained models such as wav2vec2 to improve the recognition performance. Speaker adaptation using fMLLR and xvectors have provided major gains for dysarthric speech with very little adaptation data. However, integration of wav2vec2 with fMLLR features or xvectors during wav2vec2 finetuning is yet to be explored. In this work, we propose a simple adaptation network for fine-tuning wav2vec2 using fMLLR features. The adaptation network is also flexible to handle other speaker adaptive features such as xvectors. Experimental analysis show steady improvements using our proposed approach across all impairment severity levels and attains 57.72\% WER for high severity in UASpeech dataset. We also performed experiments on German dataset to substantiate the consistency of our proposed approach across diverse domains.

</p>
</details>

<details><summary><b>Variational message passing for online polynomial NARMAX identification</b>
<a href="https://arxiv.org/abs/2204.00769">arxiv:2204.00769</a>
&#x1F4C8; 3 <br>
<p>Wouter Kouw, Albert Podusenko, Magnus Koudahl, Maarten Schoukens</p></summary>
<p>

**Abstract:** We propose a variational Bayesian inference procedure for online nonlinear system identification. For each output observation, a set of parameter posterior distributions is updated, which is then used to form a posterior predictive distribution for future outputs. We focus on the class of polynomial NARMAX models, which we cast into probabilistic form and represent in terms of a Forney-style factor graph. Inference in this graph is efficiently performed by a variational message passing algorithm. We show empirically that our variational Bayesian estimator outperforms an online recursive least-squares estimator, most notably in small sample size settings and low noise regimes, and performs on par with an iterative least-squares estimator trained offline.

</p>
</details>

<details><summary><b>FedGBF: An efficient vertical federated learning framework via gradient boosting and bagging</b>
<a href="https://arxiv.org/abs/2204.00976">arxiv:2204.00976</a>
&#x1F4C8; 2 <br>
<p>Yujin Han, Pan Du, Kai Yang</p></summary>
<p>

**Abstract:** Federated learning, conducive to solving data privacy and security problems, has attracted increasing attention recently. However, the existing federated boosting model sequentially builds a decision tree model with the weak base learner, resulting in redundant boosting steps and high interactive communication costs. In contrast, the federated bagging model saves time by building multi-decision trees in parallel, but it suffers from performance loss. With the aim of obtaining an outstanding performance with less time cost, we propose a novel model in a vertically federated setting termed as Federated Gradient Boosting Forest (FedGBF). FedGBF simultaneously integrates the boosting and bagging's preponderance by building the decision trees in parallel as a base learner for boosting. Subsequent to FedGBF, the problem of hyperparameters tuning is rising. Then we propose the Dynamic FedGBF, which dynamically changes each forest's parameters and thus reduces the complexity. Finally, the experiments based on the benchmark datasets demonstrate the superiority of our method.

</p>
</details>

<details><summary><b>Kernel Extreme Learning Machine Optimized by the Sparrow Search Algorithm for Hyperspectral Image Classification</b>
<a href="https://arxiv.org/abs/2204.00973">arxiv:2204.00973</a>
&#x1F4C8; 2 <br>
<p>Zhixin Yan, Jiawei Huang, Kehua Xiang</p></summary>
<p>

**Abstract:** To improve the classification performance and generalization ability of the hyperspectral image classification algorithm, this paper uses Multi-Scale Total Variation (MSTV) to extract the spectral features, local binary pattern (LBP) to extract spatial features, and feature superposition to obtain the fused features of hyperspectral images. A new swarm intelligence optimization method with high convergence and strong global search capability, the Sparrow Search Algorithm (SSA), is used to optimize the kernel parameters and regularization coefficients of the Kernel Extreme Learning Machine (KELM). In summary, a multiscale fusion feature hyperspectral image classification method (MLS-KELM) is proposed in this paper. The Indian Pines, Pavia University and Houston 2013 datasets were selected to validate the classification performance of MLS-KELM, and the method was applied to ZY1-02D hyperspectral data. The experimental results show that MLS-KELM has better classification performance and generalization ability compared with other popular classification methods, and MLS-KELM shows its strong robustness in the small sample case.

</p>
</details>

<details><summary><b>Exploiting Local and Global Features in Transformer-based Extreme Multi-label Text Classification</b>
<a href="https://arxiv.org/abs/2204.00933">arxiv:2204.00933</a>
&#x1F4C8; 2 <br>
<p>Ruohong Zhang, Yau-Shian Wang, Yiming Yang, Tom Vu, Likun Lei</p></summary>
<p>

**Abstract:** Extreme multi-label text classification (XMTC) is the task of tagging each document with the relevant labels from a very large space of predefined categories. Recently, large pre-trained Transformer models have made significant performance improvements in XMTC, which typically use the embedding of the special CLS token to represent the entire document semantics as a global feature vector, and match it against candidate labels. However, we argue that such a global feature vector may not be sufficient to represent different granularity levels of semantics in the document, and that complementing it with the local word-level features could bring additional gains. Based on this insight, we propose an approach that combines both the local and global features produced by Transformer models to improve the prediction power of the classifier. Our experiments show that the proposed model either outperforms or is comparable to the state-of-the-art methods on benchmark datasets.

</p>
</details>

<details><summary><b>Inverse is Better! Fast and Accurate Prompt for Few-shot Slot Tagging</b>
<a href="https://arxiv.org/abs/2204.00885">arxiv:2204.00885</a>
&#x1F4C8; 2 <br>
<p>Yutai Hou, Cheng Chen, Xianzhen Luo, Bohan Li, Wanxiang Che</p></summary>
<p>

**Abstract:** Prompting methods recently achieve impressive success in few-shot learning. These methods modify input samples with prompt sentence pieces, and decode label tokens to map samples to corresponding labels. However, such a paradigm is very inefficient for the task of slot tagging. Since slot tagging samples are multiple consecutive words in a sentence, the prompting methods have to enumerate all n-grams token spans to find all the possible slots, which greatly slows down the prediction. To tackle this, we introduce an inverse paradigm for prompting. Different from the classic prompts mapping tokens to labels, we reversely predict slot values given slot types. Such inverse prompting only requires a one-turn prediction for each slot type and greatly speeds up the prediction. Besides, we propose a novel Iterative Prediction Strategy, from which the model learns to refine predictions by considering the relations between different slot types. We find, somewhat surprisingly, the proposed method not only predicts faster but also significantly improves the effect (improve over 6.1 F1-scores on 10-shot setting) and achieves new state-of-the-art performance.

</p>
</details>

<details><summary><b>SciNoBo : A Hierarchical Multi-Label Classifier of Scientific Publications</b>
<a href="https://arxiv.org/abs/2204.00880">arxiv:2204.00880</a>
&#x1F4C8; 2 <br>
<p>Nikolaos Gialitsis, Sotiris Kotitsas, Haris Papageorgiou</p></summary>
<p>

**Abstract:** Classifying scientific publications according to Field-of-Science (FoS) taxonomies is of crucial importance, allowing funders, publishers, scholars, companies and other stakeholders to organize scientific literature more effectively. Most existing works address classification either at venue level or solely based on the textual content of a research publication. We present SciNoBo, a novel classification system of publications to predefined FoS taxonomies, leveraging the structural properties of a publication and its citations and references organised in a multilayer network. In contrast to other works, our system supports assignments of publications to multiple fields by considering their multidisciplinarity potential. By unifying publications and venues under a common multilayer network structure made up of citing and publishing relationships, classifications at the venue-level can be augmented with publication-level classifications. We evaluate SciNoBo on a publications' dataset extracted from Microsoft Academic Graph and we perform a comparative analysis against a state-of-the-art neural-network baseline. The results reveal that our proposed system is capable of producing high-quality classifications of publications.

</p>
</details>

<details><summary><b>Acoustic-to-articulatory Inversion based on Speech Decomposition and Auxiliary Feature</b>
<a href="https://arxiv.org/abs/2204.00873">arxiv:2204.00873</a>
&#x1F4C8; 2 <br>
<p>Jianrong Wang, Jinyu Liu, Longxuan Zhao, Shanyu Wang, Ruiguo Yu, Li Liu</p></summary>
<p>

**Abstract:** Acoustic-to-articulatory inversion (AAI) is to obtain the movement of articulators from speech signals. Until now, achieving a speaker-independent AAI remains a challenge given the limited data. Besides, most current works only use audio speech as input, causing an inevitable performance bottleneck. To solve these problems, firstly, we pre-train a speech decomposition network to decompose audio speech into speaker embedding and content embedding as the new personalized speech features to adapt to the speaker-independent case. Secondly, to further improve the AAI, we propose a novel auxiliary feature network to estimate the lip auxiliary features from the above personalized speech features. Experimental results on three public datasets show that, compared with the state-of-the-art only using the audio speech feature, the proposed method reduces the average RMSE by 0.25 and increases the average correlation coefficient by 2.0% in the speaker-dependent case. More importantly, the average RMSE decreases by 0.29 and the average correlation coefficient increases by 5.0% in the speaker-independent case.

</p>
</details>

<details><summary><b>Adversarial Neon Beam: Robust Physical-World Adversarial Attack to DNNs</b>
<a href="https://arxiv.org/abs/2204.00853">arxiv:2204.00853</a>
&#x1F4C8; 2 <br>
<p>Chengyin Hu, Kalibinuer Tiliwalidi</p></summary>
<p>

**Abstract:** In the physical world, light affects the performance of deep neural networks. Nowadays, many products based on deep neural network have been put into daily life. There are few researches on the effect of light on the performance of deep neural network models. However, the adversarial perturbations generated by light may have extremely dangerous effects on these systems. In this work, we propose an attack method called adversarial neon beam (AdvNB), which can execute the physical attack by obtaining the physical parameters of adversarial neon beams with very few queries. Experiments show that our algorithm can achieve advanced attack effect in both digital test and physical test. In the digital environment, 99.3% attack success rate was achieved, and in the physical environment, 100% attack success rate was achieved. Compared with the most advanced physical attack methods, our method can achieve better physical perturbation concealment. In addition, by analyzing the experimental data, we reveal some new phenomena brought about by the adversarial neon beam attack.

</p>
</details>

<details><summary><b>SAD: A Large-scale Dataset towards Airport Detection in Synthetic Aperture Radar Images</b>
<a href="https://arxiv.org/abs/2204.00790">arxiv:2204.00790</a>
&#x1F4C8; 2 <br>
<p>Daochang Wang, Fan Zhang, Fei Ma, Wei Hu, Yu Tang, Yongsheng Zhou</p></summary>
<p>

**Abstract:** Airports have an important role in both military and civilian domains. The synthetic aperture radar (SAR) based airport detection has received increasing attention in recent years. However, due to the high cost of SAR imaging and annotation process, there is no publicly available SAR dataset for airport detection. As a result, deep learning methods have not been fully used in airport detection tasks. To provide a benchmark for airport detection research in SAR images, this paper introduces a large-scale SAR Airport Dataset (SAD). In order to adequately reflect the demands of real world applications, it contains 624 SAR images from Sentinel 1B and covers 104 airfield instances with different scales, orientations and shapes. The experiments of multiple deep learning approach on this dataset proves its effectiveness. It developing state-of-the-art airport area detection algorithms or other relevant tasks.

</p>
</details>

<details><summary><b>Distributional Gradient Boosting Machines</b>
<a href="https://arxiv.org/abs/2204.00778">arxiv:2204.00778</a>
&#x1F4C8; 2 <br>
<p>Alexander März, Thomas Kneib</p></summary>
<p>

**Abstract:** We present a unified probabilistic gradient boosting framework for regression tasks that models and predicts the entire conditional distribution of a univariate response variable as a function of covariates. Our likelihood-based approach allows us to either model all conditional moments of a parametric distribution, or to approximate the conditional cumulative distribution function via Normalizing Flows. As underlying computational backbones, our framework is based on XGBoost and LightGBM. Modelling and predicting the entire conditional distribution greatly enhances existing tree-based gradient boosting implementations, as it allows to create probabilistic forecasts from which prediction intervals and quantiles of interest can be derived. Empirical results show that our framework achieves state-of-the-art forecast accuracy.

</p>
</details>

<details><summary><b>Adaptive Spike-Like Representation of EEG Signals for Sleep Stages Scoring</b>
<a href="https://arxiv.org/abs/2204.03565">arxiv:2204.03565</a>
&#x1F4C8; 1 <br>
<p>Lingwei Zhu, Koki Odani, Ziwei Yang, Guang Shi, Yirong Kan, Zheng Chen, Renyuan Zhang</p></summary>
<p>

**Abstract:** Recently there has seen promising results on automatic stage scoring by extracting spatio-temporal features from electroencephalogram (EEG). Such methods entail laborious manual feature engineering and domain knowledge. In this study, we propose an adaptive scheme to probabilistically encode, filter and accumulate the input signals and weight the resultant features by the half-Gaussian probabilities of signal intensities. The adaptive representations are subsequently fed into a transformer model to automatically mine the relevance between features and corresponding stages. Extensive experiments on the largest public dataset against state-of-the-art methods validate the effectiveness of our proposed method and reveal promising future directions.

</p>
</details>

<details><summary><b>Towards Power-Efficient Design of Myoelectric Controller based on Evolutionary Computation</b>
<a href="https://arxiv.org/abs/2204.02179">arxiv:2204.02179</a>
&#x1F4C8; 1 <br>
<p>Ahmed Aqeel Shaikh, Anand Kumar Mukhopadhyay, Soumyajit Poddar, Suman Samui</p></summary>
<p>

**Abstract:** Myoelectric pattern recognition is one of the important aspects in the design of the control strategy for various applications including upper-limb prostheses and bio-robotic hand movement systems. The current work has proposed an approach to design an energy-efficient EMG-based controller by considering a supervised learning framework using a kernelized SVM classifier for decoding the information of surface electromyography (sEMG) signals to infer the underlying muscle movements. In order to achieve the optimized performance of the EMG-based controller, our main strategy of classifier design is to reduce the false movements of the overall system (when the EMG-based controller is at the `Rest' position). To this end, unlike the traditional single training objective of soft margin kernelized SVM, we have formulated the training algorithm of the proposed supervised learning system as a general constrained multi-objective optimization problem. An elitist multi-objective evolutionary algorithm $-$ the non-dominated sorting genetic algorithm II (NSGA-II) has been used for the tuning of SVM hyperparameters. We have presented the experimental results by performing the experiments on a dataset consisting of the sEMG signals collected from eleven subjects at five different upper limb positions. It is evident from the presented result that the proposed approach provides much more flexibility to the designer in selecting the parameters of the classifier to optimize the energy efficiency of the EMG-based controller.

</p>
</details>

<details><summary><b>Towards Web Phishing Detection Limitations and Mitigation</b>
<a href="https://arxiv.org/abs/2204.00985">arxiv:2204.00985</a>
&#x1F4C8; 1 <br>
<p>Alsharif Abuadbba, Shuo Wang, Mahathir Almashor, Muhammed Ejaz Ahmed, Raj Gaire, Seyit Camtepe, Surya Nepal</p></summary>
<p>

**Abstract:** Web phishing remains a serious cyber threat responsible for most data breaches. Machine Learning (ML)-based anti-phishing detectors are seen as an effective countermeasure, and are increasingly adopted by web-browsers and software products. However, with an average of 10K phishing links reported per hour to platforms such as PhishTank and VirusTotal (VT), the deficiencies of such ML-based solutions are laid bare. We first explore how phishing sites bypass ML-based detection with a deep dive into 13K phishing pages targeting major brands such as Facebook. Results show successful evasion is caused by: (1) use of benign services to obscure phishing URLs; (2) high similarity between the HTML structures of phishing and benign pages; (3) hiding the ultimate phishing content within Javascript and running such scripts only on the client; (4) looking beyond typical credentials and credit cards for new content such as IDs and documents; (5) hiding phishing content until after human interaction. We attribute the root cause to the dependency of ML-based models on the vertical feature space (webpage content). These solutions rely only on what phishers present within the page itself. Thus, we propose Anti-SubtlePhish, a more resilient model based on logistic regression. The key augmentation is the inclusion of a horizontal feature space, which examines correlation variables between the final render of suspicious pages against what trusted services have recorded (e.g., PageRank). To defeat (1) and (2), we correlate information between WHOIS, PageRank, and page analytics. To combat (3), (4) and (5), we correlate features after rendering the page. Experiments with 100K phishing/benign sites show promising accuracy (98.8%). We also obtained 100% accuracy against 0-day phishing pages that were manually crafted, comparing well to the 0% recorded by VT vendors over the first four days.

</p>
</details>

<details><summary><b>Risk-Aware Control and Optimization for High-Renewable Power Grids</b>
<a href="https://arxiv.org/abs/2204.00950">arxiv:2204.00950</a>
&#x1F4C8; 1 <br>
<p>Neil Barry, Minas Chatzos, Wenbo Chen, Dahye Han, Chaofan Huang, Roshan Joseph, Michael Klamkin, Seonho Park, Mathieu Tanneau, Pascal Van Hentenryck, Shangkun Wang, Hanyu Zhang, Haoruo Zhao</p></summary>
<p>

**Abstract:** The transition of the electrical power grid from fossil fuels to renewable sources of energy raises fundamental challenges to the market-clearing algorithms that drive its operations. Indeed, the increased stochasticity in load and the volatility of renewable energy sources have led to significant increases in prediction errors, affecting the reliability and efficiency of existing deterministic optimization models. The RAMC project was initiated to investigate how to move from this deterministic setting into a risk-aware framework where uncertainty is quantified explicitly and incorporated in the market-clearing optimizations. Risk-aware market-clearing raises challenges on its own, primarily from a computational standpoint. This paper reviews how RAMC approaches risk-aware market clearing and presents some of its innovations in uncertainty quantification, optimization, and machine learning. Experimental results on real networks are presented.

</p>
</details>

<details><summary><b>The Effects of the Environment and Linear Actuators on Robot Morphologies</b>
<a href="https://arxiv.org/abs/2204.00934">arxiv:2204.00934</a>
&#x1F4C8; 1 <br>
<p>Steven Oud, Koen van der Pool</p></summary>
<p>

**Abstract:** The field of evolutionary robotics uses principles of natural evolution to design robots. In this paper, we study the effect of adding a new module inspired by the skeletal muscle to the existing RoboGen framework: the linear actuator. Additionally, we investigate how robots evolved in a plain environment differ from robots evolved in a rough environment. We consider the task of directed locomotion for comparing evolved robot morphologies. The results show that the addition of the linear actuator does not have a significant impact on the performance and morphologies of robots evolved in a plain environment. However, we find significant differences in the morphologies of robots evolved in a plain environment and robots evolved in a rough environment. We find that more complex behavior and morphologies emerge when we change the terrain of the environment.

</p>
</details>

<details><summary><b>Production of Categorical Data Verifying Differential Privacy: Conception and Applications to Machine Learning</b>
<a href="https://arxiv.org/abs/2204.00850">arxiv:2204.00850</a>
&#x1F4C8; 1 <br>
<p>Héber H. Arcolezi</p></summary>
<p>

**Abstract:** Private and public organizations regularly collect and analyze digitalized data about their associates, volunteers, clients, etc. However, because most personal data are sensitive, there is a key challenge in designing privacy-preserving systems. To tackle privacy concerns, research communities have proposed different methods to preserve privacy, with Differential privacy (DP) standing out as a formal definition that allows quantifying the privacy-utility trade-off. Besides, with the local DP (LDP) model, users can sanitize their data locally before transmitting it to the server. The objective of this thesis is thus two-fold: O$_1$) To improve the utility and privacy in multiple frequency estimates under LDP guarantees, which is fundamental to statistical learning. And O$_2$) To assess the privacy-utility trade-off of machine learning (ML) models trained over differentially private data. For O$_1$, we first tackled the problem from two "multiple" perspectives, i.e., multiple attributes and multiple collections throughout time, while focusing on utility. Secondly, we focused our attention on the multiple attributes aspect only, in which we proposed a solution focusing on privacy while preserving utility. In both cases, we demonstrate through analytical and experimental validations the advantages of our proposed solutions over state-of-the-art LDP protocols. For O$_2$, we empirically evaluated ML-based solutions designed to solve real-world problems while ensuring DP guarantees. Indeed, we mainly used the input data perturbation setting from the privacy-preserving ML literature. This is the situation in which the whole dataset is sanitized independently and, thus, we implemented LDP algorithms from the perspective of the centralized data owner. In all cases, we concluded that differentially private ML models achieve nearly the same utility metrics as non-private ones.

</p>
</details>

<details><summary><b>Automatic Registration of Images with Inconsistent Content Through Line-Support Region Segmentation and Geometrical Outlier Removal</b>
<a href="https://arxiv.org/abs/2204.00832">arxiv:2204.00832</a>
&#x1F4C8; 1 <br>
<p>Ming Zhao, Yongpeng Wu, Shengda Pan, Fan Zhou, Bowen An, André Kaup</p></summary>
<p>

**Abstract:** The implementation of automatic image registration is still difficult in various applications. In this paper, an automatic image registration approach through line-support region segmentation and geometrical outlier removal (ALRS-GOR) is proposed. This new approach is designed to address the problems associated with the registration of images with affine deformations and inconsistent content, such as remote sensing images with different spectral content or noise interference, or map images with inconsistent annotations. To begin with, line-support regions, namely a straight region whose points share roughly the same image gradient angle, are extracted to address the issues of inconsistent content existing in images. To alleviate the incompleteness of line segments, an iterative strategy with multi-resolution is employed to preserve global structures that are masked at full resolution by image details or noise. Then, Geometrical Outlier Removal (GOR) is developed to provide reliable feature point matching, which is based on affineinvariant geometrical classifications for corresponding matches initialized by SIFT. The candidate outliers are selected by comparing the disparity of accumulated classifications among all matches, instead of conventional methods which only rely on local geometrical relations. Various image sets have been considered in this paper for the evaluation of the proposed approach, including aerial images with simulated affine deformations, remote sensing optical and synthetic aperture radar images taken at different situations (multispectral, multisensor, and multitemporal), and map images with inconsistent annotations. Experimental results demonstrate the superior performance of the proposed method over the existing approaches for the whole data set.

</p>
</details>

<details><summary><b>AdaSmooth: An Adaptive Learning Rate Method based on Effective Ratio</b>
<a href="https://arxiv.org/abs/2204.00825">arxiv:2204.00825</a>
&#x1F4C8; 1 <br>
<p>Jun Lu</p></summary>
<p>

**Abstract:** It is well known that we need to choose the hyper-parameters in Momentum, AdaGrad, AdaDelta, and other alternative stochastic optimizers. While in many cases, the hyper-parameters are tuned tediously based on experience becoming more of an art than science. We present a novel per-dimension learning rate method for gradient descent called AdaSmooth. The method is insensitive to hyper-parameters thus it requires no manual tuning of the hyper-parameters like Momentum, AdaGrad, and AdaDelta methods. We show promising results compared to other methods on different convolutional neural networks, multi-layer perceptron, and alternative machine learning tasks. Empirical results demonstrate that AdaSmooth works well in practice and compares favorably to other stochastic optimization methods in neural networks.

</p>
</details>

<details><summary><b>RFVTM: A Recovery and Filtering Vertex Trichotomy Matching for Remote Sensing Image Registration</b>
<a href="https://arxiv.org/abs/2204.00818">arxiv:2204.00818</a>
&#x1F4C8; 1 <br>
<p>Ming Zhao, Bowen An, Yongpeng Wu, Huynh Van Luong, André Kaup</p></summary>
<p>

**Abstract:** Reliable feature point matching is a vital yet challenging process in feature-based image registration. In this paper,a robust feature point matching algorithm called Recovery and Filtering Vertex Trichotomy Matching (RFVTM) is proposed to remove outliers and retain sufficient inliers for remote sensing images. A novel affine invariant descriptor called vertex trichotomy descriptor is proposed on the basis of that geometrical relations between any of vertices and lines are preserved after affine transformations, which is constructed by mapping each vertex into trichotomy sets. The outlier removals in Vertex Trichotomy Matching (VTM) are implemented by iteratively comparing the disparity of corresponding vertex trichotomy descriptors. Some inliers mistakenly validated by a large amount of outliers are removed in VTM iterations, and several residual outliers close to correct locations cannot be excluded with the same graph structures. Therefore, a recovery and filtering strategy is designed to recover some inliers based on identical vertex trichotomy descriptors and restricted transformation errors. Assisted with the additional recovered inliers, residual outliers can also be filtered out during the process of reaching identical graph for the expanded vertex sets. Experimental results demonstrate the superior performance on precision and stability of this algorithm under various conditions, such as remote sensing images with large transformations, duplicated patterns, or inconsistent spectral content.

</p>
</details>


{% endraw %}
Prev: [2022.04.01]({{ '/2022/04/01/2022.04.01.html' | relative_url }})  Next: [2022.04.03]({{ '/2022/04/03/2022.04.03.html' | relative_url }})