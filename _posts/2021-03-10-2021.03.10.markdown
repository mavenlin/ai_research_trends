## Summary for 2021-03-10, created on 2021-12-23


<details><summary><b>What is Multimodality?</b>
<a href="https://arxiv.org/abs/2103.06304">arxiv:2103.06304</a>
&#x1F4C8; 121 <br>
<p>Letitia Parcalabescu, Nils Trost, Anette Frank</p></summary>
<p>

**Abstract:** The last years have shown rapid developments in the field of multimodal machine learning, combining e.g., vision, text or speech. In this position paper we explain how the field uses outdated definitions of multimodality that prove unfit for the machine learning era. We propose a new task-relative definition of (multi)modality in the context of multimodal machine learning that focuses on representations and information that are relevant for a given machine learning task. With our new definition of multimodality we aim to provide a missing foundation for multimodal research, an important component of language grounding and a crucial milestone towards NLU.

</p>
</details>

<details><summary><b>Full Page Handwriting Recognition via Image to Sequence Extraction</b>
<a href="https://arxiv.org/abs/2103.06450">arxiv:2103.06450</a>
&#x1F4C8; 47 <br>
<p>Sumeet S. Singh, Sergey Karayev</p></summary>
<p>

**Abstract:** We present a Neural Network based Handwritten Text Recognition (HTR) model architecture that can be trained to recognize full pages of handwritten or printed text without image segmentation. Being based on Image to Sequence architecture, it can extract text present in an image and then sequence it correctly without imposing any constraints regarding orientation, layout and size of text and non-text. Further, it can also be trained to generate auxiliary markup related to formatting, layout and content. We use character level vocabulary, thereby enabling language and terminology of any subject. The model achieves a new state-of-art in paragraph level recognition on the IAM dataset. When evaluated on scans of real world handwritten free form test answers - beset with curved and slanted lines, drawings, tables, math, chemistry and other symbols - it performs better than all commercially available HTR cloud APIs. It is deployed in production as part of a commercial web application.

</p>
</details>

<details><summary><b>MixMo: Mixing Multiple Inputs for Multiple Outputs via Deep Subnetworks</b>
<a href="https://arxiv.org/abs/2103.06132">arxiv:2103.06132</a>
&#x1F4C8; 40 <br>
<p>Alexandre Rame, Remy Sun, Matthieu Cord</p></summary>
<p>

**Abstract:** Recent strategies achieved ensembling "for free" by fitting concurrently diverse subnetworks inside a single base network. The main idea during training is that each subnetwork learns to classify only one of the multiple inputs simultaneously provided. However, the question of how to best mix these multiple inputs has not been studied so far. In this paper, we introduce MixMo, a new generalized framework for learning multi-input multi-output deep subnetworks. Our key motivation is to replace the suboptimal summing operation hidden in previous approaches by a more appropriate mixing mechanism. For that purpose, we draw inspiration from successful mixed sample data augmentations. We show that binary mixing in features - particularly with rectangular patches from CutMix - enhances results by making subnetworks stronger and more diverse. We improve state of the art for image classification on CIFAR-100 and Tiny ImageNet datasets. Our easy to implement models notably outperform data augmented deep ensembles, without the inference and memory overheads. As we operate in features and simply better leverage the expressiveness of large networks, we open a new line of research complementary to previous works.

</p>
</details>

<details><summary><b>Continual Semantic Segmentation via Repulsion-Attraction of Sparse and Disentangled Latent Representations</b>
<a href="https://arxiv.org/abs/2103.06342">arxiv:2103.06342</a>
&#x1F4C8; 25 <br>
<p>Umberto Michieli, Pietro Zanuttigh</p></summary>
<p>

**Abstract:** Deep neural networks suffer from the major limitation of catastrophic forgetting old tasks when learning new ones. In this paper we focus on class incremental continual learning in semantic segmentation, where new categories are made available over time while previous training data is not retained. The proposed continual learning scheme shapes the latent space to reduce forgetting whilst improving the recognition of novel classes. Our framework is driven by three novel components which we also combine on top of existing techniques effortlessly. First, prototypes matching enforces latent space consistency on old classes, constraining the encoder to produce similar latent representation for previously seen classes in the subsequent steps. Second, features sparsification allows to make room in the latent space to accommodate novel classes. Finally, contrastive learning is employed to cluster features according to their semantics while tearing apart those of different classes. Extensive evaluation on the Pascal VOC2012 and ADE20K datasets demonstrates the effectiveness of our approach, significantly outperforming state-of-the-art methods.

</p>
</details>

<details><summary><b>CUAD: An Expert-Annotated NLP Dataset for Legal Contract Review</b>
<a href="https://arxiv.org/abs/2103.06268">arxiv:2103.06268</a>
&#x1F4C8; 19 <br>
<p>Dan Hendrycks, Collin Burns, Anya Chen, Spencer Ball</p></summary>
<p>

**Abstract:** Many specialized domains remain untouched by deep learning, as large labeled datasets require expensive expert annotators. We address this bottleneck within the legal domain by introducing the Contract Understanding Atticus Dataset (CUAD), a new dataset for legal contract review. CUAD was created with dozens of legal experts from The Atticus Project and consists of over 13,000 annotations. The task is to highlight salient portions of a contract that are important for a human to review. We find that Transformer models have nascent performance, but that this performance is strongly influenced by model design and training dataset size. Despite these promising results, there is still substantial room for improvement. As one of the only large, specialized NLP benchmarks annotated by experts, CUAD can serve as a challenging research benchmark for the broader NLP community.

</p>
</details>

<details><summary><b>Hurdles to Progress in Long-form Question Answering</b>
<a href="https://arxiv.org/abs/2103.06332">arxiv:2103.06332</a>
&#x1F4C8; 18 <br>
<p>Kalpesh Krishna, Aurko Roy, Mohit Iyyer</p></summary>
<p>

**Abstract:** The task of long-form question answering (LFQA) involves retrieving documents relevant to a given question and using them to generate a paragraph-length answer. While many models have recently been proposed for LFQA, we show in this paper that the task formulation raises fundamental challenges regarding evaluation and dataset creation that currently preclude meaningful modeling progress. To demonstrate these challenges, we first design a new system that relies on sparse attention and contrastive retriever learning to achieve state-of-the-art performance on the ELI5 LFQA dataset. While our system tops the public leaderboard, a detailed analysis reveals several troubling trends: (1) our system's generated answers are not actually grounded in the documents that it retrieves; (2) ELI5 contains significant train / validation overlap, as at least 81% of ELI5 validation questions occur in paraphrased form in the training set; (3) ROUGE-L is not an informative metric of generated answer quality and can be easily gamed; and (4) human evaluations used for other text generation tasks are unreliable for LFQA. We offer suggestions to mitigate each of these issues, which we hope will lead to more rigorous LFQA research and meaningful progress in the future.

</p>
</details>

<details><summary><b>Quantization-Guided Training for Compact TinyML Models</b>
<a href="https://arxiv.org/abs/2103.06231">arxiv:2103.06231</a>
&#x1F4C8; 17 <br>
<p>Sedigh Ghamari, Koray Ozcan, Thu Dinh, Andrey Melnikov, Juan Carvajal, Jan Ernst, Sek Chai</p></summary>
<p>

**Abstract:** We propose a Quantization Guided Training (QGT) method to guide DNN training towards optimized low-bit-precision targets and reach extreme compression levels below 8-bit precision. Unlike standard quantization-aware training (QAT) approaches, QGT uses customized regularization to encourage weight values towards a distribution that maximizes accuracy while reducing quantization errors. One of the main benefits of this approach is the ability to identify compression bottlenecks. We validate QGT using state-of-the-art model architectures on vision datasets. We also demonstrate the effectiveness of QGT with an 81KB tiny model for person detection down to 2-bit precision (representing 17.7x size reduction), while maintaining an accuracy drop of only 3% compared to a floating-point baseline.

</p>
</details>

<details><summary><b>Spatially Consistent Representation Learning</b>
<a href="https://arxiv.org/abs/2103.06122">arxiv:2103.06122</a>
&#x1F4C8; 11 <br>
<p>Byungseok Roh, Wuhyun Shin, Ildoo Kim, Sungwoong Kim</p></summary>
<p>

**Abstract:** Self-supervised learning has been widely used to obtain transferrable representations from unlabeled images. Especially, recent contrastive learning methods have shown impressive performances on downstream image classification tasks. While these contrastive methods mainly focus on generating invariant global representations at the image-level under semantic-preserving transformations, they are prone to overlook spatial consistency of local representations and therefore have a limitation in pretraining for localization tasks such as object detection and instance segmentation. Moreover, aggressively cropped views used in existing contrastive methods can minimize representation distances between the semantically different regions of a single image.
  In this paper, we propose a spatially consistent representation learning algorithm (SCRL) for multi-object and location-specific tasks. In particular, we devise a novel self-supervised objective that tries to produce coherent spatial representations of a randomly cropped local region according to geometric translations and zooming operations. On various downstream localization tasks with benchmark datasets, the proposed SCRL shows significant performance improvements over the image-level supervised pretraining as well as the state-of-the-art self-supervised learning methods.
  Code is available at https://github.com/kakaobrain/scrl

</p>
</details>

<details><summary><b>FairFil: Contrastive Neural Debiasing Method for Pretrained Text Encoders</b>
<a href="https://arxiv.org/abs/2103.06413">arxiv:2103.06413</a>
&#x1F4C8; 10 <br>
<p>Pengyu Cheng, Weituo Hao, Siyang Yuan, Shijing Si, Lawrence Carin</p></summary>
<p>

**Abstract:** Pretrained text encoders, such as BERT, have been applied increasingly in various natural language processing (NLP) tasks, and have recently demonstrated significant performance gains. However, recent studies have demonstrated the existence of social bias in these pretrained NLP models. Although prior works have made progress on word-level debiasing, improved sentence-level fairness of pretrained encoders still lacks exploration. In this paper, we proposed the first neural debiasing method for a pretrained sentence encoder, which transforms the pretrained encoder outputs into debiased representations via a fair filter (FairFil) network. To learn the FairFil, we introduce a contrastive learning framework that not only minimizes the correlation between filtered embeddings and bias words but also preserves rich semantic information of the original sentences. On real-world datasets, our FairFil effectively reduces the bias degree of pretrained text encoders, while continuously showing desirable performance on downstream tasks. Moreover, our post-hoc method does not require any retraining of the text encoders, further enlarging FairFil's application space.

</p>
</details>

<details><summary><b>Regressive Domain Adaptation for Unsupervised Keypoint Detection</b>
<a href="https://arxiv.org/abs/2103.06175">arxiv:2103.06175</a>
&#x1F4C8; 10 <br>
<p>Junguang Jiang, Yifei Ji, Ximei Wang, Yufeng Liu, Jianmin Wang, Mingsheng Long</p></summary>
<p>

**Abstract:** Domain adaptation (DA) aims at transferring knowledge from a labeled source domain to an unlabeled target domain. Though many DA theories and algorithms have been proposed, most of them are tailored into classification settings and may fail in regression tasks, especially in the practical keypoint detection task. To tackle this difficult but significant task, we present a method of regressive domain adaptation (RegDA) for unsupervised keypoint detection. Inspired by the latest theoretical work, we first utilize an adversarial regressor to maximize the disparity on the target domain and train a feature generator to minimize this disparity. However, due to the high dimension of the output space, this regressor fails to detect samples that deviate from the support of the source. To overcome this problem, we propose two important ideas. First, based on our observation that the probability density of the output space is sparse, we introduce a spatial probability distribution to describe this sparsity and then use it to guide the learning of the adversarial regressor. Second, to alleviate the optimization difficulty in the high-dimensional space, we innovatively convert the minimax game in the adversarial training to the minimization of two opposite goals. Extensive experiments show that our method brings large improvement by 8% to 11% in terms of PCK on different datasets.

</p>
</details>

<details><summary><b>Symmetry meets AI</b>
<a href="https://arxiv.org/abs/2103.06115">arxiv:2103.06115</a>
&#x1F4C8; 10 <br>
<p>Gabriela Barenboim, Johannes Hirn, Veronica Sanz</p></summary>
<p>

**Abstract:** We explore whether Neural Networks (NNs) can {\it discover} the presence of symmetries as they learn to perform a task. For this, we train hundreds of NNs on a {\it decoy task} based on well-controlled Physics templates, where no information on symmetry is provided. We use the output from the last hidden layer of all these NNs, projected to fewer dimensions, as the input for a symmetry classification task, and show that information on symmetry had indeed been identified by the original NN without guidance. As an interdisciplinary application of this procedure, we identify the presence and level of symmetry in artistic paintings from different styles such as those of Picasso, Pollock and Van Gogh.

</p>
</details>

<details><summary><b>Automatic Speaker Independent Dysarthric Speech Intelligibility Assessment System</b>
<a href="https://arxiv.org/abs/2103.06157">arxiv:2103.06157</a>
&#x1F4C8; 9 <br>
<p>Ayush Tripathi, Swapnil Bhosale, Sunil Kumar Kopparapu</p></summary>
<p>

**Abstract:** Dysarthria is a condition which hampers the ability of an individual to control the muscles that play a major role in speech delivery. The loss of fine control over muscles that assist the movement of lips, vocal chords, tongue and diaphragm results in abnormal speech delivery. One can assess the severity level of dysarthria by analyzing the intelligibility of speech spoken by an individual. Continuous intelligibility assessment helps speech language pathologists not only study the impact of medication but also allows them to plan personalized therapy. It helps the clinicians immensely if the intelligibility assessment system is reliable, automatic, simple for (a) patients to undergo and (b) clinicians to interpret. Lack of availability of dysarthric data has resulted in development of speaker dependent automatic intelligibility assessment systems which requires patients to speak a large number of utterances. In this paper, we propose (a) a cost minimization procedure to select an optimal (small) number of utterances that need to be spoken by the dysarthric patient, (b) four different speaker independent intelligibility assessment systems which require the patient to speak a small number of words, and (c) the assessment score is close to the perceptual score that the Speech Language Pathologist (SLP) can relate to. The need for small number of utterances to be spoken by the patient and the score being relatable to the SLP benefits both the dysarthric patient and the clinician from usability perspective.

</p>
</details>

<details><summary><b>BrainNetGAN: Data augmentation of brain connectivity using generative adversarial network for dementia classification</b>
<a href="https://arxiv.org/abs/2103.08494">arxiv:2103.08494</a>
&#x1F4C8; 8 <br>
<p>Chao Li, Yiran Wei, Xi Chen, Carola-Bibiane Schonlieb</p></summary>
<p>

**Abstract:** Alzheimer's disease (AD) is the most common age-related dementia. It remains a challenge to identify the individuals at risk of dementia for precise management. Brain MRI offers a noninvasive biomarker to detect brain aging. Previous evidence shows that the brain structural change detected by diffusion MRI is associated with dementia. Mounting studies has conceptualised the brain as a complex network, which has shown the utility of this approach in characterising various neurological and psychiatric disorders. Therefore, the structural connectivity shows promise in dementia classification. The proposed BrainNetGAN is a generative adversarial network variant to augment the brain structural connectivity matrices for binary dementia classification tasks. Structural connectivity matrices between separated brain regions are constructed using tractography on diffusion MRI data. The BrainNetGAN model is trained to generate fake brain connectivity matrices, which are expected to reflect latent distribution of the real brain network data. Finally, a convolutional neural network classifier is proposed for binary dementia classification. Numerical results show that the binary classification performance in the testing set was improved using the BrainNetGAN augmented dataset. The proposed methodology allows quick synthesis of an arbitrary number of augmented connectivity matrices and can be easily transferred to similar classification tasks.

</p>
</details>

<details><summary><b>Self-Supervised Motion Retargeting with Safety Guarantee</b>
<a href="https://arxiv.org/abs/2103.06447">arxiv:2103.06447</a>
&#x1F4C8; 8 <br>
<p>Sungjoon Choi, Min Jae Song, Hyemin Ahn, Joohyung Kim</p></summary>
<p>

**Abstract:** In this paper, we present self-supervised shared latent embedding (S3LE), a data-driven motion retargeting method that enables the generation of natural motions in humanoid robots from motion capture data or RGB videos. While it requires paired data consisting of human poses and their corresponding robot configurations, it significantly alleviates the necessity of time-consuming data-collection via novel paired data generating processes. Our self-supervised learning procedure consists of two steps: automatically generating paired data to bootstrap the motion retargeting, and learning a projection-invariant mapping to handle the different expressivity of humans and humanoid robots. Furthermore, our method guarantees that the generated robot pose is collision-free and satisfies position limits by utilizing nonparametric regression in the shared latent space. We demonstrate that our method can generate expressive robotic motions from both the CMU motion capture database and YouTube videos.

</p>
</details>

<details><summary><b>Where is your place, Visual Place Recognition?</b>
<a href="https://arxiv.org/abs/2103.06443">arxiv:2103.06443</a>
&#x1F4C8; 8 <br>
<p>Sourav Garg, Tobias Fischer, Michael Milford</p></summary>
<p>

**Abstract:** Visual Place Recognition (VPR) is often characterized as being able to recognize the same place despite significant changes in appearance and viewpoint. VPR is a key component of Spatial Artificial Intelligence, enabling robotic platforms and intelligent augmentation platforms such as augmented reality devices to perceive and understand the physical world. In this paper, we observe that there are three "drivers" that impose requirements on spatially intelligent agents and thus VPR systems: 1) the particular agent including its sensors and computational resources, 2) the operating environment of this agent, and 3) the specific task that the artificial agent carries out. In this paper, we characterize and survey key works in the VPR area considering those drivers, including their place representation and place matching choices. We also provide a new definition of VPR based on the visual overlap -- akin to spatial view cells in the brain -- that enables us to find similarities and differences to other research areas in the robotics and computer vision fields. We identify numerous open challenges and suggest areas that require more in-depth attention in future works.

</p>
</details>

<details><summary><b>A Relational-learning Perspective to Multi-label Chest X-ray Classification</b>
<a href="https://arxiv.org/abs/2103.06220">arxiv:2103.06220</a>
&#x1F4C8; 8 <br>
<p>Anjany Sekuboyina, Daniel Oñoro-Rubio, Jens Kleesiek, Brandon Malone</p></summary>
<p>

**Abstract:** Multi-label classification of chest X-ray images is frequently performed using discriminative approaches, i.e. learning to map an image directly to its binary labels. Such approaches make it challenging to incorporate auxiliary information such as annotation uncertainty or a dependency among the labels. Building towards this, we propose a novel knowledge graph reformulation of multi-label classification, which not only readily increases predictive performance of an encoder but also serves as a general framework for introducing new domain knowledge.
  Specifically, we construct a multi-modal knowledge graph out of the chest X-ray images and its labels and pose multi-label classification as a link prediction problem. Incorporating auxiliary information can then simply be achieved by adding additional nodes and relations among them. When tested on a publicly-available radiograph dataset (CheXpert), our relational-reformulation using a naive knowledge graph outperforms the state-of-art by achieving an area-under-ROC curve of 83.5%, an improvement of "sim 1" over a purely discriminative approach.

</p>
</details>

<details><summary><b>Are we using appropriate segmentation metrics? Identifying correlates of human expert perception for CNN training beyond rolling the DICE coefficient</b>
<a href="https://arxiv.org/abs/2103.06205">arxiv:2103.06205</a>
&#x1F4C8; 8 <br>
<p>Florian Kofler, Ivan Ezhov, Fabian Isensee, Fabian Balsiger, Christoph Berger, Maximilian Koerner, Johannes Paetzold, Hongwei Li, Suprosanna Shit, Richard McKinley, Spyridon Bakas, Claus Zimmer, Donna Ankerst, Jan Kirschke, Benedikt Wiestler, Bjoern H. Menze</p></summary>
<p>

**Abstract:** In this study, we explore quantitative correlates of qualitative human expert perception. We discover that current quality metrics and loss functions, considered for biomedical image segmentation tasks, correlate moderately with segmentation quality assessment by experts, especially for small yet clinically relevant structures, such as the enhancing tumor in brain glioma. We propose a method employing classical statistics and experimental psychology to create complementary compound loss functions for modern deep learning methods, towards achieving a better fit with human quality assessment. When training a CNN for delineating adult brain tumor in MR images, all four proposed loss candidates outperform the established baselines on the clinically important and hardest to segment enhancing tumor label, while maintaining performance for other label channels.

</p>
</details>

<details><summary><b>Relational Weight Priors in Neural Networks for Abstract Pattern Learning and Language Modelling</b>
<a href="https://arxiv.org/abs/2103.06198">arxiv:2103.06198</a>
&#x1F4C8; 7 <br>
<p>Radha Kopparti, Tillman Weyde</p></summary>
<p>

**Abstract:** Deep neural networks have become the dominant approach in natural language processing (NLP). However, in recent years, it has become apparent that there are shortcomings in systematicity that limit the performance and data efficiency of deep learning in NLP. These shortcomings can be clearly shown in lower-level artificial tasks, mostly on synthetic data. Abstract patterns are the best known examples of a hard problem for neural networks in terms of generalisation to unseen data. They are defined by relations between items, such as equality, rather than their values. It has been argued that these low-level problems demonstrate the inability of neural networks to learn systematically. In this study, we propose Embedded Relation Based Patterns (ERBP) as a novel way to create a relational inductive bias that encourages learning equality and distance-based relations for abstract patterns. ERBP is based on Relation Based Patterns (RBP), but modelled as a Bayesian prior on network weights and implemented as a regularisation term in otherwise standard network learning. ERBP is is easy to integrate into standard neural networks and does not affect their learning capacity. In our experiments, ERBP priors lead to almost perfect generalisation when learning abstract patterns from synthetic noise-free sequences. ERBP also improves natural language models on the word and character level and pitch prediction in melodies with RNN, GRU and LSTM networks. We also find improvements in in the more complex tasks of learning of graph edit distance and compositional sentence entailment. ERBP consistently improves over RBP and over standard networks, showing that it enables abstract pattern learning which contributes to performance in natural language tasks.

</p>
</details>

<details><summary><b>U-Net Transformer: Self and Cross Attention for Medical Image Segmentation</b>
<a href="https://arxiv.org/abs/2103.06104">arxiv:2103.06104</a>
&#x1F4C8; 7 <br>
<p>Olivier Petit, Nicolas Thome, Clément Rambour, Luc Soler</p></summary>
<p>

**Abstract:** Medical image segmentation remains particularly challenging for complex and low-contrast anatomical structures. In this paper, we introduce the U-Transformer network, which combines a U-shaped architecture for image segmentation with self- and cross-attention from Transformers. U-Transformer overcomes the inability of U-Nets to model long-range contextual interactions and spatial dependencies, which are arguably crucial for accurate segmentation in challenging contexts. To this end, attention mechanisms are incorporated at two main levels: a self-attention module leverages global interactions between encoder features, while cross-attention in the skip connections allows a fine spatial recovery in the U-Net decoder by filtering out non-semantic features. Experiments on two abdominal CT-image datasets show the large performance gain brought out by U-Transformer compared to U-Net and local Attention U-Nets. We also highlight the importance of using both self- and cross-attention, and the nice interpretability features brought out by U-Transformer.

</p>
</details>

<details><summary><b>Designing Disaggregated Evaluations of AI Systems: Choices, Considerations, and Tradeoffs</b>
<a href="https://arxiv.org/abs/2103.06076">arxiv:2103.06076</a>
&#x1F4C8; 7 <br>
<p>Solon Barocas, Anhong Guo, Ece Kamar, Jacquelyn Krones, Meredith Ringel Morris, Jennifer Wortman Vaughan, Duncan Wadsworth, Hanna Wallach</p></summary>
<p>

**Abstract:** Disaggregated evaluations of AI systems, in which system performance is assessed and reported separately for different groups of people, are conceptually simple. However, their design involves a variety of choices. Some of these choices influence the results that will be obtained, and thus the conclusions that can be drawn; others influence the impacts -- both beneficial and harmful -- that a disaggregated evaluation will have on people, including the people whose data is used to conduct the evaluation. We argue that a deeper understanding of these choices will enable researchers and practitioners to design careful and conclusive disaggregated evaluations. We also argue that better documentation of these choices, along with the underlying considerations and tradeoffs that have been made, will help others when interpreting an evaluation's results and conclusions.

</p>
</details>

<details><summary><b>An Amharic News Text classification Dataset</b>
<a href="https://arxiv.org/abs/2103.05639">arxiv:2103.05639</a>
&#x1F4C8; 7 <br>
<p>Israel Abebe Azime, Nebil Mohammed</p></summary>
<p>

**Abstract:** In NLP, text classification is one of the primary problems we try to solve and its uses in language analyses are indisputable. The lack of labeled training data made it harder to do these tasks in low resource languages like Amharic. The task of collecting, labeling, annotating, and making valuable this kind of data will encourage junior researchers, schools, and machine learning practitioners to implement existing classification models in their language. In this short paper, we aim to introduce the Amharic text classification dataset that consists of more than 50k news articles that were categorized into 6 classes. This dataset is made available with easy baseline performances to encourage studies and better performance experiments.

</p>
</details>

<details><summary><b>User-centered Evaluation of Popularity Bias in Recommender Systems</b>
<a href="https://arxiv.org/abs/2103.06364">arxiv:2103.06364</a>
&#x1F4C8; 6 <br>
<p>Himan Abdollahpouri, Masoud Mansoury, Robin Burke, Bamshad Mobasher, Edward Malthouse</p></summary>
<p>

**Abstract:** Recommendation and ranking systems are known to suffer from popularity bias; the tendency of the algorithm to favor a few popular items while under-representing the majority of other items. Prior research has examined various approaches for mitigating popularity bias and enhancing the recommendation of long-tail, less popular, items. The effectiveness of these approaches is often assessed using different metrics to evaluate the extent to which over-concentration on popular items is reduced. However, not much attention has been given to the user-centered evaluation of this bias; how different users with different levels of interest towards popular items are affected by such algorithms. In this paper, we show the limitations of the existing metrics to evaluate popularity bias mitigation when we want to assess these algorithms from the users' perspective and we propose a new metric that can address these limitations. In addition, we present an effective approach that mitigates popularity bias from the user-centered point of view. Finally, we investigate several state-of-the-art approaches proposed in recent years to mitigate popularity bias and evaluate their performances using the existing metrics and also from the users' perspective. Our experimental results using two publicly-available datasets show that existing popularity bias mitigation techniques ignore the users' tolerance towards popular items. Our proposed user-centered method can tackle popularity bias effectively for different users while also improving the existing metrics.

</p>
</details>

<details><summary><b>Quantum machine learning with differential privacy</b>
<a href="https://arxiv.org/abs/2103.06232">arxiv:2103.06232</a>
&#x1F4C8; 6 <br>
<p>William M Watkins, Samuel Yen-Chi Chen, Shinjae Yoo</p></summary>
<p>

**Abstract:** Quantum machine learning (QML) can complement the growing trend of using learned models for a myriad of classification tasks, from image recognition to natural speech processing. A quantum advantage arises due to the intractability of quantum operations on a classical computer. Many datasets used in machine learning are crowd sourced or contain some private information. To the best of our knowledge, no current QML models are equipped with privacy-preserving features, which raises concerns as it is paramount that models do not expose sensitive information. Thus, privacy-preserving algorithms need to be implemented with QML. One solution is to make the machine learning algorithm differentially private, meaning the effect of a single data point on the training dataset is minimized. Differentially private machine learning models have been investigated, but differential privacy has yet to be studied in the context of QML. In this study, we develop a hybrid quantum-classical model that is trained to preserve privacy using differentially private optimization algorithm. This marks the first proof-of-principle demonstration of privacy-preserving QML. The experiments demonstrate that differentially private QML can protect user-sensitive information without diminishing model accuracy. Although the quantum model is simulated and tested on a classical computer, it demonstrates potential to be efficiently implemented on near-term quantum devices (noisy intermediate-scale quantum [NISQ]). The approach's success is illustrated via the classification of spatially classed two-dimensional datasets and a binary MNIST classification. This implementation of privacy-preserving QML will ensure confidentiality and accurate learning on NISQ technology.

</p>
</details>

<details><summary><b>RMP2: A Structured Composable Policy Class for Robot Learning</b>
<a href="https://arxiv.org/abs/2103.05922">arxiv:2103.05922</a>
&#x1F4C8; 6 <br>
<p>Anqi Li, Ching-An Cheng, M. Asif Rana, Man Xie, Karl Van Wyk, Nathan Ratliff, Byron Boots</p></summary>
<p>

**Abstract:** We consider the problem of learning motion policies for acceleration-based robotics systems with a structured policy class specified by RMPflow. RMPflow is a multi-task control framework that has been successfully applied in many robotics problems. Using RMPflow as a structured policy class in learning has several benefits, such as sufficient expressiveness, the flexibility to inject different levels of prior knowledge as well as the ability to transfer policies between robots. However, implementing a system for end-to-end learning RMPflow policies faces several computational challenges. In this work, we re-examine the message passing algorithm of RMPflow and propose a more efficient alternate algorithm, called RMP2, that uses modern automatic differentiation tools (such as TensorFlow and PyTorch) to compute RMPflow policies. Our new design retains the strengths of RMPflow while bringing in advantages from automatic differentiation, including 1) easy programming interfaces to designing complex transformations; 2) support of general directed acyclic graph (DAG) transformation structures; 3) end-to-end differentiability for policy learning; 4) improved computational efficiency. Because of these features, RMP2 can be treated as a structured policy class for efficient robot learning which is suitable encoding domain knowledge. Our experiments show that using structured policy class given by RMP2 can improve policy performance and safety in reinforcement learning tasks for goal reaching in cluttered space.

</p>
</details>

<details><summary><b>Topical Language Generation using Transformers</b>
<a href="https://arxiv.org/abs/2103.06434">arxiv:2103.06434</a>
&#x1F4C8; 5 <br>
<p>Rohola Zandie, Mohammad H. Mahoor</p></summary>
<p>

**Abstract:** Large-scale transformer-based language models (LMs) demonstrate impressive capabilities in open text generation. However, controlling the generated text's properties such as the topic, style, and sentiment is challenging and often requires significant changes to the model architecture or retraining and fine-tuning the model on new supervised data. This paper presents a novel approach for Topical Language Generation (TLG) by combining a pre-trained LM with topic modeling information. We cast the problem using Bayesian probability formulation with topic probabilities as a prior, LM probabilities as the likelihood, and topical language generation probability as the posterior. In learning the model, we derive the topic probability distribution from the user-provided document's natural structure. Furthermore, we extend our model by introducing new parameters and functions to influence the quantity of the topical features presented in the generated text. This feature would allow us to easily control the topical properties of the generated text. Our experimental results demonstrate that our model outperforms the state-of-the-art results on coherency, diversity, and fluency while being faster in decoding.

</p>
</details>

<details><summary><b>Robustness to Pruning Predicts Generalization in Deep Neural Networks</b>
<a href="https://arxiv.org/abs/2103.06002">arxiv:2103.06002</a>
&#x1F4C8; 5 <br>
<p>Lorenz Kuhn, Clare Lyle, Aidan N. Gomez, Jonas Rothfuss, Yarin Gal</p></summary>
<p>

**Abstract:** Existing generalization measures that aim to capture a model's simplicity based on parameter counts or norms fail to explain generalization in overparameterized deep neural networks. In this paper, we introduce a new, theoretically motivated measure of a network's simplicity which we call prunability: the smallest \emph{fraction} of the network's parameters that can be kept while pruning without adversely affecting its training loss. We show that this measure is highly predictive of a model's generalization performance across a large set of convolutional networks trained on CIFAR-10, does not grow with network size unlike existing pruning-based measures, and exhibits high correlation with test set loss even in a particularly challenging double descent setting. Lastly, we show that the success of prunability cannot be explained by its relation to known complexity measures based on models' margin, flatness of minima and optimization speed, finding that our new measure is similar to -- but more predictive than -- existing flatness-based measures, and that its predictions exhibit low mutual information with those of other baselines.

</p>
</details>

<details><summary><b>DeepCPCFG: Deep Learning and Context Free Grammars for End-to-End Information Extraction</b>
<a href="https://arxiv.org/abs/2103.05908">arxiv:2103.05908</a>
&#x1F4C8; 5 <br>
<p>Freddy C. Chua, Nigel P. Duffy</p></summary>
<p>

**Abstract:** We address the challenge of extracting structured information from business documents without detailed annotations. We propose Deep Conditional Probabilistic Context Free Grammars (DeepCPCFG) to parse two-dimensional complex documents and use Recursive Neural Networks to create an end-to-end system for finding the most probable parse that represents the structured information to be extracted. This system is trained end-to-end with scanned documents as input and only relational-records as labels. The relational-records are extracted from existing databases avoiding the cost of annotating documents by hand. We apply this approach to extract information from scanned invoices achieving state-of-the-art results despite using no hand-annotations.

</p>
</details>

<details><summary><b>Diagnosing Vulnerability of Variational Auto-Encoders to Adversarial Attacks</b>
<a href="https://arxiv.org/abs/2103.06701">arxiv:2103.06701</a>
&#x1F4C8; 4 <br>
<p>Anna Kuzina, Max Welling, Jakub M. Tomczak</p></summary>
<p>

**Abstract:** In this work, we explore adversarial attacks on the Variational Autoencoders (VAE). We show how to modify data point to obtain a prescribed latent code (supervised attack) or just get a drastically different code (unsupervised attack). We examine the influence of model modifications ($β$-VAE, NVAE) on the robustness of VAEs and suggest metrics to quantify it.

</p>
</details>

<details><summary><b>Causal-aware Safe Policy Improvement for Task-oriented dialogue</b>
<a href="https://arxiv.org/abs/2103.06370">arxiv:2103.06370</a>
&#x1F4C8; 4 <br>
<p>Govardana Sachithanandam Ramachandran, Kazuma Hashimoto, Caiming Xiong</p></summary>
<p>

**Abstract:** The recent success of reinforcement learning's (RL) in solving complex tasks is most often attributed to its capacity to explore and exploit an environment where it has been trained. Sample efficiency is usually not an issue since cheap simulators are available to sample data on-policy. On the other hand, task oriented dialogues are usually learnt from offline data collected using human demonstrations. Collecting diverse demonstrations and annotating them is expensive. Unfortunately, use of RL methods trained on off-policy data are prone to issues of bias and generalization, which are further exacerbated by stochasticity in human response and non-markovian belief state of a dialogue management system. To this end, we propose a batch RL framework for task oriented dialogue policy learning: causal aware safe policy improvement (CASPI). This method gives guarantees on dialogue policy's performance and also learns to shape rewards according to intentions behind human responses, rather than just mimicking demonstration data; this couple with batch-RL helps overall with sample efficiency of the framework. We demonstrate the effectiveness of this framework on a dialogue-context-to-text Generation and end-to-end dialogue task of the Multiwoz2.0 dataset. The proposed method outperforms the current state of the art on these metrics, in both case. In the end-to-end case, our method trained only on 10\% of the data was able to out perform current state in three out of four evaluation metrics.

</p>
</details>

<details><summary><b>A Tree-based Federated Learning Approach for Personalized Treatment Effect Estimation from Heterogeneous Data Sources</b>
<a href="https://arxiv.org/abs/2103.06261">arxiv:2103.06261</a>
&#x1F4C8; 4 <br>
<p>Xiaoqing Tan, Chung-Chou H. Chang, Lu Tang</p></summary>
<p>

**Abstract:** Federated learning is an appealing framework for analyzing sensitive data from distributed health data networks. Under this framework, data partners at local sites collaboratively build an analytical model under the orchestration of a coordinating site, while keeping the data decentralized. While integrating information from multiple sources may boost statistical efficiency, existing federated learning methods mainly assume data across sites are homogeneous samples of the global population, failing to properly account for the extra variability across sites in estimation and inference. Drawing on a multi-hospital electronic health records network, we develop an efficient and interpretable tree-based ensemble of personalized treatment effect estimators to join results across hospital sites, while actively modeling for the heterogeneity in data sources through site partitioning. The efficiency of this approach is demonstrated by a study of causal effects of oxygen saturation on hospital mortality and backed up by comprehensive numerical results.

</p>
</details>

<details><summary><b>A registration error estimation framework for correlative imaging</b>
<a href="https://arxiv.org/abs/2103.06256">arxiv:2103.06256</a>
&#x1F4C8; 4 <br>
<p>Guillaume Potier, Frédéric Lavancier, Stephan Kunne, Perrine Paul-Gilloteaux</p></summary>
<p>

**Abstract:** Correlative imaging workflows are now widely used in bioimaging and aims to image the same sample using at least two different and complementary imaging modalities. Part of the workflow relies on finding the transformation linking a source image to a target image. We are specifically interested in the estimation of registration error in point-based registration. We propose an application of multivariate linear regression to solve the registration problem allowing us to propose a framework for the estimation of the associated error in the case of rigid and affine transformations and with anisotropic noise. These developments can be used as a decision-support tool for the biologist to analyze multimodal correlative images and are available under Ec-CLEM, an open-source plugin under ICY.

</p>
</details>

<details><summary><b>Piecewise linear regression and classification</b>
<a href="https://arxiv.org/abs/2103.06189">arxiv:2103.06189</a>
&#x1F4C8; 4 <br>
<p>Alberto Bemporad</p></summary>
<p>

**Abstract:** This paper proposes a method for solving multivariate regression and classification problems using piecewise linear predictors over a polyhedral partition of the feature space. The resulting algorithm that we call PARC (Piecewise Affine Regression and Classification) alternates between (i) solving ridge regression problems for numeric targets, softmax regression problems for categorical targets, and either softmax regression or cluster centroid computation for piecewise linear separation, and (ii) assigning the training points to different clusters on the basis of a criterion that balances prediction accuracy and piecewise-linear separability. We prove that PARC is a block-coordinate descent algorithm that optimizes a suitably constructed objective function, and that it converges in a finite number of steps to a local minimum of that function. The accuracy of the algorithm is extensively tested numerically on synthetic and real-world datasets, showing that the approach provides an extension of linear regression/classification that is particularly useful when the obtained predictor is used as part of an optimization model. A Python implementation of the algorithm described in this paper is available at http://cse.lab.imtlucca.it/~bemporad/parc .

</p>
</details>

<details><summary><b>Towards Learning an Unbiased Classifier from Biased Data via Conditional Adversarial Debiasing</b>
<a href="https://arxiv.org/abs/2103.06179">arxiv:2103.06179</a>
&#x1F4C8; 4 <br>
<p>Christian Reimers, Paul Bodesheim, Jakob Runge, Joachim Denzler</p></summary>
<p>

**Abstract:** Bias in classifiers is a severe issue of modern deep learning methods, especially for their application in safety- and security-critical areas. Often, the bias of a classifier is a direct consequence of a bias in the training dataset, frequently caused by the co-occurrence of relevant features and irrelevant ones. To mitigate this issue, we require learning algorithms that prevent the propagation of bias from the dataset into the classifier. We present a novel adversarial debiasing method, which addresses a feature that is spuriously connected to the labels of training images but statistically independent of the labels for test images. Thus, the automatic identification of relevant features during training is perturbed by irrelevant features. This is the case in a wide range of bias-related problems for many computer vision tasks, such as automatic skin cancer detection or driver assistance. We argue by a mathematical proof that our approach is superior to existing techniques for the abovementioned bias. Our experiments show that our approach performs better than state-of-the-art techniques on a well-known benchmark dataset with real-world images of cats and dogs.

</p>
</details>

<details><summary><b>Model-inspired Deep Learning for Light-Field Microscopy with Application to Neuron Localization</b>
<a href="https://arxiv.org/abs/2103.06164">arxiv:2103.06164</a>
&#x1F4C8; 4 <br>
<p>Pingfan Song, Herman Verinaz Jadan, Carmel L. Howe, Peter Quicke, Amanda J. Foust, Pier Luigi Dragotti</p></summary>
<p>

**Abstract:** Light-field microscopes are able to capture spatial and angular information of incident light rays. This allows reconstructing 3D locations of neurons from a single snap-shot.In this work, we propose a model-inspired deep learning approach to perform fast and robust 3D localization of sources using light-field microscopy images. This is achieved by developing a deep network that efficiently solves a convolutional sparse coding (CSC) problem to map Epipolar Plane Images (EPI) to corresponding sparse codes. The network architecture is designed systematically by unrolling the convolutional Iterative Shrinkage and Thresholding Algorithm (ISTA) while the network parameters are learned from a training dataset. Such principled design enables the deep network to leverage both domain knowledge implied in the model, as well as new parameters learned from the data, thereby combining advantages of model-based and learning-based methods. Practical experiments on localization of mammalian neurons from light-fields show that the proposed approach simultaneously provides enhanced performance, interpretability and efficiency.

</p>
</details>

<details><summary><b>BCFNet: A Balanced Collaborative Filtering Network with Attention Mechanism</b>
<a href="https://arxiv.org/abs/2103.06105">arxiv:2103.06105</a>
&#x1F4C8; 4 <br>
<p>Zi-Yuan Hu, Jin Huang, Zhi-Hong Deng, Chang-Dong Wang, Ling Huang, Jian-Huang Lai, Philip S. Yu</p></summary>
<p>

**Abstract:** Collaborative Filtering (CF) based recommendation methods have been widely studied, which can be generally categorized into two types, i.e., representation learning-based CF methods and matching function learning-based CF methods. Representation learning tries to learn a common low dimensional space for the representations of users and items. In this case, a user and item match better if they have higher similarity in that common space. Matching function learning tries to directly learn the complex matching function that maps user-item pairs to matching scores. Although both methods are well developed, they suffer from two fundamental flaws, i.e., the representation learning resorts to applying a dot product which has limited expressiveness on the latent features of users and items, while the matching function learning has weakness in capturing low-rank relations. To overcome such flaws, we propose a novel recommendation model named Balanced Collaborative Filtering Network (BCFNet), which has the strengths of the two types of methods. In addition, an attention mechanism is designed to better capture the hidden information within implicit feedback and strengthen the learning ability of the neural network. Furthermore, a balance module is designed to alleviate the over-fitting issue in DNNs. Extensive experiments on eight real-world datasets demonstrate the effectiveness of the proposed model.

</p>
</details>

<details><summary><b>Deep learning with photosensor timing information as a background rejection method for the Cherenkov Telescope Array</b>
<a href="https://arxiv.org/abs/2103.06054">arxiv:2103.06054</a>
&#x1F4C8; 4 <br>
<p>Samuel Spencer, Thomas Armstrong, Jason Watson, Salvatore Mangano, Yves Renier, Garret Cotter</p></summary>
<p>

**Abstract:** New deep learning techniques present promising new analysis methods for Imaging Atmospheric Cherenkov Telescopes (IACTs) such as the upcoming Cherenkov Telescope Array (CTA). In particular, the use of Convolutional Neural Networks (CNNs) could provide a direct event classification method that uses the entire information contained within the Cherenkov shower image, bypassing the need to Hillas parameterise the image and allowing fast processing of the data.
  Existing work in this field has utilised images of the integrated charge from IACT camera photomultipliers, however the majority of current and upcoming generation IACT cameras have the capacity to read out the entire photosensor waveform following a trigger. As the arrival times of Cherenkov photons from Extensive Air Showers (EAS) at the camera plane are dependent upon the altitude of their emission and the impact distance from the telescope, these waveforms contain information potentially useful for IACT event classification.
  In this test-of-concept simulation study, we investigate the potential for using these camera pixel waveforms with new deep learning techniques as a background rejection method, against both proton and electron induced EAS. We find that a means of utilising their information is to create a set of seven additional 2-dimensional pixel maps of waveform parameters, to be fed into the machine learning algorithm along with the integrated charge image. Whilst we ultimately find that the only classification power against electrons is based upon event direction, methods based upon timing information appear to out-perform similar charge based methods for gamma/hadron separation. We also review existing methods of event classifications using a combination of deep learning and timing information in other astroparticle physics experiments.

</p>
</details>

<details><summary><b>Limitations of Post-Hoc Feature Alignment for Robustness</b>
<a href="https://arxiv.org/abs/2103.05898">arxiv:2103.05898</a>
&#x1F4C8; 4 <br>
<p>Collin Burns, Jacob Steinhardt</p></summary>
<p>

**Abstract:** Feature alignment is an approach to improving robustness to distribution shift that matches the distribution of feature activations between the training distribution and test distribution. A particularly simple but effective approach to feature alignment involves aligning the batch normalization statistics between the two distributions in a trained neural network. This technique has received renewed interest lately because of its impressive performance on robustness benchmarks. However, when and why this method works is not well understood. We investigate the approach in more detail and identify several limitations. We show that it only significantly helps with a narrow set of distribution shifts and we identify several settings in which it even degrades performance. We also explain why these limitations arise by pinpointing why this approach can be so effective in the first place. Our findings call into question the utility of this approach and Unsupervised Domain Adaptation more broadly for improving robustness in practice.

</p>
</details>

<details><summary><b>Empirical Mode Modeling: A data-driven approach to recover and forecast nonlinear dynamics from noisy data</b>
<a href="https://arxiv.org/abs/2103.07281">arxiv:2103.07281</a>
&#x1F4C8; 3 <br>
<p>Joseph Park, Gerald M Pao, Erik Stabenau, George Sugihara, Thomas Lorimer</p></summary>
<p>

**Abstract:** Data-driven, model-free analytics are natural choices for discovery and forecasting of complex, nonlinear systems. Methods that operate in the system state-space require either an explicit multidimensional state-space, or, one approximated from available observations. Since observational data are frequently sampled with noise, it is possible that noise can corrupt the state-space representation degrading analytical performance. Here, we evaluate the synthesis of empirical mode decomposition with empirical dynamic modeling, which we term empirical mode modeling, to increase the information content of state-space representations in the presence of noise. Evaluation of a mathematical, and, an ecologically important geophysical application across three different state-space representations suggests that empirical mode modeling may be a useful technique for data-driven, model-free, state-space analysis in the presence of noise.

</p>
</details>

<details><summary><b>Smartphone Impostor Detection with Behavioral Data Privacy and Minimalist Hardware Support</b>
<a href="https://arxiv.org/abs/2103.06453">arxiv:2103.06453</a>
&#x1F4C8; 3 <br>
<p>Guangyuan Hu, Zecheng He, Ruby B. Lee</p></summary>
<p>

**Abstract:** Impostors are attackers who take over a smartphone and gain access to the legitimate user's confidential and private information. This paper proposes a defense-in-depth mechanism to detect impostors quickly with simple Deep Learning algorithms, which can achieve better detection accuracy than the best prior work which used Machine Learning algorithms requiring computation of multiple features. Different from previous work, we then consider protecting the privacy of a user's behavioral (sensor) data by not exposing it outside the smartphone. For this scenario, we propose a Recurrent Neural Network (RNN) based Deep Learning algorithm that uses only the legitimate user's sensor data to learn his/her normal behavior. We propose to use Prediction Error Distribution (PED) to enhance the detection accuracy. We also show how a minimalist hardware module, dubbed SID for Smartphone Impostor Detector, can be designed and integrated into smartphones for self-contained impostor detection. Experimental results show that SID can support real-time impostor detection, at a very low hardware cost and energy consumption, compared to other RNN accelerators.

</p>
</details>

<details><summary><b>XDO: A Double Oracle Algorithm for Extensive-Form Games</b>
<a href="https://arxiv.org/abs/2103.06426">arxiv:2103.06426</a>
&#x1F4C8; 3 <br>
<p>Stephen McAleer, John Lanier, Pierre Baldi, Roy Fox</p></summary>
<p>

**Abstract:** Policy Space Response Oracles (PSRO) is a deep reinforcement learning algorithm for two-player zero-sum games that has empirically found approximate Nash equilibria in large games. Although PSRO is guaranteed to converge to a Nash equilibrium, it may take an exponential number of iterations as the number of infostates grows. We propose Extensive-Form Double Oracle (XDO), an extensive-form double oracle algorithm that is guaranteed to converge to an approximate Nash equilibrium linearly in the number of infostates. Unlike PSRO, which mixes best responses at the root of the game, XDO mixes best responses at every infostate. We also introduce Neural XDO (NXDO), where the best response is learned through deep RL. In tabular experiments on Leduc poker, we find that XDO achieves an approximate Nash equilibrium in a number of iterations 1-2 orders of magnitude smaller than PSRO. In experiments on a modified Leduc poker game, we show that tabular XDO achieves over 11x lower exploitability than CFR and over 82x lower exploitability than PSRO and XFP in the same amount of time. We also show that NXDO beats PSRO and is competitive with NFSP on a large no-limit poker game.

</p>
</details>

<details><summary><b>3D Head-Position Prediction in First-Person View by Considering Head Pose for Human-Robot Eye Contact</b>
<a href="https://arxiv.org/abs/2103.06417">arxiv:2103.06417</a>
&#x1F4C8; 3 <br>
<p>Yuki Tamaru, Yasunori Ozaki, Yuki Okafuji, Jun Baba, Junya Nakanishi, Yuichiro Yoshikawa</p></summary>
<p>

**Abstract:** For a humanoid robot to make eye contact to initiate communication with a human, it is necessary to estimate the human's head position.However, eye contact becomes difficult due to the mechanical delay of the robot while the subject with whom the robot is interacting with is moving. Owing to these issues, it is important to perform head-position prediction to mitigate the effect of the delay in the robot's motion. Based on the fact that humans turn their heads before changing direction while walking, we hypothesized that the accuracy of three-dimensional(3D) head-position prediction from the first-person view can be improved by considering the head pose into account.We compared our method with the conventional Kalman filter-based method, and found our method to be more accurate. The experimental results show that considering the head pose helps improve the accuracy of 3D head-position prediction.

</p>
</details>

<details><summary><b>A Vision Based Deep Reinforcement Learning Algorithm for UAV Obstacle Avoidance</b>
<a href="https://arxiv.org/abs/2103.06403">arxiv:2103.06403</a>
&#x1F4C8; 3 <br>
<p>Jeremy Roghair, Kyungtae Ko, Amir Ehsan Niaraki Asli, Ali Jannesari</p></summary>
<p>

**Abstract:** Integration of reinforcement learning with unmanned aerial vehicles (UAVs) to achieve autonomous flight has been an active research area in recent years. An important part focuses on obstacle detection and avoidance for UAVs navigating through an environment. Exploration in an unseen environment can be tackled with Deep Q-Network (DQN). However, value exploration with uniform sampling of actions may lead to redundant states, where often the environments inherently bear sparse rewards. To resolve this, we present two techniques for improving exploration for UAV obstacle avoidance. The first is a convergence-based approach that uses convergence error to iterate through unexplored actions and temporal threshold to balance exploration and exploitation. The second is a guidance-based approach using a Domain Network which uses a Gaussian mixture distribution to compare previously seen states to a predicted next state in order to select the next action. Performance and evaluation of these approaches were implemented in multiple 3-D simulation environments, with variation in complexity. The proposed approach demonstrates a two-fold improvement in average rewards compared to state of the art.

</p>
</details>

<details><summary><b>A Computed Tomography Vertebral Segmentation Dataset with Anatomical Variations and Multi-Vendor Scanner Data</b>
<a href="https://arxiv.org/abs/2103.06360">arxiv:2103.06360</a>
&#x1F4C8; 3 <br>
<p>Hans Liebl, David Schinz, Anjany Sekuboyina, Luca Malagutti, Maximilian T. Löffler, Amirhossein Bayat, Malek El Husseini, Giles Tetteh, Katharina Grau, Eva Niederreiter, Thomas Baum, Benedikt Wiestler, Bjoern Menze, Rickmer Braren, Claus Zimmer, Jan S. Kirschke</p></summary>
<p>

**Abstract:** With the advent of deep learning algorithms, fully automated radiological image analysis is within reach. In spine imaging, several atlas- and shape-based as well as deep learning segmentation algorithms have been proposed, allowing for subsequent automated analysis of morphology and pathology. The first Large Scale Vertebrae Segmentation Challenge (VerSe 2019) showed that these perform well on normal anatomy, but fail in variants not frequently present in the training dataset. Building on that experience, we report on the largely increased VerSe 2020 dataset and results from the second iteration of the VerSe challenge (MICCAI 2020, Lima, Peru). VerSe 2020 comprises annotated spine computed tomography (CT) images from 300 subjects with 4142 fully visualized and annotated vertebrae, collected across multiple centres from four different scanner manufacturers, enriched with cases that exhibit anatomical variants such as enumeration abnormalities (n=77) and transitional vertebrae (n=161). Metadata includes vertebral labelling information, voxel-level segmentation masks obtained with a human-machine hybrid algorithm and anatomical ratings, to enable the development and benchmarking of robust and accurate segmentation algorithms.

</p>
</details>

<details><summary><b>Face Images as Jigsaw Puzzles: Compositional Perception of Human Faces for Machines Using Generative Adversarial Networks</b>
<a href="https://arxiv.org/abs/2103.06331">arxiv:2103.06331</a>
&#x1F4C8; 3 <br>
<p>Mahla Abdolahnejad, Peter Xiaoping Liu</p></summary>
<p>

**Abstract:** An important goal in human-robot-interaction (HRI) is for machines to achieve a close to human level of face perception. One of the important differences between machine learning and human intelligence is the lack of compositionality. This paper introduces a new scheme to enable generative adversarial networks to learn the distribution of face images composed of smaller parts. This results in a more flexible machine face perception and easier generalization to outside training examples. We demonstrate that this model is able to produce realistic high-quality face images by generating and piecing together the parts. Additionally, we demonstrate that this model learns the relations between the facial parts and their distributions. Therefore, the specific facial parts are interchangeable between generated face images.

</p>
</details>

<details><summary><b>TANTRA: Timing-Based Adversarial Network Traffic Reshaping Attack</b>
<a href="https://arxiv.org/abs/2103.06297">arxiv:2103.06297</a>
&#x1F4C8; 3 <br>
<p>Yam Sharon, David Berend, Yang Liu, Asaf Shabtai, Yuval Elovici</p></summary>
<p>

**Abstract:** Network intrusion attacks are a known threat. To detect such attacks, network intrusion detection systems (NIDSs) have been developed and deployed. These systems apply machine learning models to high-dimensional vectors of features extracted from network traffic to detect intrusions. Advances in NIDSs have made it challenging for attackers, who must execute attacks without being detected by these systems. Prior research on bypassing NIDSs has mainly focused on perturbing the features extracted from the attack traffic to fool the detection system, however, this may jeopardize the attack's functionality. In this work, we present TANTRA, a novel end-to-end Timing-based Adversarial Network Traffic Reshaping Attack that can bypass a variety of NIDSs. Our evasion attack utilizes a long short-term memory (LSTM) deep neural network (DNN) which is trained to learn the time differences between the target network's benign packets. The trained LSTM is used to set the time differences between the malicious traffic packets (attack), without changing their content, such that they will "behave" like benign network traffic and will not be detected as an intrusion. We evaluate TANTRA on eight common intrusion attacks and three state-of-the-art NIDS systems, achieving an average success rate of 99.99\% in network intrusion detection system evasion. We also propose a novel mitigation technique to address this new evasion attack.

</p>
</details>

<details><summary><b>Semi-Discrete Optimal Transport: Hardness, Regularization and Numerical Solution</b>
<a href="https://arxiv.org/abs/2103.06263">arxiv:2103.06263</a>
&#x1F4C8; 3 <br>
<p>Bahar Taskesen, Soroosh Shafieezadeh-Abadeh, Daniel Kuhn</p></summary>
<p>

**Abstract:** Semi-discrete optimal transport problems, which evaluate the Wasserstein distance between a discrete and a generic (possibly non-discrete) probability measure, are believed to be computationally hard. Even though such problems are ubiquitous in statistics, machine learning and computer vision, however, this perception has not yet received a theoretical justification. To fill this gap, we prove that computing the Wasserstein distance between a discrete probability measure supported on two points and the Lebesgue measure on the standard hypercube is already #P-hard. This insight prompts us to seek approximate solutions for semi-discrete optimal transport problems. We thus perturb the underlying transportation cost with an additive disturbance governed by an ambiguous probability distribution, and we introduce a distributionally robust dual optimal transport problem whose objective function is smoothed with the most adverse disturbance distributions from within a given ambiguity set. We further show that smoothing the dual objective function is equivalent to regularizing the primal objective function, and we identify several ambiguity sets that give rise to several known and new regularization schemes. As a byproduct, we discover an intimate relation between semi-discrete optimal transport problems and discrete choice models traditionally studied in psychology and economics. To solve the regularized optimal transport problems efficiently, we use a stochastic gradient descent algorithm with imprecise stochastic gradient oracles. A new convergence analysis reveals that this algorithm improves the best known convergence guarantee for semi-discrete optimal transport problems with entropic regularizers.

</p>
</details>

<details><summary><b>Multi-Class Multiple Instance Learning for Predicting Precursors to Aviation Safety Events</b>
<a href="https://arxiv.org/abs/2103.06244">arxiv:2103.06244</a>
&#x1F4C8; 3 <br>
<p>Marc-Henri Bleu-Laine, Tejas G. Puranik, Dimitri N. Mavris, Bryan Matthews</p></summary>
<p>

**Abstract:** In recent years, there has been a rapid growth in the application of machine learning techniques that leverage aviation data collected from commercial airline operations to improve safety. Anomaly detection and predictive maintenance have been the main targets for machine learning applications. However, this paper focuses on the identification of precursors, which is a relatively newer application. Precursors are events correlated with adverse events that happen prior to the adverse event itself. Therefore, precursor mining provides many benefits including understanding the reasons behind a safety incident and the ability to identify signatures, which can be tracked throughout a flight to alert the operators of the potential for an adverse event in the future. This work proposes using the multiple-instance learning (MIL) framework, a weakly supervised learning task, combined with carefully designed binary classifier leveraging a Multi-Head Convolutional Neural Network-Recurrent Neural Network (MHCNN-RNN) architecture. Multi-class classifiers are then created and compared, enabling the prediction of different adverse events for any given flight by combining binary classifiers, and by modifying the MHCNN-RNN to handle multiple outputs. Results obtained showed that the multiple binary classifiers perform better and are able to accurately forecast high speed and high path angle events during the approach phase. Multiple binary classifiers are also capable of determining the aircraft's parameters that are correlated to these events. The identified parameters can be considered precursors to the events and may be studied/tracked further to prevent these events in the future.

</p>
</details>

<details><summary><b>A Deep Learning approach to Reduced Order Modelling of Parameter Dependent Partial Differential Equations</b>
<a href="https://arxiv.org/abs/2103.06183">arxiv:2103.06183</a>
&#x1F4C8; 3 <br>
<p>Nicola R. Franco, Andrea Manzoni, Paolo Zunino</p></summary>
<p>

**Abstract:** Within the framework of parameter dependent PDEs, we develop a constructive approach based on Deep Neural Networks for the efficient approximation of the parameter-to-solution map. The research is motivated by the limitations and drawbacks of state-of-the-art algorithms, such as the Reduced Basis method, when addressing problems that show a slow decay in the Kolmogorov n-width. Our work is based on the use of deep autoencoders, which we employ for encoding and decoding a high fidelity approximation of the solution manifold. In order to fully exploit the approximation capabilities of neural networks, we consider a nonlinear version of the Kolmogorov n-width over which we base the concept of a minimal latent dimension. We show that this minimal dimension is intimately related to the topological properties of the solution manifold, and we provide some theoretical results with particular emphasis on second order elliptic PDEs. Finally, we report numerical experiments where we compare the proposed approach with classical POD-Galerkin reduced order models. In particular, we consider parametrized advection-diffusion PDEs, and we test the methodology in the presence of strong transport fields, singular terms and stochastic coefficients.

</p>
</details>

<details><summary><b>An Image-based Approach of Task-driven Driving Scene Categorization</b>
<a href="https://arxiv.org/abs/2103.05920">arxiv:2103.05920</a>
&#x1F4C8; 3 <br>
<p>Shaochi Hu, Hanwei Fan, Biao Gao,  XijunZhao, Huijing Zhao</p></summary>
<p>

**Abstract:** Categorizing driving scenes via visual perception is a key technology for safe driving and the downstream tasks of autonomous vehicles.
  Traditional methods infer scene category by detecting scene-related objects or using a classifier that is trained on large datasets of fine-labeled scene images.
  Whereas at cluttered dynamic scenes such as campus or park, human activities are not strongly confined by rules, and the functional attributes of places are not strongly correlated with objects. So how to define, model and infer scene categories is crucial to make the technique really helpful in assisting a robot to pass through the scene.
  This paper proposes a method of task-driven driving scene categorization using weakly supervised data.
  Given a front-view video of a driving scene, a set of anchor points is marked by following the decision making of a human driver, where an anchor point is not a semantic label but an indicator meaning the semantic attribute of the scene is different from that of the previous one.
  A measure is learned to discriminate the scenes of different semantic attributes via contrastive learning, and a driving scene profiling and categorization method is developed based on that measure.
  Experiments are conducted on a front-view video that is recorded when a vehicle passed through the cluttered dynamic campus of Peking University. The scenes are categorized into straight road, turn road and alerting traffic. The results of semantic scene similarity learning and driving scene categorization are extensively studied, and positive result of scene categorization is 97.17 \% on the learning video and 85.44\% on the video of new scenes.

</p>
</details>

<details><summary><b>Learning a Domain-Agnostic Visual Representation for Autonomous Driving via Contrastive Loss</b>
<a href="https://arxiv.org/abs/2103.05902">arxiv:2103.05902</a>
&#x1F4C8; 3 <br>
<p>Dongseok Shim, H. Jin Kim</p></summary>
<p>

**Abstract:** Deep neural networks have been widely studied in autonomous driving applications such as semantic segmentation or depth estimation. However, training a neural network in a supervised manner requires a large amount of annotated labels which are expensive and time-consuming to collect. Recent studies leverage synthetic data collected from a virtual environment which are much easier to acquire and more accurate compared to data from the real world, but they usually suffer from poor generalization due to the inherent domain shift problem. In this paper, we propose a Domain-Agnostic Contrastive Learning (DACL) which is a two-stage unsupervised domain adaptation framework with cyclic adversarial training and contrastive loss. DACL leads the neural network to learn domain-agnostic representation to overcome performance degradation when there exists a difference between training and test data distribution. Our proposed approach achieves better performance in the monocular depth estimation task compared to previous state-of-the-art methods and also shows effectiveness in the semantic segmentation task.

</p>
</details>

<details><summary><b>Linear Constraints Learning for Spiking Neurons</b>
<a href="https://arxiv.org/abs/2103.12564">arxiv:2103.12564</a>
&#x1F4C8; 2 <br>
<p>Huy Le Nguyen, Dominique Chu</p></summary>
<p>

**Abstract:** We introduce a new supervised learning algorithm based to train spiking neural networks for classification. The algorithm overcomes a limitation of existing multi-spike learning methods: it solves the problem of interference between interacting output spikes during a learning trial. This problem of learning interference causes learning performance in existing approaches to decrease as the number of output spikes increases, and represents an important limitation in existing multi-spike learning approaches. We address learning interference by introducing a novel mechanism to balance the magnitudes of weight adjustments during learning, which in theory allows every spike to simultaneously converge to their desired timings. Our results indicate that our method achieves significantly higher memory capacity and faster convergence compared to existing approaches for multi-spike classification. In the ubiquitous Iris and MNIST datasets, our algorithm achieves competitive predictive performance with state-of-the-art approaches.

</p>
</details>

<details><summary><b>Rapid parameter estimation of discrete decaying signals using autoencoder networks</b>
<a href="https://arxiv.org/abs/2103.08663">arxiv:2103.08663</a>
&#x1F4C8; 2 <br>
<p>Jim C. Visschers, Dmitry Budker, Lykourgos Bougas</p></summary>
<p>

**Abstract:** In this work we demonstrate the use of neural networks for rapid extraction of signal parameters of discretely sampled signals. In particular, we use dense autoencoder networks to extract the parameters of interest from exponentially decaying signals and decaying oscillations. By using a three-stage training method and careful choice of the neural network size, we are able to retrieve the relevant signal parameters directly from the latent space of the autoencoder network at significantly improved rates compared to traditional algorithmic signal-analysis approaches. We show that the achievable precision and accuracy of this method of analysis is similar to conventional algorithm-based signal analysis methods, by demonstrating that the extracted signal parameters are approaching their fundamental parameter estimation limit as provided by the Cramér-Rao bound. Furthermore, we demonstrate that autoencoder networks are able to achieve signal analysis, and, hence, parameter extraction, at rates of 75 kHz, orders-of-magnitude faster than conventional techniques with similar precision. Finally, we explore the limitations of our approach, demonstrating that analysis rates of $>$200 kHz are feasible with further optimization of the transfer rate between the data-acquisition system and data-analysis system.

</p>
</details>

<details><summary><b>EmoNet: A Transfer Learning Framework for Multi-Corpus Speech Emotion Recognition</b>
<a href="https://arxiv.org/abs/2103.08310">arxiv:2103.08310</a>
&#x1F4C8; 2 <br>
<p>Maurice Gerczuk, Shahin Amiriparian, Sandra Ottl, Björn Schuller</p></summary>
<p>

**Abstract:** In this manuscript, the topic of multi-corpus Speech Emotion Recognition (SER) is approached from a deep transfer learning perspective. A large corpus of emotional speech data, EmoSet, is assembled from a number of existing SER corpora. In total, EmoSet contains 84181 audio recordings from 26 SER corpora with a total duration of over 65 hours. The corpus is then utilised to create a novel framework for multi-corpus speech emotion recognition, namely EmoNet. A combination of a deep ResNet architecture and residual adapters is transferred from the field of multi-domain visual recognition to multi-corpus SER on EmoSet. Compared against two suitable baselines and more traditional training and transfer settings for the ResNet, the residual adapter approach enables parameter efficient training of a multi-domain SER model on all 26 corpora. A shared model with only $3.5$ times the number of parameters of a model trained on a single database leads to increased performance for 21 of the 26 corpora in EmoSet. Measured by McNemar's test, these improvements are further significant for ten datasets at $p<0.05$ while there are just two corpora that see only significant decreases across the residual adapter transfer experiments. Finally, we make our EmoNet framework publicly available for users and developers at https://github.com/EIHW/EmoNet. EmoNet provides an extensive command line interface which is comprehensively documented and can be used in a variety of multi-corpus transfer learning settings.

</p>
</details>

<details><summary><b>PatchNet -- Short-range Template Matching for Efficient Video Processing</b>
<a href="https://arxiv.org/abs/2103.07371">arxiv:2103.07371</a>
&#x1F4C8; 2 <br>
<p>Huizi Mao, Sibo Zhu, Song Han, William J. Dally</p></summary>
<p>

**Abstract:** Object recognition is a fundamental problem in many video processing tasks, accurately locating seen objects at low computation cost paves the way for on-device video recognition. We propose PatchNet, an efficient convolutional neural network to match objects in adjacent video frames. It learns the patchwise correlation features instead of pixel features. PatchNet is very compact, running at just 58MFLOPs, $5\times$ simpler than MobileNetV2. We demonstrate its application on two tasks, video object detection and visual object tracking. On ImageNet VID, PatchNet reduces the flops of R-FCN ResNet-101 by 5x and EfficientDet-D0 by 3.4x with less than 1% mAP loss. On OTB2015, PatchNet reduces SiamFC and SiamRPN by 2.5x with no accuracy loss. Experiments on Jetson Nano further demonstrate 2.8x to 4.3x speed-ups associated with flops reduction. Code is open sourced at https://github.com/RalphMao/PatchNet.

</p>
</details>

<details><summary><b>Towards Multi-Sense Cross-Lingual Alignment of Contextual Embeddings</b>
<a href="https://arxiv.org/abs/2103.06459">arxiv:2103.06459</a>
&#x1F4C8; 2 <br>
<p>Linlin Liu, Thien Hai Nguyen, Shafiq Joty, Lidong Bing, Luo Si</p></summary>
<p>

**Abstract:** Cross-lingual word embeddings (CLWE) have been proven useful in many cross-lingual tasks. However, most existing approaches to learn CLWE including the ones with contextual embeddings are sense agnostic. In this work, we propose a novel framework to align contextual embeddings at the sense level by leveraging cross-lingual signal from bilingual dictionaries only. We operationalize our framework by first proposing a novel sense-aware cross entropy loss to model word senses explicitly. The monolingual ELMo and BERT models pretrained with our sense-aware cross entropy loss demonstrate significant performance improvement for word sense disambiguation tasks. We then propose a sense alignment objective on top of the sense-aware cross entropy loss for cross-lingual model pretraining, and pretrain cross-lingual models for several language pairs (English to German/Spanish/Japanese/Chinese). Compared with the best baseline results, our cross-lingual models achieve 0.52%, 2.09% and 1.29% average performance improvements on zero-shot cross-lingual NER, sentiment classification and XNLI tasks, respectively.

</p>
</details>

<details><summary><b>Hierarchical Bayesian Model for the Transfer of Knowledge on Spatial Concepts based on Multimodal Information</b>
<a href="https://arxiv.org/abs/2103.06442">arxiv:2103.06442</a>
&#x1F4C8; 2 <br>
<p>Yoshinobu Hagiwara, Keishiro Taguchi, Satoshi Ishibushi, Akira Taniguchi, Tadahiro Taniguchi</p></summary>
<p>

**Abstract:** This paper proposes a hierarchical Bayesian model based on spatial concepts that enables a robot to transfer the knowledge of places from experienced environments to a new environment. The transfer of knowledge based on spatial concepts is modeled as the calculation process of the posterior distribution based on the observations obtained in each environment with the parameters of spatial concepts generalized to environments as prior knowledge. We conducted experiments to evaluate the generalization performance of spatial knowledge for general places such as kitchens and the adaptive performance of spatial knowledge for unique places such as `Emma's room' in a new environment. In the experiments, the accuracies of the proposed method and conventional methods were compared in the prediction task of location names from an image and a position, and the prediction task of positions from a location name. The experimental results demonstrated that the proposed method has a higher prediction accuracy of location names and positions than the conventional method owing to the transfer of knowledge.

</p>
</details>

<details><summary><b>Covariate-assisted Sparse Tensor Completion</b>
<a href="https://arxiv.org/abs/2103.06428">arxiv:2103.06428</a>
&#x1F4C8; 2 <br>
<p>Hilda S Ibriga, Will Wei Sun</p></summary>
<p>

**Abstract:** We aim to provably complete a sparse and highly-missing tensor in the presence of covariate information along tensor modes. Our motivation comes from online advertising where users click-through-rates (CTR) on ads over various devices form a CTR tensor that has about 96% missing entries and has many zeros on non-missing entries, which makes the standalone tensor completion method unsatisfactory. Beside the CTR tensor, additional ad features or user characteristics are often available. In this paper, we propose Covariate-assisted Sparse Tensor Completion (COSTCO) to incorporate covariate information for the recovery of the sparse tensor. The key idea is to jointly extract latent components from both the tensor and the covariate matrix to learn a synthetic representation. Theoretically, we derive the error bound for the recovered tensor components and explicitly quantify the improvements on both the reveal probability condition and the tensor recovery accuracy due to covariates. Finally, we apply COSTCO to an advertisement dataset consisting of a CTR tensor and ad covariate matrix, leading to 23% accuracy improvement over the baseline. An important by-product is that ad latent components from COSTCO reveal interesting ad clusters, which are useful for better ad targeting.

</p>
</details>

<details><summary><b>Interpretable Data-driven Methods for Subgrid-scale Closure in LES for Transcritical LOX/GCH4 Combustion</b>
<a href="https://arxiv.org/abs/2103.06397">arxiv:2103.06397</a>
&#x1F4C8; 2 <br>
<p>Wai Tong Chung, Aashwin Ananda Mishra, Matthias Ihme</p></summary>
<p>

**Abstract:** Many practical combustion systems such as those in rockets, gas turbines, and internal combustion engines operate under high pressures that surpass the thermodynamic critical limit of fuel-oxidizer mixtures. These conditions require the consideration of complex fluid behaviors that pose challenges for numerical simulations, casting doubts on the validity of existing subgrid-scale (SGS) models in large-eddy simulations of these systems. While data-driven methods have shown high accuracy as closure models in simulations of turbulent flames, these models are often criticized for lack of physical interpretability, wherein they provide answers but no insight into their underlying rationale. The objective of this study is to assess SGS stress models from conventional physics-driven approaches and an interpretable machine learning algorithm, i.e., the random forest regressor, in a turbulent transcritical non-premixed flame. To this end, direct numerical simulations (DNS) of transcritical liquid-oxygen/gaseous-methane (LOX/GCH4) inert and reacting flows are performed. Using this data, a priori analysis is performed on the Favre-filtered DNS data to examine the accuracy of physics-based and random forest SGS-models under these conditions. SGS stresses calculated with the gradient model show good agreement with the exact terms extracted from filtered DNS. The accuracy of the random-forest regressor decreased when physics-based constraints are applied to the feature set. Results demonstrate that random forests can perform as effectively as algebraic models when modeling subgrid stresses, only when trained on a sufficiently representative database. The employment of random forest feature importance score is shown to provide insight into discovering subgrid-scale stresses through sparse regression.

</p>
</details>

<details><summary><b>Improving Context-Based Meta-Reinforcement Learning with Self-Supervised Trajectory Contrastive Learning</b>
<a href="https://arxiv.org/abs/2103.06386">arxiv:2103.06386</a>
&#x1F4C8; 2 <br>
<p>Bernie Wang, Simon Xu, Kurt Keutzer, Yang Gao, Bichen Wu</p></summary>
<p>

**Abstract:** Meta-reinforcement learning typically requires orders of magnitude more samples than single task reinforcement learning methods. This is because meta-training needs to deal with more diverse distributions and train extra components such as context encoders. To address this, we propose a novel self-supervised learning task, which we named Trajectory Contrastive Learning (TCL), to improve meta-training. TCL adopts contrastive learning and trains a context encoder to predict whether two transition windows are sampled from the same trajectory. TCL leverages the natural hierarchical structure of context-based meta-RL and makes minimal assumptions, allowing it to be generally applicable to context-based meta-RL algorithms. It accelerates the training of context encoders and improves meta-training overall. Experiments show that TCL performs better or comparably than a strong meta-RL baseline in most of the environments on both meta-RL MuJoCo (5 of 6) and Meta-World benchmarks (44 out of 50).

</p>
</details>

<details><summary><b>Automated liver tissues delineation based on machine learning techniques: A survey, current trends and future orientations</b>
<a href="https://arxiv.org/abs/2103.06384">arxiv:2103.06384</a>
&#x1F4C8; 2 <br>
<p>Ayman Al-Kababji, Faycal Bensaali, Sarada Prasad Dakua</p></summary>
<p>

**Abstract:** There is no denying how machine learning and computer vision have grown in the recent years. Their highest advantages lie within their automation, suitability, and ability to generate astounding results in a matter of seconds in a reproducible manner. This is aided by the ubiquitous advancements reached in the computing capabilities of current graphical processing units and the highly efficient implementation of such techniques. Hence, in this paper, we survey the key studies that are published between 2014 and 2020, showcasing the different machine learning algorithms researchers have used to segment the liver, hepatic-tumors, and hepatic-vasculature structures. We divide the surveyed studies based on the tissue of interest (hepatic-parenchyma, hepatic-tumors, or hepatic-vessels), highlighting the studies that tackle more than one task simultaneously. Additionally, the machine learning algorithms are classified as either supervised or unsupervised, and further partitioned if the amount of works that fall under a certain scheme is significant. Moreover, different datasets and challenges found in literature and websites, containing masks of the aforementioned tissues, are thoroughly discussed, highlighting the organizers original contributions, and those of other researchers. Also, the metrics that are used excessively in literature are mentioned in our review stressing their relevancy to the task at hand. Finally, critical challenges and future directions are emphasized for innovative researchers to tackle, exposing gaps that need addressing such as the scarcity of many studies on the vessels segmentation challenge, and why their absence needs to be dealt with in an accelerated manner.

</p>
</details>

<details><summary><b>Advancing Trajectory Optimization with Approximate Inference: Exploration, Covariance Control and Adaptive Risk</b>
<a href="https://arxiv.org/abs/2103.06319">arxiv:2103.06319</a>
&#x1F4C8; 2 <br>
<p>Joe Watson, Jan Peters</p></summary>
<p>

**Abstract:** Discrete-time stochastic optimal control remains a challenging problem for general, nonlinear systems under significant uncertainty, with practical solvers typically relying on the certainty equivalence assumption, replanning and/or extensive regularization. Control as inference is an approach that frames stochastic control as an equivalent inference problem, and has demonstrated desirable qualities over existing methods, namely in exploration and regularization. We look specifically at the input inference for control (i2c) algorithm, and derive three key characteristics that enable advanced trajectory optimization: An `expert' linear Gaussian controller that combines the benefits of open-loop optima and closed-loop variance reduction when optimizing for nonlinear systems, inherent adaptive risk sensitivity from the inference formulation, and covariance control functionality with only a minor algorithmic adjustment.

</p>
</details>

<details><summary><b>Symmetry Breaking in Symmetric Tensor Decomposition</b>
<a href="https://arxiv.org/abs/2103.06234">arxiv:2103.06234</a>
&#x1F4C8; 2 <br>
<p>Yossi Arjevani, Joan Bruna, Michael Field, Joe Kileel, Matthew Trager, Francis Williams</p></summary>
<p>

**Abstract:** In this note, we consider the optimization problem associated with computing the rank decomposition of a symmetric tensor. We show that, in a well-defined sense, minima in this highly nonconvex optimization problem break the symmetry of the target tensor -- but not too much. This phenomenon of symmetry breaking applies to various choices of tensor norms, and makes it possible to study the optimization landscape using a set of recently-developed symmetry-based analytical tools. The fact that the objective function under consideration is a multivariate polynomial allows us to apply symbolic methods from computational algebra to obtain more refined information on the symmetry breaking phenomenon.

</p>
</details>

<details><summary><b>Spatial Attention-based Non-reference Perceptual Quality Prediction Network for Omnidirectional Images</b>
<a href="https://arxiv.org/abs/2103.06116">arxiv:2103.06116</a>
&#x1F4C8; 2 <br>
<p>Li Yang, Mai Xu, Deng Xin, Bo Feng</p></summary>
<p>

**Abstract:** Due to the strong correlation between visual attention and perceptual quality, many methods attempt to use human saliency information for image quality assessment. Although this mechanism can get good performance, the networks require human saliency labels, which is not easily accessible for omnidirectional images (ODI). To alleviate this issue, we propose a spatial attention-based perceptual quality prediction network for non-reference quality assessment on ODIs (SAP-net). To drive our SAP-net, we establish a large-scale IQA dataset of ODIs (IQA-ODI), which is composed of subjective scores of 200 subjects on 1,080 ODIs. In IQA-ODI, there are 120 high quality ODIs as reference, and 960 ODIs with impairments in both JPEG compression and map projection. Without any human saliency labels, our network can adaptively estimate human perceptual quality on impaired ODIs through a self-attention manner, which significantly promotes the prediction performance of quality scores. Moreover, our method greatly reduces the computational complexity in quality assessment task on ODIs. Extensive experiments validate that our network outperforms 9 state-of-the-art methods for quality assessment on ODIs. The dataset and code have been available on \url{ https://github.com/yanglixiaoshen/SAP-Net}.

</p>
</details>

<details><summary><b>Oversampling errors in multimodal medical imaging are due to the Gibbs effect</b>
<a href="https://arxiv.org/abs/2103.05964">arxiv:2103.05964</a>
&#x1F4C8; 2 <br>
<p>Davide Poggiali, Diego Cecchin, Cristina Campi, Stefano De Marchi</p></summary>
<p>

**Abstract:** To analyse multimodal 3-dimensional medical images, interpolation is required for resampling which - unavoidably - introduces an interpolation error. In this work we consider three segmented 3-dimensional images resampled with three different neuroimaging software tools for comparing undersampling and oversampling strategies and to identify where the oversampling error lies. The results indicate that undersampling to the lowest image size is advantageous in terms of mean value per segment errors and that the oversampling error is larger where the gradient is steeper, showing a Gibbs effect.

</p>
</details>

<details><summary><b>Mean-field methods and algorithmic perspectives for high-dimensional machine learning</b>
<a href="https://arxiv.org/abs/2103.05945">arxiv:2103.05945</a>
&#x1F4C8; 2 <br>
<p>Benjamin Aubin</p></summary>
<p>

**Abstract:** The main difficulty that arises in the analysis of most machine learning algorithms is to handle, analytically and numerically, a large number of interacting random variables. In this Ph.D manuscript, we revisit an approach based on the tools of statistical physics of disordered systems. Developed through a rich literature, they have been precisely designed to infer the macroscopic behavior of a large number of particles from their microscopic interactions. At the heart of this work, we strongly capitalize on the deep connection between the replica method and message passing algorithms in order to shed light on the phase diagrams of various theoretical models, with an emphasis on the potential differences between statistical and algorithmic thresholds. We essentially focus on synthetic tasks and data generated in the teacher-student paradigm. In particular, we apply these mean-field methods to the Bayes-optimal analysis of committee machines, to the worst-case analysis of Rademacher generalization bounds for perceptrons, and to empirical risk minimization in the context of generalized linear models. Finally, we develop a framework to analyze estimation models with structured prior informations, produced for instance by deep neural networks based generative models with random weights.

</p>
</details>

<details><summary><b>Deep Sensing of Urban Waterlogging</b>
<a href="https://arxiv.org/abs/2103.05927">arxiv:2103.05927</a>
&#x1F4C8; 2 <br>
<p>Shi-Wei Lo, Jyh-Horng Wu, Jo-Yu Chang, Chien-Hao Tseng, Meng-Wei Lin, Fang-Pang Lin</p></summary>
<p>

**Abstract:** In the monsoon season, sudden flood events occur frequently in urban areas, which hamper the social and economic activities and may threaten the infrastructure and lives. The use of an efficient large-scale waterlogging sensing and information system can provide valuable real-time disaster information to facilitate disaster management and enhance awareness of the general public to alleviate losses during and after flood disasters. Therefore, in this study, a visual sensing approach driven by deep neural networks and information and communication technology was developed to provide an end-to-end mechanism to realize waterlogging sensing and event-location mapping. The use of a deep sensing system in the monsoon season in Taiwan was demonstrated, and waterlogging events were predicted on the island-wide scale. The system could sense approximately 2379 vision sources through an internet of video things framework and transmit the event-location information in 5 min. The proposed approach can sense waterlogging events at a national scale and provide an efficient and highly scalable alternative to conventional waterlogging sensing methods.

</p>
</details>

<details><summary><b>RL-CSDia: Representation Learning of Computer Science Diagrams</b>
<a href="https://arxiv.org/abs/2103.05900">arxiv:2103.05900</a>
&#x1F4C8; 2 <br>
<p>Shaowei Wang, LingLing Zhang, Xuan Luo, Yi Yang, Xin Hu, Jun Liu</p></summary>
<p>

**Abstract:** Recent studies on computer vision mainly focus on natural images that express real-world scenes. They achieve outstanding performance on diverse tasks such as visual question answering. Diagram is a special form of visual expression that frequently appears in the education field and is of great significance for learners to understand multimodal knowledge. Current research on diagrams preliminarily focuses on natural disciplines such as Biology and Geography, whose expressions are still similar to natural images. Another type of diagrams such as from Computer Science is composed of graphics containing complex topologies and relations, and research on this type of diagrams is still blank. The main challenges of graphic diagrams understanding are the rarity of data and the confusion of semantics, which are mainly reflected in the diversity of expressions. In this paper, we construct a novel dataset of graphic diagrams named Computer Science Diagrams (CSDia). It contains more than 1,200 diagrams and exhaustive annotations of objects and relations. Considering the visual noises caused by the various expressions in diagrams, we introduce the topology of diagrams to parse topological structure. After that, we propose Diagram Parsing Net (DPN) to represent the diagram from three branches: topology, visual feature, and text, and apply the model to the diagram classification task to evaluate the ability of diagrams understanding. The results show the effectiveness of the proposed DPN on diagrams understanding.

</p>
</details>

<details><summary><b>Streaming Linear System Identification with Reverse Experience Replay</b>
<a href="https://arxiv.org/abs/2103.05896">arxiv:2103.05896</a>
&#x1F4C8; 2 <br>
<p>Prateek Jain, Suhas S Kowshik, Dheeraj Nagaraj, Praneeth Netrapalli</p></summary>
<p>

**Abstract:** We consider the problem of estimating a linear time-invariant (LTI) dynamical system from a single trajectory via streaming algorithms, which is encountered in several applications including reinforcement learning (RL) and time-series analysis. While the LTI system estimation problem is well-studied in the {\em offline} setting, the practically important streaming/online setting has received little attention. Standard streaming methods like stochastic gradient descent (SGD) are unlikely to work since streaming points can be highly correlated. In this work, we propose a novel streaming algorithm, SGD with Reverse Experience Replay ($\mathsf{SGD}-\mathsf{RER}$), that is inspired by the experience replay (ER) technique popular in the RL literature. $\mathsf{SGD}-\mathsf{RER}$ divides data into small buffers and runs SGD backwards on the data stored in the individual buffers. We show that this algorithm exactly deconstructs the dependency structure and obtains information theoretically optimal guarantees for both parameter error and prediction error. Thus, we provide the first -- to the best of our knowledge -- optimal SGD-style algorithm for the classical problem of linear system identification with a first order oracle. Furthermore, $\mathsf{SGD}-\mathsf{RER}$ can be applied to more general settings like sparse LTI identification with known sparsity pattern, and non-linear dynamical systems. Our work demonstrates that the knowledge of data dependency structure can aid us in designing statistically and computationally efficient algorithms which can "decorrelate" streaming samples.

</p>
</details>

<details><summary><b>An IoT-Based Framework for Remote Fall Monitoring</b>
<a href="https://arxiv.org/abs/2105.09461">arxiv:2105.09461</a>
&#x1F4C8; 1 <br>
<p>Ayman Al-Kababji, Abbes Amira, Faycal Bensaali, Abdulah Jarouf, Lisan Shidqi, Hamza Djelouat</p></summary>
<p>

**Abstract:** Fall detection is a serious healthcare issue that needs to be solved. Falling without quick medical intervention would lower the chances of survival for the elderly, especially if living alone. Hence, the need is there for developing fall detection algorithms with high accuracy. This paper presents a novel IoT-based system for fall detection that includes a sensing device transmitting data to a mobile application through a cloud-connected gateway device. Then, the focus is shifted to the algorithmic aspect where multiple features are extracted from 3-axis accelerometer data taken from existing datasets. The results emphasize on the significance of Continuous Wavelet Transform (CWT) as an influential feature for determining falls. CWT, Signal Energy (SE), Signal Magnitude Area (SMA), and Signal Vector Magnitude (SVM) features have shown promising classification results using K-Nearest Neighbors (KNN) and E-Nearest Neighbors (ENN). For all performance metrics (accuracy, recall, precision, specificity, and F1 Score), the achieved results are higher than 95% for a dataset of small size, while more than 98.47% score is achieved in the aforementioned criteria over the UniMiB-SHAR dataset by the same algorithms, where the classification time for a single test record is extremely efficient and is real-time

</p>
</details>

<details><summary><b>Energy Decay Network (EDeN)</b>
<a href="https://arxiv.org/abs/2103.15552">arxiv:2103.15552</a>
&#x1F4C8; 1 <br>
<p>Jamie Nicholas Shelley, Optishell Consultancy</p></summary>
<p>

**Abstract:** This paper and accompanying Python and C++ Framework is the product of the authors perceived problems with narrow (Discrimination based) AI. (Artificial Intelligence) The Framework attempts to develop a genetic transfer of experience through potential structural expressions using a common regulation/exchange value (energy) to create a model whereby neural architecture and all unit processes are co-dependently developed by genetic and real time signal processing influences; successful routes are defined by stability of the spike distribution per epoch which is influenced by genetically encoded morphological development biases.These principles are aimed towards creating a diverse and robust network that is capable of adapting to general tasks by training within a simulation designed for transfer learning to other mediums at scale.

</p>
</details>

<details><summary><b>Disentangled Representation Learning for Astronomical Chemical Tagging</b>
<a href="https://arxiv.org/abs/2103.06377">arxiv:2103.06377</a>
&#x1F4C8; 1 <br>
<p>Damien de Mijolla, Melissa Ness, Serena Viti, Adam Wheeler</p></summary>
<p>

**Abstract:** Modern astronomical surveys are observing spectral data for millions of stars. These spectra contain chemical information that can be used to trace the Galaxy's formation and chemical enrichment history. However, extracting the information from spectra, and making precise and accurate chemical abundance measurements are challenging. Here, we present a data-driven method for isolating the chemical factors of variation in stellar spectra from those of other parameters (i.e. \teff, \logg, \feh). This enables us to build a spectral projection for each star with these parameters removed. We do this with no ab initio knowledge of elemental abundances themselves, and hence bypass the uncertainties and systematics associated with modeling that rely on synthetic stellar spectra. To remove known non-chemical factors of variation, we develop and implement a neural network architecture that learns a disentangled spectral representation. We simulate our recovery of chemically identical stars using the disentangled spectra in a synthetic APOGEE-like dataset. We show that this recovery declines as a function of the signal to noise ratio, but that our neural network architecture outperforms simpler modeling choices. Our work demonstrates the feasibility of data-driven abundance-free chemical tagging.

</p>
</details>

<details><summary><b>Functional Collection Programming with Semi-Ring Dictionaries</b>
<a href="https://arxiv.org/abs/2103.06376">arxiv:2103.06376</a>
&#x1F4C8; 1 <br>
<p>Amir Shaikhha, Mathieu Huot, Jaclyn Smith, Dan Olteanu</p></summary>
<p>

**Abstract:** This paper introduces semi-ring dictionaries, a powerful class of compositional and purely functional collections that subsume other collection types such as sets, multisets, arrays, vectors, and matrices. We developed SDQL, a statically typed language that can express relational algebra with aggregations, linear algebra, and functional collections over data such as relations and matrices using semi-ring dictionaries. Furthermore, thanks to the algebraic structure behind these dictionaries, SDQL unifies a wide range of optimizations commonly used in databases (DB) and linear algebra (LA). As a result, SDQL enables efficient processing of hybrid DB and LA workloads, by putting together optimizations that are otherwise confined to either DB systems or LA frameworks. We show experimentally that a handful of DB and LA workloads can take advantage of the SDQL language and optimizations. Overall, we observe that SDQL achieves competitive performance relative to Typer and Tectorwise, which are state-of-the-art in-memory DB systems for (flat, not nested) relational data, and achieves an average 2x speedup over SciPy for LA workloads. For hybrid workloads involving LA processing, SDQL achieves up to one order of magnitude speedup over Trance, a state-of-the-art nested relational engine for nested biomedical data, and gives an average 40% speedup over LMFAO, a state-of-the-art in-DB machine learning engine for two (flat) relational real-world retail datasets.

</p>
</details>

<details><summary><b>Majority Voting with Bidirectional Pre-translation For Bitext Retrieval</b>
<a href="https://arxiv.org/abs/2103.06369">arxiv:2103.06369</a>
&#x1F4C8; 1 <br>
<p>Alex Jones, Derry Tanti Wijaya</p></summary>
<p>

**Abstract:** Obtaining high-quality parallel corpora is of paramount importance for training NMT systems. However, as many language pairs lack adequate gold-standard training data, a popular approach has been to mine so-called "pseudo-parallel" sentences from paired documents in two languages. In this paper, we outline some problems with current methods, propose computationally economical solutions to those problems, and demonstrate success with novel methods on the Tatoeba similarity search benchmark and on a downstream task, namely NMT. We uncover the effect of resource-related factors (i.e. how much monolingual/bilingual data is available for a given language) on the optimal choice of bitext mining approach, and echo problems with the oft-used BUCC dataset that have been observed by others. We make the code and data used for our experiments publicly available.

</p>
</details>

<details><summary><b>Enhancing VMAF through New Feature Integration and Model Combination</b>
<a href="https://arxiv.org/abs/2103.06338">arxiv:2103.06338</a>
&#x1F4C8; 1 <br>
<p>Fan Zhang, Angeliki Katsenou, Christos Bampis, Lukas Krasula, Zhi Li, David Bull</p></summary>
<p>

**Abstract:** VMAF is a machine learning based video quality assessment method, originally designed for streaming applications, which combines multiple quality metrics and video features through SVM regression. It offers higher correlation with subjective opinions compared to many conventional quality assessment methods. In this paper we propose enhancements to VMAF through the integration of new video features and alternative quality metrics (selected from a diverse pool) alongside multiple model combination. The proposed combination approach enables training on multiple databases with varying content and distortion characteristics. Our enhanced VMAF method has been evaluated on eight HD video databases, and consistently outperforms the original VMAF model (0.6.1) and other benchmark quality metrics, exhibiting higher correlation with subjective ground truth data.

</p>
</details>

<details><summary><b>Learning-Based Vulnerability Analysis of Cyber-Physical Systems</b>
<a href="https://arxiv.org/abs/2103.06271">arxiv:2103.06271</a>
&#x1F4C8; 1 <br>
<p>Amir Khazraei, Spencer Hallyburton, Qitong Gao, Yu Wang, Miroslav Pajic</p></summary>
<p>

**Abstract:** This work focuses on the use of deep learning for vulnerability analysis of cyber-physical systems (CPS). Specifically, we consider a control architecture widely used in CPS (e.g., robotics), where the low-level control is based on e.g., the extended Kalman filter (EKF) and an anomaly detector. To facilitate analyzing the impact potential sensing attacks could have, our objective is to develop learning-enabled attack generators capable of designing stealthy attacks that maximally degrade system operation. We show how such problem can be cast within a learning-based grey-box framework where parts of the runtime information are known to the attacker, and introduce two models based on feed-forward neural networks (FNN); both models are trained offline, using a cost function that combines the attack effects on the estimation error and the residual signal used for anomaly detection, so that the trained models are capable of recursively generating such effective sensor attacks in real-time. The effectiveness of the proposed methods is illustrated on several case studies.

</p>
</details>

<details><summary><b>Impacts of the Numbers of Colors and Shapes on Outlier Detection: from Automated to User Evaluation</b>
<a href="https://arxiv.org/abs/2103.06084">arxiv:2103.06084</a>
&#x1F4C8; 1 <br>
<p>Loann Giovannangeli, Romain Giot, David Auber, Romain Bourqui</p></summary>
<p>

**Abstract:** The design of efficient representations is well established as a fruitful way to explore and analyze complex or large data. In these representations, data are encoded with various visual attributes depending on the needs of the representation itself. To make coherent design choices about visual attributes, the visual search field proposes guidelines based on the human brain perception of features. However, information visualization representations frequently need to depict more data than the amount these guidelines have been validated on. Since, the information visualization community has extended these guidelines to a wider parameter space.
  This paper contributes to this theme by extending visual search theories to an information visualization context. We consider a visual search task where subjects are asked to find an unknown outlier in a grid of randomly laid out distractor. Stimuli are defined by color and shape features for the purpose of visually encoding categorical data. The experimental protocol is made of a parameters space reduction step (i.e., sub-sampling) based on a machine learning model, and a user evaluation to measure capacity limits and validate hypotheses. The results show that the major difficulty factor is the number of visual attributes that are used to encode the outlier. When redundantly encoded, the display heterogeneity has no effect on the task. When encoded with one attribute, the difficulty depends on that attribute heterogeneity until its capacity limit (7 for color, 5 for shape) is reached. Finally, when encoded with two attributes simultaneously, performances drop drastically even with minor heterogeneity.

</p>
</details>

<details><summary><b>Improving Sequential Recommendation with Attribute-augmented Graph Neural Networks</b>
<a href="https://arxiv.org/abs/2103.05923">arxiv:2103.05923</a>
&#x1F4C8; 1 <br>
<p>Xinzhou Dong, Beihong Jin, Wei Zhuo, Beibei Li, Taofeng Xue</p></summary>
<p>

**Abstract:** Many practical recommender systems provide item recommendation for different users only via mining user-item interactions but totally ignoring the rich attribute information of items that users interact with. In this paper, we propose an attribute-augmented graph neural network model named Murzim. Murzim takes as input the graphs constructed from the user-item interaction sequences and corresponding item attribute sequences. By combining the GNNs with node aggregation and an attention network, Murzim can capture user preference patterns, generate embeddings for user-item interaction sequences, and then generate recommendations through next-item prediction. We conduct extensive experiments on multiple datasets. Experimental results show that Murzim outperforms several state-of-the-art methods in terms of recall and MRR, which illustrates that Murzim can make use of item attribute information to produce better recommendations. At present, Murzim has been deployed in MX Player, one of India's largest streaming platforms, and is recommending videos for tens of thousands of users.

</p>
</details>

<details><summary><b>SocialInteractionGAN: Multi-person Interaction Sequence Generation</b>
<a href="https://arxiv.org/abs/2103.05916">arxiv:2103.05916</a>
&#x1F4C8; 1 <br>
<p>Louis Airale, Dominique Vaufreydaz, Xavier Alameda-Pineda</p></summary>
<p>

**Abstract:** Prediction of human actions in social interactions has important applications in the design of social robots or artificial avatars. In this paper, we model human interaction generation as a discrete multi-sequence generation problem and present SocialInteractionGAN, a novel adversarial architecture for conditional interaction generation. Our model builds on a recurrent encoder-decoder generator network and a dual-stream discriminator. This architecture allows the discriminator to jointly assess the realism of interactions and that of individual action sequences. Within each stream a recurrent network operating on short subsequences endows the output signal with local assessments, better guiding the forthcoming generation. Crucially, contextual information on interacting participants is shared among agents and reinjected in both the generation and the discriminator evaluation processes. We show that the proposed SocialInteractionGAN succeeds in producing high realism action sequences of interacting people, comparing favorably to a diversity of recurrent and convolutional discriminator baselines. Evaluations are conducted using modified Inception Score and Fr{é}chet Inception Distance metrics, that we specifically design for discrete sequential generated data. The distribution of generated sequences is shown to approach closely that of real data. In particular our model properly learns the dynamics of interaction sequences, while exploiting the full range of actions.

</p>
</details>

<details><summary><b>VideoMoCo: Contrastive Video Representation Learning with Temporally Adversarial Examples</b>
<a href="https://arxiv.org/abs/2103.05905">arxiv:2103.05905</a>
&#x1F4C8; 1 <br>
<p>Tian Pan, Yibing Song, Tianyu Yang, Wenhao Jiang, Wei Liu</p></summary>
<p>

**Abstract:** MoCo is effective for unsupervised image representation learning. In this paper, we propose VideoMoCo for unsupervised video representation learning. Given a video sequence as an input sample, we improve the temporal feature representations of MoCo from two perspectives. First, we introduce a generator to drop out several frames from this sample temporally. The discriminator is then learned to encode similar feature representations regardless of frame removals. By adaptively dropping out different frames during training iterations of adversarial learning, we augment this input sample to train a temporally robust encoder. Second, we use temporal decay to model key attenuation in the memory queue when computing the contrastive loss. As the momentum encoder updates after keys enqueue, the representation ability of these keys degrades when we use the current input sample for contrastive learning. This degradation is reflected via temporal decay to attend the input sample to recent keys in the queue. As a result, we adapt MoCo to learn video representations without empirically designing pretext tasks. By empowering the temporal robustness of the encoder and modeling the temporal decay of the keys, our VideoMoCo improves MoCo temporally based on contrastive learning. Experiments on benchmark datasets including UCF101 and HMDB51 show that VideoMoCo stands as a state-of-the-art video representation learning method.

</p>
</details>

<details><summary><b>Optimal Targeting in Fundraising: A Causal Machine-Learning Approach</b>
<a href="https://arxiv.org/abs/2103.10251">arxiv:2103.10251</a>
&#x1F4C8; 0 <br>
<p>Tobias Cagala, Ulrich Glogowsky, Johannes Rincke, Anthony Strittmatter</p></summary>
<p>

**Abstract:** Ineffective fundraising lowers the resources charities can use to provide goods. We combine a field experiment and a causal machine-learning approach to increase a charity's fundraising effectiveness. The approach optimally targets a fundraising instrument to individuals whose expected donations exceed solicitation costs. Our results demonstrate that machine-learning-based optimal targeting allows the charity to substantially increase donations net of fundraising costs relative to uniform benchmarks in which either everybody or no one receives the gift. To that end, it (a) should direct its fundraising efforts to a subset of past donors and (b) never address individuals who were previously asked but never donated. Further, we show that the benefits of machine-learning-based optimal targeting even materialize when the charity only exploits publicly available geospatial information or applies the estimated optimal targeting rule to later fundraising campaigns conducted in similar samples. We conclude that charities not engaging in optimal targeting waste significant resources.

</p>
</details>

<details><summary><b>SAR-U-Net: squeeze-and-excitation block and atrous spatial pyramid pooling based residual U-Net for automatic liver segmentation in Computed Tomography</b>
<a href="https://arxiv.org/abs/2103.06419">arxiv:2103.06419</a>
&#x1F4C8; 0 <br>
<p>Jinke Wang, Peiqing Lv, Haiying Wang, Changfa Shi</p></summary>
<p>

**Abstract:** Background and objective: In this paper, a modified U-Net based framework is presented, which leverages techniques from Squeeze-and-Excitation (SE) block, Atrous Spatial Pyramid Pooling (ASPP) and residual learning for accurate and robust liver CT segmentation, and the effectiveness of the proposed method was tested on two public datasets LiTS17 and SLiver07.
  Methods: A new network architecture called SAR-U-Net was designed. Firstly, the SE block is introduced to adaptively extract image features after each convolution in the U-Net encoder, while suppressing irrelevant regions, and highlighting features of specific segmentation task; Secondly, ASPP was employed to replace the transition layer and the output layer, and acquire multi-scale image information via different receptive fields. Thirdly, to alleviate the degradation problem, the traditional convolution block was replaced with the residual block and thus prompt the network to gain accuracy from considerably increased depth.
  Results: In the LiTS17 experiment, the mean values of Dice, VOE, RVD, ASD and MSD were 95.71, 9.52, -0.84, 1.54 and 29.14, respectively. Compared with other closely related 2D-based models, the proposed method achieved the highest accuracy. In the experiment of the SLiver07, the mean values of Dice, VOE, RVD, ASD and MSD were 97.31, 5.37, -1.08, 1.85 and 27.45, respectively. Compared with other closely related models, the proposed method achieved the highest segmentation accuracy except for the RVD.
  Conclusion: The proposed model enables a great improvement on the accuracy compared to 2D-based models, and its robustness in circumvent challenging problems, such as small liver regions, discontinuous liver regions, and fuzzy liver boundaries, is also well demonstrated and validated.

</p>
</details>

<details><summary><b>Affine-Mapping based Variational Ensemble Kalman Filter</b>
<a href="https://arxiv.org/abs/2103.06315">arxiv:2103.06315</a>
&#x1F4C8; 0 <br>
<p>Linjie Wen, Jinglai Li</p></summary>
<p>

**Abstract:** We propose an affine-mapping based variational Ensemble Kalman filter for sequential Bayesian filtering problems with generic observation models. Specifically, the proposed method is formulated as to construct an affine mapping from the prior ensemble to the posterior one, and the affine mapping is computed via a variational Bayesian formulation, i.e., by minimizing the Kullback-Leibler divergence between the transformed distribution through the affine mapping and the actual posterior. Some theoretical properties of resulting optimization problem are studied and a gradient descent scheme is proposed to solve the resulting optimization problem. With numerical examples we demonstrate that the method has competitive performance against existing methods.

</p>
</details>

<details><summary><b>Why flatness does and does not correlate with generalization for deep neural networks</b>
<a href="https://arxiv.org/abs/2103.06219">arxiv:2103.06219</a>
&#x1F4C8; 0 <br>
<p>Shuofeng Zhang, Isaac Reid, Guillermo Valle Pérez, Ard Louis</p></summary>
<p>

**Abstract:** The intuition that local flatness of the loss landscape is correlated with better generalization for deep neural networks (DNNs) has been explored for decades, spawning many different flatness measures. Recently, this link with generalization has been called into question by a demonstration that many measures of flatness are vulnerable to parameter re-scaling which arbitrarily changes their value without changing neural network outputs.
  Here we show that, in addition, some popular variants of SGD such as Adam and Entropy-SGD, can also break the flatness-generalization correlation. As an alternative to flatness measures, we use a function based picture and propose using the log of Bayesian prior upon initialization, $\log P(f)$, as a predictor of the generalization when a DNN converges on function $f$ after training to zero error. The prior is directly proportional to the Bayesian posterior for functions that give zero error on a test set. For the case of image classification, we show that $\log P(f)$ is a significantly more robust predictor of generalization than flatness measures are.
  Whilst local flatness measures fail under parameter re-scaling, the prior/posterior, which is global quantity, remains invariant under re-scaling. Moreover, the correlation with generalization as a function of data complexity remains good for different variants of SGD.

</p>
</details>

<details><summary><b>Towards automated brain aneurysm detection in TOF-MRA: open data, weak labels, and anatomical knowledge</b>
<a href="https://arxiv.org/abs/2103.06168">arxiv:2103.06168</a>
&#x1F4C8; 0 <br>
<p>Tommaso Di Noto, Guillaume Marie, Sebastien Tourbier, Yasser Alemán-Gómez, Oscar Esteban, Guillaume Saliou, Meritxell Bach Cuadra, Patric Hagmann, Jonas Richiardi</p></summary>
<p>

**Abstract:** Brain aneurysm detection in Time-Of-Flight Magnetic Resonance Angiography (TOF-MRA) has undergone drastic improvements with the advent of Deep Learning (DL). However, performances of supervised DL models heavily rely on the quantity of labeled samples. To mitigate the recurrent bottleneck of voxel-wise label creation, we investigate the use of weak labels: these are oversized annotations which are considerably faster to create. We present a deep learning algorithm for aneurysm detection that exploits weak labels during training. In addition, our model leverages prior anatomical knowledge by focusing only on plausible locations for aneurysm occurrence. We created a retrospective dataset of 284 TOF-MRA subjects (170 females) out of which 157 are patients (with 198 aneurysms), and 127 are controls. Our open TOF-MRA dataset, the largest in the community, is released on OpenNEURO. To assess model generalizability, we participated in a challenge for aneurysm detection with TOF-MRA data (93 patients, 20 controls, 125 aneurysms). Weak labels were 4 times faster to generate than their voxel-wise counterparts. When using prior anatomical knowledge, our network achieved a sensitivity of 80% on the in-house data, with False Positive (FP) rate of 1.2 per patient. On the public challenge, sensitivity was 68% (FP rate = 2.5), ranking 4th/18 on the open leaderboard. We found no significant difference in sensitivity between aneurysm risk-of-rupture groups (p = 0.75), locations (p = 0.72), or sizes (p = 0.15). Our code is made available for reproducibility.

</p>
</details>


[Next Page]({{ '/2021/03/09/2021.03.09.html' | relative_url }})
