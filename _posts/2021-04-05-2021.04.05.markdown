## Summary for 2021-04-05, created on 2021-12-22


<details><summary><b>SpeechStew: Simply Mix All Available Speech Recognition Data to Train One Large Neural Network</b>
<a href="https://arxiv.org/abs/2104.02133">arxiv:2104.02133</a>
&#x1F4C8; 44 <br>
<p>William Chan, Daniel Park, Chris Lee, Yu Zhang, Quoc Le, Mohammad Norouzi</p></summary>
<p>

**Abstract:** We present SpeechStew, a speech recognition model that is trained on a combination of various publicly available speech recognition datasets: AMI, Broadcast News, Common Voice, LibriSpeech, Switchboard/Fisher, Tedlium, and Wall Street Journal. SpeechStew simply mixes all of these datasets together, without any special re-weighting or re-balancing of the datasets. SpeechStew achieves SoTA or near SoTA results across a variety of tasks, without the use of an external language model. Our results include 9.0\% WER on AMI-IHM, 4.7\% WER on Switchboard, 8.3\% WER on CallHome, and 1.3\% on WSJ, which significantly outperforms prior work with strong external language models. We also demonstrate that SpeechStew learns powerful transfer learning representations. We fine-tune SpeechStew on a noisy low resource speech dataset, CHiME-6. We achieve 38.9\% WER without a language model, which compares to 38.6\% WER to a strong HMM baseline with a language model.

</p>
</details>

<details><summary><b>AST: Audio Spectrogram Transformer</b>
<a href="https://arxiv.org/abs/2104.01778">arxiv:2104.01778</a>
&#x1F4C8; 35 <br>
<p>Yuan Gong, Yu-An Chung, James Glass</p></summary>
<p>

**Abstract:** In the past decade, convolutional neural networks (CNNs) have been widely adopted as the main building block for end-to-end audio classification models, which aim to learn a direct mapping from audio spectrograms to corresponding labels. To better capture long-range global context, a recent trend is to add a self-attention mechanism on top of the CNN, forming a CNN-attention hybrid model. However, it is unclear whether the reliance on a CNN is necessary, and if neural networks purely based on attention are sufficient to obtain good performance in audio classification. In this paper, we answer the question by introducing the Audio Spectrogram Transformer (AST), the first convolution-free, purely attention-based model for audio classification. We evaluate AST on various audio classification benchmarks, where it achieves new state-of-the-art results of 0.485 mAP on AudioSet, 95.6% accuracy on ESC-50, and 98.1% accuracy on Speech Commands V2.

</p>
</details>

<details><summary><b>AMP: Adversarial Motion Priors for Stylized Physics-Based Character Control</b>
<a href="https://arxiv.org/abs/2104.02180">arxiv:2104.02180</a>
&#x1F4C8; 28 <br>
<p>Xue Bin Peng, Ze Ma, Pieter Abbeel, Sergey Levine, Angjoo Kanazawa</p></summary>
<p>

**Abstract:** Synthesizing graceful and life-like behaviors for physically simulated characters has been a fundamental challenge in computer animation. Data-driven methods that leverage motion tracking are a prominent class of techniques for producing high fidelity motions for a wide range of behaviors. However, the effectiveness of these tracking-based methods often hinges on carefully designed objective functions, and when applied to large and diverse motion datasets, these methods require significant additional machinery to select the appropriate motion for the character to track in a given scenario. In this work, we propose to obviate the need to manually design imitation objectives and mechanisms for motion selection by utilizing a fully automated approach based on adversarial imitation learning. High-level task objectives that the character should perform can be specified by relatively simple reward functions, while the low-level style of the character's behaviors can be specified by a dataset of unstructured motion clips, without any explicit clip selection or sequencing. These motion clips are used to train an adversarial motion prior, which specifies style-rewards for training the character through reinforcement learning (RL). The adversarial RL procedure automatically selects which motion to perform, dynamically interpolating and generalizing from the dataset. Our system produces high-quality motions that are comparable to those achieved by state-of-the-art tracking-based techniques, while also being able to easily accommodate large datasets of unstructured motion clips. Composition of disparate skills emerges automatically from the motion prior, without requiring a high-level motion planner or other task-specific annotations of the motion clips. We demonstrate the effectiveness of our framework on a diverse cast of complex simulated characters and a challenging suite of motor control tasks.

</p>
</details>

<details><summary><b>GPU Domain Specialization via Composable On-Package Architecture</b>
<a href="https://arxiv.org/abs/2104.02188">arxiv:2104.02188</a>
&#x1F4C8; 23 <br>
<p>Yaosheng Fu, Evgeny Bolotin, Niladrish Chatterjee, David Nellans, Stephen W. Keckler</p></summary>
<p>

**Abstract:** As GPUs scale their low precision matrix math throughput to boost deep learning (DL) performance, they upset the balance between math throughput and memory system capabilities. We demonstrate that converged GPU design trying to address diverging architectural requirements between FP32 (or larger) based HPC and FP16 (or smaller) based DL workloads results in sub-optimal configuration for either of the application domains. We argue that a Composable On-PAckage GPU (COPAGPU) architecture to provide domain-specialized GPU products is the most practical solution to these diverging requirements. A COPA-GPU leverages multi-chip-module disaggregation to support maximal design reuse, along with memory system specialization per application domain. We show how a COPA-GPU enables DL-specialized products by modular augmentation of the baseline GPU architecture with up to 4x higher off-die bandwidth, 32x larger on-package cache, 2.3x higher DRAM bandwidth and capacity, while conveniently supporting scaled-down HPC-oriented designs. This work explores the microarchitectural design necessary to enable composable GPUs and evaluates the benefits composability can provide to HPC, DL training, and DL inference. We show that when compared to a converged GPU design, a DL-optimized COPA-GPU featuring a combination of 16x larger cache capacity and 1.6x higher DRAM bandwidth scales per-GPU training and inference performance by 31% and 35% respectively and reduces the number of GPU instances by 50% in scale-out training scenarios.

</p>
</details>

<details><summary><b>Domain Generalization with MixStyle</b>
<a href="https://arxiv.org/abs/2104.02008">arxiv:2104.02008</a>
&#x1F4C8; 17 <br>
<p>Kaiyang Zhou, Yongxin Yang, Yu Qiao, Tao Xiang</p></summary>
<p>

**Abstract:** Though convolutional neural networks (CNNs) have demonstrated remarkable ability in learning discriminative features, they often generalize poorly to unseen domains. Domain generalization aims to address this problem by learning from a set of source domains a model that is generalizable to any unseen domain. In this paper, a novel approach is proposed based on probabilistically mixing instance-level feature statistics of training samples across source domains. Our method, termed MixStyle, is motivated by the observation that visual domain is closely related to image style (e.g., photo vs.~sketch images). Such style information is captured by the bottom layers of a CNN where our proposed style-mixing takes place. Mixing styles of training instances results in novel domains being synthesized implicitly, which increase the domain diversity of the source domains, and hence the generalizability of the trained model. MixStyle fits into mini-batch training perfectly and is extremely easy to implement. The effectiveness of MixStyle is demonstrated on a wide range of tasks including category classification, instance retrieval and reinforcement learning.

</p>
</details>

<details><summary><b>When Pigs Fly: Contextual Reasoning in Synthetic and Natural Scenes</b>
<a href="https://arxiv.org/abs/2104.02215">arxiv:2104.02215</a>
&#x1F4C8; 10 <br>
<p>Philipp Bomatter, Mengmi Zhang, Dimitar Karev, Spandan Madan, Claire Tseng, Gabriel Kreiman</p></summary>
<p>

**Abstract:** Context is of fundamental importance to both human and machine vision; e.g., an object in the air is more likely to be an airplane than a pig. The rich notion of context incorporates several aspects including physics rules, statistical co-occurrences, and relative object sizes, among others. While previous work has focused on crowd-sourced out-of-context photographs from the web to study scene context, controlling the nature and extent of contextual violations has been a daunting task. Here we introduce a diverse, synthetic Out-of-Context Dataset (OCD) with fine-grained control over scene context. By leveraging a 3D simulation engine, we systematically control the gravity, object co-occurrences and relative sizes across 36 object categories in a virtual household environment. We conducted a series of experiments to gain insights into the impact of contextual cues on both human and machine vision using OCD. We conducted psychophysics experiments to establish a human benchmark for out-of-context recognition, and then compared it with state-of-the-art computer vision models to quantify the gap between the two. We propose a context-aware recognition transformer model, fusing object and contextual information via multi-head attention. Our model captures useful information for contextual reasoning, enabling human-level performance and better robustness in out-of-context conditions compared to baseline models across OCD and other out-of-context datasets. All source code and data are publicly available at https://github.com/kreimanlab/WhenPigsFlyContext

</p>
</details>

<details><summary><b>Automated Performance Testing Based on Active Deep Learning</b>
<a href="https://arxiv.org/abs/2104.02102">arxiv:2104.02102</a>
&#x1F4C8; 10 <br>
<p>Ali Sedaghatbaf, Mahshid Helali Moghadam, Mehrdad Saadatmand</p></summary>
<p>

**Abstract:** Generating tests that can reveal performance issues in large and complex software systems within a reasonable amount of time is a challenging task. On one hand, there are numerous combinations of input data values to explore. On the other hand, we have a limited test budget to execute tests. What makes this task even more difficult is the lack of access to source code and the internal details of these systems. In this paper, we present an automated test generation method called ACTA for black-box performance testing. ACTA is based on active learning, which means that it does not require a large set of historical test data to learn about the performance characteristics of the system under test. Instead, it dynamically chooses the tests to execute using uncertainty sampling. ACTA relies on a conditional variant of generative adversarial networks,and facilitates specifying performance requirements in terms of conditions and generating tests that address those conditions.We have evaluated ACTA on a benchmark web application, and the experimental results indicate that this method is comparable with random testing, and two other machine learning methods,i.e. PerfXRL and DN.

</p>
</details>

<details><summary><b>Rethinking Perturbations in Encoder-Decoders for Fast Training</b>
<a href="https://arxiv.org/abs/2104.01853">arxiv:2104.01853</a>
&#x1F4C8; 10 <br>
<p>Sho Takase, Shun Kiyono</p></summary>
<p>

**Abstract:** We often use perturbations to regularize neural models. For neural encoder-decoders, previous studies applied the scheduled sampling (Bengio et al., 2015) and adversarial perturbations (Sato et al., 2019) as perturbations but these methods require considerable computational time. Thus, this study addresses the question of whether these approaches are efficient enough for training time. We compare several perturbations in sequence-to-sequence problems with respect to computational time. Experimental results show that the simple techniques such as word dropout (Gal and Ghahramani, 2016) and random replacement of input tokens achieve comparable (or better) scores to the recently proposed perturbations, even though these simple methods are faster. Our code is publicly available at https://github.com/takase/rethink_perturbations.

</p>
</details>

<details><summary><b>Dr-Vectors: Decision Residual Networks and an Improved Loss for Speaker Recognition</b>
<a href="https://arxiv.org/abs/2104.01989">arxiv:2104.01989</a>
&#x1F4C8; 9 <br>
<p>Jason Pelecanos, Quan Wang, Ignacio Lopez Moreno</p></summary>
<p>

**Abstract:** Many neural network speaker recognition systems model each speaker using a fixed-dimensional embedding vector. These embeddings are generally compared using either linear or 2nd-order scoring and, until recently, do not handle utterance-specific uncertainty. In this work we propose scoring these representations in a way that can capture uncertainty, enroll/test asymmetry and additional non-linear information. This is achieved by incorporating a 2nd-stage neural network (known as a decision network) as part of an end-to-end training regimen. In particular, we propose the concept of decision residual networks which involves the use of a compact decision network to leverage cosine scores and to model the residual signal that's needed. Additionally, we present a modification to the generalized end-to-end softmax loss function to target the separation of same/different speaker scores. We observed significant performance gains for the two techniques.

</p>
</details>

<details><summary><b>Talk, Don't Write: A Study of Direct Speech-Based Image Retrieval</b>
<a href="https://arxiv.org/abs/2104.01894">arxiv:2104.01894</a>
&#x1F4C8; 9 <br>
<p>Ramon Sanabria, Austin Waters, Jason Baldridge</p></summary>
<p>

**Abstract:** Speech-based image retrieval has been studied as a proxy for joint representation learning, usually without emphasis on retrieval itself. As such, it is unclear how well speech-based retrieval can work in practice -- both in an absolute sense and versus alternative strategies that combine automatic speech recognition (ASR) with strong text encoders. In this work, we extensively study and expand choices of encoder architectures, training methodology (including unimodal and multimodal pretraining), and other factors. Our experiments cover different types of speech in three datasets: Flickr Audio, Places Audio, and Localized Narratives. Our best model configuration achieves large gains over state of the art, e.g., pushing recall-at-one from 21.8% to 33.2% for Flickr Audio and 27.6% to 53.4% for Places Audio. We also show our best speech-based models can match or exceed cascaded ASR-to-text encoding when speech is spontaneous, accented, or otherwise hard to automatically transcribe.

</p>
</details>

<details><summary><b>A Concise Review of Transfer Learning</b>
<a href="https://arxiv.org/abs/2104.02144">arxiv:2104.02144</a>
&#x1F4C8; 8 <br>
<p>Abolfazl Farahani, Behrouz Pourshojae, Khaled Rasheed, Hamid R. Arabnia</p></summary>
<p>

**Abstract:** The availability of abundant labeled data in recent years led the researchers to introduce a methodology called transfer learning, which utilizes existing data in situations where there are difficulties in collecting new annotated data. Transfer learning aims to boost the performance of a target learner by applying another related source data. In contrast to the traditional machine learning and data mining techniques, which assume that the training and testing data lie from the same feature space and distribution, transfer learning can handle situations where there is a discrepancy between domains and distributions. These characteristics give the model the potential to utilize the available related source data and extend the underlying knowledge to the target task achieving better performance. This survey paper aims to give a concise review of traditional and current transfer learning settings, existing challenges, and related approaches.

</p>
</details>

<details><summary><b>An Empirical Study of Training Self-Supervised Vision Transformers</b>
<a href="https://arxiv.org/abs/2104.02057">arxiv:2104.02057</a>
&#x1F4C8; 8 <br>
<p>Xinlei Chen, Saining Xie, Kaiming He</p></summary>
<p>

**Abstract:** This paper does not describe a novel method. Instead, it studies a straightforward, incremental, yet must-know baseline given the recent progress in computer vision: self-supervised learning for Vision Transformers (ViT). While the training recipes for standard convolutional networks have been highly mature and robust, the recipes for ViT are yet to be built, especially in the self-supervised scenarios where training becomes more challenging. In this work, we go back to basics and investigate the effects of several fundamental components for training self-supervised ViT. We observe that instability is a major issue that degrades accuracy, and it can be hidden by apparently good results. We reveal that these results are indeed partial failure, and they can be improved when training is made more stable. We benchmark ViT results in MoCo v3 and several other self-supervised frameworks, with ablations in various aspects. We discuss the currently positive evidence as well as challenges and open questions. We hope that this work will provide useful data points and experience for future research.

</p>
</details>

<details><summary><b>Generating Furry Cars: Disentangling Object Shape & Appearance across Multiple Domains</b>
<a href="https://arxiv.org/abs/2104.02052">arxiv:2104.02052</a>
&#x1F4C8; 8 <br>
<p>Utkarsh Ojha, Krishna Kumar Singh, Yong Jae Lee</p></summary>
<p>

**Abstract:** We consider the novel task of learning disentangled representations of object shape and appearance across multiple domains (e.g., dogs and cars). The goal is to learn a generative model that learns an intermediate distribution, which borrows a subset of properties from each domain, enabling the generation of images that did not exist in any domain exclusively. This challenging problem requires an accurate disentanglement of object shape, appearance, and background from each domain, so that the appearance and shape factors from the two domains can be interchanged. We augment an existing approach that can disentangle factors within a single domain but struggles to do so across domains. Our key technical contribution is to represent object appearance with a differentiable histogram of visual features, and to optimize the generator so that two images with the same latent appearance factor but different latent shape factors produce similar histograms. On multiple multi-domain datasets, we demonstrate our method leads to accurate and consistent appearance and shape transfer across domains.

</p>
</details>

<details><summary><b>Jekyll: Attacking Medical Image Diagnostics using Deep Generative Models</b>
<a href="https://arxiv.org/abs/2104.02107">arxiv:2104.02107</a>
&#x1F4C8; 7 <br>
<p>Neal Mangaokar, Jiameng Pu, Parantapa Bhattacharya, Chandan K. Reddy, Bimal Viswanath</p></summary>
<p>

**Abstract:** Advances in deep neural networks (DNNs) have shown tremendous promise in the medical domain. However, the deep learning tools that are helping the domain, can also be used against it. Given the prevalence of fraud in the healthcare domain, it is important to consider the adversarial use of DNNs in manipulating sensitive data that is crucial to patient healthcare. In this work, we present the design and implementation of a DNN-based image translation attack on biomedical imagery. More specifically, we propose Jekyll, a neural style transfer framework that takes as input a biomedical image of a patient and translates it to a new image that indicates an attacker-chosen disease condition. The potential for fraudulent claims based on such generated 'fake' medical images is significant, and we demonstrate successful attacks on both X-rays and retinal fundus image modalities. We show that these attacks manage to mislead both medical professionals and algorithmic detection schemes. Lastly, we also investigate defensive measures based on machine learning to detect images generated by Jekyll.

</p>
</details>

<details><summary><b>Unsupervised Multi-source Domain Adaptation Without Access to Source Data</b>
<a href="https://arxiv.org/abs/2104.01845">arxiv:2104.01845</a>
&#x1F4C8; 7 <br>
<p>Sk Miraj Ahmed, Dripta S. Raychaudhuri, Sujoy Paul, Samet Oymak, Amit K. Roy-Chowdhury</p></summary>
<p>

**Abstract:** Unsupervised Domain Adaptation (UDA) aims to learn a predictor model for an unlabeled domain by transferring knowledge from a separate labeled source domain. However, most of these conventional UDA approaches make the strong assumption of having access to the source data during training, which may not be very practical due to privacy, security and storage concerns. A recent line of work addressed this problem and proposed an algorithm that transfers knowledge to the unlabeled target domain from a single source model without requiring access to the source data. However, for adaptation purposes, if there are multiple trained source models available to choose from, this method has to go through adapting each and every model individually, to check for the best source. Thus, we ask the question: can we find the optimal combination of source models, with no source data and without target labels, whose performance is no worse than the single best source? To answer this, we propose a novel and efficient algorithm which automatically combines the source models with suitable weights in such a way that it performs at least as good as the best source model. We provide intuitive theoretical insights to justify our claim. Furthermore, extensive experiments are conducted on several benchmark datasets to show the effectiveness of our algorithm, where in most cases, our method not only reaches best source accuracy but also outperforms it.

</p>
</details>

<details><summary><b>In-Line Image Transformations for Imbalanced, Multiclass Computer Vision Classification of Lung Chest X-Rays</b>
<a href="https://arxiv.org/abs/2104.02238">arxiv:2104.02238</a>
&#x1F4C8; 5 <br>
<p>Alexandrea K. Ramnarine</p></summary>
<p>

**Abstract:** Artificial intelligence (AI) is disrupting the medical field as advances in modern technology allow common household computers to learn anatomical and pathological features that distinguish between healthy and disease with the accuracy of highly specialized, trained physicians. Computer vision AI applications use medical imaging, such as lung chest X-Rays (LCXRs), to facilitate diagnoses by providing second-opinions in addition to a physician's or radiologist's interpretation. Considering the advent of the current Coronavirus disease (COVID-19) pandemic, LCXRs may provide rapid insights to indirectly aid in infection containment, however generating a reliably labeled image dataset for a novel disease is not an easy feat, nor is it of highest priority when combating a global pandemic. Deep learning techniques such as convolutional neural networks (CNNs) are able to select features that distinguish between healthy and disease states for other lung pathologies; this study aims to leverage that body of literature in order to apply image transformations that would serve to balance the lack of COVID-19 LCXR data. Furthermore, this study utilizes a simple CNN architecture for high-performance multiclass LCXR classification at 94 percent accuracy.

</p>
</details>

<details><summary><b>Uncertainty-Aware COVID-19 Detection from Imbalanced Sound Data</b>
<a href="https://arxiv.org/abs/2104.02005">arxiv:2104.02005</a>
&#x1F4C8; 5 <br>
<p>Tong Xia, Jing Han, Lorena Qendro, Ting Dang, Cecilia Mascolo</p></summary>
<p>

**Abstract:** Recently, sound-based COVID-19 detection studies have shown great promise to achieve scalable and prompt digital pre-screening. However, there are still two unsolved issues hindering the practice. First, collected datasets for model training are often imbalanced, with a considerably smaller proportion of users tested positive, making it harder to learn representative and robust features. Second, deep learning models are generally overconfident in their predictions. Clinically, false predictions aggravate healthcare costs. Estimation of the uncertainty of screening would aid this. To handle these issues, we propose an ensemble framework where multiple deep learning models for sound-based COVID-19 detection are developed from different but balanced subsets from original data. As such, data are utilized more effectively compared to traditional up-sampling and down-sampling approaches: an AUC of 0.74 with a sensitivity of 0.68 and a specificity of 0.69 is achieved. Simultaneously, we estimate uncertainty from the disagreement across multiple models. It is shown that false predictions often yield higher uncertainty, enabling us to suggest the users with certainty higher than a threshold to repeat the audio test on their phones or to take clinical tests if digital diagnosis still fails. This study paves the way for a more robust sound-based COVID-19 automated screening system.

</p>
</details>

<details><summary><b>Probabilistic Programming Bots in Intuitive Physics Game Play</b>
<a href="https://arxiv.org/abs/2104.01980">arxiv:2104.01980</a>
&#x1F4C8; 5 <br>
<p>Fahad Alhasoun, Sarah Alnegheimish, Joshua Tenenbaum</p></summary>
<p>

**Abstract:** Recent findings suggest that humans deploy cognitive mechanism of physics simulation engines to simulate the physics of objects. We propose a framework for bots to deploy probabilistic programming tools for interacting with intuitive physics environments. The framework employs a physics simulation in a probabilistic way to infer about moves performed by an agent in a setting governed by Newtonian laws of motion. However, methods of probabilistic programs can be slow in such setting due to their need to generate many samples. We complement the model with a model-free approach to aid the sampling procedures in becoming more efficient through learning from experience during game playing. We present an approach where combining model-free approaches (a convolutional neural network in our model) and model-based approaches (probabilistic physics simulation) is able to achieve what neither could alone. This way the model outperforms an all model-free or all model-based approach. We discuss a case study showing empirical results of the performance of the model on the game of Flappy Bird.

</p>
</details>

<details><summary><b>Financial Markets Prediction with Deep Learning</b>
<a href="https://arxiv.org/abs/2104.05413">arxiv:2104.05413</a>
&#x1F4C8; 4 <br>
<p>Jia Wang, Tong Sun, Benyuan Liu, Yu Cao, Degang Wang</p></summary>
<p>

**Abstract:** Financial markets are difficult to predict due to its complex systems dynamics. Although there have been some recent studies that use machine learning techniques for financial markets prediction, they do not offer satisfactory performance on financial returns. We propose a novel one-dimensional convolutional neural networks (CNN) model to predict financial market movement. The customized one-dimensional convolutional layers scan financial trading data through time, while different types of data, such as prices and volume, share parameters (kernels) with each other. Our model automatically extracts features instead of using traditional technical indicators and thus can avoid biases caused by selection of technical indicators and pre-defined coefficients in technical indicators. We evaluate the performance of our prediction model with strictly backtesting on historical trading data of six futures from January 2010 to October 2017. The experiment results show that our CNN model can effectively extract more generalized and informative features than traditional technical indicators, and achieves more robust and profitable financial performance than previous machine learning approaches.

</p>
</details>

<details><summary><b>Attribute-Based Robotic Grasping with One-Grasp Adaptation</b>
<a href="https://arxiv.org/abs/2104.02271">arxiv:2104.02271</a>
&#x1F4C8; 4 <br>
<p>Yang Yang, Yuanhao Liu, Hengyue Liang, Xibai Lou, Changhyun Choi</p></summary>
<p>

**Abstract:** Robotic grasping is one of the most fundamental robotic manipulation tasks and has been actively studied. However, how to quickly teach a robot to grasp a novel target object in clutter remains challenging. This paper attempts to tackle the challenge by leveraging object attributes that facilitate recognition, grasping, and quick adaptation. In this work, we introduce an end-to-end learning method of attribute-based robotic grasping with one-grasp adaptation capability. Our approach fuses the embeddings of a workspace image and a query text using a gated-attention mechanism and learns to predict instance grasping affordances. Besides, we utilize object persistence before and after grasping to learn a joint metric space of visual and textual attributes. Our model is self-supervised in a simulation that only uses basic objects of various colors and shapes but generalizes to novel objects and real-world scenes. We further demonstrate that our model is capable of adapting to novel objects with only one grasp data and improving instance grasping performance significantly. Experimental results in both simulation and the real world demonstrate that our approach achieves over 80\% instance grasping success rate on unknown objects, which outperforms several baselines by large margins.

</p>
</details>

<details><summary><b>Adaptive Clustering of Robust Semantic Representations for Adversarial Image Purification</b>
<a href="https://arxiv.org/abs/2104.02155">arxiv:2104.02155</a>
&#x1F4C8; 4 <br>
<p>Samuel Henrique Silva, Arun Das, Ian Scarff, Peyman Najafirad</p></summary>
<p>

**Abstract:** Deep Learning models are highly susceptible to adversarial manipulations that can lead to catastrophic consequences. One of the most effective methods to defend against such disturbances is adversarial training but at the cost of generalization of unseen attacks and transferability across models. In this paper, we propose a robust defense against adversarial attacks, which is model agnostic and generalizable to unseen adversaries. Initially, with a baseline model, we extract the latent representations for each class and adaptively cluster the latent representations that share a semantic similarity. We obtain the distributions for the clustered latent representations and from their originating images, we learn semantic reconstruction dictionaries (SRD). We adversarially train a new model constraining the latent space representation to minimize the distance between the adversarial latent representation and the true cluster distribution. To purify the image, we decompose the input into low and high-frequency components. The high-frequency component is reconstructed based on the most adequate SRD from the clean dataset. In order to evaluate the most adequate SRD, we rely on the distance between robust latent representations and semantic cluster distributions. The output is a purified image with no perturbation. Image purification on CIFAR-10 and ImageNet-10 using our proposed method improved the accuracy by more than 10% compared to state-of-the-art results.

</p>
</details>

<details><summary><b>Personalized Speech Enhancement through Self-Supervised Data Augmentation and Purification</b>
<a href="https://arxiv.org/abs/2104.02018">arxiv:2104.02018</a>
&#x1F4C8; 4 <br>
<p>Aswin Sivaraman, Sunwoo Kim, Minje Kim</p></summary>
<p>

**Abstract:** Training personalized speech enhancement models is innately a no-shot learning problem due to privacy constraints and limited access to noise-free speech from the target user. If there is an abundance of unlabeled noisy speech from the test-time user, a personalized speech enhancement model can be trained using self-supervised learning. One straightforward approach to model personalization is to use the target speaker's noisy recordings as pseudo-sources. Then, a pseudo denoising model learns to remove injected training noises and recover the pseudo-sources. However, this approach is volatile as it depends on the quality of the pseudo-sources, which may be too noisy. As a remedy, we propose an improvement to the self-supervised approach through data purification. We first train an SNR predictor model to estimate the frame-by-frame SNR of the pseudo-sources. Then, the predictor's estimates are converted into weights which adjust the frame-by-frame contribution of the pseudo-sources towards training the personalized model. We empirically show that the proposed data purification step improves the usability of the speaker-specific noisy data in the context of personalized speech enhancement. Without relying on any clean speech recordings or speaker embeddings, our approach may be seen as privacy-preserving.

</p>
</details>

<details><summary><b>Multilevel Stein variational gradient descent with applications to Bayesian inverse problems</b>
<a href="https://arxiv.org/abs/2104.01945">arxiv:2104.01945</a>
&#x1F4C8; 4 <br>
<p>Terrence Alsup, Luca Venturi, Benjamin Peherstorfer</p></summary>
<p>

**Abstract:** This work presents a multilevel variant of Stein variational gradient descent to more efficiently sample from target distributions. The key ingredient is a sequence of distributions with growing fidelity and costs that converges to the target distribution of interest. For example, such a sequence of distributions is given by a hierarchy of ever finer discretization levels of the forward model in Bayesian inverse problems. The proposed multilevel Stein variational gradient descent moves most of the iterations to lower, cheaper levels with the aim of requiring only a few iterations on the higher, more expensive levels when compared to the traditional, single-level Stein variational gradient descent variant that uses the highest-level distribution only. Under certain assumptions, in the mean-field limit, the error of the proposed multilevel Stein method decays by a log factor faster than the error of the single-level counterpart with respect to computational costs. Numerical experiments with Bayesian inverse problems show speedups of more than one order of magnitude of the proposed multilevel Stein method compared to the single-level variant that uses the highest level only.

</p>
</details>

<details><summary><b>Enabling Inference Privacy with Adaptive Noise Injection</b>
<a href="https://arxiv.org/abs/2104.02261">arxiv:2104.02261</a>
&#x1F4C8; 3 <br>
<p>Sanjay Kariyappa, Ousmane Dia, Moinuddin K Qureshi</p></summary>
<p>

**Abstract:** User-facing software services are becoming increasingly reliant on remote servers to host Deep Neural Network (DNN) models, which perform inference tasks for the clients. Such services require the client to send input data to the service provider, who processes it using a DNN and returns the output predictions to the client. Due to the rich nature of the inputs such as images and speech, the input often contains more information than what is necessary to perform the primary inference task. Consequently, in addition to the primary inference task, a malicious service provider could infer secondary (sensitive) attributes from the input, compromising the client's privacy. The goal of our work is to improve inference privacy by injecting noise to the input to hide the irrelevant features that are not conducive to the primary classification task. To this end, we propose Adaptive Noise Injection (ANI), which uses a light-weight DNN on the client-side to inject noise to each input, before transmitting it to the service provider to perform inference. Our key insight is that by customizing the noise to each input, we can achieve state-of-the-art trade-off between utility and privacy (up to 48.5% degradation in sensitive-task accuracy with <1% degradation in primary accuracy), significantly outperforming existing noise injection schemes. Our method does not require prior knowledge of the sensitive attributes and incurs minimal computational overheads.

</p>
</details>

<details><summary><b>Survey of Imbalanced Data Methodologies</b>
<a href="https://arxiv.org/abs/2104.02240">arxiv:2104.02240</a>
&#x1F4C8; 3 <br>
<p>Lian Yu, Nengfeng Zhou</p></summary>
<p>

**Abstract:** Imbalanced data set is a problem often found and well-studied in financial industry. In this paper, we reviewed and compared some popular methodologies handling data imbalance. We then applied the under-sampling/over-sampling methodologies to several modeling algorithms on UCI and Keel data sets. The performance was analyzed for class-imbalance methods, modeling algorithms and grid search criteria comparison.

</p>
</details>

<details><summary><b>Contextualized Streaming End-to-End Speech Recognition with Trie-Based Deep Biasing and Shallow Fusion</b>
<a href="https://arxiv.org/abs/2104.02194">arxiv:2104.02194</a>
&#x1F4C8; 3 <br>
<p>Duc Le, Mahaveer Jain, Gil Keren, Suyoun Kim, Yangyang Shi, Jay Mahadeokar, Julian Chan, Yuan Shangguan, Christian Fuegen, Ozlem Kalinli, Yatharth Saraf, Michael L. Seltzer</p></summary>
<p>

**Abstract:** How to leverage dynamic contextual information in end-to-end speech recognition has remained an active research area. Previous solutions to this problem were either designed for specialized use cases that did not generalize well to open-domain scenarios, did not scale to large biasing lists, or underperformed on rare long-tail words. We address these limitations by proposing a novel solution that combines shallow fusion, trie-based deep biasing, and neural network language model contextualization. These techniques result in significant 19.5% relative Word Error Rate improvement over existing contextual biasing approaches and 5.4%-9.3% improvement compared to a strong hybrid baseline on both open-domain and constrained contextualization tasks, where the targets consist of mostly rare long-tail words. Our final system remains lightweight and modular, allowing for quick modification without model re-training.

</p>
</details>

<details><summary><b>Insight about Detection, Prediction and Weather Impact of Coronavirus (Covid-19) using Neural Network</b>
<a href="https://arxiv.org/abs/2104.02173">arxiv:2104.02173</a>
&#x1F4C8; 3 <br>
<p>A K M Bahalul Haque, Tahmid Hasan Pranto, Abdulla All Noman, Atik Mahmood</p></summary>
<p>

**Abstract:** The world is facing a tough situation due to the catastrophic pandemic caused by novel coronavirus (COVID-19). The number people affected by this virus are increasing exponentially day by day and the number has already crossed 6.4 million. As no vaccine has been discovered yet, the early detection of patients and isolation is the only and most effective way to reduce the spread of the virus. Detecting infected persons from chest X-Ray by using Deep Neural Networks, can be applied as a time and laborsaving solution. In this study, we tried to detect Covid-19 by classification of Covid-19, pneumonia and normal chest X-Rays. We used five different Convolutional Pre-Trained Neural Network models (VGG16, VGG19, Xception, InceptionV3 and Resnet50) and compared their performance. VGG16 and VGG19 shows precise performance in classification. Both models can classify between three kinds of X-Rays with an accuracy over 92%. Another part of our study was to find the impact of weather factors (temperature, humidity, sun hour and wind speed) on this pandemic using Decision Tree Regressor. We found that temperature, humidity and sun-hour jointly hold 85.88% impact on escalation of Covid-19 and 91.89% impact on death due to Covid-19 where humidity has 8.09% impact on death. We also tried to predict the death of an individual based on age, gender, country, and location due to COVID-19 using the LogisticRegression, which can predict death of an individual with a model accuracy of 94.40%.

</p>
</details>

<details><summary><b>SpeakerStew: Scaling to Many Languages with a Triaged Multilingual Text-Dependent and Text-Independent Speaker Verification System</b>
<a href="https://arxiv.org/abs/2104.02125">arxiv:2104.02125</a>
&#x1F4C8; 3 <br>
<p>Roza Chojnacka, Jason Pelecanos, Quan Wang, Ignacio Lopez Moreno</p></summary>
<p>

**Abstract:** In this paper, we describe SpeakerStew - a hybrid system to perform speaker verification on 46 languages. Two core ideas were explored in this system: (1) Pooling training data of different languages together for multilingual generalization and reducing development cycles; (2) A novel triage mechanism between text-dependent and text-independent models to reduce runtime cost and expected latency. To the best of our knowledge, this is the first study of speaker verification systems at the scale of 46 languages. The problem is framed from the perspective of using a smart speaker device with interactions consisting of a wake-up keyword (text-dependent) followed by a speech query (text-independent). Experimental evidence suggests that training on multiple languages can generalize to unseen varieties while maintaining performance on seen varieties. We also found that it can reduce computational requirements for training models by an order of magnitude. Furthermore, during model inference on English data, we observe that leveraging a triage framework can reduce the number of calls to the more computationally expensive text-independent system by 73% (and reduce latency by 59%) while maintaining an EER no worse than the text-independent setup.

</p>
</details>

<details><summary><b>Discrete Reasoning Templates for Natural Language Understanding</b>
<a href="https://arxiv.org/abs/2104.02115">arxiv:2104.02115</a>
&#x1F4C8; 3 <br>
<p>Hadeel Al-Negheimish, Pranava Madhyastha, Alessandra Russo</p></summary>
<p>

**Abstract:** Reasoning about information from multiple parts of a passage to derive an answer is an open challenge for reading-comprehension models. In this paper, we present an approach that reasons about complex questions by decomposing them to simpler subquestions that can take advantage of single-span extraction reading-comprehension models, and derives the final answer according to instructions in a predefined reasoning template. We focus on subtraction-based arithmetic questions and evaluate our approach on a subset of the DROP dataset. We show that our approach is competitive with the state-of-the-art while being interpretable and requires little supervision

</p>
</details>

<details><summary><b>Rejoinder: Gaussian Differential Privacy</b>
<a href="https://arxiv.org/abs/2104.01987">arxiv:2104.01987</a>
&#x1F4C8; 3 <br>
<p>Jinshuo Dong, Aaron Roth, Weijie J. Su</p></summary>
<p>

**Abstract:** In this rejoinder, we aim to address two broad issues that cover most comments made in the discussion. First, we discuss some theoretical aspects of our work and comment on how this work might impact the theoretical foundation of privacy-preserving data analysis. Taking a practical viewpoint, we next discuss how f-differential privacy (f-DP) and Gaussian differential privacy (GDP) can make a difference in a range of applications.

</p>
</details>

<details><summary><b>Acted vs. Improvised: Domain Adaptation for Elicitation Approaches in Audio-Visual Emotion Recognition</b>
<a href="https://arxiv.org/abs/2104.01978">arxiv:2104.01978</a>
&#x1F4C8; 3 <br>
<p>Haoqi Li, Yelin Kim, Cheng-Hao Kuo, Shrikanth Narayanan</p></summary>
<p>

**Abstract:** Key challenges in developing generalized automatic emotion recognition systems include scarcity of labeled data and lack of gold-standard references. Even for the cues that are labeled as the same emotion category, the variability of associated expressions can be high depending on the elicitation context e.g., emotion elicited during improvised conversations vs. acted sessions with predefined scripts. In this work, we regard the emotion elicitation approach as domain knowledge, and explore domain transfer learning techniques on emotional utterances collected under different emotion elicitation approaches, particularly with limited labeled target samples. Our emotion recognition model combines the gradient reversal technique with an entropy loss function as well as the softlabel loss, and the experiment results show that domain transfer learning methods can be employed to alleviate the domain mismatch between different elicitation approaches. Our work provides new insights into emotion data collection, particularly the impact of its elicitation strategies, and the importance of domain adaptation in emotion recognition aiming for generalized systems.

</p>
</details>

<details><summary><b>FedPandemic: A Cross-Device Federated Learning Approach Towards Elementary Prognosis of Diseases During a Pandemic</b>
<a href="https://arxiv.org/abs/2104.01864">arxiv:2104.01864</a>
&#x1F4C8; 3 <br>
<p>Aman Priyanshu, Rakshit Naidu</p></summary>
<p>

**Abstract:** The amount of data, manpower and capital required to understand, evaluate and agree on a group of symptoms for the elementary prognosis of pandemic diseases is enormous. In this paper, we present FedPandemic, a novel noise implementation algorithm integrated with cross-device Federated learning for Elementary symptom prognosis during a pandemic, taking COVID-19 as a case study. Our results display consistency and enhance robustness in recovering the common symptoms displayed by the disease, paving a faster and cheaper path towards symptom retrieval while also preserving the privacy of patient's symptoms via Federated learning.

</p>
</details>

<details><summary><b>Stopping Criterion for Active Learning Based on Error Stability</b>
<a href="https://arxiv.org/abs/2104.01836">arxiv:2104.01836</a>
&#x1F4C8; 3 <br>
<p>Hideaki Ishibashi, Hideitsu Hino</p></summary>
<p>

**Abstract:** Active learning is a framework for supervised learning to improve the predictive performance by adaptively annotating a small number of samples. To realize efficient active learning, both an acquisition function that determines the next datum and a stopping criterion that determines when to stop learning should be considered. In this study, we propose a stopping criterion based on error stability, which guarantees that the change in generalization error upon adding a new sample is bounded by the annotation cost and can be applied to any Bayesian active learning. We demonstrate that the proposed criterion stops active learning at the appropriate timing for various learning models and real datasets.

</p>
</details>

<details><summary><b>Fast Design Space Exploration of Nonlinear Systems: Part II</b>
<a href="https://arxiv.org/abs/2104.02464">arxiv:2104.02464</a>
&#x1F4C8; 2 <br>
<p>Prerit Terway, Kenza Hamidouche, Niraj K. Jha</p></summary>
<p>

**Abstract:** Nonlinear system design is often a multi-objective optimization problem involving search for a design that satisfies a number of predefined constraints. The design space is typically very large since it includes all possible system architectures with different combinations of components composing each architecture. In this article, we address nonlinear system design space exploration through a two-step approach encapsulated in a framework called Fast Design Space Exploration of Nonlinear Systems (ASSENT). In the first step, we use a genetic algorithm to search for system architectures that allow discrete choices for component values or else only component values for a fixed architecture. This step yields a coarse design since the system may or may not meet the target specifications. In the second step, we use an inverse design to search over a continuous space and fine-tune the component values with the goal of improving the value of the objective function. We use a neural network to model the system response. The neural network is converted into a mixed-integer linear program for active learning to sample component values efficiently. We illustrate the efficacy of ASSENT on problems ranging from nonlinear system design to design of electrical circuits. Experimental results show that ASSENT achieves the same or better value of the objective function compared to various other optimization techniques for nonlinear system design by up to 54%. We improve sample efficiency by 6-10x compared to reinforcement learning based synthesis of electrical circuits.

</p>
</details>

<details><summary><b>A clinical validation of VinDr-CXR, an AI system for detecting abnormal chest radiographs</b>
<a href="https://arxiv.org/abs/2104.02256">arxiv:2104.02256</a>
&#x1F4C8; 2 <br>
<p>Ngoc Huy Nguyen, Ha Quy Nguyen, Nghia Trung Nguyen, Thang Viet Nguyen, Hieu Huy Pham, Tuan Ngoc-Minh Nguyen</p></summary>
<p>

**Abstract:** Computer-Aided Diagnosis (CAD) systems for chest radiographs using artificial intelligence (AI) have recently shown a great potential as a second opinion for radiologists. The performances of such systems, however, were mostly evaluated on a fixed dataset in a retrospective manner and, thus, far from the real performances in clinical practice. In this work, we demonstrate a mechanism for validating an AI-based system for detecting abnormalities on X-ray scans, VinDr-CXR, at the Phu Tho General Hospital - a provincial hospital in the North of Vietnam. The AI system was directly integrated into the Picture Archiving and Communication System (PACS) of the hospital after being trained on a fixed annotated dataset from other sources. The performance of the system was prospectively measured by matching and comparing the AI results with the radiology reports of 6,285 chest X-ray examinations extracted from the Hospital Information System (HIS) over the last two months of 2020. The normal/abnormal status of a radiology report was determined by a set of rules and served as the ground truth. Our system achieves an F1 score - the harmonic average of the recall and the precision - of 0.653 (95% CI 0.635, 0.671) for detecting any abnormalities on chest X-rays. Despite a significant drop from the in-lab performance, this result establishes a high level of confidence in applying such a system in real-life situations.

</p>
</details>

<details><summary><b>Multi-Scale Context Aggregation Network with Attention-Guided for Crowd Counting</b>
<a href="https://arxiv.org/abs/2104.02245">arxiv:2104.02245</a>
&#x1F4C8; 2 <br>
<p>Xin Wang, Yang Zhao, Tangwen Yang, Qiuqi Ruan</p></summary>
<p>

**Abstract:** Crowd counting aims to predict the number of people and generate the density map in the image. There are many challenges, including varying head scales, the diversity of crowd distribution across images and cluttered backgrounds. In this paper, we propose a multi-scale context aggregation network (MSCANet) based on single-column encoder-decoder architecture for crowd counting, which consists of an encoder based on a dense context-aware module (DCAM) and a hierarchical attention-guided decoder. To handle the issue of scale variation, we construct the DCAM to aggregate multi-scale contextual information by densely connecting the dilated convolution with varying receptive fields. The proposed DCAM can capture rich contextual information of crowd areas due to its long-range receptive fields and dense scale sampling. Moreover, to suppress the background noise and generate a high-quality density map, we adopt a hierarchical attention-guided mechanism in the decoder. This helps to integrate more useful spatial information from shallow feature maps of the encoder by introducing multiple supervision based on semantic attention module (SAM). Extensive experiments demonstrate that the proposed approach achieves better performance than other similar state-of-the-art methods on three challenging benchmark datasets for crowd counting. The code is available at https://github.com/KingMV/MSCANet

</p>
</details>

<details><summary><b>TENT: Efficient Quantization of Neural Networks on the tiny Edge with Tapered FixEd PoiNT</b>
<a href="https://arxiv.org/abs/2104.02233">arxiv:2104.02233</a>
&#x1F4C8; 2 <br>
<p>Hamed F. Langroudi, Vedant Karia, Tej Pandit, Dhireesha Kudithipudi</p></summary>
<p>

**Abstract:** In this research, we propose a new low-precision framework, TENT, to leverage the benefits of a tapered fixed-point numerical format in TinyML models. We introduce a tapered fixed-point quantization algorithm that matches the numerical format's dynamic range and distribution to that of the deep neural network model's parameter distribution at each layer. An accelerator architecture for the tapered fixed-point with TENT framework is proposed. Results show that the accuracy on classification tasks improves up to ~31 % with an energy overhead of ~17-30 % as compared to fixed-point, for ConvNet and ResNet-18 models.

</p>
</details>

<details><summary><b>Intelligent Building Control Systems for Thermal Comfort and Energy-Efficiency: A Systematic Review of Artificial Intelligence-Assisted Techniques</b>
<a href="https://arxiv.org/abs/2104.02214">arxiv:2104.02214</a>
&#x1F4C8; 2 <br>
<p>Ghezlane Halhoul Merabet, Mohamed Essaaidi, Mohamed Ben Haddou, Basheer Qolomany, Junaid Qadir, Muhammad Anan, Ala Al-Fuqaha, Mohamed Riduan Abid, Driss Benhaddou</p></summary>
<p>

**Abstract:** Building operations represent a significant percentage of the total primary energy consumed in most countries due to the proliferation of Heating, Ventilation and Air-Conditioning (HVAC) installations in response to the growing demand for improved thermal comfort. Reducing the associated energy consumption while maintaining comfortable conditions in buildings are conflicting objectives and represent a typical optimization problem that requires intelligent system design. Over the last decade, different methodologies based on the Artificial Intelligence (AI) techniques have been deployed to find the sweet spot between energy use in HVAC systems and suitable indoor comfort levels to the occupants. This paper performs a comprehensive and an in-depth systematic review of AI-based techniques used for building control systems by assessing the outputs of these techniques, and their implementations in the reviewed works, as well as investigating their abilities to improve the energy-efficiency, while maintaining thermal comfort conditions. This enables a holistic view of (1) the complexities of delivering thermal comfort to users inside buildings in an energy-efficient way, and (2) the associated bibliographic material to assist researchers and experts in the field in tackling such a challenge. Among the 20 AI tools developed for both energy consumption and comfort control, functions such as identification and recognition patterns, optimization, predictive control. Based on the findings of this work, the application of AI technology in building control is a promising area of research and still an ongoing, i.e., the performance of AI-based control is not yet completely satisfactory. This is mainly due in part to the fact that these algorithms usually need a large amount of high-quality real-world data, which is lacking in the building or, more precisely, the energy sector.

</p>
</details>

<details><summary><b>Revisiting Rashomon: A Comment on "The Two Cultures"</b>
<a href="https://arxiv.org/abs/2104.02150">arxiv:2104.02150</a>
&#x1F4C8; 2 <br>
<p>Alexander D'Amour</p></summary>
<p>

**Abstract:** Here, I provide some reflections on Prof. Leo Breiman's "The Two Cultures" paper. I focus specifically on the phenomenon that Breiman dubbed the "Rashomon Effect", describing the situation in which there are many models that satisfy predictive accuracy criteria equally well, but process information in the data in substantially different ways. This phenomenon can make it difficult to draw conclusions or automate decisions based on a model fit to data. I make connections to recent work in the Machine Learning literature that explore the implications of this issue, and note that grappling with it can be a fruitful area of collaboration between the algorithmic and data modeling cultures.

</p>
</details>

<details><summary><b>Compressing Visual-linguistic Model via Knowledge Distillation</b>
<a href="https://arxiv.org/abs/2104.02096">arxiv:2104.02096</a>
&#x1F4C8; 2 <br>
<p>Zhiyuan Fang, Jianfeng Wang, Xiaowei Hu, Lijuan Wang, Yezhou Yang, Zicheng Liu</p></summary>
<p>

**Abstract:** Despite exciting progress in pre-training for visual-linguistic (VL) representations, very few aspire to a small VL model. In this paper, we study knowledge distillation (KD) to effectively compress a transformer-based large VL model into a small VL model. The major challenge arises from the inconsistent regional visual tokens extracted from different detectors of Teacher and Student, resulting in the misalignment of hidden representations and attention distributions. To address the problem, we retrain and adapt the Teacher by using the same region proposals from Student's detector while the features are from Teacher's own object detector. With aligned network inputs, the adapted Teacher is capable of transferring the knowledge through the intermediate representations. Specifically, we use the mean square error loss to mimic the attention distribution inside the transformer block and present a token-wise noise contrastive loss to align the hidden state by contrasting with negative representations stored in a sample queue. To this end, we show that our proposed distillation significantly improves the performance of small VL models on image captioning and visual question answering tasks. It reaches 120.8 in CIDEr score on COCO captioning, an improvement of 5.1 over its non-distilled counterpart; and an accuracy of 69.8 on VQA 2.0, a 0.8 gain from the baseline. Our extensive experiments and ablations confirm the effectiveness of VL distillation in both pre-training and fine-tuning stages.

</p>
</details>

<details><summary><b>Automated lung segmentation from CT images of normal and COVID-19 pneumonia patients</b>
<a href="https://arxiv.org/abs/2104.02042">arxiv:2104.02042</a>
&#x1F4C8; 2 <br>
<p>Faeze Gholamiankhah, Samaneh Mostafapour, Nouraddin Abdi Goushbolagh, Seyedjafar Shojaerazavi, Parvaneh Layegh, Seyyed Mohammad Tabatabaei, Hossein Arabi</p></summary>
<p>

**Abstract:** Automated semantic image segmentation is an essential step in quantitative image analysis and disease diagnosis. This study investigates the performance of a deep learning-based model for lung segmentation from CT images for normal and COVID-19 patients. Chest CT images and corresponding lung masks of 1200 confirmed COVID-19 cases were used for training a residual neural network. The reference lung masks were generated through semi-automated/manual segmentation of the CT images. The performance of the model was evaluated on two distinct external test datasets including 120 normal and COVID-19 subjects, and the results of these groups were compared to each other. Different evaluation metrics such as dice coefficient (DSC), mean absolute error (MAE), relative mean HU difference, and relative volume difference were calculated to assess the accuracy of the predicted lung masks. The proposed deep learning method achieved DSC of 0.980 and 0.971 for normal and COVID-19 subjects, respectively, demonstrating significant overlap between predicted and reference lung masks. Moreover, MAEs of 0.037 HU and 0.061 HU, relative mean HU difference of -2.679% and -4.403%, and relative volume difference of 2.405% and 5.928% were obtained for normal and COVID-19 subjects, respectively. The comparable performance in lung segmentation of the normal and COVID-19 patients indicates the accuracy of the model for the identification of the lung tissue in the presence of the COVID-19 induced infections (though slightly better performance was observed for normal patients). The promising results achieved by the proposed deep learning-based model demonstrated its reliability in COVID-19 lung segmentation. This prerequisite step would lead to a more efficient and robust pneumonia lesion analysis.

</p>
</details>

<details><summary><b>Artificial Neural Network Modeling for Airline Disruption Management</b>
<a href="https://arxiv.org/abs/2104.02032">arxiv:2104.02032</a>
&#x1F4C8; 2 <br>
<p>Kolawole Ogunsina, Wendy A. Okolo</p></summary>
<p>

**Abstract:** Since the 1970s, most airlines have incorporated computerized support for managing disruptions during flight schedule execution. However, existing platforms for airline disruption management (ADM) employ monolithic system design methods that rely on the creation of specific rules and requirements through explicit optimization routines, before a system that meets the specifications is designed. Thus, current platforms for ADM are unable to readily accommodate additional system complexities resulting from the introduction of new capabilities, such as the introduction of unmanned aerial systems (UAS), operations and infrastructure, to the system. To this end, we use historical data on airline scheduling and operations recovery to develop a system of artificial neural networks (ANNs), which describe a predictive transfer function model (PTFM) for promptly estimating the recovery impact of disruption resolutions at separate phases of flight schedule execution during ADM. Furthermore, we provide a modular approach for assessing and executing the PTFM by employing a parallel ensemble method to develop generative routines that amalgamate the system of ANNs. Our modular approach ensures that current industry standards for tardiness in flight schedule execution during ADM are satisfied, while accurately estimating appropriate time-based performance metrics for the separate phases of flight schedule execution.

</p>
</details>

<details><summary><b>Self-Supervised Learning for Personalized Speech Enhancement</b>
<a href="https://arxiv.org/abs/2104.02017">arxiv:2104.02017</a>
&#x1F4C8; 2 <br>
<p>Aswin Sivaraman, Minje Kim</p></summary>
<p>

**Abstract:** Speech enhancement systems can show improved performance by adapting the model towards a single test-time speaker. In this personalization context, the test-time user might only provide a small amount of noise-free speech data, likely insufficient for traditional fully-supervised learning. One way to overcome the lack of personal data is to transfer the model parameters from a speaker-agnostic model to initialize the personalized model, and then to finetune the model using the small amount of personal speech data. This baseline marginally adapts over the scarce clean speech data. Alternatively, we propose self-supervised methods that are designed specifically to learn personalized and discriminative features from abundant in-the-wild noisy, but still personal speech recordings. Our experiment shows that the proposed self-supervised learning methods initialize personalized speech enhancement models better than the baseline fully-supervised methods, yielding superior speech enhancement performance. The proposed methods also result in a more robust feature set under the real-world conditions: compressed model sizes and fewness of the labeled data.

</p>
</details>

<details><summary><b>Using spatial-temporal ensembles of convolutional neural networks for lumen segmentation in ureteroscopy</b>
<a href="https://arxiv.org/abs/2104.01985">arxiv:2104.01985</a>
&#x1F4C8; 2 <br>
<p>Jorge F. Lazo, Aldo Marzullo, Sara Moccia, Michele Catellani, Benoit Rosa, Michel de Mathelin, Elena De Momi</p></summary>
<p>

**Abstract:** Purpose: Ureteroscopy is an efficient endoscopic minimally invasive technique for the diagnosis and treatment of upper tract urothelial carcinoma (UTUC). During ureteroscopy, the automatic segmentation of the hollow lumen is of primary importance, since it indicates the path that the endoscope should follow. In order to obtain an accurate segmentation of the hollow lumen, this paper presents an automatic method based on Convolutional Neural Networks (CNNs).
  Methods: The proposed method is based on an ensemble of 4 parallel CNNs to simultaneously process single and multi-frame information. Of these, two architectures are taken as core-models, namely U-Net based in residual blocks($m_1$) and Mask-RCNN($m_2$), which are fed with single still-frames $I(t)$. The other two models ($M_1$, $M_2$) are modifications of the former ones consisting on the addition of a stage which makes use of 3D Convolutions to process temporal information. $M_1$, $M_2$ are fed with triplets of frames ($I(t-1)$, $I(t)$, $I(t+1)$) to produce the segmentation for $I(t)$.
  Results: The proposed method was evaluated using a custom dataset of 11 videos (2,673 frames) which were collected and manually annotated from 6 patients. We obtain a Dice similarity coefficient of 0.80, outperforming previous state-of-the-art methods.
  Conclusion: The obtained results show that spatial-temporal information can be effectively exploited by the ensemble model to improve hollow lumen segmentation in ureteroscopic images. The method is effective also in presence of poor visibility, occasional bleeding, or specular reflections.

</p>
</details>

<details><summary><b>Cascaded Robust Learning at Imperfect Labels for Chest X-ray Segmentation</b>
<a href="https://arxiv.org/abs/2104.01975">arxiv:2104.01975</a>
&#x1F4C8; 2 <br>
<p>Cheng Xue, Qiao Deng, Xiaomeng Li, Qi Dou, Pheng Ann Heng</p></summary>
<p>

**Abstract:** The superior performance of CNN on medical image analysis heavily depends on the annotation quality, such as the number of labeled image, the source of image, and the expert experience. The annotation requires great expertise and labour. To deal with the high inter-rater variability, the study of imperfect label has great significance in medical image segmentation tasks. In this paper, we present a novel cascaded robust learning framework for chest X-ray segmentation with imperfect annotation. Our model consists of three independent network, which can effectively learn useful information from the peer networks. The framework includes two stages. In the first stage, we select the clean annotated samples via a model committee setting, the networks are trained by minimizing a segmentation loss using the selected clean samples. In the second stage, we design a joint optimization framework with label correction to gradually correct the wrong annotation and improve the network performance. We conduct experiments on the public chest X-ray image datasets collected by Shenzhen Hospital. The results show that our methods could achieve a significant improvement on the accuracy in segmentation tasks compared to the previous methods.

</p>
</details>

<details><summary><b>Global Guidance Network for Breast Lesion Segmentation in Ultrasound Images</b>
<a href="https://arxiv.org/abs/2104.01896">arxiv:2104.01896</a>
&#x1F4C8; 2 <br>
<p>Cheng Xue, Lei Zhu, Huazhu Fu, Xiaowei Hu, Xiaomeng Li, Hai Zhang, Pheng Ann Heng</p></summary>
<p>

**Abstract:** Automatic breast lesion segmentation in ultrasound helps to diagnose breast cancer, which is one of the dreadful diseases that affect women globally. Segmenting breast regions accurately from ultrasound image is a challenging task due to the inherent speckle artifacts, blurry breast lesion boundaries, and inhomogeneous intensity distributions inside the breast lesion regions. Recently, convolutional neural networks (CNNs) have demonstrated remarkable results in medical image segmentation tasks. However, the convolutional operations in a CNN often focus on local regions, which suffer from limited capabilities in capturing long-range dependencies of the input ultrasound image, resulting in degraded breast lesion segmentation accuracy. In this paper, we develop a deep convolutional neural network equipped with a global guidance block (GGB) and breast lesion boundary detection (BD) modules for boosting the breast ultrasound lesion segmentation. The GGB utilizes the multi-layer integrated feature map as a guidance information to learn the long-range non-local dependencies from both spatial and channel domains. The BD modules learn additional breast lesion boundary map to enhance the boundary quality of a segmentation result refinement. Experimental results on a public dataset and a collected dataset show that our network outperforms other medical image segmentation methods and the recent semantic segmentation methods on breast ultrasound lesion segmentation. Moreover, we also show the application of our network on the ultrasound prostate segmentation, in which our method better identifies prostate regions than state-of-the-art networks.

</p>
</details>

<details><summary><b>A General Derivative Identity for the Conditional Mean Estimator in Gaussian Noise and Some Applications</b>
<a href="https://arxiv.org/abs/2104.01883">arxiv:2104.01883</a>
&#x1F4C8; 2 <br>
<p>Alex Dytso, H. Vincent Poor, Shlomo Shamai</p></summary>
<p>

**Abstract:** Consider a channel ${\bf Y}={\bf X}+ {\bf N}$ where ${\bf X}$ is an $n$-dimensional random vector, and ${\bf N}$ is a Gaussian vector with a covariance matrix ${\bf \mathsf{K}}_{\bf N}$. The object under consideration in this paper is the conditional mean of ${\bf X}$ given ${\bf Y}={\bf y}$, that is ${\bf y} \to E[{\bf X}|{\bf Y}={\bf y}]$. Several identities in the literature connect $E[{\bf X}|{\bf Y}={\bf y}]$ to other quantities such as the conditional variance, score functions, and higher-order conditional moments. The objective of this paper is to provide a unifying view of these identities.
  In the first part of the paper, a general derivative identity for the conditional mean is derived. Specifically, for the Markov chain ${\bf U} \leftrightarrow {\bf X} \leftrightarrow {\bf Y}$, it is shown that the Jacobian of $E[{\bf U}|{\bf Y}={\bf y}]$ is given by ${\bf \mathsf{K}}_{\bf N}^{-1} {\bf Cov} ( {\bf X}, {\bf U} | {\bf Y}={\bf y})$.
  In the second part of the paper, via various choices of ${\bf U}$, the new identity is used to generalize many of the known identities and derive some new ones. First, a simple proof of the Hatsel and Nolte identity for the conditional variance is shown. Second, a simple proof of the recursive identity due to Jaffer is provided. Third, a new connection between the conditional cumulants and the conditional expectation is shown. In particular, it is shown that the $k$-th derivative of $E[X|Y=y]$ is the $(k+1)$-th conditional cumulant.
  The third part of the paper considers some applications. In a first application, the power series and the compositional inverse of $E[X|Y=y]$ are derived. In a second application, the distribution of the estimator error $(X-E[X|Y])$ is derived. In a third application, we construct consistent estimators (empirical Bayes estimators) of the conditional cumulants from an i.i.d. sequence $Y_1,...,Y_n$.

</p>
</details>

<details><summary><b>Integrating 2D and 3D Digital Plant Information Towards Automatic Generation of Digital Twins</b>
<a href="https://arxiv.org/abs/2104.01854">arxiv:2104.01854</a>
&#x1F4C8; 2 <br>
<p>Seppo Sierla, Mohammad Azangoo, Alexander Fay, Valeriy Vyatkin, Nikolaos Papakonstantinou</p></summary>
<p>

**Abstract:** Ongoing standardization in Industry 4.0 supports tool vendor neutral representations of Piping and Instrumentation diagrams as well as 3D pipe routing. However, a complete digital plant model requires combining these two representations. 3D pipe routing information is essential for building any accurate first-principles process simulation model. Piping and instrumentation diagrams are the primary source for control loops. In order to automatically integrate these information sources to a unified digital plant model, it is necessary to develop algorithms for identifying corresponding elements such as tanks and pumps from piping and instrumentation diagrams and 3D CAD models. One approach is to raise these two information sources to a common level of abstraction and to match them at this level of abstraction. Graph matching is a potential technique for this purpose. This article focuses on automatic generation of the graphs as a prerequisite to graph matching. Algorithms for this purpose are proposed and validated with a case study. The paper concludes with a discussion of further research needed to reprocess the generated graphs in order to enable effective matching.

</p>
</details>

<details><summary><b>Task-Independent Knowledge Makes for Transferable Representations for Generalized Zero-Shot Learning</b>
<a href="https://arxiv.org/abs/2104.01832">arxiv:2104.01832</a>
&#x1F4C8; 2 <br>
<p>Chaoqun Wang, Xuejin Chen, Shaobo Min, Xiaoyan Sun, Houqiang Li</p></summary>
<p>

**Abstract:** Generalized Zero-Shot Learning (GZSL) targets recognizing new categories by learning transferable image representations. Existing methods find that, by aligning image representations with corresponding semantic labels, the semantic-aligned representations can be transferred to unseen categories. However, supervised by only seen category labels, the learned semantic knowledge is highly task-specific, which makes image representations biased towards seen categories. In this paper, we propose a novel Dual-Contrastive Embedding Network (DCEN) that simultaneously learns task-specific and task-independent knowledge via semantic alignment and instance discrimination. First, DCEN leverages task labels to cluster representations of the same semantic category by cross-modal contrastive learning and exploring semantic-visual complementarity. Besides task-specific knowledge, DCEN then introduces task-independent knowledge by attracting representations of different views of the same image and repelling representations of different images. Compared to high-level seen category supervision, this instance discrimination supervision encourages DCEN to capture low-level visual knowledge, which is less biased toward seen categories and alleviates the representation bias. Consequently, the task-specific and task-independent knowledge jointly make for transferable representations of DCEN, which obtains averaged 4.1% improvement on four public benchmarks.

</p>
</details>

<details><summary><b>Model Compression for Dynamic Forecast Combination</b>
<a href="https://arxiv.org/abs/2104.01830">arxiv:2104.01830</a>
&#x1F4C8; 2 <br>
<p>Vitor Cerqueira, Luis Torgo, Carlos Soares, Albert Bifet</p></summary>
<p>

**Abstract:** The predictive advantage of combining several different predictive models is widely accepted. Particularly in time series forecasting problems, this combination is often dynamic to cope with potential non-stationary sources of variation present in the data. Despite their superior predictive performance, ensemble methods entail two main limitations: high computational costs and lack of transparency. These issues often preclude the deployment of such approaches, in favour of simpler yet more efficient and reliable ones. In this paper, we leverage the idea of model compression to address this problem in time series forecasting tasks. Model compression approaches have been mostly unexplored for forecasting. Their application in time series is challenging due to the evolving nature of the data. Further, while the literature focuses on neural networks, we apply model compression to distinct types of methods. In an extensive set of experiments, we show that compressing dynamic forecasting ensembles into an individual model leads to a comparable predictive performance and a drastic reduction in computational costs. Further, the compressed individual model with best average rank is a rule-based regression model. Thus, model compression also leads to benefits in terms of model interpretability. The experiments carried in this paper are fully reproducible.

</p>
</details>

<details><summary><b>When Can Liquid Democracy Unveil the Truth?</b>
<a href="https://arxiv.org/abs/2104.01828">arxiv:2104.01828</a>
&#x1F4C8; 2 <br>
<p>Ruben Becker, Gianlorenzo D'Angelo, Esmaeil Delfaraz, Hugo Gilbert</p></summary>
<p>

**Abstract:** In this paper, we investigate the so-called ODP-problem that has been formulated by Caragiannis and Micha [10]. Here, we are in a setting with two election alternatives out of which one is assumed to be correct. In ODP, the goal is to organise the delegations in the social network in order to maximize the probability that the correct alternative, referred to as ground truth, is elected. While the problem is known to be computationally hard, we strengthen existing hardness results by providing a novel strong approximation hardness result: For any positive constant $C$, we prove that, unless $P=NP$, there is no polynomial-time algorithm for ODP that achieves an approximation guarantee of $α\ge (\ln n)^{-C}$, where $n$ is the number of voters. The reduction designed for this result uses poorly connected social networks in which some voters suffer from misinformation. Interestingly, under some hypothesis on either the accuracies of voters or the connectivity of the network, we obtain a polynomial-time $1/2$-approximation algorithm. This observation proves formally that the connectivity of the social network is a key feature for the efficiency of the liquid democracy paradigm. Lastly, we run extensive simulations and observe that simple algorithms (working either in a centralized or decentralized way) outperform direct democracy on a large class of instances. Overall, our contributions yield new insights on the question in which situations liquid democracy can be beneficial.

</p>
</details>

<details><summary><b>A Heuristic-driven Uncertainty based Ensemble Framework for Fake News Detection in Tweets and News Articles</b>
<a href="https://arxiv.org/abs/2104.01791">arxiv:2104.01791</a>
&#x1F4C8; 2 <br>
<p>Sourya Dipta Das, Ayan Basak, Saikat Dutta</p></summary>
<p>

**Abstract:** The significance of social media has increased manifold in the past few decades as it helps people from even the most remote corners of the world to stay connected. With the advent of technology, digital media has become more relevant and widely used than ever before and along with this, there has been a resurgence in the circulation of fake news and tweets that demand immediate attention. In this paper, we describe a novel Fake News Detection system that automatically identifies whether a news item is "real" or "fake", as an extension of our work in the CONSTRAINT COVID-19 Fake News Detection in English challenge. We have used an ensemble model consisting of pre-trained models followed by a statistical feature fusion network , along with a novel heuristic algorithm by incorporating various attributes present in news items or tweets like source, username handles, URL domains and authors as statistical feature. Our proposed framework have also quantified reliable predictive uncertainty along with proper class output confidence level for the classification task. We have evaluated our results on the COVID-19 Fake News dataset and FakeNewsNet dataset to show the effectiveness of the proposed algorithm on detecting fake news in short news content as well as in news articles. We obtained a best F1-score of 0.9892 on the COVID-19 dataset, and an F1-score of 0.9073 on the FakeNewsNet dataset.

</p>
</details>

<details><summary><b>Deep Learning-Based Autonomous Driving Systems: A Survey of Attacks and Defenses</b>
<a href="https://arxiv.org/abs/2104.01789">arxiv:2104.01789</a>
&#x1F4C8; 2 <br>
<p>Yao Deng, Tiehua Zhang, Guannan Lou, Xi Zheng, Jiong Jin, Qing-Long Han</p></summary>
<p>

**Abstract:** The rapid development of artificial intelligence, especially deep learning technology, has advanced autonomous driving systems (ADSs) by providing precise control decisions to counterpart almost any driving event, spanning from anti-fatigue safe driving to intelligent route planning. However, ADSs are still plagued by increasing threats from different attacks, which could be categorized into physical attacks, cyberattacks and learning-based adversarial attacks. Inevitably, the safety and security of deep learning-based autonomous driving are severely challenged by these attacks, from which the countermeasures should be analyzed and studied comprehensively to mitigate all potential risks. This survey provides a thorough analysis of different attacks that may jeopardize ADSs, as well as the corresponding state-of-the-art defense mechanisms. The analysis is unrolled by taking an in-depth overview of each step in the ADS workflow, covering adversarial attacks for various deep learning models and attacks in both physical and cyber context. Furthermore, some promising research directions are suggested in order to improve deep learning-based autonomous driving safety, including model robustness training, model testing and verification, and anomaly detection based on cloud/edge servers.

</p>
</details>

<details><summary><b>Neural Clinical Event Sequence Prediction through Personalized Online Adaptive Learning</b>
<a href="https://arxiv.org/abs/2104.01787">arxiv:2104.01787</a>
&#x1F4C8; 2 <br>
<p>Jeong Min Lee, Milos Hauskrecht</p></summary>
<p>

**Abstract:** Clinical event sequences consist of thousands of clinical events that represent records of patient care in time. Developing accurate prediction models for such sequences is of a great importance for defining representations of a patient state and for improving patient care. One important challenge of learning a good predictive model of clinical sequences is patient-specific variability. Based on underlying clinical complications, each patient's sequence may consist of different sets of clinical events. However, population-based models learned from such sequences may not accurately predict patient-specific dynamics of event sequences. To address the problem, we develop a new adaptive event sequence prediction framework that learns to adjust its prediction for individual patients through an online model update.

</p>
</details>

<details><summary><b>Reducing Racial Bias in Facial Age Prediction using Unsupervised Domain Adaptation in Regression</b>
<a href="https://arxiv.org/abs/2104.01781">arxiv:2104.01781</a>
&#x1F4C8; 2 <br>
<p>Apoorva Gokhale, Astuti Sharma, Kaustav Datta,  Savyasachi</p></summary>
<p>

**Abstract:** We propose an approach for unsupervised domain adaptation for the task of estimating someone's age from a given face image. In order to avoid the propagation of racial bias in most publicly available face image datasets into the inefficacy of models trained on them, we perform domain adaptation to motivate the predictor to learn features that are invariant to ethnicity, enhancing the generalization performance across faces of people from different ethnic backgrounds. Exploiting the ordinality of age, we also impose ranking constraints on the prediction of the model and design our model such that it takes as input a pair of images, and outputs both the relative age difference and the rank of the first identity with respect to the other in terms of their ages. Furthermore, we implement Multi-Dimensional Scaling to retrieve absolute ages from the predicted age differences from as few as two labeled images from the domain to be adapted to. We experiment with a publicly available dataset with age labels, dividing it into subsets based on the ethnicity labels, and evaluating the performance of our approach on the data from an ethnicity different from the one that the model is trained on. Additionally, we impose a constraint to preserve the sanity of the predictions with respect to relative and absolute ages, and another to ensure the smoothness of the predictions with respect to the input. We experiment extensively and compare various domain adaptation approaches for the task of regression.

</p>
</details>

<details><summary><b>A Caputo fractional derivative-based algorithm for optimization</b>
<a href="https://arxiv.org/abs/2104.02259">arxiv:2104.02259</a>
&#x1F4C8; 1 <br>
<p>Yeonjong Shin, Jérôme Darbon, George Em Karniadakis</p></summary>
<p>

**Abstract:** We propose a novel Caputo fractional derivative-based optimization algorithm. Upon defining the Caputo fractional gradient with respect to the Cartesian coordinate, we present a generic Caputo fractional gradient descent (CFGD) method. We prove that the CFGD yields the steepest descent direction of a locally smoothed objective function. The generic CFGD requires three parameters to be specified, and a choice of the parameters yields a version of CFGD. We propose three versions -- non-adaptive, adaptive terminal and adaptive order. By focusing on quadratic objective functions, we provide a convergence analysis. We prove that the non-adaptive CFGD converges to a Tikhonov regularized solution. For the two adaptive versions, we derive error bounds, which show convergence to integer-order stationary point under some conditions. We derive an explicit formula of CFGD for quadratic functions. We computationally found that the adaptive terminal (AT) CFGD mitigates the dependence on the condition number in the rate of convergence and results in significant acceleration over gradient descent (GD). For non-quadratic functions, we develop an efficient implementation of CFGD using the Gauss-Jacobi quadrature, whose computational cost is approximately proportional to the number of the quadrature points and the cost of GD. Our numerical examples show that AT-CFGD results in acceleration over GD, even when a small number of the Gauss-Jacobi quadrature points (including a single point) is used.

</p>
</details>

<details><summary><b>Designing Efficient and High-performance AI Accelerators with Customized STT-MRAM</b>
<a href="https://arxiv.org/abs/2104.02199">arxiv:2104.02199</a>
&#x1F4C8; 1 <br>
<p>Kaniz Mishty, Mehdi Sadi</p></summary>
<p>

**Abstract:** In this paper, we demonstrate the design of efficient and high-performance AI/Deep Learning accelerators with customized STT-MRAM and a reconfigurable core. Based on model-driven detailed design space exploration, we present the design methodology of an innovative scratchpad-assisted on-chip STT-MRAM based buffer system for high-performance accelerators. Using analytically derived expression of memory occupancy time of AI model weights and activation maps, the volatility of STT-MRAM is adjusted with process and temperature variation aware scaling of thermal stability factor to optimize the retention time, energy, read/write latency, and area of STT-MRAM. From the analysis of modern AI workloads and accelerator implementation in 14nm technology, we verify the efficacy of our designed AI accelerator with STT-MRAM STT-AI. Compared to an SRAM-based implementation, the STT-AI accelerator achieves 75% area and 3% power savings at iso-accuracy. Furthermore, with a relaxed bit error rate and negligible AI accuracy trade-off, the designed STT-AI Ultra accelerator achieves 75.4%, and 3.5% savings in area and power, respectively over regular SRAM-based accelerators.

</p>
</details>

<details><summary><b>Nonlinear model reduction for slow-fast stochastic systems near manifolds</b>
<a href="https://arxiv.org/abs/2104.02120">arxiv:2104.02120</a>
&#x1F4C8; 1 <br>
<p>Felix X. -F. Ye, Sichen Yang, Mauro Maggioni</p></summary>
<p>

**Abstract:** We introduce a nonlinear stochastic model reduction technique for high-dimensional stochastic dynamical systems that have a low-dimensional invariant effective manifold with slow dynamics, and high-dimensional, large fast modes. Given only access to a black box simulator from which short bursts of simulation can be obtained, we estimate the invariant manifold, a process of the effective (stochastic) dynamics on it, and construct an efficient simulator thereof. These estimation steps can be performed on-the-fly, leading to efficient exploration of the effective state space, without losing consistency with the underlying dynamics. This construction enables fast and efficient simulation of paths of the effective dynamics, together with estimation of crucial features and observables of such dynamics, including the stationary distribution, identification of metastable states, and residence times and transition rates between them.

</p>
</details>

<details><summary><b>Distributed Deep Reinforcement Learning for Collaborative Spectrum Sharing</b>
<a href="https://arxiv.org/abs/2104.02059">arxiv:2104.02059</a>
&#x1F4C8; 1 <br>
<p>Pranav M. Pawar, Amir Leshem</p></summary>
<p>

**Abstract:** Spectrum sharing among users is a fundamental problem in the management of any wireless network. In this paper, we discuss the problem of distributed spectrum collaboration without central management under general unknown channels. Since the cost of communication, coordination and control is rapidly increasing with the number of devices and the expanding bandwidth used there is an obvious need to develop distributed techniques for spectrum collaboration where no explicit signaling is used. In this paper, we combine game-theoretic insights with deep Q-learning to provide a novel asymptotically optimal solution to the spectrum collaboration problem. We propose a deterministic distributed deep reinforcement learning(D3RL) mechanism using a deep Q-network (DQN). It chooses the channels using the Q-values and the channel loads while limiting the options available to the user to a few channels with the highest Q-values and among those, it selects the least loaded channel. Using insights from both game theory and combinatorial optimization we show that this technique is asymptotically optimal for large overloaded networks. The selected channel and the outcome of the successful transmission are fed back into the learning of the deep Q-network to incorporate it into the learning of the Q-values. We also analyzed performance to understand the behavior of D3RL in differ

</p>
</details>

<details><summary><b>Generalized Joint Probability Density Function Formulation inTurbulent Combustion using DeepONet</b>
<a href="https://arxiv.org/abs/2104.01996">arxiv:2104.01996</a>
&#x1F4C8; 1 <br>
<p>Rishikesh Ranade, Kevin Gitushi, Tarek Echekki</p></summary>
<p>

**Abstract:** Joint probability density function (PDF)-based models in turbulent combustion provide direct closure for turbulence-chemistry interactions. The joint PDFs capture the turbulent flame dynamics at different spatial locations and hence it is crucial to represent them accurately. The jointPDFs are parameterized on the unconditional means of thermo-chemical state variables, which can be high dimensional. Thus, accurate construction of joint PDFs at various spatial locations may require an exorbitant amount of data. In a previous work, we introduced a framework that alleviated data requirements by constructing joint PDFs in a lower dimensional space using principal component analysis (PCA) in conjunction with Kernel Density Estimation (KDE). However, constructing the principal component (PC) joint PDFs is still computationally expensive as they are required to be calculated at each spatial location in the turbulent flame. In this work, we propose the concept of a generalized joint PDF model using the Deep Operator Network (DeepONet). The DeepONet is a machine learning model that is parameterized on the unconditional means of PCs at a given spatial location and discrete PC coordinates and predicts the joint probability density value for the corresponding PC coordinate. We demonstrate the accuracy and generalizability of the DeepONet on the Sandia flames, D, E and F. The DeepONet is trained based on the PC joint PDFs observed inflame E and yields excellent predictions of joint PDFs shapes at different spatial locations of flamesD and F, which are not seen during training

</p>
</details>

<details><summary><b>Machine Learning Applications in the Routing in Computer Networks</b>
<a href="https://arxiv.org/abs/2104.01946">arxiv:2104.01946</a>
&#x1F4C8; 1 <br>
<p>Ke Liang, Mitchel Myers</p></summary>
<p>

**Abstract:** Development of routing algorithms is of clear importance as the volume of Internet traffic continues to increase. In this survey, there is much research into how Machine Learning techniques can be employed to improve the performance and scalability of routing algorithms. We surveyed both centralized and decentralized ML routing architectures and using a variety of ML techniques broadly divided into supervised learning and reinforcement learning. Many of the papers showed promise in their ability to optimize some aspect of network routing. We also implemented two routing protocols within 14 surveyed routing algorithms and verified the efficacy of their results. While the results of most of the papers showed promise, many of them are based on simulations of potentially unrealistic network configurations. To provide further efficacy to the results, more real-world results are necessary.

</p>
</details>

<details><summary><b>Semi-supervised Variational Temporal Convolutional Network for IoT Communication Multi-anomaly Detection</b>
<a href="https://arxiv.org/abs/2104.01813">arxiv:2104.01813</a>
&#x1F4C8; 1 <br>
<p>Yan Xu, Yongliang Cheng</p></summary>
<p>

**Abstract:** The consumer Internet of Things (IoT) have developed in recent years. Mass IoT devices are constructed to build a huge communications network. But these devices are insecure in reality, it means that the communications network are exposed by the attacker. Moreover, the IoT communication network also faces with variety of sudden errors. Therefore, it easily leads to that is vulnerable with the threat of attacker and system failure. The severe situation of IoT communication network motivates the development of new techniques to automatically detect multi-anomaly. In this paper, we propose SS-VTCN, a semi-supervised network for IoT multiple anomaly detection that works well effectively for IoT communication network. SS-VTCN is designed to capture the normal patterns of the IoT traffic data based on the distribution whether it is labeled or not by learning their representations with key techniques such as Variational Autoencoders and Temporal Convolutional Network. This network can use the encode data to predict preliminary result, and reconstruct input data to determine anomalies by the representations. Extensive evaluation experiments based on a benchmark dataset and a real consumer smart home dataset demonstrate that SS-VTCN is more suitable than supervised and unsupervised method with better performance when compared other state-of-art semi-supervised method.

</p>
</details>

<details><summary><b>Modeling Gate-Level Abstraction Hierarchy Using Graph Convolutional Neural Networks to Predict Functional De-Rating Factors</b>
<a href="https://arxiv.org/abs/2104.01812">arxiv:2104.01812</a>
&#x1F4C8; 1 <br>
<p>Aneesh Balakrishnan, Thomas Lange, Maximilien Glorieux, Dan Alexandrescu, Maksim Jenihhin</p></summary>
<p>

**Abstract:** The paper is proposing a methodology for modeling a gate-level netlist using a Graph Convolutional Network (GCN). The model predicts the overall functional de-rating factors of sequential elements of a given circuit. In the preliminary phase of the work, the important goal is making a GCN which able to take a gate-level netlist as input information after transforming it into the Probabilistic Bayesian Graph in the form of Graph Modeling Language (GML). This part enables the GCN to learn the structural information of netlist in graph domains. In the second phase of the work, the modeled GCN trained with the a functional de-rating factor of a very low number of individual sequential elements (flip-flops). The third phase includes understanding of GCN models accuracy to model an arbitrary circuit netlist. The designed model was validated for two circuits. One is the IEEE 754 standard double precision floating point adder and the second one is the 10-Gigabit Ethernet MAC IEEE802.3 standard. The predicted results compared to the standard fault injection campaign results of the error called Single EventUpset (SEU). The validated results are graphically pictured in the form of the histogram and sorted probabilities and evaluated with the Confidence Interval (CI) metric between the predicted and simulated fault injection results.

</p>
</details>

<details><summary><b>Frequency Estimation Under Multiparty Differential Privacy: One-shot and Streaming</b>
<a href="https://arxiv.org/abs/2104.01808">arxiv:2104.01808</a>
&#x1F4C8; 1 <br>
<p>Ziyue Huang, Yuan Qiu, Ke Yi, Graham Cormode</p></summary>
<p>

**Abstract:** We study the fundamental problem of frequency estimation under both privacy and communication constraints, where the data is distributed among $k$ parties. We consider two application scenarios: (1) one-shot, where the data is static and the aggregator conducts a one-time computation; and (2) streaming, where each party receives a stream of items over time and the aggregator continuously monitors the frequencies. We adopt the model of multiparty differential privacy (MDP), which is more general than local differential privacy (LDP) and (centralized) differential privacy. Our protocols achieve optimality (up to logarithmic factors) permissible by the more stringent of the two constraints. In particular, when specialized to the $\varepsilon$-LDP model, our protocol achieves an error of $\sqrt{k}/(e^{Θ(\varepsilon)}-1)$ using $O(k\max\{ \varepsilon, \frac{1}{\varepsilon} \})$ bits of communication and $O(k \log u)$ bits of public randomness, where $u$ is the size of the domain.

</p>
</details>

<details><summary><b>Application of Neural Network Algorithm in Propylene Distillation</b>
<a href="https://arxiv.org/abs/2104.01774">arxiv:2104.01774</a>
&#x1F4C8; 1 <br>
<p>Jinwei Lu, Ningrui Zhao</p></summary>
<p>

**Abstract:** Artificial neural network modeling does not need to consider the mechanism. It can map the implicit relationship between input and output and predict the performance of the system well. At the same time, it has the advantages of self-learning ability and high fault tolerance. The gas-liquid two phases in the rectification tower conduct interphase heat and mass transfer through countercurrent contact. The functional relationship between the product concentration at the top and bottom of the tower and the process parameters is extremely complex. The functional relationship can be accurately controlled by artificial neural network algorithms. The key components of the propylene distillation tower are the propane concentration at the top of the tower and the propylene concentration at the bottom of the tower. Accurate measurement of them plays a key role in increasing propylene yield in ethylene production enterprises. This article mainly introduces the neural network model and its application in the propylene distillation tower.

</p>
</details>

<details><summary><b>Beyond Categorical Label Representations for Image Classification</b>
<a href="https://arxiv.org/abs/2104.02226">arxiv:2104.02226</a>
&#x1F4C8; 0 <br>
<p>Boyuan Chen, Yu Li, Sunand Raghupathi, Hod Lipson</p></summary>
<p>

**Abstract:** We find that the way we choose to represent data labels can have a profound effect on the quality of trained models. For example, training an image classifier to regress audio labels rather than traditional categorical probabilities produces a more reliable classification. This result is surprising, considering that audio labels are more complex than simpler numerical probabilities or text. We hypothesize that high dimensional, high entropy label representations are generally more useful because they provide a stronger error signal. We support this hypothesis with evidence from various label representations including constant matrices, spectrograms, shuffled spectrograms, Gaussian mixtures, and uniform random matrices of various dimensionalities. Our experiments reveal that high dimensional, high entropy labels achieve comparable accuracy to text (categorical) labels on the standard image classification task, but features learned through our label representations exhibit more robustness under various adversarial attacks and better effectiveness with a limited amount of training data. These results suggest that label representation may play a more important role than previously thought. The project website is at \url{https://www.creativemachineslab.com/label-representation.html}.

</p>
</details>

<details><summary><b>Hypothesis-driven Online Video Stream Learning with Augmented Memory</b>
<a href="https://arxiv.org/abs/2104.02206">arxiv:2104.02206</a>
&#x1F4C8; 0 <br>
<p>Mengmi Zhang, Rohil Badkundri, Morgan B. Talbot, Rushikesh Zawar, Gabriel Kreiman</p></summary>
<p>

**Abstract:** The ability to continuously acquire new knowledge without forgetting previous tasks remains a challenging problem for computer vision systems. Standard continual learning benchmarks focus on learning from static iid images in an offline setting. Here, we examine a more challenging and realistic online continual learning problem called online stream learning. Like humans, some AI agents have to learn incrementally from a continuous temporal stream of non-repeating data. We propose a novel model, Hypotheses-driven Augmented Memory Network (HAMN), which efficiently consolidates previous knowledge using an augmented memory matrix of "hypotheses" and replays reconstructed image features to avoid catastrophic forgetting. Compared with pixel-level and generative replay approaches, the advantages of HAMN are two-fold. First, hypothesis-based knowledge consolidation avoids redundant information in the image pixel space and makes memory usage far more efficient. Second, hypotheses in the augmented memory can be re-used for learning new tasks, improving generalization and transfer learning ability. Given a lack of online incremental class learning datasets on video streams, we introduce and adapt two additional video datasets, Toybox and iLab, for online stream learning. We also evaluate our method on the CORe50 and online CIFAR100 datasets. Our method performs significantly better than all state-of-the-art methods, while offering much more efficient memory usage. All source code and data are publicly available at https://github.com/kreimanlab/AugMem

</p>
</details>

<details><summary><b>Robust Classification Under $\ell_0$ Attack for the Gaussian Mixture Model</b>
<a href="https://arxiv.org/abs/2104.02189">arxiv:2104.02189</a>
&#x1F4C8; 0 <br>
<p>Payam Delgosha, Hamed Hassani, Ramtin Pedarsani</p></summary>
<p>

**Abstract:** It is well-known that machine learning models are vulnerable to small but cleverly-designed adversarial perturbations that can cause misclassification. While there has been major progress in designing attacks and defenses for various adversarial settings, many fundamental and theoretical problems are yet to be resolved. In this paper, we consider classification in the presence of $\ell_0$-bounded adversarial perturbations, a.k.a. sparse attacks. This setting is significantly different from other $\ell_p$-adversarial settings, with $p\geq 1$, as the $\ell_0$-ball is non-convex and highly non-smooth. Under the assumption that data is distributed according to the Gaussian mixture model, our goal is to characterize the optimal robust classifier and the corresponding robust classification error as well as a variety of trade-offs between robustness, accuracy, and the adversary's budget. To this end, we develop a novel classification algorithm called FilTrun that has two main modules: Filtration and Truncation. The key idea of our method is to first filter out the non-robust coordinates of the input and then apply a carefully-designed truncated inner product for classification. By analyzing the performance of FilTrun, we derive an upper bound on the optimal robust classification error. We also find a lower bound by designing a specific adversarial strategy that enables us to derive the corresponding robust classifier and its achieved error. For the case that the covariance matrix of the Gaussian mixtures is diagonal, we show that as the input's dimension gets large, the upper and lower bounds converge; i.e. we characterize the asymptotically-optimal robust classifier. Throughout, we discuss several examples that illustrate interesting behaviors such as the existence of a phase transition for adversary's budget determining whether the effect of adversarial perturbation can be fully neutralized.

</p>
</details>

<details><summary><b>Analytic function approximation by path norm regularized deep networks</b>
<a href="https://arxiv.org/abs/2104.02095">arxiv:2104.02095</a>
&#x1F4C8; 0 <br>
<p>Aleksandr Beknazaryan</p></summary>
<p>

**Abstract:** We show that neural networks with absolute value activation function and with the path norm, the depth, the width and the network weights having logarithmic dependence on $1/\varepsilon$ can $\varepsilon$-approximate functions that are analytic on certain regions of $\mathbb{C}^d$.

</p>
</details>

<details><summary><b>Automating Transfer Credit Assessment in Student Mobility -- A Natural Language Processing-based Approach</b>
<a href="https://arxiv.org/abs/2104.01955">arxiv:2104.01955</a>
&#x1F4C8; 0 <br>
<p>Dhivya Chandrasekaran, Vijay Mago</p></summary>
<p>

**Abstract:** Student mobility or academic mobility involves students moving between institutions during their post-secondary education, and one of the challenging tasks in this process is to assess the transfer credits to be offered to the incoming student. In general, this process involves domain experts comparing the learning outcomes of the courses, to decide on offering transfer credits to the incoming students. This manual implementation is not only labor-intensive but also influenced by undue bias and administrative complexity. The proposed research article focuses on identifying a model that exploits the advancements in the field of Natural Language Processing (NLP) to effectively automate this process. Given the unique structure, domain specificity, and complexity of learning outcomes (LOs), a need for designing a tailor-made model arises. The proposed model uses a clustering-inspired methodology based on knowledge-based semantic similarity measures to assess the taxonomic similarity of LOs and a transformer-based semantic similarity model to assess the semantic similarity of the LOs. The similarity between LOs is further aggregated to form course to course similarity. Due to the lack of quality benchmark datasets, a new benchmark dataset containing seven course-to-course similarity measures is proposed. Understanding the inherent need for flexibility in the decision-making process the aggregation part of the model offers tunable parameters to accommodate different scenarios. While providing an efficient model to assess the similarity between courses with existing resources, this research work steers future research attempts to apply NLP in the field of articulation in an ideal direction by highlighting the persisting research gaps.

</p>
</details>

<details><summary><b>Adaptive Gradient Balancing for Undersampled MRI Reconstruction and Image-to-Image Translation</b>
<a href="https://arxiv.org/abs/2104.01889">arxiv:2104.01889</a>
&#x1F4C8; 0 <br>
<p>Itzik Malkiel, Sangtae Ahn, Valentina Taviani, Anne Menini, Lior Wolf, Christopher J. Hardy</p></summary>
<p>

**Abstract:** Recent accelerated MRI reconstruction models have used Deep Neural Networks (DNNs) to reconstruct relatively high-quality images from highly undersampled k-space data, enabling much faster MRI scanning. However, these techniques sometimes struggle to reconstruct sharp images that preserve fine detail while maintaining a natural appearance. In this work, we enhance the image quality by using a Conditional Wasserstein Generative Adversarial Network combined with a novel Adaptive Gradient Balancing (AGB) technique that automates the process of combining the adversarial and pixel-wise terms and streamlines hyperparameter tuning. In addition, we introduce a Densely Connected Iterative Network, which is an undersampled MRI reconstruction network that utilizes dense connections. In MRI, our method minimizes artifacts, while maintaining a high-quality reconstruction that produces sharper images than other techniques. To demonstrate the general nature of our method, it is further evaluated on a battery of image-to-image translation experiments, demonstrating an ability to recover from sub-optimal weighting in multi-term adversarial training.

</p>
</details>

<details><summary><b>CCSNet: a deep learning modeling suite for CO$_2$ storage</b>
<a href="https://arxiv.org/abs/2104.01795">arxiv:2104.01795</a>
&#x1F4C8; 0 <br>
<p>Gege Wen, Catherine Hay, Sally M. Benson</p></summary>
<p>

**Abstract:** Numerical simulation is an essential tool for many applications involving subsurface flow and transport, yet often suffers from computational challenges due to the multi-physics nature, highly non-linear governing equations, inherent parameter uncertainties, and the need for high spatial resolutions to capture multi-scale heterogeneity. We developed CCSNet, a general-purpose deep-learning modeling suite that can act as an alternative to conventional numerical simulators for carbon capture and storage (CCS) problems where CO$_2$ is injected into saline aquifers in 2d-radial systems. CCSNet consists of a sequence of deep learning models producing all the outputs that a numerical simulator typically provides, including saturation distributions, pressure buildup, dry-out, fluid densities, mass balance, solubility trapping, and sweep efficiency. The results are 10$^3$ to 10$^4$ times faster than conventional numerical simulators. As an application of CCSNet illustrating the value of its high computational efficiency, we developed rigorous estimation techniques for the sweep efficiency and solubility trapping.

</p>
</details>


[Next Page]({{ '/2021/04/04/2021.04.04.html' | relative_url }})
