## Summary for 2021-09-10, created on 2021-12-18


<details><summary><b>Instance-Conditioned GAN</b>
<a href="https://arxiv.org/abs/2109.05070">arxiv:2109.05070</a>
&#x1F4C8; 219 <br>
<p>Arantxa Casanova, Marl√®ne Careil, Jakob Verbeek, Michal Drozdzal, Adriana Romero-Soriano</p></summary>
<p>

**Abstract:** Generative Adversarial Networks (GANs) can generate near photo realistic images in narrow domains such as human faces. Yet, modeling complex distributions of datasets such as ImageNet and COCO-Stuff remains challenging in unconditional settings. In this paper, we take inspiration from kernel density estimation techniques and introduce a non-parametric approach to modeling distributions of complex datasets. We partition the data manifold into a mixture of overlapping neighborhoods described by a datapoint and its nearest neighbors, and introduce a model, called instance-conditioned GAN (IC-GAN), which learns the distribution around each datapoint. Experimental results on ImageNet and COCO-Stuff show that IC-GAN significantly improves over unconditional models and unsupervised data partitioning baselines. Moreover, we show that IC-GAN can effortlessly transfer to datasets not seen during training by simply changing the conditioning instances, and still generate realistic images. Finally, we extend IC-GAN to the class-conditional case and show semantically controllable generation and competitive quantitative results on ImageNet; while improving over BigGAN on ImageNet-LT. Code and trained models to reproduce the reported results are available at https://github.com/facebookresearch/ic_gan.

</p>
</details>

<details><summary><b>MURAL: Multimodal, Multitask Retrieval Across Languages</b>
<a href="https://arxiv.org/abs/2109.05125">arxiv:2109.05125</a>
&#x1F4C8; 45 <br>
<p>Aashi Jain, Mandy Guo, Krishna Srinivasan, Ting Chen, Sneha Kudugunta, Chao Jia, Yinfei Yang, Jason Baldridge</p></summary>
<p>

**Abstract:** Both image-caption pairs and translation pairs provide the means to learn deep representations of and connections between languages. We use both types of pairs in MURAL (MUltimodal, MUltitask Representations Across Languages), a dual encoder that solves two tasks: 1) image-text matching and 2) translation pair matching. By incorporating billions of translation pairs, MURAL extends ALIGN (Jia et al. PMLR'21)--a state-of-the-art dual encoder learned from 1.8 billion noisy image-text pairs. When using the same encoders, MURAL's performance matches or exceeds ALIGN's cross-modal retrieval performance on well-resourced languages across several datasets. More importantly, it considerably improves performance on under-resourced languages, showing that text-text learning can overcome a paucity of image-caption examples for these languages. On the Wikipedia Image-Text dataset, for example, MURAL-base improves zero-shot mean recall by 8.1% on average for eight under-resourced languages and by 6.8% on average when fine-tuning. We additionally show that MURAL's text representations cluster not only with respect to genealogical connections but also based on areal linguistics, such as the Balkan Sprachbund.

</p>
</details>

<details><summary><b>ReasonBERT: Pre-trained to Reason with Distant Supervision</b>
<a href="https://arxiv.org/abs/2109.04912">arxiv:2109.04912</a>
&#x1F4C8; 44 <br>
<p>Xiang Deng, Yu Su, Alyssa Lees, You Wu, Cong Yu, Huan Sun</p></summary>
<p>

**Abstract:** We present ReasonBert, a pre-training method that augments language models with the ability to reason over long-range relations and multiple, possibly hybrid contexts. Unlike existing pre-training methods that only harvest learning signals from local contexts of naturally occurring texts, we propose a generalized notion of distant supervision to automatically connect multiple pieces of text and tables to create pre-training examples that require long-range reasoning. Different types of reasoning are simulated, including intersecting multiple pieces of evidence, bridging from one piece of evidence to another, and detecting unanswerable cases. We conduct a comprehensive evaluation on a variety of extractive question answering datasets ranging from single-hop to multi-hop and from text-only to table-only to hybrid that require various reasoning capabilities and show that ReasonBert achieves remarkable improvement over an array of strong baselines. Few-shot experiments further demonstrate that our pre-training method substantially improves sample efficiency.

</p>
</details>

<details><summary><b>R3LIVE: A Robust, Real-time, RGB-colored, LiDAR-Inertial-Visual tightly-coupled state Estimation and mapping package</b>
<a href="https://arxiv.org/abs/2109.07982">arxiv:2109.07982</a>
&#x1F4C8; 41 <br>
<p>Jiarong Lin, Fu Zhang</p></summary>
<p>

**Abstract:** In this letter, we propose a novel LiDAR-Inertial-Visual sensor fusion framework termed R3LIVE, which takes advantage of measurement of LiDAR, inertial, and visual sensors to achieve robust and accurate state estimation. R3LIVE is contained of two subsystems, the LiDAR-inertial odometry (LIO) and visual-inertial odometry (VIO). The LIO subsystem (FAST-LIO) takes advantage of the measurement from LiDAR and inertial sensors and builds the geometry structure of (i.e. the position of 3D points) global maps. The VIO subsystem utilizes the data of visual-inertial sensors and renders the map's texture (i.e. the color of 3D points). More specifically, the VIO subsystem fuses the visual data directly and effectively by minimizing the frame-to-map photometric error. The developed system R3LIVE is developed based on our previous work R2LIVE, with careful architecture design and implementation. Experiment results show that the resultant system achieves more robustness and higher accuracy in state estimation than current counterparts (see our attached video).
  R3LIVE is a versatile and well-engineered system toward various possible applications, which can not only serve as a SLAM system for real-time robotic applications, but can also reconstruct the dense, precise, RGB-colored 3D maps for applications like surveying and mapping. Moreover, to make R3LIVE more extensible, we develop a series of offline utilities for reconstructing and texturing meshes, which further minimizes the gap between R3LIVE and various of 3D applications such as simulators, video games and etc (see our demos video). To share our findings and make contributions to the community, we open source R3LIVE on our Github, including all of our codes, software utilities, and the mechanical design of our device.

</p>
</details>

<details><summary><b>Does Pretraining for Summarization Require Knowledge Transfer?</b>
<a href="https://arxiv.org/abs/2109.04953">arxiv:2109.04953</a>
&#x1F4C8; 36 <br>
<p>Kundan Krishna, Jeffrey Bigham, Zachary C. Lipton</p></summary>
<p>

**Abstract:** Pretraining techniques leveraging enormous datasets have driven recent advances in text summarization. While folk explanations suggest that knowledge transfer accounts for pretraining's benefits, little is known about why it works or what makes a pretraining task or dataset suitable. In this paper, we challenge the knowledge transfer story, showing that pretraining on documents consisting of character n-grams selected at random, we can nearly match the performance of models pretrained on real corpora. This work holds the promise of eliminating upstream corpora, which may alleviate some concerns over offensive language, bias, and copyright issues. To see whether the small residual benefit of using real data could be accounted for by the structure of the pretraining task, we design several tasks motivated by a qualitative study of summarization corpora. However, these tasks confer no appreciable benefit, leaving open the possibility of a small role for knowledge transfer.

</p>
</details>

<details><summary><b>Knowledge-Aware Meta-learning for Low-Resource Text Classification</b>
<a href="https://arxiv.org/abs/2109.04707">arxiv:2109.04707</a>
&#x1F4C8; 30 <br>
<p>Huaxiu Yao, Yingxin Wu, Maruan Al-Shedivat, Eric P. Xing</p></summary>
<p>

**Abstract:** Meta-learning has achieved great success in leveraging the historical learned knowledge to facilitate the learning process of the new task. However, merely learning the knowledge from the historical tasks, adopted by current meta-learning algorithms, may not generalize well to testing tasks when they are not well-supported by training tasks. This paper studies a low-resource text classification problem and bridges the gap between meta-training and meta-testing tasks by leveraging the external knowledge bases. Specifically, we propose KGML to introduce additional representation for each sentence learned from the extracted sentence-specific knowledge graph. The extensive experiments on three datasets demonstrate the effectiveness of KGML under both supervised adaptation and unsupervised adaptation settings.

</p>
</details>

<details><summary><b>HypoGen: Hyperbole Generation with Commonsense and Counterfactual Knowledge</b>
<a href="https://arxiv.org/abs/2109.05097">arxiv:2109.05097</a>
&#x1F4C8; 23 <br>
<p>Yufei Tian, Arvind krishna Sridhar, Nanyun Peng</p></summary>
<p>

**Abstract:** A hyperbole is an intentional and creative exaggeration not to be taken literally. Despite its ubiquity in daily life, the computational explorations of hyperboles are scarce. In this paper, we tackle the under-explored and challenging task: sentence-level hyperbole generation. We start with a representative syntactic pattern for intensification and systematically study the semantic (commonsense and counterfactual) relationships between each component in such hyperboles. Next, we leverage the COMeT and reverse COMeT models to do commonsense and counterfactual inference. We then generate multiple hyperbole candidates based on our findings from the pattern, and train neural classifiers to rank and select high-quality hyperboles. Automatic and human evaluations show that our generation method is able to generate hyperboles creatively with high success rate and intensity scores.

</p>
</details>

<details><summary><b>Efficient Test Time Adapter Ensembling for Low-resource Language Varieties</b>
<a href="https://arxiv.org/abs/2109.04877">arxiv:2109.04877</a>
&#x1F4C8; 23 <br>
<p>Xinyi Wang, Yulia Tsvetkov, Sebastian Ruder, Graham Neubig</p></summary>
<p>

**Abstract:** Adapters are light-weight modules that allow parameter-efficient fine-tuning of pretrained models. Specialized language and task adapters have recently been proposed to facilitate cross-lingual transfer of multilingual pretrained models (Pfeiffer et al., 2020b). However, this approach requires training a separate language adapter for every language one wishes to support, which can be impractical for languages with limited data. An intuitive solution is to use a related language adapter for the new language variety, but we observe that this solution can lead to sub-optimal performance. In this paper, we aim to improve the robustness of language adapters to uncovered languages without training new adapters. We find that ensembling multiple existing language adapters makes the fine-tuned model significantly more robust to other language varieties not included in these adapters. Building upon this observation, we propose Entropy Minimized Ensemble of Adapters (EMEA), a method that optimizes the ensemble weights of the pretrained language adapters for each test sentence by minimizing the entropy of its predictions. Experiments on three diverse groups of language varieties show that our method leads to significant improvements on both named entity recognition and part-of-speech tagging across all languages.

</p>
</details>

<details><summary><b>Mesh convolutional neural networks for wall shear stress estimation in 3D artery models</b>
<a href="https://arxiv.org/abs/2109.04797">arxiv:2109.04797</a>
&#x1F4C8; 22 <br>
<p>Julian Suk, Pim de Haan, Phillip Lippe, Christoph Brune, Jelmer M. Wolterink</p></summary>
<p>

**Abstract:** Computational fluid dynamics (CFD) is a valuable tool for personalised, non-invasive evaluation of hemodynamics in arteries, but its complexity and time-consuming nature prohibit large-scale use in practice. Recently, the use of deep learning for rapid estimation of CFD parameters like wall shear stress (WSS) on surface meshes has been investigated. However, existing approaches typically depend on a hand-crafted re-parametrisation of the surface mesh to match convolutional neural network architectures. In this work, we propose to instead use mesh convolutional neural networks that directly operate on the same finite-element surface mesh as used in CFD. We train and evaluate our method on two datasets of synthetic coronary artery models with and without bifurcation, using a ground truth obtained from CFD simulation. We show that our flexible deep learning model can accurately predict 3D WSS vectors on this surface mesh. Our method processes new meshes in less than 5 [s], consistently achieves a normalised mean absolute error of $\leq$ 1.6 [%], and peaks at 90.5 [%] median approximation accuracy over the held-out test set, comparing favourably to previously published work. This demonstrates the feasibility of CFD surrogate modelling using mesh convolutional neural networks for hemodynamic parameter estimation in artery models.

</p>
</details>

<details><summary><b>Entity-Based Knowledge Conflicts in Question Answering</b>
<a href="https://arxiv.org/abs/2109.05052">arxiv:2109.05052</a>
&#x1F4C8; 21 <br>
<p>Shayne Longpre, Kartik Perisetla, Anthony Chen, Nikhil Ramesh, Chris DuBois, Sameer Singh</p></summary>
<p>

**Abstract:** Knowledge-dependent tasks typically use two sources of knowledge: parametric, learned at training time, and contextual, given as a passage at inference time. To understand how models use these sources together, we formalize the problem of knowledge conflicts, where the contextual information contradicts the learned information. Analyzing the behaviour of popular models, we measure their over-reliance on memorized information (the cause of hallucinations), and uncover important factors that exacerbate this behaviour. Lastly, we propose a simple method to mitigate over-reliance on parametric knowledge, which minimizes hallucination, and improves out-of-distribution generalization by 4%-7%. Our findings demonstrate the importance for practitioners to evaluate model tendency to hallucinate rather than read, and show that our mitigation strategy encourages generalization to evolving information (i.e., time-dependent queries). To encourage these practices, we have released our framework for generating knowledge conflicts.

</p>
</details>

<details><summary><b>Unsupervised classification of simulated magnetospheric regions</b>
<a href="https://arxiv.org/abs/2109.04916">arxiv:2109.04916</a>
&#x1F4C8; 12 <br>
<p>Maria Elena Innocenti, Jorge Amaya, Joachim Raeder, Romain Dupuis, Banafsheh Ferdousi, Giovanni Lapenta</p></summary>
<p>

**Abstract:** In magnetospheric missions, burst mode data sampling should be triggered in the presence of processes of scientific or operational interest. We present an unsupervised classification method for magnetospheric regions, that could constitute the first-step of a multi-step method for the automatic identification of magnetospheric processes of interest. Our method is based on Self Organizing Maps (SOMs), and we test it preliminarily on data points from global magnetospheric simulations obtained with the OpenGGCM-CTIM-RCM code. The dimensionality of the data is reduced with Principal Component Analysis before classification. The classification relies exclusively on local plasma properties at the selected data points, without information on their neighborhood or on their temporal evolution. We classify the SOM nodes into an automatically selected number of classes, and we obtain clusters that map to well defined magnetospheric regions. We validate our classification results by plotting the classified data in the simulated space and by comparing with K-means classification. For the sake of result interpretability, we examine the SOM feature maps (magnetospheric variables are called features in the context of classification), and we use them to unlock information on the clusters. We repeat the classification experiments using different sets of features, we quantitatively compare different classification results, and we obtain insights on which magnetospheric variables make more effective features for unsupervised classification.

</p>
</details>

<details><summary><b>Topic-Aware Contrastive Learning for Abstractive Dialogue Summarization</b>
<a href="https://arxiv.org/abs/2109.04994">arxiv:2109.04994</a>
&#x1F4C8; 11 <br>
<p>Junpeng Liu, Yanyan Zou, Hainan Zhang, Hongshen Chen, Zhuoye Ding, Caixia Yuan, Xiaojie Wang</p></summary>
<p>

**Abstract:** Unlike well-structured text, such as news reports and encyclopedia articles, dialogue content often comes from two or more interlocutors, exchanging information with each other. In such a scenario, the topic of a conversation can vary upon progression and the key information for a certain topic is often scattered across multiple utterances of different speakers, which poses challenges to abstractly summarize dialogues. To capture the various topic information of a conversation and outline salient facts for the captured topics, this work proposes two topic-aware contrastive learning objectives, namely coherence detection and sub-summary generation objectives, which are expected to implicitly model the topic change and handle information scattering challenges for the dialogue summarization task. The proposed contrastive objectives are framed as auxiliary tasks for the primary dialogue summarization task, united via an alternative parameter updating strategy. Extensive experiments on benchmark datasets demonstrate that the proposed simple method significantly outperforms strong baselines and achieves new state-of-the-art performance. The code and trained models are publicly available via \href{https://github.com/Junpliu/ConDigSum}{https://github.com/Junpliu/ConDigSum}.

</p>
</details>

<details><summary><b>Efficient Contrastive Learning via Novel Data Augmentation and Curriculum Learning</b>
<a href="https://arxiv.org/abs/2109.05941">arxiv:2109.05941</a>
&#x1F4C8; 10 <br>
<p>Seonghyeon Ye, Jiseon Kim, Alice Oh</p></summary>
<p>

**Abstract:** We introduce EfficientCL, a memory-efficient continual pretraining method that applies contrastive learning with novel data augmentation and curriculum learning. For data augmentation, we stack two types of operation sequentially: cutoff and PCA jittering. While pretraining steps proceed, we apply curriculum learning by incrementing the augmentation degree for each difficulty step. After data augmentation is finished, contrastive learning is applied on projected embeddings of original and augmented examples. When finetuned on GLUE benchmark, our model outperforms baseline models, especially for sentence-level tasks. Additionally, this improvement is capable with only 70% of computational memory compared to the baseline model.

</p>
</details>

<details><summary><b>EfficientCLIP: Efficient Cross-Modal Pre-training by Ensemble Confident Learning and Language Modeling</b>
<a href="https://arxiv.org/abs/2109.04699">arxiv:2109.04699</a>
&#x1F4C8; 9 <br>
<p>Jue Wang, Haofan Wang, Jincan Deng, Weijia Wu, Debing Zhang</p></summary>
<p>

**Abstract:** While large scale pre-training has achieved great achievements in bridging the gap between vision and language, it still faces several challenges. First, the cost for pre-training is expensive. Second, there is no efficient way to handle the data noise which degrades model performance. Third, previous methods only leverage limited image-text paired data, while ignoring richer single-modal data, which may result in poor generalization to single-modal downstream tasks. In this work, we propose an EfficientCLIP method via Ensemble Confident Learning to obtain a less noisy data subset. Extra rich non-paired single-modal text data is used for boosting the generalization of text branch. We achieve the state-of-the-art performance on Chinese cross-modal retrieval tasks with only 1/10 training resources compared to CLIP and WenLan, while showing excellent generalization to single-modal tasks, including text retrieval and text classification.

</p>
</details>

<details><summary><b>Real-time multimodal image registration with partial intraoperative point-set data</b>
<a href="https://arxiv.org/abs/2109.05023">arxiv:2109.05023</a>
&#x1F4C8; 8 <br>
<p>Zachary M C Baum, Yipeng Hu, Dean C Barratt</p></summary>
<p>

**Abstract:** We present Free Point Transformer (FPT) - a deep neural network architecture for non-rigid point-set registration. Consisting of two modules, a global feature extraction module and a point transformation module, FPT does not assume explicit constraints based on point vicinity, thereby overcoming a common requirement of previous learning-based point-set registration methods. FPT is designed to accept unordered and unstructured point-sets with a variable number of points and uses a "model-free" approach without heuristic constraints. Training FPT is flexible and involves minimizing an intuitive unsupervised loss function, but supervised, semi-supervised, and partially- or weakly-supervised training are also supported. This flexibility makes FPT amenable to multimodal image registration problems where the ground-truth deformations are difficult or impossible to measure. In this paper, we demonstrate the application of FPT to non-rigid registration of prostate magnetic resonance (MR) imaging and sparsely-sampled transrectal ultrasound (TRUS) images. The registration errors were 4.71 mm and 4.81 mm for complete TRUS imaging and sparsely-sampled TRUS imaging, respectively. The results indicate superior accuracy to the alternative rigid and non-rigid registration algorithms tested and substantially lower computation time. The rapid inference possible with FPT makes it particularly suitable for applications where real-time registration is beneficial.

</p>
</details>

<details><summary><b>Self-Attention Channel Combinator Frontend for End-to-End Multichannel Far-field Speech Recognition</b>
<a href="https://arxiv.org/abs/2109.04783">arxiv:2109.04783</a>
&#x1F4C8; 8 <br>
<p>Rong Gong, Carl Quillen, Dushyant Sharma, Andrew Goderre, Jos√© La√≠nez, Ljubomir Milanoviƒá</p></summary>
<p>

**Abstract:** When a sufficiently large far-field training data is presented, jointly optimizing a multichannel frontend and an end-to-end (E2E) Automatic Speech Recognition (ASR) backend shows promising results. Recent literature has shown traditional beamformer designs, such as MVDR (Minimum Variance Distortionless Response) or fixed beamformers can be successfully integrated as the frontend into an E2E ASR system with learnable parameters. In this work, we propose the self-attention channel combinator (SACC) ASR frontend, which leverages the self-attention mechanism to combine multichannel audio signals in the magnitude spectral domain. Experiments conducted on a multichannel playback test data shows that the SACC achieved a 9.3% WERR compared to a state-of-the-art fixed beamformer-based frontend, both jointly optimized with a ContextNet-based ASR backend. We also demonstrate the connection between the SACC and the traditional beamformers, and analyze the intermediate outputs of the SACC.

</p>
</details>

<details><summary><b>Heterogeneous Graph Neural Networks for Keyphrase Generation</b>
<a href="https://arxiv.org/abs/2109.04703">arxiv:2109.04703</a>
&#x1F4C8; 8 <br>
<p>Jiacheng Ye, Ruijian Cai, Tao Gui, Qi Zhang</p></summary>
<p>

**Abstract:** The encoder-decoder framework achieves state-of-the-art results in keyphrase generation (KG) tasks by predicting both present keyphrases that appear in the source document and absent keyphrases that do not. However, relying solely on the source document can result in generating uncontrollable and inaccurate absent keyphrases. To address these problems, we propose a novel graph-based method that can capture explicit knowledge from related references. Our model first retrieves some document-keyphrases pairs similar to the source document from a pre-defined index as references. Then a heterogeneous graph is constructed to capture relationships of different granularities between the source document and its references. To guide the decoding process, a hierarchical attention and copy mechanism is introduced, which directly copies appropriate words from both the source document and its references based on their relevance and significance. The experimental results on multiple KG benchmarks show that the proposed model achieves significant improvements against other baseline models, especially with regard to the absent keyphrase prediction.

</p>
</details>

<details><summary><b>Scalable Font Reconstruction with Dual Latent Manifolds</b>
<a href="https://arxiv.org/abs/2109.06627">arxiv:2109.06627</a>
&#x1F4C8; 7 <br>
<p>Nikita Srivatsan, Si Wu, Jonathan T. Barron, Taylor Berg-Kirkpatrick</p></summary>
<p>

**Abstract:** We propose a deep generative model that performs typography analysis and font reconstruction by learning disentangled manifolds of both font style and character shape. Our approach enables us to massively scale up the number of character types we can effectively model compared to previous methods. Specifically, we infer separate latent variables representing character and font via a pair of inference networks which take as input sets of glyphs that either all share a character type, or belong to the same font. This design allows our model to generalize to characters that were not observed during training time, an important task in light of the relative sparsity of most fonts. We also put forward a new loss, adapted from prior work that measures likelihood using an adaptive distribution in a projected space, resulting in more natural images without requiring a discriminator. We evaluate on the task of font reconstruction over various datasets representing character types of many languages, and compare favorably to modern style transfer systems according to both automatic and manually-evaluated metrics.

</p>
</details>

<details><summary><b>Inverse design of 3d molecular structures with conditional generative neural networks</b>
<a href="https://arxiv.org/abs/2109.04824">arxiv:2109.04824</a>
&#x1F4C8; 7 <br>
<p>Niklas W. A. Gebauer, Michael Gastegger, Stefaan S. P. Hessmann, Klaus-Robert M√ºller, Kristof T. Sch√ºtt</p></summary>
<p>

**Abstract:** The rational design of molecules with desired properties is a long-standing challenge in chemistry. Generative neural networks have emerged as a powerful approach to sample novel molecules from a learned distribution. Here, we propose a conditional generative neural network for 3d molecular structures with specified structural and chemical properties. This approach is agnostic to chemical bonding and enables targeted sampling of novel molecules from conditional distributions, even in domains where reference calculations are sparse. We demonstrate the utility of our method for inverse design by generating molecules with specified composition or motifs, discovering particularly stable molecules, and jointly targeting multiple electronic properties beyond the training regime.

</p>
</details>

<details><summary><b>Co-Correcting: Noise-tolerant Medical Image Classification via mutual Label Correction</b>
<a href="https://arxiv.org/abs/2109.05159">arxiv:2109.05159</a>
&#x1F4C8; 6 <br>
<p>Jiarun Liu, Ruirui Li, Chuan Sun</p></summary>
<p>

**Abstract:** With the development of deep learning, medical image classification has been significantly improved. However, deep learning requires massive data with labels. While labeling the samples by human experts is expensive and time-consuming, collecting labels from crowd-sourcing suffers from the noises which may degenerate the accuracy of classifiers. Therefore, approaches that can effectively handle label noises are highly desired. Unfortunately, recent progress on handling label noise in deep learning has gone largely unnoticed by the medical image. To fill the gap, this paper proposes a noise-tolerant medical image classification framework named Co-Correcting, which significantly improves classification accuracy and obtains more accurate labels through dual-network mutual learning, label probability estimation, and curriculum label correcting. On two representative medical image datasets and the MNIST dataset, we test six latest Learning-with-Noisy-Labels methods and conduct comparative studies. The experiments show that Co-Correcting achieves the best accuracy and generalization under different noise ratios in various tasks. Our project can be found at: https://github.com/JiarunLiu/Co-Correcting.

</p>
</details>

<details><summary><b>FBERT: A Neural Transformer for Identifying Offensive Content</b>
<a href="https://arxiv.org/abs/2109.05074">arxiv:2109.05074</a>
&#x1F4C8; 6 <br>
<p>Diptanu Sarkar, Marcos Zampieri, Tharindu Ranasinghe, Alexander Ororbia</p></summary>
<p>

**Abstract:** Transformer-based models such as BERT, XLNET, and XLM-R have achieved state-of-the-art performance across various NLP tasks including the identification of offensive language and hate speech, an important problem in social media. In this paper, we present fBERT, a BERT model retrained on SOLID, the largest English offensive language identification corpus available with over $1.4$ million offensive instances. We evaluate fBERT's performance on identifying offensive content on multiple English datasets and we test several thresholds for selecting instances from SOLID. The fBERT model will be made freely available to the community.

</p>
</details>

<details><summary><b>Distantly-Supervised Named Entity Recognition with Noise-Robust Learning and Language Model Augmented Self-Training</b>
<a href="https://arxiv.org/abs/2109.05003">arxiv:2109.05003</a>
&#x1F4C8; 6 <br>
<p>Yu Meng, Yunyi Zhang, Jiaxin Huang, Xuan Wang, Yu Zhang, Heng Ji, Jiawei Han</p></summary>
<p>

**Abstract:** We study the problem of training named entity recognition (NER) models using only distantly-labeled data, which can be automatically obtained by matching entity mentions in the raw text with entity types in a knowledge base. The biggest challenge of distantly-supervised NER is that the distant supervision may induce incomplete and noisy labels, rendering the straightforward application of supervised learning ineffective. In this paper, we propose (1) a noise-robust learning scheme comprised of a new loss function and a noisy label removal step, for training NER models on distantly-labeled data, and (2) a self-training method that uses contextualized augmentations created by pre-trained language models to improve the generalization ability of the NER model. On three benchmark datasets, our method achieves superior performance, outperforming existing distantly-supervised NER models by significant margins.

</p>
</details>

<details><summary><b>Detection of GAN-synthesized street videos</b>
<a href="https://arxiv.org/abs/2109.04991">arxiv:2109.04991</a>
&#x1F4C8; 6 <br>
<p>Omran Alamayreh, Mauro Barni</p></summary>
<p>

**Abstract:** Research on the detection of AI-generated videos has focused almost exclusively on face videos, usually referred to as deepfakes. Manipulations like face swapping, face reenactment and expression manipulation have been the subject of an intense research with the development of a number of efficient tools to distinguish artificial videos from genuine ones. Much less attention has been paid to the detection of artificial non-facial videos. Yet, new tools for the generation of such kind of videos are being developed at a fast pace and will soon reach the quality level of deepfake videos. The goal of this paper is to investigate the detectability of a new kind of AI-generated videos framing driving street sequences (here referred to as DeepStreets videos), which, by their nature, can not be analysed with the same tools used for facial deepfakes. Specifically, we present a simple frame-based detector, achieving very good performance on state-of-the-art DeepStreets videos generated by the Vid2vid architecture. Noticeably, the detector retains very good performance on compressed videos, even when the compression level used during training does not match that used for the test videos.

</p>
</details>

<details><summary><b>Heading Estimation Using Ultra-Wideband Received Signal Strength and Gaussian Processes</b>
<a href="https://arxiv.org/abs/2109.04868">arxiv:2109.04868</a>
&#x1F4C8; 6 <br>
<p>Daniil Lisus, Charles Champagne Cossette, Mohammed Shalaby, James Richard Forbes</p></summary>
<p>

**Abstract:** It is essential that a robot has the ability to determine its position and orientation to execute tasks autonomously. Heading estimation is especially challenging in indoor environments where magnetic distortions make magnetometer-based heading estimation difficult. Ultra-wideband (UWB) transceivers are common in indoor localization problems. This letter experimentally demonstrates how to use UWB range and received signal strength (RSS) measurements to estimate robot heading. The RSS of a UWB antenna varies with its orientation. As such, a Gaussian process (GP) is used to learn a data-driven relationship from UWB range and RSS inputs to orientation outputs. Combined with a gyroscope in an invariant extended Kalman filter, this realizes a heading estimation method that uses only UWB and gyroscope measurements.

</p>
</details>

<details><summary><b>Artificial Text Detection via Examining the Topology of Attention Maps</b>
<a href="https://arxiv.org/abs/2109.04825">arxiv:2109.04825</a>
&#x1F4C8; 6 <br>
<p>Laida Kushnareva, Daniil Cherniavskii, Vladislav Mikhailov, Ekaterina Artemova, Serguei Barannikov, Alexander Bernstein, Irina Piontkovskaya, Dmitri Piontkovski, Evgeny Burnaev</p></summary>
<p>

**Abstract:** The impressive capabilities of recent generative models to create texts that are challenging to distinguish from the human-written ones can be misused for generating fake news, product reviews, and even abusive content. Despite the prominent performance of existing methods for artificial text detection, they still lack interpretability and robustness towards unseen models. To this end, we propose three novel types of interpretable topological features for this task based on Topological Data Analysis (TDA) which is currently understudied in the field of NLP. We empirically show that the features derived from the BERT model outperform count- and neural-based baselines up to 10\% on three common datasets, and tend to be the most robust towards unseen GPT-style generation models as opposed to existing methods. The probing analysis of the features reveals their sensitivity to the surface and syntactic properties. The results demonstrate that TDA is a promising line with respect to NLP tasks, specifically the ones that incorporate surface and structural information.

</p>
</details>

<details><summary><b>Generating Self-Contained and Summary-Centric Question Answer Pairs via Differentiable Reward Imitation Learning</b>
<a href="https://arxiv.org/abs/2109.04689">arxiv:2109.04689</a>
&#x1F4C8; 6 <br>
<p>Li Zhou, Kevin Small, Yong Zhang, Sandeep Atluri</p></summary>
<p>

**Abstract:** Motivated by suggested question generation in conversational news recommendation systems, we propose a model for generating question-answer pairs (QA pairs) with self-contained, summary-centric questions and length-constrained, article-summarizing answers. We begin by collecting a new dataset of news articles with questions as titles and pairing them with summaries of varying length. This dataset is used to learn a QA pair generation model producing summaries as answers that balance brevity with sufficiency jointly with their corresponding questions. We then reinforce the QA pair generation process with a differentiable reward function to mitigate exposure bias, a common problem in natural language generation. Both automatic metrics and human evaluation demonstrate these QA pairs successfully capture the central gists of the articles and achieve high answer accuracy.

</p>
</details>

<details><summary><b>Investigating Numeracy Learning Ability of a Text-to-Text Transfer Model</b>
<a href="https://arxiv.org/abs/2109.04672">arxiv:2109.04672</a>
&#x1F4C8; 6 <br>
<p>Kuntal Kumar Pal, Chitta Baral</p></summary>
<p>

**Abstract:** The transformer-based pre-trained language models have been tremendously successful in most of the conventional NLP tasks. But they often struggle in those tasks where numerical understanding is required. Some possible reasons can be the tokenizers and pre-training objectives which are not specifically designed to learn and preserve numeracy. Here we investigate the ability of text-to-text transfer learning model (T5), which has outperformed its predecessors in the conventional NLP tasks, to learn numeracy. We consider four numeracy tasks: numeration, magnitude order prediction, finding minimum and maximum in a series, and sorting. We find that, although T5 models perform reasonably well in the interpolation setting, they struggle considerably in the extrapolation setting across all four tasks.

</p>
</details>

<details><summary><b>Making Table Understanding Work in Practice</b>
<a href="https://arxiv.org/abs/2109.05173">arxiv:2109.05173</a>
&#x1F4C8; 5 <br>
<p>Madelon Hulsebos, Sneha Gathani, James Gale, Isil Dillig, Paul Groth, √áaƒüatay Demiralp</p></summary>
<p>

**Abstract:** Understanding the semantics of tables at scale is crucial for tasks like data integration, preparation, and search. Table understanding methods aim at detecting a table's topic, semantic column types, column relations, or entities. With the rise of deep learning, powerful models have been developed for these tasks with excellent accuracy on benchmarks. However, we observe that there exists a gap between the performance of these models on these benchmarks and their applicability in practice. In this paper, we address the question: what do we need for these models to work in practice?
  We discuss three challenges of deploying table understanding models and propose a framework to address them. These challenges include 1) difficulty in customizing models to specific domains, 2) lack of training data for typical database tables often found in enterprises, and 3) lack of confidence in the inferences made by models. We present SigmaTyper which implements this framework for the semantic column type detection task. SigmaTyper encapsulates a hybrid model trained on GitTables and integrates a lightweight human-in-the-loop approach to customize the model. Lastly, we highlight avenues for future research that further close the gap towards making table understanding effective in practice.

</p>
</details>

<details><summary><b>Box Embeddings: An open-source library for representation learning using geometric structures</b>
<a href="https://arxiv.org/abs/2109.04997">arxiv:2109.04997</a>
&#x1F4C8; 5 <br>
<p>Tejas Chheda, Purujit Goyal, Trang Tran, Dhruvesh Patel, Michael Boratko, Shib Sankar Dasgupta, Andrew McCallum</p></summary>
<p>

**Abstract:** A major factor contributing to the success of modern representation learning is the ease of performing various vector operations. Recently, objects with geometric structures (eg. distributions, complex or hyperbolic vectors, or regions such as cones, disks, or boxes) have been explored for their alternative inductive biases and additional representational capacities. In this work, we introduce Box Embeddings, a Python library that enables researchers to easily apply and extend probabilistic box embeddings.

</p>
</details>

<details><summary><b>Unsupervised Change Detection in Hyperspectral Images using Feature Fusion Deep Convolutional Autoencoders</b>
<a href="https://arxiv.org/abs/2109.04990">arxiv:2109.04990</a>
&#x1F4C8; 5 <br>
<p>Debasrita Chakraborty, Ashish Ghosh</p></summary>
<p>

**Abstract:** Binary change detection in bi-temporal co-registered hyperspectral images is a challenging task due to a large number of spectral bands present in the data. Researchers, therefore, try to handle it by reducing dimensions. The proposed work aims to build a novel feature extraction system using a feature fusion deep convolutional autoencoder for detecting changes between a pair of such bi-temporal co-registered hyperspectral images. The feature fusion considers features across successive levels and multiple receptive fields and therefore adds a competitive edge over the existing feature extraction methods. The change detection technique described is completely unsupervised and is much more elegant than other supervised or semi-supervised methods which require some amount of label information. Different methods have been applied to the extracted features to find the changes in the two images and it is found that the proposed method clearly outperformed the state of the art methods in unsupervised change detection for all the datasets.

</p>
</details>

<details><summary><b>Examining Cross-lingual Contextual Embeddings with Orthogonal Structural Probes</b>
<a href="https://arxiv.org/abs/2109.04921">arxiv:2109.04921</a>
&#x1F4C8; 5 <br>
<p>Tomasz Limisiewicz, David Mareƒçek</p></summary>
<p>

**Abstract:** State-of-the-art contextual embeddings are obtained from large language models available only for a few languages. For others, we need to learn representations using a multilingual model. There is an ongoing debate on whether multilingual embeddings can be aligned in a space shared across many languages. The novel Orthogonal Structural Probe (Limisiewicz and Mareƒçek, 2021) allows us to answer this question for specific linguistic features and learn a projection based only on mono-lingual annotated datasets. We evaluate syntactic (UD) and lexical (WordNet) structural information encoded inmBERT's contextual representations for nine diverse languages. We observe that for languages closely related to English, no transformation is needed. The evaluated information is encoded in a shared cross-lingual embedding space. For other languages, it is beneficial to apply orthogonal transformation learned separately for each language. We successfully apply our findings to zero-shot and few-shot cross-lingual parsing.

</p>
</details>

<details><summary><b>Improving Multilingual Translation by Representation and Gradient Regularization</b>
<a href="https://arxiv.org/abs/2109.04778">arxiv:2109.04778</a>
&#x1F4C8; 5 <br>
<p>Yilin Yang, Akiko Eriguchi, Alexandre Muzio, Prasad Tadepalli, Stefan Lee, Hany Hassan</p></summary>
<p>

**Abstract:** Multilingual Neural Machine Translation (NMT) enables one model to serve all translation directions, including ones that are unseen during training, i.e. zero-shot translation. Despite being theoretically attractive, current models often produce low quality translations -- commonly failing to even produce outputs in the right target language. In this work, we observe that off-target translation is dominant even in strong multilingual systems, trained on massive multilingual corpora. To address this issue, we propose a joint approach to regularize NMT models at both representation-level and gradient-level. At the representation level, we leverage an auxiliary target language prediction task to regularize decoder outputs to retain information about the target language. At the gradient level, we leverage a small amount of direct data (in thousands of sentence pairs) to regularize model gradients. Our results demonstrate that our approach is highly effective in both reducing off-target translation occurrences and improving zero-shot translation performance by +5.59 and +10.38 BLEU on WMT and OPUS datasets respectively. Moreover, experiments show that our method also works well when the small amount of direct data is not available.

</p>
</details>

<details><summary><b>6MapNet: Representing soccer players from tracking data by a triplet network</b>
<a href="https://arxiv.org/abs/2109.04720">arxiv:2109.04720</a>
&#x1F4C8; 5 <br>
<p>Hyunsung Kim, Jihun Kim, Dongwook Chung, Jonghyun Lee, Jinsung Yoon, Sang-Ki Ko</p></summary>
<p>

**Abstract:** Although the values of individual soccer players have become astronomical, subjective judgments still play a big part in the player analysis. Recently, there have been new attempts to quantitatively grasp players' styles using video-based event stream data. However, they have some limitations in scalability due to high annotation costs and sparsity of event stream data. In this paper, we build a triplet network named 6MapNet that can effectively capture the movement styles of players using in-game GPS data. Without any annotation of soccer-specific actions, we use players' locations and velocities to generate two types of heatmaps. Our subnetworks then map these heatmap pairs into feature vectors whose similarity corresponds to the actual similarity of playing styles. The experimental results show that players can be accurately identified with only a small number of matches by our method.

</p>
</details>

<details><summary><b>Life, the universe and the hidden meaning of everything</b>
<a href="https://arxiv.org/abs/2109.10241">arxiv:2109.10241</a>
&#x1F4C8; 4 <br>
<p>Zhi-Wei Wang, Samuel L. Braunstein</p></summary>
<p>

**Abstract:** It is hard to look at the universe and not wonder about the meaning, of, well, everything. A natural question is whether what we see is a sign of intelligent design. The antithesis of design would be a random universe or, assuming laws of physics, one whose fundamental physical parameters were randomly selected, but conditioned on life (ourselves) being here to observe it. In unpublished work, the British physicist Dennis Sciama argued that such a randomly selected universe would display a statistical signature. He concluded that a random universe would almost certainly have parameters only just allowing for the possibility of life. Here we consider whether this signature is definitive. We find that with plausible additional assumptions Sciama's signature would appear to reverse: Were our universe random, it could give the false impression of being intelligently designed, with the fundamental constants appearing to be fine-tuned to a strong probability for life to emerge and be maintained.

</p>
</details>

<details><summary><b>Photon detection probability prediction using one-dimensional generative neural network</b>
<a href="https://arxiv.org/abs/2109.07277">arxiv:2109.07277</a>
&#x1F4C8; 4 <br>
<p>Wei Mu, Alexander I. Himmel, Bryan Ramson</p></summary>
<p>

**Abstract:** Photon detection is important for liquid argon detectors for direct dark matter searches or neutrino property measurements. Precise simulation of photon transport is widely used to understand the probability of photon detection in liquid argon detectors. Traditional photon transport simulation, which tracks every photon using theGeant4simulation toolkit, is a major computational challenge for kilo-tonne-scale liquid argon detectors and GeV-level energy depositions. In this work, we propose a one-dimensional generative model which efficiently generates features using an OuterProduct-layer. This model bypasses photon transport simulation and predicts the number of photons detected by particular photon detectors at the same level of detail as theGeant4simulation. The application to simulating photon detection systems in kilo-tonne-scale liquid argon detectors demonstrates this novel generative model is able to reproduceGeant4simulation with good accuracy and 20 to 50 times faster. This generative model can be used to quickly predict photon detection probability in huge liquid argon detectors like ProtoDUNE or DUNE.

</p>
</details>

<details><summary><b>TopicRefine: Joint Topic Prediction and Dialogue Response Generation for Multi-turn End-to-End Dialogue System</b>
<a href="https://arxiv.org/abs/2109.05187">arxiv:2109.05187</a>
&#x1F4C8; 4 <br>
<p>Hongru Wang, Mingyu Cui, Zimo Zhou, Gabriel Pui Cheong Fung, Kam-Fai Wong</p></summary>
<p>

**Abstract:** A multi-turn dialogue always follows a specific topic thread, and topic shift at the discourse level occurs naturally as the conversation progresses, necessitating the model's ability to capture different topics and generate topic-aware responses. Previous research has either predicted the topic first and then generated the relevant response, or simply applied the attention mechanism to all topics, ignoring the joint distribution of the topic prediction and response generation models and resulting in uncontrollable and unrelated responses. In this paper, we propose a joint framework with a topic refinement mechanism to learn these two tasks simultaneously. Specifically, we design a three-pass iteration mechanism to generate coarse response first, then predict corresponding topics, and finally generate refined response conditioned on predicted topics. Moreover, we utilize GPT2DoubleHeads and BERT for the topic prediction task respectively, aiming to investigate the effects of joint learning and the understanding ability of GPT model. Experimental results demonstrate that our proposed framework achieves new state-of-the-art performance at response generation task and the great potential understanding capability of GPT model.

</p>
</details>

<details><summary><b>Preliminary Wildfire Detection Using State-of-the-art PTZ (Pan, Tilt, Zoom) Camera Technology and Convolutional Neural Networks</b>
<a href="https://arxiv.org/abs/2109.05083">arxiv:2109.05083</a>
&#x1F4C8; 4 <br>
<p>Samarth Shah</p></summary>
<p>

**Abstract:** Wildfires are uncontrolled fires in the environment that can be caused by humans or nature. In 2020 alone, wildfires in California have burned 4.2 million acres, damaged 10,500 buildings or structures, and killed more than 31 people, exacerbated by climate change and a rise in average global temperatures. This also means there has been an increase in the costs of extinguishing these treacherous wildfires. The objective of the research is to detect forest fires in their earlier stages to prevent them from spreading, prevent them from causing damage to a variety of things, and most importantly, reduce or eliminate the chances of someone dying from a wildfire. A fire detection system should be efficient and accurate with respect to extinguishing wildfires in their earlier stages to prevent the spread of them along with their consequences. Computer Vision is potentially a more reliable, fast, and widespread method we need. The current research in the field of preliminary fire detection has several problems related to unrepresentative data being used to train models and their existing varied amounts of label imbalance in the classes of their dataset. We propose a more representative and evenly distributed data through better settings, lighting, atmospheres, etc., and class distribution in the entire dataset. After thoroughly examining the results of this research, it can be inferred that they supported the datasets strengths by being a viable resource when tested in the real world on unfamiliar data. This is evident since as the model trains on the dataset, it is able to generalize on it, hence confirming this is a viable Machine Learning setting that has practical impact.

</p>
</details>

<details><summary><b>Integrating Approaches to Word Representation</b>
<a href="https://arxiv.org/abs/2109.04876">arxiv:2109.04876</a>
&#x1F4C8; 4 <br>
<p>Yuval Pinter</p></summary>
<p>

**Abstract:** The problem of representing the atomic elements of language in modern neural learning systems is one of the central challenges of the field of natural language processing. I present a survey of the distributional, compositional, and relational approaches to addressing this task, and discuss various means of integrating them into systems, with special emphasis on the word level and the out-of-vocabulary phenomenon.

</p>
</details>

<details><summary><b>FR-Detect: A Multi-Modal Framework for Early Fake News Detection on Social Media Using Publishers Features</b>
<a href="https://arxiv.org/abs/2109.04835">arxiv:2109.04835</a>
&#x1F4C8; 4 <br>
<p>Ali Jarrahi, Leila Safari</p></summary>
<p>

**Abstract:** In recent years, with the expansion of the Internet and attractive social media infrastructures, people prefer to follow the news through these media. Despite the many advantages of these media in the news field, the lack of any control and verification mechanism has led to the spread of fake news, as one of the most important threats to democracy, economy, journalism and freedom of expression. Designing and using automatic methods to detect fake news on social media has become a significant challenge. In this paper, we examine the publishers' role in detecting fake news on social media. We also suggest a high accurate multi-modal framework, namely FR-Detect, using user-related and content-related features with early detection capability. For this purpose, two new user-related features, namely Activity Credibility and Influence, have been introduced for publishers. Furthermore, a sentence-level convolutional neural network is provided to combine these features with latent textual content features properly. Experimental results have shown that the publishers' features can improve the performance of content-based models by up to 13% and 29% in accuracy and F1-score, respectively.

</p>
</details>

<details><summary><b>An Evaluation Dataset and Strategy for Building Robust Multi-turn Response Selection Model</b>
<a href="https://arxiv.org/abs/2109.04834">arxiv:2109.04834</a>
&#x1F4C8; 4 <br>
<p>Kijong Han, Seojin Lee, Wooin Lee, Joosung Lee, Dong-hun Lee</p></summary>
<p>

**Abstract:** Multi-turn response selection models have recently shown comparable performance to humans in several benchmark datasets. However, in the real environment, these models often have weaknesses, such as making incorrect predictions based heavily on superficial patterns without a comprehensive understanding of the context. For example, these models often give a high score to the wrong response candidate containing several keywords related to the context but using the inconsistent tense. In this study, we analyze the weaknesses of the open-domain Korean Multi-turn response selection models and publish an adversarial dataset to evaluate these weaknesses. We also suggest a strategy to build a robust model in this adversarial environment.

</p>
</details>

<details><summary><b>Automated Machine Learning, Bounded Rationality, and Rational Metareasoning</b>
<a href="https://arxiv.org/abs/2109.04744">arxiv:2109.04744</a>
&#x1F4C8; 4 <br>
<p>Eyke H√ºllermeier, Felix Mohr, Alexander Tornede, Marcel Wever</p></summary>
<p>

**Abstract:** The notion of bounded rationality originated from the insight that perfectly rational behavior cannot be realized by agents with limited cognitive or computational resources. Research on bounded rationality, mainly initiated by Herbert Simon, has a longstanding tradition in economics and the social sciences, but also plays a major role in modern AI and intelligent agent design. Taking actions under bounded resources requires an agent to reflect on how to use these resources in an optimal way - hence, to reason and make decisions on a meta-level. In this paper, we will look at automated machine learning (AutoML) and related problems from the perspective of bounded rationality, essentially viewing an AutoML tool as an agent that has to train a model on a given set of data, and the search for a good way of doing so (a suitable "ML pipeline") as deliberation on a meta-level.

</p>
</details>

<details><summary><b>A Simple and Effective Method To Eliminate the Self Language Bias in Multilingual Representations</b>
<a href="https://arxiv.org/abs/2109.04727">arxiv:2109.04727</a>
&#x1F4C8; 4 <br>
<p>Ziyi Yang, Yinfei Yang, Daniel Cer, Eric Darve</p></summary>
<p>

**Abstract:** Language agnostic and semantic-language information isolation is an emerging research direction for multilingual representations models. We explore this problem from a novel angle of geometric algebra and semantic space. A simple but highly effective method "Language Information Removal (LIR)" factors out language identity information from semantic related components in multilingual representations pre-trained on multi-monolingual data. A post-training and model-agnostic method, LIR only uses simple linear operations, e.g. matrix factorization and orthogonal projection. LIR reveals that for weak-alignment multilingual systems, the principal components of semantic spaces primarily encodes language identity information. We first evaluate the LIR on a cross-lingual question answer retrieval task (LAReQA), which requires the strong alignment for the multilingual embedding space. Experiment shows that LIR is highly effectively on this task, yielding almost 100% relative improvement in MAP for weak-alignment models. We then evaluate the LIR on Amazon Reviews and XEVAL dataset, with the observation that removing language information is able to improve the cross-lingual transfer performance.

</p>
</details>

<details><summary><b>Combining GEDI and Sentinel-2 for wall-to-wall mapping of tall and short crops</b>
<a href="https://arxiv.org/abs/2109.06972">arxiv:2109.06972</a>
&#x1F4C8; 3 <br>
<p>Stefania Di Tommaso, Sherrie Wang, David B. Lobell</p></summary>
<p>

**Abstract:** High resolution crop type maps are an important tool for improving food security, and remote sensing is increasingly used to create such maps in regions that possess ground truth labels for model training. However, these labels are absent in many regions, and models trained in other regions on typical satellite features, such as those from optical sensors, often exhibit low performance when transferred. Here we explore the use of NASA's Global Ecosystem Dynamics Investigation (GEDI) spaceborne lidar instrument, combined with Sentinel-2 optical data, for crop type mapping. Using data from three major cropped regions (in China, France, and the United States) we first demonstrate that GEDI energy profiles are capable of reliably distinguishing maize, a crop typically above 2m in height, from crops like rice and soybean that are shorter. We further show that these GEDI profiles provide much more invariant features across geographies compared to spectral and phenological features detected by passive optical sensors. GEDI is able to distinguish maize from other crops within each region with accuracies higher than 84%, and able to transfer across regions with accuracies higher than 82% compared to 64% for transfer of optical features. Finally, we show that GEDI profiles can be used to generate training labels for models based on optical imagery from Sentinel-2, thereby enabling the creation of 10m wall-to-wall maps of tall versus short crops in label-scarce regions. As maize is the second most widely grown crop in the world and often the only tall crop grown within a landscape, we conclude that GEDI offers great promise for improving global crop type maps.

</p>
</details>

<details><summary><b>Global and Local Interpretation of black-box Machine Learning models to determine prognostic factors from early COVID-19 data</b>
<a href="https://arxiv.org/abs/2109.05087">arxiv:2109.05087</a>
&#x1F4C8; 3 <br>
<p>Ananya Jana, Carlos D. Minacapelli, Vinod Rustgi, Dimitris Metaxas</p></summary>
<p>

**Abstract:** The COVID-19 corona virus has claimed 4.1 million lives, as of July 24, 2021. A variety of machine learning models have been applied to related data to predict important factors such as the severity of the disease, infection rate and discover important prognostic factors. Often the usefulness of the findings from the use of these techniques is reduced due to lack of method interpretability. Some recent progress made on the interpretability of machine learning models has the potential to unravel more insights while using conventional machine learning models. In this work, we analyze COVID-19 blood work data with some of the popular machine learning models; then we employ state-of-the-art post-hoc local interpretability techniques(e.g.- SHAP, LIME), and global interpretability techniques(e.g. - symbolic metamodeling) to the trained black-box models to draw interpretable conclusions. In the gamut of machine learning algorithms, regressions remain one of the simplest and most explainable models with clear mathematical formulation. We explore one of the most recent techniques called symbolic metamodeling to find the mathematical expression of the machine learning models for COVID-19. We identify Acute Kidney Injury (AKI), initial Albumin level (ALBI), Aspartate aminotransferase (ASTI), Total Bilirubin initial(TBILI) and D-Dimer initial (DIMER) as major prognostic factors of the disease severity. Our contributions are- (i) uncover the underlying mathematical expression for the black-box models on COVID-19 severity prediction task (ii) we are the first to apply symbolic metamodeling to this task, and (iii) discover important features and feature interactions.

</p>
</details>

<details><summary><b>Optimizing a domestic battery and solar photovoltaic system with deep reinforcement learning</b>
<a href="https://arxiv.org/abs/2109.05024">arxiv:2109.05024</a>
&#x1F4C8; 3 <br>
<p>Alexander J. M. Kell, A. Stephen McGough, Matthew Forshaw</p></summary>
<p>

**Abstract:** A lowering in the cost of batteries and solar PV systems has led to a high uptake of solar battery home systems. In this work, we use the deep deterministic policy gradient algorithm to optimise the charging and discharging behaviour of a battery within such a system. Our approach outputs a continuous action space when it charges and discharges the battery, and can function well in a stochastic environment. We show good performance of this algorithm by lowering the expenditure of a single household on electricity to almost \$1AUD for large batteries across selected weeks within a year.

</p>
</details>

<details><summary><b>Fairness without the sensitive attribute via Causal Variational Autoencoder</b>
<a href="https://arxiv.org/abs/2109.04999">arxiv:2109.04999</a>
&#x1F4C8; 3 <br>
<p>Vincent Grari, Sylvain Lamprier, Marcin Detyniecki</p></summary>
<p>

**Abstract:** In recent years, most fairness strategies in machine learning models focus on mitigating unwanted biases by assuming that the sensitive information is observed. However this is not always possible in practice. Due to privacy purposes and var-ious regulations such as RGPD in EU, many personal sensitive attributes are frequently not collected. We notice a lack of approaches for mitigating bias in such difficult settings, in particular for achieving classical fairness objectives such as Demographic Parity and Equalized Odds. By leveraging recent developments for approximate inference, we propose an approach to fill this gap. Based on a causal graph, we rely on a new variational auto-encoding based framework named SRCVAE to infer a sensitive information proxy, that serve for bias mitigation in an adversarial fairness approach. We empirically demonstrate significant improvements over existing works in the field. We observe that the generated proxy's latent space recovers sensitive information and that our approach achieves a higher accuracy while obtaining the same level of fairness on two real datasets, as measured using com-mon fairness definitions.

</p>
</details>

<details><summary><b>Saliency Guided Experience Packing for Replay in Continual Learning</b>
<a href="https://arxiv.org/abs/2109.04954">arxiv:2109.04954</a>
&#x1F4C8; 3 <br>
<p>Gobinda Saha, Kaushik Roy</p></summary>
<p>

**Abstract:** Artificial learning systems aspire to mimic human intelligence by continually learning from a stream of tasks without forgetting past knowledge. One way to enable such learning is to store past experiences in the form of input examples in episodic memory and replay them when learning new tasks. However, performance of such method suffers as the size of the memory becomes smaller. In this paper, we propose a new approach for experience replay, where we select the past experiences by looking at the saliency maps which provide visual explanations for the model's decision. Guided by these saliency maps, we pack the memory with only the parts or patches of the input images important for the model's prediction. While learning a new task, we replay these memory patches with appropriate zero-padding to remind the model about its past decisions. We evaluate our algorithm on diverse image classification datasets and report better performance than the state-of-the-art approaches. With qualitative and quantitative analyses we show that our method captures richer summary of past experiences without any memory increase, and hence performs well with small episodic memory.

</p>
</details>

<details><summary><b>MultiAzterTest: a Multilingual Analyzer on Multiple Levels of Language for Readability Assessment</b>
<a href="https://arxiv.org/abs/2109.04870">arxiv:2109.04870</a>
&#x1F4C8; 3 <br>
<p>Kepa Bengoetxea, Itziar Gonzalez-Dios</p></summary>
<p>

**Abstract:** Readability assessment is the task of determining how difficult or easy a text is or which level/grade it has. Traditionally, language dependent readability formula have been used, but these formulae take few text characteristics into account. However, Natural Language Processing (NLP) tools that assess the complexity of texts are able to measure more different features and can be adapted to different languages. In this paper, we present the MultiAzterTest tool: (i) an open source NLP tool which analyzes texts on over 125 measures of cohesion,language, and readability for English, Spanish and Basque, but whose architecture is designed to easily adapt other languages; (ii) readability assessment classifiers that improve the performance of Coh-Metrix in English, Coh-Metrix-Esp in Spanish and ErreXail in Basque; iii) a web tool. MultiAzterTest obtains 90.09 % in accuracy when classifying into three reading levels (elementary, intermediate, and advanced) in English and 95.50 % in Basque and 90 % in Spanish when classifying into two reading levels (simple and complex) using a SMO classifier. Using cross-lingual features, MultiAzterTest also obtains competitive results above all in a complex vs simple distinction.

</p>
</details>

<details><summary><b>Active learning for reducing labeling effort in text classification tasks</b>
<a href="https://arxiv.org/abs/2109.04847">arxiv:2109.04847</a>
&#x1F4C8; 3 <br>
<p>Pieter Floris Jacobs, Gideon Maillette de Buy Wenniger, Marco Wiering, Lambert Schomaker</p></summary>
<p>

**Abstract:** Labeling data can be an expensive task as it is usually performed manually by domain experts. This is cumbersome for deep learning, as it is dependent on large labeled datasets. Active learning (AL) is a paradigm that aims to reduce labeling effort by only using the data which the used model deems most informative. Little research has been done on AL in a text classification setting and next to none has involved the more recent, state-of-the-art Natural Language Processing (NLP) models. Here, we present an empirical study that compares different uncertainty-based algorithms with BERT$_{base}$ as the used classifier. We evaluate the algorithms on two NLP classification datasets: Stanford Sentiment Treebank and KvK-Frontpages. Additionally, we explore heuristics that aim to solve presupposed problems of uncertainty-based AL; namely, that it is unscalable and that it is prone to selecting outliers. Furthermore, we explore the influence of the query-pool size on the performance of AL. Whereas it was found that the proposed heuristics for AL did not improve performance of AL; our results show that using uncertainty-based AL with BERT$_{base}$ outperforms random sampling of data. This difference in performance can decrease as the query-pool size gets larger.

</p>
</details>

<details><summary><b>Dual-State Capsule Networks for Text Classification</b>
<a href="https://arxiv.org/abs/2109.04762">arxiv:2109.04762</a>
&#x1F4C8; 3 <br>
<p>Piyumal Demotte, Surangika Ranathunga</p></summary>
<p>

**Abstract:** Text classification systems based on contextual embeddings are not viable options for many of the low resource languages. On the other hand, recently introduced capsule networks have shown performance in par with these text classification models. Thus, they could be considered as a viable alternative for text classification for languages that do not have pre-trained contextual embedding models. However, current capsule networks depend upon spatial patterns without considering the sequential features of the text. They are also sub-optimal in capturing the context-level information in longer sequences. This paper presents a novel Dual-State Capsule (DS-Caps) network-based technique for text classification, which is optimized to mitigate these issues. Two varieties of states, namely sentence-level and word-level, are integrated with capsule layers to capture deeper context-level information for language modeling. The dynamic routing process among capsules was also optimized using the context-level information obtained through sentence-level states. The DS-Caps networks outperform the existing capsule network architectures for multiple datasets, particularly for tasks with longer sequences of text. We also demonstrate the superiority of DS-Caps in text classification for a low resource language.

</p>
</details>

<details><summary><b>A framework for benchmarking uncertainty in deep regression</b>
<a href="https://arxiv.org/abs/2109.09048">arxiv:2109.09048</a>
&#x1F4C8; 2 <br>
<p>Franko Schm√§hling, J√∂rg Martin, Clemens Elster</p></summary>
<p>

**Abstract:** We propose a framework for the assessment of uncertainty quantification in deep regression. The framework is based on regression problems where the regression function is a linear combination of nonlinear functions. Basically, any level of complexity can be realized through the choice of the nonlinear functions and the dimensionality of their domain. Results of an uncertainty quantification for deep regression are compared against those obtained by a statistical reference method. The reference method utilizes knowledge of the underlying nonlinear functions and is based on a Bayesian linear regression using a reference prior. Reliability of uncertainty quantification is assessed in terms of coverage probabilities, and accuracy through the size of calculated uncertainties. We illustrate the proposed framework by applying it to current approaches for uncertainty quantification in deep regression. The flexibility, together with the availability of a reference solution, makes the framework suitable for defining benchmark sets for uncertainty quantification.

</p>
</details>

<details><summary><b>Estimation of Local Average Treatment Effect by Data Combination</b>
<a href="https://arxiv.org/abs/2109.05175">arxiv:2109.05175</a>
&#x1F4C8; 2 <br>
<p>Kazuhiko Shinoda, Takahiro Hoshino</p></summary>
<p>

**Abstract:** It is important to estimate the local average treatment effect (LATE) when compliance with a treatment assignment is incomplete. The previously proposed methods for LATE estimation required all relevant variables to be jointly observed in a single dataset; however, it is sometimes difficult or even impossible to collect such data in many real-world problems for technical or privacy reasons. We consider a novel problem setting in which LATE, as a function of covariates, is nonparametrically identified from the combination of separately observed datasets. For estimation, we show that the direct least squares method, which was originally developed for estimating the average treatment effect under complete compliance, is applicable to our setting. However, model selection and hyperparameter tuning for the direct least squares estimator can be unstable in practice since it is defined as a solution to the minimax problem. We then propose a weighted least squares estimator that enables simpler model selection by avoiding the minimax objective formulation. Unlike the inverse probability weighted (IPW) estimator, the proposed estimator directly uses the pre-estimated weight without inversion, avoiding the problems caused by the IPW methods. We demonstrate the effectiveness of our method through experiments using synthetic and real-world datasets.

</p>
</details>

<details><summary><b>Near Instance Optimal Model Selection for Pure Exploration Linear Bandits</b>
<a href="https://arxiv.org/abs/2109.05131">arxiv:2109.05131</a>
&#x1F4C8; 2 <br>
<p>Yinglun Zhu, Julian Katz-Samuels, Robert Nowak</p></summary>
<p>

**Abstract:** The model selection problem in the pure exploration linear bandit setting is introduced and studied in both the fixed confidence and fixed budget settings. The model selection problem considers a nested sequence of hypothesis classes of increasing complexities. Our goal is to automatically adapt to the instance-dependent complexity measure of the smallest hypothesis class containing the true model, rather than suffering from the complexity measure related to the largest hypothesis class. We provide evidence showing that a standard doubling trick over dimension fails to achieve the optimal instance-dependent sample complexity. Our algorithms define a new optimization problem based on experimental design that leverages the geometry of the action set to efficiently identify a near-optimal hypothesis class. Our fixed budget algorithm uses a novel application of a selection-validation trick in bandits. This provides a new method for the understudied fixed budget setting in linear bandits (even without the added challenge of model selection). We further generalize the model selection problem to the misspecified regime, adapting our algorithms in both fixed confidence and fixed budget settings.

</p>
</details>

<details><summary><b>An Empirical Comparison of Off-policy Prediction Learning Algorithms in the Four Rooms Environment</b>
<a href="https://arxiv.org/abs/2109.05110">arxiv:2109.05110</a>
&#x1F4C8; 2 <br>
<p>Sina Ghiassian, Richard S. Sutton</p></summary>
<p>

**Abstract:** Many off-policy prediction learning algorithms have been proposed in the past decade, but it remains unclear which algorithms learn faster than others. We empirically compare 11 off-policy prediction learning algorithms with linear function approximation on two small tasks: the Rooms task, and the High Variance Rooms task. The tasks are designed such that learning fast in them is challenging. In the Rooms task, the product of importance sampling ratios can be as large as $2^{14}$ and can sometimes be two. To control the high variance caused by the product of the importance sampling ratios, step size should be set small, which in turn slows down learning. The High Variance Rooms task is more extreme in that the product of the ratios can become as large as $2^{14}\times 25$. This paper builds upon the empirical study of off-policy prediction learning algorithms by Ghiassian and Sutton (2021). We consider the same set of algorithms as theirs and employ the same experimental methodology. The algorithms considered are: Off-policy TD($Œª$), five Gradient-TD algorithms, two Emphatic-TD algorithms, Tree Backup($Œª$), Vtrace($Œª$), and ABTD($Œ∂$). We found that the algorithms' performance is highly affected by the variance induced by the importance sampling ratios. The data shows that Tree Backup($Œª$), Vtrace($Œª$), and ABTD($Œ∂$) are not affected by the high variance as much as other algorithms but they restrict the effective bootstrapping parameter in a way that is too limiting for tasks where high variance is not present. We observed that Emphatic TD($Œª$) tends to have lower asymptotic error than other algorithms, but might learn more slowly in some cases. We suggest algorithms for practitioners based on their problem of interest, and suggest approaches that can be applied to specific algorithms that might result in substantially improved algorithms.

</p>
</details>

<details><summary><b>Toward Communication Efficient Adaptive Gradient Method</b>
<a href="https://arxiv.org/abs/2109.05109">arxiv:2109.05109</a>
&#x1F4C8; 2 <br>
<p>Xiangyi Chen, Xiaoyun Li, Ping Li</p></summary>
<p>

**Abstract:** In recent years, distributed optimization is proven to be an effective approach to accelerate training of large scale machine learning models such as deep neural networks. With the increasing computation power of GPUs, the bottleneck of training speed in distributed training is gradually shifting from computation to communication. Meanwhile, in the hope of training machine learning models on mobile devices, a new distributed training paradigm called ``federated learning'' has become popular. The communication time in federated learning is especially important due to the low bandwidth of mobile devices. While various approaches to improve the communication efficiency have been proposed for federated learning, most of them are designed with SGD as the prototype training algorithm. While adaptive gradient methods have been proven effective for training neural nets, the study of adaptive gradient methods in federated learning is scarce. In this paper, we propose an adaptive gradient method that can guarantee both the convergence and the communication efficiency for federated learning.

</p>
</details>

<details><summary><b>Data Generation Method for Learning a Low-dimensional Safe Region in Safe Reinforcement Learning</b>
<a href="https://arxiv.org/abs/2109.05077">arxiv:2109.05077</a>
&#x1F4C8; 2 <br>
<p>Zhehua Zhou, Ozgur S. Oguz, Yi Ren, Marion Leibold, Martin Buss</p></summary>
<p>

**Abstract:** Safe reinforcement learning aims to learn a control policy while ensuring that neither the system nor the environment gets damaged during the learning process. For implementing safe reinforcement learning on highly nonlinear and high-dimensional dynamical systems, one possible approach is to find a low-dimensional safe region via data-driven feature extraction methods, which provides safety estimates to the learning algorithm. As the reliability of the learned safety estimates is data-dependent, we investigate in this work how different training data will affect the safe reinforcement learning approach. By balancing between the learning performance and the risk of being unsafe, a data generation method that combines two sampling methods is proposed to generate representative training data. The performance of the method is demonstrated with a three-link inverted pendulum example.

</p>
</details>

<details><summary><b>Medulloblastoma Tumor Classification using Deep Transfer Learning with Multi-Scale EfficientNets</b>
<a href="https://arxiv.org/abs/2109.05025">arxiv:2109.05025</a>
&#x1F4C8; 2 <br>
<p>Marcel Bengs, Michael Bockmayr, Ulrich Sch√ºller, Alexander Schlaefer</p></summary>
<p>

**Abstract:** Medulloblastoma (MB) is the most common malignant brain tumor in childhood. The diagnosis is generally based on the microscopic evaluation of histopathological tissue slides. However, visual-only assessment of histopathological patterns is a tedious and time-consuming task and is also affected by observer variability. Hence, automated MB tumor classification could assist pathologists by promoting consistency and robust quantification. Recently, convolutional neural networks (CNNs) have been proposed for this task, while transfer learning has shown promising results. In this work, we propose an end-to-end MB tumor classification and explore transfer learning with various input sizes and matching network dimensions. We focus on differentiating between the histological subtypes classic and desmoplastic/nodular. For this purpose, we systematically evaluate recently proposed EfficientNets, which uniformly scale all dimensions of a CNN. Using a data set with 161 cases, we demonstrate that pre-trained EfficientNets with larger input resolutions lead to significant performance improvements compared to commonly used pre-trained CNN architectures. Also, we highlight the importance of transfer learning, when using such large architectures. Overall, our best performing method achieves an F1-Score of 80.1%.

</p>
</details>

<details><summary><b>Potential-based Reward Shaping in Sokoban</b>
<a href="https://arxiv.org/abs/2109.05022">arxiv:2109.05022</a>
&#x1F4C8; 2 <br>
<p>Zhao Yang, Mike Preuss, Aske Plaat</p></summary>
<p>

**Abstract:** Learning to solve sparse-reward reinforcement learning problems is difficult, due to the lack of guidance towards the goal. But in some problems, prior knowledge can be used to augment the learning process. Reward shaping is a way to incorporate prior knowledge into the original reward function in order to speed up the learning. While previous work has investigated the use of expert knowledge to generate potential functions, in this work, we study whether we can use a search algorithm(A*) to automatically generate a potential function for reward shaping in Sokoban, a well-known planning task. The results showed that learning with shaped reward function is faster than learning from scratch. Our results indicate that distance functions could be a suitable function for Sokoban. This work demonstrates the possibility of solving multiple instances with the help of reward shaping. The result can be compressed into a single policy, which can be seen as the first phrase towards training a general policy that is able to solve unseen instances.

</p>
</details>

<details><summary><b>PWPAE: An Ensemble Framework for Concept Drift Adaptation in IoT Data Streams</b>
<a href="https://arxiv.org/abs/2109.05013">arxiv:2109.05013</a>
&#x1F4C8; 2 <br>
<p>Li Yang, Dimitrios Michael Manias, Abdallah Shami</p></summary>
<p>

**Abstract:** As the number of Internet of Things (IoT) devices and systems have surged, IoT data analytics techniques have been developed to detect malicious cyber-attacks and secure IoT systems; however, concept drift issues often occur in IoT data analytics, as IoT data is often dynamic data streams that change over time, causing model degradation and attack detection failure. This is because traditional data analytics models are static models that cannot adapt to data distribution changes. In this paper, we propose a Performance Weighted Probability Averaging Ensemble (PWPAE) framework for drift adaptive IoT anomaly detection through IoT data stream analytics. Experiments on two public datasets show the effectiveness of our proposed PWPAE method compared against state-of-the-art methods.

</p>
</details>

<details><summary><b>A Neural Tangent Kernel Perspective of Infinite Tree Ensembles</b>
<a href="https://arxiv.org/abs/2109.04983">arxiv:2109.04983</a>
&#x1F4C8; 2 <br>
<p>Ryuichi Kanoh, Mahito Sugiyama</p></summary>
<p>

**Abstract:** In practical situations, the ensemble tree model is one of the most popular models along with neural networks. A soft tree is one of the variants of a decision tree. Instead of using a greedy method for searching splitting rules, the soft tree is trained using a gradient method in which the whole splitting operation is formulated in a differentiable form. Although ensembles of such soft trees have been increasingly used in recent years, little theoretical work has been done for understanding their behavior. In this paper, by considering an ensemble of infinite soft trees, we introduce and study the Tree Neural Tangent Kernel (TNTK), which provides new insights into the behavior of the infinite ensemble of soft trees. Using the TNTK, we succeed in theoretically finding several non-trivial properties, such as the effect of the oblivious tree structure and the degeneracy of the TNTK induced by the deepening of the trees. Moreover, we empirically examine the performance of an ensemble of infinite soft trees using the TNTK.

</p>
</details>

<details><summary><b>View Blind-spot as Inpainting: Self-Supervised Denoising with Mask Guided Residual Convolution</b>
<a href="https://arxiv.org/abs/2109.04970">arxiv:2109.04970</a>
&#x1F4C8; 2 <br>
<p>Yuhongze Zhou, Liguang Zhou, Tin Lun Lam, Yangsheng Xu</p></summary>
<p>

**Abstract:** In recent years, self-supervised denoising methods have shown impressive performance, which circumvent painstaking collection procedure of noisy-clean image pairs in supervised denoising methods and boost denoising applicability in real world. One of well-known self-supervised denoising strategies is the blind-spot training scheme. However, a few works attempt to improve blind-spot based self-denoiser in the aspect of network architecture. In this paper, we take an intuitive view of blind-spot strategy and consider its process of using neighbor pixels to predict manipulated pixels as an inpainting process. Therefore, we propose a novel Mask Guided Residual Convolution (MGRConv) into common convolutional neural networks, e.g. U-Net, to promote blind-spot based denoising. Our MGRConv can be regarded as soft partial convolution and find a trade-off among partial convolution, learnable attention maps, and gated convolution. It enables dynamic mask learning with appropriate mask constrain. Different from partial convolution and gated convolution, it provides moderate freedom for network learning. It also avoids leveraging external learnable parameters for mask activation, unlike learnable attention maps. The experiments show that our proposed plug-and-play MGRConv can assist blind-spot based denoising network to reach promising results on both existing single-image based and dataset-based methods.

</p>
</details>

<details><summary><b>Automatic Displacement and Vibration Measurement in Laboratory Experiments with A Deep Learning Method</b>
<a href="https://arxiv.org/abs/2109.04960">arxiv:2109.04960</a>
&#x1F4C8; 2 <br>
<p>Yongsheng Bai, Ramzi M. Abduallah, Halil Sezen, Alper Yilmaz</p></summary>
<p>

**Abstract:** This paper proposes a pipeline to automatically track and measure displacement and vibration of structural specimens during laboratory experiments. The latest Mask Regional Convolutional Neural Network (Mask R-CNN) can locate the targets and monitor their movement from videos recorded by a stationary camera. To improve precision and remove the noise, techniques such as Scale-invariant Feature Transform (SIFT) and various filters for signal processing are included. Experiments on three small-scale reinforced concrete beams and a shaking table test are utilized to verify the proposed method. Results show that the proposed deep learning method can achieve the goal to automatically and precisely measure the motion of tested structural members during laboratory experiments.

</p>
</details>

<details><summary><b>Best-Arm Identification in Correlated Multi-Armed Bandits</b>
<a href="https://arxiv.org/abs/2109.04941">arxiv:2109.04941</a>
&#x1F4C8; 2 <br>
<p>Samarth Gupta, Gauri Joshi, Osman Yaƒüan</p></summary>
<p>

**Abstract:** In this paper we consider the problem of best-arm identification in multi-armed bandits in the fixed confidence setting, where the goal is to identify, with probability $1-Œ¥$ for some $Œ¥>0$, the arm with the highest mean reward in minimum possible samples from the set of arms $\mathcal{K}$. Most existing best-arm identification algorithms and analyses operate under the assumption that the rewards corresponding to different arms are independent of each other. We propose a novel correlated bandit framework that captures domain knowledge about correlation between arms in the form of upper bounds on expected conditional reward of an arm, given a reward realization from another arm. Our proposed algorithm C-LUCB, which generalizes the LUCB algorithm utilizes this partial knowledge of correlations to sharply reduce the sample complexity of best-arm identification. More interestingly, we show that the total samples obtained by C-LUCB are of the form $\mathcal{O}\left(\sum_{k \in \mathcal{C}} \log\left(\frac{1}Œ¥\right)\right)$ as opposed to the typical $\mathcal{O}\left(\sum_{k \in \mathcal{K}} \log\left(\frac{1}Œ¥\right)\right)$ samples required in the independent reward setting. The improvement comes, as the $\mathcal{O}(\log(1/Œ¥))$ term is summed only for the set of competitive arms $\mathcal{C}$, which is a subset of the original set of arms $\mathcal{K}$. The size of the set $\mathcal{C}$, depending on the problem setting, can be as small as $2$, and hence using C-LUCB in the correlated bandits setting can lead to significant performance improvements. Our theoretical findings are supported by experiments on the Movielens and Goodreads recommendation datasets.

</p>
</details>

<details><summary><b>SO-SLAM: Semantic Object SLAM with Scale Proportional and Symmetrical Texture Constraints</b>
<a href="https://arxiv.org/abs/2109.04884">arxiv:2109.04884</a>
&#x1F4C8; 2 <br>
<p>Ziwei Liao, Yutong Hu, Jiadong Zhang, Xianyu Qi, Xiaoyu Zhang, Wei Wang</p></summary>
<p>

**Abstract:** Object SLAM introduces the concept of objects into Simultaneous Localization and Mapping (SLAM) and helps understand indoor scenes for mobile robots and object-level interactive applications. The state-of-art object SLAM systems face challenges such as partial observations, occlusions, unobservable problems, limiting the mapping accuracy and robustness. This paper proposes a novel monocular Semantic Object SLAM (SO-SLAM) system that addresses the introduction of object spatial constraints. We explore three representative spatial constraints, including scale proportional constraint, symmetrical texture constraint and plane supporting constraint. Based on these semantic constraints, we propose two new methods - a more robust object initialization method and an orientation fine optimization method. We have verified the performance of the algorithm on the public datasets and an author-recorded mobile robot dataset and achieved a significant improvement on mapping effects. We will release the code here: https://github.com/XunshanMan/SoSLAM.

</p>
</details>

<details><summary><b>Neural Networks for Latent Budget Analysis of Compositional Data</b>
<a href="https://arxiv.org/abs/2109.04875">arxiv:2109.04875</a>
&#x1F4C8; 2 <br>
<p>Zhenwei Yang, Ayoub Bagheri, P. G. M van der Heijden</p></summary>
<p>

**Abstract:** Compositional data are non-negative data collected in a rectangular matrix with a constant row sum. Due to the non-negativity the focus is on conditional proportions that add up to 1 for each row. A row of conditional proportions is called an observed budget. Latent budget analysis (LBA) assumes a mixture of latent budgets that explains the observed budgets. LBA is usually fitted to a contingency table, where the rows are levels of one or more explanatory variables and the columns the levels of a response variable. In prospective studies, there is only knowledge about the explanatory variables of individuals and interest goes out to predicting the response variable. Thus, a form of LBA is needed that has the functionality of prediction. Previous studies proposed a constrained neural network (NN) extension of LBA that was hampered by an unsatisfying prediction ability. Here we propose LBA-NN, a feed forward NN model that yields a similar interpretation to LBA but equips LBA with a better ability of prediction. A stable and plausible interpretation of LBA-NN is obtained through the use of importance plots and table, that show the relative importance of all explanatory variables on the response variable. An LBA-NN-K- means approach that applies K-means clustering on the importance table is used to produce K clusters that are comparable to K latent budgets in LBA. Here we provide different experiments where LBA-NN is implemented and compared with LBA. In our analysis, LBA-NN outperforms LBA in prediction in terms of accuracy, specificity, recall and mean square error. We provide open-source software at GitHub.

</p>
</details>

<details><summary><b>KNODE-MPC: A Knowledge-based Data-driven Predictive Control Framework for Aerial Robots</b>
<a href="https://arxiv.org/abs/2109.04821">arxiv:2109.04821</a>
&#x1F4C8; 2 <br>
<p>Kong Yao Chee, Tom Z. Jiahao, M. Ani Hsieh</p></summary>
<p>

**Abstract:** In this work, we consider the problem of deriving and incorporating accurate dynamic models for model predictive control (MPC) with an application to quadrotor control. MPC relies on precise dynamic models to achieve the desired closed-loop performance. However, the presence of uncertainties in complex systems and the environments they operate in poses a challenge in obtaining sufficiently accurate representations of the system dynamics. In this work, we make use of a deep learning tool, knowledge-based neural ordinary differential equations (KNODE), to augment a model obtained from first principles. The resulting hybrid model encompasses both a nominal first-principle model and a neural network learnt from simulated or real-world experimental data. Using a quadrotor, we benchmark our hybrid model against a state-of-the-art Gaussian Process (GP) model and show that the hybrid model provides more accurate predictions of the quadrotor dynamics and is able to generalize beyond the training data. To improve closed-loop performance, the hybrid model is integrated into a novel MPC framework, known as KNODE-MPC. Results show that the integrated framework achieves 60.2% improvement in simulations and more than 21% in physical experiments, in terms of trajectory tracking performance.

</p>
</details>

<details><summary><b>Efficient Locally Optimal Number Set Partitioning for Scheduling, Allocation and Fair Selection</b>
<a href="https://arxiv.org/abs/2109.04809">arxiv:2109.04809</a>
&#x1F4C8; 2 <br>
<p>Kaan Gokcesu, Hakan Gokcesu</p></summary>
<p>

**Abstract:** We study the optimization version of the set partition problem (where the difference between the partition sums are minimized), which has numerous applications in decision theory literature. While the set partitioning problem is NP-hard and requires exponential complexity to solve (i.e., intractable); we formulate a weaker version of this NP-hard problem, where the goal is to find a locally optimal solution. We show that our proposed algorithms can find a locally optimal solution in near linear time. Our algorithms require neither positive nor integer elements in the input set, hence, they are more widely applicable.

</p>
</details>

<details><summary><b>ReconfigISP: Reconfigurable Camera Image Processing Pipeline</b>
<a href="https://arxiv.org/abs/2109.04760">arxiv:2109.04760</a>
&#x1F4C8; 2 <br>
<p>Ke Yu, Zexian Li, Yue Peng, Chen Change Loy, Jinwei Gu</p></summary>
<p>

**Abstract:** Image Signal Processor (ISP) is a crucial component in digital cameras that transforms sensor signals into images for us to perceive and understand. Existing ISP designs always adopt a fixed architecture, e.g., several sequential modules connected in a rigid order. Such a fixed ISP architecture may be suboptimal for real-world applications, where camera sensors, scenes and tasks are diverse. In this study, we propose a novel Reconfigurable ISP (ReconfigISP) whose architecture and parameters can be automatically tailored to specific data and tasks. In particular, we implement several ISP modules, and enable backpropagation for each module by training a differentiable proxy, hence allowing us to leverage the popular differentiable neural architecture search and effectively search for the optimal ISP architecture. A proxy tuning mechanism is adopted to maintain the accuracy of proxy networks in all cases. Extensive experiments conducted on image restoration and object detection, with different sensors, light conditions and efficiency constraints, validate the effectiveness of ReconfigISP. Only hundreds of parameters need tuning for every task.

</p>
</details>

<details><summary><b>Enhancing Unsupervised Anomaly Detection with Score-Guided Network</b>
<a href="https://arxiv.org/abs/2109.04684">arxiv:2109.04684</a>
&#x1F4C8; 2 <br>
<p>Zongyuan Huang, Baohua Zhang, Guoqiang Hu, Longyuan Li, Yanyan Xu, Yaohui Jin</p></summary>
<p>

**Abstract:** Anomaly detection plays a crucial role in various real-world applications, including healthcare and finance systems. Owing to the limited number of anomaly labels in these complex systems, unsupervised anomaly detection methods have attracted great attention in recent years. Two major challenges faced by the existing unsupervised methods are: (i) distinguishing between normal and abnormal data in the transition field, where normal and abnormal data are highly mixed together; (ii) defining an effective metric to maximize the gap between normal and abnormal data in a hypothesis space, which is built by a representation learner. To that end, this work proposes a novel scoring network with a score-guided regularization to learn and enlarge the anomaly score disparities between normal and abnormal data. With such score-guided strategy, the representation learner can gradually learn more informative representation during the model training stage, especially for the samples in the transition field. We next propose a score-guided autoencoder (SG-AE), incorporating the scoring network into an autoencoder framework for anomaly detection, as well as other three state-of-the-art models, to further demonstrate the effectiveness and transferability of the design. Extensive experiments on both synthetic and real-world datasets demonstrate the state-of-the-art performance of these score-guided models (SGMs).

</p>
</details>

<details><summary><b>No Size Fits All: Automated Radio Configuration for LPWANs</b>
<a href="https://arxiv.org/abs/2109.05103">arxiv:2109.05103</a>
&#x1F4C8; 1 <br>
<p>Zerina Kapetanovic, Deepak Vasisht, Tusher Chakraborty, Joshua R. Smith, Ranveer Chandra</p></summary>
<p>

**Abstract:** Low power long-range networks like LoRa have become increasingly mainstream for Internet of Things deployments. Given the versatility of applications that these protocols enable, they support many data rates and bandwidths. Yet, for a given network that supports hundreds of devices over multiple miles, the network operator typically needs to specify the same configuration or among a small subset of configurations for all the client devices to communicate with the gateway. This one-size-fits-all approach is highly inefficient in large networks. We propose an alternative approach -- we allow network devices to transmit at any data rate they choose. The gateway uses the first few symbols in the preamble to classify the correct data rate, switches its configuration, and then decodes the data. Our design leverages the inherent asymmetry in outdoor IoT deployments where the clients are power-starved and resource-constrained, but the gateway is not. Our gateway design, Proteus, runs a neural network architecture and is backward compatible with existing LoRa protocols. Our experiments reveal that Proteus can identify the correct configuration with over 97% accuracy in both indoor and outdoor deployments. Our network architecture leads to a 3.8 to 11 times increase in throughput for our LoRa testbed.

</p>
</details>

<details><summary><b>Multi-agent deep reinforcement learning (MADRL) meets multi-user MIMO systems</b>
<a href="https://arxiv.org/abs/2109.04986">arxiv:2109.04986</a>
&#x1F4C8; 1 <br>
<p>Heunchul Lee, Jaeseong Jeong</p></summary>
<p>

**Abstract:** A multi-agent deep reinforcement learning (MADRL) is a promising approach to challenging problems in wireless environments involving multiple decision-makers (or actors) with high-dimensional continuous action space. In this paper, we present a MADRL-based approach that can jointly optimize precoders to achieve the outer-boundary, called pareto-boundary, of the achievable rate region for a multiple-input single-output (MISO) interference channel (IFC). In order to address two main challenges, namely, multiple actors (or agents) with partial observability and multi-dimensional continuous action space in MISO IFC setup, we adopt a multi-agent deep deterministic policy gradient (MA-DDPG) framework in which decentralized actors with partial observability can learn a multi-dimensional continuous policy in a centralized manner with the aid of shared critic with global information. Meanwhile, we will also address a phase ambiguity issue with the conventional complex baseband representation of signals widely used in radio communications. In order to mitigate the impact of phase ambiguity on training performance, we propose a training method, called phase ambiguity elimination (PAE), that leads to faster learning and better performance of MA-DDPG in wireless communication systems. The simulation results exhibit that MA-DDPG is capable of learning a near-optimal precoding strategy in a MISO IFC environment. To the best of our knowledge, this is the first work to demonstrate that the MA-DDPG framework can jointly optimize precoders to achieve the pareto-boundary of achievable rate region in a multi-cell multi-user multi-antenna system.

</p>
</details>

<details><summary><b>Citizen centric optimal electric vehicle charging stations locations in a full city: case of Malaga</b>
<a href="https://arxiv.org/abs/2109.04975">arxiv:2109.04975</a>
&#x1F4C8; 1 <br>
<p>Christian Cintrano, Jamal Toutouh, Enrique Alba</p></summary>
<p>

**Abstract:** This article presents the problem of locating electric vehicle (EV) charging stations in a city by defining the Electric Vehicle Charging Stations Locations (EV-CSL) problem. The idea is to minimize the distance the citizens have to travel to charge their vehicles. EV-CSL takes into account the maximum number of charging stations to install and the electric power requirements. Two metaheuristics are applied to address the relying optimization problem: a genetic algorithm (GA) and a variable neighborhood search (VNS). The experimental analysis over a realistic scenario of Malaga city, Spain, shows that the metaheuristics are able to find competitive solutions which dramatically improve the actual installation of the stations in Malaga. GA provided statistically the best results.

</p>
</details>

<details><summary><b>How Can Subgroup Discovery Help AIOps?</b>
<a href="https://arxiv.org/abs/2109.04909">arxiv:2109.04909</a>
&#x1F4C8; 1 <br>
<p>Youcef Remil</p></summary>
<p>

**Abstract:** The genuine supervision of modern IT systems brings new challenges as it requires higher standards of scalability, reliability and efficiency when analysing and monitoring big data streams. Rule-based inference engines are a key component of maintenance systems in detecting anomalies and automating their resolution. However, they remain confined to simple and general rules and cannot handle the huge amount of data, nor the large number of alerts raised by IT systems, a lesson learned from expert systems era. Artificial Intelligence for Operation Systems (AIOps) proposes to take advantage of advanced analytics and machine learning on big data to improve and automate every step of supervision systems and aid incident management in detecting outages, identifying root causes and applying appropriate healing actions. Nevertheless, the best AIOps techniques rely on opaque models, strongly limiting their adoption. As a part of this PhD thesis, we study how Subgroup Discovery can help AIOps. This promising data mining technique offers possibilities to extract interesting hypothesis from data and understand the underlying process behind predictive models. To ensure relevancy of our propositions, this project involves both data mining researchers and practitioners from Infologic, a French software editor.

</p>
</details>

<details><summary><b>ProcK: Machine Learning for Knowledge-Intensive Processes</b>
<a href="https://arxiv.org/abs/2109.04881">arxiv:2109.04881</a>
&#x1F4C8; 1 <br>
<p>Tobias Jacobs, Jingyi Yu, Julia Gastinger, Timo Sztyler</p></summary>
<p>

**Abstract:** Process mining deals with extraction of knowledge from business process execution logs. Traditional process mining tasks, like process model generation or conformance checking, rely on a minimalistic feature set where each event is characterized only by its case identifier, activity type, and timestamp. In contrast, the success of modern machine learning is based on models that take any available data as direct input and build layers of features automatically during training. In this work, we introduce ProcK (Process & Knowledge), a novel pipeline to build business process prediction models that take into account both sequential data in the form of event logs and rich semantic information represented in a graph-structured knowledge base. The hybrid approach enables ProcK to flexibly make use of all information residing in the databases of organizations. Components to extract inter-linked event logs and knowledge bases from relational databases are part of the pipeline. We demonstrate the power of ProcK by training it for prediction tasks on the OULAD e-learning dataset, where we achieve state-of-the-art performance on the tasks of predicting student dropout from courses and predicting their success. We also apply our method on a number of additional machine learning tasks, including exam score prediction and early predictions that only take into account data recorded during the first weeks of the courses.

</p>
</details>

<details><summary><b>Secondary control activation analysed and predicted with explainable AI</b>
<a href="https://arxiv.org/abs/2109.04802">arxiv:2109.04802</a>
&#x1F4C8; 1 <br>
<p>Johannes Kruse, Benjamin Sch√§fer, Dirk Witthaut</p></summary>
<p>

**Abstract:** The transition to a renewable energy system poses challenges for power grid operation and stability. Secondary control is key in restoring the power system to its reference following a disturbance. Underestimating the necessary control capacity may require emergency measures, such as load shedding. Hence, a solid understanding of the emerging risks and the driving factors of control is needed. In this contribution, we establish an explainable machine learning model for the activation of secondary control power in Germany. Training gradient boosted trees, we obtain an accurate description of control activation. Using SHapely Additive exPlanation (SHAP) values, we investigate the dependency between control activation and external features such as the generation mix, forecasting errors, and electricity market data. Thereby, our analysis reveals drivers that lead to high reserve requirements in the German power system. Our transparent approach, utilizing open data and making machine learning models interpretable, opens new scientific discovery avenues.

</p>
</details>

<details><summary><b>On the validity of pre-trained transformers for natural language processing in the software engineering domain</b>
<a href="https://arxiv.org/abs/2109.04738">arxiv:2109.04738</a>
&#x1F4C8; 1 <br>
<p>Julian von der Mosel, Alexander Trautsch, Steffen Herbold</p></summary>
<p>

**Abstract:** Transformers are the current state-of-the-art of natural language processing in many domains and are using traction within software engineering research as well. Such models are pre-trained on large amounts of data, usually from the general domain. However, we only have a limited understanding regarding the validity of transformers within the software engineering domain, i.e., how good such models are at understanding words and sentences within a software engineering context and how this improves the state-of-the-art. Within this article, we shed light on this complex, but crucial issue. We compare BERT transformer models trained with software engineering data with transformers based on general domain data in multiple dimensions: their vocabulary, their ability to understand which words are missing, and their performance in classification tasks. Our results show that for tasks that require understanding of the software engineering context, pre-training with software engineering data is valuable, while general domain models are sufficient for general language understanding, also within the software engineering domain.

</p>
</details>

<details><summary><b>On the Compression of Neural Networks Using $\ell_0$-Norm Regularization and Weight Pruning</b>
<a href="https://arxiv.org/abs/2109.05075">arxiv:2109.05075</a>
&#x1F4C8; 0 <br>
<p>Felipe Dennis de Resende Oliveira, Eduardo Luiz Ortiz Batista, Rui Seara</p></summary>
<p>

**Abstract:** Despite the growing availability of high-capacity computational platforms, implementation complexity still has been a great concern for the real-world deployment of neural networks. This concern is not exclusively due to the huge costs of state-of-the-art network architectures, but also due to the recent push towards edge intelligence and the use of neural networks in embedded applications. In this context, network compression techniques have been gaining interest due to their ability for reducing deployment costs while keeping inference accuracy at satisfactory levels. The present paper is dedicated to the development of a novel compression scheme for neural networks. To this end, a new $\ell_0$-norm-based regularization approach is firstly developed, which is capable of inducing strong sparseness in the network during training. Then, targeting the smaller weights of the trained network with pruning techniques, smaller yet highly effective networks can be obtained. The proposed compression scheme also involves the use of $\ell_2$-norm regularization to avoid overfitting as well as fine tuning to improve the performance of the pruned network. Experimental results are presented aiming to show the effectiveness of the proposed scheme as well as to make comparisons with competing approaches.

</p>
</details>

<details><summary><b>Emerging AI Security Threats for Autonomous Cars -- Case Studies</b>
<a href="https://arxiv.org/abs/2109.04865">arxiv:2109.04865</a>
&#x1F4C8; 0 <br>
<p>Shanthi Lekkala, Tanya Motwani, Manojkumar Parmar, Amit Phadke</p></summary>
<p>

**Abstract:** Artificial Intelligence has made a significant contribution to autonomous vehicles, from object detection to path planning. However, AI models require a large amount of sensitive training data and are usually computationally intensive to build. The commercial value of such models motivates attackers to mount various attacks. Adversaries can launch model extraction attacks for monetization purposes or step-ping-stone towards other attacks like model evasion. In specific cases, it even results in destroying brand reputation, differentiation, and value proposition. In addition, IP laws and AI-related legalities are still evolving and are not uniform across countries. We discuss model extraction attacks in detail with two use-cases and a generic kill-chain that can compromise autonomous cars. It is essential to investigate strategies to manage and mitigate the risk of model theft.

</p>
</details>

<details><summary><b>PIP: Physical Interaction Prediction via Mental Simulation with Span Selection</b>
<a href="https://arxiv.org/abs/2109.04683">arxiv:2109.04683</a>
&#x1F4C8; 0 <br>
<p>Jiafei Duan, Samson Yu, Soujanya Poria, Bihan Wen, Cheston Tan</p></summary>
<p>

**Abstract:** Accurate prediction of physical interaction outcomes is a crucial component of human intelligence and is important for safe and efficient deployments of robots in the real world. While there are existing vision-based intuitive physics models that learn to predict physical interaction outcomes, they mostly focus on generating short sequences of future frames based on physical properties (e.g. mass, friction and velocity) extracted from visual inputs or a latent space. However, there is a lack of intuitive physics models that are tested on long physical interaction sequences with multiple interactions among different objects. We hypothesize that selective temporal attention during approximate mental simulations helps humans in physical interaction outcome prediction. With these motivations, we propose a novel scheme: Physical Interaction Prediction via Mental Simulation with Span Selection (PIP). It utilizes a deep generative model to model approximate mental simulations by generating future frames of physical interactions before employing selective temporal attention in the form of span selection for predicting physical interaction outcomes. To evaluate our model, we further propose the large-scale SPACE+ dataset of synthetic videos with long sequences of three prime physical interactions in a 3D environment. Our experiments show that PIP outperforms human, baseline, and related intuitive physics models that utilize mental simulation. Furthermore, PIP's span selection module effectively identifies the frames indicating key physical interactions among objects, allowing for added interpretability.

</p>
</details>


[Next Page]({{ '/2021/09/09/2021.09.09.html' | relative_url }})
