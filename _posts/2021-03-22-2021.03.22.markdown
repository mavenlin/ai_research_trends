## Summary for 2021-03-22, created on 2021-12-23


<details><summary><b>Prototypical Representation Learning for Relation Extraction</b>
<a href="https://arxiv.org/abs/2103.11647">arxiv:2103.11647</a>
&#x1F4C8; 72 <br>
<p>Ning Ding, Xiaobin Wang, Yao Fu, Guangwei Xu, Rui Wang, Pengjun Xie, Ying Shen, Fei Huang, Hai-Tao Zheng, Rui Zhang</p></summary>
<p>

**Abstract:** Recognizing relations between entities is a pivotal task of relational learning. Learning relation representations from distantly-labeled datasets is difficult because of the abundant label noise and complicated expressions in human language. This paper aims to learn predictive, interpretable, and robust relation representations from distantly-labeled data that are effective in different settings, including supervised, distantly supervised, and few-shot learning. Instead of solely relying on the supervision from noisy labels, we propose to learn prototypes for each relation from contextual information to best explore the intrinsic semantics of relations. Prototypes are representations in the feature space abstracting the essential semantics of relations between entities in sentences. We learn prototypes based on objectives with clear geometric interpretation, where the prototypes are unit vectors uniformly dispersed in a unit ball, and statement embeddings are centered at the end of their corresponding prototype vectors on the surface of the ball. This approach allows us to learn meaningful, interpretable prototypes for the final classification. Results on several relation learning tasks show that our model significantly outperforms the previous state-of-the-art models. We further demonstrate the robustness of the encoder and the interpretability of prototypes with extensive experiments.

</p>
</details>

<details><summary><b>MasakhaNER: Named Entity Recognition for African Languages</b>
<a href="https://arxiv.org/abs/2103.11811">arxiv:2103.11811</a>
&#x1F4C8; 64 <br>
<p>David Ifeoluwa Adelani, Jade Abbott, Graham Neubig, Daniel D'souza, Julia Kreutzer, Constantine Lignos, Chester Palen-Michel, Happy Buzaaba, Shruti Rijhwani, Sebastian Ruder, Stephen Mayhew, Israel Abebe Azime, Shamsuddeen Muhammad, Chris Chinenye Emezue, Joyce Nakatumba-Nabende, Perez Ogayo, Anuoluwapo Aremu, Catherine Gitau, Derguene Mbaye, Jesujoba Alabi, Seid Muhie Yimam, Tajuddeen Gwadabe, Ignatius Ezeani, Rubungo Andre Niyongabo, Jonathan Mukiibi</p></summary>
<p>

**Abstract:** We take a step towards addressing the under-representation of the African continent in NLP research by creating the first large publicly available high-quality dataset for named entity recognition (NER) in ten African languages, bringing together a variety of stakeholders. We detail characteristics of the languages to help researchers understand the challenges that these languages pose for NER. We analyze our datasets and conduct an extensive empirical evaluation of state-of-the-art methods across both supervised and transfer learning settings. We release the data, code, and models in order to inspire future research on African NLP.

</p>
</details>

<details><summary><b>Quality at a Glance: An Audit of Web-Crawled Multilingual Datasets</b>
<a href="https://arxiv.org/abs/2103.12028">arxiv:2103.12028</a>
&#x1F4C8; 52 <br>
<p>Julia Kreutzer, Isaac Caswell, Lisa Wang, Ahsan Wahab, Daan van Esch, Nasanbayar Ulzii-Orshikh, Allahsera Tapo, Nishant Subramani, Artem Sokolov, Claytone Sikasote, Monang Setyawan, Supheakmungkol Sarin, Sokhar Samb, Benoît Sagot, Clara Rivera, Annette Rios, Isabel Papadimitriou, Salomey Osei, Pedro Ortiz Suárez, Iroro Orife, Kelechi Ogueji, Andre Niyongabo Rubungo, Toan Q. Nguyen, Mathias Müller, André Müller</p></summary>
<p>

**Abstract:** With the success of large-scale pre-training and multilingual modeling in Natural Language Processing (NLP), recent years have seen a proliferation of large, web-mined text datasets covering hundreds of languages. We manually audit the quality of 205 language-specific corpora released with five major public datasets (CCAligned, ParaCrawl, WikiMatrix, OSCAR, mC4). Lower-resource corpora have systematic issues: At least 15 corpora have no usable text, and a significant fraction contains less than 50% sentences of acceptable quality. In addition, many are mislabeled or use nonstandard/ambiguous language codes. We demonstrate that these issues are easy to detect even for non-proficient speakers, and supplement the human audit with automatic analyses. Finally, we recommend techniques to evaluate and improve multilingual corpora and discuss potential risks that come with low-quality data releases.

</p>
</details>

<details><summary><b>Measuring and modeling the motor system with machine learning</b>
<a href="https://arxiv.org/abs/2103.11775">arxiv:2103.11775</a>
&#x1F4C8; 52 <br>
<p>Sébastien B. Hausmann, Alessandro Marin Vargas, Alexander Mathis, Mackenzie W. Mathis</p></summary>
<p>

**Abstract:** The utility of machine learning in understanding the motor system is promising a revolution in how to collect, measure, and analyze data. The field of movement science already elegantly incorporates theory and engineering principles to guide experimental work, and in this review we discuss the growing use of machine learning: from pose estimation, kinematic analyses, dimensionality reduction, and closed-loop feedback, to its use in understanding neural correlates and untangling sensorimotor systems. We also give our perspective on new avenues where markerless motion capture combined with biomechanical modeling and neural networks could be a new platform for hypothesis-driven research.

</p>
</details>

<details><summary><b>An Experimental Review on Deep Learning Architectures for Time Series Forecasting</b>
<a href="https://arxiv.org/abs/2103.12057">arxiv:2103.12057</a>
&#x1F4C8; 38 <br>
<p>Pedro Lara-Benítez, Manuel Carranza-García, José C. Riquelme</p></summary>
<p>

**Abstract:** In recent years, deep learning techniques have outperformed traditional models in many machine learning tasks. Deep neural networks have successfully been applied to address time series forecasting problems, which is a very important topic in data mining. They have proved to be an effective solution given their capacity to automatically learn the temporal dependencies present in time series. However, selecting the most convenient type of deep neural network and its parametrization is a complex task that requires considerable expertise. Therefore, there is a need for deeper studies on the suitability of all existing architectures for different forecasting tasks. In this work, we face two main challenges: a comprehensive review of the latest works using deep learning for time series forecasting; and an experimental study comparing the performance of the most popular architectures. The comparison involves a thorough analysis of seven types of deep learning models in terms of accuracy and efficiency. We evaluate the rankings and distribution of results obtained with the proposed models under many different architecture configurations and training hyperparameters. The datasets used comprise more than 50000 time series divided into 12 different forecasting problems. By training more than 38000 models on these data, we provide the most extensive deep learning study for time series forecasting. Among all studied models, the results show that long short-term memory (LSTM) and convolutional networks (CNN) are the best alternatives, with LSTMs obtaining the most accurate forecasts. CNNs achieve comparable performance with less variability of results under different parameter configurations, while also being more efficient.

</p>
</details>

<details><summary><b>Federated Quantum Machine Learning</b>
<a href="https://arxiv.org/abs/2103.12010">arxiv:2103.12010</a>
&#x1F4C8; 36 <br>
<p>Samuel Yen-Chi Chen, Shinjae Yoo</p></summary>
<p>

**Abstract:** Distributed training across several quantum computers could significantly improve the training time and if we could share the learned model, not the data, it could potentially improve the data privacy as the training would happen where the data is located. However, to the best of our knowledge, no work has been done in quantum machine learning (QML) in federation setting yet. In this work, we present the federated training on hybrid quantum-classical machine learning models although our framework could be generalized to pure quantum machine learning model. Specifically, we consider the quantum neural network (QNN) coupled with classical pre-trained convolutional model. Our distributed federated learning scheme demonstrated almost the same level of trained model accuracies and yet significantly faster distributed training. It demonstrates a promising future research direction for scaling and privacy aspects.

</p>
</details>

<details><summary><b>On the Robustness of Monte Carlo Dropout Trained with Noisy Labels</b>
<a href="https://arxiv.org/abs/2103.12002">arxiv:2103.12002</a>
&#x1F4C8; 31 <br>
<p>Purvi Goel, Li Chen</p></summary>
<p>

**Abstract:** The memorization effect of deep learning hinders its performance to effectively generalize on test set when learning with noisy labels. Prior study has discovered that epistemic uncertainty techniques are robust when trained with noisy labels compared with neural networks without uncertainty estimation. They obtain prolonged memorization effect and better generalization performance under the adversarial setting of noisy labels. Due to its superior performance amongst other selected epistemic uncertainty methods under noisy labels, we focus on Monte Carlo Dropout (MCDropout) and investigate why it is robust when trained with noisy labels. Through empirical studies on datasets MNIST, CIFAR-10, Animal-10n, we deep dive into three aspects of MCDropout under noisy label setting: 1. efficacy: understanding the learning behavior and test accuracy of MCDropout when training set contains artificially generated or naturally embedded label noise; 2. representation volatility: studying the responsiveness of neurons by examining the mean and standard deviation on each neuron's activation; 3. network sparsity: investigating the network support of MCDropout in comparison with deterministic neural networks. Our findings suggest that MCDropout further sparsifies and regularizes the deterministic neural networks and thus provides higher robustness against noisy labels.

</p>
</details>

<details><summary><b>Improving and Simplifying Pattern Exploiting Training</b>
<a href="https://arxiv.org/abs/2103.11955">arxiv:2103.11955</a>
&#x1F4C8; 24 <br>
<p>Derek Tam, Rakesh R Menon, Mohit Bansal, Shashank Srivastava, Colin Raffel</p></summary>
<p>

**Abstract:** Recently, pre-trained language models (LMs) have achieved strong performance when fine-tuned on difficult benchmarks like SuperGLUE. However, performance can suffer when there are very few labeled examples available for fine-tuning. Pattern Exploiting Training (PET) is a recent approach that leverages patterns for few-shot learning. However, PET uses task-specific unlabeled data. In this paper, we focus on few-shot learning without any unlabeled data and introduce ADAPET, which modifies PET's objective to provide denser supervision during fine-tuning. As a result, ADAPET outperforms PET on SuperGLUE without any task-specific unlabeled data. Our code can be found at https://github.com/rrmenon10/ADAPET.

</p>
</details>

<details><summary><b>Multimodal Motion Prediction with Stacked Transformers</b>
<a href="https://arxiv.org/abs/2103.11624">arxiv:2103.11624</a>
&#x1F4C8; 24 <br>
<p>Yicheng Liu, Jinghuai Zhang, Liangji Fang, Qinhong Jiang, Bolei Zhou</p></summary>
<p>

**Abstract:** Predicting multiple plausible future trajectories of the nearby vehicles is crucial for the safety of autonomous driving. Recent motion prediction approaches attempt to achieve such multimodal motion prediction by implicitly regularizing the feature or explicitly generating multiple candidate proposals. However, it remains challenging since the latent features may concentrate on the most frequent mode of the data while the proposal-based methods depend largely on the prior knowledge to generate and select the proposals. In this work, we propose a novel transformer framework for multimodal motion prediction, termed as mmTransformer. A novel network architecture based on stacked transformers is designed to model the multimodality at feature level with a set of fixed independent proposals. A region-based training strategy is then developed to induce the multimodality of the generated proposals. Experiments on Argoverse dataset show that the proposed model achieves the state-of-the-art performance on motion prediction, substantially improving the diversity and the accuracy of the predicted trajectories. Demo video and code are available at https://decisionforce.github.io/mmTransformer.

</p>
</details>

<details><summary><b>Bridging Offline Reinforcement Learning and Imitation Learning: A Tale of Pessimism</b>
<a href="https://arxiv.org/abs/2103.12021">arxiv:2103.12021</a>
&#x1F4C8; 23 <br>
<p>Paria Rashidinejad, Banghua Zhu, Cong Ma, Jiantao Jiao, Stuart Russell</p></summary>
<p>

**Abstract:** Offline (or batch) reinforcement learning (RL) algorithms seek to learn an optimal policy from a fixed dataset without active data collection. Based on the composition of the offline dataset, two main categories of methods are used: imitation learning which is suitable for expert datasets and vanilla offline RL which often requires uniform coverage datasets. From a practical standpoint, datasets often deviate from these two extremes and the exact data composition is usually unknown a priori. To bridge this gap, we present a new offline RL framework that smoothly interpolates between the two extremes of data composition, hence unifying imitation learning and vanilla offline RL. The new framework is centered around a weak version of the concentrability coefficient that measures the deviation from the behavior policy to the expert policy alone.
  Under this new framework, we further investigate the question on algorithm design: can one develop an algorithm that achieves a minimax optimal rate and also adapts to unknown data composition? To address this question, we consider a lower confidence bound (LCB) algorithm developed based on pessimism in the face of uncertainty in offline RL. We study finite-sample properties of LCB as well as information-theoretic limits in multi-armed bandits, contextual bandits, and Markov decision processes (MDPs). Our analysis reveals surprising facts about optimality rates. In particular, in all three settings, LCB achieves a faster rate of $1/N$ for nearly-expert datasets compared to the usual rate of $1/\sqrt{N}$ in offline RL, where $N$ is the number of samples in the batch dataset. In the case of contextual bandits with at least two contexts, we prove that LCB is adaptively optimal for the entire data composition range, achieving a smooth transition from imitation learning to offline RL. We further show that LCB is almost adaptively optimal in MDPs.

</p>
</details>

<details><summary><b>Self-paced ensemble learning for speech and audio classification</b>
<a href="https://arxiv.org/abs/2103.11988">arxiv:2103.11988</a>
&#x1F4C8; 23 <br>
<p>Nicolae-Catalin Ristea, Radu Tudor Ionescu</p></summary>
<p>

**Abstract:** Combining multiple machine learning models into an ensemble is known to provide superior performance levels compared to the individual components forming the ensemble. This is because models can complement each other in taking better decisions. Instead of just combining the models, we propose a self-paced ensemble learning scheme in which models learn from each other over several iterations. During the self-paced learning process based on pseudo-labeling, in addition to improving the individual models, our ensemble also gains knowledge about the target domain. To demonstrate the generality of our self-paced ensemble learning (SPEL) scheme, we conduct experiments on three audio tasks. Our empirical results indicate that SPEL significantly outperforms the baseline ensemble models. We also show that applying self-paced learning on individual models is less effective, illustrating the idea that models in the ensemble actually learn from each other.

</p>
</details>

<details><summary><b>SSD: A Unified Framework for Self-Supervised Outlier Detection</b>
<a href="https://arxiv.org/abs/2103.12051">arxiv:2103.12051</a>
&#x1F4C8; 21 <br>
<p>Vikash Sehwag, Mung Chiang, Prateek Mittal</p></summary>
<p>

**Abstract:** We ask the following question: what training information is required to design an effective outlier/out-of-distribution (OOD) detector, i.e., detecting samples that lie far away from the training distribution? Since unlabeled data is easily accessible for many applications, the most compelling approach is to develop detectors based on only unlabeled in-distribution data. However, we observe that most existing detectors based on unlabeled data perform poorly, often equivalent to a random prediction. In contrast, existing state-of-the-art OOD detectors achieve impressive performance but require access to fine-grained data labels for supervised training. We propose SSD, an outlier detector based on only unlabeled in-distribution data. We use self-supervised representation learning followed by a Mahalanobis distance based detection in the feature space. We demonstrate that SSD outperforms most existing detectors based on unlabeled data by a large margin. Additionally, SSD even achieves performance on par, and sometimes even better, with supervised training based detectors. Finally, we expand our detection framework with two key extensions. First, we formulate few-shot OOD detection, in which the detector has access to only one to five samples from each class of the targeted OOD dataset. Second, we extend our framework to incorporate training data labels, if available. We find that our novel detection framework based on SSD displays enhanced performance with these extensions, and achieves state-of-the-art performance. Our code is publicly available at https://github.com/inspire-group/SSD.

</p>
</details>

<details><summary><b>BERT: A Review of Applications in Natural Language Processing and Understanding</b>
<a href="https://arxiv.org/abs/2103.11943">arxiv:2103.11943</a>
&#x1F4C8; 21 <br>
<p>M. V. Koroteev</p></summary>
<p>

**Abstract:** In this review, we describe the application of one of the most popular deep learning-based language models - BERT. The paper describes the mechanism of operation of this model, the main areas of its application to the tasks of text analytics, comparisons with similar models in each task, as well as a description of some proprietary models. In preparing this review, the data of several dozen original scientific articles published over the past few years, which attracted the most attention in the scientific community, were systematized. This survey will be useful to all students and researchers who want to get acquainted with the latest advances in the field of natural language text analysis.

</p>
</details>

<details><summary><b>Raven's Progressive Matrices Completion with Latent Gaussian Process Priors</b>
<a href="https://arxiv.org/abs/2103.12045">arxiv:2103.12045</a>
&#x1F4C8; 20 <br>
<p>Fan Shi, Bin Li, Xiangyang Xue</p></summary>
<p>

**Abstract:** Abstract reasoning ability is fundamental to human intelligence. It enables humans to uncover relations among abstract concepts and further deduce implicit rules from the relations. As a well-known abstract visual reasoning task, Raven's Progressive Matrices (RPM) are widely used in human IQ tests. Although extensive research has been conducted on RPM solvers with machine intelligence, few studies have considered further advancing the standard answer-selection (classification) problem to a more challenging answer-painting (generating) problem, which can verify whether the model has indeed understood the implicit rules. In this paper we aim to solve the latter one by proposing a deep latent variable model, in which multiple Gaussian processes are employed as priors of latent variables to separately learn underlying abstract concepts from RPMs; thus the proposed model is interpretable in terms of concept-specific latent variables. The latent Gaussian process also provides an effective way of extrapolation for answer painting based on the learned concept-changing rules. We evaluate the proposed model on RPM-like datasets with multiple continuously-changing visual concepts. Experimental results demonstrate that our model requires only few training samples to paint high-quality answers, generate novel RPM panels, and achieve interpretability through concept-specific latent variables.

</p>
</details>

<details><summary><b>Improving Actor-Critic Reinforcement Learning via Hamiltonian Policy</b>
<a href="https://arxiv.org/abs/2103.12020">arxiv:2103.12020</a>
&#x1F4C8; 20 <br>
<p>Duo Xu, Faramarz Fekri</p></summary>
<p>

**Abstract:** Approximating optimal policies in reinforcement learning (RL) is often necessary in many real-world scenarios, which is termed as policy optimization. By viewing the reinforcement learning from the perspective of variational inference (VI), the policy network is trained to obtain the approximate posterior of actions given the optimality criteria. However, in practice, the policy optimization may lead to suboptimal policy estimates due to the amortization gap and insufficient exploration. In this work, inspired by the previous use of Hamiltonian Monte Carlo (HMC) in VI, we propose to integrate policy optimization with HMC. As such we choose evolving actions from the base policy according to HMC, which has two benefits: i) HMC can improve the policy distribution to better approximate the posterior and hence reduces the amortization gap; ii) HMC can also guide the exploration more to the regions with higher action values, enhancing the exploration efficiency. Instead of directly applying HMC into RL, we propose a new leapfrog operator to simulate the Hamiltonian dynamics. With comprehensive empirical experiments on continuous control baselines, including MuJoCo and PyBullet Roboschool, we show that the proposed approach is a data-efficient, and an easy-to-implement improvement over previous policy optimization methods. Besides, the proposed approach can also outperform previous methods on DeepMind Control Suite which has image-based high-dimensional observation space.

</p>
</details>

<details><summary><b>Statistically-Robust Clustering Techniques for Mapping Spatial Hotspots: A Survey</b>
<a href="https://arxiv.org/abs/2103.12019">arxiv:2103.12019</a>
&#x1F4C8; 20 <br>
<p>Yiqun Xie, Shashi Shekhar, Yan Li</p></summary>
<p>

**Abstract:** Mapping of spatial hotspots, i.e., regions with significantly higher rates of generating cases of certain events (e.g., disease or crime cases), is an important task in diverse societal domains, including public health, public safety, transportation, agriculture, environmental science, etc. Clustering techniques required by these domains differ from traditional clustering methods due to the high economic and social costs of spurious results (e.g., false alarms of crime clusters). As a result, statistical rigor is needed explicitly to control the rate of spurious detections. To address this challenge, techniques for statistically-robust clustering (e.g., scan statistics) have been extensively studied by the data mining and statistics communities. In this survey we present an up-to-date and detailed review of the models and algorithms developed by this field. We first present a general taxonomy for statistically-robust clustering, covering key steps of data and statistical modeling, region enumeration and maximization, and significance testing. We further discuss different paradigms and methods within each of the key steps. Finally, we highlight research gaps and potential future directions, which may serve as a stepping stone in generating new ideas and thoughts in this growing field and beyond.

</p>
</details>

<details><summary><b>Evaluating Post-Training Compression in GANs using Locality-Sensitive Hashing</b>
<a href="https://arxiv.org/abs/2103.11912">arxiv:2103.11912</a>
&#x1F4C8; 18 <br>
<p>Gonçalo Mordido, Haojin Yang, Christoph Meinel</p></summary>
<p>

**Abstract:** The analysis of the compression effects in generative adversarial networks (GANs) after training, i.e. without any fine-tuning, remains an unstudied, albeit important, topic with the increasing trend of their computation and memory requirements. While existing works discuss the difficulty of compressing GANs during training, requiring novel methods designed with the instability of GANs training in mind, we show that existing compression methods (namely clipping and quantization) may be directly applied to compress GANs post-training, without any additional changes. High compression levels may distort the generated set, likely leading to an increase of outliers that may negatively affect the overall assessment of existing k-nearest neighbor (KNN) based metrics. We propose two new precision and recall metrics based on locality-sensitive hashing (LSH), which, on top of increasing the outlier robustness, decrease the complexity of assessing an evaluation sample against $n$ reference samples from $O(n)$ to $O(\log(n))$, if using LSH and KNN, and to $O(1)$, if only applying LSH. We show that low-bit compression of several pre-trained GANs on multiple datasets induces a trade-off between precision and recall, retaining sample quality while sacrificing sample diversity.

</p>
</details>

<details><summary><b>Explaining Black-Box Algorithms Using Probabilistic Contrastive Counterfactuals</b>
<a href="https://arxiv.org/abs/2103.11972">arxiv:2103.11972</a>
&#x1F4C8; 14 <br>
<p>Sainyam Galhotra, Romila Pradhan, Babak Salimi</p></summary>
<p>

**Abstract:** There has been a recent resurgence of interest in explainable artificial intelligence (XAI) that aims to reduce the opaqueness of AI-based decision-making systems, allowing humans to scrutinize and trust them. Prior work in this context has focused on the attribution of responsibility for an algorithm's decisions to its inputs wherein responsibility is typically approached as a purely associational concept. In this paper, we propose a principled causality-based approach for explaining black-box decision-making systems that addresses limitations of existing methods in XAI. At the core of our framework lies probabilistic contrastive counterfactuals, a concept that can be traced back to philosophical, cognitive, and social foundations of theories on how humans generate and select explanations. We show how such counterfactuals can quantify the direct and indirect influences of a variable on decisions made by an algorithm, and provide actionable recourse for individuals negatively affected by the algorithm's decision. Unlike prior work, our system, LEWIS: (1)can compute provably effective explanations and recourse at local, global and contextual levels (2)is designed to work with users with varying levels of background knowledge of the underlying causal model and (3)makes no assumptions about the internals of an algorithmic system except for the availability of its input-output data. We empirically evaluate LEWIS on three real-world datasets and show that it generates human-understandable explanations that improve upon state-of-the-art approaches in XAI, including the popular LIME and SHAP. Experiments on synthetic data further demonstrate the correctness of LEWIS's explanations and the scalability of its recourse algorithm.

</p>
</details>

<details><summary><b>Hardware Acceleration of Explainable Machine Learning using Tensor Processing Units</b>
<a href="https://arxiv.org/abs/2103.11927">arxiv:2103.11927</a>
&#x1F4C8; 13 <br>
<p>Zhixin Pan, Prabhat Mishra</p></summary>
<p>

**Abstract:** Machine learning (ML) is successful in achieving human-level performance in various fields. However, it lacks the ability to explain an outcome due to its black-box nature. While existing explainable ML is promising, almost all of these methods focus on formatting interpretability as an optimization problem. Such a mapping leads to numerous iterations of time-consuming complex computations, which limits their applicability in real-time applications. In this paper, we propose a novel framework for accelerating explainable ML using Tensor Processing Units (TPUs). The proposed framework exploits the synergy between matrix convolution and Fourier transform, and takes full advantage of TPU's natural ability in accelerating matrix computations. Specifically, this paper makes three important contributions. (1) To the best of our knowledge, our proposed work is the first attempt in enabling hardware acceleration of explainable ML using TPUs. (2) Our proposed approach is applicable across a wide variety of ML algorithms, and effective utilization of TPU-based acceleration can lead to real-time outcome interpretation. (3) Extensive experimental results demonstrate that our proposed approach can provide an order-of-magnitude speedup in both classification time (25x on average) and interpretation time (13x on average) compared to state-of-the-art techniques.

</p>
</details>

<details><summary><b>Intra-Inter Camera Similarity for Unsupervised Person Re-Identification</b>
<a href="https://arxiv.org/abs/2103.11658">arxiv:2103.11658</a>
&#x1F4C8; 11 <br>
<p>Shiyu Xuan, Shiliang Zhang</p></summary>
<p>

**Abstract:** Most of unsupervised person Re-Identification (Re-ID) works produce pseudo-labels by measuring the feature similarity without considering the distribution discrepancy among cameras, leading to degraded accuracy in label computation across cameras. This paper targets to address this challenge by studying a novel intra-inter camera similarity for pseudo-label generation. We decompose the sample similarity computation into two stage, i.e., the intra-camera and inter-camera computations, respectively. The intra-camera computation directly leverages the CNN features for similarity computation within each camera. Pseudo-labels generated on different cameras train the re-id model in a multi-branch network. The second stage considers the classification scores of each sample on different cameras as a new feature vector. This new feature effectively alleviates the distribution discrepancy among cameras and generates more reliable pseudo-labels. We hence train our re-id model in two stages with intra-camera and inter-camera pseudo-labels, respectively. This simple intra-inter camera similarity produces surprisingly good performance on multiple datasets, e.g., achieves rank-1 accuracy of 89.5% on the Market1501 dataset, outperforming the recent unsupervised works by 9+%, and is comparable with the latest transfer learning works that leverage extra annotations.

</p>
</details>

<details><summary><b>Demographic Aware Probabilistic Medical Knowledge Graph Embeddings of Electronic Medical Records</b>
<a href="https://arxiv.org/abs/2103.11951">arxiv:2103.11951</a>
&#x1F4C8; 10 <br>
<p>Aynur Guluzade, Endri Kacupaj, Maria Maleshkova</p></summary>
<p>

**Abstract:** Medical knowledge graphs (KGs) constructed from Electronic Medical Records (EMR) contain abundant information about patients and medical entities. The utilization of KG embedding models on these data has proven to be efficient for different medical tasks. However, existing models do not properly incorporate patient demographics and most of them ignore the probabilistic features of the medical KG. In this paper, we propose DARLING (Demographic Aware pRobabiListic medIcal kNowledge embeddinG), a demographic-aware medical KG embedding framework that explicitly incorporates demographics in the medical entities space by associating patient demographics with a corresponding hyperplane. Our framework leverages the probabilistic features within the medical entities for learning their representations through demographic guidance. We evaluate DARLING through link prediction for treatments and medicines, on a medical KG constructed from EMR data, and illustrate its superior performance compared to existing KG embedding models.

</p>
</details>

<details><summary><b>NDT-Transformer: Large-Scale 3D Point Cloud Localisation using the Normal Distribution Transform Representation</b>
<a href="https://arxiv.org/abs/2103.12292">arxiv:2103.12292</a>
&#x1F4C8; 9 <br>
<p>Zhicheng Zhou, Cheng Zhao, Daniel Adolfsson, Songzhi Su, Yang Gao, Tom Duckett, Li Sun</p></summary>
<p>

**Abstract:** 3D point cloud-based place recognition is highly demanded by autonomous driving in GPS-challenged environments and serves as an essential component (i.e. loop-closure detection) in lidar-based SLAM systems. This paper proposes a novel approach, named NDT-Transformer, for realtime and large-scale place recognition using 3D point clouds. Specifically, a 3D Normal Distribution Transform (NDT) representation is employed to condense the raw, dense 3D point cloud as probabilistic distributions (NDT cells) to provide the geometrical shape description. Then a novel NDT-Transformer network learns a global descriptor from a set of 3D NDT cell representations. Benefiting from the NDT representation and NDT-Transformer network, the learned global descriptors are enriched with both geometrical and contextual information. Finally, descriptor retrieval is achieved using a query-database for place recognition. Compared to the state-of-the-art methods, the proposed approach achieves an improvement of 7.52% on average top 1 recall and 2.73% on average top 1% recall on the Oxford Robotcar benchmark.

</p>
</details>

<details><summary><b>Deconvolution-and-convolution Networks</b>
<a href="https://arxiv.org/abs/2103.11887">arxiv:2103.11887</a>
&#x1F4C8; 9 <br>
<p>Yimin Yang, Wandong Zhang, Jonathan Wu, Will Zhao, Ao Chen</p></summary>
<p>

**Abstract:** 2D Convolutional neural network (CNN) has arguably become the de facto standard for computer vision tasks. Recent findings, however, suggest that CNN may not be the best option for 1D pattern recognition, especially for datasets with over 1 M training samples, e.g., existing CNN-based methods for 1D signals are highly reliant on human pre-processing. Common practices include utilizing discrete Fourier transform (DFT) to reconstruct 1D signal into 2D array. To add to extant knowledge, in this paper, a novel 1D data processing algorithm is proposed for 1D big data analysis through learning a deep deconvolutional-convolutional network. Rather than resorting to human-based techniques, we employed deconvolution layers to convert 1 D signals into 2D data. On top of the deconvolution model, the data was identified by a 2D CNN. Compared with the existing 1D signal processing algorithms, DCNet boasts the advantages of less human-made inference and higher generalization performance. Our experimental results from a varying number of training patterns (50 K to 11 M) from classification and regression demonstrate the desirability of our new approach.

</p>
</details>

<details><summary><b>Higher-Order Orthogonal Causal Learning for Treatment Effect</b>
<a href="https://arxiv.org/abs/2103.11869">arxiv:2103.11869</a>
&#x1F4C8; 8 <br>
<p>Yiyan Huang, Cheuk Hang Leung, Xing Yan, Qi Wu</p></summary>
<p>

**Abstract:** Most existing studies on the double/debiased machine learning method concentrate on the causal parameter estimation recovering from the first-order orthogonal score function. In this paper, we will construct the $k^{\mathrm{th}}$-order orthogonal score function for estimating the average treatment effect (ATE) and present an algorithm that enables us to obtain the debiased estimator recovered from the score function. Such a higher-order orthogonal estimator is more robust to the misspecification of the propensity score than the first-order one does. Besides, it has the merit of being applicable with many machine learning methodologies such as Lasso, Random Forests, Neural Nets, etc. We also undergo comprehensive experiments to test the power of the estimator we construct from the score function using both the simulated datasets and the real datasets.

</p>
</details>

<details><summary><b>Generation and Simulation of Yeast Microscopy Imagery with Deep Learning</b>
<a href="https://arxiv.org/abs/2103.11834">arxiv:2103.11834</a>
&#x1F4C8; 8 <br>
<p>Christoph Reich</p></summary>
<p>

**Abstract:** Time-lapse fluorescence microscopy (TLFM) is an important and powerful tool in synthetic biological research. Modeling TLFM experiments based on real data may enable researchers to repeat certain experiments with minor effort. This thesis is a study towards deep learning-based modeling of TLFM experiments on the image level. The modeling of TLFM experiments, by way of the example of trapped yeast cells, is split into two tasks. The first task is to generate synthetic image data based on real image data. To approach this problem, a novel generative adversarial network, for conditionalized and unconditionalized image generation, is proposed. The second task is the simulation of brightfield microscopy images over multiple discrete time-steps. To tackle this simulation task an advanced future frame prediction model is introduced. The proposed models are trained and tested on a novel dataset that is presented in this thesis. The obtained results showed that the modeling of TLFM experiments, with deep learning, is a proper approach, but requires future research to effectively model real-world experiments.

</p>
</details>

<details><summary><b>Catastrophic Forgetting in Deep Graph Networks: an Introductory Benchmark for Graph Classification</b>
<a href="https://arxiv.org/abs/2103.11750">arxiv:2103.11750</a>
&#x1F4C8; 7 <br>
<p>Antonio Carta, Andrea Cossu, Federico Errica, Davide Bacciu</p></summary>
<p>

**Abstract:** In this work, we study the phenomenon of catastrophic forgetting in the graph representation learning scenario. The primary objective of the analysis is to understand whether classical continual learning techniques for flat and sequential data have a tangible impact on performances when applied to graph data. To do so, we experiment with a structure-agnostic model and a deep graph network in a robust and controlled environment on three different datasets. The benchmark is complemented by an investigation on the effect of structure-preserving regularization techniques on catastrophic forgetting. We find that replay is the most effective strategy in so far, which also benefits the most from the use of regularization. Our findings suggest interesting future research at the intersection of the continual and graph representation learning fields. Finally, we provide researchers with a flexible software framework to reproduce our results and carry out further experiments.

</p>
</details>

<details><summary><b>Plug-and-Blend: A Framework for Controllable Story Generation with Blended Control Codes</b>
<a href="https://arxiv.org/abs/2104.04039">arxiv:2104.04039</a>
&#x1F4C8; 6 <br>
<p>Zhiyu Lin, Mark Riedl</p></summary>
<p>

**Abstract:** Large pre-trained neural language models (LM) have very powerful text generation capabilities. However, in practice, they are hard to control for creative purposes. We describe a Plug-and-Play controllable language generation framework, Plug-and-Blend, that allows a human user to input multiple control codes (topics). In the context of automated story generation, this allows a human user loose or fine-grained control of the topics and transitions between them that will appear in the generated story, and can even allow for overlapping, blended topics. Automated evaluations show our framework, working with different generative LMs, controls the generation towards given continuous-weighted control codes while keeping the generated sentences fluent, demonstrating strong blending capability. A human participant evaluation shows that the generated stories are observably transitioning between two topics.

</p>
</details>

<details><summary><b>Human-like Controllable Image Captioning with Verb-specific Semantic Roles</b>
<a href="https://arxiv.org/abs/2103.12204">arxiv:2103.12204</a>
&#x1F4C8; 6 <br>
<p>Long Chen, Zhihong Jiang, Jun Xiao, Wei Liu</p></summary>
<p>

**Abstract:** Controllable Image Captioning (CIC) -- generating image descriptions following designated control signals -- has received unprecedented attention over the last few years. To emulate the human ability in controlling caption generation, current CIC studies focus exclusively on control signals concerning objective properties, such as contents of interest or descriptive patterns. However, we argue that almost all existing objective control signals have overlooked two indispensable characteristics of an ideal control signal: 1) Event-compatible: all visual contents referred to in a single sentence should be compatible with the described activity. 2) Sample-suitable: the control signals should be suitable for a specific image sample. To this end, we propose a new control signal for CIC: Verb-specific Semantic Roles (VSR). VSR consists of a verb and some semantic roles, which represents a targeted activity and the roles of entities involved in this activity. Given a designated VSR, we first train a grounded semantic role labeling (GSRL) model to identify and ground all entities for each role. Then, we propose a semantic structure planner (SSP) to learn human-like descriptive semantic structures. Lastly, we use a role-shift captioning model to generate the captions. Extensive experiments and ablations demonstrate that our framework can achieve better controllability than several strong baselines on two challenging CIC benchmarks. Besides, we can generate multi-level diverse captions easily. The code is available at: https://github.com/mad-red/VSR-guided-CIC.

</p>
</details>

<details><summary><b>Introspective Visuomotor Control: Exploiting Uncertainty in Deep Visuomotor Control for Failure Recovery</b>
<a href="https://arxiv.org/abs/2103.11881">arxiv:2103.11881</a>
&#x1F4C8; 6 <br>
<p>Chia-Man Hung, Li Sun, Yizhe Wu, Ioannis Havoutis, Ingmar Posner</p></summary>
<p>

**Abstract:** End-to-end visuomotor control is emerging as a compelling solution for robot manipulation tasks. However, imitation learning-based visuomotor control approaches tend to suffer from a common limitation, lacking the ability to recover from an out-of-distribution state caused by compounding errors. In this paper, instead of using tactile feedback or explicitly detecting the failure through vision, we investigate using the uncertainty of a policy neural network. We propose a novel uncertainty-based approach to detect and recover from failure cases. Our hypothesis is that policy uncertainties can implicitly indicate the potential failures in the visuomotor control task and that robot states with minimum uncertainty are more likely to lead to task success. To recover from high uncertainty cases, the robot monitors its uncertainty along a trajectory and explores possible actions in the state-action space to bring itself to a more certain state. Our experiments verify this hypothesis and show a significant improvement on task success rate: 12% in pushing, 15% in pick-and-reach and 22% in pick-and-place.

</p>
</details>

<details><summary><b>Interpreting Deep Learning Models with Marginal Attribution by Conditioning on Quantiles</b>
<a href="https://arxiv.org/abs/2103.11706">arxiv:2103.11706</a>
&#x1F4C8; 6 <br>
<p>M. Merz, R. Richman, T. Tsanakas, M. V. Wüthrich</p></summary>
<p>

**Abstract:** A vastly growing literature on explaining deep learning models has emerged. This paper contributes to that literature by introducing a global gradient-based model-agnostic method, which we call Marginal Attribution by Conditioning on Quantiles (MACQ). Our approach is based on analyzing the marginal attribution of predictions (outputs) to individual features (inputs). Specificalllly, we consider variable importance by mixing (global) output levels and, thus, explain how features marginally contribute across different regions of the prediction space. Hence, MACQ can be seen as a marginal attribution counterpart to approaches such as accumulated local effects (ALE), which study the sensitivities of outputs by perturbing inputs. Furthermore, MACQ allows us to separate marginal attribution of individual features from interaction effect, and visually illustrate the 3-way relationship between marginal attribution, output level, and feature value.

</p>
</details>

<details><summary><b>Detecting cognitive decline using speech only: The ADReSSo Challenge</b>
<a href="https://arxiv.org/abs/2104.09356">arxiv:2104.09356</a>
&#x1F4C8; 5 <br>
<p>Saturnino Luz, Fasih Haider, Sofia de la Fuente, Davida Fromm, Brian MacWhinney</p></summary>
<p>

**Abstract:** Building on the success of the ADReSS Challenge at Interspeech 2020, which attracted the participation of 34 teams from across the world, the ADReSSo Challenge targets three difficult automatic prediction problems of societal and medical relevance, namely: detection of Alzheimer's Dementia, inference of cognitive testing scores, and prediction of cognitive decline. This paper presents these prediction tasks in detail, describes the datasets used, and reports the results of the baseline classification and regression models we developed for each task. A combination of acoustic and linguistic features extracted directly from audio recordings, without human intervention, yielded a baseline accuracy of 78.87% for the AD classification task, an MMSE prediction root mean squared (RMSE) error of 5.28, and 68.75% accuracy for the cognitive decline prediction task.

</p>
</details>

<details><summary><b>Learning to Robustly Negotiate Bi-Directional Lane Usage in High-Conflict Driving Scenarios</b>
<a href="https://arxiv.org/abs/2103.12070">arxiv:2103.12070</a>
&#x1F4C8; 5 <br>
<p>Christoph Killing, Adam Villaflor, John M. Dolan</p></summary>
<p>

**Abstract:** Recently, autonomous driving has made substantial progress in addressing the most common traffic scenarios like intersection navigation and lane changing. However, most of these successes have been limited to scenarios with well-defined traffic rules and require minimal negotiation with other vehicles. In this paper, we introduce a previously unconsidered, yet everyday, high-conflict driving scenario requiring negotiations between agents of equal rights and priorities. There exists no centralized control structure and we do not allow communications. Therefore, it is unknown if other drivers are willing to cooperate, and if so to what extent. We train policies to robustly negotiate with opposing vehicles of an unobservable degree of cooperativeness using multi-agent reinforcement learning (MARL). We propose Discrete Asymmetric Soft Actor-Critic (DASAC), a maximum-entropy off-policy MARL algorithm allowing for centralized training with decentralized execution. We show that using DASAC we are able to successfully negotiate and traverse the scenario considered over 99% of the time. Our agents are robust to an unknown timing of opponent decisions, an unobservable degree of cooperativeness of the opposing vehicle, and previously unencountered policies. Furthermore, they learn to exhibit human-like behaviors such as defensive driving, anticipating solution options and interpreting the behavior of other agents.

</p>
</details>

<details><summary><b>Deep learning on fundus images detects glaucoma beyond the optic disc</b>
<a href="https://arxiv.org/abs/2103.11895">arxiv:2103.11895</a>
&#x1F4C8; 5 <br>
<p>Ruben Hemelings, Bart Elen, João Barbosa-Breda, Matthew B. Blaschko, Patrick De Boever, Ingeborg Stalmans</p></summary>
<p>

**Abstract:** Although unprecedented sensitivity and specificity values are reported, recent glaucoma detection deep learning models lack in decision transparency. Here, we propose a methodology that advances explainable deep learning in the field of glaucoma detection and vertical cup-disc ratio (VCDR), an important risk factor. We trained and evaluated deep learning models using fundus images that underwent a certain cropping policy. We defined the crop radius as a percentage of image size, centered on the optic nerve head (ONH), with an equidistant spaced range from 10%-60% (ONH crop policy). The inverse of the cropping mask was also applied (periphery crop policy). Trained models using original images resulted in an area under the curve (AUC) of 0.94 [95% CI: 0.92-0.96] for glaucoma detection, and a coefficient of determination (R^2) equal to 77% [95% CI: 0.77-0.79] for VCDR estimation. Models that were trained on images with absence of the ONH are still able to obtain significant performance (0.88 [95% CI: 0.85-0.90] AUC for glaucoma detection and 37% [95% CI: 0.35-0.40] R^2 score for VCDR estimation in the most extreme setup of 60% ONH crop). Our findings provide the first irrefutable evidence that deep learning can detect glaucoma from fundus image regions outside the ONH.

</p>
</details>

<details><summary><b>Data Cleansing for Deep Neural Networks with Storage-efficient Approximation of Influence Functions</b>
<a href="https://arxiv.org/abs/2103.11807">arxiv:2103.11807</a>
&#x1F4C8; 5 <br>
<p>Kenji Suzuki, Yoshiyuki Kobayashi, Takuya Narihira</p></summary>
<p>

**Abstract:** Identifying the influence of training data for data cleansing can improve the accuracy of deep learning. An approach with stochastic gradient descent (SGD) called SGD-influence to calculate the influence scores was proposed, but, the calculation costs are expensive. It is necessary to temporally store the parameters of the model during training phase for inference phase to calculate influence sores. In close connection with the previous method, we propose a method to reduce cache files to store the parameters in training phase for calculating inference score. We only adopt the final parameters in last epoch for influence functions calculation. In our experiments on classification, the cache size of training using MNIST dataset with our approach is 1.236 MB. On the other hand, the previous method used cache size of 1.932 GB in last epoch. It means that cache size has been reduced to 1/1,563. We also observed the accuracy improvement by data cleansing with removal of negatively influential data using our approach as well as the previous method. Moreover, our simple and general proposed method to calculate influence scores is available on our auto ML tool without programing, Neural Network Console. The source code is also available.

</p>
</details>

<details><summary><b>Large Motion Video Super-Resolution with Dual Subnet and Multi-Stage Communicated Upsampling</b>
<a href="https://arxiv.org/abs/2103.11744">arxiv:2103.11744</a>
&#x1F4C8; 5 <br>
<p>Hongying Liu, Peng Zhao, Zhubo Ruan, Fanhua Shang, Yuanyuan Liu</p></summary>
<p>

**Abstract:** Video super-resolution (VSR) aims at restoring a video in low-resolution (LR) and improving it to higher-resolution (HR). Due to the characteristics of video tasks, it is very important that motion information among frames should be well concerned, summarized and utilized for guidance in a VSR algorithm. Especially, when a video contains large motion, conventional methods easily bring incoherent results or artifacts. In this paper, we propose a novel deep neural network with Dual Subnet and Multi-stage Communicated Upsampling (DSMC) for super-resolution of videos with large motion. We design a new module named U-shaped residual dense network with 3D convolution (U3D-RDN) for fine implicit motion estimation and motion compensation (MEMC) as well as coarse spatial feature extraction. And we present a new Multi-Stage Communicated Upsampling (MSCU) module to make full use of the intermediate results of upsampling for guiding the VSR. Moreover, a novel dual subnet is devised to aid the training of our DSMC, whose dual loss helps to reduce the solution space as well as enhance the generalization ability. Our experimental results confirm that our method achieves superior performance on videos with large motion compared to state-of-the-art methods.

</p>
</details>

<details><summary><b>Control Distance IoU and Control Distance IoU Loss Function for Better Bounding Box Regression</b>
<a href="https://arxiv.org/abs/2103.11696">arxiv:2103.11696</a>
&#x1F4C8; 5 <br>
<p>Dong Chen, Duoqian Miao</p></summary>
<p>

**Abstract:** Numerous improvements for feedback mechanisms have contributed to the great progress in object detection. In this paper, we first present an evaluation-feedback module, which is proposed to consist of evaluation system and feedback mechanism. Then we analyze and summarize the disadvantages and improvements of traditional evaluation-feedback module. Finally, we focus on both the evaluation system and the feedback mechanism, and propose Control Distance IoU and Control Distance IoU loss function (or CDIoU and CDIoU loss for short) without increasing parameters or FLOPs in models, which show different significant enhancements on several classical and emerging models. Some experiments and comparative tests show that coordinated evaluation-feedback module can effectively improve model performance. CDIoU and CDIoU loss have different excellent performances in several models such as Faster R-CNN, YOLOv4, RetinaNet and ATSS. There is a maximum AP improvement of 1.9% and an average AP of 0.8% improvement on MS COCO dataset, compared to traditional evaluation-feedback modules.

</p>
</details>

<details><summary><b>Domain Specific Concept Drift Detectors for Predicting Financial Time Series</b>
<a href="https://arxiv.org/abs/2103.14079">arxiv:2103.14079</a>
&#x1F4C8; 4 <br>
<p>Filippo Neri</p></summary>
<p>

**Abstract:** Concept drift detectors allow learning systems to maintain good accuracy on non-stationary data streams. Financial time series are an instance of non-stationary data streams whose concept drifts (market phases) are so important to affect investment decisions worldwide. This paper studies how concept drift detectors behave when applied to financial time series. General results are: a) concept drift detectors usually improve the runtime over continuous learning, b) their computational cost is usually a fraction of the learning and prediction steps of even basic learners, c) it is important to study concept drift detectors in combination with the learning systems they will operate with, and d) concept drift detectors can be directly applied to the time series of raw financial data and not only to the model's accuracy one. Moreover, the study introduces three simple concept drift detectors, tailored to financial time series, and shows that two of them can be at least as effective as the most sophisticated ones from the state of the art when applied to financial time series. Currently submitted to Pattern Recognition

</p>
</details>

<details><summary><b>F-SIOL-310: A Robotic Dataset and Benchmark for Few-Shot Incremental Object Learning</b>
<a href="https://arxiv.org/abs/2103.12242">arxiv:2103.12242</a>
&#x1F4C8; 4 <br>
<p>Ali Ayub, Alan R. Wagner</p></summary>
<p>

**Abstract:** Deep learning has achieved remarkable success in object recognition tasks through the availability of large scale datasets like ImageNet. However, deep learning systems suffer from catastrophic forgetting when learning incrementally without replaying old data. For real-world applications, robots also need to incrementally learn new objects. Further, since robots have limited human assistance available, they must learn from only a few examples. However, very few object recognition datasets and benchmarks exist to test incremental learning capability for robotic vision. Further, there is no dataset or benchmark specifically designed for incremental object learning from a few examples. To fill this gap, we present a new dataset termed F-SIOL-310 (Few-Shot Incremental Object Learning) which is specifically captured for testing few-shot incremental object learning capability for robotic vision. We also provide benchmarks and evaluations of 8 incremental learning algorithms on F-SIOL-310 for future comparisons. Our results demonstrate that the few-shot incremental object learning problem for robotic vision is far from being solved.

</p>
</details>

<details><summary><b>Adversarial Feature Augmentation and Normalization for Visual Recognition</b>
<a href="https://arxiv.org/abs/2103.12171">arxiv:2103.12171</a>
&#x1F4C8; 4 <br>
<p>Tianlong Chen, Yu Cheng, Zhe Gan, Jianfeng Wang, Lijuan Wang, Zhangyang Wang, Jingjing Liu</p></summary>
<p>

**Abstract:** Recent advances in computer vision take advantage of adversarial data augmentation to ameliorate the generalization ability of classification models. Here, we present an effective and efficient alternative that advocates adversarial augmentation on intermediate feature embeddings, instead of relying on computationally-expensive pixel-level perturbations. We propose Adversarial Feature Augmentation and Normalization (A-FAN), which (i) first augments visual recognition models with adversarial features that integrate flexible scales of perturbation strengths, (ii) then extracts adversarial feature statistics from batch normalization, and re-injects them into clean features through feature normalization. We validate the proposed approach across diverse visual recognition tasks with representative backbone networks, including ResNets and EfficientNets for classification, Faster-RCNN for detection, and Deeplab V3+ for segmentation. Extensive experiments show that A-FAN yields consistent generalization improvement over strong baselines across various datasets for classification, detection and segmentation tasks, such as CIFAR-10, CIFAR-100, ImageNet, Pascal VOC2007, Pascal VOC2012, COCO2017, and Cityspaces. Comprehensive ablation studies and detailed analyses also demonstrate that adding perturbations to specific modules and layers of classification/detection/segmentation backbones yields optimal performance. Codes and pre-trained models will be made available at: https://github.com/VITA-Group/CV_A-FAN.

</p>
</details>

<details><summary><b>Recovery of Joint Probability Distribution from one-way marginals: Low rank Tensors and Random Projections</b>
<a href="https://arxiv.org/abs/2103.11864">arxiv:2103.11864</a>
&#x1F4C8; 4 <br>
<p>Jian Vora, Karthik S. Gurumoorthy, Ajit Rajwade</p></summary>
<p>

**Abstract:** Joint probability mass function (PMF) estimation is a fundamental machine learning problem. The number of free parameters scales exponentially with respect to the number of random variables. Hence, most work on nonparametric PMF estimation is based on some structural assumptions such as clique factorization adopted by probabilistic graphical models, imposition of low rank on the joint probability tensor and reconstruction from 3-way or 2-way marginals, etc. In the present work, we link random projections of data to the problem of PMF estimation using ideas from tomography. We integrate this idea with the idea of low-rank tensor decomposition to show that we can estimate the joint density from just one-way marginals in a transformed space. We provide a novel algorithm for recovering factors of the tensor from one-way marginals, test it across a variety of synthetic and real-world datasets, and also perform MAP inference on the estimated model for classification.

</p>
</details>

<details><summary><b>Spatially Dependent U-Nets: Highly Accurate Architectures for Medical Imaging Segmentation</b>
<a href="https://arxiv.org/abs/2103.11713">arxiv:2103.11713</a>
&#x1F4C8; 4 <br>
<p>João B. S. Carvalho, João A. Santinha, Đorđe Miladinović, Joachim M. Buhmann</p></summary>
<p>

**Abstract:** In clinical practice, regions of interest in medical imaging often need to be identified through a process of precise image segmentation. The quality of this image segmentation step critically affects the subsequent clinical assessment of the patient status. To enable high accuracy, automatic image segmentation, we introduce a novel deep neural network architecture that exploits the inherent spatial coherence of anatomical structures and is well equipped to capture long-range spatial dependencies in the segmented pixel/voxel space. In contrast to the state-of-the-art solutions based on convolutional layers, our approach leverages on recently introduced spatial dependency layers that have an unbounded receptive field and explicitly model the inductive bias of spatial coherence. Our method performs favourably to commonly used U-Net and U-Net++ architectures as demonstrated by improved Dice and Jaccardscore in three different medical segmentation tasks: nuclei segmentation in microscopy images, polyp segmentation in colonoscopy videos, and liver segmentation in abdominal CT scans.

</p>
</details>

<details><summary><b>Supervised Contrastive Replay: Revisiting the Nearest Class Mean Classifier in Online Class-Incremental Continual Learning</b>
<a href="https://arxiv.org/abs/2103.13885">arxiv:2103.13885</a>
&#x1F4C8; 3 <br>
<p>Zheda Mai, Ruiwen Li, Hyunwoo Kim, Scott Sanner</p></summary>
<p>

**Abstract:** Online class-incremental continual learning (CL) studies the problem of learning new classes continually from an online non-stationary data stream, intending to adapt to new data while mitigating catastrophic forgetting. While memory replay has shown promising results, the recency bias in online learning caused by the commonly used Softmax classifier remains an unsolved challenge. Although the Nearest-Class-Mean (NCM) classifier is significantly undervalued in the CL community, we demonstrate that it is a simple yet effective substitute for the Softmax classifier. It addresses the recency bias and avoids structural changes in the fully-connected layer for new classes. Moreover, we observe considerable and consistent performance gains when replacing the Softmax classifier with the NCM classifier for several state-of-the-art replay methods. To leverage the NCM classifier more effectively, data embeddings belonging to the same class should be clustered and well-separated from those with a different class label. To this end, we contribute Supervised Contrastive Replay (SCR), which explicitly encourages samples from the same class to cluster tightly in embedding space while pushing those of different classes further apart during replay-based training. Overall, we observe that our proposed SCR substantially reduces catastrophic forgetting and outperforms state-of-the-art CL methods by a significant margin on a variety of datasets.

</p>
</details>

<details><summary><b>Multiview and Multiclass Image Segmentation using Deep Learning in Fetal Echocardiography</b>
<a href="https://arxiv.org/abs/2103.12245">arxiv:2103.12245</a>
&#x1F4C8; 3 <br>
<p>Ken C. L. Wong, Elena S. Sinkovskaya, Alfred Z. Abuhamad, Tanveer Syeda-Mahmood</p></summary>
<p>

**Abstract:** Congenital heart disease (CHD) is the most common congenital abnormality associated with birth defects in the United States. Despite training efforts and substantial advancement in ultrasound technology over the past years, CHD remains an abnormality that is frequently missed during prenatal ultrasonography. Therefore, computer-aided detection of CHD can play a critical role in prenatal care by improving screening and diagnosis. Since many CHDs involve structural abnormalities, automatic segmentation of anatomical structures is an important step in the analysis of fetal echocardiograms. While existing methods mainly focus on the four-chamber view with a small number of structures, here we present a more comprehensive deep learning segmentation framework covering 14 anatomical structures in both three-vessel trachea and four-chamber views. Specifically, our framework enhances the V-Net with spatial dropout, group normalization, and deep supervision to train a segmentation model that can be applied on both views regardless of abnormalities. By identifying the pitfall of using the Dice loss when some labels are unavailable in some images, this framework integrates information from multiple views and is robust to missing structures due to anatomical anomalies, achieving an average Dice score of 79%.

</p>
</details>

<details><summary><b>Adaptive Importance Sampling for Finite-Sum Optimization and Sampling with Decreasing Step-Sizes</b>
<a href="https://arxiv.org/abs/2103.12243">arxiv:2103.12243</a>
&#x1F4C8; 3 <br>
<p>Ayoub El Hanchi, David A. Stephens</p></summary>
<p>

**Abstract:** Reducing the variance of the gradient estimator is known to improve the convergence rate of stochastic gradient-based optimization and sampling algorithms. One way of achieving variance reduction is to design importance sampling strategies. Recently, the problem of designing such schemes was formulated as an online learning problem with bandit feedback, and algorithms with sub-linear static regret were designed. In this work, we build on this framework and propose Avare, a simple and efficient algorithm for adaptive importance sampling for finite-sum optimization and sampling with decreasing step-sizes. Under standard technical conditions, we show that Avare achieves $\mathcal{O}(T^{2/3})$ and $\mathcal{O}(T^{5/6})$ dynamic regret for SGD and SGLD respectively when run with $\mathcal{O}(1/t)$ step sizes. We achieve this dynamic regret bound by leveraging our knowledge of the dynamics defined by the algorithm, and combining ideas from online learning and variance-reduced stochastic optimization. We validate empirically the performance of our algorithm and identify settings in which it leads to significant improvements.

</p>
</details>

<details><summary><b>Partitioned hybrid learning of Bayesian network structures</b>
<a href="https://arxiv.org/abs/2103.12188">arxiv:2103.12188</a>
&#x1F4C8; 3 <br>
<p>Jireh Huang, Qing Zhou</p></summary>
<p>

**Abstract:** We develop a novel hybrid method for Bayesian network structure learning called partitioned hybrid greedy search (pHGS), composed of three distinct yet compatible new algorithms: Partitioned PC (pPC) accelerates skeleton learning via a divide-and-conquer strategy, $p$-value adjacency thresholding (PATH) effectively accomplishes parameter tuning with a single execution, and hybrid greedy initialization (HGI) maximally utilizes constraint-based information to obtain a high-scoring and well-performing initial graph for greedy search. We establish structure learning consistency of our algorithms in the large-sample limit, and empirically validate our methods individually and collectively through extensive numerical comparisons. The combined merits of pPC and PATH achieve significant computational reductions compared to the PC algorithm without sacrificing the accuracy of estimated structures, and our generally applicable HGI strategy reliably improves the estimation structural accuracy of popular hybrid algorithms with negligible additional computational expense. Our empirical results demonstrate the superior empirical performance of pHGS against many state-of-the-art structure learning algorithms.

</p>
</details>

<details><summary><b>Tiny Transformers for Environmental Sound Classification at the Edge</b>
<a href="https://arxiv.org/abs/2103.12157">arxiv:2103.12157</a>
&#x1F4C8; 3 <br>
<p>David Elliott, Carlos E. Otero, Steven Wyatt, Evan Martino</p></summary>
<p>

**Abstract:** With the growth of the Internet of Things and the rise of Big Data, data processing and machine learning applications are being moved to cheap and low size, weight, and power (SWaP) devices at the edge, often in the form of mobile phones, embedded systems, or microcontrollers. The field of Cyber-Physical Measurements and Signature Intelligence (MASINT) makes use of these devices to analyze and exploit data in ways not otherwise possible, which results in increased data quality, increased security, and decreased bandwidth. However, methods to train and deploy models at the edge are limited, and models with sufficient accuracy are often too large for the edge device. Therefore, there is a clear need for techniques to create efficient AI/ML at the edge. This work presents training techniques for audio models in the field of environmental sound classification at the edge. Specifically, we design and train Transformers to classify office sounds in audio clips. Results show that a BERT-based Transformer, trained on Mel spectrograms, can outperform a CNN using 99.85% fewer parameters. To achieve this result, we first tested several audio feature extraction techniques designed for Transformers, using ESC-50 for evaluation, along with various augmentations. Our final model outperforms the state-of-the-art MFCC-based CNN on the office sounds dataset, using just over 6,000 parameters -- small enough to run on a microcontroller.

</p>
</details>

<details><summary><b>Prediction of lung and colon cancer through analysis of histopathological images by utilizing Pre-trained CNN models with visualization of class activation and saliency maps</b>
<a href="https://arxiv.org/abs/2103.12155">arxiv:2103.12155</a>
&#x1F4C8; 3 <br>
<p>Satvik Garg, Somya Garg</p></summary>
<p>

**Abstract:** Colon and Lung cancer is one of the most perilous and dangerous ailments that individuals are enduring worldwide and has become a general medical problem. To lessen the risk of death, a legitimate and early finding is particularly required. In any case, it is a truly troublesome task that depends on the experience of histopathologists. If a histologist is under-prepared it may even hazard the life of a patient. As of late, deep learning has picked up energy, and it is being valued in the analysis of Medical Imaging. This paper intends to utilize and alter the current pre-trained CNN-based model to identify lung and colon cancer utilizing histopathological images with better augmentation techniques. In this paper, eight distinctive Pre-trained CNN models, VGG16, NASNetMobile, InceptionV3, InceptionResNetV2, ResNet50, Xception, MobileNet, and DenseNet169 are trained on LC25000 dataset. The model performances are assessed on precision, recall, f1score, accuracy, and auroc score. The results exhibit that all eight models accomplished noteworthy results ranging from 96% to 100% accuracy. Subsequently, GradCAM and SmoothGrad are also used to picture the attention images of Pre-trained CNN models classifying malignant and benign images.

</p>
</details>

<details><summary><b>Edge Intelligence for Empowering IoT-based Healthcare Systems</b>
<a href="https://arxiv.org/abs/2103.12144">arxiv:2103.12144</a>
&#x1F4C8; 3 <br>
<p>Vahideh Hayyolalam, Moayad Aloqaily, Oznur Ozkasap, Mohsen Guizani</p></summary>
<p>

**Abstract:** The demand for real-time, affordable, and efficient smart healthcare services is increasing exponentially due to the technological revolution and burst of population. To meet the increasing demands on this critical infrastructure, there is a need for intelligent methods to cope with the existing obstacles in this area. In this regard, edge computing technology can reduce latency and energy consumption by moving processes closer to the data sources in comparison to the traditional centralized cloud and IoT-based healthcare systems. In addition, by bringing automated insights into the smart healthcare systems, artificial intelligence (AI) provides the possibility of detecting and predicting high-risk diseases in advance, decreasing medical costs for patients, and offering efficient treatments. The objective of this article is to highlight the benefits of the adoption of edge intelligent technology, along with AI in smart healthcare systems. Moreover, a novel smart healthcare model is proposed to boost the utilization of AI and edge technology in smart healthcare systems. Additionally, the paper discusses issues and research directions arising when integrating these different technologies together.

</p>
</details>

<details><summary><b>Leveraging Spatial and Photometric Context for Calibrated Non-Lambertian Photometric Stereo</b>
<a href="https://arxiv.org/abs/2103.12106">arxiv:2103.12106</a>
&#x1F4C8; 3 <br>
<p>David Honzátko, Engin Türetken, Pascal Fua, L. Andrea Dunbar</p></summary>
<p>

**Abstract:** The problem of estimating a surface shape from its observed reflectance properties still remains a challenging task in computer vision. The presence of global illumination effects such as inter-reflections or cast shadows makes the task particularly difficult for non-convex real-world surfaces. State-of-the-art methods for calibrated photometric stereo address these issues using convolutional neural networks (CNNs) that primarily aim to capture either the spatial context among adjacent pixels or the photometric one formed by illuminating a sample from adjacent directions.
  In this paper, we bridge these two objectives and introduce an efficient fully-convolutional architecture that can leverage both spatial and photometric context simultaneously. In contrast to existing approaches that rely on standard 2D CNNs and regress directly to surface normals, we argue that using separable 4D convolutions and regressing to 2D Gaussian heat-maps severely reduces the size of the network and makes inference more efficient. Our experimental results on a real-world photometric stereo benchmark show that the proposed approach outperforms the existing methods both in efficiency and accuracy.

</p>
</details>

<details><summary><b>Spatio-Temporal Neural Network for Fitting and Forecasting COVID-19</b>
<a href="https://arxiv.org/abs/2103.11860">arxiv:2103.11860</a>
&#x1F4C8; 3 <br>
<p>Yi-Shuai Niu, Wentao Ding, Junpeng Hu, Wenxu Xu, Stephane Canu</p></summary>
<p>

**Abstract:** We established a Spatio-Temporal Neural Network, namely STNN, to forecast the spread of the coronavirus COVID-19 outbreak worldwide in 2020. The basic structure of STNN is similar to the Recurrent Neural Network (RNN) incorporating with not only temporal data but also spatial features. Two improved STNN architectures, namely the STNN with Augmented Spatial States (STNN-A) and the STNN with Input Gate (STNN-I), are proposed, which ensure more predictability and flexibility. STNN and its variants can be trained using Stochastic Gradient Descent (SGD) algorithm and its improved variants (e.g., Adam, AdaGrad and RMSProp). Our STNN models are compared with several classical epidemic prediction models, including the fully-connected neural network (BPNN), and the recurrent neural network (RNN), the classical curve fitting models, as well as the SEIR dynamical system model. Numerical simulations demonstrate that STNN models outperform many others by providing more accurate fitting and prediction, and by handling both spatial and temporal data.

</p>
</details>

<details><summary><b>SuSketch: Surrogate Models of Gameplay as a Design Assistant</b>
<a href="https://arxiv.org/abs/2103.11726">arxiv:2103.11726</a>
&#x1F4C8; 3 <br>
<p>Panagiotis Migkotzidis, Antonios Liapis</p></summary>
<p>

**Abstract:** This paper introduces SuSketch, a design tool for first person shooter levels. SuSketch provides the designer with gameplay predictions for two competing players of specific character classes. The interface allows the designer to work side-by-side with an artificially intelligent creator and to receive varied types of feedback such as path information, predicted balance between players in a complete playthrough, or a predicted heatmap of the locations of player deaths. The system also proactively designs alternatives to the level and class pairing, and presents them to the designer as suggestions that improve the predicted balance of the game. SuSketch offers a new way of integrating machine learning into mixed-initiative co-creation tools, as a surrogate of human play trained on a large corpus of artificial playtraces. A user study with 16 game developers indicated that the tool was easy to use, but also highlighted a need to make SuSketch more accessible and more explainable.

</p>
</details>

<details><summary><b>Retinal-inspired Filtering for Dynamic Image Coding</b>
<a href="https://arxiv.org/abs/2103.11716">arxiv:2103.11716</a>
&#x1F4C8; 3 <br>
<p>Effrosyni Doutsi, Lionel Fillatre, Marc Antonini, Julien Gaulmin</p></summary>
<p>

**Abstract:** This paper introduces a novel non-Separable sPAtioteMporal filter (non-SPAM) which enables the spatiotemporal decomposition of a still-image. The construction of this filter is inspired by the model of the retina which is able to selectively transmit information to the brain. The non-SPAM filter mimics the retinal-way to extract necessary information for a dynamic encoding/decoding system. We applied the non-SPAM filter on a still image which is flashed for a long time. We prove that the non-SPAM filter decomposes the still image over a set of time-varying difference of Gaussians, which form a frame. We simulate the analysis and synthesis system based on this frame. This system results in a progressive reconstruction of the input image. Both the theoretical and numerical results show that the quality of the reconstruction improves while the time increases.

</p>
</details>

<details><summary><b>Transforming Exploratory Creativity with DeLeNoX</b>
<a href="https://arxiv.org/abs/2103.11715">arxiv:2103.11715</a>
&#x1F4C8; 3 <br>
<p>Antonios Liapis, Hector P. Martinez, Julian Togelius, Georgios N. Yannakakis</p></summary>
<p>

**Abstract:** We introduce DeLeNoX (Deep Learning Novelty Explorer), a system that autonomously creates artifacts in constrained spaces according to its own evolving interestingness criterion. DeLeNoX proceeds in alternating phases of exploration and transformation. In the exploration phases, a version of novelty search augmented with constraint handling searches for maximally diverse artifacts using a given distance function. In the transformation phases, a deep learning autoencoder learns to compress the variation between the found artifacts into a lower-dimensional space. The newly trained encoder is then used as the basis for a new distance function, transforming the criteria for the next exploration phase. In the current paper, we apply DeLeNoX to the creation of spaceships suitable for use in two-dimensional arcade-style computer games, a representative problem in procedural content generation in games. We also situate DeLeNoX in relation to the distinction between exploratory and transformational creativity, and in relation to Schmidhuber's theory of creativity through the drive for compression progress.

</p>
</details>

<details><summary><b>Predicting brain-age from raw T 1 -weighted Magnetic Resonance Imaging data using 3D Convolutional Neural Networks</b>
<a href="https://arxiv.org/abs/2103.11695">arxiv:2103.11695</a>
&#x1F4C8; 3 <br>
<p>Lukas Fisch, Jan Ernsting, Nils R. Winter, Vincent Holstein, Ramona Leenings, Marie Beisemann, Kelvin Sarink, Daniel Emden, Nils Opel, Ronny Redlich, Jonathan Repple, Dominik Grotegerd, Susanne Meinert, Niklas Wulms, Heike Minnerup, Jochen G. Hirsch, Thoralf Niendorf, Beate Endemann, Fabian Bamberg, Thomas Kröncke, Annette Peters, Robin Bülow, Henry Völzke, Oyunbileg von Stackelberg, Ramona Felizitas Sowade</p></summary>
<p>

**Abstract:** Age prediction based on Magnetic Resonance Imaging (MRI) data of the brain is a biomarker to quantify the progress of brain diseases and aging. Current approaches rely on preparing the data with multiple preprocessing steps, such as registering voxels to a standardized brain atlas, which yields a significant computational overhead, hampers widespread usage and results in the predicted brain-age to be sensitive to preprocessing parameters. Here we describe a 3D Convolutional Neural Network (CNN) based on the ResNet architecture being trained on raw, non-registered T$_ 1$-weighted MRI data of N=10,691 samples from the German National Cohort and additionally applied and validated in N=2,173 samples from three independent studies using transfer learning. For comparison, state-of-the-art models using preprocessed neuroimaging data are trained and validated on the same samples. The 3D CNN using raw neuroimaging data predicts age with a mean average deviation of 2.84 years, outperforming the state-of-the-art brain-age models using preprocessed data. Since our approach is invariant to preprocessing software and parameter choices, it enables faster, more robust and more accurate brain-age modeling.

</p>
</details>

<details><summary><b>Feature Selection for Imbalanced Data with Deep Sparse Autoencoders Ensemble</b>
<a href="https://arxiv.org/abs/2103.11678">arxiv:2103.11678</a>
&#x1F4C8; 3 <br>
<p>Michela C. Massi, Francesca Ieva, Francesca Gasperoni, Anna Maria Paganoni</p></summary>
<p>

**Abstract:** Class imbalance is a common issue in many domain applications of learning algorithms. Oftentimes, in the same domains it is much more relevant to correctly classify and profile minority class observations. This need can be addressed by Feature Selection (FS), that offers several further advantages, s.a. decreasing computational costs, aiding inference and interpretability. However, traditional FS techniques may become sub-optimal in the presence of strongly imbalanced data. To achieve FS advantages in this setting, we propose a filtering FS algorithm ranking feature importance on the basis of the Reconstruction Error of a Deep Sparse AutoEncoders Ensemble (DSAEE). We use each DSAE trained only on majority class to reconstruct both classes. From the analysis of the aggregated Reconstruction Error, we determine the features where the minority class presents a different distribution of values w.r.t. the overrepresented one, thus identifying the most relevant features to discriminate between the two. We empirically demonstrate the efficacy of our algorithm in several experiments on high-dimensional datasets of varying sample size, showcasing its capability to select relevant and generalizable features to profile and classify minority class, outperforming other benchmark FS methods. We also briefly present a real application in radiogenomics, where the methodology was applied successfully.

</p>
</details>

<details><summary><b>Project-Level Encoding for Neural Source Code Summarization of Subroutines</b>
<a href="https://arxiv.org/abs/2103.11599">arxiv:2103.11599</a>
&#x1F4C8; 3 <br>
<p>Aakash Bansal, Sakib Haque, Collin McMillan</p></summary>
<p>

**Abstract:** Source code summarization of a subroutine is the task of writing a short, natural language description of that subroutine. The description usually serves in documentation aimed at programmers, where even brief phrase (e.g. "compresses data to a zip file") can help readers rapidly comprehend what a subroutine does without resorting to reading the code itself. Techniques based on neural networks (and encoder-decoder model designs in particular) have established themselves as the state-of-the-art. Yet a problem widely recognized with these models is that they assume the information needed to create a summary is present within the code being summarized itself - an assumption which is at odds with program comprehension literature. Thus a current research frontier lies in the question of encoding source code context into neural models of summarization. In this paper, we present a project-level encoder to improve models of code summarization. By project-level, we mean that we create a vectorized representation of selected code files in a software project, and use that representation to augment the encoder of state-of-the-art neural code summarization techniques. We demonstrate how our encoder improves several existing models, and provide guidelines for maximizing improvement while controlling time and resource costs in model size.

</p>
</details>

<details><summary><b>Adaptive Degradation Process with Deep Learning-Driven Trajectory</b>
<a href="https://arxiv.org/abs/2103.11598">arxiv:2103.11598</a>
&#x1F4C8; 3 <br>
<p>Li Yang</p></summary>
<p>

**Abstract:** Remaining useful life (RUL) estimation is a crucial component in the implementation of intelligent predictive maintenance and health management. Deep neural network (DNN) approaches have been proven effective in RUL estimation due to their capacity in handling high-dimensional non-linear degradation features. However, the applications of DNN in practice face two challenges: (a) online update of lifetime information is often unavailable, and (b) uncertainties in predicted values may not be analytically quantified. This paper addresses these issues by developing a hybrid DNN-based prognostic approach, where a Wiener-based-degradation model is enhanced with adaptive drift to characterize the system degradation. An LSTM-CNN encoder-decoder is developed to predict future degradation trajectories by jointly learning noise coefficients as well as drift coefficients, and adaptive drift is updated via Bayesian inference. A computationally efficient algorithm is proposed for the calculation of RUL distributions. Numerical experiments are presented using turbofan engines degradation data to demonstrate the superior accuracy of RUL prediction of our proposed approach.

</p>
</details>

<details><summary><b>Comprehensive process-molten pool relations modeling using CNN for wire-feed laser additive manufacturing</b>
<a href="https://arxiv.org/abs/2103.11588">arxiv:2103.11588</a>
&#x1F4C8; 3 <br>
<p>Noopur Jamnikar, Sen Liu, Craig Brice, Xiaoli Zhang</p></summary>
<p>

**Abstract:** Wire-feed laser additive manufacturing (WLAM) is gaining wide interest due to its high level of automation, high deposition rates, and good quality of printed parts. In-process monitoring and feedback controls that would reduce the uncertainty in the quality of the material are in the early stages of development. Machine learning promises the ability to accelerate the adoption of new processes and property design in additive manufacturing by making process-structure-property connections between process setting inputs and material quality outcomes. The molten pool dimensional information and temperature are the indicators for achieving the high quality of the build, which can be directly controlled by processing parameters. For the purpose of in situ quality control, the process parameters should be controlled in real-time based on sensed information from the process, in particular the molten pool. Thus, the molten pool-process relations are of preliminary importance. This paper analyzes experimentally collected in situ sensing data from the molten pool under a set of controlled process parameters in a WLAM system. The variations in the steady-state and transient state of the molten pool are presented with respect to the change of independent process parameters. A multi-modality convolutional neural network (CNN) architecture is proposed for predicting the control parameter directly from the measurable molten pool sensor data for achieving desired geometric and microstructural properties. Dropout and regularization are applied to the CNN architecture to avoid the problem of overfitting. The results highlighted that the multi-modal CNN, which receives temperature profile as an external feature to the features extracted from the image data, has improved prediction performance compared to the image-based uni-modality CNN approach.

</p>
</details>

<details><summary><b>A Novel Methodology For Crowdsourcing AI Models in an Enterprise</b>
<a href="https://arxiv.org/abs/2103.14033">arxiv:2103.14033</a>
&#x1F4C8; 2 <br>
<p>Parthasarathy Suryanarayanan, Sundar Saranathan, Shilpa Mahatma, Divya Pathak</p></summary>
<p>

**Abstract:** The evolution of AI is advancing rapidly, creating both challenges and opportunities for industry-community collaboration. In this work, we present a novel methodology aiming to facilitate this collaboration through crowdsourcing of AI models. Concretely, we have implemented a system and a process that any organization can easily adopt to host AI competitions. The system allows them to automatically harvest and evaluate the submitted models against in-house proprietary data and also to incorporate them as reusable services in a product.

</p>
</details>

<details><summary><b>RA-BNN: Constructing Robust & Accurate Binary Neural Network to Simultaneously Defend Adversarial Bit-Flip Attack and Improve Accuracy</b>
<a href="https://arxiv.org/abs/2103.13813">arxiv:2103.13813</a>
&#x1F4C8; 2 <br>
<p>Adnan Siraj Rakin, Li Yang, Jingtao Li, Fan Yao, Chaitali Chakrabarti, Yu Cao, Jae-sun Seo, Deliang Fan</p></summary>
<p>

**Abstract:** Recently developed adversarial weight attack, a.k.a. bit-flip attack (BFA), has shown enormous success in compromising Deep Neural Network (DNN) performance with an extremely small amount of model parameter perturbation. To defend against this threat, we propose RA-BNN that adopts a complete binary (i.e., for both weights and activation) neural network (BNN) to significantly improve DNN model robustness (defined as the number of bit-flips required to degrade the accuracy to as low as a random guess). However, such an aggressive low bit-width model suffers from poor clean (i.e., no attack) inference accuracy. To counter this, we propose a novel and efficient two-stage network growing method, named Early-Growth. It selectively grows the channel size of each BNN layer based on channel-wise binary masks training with Gumbel-Sigmoid function. Apart from recovering the inference accuracy, our RA-BNN after growing also shows significantly higher resistance to BFA. Our evaluation of the CIFAR-10 dataset shows that the proposed RA-BNN can improve the clean model accuracy by ~2-8 %, compared with a baseline BNN, while simultaneously improving the resistance to BFA by more than 125 x. Moreover, on ImageNet, with a sufficiently large (e.g., 5,000) amount of bit-flips, the baseline BNN accuracy drops to 4.3 % from 51.9 %, while our RA-BNN accuracy only drops to 37.1 % from 60.9 % (9 % clean accuracy improvement).

</p>
</details>

<details><summary><b>Drop-Bottleneck: Learning Discrete Compressed Representation for Noise-Robust Exploration</b>
<a href="https://arxiv.org/abs/2103.12300">arxiv:2103.12300</a>
&#x1F4C8; 2 <br>
<p>Jaekyeom Kim, Minjung Kim, Dongyeon Woo, Gunhee Kim</p></summary>
<p>

**Abstract:** We propose a novel information bottleneck (IB) method named Drop-Bottleneck, which discretely drops features that are irrelevant to the target variable. Drop-Bottleneck not only enjoys a simple and tractable compression objective but also additionally provides a deterministic compressed representation of the input variable, which is useful for inference tasks that require consistent representation. Moreover, it can jointly learn a feature extractor and select features considering each feature dimension's relevance to the target task, which is unattainable by most neural network-based IB methods. We propose an exploration method based on Drop-Bottleneck for reinforcement learning tasks. In a multitude of noisy and reward sparse maze navigation tasks in VizDoom (Kempka et al., 2016) and DMLab (Beattie et al., 2016), our exploration method achieves state-of-the-art performance. As a new IB framework, we demonstrate that Drop-Bottleneck outperforms Variational Information Bottleneck (VIB) (Alemi et al., 2017) in multiple aspects including adversarial robustness and dimensionality reduction.

</p>
</details>

<details><summary><b>Stochastic Reweighted Gradient Descent</b>
<a href="https://arxiv.org/abs/2103.12293">arxiv:2103.12293</a>
&#x1F4C8; 2 <br>
<p>Ayoub El Hanchi, David A. Stephens</p></summary>
<p>

**Abstract:** Despite the strong theoretical guarantees that variance-reduced finite-sum optimization algorithms enjoy, their applicability remains limited to cases where the memory overhead they introduce (SAG/SAGA), or the periodic full gradient computation they require (SVRG/SARAH) are manageable. A promising approach to achieving variance reduction while avoiding these drawbacks is the use of importance sampling instead of control variates. While many such methods have been proposed in the literature, directly proving that they improve the convergence of the resulting optimization algorithm has remained elusive. In this work, we propose an importance-sampling-based algorithm we call SRG (stochastic reweighted gradient). We analyze the convergence of SRG in the strongly-convex case and show that, while it does not recover the linear rate of control variates methods, it provably outperforms SGD. We pay particular attention to the time and memory overhead of our proposed method, and design a specialized red-black tree allowing its efficient implementation. Finally, we present empirical results to support our findings.

</p>
</details>

<details><summary><b>Conditional Training with Bounding Map for Universal Lesion Detection</b>
<a href="https://arxiv.org/abs/2103.12277">arxiv:2103.12277</a>
&#x1F4C8; 2 <br>
<p>Han Li, Long Chen, Hu Han, S. Kevin Zhou</p></summary>
<p>

**Abstract:** Universal Lesion Detection (ULD) in computed tomography plays an essential role in computer-aided diagnosis. Promising ULD results have been reported by coarse-to-fine two-stage detection approaches, but such two-stage ULD methods still suffer from issues like imbalance of positive v.s. negative anchors during object proposal and insufficient supervision problem during localization regression and classification of the region of interest (RoI) proposals. While leveraging pseudo segmentation masks such as bounding map (BM) can reduce the above issues to some degree, it is still an open problem to effectively handle the diverse lesion shapes and sizes in ULD. In this paper, we propose a BM-based conditional training for two-stage ULD, which can (i) reduce positive vs. negative anchor imbalance via BM-based conditioning (BMC) mechanism for anchor sampling instead of traditional IoU-based rule; and (ii) adaptively compute size-adaptive BM (ABM) from lesion bounding box, which is used for improving lesion localization accuracy via ABMsupervised segmentation. Experiments with four state-of-the-art methods show that the proposed approach can bring an almost free detection accuracy improvement without requiring expensive lesion mask annotations.

</p>
</details>

<details><summary><b>Dilated SpineNet for Semantic Segmentation</b>
<a href="https://arxiv.org/abs/2103.12270">arxiv:2103.12270</a>
&#x1F4C8; 2 <br>
<p>Abdullah Rashwan, Xianzhi Du, Xiaoqi Yin, Jing Li</p></summary>
<p>

**Abstract:** Scale-permuted networks have shown promising results on object bounding box detection and instance segmentation. Scale permutation and cross-scale fusion of features enable the network to capture multi-scale semantics while preserving spatial resolution. In this work, we evaluate this meta-architecture design on semantic segmentation - another vision task that benefits from high spatial resolution and multi-scale feature fusion at different network stages. By further leveraging dilated convolution operations, we propose SpineNet-Seg, a network discovered by NAS that is searched from the DeepLabv3 system. SpineNet-Seg is designed with a better scale-permuted network topology with customized dilation ratios per block on a semantic segmentation task. SpineNet-Seg models outperform the DeepLabv3/v3+ baselines at all model scales on multiple popular benchmarks in speed and accuracy. In particular, our SpineNet-S143+ model achieves the new state-of-the-art on the popular Cityscapes benchmark at 83.04% mIoU and attained strong performance on the PASCAL VOC2012 benchmark at 85.56% mIoU. SpineNet-Seg models also show promising results on a challenging Street View segmentation dataset. Code and checkpoints will be open-sourced.

</p>
</details>

<details><summary><b>Hallucination of speech recognition errors with sequence to sequence learning</b>
<a href="https://arxiv.org/abs/2103.12258">arxiv:2103.12258</a>
&#x1F4C8; 2 <br>
<p>Prashant Serai, Vishal Sunder, Eric Fosler-Lussier</p></summary>
<p>

**Abstract:** Automatic Speech Recognition (ASR) is an imperfect process that results in certain mismatches in ASR output text when compared to plain written text or transcriptions. When plain text data is to be used to train systems for spoken language understanding or ASR, a proven strategy to reduce said mismatch and prevent degradations, is to hallucinate what the ASR outputs would be given a gold transcription. Prior work in this domain has focused on modeling errors at the phonetic level, while using a lexicon to convert the phones to words, usually accompanied by an FST Language model. We present novel end-to-end models to directly predict hallucinated ASR word sequence outputs, conditioning on an input word sequence as well as a corresponding phoneme sequence. This improves prior published results for recall of errors from an in-domain ASR system's transcription of unseen data, as well as an out-of-domain ASR system's transcriptions of audio from an unrelated task, while additionally exploring an in-between scenario when limited characterization data from the test ASR system is obtainable. To verify the extrinsic validity of the method, we also use our hallucinated ASR errors to augment training for a spoken question classifier, finding that they enable robustness to real ASR errors in a downstream task, when scarce or even zero task-specific audio was available at train-time.

</p>
</details>

<details><summary><b>Spatio-Temporal Sparsification for General Robust Graph Convolution Networks</b>
<a href="https://arxiv.org/abs/2103.12256">arxiv:2103.12256</a>
&#x1F4C8; 2 <br>
<p>Mingming Lu, Ya Zhang</p></summary>
<p>

**Abstract:** Graph Neural Networks (GNNs) have attracted increasing attention due to its successful applications on various graph-structure data. However, recent studies have shown that adversarial attacks are threatening the functionality of GNNs. Although numerous works have been proposed to defend adversarial attacks from various perspectives, most of them can be robust against the attacks only on specific scenarios. To address this shortage of robust generalization, we propose to defend the adversarial attacks on GNN through applying the Spatio-Temporal sparsification (called ST-Sparse) on the GNN hidden node representation. ST-Sparse is similar to the Dropout regularization in spirit. Through intensive experiment evaluation with GCN as the target GNN model, we identify the benefits of ST-Sparse as follows: (1) ST-Sparse shows the defense performance improvement in most cases, as it can effectively increase the robust accuracy by up to 6\% improvement; (2) ST-Sparse illustrates its robust generalization capability by integrating with the existing defense methods, similar to the integration of Dropout into various deep learning models as a standard regularization technique; (3) ST-Sparse also shows its ordinary generalization capability on clean datasets, in that ST-SparseGCN (the integration of ST-Sparse and the original GCN) even outperform the original GCN, while the other three representative defense methods are inferior to the original GCN.

</p>
</details>

<details><summary><b>Efficient sign language recognition system and dataset creation method based on deep learning and image processing</b>
<a href="https://arxiv.org/abs/2103.12233">arxiv:2103.12233</a>
&#x1F4C8; 2 <br>
<p>Alvaro Leandro Cavalcante Carneiro, Lucas de Brito Silva, Denis Henrique Pinheiro Salvadeo</p></summary>
<p>

**Abstract:** New deep-learning architectures are created every year, achieving state-of-the-art results in image recognition and leading to the belief that, in a few years, complex tasks such as sign language translation will be considerably easier, serving as a communication tool for the hearing-impaired community. On the other hand, these algorithms still need a lot of data to be trained and the dataset creation process is expensive, time-consuming, and slow. Thereby, this work aims to investigate techniques of digital image processing and machine learning that can be used to create a sign language dataset effectively. We argue about data acquisition, such as the frames per second rate to capture or subsample the videos, the background type, preprocessing, and data augmentation, using convolutional neural networks and object detection to create an image classifier and comparing the results based on statistical tests. Different datasets were created to test the hypotheses, containing 14 words used daily and recorded by different smartphones in the RGB color system. We achieved an accuracy of 96.38% on the test set and 81.36% on the validation set containing more challenging conditions, showing that 30 FPS is the best frame rate subsample to train the classifier, geometric transformations work better than intensity transformations, and artificial background creation is not effective to model generalization. These trade-offs should be considered in future work as a cost-benefit guideline between computational cost and accuracy gain when creating a dataset and training a sign recognition model.

</p>
</details>

<details><summary><b>Online Baum-Welch algorithm for Hierarchical Imitation Learning</b>
<a href="https://arxiv.org/abs/2103.12197">arxiv:2103.12197</a>
&#x1F4C8; 2 <br>
<p>Vittorio Giammarino, Ioannis Ch. Paschalidis</p></summary>
<p>

**Abstract:** The options framework for hierarchical reinforcement learning has increased its popularity in recent years and has made improvements in tackling the scalability problem in reinforcement learning. Yet, most of these recent successes are linked with a proper options initialization or discovery. When an expert is available, the options discovery problem can be addressed by learning an options-type hierarchical policy directly from expert demonstrations. This problem is referred to as hierarchical imitation learning and can be handled as an inference problem in a Hidden Markov Model, which is done via an Expectation-Maximization type algorithm. In this work, we propose a novel online algorithm to perform hierarchical imitation learning in the options framework. Further, we discuss the benefits of such an algorithm and compare it with its batch version in classical reinforcement learning benchmarks. We show that this approach works well in both discrete and continuous environments and, under certain conditions, it outperforms the batch version.

</p>
</details>

<details><summary><b>Combining Reward Information from Multiple Sources</b>
<a href="https://arxiv.org/abs/2103.12142">arxiv:2103.12142</a>
&#x1F4C8; 2 <br>
<p>Dmitrii Krasheninnikov, Rohin Shah, Herke van Hoof</p></summary>
<p>

**Abstract:** Given two sources of evidence about a latent variable, one can combine the information from both by multiplying the likelihoods of each piece of evidence. However, when one or both of the observation models are misspecified, the distributions will conflict. We study this problem in the setting with two conflicting reward functions learned from different sources. In such a setting, we would like to retreat to a broader distribution over reward functions, in order to mitigate the effects of misspecification. We assume that an agent will maximize expected reward given this distribution over reward functions, and identify four desiderata for this setting. We propose a novel algorithm, Multitask Inverse Reward Design (MIRD), and compare it to a range of simple baselines. While all methods must trade off between conservatism and informativeness, through a combination of theory and empirical results on a toy environment, we find that MIRD and its variant MIRD-IF strike a good balance between the two.

</p>
</details>

<details><summary><b>A Deep Learning Approach for Active Anomaly Detection of Extragalactic Transients</b>
<a href="https://arxiv.org/abs/2103.12102">arxiv:2103.12102</a>
&#x1F4C8; 2 <br>
<p>V. Ashley Villar, Miles Cranmer, Edo Berger, Gabriella Contardo, Shirley Ho, Griffin Hosseinzadeh, Joshua Yao-Yu Lin</p></summary>
<p>

**Abstract:** There is a shortage of multi-wavelength and spectroscopic followup capabilities given the number of transient and variable astrophysical events discovered through wide-field, optical surveys such as the upcoming Vera C. Rubin Observatory. From the haystack of potential science targets, astronomers must allocate scarce resources to study a selection of needles in real time. Here we present a variational recurrent autoencoder neural network to encode simulated Rubin Observatory extragalactic transient events using 1% of the PLAsTiCC dataset to train the autoencoder. Our unsupervised method uniquely works with unlabeled, real time, multivariate and aperiodic data. We rank 1,129,184 events based on an anomaly score estimated using an isolation forest. We find that our pipeline successfully ranks rarer classes of transients as more anomalous. Using simple cuts in anomaly score and uncertainty, we identify a pure (~95% pure) sample of rare transients (i.e., transients other than Type Ia, Type II and Type Ibc supernovae) including superluminous and pair-instability supernovae. Finally, our algorithm is able to identify these transients as anomalous well before peak, enabling real-time follow up studies in the era of the Rubin Observatory.

</p>
</details>

<details><summary><b>Am I fit for this physical activity? Neural embedding of physical conditioning from inertial sensors</b>
<a href="https://arxiv.org/abs/2103.12095">arxiv:2103.12095</a>
&#x1F4C8; 2 <br>
<p>Davi Pedrosa de Aguiar, Fabricio Murai</p></summary>
<p>

**Abstract:** Inertial Measurement Unit (IMU) sensors are present in everyday devices such as smartphones and fitness watches. As a result, the array of health-related research and applications that tap onto this data has been growing, but little attention has been devoted to the prediction of an individual's heart rate (HR) from IMU data, when undergoing a physical activity. Would that be even possible? If so, this could be used to design personalized sets of aerobic exercises, for instance. In this work, we show that it is viable to obtain accurate HR predictions from IMU data using Recurrent Neural Networks, provided only access to HR and IMU data from a short-lived, previously executed activity. We propose a novel method for initializing an RNN's hidden state vectors, using a specialized network that attempts to extract an embedding of the physical conditioning (PCE) of a subject. We show that using a discriminator in the training phase to help the model learn whether two PCEs belong to the same individual further reduces the prediction error. We evaluate the proposed model when predicting the HR of 23 subjects performing a variety of physical activities from IMU data available in public datasets (PAMAP2, PPG-DaLiA). For comparison, we use as baselines the only model specifically proposed for this task and an adapted state-of-the-art model for Human Activity Recognition (HAR), a closely related task. Our method, PCE-LSTM, yields over 10% lower mean absolute error. We demonstrate empirically that this error reduction is in part due to the use of the PCE. Last, we use the two datasets (PPG-DaLiA, WESAD) to show that PCE-LSTM can also be successfully applied when photoplethysmography (PPG) sensors are available, outperforming the state-of-the-art deep learning baselines by more than 30%.

</p>
</details>

<details><summary><b>Exemplars can Reciprocate Principal Components</b>
<a href="https://arxiv.org/abs/2103.12069">arxiv:2103.12069</a>
&#x1F4C8; 2 <br>
<p>Kieran Greer</p></summary>
<p>

**Abstract:** This paper presents a clustering algorithm that is an extension of the Category Trees algorithm. Category Trees is a clustering method that creates tree structures that branch on category type and not feature. The development in this paper is to consider a secondary order of clustering that is not the category to which the data row belongs, but the tree, representing a single classifier, that it is eventually clustered with. Each tree branches to store subsets of other categories, but the rows in those subsets may also be related. This paper is therefore concerned with looking at that second level of clustering between the other category subsets, to try to determine if there is any consistency over it. It is argued that Principal Components may be a related and reciprocal type of structure, and there is an even bigger question about the relation between exemplars and principal components, in general. The theory is demonstrated using the Portugal Forest Fires dataset as a case study. The Category Trees are then combined with other Self-Organising algorithms from the author and it is suggested that they all belong to the same family type, which is an Entropy-style of classifier.

</p>
</details>

<details><summary><b>Identifying Machine-Paraphrased Plagiarism</b>
<a href="https://arxiv.org/abs/2103.11909">arxiv:2103.11909</a>
&#x1F4C8; 2 <br>
<p>Jan Philip Wahle, Terry Ruas, Tomáš Foltýnek, Norman Meuschke, Bela Gipp</p></summary>
<p>

**Abstract:** Employing paraphrasing tools to conceal plagiarized text is a severe threat to academic integrity. To enable the detection of machine-paraphrased text, we evaluate the effectiveness of five pre-trained word embedding models combined with machine learning classifiers and state-of-the-art neural language models. We analyze preprints of research papers, graduation theses, and Wikipedia articles, which we paraphrased using different configurations of the tools SpinBot and SpinnerChief. The best performing technique, Longformer, achieved an average F1 score of 80.99% (F1=99.68% for SpinBot and F1=71.64% for SpinnerChief cases), while human evaluators achieved F1=78.4% for SpinBot and F1=65.6% for SpinnerChief cases. We show that the automated classification alleviates shortcomings of widely-used text-matching systems, such as Turnitin and PlagScan. To facilitate future research, all data, code, and two web applications showcasing our contributions are openly available.

</p>
</details>

<details><summary><b>BlonD: An Automatic Evaluation Metric for Document-level MachineTranslation</b>
<a href="https://arxiv.org/abs/2103.11878">arxiv:2103.11878</a>
&#x1F4C8; 2 <br>
<p>Yuchen Jiang, Shuming Ma, Dongdong Zhang, Jian Yang, Haoyang Huang, Ming Zhou</p></summary>
<p>

**Abstract:** Standard automatic metrics (such as BLEU) are problematic for document-level MT evaluation. They can neither distinguish document-level improvements in translation quality from sentence-level ones nor can they identify the specific discourse phenomena that caused the translation errors. To address these problems, we propose an automatic metric BlonD for document-level machine translation evaluation. BlonD takes discourse coherence into consideration by calculating the recall and distance of check-pointing phrases and tags, and further provides comprehensive evaluation scores by combining with n-gram. Extensive comparisons between BlonD and existing evaluation metrics are conducted to illustrate their critical distinctions. Experimental results show that BlonD has a much higher document-level sensitivity with respect to previous metrics. The human evaluation also reveals high Pearson R correlation values between BlonD scores and manual quality judgments.

</p>
</details>

<details><summary><b>Online search of unknown terrains using a dynamical system-based path planning approach</b>
<a href="https://arxiv.org/abs/2103.11863">arxiv:2103.11863</a>
&#x1F4C8; 2 <br>
<p>Karan Sridharan, Zahra Nili Ahmadabadi, Jeffrey Hudack</p></summary>
<p>

**Abstract:** Surveillance and exploration of large environments is a tedious task. In spaces with limited environmental cues, random-like search appears to be an effective approach as it allows the robot to perform online coverage of environments using a simple design. One way to generate random-like scanning is to use nonlinear dynamical systems to impart chaos into the robot's controller. This will result in generation of unpredictable but at the same time deterministic trajectories, allowing the designer to control the system and achieve a high scanning coverage. However, the unpredictability comes at the cost of increased coverage time and lack of scalability, both of which have been ignored by the state-of-the-art chaotic path planners. This study introduces a new scalable technique that helps a robot to steer away from the obstacles and cover the entire space in a short period of time. The technique involves coupling and manipulating two chaotic systems to minimize the coverage time and enable scanning of unknown environments with different properties online. Using this technique resulted in 49% boost, on average, in the robot's performance compared to the state-of-the-art planners. While ensuring unpredictability in the paths, the overall performance of the chaotic planner remained comparable to optimal systems.

</p>
</details>

<details><summary><b>Learning to Simulate on Sparse Trajectory Data</b>
<a href="https://arxiv.org/abs/2103.11845">arxiv:2103.11845</a>
&#x1F4C8; 2 <br>
<p>Hua Wei, Chacha Chen, Chang Liu, Guanjie Zheng, Zhenhui Li</p></summary>
<p>

**Abstract:** Simulation of the real-world traffic can be used to help validate the transportation policies. A good simulator means the simulated traffic is similar to real-world traffic, which often requires dense traffic trajectories (i.e., with a high sampling rate) to cover dynamic situations in the real world. However, in most cases, the real-world trajectories are sparse, which makes simulation challenging. In this paper, we present a novel framework ImInGAIL to address the problem of learning to simulate the driving behavior from sparse real-world data. The proposed architecture incorporates data interpolation with the behavior learning process of imitation learning. To the best of our knowledge, we are the first to tackle the data sparsity issue for behavior learning problems. We investigate our framework on both synthetic and real-world trajectory datasets of driving vehicles, showing that our method outperforms various baselines and state-of-the-art methods.

</p>
</details>

<details><summary><b>DeepOPF-V: Solving AC-OPF Problems Efficiently</b>
<a href="https://arxiv.org/abs/2103.11793">arxiv:2103.11793</a>
&#x1F4C8; 2 <br>
<p>Wanjun Huang, Xiang Pan, Minghua Chen, Steven H. Low</p></summary>
<p>

**Abstract:** AC optimal power flow (AC-OPF) problems need to be solved more frequently in the future to maintain stable and economic power system operation. To tackle this challenge, a deep neural network-based voltage-constrained approach (DeepOPF-V) is proposed to solve AC-OPF problems with high computational efficiency. Its unique design predicts voltages of all buses and then uses them to reconstruct the remaining variables without solving non-linear AC power flow equations. A fast post-processing process is developed to enforce the box constraints. The effectiveness of DeepOPF-V is validated by simulations on IEEE 118/300-bus systems and a 2000-bus test system. Compared with existing studies, DeepOPF-V achieves decent computation speedup up to four orders of magnitude and comparable performance in optimality gap and preserving the feasibility of the solution.

</p>
</details>

<details><summary><b>Numerical comparisons between Bayesian and frequentist low-rank matrix completion: estimation accuracy and uncertainty quantification</b>
<a href="https://arxiv.org/abs/2103.11749">arxiv:2103.11749</a>
&#x1F4C8; 2 <br>
<p>The Tien Mai</p></summary>
<p>

**Abstract:** In this paper we perform a numerious numerical studies for the problem of low-rank matrix completion. We compare the Bayesain approaches and a recently introduced de-biased estimator which provides a useful way to build confidence intervals of interest. From a theoretical viewpoint, the de-biased estimator comes with a sharp minimax-optinmal rate of estimation error whereas the Bayesian approach reaches this rate with an additional logarithmic factor. Our simulation studies show originally interesting results that the de-biased estimator is just as good as the Bayesain estimators. Moreover, Bayesian approaches are much more stable and can outperform the de-biased estimator in the case of small samples. However, we also find that the length of the confidence intervals revealed by the de-biased estimator for an entry is absolutely shorter than the length of the considered credible interval. These suggest further theoretical studies on the estimation error and the concentration for Bayesian methods as they are being quite limited up to present.

</p>
</details>

<details><summary><b>Evaluating glioma growth predictions as a forward ranking problem</b>
<a href="https://arxiv.org/abs/2103.11651">arxiv:2103.11651</a>
&#x1F4C8; 2 <br>
<p>Karin A. van Garderen, Sebastian R. van der Voort, Maarten M. J. Wijnenga, Fatih Incekara, Georgios Kapsas, Renske Gahrmann, Ahmad Alafandi, Marion Smits, Stefan Klein</p></summary>
<p>

**Abstract:** The problem of tumor growth prediction is challenging, but promising results have been achieved with both model-driven and statistical methods. In this work, we present a framework for the evaluation of growth predictions that focuses on the spatial infiltration patterns, and specifically evaluating a prediction of future growth. We propose to frame the problem as a ranking problem rather than a segmentation problem. Using the average precision as a metric, we can evaluate the results with segmentations while using the full spatiotemporal prediction. Furthermore, by separating the model goodness-of-fit from future predictive performance, we show that in some cases, a better fit of model parameters does not guarantee a better the predictive power.

</p>
</details>

<details><summary><b>D3p -- A Python Package for Differentially-Private Probabilistic Programming</b>
<a href="https://arxiv.org/abs/2103.11648">arxiv:2103.11648</a>
&#x1F4C8; 2 <br>
<p>Lukas Prediger, Niki Loppi, Samuel Kaski, Antti Honkela</p></summary>
<p>

**Abstract:** We present d3p, a software package designed to help fielding runtime efficient widely-applicable Bayesian inference under differential privacy guarantees. d3p achieves general applicability to a wide range of probabilistic modelling problems by implementing the differentially private variational inference algorithm, allowing users to fit any parametric probabilistic model with a differentiable density function. d3p adopts the probabilistic programming paradigm as a powerful way for the user to flexibly define such models. We demonstrate the use of our software on a hierarchical logistic regression example, showing the expressiveness of the modelling approach as well as the ease of running the parameter inference. We also perform an empirical evaluation of the runtime of the private inference on a complex model and find a $\sim$10 fold speed-up compared to an implementation using TensorFlow Privacy.

</p>
</details>

<details><summary><b>A Batch Normalization Classifier for Domain Adaptation</b>
<a href="https://arxiv.org/abs/2103.11642">arxiv:2103.11642</a>
&#x1F4C8; 2 <br>
<p>Matthew R. Behrend, Sean M. Robinson</p></summary>
<p>

**Abstract:** Adapting a model to perform well on unforeseen data outside its training set is a common problem that continues to motivate new approaches. We demonstrate that application of batch normalization in the output layer, prior to softmax activation, results in improved generalization across visual data domains in a refined ResNet model. The approach adds negligible computational complexity yet outperforms many domain adaptation methods that explicitly learn to align data domains. We benchmark this technique on the Office-Home dataset and show that batch normalization is competitive with other leading methods. We show that this method is not sensitive to presence of source data during adaptation and further present the impact on trained tensor distributions tends toward sparsity. Code is available at https://github.com/matthewbehrend/BNC

</p>
</details>

<details><summary><b>PriorityCut: Occlusion-guided Regularization for Warp-based Image Animation</b>
<a href="https://arxiv.org/abs/2103.11600">arxiv:2103.11600</a>
&#x1F4C8; 2 <br>
<p>Wai Ting Cheung, Gyeongsu Chae</p></summary>
<p>

**Abstract:** Image animation generates a video of a source image following the motion of a driving video. State-of-the-art self-supervised image animation approaches warp the source image according to the motion of the driving video and recover the warping artifacts by inpainting. These approaches mostly use vanilla convolution for inpainting, and vanilla convolution does not distinguish between valid and invalid pixels. As a result, visual artifacts are still noticeable after inpainting. CutMix is a state-of-the-art regularization strategy that cuts and mixes patches of images and is widely studied in different computer vision tasks. Among the remaining computer vision tasks, warp-based image animation is one of the fields that the effects of CutMix have yet to be studied. This paper first presents a preliminary study on the effects of CutMix on warp-based image animation. We observed in our study that CutMix helps improve only pixel values, but disturbs the spatial relationships between pixels. Based on such observation, we propose PriorityCut, a novel augmentation approach that uses the top-k percent occluded pixels of the foreground to regularize warp-based image animation. By leveraging the domain knowledge in warp-based image animation, PriorityCut significantly reduces the warping artifacts in state-of-the-art warp-based image animation models on diverse datasets.

</p>
</details>

<details><summary><b>Adversarially Optimized Mixup for Robust Classification</b>
<a href="https://arxiv.org/abs/2103.11589">arxiv:2103.11589</a>
&#x1F4C8; 2 <br>
<p>Jason Bunk, Srinjoy Chattopadhyay, B. S. Manjunath, Shivkumar Chandrasekaran</p></summary>
<p>

**Abstract:** Mixup is a procedure for data augmentation that trains networks to make smoothly interpolated predictions between datapoints. Adversarial training is a strong form of data augmentation that optimizes for worst-case predictions in a compact space around each data-point, resulting in neural networks that make much more robust predictions. In this paper, we bring these ideas together by adversarially probing the space between datapoints, using projected gradient descent (PGD). The fundamental approach in this work is to leverage backpropagation through the mixup interpolation during training to optimize for places where the network makes unsmooth and incongruous predictions. Additionally, we also explore several modifications and nuances, like optimization of the mixup ratio and geometrical label assignment, and discuss their impact on enhancing network robustness. Through these ideas, we have been able to train networks that robustly generalize better; experiments on CIFAR-10 and CIFAR-100 demonstrate consistent improvements in accuracy against strong adversaries, including the recent strong ensemble attack AutoAttack. Our source code would be released for reproducibility.

</p>
</details>

<details><summary><b>Power Modeling for Effective Datacenter Planning and Compute Management</b>
<a href="https://arxiv.org/abs/2103.13308">arxiv:2103.13308</a>
&#x1F4C8; 1 <br>
<p>Ana Radovanovic, Bokan Chen, Saurav Talukdar, Binz Roy, Alexandre Duarte, Mahya Shahbazi</p></summary>
<p>

**Abstract:** Datacenter power demand has been continuously growing and is the key driver of its cost. An accurate mapping of compute resources (CPU, RAM, etc.) and hardware types (servers, accelerators, etc.) to power consumption has emerged as a critical requirement for major Web and cloud service providers. With the global growth in datacenter capacity and associated power consumption, such models are essential for important decisions around datacenter design and operation. In this paper, we discuss two classes of statistical power models designed and validated to be accurate, simple, interpretable and applicable to all hardware configurations and workloads across hyperscale datacenters of Google fleet. To the best of our knowledge, this is the largest scale power modeling study of this kind, in both the scope of diverse datacenter planning and real-time management use cases, as well as the variety of hardware configurations and workload types used for modeling and validation. We demonstrate that the proposed statistical modeling techniques, while simple and scalable, predict power with less than 5% Mean Absolute Percent Error (MAPE) for more than 95% diverse Power Distribution Units (more than 2000) using only 4 features. This performance matches the reported accuracy of the previous started-of-the-art methods, while using significantly less features and covering a wider range of use cases.

</p>
</details>

<details><summary><b>Fairness Perceptions of Algorithmic Decision-Making: A Systematic Review of the Empirical Literature</b>
<a href="https://arxiv.org/abs/2103.12016">arxiv:2103.12016</a>
&#x1F4C8; 1 <br>
<p>Christopher Starke, Janine Baleis, Birte Keller, Frank Marcinkowski</p></summary>
<p>

**Abstract:** Algorithmic decision-making (ADM) increasingly shapes people's daily lives. Given that such autonomous systems can cause severe harm to individuals and social groups, fairness concerns have arisen. A human-centric approach demanded by scholars and policymakers requires taking people's fairness perceptions into account when designing and implementing ADM. We provide a comprehensive, systematic literature review synthesizing the existing empirical insights on perceptions of algorithmic fairness from 39 empirical studies spanning multiple domains and scientific disciplines. Through thorough coding, we systemize the current empirical literature along four dimensions: (a) algorithmic predictors, (b) human predictors, (c) comparative effects (human decision-making vs. algorithmic decision-making), and (d) consequences of ADM. While we identify much heterogeneity around the theoretical concepts and empirical measurements of algorithmic fairness, the insights come almost exclusively from Western-democratic contexts. By advocating for more interdisciplinary research adopting a society-in-the-loop framework, we hope our work will contribute to fairer and more responsible ADM.

</p>
</details>

<details><summary><b>Tackling Racial Bias in Automated Online Hate Detection: Towards Fair and Accurate Classification of Hateful Online Users Using Geometric Deep Learning</b>
<a href="https://arxiv.org/abs/2103.11806">arxiv:2103.11806</a>
&#x1F4C8; 1 <br>
<p>Zo Ahmed, Bertie Vidgen, Scott A. Hale</p></summary>
<p>

**Abstract:** Online hate is a growing concern on many social media platforms and other sites. To combat it, technology companies are increasingly identifying and sanctioning `hateful users' rather than simply moderating hateful content. Yet, most research in online hate detection to date has focused on hateful content. This paper examines how fairer and more accurate hateful user detection systems can be developed by incorporating social network information through geometric deep learning. Geometric deep learning dynamically learns information-rich network representations and can generalise to unseen nodes. This is essential for moving beyond manually engineered network features, which lack scalability and produce information-sparse network representations. This paper compares the accuracy of geometric deep learning with other techniques which either exclude network information or incorporate it through manual feature engineering (e.g., node2vec). It also evaluates the fairness of these techniques using the `predictive equality' criteria, comparing the false positive rates on a subset of 136 African-American users with 4836 other users. Geometric deep learning produces the most accurate and fairest classifier, with an AUC score of 90.8\% on the entire dataset and a false positive rate of zero among the African-American subset for the best performing model. This highlights the benefits of more effectively incorporating social network features in automated hateful user detection. Such an approach is also easily operationalized for real-world content moderation as it has an efficient and scalable design.

</p>
</details>

<details><summary><b>Evolving Continuous Optimisers from Scratch</b>
<a href="https://arxiv.org/abs/2103.11746">arxiv:2103.11746</a>
&#x1F4C8; 1 <br>
<p>Michael A. Lones</p></summary>
<p>

**Abstract:** This work uses genetic programming to explore the space of continuous optimisers, with the goal of discovering novel ways of doing optimisation. In order to keep the search space broad, the optimisers are evolved from scratch using Push, a Turing-complete, general-purpose, language. The resulting optimisers are found to be diverse, and explore their optimisation landscapes using a variety of interesting, and sometimes unusual, strategies. Significantly, when applied to problems that were not seen during training, many of the evolved optimisers generalise well, and often outperform existing optimisers. This supports the idea that novel and effective forms of optimisation can be discovered in an automated manner. This paper also shows that pools of evolved optimisers can be hybridised to further increase their generality, leading to optimisers that perform robustly over a broad variety of problem types and sizes.

</p>
</details>

<details><summary><b>Meta-DETR: Image-Level Few-Shot Object Detection with Inter-Class Correlation Exploitation</b>
<a href="https://arxiv.org/abs/2103.11731">arxiv:2103.11731</a>
&#x1F4C8; 1 <br>
<p>Gongjie Zhang, Zhipeng Luo, Kaiwen Cui, Shijian Lu</p></summary>
<p>

**Abstract:** Few-shot object detection has been extensively investigated by incorporating meta-learning into region-based detection frameworks. Despite its success, the said paradigm is constrained by several factors, such as (i) low-quality region proposals for novel classes and (ii) negligence of the inter-class correlation among different classes. Such limitations hinder the generalization of base-class knowledge for the detection of novel-class objects. In this work, we design Meta-DETR, a novel few-shot detection framework that incorporates correlational aggregation for meta-learning into DETR detection frameworks. Meta-DETR works entirely at image level without any region proposals, which circumvents the constraint of inaccurate proposals in prevalent few-shot detection frameworks. Besides, Meta-DETR can simultaneously attend to multiple support classes within a single feed-forward. This unique design allows capturing the inter-class correlation among different classes, which significantly reduces the misclassification of similar classes and enhances knowledge generalization to novel classes. Experiments over multiple few-shot object detection benchmarks show that the proposed Meta-DETR outperforms state-of-the-art methods by large margins. The implementation codes will be released at https://github.com/ZhangGongjie/Meta-DETR.

</p>
</details>

<details><summary><b>ast2vec: Utilizing Recursive Neural Encodings of Python Programs</b>
<a href="https://arxiv.org/abs/2103.11614">arxiv:2103.11614</a>
&#x1F4C8; 1 <br>
<p>Benjamin Paaßen, Jessica McBroom, Bryn Jeffries, Irena Koprinska, Kalina Yacef</p></summary>
<p>

**Abstract:** Educational datamining involves the application of datamining techniques to student activity. However, in the context of computer programming, many datamining techniques can not be applied because they expect vector-shaped input whereas computer programs have the form of syntax trees. In this paper, we present ast2vec, a neural network that maps Python syntax trees to vectors and back, thereby facilitating datamining on computer programs as well as the interpretation of datamining results. Ast2vec has been trained on almost half a million programs of novice programmers and is designed to be applied across learning tasks without re-training, meaning that users can apply it without any need for (additional) deep learning. We demonstrate the generality of ast2vec in three settings: First, we provide example analyses using ast2vec on a classroom-sized dataset, involving visualization, student motion analysis, clustering, and outlier detection, including two novel analyses, namely a progress-variance-projection and a dynamical systems analysis. Second, we consider the ability of ast2vec to recover the original syntax tree from its vector representation on the training data and two further large-scale programming datasets. Finally, we evaluate the predictive capability of a simple linear regression on top of ast2vec, obtaining similar results to techniques that work directly on syntax trees. We hope ast2vec can augment the educational datamining toolbelt by making analyses of computer programs easier, richer, and more efficient.

</p>
</details>

<details><summary><b>Variational quantum compiling with double Q-learning</b>
<a href="https://arxiv.org/abs/2103.11611">arxiv:2103.11611</a>
&#x1F4C8; 1 <br>
<p>Zhimin He, Lvzhou Li, Shenggen Zheng, Yongyao Li, Haozhen Situ</p></summary>
<p>

**Abstract:** Quantum compiling aims to construct a quantum circuit V by quantum gates drawn from a native gate alphabet, which is functionally equivalent to the target unitary U. It is a crucial stage for the running of quantum algorithms on noisy intermediate-scale quantum (NISQ) devices. However, the space for structure exploration of quantum circuit is enormous, resulting in the requirement of human expertise, hundreds of experimentations or modifications from existing quantum circuits. In this paper, we propose a variational quantum compiling (VQC) algorithm based on reinforcement learning (RL), in order to automatically design the structure of quantum circuit for VQC with no human intervention. An agent is trained to sequentially select quantum gates from the native gate alphabet and the qubits they act on by double Q-learning with ε-greedy exploration strategy and experience replay. At first, the agent randomly explores a number of quantum circuits with different structures, and then iteratively discovers structures with higher performance on the learning task. Simulation results show that the proposed method can make exact compilations with less quantum gates compared to previous VQC algorithms. It can reduce the errors of quantum algorithms due to decoherence process and gate noise in NISQ devices, and enable quantum algorithms especially for complex algorithms to be executed within coherence time.

</p>
</details>

<details><summary><b>Deep Learning for Exotic Option Valuation</b>
<a href="https://arxiv.org/abs/2103.12551">arxiv:2103.12551</a>
&#x1F4C8; 0 <br>
<p>Jay Cao, Jacky Chen, John Hull, Zissis Poulos</p></summary>
<p>

**Abstract:** A common approach to valuing exotic options involves choosing a model and then determining its parameters to fit the volatility surface as closely as possible. We refer to this as the model calibration approach (MCA). A disadvantage of MCA is that some information in the volatility surface is lost during the calibration process and the prices of exotic options will not in general be consistent with those of plain vanilla options. We consider an alternative approach where the structure of the user's preferred model is preserved but points on the volatility are features input to a neural network. We refer to this as the volatility feature approach (VFA) model. We conduct experiments showing that VFA can be expected to outperform MCA for the volatility surfaces encountered in practice. Once the upfront computational time has been invested in developing the neural network, the valuation of exotic options using VFA is very fast.

</p>
</details>

<details><summary><b>Transfer Learning with Ensembles of Deep Neural Networks for Skin Cancer Detection in Imbalanced Data Sets</b>
<a href="https://arxiv.org/abs/2103.12068">arxiv:2103.12068</a>
&#x1F4C8; 0 <br>
<p>Aqsa Saeed Qureshi, Teemu Roos</p></summary>
<p>

**Abstract:** Several machine learning techniques for accurate detection of skin cancer from medical images have been reported. Many of these techniques are based on pre-trained convolutional neural networks (CNNs), which enable training the models based on limited amounts of training data. However, the classification accuracy of these models still tends to be severely limited by the scarcity of representative images from malignant tumours. We propose a novel ensemble-based CNN architecture where multiple CNN models, some of which are pre-trained and some are trained only on the data at hand, along with auxiliary data in the form of metadata associated with the input images, are combined using a meta-learner. The proposed approach improves the model's ability to handle limited and imbalanced data. We demonstrate the benefits of the proposed technique using a dataset with 33126 dermoscopic images from 2056 patients. We evaluate the performance of the proposed technique in terms of the F1-measure, area under the ROC curve (AUC-ROC), and area under the PR-curve (AUC-PR), and compare it with that of seven different benchmark methods, including two recent CNN-based techniques. The proposed technique compares favourably in terms of all the evaluation metrics.

</p>
</details>

<details><summary><b>Regularized Optimal Transport for Dynamic Semi-supervised Learning</b>
<a href="https://arxiv.org/abs/2103.11937">arxiv:2103.11937</a>
&#x1F4C8; 0 <br>
<p>Mourad El Hamri, Younès Bennani</p></summary>
<p>

**Abstract:** Semi-supervised learning provides an effective paradigm for leveraging unlabeled data to improve a model's performance. Among the many strategies proposed, graph-based methods have shown excellent properties, in particular since they allow to solve directly the transductive tasks according to Vapnik's principle and they can be extended efficiently for inductive tasks. In this paper, we propose a novel approach for the transductive semi-supervised learning, using a complete bipartite edge-weighted graph. The proposed approach uses the regularized optimal transport between empirical measures defined on labelled and unlabelled data points in order to obtain an affinity matrix from the optimal transport plan. This matrix is further used to propagate labels through the vertices of the graph in an incremental process ensuring the certainty of the predictions by incorporating a certainty score based on Shannon's entropy. We also analyze the convergence of our approach and we derive an efficient way to extend it for out-of-sample data. Experimental analysis was used to compare the proposed approach with other label propagation algorithms on 12 benchmark datasets, for which we surpass state-of-the-art results. We release our code.

</p>
</details>

<details><summary><b>Forest Fire Clustering: Iterative Label Propagation Clustering and Monte Carlo Validation For Single-cell Sequencing Analysis</b>
<a href="https://arxiv.org/abs/2103.11802">arxiv:2103.11802</a>
&#x1F4C8; 0 <br>
<p>Zhanlin Chen, Jeremy Goldwasser, Philip Tuckman, Jing Zhang, Mark Gerstein</p></summary>
<p>

**Abstract:** With the rise of single-cell sequencing technologies, there is a growing need for robust clustering algorithms to extract deeper insights from data. Here, we introduce an intuitive and efficient clustering method, Forest Fire Clustering, for discovering and validating cell types in single-cell sequencing analysis. Compared to existing methods, our clustering algorithm makes minimum prior assumptions about the data distribution and can provide a point-wise significance value via Monte Carlo simulations for internal validation. Additionally, point-wise label entropies can highlight novel transition cell types \emph{de novo} along developmental pseudo-time manifolds. Lastly, our inductive algorithm has the ability to make robust inferences in an online-learning context. In this paper, we describe the method, provide a summary of its performance against common clustering benchmarks, and demonstrate that Forest Fire Clustering is uniquely suitable for single-cell sequencing analysis.

</p>
</details>

<details><summary><b>Automatic Pulmonary Artery-Vein Separation in CT Images using Twin-Pipe Network and Topology Reconstruction</b>
<a href="https://arxiv.org/abs/2103.11736">arxiv:2103.11736</a>
&#x1F4C8; 0 <br>
<p>Lin Pan, Yaoyong Zheng, Liqin Huang, Liuqing Chen, Zhen Zhang, Rongda Fu, Bin Zheng, Shaohua Zheng</p></summary>
<p>

**Abstract:** With the development of medical computer-aided diagnostic systems, pulmonary artery-vein(A/V) separation plays a crucial role in assisting doctors in preoperative planning for lung cancer surgery. However, distinguishing arterial from venous irrigation in chest CT images remains a challenge due to the similarity and complex structure of the arteries and veins. We propose a novel method for automatic separation of pulmonary arteries and veins from chest CT images. The method consists of three parts. First, global connection information and local feature information are used to construct a complete topological tree and ensure the continuity of vessel reconstruction. Second, the Twin-Pipe network proposed can automatically learn the differences between arteries and veins at different levels to reduce classification errors caused by changes in terminal vessel characteristics. Finally, the topology optimizer considers interbranch and intrabranch topological relationships to maintain spatial consistency to avoid the misclassification of A/V irrigations. We validate the performance of the method on chest CT images. Compared with manual classification, the proposed method achieves an average accuracy of 96.2% on noncontrast chest CT. In addition, the method has been proven to have good generalization, that is, the accuracies of 93.8% and 94.8% are obtained for CT scans from other devices and other modes, respectively. The result of pulmonary artery-vein obtained by the proposed method can provide better assistance for preoperative planning of lung cancer surgery.

</p>
</details>

<details><summary><b>IPAPRec: A promising tool for learning high-performance mapless navigation skills with deep reinforcement learning</b>
<a href="https://arxiv.org/abs/2103.11686">arxiv:2103.11686</a>
&#x1F4C8; 0 <br>
<p>Wei Zhang, Yunfeng Zhang, Ning Liu, Kai Ren, Pengfei Wang</p></summary>
<p>

**Abstract:** This paper studies how to improve the generalization performance and learning speed of the navigation agents trained with deep reinforcement learning (DRL). DRL exhibits huge potential in mapless navigation, but DRL agents performing well in training scenarios are found to perform poorly in unfamiliar real-world scenarios. In this work, we present the representation of LiDAR readings as a key factor behind agents' performance degradation and propose a simple but powerful input pre-processing (IP) approach to improve the agents' performance. As this approach uses adaptively parametric reciprocal functions to pre-process LiDAR readings, we refer to this approach as IPAPRec and its normalized version as IPAPRecN. IPAPRec/IPAPRecN can highlight important short-distance values and compress the range of less-important long-distance values in laser scans, which well addressed the issues induced by conventional representations of laser scans. Their high performance is validated by extensive simulation and real-world experiments. The results show that our methods can substantially improve agents' success rates and greatly reduce the training time compared to conventional methods.

</p>
</details>


[Next Page](2021/2021-03/2021-03-21.md)
