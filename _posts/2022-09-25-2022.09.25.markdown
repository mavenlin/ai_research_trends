Prev: [2022.09.24]({{ '/2022/09/24/2022.09.24.html' | relative_url }})  Next: [2022.09.26]({{ '/2022/09/26/2022.09.26.html' | relative_url }})
{% raw %}
## Summary for 2022-09-25, created on 2022-10-02


<details><summary><b>WinoDict: Probing language models for in-context word acquisition</b>
<a href="https://arxiv.org/abs/2209.12153">arxiv:2209.12153</a>
&#x1F4C8; 16 <br>
<p>Julian Martin Eisenschlos, Jeremy R. Cole, Fangyu Liu, William W. Cohen</p></summary>
<p>

**Abstract:** We introduce a new in-context learning paradigm to measure Large Language Models' (LLMs) ability to learn novel words during inference. In particular, we rewrite Winograd-style co-reference resolution problems by replacing the key concept word with a synthetic but plausible word that the model must understand to complete the task. Solving this task requires the model to make use of the dictionary definition of the new word given in the prompt. This benchmark addresses word acquisition, one important aspect of the diachronic degradation known to afflict LLMs. As LLMs are frozen in time at the moment they are trained, they are normally unable to reflect the way language changes over time. We show that the accuracy of LLMs compared to the original Winograd tasks decreases radically in our benchmark, thus identifying a limitation of current models and providing a benchmark to measure future improvements in LLMs ability to do in-context learning.

</p>
</details>

<details><summary><b>An Empirical Study on Cross-X Transfer for Legal Judgment Prediction</b>
<a href="https://arxiv.org/abs/2209.12325">arxiv:2209.12325</a>
&#x1F4C8; 11 <br>
<p>Joel Niklaus, Matthias St√ºrmer, Ilias Chalkidis</p></summary>
<p>

**Abstract:** Cross-lingual transfer learning has proven useful in a variety of Natural Language Processing (NLP) tasks, but it is understudied in the context of legal NLP, and not at all in Legal Judgment Prediction (LJP). We explore transfer learning techniques on LJP using the trilingual Swiss-Judgment-Prediction dataset, including cases written in three languages. We find that cross-lingual transfer improves the overall results across languages, especially when we use adapter-based fine-tuning. Finally, we further improve the model's performance by augmenting the training dataset with machine-translated versions of the original documents, using a 3x larger training corpus. Further on, we perform an analysis exploring the effect of cross-domain and cross-regional transfer, i.e., train a model across domains (legal areas), or regions. We find that in both settings (legal areas, origin regions), models trained across all groups perform overall better, while they also have improved results in the worst-case scenarios. Finally, we report improved results when we ambitiously apply cross-jurisdiction transfer, where we further augment our dataset with Indian legal cases.

</p>
</details>

<details><summary><b>FastStamp: Accelerating Neural Steganography and Digital Watermarking of Images on FPGAs</b>
<a href="https://arxiv.org/abs/2209.12391">arxiv:2209.12391</a>
&#x1F4C8; 8 <br>
<p>Shehzeen Hussain, Nojan Sheybani, Paarth Neekhara, Xinqiao Zhang, Javier Duarte, Farinaz Koushanfar</p></summary>
<p>

**Abstract:** Steganography and digital watermarking are the tasks of hiding recoverable data in image pixels. Deep neural network (DNN) based image steganography and watermarking techniques are quickly replacing traditional hand-engineered pipelines. DNN based watermarking techniques have drastically improved the message capacity, imperceptibility and robustness of the embedded watermarks. However, this improvement comes at the cost of increased computational overhead of the watermark encoder neural network. In this work, we design the first accelerator platform FastStamp to perform DNN based steganography and digital watermarking of images on hardware. We first propose a parameter efficient DNN model for embedding recoverable bit-strings in image pixels. Our proposed model can match the success metrics of prior state-of-the-art DNN based watermarking methods while being significantly faster and lighter in terms of memory footprint. We then design an FPGA based accelerator framework to further improve the model throughput and power consumption by leveraging data parallelism and customized computation paths. FastStamp allows embedding hardware signatures into images to establish media authenticity and ownership of digital media. Our best design achieves 68 times faster inference as compared to GPU implementations of prior DNN based watermark encoder while consuming less power.

</p>
</details>

<details><summary><b>Convergence of score-based generative modeling for general data distributions</b>
<a href="https://arxiv.org/abs/2209.12381">arxiv:2209.12381</a>
&#x1F4C8; 7 <br>
<p>Holden Lee, Jianfeng Lu, Yixin Tan</p></summary>
<p>

**Abstract:** We give polynomial convergence guarantees for denoising diffusion models that do not rely on the data distribution satisfying functional inequalities or strong smoothness assumptions. Assuming a $L^2$-accurate score estimate, we obtain Wasserstein distance guarantees for any distributions of bounded support or sufficiently decaying tails, as well as TV guarantees for distributions with further smoothness assumptions.

</p>
</details>

<details><summary><b>Paraphrasing Is All You Need for Novel Object Captioning</b>
<a href="https://arxiv.org/abs/2209.12343">arxiv:2209.12343</a>
&#x1F4C8; 6 <br>
<p>Cheng-Fu Yang, Yao-Hung Hubert Tsai, Wan-Cyuan Fan, Ruslan Salakhutdinov, Louis-Philippe Morency, Yu-Chiang Frank Wang</p></summary>
<p>

**Abstract:** Novel object captioning (NOC) aims to describe images containing objects without observing their ground truth captions during training. Due to the absence of caption annotation, captioning models cannot be directly optimized via sequence-to-sequence training or CIDEr optimization. As a result, we present Paraphrasing-to-Captioning (P2C), a two-stage learning framework for NOC, which would heuristically optimize the output captions via paraphrasing. With P2C, the captioning model first learns paraphrasing from a language model pre-trained on text-only corpus, allowing expansion of the word bank for improving linguistic fluency. To further enforce the output caption sufficiently describing the visual content of the input image, we perform self-paraphrasing for the captioning model with fidelity and adequacy objectives introduced. Since no ground truth captions are available for novel object images during training, our P2C leverages cross-modality (image-text) association modules to ensure the above caption characteristics can be properly preserved. In the experiments, we not only show that our P2C achieves state-of-the-art performances on nocaps and COCO Caption datasets, we also verify the effectiveness and flexibility of our learning framework by replacing language and cross-modality association models for NOC. Implementation details and code are available in the supplementary materials.

</p>
</details>

<details><summary><b>Application of Deep Learning in Generating Structured Radiology Reports: A Transformer-Based Technique</b>
<a href="https://arxiv.org/abs/2209.12177">arxiv:2209.12177</a>
&#x1F4C8; 6 <br>
<p>Seyed Ali Reza Moezzi, Abdolrahman Ghaedi, Mojdeh Rahmanian, Seyedeh Zahra Mousavi, Ashkan Sami</p></summary>
<p>

**Abstract:** Since radiology reports needed for clinical practice and research are written and stored in free-text narrations, extraction of relative information for further analysis is difficult. In these circumstances, natural language processing (NLP) techniques can facilitate automatic information extraction and transformation of free-text formats to structured data. In recent years, deep learning (DL)-based models have been adapted for NLP experiments with promising results. Despite the significant potential of DL models based on artificial neural networks (ANN) and convolutional neural networks (CNN), the models face some limitations to implement in clinical practice. Transformers, another new DL architecture, have been increasingly applied to improve the process. Therefore, in this study, we propose a transformer-based fine-grained named entity recognition (NER) architecture for clinical information extraction. We collected 88 abdominopelvic sonography reports in free-text formats and annotated them based on our developed information schema. The text-to-text transfer transformer model (T5) and Scifive, a pre-trained domain-specific adaptation of the T5 model, were applied for fine-tuning to extract entities and relations and transform the input into a structured format. Our transformer-based model in this study outperformed previously applied approaches such as ANN and CNN models based on ROUGE-1, ROUGE-2, ROUGE-L, and BLEU scores of 0.816, 0.668, 0.528, and 0.743, respectively, while providing an interpretable structured report.

</p>
</details>

<details><summary><b>Capacity dependent analysis for functional online learning algorithms</b>
<a href="https://arxiv.org/abs/2209.12198">arxiv:2209.12198</a>
&#x1F4C8; 5 <br>
<p>Xin Guo, Zheng-Chu Guo, Lei Shi</p></summary>
<p>

**Abstract:** This article provides convergence analysis of online stochastic gradient descent algorithms for functional linear models. Adopting the characterizations of the slope function regularity, the kernel space capacity, and the capacity of the sampling process covariance operator, significant improvement on the convergence rates is achieved. Both prediction problems and estimation problems are studied, where we show that capacity assumption can alleviate the saturation of the convergence rate as the regularity of the target function increases. We show that with properly selected kernel, capacity assumptions can fully compensate for the regularity assumptions for prediction problems (but not for estimation problems). This demonstrates the significant difference between the prediction problems and the estimation problems in functional data analysis.

</p>
</details>

<details><summary><b>Joint Triplet Loss Learning for Next New POI Recommendation</b>
<a href="https://arxiv.org/abs/2209.12162">arxiv:2209.12162</a>
&#x1F4C8; 5 <br>
<p>Nicholas Lim, Bryan Hooi, See-Kiong Ng, Yong Liang Goh</p></summary>
<p>

**Abstract:** Sparsity of the User-POI matrix is a well established problem for next POI recommendation, which hinders effective learning of user preferences. Focusing on a more granular extension of the problem, we propose a Joint Triplet Loss Learning (JTLL) module for the Next New ($N^2$) POI recommendation task, which is more challenging. Our JTLL module first computes additional training samples from the users' historical POI visit sequence, then, a designed triplet loss function is proposed to decrease and increase distances of POI and user embeddings based on their respective relations. Next, the JTLL module is jointly trained with recent approaches to additionally learn unvisited relations for the recommendation task. Experiments conducted on two known real-world LBSN datasets show that our joint training module was able to improve the performances of recent existing works.

</p>
</details>

<details><summary><b>Deep learning forward and reverse primer design to detect SARS-CoV-2 emerging variants</b>
<a href="https://arxiv.org/abs/2209.13591">arxiv:2209.13591</a>
&#x1F4C8; 4 <br>
<p>Hanyu Wang, Emmanuel K. Tsinda, Anthony J. Dunn, Francis Chikweto, Nusreen Ahmed, Emanuela Pelosi, Alain B. Zemkoho</p></summary>
<p>

**Abstract:** Surges that have been observed at different periods in the number of COVID-19 cases are associated with the emergence of multiple SARS-CoV-2 (Severe Acute Respiratory Virus) variants. The design of methods to support laboratory detection are crucial in the monitoring of these variants. Hence, in this paper, we develop a semi-automated method to design both forward and reverse primer sets to detect SARS-CoV-2 variants. To proceed, we train deep Convolution Neural Networks (CNNs) to classify labelled SARS-CoV-2 variants and identify partial genomic features needed for the forward and reverse Polymerase Chain Reaction (PCR) primer design. Our proposed approach supplements existing ones while promoting the emerging concept of neural network assisted primer design for PCR. Our CNN model was trained using a database of SARS-CoV-2 full-length genomes from GISAID and tested on a separate dataset from NCBI, with 98\% accuracy for the classification of variants. This result is based on the development of three different methods of feature extraction, and the selected primer sequences for each SARS-CoV-2 variant detection (except Omicron) were present in more than 95 \% of sequences in an independent set of 5000 same variant sequences, and below 5 \% in other independent datasets with 5000 sequences of each variant. In total, we obtain 22 forward and reverse primer pairs with flexible length sizes (18-25 base pairs) with an expected amplicon length ranging between 42 and 3322 nucleotides. Besides the feature appearance, in-silico primer checks confirmed that the identified primer pairs are suitable for accurate SARS-CoV-2 variant detection by means of PCR tests.

</p>
</details>

<details><summary><b>Neural State-Space Modeling with Latent Causal-Effect Disentanglement</b>
<a href="https://arxiv.org/abs/2209.12387">arxiv:2209.12387</a>
&#x1F4C8; 4 <br>
<p>Maryam Toloubidokhti, Ryan Missel, Xiajun Jiang, Niels Otani, Linwei Wang</p></summary>
<p>

**Abstract:** Despite substantial progress in deep learning approaches to time-series reconstruction, no existing methods are designed to uncover local activities with minute signal strength due to their negligible contribution to the optimization loss. Such local activities however can signify important abnormal events in physiological systems, such as an extra foci triggering an abnormal propagation of electrical waves in the heart. We discuss a novel technique for reconstructing such local activity that, while small in signal strength, is the cause of subsequent global activities that have larger signal strength. Our central innovation is to approach this by explicitly modeling and disentangling how the latent state of a system is influenced by potential hidden internal interventions. In a novel neural formulation of state-space models (SSMs), we first introduce causal-effect modeling of the latent dynamics via a system of interacting neural ODEs that separately describes 1) the continuous-time dynamics of the internal intervention, and 2) its effect on the trajectory of the system's native state. Because the intervention can not be directly observed but have to be disentangled from the observed subsequent effect, we integrate knowledge of the native intervention-free dynamics of a system, and infer the hidden intervention by assuming it to be responsible for differences observed between the actual and hypothetical intervention-free dynamics. We demonstrated a proof-of-concept of the presented framework on reconstructing ectopic foci disrupting the course of normal cardiac electrical propagation from remote observations.

</p>
</details>

<details><summary><b>Weather2vec: Representation Learning for Causal Inference with Non-Local Confounding in Air Pollution and Climate Studies</b>
<a href="https://arxiv.org/abs/2209.12316">arxiv:2209.12316</a>
&#x1F4C8; 4 <br>
<p>Mauricio Tec, James Scott, Corwin Zigler</p></summary>
<p>

**Abstract:** Estimating the causal effects of a spatially-varying intervention on a spatially-varying outcome may be subject to non-local confounding (NLC), a phenomenon that can bias estimates when the treatments and outcomes of a given unit are dictated in part by the covariates of other nearby units. In particular, NLC is a challenge for evaluating the effects of environmental policies and climate events on health-related outcomes such as air pollution exposure. This paper first formalizes NLC using the potential outcomes framework, providing a comparison with the related phenomenon of causal interference. Then, it proposes a broadly applicable framework, termed "weather2vec", that uses the theory of balancing scores to learn representations of non-local information into a scalar or vector defined for each observational unit, which is subsequently used to adjust for confounding in conjunction with causal inference methods. The framework is evaluated in a simulation study and two case studies on air pollution where the weather is an (inherently regional) known confounder.

</p>
</details>

<details><summary><b>Mental arithmetic task classification with convolutional neural network based on spectral-temporal features from EEG</b>
<a href="https://arxiv.org/abs/2209.11767">arxiv:2209.11767</a>
&#x1F4C8; 4 <br>
<p>Zaineb Ajra, Binbin Xu, G√©rard Dray, Jacky Montmain, Stephane Perrey</p></summary>
<p>

**Abstract:** In recent years, neuroscientists have been interested to the development of brain-computer interface (BCI) devices. Patients with motor disorders may benefit from BCIs as a means of communication and for the restoration of motor functions. Electroencephalography (EEG) is one of most used for evaluating the neuronal activity. In many computer vision applications, deep neural networks (DNN) show significant advantages. Towards to ultimate usage of DNN, we present here a shallow neural network that uses mainly two convolutional neural network (CNN) layers, with relatively few parameters and fast to learn spectral-temporal features from EEG. We compared this models to three other neural network models with different depths applied to a mental arithmetic task using eye-closed state adapted for patients suffering from motor disorders and a decline in visual functions. Experimental results showed that the shallow CNN model outperformed all the other models and achieved the highest classification accuracy of 90.68%. It's also more robust to deal with cross-subject classification issues: only 3% standard deviation of accuracy instead of 15.6% from conventional method.

</p>
</details>

<details><summary><b>Reward Learning using Structural Motifs in Inverse Reinforcement Learning</b>
<a href="https://arxiv.org/abs/2209.13489">arxiv:2209.13489</a>
&#x1F4C8; 3 <br>
<p>Raeid Saqur</p></summary>
<p>

**Abstract:** The Inverse Reinforcement Learning (\textit{IRL}) problem has seen rapid evolution in the past few years, with important applications in domains like robotics, cognition, and health. In this work, we explore the inefficacy of current IRL methods in learning an agent's reward function from expert trajectories depicting long-horizon, complex sequential tasks. We hypothesize that imbuing IRL models with structural motifs capturing underlying tasks can enable and enhance their performance. Subsequently, we propose a novel IRL method, SMIRL, that first learns the (approximate) structure of a task as a finite-state-automaton (FSA), then uses the structural motif to solve the IRL problem. We test our model on both discrete grid world and high-dimensional continuous domain environments. We empirically show that our proposed approach successfully learns all four complex tasks, where two foundational IRL baselines fail. Our model also outperforms the baselines in sample efficiency on a simpler toy task. We further show promising test results in a modified continuous domain on tasks with compositional reward functions.

</p>
</details>

<details><summary><b>DEFT: Diverse Ensembles for Fast Transfer in Reinforcement Learning</b>
<a href="https://arxiv.org/abs/2209.12412">arxiv:2209.12412</a>
&#x1F4C8; 3 <br>
<p>Simeon Adebola, Satvik Sharma, Kaushik Shivakumar</p></summary>
<p>

**Abstract:** Deep ensembles have been shown to extend the positive effect seen in typical ensemble learning to neural networks and to reinforcement learning (RL). However, there is still much to be done to improve the efficiency of such ensemble models. In this work, we present Diverse Ensembles for Fast Transfer in RL (DEFT), a new ensemble-based method for reinforcement learning in highly multimodal environments and improved transfer to unseen environments. The algorithm is broken down into two main phases: training of ensemble members, and synthesis (or fine-tuning) of the ensemble members into a policy that works in a new environment.
  The first phase of the algorithm involves training regular policy gradient or actor-critic agents in parallel but adding a term to the loss that encourages these policies to differ from each other. This causes the individual unimodal agents to explore the space of optimal policies and capture more of the multimodality of the environment than a single actor could. The second phase of DEFT involves synthesizing the component policies into a new policy that works well in a modified environment in one of two ways. To evaluate the performance of DEFT, we start with a base version of the Proximal Policy Optimization (PPO) algorithm and extend it with the modifications for DEFT. Our results show that the pretraining phase is effective in producing diverse policies in multimodal environments. DEFT often converges to a high reward significantly faster than alternatives, such as random initialization without DEFT and fine-tuning of ensemble members.
  While there is certainly more work to be done to analyze DEFT theoretically and extend it to be even more robust, we believe it provides a strong framework for capturing multimodality in environments while still using RL methods with simple policy representations.

</p>
</details>

<details><summary><b>On the Opportunities and Challenges of using Animals Videos in Reinforcement Learning</b>
<a href="https://arxiv.org/abs/2209.12347">arxiv:2209.12347</a>
&#x1F4C8; 3 <br>
<p>Vittorio Giammarino</p></summary>
<p>

**Abstract:** We investigate the use of animals videos to improve efficiency and performance in Reinforcement Learning (RL). Under a theoretical perspective, we motivate the use of weighted policy optimization for off-policy RL, describe the main challenges when learning from videos and propose solutions. We test our ideas in offline and online RL and show encouraging results on a series of 2D navigation tasks.

</p>
</details>

<details><summary><b>Generating Formal Safety Assurances for High-Dimensional Reachability</b>
<a href="https://arxiv.org/abs/2209.12336">arxiv:2209.12336</a>
&#x1F4C8; 3 <br>
<p>Albert Lin, Somil Bansal</p></summary>
<p>

**Abstract:** Providing formal safety and performance guarantees for autonomous systems is becoming increasingly important as they are integrated in our society. Hamilton-Jacobi (HJ) reachability analysis is a popular formal verification tool for providing these guarantees, since it can handle general nonlinear system dynamics, bounded adversarial system disturbances, and state and input constraints. However, it involves solving a PDE, whose computational and memory complexity scales exponentially with respect to the state dimensionality, making its direct use on large-scale systems intractable. A recently proposed method called DeepReach overcomes this challenge by leveraging a sinusoidal neural network PDE solver for high-dimensional reachability problems, whose computational requirements scale with the complexity of the underlying reachable tube rather than the state space dimension. Unfortunately, neural networks can make errors and thus the computed solution may not be safe, which falls short of achieving our overarching goal to provide formal safety assurances. In this work, we propose a method to compute an error bound for the DeepReach solution. This error bound can then be used for reachable tube correction, resulting in a provably safe approximation of the true reachable tube. We also propose a scenario optimization-based approach to compute this error bound for general nonlinear dynamical systems. We demonstrate the efficacy of the proposed approach in obtaining reachable tubes for high-dimensional rocket-landing and multi-vehicle collision-avoidance problems.

</p>
</details>

<details><summary><b>Algorithms that Approximate Data Removal: New Results and Limitations</b>
<a href="https://arxiv.org/abs/2209.12269">arxiv:2209.12269</a>
&#x1F4C8; 3 <br>
<p>Vinith M. Suriyakumar, Ashia C. Wilson</p></summary>
<p>

**Abstract:** We study the problem of deleting user data from machine learning models trained using empirical risk minimization. Our focus is on learning algorithms which return the empirical risk minimizer and approximate unlearning algorithms that comply with deletion requests that come streaming minibatches. Leveraging the infintesimal jacknife, we develop an online unlearning algorithm that is both computationally and memory efficient. Unlike prior memory efficient unlearning algorithms, we target models that minimize objectives with non-smooth regularizers, such as the commonly used $\ell_1$, elastic net, or nuclear norm penalties. We also provide generalization, deletion capacity, and unlearning guarantees that are consistent with state of the art methods. Across a variety of benchmark datasets, our algorithm empirically improves upon the runtime of prior methods while maintaining the same memory requirements and test accuracy. Finally, we open a new direction of inquiry by proving that all approximate unlearning algorithms introduced so far fail to unlearn in problem settings where common hyperparameter tuning methods, such as cross-validation, have been used to select models.

</p>
</details>

<details><summary><b>High-Resolution Satellite Imagery for Modeling the Impact of Aridification on Crop Production</b>
<a href="https://arxiv.org/abs/2209.12238">arxiv:2209.12238</a>
&#x1F4C8; 3 <br>
<p>Depanshu Sani, Sandeep Mahato, Parichya Sirohi, Saket Anand, Gaurav Arora, Charu Chandra Devshali, Thiagarajan Jayaraman, Harsh Kumar Agarwal</p></summary>
<p>

**Abstract:** The availability of well-curated datasets has driven the success of Machine Learning (ML) models. Despite the increased access to earth observation data for agriculture, there is a scarcity of curated, labelled datasets, which limits the potential of its use in training ML models for remote sensing (RS) in agriculture. To this end, we introduce a first-of-its-kind dataset, SICKLE, having time-series images at different spatial resolutions from 3 different satellites, annotated with multiple key cropping parameters for paddy cultivation for the Cauvery Delta region in Tamil Nadu, India. The dataset comprises of 2,398 season-wise samples from 388 unique plots distributed across 4 districts of the Delta. The dataset covers multi-spectral, thermal and microwave data between the time period January 2018-March 2021. The paddy samples are annotated with 4 key cropping parameters, i.e. sowing date, transplanting date, harvesting date and crop yield. This is one of the first studies to consider the growing season (using sowing and harvesting dates) as part of a dataset. We also propose a yield prediction strategy that uses time-series data generated based on the observed growing season and the standard seasonal information obtained from Tamil Nadu Agricultural University for the region. The consequent performance improvement highlights the impact of ML techniques that leverage domain knowledge that are consistent with standard practices followed by farmers in a specific region. We benchmark the dataset on 3 separate tasks, namely crop type, phenology date (sowing, transplanting, harvesting) and yield prediction, and develop an end-to-end framework for predicting key crop parameters in a real-world setting.

</p>
</details>

<details><summary><b>Transfer learning for self-supervised, blind-spot seismic denoising</b>
<a href="https://arxiv.org/abs/2209.12210">arxiv:2209.12210</a>
&#x1F4C8; 3 <br>
<p>Claire Birnie, Tariq Alkhalifah</p></summary>
<p>

**Abstract:** Noise in seismic data arises from numerous sources and is continually evolving. The use of supervised deep learning procedures for denoising of seismic datasets often results in poor performance: this is due to the lack of noise-free field data to act as training targets and the large difference in characteristics between synthetic and field datasets. Self-supervised, blind-spot networks typically overcome these limitation by training directly on the raw, noisy data. However, such networks often rely on a random noise assumption, and their denoising capabilities quickly decrease in the presence of even minimally-correlated noise. Extending from blind-spots to blind-masks can efficiently suppress coherent noise along a specific direction, but it cannot adapt to the ever-changing properties of noise. To preempt the network's ability to predict the signal and reduce its opportunity to learn the noise properties, we propose an initial, supervised training of the network on a frugally-generated synthetic dataset prior to fine-tuning in a self-supervised manner on the field dataset of interest. Considering the change in peak signal-to-noise ratio, as well as the volume of noise reduced and signal leakage observed, we illustrate the clear benefit in initialising the self-supervised network with the weights from a supervised base-training. This is further supported by a test on a field dataset where the fine-tuned network strikes the best balance between signal preservation and noise reduction. Finally, the use of the unrealistic, frugally-generated synthetic dataset for the supervised base-training includes a number of benefits: minimal prior geological knowledge is required, substantially reduced computational cost for the dataset generation, and a reduced requirement of re-training the network should recording conditions change, to name a few.

</p>
</details>

<details><summary><b>All are Worth Words: a ViT Backbone for Score-based Diffusion Models</b>
<a href="https://arxiv.org/abs/2209.12152">arxiv:2209.12152</a>
&#x1F4C8; 3 <br>
<p>Fan Bao, Chongxuan Li, Yue Cao, Jun Zhu</p></summary>
<p>

**Abstract:** Vision transformers (ViT) have shown promise in various vision tasks including low-level ones while the U-Net remains dominant in score-based diffusion models. In this paper, we perform a systematical empirical study on the ViT-based architectures in diffusion models. Our results suggest that adding extra long skip connections (like the U-Net) to ViT is crucial to diffusion models. The new ViT architecture, together with other improvements, is referred to as U-ViT. On several popular visual datasets, U-ViT achieves competitive generation results to SOTA U-Net while requiring comparable amount of parameters and computation if not less.

</p>
</details>

<details><summary><b>Self-Supervised Masked Convolutional Transformer Block for Anomaly Detection</b>
<a href="https://arxiv.org/abs/2209.12148">arxiv:2209.12148</a>
&#x1F4C8; 3 <br>
<p>Neelu Madan, Nicolae-Catalin Ristea, Radu Tudor Ionescu, Kamal Nasrollahi, Fahad Shahbaz Khan, Thomas B. Moeslund, Mubarak Shah</p></summary>
<p>

**Abstract:** Anomaly detection has recently gained increasing attention in the field of computer vision, likely due to its broad set of applications ranging from product fault detection on industrial production lines and impending event detection in video surveillance to finding lesions in medical scans. Regardless of the domain, anomaly detection is typically framed as a one-class classification task, where the learning is conducted on normal examples only. An entire family of successful anomaly detection methods is based on learning to reconstruct masked normal inputs (e.g. patches, future frames, etc.) and exerting the magnitude of the reconstruction error as an indicator for the abnormality level. Unlike other reconstruction-based methods, we present a novel self-supervised masked convolutional transformer block (SSMCTB) that comprises the reconstruction-based functionality at a core architectural level. The proposed self-supervised block is extremely flexible, enabling information masking at any layer of a neural network and being compatible with a wide range of neural architectures. In this work, we extend our previous self-supervised predictive convolutional attentive block (SSPCAB) with a 3D masked convolutional layer, as well as a transformer for channel-wise attention. Furthermore, we show that our block is applicable to a wider variety of tasks, adding anomaly detection in medical images and thermal videos to the previously considered tasks based on RGB images and surveillance videos. We exhibit the generality and flexibility of SSMCTB by integrating it into multiple state-of-the-art neural models for anomaly detection, bringing forth empirical results that confirm considerable performance improvements on five benchmarks: MVTec AD, BRATS, Avenue, ShanghaiTech, and Thermal Rare Event. We release our code and data as open source at https://github.com/ristea/ssmctb.

</p>
</details>

<details><summary><b>Quantum Speedups of Optimizing Approximately Convex Functions with Applications to Logarithmic Regret Stochastic Convex Bandits</b>
<a href="https://arxiv.org/abs/2209.12897">arxiv:2209.12897</a>
&#x1F4C8; 2 <br>
<p>Tongyang Li, Ruizhe Zhang</p></summary>
<p>

**Abstract:** We initiate the study of quantum algorithms for optimizing approximately convex functions. Given a convex set ${\cal K}\subseteq\mathbb{R}^{n}$ and a function $F\colon\mathbb{R}^{n}\to\mathbb{R}$ such that there exists a convex function $f\colon\mathcal{K}\to\mathbb{R}$ satisfying $\sup_{x\in{\cal K}}|F(x)-f(x)|\leq Œµ/n$, our quantum algorithm finds an $x^{*}\in{\cal K}$ such that $F(x^{*})-\min_{x\in{\cal K}} F(x)\leqŒµ$ using $\tilde{O}(n^{3})$ quantum evaluation queries to $F$. This achieves a polynomial quantum speedup compared to the best-known classical algorithms. As an application, we give a quantum algorithm for zeroth-order stochastic convex bandits with $\tilde{O}(n^{5}\log^{2} T)$ regret, an exponential speedup in $T$ compared to the classical $Œ©(\sqrt{T})$ lower bound. Technically, we achieve quantum speedup in $n$ by exploiting a quantum framework of simulated annealing and adopting a quantum version of the hit-and-run walk. Our speedup in $T$ for zeroth-order stochastic convex bandits is due to a quadratic quantum speedup in multiplicative error of mean estimation.

</p>
</details>

<details><summary><b>Learning Cost-maps Made Easy</b>
<a href="https://arxiv.org/abs/2209.12413">arxiv:2209.12413</a>
&#x1F4C8; 2 <br>
<p>Kasi Vishwanath, P. B. Sujit, Srikanth Saripalli</p></summary>
<p>

**Abstract:** Cost-maps are used by robotic vehicles to plan collision-free paths. The cost associated with each cell in the map represents the sensed environment information which is often determined manually after several trial-and-error efforts. In off-road environments, due to the presence of several types of features, it is challenging to handcraft the cost values associated with each feature. Moreover, different handcrafted cost values can lead to different paths for the same environment which is not desirable. In this paper, we address the problem of learning the cost-map values from the sensed environment for robust vehicle path planning. We propose a novel framework called as CAMEL using deep learning approach that learns the parameters through demonstrations yielding an adaptive and robust cost-map for path planning. CAMEL has been trained on multi-modal datasets such as RELLIS-3D. The evaluation of CAMEL is carried out on an off-road scene simulator (MAVS) and on field data from IISER-B campus. We also perform realworld implementation of CAMEL on a ground rover. The results shows flexible and robust motion of the vehicle without collisions in unstructured terrains.

</p>
</details>

<details><summary><b>Deep Reinforcement Learning for Adaptive Mesh Refinement</b>
<a href="https://arxiv.org/abs/2209.12351">arxiv:2209.12351</a>
&#x1F4C8; 2 <br>
<p>Corbin Foucart, Aaron Charous, Pierre F. J. Lermusiaux</p></summary>
<p>

**Abstract:** Finite element discretizations of problems in computational physics often rely on adaptive mesh refinement (AMR) to preferentially resolve regions containing important features during simulation. However, these spatial refinement strategies are often heuristic and rely on domain-specific knowledge or trial-and-error. We treat the process of adaptive mesh refinement as a local, sequential decision-making problem under incomplete information, formulating AMR as a partially observable Markov decision process. Using a deep reinforcement learning approach, we train policy networks for AMR strategy directly from numerical simulation. The training process does not require an exact solution or a high-fidelity ground truth to the partial differential equation at hand, nor does it require a pre-computed training dataset. The local nature of our reinforcement learning formulation allows the policy network to be trained inexpensively on much smaller problems than those on which they are deployed. The methodology is not specific to any particular partial differential equation, problem dimension, or numerical discretization, and can flexibly incorporate diverse problem physics. To that end, we apply the approach to a diverse set of partial differential equations, using a variety of high-order discontinuous Galerkin and hybridizable discontinuous Galerkin finite element discretizations. We show that the resultant deep reinforcement learning policies are competitive with common AMR heuristics, generalize well across problem classes, and strike a favorable balance between accuracy and cost such that they often lead to a higher accuracy per problem degree of freedom.

</p>
</details>

<details><summary><b>Unsupervised Reward Shaping for a Robotic Sequential Picking Task from Visual Observations in a Logistics Scenario</b>
<a href="https://arxiv.org/abs/2209.12350">arxiv:2209.12350</a>
&#x1F4C8; 2 <br>
<p>Vittorio Giammarino</p></summary>
<p>

**Abstract:** We focus on an unloading problem, typical of the logistics sector, modeled as a sequential pick-and-place task. In this type of task, modern machine learning techniques have shown to work better than classic systems since they are more adaptable to stochasticity and better able to cope with large uncertainties. More specifically, supervised and imitation learning have achieved outstanding results in this regard, with the shortcoming of requiring some form of supervision which is not always obtainable for all settings. On the other hand, reinforcement learning (RL) requires much milder form of supervision but still remains impracticable due to its inefficiency. In this paper, we propose and theoretically motivate a novel Unsupervised Reward Shaping algorithm from expert's observations which relaxes the level of supervision required by the agent and works on improving RL performance in our task.

</p>
</details>

<details><summary><b>Political economy of superhuman AI</b>
<a href="https://arxiv.org/abs/2209.12346">arxiv:2209.12346</a>
&#x1F4C8; 2 <br>
<p>Mehmet S. Ismail</p></summary>
<p>

**Abstract:** In this note, I study the institutions and game theoretic assumptions that would prevent the emergence of "superhuman-level" arfiticial general intelligence, denoted by AI*. These assumptions are (i) the "Freedom of the Mind," (ii) open source "access" to AI*, and (iii) rationality of the representative human agent, who competes against AI*. I prove that under these three assumptions it is impossible that an AI* exists. This result gives rise to two immediate recommendations for public policy. First, "cloning" digitally the human brain should be strictly regulated, and hypothetical AI*'s access to brain should be prohibited. Second, AI* research should be made widely, if not publicly, accessible.

</p>
</details>

<details><summary><b>Stochastic Gradient Descent Captures How Children Learn About Physics</b>
<a href="https://arxiv.org/abs/2209.12344">arxiv:2209.12344</a>
&#x1F4C8; 2 <br>
<p>Luca M. Schulze Buschoff, Eric Schulz, Marcel Binz</p></summary>
<p>

**Abstract:** As children grow older, they develop an intuitive understanding of the physical processes around them. They move along developmental trajectories, which have been mapped out extensively in previous empirical research. We investigate how children's developmental trajectories compare to the learning trajectories of artificial systems. Specifically, we examine the idea that cognitive development results from some form of stochastic optimization procedure. For this purpose, we train a modern generative neural network model using stochastic gradient descent. We then use methods from the developmental psychology literature to probe the physical understanding of this model at different degrees of optimization. We find that the model's learning trajectory captures the developmental trajectories of children, thereby providing support to the idea of development as stochastic optimization.

</p>
</details>

<details><summary><b>Temporally Extended Successor Representations</b>
<a href="https://arxiv.org/abs/2209.12331">arxiv:2209.12331</a>
&#x1F4C8; 2 <br>
<p>Matthew J. Sargent, Peter J. Bentley, Caswell Barry, William de Cothi</p></summary>
<p>

**Abstract:** We present a temporally extended variation of the successor representation, which we term t-SR. t-SR captures the expected state transition dynamics of temporally extended actions by constructing successor representations over primitive action repeats. This form of temporal abstraction does not learn a top-down hierarchy of pertinent task structures, but rather a bottom-up composition of coupled actions and action repetitions. This lessens the amount of decisions required in control without learning a hierarchical policy. As such, t-SR directly considers the time horizon of temporally extended action sequences without the need for predefined or domain-specific options. We show that in environments with dynamic reward structure, t-SR is able to leverage both the flexibility of the successor representation and the abstraction afforded by temporally extended actions. Thus, in a series of sparsely rewarded gridworld environments, t-SR optimally adapts learnt policies far faster than comparable value-based, model-free reinforcement learning methods. We also show that the manner in which t-SR learns to solve these tasks requires the learnt policy to be sampled consistently less often than non-temporally extended policies.

</p>
</details>

<details><summary><b>Personalizing Text-to-Image Generation via Aesthetic Gradients</b>
<a href="https://arxiv.org/abs/2209.12330">arxiv:2209.12330</a>
&#x1F4C8; 2 <br>
<p>Victor Gallego</p></summary>
<p>

**Abstract:** This work proposes aesthetic gradients, a method to personalize a CLIP-conditioned diffusion model by guiding the generative process towards custom aesthetics defined by the user from a set of images. The approach is validated with qualitative and quantitative experiments, using the recent stable diffusion model and several aesthetically-filtered datasets. Code is released at https://github.com/vicgalle/stable-diffusion-aesthetic-gradients

</p>
</details>

<details><summary><b>Random graph matching at Otter's threshold via counting chandeliers</b>
<a href="https://arxiv.org/abs/2209.12313">arxiv:2209.12313</a>
&#x1F4C8; 2 <br>
<p>Cheng Mao, Yihong Wu, Jiaming Xu, Sophie H. Yu</p></summary>
<p>

**Abstract:** We propose an efficient algorithm for graph matching based on similarity scores constructed from counting a certain family of weighted trees rooted at each vertex. For two Erd≈ës-R√©nyi graphs $\mathcal{G}(n,q)$ whose edges are correlated through a latent vertex correspondence, we show that this algorithm correctly matches all but a vanishing fraction of the vertices with high probability, provided that $nq\to\infty$ and the edge correlation coefficient $œÅ$ satisfies $œÅ^2>Œ±\approx 0.338$, where $Œ±$ is Otter's tree-counting constant. Moreover, this almost exact matching can be made exact under an extra condition that is information-theoretically necessary. This is the first polynomial-time graph matching algorithm that succeeds at an explicit constant correlation and applies to both sparse and dense graphs. In comparison, previous methods either require $œÅ=1-o(1)$ or are restricted to sparse graphs.
  The crux of the algorithm is a carefully curated family of rooted trees called chandeliers, which allows effective extraction of the graph correlation from the counts of the same tree while suppressing the undesirable correlation between those of different trees.

</p>
</details>

<details><summary><b>Adnexal Mass Segmentation with Ultrasound Data Synthesis</b>
<a href="https://arxiv.org/abs/2209.12305">arxiv:2209.12305</a>
&#x1F4C8; 2 <br>
<p>Clara Lebbos, Jen Barcroft, Jeremy Tan, Johanna P. Muller, Matthew Baugh, Athanasios Vlontzos, Srdjan Saso, Bernhard Kainz</p></summary>
<p>

**Abstract:** Ovarian cancer is the most lethal gynaecological malignancy. The disease is most commonly asymptomatic at its early stages and its diagnosis relies on expert evaluation of transvaginal ultrasound images. Ultrasound is the first-line imaging modality for characterising adnexal masses, it requires significant expertise and its analysis is subjective and labour-intensive, therefore open to error. Hence, automating processes to facilitate and standardise the evaluation of scans is desired in clinical practice. Using supervised learning, we have demonstrated that segmentation of adnexal masses is possible, however, prevalence and label imbalance restricts the performance on under-represented classes. To mitigate this we apply a novel pathology-specific data synthesiser. We create synthetic medical images with their corresponding ground truth segmentations by using Poisson image editing to integrate less common masses into other samples. Our approach achieves the best performance across all classes, including an improvement of up to 8% when compared with nnU-Net baseline approaches.

</p>
</details>

<details><summary><b>Social Assistive Robotics for Autistic Children</b>
<a href="https://arxiv.org/abs/2209.12289">arxiv:2209.12289</a>
&#x1F4C8; 2 <br>
<p>Stefania Brighenti, Federico Buratto, Fernando Vito Falcone, Cristina Gena, Claudio Mattutino, Matteo Nazzario</p></summary>
<p>

**Abstract:** This paper introduces the project Social Assistive Robotics for Autistic Children aimed at using robotic therapy for autism. The goal of the project is testing autistic children's interactions with the social robot NAO. In particular the robot will support the operators (psychologists, educators, speech therapists etc.) in their work. The innovative aspect of the project is that the children robot interaction will consider the children's emotions and specific features and the robot will adapt its behavior accordingly.

</p>
</details>

<details><summary><b>VAESim: A probabilistic approach for self-supervised prototype discovery</b>
<a href="https://arxiv.org/abs/2209.12279">arxiv:2209.12279</a>
&#x1F4C8; 2 <br>
<p>Matteo Ferrante, Tommaso Boccato, Simeon Spasov, Andrea Duggento, Nicola Toschi</p></summary>
<p>

**Abstract:** In medicine, curated image datasets often employ discrete labels to describe what is known to be a continuous spectrum of healthy to pathological conditions, such as e.g. the Alzheimer's Disease Continuum or other areas where the image plays a pivotal point in diagnosis. We propose an architecture for image stratification based on a conditional variational autoencoder. Our framework, VAESim, leverages a continuous latent space to represent the continuum of disorders and finds clusters during training, which can then be used for image/patient stratification. The core of the method learns a set of prototypical vectors, each associated with a cluster. First, we perform a soft assignment of each data sample to the clusters. Then, we reconstruct the sample based on a similarity measure between the sample embedding and the prototypical vectors of the clusters. To update the prototypical embeddings, we use an exponential moving average of the most similar representations between actual prototypes and samples in the batch size. We test our approach on the MNIST-handwritten digit dataset and on a medical benchmark dataset called PneumoniaMNIST. We demonstrate that our method outperforms baselines in terms of kNN accuracy measured on a classification task against a standard VAE (up to 15% improvement in performance) in both datasets, and also performs at par with classification models trained in a fully supervised way. We also demonstrate how our model outperforms current, end-to-end models for unsupervised stratification.

</p>
</details>

<details><summary><b>Probabilistic Planning with Partially Ordered Preferences over Temporal Goals</b>
<a href="https://arxiv.org/abs/2209.12267">arxiv:2209.12267</a>
&#x1F4C8; 2 <br>
<p>Hazhar Rahmani, Abhishek N. Kulkarni, Jie Fu</p></summary>
<p>

**Abstract:** In this paper, we study planning in stochastic systems, modeled as Markov decision processes (MDPs), with preferences over temporally extended goals. Prior work on temporal planning with preferences assumes that the user preferences form a total order, meaning that every pair of outcomes are comparable with each other. In this work, we consider the case where the preferences over possible outcomes are a partial order rather than a total order. We first introduce a variant of deterministic finite automaton, referred to as a preference DFA, for specifying the user's preferences over temporally extended goals. Based on the order theory, we translate the preference DFA to a preference relation over policies for probabilistic planning in a labeled MDP. In this treatment, a most preferred policy induces a weak-stochastic nondominated probability distribution over the finite paths in the MDP. The proposed planning algorithm hinges on the construction of a multi-objective MDP. We prove that a weak-stochastic nondominated policy given the preference specification is Pareto-optimal in the constructed multi-objective MDP, and vice versa. Throughout the paper, we employ a running example to demonstrate the proposed preference specification and solution approaches. We show the efficacy of our algorithm using the example with detailed analysis, and then discuss possible future directions.

</p>
</details>

<details><summary><b>A Tightly Coupled LiDAR-IMU Odometry through Iterated Point-Level Undistortion</b>
<a href="https://arxiv.org/abs/2209.12249">arxiv:2209.12249</a>
&#x1F4C8; 2 <br>
<p>Keke Liu, Hao Ma, Zemin Wang</p></summary>
<p>

**Abstract:** Scan undistortion is a key module for LiDAR odometry in high dynamic environment with high rotation and translation speed. The existing line of studies mostly focuses on one pass undistortion, which means undistortion for each point is conducted only once in the whole LiDAR-IMU odometry pipeline. In this paper, we propose an optimization based tightly coupled LiDAR-IMU odometry addressing iterated point-level undistortion. By jointly minimizing the cost derived from LiDAR and IMU measurements, our LiDAR-IMU odometry method performs more accurate and robust in high dynamic environment. Besides, the method characters good computation efficiency by limiting the quantity of parameters.

</p>
</details>

<details><summary><b>Partial annotations for the segmentation of large structures with low annotation cost</b>
<a href="https://arxiv.org/abs/2209.12216">arxiv:2209.12216</a>
&#x1F4C8; 2 <br>
<p>Bella Specktor Fadida, Daphna Link Sourani, Liat Ben Sira Elka Miller, Dafna Ben Bashat, Leo Joskowicz</p></summary>
<p>

**Abstract:** Deep learning methods have been shown to be effective for the automatic segmentation of structures and pathologies in medical imaging. However, they require large annotated datasets, whose manual segmentation is a tedious and time-consuming task, especially for large structures. We present a new method of partial annotations that uses a small set of consecutive annotated slices from each scan with an annotation effort that is equal to that of only few annotated cases. The training with partial annotations is performed by using only annotated blocks, incorporating information about slices outside the structure of interest and modifying a batch loss function to consider only the annotated slices. To facilitate training in a low data regime, we use a two-step optimization process. We tested the method with the popular soft Dice loss for the fetal body segmentation task in two MRI sequences, TRUFI and FIESTA, and compared full annotation regime to partial annotations with a similar annotation effort. For TRUFI data, the use of partial annotations yielded slightly better performance on average compared to full annotations with an increase in Dice score from 0.936 to 0.942, and a substantial decrease in Standard Deviations (STD) of Dice score by 22% and Average Symmetric Surface Distance (ASSD) by 15%. For the FIESTA sequence, partial annotations also yielded a decrease in STD of the Dice score and ASSD metrics by 27.5% and 33% respectively for in-distribution data, and a substantial improvement also in average performance on out-of-distribution data, increasing Dice score from 0.84 to 0.9 and decreasing ASSD from 7.46 to 4.01 mm. The two-step optimization process was helpful for partial annotations for both in-distribution and out-of-distribution data. The partial annotations method with the two-step optimizer is therefore recommended to improve segmentation performance under low data regime.

</p>
</details>

<details><summary><b>GPatch: Patching Graph Neural Networks for Cold-Start Recommendations</b>
<a href="https://arxiv.org/abs/2209.12215">arxiv:2209.12215</a>
&#x1F4C8; 2 <br>
<p>Hao Chen, Zefan Wang, Yue Xu, Xiao Huang, Feiran Huang</p></summary>
<p>

**Abstract:** Cold start is an essential and persistent problem in recommender systems. State-of-the-art solutions rely on training hybrid models for both cold-start and existing users/items, based on the auxiliary information. Such a hybrid model would compromise the performance of existing users/items, which might make these solutions not applicable in real-worlds recommender systems where the experience of existing users/items must be guaranteed. Meanwhile, graph neural networks (GNNs) have been demonstrated to perform effectively warm (non-cold-start) recommendations. However, they have never been applied to handle the cold-start problem in a user-item bipartite graph. This is a challenging but rewarding task since cold-start users/items do not have links. Besides, it is nontrivial to design an appropriate GNN to conduct cold-start recommendations while maintaining the performance for existing users/items. To bridge the gap, we propose a tailored GNN-based framework (GPatch) that contains two separate but correlated components. First, an efficient GNN architecture -- GWarmer, is designed to model the warm users/items. Second, we construct correlated Patching Networks to simulate and patch GWarmer by conducting cold-start recommendations. Experiments on benchmark and large-scale commercial datasets demonstrate that GPatch is significantly superior in providing recommendations for both existing and cold-start users/items.

</p>
</details>

<details><summary><b>Efficient Long Sequential User Data Modeling for Click-Through Rate Prediction</b>
<a href="https://arxiv.org/abs/2209.12212">arxiv:2209.12212</a>
&#x1F4C8; 2 <br>
<p>Qiwei Chen, Yue Xu, Changhua Pei, Shanshan Lv, Tao Zhuang, Junfeng Ge</p></summary>
<p>

**Abstract:** Recent studies on Click-Through Rate (CTR) prediction has reached new levels by modeling longer user behavior sequences. Among others, the two-stage methods stand out as the state-of-the-art (SOTA) solution for industrial applications. The two-stage methods first train a retrieval model to truncate the long behavior sequence beforehand and then use the truncated sequences to train a CTR model. However, the retrieval model and the CTR model are trained separately. So the retrieved subsequences in the CTR model is inaccurate, which degrades the final performance. In this paper, we propose an end-to-end paradigm to model long behavior sequences, which is able to achieve superior performance along with remarkable cost-efficiency compared to existing models. Our contribution is three-fold: First, we propose a hashing-based efficient target attention (TA) network named ETA-Net to enable end-to-end user behavior retrieval based on low-cost bit-wise operations. The proposed ETA-Net can reduce the complexity of standard TA by orders of magnitude for sequential data modeling. Second, we propose a general system architecture as one viable solution to deploy ETA-Net on industrial systems. Particularly, ETA-Net has been deployed on the recommender system of Taobao, and brought 1.8% lift on CTR and 3.1% lift on Gross Merchandise Value (GMV) compared to the SOTA two-stage methods. Third, we conduct extensive experiments on both offline datasets and online A/B test. The results verify that the proposed model outperforms existing CTR models considerably, in terms of both CTR prediction performance and online cost-efficiency. ETA-Net now serves the main traffic of Taobao, delivering services to hundreds of millions of users towards billions of items every day.

</p>
</details>

<details><summary><b>Multimodal Exponentially Modified Gaussian Oscillators</b>
<a href="https://arxiv.org/abs/2209.12202">arxiv:2209.12202</a>
&#x1F4C8; 2 <br>
<p>Christopher Hahne</p></summary>
<p>

**Abstract:** Acoustic modeling serves de-noising, data reconstruction, model-based testing and classification in audio processing tasks. Previous work dealt with signal parameterization of wave envelopes either by multiple Gaussian distributions or a single asymmetric Gaussian curve, which both fall short in representing super-imposed echoes sufficiently well. This study presents a three-stage Multimodal Exponentially Modified Gaussian (MEMG) model with an optional oscillating term that regards captured echoes as a superposition of univariate probability distributions in the temporal domain. With this, synthetic ultrasound signals suffering from artifacts can be fully recovered, which is backed by quantitative assessment. Real data experimentation is carried out to demonstrate the classification capability of the acquired features with object reflections being detected at different points in time. The code is available at https://github.com/hahnec/multimodal_emg.

</p>
</details>

<details><summary><b>SPRITZ-1.5C: Employing Deep Ensemble Learning for Improving the Security of Computer Networks against Adversarial Attacks</b>
<a href="https://arxiv.org/abs/2209.12195">arxiv:2209.12195</a>
&#x1F4C8; 2 <br>
<p>Ehsan Nowroozi, Mohammadreza Mohammadi, Erkay Savas, Mauro Conti, Yassine Mekdad</p></summary>
<p>

**Abstract:** In the past few years, Convolutional Neural Networks (CNN) have demonstrated promising performance in various real-world cybersecurity applications, such as network and multimedia security. However, the underlying fragility of CNN structures poses major security problems, making them inappropriate for use in security-oriented applications including such computer networks. Protecting these architectures from adversarial attacks necessitates using security-wise architectures that are challenging to attack.
  In this study, we present a novel architecture based on an ensemble classifier that combines the enhanced security of 1-Class classification (known as 1C) with the high performance of conventional 2-Class classification (known as 2C) in the absence of attacks.Our architecture is referred to as the 1.5-Class (SPRITZ-1.5C) classifier and constructed using a final dense classifier, one 2C classifier (i.e., CNNs), and two parallel 1C classifiers (i.e., auto-encoders). In our experiments, we evaluated the robustness of our proposed architecture by considering eight possible adversarial attacks in various scenarios. We performed these attacks on the 2C and SPRITZ-1.5C architectures separately. The experimental results of our study showed that the Attack Success Rate (ASR) of the I-FGSM attack against a 2C classifier trained with the N-BaIoT dataset is 0.9900. In contrast, the ASR is 0.0000 for the SPRITZ-1.5C classifier.

</p>
</details>

<details><summary><b>Multi-modal Segment Assemblage Network for Ad Video Editing with Importance-Coherence Reward</b>
<a href="https://arxiv.org/abs/2209.12164">arxiv:2209.12164</a>
&#x1F4C8; 2 <br>
<p>Yunlong Tang, Siting Xu, Teng Wang, Qin Lin, Qinglin Lu, Feng Zheng</p></summary>
<p>

**Abstract:** Advertisement video editing aims to automatically edit advertising videos into shorter videos while retaining coherent content and crucial information conveyed by advertisers. It mainly contains two stages: video segmentation and segment assemblage. The existing method performs well at video segmentation stages but suffers from the problems of dependencies on extra cumbersome models and poor performance at the segment assemblage stage. To address these problems, we propose M-SAN (Multi-modal Segment Assemblage Network) which can perform efficient and coherent segment assemblage task end-to-end. It utilizes multi-modal representation extracted from the segments and follows the Encoder-Decoder Ptr-Net framework with the Attention mechanism. Importance-coherence reward is designed for training M-SAN. We experiment on the Ads-1k dataset with 1000+ videos under rich ad scenarios collected from advertisers. To evaluate the methods, we propose a unified metric, Imp-Coh@Time, which comprehensively assesses the importance, coherence, and duration of the outputs at the same time. Experimental results show that our method achieves better performance than random selection and the previous method on the metric. Ablation experiments further verify that multi-modal representation and importance-coherence reward significantly improve the performance. Ads-1k dataset is available at: https://github.com/yunlong10/Ads-1k

</p>
</details>

<details><summary><b>A heterogeneous group CNN for image super-resolution</b>
<a href="https://arxiv.org/abs/2209.12406">arxiv:2209.12406</a>
&#x1F4C8; 1 <br>
<p>Chunwei Tian, Yanning Zhang, Wangmeng Zuo, Chia-Wen Lin, David Zhang, Yixuan Yuan</p></summary>
<p>

**Abstract:** Convolutional neural networks (CNNs) have obtained remarkable performance via deep architectures. However, these CNNs often achieve poor robustness for image super-resolution (SR) under complex scenes. In this paper, we present a heterogeneous group SR CNN (HGSRCNN) via leveraging structure information of different types to obtain a high-quality image. Specifically, each heterogeneous group block (HGB) of HGSRCNN uses a heterogeneous architecture containing a symmetric group convolutional block and a complementary convolutional block in a parallel way to enhance internal and external relations of different channels for facilitating richer low-frequency structure information of different types. To prevent appearance of obtained redundant features, a refinement block with signal enhancements in a serial way is designed to filter useless information. To prevent loss of original information, a multi-level enhancement mechanism guides a CNN to achieve a symmetric architecture for promoting expressive ability of HGSRCNN. Besides, a parallel up-sampling mechanism is developed to train a blind SR model. Extensive experiments illustrate that the proposed HGSRCNN has obtained excellent SR performance in terms of both quantitative and qualitative analysis. Codes can be accessed at https://github.com/hellloxiaotian/HGSRCNN.

</p>
</details>

<details><summary><b>Multi-stage image denoising with the wavelet transform</b>
<a href="https://arxiv.org/abs/2209.12394">arxiv:2209.12394</a>
&#x1F4C8; 1 <br>
<p>Chunwei Tian, Menghua Zheng, Wangmeng Zuo, Bob Zhang, Yanning Zhang, David Zhang</p></summary>
<p>

**Abstract:** Deep convolutional neural networks (CNNs) are used for image denoising via automatically mining accurate structure information. However, most of existing CNNs depend on enlarging depth of designed networks to obtain better denoising performance, which may cause training difficulty. In this paper, we propose a multi-stage image denoising CNN with the wavelet transform (MWDCNN) via three stages, i.e., a dynamic convolutional block (DCB), two cascaded wavelet transform and enhancement blocks (WEBs) and residual block (RB). DCB uses a dynamic convolution to dynamically adjust parameters of several convolutions for making a tradeoff between denoising performance and computational costs. WEB uses a combination of signal processing technique (i.e., wavelet transformation) and discriminative learning to suppress noise for recovering more detailed information in image denoising. To further remove redundant features, RB is used to refine obtained features for improving denoising effects and reconstruct clean images via improved residual dense architectures. Experimental results show that the proposed MWDCNN outperforms some popular denoising methods in terms of quantitative and qualitative analysis. Codes are available at https://github.com/hellloxiaotian/MWDCNN.

</p>
</details>

<details><summary><b>Scalable Quantum Convolutional Neural Networks</b>
<a href="https://arxiv.org/abs/2209.12372">arxiv:2209.12372</a>
&#x1F4C8; 1 <br>
<p>Hankyul Baek, Won Joon Yun, Joongheon Kim</p></summary>
<p>

**Abstract:** With the beginning of the noisy intermediate-scale quantum (NISQ) era, quantum neural network (QNN) has recently emerged as a solution for the problems that classical neural networks cannot solve. Moreover, QCNN is attracting attention as the next generation of QNN because it can process high-dimensional vector input. However, due to the nature of quantum computing, it is difficult for the classical QCNN to extract a sufficient number of features. Motivated by this, we propose a new version of QCNN, named scalable quantum convolutional neural network (sQCNN). In addition, using the fidelity of QC, we propose an sQCNN training algorithm named reverse fidelity training (RF-Train) that maximizes the performance of sQCNN.

</p>
</details>

<details><summary><b>Contour Dice loss for structures with Fuzzy and Complex Boundaries in Fetal MRI</b>
<a href="https://arxiv.org/abs/2209.12232">arxiv:2209.12232</a>
&#x1F4C8; 1 <br>
<p>Bella Specktor Fadida, Bossmat Yehuda, Daphna Link Sourani, Liat Ben Sira, Dafna Ben Bashat, Leo Joskowicz</p></summary>
<p>

**Abstract:** Volumetric measurements of fetal structures in MRI are time consuming and error prone and therefore require automatic segmentation. Placenta segmentation and accurate fetal brain segmentation for gyrification assessment are particularly challenging because of the placenta fuzzy boundaries and the fetal brain cortex complex foldings. In this paper, we study the use of the Contour Dice loss for both problems and compare it to other boundary losses and to the combined Dice and Cross-Entropy loss. The loss is computed efficiently for each slice via erosion, dilation and XOR operators. We describe a new formulation of the loss akin to the Contour Dice metric. The combination of the Dice loss and the Contour Dice yielded the best performance for placenta segmentation. For fetal brain segmentation, the best performing loss was the combined Dice with Cross-Entropy loss followed by the Dice with Contour Dice loss, which performed better than other boundary losses.

</p>
</details>


{% endraw %}
Prev: [2022.09.24]({{ '/2022/09/24/2022.09.24.html' | relative_url }})  Next: [2022.09.26]({{ '/2022/09/26/2022.09.26.html' | relative_url }})