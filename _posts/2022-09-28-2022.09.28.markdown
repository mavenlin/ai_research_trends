Prev: [2022.09.27]({{ '/2022/09/27/2022.09.27.html' | relative_url }})  Next: [2022.09.29]({{ '/2022/09/29/2022.09.29.html' | relative_url }})
{% raw %}
## Summary for 2022-09-28, created on 2022-10-08


<details><summary><b>Biological connectomes as a representation for the architecture of artificial neural networks</b>
<a href="https://arxiv.org/abs/2209.14406">arxiv:2209.14406</a>
&#x1F4C8; 1010 <br>
<p>Samuel Schmidgall, Catherine Schuman, Maryam Parsa</p></summary>
<p>

**Abstract:** Grand efforts in neuroscience are working toward mapping the connectomes of many new species, including the near completion of the Drosophila melanogaster. It is important to ask whether these models could benefit artificial intelligence. In this work we ask two fundamental questions: (1) where and when biological connectomes can provide use in machine learning, (2) which design principles are necessary for extracting a good representation of the connectome. Toward this end, we translate the motor circuit of the C. Elegans nematode into artificial neural networks at varying levels of biophysical realism and evaluate the outcome of training these networks on motor and non-motor behavioral tasks. We demonstrate that biophysical realism need not be upheld to attain the advantages of using biological circuits. We also establish that, even if the exact wiring diagram is not retained, the architectural statistics provide a valuable prior. Finally, we show that while the C. Elegans locomotion circuit provides a powerful inductive bias on locomotion problems, its structure may hinder performance on tasks unrelated to locomotion such as visual classification problems.

</p>
</details>

<details><summary><b>On the Generalization of Deep Reinforcement Learning Methods in the Problem of Local Navigation</b>
<a href="https://arxiv.org/abs/2209.14271">arxiv:2209.14271</a>
&#x1F4C8; 336 <br>
<p>Victor R. F. Miranda, Armando A. Neto, Gustavo M. Freitas, Leonardo A. Mozelli</p></summary>
<p>

**Abstract:** In this paper, we study the application of DRL algorithms in the context of local navigation problems, in which a robot moves towards a goal location in unknown and cluttered workspaces equipped only with limited-range exteroceptive sensors, such as LiDAR. Collision avoidance policies based on DRL present some advantages, but they are quite susceptible to local minima, once their capacity to learn suitable actions is limited to the sensor range. Since most robots perform tasks in unstructured environments, it is of great interest to seek generalized local navigation policies capable of avoiding local minima, especially in untrained scenarios. To do so, we propose a novel reward function that incorporates map information gained in the training stage, increasing the agent's capacity to deliberate about the best course of action. Also, we use the SAC algorithm for training our ANN, which shows to be more effective than others in the state-of-the-art literature. A set of sim-to-sim and sim-to-real experiments illustrate that our proposed reward combined with the SAC outperforms the compared methods in terms of local minima and collision avoidance.

</p>
</details>

<details><summary><b>Re-Imagen: Retrieval-Augmented Text-to-Image Generator</b>
<a href="https://arxiv.org/abs/2209.14491">arxiv:2209.14491</a>
&#x1F4C8; 209 <br>
<p>Wenhu Chen, Hexiang Hu, Chitwan Saharia, William W. Cohen</p></summary>
<p>

**Abstract:** Research on text-to-image generation has witnessed significant progress in generating diverse and photo-realistic images, driven by diffusion and auto-regressive models trained on large-scale image-text data. Though state-of-the-art models can generate high-quality images of common entities, they often have difficulty generating images of uncommon entities, such as `Chortai (dog)' or `Picarones (food)'. To tackle this issue, we present the Retrieval-Augmented Text-to-Image Generator (Re-Imagen), a generative model that uses retrieved information to produce high-fidelity and faithful images, even for rare or unseen entities. Given a text prompt, Re-Imagen accesses an external multi-modal knowledge base to retrieve relevant (image, text) pairs, and uses them as references to generate the image. With this retrieval step, Re-Imagen is augmented with the knowledge of high-level semantics and low-level visual details of the mentioned entities, and thus improves its accuracy in generating the entities' visual appearances. We train Re-Imagen on a constructed dataset containing (image, text, retrieval) triples to teach the model to ground on both text prompt and retrieval. Furthermore, we develop a new sampling strategy to interleave the classifier-free guidance for text and retrieval condition to balance the text and retrieval alignment. Re-Imagen achieves new SoTA FID results on two image generation benchmarks, such as COCO (ie, FID = 5.25) and WikiImage (ie, FID = 5.82) without fine-tuning. To further evaluate the capabilities of the model, we introduce EntityDrawBench, a new benchmark that evaluates image generation for diverse entities, from frequent to rare, across multiple visual domains. Human evaluation on EntityDrawBench shows that Re-Imagen performs on par with the best prior models in photo-realism, but with significantly better faithfulness, especially on less frequent entities.

</p>
</details>

<details><summary><b>Debiasing Graph Neural Networks via Learning Disentangled Causal Substructure</b>
<a href="https://arxiv.org/abs/2209.14107">arxiv:2209.14107</a>
&#x1F4C8; 120 <br>
<p>Shaohua Fan, Xiao Wang, Yanhu Mo, Chuan Shi, Jian Tang</p></summary>
<p>

**Abstract:** Most Graph Neural Networks (GNNs) predict the labels of unseen graphs by learning the correlation between the input graphs and labels. However, by presenting a graph classification investigation on the training graphs with severe bias, surprisingly, we discover that GNNs always tend to explore the spurious correlations to make decision, even if the causal correlation always exists. This implies that existing GNNs trained on such biased datasets will suffer from poor generalization capability. By analyzing this problem in a causal view, we find that disentangling and decorrelating the causal and bias latent variables from the biased graphs are both crucial for debiasing. Inspiring by this, we propose a general disentangled GNN framework to learn the causal substructure and bias substructure, respectively. Particularly, we design a parameterized edge mask generator to explicitly split the input graph into causal and bias subgraphs. Then two GNN modules supervised by causal/bias-aware loss functions respectively are trained to encode causal and bias subgraphs into their corresponding representations. With the disentangled representations, we synthesize the counterfactual unbiased training samples to further decorrelate causal and bias variables. Moreover, to better benchmark the severe bias problem, we construct three new graph datasets, which have controllable bias degrees and are easier to visualize and explain. Experimental results well demonstrate that our approach achieves superior generalization performance over existing baselines. Furthermore, owing to the learned edge mask, the proposed model has appealing interpretability and transferability. Code and data are available at: https://github.com/googlebaba/DisC.

</p>
</details>

<details><summary><b>DMAP: a Distributed Morphological Attention Policy for Learning to Locomote with a Changing Body</b>
<a href="https://arxiv.org/abs/2209.14218">arxiv:2209.14218</a>
&#x1F4C8; 100 <br>
<p>Alberto Silvio Chiappa, Alessandro Marin Vargas, Alexander Mathis</p></summary>
<p>

**Abstract:** Biological and artificial agents need to deal with constant changes in the real world. We study this problem in four classical continuous control environments, augmented with morphological perturbations. Learning to locomote when the length and the thickness of different body parts vary is challenging, as the control policy is required to adapt to the morphology to successfully balance and advance the agent. We show that a control policy based on the proprioceptive state performs poorly with highly variable body configurations, while an (oracle) agent with access to a learned encoding of the perturbation performs significantly better. We introduce DMAP, a biologically-inspired, attention-based policy network architecture. DMAP combines independent proprioceptive processing, a distributed policy with individual controllers for each joint, and an attention mechanism, to dynamically gate sensory information from different body parts to different controllers. Despite not having access to the (hidden) morphology information, DMAP can be trained end-to-end in all the considered environments, overall matching or surpassing the performance of an oracle agent. Thus DMAP, implementing principles from biological motor control, provides a strong inductive bias for learning challenging sensorimotor tasks. Overall, our work corroborates the power of these principles in challenging locomotion tasks.

</p>
</details>

<details><summary><b>TVLT: Textless Vision-Language Transformer</b>
<a href="https://arxiv.org/abs/2209.14156">arxiv:2209.14156</a>
&#x1F4C8; 96 <br>
<p>Zineng Tang, Jaemin Cho, Yixin Nie, Mohit Bansal</p></summary>
<p>

**Abstract:** In this work, we present the Textless Vision-Language Transformer (TVLT), where homogeneous transformer blocks take raw visual and audio inputs for vision-and-language representation learning with minimal modality-specific design, and do not use text-specific modules such as tokenization or automatic speech recognition (ASR). TVLT is trained by reconstructing masked patches of continuous video frames and audio spectrograms (masked autoencoding) and contrastive modeling to align video and audio. TVLT attains performance comparable to its text-based counterpart, on various multimodal tasks, such as visual question answering, image retrieval, video retrieval, and multimodal sentiment analysis, with 28x faster inference speed and only 1/3 of the parameters. Our findings suggest the possibility of learning compact and efficient visual-linguistic representations from low-level visual and audio signals without assuming the prior existence of text. Our code and checkpoints are available at: https://github.com/zinengtang/TVLT

</p>
</details>

<details><summary><b>Downstream Datasets Make Surprisingly Good Pretraining Corpora</b>
<a href="https://arxiv.org/abs/2209.14389">arxiv:2209.14389</a>
&#x1F4C8; 89 <br>
<p>Kundan Krishna, Saurabh Garg, Jeffrey P. Bigham, Zachary C. Lipton</p></summary>
<p>

**Abstract:** For most natural language processing tasks, the dominant practice is to finetune large pretrained transformer models (e.g., BERT) using smaller downstream datasets. Despite the success of this approach, it remains unclear to what extent these gains are attributable to the massive background corpora employed for pretraining versus to the pretraining objectives themselves. This paper introduces a large-scale study of self-pretraining, where the same (downstream) training data is used for both pretraining and finetuning. In experiments addressing both ELECTRA and RoBERTa models and 10 distinct downstream datasets, we observe that self-pretraining rivals standard pretraining on the BookWiki corpus (despite using around $10\times$--$500\times$ less data), outperforming the latter on $7$ and $5$ datasets, respectively. Surprisingly, these task-specific pretrained models often perform well on other tasks, including the GLUE benchmark. Our results suggest that in many scenarios, performance gains attributable to pretraining are driven primarily by the pretraining objective itself and are not always attributable to the incorporation of massive datasets. These findings are especially relevant in light of concerns about intellectual property and offensive content in web-scale pretraining data.

</p>
</details>

<details><summary><b>Automated Quality Controlled Analysis of 2D Phase Contrast Cardiovascular Magnetic Resonance Imaging</b>
<a href="https://arxiv.org/abs/2209.14212">arxiv:2209.14212</a>
&#x1F4C8; 81 <br>
<p>Emily Chan, Ciaran O'Hanlon, Carlota Asegurado Marquez, Marwenie Petalcorin, Jorge Mariscal-Harana, Haotian Gu, Raymond J. Kim, Robert M. Judd, Phil Chowienczyk, Julia A. Schnabel, Reza Razavi, Andrew P. King, Bram Ruijsink, Esther Puyol-Antón</p></summary>
<p>

**Abstract:** Flow analysis carried out using phase contrast cardiac magnetic resonance imaging (PC-CMR) enables the quantification of important parameters that are used in the assessment of cardiovascular function. An essential part of this analysis is the identification of the correct CMR views and quality control (QC) to detect artefacts that could affect the flow quantification. We propose a novel deep learning based framework for the fully-automated analysis of flow from full CMR scans that first carries out these view selection and QC steps using two sequential convolutional neural networks, followed by automatic aorta and pulmonary artery segmentation to enable the quantification of key flow parameters. Accuracy values of 0.958 and 0.914 were obtained for view classification and QC, respectively. For segmentation, Dice scores were $>$0.969 and the Bland-Altman plots indicated excellent agreement between manual and automatic peak flow values. In addition, we tested our pipeline on an external validation data set, with results indicating good robustness of the pipeline. This work was carried out using multivendor clinical data consisting of 986 cases, indicating the potential for the use of this pipeline in a clinical setting.

</p>
</details>

<details><summary><b>Spectral Diffusion Processes</b>
<a href="https://arxiv.org/abs/2209.14125">arxiv:2209.14125</a>
&#x1F4C8; 40 <br>
<p>Angus Phillips, Thomas Seror, Michael Hutchinson, Valentin De Bortoli, Arnaud Doucet, Emile Mathieu</p></summary>
<p>

**Abstract:** Score-based generative modelling (SGM) has proven to be a very effective method for modelling densities on finite-dimensional spaces. In this work we propose to extend this methodology to learn generative models over functional spaces. To do so, we represent functional data in spectral space to dissociate the stochastic part of the processes from their space-time part. Using dimensionality reduction techniques we then sample from their stochastic component using finite dimensional SGM. We demonstrate our method's effectiveness for modelling various multimodal datasets.

</p>
</details>

<details><summary><b>ArNLI: Arabic Natural Language Inference for Entailment and Contradiction Detection</b>
<a href="https://arxiv.org/abs/2209.13953">arxiv:2209.13953</a>
&#x1F4C8; 38 <br>
<p>Khloud Al Jallad, Nada Ghneim</p></summary>
<p>

**Abstract:** Natural Language Inference (NLI) is a hot topic research in natural language processing, contradiction detection between sentences is a special case of NLI. This is considered a difficult NLP task which has a big influence when added as a component in many NLP applications, such as Question Answering Systems, text Summarization. Arabic Language is one of the most challenging low-resources languages in detecting contradictions due to its rich lexical, semantics ambiguity. We have created a data set of more than 12k sentences and named ArNLI, that will be publicly available. Moreover, we have applied a new model inspired by Stanford contradiction detection proposed solutions on English language. We proposed an approach to detect contradictions between pairs of sentences in Arabic language using contradiction vector combined with language model vector as an input to machine learning model. We analyzed results of different traditional machine learning classifiers and compared their results on our created data set (ArNLI) and on an automatic translation of both PHEME, SICK English data sets. Best results achieved using Random Forest classifier with an accuracy of 99%, 60%, 75% on PHEME, SICK and ArNLI respectively.

</p>
</details>

<details><summary><b>NVRadarNet: Real-Time Radar Obstacle and Free Space Detection for Autonomous Driving</b>
<a href="https://arxiv.org/abs/2209.14499">arxiv:2209.14499</a>
&#x1F4C8; 22 <br>
<p>Alexander Popov, Patrik Gebhardt, Ke Chen, Ryan Oldja, Heeseok Lee, Shane Murray, Ruchi Bhargava, Nikolai Smolyanskiy</p></summary>
<p>

**Abstract:** Detecting obstacles is crucial for safe and efficient autonomous driving. To this end, we present NVRadarNet, a deep neural network (DNN) that detects dynamic obstacles and drivable free space using automotive RADAR sensors. The network utilizes temporally accumulated data from multiple RADAR sensors to detect dynamic obstacles and compute their orientation in a top-down bird's-eye view (BEV). The network also regresses drivable free space to detect unclassified obstacles. Our DNN is the first of its kind to utilize sparse RADAR signals in order to perform obstacle and free space detection in real time from RADAR data only. The network has been successfully used for perception on our autonomous vehicles in real self-driving scenarios. The network runs faster than real time on an embedded GPU and shows good generalization across geographic regions.

</p>
</details>

<details><summary><b>Conformal Prediction is Robust to Label Noise</b>
<a href="https://arxiv.org/abs/2209.14295">arxiv:2209.14295</a>
&#x1F4C8; 19 <br>
<p>Bat-Sheva Einbinder, Stephen Bates, Anastasios N. Angelopoulos, Asaf Gendler, Yaniv Romano</p></summary>
<p>

**Abstract:** We study the robustness of conformal prediction, a powerful tool for uncertainty quantification, to label noise. Our analysis tackles both regression and classification problems, characterizing when and how it is possible to construct uncertainty sets that correctly cover the unobserved noiseless ground truth labels. Through stylized theoretical examples and practical experiments, we argue that naive conformal prediction covers the noiseless ground truth label unless the noise distribution is adversarially designed. This leads us to believe that correcting for label noise is unnecessary except for pathological data distributions or noise sources. In such cases, we can also correct for noise of bounded size in the conformal prediction algorithm in order to ensure correct coverage of the ground truth labels without score or data regularity.

</p>
</details>

<details><summary><b>Minimax Optimal Kernel Operator Learning via Multilevel Training</b>
<a href="https://arxiv.org/abs/2209.14430">arxiv:2209.14430</a>
&#x1F4C8; 16 <br>
<p>Jikai Jin, Yiping Lu, Jose Blanchet, Lexing Ying</p></summary>
<p>

**Abstract:** Learning mappings between infinite-dimensional function spaces has achieved empirical success in many disciplines of machine learning, including generative modeling, functional data analysis, causal inference, and multi-agent reinforcement learning. In this paper, we study the statistical limit of learning a Hilbert-Schmidt operator between two infinite-dimensional Sobolev reproducing kernel Hilbert spaces. We establish the information-theoretic lower bound in terms of the Sobolev Hilbert-Schmidt norm and show that a regularization that learns the spectral components below the bias contour and ignores the ones that are above the variance contour can achieve the optimal learning rate. At the same time, the spectral components between the bias and variance contours give us flexibility in designing computationally feasible machine learning algorithms. Based on this observation, we develop a multilevel kernel operator learning algorithm that is optimal when learning linear operators between infinite-dimensional function spaces.

</p>
</details>

<details><summary><b>Neural Methods for Logical Reasoning Over Knowledge Graphs</b>
<a href="https://arxiv.org/abs/2209.14464">arxiv:2209.14464</a>
&#x1F4C8; 13 <br>
<p>Alfonso Amayuelas, Shuai Zhang, Susie Xi Rao, Ce Zhang</p></summary>
<p>

**Abstract:** Reasoning is a fundamental problem for computers and deeply studied in Artificial Intelligence. In this paper, we specifically focus on answering multi-hop logical queries on Knowledge Graphs (KGs). This is a complicated task because, in real-world scenarios, the graphs tend to be large and incomplete. Most previous works have been unable to create models that accept full First-Order Logical (FOL) queries, which include negative queries, and have only been able to process a limited set of query structures. Additionally, most methods present logic operators that can only perform the logical operation they are made for. We introduce a set of models that use Neural Networks to create one-point vector embeddings to answer the queries. The versatility of neural networks allows the framework to handle FOL queries with Conjunction ($\wedge$), Disjunction ($\vee$) and Negation ($\neg$) operators. We demonstrate experimentally the performance of our model through extensive experimentation on well-known benchmarking datasets. Besides having more versatile operators, the models achieve a 10\% relative increase over the best performing state of the art and more than 30\% over the original method based on single-point vector embeddings.

</p>
</details>

<details><summary><b>Racial Bias in the Beautyverse</b>
<a href="https://arxiv.org/abs/2209.13939">arxiv:2209.13939</a>
&#x1F4C8; 12 <br>
<p>Piera Riccio, Nuria Oliver</p></summary>
<p>

**Abstract:** This short paper proposes a preliminary and yet insightful investigation of racial biases in beauty filters techniques currently used on social media. The obtained results are a call to action for researchers in Computer Vision: such biases risk being replicated and exaggerated in the Metaverse and, as a consequence, they deserve more attention from the community.

</p>
</details>

<details><summary><b>Out-of-Distribution Detection for LiDAR-based 3D Object Detection</b>
<a href="https://arxiv.org/abs/2209.14435">arxiv:2209.14435</a>
&#x1F4C8; 10 <br>
<p>Chengjie Huang, Van Duong Nguyen, Vahdat Abdelzad, Christopher Gus Mannes, Luke Rowe, Benjamin Therien, Rick Salay, Krzysztof Czarnecki</p></summary>
<p>

**Abstract:** 3D object detection is an essential part of automated driving, and deep neural networks (DNNs) have achieved state-of-the-art performance for this task. However, deep models are notorious for assigning high confidence scores to out-of-distribution (OOD) inputs, that is, inputs that are not drawn from the training distribution. Detecting OOD inputs is challenging and essential for the safe deployment of models. OOD detection has been studied extensively for the classification task, but it has not received enough attention for the object detection task, specifically LiDAR-based 3D object detection. In this paper, we focus on the detection of OOD inputs for LiDAR-based 3D object detection. We formulate what OOD inputs mean for object detection and propose to adapt several OOD detection methods for object detection. We accomplish this by our proposed feature extraction method. To evaluate OOD detection methods, we develop a simple but effective technique of generating OOD objects for a given object detection model. Our evaluation based on the KITTI dataset shows that different OOD detection methods have biases toward detecting specific OOD objects. It emphasizes the importance of combined OOD detection methods and more research in this direction.

</p>
</details>

<details><summary><b>The Chamber Ensemble Generator: Limitless High-Quality MIR Data via Generative Modeling</b>
<a href="https://arxiv.org/abs/2209.14458">arxiv:2209.14458</a>
&#x1F4C8; 9 <br>
<p>Yusong Wu, Josh Gardner, Ethan Manilow, Ian Simon, Curtis Hawthorne, Jesse Engel</p></summary>
<p>

**Abstract:** Data is the lifeblood of modern machine learning systems, including for those in Music Information Retrieval (MIR). However, MIR has long been mired by small datasets and unreliable labels. In this work, we propose to break this bottleneck using generative modeling. By pipelining a generative model of notes (Coconet trained on Bach Chorales) with a structured synthesis model of chamber ensembles (MIDI-DDSP trained on URMP), we demonstrate a system capable of producing unlimited amounts of realistic chorale music with rich annotations including mixes, stems, MIDI, note-level performance attributes (staccato, vibrato, etc.), and even fine-grained synthesis parameters (pitch, amplitude, etc.). We call this system the Chamber Ensemble Generator (CEG), and use it to generate a large dataset of chorales from four different chamber ensembles (CocoChorales). We demonstrate that data generated using our approach improves state-of-the-art models for music transcription and source separation, and we release both the system and the dataset as an open-source foundation for future work in the MIR community.

</p>
</details>

<details><summary><b>Multilingual Search with Subword TF-IDF</b>
<a href="https://arxiv.org/abs/2209.14281">arxiv:2209.14281</a>
&#x1F4C8; 9 <br>
<p>Artit Wangperawong</p></summary>
<p>

**Abstract:** Multilingual search can be achieved with subword tokenization. The accuracy of traditional TF-IDF approaches depend on manually curated tokenization, stop words and stemming rules, whereas subword TF-IDF (STF-IDF) can offer higher accuracy without such heuristics. Moreover, multilingual support can be incorporated inherently as part of the subword tokenization model training. XQuAD evaluation demonstrates the advantages of STF-IDF: superior information retrieval accuracy of 85.4% for English and over 80% for 10 other languages without any heuristics-based preprocessing. The software to reproduce these results are open-sourced as a part of Text2Text: https://github.com/artitw/text2text

</p>
</details>

<details><summary><b>Automatic Analysis of Available Source Code of Top Artificial Intelligence Conference Papers</b>
<a href="https://arxiv.org/abs/2209.14155">arxiv:2209.14155</a>
&#x1F4C8; 9 <br>
<p>Jialiang Lin, Yingmin Wang, Yao Yu, Yu Zhou, Yidong Chen, Xiaodong Shi</p></summary>
<p>

**Abstract:** Source code is essential for researchers to reproduce the methods and replicate the results of artificial intelligence (AI) papers. Some organizations and researchers manually collect AI papers with available source code to contribute to the AI community. However, manual collection is a labor-intensive and time-consuming task. To address this issue, we propose a method to automatically identify papers with available source code and extract their source code repository URLs. With this method, we find that 20.5% of regular papers of 10 top AI conferences published from 2010 to 2019 are identified as papers with available source code and that 8.1% of these source code repositories are no longer accessible. We also create the XMU NLP Lab README Dataset, the largest dataset of labeled README files for source code document research. Through this dataset, we have discovered that quite a few README files have no installation instructions or usage tutorials provided. Further, a large-scale comprehensive statistical analysis is made for a general picture of the source code of AI conference papers. The proposed solution can also go beyond AI conference papers to analyze other scientific papers from both journals and conferences to shed light on more domains.

</p>
</details>

<details><summary><b>Leveraging machine learning for less developed languages: Progress on Urdu text detection</b>
<a href="https://arxiv.org/abs/2209.14022">arxiv:2209.14022</a>
&#x1F4C8; 9 <br>
<p>Hazrat Ali</p></summary>
<p>

**Abstract:** Text detection in natural scene images has applications for autonomous driving, navigation help for elderly and blind people. However, the research on Urdu text detection is usually hindered by lack of data resources. We have developed a dataset of scene images with Urdu text. We present the use of machine learning methods to perform detection of Urdu text from the scene images. We extract text regions using channel enhanced Maximally Stable Extremal Region (MSER) method. First, we classify text and noise based on their geometric properties. Next, we use a support vector machine for early discarding of non-text regions. To further remove the non-text regions, we use histogram of oriented gradients (HoG) features obtained and train a second SVM classifier. This improves the overall performance on text region detection within the scene images. To support research on Urdu text, We aim to make the data freely available for research use. We also aim to highlight the challenges and the research gap for Urdu text detection.

</p>
</details>

<details><summary><b>Argumentative Reward Learning: Reasoning About Human Preferences</b>
<a href="https://arxiv.org/abs/2209.14010">arxiv:2209.14010</a>
&#x1F4C8; 9 <br>
<p>Francis Rhys Ward, Francesco Belardinelli, Francesca Toni</p></summary>
<p>

**Abstract:** We define a novel neuro-symbolic framework, argumentative reward learning, which combines preference-based argumentation with existing approaches to reinforcement learning from human feedback. Our method improves prior work by generalising human preferences, reducing the burden on the user and increasing the robustness of the reward model. We demonstrate this with a number of experiments.

</p>
</details>

<details><summary><b>Hierarchical MixUp Multi-label Classification with Imbalanced Interdisciplinary Research Proposals</b>
<a href="https://arxiv.org/abs/2209.13912">arxiv:2209.13912</a>
&#x1F4C8; 9 <br>
<p>Meng Xiao, Min Wu, Ziyue Qiao, Zhiyuan Ning, Yi Du, Yanjie Fu, Yuanchun Zhou</p></summary>
<p>

**Abstract:** Funding agencies are largely relied on a topic matching between domain experts and research proposals to assign proposal reviewers. As proposals are increasingly interdisciplinary, it is challenging to profile the interdisciplinary nature of a proposal, and, thereafter, find expert reviewers with an appropriate set of expertise. An essential step in solving this challenge is to accurately model and classify the interdisciplinary labels of a proposal. Existing methodological and application-related literature, such as textual classification and proposal classification, are insufficient in jointly addressing the three key unique issues introduced by interdisciplinary proposal data: 1) the hierarchical structure of discipline labels of a proposal from coarse-grain to fine-grain, e.g., from information science to AI to fundamentals of AI. 2) the heterogeneous semantics of various main textual parts that play different roles in a proposal; 3) the number of proposals is imbalanced between non-interdisciplinary and interdisciplinary research. Can we simultaneously address the three issues in understanding the proposal's interdisciplinary nature? In response to this question, we propose a hierarchical mixup multiple-label classification framework, which we called H-MixUp. H-MixUp leverages a transformer-based semantic information extractor and a GCN-based interdisciplinary knowledge extractor for the first and second issues. H-MixUp develops a fused training method of Wold-level MixUp, Word-level CutMix, Manifold MixUp, and Document-level MixUp to address the third issue.

</p>
</details>

<details><summary><b>Multimodal Prediction of Spontaneous Humour: A Novel Dataset and First Results</b>
<a href="https://arxiv.org/abs/2209.14272">arxiv:2209.14272</a>
&#x1F4C8; 8 <br>
<p>Lukas Christ, Shahin Amiriparian, Alexander Kathan, Niklas Müller, Andreas König, Björn W. Schuller</p></summary>
<p>

**Abstract:** Humour is a substantial element of human affect and cognition. Its automatic understanding can facilitate a more naturalistic human-device interaction and the humanisation of artificial intelligence. Current methods of humour detection are solely based on staged data making them inadequate for 'real-world' applications. We address this deficiency by introducing the novel Passau-Spontaneous Football Coach Humour (Passau-SFCH) dataset, comprising of about 11 hours of recordings. The Passau-SFCH dataset is annotated for the presence of humour and its dimensions (sentiment and direction) as proposed in Martin's Humor Style Questionnaire. We conduct a series of experiments, employing pretrained Transformers, convolutional neural networks, and expert-designed features. The performance of each modality (text, audio, video) for spontaneous humour recognition is analysed and their complementarity is investigated. Our findings suggest that for the automatic analysis of humour and its sentiment, facial expressions are most promising, while humour direction can be best modelled via text-based features. The results reveal considerable differences among various subjects, highlighting the individuality of humour usage and style. Further, we observe that a decision-level fusion yields the best recognition result. Finally, we make our code publicly available at https://www.github.com/EIHW/passau-sfch. The Passau-SFCH dataset is available upon request.

</p>
</details>

<details><summary><b>Efficient Medical Image Assessment via Self-supervised Learning</b>
<a href="https://arxiv.org/abs/2209.14434">arxiv:2209.14434</a>
&#x1F4C8; 7 <br>
<p>Chun-Yin Huang, Qi Lei, Xiaoxiao Li</p></summary>
<p>

**Abstract:** High-performance deep learning methods typically rely on large annotated training datasets, which are difficult to obtain in many clinical applications due to the high cost of medical image labeling. Existing data assessment methods commonly require knowing the labels in advance, which are not feasible to achieve our goal of 'knowing which data to label.' To this end, we formulate and propose a novel and efficient data assessment strategy, EXponentiAl Marginal sINgular valuE (EXAMINE) score, to rank the quality of unlabeled medical image data based on their useful latent representations extracted via Self-supervised Learning (SSL) networks. Motivated by theoretical implication of SSL embedding space, we leverage a Masked Autoencoder for feature extraction. Furthermore, we evaluate data quality based on the marginal change of the largest singular value after excluding the data point in the dataset. We conduct extensive experiments on a pathology dataset. Our results indicate the effectiveness and efficiency of our proposed methods for selecting the most valuable data to label.

</p>
</details>

<details><summary><b>Score Modeling for Simulation-based Inference</b>
<a href="https://arxiv.org/abs/2209.14249">arxiv:2209.14249</a>
&#x1F4C8; 7 <br>
<p>Tomas Geffner, George Papamakarios, Andriy Mnih</p></summary>
<p>

**Abstract:** Neural Posterior Estimation methods for simulation-based inference can be ill-suited for dealing with posterior distributions obtained by conditioning on multiple observations, as they may require a large number of simulator calls to yield accurate approximations. Neural Likelihood Estimation methods can naturally handle multiple observations, but require a separate inference step, which may affect their efficiency and performance. We introduce a new method for simulation-based inference that enjoys the benefits of both approaches. We propose to model the scores for the posterior distributions induced by individual observations, and introduce a sampling algorithm that combines the learned scores to approximately sample from the target efficiently.

</p>
</details>

<details><summary><b>Online Policy Optimization for Robust MDP</b>
<a href="https://arxiv.org/abs/2209.13841">arxiv:2209.13841</a>
&#x1F4C8; 7 <br>
<p>Jing Dong, Jingwei Li, Baoxiang Wang, Jingzhao Zhang</p></summary>
<p>

**Abstract:** Reinforcement learning (RL) has exceeded human performance in many synthetic settings such as video games and Go. However, real-world deployment of end-to-end RL models is less common, as RL models can be very sensitive to slight perturbation of the environment. The robust Markov decision process (MDP) framework -- in which the transition probabilities belong to an uncertainty set around a nominal model -- provides one way to develop robust models. While previous analysis shows RL algorithms are effective assuming access to a generative model, it remains unclear whether RL can be efficient under a more realistic online setting, which requires a careful balance between exploration and exploitation. In this work, we consider online robust MDP by interacting with an unknown nominal system. We propose a robust optimistic policy optimization algorithm that is provably efficient. To address the additional uncertainty caused by an adversarial environment, our model features a new optimistic update rule derived via Fenchel conjugates. Our analysis establishes the first regret bound for online robust MDPs.

</p>
</details>

<details><summary><b>A Two-Stage Method for Chinese AMR Parsing</b>
<a href="https://arxiv.org/abs/2209.14512">arxiv:2209.14512</a>
&#x1F4C8; 6 <br>
<p>Liang Chen, Bofei Gao, Baobao Chang</p></summary>
<p>

**Abstract:** In this paper, we provide a detailed description of our system at CAMRP-2022 evaluation. We firstly propose a two-stage method to conduct Chinese AMR Parsing with alignment generation, which includes Concept-Prediction and Relation-Prediction stages. Our model achieves 0.7756 and 0.7074 Align-Smatch F1 scores on the CAMR 2.0 test set and the blind-test set of CAMRP-2022 individually. We also analyze the result and the limitation such as the error propagation and class imbalance problem we conclude in the current method. Code and the trained models are released at https://github.com/PKUnlp-icler/Two-Stage-CAMRP for reproduction.

</p>
</details>

<details><summary><b>medigan: A Python Library of Pretrained Generative Models for Enriched Data Access in Medical Imaging</b>
<a href="https://arxiv.org/abs/2209.14472">arxiv:2209.14472</a>
&#x1F4C8; 6 <br>
<p>Richard Osuala, Grzegorz Skorupko, Noussair Lazrak, Lidia Garrucho, Eloy García, Smriti Joshi, Socayna Jouide, Michael Rutherford, Fred Prior, Kaisar Kushibar, Oliver Diaz, Karim Lekadir</p></summary>
<p>

**Abstract:** Synthetic data generated by generative models can enhance the performance and capabilities of data-hungry deep learning models in medical imaging. However, there is (1) limited availability of (synthetic) datasets and (2) generative models are complex to train, which hinders their adoption in research and clinical applications. To reduce this entry barrier, we propose medigan, a one-stop shop for pretrained generative models implemented as an open-source framework-agnostic Python library. medigan allows researchers and developers to create, increase, and domain-adapt their training data in just a few lines of code. Guided by design decisions based on gathered end-user requirements, we implement medigan based on modular components for generative model (i) execution, (ii) visualisation, (iii) search & ranking, and (iv) contribution. The library's scalability and design is demonstrated by its growing number of integrated and readily-usable pretrained generative models consisting of 21 models utilising 9 different Generative Adversarial Network architectures trained on 11 datasets from 4 domains, namely, mammography, endoscopy, x-ray, and MRI. Furthermore, 3 applications of medigan are analysed in this work, which include (a) enabling community-wide sharing of restricted data, (b) investigating generative model evaluation metrics, and (c) improving clinical downstream tasks. In (b), extending on common medical image synthesis assessment and reporting standards, we show Fréchet Inception Distance variability based on image normalisation and radiology-specific feature extraction.

</p>
</details>

<details><summary><b>GeONet: a neural operator for learning the Wasserstein geodesic</b>
<a href="https://arxiv.org/abs/2209.14440">arxiv:2209.14440</a>
&#x1F4C8; 6 <br>
<p>Andrew Gracyk, Xiaohui Chen</p></summary>
<p>

**Abstract:** Optimal transport (OT) offers a versatile framework to compare complex data distributions in a geometrically meaningful way. Traditional methods for computing the Wasserstein distance and geodesic between probability measures require mesh-dependent domain discretization and suffer from the curse-of-dimensionality. We present GeONet, a mesh-invariant deep neural operator network that learns the non-linear mapping from the input pair of initial and terminal distributions to the Wasserstein geodesic connecting the two endpoint distributions. In the offline training stage, GeONet learns the saddle point optimality conditions for the dynamic formulation of the OT problem in the primal and dual spaces that are characterized by a coupled PDE system. The subsequent inference stage is instantaneous and can be deployed for real-time predictions in the online learning setting. We demonstrate that GeONet achieves comparable testing accuracy to the standard OT solvers on a simulation example and the CIFAR-10 dataset with considerably reduced inference-stage computational cost by orders of magnitude.

</p>
</details>

<details><summary><b>CALIP: Zero-Shot Enhancement of CLIP with Parameter-free Attention</b>
<a href="https://arxiv.org/abs/2209.14169">arxiv:2209.14169</a>
&#x1F4C8; 6 <br>
<p>Ziyu Guo, Renrui Zhang, Longtian Qiu, Xianzheng Ma, Xupeng Miao, Xuming He, Bin Cui</p></summary>
<p>

**Abstract:** Contrastive Language-Image Pre-training (CLIP) has been shown to learn visual representations with great transferability, which achieves promising accuracy for zero-shot classification. To further improve its downstream performance, existing works propose additional learnable modules upon CLIP and fine-tune them by few-shot training sets. However, the resulting extra training cost and data requirement severely hinder the efficiency for model deployment and knowledge transfer. In this paper, we introduce a free-lunch enhancement method, CALIP, to boost CLIP's zero-shot performance via a parameter-free Attention module. Specifically, we guide visual and textual representations to interact with each other and explore cross-modal informative features via attention. As the pre-training has largely reduced the embedding distances between two modalities, we discard all learnable parameters in the attention and bidirectionally update the multi-modal features, enabling the whole process to be parameter-free and training-free. In this way, the images are blended with textual-aware signals and the text representations become visual-guided for better adaptive zero-shot alignment. We evaluate CALIP on various benchmarks of 14 datasets for both 2D image and 3D point cloud few-shot classification, showing consistent zero-shot performance improvement over CLIP. Based on that, we further insert a small number of linear layers in CALIP's attention module and verify our robustness under the few-shot settings, which also achieves leading performance compared to existing methods. Those extensive experiments demonstrate the superiority of our approach for efficient enhancement of CLIP.

</p>
</details>

<details><summary><b>Graph Soft-Contrastive Learning via Neighborhood Ranking</b>
<a href="https://arxiv.org/abs/2209.13964">arxiv:2209.13964</a>
&#x1F4C8; 6 <br>
<p>Zhiyuan Ning, Pengfei Wang, Pengyang Wang, Ziyue Qiao, Wei Fan, Denghui Zhang, Yi Du, Yuanchun Zhou</p></summary>
<p>

**Abstract:** Graph contrastive learning (GCL) has been an emerging solution for graph self-supervised learning. The core principle of GCL is to reduce the distance between samples in the positive view, but increase the distance between samples in the negative view. While achieving promising performances, current GCL methods still suffer from two limitations: (1) uncontrollable validity of augmentation, that graph perturbation may produce invalid views against semantics and feature-topology correspondence of graph data; and (2) unreliable binary contrastive justification, that the positiveness and negativeness of the constructed views are difficult to be determined for non-euclidean graph data. To tackle the above limitations, we propose a new contrastive learning paradigm for graphs, namely Graph Soft-Contrastive Learning (GSCL), that conducts contrastive learning in a finer-granularity via ranking neighborhoods without any augmentations and binary contrastive justification. GSCL is built upon the fundamental assumption of graph proximity that connected neighbors are more similar than far-distant nodes. Specifically, we develop pair-wise and list-wise Gated Ranking infoNCE Loss functions to preserve the relative ranking relationship in the neighborhood. Moreover, as the neighborhood size exponentially expands with more hops considered, we propose neighborhood sampling strategies to improve learning efficiency. The extensive experimental results show that our proposed GSCL can consistently achieve state-of-the-art performances on various public datasets with comparable practical complexity to GCL.

</p>
</details>

<details><summary><b>A simple but strong baseline for online continual learning: Repeated Augmented Rehearsal</b>
<a href="https://arxiv.org/abs/2209.13917">arxiv:2209.13917</a>
&#x1F4C8; 6 <br>
<p>Yaqian Zhang, Bernhard Pfahringer, Eibe Frank, Albert Bifet, Nick Jin Sean Lim, Yunzhe Jia</p></summary>
<p>

**Abstract:** Online continual learning (OCL) aims to train neural networks incrementally from a non-stationary data stream with a single pass through data. Rehearsal-based methods attempt to approximate the observed input distributions over time with a small memory and revisit them later to avoid forgetting. Despite its strong empirical performance, rehearsal methods still suffer from a poor approximation of the loss landscape of past data with memory samples. This paper revisits the rehearsal dynamics in online settings. We provide theoretical insights on the inherent memory overfitting risk from the viewpoint of biased and dynamic empirical risk minimization, and examine the merits and limits of repeated rehearsal. Inspired by our analysis, a simple and intuitive baseline, Repeated Augmented Rehearsal (RAR), is designed to address the underfitting-overfitting dilemma of online rehearsal. Surprisingly, across four rather different OCL benchmarks, this simple baseline outperforms vanilla rehearsal by 9%-17% and also significantly improves state-of-the-art rehearsal-based methods MIR, ASER, and SCR. We also demonstrate that RAR successfully achieves an accurate approximation of the loss landscape of past data and high-loss ridge aversion in its learning trajectory. Extensive ablation studies are conducted to study the interplay between repeated and augmented rehearsal and reinforcement learning (RL) is applied to dynamically adjust the hyperparameters of RAR to balance the stability-plasticity trade-off online.

</p>
</details>

<details><summary><b>Natural Language Processing Methods to Identify Oncology Patients at High Risk for Acute Care with Clinical Notes</b>
<a href="https://arxiv.org/abs/2209.13860">arxiv:2209.13860</a>
&#x1F4C8; 6 <br>
<p>Claudio Fanconi, Marieke van Buchem, Tina Hernandez-Boussard</p></summary>
<p>

**Abstract:** Clinical notes are an essential component of a health record. This paper evaluates how natural language processing (NLP) can be used to identify the risk of acute care use (ACU) in oncology patients, once chemotherapy starts. Risk prediction using structured health data (SHD) is now standard, but predictions using free-text formats are complex. This paper explores the use of free-text notes for the prediction of ACU instead of SHD. Deep Learning models were compared to manually engineered language features. Results show that SHD models minimally outperform NLP models; an l1-penalised logistic regression with SHD achieved a C-statistic of 0.748 (95%-CI: 0.735, 0.762), while the same model with language features achieved 0.730 (95%-CI: 0.717, 0.745) and a transformer-based model achieved 0.702 (95%-CI: 0.688, 0.717). This paper shows how language models can be used in clinical applications and underlines how risk bias is different for diverse patient groups, even using only free-text data.

</p>
</details>

<details><summary><b>Intrinsic Dimensionality Estimation within Tight Localities: A Theoretical and Experimental Analysis</b>
<a href="https://arxiv.org/abs/2209.14475">arxiv:2209.14475</a>
&#x1F4C8; 5 <br>
<p>Laurent Amsaleg, Oussama Chelly, Michael E. Houle, Ken-ichi Kawarabayashi, Miloš Radovanović, Weeris Treeratanajaru</p></summary>
<p>

**Abstract:** Accurate estimation of Intrinsic Dimensionality (ID) is of crucial importance in many data mining and machine learning tasks, including dimensionality reduction, outlier detection, similarity search and subspace clustering. However, since their convergence generally requires sample sizes (that is, neighborhood sizes) on the order of hundreds of points, existing ID estimation methods may have only limited usefulness for applications in which the data consists of many natural groups of small size. In this paper, we propose a local ID estimation strategy stable even for `tight' localities consisting of as few as 20 sample points. The estimator applies MLE techniques over all available pairwise distances among the members of the sample, based on a recent extreme-value-theoretic model of intrinsic dimensionality, the Local Intrinsic Dimension (LID). Our experimental results show that our proposed estimation technique can achieve notably smaller variance, while maintaining comparable levels of bias, at much smaller sample sizes than state-of-the-art estimators.

</p>
</details>

<details><summary><b>Feature Decoupling in Self-supervised Representation Learning for Open Set Recognition</b>
<a href="https://arxiv.org/abs/2209.14385">arxiv:2209.14385</a>
&#x1F4C8; 5 <br>
<p>Jingyun Jia, Philip K. Chan</p></summary>
<p>

**Abstract:** Assuming unknown classes could be present during classification, the open set recognition (OSR) task aims to classify an instance into a known class or reject it as unknown. In this paper, we use a two-stage training strategy for the OSR problems. In the first stage, we introduce a self-supervised feature decoupling method that finds the content features of the input samples from the known classes. Specifically, our feature decoupling approach learns a representation that can be split into content features and transformation features. In the second stage, we fine-tune the content features with the class labels. The fine-tuned content features are then used for the OSR problems. Moreover, we consider an unsupervised OSR scenario, where we cluster the content features learned from the first stage. To measure representation quality, we introduce intra-inter ratio (IIR). Our experimental results indicate that our proposed self-supervised approach outperforms others in image and malware OSR problems. Also, our analyses indicate that IIR is correlated with OSR performance.

</p>
</details>

<details><summary><b>Mobile Edge Computing, Metaverse, 6G Wireless Communications, Artificial Intelligence, and Blockchain: Survey and Their Convergence</b>
<a href="https://arxiv.org/abs/2209.14147">arxiv:2209.14147</a>
&#x1F4C8; 5 <br>
<p>Yitong Wang, Jun Zhao</p></summary>
<p>

**Abstract:** With the advances of the Internet of Things (IoT) and 5G/6G wireless communications, the paradigms of mobile computing have developed dramatically in recent years, from centralized mobile cloud computing to distributed fog computing and mobile edge computing (MEC). MEC pushes compute-intensive assignments to the edge of the network and brings resources as close to the endpoints as possible, addressing the shortcomings of mobile devices with regard to storage space, resource optimisation, computational performance and efficiency. Compared to cloud computing, as the distributed and closer infrastructure, the convergence of MEC with other emerging technologies, including the Metaverse, 6G wireless communications, artificial intelligence (AI), and blockchain, also solves the problems of network resource allocation, more network load as well as latency requirements. Accordingly, this paper investigates the computational paradigms used to meet the stringent requirements of modern applications. The application scenarios of MEC in mobile augmented reality (MAR) are provided. Furthermore, this survey presents the motivation of MEC-based Metaverse and introduces the applications of MEC to the Metaverse. Particular emphasis is given on a set of technical fusions mentioned above, e.g., 6G with MEC paradigm, MEC strengthened by blockchain, etc.

</p>
</details>

<details><summary><b>Offensive Language Detection on Twitter</b>
<a href="https://arxiv.org/abs/2209.14091">arxiv:2209.14091</a>
&#x1F4C8; 5 <br>
<p>Nikhil Chilwant, Syed Taqi Abbas Rizvi, Hassan Soliman</p></summary>
<p>

**Abstract:** Detection of offensive language in social media is one of the key challenges for social media. Researchers have proposed many advanced methods to accomplish this task. In this report, we try to use the learnings from their approach and incorporate our ideas to improve upon them. We have successfully achieved an accuracy of 74% in classifying offensive tweets. We also list upcoming challenges in the abusive content detection in the social media world.

</p>
</details>

<details><summary><b>An Efficient Multitask Learning Architecture for Affective Vocal Burst Analysis</b>
<a href="https://arxiv.org/abs/2209.13914">arxiv:2209.13914</a>
&#x1F4C8; 5 <br>
<p>Tobias Hallmen, Silvan Mertes, Dominik Schiller, Elisabeth André</p></summary>
<p>

**Abstract:** Affective speech analysis is an ongoing topic of research. A relatively new problem in this field is the analysis of vocal bursts, which are nonverbal vocalisations such as laughs or sighs. Current state-of-the-art approaches to address affective vocal burst analysis are mostly based on wav2vec2 or HuBERT features. In this paper, we investigate the use of the wav2vec successor data2vec in combination with a multitask learning pipeline to tackle different analysis problems at once. To assess the performance of our efficient multitask learning architecture, we participate in the 2022 ACII Affective Vocal Burst Challenge, showing that our approach substantially outperforms the baseline established there in three different subtasks.

</p>
</details>

<details><summary><b>Explainable classification of astronomical uncertain time series</b>
<a href="https://arxiv.org/abs/2210.00869">arxiv:2210.00869</a>
&#x1F4C8; 4 <br>
<p>Michael Franklin Mbouopda, Emille E O Ishida, Engelbert Mephu Nguifo, Emmanuel Gangler</p></summary>
<p>

**Abstract:** Exploring the expansion history of the universe, understanding its evolutionary stages, and predicting its future evolution are important goals in astrophysics. Today, machine learning tools are used to help achieving these goals by analyzing transient sources, which are modeled as uncertain time series. Although black-box methods achieve appreciable performance, existing interpretable time series methods failed to obtain acceptable performance for this type of data. Furthermore, data uncertainty is rarely taken into account in these methods. In this work, we propose an uncertaintyaware subsequence based model which achieves a classification comparable to that of state-of-the-art methods. Unlike conformal learning which estimates model uncertainty on predictions, our method takes data uncertainty as additional input. Moreover, our approach is explainable-by-design, giving domain experts the ability to inspect the model and explain its predictions. The explainability of the proposed method has also the potential to inspire new developments in theoretical astrophysics modeling by suggesting important subsequences which depict details of light curve shapes. The dataset, the source code of our experiment, and the results are made available on a public repository.

</p>
</details>

<details><summary><b>A deep learning approach to the probabilistic numerical solution of path-dependent partial differential equations</b>
<a href="https://arxiv.org/abs/2209.15010">arxiv:2209.15010</a>
&#x1F4C8; 4 <br>
<p>Jiang Yu Nguwi, Nicolas Privault</p></summary>
<p>

**Abstract:** Recent work on Path-Dependent Partial Differential Equations (PPDEs) has shown that PPDE solutions can be approximated by a probabilistic representation, implemented in the literature by the estimation of conditional expectations using regression. However, a limitation of this approach is to require the selection of a basis in a function space. In this paper, we overcome this limitation by the use of deep learning methods, and we show that this setting allows for the derivation of error bounds on the approximation of conditional expectations. Numerical examples based on a two-person zero-sum game, as well as on Asian and barrier option pricing, are presented. In comparison with other deep learning approaches, our algorithm appears to be more accurate, especially in large dimensions.

</p>
</details>

<details><summary><b>Motion and Appearance Adaptation for Cross-Domain Motion Transfer</b>
<a href="https://arxiv.org/abs/2209.14529">arxiv:2209.14529</a>
&#x1F4C8; 4 <br>
<p>Borun Xu, Biao Wang, Jinhong Deng, Jiale Tao, Tiezheng Ge, Yuning Jiang, Wen Li, Lixin Duan</p></summary>
<p>

**Abstract:** Motion transfer aims to transfer the motion of a driving video to a source image. When there are considerable differences between object in the driving video and that in the source image, traditional single domain motion transfer approaches often produce notable artifacts; for example, the synthesized image may fail to preserve the human shape of the source image (cf . Fig. 1 (a)). To address this issue, in this work, we propose a Motion and Appearance Adaptation (MAA) approach for cross-domain motion transfer, in which we regularize the object in the synthesized image to capture the motion of the object in the driving frame, while still preserving the shape and appearance of the object in the source image. On one hand, considering the object shapes of the synthesized image and the driving frame might be different, we design a shape-invariant motion adaptation module that enforces the consistency of the angles of object parts in two images to capture the motion information. On the other hand, we introduce a structure-guided appearance consistency module designed to regularize the similarity between the corresponding patches of the synthesized image and the source image without affecting the learned motion in the synthesized image. Our proposed MAA model can be trained in an end-to-end manner with a cyclic reconstruction loss, and ultimately produces a satisfactory motion transfer result (cf . Fig. 1 (b)). We conduct extensive experiments on human dancing dataset Mixamo-Video to Fashion-Video and human face dataset Vox-Celeb to Cufs; on both of these, our MAA model outperforms existing methods both quantitatively and qualitatively.

</p>
</details>

<details><summary><b>Visual Detection of Diver Attentiveness for Underwater Human-Robot Interaction</b>
<a href="https://arxiv.org/abs/2209.14447">arxiv:2209.14447</a>
&#x1F4C8; 4 <br>
<p>Sadman Sakib Enan, Junaed Sattar</p></summary>
<p>

**Abstract:** Many underwater tasks, such as cable-and-wreckage inspection, search-and-rescue, benefit from robust human-robot interaction (HRI) capabilities. With the recent advancements in vision-based underwater HRI methods, autonomous underwater vehicles (AUVs) can communicate with their human partners even during a mission. However, these interactions usually require active participation especially from humans (e.g., one must keep looking at the robot during an interaction). Therefore, an AUV must know when to start interacting with a human partner, i.e., if the human is paying attention to the AUV or not. In this paper, we present a diver attention estimation framework for AUVs to autonomously detect the attentiveness of a diver and then navigate and reorient itself, if required, with respect to the diver to initiate an interaction. The core element of the framework is a deep neural network (called DATT-Net) which exploits the geometric relation among 10 facial keypoints of the divers to determine their head orientation. Our on-the-bench experimental evaluations (using unseen data) demonstrate that the proposed DATT-Net architecture can determine the attentiveness of human divers with promising accuracy. Our real-world experiments also confirm the efficacy of DATT-Net which enables real-time inference and allows the AUV to position itself for an AUV-diver interaction.

</p>
</details>

<details><summary><b>Optimistic Posterior Sampling for Reinforcement Learning with Few Samples and Tight Guarantees</b>
<a href="https://arxiv.org/abs/2209.14414">arxiv:2209.14414</a>
&#x1F4C8; 4 <br>
<p>Daniil Tiapkin, Denis Belomestny, Daniele Calandriello, Eric Moulines, Remi Munos, Alexey Naumov, Mark Rowland, Michal Valko, Pierre Menard</p></summary>
<p>

**Abstract:** We consider reinforcement learning in an environment modeled by an episodic, finite, stage-dependent Markov decision process of horizon $H$ with $S$ states, and $A$ actions. The performance of an agent is measured by the regret after interacting with the environment for $T$ episodes. We propose an optimistic posterior sampling algorithm for reinforcement learning (OPSRL), a simple variant of posterior sampling that only needs a number of posterior samples logarithmic in $H$, $S$, $A$, and $T$ per state-action pair. For OPSRL we guarantee a high-probability regret bound of order at most $\widetilde{\mathcal{O}}(\sqrt{H^3SAT})$ ignoring $\text{poly}\log(HSAT)$ terms. The key novel technical ingredient is a new sharp anti-concentration inequality for linear forms which may be of independent interest. Specifically, we extend the normal approximation-based lower bound for Beta distributions by Alfers and Dinges [1984] to Dirichlet distributions. Our bound matches the lower bound of order $Ω(\sqrt{H^3SAT})$, thereby answering the open problems raised by Agrawal and Jia [2017b] for the episodic setting.

</p>
</details>

<details><summary><b>RADACS: Towards Higher-Order Reasoning using Action Recognition in Autonomous Vehicles</b>
<a href="https://arxiv.org/abs/2209.14408">arxiv:2209.14408</a>
&#x1F4C8; 4 <br>
<p>Alex Zhuang, Eddy Zhou, Quanquan Li, Rowan Dempster, Alikasim Budhwani, Mohammad Al-Sharman, Derek Rayside, William Melek</p></summary>
<p>

**Abstract:** When applied to autonomous vehicle settings, action recognition can help enrich an environment model's understanding of the world and improve plans for future action. Towards these improvements in autonomous vehicle decision-making, we propose in this work a novel two-stage online action recognition system, termed RADACS. RADACS formulates the problem of active agent detection and adapts ideas about actor-context relations from human activity recognition in a straightforward two-stage pipeline for action detection and classification. We show that our proposed scheme can outperform the baseline on the ICCV2021 Road Challenge dataset and by deploying it on a real vehicle platform, we demonstrate how a higher-order understanding of agent actions in an environment can improve decisions on a real autonomous vehicle.

</p>
</details>

<details><summary><b>Audio Barlow Twins: Self-Supervised Audio Representation Learning</b>
<a href="https://arxiv.org/abs/2209.14345">arxiv:2209.14345</a>
&#x1F4C8; 4 <br>
<p>Jonah Anton, Harry Coppock, Pancham Shukla, Bjorn W. Schuller</p></summary>
<p>

**Abstract:** The Barlow Twins self-supervised learning objective requires neither negative samples or asymmetric learning updates, achieving results on a par with the current state-of-the-art within Computer Vision. As such, we present Audio Barlow Twins, a novel self-supervised audio representation learning approach, adapting Barlow Twins to the audio domain. We pre-train on the large-scale audio dataset AudioSet, and evaluate the quality of the learnt representations on 18 tasks from the HEAR 2021 Challenge, achieving results which outperform, or otherwise are on a par with, the current state-of-the-art for instance discrimination self-supervised learning approaches to audio representation learning. Code at https://github.com/jonahanton/SSL_audio.

</p>
</details>

<details><summary><b>A Closer Look at Evaluating the Bit-Flip Attack Against Deep Neural Networks</b>
<a href="https://arxiv.org/abs/2209.14243">arxiv:2209.14243</a>
&#x1F4C8; 4 <br>
<p>Kevin Hector, Mathieu Dumont, Pierre-Alain Moellic, Jean-Max Dutertre</p></summary>
<p>

**Abstract:** Deep neural network models are massively deployed on a wide variety of hardware platforms. This results in the appearance of new attack vectors that significantly extend the standard attack surface, extensively studied by the adversarial machine learning community. One of the first attack that aims at drastically dropping the performance of a model, by targeting its parameters (weights) stored in memory, is the Bit-Flip Attack (BFA). In this work, we point out several evaluation challenges related to the BFA. First of all, the lack of an adversary's budget in the standard threat model is problematic, especially when dealing with physical attacks. Moreover, since the BFA presents critical variability, we discuss the influence of some training parameters and the importance of the model architecture. This work is the first to present the impact of the BFA against fully-connected architectures that present different behaviors compared to convolutional neural networks. These results highlight the importance of defining robust and sound evaluation methodologies to properly evaluate the dangers of parameter-based attacks as well as measure the real level of robustness offered by a defense.

</p>
</details>

<details><summary><b>Online Subset Selection using $α$-Core with no Augmented Regret</b>
<a href="https://arxiv.org/abs/2209.14222">arxiv:2209.14222</a>
&#x1F4C8; 4 <br>
<p>Sourav Sahoo, Samrat Mukhopadhyay, Abhishek Sinha</p></summary>
<p>

**Abstract:** We consider the problem of sequential sparse subset selections in an online learning setup. Assume that the set $[N]$ consists of $N$ distinct elements. On the $t^{\text{th}}$ round, a monotone reward function $f_t: 2^{[N]} \to \mathbb{R}_+,$ which assigns a non-negative reward to each subset of $[N],$ is revealed to a learner. The learner selects (perhaps randomly) a subset $S_t \subseteq [N]$ of $k$ elements before the reward function $f_t$ for that round is revealed $(k \leq N)$. As a consequence of its choice, the learner receives a reward of $f_t(S_t)$ on the $t^{\text{th}}$ round. The learner's goal is to design an online subset selection policy to maximize its expected cumulative reward accrued over a given time horizon. In this connection, we propose an online learning policy called SCore (Subset Selection with Core) that solves the problem for a large class of reward functions. The proposed SCore policy is based on a new concept of $α$-Core, which is a generalization of the notion of Core from the cooperative game theory literature. We establish a learning guarantee for the SCore policy in terms of a new performance metric called $α$-augmented regret. In this new metric, the power of the offline benchmark is suitably augmented compared to the online policy. We give several illustrative examples to show that a broad class of reward functions, including submodular, can be efficiently learned with the SCore policy. We also outline how the SCore policy can be used under a semi-bandit feedback model and conclude the paper with a number of open problems.

</p>
</details>

<details><summary><b>Verifying Safety of Behaviour Trees in Event-B</b>
<a href="https://arxiv.org/abs/2209.14045">arxiv:2209.14045</a>
&#x1F4C8; 4 <br>
<p>Matteo Tadiello, Elena Troubitsyna</p></summary>
<p>

**Abstract:** Behavior Trees (BT) are becoming increasingly popular in the robotics community. The BT tool is well suited for decision-making applications allowing a robot to perform complex behavior while being explainable to humans as well. Verifying that BTs used are well constructed with respect to safety and reliability requirements is essential, especially for robots operating in critical environments. In this work, we propose a formal specification of Behavior Trees and a methodology to prove invariants of already used trees, while keeping the complexity of the formalization of the tree simple for the final user. Allowing the possibility to test the particular instance of the behavior tree without the necessity to know the more abstract levels of the formalization.

</p>
</details>

<details><summary><b>A Secure Federated Learning Framework for Residential Short Term Load Forecasting</b>
<a href="https://arxiv.org/abs/2209.14547">arxiv:2209.14547</a>
&#x1F4C8; 3 <br>
<p>Muhammad Akbar Husnoo, Adnan Anwar, Nasser Hosseinzadeh, Shama Naz Islam, Abdun Naser Mahmood, Robin Doss</p></summary>
<p>

**Abstract:** Smart meter measurements, though critical for accurate demand forecasting, face several drawbacks including consumers' privacy, data breach issues, to name a few. Recent literature has explored Federated Learning (FL) as a promising privacy-preserving machine learning alternative which enables collaborative learning of a model without exposing private raw data for short term load forecasting. Despite its virtue, standard FL is still vulnerable to an intractable cyber threat known as Byzantine attack carried out by faulty and/or malicious clients. Therefore, to improve the robustness of federated short-term load forecasting against Byzantine threats, we develop a state-of-the-art differentially private secured FL-based framework that ensures the privacy of the individual smart meter's data while protect the security of FL models and architecture. Our proposed framework leverages the idea of gradient quantization through the Sign Stochastic Gradient Descent (SignSGD) algorithm, where the clients only transmit the `sign' of the gradient to the control centre after local model training. As we highlight through our experiments involving benchmark neural networks with a set of Byzantine attack models, our proposed approach mitigates such threats quite effectively and thus outperforms conventional Fed-SGD models.

</p>
</details>

<details><summary><b>Semantics-Guided Object Removal for Facial Images: with Broad Applicability and Robust Style Preservation</b>
<a href="https://arxiv.org/abs/2209.14479">arxiv:2209.14479</a>
&#x1F4C8; 3 <br>
<p>Jookyung Song, Yeonjin Chang, Seonguk Park, Nojun Kwak</p></summary>
<p>

**Abstract:** Object removal and image inpainting in facial images is a task in which objects that occlude a facial image are specifically targeted, removed, and replaced by a properly reconstructed facial image. Two different approaches utilizing U-net and modulated generator respectively have been widely endorsed for this task for their unique advantages but notwithstanding each method's innate disadvantages. U-net, a conventional approach for conditional GANs, retains fine details of unmasked regions but the style of the reconstructed image is inconsistent with the rest of the original image and only works robustly when the size of the occluding object is small enough. In contrast, the modulated generative approach can deal with a larger occluded area in an image and provides {a} more consistent style, yet it usually misses out on most of the detailed features. This trade-off between these two models necessitates an invention of a model that can be applied to any size of mask while maintaining a consistent style and preserving minute details of facial features. Here, we propose Semantics-Guided Inpainting Network (SGIN) which itself is a modification of the modulated generator, aiming to take advantage of its advanced generative capability and preserve the high-fidelity details of the original image. By using the guidance of a semantic map, our model is capable of manipulating facial features which grants direction to the one-to-many problem for further practicability.

</p>
</details>

<details><summary><b>Machine Learning for Optical Motion Capture-driven Musculoskeletal Modeling from Inertial Motion Capture Data</b>
<a href="https://arxiv.org/abs/2209.14456">arxiv:2209.14456</a>
&#x1F4C8; 3 <br>
<p>Abhishek Dasgupta, Rahul Sharma, Challenger Mishra, Vikranth H. Nagaraja</p></summary>
<p>

**Abstract:** Marker-based Optical Motion Capture (OMC) systems and the associated musculoskeletal (MSK) modeling predictions have offered the ability to gain insights into in vivo joint and muscle loading non-invasively as well as aid clinical decision-making. However, an OMC system is lab-based, expensive, and requires a line of sight. A widely used alternative is the Inertial Motion Capture (IMC) system, which is portable, user-friendly, and relatively low cost, although it is not as accurate as an OMC system. Irrespective of the choice of motion capture technique, one needs to use an MSK model to obtain the kinematic and kinetic outputs, which is a computationally expensive tool increasingly well approximated by machine learning (ML) methods. Here, we present an ML approach to map IMC data to the human upper-extremity MSK outputs computed from OMC input data. Essentially, we attempt to predict high-quality MSK outputs from the relatively easier-to-obtain IMC data. We use OMC and IMC data simultaneously collected for the same subjects to train an ML (feed-forward multi-layer perceptron) model that predicts OMC-based MSK outputs from IMC measurements. We demonstrate that our ML predictions have a high degree of agreement with the desired OMC-based MSK estimates. Thus, this approach will be instrumental in getting the technology from 'lab to field' where OMC-based systems are infeasible.

</p>
</details>

<details><summary><b>CompNet: A Designated Model to Handle Combinations of Images and Designed features</b>
<a href="https://arxiv.org/abs/2209.14454">arxiv:2209.14454</a>
&#x1F4C8; 3 <br>
<p>Bowen Qiu, Daniela Raicu, Jacob Furst, Roselyne Tchoua</p></summary>
<p>

**Abstract:** Convolutional neural networks (CNNs) are one of the most popular models of Artificial Neural Networks (ANN)s in Computer Vision (CV). A variety of CNN-based structures were developed by researchers to solve problems like image classification, object detection, and image similarity measurement. Although CNNs have shown their value in most cases, they still have a downside: they easily overfit when there are not enough samples in the dataset. Most medical image datasets are examples of such a dataset. Additionally, many datasets also contain both designed features and images, but CNNs can only deal with images directly. This represents a missed opportunity to leverage additional information. For this reason, we propose a new structure of CNN-based model: CompNet, a composite convolutional neural network. This is a specially designed neural network that accepts combinations of images and designed features as input in order to leverage all available information. The novelty of this structure is that it uses learned features from images to weight designed features in order to gain all information from both images and designed features. With the use of this structure on classification tasks, the results indicate that our approach has the capability to significantly reduce overfitting. Furthermore, we also found several similar approaches proposed by other researchers that can combine images and designed features. To make comparison, we first applied those similar approaches on LIDC and compared the results with the CompNet results, then we applied our CompNet on the datasets that those similar approaches originally used in their works and compared the results with the results they proposed in their papers. All these comparison results showed that our model outperformed those similar approaches on classification tasks either on LIDC dataset or on their proposed datasets.

</p>
</details>

<details><summary><b>View-Invariant Localization using Semantic Objects in Changing Environments</b>
<a href="https://arxiv.org/abs/2209.14426">arxiv:2209.14426</a>
&#x1F4C8; 3 <br>
<p>Jacqueline Ankenbauer, Kaveh Fathian, Jonathan P. How</p></summary>
<p>

**Abstract:** This paper proposes a novel framework for real-time localization and egomotion tracking of a vehicle in a reference map. The core idea is to map the semantic objects observed by the vehicle and register them to their corresponding objects in the reference map. While several recent works have leveraged semantic information for cross-view localization, the main contribution of this work is a view-invariant formulation that makes the approach directly applicable to any viewpoint configuration for which objects are detectable. Another distinctive feature is robustness to changes in the environment/objects due to a data association scheme suited for extreme outlier regimes (e.g., 90% association outliers). To demonstrate our framework, we consider an example of localizing a ground vehicle in a reference object map using only cars as objects. While only a stereo camera is used for the ground vehicle, we consider reference maps constructed a priori from ground viewpoints using stereo cameras and Lidar scans, and georeferenced aerial images captured at a different date to demonstrate the framework's robustness to different modalities, viewpoints, and environment changes. Evaluations on the KITTI dataset show that over a 3.7 km trajectory, localization occurs in 36 sec and is followed by real-time egomotion tracking with an average position error of 8.5 m in a Lidar reference map, and on an aerial object map where 77% of objects are outliers, localization is achieved in 71 sec with an average position error of 7.9 m.

</p>
</details>

<details><summary><b>Variational Bayes for robust radar single object tracking</b>
<a href="https://arxiv.org/abs/2209.14397">arxiv:2209.14397</a>
&#x1F4C8; 3 <br>
<p>Alp Sarı, Tak Kaneko, Lense H. M. Swaenen, Wouter M. Kouw</p></summary>
<p>

**Abstract:** We address object tracking by radar and the robustness of the current state-of-the-art methods to process outliers. The standard tracking algorithms extract detections from radar image space to use it in the filtering stage. Filtering is performed by a Kalman filter, which assumes Gaussian distributed noise. However, this assumption does not account for large modeling errors and results in poor tracking performance during abrupt motions. We take the Gaussian Sum Filter (single-object variant of the Multi Hypothesis Tracker) as our baseline and propose a modification by modelling process noise with a distribution that has heavier tails than a Gaussian. Variational Bayes provides a fast, computationally cheap inference algorithm. Our simulations show that - in the presence of process outliers - the robust tracker outperforms the Gaussian Sum filter when tracking single objects.

</p>
</details>

<details><summary><b>Semantic Segmentation of Vegetation in Remote Sensing Imagery Using Deep Learning</b>
<a href="https://arxiv.org/abs/2209.14364">arxiv:2209.14364</a>
&#x1F4C8; 3 <br>
<p>Alexandru Munteanu, Marian Neagul</p></summary>
<p>

**Abstract:** In recent years, the geospatial industry has been developing at a steady pace. This growth implies the addition of satellite constellations that produce a copious supply of satellite imagery and other Remote Sensing data on a daily basis. Sometimes, this information, even if in some cases we are referring to publicly available data, it sits unaccounted for due to the sheer size of it. Processing such large amounts of data with the help of human labour or by using traditional automation methods is not always a viable solution from the standpoint of both time and other resources.
  Within the present work, we propose an approach for creating a multi-modal and spatio-temporal dataset comprised of publicly available Remote Sensing data and testing for feasibility using state of the art Machine Learning (ML) techniques. Precisely, the usage of Convolutional Neural Networks (CNN) models that are capable of separating different classes of vegetation that are present in the proposed dataset. Popularity and success of similar methods in the context of Geographical Information Systems (GIS) and Computer Vision (CV) more generally indicate that methods alike should be taken in consideration and further analysed and developed.

</p>
</details>

<details><summary><b>Less is More: Rethinking Few-Shot Learning and Recurrent Neural Nets</b>
<a href="https://arxiv.org/abs/2209.14267">arxiv:2209.14267</a>
&#x1F4C8; 3 <br>
<p>Deborah Pereg, Martin Villiger, Brett Bouma, Polina Golland</p></summary>
<p>

**Abstract:** The statistical supervised learning framework assumes an input-output set with a joint probability distribution that is reliably represented by the training dataset. The learner is then required to output a prediction rule learned from the training dataset's input-output pairs. In this work, we provide meaningful insights into the asymptotic equipartition property (AEP) \citep{Shannon:1948} in the context of machine learning, and illuminate some of its potential ramifications for few-shot learning. We provide theoretical guarantees for reliable learning under the information-theoretic AEP, and for the generalization error with respect to the sample size. We then focus on a highly efficient recurrent neural net (RNN) framework and propose a reduced-entropy algorithm for few-shot learning. We also propose a mathematical intuition for the RNN as an approximation of a sparse coding solver. We verify the applicability, robustness, and computational efficiency of the proposed approach with image deblurring and optical coherence tomography (OCT) speckle suppression. Our experimental results demonstrate significant potential for improving learning models' sample efficiency, generalization, and time complexity, that can therefore be leveraged for practical real-time applications.

</p>
</details>

<details><summary><b>Obstacle Identification and Ellipsoidal Decomposition for Fast Motion Planning in Unknown Dynamic Environments</b>
<a href="https://arxiv.org/abs/2209.14233">arxiv:2209.14233</a>
&#x1F4C8; 3 <br>
<p>Mehmetcan Kaymaz, Nazim Kemal Ure</p></summary>
<p>

**Abstract:** Collision avoidance in the presence of dynamic obstacles in unknown environments is one of the most critical challenges for unmanned systems. In this paper, we present a method that identifies obstacles in terms of ellipsoids to estimate linear and angular obstacle velocities. Our proposed method is based on the idea of any object can be approximately expressed by ellipsoids. To achieve this, we propose a method based on variational Bayesian estimation of Gaussian mixture model, the Kyachiyan algorithm, and a refinement algorithm. Our proposed method does not require knowledge of the number of clusters and can operate in real-time, unlike existing optimization-based methods. In addition, we define an ellipsoid-based feature vector to match obstacles given two timely close point frames. Our method can be applied to any environment with static and dynamic obstacles, including the ones with rotating obstacles. We compare our algorithm with other clustering methods and show that when coupled with a trajectory planner, the overall system can efficiently traverse unknown environments in the presence of dynamic obstacles.

</p>
</details>

<details><summary><b>Learning Filter-Based Compressed Blind-Deconvolution</b>
<a href="https://arxiv.org/abs/2209.14165">arxiv:2209.14165</a>
&#x1F4C8; 3 <br>
<p>Bahareh Tolooshams, Satish Mulleti, Demba Ba, Yonina C. Eldar</p></summary>
<p>

**Abstract:** The problem of sparse multichannel blind deconvolution (S-MBD) arises frequently in many engineering applications such as radar/sonar/ultrasound imaging. To reduce its computational and implementation cost, we propose a compression method that enables blind recovery from much fewer measurements with respect to the full received signal in time. The proposed compression measures the signal through a filter followed by a subsampling, allowing for a significant reduction in implementation cost. We derive theoretical guarantees for the identifiability and recovery of a sparse filter from compressed measurements. Our results allow for the design of a wide class of compression filters. We, then, propose a data-driven unrolled learning framework to learn the compression filter and solve the S-MBD problem. The encoder is a recurrent inference network that maps compressed measurements into an estimate of sparse filters. We demonstrate that our unrolled learning method is more robust to choices of source shapes and has better recovery performance compared to optimization-based methods. Finally, in applications with limited data (fewshot learning), we highlight the superior generalization capability of unrolled learning compared to conventional deep learning.

</p>
</details>

<details><summary><b>Deep learning for gradient flows using the Brezis-Ekeland principle</b>
<a href="https://arxiv.org/abs/2209.14115">arxiv:2209.14115</a>
&#x1F4C8; 3 <br>
<p>Laura Carini, Max Jensen, Robert Nürnberg</p></summary>
<p>

**Abstract:** We propose a deep learning method for the numerical solution of partial differential equations that arise as gradient flows. The method relies on the Brezis--Ekeland principle, which naturally defines an objective function to be minimized, and so is ideally suited for a machine learning approach using deep neural networks. We describe our approach in a general framework and illustrate the method with the help of an example implementation for the heat equation in space dimensions two to seven.

</p>
</details>

<details><summary><b>Cyclegan Network for Sheet Metal Welding Drawing Translation</b>
<a href="https://arxiv.org/abs/2209.14106">arxiv:2209.14106</a>
&#x1F4C8; 3 <br>
<p>Zhiwei Song, Hui Yao, Dan Tian, Gaohui Zhan</p></summary>
<p>

**Abstract:** In intelligent manufacturing, the quality of machine translation engineering drawings will directly affect its manufacturing accuracy. Currently, most of the work is manually translated, greatly reducing production efficiency. This paper proposes an automatic translation method for welded structural engineering drawings based on Cyclic Generative Adversarial Networks (CycleGAN). The CycleGAN network model of unpaired transfer learning is used to learn the feature mapping of real welding engineering drawings to realize automatic translation of engineering drawings. U-Net and PatchGAN are the main network for the generator and discriminator, respectively. Based on removing the identity mapping function, a high-dimensional sparse network is proposed to replace the traditional dense network for the Cyclegan generator to improve noise robustness. Increase the residual block hidden layer to increase the resolution of the generated graph. The improved and fine-tuned network models are experimentally validated, computing the gap between real and generated data. It meets the welding engineering precision standard and solves the main problem of low drawing recognition efficiency in the welding manufacturing process. The results show. After training with our model, the PSNR, SSIM and MSE of welding engineering drawings reach about 44.89%, 99.58% and 2.11, respectively, which are superior to traditional networks in both training speed and accuracy.

</p>
</details>

<details><summary><b>CSSAM: U-net Network for Application and Segmentation of Welding Engineering Drawings</b>
<a href="https://arxiv.org/abs/2209.14102">arxiv:2209.14102</a>
&#x1F4C8; 3 <br>
<p>Zhiwei Song, Hui Yao, Dan Tian, GaoHui Zhan</p></summary>
<p>

**Abstract:** Heavy equipment manufacturing splits specific contours in drawings and cuts sheet metal to scale for welding. Currently, most of the segmentation and extraction of weld map contours is achieved manually. Its efficiency is greatly reduced. Therefore, we propose a U-net-based contour segmentation and extraction method for welding engineering drawings. The contours of the parts required for engineering drawings can be automatically divided and blanked, which significantly improves manufacturing efficiency. U-net includes an encoder-decoder, which implements end-to-end mapping through semantic differences and spatial location feature information between the encoder and decoder. While U-net excels at segmenting medical images, our extensive experiments on the Welding Structural Diagram dataset show that the classic U-Net architecture falls short in segmenting welding engineering drawings. Therefore, we design a novel Channel Spatial Sequence Attention Module (CSSAM) and improve on the classic U-net. At the same time, vertical max pooling and average horizontal pooling are proposed. Pass the pooling operation through two equal convolutions into the CSSAM module. The output and the features before pooling are fused by semantic clustering, which replaces the traditional jump structure and effectively narrows the semantic gap between the encoder and the decoder, thereby improving the segmentation performance of welding engineering drawings. We use vgg16 as the backbone network. Compared with the classic U-net, our network has good performance in engineering drawing dataset segmentation.

</p>
</details>

<details><summary><b>Deepfake audio detection by speaker verification</b>
<a href="https://arxiv.org/abs/2209.14098">arxiv:2209.14098</a>
&#x1F4C8; 3 <br>
<p>Alessandro Pianese, Davide Cozzolino, Giovanni Poggi, Luisa Verdoliva</p></summary>
<p>

**Abstract:** Thanks to recent advances in deep learning, sophisticated generation tools exist, nowadays, that produce extremely realistic synthetic speech. However, malicious uses of such tools are possible and likely, posing a serious threat to our society. Hence, synthetic voice detection has become a pressing research topic, and a large variety of detection methods have been recently proposed. Unfortunately, they hardly generalize to synthetic audios generated by tools never seen in the training phase, which makes them unfit to face real-world scenarios. In this work, we aim at overcoming this issue by proposing a new detection approach that leverages only the biometric characteristics of the speaker, with no reference to specific manipulations. Since the detector is trained only on real data, generalization is automatically ensured. The proposed approach can be implemented based on off-the-shelf speaker verification tools. We test several such solutions on three popular test sets, obtaining good performance, high generalization ability, and high robustness to audio impairment.

</p>
</details>

<details><summary><b>Data Augmentation using Feature Generation for Volumetric Medical Images</b>
<a href="https://arxiv.org/abs/2209.14097">arxiv:2209.14097</a>
&#x1F4C8; 3 <br>
<p>Khushboo Mehra, Hassan Soliman, Soumya Ranjan Sahoo</p></summary>
<p>

**Abstract:** Medical image classification is one of the most critical problems in the image recognition area. One of the major challenges in this field is the scarcity of labelled training data. Additionally, there is often class imbalance in datasets as some cases are very rare to happen. As a result, accuracy in classification task is normally low. Deep Learning models, in particular, show promising results on image segmentation and classification problems, but they require very large datasets for training. Therefore, there is a need to generate more of synthetic samples from the same distribution. Previous work has shown that feature generation is more efficient and leads to better performance than corresponding image generation. We apply this idea in the Medical Imaging domain. We use transfer learning to train a segmentation model for the small dataset for which gold-standard class annotations are available. We extracted the learnt features and use them to generate synthetic features conditioned on class labels, using Auxiliary Classifier GAN (ACGAN). We test the quality of the generated features in a downstream classification task for brain tumors according to their severity level. Experimental results show a promising result regarding the validity of these generated features and their overall contribution to balancing the data and improving the classification class-wise accuracy.

</p>
</details>

<details><summary><b>Reinforcement Learning with Tensor Networks: Application to Dynamical Large Deviations</b>
<a href="https://arxiv.org/abs/2209.14089">arxiv:2209.14089</a>
&#x1F4C8; 3 <br>
<p>Edward Gillman, Dominic C. Rose, Juan P. Garrahan</p></summary>
<p>

**Abstract:** We present a framework to integrate tensor network (TN) methods with reinforcement learning (RL) for solving dynamical optimisation tasks. We consider the RL actor-critic method, a model-free approach for solving RL problems, and introduce TNs as the approximators for its policy and value functions. Our "actor-critic with tensor networks" (ACTeN) method is especially well suited to problems with large and factorisable state and action spaces. As an illustration of the applicability of ACTeN we solve the exponentially hard task of sampling rare trajectories in two paradigmatic stochastic models, the East model of glasses and the asymmetric simple exclusion process (ASEP), the latter being particularly challenging to other methods due to the absence of detailed balance. With substantial potential for further integration with the vast array of existing RL methods, the approach introduced here is promising both for applications in physics and to multi-agent RL problems more generally.

</p>
</details>

<details><summary><b>PTSD in the Wild: A Video Database for Studying Post-Traumatic Stress Disorder Recognition in Unconstrained Environments</b>
<a href="https://arxiv.org/abs/2209.14085">arxiv:2209.14085</a>
&#x1F4C8; 3 <br>
<p>Moctar Abdoul Latif Sawadogo, Furkan Pala, Gurkirat Singh, Imen Selmi, Pauline Puteaux, Alice Othmani</p></summary>
<p>

**Abstract:** POST-traumatic stress disorder (PTSD) is a chronic and debilitating mental condition that is developed in response to catastrophic life events, such as military combat, sexual assault, and natural disasters. PTSD is characterized by flashbacks of past traumatic events, intrusive thoughts, nightmares, hypervigilance, and sleep disturbance, all of which affect a person's life and lead to considerable social, occupational, and interpersonal dysfunction. The diagnosis of PTSD is done by medical professionals using self-assessment questionnaire of PTSD symptoms as defined in the Diagnostic and Statistical Manual of Mental Disorders (DSM). In this paper, and for the first time, we collected, annotated, and prepared for public distribution a new video database for automatic PTSD diagnosis, called PTSD in the wild dataset. The database exhibits "natural" and big variability in acquisition conditions with different pose, facial expression, lighting, focus, resolution, age, gender, race, occlusions and background. In addition to describing the details of the dataset collection, we provide a benchmark for evaluating computer vision and machine learning based approaches on PTSD in the wild dataset. In addition, we propose and we evaluate a deep learning based approach for PTSD detection in respect to the given benchmark. The proposed approach shows very promising results. Interested researcher can download a copy of PTSD-in-the wild dataset from: http://www.lissi.fr/PTSD-Dataset/

</p>
</details>

<details><summary><b>Backward Reachability Analysis of Neural Feedback Loops: Techniques for Linear and Nonlinear Systems</b>
<a href="https://arxiv.org/abs/2209.14076">arxiv:2209.14076</a>
&#x1F4C8; 3 <br>
<p>Nicholas Rober, Sydney M. Katz, Chelsea Sidrane, Esen Yel, Michael Everett, Mykel J. Kochenderfer, Jonathan P. How</p></summary>
<p>

**Abstract:** The increasing prevalence of neural networks (NNs) in safety-critical applications calls for methods to certify safe behavior. This paper presents a backward reachability approach for safety verification of neural feedback loops (NFLs), i.e., closed-loop systems with NN control policies. While recent works have focused on forward reachability as a strategy for safety certification of NFLs, backward reachability offers advantages over the forward strategy, particularly in obstacle avoidance scenarios. Prior works have developed techniques for backward reachability analysis for systems without NNs, but the presence of NNs in the feedback loop presents a unique set of problems due to the nonlinearities in their activation functions and because NN models are generally not invertible. To overcome these challenges, we use existing forward NN analysis tools to efficiently find an over-approximation of the backprojection (BP) set, i.e., the set of states for which the NN control policy will drive the system to a given target set. We present frameworks for calculating BP over-approximations for both linear and nonlinear systems with control policies represented by feedforward NNs and propose computationally efficient strategies. We use numerical results from a variety of models to showcase the proposed algorithms, including a demonstration of safety certification for a 6D system.

</p>
</details>

<details><summary><b>Recipro-CAM: Gradient-free reciprocal class activation map</b>
<a href="https://arxiv.org/abs/2209.14074">arxiv:2209.14074</a>
&#x1F4C8; 3 <br>
<p>Seok-Yong Byun, Wonju Lee</p></summary>
<p>

**Abstract:** Convolutional neural network (CNN) becomes one of the most popular and prominent deep learning architectures for computer vision, but its black box feature hides the internal prediction process. For this reason, AI practitioners have shed light on explainable AI to provide the interpretability of the model behavior. In particular, class activation map (CAM) and Grad-CAM based methods have shown promise results, but they have architectural limitation or gradient computing burden. To resolve these, Score-CAM has been suggested as a gradient-free method, however, it requires more execution time compared to CAM or Grad-CAM based methods. Therefore, we propose a lightweight architecture and gradient free Reciprocal CAM (Recipro-CAM) by spatially masking the extracted feature maps to exploit the correlation between activation maps and network outputs. With the proposed method, we achieved the gains of 1:78 - 3:72% in the ResNet family compared to Score-CAM in Average Drop- Coherence-Complexity (ADCC) metric, excluding the VGG-16 (1:39% drop). In addition, Recipro-CAM exhibits a saliency map generation rate similar to Grad-CAM and approximately 148 times faster than Score-CAM.

</p>
</details>

<details><summary><b>LL-GNN: Low Latency Graph Neural Networks on FPGAs for Particle Detectors</b>
<a href="https://arxiv.org/abs/2209.14065">arxiv:2209.14065</a>
&#x1F4C8; 3 <br>
<p>Zhiqiang Que, Marcus Loo, Hongxiang Fan, Michaela Blott, Maurizio Pierini, Alexander D Tapper, Wayne Luk</p></summary>
<p>

**Abstract:** This work proposes a novel reconfigurable architecture for low latency Graph Neural Network (GNN) design specifically for particle detectors. Accelerating GNNs for particle detectors is challenging since it requires sub-microsecond latency to deploy the networks for online event selection in the Level-1 triggers at the CERN Large Hadron Collider experiments. This paper proposes a custom code transformation with strength reduction for the matrix multiplication operations in the interaction-network based GNNs with fully connected graphs, which avoids the costly multiplication. It exploits sparsity patterns as well as binary adjacency matrices, and avoids irregular memory access, leading to a reduction in latency and improvement in hardware efficiency. In addition, we introduce an outer-product based matrix multiplication approach which is enhanced by the strength reduction for low latency design. Also, a fusion step is introduced to further reduce the design latency. Furthermore, an GNN-specific algorithm-hardware co-design approach is presented which not only finds a design with a much better latency but also finds a high accuracy design under a given latency constraint. Finally, a customizable template for this low latency GNN hardware architecture has been designed and open-sourced, which enables the generation of low-latency FPGA designs with efficient resource utilization using a high-level synthesis tool. Evaluation results show that our FPGA implementation is up to 24 times faster and consumes up to 45 times less power than a GPU implementation. Compared to our previous FPGA implementations, this work achieves 6.51 to 16.7 times lower latency. Moreover, the latency of our FPGA design is sufficiently low to enable deployment of GNNs in a sub-microsecond, real-time collider trigger system, enabling it to benefit from improved accuracy.

</p>
</details>

<details><summary><b>Medical Image Captioning via Generative Pretrained Transformers</b>
<a href="https://arxiv.org/abs/2209.13983">arxiv:2209.13983</a>
&#x1F4C8; 3 <br>
<p>Alexander Selivanov, Oleg Y. Rogov, Daniil Chesakov, Artem Shelmanov, Irina Fedulova, Dmitry V. Dylov</p></summary>
<p>

**Abstract:** The automatic clinical caption generation problem is referred to as proposed model combining the analysis of frontal chest X-Ray scans with structured patient information from the radiology records. We combine two language models, the Show-Attend-Tell and the GPT-3, to generate comprehensive and descriptive radiology records. The proposed combination of these models generates a textual summary with the essential information about pathologies found, their location, and the 2D heatmaps localizing each pathology on the original X-Ray scans. The proposed model is tested on two medical datasets, the Open-I, MIMIC-CXR, and the general-purpose MS-COCO. The results measured with the natural language assessment metrics prove their efficient applicability to the chest X-Ray image captioning.

</p>
</details>

<details><summary><b>Toward Certification of Machine-Learning Systems for Low Criticality Airborne Applications</b>
<a href="https://arxiv.org/abs/2209.13975">arxiv:2209.13975</a>
&#x1F4C8; 3 <br>
<p>K. Dmitriev, J. Schumann, F. Holzapfel</p></summary>
<p>

**Abstract:** The exceptional progress in the field of machine learning (ML) in recent years has attracted a lot of interest in using this technology in aviation. Possible airborne applications of ML include safety-critical functions, which must be developed in compliance with rigorous certification standards of the aviation industry. Current certification standards for the aviation industry were developed prior to the ML renaissance without taking specifics of ML technology into account. There are some fundamental incompatibilities between traditional design assurance approaches and certain aspects of ML-based systems. In this paper, we analyze the current airborne certification standards and show that all objectives of the standards can be achieved for a low-criticality ML-based system if certain assumptions about ML development workflow are applied.

</p>
</details>

<details><summary><b>Anomaly detection optimization using big data and deep learning to reduce false-positive</b>
<a href="https://arxiv.org/abs/2209.13965">arxiv:2209.13965</a>
&#x1F4C8; 3 <br>
<p>Khloud Al Jallad, Mohamad Aljnidi, Mohammad Said Desouki</p></summary>
<p>

**Abstract:** Anomaly-based Intrusion Detection System (IDS) has been a hot research topic because of its ability to detect new threats rather than only memorized signatures threats of signature-based IDS. Especially after the availability of advanced technologies that increase the number of hacking tools and increase the risk impact of an attack. The problem of any anomaly-based model is its high false-positive rate. The high false-positive rate is the reason why anomaly IDS is not commonly applied in practice. Because anomaly-based models classify an unseen pattern as a threat where it may be normal but not included in the training dataset. This type of problem is called overfitting where the model is not able to generalize. Optimizing Anomaly-based models by having a big training dataset that includes all possible normal cases may be an optimal solution but could not be applied in practice. Although we can increase the number of training samples to include much more normal cases, still we need a model that has more ability to generalize. In this research paper, we propose applying deep model instead of traditional models because it has more ability to generalize. Thus, we will obtain less false-positive by using big data and deep model. We made a comparison between machine learning and deep learning algorithms in the optimization of anomaly-based IDS by decreasing the false-positive rate. We did an experiment on the NSL-KDD benchmark and compared our results with one of the best used classifiers in traditional learning in IDS optimization. The experiment shows 10% lower false-positive by using deep learning instead of traditional learning.

</p>
</details>

<details><summary><b>quEEGNet: Quantum AI for Biosignal Processing</b>
<a href="https://arxiv.org/abs/2210.00864">arxiv:2210.00864</a>
&#x1F4C8; 2 <br>
<p>Toshiaki Koike-Akino, Ye Wang</p></summary>
<p>

**Abstract:** In this paper, we introduce an emerging quantum machine learning (QML) framework to assist classical deep learning methods for biosignal processing applications. Specifically, we propose a hybrid quantum-classical neural network model that integrates a variational quantum circuit (VQC) into a deep neural network (DNN) for electroencephalogram (EEG), electromyogram (EMG), and electrocorticogram (ECoG) analysis. We demonstrate that the proposed quantum neural network (QNN) achieves state-of-the-art performance while the number of trainable parameters is kept small for VQC.

</p>
</details>

<details><summary><b>Scheduling for Urban Air Mobility using Safe Learning</b>
<a href="https://arxiv.org/abs/2209.15457">arxiv:2209.15457</a>
&#x1F4C8; 2 <br>
<p>Surya Murthy, Natasha A. Neogi, Suda Bharadwaj</p></summary>
<p>

**Abstract:** This work considers the scheduling problem for Urban Air Mobility (UAM) vehicles travelling between origin-destination pairs with both hard and soft trip deadlines.  Each route is described by a discrete probability distribution over trip completion times (or delay) and over inter-arrival times of requests (or demand) for the route along with a fixed hard or soft deadline.  Soft deadlines carry a cost that is incurred when the deadline is missed.  An online, safe scheduler is developed that ensures that hard deadlines are never missed, and that average cost of missing soft deadlines is minimized.  The system is modelled as a Markov Decision Process (MDP) and safe model-based learning is used to find the probabilistic distributions over route delays and demand.  Monte Carlo Tree Search (MCTS) Earliest Deadline First (EDF) is used to safely explore the learned models in an online fashion and develop a near-optimal non-preemptive scheduling policy.  These results are compared with Value Iteration (VI) and MCTS (Random) scheduling solutions.

</p>
</details>

<details><summary><b>Non-contrastive approaches to similarity learning: positive examples are all you need</b>
<a href="https://arxiv.org/abs/2209.14750">arxiv:2209.14750</a>
&#x1F4C8; 2 <br>
<p>Alexander Marusov, Valerii Baianov, Alexey Zaytsev</p></summary>
<p>

**Abstract:** The similarity learning problem in the oil \& gas industry aims to construct a model that estimates similarity between interval measurements for logging data. Previous attempts are mostly based on empirical rules, so our goal is to automate this process and exclude expensive and time-consuming expert labelling.
  One of the approaches for similarity learning is self-supervised learning (SSL). In contrast to the supervised paradigm, this one requires little or no labels for the data. Thus, we can learn such models even if the data labelling is absent or scarce. Nowadays, most SSL approaches are contrastive and non-contrastive. However, due to possible wrong labelling of positive and negative samples, contrastive methods don't scale well with the number of objects. Non-contrastive methods don't rely on negative samples. Such approaches are actively used in the computer vision.
  We introduce non-contrastive SSL for time series data. In particular, we build on top of BYOL and Barlow Twins methods that avoid using negative pairs and focus only on matching positive pairs. The crucial part of these methods is an augmentation strategy. Different augmentations of time series exist, while their effect on the performance can be both positive and negative. Our augmentation strategies and adaption for BYOL and Barlow Twins together allow us to achieve a higher quality (ARI $= 0.49$) than other self-supervised methods (ARI $= 0.34$ only), proving usefulness of the proposed non-contrastive self-supervised approach for the interval similarity problem and time series representation learning in general.

</p>
</details>

<details><summary><b>NAF: Neural Attenuation Fields for Sparse-View CBCT Reconstruction</b>
<a href="https://arxiv.org/abs/2209.14540">arxiv:2209.14540</a>
&#x1F4C8; 2 <br>
<p>Ruyi Zha, Yanhao Zhang, Hongdong Li</p></summary>
<p>

**Abstract:** This paper proposes a novel and fast self-supervised solution for sparse-view CBCT reconstruction (Cone Beam Computed Tomography) that requires no external training data. Specifically, the desired attenuation coefficients are represented as a continuous function of 3D spatial coordinates, parameterized by a fully-connected deep neural network. We synthesize projections discretely and train the network by minimizing the error between real and synthesized projections. A learning-based encoder entailing hash coding is adopted to help the network capture high-frequency details. This encoder outperforms the commonly used frequency-domain encoder in terms of having higher performance and efficiency, because it exploits the smoothness and sparsity of human organs. Experiments have been conducted on both human organ and phantom datasets. The proposed method achieves state-of-the-art accuracy and spends reasonably short computation time.

</p>
</details>

<details><summary><b>Label driven Knowledge Distillation for Federated Learning with non-IID Data</b>
<a href="https://arxiv.org/abs/2209.14520">arxiv:2209.14520</a>
&#x1F4C8; 2 <br>
<p>Minh-Duong Nguyen, Quoc-Viet Pham, Dinh Thai Hoang, Long Tran-Thanh, Diep N. Nguyen, Won-Joo Hwang</p></summary>
<p>

**Abstract:** In real-world applications, Federated Learning (FL) meets two challenges: (1) scalability, especially when applied to massive IoT networks; and (2) how to be robust against an environment with heterogeneous data. Realizing the first problem, we aim to design a novel FL framework named Full-stack FL (F2L). More specifically, F2L utilizes a hierarchical network architecture, making extending the FL network accessible without reconstructing the whole network system. Moreover, leveraging the advantages of hierarchical network design, we propose a new label-driven knowledge distillation (LKD) technique at the global server to address the second problem. As opposed to current knowledge distillation techniques, LKD is capable of training a student model, which consists of good knowledge from all teachers' models. Therefore, our proposed algorithm can effectively extract the knowledge of the regions' data distribution (i.e., the regional aggregated models) to reduce the divergence between clients' models when operating under the FL system with non-independent identically distributed data. Extensive experiment results reveal that: (i) our F2L method can significantly improve the overall FL efficiency in all global distillations, and (ii) F2L rapidly achieves convergence as global distillation stages occur instead of increasing on each communication cycle.

</p>
</details>

<details><summary><b>On Quantum Speedups for Nonconvex Optimization via Quantum Tunneling Walks</b>
<a href="https://arxiv.org/abs/2209.14501">arxiv:2209.14501</a>
&#x1F4C8; 2 <br>
<p>Yizhou Liu, Weijie J. Su, Tongyang Li</p></summary>
<p>

**Abstract:** Classical algorithms are often not effective for solving nonconvex optimization problems where local minima are separated by high barriers. In this paper, we explore possible quantum speedups for nonconvex optimization by leveraging the global effect of quantum tunneling. Specifically, we introduce a quantum algorithm termed the quantum tunneling walk (QTW) and apply it to nonconvex problems where local minima are approximately global minima. We show that QTW achieves quantum speedup over classical stochastic gradient descents (SGD) when the barriers between different local minima are high but thin and the minima are flat. Based on this observation, we construct a specific double-well landscape, where classical algorithms cannot efficiently hit one target well knowing the other well but QTW can when given proper initial states near the known well. Finally, we corroborate our findings with numerical experiments.

</p>
</details>

<details><summary><b>Lazy Probabilistic Roadmaps Revisited</b>
<a href="https://arxiv.org/abs/2209.14471">arxiv:2209.14471</a>
&#x1F4C8; 2 <br>
<p>Miquel Ramirez, Daniel Selvaratnam, Chris Manzie</p></summary>
<p>

**Abstract:** This paper describes a revision of the classic Lazy Probabilistic Roadmaps algorithm (Lazy PRM), that results from pairing PRM and a novel Branch-and-Cut (BC) algorithm. Cuts are dynamically generated constraints that are imposed on minimum cost paths over the geometric graphs selected by PRM. Cuts eliminate paths that cannot be mapped into smooth plans that satisfy suitably defined kinematic constraints. We generate candidate smooth plans by fitting splines to vertices in minimum-cost path. Plans are validated with a recently proposed algorithm that maps them into finite traces, without need to choose a fixed discretization step. Trace elements exactly describe when plans cross constraint boundaries modulo arithmetic precision. We evaluate several planners using our methods over the recently proposed BARN benchmark, and we report evidence of the scalability of our approach.

</p>
</details>

<details><summary><b>Reducing Positional Variance in Cross-sectional Abdominal CT Slices with Deep Conditional Generative Models</b>
<a href="https://arxiv.org/abs/2209.14467">arxiv:2209.14467</a>
&#x1F4C8; 2 <br>
<p>Xin Yu, Qi Yang, Yucheng Tang, Riqiang Gao, Shunxing Bao, LeonY. Cai, Ho Hin Lee, Yuankai Huo, Ann Zenobia Moore, Luigi Ferrucci, Bennett A. Landman</p></summary>
<p>

**Abstract:** 2D low-dose single-slice abdominal computed tomography (CT) slice enables direct measurements of body composition, which are critical to quantitatively characterizing health relationships on aging. However, longitudinal analysis of body composition changes using 2D abdominal slices is challenging due to positional variance between longitudinal slices acquired in different years. To reduce the positional variance, we extend the conditional generative models to our C-SliceGen that takes an arbitrary axial slice in the abdominal region as the condition and generates a defined vertebral level slice by estimating the structural changes in the latent space. Experiments on 1170 subjects from an in-house dataset and 50 subjects from BTCV MICCAI Challenge 2015 show that our model can generate high quality images in terms of realism and similarity. External experiments on 20 subjects from the Baltimore Longitudinal Study of Aging (BLSA) dataset that contains longitudinal single abdominal slices validate that our method can harmonize the slice positional variance in terms of muscle and visceral fat area. Our approach provides a promising direction of mapping slices from different vertebral levels to a target slice to reduce positional variance for single slice longitudinal analysis. The source code is available at: https://github.com/MASILab/C-SliceGen.

</p>
</details>

<details><summary><b>Constrained Dynamic Movement Primitives for Safe Learning of Motor Skills</b>
<a href="https://arxiv.org/abs/2209.14461">arxiv:2209.14461</a>
&#x1F4C8; 2 <br>
<p>Seiji Shaw, Devesh K. Jha, Arvind Raghunathan, Radu Corcodel, Diego Romeres, George Konidaris, Daniel Nikovski</p></summary>
<p>

**Abstract:** Dynamic movement primitives are widely used for learning skills which can be demonstrated to a robot by a skilled human or controller. While their generalization capabilities and simple formulation make them very appealing to use, they possess no strong guarantees to satisfy operational safety constraints for a task. In this paper, we present constrained dynamic movement primitives (CDMP) which can allow for constraint satisfaction in the robot workspace. We present a formulation of a non-linear optimization to perturb the DMP forcing weights regressed by locally-weighted regression to admit a Zeroing Barrier Function (ZBF), which certifies workspace constraint satisfaction. We demonstrate the proposed CDMP under different constraints on the end-effector movement such as obstacle avoidance and workspace constraints on a physical robot. A video showing the implementation of the proposed algorithm using different manipulators in different environments could be found here https://youtu.be/hJegJJkJfys.

</p>
</details>

<details><summary><b>Masked Multi-Step Multivariate Time Series Forecasting with Future Information</b>
<a href="https://arxiv.org/abs/2209.14413">arxiv:2209.14413</a>
&#x1F4C8; 2 <br>
<p>Yiwei Fu, Honggang Wang, Nurali Virani</p></summary>
<p>

**Abstract:** In this paper, we introduce Masked Multi-Step Multivariate Forecasting (MMMF), a novel and general self-supervised learning framework for time series forecasting with known future information. In many real-world forecasting scenarios, some future information is known, e.g., the weather information when making a short-to-mid-term electricity demand forecast, or the oil price forecasts when making an airplane departure forecast. Existing machine learning forecasting frameworks can be categorized into (1) sample-based approaches where each forecast is made independently, and (2) time series regression approaches where the future information is not fully incorporated. To overcome the limitations of existing approaches, we propose MMMF, a framework to train any neural network model capable of generating a sequence of outputs, that combines both the temporal information from the past and the known information about the future to make better predictions. Experiments are performed on two real-world datasets for (1) mid-term electricity demand forecasting, and (2) two-month ahead flight departures forecasting. They show that the proposed MMMF framework outperforms not only sample-based methods but also existing time series forecasting models with the exact same base models. Furthermore, once a neural network model is trained with MMMF, its inference speed is similar to that of the same model trained with traditional regression formulations, thus making MMMF a better alternative to existing regression-trained time series forecasting models if there is some available future information.

</p>
</details>

<details><summary><b>Applying Machine Learning for Duplicate Detection, Throttling and Prioritization of Equipment Commissioning Audits at Fulfillment Network</b>
<a href="https://arxiv.org/abs/2209.14409">arxiv:2209.14409</a>
&#x1F4C8; 2 <br>
<p>Farouq Halawa, Majid Abdul, Raashid Mohammed</p></summary>
<p>

**Abstract:** VQ (Vendor Qualification) and IOQ (Installation and Operation Qualification) audits are implemented in warehouses to ensure all equipment being turned over in the fulfillment network meets the quality standards. Audit checks are likely to be skipped if there are many checks to be performed in a short time. In addition, exploratory data analysis reveals several instances of similar checks being performed on the same assets and thus, duplicating the effort. In this work, Natural Language Processing and Machine Learning are applied to trim a large checklist dataset for a network of warehouses by identifying similarities and duplicates, and predict the non-critical ones with a high passing rate. The study proposes ML classifiers to identify checks which have a high passing probability of IOQ and VQ and assign priorities to checks to be prioritized when the time is not available to perform all checks. This research proposes using NLP-based BlazingText classifier to throttle the checklists with a high passing rate, which can reduce 10%-37% of the checks and achieve significant cost reduction. The applied algorithm over performs Random Forest and Neural Network classifiers and achieves an area under the curve of 90%. Because of imbalanced data, down-sampling and upweighting have shown a positive impact on the models' accuracy using F1 score, which improve from 8% to 75%. In addition, the proposed duplicate detection process identifies 17% possible redundant checks to be trimmed.

</p>
</details>

<details><summary><b>Learning to Explain Graph Neural Networks</b>
<a href="https://arxiv.org/abs/2209.14402">arxiv:2209.14402</a>
&#x1F4C8; 2 <br>
<p>Giuseppe Serra, Mathias Niepert</p></summary>
<p>

**Abstract:** Graph Neural Networks (GNNs) are a popular class of machine learning models. Inspired by the learning to explain (L2X) paradigm, we propose L2XGNN, a framework for explainable GNNs which provides faithful explanations by design. L2XGNN learns a mechanism for selecting explanatory subgraphs (motifs) which are exclusively used in the GNNs message-passing operations. L2XGNN is able to select, for each input graph, a subgraph with specific properties such as being sparse and connected. Imposing such constraints on the motifs often leads to more interpretable and effective explanations. Experiments on several datasets suggest that L2XGNN achieves the same classification accuracy as baseline methods using the entire input graph while ensuring that only the provided explanations are used to make predictions. Moreover, we show that L2XGNN is able to identify motifs responsible for the graph's properties it is intended to predict.

</p>
</details>

<details><summary><b>Generalized Kernel Regularized Least Squares</b>
<a href="https://arxiv.org/abs/2209.14355">arxiv:2209.14355</a>
&#x1F4C8; 2 <br>
<p>Qing Chang, Max Goplerud</p></summary>
<p>

**Abstract:** Kernel Regularized Least Squares (KRLS) is a popular method for flexibly estimating models that may have complex relationships between variables. However, its usefulness to many researchers is limited for two reasons. First, existing approaches are inflexible and do not allow KRLS to be combined with theoretically-motivated extensions such as fixed effects or non-linear outcomes. Second, estimation is extremely computationally intensive for even modestly sized datasets.
  Our paper addresses both concerns by introducing generalized KRLS (gKRLS). We note that KRLS can be re-formulated as a hierarchical model thereby allowing easy inference and modular model construction. Computationally, we also implement random sketching to dramatically accelerate estimation while incurring a limited penalty in estimation quality. We demonstrate that gKRLS can be fit on datasets with tens of thousands of observations in under one minute. Further, state-of-the-art techniques that require fitting the model over a dozen times (e.g. meta-learners) can be estimated quickly.

</p>
</details>

<details><summary><b>Scalably learning quantum many-body Hamiltonians from dynamical data</b>
<a href="https://arxiv.org/abs/2209.14328">arxiv:2209.14328</a>
&#x1F4C8; 2 <br>
<p>Frederik Wilde, Augustine Kshetrimayum, Ingo Roth, Dominik Hangleiter, Ryan Sweke, Jens Eisert</p></summary>
<p>

**Abstract:** The physics of a closed quantum mechanical system is governed by its Hamiltonian. However, in most practical situations, this Hamiltonian is not precisely known, and ultimately all there is are data obtained from measurements on the system. In this work, we introduce a highly scalable, data-driven approach to learning families of interacting many-body Hamiltonians from dynamical data, by bringing together techniques from gradient-based optimization from machine learning with efficient quantum state representations in terms of tensor networks. Our approach is highly practical, experimentally friendly, and intrinsically scalable to allow for system sizes of above 100 spins. In particular, we demonstrate on synthetic data that the algorithm works even if one is restricted to one simple initial state, a small number of single-qubit observables, and time evolution up to relatively short times. For the concrete example of the one-dimensional Heisenberg model our algorithm exhibits an error constant in the system size and scaling as the inverse square root of the size of the data set.

</p>
</details>

<details><summary><b>Audio Retrieval with WavText5K and CLAP Training</b>
<a href="https://arxiv.org/abs/2209.14275">arxiv:2209.14275</a>
&#x1F4C8; 2 <br>
<p>Soham Deshmukh, Benjamin Elizalde, Huaming Wang</p></summary>
<p>

**Abstract:** Audio-Text retrieval takes a natural language query to retrieve relevant audio files in a database. Conversely, Text-Audio retrieval takes an audio file as a query to retrieve relevant natural language descriptions. Most of the literature train retrieval systems with one audio captioning dataset, but evaluating the benefit of training with multiple datasets is underexplored. Moreover, retrieval systems have to learn the alignment between elaborated sentences describing audio content of variable length ranging from a few seconds to several minutes. In this work, we propose a new collection of web audio-text pairs and a new framework for retrieval. First, we provide a new collection of about five thousand web audio-text pairs that we refer to as WavText5K. When used to train our retrieval system, WavText5K improved performance more than other audio captioning datasets. Second, our framework learns to connect language and audio content by using a text encoder, two audio encoders, and a contrastive learning objective. Combining both audio encoders helps to process variable length audio. The two contributions beat state of the art performance for AudioCaps and Clotho on Text-Audio retrieval by a relative 2% and 16%, and Audio-Text retrieval by 6% and 23%.

</p>
</details>

<details><summary><b>Programmable and Customized Intelligence for Traffic Steering in 5G Networks Using Open RAN Architectures</b>
<a href="https://arxiv.org/abs/2209.14171">arxiv:2209.14171</a>
&#x1F4C8; 2 <br>
<p>Andrea Lacava, Michele Polese, Rajarajan Sivaraj, Rahul Soundrarajan, Bhawani Shanker Bhati, Tarunjeet Singh, Tommaso Zugno, Francesca Cuomo, Tommaso Melodia</p></summary>
<p>

**Abstract:** 5G and beyond mobile networks will support heterogeneous use cases at an unprecedented scale, thus demanding automated control and optimization of network functionalities customized to the needs of individual users. Such fine-grained control of the Radio Access Network (RAN) is not possible with the current cellular architecture. To fill this gap, the Open RAN paradigm and its specification introduce an open architecture with abstractions that enable closed-loop control and provide data-driven, and intelligent optimization of the RAN at the user level. This is obtained through custom RAN control applications (i.e., xApps) deployed on near-real-time RAN Intelligent Controller (near-RT RIC) at the edge of the network. Despite these premises, as of today the research community lacks a sandbox to build data-driven xApps, and create large-scale datasets for effective AI training. In this paper, we address this by introducing ns-O-RAN, a software framework that integrates a real-world, production-grade near-RT RIC with a 3GPP-based simulated environment on ns-3, enabling the development of xApps and automated large-scale data collection and testing of Deep Reinforcement Learning-driven control policies for the optimization at the user-level. In addition, we propose the first user-specific O-RAN Traffic Steering (TS) intelligent handover framework. It uses Random Ensemble Mixture, combined with a state-of-the-art Convolutional Neural Network architecture, to optimally assign a serving base station to each user in the network. Our TS xApp, trained with more than 40 million data points collected by ns-O-RAN, runs on the near-RT RIC and controls its base stations. We evaluate the performance on a large-scale deployment, showing that the xApp-based handover improves throughput and spectral efficiency by an average of 50% over traditional handover heuristics, with less mobility overhead.

</p>
</details>

<details><summary><b>Machine Beats Machine: Machine Learning Models to Defend Against Adversarial Attacks</b>
<a href="https://arxiv.org/abs/2209.13963">arxiv:2209.13963</a>
&#x1F4C8; 2 <br>
<p>Jože M. Rožanec, Dimitrios Papamartzivanos, Entso Veliou, Theodora Anastasiou, Jelle Keizer, Blaž Fortuna, Dunja Mladenić</p></summary>
<p>

**Abstract:** We propose using a two-layered deployment of machine learning models to prevent adversarial attacks. The first layer determines whether the data was tampered, while the second layer solves a domain-specific problem. We explore three sets of features and three dataset variations to train machine learning models. Our results show clustering algorithms achieved promising results. In particular, we consider the best results were obtained by applying the DBSCAN algorithm to the structured structural similarity index measure computed between the images and a white reference image.

</p>
</details>

<details><summary><b>Big data analysis and distributed deep learning for next-generation intrusion detection system optimization</b>
<a href="https://arxiv.org/abs/2209.13961">arxiv:2209.13961</a>
&#x1F4C8; 2 <br>
<p>Khloud Al Jallad, Mohamad Aljnidi, Mohammad Said Desouki</p></summary>
<p>

**Abstract:** With the growing use of information technology in all life domains, hacking has become more negatively effective than ever before. Also with developing technologies, attacks numbers are growing exponentially every few months and become more sophisticated so that traditional IDS becomes inefficient detecting them. This paper proposes a solution to detect not only new threats with higher detection rate and lower false positive than already used IDS, but also it could detect collective and contextual security attacks. We achieve those results by using Networking Chatbot, a deep recurrent neural network: Long Short Term Memory (LSTM) on top of Apache Spark Framework that has an input of flow traffic and traffic aggregation and the output is a language of two words, normal or abnormal. We propose merging the concepts of language processing, contextual analysis, distributed deep learning, big data, anomaly detection of flow analysis. We propose a model that describes the network abstract normal behavior from a sequence of millions of packets within their context and analyzes them in near real-time to detect point, collective and contextual anomalies. Experiments are done on MAWI dataset, and it shows better detection rate not only than signature IDS, but also better than traditional anomaly IDS. The experiment shows lower false positive, higher detection rate and better point anomalies detection. As for prove of contextual and collective anomalies detection, we discuss our claim and the reason behind our hypothesis. But the experiment is done on random small subsets of the dataset because of hardware limitations, so we share experiment and our future vision thoughts as we wish that full prove will be done in future by other interested researchers who have better hardware infrastructure than ours.

</p>
</details>

<details><summary><b>Forecasting Sensor Values in Waste-To-Fuel Plants: a Case Study</b>
<a href="https://arxiv.org/abs/2209.13957">arxiv:2209.13957</a>
&#x1F4C8; 2 <br>
<p>Bor Brecelj, Beno Šircelj, Jože M. Rožanec, Blaž Fortuna, Dunja Mladenić</p></summary>
<p>

**Abstract:** In this research, we develop machine learning models to predict future sensor readings of a waste-to-fuel plant, which would enable proactive control of the plant's operations. We developed models that predict sensor readings for 30 and 60 minutes into the future. The models were trained using historical data, and predictions were made based on sensor readings taken at a specific time. We compare three types of models: (a) a näive prediction that considers only the last predicted value, (b) neural networks that make predictions based on past sensor data (we consider different time window sizes for making a prediction), and (c) a gradient boosted tree regressor created with a set of features that we developed. We developed and tested our models on a real-world use case at a waste-to-fuel plant in Canada. We found that approach (c) provided the best results, while approach (b) provided mixed results and was not able to outperform the näive consistently.

</p>
</details>

<details><summary><b>Deep Learning based Automatic Quantification of Urethral Plate Quality using the Plate Objective Scoring Tool (POST)</b>
<a href="https://arxiv.org/abs/2209.13848">arxiv:2209.13848</a>
&#x1F4C8; 2 <br>
<p>Tariq O. Abbas, Mohamed AbdelMoniem, Ibrahim Khalil, Md Sakib Abrar Hossain, Muhammad E. H. Chowdhury</p></summary>
<p>

**Abstract:** Objectives: To explore the capacity of deep learning algorithm to further streamline and optimize urethral plate (UP) quality appraisal on 2D images using the plate objective scoring tool (POST), aiming to increase the objectivity and reproducibility of UP appraisal in hypospadias repair. Methods: The five key POST landmarks were marked by specialists in a 691-image dataset of prepubertal boys undergoing primary hypospadias repair. This dataset was then used to develop and validate a deep learning-based landmark detection model. The proposed framework begins with glans localization and detection, where the input image is cropped using the predicted bounding box. Next, a deep convolutional neural network (CNN) architecture is used to predict the coordinates of the five POST landmarks. These predicted landmarks are then used to assess UP quality in distal hypospadias. Results: The proposed model accurately localized the glans area, with a mean average precision (mAP) of 99.5% and an overall sensitivity of 99.1%. A normalized mean error (NME) of 0.07152 was achieved in predicting the coordinates of the landmarks, with a mean squared error (MSE) of 0.001 and a 20.2% failure rate at a threshold of 0.1 NME. Conclusions: This deep learning application shows robustness and high precision in using POST to appraise UP quality. Further assessment using international multi-centre image-based databases is ongoing. External validation could benefit deep learning algorithms and lead to better assessments, decision-making and predictions for surgical outcomes.

</p>
</details>

<details><summary><b>Low-Stabilizer-Complexity Quantum States Are Not Pseudorandom</b>
<a href="https://arxiv.org/abs/2209.14530">arxiv:2209.14530</a>
&#x1F4C8; 1 <br>
<p>Sabee Grewal, Vishnu Iyer, William Kretschmer, Daniel Liang</p></summary>
<p>

**Abstract:** We show that quantum states with "low stabilizer complexity" can be efficiently distinguished from Haar-random. Specifically, given an $n$-qubit pure state $|ψ\rangle$, we give an efficient algorithm that distinguishes whether $|ψ\rangle$ is (i) Haar-random or (ii) a state with stabilizer fidelity at least $\frac{1}{k}$ (i.e., has fidelity at least $\frac{1}{k}$ with some stabilizer state), promised that one of these is the case. With black-box access to $|ψ\rangle$, our algorithm uses $O\!\left( k^{12} \log(1/δ)\right)$ copies of $|ψ\rangle$ and $O\!\left(n k^{12} \log(1/δ)\right)$ time to succeed with probability at least $1-δ$, and, with access to a state preparation unitary for $|ψ\rangle$ (and its inverse), $O\!\left( k^{3} \log(1/δ)\right)$ queries and $O\!\left(n k^{3} \log(1/δ)\right)$ time suffice.
  As a corollary, we prove that $ω(\log(n))$ $T$-gates are necessary for any Clifford+$T$ circuit to prepare computationally pseudorandom quantum states, a first-of-its-kind lower bound.

</p>
</details>

<details><summary><b>Parameterized Quantum Circuits with Quantum Kernels for Machine Learning: A Hybrid Quantum-Classical Approach</b>
<a href="https://arxiv.org/abs/2209.14449">arxiv:2209.14449</a>
&#x1F4C8; 1 <br>
<p>Daniel T. Chang</p></summary>
<p>

**Abstract:** Quantum machine learning (QML) is the use of quantum computing for the computation of machine learning algorithms. With the prevalence and importance of classical data, a hybrid quantum-classical approach to QML is called for. Parameterized Quantum Circuits (PQCs), and particularly Quantum Kernel PQCs, are generally used in the hybrid approach to QML. In this paper we discuss some important aspects of PQCs with quantum kernels including PQCs, quantum kernels, quantum kernels with quantum advantage, and the trainability of quantum kernels. We conclude that quantum kernels with hybrid kernel methods, a.k.a. quantum kernel methods, offer distinct advantages as a hybrid approach to QML. Not only do they apply to Noisy Intermediate-Scale Quantum (NISQ) devices, but they also can be used to solve all types of machine learning problems including regression, classification, clustering, and dimension reduction. Furthermore, beyond quantum utility, quantum advantage can be attained if the quantum kernels, i.e., the quantum feature encodings, are classically intractable.

</p>
</details>

<details><summary><b>FIRE: A Failure-Adaptive Reinforcement Learning Framework for Edge Computing Migrations</b>
<a href="https://arxiv.org/abs/2209.14399">arxiv:2209.14399</a>
&#x1F4C8; 1 <br>
<p>Marie Siew, Shikhar Sharma, Kun Guo, Chao Xu, Tony Q. S. Quek, Carlee Joe-Wong</p></summary>
<p>

**Abstract:** In edge computing, users' service profiles must be migrated in response to user mobility. Reinforcement learning (RL) frameworks have been proposed to do so. Nevertheless, these frameworks do not consider occasional server failures, which although rare, can prevent the smooth and safe functioning of edge computing users' latency sensitive applications such as autonomous driving and real-time obstacle detection, because users' computing jobs can no longer be completed. As these failures occur at a low probability, it is difficult for RL algorithms, which are inherently data-driven, to learn an optimal service migration solution for both the typical and rare event scenarios. Therefore, we introduce a rare events adaptive resilience framework FIRE, which integrates importance sampling into reinforcement learning to place backup services. We sample rare events at a rate proportional to their contribution to the value function, to learn an optimal policy. Our framework balances service migration trade-offs between delay and migration costs, with the costs of failure and the costs of backup placement and migration. We propose an importance sampling based Q-learning algorithm, and prove its boundedness and convergence to optimality. Following which we propose novel eligibility traces, linear function approximation and deep Q-learning versions of our algorithm to ensure it scales to real-world scenarios. We extend our framework to cater to users with different risk tolerances towards failure. Finally, we use trace driven experiments to show that our algorithm gives cost reductions in the event of failures.

</p>
</details>

<details><summary><b>A Review of Modern Approaches for Coronary Angiography Imaging Analysis</b>
<a href="https://arxiv.org/abs/2209.13997">arxiv:2209.13997</a>
&#x1F4C8; 1 <br>
<p>Maxim Popov, Temirgali Aimyshev, Eldar Ismailov, Ablay Bulegenov, Siamac Fazli</p></summary>
<p>

**Abstract:** Coronary Heart Disease (CHD) is a leading cause of death in the modern world. The development of modern analytical tools for diagnostics and treatment of CHD is receiving substantial attention from the scientific community. Deep learning-based algorithms, such as segmentation networks and detectors, play an important role in assisting medical professionals by providing timely analysis of a patient's angiograms. This paper focuses on X-Ray Coronary Angiography (XCA), which is considered to be a "gold standard" in the diagnosis and treatment of CHD. First, we describe publicly available datasets of XCA images. Then, classical and modern techniques of image preprocessing are reviewed. In addition, common frame selection techniques are discussed, which are an important factor of input quality and thus model performance. In the following two chapters we discuss modern vessel segmentation and stenosis detection networks and, finally, open problems and current limitations of the current state-of-the-art.

</p>
</details>

<details><summary><b>Multi-scale Attention Network for Single Image Super-Resolution</b>
<a href="https://arxiv.org/abs/2209.14145">arxiv:2209.14145</a>
&#x1F4C8; 0 <br>
<p>Yan Wang, Yusen Li, Gang Wang, Xiaoguang Liu</p></summary>
<p>

**Abstract:** By exploiting large kernel decomposition and attention mechanisms, convolutional neural networks (CNN) can compete with transformer-based methods in many high-level computer vision tasks. However, due to the advantage of long-range modeling, the transformers with self-attention still dominate the low-level vision, including the super-resolution task. In this paper, we propose a CNN-based multi-scale attention network (MAN), which consists of multi-scale large kernel attention (MLKA) and a gated spatial attention unit (GSAU), to improve the performance of convolutional SR networks. Within our MLKA, we rectify LKA with multi-scale and gate schemes to obtain the abundant attention map at various granularity levels, therefore jointly aggregating global and local information and avoiding the potential blocking artifacts. In GSAU, we integrate gate mechanism and spatial attention to remove the unnecessary linear layer and aggregate informative spatial context. To confirm the effectiveness of our designs, we evaluate MAN with multiple complexities by simply stacking different numbers of MLKA and GSAU. Experimental results illustrate that our MAN can achieve varied trade-offs between state-of-the-art performance and computations. Code is available at https://github.com/icandle/MAN.

</p>
</details>

<details><summary><b>Towards Automatic Forecasting: Evaluation of Time-Series Forecasting Models for Chickenpox Cases Estimation in Hungary</b>
<a href="https://arxiv.org/abs/2209.14129">arxiv:2209.14129</a>
&#x1F4C8; 0 <br>
<p>Wadie Skaf, Arzu Tosayeva, Dániel T. Várkonyi</p></summary>
<p>

**Abstract:** Time-Series Forecasting is a powerful data modeling discipline that analyzes historical observations to predict future values of a time-series. It has been utilized in numerous applications, including but not limited to economics, meteorology, and health. In this paper, we use time-series forecasting techniques to model and predict the future incidence of chickenpox. To achieve this, we implement and simulate multiple models and data preprocessing techniques on a Hungary-collected dataset. We demonstrate that the LSTM model outperforms all other models in the vast majority of the experiments in terms of county-level forecasting, whereas the SARIMAX model performs best at the national level. We also demonstrate that the performance of the traditional data preprocessing method is inferior to that of the data preprocessing method that we have proposed.

</p>
</details>

<details><summary><b>3D Neural Sculpting (3DNS): Editing Neural Signed Distance Functions</b>
<a href="https://arxiv.org/abs/2209.13971">arxiv:2209.13971</a>
&#x1F4C8; 0 <br>
<p>Petros Tzathas, Petros Maragos, Anastasios Roussos</p></summary>
<p>

**Abstract:** In recent years, implicit surface representations through neural networks that encode the signed distance have gained popularity and have achieved state-of-the-art results in various tasks (e.g. shape representation, shape reconstruction, and learning shape priors). However, in contrast to conventional shape representations such as polygon meshes, the implicit representations cannot be easily edited and existing works that attempt to address this problem are extremely limited. In this work, we propose the first method for efficient interactive editing of signed distance functions expressed through neural networks, allowing free-form editing. Inspired by 3D sculpting software for meshes, we use a brush-based framework that is intuitive and can in the future be used by sculptors and digital artists. In order to localize the desired surface deformations, we regulate the network by using a copy of it to sample the previously expressed surface. We introduce a novel framework for simulating sculpting-style surface edits, in conjunction with interactive surface sampling and efficient adaptation of network weights. We qualitatively and quantitatively evaluate our method in various different 3D objects and under many different edits. The reported results clearly show that our method yields high accuracy, in terms of achieving the desired edits, while at the same time preserving the geometry outside the interaction areas.

</p>
</details>

<details><summary><b>USEEK: Unsupervised SE(3)-Equivariant 3D Keypoints for Generalizable Manipulation</b>
<a href="https://arxiv.org/abs/2209.13864">arxiv:2209.13864</a>
&#x1F4C8; 0 <br>
<p>Zhengrong Xue, Zhecheng Yuan, Jiashun Wang, Xueqian Wang, Yang Gao, Huazhe Xu</p></summary>
<p>

**Abstract:** Can a robot manipulate intra-category unseen objects in arbitrary poses with the help of a mere demonstration of grasping pose on a single object instance? In this paper, we try to address this intriguing challenge by using USEEK, an unsupervised SE(3)-equivariant keypoints method that enjoys alignment across instances in a category, to perform generalizable manipulation. USEEK follows a teacher-student structure to decouple the unsupervised keypoint discovery and SE(3)-equivariant keypoint detection. With USEEK in hand, the robot can infer the category-level task-relevant object frames in an efficient and explainable manner, enabling manipulation of any intra-category objects from and to any poses. Through extensive experiments, we demonstrate that the keypoints produced by USEEK possess rich semantics, thus successfully transferring the functional knowledge from the demonstration object to the novel ones. Compared with other object representations for manipulation, USEEK is more adaptive in the face of large intra-category shape variance, more robust with limited demonstrations, and more efficient at inference time.

</p>
</details>


{% endraw %}
Prev: [2022.09.27]({{ '/2022/09/27/2022.09.27.html' | relative_url }})  Next: [2022.09.29]({{ '/2022/09/29/2022.09.29.html' | relative_url }})