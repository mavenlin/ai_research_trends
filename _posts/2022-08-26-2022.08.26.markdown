Prev: [2022.08.25]({{ '/2022/08/25/2022.08.25.html' | relative_url }})  Next: [2022.08.27]({{ '/2022/08/27/2022.08.27.html' | relative_url }})
{% raw %}
## Summary for 2022-08-26, created on 2022-08-30


<details><summary><b>Ab-initio quantum chemistry with neural-network wavefunctions</b>
<a href="https://arxiv.org/abs/2208.12590">arxiv:2208.12590</a>
&#x1F4C8; 3 <br>
<p>Jan Hermann, James Spencer, Kenny Choo, Antonio Mezzacapo, W. M. C. Foulkes, David Pfau, Giuseppe Carleo, Frank Noé</p></summary>
<p>

**Abstract:** Machine learning and specifically deep-learning methods have outperformed human capabilities in many pattern recognition and data processing problems, in game playing, and now also play an increasingly important role in scientific discovery. A key application of machine learning in the molecular sciences is to learn potential energy surfaces or force fields from ab-initio solutions of the electronic Schrödinger equation using datasets obtained with density functional theory, coupled cluster, or other quantum chemistry methods. Here we review a recent and complementary approach: using machine learning to aid the direct solution of quantum chemistry problems from first principles. Specifically, we focus on quantum Monte Carlo (QMC) methods that use neural network ansatz functions in order to solve the electronic Schrödinger equation, both in first and second quantization, computing ground and excited states, and generalizing over multiple nuclear configurations. Compared to existing quantum chemistry methods, these new deep QMC methods have the potential to generate highly accurate solutions of the Schrödinger equation at relatively modest computational cost.

</p>
</details>

<details><summary><b>Deep Hypergraph Structure Learning</b>
<a href="https://arxiv.org/abs/2208.12547">arxiv:2208.12547</a>
&#x1F4C8; 3 <br>
<p>Zizhao Zhang, Yifan Feng, Shihui Ying, Yue Gao</p></summary>
<p>

**Abstract:** Learning on high-order correlation has shown superiority in data representation learning, where hypergraph has been widely used in recent decades. The performance of hypergraph-based representation learning methods, such as hypergraph neural networks, highly depends on the quality of the hypergraph structure. How to generate the hypergraph structure among data is still a challenging task. Missing and noisy data may lead to "bad connections" in the hypergraph structure and destroy the hypergraph-based representation learning process. Therefore, revealing the high-order structure, i.e., the hypergraph behind the observed data, becomes an urgent but important task. To address this issue, we design a general paradigm of deep hypergraph structure learning, namely DeepHGSL, to optimize the hypergraph structure for hypergraph-based representation learning. Concretely, inspired by the information bottleneck principle for the robustness issue, we first extend it to the hypergraph case, named by the hypergraph information bottleneck (HIB) principle. Then, we apply this principle to guide the hypergraph structure learning, where the HIB is introduced to construct the loss function to minimize the noisy information in the hypergraph structure. The hypergraph structure can be optimized and this process can be regarded as enhancing the correct connections and weakening the wrong connections in the training phase. Therefore, the proposed method benefits to extract more robust representations even on a heavily noisy structure. Finally, we evaluate the model on four benchmark datasets for representation learning. The experimental results on both graph- and hypergraph-structured data demonstrate the effectiveness and robustness of our method compared with other state-of-the-art methods.

</p>
</details>

<details><summary><b>Mel Spectrogram Inversion with Stable Pitch</b>
<a href="https://arxiv.org/abs/2208.12782">arxiv:2208.12782</a>
&#x1F4C8; 2 <br>
<p>Bruno Di Giorgi, Mark Levy, Richard Sharp</p></summary>
<p>

**Abstract:** Vocoders are models capable of transforming a low-dimensional spectral representation of an audio signal, typically the mel spectrogram, to a waveform. Modern speech generation pipelines use a vocoder as their final component. Recent vocoder models developed for speech achieve a high degree of realism, such that it is natural to wonder how they would perform on music signals. Compared to speech, the heterogeneity and structure of the musical sound texture offers new challenges. In this work we focus on one specific artifact that some vocoder models designed for speech tend to exhibit when applied to music: the perceived instability of pitch when synthesizing sustained notes. We argue that the characteristic sound of this artifact is due to the lack of horizontal phase coherence, which is often the result of using a time-domain target space with a model that is invariant to time-shifts, such as a convolutional neural network. We propose a new vocoder model that is specifically designed for music. Key to improving the pitch stability is the choice of a shift-invariant target space that consists of the magnitude spectrum and the phase gradient. We discuss the reasons that inspired us to re-formulate the vocoder task, outline a working example, and evaluate it on musical signals. Our method results in 60% and 10% improved reconstruction of sustained notes and chords with respect to existing models, using a novel harmonic error metric.

</p>
</details>

<details><summary><b>NeuralSI: Structural Parameter Identification in Nonlinear Dynamical Systems</b>
<a href="https://arxiv.org/abs/2208.12771">arxiv:2208.12771</a>
&#x1F4C8; 2 <br>
<p>Xuyang Li, Hamed Bolandi, Talal Salem, Nizar Lajnef, Vishnu Naresh Boddeti</p></summary>
<p>

**Abstract:** Structural monitoring for complex built environments often suffers from mismatch between design, laboratory testing, and actual built parameters. Additionally, real-world structural identification problems encounter many challenges. For example, the lack of accurate baseline models, high dimensionality, and complex multivariate partial differential equations (PDEs) pose significant difficulties in training and learning conventional data-driven algorithms. This paper explores a new framework, dubbed NeuralSI, for structural identification by augmenting PDEs that govern structural dynamics with neural networks. Our approach seeks to estimate nonlinear parameters from governing equations. We consider the vibration of nonlinear beams with two unknown parameters, one that represents geometric and material variations, and another that captures energy losses in the system mainly through damping. The data for parameter estimation is obtained from a limited set of measurements, which is conducive to applications in structural health monitoring where the exact state of an existing structure is typically unknown and only a limited amount of data samples can be collected in the field. The trained model can also be extrapolated under both standard and extreme conditions using the identified structural parameters. We compare with pure data-driven Neural Networks and other classical Physics-Informed Neural Networks (PINNs). Our approach reduces both interpolation and extrapolation errors in displacement distribution by two to five orders of magnitude over the baselines. Code is available at https://github.com/human-analysis/neural-structural-identification

</p>
</details>

<details><summary><b>Causal Bandits for Linear Structural Equation Models</b>
<a href="https://arxiv.org/abs/2208.12764">arxiv:2208.12764</a>
&#x1F4C8; 2 <br>
<p>Burak Varici, Karthikeyan Shanmugam, Prasanna Sattigeri, Ali Tajer</p></summary>
<p>

**Abstract:** This paper studies the problem of designing an optimal sequence of interventions in a causal graphical model to minimize the cumulative regret with respect to the best intervention in hindsight. This is, naturally, posed as a causal bandit problem. The focus is on causal bandits for linear structural equation models (SEMs) and soft interventions. It is assumed that the graph's structure is known, and it has $N$ nodes. Two linear mechanisms, one soft intervention and one observational, are assumed for each node, giving rise to $2^N$ possible interventions. The existing causal bandit algorithms assume that at least the interventional distributions of the reward node's parents are fully specified. However, there are $2^N$ such distributions (one corresponding to each intervention), acquiring which becomes prohibitive even in moderate-sized graphs. This paper dispenses with the assumption of knowing these distributions. Two algorithms are proposed for the frequentist (UCB-based) and Bayesian (Thompson Sampling-based) settings. The key idea of these algorithms is to avoid directly estimating the $2^N$ reward distributions and instead estimate the parameters that fully specify the SEMs (linear in $N$) and use them to compute the rewards. In both algorithms, under boundedness assumptions on noise and the parameter space, the cumulative regrets scale as $\tilde{\cal O} ((2d)^L L \sqrt{T})$, where $d$ is the graph's maximum degree, and $L$ is the length of its longest causal path.

</p>
</details>

<details><summary><b>Take One Gram of Neural Features, Get Enhanced Group Robustness</b>
<a href="https://arxiv.org/abs/2208.12625">arxiv:2208.12625</a>
&#x1F4C8; 2 <br>
<p>Simon Roburin, Charles Corbière, Gilles Puy, Nicolas Thome, Matthieu Aubry, Renaud Marlet, Patrick Pérez</p></summary>
<p>

**Abstract:** Predictive performance of machine learning models trained with empirical risk minimization (ERM) can degrade considerably under distribution shifts. The presence of spurious correlations in training datasets leads ERM-trained models to display high loss when evaluated on minority groups not presenting such correlations. Extensive attempts have been made to develop methods improving worst-group robustness. However, they require group information for each training input or at least, a validation set with group labels to tune their hyperparameters, which may be expensive to get or unknown a priori. In this paper, we address the challenge of improving group robustness without group annotation during training or validation. To this end, we propose to partition the training dataset into groups based on Gram matrices of features extracted by an ``identification'' model and to apply robust optimization based on these pseudo-groups. In the realistic context where no group labels are available, our experiments show that our approach not only improves group robustness over ERM but also outperforms all recent baselines

</p>
</details>

<details><summary><b>On the Implicit Bias in Deep-Learning Algorithms</b>
<a href="https://arxiv.org/abs/2208.12591">arxiv:2208.12591</a>
&#x1F4C8; 2 <br>
<p>Gal Vardi</p></summary>
<p>

**Abstract:** Gradient-based deep-learning algorithms exhibit remarkable performance in practice, but it is not well-understood why they are able to generalize despite having more parameters than training examples. It is believed that implicit bias is a key factor in their ability to generalize, and hence it has been widely studied in recent years. In this short survey, we explain the notion of implicit bias, review main results and discuss their implications.

</p>
</details>

<details><summary><b>Large-N dynamics of the spiked tensor model with random initial conditions</b>
<a href="https://arxiv.org/abs/2208.12586">arxiv:2208.12586</a>
&#x1F4C8; 2 <br>
<p>Vasily Sazonov</p></summary>
<p>

**Abstract:** In these notes, we develop a path integral approach for the partial differential equations with random initial conditions. Then, we apply it to the dynamics of the spiked tensor model and show that the large-$N$ saddle point equations are dominated by the melonic type diagrams.

</p>
</details>

<details><summary><b>Constraining Gaussian Processes to Systems of Linear Ordinary Differential Equations</b>
<a href="https://arxiv.org/abs/2208.12515">arxiv:2208.12515</a>
&#x1F4C8; 2 <br>
<p>Andreas Besginow, Markus Lange-Hegermann</p></summary>
<p>

**Abstract:** Data in many applications follows systems of Ordinary Differential Equations (ODEs). This paper presents a novel algorithmic and symbolic construction for covariance functions of Gaussian Processes (GPs) with realizations strictly following a system of linear homogeneous ODEs with constant coefficients, which we call LODE-GPs. Introducing this strong inductive bias into a GP improves modelling of such data. Using smith normal form algorithms, a symbolic technique, we overcome two current restrictions in the state of the art: (1) the need for certain uniqueness conditions in the set of solutions, typically assumed in classical ODE solvers and their probabilistic counterparts, and (2) the restriction to controllable systems, typically assumed when encoding differential equations in covariance functions. We show the effectiveness of LODE-GPs in a number of experiments, for example learning physically interpretable parameters by maximizing the likelihood.

</p>
</details>

<details><summary><b>AiM: Taking Answers in Mind to Correct Chinese Cloze Tests in Educational Applications</b>
<a href="https://arxiv.org/abs/2208.12505">arxiv:2208.12505</a>
&#x1F4C8; 2 <br>
<p>Yusen Zhang, Zhongli Li, Qingyu Zhou, Ziyi Liu, Chao Li, Mina Ma, Yunbo Cao, Hongzhi Liu</p></summary>
<p>

**Abstract:** To automatically correct handwritten assignments, the traditional approach is to use an OCR model to recognize characters and compare them to answers. The OCR model easily gets confused on recognizing handwritten Chinese characters, and the textual information of the answers is missing during the model inference. However, teachers always have these answers in mind to review and correct assignments. In this paper, we focus on the Chinese cloze tests correction and propose a multimodal approach (named AiM). The encoded representations of answers interact with the visual information of students' handwriting. Instead of predicting 'right' or 'wrong', we perform the sequence labeling on the answer text to infer which answer character differs from the handwritten content in a fine-grained way. We take samples of OCR datasets as the positive samples for this task, and develop a negative sample augmentation method to scale up the training data. Experimental results show that AiM outperforms OCR-based methods by a large margin. Extensive studies demonstrate the effectiveness of our multimodal approach.

</p>
</details>

<details><summary><b>GRASP: Guiding model with RelAtional Semantics using Prompt</b>
<a href="https://arxiv.org/abs/2208.12494">arxiv:2208.12494</a>
&#x1F4C8; 2 <br>
<p>Junyoung Son, Jinsung Kim, Jungwoo Lim, Heuiseok Lim</p></summary>
<p>

**Abstract:** The dialogue-based relation extraction (DialogRE) task aims to predict the relations between argument pairs that appear in dialogue. Most previous studies utilize fine-tuning pre-trained language models (PLMs) only with extensive features to supplement the low information density of the dialogue by multiple speakers. To effectively exploit inherent knowledge of PLMs without extra layers and consider scattered semantic cues on the relation between the arguments, we propose a Guiding model with RelAtional Semantics using Prompt (GRASP). We adopt a prompt-based fine-tuning approach and capture relational semantic clues of a given dialogue with 1) an argument-aware prompt marker strategy and 2) the relational clue detection task. In the experiments, GRASP achieves state-of-the-art performance in terms of both F1 and F1c scores on a DialogRE dataset even though our method only leverages PLMs without adding any extra layers.

</p>
</details>

<details><summary><b>Cross-lingual Transfer Learning for Fake News Detector in a Low-Resource Language</b>
<a href="https://arxiv.org/abs/2208.12482">arxiv:2208.12482</a>
&#x1F4C8; 2 <br>
<p>Sangdo Han</p></summary>
<p>

**Abstract:** Development of methods to detect fake news (FN) in low-resource languages has been impeded by a lack of training data. In this study, we solve the problem by using only training data from a high-resource language. Our FN-detection system permitted this strategy by applying adversarial learning that transfers the detection knowledge through languages. To assist the knowledge transfer, our system judges the reliability of articles by exploiting source information, which is a cross-lingual feature that represents the credibility of the speaker. In experiments, our system got 3.71% higher accuracy than a system that uses a machine-translated training dataset. In addition, our suggested cross-lingual feature exploitation for fake news detection improved accuracy by 3.03%.

</p>
</details>

<details><summary><b>Confusion Matrices and Accuracy Statistics for Binary Classifiers Using Unlabeled Data: The Diagnostic Test Approach</b>
<a href="https://arxiv.org/abs/2208.12664">arxiv:2208.12664</a>
&#x1F4C8; 1 <br>
<p>Richard Evans</p></summary>
<p>

**Abstract:** Medical researchers have solved the problem of estimating the sensitivity and specificity of binary medical diagnostic tests without gold standard tests for comparison. That problem is the same as estimating confusion matrices for classifiers on unlabeled data. This article describes how to modify the diagnostic test solutions to estimate confusion matrices and accuracy statistics for supervised or unsupervised binary classifiers on unlabeled data.

</p>
</details>

<details><summary><b>Symbolic Explanation of Affinity-Based Reinforcement Learning Agents with Markov Models</b>
<a href="https://arxiv.org/abs/2208.12627">arxiv:2208.12627</a>
&#x1F4C8; 1 <br>
<p>Charl Maree, Christian W. Omlin</p></summary>
<p>

**Abstract:** The proliferation of artificial intelligence is increasingly dependent on model understanding. Understanding demands both an interpretation - a human reasoning about a model's behavior - and an explanation - a symbolic representation of the functioning of the model. Notwithstanding the imperative of transparency for safety, trust, and acceptance, the opacity of state-of-the-art reinforcement learning algorithms conceals the rudiments of their learned strategies. We have developed a policy regularization method that asserts the global intrinsic affinities of learned strategies. These affinities provide a means of reasoning about a policy's behavior, thus making it inherently interpretable. We have demonstrated our method in personalized prosperity management where individuals' spending behavior in time dictate their investment strategies, i.e. distinct spending personalities may have dissimilar associations with different investment classes. We now explain our model by reproducing the underlying prototypical policies with discretized Markov models. These global surrogates are symbolic representations of the prototypical policies.

</p>
</details>

<details><summary><b>Play with Emotion: Affect-Driven Reinforcement Learning</b>
<a href="https://arxiv.org/abs/2208.12622">arxiv:2208.12622</a>
&#x1F4C8; 1 <br>
<p>Matthew Barthet, Ahmed Khalifa, Antonios Liapis, Georgios N. Yannakakis</p></summary>
<p>

**Abstract:** This paper introduces a paradigm shift by viewing the task of affect modeling as a reinforcement learning (RL) process. According to the proposed paradigm, RL agents learn a policy (i.e. affective interaction) by attempting to maximize a set of rewards (i.e. behavioral and affective patterns) via their experience with their environment (i.e. context). Our hypothesis is that RL is an effective paradigm for interweaving affect elicitation and manifestation with behavioral and affective demonstrations. Importantly, our second hypothesis-building on Damasio's somatic marker hypothesis-is that emotion can be the facilitator of decision-making. We test our hypotheses in a racing game by training Go-Blend agents to model human demonstrations of arousal and behavior; Go-Blend is a modified version of the Go-Explore algorithm which has recently showcased supreme performance in hard exploration tasks. We first vary the arousal-based reward function and observe agents that can effectively display a palette of affect and behavioral patterns according to the specified reward. Then we use arousal-based state selection mechanisms in order to bias the strategies that Go-Blend explores. Our findings suggest that Go-Blend not only is an efficient affect modeling paradigm but, more importantly, affect-driven RL improves exploration and yields higher performing agents, validating Damasio's hypothesis in the domain of games.

</p>
</details>

<details><summary><b>I still know it's you! On Challenges in Anonymizing Source Code</b>
<a href="https://arxiv.org/abs/2208.12553">arxiv:2208.12553</a>
&#x1F4C8; 1 <br>
<p>Micha Horlboge, Erwin Quiring, Roland Meyer, Konrad Rieck</p></summary>
<p>

**Abstract:** The source code of a program not only defines its semantics but also contains subtle clues that can identify its author. Several studies have shown that these clues can be automatically extracted using machine learning and allow for determining a program's author among hundreds of programmers. This attribution poses a significant threat to developers of anti-censorship and privacy-enhancing technologies, as they become identifiable and may be prosecuted. An ideal protection from this threat would be the anonymization of source code. However, neither theoretical nor practical principles of such an anonymization have been explored so far.
  In this paper, we tackle this problem and develop a framework for reasoning about code anonymization. We prove that the task of generating a $k$-anonymous program -- a program that cannot be attributed to one of $k$ authors -- is not computable and thus a dead end for research. As a remedy, we introduce a relaxed concept called $k$-uncertainty, which enables us to measure the protection of developers. Based on this concept, we empirically study candidate techniques for anonymization, such as code normalization, coding style imitation, and code obfuscation. We find that none of the techniques provides sufficient protection when the attacker is aware of the anonymization. While we introduce an approach for removing remaining clues from the code, the main result of our work is negative: Anonymization of source code is a hard and open problem.

</p>
</details>

<details><summary><b>EGFR Mutation Prediction of Lung Biopsy Images using Deep Learning</b>
<a href="https://arxiv.org/abs/2208.12506">arxiv:2208.12506</a>
&#x1F4C8; 1 <br>
<p>Ravi Kant Gupta, Shivani Nandgaonkar, Nikhil Cherian Kurian, Swapnil Rane, Amit Sethi</p></summary>
<p>

**Abstract:** The standard diagnostic procedures for targeted therapies in lung cancer treatment involve histological subtyping and subsequent detection of key driver mutations, such as EGFR. Even though molecular profiling can uncover the driver mutation, the process is often expensive and time-consuming. Deep learning-oriented image analysis offers a more economical alternative for discovering driver mutations directly from whole slide images (WSIs). In this work, we used customized deep learning pipelines with weak supervision to identify the morphological correlates of EGFR mutation from hematoxylin and eosin-stained WSIs, in addition to detecting tumor and histologically subtyping it. We demonstrate the effectiveness of our pipeline by conducting rigorous experiments and ablation studies on two lung cancer datasets - TCGA and a private dataset from India. With our pipeline, we achieved an average area under the curve (AUC) of 0.964 for tumor detection, and 0.942 for histological subtyping between adenocarcinoma and squamous cell carcinoma on the TCGA dataset. For EGFR detection, we achieved an average AUC of 0.864 on the TCGA dataset and 0.783 on the dataset from India. Our key learning points include the following. Firstly, there is no particular advantage of using a feature extractor layers trained on histology, if one is going to fine-tune the feature extractor on the target dataset. Secondly, selecting patches with high cellularity, presumably capturing tumor regions, is not always helpful, as the sign of a disease class may be present in the tumor-adjacent stroma.

</p>
</details>

<details><summary><b>GHN-Q: Parameter Prediction for Unseen Quantized Convolutional Architectures via Graph Hypernetworks</b>
<a href="https://arxiv.org/abs/2208.12489">arxiv:2208.12489</a>
&#x1F4C8; 1 <br>
<p>Stone Yun, Alexander Wong</p></summary>
<p>

**Abstract:** Deep convolutional neural network (CNN) training via iterative optimization has had incredible success in finding optimal parameters. However, modern CNN architectures often contain millions of parameters. Thus, any given model for a single architecture resides in a massive parameter space. Models with similar loss could have drastically different characteristics such as adversarial robustness, generalizability, and quantization robustness. For deep learning on the edge, quantization robustness is often crucial. Finding a model that is quantization-robust can sometimes require significant efforts. Recent works using Graph Hypernetworks (GHN) have shown remarkable performance predicting high-performant parameters of varying CNN architectures. Inspired by these successes, we wonder if the graph representations of GHN-2 can be leveraged to predict quantization-robust parameters as well, which we call GHN-Q. We conduct the first-ever study exploring the use of graph hypernetworks for predicting parameters of unseen quantized CNN architectures. We focus on a reduced CNN search space and find that GHN-Q can in fact predict quantization-robust parameters for various 8-bit quantized CNNs. Decent quantized accuracies are observed even with 4-bit quantization despite GHN-Q not being trained on it. Quantized finetuning of GHN-Q at lower bitwidths may bring further improvements and is currently being explored.

</p>
</details>

<details><summary><b>Concept-Based Techniques for "Musicologist-friendly" Explanations in a Deep Music Classifier</b>
<a href="https://arxiv.org/abs/2208.12485">arxiv:2208.12485</a>
&#x1F4C8; 1 <br>
<p>Francesco Foscarin, Katharina Hoedt, Verena Praher, Arthur Flexer, Gerhard Widmer</p></summary>
<p>

**Abstract:** Current approaches for explaining deep learning systems applied to musical data provide results in a low-level feature space, e.g., by highlighting potentially relevant time-frequency bins in a spectrogram or time-pitch bins in a piano roll. This can be difficult to understand, particularly for musicologists without technical knowledge. To address this issue, we focus on more human-friendly explanations based on high-level musical concepts. Our research targets trained systems (post-hoc explanations) and explores two approaches: a supervised one, where the user can define a musical concept and test if it is relevant to the system; and an unsupervised one, where musical excerpts containing relevant concepts are automatically selected and given to the user for interpretation. We demonstrate both techniques on an existing symbolic composer classification system, showcase their potential, and highlight their intrinsic limitations.

</p>
</details>

<details><summary><b>Dynamic Regret of Online Markov Decision Processes</b>
<a href="https://arxiv.org/abs/2208.12483">arxiv:2208.12483</a>
&#x1F4C8; 1 <br>
<p>Peng Zhao, Long-Fei Li, Zhi-Hua Zhou</p></summary>
<p>

**Abstract:** We investigate online Markov Decision Processes (MDPs) with adversarially changing loss functions and known transitions. We choose dynamic regret as the performance measure, defined as the performance difference between the learner and any sequence of feasible changing policies. The measure is strictly stronger than the standard static regret that benchmarks the learner's performance with a fixed compared policy. We consider three foundational models of online MDPs, including episodic loop-free Stochastic Shortest Path (SSP), episodic SSP, and infinite-horizon MDPs. For these three models, we propose novel online ensemble algorithms and establish their dynamic regret guarantees respectively, in which the results for episodic (loop-free) SSP are provably minimax optimal in terms of time horizon and certain non-stationarity measure. Furthermore, when the online environments encountered by the learner are predictable, we design improved algorithms and achieve better dynamic regret bounds for the episodic (loop-free) SSP; and moreover, we demonstrate impossibility results for the infinite-horizon MDPs.

</p>
</details>

<details><summary><b>Exploiting Deep Reinforcement Learning for Edge Caching in Cell-Free Massive MIMO Systems</b>
<a href="https://arxiv.org/abs/2208.12453">arxiv:2208.12453</a>
&#x1F4C8; 1 <br>
<p>Yu Zhang, Shuaifei Chen, Jiayi Zhang</p></summary>
<p>

**Abstract:** Cell-free massive multiple-input-multiple-output is promising to meet the stringent quality-of-experience (QoE) requirements of railway wireless communications by coordinating many successional access points (APs) to serve the onboard users coherently. A key challenge is how to deliver the desired contents timely due to the radical changing propagation environment caused by the growing train speed. In this paper, we propose to proactively cache the likely-requesting contents at the upcoming APs which perform the coherent transmission to reduce end-to-end delay. A long-term QoE-maximization problem is formulated and two cache placement algorithms are proposed. One is based on heuristic convex optimization (HCO) and the other exploits deep reinforcement learning (DRL) with soft actor-critic (SAC). Compared to the conventional benchmark, numerical results show the advantage of our proposed algorithms on QoE and hit probability. With the advanced DRL model, SAC outperforms HCO on QoE by predicting the user requests accurately.

</p>
</details>

<details><summary><b>Algebraically Explainable Controllers: Decision Trees and Support Vector Machines Join Forces</b>
<a href="https://arxiv.org/abs/2208.12804">arxiv:2208.12804</a>
&#x1F4C8; 0 <br>
<p>Florian Jüngermann, Jan Křetínský, Maximilian Weininger</p></summary>
<p>

**Abstract:** Recently, decision trees (DT) have been used as an explainable representation of controllers (a.k.a. strategies, policies, schedulers). Although they are often very efficient and produce small and understandable controllers for discrete systems, complex continuous dynamics still pose a challenge. In particular, when the relationships between variables take more complex forms, such as polynomials, they cannot be obtained using the available DT learning procedures. In contrast, support vector machines provide a more powerful representation, capable of discovering many such relationships, but not in an explainable form. Therefore, we suggest to combine the two frameworks in order to obtain an understandable representation over richer, domain-relevant algebraic predicates. We demonstrate and evaluate the proposed method experimentally on established benchmarks.

</p>
</details>

<details><summary><b>Battery and Hydrogen Energy Storage Control in a Smart Energy Network with Flexible Energy Demand using Deep Reinforcement Learning</b>
<a href="https://arxiv.org/abs/2208.12779">arxiv:2208.12779</a>
&#x1F4C8; 0 <br>
<p>Cephas Samende, Zhong Fan, Jun Cao</p></summary>
<p>

**Abstract:** Smart energy networks provide for an effective means to accommodate high penetrations of variable renewable energy sources like solar and wind, which are key for deep decarbonisation of energy production. However, given the variability of the renewables as well as the energy demand, it is imperative to develop effective control and energy storage schemes to manage the variable energy generation and achieve desired system economics and environmental goals. In this paper, we introduce a hybrid energy storage system composed of battery and hydrogen energy storage to handle the uncertainties related to electricity prices, renewable energy production and consumption. We aim to improve renewable energy utilisation and minimise energy costs and carbon emissions while ensuring energy reliability and stability within the network. To achieve this, we propose a multi-agent deep deterministic policy gradient approach, which is a deep reinforcement learning-based control strategy to optimise the scheduling of the hybrid energy storage system and energy demand in real-time. The proposed approach is model-free and does not require explicit knowledge and rigorous mathematical models of the smart energy network environment. Simulation results based on real-world data show that: (i) integration and optimised operation of the hybrid energy storage system and energy demand reduces carbon emissions by 78.69%, improves cost savings by 23.5% and renewable energy utilisation by over 13.2% compared to other baseline models and (ii) the proposed algorithm outperforms the state-of-the-art self-learning algorithms like deep-Q network.

</p>
</details>

<details><summary><b>Prospect Theory-inspired Automated P2P Energy Trading with Q-learning-based Dynamic Pricing</b>
<a href="https://arxiv.org/abs/2208.12777">arxiv:2208.12777</a>
&#x1F4C8; 0 <br>
<p>Ashutosh Timilsina, Simone Silvestri</p></summary>
<p>

**Abstract:** The widespread adoption of distributed energy resources, and the advent of smart grid technologies, have allowed traditionally passive power system users to become actively involved in energy trading. Recognizing the fact that the traditional centralized grid-driven energy markets offer minimal profitability to these users, recent research has shifted focus towards decentralized peer-to-peer (P2P) energy markets. In these markets, users trade energy with each other, with higher benefits than buying or selling to the grid. However, most researches in P2P energy trading largely overlook the user perception in the trading process, assuming constant availability, participation, and full compliance. As a result, these approaches may result in negative attitudes and reduced engagement over time. In this paper, we design an automated P2P energy market that takes user perception into account. We employ prospect theory to model the user perception and formulate an optimization framework to maximize the buyer's perception while matching demand and production. Given the non-linear and non-convex nature of the optimization problem, we propose Differential Evolution-based Algorithm for Trading Energy called DEbATE. Additionally, we introduce a risk-sensitive Q-learning algorithm, named Pricing mechanism with Q-learning and Risk-sensitivity (PQR), which learns the optimal price for sellers considering their perceived utility. Results based on real traces of energy consumption and production, as well as realistic prospect theory functions, show that our approach achieves a 26% higher perceived value for buyers and generates 7% more reward for sellers, compared to a recent state of the art approach.

</p>
</details>

<details><summary><b>TFusion: Transformer based N-to-One Multimodal Fusion Block</b>
<a href="https://arxiv.org/abs/2208.12776">arxiv:2208.12776</a>
&#x1F4C8; 0 <br>
<p>Zecheng Liu, Jia Wei, Rui Li</p></summary>
<p>

**Abstract:** People perceive the world with different senses, such as sight, hearing, smell, and touch. Processing and fusing information from multiple modalities enables Artificial Intelligence to understand the world around us more easily. However, when there are missing modalities, the number of available modalities is different in diverse situations, which leads to an N-to-One fusion problem. To solve this problem, we propose a transformer based fusion block called TFusion. Different from preset formulations or convolution based methods, the proposed block automatically learns to fuse available modalities without synthesizing or zero-padding missing ones. Specifically, the feature representations extracted from upstream processing model are projected as tokens and fed into transformer layers to generate latent multimodal correlations. Then, to reduce the dependence on particular modalities, a modal attention mechanism is introduced to build a shared representation, which can be applied by the downstream decision model. The proposed TFusion block can be easily integrated into existing multimodal analysis networks. In this work, we apply TFusion to different backbone networks for multimodal human activity recognition and brain tumor segmentation tasks. Extensive experimental results show that the TFusion block achieves better performance than the competing fusion strategies.

</p>
</details>

<details><summary><b>Comparing Apples to Oranges: Learning Similarity Functions for Data Produced by Different Distributions</b>
<a href="https://arxiv.org/abs/2208.12731">arxiv:2208.12731</a>
&#x1F4C8; 0 <br>
<p>Leonidas Tsepenekas, Ivan Brugere</p></summary>
<p>

**Abstract:** Similarity functions measure how comparable pairs of elements are, and play a key role in a wide variety of applications, e.g., Clustering problems and considerations of Individual Fairness. However, access to an accurate similarity function should not always be considered guaranteed. Specifically, when the elements to be compared are produced by different distributions, or in other words belong to different ``demographic'' groups, knowledge of their true similarity might be very difficult to obtain. In this work, we present a sampling framework that learns these across-groups similarity functions, using only a limited amount of experts' feedback. We show analytical results with rigorous bounds, and empirically validate our algorithms via a large suite of experiments.

</p>
</details>

<details><summary><b>Generalizability of Code Clone Detection on CodeBERT</b>
<a href="https://arxiv.org/abs/2208.12588">arxiv:2208.12588</a>
&#x1F4C8; 0 <br>
<p>Tim Sonnekalb, Bernd Gruner, Clemens-Alexander Brust, Patrick Mäder</p></summary>
<p>

**Abstract:** Transformer networks such as CodeBERT already achieve outstanding results for code clone detection in benchmark datasets, so one could assume that this task has already been solved. However, code clone detection is not a trivial task. Semantic code clones, in particular, are challenging to detect. We show that the generalizability of CodeBERT decreases by evaluating two different subsets of Java code clones from BigCloneBench. We observe a significant drop in F1 score when we evaluate different code snippets and functionality IDs than those used for model building.

</p>
</details>

<details><summary><b>A Framework for Inherently Interpretable Optimization Models</b>
<a href="https://arxiv.org/abs/2208.12570">arxiv:2208.12570</a>
&#x1F4C8; 0 <br>
<p>Marc Goerigk, Michael Hartisch</p></summary>
<p>

**Abstract:** With dramatic improvements in optimization software, the solution of large-scale problems that seemed intractable decades ago are now a routine task. This puts even more real-world applications into the reach of optimizers. At the same time, solving optimization problems often turns out to be one of the smaller difficulties when putting solutions into practice. One major barrier is that the optimization software can be perceived as a black box, which may produce solutions of high quality, but can create completely different solutions when circumstances change leading to low acceptance of optimized solutions. Such issues of interpretability and explainability have seen significant attention in other areas, such as machine learning, but less so in optimization. In this paper we propose an optimization framework to derive solutions that inherently come with an easily comprehensible explanatory rule, under which circumstances which solution should be chosen. Focussing on decision trees to represent explanatory rules, we propose integer programming formulations as well as a heuristic method that ensure applicability of our approach even for large-scale problems. Computational experiments using random and real-world data indicate that the costs of inherent interpretability can be very small.

</p>
</details>

<details><summary><b>Semi-Supervised Disentanglement of Tactile Contact~Geometry from Sliding-Induced Shear</b>
<a href="https://arxiv.org/abs/2208.12500">arxiv:2208.12500</a>
&#x1F4C8; 0 <br>
<p>Anupam K. Gupta, Alex Church, Nathan F. Lepora</p></summary>
<p>

**Abstract:** The sense of touch is fundamental to human dexterity. When mimicked in robotic touch, particularly by use of soft optical tactile sensors, it suffers from distortion due to motion-dependent shear. This complicates tactile tasks like shape reconstruction and exploration that require information about contact geometry. In this work, we pursue a semi-supervised approach to remove shear while preserving contact-only information. We validate our approach by showing a match between the model-generated unsheared images with their counterparts from vertically tapping onto the object. The model-generated unsheared images give faithful reconstruction of contact-geometry otherwise masked by shear, along with robust estimation of object pose then used for sliding exploration and full reconstruction of several planar shapes. We show that our semi-supervised approach achieves comparable performance to its fully supervised counterpart across all validation tasks with an order of magnitude less supervision. The semi-supervised method is thus more computational and labeled sample-efficient. We expect it will have broad applicability to wide range of complex tactile exploration and manipulation tasks performed via a shear-sensitive sense of touch.

</p>
</details>

<details><summary><b>Deformation equivariant cross-modality image synthesis with paired non-aligned training data</b>
<a href="https://arxiv.org/abs/2208.12491">arxiv:2208.12491</a>
&#x1F4C8; 0 <br>
<p>Joel Honkamaa, Umair Khan, Sonja Koivukoski, Leena Latonen, Pekka Ruusuvuori, Pekka Marttinen</p></summary>
<p>

**Abstract:** Cross-modality image synthesis is an active research topic with multiple medical clinically relevant applications. Recently, methods allowing training with paired but misaligned data have started to emerge. However, no robust and well-performing methods applicable to a wide range of real world data sets exist. In this work, we propose a generic solution to the problem of cross-modality image synthesis with paired but non-aligned data by introducing new deformation equivariance encouraging loss functions. The method consists of joint training of an image synthesis network together with separate registration networks and allows adversarial training conditioned on the input even with misaligned data. The work lowers the bar for new clinical applications by allowing effortless training of cross-modality image synthesis networks for more difficult data sets and opens up opportunities for the development of new generic learning based cross-modality registration algorithms.

</p>
</details>

<details><summary><b>Laplacian Pyramid-like Autoencoder</b>
<a href="https://arxiv.org/abs/2208.12484">arxiv:2208.12484</a>
&#x1F4C8; 0 <br>
<p>Sangjun Han, Taeil Hur, Youngmi Hur</p></summary>
<p>

**Abstract:** In this paper, we develop the Laplacian pyramid-like autoencoder (LPAE) by adding the Laplacian pyramid (LP) concept widely used to analyze images in Signal Processing. LPAE decomposes an image into the approximation image and the detail image in the encoder part and then tries to reconstruct the original image in the decoder part using the two components. We use LPAE for experiments on classifications and super-resolution areas. Using the detail image and the smaller-sized approximation image as inputs of a classification network, our LPAE makes the model lighter. Moreover, we show that the performance of the connected classification networks has remained substantially high. In a super-resolution area, we show that the decoder part gets a high-quality reconstruction image by setting to resemble the structure of LP. Consequently, LPAE improves the original results by combining the decoder part of the autoencoder and the super-resolution network.

</p>
</details>

<details><summary><b>Nuclei & Glands Instance Segmentation in Histology Images: A Narrative Review</b>
<a href="https://arxiv.org/abs/2208.12460">arxiv:2208.12460</a>
&#x1F4C8; 0 <br>
<p>Esha Sadia Nasir, Arshi Perviaz, Muhammad Moazam Fraz</p></summary>
<p>

**Abstract:** Instance segmentation of nuclei and glands in the histology images is an important step in computational pathology workflow for cancer diagnosis, treatment planning and survival analysis. With the advent of modern hardware, the recent availability of large-scale quality public datasets and the community organized grand challenges have seen a surge in automated methods focusing on domain specific challenges, which is pivotal for technology advancements and clinical translation. In this survey, 126 papers illustrating the AI based methods for nuclei and glands instance segmentation published in the last five years (2017-2022) are deeply analyzed, the limitations of current approaches and the open challenges are discussed. Moreover, the potential future research direction is presented and the contribution of state-of-the-art methods is summarized. Further, a generalized summary of publicly available datasets and a detailed insights on the grand challenges illustrating the top performing methods specific to each challenge is also provided. Besides, we intended to give the reader current state of existing research and pointers to the future directions in developing methods that can be used in clinical practice enabling improved diagnosis, grading, prognosis, and treatment planning of cancer. To the best of our knowledge, no previous work has reviewed the instance segmentation in histology images focusing towards this direction.

</p>
</details>

<details><summary><b>Race and ethnicity data for first, middle, and last names</b>
<a href="https://arxiv.org/abs/2208.12443">arxiv:2208.12443</a>
&#x1F4C8; 0 <br>
<p>Evan T. R. Rosenman, Santiago Olivella, Kosuke Imai</p></summary>
<p>

**Abstract:** We provide the largest compiled publicly available dictionaries of first, middle, and last names for the purpose of imputing race and ethnicity using, for example, Bayesian Improved Surname Geocoding (BISG). The dictionaries are based on the voter files of six Southern states that collect self-reported racial data upon voter registration. Our data cover a much larger scope of names than any comparable dataset, containing roughly one million first names, 1.1 million middle names, and 1.4 million surnames. Individuals are categorized into five mutually exclusive racial and ethnic groups -- White, Black, Hispanic, Asian, and Other -- and racial/ethnic counts by name are provided for every name in each dictionary. Counts can then be normalized row-wise or column-wise to obtain conditional probabilities of race given name or name given race. These conditional probabilities can then be deployed for imputation in a data analytic task for which ground truth racial and ethnic data is not available.

</p>
</details>

<details><summary><b>Temporal Fuzzy Utility Maximization with Remaining Measure</b>
<a href="https://arxiv.org/abs/2208.12439">arxiv:2208.12439</a>
&#x1F4C8; 0 <br>
<p>Shicheng Wan, Zhenqiang Ye, Wensheng Gan, Jiahui Chen</p></summary>
<p>

**Abstract:** High utility itemset mining approaches discover hidden patterns from large amounts of temporal data. However, an inescapable problem of high utility itemset mining is that its discovered results hide the quantities of patterns, which causes poor interpretability. The results only reflect the shopping trends of customers, which cannot help decision makers quantify collected information. In linguistic terms, computers use mathematical or programming languages that are precisely formalized, but the language used by humans is always ambiguous. In this paper, we propose a novel one-phase temporal fuzzy utility itemset mining approach called TFUM. It revises temporal fuzzy-lists to maintain less but major information about potential high temporal fuzzy utility itemsets in memory, and then discovers a complete set of real interesting patterns in a short time. In particular, the remaining measure is the first adopted in the temporal fuzzy utility itemset mining domain in this paper. The remaining maximal temporal fuzzy utility is a tighter and stronger upper bound than that of previous studies adopted. Hence, it plays an important role in pruning the search space in TFUM. Finally, we also evaluate the efficiency and effectiveness of TFUM on various datasets. Extensive experimental results indicate that TFUM outperforms the state-of-the-art algorithms in terms of runtime cost, memory usage, and scalability. In addition, experiments prove that the remaining measure can significantly prune unnecessary candidates during mining.

</p>
</details>


{% endraw %}
Prev: [2022.08.25]({{ '/2022/08/25/2022.08.25.html' | relative_url }})  Next: [2022.08.27]({{ '/2022/08/27/2022.08.27.html' | relative_url }})