## Summary for 2021-10-27, created on 2021-12-14


<details><summary><b>VQ-GNN: A Universal Framework to Scale up Graph Neural Networks using Vector Quantization</b>
<a href="https://arxiv.org/abs/2110.14363">arxiv:2110.14363</a>
&#x1F4C8; 69 <br>
<p>Mucong Ding, Kezhi Kong, Jingling Li, Chen Zhu, John P Dickerson, Furong Huang, Tom Goldstein</p></summary>
<p>

**Abstract:** Most state-of-the-art Graph Neural Networks (GNNs) can be defined as a form of graph convolution which can be realized by message passing between direct neighbors or beyond. To scale such GNNs to large graphs, various neighbor-, layer-, or subgraph-sampling techniques are proposed to alleviate the "neighbor explosion" problem by considering only a small subset of messages passed to the nodes in a mini-batch. However, sampling-based methods are difficult to apply to GNNs that utilize many-hops-away or global context each layer, show unstable performance for different tasks and datasets, and do not speed up model inference. We propose a principled and fundamentally different approach, VQ-GNN, a universal framework to scale up any convolution-based GNNs using Vector Quantization (VQ) without compromising the performance. In contrast to sampling-based techniques, our approach can effectively preserve all the messages passed to a mini-batch of nodes by learning and updating a small number of quantized reference vectors of global node representations, using VQ within each GNN layer. Our framework avoids the "neighbor explosion" problem of GNNs using quantized representations combined with a low-rank version of the graph convolution matrix. We show that such a compact low-rank version of the gigantic convolution matrix is sufficient both theoretically and experimentally. In company with VQ, we design a novel approximated message passing algorithm and a nontrivial back-propagation rule for our framework. Experiments on various types of GNN backbones demonstrate the scalability and competitive performance of our framework on large-graph node classification and link prediction benchmarks.

</p>
</details>

<details><summary><b>Minimax Optimal Quantile and Semi-Adversarial Regret via Root-Logarithmic Regularizers</b>
<a href="https://arxiv.org/abs/2110.14804">arxiv:2110.14804</a>
&#x1F4C8; 45 <br>
<p>Jeffrey Negrea, Blair Bilodeau, Nicol√≤ Campolongo, Francesco Orabona, Daniel M. Roy</p></summary>
<p>

**Abstract:** Quantile (and, more generally, KL) regret bounds, such as those achieved by NormalHedge (Chaudhuri, Freund, and Hsu 2009) and its variants, relax the goal of competing against the best individual expert to only competing against a majority of experts on adversarial data. More recently, the semi-adversarial paradigm (Bilodeau, Negrea, and Roy 2020) provides an alternative relaxation of adversarial online learning by considering data that may be neither fully adversarial nor stochastic (i.i.d.). We achieve the minimax optimal regret in both paradigms using FTRL with separate, novel, root-logarithmic regularizers, both of which can be interpreted as yielding variants of NormalHedge. We extend existing KL regret upper bounds, which hold uniformly over target distributions, to possibly uncountable expert classes with arbitrary priors; provide the first full-information lower bounds for quantile regret on finite expert classes (which are tight); and provide an adaptively minimax optimal algorithm for the semi-adversarial paradigm that adapts to the true, unknown constraint faster, leading to uniformly improved regret bounds over existing methods.

</p>
</details>

<details><summary><b>A Survey of Self-Supervised and Few-Shot Object Detection</b>
<a href="https://arxiv.org/abs/2110.14711">arxiv:2110.14711</a>
&#x1F4C8; 43 <br>
<p>Gabriel Huang, Issam Laradji, David Vazquez, Simon Lacoste-Julien, Pau Rodriguez</p></summary>
<p>

**Abstract:** Labeling data is often expensive and time-consuming, especially for tasks such as object detection and instance segmentation, which require dense labeling of the image. While few-shot object detection is about training a model on novel (unseen) object classes with little data, it still requires prior training on many labeled examples of base (seen) classes. On the other hand, self-supervised methods aim at learning representations from unlabeled data which transfer well to downstream tasks such as object detection. Combining few-shot and self-supervised object detection is a promising research direction. In this survey, we review and characterize the most recent approaches on few-shot and self-supervised object detection. Then, we give our main takeaways and discuss future research directions. Project page at https://gabrielhuang.github.io/fsod-survey/

</p>
</details>

<details><summary><b>Large Scale Learning on Non-Homophilous Graphs: New Benchmarks and Strong Simple Methods</b>
<a href="https://arxiv.org/abs/2110.14446">arxiv:2110.14446</a>
&#x1F4C8; 43 <br>
<p>Derek Lim, Felix Hohne, Xiuyu Li, Sijia Linda Huang, Vaishnavi Gupta, Omkar Bhalerao, Ser-Nam Lim</p></summary>
<p>

**Abstract:** Many widely used datasets for graph machine learning tasks have generally been homophilous, where nodes with similar labels connect to each other. Recently, new Graph Neural Networks (GNNs) have been developed that move beyond the homophily regime; however, their evaluation has often been conducted on small graphs with limited application domains. We collect and introduce diverse non-homophilous datasets from a variety of application areas that have up to 384x more nodes and 1398x more edges than prior datasets. We further show that existing scalable graph learning and graph minibatching techniques lead to performance degradation on these non-homophilous datasets, thus highlighting the need for further work on scalable non-homophilous methods. To address these concerns, we introduce LINKX -- a strong simple method that admits straightforward minibatch training and inference. Extensive experimental results with representative simple methods and GNNs across our proposed datasets show that LINKX achieves state-of-the-art performance for learning on non-homophilous graphs. Our codes and data are available at https://github.com/CUAI/Non-Homophily-Large-Scale.

</p>
</details>

<details><summary><b>Feature selection revisited in the single-cell era</b>
<a href="https://arxiv.org/abs/2110.14329">arxiv:2110.14329</a>
&#x1F4C8; 29 <br>
<p>Pengyi Yang, Hao Huang, Chunlei Liu</p></summary>
<p>

**Abstract:** Feature selection techniques are essential for high-dimensional data analysis. In the last two decades, their popularity has been fuelled by the increasing availability of high-throughput biomolecular data where high-dimensionality is a common data property. Recent advances in biotechnologies enable global profiling of various molecular and cellular features at single-cell resolution, resulting in large-scale datasets with increased complexity. These technological developments have led to a resurgence in feature selection research and application in the single-cell field. Here, we revisit feature selection techniques and summarise recent developments. We review their versatile application to a range of single-cell data types including those generated from traditional cytometry and imaging technologies and the latest array of single-cell omics technologies. We highlight some of the challenges and future directions on which feature selection could have a significant impact. Finally, we consider the scalability and make general recommendations on the utility of each type of feature selection method. We hope this review serves as a reference point to stimulate future research and application of feature selection in the single-cell era.

</p>
</details>

<details><summary><b>Intermediate Layers Matter in Momentum Contrastive Self Supervised Learning</b>
<a href="https://arxiv.org/abs/2110.14805">arxiv:2110.14805</a>
&#x1F4C8; 28 <br>
<p>Aakash Kaku, Sahana Upadhya, Narges Razavian</p></summary>
<p>

**Abstract:** We show that bringing intermediate layers' representations of two augmented versions of an image closer together in self-supervised learning helps to improve the momentum contrastive (MoCo) method. To this end, in addition to the contrastive loss, we minimize the mean squared error between the intermediate layer representations or make their cross-correlation matrix closer to an identity matrix. Both loss objectives either outperform standard MoCo, or achieve similar performances on three diverse medical imaging datasets: NIH-Chest Xrays, Breast Cancer Histopathology, and Diabetic Retinopathy. The gains of the improved MoCo are especially large in a low-labeled data regime (e.g. 1% labeled data) with an average gain of 5% across three datasets. We analyze the models trained using our novel approach via feature similarity analysis and layer-wise probing. Our analysis reveals that models trained via our approach have higher feature reuse compared to a standard MoCo and learn informative features earlier in the network. Finally, by comparing the output probability distribution of models fine-tuned on small versus large labeled data, we conclude that our proposed method of pre-training leads to lower Kolmogorov-Smirnov distance, as compared to a standard MoCo. This provides additional evidence that our proposed method learns more informative features in the pre-training phase which could be leveraged in a low-labeled data regime.

</p>
</details>

<details><summary><b>Neural-PIL: Neural Pre-Integrated Lighting for Reflectance Decomposition</b>
<a href="https://arxiv.org/abs/2110.14373">arxiv:2110.14373</a>
&#x1F4C8; 27 <br>
<p>Mark Boss, Varun Jampani, Raphael Braun, Ce Liu, Jonathan T. Barron, Hendrik P. A. Lensch</p></summary>
<p>

**Abstract:** Decomposing a scene into its shape, reflectance and illumination is a fundamental problem in computer vision and graphics. Neural approaches such as NeRF have achieved remarkable success in view synthesis, but do not explicitly perform decomposition and instead operate exclusively on radiance (the product of reflectance and illumination). Extensions to NeRF, such as NeRD, can perform decomposition but struggle to accurately recover detailed illumination, thereby significantly limiting realism. We propose a novel reflectance decomposition network that can estimate shape, BRDF, and per-image illumination given a set of object images captured under varying illumination. Our key technique is a novel illumination integration network called Neural-PIL that replaces a costly illumination integral operation in the rendering with a simple network query. In addition, we also learn deep low-dimensional priors on BRDF and illumination representations using novel smooth manifold auto-encoders. Our decompositions can result in considerably better BRDF and light estimates enabling more accurate novel view-synthesis and relighting compared to prior art. Project page: https://markboss.me/publication/2021-neural-pil/

</p>
</details>

<details><summary><b>Learning Graph Cellular Automata</b>
<a href="https://arxiv.org/abs/2110.14237">arxiv:2110.14237</a>
&#x1F4C8; 25 <br>
<p>Daniele Grattarola, Lorenzo Livi, Cesare Alippi</p></summary>
<p>

**Abstract:** Cellular automata (CA) are a class of computational models that exhibit rich dynamics emerging from the local interaction of cells arranged in a regular lattice. In this work we focus on a generalised version of typical CA, called graph cellular automata (GCA), in which the lattice structure is replaced by an arbitrary graph. In particular, we extend previous work that used convolutional neural networks to learn the transition rule of conventional CA and we use graph neural networks to learn a variety of transition rules for GCA. First, we present a general-purpose architecture for learning GCA, and we show that it can represent any arbitrary GCA with finite and discrete state space. Then, we test our approach on three different tasks: 1) learning the transition rule of a GCA on a Voronoi tessellation; 2) imitating the behaviour of a group of flocking agents; 3) learning a rule that converges to a desired target state.

</p>
</details>

<details><summary><b>Beyond Classification: Knowledge Distillation using Multi-Object Impressions</b>
<a href="https://arxiv.org/abs/2110.14215">arxiv:2110.14215</a>
&#x1F4C8; 24 <br>
<p>Gaurav Kumar Nayak, Monish Keswani, Sharan Seshadri, Anirban Chakraborty</p></summary>
<p>

**Abstract:** Knowledge Distillation (KD) utilizes training data as a transfer set to transfer knowledge from a complex network (Teacher) to a smaller network (Student). Several works have recently identified many scenarios where the training data may not be available due to data privacy or sensitivity concerns and have proposed solutions under this restrictive constraint for the classification task. Unlike existing works, we, for the first time, solve a much more challenging problem, i.e., "KD for object detection with zero knowledge about the training data and its statistics". Our proposed approach prepares pseudo-targets and synthesizes corresponding samples (termed as "Multi-Object Impressions"), using only the pretrained Faster RCNN Teacher network. We use this pseudo-dataset as a transfer set to conduct zero-shot KD for object detection. We demonstrate the efficacy of our proposed method through several ablations and extensive experiments on benchmark datasets like KITTI, Pascal and COCO. Our approach with no training samples, achieves a respectable mAP of 64.2% and 55.5% on the student with same and half capacity while performing distillation from a Resnet-18 Teacher of 73.3% mAP on KITTI.

</p>
</details>

<details><summary><b>Dex-NeRF: Using a Neural Radiance Field to Grasp Transparent Objects</b>
<a href="https://arxiv.org/abs/2110.14217">arxiv:2110.14217</a>
&#x1F4C8; 19 <br>
<p>Jeffrey Ichnowski, Yahav Avigal, Justin Kerr, Ken Goldberg</p></summary>
<p>

**Abstract:** The ability to grasp and manipulate transparent objects is a major challenge for robots. Existing depth cameras have difficulty detecting, localizing, and inferring the geometry of such objects. We propose using neural radiance fields (NeRF) to detect, localize, and infer the geometry of transparent objects with sufficient accuracy to find and grasp them securely. We leverage NeRF's view-independent learned density, place lights to increase specular reflections, and perform a transparency-aware depth-rendering that we feed into the Dex-Net grasp planner. We show how additional lights create specular reflections that improve the quality of the depth map, and test a setup for a robot workcell equipped with an array of cameras to perform transparent object manipulation. We also create synthetic and real datasets of transparent objects in real-world settings, including singulated objects, cluttered tables, and the top rack of a dishwasher. In each setting we show that NeRF and Dex-Net are able to reliably compute robust grasps on transparent objects, achieving 90% and 100% grasp success rates in physical experiments on an ABB YuMi, on objects where baseline methods fail.

</p>
</details>

<details><summary><b>You Are the Best Reviewer of Your Own Papers: An Owner-Assisted Scoring Mechanism</b>
<a href="https://arxiv.org/abs/2110.14802">arxiv:2110.14802</a>
&#x1F4C8; 17 <br>
<p>Weijie J. Su</p></summary>
<p>

**Abstract:** I consider the setting where reviewers offer very noisy scores for a number of items for the selection of high-quality ones (e.g., peer review of large conference proceedings) whereas the owner of these items knows the true underlying scores but prefers not to provide this information. To address this withholding of information, in this paper, I introduce the \textit{Isotonic Mechanism}, a simple and efficient approach to improving on the imprecise raw scores by leveraging certain information that the owner is incentivized to provide. This mechanism takes as input the ranking of the items from best to worst provided by the owner, in addition to the raw scores provided by the reviewers. It reports adjusted scores for the items by solving a convex optimization problem. Under certain conditions, I show that the owner's optimal strategy is to honestly report the true ranking of the items to her best knowledge in order to maximize the expected utility. Moreover, I prove that the adjusted scores provided by this owner-assisted mechanism are indeed significantly more accurate than the raw scores provided by the reviewers. This paper concludes with several extensions of the Isotonic Mechanism and some refinements of the mechanism for practical considerations.

</p>
</details>

<details><summary><b>Towards a Theory of Evolution as Multilevel Learning</b>
<a href="https://arxiv.org/abs/2110.14602">arxiv:2110.14602</a>
&#x1F4C8; 10 <br>
<p>Vitaly Vanchurin, Yuri I. Wolf, Mikhail I. Katsnelson, Eugene V. Koonin</p></summary>
<p>

**Abstract:** We apply the theory of learning to physically renormalizable systems in an attempt to develop a theory of biological evolution, including the origin of life, as multilevel learning. We formulate seven fundamental principles of evolution that appear to be necessary and sufficient to render a universe observable and show that they entail the major features of biological evolution, including replication and natural selection. These principles also follow naturally from the theory of learning. We formulate the theory of evolution using the mathematical framework of neural networks, which provides for detailed analysis of evolutionary phenomena. To demonstrate the potential of the proposed theoretical framework, we derive a generalized version of the Central Dogma of molecular biology by analyzing the flow of information during learning (back-propagation) and predicting (forward-propagation) the environment by evolving organisms. The more complex evolutionary phenomena, such as major transitions in evolution, in particular, the origin of life, have to be analyzed in the thermodynamic limit, which is described in detail in the accompanying paper.

</p>
</details>

<details><summary><b>Latent Equilibrium: A unified learning theory for arbitrarily fast computation with arbitrarily slow neurons</b>
<a href="https://arxiv.org/abs/2110.14549">arxiv:2110.14549</a>
&#x1F4C8; 10 <br>
<p>Paul Haider, Benjamin Ellenberger, Laura Kriener, Jakob Jordan, Walter Senn, Mihai A. Petrovici</p></summary>
<p>

**Abstract:** The response time of physical computational elements is finite, and neurons are no exception. In hierarchical models of cortical networks each layer thus introduces a response lag. This inherent property of physical dynamical systems results in delayed processing of stimuli and causes a timing mismatch between network output and instructive signals, thus afflicting not only inference, but also learning. We introduce Latent Equilibrium, a new framework for inference and learning in networks of slow components which avoids these issues by harnessing the ability of biological neurons to phase-advance their output with respect to their membrane potential. This principle enables quasi-instantaneous inference independent of network depth and avoids the need for phased plasticity or computationally expensive network relaxation phases. We jointly derive disentangled neuron and synapse dynamics from a prospective energy function that depends on a network's generalized position and momentum. The resulting model can be interpreted as a biologically plausible approximation of error backpropagation in deep cortical networks with continuous-time, leaky neuronal dynamics and continuously active, local plasticity. We demonstrate successful learning of standard benchmark datasets, achieving competitive performance using both fully-connected and convolutional architectures, and show how our principle can be applied to detailed models of cortical microcircuitry. Furthermore, we study the robustness of our model to spatio-temporal substrate imperfections to demonstrate its feasibility for physical realization, be it in vivo or in silico.

</p>
</details>

<details><summary><b>Learning where to learn: Gradient sparsity in meta and continual learning</b>
<a href="https://arxiv.org/abs/2110.14402">arxiv:2110.14402</a>
&#x1F4C8; 10 <br>
<p>Johannes von Oswald, Dominic Zhao, Seijin Kobayashi, Simon Schug, Massimo Caccia, Nicolas Zucchet, Jo√£o Sacramento</p></summary>
<p>

**Abstract:** Finding neural network weights that generalize well from small datasets is difficult. A promising approach is to learn a weight initialization such that a small number of weight changes results in low generalization error. We show that this form of meta-learning can be improved by letting the learning algorithm decide which weights to change, i.e., by learning where to learn. We find that patterned sparsity emerges from this process, with the pattern of sparsity varying on a problem-by-problem basis. This selective sparsity results in better generalization and less interference in a range of few-shot and continual learning problems. Moreover, we find that sparse learning also emerges in a more expressive model where learning rates are meta-learned. Our results shed light on an ongoing debate on whether meta-learning can discover adaptable features and suggest that learning by sparse gradient descent is a powerful inductive bias for meta-learning systems.

</p>
</details>

<details><summary><b>Colossal-AI: A Unified Deep Learning System For Large-Scale Parallel Training</b>
<a href="https://arxiv.org/abs/2110.14883">arxiv:2110.14883</a>
&#x1F4C8; 9 <br>
<p>Zhengda Bian, Hongxin Liu, Boxiang Wang, Haichen Huang, Yongbin Li, Chuanrui Wang, Fan Cui, Yang You</p></summary>
<p>

**Abstract:** The Transformer architecture has improved the performance of deep learning models in domains such as Computer Vision and Natural Language Processing. Together with better performance come larger model sizes. This imposes challenges to the memory wall of the current accelerator hardware such as GPU. It is never ideal to train large models such as Vision Transformer, BERT, and GPT on a single GPU or a single machine. There is an urgent demand to train models in a distributed environment. However, distributed training, especially model parallelism, often requires domain expertise in computer systems and architecture. It remains a challenge for AI researchers to implement complex distributed training solutions for their models.
  In this paper, we introduce Colossal-AI, which is a unified parallel training system designed to seamlessly integrate different paradigms of parallelization techniques including data parallelism, pipeline parallelism, multiple tensor parallelism, and sequence parallelism. Colossal-AI aims to support the AI community to write distributed models in the same way as how they write models normally. This allows them to focus on developing the model architecture and separates the concerns of distributed training from the development process. The documentations can be found at https://www.colossalai.org and the source code can be found at https://github.com/hpcaitech/ColossalAI.

</p>
</details>

<details><summary><b>V2iFi: in-Vehicle Vital Sign Monitoring via Compact RF Sensing</b>
<a href="https://arxiv.org/abs/2110.14848">arxiv:2110.14848</a>
&#x1F4C8; 9 <br>
<p>Tianyue Zheng, Zhe Chen, Chao Cai, Jun Luo, Xu Zhang</p></summary>
<p>

**Abstract:** Given the significant amount of time people spend in vehicles, health issues under driving condition have become a major concern. Such issues may vary from fatigue, asthma, stroke, to even heart attack, yet they can be adequately indicated by vital signs and abnormal activities. Therefore, in-vehicle vital sign monitoring can help us predict and hence prevent these issues. Whereas existing sensor-based (including camera) methods could be used to detect these indicators, privacy concern and system complexity both call for a convenient yet effective and robust alternative. This paper aims to develop V2iFi, an intelligent system performing monitoring tasks using a COTS impulse radio mounted on the windshield. V2iFi is capable of reliably detecting driver's vital signs under driving condition and with the presence of passengers, thus allowing for potentially inferring corresponding health issues. Compared with prior work based on Wi-Fi CSI, V2iFi is able to distinguish reflected signals from multiple users, and hence provide finer-grained measurements under more realistic settings. We evaluate V2iFi both in lab environments and during real-life road tests; the results demonstrate that respiratory rate, heart rate, and heart rate variability can all be estimated accurately. Based on these estimation results, we further discuss how machine learning models can be applied on top of V2iFi so as to improve both physiological and psychological wellbeing in driving environments.

</p>
</details>

<details><summary><b>MedMNIST v2: A Large-Scale Lightweight Benchmark for 2D and 3D Biomedical Image Classification</b>
<a href="https://arxiv.org/abs/2110.14795">arxiv:2110.14795</a>
&#x1F4C8; 9 <br>
<p>Jiancheng Yang, Rui Shi, Donglai Wei, Zequan Liu, Lin Zhao, Bilian Ke, Hanspeter Pfister, Bingbing Ni</p></summary>
<p>

**Abstract:** We introduce MedMNIST v2, a large-scale MNIST-like dataset collection of standardized biomedical images, including 12 datasets for 2D and 6 datasets for 3D. All images are pre-processed into a small size of 28x28 (2D) or 28x28x28 (3D) with the corresponding classification labels so that no background knowledge is required for users. Covering primary data modalities in biomedical images, MedMNIST v2 is designed to perform classification on lightweight 2D and 3D images with various dataset scales (from 100 to 100,000) and diverse tasks (binary/multi-class, ordinal regression, and multi-label). The resulting dataset, consisting of 708,069 2D images and 10,214 3D images in total, could support numerous research / educational purposes in biomedical image analysis, computer vision, and machine learning. We benchmark several baseline methods on MedMNIST v2, including 2D / 3D neural networks and open-source / commercial AutoML tools. The data and code are publicly available at https://medmnist.com/.

</p>
</details>

<details><summary><b>Evidential Softmax for Sparse Multimodal Distributions in Deep Generative Models</b>
<a href="https://arxiv.org/abs/2110.14182">arxiv:2110.14182</a>
&#x1F4C8; 9 <br>
<p>Phil Chen, Masha Itkina, Ransalu Senanayake, Mykel J. Kochenderfer</p></summary>
<p>

**Abstract:** Many applications of generative models rely on the marginalization of their high-dimensional output probability distributions. Normalization functions that yield sparse probability distributions can make exact marginalization more computationally tractable. However, sparse normalization functions usually require alternative loss functions for training since the log-likelihood is undefined for sparse probability distributions. Furthermore, many sparse normalization functions often collapse the multimodality of distributions. In this work, we present $\textit{ev-softmax}$, a sparse normalization function that preserves the multimodality of probability distributions. We derive its properties, including its gradient in closed-form, and introduce a continuous family of approximations to $\textit{ev-softmax}$ that have full support and can be trained with probabilistic loss functions such as negative log-likelihood and Kullback-Leibler divergence. We evaluate our method on a variety of generative models, including variational autoencoders and auto-regressive architectures. Our method outperforms existing dense and sparse normalization techniques in distributional accuracy. We demonstrate that $\textit{ev-softmax}$ successfully reduces the dimensionality of probability distributions while maintaining multimodality.

</p>
</details>

<details><summary><b>Discovering Non-monotonic Autoregressive Orderings with Variational Inference</b>
<a href="https://arxiv.org/abs/2110.15797">arxiv:2110.15797</a>
&#x1F4C8; 8 <br>
<p>Xuanlin Li, Brandon Trabucco, Dong Huk Park, Michael Luo, Sheng Shen, Trevor Darrell, Yang Gao</p></summary>
<p>

**Abstract:** The predominant approach for language modeling is to process sequences from left to right, but this eliminates a source of information: the order by which the sequence was generated. One strategy to recover this information is to decode both the content and ordering of tokens. Existing approaches supervise content and ordering by designing problem-specific loss functions and pre-training with an ordering pre-selected. Other recent works use iterative search to discover problem-specific orderings for training, but suffer from high time complexity and cannot be efficiently parallelized. We address these limitations with an unsupervised parallelizable learner that discovers high-quality generation orders purely from training data -- no domain knowledge required. The learner contains an encoder network and decoder language model that perform variational inference with autoregressive orders (represented as permutation matrices) as latent variables. The corresponding ELBO is not differentiable, so we develop a practical algorithm for end-to-end optimization using policy gradients. We implement the encoder as a Transformer with non-causal attention that outputs permutations in one forward pass. Permutations then serve as target generation orders for training an insertion-based Transformer language model. Empirical results in language modeling tasks demonstrate that our method is context-aware and discovers orderings that are competitive with or even better than fixed orders.

</p>
</details>

<details><summary><b>Vector-valued Gaussian Processes on Riemannian Manifolds via Gauge Independent Projected Kernels</b>
<a href="https://arxiv.org/abs/2110.14423">arxiv:2110.14423</a>
&#x1F4C8; 8 <br>
<p>Michael Hutchinson, Alexander Terenin, Viacheslav Borovitskiy, So Takao, Yee Whye Teh, Marc Peter Deisenroth</p></summary>
<p>

**Abstract:** Gaussian processes are machine learning models capable of learning unknown functions in a way that represents uncertainty, thereby facilitating construction of optimal decision-making systems. Motivated by a desire to deploy Gaussian processes in novel areas of science, a rapidly-growing line of research has focused on constructively extending these models to handle non-Euclidean domains, including Riemannian manifolds, such as spheres and tori. We propose techniques that generalize this class to model vector fields on Riemannian manifolds, which are important in a number of application areas in the physical sciences. To do so, we present a general recipe for constructing gauge independent kernels, which induce Gaussian vector fields, i.e. vector-valued Gaussian processes coherent with geometry, from scalar-valued Riemannian kernels. We extend standard Gaussian process training methods, such as variational inference, to this setting. This enables vector-valued Gaussian processes on Riemannian manifolds to be trained using standard methods and makes them accessible to machine learning practitioners.

</p>
</details>

<details><summary><b>Iterative Teaching by Label Synthesis</b>
<a href="https://arxiv.org/abs/2110.14432">arxiv:2110.14432</a>
&#x1F4C8; 7 <br>
<p>Weiyang Liu, Zhen Liu, Hanchen Wang, Liam Paull, Bernhard Sch√∂lkopf, Adrian Weller</p></summary>
<p>

**Abstract:** In this paper, we consider the problem of iterative machine teaching, where a teacher provides examples sequentially based on the current iterative learner. In contrast to previous methods that have to scan over the entire pool and select teaching examples from it in each iteration, we propose a label synthesis teaching framework where the teacher randomly selects input teaching examples (e.g., images) and then synthesizes suitable outputs (e.g., labels) for them. We show that this framework can avoid costly example selection while still provably achieving exponential teachability. We propose multiple novel teaching algorithms in this framework. Finally, we empirically demonstrate the value of our framework.

</p>
</details>

<details><summary><b>Locally Differentially Private Bayesian Inference</b>
<a href="https://arxiv.org/abs/2110.14426">arxiv:2110.14426</a>
&#x1F4C8; 7 <br>
<p>Tejas Kulkarni, Joonas J√§lk√∂, Samuel Kaski, Antti Honkela</p></summary>
<p>

**Abstract:** In recent years, local differential privacy (LDP) has emerged as a technique of choice for privacy-preserving data collection in several scenarios when the aggregator is not trustworthy. LDP provides client-side privacy by adding noise at the user's end. Thus, clients need not rely on the trustworthiness of the aggregator.
  In this work, we provide a noise-aware probabilistic modeling framework, which allows Bayesian inference to take into account the noise added for privacy under LDP, conditioned on locally perturbed observations. Stronger privacy protection (compared to the central model) provided by LDP protocols comes at a much harsher privacy-utility trade-off. Our framework tackles several computational and statistical challenges posed by LDP for accurate uncertainty quantification under Bayesian settings. We demonstrate the efficacy of our framework in parameter estimation for univariate and multi-variate distributions as well as logistic and linear regression.

</p>
</details>

<details><summary><b>Perceptual Score: What Data Modalities Does Your Model Perceive?</b>
<a href="https://arxiv.org/abs/2110.14375">arxiv:2110.14375</a>
&#x1F4C8; 7 <br>
<p>Itai Gat, Idan Schwartz, Alexander Schwing</p></summary>
<p>

**Abstract:** Machine learning advances in the last decade have relied significantly on large-scale datasets that continue to grow in size. Increasingly, those datasets also contain different data modalities. However, large multi-modal datasets are hard to annotate, and annotations may contain biases that we are often unaware of. Deep-net-based classifiers, in turn, are prone to exploit those biases and to find shortcuts. To study and quantify this concern, we introduce the perceptual score, a metric that assesses the degree to which a model relies on the different subsets of the input features, i.e., modalities. Using the perceptual score, we find a surprisingly consistent trend across four popular datasets: recent, more accurate state-of-the-art multi-modal models for visual question-answering or visual dialog tend to perceive the visual data less than their predecessors. This trend is concerning as answers are hence increasingly inferred from textual cues only. Using the perceptual score also helps to analyze model biases by decomposing the score into data subset contributions. We hope to spur a discussion on the perceptiveness of multi-modal models and also hope to encourage the community working on multi-modal classifiers to start quantifying perceptiveness via the proposed perceptual score.

</p>
</details>

<details><summary><b>Ask "Who", Not "What": Bitcoin Volatility Forecasting with Twitter Data</b>
<a href="https://arxiv.org/abs/2110.14317">arxiv:2110.14317</a>
&#x1F4C8; 7 <br>
<p>M. Eren Akbiyik, Mert Erkul, Killian Kaempf, Vaiva Vasiliauskaite, Nino Antulov-Fantulin</p></summary>
<p>

**Abstract:** Understanding the variations in trading price (volatility), and its response to external information is a well-studied topic in finance. In this study, we focus on volatility predictions for a relatively new asset class of cryptocurrencies (in particular, Bitcoin) using deep learning representations of public social media data from Twitter. For the field work, we extracted semantic information and user interaction statistics from over 30 million Bitcoin-related tweets, in conjunction with 15-minute intraday price data over a 144-day horizon. Using this data, we built several deep learning architectures that utilized a combination of the gathered information. For all architectures, we conducted ablation studies to assess the influence of each component and feature set in our model. We found statistical evidences for the hypotheses that: (i) temporal convolutional networks perform significantly better than both autoregressive and other deep learning-based models in the literature, and (ii) the tweet author meta-information, even detached from the tweet itself, is a better predictor than the semantic content and tweet volume statistics.

</p>
</details>

<details><summary><b>A Sequence to Sequence Model for Extracting Multiple Product Name Entities from Dialog</b>
<a href="https://arxiv.org/abs/2110.14843">arxiv:2110.14843</a>
&#x1F4C8; 6 <br>
<p>Praneeth Gubbala, Xuan Zhang</p></summary>
<p>

**Abstract:** E-commerce voice ordering systems need to recognize multiple product name entities from ordering utterances. Existing voice ordering systems such as Amazon Alexa can capture only a single product name entity. This restrains users from ordering multiple items with one utterance. In recent years, pre-trained language models, e.g., BERT and GPT-2, have shown promising results on NLP benchmarks like Super-GLUE. However, they can't perfectly generalize to this Multiple Product Name Entity Recognition (MPNER) task due to the ambiguity in voice ordering utterances. To fill this research gap, we propose Entity Transformer (ET) neural network architectures which recognize up to 10 items in an utterance. In our evaluation, the best ET model (conveRT + ngram + ET) has a performance improvement of 12% on our test set compared to the non-neural model, and outperforms BERT with ET as well. This helps customers finalize their shopping cart via voice dialog, which improves shopping efficiency and experience.

</p>
</details>

<details><summary><b>Characterizing and Taming Resolution in Convolutional Neural Networks</b>
<a href="https://arxiv.org/abs/2110.14819">arxiv:2110.14819</a>
&#x1F4C8; 6 <br>
<p>Eddie Yan, Liang Luo, Luis Ceze</p></summary>
<p>

**Abstract:** Image resolution has a significant effect on the accuracy and computational, storage, and bandwidth costs of computer vision model inference. These costs are exacerbated when scaling out models to large inference serving systems and make image resolution an attractive target for optimization. However, the choice of resolution inherently introduces additional tightly coupled choices, such as image crop size, image detail, and compute kernel implementation that impact computational, storage, and bandwidth costs. Further complicating this setting, the optimal choices from the perspective of these metrics are highly dependent on the dataset and problem scenario. We characterize this tradeoff space, quantitatively studying the accuracy and efficiency tradeoff via systematic and automated tuning of image resolution, image quality and convolutional neural network operators. With the insights from this study, we propose a dynamic resolution mechanism that removes the need to statically choose a resolution ahead of time.

</p>
</details>

<details><summary><b>When is BERT Multilingual? Isolating Crucial Ingredients for Cross-lingual Transfer</b>
<a href="https://arxiv.org/abs/2110.14782">arxiv:2110.14782</a>
&#x1F4C8; 6 <br>
<p>Ameet Deshpande, Partha Talukdar, Karthik Narasimhan</p></summary>
<p>

**Abstract:** While recent work on multilingual language models has demonstrated their capacity for cross-lingual zero-shot transfer on downstream tasks, there is a lack of consensus in the community as to what shared properties between languages enable such transfer. Analyses involving pairs of natural languages are often inconclusive and contradictory since languages simultaneously differ in many linguistic aspects. In this paper, we perform a large-scale empirical study to isolate the effects of various linguistic properties by measuring zero-shot transfer between four diverse natural languages and their counterparts constructed by modifying aspects such as the script, word order, and syntax. Among other things, our experiments show that the absence of sub-word overlap significantly affects zero-shot transfer when languages differ in their word order, and there is a strong correlation between transfer performance and word embedding alignment between languages (e.g., R=0.94 on the task of NLI). Our results call for focus in multilingual models on explicitly improving word embedding alignment between languages rather than relying on its implicit emergence.

</p>
</details>

<details><summary><b>Detecting Dementia from Speech and Transcripts using Transformers</b>
<a href="https://arxiv.org/abs/2110.14769">arxiv:2110.14769</a>
&#x1F4C8; 6 <br>
<p>Loukas Ilias, Dimitris Askounis, John Psarras</p></summary>
<p>

**Abstract:** Alzheimer's disease (AD) constitutes a neurodegenerative disease with serious consequences to peoples' everyday lives, if it is not diagnosed early since there is no available cure. Because of the cost of examinations for diagnosing dementia, i.e., Magnetic Resonance Imaging (MRI), electroencephalogram (EEG) signals etc., current work has been focused on diagnosing dementia from spontaneous speech. However, little work has been done regarding the conversion of speech data to Log-Mel spectrograms and Mel-frequency cepstral coefficients (MFCCs) and the usage of pretrained models. Concurrently, little work has been done in terms of both the usage of transformer networks and the way the two modalities, i.e., speech and transcripts, are combined in a single neural network. To address these limitations, first we employ several pretrained models, with Vision Transformer (ViT) achieving the highest evaluation results. Secondly, we propose multimodal models. More specifically, our introduced models include Gated Multimodal Unit in order to control the influence of each modality towards the final classification and crossmodal attention so as to capture in an effective way the relationships between the two modalities. Extensive experiments conducted on the ADReSS Challenge dataset demonstrate the effectiveness of the proposed models and their superiority over state-of-the-art approaches.

</p>
</details>

<details><summary><b>Confidence-Aware Imitation Learning from Demonstrations with Varying Optimality</b>
<a href="https://arxiv.org/abs/2110.14754">arxiv:2110.14754</a>
&#x1F4C8; 6 <br>
<p>Songyuan Zhang, Zhangjie Cao, Dorsa Sadigh, Yanan Sui</p></summary>
<p>

**Abstract:** Most existing imitation learning approaches assume the demonstrations are drawn from experts who are optimal, but relaxing this assumption enables us to use a wider range of data. Standard imitation learning may learn a suboptimal policy from demonstrations with varying optimality. Prior works use confidence scores or rankings to capture beneficial information from demonstrations with varying optimality, but they suffer from many limitations, e.g., manually annotated confidence scores or high average optimality of demonstrations. In this paper, we propose a general framework to learn from demonstrations with varying optimality that jointly learns the confidence score and a well-performing policy. Our approach, Confidence-Aware Imitation Learning (CAIL) learns a well-performing policy from confidence-reweighted demonstrations, while using an outer loss to track the performance of our model and to learn the confidence. We provide theoretical guarantees on the convergence of CAIL and evaluate its performance in both simulated and real robot experiments. Our results show that CAIL significantly outperforms other imitation learning methods from demonstrations with varying optimality. We further show that even without access to any optimal demonstrations, CAIL can still learn a successful policy, and outperforms prior work.

</p>
</details>

<details><summary><b>Play to Grade: Testing Coding Games as Classifying Markov Decision Process</b>
<a href="https://arxiv.org/abs/2110.14615">arxiv:2110.14615</a>
&#x1F4C8; 6 <br>
<p>Allen Nie, Emma Brunskill, Chris Piech</p></summary>
<p>

**Abstract:** Contemporary coding education often presents students with the task of developing programs that have user interaction and complex dynamic systems, such as mouse based games. While pedagogically compelling, there are no contemporary autonomous methods for providing feedback. Notably, interactive programs are impossible to grade by traditional unit tests. In this paper we formalize the challenge of providing feedback to interactive programs as a task of classifying Markov Decision Processes (MDPs). Each student's program fully specifies an MDP where the agent needs to operate and decide, under reasonable generalization, if the dynamics and reward model of the input MDP should be categorized as correct or broken. We demonstrate that by designing a cooperative objective between an agent and an autoregressive model, we can use the agent to sample differential trajectories from the input MDP that allows a classifier to determine membership: Play to Grade. Our method enables an automatic feedback system for interactive code assignments. We release a dataset of 711,274 anonymized student submissions to a single assignment with hand-coded bug labels to support future research.

</p>
</details>

<details><summary><b>Neural Analysis and Synthesis: Reconstructing Speech from Self-Supervised Representations</b>
<a href="https://arxiv.org/abs/2110.14513">arxiv:2110.14513</a>
&#x1F4C8; 6 <br>
<p>Hyeong-Seok Choi, Juheon Lee, Wansoo Kim, Jie Hwan Lee, Hoon Heo, Kyogu Lee</p></summary>
<p>

**Abstract:** We present a neural analysis and synthesis (NANSY) framework that can manipulate voice, pitch, and speed of an arbitrary speech signal. Most of the previous works have focused on using information bottleneck to disentangle analysis features for controllable synthesis, which usually results in poor reconstruction quality. We address this issue by proposing a novel training strategy based on information perturbation. The idea is to perturb information in the original input signal (e.g., formant, pitch, and frequency response), thereby letting synthesis networks selectively take essential attributes to reconstruct the input signal. Because NANSY does not need any bottleneck structures, it enjoys both high reconstruction quality and controllability. Furthermore, NANSY does not require any labels associated with speech data such as text and speaker information, but rather uses a new set of analysis features, i.e., wav2vec feature and newly proposed pitch feature, Yingram, which allows for fully self-supervised training. Taking advantage of fully self-supervised training, NANSY can be easily extended to a multilingual setting by simply training it with a multilingual dataset. The experiments show that NANSY can achieve significant improvement in performance in several applications such as zero-shot voice conversion, pitch shift, and time-scale modification.

</p>
</details>

<details><summary><b>Training Lightweight CNNs for Human-Nanodrone Proximity Interaction from Small Datasets using Background Randomization</b>
<a href="https://arxiv.org/abs/2110.14491">arxiv:2110.14491</a>
&#x1F4C8; 6 <br>
<p>Marco Ferri, Dario Mantegazza, Elia Cereda, Nicky Zimmerman, Luca M. Gambardella, Daniele Palossi, J√©r√¥me Guzzi, Alessandro Giusti</p></summary>
<p>

**Abstract:** We consider the task of visually estimating the pose of a human from images acquired by a nearby nano-drone; in this context, we propose a data augmentation approach based on synthetic background substitution to learn a lightweight CNN model from a small real-world training set. Experimental results on data from two different labs proves that the approach improves generalization to unseen environments.

</p>
</details>

<details><summary><b>Online Selective Classification with Limited Feedback</b>
<a href="https://arxiv.org/abs/2110.14243">arxiv:2110.14243</a>
&#x1F4C8; 6 <br>
<p>Aditya Gangrade, Anil Kag, Ashok Cutkosky, Venkatesh Saligrama</p></summary>
<p>

**Abstract:** Motivated by applications to resource-limited and safety-critical domains, we study selective classification in the online learning model, wherein a predictor may abstain from classifying an instance. For example, this may model an adaptive decision to invoke more resources on this instance. Two salient aspects of the setting we consider are that the data may be non-realisable, due to which abstention may be a valid long-term action, and that feedback is only received when the learner abstains, which models the fact that reliable labels are only available when the resource intensive processing is invoked.
  Within this framework, we explore strategies that make few mistakes, while not abstaining too many times more than the best-in-hindsight error-free classifier from a given class. That is, the one that makes no mistakes, while abstaining the fewest number of times. We construct simple versioning-based schemes for any $Œº\in (0,1],$ that make most $T^Œº$ mistakes while incurring \smash{$\tilde{O}(T^{1-Œº})$} excess abstention against adaptive adversaries. We further show that this dependence on $T$ is tight, and provide illustrative experiments on realistic datasets.

</p>
</details>

<details><summary><b>Dynamic population-based meta-learning for multi-agent communication with natural language</b>
<a href="https://arxiv.org/abs/2110.14241">arxiv:2110.14241</a>
&#x1F4C8; 6 <br>
<p>Abhinav Gupta, Marc Lanctot, Angeliki Lazaridou</p></summary>
<p>

**Abstract:** In this work, our goal is to train agents that can coordinate with seen, unseen as well as human partners in a multi-agent communication environment involving natural language. Previous work using a single set of agents has shown great progress in generalizing to known partners, however it struggles when coordinating with unfamiliar agents. To mitigate that, recent work explored the use of population-based approaches, where multiple agents interact with each other with the goal of learning more generic protocols. These methods, while able to result in good coordination between unseen partners, still only achieve so in cases of simple languages, thus failing to adapt to human partners using natural language. We attribute this to the use of static populations and instead propose a dynamic population-based meta-learning approach that builds such a population in an iterative manner. We perform a holistic evaluation of our method on two different referential games, and show that our agents outperform all prior work when communicating with seen partners and humans. Furthermore, we analyze the natural language generation skills of our agents, where we find that our agents also outperform strong baselines. Finally, we test the robustness of our agents when communicating with out-of-population agents and carefully test the importance of each component of our method through ablation studies.

</p>
</details>

<details><summary><b>Revisit Multimodal Meta-Learning through the Lens of Multi-Task Learning</b>
<a href="https://arxiv.org/abs/2110.14202">arxiv:2110.14202</a>
&#x1F4C8; 6 <br>
<p>Milad Abdollahzadeh, Touba Malekzadeh, Ngai-Man Cheung</p></summary>
<p>

**Abstract:** Multimodal meta-learning is a recent problem that extends conventional few-shot meta-learning by generalizing its setup to diverse multimodal task distributions. This setup makes a step towards mimicking how humans make use of a diverse set of prior skills to learn new skills. Previous work has achieved encouraging performance. In particular, in spite of the diversity of the multimodal tasks, previous work claims that a single meta-learner trained on a multimodal distribution can sometimes outperform multiple specialized meta-learners trained on individual unimodal distributions. The improvement is attributed to knowledge transfer between different modes of task distributions. However, there is no deep investigation to verify and understand the knowledge transfer between multimodal tasks. Our work makes two contributions to multimodal meta-learning. First, we propose a method to quantify knowledge transfer between tasks of different modes at a micro-level. Our quantitative, task-level analysis is inspired by the recent transference idea from multi-task learning. Second, inspired by hard parameter sharing in multi-task learning and a new interpretation of related work, we propose a new multimodal meta-learner that outperforms existing work by considerable margins. While the major focus is on multimodal meta-learning, our work also attempts to shed light on task interaction in conventional meta-learning. The code for this project is available at https://miladabd.github.io/KML.

</p>
</details>

<details><summary><b>Generalized Shape Metrics on Neural Representations</b>
<a href="https://arxiv.org/abs/2110.14739">arxiv:2110.14739</a>
&#x1F4C8; 5 <br>
<p>Alex H. Williams, Erin Kunz, Simon Kornblith, Scott W. Linderman</p></summary>
<p>

**Abstract:** Understanding the operation of biological and artificial networks remains a difficult and important challenge. To identify general principles, researchers are increasingly interested in surveying large collections of networks that are trained on, or biologically adapted to, similar tasks. A standardized set of analysis tools is now needed to identify how network-level covariates -- such as architecture, anatomical brain region, and model organism -- impact neural representations (hidden layer activations). Here, we provide a rigorous foundation for these analyses by defining a broad family of metric spaces that quantify representational dissimilarity. Using this framework we modify existing representational similarity measures based on canonical correlation analysis to satisfy the triangle inequality, formulate a novel metric that respects the inductive biases in convolutional layers, and identify approximate Euclidean embeddings that enable network representations to be incorporated into essentially any off-the-shelf machine learning method. We demonstrate these methods on large-scale datasets from biology (Allen Institute Brain Observatory) and deep learning (NAS-Bench-101). In doing so, we identify relationships between neural representations that are interpretable in terms of anatomical features and model performance.

</p>
</details>

<details><summary><b>Sensing Anomalies as Potential Hazards: Datasets and Benchmarks</b>
<a href="https://arxiv.org/abs/2110.14706">arxiv:2110.14706</a>
&#x1F4C8; 5 <br>
<p>Dario Mantegazza, Carlos Redondo, Fran Espada, Luca M. Gambardella, Alessandro Giusti, J√©r√¥me Guzzi</p></summary>
<p>

**Abstract:** We consider the problem of detecting, in the visual sensing data stream of an autonomous mobile robot, semantic patterns that are unusual (i.e., anomalous) with respect to the robot's previous experience in similar environments. These anomalies might indicate unforeseen hazards and, in scenarios where failure is costly, can be used to trigger an avoidance behavior. We contribute three novel image-based datasets acquired in robot exploration scenarios, comprising a total of more than 200k labeled frames, spanning various types of anomalies. On these datasets, we study the performance of an anomaly detection approach based on autoencoders operating at different scales.

</p>
</details>

<details><summary><b>Towards Realistic Single-Task Continuous Learning Research for NER</b>
<a href="https://arxiv.org/abs/2110.14694">arxiv:2110.14694</a>
&#x1F4C8; 5 <br>
<p>Justin Payan, Yuval Merhav, He Xie, Satyapriya Krishna, Anil Ramakrishna, Mukund Sridhar, Rahul Gupta</p></summary>
<p>

**Abstract:** There is an increasing interest in continuous learning (CL), as data privacy is becoming a priority for real-world machine learning applications. Meanwhile, there is still a lack of academic NLP benchmarks that are applicable for realistic CL settings, which is a major challenge for the advancement of the field. In this paper we discuss some of the unrealistic data characteristics of public datasets, study the challenges of realistic single-task continuous learning as well as the effectiveness of data rehearsal as a way to mitigate accuracy loss. We construct a CL NER dataset from an existing publicly available dataset and release it along with the code to the research community.

</p>
</details>

<details><summary><b>GenURL: A General Framework for Unsupervised Representation Learning</b>
<a href="https://arxiv.org/abs/2110.14553">arxiv:2110.14553</a>
&#x1F4C8; 5 <br>
<p>Siyuan Li, Zelin Zang, Di Wu, Zhiyuan Chen, Stan Z. Li</p></summary>
<p>

**Abstract:** Recently unsupervised representation learning (URL) has achieved remarkable progress in various scenarios. However, most methods are specifically designed based on specific data characters or task assumptions. Based on the manifold assumption, we regard most URL problems as an embedding problem that seeks an optimal low-dimensional representation of the given high-dimensional data. We split the embedding process into two steps, data structural modeling and low-dimensional embedding, and propose a general similarity-based framework called GenURL. Specifically, we provide a general method to model data structures by adaptively combining graph distances on the feature space and predefined graphs, then propose robust loss functions to learn the low-dimensional embedding. Combining with a specific pretext task, we can adapt GenURL to various URL tasks in a unified manner and achieve state-of-the-art performance, including self-supervised visual representation learning, unsupervised knowledge distillation, graph embeddings, and dimension reduction. Moreover, ablation studies of loss functions and basic hyper-parameter settings in GenURL illustrate the data characters of various tasks.

</p>
</details>

<details><summary><b>How Much Coffee Was Consumed During EMNLP 2019? Fermi Problems: A New Reasoning Challenge for AI</b>
<a href="https://arxiv.org/abs/2110.14207">arxiv:2110.14207</a>
&#x1F4C8; 5 <br>
<p>Ashwin Kalyan, Abhinav Kumar, Arjun Chandrasekaran, Ashish Sabharwal, Peter Clark</p></summary>
<p>

**Abstract:** Many real-world problems require the combined application of multiple reasoning abilities employing suitable abstractions, commonsense knowledge, and creative synthesis of problem-solving strategies. To help advance AI systems towards such capabilities, we propose a new reasoning challenge, namely Fermi Problems (FPs), which are questions whose answers can only be approximately estimated because their precise computation is either impractical or impossible. For example, "How much would the sea level rise if all ice in the world melted?" FPs are commonly used in quizzes and interviews to bring out and evaluate the creative reasoning abilities of humans. To do the same for AI systems, we present two datasets: 1) A collection of 1k real-world FPs sourced from quizzes and olympiads; and 2) a bank of 10k synthetic FPs of intermediate complexity to serve as a sandbox for the harder real-world challenge. In addition to question answer pairs, the datasets contain detailed solutions in the form of an executable program and supporting facts, helping in supervision and evaluation of intermediate steps. We demonstrate that even extensively fine-tuned large scale language models perform poorly on these datasets, on average making estimates that are off by two orders of magnitude. Our contribution is thus the crystallization of several unsolved AI problems into a single, new challenge that we hope will spur further advances in building systems that can reason.

</p>
</details>

<details><summary><b>From Image to Imuge: Immunized Image Generation</b>
<a href="https://arxiv.org/abs/2110.14196">arxiv:2110.14196</a>
&#x1F4C8; 5 <br>
<p>Qichao Ying, Zhenxing Qian, Hang Zhou, Haisheng Xu, Xinpeng Zhang, Siyi Li</p></summary>
<p>

**Abstract:** We introduce Imuge, an image tamper resilient generative scheme for image self-recovery. The traditional manner of concealing image content within the image are inflexible and fragile to diverse digital attack, i.e. image cropping and JPEG compression. To address this issue, we jointly train a U-Net backboned encoder, a tamper localization network and a decoder for image recovery. Given an original image, the encoder produces a visually indistinguishable immunized image. At the recipient's side, the verifying network localizes the malicious modifications, and the original content can be approximately recovered by the decoder, despite the presence of the attacks. Several strategies are proposed to boost the training efficiency. We demonstrate that our method can recover the details of the tampered regions with a high quality despite the presence of various kinds of attacks. Comprehensive ablation studies are conducted to validate our network designs.

</p>
</details>

<details><summary><b>Robust Contrastive Learning Using Negative Samples with Diminished Semantics</b>
<a href="https://arxiv.org/abs/2110.14189">arxiv:2110.14189</a>
&#x1F4C8; 5 <br>
<p>Songwei Ge, Shlok Mishra, Haohan Wang, Chun-Liang Li, David Jacobs</p></summary>
<p>

**Abstract:** Unsupervised learning has recently made exceptional progress because of the development of more effective contrastive learning methods. However, CNNs are prone to depend on low-level features that humans deem non-semantic. This dependency has been conjectured to induce a lack of robustness to image perturbations or domain shift. In this paper, we show that by generating carefully designed negative samples, contrastive learning can learn more robust representations with less dependence on such features. Contrastive learning utilizes positive pairs that preserve semantic information while perturbing superficial features in the training images. Similarly, we propose to generate negative samples in a reversed way, where only the superfluous instead of the semantic features are preserved. We develop two methods, texture-based and patch-based augmentations, to generate negative samples. These samples achieve better generalization, especially under out-of-domain settings. We also analyze our method and the generated texture-based samples, showing that texture features are indispensable in classifying particular ImageNet classes and especially finer classes. We also show that model bias favors texture and shape features differently under different test settings. Our code, trained models, and ImageNet-Texture dataset can be found at https://github.com/SongweiGe/Contrastive-Learning-with-Non-Semantic-Negatives.

</p>
</details>

<details><summary><b>Mosaicking to Distill: Knowledge Distillation from Out-of-Domain Data</b>
<a href="https://arxiv.org/abs/2110.15094">arxiv:2110.15094</a>
&#x1F4C8; 4 <br>
<p>Gongfan Fang, Yifan Bao, Jie Song, Xinchao Wang, Donglin Xie, Chengchao Shen, Mingli Song</p></summary>
<p>

**Abstract:** Knowledge distillation~(KD) aims to craft a compact student model that imitates the behavior of a pre-trained teacher in a target domain. Prior KD approaches, despite their gratifying results, have largely relied on the premise that \emph{in-domain} data is available to carry out the knowledge transfer. Such an assumption, unfortunately, in many cases violates the practical setting, since the original training data or even the data domain is often unreachable due to privacy or copyright reasons. In this paper, we attempt to tackle an ambitious task, termed as \emph{out-of-domain} knowledge distillation~(OOD-KD), which allows us to conduct KD using only OOD data that can be readily obtained at a very low cost. Admittedly, OOD-KD is by nature a highly challenging task due to the agnostic domain gap. To this end, we introduce a handy yet surprisingly efficacious approach, dubbed as~\textit{MosaicKD}. The key insight behind MosaicKD lies in that, samples from various domains share common local patterns, even though their global semantic may vary significantly; these shared local patterns, in turn, can be re-assembled analogous to mosaic tiling, to approximate the in-domain data and to further alleviating the domain discrepancy. In MosaicKD, this is achieved through a four-player min-max game, in which a generator, a discriminator, a student network, are collectively trained in an adversarial manner, partially under the guidance of a pre-trained teacher. We validate MosaicKD over {classification and semantic segmentation tasks} across various benchmarks, and demonstrate that it yields results much superior to the state-of-the-art counterparts on OOD data. Our code is available at \url{https://github.com/zju-vipa/MosaicKD}.

</p>
</details>

<details><summary><b>Graph Communal Contrastive Learning</b>
<a href="https://arxiv.org/abs/2110.14863">arxiv:2110.14863</a>
&#x1F4C8; 4 <br>
<p>Bolian Li, Baoyu Jing, Hanghang Tong</p></summary>
<p>

**Abstract:** Graph representation learning is crucial for many real-world applications (e.g. social relation analysis). A fundamental problem for graph representation learning is how to effectively learn representations without human labeling, which is usually costly and time-consuming. Graph contrastive learning (GCL) addresses this problem by pulling the positive node pairs (or similar nodes) closer while pushing the negative node pairs (or dissimilar nodes) apart in the representation space. Despite the success of the existing GCL methods, they primarily sample node pairs based on the node-level proximity yet the community structures have rarely been taken into consideration. As a result, two nodes from the same community might be sampled as a negative pair. We argue that the community information should be considered to identify node pairs in the same communities, where the nodes insides are semantically similar. To address this issue, we propose a novel Graph Communal Contrastive Learning (gCooL) framework to jointly learn the community partition and learn node representations in an end-to-end fashion. Specifically, the proposed gCooL consists of two components: a Dense Community Aggregation (DeCA) algorithm for community detection and a Reweighted Self-supervised Cross-contrastive (ReSC) training scheme to utilize the community information. Additionally, the real-world graphs are complex and often consist of multiple views. In this paper, we demonstrate that the proposed gCooL can also be naturally adapted to multiplex graphs. Finally, we comprehensively evaluate the proposed gCooL on a variety of real-world graphs. The experimental results show that the gCooL outperforms the state-of-the-art methods.

</p>
</details>

<details><summary><b>SCALP -- Supervised Contrastive Learning for Cardiopulmonary Disease Classification and Localization in Chest X-rays using Patient Metadata</b>
<a href="https://arxiv.org/abs/2110.14787">arxiv:2110.14787</a>
&#x1F4C8; 4 <br>
<p>Ajay Jaiswal, Tianhao Li, Cyprian Zander, Yan Han, Justin F. Rousseau, Yifan Peng, Ying Ding</p></summary>
<p>

**Abstract:** Computer-aided diagnosis plays a salient role in more accessible and accurate cardiopulmonary diseases classification and localization on chest radiography. Millions of people get affected and die due to these diseases without an accurate and timely diagnosis. Recently proposed contrastive learning heavily relies on data augmentation, especially positive data augmentation. However, generating clinically-accurate data augmentations for medical images is extremely difficult because the common data augmentation methods in computer vision, such as sharp, blur, and crop operations, can severely alter the clinical settings of medical images. In this paper, we proposed a novel and simple data augmentation method based on patient metadata and supervised knowledge to create clinically accurate positive and negative augmentations for chest X-rays. We introduce an end-to-end framework, SCALP, which extends the self-supervised contrastive approach to a supervised setting. Specifically, SCALP pulls together chest X-rays from the same patient (positive keys) and pushes apart chest X-rays from different patients (negative keys). In addition, it uses ResNet-50 along with the triplet-attention mechanism to identify cardiopulmonary diseases, and Grad-CAM++ to highlight the abnormal regions. Our extensive experiments demonstrate that SCALP outperforms existing baselines with significant margins in both classification and localization tasks. Specifically, the average classification AUCs improve from 82.8% (SOTA using DenseNet-121) to 83.9% (SCALP using ResNet-50), while the localization results improve on average by 3.7% over different IoU thresholds.

</p>
</details>

<details><summary><b>Combining Vagueness Detection with Deep Learning to Identify Fake News</b>
<a href="https://arxiv.org/abs/2110.14780">arxiv:2110.14780</a>
&#x1F4C8; 4 <br>
<p>Paul Gu√©lorget, Benjamin Icard, Guillaume Gadek, Souhir Gahbiche, Sylvain Gatepaille, Ghislain Atemezing, Paul √âgr√©</p></summary>
<p>

**Abstract:** In this paper, we combine two independent detection methods for identifying fake news: the algorithm VAGO uses semantic rules combined with NLP techniques to measure vagueness and subjectivity in texts, while the classifier FAKE-CLF relies on Convolutional Neural Network classification and supervised deep learning to classify texts as biased or legitimate. We compare the results of the two methods on four corpora. We find a positive correlation between the vagueness and subjectivity measures obtained by VAGO, and the classification of text as biased by FAKE-CLF. The comparison yields mutual benefits: VAGO helps explain the results of FAKE-CLF. Conversely FAKE-CLF helps us corroborate and expand VAGO's database. The use of two complementary techniques (rule-based vs data-driven) proves a fruitful approach for the challenging problem of identifying fake news.

</p>
</details>

<details><summary><b>BI-GCN: Boundary-Aware Input-Dependent Graph Convolution Network for Biomedical Image Segmentation</b>
<a href="https://arxiv.org/abs/2110.14775">arxiv:2110.14775</a>
&#x1F4C8; 4 <br>
<p>Yanda Meng, Hongrun Zhang, Dongxu Gao, Yitian Zhao, Xiaoyun Yang, Xuesheng Qian, Xiaowei Huang, Yalin Zheng</p></summary>
<p>

**Abstract:** Segmentation is an essential operation of image processing. The convolution operation suffers from a limited receptive field, while global modelling is fundamental to segmentation tasks. In this paper, we apply graph convolution into the segmentation task and propose an improved \textit{Laplacian}. Different from existing methods, our \textit{Laplacian} is data-dependent, and we introduce two attention diagonal matrices to learn a better vertex relationship. In addition, it takes advantage of both region and boundary information when performing graph-based information propagation. Specifically, we model and reason about the boundary-aware region-wise correlations of different classes through learning graph representations, which is capable of manipulating long range semantic reasoning across various regions with the spatial enhancement along the object's boundary. Our model is well-suited to obtain global semantic region information while also accommodates local spatial boundary characteristics simultaneously. Experiments on two types of challenging datasets demonstrate that our method outperforms the state-of-the-art approaches on the segmentation of polyps in colonoscopy images and of the optic disc and optic cup in colour fundus images.

</p>
</details>

<details><summary><b>Regularized Frank-Wolfe for Dense CRFs: Generalizing Mean Field and Beyond</b>
<a href="https://arxiv.org/abs/2110.14759">arxiv:2110.14759</a>
&#x1F4C8; 4 <br>
<p>ƒê. Khu√™ L√™-Huu, Karteek Alahari</p></summary>
<p>

**Abstract:** We introduce regularized Frank-Wolfe, a general and effective algorithm for inference and learning of dense conditional random fields (CRFs). The algorithm optimizes a nonconvex continuous relaxation of the CRF inference problem using vanilla Frank-Wolfe with approximate updates, which are equivalent to minimizing a regularized energy function. Our proposed method is a generalization of existing algorithms such as mean field or concave-convex procedure. This perspective not only offers a unified analysis of these algorithms, but also allows an easy way of exploring different variants that potentially yield better performance. We illustrate this in our empirical results on standard semantic segmentation datasets, where several instantiations of our regularized Frank-Wolfe outperform mean field inference, both as a standalone component and as an end-to-end trainable layer in a neural network. We also show that dense CRFs, coupled with our new algorithms, produce significant improvements over strong CNN baselines.

</p>
</details>

<details><summary><b>Algorithmic encoding of protected characteristics and its implications on disparities across subgroups</b>
<a href="https://arxiv.org/abs/2110.14755">arxiv:2110.14755</a>
&#x1F4C8; 4 <br>
<p>Ben Glocker, Stefan Winzeck</p></summary>
<p>

**Abstract:** It has been rightfully emphasized that the use of AI for clinical decision making could amplify health disparities. A machine learning model may pick up undesirable correlations, for example, between a patient's racial identity and clinical outcome. Such correlations are often present in (historical) data used for model development. There has been an increase in studies reporting biases in disease detection models across patient subgroups. Besides the scarcity of data from underserved populations, very little is known about how these biases are encoded and how one may reduce or even remove disparate performance. There is some speculation whether algorithms may recognize patient characteristics such as biological sex or racial identity, and then directly or indirectly use this information when making predictions. But it remains unclear how we can establish whether such information is actually used. This article aims to shed some light on these issues by exploring new methodology allowing intuitive inspections of the inner working of machine learning models for image-based detection of disease. We also evaluate an effective yet debatable technique for addressing disparities leveraging the automatic prediction of patient characteristics, resulting in models with comparable true and false positive rates across subgroups. Our findings may stimulate the discussion about safe and ethical use of AI.

</p>
</details>

<details><summary><b>Dynamic Review-based Recommenders</b>
<a href="https://arxiv.org/abs/2110.14747">arxiv:2110.14747</a>
&#x1F4C8; 4 <br>
<p>Kostadin Cvejoski, Ramses J. Sanchez, Christian Bauckhage, Cesar Ojeda</p></summary>
<p>

**Abstract:** Just as user preferences change with time, item reviews also reflect those same preference changes. In a nutshell, if one is to sequentially incorporate review content knowledge into recommender systems, one is naturally led to dynamical models of text. In the present work we leverage the known power of reviews to enhance rating predictions in a way that (i) respects the causality of review generation and (ii) includes, in a bidirectional fashion, the ability of ratings to inform language review models and vice-versa, language representations that help predict ratings end-to-end. Moreover, our representations are time-interval aware and thus yield a continuous-time representation of the dynamics. We provide experiments on real-world datasets and show that our methodology is able to outperform several state-of-the-art models. Source code for all models can be found at [1].

</p>
</details>

<details><summary><b>TMBuD: A dataset for urban scene building detection</b>
<a href="https://arxiv.org/abs/2110.14590">arxiv:2110.14590</a>
&#x1F4C8; 4 <br>
<p>Orhei Ciprian, Vert Silviu, Mocofan Muguras, Vasiu Radu</p></summary>
<p>

**Abstract:** Building recognition and 3D reconstruction of human made structures in urban scenarios has become an interesting and actual topic in the image processing domain. For this research topic the Computer Vision and Augmented Reality areas intersect for creating a better understanding of the urban scenario for various topics. In this paper we aim to introduce a dataset solution, the TMBuD, that is better fitted for image processing on human made structures for urban scene scenarios. The proposed dataset will allow proper evaluation of salient edges and semantic segmentation of images focusing on the street view perspective of buildings. The images that form our dataset offer various street view perspectives of buildings from urban scenarios, which allows for evaluating complex algorithms. The dataset features 160 images of buildings from Timisoara, Romania, with a resolution of 768 x 1024 pixels each.

</p>
</details>

<details><summary><b>Zero-shot Voice Conversion via Self-supervised Prosody Representation Learning</b>
<a href="https://arxiv.org/abs/2110.14422">arxiv:2110.14422</a>
&#x1F4C8; 4 <br>
<p>Shijun Wang, Dimche Kostadinov, Damian Borth</p></summary>
<p>

**Abstract:** Voice Conversion (VC) for unseen speakers, also known as zero-shot VC, is an attractive topic due to its usefulness in real use-case scenarios. Recent work in this area made progress with disentanglement methods that separate utterance content and speaker characteristics. Although crucial, extracting disentangled prosody characteristics for unseen speakers remains an open issue. In this paper, we propose a novel self-supervised approach to effectively learn the prosody characteristics. Then, we use the learned prosodic representations to train our VC model for zero-shot conversion. Our evaluation demonstrates that we can efficiently extract disentangled prosody representation. Moreover, we show improved performance compared to the state-of-the-art zero-shot VC models.

</p>
</details>

<details><summary><b>Traffic Forecasting on Traffic Moving Snippets</b>
<a href="https://arxiv.org/abs/2110.14383">arxiv:2110.14383</a>
&#x1F4C8; 4 <br>
<p>Nina Wiedemann, Martin Raubal</p></summary>
<p>

**Abstract:** Advances in traffic forecasting technology can greatly impact urban mobility. In the traffic4cast competition, the task of short-term traffic prediction is tackled in unprecedented detail, with traffic volume and speed information available at 5 minute intervals and high spatial resolution. To improve generalization to unknown cities, as required in the 2021 extended challenge, we propose to predict small quadratic city sections, rather than processing a full-city-raster at once. At test time, breaking down the test data into spatially-cropped overlapping snippets improves stability and robustness of the final predictions, since multiple patches covering one cell can be processed independently. With the performance on the traffic4cast test data and further experiments on a validation set it is shown that patch-wise prediction indeed improves accuracy. Further advantages can be gained with a Unet++ architecture and with an increasing number of patches per sample processed at test time. We conclude that our snippet-based method, combined with other successful network architectures proposed in the competition, can leverage performance, in particular on unseen cities. All source code is available at https://github.com/NinaWie/NeurIPS2021-traffic4cast.

</p>
</details>

<details><summary><b>Temporal-attentive Covariance Pooling Networks for Video Recognition</b>
<a href="https://arxiv.org/abs/2110.14381">arxiv:2110.14381</a>
&#x1F4C8; 4 <br>
<p>Zilin Gao, Qilong Wang, Bingbing Zhang, Qinghua Hu, Peihua Li</p></summary>
<p>

**Abstract:** For video recognition task, a global representation summarizing the whole contents of the video snippets plays an important role for the final performance. However, existing video architectures usually generate it by using a simple, global average pooling (GAP) method, which has limited ability to capture complex dynamics of videos. For image recognition task, there exist evidences showing that covariance pooling has stronger representation ability than GAP. Unfortunately, such plain covariance pooling used in image recognition is an orderless representative, which cannot model spatio-temporal structure inherent in videos. Therefore, this paper proposes a Temporal-attentive Covariance Pooling(TCP), inserted at the end of deep architectures, to produce powerful video representations. Specifically, our TCP first develops a temporal attention module to adaptively calibrate spatio-temporal features for the succeeding covariance pooling, approximatively producing attentive covariance representations. Then, a temporal covariance pooling performs temporal pooling of the attentive covariance representations to characterize both intra-frame correlations and inter-frame cross-correlations of the calibrated features. As such, the proposed TCP can capture complex temporal dynamics. Finally, a fast matrix power normalization is introduced to exploit geometry of covariance representations. Note that our TCP is model-agnostic and can be flexibly integrated into any video architectures, resulting in TCPNet for effective video recognition. The extensive experiments on six benchmarks (e.g., Kinetics, Something-Something V1 and Charades) using various video architectures show our TCPNet is clearly superior to its counterparts, while having strong generalization ability. The source code is publicly available.

</p>
</details>

<details><summary><b>A Scalable Inference Method For Large Dynamic Economic Systems</b>
<a href="https://arxiv.org/abs/2110.14346">arxiv:2110.14346</a>
&#x1F4C8; 4 <br>
<p>Pratha Khandelwal, Philip Nadler, Rossella Arcucci, William Knottenbelt, Yi-Ke Guo</p></summary>
<p>

**Abstract:** The nature of available economic data has changed fundamentally in the last decade due to the economy's digitisation. With the prevalence of often black box data-driven machine learning methods, there is a necessity to develop interpretable machine learning methods that can conduct econometric inference, helping policymakers leverage the new nature of economic data. We therefore present a novel Variational Bayesian Inference approach to incorporate a time-varying parameter auto-regressive model which is scalable for big data. Our model is applied to a large blockchain dataset containing prices, transactions of individual actors, analyzing transactional flows and price movements on a very granular level. The model is extendable to any dataset which can be modelled as a dynamical system. We further improve the simple state-space modelling by introducing non-linearities in the forward model with the help of machine learning architectures.

</p>
</details>

<details><summary><b>SQALER: Scaling Question Answering by Decoupling Multi-Hop and Logical Reasoning</b>
<a href="https://arxiv.org/abs/2110.14266">arxiv:2110.14266</a>
&#x1F4C8; 4 <br>
<p>Mattia Atzeni, Jasmina Bogojeska, Andreas Loukas</p></summary>
<p>

**Abstract:** State-of-the-art approaches to reasoning and question answering over knowledge graphs (KGs) usually scale with the number of edges and can only be applied effectively on small instance-dependent subgraphs. In this paper, we address this issue by showing that multi-hop and more complex logical reasoning can be accomplished separately without losing expressive power. Motivated by this insight, we propose an approach to multi-hop reasoning that scales linearly with the number of relation types in the graph, which is usually significantly smaller than the number of edges or nodes. This produces a set of candidate solutions that can be provably refined to recover the solution to the original problem. Our experiments on knowledge-based question answering show that our approach solves the multi-hop MetaQA dataset, achieves a new state-of-the-art on the more challenging WebQuestionsSP, is orders of magnitude more scalable than competitive approaches, and can achieve compositional generalization out of the training distribution.

</p>
</details>

<details><summary><b>Sample Selection for Fair and Robust Training</b>
<a href="https://arxiv.org/abs/2110.14222">arxiv:2110.14222</a>
&#x1F4C8; 4 <br>
<p>Yuji Roh, Kangwook Lee, Steven Euijong Whang, Changho Suh</p></summary>
<p>

**Abstract:** Fairness and robustness are critical elements of Trustworthy AI that need to be addressed together. Fairness is about learning an unbiased model while robustness is about learning from corrupted data, and it is known that addressing only one of them may have an adverse affect on the other. In this work, we propose a sample selection-based algorithm for fair and robust training. To this end, we formulate a combinatorial optimization problem for the unbiased selection of samples in the presence of data corruption. Observing that solving this optimization problem is strongly NP-hard, we propose a greedy algorithm that is efficient and effective in practice. Experiments show that our algorithm obtains fairness and robustness that are better than or comparable to the state-of-the-art technique, both on synthetic and benchmark real datasets. Moreover, unlike other fair and robust training baselines, our algorithm can be used by only modifying the sampling step in batch selection without changing the training algorithm or leveraging additional clean data.

</p>
</details>

<details><summary><b>Diversity Enhanced Active Learning with Strictly Proper Scoring Rules</b>
<a href="https://arxiv.org/abs/2110.14171">arxiv:2110.14171</a>
&#x1F4C8; 4 <br>
<p>Wei Tan, Lan Du, Wray Buntine</p></summary>
<p>

**Abstract:** We study acquisition functions for active learning (AL) for text classification. The Expected Loss Reduction (ELR) method focuses on a Bayesian estimate of the reduction in classification error, recently updated with Mean Objective Cost of Uncertainty (MOCU). We convert the ELR framework to estimate the increase in (strictly proper) scores like log probability or negative mean square error, which we call Bayesian Estimate of Mean Proper Scores (BEMPS). We also prove convergence results borrowing techniques used with MOCU. In order to allow better experimentation with the new acquisition functions, we develop a complementary batch AL algorithm, which encourages diversity in the vector of expected changes in scores for unlabelled data. To allow high performance text classifiers, we combine ensembling and dynamic validation set construction on pretrained language models. Extensive experimental evaluation then explores how these different acquisition functions perform. The results show that the use of mean square error and log probability with BEMPS yields robust acquisition functions, which consistently outperform the others tested.

</p>
</details>

<details><summary><b>LSTM-RPA: A Simple but Effective Long Sequence Prediction Algorithm for Music Popularity Prediction</b>
<a href="https://arxiv.org/abs/2110.15790">arxiv:2110.15790</a>
&#x1F4C8; 3 <br>
<p>Kun Li, Meng Li, Yanling Li, Min Lin</p></summary>
<p>

**Abstract:** The big data about music history contains information about time and users' behavior. Researchers could predict the trend of popular songs accurately by analyzing this data. The traditional trend prediction models can better predict the short trend than the long trend. In this paper, we proposed the improved LSTM Rolling Prediction Algorithm (LSTM-RPA), which combines LSTM historical input with current prediction results as model input for next time prediction. Meanwhile, this algorithm converts the long trend prediction task into multiple short trend prediction tasks. The evaluation results show that the LSTM-RPA model increased F score by 13.03%, 16.74%, 11.91%, 18.52%, compared with LSTM, BiLSTM, GRU and RNN. And our method outperforms tradi-tional sequence models, which are ARIMA and SMA, by 10.67% and 3.43% improvement in F score.Code: https://github.com/maliaosaide/lstm-rpa

</p>
</details>

<details><summary><b>Sayer: Using Implicit Feedback to Optimize System Policies</b>
<a href="https://arxiv.org/abs/2110.14874">arxiv:2110.14874</a>
&#x1F4C8; 3 <br>
<p>Mathias L√©cuyer, Sang Hoon Kim, Mihir Nanavati, Junchen Jiang, Siddhartha Sen, Amit Sharma, Aleksandrs Slivkins</p></summary>
<p>

**Abstract:** We observe that many system policies that make threshold decisions involving a resource (e.g., time, memory, cores) naturally reveal additional, or implicit feedback. For example, if a system waits X min for an event to occur, then it automatically learns what would have happened if it waited <X min, because time has a cumulative property. This feedback tells us about alternative decisions, and can be used to improve the system policy. However, leveraging implicit feedback is difficult because it tends to be one-sided or incomplete, and may depend on the outcome of the event. As a result, existing practices for using feedback, such as simply incorporating it into a data-driven model, suffer from bias.
  We develop a methodology, called Sayer, that leverages implicit feedback to evaluate and train new system policies. Sayer builds on two ideas from reinforcement learning -- randomized exploration and unbiased counterfactual estimators -- to leverage data collected by an existing policy to estimate the performance of new candidate policies, without actually deploying those policies. Sayer uses implicit exploration and implicit data augmentation to generate implicit feedback in an unbiased form, which is then used by an implicit counterfactual estimator to evaluate and train new policies. The key idea underlying these techniques is to assign implicit probabilities to decisions that are not actually taken but whose feedback can be inferred; these probabilities are carefully calculated to ensure statistical unbiasedness. We apply Sayer to two production scenarios in Azure, and show that it can evaluate arbitrary policies accurately, and train new policies that outperform the production policies.

</p>
</details>

<details><summary><b>Generalized Depthwise-Separable Convolutions for Adversarially Robust and Efficient Neural Networks</b>
<a href="https://arxiv.org/abs/2110.14871">arxiv:2110.14871</a>
&#x1F4C8; 3 <br>
<p>Hassan Dbouk, Naresh R. Shanbhag</p></summary>
<p>

**Abstract:** Despite their tremendous successes, convolutional neural networks (CNNs) incur high computational/storage costs and are vulnerable to adversarial perturbations. Recent works on robust model compression address these challenges by combining model compression techniques with adversarial training. But these methods are unable to improve throughput (frames-per-second) on real-life hardware while simultaneously preserving robustness to adversarial perturbations. To overcome this problem, we propose the method of Generalized Depthwise-Separable (GDWS) convolution -- an efficient, universal, post-training approximation of a standard 2D convolution. GDWS dramatically improves the throughput of a standard pre-trained network on real-life hardware while preserving its robustness. Lastly, GDWS is scalable to large problem sizes since it operates on pre-trained models and doesn't require any additional training. We establish the optimality of GDWS as a 2D convolution approximator and present exact algorithms for constructing optimal GDWS convolutions under complexity and error constraints. We demonstrate the effectiveness of GDWS via extensive experiments on CIFAR-10, SVHN, and ImageNet datasets. Our code can be found at https://github.com/hsndbk4/GDWS.

</p>
</details>

<details><summary><b>ABIDES-Gym: Gym Environments for Multi-Agent Discrete Event Simulation and Application to Financial Markets</b>
<a href="https://arxiv.org/abs/2110.14771">arxiv:2110.14771</a>
&#x1F4C8; 3 <br>
<p>Selim Amrouni, Aymeric Moulin, Jared Vann, Svitlana Vyetrenko, Tucker Balch, Manuela Veloso</p></summary>
<p>

**Abstract:** Model-free Reinforcement Learning (RL) requires the ability to sample trajectories by taking actions in the original problem environment or a simulated version of it. Breakthroughs in the field of RL have been largely facilitated by the development of dedicated open source simulators with easy to use frameworks such as OpenAI Gym and its Atari environments. In this paper we propose to use the OpenAI Gym framework on discrete event time based Discrete Event Multi-Agent Simulation (DEMAS). We introduce a general technique to wrap a DEMAS simulator into the Gym framework. We expose the technique in detail and implement it using the simulator ABIDES as a base. We apply this work by specifically using the markets extension of ABIDES, ABIDES-Markets, and develop two benchmark financial markets OpenAI Gym environments for training daily investor and execution agents. As a result, these two environments describe classic financial problems with a complex interactive market behavior response to the experimental agent's action.

</p>
</details>

<details><summary><b>Efficient Placard Discovery for Semantic Mapping During Frontier Exploration</b>
<a href="https://arxiv.org/abs/2110.14742">arxiv:2110.14742</a>
&#x1F4C8; 3 <br>
<p>David Balaban, Harshavardhan Jagannathan, Henry Liu, Justin Hart</p></summary>
<p>

**Abstract:** Semantic mapping is the task of providing a robot with a map of its environment beyond the open, navigable space of traditional Simultaneous Localization and Mapping (SLAM) algorithms by attaching semantics to locations. The system presented in this work reads door placards to annotate the locations of offices. Whereas prior work on this system developed hand-crafted detectors, this system leverages YOLOv2 for detection and a segmentation network for segmentation. Placards are localized by computing their pose from a homography computed from a segmented quadrilateral outline. This work also introduces an Interruptable Frontier Exploration algorithm, enabling the robot to explore its environment to construct its SLAM map while pausing to inspect placards observed during this process. This allows the robot to autonomously discover room placards without human intervention while speeding up significantly over previous autonomous exploration methods.

</p>
</details>

<details><summary><b>Anomaly-Injected Deep Support Vector Data Description for Text Outlier Detection</b>
<a href="https://arxiv.org/abs/2110.14729">arxiv:2110.14729</a>
&#x1F4C8; 3 <br>
<p>Zeyu You, Yichu Zhou, Tao Yang, Wei Fan</p></summary>
<p>

**Abstract:** Anomaly detection or outlier detection is a common task in various domains, which has attracted significant research efforts in recent years. Existing works mainly focus on structured data such as numerical or categorical data; however, anomaly detection on unstructured textual data is less attended. In this work, we target the textual anomaly detection problem and propose a deep anomaly-injected support vector data description (AI-SVDD) framework. AI-SVDD not only learns a more compact representation of the data hypersphere but also adopts a small number of known anomalies to increase the discriminative power. To tackle text input, we employ a multilayer perceptron (MLP) network in conjunction with BERT to obtain enriched text representations. We conduct experiments on three text anomaly detection applications with multiple datasets. Experimental results show that the proposed AI-SVDD is promising and outperforms existing works.

</p>
</details>

<details><summary><b>Sharp-GAN: Sharpness Loss Regularized GAN for Histopathology Image Synthesis</b>
<a href="https://arxiv.org/abs/2110.14709">arxiv:2110.14709</a>
&#x1F4C8; 3 <br>
<p>Sujata Butte, Haotian Wang, Min Xian, Aleksandar Vakanski</p></summary>
<p>

**Abstract:** Existing deep learning-based approaches for histopathology image analysis require large annotated training sets to achieve good performance; but annotating histopathology images is slow and resource-intensive. Conditional generative adversarial networks have been applied to generate synthetic histopathology images to alleviate this issue, but current approaches fail to generate clear contours for overlapped and touching nuclei. In this study, We propose a sharpness loss regularized generative adversarial network to synthesize realistic histopathology images. The proposed network uses normalized nucleus distance map rather than the binary mask to encode nuclei contour information. The proposed sharpness loss enhances the contrast of nuclei contour pixels. The proposed method is evaluated using four image quality metrics and segmentation results on two public datasets. Both quantitative and qualitative results demonstrate that the proposed approach can generate realistic histopathology images with clear nuclei contours.

</p>
</details>

<details><summary><b>Identifiable Generative Models for Missing Not at Random Data Imputation</b>
<a href="https://arxiv.org/abs/2110.14708">arxiv:2110.14708</a>
&#x1F4C8; 3 <br>
<p>Chao Ma, Cheng Zhang</p></summary>
<p>

**Abstract:** Real-world datasets often have missing values associated with complex generative processes, where the cause of the missingness may not be fully observed. This is known as missing not at random (MNAR) data. However, many imputation methods do not take into account the missingness mechanism, resulting in biased imputation values when MNAR data is present. Although there are a few methods that have considered the MNAR scenario, their model's identifiability under MNAR is generally not guaranteed. That is, model parameters can not be uniquely determined even with infinite data samples, hence the imputation results given by such models can still be biased. This issue is especially overlooked by many modern deep generative models. In this work, we fill in this gap by systematically analyzing the identifiability of generative models under MNAR. Furthermore, we propose a practical deep generative model which can provide identifiability guarantees under mild assumptions, for a wide range of MNAR mechanisms. Our method demonstrates a clear advantage for tasks on both synthetic data and multiple real-world scenarios with MNAR data.

</p>
</details>

<details><summary><b>Improving Super-Resolution Performance using Meta-Attention Layers</b>
<a href="https://arxiv.org/abs/2110.14638">arxiv:2110.14638</a>
&#x1F4C8; 3 <br>
<p>Matthew Aquilina, Christian Galea, John Abela, Kenneth P. Camilleri, Reuben A. Farrugia</p></summary>
<p>

**Abstract:** Convolutional Neural Networks (CNNs) have achieved impressive results across many super-resolution (SR) and image restoration tasks. While many such networks can upscale low-resolution (LR) images using just the raw pixel-level information, the ill-posed nature of SR can make it difficult to accurately super-resolve an image which has undergone multiple different degradations. Additional information (metadata) describing the degradation process (such as the blur kernel applied, compression level, etc.) can guide networks to super-resolve LR images with higher fidelity to the original source. Previous attempts at informing SR networks with degradation parameters have indeed been able to improve performance in a number of scenarios. However, due to the fully-convolutional nature of many SR networks, most of these metadata fusion methods either require a complete architectural change, or necessitate the addition of significant extra complexity. Thus, these approaches are difficult to introduce into arbitrary SR networks without considerable design alterations. In this paper, we introduce meta-attention, a simple mechanism which allows any SR CNN to exploit the information available in relevant degradation parameters. The mechanism functions by translating the metadata into a channel attention vector, which in turn selectively modulates the network's feature maps. Incorporating meta-attention into SR networks is straightforward, as it requires no specific type of architecture to function correctly. Extensive testing has shown that meta-attention can consistently improve the pixel-level accuracy of state-of-the-art (SOTA) networks when provided with relevant degradation metadata. For PSNR, the gain on blurred/downsampled (X4) images is of 0.2969 dB (on average) and 0.3320 dB for SOTA general and face SR models, respectively.

</p>
</details>

<details><summary><b>Scalable Bayesian Network Structure Learning with Splines</b>
<a href="https://arxiv.org/abs/2110.14626">arxiv:2110.14626</a>
&#x1F4C8; 3 <br>
<p>Charupriya Sharma, Peter van Beek</p></summary>
<p>

**Abstract:** A Bayesian Network (BN) is a probabilistic graphical model consisting of a directed acyclic graph (DAG), where each node is a random variable represented as a function of its parents. We present a novel approach capable of learning the global DAG structure of a BN and modelling linear and non-linear local relationships between variables. We achieve this by a combination of feature selection to reduce the search space for local relationships, and extending the widely used score-and-search approach to support modelling relationships between variables as Multivariate Adaptive Regression Splines (MARS). MARS are polynomial regression models represented as piecewise spline functions - this lets us model non-linear relationships without the risk of overfitting that a single polynomial regression model would bring. The combination allows us to learn relationships in all bnlearn benchmark instances within minutes and enables us to scale to networks of over a thousand nodes

</p>
</details>

<details><summary><b>International Workshop on Continual Semi-Supervised Learning: Introduction, Benchmarks and Baselines</b>
<a href="https://arxiv.org/abs/2110.14613">arxiv:2110.14613</a>
&#x1F4C8; 3 <br>
<p>Ajmal Shahbaz, Salman Khan, Mohammad Asiful Hossain, Vincenzo Lomonaco, Kevin Cannons, Zhan Xu, Fabio Cuzzolin</p></summary>
<p>

**Abstract:** The aim of this paper is to formalize a new continual semi-supervised learning (CSSL) paradigm, proposed to the attention of the machine learning community via the IJCAI 2021 International Workshop on Continual Semi-Supervised Learning (CSSL-IJCAI), with the aim of raising field awareness about this problem and mobilizing its effort in this direction. After a formal definition of continual semi-supervised learning and the appropriate training and testing protocols, the paper introduces two new benchmarks specifically designed to assess CSSL on two important computer vision tasks: activity recognition and crowd counting. We describe the Continual Activity Recognition (CAR) and Continual Crowd Counting (CCC) challenges built upon those benchmarks, the baseline models proposed for the challenges, and describe a simple CSSL baseline which consists in applying batch self-training in temporal sessions, for a limited number of rounds. The results show that learning from unlabelled data streams is extremely challenging, and stimulate the search for methods that can encode the dynamics of the data stream.

</p>
</details>

<details><summary><b>PL-Net: Progressive Learning Network for Medical Image Segmentation</b>
<a href="https://arxiv.org/abs/2110.14484">arxiv:2110.14484</a>
&#x1F4C8; 3 <br>
<p>Junlong Cheng, Chengrui Gao, Chaoqing Wang, Zhangqiang Ming, Yong Yang, Min Zhu</p></summary>
<p>

**Abstract:** In recent years, segmentation methods based on deep convolutional neural networks (CNNs) have made state-of-the-art achievements for many medical analysis tasks. However, most of these approaches improve performance by optimizing the structure or adding new functional modules of the U-Net, which ignoring the complementation and fusion of the coarse-grained and fine-grained semantic information. To solve the above problems, we propose a medical image segmentation framework called progressive learning network (PL-Net), which includes internal progressive learning (IPL) and external progressive learning (EPL). PL-Net has the following advantages: (1) IPL divides feature extraction into two "steps", which can mix different size receptive fields and capture semantic information from coarse to fine granularity without introducing additional parameters; (2) EPL divides the training process into two "stages" to optimize parameters, and realizes the fusion of coarse-grained information in the previous stage and fine-grained information in the latter stage. We evaluate our method in different medical image analysis tasks, and the results show that the segmentation performance of PL-Net is better than the state-of-the-art methods of U-Net and its variants.

</p>
</details>

<details><summary><b>CBIR using Pre-Trained Neural Networks</b>
<a href="https://arxiv.org/abs/2110.14455">arxiv:2110.14455</a>
&#x1F4C8; 3 <br>
<p>Agnel Lazar Alappat, Prajwal Nakhate, Sagar Suman, Ambarish Chandurkar, Varad Pimpalkhute, Tapan Jain</p></summary>
<p>

**Abstract:** Much of the recent research work in image retrieval, has been focused around using Neural Networks as the core component. Many of the papers in other domain have shown that training multiple models, and then combining their outcomes, provide good results. This is since, a single Neural Network model, may not extract sufficient information from the input. In this paper, we aim to follow a different approach. Instead of the using a single model, we use a pretrained Inception V3 model, and extract activation of its last fully connected layer, which forms a low dimensional representation of the image. This feature matrix, is then divided into branches and separate feature extraction is done for each branch, to obtain multiple features flattened into a vector. Such individual vectors are then combined, to get a single combined feature. We make use of CUB200-2011 Dataset, which comprises of 200 birds classes to train the model on. We achieved a training accuracy of 99.46% and validation accuracy of 84.56% for the same. On further use of 3 branched global descriptors, we improve the validation accuracy to 88.89%. For this, we made use of MS-RMAC feature extraction method.

</p>
</details>

<details><summary><b>Nonnegative Tucker Decomposition with Beta-divergence for Music Structure Analysis of audio signals</b>
<a href="https://arxiv.org/abs/2110.14434">arxiv:2110.14434</a>
&#x1F4C8; 3 <br>
<p>Axel Marmoret, Florian Voorwinden, Valentin Leplat, J√©r√©my E. Cohen, Fr√©d√©ric Bimbot</p></summary>
<p>

**Abstract:** Nonnegative Tucker Decomposition (NTD), a tensor decomposition model, has received increased interest in the recent years because of its ability to blindly extract meaningful patterns in tensor data. Nevertheless, existing algorithms to compute NTD are mostly designed for the Euclidean loss. On the other hand, NTD has recently proven to be a powerful tool in Music Information Retrieval. This work proposes a Multiplicative Updates algorithm to compute NTD with the beta-divergence loss, often considered a better loss for audio processing. We notably show how to implement efficiently the multiplicative rules using tensor algebra, a naive approach being intractable. Finally, we show on a Music Structure Analysis task that unsupervised NTD fitted with beta-divergence loss outperforms earlier results obtained with the Euclidean loss.

</p>
</details>

<details><summary><b>Adversarial Neuron Pruning Purifies Backdoored Deep Models</b>
<a href="https://arxiv.org/abs/2110.14430">arxiv:2110.14430</a>
&#x1F4C8; 3 <br>
<p>Dongxian Wu, Yisen Wang</p></summary>
<p>

**Abstract:** As deep neural networks (DNNs) are growing larger, their requirements for computational resources become huge, which makes outsourcing training more popular. Training in a third-party platform, however, may introduce potential risks that a malicious trainer will return backdoored DNNs, which behave normally on clean samples but output targeted misclassifications whenever a trigger appears at the test time. Without any knowledge of the trigger, it is difficult to distinguish or recover benign DNNs from backdoored ones. In this paper, we first identify an unexpected sensitivity of backdoored DNNs, that is, they are much easier to collapse and tend to predict the target label on clean samples when their neurons are adversarially perturbed. Based on these observations, we propose a novel model repairing method, termed Adversarial Neuron Pruning (ANP), which prunes some sensitive neurons to purify the injected backdoor. Experiments show, even with only an extremely small amount of clean data (e.g., 1%), ANP effectively removes the injected backdoor without causing obvious performance degradation.

</p>
</details>

<details><summary><b>Generalizing AUC Optimization to Multiclass Classification for Audio Segmentation With Limited Training Data</b>
<a href="https://arxiv.org/abs/2110.14425">arxiv:2110.14425</a>
&#x1F4C8; 3 <br>
<p>Pablo Gimeno, Victoria Mingote, Alfonso Ortega, Antonio Miguel, Eduardo Lleida</p></summary>
<p>

**Abstract:** Area under the ROC curve (AUC) optimisation techniques developed for neural networks have recently demonstrated their capabilities in different audio and speech related tasks. However, due to its intrinsic nature, AUC optimisation has focused only on binary tasks so far. In this paper, we introduce an extension to the AUC optimisation framework so that it can be easily applied to an arbitrary number of classes, aiming to overcome the issues derived from training data limitations in deep learning solutions. Building upon the multiclass definitions of the AUC metric found in the literature, we define two new training objectives using a one-versus-one and a one-versus-rest approach. In order to demonstrate its potential, we apply them in an audio segmentation task with limited training data that aims to differentiate 3 classes: foreground music, background music and no music. Experimental results show that our proposal can improve the performance of audio segmentation systems significantly compared to traditional training criteria such as cross entropy.

</p>
</details>

<details><summary><b>Localized Super Resolution for Foreground Images using U-Net and MR-CNN</b>
<a href="https://arxiv.org/abs/2110.14413">arxiv:2110.14413</a>
&#x1F4C8; 3 <br>
<p>Umashankar Kumaravelan, Nivedita M</p></summary>
<p>

**Abstract:** Images play a vital role in understanding data through visual representation. It gives a clear representation of the object in context. But if this image is not clear it might not be of much use. Thus, the topic of Image Super Resolution arose and many researchers have been working towards applying Computer Vision and Deep Learning Techniques to increase the quality of images. One of the applications of Super Resolution is to increase the quality of Portrait Images. Portrait Images are images which mainly focus on capturing the essence of the main object in the frame, where the object in context is highlighted whereas the background is occluded. When performing Super Resolution the model tries to increase the overall resolution of the image. But in portrait images the foreground resolution is more important than that of the background. In this paper, the performance of a Convolutional Neural Network (CNN) architecture known as U-Net for Super Resolution combined with Mask Region Based CNN (MR-CNN) for foreground super resolution is analysed. This analysis is carried out based on Localized Super Resolution i.e. We pass the LR Images to a pre-trained Image Segmentation model (MR-CNN) and perform super resolution inference on the foreground or Segmented Images and compute the Structural Similarity Index (SSIM) and Peak Signal-to-Noise Ratio (PSNR) metrics for comparisons.

</p>
</details>

<details><summary><b>Transfer learning with causal counterfactual reasoning in Decision Transformers</b>
<a href="https://arxiv.org/abs/2110.14355">arxiv:2110.14355</a>
&#x1F4C8; 3 <br>
<p>Ayman Boustati, Hana Chockler, Daniel C. McNamee</p></summary>
<p>

**Abstract:** The ability to adapt to changes in environmental contingencies is an important challenge in reinforcement learning. Indeed, transferring previously acquired knowledge to environments with unseen structural properties can greatly enhance the flexibility and efficiency by which novel optimal policies may be constructed. In this work, we study the problem of transfer learning under changes in the environment dynamics. In this study, we apply causal reasoning in the offline reinforcement learning setting to transfer a learned policy to new environments. Specifically, we use the Decision Transformer (DT) architecture to distill a new policy on the new environment. The DT is trained on data collected by performing policy rollouts on factual and counterfactual simulations from the source environment. We show that this mechanism can bootstrap a successful policy on the target environment while retaining most of the reward.

</p>
</details>

<details><summary><b>Revisiting Sanity Checks for Saliency Maps</b>
<a href="https://arxiv.org/abs/2110.14297">arxiv:2110.14297</a>
&#x1F4C8; 3 <br>
<p>Gal Yona, Daniel Greenfeld</p></summary>
<p>

**Abstract:** Saliency methods are a popular approach for model debugging and explainability. However, in the absence of ground-truth data for what the correct maps should be, evaluating and comparing different approaches remains a long-standing challenge. The sanity checks methodology of Adebayo et al [Neurips 2018] has sought to address this challenge. They argue that some popular saliency methods should not be used for explainability purposes since the maps they produce are not sensitive to the underlying model that is to be explained. Through a causal re-framing of their objective, we argue that their empirical evaluation does not fully establish these conclusions, due to a form of confounding introduced by the tasks they evaluate on. Through various experiments on simple custom tasks we demonstrate that some of their conclusions may indeed be artifacts of the tasks more than a criticism of the saliency methods themselves. More broadly, our work challenges the utility of the sanity check methodology, and further highlights that saliency map evaluation beyond ad-hoc visual examination remains a fundamental challenge.

</p>
</details>

<details><summary><b>Counterfactual Shapley Additive Explanations</b>
<a href="https://arxiv.org/abs/2110.14270">arxiv:2110.14270</a>
&#x1F4C8; 3 <br>
<p>Emanuele Albini, Jason Long, Danial Dervovic, Daniele Magazzeni</p></summary>
<p>

**Abstract:** Feature attributions are a common paradigm for model explanations due to their simplicity in assigning a single numeric score for each input feature to a model. In the actionable recourse setting, wherein the goal of the explanations is to improve outcomes for model consumers, it is often unclear how feature attributions should be correctly used. With this work, we aim to strengthen and clarify the link between actionable recourse and feature attributions. Concretely, we propose a variant of SHAP, CoSHAP, that uses counterfactual generation techniques to produce a background dataset for use within the marginal (a.k.a. interventional) Shapley value framework. We motivate the need within the actionable recourse setting for careful consideration of background datasets when using Shapley values for feature attributions, alongside the requirement for monotonicity, with numerous synthetic examples. Moreover, we demonstrate the efficacy of CoSHAP by proposing and justifying a quantitative score for feature attributions, counterfactual-ability, showing that as measured by this metric, CoSHAP is superior to existing methods when evaluated on public datasets using monotone tree ensembles.

</p>
</details>

<details><summary><b>Multilayer Lookahead: a Nested Version of Lookahead</b>
<a href="https://arxiv.org/abs/2110.14254">arxiv:2110.14254</a>
&#x1F4C8; 3 <br>
<p>Denys Pushkin, Luis Barba</p></summary>
<p>

**Abstract:** In recent years, SGD and its variants have become the standard tool to train Deep Neural Networks. In this paper, we focus on the recently proposed variant Lookahead, which improves upon SGD in a wide range of applications. Following this success, we study an extension of this algorithm, the \emph{Multilayer Lookahead} optimizer, which recursively wraps Lookahead around itself. We prove the convergence of Multilayer Lookahead with two layers to a stationary point of smooth non-convex functions with $O(\frac{1}{\sqrt{T}})$ rate. We also justify the improved generalization of both Lookahead over SGD, and of Multilayer Lookahead over Lookahead, by showing how they amplify the implicit regularization effect of SGD. We empirically verify our results and show that Multilayer Lookahead outperforms Lookahead on CIFAR-10 and CIFAR-100 classification tasks, and on GANs training on the MNIST dataset.

</p>
</details>

<details><summary><b>Emoji-based Co-attention Network for Microblog Sentiment Analysis</b>
<a href="https://arxiv.org/abs/2110.14227">arxiv:2110.14227</a>
&#x1F4C8; 3 <br>
<p>Xiaowei Yuan, Jingyuan Hu, Xiaodan Zhang, Honglei Lv, Hao Liu</p></summary>
<p>

**Abstract:** Emojis are widely used in online social networks to express emotions, attitudes, and opinions. As emotional-oriented characters, emojis can be modeled as important features of emotions towards the recipient or subject for sentiment analysis. However, existing methods mainly take emojis as heuristic information that fails to resolve the problem of ambiguity noise. Recent researches have utilized emojis as an independent input to classify text sentiment but they ignore the emotional impact of the interaction between text and emojis. It results that the emotional semantics of emojis cannot be fully explored. In this paper, we propose an emoji-based co-attention network that learns the mutual emotional semantics between text and emojis on microblogs. Our model adopts the co-attention mechanism based on bidirectional long short-term memory incorporating the text and emojis, and integrates a squeeze-and-excitation block in a convolutional neural network classifier to increase its sensitivity to emotional semantic features. Experimental results show that the proposed method can significantly outperform several baselines for sentiment analysis on short texts of social media.

</p>
</details>

<details><summary><b>What Do We Mean by Generalization in Federated Learning?</b>
<a href="https://arxiv.org/abs/2110.14216">arxiv:2110.14216</a>
&#x1F4C8; 3 <br>
<p>Honglin Yuan, Warren Morningstar, Lin Ning, Karan Singhal</p></summary>
<p>

**Abstract:** Federated learning data is drawn from a distribution of distributions: clients are drawn from a meta-distribution, and their data are drawn from local data distributions. Thus generalization studies in federated learning should separate performance gaps from unseen client data (out-of-sample gap) from performance gaps from unseen client distributions (participation gap). In this work, we propose a framework for disentangling these performance gaps. Using this framework, we observe and explain differences in behavior across natural and synthetic federated datasets, indicating that dataset synthesis strategy can be important for realistic simulations of generalization in federated learning. We propose a semantic synthesis strategy that enables realistic simulation without naturally-partitioned data. Informed by our findings, we call out community suggestions for future federated learning works.

</p>
</details>

<details><summary><b>Syllabic Quantity Patterns as Rhythmic Features for Latin Authorship Attribution</b>
<a href="https://arxiv.org/abs/2110.14203">arxiv:2110.14203</a>
&#x1F4C8; 3 <br>
<p>Silvia Corbara, Alejandro Moreo, Fabrizio Sebastiani</p></summary>
<p>

**Abstract:** It is well known that, within the Latin production of written text, peculiar metric schemes were followed not only in poetic compositions, but also in many prose works. Such metric patterns were based on so-called syllabic quantity, i.e., on the length of the involved syllables, and there is substantial evidence suggesting that certain authors had a preference for certain metric patterns over others. In this research we investigate the possibility to employ syllabic quantity as a base for deriving rhythmic features for the task of computational authorship attribution of Latin prose texts. We test the impact of these features on the authorship attribution task when combined with other topic-agnostic features. Our experiments, carried out on three different datasets, using two different machine learning methods, show that rhythmic features based on syllabic quantity are beneficial in discriminating among Latin prose authors.

</p>
</details>

<details><summary><b>QU-net++: Image Quality Detection Framework for Segmentation of 3D Medical Image Stacks</b>
<a href="https://arxiv.org/abs/2110.14181">arxiv:2110.14181</a>
&#x1F4C8; 3 <br>
<p>Sohini Roychowdhury</p></summary>
<p>

**Abstract:** Automated segmentation of pathological regions of interest has been shown to aid prognosis and follow up treatment. However, accurate pathological segmentations require high quality of annotated data that can be both cost and time intensive to generate. In this work, we propose an automated two-step method that evaluates the quality of medical images from 3D image stacks using a U-net++ model, such that images that can aid further training of the U-net++ model can be detected based on the disagreement in segmentations produced from the final two layers. Images thus detected can then be used to further fine tune the U-net++ model for semantic segmentation. The proposed QU-net++ model isolates around 10\% of images per 3D stack and can scale across imaging modalities to segment cysts in OCT images and ground glass opacity in Lung CT images with Dice cores in the range 0.56-0.72. Thus, the proposed method can be applied for multi-modal binary segmentation of pathology.

</p>
</details>

<details><summary><b>Standing on the Shoulders of Predecessors: Meta-Knowledge Transfer for Knowledge Graphs</b>
<a href="https://arxiv.org/abs/2110.14170">arxiv:2110.14170</a>
&#x1F4C8; 3 <br>
<p>Mingyang Chen, Wen Zhang, Yushan Zhu, Hongting Zhou, Zonggang Yuan, Changliang Xu, Huajun Chen</p></summary>
<p>

**Abstract:** Knowledge graphs (KGs) have become widespread, and various knowledge graphs are constructed incessantly to support many in-KG and out-of-KG applications. During the construction of KGs, although new KGs may contain new entities with respect to constructed KGs, some entity-independent knowledge can be transferred from constructed KGs to new KGs. We call such knowledge meta-knowledge, and refer to the problem of transferring meta-knowledge from constructed (source) KGs to new (target) KGs to improve the performance of tasks on target KGs as meta-knowledge transfer for knowledge graphs. However, there is no available general framework that can tackle meta-knowledge transfer for both in-KG and out-of-KG tasks uniformly. Therefore, in this paper, we propose a framework, MorsE, which means conducting Meta-Learning for Meta-Knowledge Transfer via Knowledge Graph Embedding. MorsE represents the meta-knowledge via Knowledge Graph Embedding and learns the meta-knowledge by Meta-Learning. Specifically, MorsE uses an entity initializer and a Graph Neural Network (GNN) modulator to entity-independently obtain entity embeddings given a KG and is trained following the meta-learning setting to gain the ability of effectively obtaining embeddings. Experimental results on meta-knowledge transfer for both in-KG and out-of-KG tasks show that MorsE is able to learn and transfer meta-knowledge between KGs effectively, and outperforms existing state-of-the-art models.

</p>
</details>

<details><summary><b>Parameterized Explanations for Investor / Company Matching</b>
<a href="https://arxiv.org/abs/2111.01911">arxiv:2111.01911</a>
&#x1F4C8; 2 <br>
<p>Simerjot Kaur, Ivan Brugere, Andrea Stefanucci, Armineh Nourbakhsh, Sameena Shah, Manuela Veloso</p></summary>
<p>

**Abstract:** Matching companies and investors is usually considered a highly specialized decision making process. Building an AI agent that can automate such recommendation process can significantly help reduce costs, and eliminate human biases and errors. However, limited sample size of financial data-sets and the need for not only good recommendations, but also explaining why a particular recommendation is being made, makes this a challenging problem. In this work we propose a representation learning based recommendation engine that works extremely well with small datasets and demonstrate how it can be coupled with a parameterized explanation generation engine to build an explainable recommendation system for investor-company matching. We compare the performance of our system with human generated recommendations and demonstrate the ability of our algorithm to perform extremely well on this task. We also highlight how explainability helps with real-life adoption of our system.

</p>
</details>

<details><summary><b>Finite Horizon Q-learning: Stability, Convergence and Simulations</b>
<a href="https://arxiv.org/abs/2110.15093">arxiv:2110.15093</a>
&#x1F4C8; 2 <br>
<p>Vivek VP, Dr. Shalabh Bhatnagar</p></summary>
<p>

**Abstract:** Q-learning is a popular reinforcement learning algorithm. This algorithm has however been studied and analysed mainly in the infinite horizon setting. There are several important applications which can be modeled in the framework of finite horizon Markov decision processes. We develop a version of Q-learning algorithm for finite horizon Markov decision processes (MDP) and provide a full proof of its stability and convergence. Our analysis of stability and convergence of finite horizon Q-learning is based entirely on the ordinary differential equations (O.D.E) method. We also demonstrate the performance of our algorithm on a setting of random MDP.

</p>
</details>

<details><summary><b>AEVA: Black-box Backdoor Detection Using Adversarial Extreme Value Analysis</b>
<a href="https://arxiv.org/abs/2110.14880">arxiv:2110.14880</a>
&#x1F4C8; 2 <br>
<p>Junfeng Guo, Ang Li, Cong Liu</p></summary>
<p>

**Abstract:** Deep neural networks (DNNs) are proved to be vulnerable against backdoor attacks. A backdoor is often embedded in the target DNNs through injecting a backdoor trigger into training examples, which can cause the target DNNs misclassify an input attached with the backdoor trigger. Existing backdoor detection methods often require the access to the original poisoned training data, the parameters of the target DNNs, or the predictive confidence for each given input, which are impractical in many real-world applications, e.g., on-device deployed DNNs. We address the black-box hard-label backdoor detection problem where the DNN is fully black-box and only its final output label is accessible. We approach this problem from the optimization perspective and show that the objective of backdoor detection is bounded by an adversarial objective. Further theoretical and empirical studies reveal that this adversarial objective leads to a solution with highly skewed distribution; a singularity is often observed in the adversarial map of a backdoor-infected example, which we call the adversarial singularity phenomenon. Based on this observation, we propose the adversarial extreme value analysis(AEVA) to detect backdoors in black-box neural networks. AEVA is based on an extreme value analysis of the adversarial map, computed from the monte-carlo gradient estimation. Evidenced by extensive experiments across multiple popular tasks and backdoor attacks, our approach is shown effective in detecting backdoor attacks under the black-box hard-label scenarios.

</p>
</details>

<details><summary><b>From Intrinsic to Counterfactual: On the Explainability of Contextualized Recommender Systems</b>
<a href="https://arxiv.org/abs/2110.14844">arxiv:2110.14844</a>
&#x1F4C8; 2 <br>
<p>Yao Zhou, Haonan Wang, Jingrui He, Haixun Wang</p></summary>
<p>

**Abstract:** With the prevalence of deep learning based embedding approaches, recommender systems have become a proven and indispensable tool in various information filtering applications. However, many of them remain difficult to diagnose what aspects of the deep models' input drive the final ranking decision, thus, they cannot often be understood by human stakeholders. In this paper, we investigate the dilemma between recommendation and explainability, and show that by utilizing the contextual features (e.g., item reviews from users), we can design a series of explainable recommender systems without sacrificing their performance. In particular, we propose three types of explainable recommendation strategies with gradual change of model transparency: whitebox, graybox, and blackbox. Each strategy explains its ranking decisions via different mechanisms: attention weights, adversarial perturbations, and counterfactual perturbations. We apply these explainable models on five real-world data sets under the contextualized setting where users and items have explicit interactions. The empirical results show that our model achieves highly competitive ranking performance, and generates accurate and effective explanations in terms of numerous quantitative metrics and qualitative visualizations.

</p>
</details>

<details><summary><b>Normality-Calibrated Autoencoder for Unsupervised Anomaly Detection on Data Contamination</b>
<a href="https://arxiv.org/abs/2110.14825">arxiv:2110.14825</a>
&#x1F4C8; 2 <br>
<p>Jongmin Yu, Hyeontaek Oh, Minkyung Kim, Junsik Kim</p></summary>
<p>

**Abstract:** In this paper, we propose Normality-Calibrated Autoencoder (NCAE), which can boost anomaly detection performance on the contaminated datasets without any prior information or explicit abnormal samples in the training phase. The NCAE adversarially generates high confident normal samples from a latent space having low entropy and leverages them to predict abnormal samples in a training dataset. NCAE is trained to minimise reconstruction errors in uncontaminated samples and maximise reconstruction errors in contaminated samples. The experimental results demonstrate that our method outperforms shallow, hybrid, and deep methods for unsupervised anomaly detection and achieves comparable performance compared with semi-supervised methods using labelled anomaly samples in the training phase. The source code is publicly available on `https://github.com/andreYoo/NCAE_UAD.git'.

</p>
</details>

<details><summary><b>Temporal-Difference Value Estimation via Uncertainty-Guided Soft Updates</b>
<a href="https://arxiv.org/abs/2110.14818">arxiv:2110.14818</a>
&#x1F4C8; 2 <br>
<p>Litian Liang, Yaosheng Xu, Stephen McAleer, Dailin Hu, Alexander Ihler, Pieter Abbeel, Roy Fox</p></summary>
<p>

**Abstract:** Temporal-Difference (TD) learning methods, such as Q-Learning, have proven effective at learning a policy to perform control tasks. One issue with methods like Q-Learning is that the value update introduces bias when predicting the TD target of a unfamiliar state. Estimation noise becomes a bias after the max operator in the policy improvement step, and carries over to value estimations of other states, causing Q-Learning to overestimate the Q value. Algorithms like Soft Q-Learning (SQL) introduce the notion of a soft-greedy policy, which reduces the estimation bias via soft updates in early stages of training. However, the inverse temperature $Œ≤$ that controls the softness of an update is usually set by a hand-designed heuristic, which can be inaccurate at capturing the uncertainty in the target estimate. Under the belief that $Œ≤$ is closely related to the (state dependent) model uncertainty, Entropy Regularized Q-Learning (EQL) further introduces a principled scheduling of $Œ≤$ by maintaining a collection of the model parameters that characterizes model uncertainty. In this paper, we present Unbiased Soft Q-Learning (UQL), which extends the work of EQL from two action, finite state spaces to multi-action, infinite state space Markov Decision Processes. We also provide a principled numerical scheduling of $Œ≤$, extended from SQL and using model uncertainty, during the optimization process. We show the theoretical guarantees and the effectiveness of this update method in experiments on several discrete control environments.

</p>
</details>

<details><summary><b>Convolutional Deep Exponential Families</b>
<a href="https://arxiv.org/abs/2110.14800">arxiv:2110.14800</a>
&#x1F4C8; 2 <br>
<p>Chengkuan Hong, Christian R. Shelton</p></summary>
<p>

**Abstract:** We describe convolutional deep exponential families (CDEFs) in this paper. CDEFs are built based on deep exponential families, deep probabilistic models that capture the hierarchical dependence between latent variables. CDEFs greatly reduce the number of free parameters by tying the weights of DEFs. Our experiments show that CDEFs are able to uncover time correlations with a small amount of data.

</p>
</details>

<details><summary><b>Masked LARk: Masked Learning, Aggregation and Reporting worKflow</b>
<a href="https://arxiv.org/abs/2110.14794">arxiv:2110.14794</a>
&#x1F4C8; 2 <br>
<p>Joseph J. Pfeiffer III, Denis Charles, Davis Gilton, Young Hun Jung, Mehul Parsana, Erik Anderson</p></summary>
<p>

**Abstract:** Today, many web advertising data flows involve passive cross-site tracking of users. Enabling such a mechanism through the usage of third party tracking cookies (3PC) exposes sensitive user data to a large number of parties, with little oversight on how that data can be used. Thus, most browsers are moving towards removal of 3PC in subsequent browser iterations. In order to substantially improve end-user privacy while allowing sites to continue to sustain their business through ad funding, new privacy-preserving primitives need to be introduced.
  In this paper, we discuss a new proposal, called Masked LARk, for aggregation of user engagement measurement and model training that prevents cross-site tracking, while remaining (a) flexible, for engineering development and maintenance, (b) secure, in the sense that cross-site tracking and tracing are blocked and (c) open for continued model development and training, allowing advertisers to serve relevant ads to interested users. We introduce a secure multi-party compute (MPC) protocol that utilizes "helper" parties to train models, so that once data leaves the browser, no downstream system can individually construct a complete picture of the user activity. For training, our key innovation is through the usage of masking, or the obfuscation of the true labels, while still allowing a gradient to be accurately computed in aggregate over a batch of data. Our protocol only utilizes light cryptography, at such a level that an interested yet inexperienced reader can understand the core algorithm. We develop helper endpoints that implement this system, and give example usage of training in PyTorch.

</p>
</details>

<details><summary><b>Subtleties in the trainability of quantum machine learning models</b>
<a href="https://arxiv.org/abs/2110.14753">arxiv:2110.14753</a>
&#x1F4C8; 2 <br>
<p>Supanut Thanasilp, Samson Wang, Nhat A. Nghiem, Patrick J. Coles, M. Cerezo</p></summary>
<p>

**Abstract:** A new paradigm for data science has emerged, with quantum data, quantum models, and quantum computational devices. This field, called Quantum Machine Learning (QML), aims to achieve a speedup over traditional machine learning for data analysis. However, its success usually hinges on efficiently training the parameters in quantum neural networks, and the field of QML is still lacking theoretical scaling results for their trainability. Some trainability results have been proven for a closely related field called Variational Quantum Algorithms (VQAs). While both fields involve training a parametrized quantum circuit, there are crucial differences that make the results for one setting not readily applicable to the other. In this work we bridge the two frameworks and show that gradient scaling results for VQAs can also be applied to study the gradient scaling of QML models. Our results indicate that features deemed detrimental for VQA trainability can also lead to issues such as barren plateaus in QML. Consequently, our work has implications for several QML proposals in the literature. In addition, we provide theoretical and numerical evidence that QML models exhibit further trainability issues not present in VQAs, arising from the use of a training dataset. We refer to these as dataset-induced barren plateaus. These results are most relevant when dealing with classical data, as here the choice of embedding scheme (i.e., the map between classical data and quantum states) can greatly affect the gradient scaling.

</p>
</details>

<details><summary><b>MutFormer: A context-dependent transformer-based model to predict pathogenic missense mutations</b>
<a href="https://arxiv.org/abs/2110.14746">arxiv:2110.14746</a>
&#x1F4C8; 2 <br>
<p>Theodore Jiang, Li Fang, Kai Wang</p></summary>
<p>

**Abstract:** A missense mutation is a point mutation that results in a substitution of an amino acid in a protein sequence. Currently, missense mutations account for approximately half of the known variants responsible for human inherited diseases, but accurate prediction of the pathogenicity of missense variants is still challenging. Recent advances in deep learning show that transformer models are particularly powerful at modeling sequences. In this study, we introduce MutFormer, a transformer-based model for prediction of pathogenic missense mutations. We pre-trained MutFormer on reference protein sequences and alternative protein sequences result from common genetic variants. We tested different fine-tuning methods for pathogenicity prediction. Our results show that MutFormer outperforms a variety of existing tools. MutFormer and pre-computed variant scores are publicly available on GitHub at https://github.com/WGLab/mutformer.

</p>
</details>

<details><summary><b>Lung Cancer Lesion Detection in Histopathology Images Using Graph-Based Sparse PCA Network</b>
<a href="https://arxiv.org/abs/2110.14728">arxiv:2110.14728</a>
&#x1F4C8; 2 <br>
<p>Sundaresh Ram, Wenfei Tang, Alexander J. Bell, Cara Spencer, Alexander Buschhaus, Charles R. Hatt, Marina Pasca diMagliano, Jeffrey J. Rodriguez, Stefanie Galban, Craig J. Galban</p></summary>
<p>

**Abstract:** Early detection of lung cancer is critical for improvement of patient survival. To address the clinical need for efficacious treatments, genetically engineered mouse models (GEMM) have become integral in identifying and evaluating the molecular underpinnings of this complex disease that may be exploited as therapeutic targets. Assessment of GEMM tumor burden on histopathological sections performed by manual inspection is both time consuming and prone to subjective bias. Therefore, an interplay of needs and challenges exists for computer-aided diagnostic tools, for accurate and efficient analysis of these histopathology images. In this paper, we propose a simple machine learning approach called the graph-based sparse principal component analysis (GS-PCA) network, for automated detection of cancerous lesions on histological lung slides stained by hematoxylin and eosin (H&E). Our method comprises four steps: 1) cascaded graph-based sparse PCA, 2) PCA binary hashing, 3) block-wise histograms, and 4) support vector machine (SVM) classification. In our proposed architecture, graph-based sparse PCA is employed to learn the filter banks of the multiple stages of a convolutional network. This is followed by PCA hashing and block histograms for indexing and pooling. The meaningful features extracted from this GS-PCA are then fed to an SVM classifier. We evaluate the performance of the proposed algorithm on H&E slides obtained from an inducible K-rasG12D lung cancer mouse model using precision/recall rates, F-score, Tanimoto coefficient, and area under the curve (AUC) of the receiver operator characteristic (ROC) and show that our algorithm is efficient and provides improved detection accuracy compared to existing algorithms.

</p>
</details>

<details><summary><b>VACA: Design of Variational Graph Autoencoders for Interventional and Counterfactual Queries</b>
<a href="https://arxiv.org/abs/2110.14690">arxiv:2110.14690</a>
&#x1F4C8; 2 <br>
<p>Pablo Sanchez-Martin, Miriam Rateike, Isabel Valera</p></summary>
<p>

**Abstract:** In this paper, we introduce VACA, a novel class of variational graph autoencoders for causal inference in the absence of hidden confounders, when only observational data and the causal graph are available. Without making any parametric assumptions, VACA mimics the necessary properties of a Structural Causal Model (SCM) to provide a flexible and practical framework for approximating interventions (do-operator) and abduction-action-prediction steps. As a result, and as shown by our empirical results, VACA accurately approximates the interventional and counterfactual distributions on diverse SCMs. Finally, we apply VACA to evaluate counterfactual fairness in fair classification problems, as well as to learn fair classifiers without compromising performance.

</p>
</details>

<details><summary><b>(Almost) Free Incentivized Exploration from Decentralized Learning Agents</b>
<a href="https://arxiv.org/abs/2110.14628">arxiv:2110.14628</a>
&#x1F4C8; 2 <br>
<p>Chengshuai Shi, Haifeng Xu, Wei Xiong, Cong Shen</p></summary>
<p>

**Abstract:** Incentivized exploration in multi-armed bandits (MAB) has witnessed increasing interests and many progresses in recent years, where a principal offers bonuses to agents to do explorations on her behalf. However, almost all existing studies are confined to temporary myopic agents. In this work, we break this barrier and study incentivized exploration with multiple and long-term strategic agents, who have more complicated behaviors that often appear in real-world applications. An important observation of this work is that strategic agents' intrinsic needs of learning benefit (instead of harming) the principal's explorations by providing "free pulls". Moreover, it turns out that increasing the population of agents significantly lowers the principal's burden of incentivizing. The key and somewhat surprising insight revealed from our results is that when there are sufficiently many learning agents involved, the exploration process of the principal can be (almost) free. Our main results are built upon three novel components which may be of independent interest: (1) a simple yet provably effective incentive-provision strategy; (2) a carefully crafted best arm identification algorithm for rewards aggregated under unequal confidences; (3) a high-probability finite-time lower bound of UCB algorithms. Experimental results are provided to complement the theoretical analysis.

</p>
</details>

<details><summary><b>Heterogeneous Multi-player Multi-armed Bandits: Closing the Gap and Generalization</b>
<a href="https://arxiv.org/abs/2110.14622">arxiv:2110.14622</a>
&#x1F4C8; 2 <br>
<p>Chengshuai Shi, Wei Xiong, Cong Shen, Jing Yang</p></summary>
<p>

**Abstract:** Despite the significant interests and many progresses in decentralized multi-player multi-armed bandits (MP-MAB) problems in recent years, the regret gap to the natural centralized lower bound in the heterogeneous MP-MAB setting remains open. In this paper, we propose BEACON -- Batched Exploration with Adaptive COmmunicatioN -- that closes this gap. BEACON accomplishes this goal with novel contributions in implicit communication and efficient exploration. For the former, we propose a novel adaptive differential communication (ADC) design that significantly improves the implicit communication efficiency. For the latter, a carefully crafted batched exploration scheme is developed to enable incorporation of the combinatorial upper confidence bound (CUCB) principle. We then generalize the existing linear-reward MP-MAB problems, where the system reward is always the sum of individually collected rewards, to a new MP-MAB problem where the system reward is a general (nonlinear) function of individual rewards. We extend BEACON to solve this problem and prove a logarithmic regret. BEACON bridges the algorithm design and regret analysis of combinatorial MAB (CMAB) and MP-MAB, two largely disjointed areas in MAB, and the results in this paper suggest that this previously ignored connection is worth further investigation.

</p>
</details>

<details><summary><b>TA-Net: Topology-Aware Network for Gland Segmentation</b>
<a href="https://arxiv.org/abs/2110.14593">arxiv:2110.14593</a>
&#x1F4C8; 2 <br>
<p>Haotian Wang, Min Xian, Aleksandar Vakanski</p></summary>
<p>

**Abstract:** Gland segmentation is a critical step to quantitatively assess the morphology of glands in histopathology image analysis. However, it is challenging to separate densely clustered glands accurately. Existing deep learning-based approaches attempted to use contour-based techniques to alleviate this issue but only achieved limited success. To address this challenge, we propose a novel topology-aware network (TA-Net) to accurately separate densely clustered and severely deformed glands. The proposed TA-Net has a multitask learning architecture and enhances the generalization of gland segmentation by learning shared representation from two tasks: instance segmentation and gland topology estimation. The proposed topology loss computes gland topology using gland skeletons and markers. It drives the network to generate segmentation results that comply with the true gland topology. We validate the proposed approach on the GlaS and CRAG datasets using three quantitative metrics, F1-score, object-level Dice coefficient, and object-level Hausdorff distance. Extensive experiments demonstrate that TA-Net achieves state-of-the-art performance on the two datasets. TA-Net outperforms other approaches in the presence of densely clustered glands.

</p>
</details>

<details><summary><b>Deep learning via message passing algorithms based on belief propagation</b>
<a href="https://arxiv.org/abs/2110.14583">arxiv:2110.14583</a>
&#x1F4C8; 2 <br>
<p>Carlo Lucibello, Fabrizio Pittorino, Gabriele Perugini, Riccardo Zecchina</p></summary>
<p>

**Abstract:** Message-passing algorithms based on the Belief Propagation (BP) equations constitute a well-known distributed computational scheme. It is exact on tree-like graphical models and has also proven to be effective in many problems defined on graphs with loops (from inference to optimization, from signal processing to clustering). The BP-based scheme is fundamentally different from stochastic gradient descent (SGD), on which the current success of deep networks is based. In this paper, we present and adapt to mini-batch training on GPUs a family of BP-based message-passing algorithms with a reinforcement field that biases distributions towards locally entropic solutions. These algorithms are capable of training multi-layer neural networks with discrete weights and activations with performance comparable to SGD-inspired heuristics (BinaryNet) and are naturally well-adapted to continual learning. Furthermore, using these algorithms to estimate the marginals of the weights allows us to make approximate Bayesian predictions that have higher accuracy than point-wise solutions.

</p>
</details>

<details><summary><b>DreamerPro: Reconstruction-Free Model-Based Reinforcement Learning with Prototypical Representations</b>
<a href="https://arxiv.org/abs/2110.14565">arxiv:2110.14565</a>
&#x1F4C8; 2 <br>
<p>Fei Deng, Ingook Jang, Sungjin Ahn</p></summary>
<p>

**Abstract:** Top-performing Model-Based Reinforcement Learning (MBRL) agents, such as Dreamer, learn the world model by reconstructing the image observations. Hence, they often fail to discard task-irrelevant details and struggle to handle visual distractions. To address this issue, previous work has proposed to contrastively learn the world model, but the performance tends to be inferior in the absence of distractions. In this paper, we seek to enhance robustness to distractions for MBRL agents. Specifically, we consider incorporating prototypical representations, which have yielded more accurate and robust results than contrastive approaches in computer vision. However, it remains elusive how prototypical representations can benefit temporal dynamics learning in MBRL, since they treat each image independently without capturing temporal structures. To this end, we propose to learn the prototypes from the recurrent states of the world model, thereby distilling temporal structures from past observations and actions into the prototypes. The resulting model, DreamerPro, successfully combines Dreamer with prototypes, making large performance gains on the DeepMind Control suite both in the standard setting and when there are complex background distractions. Code available at https://github.com/fdeng18/dreamer-pro .

</p>
</details>

<details><summary><b>Streaming Generalized Canonical Polyadic Tensor Decompositions</b>
<a href="https://arxiv.org/abs/2110.14514">arxiv:2110.14514</a>
&#x1F4C8; 2 <br>
<p>Eric Phipps, Nick Johnson, Tamara G. Kolda</p></summary>
<p>

**Abstract:** In this paper, we develop a method which we call OnlineGCP for computing the Generalized Canonical Polyadic (GCP) tensor decomposition of streaming data. GCP differs from traditional canonical polyadic (CP) tensor decompositions as it allows for arbitrary objective functions which the CP model attempts to minimize. This approach can provide better fits and more interpretable models when the observed tensor data is strongly non-Gaussian. In the streaming case, tensor data is gradually observed over time and the algorithm must incrementally update a GCP factorization with limited access to prior data. In this work, we extend the GCP formalism to the streaming context by deriving a GCP optimization problem to be solved as new tensor data is observed, formulate a tunable history term to balance reconstruction of recently observed data with data observed in the past, develop a scalable solution strategy based on segregated solves using stochastic gradient descent methods, describe a software implementation that provides performance and portability to contemporary CPU and GPU architectures and integrates with Matlab for enhanced useability, and demonstrate the utility and performance of the approach and software on several synthetic and real tensor data sets.

</p>
</details>

<details><summary><b>Finding Regions of Heterogeneity in Decision-Making via Expected Conditional Covariance</b>
<a href="https://arxiv.org/abs/2110.14508">arxiv:2110.14508</a>
&#x1F4C8; 2 <br>
<p>Justin Lim, Christina X Ji, Michael Oberst, Saul Blecker, Leora Horwitz, David Sontag</p></summary>
<p>

**Abstract:** Individuals often make different decisions when faced with the same context, due to personal preferences and background. For instance, judges may vary in their leniency towards certain drug-related offenses, and doctors may vary in their preference for how to start treatment for certain types of patients. With these examples in mind, we present an algorithm for identifying types of contexts (e.g., types of cases or patients) with high inter-decision-maker disagreement. We formalize this as a causal inference problem, seeking a region where the assignment of decision-maker has a large causal effect on the decision. Our algorithm finds such a region by maximizing an empirical objective, and we give a generalization bound for its performance. In a semi-synthetic experiment, we show that our algorithm recovers the correct region of heterogeneity accurately compared to baselines. Finally, we apply our algorithm to real-world healthcare datasets, recovering variation that aligns with existing clinical knowledge.

</p>
</details>

<details><summary><b>An Arbitrary Scale Super-Resolution Approach for 3-Dimensional Magnetic Resonance Image using Implicit Neural Representation</b>
<a href="https://arxiv.org/abs/2110.14476">arxiv:2110.14476</a>
&#x1F4C8; 2 <br>
<p>Qing Wu, Yuwei Li, Yawen Sun, Yan Zhou, Hongjiang Wei, Jingyi Yu, Yuyao Zhang</p></summary>
<p>

**Abstract:** High Resolution (HR) medical images provide rich anatomical structure details to facilitate early and accurate diagnosis. In MRI, restricted by hardware capacity, scan time, and patient cooperation ability, isotropic 3D HR image acquisition typically requests long scan time and, results in small spatial coverage and low SNR. Recent studies showed that, with deep convolutional neural networks, isotropic HR MR images could be recovered from low-resolution (LR) input via single image super-resolution (SISR) algorithms. However, most existing SISR methods tend to approach a scale-specific projection between LR and HR images, thus these methods can only deal with a fixed up-sampling rate. For achieving different up-sampling rates, multiple SR networks have to be built up respectively, which is very time-consuming and resource-intensive. In this paper, we propose ArSSR, an Arbitrary Scale Super-Resolution approach for recovering 3D HR MR images. In the ArSSR model, the reconstruction of HR images with different up-scaling rates is defined as learning a continuous implicit voxel function from the observed LR images. Then the SR task is converted to represent the implicit voxel function via deep neural networks from a set of paired HR-LR training examples. The ArSSR model consists of an encoder network and a decoder network. Specifically, the convolutional encoder network is to extract feature maps from the LR input images and the fully-connected decoder network is to approximate the implicit voxel function. Due to the continuity of the learned function, a single ArSSR model can achieve arbitrary up-sampling rate reconstruction of HR images from any input LR image after training. Experimental results on three datasets show that the ArSSR model can achieve state-of-the-art SR performance for 3D HR MR image reconstruction while using a single trained model to achieve arbitrary up-sampling scales.

</p>
</details>

<details><summary><b>Failure-averse Active Learning for Physics-constrained Systems</b>
<a href="https://arxiv.org/abs/2110.14443">arxiv:2110.14443</a>
&#x1F4C8; 2 <br>
<p>Cheolhei Lee, Xing Wang, Jianguo Wu, Xiaowei Yue</p></summary>
<p>

**Abstract:** Active learning is a subfield of machine learning that is devised for design and modeling of systems with highly expensive sampling costs. Industrial and engineering systems are generally subject to physics constraints that may induce fatal failures when they are violated, while such constraints are frequently underestimated in active learning. In this paper, we develop a novel active learning method that avoids failures considering implicit physics constraints that govern the system. The proposed approach is driven by two tasks: the safe variance reduction explores the safe region to reduce the variance of the target model, and the safe region expansion aims to extend the explorable region exploiting the probabilistic model of constraints. The global acquisition function is devised to judiciously optimize acquisition functions of two tasks, and its theoretical properties are provided. The proposed method is applied to the composite fuselage assembly process with consideration of material failure using the Tsai-wu criterion, and it is able to achieve zero-failure without the knowledge of explicit failure regions.

</p>
</details>

<details><summary><b>Exploring single-song autoencoding schemes for audio-based music structure analysis</b>
<a href="https://arxiv.org/abs/2110.14437">arxiv:2110.14437</a>
&#x1F4C8; 2 <br>
<p>Axel Marmoret, J√©r√©my E. Cohen, Fr√©d√©ric Bimbot</p></summary>
<p>

**Abstract:** The ability of deep neural networks to learn complex data relations and representations is established nowadays, but it generally relies on large sets of training data. This work explores a "piece-specific" autoencoding scheme, in which a low-dimensional autoencoder is trained to learn a latent/compressed representation specific to a given song, which can then be used to infer the song structure. Such a model does not rely on supervision nor annotations, which are well-known to be tedious to collect and often ambiguous in Music Structure Analysis. We report that the proposed unsupervised auto-encoding scheme achieves the level of performance of supervised state-of-the-art methods with 3 seconds tolerance when using a Log Mel spectrogram representation on the RWC-Pop dataset.

</p>
</details>

<details><summary><b>The ODE Method for Asymptotic Statistics in Stochastic Approximation and Reinforcement Learning</b>
<a href="https://arxiv.org/abs/2110.14427">arxiv:2110.14427</a>
&#x1F4C8; 2 <br>
<p>Vivek Borkar, Shuhang Chen, Adithya Devraj, Ioannis Kontoyiannis, Sean Meyn</p></summary>
<p>

**Abstract:** The paper concerns convergence and asymptotic statistics for stochastic approximation driven by Markovian noise: $$ Œ∏_{n+1}= Œ∏_n + Œ±_{n + 1} f(Œ∏_n, Œ¶_{n+1}) \,,\quad n\ge 0, $$ in which each $Œ∏_n\in\Re^d$, $ \{ Œ¶_n \}$ is a Markov chain on a general state space X with stationary distribution $œÄ$, and $f:\Re^d\times \text{X} \to\Re^d$. In addition to standard Lipschitz bounds on $f$, and conditions on the vanishing step-size sequence $\{Œ±_n\}$, it is assumed that the associated ODE is globally asymptotically stable with stationary point denoted $Œ∏^*$, where $\bar f(Œ∏)=E[f(Œ∏,Œ¶)]$ with $Œ¶\simœÄ$. Moreover, the ODE@$\infty$ defined with respect to the vector field, $$ \bar f_\infty(Œ∏):= \lim_{r\to\infty} r^{-1} \bar f(rŒ∏) \,,\qquad Œ∏\in\Re^d, $$ is asymptotically stable. The main contributions are summarized as follows:
  (i) The sequence $Œ∏$ is convergent if $Œ¶$ is geometrically ergodic, and subject to compatible bounds on $f$.
  The remaining results are established under a stronger assumption on the Markov chain: A slightly weaker version of the Donsker-Varadhan Lyapunov drift condition known as (DV3).
  (ii) A Lyapunov function is constructed for the joint process $\{Œ∏_n,Œ¶_n\}$ that implies convergence of $\{ Œ∏_n\}$ in $L_4$.
  (iii) A functional CLT is established, as well as the usual one-dimensional CLT for the normalized error $z_n:= (Œ∏_n-Œ∏^*)/\sqrt{Œ±_n}$. Moment bounds combined with the CLT imply convergence of the normalized covariance, $$ \lim_{n \to \infty} E [ z_n z_n^T ] = Œ£_Œ∏, $$ where $Œ£_Œ∏$ is the asymptotic covariance appearing in the CLT.
  (iv) An example is provided where the Markov chain $Œ¶$ is geometrically ergodic but it does not satisfy (DV3). While the algorithm is convergent, the second moment is unbounded.

</p>
</details>

<details><summary><b>Enhancing Reinforcement Learning with discrete interfaces to learn the Dyck Language</b>
<a href="https://arxiv.org/abs/2110.14350">arxiv:2110.14350</a>
&#x1F4C8; 2 <br>
<p>Florian Dietz, Dietrich Klakow</p></summary>
<p>

**Abstract:** Even though most interfaces in the real world are discrete, no efficient way exists to train neural networks to make use of them, yet. We enhance an Interaction Network (a Reinforcement Learning architecture) with discrete interfaces and train it on the generalized Dyck language. This task requires an understanding of hierarchical structures to solve, and has long proven difficult for neural networks. We provide the first solution based on learning to use discrete data structures. We encountered unexpected anomalous behavior during training, and utilized pre-training based on execution traces to overcome them. The resulting model is very small and fast, and generalizes to sequences that are an entire order of magnitude longer than the training data.

</p>
</details>

<details><summary><b>Active-LATHE: An Active Learning Algorithm for Boosting the Error Exponent for Learning Homogeneous Ising Trees</b>
<a href="https://arxiv.org/abs/2110.14341">arxiv:2110.14341</a>
&#x1F4C8; 2 <br>
<p>Fengzhuo Zhang, Anshoo Tandon, Vincent Y. F. Tan</p></summary>
<p>

**Abstract:** The Chow-Liu algorithm (IEEE Trans.~Inform.~Theory, 1968) has been a mainstay for the learning of tree-structured graphical models from i.i.d.\ sampled data vectors. Its theoretical properties have been well-studied and are well-understood. In this paper, we focus on the class of trees that are arguably even more fundamental, namely {\em homogeneous} trees in which each pair of nodes that forms an edge has the same correlation $œÅ$. We ask whether we are able to further reduce the error probability of learning the structure of the homogeneous tree model when {\em active learning} or {\em active sampling of nodes or variables} is allowed. Our figure of merit is the {\em error exponent}, which quantifies the exponential rate of decay of the error probability with an increasing number of data samples. At first sight, an improvement in the error exponent seems impossible, as all the edges are statistically identical. We design and analyze an algorithm Active Learning Algorithm for Trees with Homogeneous Edge (Active-LATHE), which surprisingly boosts the error exponent by at least 40\% when $œÅ$ is at least $0.8$. For all other values of $œÅ$, we also observe commensurate, but more modest, improvements in the error exponent. Our analysis hinges on judiciously exploiting the minute but detectable statistical variation of the samples to allocate more data to parts of the graph in which we are less confident of being correct.

</p>
</details>

<details><summary><b>GACAN: Graph Attention-Convolution-Attention Networks for Traffic Forecasting Based on Multi-granularity Time Series</b>
<a href="https://arxiv.org/abs/2110.14331">arxiv:2110.14331</a>
&#x1F4C8; 2 <br>
<p>Sikai Zhang, Hong Zheng, Hongyi Su, Bo Yan, Jiamou Liu, Song Yang</p></summary>
<p>

**Abstract:** Traffic forecasting is an integral part of intelligent transportation systems (ITS). Achieving a high prediction accuracy is a challenging task due to a high level of dynamics and complex spatial-temporal dependency of road networks. For this task, we propose Graph Attention-Convolution-Attention Networks (GACAN). The model uses a novel Att-Conv-Att (ACA) block which contains two graph attention layers and one spectral-based GCN layer sandwiched in between. The graph attention layers are meant to capture temporal features while the spectral-based GCN layer is meant to capture spatial features. The main novelty of the model is the integration of time series of four different time granularities: the original time series, together with hourly, daily, and weekly time series. Unlike previous work that used multi-granularity time series by handling every time series separately, GACAN combines the outcome of processing all time series after each graph attention layer. Thus, the effects of different time granularities are integrated throughout the model. We perform a series of experiments on three real-world datasets. The experimental results verify the advantage of using multi-granularity time series and that the proposed GACAN model outperforms the state-of-the-art baselines.

</p>
</details>

<details><summary><b>Learning Stable Deep Dynamics Models for Partially Observed or Delayed Dynamical Systems</b>
<a href="https://arxiv.org/abs/2110.14296">arxiv:2110.14296</a>
&#x1F4C8; 2 <br>
<p>Andreas Schlaginhaufen, Philippe Wenk, Andreas Krause, Florian D√∂rfler</p></summary>
<p>

**Abstract:** Learning how complex dynamical systems evolve over time is a key challenge in system identification. For safety critical systems, it is often crucial that the learned model is guaranteed to converge to some equilibrium point. To this end, neural ODEs regularized with neural Lyapunov functions are a promising approach when states are fully observed. For practical applications however, partial observations are the norm. As we will demonstrate, initialization of unobserved augmented states can become a key problem for neural ODEs. To alleviate this issue, we propose to augment the system's state with its history. Inspired by state augmentation in discrete-time systems, we thus obtain neural delay differential equations. Based on classical time delay stability analysis, we then show how to ensure stability of the learned models, and theoretically analyze our approach. Our experiments demonstrate its applicability to stable system identification of partially observed systems and learning a stabilizing feedback policy in delayed feedback control.

</p>
</details>

<details><summary><b>MIRA: Multihop Relation Prediction in Temporal Knowledge Graphs</b>
<a href="https://arxiv.org/abs/2110.14284">arxiv:2110.14284</a>
&#x1F4C8; 2 <br>
<p>Christian M. M. Frey, Yunpu Ma, Matthias Schubert</p></summary>
<p>

**Abstract:** In knowledge graph reasoning, we observe a trend to analyze temporal data evolving over time. The additional temporal dimension is attached to facts in a knowledge base resulting in quadruples between entities such as (Nintendo, released, Super Mario, Sep-13-1985), where the relation between two entities is associated to a specific time interval or point in time. Multi-hop reasoning on inferred subgraphs connecting entities within a knowledge graph can be formulated as a reinforcement learning task where the agent sequentially performs inference upon the explored subgraph. The task in this work is to infer the predicate between a subject and an object entity, i.e., (subject, ?, object, time), being valid at a certain timestamp or time interval. Given query entities, our agent starts to gather temporal relevant information about the neighborhood of the subject and object. The encoding of information about the explored graph structures is referred to as fingerprints. Subsequently, we use the two fingerprints as input to a Q-Network. Our agent decides sequentially which relational type needs to be explored next expanding the local subgraphs of the query entities in order to find promising paths between them. The evaluation shows that the proposed method not only yields results being in line with state-of-the-art embedding algorithms for temporal Knowledge Graphs (tKG), but we also gain information about the relevant structures between subjects and objects.

</p>
</details>

<details><summary><b>Learning Domain Invariant Representations in Goal-conditioned Block MDPs</b>
<a href="https://arxiv.org/abs/2110.14248">arxiv:2110.14248</a>
&#x1F4C8; 2 <br>
<p>Beining Han, Chongyi Zheng, Harris Chan, Keiran Paster, Michael R. Zhang, Jimmy Ba</p></summary>
<p>

**Abstract:** Deep Reinforcement Learning (RL) is successful in solving many complex Markov Decision Processes (MDPs) problems. However, agents often face unanticipated environmental changes after deployment in the real world. These changes are often spurious and unrelated to the underlying problem, such as background shifts for visual input agents. Unfortunately, deep RL policies are usually sensitive to these changes and fail to act robustly against them. This resembles the problem of domain generalization in supervised learning. In this work, we study this problem for goal-conditioned RL agents. We propose a theoretical framework in the Block MDP setting that characterizes the generalizability of goal-conditioned policies to new environments. Under this framework, we develop a practical method PA-SkewFit that enhances domain generalization. The empirical evaluation shows that our goal-conditioned RL agent can perform well in various unseen test environments, improving by 50% over baselines.

</p>
</details>

<details><summary><b>Learning Diverse Policies in MOBA Games via Macro-Goals</b>
<a href="https://arxiv.org/abs/2110.14221">arxiv:2110.14221</a>
&#x1F4C8; 2 <br>
<p>Yiming Gao, Bei Shi, Xueying Du, Liang Wang, Guangwei Chen, Zhenjie Lian, Fuhao Qiu, Guoan Han, Weixuan Wang, Deheng Ye, Qiang Fu, Wei Yang, Lanxiao Huang</p></summary>
<p>

**Abstract:** Recently, many researchers have made successful progress in building the AI systems for MOBA-game-playing with deep reinforcement learning, such as on Dota 2 and Honor of Kings. Even though these AI systems have achieved or even exceeded human-level performance, they still suffer from the lack of policy diversity. In this paper, we propose a novel Macro-Goals Guided framework, called MGG, to learn diverse policies in MOBA games. MGG abstracts strategies as macro-goals from human demonstrations and trains a Meta-Controller to predict these macro-goals. To enhance policy diversity, MGG samples macro-goals from the Meta-Controller prediction and guides the training process towards these goals. Experimental results on the typical MOBA game Honor of Kings demonstrate that MGG can execute diverse policies in different matches and lineups, and also outperform the state-of-the-art methods over 102 heroes.

</p>
</details>

<details><summary><b>Federated Linear Contextual Bandits</b>
<a href="https://arxiv.org/abs/2110.14177">arxiv:2110.14177</a>
&#x1F4C8; 2 <br>
<p>Ruiquan Huang, Weiqiang Wu, Jing Yang, Cong Shen</p></summary>
<p>

**Abstract:** This paper presents a novel federated linear contextual bandits model, where individual clients face different $K$-armed stochastic bandits coupled through common global parameters. By leveraging the geometric structure of the linear rewards, a collaborative algorithm called Fed-PE is proposed to cope with the heterogeneity across clients without exchanging local feature vectors or raw data. Fed-PE relies on a novel multi-client G-optimal design, and achieves near-optimal regrets for both disjoint and shared parameter cases with logarithmic communication costs. In addition, a new concept called collinearly-dependent policies is introduced, based on which a tight minimax regret lower bound for the disjoint parameter case is derived. Experiments demonstrate the effectiveness of the proposed algorithms on both synthetic and real-world datasets.

</p>
</details>

<details><summary><b>Influential Papers in Artificial Intelligence and Paediatrics: Assessing RPYS by Experts Review</b>
<a href="https://arxiv.org/abs/2111.06852">arxiv:2111.06852</a>
&#x1F4C8; 1 <br>
<p>Peter Kokol, Jernej Zavr≈°nik, Helena Bla≈æun Vo≈°ner</p></summary>
<p>

**Abstract:** The use of artificial intelligence in paediatrics has vastly increased in the last few years. Interestingly, no historical bibliometric study analysing the knowledge development in this specific paediatric field has been performed yet, thus our study aimed to close this gap. References Publication Years Spectrography (RPYS), more precisely CitedReferenceExplorer (CRE) software tool was employed to achieve this aim. We identified 28 influential papers and domain experts validation showed that both, the RPYS method and CRE tool performed adequately in the identification process.

</p>
</details>

<details><summary><b>A multi-task learning-based optimization approach for finding diverse sets of material microstructures with desired properties and its application to texture optimization</b>
<a href="https://arxiv.org/abs/2111.00916">arxiv:2111.00916</a>
&#x1F4C8; 1 <br>
<p>Tarek Iraki, Lukas Morand, Johannes Dornheim, Norbert Link, Dirk Helm</p></summary>
<p>

**Abstract:** The optimization along the chain processing-structure-properties-performance is one of the core objectives in data-driven materials science. In this sense, processes are supposed to manufacture workpieces with targeted material microstructures. These microstructures are defined by the material properties of interest and identifying them is a question of materials design. In the present paper, we addresse this issue and introduce a generic multi-task learning-based optimization approach. The approach enables the identification of sets of highly diverse microstructures for given desired properties and corresponding tolerances. Basically, the approach consists of an optimization algorithm that interacts with a machine learning model that combines multi-task learning with siamese neural networks. The resulting model (1) relates microstructures and properties, (2) estimates the likelihood of a microstructure of being producible, and (3) performs a distance preserving microstructure feature extraction in order to generate a lower dimensional latent feature space to enable efficient optimization. The proposed approach is applied on a crystallographic texture optimization problem for rolled steel sheets given desired properties.

</p>
</details>

<details><summary><b>Earning Sans Learning: Noisy Decision-Making and Labor Supply on Gig Economy Platforms</b>
<a href="https://arxiv.org/abs/2111.00002">arxiv:2111.00002</a>
&#x1F4C8; 1 <br>
<p>Daniel Freund, Chamsi Hssaine</p></summary>
<p>

**Abstract:** We study a gig economy platform's problem of finding optimal compensation schemes when faced with workers who myopically base their participation decisions on limited information with respect to their earnings. The stylized model we consider captures two key, related features absent from prior work on the operations of on-demand service platforms: (i) workers' lack of information regarding the distribution from which their earnings are drawn and (ii) worker decisions that are sensitive to variability in earnings. Despite its stylized nature, our model induces a complex stochastic optimization problem whose natural fluid relaxation is also a priori intractable. Nevertheless, we uncover a surprising structural property of the relaxation that allows us to design a tractable, fast-converging heuristic policy that is asymptotically optimal amongst the space of all policies that fulfill a fairness property. In doing so, via both theory and extensive simulations, we uncover phenomena that may arise when earnings are volatile and hard to predict, as both the empirical literature and our own data-driven observations suggest may be prevalent on gig economy platforms.

</p>
</details>

<details><summary><b>Towards Intelligent Load Balancing in Data Centers</b>
<a href="https://arxiv.org/abs/2110.15788">arxiv:2110.15788</a>
&#x1F4C8; 1 <br>
<p>Zhiyuan Yao, Yoann Desmouceaux, Mark Townsley, Thomas Heide Clausen</p></summary>
<p>

**Abstract:** Network load balancers are important components in data centers to provide scalable services. Workload distribution algorithms are based on heuristics, e.g., Equal-Cost Multi-Path (ECMP), Weighted-Cost Multi-Path (WCMP) or naive machine learning (ML) algorithms, e.g., ridge regression. Advanced ML-based approaches help achieve performance gain in different networking and system problems. However, it is challenging to apply ML algorithms on networking problems in real-life systems. It requires domain knowledge to collect features from low-latency, high-throughput, and scalable networking systems, which are dynamic and heterogenous. This paper proposes Aquarius to bridge the gap between ML and networking systems and demonstrates its usage in the context of network load balancers. This paper demonstrates its ability of conducting both offline data analysis and online model deployment in realistic systems. The results show that the ML model trained and deployed using Aquarius improves load balancing performance yet they also reveals more challenges to be resolved to apply ML for networking systems.

</p>
</details>

<details><summary><b>A Novel Sleep Stage Classification Using CNN Generated by an Efficient Neural Architecture Search with a New Data Processing Trick</b>
<a href="https://arxiv.org/abs/2110.15277">arxiv:2110.15277</a>
&#x1F4C8; 1 <br>
<p>Yu Xue, Ziming Yuan, Adam Slowik</p></summary>
<p>

**Abstract:** With the development of automatic sleep stage classification (ASSC) techniques, many classical methods such as k-means, decision tree, and SVM have been used in automatic sleep stage classification. However, few methods explore deep learning on ASSC. Meanwhile, most deep learning methods require extensive expertise and suffer from a mass of handcrafted steps which are time-consuming especially when dealing with multi-classification tasks. In this paper, we propose an efficient five-sleep-stage classification method using convolutional neural networks (CNNs) with a novel data processing trick and we design neural architecture search (NAS) technique based on genetic algorithm (GA), NAS-G, to search for the best CNN architecture. Firstly, we attach each kernel with an adaptive coefficient to enhance the signal processing of the inputs. This can enhance the propagation of informative features and suppress the propagation of useless features in the early stage of the network. Then, we make full use of GA's heuristic search and the advantage of no need for the gradient to search for the best architecture of CNN. This can achieve a CNN with better performance than a handcrafted one in a large search space at the minimum cost. We verify the convergence of our data processing trick and compare the performance of traditional CNNs before and after using our trick. Meanwhile, we compare the performance between the CNN generated through NAS-G and the traditional CNNs with our trick. The experiments demonstrate that the convergence of CNNs with data processing trick is faster than without data processing trick and the CNN with data processing trick generated by NAS-G outperforms the handcrafted counterparts that use the data processing trick too.

</p>
</details>

<details><summary><b>Generalizability of density functionals learned from differentiable programming on weakly correlated spin-polarized systems</b>
<a href="https://arxiv.org/abs/2110.14846">arxiv:2110.14846</a>
&#x1F4C8; 1 <br>
<p>Bhupalee Kalita, Ryan Pederson, Jielun Chen, Li Li, Kieron Burke</p></summary>
<p>

**Abstract:** Kohn-Sham regularizer (KSR) is a machine learning approach that optimizes a physics-informed exchange-correlation functional within a differentiable Kohn-Sham density functional theory framework. We evaluate the generalizability of KSR by training on atomic systems and testing on molecules at equilibrium. We propose a spin-polarized version of KSR with local, semilocal, and nonlocal approximations for the exchange-correlation functional. The generalization error from our semilocal approximation is comparable to other differentiable approaches. Our nonlocal functional outperforms any existing machine learning functionals by predicting the ground-state energies of the test systems with a mean absolute error of 2.7 milli-Hartrees.

</p>
</details>

<details><summary><b>Telling Creative Stories Using Generative Visual Aids</b>
<a href="https://arxiv.org/abs/2110.14810">arxiv:2110.14810</a>
&#x1F4C8; 1 <br>
<p>Safinah Ali, Devi Parikh</p></summary>
<p>

**Abstract:** Can visual artworks created using generative visual algorithms inspire human creativity in storytelling? We asked writers to write creative stories from a starting prompt, and provided them with visuals created by generative AI models from the same prompt. Compared to a control group, writers who used the visuals as story writing aid wrote significantly more creative, original, complete and visualizable stories, and found the task more fun. Of the generative algorithms used (BigGAN, VQGAN, DALL-E, CLIPDraw), VQGAN was the most preferred. The control group that did not view the visuals did significantly better in integrating the starting prompts. Findings indicate that cross modality inputs by AI can benefit divergent aspects of creativity in human-AI co-creation, but hinders convergent thinking.

</p>
</details>

<details><summary><b>Designing Machine Learning Surrogates using Outputs of Molecular Dynamics Simulations as Soft Labels</b>
<a href="https://arxiv.org/abs/2110.14714">arxiv:2110.14714</a>
&#x1F4C8; 1 <br>
<p>J. C. S. Kadupitiya, Nasim Anousheh, Vikram Jadhao</p></summary>
<p>

**Abstract:** Molecular dynamics simulations are powerful tools to extract the microscopic mechanisms characterizing the properties of soft materials. We recently introduced machine learning surrogates for molecular dynamics simulations of soft materials and demonstrated that artificial neural network based regression models can successfully predict the relationships between the input material attributes and the simulation outputs. Here, we show that statistical uncertainties associated with the outputs of molecular dynamics simulations can be utilized to train artificial neural networks and design machine learning surrogates with higher accuracy and generalizability. We design soft labels for the simulation outputs by incorporating the uncertainties in the estimated average output quantities, and introduce a modified loss function that leverages these soft labels during training to significantly reduce the surrogate prediction error for input systems in the unseen test data. The approach is illustrated with the design of a surrogate for molecular dynamics simulations of confined electrolytes to predict the complex relationship between the input electrolyte attributes and the output ionic structure. The surrogate predictions for the ionic density profiles show excellent agreement with the ground truth results produced using molecular dynamics simulations. The high accuracy and small inference times associated with the surrogate predictions provide quick access to quantities derived using the number density profiles and facilitate rapid sensitivity analysis.

</p>
</details>

<details><summary><b>Alternating Learning Approach for Variational Networks and Undersampling Pattern in Parallel MRI Applications</b>
<a href="https://arxiv.org/abs/2110.14703">arxiv:2110.14703</a>
&#x1F4C8; 1 <br>
<p>Marcelo V. W. Zibetti, Florian Knoll, Ravinder R. Regatte</p></summary>
<p>

**Abstract:** Purpose: To propose an alternating learning approach to learn the sampling pattern (SP) and the parameters of variational networks (VN) in accelerated parallel magnetic resonance imaging (MRI). Methods: The approach alternates between improving the SP, using bias-accelerated subset selection, and improving parameters of the VN, using ADAM with monotonicity verification. The algorithm learns an effective pair: an SP that captures fewer k-space samples generating undersampling artifacts that are removed by the VN reconstruction. The proposed approach was tested for stability and convergence, considering different initial SPs. The quality of the VNs and SPs was compared against other approaches, including joint learning methods and VN learning with fixed variable density Poisson-disc SPs, using two different datasets and different acceleration factors (AF). Results: The root mean squared error (RMSE) improvements ranged from 14.9% to 51.2% considering AF from 2 to 20 in the tested brain and knee joint datasets when compared to the other approaches. The proposed approach has shown stable convergence, obtaining similar SPs with the same RMSE under different initial conditions. Conclusion: The proposed approach was stable and learned effective SPs with the corresponding VN parameters that produce images with better quality than other approaches, improving accelerated parallel MRI applications.

</p>
</details>

<details><summary><b>Stabilising viscous extensional flows using Reinforcement Learning</b>
<a href="https://arxiv.org/abs/2110.14677">arxiv:2110.14677</a>
&#x1F4C8; 1 <br>
<p>Marco Vona, Eric Lauga</p></summary>
<p>

**Abstract:** The four-roll mill, wherein four identical cylinders undergo rotation of identical magnitude but alternate signs, was originally proposed by GI Taylor to create local extensional flows and study their ability to deform small liquid drops. Since an extensional flow has an unstable eigendirection, a drop located at the flow stagnation point will have a tendency to escape. This unstable dynamics can however be stabilised using, e.g., a modulation of the rotation rates of the cylinders. Here we use Reinforcement Learning, a branch of Machine Learning devoted to the optimal selection of actions based on cumulative rewards, in order to devise a stabilisation algorithm for the four-roll mill flow. The flow is modelled as the linear superposition of four two-dimensional rotlets and the drop is treated as a rigid spherical particle smaller than all other length scales in the problem. Unlike previous attempts to devise control, we take a probabilistic approach whereby speed adjustments are drawn from a probability density function whose shape is improved over time via a form of gradient ascent know as Actor-Critic method. With enough training, our algorithm is able to precisely control the drop and keep it close to the stagnation point for as long as needed. We explore the impact of the physical and learning parameters on the effectiveness of the control and demonstrate the robustness of the algorithm against thermal noise. We finally show that Reinforcement Learning can provide a control algorithm effective for all initial positions and that can be adapted to limit the magnitude of the flow extension near the position of the drop.

</p>
</details>

<details><summary><b>Fairer LP-based Online Allocation</b>
<a href="https://arxiv.org/abs/2110.14621">arxiv:2110.14621</a>
&#x1F4C8; 1 <br>
<p>Guanting Chen, Xiaocheng Li, Yinyu Ye</p></summary>
<p>

**Abstract:** In this paper, we consider a Linear Program (LP)-based online resource allocation problem where a decision maker accepts or rejects incoming customer requests irrevocably in order to maximize expected revenue given limited resources. At each time, a new order/customer/bid is revealed with a request of some resource(s) and a reward. We consider a stochastic setting where all the orders are i.i.d. sampled from an unknown distribution. Such formulation gives rise to many classic applications such as the canonical (quantity-based) network revenue management problem and the Adwords problem. Instead of focusing only on regret minimization, this paper aims to provide fairness guarantees while maintaining low regret. Our definition of fairness is that a fair online algorithm should treat similar agents/customers similarly and the decision made for similar individuals should be consistent over time. We define the fair offline solution as the analytic center of the offline optimal solution set, and define \textit{cumulative unfairness} as the cumulative deviation from the online solutions to the fair offline solution. We propose a fair algorithm that uses an interior-point LP solver and dynamically detects unfair resource spending. Our algorithm can control cumulative unfairness on the scale of order $O(\log(T))$, while maintaining the regret to be bounded without dependency on $T$. Moreover, we partially remove the nondegeneracy assumptions used in early results in the literature. This paper only requires the nondegeneracy condition for the binding constraints, and allows the existence of multiple optimal solutions.

</p>
</details>

<details><summary><b>End-to-end LSTM based estimation of volcano event epicenter localization</b>
<a href="https://arxiv.org/abs/2110.14594">arxiv:2110.14594</a>
&#x1F4C8; 1 <br>
<p>Nestor Becerra Yoma, Jorge Wuth, Andres Pinto, Nicolas de Celis, Jorge Celis, Fernando Huenupan</p></summary>
<p>

**Abstract:** In this paper, an end-to-end based LSTM scheme is proposed to address the problem of volcano event localization without any a priori model relating phase picking with localization estimation. It is worth emphasizing that automatic phase picking in volcano signals is highly inaccurate because of the short distances between the event epicenters and the seismograph stations. LSTM was chosen due to its capability to capture the dynamics of time varying signals, and to remove or add information within the memory cell state and model long-term dependencies. A brief insight into LSTM is also discussed here. The results presented in this paper show that the LSTM based architecture provided a success rate, i.e., an error smaller than 1.0Km, equal to 48.5%, which in turn is dramatically superior to the one delivered by automatic phase picking. Moreover, the proposed end-to-end LSTM based method gave a success rate 18% higher than CNN.

</p>
</details>

<details><summary><b>Active clustering for labeling training data</b>
<a href="https://arxiv.org/abs/2110.14521">arxiv:2110.14521</a>
&#x1F4C8; 1 <br>
<p>Quentin Lutz, √âlie de Panafieu, Alex Scott, Maya Stein</p></summary>
<p>

**Abstract:** Gathering training data is a key step of any supervised learning task, and it is both critical and expensive. Critical, because the quantity and quality of the training data has a high impact on the performance of the learned function. Expensive, because most practical cases rely on humans-in-the-loop to label the data. The process of determining the correct labels is much more expensive than comparing two items to see whether they belong to the same class. Thus motivated, we propose a setting for training data gathering where the human experts perform the comparatively cheap task of answering pairwise queries, and the computer groups the items into classes (which can be labeled cheaply at the very end of the process). Given the items, we consider two random models for the classes: one where the set partition they form is drawn uniformly, the other one where each item chooses its class independently following a fixed distribution. In the first model, we characterize the algorithms that minimize the average number of queries required to cluster the items and analyze their complexity. In the second model, we analyze a specific algorithm family, propose as a conjecture that they reach the minimum average number of queries and compare their performance to a random approach. We also propose solutions to handle errors or inconsistencies in the experts' answers.

</p>
</details>

<details><summary><b>Predictive Geological Mapping with Convolution Neural Network Using Statistical Data Augmentation on a 3D Model</b>
<a href="https://arxiv.org/abs/2110.14440">arxiv:2110.14440</a>
&#x1F4C8; 1 <br>
<p>Cedou Matthieu, Gloaguen Erwan, Blouin Martin, Cat√© Antoine, Paiement Jean-Philippe, Tirdad Shiva</p></summary>
<p>

**Abstract:** Airborne magnetic data are commonly used to produce preliminary geological maps. Machine learning has the potential to partly fulfill this task rapidly and objectively, as geological mapping is comparable to a semantic segmentation problem. Because this method requires a high-quality dataset, we developed a data augmentation workflow that uses a 3D geological and magnetic susceptibility model as input. The workflow uses soft-constrained Multi-Point Statistics, to create many synthetic 3D geological models, and Sequential Gaussian Simulation algorithms, to populate the models with the appropriate magnetic distribution. Then, forward modeling is used to compute the airborne magnetic responses of the synthetic models, which are associated with their counterpart surficial lithologies. A Gated Shape Convolutional Neural Network algorithm was trained on a generated synthetic dataset to perform geological mapping of airborne magnetic data and detect lithological contacts. The algorithm also provides attention maps highlighting the structures at different scales, and clustering was applied to its high-level features to do a semi-supervised segmentation of the area. The validation conducted on a portion of the synthetic dataset and data from adjacent areas shows that the methodology is suitable to segment the surficial geology using airborne magnetic data. Especially, the clustering shows a good segmentation of the magnetic anomalies into a pertinent geological map. Moreover, the first attention map isolates the structures at low scales and shows a pertinent representation of the original data. Thus, our method can be used to produce preliminary geological maps of good quality and new representations of any area where a geological and petrophysical 3D model exists, or in areas sharing the same geological context, using airborne magnetic data only.

</p>
</details>

<details><summary><b>Comprehensive learning particle swarm optimization enabled modeling framework for multi-step-ahead influenza prediction</b>
<a href="https://arxiv.org/abs/2110.14343">arxiv:2110.14343</a>
&#x1F4C8; 1 <br>
<p>Siyue Yang, Yukun Bao</p></summary>
<p>

**Abstract:** Epidemics of influenza are major public health concerns. Since influenza prediction always relies on the weekly clinical or laboratory surveillance data, typically the weekly Influenza-like illness (ILI) rate series, accurate multi-step-ahead influenza predictions using ILI series is of great importance, especially, to the potential coming influenza outbreaks. This study proposes Comprehensive Learning Particle Swarm Optimization based Machine Learning (CLPSO-ML) framework incorporating support vector regression (SVR) and multilayer perceptron (MLP) for multi-step-ahead influenza prediction. A comprehensive examination and comparison of the performance and potential of three commonly used multi-step-ahead prediction modeling strategies, including iterated strategy, direct strategy and multiple-input multiple-output (MIMO) strategy, was conducted using the weekly ILI rate series from both the Southern and Northern China. The results show that: (1) The MIMO strategy achieves the best multi-step-ahead prediction, and is potentially more adaptive for longer horizon; (2) The iterated strategy demonstrates special potentials for deriving the least time difference between the occurrence of the predicted peak value and the true peak value of an influenza outbreak; (3) For ILI in the Northern China, SVR model implemented with MIMO strategy performs best, and SVR with iterated strategy also shows remarkable performance especially during outbreak periods; while for ILI in the Southern China, both SVR and MLP models with MIMO strategy have competitive prediction performance

</p>
</details>

<details><summary><b>Tight FPT Approximation for Constrained k-Center and k-Supplier</b>
<a href="https://arxiv.org/abs/2110.14242">arxiv:2110.14242</a>
&#x1F4C8; 1 <br>
<p>Dishant Goyal, Ragesh Jaiswal</p></summary>
<p>

**Abstract:** In this work, we study a range of constrained versions of the $k$-supplier and $k$-center problems such as: capacitated, fault-tolerant, fair, etc. These problems fall under a broad framework of constrained clustering. A unified framework for constrained clustering was proposed by Ding and Xu [SODA 2015] in context of the $k$-median and $k$-means objectives. In this work, we extend this framework to the $k$-supplier and $k$-center objectives. This unified framework allows us to obtain results simultaneously for the following constrained versions of the $k$-supplier problem: $r$-gather, $r$-capacity, balanced, chromatic, fault-tolerant, strongly private, $\ell$-diversity, and fair $k$-supplier problems, with and without outliers. We obtain the following results: We give $3$ and $2$ approximation algorithms for the constrained $k$-supplier and $k$-center problems, respectively, with $\mathsf{FPT}$ running time $k^{O(k)} \cdot n^{O(1)}$, where $n = |C \cup L|$. Moreover, these approximation guarantees are tight; that is, for any constant $Œµ>0$, no algorithm can achieve $(3-Œµ)$ and $(2-Œµ)$ approximation guarantees for the constrained $k$-supplier and $k$-center problems in $\mathsf{FPT}$ time, assuming $\mathsf{FPT} \neq \mathsf{W}[2]$. Furthermore, we study these constrained problems in outlier setting. Our algorithm gives $3$ and $2$ approximation guarantees for the constrained outlier $k$-supplier and $k$-center problems, respectively, with $\mathsf{FPT}$ running time $(k+m)^{O(k)} \cdot n^{O(1)}$, where $n = |C \cup L|$ and $m$ is the number of outliers.

</p>
</details>

<details><summary><b>Encoder-Decoder Networks for Analyzing Thermal and Power Delivery Networks</b>
<a href="https://arxiv.org/abs/2110.14197">arxiv:2110.14197</a>
&#x1F4C8; 1 <br>
<p>Vidya A. Chhabria, Vipul Ahuja, Ashwath Prabhu, Nikhil Patil, Palkesh Jain, Sachin S. Sapatnekar</p></summary>
<p>

**Abstract:** Power delivery network (PDN) analysis and thermal analysis are computationally expensive tasks that are essential for successful IC design. Algorithmically, both these analyses have similar computational structure and complexity as they involve the solution to a partial differential equation of the same form. This paper converts these analyses into image-to-image and sequence-to-sequence translation tasks, which allows leveraging a class of machine learning models with an encoder-decoder-based generative (EDGe) architecture to address the time-intensive nature of these tasks. For PDN analysis, we propose two networks: (i) IREDGe: a full-chip static and dynamic IR drop predictor and (ii) EMEDGe: electromigration (EM) hotspot classifier based on input power, power grid distribution, and power pad distribution patterns. For thermal analysis, we propose ThermEDGe, a full-chip static and dynamic temperature estimator based on input power distribution patterns for thermal analysis. These networks are transferable across designs synthesized within the same technology and packing solution. The networks predict on-chip IR drop, EM hotspot locations, and temperature in milliseconds with negligibly small errors against commercial tools requiring several hours.

</p>
</details>

<details><summary><b>OpeNPDN: A Neural-network-based Framework for Power Delivery Network Synthesis</b>
<a href="https://arxiv.org/abs/2110.14184">arxiv:2110.14184</a>
&#x1F4C8; 1 <br>
<p>Vidya A. Chhabria, Sachin S. Sapatnekar</p></summary>
<p>

**Abstract:** Power delivery network (PDN) design is a nontrivial, time-intensive, and iterative task. Correct PDN design must account for considerations related to power bumps, currents, blockages, and signal congestion distribution patterns. This work proposes a machine learning-based methodology that employs a set of predefined PDN templates. At the floorplan stage, coarse estimates of current, congestion, macro/blockages, and C4 bump distributions are used to synthesize a grid for early design. At the placement stage, the grid is incrementally refined based on more accurate and fine-grained distributions of current and congestion. At each stage, a convolutional neural network (CNN) selects an appropriate PDN template for each region on the chip, building a safe-by-construction PDN that meets IR drop and electromigration (EM) specifications. The CNN is initially trained using a large synthetically-created dataset, following which transfer learning is leveraged to bridge the gap between real-circuit data (with a limited dataset size) and synthetically-generated data. On average, the optimization of the PDN frees thousands of routing tracks in congestion-critical regions, when compared to a globally uniform PDN, while staying within the IR drop and EM limits.

</p>
</details>

<details><summary><b>An $\ell^p$-based Kernel Conditional Independence Test</b>
<a href="https://arxiv.org/abs/2110.14868">arxiv:2110.14868</a>
&#x1F4C8; 0 <br>
<p>Meyer Scetbon, Laurent Meunier, Yaniv Romano</p></summary>
<p>

**Abstract:** We propose a new computationally efficient test for conditional independence based on the $L^{p}$ distance between two kernel-based representatives of well suited distributions. By evaluating the difference of these two representatives at a finite set of locations, we derive a finite dimensional approximation of the $L^{p}$ metric, obtain its asymptotic distribution under the null hypothesis of conditional independence and design a simple statistical test from it. The test obtained is consistent and computationally efficient. We conduct a series of experiments showing that the performance of our new tests outperforms state-of-the-art methods both in term of statistical power and type-I error even in the high dimensional setting.

</p>
</details>

<details><summary><b>A Geometric Perspective towards Neural Calibration via Sensitivity Decomposition</b>
<a href="https://arxiv.org/abs/2110.14577">arxiv:2110.14577</a>
&#x1F4C8; 0 <br>
<p>Junjiao Tian, Dylan Yung, Yen-Chang Hsu, Zsolt Kira</p></summary>
<p>

**Abstract:** It is well known that vision classification models suffer from poor calibration in the face of data distribution shifts. In this paper, we take a geometric approach to this problem. We propose Geometric Sensitivity Decomposition (GSD) which decomposes the norm of a sample feature embedding and the angular similarity to a target classifier into an instance-dependent and an instance-independent component. The instance-dependent component captures the sensitive information about changes in the input while the instance-independent component represents the insensitive information serving solely to minimize the loss on the training dataset. Inspired by the decomposition, we analytically derive a simple extension to current softmax-linear models, which learns to disentangle the two components during training. On several common vision models, the disentangled model outperforms other calibration methods on standard calibration metrics in the face of out-of-distribution (OOD) data and corruption with significantly less complexity. Specifically, we surpass the current state of the art by 30.8% relative improvement on corrupted CIFAR100 in Expected Calibration Error. Code available at https://github.com/GT-RIPL/Geometric-Sensitivity-Decomposition.git.

</p>
</details>

<details><summary><b>V-Learning -- A Simple, Efficient, Decentralized Algorithm for Multiagent RL</b>
<a href="https://arxiv.org/abs/2110.14555">arxiv:2110.14555</a>
&#x1F4C8; 0 <br>
<p>Chi Jin, Qinghua Liu, Yuanhao Wang, Tiancheng Yu</p></summary>
<p>

**Abstract:** A major challenge of multiagent reinforcement learning (MARL) is the curse of multiagents, where the size of the joint action space scales exponentially with the number of agents. This remains to be a bottleneck for designing efficient MARL algorithms even in a basic scenario with finitely many states and actions. This paper resolves this challenge for the model of episodic Markov games. We design a new class of fully decentralized algorithms -- V-learning, which provably learns Nash equilibria (in the two-player zero-sum setting), correlated equilibria and coarse correlated equilibria (in the multiplayer general-sum setting) in a number of samples that only scales with $\max_{i\in[m]} A_i$, where $A_i$ is the number of actions for the $i^{\rm th}$ player. This is in sharp contrast to the size of the joint action space which is $\prod_{i=1}^m A_i$. V-learning (in its basic form) is a new class of single-agent RL algorithms that convert any adversarial bandit algorithm with suitable regret guarantees into a RL algorithm. Similar to the classical Q-learning algorithm, it performs incremental updates to the value functions. Different from Q-learning, it only maintains the estimates of V-values instead of Q-values. This key difference allows V-learning to achieve the claimed guarantees in the MARL setting by simply letting all agents run V-learning independently.

</p>
</details>

<details><summary><b>Simple data balancing achieves competitive worst-group-accuracy</b>
<a href="https://arxiv.org/abs/2110.14503">arxiv:2110.14503</a>
&#x1F4C8; 0 <br>
<p>Badr Youbi Idrissi, Martin Arjovsky, Mohammad Pezeshki, David Lopez-Paz</p></summary>
<p>

**Abstract:** We study the problem of learning classifiers that perform well across (known or unknown) groups of data. After observing that common worst-group-accuracy datasets suffer from substantial imbalances, we set out to compare state-of-the-art methods to simple balancing of classes and groups by either subsampling or reweighting data. Our results show that these data balancing baselines achieve state-of-the-art-accuracy, while being faster to train and requiring no additional hyper-parameters. In addition, we highlight that access to group information is most critical for model selection purposes, and not so much during training. All in all, our findings beg closer examination of benchmarks and methods for research in worst-group-accuracy optimization.

</p>
</details>

<details><summary><b>Hand gesture detection in tests performed by older adults</b>
<a href="https://arxiv.org/abs/2110.14461">arxiv:2110.14461</a>
&#x1F4C8; 0 <br>
<p>Guan Huang, Son N. Tran, Quan Bai, Jane Alty</p></summary>
<p>

**Abstract:** Our team are developing a new online test that analyses hand movement features associated with ageing that can be completed remotely from the research centre. To obtain hand movement features, participants will be asked to perform a variety of hand gestures using their own computer cameras. However, it is challenging to collect high quality hand movement video data, especially for older participants, many of whom have no IT background. During the data collection process, one of the key steps is to detect whether the participants are following the test instructions correctly and also to detect similar gestures from different devices. Furthermore, we need this process to be automated and accurate as we expect many thousands of participants to complete the test. We have implemented a hand gesture detector to detect the gestures in the hand movement tests and our detection mAP is 0.782 which is better than the state-of-the-art. In this research, we have processed 20,000 images collected from hand movement tests and labelled 6,450 images to detect different hand gestures in the hand movement tests. This paper has the following three contributions. Firstly, we compared and analysed the performance of different network structures for hand gesture detection. Secondly, we have made many attempts to improve the accuracy of the model and have succeeded in improving the classification accuracy for similar gestures by implementing attention layers. Thirdly, we have created two datasets and included 20 percent of blurred images in the dataset to investigate how different network structures were impacted by noisy data, our experiments have also shown our network has better performance on the noisy dataset.

</p>
</details>

<details><summary><b>Binarized ResNet: Enabling Automatic Modulation Classification at the resource-constrained Edge</b>
<a href="https://arxiv.org/abs/2110.14357">arxiv:2110.14357</a>
&#x1F4C8; 0 <br>
<p>Nitin Priyadarshini Shankar, Deepsayan Sadhukhan, Nancy Nayak, Sheetal Kalyani</p></summary>
<p>

**Abstract:** In this paper, we propose a ResNet based neural architecture to solve the problem of Automatic Modulation Classification. We showed that our architecture outperforms the state-of-the-art (SOTA) architectures. We further propose to binarize the network to deploy it in the Edge network where the devices are resource-constrained i.e. have limited memory and computing power. Instead of simple binarization, rotated binarization is applied to the network which helps to close the significant performance gap between the real and the binarized network. Because of the immense representation capability or the real network, its rotated binarized version achieves $85.33\%$ accuracy compared to $95.76\%$ accuracy of the proposed real network with $2.33$ and $16$ times lesser computing power than two of the SOTA architectures, MCNet and RMLResNet respectively, and approximately $16$ times less memory than both. The performance can be improved further to $87.74\%$ by taking an ensemble of four such rotated binarized networks.

</p>
</details>


[Next Page]({{ '/2021/10/26/2021.10.26.html' | relative_url }})
