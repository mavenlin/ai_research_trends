## Summary for 2021-07-25, created on 2021-12-21


<details><summary><b>Go Wider Instead of Deeper</b>
<a href="https://arxiv.org/abs/2107.11817">arxiv:2107.11817</a>
&#x1F4C8; 30 <br>
<p>Fuzhao Xue, Ziji Shi, Futao Wei, Yuxuan Lou, Yong Liu, Yang You</p></summary>
<p>

**Abstract:** More transformer blocks with residual connections have recently achieved impressive results on various tasks. To achieve better performance with fewer trainable parameters, recent methods are proposed to go shallower by parameter sharing or model compressing along with the depth. However, weak modeling capacity limits their performance. Contrastively, going wider by inducing more trainable matrixes and parameters would produce a huge model requiring advanced parallelism to train and inference.
  In this paper, we propose a parameter-efficient framework, going wider instead of deeper. Specially, following existing works, we adapt parameter sharing to compress along depth. But, such deployment would limit the performance. To maximize modeling capacity, we scale along model width by replacing feed-forward network (FFN) with mixture-of-experts (MoE). Across transformer blocks, instead of sharing normalization layers, we propose to use individual layernorms to transform various semantic representations in a more parameter-efficient way. To evaluate our plug-and-run framework, we design WideNet and conduct comprehensive experiments on popular computer vision and natural language processing benchmarks. On ImageNet-1K, our best model outperforms Vision Transformer (ViT) by $1.5\%$ with $0.72 \times$ trainable parameters. Using $0.46 \times$ and $0.13 \times$ parameters, our WideNet can still surpass ViT and ViT-MoE by $0.8\%$ and $2.1\%$, respectively. On four natural language processing datasets, WideNet outperforms ALBERT by $1.8\%$ on average and surpass BERT using factorized embedding parameterization by $0.8\%$ with fewer parameters.

</p>
</details>

<details><summary><b>Improving Robot Localisation by Ignoring Visual Distraction</b>
<a href="https://arxiv.org/abs/2107.11857">arxiv:2107.11857</a>
&#x1F4C8; 14 <br>
<p>Oscar Mendez, Matthew Vowels, Richard Bowden</p></summary>
<p>

**Abstract:** Attention is an important component of modern deep learning. However, less emphasis has been put on its inverse: ignoring distraction. Our daily lives require us to explicitly avoid giving attention to salient visual features that confound the task we are trying to accomplish. This visual prioritisation allows us to concentrate on important tasks while ignoring visual distractors.
  In this work, we introduce Neural Blindness, which gives an agent the ability to completely ignore objects or classes that are deemed distractors. More explicitly, we aim to render a neural network completely incapable of representing specific chosen classes in its latent space. In a very real sense, this makes the network "blind" to certain classes, allowing and agent to focus on what is important for a given task, and demonstrates how this can be used to improve localisation.

</p>
</details>

<details><summary><b>On-Device Content Moderation</b>
<a href="https://arxiv.org/abs/2107.11845">arxiv:2107.11845</a>
&#x1F4C8; 12 <br>
<p>Anchal Pandey, Sukumar Moharana, Debi Prasanna Mohanty, Archit Panwar, Dewang Agarwal, Siva Prasad Thota</p></summary>
<p>

**Abstract:** With the advent of internet, not safe for work(NSFW) content moderation is a major problem today. Since,smartphones are now part of daily life of billions of people,it becomes even more important to have a solution which coulddetect and suggest user about potential NSFW content present ontheir phone. In this paper we present a novel on-device solutionfor detecting NSFW images. In addition to conventional porno-graphic content moderation, we have also included semi-nudecontent moderation as it is still NSFW in a large demography.We have curated a dataset comprising of three major categories,namely nude, semi-nude and safe images. We have created anensemble of object detector and classifier for filtering of nudeand semi-nude contents. The solution provides unsafe body partannotations along with identification of semi-nude images. Weextensively tested our proposed solution on several public datasetand also on our custom dataset. The model achieves F1 scoreof 0.91 with 95% precision and 88% recall on our customNSFW16k dataset and 0.92 MAP on NPDI dataset. Moreover itachieves average 0.002 false positive rate on a collection of safeimage open datasets.

</p>
</details>

<details><summary><b>Massive feature extraction for explaining and foretelling hydroclimatic time series forecastability at the global scale</b>
<a href="https://arxiv.org/abs/2108.00846">arxiv:2108.00846</a>
&#x1F4C8; 9 <br>
<p>Georgia Papacharalampous, Hristos Tyralis, Ilias G. Pechlivanidis, Salvatore Grimaldi, Elena Volpi</p></summary>
<p>

**Abstract:** Statistical analyses and descriptive characterizations are sometimes assumed to be offering information on time series forecastability. Despite the scientific interest suggested by such assumptions, the relationships between descriptive time series features (e.g., temporal dependence, entropy, seasonality, trend and nonlinearity features) and actual time series forecastability (quantified by issuing and assessing forecasts for the past) are scarcely studied and quantified in the literature. In this work, we aim to fill in this gap by investigating such relationships, and the way that they can be exploited for understanding hydroclimatic forecastability. To this end, we follow a systematic framework bringing together a variety of -- mostly new for hydrology -- concepts and methods, including 57 descriptive features. We apply this framework to three global datasets. As these datasets comprise over 13 000 monthly temperature, precipitation and river flow time series from several continents and hydroclimatic regimes, they allow us to provide trustable characterizations and interpretations of 12-month ahead hydroclimatic forecastability at the global scale. We find that this forecastability in terms of Nash-Sutcliffe efficiency is strongly related to several descriptive features. We further (i) show that, if such descriptive information is available for a time series, we can even foretell the quality of its future forecasts with a considerable degree of confidence, and (ii) rank the features according to their efficiency in inferring and foretelling forecastability. Spatial forecastability patterns are also revealed through our experiments. A comprehensive interpretation of such patters through massive feature extraction and feature-based time series clustering is shown to be possible.

</p>
</details>

<details><summary><b>Measuring Ethics in AI with AI: A Methodology and Dataset Construction</b>
<a href="https://arxiv.org/abs/2107.11913">arxiv:2107.11913</a>
&#x1F4C8; 8 <br>
<p>Pedro H. C. Avelar, Rafael B. Audibert, Anderson R. Tavares, Luís C. Lamb</p></summary>
<p>

**Abstract:** Recently, the use of sound measures and metrics in Artificial Intelligence has become the subject of interest of academia, government, and industry. Efforts towards measuring different phenomena have gained traction in the AI community, as illustrated by the publication of several influential field reports and policy documents. These metrics are designed to help decision takers to inform themselves about the fast-moving and impacting influences of key advances in Artificial Intelligence in general and Machine Learning in particular. In this paper we propose to use such newfound capabilities of AI technologies to augment our AI measuring capabilities. We do so by training a model to classify publications related to ethical issues and concerns. In our methodology we use an expert, manually curated dataset as the training set and then evaluate a large set of research papers. Finally, we highlight the implications of AI metrics, in particular their contribution towards developing trustful and fair AI-based tools and technologies. Keywords: AI Ethics; AI Fairness; AI Measurement. Ethics in Computer Science.

</p>
</details>

<details><summary><b>Transferable Dialogue Systems and User Simulators</b>
<a href="https://arxiv.org/abs/2107.11904">arxiv:2107.11904</a>
&#x1F4C8; 7 <br>
<p>Bo-Hsiang Tseng, Yinpei Dai, Florian Kreyssig, Bill Byrne</p></summary>
<p>

**Abstract:** One of the difficulties in training dialogue systems is the lack of training data. We explore the possibility of creating dialogue data through the interaction between a dialogue system and a user simulator. Our goal is to develop a modelling framework that can incorporate new dialogue scenarios through self-play between the two agents. In this framework, we first pre-train the two agents on a collection of source domain dialogues, which equips the agents to converse with each other via natural language. With further fine-tuning on a small amount of target domain data, the agents continue to interact with the aim of improving their behaviors using reinforcement learning with structured reward functions. In experiments on the MultiWOZ dataset, two practical transfer learning problems are investigated: 1) domain adaptation and 2) single-to-multiple domain transfer. We demonstrate that the proposed framework is highly effective in bootstrapping the performance of the two agents in transfer learning. We also show that our method leads to improvements in dialogue system performance on complete datasets.

</p>
</details>

<details><summary><b>Character Spotting Using Machine Learning Techniques</b>
<a href="https://arxiv.org/abs/2107.11795">arxiv:2107.11795</a>
&#x1F4C8; 6 <br>
<p>P Preethi, Hrishikesh Viswanath</p></summary>
<p>

**Abstract:** This work presents a comparison of machine learning algorithms that are implemented to segment the characters of text presented as an image. The algorithms are designed to work on degraded documents with text that is not aligned in an organized fashion. The paper investigates the use of Support Vector Machines, K-Nearest Neighbor algorithm and an Encoder Network to perform the operation of character spotting. Character Spotting involves extracting potential characters from a stream of text by selecting regions bound by white space.

</p>
</details>

<details><summary><b>A brief note on understanding neural networks as Gaussian processes</b>
<a href="https://arxiv.org/abs/2107.11892">arxiv:2107.11892</a>
&#x1F4C8; 5 <br>
<p>Mengwu Guo</p></summary>
<p>

**Abstract:** As a generalization of the work in [Lee et al., 2017], this note briefly discusses when the prior of a neural network output follows a Gaussian process, and how a neural-network-induced Gaussian process is formulated. The posterior mean functions of such a Gaussian process regression lie in the reproducing kernel Hilbert space defined by the neural-network-induced kernel. In the case of two-layer neural networks, the induced Gaussian processes provide an interpretation of the reproducing kernel Hilbert spaces whose union forms a Barron space.

</p>
</details>

<details><summary><b>Hybrid Autoregressive Inference for Scalable Multi-hop Explanation Regeneration</b>
<a href="https://arxiv.org/abs/2107.11879">arxiv:2107.11879</a>
&#x1F4C8; 5 <br>
<p>Marco Valentino, Mokanarangan Thayaparan, Deborah Ferreira, André Freitas</p></summary>
<p>

**Abstract:** Regenerating natural language explanations in the scientific domain has been proposed as a benchmark to evaluate complex multi-hop and explainable inference. In this context, large language models can achieve state-of-the-art performance when employed as cross-encoder architectures and fine-tuned on human-annotated explanations. However, while much attention has been devoted to the quality of the explanations, the problem of performing inference efficiently is largely under-studied. Cross-encoders, in fact, are intrinsically not scalable, possessing limited applicability to real-world scenarios that require inference on massive facts banks. To enable complex multi-hop reasoning at scale, this paper focuses on bi-encoder architectures, investigating the problem of scientific explanation regeneration at the intersection of dense and sparse models. Specifically, we present SCAR (for Scalable Autoregressive Inference), a hybrid framework that iteratively combines a Transformer-based bi-encoder with a sparse model of explanatory power, designed to leverage explicit inference patterns in the explanations. Our experiments demonstrate that the hybrid framework significantly outperforms previous sparse models, achieving performance comparable with that of state-of-the-art cross-encoders while being approx 50 times faster and scalable to corpora of millions of facts. Further analyses on semantic drift and multi-hop question answering reveal that the proposed hybridisation boosts the quality of the most challenging explanations, contributing to improved performance on downstream inference tasks.

</p>
</details>

<details><summary><b>ReDAL: Region-based and Diversity-aware Active Learning for Point Cloud Semantic Segmentation</b>
<a href="https://arxiv.org/abs/2107.11769">arxiv:2107.11769</a>
&#x1F4C8; 5 <br>
<p>Tsung-Han Wu, Yueh-Cheng Liu, Yu-Kai Huang, Hsin-Ying Lee, Hung-Ting Su, Ping-Chia Huang, Winston H. Hsu</p></summary>
<p>

**Abstract:** Despite the success of deep learning on supervised point cloud semantic segmentation, obtaining large-scale point-by-point manual annotations is still a significant challenge. To reduce the huge annotation burden, we propose a Region-based and Diversity-aware Active Learning (ReDAL), a general framework for many deep learning approaches, aiming to automatically select only informative and diverse sub-scene regions for label acquisition. Observing that only a small portion of annotated regions are sufficient for 3D scene understanding with deep learning, we use softmax entropy, color discontinuity, and structural complexity to measure the information of sub-scene regions. A diversity-aware selection algorithm is also developed to avoid redundant annotations resulting from selecting informative but similar regions in a querying batch. Extensive experiments show that our method highly outperforms previous active learning strategies, and we achieve the performance of 90% fully supervised learning, while less than 15% and 5% annotations are required on S3DIS and SemanticKITTI datasets, respectively.

</p>
</details>

<details><summary><b>Improving Variational Autoencoder based Out-of-Distribution Detection for Embedded Real-time Applications</b>
<a href="https://arxiv.org/abs/2107.11750">arxiv:2107.11750</a>
&#x1F4C8; 5 <br>
<p>Yeli Feng, Daniel Jun Xian Ng, Arvind Easwaran</p></summary>
<p>

**Abstract:** Uncertainties in machine learning are a significant roadblock for its application in safety-critical cyber-physical systems (CPS). One source of uncertainty arises from distribution shifts in the input data between training and test scenarios. Detecting such distribution shifts in real-time is an emerging approach to address the challenge. The high dimensional input space in CPS applications involving imaging adds extra difficulty to the task. Generative learning models are widely adopted for the task, namely out-of-distribution (OoD) detection. To improve the state-of-the-art, we studied existing proposals from both machine learning and CPS fields. In the latter, safety monitoring in real-time for autonomous driving agents has been a focus. Exploiting the spatiotemporal correlation of motion in videos, we can robustly detect hazardous motion around autonomous driving agents. Inspired by the latest advances in the Variational Autoencoder (VAE) theory and practice, we tapped into the prior knowledge in data to further boost OoD detection's robustness. Comparison studies over nuScenes and Synthia data sets show our methods significantly improve detection capabilities of OoD factors unique to driving scenarios, 42% better than state-of-the-art approaches. Our model also generalized near-perfectly, 97% better than the state-of-the-art across the real-world and simulation driving data sets experimented. Finally, we customized one proposed method into a twin-encoder model that can be deployed to resource limited embedded devices for real-time OoD detection. Its execution time was reduced over four times in low-precision 8-bit integer inference, while detection capability is comparable to its corresponding floating-point model.

</p>
</details>

<details><summary><b>A Survey of Machine Learning Techniques for Detecting and Diagnosing COVID-19 from Imaging</b>
<a href="https://arxiv.org/abs/2108.04344">arxiv:2108.04344</a>
&#x1F4C8; 4 <br>
<p>Aishwarza Panday, Muhammad Ashad Kabir, Nihad Karim Chowdhury</p></summary>
<p>

**Abstract:** Due to the limited availability and high cost of the reverse transcription-polymerase chain reaction (RT-PCR) test, many studies have proposed machine learning techniques for detecting COVID-19 from medical imaging. The purpose of this study is to systematically review, assess, and synthesize research articles that have used different machine learning techniques to detect and diagnose COVID-19 from chest X-ray and CT scan images. A structured literature search was conducted in the relevant bibliographic databases to ensure that the survey solely centered on reproducible and high-quality research. We selected papers based on our inclusion criteria. In this survey, we reviewed $98$ articles that fulfilled our inclusion criteria. We have surveyed a complete pipeline of chest imaging analysis techniques related to COVID-19, including data collection, pre-processing, feature extraction, classification, and visualization. We have considered CT scans and X-rays as both are widely used to describe the latest developments in medical imaging to detect COVID-19. This survey provides researchers with valuable insights into different machine learning techniques and their performance in the detection and diagnosis of COVID-19 from chest imaging. At the end, the challenges and limitations in detecting COVID-19 using machine learning techniques and the future direction of research are discussed.

</p>
</details>

<details><summary><b>Power of human-algorithm collaboration in solving combinatorial optimization problems</b>
<a href="https://arxiv.org/abs/2107.11784">arxiv:2107.11784</a>
&#x1F4C8; 4 <br>
<p>Tapani Toivonen</p></summary>
<p>

**Abstract:** Many combinatorial optimization problems are often considered intractable to solve exactly or by approximation. An example of such problem is maximum clique which -- under standard assumptions in complexity theory -- cannot be solved in sub-exponential time or be approximated within polynomial factor efficiently. We show that if a polynomial time algorithm can query informative Gaussian priors from an expert $poly(n)$ times, then a class of combinatorial optimization problems can be solved efficiently in expectation up to a multiplicative factor $ε$ where $ε$ is arbitrary constant. While our proposed methods are merely theoretical, they cast new light on how to approach solving these problems that have been usually considered intractable.

</p>
</details>

<details><summary><b>DR2L: Surfacing Corner Cases to Robustify Autonomous Driving via Domain Randomization Reinforcement Learning</b>
<a href="https://arxiv.org/abs/2107.11762">arxiv:2107.11762</a>
&#x1F4C8; 4 <br>
<p>Haoyi Niu, Jianming Hu, Zheyu Cui, Yi Zhang</p></summary>
<p>

**Abstract:** How to explore corner cases as efficiently and thoroughly as possible has long been one of the top concerns in the context of deep reinforcement learning (DeepRL) autonomous driving. Training with simulated data is less costly and dangerous than utilizing real-world data, but the inconsistency of parameter distribution and the incorrect system modeling in simulators always lead to an inevitable Sim2real gap, which probably accounts for the underperformance in novel, anomalous and risky cases that simulators can hardly generate. Domain Randomization(DR) is a methodology that can bridge this gap with little or no real-world data. Consequently, in this research, an adversarial model is put forward to robustify DeepRL-based autonomous vehicles trained in simulation to gradually surfacing harder events, so that the models could readily transfer to the real world.

</p>
</details>

<details><summary><b>A Comparison of Latent Semantic Analysis and Correspondence Analysis for Text Mining</b>
<a href="https://arxiv.org/abs/2108.06197">arxiv:2108.06197</a>
&#x1F4C8; 3 <br>
<p>Qianqian Qi, David J. Hessen, Peter G. M. van der Heijden</p></summary>
<p>

**Abstract:** Both latent semantic analysis (LSA) and correspondence analysis (CA) use a singular value decomposition (SVD) for dimensionality reduction. In this article, LSA and CA are compared from a theoretical point of view and applied in both a toy example and an authorship attribution example. In text mining interest goes out to the relationships among documents and terms: for example, what terms are more often used in what documents. However, the LSA solution displays a mix of marginal effects and these relationships. It appears that CA has more attractive properties than LSA. One such property is that, in CA, the effect of the margins is effectively eliminated, so that the CA solution is optimally suited to focus on the relationships among documents and terms. Three mechanisms are distinguished to weight documents and terms, and a unifying framework is proposed that includes these three mechanisms and includes both CA and LSA as special cases. In the authorship attribution example, the national anthem of the Netherlands, the application of the discussed methods is illustrated.

</p>
</details>

<details><summary><b>Distributional Shifts in Automated Diabetic Retinopathy Screening</b>
<a href="https://arxiv.org/abs/2107.11822">arxiv:2107.11822</a>
&#x1F4C8; 3 <br>
<p>Jay Nandy, Wynne Hsu, Mong Li Lee</p></summary>
<p>

**Abstract:** Deep learning-based models are developed to automatically detect if a retina image is `referable' in diabetic retinopathy (DR) screening. However, their classification accuracy degrades as the input images distributionally shift from their training distribution. Further, even if the input is not a retina image, a standard DR classifier produces a high confident prediction that the image is `referable'. Our paper presents a Dirichlet Prior Network-based framework to address this issue. It utilizes an out-of-distribution (OOD) detector model and a DR classification model to improve generalizability by identifying OOD images. Experiments on real-world datasets indicate that the proposed framework can eliminate the unknown non-retina images and identify the distributionally shifted retina images for human intervention.

</p>
</details>

<details><summary><b>A Survey of Monte Carlo Methods for Parameter Estimation</b>
<a href="https://arxiv.org/abs/2107.11820">arxiv:2107.11820</a>
&#x1F4C8; 3 <br>
<p>D. Luengo, L. Martino, M. Bugallo, V. Elvira, S. Särkkä</p></summary>
<p>

**Abstract:** Statistical signal processing applications usually require the estimation of some parameters of interest given a set of observed data. These estimates are typically obtained either by solving a multi-variate optimization problem, as in the maximum likelihood (ML) or maximum a posteriori (MAP) estimators, or by performing a multi-dimensional integration, as in the minimum mean squared error (MMSE) estimators. Unfortunately, analytical expressions for these estimators cannot be found in most real-world applications, and the Monte Carlo (MC) methodology is one feasible approach. MC methods proceed by drawing random samples, either from the desired distribution or from a simpler one, and using them to compute consistent estimators. The most important families of MC algorithms are Markov chain MC (MCMC) and importance sampling (IS). On the one hand, MCMC methods draw samples from a proposal density, building then an ergodic Markov chain whose stationary distribution is the desired distribution by accepting or rejecting those candidate samples as the new state of the chain. On the other hand, IS techniques draw samples from a simple proposal density, and then assign them suitable weights that measure their quality in some appropriate way. In this paper, we perform a thorough review of MC methods for the estimation of static parameters in signal processing applications. A historical note on the development of MC schemes is also provided, followed by the basic MC method and a brief description of the rejection sampling (RS) algorithm, as well as three sections describing many of the most relevant MCMC and IS algorithms, and their combined use.

</p>
</details>

<details><summary><b>ROD: Reception-aware Online Distillation for Sparse Graphs</b>
<a href="https://arxiv.org/abs/2107.11789">arxiv:2107.11789</a>
&#x1F4C8; 3 <br>
<p>Wentao Zhang, Yuezihan Jiang, Yang Li, Zeang Sheng, Yu Shen, Xupeng Miao, Liang Wang, Zhi Yang, Bin Cui</p></summary>
<p>

**Abstract:** Graph neural networks (GNNs) have been widely used in many graph-based tasks such as node classification, link prediction, and node clustering. However, GNNs gain their performance benefits mainly from performing the feature propagation and smoothing across the edges of the graph, thus requiring sufficient connectivity and label information for effective propagation. Unfortunately, many real-world networks are sparse in terms of both edges and labels, leading to sub-optimal performance of GNNs. Recent interest in this sparse problem has focused on the self-training approach, which expands supervised signals with pseudo labels. Nevertheless, the self-training approach inherently cannot realize the full potential of refining the learning performance on sparse graphs due to the unsatisfactory quality and quantity of pseudo labels.
  In this paper, we propose ROD, a novel reception-aware online knowledge distillation approach for sparse graph learning. We design three supervision signals for ROD: multi-scale reception-aware graph knowledge, task-based supervision, and rich distilled knowledge, allowing online knowledge transfer in a peer-teaching manner. To extract knowledge concealed in the multi-scale reception fields, ROD explicitly requires individual student models to preserve different levels of locality information. For a given task, each student would predict based on its reception-scale knowledge, while simultaneously a strong teacher is established on-the-fly by combining multi-scale knowledge. Our approach has been extensively evaluated on 9 datasets and a variety of graph-based tasks, including node classification, link prediction, and node clustering. The result demonstrates that ROD achieves state-of-art performance and is more robust for the graph sparsity.

</p>
</details>

<details><summary><b>A Study on Herd Behavior Using Sentiment Analysis in Online Social Network</b>
<a href="https://arxiv.org/abs/2108.01728">arxiv:2108.01728</a>
&#x1F4C8; 2 <br>
<p>Suchandra Dutta, Dhrubasish Sarkar, Sohom Roy, Dipak K. Kole, Premananda Jana</p></summary>
<p>

**Abstract:** Social media platforms are thriving nowadays, so a huge volume of data is produced. As it includes brief and clear statements, millions of people post their thoughts on microblogging sites every day. This paper represents and analyze the capacity of diverse strategies to volumetric, delicate, and social networks to predict critical opinions from online social networking sites. In the exploration of certain searching for relevant, the thoughts of people play a crucial role. Social media becomes a good outlet since the last decades to share the opinions globally. Sentiment analysis as well as opinion mining is a tool that is used to extract the opinions or thoughts of the common public. An occurrence in one place, be it economic, political, or social, may trigger large-scale chain public reaction across many other sites in an increasingly interconnected world. This study demonstrates the evaluation of sentiment analysis techniques using social media contents and creating the association between subjectivity with herd behavior and clustering coefficient as well as tries to predict the election result (2021 election in West Bengal). This is an implementation of sentiment analysis targeted at estimating the results of an upcoming election by assessing the public's opinion across social media. This paper also has a short discussion section on the usefulness of the idea in other fields.

</p>
</details>

<details><summary><b>Vowel-based Meeteilon dialect identification using a Random Forest classifier</b>
<a href="https://arxiv.org/abs/2107.13419">arxiv:2107.13419</a>
&#x1F4C8; 2 <br>
<p>Thangjam Clarinda Devi, Kabita Thaoroijam</p></summary>
<p>

**Abstract:** This paper presents a vowel-based dialect identification system for Meeteilon. For this work, a vowel dataset is created by using Meeteilon Speech Corpora available at Linguistic Data Consortium for Indian Languages (LDC-IL). Spectral features such as formant frequencies (F1, F1 and F3) and prosodic features such as pitch (F0), energy, intensity and segment duration values are extracted from monophthong vowel sounds. Random forest classifier, a decision tree-based ensemble algorithm is used for classification of three major dialects of Meeteilon namely, Imphal, Kakching and Sekmai. Model has shown an average dialect identification performance in terms of accuracy of around 61.57%. The role of spectral and prosodic features are found to be significant in Meeteilon dialect classification.

</p>
</details>

<details><summary><b>Restless Bandits with Many Arms: Beating the Central Limit Theorem</b>
<a href="https://arxiv.org/abs/2107.11911">arxiv:2107.11911</a>
&#x1F4C8; 2 <br>
<p>Xiangyu Zhang, Peter I. Frazier</p></summary>
<p>

**Abstract:** We consider finite-horizon restless bandits with multiple pulls per period, which play an important role in recommender systems, active learning, revenue management, and many other areas. While an optimal policy can be computed, in principle, using dynamic programming, the computation required scales exponentially in the number of arms $N$. Thus, there is substantial value in understanding the performance of index policies and other policies that can be computed efficiently for large $N$. We study the growth of the optimality gap, i.e., the loss in expected performance compared to an optimal policy, for such policies in a classical asymptotic regime proposed by Whittle in which $N$ grows while holding constant the fraction of arms that can be pulled per period. Intuition from the Central Limit Theorem and the tightest previous theoretical bounds suggest that this optimality gap should grow like $O(\sqrt{N})$. Surprisingly, we show that it is possible to outperform this bound. We characterize a non-degeneracy condition and a wide class of novel practically-computable policies, called fluid-priority policies, in which the optimality gap is $O(1)$. These include most widely-used index policies. When this non-degeneracy condition does not hold, we show that fluid-priority policies nevertheless have an optimality gap that is $O(\sqrt{N})$, significantly generalizing the class of policies for which convergence rates are known. We demonstrate that fluid-priority policies offer state-of-the-art performance on a collection of restless bandit problems in numerical experiments.

</p>
</details>

<details><summary><b>Lung Cancer Risk Estimation with Incomplete Data: A Joint Missing Imputation Perspective</b>
<a href="https://arxiv.org/abs/2107.11882">arxiv:2107.11882</a>
&#x1F4C8; 2 <br>
<p>Riqiang Gao, Yucheng Tang, Kaiwen Xu, Ho Hin Lee, Steve Deppen, Kim Sandler, Pierre Massion, Thomas A. Lasko, Yuankai Huo, Bennett A. Landman</p></summary>
<p>

**Abstract:** Data from multi-modality provide complementary information in clinical prediction, but missing data in clinical cohorts limits the number of subjects in multi-modal learning context. Multi-modal missing imputation is challenging with existing methods when 1) the missing data span across heterogeneous modalities (e.g., image vs. non-image); or 2) one modality is largely missing. In this paper, we address imputation of missing data by modeling the joint distribution of multi-modal data. Motivated by partial bidirectional generative adversarial net (PBiGAN), we propose a new Conditional PBiGAN (C-PBiGAN) method that imputes one modality combining the conditional knowledge from another modality. Specifically, C-PBiGAN introduces a conditional latent space in a missing imputation framework that jointly encodes the available multi-modal data, along with a class regularization loss on imputed data to recover discriminative information. To our knowledge, it is the first generative adversarial model that addresses multi-modal missing imputation by modeling the joint distribution of image and non-image data. We validate our model with both the national lung screening trial (NLST) dataset and an external clinical validation cohort. The proposed C-PBiGAN achieves significant improvements in lung cancer risk estimation compared with representative imputation methods (e.g., AUC values increase in both NLST (+2.9\%) and in-house dataset (+4.3\%) compared with PBiGAN, p$<$0.05).

</p>
</details>

<details><summary><b>A Study on Speech Enhancement Based on Diffusion Probabilistic Model</b>
<a href="https://arxiv.org/abs/2107.11876">arxiv:2107.11876</a>
&#x1F4C8; 2 <br>
<p>Yen-Ju Lu, Yu Tsao, Shinji Watanabe</p></summary>
<p>

**Abstract:** Diffusion probabilistic models have demonstrated an outstanding capability to model natural images and raw audio waveforms through a paired diffusion and reverse processes. The unique property of the reverse process (namely, eliminating non-target signals from the Gaussian noise and noisy signals) could be utilized to restore clean signals. Based on this property, we propose a diffusion probabilistic model-based speech enhancement (DiffuSE) model that aims to recover clean speech signals from noisy signals. The fundamental architecture of the proposed DiffuSE model is similar to that of DiffWave--a high-quality audio waveform generation model that has a relatively low computational cost and footprint. To attain better enhancement performance, we designed an advanced reverse process, termed the supportive reverse process, which adds noisy speech in each time-step to the predicted speech. The experimental results show that DiffuSE yields performance that is comparable to related audio generative models on the standardized Voice Bank corpus SE task. Moreover, relative to the generally suggested full sampling schedule, the proposed supportive reverse process especially improved the fast sampling, taking few steps to yield better enhancement results over the conventional full step inference process.

</p>
</details>

<details><summary><b>Graph Representation Learning on Tissue-Specific Multi-Omics</b>
<a href="https://arxiv.org/abs/2107.11856">arxiv:2107.11856</a>
&#x1F4C8; 2 <br>
<p>Amine Amor, Pietro Lio', Vikash Singh, Ramon Viñas Torné, Helena Andres Terre</p></summary>
<p>

**Abstract:** Combining different modalities of data from human tissues has been critical in advancing biomedical research and personalised medical care. In this study, we leverage a graph embedding model (i.e VGAE) to perform link prediction on tissue-specific Gene-Gene Interaction (GGI) networks. Through ablation experiments, we prove that the combination of multiple biological modalities (i.e multi-omics) leads to powerful embeddings and better link prediction performances. Our evaluation shows that the integration of gene methylation profiles and RNA-sequencing data significantly improves the link prediction performance. Overall, the combination of RNA-sequencing and gene methylation data leads to a link prediction accuracy of 71% on GGI networks. By harnessing graph representation learning on multi-omics data, our work brings novel insights to the current literature on multi-omics integration in bioinformatics.

</p>
</details>

<details><summary><b>A binary variant of gravitational search algorithm and its application to windfarm layout optimization problem</b>
<a href="https://arxiv.org/abs/2107.11844">arxiv:2107.11844</a>
&#x1F4C8; 2 <br>
<p>Susheel Kumar Joshi, Jagdish Chand Bansal</p></summary>
<p>

**Abstract:** In the binary search space, GSA framework encounters the shortcomings of stagnation, diversity loss, premature convergence and high time complexity. To address these issues, a novel binary variant of GSA called `A novel neighbourhood archives embedded gravitational constant in GSA for binary search space (BNAGGSA)' is proposed in this paper. In BNAGGSA, the novel fitness-distance based social interaction strategy produces a self-adaptive step size mechanism through which the agent moves towards the optimal direction with the optimal step size, as per its current search requirement. The performance of the proposed algorithm is compared with the two binary variants of GSA over 23 well-known benchmark test problems. The experimental results and statistical analyses prove the supremacy of BNAGGSA over the compared algorithms. Furthermore, to check the applicability of the proposed algorithm in solving real-world applications, a windfarm layout optimization problem is considered. Two case studies with two different wind data sets of two different wind sites is considered for experiments.

</p>
</details>

<details><summary><b>Bangla sign language recognition using concatenated BdSL network</b>
<a href="https://arxiv.org/abs/2107.11818">arxiv:2107.11818</a>
&#x1F4C8; 2 <br>
<p>Thasin Abedin, Khondokar S. S. Prottoy, Ayana Moshruba, Safayat Bin Hakim</p></summary>
<p>

**Abstract:** Sign language is the only medium of communication for the hearing impaired and the deaf and dumb community. Communication with the general mass is thus always a challenge for this minority group. Especially in Bangla sign language (BdSL), there are 38 alphabets with some having nearly identical symbols. As a result, in BdSL recognition, the posture of hand is an important factor in addition to visual features extracted from traditional Convolutional Neural Network (CNN). In this paper, a novel architecture "Concatenated BdSL Network" is proposed which consists of a CNN based image network and a pose estimation network. While the image network gets the visual features, the relative positions of hand keypoints are taken by the pose estimation network to obtain the additional features to deal with the complexity of the BdSL symbols. A score of 91.51% was achieved by this novel approach in test set and the effectiveness of the additional pose estimation network is suggested by the experimental results.

</p>
</details>

<details><summary><b>Reinforced Imitation Learning by Free Energy Principle</b>
<a href="https://arxiv.org/abs/2107.11811">arxiv:2107.11811</a>
&#x1F4C8; 2 <br>
<p>Ryoya Ogishima, Izumi Karino, Yasuo Kuniyoshi</p></summary>
<p>

**Abstract:** Reinforcement Learning (RL) requires a large amount of exploration especially in sparse-reward settings. Imitation Learning (IL) can learn from expert demonstrations without exploration, but it never exceeds the expert's performance and is also vulnerable to distributional shift between demonstration and execution. In this paper, we radically unify RL and IL based on Free Energy Principle (FEP). FEP is a unified Bayesian theory of the brain that explains perception, action and model learning by a common fundamental principle. We present a theoretical extension of FEP and derive an algorithm in which an agent learns the world model that internalizes expert demonstrations and at the same time uses the model to infer the current and future states and actions that maximize rewards. The algorithm thus reduces exploration costs by partially imitating experts as well as maximizing its return in a seamless way, resulting in a higher performance than the suboptimal expert. Our experimental results show that this approach is promising in visual control tasks especially in sparse-reward environments.

</p>
</details>

<details><summary><b>Denoising and Segmentation of Epigraphical Scripts</b>
<a href="https://arxiv.org/abs/2107.11801">arxiv:2107.11801</a>
&#x1F4C8; 2 <br>
<p>P Preethi, Hrishikesh Viswanath</p></summary>
<p>

**Abstract:** This paper is a presentation of a new method for denoising images using Haralick features and further segmenting the characters using artificial neural networks. The image is divided into kernels, each of which is converted to a GLCM (Gray Level Co-Occurrence Matrix) on which a Haralick Feature generation function is called, the result of which is an array with fourteen elements corresponding to fourteen features The Haralick values and the corresponding noise/text classification form a dictionary, which is then used to de-noise the image through kernel comparison. Segmentation is the process of extracting characters from a document and can be used when letters are separated by white space, which is an explicit boundary marker. Segmentation is the first step in many Natural Language Processing problems. This paper explores the process of segmentation using Neural Networks. While there have been numerous methods to segment characters of a document, this paper is only concerned with the accuracy of doing so using neural networks. It is imperative that the characters be segmented correctly, for failing to do so will lead to incorrect recognition by Natural language processing tools. Artificial Neural Networks was used to attain accuracy of upto 89%. This method is suitable for languages where the characters are delimited by white space. However, this method will fail to provide acceptable results when the language heavily uses connected letters. An example would be the Devanagari script, which is predominantly used in northern India.

</p>
</details>

<details><summary><b>Sensitivity and robustness analysis in Bayesian networks with the bnmonitor R package</b>
<a href="https://arxiv.org/abs/2107.11785">arxiv:2107.11785</a>
&#x1F4C8; 2 <br>
<p>Manuele Leonelli, Ramsiya Ramanathan, Rachel L. Wilkerson</p></summary>
<p>

**Abstract:** Bayesian networks are a class of models that are widely used for risk assessment of complex operational systems. There are now multiple approaches, as well as implemented software, that guide their construction via data learning or expert elicitation. However, a constructed Bayesian network needs to be validated before it can be used for practical risk assessment. Here, we illustrate the usage of the bnmonitor R package: the first comprehensive software for the validation of a Bayesian network. An applied data analysis using bnmonitor is carried out over a medical dataset to illustrate the use of its wide array of functions.

</p>
</details>

<details><summary><b>Learn to Focus: Hierarchical Dynamic Copy Network for Dialogue State Tracking</b>
<a href="https://arxiv.org/abs/2107.11778">arxiv:2107.11778</a>
&#x1F4C8; 2 <br>
<p>Linhao Zhang, Houfeng Wang</p></summary>
<p>

**Abstract:** Recently, researchers have explored using the encoder-decoder framework to tackle dialogue state tracking (DST), which is a key component of task-oriented dialogue systems. However, they regard a multi-turn dialogue as a flat sequence, failing to focus on useful information when the sequence is long. In this paper, we propose a Hierarchical Dynamic Copy Network (HDCN) to facilitate focusing on the most informative turn, making it easier to extract slot values from the dialogue context. Based on the encoder-decoder framework, we adopt a hierarchical copy approach that calculates two levels of attention at the word- and turn-level, which are then renormalized to obtain the final copy distribution. A focus loss term is employed to encourage the model to assign the highest turn-level attention weight to the most informative turn. Experimental results show that our model achieves 46.76% joint accuracy on the MultiWOZ 2.1 dataset.

</p>
</details>

<details><summary><b>SGD May Never Escape Saddle Points</b>
<a href="https://arxiv.org/abs/2107.11774">arxiv:2107.11774</a>
&#x1F4C8; 2 <br>
<p>Liu Ziyin, Botao Li, James B. Simon, Masahito Ueda</p></summary>
<p>

**Abstract:** Stochastic gradient descent (SGD) has been deployed to solve highly non-linear and non-convex machine learning problems such as the training of deep neural networks. However, previous works on SGD often rely on restrictive and unrealistic assumptions about the nature of noise in SGD. In this work, we mathematically construct examples that defy previous understandings of SGD. For example, our constructions show that: (1) SGD may converge to a local maximum; (2) SGD may escape a saddle point arbitrarily slowly; (3) SGD may prefer sharp minima over the flat ones; and (4) AMSGrad may converge to a local maximum. We also show the relevance of our result to deep learning by presenting a minimal neural network example. Our result suggests that the noise structure of SGD might be more important than the loss landscape in neural network training and that future research should focus on deriving the actual noise structure in deep learning.

</p>
</details>

<details><summary><b>A Joint and Domain-Adaptive Approach to Spoken Language Understanding</b>
<a href="https://arxiv.org/abs/2107.11768">arxiv:2107.11768</a>
&#x1F4C8; 2 <br>
<p>Linhao Zhang, Yu Shi, Linjun Shou, Ming Gong, Houfeng Wang, Michael Zeng</p></summary>
<p>

**Abstract:** Spoken Language Understanding (SLU) is composed of two subtasks: intent detection (ID) and slot filling (SF). There are two lines of research on SLU. One jointly tackles these two subtasks to improve their prediction accuracy, and the other focuses on the domain-adaptation ability of one of the subtasks. In this paper, we attempt to bridge these two lines of research and propose a joint and domain adaptive approach to SLU. We formulate SLU as a constrained generation task and utilize a dynamic vocabulary based on domain-specific ontology. We conduct experiments on the ASMixed and MTOD datasets and achieve competitive performance with previous state-of-the-art joint models. Besides, results show that our joint model can be effectively adapted to a new domain.

</p>
</details>

<details><summary><b>Evolutionary Generative Adversarial Networks based on New Fitness Function and Generic Crossover Operator</b>
<a href="https://arxiv.org/abs/2109.11078">arxiv:2109.11078</a>
&#x1F4C8; 1 <br>
<p>Junjie Li, Jingyao Li, Wenbo Zhou, Shuai Lü</p></summary>
<p>

**Abstract:** Evolutionary generative adversarial networks (E-GAN) attempts to alleviate mode collapse and vanishing gradient that plague generative adversarial networks by introducing evolutionary computation. However, E-GAN lacks a reasonable evaluation mechanism, which limits its effect. Moreover, E-GAN only contains mutation operators in its evolutionary step, while ignoring crossover operators. The crossover operator generates more competitive individuals by combining the good traits of multiple individuals, thus it can complement the mutation operator. In this paper, we propose a novel evolutionary generative adversarial networks framework called improved evolutionary generative adversarial networks (IE-GAN), which introduces a new fitness function and generic crossover operator. A more efficient fitness function can measure the evolutionary degree of individuals more precisely. And with the help of knowledge distillation, crossover offspring can learn knowledge from multiple networks simultaneously. Experiments on various datasets demonstrate the effectiveness of IE-GAN, and show that our framework is competitive in terms of the quality of generated samples and time efficiency.

</p>
</details>

<details><summary><b>Relational Boosted Regression Trees</b>
<a href="https://arxiv.org/abs/2107.12373">arxiv:2107.12373</a>
&#x1F4C8; 1 <br>
<p>Sonia Cromp, Alireza Samadian, Kirk Pruhs</p></summary>
<p>

**Abstract:** Many tasks use data housed in relational databases to train boosted regression tree models. In this paper, we give a relational adaptation of the greedy algorithm for training boosted regression trees. For the subproblem of calculating the sum of squared residuals of the dataset, which dominates the runtime of the boosting algorithm, we provide a $(1 + ε)$-approximation using the tensor sketch technique. Employing this approximation within the relational boosted regression trees algorithm leads to learning similar model parameters, but with asymptotically better runtime.

</p>
</details>

<details><summary><b>A Unified Hyper-GAN Model for Unpaired Multi-contrast MR Image Translation</b>
<a href="https://arxiv.org/abs/2107.11945">arxiv:2107.11945</a>
&#x1F4C8; 1 <br>
<p>Heran Yang, Jian Sun, Liwei Yang, Zongben Xu</p></summary>
<p>

**Abstract:** Cross-contrast image translation is an important task for completing missing contrasts in clinical diagnosis. However, most existing methods learn separate translator for each pair of contrasts, which is inefficient due to many possible contrast pairs in real scenarios. In this work, we propose a unified Hyper-GAN model for effectively and efficiently translating between different contrast pairs. Hyper-GAN consists of a pair of hyper-encoder and hyper-decoder to first map from the source contrast to a common feature space, and then further map to the target contrast image. To facilitate the translation between different contrast pairs, contrast-modulators are designed to tune the hyper-encoder and hyper-decoder adaptive to different contrasts. We also design a common space loss to enforce that multi-contrast images of a subject share a common feature space, implicitly modeling the shared underlying anatomical structures. Experiments on two datasets of IXI and BraTS 2019 show that our Hyper-GAN achieves state-of-the-art results in both accuracy and efficiency, e.g., improving more than 1.47 and 1.09 dB in PSNR on two datasets with less than half the amount of parameters.

</p>
</details>

<details><summary><b>Logspace Reducibility From Secret Leakage Planted Clique</b>
<a href="https://arxiv.org/abs/2107.11886">arxiv:2107.11886</a>
&#x1F4C8; 1 <br>
<p>Jay Mardia</p></summary>
<p>

**Abstract:** The planted clique problem is well-studied in the context of observing, explaining, and predicting interesting computational phenomena associated with statistical problems. When equating computational efficiency with the existence of polynomial time algorithms, the computational hardness of (some variant of) the planted clique problem can be used to infer the computational hardness of a host of other statistical problems.
  Is this ability to transfer computational hardness from (some variant of) the planted clique problem to other statistical problems robust to changing our notion of computational efficiency to space efficiency?
  We answer this question affirmatively for three different statistical problems, namely Sparse PCA, submatrix detection, and testing almost k-wise independence. The key challenge is that space efficient randomized reductions need to repeatedly access the randomness they use. Known reductions to these problems are all randomized and need polynomially many random bits to implement. Since we can not store polynomially many random bits in memory, it is unclear how to implement these existing reductions space efficiently. There are two ideas involved in circumventing this issue and implementing known reductions to these problems space efficiently.
  1. When solving statistical problems, we can use parts of the input itself as randomness.
  2. Secret leakage variants of the planted clique problem with appropriate secret leakage can be more useful than the standard planted clique problem when we want to use parts of the input as randomness.
  (abstract shortened due to arxiv constraints)

</p>
</details>

<details><summary><b>Deep Learning Explicit Differentiable Predictive Control Laws for Buildings</b>
<a href="https://arxiv.org/abs/2107.11843">arxiv:2107.11843</a>
&#x1F4C8; 1 <br>
<p>Jan Drgona, Aaron Tuor, Soumya Vasisht, Elliott Skomski, Draguna Vrabie</p></summary>
<p>

**Abstract:** We present a differentiable predictive control (DPC) methodology for learning constrained control laws for unknown nonlinear systems. DPC poses an approximate solution to multiparametric programming problems emerging from explicit nonlinear model predictive control (MPC). Contrary to approximate MPC, DPC does not require supervision by an expert controller. Instead, a system dynamics model is learned from the observed system's dynamics, and the neural control law is optimized offline by leveraging the differentiable closed-loop system model. The combination of a differentiable closed-loop system and penalty methods for constraint handling of system outputs and inputs allows us to optimize the control law's parameters directly by backpropagating economic MPC loss through the learned system model. The control performance of the proposed DPC method is demonstrated in simulation using learned model of multi-zone building thermal dynamics.

</p>
</details>

<details><summary><b>Deep Learning-based Frozen Section to FFPE Translation</b>
<a href="https://arxiv.org/abs/2107.11786">arxiv:2107.11786</a>
&#x1F4C8; 1 <br>
<p>Kutsev Bengisu Ozyoruk, Sermet Can, Guliz Irem Gokceler, Kayhan Basak, Derya Demir, Gurdeniz Serin, Uguray Payam Hacisalihoglu, Emirhan Kurtuluş, Berkan Darbaz, Ming Y. Lu, Tiffany Y. Chen, Drew F. K. Williamson, Funda Yilmaz, Faisal Mahmood, Mehmet Turan</p></summary>
<p>

**Abstract:** Frozen sectioning (FS) is the preparation method of choice for microscopic evaluation of tissues during surgical operations. The high speed of the procedure allows pathologists to rapidly assess the key microscopic features, such as tumour margins and malignant status to guide surgical decision-making and minimise disruptions to the course of the operation. However, FS is prone to introducing many misleading artificial structures (histological artefacts), such as nuclear ice crystals, compression, and cutting artefacts, hindering timely and accurate diagnostic judgement of the pathologist. Additional training and prolonged experience is often required to make highly effective and time-critical diagnosis on frozen sections. On the other hand, the gold standard tissue preparation technique of formalin-fixation and paraffin-embedding (FFPE) provides significantly superior image quality, but is a very time-consuming process (12-48 hours), making it unsuitable for intra-operative use. In this paper, we propose an artificial intelligence (AI) method that improves FS image quality by computationally transforming frozen-sectioned whole-slide images (FS-WSIs) into whole-slide FFPE-style images in minutes. AI-FFPE rectifies FS artefacts with the guidance of an attention mechanism that puts a particular emphasis on artefacts while utilising a self-regularization mechanism established between FS input image and synthesized FFPE-style image that preserves clinically relevant features. As a result, AI-FFPE method successfully generates FFPE-style images without significantly extending tissue processing time and consequently improves diagnostic accuracy. We demonstrate the efficacy of AI-FFPE on lung and brain frozen sections using a variety of different qualitative and quantitative metrics including visual Turing tests from 20 board certified pathologists.

</p>
</details>

<details><summary><b>Identifying the fragment structure of the organic compounds by deeply learning the original NMR data</b>
<a href="https://arxiv.org/abs/2107.11740">arxiv:2107.11740</a>
&#x1F4C8; 1 <br>
<p>Chongcan Li, Yong Cong, Weihua Deng</p></summary>
<p>

**Abstract:** We preprocess the raw NMR spectrum and extract key characteristic features by using two different methodologies, called equidistant sampling and peak sampling for subsequent substructure pattern recognition; meanwhile may provide the alternative strategy to address the imbalance issue of the NMR dataset frequently encountered in dataset collection of statistical modeling and establish two conventional SVM and KNN models to assess the capability of two feature selection, respectively. Our results in this study show that the models using the selected features of peak sampling outperform the ones using the other. Then we build the Recurrent Neural Network (RNN) model trained by Data B collected from peak sampling. Furthermore, we illustrate the easier optimization of hyper parameters and the better generalization ability of the RNN deep learning model by comparison with traditional machine learning SVM and KNN models in detail.

</p>
</details>

<details><summary><b>Federated Learning with Fair Worker Selection: A Multi-Round Submodular Maximization Approach</b>
<a href="https://arxiv.org/abs/2107.11728">arxiv:2107.11728</a>
&#x1F4C8; 1 <br>
<p>Fengjiao Li, Jia Liu, Bo Ji</p></summary>
<p>

**Abstract:** In this paper, we study the problem of fair worker selection in Federated Learning systems, where fairness serves as an incentive mechanism that encourages more workers to participate in the federation. Considering the achieved training accuracy of the global model as the utility of the selected workers, which is typically a monotone submodular function, we formulate the worker selection problem as a new multi-round monotone submodular maximization problem with cardinality and fairness constraints. The objective is to maximize the time-average utility over multiple rounds subject to an additional fairness requirement that each worker must be selected for a certain fraction of time. While the traditional submodular maximization with a cardinality constraint is already a well-known NP-Hard problem, the fairness constraint in the multi-round setting adds an extra layer of difficulty. To address this novel challenge, we propose three algorithms: Fair Continuous Greedy (FairCG1 and FairCG2) and Fair Discrete Greedy (FairDG), all of which satisfy the fairness requirement whenever feasible. Moreover, we prove nontrivial lower bounds on the achieved time-average utility under FairCG1 and FairCG2. In addition, by giving a higher priority to fairness, FairDG ensures a stronger short-term fairness guarantee, which holds in every round. Finally, we perform extensive simulations to verify the effectiveness of the proposed algorithms in terms of the time-average utility and fairness satisfaction.

</p>
</details>


[Next Page]({{ '/2021/07/24/2021.07.24.html' | relative_url }})
