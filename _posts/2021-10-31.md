## Summary for 2021-10-31, created on 2021-12-14


<details><summary><b>PIE: Pseudo-Invertible Encoder</b>
<a href="https://arxiv.org/abs/2111.00619">arxiv:2111.00619</a>
&#x1F4C8; 8 <br>
<p>Jan Jetze Beitler, Ivan Sosnovik, Arnold Smeulders</p></summary>
<p>

**Abstract:** We consider the problem of information compression from high dimensional data. Where many studies consider the problem of compression by non-invertible transformations, we emphasize the importance of invertible compression. We introduce new class of likelihood-based autoencoders with pseudo bijective architecture, which we call Pseudo Invertible Encoders. We provide the theoretical explanation of their principles. We evaluate Gaussian Pseudo Invertible Encoder on MNIST, where our model outperforms WAE and VAE in sharpness of the generated images.

</p>
</details>

<details><summary><b>R-BERT-CNN: Drug-target interactions extraction from biomedical literature</b>
<a href="https://arxiv.org/abs/2111.00611">arxiv:2111.00611</a>
&#x1F4C8; 7 <br>
<p>Jehad Aldahdooh, Ziaurrehman Tanoli, Jing Tang</p></summary>
<p>

**Abstract:** In this research, we present our work participation for the DrugProt task of BioCreative VII challenge. Drug-target interactions (DTIs) are critical for drug discovery and repurposing, which are often manually extracted from the experimental articles. There are >32M biomedical articles on PubMed and manually extracting DTIs from such a huge knowledge base is challenging. To solve this issue, we provide a solution for Track 1, which aims to extract 10 types of interactions between drug and protein entities. We applied an Ensemble Classifier model that combines BioMed-RoBERTa, a state of art language model, with Convolutional Neural Networks (CNN) to extract these relations. Despite the class imbalances in the BioCreative VII DrugProt test corpus, our model achieves a good performance compared to the average of other submissions in the challenge, with the micro F1 score of 55.67% (and 63% on BioCreative VI ChemProt test corpus). The results show the potential of deep learning in extracting various types of DTIs.

</p>
</details>

<details><summary><b>TorchXRayVision: A library of chest X-ray datasets and models</b>
<a href="https://arxiv.org/abs/2111.00595">arxiv:2111.00595</a>
&#x1F4C8; 7 <br>
<p>Joseph Paul Cohen, Joseph D. Viviano, Paul Bertin, Paul Morrison, Parsa Torabian, Matteo Guarrera, Matthew P Lungren, Akshay Chaudhari, Rupert Brooks, Mohammad Hashir, Hadrien Bertrand</p></summary>
<p>

**Abstract:** TorchXRayVision is an open source software library for working with chest X-ray datasets and deep learning models. It provides a common interface and common pre-processing chain for a wide set of publicly available chest X-ray datasets. In addition, a number of classification and representation learning models with different architectures, trained on different data combinations, are available through the library to serve as baselines or feature extractors.

</p>
</details>

<details><summary><b>RMNet: Equivalently Removing Residual Connection from Networks</b>
<a href="https://arxiv.org/abs/2111.00687">arxiv:2111.00687</a>
&#x1F4C8; 5 <br>
<p>Fanxu Meng, Hao Cheng, Jiaxin Zhuang, Ke Li, Xing Sun</p></summary>
<p>

**Abstract:** Although residual connection enables training very deep neural networks, it is not friendly for online inference due to its multi-branch topology. This encourages many researchers to work on designing DNNs without residual connections at inference. For example, RepVGG re-parameterizes multi-branch topology to a VGG-like (single-branch) model when deploying, showing great performance when the network is relatively shallow. However, RepVGG can not transform ResNet to VGG equivalently because re-parameterizing methods can only be applied to linear blocks and the non-linear layers (ReLU) have to be put outside of the residual connection which results in limited representation ability, especially for deeper networks. In this paper, we aim to remedy this problem and propose to remove the residual connection in a vanilla ResNet equivalently by a reserving and merging (RM) operation on ResBlock. Specifically, the RM operation allows input feature maps to pass through the block while reserving their information and merges all the information at the end of each block, which can remove residual connections without changing the original output. As a plug-in method, RM Operation basically has three advantages: 1) its implementation makes it naturally friendly for high ratio network pruning. 2) it helps break the depth limitation of RepVGG. 3) it leads to better accuracy-speed trade-off network (RMNet) compared to ResNet and RepVGG. We believe the ideology of RM Operation can inspire many insights on model design for the community in the future. Code is available at: https://github.com/fxmeng/RMNet.

</p>
</details>

<details><summary><b>Distantly Supervised Semantic Text Detection and Recognition for Broadcast Sports Videos Understanding</b>
<a href="https://arxiv.org/abs/2111.00629">arxiv:2111.00629</a>
&#x1F4C8; 5 <br>
<p>Avijit Shah, Topojoy Biswas, Sathish Ramadoss, Deven Santosh Shah</p></summary>
<p>

**Abstract:** Comprehensive understanding of key players and actions in multiplayer sports broadcast videos is a challenging problem. Unlike in news or finance videos, sports videos have limited text. While both action recognition for multiplayer sports and detection of players has seen robust research, understanding contextual text in video frames still remains one of the most impactful avenues of sports video understanding. In this work we study extremely accurate semantic text detection and recognition in sports clocks, and challenges therein. We observe unique properties of sports clocks, which makes it hard to utilize general-purpose pre-trained detectors and recognizers, so that text can be accurately understood to the degree of being used to align to external knowledge. We propose a novel distant supervision technique to automatically build sports clock datasets. Along with suitable data augmentations, combined with any state-of-the-art text detection and recognition model architectures, we extract extremely accurate semantic text. Finally, we share our computational architecture pipeline to scale this system in industrial setting and proposed a robust dataset for the same to validate our results.

</p>
</details>

<details><summary><b>IGCN: Image-to-graph Convolutional Network for 2D/3D Deformable Registration</b>
<a href="https://arxiv.org/abs/2111.00484">arxiv:2111.00484</a>
&#x1F4C8; 5 <br>
<p>Megumi Nakao, Mitsuhiro Nakamura, Tetsuya Matsuda</p></summary>
<p>

**Abstract:** Organ shape reconstruction based on a single-projection image during treatment has wide clinical scope, e.g., in image-guided radiotherapy and surgical guidance. We propose an image-to-graph convolutional network that achieves deformable registration of a 3D organ mesh for a single-viewpoint 2D projection image. This framework enables simultaneous training of two types of transformation: from the 2D projection image to a displacement map, and from the sampled per-vertex feature to a 3D displacement that satisfies the geometrical constraint of the mesh structure. Assuming application to radiation therapy, the 2D/3D deformable registration performance is verified for multiple abdominal organs that have not been targeted to date, i.e., the liver, stomach, duodenum, and kidney, and for pancreatic cancer. The experimental results show shape prediction considering relationships among multiple organs can be used to predict respiratory motion and deformation from digitally reconstructed radiographs with clinically acceptable accuracy.

</p>
</details>

<details><summary><b>Learning Pruned Structure and Weights Simultaneously from Scratch: an Attention based Approach</b>
<a href="https://arxiv.org/abs/2111.02399">arxiv:2111.02399</a>
&#x1F4C8; 4 <br>
<p>Qisheng He, Ming Dong, Loren Schwiebert, Weisong Shi</p></summary>
<p>

**Abstract:** As a deep learning model typically contains millions of trainable weights, there has been a growing demand for a more efficient network structure with reduced storage space and improved run-time efficiency. Pruning is one of the most popular network compression techniques. In this paper, we propose a novel unstructured pruning pipeline, Attention-based Simultaneous sparse structure and Weight Learning (ASWL). Unlike traditional channel-wise or weight-wise attention mechanism, ASWL proposed an efficient algorithm to calculate the pruning ratio through layer-wise attention for each layer, and both weights for the dense network and the sparse network are tracked so that the pruned structure is simultaneously learned from randomly initialized weights. Our experiments on MNIST, Cifar10, and ImageNet show that ASWL achieves superior pruning results in terms of accuracy, pruning ratio and operating efficiency when compared with state-of-the-art network pruning methods.

</p>
</details>

<details><summary><b>Transparency of Deep Neural Networks for Medical Image Analysis: A Review of Interpretability Methods</b>
<a href="https://arxiv.org/abs/2111.02398">arxiv:2111.02398</a>
&#x1F4C8; 4 <br>
<p>Zohaib Salahuddin, Henry C Woodruff, Avishek Chatterjee, Philippe Lambin</p></summary>
<p>

**Abstract:** Artificial Intelligence has emerged as a useful aid in numerous clinical applications for diagnosis and treatment decisions. Deep neural networks have shown same or better performance than clinicians in many tasks owing to the rapid increase in the available data and computational power. In order to conform to the principles of trustworthy AI, it is essential that the AI system be transparent, robust, fair and ensure accountability. Current deep neural solutions are referred to as black-boxes due to a lack of understanding of the specifics concerning the decision making process. Therefore, there is a need to ensure interpretability of deep neural networks before they can be incorporated in the routine clinical workflow. In this narrative review, we utilized systematic keyword searches and domain expertise to identify nine different types of interpretability methods that have been used for understanding deep learning models for medical image analysis applications based on the type of generated explanations and technical similarities. Furthermore, we report the progress made towards evaluating the explanations produced by various interpretability methods. Finally we discuss limitations, provide guidelines for using interpretability methods and future directions concerning the interpretability of deep neural networks for medical imaging analysis.

</p>
</details>

<details><summary><b>Hierarchical Decision Ensembles- An inferential framework for uncertain Human-AI collaboration in forensic examinations</b>
<a href="https://arxiv.org/abs/2111.01131">arxiv:2111.01131</a>
&#x1F4C8; 4 <br>
<p>Ganesh Krishnan, Heike Hofmann</p></summary>
<p>

**Abstract:** Forensic examination of evidence like firearms and toolmarks, traditionally involves a visual and therefore subjective assessment of similarity of two questioned items. Statistical models are used to overcome this subjectivity and allow specification of error rates. These models are generally quite complex and produce abstract results at different levels of the analysis. Presenting such metrics and complicated results to examiners is challenging, as examiners generally do not have substantial statistical training to accurately interpret results. This creates distrust in statistical modelling and lowers the rate of acceptance of more objective measures that the discipline at large is striving for. We present an inferential framework for assessing the model and its output. The framework is designed to calibrate trust in forensic experts by bridging the gap between domain specific knowledge and predictive model results, allowing forensic examiners to validate the claims of the predictive model while critically assessing results.

</p>
</details>

<details><summary><b>End-to-End Learning of Deep Kernel Acquisition Functions for Bayesian Optimization</b>
<a href="https://arxiv.org/abs/2111.00639">arxiv:2111.00639</a>
&#x1F4C8; 4 <br>
<p>Tomoharu Iwata</p></summary>
<p>

**Abstract:** For Bayesian optimization (BO) on high-dimensional data with complex structure, neural network-based kernels for Gaussian processes (GPs) have been used to learn flexible surrogate functions by the high representation power of deep learning. However, existing methods train neural networks by maximizing the marginal likelihood, which do not directly improve the BO performance. In this paper, we propose a meta-learning method for BO with neural network-based kernels that minimizes the expected gap between the true optimum value and the best value found by BO. We model a policy, which takes the current evaluated data points as input and outputs the next data point to be evaluated, by a neural network, where neural network-based kernels, GPs, and mutual information-based acquisition functions are used as its layers. With our model, the neural network-based kernel is trained to be appropriate for the acquisition function by backpropagating the gap through the acquisition function and GP. Our model is trained by a reinforcement learning framework from multiple tasks. Since the neural network is shared across different tasks, we can gather knowledge on BO from multiple training tasks, and use the knowledge for unseen test tasks. In experiments using three text document datasets, we demonstrate that the proposed method achieves better BO performance than the existing methods.

</p>
</details>

<details><summary><b>Towards Language Modelling in the Speech Domain Using Sub-word Linguistic Units</b>
<a href="https://arxiv.org/abs/2111.00610">arxiv:2111.00610</a>
&#x1F4C8; 4 <br>
<p>Anurag Katakkar, Alan W Black</p></summary>
<p>

**Abstract:** Language models (LMs) for text data have been studied extensively for their usefulness in language generation and other downstream tasks. However, language modelling purely in the speech domain is still a relatively unexplored topic, with traditional speech LMs often depending on auxiliary text LMs for learning distributional aspects of the language. For the English language, these LMs treat words as atomic units, which presents inherent challenges to language modelling in the speech domain. In this paper, we propose a novel LSTM-based generative speech LM that is inspired by the CBOW model and built on linguistic units including syllables and phonemes. This offers better acoustic consistency across utterances in the dataset, as opposed to single melspectrogram frames, or whole words. With a limited dataset, orders of magnitude smaller than that required by contemporary generative models, our model closely approximates babbling speech. We show the effect of training with auxiliary text LMs, multitask learning objectives, and auxiliary articulatory features. Through our experiments, we also highlight some well known, but poorly documented challenges in training generative speech LMs, including the mismatch between the supervised learning objective with which these models are trained such as Mean Squared Error (MSE), and the true objective, which is speech quality. Our experiments provide an early indication that while validation loss and Mel Cepstral Distortion (MCD) are not strongly correlated with generated speech quality, traditional text language modelling metrics like perplexity and next-token-prediction accuracy might be.

</p>
</details>

<details><summary><b>Cross-Domain Reasoning via Template Filling</b>
<a href="https://arxiv.org/abs/2111.00539">arxiv:2111.00539</a>
&#x1F4C8; 4 <br>
<p>Dheeraj Rajagopal, Vivek Khetan, Bogdan Sacaleanu, Anatole Gershman, Andrew Fano, Eduard Hovy</p></summary>
<p>

**Abstract:** In this paper, we explore the ability of sequence to sequence models to perform cross-domain reasoning. Towards this, we present a prompt-template-filling approach to enable sequence to sequence models to perform cross-domain reasoning. We also present a case-study with commonsense and health and well-being domains, where we study how prompt-template-filling enables pretrained sequence to sequence models across domains. Our experiments across several pretrained encoder-decoder models show that cross-domain reasoning is challenging for current models. We also show an in-depth error analysis and avenues for future research for reasoning across domains

</p>
</details>

<details><summary><b>Smart(Sampling)Augment: Optimal and Efficient Data Augmentation for Semantic Segmentation</b>
<a href="https://arxiv.org/abs/2111.00487">arxiv:2111.00487</a>
&#x1F4C8; 4 <br>
<p>Misgana Negassi, Diane Wagner, Alexander Reiterer</p></summary>
<p>

**Abstract:** Data augmentation methods enrich datasets with augmented data to improve the performance of neural networks. Recently, automated data augmentation methods have emerged, which automatically design augmentation strategies. Existing work focuses on image classification and object detection, whereas we provide the first study on semantic image segmentation and introduce two new approaches: \textit{SmartAugment} and \textit{SmartSamplingAugment}. SmartAugment uses Bayesian Optimization to search over a rich space of augmentation strategies and achieves a new state-of-the-art performance in all semantic segmentation tasks we consider. SmartSamplingAugment, a simple parameter-free approach with a fixed augmentation strategy competes in performance with the existing resource-intensive approaches and outperforms cheap state-of-the-art data augmentation methods. Further, we analyze the impact, interaction, and importance of data augmentation hyperparameters and perform ablation studies, which confirm our design choices behind SmartAugment and SmartSamplingAugment. Lastly, we will provide our source code for reproducibility and to facilitate further research.

</p>
</details>

<details><summary><b>Hierarchical Deep Residual Reasoning for Temporal Moment Localization</b>
<a href="https://arxiv.org/abs/2111.00417">arxiv:2111.00417</a>
&#x1F4C8; 4 <br>
<p>Ziyang Ma, Xianjing Han, Xuemeng Song, Yiran Cui, Liqiang Nie</p></summary>
<p>

**Abstract:** Temporal Moment Localization (TML) in untrimmed videos is a challenging task in the field of multimedia, which aims at localizing the start and end points of the activity in the video, described by a sentence query. Existing methods mainly focus on mining the correlation between video and sentence representations or investigating the fusion manner of the two modalities. These works mainly understand the video and sentence coarsely, ignoring the fact that a sentence can be understood from various semantics, and the dominant words affecting the moment localization in the semantics are the action and object reference. Toward this end, we propose a Hierarchical Deep Residual Reasoning (HDRR) model, which decomposes the video and sentence into multi-level representations with different semantics to achieve a finer-grained localization. Furthermore, considering that videos with different resolution and sentences with different length have different difficulty in understanding, we design the simple yet effective Res-BiGRUs for feature fusion, which is able to grasp the useful information in a self-adapting manner. Extensive experiments conducted on Charades-STA and ActivityNet-Captions datasets demonstrate the superiority of our HDRR model compared with other state-of-the-art methods.

</p>
</details>

<details><summary><b>Communication-Compressed Adaptive Gradient Method for Distributed Nonconvex Optimization</b>
<a href="https://arxiv.org/abs/2111.00705">arxiv:2111.00705</a>
&#x1F4C8; 3 <br>
<p>Yujia Wang, Lu Lin, Jinghui Chen</p></summary>
<p>

**Abstract:** Due to the explosion in the size of the training datasets, distributed learning has received growing interest in recent years. One of the major bottlenecks is the large communication cost between the central server and the local workers. While error feedback compression has been proven to be successful in reducing communication costs with stochastic gradient descent (SGD), there are much fewer attempts in building communication-efficient adaptive gradient methods with provable guarantees, which are widely used in training large-scale machine learning models. In this paper, we propose a new communication-compressed AMSGrad for distributed nonconvex optimization problem, which is provably efficient. Our proposed distributed learning framework features an effective gradient compression strategy and a worker-side model update design. We prove that the proposed communication-efficient distributed adaptive gradient method converges to the first-order stationary point with the same iteration complexity as uncompressed vanilla AMSGrad in the stochastic nonconvex optimization setting. Experiments on various benchmarks back up our theory.

</p>
</details>

<details><summary><b>Comparative Study of Long Document Classification</b>
<a href="https://arxiv.org/abs/2111.00702">arxiv:2111.00702</a>
&#x1F4C8; 3 <br>
<p>Vedangi Wagh, Snehal Khandve, Isha Joshi, Apurva Wani, Geetanjali Kale, Raviraj Joshi</p></summary>
<p>

**Abstract:** The amount of information stored in the form of documents on the internet has been increasing rapidly. Thus it has become a necessity to organize and maintain these documents in an optimum manner. Text classification algorithms study the complex relationships between words in a text and try to interpret the semantics of the document. These algorithms have evolved significantly in the past few years. There has been a lot of progress from simple machine learning algorithms to transformer-based architectures. However, existing literature has analyzed different approaches on different data sets thus making it difficult to compare the performance of machine learning algorithms. In this work, we revisit long document classification using standard machine learning approaches. We benchmark approaches ranging from simple Naive Bayes to complex BERT on six standard text classification datasets. We present an exhaustive comparison of different algorithms on a range of long document datasets. We re-iterate that long document classification is a simpler task and even basic algorithms perform competitively with BERT-based approaches on most of the datasets. The BERT-based models perform consistently well on all the datasets and can be blindly used for the document classification task when the computations cost is not a concern. In the shallow model's category, we suggest the usage of raw BiLSTM + Max architecture which performs decently across all the datasets. Even simpler Glove + Attention bag of words model can be utilized for simpler use cases. The importance of using sophisticated models is clearly visible in the IMDB sentiment dataset which is a comparatively harder task.

</p>
</details>

<details><summary><b>Influential Prototypical Networks for Few Shot Learning: A Dermatological Case Study</b>
<a href="https://arxiv.org/abs/2111.00698">arxiv:2111.00698</a>
&#x1F4C8; 3 <br>
<p>Ranjana Roy Chowdhury, Deepti R. Bathula</p></summary>
<p>

**Abstract:** Prototypical network (PN) is a simple yet effective few shot learning strategy. It is a metric-based meta-learning technique where classification is performed by computing Euclidean distances to prototypical representations of each class. Conventional PN attributes equal importance to all samples and generates prototypes by simply averaging the support sample embeddings belonging to each class. In this work, we propose a novel version of PN that attributes weights to support samples corresponding to their influence on the support sample distribution. Influence weights of samples are calculated based on maximum mean discrepancy (MMD) between the mean embeddings of sample distributions including and excluding the sample. Comprehensive evaluation of our proposed influential PN (IPNet) is performed by comparing its performance with other baseline PNs on three different benchmark dermatological datasets. IPNet outperforms all baseline models with compelling results across all three datasets and various N-way, K-shot classification tasks. Findings from cross-domain adaptation experiments further establish the robustness and generalizability of IPNet.

</p>
</details>

<details><summary><b>Comparative Explanations of Recommendations</b>
<a href="https://arxiv.org/abs/2111.00670">arxiv:2111.00670</a>
&#x1F4C8; 3 <br>
<p>Aobo Yang, Nan Wang, Renqin Cai, Hongbo Deng, Hongning Wang</p></summary>
<p>

**Abstract:** As recommendation is essentially a comparative (or ranking) process, a good explanation should illustrate to users why an item is believed to be better than another, i.e., comparative explanations about the recommended items. Ideally, after reading the explanations, a user should reach the same ranking of items as the system's. Unfortunately, little research attention has yet been paid on such comparative explanations.
  In this work, we develop an extract-and-refine architecture to explain the relative comparisons among a set of ranked items from a recommender system. For each recommended item, we first extract one sentence from its associated reviews that best suits the desired comparison against a set of reference items. Then this extracted sentence is further articulated with respect to the target user through a generative model to better explain why the item is recommended. We design a new explanation quality metric based on BLEU to guide the end-to-end training of the extraction and refinement components, which avoids generation of generic content. Extensive offline evaluations on two large recommendation benchmark datasets and serious user studies against an array of state-of-the-art explainable recommendation algorithms demonstrate the necessity of comparative explanations and the effectiveness of our solution.

</p>
</details>

<details><summary><b>RMNA: A Neighbor Aggregation-Based Knowledge Graph Representation Learning Model Using Rule Mining</b>
<a href="https://arxiv.org/abs/2111.00658">arxiv:2111.00658</a>
&#x1F4C8; 3 <br>
<p>Ling Chen, Jun Cui, Xing Tang, Chaodu Song, Yuntao Qian, Yansheng Li, Yongjun Zhang</p></summary>
<p>

**Abstract:** Although the state-of-the-art traditional representation learning (TRL) models show competitive performance on knowledge graph completion, there is no parameter sharing between the embeddings of entities, and the connections between entities are weak. Therefore, neighbor aggregation-based representation learning (NARL) models are proposed, which encode the information in the neighbors of an entity into its embeddings. However, existing NARL models either only utilize one-hop neighbors, ignoring the information in multi-hop neighbors, or utilize multi-hop neighbors by hierarchical neighbor aggregation, destroying the completeness of multi-hop neighbors. In this paper, we propose a NARL model named RMNA, which obtains and filters horn rules through a rule mining algorithm, and uses selected horn rules to transform valuable multi-hop neighbors into one-hop neighbors, therefore, the information in valuable multi-hop neighbors can be completely utilized by aggregating these one-hop neighbors. In experiments, we compare RMNA with the state-of-the-art TRL models and NARL models. The results show that RMNA has a competitive performance.

</p>
</details>

<details><summary><b>Settling the Horizon-Dependence of Sample Complexity in Reinforcement Learning</b>
<a href="https://arxiv.org/abs/2111.00633">arxiv:2111.00633</a>
&#x1F4C8; 3 <br>
<p>Yuanzhi Li, Ruosong Wang, Lin F. Yang</p></summary>
<p>

**Abstract:** Recently there is a surge of interest in understanding the horizon-dependence of the sample complexity in reinforcement learning (RL). Notably, for an RL environment with horizon length $H$, previous work have shown that there is a probably approximately correct (PAC) algorithm that learns an $O(1)$-optimal policy using $\mathrm{polylog}(H)$ episodes of environment interactions when the number of states and actions is fixed. It is yet unknown whether the $\mathrm{polylog}(H)$ dependence is necessary or not. In this work, we resolve this question by developing an algorithm that achieves the same PAC guarantee while using only $O(1)$ episodes of environment interactions, completely settling the horizon-dependence of the sample complexity in RL. We achieve this bound by (i) establishing a connection between value functions in discounted and finite-horizon Markov decision processes (MDPs) and (ii) a novel perturbation analysis in MDPs. We believe our new techniques are of independent interest and could be applied in related questions in RL.

</p>
</details>

<details><summary><b>Text Classification for Task-based Source Code Related Questions</b>
<a href="https://arxiv.org/abs/2111.00580">arxiv:2111.00580</a>
&#x1F4C8; 3 <br>
<p>Sairamvinay Vijayaraghavan, Jinxiao Song, David Tomassi, Siddhartha Punj, Jailan Sabet</p></summary>
<p>

**Abstract:** There is a key demand to automatically generate code for small tasks for developers. Websites such as StackOverflow provide a simplistic way by offering solutions in small snippets which provide a complete answer to whatever task question the developer wants to code. Natural Language Processing and particularly Question-Answering Systems are very helpful in resolving and working on these tasks. In this paper, we develop a two-fold deep learning model: Seq2Seq and a binary classifier that takes in the intent (which is in natural language) and code snippets in Python. We train both the intent and the code utterances in the Seq2Seq model, where we decided to compare the effect of the hidden layer embedding from the encoder for representing the intent and similarly, using the decoder's hidden layer embeddings for the code sequence. Then we combine both these embeddings and then train a simple binary neural network classifier model for predicting if the intent is correctly answered by the predicted code sequence from the seq2seq model. We find that the hidden state layer's embeddings perform slightly better than regular standard embeddings from a constructed vocabulary. We experimented with our tests on the CoNaLa dataset in addition to the StaQC database consisting of simple task-code snippet-based pairs. We empirically establish that using additional pre-trained embeddings for code snippets in Python is less context-based in comparison to using hidden state context vectors from seq2seq models.

</p>
</details>

<details><summary><b>What Went Wrong? Explaining Overall Dialogue Quality through Utterance-Level Impacts</b>
<a href="https://arxiv.org/abs/2111.00572">arxiv:2111.00572</a>
&#x1F4C8; 3 <br>
<p>James D. Finch, Sarah E. Finch, Jinho D. Choi</p></summary>
<p>

**Abstract:** Improving user experience of a dialogue system often requires intensive developer effort to read conversation logs, run statistical analyses, and intuit the relative importance of system shortcomings. This paper presents a novel approach to automated analysis of conversation logs that learns the relationship between user-system interactions and overall dialogue quality. Unlike prior work on utterance-level quality prediction, our approach learns the impact of each interaction from the overall user rating without utterance-level annotation, allowing resultant model conclusions to be derived on the basis of empirical evidence and at low cost. Our model identifies interactions that have a strong correlation with the overall dialogue quality in a chatbot setting. Experiments show that the automated analysis from our model agrees with expert judgments, making this work the first to show that such weakly-supervised learning of utterance-level quality prediction is highly achievable.

</p>
</details>

<details><summary><b>An Approach to Inference-Driven Dialogue Management within a Social Chatbot</b>
<a href="https://arxiv.org/abs/2111.00570">arxiv:2111.00570</a>
&#x1F4C8; 3 <br>
<p>Sarah E. Finch, James D. Finch, Daniil Huryn, William Hutsell, Xiaoyuan Huang, Han He, Jinho D. Choi</p></summary>
<p>

**Abstract:** We present a chatbot implementing a novel dialogue management approach based on logical inference. Instead of framing conversation a sequence of response generation tasks, we model conversation as a collaborative inference process in which speakers share information to synthesize new knowledge in real time. Our chatbot pipeline accomplishes this modelling in three broad stages. The first stage translates user utterances into a symbolic predicate representation. The second stage then uses this structured representation in conjunction with a larger knowledge base to synthesize new predicates using efficient graph matching. In the third and final stage, our bot selects a small subset of predicates and translates them into an English response. This approach lends itself to understanding latent semantics of user inputs, flexible initiative taking, and responses that are novel and coherent with the dialogue context.

</p>
</details>

<details><summary><b>Quality Estimation Using Round-trip Translation with Sentence Embeddings</b>
<a href="https://arxiv.org/abs/2111.00554">arxiv:2111.00554</a>
&#x1F4C8; 3 <br>
<p>Nathan Crone, Adam Power, John Weldon</p></summary>
<p>

**Abstract:** Estimating the quality of machine translation systems has been an ongoing challenge for researchers in this field. Many previous attempts at using round-trip translation as a measure of quality have failed, and there is much disagreement as to whether it can be a viable method of quality estimation. In this paper, we revisit round-trip translation, proposing a system which aims to solve the previous pitfalls found with the approach. Our method makes use of recent advances in language representation learning to more accurately gauge the similarity between the original and round-trip translated sentences. Experiments show that while our approach does not reach the performance of current state of the art methods, it may still be an effective approach for some language pairs.

</p>
</details>

<details><summary><b>Focal Attention Networks: optimising attention for biomedical image segmentation</b>
<a href="https://arxiv.org/abs/2111.00534">arxiv:2111.00534</a>
&#x1F4C8; 3 <br>
<p>Michael Yeung, Leonardo Rundo, Evis Sala, Carola-Bibiane Schönlieb, Guang Yang</p></summary>
<p>

**Abstract:** In recent years, there has been increasing interest to incorporate attention into deep learning architectures for biomedical image segmentation. The modular design of attention mechanisms enables flexible integration into convolutional neural network architectures, such as the U-Net. Whether attention is appropriate to use, what type of attention to use, and where in the network to incorporate attention modules, are all important considerations that are currently overlooked. In this paper, we investigate the role of the Focal parameter in modulating attention, revealing a link between attention in loss functions and networks. By incorporating a Focal distance penalty term, we extend the Unified Focal loss framework to include boundary-based losses. Furthermore, we develop a simple and interpretable, dataset and model-specific heuristic to integrate the Focal parameter into the Squeeze-and-Excitation block and Attention Gate, achieving optimal performance with fewer number of attention modules on three well-validated biomedical imaging datasets, suggesting judicious use of attention modules results in better performance and efficiency.

</p>
</details>

<details><summary><b>Incorporating Boundary Uncertainty into loss functions for biomedical image segmentation</b>
<a href="https://arxiv.org/abs/2111.00533">arxiv:2111.00533</a>
&#x1F4C8; 3 <br>
<p>Michael Yeung, Guang Yang, Evis Sala, Carola-Bibiane Schönlieb, Leonardo Rundo</p></summary>
<p>

**Abstract:** Manual segmentation is used as the gold-standard for evaluating neural networks on automated image segmentation tasks. Due to considerable heterogeneity in shapes, colours and textures, demarcating object boundaries is particularly difficult in biomedical images, resulting in significant inter and intra-rater variability. Approaches, such as soft labelling and distance penalty term, apply a global transformation to the ground truth, redefining the loss function with respect to uncertainty. However, global operations are computationally expensive, and neither approach accurately reflects the uncertainty underlying manual annotation. In this paper, we propose the Boundary Uncertainty, which uses morphological operations to restrict soft labelling to object boundaries, providing an appropriate representation of uncertainty in ground truth labels, and may be adapted to enable robust model training where systematic manual segmentation errors are present. We incorporate Boundary Uncertainty with the Dice loss, achieving consistently improved performance across three well-validated biomedical imaging datasets compared to soft labelling and distance-weighted penalty. Boundary Uncertainty not only more accurately reflects the segmentation process, but it is also efficient, robust to segmentation errors and exhibits better generalisation.

</p>
</details>

<details><summary><b>Learning Debiased and Disentangled Representations for Semantic Segmentation</b>
<a href="https://arxiv.org/abs/2111.00531">arxiv:2111.00531</a>
&#x1F4C8; 3 <br>
<p>Sanghyeok Chu, Dongwan Kim, Bohyung Han</p></summary>
<p>

**Abstract:** Deep neural networks are susceptible to learn biased models with entangled feature representations, which may lead to subpar performances on various downstream tasks. This is particularly true for under-represented classes, where a lack of diversity in the data exacerbates the tendency. This limitation has been addressed mostly in classification tasks, but there is little study on additional challenges that may appear in more complex dense prediction problems including semantic segmentation. To this end, we propose a model-agnostic and stochastic training scheme for semantic segmentation, which facilitates the learning of debiased and disentangled representations. For each class, we first extract class-specific information from the highly entangled feature map. Then, information related to a randomly sampled class is suppressed by a feature selection process in the feature space. By randomly eliminating certain class information in each training iteration, we effectively reduce feature dependencies among classes, and the model is able to learn more debiased and disentangled feature representations. Models trained with our approach demonstrate strong results on multiple semantic segmentation benchmarks, with especially notable performance gains on under-represented classes.

</p>
</details>

<details><summary><b>Calibrating the Dice loss to handle neural network overconfidence for biomedical image segmentation</b>
<a href="https://arxiv.org/abs/2111.00528">arxiv:2111.00528</a>
&#x1F4C8; 3 <br>
<p>Michael Yeung, Leonardo Rundo, Yang Nan, Evis Sala, Carola-Bibiane Schönlieb, Guang Yang</p></summary>
<p>

**Abstract:** The Dice similarity coefficient (DSC) is both a widely used metric and loss function for biomedical image segmentation due to its robustness to class imbalance. However, it is well known that the DSC loss is poorly calibrated, resulting in overconfident predictions that cannot be usefully interpreted in biomedical and clinical practice. Performance is often the only metric used to evaluate segmentations produced by deep neural networks, and calibration is often neglected. However, calibration is important for translation into biomedical and clinical practice, providing crucial contextual information to model predictions for interpretation by scientists and clinicians. In this study, we identify poor calibration as an emerging challenge of deep learning based biomedical image segmentation. We provide a simple yet effective extension of the DSC loss, named the DSC++ loss, that selectively modulates the penalty associated with overconfident, incorrect predictions. As a standalone loss function, the DSC++ loss achieves significantly improved calibration over the conventional DSC loss across five well-validated open-source biomedical imaging datasets. Similarly, we observe significantly improved when integrating the DSC++ loss into four DSC-based loss functions. Finally, we use softmax thresholding to illustrate that well calibrated outputs enable tailoring of precision-recall bias, an important post-processing technique to adapt the model predictions to suit the biomedical or clinical task. The DSC++ loss overcomes the major limitation of the DSC, providing a suitable loss function for training deep learning segmentation models for use in biomedical and clinical practice.

</p>
</details>

<details><summary><b>DSC-IITISM at FinCausal 2021: Combining POS tagging with Attention-based Contextual Representations for Identifying Causal Relationships in Financial Documents</b>
<a href="https://arxiv.org/abs/2111.00490">arxiv:2111.00490</a>
&#x1F4C8; 3 <br>
<p>Gunjan Haldar, Aman Mittal, Pradyumna Gupta</p></summary>
<p>

**Abstract:** Causality detection draws plenty of attention in the field of Natural Language Processing and linguistics research. It has essential applications in information retrieval, event prediction, question answering, financial analysis, and market research. In this study, we explore several methods to identify and extract cause-effect pairs in financial documents using transformers. For this purpose, we propose an approach that combines POS tagging with the BIO scheme, which can be integrated with modern transformer models to address this challenge of identifying causality in a given text. Our best methodology achieves an F1-Score of 0.9551, and an Exact Match Score of 0.8777 on the blind test in the FinCausal-2021 Shared Task at the FinCausal 2021 Workshop.

</p>
</details>

<details><summary><b>Graph Neural Network based scheduling : Improved throughput under a generalized interference model</b>
<a href="https://arxiv.org/abs/2111.00459">arxiv:2111.00459</a>
&#x1F4C8; 3 <br>
<p>S. Ramakrishnan, Jaswanthi Mandalapu, Subrahmanya Swamy Peruru, Bhavesh Jain, Eitan Altman</p></summary>
<p>

**Abstract:** In this work, we propose a Graph Convolutional Neural Networks (GCN) based scheduling algorithm for adhoc networks. In particular, we consider a generalized interference model called the $k$-tolerant conflict graph model and design an efficient approximation for the well-known Max-Weight scheduling algorithm. A notable feature of this work is that the proposed method do not require labelled data set (NP-hard to compute) for training the neural network. Instead, we design a loss function that utilises the existing greedy approaches and trains a GCN that improves the performance of greedy approaches. Our extensive numerical experiments illustrate that using our GCN approach, we can significantly ($4$-$20$ percent) improve the performance of the conventional greedy approach.

</p>
</details>

<details><summary><b>Predicting Cancer Using Supervised Machine Learning: Mesothelioma</b>
<a href="https://arxiv.org/abs/2111.01912">arxiv:2111.01912</a>
&#x1F4C8; 2 <br>
<p>Avishek Choudhury</p></summary>
<p>

**Abstract:** Background: Pleural Mesothelioma (PM) is an unusual, belligerent tumor that rapidly develops into cancer in the pleura of the lungs. Pleural Mesothelioma is a common type of Mesothelioma that accounts for about 75% of all Mesothelioma diagnosed yearly in the U.S. Diagnosis of Mesothelioma takes several months and is expensive. Given the risk and constraints associated with PM diagnosis, early identification of this ailment is essential for patient health. Objective: In this study, we use artificial intelligence algorithms recommending the best fit model for early diagnosis and prognosis of MPM. Methods: We retrospectively retrieved patients clinical data collected by Dicle University, Turkey, and applied multilayered perceptron (MLP), voted perceptron (VP), Clojure classifier (CC), kernel logistic regression (KLR), stochastic gradient decent SGD), adaptive boosting (AdaBoost), Hoeffding tree (VFDT), and primal estimated sub-gradient solver for support vector machine (s-Pegasos). We evaluated the models, compared and tested using paired T-test (corrected) at 0.05 significance based on their respective classification accuracy, f-measure, precision, recall, root mean squared error, receivers characteristic curve (ROC), and precision-recall curve (PRC). Results: In phase-1, SGD, AdaBoost. M1, KLR, MLP, VFDT generate optimal results with the highest possible performance measures. In phase 2, AdaBoost, with a classification accuracy of 71.29%, outperformed all other algorithms. C-reactive protein, platelet count, duration of symptoms, gender, and pleural protein were found to be the most relevant predictors that can prognosticate Mesothelioma. Conclusion: This study confirms that data obtained from Biopsy and imagining tests are strong predictors of Mesothelioma but are associated with a high cost; however, they can identify Mesothelioma with optimal accuracy.

</p>
</details>

<details><summary><b>Graph Structural Attack by Spectral Distance</b>
<a href="https://arxiv.org/abs/2111.00684">arxiv:2111.00684</a>
&#x1F4C8; 2 <br>
<p>Lu Lin, Ethan Blaser, Hongning Wang</p></summary>
<p>

**Abstract:** Graph Convolutional Networks (GCNs) have fueled a surge of interest due to their superior performance on graph learning tasks, but are also shown vulnerability to adversarial attacks. In this paper, an effective graph structural attack is investigated to disrupt graph spectral filters in the Fourier domain. We define the spectral distance based on the eigenvalues of graph Laplacian to measure the disruption of spectral filters. We then generate edge perturbations by simultaneously maximizing a task-specific attack objective and the proposed spectral distance. The experiments demonstrate remarkable effectiveness of the proposed attack in the white-box setting at both training and test time. Our qualitative analysis shows the connection between the attack behavior and the imposed changes on the spectral distribution, which provides empirical evidence that maximizing spectral distance is an effective manner to change the structural property of graphs in the spatial domain and perturb the frequency components in the Fourier domain.

</p>
</details>

<details><summary><b>Self-Verification in Image Denoising</b>
<a href="https://arxiv.org/abs/2111.00666">arxiv:2111.00666</a>
&#x1F4C8; 2 <br>
<p>Huangxing Lin, Yihong Zhuang, Delu Zeng, Yue Huang, Xinghao Ding, John Paisley</p></summary>
<p>

**Abstract:** We devise a new regularization, called self-verification, for image denoising. This regularization is formulated using a deep image prior learned by the network, rather than a traditional predefined prior. Specifically, we treat the output of the network as a ``prior'' that we denoise again after ``re-noising''. The comparison between the again denoised image and its prior can be interpreted as a self-verification of the network's denoising ability. We demonstrate that self-verification encourages the network to capture low-level image statistics needed to restore the image. Based on this self-verification regularization, we further show that the network can learn to denoise even if it has not seen any clean images. This learning strategy is self-supervised, and we refer to it as Self-Verification Image Denoising (SVID). SVID can be seen as a mixture of learning-based methods and traditional model-based denoising methods, in which regularization is adaptively formulated using the output of the network. We show the application of SVID to various denoising tasks using only observed corrupted data. It can achieve the denoising performance close to supervised CNNs.

</p>
</details>

<details><summary><b>Collage: Automated Integration of Deep Learning Backends</b>
<a href="https://arxiv.org/abs/2111.00655">arxiv:2111.00655</a>
&#x1F4C8; 2 <br>
<p>Byungsoo Jeon, Sunghyun Park, Peiyuan Liao, Sheng Xu, Tianqi Chen, Zhihao Jia</p></summary>
<p>

**Abstract:** Strong demands for efficient deployment of Deep Learning (DL) applications prompt the rapid development of a rich DL ecosystem. To keep up with its fast advancement, it is crucial for DL frameworks to efficiently integrate a variety of optimized libraries and runtimes as their backends and generate the fastest possible executable by using them properly. However, current DL frameworks require significant manual effort to integrate diverse backends and often fail to deliver high performance. In this paper, we propose Collage, an automatic framework for integrating DL backends. Collage provides a backend registration interface that allows users to precisely specify the capability of various backends. By leveraging the specifications of available backends, Collage searches for an optimized backend placement for a given workload and execution environment. Our evaluation shows that Collage automatically integrates multiple backends together without manual intervention, and outperforms existing frameworks by 1.21x, 1.39x, 1.40x on two different NVIDIA GPUs and an Intel CPU respectively.

</p>
</details>

<details><summary><b>Safe Learning of Linear Time-Invariant Systems</b>
<a href="https://arxiv.org/abs/2111.00631">arxiv:2111.00631</a>
&#x1F4C8; 2 <br>
<p>Farhad Farokhi, Alex S. Leong, Mohammad Zamani, Iman Shames</p></summary>
<p>

**Abstract:** We consider safety in simultaneous learning and control of discrete-time linear time-invariant systems. We provide rigorous confidence bounds on the learned model of the system based on the number of utilized state measurements. These bounds are used to modify control inputs to the system via an optimization problem with potentially time-varying safety constraints. We prove that the state can only exit the safe set with small probability, provided a feasible solution to the safety-constrained optimization exists. This optimization problem is then reformulated in a more computationally-friendly format by tightening the safety constraints to account for model uncertainty during learning. The tightening decreases as the confidence in the learned model improves. We finally prove that, under persistence of excitation, the tightening becomes negligible as more measurements are gathered.

</p>
</details>

<details><summary><b>Unsupervised Learning to Subphenotype Delirium Patients from Electronic Health Records</b>
<a href="https://arxiv.org/abs/2111.00592">arxiv:2111.00592</a>
&#x1F4C8; 2 <br>
<p>Yiqing Zhao, Yuan Luo</p></summary>
<p>

**Abstract:** Delirium is a common acute onset brain dysfunction in the emergency setting and is associated with higher mortality. It is difficult to detect and monitor since its presentations and risk factors can be different depending on the underlying medical condition of patients. In our study, we aimed to identify subtypes within the delirium population and build subgroup-specific predictive models to detect delirium using Medical Information Mart for Intensive Care IV (MIMIC-IV) data. We showed that clusters exist within the delirium population. Differences in feature importance were also observed for subgroup-specific predictive models. Our work could recalibrate existing delirium prediction models for each delirium subgroup and improve the precision of delirium detection and monitoring for ICU or emergency department patients who had highly heterogeneous medical conditions.

</p>
</details>

<details><summary><b>Laplacian Constrained Precision Matrix Estimation: Existence and High Dimensional Consistency</b>
<a href="https://arxiv.org/abs/2111.00590">arxiv:2111.00590</a>
&#x1F4C8; 2 <br>
<p>Eduardo Pavez</p></summary>
<p>

**Abstract:** This paper considers the problem of estimating high dimensional Laplacian constrained precision matrices by minimizing Stein's loss. We obtain a necessary and sufficient condition for existence of this estimator, that boils down to checking whether a certain data dependent graph is connected. We also prove consistency in the high dimensional setting under the symmetryzed Stein loss. We show that the error rate does not depend on the graph sparsity, or other type of structure, and that Laplacian constraints are sufficient for high dimensional consistency. Our proofs exploit properties of graph Laplacians, and a characterization of the proposed estimator based on effective graph resistances. We validate our theoretical claims with numerical experiments.

</p>
</details>

<details><summary><b>Fast Global Convergence of Policy Optimization for Constrained MDPs</b>
<a href="https://arxiv.org/abs/2111.00552">arxiv:2111.00552</a>
&#x1F4C8; 2 <br>
<p>Tao Liu, Ruida Zhou, Dileep Kalathil, P. R. Kumar, Chao Tian</p></summary>
<p>

**Abstract:** We address the issue of safety in reinforcement learning. We pose the problem in a discounted infinite-horizon constrained Markov decision process framework. Existing results have shown that gradient-based methods are able to achieve an $\mathcal{O}(1/\sqrt{T})$ global convergence rate both for the optimality gap and the constraint violation. We exhibit a natural policy gradient-based algorithm that has a faster convergence rate $\mathcal{O}(\log(T)/T)$ for both the optimality gap and the constraint violation. When Slater's condition is satisfied and known a priori, zero constraint violation can be further guaranteed for a sufficiently large $T$ while maintaining the same convergence rate.

</p>
</details>

<details><summary><b>Learning to Detect Open Carry and Concealed Object with 77GHz Radar</b>
<a href="https://arxiv.org/abs/2111.00551">arxiv:2111.00551</a>
&#x1F4C8; 2 <br>
<p>Xiangyu Gao, Hui Liu, Sumit Roy, Guanbin Xing, Ali Alansari, Youchen Luo</p></summary>
<p>

**Abstract:** Detecting harmful carried objects plays a key role in intelligent surveillance systems and has widespread applications, for example, in airport security. In this paper, we focus on the relatively unexplored area of using low-cost 77GHz mmWave radar for the carried objects detection problem. The proposed system is capable of real-time detecting three classes of objects - laptop, phone, and knife - under open carry and concealed cases where objects are hidden with clothes or bags. This capability is achieved by initial signal processing for localization and generating range-azimuth-elevation image cubes, followed by a deep learning-based prediction network and a multi-shot post-processing module for detecting objects. Extensive experiments for validating the system performance on detecting open carry and concealed objects have been presented with a self-built radar-camera testbed and dataset. Additionally, the influence of different input, factors, and parameters on system performance is analyzed, providing an intuitive understanding of the system. This system would be the very first baseline for other future works aiming to detect carried objects using 77GHz radar.

</p>
</details>

<details><summary><b>Efficient, Anytime Algorithms for Calibration with Isotonic Regression under Strictly Convex Losses</b>
<a href="https://arxiv.org/abs/2111.00468">arxiv:2111.00468</a>
&#x1F4C8; 2 <br>
<p>Kaan Gokcesu, Hakan Gokcesu</p></summary>
<p>

**Abstract:** We investigate the calibration of estimations to increase performance with an optimal monotone transform on the estimator outputs. We start by studying the traditional square error setting with its weighted variant and show that the optimal monotone transform is in the form of a unique staircase function. We further show that this staircase behavior is preserved for general strictly convex loss functions. Their optimal monotone transforms are also unique, i.e., there exist a single staircase transform that achieves the minimum loss. We propose a linear time and space algorithm that can find such optimal transforms for specific loss settings. Our algorithm has an online implementation where the optimal transform for the samples observed so far are found in linear space and amortized time when the samples arrive in an ordered fashion. We also extend our results to cases where the functions are not trivial to individually optimize and propose an anytime algorithm, which has linear space and pseudo-linearithmic time complexity.

</p>
</details>

<details><summary><b>FastCover: An Unsupervised Learning Framework for Multi-Hop Influence Maximization in Social Networks</b>
<a href="https://arxiv.org/abs/2111.00463">arxiv:2111.00463</a>
&#x1F4C8; 2 <br>
<p>Runbo Ni, Xueyan Li, Fangqi Li, Xiaofeng Gao, Guihai Chen</p></summary>
<p>

**Abstract:** Finding influential users in social networks is a fundamental problem with many possible useful applications. Viewing the social network as a graph, the influence of a set of users can be measured by the number of neighbors located within a given number of hops in the network, where each hop marks a step of influence diffusion. In this paper, we reduce the problem of IM to a budget-constrained d-hop dominating set problem (kdDSP). We propose a unified machine learning (ML) framework, FastCover, to solve kdDSP by learning an efficient greedy strategy in an unsupervised way. As one critical component of the framework, we devise a novel graph neural network (GNN) architecture, graph reversed attention network (GRAT), that captures the diffusion process among neighbors. Unlike most heuristic algorithms and concurrent ML frameworks for combinatorial optimization problems, FastCover determines the entire seed set from the nodes' scores computed with only one forward propagation of the GNN and has a time complexity quasi-linear in the graph size. Experiments on synthetic graphs and real-world social networks demonstrate that FastCover finds solutions with better or comparable quality rendered by the concurrent algorithms while achieving a speedup of over 1000x.

</p>
</details>

<details><summary><b>Revisiting joint decoding based multi-talker speech recognition with DNN acoustic model</b>
<a href="https://arxiv.org/abs/2111.00009">arxiv:2111.00009</a>
&#x1F4C8; 2 <br>
<p>Martin Kocour, Kateřina Žmolíková, Lucas Ondel, Ján Švec, Marc Delcroix, Tsubasa Ochiai, Lukáš Burget, Jan Černocký</p></summary>
<p>

**Abstract:** In typical multi-talker speech recognition systems, a neural network-based acoustic model predicts senone state posteriors for each speaker. These are later used by a single-talker decoder which is applied on each speaker-specific output stream separately. In this work, we argue that such a scheme is sub-optimal and propose a principled solution that decodes all speakers jointly. We modify the acoustic model to predict joint state posteriors for all speakers, enabling the network to express uncertainty about the attribution of parts of the speech signal to the speakers. We employ a joint decoder that can make use of this uncertainty together with higher-level language information. For this, we revisit decoding algorithms used in factorial generative models in early multi-talker speech recognition systems. In contrast with these early works, we replace the GMM acoustic model with DNN, which provides greater modeling power and simplifies part of the inference. We demonstrate the advantage of joint decoding in proof of concept experiments on a mixed-TIDIGITS dataset.

</p>
</details>

<details><summary><b>Stress field prediction in fiber-reinforced composite materials using a deep learning approach</b>
<a href="https://arxiv.org/abs/2111.05271">arxiv:2111.05271</a>
&#x1F4C8; 1 <br>
<p>Anindya Bhaduri, Ashwini Gupta, Lori Graham-Brady</p></summary>
<p>

**Abstract:** Computational stress analysis is an important step in the design of material systems. Finite element method (FEM) is a standard approach of performing stress analysis of complex material systems. A way to accelerate stress analysis is to replace FEM with a data-driven machine learning based stress analysis approach. In this study, we consider a fiber-reinforced matrix composite material system and we use deep learning tools to find an alternative to the FEM approach for stress field prediction. We first try to predict stress field maps for composite material systems of fixed number of fibers with varying spatial configurations. Specifically, we try to find a mapping between the spatial arrangement of the fibers in the composite material and the corresponding von Mises stress field. This is achieved by using a convolutional neural network (CNN), specifically a U-Net architecture, using true stress maps of systems with same number of fibers as training data. U-Net is a encoder-decoder network which in this study takes in the composite material image as an input and outputs the stress field image which is of the same size as the input image. We perform a robustness analysis by taking different initializations of the training samples to find the sensitivity of the prediction accuracy to the small number of training samples. When the number of fibers in the composite material system is increased for the same volume fraction, a finer finite element mesh discretization is required to represent the geometry accurately. This leads to an increase in the computational cost. Thus, the secondary goal here is to predict the stress field for systems with larger number of fibers with varying spatial configurations using information from the true stress maps of relatively cheaper systems of smaller fiber number.

</p>
</details>

<details><summary><b>Classifying YouTube Comments Based on Sentiment and Type of Sentence</b>
<a href="https://arxiv.org/abs/2111.01908">arxiv:2111.01908</a>
&#x1F4C8; 1 <br>
<p>Rhitabrat Pokharel, Dixit Bhatta</p></summary>
<p>

**Abstract:** As a YouTube channel grows, each video can potentially collect enormous amounts of comments that provide direct feedback from the viewers. These comments are a major means of understanding viewer expectations and improving channel engagement. However, the comments only represent a general collection of user opinions about the channel and the content. Many comments are poorly constructed, trivial, and have improper spellings and grammatical errors. As a result, it is a tedious job to identify the comments that best interest the content creators. In this paper, we extract and classify the raw comments into different categories based on both sentiment and sentence types that will help YouTubers find relevant comments for growing their viewership. Existing studies have focused either on sentiment analysis (positive and negative) or classification of sub-types within the same sentence types (e.g., types of questions) on a text corpus. These have limited application on non-traditional text corpus like YouTube comments. We address this challenge of text extraction and classification from YouTube comments using well-known statistical measures and machine learning models. We evaluate each combination of statistical measure and the machine learning model using cross validation and $F_1$ scores. The results show that our approach that incorporates conventional methods performs well on the classification task, validating its potential in assisting content creators increase viewer engagement on their channel.

</p>
</details>

<details><summary><b>Latent Structures Mining with Contrastive Modality Fusion for Multimedia Recommendation</b>
<a href="https://arxiv.org/abs/2111.00678">arxiv:2111.00678</a>
&#x1F4C8; 1 <br>
<p>Jinghao Zhang, Yanqiao Zhu, Qiang Liu, Mengqi Zhang, Shu Wu, Liang Wang</p></summary>
<p>

**Abstract:** Recent years have witnessed growing interests in multimedia recommendation, which aims to predict whether a user will interact with an item with multimodal contents. Previous studies focus on modeling user-item interactions with multimodal features included as side information. However, this scheme is not well-designed for multimedia recommendation. Firstly, only collaborative item-item relationships are implicitly modeled through high-order item-user-item co-occurrences. We argue that the latent semantic item-item structures underlying these multimodal contents could be beneficial for learning better item representations and assist the recommender models to comprehensively discover candidate items. Secondly, previous studies disregard the fine-grained multimodal fusion. Although having access to multiple modalities might allow us to capture rich information, we argue that the simple coarse-grained fusion by linear combination or concatenation in previous work is insufficient to fully understand content information and item relationships.To this end, we propose a latent structure MIning with ContRastive mOdality fusion method (MICRO for brevity). To be specific, we devise a novel modality-aware structure learning module, which learns item-item relationships for each modality. Based on the learned modality-aware latent item relationships, we perform graph convolutions that explicitly inject item affinities to modality-aware item representations. Then, we design a novel contrastive method to fuse multimodal features. These enriched item representations can be plugged into existing collaborative filtering methods to make more accurate recommendations. Extensive experiments on real-world datasets demonstrate the superiority of our method over state-of-the-art baselines.

</p>
</details>

<details><summary><b>Bayesian optimization of distributed neurodynamical controller models for spatial navigation</b>
<a href="https://arxiv.org/abs/2111.00599">arxiv:2111.00599</a>
&#x1F4C8; 1 <br>
<p>Armin Hadzic, Grace M. Hwang, Kechen Zhang, Kevin M. Schultz, Joseph D. Monaco</p></summary>
<p>

**Abstract:** Dynamical systems models for controlling multi-agent swarms have demonstrated advances toward resilient, decentralized navigation algorithms. We previously introduced the NeuroSwarms controller, in which agent-based interactions were modeled by analogy to neuronal network interactions, including attractor dynamics and phase synchrony, that have been theorized to operate within hippocampal place-cell circuits in navigating rodents. This complexity precludes linear analyses of stability, controllability, and performance typically used to study conventional swarm models. Further, tuning dynamical controllers by hand or grid search is often inadequate due to the complexity of objectives, dimensionality of model parameters, and computational costs of simulation-based sampling. Here, we present a framework for tuning dynamical controller models of autonomous multi-agent systems based on Bayesian Optimization (BayesOpt). Our approach utilizes a task-dependent objective function to train Gaussian Processes (GPs) as surrogate models to achieve adaptive and efficient exploration of a dynamical controller model's parameter space. We demonstrate this approach by studying an objective function selecting for NeuroSwarms behaviors that cooperatively localize and capture spatially distributed rewards under time pressure. We generalized task performance across environments by combining scores for simulations in distinct geometries. To validate search performance, we compared high-dimensional clustering for high- vs. low-likelihood parameter points by visualizing sample trajectories in Uniform Manifold Approximation and Projection (UMAP) embeddings. Our findings show that adaptive, sample-efficient evaluation of the self-organizing behavioral capacities of complex systems, including dynamical swarm controllers, can accelerate the translation of neuroscientific theory to applied domains.

</p>
</details>

<details><summary><b>Decentralized Multi-Agent Reinforcement Learning: An Off-Policy Method</b>
<a href="https://arxiv.org/abs/2111.00438">arxiv:2111.00438</a>
&#x1F4C8; 1 <br>
<p>Kuo Li, Qing-Shan Jia</p></summary>
<p>

**Abstract:** We discuss the problem of decentralized multi-agent reinforcement learning (MARL) in this work. In our setting, the global state, action, and reward are assumed to be fully observable, while the local policy is protected as privacy by each agent, and thus cannot be shared with others. There is a communication graph, among which the agents can exchange information with their neighbors. The agents make individual decisions and cooperate to reach a higher accumulated reward.
  Towards this end, we first propose a decentralized actor-critic (AC) setting. Then, the policy evaluation and policy improvement algorithms are designed for discrete and continuous state-action-space Markov Decision Process (MDP) respectively. Furthermore, convergence analysis is given under the discrete-space case, which guarantees that the policy will be reinforced by alternating between the processes of policy evaluation and policy improvement. In order to validate the effectiveness of algorithms, we design experiments and compare them with previous algorithms, e.g., Q-learning \cite{watkins1992q} and MADDPG \cite{lowe2017multi}. The results show that our algorithms perform better from the aspects of both learning speed and final performance. Moreover, the algorithms can be executed in an off-policy manner, which greatly improves the data efficiency compared with on-policy algorithms.

</p>
</details>

<details><summary><b>Deep Learning in Human Activity Recognition with Wearable Sensors: A Review on Advances</b>
<a href="https://arxiv.org/abs/2111.00418">arxiv:2111.00418</a>
&#x1F4C8; 1 <br>
<p>Shibo Zhang, Yaxuan Li, Shen Zhang, Farzad Shahabi, Stephen Xia, Yu Deng, Nabil Alshurafa</p></summary>
<p>

**Abstract:** Mobile and wearable devices have enabled numerous applications, including activity tracking, wellness monitoring, and human-computer interaction, that measure and improve our daily lives. Many of these applications are made possible by leveraging the rich collection of low-power sensors found in many mobile and wearable devices to perform human activity recognition (HAR). Recently, deep learning has greatly pushed the boundaries of HAR on mobile and wearable devices. This paper systematically categorizes and summarizes existing work that introduces deep learning methods for wearables-based HAR and provides a comprehensive analysis of the current advancements, developing trends, and major challenges. We also present cutting-edge frontiers and future directions for deep learning--based HAR.

</p>
</details>

<details><summary><b>Safe Adaptive Learning-based Control for Constrained Linear Quadratic Regulators with Regret Guarantees</b>
<a href="https://arxiv.org/abs/2111.00411">arxiv:2111.00411</a>
&#x1F4C8; 1 <br>
<p>Yingying Li, Subhro Das, Jeff Shamma, Na Li</p></summary>
<p>

**Abstract:** We study the adaptive control of an unknown linear system with a quadratic cost function subject to safety constraints on both the states and actions. The challenges of this problem arise from the tension among safety, exploration, performance, and computation. To address these challenges, we propose a polynomial-time algorithm that guarantees feasibility and constraint satisfaction with high probability under proper conditions. Our algorithm is implemented on a single trajectory and does not require system restarts. Further, we analyze the regret of our learning algorithm compared to the optimal safe linear controller with known model information. The proposed algorithm can achieve a $\tilde O(T^{2/3})$ regret, where $T$ is the number of stages and $\tilde O(\cdot)$ absorbs some logarithmic terms of $T$.

</p>
</details>

<details><summary><b>Creating A Coefficient of Change in the Built Environment After a Natural Disaster</b>
<a href="https://arxiv.org/abs/2111.04462">arxiv:2111.04462</a>
&#x1F4C8; 0 <br>
<p>Karla Saldana Ochoa</p></summary>
<p>

**Abstract:** This study proposes a novel method to assess damages in the built environment using a deep learning workflow to quantify it. Thanks to an automated crawler, aerial images from before and after a natural disaster of 50 epicenters worldwide were obtained from Google Earth, generating a 10,000 aerial image database with a spatial resolution of 2 m per pixel. The study utilizes the algorithm Seg-Net to perform semantic segmentation of the built environment from the satellite images in both instances (prior and post-natural disasters). For image segmentation, Seg-Net is one of the most popular and general CNN architectures. The Seg-Net algorithm used reached an accuracy of 92% in the segmentation. After the segmentation, we compared the disparity between both cases represented as a percentage of change. Such coefficient of change represents the damage numerically an urban environment had to quantify the overall damage in the built environment. Such an index can give the government an estimate of the number of affected households and perhaps the extent of housing damage.

</p>
</details>


[Next Page](2021/2021-10/2021-10-30.md)
