## Summary for 2021-05-06, created on 2021-12-21


<details><summary><b>Machine Collaboration</b>
<a href="https://arxiv.org/abs/2105.02569">arxiv:2105.02569</a>
&#x1F4C8; 3840 <br>
<p>Qingfeng Liu, Yang Feng</p></summary>
<p>

**Abstract:** We propose a new ensemble framework for supervised learning, called machine collaboration (MaC), using a collection of base machines for prediction tasks. Unlike bagging/stacking (a parallel & independent framework) and boosting (a sequential & top-down framework), MaC is a type of circular & interactive learning framework. The circular & interactive feature helps the base machines to transfer information circularly and update their structures and parameters accordingly. The theoretical result on the risk bound of the estimator from MaC reveals that the circular & interactive feature can help MaC reduce risk via a parsimonious ensemble. We conduct extensive experiments on MaC using both simulated data and 119 benchmark real datasets. The results demonstrate that in most cases, MaC performs significantly better than several other state-of-the-art methods, including classification and regression trees, neural networks, stacking, and boosting.

</p>
</details>

<details><summary><b>Neural Algorithmic Reasoning</b>
<a href="https://arxiv.org/abs/2105.02761">arxiv:2105.02761</a>
&#x1F4C8; 298 <br>
<p>Petar Veličković, Charles Blundell</p></summary>
<p>

**Abstract:** Algorithms have been fundamental to recent global technological advances and, in particular, they have been the cornerstone of technical advances in one field rapidly being applied to another. We argue that algorithms possess fundamentally different qualities to deep learning methods, and this strongly suggests that, were deep learning methods better able to mimic algorithms, generalisation of the sort seen with algorithms would become possible with deep learning -- something far out of the reach of current machine learning methods. Furthermore, by representing elements in a continuous space of learnt algorithms, neural networks are able to adapt known algorithms more closely to real-world problems, potentially finding more efficient and pragmatic solutions than those proposed by human computer scientists.
  Here we present neural algorithmic reasoning -- the art of building neural networks that are able to execute algorithmic computation -- and provide our opinion on its transformative potential for running classical algorithms on inputs previously considered inaccessible to them.

</p>
</details>

<details><summary><b>Computer-Aided Design as Language</b>
<a href="https://arxiv.org/abs/2105.02769">arxiv:2105.02769</a>
&#x1F4C8; 51 <br>
<p>Yaroslav Ganin, Sergey Bartunov, Yujia Li, Ethan Keller, Stefano Saliceti</p></summary>
<p>

**Abstract:** Computer-Aided Design (CAD) applications are used in manufacturing to model everything from coffee mugs to sports cars. These programs are complex and require years of training and experience to master. A component of all CAD models particularly difficult to make are the highly structured 2D sketches that lie at the heart of every 3D construction. In this work, we propose a machine learning model capable of automatically generating such sketches. Through this, we pave the way for developing intelligent tools that would help engineers create better designs with less effort. Our method is a combination of a general-purpose language modeling technique alongside an off-the-shelf data serialization protocol. We show that our approach has enough flexibility to accommodate the complexity of the domain and performs well for both unconditional synthesis and image-to-sketch translation.

</p>
</details>

<details><summary><b>Learning Skeletal Articulations with Neural Blend Shapes</b>
<a href="https://arxiv.org/abs/2105.02451">arxiv:2105.02451</a>
&#x1F4C8; 49 <br>
<p>Peizhuo Li, Kfir Aberman, Rana Hanocka, Libin Liu, Olga Sorkine-Hornung, Baoquan Chen</p></summary>
<p>

**Abstract:** Animating a newly designed character using motion capture (mocap) data is a long standing problem in computer animation. A key consideration is the skeletal structure that should correspond to the available mocap data, and the shape deformation in the joint regions, which often requires a tailored, pose-specific refinement. In this work, we develop a neural technique for articulating 3D characters using enveloping with a pre-defined skeletal structure which produces high quality pose dependent deformations. Our framework learns to rig and skin characters with the same articulation structure (e.g., bipeds or quadrupeds), and builds the desired skeleton hierarchy into the network architecture. Furthermore, we propose neural blend shapes--a set of corrective pose-dependent shapes which improve the deformation quality in the joint regions in order to address the notorious artifacts resulting from standard rigging and skinning. Our system estimates neural blend shapes for input meshes with arbitrary connectivity, as well as weighting coefficients which are conditioned on the input joint rotations. Unlike recent deep learning techniques which supervise the network with ground-truth rigging and skinning parameters, our approach does not assume that the training data has a specific underlying deformation model. Instead, during training, the network observes deformed shapes and learns to infer the corresponding rig, skin and blend shapes using indirect supervision. During inference, we demonstrate that our network generalizes to unseen characters with arbitrary mesh connectivity, including unrigged characters built by 3D artists. Conforming to standard skeletal animation models enables direct plug-and-play in standard animation software, as well as game engines.

</p>
</details>

<details><summary><b>Reliability Testing for Natural Language Processing Systems</b>
<a href="https://arxiv.org/abs/2105.02590">arxiv:2105.02590</a>
&#x1F4C8; 45 <br>
<p>Samson Tan, Shafiq Joty, Kathy Baxter, Araz Taeihagh, Gregory A. Bennett, Min-Yen Kan</p></summary>
<p>

**Abstract:** Questions of fairness, robustness, and transparency are paramount to address before deploying NLP systems. Central to these concerns is the question of reliability: Can NLP systems reliably treat different demographics fairly and function correctly in diverse and noisy environments? To address this, we argue for the need for reliability testing and contextualize it among existing work on improving accountability. We show how adversarial attacks can be reframed for this goal, via a framework for developing reliability tests. We argue that reliability testing -- with an emphasis on interdisciplinary collaboration -- will enable rigorous and targeted testing, and aid in the enactment and enforcement of industry standards.

</p>
</details>

<details><summary><b>Learning Controllable Content Generators</b>
<a href="https://arxiv.org/abs/2105.02993">arxiv:2105.02993</a>
&#x1F4C8; 42 <br>
<p>Sam Earle, Maria Edwards, Ahmed Khalifa, Philip Bontrager, Julian Togelius</p></summary>
<p>

**Abstract:** It has recently been shown that reinforcement learning can be used to train generators capable of producing high-quality game levels, with quality defined in terms of some user-specified heuristic. To ensure that these generators' output is sufficiently diverse (that is, not amounting to the reproduction of a single optimal level configuration), the generation process is constrained such that the initial seed results in some variance in the generator's output. However, this results in a loss of control over the generated content for the human user. We propose to train generators capable of producing controllably diverse output, by making them "goal-aware." To this end, we add conditional inputs representing how close a generator is to some heuristic, and also modify the reward mechanism to incorporate that value. Testing on multiple domains, we show that the resulting level generators are capable of exploring the space of possible levels in a targeted, controllable manner, producing levels of comparable quality as their goal-unaware counterparts, that are diverse along designer-specified dimensions.

</p>
</details>

<details><summary><b>Structured dataset documentation: a datasheet for CheXpert</b>
<a href="https://arxiv.org/abs/2105.03020">arxiv:2105.03020</a>
&#x1F4C8; 23 <br>
<p>Christian Garbin, Pranav Rajpurkar, Jeremy Irvin, Matthew P. Lungren, Oge Marques</p></summary>
<p>

**Abstract:** Billions of X-ray images are taken worldwide each year. Machine learning, and deep learning in particular, has shown potential to help radiologists triage and diagnose images. However, deep learning requires large datasets with reliable labels. The CheXpert dataset was created with the participation of board-certified radiologists, resulting in the strong ground truth needed to train deep learning networks. Following the structured format of Datasheets for Datasets, this paper expands on the original CheXpert paper and other sources to show the critical role played by radiologists in the creation of reliable labels and to describe the different aspects of the dataset composition in detail. Such structured documentation intends to increase the awareness in the machine learning and medical communities of the strengths, applications, and evolution of CheXpert, thereby advancing the field of medical image analysis. Another objective of this paper is to put forward this dataset datasheet as an example to the community of how to create detailed and structured descriptions of datasets. We believe that clearly documenting the creation process, the contents, and applications of datasets accelerates the creation of useful and reliable models.

</p>
</details>

<details><summary><b>On the Ethical Limits of Natural Language Processing on Legal Text</b>
<a href="https://arxiv.org/abs/2105.02751">arxiv:2105.02751</a>
&#x1F4C8; 20 <br>
<p>Dimitrios Tsarapatsanis, Nikolaos Aletras</p></summary>
<p>

**Abstract:** Natural language processing (NLP) methods for analyzing legal text offer legal scholars and practitioners a range of tools allowing to empirically analyze law on a large scale. However, researchers seem to struggle when it comes to identifying ethical limits to using NLP systems for acquiring genuine insights both about the law and the systems' predictive capacity. In this paper we set out a number of ways in which to think systematically about such issues. We place emphasis on three crucial normative parameters which have, to the best of our knowledge, been underestimated by current debates: (a) the importance of academic freedom, (b) the existence of a wide diversity of legal and ethical norms domestically but even more so internationally and (c) the threat of moralism in research related to computational law. For each of these three parameters we provide specific recommendations for the legal NLP community. Our discussion is structured around the study of a real-life scenario that has prompted recent debate in the legal NLP research community.

</p>
</details>

<details><summary><b>Structured Ensembles: an Approach to Reduce the Memory Footprint of Ensemble Methods</b>
<a href="https://arxiv.org/abs/2105.02551">arxiv:2105.02551</a>
&#x1F4C8; 14 <br>
<p>Jary Pomponi, Simone Scardapane, Aurelio Uncini</p></summary>
<p>

**Abstract:** In this paper, we propose a novel ensembling technique for deep neural networks, which is able to drastically reduce the required memory compared to alternative approaches. In particular, we propose to extract multiple sub-networks from a single, untrained neural network by solving an end-to-end optimization task combining differentiable scaling over the original architecture, with multiple regularization terms favouring the diversity of the ensemble. Since our proposal aims to detect and extract sub-structures, we call it Structured Ensemble. On a large experimental evaluation, we show that our method can achieve higher or comparable accuracy to competing methods while requiring significantly less storage. In addition, we evaluate our ensembles in terms of predictive calibration and uncertainty, showing they compare favourably with the state-of-the-art. Finally, we draw a link with the continual learning literature, and we propose a modification of our framework to handle continuous streams of tasks with a sub-linear memory cost. We compare with a number of alternative strategies to mitigate catastrophic forgetting, highlighting advantages in terms of average accuracy and memory.

</p>
</details>

<details><summary><b>Digital Voodoo Dolls</b>
<a href="https://arxiv.org/abs/2105.02738">arxiv:2105.02738</a>
&#x1F4C8; 9 <br>
<p>Marija Slavkovik, Clemens Stachl, Caroline Pitman, Jonathan Askonas</p></summary>
<p>

**Abstract:** An institution, be it a body of government, commercial enterprise, or a service, cannot interact directly with a person. Instead, a model is created to represent us. We argue the existence of a new high-fidelity type of person model which we call a digital voodoo doll. We conceptualize it and compare its features with existing models of persons. Digital voodoo dolls are distinguished by existing completely beyond the influence and control of the person they represent. We discuss the ethical issues that such a lack of accountability creates and argue how these concerns can be mitigated.

</p>
</details>

<details><summary><b>Deep Polarization Imaging for 3D shape and SVBRDF Acquisition</b>
<a href="https://arxiv.org/abs/2105.02875">arxiv:2105.02875</a>
&#x1F4C8; 8 <br>
<p>Valentin Deschaintre, Yiming Lin, Abhijeet Ghosh</p></summary>
<p>

**Abstract:** We present a novel method for efficient acquisition of shape and spatially varying reflectance of 3D objects using polarization cues. Unlike previous works that have exploited polarization to estimate material or object appearance under certain constraints (known shape or multiview acquisition), we lift such restrictions by coupling polarization imaging with deep learning to achieve high quality estimate of 3D object shape (surface normals and depth) and SVBRDF using single-view polarization imaging under frontal flash illumination. In addition to acquired polarization images, we provide our deep network with strong novel cues related to shape and reflectance, in the form of a normalized Stokes map and an estimate of diffuse color. We additionally describe modifications to network architecture and training loss which provide further qualitative improvements. We demonstrate our approach to achieve superior results compared to recent works employing deep learning in conjunction with flash illumination.

</p>
</details>

<details><summary><b>Relative stability toward diffeomorphisms indicates performance in deep nets</b>
<a href="https://arxiv.org/abs/2105.02468">arxiv:2105.02468</a>
&#x1F4C8; 7 <br>
<p>Leonardo Petrini, Alessandro Favero, Mario Geiger, Matthieu Wyart</p></summary>
<p>

**Abstract:** Understanding why deep nets can classify data in large dimensions remains a challenge. It has been proposed that they do so by becoming stable to diffeomorphisms, yet existing empirical measurements support that it is often not the case. We revisit this question by defining a maximum-entropy distribution on diffeomorphisms, that allows to study typical diffeomorphisms of a given norm. We confirm that stability toward diffeomorphisms does not strongly correlate to performance on benchmark data sets of images. By contrast, we find that the stability toward diffeomorphisms relative to that of generic transformations $R_f$ correlates remarkably with the test error $ε_t$. It is of order unity at initialization but decreases by several decades during training for state-of-the-art architectures. For CIFAR10 and 15 known architectures, we find $ε_t\approx 0.2\sqrt{R_f}$, suggesting that obtaining a small $R_f$ is important to achieve good performance. We study how $R_f$ depends on the size of the training set and compare it to a simple model of invariant learning.

</p>
</details>

<details><summary><b>PLSM: A Parallelized Liquid State Machine for Unintentional Action Detection</b>
<a href="https://arxiv.org/abs/2105.09909">arxiv:2105.09909</a>
&#x1F4C8; 5 <br>
<p>Dipayan Das, Saumik Bhattacharya, Umapada Pal, Sukalpa Chanda</p></summary>
<p>

**Abstract:** Reservoir Computing (RC) offers a viable option to deploy AI algorithms on low-end embedded system platforms. Liquid State Machine (LSM) is a bio-inspired RC model that mimics the cortical microcircuits and uses spiking neural networks (SNN) that can be directly realized on neuromorphic hardware. In this paper, we present a novel Parallelized LSM (PLSM) architecture that incorporates spatio-temporal read-out layer and semantic constraints on model output. To the best of our knowledge, such a formulation has been done for the first time in literature, and it offers a computationally lighter alternative to traditional deep-learning models. Additionally, we also present a comprehensive algorithm for the implementation of parallelizable SNNs and LSMs that are GPU-compatible. We implement the PLSM model to classify unintentional/accidental video clips, using the Oops dataset. From the experimental results on detecting unintentional action in video, it can be observed that our proposed model outperforms a self-supervised model and a fully supervised traditional deep learning model. All the implemented codes can be found at our repository https://github.com/anonymoussentience2020/Parallelized_LSM_for_Unintentional_Action_Recognition.

</p>
</details>

<details><summary><b>GANTL: Towards Practical and Real-Time Topology Optimization with Conditional GANs and Transfer Learning</b>
<a href="https://arxiv.org/abs/2105.03045">arxiv:2105.03045</a>
&#x1F4C8; 5 <br>
<p>Mohammad Mahdi Behzadi, Horea T. Ilies</p></summary>
<p>

**Abstract:** Many machine learning methods have been recently developed to circumvent the high computational cost of the gradient-based topology optimization. These methods typically require extensive and costly datasets for training, have a difficult time generalizing to unseen boundary and loading conditions and to new domains, and do not take into consideration topological constraints of the predictions, which produces predictions with inconsistent topologies. We present a deep learning method based on generative adversarial networks for generative design exploration. The proposed method combines the generative power of conditional GANs with the knowledge transfer capabilities of transfer learning methods to predict optimal topologies for unseen boundary conditions. We also show that the knowledge transfer capabilities embedded in the design of the proposed algorithm significantly reduces the size of the training dataset compared to the traditional deep learning neural or adversarial networks. Moreover, we formulate a topological loss function based on the bottleneck distance obtained from the persistent diagram of the structures and demonstrate a significant improvement in the topological connectivity of the predicted structures. We use numerous examples to explore the efficiency and accuracy of the proposed approach for both seen and unseen boundary conditions in 2D.

</p>
</details>

<details><summary><b>SparseConvMIL: Sparse Convolutional Context-Aware Multiple Instance Learning for Whole Slide Image Classification</b>
<a href="https://arxiv.org/abs/2105.02726">arxiv:2105.02726</a>
&#x1F4C8; 5 <br>
<p>Marvin Lerousseau, Maria Vakalopoulou, Eric Deutsch, Nikos Paragios</p></summary>
<p>

**Abstract:** Multiple instance learning (MIL) is the preferred approach for whole slide image classification. However, most MIL approaches do not exploit the interdependencies of tiles extracted from a whole slide image, which could provide valuable cues for classification. This paper presents a novel MIL approach that exploits the spatial relationship of tiles for classifying whole slide images. To do so, a sparse map is built from tiles embeddings, and is then classified by a sparse-input CNN. It obtained state-of-the-art performance over popular MIL approaches on the classification of cancer subtype involving 10000 whole slide images. Our results suggest that the proposed approach might (i) improve the representation learning of instances and (ii) exploit the context of instance embeddings to enhance the classification performance. The code of this work is open-source at {github censored for review}.

</p>
</details>

<details><summary><b>GraphFormers: GNN-nested Transformers for Representation Learning on Textual Graph</b>
<a href="https://arxiv.org/abs/2105.02605">arxiv:2105.02605</a>
&#x1F4C8; 5 <br>
<p>Junhan Yang, Zheng Liu, Shitao Xiao, Chaozhuo Li, Defu Lian, Sanjay Agrawal, Amit Singh, Guangzhong Sun, Xing Xie</p></summary>
<p>

**Abstract:** The representation learning on textual graph is to generate low-dimensional embeddings for the nodes based on the individual textual features and the neighbourhood information. Recent breakthroughs on pretrained language models and graph neural networks push forward the development of corresponding techniques. The existing works mainly rely on the cascaded model architecture: the textual features of nodes are independently encoded by language models at first; the textual embeddings are aggregated by graph neural networks afterwards. However, the above architecture is limited due to the independent modeling of textual features. In this work, we propose GraphFormers, where layerwise GNN components are nested alongside the transformer blocks of language models. With the proposed architecture, the text encoding and the graph aggregation are fused into an iterative workflow, making each node's semantic accurately comprehended from the global perspective. In addition, a progressive learning strategy is introduced, where the model is successively trained on manipulated data and original data to reinforce its capability of integrating information on graph. Extensive evaluations are conducted on three large-scale benchmark datasets, where GraphFormers outperform the SOTA baselines with comparable running efficiency.

</p>
</details>

<details><summary><b>SGG: Learning to Select, Guide, and Generate for Keyphrase Generation</b>
<a href="https://arxiv.org/abs/2105.02544">arxiv:2105.02544</a>
&#x1F4C8; 5 <br>
<p>Jing Zhao, Junwei Bao, Yifan Wang, Youzheng Wu, Xiaodong He, Bowen Zhou</p></summary>
<p>

**Abstract:** Keyphrases, that concisely summarize the high-level topics discussed in a document, can be categorized into present keyphrase which explicitly appears in the source text, and absent keyphrase which does not match any contiguous subsequence but is highly semantically related to the source. Most existing keyphrase generation approaches synchronously generate present and absent keyphrases without explicitly distinguishing these two categories. In this paper, a Select-Guide-Generate (SGG) approach is proposed to deal with present and absent keyphrase generation separately with different mechanisms. Specifically, SGG is a hierarchical neural network which consists of a pointing-based selector at low layer concentrated on present keyphrase generation, a selection-guided generator at high layer dedicated to absent keyphrase generation, and a guider in the middle to transfer information from selector to generator. Experimental results on four keyphrase generation benchmarks demonstrate the effectiveness of our model, which significantly outperforms the strong baselines for both present and absent keyphrases generation. Furthermore, we extend SGG to a title generation task which indicates its extensibility in natural language generation tasks.

</p>
</details>

<details><summary><b>Distribution Awareness for AI System Testing</b>
<a href="https://arxiv.org/abs/2105.02540">arxiv:2105.02540</a>
&#x1F4C8; 5 <br>
<p>David Berend</p></summary>
<p>

**Abstract:** As Deep Learning (DL) is continuously adopted in many safety critical applications, its quality and reliability start to raise concerns. Similar to the traditional software development process, testing the DL software to uncover its defects at an early stage is an effective way to reduce risks after deployment. Although recent progress has been made in designing novel testing techniques for DL software, the distribution of generated test data is not taken into consideration. It is therefore hard to judge whether the identified errors are indeed meaningful errors to the DL application. Therefore, we propose a new OOD-guided testing technique which aims to generate new unseen test cases relevant to the underlying DL system task. Our results show that this technique is able to filter up to 55.44% of error test case on CIFAR-10 and is 10.05% more effective in enhancing robustness.

</p>
</details>

<details><summary><b>Point Cloud Audio Processing</b>
<a href="https://arxiv.org/abs/2105.02469">arxiv:2105.02469</a>
&#x1F4C8; 5 <br>
<p>Krishna Subramani, Paris Smaragdis</p></summary>
<p>

**Abstract:** Most audio processing pipelines involve transformations that act on fixed-dimensional input representations of audio. For example, when using the Short Time Fourier Transform (STFT) the DFT size specifies a fixed dimension for the input representation. As a consequence, most audio machine learning models are designed to process fixed-size vector inputs which often prohibits the repurposing of learned models on audio with different sampling rates or alternative representations. We note, however, that the intrinsic spectral information in the audio signal is invariant to the choice of the input representation or the sampling rate. Motivated by this, we introduce a novel way of processing audio signals by treating them as a collection of points in feature space, and we use point cloud machine learning models that give us invariance to the choice of representation parameters, such as DFT size or the sampling rate. Additionally, we observe that these methods result in smaller models, and allow us to significantly subsample the input representation with minimal effects to a trained model performance.

</p>
</details>

<details><summary><b>Reducing Streaming ASR Model Delay with Self Alignment</b>
<a href="https://arxiv.org/abs/2105.05005">arxiv:2105.05005</a>
&#x1F4C8; 4 <br>
<p>Jaeyoung Kim, Han Lu, Anshuman Tripathi, Qian Zhang, Hasim Sak</p></summary>
<p>

**Abstract:** Reducing prediction delay for streaming end-to-end ASR models with minimal performance regression is a challenging problem. Constrained alignment is a well-known existing approach that penalizes predicted word boundaries using external low-latency acoustic models. On the contrary, recently proposed FastEmit is a sequence-level delay regularization scheme encouraging vocabulary tokens over blanks without any reference alignments. Although all these schemes are successful in reducing delay, ASR word error rate (WER) often severely degrades after applying these delay constraining schemes. In this paper, we propose a novel delay constraining method, named self alignment. Self alignment does not require external alignment models. Instead, it utilizes Viterbi forced-alignments from the trained model to find the lower latency alignment direction. From LibriSpeech evaluation, self alignment outperformed existing schemes: 25% and 56% less delay compared to FastEmit and constrained alignment at the similar word error rate. For Voice Search evaluation,12% and 25% delay reductions were achieved compared to FastEmit and constrained alignment with more than 2% WER improvements.

</p>
</details>

<details><summary><b>Informational Design of Dynamic Multi-Agent System</b>
<a href="https://arxiv.org/abs/2105.03052">arxiv:2105.03052</a>
&#x1F4C8; 4 <br>
<p>Tao Zhang, Quanyan Zhu</p></summary>
<p>

**Abstract:** This work considers a novel information design problem and studies how the craft of payoff-relevant environmental signals solely can influence the behaviors of intelligent agents. The agents' strategic interactions are captured by a Markov game, in which each agent first selects one external signal from multiple signal sources as additional payoff-relevant information and then takes an action. There is a rational information designer (principal) who possesses one signal source and aims to influence the equilibrium behaviors of the agents by designing the information structure of her signals sent to the agents. We propose a direct information design approach that incentivizes each agent to select the signal sent by the principal, such that the design process avoids the predictions of the agents' strategic selection behaviors. We then introduce the design protocol given a goal of the designer which we refer to as obedient implementability (OIL) and characterize the OIL in a class of obedient sequential Markov perfect equilibria (O-SMPE). A design regime is proposed based on an approach which we refer to as the fixed-point alignment that incentivizes the agents to choose the signal sent by the principal, guarantees that the agents' policy profile of taking actions is the policy component of an O-SMPE and the principal's goal is achieved. We then formulate the principal's optimal goal selection problem in terms of information design and characterize the optimization problem by minimizing the fixed-point misalignments. The proposed approach can be applied to elicit desired behaviors of multi-agent systems in competing as well as cooperating settings and be extended to heterogeneous stochastic games in the complete- and the incomplete-information environments.

</p>
</details>

<details><summary><b>On the logistical difficulties and findings of Jopara Sentiment Analysis</b>
<a href="https://arxiv.org/abs/2105.02947">arxiv:2105.02947</a>
&#x1F4C8; 4 <br>
<p>Marvin M. Agüero-Torales, David Vilares, Antonio G. López-Herrera</p></summary>
<p>

**Abstract:** This paper addresses the problem of sentiment analysis for Jopara, a code-switching language between Guarani and Spanish. We first collect a corpus of Guarani-dominant tweets and discuss on the difficulties of finding quality data for even relatively easy-to-annotate tasks, such as sentiment analysis. Then, we train a set of neural models, including pre-trained language models, and explore whether they perform better than traditional machine learning ones in this low-resource setup. Transformer architectures obtain the best results, despite not considering Guarani during pre-training, but traditional machine learning models perform close due to the low-resource nature of the problem.

</p>
</details>

<details><summary><b>Membership Inference Attacks on Deep Regression Models for Neuroimaging</b>
<a href="https://arxiv.org/abs/2105.02866">arxiv:2105.02866</a>
&#x1F4C8; 4 <br>
<p>Umang Gupta, Dimitris Stripelis, Pradeep K. Lam, Paul M. Thompson, José Luis Ambite, Greg Ver Steeg</p></summary>
<p>

**Abstract:** Ensuring the privacy of research participants is vital, even more so in healthcare environments. Deep learning approaches to neuroimaging require large datasets, and this often necessitates sharing data between multiple sites, which is antithetical to the privacy objectives. Federated learning is a commonly proposed solution to this problem. It circumvents the need for data sharing by sharing parameters during the training process. However, we demonstrate that allowing access to parameters may leak private information even if data is never directly shared. In particular, we show that it is possible to infer if a sample was used to train the model given only access to the model prediction (black-box) or access to the model itself (white-box) and some leaked samples from the training data distribution. Such attacks are commonly referred to as Membership Inference attacks. We show realistic Membership Inference attacks on deep learning models trained for 3D neuroimaging tasks in a centralized as well as decentralized setup. We demonstrate feasible attacks on brain age prediction models (deep learning models that predict a person's age from their brain MRI scan). We correctly identified whether an MRI scan was used in model training with a 60% to over 80% success rate depending on model complexity and security assumptions.

</p>
</details>

<details><summary><b>CrossWalk: Fairness-enhanced Node Representation Learning</b>
<a href="https://arxiv.org/abs/2105.02725">arxiv:2105.02725</a>
&#x1F4C8; 4 <br>
<p>Ahmad Khajehnejad, Moein Khajehnejad, Mahmoudreza Babaei, Krishna P. Gummadi, Adrian Weller, Baharan Mirzasoleiman</p></summary>
<p>

**Abstract:** The potential for machine learning systems to amplify social inequities and unfairness is receiving increasing popular and academic attention. Much recent work has focused on developing algorithmic tools to assess and mitigate such unfairness. However, there is little work on enhancing fairness in graph algorithms. Here, we develop a simple, effective and general method, CrossWalk, that enhances fairness of various graph algorithms, including influence maximization, link prediction and node classification, applied to node embeddings. CrossWalk is applicable to any random walk based node representation learning algorithm, such as DeepWalk and Node2Vec. The key idea is to bias random walks to cross group boundaries, by upweighting edges which (1) are closer to the groups' peripheries or (2) connect different groups in the network. CrossWalk pulls nodes that are near groups' peripheries towards their neighbors from other groups in the embedding space, while preserving the necessary structural information from the graph. Extensive experiments show the effectiveness of our algorithm to enhance fairness in various graph algorithms, including influence maximization, link prediction and node classification in synthetic and real networks, with only a very small decrease in performance.

</p>
</details>

<details><summary><b>Generalized Multimodal ELBO</b>
<a href="https://arxiv.org/abs/2105.02470">arxiv:2105.02470</a>
&#x1F4C8; 4 <br>
<p>Thomas M. Sutter, Imant Daunhawer, Julia E. Vogt</p></summary>
<p>

**Abstract:** Multiple data types naturally co-occur when describing real-world phenomena and learning from them is a long-standing goal in machine learning research. However, existing self-supervised generative models approximating an ELBO are not able to fulfill all desired requirements of multimodal models: their posterior approximation functions lead to a trade-off between the semantic coherence and the ability to learn the joint data distribution. We propose a new, generalized ELBO formulation for multimodal data that overcomes these limitations. The new objective encompasses two previous methods as special cases and combines their benefits without compromises. In extensive experiments, we demonstrate the advantage of the proposed method compared to state-of-the-art models in self-supervised, generative learning tasks.

</p>
</details>

<details><summary><b>fAshIon after fashion: A Report of AI in Fashion</b>
<a href="https://arxiv.org/abs/2105.03050">arxiv:2105.03050</a>
&#x1F4C8; 3 <br>
<p>Xingxing Zou, Waikeung Wong</p></summary>
<p>

**Abstract:** In this independent report fAshIon after fashion, we examine the development of fAshIon (artificial intelligence (AI) in fashion) and explore its potentiality to become a major disruptor of the fashion industry in the near future. To do this, we investigate AI technologies used in the fashion industry through several lenses. We summarise fAshIon studies conducted over the past decade and categorise them into seven groups: Overview, Evaluation, Basic Tech, Selling, Styling, Design, and Buying. The datasets mentioned in fAshIon research have been consolidated on one GitHub page for ease of use. We analyse the authors' backgrounds and the geographic regions treated in these studies to determine the landscape of fAshIon research. The results of our analysis are presented with an aim to provide researchers with a holistic view of research in fAshIon. As part of our primary research, we also review a wide range of cases of applied fAshIon in the fashion industry and analyse their impact on the industry, markets and individuals. We also identify the challenges presented by fAshIon and suggest that these may form the basis for future research. We finally exhibit that many potential opportunities exist for the use of AI in fashion which can transform the fashion industry embedded with AI technologies and boost profits.

</p>
</details>

<details><summary><b>A Multivariate Density Forecast Approach for Online Power System Security Assessment</b>
<a href="https://arxiv.org/abs/2105.03047">arxiv:2105.03047</a>
&#x1F4C8; 3 <br>
<p>Zichao Meng, Ye Guo, Wenjun Tang, Hongbin Sun, Wenqi Huang</p></summary>
<p>

**Abstract:** A multivariate density forecast model based on deep learning is designed in this paper to forecast the joint cumulative distribution functions (JCDFs) of multiple security margins in power systems. Differing from existing multivariate density forecast models, the proposed method requires no a priori hypotheses on the distribution of forecasting targets. In addition, based on the universal approximation capability of neural networks, the value domain of the proposed approach has been proven to include all continuous JCDFs. The forecasted JCDF is further employed to calculate the deterministic security assessment index evaluating the security level of future power system operations. Numerical tests verify the superiority of the proposed method over current multivariate density forecast models. The deterministic security assessment index is demonstrated to be more informative for operators than security margins as well.

</p>
</details>

<details><summary><b>Utilizing Skipped Frames in Action Repeats via Pseudo-Actions</b>
<a href="https://arxiv.org/abs/2105.03041">arxiv:2105.03041</a>
&#x1F4C8; 3 <br>
<p>Taisei Hashimoto, Yoshimasa Tsuruoka</p></summary>
<p>

**Abstract:** In many deep reinforcement learning settings, when an agent takes an action, it repeats the same action a predefined number of times without observing the states until the next action-decision point. This technique of action repetition has several merits in training the agent, but the data between action-decision points (i.e., intermediate frames) are, in effect, discarded. Since the amount of training data is inversely proportional to the interval of action repeats, they can have a negative impact on the sample efficiency of training. In this paper, we propose a simple but effective approach to alleviate to this problem by introducing the concept of pseudo-actions. The key idea of our method is making the transition between action-decision points usable as training data by considering pseudo-actions. Pseudo-actions for continuous control tasks are obtained as the average of the action sequence straddling an action-decision point. For discrete control tasks, pseudo-actions are computed from learned action embeddings. This method can be combined with any model-free reinforcement learning algorithm that involves the learning of Q-functions. We demonstrate the effectiveness of our approach on both continuous and discrete control tasks in OpenAI Gym.

</p>
</details>

<details><summary><b>Exact Acceleration of K-Means++ and K-Means$\|$</b>
<a href="https://arxiv.org/abs/2105.02936">arxiv:2105.02936</a>
&#x1F4C8; 3 <br>
<p>Edward Raff</p></summary>
<p>

**Abstract:** K-Means++ and its distributed variant K-Means$\|$ have become de facto tools for selecting the initial seeds of K-means. While alternatives have been developed, the effectiveness, ease of implementation, and theoretical grounding of the K-means++ and $\|$ methods have made them difficult to "best" from a holistic perspective. By considering the limited opportunities within seed selection to perform pruning, we develop specialized triangle inequality pruning strategies and a dynamic priority queue to show the first acceleration of K-Means++ and K-Means$\|$ that is faster in run-time while being algorithmicly equivalent. For both algorithms we are able to reduce distance computations by over $500\times$. For K-means++ this results in up to a 17$\times$ speedup in run-time and a $551\times$ speedup for K-means$\|$. We achieve this with simple, but carefully chosen, modifications to known techniques which makes it easy to integrate our approach into existing implementations of these algorithms.

</p>
</details>

<details><summary><b>Contextual Bandits with Sparse Data in Web setting</b>
<a href="https://arxiv.org/abs/2105.02873">arxiv:2105.02873</a>
&#x1F4C8; 3 <br>
<p>Björn H Eriksson</p></summary>
<p>

**Abstract:** This paper is a scoping study to identify current methods used in handling sparse data with contextual bandits in web settings. The area is highly current and state of the art methods are identified. The years 2017-2020 are investigated, and 19 method articles are identified, and two review articles. Five categories of methods are described, making it easy to choose how to address sparse data using contextual bandits with a method available for modification in the specific setting of concern. In addition, each method has multiple techniques to choose from for future evaluation. The problem areas are also mentioned that each article covers. An overall updated understanding of sparse data problems using contextual bandits in web settings is given. The identified methods are policy evaluation (off-line and on-line) , hybrid-method, model representation (clusters and deep neural networks), dimensionality reduction, and simulation.

</p>
</details>

<details><summary><b>Online Preconditioning of Experimental Inkjet Hardware by Bayesian Optimization in Loop</b>
<a href="https://arxiv.org/abs/2105.02858">arxiv:2105.02858</a>
&#x1F4C8; 3 <br>
<p>Alexander E. Siemenn, Matthew Beveridge, Tonio Buonassisi, Iddo Drori</p></summary>
<p>

**Abstract:** High-performance semiconductor optoelectronics such as perovskites have high-dimensional and vast composition spaces that govern the performance properties of the material. To cost-effectively search these composition spaces, we utilize a high-throughput experimentation method of rapidly printing discrete droplets via inkjet deposition, in which each droplet is comprised of a unique permutation of semiconductor materials. However, inkjet printer systems are not optimized to run high-throughput experimentation on semiconductor materials. Thus, in this work, we develop a computer vision-driven Bayesian optimization framework for optimizing the deposited droplet structures from an inkjet printer such that it is tuned to perform high-throughput experimentation on semiconductor materials. The goal of this framework is to tune to the hardware conditions of the inkjet printer in the shortest amount of time using the fewest number of droplet samples such that we minimize the time and resources spent on setting the system up for material discovery applications. We demonstrate convergence on optimum inkjet hardware conditions in 10 minutes using Bayesian optimization of computer vision-scored droplet structures. We compare our Bayesian optimization results with stochastic gradient descent.

</p>
</details>

<details><summary><b>Semidefinite Programming for Community Detection with Side Information</b>
<a href="https://arxiv.org/abs/2105.02816">arxiv:2105.02816</a>
&#x1F4C8; 3 <br>
<p>Mohammad Esmaeili, Hussein Metwaly Saad, Aria Nosratinia</p></summary>
<p>

**Abstract:** This paper produces an efficient Semidefinite Programming (SDP) solution for community detection that incorporates non-graph data, which in this context is known as side information. SDP is an efficient solution for standard community detection on graphs. We formulate a semi-definite relaxation for the maximum likelihood estimation of node labels, subject to observing both graph and non-graph data. This formulation is distinct from the SDP solution of standard community detection, but maintains its desirable properties. We calculate the exact recovery threshold for three types of non-graph information, which in this paper are called side information: partially revealed labels, noisy labels, as well as multiple observations (features) per node with arbitrary but finite cardinality. We find that SDP has the same exact recovery threshold in the presence of side information as maximum likelihood with side information. Thus, the methods developed herein are computationally efficient as well as asymptotically accurate for the solution of community detection in the presence of side information. Simulations show that the asymptotic results of this paper can also shed light on the performance of SDP for graphs of modest size.

</p>
</details>

<details><summary><b>MIMII DUE: Sound Dataset for Malfunctioning Industrial Machine Investigation and Inspection with Domain Shifts due to Changes in Operational and Environmental Conditions</b>
<a href="https://arxiv.org/abs/2105.02702">arxiv:2105.02702</a>
&#x1F4C8; 3 <br>
<p>Ryo Tanabe, Harsh Purohit, Kota Dohi, Takashi Endo, Yuki Nikaido, Toshiki Nakamura, Yohei Kawaguchi</p></summary>
<p>

**Abstract:** In this paper, we introduce MIMII DUE, a new dataset for malfunctioning industrial machine investigation and inspection with domain shifts due to changes in operational and environmental conditions. Conventional methods for anomalous sound detection face practical challenges because the distribution of features changes between the training and operational phases (called domain shift) due to various real-world factors. To check the robustness against domain shifts, we need a dataset that actually includes domain shifts, but such a dataset does not exist so far. The new dataset we created consists of the normal and abnormal operating sounds of five different types of industrial machines under two different operational/environmental conditions (source domain and target domain) independent of normal/abnormal, with domain shifts occurring between the two domains. Experimental results showed significant performance differences between the source and target domains, indicating that the dataset contains the domain shifts. These findings demonstrate that the dataset will be helpful for checking the robustness against domain shifts. The dataset is a subset of the dataset for DCASE 2021 Challenge Task 2 and freely available for download at https://zenodo.org/record/4740355

</p>
</details>

<details><summary><b>Dataset Bias in the Natural Sciences: A Case Study in Chemical Reaction Prediction and Synthesis Design</b>
<a href="https://arxiv.org/abs/2105.02637">arxiv:2105.02637</a>
&#x1F4C8; 3 <br>
<p>Ryan-Rhys Griffiths, Philippe Schwaller, Alpha A. Lee</p></summary>
<p>

**Abstract:** Datasets in the Natural Sciences are often curated with the goal of aiding scientific understanding and hence may not always be in a form that facilitates the application of machine learning. In this paper, we identify three trends within the fields of chemical reaction prediction and synthesis design that require a change in direction. First, the manner in which reaction datasets are split into reactants and reagents encourages testing models in an unrealistically generous manner. Second, we highlight the prevalence of mislabelled data, and suggest that the focus should be on outlier removal rather than data fitting only. Lastly, we discuss the problem of reagent prediction, in addition to reactant prediction, in order to solve the full synthesis design problem, highlighting the mismatch between what machine learning solves and what a lab chemist would need. Our critiques are also relevant to the burgeoning field of using machine learning to accelerate progress in experimental Natural Sciences, where datasets are often split in a biased way, are highly noisy, and contextual variables that are not evident from the data strongly influence the outcome of experiments.

</p>
</details>

<details><summary><b>Speech Enhancement using Separable Polling Attention and Global Layer Normalization followed with PReLU</b>
<a href="https://arxiv.org/abs/2105.02509">arxiv:2105.02509</a>
&#x1F4C8; 3 <br>
<p>Dengfeng Ke, Jinsong Zhang, Yanlu Xie, Yanyan Xu, Binghuai Lin</p></summary>
<p>

**Abstract:** Single channel speech enhancement is a challenging task in speech community. Recently, various neural networks based methods have been applied to speech enhancement. Among these models, PHASEN and T-GSA achieve state-of-the-art performances on the publicly opened VoiceBank+DEMAND corpus. Both of the models reach the COVL score of 3.62. PHASEN achieves the highest CSIG score of 4.21 while T-GSA gets the highest PESQ score of 3.06. However, both of these two models are very large. The contradiction between the model performance and the model size is hard to reconcile. In this paper, we introduce three kinds of techniques to shrink the PHASEN model and improve the performance. Firstly, seperable polling attention is proposed to replace the frequency transformation blocks in PHASEN. Secondly, global layer normalization followed with PReLU is used to replace batch normalization followed with ReLU. Finally, BLSTM in PHASEN is replaced with Conv2d operation and the phase stream is simplified. With all these modifications, the size of the PHASEN model is shrunk from 33M parameters to 5M parameters, while the performance on VoiceBank+DEMAND is improved to the CSIG score of 4.30, the PESQ score of 3.07 and the COVL score of 3.73.

</p>
</details>

<details><summary><b>Federated Face Recognition</b>
<a href="https://arxiv.org/abs/2105.02501">arxiv:2105.02501</a>
&#x1F4C8; 3 <br>
<p>Fan Bai, Jiaxiang Wu, Pengcheng Shen, Shaoxin Li, Shuigeng Zhou</p></summary>
<p>

**Abstract:** Face recognition has been extensively studied in computer vision and artificial intelligence communities in recent years. An important issue of face recognition is data privacy, which receives more and more public concerns. As a common privacy-preserving technique, Federated Learning is proposed to train a model cooperatively without sharing data between parties. However, as far as we know, it has not been successfully applied in face recognition. This paper proposes a framework named FedFace to innovate federated learning for face recognition. Specifically, FedFace relies on two major innovative algorithms, Partially Federated Momentum (PFM) and Federated Validation (FV). PFM locally applies an estimated equivalent global momentum to approximating the centralized momentum-SGD efficiently. FV repeatedly searches for better federated aggregating weightings via testing the aggregated models on some private validation datasets, which can improve the model's generalization ability. The ablation study and extensive experiments validate the effectiveness of the FedFace method and show that it is comparable to or even better than the centralized baseline in performance.

</p>
</details>

<details><summary><b>Why Approximate Matrix Square Root Outperforms Accurate SVD in Global Covariance Pooling?</b>
<a href="https://arxiv.org/abs/2105.02498">arxiv:2105.02498</a>
&#x1F4C8; 3 <br>
<p>Yue Song, Nicu Sebe, Wei Wang</p></summary>
<p>

**Abstract:** Global covariance pooling (GCP) aims at exploiting the second-order statistics of the convolutional feature. Its effectiveness has been demonstrated in boosting the classification performance of Convolutional Neural Networks (CNNs). Singular Value Decomposition (SVD) is used in GCP to compute the matrix square root. However, the approximate matrix square root calculated using Newton-Schulz iteration \cite{li2018towards} outperforms the accurate one computed via SVD \cite{li2017second}. We empirically analyze the reason behind the performance gap from the perspectives of data precision and gradient smoothness. Various remedies for computing smooth SVD gradients are investigated. Based on our observation and analyses, a hybrid training protocol is proposed for SVD-based GCP meta-layers such that competitive performances can be achieved against Newton-Schulz iteration. Moreover, we propose a new GCP meta-layer that uses SVD in the forward pass, and Padé Approximants in the backward propagation to compute the gradients. The proposed meta-layer has been integrated into different CNN models and achieves state-of-the-art performances on both large-scale and fine-grained datasets.

</p>
</details>

<details><summary><b>A Survey of Knowledge Tracing</b>
<a href="https://arxiv.org/abs/2105.15106">arxiv:2105.15106</a>
&#x1F4C8; 2 <br>
<p>Qi Liu, Shuanghong Shen, Zhenya Huang, Enhong Chen, Yonghe Zheng</p></summary>
<p>

**Abstract:** High-quality education is one of the keys to achieving a more sustainable world. The recent COVID-19 epidemic has triggered the outbreak of online education, which has enabled both students and teachers to learn and teach at home. Meanwhile, it is now possible to record and research a large amount of learning data using online learning platforms in order to offer better intelligent educational services. Knowledge Tracing (KT), which aims to monitor students' evolving knowledge state, is a fundamental and crucial task to support these intelligent services. Therefore, an increasing amount of research attention has been paid to this emerging area and considerable progress has been made. In this survey, we propose a new taxonomy of existing basic KT models from a technical perspective and provide a comprehensive overview of these models in a systematic manner. In addition, many variants of KT models have been proposed to capture more complete learning process. We then review these variants involved in three phases of the learning process: before, during, and after the student learning, respectively. Moreover, we present several typical applications of KT in different educational scenarios. Finally, we provide some potential directions for future research in this fast-growing field.

</p>
</details>

<details><summary><b>Deep Graph Convolutional Reinforcement Learning for Financial Portfolio Management -- DeepPocket</b>
<a href="https://arxiv.org/abs/2105.08664">arxiv:2105.08664</a>
&#x1F4C8; 2 <br>
<p>Farzan Soleymani, Eric Paquet</p></summary>
<p>

**Abstract:** Portfolio management aims at maximizing the return on investment while minimizing risk by continuously reallocating the assets forming the portfolio. These assets are not independent but correlated during a short time period. A graph convolutional reinforcement learning framework called DeepPocket is proposed whose objective is to exploit the time-varying interrelations between financial instruments. These interrelations are represented by a graph whose nodes correspond to the financial instruments while the edges correspond to a pair-wise correlation function in between assets. DeepPocket consists of a restricted, stacked autoencoder for feature extraction, a convolutional network to collect underlying local information shared among financial instruments, and an actor-critic reinforcement learning agent. The actor-critic structure contains two convolutional networks in which the actor learns and enforces an investment policy which is, in turn, evaluated by the critic in order to determine the best course of action by constantly reallocating the various portfolio assets to optimize the expected return on investment. The agent is initially trained offline with online stochastic batching on historical data. As new data become available, it is trained online with a passive concept drift approach to handle unexpected changes in their distributions. DeepPocket is evaluated against five real-life datasets over three distinct investment periods, including during the Covid-19 crisis, and clearly outperformed market indexes.

</p>
</details>

<details><summary><b>Deep reinforcement learning-designed radiofrequency waveform in MRI</b>
<a href="https://arxiv.org/abs/2105.03061">arxiv:2105.03061</a>
&#x1F4C8; 2 <br>
<p>Dongmyung Shin, Younghoon Kim, Chungseok Oh, Hongjun An, Juhyung Park, Jiye Kim, Jongho Lee</p></summary>
<p>

**Abstract:** Carefully engineered radiofrequency (RF) pulses play a key role in a number of systems such as mobile phone, radar, and magnetic resonance imaging. The design of an RF waveform, however, is often posed as an inverse problem with no general solution. As a result, various design methods each with a specific purpose have been developed based on the intuition of human experts. In this work, we propose an artificial intelligence (AI)-powered RF pulse design framework, DeepRF, which utilizes the self-learning characteristics of deep reinforcement learning to generate a novel RF pulse. The effectiveness of DeepRF is demonstrated using four types of RF pulses that are commonly used. The DeepRF-designed pulses successfully satisfy the design criteria while reporting reduced energy. Analyses demonstrate the pulses utilize new mechanisms of magnetization manipulation, suggesting the potentials of DeepRF in discovering unseen design dimensions beyond human intuition. This work may lay the foundation for an emerging field of AI-driven RF waveform design.

</p>
</details>

<details><summary><b>Error-Robust Multi-View Clustering: Progress, Challenges and Opportunities</b>
<a href="https://arxiv.org/abs/2105.03058">arxiv:2105.03058</a>
&#x1F4C8; 2 <br>
<p>Mehrnaz Najafi, Lifang He, Philip S. Yu</p></summary>
<p>

**Abstract:** With recent advances in data collection from multiple sources, multi-view data has received significant attention. In multi-view data, each view represents a different perspective of data. Since label information is often expensive to acquire, multi-view clustering has gained growing interest, which aims to obtain better clustering solution by exploiting complementary and consistent information across all views rather than only using an individual view. Due to inevitable sensor failures, data in each view may contain error. Error often exhibits as noise or feature-specific corruptions or outliers. Multi-view data may contain any or combination of these error types. Blindly clustering multi-view data i.e., without considering possible error in view(s) could significantly degrade the performance. The goal of error-robust multi-view clustering is to obtain useful outcome even if the multi-view data is corrupted. Existing error-robust multi-view clustering approaches with explicit error removal formulation can be structured into five broad research categories - sparsity norm based approaches, graph based methods, subspace based learning approaches, deep learning based methods and hybrid approaches, this survey summarizes and reviews recent advances in error-robust clustering for multi-view data. Finally, we highlight the challenges and provide future research opportunities.

</p>
</details>

<details><summary><b>Understanding Catastrophic Overfitting in Adversarial Training</b>
<a href="https://arxiv.org/abs/2105.02942">arxiv:2105.02942</a>
&#x1F4C8; 2 <br>
<p>Peilin Kang, Seyed-Mohsen Moosavi-Dezfooli</p></summary>
<p>

**Abstract:** Recently, FGSM adversarial training is found to be able to train a robust model which is comparable to the one trained by PGD but an order of magnitude faster. However, there is a failure mode called catastrophic overfitting (CO) that the classifier loses its robustness suddenly during the training and hardly recovers by itself. In this paper, we find CO is not only limited to FGSM, but also happens in $\mbox{DF}^{\infty}$-1 adversarial training. Then, we analyze the geometric properties for both FGSM and $\mbox{DF}^{\infty}$-1 and find they have totally different decision boundaries after CO. For FGSM, a new decision boundary is generated along the direction of perturbation and makes the small perturbation more effective than the large one. While for $\mbox{DF}^{\infty}$-1, there is no new decision boundary generated along the direction of perturbation, instead the perturbation generated by $\mbox{DF}^{\infty}$-1 becomes smaller after CO and thus loses its effectiveness. We also experimentally analyze three hypotheses on potential factors causing CO. And then based on the empirical analysis, we modify the RS-FGSM by not projecting perturbation back to the $l_\infty$ ball. By this small modification, we could achieve $47.56 \pm 0.37\% $ PGD-50-10 accuracy on CIFAR10 with $ε=8/255$ in contrast to $43.57 \pm 0.30\% $ by RS-FGSM and also further extend the working range of $ε$ from 8/255 to 11/255 on CIFAR10 without CO occurring.

</p>
</details>

<details><summary><b>Estimating Reproducible Functional Networks Associated with Task Dynamics using Unsupervised LSTMs</b>
<a href="https://arxiv.org/abs/2105.02869">arxiv:2105.02869</a>
&#x1F4C8; 2 <br>
<p>Nicha C. Dvornek, Pamela Ventola, James S. Duncan</p></summary>
<p>

**Abstract:** We propose a method for estimating more reproducible functional networks that are more strongly associated with dynamic task activity by using recurrent neural networks with long short term memory (LSTMs). The LSTM model is trained in an unsupervised manner to learn to generate the functional magnetic resonance imaging (fMRI) time-series data in regions of interest. The learned functional networks can then be used for further analysis, e.g., correlation analysis to determine functional networks that are strongly associated with an fMRI task paradigm. We test our approach and compare to other methods for decomposing functional networks from fMRI activity on 2 related but separate datasets that employ a biological motion perception task. We demonstrate that the functional networks learned by the LSTM model are more strongly associated with the task activity and dynamics compared to other approaches. Furthermore, the patterns of network association are more closely replicated across subjects within the same dataset as well as across datasets. More reproducible functional networks are essential for better characterizing the neural correlates of a target task.

</p>
</details>

<details><summary><b>The layer-wise L1 Loss Landscape of Neural Nets is more complex around local minima</b>
<a href="https://arxiv.org/abs/2105.02831">arxiv:2105.02831</a>
&#x1F4C8; 2 <br>
<p>Peter Hinz</p></summary>
<p>

**Abstract:** For fixed training data and network parameters in the other layers the L1 loss of a ReLU neural network as a function of the first layer's parameters is a piece-wise affine function. We use the Deep ReLU Simplex algorithm to iteratively minimize the loss monotonically on adjacent vertices and analyze the trajectory of these vertex positions. We empirically observe that in a neighbourhood around a local minimum, the iterations behave differently such that conclusions on loss level and proximity of the local minimum can be made before it has been found: Firstly the loss seems to decay exponentially slow at iterated adjacent vertices such that the loss level at the local minimum can be estimated from the loss levels of subsequently iterated vertices, and secondly we observe a strong increase of the vertex density around local minima. This could have far-reaching consequences for the design of new gradient-descent algorithms that might improve convergence rate by exploiting these facts.

</p>
</details>

<details><summary><b>Pathloss modeling for in-body optical wireless communications</b>
<a href="https://arxiv.org/abs/2105.02829">arxiv:2105.02829</a>
&#x1F4C8; 2 <br>
<p>Stylianos E. Trevlakis, Alexandros-Apostolos A. Boulogeorgos, Nestor D. Chatzidiamantis</p></summary>
<p>

**Abstract:** Optical wireless communications (OWCs) have been recognized as a candidate enabler of next generation in-body nano-scale networks and implants. The development of an accurate channel model capable of accommodating the particularities of different type of tissues is expected to boost the design of optimized communication protocols for such applications. Motivated by this, this paper focuses on presenting a general pathloss model for in-body OWCs. In particular, we use experimental measurements in order to extract analytical expressions for the absorption coefficients of the five main tissues' constitutions, namely oxygenated and de-oxygenated blood, water, fat, and melanin. Building upon these expressions, we derive a general formula for the absorption coefficient evaluation of any biological tissue. To verify the validity of this formula, we compute the absorption coefficient of complex tissues and compare them against respective experimental results reported by independent research works. Interestingly, we observe that the analytical formula has high accuracy and is capable of modeling the pathloss and, therefore, the penetration depth in complex tissues.

</p>
</details>

<details><summary><b>Two4Two: Evaluating Interpretable Machine Learning - A Synthetic Dataset For Controlled Experiments</b>
<a href="https://arxiv.org/abs/2105.02825">arxiv:2105.02825</a>
&#x1F4C8; 2 <br>
<p>Martin Schuessler, Philipp Weiß, Leon Sixt</p></summary>
<p>

**Abstract:** A growing number of approaches exist to generate explanations for image classification. However, few of these approaches are subjected to human-subject evaluations, partly because it is challenging to design controlled experiments with natural image datasets, as they leave essential factors out of the researcher's control. With our approach, researchers can describe their desired dataset with only a few parameters. Based on these, our library generates synthetic image data of two 3D abstract animals. The resulting data is suitable for algorithmic as well as human-subject evaluations. Our user study results demonstrate that our method can create biases predictive enough for a classifier and subtle enough to be noticeable only to every second participant inspecting the data visually. Our approach significantly lowers the barrier for conducting human subject evaluations, thereby facilitating more rigorous investigations into interpretable machine learning. For our library and datasets see, https://github.com/mschuessler/two4two/

</p>
</details>

<details><summary><b>Practical and Rigorous Uncertainty Bounds for Gaussian Process Regression</b>
<a href="https://arxiv.org/abs/2105.02796">arxiv:2105.02796</a>
&#x1F4C8; 2 <br>
<p>Christian Fiedler, Carsten W. Scherer, Sebastian Trimpe</p></summary>
<p>

**Abstract:** Gaussian Process Regression is a popular nonparametric regression method based on Bayesian principles that provides uncertainty estimates for its predictions. However, these estimates are of a Bayesian nature, whereas for some important applications, like learning-based control with safety guarantees, frequentist uncertainty bounds are required. Although such rigorous bounds are available for Gaussian Processes, they are too conservative to be useful in applications. This often leads practitioners to replacing these bounds by heuristics, thus breaking all theoretical guarantees. To address this problem, we introduce new uncertainty bounds that are rigorous, yet practically useful at the same time. In particular, the bounds can be explicitly evaluated and are much less conservative than state of the art results. Furthermore, we show that certain model misspecifications lead to only graceful degradation. We demonstrate these advantages and the usefulness of our results for learning-based control with numerical examples.

</p>
</details>

<details><summary><b>ACORN: Adaptive Coordinate Networks for Neural Scene Representation</b>
<a href="https://arxiv.org/abs/2105.02788">arxiv:2105.02788</a>
&#x1F4C8; 2 <br>
<p>Julien N. P. Martel, David B. Lindell, Connor Z. Lin, Eric R. Chan, Marco Monteiro, Gordon Wetzstein</p></summary>
<p>

**Abstract:** Neural representations have emerged as a new paradigm for applications in rendering, imaging, geometric modeling, and simulation. Compared to traditional representations such as meshes, point clouds, or volumes they can be flexibly incorporated into differentiable learning-based pipelines. While recent improvements to neural representations now make it possible to represent signals with fine details at moderate resolutions (e.g., for images and 3D shapes), adequately representing large-scale or complex scenes has proven a challenge. Current neural representations fail to accurately represent images at resolutions greater than a megapixel or 3D scenes with more than a few hundred thousand polygons. Here, we introduce a new hybrid implicit-explicit network architecture and training strategy that adaptively allocates resources during training and inference based on the local complexity of a signal of interest. Our approach uses a multiscale block-coordinate decomposition, similar to a quadtree or octree, that is optimized during training. The network architecture operates in two stages: using the bulk of the network parameters, a coordinate encoder generates a feature grid in a single forward pass. Then, hundreds or thousands of samples within each block can be efficiently evaluated using a lightweight feature decoder. With this hybrid implicit-explicit network architecture, we demonstrate the first experiments that fit gigapixel images to nearly 40 dB peak signal-to-noise ratio. Notably this represents an increase in scale of over 1000x compared to the resolution of previously demonstrated image-fitting experiments. Moreover, our approach is able to represent 3D shapes significantly faster and better than previous techniques; it reduces training times from days to hours or minutes and memory requirements by over an order of magnitude.

</p>
</details>

<details><summary><b>A probabilistic model for missing traffic volume reconstruction based on data fusion</b>
<a href="https://arxiv.org/abs/2105.02777">arxiv:2105.02777</a>
&#x1F4C8; 2 <br>
<p>Xintao Yan, Yan Zhao, Henry X. Liu</p></summary>
<p>

**Abstract:** Traffic volume information is critical for intelligent transportation systems. It serves as a key input to transportation planning, roadway design, and traffic signal control. However, the traffic volume data collected by fixed-location sensors, such as loop detectors, often suffer from the missing data problem and low coverage problem. The missing data problem could be caused by hardware malfunction. The low coverage problem is due to the limited coverage of fixed-location sensors in the transportation network, which restrains our understanding of the traffic at the network level. To tackle these problems, we propose a probabilistic model for traffic volume reconstruction by fusing fixed-location sensor data and probe vehicle data. We apply the probabilistic principal component analysis (PPCA) to capture the correlations in traffic volume data. An innovative contribution of this work is that we also integrate probe vehicle data into the framework, which allows the model to solve both of the above-mentioned two problems. Using a real-world traffic volume dataset, we show that the proposed method outperforms state-of-the-art methods for the extensively studied missing data problem. Moreover, for the low coverage problem, which cannot be handled by most existing methods, the proposed model can also achieve high accuracy. The experiments also show that even when the missing ratio reaches 80%, the proposed method can still give an accurate estimate of the unknown traffic volumes with only a 10% probe vehicle penetration rate. The results validate the effectiveness and robustness of the proposed model and demonstrate its potential for practical applications.

</p>
</details>

<details><summary><b>Modeling the geospatial evolution of COVID-19 using spatio-temporal convolutional sequence-to-sequence neural networks</b>
<a href="https://arxiv.org/abs/2105.02752">arxiv:2105.02752</a>
&#x1F4C8; 2 <br>
<p>Mário Cardoso, André Cavalheiro, Alexandre Borges, Ana F. Duarte, Amílcar Soares, Maria João Pereira, Nuno J. Nunes, Leonardo Azevedo, Arlindo L. Oliveira</p></summary>
<p>

**Abstract:** Europe was hit hard by the COVID-19 pandemic and Portugal was one of the most affected countries, having suffered three waves in the first twelve months. Approximately between Jan 19th and Feb 5th 2021 Portugal was the country in the world with the largest incidence rate, with 14-days incidence rates per 100,000 inhabitants in excess of 1000. Despite its importance, accurate prediction of the geospatial evolution of COVID-19 remains a challenge, since existing analytical methods fail to capture the complex dynamics that result from both the contagion within a region and the spreading of the infection from infected neighboring regions.
  We use a previously developed methodology and official municipality level data from the Portuguese Directorate-General for Health (DGS), relative to the first twelve months of the pandemic, to compute an estimate of the incidence rate in each location of mainland Portugal. The resulting sequence of incidence rate maps was then used as a gold standard to test the effectiveness of different approaches in the prediction of the spatial-temporal evolution of the incidence rate. Four different methods were tested: a simple cell level autoregressive moving average (ARMA) model, a cell level vector autoregressive (VAR) model, a municipality-by-municipality compartmental SIRD model followed by direct block sequential simulation and a convolutional sequence-to-sequence neural network model based on the STConvS2S architecture. We conclude that the convolutional sequence-to-sequence neural network is the best performing method, when predicting the medium-term future incidence rate, using the available information.

</p>
</details>

<details><summary><b>Noether's Learning Dynamics: Role of Symmetry Breaking in Neural Networks</b>
<a href="https://arxiv.org/abs/2105.02716">arxiv:2105.02716</a>
&#x1F4C8; 2 <br>
<p>Hidenori Tanaka, Daniel Kunin</p></summary>
<p>

**Abstract:** In nature, symmetry governs regularities, while symmetry breaking brings texture. In artificial neural networks, symmetry has been a central design principle to efficiently capture regularities in the world, but the role of symmetry breaking is not well understood. Here, we develop a theoretical framework to study the "geometry of learning dynamics" in neural networks, and reveal a key mechanism of explicit symmetry breaking behind the efficiency and stability of modern neural networks. To build this understanding, we model the discrete learning dynamics of gradient descent using a continuous-time Lagrangian formulation, in which the learning rule corresponds to the kinetic energy and the loss function corresponds to the potential energy. Then, we identify "kinetic symmetry breaking" (KSB), the condition when the kinetic energy explicitly breaks the symmetry of the potential function. We generalize Noether's theorem known in physics to take into account KSB and derive the resulting motion of the Noether charge: "Noether's Learning Dynamics" (NLD). Finally, we apply NLD to neural networks with normalization layers and reveal how KSB introduces a mechanism of "implicit adaptive optimization", establishing an analogy between learning dynamics induced by normalization layers and RMSProp. Overall, through the lens of Lagrangian mechanics, we have established a theoretical foundation to discover geometric design principles for the learning dynamics of neural networks.

</p>
</details>

<details><summary><b>Deep Weighted Consensus: Dense correspondence confidence maps for 3D shape registration</b>
<a href="https://arxiv.org/abs/2105.02714">arxiv:2105.02714</a>
&#x1F4C8; 2 <br>
<p>Dvir Ginzburg, Dan Raviv</p></summary>
<p>

**Abstract:** We present a new paradigm for rigid alignment between point clouds based on learnable weighted consensus which is robust to noise as well as the full spectrum of the rotation group.
  Current models, learnable or axiomatic, work well for constrained orientations and limited noise levels, usually by an end-to-end learner or an iterative scheme. However, real-world tasks require us to deal with large rotations as well as outliers and all known models fail to deliver.
  Here we present a different direction. We claim that we can align point clouds out of sampled matched points according to confidence level derived from a dense, soft alignment map. The pipeline is differentiable, and converges under large rotations in the full spectrum of SO(3), even with high noise levels. We compared the network to recently presented methods such as DCP, PointNetLK, RPM-Net, PRnet, and axiomatic methods such as ICP and Go-ICP. We report here a fundamental boost in performance.

</p>
</details>

<details><summary><b>A 2.5D Vehicle Odometry Estimation for Vision Applications</b>
<a href="https://arxiv.org/abs/2105.02679">arxiv:2105.02679</a>
&#x1F4C8; 2 <br>
<p>Paul Moran, Leroy-Francisco Periera, Anbuchezhiyan Selvaraju, Tejash Prakash, Pantelis Ermilios, John McDonald, Jonathan Horgan, Ciarán Eising</p></summary>
<p>

**Abstract:** This paper proposes a method to estimate the pose of a sensor mounted on a vehicle as the vehicle moves through the world, an important topic for autonomous driving systems. Based on a set of commonly deployed vehicular odometric sensors, with outputs available on automotive communication buses (e.g. CAN or FlexRay), we describe a set of steps to combine a planar odometry based on wheel sensors with a suspension model based on linear suspension sensors. The aim is to determine a more accurate estimate of the camera pose. We outline its usage for applications in both visualisation and computer vision.

</p>
</details>

<details><summary><b>FDNet: A Deep Learning Approach with Two Parallel Cross Encoding Pathways for Precipitation Nowcasting</b>
<a href="https://arxiv.org/abs/2105.02585">arxiv:2105.02585</a>
&#x1F4C8; 2 <br>
<p>Bi-Ying Yan, Chao Yang, Feng Chen, Kohei Takeda, Changjun Wang</p></summary>
<p>

**Abstract:** With the goal of predicting the future rainfall intensity in a local region over a relatively short period time, precipitation nowcasting has been a long-time scientific challenge with great social and economic impact. The radar echo extrapolation approaches for precipitation nowcasting take radar echo images as input, aiming to generate future radar echo images by learning from the historical images. To effectively handle complex and high non-stationary evolution of radar echoes, we propose to decompose the movement into optical flow field motion and morphologic deformation. Following this idea, we introduce Flow-Deformation Network (FDNet), a neural network that models flow and deformation in two parallel cross pathways. The flow encoder captures the optical flow field motion between consecutive images and the deformation encoder distinguishes the change of shape from the translational motion of radar echoes. We evaluate the proposed network architecture on two real-world radar echo datasets. Our model achieves state-of-the-art prediction results compared with recent approaches. To the best of our knowledge, this is the first network architecture with flow and deformation separation to model the evolution of radar echoes for precipitation nowcasting. We believe that the general idea of this work could not only inspire much more effective approaches but also be applied to other similar spatiotemporal prediction tasks

</p>
</details>

<details><summary><b>MCMC-driven importance samplers</b>
<a href="https://arxiv.org/abs/2105.02579">arxiv:2105.02579</a>
&#x1F4C8; 2 <br>
<p>F. Llorente, E. Curbelo, L. Martino, V. Elvira, D. Delgado</p></summary>
<p>

**Abstract:** Monte Carlo methods are the standard procedure for estimating complicated integrals of multidimensional Bayesian posterior distributions. In this work, we focus on LAIS, a class of adaptive importance samplers where Markov chain Monte Carlo (MCMC) algorithms are employed to drive an underlying multiple importance sampling (IS) scheme. Its power lies in the simplicity of the layered framework: the upper layer locates proposal densities by means of MCMC algorithms; while the lower layer handles the multiple IS scheme, in order to compute the final estimators. The modular nature of LAIS allows for different possible choices in the upper and lower layers, that will have different performance and computational costs. In this work, we propose different enhancements in order to increase the efficiency and reduce the computational cost, of both upper and lower layers. The different variants are essential if we aim to address computational challenges arising in real-world applications, such as highly concentrated posterior distributions (due to large amounts of data, etc.). Hamiltonian-driven importance samplers are presented and tested. Furthermore, we introduce different strategies for designing cheaper schemes, for instance, recycling samples generated in the upper layer and using them in the final estimators in the lower layer. Numerical experiments show the benefits of the proposed schemes as compared to the vanilla version of LAIS and other benchmark methods.

</p>
</details>

<details><summary><b>A novel method of predictive collision risk area estimation for proactive pedestrian accident prevention system in urban surveillance infrastructure</b>
<a href="https://arxiv.org/abs/2105.02572">arxiv:2105.02572</a>
&#x1F4C8; 2 <br>
<p>Byeongjoon Noh, Hwasoo Yeo</p></summary>
<p>

**Abstract:** Road traffic accidents, especially vehicle pedestrian collisions in crosswalk, globally pose a severe threat to human lives and have become a leading cause of premature deaths. In order to protect such vulnerable road users from collisions, it is necessary to recognize possible conflict in advance and warn to road users, not post facto. A breakthrough for proactively preventing pedestrian collisions is to recognize pedestrian's potential risks based on vision sensors such as CCTVs. In this study, we propose a predictive collision risk area estimation system at unsignalized crosswalks. The proposed system applied trajectories of vehicles and pedestrians from video footage after preprocessing, and then predicted their trajectories by using deep LSTM networks. With use of predicted trajectories, this system can infer collision risk areas statistically, further severity of levels is divided as danger, warning, and relative safe. In order to validate the feasibility and applicability of the proposed system, we applied it and assess the severity of potential risks in two unsignalized spots in Osan city, Korea.

</p>
</details>

<details><summary><b>Quantification of pulmonary involvement in COVID-19 pneumonia by means of a cascade oftwo U-nets: training and assessment on multipledatasets using different annotation criteria</b>
<a href="https://arxiv.org/abs/2105.02566">arxiv:2105.02566</a>
&#x1F4C8; 2 <br>
<p>Francesca Lizzi, Abramo Agosti, Francesca Brero, Raffaella Fiamma Cabini, Maria Evelina Fantacci, Silvia Figini, Alessandro Lascialfari, Francesco Laruina, Piernicola Oliva, Stefano Piffer, Ian Postuma, Lisa Rinaldi, Cinzia Talamonti, Alessandra Retico</p></summary>
<p>

**Abstract:** The automatic assignment of a severity score to the CT scans of patients affected by COVID-19 pneumonia could reduce the workload in radiology departments. This study aims at exploiting Artificial intelligence (AI) for the identification, segmentation and quantification of COVID-19 pulmonary lesions. We investigated the effects of using multiple datasets, heterogeneously populated and annotated according to different criteria. We developed an automated analysis pipeline, the LungQuant system, based on a cascade of two U-nets. The first one (U-net_1) is devoted to the identification of the lung parenchyma, the second one (U-net_2) acts on a bounding box enclosing the segmented lungs to identify the areas affected by COVID-19 lesions. Different public datasets were used to train the U-nets and to evaluate their segmentation performances, which have been quantified in terms of the Dice index. The accuracy in predicting the CT-Severity Score (CT-SS) of the LungQuant system has been also evaluated. Both Dice and accuracy showed a dependency on the quality of annotations of the available data samples. On an independent and publicly available benchmark dataset, the Dice values measured between the masks predicted by LungQuant system and the reference ones were 0.95$\pm$0.01 and 0.66$\pm$0.13 for the segmentation of lungs and COVID-19 lesions, respectively. The accuracy of 90% in the identification of the CT-SS on this benchmark dataset was achieved. We analysed the impact of using data samples with different annotation criteria in training an AI-based quantification system for pulmonary involvement in COVID-19 pneumonia. In terms of the Dice index, the U-net segmentation quality strongly depends on the quality of the lesion annotations. Nevertheless, the CT-SS can be accurately predicted on independent validation sets, demonstrating the satisfactory generalization ability of the LungQuant.

</p>
</details>

<details><summary><b>(ASNA) An Attention-based Siamese-Difference Neural Network with Surrogate Ranking Loss function for Perceptual Image Quality Assessment</b>
<a href="https://arxiv.org/abs/2105.02531">arxiv:2105.02531</a>
&#x1F4C8; 2 <br>
<p>Seyed Mehdi Ayyoubzadeh, Ali Royat</p></summary>
<p>

**Abstract:** Recently, deep convolutional neural networks (DCNN) that leverage the adversarial training framework for image restoration and enhancement have significantly improved the processed images' sharpness. Surprisingly, although these DCNNs produced crispier images than other methods visually, they may get a lower quality score when popular measures are employed for evaluating them. Therefore it is necessary to develop a quantitative metric to reflect their performances, which is well-aligned with the perceived quality of an image. Famous quantitative metrics such as Peak signal-to-noise ratio (PSNR), The structural similarity index measure (SSIM), and Perceptual Index (PI) are not well-correlated with the mean opinion score (MOS) for an image, especially for the neural networks trained with adversarial loss functions.
  This paper has proposed a convolutional neural network using an extension architecture of the traditional Siamese network so-called Siamese-Difference neural network. We have equipped this architecture with the spatial and channel-wise attention mechanism to increase our method's performance.
  Finally, we employed an auxiliary loss function to train our model. The suggested additional cost function surrogates ranking loss to increase Spearman's rank correlation coefficient while it is differentiable concerning the neural network parameters. Our method achieved superior performance in \textbf{\textit{NTIRE 2021 Perceptual Image Quality Assessment}} Challenge. The implementations of our proposed method are publicly available.

</p>
</details>

<details><summary><b>Learning Neighborhood Representation from Multi-Modal Multi-Graph: Image, Text, Mobility Graph and Beyond</b>
<a href="https://arxiv.org/abs/2105.02489">arxiv:2105.02489</a>
&#x1F4C8; 2 <br>
<p>Tianyuan Huang, Zhecheng Wang, Hao Sheng, Andrew Y. Ng, Ram Rajagopal</p></summary>
<p>

**Abstract:** Recent urbanization has coincided with the enrichment of geotagged data, such as street view and point-of-interest (POI). Region embedding enhanced by the richer data modalities has enabled researchers and city administrators to understand the built environment, socioeconomics, and the dynamics of cities better. While some efforts have been made to simultaneously use multi-modal inputs, existing methods can be improved by incorporating different measures of 'proximity' in the same embedding space - leveraging not only the data that characterizes the regions (e.g., street view, local businesses pattern) but also those that depict the relationship between regions (e.g., trips, road network). To this end, we propose a novel approach to integrate multi-modal geotagged inputs as either node or edge features of a multi-graph based on their relations with the neighborhood region (e.g., tiles, census block, ZIP code region, etc.). We then learn the neighborhood representation based on a contrastive-sampling scheme from the multi-graph. Specifically, we use street view images and POI features to characterize neighborhoods (nodes) and use human mobility to characterize the relationship between neighborhoods (directed edges). We show the effectiveness of the proposed methods with quantitative downstream tasks as well as qualitative analysis of the embedding space: The embedding we trained outperforms the ones using only unimodal data as regional inputs.

</p>
</details>

<details><summary><b>High-dimensional Functional Graphical Model Structure Learning via Neighborhood Selection Approach</b>
<a href="https://arxiv.org/abs/2105.02487">arxiv:2105.02487</a>
&#x1F4C8; 2 <br>
<p>Boxin Zhao, Shengjun Zhai, Y. Samuel Wang, Mladen Kolar</p></summary>
<p>

**Abstract:** Undirected graphical models have been widely used to model the conditional independence structure of high-dimensional random vector data for years. In many modern applications such as EEG and fMRI data, the observations are multivariate random functions rather than scalars. To model the conditional independence of this type of data, functional graphical models are proposed and have attracted an increasing attention in recent years. In this paper, we propose a neighborhood selection approach to estimate Gaussian functional graphical models. We first estimate the neighborhood of all nodes via function-on-function regression, and then we can recover the whole graph structure based on the neighborhood information. By estimating conditional structure directly, we can circumvent the need of a well-defined precision operator which generally does not exist. Besides, we can better explore the effect of the choice of function basis for dimension reduction. We give a criterion for choosing the best function basis and motivate two practically useful choices, which we justified by both theory and experiments and show that they are better than expanding each function onto its own FPCA basis as in previous literature. In addition, the neighborhood selection approach is computationally more efficient than fglasso as it is more easy to do parallel computing. The statistical consistency of our proposed methods in high-dimensional setting are supported by both theory and experiment.

</p>
</details>

<details><summary><b>KuraNet: Systems of Coupled Oscillators that Learn to Synchronize</b>
<a href="https://arxiv.org/abs/2105.02838">arxiv:2105.02838</a>
&#x1F4C8; 1 <br>
<p>Matthew Ricci, Minju Jung, Yuwei Zhang, Mathieu Chalvidal, Aneri Soni, Thomas Serre</p></summary>
<p>

**Abstract:** Networks of coupled oscillators are some of the most studied objects in the theory of dynamical systems. Two important areas of current interest are the study of synchrony in highly disordered systems and the modeling of systems with adaptive network structures. Here, we present a single approach to both of these problems in the form of "KuraNet", a deep-learning-based system of coupled oscillators that can learn to synchronize across a distribution of disordered network conditions. The key feature of the model is the replacement of the traditionally static couplings with a coupling function which can learn optimal interactions within heterogeneous oscillator populations. We apply our approach to the eponymous Kuramoto model and demonstrate how KuraNet can learn data-dependent coupling structures that promote either global or cluster synchrony. For example, we show how KuraNet can be used to empirically explore the conditions of global synchrony in analytically impenetrable models with disordered natural frequencies, external field strengths, and interaction delays. In a sequence of cluster synchrony experiments, we further show how KuraNet can function as a data classifier by synchronizing into coherent assemblies. In all cases, we show how KuraNet can generalize to both new data and new network scales, making it easy to work with small systems and form hypotheses about the thermodynamic limit. Our proposed learning-based approach is broadly applicable to arbitrary dynamical systems with wide-ranging relevance to modeling in physics and systems biology.

</p>
</details>

<details><summary><b>Deep Learning based Multi-modal Computing with Feature Disentanglement for MRI Image Synthesis</b>
<a href="https://arxiv.org/abs/2105.02835">arxiv:2105.02835</a>
&#x1F4C8; 1 <br>
<p>Yuchen Fei, Bo Zhan, Mei Hong, Xi Wu, Jiliu Zhou, Yan Wang</p></summary>
<p>

**Abstract:** Purpose: Different Magnetic resonance imaging (MRI) modalities of the same anatomical structure are required to present different pathological information from the physical level for diagnostic needs. However, it is often difficult to obtain full-sequence MRI images of patients owing to limitations such as time consumption and high cost. The purpose of this work is to develop an algorithm for target MRI sequences prediction with high accuracy, and provide more information for clinical diagnosis. Methods: We propose a deep learning based multi-modal computing model for MRI synthesis with feature disentanglement strategy. To take full advantage of the complementary information provided by different modalities, multi-modal MRI sequences are utilized as input. Notably, the proposed approach decomposes each input modality into modality-invariant space with shared information and modality-specific space with specific information, so that features are extracted separately to effectively process the input data. Subsequently, both of them are fused through the adaptive instance normalization (AdaIN) layer in the decoder. In addition, to address the lack of specific information of the target modality in the test phase, a local adaptive fusion (LAF) module is adopted to generate a modality-like pseudo-target with specific information similar to the ground truth. Results: To evaluate the synthesis performance, we verify our method on the BRATS2015 dataset of 164 subjects. The experimental results demonstrate our approach significantly outperforms the benchmark method and other state-of-the-art medical image synthesis methods in both quantitative and qualitative measures. Compared with the pix2pixGANs method, the PSNR improves from 23.68 to 24.8. Conclusion: The proposed method could be effective in prediction of target MRI sequences, and useful for clinical diagnosis and treatment.

</p>
</details>

<details><summary><b>Dynamic Defense Approach for Adversarial Robustness in Deep Neural Networks via Stochastic Ensemble Smoothed Model</b>
<a href="https://arxiv.org/abs/2105.02803">arxiv:2105.02803</a>
&#x1F4C8; 1 <br>
<p>Ruoxi Qin, Linyuan Wang, Xingyuan Chen, Xuehui Du, Bin Yan</p></summary>
<p>

**Abstract:** Deep neural networks have been shown to suffer from critical vulnerabilities under adversarial attacks. This phenomenon stimulated the creation of different attack and defense strategies similar to those adopted in cyberspace security. The dependence of such strategies on attack and defense mechanisms makes the associated algorithms on both sides appear as closely reciprocating processes. The defense strategies are particularly passive in these processes, and enhancing initiative of such strategies can be an effective way to get out of this arms race. Inspired by the dynamic defense approach in cyberspace, this paper builds upon stochastic ensemble smoothing based on defense method of random smoothing and model ensemble. Proposed method employs network architecture and smoothing parameters as ensemble attributes, and dynamically change attribute-based ensemble model before every inference prediction request. The proposed method handles the extreme transferability and vulnerability of ensemble models under white-box attacks. Experimental comparison of ASR-vs-distortion curves with different attack scenarios shows that even the attacker with the highest attack capability cannot easily exceed the attack success rate associated with the ensemble smoothed model, especially under untargeted attacks.

</p>
</details>

<details><summary><b>Saliency-Guided Deep Learning Network for Automatic Tumor Bed Volume Delineation in Post-operative Breast Irradiation</b>
<a href="https://arxiv.org/abs/2105.02771">arxiv:2105.02771</a>
&#x1F4C8; 1 <br>
<p>Mahdieh Kazemimoghadam, Weicheng Chi, Asal Rahimi, Nathan Kim, Prasanna Alluri, Chika Nwachukwu, Weiguo Lu, Xuejun Gu</p></summary>
<p>

**Abstract:** Efficient, reliable and reproducible target volume delineation is a key step in the effective planning of breast radiotherapy. However, post-operative breast target delineation is challenging as the contrast between the tumor bed volume (TBV) and normal breast tissue is relatively low in CT images. In this study, we propose to mimic the marker-guidance procedure in manual target delineation. We developed a saliency-based deep learning segmentation (SDL-Seg) algorithm for accurate TBV segmentation in post-operative breast irradiation. The SDL-Seg algorithm incorporates saliency information in the form of markers' location cues into a U-Net model. The design forces the model to encode the location-related features, which underscores regions with high saliency levels and suppresses low saliency regions. The saliency maps were generated by identifying markers on CT images. Markers' locations were then converted to probability maps using a distance-transformation coupled with a Gaussian filter. Subsequently, the CT images and the corresponding saliency maps formed a multi-channel input for the SDL-Seg network. Our in-house dataset was comprised of 145 prone CT images from 29 post-operative breast cancer patients, who received 5-fraction partial breast irradiation (PBI) regimen on GammaPod. The performance of the proposed method was compared against basic U-Net. Our model achieved mean (standard deviation) of 76.4 %, 6.76 mm, and 1.9 mm for DSC, HD95, and ASD respectively on the test set with computation time of below 11 seconds per one CT volume. SDL-Seg showed superior performance relative to basic U-Net for all the evaluation metrics while preserving low computation cost. The findings demonstrate that SDL-Seg is a promising approach for improving the efficiency and accuracy of the on-line treatment planning procedure of PBI, such as GammaPod based PBI.

</p>
</details>

<details><summary><b>SS-CADA: A Semi-Supervised Cross-Anatomy Domain Adaptation for Coronary Artery Segmentation</b>
<a href="https://arxiv.org/abs/2105.02674">arxiv:2105.02674</a>
&#x1F4C8; 1 <br>
<p>Jingyang Zhang, Ran Gu, Guotai Wang, Hongzhi Xie, Lixu Gu</p></summary>
<p>

**Abstract:** The segmentation of coronary arteries by convolutional neural network is promising yet requires a large amount of labor-intensive manual annotations. Transferring knowledge from retinal vessels in widely-available public labeled fundus images (FIs) has a potential to reduce the annotation requirement for coronary artery segmentation in X-ray angiograms (XAs) due to their common tubular structures. However, it is challenged by the cross-anatomy domain shift due to the intrinsically different vesselness characteristics in different anatomical regions under even different imaging protocols. To solve this problem, we propose a Semi-Supervised Cross-Anatomy Domain Adaptation (SS-CADA) which requires only limited annotations for coronary arteries in XAs. With the supervision from a small number of labeled XAs and publicly available labeled FIs, we propose a vesselness-specific batch normalization (VSBN) to individually normalize feature maps for them considering their different cross-anatomic vesselness characteristics. In addition, to further facilitate the annotation efficiency, we employ a self-ensembling mean-teacher (SEMT) to exploit abundant unlabeled XAs by imposing a prediction consistency constraint. Extensive experiments show that our SS-CADA is able to solve the challenging cross-anatomy domain shift, achieving accurate segmentation for coronary arteries given only a small number of labeled XAs.

</p>
</details>

<details><summary><b>Ordinal UNLOC: Target Localization with Noisy and Incomplete Distance Measures</b>
<a href="https://arxiv.org/abs/2105.02671">arxiv:2105.02671</a>
&#x1F4C8; 1 <br>
<p>Mahesh K. Banavar, Shandeepa Wickramasinghe, Monalisa Achalla, Jie Sun</p></summary>
<p>

**Abstract:** A main challenge in target localization arises from the lack of reliable distance measures. This issue is especially pronounced in indoor settings due to the presence of walls, floors, furniture, and other dynamically changing conditions such as the movement of people and goods, varying temperature, and airflows. Here, we develop a new computational framework to estimate the location of a target without the need for reliable distance measures. The method, which we term Ordinal UNLOC, uses only ordinal data obtained from comparing the signal strength from anchor pairs at known locations to the target. Our estimation technique utilizes rank aggregation, function learning as well as proximity-based unfolding optimization. As a result, it yields accurate target localization for common transmission models with unknown parameters and noisy observations that are reminiscent of practical settings. Our results are validated by both numerical simulations and hardware experiments.

</p>
</details>

<details><summary><b>A Reinforcement Learning-based Economic Model Predictive Control Framework for Autonomous Operation of Chemical Reactors</b>
<a href="https://arxiv.org/abs/2105.02656">arxiv:2105.02656</a>
&#x1F4C8; 1 <br>
<p>Khalid Alhazmi, Fahad Albalawi, S. Mani Sarathy</p></summary>
<p>

**Abstract:** Economic model predictive control (EMPC) is a promising methodology for optimal operation of dynamical processes that has been shown to improve process economics considerably. However, EMPC performance relies heavily on the accuracy of the process model used. As an alternative to model-based control strategies, reinforcement learning (RL) has been investigated as a model-free control methodology, but issues regarding its safety and stability remain an open research challenge. This work presents a novel framework for integrating EMPC and RL for online model parameter estimation of a class of nonlinear systems. In this framework, EMPC optimally operates the closed loop system while maintaining closed loop stability and recursive feasibility. At the same time, to optimize the process, the RL agent continuously compares the measured state of the process with the model's predictions (nominal states), and modifies model parameters accordingly. The major advantage of this framework is its simplicity; state-of-the-art RL algorithms and EMPC schemes can be employed with minimal modifications. The performance of the proposed framework is illustrated on a network of reactions with challenging dynamics and practical significance. This framework allows control, optimization, and model correction to be performed online and continuously, making autonomous reactor operation more attainable.

</p>
</details>

<details><summary><b>Direct Prediction of Steady-State Flow Fields in Meshed Domain with Graph Networks</b>
<a href="https://arxiv.org/abs/2105.02575">arxiv:2105.02575</a>
&#x1F4C8; 1 <br>
<p>Lukas Harsch, Stefan Riedelbauch</p></summary>
<p>

**Abstract:** We propose a model to directly predict the steady-state flow field for a given geometry setup. The setup is an Eulerian representation of the fluid flow as a meshed domain. We introduce a graph network architecture to process the mesh-space simulation as a graph. The benefit of our model is a strong understanding of the global physical system, while being able to explore the local structure. This is essential to perform direct prediction and is thus superior to other existing methods.

</p>
</details>

<details><summary><b>DiffSinger: Singing Voice Synthesis via Shallow Diffusion Mechanism</b>
<a href="https://arxiv.org/abs/2105.02446">arxiv:2105.02446</a>
&#x1F4C8; 1 <br>
<p>Jinglin Liu, Chengxi Li, Yi Ren, Feiyang Chen, Zhou Zhao</p></summary>
<p>

**Abstract:** Singing voice synthesis (SVS) systems are built to synthesize high-quality and expressive singing voice, in which the acoustic model generates the acoustic features (e.g., mel-spectrogram) given a music score. Previous singing acoustic models adopt a simple loss (e.g., L1 and L2) or generative adversarial network (GAN) to reconstruct the acoustic features, while they suffer from over-smoothing and unstable training issues respectively, which hinder the naturalness of synthesized singing. In this work, we propose DiffSinger, an acoustic model for SVS based on the diffusion probabilistic model. DiffSinger is a parameterized Markov chain that iteratively converts the noise into mel-spectrogram conditioned on the music score. By implicitly optimizing variational bound, DiffSinger can be stably trained and generate realistic outputs. To further improve the voice quality and speed up inference, we introduce a shallow diffusion mechanism to make better use of the prior knowledge learned by the simple loss. Specifically, DiffSinger starts generation at a shallow step smaller than the total number of diffusion steps, according to the intersection of the diffusion trajectories of the ground-truth mel-spectrogram and the one predicted by a simple mel-spectrogram decoder. Besides, we propose boundary prediction methods to locate the intersection and determine the shallow step adaptively. The evaluations conducted on a Chinese singing dataset demonstrate that DiffSinger outperforms state-of-the-art SVS work. Extensional experiments also prove the generalization of our methods on text-to-speech task (DiffSpeech). Audio samples: https://diffsinger.github.io. Codes: https://github.com/MoonInTheRiver/DiffSinger.

</p>
</details>

<details><summary><b>Imitation Learning via Simultaneous Optimization of Policies and Auxiliary Trajectories</b>
<a href="https://arxiv.org/abs/2105.03019">arxiv:2105.03019</a>
&#x1F4C8; 0 <br>
<p>Mandy Xie, Anqi Li, Karl Van Wyk, Frank Dellaert, Byron Boots, Nathan Ratliff</p></summary>
<p>

**Abstract:** Imitation learning (IL) is a frequently used approach for data-efficient policy learning. Many IL methods, such as Dataset Aggregation (DAgger), combat challenges like distributional shift by interacting with oracular experts. Unfortunately, assuming access to oracular experts is often unrealistic in practice; data used in IL frequently comes from offline processes such as lead-through or teleoperation. In this paper, we present a novel imitation learning technique called Collocation for Demonstration Encoding (CoDE) that operates on only a fixed set of trajectory demonstrations. We circumvent challenges with methods like back-propagation-through-time by introducing an auxiliary trajectory network, which takes inspiration from collocation techniques in optimal control. Our method generalizes well and more accurately reproduces the demonstrated behavior with fewer guiding trajectories when compared to standard behavioral cloning methods. We present simulation results on a 7-degree-of-freedom (DoF) robotic manipulator that learns to exhibit lifting, target-reaching, and obstacle avoidance behaviors.

</p>
</details>

<details><summary><b>Graphical modelling in continuous-time: consistency guarantees and algorithms using Neural ODEs</b>
<a href="https://arxiv.org/abs/2105.02522">arxiv:2105.02522</a>
&#x1F4C8; 0 <br>
<p>Alexis Bellot, Kim Branson, Mihaela van der Schaar</p></summary>
<p>

**Abstract:** The discovery of structure from time series data is a key problem in fields of study working with complex systems. Most identifiability results and learning algorithms assume the underlying dynamics to be discrete in time. Comparatively few, in contrast, explicitly define dependencies in infinitesimal intervals of time, independently of the scale of observation and of the regularity of sampling. In this paper, we consider score-based graph learning for the study of dynamical systems. We prove that for vector fields parameterized in a large class of neural networks, least squares optimization with adaptive regularization schemes consistently recovers directed graphs of local independencies in systems of stochastic differential equations. Using this insight, we propose a score-based learning algorithm based on penalized Neural Ordinary Differential Equations (modelling the mean process) that we show to be applicable to the general setting of irregularly-sampled multivariate time series and to outperform the state of the art across a range of dynamical systems.

</p>
</details>


[Next Page]({{ '/2021/05/05/2021.05.05.html' | relative_url }})
