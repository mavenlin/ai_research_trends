## Summary for 2021-05-20, created on 2021-12-21


<details><summary><b>Improving Generation and Evaluation of Visual Stories via Semantic Consistency</b>
<a href="https://arxiv.org/abs/2105.10026">arxiv:2105.10026</a>
&#x1F4C8; 22 <br>
<p>Adyasha Maharana, Darryl Hannan, Mohit Bansal</p></summary>
<p>

**Abstract:** Story visualization is an under-explored task that falls at the intersection of many important research directions in both computer vision and natural language processing. In this task, given a series of natural language captions which compose a story, an agent must generate a sequence of images that correspond to the captions. Prior work has introduced recurrent generative models which outperform text-to-image synthesis models on this task. However, there is room for improvement of generated images in terms of visual quality, coherence and relevance. We present a number of improvements to prior modeling approaches, including (1) the addition of a dual learning framework that utilizes video captioning to reinforce the semantic alignment between the story and generated images, (2) a copy-transform mechanism for sequentially-consistent story visualization, and (3) MART-based transformers to model complex interactions between frames. We present ablation studies to demonstrate the effect of each of these techniques on the generative power of the model for both individual images as well as the entire narrative. Furthermore, due to the complexity and generative nature of the task, standard evaluation metrics do not accurately reflect performance. Therefore, we also provide an exploration of evaluation metrics for the model, focused on aspects of the generated frames such as the presence/quality of generated characters, the relevance to captions, and the diversity of the generated images. We also present correlation experiments of our proposed automated metrics with human evaluations. Code and data available at: https://github.com/adymaharana/StoryViz

</p>
</details>

<details><summary><b>Kernel Stein Discrepancy Descent</b>
<a href="https://arxiv.org/abs/2105.09994">arxiv:2105.09994</a>
&#x1F4C8; 22 <br>
<p>Anna Korba, Pierre-Cyril Aubin-Frankowski, Szymon Majewski, Pierre Ablin</p></summary>
<p>

**Abstract:** Among dissimilarities between probability distributions, the Kernel Stein Discrepancy (KSD) has received much interest recently. We investigate the properties of its Wasserstein gradient flow to approximate a target probability distribution $π$ on $\mathbb{R}^d$, known up to a normalization constant. This leads to a straightforwardly implementable, deterministic score-based method to sample from $π$, named KSD Descent, which uses a set of particles to approximate $π$. Remarkably, owing to a tractable loss function, KSD Descent can leverage robust parameter-free optimization schemes such as L-BFGS; this contrasts with other popular particle-based schemes such as the Stein Variational Gradient Descent algorithm. We study the convergence properties of KSD Descent and demonstrate its practical relevance. However, we also highlight failure cases by showing that the algorithm can get stuck in spurious local minima.

</p>
</details>

<details><summary><b>Measuring Coding Challenge Competence With APPS</b>
<a href="https://arxiv.org/abs/2105.09938">arxiv:2105.09938</a>
&#x1F4C8; 22 <br>
<p>Dan Hendrycks, Steven Basart, Saurav Kadavath, Mantas Mazeika, Akul Arora, Ethan Guo, Collin Burns, Samir Puranik, Horace He, Dawn Song, Jacob Steinhardt</p></summary>
<p>

**Abstract:** While programming is one of the most broadly applicable skills in modern society, modern machine learning models still cannot code solutions to basic problems. Despite its importance, there has been surprisingly little work on evaluating code generation, and it can be difficult to accurately assess code generation performance rigorously. To meet this challenge, we introduce APPS, a benchmark for code generation. Unlike prior work in more restricted settings, our benchmark measures the ability of models to take an arbitrary natural language specification and generate satisfactory Python code. Similar to how companies assess candidate software developers, we then evaluate models by checking their generated code on test cases. Our benchmark includes 10,000 problems, which range from having simple one-line solutions to being substantial algorithmic challenges. We fine-tune large language models on both GitHub and our training set, and we find that the prevalence of syntax errors is decreasing exponentially as models improve. Recent models such as GPT-Neo can pass approximately 20% of the test cases of introductory problems, so we find that machine learning models are now beginning to learn how to code. As the social significance of automatic code generation increases over the coming years, our benchmark can provide an important measure for tracking advancements.

</p>
</details>

<details><summary><b>Efficient and Robust LiDAR-Based End-to-End Navigation</b>
<a href="https://arxiv.org/abs/2105.09932">arxiv:2105.09932</a>
&#x1F4C8; 16 <br>
<p>Zhijian Liu, Alexander Amini, Sibo Zhu, Sertac Karaman, Song Han, Daniela Rus</p></summary>
<p>

**Abstract:** Deep learning has been used to demonstrate end-to-end neural network learning for autonomous vehicle control from raw sensory input. While LiDAR sensors provide reliably accurate information, existing end-to-end driving solutions are mainly based on cameras since processing 3D data requires a large memory footprint and computation cost. On the other hand, increasing the robustness of these systems is also critical; however, even estimating the model's uncertainty is very challenging due to the cost of sampling-based methods. In this paper, we present an efficient and robust LiDAR-based end-to-end navigation framework. We first introduce Fast-LiDARNet that is based on sparse convolution kernel optimization and hardware-aware model design. We then propose Hybrid Evidential Fusion that directly estimates the uncertainty of the prediction from only a single forward pass and then fuses the control predictions intelligently. We evaluate our system on a full-scale vehicle and demonstrate lane-stable as well as navigation capabilities. In the presence of out-of-distribution events (e.g., sensor failures), our system significantly improves robustness and reduces the number of takeovers in the real world.

</p>
</details>

<details><summary><b>Cross-domain Imitation from Observations</b>
<a href="https://arxiv.org/abs/2105.10037">arxiv:2105.10037</a>
&#x1F4C8; 13 <br>
<p>Dripta S. Raychaudhuri, Sujoy Paul, Jeroen van Baar, Amit K. Roy-Chowdhury</p></summary>
<p>

**Abstract:** Imitation learning seeks to circumvent the difficulty in designing proper reward functions for training agents by utilizing expert behavior. With environments modeled as Markov Decision Processes (MDP), most of the existing imitation algorithms are contingent on the availability of expert demonstrations in the same MDP as the one in which a new imitation policy is to be learned. In this paper, we study the problem of how to imitate tasks when there exist discrepancies between the expert and agent MDP. These discrepancies across domains could include differing dynamics, viewpoint, or morphology; we present a novel framework to learn correspondences across such domains. Importantly, in contrast to prior works, we use unpaired and unaligned trajectories containing only states in the expert domain, to learn this correspondence. We utilize a cycle-consistency constraint on both the state space and a domain agnostic latent space to do this. In addition, we enforce consistency on the temporal position of states via a normalized position estimator function, to align the trajectories across the two domains. Once this correspondence is found, we can directly transfer the demonstrations on one domain to the other and use it for imitation. Experiments across a wide variety of challenging domains demonstrate the efficacy of our approach.

</p>
</details>

<details><summary><b>Low-Latency Real-Time Non-Parallel Voice Conversion based on Cyclic Variational Autoencoder and Multiband WaveRNN with Data-Driven Linear Prediction</b>
<a href="https://arxiv.org/abs/2105.09858">arxiv:2105.09858</a>
&#x1F4C8; 10 <br>
<p>Patrick Lumban Tobing, Tomoki Toda</p></summary>
<p>

**Abstract:** This paper presents a low-latency real-time (LLRT) non-parallel voice conversion (VC) framework based on cyclic variational autoencoder (CycleVAE) and multiband WaveRNN with data-driven linear prediction (MWDLP). CycleVAE is a robust non-parallel multispeaker spectral model, which utilizes a speaker-independent latent space and a speaker-dependent code to generate reconstructed/converted spectral features given the spectral features of an input speaker. On the other hand, MWDLP is an efficient and a high-quality neural vocoder that can handle multispeaker data and generate speech waveform for LLRT applications with CPU. To accommodate LLRT constraint with CPU, we propose a novel CycleVAE framework that utilizes mel-spectrogram as spectral features and is built with a sparse network architecture. Further, to improve the modeling performance, we also propose a novel fine-tuning procedure that refines the frame-rate CycleVAE network by utilizing the waveform loss from the MWDLP network. The experimental results demonstrate that the proposed framework achieves high-performance VC, while allowing for LLRT usage with a single-core of $2.1$--$2.7$ GHz CPU on a real-time factor of $0.87$--$0.95$, including input/output, feature extraction, on a frame shift of $10$ ms, a window length of $27.5$ ms, and $2$ lookup frames.

</p>
</details>

<details><summary><b>Manual Evaluation Matters: Reviewing Test Protocols of Distantly Supervised Relation Extraction</b>
<a href="https://arxiv.org/abs/2105.09543">arxiv:2105.09543</a>
&#x1F4C8; 10 <br>
<p>Tianyu Gao, Xu Han, Keyue Qiu, Yuzhuo Bai, Zhiyu Xie, Yankai Lin, Zhiyuan Liu, Peng Li, Maosong Sun, Jie Zhou</p></summary>
<p>

**Abstract:** Distantly supervised (DS) relation extraction (RE) has attracted much attention in the past few years as it can utilize large-scale auto-labeled data. However, its evaluation has long been a problem: previous works either took costly and inconsistent methods to manually examine a small sample of model predictions, or directly test models on auto-labeled data -- which, by our check, produce as much as 53% wrong labels at the entity pair level in the popular NYT10 dataset. This problem has not only led to inaccurate evaluation, but also made it hard to understand where we are and what's left to improve in the research of DS-RE. To evaluate DS-RE models in a more credible way, we build manually-annotated test sets for two DS-RE datasets, NYT10 and Wiki20, and thoroughly evaluate several competitive models, especially the latest pre-trained ones. The experimental results show that the manual evaluation can indicate very different conclusions from automatic ones, especially some unexpected observations, e.g., pre-trained models can achieve dominating performance while being more susceptible to false-positives compared to previous methods. We hope that both our manual test sets and novel observations can help advance future DS-RE research.

</p>
</details>

<details><summary><b>Document Domain Randomization for Deep Learning Document Layout Extraction</b>
<a href="https://arxiv.org/abs/2105.14931">arxiv:2105.14931</a>
&#x1F4C8; 9 <br>
<p>Meng Ling, Jian Chen, Torsten Möller, Petra Isenberg, Tobias Isenberg, Michael Sedlmair, Robert S. Laramee, Han-Wei Shen, Jian Wu, C. Lee Giles</p></summary>
<p>

**Abstract:** We present document domain randomization (DDR), the first successful transfer of convolutional neural networks (CNNs) trained only on graphically rendered pseudo-paper pages to real-world document segmentation. DDR renders pseudo-document pages by modeling randomized textual and non-textual contents of interest, with user-defined layout and font styles to support joint learning of fine-grained classes. We demonstrate competitive results using our DDR approach to extract nine document classes from the benchmark CS-150 and papers published in two domains, namely annual meetings of Association for Computational Linguistics (ACL) and IEEE Visualization (VIS). We compare DDR to conditions of style mismatch, fewer or more noisy samples that are more easily obtained in the real world. We show that high-fidelity semantic information is not necessary to label semantic classes but style mismatch between train and test can lower model accuracy. Using smaller training samples had a slightly detrimental effect. Finally, network models still achieved high test accuracy when correct labels are diluted towards confusing labels; this behavior hold across several classes.

</p>
</details>

<details><summary><b>Robust Unsupervised Multi-Object Tracking in Noisy Environments</b>
<a href="https://arxiv.org/abs/2105.10005">arxiv:2105.10005</a>
&#x1F4C8; 9 <br>
<p>C. -H. Huck Yang, Mohit Chhabra, Y. -C. Liu, Quan Kong, Tomoaki Yoshinaga, Tomokazu Murakami</p></summary>
<p>

**Abstract:** Physical processes, camera movement, and unpredictable environmental conditions like the presence of dust can induce noise and artifacts in video feeds. We observe that popular unsupervised MOT methods are dependent on noise-free inputs. We show that the addition of a small amount of artificial random noise causes a sharp degradation in model performance on benchmark metrics. We resolve this problem by introducing a robust unsupervised multi-object tracking (MOT) model: AttU-Net. The proposed single-head attention model helps limit the negative impact of noise by learning visual representations at different segment scales. AttU-Net shows better unsupervised MOT tracking performance over variational inference-based state-of-the-art baselines. We evaluate our method in the MNIST-MOT and the Atari game video benchmark. We also provide two extended video datasets: ``Kuzushiji-MNIST MOT'' which consists of moving Japanese characters and ``Fashion-MNIST MOT'' to validate the effectiveness of the MOT models.

</p>
</details>

<details><summary><b>Happy Dance, Slow Clap: Using Reaction GIFs to Predict Induced Affect on Twitter</b>
<a href="https://arxiv.org/abs/2105.09967">arxiv:2105.09967</a>
&#x1F4C8; 9 <br>
<p>Boaz Shmueli, Soumya Ray, Lun-Wei Ku</p></summary>
<p>

**Abstract:** Datasets with induced emotion labels are scarce but of utmost importance for many NLP tasks. We present a new, automated method for collecting texts along with their induced reaction labels. The method exploits the online use of reaction GIFs, which capture complex affective states. We show how to augment the data with induced emotion and induced sentiment labels. We use our method to create and publish ReactionGIF, a first-of-its-kind affective dataset of 30K tweets. We provide baselines for three new tasks, including induced sentiment prediction and multilabel classification of induced emotions. Our method and dataset open new research opportunities in emotion detection and affective computing.

</p>
</details>

<details><summary><b>High-Fidelity and Low-Latency Universal Neural Vocoder based on Multiband WaveRNN with Data-Driven Linear Prediction for Discrete Waveform Modeling</b>
<a href="https://arxiv.org/abs/2105.09856">arxiv:2105.09856</a>
&#x1F4C8; 9 <br>
<p>Patrick Lumban Tobing, Tomoki Toda</p></summary>
<p>

**Abstract:** This paper presents a novel high-fidelity and low-latency universal neural vocoder framework based on multiband WaveRNN with data-driven linear prediction for discrete waveform modeling (MWDLP). MWDLP employs a coarse-fine bit WaveRNN architecture for 10-bit mu-law waveform modeling. A sparse gated recurrent unit with a relatively large size of hidden units is utilized, while the multiband modeling is deployed to achieve real-time low-latency usage. A novel technique for data-driven linear prediction (LP) with discrete waveform modeling is proposed, where the LP coefficients are estimated in a data-driven manner. Moreover, a novel loss function using short-time Fourier transform (STFT) for discrete waveform modeling with Gumbel approximation is also proposed. The experimental results demonstrate that the proposed MWDLP framework generates high-fidelity synthetic speech for seen and unseen speakers and/or language on 300 speakers training data including clean and noisy/reverberant conditions, where the number of training utterances is limited to 60 per speaker, while allowing for real-time low-latency processing using a single core of $\sim\!$ 2.1--2.7 GHz CPU with $\sim\!$ 0.57--0.64 real-time factor including input/output and feature extraction.

</p>
</details>

<details><summary><b>Mondegreen: A Post-Processing Solution to Speech Recognition Error Correction for Voice Search Queries</b>
<a href="https://arxiv.org/abs/2105.09930">arxiv:2105.09930</a>
&#x1F4C8; 8 <br>
<p>Sukhdeep S. Sodhi, Ellie Ka-In Chio, Ambarish Jash, Santiago Ontañón, Ajit Apte, Ankit Kumar, Ayooluwakunmi Jeje, Dima Kuzmin, Harry Fung, Heng-Tze Cheng, Jon Effrat, Tarush Bali, Nitin Jindal, Pei Cao, Sarvjeet Singh, Senqiang Zhou, Tameen Khan, Amol Wankhede, Moustafa Alzantot, Allen Wu, Tushar Chandra</p></summary>
<p>

**Abstract:** As more and more online search queries come from voice, automatic speech recognition becomes a key component to deliver relevant search results. Errors introduced by automatic speech recognition (ASR) lead to irrelevant search results returned to the user, thus causing user dissatisfaction. In this paper, we introduce an approach, Mondegreen, to correct voice queries in text space without depending on audio signals, which may not always be available due to system constraints or privacy or bandwidth (for example, some ASR systems run on-device) considerations. We focus on voice queries transcribed via several proprietary commercial ASR systems. These queries come from users making internet, or online service search queries. We first present an analysis showing how different the language distribution coming from user voice queries is from that in traditional text corpora used to train off-the-shelf ASR systems. We then demonstrate that Mondegreen can achieve significant improvements in increased user interaction by correcting user voice queries in one of the largest search systems in Google. Finally, we see Mondegreen as complementing existing highly-optimized production ASR systems, which may not be frequently retrained and thus lag behind due to vocabulary drifts.

</p>
</details>

<details><summary><b>Multi-Perspective Anomaly Detection</b>
<a href="https://arxiv.org/abs/2105.09903">arxiv:2105.09903</a>
&#x1F4C8; 8 <br>
<p>Peter Jakob, Manav Madan, Tobias Schmid-Schirling, Abhinav Valada</p></summary>
<p>

**Abstract:** Anomaly detection is a critical problem in the manufacturing industry. In many applications, images of objects to be analyzed are captured from multiple perspectives which can be exploited to improve the robustness of anomaly detection. In this work, we build upon the deep support vector data description algorithm and address multi-perspective anomaly detection using three different fusion techniques, i.e., early fusion, late fusion, and late fusion with multiple decoders. We employ different augmentation techniques with a denoising process to deal with scarce one-class data, which further improves the performance (ROC AUC $= 80\%$). Furthermore, we introduce the dices dataset, which consists of over 2000 grayscale images of falling dices from multiple perspectives, with 5\% of the images containing rare anomalies (e.g., drill holes, sawing, or scratches). We evaluate our approach on the new dices dataset using images from two different perspectives and also benchmark on the standard MNIST dataset. Extensive experiments demonstrate that our proposed {multi-perspective} approach exceeds the state-of-the-art {single-perspective anomaly detection on both the MNIST and dices datasets}. To the best of our knowledge, this is the first work that focuses on addressing multi-perspective anomaly detection in images by jointly using different perspectives together with one single objective function for anomaly detection.

</p>
</details>

<details><summary><b>DeepAVO: Efficient Pose Refining with Feature Distilling for Deep Visual Odometry</b>
<a href="https://arxiv.org/abs/2105.09899">arxiv:2105.09899</a>
&#x1F4C8; 8 <br>
<p>Ran Zhu, Mingkun Yang, Wang Liu, Rujun Song, Bo Yan, Zhuoling Xiao</p></summary>
<p>

**Abstract:** The technology for Visual Odometry (VO) that estimates the position and orientation of the moving object through analyzing the image sequences captured by on-board cameras, has been well investigated with the rising interest in autonomous driving. This paper studies monocular VO from the perspective of Deep Learning (DL). Unlike most current learning-based methods, our approach, called DeepAVO, is established on the intuition that features contribute discriminately to different motion patterns. Specifically, we present a novel four-branch network to learn the rotation and translation by leveraging Convolutional Neural Networks (CNNs) to focus on different quadrants of optical flow input. To enhance the ability of feature selection, we further introduce an effective channel-spatial attention mechanism to force each branch to explicitly distill related information for specific Frame to Frame (F2F) motion estimation. Experiments on various datasets involving outdoor driving and indoor walking scenarios show that the proposed DeepAVO outperforms the state-of-the-art monocular methods by a large margin, demonstrating competitive performance to the stereo VO algorithm and verifying promising potential for generalization.

</p>
</details>

<details><summary><b>DeepDarts: Modeling Keypoints as Objects for Automatic Scorekeeping in Darts using a Single Camera</b>
<a href="https://arxiv.org/abs/2105.09880">arxiv:2105.09880</a>
&#x1F4C8; 8 <br>
<p>William McNally, Pascale Walters, Kanav Vats, Alexander Wong, John McPhee</p></summary>
<p>

**Abstract:** Existing multi-camera solutions for automatic scorekeeping in steel-tip darts are very expensive and thus inaccessible to most players. Motivated to develop a more accessible low-cost solution, we present a new approach to keypoint detection and apply it to predict dart scores from a single image taken from any camera angle. This problem involves detecting multiple keypoints that may be of the same class and positioned in close proximity to one another. The widely adopted framework for regressing keypoints using heatmaps is not well-suited for this task. To address this issue, we instead propose to model keypoints as objects. We develop a deep convolutional neural network around this idea and use it to predict dart locations and dartboard calibration points within an overall pipeline for automatic dart scoring, which we call DeepDarts. Additionally, we propose several task-specific data augmentation strategies to improve the generalization of our method. As a proof of concept, two datasets comprising 16k images originating from two different dartboard setups were manually collected and annotated to evaluate the system. In the primary dataset containing 15k images captured from a face-on view of the dartboard using a smartphone, DeepDarts predicted the total score correctly in 94.7% of the test images. In a second more challenging dataset containing limited training data (830 images) and various camera angles, we utilize transfer learning and extensive data augmentation to achieve a test accuracy of 84.0%. Because DeepDarts relies only on single images, it has the potential to be deployed on edge devices, giving anyone with a smartphone access to an automatic dart scoring system for steel-tip darts. The code and datasets are available.

</p>
</details>

<details><summary><b>IDEAL: Independent Domain Embedding Augmentation Learning</b>
<a href="https://arxiv.org/abs/2105.10112">arxiv:2105.10112</a>
&#x1F4C8; 7 <br>
<p>Zhiyuan Chen, Guang Yao, Wennan Ma, Lin Xu</p></summary>
<p>

**Abstract:** Many efforts have been devoted to designing sampling, mining, and weighting strategies in high-level deep metric learning (DML) loss objectives. However, little attention has been paid to low-level but essential data transformation. In this paper, we develop a novel mechanism, the independent domain embedding augmentation learning ({IDEAL}) method. It can simultaneously learn multiple independent embedding spaces for multiple domains generated by predefined data transformations. Our IDEAL is orthogonal to existing DML techniques and can be seamlessly combined with prior DML approaches for enhanced performance. Empirical results on visual retrieval tasks demonstrate the superiority of the proposed method. For example, the IDEAL improves the performance of MS loss by a large margin, 84.5\% $\rightarrow$ 87.1\% on Cars-196, and 65.8\% $\rightarrow$ 69.5\% on CUB-200 at Recall$@1$. Our IDEAL with MS loss also achieves the new state-of-the-art performance on three image retrieval benchmarks, \ie, \emph{Cars-196}, \emph{CUB-200}, and \emph{SOP}. It outperforms the most recent DML approaches, such as Circle loss and XBM, significantly. The source code and pre-trained models of our method will be available at\emph{\url{https://github.com/emdata-ailab/IDEAL}}.

</p>
</details>

<details><summary><b>Flexible Compositional Learning of Structured Visual Concepts</b>
<a href="https://arxiv.org/abs/2105.09848">arxiv:2105.09848</a>
&#x1F4C8; 7 <br>
<p>Yanli Zhou, Brenden M. Lake</p></summary>
<p>

**Abstract:** Humans are highly efficient learners, with the ability to grasp the meaning of a new concept from just a few examples. Unlike popular computer vision systems, humans can flexibly leverage the compositional structure of the visual world, understanding new concepts as combinations of existing concepts. In the current paper, we study how people learn different types of visual compositions, using abstract visual forms with rich relational structure. We find that people can make meaningful compositional generalizations from just a few examples in a variety of scenarios, and we develop a Bayesian program induction model that provides a close fit to the behavioral data. Unlike past work examining special cases of compositionality, our work shows how a single computational approach can account for many distinct types of compositional generalization.

</p>
</details>

<details><summary><b>Improved Neuronal Ensemble Inference with Generative Model and MCMC</b>
<a href="https://arxiv.org/abs/2105.09679">arxiv:2105.09679</a>
&#x1F4C8; 7 <br>
<p>Shun Kimura, Keisuke Ota, Koujin Takeda</p></summary>
<p>

**Abstract:** Neuronal ensemble inference is a significant problem in the study of biological neural networks. Various methods have been proposed for ensemble inference from experimental data of neuronal activity. Among them, Bayesian inference approach with generative model was proposed recently. However, this method requires large computational cost for appropriate inference. In this work, we give an improved Bayesian inference algorithm by modifying update rule in Markov chain Monte Carlo method and introducing the idea of simulated annealing for hyperparameter control. We compare the performance of ensemble inference between our algorithm and the original one, and discuss the advantage of our method.

</p>
</details>

<details><summary><b>Unified Dual-view Cognitive Model for Interpretable Claim Verification</b>
<a href="https://arxiv.org/abs/2105.09567">arxiv:2105.09567</a>
&#x1F4C8; 7 <br>
<p>Lianwei Wu, Yuan Rao, Yuqian Lan, Ling Sun, Zhaoyin Qi</p></summary>
<p>

**Abstract:** Recent studies constructing direct interactions between the claim and each single user response (a comment or a relevant article) to capture evidence have shown remarkable success in interpretable claim verification. Owing to different single responses convey different cognition of individual users (i.e., audiences), the captured evidence belongs to the perspective of individual cognition. However, individuals' cognition of social things is not always able to truly reflect the objective. There may be one-sided or biased semantics in their opinions on a claim. The captured evidence correspondingly contains some unobjective and biased evidence fragments, deteriorating task performance. In this paper, we propose a Dual-view model based on the views of Collective and Individual Cognition (CICD) for interpretable claim verification. From the view of the collective cognition, we not only capture the word-level semantics based on individual users, but also focus on sentence-level semantics (i.e., the overall responses) among all users and adjust the proportion between them to generate global evidence. From the view of individual cognition, we select the top-$k$ articles with high degree of difference and interact with the claim to explore the local key evidence fragments. To weaken the bias of individual cognition-view evidence, we devise inconsistent loss to suppress the divergence between global and local evidence for strengthening the consistent shared evidence between the both. Experiments on three benchmark datasets confirm that CICD achieves state-of-the-art performance.

</p>
</details>

<details><summary><b>Dual-side Sparse Tensor Core</b>
<a href="https://arxiv.org/abs/2105.09564">arxiv:2105.09564</a>
&#x1F4C8; 7 <br>
<p>Yang Wang, Chen Zhang, Zhiqiang Xie, Cong Guo, Yunxin Liu, Jingwen Leng</p></summary>
<p>

**Abstract:** Leveraging sparsity in deep neural network (DNN) models is promising for accelerating model inference. Yet existing GPUs can only leverage the sparsity from weights but not activations, which are dynamic, unpredictable, and hence challenging to exploit. In this work, we propose a novel architecture to efficiently harness the dual-side sparsity (i.e., weight and activation sparsity). We take a systematic approach to understand the (dis)advantages of previous sparsity-related architectures and propose a novel, unexplored paradigm that combines outer-product computation primitive and bitmap-based encoding format. We demonstrate the feasibility of our design with minimal changes to the existing production-scale inner-product-based Tensor Core. We propose a set of novel ISA extensions and co-design the matrix-matrix multiplication and convolution algorithms, which are the two dominant computation patterns in today's DNN models, to exploit our new dual-side sparse Tensor Core. Our evaluation shows that our design can fully unleash the dual-side DNN sparsity and improve the performance by up to one order of magnitude with \hl{small} hardware overhead.

</p>
</details>

<details><summary><b>Probabilistic Sufficient Explanations</b>
<a href="https://arxiv.org/abs/2105.10118">arxiv:2105.10118</a>
&#x1F4C8; 6 <br>
<p>Eric Wang, Pasha Khosravi, Guy Van den Broeck</p></summary>
<p>

**Abstract:** Understanding the behavior of learned classifiers is an important task, and various black-box explanations, logical reasoning approaches, and model-specific methods have been proposed. In this paper, we introduce probabilistic sufficient explanations, which formulate explaining an instance of classification as choosing the "simplest" subset of features such that only observing those features is "sufficient" to explain the classification. That is, sufficient to give us strong probabilistic guarantees that the model will behave similarly when all features are observed under the data distribution. In addition, we leverage tractable probabilistic reasoning tools such as probabilistic circuits and expected predictions to design a scalable algorithm for finding the desired explanations while keeping the guarantees intact. Our experiments demonstrate the effectiveness of our algorithm in finding sufficient explanations, and showcase its advantages compared to Anchors and logical explanations.

</p>
</details>

<details><summary><b>EMface: Detecting Hard Faces by Exploring Receptive Field Pyraminds</b>
<a href="https://arxiv.org/abs/2105.10104">arxiv:2105.10104</a>
&#x1F4C8; 6 <br>
<p>Leilei Cao, Yao Xiao, Lin Xu</p></summary>
<p>

**Abstract:** Scale variation is one of the most challenging problems in face detection. Modern face detectors employ feature pyramids to deal with scale variation. However, it might break the feature consistency across different scales of faces. In this paper, we propose a simple yet effective method named the receptive field pyramids (RFP) method to enhance the representation ability of feature pyramids. It can learn different receptive fields in each feature map adaptively based on the varying scales of detected faces. Empirical results on two face detection benchmark datasets, i.e., WIDER FACE and UFDD, demonstrate that our proposed method can accelerate the inference rate significantly while achieving state-of-the-art performance. The source code of our method is available at \url{https://github.com/emdata-ailab/EMface}.

</p>
</details>

<details><summary><b>Monte Carlo Filtering Objectives: A New Family of Variational Objectives to Learn Generative Model and Neural Adaptive Proposal for Time Series</b>
<a href="https://arxiv.org/abs/2105.09801">arxiv:2105.09801</a>
&#x1F4C8; 6 <br>
<p>Shuangshuang Chen, Sihao Ding, Yiannis Karayiannidis, Mårten Björkman</p></summary>
<p>

**Abstract:** Learning generative models and inferring latent trajectories have shown to be challenging for time series due to the intractable marginal likelihoods of flexible generative models. It can be addressed by surrogate objectives for optimization. We propose Monte Carlo filtering objectives (MCFOs), a family of variational objectives for jointly learning parametric generative models and amortized adaptive importance proposals of time series. MCFOs extend the choices of likelihood estimators beyond Sequential Monte Carlo in state-of-the-art objectives, possess important properties revealing the factors for the tightness of objectives, and allow for less biased and variant gradient estimates. We demonstrate that the proposed MCFOs and gradient estimations lead to efficient and stable model learning, and learned generative models well explain data and importance proposals are more sample efficient on various kinds of time series data.

</p>
</details>

<details><summary><b>A Spatio-temporal Attention-based Model for Infant Movement Assessment from Videos</b>
<a href="https://arxiv.org/abs/2105.09783">arxiv:2105.09783</a>
&#x1F4C8; 6 <br>
<p>Binh Nguyen-Thai, Vuong Le, Catherine Morgan, Nadia Badawi, Truyen Tran, Svetha Venkatesh</p></summary>
<p>

**Abstract:** The absence or abnormality of fidgety movements of joints or limbs is strongly indicative of cerebral palsy in infants. Developing computer-based methods for assessing infant movements in videos is pivotal for improved cerebral palsy screening. Most existing methods use appearance-based features and are thus sensitive to strong but irrelevant signals caused by background clutter or a moving camera. Moreover, these features are computed over the whole frame, thus they measure gross whole body movements rather than specific joint/limb motion.
  Addressing these challenges, we develop and validate a new method for fidgety movement assessment from consumer-grade videos using human poses extracted from short clips. Human poses capture only relevant motion profiles of joints and limbs and are thus free from irrelevant appearance artifacts. The dynamics and coordination between joints are modeled using spatio-temporal graph convolutional networks. Frames and body parts that contain discriminative information about fidgety movements are selected through a spatio-temporal attention mechanism. We validate the proposed model on the cerebral palsy screening task using a real-life consumer-grade video dataset collected at an Australian hospital through the Cerebral Palsy Alliance, Australia. Our experiments show that the proposed method achieves the ROC-AUC score of 81.87%, significantly outperforming existing competing methods with better interpretability.

</p>
</details>

<details><summary><b>On the Parameterized Complexity of Polytree Learning</b>
<a href="https://arxiv.org/abs/2105.09675">arxiv:2105.09675</a>
&#x1F4C8; 6 <br>
<p>Niels Grüttemeier, Christian Komusiewicz, Nils Morawietz</p></summary>
<p>

**Abstract:** A Bayesian network is a directed acyclic graph that represents statistical dependencies between variables of a joint probability distribution. A fundamental task in data science is to learn a Bayesian network from observed data. \textsc{Polytree Learning} is the problem of learning an optimal Bayesian network that fulfills the additional property that its underlying undirected graph is a forest. In this work, we revisit the complexity of \textsc{Polytree Learning}. We show that \textsc{Polytree Learning} can be solved in $3^n \cdot |I|^{\mathcal{O}(1)}$ time where $n$ is the number of variables and $|I|$ is the total instance size. Moreover, we consider the influence of the number of variables $d$ that might receive a nonempty parent set in the final DAG on the complexity of \textsc{Polytree Learning}. We show that \textsc{Polytree Learning} has no $f(d)\cdot |I|^{\mathcal{O}(1)}$-time algorithm, unlike Bayesian network learning which can be solved in $2^d \cdot |I|^{\mathcal{O}(1)}$ time. We show that, in contrast, if $d$ and the maximum parent set size are bounded, then we can obtain efficient algorithms.

</p>
</details>

<details><summary><b>Negational Symmetry of Quantum Neural Networks for Binary Pattern Classification</b>
<a href="https://arxiv.org/abs/2105.09580">arxiv:2105.09580</a>
&#x1F4C8; 6 <br>
<p>Nanqing Dong, Michael Kampffmeyer, Irina Voiculescu, Eric Xing</p></summary>
<p>

**Abstract:** Entanglement is a physical phenomenon, which has fueled recent successes of quantum algorithms. Although quantum neural networks (QNNs) have shown promising results in solving simple machine learning tasks recently, for the time being, the effect of entanglement in QNNs and the behavior of QNNs in binary pattern classification are still underexplored. In this work, we provide some theoretical insight into the properties of QNNs by presenting and analyzing a new form of invariance embedded in QNNs for both quantum binary classification and quantum representation learning, which we term negational symmetry. Given a quantum binary signal and its negational counterpart where a bitwise NOT operation is applied to each quantum bit of the binary signal, a QNN outputs the same logits. That is to say, QNNs cannot differentiate a quantum binary signal and its negational counterpart in a binary classification task. We further empirically evaluate the negational symmetry of QNNs in binary pattern classification tasks using Google's quantum computing framework. The theoretical and experimental results suggest that negational symmetry is a fundamental property of QNNs, which is not shared by classical models. Our findings also imply that negational symmetry is a double-edged sword in practical quantum applications.

</p>
</details>

<details><summary><b>Neural networks with superexpressive activations and integer weights</b>
<a href="https://arxiv.org/abs/2105.09917">arxiv:2105.09917</a>
&#x1F4C8; 5 <br>
<p>Aleksandr Beknazaryan</p></summary>
<p>

**Abstract:** An example of an activation function $σ$ is given such that networks with activations $\{σ, \lfloor\cdot\rfloor\}$, integer weights and a fixed architecture depending on $d$ approximate continuous functions on $[0,1]^d$. The range of integer weights required for $\varepsilon$-approximation of Hölder continuous functions is derived, which leads to a convergence rate of order $n^{\frac{-2β}{2β+d}}\log_2n$ for neural network regression estimation of unknown $β$-Hölder continuous function with given $n$ samples.

</p>
</details>

<details><summary><b>Semi-supervised, Topology-Aware Segmentation of Tubular Structures from Live Imaging 3D Microscopy</b>
<a href="https://arxiv.org/abs/2105.09737">arxiv:2105.09737</a>
&#x1F4C8; 5 <br>
<p>Kasra Arnavaz, Oswin Krause, Jelena M. Krivokapic, Silja Heilmann, Jakob Andreas Bærentzen, Pia Nyeng, Aasa Feragen</p></summary>
<p>

**Abstract:** Motivated by a challenging tubular network segmentation task, this paper tackles two commonly encountered problems in biomedical imaging: Topological consistency of the segmentation, and limited annotations. We propose a topological score which measures both topological and geometric consistency between the predicted and ground truth segmentations, applied for model selection and validation. We apply our topological score in three scenarios: i. a U-net ii. a U-net pretrained on an autoencoder, and iii. a semisupervised U-net architecture, which offers a straightforward approach to jointly training the network both as an autoencoder and a segmentation algorithm. This allows us to utilize un-annotated data for training a representation that generalizes across test data variability, in spite of our annotated training data having very limited variation. Our contributions are validated on a challenging segmentation task, locating tubular structures in the fetal pancreas from noisy live imaging confocal microscopy.

</p>
</details>

<details><summary><b>Semantic segmentation of multispectral photoacoustic images using deep learning</b>
<a href="https://arxiv.org/abs/2105.09624">arxiv:2105.09624</a>
&#x1F4C8; 5 <br>
<p>Janek Gröhl, Melanie Schellenberg, Kris Dreher, Niklas Holzwarth, Minu D. Tizabi, Alexander Seitel, Lena Maier-Hein</p></summary>
<p>

**Abstract:** Photoacoustic imaging has the potential to revolutionise healthcare due to the valuable information on tissue physiology that is contained in multispectral photoacoustic measurements. Clinical translation of the technology requires conversion of the high-dimensional acquired data into clinically relevant and interpretable information. In this work, we present a deep learning-based approach to semantic segmentation of multispectral photoacoustic images to facilitate the interpretability of recorded images. Manually annotated multispectral photoacoustic imaging data are used as gold standard reference annotations and enable the training of a deep learning-based segmentation algorithm in a supervised manner. Based on a validation study with experimentally acquired data of healthy human volunteers, we show that automatic tissue segmentation can be used to create powerful analyses and visualisations of multispectral photoacoustic images. Due to the intuitive representation of high-dimensional information, such a processing algorithm could be a valuable means to facilitate the clinical translation of photoacoustic imaging.

</p>
</details>

<details><summary><b>Dynaboard: An Evaluation-As-A-Service Platform for Holistic Next-Generation Benchmarking</b>
<a href="https://arxiv.org/abs/2106.06052">arxiv:2106.06052</a>
&#x1F4C8; 4 <br>
<p>Zhiyi Ma, Kawin Ethayarajh, Tristan Thrush, Somya Jain, Ledell Wu, Robin Jia, Christopher Potts, Adina Williams, Douwe Kiela</p></summary>
<p>

**Abstract:** We introduce Dynaboard, an evaluation-as-a-service framework for hosting benchmarks and conducting holistic model comparison, integrated with the Dynabench platform. Our platform evaluates NLP models directly instead of relying on self-reported metrics or predictions on a single dataset. Under this paradigm, models are submitted to be evaluated in the cloud, circumventing the issues of reproducibility, accessibility, and backwards compatibility that often hinder benchmarking in NLP. This allows users to interact with uploaded models in real time to assess their quality, and permits the collection of additional metrics such as memory use, throughput, and robustness, which -- despite their importance to practitioners -- have traditionally been absent from leaderboards. On each task, models are ranked according to the Dynascore, a novel utility-based aggregation of these statistics, which users can customize to better reflect their preferences, placing more/less weight on a particular axis of evaluation or dataset. As state-of-the-art NLP models push the limits of traditional benchmarks, Dynaboard offers a standardized solution for a more diverse and comprehensive evaluation of model quality.

</p>
</details>

<details><summary><b>Generation of COVID-19 Chest CT Scan Images using Generative Adversarial Networks</b>
<a href="https://arxiv.org/abs/2105.11241">arxiv:2105.11241</a>
&#x1F4C8; 4 <br>
<p>Prerak Mann, Sahaj Jain, Saurabh Mittal, Aruna Bhat</p></summary>
<p>

**Abstract:** SARS-CoV-2, also known as COVID-19 or Coronavirus, is a viral contagious disease that is infected by a novel coronavirus, and has been rapidly spreading across the globe. It is very important to test and isolate people to reduce spread, and from here comes the need to do this quickly and efficiently. According to some studies, Chest-CT outperforms RT-PCR lab testing, which is the current standard, when diagnosing COVID-19 patients. Due to this, computer vision researchers have developed various deep learning systems that can predict COVID-19 using a Chest-CT scan correctly to a certain degree. The accuracy of these systems is limited since deep learning neural networks such as CNNs (Convolutional Neural Networks) need a significantly large quantity of data for training in order to produce good quality results. Since the disease is relatively recent and more focus has been on CXR (Chest XRay) images, the available chest CT Scan image dataset is much less. We propose a method, by utilizing GANs, to generate synthetic chest CT images of both positive and negative COVID-19 patients. Using a pre-built predictive model, we concluded that around 40% of the generated images are correctly predicted as COVID-19 positive. The dataset thus generated can be used to train a CNN-based classifier which can help determine COVID-19 in a patient with greater accuracy.

</p>
</details>

<details><summary><b>Evaluating Robustness over High Level Driving Instruction for Autonomous Driving</b>
<a href="https://arxiv.org/abs/2105.10014">arxiv:2105.10014</a>
&#x1F4C8; 4 <br>
<p>Florence Carton, David Filliat, Jaonary Rabarisoa, Quoc Cuong Pham</p></summary>
<p>

**Abstract:** In recent years, we have witnessed increasingly high performance in the field of autonomous end-to-end driving. In particular, more and more research is being done on driving in urban environments, where the car has to follow high level commands to navigate. However, few evaluations are made on the ability of these agents to react in an unexpected situation. Specifically, no evaluations are conducted on the robustness of driving agents in the event of a bad high-level command. We propose here an evaluation method, namely a benchmark that allows to assess the robustness of an agent, and to appreciate its understanding of the environment through its ability to keep a safe behavior, regardless of the instruction.

</p>
</details>

<details><summary><b>Measuring Model Fairness under Noisy Covariates: A Theoretical Perspective</b>
<a href="https://arxiv.org/abs/2105.09985">arxiv:2105.09985</a>
&#x1F4C8; 4 <br>
<p>Flavien Prost, Pranjal Awasthi, Nick Blumm, Aditee Kumthekar, Trevor Potter, Li Wei, Xuezhi Wang, Ed H. Chi, Jilin Chen, Alex Beutel</p></summary>
<p>

**Abstract:** In this work we study the problem of measuring the fairness of a machine learning model under noisy information. Focusing on group fairness metrics, we investigate the particular but common situation when the evaluation requires controlling for the confounding effect of covariate variables. In a practical setting, we might not be able to jointly observe the covariate and group information, and a standard workaround is to then use proxies for one or more of these variables. Prior works have demonstrated the challenges with using a proxy for sensitive attributes, and strong independence assumptions are needed to provide guarantees on the accuracy of the noisy estimates. In contrast, in this work we study using a proxy for the covariate variable and present a theoretical analysis that aims to characterize weaker conditions under which accurate fairness evaluation is possible.
  Furthermore, our theory identifies potential sources of errors and decouples them into two interpretable parts $γ$ and $ε$. The first part $γ$ depends solely on the performance of the proxy such as precision and recall, whereas the second part $ε$ captures correlations between all the variables of interest. We show that in many scenarios the error in the estimates is dominated by $γ$ via a linear dependence, whereas the dependence on the correlations $ε$ only constitutes a lower order term. As a result we expand the understanding of scenarios where measuring model fairness via proxies can be an effective approach. Finally, we compare, via simulations, the theoretical upper-bounds to the distribution of simulated estimation errors and show that assuming some structure on the data, even weak, is key to significantly improve both theoretical guarantees and empirical results.

</p>
</details>

<details><summary><b>Pseudo Pixel-level Labeling for Images with Evolving Content</b>
<a href="https://arxiv.org/abs/2105.09975">arxiv:2105.09975</a>
&#x1F4C8; 4 <br>
<p>Sara Mousavi, Zhenning Yang, Kelley Cross, Dawnie Steadman, Audris Mockus</p></summary>
<p>

**Abstract:** Annotating images for semantic segmentation requires intense manual labor and is a time-consuming and expensive task especially for domains with a scarcity of experts, such as Forensic Anthropology. We leverage the evolving nature of images depicting the decay process in human decomposition data to design a simple yet effective pseudo-pixel-level label generation technique to reduce the amount of effort for manual annotation of such images. We first identify sequences of images with a minimum variation that are most suitable to share the same or similar annotation using an unsupervised approach. Given one user-annotated image in each sequence, we propagate the annotation to the remaining images in the sequence by merging it with annotations produced by a state-of-the-art CAM-based pseudo label generation technique. To evaluate the quality of our pseudo-pixel-level labels, we train two semantic segmentation models with VGG and ResNet backbones on images labeled using our pseudo labeling method and those of a state-of-the-art method. The results indicate that using our pseudo-labels instead of those generated using the state-of-the-art method in the training process improves the mean-IoU and the frequency-weighted-IoU of the VGG and ResNet-based semantic segmentation models by 3.36%, 2.58%, 10.39%, and 12.91% respectively.

</p>
</details>

<details><summary><b>EiGLasso for Scalable Sparse Kronecker-Sum Inverse Covariance Estimation</b>
<a href="https://arxiv.org/abs/2105.09872">arxiv:2105.09872</a>
&#x1F4C8; 4 <br>
<p>Jun Ho Yoon, Seyoung Kim</p></summary>
<p>

**Abstract:** In many real-world problems, complex dependencies are present both among samples and among features. The Kronecker sum or the Cartesian product of two graphs, each modeling dependencies across features and across samples, has been used as an inverse covariance matrix for a matrix-variate Gaussian distribution, as an alternative to a Kronecker-product inverse covariance matrix, due to its more intuitive sparse structure. However, the existing methods for sparse Kronecker-sum inverse covariance estimation are limited in that they do not scale to more than a few hundred features and samples and that the unidentifiable parameters pose challenges in estimation. In this paper, we introduce EiGLasso, a highly scalable method for sparse Kronecker-sum inverse covariance estimation, based on Newton's method combined with eigendecomposition of the two graphs for exploiting the structure of Kronecker sum. EiGLasso further reduces computation time by approximating the Hessian based on the eigendecomposition of the sample and feature graphs. EiGLasso achieves quadratic convergence with the exact Hessian and linear convergence with the approximate Hessian. We describe a simple new approach to estimating the unidentifiable parameters that generalizes the existing methods. On simulated and real-world data, we demonstrate that EiGLasso achieves two to three orders-of-magnitude speed-up compared to the existing methods.

</p>
</details>

<details><summary><b>Multiple Support Recovery Using Very Few Measurements Per Sample</b>
<a href="https://arxiv.org/abs/2105.09855">arxiv:2105.09855</a>
&#x1F4C8; 4 <br>
<p>Lekshmi Ramesh, Chandra R. Murthy, Himanshu Tyagi</p></summary>
<p>

**Abstract:** In the problem of multiple support recovery, we are given access to linear measurements of multiple sparse samples in $\mathbb{R}^{d}$. These samples can be partitioned into $\ell$ groups, with samples having the same support belonging to the same group. For a given budget of $m$ measurements per sample, the goal is to recover the $\ell$ underlying supports, in the absence of the knowledge of group labels. We study this problem with a focus on the measurement-constrained regime where $m$ is smaller than the support size $k$ of each sample. We design a two-step procedure that estimates the union of the underlying supports first, and then uses a spectral algorithm to estimate the individual supports. Our proposed estimator can recover the supports with $m<k$ measurements per sample, from $\tilde{O}(k^{4}\ell^{4}/m^{4})$ samples. Our guarantees hold for a general, generative model assumption on the samples and measurement matrices. We also provide results from experiments conducted on synthetic data and on the MNIST dataset.

</p>
</details>

<details><summary><b>Personalized Counterfactual Fairness in Recommendation</b>
<a href="https://arxiv.org/abs/2105.09829">arxiv:2105.09829</a>
&#x1F4C8; 4 <br>
<p>Yunqi Li, Hanxiong Chen, Shuyuan Xu, Yingqiang Ge, Yongfeng Zhang</p></summary>
<p>

**Abstract:** Recommender systems are gaining increasing and critical impacts on human and society since a growing number of users use them for information seeking and decision making. Therefore, it is crucial to address the potential unfairness problems in recommendations. Just like users have personalized preferences on items, users' demands for fairness are also personalized in many scenarios. Therefore, it is important to provide personalized fair recommendations for users to satisfy their personalized fairness demands. Besides, previous works on fair recommendation mainly focus on association-based fairness. However, it is important to advance from associative fairness notions to causal fairness notions for assessing fairness more properly in recommender systems. Based on the above considerations, this paper focuses on achieving personalized counterfactual fairness for users in recommender systems. To this end, we introduce a framework for achieving counterfactually fair recommendations through adversary learning by generating feature-independent user embeddings for recommendation. The framework allows recommender systems to achieve personalized fairness for users while also covering non-personalized situations. Experiments on two real-world datasets with shallow and deep recommendation algorithms show that our method can generate fairer recommendations for users with a desirable recommendation performance.

</p>
</details>

<details><summary><b>Distributed Adaptive Nearest Neighbor Classifier: Algorithm and Theory</b>
<a href="https://arxiv.org/abs/2105.09788">arxiv:2105.09788</a>
&#x1F4C8; 4 <br>
<p>Ruiqi Liu, Ganggang Xu, Zuofeng Shang</p></summary>
<p>

**Abstract:** When data is of an extraordinarily large size or physically stored in different locations, the distributed nearest neighbor (NN) classifier is an attractive tool for classification. We propose a novel distributed adaptive NN classifier for which the number of nearest neighbors is a tuning parameter stochastically chosen by a data-driven criterion. An early stopping rule is proposed when searching for the optimal tuning parameter, which not only speeds up the computation but also improves the finite sample performance of the proposed Algorithm. Convergence rate of excess risk of the distributed adaptive NN classifier is investigated under various sub-sample size compositions. In particular, we show that when the sub-sample sizes are sufficiently large, the proposed classifier achieves the nearly optimal convergence rate. Effectiveness of the proposed approach is demonstrated through simulation studies as well as an empirical application to a real-world dataset.

</p>
</details>

<details><summary><b>Covid-19 Detection from Chest X-ray and Patient Metadata using Graph Convolutional Neural Networks</b>
<a href="https://arxiv.org/abs/2105.09720">arxiv:2105.09720</a>
&#x1F4C8; 4 <br>
<p>Thosini Bamunu Mudiyanselage, Nipuna Senanayake, Chunyan Ji, Yi Pan, Yanqing Zhang</p></summary>
<p>

**Abstract:** The novel corona virus (Covid-19) has introduced significant challenges due to its rapid spreading nature through respiratory transmission. As a result, there is a huge demand for Artificial Intelligence (AI) based quick disease diagnosis methods as an alternative to high demand tests such as Polymerase Chain Reaction (PCR). Chest X-ray (CXR) Image analysis is such cost-effective radiography technique due to resource availability and quick screening. But, a sufficient and systematic data collection that is required by complex deep leaning (DL) models is more difficult and hence there are recent efforts that utilize transfer learning to address this issue. Still these transfer learnt models suffer from lack of generalization and increased bias to the training dataset resulting poor performance for unseen data. Limited correlation of the transferred features from the pre-trained model to a specific medical imaging domain like X-ray and overfitting on fewer data can be reasons for this circumstance. In this work, we propose a novel Graph Convolution Neural Network (GCN) that is capable of identifying bio-markers of Covid-19 pneumonia from CXR images and meta information about patients. The proposed method exploits important relational knowledge between data instances and their features using graph representation and applies convolution to learn the graph data which is not possible with conventional convolution on Euclidean domain. The results of extensive experiments of proposed model on binary (Covid vs normal) and three class (Covid, normal, other pneumonia) classification problems outperform different benchmark transfer learnt models, hence overcoming the aforementioned drawbacks.

</p>
</details>

<details><summary><b>A Stochastic Composite Augmented Lagrangian Method For Reinforcement Learning</b>
<a href="https://arxiv.org/abs/2105.09716">arxiv:2105.09716</a>
&#x1F4C8; 4 <br>
<p>Yongfeng Li, Mingming Zhao, Weijie Chen, Zaiwen Wen</p></summary>
<p>

**Abstract:** In this paper, we consider the linear programming (LP) formulation for deep reinforcement learning. The number of the constraints depends on the size of state and action spaces, which makes the problem intractable in large or continuous environments. The general augmented Lagrangian method suffers the double-sampling obstacle in solving the LP. Namely, the conditional expectations originated from the constraint functions and the quadratic penalties in the augmented Lagrangian function impose difficulties in sampling and evaluation. Motivated from the updates of the multipliers, we overcome the obstacles in minimizing the augmented Lagrangian function by replacing the intractable conditional expectations with the multipliers. Therefore, a deep parameterized augment Lagrangian method is proposed. Furthermore, the replacement provides a promising breakthrough to integrate the two steps in the augmented Lagrangian method into a single constrained problem. A general theoretical analysis shows that the solutions generated from a sequence of the constrained optimizations converge to the optimal solution of the LP if the error is controlled properly. A theoretical analysis on the quadratic penalty algorithm under neural tangent kernel setting shows the residual can be arbitrarily small if the parameter in network and optimization algorithm is chosen suitably. Preliminary experiments illustrate that our method is competitive to other state-of-the-art algorithms.

</p>
</details>

<details><summary><b>Simple Transparent Adversarial Examples</b>
<a href="https://arxiv.org/abs/2105.09685">arxiv:2105.09685</a>
&#x1F4C8; 4 <br>
<p>Jaydeep Borkar, Pin-Yu Chen</p></summary>
<p>

**Abstract:** There has been a rise in the use of Machine Learning as a Service (MLaaS) Vision APIs as they offer multiple services including pre-built models and algorithms, which otherwise take a huge amount of resources if built from scratch. As these APIs get deployed for high-stakes applications, it's very important that they are robust to different manipulations. Recent works have only focused on typical adversarial attacks when evaluating the robustness of vision APIs. We propose two new aspects of adversarial image generation methods and evaluate them on the robustness of Google Cloud Vision API's optical character recognition service and object detection APIs deployed in real-world settings such as sightengine.com, picpurify.com, Google Cloud Vision API, and Microsoft Azure's Computer Vision API. Specifically, we go beyond the conventional small-noise adversarial attacks and introduce secret embedding and transparent adversarial examples as a simpler way to evaluate robustness. These methods are so straightforward that even non-specialists can craft such attacks. As a result, they pose a serious threat where APIs are used for high-stakes applications. Our transparent adversarial examples successfully evade state-of-the art object detections APIs such as Azure Cloud Vision (attack success rate 52%) and Google Cloud Vision (attack success rate 36%). 90% of the images have a secret embedded text that successfully fools the vision of time-limited humans but is detected by Google Cloud Vision API's optical character recognition. Complementing to current research, our results provide simple but unconventional methods on robustness evaluation.

</p>
</details>

<details><summary><b>Nonlinear Hawkes Process with Gaussian Process Self Effects</b>
<a href="https://arxiv.org/abs/2105.09618">arxiv:2105.09618</a>
&#x1F4C8; 4 <br>
<p>Noa Malem-Shinitski, Cesar Ojeda, Manfred Opper</p></summary>
<p>

**Abstract:** Traditionally, Hawkes processes are used to model time--continuous point processes with history dependence. Here we propose an extended model where the self--effects are of both excitatory and inhibitory type and follow a Gaussian Process. Whereas previous work either relies on a less flexible parameterization of the model, or requires a large amount of data, our formulation allows for both a flexible model and learning when data are scarce. We continue the line of work of Bayesian inference for Hawkes processes, and our approach dispenses with the necessity of estimating a branching structure for the posterior, as we perform inference on an aggregated sum of Gaussian Processes. Efficient approximate Bayesian inference is achieved via data augmentation, and we describe a mean--field variational inference approach to learn the model parameters. To demonstrate the flexibility of the model we apply our methodology on data from three different domains and compare it to previously reported results.

</p>
</details>

<details><summary><b>Error Resilient Collaborative Intelligence via Low-Rank Tensor Completion</b>
<a href="https://arxiv.org/abs/2105.10341">arxiv:2105.10341</a>
&#x1F4C8; 3 <br>
<p>Lior Bragilevsky, Ivan V. Bajić</p></summary>
<p>

**Abstract:** In the race to bring Artificial Intelligence (AI) to the edge, collaborative intelligence has emerged as a promising way to lighten the computation load on edge devices that run applications based on Deep Neural Networks (DNNs). Typically, a deep model is split at a certain layer into edge and cloud sub-models. The deep feature tensor produced by the edge sub-model is transmitted to the cloud, where the remaining computationally intensive workload is performed by the cloud sub-model. The communication channel between the edge and cloud is imperfect, which will result in missing data in the deep feature tensor received at the cloud side. In this study, we examine the effectiveness of four low-rank tensor completion methods in recovering missing data in the deep feature tensor. We consider both sparse tensors, such as those produced by the VGG16 model, as well as non-sparse tensors, such as those produced by ResNet34 model. We study tensor completion effectiveness in both conplexity-constrained and unconstrained scenario.

</p>
</details>

<details><summary><b>A Rule Mining-Based Advanced Persistent Threats Detection System</b>
<a href="https://arxiv.org/abs/2105.10053">arxiv:2105.10053</a>
&#x1F4C8; 3 <br>
<p>Sidahmed Benabderrahmane, Ghita Berrada, James Cheney, Petko Valtchev</p></summary>
<p>

**Abstract:** Advanced persistent threats (APT) are stealthy cyber-attacks that are aimed at stealing valuable information from target organizations and tend to extend in time. Blocking all APTs is impossible, security experts caution, hence the importance of research on early detection and damage limitation. Whole-system provenance-tracking and provenance trace mining are considered promising as they can help find causal relationships between activities and flag suspicious event sequences as they occur. We introduce an unsupervised method that exploits OS-independent features reflecting process activity to detect realistic APT-like attacks from provenance traces. Anomalous processes are ranked using both frequent and rare event associations learned from traces. Results are then presented as implications which, since interpretable, help leverage causality in explaining the detected anomalies. When evaluated on Transparent Computing program datasets (DARPA), our method outperformed competing approaches.

</p>
</details>

<details><summary><b>Learning Modular Robot Control Policies</b>
<a href="https://arxiv.org/abs/2105.10049">arxiv:2105.10049</a>
&#x1F4C8; 3 <br>
<p>Julian Whitman, Matthew Travers, Howie Choset</p></summary>
<p>

**Abstract:** Modular robots can be rearranged into a new design, perhaps each day, to handle a wide variety of tasks by forming a customized robot for each new task. However, reconfiguring just the mechanism is not sufficient: each design also requires its own unique control policy. One could craft a policy from scratch for each new design, but such an approach is not scalable, especially given the large number of designs that can be generated from even a small set of modules. Instead, we create a modular policy framework where the policy structure is conditioned on the hardware arrangement, and use just one training process to create a policy that controls a wide variety of designs. Our approach leverages the fact that the kinematics of a modular robot can be represented as a design graph, with nodes as modules and edges as connections between them. Given a robot, its design graph is used to create a policy graph with the same structure, where each node contains a deep neural network, and modules of the same type share knowledge via shared parameters (e.g., all legs on a hexapod share the same network parameters). We developed a model-based reinforcement learning algorithm, interleaving model learning and trajectory optimization to train the policy. We show the modular policy generalizes to a large number of designs that were not seen during training without any additional learning. Finally, we demonstrate the policy controlling a variety of designs to locomote with both simulated and real robots.

</p>
</details>

<details><summary><b>Enhancing Cross-Sectional Currency Strategies by Ranking Refinement with Transformer-based Architectures</b>
<a href="https://arxiv.org/abs/2105.10019">arxiv:2105.10019</a>
&#x1F4C8; 3 <br>
<p>Daniel Poh, Bryan Lim, Stefan Zohren, Stephen Roberts</p></summary>
<p>

**Abstract:** The performance of a cross-sectional currency strategy depends crucially on accurately ranking instruments prior to portfolio construction. While this ranking step is traditionally performed using heuristics, or by sorting outputs produced by pointwise regression or classification models, Learning to Rank algorithms have recently presented themselves as competitive and viable alternatives. Despite improving ranking accuracy on average however, these techniques do not account for the possibility that assets positioned at the extreme ends of the ranked list -- which are ultimately used to construct the long/short portfolios -- can assume different distributions in the input space, and thus lead to sub-optimal strategy performance. Drawing from research in Information Retrieval that demonstrates the utility of contextual information embedded within top-ranked documents to learn the query's characteristics to improve ranking, we propose an analogous approach: exploiting the features of both out- and under-performing instruments to learn a model for refining the original ranked list. Under a re-ranking framework, we adapt the Transformer architecture to encode the features of extreme assets for refining our selection of long/short instruments obtained with an initial retrieval. Backtesting on a set of 31 currencies, our proposed methodology significantly boosts Sharpe ratios -- by approximately 20% over the original LTR algorithms and double that of traditional baselines.

</p>
</details>

<details><summary><b>AnaXNet: Anatomy Aware Multi-label Finding Classification in Chest X-ray</b>
<a href="https://arxiv.org/abs/2105.09937">arxiv:2105.09937</a>
&#x1F4C8; 3 <br>
<p>Nkechinyere N. Agu, Joy T. Wu, Hanqing Chao, Ismini Lourentzou, Arjun Sharma, Mehdi Moradi, Pingkun Yan, James Hendler</p></summary>
<p>

**Abstract:** Radiologists usually observe anatomical regions of chest X-ray images as well as the overall image before making a decision. However, most existing deep learning models only look at the entire X-ray image for classification, failing to utilize important anatomical information. In this paper, we propose a novel multi-label chest X-ray classification model that accurately classifies the image finding and also localizes the findings to their correct anatomical regions. Specifically, our model consists of two modules, the detection module and the anatomical dependency module. The latter utilizes graph convolutional networks, which enable our model to learn not only the label dependency but also the relationship between the anatomical regions in the chest X-ray. We further utilize a method to efficiently create an adjacency matrix for the anatomical regions using the correlation of the label across the different regions. Detailed experiments and analysis of our results show the effectiveness of our method when compared to the current state-of-the-art multi-label chest X-ray image classification methods while also providing accurate location information.

</p>
</details>

<details><summary><b>Probing the Effect of Selection Bias on NN Generalization with a Thought Experiment</b>
<a href="https://arxiv.org/abs/2105.09934">arxiv:2105.09934</a>
&#x1F4C8; 3 <br>
<p>John K. Tsotsos, Jun Luo</p></summary>
<p>

**Abstract:** Learned networks in the domain of visual recognition and cognition impress in part because even though they are trained with datasets many orders of magnitude smaller than the full population of possible images, they exhibit sufficient generalization to be applicable to new and previously unseen data. Although many have examined issues regarding generalization from several perspectives, we wondered If a network is trained with a biased dataset that misses particular samples corresponding to some defining domain attribute, can it generalize to the full domain from which that training dataset was extracted? It is certainly true that in vision, no current training set fully captures all visual information and this may lead to Selection Bias. Here, we try a novel approach in the tradition of the Thought Experiment. We run this thought experiment on a real domain of visual objects that we can fully characterize and look at specific gaps in training data and their impact on performance requirements. Our thought experiment points to three conclusions: first, that generalization behavior is dependent on how sufficiently the particular dimensions of the domain are represented during training; second, that the utility of any generalization is completely dependent on the acceptable system error; and third, that specific visual features of objects, such as pose orientations out of the imaging plane or colours, may not be recoverable if not represented sufficiently in a training set. Any currently observed generalization in modern deep learning networks may be more the result of coincidental alignments and whose utility needs to be confirmed with respect to a system's performance specification. Our Thought Experiment Probe approach, coupled with the resulting Bias Breakdown can be very informative towards understanding the impact of biases.

</p>
</details>

<details><summary><b>Anchor-based Plain Net for Mobile Image Super-Resolution</b>
<a href="https://arxiv.org/abs/2105.09750">arxiv:2105.09750</a>
&#x1F4C8; 3 <br>
<p>Zongcai Du, Jie Liu, Jie Tang, Gangshan Wu</p></summary>
<p>

**Abstract:** Along with the rapid development of real-world applications, higher requirements on the accuracy and efficiency of image super-resolution (SR) are brought forward. Though existing methods have achieved remarkable success, the majority of them demand plenty of computational resources and large amount of RAM, and thus they can not be well applied to mobile device. In this paper, we aim at designing efficient architecture for 8-bit quantization and deploy it on mobile device. First, we conduct an experiment about meta-node latency by decomposing lightweight SR architectures, which determines the portable operations we can utilize. Then, we dig deeper into what kind of architecture is beneficial to 8-bit quantization and propose anchor-based plain net (ABPN). Finally, we adopt quantization-aware training strategy to further boost the performance. Our model can outperform 8-bit quantized FSRCNN by nearly 2dB in terms of PSNR, while satisfying realistic needs at the same time. Code is avaliable at https://github.com/NJU- Jet/SR_Mobile_Quantization.

</p>
</details>

<details><summary><b>Ensemble machine learning approach for screening of coronary heart disease based on echocardiography and risk factors</b>
<a href="https://arxiv.org/abs/2105.09670">arxiv:2105.09670</a>
&#x1F4C8; 3 <br>
<p>Jingyi Zhang, Huolan Zhu, Yongkai Chen, Chenguang Yang, Huimin Cheng, Yi Li, Wenxuan Zhong, Fang Wang</p></summary>
<p>

**Abstract:** Background: Extensive clinical evidence suggests that a preventive screening of coronary heart disease (CHD) at an earlier stage can greatly reduce the mortality rate. We use 64 two-dimensional speckle tracking echocardiography (2D-STE) features and seven clinical features to predict whether one has CHD. Methods: We develop a machine learning approach that integrates a number of popular classification methods together by model stacking, and generalize the traditional stacking method to a two-step stacking method to improve the diagnostic performance. Results: By borrowing strengths from multiple classification models through the proposed method, we improve the CHD classification accuracy from around 70% to 87.7% on the testing set. The sensitivity of the proposed method is 0.903 and the specificity is 0.843, with an AUC of 0.904, which is significantly higher than those of the individual classification models. Conclusions: Our work lays a foundation for the deployment of speckle tracking echocardiography-based screening tools for coronary heart disease.

</p>
</details>

<details><summary><b>TF-IDF vs Word Embeddings for Morbidity Identification in Clinical Notes: An Initial Study</b>
<a href="https://arxiv.org/abs/2105.09632">arxiv:2105.09632</a>
&#x1F4C8; 3 <br>
<p>Danilo Dessi, Rim Helaoui, Vivek Kumar, Diego Reforgiato Recupero, Daniele Riboni</p></summary>
<p>

**Abstract:** Today, we are seeing an ever-increasing number of clinical notes that contain clinical results, images, and textual descriptions of patient's health state. All these data can be analyzed and employed to cater novel services that can help people and domain experts with their common healthcare tasks. However, many technologies such as Deep Learning and tools like Word Embeddings have started to be investigated only recently, and many challenges remain open when it comes to healthcare domain applications. To address these challenges, we propose the use of Deep Learning and Word Embeddings for identifying sixteen morbidity types within textual descriptions of clinical records. For this purpose, we have used a Deep Learning model based on Bidirectional Long-Short Term Memory (LSTM) layers which can exploit state-of-the-art vector representations of data such as Word Embeddings. We have employed pre-trained Word Embeddings namely GloVe and Word2Vec, and our own Word Embeddings trained on the target domain. Furthermore, we have compared the performances of the deep learning approaches against the traditional tf-idf using Support Vector Machine and Multilayer perceptron (our baselines). From the obtained results it seems that the latter outperforms the combination of Deep Learning approaches using any word embeddings. Our preliminary results indicate that there are specific features that make the dataset biased in favour of traditional machine learning approaches.

</p>
</details>

<details><summary><b>FVC: A New Framework towards Deep Video Compression in Feature Space</b>
<a href="https://arxiv.org/abs/2105.09600">arxiv:2105.09600</a>
&#x1F4C8; 3 <br>
<p>Zhihao Hu, Guo Lu, Dong Xu</p></summary>
<p>

**Abstract:** Learning based video compression attracts increasing attention in the past few years. The previous hybrid coding approaches rely on pixel space operations to reduce spatial and temporal redundancy, which may suffer from inaccurate motion estimation or less effective motion compensation. In this work, we propose a feature-space video coding network (FVC) by performing all major operations (i.e., motion estimation, motion compression, motion compensation and residual compression) in the feature space. Specifically, in the proposed deformable compensation module, we first apply motion estimation in the feature space to produce motion information (i.e., the offset maps), which will be compressed by using the auto-encoder style network. Then we perform motion compensation by using deformable convolution and generate the predicted feature. After that, we compress the residual feature between the feature from the current frame and the predicted feature from our deformable compensation module. For better frame reconstruction, the reference features from multiple previous reconstructed frames are also fused by using the non-local attention mechanism in the multi-frame feature fusion module. Comprehensive experimental results demonstrate that the proposed framework achieves the state-of-the-art performance on four benchmark datasets including HEVC, UVG, VTL and MCL-JCV.

</p>
</details>

<details><summary><b>Distribution Agnostic Symbolic Representations for Time Series Dimensionality Reduction and Online Anomaly Detection</b>
<a href="https://arxiv.org/abs/2105.09592">arxiv:2105.09592</a>
&#x1F4C8; 3 <br>
<p>Konstantinos Bountrogiannis, George Tzagkarakis, Panagiotis Tsakalides</p></summary>
<p>

**Abstract:** Due to the importance of the lower bounding distances and the attractiveness of symbolic representations, the family of symbolic aggregate approximations (SAX) has been used extensively for encoding time series data. However, typical SAX-based methods rely on two restrictive assumptions; the Gaussian distribution and equiprobable symbols. This paper proposes two novel data-driven SAX-based symbolic representations, distinguished by their discretization steps. The first representation, oriented for general data compaction and indexing scenarios, is based on the combination of kernel density estimation and Lloyd-Max quantization to minimize the information loss and mean squared error in the discretization step. The second method, oriented for high-level mining tasks, employs the Mean-Shift clustering method and is shown to enhance anomaly detection in the lower-dimensional space. Besides, we verify on a theoretical basis a previously observed phenomenon of the intrinsic process that results in a lower than the expected variance of the intermediate piecewise aggregate approximation. This phenomenon causes an additional information loss but can be avoided with a simple modification. The proposed representations possess all the attractive properties of the conventional SAX method. Furthermore, experimental evaluation on real-world datasets demonstrates their superiority compared to the traditional SAX and an alternative data-driven SAX variant.

</p>
</details>

<details><summary><b>Aggregate Learning for Mixed Frequency Data</b>
<a href="https://arxiv.org/abs/2105.09579">arxiv:2105.09579</a>
&#x1F4C8; 3 <br>
<p>Takamichi Toda, Daisuke Moriwaki, Kazuhiro Ota</p></summary>
<p>

**Abstract:** Large and acute economic shocks such as the 2007-2009 financial crisis and the current COVID-19 infections rapidly change the economic environment. In such a situation, the importance of real-time economic analysis using alternative datais emerging. Alternative data such as search query and location data are closer to real-time and richer than official statistics that are typically released once a month in an aggregated form. We take advantage of spatio-temporal granularity of alternative data and propose a mixed-FrequencyAggregate Learning (MF-AGL)model that predicts economic indicators for the smaller areas in real-time. We apply the model for the real-world problem; prediction of the number of job applicants which is closely related to the unemployment rates. We find that the proposed model predicts (i) the regional heterogeneity of the labor market condition and (ii) the rapidly changing economic status. The model can be applied to various tasks, especially economic analysis

</p>
</details>

<details><summary><b>Logarithmic landscape and power-law escape rate of SGD</b>
<a href="https://arxiv.org/abs/2105.09557">arxiv:2105.09557</a>
&#x1F4C8; 3 <br>
<p>Takashi Mori, Liu Ziyin, Kangqiao Liu, Masahito Ueda</p></summary>
<p>

**Abstract:** Stochastic gradient descent (SGD) undergoes complicated multiplicative noise for the mean-square loss. We use this property of the SGD noise to derive a stochastic differential equation (SDE) with simpler additive noise by performing a non-uniform transformation of the time variable. In the SDE, the gradient of the loss is replaced by that of the logarithmized loss. Consequently, we show that, near a local or global minimum, the stationary distribution $P_\mathrm{ss}(θ)$ of the network parameters $θ$ follows a power-law with respect to the loss function $L(θ)$, i.e. $P_\mathrm{ss}(θ)\propto L(θ)^{-φ}$ with the exponent $φ$ specified by the mini-batch size, the learning rate, and the Hessian at the minimum. We obtain the escape rate formula from a local minimum, which is determined not by the loss barrier height $ΔL=L(θ^s)-L(θ^*)$ between a minimum $θ^*$ and a saddle $θ^s$ but by the logarithmized loss barrier height $Δ\log L=\log[L(θ^s)/L(θ^*)]$. Our escape-rate formula explains an empirical fact that SGD prefers flat minima with low effective dimensions.

</p>
</details>

<details><summary><b>Fed-EINI: An Efficient and Interpretable Inference Framework for Decision Tree Ensembles in Federated Learning</b>
<a href="https://arxiv.org/abs/2105.09540">arxiv:2105.09540</a>
&#x1F4C8; 3 <br>
<p>Xiaolin Chen, Shuai Zhou, Bei guan, Kai Yang, Hao Fan, Hu Wang, Yongji Wang</p></summary>
<p>

**Abstract:** The increasing concerns about data privacy and security drive an emerging field of studying privacy-preserving machine learning from isolated data sources, i.e., federated learning. A class of federated learning, vertical federated learning, where different parties hold different features for common users, has a great potential of driving a great variety of business cooperation among enterprises in many fields. In machine learning, decision tree ensembles such as gradient boosting decision trees (GBDT) and random forest are widely applied powerful models with high interpretability and modeling efficiency. However, stateof-art vertical federated learning frameworks adapt anonymous features to avoid possible data breaches, makes the interpretability of the model compromised. To address this issue in the inference process, in this paper, we firstly make a problem analysis about the necessity of disclosure meanings of feature to Guest Party in vertical federated learning. Then we find the prediction result of a tree could be expressed as the intersection of results of sub-models of the tree held by all parties. With this key observation, we protect data privacy and allow the disclosure of feature meaning by concealing decision paths and adapt a communication-efficient secure computation method for inference outputs. The advantages of Fed-EINI will be demonstrated through both theoretical analysis and extensive numerical results. We improve the interpretability of the model by disclosing the meaning of features while ensuring efficiency and accuracy.

</p>
</details>

<details><summary><b>Predicting Potential Drug Targets Using Tensor Factorisation and Knowledge Graph Embeddings</b>
<a href="https://arxiv.org/abs/2105.10578">arxiv:2105.10578</a>
&#x1F4C8; 2 <br>
<p>Cheng Ye, Rowan Swiers, Stephen Bonner, Ian Barrett</p></summary>
<p>

**Abstract:** The drug discovery and development process is a long and expensive one, costing over 1 billion USD on average per drug and taking 10-15 years. To reduce the high levels of attrition throughout the process, there has been a growing interest in applying machine learning methodologies to various stages of drug discovery process in the recent decade, including at the earliest stage - identification of druggable disease genes. In this paper, we have developed a new tensor factorisation model to predict potential drug targets (i.e.,genes or proteins) for diseases. We created a three dimensional tensor which consists of 1,048 targets, 860 diseases and 230,011 evidence attributes and clinical outcomes connecting them, using data extracted from the Open Targets and PharmaProjects databases. We enriched the data with gene representations learned from a drug discovery-oriented knowledge graph and applied our proposed method to predict the clinical outcomes for unseen target and dis-ease pairs. We designed three evaluation strategies to measure the prediction performance and benchmarked several commonly used machine learning classifiers together with matrix and tensor factorisation methods. The result shows that incorporating knowledge graph embeddings significantly improves the prediction accuracy and that training tensor factorisation alongside a dense neural network outperforms other methods. In summary, our framework combines two actively studied machine learning approaches to disease target identification, tensor factorisation and knowledge graph representation learning, which could be a promising avenue for further exploration in data-driven drug discovery.

</p>
</details>

<details><summary><b>Deep-Learned Event Variables for Collider Phenomenology</b>
<a href="https://arxiv.org/abs/2105.10126">arxiv:2105.10126</a>
&#x1F4C8; 2 <br>
<p>Doojin Kim, Kyoungchul Kong, Konstantin T. Matchev, Myeonghun Park, Prasanth Shyamsundar</p></summary>
<p>

**Abstract:** The choice of optimal event variables is crucial for achieving the maximal sensitivity of experimental analyses. Over time, physicists have derived suitable kinematic variables for many typical event topologies in collider physics. Here we introduce a deep learning technique to design good event variables, which are sensitive over a wide range of values for the unknown model parameters. We demonstrate that the neural networks trained with our technique on some simple event topologies are able to reproduce standard event variables like invariant mass, transverse mass, and stransverse mass. The method is automatable, completely general, and can be used to derive sensitive, previously unknown, event variables for other, more complex event topologies.

</p>
</details>

<details><summary><b>Escaping Saddle Points with Compressed SGD</b>
<a href="https://arxiv.org/abs/2105.10090">arxiv:2105.10090</a>
&#x1F4C8; 2 <br>
<p>Dmitrii Avdiukhin, Grigory Yaroslavtsev</p></summary>
<p>

**Abstract:** Stochastic gradient descent (SGD) is a prevalent optimization technique for large-scale distributed machine learning. While SGD computation can be efficiently divided between multiple machines, communication typically becomes a bottleneck in the distributed setting. Gradient compression methods can be used to alleviate this problem, and a recent line of work shows that SGD augmented with gradient compression converges to an $\varepsilon$-first-order stationary point. In this paper we extend these results to convergence to an $\varepsilon$-second-order stationary point ($\varepsilon$-SOSP), which is to the best of our knowledge the first result of this type. In addition, we show that, when the stochastic gradient is not Lipschitz, compressed SGD with RandomK compressor converges to an $\varepsilon$-SOSP with the same number of iterations as uncompressed SGD [Jin et al.,2021] (JACM), while improving the total communication by a factor of $\tilde Θ(\sqrt{d} \varepsilon^{-3/4})$, where $d$ is the dimension of the optimization problem. We present additional results for the cases when the compressor is arbitrary and when the stochastic gradient is Lipschitz.

</p>
</details>

<details><summary><b>A GAN-Like Approach for Physics-Based Imitation Learning and Interactive Control</b>
<a href="https://arxiv.org/abs/2105.10066">arxiv:2105.10066</a>
&#x1F4C8; 2 <br>
<p>Pei Xu, Ioannis Karamouzas</p></summary>
<p>

**Abstract:** We present a simple and intuitive approach for interactive control of physically simulated characters. Our work builds upon generative adversarial networks (GAN) and reinforcement learning, and introduces an imitation learning framework where an ensemble of classifiers and an imitation policy are trained in tandem given pre-processed reference clips. The classifiers are trained to discriminate the reference motion from the motion generated by the imitation policy, while the policy is rewarded for fooling the discriminators. Using our GAN-based approach, multiple motor control policies can be trained separately to imitate different behaviors. In runtime, our system can respond to external control signal provided by the user and interactively switch between different policies. Compared to existing methods, our proposed approach has the following attractive properties: 1) achieves state-of-the-art imitation performance without manually designing and fine tuning a reward function; 2) directly controls the character without having to track any target reference pose explicitly or implicitly through a phase state; and 3) supports interactive policy switching without requiring any motion generation or motion matching mechanism. We highlight the applicability of our approach in a range of imitation and interactive control tasks, while also demonstrating its ability to withstand external perturbations as well as to recover balance. Overall, our approach generates high-fidelity motion, has low runtime cost, and can be easily integrated into interactive applications and games.

</p>
</details>

<details><summary><b>Scalable Multi-Robot System for Non-myopic Spatial Sampling</b>
<a href="https://arxiv.org/abs/2105.10018">arxiv:2105.10018</a>
&#x1F4C8; 2 <br>
<p>Sandeep Manjanna, M. Ani Hsieh, Gregory Dudek</p></summary>
<p>

**Abstract:** This paper presents a distributed scalable multi-robot planning algorithm for non-uniform sampling of quasi-static spatial fields. We address the problem of efficient data collection using multiple autonomous vehicles and consider the effects of communication between multiple robots, acting independently, on the overall sampling performance of the team. We focus on the distributed sampling problem where the robots operate independent of their teammates, but have the ability to communicate their current state to other neighbors within a fixed communication range. Our proposed approach is scalable and adaptive to various environmental scenarios, changing robot team configurations, and runs in real-time, which are important features for many real-world applications. We compare the performance of our proposed algorithm to baseline strategies through simulated experiments that utilize models derived from both synthetic and field deployment data. The results show that our sampling algorithm is efficient even when robots in the team are operating with a limited communication range, thus demonstrating the scalability our method in sampling large-scale environments.

</p>
</details>

<details><summary><b>Opening Deep Neural Networks with Generative Models</b>
<a href="https://arxiv.org/abs/2105.10013">arxiv:2105.10013</a>
&#x1F4C8; 2 <br>
<p>Marcos Vendramini, Hugo Oliveira, Alexei Machado, Jefersson A. dos Santos</p></summary>
<p>

**Abstract:** Image classification methods are usually trained to perform predictions taking into account a predefined group of known classes. Real-world problems, however, may not allow for a full knowledge of the input and label spaces, making failures in recognition a hazard to deep visual learning. Open set recognition methods are characterized by the ability to correctly identify inputs of known and unknown classes. In this context, we propose GeMOS: simple and plug-and-play open set recognition modules that can be attached to pretrained Deep Neural Networks for visual recognition. The GeMOS framework pairs pre-trained Convolutional Neural Networks with generative models for open set recognition to extract open set scores for each sample, allowing for failure recognition in object recognition tasks. We conduct a thorough evaluation of the proposed method in comparison with state-of-the-art open set algorithms, finding that GeMOS either outperforms or is statistically indistinguishable from more complex and costly models.

</p>
</details>

<details><summary><b>Optimizing Neural Network Weights using Nature-Inspired Algorithms</b>
<a href="https://arxiv.org/abs/2105.09983">arxiv:2105.09983</a>
&#x1F4C8; 2 <br>
<p>Wael Korani, Malek Mouhoub, Samira Sadaoui</p></summary>
<p>

**Abstract:** This study aims to optimize Deep Feedforward Neural Networks (DFNNs) training using nature-inspired optimization algorithms, such as PSO, MTO, and its variant called MTOCL. We show how these algorithms efficiently update the weights of DFNNs when learning from data. We evaluate the performance of DFNN fused with optimization algorithms using three Wisconsin breast cancer datasets, Original, Diagnostic, and Prognosis, under different experimental scenarios. The empirical analysis demonstrates that MTOCL is the most performing in most scenarios across the three datasets. Also, MTOCL is comparable to past weight optimization algorithms for the original dataset, and superior for the other datasets, especially for the challenging Prognostic dataset.

</p>
</details>

<details><summary><b>Data-driven discovery of interpretable causal relations for deep learning material laws with uncertainty propagation</b>
<a href="https://arxiv.org/abs/2105.09980">arxiv:2105.09980</a>
&#x1F4C8; 2 <br>
<p>Xiao Sun, Bahador Bahmani, Nikolaos N. Vlassis, WaiChing Sun, Yanxun Xu</p></summary>
<p>

**Abstract:** This paper presents a computational framework that generates ensemble predictive mechanics models with uncertainty quantification (UQ). We first develop a causal discovery algorithm to infer causal relations among time-history data measured during each representative volume element (RVE) simulation through a directed acyclic graph (DAG). With multiple plausible sets of causal relationships estimated from multiple RVE simulations, the predictions are propagated in the derived causal graph while using a deep neural network equipped with dropout layers as a Bayesian approximation for uncertainty quantification. We select two representative numerical examples (traction-separation laws for frictional interfaces, elastoplasticity models for granular assembles) to examine the accuracy and robustness of the proposed causal discovery method for the common material law predictions in civil engineering applications.

</p>
</details>

<details><summary><b>On planetary systems as ordered sequences</b>
<a href="https://arxiv.org/abs/2105.09966">arxiv:2105.09966</a>
&#x1F4C8; 2 <br>
<p>Emily Sandford, David Kipping, Michael Collins</p></summary>
<p>

**Abstract:** A planetary system consists of a host star and one or more planets, arranged into a particular configuration. Here, we consider what information belongs to the configuration, or ordering, of 4286 Kepler planets in their 3277 planetary systems. First, we train a neural network model to predict the radius and period of a planet based on the properties of its host star and the radii and period of its neighbors. The mean absolute error of the predictions of the trained model is a factor of 2.1 better than the MAE of the predictions of a naive model which draws randomly from dynamically allowable periods and radii. Second, we adapt a model used for unsupervised part-of-speech tagging in computational linguistics to investigate whether planets or planetary systems fall into natural categories with physically interpretable "grammatical rules." The model identifies two robust groups of planetary systems: (1) compact multi-planet systems and (2) systems around giant stars ($\log{g} \lesssim 4.0$), although the latter group is strongly sculpted by the selection bias of the transit method. These results reinforce the idea that planetary systems are not random sequences -- instead, as a population, they contain predictable patterns that can provide insight into the formation and evolution of planetary systems.

</p>
</details>

<details><summary><b>A comprehensive comparative evaluation and analysis of Distributional Semantic Models</b>
<a href="https://arxiv.org/abs/2105.09825">arxiv:2105.09825</a>
&#x1F4C8; 2 <br>
<p>Alessandro Lenci, Magnus Sahlgren, Patrick Jeuniaux, Amaru Cuba Gyllensten, Martina Miliani</p></summary>
<p>

**Abstract:** Distributional semantics has deeply changed in the last decades. First, predict models stole the thunder from traditional count ones, and more recently both of them were replaced in many NLP applications by contextualized vectors produced by Transformer neural language models. Although an extensive body of research has been devoted to Distributional Semantic Model (DSM) evaluation, we still lack a thorough comparison with respect to tested models, semantic tasks, and benchmark datasets. Moreover, previous work has mostly focused on task-driven evaluation, instead of exploring the differences between the way models represent the lexical semantic space. In this paper, we perform a comprehensive evaluation of type distributional vectors, either produced by static DSMs or obtained by averaging the contextualized vectors generated by BERT. First of all, we investigate the performance of embeddings in several semantic tasks, carrying out an in-depth statistical analysis to identify the major factors influencing the behavior of DSMs. The results show that i.) the alleged superiority of predict based models is more apparent than real, and surely not ubiquitous and ii.) static DSMs surpass contextualized representations in most out-of-context semantic tasks and datasets. Furthermore, we borrow from cognitive neuroscience the methodology of Representational Similarity Analysis (RSA) to inspect the semantic spaces generated by distributional models. RSA reveals important differences related to the frequency and part-of-speech of lexical items.

</p>
</details>

<details><summary><b>DPN-SENet:A self-attention mechanism neural network for detection and diagnosis of COVID-19 from chest x-ray images</b>
<a href="https://arxiv.org/abs/2105.09683">arxiv:2105.09683</a>
&#x1F4C8; 2 <br>
<p>Bo Cheng, Ruhui Xue, Hang Yang, Laili Zhu, Wei Xiang</p></summary>
<p>

**Abstract:** Background and Objective: The new type of coronavirus is also called COVID-19. It began to spread at the end of 2019 and has now spread across the world. Until October 2020, It has infected around 37 million people and claimed about 1 million lives. We propose a deep learning model that can help radiologists and clinicians use chest X-rays to diagnose COVID-19 cases and show the diagnostic features of pneumonia. Methods: The approach in this study is: 1) we propose a data enhancement method to increase the diversity of the data set, thereby improving the generalization performance of the model. 2) Our deep convolution neural network model DPN-SE adds a self-attention mechanism to the DPN network. The addition of a self-attention mechanism has greatly improved the performance of the network. 3) Use the Lime interpretable library to mark the feature regions on the X-ray medical image that helps doctors more quickly diagnose COVID-19 in people. Results: Under the same network model, the data with and without data enhancement is put into the model for training respectively. At last, comparing two experimental results: among the 10 network models with different structures, 7 network models have improved their effects after using data enhancement, with an average improvement of 1% in recognition accuracy. We propose that the accuracy and recall rates of the DPN-SE network are 93% and 98% of cases (COVID vs. pneumonia bacteria vs. viral pneumonia vs. normal). Compared with the original DPN, the respective accuracy is improved by 2%. Conclusion: The data augmentation method we used has achieved effective results on a small amount of data set, showing that a reasonable data augmentation method can improve the recognition accuracy without changing the sample size and model structure. Overall, the proposed method and model can effectively become a very useful tool for clinical radiologists.

</p>
</details>

<details><summary><b>Survey and Perspective on Social Emotions in Robotics</b>
<a href="https://arxiv.org/abs/2105.09647">arxiv:2105.09647</a>
&#x1F4C8; 2 <br>
<p>Chie Hieida, Takayuki Nagai</p></summary>
<p>

**Abstract:** This study reviews research on social emotions in robotics. In robotics, the study of emotions has been pursued for a long time, including the study of their recognition, expression, and computational modeling of the basic mechanisms which underlie them. Research has advanced according to well-known psychological findings, such as category and dimension theories. Many studies have been based on these basic theories, addressing only basic emotions. However, social emotions, also referred to as higher-level emotions, have been studied in psychology. We believe that these higher-level emotions are worth pursuing in robotics for next-generation, socially aware robots. In this review paper, we summarize the findings on social emotions in psychology and neuroscience, along with a survey of the studies on social emotions in robotics that have been conducted to date. Thereafter, research directions toward the implementation of social emotions in robots are discussed.

</p>
</details>

<details><summary><b>AGSFCOS: Based on attention mechanism and Scale-Equalizing pyramid network of object detection</b>
<a href="https://arxiv.org/abs/2105.09596">arxiv:2105.09596</a>
&#x1F4C8; 2 <br>
<p>Li Wang, Wei Xiang, Ruhui Xue, Kaida Zou, Laili Zhu</p></summary>
<p>

**Abstract:** Recently, the anchor-free object detection model has shown great potential for accuracy and speed to exceed anchor-based object detection. Therefore, two issues are mainly studied in this article: (1) How to let the backbone network in the anchor-free object detection model learn feature extraction? (2) How to make better use of the feature pyramid network? In order to solve the above problems, Experiments show that our model has a certain improvement in accuracy compared with the current popular detection models on the COCO dataset, the designed attention mechanism module can capture contextual information well, improve detection accuracy, and use sepc network to help balance abstract and detailed information, and reduce the problem of semantic gap in the feature pyramid network. Whether it is anchor-based network model YOLOv3, Faster RCNN, or anchor-free network model Foveabox, FSAF, FCOS. Our optimal model can get 39.5% COCO AP under the background of ResNet50.

</p>
</details>

<details><summary><b>Deep Learning-based Implicit CSI Feedback in Massive MIMO</b>
<a href="https://arxiv.org/abs/2105.10100">arxiv:2105.10100</a>
&#x1F4C8; 1 <br>
<p>Muhan Chen, Jiajia Guo, Chao-Kai Wen, Shi Jin, Geoffrey Ye Li, Ang Yang</p></summary>
<p>

**Abstract:** Massive multiple-input multiple-output can obtain more performance gain by exploiting the downlink channel state information (CSI) at the base station (BS). Therefore, studying CSI feedback with limited communication resources in frequency-division duplexing systems is of great importance. Recently, deep learning (DL)-based CSI feedback has shown considerable potential. However, the existing DL-based explicit feedback schemes are difficult to deploy because current fifth-generation mobile communication protocols and systems are designed based on an implicit feedback mechanism. In this paper, we propose a DL-based implicit feedback architecture to inherit the low-overhead characteristic, which uses neural networks (NNs) to replace the precoding matrix indicator (PMI) encoding and decoding modules. By using environment information, the NNs can achieve a more refined mapping between the precoding matrix and the PMI compared with codebooks. The correlation between subbands is also used to further improve the feedback performance. Simulation results show that, for a single resource block (RB), the proposed architecture can save 25.0% and 40.0% of overhead compared with Type I codebook under two antenna configurations, respectively. For a wideband system with 52 RBs, overhead can be saved by 30.7% and 48.0% compared with Type II codebook when ignoring and considering extracting subband correlation, respectively.

</p>
</details>

<details><summary><b>Fair and Efficient Resource Allocation with Partial Information</b>
<a href="https://arxiv.org/abs/2105.10064">arxiv:2105.10064</a>
&#x1F4C8; 1 <br>
<p>Daniel Halpern, Nisarg Shah</p></summary>
<p>

**Abstract:** We study the fundamental problem of allocating indivisible goods to agents with additive preferences. We consider eliciting from each agent only a ranking of her $k$ most preferred goods instead of her full cardinal valuations. We characterize the value of $k$ needed to achieve envy-freeness up to one good and approximate maximin share guarantee, two widely studied fairness notions. We also analyze the multiplicative loss in social welfare incurred due to the lack of full information with and without the fairness requirements.

</p>
</details>

<details><summary><b>Data Curation and Quality Assurance for Machine Learning-based Cyber Intrusion Detection</b>
<a href="https://arxiv.org/abs/2105.10041">arxiv:2105.10041</a>
&#x1F4C8; 1 <br>
<p>Haihua Chen, Ngan Tran, Anand Sagar Thumati, Jay Bhuyan, Junhua Ding</p></summary>
<p>

**Abstract:** Intrusion detection is an essential task in the cyber threat environment. Machine learning and deep learning techniques have been applied for intrusion detection. However, most of the existing research focuses on the model work but ignores the fact that poor data quality has a direct impact on the performance of a machine learning system. More attention should be paid to the data work when building a machine learning-based intrusion detection system. This article first summarizes existing machine learning-based intrusion detection systems and the datasets used for building these systems. Then the data preparation workflow and quality requirements for intrusion detection are discussed. To figure out how data and models affect machine learning performance, we conducted experiments on 11 HIDS datasets using seven machine learning models and three deep learning models. The experimental results show that BERT and GPT were the best algorithms for HIDS on all of the datasets. However, the performance on different datasets varies, indicating the differences between the data quality of these datasets. We then evaluate the data quality of the 11 datasets based on quality dimensions proposed in this paper to determine the best characteristics that a HIDS dataset should possess in order to yield the best possible result. This research initiates a data quality perspective for researchers and practitioners to improve the performance of machine learning-based intrusion detection.

</p>
</details>

<details><summary><b>Dense Reconstruction of Transparent Objects by Altering Incident Light Paths Through Refraction</b>
<a href="https://arxiv.org/abs/2105.09993">arxiv:2105.09993</a>
&#x1F4C8; 1 <br>
<p>Kai Han, Kwan-Yee K. Wong, Miaomiao Liu</p></summary>
<p>

**Abstract:** This paper addresses the problem of reconstructing the surface shape of transparent objects. The difficulty of this problem originates from the viewpoint dependent appearance of a transparent object, which quickly makes reconstruction methods tailored for diffuse surfaces fail disgracefully. In this paper, we introduce a fixed viewpoint approach to dense surface reconstruction of transparent objects based on refraction of light. We present a simple setup that allows us to alter the incident light paths before light rays enter the object by immersing the object partially in a liquid, and develop a method for recovering the object surface through reconstructing and triangulating such incident light paths. Our proposed approach does not need to model the complex interactions of light as it travels through the object, neither does it assume any parametric form for the object shape nor the exact number of refractions and reflections taken place along the light paths. It can therefore handle transparent objects with a relatively complex shape and structure, with unknown and inhomogeneous refractive index. We also show that for thin transparent objects, our proposed acquisition setup can be further simplified by adopting a single refraction approximation. Experimental results on both synthetic and real data demonstrate the feasibility and accuracy of our proposed approach.

</p>
</details>

<details><summary><b>POCFormer: A Lightweight Transformer Architecture for Detection of COVID-19 Using Point of Care Ultrasound</b>
<a href="https://arxiv.org/abs/2105.09913">arxiv:2105.09913</a>
&#x1F4C8; 1 <br>
<p>Shehan Perera, Srikar Adhikari, Alper Yilmaz</p></summary>
<p>

**Abstract:** The rapid and seemingly endless expansion of COVID-19 can be traced back to the inefficiency and shortage of testing kits that offer accurate results in a timely manner. An emerging popular technique, which adopts improvements made in mobile ultrasound technology, allows for healthcare professionals to conduct rapid screenings on a large scale. We present an image-based solution that aims at automating the testing process which allows for rapid mass testing to be conducted with or without a trained medical professional that can be applied to rural environments and third world countries. Our contributions towards rapid large-scale testing include a novel deep learning architecture capable of analyzing ultrasound data that can run in real-time and significantly improve the current state-of-the-art detection accuracies using image-based COVID-19 detection.

</p>
</details>

<details><summary><b>Learning Robust Recommenders through Cross-Model Agreement</b>
<a href="https://arxiv.org/abs/2105.09605">arxiv:2105.09605</a>
&#x1F4C8; 1 <br>
<p>Yu Wang, Xin Xin, Zaiqiao Meng, Xiangnan He, Joemon Jose, Fuli Feng</p></summary>
<p>

**Abstract:** Learning from implicit feedback is one of the most common cases in the application of recommender systems. Generally speaking, interacted examples are considered as positive while negative examples are sampled from uninteracted ones. However, noisy examples are prevalent in real-world implicit feedback. A noisy positive example could be interacted but it actually leads to negative user preference. A noisy negative example which is uninteracted because of unawareness of the user could also denote potential positive user preference. Conventional training methods overlook these noisy examples, leading to sub-optimal recommendations. In this work, we propose a novel framework to learn robust recommenders from implicit feedback. Through an empirical study, we find that different models make relatively similar predictions on clean examples which denote the real user preference, while the predictions on noisy examples vary much more across different models. Motivated by this observation, we propose denoising with cross-model agreement(DeCA) which aims to minimize the KL-divergence between the real user preference distributions parameterized by two recommendation models while maximizing the likelihood of data observation. We employ the proposed DeCA on four state-of-the-art recommendation models and conduct experiments on four datasets. Experimental results demonstrate that DeCA significantly improves recommendation performance compared with normal training and other denoising methods. Codes will be open-sourced.

</p>
</details>

<details><summary><b>DEHB: Evolutionary Hyperband for Scalable, Robust and Efficient Hyperparameter Optimization</b>
<a href="https://arxiv.org/abs/2105.09821">arxiv:2105.09821</a>
&#x1F4C8; 0 <br>
<p>Noor Awad, Neeratyoy Mallik, Frank Hutter</p></summary>
<p>

**Abstract:** Modern machine learning algorithms crucially rely on several design decisions to achieve strong performance, making the problem of Hyperparameter Optimization (HPO) more important than ever. Here, we combine the advantages of the popular bandit-based HPO method Hyperband (HB) and the evolutionary search approach of Differential Evolution (DE) to yield a new HPO method which we call DEHB. Comprehensive results on a very broad range of HPO problems, as well as a wide range of tabular benchmarks from neural architecture search, demonstrate that DEHB achieves strong performance far more robustly than all previous HPO methods we are aware of, especially for high-dimensional problems with discrete input dimensions. For example, DEHB is up to 1000x faster than random search. It is also efficient in computational time, conceptually simple and easy to implement, positioning it well to become a new default HPO method.

</p>
</details>

<details><summary><b>Navigation Turing Test (NTT): Learning to Evaluate Human-Like Navigation</b>
<a href="https://arxiv.org/abs/2105.09637">arxiv:2105.09637</a>
&#x1F4C8; 0 <br>
<p>Sam Devlin, Raluca Georgescu, Ida Momennejad, Jaroslaw Rzepecki, Evelyn Zuniga, Gavin Costello, Guy Leroy, Ali Shaw, Katja Hofmann</p></summary>
<p>

**Abstract:** A key challenge on the path to developing agents that learn complex human-like behavior is the need to quickly and accurately quantify human-likeness. While human assessments of such behavior can be highly accurate, speed and scalability are limited. We address these limitations through a novel automated Navigation Turing Test (ANTT) that learns to predict human judgments of human-likeness. We demonstrate the effectiveness of our automated NTT on a navigation task in a complex 3D environment. We investigate six classification models to shed light on the types of architectures best suited to this task, and validate them against data collected through a human NTT. Our best models achieve high accuracy when distinguishing true human and agent behavior. At the same time, we show that predicting finer-grained human assessment of agents' progress towards human-like behavior remains unsolved. Our work takes an important step towards agents that more effectively learn complex human-like behavior.

</p>
</details>

<details><summary><b>On the $α$-lazy version of Markov chains in estimation and testing problems</b>
<a href="https://arxiv.org/abs/2105.09536">arxiv:2105.09536</a>
&#x1F4C8; 0 <br>
<p>Sela Fried, Geoffrey Wolfer</p></summary>
<p>

**Abstract:** Given access to a single long trajectory generated by an unknown irreducible Markov chain $M$, we simulate an $α$-lazy version of $M$ which is ergodic. This enables us to generalize recent results on estimation and identity testing that were stated for ergodic Markov chains in a way that allows fully empirical inference. In particular, our approach shows that the pseudo spectral gap introduced by Paulin [2015] and defined for ergodic Markov chains may be given a meaning already in the case of irreducible but possibly periodic Markov chains.

</p>
</details>


[Next Page](2021/2021-05/2021-05-19.md)
