Prev: [2022.05.22]({{ '/2022/05/22/2022.05.22.html' | relative_url }})  Next: [2022.05.24]({{ '/2022/05/24/2022.05.24.html' | relative_url }})
{% raw %}
## Summary for 2022-05-23, created on 2022-06-02


<details><summary><b>On the Paradox of Learning to Reason from Data</b>
<a href="https://arxiv.org/abs/2205.11502">arxiv:2205.11502</a>
&#x1F4C8; 6560 <br>
<p>Honghua Zhang, Liunian Harold Li, Tao Meng, Kai-Wei Chang, Guy Van den Broeck</p></summary>
<p>

**Abstract:** Logical reasoning is needed in a wide range of NLP tasks. Can a BERT model be trained end-to-end to solve logical reasoning problems presented in natural language? We attempt to answer this question in a confined problem space where there exists a set of parameters that perfectly simulates logical reasoning. We make observations that seem to contradict each other: BERT attains near-perfect accuracy on in-distribution test examples while failing to generalize to other data distributions over the exact same problem space. Our study provides an explanation for this paradox: instead of learning to emulate the correct reasoning function, BERT has in fact learned statistical features that inherently exist in logical reasoning problems. We also show that it is infeasible to jointly remove statistical features from data, illustrating the difficulty of learning to reason in general. Our result naturally extends to other neural models and unveils the fundamental difference between learning to reason and learning to achieve high performance on NLP benchmarks using statistical features.

</p>
</details>

<details><summary><b>Flexible Diffusion Modeling of Long Videos</b>
<a href="https://arxiv.org/abs/2205.11495">arxiv:2205.11495</a>
&#x1F4C8; 4790 <br>
<p>William Harvey, Saeid Naderiparizi, Vaden Masrani, Christian Weilbach, Frank Wood</p></summary>
<p>

**Abstract:** We present a framework for video modeling based on denoising diffusion probabilistic models that produces long-duration video completions in a variety of realistic environments. We introduce a generative model that can at test-time sample any arbitrary subset of video frames conditioned on any other subset and present an architecture adapted for this purpose. Doing so allows us to efficiently compare and optimize a variety of schedules for the order in which frames in a long video are sampled and use selective sparse and long-range conditioning on previously sampled frames. We demonstrate improved video modeling over prior work on a number of datasets and sample temporally coherent videos over 25 minutes in length. We additionally release a new video modeling dataset and semantically meaningful metrics based on videos generated in the CARLA self-driving car simulator.

</p>
</details>

<details><summary><b>HyperTree Proof Search for Neural Theorem Proving</b>
<a href="https://arxiv.org/abs/2205.11491">arxiv:2205.11491</a>
&#x1F4C8; 4080 <br>
<p>Guillaume Lample, Marie-Anne Lachaux, Thibaut Lavril, Xavier Martinet, Amaury Hayat, Gabriel Ebner, Aurélien Rodriguez, Timothée Lacroix</p></summary>
<p>

**Abstract:** We propose an online training procedure for a transformer-based automated theorem prover. Our approach leverages a new search algorithm, HyperTree Proof Search (HTPS), inspired by the recent success of AlphaZero. Our model learns from previous proof searches through online training, allowing it to generalize to domains far from the training distribution. We report detailed ablations of our pipeline's main components by studying performance on three environments of increasing complexity. In particular, we show that with HTPS alone, a model trained on annotated proofs manages to prove 65.4% of a held-out set of Metamath theorems, significantly outperforming the previous state of the art of 56.5% by GPT-f. Online training on these unproved theorems increases accuracy to 82.6%. With a similar computational budget, we improve the state of the art on the Lean-based miniF2F-curriculum dataset from 31% to 42% proving accuracy.

</p>
</details>

<details><summary><b>Photorealistic Text-to-Image Diffusion Models with Deep Language Understanding</b>
<a href="https://arxiv.org/abs/2205.11487">arxiv:2205.11487</a>
&#x1F4C8; 3620 <br>
<p>Chitwan Saharia, William Chan, Saurabh Saxena, Lala Li, Jay Whang, Emily Denton, Seyed Kamyar Seyed Ghasemipour, Burcu Karagol Ayan, S. Sara Mahdavi, Rapha Gontijo Lopes, Tim Salimans, Jonathan Ho, David J Fleet, Mohammad Norouzi</p></summary>
<p>

**Abstract:** We present Imagen, a text-to-image diffusion model with an unprecedented degree of photorealism and a deep level of language understanding. Imagen builds on the power of large transformer language models in understanding text and hinges on the strength of diffusion models in high-fidelity image generation. Our key discovery is that generic large language models (e.g. T5), pretrained on text-only corpora, are surprisingly effective at encoding text for image synthesis: increasing the size of the language model in Imagen boosts both sample fidelity and image-text alignment much more than increasing the size of the image diffusion model. Imagen achieves a new state-of-the-art FID score of 7.27 on the COCO dataset, without ever training on COCO, and human raters find Imagen samples to be on par with the COCO data itself in image-text alignment. To assess text-to-image models in greater depth, we introduce DrawBench, a comprehensive and challenging benchmark for text-to-image models. With DrawBench, we compare Imagen with recent methods including VQ-GAN+CLIP, Latent Diffusion Models, and DALL-E 2, and find that human raters prefer Imagen over other models in side-by-side comparisons, both in terms of sample quality and image-text alignment. See https://imagen.research.google/ for an overview of the results.

</p>
</details>

<details><summary><b>Unsupervised Tokenization Learning</b>
<a href="https://arxiv.org/abs/2205.11443">arxiv:2205.11443</a>
&#x1F4C8; 403 <br>
<p>Anton Kolonin</p></summary>
<p>

**Abstract:** In the presented study, we discover that so called "transition freedom" metric appears superior for unsupervised tokenization purposes, compared to statistical metrics such as mutual information and conditional probability, providing F-measure scores in range from 0.71 to 1.0 across explored corpora. We find that different languages require different derivatives of that metric (such as variance and "peak values") for successful tokenization. Larger training corpora does not necessarily effect in better tokenization quality, while compacting the models eliminating statistically weak evidence tends to improve performance. Proposed unsupervised tokenization technique provides quality better or comparable to lexicon-based one, depending on the language.

</p>
</details>

<details><summary><b>Proceedings Seventeenth International Workshop on the ACL2 Theorem Prover and its Applications</b>
<a href="https://arxiv.org/abs/2205.11103">arxiv:2205.11103</a>
&#x1F4C8; 197 <br>
<p>Rob Sumners, Cuong Chau</p></summary>
<p>

**Abstract:** This volume contains a selection of papers presented at the 17th International Workshop on the ACL2 Theorem Prover and its Applications (ACL2 2022). The workshops are the premier technical forum for presenting research and experiences related to ACL2.

</p>
</details>

<details><summary><b>Contrastive and Non-Contrastive Self-Supervised Learning Recover Global and Local Spectral Embedding Methods</b>
<a href="https://arxiv.org/abs/2205.11508">arxiv:2205.11508</a>
&#x1F4C8; 96 <br>
<p>Randall Balestriero, Yann LeCun</p></summary>
<p>

**Abstract:** Self-Supervised Learning (SSL) surmises that inputs and pairwise positive relationships are enough to learn meaningful representations. Although SSL has recently reached a milestone: outperforming supervised methods in many modalities\dots the theoretical foundations are limited, method-specific, and fail to provide principled design guidelines to practitioners. In this paper, we propose a unifying framework under the helm of spectral manifold learning to address those limitations. Through the course of this study, we will rigorously demonstrate that VICReg, SimCLR, BarlowTwins et al. correspond to eponymous spectral methods such as Laplacian Eigenmaps, Multidimensional Scaling et al.
  This unification will then allow us to obtain (i) the closed-form optimal representation for each method, (ii) the closed-form optimal network parameters in the linear regime for each method, (iii) the impact of the pairwise relations used during training on each of those quantities and on downstream task performances, and most importantly, (iv) the first theoretical bridge between contrastive and non-contrastive methods towards global and local spectral embedding methods respectively, hinting at the benefits and limitations of each. For example, (i) if the pairwise relation is aligned with the downstream task, any SSL method can be employed successfully and will recover the supervised method, but in the low data regime, VICReg's invariance hyper-parameter should be high; (ii) if the pairwise relation is misaligned with the downstream task, VICReg with small invariance hyper-parameter should be preferred over SimCLR or BarlowTwins.

</p>
</details>

<details><summary><b>Causal Machine Learning for Healthcare and Precision Medicine</b>
<a href="https://arxiv.org/abs/2205.11402">arxiv:2205.11402</a>
&#x1F4C8; 87 <br>
<p>Pedro Sanchez, Jeremy P. Voisey, Tian Xia, Hannah I. Watson, Alison Q. ONeil, Sotirios A. Tsaftaris</p></summary>
<p>

**Abstract:** Causal machine learning (CML) has experienced increasing popularity in healthcare. Beyond the inherent capabilities of adding domain knowledge into learning systems, CML provides a complete toolset for investigating how a system would react to an intervention (e.g.\ outcome given a treatment). Quantifying effects of interventions allows actionable decisions to be made whilst maintaining robustness in the presence of confounders. Here, we explore how causal inference can be incorporated into different aspects of clinical decision support (CDS) systems by using recent advances in machine learning. Throughout this paper, we use Alzheimer's disease (AD) to create examples for illustrating how CML can be advantageous in clinical scenarios. Furthermore, we discuss important challenges present in healthcare applications such as processing high-dimensional and unstructured data, generalisation to out-of-distribution samples, and temporal relationships, that despite the great effort from the research community remain to be solved. Finally, we review lines of research within causal representation learning, causal discovery and causal reasoning which offer the potential towards addressing the aforementioned challenges.

</p>
</details>

<details><summary><b>ItemSage: Learning Product Embeddings for Shopping Recommendations at Pinterest</b>
<a href="https://arxiv.org/abs/2205.11728">arxiv:2205.11728</a>
&#x1F4C8; 42 <br>
<p>Paul Baltescu, Haoyu Chen, Nikil Pancha, Andrew Zhai, Jure Leskovec, Charles Rosenberg</p></summary>
<p>

**Abstract:** Learned embeddings for products are an important building block for web-scale e-commerce recommendation systems. At Pinterest, we build a single set of product embeddings called ItemSage to provide relevant recommendations in all shopping use cases including user, image and search based recommendations. This approach has led to significant improvements in engagement and conversion metrics, while reducing both infrastructure and maintenance cost. While most prior work focuses on building product embeddings from features coming from a single modality, we introduce a transformer-based architecture capable of aggregating information from both text and image modalities and show that it significantly outperforms single modality baselines. We also utilize multi-task learning to make ItemSage optimized for several engagement types, leading to a candidate generation system that is efficient for all of the engagement objectives of the end-to-end recommendation system. Extensive offline experiments are conducted to illustrate the effectiveness of our approach and results from online A/B experiments show substantial gains in key business metrics (up to +7% gross merchandise value/user and +11% click volume).

</p>
</details>

<details><summary><b>Simple Recurrence Improves Masked Language Models</b>
<a href="https://arxiv.org/abs/2205.11588">arxiv:2205.11588</a>
&#x1F4C8; 40 <br>
<p>Tao Lei, Ran Tian, Jasmijn Bastings, Ankur P. Parikh</p></summary>
<p>

**Abstract:** In this work, we explore whether modeling recurrence into the Transformer architecture can both be beneficial and efficient, by building an extremely simple recurrent module into the Transformer. We compare our model to baselines following the training and evaluation recipe of BERT. Our results confirm that recurrence can indeed improve Transformer models by a consistent margin, without requiring low-level performance optimizations, and while keeping the number of parameters constant. For example, our base model achieves an absolute improvement of 2.1 points averaged across 10 tasks and also demonstrates increased stability in fine-tuning over a range of learning rates.

</p>
</details>

<details><summary><b>Collaborative Adversarial Training</b>
<a href="https://arxiv.org/abs/2205.11156">arxiv:2205.11156</a>
&#x1F4C8; 20 <br>
<p>Qizhang Li, Yiwen Guo, Wangmeng Zuo, Hao Chen</p></summary>
<p>

**Abstract:** The vulnerability of deep neural networks (DNNs) to adversarial examples has attracted great attention in the machine learning community. The problem is related to local non-smoothness and steepness of normally obtained loss landscapes. Training augmented with adversarial examples (a.k.a., adversarial training) is considered as an effective remedy. In this paper, we highlight that some collaborative examples, nearly perceptually indistinguishable from both adversarial and benign examples yet show extremely lower prediction loss, can be utilized to enhance adversarial training. A novel method called collaborative adversarial training (CoAT) is thus proposed to achieve new state-of-the-arts.

</p>
</details>

<details><summary><b>Exposing Outlier Exposure: What Can Be Learned From Few, One, and Zero Outlier Images</b>
<a href="https://arxiv.org/abs/2205.11474">arxiv:2205.11474</a>
&#x1F4C8; 14 <br>
<p>Philipp Liznerski, Lukas Ruff, Robert A. Vandermeulen, Billy Joe Franks, Klaus-Robert Müller, Marius Kloft</p></summary>
<p>

**Abstract:** Traditionally anomaly detection (AD) is treated as an unsupervised problem utilizing only normal samples due to the intractability of characterizing everything that looks unlike the normal data. However, it has recently been found that unsupervised image anomaly detection can be drastically improved through the utilization of huge corpora of random images to represent anomalousness; a technique which is known as Outlier Exposure. In this paper we show that specialized AD learning methods seem actually superfluous and huge corpora of data expendable. For a common AD benchmark on ImageNet, standard classifiers and semi-supervised one-class methods trained to discern between normal samples and just a few random natural images are able to outperform the current state of the art in deep AD, and only one useful outlier sample is sufficient to perform competitively. We investigate this phenomenon and reveal that one-class methods are more robust towards the particular choice of training outliers. Furthermore, we find that a simple classifier based on representations from CLIP, a recent foundation model, achieves state-of-the-art results on CIFAR-10 and also outperforms all previous AD methods on ImageNet without any training samples (i.e., in a zero-shot setting).

</p>
</details>

<details><summary><b>Prompt Tuning for Discriminative Pre-trained Language Models</b>
<a href="https://arxiv.org/abs/2205.11166">arxiv:2205.11166</a>
&#x1F4C8; 10 <br>
<p>Yuan Yao, Bowen Dong, Ao Zhang, Zhengyan Zhang, Ruobing Xie, Zhiyuan Liu, Leyu Lin, Maosong Sun, Jianyong Wang</p></summary>
<p>

**Abstract:** Recent works have shown promising results of prompt tuning in stimulating pre-trained language models (PLMs) for natural language processing (NLP) tasks. However, to the best of our knowledge, existing works focus on prompt-tuning generative PLMs that are pre-trained to generate target tokens, such as BERT. It is still unknown whether and how discriminative PLMs, e.g., ELECTRA, can be effectively prompt-tuned. In this work, we present DPT, the first prompt tuning framework for discriminative PLMs, which reformulates NLP tasks into a discriminative language modeling problem. Comprehensive experiments on text classification and question answering show that, compared with vanilla fine-tuning, DPT achieves significantly higher performance, and also prevents the unstable problem in tuning large PLMs in both full-set and low-resource settings. The source code and experiment details of this paper can be obtained from https://github.com/thunlp/DPT.

</p>
</details>

<details><summary><b>Deep Learning-based automated classification of Chinese Speech Sound Disorders</b>
<a href="https://arxiv.org/abs/2205.11748">arxiv:2205.11748</a>
&#x1F4C8; 9 <br>
<p>Yao-Ming Kuo, Shanq-Jang Ruan, Yu-Chin Chen, Ya-Wen Tu</p></summary>
<p>

**Abstract:** This article describes a system for analyzing acoustic data in order to assist in the diagnosis and classification of children's speech disorders using a computer. The analysis concentrated on identifying and categorizing four distinct types of Chinese misconstructions. The study collected and generated a speech corpus containing 2540 Stopping, Velar, Consonant-vowel, and Affricate samples from 90 children aged 3-6 years with normal or pathological articulatory features. Each recording was accompanied by a detailed annotation from the field of speech therapy. Classification of the speech samples was accomplished using three well-established neural network models for image classification. The feature maps are created using three sets of MFCC parameters extracted from speech sounds and aggregated into a three-dimensional data structure as model input. We employ six techniques for data augmentation in order to augment the available dataset while avoiding over-simulation. The experiments examine the usability of four different categories of Chinese phrases and characters. Experiments with different data subsets demonstrate the system's ability to accurately detect the analyzed pronunciation disorders.

</p>
</details>

<details><summary><b>TAILOR: Teaching with Active and Incremental Learning for Object Registration</b>
<a href="https://arxiv.org/abs/2205.11692">arxiv:2205.11692</a>
&#x1F4C8; 9 <br>
<p>Qianli Xu, Nicolas Gauthier, Wenyu Liang, Fen Fang, Hui Li Tan, Ying Sun, Yan Wu, Liyuan Li, Joo-Hwee Lim</p></summary>
<p>

**Abstract:** When deploying a robot to a new task, one often has to train it to detect novel objects, which is time-consuming and labor-intensive. We present TAILOR -- a method and system for object registration with active and incremental learning. When instructed by a human teacher to register an object, TAILOR is able to automatically select viewpoints to capture informative images by actively exploring viewpoints, and employs a fast incremental learning algorithm to learn new objects without potential forgetting of previously learned objects. We demonstrate the effectiveness of our method with a KUKA robot to learn novel objects used in a real-world gearbox assembly task through natural interactions.

</p>
</details>

<details><summary><b>ImGCL: Revisiting Graph Contrastive Learning on Imbalanced Node Classification</b>
<a href="https://arxiv.org/abs/2205.11332">arxiv:2205.11332</a>
&#x1F4C8; 9 <br>
<p>Liang Zeng, Lanqing Li, Ziqi Gao, Peilin Zhao, Jian Li</p></summary>
<p>

**Abstract:** Graph contrastive learning (GCL) has attracted a surge of attention due to its superior performance for learning node/graph representations without labels. However, in practice, unlabeled nodes for the given graph usually follow an implicit imbalanced class distribution, where the majority of nodes belong to a small fraction of classes (a.k.a., head class) and the rest classes occupy only a few samples (a.k.a., tail classes). This highly imbalanced class distribution inevitably deteriorates the quality of learned node representations in GCL. Indeed, we empirically find that most state-of-the-art GCL methods exhibit poor performance on imbalanced node classification. Motivated by this observation, we propose a principled GCL framework on Imbalanced node classification (ImGCL), which automatically and adaptively balances the representation learned from GCL without knowing the labels. Our main inspiration is drawn from the recent progressively balanced sampling (PBS) method in the computer vision domain. We first introduce online clustering based PBS, which balances the training sets based on pseudo-labels obtained from learned representations. We then develop the node centrality based PBS method to better preserve the intrinsic structure of graphs, which highlight the important nodes of the given graph. Besides, we theoretically consolidate our method by proving that the classifier learned by balanced sampling without labels on an imbalanced dataset can converge to the optimal balanced classifier with a linear rate. Extensive experiments on multiple imbalanced graph datasets and imbalance settings verify the effectiveness of our proposed framework, which significantly improves the performance of the recent state-of-the-art GCL methods. Further experimental ablations and analysis show that the ImGCL framework remarkably improves the representations of nodes in tail classes.

</p>
</details>

<details><summary><b>KOLD: Korean Offensive Language Dataset</b>
<a href="https://arxiv.org/abs/2205.11315">arxiv:2205.11315</a>
&#x1F4C8; 9 <br>
<p>Younghoon Jeong, Juhyun Oh, Jaimeen Ahn, Jongwon Lee, Jihyung Mon, Sungjoon Park, Alice Oh</p></summary>
<p>

**Abstract:** Although large attention has been paid to the detection of hate speech, most work has been done in English, failing to make it applicable to other languages. To fill this gap, we present a Korean offensive language dataset (KOLD), 40k comments labeled with offensiveness, target, and targeted group information. We also collect two types of span, offensive and target span that justifies the decision of the categorization within the text. Comparing the distribution of targeted groups with the existing English dataset, we point out the necessity of a hate speech dataset fitted to the language that best reflects the culture. Trained with our dataset, we report the baseline performance of the models built on top of large pretrained language models. We also show that title information serves as context and is helpful to discern the target of hatred, especially when they are omitted in the comment.

</p>
</details>

<details><summary><b>Beyond EM Algorithm on Over-specified Two-Component Location-Scale Gaussian Mixtures</b>
<a href="https://arxiv.org/abs/2205.11078">arxiv:2205.11078</a>
&#x1F4C8; 9 <br>
<p>Tongzheng Ren, Fuheng Cui, Sujay Sanghavi, Nhat Ho</p></summary>
<p>

**Abstract:** The Expectation-Maximization (EM) algorithm has been predominantly used to approximate the maximum likelihood estimation of the location-scale Gaussian mixtures. However, when the models are over-specified, namely, the chosen number of components to fit the data is larger than the unknown true number of components, EM needs a polynomial number of iterations in terms of the sample size to reach the final statistical radius; this is computationally expensive in practice. The slow convergence of EM is due to the missing of the locally strong convexity with respect to the location parameter on the negative population log-likelihood function, i.e., the limit of the negative sample log-likelihood function when the sample size goes to infinity. To efficiently explore the curvature of the negative log-likelihood functions, by specifically considering two-component location-scale Gaussian mixtures, we develop the Exponential Location Update (ELU) algorithm. The idea of the ELU algorithm is that we first obtain the exact optimal solution for the scale parameter and then perform an exponential step-size gradient descent for the location parameter. We demonstrate theoretically and empirically that the ELU iterates converge to the final statistical radius of the models after a logarithmic number of iterations. To the best of our knowledge, it resolves the long-standing open question in the literature about developing an optimization algorithm that has optimal statistical and computational complexities for solving parameter estimation even under some specific settings of the over-specified Gaussian mixture models.

</p>
</details>

<details><summary><b>Thalamus: a brain-inspired algorithm for biologically-plausible continual learning and disentangled representations</b>
<a href="https://arxiv.org/abs/2205.11713">arxiv:2205.11713</a>
&#x1F4C8; 8 <br>
<p>Ali Hummos</p></summary>
<p>

**Abstract:** Animals thrive in a constantly changing environment and leverage the temporal structure to learn well-factorized causal representations. In contrast, traditional neural networks suffer from forgetting in changing environments and many methods have been proposed to limit forgetting with different trade-offs. Inspired by the brain thalamocortical circuit, we introduce a simple algorithm that uses optimization at inference time to generate internal representations of temporal context and to infer current context dynamically, allowing the agent to parse the stream of temporal experience into discrete events and organize learning about them. We show that a network trained on a series of tasks using traditional weight updates can infer tasks dynamically using gradient descent steps in the latent task embedding space (latent updates). We then alternate between the weight updates and the latent updates to arrive at Thalamus, a task-agnostic algorithm capable of discovering disentangled representations in a stream of unlabeled tasks using simple gradient descent. On a continual learning benchmark, it achieves competitive end average accuracy and demonstrates knowledge transfer. After learning a subset of tasks it can generalize to unseen tasks as they become reachable within the well-factorized latent space, through one-shot latent updates. The algorithm meets many of the desiderata of an ideal continually learning agent in open-ended environments, and its simplicity suggests fundamental computations in circuits with abundant feedback control loops such as the thalamocortical circuits in the brain.

</p>
</details>

<details><summary><b>Looking for a Handsome Carpenter! Debiasing GPT-3 Job Advertisements</b>
<a href="https://arxiv.org/abs/2205.11374">arxiv:2205.11374</a>
&#x1F4C8; 8 <br>
<p>Conrad Borchers, Dalia Sara Gala, Benjamin Gilburt, Eduard Oravkin, Wilfried Bounsi, Yuki M. Asano, Hannah Rose Kirk</p></summary>
<p>

**Abstract:** The growing capability and availability of generative language models has enabled a wide range of new downstream tasks. Academic research has identified, quantified and mitigated biases present in language models but is rarely tailored to downstream tasks where wider impact on individuals and society can be felt. In this work, we leverage one popular generative language model, GPT-3, with the goal of writing unbiased and realistic job advertisements. We first assess the bias and realism of zero-shot generated advertisements and compare them to real-world advertisements. We then evaluate prompt-engineering and fine-tuning as debiasing methods. We find that prompt-engineering with diversity-encouraging prompts gives no significant improvement to bias, nor realism. Conversely, fine-tuning, especially on unbiased real advertisements, can improve realism and reduce bias.

</p>
</details>

<details><summary><b>ScholarBERT: Bigger is Not Always Better</b>
<a href="https://arxiv.org/abs/2205.11342">arxiv:2205.11342</a>
&#x1F4C8; 8 <br>
<p>Zhi Hong, Aswathy Ajith, Gregory Pauloski, Eamon Duede, Carl Malamud, Roger Magoulas, Kyle Chard, Ian Foster</p></summary>
<p>

**Abstract:** Transformer-based masked language models trained on general corpora, such as BERT and RoBERTa, have shown impressive performance on various downstream tasks. Increasingly, researchers are "finetuning" these models to improve performance on domain-specific tasks. Here, we report a broad study in which we applied 14 transformer-based models to 11 scientific tasks in order to evaluate how downstream performance is affected by changes along various dimensions (e.g., training data, model size, pretraining time, finetuning length). In this process, we created the largest and most diverse scientific language model to date, ScholarBERT, by training a 770M-parameter BERT model on an 221B token scientific literature dataset spanning many disciplines. Counterintuitively, our evaluation of the 14 BERT-based models (seven versions of ScholarBERT, five science-specific large language models from the literature, BERT-Base, and BERT-Large) reveals little difference in performance across the 11 science-focused tasks, despite major differences in model size and training data. We argue that our results establish an upper bound for the performance achievable with BERT-based architectures on tasks from the scientific domain.

</p>
</details>

<details><summary><b>PEVL: Position-enhanced Pre-training and Prompt Tuning for Vision-language Models</b>
<a href="https://arxiv.org/abs/2205.11169">arxiv:2205.11169</a>
&#x1F4C8; 8 <br>
<p>Yuan Yao, Qianyu Chen, Ao Zhang, Wei Ji, Zhiyuan Liu, Tat-Seng Chua, Maosong Sun</p></summary>
<p>

**Abstract:** Vision-language pre-training (VLP) has shown impressive performance on a wide range of cross-modal tasks, where VLP models without reliance on object detectors are becoming the mainstream due to their superior computation efficiency and competitive performance. However, the removal of object detectors also deprives the capability of VLP models in explicit object modeling, which is essential to various position-sensitive vision-language (VL) tasks, such as referring expression comprehension and visual commonsense reasoning. To address the challenge, we introduce PEVL that enhances the pre-training and prompt tuning of VLP models with explicit object position modeling. Specifically, PEVL reformulates discretized object positions and language in a unified language modeling framework, which facilitates explicit VL alignment during pre-training, and also enables flexible prompt tuning for various downstream tasks. We show that PEVL enables state-of-the-art performance of detector-free VLP models on position-sensitive tasks such as referring expression comprehension and phrase grounding, and also improves the performance on position-insensitive tasks with grounded inputs. We make the data and code for this paper publicly available at https://github.com/thunlp/PEVL.

</p>
</details>

<details><summary><b>UMSNet: An Universal Multi-sensor Network for Human Activity Recognition</b>
<a href="https://arxiv.org/abs/2205.11756">arxiv:2205.11756</a>
&#x1F4C8; 7 <br>
<p>Jialiang Wang, Haotian Wei, Yi Wang, Shu Yang, Chi Li</p></summary>
<p>

**Abstract:** Human activity recognition (HAR) based on multimodal sensors has become a rapidly growing branch of biometric recognition and artificial intelligence. However, how to fully mine multimodal time series data and effectively learn accurate behavioral features has always been a hot topic in this field. Practical applications also require a well-generalized framework that can quickly process a variety of raw sensor data and learn better feature representations. This paper proposes a universal multi-sensor network (UMSNet) for human activity recognition. In particular, we propose a new lightweight sensor residual block (called LSR block), which improves the performance by reducing the number of activation function and normalization layers, and adding inverted bottleneck structure and grouping convolution. Then, the Transformer is used to extract the relationship of series features to realize the classification and recognition of human activities. Our framework has a clear structure and can be directly applied to various types of multi-modal Time Series Classification (TSC) tasks after simple specialization. Extensive experiments show that the proposed UMSNet outperforms other state-of-the-art methods on two popular multi-sensor human activity recognition datasets (i.e. HHAR dataset and MHEALTH dataset).

</p>
</details>

<details><summary><b>High-Order Pooling for Graph Neural Networks with Tensor Decomposition</b>
<a href="https://arxiv.org/abs/2205.11691">arxiv:2205.11691</a>
&#x1F4C8; 7 <br>
<p>Chenqing Hua, Guillaume Rabusseau, Jian Tang</p></summary>
<p>

**Abstract:** Graph Neural Networks (GNNs) are attracting growing attention due to their effectiveness and flexibility in modeling a variety of graph-structured data. Exiting GNN architectures usually adopt simple pooling operations (e.g., sum, average, max) when aggregating messages from a local neighborhood for updating node representation or pooling node representations from the entire graph to compute the graph representation. Though simple and effective, these linear operations do not model high-order non-linear interactions among nodes. We propose the Tensorized Graph Neural Network (tGNN), a highly expressive GNN architecture relying on tensor decomposition to model high-order non-linear node interactions. tGNN leverages the symmetric CP decomposition to efficiently parameterize permutation-invariant multilinear maps for modeling node interactions. Theoretical and empirical analysis on both node and graph classification tasks show the superiority of tGNN over competitive baselines. In particular, tGNN achieves state-of-the-art results on two OGB node classification datasets and one OGB graph classification dataset.

</p>
</details>

<details><summary><b>Learning multi-scale functional representations of proteins from single-cell microscopy data</b>
<a href="https://arxiv.org/abs/2205.11676">arxiv:2205.11676</a>
&#x1F4C8; 7 <br>
<p>Anastasia Razdaibiedina, Alexander Brechalov</p></summary>
<p>

**Abstract:** Protein function is inherently linked to its localization within the cell, and fluorescent microscopy data is an indispensable resource for learning representations of proteins. Despite major developments in molecular representation learning, extracting functional information from biological images remains a non-trivial computational task. Current state-of-the-art approaches use autoencoder models to learn high-quality features by reconstructing images. However, such methods are prone to capturing noise and imaging artifacts. In this work, we revisit deep learning models used for classifying major subcellular localizations, and evaluate representations extracted from their final layers. We show that simple convolutional networks trained on localization classification can learn protein representations that encapsulate diverse functional information, and significantly outperform autoencoder-based models. We also propose a robust evaluation strategy to assess quality of protein representations across different scales of biological function.

</p>
</details>

<details><summary><b>From Hours to Seconds: Towards 100x Faster Quantitative Phase Imaging via Differentiable Microscopy</b>
<a href="https://arxiv.org/abs/2205.11521">arxiv:2205.11521</a>
&#x1F4C8; 7 <br>
<p>Udith Haputhanthri, Kithmini Herath, Ramith Hettiarachchi, Hasindu Kariyawasam, Azeem Ahmad, Balpreet S. Ahluwalia, Chamira U. S. Edussooriya, Dushan N. Wadduwage</p></summary>
<p>

**Abstract:** With applications ranging from metabolomics to histopathology, quantitative phase microscopy (QPM) is a powerful label-free imaging modality. Despite significant advances in fast multiplexed imaging sensors and deep-learning-based inverse solvers, the throughput of QPM is currently limited by the speed of electronic hardware. Complementarily, to improve throughput further, here we propose to acquire images in a compressed form such that more information can be transferred beyond the existing electronic hardware bottleneck. To this end, we present a learnable optical compression-decompression framework that learns content-specific features. The proposed differentiable optical-electronic quantitative phase microscopy ($\partial μ$) first uses learnable optical feature extractors as image compressors. The intensity representation produced by these networks is then captured by the imaging sensor. Finally, a reconstruction network running on electronic hardware decompresses the QPM images. The proposed system achieves compression of $\times$ 64 while maintaining the SSIM of $\sim 0.90$ and PSNR of $\sim 30$ dB. The promising results demonstrated by our experiments open up a new pathway for achieving end-to-end optimized (i.e., optics and electronic) compact QPM systems that provide unprecedented throughput improvements.

</p>
</details>

<details><summary><b>Outliers Dimensions that Disrupt Transformers Are Driven by Frequency</b>
<a href="https://arxiv.org/abs/2205.11380">arxiv:2205.11380</a>
&#x1F4C8; 7 <br>
<p>Giovanni Puccetti, Anna Rogers, Aleksandr Drozd, Felice Dell'Orletta</p></summary>
<p>

**Abstract:** Transformer-based language models are known to display anisotropic behavior: the token embeddings are not homogeneously spread in space, but rather accumulate along certain directions. A related recent finding is the outlier phenomenon: the parameters in the final element of Transformer layers that consistently have unusual magnitude in the same dimension across the model, and significantly degrade its performance if disabled. We replicate the evidence for the outlier phenomenon and we link it to the geometry of the embedding space. Our main finding is that in both BERT and RoBERTa the token frequency, known to contribute to anisotropicity, also contributes to the outlier phenomenon. In its turn, the outlier phenomenon contributes to the "vertical" self-attention pattern that enables the model to focus on the special tokens. We also find that, surprisingly, the outlier effect on the model performance varies by layer, and that variance is also related to the correlation between outlier magnitude and encoded token frequency.

</p>
</details>

<details><summary><b>A Survey of Research on Fair Recommender Systems</b>
<a href="https://arxiv.org/abs/2205.11127">arxiv:2205.11127</a>
&#x1F4C8; 7 <br>
<p>Yashar Deldjoo, Dietmar Jannach, Alejandro Bellogin, Alessandro Difonzo, Dario Zanzonelli</p></summary>
<p>

**Abstract:** Recommender systems can strongly influence which information we see online, e.g, on social media, and thus impact our beliefs, decisions, and actions. At the same time, these systems can create substantial business value for different stakeholders. Given the growing potential impact of such AI-based systems on individuals, organizations, and society, questions of fairness have gained increased attention in recent years. However, research on fairness in recommender systems is still a developing area. In this survey, we first review the fundamental concepts and notions of fairness that were put forward in the area in the recent past. Afterward, we provide a survey of how research in this area is currently operationalized, for example, in terms of the general research methodology, fairness metrics, and algorithmic approaches. Overall, our analysis of recent works points to certain research gaps. In particular, we find that in many research works in computer science very abstract problem operationalizations are prevalent, which circumvent the fundamental and important question of what represents a fair recommendation in the context of a given application.

</p>
</details>

<details><summary><b>Soft-SVM Regression For Binary Classification</b>
<a href="https://arxiv.org/abs/2205.11735">arxiv:2205.11735</a>
&#x1F4C8; 6 <br>
<p>Man Huang, Luis Carvalho</p></summary>
<p>

**Abstract:** The binomial deviance and the SVM hinge loss functions are two of the most widely used loss functions in machine learning. While there are many similarities between them, they also have their own strengths when dealing with different types of data. In this work, we introduce a new exponential family based on a convex relaxation of the hinge loss function using softness and class-separation parameters. This new family, denoted Soft-SVM, allows us to prescribe a generalized linear model that effectively bridges between logistic regression and SVM classification. This new model is interpretable and avoids data separability issues, attaining good fitting and predictive performance by automatically adjusting for data label separability via the softness parameter. These results are confirmed empirically through simulations and case studies as we compare regularized logistic, SVM, and Soft-SVM regressions and conclude that the proposed model performs well in terms of both classification and prediction errors.

</p>
</details>

<details><summary><b>Quasi Black-Box Variational Inference with Natural Gradients for Bayesian Learning</b>
<a href="https://arxiv.org/abs/2205.11568">arxiv:2205.11568</a>
&#x1F4C8; 6 <br>
<p>Martin Magris, Mostafa Shabani, Alexandros Iosifidis</p></summary>
<p>

**Abstract:** We develop an optimization algorithm suitable for Bayesian learning in complex models. Our approach relies on natural gradient updates within a general black-box framework for efficient training with limited model-specific derivations. It applies within the class of exponential-family variational posterior distributions, for which we extensively discuss the Gaussian case for which the updates have a rather simple form. Our Quasi Black-box Variational Inference (QBVI) framework is readily applicable to a wide class of Bayesian inference problems and is of simple implementation as the updates of the variational posterior do not involve gradients with respect to the model parameters, nor the prescription of the Fisher information matrix. We develop QBVI under different hypotheses for the posterior covariance matrix, discuss details about its robust and feasible implementation, and provide a number of real-world applications to demonstrate its effectiveness.

</p>
</details>

<details><summary><b>Logical Reasoning with Span Predictions: Span-level Logical Atoms for Interpretable and Robust NLI Models</b>
<a href="https://arxiv.org/abs/2205.11432">arxiv:2205.11432</a>
&#x1F4C8; 6 <br>
<p>Joe Stacey, Pasquale Minervini, Haim Dubossarsky, Marek Rei</p></summary>
<p>

**Abstract:** Current Natural Language Inference (NLI) models achieve impressive results, sometimes outperforming humans when evaluating on in-distribution test sets. However, as these models are known to learn from annotation artefacts and dataset biases, it is unclear to what extent the models are learning the task of NLI instead of learning from shallow heuristics in their training data. We address this issue by introducing a logical reasoning framework for NLI, creating highly transparent model decisions that are based on logical rules. Unlike prior work, we show that the improved interpretability can be achieved without decreasing the predictive accuracy. We almost fully retain performance on SNLI while identifying the exact hypothesis spans that are responsible for each model prediction. Using the e-SNLI human explanations, we also verify that our model makes sensible decisions at a span level, despite not using any span-level labels during training. We can further improve model performance and the span-level decisions by using the e-SNLI explanations during training. Finally, our model outperforms its baseline in a reduced data setting. When training with only 100 examples, in-distribution performance improves by 18%, while out-of-distribution performance improves on SNLI-hard, MNLI-mismatched, MNLI-matched and SICK by 11%, 26%, 22%, and 21% respectively.

</p>
</details>

<details><summary><b>FedNorm: Modality-Based Normalization in Federated Learning for Multi-Modal Liver Segmentation</b>
<a href="https://arxiv.org/abs/2205.11096">arxiv:2205.11096</a>
&#x1F4C8; 6 <br>
<p>Tobias Bernecker, Annette Peters, Christopher L. Schlett, Fabian Bamberg, Fabian Theis, Daniel Rueckert, Jakob Weiß, Shadi Albarqouni</p></summary>
<p>

**Abstract:** Given the high incidence and effective treatment options for liver diseases, they are of great socioeconomic importance. One of the most common methods for analyzing CT and MRI images for diagnosis and follow-up treatment is liver segmentation. Recent advances in deep learning have demonstrated encouraging results for automatic liver segmentation. Despite this, their success depends primarily on the availability of an annotated database, which is often not available because of privacy concerns. Federated Learning has been recently proposed as a solution to alleviate these challenges by training a shared global model on distributed clients without access to their local databases. Nevertheless, Federated Learning does not perform well when it is trained on a high degree of heterogeneity of image data due to multi-modal imaging, such as CT and MRI, and multiple scanner types. To this end, we propose Fednorm and its extension \fednormp, two Federated Learning algorithms that use a modality-based normalization technique. Specifically, Fednorm normalizes the features on a client-level, while Fednorm+ employs the modality information of single slices in the feature normalization. Our methods were validated using 428 patients from six publicly available databases and compared to state-of-the-art Federated Learning algorithms and baseline models in heterogeneous settings (multi-institutional, multi-modal data). The experimental results demonstrate that our methods show an overall acceptable performance, achieve Dice per patient scores up to 0.961, consistently outperform locally trained models, and are on par or slightly better than centralized models.

</p>
</details>

<details><summary><b>Adaptive Few-Shot Learning Algorithm for Rare Sound Event Detection</b>
<a href="https://arxiv.org/abs/2205.11738">arxiv:2205.11738</a>
&#x1F4C8; 5 <br>
<p>Chendong Zhao, Jianzong Wang, Leilai Li, Xiaoyang Qu, Jing Xiao</p></summary>
<p>

**Abstract:** Sound event detection is to infer the event by understanding the surrounding environmental sounds. Due to the scarcity of rare sound events, it becomes challenging for the well-trained detectors which have learned too much prior knowledge. Meanwhile, few-shot learning methods promise a good generalization ability when facing a new limited-data task. Recent approaches have achieved promising results in this field. However, these approaches treat each support example independently, ignoring the information of other examples from the whole task. Because of this, most of previous methods are constrained to generate a same feature embedding for all test-time tasks, which is not adaptive to each inputted data. In this work, we propose a novel task-adaptive module which is easy to plant into any metric-based few-shot learning frameworks. The module could identify the task-relevant feature dimension. Incorporating our module improves the performance considerably on two datasets over baseline methods, especially for the transductive propagation network. Such as +6.8% for 5-way 1-shot accuracy on ESC-50, and +5.9% on noiseESC-50. We investigate our approach in the domain-mismatch setting and also achieve better results than previous methods.

</p>
</details>

<details><summary><b>On the Role of Bidirectionality in Language Model Pre-Training</b>
<a href="https://arxiv.org/abs/2205.11726">arxiv:2205.11726</a>
&#x1F4C8; 5 <br>
<p>Mikel Artetxe, Jingfei Du, Naman Goyal, Luke Zettlemoyer, Ves Stoyanov</p></summary>
<p>

**Abstract:** Prior work on language model pre-training has explored different architectures and learning objectives, but differences in data, hyperparameters and evaluation make a principled comparison difficult. In this work, we focus on bidirectionality as a key factor that differentiates existing approaches, and present a comprehensive study of its role in next token prediction, text infilling, zero-shot priming and fine-tuning. We propose a new framework that generalizes prior approaches, including fully unidirectional models like GPT, fully bidirectional models like BERT, and hybrid models like CM3 and prefix LM. Our framework distinguishes between two notions of bidirectionality (bidirectional context and bidirectional attention) and allows us to control each of them separately. We find that the optimal configuration is largely application-dependent (e.g., bidirectional attention is beneficial for fine-tuning and infilling, but harmful for next token prediction and zero-shot priming). We train models with up to 6.7B parameters, and find differences to remain consistent at scale. While prior work on scaling has focused on left-to-right autoregressive models, our results suggest that this approach comes with some trade-offs, and it might be worthwhile to develop very large bidirectional models.

</p>
</details>

<details><summary><b>Randomly Initialized One-Layer Neural Networks Make Data Linearly Separable</b>
<a href="https://arxiv.org/abs/2205.11716">arxiv:2205.11716</a>
&#x1F4C8; 5 <br>
<p>Promit Ghosal, Srinath Mahankali, Yihang Sun</p></summary>
<p>

**Abstract:** Recently, neural networks have been shown to perform exceptionally well in transforming two arbitrary sets into two linearly separable sets. Doing this with a randomly initialized neural network is of immense interest because the associated computation is cheaper than using fully trained networks. In this paper, we show that, with sufficient width, a randomly initialized one-layer neural network transforms two sets into two linearly separable sets with high probability. Furthermore, we provide explicit bounds on the required width of the neural network for this to occur. Our first bound is exponential in the input dimension and polynomial in all other parameters, while our second bound is independent of the input dimension, thereby overcoming the curse of dimensionality. We also perform an experimental study comparing the separation capacity of randomly initialized one-layer and two-layer neural networks. With correctly chosen biases, our study shows for low-dimensional data, the two-layer neural network outperforms the one-layer network. However, the opposite is observed for higher-dimensional data.

</p>
</details>

<details><summary><b>Generalization Gap in Amortized Inference</b>
<a href="https://arxiv.org/abs/2205.11640">arxiv:2205.11640</a>
&#x1F4C8; 5 <br>
<p>Mingtian Zhang, Peter Hayes, David Barber</p></summary>
<p>

**Abstract:** The ability of likelihood-based probabilistic models to generalize to unseen data is central to many machine learning applications such as lossless compression. In this work, we study the generalizations of a popular class of probabilistic models - the Variational Auto-Encoder (VAE). We point out the two generalization gaps that can affect the generalization ability of VAEs and show that the over-fitting phenomenon is usually dominated by the amortized inference network. Based on this observation we propose a new training objective, inspired by the classic wake-sleep algorithm, to improve the generalizations properties of amortized inference. We also demonstrate how it can improve generalization performance in the context of image modeling and lossless compression.

</p>
</details>

<details><summary><b>VQA-GNN: Reasoning with Multimodal Semantic Graph for Visual Question Answering</b>
<a href="https://arxiv.org/abs/2205.11501">arxiv:2205.11501</a>
&#x1F4C8; 5 <br>
<p>Yanan Wang, Michihiro Yasunaga, Hongyu Ren, Shinya Wada, Jure Leskovec</p></summary>
<p>

**Abstract:** Visual understanding requires seamless integration between recognition and reasoning: beyond image-level recognition (e.g., detecting objects), systems must perform concept-level reasoning (e.g., inferring the context of objects and intents of people). However, existing methods only model the image-level features, and do not ground them and reason with background concepts such as knowledge graphs (KGs). In this work, we propose a novel visual question answering method, VQA-GNN, which unifies the image-level information and conceptual knowledge to perform joint reasoning of the scene. Specifically, given a question-image pair, we build a scene graph from the image, retrieve a relevant linguistic subgraph from ConceptNet and visual subgraph from VisualGenome, and unify these three graphs and the question into one joint graph, multimodal semantic graph. Our VQA-GNN then learns to aggregate messages and reason across different modalities captured by the multimodal semantic graph. In the evaluation on the VCR task, our method outperforms the previous scene graph-based Trans-VL models by over 4%, and VQA-GNN-Large, our model that fuses a Trans-VL further improves the state of the art by 2%, attaining the top of the VCR leaderboard at the time of submission. This result suggests the efficacy of our model in performing conceptual reasoning beyond image-level recognition for visual understanding. Finally, we demonstrate that our model is the first work to provide interpretability across visual and textual knowledge domains for the VQA task.

</p>
</details>

<details><summary><b>Deep-learning-based prediction of nanoparticle phase transitions during in situ transmission electron microscopy</b>
<a href="https://arxiv.org/abs/2205.11407">arxiv:2205.11407</a>
&#x1F4C8; 5 <br>
<p>Wenkai Fu, Steven R. Spurgeon, Chongmin Wang, Yuyan Shao, Wei Wang, Amra Peles</p></summary>
<p>

**Abstract:** We develop the machine learning capability to predict a time sequence of in-situ transmission electron microscopy (TEM) video frames based on the combined long-short-term-memory (LSTM) algorithm and the features de-entanglement method. We train deep learning models to predict a sequence of future video frames based on the input of a sequence of previous frames. This unique capability provides insight into size dependent structural changes in Au nanoparticles under dynamic reaction condition using in-situ environmental TEM data, informing models of morphological evolution and catalytic properties. The model performance and achieved accuracy of predictions are desirable based on, for scientific data characteristic, based on limited size of training data sets. The model convergence and values for the loss function mean square error show dependence on the training strategy, and structural similarity measure between predicted structure images and ground truth reaches the value of about 0.7. This computed structural similarity is smaller than values obtained when the deep learning architecture is trained using much larger benchmark data sets, it is sufficient to show the structural transition of Au nanoparticles. While performance parameters of our model applied to scientific data fall short of those achieved for the non-scientific big data sets, we demonstrate model ability to predict the evolution, even including the particle structural phase transformation, of Au nano particles as catalyst for CO oxidation under the chemical reaction conditions. Using this approach, it may be possible to anticipate the next steps of a chemical reaction for emerging automated experimentation platforms.

</p>
</details>

<details><summary><b>Fine-Grained Counting with Crowd-Sourced Supervision</b>
<a href="https://arxiv.org/abs/2205.11398">arxiv:2205.11398</a>
&#x1F4C8; 5 <br>
<p>Justin Kay, Catherine M. Foley, Tom Hart</p></summary>
<p>

**Abstract:** Crowd-sourcing is an increasingly popular tool for image analysis in animal ecology. Computer vision methods that can utilize crowd-sourced annotations can help scale up analysis further. In this work we study the potential to do so on the challenging task of fine-grained counting. As opposed to the standard crowd counting task, fine-grained counting also involves classifying attributes of individuals in dense crowds. We introduce a new dataset from animal ecology to enable this study that contains 1.7M crowd-sourced annotations of 8 fine-grained classes. It is the largest available dataset for fine-grained counting and the first to enable the study of the task with crowd-sourced annotations. We introduce methods for generating aggregate "ground truths" from the collected annotations, as well as a counting method that can utilize the aggregate information. Our method improves results by 8% over a comparable baseline, indicating the potential for algorithms to learn fine-grained counting using crowd-sourced supervision.

</p>
</details>

<details><summary><b>Markedness in Visual Semantic AI</b>
<a href="https://arxiv.org/abs/2205.11378">arxiv:2205.11378</a>
&#x1F4C8; 5 <br>
<p>Robert Wolfe, Aylin Caliskan</p></summary>
<p>

**Abstract:** We evaluate the state-of-the-art multimodal "visual semantic" model CLIP ("Contrastive Language Image Pretraining") for biases related to the marking of age, gender, and race or ethnicity. Given the option to label an image as "a photo of a person" or to select a label denoting race or ethnicity, CLIP chooses the "person" label 47.9% of the time for White individuals, compared with 5.0% or less for individuals who are Black, East Asian, Southeast Asian, Indian, or Latino or Hispanic. The model is more likely to rank the unmarked "person" label higher than labels denoting gender for Male individuals (26.7% of the time) vs. Female individuals (15.2% of the time). Age affects whether an individual is marked by the model: Female individuals under the age of 20 are more likely than Male individuals to be marked with a gender label, but less likely to be marked with an age label, while Female individuals over the age of 40 are more likely to be marked based on age than Male individuals. We also examine the self-similarity (mean pairwise cosine similarity) for each social group, where higher self-similarity denotes greater attention directed by CLIP to the shared characteristics (age, race, or gender) of the social group. As age increases, the self-similarity of representations of Female individuals increases at a higher rate than for Male individuals, with the disparity most pronounced at the "more than 70" age range. All ten of the most self-similar social groups are individuals under the age of 10 or over the age of 70, and six of the ten are Female individuals. Existing biases of self-similarity and markedness between Male and Female gender groups are further exacerbated when the groups compared are individuals who are White and Male and individuals who are Black and Female. Results indicate that CLIP reflects the biases of the language and society which produced its training data.

</p>
</details>

<details><summary><b>Non-Parametric Domain Adaptation for End-to-End Speech Translation</b>
<a href="https://arxiv.org/abs/2205.11211">arxiv:2205.11211</a>
&#x1F4C8; 5 <br>
<p>Yichao Du, Weizhi Wang, Zhirui Zhang, Boxing Chen, Tong Xu, Jun Xie, Enhong Chen</p></summary>
<p>

**Abstract:** End-to-End Speech Translation (E2E-ST) has received increasing attention due to the potential of its less error propagation, lower latency, and fewer parameters. However, the effectiveness of neural-based approaches to this task is severely limited by the available training corpus, especially for domain adaptation where in-domain triplet training data is scarce or nonexistent. In this paper, we propose a novel non-parametric method that leverages domain-specific text translation corpus to achieve domain adaptation for the E2E-ST system. To this end, we first incorporate an additional encoder into the pre-trained E2E-ST model to realize text translation modelling, and then unify the decoder's output representation for text and speech translation tasks by reducing the correspondent representation mismatch in available triplet training data. During domain adaptation, a k-nearest-neighbor (kNN) classifier is introduced to produce the final translation distribution using the external datastore built by the domain-specific text translation corpus, while the universal output representation is adopted to perform a similarity search. Experiments on the Europarl-ST benchmark demonstrate that when in-domain text translation data is involved only, our proposed approach significantly improves baseline by 12.82 BLEU on average in all translation directions, even outperforming the strong in-domain fine-tuning method.

</p>
</details>

<details><summary><b>Meta-Learning Regrasping Strategies for Physical-Agnostic Objects</b>
<a href="https://arxiv.org/abs/2205.11110">arxiv:2205.11110</a>
&#x1F4C8; 5 <br>
<p>Ruijie Chen, Ning Gao, Ngo Anh Vien, Hanna Ziesche, Gerhard Neumann</p></summary>
<p>

**Abstract:** Grasping inhomogeneous objects, practical use in real-world applications, remains a challenging task due to the unknown physical properties such as mass distribution and coefficient of friction. In this study, we propose a vision-based meta-learning algorithm to learn physical properties in an agnostic way. In particular, we employ Conditional Neural Processes (CNPs) on top of DexNet-2.0. CNPs learn physical embeddings rapidly from a few observations where each observation is composed of i) the cropped depth image, ii) the grasping height between the gripper and estimated grasping point, and iii) the binary grasping result. Our modified conditional DexNet-2.0 (DexNet-CNP) updates the predicted grasping quality iteratively from new observations, which can be executed in an online fashion. We evaluate our method in the Pybullet simulator using various shape primitive objects with different physical parameters. The results show that our model outperforms the original DexNet-2.0 and is able to generalize on unseen objects with different shapes.

</p>
</details>

<details><summary><b>Falsification of Multiple Requirements for Cyber-Physical Systems Using Online Generative Adversarial Networks and Multi-Armed Bandits</b>
<a href="https://arxiv.org/abs/2205.11057">arxiv:2205.11057</a>
&#x1F4C8; 5 <br>
<p>Jarkko Peltomäki, Ivan Porres</p></summary>
<p>

**Abstract:** We consider the problem of falsifying safety requirements of Cyber-Physical Systems expressed in signal temporal logic (STL). This problem can be turned into an optimization problem via STL robustness functions. In this paper, our focus is in falsifying systems with multiple requirements. We propose to solve such conjunctive requirements using online generative adversarial networks (GANs) as test generators. Our main contribution is an algorithm which falsifies a conjunctive requirement $\varphi_1 \land \cdots \land \varphi_n$ by using a GAN for each requirement $\varphi_i$ separately. Using ideas from multi-armed bandit algorithms, our algorithm only trains a single GAN at every step, which saves resources. Our experiments indicate that, in addition to saving resources, this multi-armed bandit algorithm can falsify requirements with fewer number of executions on the system under test when compared to (i) an algorithm training a single GAN for the complete conjunctive requirement and (ii) an algorithm always training $n$ GANs at each step.

</p>
</details>

<details><summary><b>Training Efficient CNNS: Tweaking the Nuts and Bolts of Neural Networks for Lighter, Faster and Robust Models</b>
<a href="https://arxiv.org/abs/2205.12050">arxiv:2205.12050</a>
&#x1F4C8; 4 <br>
<p>Sabeesh Ethiraj, Bharath Kumar Bolla</p></summary>
<p>

**Abstract:** Deep Learning has revolutionized the fields of computer vision, natural language understanding, speech recognition, information retrieval and more. Many techniques have evolved over the past decade that made models lighter, faster, and robust with better generalization. However, many deep learning practitioners persist with pre-trained models and architectures trained mostly on standard datasets such as Imagenet, MS-COCO, IMDB-Wiki Dataset, and Kinetics-700 and are either hesitant or unaware of redesigning the architecture from scratch that will lead to better performance. This scenario leads to inefficient models that are not suitable on various devices such as mobile, edge, and fog. In addition, these conventional training methods are of concern as they consume a lot of computing power. In this paper, we revisit various SOTA techniques that deal with architecture efficiency (Global Average Pooling, depth-wise convolutions & squeeze and excitation, Blurpool), learning rate (Cyclical Learning Rate), data augmentation (Mixup, Cutout), label manipulation (label smoothing), weight space manipulation (stochastic weight averaging), and optimizer (sharpness aware minimization). We demonstrate how an efficient deep convolution network can be built in a phased manner by sequentially reducing the number of training parameters and using the techniques mentioned above. We achieved a SOTA accuracy of 99.2% on MNIST data with just 1500 parameters and an accuracy of 86.01% with just over 140K parameters on the CIFAR-10 dataset.

</p>
</details>

<details><summary><b>Constrained Monotonic Neural Networks</b>
<a href="https://arxiv.org/abs/2205.11775">arxiv:2205.11775</a>
&#x1F4C8; 4 <br>
<p>Davor Runje, Sharath M. Shankaranarayana</p></summary>
<p>

**Abstract:** Deep neural networks are becoming increasingly popular in approximating arbitrary functions from noisy data. But wider adoption is being hindered by the need to explain such models and to impose additional constraints on them. Monotonicity constraint is one of the most requested properties in real-world scenarios and is the focus of this paper. One of the oldest ways to construct a monotonic fully connected neural network is to constrain its weights to be non-negative while employing a monotonic activation function. Unfortunately, this construction does not work with popular non-saturated activation functions such as ReLU, ELU, SELU etc, as it can only approximate convex functions. We show this shortcoming can be fixed by employing the original activation function for a part of the neurons in the layer, and employing its point reflection for the other part. Our experiments show this approach of building monotonic deep neural networks have matching or better accuracy when compared to other state-of-the-art methods such as deep lattice networks or monotonic networks obtained by heuristic regularization. This method is the simplest one in the sense of having the least number of parameters, not requiring any modifications to the learning procedure or steps post-learning steps.

</p>
</details>

<details><summary><b>Byzantine-Robust Federated Learning with Optimal Statistical Rates and Privacy Guarantees</b>
<a href="https://arxiv.org/abs/2205.11765">arxiv:2205.11765</a>
&#x1F4C8; 4 <br>
<p>Banghua Zhu, Lun Wang, Qi Pang, Shuai Wang, Jiantao Jiao, Dawn Song, Michael I. Jordan</p></summary>
<p>

**Abstract:** We propose Byzantine-robust federated learning protocols with nearly optimal statistical rates. In contrast to prior work, our proposed protocols improve the dimension dependence and achieve a tight statistical rate in terms of all the parameters for strongly convex losses. We benchmark against competing protocols and show the empirical superiority of the proposed protocols. Finally, we remark that our protocols with bucketing can be naturally combined with privacy-guaranteeing procedures to introduce security against a semi-honest server. The code for evaluation is provided in https://github.com/wanglun1996/secure-robust-federated-learning.

</p>
</details>

<details><summary><b>Alleviating Robust Overfitting of Adversarial Training With Consistency Regularization</b>
<a href="https://arxiv.org/abs/2205.11744">arxiv:2205.11744</a>
&#x1F4C8; 4 <br>
<p>Shudong Zhang, Haichang Gao, Tianwei Zhang, Yunyi Zhou, Zihui Wu</p></summary>
<p>

**Abstract:** Adversarial training (AT) has proven to be one of the most effective ways to defend Deep Neural Networks (DNNs) against adversarial attacks. However, the phenomenon of robust overfitting, i.e., the robustness will drop sharply at a certain stage, always exists during AT. It is of great importance to decrease this robust generalization gap in order to obtain a robust model. In this paper, we present an in-depth study towards the robust overfitting from a new angle. We observe that consistency regularization, a popular technique in semi-supervised learning, has a similar goal as AT and can be used to alleviate robust overfitting. We empirically validate this observation, and find a majority of prior solutions have implicit connections to consistency regularization. Motivated by this, we introduce a new AT solution, which integrates the consistency regularization and Mean Teacher (MT) strategy into AT. Specifically, we introduce a teacher model, coming from the average weights of the student models over the training steps. Then we design a consistency loss function to make the prediction distribution of the student models over adversarial examples consistent with that of the teacher model over clean samples. Experiments show that our proposed method can effectively alleviate robust overfitting and improve the robustness of DNN models against common adversarial attacks.

</p>
</details>

<details><summary><b>Towards a Defense against Backdoor Attacks in Continual Federated Learning</b>
<a href="https://arxiv.org/abs/2205.11736">arxiv:2205.11736</a>
&#x1F4C8; 4 <br>
<p>Shuaiqi Wang, Jonathan Hayase, Giulia Fanti, Sewoong Oh</p></summary>
<p>

**Abstract:** Backdoor attacks are a major concern in federated learning (FL) pipelines where training data is sourced from untrusted clients over long periods of time (i.e., continual learning). Preventing such attacks is difficult because defenders in FL do not have access to raw training data. Moreover, in a phenomenon we call backdoor leakage, models trained continuously eventually suffer from backdoors due to cumulative errors in backdoor defense mechanisms. We propose a novel framework for defending against backdoor attacks in the federated continual learning setting. Our framework trains two models in parallel: a backbone model and a shadow model. The backbone is trained without any defense mechanism to obtain good performance on the main task. The shadow model combines recent ideas from robust covariance estimation-based filters with early-stopping to control the attack success rate even as the data distribution changes. We provide theoretical motivation for this design and show experimentally that our framework significantly improves upon existing defenses against backdoor attacks.

</p>
</details>

<details><summary><b>M6-Fashion: High-Fidelity Multi-modal Image Generation and Editing</b>
<a href="https://arxiv.org/abs/2205.11705">arxiv:2205.11705</a>
&#x1F4C8; 4 <br>
<p>Zhikang Li, Huiling Zhou, Shuai Bai, Peike Li, Chang Zhou, Hongxia Yang</p></summary>
<p>

**Abstract:** The fashion industry has diverse applications in multi-modal image generation and editing. It aims to create a desired high-fidelity image with the multi-modal conditional signal as guidance. Most existing methods learn different condition guidance controls by introducing extra models or ignoring the style prior knowledge, which is difficult to handle multiple signal combinations and faces a low-fidelity problem. In this paper, we adapt both style prior knowledge and flexibility of multi-modal control into one unified two-stage framework, M6-Fashion, focusing on the practical AI-aided Fashion design. It decouples style codes in both spatial and semantic dimensions to guarantee high-fidelity image generation in the first stage. M6-Fashion utilizes self-correction for the non-autoregressive generation to improve inference speed, enhance holistic consistency, and support various signal controls. Extensive experiments on a large-scale clothing dataset M2C-Fashion demonstrate superior performances on various image generation and editing tasks. M6-Fashion model serves as a highly potential AI designer for the fashion industry.

</p>
</details>

<details><summary><b>RCC-GAN: Regularized Compound Conditional GAN for Large-Scale Tabular Data Synthesis</b>
<a href="https://arxiv.org/abs/2205.11693">arxiv:2205.11693</a>
&#x1F4C8; 4 <br>
<p>Mohammad Esmaeilpour, Nourhene Chaalia, Adel Abusitta, Francois-Xavier Devailly, Wissem Maazoun, Patrick Cardinal</p></summary>
<p>

**Abstract:** This paper introduces a novel generative adversarial network (GAN) for synthesizing large-scale tabular databases which contain various features such as continuous, discrete, and binary. Technically, our GAN belongs to the category of class-conditioned generative models with a predefined conditional vector. However, we propose a new formulation for deriving such a vector incorporating both binary and discrete features simultaneously. We refer to this noble definition as compound conditional vector and employ it for training the generator network. The core architecture of this network is a three-layered deep residual neural network with skip connections. For improving the stability of such complex architecture, we present a regularization scheme towards limiting unprecedented variations on its weight vectors during training. This regularization approach is quite compatible with the nature of adversarial training and it is not computationally prohibitive in runtime. Furthermore, we constantly monitor the variation of the weight vectors for identifying any potential instabilities or irregularities to measure the strength of our proposed regularizer. Toward this end, we also develop a new metric for tracking sudden perturbation on the weight vectors using the singular value decomposition theory. Finally, we evaluate the performance of our proposed synthesis approach on six benchmarking tabular databases, namely Adult, Census, HCDR, Cabs, News, and King. The achieved results corroborate that for the majority of the cases, our proposed RccGAN outperforms other conventional and modern generative models in terms of accuracy, stability, and reliability.

</p>
</details>

<details><summary><b>Compressing Deep Graph Neural Networks via Adversarial Knowledge Distillation</b>
<a href="https://arxiv.org/abs/2205.11678">arxiv:2205.11678</a>
&#x1F4C8; 4 <br>
<p>Huarui He, Jie Wang, Zhanqiu Zhang, Feng Wu</p></summary>
<p>

**Abstract:** Deep graph neural networks (GNNs) have been shown to be expressive for modeling graph-structured data. Nevertheless, the over-stacked architecture of deep graph models makes it difficult to deploy and rapidly test on mobile or embedded systems. To compress over-stacked GNNs, knowledge distillation via a teacher-student architecture turns out to be an effective technique, where the key step is to measure the discrepancy between teacher and student networks with predefined distance functions. However, using the same distance for graphs of various structures may be unfit, and the optimal distance formulation is hard to determine. To tackle these problems, we propose a novel Adversarial Knowledge Distillation framework for graph models named GraphAKD, which adversarially trains a discriminator and a generator to adaptively detect and decrease the discrepancy. Specifically, noticing that the well-captured inter-node and inter-class correlations favor the success of deep GNNs, we propose to criticize the inherited knowledge from node-level and class-level views with a trainable discriminator. The discriminator distinguishes between teacher knowledge and what the student inherits, while the student GNN works as a generator and aims to fool the discriminator. To our best knowledge, GraphAKD is the first to introduce adversarial training to knowledge distillation in graph domains. Experiments on node-level and graph-level classification benchmarks demonstrate that GraphAKD improves the student performance by a large margin. The results imply that GraphAKD can precisely transfer knowledge from a complicated teacher GNN to a compact student GNN.

</p>
</details>

<details><summary><b>PCA-Boosted Autoencoders for Nonlinear Dimensionality Reduction in Low Data Regimes</b>
<a href="https://arxiv.org/abs/2205.11673">arxiv:2205.11673</a>
&#x1F4C8; 4 <br>
<p>Muhammad Al-Digeil, Yuri Grinberg, Daniele Melati3, Mohsen Kamandar Dezfouli, Jens H. Schmid, Pavel Cheben, Siegfried Janz, Dan-Xia Xu</p></summary>
<p>

**Abstract:** Autoencoders (AE) provide a useful method for nonlinear dimensionality reduction but are ill-suited for low data regimes. Conversely, Principal Component Analysis (PCA) is data-efficient but is limited to linear dimensionality reduction, posing a problem when data exhibits inherent nonlinearity. This presents a challenge in various scientific and engineering domains such as the nanophotonic component design, where data exhibits nonlinear features while being expensive to obtain due to costly real measurements or resource-consuming solutions of partial differential equations.
  To address this difficulty, we propose a technique that harnesses the best of both worlds: an autoencoder that leverages PCA to perform well on scarce nonlinear data. Specifically, we outline a numerically robust PCA-based initialization of AE, which, together with the parameterized ReLU activation function, allows the training process to start from an exact PCA solution and improve upon it. A synthetic example is presented first to study the effects of data nonlinearity and size on the performance of the proposed method. We then evaluate our method on several nanophotonic component design problems where obtaining useful data is expensive. To demonstrate universality, we also apply it to tasks in other scientific domains: a benchmark breast cancer dataset and a gene expression dataset.
  We show that our proposed approach is substantially better than both PCA and randomly initialized AE in the majority of low-data regime cases we consider, or at least is comparable to the best of either of the other two methods.

</p>
</details>

<details><summary><b>Forecasting of Non-Stationary Sales Time Series Using Deep Learning</b>
<a href="https://arxiv.org/abs/2205.11636">arxiv:2205.11636</a>
&#x1F4C8; 4 <br>
<p>Bohdan M. Pavlyshenko</p></summary>
<p>

**Abstract:** The paper describes the deep learning approach for forecasting non-stationary time series with using time trend correction in a neural network model. Along with the layers for predicting sales values, the neural network model includes a subnetwork block for the prediction weight for a time trend term which is added to a predicted sales value. The time trend term is considered as a product of the predicted weight value and normalized time value. The results show that the forecasting accuracy can be essentially improved for non-stationary sales with time trends using the trend correction block in the deep learning model.

</p>
</details>

<details><summary><b>SiPRNet: End-to-End Learning for Single-Shot Phase Retrieval</b>
<a href="https://arxiv.org/abs/2205.11434">arxiv:2205.11434</a>
&#x1F4C8; 4 <br>
<p>Qiuliang Ye, Li-Wen Wang, Daniel P. K. Lun</p></summary>
<p>

**Abstract:** Traditional optimization algorithms have been developed to deal with the phase retrieval problem. However, multiple measurements with different random or non-random masks are needed for giving a satisfactory performance. This brings a burden to the implementation of the algorithms in practical systems. Even worse, expensive optical devices are required to implement the optical masks. Recently, deep learning, especially convolutional neural networks (CNN), has played important roles in various image reconstruction tasks. However, traditional CNN structure fails to reconstruct the original images from their Fourier measurements because of tremendous domain discrepancy. In this paper, we design a novel CNN structure, named SiPRNet, to recover a signal from a single Fourier intensity measurement. To effectively utilize the spectral information of the measurements, we propose a new Multi-Layer Perception block embedded with the dropout layer to extract the global representations. Two Up-sampling and Reconstruction blocks with self-attention are utilized to recover the signals from the extracted features. Extensive evaluations of the proposed model are performed using different testing datasets on both simulation and optical experimentation platforms. The results demonstrate that the proposed approach consistently outperforms other CNN-based and traditional optimization-based methods in single-shot maskless phase retrieval. The source codes of the proposed method have been released on Github: https://github.com/Qiustander/SiPRNet.

</p>
</details>

<details><summary><b>LILA-BOTI : Leveraging Isolated Letter Accumulations By Ordering Teacher Insights for Bangla Handwriting Recognition</b>
<a href="https://arxiv.org/abs/2205.11420">arxiv:2205.11420</a>
&#x1F4C8; 4 <br>
<p>Md. Ismail Hossain, Mohammed Rakib, Sabbir Mollah, Fuad Rahman, Nabeel Mohammed</p></summary>
<p>

**Abstract:** Word-level handwritten optical character recognition (OCR) remains a challenge for morphologically rich languages like Bangla. The complexity arises from the existence of a large number of alphabets, the presence of several diacritic forms, and the appearance of complex conjuncts. The difficulty is exacerbated by the fact that some graphemes occur infrequently but remain indispensable, so addressing the class imbalance is required for satisfactory results. This paper addresses this issue by introducing two knowledge distillation methods: Leveraging Isolated Letter Accumulations By Ordering Teacher Insights (LILA-BOTI) and Super Teacher LILA-BOTI. In both cases, a Convolutional Recurrent Neural Network (CRNN) student model is trained with the dark knowledge gained from a printed isolated character recognition teacher model. We conducted inter-dataset testing on \emph{BN-HTRd} and \emph{BanglaWriting} as our evaluation protocol, thus setting up a challenging problem where the results would better reflect the performance on unseen data. Our evaluations achieved up to a 3.5% increase in the F1-Macro score for the minor classes and up to 4.5% increase in our overall word recognition rate when compared with the base model (No KD) and conventional KD.

</p>
</details>

<details><summary><b>What You See is What You Classify: Black Box Attributions</b>
<a href="https://arxiv.org/abs/2205.11266">arxiv:2205.11266</a>
&#x1F4C8; 4 <br>
<p>Steven Stalder, Nathanaël Perraudin, Radhakrishna Achanta, Fernando Perez-Cruz, Michele Volpi</p></summary>
<p>

**Abstract:** An important step towards explaining deep image classifiers lies in the identification of image regions that contribute to individual class scores in the model's output. However, doing this accurately is a difficult task due to the black-box nature of such networks. Most existing approaches find such attributions either using activations and gradients or by repeatedly perturbing the input. We instead address this challenge by training a second deep network, the Explainer, to predict attributions for a pre-trained black-box classifier, the Explanandum. These attributions are in the form of masks that only show the classifier-relevant parts of an image, masking out the rest. Our approach produces sharper and more boundary-precise masks when compared to the saliency maps generated by other methods. Moreover, unlike most existing approaches, ours is capable of directly generating very distinct class-specific masks. Finally, the proposed method is very efficient for inference since it only takes a single forward pass through the Explainer to generate all class-specific masks. We show that our attributions are superior to established methods both visually and quantitatively, by evaluating them on the PASCAL VOC-2007 and Microsoft COCO-2014 datasets.

</p>
</details>

<details><summary><b>OPQ: Compressing Deep Neural Networks with One-shot Pruning-Quantization</b>
<a href="https://arxiv.org/abs/2205.11141">arxiv:2205.11141</a>
&#x1F4C8; 4 <br>
<p>Peng Hu, Xi Peng, Hongyuan Zhu, Mohamed M. Sabry Aly, Jie Lin</p></summary>
<p>

**Abstract:** As Deep Neural Networks (DNNs) usually are overparameterized and have millions of weight parameters, it is challenging to deploy these large DNN models on resource-constrained hardware platforms, e.g., smartphones. Numerous network compression methods such as pruning and quantization are proposed to reduce the model size significantly, of which the key is to find suitable compression allocation (e.g., pruning sparsity and quantization codebook) of each layer. Existing solutions obtain the compression allocation in an iterative/manual fashion while finetuning the compressed model, thus suffering from the efficiency issue. Different from the prior art, we propose a novel One-shot Pruning-Quantization (OPQ) in this paper, which analytically solves the compression allocation with pre-trained weight parameters only. During finetuning, the compression module is fixed and only weight parameters are updated. To our knowledge, OPQ is the first work that reveals pre-trained model is sufficient for solving pruning and quantization simultaneously, without any complex iterative/manual optimization at the finetuning stage. Furthermore, we propose a unified channel-wise quantization method that enforces all channels of each layer to share a common codebook, which leads to low bit-rate allocation without introducing extra overhead brought by traditional channel-wise quantization. Comprehensive experiments on ImageNet with AlexNet/MobileNet-V1/ResNet-50 show that our method improves accuracy and training efficiency while obtains significantly higher compression rates compared to the state-of-the-art.

</p>
</details>

<details><summary><b>Vegetation Mapping by UAV Visible Imagery and Machine Learning</b>
<a href="https://arxiv.org/abs/2205.11061">arxiv:2205.11061</a>
&#x1F4C8; 4 <br>
<p>Giuliano Vitali</p></summary>
<p>

**Abstract:** An experimental field cropped with sugar-beet with a wide spreading of weeds has been used to test vegetation identification from drone visible imagery. Expert masked and hue-filtered pictures have been used to train several Machine Learning algorithms to develop a semi-automatic methodology for identification and mapping species at high resolution. Results show that 5m altitude allows for obtaining maps with an identification efficiency of more than 90%. Such a method can be easily integrated to present VRHA, as much as tools to obtain detailed maps of vegetation.

</p>
</details>

<details><summary><b>Wireless Ad Hoc Federated Learning: A Fully Distributed Cooperative Machine Learning</b>
<a href="https://arxiv.org/abs/2205.11779">arxiv:2205.11779</a>
&#x1F4C8; 3 <br>
<p>Hideya Ochiai, Yuwei Sun, Qingzhe Jin, Nattanon Wongwiwatchai, Hiroshi Esaki</p></summary>
<p>

**Abstract:** Federated learning has allowed training of a global model by aggregating local models trained on local nodes. However, it still takes client-server model, which can be further distributed, fully decentralized, or even partially connected, or totally opportunistic. In this paper, we propose a wireless ad hoc federated learning (WAFL) -- a fully distributed cooperative machine learning organized by the nodes physically nearby. Here, each node has a wireless interface and can communicate with each other when they are within the radio range. The nodes are expected to move with people, vehicles, or robots, producing opportunistic contacts with each other. In WAFL, each node trains a model individually with the local data it has. When a node encounter with others, they exchange their trained models, and generate new aggregated models, which are expected to be more general compared to the locally trained models on Non-IID data. For evaluation, we have prepared four static communication networks and two types of dynamic and opportunistic communication networks based on random waypoint mobility and community-structured environment, and then studied the training process of a fully connected neural network with 90% Non-IID MNIST dataset. The evaluation results indicate that WAFL allowed the convergence of model parameters among the nodes toward generalization, even with opportunistic node contact scenarios -- whereas in self-training (or lonely training) case, they have diverged. This WAFL's model generalization contributed to achieving higher accuracy 94.7-96.2% to the testing IID dataset compared to the self-training case 84.7%.

</p>
</details>

<details><summary><b>Semi-Supervised Clustering of Sparse Graphs: Crossing the Information-Theoretic Threshold</b>
<a href="https://arxiv.org/abs/2205.11677">arxiv:2205.11677</a>
&#x1F4C8; 3 <br>
<p>Junda Sheng, Thomas Strohmer</p></summary>
<p>

**Abstract:** The stochastic block model is a canonical random graph model for clustering and community detection on network-structured data. Decades of extensive study on the problem have established many profound results, among which the phase transition at the Kesten-Stigum threshold is particularly interesting both from a mathematical and an applied standpoint. It states that no estimator based on the network topology can perform substantially better than chance on sparse graphs if the model parameter is below certain threshold. Nevertheless, if we slightly extend the horizon to the ubiquitous semi-supervised setting, such a fundamental limitation will disappear completely. We prove that with arbitrary fraction of the labels revealed, the detection problem is feasible throughout the parameter domain. Moreover, we introduce two efficient algorithms, one combinatorial and one based on optimization, to integrate label information with graph structures. Our work brings a new perspective to stochastic model of networks and semidefinite program research.

</p>
</details>

<details><summary><b>Algorithm Development for Controlling Movement of a Robotic Platform by Digital Image Processing</b>
<a href="https://arxiv.org/abs/2205.11666">arxiv:2205.11666</a>
&#x1F4C8; 3 <br>
<p>Benjamin Andres Huerfano Zapata, Humberto Numpaque Lopez, Cindy Lorena Diaz Murillo</p></summary>
<p>

**Abstract:** The following work shows an algorithm that can process images digitally with the goal of control the movement of a mobile robotic platform in a certain environment. The platform is identified with a specific color, and displacement environment of the platform shift has identified obstacles with different colors, for both cases it worked with the RGB color scale. To obtain the control's movement of the robotic platform, the algorithm was developed in C programming language, and used the Open CV libraries for processing images captured by a video camera on the Dev-platform C + +. The video camera was previously calibrated using ZHANG technique where parameters were obtained focal length and tilt focal pixel. In the algorithm histogram analysis and segmentation of the image were developed, allowing to determine exactly the relative position of the platform with respect to the obstacles and movement strategy to follow.

</p>
</details>

<details><summary><b>uGLAD: Sparse graph recovery by optimizing deep unrolled networks</b>
<a href="https://arxiv.org/abs/2205.11610">arxiv:2205.11610</a>
&#x1F4C8; 3 <br>
<p>Harsh Shrivastava, Urszula Chajewska, Robin Abraham, Xinshi Chen</p></summary>
<p>

**Abstract:** Probabilistic Graphical Models (PGMs) are generative models of complex systems. They rely on conditional independence assumptions between variables to learn sparse representations which can be visualized in a form of a graph. Such models are used for domain exploration and structure discovery in poorly understood domains. This work introduces a novel technique to perform sparse graph recovery by optimizing deep unrolled networks. Assuming that the input data $X\in\mathbb{R}^{M\times D}$ comes from an underlying multivariate Gaussian distribution, we apply a deep model on $X$ that outputs the precision matrix $Θ$, which can also be interpreted as the adjacency matrix. Our model, uGLAD, builds upon and extends the state-of-the-art model GLAD to the unsupervised setting. The key benefits of our model are (1) uGLAD automatically optimizes sparsity-related regularization parameters leading to better performance than existing algorithms. (2) We introduce multi-task learning based `consensus' strategy for robust handling of missing data in an unsupervised setting. We evaluate model results on synthetic Gaussian data, non-Gaussian data generated from Gene Regulatory Networks, and present a case study in anaerobic digestion.

</p>
</details>

<details><summary><b>Information Propagation by Composited Labels in Natural Language Processing</b>
<a href="https://arxiv.org/abs/2205.11509">arxiv:2205.11509</a>
&#x1F4C8; 3 <br>
<p>Takeshi Inagaki</p></summary>
<p>

**Abstract:** In natural language processing (NLP), labeling on regions of text, such as words, sentences and paragraphs, is a basic task. In this paper, label is defined as map between mention of entity in a region on text and context of entity in a broader region on text containing the mention. This definition naturally introduces linkage of entities induced from inclusion relation of regions, and connected entities form a graph representing information flow defined by map. It also enables calculation of information loss through map using entropy, and entropy lost is regarded as distance between two entities over a path on graph.

</p>
</details>

<details><summary><b>Computationally Efficient Horizon-Free Reinforcement Learning for Linear Mixture MDPs</b>
<a href="https://arxiv.org/abs/2205.11507">arxiv:2205.11507</a>
&#x1F4C8; 3 <br>
<p>Dongruo Zhou, Quanquan Gu</p></summary>
<p>

**Abstract:** Recent studies have shown that episodic reinforcement learning (RL) is not more difficult than contextual bandits, even with a long planning horizon and unknown state transitions. However, these results are limited to either tabular Markov decision processes (MDPs) or computationally inefficient algorithms for linear mixture MDPs. In this paper, we propose the first computationally efficient horizon-free algorithm for linear mixture MDPs, which achieves the optimal $\tilde O(d\sqrt{K} +d^2)$ regret up to logarithmic factors. Our algorithm adapts a weighted least square estimator for the unknown transitional dynamic, where the weight is both \emph{variance-aware} and \emph{uncertainty-aware}. When applying our weighted least square estimator to heterogeneous linear bandits, we can obtain an $\tilde O(d\sqrt{\sum_{k=1}^K σ_k^2} +d)$ regret in the first $K$ rounds, where $d$ is the dimension of the context and $σ_k^2$ is the variance of the reward in the $k$-th round. This also improves upon the best-known algorithms in this setting when $σ_k^2$'s are known.

</p>
</details>

<details><summary><b>Orchestra: Unsupervised Federated Learning via Globally Consistent Clustering</b>
<a href="https://arxiv.org/abs/2205.11506">arxiv:2205.11506</a>
&#x1F4C8; 3 <br>
<p>Ekdeep Singh Lubana, Chi Ian Tang, Fahim Kawsar, Robert P. Dick, Akhil Mathur</p></summary>
<p>

**Abstract:** Federated learning is generally used in tasks where labels are readily available (e.g., next word prediction). Relaxing this constraint requires design of unsupervised learning techniques that can support desirable properties for federated training: robustness to statistical/systems heterogeneity, scalability with number of participants, and communication efficiency. Prior work on this topic has focused on directly extending centralized self-supervised learning techniques, which are not designed to have the properties listed above. To address this situation, we propose Orchestra, a novel unsupervised federated learning technique that exploits the federation's hierarchy to orchestrate a distributed clustering task and enforce a globally consistent partitioning of clients' data into discriminable clusters. We show the algorithmic pipeline in Orchestra guarantees good generalization performance under a linear probe, allowing it to outperform alternative techniques in a broad range of conditions, including variation in heterogeneity, number of clients, participation ratio, and local epochs.

</p>
</details>

<details><summary><b>What Makes Data-to-Text Generation Hard for Pretrained Language Models?</b>
<a href="https://arxiv.org/abs/2205.11505">arxiv:2205.11505</a>
&#x1F4C8; 3 <br>
<p>Moniba Keymanesh, Adrian Benton, Mark Dredze</p></summary>
<p>

**Abstract:** Expressing natural language descriptions of structured facts or relations -- data-to-text generation (D2T) -- increases the accessibility of structured knowledge repositories. Previous work shows that pre-trained language models(PLMs) perform remarkably well on this task after fine-tuning on a significant amount of task-specific training data. On the other hand, while auto-regressive PLMs can generalize from a few task examples, their efficacy at D2T is largely unexplored. Furthermore, we have an incomplete understanding of the limits of PLMs on D2T.
  In this work, we conduct an empirical study of both fine-tuned and auto-regressive PLMs on the DART multi-domain D2T dataset. We consider their performance as a function of the amount of task-specific data and how these data are incorporated into the models: zero and few-shot learning, and fine-tuning of model weights. In addition, we probe the limits of PLMs by measuring performance on subsets of the evaluation data: novel predicates and abstractive test examples. To improve the performance on these subsets, we investigate two techniques: providing predicate descriptions in the context and re-ranking generated candidates by information reflected in the source. Finally, we conduct a human evaluation of model errors and show that D2T generation tasks would benefit from datasets with more careful manual curation.

</p>
</details>

<details><summary><b>Robust and Agnostic Learning of Conditional Distributional Treatment Effects</b>
<a href="https://arxiv.org/abs/2205.11486">arxiv:2205.11486</a>
&#x1F4C8; 3 <br>
<p>Nathan Kallus, Miruna Oprescu</p></summary>
<p>

**Abstract:** The conditional average treatment effect (CATE) is the best point prediction of individual causal effects given individual baseline covariates and can help personalize treatments. However, as CATE only reflects the (conditional) average, it can wash out potential risks and tail events, which are crucially relevant to treatment choice. In aggregate analyses, this is usually addressed by measuring distributional treatment effect (DTE), such as differences in quantiles or tail expectations between treatment groups. Hypothetically, one can similarly fit covariate-conditional quantile regressions in each treatment group and take their difference, but this would not be robust to misspecification or provide agnostic best-in-class predictions. We provide a new robust and model-agnostic methodology for learning the conditional DTE (CDTE) for a wide class of problems that includes conditional quantile treatment effects, conditional super-quantile treatment effects, and conditional treatment effects on coherent risk measures given by $f$-divergences. Our method is based on constructing a special pseudo-outcome and regressing it on baseline covariates using any given regression learner. Our method is model-agnostic in the sense that it can provide the best projection of CDTE onto the regression model class. Our method is robust in the sense that even if we learn these nuisances nonparametrically at very slow rates, we can still learn CDTEs at rates that depend on the class complexity and even conduct inferences on linear projections of CDTEs. We investigate the performance of our proposal in simulation studies, and we demonstrate its use in a case study of 401(k) eligibility effects on wealth.

</p>
</details>

<details><summary><b>Conditional Supervised Contrastive Learning for Fair Text Classification</b>
<a href="https://arxiv.org/abs/2205.11485">arxiv:2205.11485</a>
&#x1F4C8; 3 <br>
<p>Jianfeng Chi, William Shand, Yaodong Yu, Kai-Wei Chang, Han Zhao, Yuan Tian</p></summary>
<p>

**Abstract:** Contrastive representation learning has gained much attention due to its superior performance in learning representations from both image and sequential data. However, the learned representations could potentially lead to performance disparities in downstream tasks, such as increased silencing of underrepresented groups in toxicity comment classification. In light of this challenge, in this work, we study learning fair representations that satisfy a notion of fairness known as equalized odds for text classification via contrastive learning. Specifically, we first theoretically analyze the connections between learning representations with fairness constraint and conditional supervised contrastive objectives. Inspired by our theoretical findings, we propose to use conditional supervised contrastive objectives to learn fair representations for text classification. We conduct experiments on two text datasets to demonstrate the effectiveness of our approaches in balancing the trade-offs between task performance and bias mitigation among existing baselines for text classification. Furthermore, we also show that the proposed methods are stable in different hyperparameter settings.

</p>
</details>

<details><summary><b>Rethinking Streaming Machine Learning Evaluation</b>
<a href="https://arxiv.org/abs/2205.11473">arxiv:2205.11473</a>
&#x1F4C8; 3 <br>
<p>Shreya Shankar, Bernease Herman, Aditya G. Parameswaran</p></summary>
<p>

**Abstract:** While most work on evaluating machine learning (ML) models focuses on computing accuracy on batches of data, tracking accuracy alone in a streaming setting (i.e., unbounded, timestamp-ordered datasets) fails to appropriately identify when models are performing unexpectedly. In this position paper, we discuss how the nature of streaming ML problems introduces new real-world challenges (e.g., delayed arrival of labels) and recommend additional metrics to assess streaming ML performance.

</p>
</details>

<details><summary><b>StreamingQA: A Benchmark for Adaptation to New Knowledge over Time in Question Answering Models</b>
<a href="https://arxiv.org/abs/2205.11388">arxiv:2205.11388</a>
&#x1F4C8; 3 <br>
<p>Adam Liška, Tomáš Kočiský, Elena Gribovskaya, Tayfun Terzi, Eren Sezener, Devang Agrawal, Cyprien de Masson d'Autume, Tim Scholtes, Manzil Zaheer, Susannah Young, Ellen Gilsenan-McMahon, Sophia Austin, Phil Blunsom, Angeliki Lazaridou</p></summary>
<p>

**Abstract:** Knowledge and language understanding of models evaluated through question answering (QA) has been usually studied on static snapshots of knowledge, like Wikipedia. However, our world is dynamic, evolves over time, and our models' knowledge becomes outdated. To study how semi-parametric QA models and their underlying parametric language models (LMs) adapt to evolving knowledge, we construct a new large-scale dataset, StreamingQA, with human written and generated questions asked on a given date, to be answered from 14 years of time-stamped news articles. We evaluate our models quarterly as they read new articles not seen in pre-training. We show that parametric models can be updated without full retraining, while avoiding catastrophic forgetting. For semi-parametric models, adding new articles into the search space allows for rapid adaptation, however, models with an outdated underlying LM under-perform those with a retrained LM. For questions about higher-frequency named entities, parametric updates are particularly beneficial. In our dynamic world, the StreamingQA dataset enables a more realistic evaluation of QA models, and our experiments highlight several promising directions for future research.

</p>
</details>

<details><summary><b>Chaotic Regularization and Heavy-Tailed Limits for Deterministic Gradient Descent</b>
<a href="https://arxiv.org/abs/2205.11361">arxiv:2205.11361</a>
&#x1F4C8; 3 <br>
<p>Soon Hoe Lim, Yijun Wan, Umut Şimşekli</p></summary>
<p>

**Abstract:** Recent studies have shown that gradient descent (GD) can achieve improved generalization when its dynamics exhibits a chaotic behavior. However, to obtain the desired effect, the step-size should be chosen sufficiently large, a task which is problem dependent and can be difficult in practice. In this study, we incorporate a chaotic component to GD in a controlled manner, and introduce multiscale perturbed GD (MPGD), a novel optimization framework where the GD recursion is augmented with chaotic perturbations that evolve via an independent dynamical system. We analyze MPGD from three different angles: (i) By building up on recent advances in rough paths theory, we show that, under appropriate assumptions, as the step-size decreases, the MPGD recursion converges weakly to a stochastic differential equation (SDE) driven by a heavy-tailed Lévy-stable process. (ii) By making connections to recently developed generalization bounds for heavy-tailed processes, we derive a generalization bound for the limiting SDE and relate the worst-case generalization error over the trajectories of the process to the parameters of MPGD. (iii) We analyze the implicit regularization effect brought by the dynamical regularization and show that, in the weak perturbation regime, MPGD introduces terms that penalize the Hessian of the loss function. Empirical results are provided to demonstrate the advantages of MPGD.

</p>
</details>

<details><summary><b>Towards automatic detection of wildlife trade using machine vision models</b>
<a href="https://arxiv.org/abs/2205.11324">arxiv:2205.11324</a>
&#x1F4C8; 3 <br>
<p>Ritwik Kulkarni, Enrico Di Minin</p></summary>
<p>

**Abstract:** Unsustainable trade in wildlife is one of the major threats affecting the global biodiversity crisis. An important part of the trade now occurs on the internet, especially on digital marketplaces and social media. Automated methods to identify trade posts are needed as resources for conservation are limited. Here, we developed machine vision models based on Deep Neural Networks with the aim to automatically identify images of exotic pet animals for sale. A new training dataset representing exotic pet animals advertised for sale on the web was generated for this purpose. We trained 24 neural-net models spanning a combination of five different architectures, three methods of training and two types of datasets. Specifically, model generalisation improved after setting a portion of the training images to represent negative features. Models were evaluated on both within and out of distribution data to test wider model applicability. The top performing models achieved an f-score of over 0.95 on within distribution evaluation and between 0.75 to 0.87 on the two out of distribution datasets. Notably, feature visualisation indicated that models performed well in detecting the surrounding context (e.g. a cage) in which an animal was located, therefore helping to automatically detect images of animals in non-natural environments. The proposed methods can help investigate the online wildlife trade, but can also be adapted to study other types of people-nature interactions from digital platforms. Future studies can use these findings to build robust machine learning models and new data collection pipelines for more taxonomic groups.

</p>
</details>

<details><summary><b>SelfReformer: Self-Refined Network with Transformer for Salient Object Detection</b>
<a href="https://arxiv.org/abs/2205.11283">arxiv:2205.11283</a>
&#x1F4C8; 3 <br>
<p>Yi Ke Yun, Weisi Lin</p></summary>
<p>

**Abstract:** The global and local contexts significantly contribute to the integrity of predictions in Salient Object Detection (SOD). Unfortunately, existing methods still struggle to generate complete predictions with fine details. There are two major problems in conventional approaches: first, for global context, high-level CNN-based encoder features cannot effectively catch long-range dependencies, resulting in incomplete predictions. Second, downsampling the ground truth to fit the size of predictions will introduce inaccuracy as the ground truth details are lost during interpolation or pooling. Thus, in this work, we developed a Transformer-based network and framed a supervised task for a branch to learn the global context information explicitly. Besides, we adopt Pixel Shuffle from Super-Resolution (SR) to reshape the predictions back to the size of ground truth instead of the reverse. Thus details in the ground truth are untouched. In addition, we developed a two-stage Context Refinement Module (CRM) to fuse global context and automatically locate and refine the local details in the predictions. The proposed network can guide and correct itself based on the global and local context generated, thus is named, Self-Refined Transformer (SelfReformer). Extensive experiments and evaluation results on five benchmark datasets demonstrate the outstanding performance of the network, and we achieved the state-of-the-art.

</p>
</details>

<details><summary><b>RL with KL penalties is better viewed as Bayesian inference</b>
<a href="https://arxiv.org/abs/2205.11275">arxiv:2205.11275</a>
&#x1F4C8; 3 <br>
<p>Tomasz Korbak, Ethan Perez, Christopher L Buckley</p></summary>
<p>

**Abstract:** Reinforcement learning (RL) is frequently employed in fine-tuning large language models (LMs), such as GPT-3, to penalize them for undesirable features of generated sequences, such as offensiveness, social bias, harmfulness or falsehood. The RL formulation involves treating the LM as a policy and updating it to maximise the expected value of a reward function which captures human preferences, such as non-offensiveness. In this paper, we analyze challenges associated with treating a language model as an RL policy and show how avoiding those challenges requires moving beyond the RL paradigm. We start by observing that the standard RL approach is flawed as an objective for fine-tuning LMs because it leads to distribution collapse: turning the LM into a degenerate distribution. Then, we analyze KL-regularised RL, a widely used recipe for fine-tuning LMs, which additionally constrains the fine-tuned LM to stay close to its original distribution in terms of Kullback-Leibler (KL) divergence. We show that KL-regularised RL is equivalent to variational inference: approximating a Bayesian posterior which specifies how to update a prior LM to conform with evidence provided by the reward function. We argue that this Bayesian inference view of KL-regularised RL is more insightful than the typically employed RL perspective. The Bayesian inference view explains how KL-regularised RL avoids the distribution collapse problem and offers a first-principles derivation for its objective. While this objective happens to be equivalent to RL (with a particular choice of parametric reward), there exist other objectives for fine-tuning LMs which are no longer equivalent to RL. That observation leads to a more general point: RL is not an adequate formal framework for problems such as fine-tuning language models. These problems are best viewed as Bayesian inference: approximating a pre-defined target distribution.

</p>
</details>

<details><summary><b>GR-GAN: Gradual Refinement Text-to-image Generation</b>
<a href="https://arxiv.org/abs/2205.11273">arxiv:2205.11273</a>
&#x1F4C8; 3 <br>
<p>Bo Yang, Fangxiang Feng, Xiaojie Wang</p></summary>
<p>

**Abstract:** A good Text-to-Image model should not only generate high quality images, but also ensure the consistency between the text and the generated image. Previous models failed to simultaneously fix both sides well. This paper proposes a Gradual Refinement Generative Adversarial Network (GR-GAN) to alleviates the problem efficiently. A GRG module is designed to generate images from low resolution to high resolution with the corresponding text constraints from coarse granularity (sentence) to fine granularity (word) stage by stage, a ITM module is designed to provide image-text matching losses at both sentence-image level and word-region level for corresponding stages. We also introduce a new metric Cross-Model Distance (CMD) for simultaneously evaluating image quality and image-text consistency. Experimental results show GR-GAN significant outperform previous models, and achieve new state-of-the-art on both FID and CMD. A detailed analysis demonstrates the efficiency of different generation stages in GR-GAN.

</p>
</details>

<details><summary><b>Stop Filtering: Multi-View Attribute-Enhanced Dialogue Learning</b>
<a href="https://arxiv.org/abs/2205.11206">arxiv:2205.11206</a>
&#x1F4C8; 3 <br>
<p>Yiwei Li, Bin Sun, Shaoxiong Feng, Kan Li</p></summary>
<p>

**Abstract:** There is a growing interest in improving the conversational ability of models by filtering the raw dialogue corpora. Previous filtering strategies usually rely on a scoring method to assess and discard samples from one perspective, enabling the model to enhance the corresponding dialogue attributes (e.g., consistency) more easily. However, the discarded samples may obtain high scores in other perspectives and can provide regularization effects on the model learning, which causes the performance improvement to be sensitive to the filtering ratio. In this work, we propose a multi-view attribute-enhanced dialogue learning framework that strengthens the attribute-related features more robustly and comprehensively. Instead of filtering the raw dataset to train the model, our framework first pre-trains the model on the raw dataset and then fine-tunes it through adapters on the selected sub-sets, which also enhances certain attributes of responses but without suffering from the problems mentioned above. Considering the variety of the dialogue attribute, we further design a multi-view enhancement mechanism, including multi-view selection and inter-view fusion. It groups the high-quality samples from multiple perspectives, respectively, and enhances different attributes of responses with the corresponding sample sets and adapters, keeping knowledge independent and allowing flexible integration. Empirical results and analysis show that our framework can improve the performance significantly in terms of enhancing dialogue attributes and fusing view-specific knowledge.

</p>
</details>

<details><summary><b>BBTv2: Pure Black-Box Optimization Can Be Comparable to Gradient Descent for Few-Shot Learning</b>
<a href="https://arxiv.org/abs/2205.11200">arxiv:2205.11200</a>
&#x1F4C8; 3 <br>
<p>Tianxiang Sun, Zhengfu He, Hong Qian, Xuanjing Huang, Xipeng Qiu</p></summary>
<p>

**Abstract:** Black-Box Tuning (BBT) is a derivative-free approach to optimize continuous prompt tokens prepended to the input of language models. Although BBT has achieved comparable performance to full model tuning on simple classification tasks under few-shot settings, it requires pre-trained prompt embedding to match model tuning on hard tasks (e.g., entailment tasks), and therefore does not completely get rid of the dependence on gradients. In this paper we present BBTv2, a pure black-box optimization approach that can drive language models to achieve comparable results to gradient-based optimization. In particular, we prepend continuous prompt tokens to every layer of the language model and propose a divide-and-conquer algorithm to alternately optimize the prompt tokens at different layers. For the optimization at each layer, we perform derivative-free optimization in a low-dimensional subspace, which is then randomly projected to the original prompt parameter space. Experimental results show that BBTv2 not only outperforms BBT by a large margin, but also achieves comparable or even better performance than full model tuning and state-of-the-art parameter-efficient methods (e.g., Adapter, LoRA, BitFit, etc.) under few-shot learning settings, while maintaining much fewer tunable parameters.

</p>
</details>

<details><summary><b>Deep Image Retrieval is not Robust to Label Noise</b>
<a href="https://arxiv.org/abs/2205.11195">arxiv:2205.11195</a>
&#x1F4C8; 3 <br>
<p>Stanislav Dereka, Ivan Karpukhin, Sergey Kolesnikov</p></summary>
<p>

**Abstract:** Large-scale datasets are essential for the success of deep learning in image retrieval. However, manual assessment errors and semi-supervised annotation techniques can lead to label noise even in popular datasets. As previous works primarily studied annotation quality in image classification tasks, it is still unclear how label noise affects deep learning approaches to image retrieval. In this work, we show that image retrieval methods are less robust to label noise than image classification ones. Furthermore, we, for the first time, investigate different types of label noise specific to image retrieval tasks and study their effect on model performance.

</p>
</details>

<details><summary><b>NPU-BOLT: A Dataset for Bolt Object Detection in Natural Scene Images</b>
<a href="https://arxiv.org/abs/2205.11191">arxiv:2205.11191</a>
&#x1F4C8; 3 <br>
<p>Yadian Zhao, Zhenglin Yang, Chao Xu</p></summary>
<p>

**Abstract:** Bolt joints are very common and important in engineering structures. Due to extreme service environment and load factors, bolts often get loose or even disengaged. To real-time or timely detect the loosed or disengaged bolts is an urgent need in practical engineering, which is critical to keep structural safety and service life. In recent years, many bolt loosening detection methods using deep learning and machine learning techniques have been proposed and are attracting more and more attention. However, most of these studies use bolt images captured in laboratory for deep leaning model training. The images are obtained in a well-controlled light, distance, and view angle conditions. Also, the bolted structures are well designed experimental structures with brand new bolts and the bolts are exposed without any shelter nearby. It is noted that in practical engineering, the above well controlled lab conditions are not easy realized and the real bolt images often have blur edges, oblique perspective, partial occlusion and indistinguishable colors etc., which make the trained models obtained in laboratory conditions loss their accuracy or fails. Therefore, the aim of this study is to develop a dataset named NPU-BOLT for bolt object detection in natural scene images and open it to researchers for public use and further development. In the first version of the dataset, it contains 337 samples of bolt joints images mainly in the natural environment, with image data sizes ranging from 400*400 to 6000*4000, totaling approximately 1275 bolt targets. The bolt targets are annotated into four categories named blur bolt, bolt head, bolt nut and bolt side. The dataset is tested with advanced object detection models including yolov5, Faster-RCNN and CenterNet. The effectiveness of the dataset is validated.

</p>
</details>

<details><summary><b>How Powerful are Spectral Graph Neural Networks</b>
<a href="https://arxiv.org/abs/2205.11172">arxiv:2205.11172</a>
&#x1F4C8; 3 <br>
<p>Xiyuan Wang, Muhan Zhang</p></summary>
<p>

**Abstract:** Spectral Graph Neural Network is a kind of Graph Neural Network (GNN) based on graph signal filters, and some models able to learn arbitrary spectral filters have emerged recently. However, few works analyze the expressive power of spectral GNNs. This paper studies spectral GNNs' expressive power theoretically. We first prove that even spectral GNNs without nonlinearity can produce arbitrary graph signals and give two conditions for reaching universality. They are: 1) no multiple eigenvalues of graph Laplacian, and 2) no missing frequency components in node features. We also establish a connection between the expressive power of spectral GNNs and Graph Isomorphism (GI) testing which is often used to characterize spatial GNNs' expressive power. Moreover, we study the difference in empirical performance among different spectral GNNs with the same expressive power from an optimization perspective, and motivate the use of an orthogonal basis whose weight function corresponds to the graph signal density in the spectrum. Inspired by the analysis, we propose JacobiConv, which uses Jacobi polynomial basis due to their orthogonality and flexibility to adapt to a wide range of weight functions. JacobiConv deserts nonlinearity while outperforming all baselines on both synthetic and real-world datasets.

</p>
</details>

<details><summary><b>Split personalities in Bayesian Neural Networks: the case for full marginalisation</b>
<a href="https://arxiv.org/abs/2205.11151">arxiv:2205.11151</a>
&#x1F4C8; 3 <br>
<p>David Yallup, Will Handley, Mike Hobson, Anthony Lasenby, Pablo Lemos</p></summary>
<p>

**Abstract:** The true posterior distribution of a Bayesian neural network is massively multimodal. Whilst most of these modes are functionally equivalent, we demonstrate that there remains a level of real multimodality that manifests in even the simplest neural network setups. It is only by fully marginalising over all posterior modes, using appropriate Bayesian sampling tools, that we can capture the split personalities of the network. The ability of a network trained in this manner to reason between multiple candidate solutions dramatically improves the generalisability of the model, a feature we contend is not consistently captured by alternative approaches to the training of Bayesian neural networks. We provide a concise minimal example of this, which can provide lessons and a future path forward for correctly utilising the explainability and interpretability of Bayesian neural networks.

</p>
</details>

<details><summary><b>KRNet: Towards Efficient Knowledge Replay</b>
<a href="https://arxiv.org/abs/2205.11126">arxiv:2205.11126</a>
&#x1F4C8; 3 <br>
<p>Yingying Zhang, Qiaoyong Zhong, Di Xie, Shiliang Pu</p></summary>
<p>

**Abstract:** The knowledge replay technique has been widely used in many tasks such as continual learning and continuous domain adaptation. The key lies in how to effectively encode the knowledge extracted from previous data and replay them during current training procedure. A simple yet effective model to achieve knowledge replay is autoencoder. However, the number of stored latent codes in autoencoder increases linearly with the scale of data and the trained encoder is redundant for the replaying stage. In this paper, we propose a novel and efficient knowledge recording network (KRNet) which directly maps an arbitrary sample identity number to the corresponding datum. Compared with autoencoder, our KRNet requires significantly ($400\times$) less storage cost for the latent codes and can be trained without the encoder sub-network. Extensive experiments validate the efficiency of KRNet, and as a showcase, it is successfully applied in the task of continual learning.

</p>
</details>

<details><summary><b>Gradient Hedging for Intensively Exploring Salient Interpretation beyond Neuron Activation</b>
<a href="https://arxiv.org/abs/2205.11109">arxiv:2205.11109</a>
&#x1F4C8; 3 <br>
<p>Woo-Jeoung Nam, Seong-Whan Lee</p></summary>
<p>

**Abstract:** Hedging is a strategy for reducing the potential risks in various types of investments by adopting an opposite position in a related asset. Motivated by the equity technique, we introduce a method for decomposing output predictions into intensive salient attributions by hedging the evidence for a decision. We analyze the conventional approach applied to the evidence for a decision and discuss the paradox of the conservation rule. Subsequently, we define the viewpoint of evidence as a gap of positive and negative influence among the gradient-derived initial contribution maps and propagate the antagonistic elements to the evidence as suppressors, following the criterion of the degree of positive attribution defined by user preference. In addition, we reflect the severance or sparseness contribution of inactivated neurons, which are mostly irrelevant to a decision, resulting in increased robustness to interpretability. We conduct the following assessments in a verified experimental environment: pointing game, most relevant first region insertion, outside-inside relevance ratio, and mean average precision on the PASCAL VOC 2007, MS COCO 2014, and ImageNet datasets. The results demonstrate that our method outperforms existing attribution methods in distinctive, intensive, and intuitive visualization with robustness and applicability in general models.

</p>
</details>

<details><summary><b>An improved neural network model for treatment effect estimation</b>
<a href="https://arxiv.org/abs/2205.11106">arxiv:2205.11106</a>
&#x1F4C8; 3 <br>
<p>Niki Kiriakidou, Christos Diou</p></summary>
<p>

**Abstract:** Nowadays, in many scientific and industrial fields there is an increasing need for estimating treatment effects and answering causal questions. The key for addressing these problems is the wealth of observational data and the processes for leveraging this data. In this work, we propose a new model for predicting the potential outcomes and the propensity score, which is based on a neural network architecture. The proposed model exploits the covariates as well as the outcomes of neighboring instances in training data. Numerical experiments illustrate that the proposed model reports better treatment effect estimation performance compared to state-of-the-art models.

</p>
</details>

<details><summary><b>FL Games: A federated learning framework for distribution shifts</b>
<a href="https://arxiv.org/abs/2205.11101">arxiv:2205.11101</a>
&#x1F4C8; 3 <br>
<p>Sharut Gupta, Kartik Ahuja, Mohammad Havaei, Niladri Chatterjee, Yoshua Bengio</p></summary>
<p>

**Abstract:** Federated learning aims to train predictive models for data that is distributed across clients, under the orchestration of a server. However, participating clients typically each hold data from a different distribution, whereby predictive models with strong in-distribution generalization can fail catastrophically on unseen domains. In this work, we argue that in order to generalize better across non-i.i.d. clients, it is imperative to only learn correlations that are stable and invariant across domains. We propose FL Games, a game-theoretic framework for federated learning for learning causal features that are invariant across clients. While training to achieve the Nash equilibrium, the traditional best response strategy suffers from high-frequency oscillations. We demonstrate that FL Games effectively resolves this challenge and exhibits smooth performance curves. Further, FL Games scales well in the number of clients, requires significantly fewer communication rounds, and is agnostic to device heterogeneity. Through empirical evaluation, we demonstrate that FL Games achieves high out-of-distribution performance on various benchmarks.

</p>
</details>

<details><summary><b>PointDistiller: Structured Knowledge Distillation Towards Efficient and Compact 3D Detection</b>
<a href="https://arxiv.org/abs/2205.11098">arxiv:2205.11098</a>
&#x1F4C8; 3 <br>
<p>Linfeng Zhang, Runpei Dong, Hung-Shuo Tai, Kaisheng Ma</p></summary>
<p>

**Abstract:** The remarkable breakthroughs in point cloud representation learning have boosted their usage in real-world applications such as self-driving cars and virtual reality. However, these applications usually have an urgent requirement for not only accurate but also efficient 3D object detection. Recently, knowledge distillation has been proposed as an effective model compression technique, which transfers the knowledge from an over-parameterized teacher to a lightweight student and achieves consistent effectiveness in 2D vision. However, due to point clouds' sparsity and irregularity, directly applying previous image-based knowledge distillation methods to point cloud detectors usually leads to unsatisfactory performance. To fill the gap, this paper proposes PointDistiller, a structured knowledge distillation framework for point clouds-based 3D detection. Concretely, PointDistiller includes local distillation which extracts and distills the local geometric structure of point clouds with dynamic graph convolution and reweighted learning strategy, which highlights student learning on the crucial points or voxels to improve knowledge distillation efficiency. Extensive experiments on both voxels-based and raw points-based detectors have demonstrated the effectiveness of our method over seven previous knowledge distillation methods. For instance, our 4X compressed PointPillars student achieves 2.8 and 3.4 mAP improvements on BEV and 3D object detection, outperforming its teacher by 0.9 and 1.8 mAP, respectively. Codes have been released at https://github.com/RunpeiDong/PointDistiller.

</p>
</details>

<details><summary><b>MonoFormer: Towards Generalization of self-supervised monocular depth estimation with Transformers</b>
<a href="https://arxiv.org/abs/2205.11083">arxiv:2205.11083</a>
&#x1F4C8; 3 <br>
<p>Jinwoo Bae, Sungho Moon, Sunghoon Im</p></summary>
<p>

**Abstract:** Self-supervised monocular depth estimation has been widely studied recently. Most of the work has focused on improving performance on benchmark datasets, such as KITTI, but has offered a few experiments on generalization performance. In this paper, we investigate the backbone networks (e.g. CNNs, Transformers, and CNN-Transformer hybrid models) toward the generalization of monocular depth estimation. We first evaluate state-of-the-art models on diverse public datasets, which have never been seen during the network training. Next, we investigate the effects of texture-biased and shape-biased representations using the various texture-shifted datasets that we generated. We observe that Transformers exhibit a strong shape bias and CNNs do a strong texture-bias. We also find that shape-biased models show better generalization performance for monocular depth estimation compared to texture-biased models. Based on these observations, we newly design a CNN-Transformer hybrid network with a multi-level adaptive feature fusion module, called MonoFormer. The design intuition behind MonoFormer is to increase shape bias by employing Transformers while compensating for the weak locality bias of Transformers by adaptively fusing multi-level representations. Extensive experiments show that the proposed method achieves state-of-the-art performance with various public datasets. Our method also shows the best generalization ability among the competitive methods.

</p>
</details>

<details><summary><b>WOGAN at the SBST 2022 CPS Tool Competition</b>
<a href="https://arxiv.org/abs/2205.11064">arxiv:2205.11064</a>
&#x1F4C8; 3 <br>
<p>Jarkko Peltomäki, Frankie Spencer, Ivan Porres</p></summary>
<p>

**Abstract:** WOGAN is an online test generation algorithm based on Wasserstein generative adversarial networks. In this note, we present how WOGAN works and summarize its performance in the SBST 2022 CPS tool competition concerning the AI of a self-driving car.

</p>
</details>

<details><summary><b>Flow-based Recurrent Belief State Learning for POMDPs</b>
<a href="https://arxiv.org/abs/2205.11051">arxiv:2205.11051</a>
&#x1F4C8; 3 <br>
<p>Xiaoyu Chen, Yao Mu, Ping Luo, Shengbo Li, Jianyu Chen</p></summary>
<p>

**Abstract:** Partially Observable Markov Decision Process (POMDP) provides a principled and generic framework to model real world sequential decision making processes but yet remains unsolved, especially for high dimensional continuous space and unknown models. The main challenge lies in how to accurately obtain the belief state, which is the probability distribution over the unobservable environment states given historical information. Accurately calculating this belief state is a precondition for obtaining an optimal policy of POMDPs. Recent advances in deep learning techniques show great potential to learn good belief states. However, existing methods can only learn approximated distribution with limited flexibility. In this paper, we introduce the \textbf{F}l\textbf{O}w-based \textbf{R}ecurrent \textbf{BE}lief \textbf{S}tate model (FORBES), which incorporates normalizing flows into the variational inference to learn general continuous belief states for POMDPs. Furthermore, we show that the learned belief states can be plugged into downstream RL algorithms to improve performance. In experiments, we show that our methods successfully capture the complex belief states that enable multi-modal predictions as well as high quality reconstructions, and results on challenging visual-motor control tasks show that our method achieves superior performance and sample efficiency.

</p>
</details>

<details><summary><b>KQGC: Knowledge Graph Embedding with Smoothing Effects of Graph Convolutions for Recommendation</b>
<a href="https://arxiv.org/abs/2205.12102">arxiv:2205.12102</a>
&#x1F4C8; 2 <br>
<p>Daisuke Kikuta, Toyotaro Suzumura, Md Mostafizur Rahman, Yu Hirate, Satyen Abrol, Manoj Kondapaka, Takuma Ebisu, Pablo Loyola</p></summary>
<p>

**Abstract:** Leveraging graphs on recommender systems has gained popularity with the development of graph representation learning (GRL). In particular, knowledge graph embedding (KGE) and graph neural networks (GNNs) are representative GRL approaches, which have achieved the state-of-the-art performance on several recommendation tasks. Furthermore, combination of KGE and GNNs (KG-GNNs) has been explored and found effective in many academic literatures. One of the main characteristics of GNNs is their ability to retain structural properties among neighbors in the resulting dense representation, which is usually coined as smoothing. The smoothing is specially desired in the presence of homophilic graphs, such as the ones we find on recommender systems. In this paper, we propose a new model for recommender systems named Knowledge Query-based Graph Convolution (KQGC). In contrast to exisiting KG-GNNs, KQGC focuses on the smoothing, and leverages a simple linear graph convolution for smoothing KGE. A pre-trained KGE is fed into KQGC, and it is smoothed by aggregating neighbor knowledge queries, which allow entity-embeddings to be aligned on appropriate vector points for smoothing KGE effectively. We apply the proposed KQGC to a recommendation task that aims prospective users for specific products. Extensive experiments on a real E-commerce dataset demonstrate the effectiveness of KQGC.

</p>
</details>

<details><summary><b>Deep Learning Meets Software Engineering: A Survey on Pre-Trained Models of Source Code</b>
<a href="https://arxiv.org/abs/2205.11739">arxiv:2205.11739</a>
&#x1F4C8; 2 <br>
<p>Changan Niu, Chuanyi Li, Bin Luo, Vincent Ng</p></summary>
<p>

**Abstract:** Recent years have seen the successful application of deep learning to software engineering (SE). In particular, the development and use of pre-trained models of source code has enabled state-of-the-art results to be achieved on a wide variety of SE tasks. This paper provides an overview of this rapidly advancing field of research and reflects on future research directions.

</p>
</details>

<details><summary><b>On Advances in Text Generation from Images Beyond Captioning: A Case Study in Self-Rationalization</b>
<a href="https://arxiv.org/abs/2205.11686">arxiv:2205.11686</a>
&#x1F4C8; 2 <br>
<p>Shruti Palaskar, Akshita Bhagia, Yonatan Bisk, Florian Metze, Alan W Black, Ana Marasovic</p></summary>
<p>

**Abstract:** Integrating vision and language has gained notable attention following the success of pretrained language models. Despite that, a fraction of emerging multimodal models is suitable for text generation conditioned on images. This minority is typically developed and evaluated for image captioning, a text generation task conditioned solely on images with the goal to describe what is explicitly visible in an image. In this paper, we take a step back and ask: How do these models work for more complex generative tasks, conditioned on both text and images? Are models based on joint multimodal pretraining, visually adapted pretrained language models, or models that combine these two approaches, more promising for such tasks? We address these questions in the context of self-rationalization (jointly generating task labels/answers and free-text explanations) of three tasks: (i) visual question answering in VQA-X, (ii) visual commonsense reasoning in VCR, and (iii) visual-textual entailment in E-SNLI-VE. We show that recent advances in each modality, CLIP image representations and scaling of language models, do not consistently improve multimodal self-rationalization of tasks with multimodal inputs. We also observe that no model type works universally the best across tasks/datasets and finetuning data sizes. Our findings call for a backbone modelling approach that can be built on to advance text generation from images and text beyond image captioning.

</p>
</details>

<details><summary><b>Throwing Away Data Improves Worst-Class Error in Imbalanced Classification</b>
<a href="https://arxiv.org/abs/2205.11672">arxiv:2205.11672</a>
&#x1F4C8; 2 <br>
<p>Martin Arjovsky, Kamalika Chaudhuri, David Lopez-Paz</p></summary>
<p>

**Abstract:** Class imbalances pervade classification problems, yet their treatment differs in theory and practice. On the one hand, learning theory instructs us that \emph{more data is better}, as sample size relates inversely to the average test error over the entire data distribution. On the other hand, practitioners have long developed a plethora of tricks to improve the performance of learning machines over imbalanced data.
  These include data reweighting and subsampling, synthetic construction of additional samples from minority classes, ensembling expensive one-versus all architectures, and tweaking classification losses and thresholds. All of these are efforts to minimize the worst-class error, which is often associated to the minority group in the training data, and finds additional motivation in the robustness, fairness, and out-of-distribution literatures.
  Here we take on the challenge of developing learning theory able to describe the worst-class error of classifiers over linearly-separable data when fitted either on (i) the full training set, or (ii) a subset where the majority class is subsampled to match in size the minority class. We borrow tools from extreme value theory to show that, under distributions with certain tail properties, \emph{throwing away most data from the majority class leads to better worst-class error}.

</p>
</details>

<details><summary><b>A Natural Language Processing Pipeline for Detecting Informal Data References in Academic Literature</b>
<a href="https://arxiv.org/abs/2205.11651">arxiv:2205.11651</a>
&#x1F4C8; 2 <br>
<p>Sara Lafia, Lizhou Fan, Libby Hemphill</p></summary>
<p>

**Abstract:** Discovering authoritative links between publications and the datasets that they use can be a labor-intensive process. We introduce a natural language processing pipeline that retrieves and reviews publications for informal references to research datasets, which complements the work of data librarians. We first describe the components of the pipeline and then apply it to expand an authoritative bibliography linking thousands of social science studies to the data-related publications in which they are used. The pipeline increases recall for literature to review for inclusion in data-related collections of publications and makes it possible to detect informal data references at scale. We contribute (1) a novel Named Entity Recognition (NER) model that reliably detects informal data references and (2) a dataset connecting items from social science literature with datasets they reference. Together, these contributions enable future work on data reference, data citation networks, and data reuse.

</p>
</details>

<details><summary><b>Identifying Patient-Specific Root Causes of Disease</b>
<a href="https://arxiv.org/abs/2205.11627">arxiv:2205.11627</a>
&#x1F4C8; 2 <br>
<p>Eric V. Strobl, Thomas A. Lasko</p></summary>
<p>

**Abstract:** Complex diseases are caused by a multitude of factors that may differ between patients. As a result, hypothesis tests comparing all patients to all healthy controls can detect many significant variables with inconsequential effect sizes. A few highly predictive root causes may nevertheless generate disease within each patient. In this paper, we define patient-specific root causes as variables subject to exogenous "shocks" which go on to perturb an otherwise healthy system and induce disease. In other words, the variables are associated with the exogenous errors of a structural equation model (SEM), and these errors predict a downstream diagnostic label. We quantify predictivity using sample-specific Shapley values. This derivation allows us to develop a fast algorithm called Root Causal Inference for identifying patient-specific root causes by extracting the error terms of a linear SEM and then computing the Shapley value associated with each error. Experiments highlight considerable improvements in accuracy because the method uncovers root causes that may have large effect sizes at the individual level but clinically insignificant effect sizes at the group level. An R implementation is available at github.com/ericstrobl/RCI.

</p>
</details>

<details><summary><b>BolT: Fused Window Transformers for fMRI Time Series Analysis</b>
<a href="https://arxiv.org/abs/2205.11578">arxiv:2205.11578</a>
&#x1F4C8; 2 <br>
<p>Hasan Atakan Bedel, Irmak Şıvgın, Onat Dalmaz, Salman Ul Hassan Dar, Tolga Çukur</p></summary>
<p>

**Abstract:** Functional magnetic resonance imaging (fMRI) enables examination of inter-regional interactions in the brain via functional connectivity (FC) analyses that measure the synchrony between the temporal activations of separate regions. Given their exceptional sensitivity, deep-learning methods have received growing interest for FC analyses of high-dimensional fMRI data. In this domain, models that operate directly on raw time series as opposed to pre-computed FC features have the potential benefit of leveraging the full scale of information present in fMRI data. However, previous models are based on architectures suboptimal for temporal integration of representations across multiple time scales. Here, we present BolT, blood-oxygen-level-dependent transformer, for analyzing multi-variate fMRI time series. BolT leverages a cascade of transformer encoders equipped with a novel fused window attention mechanism. Transformer encoding is performed on temporally-overlapped time windows within the fMRI time series to capture short time-scale representations. To integrate information across windows, cross-window attention is computed between base tokens in each time window and fringe tokens from neighboring time windows. To transition from local to global representations, the extent of window overlap and thereby number of fringe tokens is progressively increased across the cascade. Finally, a novel cross-window regularization is enforced to align the high-level representations of global $CLS$ features across time windows. Comprehensive experiments on public fMRI datasets clearly illustrate the superior performance of BolT against state-of-the-art methods. Posthoc explanatory analyses to identify landmark time points and regions that contribute most significantly to model decisions corroborate prominent neuroscientific findings from recent fMRI studies.

</p>
</details>

<details><summary><b>Learning to Ignore Adversarial Attacks</b>
<a href="https://arxiv.org/abs/2205.11551">arxiv:2205.11551</a>
&#x1F4C8; 2 <br>
<p>Yiming Zhang, Yangqiaoyu Zhou, Samuel Carton, Chenhao Tan</p></summary>
<p>

**Abstract:** Despite the strong performance of current NLP models, they can be brittle against adversarial attacks. To enable effective learning against adversarial inputs, we introduce the use of rationale models that can explicitly learn to ignore attack tokens. We find that the rationale models can successfully ignore over 90\% of attack tokens. This approach leads to consistent sizable improvements ($\sim$10\%) over baseline models in robustness on three datasets for both BERT and RoBERTa, and also reliably outperforms data augmentation with adversarial examples alone. In many cases, we find that our method is able to close the gap between model performance on a clean test set and an attacked test set and hence reduce the effect of adversarial attacks.

</p>
</details>

<details><summary><b>Privacy-preserving Data Filtering in Federated Learning Using Influence Approximation</b>
<a href="https://arxiv.org/abs/2205.11518">arxiv:2205.11518</a>
&#x1F4C8; 2 <br>
<p>Ljubomir Rokvic, Panayiotis Danassis, Boi Faltings</p></summary>
<p>

**Abstract:** Federated Learning by nature is susceptible to low-quality, corrupted, or even malicious data that can severely degrade the quality of the learned model. Traditional techniques for data valuation cannot be applied as the data is never revealed. We present a novel technique for filtering, and scoring data based on a practical influence approximation that can be implemented in a privacy-preserving manner. Each agent uses his own data to evaluate the influence of another agent's batch, and reports to the center an obfuscated score using differential privacy. Our technique allows for almost perfect ($>92\%$ recall) filtering of corrupted data in a variety of applications using real-data. Importantly, the accuracy does not degrade significantly, even under really strong privacy guarantees ($\varepsilon \leq 1$), especially under realistic percentages of mislabeled data (for $15\%$ mislabeled data we only lose $10\%$ in accuracy).

</p>
</details>

<details><summary><b>Domain Adaptation for Memory-Efficient Dense Retrieval</b>
<a href="https://arxiv.org/abs/2205.11498">arxiv:2205.11498</a>
&#x1F4C8; 2 <br>
<p>Nandan Thakur, Nils Reimers, Jimmy Lin</p></summary>
<p>

**Abstract:** Dense retrievers encode documents into fixed dimensional embeddings. However, storing all the document embeddings within an index produces bulky indexes which are expensive to serve. Recently, BPR (Yamada et al., 2021) and JPQ (Zhan et al., 2021a) have been proposed which train the model to produce binary document vectors, which reduce the index 32x and more. The authors showed these binary embedding models significantly outperform more traditional index compression techniques like Product Quantization (PQ). Previous work evaluated these approaches just in-domain, i.e. the methods were evaluated on tasks for which training data is available. In practice, retrieval models are often used in an out-of-domain setting, where they have been trained on a publicly available dataset, like MS MARCO, but are then used for some custom dataset for which no training data is available.
  In this work, we show that binary embedding models like BPR and JPQ can perform significantly worse than baselines once there is a domain-shift involved. We propose a modification to the training procedure of BPR and JPQ and combine it with a corpus specific generative procedure which allow the adaptation of BPR and JPQ to any corpus without requiring labeled training data. Our domain-adapted strategy known as GPL is model agnostic, achieves an improvement by up-to 19.3 and 11.6 points in nDCG@10 across the BEIR benchmark in comparison to BPR and JPQ while maintaining its 32x memory efficiency. JPQ+GPL even outperforms our upper baseline: uncompressed TAS-B model on average by 2.0 points.

</p>
</details>

<details><summary><b>Local Byte Fusion for Neural Machine Translation</b>
<a href="https://arxiv.org/abs/2205.11490">arxiv:2205.11490</a>
&#x1F4C8; 2 <br>
<p>Makesh Narsimhan Sreedhar, Xiangpeng Wan, Yu Cheng, Junjie Hu</p></summary>
<p>

**Abstract:** Subword tokenization schemes are the dominant technique used in current NLP models. However, such schemes can be rigid and tokenizers built on one corpus do not adapt well to other parallel corpora. It has also been observed that in multilingual corpora, subword tokenization schemes over-segment low-resource languages leading to a drop in translation performance. A simple alternative to subword tokenizers is byte-based methods i.e. tokenization into byte sequences using encoding schemes such as UTF-8. Byte tokens often represent inputs at a sub-character granularity i.e. one character can be represented by a sequence of multiple byte tokens. This results in byte sequences that are significantly longer than character sequences. Enforcing aggregation of local information in the lower layers can guide the model to build higher-level semantic information. We propose a Local Byte Fusion (LOBEF) method for byte-based machine translation -- utilizing byte $n$-gram and word boundaries -- to aggregate local semantic information. Extensive experiments on multilingual translation, zero-shot cross-lingual transfer, and domain adaptation reveal a consistent improvement over traditional byte-based models and even over subword techniques. Further analysis also indicates that our byte-based models are parameter-efficient and can be trained faster than subword models.

</p>
</details>

<details><summary><b>Novel Light Field Imaging Device with Enhanced Light Collection for Cold Atom Clouds</b>
<a href="https://arxiv.org/abs/2205.11480">arxiv:2205.11480</a>
&#x1F4C8; 2 <br>
<p>Sanha Cheong, Josef C. Frisch, Sean Gasiorowski, Jason M. Hogan, Michael Kagan, Murtaza Safdari, Ariel Schwartzman, Maxime Vandegar</p></summary>
<p>

**Abstract:** We present a light field imaging system that captures multiple views of an object with a single shot. The system is designed to maximize the total light collection by accepting a larger solid angle of light than a conventional lens with equivalent depth of field. This is achieved by populating a plane of virtual objects using mirrors and fully utilizing the available field of view and depth of field. Simulation results demonstrate that this design is capable of single-shot tomography of objects of size $\mathcal{O}$(1 mm$^3$), reconstructing the 3-dimensional (3D) distribution and features not accessible from any single view angle in isolation. In particular, for atom clouds used in atom interferometry experiments, the system can reconstruct 3D fringe patterns with size $\mathcal{O}$(100 $μ$m). We also demonstrate this system with a 3D-printed prototype. The prototype is used to take images of $\mathcal{O}$(1 mm$^{3}$) sized objects, and 3D reconstruction algorithms running on a single-shot image successfully reconstruct $\mathcal{O}$(100 $μ$m) internal features. The prototype also shows that the system can be built with 3D printing technology and hence can be deployed quickly and cost-effectively in experiments with needs for enhanced light collection or 3D reconstruction. Imaging of cold atom clouds in atom interferometry is a key application of this new type of imaging device where enhanced light collection, high depth of field, and 3D tomographic reconstruction can provide new handles to characterize the atom clouds.

</p>
</details>

<details><summary><b>SQuALITY: Building a Long-Document Summarization Dataset the Hard Way</b>
<a href="https://arxiv.org/abs/2205.11465">arxiv:2205.11465</a>
&#x1F4C8; 2 <br>
<p>Alex Wang, Richard Yuanzhe Pang, Angelica Chen, Jason Phang, Samuel R. Bowman</p></summary>
<p>

**Abstract:** Summarization datasets are often assembled either by scraping naturally occurring public-domain summaries -- which are nearly always in difficult-to-work-with technical domains -- or by using approximate heuristics to extract them from everyday text -- which frequently yields unfaithful summaries. In this work, we turn to a slower but more straightforward approach to developing summarization benchmark data: We hire highly-qualified contractors to read stories and write original summaries from scratch. To amortize reading time, we collect five summaries per document, with the first giving an overview and the subsequent four addressing specific questions. We use this protocol to collect SQuALITY, a dataset of question-focused summaries built on the same public-domain short stories as the multiple-choice dataset QuALITY (Pang et al., 2021). Experiments with state-of-the-art summarization systems show that our dataset is challenging and that existing automatic evaluation metrics are weak indicators of quality.

</p>
</details>

<details><summary><b>Data augmentation for efficient learning from parametric experts</b>
<a href="https://arxiv.org/abs/2205.11448">arxiv:2205.11448</a>
&#x1F4C8; 2 <br>
<p>Alexandre Galashov, Josh Merel, Nicolas Heess</p></summary>
<p>

**Abstract:** We present a simple, yet powerful data-augmentation technique to enable data-efficient learning from parametric experts for reinforcement and imitation learning. We focus on what we call the policy cloning setting, in which we use online or offline queries of an expert or expert policy to inform the behavior of a student policy. This setting arises naturally in a number of problems, for instance as variants of behavior cloning, or as a component of other algorithms such as DAGGER, policy distillation or KL-regularized RL. Our approach, augmented policy cloning (APC), uses synthetic states to induce feedback-sensitivity in a region around sampled trajectories, thus dramatically reducing the environment interactions required for successful cloning of the expert. We achieve highly data-efficient transfer of behavior from an expert to a student policy for high-degrees-of-freedom control problems. We demonstrate the benefit of our method in the context of several existing and widely used algorithms that include policy cloning as a constituent part. Moreover, we highlight the benefits of our approach in two practically relevant settings (a) expert compression, i.e. transfer to a student with fewer parameters; and (b) transfer from privileged experts, i.e. where the expert has a different observation space than the student, usually including access to privileged information.

</p>
</details>

<details><summary><b>Overfitting in quantum machine learning and entangling dropout</b>
<a href="https://arxiv.org/abs/2205.11446">arxiv:2205.11446</a>
&#x1F4C8; 2 <br>
<p>Masahiro Kobayashi, Kohei Nakaji, Naoki Yamamoto</p></summary>
<p>

**Abstract:** The ultimate goal in machine learning is to construct a model function that has a generalization capability for unseen dataset, based on given training dataset. If the model function has too much expressibility power, then it may overfit to the training data and as a result lose the generalization capability. To avoid such overfitting issue, several techniques have been developed in the classical machine learning regime, and the dropout is one such effective method. This paper proposes a straightforward analogue of this technique in the quantum machine learning regime, the entangling dropout, meaning that some entangling gates in a given parametrized quantum circuit are randomly removed during the training process to reduce the expressibility of the circuit. Some simple case studies are given to show that this technique actually suppresses the overfitting.

</p>
</details>

<details><summary><b>Informed Pre-Training on Prior Knowledge</b>
<a href="https://arxiv.org/abs/2205.11433">arxiv:2205.11433</a>
&#x1F4C8; 2 <br>
<p>Laura von Rueden, Sebastian Houben, Kostadin Cvejoski, Christian Bauckhage, Nico Piatkowski</p></summary>
<p>

**Abstract:** When training data is scarce, the incorporation of additional prior knowledge can assist the learning process. While it is common to initialize neural networks with weights that have been pre-trained on other large data sets, pre-training on more concise forms of knowledge has rather been overlooked. In this paper, we propose a novel informed machine learning approach and suggest to pre-train on prior knowledge. Formal knowledge representations, e.g. graphs or equations, are first transformed into a small and condensed data set of knowledge prototypes. We show that informed pre-training on such knowledge prototypes (i) speeds up the learning processes, (ii) improves generalization capabilities in the regime where not enough training data is available, and (iii) increases model robustness. Analyzing which parts of the model are affected most by the prototypes reveals that improvements come from deeper layers that typically represent high-level features. This confirms that informed pre-training can indeed transfer semantic knowledge. This is a novel effect, which shows that knowledge-based pre-training has additional and complementary strengths to existing approaches.

</p>
</details>

<details><summary><b>Variable-Input Deep Operator Networks</b>
<a href="https://arxiv.org/abs/2205.11404">arxiv:2205.11404</a>
&#x1F4C8; 2 <br>
<p>Michael Prasthofer, Tim De Ryck, Siddhartha Mishra</p></summary>
<p>

**Abstract:** Existing architectures for operator learning require that the number and locations of sensors (where the input functions are evaluated) remain the same across all training and test samples, significantly restricting the range of their applicability. We address this issue by proposing a novel operator learning framework, termed Variable-Input Deep Operator Network (VIDON), which allows for random sensors whose number and locations can vary across samples. VIDON is invariant to permutations of sensor locations and is proved to be universal in approximating a class of continuous operators. We also prove that VIDON can efficiently approximate operators arising in PDEs. Numerical experiments with a diverse set of PDEs are presented to illustrate the robust performance of VIDON in learning operators.

</p>
</details>

<details><summary><b>Learned Digital Back-Propagation for Dual-Polarization Dispersion Managed Systems</b>
<a href="https://arxiv.org/abs/2205.11376">arxiv:2205.11376</a>
&#x1F4C8; 2 <br>
<p>Mohannad Abu-romoh, Nelson Costa, Antonio Napoli, Bernhard Spinnler, Yves Jaouën, Mansoor Yousefi</p></summary>
<p>

**Abstract:** Digital back-propagation (DBP) and learned DBP (LDBP) are proposed for nonlinearity mitigation in WDM dual-polarization dispersion-managed systems. LDBP achieves Q-factor improvement of 1.8 dB and 1.2 dB, respectively, over linear equalization and a variant of DBP adapted to DM systems.

</p>
</details>

<details><summary><b>Capacity Bounds for the DeepONet Method of Solving Differential Equations</b>
<a href="https://arxiv.org/abs/2205.11359">arxiv:2205.11359</a>
&#x1F4C8; 2 <br>
<p>Pulkit Gopalani, Sayar Karmakar, Anirbit Mukherjee</p></summary>
<p>

**Abstract:** In recent times machine learning methods have made significant advances in becoming a useful tool for analyzing physical systems. A particularly active area in this theme has been "physics informed machine learning" [1] which focuses on using neural nets for numerically solving differential equations. Among all the proposals for solving differential equations using deep-learning, in this paper we aim to advance the theory of generalization error for DeepONets - which is unique among all the available ideas because of its particularly intriguing structure of having an inner-product of two neural nets.
  Our key contribution is to give a bound on the Rademacher complexity for a large class of DeepONets. Our bound does not explicitly scale with the number of parameters of the nets involved and is thus a step towards explaining the efficacy of overparameterized DeepONets. Additionally, a capacity bound such as ours suggests a novel regularizer on the neural net weights that can help in training DeepONets - irrespective of the differential equation being solved.
  [1] G. E. Karniadakis, I. G. Kevrekidis, L. Lu, P. Perdikaris, S. Wang, and L. Yang. Physics-informed machine learning. Nature Reviews Physics, 2021.

</p>
</details>

<details><summary><b>Arbitrary Reduction of MRI Slice Spacing Based on Local-Aware Implicit Representation</b>
<a href="https://arxiv.org/abs/2205.11346">arxiv:2205.11346</a>
&#x1F4C8; 2 <br>
<p>Xin Wang, Kai Xuan, Sheng Wang, Honglin Xiong, Lichi Zhang, Qian Wang</p></summary>
<p>

**Abstract:** Magnetic resonance (MR) images are often acquired in 2D settings for real clinical applications. The 3D volumes reconstructed by stacking multiple 2D slices have large inter-slice spacing, resulting in lower inter-slice resolution than intra-slice resolution. Super-resolution is a powerful tool to reduce the inter-slice spacing of 3D images to facilitate subsequent visualization and computation tasks. However, most existing works train the super-resolution network at a fixed ratio, which is inconvenient in clinical scenes due to the heterogeneous parameters in MR scanning. In this paper, we propose a single super-resolution network to reduce the inter-slice spacing of MR images at an arbitrarily adjustable ratio. Specifically, we view the input image as a continuous implicit function of coordinates. The intermediate slices of different spacing ratios could be constructed according to the implicit representation up-sampled in the continuous domain. We particularly propose a novel local-aware spatial attention mechanism and long-range residual learning to boost the quality of the output image. The experimental results demonstrate the superiority of our proposed method, even compared to the models trained at a fixed ratio.

</p>
</details>

<details><summary><b>An Evaluation Study of Intrinsic Motivation Techniques applied to Reinforcement Learning over Hard Exploration Environments</b>
<a href="https://arxiv.org/abs/2205.11184">arxiv:2205.11184</a>
&#x1F4C8; 2 <br>
<p>Alain Andres, Esther Villar-Rodriguez, Javier Del Ser</p></summary>
<p>

**Abstract:** In the last few years, the research activity around reinforcement learning tasks formulated over environments with sparse rewards has been especially notable. Among the numerous approaches proposed to deal with these hard exploration problems, intrinsic motivation mechanisms are arguably among the most studied alternatives to date. Advances reported in this area over time have tackled the exploration issue by proposing new algorithmic ideas to generate alternative mechanisms to measure the novelty. However, most efforts in this direction have overlooked the influence of different design choices and parameter settings that have also been introduced to improve the effect of the generated intrinsic bonus, forgetting the application of those choices to other intrinsic motivation techniques that may also benefit of them. Furthermore, some of those intrinsic methods are applied with different base reinforcement algorithms (e.g. PPO, IMPALA) and neural network architectures, being hard to fairly compare the provided results and the actual progress provided by each solution. The goal of this work is to stress on this crucial matter in reinforcement learning over hard exploration environments, exposing the variability and susceptibility of avant-garde intrinsic motivation techniques to diverse design factors. Ultimately, our experiments herein reported underscore the importance of a careful selection of these design aspects coupled with the exploration requirements of the environment and the task in question under the same setup, so that fair comparisons can be guaranteed.

</p>
</details>

<details><summary><b>Logarithmic regret bounds for continuous-time average-reward Markov decision processes</b>
<a href="https://arxiv.org/abs/2205.11168">arxiv:2205.11168</a>
&#x1F4C8; 2 <br>
<p>Xuefeng Gao, Xun Yu Zhou</p></summary>
<p>

**Abstract:** We consider reinforcement learning for continuous-time Markov decision processes (MDPs) in the infinite-horizon, average-reward setting. In contrast to discrete-time MDPs, a continuous-time process moves to a state and stays there for a random holding time after an action is taken. With unknown transition probabilities and rates of exponential holding times, we derive instance-dependent regret lower bounds that are logarithmic in the time horizon. Moreover, we design a learning algorithm and establish a finite-time regret bound that achieves the logarithmic growth rate. Our analysis builds upon upper confidence reinforcement learning, a delicate estimation of the mean holding times, and stochastic comparison of point processes.

</p>
</details>

<details><summary><b>A Coupling Enhancement Algorithm for ZrO2 Ceramic Bearing Ball Surface Defect Detection Based on Cartoon-texture Decomposition Model and Multi-Scale Filtering Method</b>
<a href="https://arxiv.org/abs/2205.11145">arxiv:2205.11145</a>
&#x1F4C8; 2 <br>
<p>Wei Wang, Xin Zhang, Jiaqi Yi, Xianqi Liao, Wenjie Li, Zhenhong Li</p></summary>
<p>

**Abstract:** This study aimed to improve the surface defect detection accuracy of ZrO2 ceramic bearing balls. Combined with the noise damage of the image samples, a surface defect detection method for ZrO2 ceramic bearing balls based on cartoon-texture decomposition model was proposed. Building a ZrO2 ceramic bearing ball surface defect detection system. The ZrO2 ceramic bearing ball surface defect image was decomposed by using the Gaussian curvature model and the decomposed image layer was filtered by using Winner filter and wavelet value domain filter. Then they were fused into a clear and undamaged ZrO2 ceramic bearing ball surface defect image and detected. The experimental results show that the image denoising method of ZrO2 ceramic bearing ball surface defect based on cartoon-texture decomposition model can denoise while retaining the image details. The PSNR of image is 34.1 dB, the SSIM is 0.9476, the detection accuracy is 95.8%, and the detection speed of a single defect image is 191ms / img. This method can effectively improve the efficiency and accuracy of ZrO2 ceramic bearing ball surface defect detection.

</p>
</details>

<details><summary><b>Stability of the scattering transform for deformations with minimal regularity</b>
<a href="https://arxiv.org/abs/2205.11142">arxiv:2205.11142</a>
&#x1F4C8; 2 <br>
<p>Fabio Nicola, S. Ivan Trapasso</p></summary>
<p>

**Abstract:** Within the mathematical analysis of deep convolutional neural networks, the wavelet scattering transform introduced by Stéphane Mallat is a unique example of how the ideas of multiscale analysis can be combined with a cascade of modulus nonlinearities to build a nonexpansive, translation invariant signal representation with provable geometric stability properties, namely Lipschitz continuity to the action of small $C^2$ diffeomorphisms - a remarkable result for both theoretical and practical purposes, inherently depending on the choice of the filters and their arrangement into a hierarchical architecture. In this note, we further investigate the intimate relationship between the scattering structure and the regularity of the deformation in the Hölder regularity scale $C^α$, $α>0$. We are able to precisely identify the stability threshold, proving that stability is still achievable for deformations of class $C^α$, $α>1$, whereas instability phenomena can occur at lower regularity levels modelled by $C^α$, $0\le α<1$. While the behaviour at the threshold given by Lipschitz (or even $C^1$) regularity remains beyond reach, we are able to prove a stability bound in that case, up to $\varepsilon$ losses.

</p>
</details>

<details><summary><b>PyRelationAL: A Library for Active Learning Research and Development</b>
<a href="https://arxiv.org/abs/2205.11117">arxiv:2205.11117</a>
&#x1F4C8; 2 <br>
<p>Paul Scherer, Thomas Gaudelet, Alison Pouplin, Suraj M S, Jyothish Soman, Lindsay Edwards, Jake P. Taylor-King</p></summary>
<p>

**Abstract:** In constrained real-world scenarios where it is challenging or costly to generate data, disciplined methods for acquiring informative new data points are of fundamental importance for the efficient training of machine learning (ML) models. Active learning (AL) is a subfield of ML focused on the development of methods to iteratively and economically acquire data through strategically querying new data points that are the most useful for a particular task. Here, we introduce PyRelationAL, an open source library for AL research. We describe a modular toolkit that is compatible with diverse ML frameworks (e.g. PyTorch, Scikit-Learn, TensorFlow, JAX). Furthermore, to help accelerate research and development in the field, the library implements a number of published methods and provides API access to wide-ranging benchmark datasets and AL task configurations based on existing literature. The library is supplemented by an expansive set of tutorials, demos, and documentation to help users get started. We perform experiments on the PyRelationAL collection of benchmark datasets and showcase the considerable economies that AL can provide. PyRelationAL is maintained using modern software engineering practices - with an inclusive contributor code of conduct - to promote long term library quality and utilisation.

</p>
</details>

<details><summary><b>DTU-Net: Learning Topological Similarity for Curvilinear Structure Segmentation</b>
<a href="https://arxiv.org/abs/2205.11115">arxiv:2205.11115</a>
&#x1F4C8; 2 <br>
<p>Manxi Lin, Zahra Bashir, Martin Grønnebæk Tolsgaard, Anders Nymark Christensen, Aasa Feragen</p></summary>
<p>

**Abstract:** Curvilinear structure segmentation plays an important role in many applications. The standard formulation of segmentation as pixel-wise classification often fails to capture these structures due to the small size and low contrast. Some works introduce prior topological information to address this problem with the cost of expensive computations and the need for extra labels. Moreover, prior work primarily focuses on avoiding false splits by encouraging the connection of small gaps. Less attention has been given to avoiding missed splits, namely the incorrect inference of structures that are not visible in the image.
  In this paper, we present DTU-Net, a dual-decoder and topology-aware deep neural network consisting of two sequential light-weight U-Nets, namely a texture net, and a topology net. The texture net makes a coarse prediction using image texture information. The topology net learns topological information from the coarse prediction by employing a triplet loss trained to recognize false and missed splits, and provides a topology-aware separation of the foreground and background. The separation is further utilized to correct the coarse prediction. We conducted experiments on a challenging multi-class ultrasound scan segmentation dataset and an open dataset for road extraction. Results show that our model achieves state-of-the-art results in both segmentation accuracy and continuity. Compared to existing methods, our model corrects both false positive and false negative examples more effectively with no need for prior knowledge.

</p>
</details>

<details><summary><b>DistilCamemBERT: a distillation of the French model CamemBERT</b>
<a href="https://arxiv.org/abs/2205.11111">arxiv:2205.11111</a>
&#x1F4C8; 2 <br>
<p>Cyrile Delestre, Abibatou Amar</p></summary>
<p>

**Abstract:** Modern Natural Language Processing (NLP) models based on Transformer structures represent the state of the art in terms of performance on very diverse tasks. However, these models are complex and represent several hundred million parameters for the smallest of them. This may hinder their adoption at the industrial level, making it difficult to scale up to a reasonable infrastructure and/or to comply with societal and environmental responsibilities. To this end, we present in this paper a model that drastically reduces the computational cost of a well-known French model (CamemBERT), while preserving good performance.

</p>
</details>

<details><summary><b>TempLM: Distilling Language Models into Template-Based Generators</b>
<a href="https://arxiv.org/abs/2205.11055">arxiv:2205.11055</a>
&#x1F4C8; 2 <br>
<p>Tianyi Zhang, Mina Lee, Lisa Li, Ende Shen, Tatsunori B. Hashimoto</p></summary>
<p>

**Abstract:** While pretrained language models (PLMs) have greatly improved text generation, they have also been known to produce unfaithful or inappropriate content. In contrast, classic template-based systems provide strong guarantees of faithfulness at the cost of fluency. We propose TempLM, which achieves the best of both worlds by distilling a PLM into a template-based generator. On the E2E and SynthBio data-to-text datasets, we show that TempLM is more faithful than the original PLM and is more fluent than prior template systems. Notably, on an out-of-domain evaluation, TempLM reduces a finetuned BART model's unfaithfulness rate from 83% to 0%. In a human study, we find that TempLM's templates substantially improve upon human-written ones in BERTScore.

</p>
</details>

<details><summary><b>Personalized Federated Learning with Server-Side Information</b>
<a href="https://arxiv.org/abs/2205.11044">arxiv:2205.11044</a>
&#x1F4C8; 2 <br>
<p>Jaehun Song, Min-hwan Oh, Hyung-Sin Kim</p></summary>
<p>

**Abstract:** Personalized Federated Learning (FL) is an emerging research field in FL that learns an easily adaptable global model in the presence of data heterogeneity among clients. However, one of the main challenges for personalized FL is the heavy reliance on clients' computing resources to calculate higher-order gradients since client data is segregated from the server to ensure privacy. To resolve this, we focus on a problem setting where the server may possess its own data independent of clients' data -- a prevalent problem setting in various applications, yet relatively unexplored in existing literature. Specifically, we propose FedSIM, a new method for personalized FL that actively utilizes such server data to improve meta-gradient calculation in the server for increased personalization performance. Experimentally, we demonstrate through various benchmarks and ablations that FedSIM is superior to existing methods in terms of accuracy, more computationally efficient by calculating the full meta-gradients in the server, and converges up to 34.2% faster.

</p>
</details>

<details><summary><b>FLEX: Feature-Logic Embedding Framework for CompleX Knowledge Graph Reasoning</b>
<a href="https://arxiv.org/abs/2205.11039">arxiv:2205.11039</a>
&#x1F4C8; 2 <br>
<p>Xueyuan Lin, Haihong E, Gengxian Zhou, Tianyi Hu, Li Ningyuan, Mingzhi Sun, Haoran Luo</p></summary>
<p>

**Abstract:** Current best performing models for knowledge graph reasoning (KGR) are based on complex distribution or geometry objects to embed entities and first-order logical (FOL) queries in low-dimensional spaces. They can be summarized as a center-size framework (point/box/cone, Beta/Gaussian distribution, etc.) whose logical reasoning ability is limited by the expressiveness of the relevant mathematical concepts. Because too deeply the center and the size depend on each other, it is difficult to integrate the logical reasoning ability with other models. To address these challenges, we instead propose a novel KGR framework named Feature-Logic Embedding framework, FLEX, which is the first KGR framework that can not only TRULY handle all FOL operations including conjunction, disjunction, negation and so on, but also support various feature spaces. Specifically, the logic part of feature-logic framework is based on vector logic, which naturally models all FOL operations. Experiments demonstrate that FLEX significantly outperforms existing state-of-the-art methods on benchmark datasets.

</p>
</details>

<details><summary><b>Theoretical Analysis of Primal-Dual Algorithm for Non-Convex Stochastic Decentralized Optimization</b>
<a href="https://arxiv.org/abs/2205.11979">arxiv:2205.11979</a>
&#x1F4C8; 1 <br>
<p>Yuki Takezawa, Kenta Niwa, Makoto Yamada</p></summary>
<p>

**Abstract:** In recent years, decentralized learning has emerged as a powerful tool not only for large-scale machine learning, but also for preserving privacy. One of the key challenges in decentralized learning is that the data distribution held by each node is statistically heterogeneous. To address this challenge, the primal-dual algorithm called the Edge-Consensus Learning (ECL) was proposed and was experimentally shown to be robust to the heterogeneity of data distributions. However, the convergence rate of the ECL is provided only when the objective function is convex, and has not been shown in a standard machine learning setting where the objective function is non-convex. Furthermore, the intuitive reason why the ECL is robust to the heterogeneity of data distributions has not been investigated. In this work, we first investigate the relationship between the ECL and Gossip algorithm and show that the update formulas of the ECL can be regarded as correcting the local stochastic gradient in the Gossip algorithm. Then, we propose the Generalized ECL (G-ECL), which contains the ECL as a special case, and provide the convergence rates of the G-ECL in both (strongly) convex and non-convex settings, which do not depend on the heterogeneity of data distributions. Through synthetic experiments, we demonstrate that the numerical results of both the G-ECL and ECL coincide with the convergence rate of the G-ECL.

</p>
</details>

<details><summary><b>Learning Context-Aware Service Representation for Service Recommendation in Workflow Composition</b>
<a href="https://arxiv.org/abs/2205.11771">arxiv:2205.11771</a>
&#x1F4C8; 1 <br>
<p>Xihao Xie, Jia Zhang, Rahul Ramachandran, Tsengdar J. Lee, Seungwon Lee</p></summary>
<p>

**Abstract:** As increasingly more software services have been published onto the Internet, it remains a significant challenge to recommend suitable services to facilitate scientific workflow composition. This paper proposes a novel NLP-inspired approach to recommending services throughout a workflow development process, based on incrementally learning latent service representation from workflow provenance. A workflow composition process is formalized as a step-wise, context-aware service generation procedure, which is mapped to next-word prediction in a natural language sentence. Historical service dependencies are extracted from workflow provenance to build and enrich a knowledge graph. Each path in the knowledge graph reflects a scenario in a data analytics experiment, which is analogous to a sentence in a conversation. All paths are thus formalized as composable service sequences and are mined, using various patterns, from the established knowledge graph to construct a corpus. Service embeddings are then learned by applying deep learning model from the NLP field. Extensive experiments on the real-world dataset demonstrate the effectiveness and efficiency of the approach.

</p>
</details>

<details><summary><b>BabyBear: Cheap inference triage for expensive language models</b>
<a href="https://arxiv.org/abs/2205.11747">arxiv:2205.11747</a>
&#x1F4C8; 1 <br>
<p>Leila Khalili, Yao You, John Bohannon</p></summary>
<p>

**Abstract:** Transformer language models provide superior accuracy over previous models but they are computationally and environmentally expensive. Borrowing the concept of model cascading from computer vision, we introduce BabyBear, a framework for cascading models for natural language processing (NLP) tasks to minimize cost. The core strategy is inference triage, exiting early when the least expensive model in the cascade achieves a sufficiently high-confidence prediction. We test BabyBear on several open source data sets related to document classification and entity recognition. We find that for common NLP tasks a high proportion of the inference load can be accomplished with cheap, fast models that have learned by observing a deep learning model. This allows us to reduce the compute cost of large-scale classification jobs by more than 50% while retaining overall accuracy. For named entity recognition, we save 33% of the deep learning compute while maintaining an F1 score higher than 95% on the CoNLL benchmark.

</p>
</details>

<details><summary><b>Demand Response Method Considering Multiple Types of Flexible Loads in Industrial Parks</b>
<a href="https://arxiv.org/abs/2205.11743">arxiv:2205.11743</a>
&#x1F4C8; 1 <br>
<p>Jia Cui, Mingze Gao, Xiaoming Zhou, Yang Li, Wei Liu, Jiazheng Tian, Ximing Zhang</p></summary>
<p>

**Abstract:** With the rapid development of the energy internet, the proportion of flexible loads in smart grid is getting much higher than before. It is highly important to model flexible loads based on demand response. Therefore, a new demand response method considering multiple flexible loads is proposed in this paper to character the integrated demand response (IDR) resources. Firstly, a physical process analytical deduction (PPAD) model is proposed to improve the classification of flexible loads in industrial parks. Scenario generation, data point augmentation, and smooth curves under various operating conditions are considered to enhance the applicability of the model. Secondly, in view of the strong volatility and poor modeling effect of Wasserstein-generative adversarial networks (WGAN), an improved WGAN-gradient penalty (IWGAN-GP) model is developed to get a faster convergence speed than traditional WGAN and generate a higher quality samples. Finally, the PPAD and IWGAN-GP models are jointly implemented to reveal the degree of correlation between flexible loads. Meanwhile, an intelligent offline database is built to deal with the impact of nonlinear factors in different response scenarios. Numerical examples have been performed with the results proving that the proposed method is significantly better than the existing technologies in reducing load modeling deviation and improving the responsiveness of park loads.

</p>
</details>

<details><summary><b>PERT: A New Solution to Pinyin to Character Conversion Task</b>
<a href="https://arxiv.org/abs/2205.11737">arxiv:2205.11737</a>
&#x1F4C8; 1 <br>
<p>Jinghui Xiao, Qun Liu, Xin Jiang, Yuanfeng Xiong, Haiteng Wu, Zhe Zhang</p></summary>
<p>

**Abstract:** Pinyin to Character conversion (P2C) task is the key task of Input Method Engine (IME) in commercial input software for Asian languages, such as Chinese, Japanese, Thai language and so on. It's usually treated as sequence labelling task and resolved by language model, i.e. n-gram or RNN. However, the low capacity of the n-gram or RNN limits its performance. This paper introduces a new solution named PERT which stands for bidirectional Pinyin Encoder Representations from Transformers. It achieves significant improvement of performance over baselines. Furthermore, we combine PERT with n-gram under a Markov framework, and improve performance further. Lastly, the external lexicon is incorporated into PERT so as to resolve the OOD issue of IME.

</p>
</details>

<details><summary><b>Machine Learning for Electricity Market Clearing</b>
<a href="https://arxiv.org/abs/2205.11641">arxiv:2205.11641</a>
&#x1F4C8; 1 <br>
<p>Laurent Pagnier, Robert Ferrando, Yury Dvorkin, Michael Chertkov</p></summary>
<p>

**Abstract:** This paper seeks to design a machine learning twin of the optimal power flow (OPF) optimization, which is used in market-clearing procedures by wholesale electricity markets. The motivation for the proposed approach stems from the need to obtain the digital twin, which is much faster than the original, while also being sufficiently accurate and producing consistent generation dispatches and locational marginal prices (LMPs), which are primal and dual solutions of the OPF optimization, respectively. Availability of market-clearing tools based on this approach will enable computationally tractable evaluation of multiple dispatch scenarios under a given unit commitment. Rather than direct solution of OPF, the Karush-Kuhn-Tucker (KKT) conditions for the OPF problem in question may be written, and in parallel the LMPs of generators and loads may be expressed in terms of the OPF Lagrangian multipliers. Also, taking advantage of the practical fact that many of the Lagrangian multipliers associated with lines will be zero (thermal limits are not binding), we build and train an ML scheme which maps flexible resources (loads and renewables) to the binding lines, and supplement it with an efficient power-grid aware linear map to optimal dispatch and LMPs. The scheme is validated and illustrated on IEEE models. We also report a trade of analysis between quality of the reconstruction and number of samples needed to train the model.

</p>
</details>

<details><summary><b>Utilizing Language-Image Pretraining for Efficient and Robust Bilingual Word Alignment</b>
<a href="https://arxiv.org/abs/2205.11616">arxiv:2205.11616</a>
&#x1F4C8; 1 <br>
<p>Tuan Dinh, Jy-yong Sohn, Shashank Rajput, Timothy Ossowski, Yifei Ming, Junjie Hu, Dimitris Papailiopoulos, Kangwook Lee</p></summary>
<p>

**Abstract:** Word translation without parallel corpora has become feasible, rivaling the performance of supervised methods. Recent findings have shown that the accuracy and robustness of unsupervised word translation (UWT) can be improved by making use of visual observations, which are universal representations across languages. In this work, we investigate the potential of using not only visual observations but also pretrained language-image models for enabling a more efficient and robust UWT. Specifically, we develop a novel UWT method dubbed Word Alignment using Language-Image Pretraining (WALIP), which leverages visual observations via the shared embedding space of images and texts provided by CLIP models (Radford et al., 2021). WALIP has a two-step procedure. First, we retrieve word pairs with high confidences of similarity, computed using our proposed image-based fingerprints, which define the initial pivot for the word alignment. Second, we apply our robust Procrustes algorithm to estimate the linear mapping between two embedding spaces, which iteratively corrects and refines the estimated alignment. Our extensive experiments show that WALIP improves upon the state-of-the-art performance of bilingual word alignment for a few language pairs across different word embeddings and displays great robustness to the dissimilarity of language pairs or training corpora for two word embeddings.

</p>
</details>

<details><summary><b>FedSA: Accelerating Intrusion Detection in Collaborative Environments with Federated Simulated Annealing</b>
<a href="https://arxiv.org/abs/2205.11519">arxiv:2205.11519</a>
&#x1F4C8; 1 <br>
<p>Helio N. Cunha Neto, Ivana Dusparic, Diogo M. F. Mattos, Natalia C. Fernandes</p></summary>
<p>

**Abstract:** Fast identification of new network attack patterns is crucial for improving network security. Nevertheless, identifying an ongoing attack in a heterogeneous network is a non-trivial task. Federated learning emerges as a solution to collaborative training for an Intrusion Detection System (IDS). The federated learning-based IDS trains a global model using local machine learning models provided by federated participants without sharing local data. However, optimization challenges are intrinsic to federated learning. This paper proposes the Federated Simulated Annealing (FedSA) metaheuristic to select the hyperparameters and a subset of participants for each aggregation round in federated learning. FedSA optimizes hyperparameters linked to the global model convergence. The proposal reduces aggregation rounds and speeds up convergence. Thus, FedSA accelerates learning extraction from local models, requiring fewer IDS updates. The proposal assessment shows that the FedSA global model converges in less than ten communication rounds. The proposal requires up to 50% fewer aggregation rounds to achieve approximately 97% accuracy in attack detection than the conventional aggregation approach.

</p>
</details>

<details><summary><b>CELEST: Federated Learning for Globally Coordinated Threat Detection</b>
<a href="https://arxiv.org/abs/2205.11459">arxiv:2205.11459</a>
&#x1F4C8; 1 <br>
<p>Talha Ongun, Simona Boboila, Alina Oprea, Tina Eliassi-Rad, Jason Hiser, Jack Davidson</p></summary>
<p>

**Abstract:** The cyber-threat landscape has evolved tremendously in recent years, with new threat variants emerging daily, and large-scale coordinated campaigns becoming more prevalent. In this study, we propose CELEST (CollaborativE LEarning for Scalable Threat detection), a federated machine learning framework for global threat detection over HTTP, which is one of the most commonly used protocols for malware dissemination and communication. CELEST leverages federated learning in order to collaboratively train a global model across multiple clients who keep their data locally, thus providing increased privacy and confidentiality assurances. Through a novel active learning component integrated with the federated learning technique, our system continuously discovers and learns the behavior of new, evolving, and globally-coordinated cyber threats. We show that CELEST is able to expose attacks that are largely invisible to individual organizations. For instance, in one challenging attack scenario with data exfiltration malware, the global model achieves a three-fold increase in Precision-Recall AUC compared to the local model. We deploy CELEST on two university networks and show that it is able to detect the malicious HTTP communication with high precision and low false positive rates. Furthermore, during its deployment, CELEST detected a set of previously unknown 42 malicious URLs and 20 malicious domains in one day, which were confirmed to be malicious by VirusTotal.

</p>
</details>

<details><summary><b>Federated Distillation based Indoor Localization for IoT Networks</b>
<a href="https://arxiv.org/abs/2205.11440">arxiv:2205.11440</a>
&#x1F4C8; 1 <br>
<p>Yaya Etiabi, Marwa Chafii, El Mehdi Amhoud</p></summary>
<p>

**Abstract:** Federated distillation (FD) paradigm has been recently proposed as a promising alternative to federated learning (FL) especially in wireless sensor networks with limited communication resources. However, all state-of-the art FD algorithms are designed for only classification tasks and less attention has been given to regression tasks. In this work, we propose an FD framework that properly operates on regression learning problems. Afterwards, we present a use-case implementation by proposing an indoor localization system that shows a good trade-off communication load vs. accuracy compared to federated learning (FL) based indoor localization. With our proposed framework, we reduce the number of transmitted bits by up to 98%. Moreover, we show that the proposed framework is much more scalable than FL, thus more likely to cope with the expansion of wireless networks.

</p>
</details>

<details><summary><b>Spreading Factor and RSSI for Localization in LoRa Networks: A Deep Reinforcement Learning Approach</b>
<a href="https://arxiv.org/abs/2205.11428">arxiv:2205.11428</a>
&#x1F4C8; 1 <br>
<p>Yaya Etiabi, Mohammed JOUHARI, El Mehdi Amhoud</p></summary>
<p>

**Abstract:** Recent advancements in Internet of Things (IoT) technologies have resulted in a tightening of requirements from various applications including localization in LoRa networks. To address the growing demand for LoRaWAN-powered IoT location-based services, accurate localization solutions are more crucial than ever. As such, in this work, we develop an accurate deep neural network based localization framework over a LoRa network by proposing a novel approach that builds the network radio map with the combination of RSSI recordings and the spreading factors (SF) used by LoRa devices during the transmissions. Then, we validate our framework using a publicly available experimental dataset recorded in an urban LoRa network. The performance evaluation shows the prominence of adding the spreading factor as an additional fingerprint, since we can achieve, by our approach, an improvement in localization accuracy by up to 6.67% compared to the state-of-the-art methods which employ uniquely the RSSI fingerprints. Additionally, we provide an analysis of the impact of the SF on the localization performance which reveals that the localization accuracy relies on the SF used for position request. Finally, we propose a deep reinforcement learning based localization system to capture the ever-growing complexity of LoRa networks environment and cope with the scalability issue in LoRa enabled massive IoT, and the results show an improvement of 63.3% in terms of accuracy.

</p>
</details>

<details><summary><b>Exploring the limits of multifunctionality across different reservoir computers</b>
<a href="https://arxiv.org/abs/2205.11375">arxiv:2205.11375</a>
&#x1F4C8; 1 <br>
<p>Andrew Flynn, Oliver Heilmann, Daniel Köglmayr, Vassilios A. Tsachouridis, Christoph Räth, Andreas Amann</p></summary>
<p>

**Abstract:** Multifunctional neural networks are capable of performing more than one task without changing any network connections. In this paper we explore the performance of a continuous-time, leaky-integrator, and next-generation `reservoir computer' (RC), when trained on tasks which test the limits of multifunctionality. In the first task we train each RC to reconstruct a coexistence of chaotic attractors from different dynamical systems. By moving the data describing these attractors closer together, we find that the extent to which each RC can reconstruct both attractors diminishes as they begin to overlap in state space. In order to provide a greater understanding of this inhibiting effect, in the second task we train each RC to reconstruct a coexistence of two circular orbits which differ only in the direction of rotation. We examine the critical effects that certain parameters can have in each RC to achieve multifunctionality in this extreme case of completely overlapping training data.

</p>
</details>

<details><summary><b>User Clustering for Rate Splitting using Machine Learning</b>
<a href="https://arxiv.org/abs/2205.11373">arxiv:2205.11373</a>
&#x1F4C8; 1 <br>
<p>Roberto Pereira, Anay Ajit Deshpande, Cristian J. Vaca-Rubio, Xavier Mestre, Andrea Zanella, David Gregoratti, Elisabeth de Carvalho, Petar Popovski</p></summary>
<p>

**Abstract:** Hierarchical Rate Splitting (HRS) schemes proposed in recent years have shown to provide significant improvements in exploiting spatial diversity in wireless networks and provide high throughput for all users while minimising interference among them. Hence, one of the major challenges for such HRS schemes is the necessity to know the optimal clustering of these users based only on their Channel State Information (CSI). This clustering problem is known to be NP hard and, to deal with the unmanageable complexity of finding an optimal solution, in this work a scalable and much lighter clustering mechanism based on Neural Network (NN) is proposed. The accuracy and performance metrics show that the NN is able to learn and cluster the users based on the noisy channel response and is able to achieve a rate comparable to other more complex clustering schemes from the literature.

</p>
</details>

<details><summary><b>Statistical inference as Green's functions</b>
<a href="https://arxiv.org/abs/2205.11366">arxiv:2205.11366</a>
&#x1F4C8; 1 <br>
<p>Hyun Keun Lee, Chulan Kwon, Yong Woon Kim</p></summary>
<p>

**Abstract:** Statistical inference from data is foundational task in science. Recently, it receives growing attention for its central role in inference systems of primary interest in data science, artificial intelligence, or machine learning. However, the understanding of statistical inference itself is not that solid while regarded as a matter of subjective choice or implemented in obscure ways. We here show that statistical inference has rigorous scientific description for long sequence of exchangeable binary random variables, the prototypal stochasticity in theories and applications. A linear differential equation is derived from the exchangeability, and it turns out that statistical inference is given by the Green's functions. Our finding is the answer to the normative and foundational issue in science, and its significance will be far-reaching in all pure and applied fields.

</p>
</details>

<details><summary><b>Memory-enriched computation and learning in spiking neural networks through Hebbian plasticity</b>
<a href="https://arxiv.org/abs/2205.11276">arxiv:2205.11276</a>
&#x1F4C8; 1 <br>
<p>Thomas Limbacher, Ozan Özdenizci, Robert Legenstein</p></summary>
<p>

**Abstract:** Memory is a key component of biological neural systems that enables the retention of information over a huge range of temporal scales, ranging from hundreds of milliseconds up to years. While Hebbian plasticity is believed to play a pivotal role in biological memory, it has so far been analyzed mostly in the context of pattern completion and unsupervised learning. Here, we propose that Hebbian plasticity is fundamental for computations in biological neural systems. We introduce a novel spiking neural network architecture that is enriched by Hebbian synaptic plasticity. We show that Hebbian enrichment renders spiking neural networks surprisingly versatile in terms of their computational as well as learning capabilities. It improves their abilities for out-of-distribution generalization, one-shot learning, cross-modal generative association, language processing, and reward-based learning. As spiking neural networks are the basis for energy-efficient neuromorphic hardware, this also suggests that powerful cognitive neuromorphic systems can be build based on this principle.

</p>
</details>

<details><summary><b>Learning to Advise and Learning from Advice in Cooperative Multi-Agent Reinforcement Learning</b>
<a href="https://arxiv.org/abs/2205.11163">arxiv:2205.11163</a>
&#x1F4C8; 1 <br>
<p>Yue Jin, Shuangqing Wei, Jian Yuan, Xudong Zhang</p></summary>
<p>

**Abstract:** Learning to coordinate is a daunting problem in multi-agent reinforcement learning (MARL). Previous works have explored it from many facets, including cognition between agents, credit assignment, communication, expert demonstration, etc. However, less attention were paid to agents' decision structure and the hierarchy of coordination. In this paper, we explore the spatiotemporal structure of agents' decisions and consider the hierarchy of coordination from the perspective of multilevel emergence dynamics, based on which a novel approach, Learning to Advise and Learning from Advice (LALA), is proposed to improve MARL. Specifically, by distinguishing the hierarchy of coordination, we propose to enhance decision coordination at meso level with an advisor and leverage a policy discriminator to advise agents' learning at micro level. The advisor learns to aggregate decision information in both spatial and temporal domains and generates coordinated decisions by employing a spatiotemporal dual graph convolutional neural network with a task-oriented objective function. Each agent learns from the advice via a policy generative adversarial learning method where a discriminator distinguishes between the policies of the agent and the advisor and boosts both of them based on its judgement. Experimental results indicate the advantage of LALA over baseline approaches in terms of both learning efficiency and coordination capability. Coordination mechanism is investigated from the perspective of multilevel emergence dynamics and mutual information point of view, which provides a novel perspective and method to analyze and improve MARL algorithms.

</p>
</details>

<details><summary><b>Bézier Flow: a Surface-wise Gradient Descent Method for Multi-objective Optimization</b>
<a href="https://arxiv.org/abs/2205.11099">arxiv:2205.11099</a>
&#x1F4C8; 1 <br>
<p>Akiyoshi Sannai, Yasunari Hikima, Ken Kobayashi, Akinori Tanaka, Naoki Hamada</p></summary>
<p>

**Abstract:** In this paper, we propose a strategy to construct a multi-objective optimization algorithm from a single-objective optimization algorithm by using the Bézier simplex model. Also, we extend the stability of optimization algorithms in the sense of Probability Approximately Correct (PAC) learning and define the PAC stability. We prove that it leads to an upper bound on the generalization with high probability. Furthermore, we show that multi-objective optimization algorithms derived from a gradient descent-based single-objective optimization algorithm are PAC stable. We conducted numerical experiments and demonstrated that our method achieved lower generalization errors than the existing multi-objective optimization algorithm.

</p>
</details>

<details><summary><b>UNet#: A UNet-like Redesigning Skip Connections for Medical Image Segmentation</b>
<a href="https://arxiv.org/abs/2205.11759">arxiv:2205.11759</a>
&#x1F4C8; 0 <br>
<p>Ledan Qian, Xiao Zhou, Yi Li, Zhongyi Hu</p></summary>
<p>

**Abstract:** As an essential prerequisite for developing a medical intelligent assistant system, medical image segmentation has received extensive research and concentration from the neural network community. A series of UNet-like networks with encoder-decoder architecture has achieved extraordinary success, in which UNet2+ and UNet3+ redesign skip connections, respectively proposing dense skip connection and full-scale skip connection and dramatically improving compared with UNet in medical image segmentation. However, UNet2+ lacks sufficient information explored from the full scale, which will affect the learning of organs' location and boundary. Although UNet3+ can obtain the full-scale aggregation feature map, owing to the small number of neurons in the structure, it does not satisfy the segmentation of tiny objects when the number of samples is small. This paper proposes a novel network structure combining dense skip connections and full-scale skip connections, named UNet-sharp (UNet\#) for its shape similar to symbol \#. The proposed UNet\# can aggregate feature maps of different scales in the decoder sub-network and capture fine-grained details and coarse-grained semantics from the full scale, which benefits learning the exact location and accurately segmenting the boundary of organs or lesions. We perform deep supervision for model pruning to speed up testing and make it possible for the model to run on mobile devices; furthermore, designing two classification-guided modules to reduce false positives achieves more accurate segmentation results. Various experiments of semantic segmentation and instance segmentation on different modalities (EM, CT, MRI) and dimensions (2D, 3D) datasets, including the nuclei, brain tumor, liver, and lung, demonstrate that the proposed method outperforms state-of-the-art models.

</p>
</details>

<details><summary><b>Identifying (anti-)skyrmions while they form</b>
<a href="https://arxiv.org/abs/2205.11535">arxiv:2205.11535</a>
&#x1F4C8; 0 <br>
<p>Jack Y. Araz, Juan Carlos Criado, Michael Spannowsky</p></summary>
<p>

**Abstract:** We use a Convolutional Neural Network (CNN) to identify the relevant features in the thermodynamical phases of a simulated three-dimensional spin-lattice system with ferromagnetic and Dzyaloshinskii-Moriya (DM) interactions. Such features include (anti-)skyrmions, merons, and helical and ferromagnetic states. We use a multi-label classification framework, which is flexible enough to accommodate states that mix different features and phases. We then train the CNN to predict the features of the final state from snapshots of intermediate states of the simulation. The trained model allows identifying the different phases reliably and early in the formation process. Thus, the CNN can significantly speed up the phase diagram calculations by predicting the final phase before the spin-lattice Monte Carlo sampling has converged. We show the prowess of this approach by generating phase diagrams with significantly shorter simulation times.

</p>
</details>

<details><summary><b>Heterogeneous Graph Neural Network for Personalized Session-Based Recommendation with User-Session Constraints</b>
<a href="https://arxiv.org/abs/2205.11343">arxiv:2205.11343</a>
&#x1F4C8; 0 <br>
<p>Minjae Park</p></summary>
<p>

**Abstract:** The recommendation system provides users with an appropriate limit of recent online large amounts of information. Session-based recommendation, a sub-area of recommender systems, attempts to recommend items by interpreting sessions that consist of sequences of items. Recently, research to include user information in these sessions is progress. However, it is difficult to generate high-quality user representation that includes session representations generated by user. In this paper, we consider various relationships in graph created by sessions through Heterogeneous attention network. Constraints also force user representations to consider the user's preferences presented in the session. It seeks to increase performance through additional optimization in the training process. The proposed model outperformed other methods on various real-world datasets.

</p>
</details>


{% endraw %}
Prev: [2022.05.22]({{ '/2022/05/22/2022.05.22.html' | relative_url }})  Next: [2022.05.24]({{ '/2022/05/24/2022.05.24.html' | relative_url }})