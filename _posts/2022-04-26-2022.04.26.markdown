Prev: [2022.04.25]({{ '/2022/04/25/2022.04.25.html' | relative_url }})  Next: [2022.04.27]({{ '/2022/04/27/2022.04.27.html' | relative_url }})
{% raw %}
## Summary for 2022-04-26, created on 2022-05-06


<details><summary><b>Process Knowledge-infused Learning for Suicidality Assessment on Social Media</b>
<a href="https://arxiv.org/abs/2204.12560">arxiv:2204.12560</a>
&#x1F4C8; 155 <br>
<p>Kaushik Roy, Manas Gaur, Qi Zhang, Amit Sheth</p></summary>
<p>

**Abstract:** Improving the performance and natural language explanations of deep learning algorithms is a priority for adoption by humans in the real world. In several domains, such as healthcare, such technology has significant potential to reduce the burden on humans by providing quality assistance at scale. However, current methods rely on the traditional pipeline of predicting labels from data, thus completely ignoring the process and guidelines used to obtain the labels. Furthermore, post hoc explanations on the data to label prediction using explainable AI (XAI) models, while satisfactory to computer scientists, leave much to be desired to the end-users due to lacking explanations of the process in terms of human-understandable concepts. We \textit{introduce}, \textit{formalize}, and \textit{develop} a novel Artificial Intelligence (A) paradigm -- Process Knowledge-infused Learning (PK-iL). PK-iL utilizes a structured process knowledge that explicitly explains the underlying prediction process that makes sense to end-users. The qualitative human evaluation confirms through a annotator agreement of 0.72, that humans are understand explanations for the predictions. PK-iL also performs competitively with the state-of-the-art (SOTA) baselines.

</p>
</details>

<details><summary><b>Reformulating Speaker Diarization as Community Detection With Emphasis On Topological Structure</b>
<a href="https://arxiv.org/abs/2204.12112">arxiv:2204.12112</a>
&#x1F4C8; 87 <br>
<p>Siqi Zheng, Hongbin Suo</p></summary>
<p>

**Abstract:** Clustering-based speaker diarization has stood firm as one of the major approaches in reality, despite recent development in end-to-end diarization. However, clustering methods have not been explored extensively for speaker diarization. Commonly-used methods such as k-means, spectral clustering, and agglomerative hierarchical clustering only take into account properties such as proximity and relative densities. In this paper we propose to view clustering-based diarization as a community detection problem. By doing so the topological structure is considered. This work has four major contributions. First it is shown that Leiden community detection algorithm significantly outperforms the previous methods on the clustering of speaker-segments. Second, we propose to use uniform manifold approximation to reduce dimension while retaining global and local topological structure. Third, a masked filtering approach is introduced to extract "clean" speaker embeddings. Finally, the community structure is applied to an end-to-end post-processing network to obtain diarization results. The final system presents a relative DER reduction of up to 70 percent. The breakdown contribution of each component is analyzed.

</p>
</details>

<details><summary><b>Cross Pairwise Ranking for Unbiased Item Recommendation</b>
<a href="https://arxiv.org/abs/2204.12176">arxiv:2204.12176</a>
&#x1F4C8; 44 <br>
<p>Qi Wan, Xiangnan He, Xiang Wang, Jiancan Wu, Wei Guo, Ruiming Tang</p></summary>
<p>

**Abstract:** Most recommender systems optimize the model on observed interaction data, which is affected by the previous exposure mechanism and exhibits many biases like popularity bias. The loss functions, such as the mostly used pointwise Binary Cross-Entropy and pairwise Bayesian Personalized Ranking, are not designed to consider the biases in observed data. As a result, the model optimized on the loss would inherit the data biases, or even worse, amplify the biases. For example, a few popular items take up more and more exposure opportunities, severely hurting the recommendation quality on niche items -- known as the notorious Mathew effect. In this work, we develop a new learning paradigm named Cross Pairwise Ranking (CPR) that achieves unbiased recommendation without knowing the exposure mechanism. Distinct from inverse propensity scoring (IPS), we change the loss term of a sample -- we innovatively sample multiple observed interactions once and form the loss as the combination of their predictions. We prove in theory that this way offsets the influence of user/item propensity on the learning, removing the influence of data biases caused by the exposure mechanism. Advantageous to IPS, our proposed CPR ensures unbiased learning for each training instance without the need of setting the propensity scores. Experimental results demonstrate the superiority of CPR over state-of-the-art debiasing solutions in both model generalization and training efficiency. The codes are available at https://github.com/Qcactus/CPR.

</p>
</details>

<details><summary><b>Learning Value Functions from Undirected State-only Experience</b>
<a href="https://arxiv.org/abs/2204.12458">arxiv:2204.12458</a>
&#x1F4C8; 41 <br>
<p>Matthew Chang, Arjun Gupta, Saurabh Gupta</p></summary>
<p>

**Abstract:** This paper tackles the problem of learning value functions from undirected state-only experience (state transitions without action labels i.e. (s,s',r) tuples). We first theoretically characterize the applicability of Q-learning in this setting. We show that tabular Q-learning in discrete Markov decision processes (MDPs) learns the same value function under any arbitrary refinement of the action space. This theoretical result motivates the design of Latent Action Q-learning or LAQ, an offline RL method that can learn effective value functions from state-only experience. Latent Action Q-learning (LAQ) learns value functions using Q-learning on discrete latent actions obtained through a latent-variable future prediction model. We show that LAQ can recover value functions that have high correlation with value functions learned using ground truth actions. Value functions learned using LAQ lead to sample efficient acquisition of goal-directed behavior, can be used with domain-specific low-level controllers, and facilitate transfer across embodiments. Our experiments in 5 environments ranging from 2D grid world to 3D visual navigation in realistic environments demonstrate the benefits of LAQ over simpler alternatives, imitation learning oracles, and competing methods.

</p>
</details>

<details><summary><b>Modular Domain Adaptation</b>
<a href="https://arxiv.org/abs/2204.14213">arxiv:2204.14213</a>
&#x1F4C8; 38 <br>
<p>Junshen K. Chen, Dallas Card, Dan Jurafsky</p></summary>
<p>

**Abstract:** Off-the-shelf models are widely used by computational social science researchers to measure properties of text, such as sentiment. However, without access to source data it is difficult to account for domain shift, which represents a threat to validity. Here, we treat domain adaptation as a modular process that involves separate model producers and model consumers, and show how they can independently cooperate to facilitate more accurate measurements of text. We introduce two lightweight techniques for this scenario, and demonstrate that they reliably increase out-of-domain accuracy on four multi-domain text classification datasets when used with linear and contextual embedding models. We conclude with recommendations for model producers and consumers, and release models and replication code to accompany this paper.

</p>
</details>

<details><summary><b>From One Hand to Multiple Hands: Imitation Learning for Dexterous Manipulation from Single-Camera Teleoperation</b>
<a href="https://arxiv.org/abs/2204.12490">arxiv:2204.12490</a>
&#x1F4C8; 19 <br>
<p>Yuzhe Qin, Hao Su, Xiaolong Wang</p></summary>
<p>

**Abstract:** We propose to perform imitation learning for dexterous manipulation with multi-finger robot hand from human demonstrations, and transfer the policy to the real robot hand. We introduce a novel single-camera teleoperation system to collect the 3D demonstrations efficiently with only an iPad and a computer. One key contribution of our system is that we construct a customized robot hand for each user in the physical simulator, which is a manipulator resembling the same kinematics structure and shape of the operator's hand. This provides an intuitive interface and avoid unstable human-robot hand retargeting for data collection, leading to large-scale and high quality data. Once the data is collected, the customized robot hand trajectories can be converted to different specified robot hands (models that are manufactured) to generate training demonstrations. With imitation learning using our data, we show large improvement over baselines with multiple complex manipulation tasks. Importantly, we show our learned policy is significantly more robust when transferring to the real robot. More videos can be found in the https://yzqin.github.io/dex-teleop-imitation .

</p>
</details>

<details><summary><b>Beyond Lipschitz: Sharp Generalization and Excess Risk Bounds for Full-Batch GD</b>
<a href="https://arxiv.org/abs/2204.12446">arxiv:2204.12446</a>
&#x1F4C8; 15 <br>
<p>Konstantinos E. Nikolakakis, Farzin Haddadpour, Amin Karbasi, Dionysios S. Kalogerias</p></summary>
<p>

**Abstract:** We provide sharp path-dependent generalization and excess error guarantees for the full-batch Gradient Decent (GD) algorithm for smooth losses (possibly non-Lipschitz, possibly nonconvex). At the heart of our analysis is a novel generalization error technique for deterministic symmetric algorithms, that implies average output stability and a bounded expected gradient of the loss at termination leads to generalization. This key result shows that small generalization error occurs at stationary points, and allows us to bypass Lipschitz assumptions on the loss prevalent in previous work. For nonconvex, convex and strongly convex losses, we show the explicit dependence of the generalization error in terms of the accumulated path-dependent optimization error, terminal optimization error, number of samples, and number of iterations. For nonconvex smooth losses, we prove that full-batch GD efficiently generalizes close to any stationary point at termination, under the proper choice of a decreasing step size. Further, if the loss is nonconvex but the objective is PL, we derive vanishing bounds on the corresponding excess risk. For convex and strongly-convex smooth losses, we prove that full-batch GD generalizes even for large constant step sizes, and achieves a small excess risk while training fast. Our full-batch GD generalization error and excess risk bounds are significantly tighter than the existing bounds for (stochastic) GD, when the loss is smooth (but possibly non-Lipschitz).

</p>
</details>

<details><summary><b>Focal Sparse Convolutional Networks for 3D Object Detection</b>
<a href="https://arxiv.org/abs/2204.12463">arxiv:2204.12463</a>
&#x1F4C8; 14 <br>
<p>Yukang Chen, Yanwei Li, Xiangyu Zhang, Jian Sun, Jiaya Jia</p></summary>
<p>

**Abstract:** Non-uniformed 3D sparse data, e.g., point clouds or voxels in different spatial positions, make contribution to the task of 3D object detection in different ways. Existing basic components in sparse convolutional networks (Sparse CNNs) process all sparse data, regardless of regular or submanifold sparse convolution. In this paper, we introduce two new modules to enhance the capability of Sparse CNNs, both are based on making feature sparsity learnable with position-wise importance prediction. They are focal sparse convolution (Focals Conv) and its multi-modal variant of focal sparse convolution with fusion, or Focals Conv-F for short. The new modules can readily substitute their plain counterparts in existing Sparse CNNs and be jointly trained in an end-to-end fashion. For the first time, we show that spatially learnable sparsity in sparse convolution is essential for sophisticated 3D object detection. Extensive experiments on the KITTI, nuScenes and Waymo benchmarks validate the effectiveness of our approach. Without bells and whistles, our results outperform all existing single-model entries on the nuScenes test benchmark at the paper submission time. Code and models are at https://github.com/dvlab-research/FocalsConv.

</p>
</details>

<details><summary><b>Bias-Variance Decompositions for Margin Losses</b>
<a href="https://arxiv.org/abs/2204.12155">arxiv:2204.12155</a>
&#x1F4C8; 13 <br>
<p>Danny Wood, Tingting Mu, Gavin Brown</p></summary>
<p>

**Abstract:** We introduce a novel bias-variance decomposition for a range of strictly convex margin losses, including the logistic loss (minimized by the classic LogitBoost algorithm), as well as the squared margin loss and canonical boosting loss. Furthermore, we show that, for all strictly convex margin losses, the expected risk decomposes into the risk of a "central" model and a term quantifying variation in the functional margin with respect to variations in the training data. These decompositions provide a diagnostic tool for practitioners to understand model overfitting/underfitting, and have implications for additive ensemble models -- for example, when our bias-variance decomposition holds, there is a corresponding "ambiguity" decomposition, which can be used to quantify model diversity.

</p>
</details>

<details><summary><b>Hybridised Loss Functions for Improved Neural Network Generalisation</b>
<a href="https://arxiv.org/abs/2204.12244">arxiv:2204.12244</a>
&#x1F4C8; 10 <br>
<p>Matthew C. Dickson, Anna S. Bosman, Katherine M. Malan</p></summary>
<p>

**Abstract:** Loss functions play an important role in the training of artificial neural networks (ANNs), and can affect the generalisation ability of the ANN model, among other properties. Specifically, it has been shown that the cross entropy and sum squared error loss functions result in different training dynamics, and exhibit different properties that are complementary to one another. It has previously been suggested that a hybrid of the entropy and sum squared error loss functions could combine the advantages of the two functions, while limiting their disadvantages. The effectiveness of such hybrid loss functions is investigated in this study. It is shown that hybridisation of the two loss functions improves the generalisation ability of the ANNs on all problems considered. The hybrid loss function that starts training with the sum squared error loss function and later switches to the cross entropy error loss function is shown to either perform the best on average, or to not be significantly different than the best loss function tested for all problems considered. This study shows that the minima discovered by the sum squared error loss function can be further exploited by switching to cross entropy error loss function. It can thus be concluded that hybridisation of the two loss functions could lead to better performance in ANNs.

</p>
</details>

<details><summary><b>Testing the Ability of Language Models to Interpret Figurative Language</b>
<a href="https://arxiv.org/abs/2204.12632">arxiv:2204.12632</a>
&#x1F4C8; 9 <br>
<p>Emmy Liu, Chen Cui, Kenneth Zheng, Graham Neubig</p></summary>
<p>

**Abstract:** Figurative and metaphorical language are commonplace in discourse, and figurative expressions play an important role in communication and cognition. However, figurative language has been a relatively under-studied area in NLP, and it remains an open question to what extent modern language models can interpret nonliteral phrases. To address this question, we introduce Fig-QA, a Winograd-style nonliteral language understanding task consisting of correctly interpreting paired figurative phrases with divergent meanings. We evaluate the performance of several state-of-the-art language models on this task, and find that although language models achieve performance significantly over chance, they still fall short of human performance, particularly in zero- or few-shot settings. This suggests that further work is needed to improve the nonliteral reasoning capabilities of language models.

</p>
</details>

<details><summary><b>A survey on attention mechanisms for medical applications: are we moving towards better algorithms?</b>
<a href="https://arxiv.org/abs/2204.12406">arxiv:2204.12406</a>
&#x1F4C8; 9 <br>
<p>Tiago Gonçalves, Isabel Rio-Torto, Luís F. Teixeira, Jaime S. Cardoso</p></summary>
<p>

**Abstract:** The increasing popularity of attention mechanisms in deep learning algorithms for computer vision and natural language processing made these models attractive to other research domains. In healthcare, there is a strong need for tools that may improve the routines of the clinicians and the patients. Naturally, the use of attention-based algorithms for medical applications occurred smoothly. However, being healthcare a domain that depends on high-stake decisions, the scientific community must ponder if these high-performing algorithms fit the needs of medical applications. With this motto, this paper extensively reviews the use of attention mechanisms in machine learning (including Transformers) for several medical applications. This work distinguishes itself from its predecessors by proposing a critical analysis of the claims and potentialities of attention mechanisms presented in the literature through an experimental case study on medical image classification with three different use cases. These experiments focus on the integrating process of attention mechanisms into established deep learning architectures, the analysis of their predictive power, and a visual assessment of their saliency maps generated by post-hoc explanation methods. This paper concludes with a critical analysis of the claims and potentialities presented in the literature about attention mechanisms and proposes future research lines in medical applications that may benefit from these frameworks.

</p>
</details>

<details><summary><b>On Fragile Features and Batch Normalization in Adversarial Training</b>
<a href="https://arxiv.org/abs/2204.12393">arxiv:2204.12393</a>
&#x1F4C8; 9 <br>
<p>Nils Philipp Walter, David Stutz, Bernt Schiele</p></summary>
<p>

**Abstract:** Modern deep learning architecture utilize batch normalization (BN) to stabilize training and improve accuracy. It has been shown that the BN layers alone are surprisingly expressive. In the context of robustness against adversarial examples, however, BN is argued to increase vulnerability. That is, BN helps to learn fragile features. Nevertheless, BN is still used in adversarial training, which is the de-facto standard to learn robust features. In order to shed light on the role of BN in adversarial training, we investigate to what extent the expressiveness of BN can be used to robustify fragile features in comparison to random features. On CIFAR10, we find that adversarially fine-tuning just the BN layers can result in non-trivial adversarial robustness. Adversarially training only the BN layers from scratch, in contrast, is not able to convey meaningful adversarial robustness. Our results indicate that fragile features can be used to learn models with moderate adversarial robustness, while random features cannot

</p>
</details>

<details><summary><b>Treating Crowdsourcing as Examination: How to Score Tasks and Online Workers?</b>
<a href="https://arxiv.org/abs/2204.13065">arxiv:2204.13065</a>
&#x1F4C8; 8 <br>
<p>Guangyang Han, Sufang Li, Runmin Wang, Chunming Wu</p></summary>
<p>

**Abstract:** Crowdsourcing is an online outsourcing mode which can solve the current machine learning algorithm's urge need for massive labeled data. Requester posts tasks on crowdsourcing platforms, which employ online workers over the Internet to complete tasks, then aggregate and return results to requester. How to model the interaction between different types of workers and tasks is a hot spot. In this paper, we try to model workers as four types based on their ability: expert, normal worker, sloppy worker and spammer, and divide tasks into hard, medium and easy task according to their difficulty. We believe that even experts struggle with difficult tasks while sloppy workers can get easy tasks right, and spammers always give out wrong answers deliberately. So, good examination tasks should have moderate degree of difficulty and discriminability to score workers more objectively. Thus, we first score workers' ability mainly on the medium difficult tasks, then reducing the weight of answers from sloppy workers and modifying the answers from spammers when inferring the tasks' ground truth. A probability graph model is adopted to simulate the task execution process, and an iterative method is adopted to calculate and update the ground truth, the ability of workers and the difficulty of the task successively. We verify the rightness and effectiveness of our algorithm both in simulated and real crowdsourcing scenes.

</p>
</details>

<details><summary><b>Learning Meta Word Embeddings by Unsupervised Weighted Concatenation of Source Embeddings</b>
<a href="https://arxiv.org/abs/2204.12386">arxiv:2204.12386</a>
&#x1F4C8; 8 <br>
<p>Danushka Bollegala</p></summary>
<p>

**Abstract:** Given multiple source word embeddings learnt using diverse algorithms and lexical resources, meta word embedding learning methods attempt to learn more accurate and wide-coverage word embeddings.
  Prior work on meta-embedding has repeatedly discovered that simple vector concatenation of the source embeddings to be a competitive baseline.
  However, it remains unclear as to why and when simple vector concatenation can produce accurate meta-embeddings.
  We show that weighted concatenation can be seen as a spectrum matching operation between each source embedding and the meta-embedding, minimising the pairwise inner-product loss.
  Following this theoretical analysis, we propose two \emph{unsupervised} methods to learn the optimal concatenation weights for creating meta-embeddings from a given set of source embeddings.
  Experimental results on multiple benchmark datasets show that the proposed weighted concatenated meta-embedding methods outperform previously proposed meta-embedding learning methods.

</p>
</details>

<details><summary><b>Convergence of neural networks to Gaussian mixture distribution</b>
<a href="https://arxiv.org/abs/2204.12100">arxiv:2204.12100</a>
&#x1F4C8; 8 <br>
<p>Yasuhiko Asao, Ryotaro Sakamoto, Shiro Takagi</p></summary>
<p>

**Abstract:** We give a proof that, under relatively mild conditions, fully-connected feed-forward deep random neural networks converge to a Gaussian mixture distribution as only the width of the last hidden layer goes to infinity. We conducted experiments for a simple model which supports our result. Moreover, it gives a detailed description of the convergence, namely, the growth of the last hidden layer gets the distribution closer to the Gaussian mixture, and the other layer successively get the Gaussian mixture closer to the normal distribution.

</p>
</details>

<details><summary><b>Intercategorical Label Interpolation for Emotional Face Generation with Conditional Generative Adversarial Networks</b>
<a href="https://arxiv.org/abs/2204.12237">arxiv:2204.12237</a>
&#x1F4C8; 7 <br>
<p>Silvan Mertes, Dominik Schiller, Florian Lingenfelser, Thomas Kiderle, Valentin Kroner, Lama Diab, Elisabeth André</p></summary>
<p>

**Abstract:** Generative adversarial networks offer the possibility to generate deceptively real images that are almost indistinguishable from actual photographs. Such systems however rely on the presence of large datasets to realistically replicate the corresponding domain. This is especially a problem if not only random new images are to be generated, but specific (continuous) features are to be co-modeled. A particularly important use case in \emph{Human-Computer Interaction} (HCI) research is the generation of emotional images of human faces, which can be used for various use cases, such as the automatic generation of avatars. The problem hereby lies in the availability of training data. Most suitable datasets for this task rely on categorical emotion models and therefore feature only discrete annotation labels. This greatly hinders the learning and modeling of smooth transitions between displayed affective states. To overcome this challenge, we explore the potential of label interpolation to enhance networks trained on categorical datasets with the ability to generate images conditioned on continuous features.

</p>
</details>

<details><summary><b>Supervised machine learning classification for short straddles on the S&P500</b>
<a href="https://arxiv.org/abs/2204.13587">arxiv:2204.13587</a>
&#x1F4C8; 6 <br>
<p>Alexander Brunhuemer, Lukas Larcher, Philipp Seidl, Sascha Desmettre, Johannes Kofler, Gerhard Larcher</p></summary>
<p>

**Abstract:** In this working paper we present our current progress in the training of machine learning models to execute short option strategies on the S&P500. As a first step, this paper is breaking this problem down to a supervised classification task to decide if a short straddle on the S&P500 should be executed or not on a daily basis. We describe our used framework and present an overview over our evaluation metrics on different classification models. In this preliminary work, using standard machine learning techniques and without hyperparameter search, we find no statistically significant outperformance to a simple "trade always" strategy, but gain additional insights on how we could proceed in further experiments.

</p>
</details>

<details><summary><b>Data Bootstrapping Approaches to Improve Low Resource Abusive Language Detection for Indic Languages</b>
<a href="https://arxiv.org/abs/2204.12543">arxiv:2204.12543</a>
&#x1F4C8; 6 <br>
<p>Mithun Das, Somnath Banerjee, Animesh Mukherjee</p></summary>
<p>

**Abstract:** Abusive language is a growing concern in many social media platforms. Repeated exposure to abusive speech has created physiological effects on the target users. Thus, the problem of abusive language should be addressed in all forms for online peace and safety. While extensive research exists in abusive speech detection, most studies focus on English. Recently, many smearing incidents have occurred in India, which provoked diverse forms of abusive speech in online space in various languages based on the geographic location. Therefore it is essential to deal with such malicious content. In this paper, to bridge the gap, we demonstrate a large-scale analysis of multilingual abusive speech in Indic languages. We examine different interlingual transfer mechanisms and observe the performance of various multilingual models for abusive speech detection for eight different Indic languages. We also experiment to show how robust these models are on adversarial attacks. Finally, we conduct an in-depth error analysis by looking into the models' misclassified posts across various settings. We have made our code and models public for other researchers.

</p>
</details>

<details><summary><b>Performance Analysis of Out-of-Distribution Detection on Trained Neural Networks</b>
<a href="https://arxiv.org/abs/2204.12378">arxiv:2204.12378</a>
&#x1F4C8; 6 <br>
<p>Jens Henriksson, Christian Berger, Markus Borg, Lars Tornberg, Sankar Raman Sathyamoorthy, Cristofer Englund</p></summary>
<p>

**Abstract:** Several areas have been improved with Deep Learning during the past years. Implementing Deep Neural Networks (DNN) for non-safety related applications have shown remarkable achievements over the past years; however, for using DNNs in safety critical applications, we are missing approaches for verifying the robustness of such models. A common challenge for DNNs occurs when exposed to out-of-distribution samples that are outside of the scope of a DNN, but which result in high confidence outputs despite no prior knowledge of such input.
  In this paper, we analyze three methods that separate between in- and out-of-distribution data, called supervisors, on four well-known DNN architectures. We find that the outlier detection performance improves with the quality of the model. We also analyse the performance of the particular supervisors during the training procedure by applying the supervisor at a predefined interval to investigate its performance as the training proceeds. We observe that understanding the relationship between training results and supervisor performance is crucial to improve the model's robustness and to indicate, what input samples require further measures to improve the robustness of a DNN. In addition, our work paves the road towards an instrument for safety argumentation for safety critical applications. This paper is an extended version of our previous work presented at 2019 SEAA (cf. [1]); here, we elaborate on the used metrics, add an additional supervisor and test them on two additional datasets.

</p>
</details>

<details><summary><b>Science Checker: Extractive-Boolean Question Answering For Scientific Fact Checking</b>
<a href="https://arxiv.org/abs/2204.12263">arxiv:2204.12263</a>
&#x1F4C8; 6 <br>
<p>Loïc Rakotoson, Charles Letaillieur, Sylvain Massip, Fréjus Laleye</p></summary>
<p>

**Abstract:** With the explosive growth of scientific publications, making the synthesis of scientific knowledge and fact checking becomes an increasingly complex task. In this paper, we propose a multi-task approach for verifying the scientific questions based on a joint reasoning from facts and evidence in research articles. We propose an intelligent combination of (1) an automatic information summarization and (2) a Boolean Question Answering which allows to generate an answer to a scientific question from only extracts obtained after summarization. Thus on a given topic, our proposed approach conducts structured content modeling based on paper abstracts to answer a scientific question while highlighting texts from paper that discuss the topic. We based our final system on an end-to-end Extractive Question Answering (EQA) combined with a three outputs classification model to perform in-depth semantic understanding of a question to illustrate the aggregation of multiple responses. With our light and fast proposed architecture, we achieved an average error rate of 4% and a F1-score of 95.6%. Our results are supported via experiments with two QA models (BERT, RoBERTa) over 3 Million Open Access (OA) articles in the medical and health domains on Europe PMC.

</p>
</details>

<details><summary><b>Acquiring a Dynamic Light Field through a Single-Shot Coded Image</b>
<a href="https://arxiv.org/abs/2204.12089">arxiv:2204.12089</a>
&#x1F4C8; 6 <br>
<p>Ryoya Mizuno, Keita Takahashi, Michitaka Yoshida, Chihiro Tsutake, Toshiaki Fujii, Hajime Nagahara</p></summary>
<p>

**Abstract:** We propose a method for compressively acquiring a dynamic light field (a 5-D volume) through a single-shot coded image (a 2-D measurement). We designed an imaging model that synchronously applies aperture coding and pixel-wise exposure coding within a single exposure time. This coding scheme enables us to effectively embed the original information into a single observed image. The observed image is then fed to a convolutional neural network (CNN) for light-field reconstruction, which is jointly trained with the camera-side coding patterns. We also developed a hardware prototype to capture a real 3-D scene moving over time. We succeeded in acquiring a dynamic light field with 5x5 viewpoints over 4 temporal sub-frames (100 views in total) from a single observed image. Repeating capture and reconstruction processes over time, we can acquire a dynamic light field at 4x the frame rate of the camera. To our knowledge, our method is the first to achieve a finer temporal resolution than the camera itself in compressive light-field acquisition. Our software is available from our project webpage

</p>
</details>

<details><summary><b>Coarse-to-fine Q-attention with Tree Expansion</b>
<a href="https://arxiv.org/abs/2204.12471">arxiv:2204.12471</a>
&#x1F4C8; 5 <br>
<p>Stephen James, Pieter Abbeel</p></summary>
<p>

**Abstract:** Coarse-to-fine Q-attention enables sample-efficient robot manipulation by discretizing the translation space in a coarse-to-fine manner, where the resolution gradually increases at each layer in the hierarchy. Although effective, Q-attention suffers from "coarse ambiguity" - when voxelization is significantly coarse, it is not feasible to distinguish similar-looking objects without first inspecting at a finer resolution. To combat this, we propose to envision Q-attention as a tree that can be expanded and used to accumulate value estimates across the top-k voxels at each Q-attention depth. When our extension, Q-attention with Tree Expansion (QTE), replaces standard Q-attention in the Attention-driven Robot Manipulation (ARM) system, we are able to accomplish a larger set of tasks; especially on those that suffer from "coarse ambiguity". In addition to evaluating our approach across 12 RLBench tasks, we also show that the improved performance is visible in a real-world task involving small objects.

</p>
</details>

<details><summary><b>Streaming Algorithms for High-Dimensional Robust Statistics</b>
<a href="https://arxiv.org/abs/2204.12399">arxiv:2204.12399</a>
&#x1F4C8; 5 <br>
<p>Ilias Diakonikolas, Daniel M. Kane, Ankit Pensia, Thanasis Pittas</p></summary>
<p>

**Abstract:** We study high-dimensional robust statistics tasks in the streaming model. A recent line of work obtained computationally efficient algorithms for a range of high-dimensional robust estimation tasks. Unfortunately, all previous algorithms require storing the entire dataset, incurring memory at least quadratic in the dimension. In this work, we develop the first efficient streaming algorithms for high-dimensional robust statistics with near-optimal memory requirements (up to logarithmic factors). Our main result is for the task of high-dimensional robust mean estimation in (a strengthening of) Huber's contamination model. We give an efficient single-pass streaming algorithm for this task with near-optimal error guarantees and space complexity nearly-linear in the dimension. As a corollary, we obtain streaming algorithms with near-optimal space complexity for several more complex tasks, including robust covariance estimation, robust regression, and more generally robust stochastic optimization.

</p>
</details>

<details><summary><b>Explaining Adverse Actions in Credit Decisions Using Shapley Decomposition</b>
<a href="https://arxiv.org/abs/2204.12365">arxiv:2204.12365</a>
&#x1F4C8; 5 <br>
<p>Vijayan N. Nair, Tianshu Feng, Linwei Hu, Zach Zhang, Jie Chen, Agus Sudjianto</p></summary>
<p>

**Abstract:** When a financial institution declines an application for credit, an adverse action (AA) is said to occur. The applicant is then entitled to an explanation for the negative decision. This paper focuses on credit decisions based on a predictive model for probability of default and proposes a methodology for AA explanation. The problem involves identifying the important predictors responsible for the negative decision and is straightforward when the underlying model is additive. However, it becomes non-trivial even for linear models with interactions. We consider models with low-order interactions and develop a simple and intuitive approach based on first principles. We then show how the methodology generalizes to the well-known Shapely decomposition and the recently proposed concept of Baseline Shapley (B-Shap). Unlike other Shapley techniques in the literature for local interpretability of machine learning results, B-Shap is computationally tractable since it involves just function evaluations. An illustrative case study is used to demonstrate the usefulness of the method. The paper also discusses situations with highly correlated predictors and desirable properties of fitted models in the credit-lending context, such as monotonicity and continuity.

</p>
</details>

<details><summary><b>Designing Perceptual Puzzles by Differentiating Probabilistic Programs</b>
<a href="https://arxiv.org/abs/2204.12301">arxiv:2204.12301</a>
&#x1F4C8; 5 <br>
<p>Kartik Chandra, Tzu-Mao Li, Joshua Tenenbaum, Jonathan Ragan-Kelley</p></summary>
<p>

**Abstract:** We design new visual illusions by finding "adversarial examples" for principled models of human perception -- specifically, for probabilistic models, which treat vision as Bayesian inference. To perform this search efficiently, we design a differentiable probabilistic programming language, whose API exposes MCMC inference as a first-class differentiable function. We demonstrate our method by automatically creating illusions for three features of human vision: color constancy, size constancy, and face perception.

</p>
</details>

<details><summary><b>Monant Medical Misinformation Dataset: Mapping Articles to Fact-Checked Claims</b>
<a href="https://arxiv.org/abs/2204.12294">arxiv:2204.12294</a>
&#x1F4C8; 5 <br>
<p>Ivan Srba, Branislav Pecher, Matus Tomlein, Robert Moro, Elena Stefancova, Jakub Simko, Maria Bielikova</p></summary>
<p>

**Abstract:** False information has a significant negative influence on individuals as well as on the whole society. Especially in the current COVID-19 era, we witness an unprecedented growth of medical misinformation. To help tackle this problem with machine learning approaches, we are publishing a feature-rich dataset of approx. 317k medical news articles/blogs and 3.5k fact-checked claims. It also contains 573 manually and more than 51k automatically labelled mappings between claims and articles. Mappings consist of claim presence, i.e., whether a claim is contained in a given article, and article stance towards the claim. We provide several baselines for these two tasks and evaluate them on the manually labelled part of the dataset. The dataset enables a number of additional tasks related to medical misinformation, such as misinformation characterisation studies or studies of misinformation diffusion between sources.

</p>
</details>

<details><summary><b>Hypergraph Contrastive Collaborative Filtering</b>
<a href="https://arxiv.org/abs/2204.12200">arxiv:2204.12200</a>
&#x1F4C8; 5 <br>
<p>Lianghao Xia, Chao Huang, Yong Xu, Jiashu Zhao, Dawei Yin, Jimmy Xiangji Huang</p></summary>
<p>

**Abstract:** Collaborative Filtering (CF) has emerged as fundamental paradigms for parameterizing users and items into latent representation space, with their correlative patterns from interaction data. Among various CF techniques, the development of GNN-based recommender systems, e.g., PinSage and LightGCN, has offered the state-of-the-art performance. However, two key challenges have not been well explored in existing solutions: i) The over-smoothing effect with deeper graph-based CF architecture, may cause the indistinguishable user representations and degradation of recommendation results. ii) The supervision signals (i.e., user-item interactions) are usually scarce and skewed distributed in reality, which limits the representation power of CF paradigms. To tackle these challenges, we propose a new self-supervised recommendation framework Hypergraph Contrastive Collaborative Filtering (HCCF) to jointly capture local and global collaborative relations with a hypergraph-enhanced cross-view contrastive learning architecture. In particular, the designed hypergraph structure learning enhances the discrimination ability of GNN-based CF paradigm, so as to comprehensively capture the complex high-order dependencies among users. Additionally, our HCCF model effectively integrates the hypergraph structure encoding with self-supervised learning to reinforce the representation quality of recommender systems, based on the hypergraph-enhanced self-discrimination. Extensive experiments on three benchmark datasets demonstrate the superiority of our model over various state-of-the-art recommendation methods, and the robustness against sparse user interaction data. Our model implementation codes are available at https://github.com/akaxlh/HCCF.

</p>
</details>

<details><summary><b>Poisoning Deep Learning based Recommender Model in Federated Learning Scenarios</b>
<a href="https://arxiv.org/abs/2204.13594">arxiv:2204.13594</a>
&#x1F4C8; 4 <br>
<p>Dazhong Rong, Qinming He, Jianhai Chen</p></summary>
<p>

**Abstract:** Various attack methods against recommender systems have been proposed in the past years, and the security issues of recommender systems have drawn considerable attention. Traditional attacks attempt to make target items recommended to as many users as possible by poisoning the training data. Benifiting from the feature of protecting users' private data, federated recommendation can effectively defend such attacks. Therefore, quite a few works have devoted themselves to developing federated recommender systems. For proving current federated recommendation is still vulnerable, in this work we probe to design attack approaches targeting deep learning based recommender models in federated learning scenarios. Specifically, our attacks generate poisoned gradients for manipulated malicious users to upload based on two strategies (i.e., random approximation and hard user mining). Extensive experiments show that our well-designed attacks can effectively poison the target models, and the attack effectiveness sets the state-of-the-art.

</p>
</details>

<details><summary><b>Forecasting Foreign Exchange Rates With Parameter-Free Regression Networks Tuned By Bayesian Optimization</b>
<a href="https://arxiv.org/abs/2204.12914">arxiv:2204.12914</a>
&#x1F4C8; 4 <br>
<p>Linwei Li, Paul-Amaury Matt, Christian Heumann</p></summary>
<p>

**Abstract:** The article is concerned with the problem of multi-step financial time series forecasting of Foreign Exchange (FX) rates. To address this problem, we introduce a parameter-free regression network termed RegPred Net. The exchange rate to forecast is treated as a stochastic process. It is assumed to follow a generalization of Brownian motion and the mean-reverting process referred to as the generalized Ornstein-Uhlenbeck (OU) process, with time-dependent coefficients. Using past observed values of the input time series, these coefficients can be regressed online by the cells of the first half of the network (Reg). The regressed coefficients depend only on - but are very sensitive to - a small number of hyperparameters required to be set by a global optimization procedure for which, Bayesian optimization is an adequate heuristic. Thanks to its multi-layered architecture, the second half of the regression network (Pred) can project time-dependent values for the OU process coefficients and generate realistic trajectories of the time series. Predictions can be easily derived in the form of expected values estimated by averaging values obtained by Monte Carlo simulation. The forecasting accuracy on a 100 days horizon is evaluated for several of the most important FX rates such as EUR/USD, EUR/CNY, and EUR/GBP. Our experimental results show that the RegPred Net significantly outperforms ARMA, ARIMA, LSTMs, and Autoencoder-LSTM models in this task.

</p>
</details>

<details><summary><b>Enhancing Privacy against Inversion Attacks in Federated Learning by using Mixing Gradients Strategies</b>
<a href="https://arxiv.org/abs/2204.12495">arxiv:2204.12495</a>
&#x1F4C8; 4 <br>
<p>Shaltiel Eloul, Fran Silavong, Sanket Kamthe, Antonios Georgiadis, Sean J. Moran</p></summary>
<p>

**Abstract:** Federated learning reduces the risk of information leakage, but remains vulnerable to attacks. We investigate how several neural network design decisions can defend against gradients inversion attacks. We show that overlapping gradients provides numerical resistance to gradient inversion on the highly vulnerable dense layer. Specifically, we propose to leverage batching to maximise mixing of gradients by choosing an appropriate loss function and drawing identical labels. We show that otherwise it is possible to directly recover all vectors in a mini-batch without any numerical optimisation due to the de-mixing nature of the cross entropy loss. To accurately assess data recovery, we introduce an absolute variation distance (AVD) metric for information leakage in images, derived from total variation. In contrast to standard metrics, e.g. Mean Squared Error or Structural Similarity Index, AVD offers a continuous metric for extracting information in noisy images. Finally, our empirical results on information recovery from various inversion attacks and training performance supports our defense strategies. These strategies are also shown to be useful for deep convolutional neural networks such as LeNET for image recognition. We hope that this study will help guide the development of further strategies that achieve a trustful federation policy.

</p>
</details>

<details><summary><b>Digital Twins for Dynamic Management of Blockchain Systems</b>
<a href="https://arxiv.org/abs/2204.12477">arxiv:2204.12477</a>
&#x1F4C8; 4 <br>
<p>Georgios Diamantopoulos, Nikos Tziritas, Rami Bahsoon, Georgios Theodoropoulos</p></summary>
<p>

**Abstract:** Blockchain systems are challenged by the so-called Trilemma tradeoff: decentralization, scalability and security. Infrastructure and node configuration, choice of the Consensus Protocol and complexity of the application transactions are cited amongst the factors that affect the tradeoffs balance. Given that Blockchains are complex, dynamic dynamic systems, a dynamic approach to their management and reconfiguration at runtime is deemed necessary to reflect the changes in the state of the infrastructure and application. This paper introduces the utilisation of Digital Twins for this purpose. The novel contribution of the paper is design of a framework and conceptual architecture of a Digital Twin that can assist in maintaining the Trilemma tradeoffs of time critical systems. The proposed Digital Twin is illustrated via an innovative approach to dynamic selection of Consensus Protocols. Simulations results show that the proposed framework can effectively support the dynamic adaptation and management of the Blockchain

</p>
</details>

<details><summary><b>Event Detection Explorer: An Interactive Tool for Event Detection Exploration</b>
<a href="https://arxiv.org/abs/2204.12456">arxiv:2204.12456</a>
&#x1F4C8; 4 <br>
<p>Wenlong Zhang, Bhagyashree Ingale, Hamza Shabir, Tianyi Li, Tian Shi, Ping Wang</p></summary>
<p>

**Abstract:** Event Detection (ED) is an important task in natural language processing. In the past few years, many datasets have been introduced for advancing ED machine learning models. However, most of these datasets are under-explored because not many tools are available for people to study events, trigger words, and event mention instances systematically and efficiently. In this paper, we present an interactive and easy-to-use tool, namely ED Explorer, for ED dataset and model exploration. ED Explorer consists of an interactive web application, an API, and an NLP toolkit, which can help both domain experts and non-experts to better understand the ED task. We use ED Explorer to analyze a recent proposed large-scale ED datasets (referred to as MAVEN), and discover several underlying problems, including sparsity, label bias, label imbalance, and debatable annotations, which provide us with directions to improve the MAVEN dataset. The ED Explorer can be publicly accessed through http://edx.leafnlp.org/. The demonstration video is available here https://www.youtube.com/watch?v=6QPnxPwxg50.

</p>
</details>

<details><summary><b>RadioPathomics: Multimodal Learning in Non-Small Cell Lung Cancer for Adaptive Radiotherapy</b>
<a href="https://arxiv.org/abs/2204.12423">arxiv:2204.12423</a>
&#x1F4C8; 4 <br>
<p>Matteo Tortora, Ermanno Cordelli, Rosa Sicilia, Lorenzo Nibid, Edy Ippolito, Giuseppe Perrone, Sara Ramella, Paolo Soda</p></summary>
<p>

**Abstract:** The current cancer treatment practice collects multimodal data, such as radiology images, histopathology slides, genomics and clinical data. The importance of these data sources taken individually has fostered the recent raise of radiomics and pathomics, i.e. the extraction of quantitative features from radiology and histopathology images routinely collected to predict clinical outcomes or to guide clinical decisions using artificial intelligence algorithms. Nevertheless, how to combine them into a single multimodal framework is still an open issue. In this work we therefore develop a multimodal late fusion approach that combines hand-crafted features computed from radiomics, pathomics and clinical data to predict radiation therapy treatment outcomes for non-small-cell lung cancer patients. Within this context, we investigate eight different late fusion rules (i.e. product, maximum, minimum, mean, decision template, Dempster-Shafer, majority voting, and confidence rule) and two patient-wise aggregation rules leveraging the richness of information given by computer tomography images and whole-slide scans. The experiments in leave-one-patient-out cross-validation on an in-house cohort of 33 patients show that the proposed multimodal paradigm with an AUC equal to $90.9\%$ outperforms each unimodal approach, suggesting that data integration can advance precision medicine. As a further contribution, we also compare the hand-crafted representations with features automatically computed by deep networks, and the late fusion paradigm with early fusion, another popular multimodal approach. In both cases, the experiments show that the proposed multimodal approach provides the best results.

</p>
</details>

<details><summary><b>An Algorithm for the Labeling and Interactive Visualization of the Cerebrovascular System of Ischemic Strokes</b>
<a href="https://arxiv.org/abs/2204.12333">arxiv:2204.12333</a>
&#x1F4C8; 4 <br>
<p>Florian Thamm, Markus Jürgens, Oliver Taubmann, Aleksandra Thamm, Leonhard Rist, Hendrik Ditt, Andreas Maier</p></summary>
<p>

**Abstract:** During the diagnosis of ischemic strokes, the Circle of Willis and its surrounding vessels are the arteries of interest. Their visualization in case of an acute stroke is often enabled by Computed Tomography Angiography (CTA). Still, the identification and analysis of the cerebral arteries remain time consuming in such scans due to a large number of peripheral vessels which may disturb the visual impression. In previous work we proposed VirtualDSA++, an algorithm designed to segment and label the cerebrovascular tree on CTA scans. Especially with stroke patients, labeling is a delicate procedure, as in the worst case whole hemispheres may not be present due to impeded perfusion. Hence, we extended the labeling mechanism for the cerebral arteries to identify occluded vessels. In the work at hand, we place the algorithm in a clinical context by evaluating the labeling and occlusion detection on stroke patients, where we have achieved labeling sensitivities comparable to other works between 92\,\% and 95\,\%. To the best of our knowledge, ours is the first work to address labeling and occlusion detection at once, whereby a sensitivity of 67\,\% and a specificity of 81\,\% were obtained for the latter. VirtualDSA++ also automatically segments and models the intracranial system, which we further used in a deep learning driven follow up work. We present the generic concept of iterative systematic search for pathways on all nodes of said model, which enables new interactive features. Exemplary, we derive in detail, firstly, the interactive planning of vascular interventions like the mechanical thrombectomy and secondly, the interactive suppression of vessel structures that are not of interest in diagnosing strokes (like veins). We discuss both features as well as further possibilities emerging from the proposed concept.

</p>
</details>

<details><summary><b>Sentiment Analysis of Cybersecurity Content on Twitter and Reddit</b>
<a href="https://arxiv.org/abs/2204.12267">arxiv:2204.12267</a>
&#x1F4C8; 4 <br>
<p>Bipun Thapa</p></summary>
<p>

**Abstract:** Sentiment Analysis provides an opportunity to understand the subject(s), especially in the digital age, due to an abundance of public data and effective algorithms. Cybersecurity is a subject where opinions are plentiful and differing in the public domain. This descriptive research analyzed cybersecurity content on Twitter and Reddit to measure its sentiment, positive or negative, or neutral. The data from Twitter and Reddit was amassed via technology-specific APIs during a selected timeframe to create datasets, which were then analyzed individually for their sentiment by VADER, an NLP (Natural Language Processing) algorithm. A random sample of cybersecurity content (ten tweets and posts) was also classified for sentiments by twenty human annotators to evaluate the performance of VADER. Cybersecurity content on Twitter was at least 48% positive, and Reddit was at least 26.5% positive. The positive or neutral content far outweighed negative sentiments across both platforms. When compared to human classification, which was considered the standard or source of truth, VADER produced 60% accuracy for Twitter and 70% for Reddit in assessing the sentiment; in other words, some agreement between algorithm and human classifiers. Overall, the goal was to explore an uninhibited research topic about cybersecurity sentiment

</p>
</details>

<details><summary><b>Stochastic Coherence Over Attention Trajectory For Continuous Learning In Video Streams</b>
<a href="https://arxiv.org/abs/2204.12193">arxiv:2204.12193</a>
&#x1F4C8; 4 <br>
<p>Matteo Tiezzi, Simone Marullo, Lapo Faggi, Enrico Meloni, Alessandro Betti, Stefano Melacci</p></summary>
<p>

**Abstract:** Devising intelligent agents able to live in an environment and learn by observing the surroundings is a longstanding goal of Artificial Intelligence. From a bare Machine Learning perspective, challenges arise when the agent is prevented from leveraging large fully-annotated dataset, but rather the interactions with supervisory signals are sparsely distributed over space and time. This paper proposes a novel neural-network-based approach to progressively and autonomously develop pixel-wise representations in a video stream. The proposed method is based on a human-like attention mechanism that allows the agent to learn by observing what is moving in the attended locations. Spatio-temporal stochastic coherence along the attention trajectory, paired with a contrastive term, leads to an unsupervised learning criterion that naturally copes with the considered setting. Differently from most existing works, the learned representations are used in open-set class-incremental classification of each frame pixel, relying on few supervisions. Our experiments leverage 3D virtual environments and they show that the proposed agents can learn to distinguish objects just by observing the video stream. Inheriting features from state-of-the art models is not as powerful as one might expect.

</p>
</details>

<details><summary><b>SkillNet-NLG: General-Purpose Natural Language Generation with a Sparsely Activated Approach</b>
<a href="https://arxiv.org/abs/2204.12184">arxiv:2204.12184</a>
&#x1F4C8; 4 <br>
<p>Junwei Liao, Duyu Tang, Fan Zhang, Shuming Shi</p></summary>
<p>

**Abstract:** We present SkillNet-NLG, a sparsely activated approach that handles many natural language generation tasks with one model. Different from traditional dense models that always activate all the parameters, SkillNet-NLG selectively activates relevant parts of the parameters to accomplish a task, where the relevance is controlled by a set of predefined skills. The strength of such model design is that it provides an opportunity to precisely adapt relevant skills to learn new tasks effectively. We evaluate on Chinese natural language generation tasks. Results show that, with only one model file, SkillNet-NLG outperforms previous best performance methods on four of five tasks. SkillNet-NLG performs better than two multi-task learning baselines (a dense model and a Mixture-of-Expert model) and achieves comparable performance to task-specific models. Lastly, SkillNet-NLG surpasses baseline systems when being adapted to new tasks.

</p>
</details>

<details><summary><b>A Comparative Study on Approaches to Acoustic Scene Classification using CNNs</b>
<a href="https://arxiv.org/abs/2204.12177">arxiv:2204.12177</a>
&#x1F4C8; 4 <br>
<p>Ishrat Jahan Ananya, Sarah Suad, Shadab Hafiz Choudhury, Mohammad Ashrafuzzaman Khan</p></summary>
<p>

**Abstract:** Acoustic scene classification is a process of characterizing and classifying the environments from sound recordings. The first step is to generate features (representations) from the recorded sound and then classify the background environments. However, different kinds of representations have dramatic effects on the accuracy of the classification. In this paper, we explored the three such representations on classification accuracy using neural networks. We investigated the spectrograms, MFCCs, and embeddings representations using different CNN networks and autoencoders. Our dataset consists of sounds from three settings of indoors and outdoors environments - thus the dataset contains sound from six different kinds of environments. We found that the spectrogram representation has the highest classification accuracy while MFCC has the lowest classification accuracy. We reported our findings, insights as well as some guidelines to achieve better accuracy for environment classification using sounds.

</p>
</details>

<details><summary><b>ATST: Audio Representation Learning with Teacher-Student Transformer</b>
<a href="https://arxiv.org/abs/2204.12076">arxiv:2204.12076</a>
&#x1F4C8; 4 <br>
<p>Xian Li, Xiaofei Li</p></summary>
<p>

**Abstract:** Self-supervised learning (SSL) learns knowledge from a large amount of unlabeled data, and then transfers the knowledge to a specific problem with a limited number of labeled data. SSL has achieved promising results in various domains. This work addresses the problem of segment-level general audio SSL, and proposes a new transformer-based teacher-student SSL model, named ATST. A transformer encoder is developed on a recently emerged teacher-student baseline scheme, which largely improves the modeling capability of pre-training. In addition, a new strategy for positive pair creation is designed to fully leverage the capability of transformer. Extensive experiments have been conducted, and the proposed model achieves the new state-of-the-art results on almost all of the downstream tasks.

</p>
</details>

<details><summary><b>Continual Learning for Peer-to-Peer Federated Learning: A Study on Automated Brain Metastasis Identification</b>
<a href="https://arxiv.org/abs/2204.13591">arxiv:2204.13591</a>
&#x1F4C8; 3 <br>
<p>Yixing Huang, Christoph Bert, Stefan Fischer, Manuel Schmidt, Arnd Dörfler, Andreas Maier, Rainer Fietkau, Florian Putz</p></summary>
<p>

**Abstract:** Due to data privacy constraints, data sharing among multiple centers is restricted. Continual learning, as one approach to peer-to-peer federated learning, can promote multicenter collaboration on deep learning algorithm development by sharing intermediate models instead of training data. This work aims to investigate the feasibility of continual learning for multicenter collaboration on an exemplary application of brain metastasis identification using DeepMedic. 920 T1 MRI contrast enhanced volumes are split to simulate multicenter collaboration scenarios. A continual learning algorithm, synaptic intelligence (SI), is applied to preserve important model weights for training one center after another. In a bilateral collaboration scenario, continual learning with SI achieves a sensitivity of 0.917, and naive continual learning without SI achieves a sensitivity of 0.906, while two models trained on internal data solely without continual learning achieve sensitivity of 0.853 and 0.831 only. In a seven-center multilateral collaboration scenario, the models trained on internal datasets (100 volumes each center) without continual learning obtain a mean sensitivity value of 0.699. With single-visit continual learning (i.e., the shared model visits each center only once during training), the sensitivity is improved to 0.788 and 0.849 without SI and with SI, respectively. With iterative continual learning (i.e., the shared model revisits each center multiple times during training), the sensitivity is further improved to 0.914, which is identical to the sensitivity using mixed data for training. Our experiments demonstrate that continual learning can improve brain metastasis identification performance for centers with limited data. This study demonstrates the feasibility of applying continual learning for peer-to-peer federated learning in multicenter collaboration.

</p>
</details>

<details><summary><b>Nonbacktracking spectral clustering of nonuniform hypergraphs</b>
<a href="https://arxiv.org/abs/2204.13586">arxiv:2204.13586</a>
&#x1F4C8; 3 <br>
<p>Philip Chodrow, Nicole Eikmeier, Jamie Haddock</p></summary>
<p>

**Abstract:** Spectral methods offer a tractable, global framework for clustering in graphs via eigenvector computations on graph matrices. Hypergraph data, in which entities interact on edges of arbitrary size, poses challenges for matrix representations and therefore for spectral clustering. We study spectral clustering for nonuniform hypergraphs based on the hypergraph nonbacktracking operator. After reviewing the definition of this operator and its basic properties, we prove a theorem of Ihara-Bass type to enable faster computation of eigenpairs. We then propose an alternating algorithm for inference in a hypergraph stochastic blockmodel via linearized belief-propagation, offering proofs that both formalize and extend several previous results. We perform experiments in real and synthetic data that underscore the benefits of hypergraph methods over graph-based ones when interactions of different sizes carry different information about cluster structure. Through an analysis of our algorithm, we pose several conjectures about the limits of spectral methods and detectability in hypergraph stochastic blockmodels writ large.

</p>
</details>

<details><summary><b>Adaptable Text Matching via Meta-Weight Regulator</b>
<a href="https://arxiv.org/abs/2204.12668">arxiv:2204.12668</a>
&#x1F4C8; 3 <br>
<p>Bo Zhang, Chen Zhang, Fang Ma, Dawei Song</p></summary>
<p>

**Abstract:** Neural text matching models have been used in a range of applications such as question answering and natural language inference, and have yielded a good performance. However, these neural models are of a limited adaptability, resulting in a decline in performance when encountering test examples from a different dataset or even a different task. The adaptability is particularly important in the few-shot setting: in many cases, there is only a limited amount of labeled data available for a target dataset or task, while we may have access to a richly labeled source dataset or task. However, adapting a model trained on the abundant source data to a few-shot target dataset or task is challenging. To tackle this challenge, we propose a Meta-Weight Regulator (MWR), which is a meta-learning approach that learns to assign weights to the source examples based on their relevance to the target loss. Specifically, MWR first trains the model on the uniformly weighted source examples, and measures the efficacy of the model on the target examples via a loss function. By iteratively performing a (meta) gradient descent, high-order gradients are propagated to the source examples. These gradients are then used to update the weights of source examples, in a way that is relevant to the target performance. As MWR is model-agnostic, it can be applied to any backbone neural model. Extensive experiments are conducted with various backbone text matching models, on four widely used datasets and two tasks. The results demonstrate that our proposed approach significantly outperforms a number of existing adaptation methods and effectively improves the cross-dataset and cross-task adaptability of the neural text matching models in the few-shot setting.

</p>
</details>

<details><summary><b>Gaussian Kernel Variance For an Adaptive Learning Method on Signals Over Graphs</b>
<a href="https://arxiv.org/abs/2204.12629">arxiv:2204.12629</a>
&#x1F4C8; 3 <br>
<p>Yue Zhao, Ender Ayanoglu</p></summary>
<p>

**Abstract:** This paper discusses a special kind of a simple yet possibly powerful algorithm, called single-kernel Gradraker (SKG), which is an adaptive learning method predicting unknown nodal values in a network using known nodal values and the network structure. We aim to find out how to configure the special kind of the model in applying the algorithm. To be more specific, we focus on SKG with a Gaussian kernel and specify how to find a suitable variance for the kernel. To do so, we introduce two variables with which we are able to set up requirements on the variance of the Gaussian kernel to achieve (near-) optimal performance and can better understand how SKG works. Our contribution is that we introduce two variables as analysis tools, illustrate how predictions will be affected under different Gaussian kernels, and provide an algorithm finding a suitable Gaussian kernel for SKG with knowledge about the training network. Simulation results on real datasets are provided.

</p>
</details>

<details><summary><b>Learning Eco-Driving Strategies at Signalized Intersections</b>
<a href="https://arxiv.org/abs/2204.12561">arxiv:2204.12561</a>
&#x1F4C8; 3 <br>
<p>Vindula Jayawardana, Cathy Wu</p></summary>
<p>

**Abstract:** Signalized intersections in arterial roads result in persistent vehicle idling and excess accelerations, contributing to fuel consumption and CO2 emissions. There has thus been a line of work studying eco-driving control strategies to reduce fuel consumption and emission levels at intersections. However, methods to devise effective control strategies across a variety of traffic settings remain elusive. In this paper, we propose a reinforcement learning (RL) approach to learn effective eco-driving control strategies. We analyze the potential impact of a learned strategy on fuel consumption, CO2 emission, and travel time and compare with naturalistic driving and model-based baselines. We further demonstrate the generalizability of the learned policies under mixed traffic scenarios. Simulation results indicate that scenarios with 100% penetration of connected autonomous vehicles (CAV) may yield as high as 18% reduction in fuel consumption and 25% reduction in CO2 emission levels while even improving travel speed by 20%. Furthermore, results indicate that even 25% CAV penetration can bring at least 50% of the total fuel and emission reduction benefits.

</p>
</details>

<details><summary><b>Self-Supervised Information Bottleneck for Deep Multi-View Subspace Clustering</b>
<a href="https://arxiv.org/abs/2204.12496">arxiv:2204.12496</a>
&#x1F4C8; 3 <br>
<p>Shiye Wang, Changsheng Li, Yanming Li, Ye Yuan, Guoren Wang</p></summary>
<p>

**Abstract:** In this paper, we explore the problem of deep multi-view subspace clustering framework from an information-theoretic point of view. We extend the traditional information bottleneck principle to learn common information among different views in a self-supervised manner, and accordingly establish a new framework called Self-supervised Information Bottleneck based Multi-view Subspace Clustering (SIB-MSC). Inheriting the advantages from information bottleneck, SIB-MSC can learn a latent space for each view to capture common information among the latent representations of different views by removing superfluous information from the view itself while retaining sufficient information for the latent representations of other views. Actually, the latent representation of each view provides a kind of self-supervised signal for training the latent representations of other views. Moreover, SIB-MSC attempts to learn the other latent space for each view to capture the view-specific information by introducing mutual information based regularization terms, so as to further improve the performance of multi-view subspace clustering. To the best of our knowledge, this is the first work to explore information bottleneck for multi-view subspace clustering. Extensive experiments on real-world multi-view data demonstrate that our method achieves superior performance over the related state-of-the-art methods.

</p>
</details>

<details><summary><b>A review of Federated Learning in Intrusion Detection Systems for IoT</b>
<a href="https://arxiv.org/abs/2204.12443">arxiv:2204.12443</a>
&#x1F4C8; 3 <br>
<p>Aitor Belenguer, Javier Navaridas, Jose A. Pascual</p></summary>
<p>

**Abstract:** Intrusion detection systems are evolving into intelligent systems that perform data analysis searching for anomalies in their environment. The development of deep learning technologies opened the door to build more complex and effective threat detection models. However, training those models may be computationally infeasible in most Internet of Things devices. Current approaches rely on powerful centralized servers that receive data from all their parties -- violating basic privacy constraints and substantially affecting response times and operational costs due to the huge communication overheads. To mitigate these issues, Federated Learning emerged as a promising approach where different agents collaboratively train a shared model, neither exposing training data to others nor requiring a compute-intensive centralized infrastructure. This paper focuses on the application of Federated Learning approaches in the field of Intrusion Detection. Both technologies are described in detail and current scientific progress is reviewed and categorized. Finally, the paper highlights the limitations present in recent works and presents some future directions for this technology.

</p>
</details>

<details><summary><b>Quantum-classical convolutional neural networks in radiological image classification</b>
<a href="https://arxiv.org/abs/2204.12390">arxiv:2204.12390</a>
&#x1F4C8; 3 <br>
<p>Andrea Matic, Maureen Monnet, Jeanette Miriam Lorenz, Balthasar Schachtner, Thomas Messerer</p></summary>
<p>

**Abstract:** Quantum machine learning is receiving significant attention currently, but its usefulness in comparison to classical machine learning techniques for practical applications remains unclear. However, there are indications that certain quantum machine learning algorithms might result in improved training capabilities with respect to their classical counterparts -- which might be particularly beneficial in situations with little training data available. Such situations naturally arise in medical classification tasks. Within this paper, different hybrid quantum-classical convolutional neural networks (QCCNN) with varying quantum circuit designs and encoding techniques are proposed. They are applied to two- and three-dimensional medical imaging data, e.g. featuring different, potentially malign, lesions in computed tomography scans. The performance of these QCCNNs is already similar to the one of their classical counterparts -- therefore encouraging further studies towards the direction of applying these algorithms within medical imaging tasks.

</p>
</details>

<details><summary><b>Multi-task Learning for Concurrent Prediction of Thermal Comfort, Sensation, and Preference</b>
<a href="https://arxiv.org/abs/2204.12380">arxiv:2204.12380</a>
&#x1F4C8; 3 <br>
<p>Betty Lala, Hamada Rizk, Srikant Manas Kala, Aya Hagishima</p></summary>
<p>

**Abstract:** Indoor thermal comfort immensely impacts the health and performance of occupants. Therefore, researchers and engineers have proposed numerous computational models to estimate thermal comfort (TC). Given the impetus toward energy efficiency, the current focus is on data-driven TC prediction solutions that leverage state-of-the-art machine learning (ML) algorithms. However, an indoor occupant's perception of indoor thermal comfort (TC) is subjective and multi-dimensional. Different aspects of TC are represented by various standard metrics/scales viz., thermal sensation (TSV), thermal comfort (TCV), and thermal preference (TPV). The current ML-based TC prediction solutions adopt the Single-task Learning approach, i.e., one prediction model per metric. Consequently, solutions often focus on only one TC metric. Moreover, when several metrics are considered, multiple TC models for a single indoor space lead to conflicting predictions, making real-world deployment infeasible. This work addresses these problems. With the vision toward energy conservation and real-world application, naturally ventilated primary school classrooms are considered. First, month-long field experiments are conducted in 5 schools and 14 classrooms, including 512 unique student participants. Further, "DeepComfort," a Multi-task Learning inspired deep-learning model is proposed. DeepComfort predicts multiple TC output metrics viz., TSV, TPV, and TCV, simultaneously, through a single model. It demonstrates high F1-scores, Accuracy (>90%), and generalization capability when validated on the ASHRAE-II database and the dataset created in this study. DeepComfort is also shown to outperform 6 popular metric-specific single-task machine learning algorithms. To the best of our knowledge, this work is the first application of Multi-task Learning to thermal comfort prediction in classrooms.

</p>
</details>

<details><summary><b>EmpHi: Generating Empathetic Responses with Human-like Intents</b>
<a href="https://arxiv.org/abs/2204.12191">arxiv:2204.12191</a>
&#x1F4C8; 3 <br>
<p>Mao Yan Chen, Siheng Li, Yujiu Yang</p></summary>
<p>

**Abstract:** In empathetic conversations, humans express their empathy to others with empathetic intents. However, most existing empathetic conversational methods suffer from a lack of empathetic intents, which leads to monotonous empathy. To address the bias of the empathetic intents distribution between empathetic dialogue models and humans, we propose a novel model to generate empathetic responses with human-consistent empathetic intents, EmpHi for short. Precisely, EmpHi learns the distribution of potential empathetic intents with a discrete latent variable, then combines both implicit and explicit intent representation to generate responses with various empathetic intents. Experiments show that EmpHi outperforms state-of-the-art models in terms of empathy, relevance, and diversity on both automatic and human evaluation. Moreover, the case studies demonstrate the high interpretability and outstanding performance of our model.

</p>
</details>

<details><summary><b>U-Net with ResNet Backbone for Garment Landmarking Purpose</b>
<a href="https://arxiv.org/abs/2204.12084">arxiv:2204.12084</a>
&#x1F4C8; 3 <br>
<p>Khay Boon Hong</p></summary>
<p>

**Abstract:** We build a heatmap-based landmark detection model to locate important landmarks on 2D RGB garment images. The main goal is to detect edges, corners and suitable interior region of the garments. This let us re-create 3D garments in modern 3D editing software by incorporate landmark detection model and texture unwrapping. We use a U-net architecture with ResNet backbone to build the model. With an appropriate loss function, we are able to train a moderately robust model.

</p>
</details>

<details><summary><b>AAU-net: An Adaptive Attention U-net for Breast Lesions Segmentation in Ultrasound Images</b>
<a href="https://arxiv.org/abs/2204.12077">arxiv:2204.12077</a>
&#x1F4C8; 3 <br>
<p>Gongping Chen, Yu Dai, Jianxun Zhang, Moi Hoon Yap</p></summary>
<p>

**Abstract:** Various deep learning methods have been proposed to segment breast lesion from ultrasound images. However, similar intensity distributions, variable tumor morphology and blurred boundaries present challenges for breast lesions segmentation, especially for malignant tumors with irregular shapes. Considering the complexity of ultrasound images, we develop an adaptive attention U-net (AAU-net) to segment breast lesions automatically and stably from ultrasound images. Specifically, we introduce a hybrid adaptive attention module, which mainly consists of a channel self-attention block and a spatial self-attention block, to replace the traditional convolution operation. Compared with the conventional convolution operation, the design of the hybrid adaptive attention module can help us capture more features under different receptive fields. Different from existing attention mechanisms, the hybrid adaptive attention module can guide the network to adaptively select more robust representation in channel and space dimensions to cope with more complex breast lesions segmentation. Extensive experiments with several state-of-the-art deep learning segmentation methods on three public breast ultrasound datasets show that our method has better performance on breast lesion segmentation. Furthermore, robustness analysis and external experiments demonstrate that our proposed AAU-net has better generalization performance on the segmentation of breast lesions. Moreover, the hybrid adaptive attention module can be flexibly applied to existing network frameworks.

</p>
</details>

<details><summary><b>GPUNet: Searching the Deployable Convolution Neural Networks for GPUs</b>
<a href="https://arxiv.org/abs/2205.00841">arxiv:2205.00841</a>
&#x1F4C8; 2 <br>
<p>Linnan Wang, Chenhan Yu, Satish Salian, Slawomir Kierat, Szymon Migacz, Alex Fit Florea</p></summary>
<p>

**Abstract:** Customizing Convolution Neural Networks (CNN) for production use has been a challenging task for DL practitioners. This paper intends to expedite the model customization with a model hub that contains the optimized models tiered by their inference latency using Neural Architecture Search (NAS). To achieve this goal, we build a distributed NAS system to search on a novel search space that consists of prominent factors to impact latency and accuracy. Since we target GPU, we name the NAS optimized models as GPUNet, which establishes a new SOTA Pareto frontier in inference latency and accuracy. Within 1$ms$, GPUNet is 2x faster than EfficientNet-X and FBNetV3 with even better accuracy. We also validate GPUNet on detection tasks, and GPUNet consistently outperforms EfficientNet-X and FBNetV3 on COCO detection tasks in both latency and accuracy. All of these data validate that our NAS system is effective and generic to handle different design tasks. With this NAS system, we expand GPUNet to cover a wide range of latency targets such that DL practitioners can deploy our models directly in different scenarios.

</p>
</details>

<details><summary><b>Unsupervised Learning of Unbiased Visual Representations</b>
<a href="https://arxiv.org/abs/2204.12941">arxiv:2204.12941</a>
&#x1F4C8; 2 <br>
<p>Carlo Alberto Barbano, Enzo Tartaglione, Marco Grangetto</p></summary>
<p>

**Abstract:** Deep neural networks are known for their inability to learn robust representations when biases exist in the dataset. This results in a poor generalization to unbiased datasets, as the predictions strongly rely on peripheral and confounding factors, which are erroneously learned by the network. Many existing works deal with this issue by either employing an explicit supervision on the bias attributes, or assuming prior knowledge about the bias. In this work we study this problem in a more difficult scenario, in which no explicit annotation about the bias is available, and without any prior knowledge about its nature. We propose a fully unsupervised debiasing framework, consisting of three steps: first, we exploit the natural preference for learning malignant biases, obtaining a bias-capturing model; then, we perform a pseudo-labelling step to obtain bias labels; finally we employ state-of-the-art supervised debiasing techniques to obtain an unbiased model. We also propose a theoretical framework to assess the biasness of a model, and provide a detailed analysis on how biases affect the training of neural networks. We perform experiments on synthetic and real-world datasets, showing that our method achieves state-of-the-art performance in a variety of settings, sometimes even higher than fully supervised debiasing approaches.

</p>
</details>

<details><summary><b>The Multimarginal Optimal Transport Formulation of Adversarial Multiclass Classification</b>
<a href="https://arxiv.org/abs/2204.12676">arxiv:2204.12676</a>
&#x1F4C8; 2 <br>
<p>Nicolas Garcia Trillos, Matt Jacobs, Jakwang Kim</p></summary>
<p>

**Abstract:** We study a family of adversarial multiclass classification problems and provide equivalent reformulations in terms of: 1) a family of generalized barycenter problems introduced in the paper and 2) a family of multimarginal optimal transport problems where the number of marginals is equal to the number of classes in the original classification problem. These new theoretical results reveal a rich geometric structure of adversarial learning problems in multiclass classification and extend recent results restricted to the binary classification setting. A direct computational implication of our results is that by solving either the barycenter problem and its dual, or the MOT problem and its dual, we can recover the optimal robust classification rule and the optimal adversarial strategy for the original adversarial problem. Examples with synthetic and real data illustrate our results.

</p>
</details>

<details><summary><b>Span-level Bidirectional Cross-attention Framework for Aspect Sentiment Triplet Extraction</b>
<a href="https://arxiv.org/abs/2204.12674">arxiv:2204.12674</a>
&#x1F4C8; 2 <br>
<p>Yuqi Chen, Keming Chen, Xian Sun, Zequn Zhang</p></summary>
<p>

**Abstract:** Aspect Sentiment Triplet Extraction (ASTE) is a new fine-grained sentiment analysis task that aims to extract triplets of aspect terms, sentiments, and opinion terms from review sentences. Recently, span-level models achieve gratifying results on ASTE task by taking advantage of whole span predictions. However, all the spans generated by these methods inevitably share at least one token with some others, and these method suffer from the similarity of these spans due to their similar distributions. Moreover, since either the aspect term or opinion term can trigger a sentiment triplet, it is challenging to make use of the information more comprehensively and adequately. To address these concerns, we propose a span-level bidirectional cross-attention framework. Specifically, we design a similar span separation loss to detach the spans with shared tokens and a bidirectional cross-attention structure that consists of aspect and opinion decoders to decode the span-level representations in both aspect-to-opinion and opinion-to-aspect directions. With differentiated span representations and bidirectional decoding structure, our model can extract sentiment triplets more precisely and efficiently. Experimental results show that our framework significantly outperforms state-of-the-art methods, achieving better performance in predicting triplets with multi-token entities and extracting triplets in sentences with multi-triplets.

</p>
</details>

<details><summary><b>Relational Abstractions for Generalized Reinforcement Learning on Symbolic Problems</b>
<a href="https://arxiv.org/abs/2204.12665">arxiv:2204.12665</a>
&#x1F4C8; 2 <br>
<p>Rushang Karia, Siddharth Srivastava</p></summary>
<p>

**Abstract:** Reinforcement learning in problems with symbolic state spaces is challenging due to the need for reasoning over long horizons. This paper presents a new approach that utilizes relational abstractions in conjunction with deep learning to learn a generalizable Q-function for such problems. The learned Q-function can be efficiently transferred to related problems that have different object names and object quantities, and thus, entirely different state spaces. We show that the learned generalized Q-function can be utilized for zero-shot transfer to related problems without an explicit, hand-coded curriculum. Empirical evaluations on a range of problems show that our method facilitates efficient zero-shot transfer of learned knowledge to much larger problem instances containing many objects.

</p>
</details>

<details><summary><b>SCGC : Self-Supervised Contrastive Graph Clustering</b>
<a href="https://arxiv.org/abs/2204.12656">arxiv:2204.12656</a>
&#x1F4C8; 2 <br>
<p>Gayan K. Kulatilleke, Marius Portmann, Shekhar S. Chandra</p></summary>
<p>

**Abstract:** Graph clustering discovers groups or communities within networks. Deep learning methods such as autoencoders (AE) extract effective clustering and downstream representations but cannot incorporate rich structural information. While Graph Neural Networks (GNN) have shown great success in encoding graph structure, typical GNNs based on convolution or attention variants suffer from over-smoothing, noise, heterophily, are computationally expensive and typically require the complete graph being present. Instead, we propose Self-Supervised Contrastive Graph Clustering (SCGC), which imposes graph-structure via contrastive loss signals to learn discriminative node representations and iteratively refined soft cluster labels. We also propose SCGC*, with a more effective, novel, Influence Augmented Contrastive (IAC) loss to fuse richer structural information, and half the original model parameters. SCGC(*) is faster with simple linear units, completely eliminate convolutions and attention of traditional GNNs, yet efficiently incorporates structure. It is impervious to layer depth and robust to over-smoothing, incorrect edges and heterophily. It is scalable by batching, a limitation in many prior GNN models, and trivially parallelizable. We obtain significant improvements over state-of-the-art on a wide range of benchmark graph datasets, including images, sensor data, text, and citation networks efficiently. Specifically, 20% on ARI and 18% on NMI for DBLP; overall 55% reduction in training time and overall, 81% reduction on inference time. Our code is available at : https://github.com/gayanku/SCGC

</p>
</details>

<details><summary><b>Trends in Remote Learning-based Google Shopping in the United States due to COVID-19</b>
<a href="https://arxiv.org/abs/2204.12654">arxiv:2204.12654</a>
&#x1F4C8; 2 <br>
<p>Isabella Hall, Nirmalya Thakur, Chia Y. Han</p></summary>
<p>

**Abstract:** The United States of America has been the worst affected country in terms of the number of cases and deaths on account of the severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) or COVID-19, a highly transmissible and pathogenic coronavirus that started spreading globally in late 2019. On account of the surge of infections, accompanied by hospitalizations and deaths due to COVID-19, and lack of a definitive cure at that point, a national emergency was declared in the United States on March 13, 2020. To prevent the rapid spread of the virus, several states declared stay at home and remote work guidelines shortly after this declaration of an emergency. Such guidelines caused schools, colleges, and universities, both private and public, in all the 50-United States to switch to remote or online forms of teaching for a significant period of time. As a result, Google, the most widely used search engine in the United States, experienced a surge in online shopping of remote learning-based software, systems, applications, and gadgets by both educators and students from all the 50-United States, due to both these groups responding to the associated needs and demands related to switching to remote teaching and learning. This paper aims to investigate, analyze, and interpret these trends of Google Shopping related to remote learning that emerged since March 13, 2020, on account of COVID-19 and the subsequent remote learning adoption in almost all schools, colleges, and universities, from all the 50-United States. The study was performed using Google Trends, which helps to track and study Google Shopping-based online activity emerging from different geolocations. The results and discussions show that the highest interest related to Remote Learning-based Google Shopping was recorded from Oregon, which was followed by Illinois, Florida, Texas, California, and the other states.

</p>
</details>

<details><summary><b>Generating Self-Serendipity Preference in Recommender Systems for Addressing Cold Start Problems</b>
<a href="https://arxiv.org/abs/2204.12651">arxiv:2204.12651</a>
&#x1F4C8; 2 <br>
<p>Yuanbo Xu, Yongjian Yang, En Wang</p></summary>
<p>

**Abstract:** Classical accuracy-oriented Recommender Systems (RSs) typically face the cold-start problem and the filter-bubble problem when users suffer the familiar, repeated, and even predictable recommendations, making them boring and unsatisfied. To address the above issues, serendipity-oriented RSs are proposed to recommend appealing and valuable items significantly deviating from users' historical interactions and thus satisfying them by introducing unexplored but relevant candidate items to them. In this paper, we devise a novel serendipity-oriented recommender system (\textbf{G}enerative \textbf{S}elf-\textbf{S}erendipity \textbf{R}ecommender \textbf{S}ystem, \textbf{GS$^2$-RS}) that generates users' self-serendipity preferences to enhance the recommendation performance. Specifically, this model extracts users' interest and satisfaction preferences, generates virtual but convincible neighbors' preferences from themselves, and achieves their self-serendipity preference. Then these preferences are injected into the rating matrix as additional information for RS models. Note that GS$^2$-RS can not only tackle the cold-start problem but also provides diverse but relevant recommendations to relieve the filter-bubble problem. Extensive experiments on benchmark datasets illustrate that the proposed GS$^2$-RS model can significantly outperform the state-of-the-art baseline approaches in serendipity measures with a stable accuracy performance.

</p>
</details>

<details><summary><b>Generating Examples From CLI Usage: Can Transformers Help?</b>
<a href="https://arxiv.org/abs/2204.12648">arxiv:2204.12648</a>
&#x1F4C8; 2 <br>
<p>Roshanak Zilouchian Moghaddam, Spandan Garg, Colin B. Clement, Yevhen Mohylevskyy, Neel Sundaresan</p></summary>
<p>

**Abstract:** Continuous evolution in modern software often causes documentation, tutorials, and examples to be out of sync with changing interfaces and frameworks. Relying on outdated documentation and examples can lead programs to fail or be less efficient or even less secure. In response, programmers need to regularly turn to other resources on the web such as StackOverflow for examples to guide them in writing software. We recognize that this inconvenient, error-prone, and expensive process can be improved by using machine learning applied to software usage data. In this paper, we present our practical system which uses machine learning on large-scale telemetry data and documentation corpora, generating appropriate and complex examples that can be used to improve documentation. We discuss both feature-based and transformer-based machine learning approaches and demonstrate that our system achieves 100% coverage for the used functionalities in the product, providing up-to-date examples upon every release and reduces the numbers of PRs submitted by software owners writing and editing documentation by >68%. We also share valuable lessons learnt during the 3 years that our production quality system has been deployed for Azure Cloud Command Line Interface (Azure CLI).

</p>
</details>

<details><summary><b>Evaluation of Self-taught Learning-based Representations for Facial Emotion Recognition</b>
<a href="https://arxiv.org/abs/2204.12624">arxiv:2204.12624</a>
&#x1F4C8; 2 <br>
<p>Bruna Delazeri, Leonardo L. Veras, Alceu de S. Britto Jr., Jean Paul Barddal, Alessandro L. Koerich</p></summary>
<p>

**Abstract:** This work describes different strategies to generate unsupervised representations obtained through the concept of self-taught learning for facial emotion recognition (FER). The idea is to create complementary representations promoting diversity by varying the autoencoders' initialization, architecture, and training data. SVM, Bagging, Random Forest, and a dynamic ensemble selection method are evaluated as final classification methods. Experimental results on Jaffe and Cohn-Kanade datasets using a leave-one-subject-out protocol show that FER methods based on the proposed diverse representations compare favorably against state-of-the-art approaches that also explore unsupervised feature learning.

</p>
</details>

<details><summary><b>RAMBO-RL: Robust Adversarial Model-Based Offline Reinforcement Learning</b>
<a href="https://arxiv.org/abs/2204.12581">arxiv:2204.12581</a>
&#x1F4C8; 2 <br>
<p>Marc Rigter, Bruno Lacerda, Nick Hawes</p></summary>
<p>

**Abstract:** Offline reinforcement learning (RL) aims to find near-optimal policies from logged data without further environment interaction. Model-based algorithms, which learn a model of the environment from the dataset and perform conservative policy optimisation within that model, have emerged as a promising approach to this problem. In this work, we present Robust Adversarial Model-Based Offline RL (RAMBO), a novel approach to model-based offline RL. To achieve conservatism, we formulate the problem as a two-player zero sum game against an adversarial environment model. The model is trained minimise the value function while still accurately predicting the transitions in the dataset, forcing the policy to act conservatively in areas not covered by the dataset. To approximately solve the two-player game, we alternate between optimising the policy and optimising the model adversarially. The problem formulation that we address is theoretically grounded, resulting in a PAC performance guarantee and a pessimistic value function which lower bounds the value function in the true environment. We evaluate our approach on widely studied offline RL benchmarks, and demonstrate that our approach achieves state of the art performance.

</p>
</details>

<details><summary><b>Toward Policy Explanations for Multi-Agent Reinforcement Learning</b>
<a href="https://arxiv.org/abs/2204.12568">arxiv:2204.12568</a>
&#x1F4C8; 2 <br>
<p>Kayla Boggess, Sarit Kraus, Lu Feng</p></summary>
<p>

**Abstract:** Advances in multi-agent reinforcement learning (MARL) enable sequential decision making for a range of exciting multi-agent applications such as cooperative AI and autonomous driving. Explaining agent decisions is crucial for improving system transparency, increasing user satisfaction, and facilitating human-agent collaboration. However, existing works on explainable reinforcement learning mostly focus on the single-agent setting and are not suitable for addressing challenges posed by multi-agent environments. We present novel methods to generate two types of policy explanations for MARL: (i) policy summarization about the agent cooperation and task sequence, and (ii) language explanations to answer queries about agent behavior. Experimental results on three MARL domains demonstrate the scalability of our methods. A user study shows that the generated explanations significantly improve user performance and increase subjective ratings on metrics such as user satisfaction.

</p>
</details>

<details><summary><b>Parkinson's disease diagnostics using AI and natural language knowledge transfer</b>
<a href="https://arxiv.org/abs/2204.12559">arxiv:2204.12559</a>
&#x1F4C8; 2 <br>
<p>Maurycy Chronowski, Maciej Klaczynski, Malgorzata Dec-Cwiek, Karolina Porebska</p></summary>
<p>

**Abstract:** In this work, the issue of Parkinson's disease (PD) diagnostics using non-invasive antemortem techniques was tackled. A deep learning approach for classification of raw speech recordings in patients with diagnosed PD was proposed. The core of proposed method is an audio classifier using knowledge transfer from a pretrained natural language model, namely \textit{wav2vec 2.0}. Method was tested on a group of 38 PD patients and 10 healthy persons above the age of 50. A dataset of speech recordings acquired using a smartphone recorder was constructed and the recordings were label as PD/non-PD with severity of the disease additionally rated using Hoehn-Yahr scale. The audio recordings were cut into 2141 samples that include sentences, syllables, vowels and sustained phonation. The classifier scores up to 97.92\% of cross-validated accuracy. Additionally, paper presents results of a human-level performance assessment questionnaire, which was consulted with the neurology professionals

</p>
</details>

<details><summary><b>Multi stain graph fusion for multimodal integration in pathology</b>
<a href="https://arxiv.org/abs/2204.12541">arxiv:2204.12541</a>
&#x1F4C8; 2 <br>
<p>Chaitanya Dwivedi, Shima Nofallah, Maryam Pouryahya, Janani Iyer, Kenneth Leidal, Chuhan Chung, Timothy Watkins, Andrew Billin, Robert Myers, John Abel, Ali Behrooz</p></summary>
<p>

**Abstract:** In pathology, tissue samples are assessed using multiple staining techniques to enhance contrast in unique histologic features. In this paper, we introduce a multimodal CNN-GNN based graph fusion approach that leverages complementary information from multiple non-registered histopathology images to predict pathologic scores. We demonstrate this approach in nonalcoholic steatohepatitis (NASH) by predicting CRN fibrosis stage and NAFLD Activity Score (NAS). Primary assessment of NASH typically requires liver biopsy evaluation on two histological stains: Trichrome (TC) and hematoxylin and eosin (H&E). Our multimodal approach learns to extract complementary information from TC and H&E graphs corresponding to each stain while simultaneously learning an optimal policy to combine this information. We report up to 20% improvement in predicting fibrosis stage and NAS component grades over single-stain modeling approaches, measured by computing linearly weighted Cohen's kappa between machine-derived vs. pathologist consensus scores. Broadly, this paper demonstrates the value of leveraging diverse pathology images for improved ML-powered histologic assessment.

</p>
</details>

<details><summary><b>Automation of Radiation Treatment Planning for Rectal Cancer</b>
<a href="https://arxiv.org/abs/2204.12539">arxiv:2204.12539</a>
&#x1F4C8; 2 <br>
<p>Kai Huang, Prajnan Das, Adenike M. Olanrewaju, Carlos Cardenas, David Fuentes, Lifei Zhang, Donald Hancock, Hannah Simonds, Dong Joo Rhee, Sam Beddar, Tina Marie Briere, Laurence Court</p></summary>
<p>

**Abstract:** To develop an automated workflow for rectal cancer three-dimensional conformal radiotherapy treatment planning that combines deep-learning(DL) aperture predictions and forward-planning algorithms. We designed an algorithm to automate the clinical workflow for planning with field-in-field. DL models were trained, validated, and tested on 555 patients to automatically generate aperture shapes for primary and boost fields. Network inputs were digitally reconstructed radiography, gross tumor volume(GTV), and nodal GTV. A physician scored each aperture for 20 patients on a 5-point scale(>3 acceptable). A planning algorithm was then developed to create a homogeneous dose using a combination of wedges and subfields. The algorithm iteratively identifies a hotspot volume, creates a subfield, and optimizes beam weight all without user intervention. The algorithm was tested on 20 patients using clinical apertures with different settings, and the resulting plans(4 plans/patient) were scored by a physician. The end-to-end workflow was tested and scored by a physician on 39 patients using DL-generated apertures and planning algorithms. The predicted apertures had Dice scores of 0.95, 0.94, and 0.90 for posterior-anterior, laterals, and boost fields, respectively. 100%, 95%, and 87.5% of the posterior-anterior, laterals, and boost apertures were scored as clinically acceptable, respectively. Wedged and non-wedged plans were clinically acceptable for 85% and 50% of patients, respectively. The final plans hotspot dose percentage was reduced from 121%($\pm$ 14%) to 109%($\pm$ 5%) of prescription dose. The integrated end-to-end workflow of automatically generated apertures and optimized field-in-field planning gave clinically acceptable plans for 38/39(97%) of patients. We have successfully automated the clinical workflow for generating radiotherapy plans for rectal cancer for our institution.

</p>
</details>

<details><summary><b>Application of WGAN-GP in recommendation and Questioning the relevance of GAN-based approaches</b>
<a href="https://arxiv.org/abs/2204.12527">arxiv:2204.12527</a>
&#x1F4C8; 2 <br>
<p>Hichem Ammar Khodja, Oussama Boudjeniba</p></summary>
<p>

**Abstract:** Many neural-based recommender systems were proposed in recent years and part of them used Generative Adversarial Networks (GAN) to model user-item interactions. However, the exploration of Wasserstein GAN with Gradient Penalty (WGAN-GP) on recommendation has received relatively less scrutiny. In this paper, we focus on two questions: 1- Can we successfully apply WGAN-GP on recommendation and does this approach give an advantage compared to the best GAN models? 2- Are GAN-based recommender systems relevant? To answer the first question, we propose a recommender system based on WGAN-GP called CFWGAN-GP which is founded on a previous model (CFGAN). We successfully applied our method on real-world datasets on the top-k recommendation task and the empirical results show that it is competitive with state-of-the-art GAN approaches, but we found no evidence of significant advantage of using WGAN-GP instead of the original GAN, at least from the accuracy point of view. As for the second question, we conduct a simple experiment in which we show that a well-tuned conceptually simpler method outperforms GAN-based models by a considerable margin, questioning the use of such models.

</p>
</details>

<details><summary><b>Automatic Monitoring of Fruit Ripening Rooms by UHF RFID Sensor Network and Machine Learning</b>
<a href="https://arxiv.org/abs/2204.12415">arxiv:2204.12415</a>
&#x1F4C8; 2 <br>
<p>Cecilia Occhiuzzi, Francesca Camera, Michele D'Orazio, Nicola D'Uva, Sara Amendola, Giulio Maria Bianco, Carolina Miozzi, Luigi Garavaglia, Eugenio Martinelli, Gaetano Marrocco</p></summary>
<p>

**Abstract:** Accelerated ripening through the exposure of fruits to controlled environmental conditions and gases is nowadays one of the most assessed food technologies, especially for climacteric and exotic products. However, a fine granularity control of the process and consequently of the quality of the goods is still missing, so the management of the ripening rooms is mainly based on qualitative estimations only. Following the modern paradigms of Industry 4.0, this contribution proposes a non-destructive RFID-based system for the automatic evaluation of the live ripening of avocados. The system, coupled with a properly trained automatic classification algorithm based on Support Vector Machines (SVMs), can discriminate the stage of ripening with an accuracy greater than 85%.

</p>
</details>

<details><summary><b>Knowledge Transfer in Engineering Fleets: Hierarchical Bayesian Modelling for Multi-Task Learning</b>
<a href="https://arxiv.org/abs/2204.12404">arxiv:2204.12404</a>
&#x1F4C8; 2 <br>
<p>L. A. Bull, M. Dhada, O. Steinert, T. Lindgren, A. K. Parlikad, A. B. Duncan, M. Girolami</p></summary>
<p>

**Abstract:** We propose a population-level analysis to address issues of data sparsity when building predictive models of engineering infrastructure. By sharing information between similar assets, hierarchical Bayesian modelling is used to improve the survival analysis of a truck fleet (hazard curves) and power prediction in a wind farm (power curves). In each example, a set of correlated functions are learnt over the asset fleet, in a combined inference, to learn a population model. Parameter estimation is improved when sub-fleets of assets are allowed to share correlated information at different levels in the hierarchy. In turn, groups with incomplete data automatically borrow statistical strength from those that are data-rich. The correlations can be inspected to inform which assets share information for which effect (i.e. parameter).

</p>
</details>

<details><summary><b>Social learning spontaneously emerges by searching optimal heuristics with deep reinforcement learning</b>
<a href="https://arxiv.org/abs/2204.12371">arxiv:2204.12371</a>
&#x1F4C8; 2 <br>
<p>Seungwoong Ha, Hawoong Jeong</p></summary>
<p>

**Abstract:** How have individuals of social animals in nature evolved to learn from each other, and what would be the optimal strategy for such learning in a specific environment? Here, we address both problems by employing a deep reinforcement learning model to optimize the social learning strategies (SLSs) of agents in a cooperative game in a multi-dimensional landscape. Throughout the training for maximizing the overall payoff, we find that the agent spontaneously learns various concepts of social learning, such as copying, focusing on frequent and well-performing neighbors, self-comparison, and the importance of balancing between individual and social learning, without any explicit guidance or prior knowledge about the system. The SLS from a fully trained agent outperforms all of the traditional, baseline SLSs in terms of mean payoff. We demonstrate the superior performance of the reinforcement learning agent in various environments, including temporally changing environments and real social networks, which also verifies the adaptability of our framework to different social settings.

</p>
</details>

<details><summary><b>Graph Neural Networks for Microbial Genome Recovery</b>
<a href="https://arxiv.org/abs/2204.12270">arxiv:2204.12270</a>
&#x1F4C8; 2 <br>
<p>Andre Lamurias, Alessandro Tibo, Katja Hose, Mads Albertsen, Thomas Dyhre Nielsen</p></summary>
<p>

**Abstract:** Microbes have a profound impact on our health and environment, but our understanding of the diversity and function of microbial communities is severely limited. Through DNA sequencing of microbial communities (metagenomics), DNA fragments (reads) of the individual microbes can be obtained, which through assembly graphs can be combined into long contiguous DNA sequences (contigs). Given the complexity of microbial communities, single contig microbial genomes are rarely obtained. Instead, contigs are eventually clustered into bins, with each bin ideally making up a full genome. This process is referred to as metagenomic binning.
  Current state-of-the-art techniques for metagenomic binning rely only on the local features for the individual contigs. These techniques therefore fail to exploit the similarities between contigs as encoded by the assembly graph, in which the contigs are organized. In this paper, we propose to use Graph Neural Networks (GNNs) to leverage the assembly graph when learning contig representations for metagenomic binning. Our method, VaeG-Bin, combines variational autoencoders for learning latent representations of the individual contigs, with GNNs for refining these representations by taking into account the neighborhood structure of the contigs in the assembly graph. We explore several types of GNNs and demonstrate that VaeG-Bin recovers more high-quality genomes than other state-of-the-art binners on both simulated and real-world datasets.

</p>
</details>

<details><summary><b>IRC-safe Graph Autoencoder for an unsupervised anomaly detection</b>
<a href="https://arxiv.org/abs/2204.12231">arxiv:2204.12231</a>
&#x1F4C8; 2 <br>
<p>Oliver Atkinson, Akanksha Bhardwaj, Christoph Englert, Partha Konar, Vishal S. Ngairangbam, Michael Spannowsky</p></summary>
<p>

**Abstract:** Anomaly detection through employing machine learning techniques has emerged as a novel powerful tool in the search for new physics beyond the Standard Model. Historically similar to the development of jet observables, theoretical consistency has not always assumed a central role in the fast development of algorithms and neural network architectures. In this work, we construct an infrared and collinear safe autoencoder based on graph neural networks by employing energy-weighted message passing. We demonstrate that whilst this approach has theoretically favourable properties, it also exhibits formidable sensitivity to non-QCD structures.

</p>
</details>

<details><summary><b>Collaborative Target Search with a Visual Drone Swarm: An Adaptive Curriculum Embedded Multi-stage Reinforcement Learning Approach</b>
<a href="https://arxiv.org/abs/2204.12181">arxiv:2204.12181</a>
&#x1F4C8; 2 <br>
<p>Jiaping Xiao, Phumrapee Pisutsin, Mir Feroskhan</p></summary>
<p>

**Abstract:** Equipping drones with target search capabilities is desirable for applications in disaster management scenarios and smart warehouse delivery systems. Instead of deploying a single drone, an intelligent drone swarm that can collaborate with one another in maneuvering among obstacles will be more effective in accomplishing the target search in a shorter amount of time. In this work, we propose a data-efficient reinforcement learning-based approach, Adaptive Curriculum Embedded Multi-Stage Learning (ACEMSL), to address the challenges of carrying out a collaborative target search with a visual drone swarm, namely the 3D sparse reward space exploration and the collaborative behavior requirement. Specifically, we develop an adaptive embedded curriculum, where the task difficulty level can be adaptively adjusted according to the success rate achieved in training. Meanwhile, with multi-stage learning, ACEMSL allows data-efficient training and individual-team reward allocation for the collaborative drone swarm. The effectiveness and generalization capability of our approach are validated using simulations and actual flight tests.

</p>
</details>

<details><summary><b>GypSum: Learning Hybrid Representations for Code Summarization</b>
<a href="https://arxiv.org/abs/2204.12916">arxiv:2204.12916</a>
&#x1F4C8; 1 <br>
<p>Yu Wang, Yu Dong, Xuesong Lu, Aoying Zhou</p></summary>
<p>

**Abstract:** Code summarization with deep learning has been widely studied in recent years. Current deep learning models for code summarization generally follow the principle in neural machine translation and adopt the encoder-decoder framework, where the encoder learns the semantic representations from source code and the decoder transforms the learnt representations into human-readable text that describes the functionality of code snippets. Despite they achieve the new state-of-the-art performance, we notice that current models often either generate less fluent summaries, or fail to capture the core functionality, since they usually focus on a single type of code representations. As such we propose GypSum, a new deep learning model that learns hybrid representations using graph attention neural networks and a pre-trained programming and natural language model. We introduce particular edges related to the control flow of a code snippet into the abstract syntax tree for graph construction, and design two encoders to learn from the graph and the token sequence of source code, respectively. We modify the encoder-decoder sublayer in the Transformer's decoder to fuse the representations and propose a dual-copy mechanism to facilitate summary generation. Experimental results demonstrate the superior performance of GypSum over existing code summarization models.

</p>
</details>

<details><summary><b>Investigating the Emergence of Online Learning in Different Countries using the 5 W's and 1 H Approach</b>
<a href="https://arxiv.org/abs/2204.12650">arxiv:2204.12650</a>
&#x1F4C8; 1 <br>
<p>Nirmalya Thakur, Isabella Hall, Chia Y. Han</p></summary>
<p>

**Abstract:** The rise of the Internet of Everything lifestyle in the last decade has had a significant impact on the increased emergence and adoption of online learning in almost all countries across the world. E-learning 3.0 is expected to become the norm of learning globally in almost all sectors in the next few years. The pervasiveness of the Semantic Web powered by the Internet of Everything lifestyle is expected to play a huge role towards seamless and faster adoption of the emerging paradigms of E-learning 3.0. Therefore, this paper presents an exploratory study to analyze multimodal components of Semantic Web behavior data to investigate the emergence of online learning in different countries across the world. The work specifically involved investigating relevant web behavior data to interpret the 5 W's and 1 H - Who, What, When Where, Why, and How related to online learning. Based on studying the E-learning Index of 2021, the study was performed for all the countries that are member states of the Organization for Economic Cooperation and Development. The results presented and discussed help to interpret the emergence of online learning in each of these countries in terms of the associated public perceptions, queries, opinions, behaviors, and perspectives. Furthermore, to support research and development in this field, we have published the web behavior-based Big Data related to online learning that was mined for all these 38 countries, in the form of a dataset, which is avail-able at https://dx.doi.org/10.21227/xbvs-0198.

</p>
</details>

<details><summary><b>An Empirical Study of the Occurrence of Heavy-Tails in Training a ReLU Gate</b>
<a href="https://arxiv.org/abs/2204.12554">arxiv:2204.12554</a>
&#x1F4C8; 1 <br>
<p>Sayar Karmakar, Anirbit Mukherjee</p></summary>
<p>

**Abstract:** A particular direction of recent advance about stochastic deep-learning algorithms has been about uncovering a rather mysterious heavy-tailed nature of the stationary distribution of these algorithms, even when the data distribution is not so. Moreover, the heavy-tail index is known to show interesting dependence on the input dimension of the net, the mini-batch size and the step size of the algorithm. In this short note, we undertake an experimental study of this index for S.G.D. while training a $\relu$ gate (in the realizable and in the binary classification setup) and for a variant of S.G.D. that was proven in Karmakar and Mukherjee (2022) for ReLU realizable data. From our experiments we conjecture that these two algorithms have similar heavy-tail behaviour on any data where the latter can be proven to converge. Secondly, we demonstrate that the heavy-tail index of the late time iterates in this model scenario has strikingly different properties than either what has been proven for linear hypothesis classes or what has been previously demonstrated for large nets.

</p>
</details>

<details><summary><b>Double Diffusion Maps and their Latent Harmonics for Scientific Computations in Latent Space</b>
<a href="https://arxiv.org/abs/2204.12536">arxiv:2204.12536</a>
&#x1F4C8; 1 <br>
<p>Nikolaos Evangelou, Felix Dietrich, Eliodoro Chiavazzo, Daniel Lehmberg, Marina Meila, Ioannis G. Kevrekidis</p></summary>
<p>

**Abstract:** We introduce a data-driven approach to building reduced dynamical models through manifold learning; the reduced latent space is discovered using Diffusion Maps (a manifold learning technique) on time series data. A second round of Diffusion Maps on those latent coordinates allows the approximation of the reduced dynamical models. This second round enables mapping the latent space coordinates back to the full ambient space (what is called lifting); it also enables the approximation of full state functions of interest in terms of the reduced coordinates. In our work, we develop and test three different reduced numerical simulation methodologies, either through pre-tabulation in the latent space and integration on the fly or by going back and forth between the ambient space and the latent space. The data-driven latent space simulation results, based on the three different approaches, are validated through (a) the latent space observation of the full simulation through the Nyström Extension formula, or through (b) lifting the reduced trajectory back to the full ambient space, via Latent Harmonics. Latent space modeling often involves additional regularization to favor certain properties of the space over others, and the mapping back to the ambient space is then constructed mostly independently from these properties; here, we use the same data-driven approach to construct the latent space and then map back to the ambient space.

</p>
</details>

<details><summary><b>AccMPEG: Optimizing Video Encoding for Video Analytics</b>
<a href="https://arxiv.org/abs/2204.12534">arxiv:2204.12534</a>
&#x1F4C8; 1 <br>
<p>Kuntai Du, Qizheng Zhang, Anton Arapin, Haodong Wang, Zhengxu Xia, Junchen Jiang</p></summary>
<p>

**Abstract:** With more videos being recorded by edge sensors (cameras) and analyzed by computer-vision deep neural nets (DNNs), a new breed of video streaming systems has emerged, with the goal to compress and stream videos to remote servers in real time while preserving enough information to allow highly accurate inference by the server-side DNNs. An ideal design of the video streaming system should simultaneously meet three key requirements: (1) low latency of encoding and streaming, (2) high accuracy of server-side DNNs, and (3) low compute overheads on the camera. Unfortunately, despite many recent efforts, such video streaming system has hitherto been elusive, especially when serving advanced vision tasks such as object detection or semantic segmentation. This paper presents AccMPEG, a new video encoding and streaming system that meets all the three requirements. The key is to learn how much the encoding quality at each (16x16) macroblock can influence the server-side DNN accuracy, which we call accuracy gradient. Our insight is that these macroblock-level accuracy gradient can be inferred with sufficient precision by feeding the video frames through a cheap model. AccMPEG provides a suite of techniques that, given a new server-side DNN, can quickly create a cheap model to infer the accuracy gradient on any new frame in near realtime. Our extensive evaluation of AccMPEG on two types of edge devices (one Intel Xeon Silver 4100 CPU or NVIDIA Jetson Nano) and three vision tasks (six recent pre-trained DNNs) shows that AccMPEG (with the same camera-side compute resources) can reduce the end-to-end inference delay by 10-43% without hurting accuracy compared to the state-of-the-art baselines

</p>
</details>

<details><summary><b>Identification of feasible pathway information for c-di-GMP binding proteins in cellulose production</b>
<a href="https://arxiv.org/abs/2204.12526">arxiv:2204.12526</a>
&#x1F4C8; 1 <br>
<p>Syeda Sakira Hassan, Rahul Mangayil, Tommi Aho, Olli Yli-Harja, Matti Karp</p></summary>
<p>

**Abstract:** In this paper, we utilize a machine learning approach to identify the significant pathways for c-di-GMP signaling proteins. The dataset involves gene counts from 12 pathways and 5 essential c-di-GMP binding domains for 1024 bacterial genomes. Two novel approaches, Least absolute shrinkage and selection operator (Lasso) and Random forests, have been applied for analyzing and modeling the dataset. Both approaches show that bacterial chemotaxis is the most essential pathway for c-di-GMP encoding domains. Though popular for feature selection, the strong regularization of Lasso method fails to associate any pathway to MshE domain. Results from the analysis may help to understand and emphasize the supporting pathways involved in bacterial cellulose production. These findings demonstrate the need for a chassis to restrict the behavior or functionality by deactivating the selective pathways in cellulose production.

</p>
</details>

<details><summary><b>Interpretable Battery Cycle Life Range Prediction Using Early Degradation Data at Cell Level</b>
<a href="https://arxiv.org/abs/2204.12420">arxiv:2204.12420</a>
&#x1F4C8; 1 <br>
<p>Huang Zhang, Yang Su, Faisal Altaf, Torsten Wik, Sebastien Gros</p></summary>
<p>

**Abstract:** Battery cycle life prediction using early degradation data has many potential applications throughout the battery product life cycle. Various data-driven methods have been proposed for point prediction of battery cycle life with minimum knowledge of the battery degradation mechanisms. However, management of batteries at end-of-life with lower economic and technical risk requires prediction of cycle life with quantified uncertainty, which is still lacking. The interpretability (i.e., the reason for high prediction accuracy) of these advanced data-driven methods is also worthy of investigation. Here, a physics-informed Quantile Regression Forest (QRF) model is introduced to make cycle life range prediction with uncertainty quantified as the length of the prediction interval, in addition to point predictions with high accuracy. The hyperparameters of the QRF model are tuned with a proposed area-based performance evaluation metric so that the coverage probabilities associated with the prediction intervals are calibrated. The interpretability of the final QRF model is explored with two global model-agnostic methods, namely permutation importance, and partial dependence plot. The final QRF model facilitates dual-criteria decision-making to select the high-cycle-life charging protocol with consideration of both point predictions and uncertainty associated with the prediction.

</p>
</details>

<details><summary><b>Mixed Strategies for Security Games with General Defending Requirements</b>
<a href="https://arxiv.org/abs/2204.12158">arxiv:2204.12158</a>
&#x1F4C8; 1 <br>
<p>Rufan Bai, Haoxing Lin, Xinyu Yang, Xiaowei Wu, Minming Li, Weijia Jia</p></summary>
<p>

**Abstract:** The Stackelberg security game is played between a defender and an attacker, where the defender needs to allocate a limited amount of resources to multiple targets in order to minimize the loss due to adversarial attack by the attacker. While allowing targets to have different values, classic settings often assume uniform requirements to defend the targets. This enables existing results that study mixed strategies (randomized allocation algorithms) to adopt a compact representation of the mixed strategies.
  In this work, we initiate the study of mixed strategies for the security games in which the targets can have different defending requirements. In contrast to the case of uniform defending requirement, for which an optimal mixed strategy can be computed efficiently, we show that computing the optimal mixed strategy is NP-hard for the general defending requirements setting. However, we show that strong upper and lower bounds for the optimal mixed strategy defending result can be derived. We propose an efficient close-to-optimal Patching algorithm that computes mixed strategies that use only few pure strategies. We also study the setting when the game is played on a network and resource sharing is enabled between neighboring targets. Our experimental results demonstrate the effectiveness of our algorithm in several large real-world datasets.

</p>
</details>

<details><summary><b>Self-scalable Tanh (Stan): Faster Convergence and Better Generalization in Physics-informed Neural Networks</b>
<a href="https://arxiv.org/abs/2204.12589">arxiv:2204.12589</a>
&#x1F4C8; 0 <br>
<p>Raghav Gnanasambandam, Bo Shen, Jihoon Chung, Xubo Yue,  Zhenyu,  Kong</p></summary>
<p>

**Abstract:** Physics-informed Neural Networks (PINNs) are gaining attention in the engineering and scientific literature for solving a range of differential equations with applications in weather modeling, healthcare, manufacturing, etc. Poor scalability is one of the barriers to utilizing PINNs for many real-world problems. To address this, a Self-scalable tanh (Stan) activation function is proposed for the PINNs. The proposed Stan function is smooth, non-saturating, and has a trainable parameter. During training, it can allow easy flow of gradients to compute the required derivatives and also enable systematic scaling of the input-output mapping. It is shown theoretically that the PINNs with the proposed Stan function have no spurious stationary points when using gradient descent algorithms. The proposed Stan is tested on a number of numerical studies involving general regression problems. It is subsequently used for solving multiple forward problems, which involve second-order derivatives and multiple dimensions, and an inverse problem where the thermal diffusivity of a rod is predicted with heat conduction data. These case studies establish empirically that the Stan activation function can achieve better training and more accurate predictions than the existing activation functions in the literature.

</p>
</details>

<details><summary><b>Meta-free few-shot learning via representation learning with weight averaging</b>
<a href="https://arxiv.org/abs/2204.12466">arxiv:2204.12466</a>
&#x1F4C8; 0 <br>
<p>Kuilin Chen, Chi-Guhn Lee</p></summary>
<p>

**Abstract:** Recent studies on few-shot classification using transfer learning pose challenges to the effectiveness and efficiency of episodic meta-learning algorithms. Transfer learning approaches are a natural alternative, but they are restricted to few-shot classification. Moreover, little attention has been on the development of probabilistic models with well-calibrated uncertainty from few-shot samples, except for some Bayesian episodic learning algorithms. To tackle the aforementioned issues, we propose a new transfer learning method to obtain accurate and reliable models for few-shot regression and classification. The resulting method does not require episodic meta-learning and is called meta-free representation learning (MFRL). MFRL first finds low-rank representation generalizing well on meta-test tasks. Given the learned representation, probabilistic linear models are fine-tuned with few-shot samples to obtain models with well-calibrated uncertainty. The proposed method not only achieves the highest accuracy on a wide range of few-shot learning benchmark datasets but also correctly quantifies the prediction uncertainty. In addition, weight averaging and temperature scaling are effective in improving the accuracy and reliability of few-shot learning in existing meta-learning algorithms with a wide range of learning paradigms and model architectures.

</p>
</details>


{% endraw %}
Prev: [2022.04.25]({{ '/2022/04/25/2022.04.25.html' | relative_url }})  Next: [2022.04.27]({{ '/2022/04/27/2022.04.27.html' | relative_url }})