Prev: [2022.08.09]({{ '/2022/08/09/2022.08.09.html' | relative_url }})  Next: [2022.08.11]({{ '/2022/08/11/2022.08.11.html' | relative_url }})
{% raw %}
## Summary for 2022-08-10, created on 2022-08-20


<details><summary><b>High-Frequency Space Diffusion Models for Accelerated MRI</b>
<a href="https://arxiv.org/abs/2208.05481">arxiv:2208.05481</a>
&#x1F4C8; 135 <br>
<p>Chentao Cao, Zhuo-Xu Cui, Shaonan Liu, Dong Liang, Yanjie Zhu</p></summary>
<p>

**Abstract:** Denoising diffusion probabilistic models (DDPMs) have been shown to have superior performances in MRI reconstruction. From the perspective of continuous stochastic differential equations (SDEs), the reverse process of DDPM can be seen as maximizing the energy of the reconstructed MR image, leading to SDE sequence divergence. For this reason, a modified high-frequency DDPM model is proposed for MRI reconstruction. From its continuous SDE viewpoint, termed high-frequency space SDE (HFS-SDE), the energy concentrated low-frequency part of the MR image is no longer amplified, and the diffusion process focuses more on acquiring high-frequency prior information. It not only improves the stability of the diffusion model but also provides the possibility of better recovery of high-frequency details. Experiments on the publicly fastMRI dataset show that our proposed HFS-SDE outperforms the DDPM-driven VP-SDE, supervised deep learning methods and traditional parallel imaging methods in terms of stability and reconstruction accuracy.

</p>
</details>

<details><summary><b>Trustworthy Recommender Systems</b>
<a href="https://arxiv.org/abs/2208.06265">arxiv:2208.06265</a>
&#x1F4C8; 107 <br>
<p>Shoujin Wang, Xiuzhen Zhang, Yan Wang, Huan Liu, Francesco Ricci</p></summary>
<p>

**Abstract:** Recommender systems (RSs) aim to help users to effectively retrieve items of their interests from a large catalogue. For a quite long period of time, researchers and practitioners have been focusing on developing accurate RSs. Recent years have witnessed an increasing number of threats to RSs, coming from attacks, system and user generated noise, system bias. As a result, it has become clear that a strict focus on RS accuracy is limited and the research must consider other important factors, e.g., trustworthiness. For end users, a trustworthy RS (TRS) should not only be accurate, but also transparent, unbiased and fair as well as robust to noise or attacks. These observations actually led to a paradigm shift of the research on RSs: from accuracy-oriented RSs to TRSs. However, researchers lack a systematic overview and discussion of the literature in this novel and fast developing field of TRSs. To this end, in this paper, we provide an overview of TRSs, including a discussion of the motivation and basic concepts of TRSs, a presentation of the challenges in building TRSs, and a perspective on the future directions in this area. We also provide a novel conceptual framework to support the construction of TRSs.

</p>
</details>

<details><summary><b>The Moral Foundations Reddit Corpus</b>
<a href="https://arxiv.org/abs/2208.05545">arxiv:2208.05545</a>
&#x1F4C8; 97 <br>
<p>Jackson Trager, Alireza S. Ziabari, Aida Mostafazadeh Davani, Preni Golazizian, Farzan Karimi-Malekabadi, Ali Omrani, Zhihe Li, Brendan Kennedy, Nils Karl Reimer, Melissa Reyes, Kelsey Cheng, Mellow Wei, Christina Merrifield, Arta Khosravi, Evans Alvarez, Morteza Dehghani</p></summary>
<p>

**Abstract:** Moral framing and sentiment can affect a variety of online and offline behaviors, including donation, pro-environmental action, political engagement, and even participation in violent protests. Various computational methods in Natural Language Processing (NLP) have been used to detect moral sentiment from textual data, but in order to achieve better performances in such subjective tasks, large sets of hand-annotated training data are needed. Previous corpora annotated for moral sentiment have proven valuable, and have generated new insights both within NLP and across the social sciences, but have been limited to Twitter. To facilitate improving our understanding of the role of moral rhetoric, we present the Moral Foundations Reddit Corpus, a collection of 16,123 Reddit comments that have been curated from 12 distinct subreddits, hand-annotated by at least three trained annotators for 8 categories of moral sentiment (i.e., Care, Proportionality, Equality, Purity, Authority, Loyalty, Thin Morality, Implicit/Explicit Morality) based on the updated Moral Foundations Theory (MFT) framework. We use a range of methodologies to provide baseline moral-sentiment classification results for this new corpus, e.g., cross-domain classification and knowledge transfer.

</p>
</details>

<details><summary><b>Quality Not Quantity: On the Interaction between Dataset Design and Robustness of CLIP</b>
<a href="https://arxiv.org/abs/2208.05516">arxiv:2208.05516</a>
&#x1F4C8; 26 <br>
<p>Thao Nguyen, Gabriel Ilharco, Mitchell Wortsman, Sewoong Oh, Ludwig Schmidt</p></summary>
<p>

**Abstract:** Web-crawled datasets have enabled remarkable generalization capabilities in recent image-text models such as CLIP (Contrastive Language-Image pre-training) or Flamingo, but little is known about the dataset creation processes. In this work, we introduce a testbed of six publicly available data sources - YFCC, LAION, Conceptual Captions, WIT, RedCaps, Shutterstock - to investigate how pre-training distributions induce robustness in CLIP. We find that the performance of the pre-training data varies substantially across distribution shifts, with no single data source dominating. Moreover, we systematically study the interactions between these data sources and find that combining multiple sources does not necessarily yield better models, but rather dilutes the robustness of the best individual data source. We complement our empirical findings with theoretical insights from a simple setting, where combining the training data also results in diluted robustness. In addition, our theoretical model provides a candidate explanation for the success of the CLIP-based data filtering technique recently employed in the LAION dataset. Overall our results demonstrate that simply gathering a large amount of data from the web is not the most effective way to build a pre-training dataset for robust generalization, necessitating further study into dataset design.

</p>
</details>

<details><summary><b>Patching open-vocabulary models by interpolating weights</b>
<a href="https://arxiv.org/abs/2208.05592">arxiv:2208.05592</a>
&#x1F4C8; 25 <br>
<p>Gabriel Ilharco, Mitchell Wortsman, Samir Yitzhak Gadre, Shuran Song, Hannaneh Hajishirzi, Simon Kornblith, Ali Farhadi, Ludwig Schmidt</p></summary>
<p>

**Abstract:** Open-vocabulary models like CLIP achieve high accuracy across many image classification tasks. However, there are still settings where their zero-shot performance is far from optimal. We study model patching, where the goal is to improve accuracy on specific tasks without degrading accuracy on tasks where performance is already adequate. Towards this goal, we introduce PAINT, a patching method that uses interpolations between the weights of a model before fine-tuning and the weights after fine-tuning on a task to be patched. On nine tasks where zero-shot CLIP performs poorly, PAINT increases accuracy by 15 to 60 percentage points while preserving accuracy on ImageNet within one percentage point of the zero-shot model. PAINT also allows a single model to be patched on multiple tasks and improves with model scale. Furthermore, we identify cases of broad transfer, where patching on one task increases accuracy on other tasks even when the tasks have disjoint classes. Finally, we investigate applications beyond common benchmarks such as counting or reducing the impact of typographic attacks on CLIP. Our findings demonstrate that it is possible to expand the set of tasks on which open-vocabulary models achieve high accuracy without re-training them from scratch.

</p>
</details>

<details><summary><b>Visual Haptic Reasoning: Estimating Contact Forces by Observing Deformable Object Interactions</b>
<a href="https://arxiv.org/abs/2208.05632">arxiv:2208.05632</a>
&#x1F4C8; 23 <br>
<p>Yufei Wang, David Held, Zackory Erickson</p></summary>
<p>

**Abstract:** Robotic manipulation of highly deformable cloth presents a promising opportunity to assist people with several daily tasks, such as washing dishes; folding laundry; or dressing, bathing, and hygiene assistance for individuals with severe motor impairments. In this work, we introduce a formulation that enables a collaborative robot to perform visual haptic reasoning with cloth -- the act of inferring the location and magnitude of applied forces during physical interaction. We present two distinct model representations, trained in physics simulation, that enable haptic reasoning using only visual and robot kinematic observations. We conducted quantitative evaluations of these models in simulation for robot-assisted dressing, bathing, and dish washing tasks, and demonstrate that the trained models can generalize across different tasks with varying interactions, human body sizes, and object shapes. We also present results with a real-world mobile manipulator, which used our simulation-trained models to estimate applied contact forces while performing physically assistive tasks with cloth. Videos can be found at our project webpage.

</p>
</details>

<details><summary><b>Learning Two-Player Mixture Markov Games: Kernel Function Approximation and Correlated Equilibrium</b>
<a href="https://arxiv.org/abs/2208.05363">arxiv:2208.05363</a>
&#x1F4C8; 11 <br>
<p>Chris Junchi Li, Dongruo Zhou, Quanquan Gu, Michael I. Jordan</p></summary>
<p>

**Abstract:** We consider learning Nash equilibria in two-player zero-sum Markov Games with nonlinear function approximation, where the action-value function is approximated by a function in a Reproducing Kernel Hilbert Space (RKHS). The key challenge is how to do exploration in the high-dimensional function space. We propose a novel online learning algorithm to find a Nash equilibrium by minimizing the duality gap. At the core of our algorithms are upper and lower confidence bounds that are derived based on the principle of optimism in the face of uncertainty. We prove that our algorithm is able to attain an $O(\sqrt{T})$ regret with polynomial computational complexity, under very mild assumptions on the reward function and the underlying dynamic of the Markov Games. We also propose several extensions of our algorithm, including an algorithm with Bernstein-type bonus that can achieve a tighter regret bound, and another algorithm for model misspecification that can be applied to neural function approximation.

</p>
</details>

<details><summary><b>Quantized Adaptive Subgradient Algorithms and Their Applications</b>
<a href="https://arxiv.org/abs/2208.05631">arxiv:2208.05631</a>
&#x1F4C8; 10 <br>
<p>Ke Xu, Jianqiao Wangni, Yifan Zhang, Deheng Ye, Jiaxiang Wu, Peilin Zhao</p></summary>
<p>

**Abstract:** Data explosion and an increase in model size drive the remarkable advances in large-scale machine learning, but also make model training time-consuming and model storage difficult. To address the above issues in the distributed model training setting which has high computation efficiency and less device limitation, there are still two main difficulties. On one hand, the communication costs for exchanging information, e.g., stochastic gradients among different workers, is a key bottleneck for distributed training efficiency. On the other hand, less parameter model is easy for storage and communication, but the risk of damaging the model performance. To balance the communication costs, model capacity and model performance simultaneously, we propose quantized composite mirror descent adaptive subgradient (QCMD adagrad) and quantized regularized dual average adaptive subgradient (QRDA adagrad) for distributed training. To be specific, we explore the combination of gradient quantization and sparse model to reduce the communication cost per iteration in distributed training. A quantized gradient-based adaptive learning rate matrix is constructed to achieve a balance between communication costs, accuracy, and model sparsity. Moreover, we theoretically find that a large quantization error brings in extra noise, which influences the convergence and sparsity of the model. Therefore, a threshold quantization strategy with a relatively small error is adopted in QCMD adagrad and QRDA adagrad to improve the signal-to-noise ratio and preserve the sparsity of the model. Both theoretical analyses and empirical results demonstrate the efficacy and efficiency of the proposed algorithms.

</p>
</details>

<details><summary><b>FIGO: Enhanced Fingerprint Identification Approach Using GAN and One Shot Learning Techniques</b>
<a href="https://arxiv.org/abs/2208.05615">arxiv:2208.05615</a>
&#x1F4C8; 10 <br>
<p>Ibrahim Yilmaz</p></summary>
<p>

**Abstract:** Fingerprint evidence plays an important role in a criminal investigation for the identification of individuals. Although various techniques have been proposed for fingerprint classification and feature extraction, automated fingerprint identification of fingerprints is still in its earliest stage. The performance of traditional \textit{Automatic Fingerprint Identification System} (AFIS) depends on the presence of valid minutiae points and still requires human expert assistance in feature extraction and identification stages. Based on this motivation, we propose a Fingerprint Identification approach based on Generative adversarial network and One-shot learning techniques (FIGO). Our solution contains two components: fingerprint enhancement tier and fingerprint identification tier. First, we propose a Pix2Pix model to transform low-quality fingerprint images to a higher level of fingerprint images pixel by pixel directly in the fingerprint enhancement tier. With the proposed enhancement algorithm, the fingerprint identification model's performance is significantly improved. Furthermore, we develop another existing solution based on Gabor filters as a benchmark to compare with the proposed model by observing the fingerprint device's recognition accuracy. Experimental results show that our proposed Pix2pix model has better support than the baseline approach for fingerprint identification. Second, we construct a fully automated fingerprint feature extraction model using a one-shot learning approach to differentiate each fingerprint from the others in the fingerprint identification process. Two twin convolutional neural networks (CNNs) with shared weights and parameters are used to obtain the feature vectors in this process. Using the proposed method, we demonstrate that it is possible to learn necessary information from only one training sample with high accuracy.

</p>
</details>

<details><summary><b>Memorizing Complementation Network for Few-Shot Class-Incremental Learning</b>
<a href="https://arxiv.org/abs/2208.05610">arxiv:2208.05610</a>
&#x1F4C8; 10 <br>
<p>Zhong Ji, Zhishen Hou, Xiyao Liu, Yanwei Pang, Xuelong Li</p></summary>
<p>

**Abstract:** Few-shot Class-Incremental Learning (FSCIL) aims at learning new concepts continually with only a few samples, which is prone to suffer the catastrophic forgetting and overfitting problems. The inaccessibility of old classes and the scarcity of the novel samples make it formidable to realize the trade-off between retaining old knowledge and learning novel concepts. Inspired by that different models memorize different knowledge when learning novel concepts, we propose a Memorizing Complementation Network (MCNet) to ensemble multiple models that complements the different memorized knowledge with each other in novel tasks. Additionally, to update the model with few novel samples, we develop a Prototype Smoothing Hard-mining Triplet (PSHT) loss to push the novel samples away from not only each other in current task but also the old distribution. Extensive experiments on three benchmark datasets, e.g., CIFAR100, miniImageNet and CUB200, have demonstrated the superiority of our proposed method.

</p>
</details>

<details><summary><b>Non-Contrastive Self-supervised Learning for Utterance-Level Information Extraction from Speech</b>
<a href="https://arxiv.org/abs/2208.05445">arxiv:2208.05445</a>
&#x1F4C8; 10 <br>
<p>Jaejin Cho, Jes'us Villalba, Laureano Moro-Velazquez, Najim Dehak</p></summary>
<p>

**Abstract:** In recent studies, self-supervised pre-trained models tend to outperform supervised pre-trained models in transfer learning. In particular, self-supervised learning (SSL) of utterance-level speech representation can be used in speech applications that require discriminative representation of consistent attributes within an utterance: speaker, language, emotion, and age. Existing frame-level self-supervised speech representation, e.g., wav2vec, can be used as utterance-level representation with pooling, but the models are usually large. There are also SSL techniques to learn utterance-level representation. One of the most successful is a contrastive method, which requires negative sampling: selecting alternative samples to contrast with the current sample (anchor). However, this does not ensure that all the negative samples belong to classes different from the anchor class without labels. This paper applies a non-contrastive self-supervised method to learn utterance-level embeddings. We adapted DIstillation with NO labels (DINO) from computer vision to speech. Unlike contrastive methods, DINO does not require negative sampling. We compared DINO to x-vector trained in a supervised manner. When transferred to down-stream tasks (speaker verification, speech emotion recognition (SER), and Alzheimer's disease detection), DINO outperformed x-vector. We studied the influence of several aspects during transfer learning such as dividing the fine-tuning process into steps, chunk lengths, or augmentation. During fine-tuning, tuning the last affine layers first and then the whole network surpassed fine-tuning all at once. Using shorter chunk lengths, although they generate more diverse inputs, did not necessarily improve performance, implying speech segments at least with a specific length are required for better performance per application. Augmentation was helpful in SER.

</p>
</details>

<details><summary><b>Convergence of denoising diffusion models under the manifold hypothesis</b>
<a href="https://arxiv.org/abs/2208.05314">arxiv:2208.05314</a>
&#x1F4C8; 10 <br>
<p>Valentin De Bortoli</p></summary>
<p>

**Abstract:** Denoising diffusion models are a recent class of generative models exhibiting state-of-the-art performance in image and audio synthesis. Such models approximate the time-reversal of a forward noising process from a target distribution to a reference density, which is usually Gaussian. Despite their strong empirical results, the theoretical analysis of such models remains limited. In particular, all current approaches crucially assume that the target density admits a density w.r.t. the Lebesgue measure. This does not cover settings where the target distribution is supported on a lower-dimensional manifold or is given by some empirical distribution. In this paper, we bridge this gap by providing the first convergence results for diffusion models in this more general setting. In particular, we provide quantitative bounds on the Wasserstein distance of order one between the target data distribution and the generative distribution of the diffusion model.

</p>
</details>

<details><summary><b>Comparison and Analysis of New Curriculum Criteria for End-to-End ASR</b>
<a href="https://arxiv.org/abs/2208.05782">arxiv:2208.05782</a>
&#x1F4C8; 9 <br>
<p>Georgios Karakasidis, Tamás Grósz, Mikko Kurimo</p></summary>
<p>

**Abstract:** It is common knowledge that the quantity and quality of the training data play a significant role in the creation of a good machine learning model. In this paper, we take it one step further and demonstrate that the way the training examples are arranged is also of crucial importance. Curriculum Learning is built on the observation that organized and structured assimilation of knowledge has the ability to enable faster training and better comprehension. When humans learn to speak, they first try to utter basic phones and then gradually move towards more complex structures such as words and sentences. This methodology is known as Curriculum Learning, and we employ it in the context of Automatic Speech Recognition. We hypothesize that end-to-end models can achieve better performance when provided with an organized training set consisting of examples that exhibit an increasing level of difficulty (i.e. a curriculum). To impose structure on the training set and to define the notion of an easy example, we explored multiple scoring functions that either use feedback from an external neural network or incorporate feedback from the model itself. Empirical results show that with different curriculums we can balance the training times and the network's performance.

</p>
</details>

<details><summary><b>The emergence of division of labor through decentralized social sanctioning</b>
<a href="https://arxiv.org/abs/2208.05568">arxiv:2208.05568</a>
&#x1F4C8; 9 <br>
<p>Anil Yaman, Joel Z. Leibo, Giovanni Iacca, Sang Wan Lee</p></summary>
<p>

**Abstract:** Human ecological success relies on our characteristic ability to flexibly self-organize in cooperative social groups. Successful groups employ substantial specialization and division of labor. Unlike most other animals, humans learn by trial and error during their lives what role to take on. However, when some critical roles are more attractive than others, and individuals are self-interested, then there is a social dilemma: each individual would prefer others take on the critical-but-unremunerative roles so they may remain free to take one that pays better. But disaster occurs if all act thusly and a critical role goes unfilled. In such situations learning an optimum role distribution may not be possible. Consequently, a fundamental question is: how can division of labor emerge in groups of self-interested lifetime-learning individuals? Here we show that by introducing a model of social norms, which we regard as patterns of decentralized social sanctioning, it becomes possible for groups of self-interested individuals to learn a productive division of labor involving all critical roles. Such social norms work by redistributing rewards within the population to disincentivize antisocial roles while incentivizing prosocial roles that do not intrinsically pay as well as others.

</p>
</details>

<details><summary><b>CLEVR-Math: A Dataset for Compositional Language, Visual and Mathematical Reasoning</b>
<a href="https://arxiv.org/abs/2208.05358">arxiv:2208.05358</a>
&#x1F4C8; 9 <br>
<p>Adam Dahlgren Lindström, Savitha Sam Abraham</p></summary>
<p>

**Abstract:** We introduce CLEVR-Math, a multi-modal math word problems dataset consisting of simple math word problems involving addition/subtraction, represented partly by a textual description and partly by an image illustrating the scenario. The text describes actions performed on the scene that is depicted in the image. Since the question posed may not be about the scene in the image, but about the state of the scene before or after the actions are applied, the solver envision or imagine the state changes due to these actions. Solving these word problems requires a combination of language, visual and mathematical reasoning. We apply state-of-the-art neural and neuro-symbolic models for visual question answering on CLEVR-Math and empirically evaluate their performances. Our results show how neither method generalise to chains of operations. We discuss the limitations of the two in addressing the task of multi-modal word problem solving.

</p>
</details>

<details><summary><b>EvolveHypergraph: Group-Aware Dynamic Relational Reasoning for Trajectory Prediction</b>
<a href="https://arxiv.org/abs/2208.05470">arxiv:2208.05470</a>
&#x1F4C8; 8 <br>
<p>Jiachen Li, Chuanbo Hua, Jinkyoo Park, Hengbo Ma, Victoria Dax, Mykel J. Kochenderfer</p></summary>
<p>

**Abstract:** While the modeling of pair-wise relations has been widely studied in multi-agent interacting systems, its ability to capture higher-level and larger-scale group-wise activities is limited. In this paper, we propose a group-aware relational reasoning approach (named EvolveHypergraph) with explicit inference of the underlying dynamically evolving relational structures, and we demonstrate its effectiveness for multi-agent trajectory prediction. In addition to the edges between a pair of nodes (i.e., agents), we propose to infer hyperedges that adaptively connect multiple nodes to enable group-aware relational reasoning in an unsupervised manner without fixing the number of hyperedges. The proposed approach infers the dynamically evolving relation graphs and hypergraphs over time to capture the evolution of relations, which are used by the trajectory predictor to obtain future states. Moreover, we propose to regularize the smoothness of the relation evolution and the sparsity of the inferred graphs or hypergraphs, which effectively improves training stability and enhances the explainability of inferred relations. The proposed approach is validated on both synthetic crowd simulations and multiple real-world benchmark datasets. Our approach infers explainable, reasonable group-aware relations and achieves state-of-the-art performance in long-term prediction.

</p>
</details>

<details><summary><b>Looking for a Needle in a Haystack: A Comprehensive Study of Hallucinations in Neural Machine Translation</b>
<a href="https://arxiv.org/abs/2208.05309">arxiv:2208.05309</a>
&#x1F4C8; 8 <br>
<p>Nuno M. Guerreiro, Elena Voita, André F. T. Martins</p></summary>
<p>

**Abstract:** Although the problem of hallucinations in neural machine translation (NMT) has received some attention, research on this highly pathological phenomenon lacks solid ground. Previous work has been limited in several ways: it often resorts to artificial settings where the problem is amplified, it disregards some (common) types of hallucinations, and it does not validate adequacy of detection heuristics. In this paper, we set foundations for the study of NMT hallucinations. First, we work in a natural setting, i.e., in-domain data without artificial noise neither in training nor in inference. Next, we annotate a dataset of over 3.4k sentences indicating different kinds of critical errors and hallucinations. Then, we turn to detection methods and both revisit methods used previously and propose using glass-box uncertainty-based detectors. Overall, we show that for preventive settings, (i) previously used methods are largely inadequate, (ii) sequence log-probability works best and performs on par with reference-based methods. Finally, we propose DeHallucinator, a simple method for alleviating hallucinations at test time that significantly reduces the hallucinatory rate. To ease future research, we release our annotated dataset for WMT18 German-English data, along with the model, training data, and code.

</p>
</details>

<details><summary><b>KiPA22 Report: U-Net with Contour Regularization for Renal Structures Segmentation</b>
<a href="https://arxiv.org/abs/2208.05772">arxiv:2208.05772</a>
&#x1F4C8; 7 <br>
<p>Kangqing Ye, Peng Liu, Qin Zhou, Guoyan Zheng</p></summary>
<p>

**Abstract:** Three-dimensional (3D) integrated renal structures (IRS) segmentation is important in clinical practice. With the advancement of deep learning techniques, many powerful frameworks focusing on medical image segmentation are proposed. In this challenge, we utilized the nnU-Net framework, which is the state-of-the-art method for medical image segmentation. To reduce the outlier prediction for the tumor label, we combine contour regularization (CR) loss of the tumor label with Dice loss and cross-entropy loss to improve this phenomenon.

</p>
</details>

<details><summary><b>OpenMedIA: Open-Source Medical Image Analysis Toolbox and Benchmark under Heterogeneous AI Computing Platforms</b>
<a href="https://arxiv.org/abs/2208.05616">arxiv:2208.05616</a>
&#x1F4C8; 7 <br>
<p>Jia-Xin Zhuang, Xiansong Huang, Yang Yang, Jiancong Chen, Yue Yu, Wei Gao, Ge Li, Jie Chen, Tong Zhang</p></summary>
<p>

**Abstract:** In this paper, we present OpenMedIA, an open-source toolbox library containing a rich set of deep learning methods for medical image analysis under heterogeneous Artificial Intelligence (AI) computing platforms. Various medical image analysis methods, including 2D$/$3D medical image classification, segmentation, localisation, and detection, have been included in the toolbox with PyTorch and$/$or MindSpore implementations under heterogeneous NVIDIA and Huawei Ascend computing systems. To our best knowledge, OpenMedIA is the first open-source algorithm library providing compared PyTorch and MindSp

</p>
</details>

<details><summary><b>CoditT5: Pretraining for Source Code and Natural Language Editing</b>
<a href="https://arxiv.org/abs/2208.05446">arxiv:2208.05446</a>
&#x1F4C8; 7 <br>
<p>Jiyang Zhang, Sheena Panthaplackel, Pengyu Nie, Junyi Jessy Li, Milos Gligoric</p></summary>
<p>

**Abstract:** Pretrained language models have been shown to be effective in many software-related generation tasks; however, they are not well-suited for editing tasks as they are not designed to reason about edits. To address this, we propose a novel pretraining objective which explicitly models edits and use it to build CoditT5, a large language model for software-related editing tasks that is pretrained on large amounts of source code and natural language comments. We fine-tune it on various downstream editing tasks, including comment updating, bug fixing, and automated code review. By outperforming pure generation-based models, we demonstrate the generalizability of our approach and its suitability for editing tasks. We also show how a pure generation model and our edit-based model can complement one another through simple reranking strategies, with which we achieve state-of-the-art performance for the three downstream editing tasks.

</p>
</details>

<details><summary><b>Diversifying Design of Nucleic Acid Aptamers Using Unsupervised Machine Learning</b>
<a href="https://arxiv.org/abs/2208.05341">arxiv:2208.05341</a>
&#x1F4C8; 7 <br>
<p>Siba Moussa, Michael Kilgour, Clara Jans, Alex Hernandez-Garcia, Miroslava Cuperlovic-Culf, Yoshua Bengio, Lena Simine</p></summary>
<p>

**Abstract:** Inverse design of short single-stranded RNA and DNA sequences (aptamers) is the task of finding sequences that satisfy a set of desired criteria. Relevant criteria may be, for example, the presence of specific folding motifs, binding to molecular ligands, sensing properties, etc. Most practical approaches to aptamer design identify a small set of promising candidate sequences using high-throughput experiments (e.g. SELEX), and then optimize performance by introducing only minor modifications to the empirically found candidates. Sequences that possess the desired properties but differ drastically in chemical composition will add diversity to the search space and facilitate the discovery of useful nucleic acid aptamers. Systematic diversification protocols are needed. Here we propose to use an unsupervised machine learning model known as the Potts model to discover new, useful sequences with controllable sequence diversity. We start by training a Potts model using the maximum entropy principle on a small set of empirically identified sequences unified by a common feature. To generate new candidate sequences with a controllable degree of diversity, we take advantage of the model's spectral feature: an energy bandgap separating sequences that are similar to the training set from those that are distinct. By controlling the Potts energy range that is sampled, we generate sequences that are distinct from the training set yet still likely to have the encoded features. To demonstrate performance, we apply our approach to design diverse pools of sequences with specified secondary structure motifs in 30-mer RNA and DNA aptamers.

</p>
</details>

<details><summary><b>Language Supervised Training for Skeleton-based Action Recognition</b>
<a href="https://arxiv.org/abs/2208.05318">arxiv:2208.05318</a>
&#x1F4C8; 7 <br>
<p>Wangmeng Xiang, Chao Li, Yuxuan Zhou, Biao Wang, Lei Zhang</p></summary>
<p>

**Abstract:** Skeleton-based action recognition has drawn a lot of attention for its computation efficiency and robustness to lighting conditions. Existing skeleton-based action recognition methods are typically formulated as a one-hot classification task without fully utilizing the semantic relations between actions. For example, "make victory sign" and "thumb up" are two actions of hand gestures, whose major difference lies in the movement of hands. This information is agnostic from the categorical one-hot encoding of action classes but could be unveiled in the language description of actions. Therefore, utilizing action language descriptions in training could potentially benefit representation learning. In this work, we propose a Language Supervised Training (LST) approach for skeleton-based action recognition. More specifically, we employ a large-scale language model as the knowledge engine to provide text descriptions for body parts movements of actions, and propose a multi-modal training scheme by utilizing the text encoder to generate feature vectors for different body parts and supervise the skeleton encoder for action representation learning. Experiments show that our proposed LST method achieves noticeable improvements over various baseline models without extra computation cost at inference. LST achieves new state-of-the-arts on popular skeleton-based action recognition benchmarks, including NTU RGB+D, NTU RGB+D 120 and NW-UCLA. The code can be found at https://github.com/MartinXM/LST.

</p>
</details>

<details><summary><b>Explaining Machine Learning DGA Detectors from DNS Traffic Data</b>
<a href="https://arxiv.org/abs/2208.05285">arxiv:2208.05285</a>
&#x1F4C8; 7 <br>
<p>Giorgio Piras, Maura Pintor, Luca Demetrio, Battista Biggio</p></summary>
<p>

**Abstract:** One of the most common causes of lack of continuity of online systems stems from a widely popular Cyber Attack known as Distributed Denial of Service (DDoS), in which a network of infected devices (botnet) gets exploited to flood the computational capacity of services through the commands of an attacker. This attack is made by leveraging the Domain Name System (DNS) technology through Domain Generation Algorithms (DGAs), a stealthy connection strategy that yet leaves suspicious data patterns. To detect such threats, advances in their analysis have been made. For the majority, they found Machine Learning (ML) as a solution, which can be highly effective in analyzing and classifying massive amounts of data. Although strongly performing, ML models have a certain degree of obscurity in their decision-making process. To cope with this problem, a branch of ML known as Explainable ML tries to break down the black-box nature of classifiers and make them interpretable and human-readable. This work addresses the problem of Explainable ML in the context of botnet and DGA detection, which at the best of our knowledge, is the first to concretely break down the decisions of ML classifiers when devised for botnet/DGA detection, therefore providing global and local explanations.

</p>
</details>

<details><summary><b>Trustworthy Visual Analytics in Clinical Gait Analysis: A Case Study for Patients with Cerebral Palsy</b>
<a href="https://arxiv.org/abs/2208.05232">arxiv:2208.05232</a>
&#x1F4C8; 7 <br>
<p>Alexander Rind, Djordje Slijepčević, Matthias Zeppelzauer, Fabian Unglaube, Andreas Kranzl, Brian Horsak</p></summary>
<p>

**Abstract:** Three-dimensional clinical gait analysis is essential for selecting optimal treatment interventions for patients with cerebral palsy (CP), but generates a large amount of time series data. For the automated analysis of these data, machine learning approaches yield promising results. However, due to their black-box nature, such approaches are often mistrusted by clinicians. We propose gaitXplorer, a visual analytics approach for the classification of CP-related gait patterns that integrates Grad-CAM, a well-established explainable artificial intelligence algorithm, for explanations of machine learning classifications. Regions of high relevance for classification are highlighted in the interactive visual interface. The approach is evaluated in a case study with two clinical gait experts. They inspected the explanations for a sample of eight patients using the visual interface and expressed which relevance scores they found trustworthy and which they found suspicious. Overall, the clinicians gave positive feedback on the approach as it allowed them a better understanding of which regions in the data were relevant for the classification.

</p>
</details>

<details><summary><b>An Empirical Exploration of Cross-domain Alignment between Language and Electroencephalogram</b>
<a href="https://arxiv.org/abs/2208.06348">arxiv:2208.06348</a>
&#x1F4C8; 6 <br>
<p>William Han, Jielin Qiu, Jiacheng Zhu, Mengdi Xu, Douglas Weber, Bo Li, Ding Zhao</p></summary>
<p>

**Abstract:** Electroencephalography (EEG) and language have been widely explored independently for many downstream tasks (e.g., sentiment analysis, relation detection, etc.). Multimodal approaches that study both domains have not been well explored, even though in recent years, multimodal learning has been seen to be more powerful than its unimodal counterparts. In this study, we want to explore the relationship and dependency between EEG and language, i.e., how one domain reflects and represents the other. To study the relationship at the representation level, we introduced MTAM, a Multimodal Transformer Alignment Model, to observe coordinated representations between the two modalities, and thus employ the transformed representations for downstream applications. We used various relationship alignment-seeking techniques, such as Canonical Correlation Analysis and Wasserstein Distance, as loss functions to transfigure low-level language and EEG features to high-level transformed features. On downstream applications, sentiment analysis, and relation detection, we achieved new state-of-the-art results on two datasets, ZuCo and K-EmoCon. Our method achieved an F1-score improvement of 16.5% on sentiment analysis for K-EmoCon, 26.6% on sentiment analysis of ZuCo, and 31.1% on relation detection of ZuCo. In addition, we provide interpretation of the performance improvement by: (1) visualizing the original feature distribution and the transformed feature distribution, showing the effectiveness of the alignment module for discovering and encoding the relationship between EEG and language; (2) visualizing word-level and sentence-level EEG-language alignment weights, showing the influence of different language semantics as well as EEG frequency features; and (3) visualizing brain topographical maps to provide an intuitive demonstration of the connectivity of EEG and language response in the brain regions.

</p>
</details>

<details><summary><b>Path-aware Siamese Graph Neural Network for Link Prediction</b>
<a href="https://arxiv.org/abs/2208.05781">arxiv:2208.05781</a>
&#x1F4C8; 6 <br>
<p>Jingsong Lv, Zhao Li, Hongyang Chen, Yao Qi, Chunqi Wu</p></summary>
<p>

**Abstract:** In this paper, we propose an algorithm of Path-aware Siamese Graph neural network(PSG) for link prediction tasks. Firstly, PSG can capture both nodes and edge features for given two nodes, namely the structure information of k-neighborhoods and relay paths information of the nodes. Furthermore, siamese graph neural network is utilized by PSG for representation learning of two contrastive links, which are a positive link and a negative link. We evaluate the proposed algorithm PSG on a link property prediction dataset of Open Graph Benchmark (OGB), ogbl-ddi. PSG achieves top 1 performance on ogbl-ddi. The experimental results verify the superiority of PSG.

</p>
</details>

<details><summary><b>Best Policy Identification in Linear MDPs</b>
<a href="https://arxiv.org/abs/2208.05633">arxiv:2208.05633</a>
&#x1F4C8; 6 <br>
<p>Jerome Taupin, Yassir Jedra, Alexandre Proutiere</p></summary>
<p>

**Abstract:** We investigate the problem of best policy identification in discounted linear Markov Decision Processes in the fixed confidence setting under a generative model. We first derive an instance-specific lower bound on the expected number of samples required to identify an $\varepsilon$-optimal policy with probability $1-δ$. The lower bound characterizes the optimal sampling rule as the solution of an intricate non-convex optimization program, but can be used as the starting point to devise simple and near-optimal sampling rules and algorithms. We devise such algorithms. One of these exhibits a sample complexity upper bounded by ${\cal O}({\frac{d}{(\varepsilon+Δ)^2}} (\log(\frac{1}δ)+d))$ where $Δ$ denotes the minimum reward gap of sub-optimal actions and $d$ is the dimension of the feature space. This upper bound holds in the moderate-confidence regime (i.e., for all $δ$), and matches existing minimax and gap-dependent lower bounds. We extend our algorithm to episodic linear MDPs.

</p>
</details>

<details><summary><b>Imbalance Trouble: Revisiting Neural-Collapse Geometry</b>
<a href="https://arxiv.org/abs/2208.05512">arxiv:2208.05512</a>
&#x1F4C8; 6 <br>
<p>Christos Thrampoulidis, Ganesh R. Kini, Vala Vakilian, Tina Behnia</p></summary>
<p>

**Abstract:** Neural Collapse refers to the remarkable structural properties characterizing the geometry of class embeddings and classifier weights, found by deep nets when trained beyond zero training error. However, this characterization only holds for balanced data. Here we thus ask whether it can be made invariant to class imbalances. Towards this end, we adopt the unconstrained-features model (UFM), a recent theoretical model for studying neural collapse, and introduce Simplex-Encoded-Labels Interpolation (SELI) as an invariant characterization of the neural collapse phenomenon. Specifically, we prove for the UFM with cross-entropy loss and vanishing regularization that, irrespective of class imbalances, the embeddings and classifiers always interpolate a simplex-encoded label matrix and that their individual geometries are determined by the SVD factors of this same label matrix. We then present extensive experiments on synthetic and real datasets that confirm convergence to the SELI geometry. However, we caution that convergence worsens with increasing imbalances. We theoretically support this finding by showing that unlike the balanced case, when minorities are present, ridge-regularization plays a critical role in tweaking the geometry. This defines new questions and motivates further investigations into the impact of class imbalances on the rates at which first-order methods converge to their asymptotically preferred solutions.

</p>
</details>

<details><summary><b>Fairness Based Energy-Efficient 3D Path Planning of a Portable Access Point: A Deep Reinforcement Learning Approach</b>
<a href="https://arxiv.org/abs/2208.05265">arxiv:2208.05265</a>
&#x1F4C8; 6 <br>
<p>Nithin Babu, Igor Donevski, Alvaro Valcarce, Petar Popovski, Jimmy Jessen Nielsen, Constantinos B. Papadias</p></summary>
<p>

**Abstract:** In this work, we optimize the 3D trajectory of an unmanned aerial vehicle (UAV)-based portable access point (PAP) that provides wireless services to a set of ground nodes (GNs). Moreover, as per the Peukert effect, we consider pragmatic non-linear battery discharge for the battery of the UAV. Thus, we formulate the problem in a novel manner that represents the maximization of a fairness-based energy efficiency metric and is named fair energy efficiency (FEE). The FEE metric defines a system that lays importance on both the per-user service fairness and the energy efficiency of the PAP. The formulated problem takes the form of a non-convex problem with non-tractable constraints. To obtain a solution, we represent the problem as a Markov Decision Process (MDP) with continuous state and action spaces. Considering the complexity of the solution space, we use the twin delayed deep deterministic policy gradient (TD3) actor-critic deep reinforcement learning (DRL) framework to learn a policy that maximizes the FEE of the system. We perform two types of RL training to exhibit the effectiveness of our approach: the first (offline) approach keeps the positions of the GNs the same throughout the training phase; the second approach generalizes the learned policy to any arrangement of GNs by changing the positions of GNs after each training episode. Numerical evaluations show that neglecting the Peukert effect overestimates the air-time of the PAP and can be addressed by optimally selecting the PAP's flying speed. Moreover, the user fairness, energy efficiency, and hence the FEE value of the system can be improved by efficiently moving the PAP above the GNs. As such, we notice massive FEE improvements over baseline scenarios of up to 88.31%, 272.34%, and 318.13% for suburban, urban, and dense urban environments, respectively.

</p>
</details>

<details><summary><b>What's on your mind? A Mental and Perceptual Load Estimation Framework towards Adaptive In-vehicle Interaction while Driving</b>
<a href="https://arxiv.org/abs/2208.05564">arxiv:2208.05564</a>
&#x1F4C8; 5 <br>
<p>Amr Gomaa, Alexandra Alles, Elena Meiser, Lydia Helene Rupp, Marco Molz, Guillermo Reyes</p></summary>
<p>

**Abstract:** Several researchers have focused on studying driver cognitive behavior and mental load for in-vehicle interaction while driving. Adaptive interfaces that vary with mental and perceptual load levels could help in reducing accidents and enhancing the driver experience. In this paper, we analyze the effects of mental workload and perceptual load on psychophysiological dimensions and provide a machine learning-based framework for mental and perceptual load estimation in a dual task scenario for in-vehicle interaction (https://github.com/amrgomaaelhady/MWL-PL-estimator). We use off-the-shelf non-intrusive sensors that can be easily integrated into the vehicle's system. Our statistical analysis shows that while mental workload influences some psychophysiological dimensions, perceptual load shows little effect. Furthermore, we classify the mental and perceptual load levels through the fusion of these measurements, moving towards a real-time adaptive in-vehicle interface that is personalized to user behavior and driving conditions. We report up to 89% mental workload classification accuracy and provide a real-time minimally-intrusive solution.

</p>
</details>

<details><summary><b>Generative Transfer Learning: Covid-19 Classification with a few Chest X-ray Images</b>
<a href="https://arxiv.org/abs/2208.05305">arxiv:2208.05305</a>
&#x1F4C8; 5 <br>
<p>Suvarna Kadam, Vinay G. Vaidya</p></summary>
<p>

**Abstract:** Detection of diseases through medical imaging is preferred due to its non-invasive nature. Medical imaging supports multiple modalities of data that enable a thorough and quick look inside a human body. However, interpreting imaging data is often time-consuming and requires a great deal of human expertise. Deep learning models can expedite interpretation and alleviate the work of human experts. However, these models are data-intensive and require significant labeled images for training. During novel disease outbreaks such as Covid-19, we often do not have the required labeled imaging data, especially at the start of the epidemic. Deep Transfer Learning addresses this problem by using a pretrained model in the public domain, e.g. any variant of either VGGNet, ResNet, Inception, DenseNet, etc., as a feature learner to quickly adapt the target task from fewer samples. Most pretrained models are deep with complex architectures. They are trained with large multi-class datasets such as ImageNet, with significant human efforts in architecture design and hyper parameters tuning. We presented 1 a simpler generative source model, pretrained on a single but related concept, can perform as effectively as existing larger pretrained models. We demonstrate the usefulness of generative transfer learning that requires less compute and training data, for Few Shot Learning (FSL) with a Covid-19 binary classification use case. We compare classic deep transfer learning with our approach and also report FSL results with three settings of 84, 20, and 10 training samples. The model implementation of generative FSL for Covid-19 classification is available publicly at https://github.com/suvarnak/GenerativeFSLCovid.git.

</p>
</details>

<details><summary><b>Auto-ViT-Acc: An FPGA-Aware Automatic Acceleration Framework for Vision Transformer with Mixed-Scheme Quantization</b>
<a href="https://arxiv.org/abs/2208.05163">arxiv:2208.05163</a>
&#x1F4C8; 5 <br>
<p>Zhengang Li, Mengshu Sun, Alec Lu, Haoyu Ma, Geng Yuan, Yanyue Xie, Hao Tang, Yanyu Li, Miriam Leeser, Zhangyang Wang, Xue Lin, Zhenman Fang</p></summary>
<p>

**Abstract:** Vision transformers (ViTs) are emerging with significantly improved accuracy in computer vision tasks. However, their complex architecture and enormous computation/storage demand impose urgent needs for new hardware accelerator design methodology. This work proposes an FPGA-aware automatic ViT acceleration framework based on the proposed mixed-scheme quantization. To the best of our knowledge, this is the first FPGA-based ViT acceleration framework exploring model quantization. Compared with state-of-the-art ViT quantization work (algorithmic approach only without hardware acceleration), our quantization achieves 0.47% to 1.36% higher Top-1 accuracy under the same bit-width. Compared with the 32-bit floating-point baseline FPGA accelerator, our accelerator achieves around 5.6x improvement on the frame rate (i.e., 56.8 FPS vs. 10.0 FPS) with 0.71% accuracy drop on ImageNet dataset for DeiT-base.

</p>
</details>

<details><summary><b>A Scalable Probabilistic Model for Reward Optimizing Slate Recommendation</b>
<a href="https://arxiv.org/abs/2208.06263">arxiv:2208.06263</a>
&#x1F4C8; 4 <br>
<p>Imad Aouali, Achraf Ait Sidi Hammou, Sergey Ivanov, Otmane Sakhi, David Rohde, Flavian Vasile</p></summary>
<p>

**Abstract:** We introduce Probabilistic Rank and Reward model (PRR), a scalable probabilistic model for personalized slate recommendation. Our model allows state-of-the-art estimation of user interests in the following ubiquitous recommender system scenario: A user is shown a slate of K recommendations and the user chooses at most one of these K items. It is the goal of the recommender system to find the K items of most interest to a user in order to maximize the probability that the user interacts with the slate. Our contribution is to show that we can learn more effectively the probability of the recommendations being successful by combining the reward - whether the slate was clicked or not - and the rank - the item on the slate that was selected. Our method learns more efficiently than bandit methods that use only the reward, and user preference methods that use only the rank. It also provides similar or better estimation performance to independent inverse-propensity-score methods and is far more scalable. Our method is state of the art in terms of both speed and accuracy on massive datasets with up to 1 million items. Finally, our method allows fast delivery of recommendations powered by maximum inner product search (MIPS), making it suitable in extremely low latency domains such as computational advertising.

</p>
</details>

<details><summary><b>Evaluating Generatively Synthesized Diabetic Retinopathy Imagery</b>
<a href="https://arxiv.org/abs/2208.05593">arxiv:2208.05593</a>
&#x1F4C8; 4 <br>
<p>Cristina-Madalina Dragan, Ruairi O'Reilly</p></summary>
<p>

**Abstract:** Publicly available data for the training of diabetic retinopathy classifiers is unbalanced. Generative adversarial networks can successfully synthesize retinal fundus imagery. In order for synthetic imagery to be of benefit, images need to be of high quality and diverse. Presently, several evaluation metrics are used to evaluate the quality and diversity of imagery synthesized from generative adversarial networks. This work contributes, the first of its kind, empirical assessment for the suitability of evaluation metrics used in the literature for the evaluation of generative adversarial networks for generating retinal fundus images in the context of diabetic retinopathy. Frechet Inception Distance, Peak Signal-to-Noise Ratio and Cosine Distance's capacity to assess the quality and diversity of synthetic proliferative diabetic retionpathy imagery is investigated. A quantitative analysis is performed to enable an improved methodology for selecting the synthetic imagery to be used for augmenting a classifier's training dataset. Results indicate that Frechet Inception Distance is suitable for evaluating the diversity of synthetic imagery, and for identifying if the imagery has features corresponding to its class label. Peak Signal-to-Noise Ratio is suitable for indicating if the synthetic imagery has valid diabetic retinopathy lesions and if its features correspond to its class label. These results demonstrate the importance of performing such empirical evaluation, especially in the context of biomedical domains where utilisation in applied setting is intended.

</p>
</details>

<details><summary><b>SSDBCODI: Semi-Supervised Density-Based Clustering with Outliers Detection Integrated</b>
<a href="https://arxiv.org/abs/2208.05561">arxiv:2208.05561</a>
&#x1F4C8; 4 <br>
<p>Jiahao Deng, Eli T. Brown</p></summary>
<p>

**Abstract:** Clustering analysis is one of the critical tasks in machine learning. Traditionally, clustering has been an independent task, separate from outlier detection. Due to the fact that the performance of clustering can be significantly eroded by outliers, a small number of algorithms try to incorporate outlier detection in the process of clustering. However, most of those algorithms are based on unsupervised partition-based algorithms such as k-means. Given the nature of those algorithms, they often fail to deal with clusters of complex, non-convex shapes. To tackle this challenge, we have proposed SSDBCODI, a semi-supervised density-based algorithm. SSDBCODI combines the advantage of density-based algorithms, which are capable of dealing with clusters of complex shapes, with the semi-supervised element, which offers flexibility to adjust the clustering results based on a few user labels. We also merge an outlier detection component with the clustering process. Potential outliers are detected based on three scores generated during the process: (1) reachability-score, which measures how density-reachable a point is to a labeled normal object, (2) local-density-score, which measures the neighboring density of data objects, and (3) similarity-score, which measures the closeness of a point to its nearest labeled outliers. Then in the following step, instance weights are generated for each data instance based on those three scores before being used to train a classifier for further clustering and outlier detection. To enhance the understanding of the proposed algorithm, for our evaluation, we have run our proposed algorithm against some of the state-of-art approaches on multiple datasets and separately listed the results of outlier detection apart from clustering. Our results indicate that our algorithm can achieve superior results with a small percentage of labels.

</p>
</details>

<details><summary><b>Towards Automating Retinoscopy for Refractive Error Diagnosis</b>
<a href="https://arxiv.org/abs/2208.05552">arxiv:2208.05552</a>
&#x1F4C8; 4 <br>
<p>Aditya Aggarwal, Siddhartha Gairola, Uddeshya Upadhyay, Akshay P Vasishta, Diwakar Rao, Aditya Goyal, Kaushik Murali, Nipun Kwatra, Mohit Jain</p></summary>
<p>

**Abstract:** Refractive error is the most common eye disorder and is the key cause behind correctable visual impairment, responsible for nearly 80% of the visual impairment in the US. Refractive error can be diagnosed using multiple methods, including subjective refraction, retinoscopy, and autorefractors. Although subjective refraction is the gold standard, it requires cooperation from the patient and hence is not suitable for infants, young children, and developmentally delayed adults. Retinoscopy is an objective refraction method that does not require any input from the patient. However, retinoscopy requires a lens kit and a trained examiner, which limits its use for mass screening. In this work, we automate retinoscopy by attaching a smartphone to a retinoscope and recording retinoscopic videos with the patient wearing a custom pair of paper frames. We develop a video processing pipeline that takes retinoscopic videos as input and estimates the net refractive error based on our proposed extension of the retinoscopy mathematical model. Our system alleviates the need for a lens kit and can be performed by an untrained examiner. In a clinical trial with 185 eyes, we achieved a sensitivity of 91.0% and specificity of 74.0% on refractive error diagnosis. Moreover, the mean absolute error of our approach was 0.75$\pm$0.67D on net refractive error estimation compared to subjective refraction measurements. Our results indicate that our approach has the potential to be used as a retinoscopy-based refractive error screening tool in real-world medical settings.

</p>
</details>

<details><summary><b>Semi-supervised segmentation of tooth from 3D Scanned Dental Arches</b>
<a href="https://arxiv.org/abs/2208.05539">arxiv:2208.05539</a>
&#x1F4C8; 4 <br>
<p>Ammar Alsheghri, Farnoosh Ghadiri, Ying Zhang, Olivier Lessard, Julia Keren, Farida Cheriet, Francois Guibault</p></summary>
<p>

**Abstract:** Teeth segmentation is an important topic in dental restorations that is essential for crown generation, diagnosis, and treatment planning. In the dental field, the variability of input data is high and there are no publicly available 3D dental arch datasets. Although there has been improvement in the field provided by recent deep learning architectures on 3D data, there still exists some problems such as properly identifying missing teeth in an arch. We propose to use spectral clustering as a self-supervisory signal to joint-train neural networks for segmentation of 3D arches. Our approach is motivated by the observation that K-means clustering provides cues to capture margin lines related to human perception. The main idea is to automatically generate training data by decomposing unlabeled 3D arches into segments relying solely on geometric information. The network is then trained using a joint loss that combines a supervised loss of annotated input and a self-supervised loss of non-labeled input. Our collected data has a variety of arches including arches with missing teeth. Our experimental results show improvement over the fully supervised state-of-the-art MeshSegNet when using semi-supervised learning. Finally, we contribute code and a dataset.

</p>
</details>

<details><summary><b>Differentiable Inference of Temporal Logic Formulas</b>
<a href="https://arxiv.org/abs/2208.05440">arxiv:2208.05440</a>
&#x1F4C8; 4 <br>
<p>Nicole Fronda, Houssam Abbas</p></summary>
<p>

**Abstract:** We demonstrate the first Recurrent Neural Network architecture for learning Signal Temporal Logic formulas, and present the first systematic comparison of formula inference methods. Legacy systems embed much expert knowledge which is not explicitly formalized. There is great interest in learning formal specifications that characterize the ideal behavior of such systems -- that is, formulas in temporal logic that are satisfied by the system's output signals. Such specifications can be used to better understand the system's behavior and improve design of its next iteration. Previous inference methods either assumed certain formula templates, or did a heuristic enumeration of all possible templates. This work proposes a neural network architecture that infers the formula structure via gradient descent, eliminating the need for imposing any specific templates. It combines learning of formula structure and parameters in one optimization. Through systematic comparison, we demonstrate that this method achieves similar or better mis-classification rates (MCR) than enumerative and lattice methods. We also observe that different formulas can achieve similar MCR, empirically demonstrating the under-determinism of the problem of temporal logic inference.

</p>
</details>

<details><summary><b>Towards Autonomous Atlas-based Ultrasound Acquisitions in Presence of Articulated Motion</b>
<a href="https://arxiv.org/abs/2208.05399">arxiv:2208.05399</a>
&#x1F4C8; 4 <br>
<p>Zhongliang Jiang, Yuan Gao, Le Xie, Nassir Navab</p></summary>
<p>

**Abstract:** Robotic ultrasound (US) imaging aims at overcoming some of the limitations of free-hand US examinations, e.g. difficulty in guaranteeing intra- and inter-operator repeatability. However, due to anatomical and physiological variations between patients and relative movement of anatomical substructures, it is challenging to robustly generate optimal trajectories to examine the anatomies of interest, in particular, when they comprise articulated joints. To address this challenge, this paper proposes a vision-based approach allowing autonomous robotic US limb scanning. To this end, an atlas MRI template of a human arm with annotated vascular structures is used to generate trajectories and register and project them onto patients' skin surfaces for robotic US acquisition. To effectively segment and accurately reconstruct the targeted 3D vessel, we make use of spatial continuity in consecutive US frames by incorporating channel attention modules into a U-Net-type neural network. The automatic trajectory generation method is evaluated on six volunteers with various articulated joint angles. In all cases, the system can successfully acquire the planned vascular structure on volunteers' limbs. For one volunteer the MRI scan was also available, which allows the evaluation of the average radius of the scanned artery from US images, resulting in a radius estimation ($1.2\pm0.05~mm$) comparable to the MRI ground truth ($1.2\pm0.04~mm$).

</p>
</details>

<details><summary><b>Exploring Anchor-based Detection for Ego4D Natural Language Query</b>
<a href="https://arxiv.org/abs/2208.05375">arxiv:2208.05375</a>
&#x1F4C8; 4 <br>
<p>Sipeng Zheng, Qi Zhang, Bei Liu, Qin Jin, Jianlong Fu</p></summary>
<p>

**Abstract:** In this paper we provide the technique report of Ego4D natural language query challenge in CVPR 2022. Natural language query task is challenging due to the requirement of comprehensive understanding of video contents. Most previous works address this task based on third-person view datasets while few research interest has been placed in the ego-centric view by far. Great progress has been made though, we notice that previous works can not adapt well to ego-centric view datasets e.g., Ego4D mainly because of two reasons: 1) most queries in Ego4D have a excessively small temporal duration (e.g., less than 5 seconds); 2) queries in Ego4D are faced with much more complex video understanding of long-term temporal orders. Considering these, we propose our solution of this challenge to solve the above issues.

</p>
</details>

<details><summary><b>E Pluribus Unum Interpretable Convolutional Neural Networks</b>
<a href="https://arxiv.org/abs/2208.05369">arxiv:2208.05369</a>
&#x1F4C8; 4 <br>
<p>George Dimas, Eirini Cholopoulou, Dimitris K. Iakovidis</p></summary>
<p>

**Abstract:** The adoption of Convolutional Neural Network (CNN) models in high-stake domains is hindered by their inability to meet society's demand for transparency in decision-making. So far, a growing number of methodologies have emerged for developing CNN models that are interpretable by design. However, such models are not capable of providing interpretations in accordance with human perception, while maintaining competent performance. In this paper, we tackle these challenges with a novel, general framework for instantiating inherently interpretable CNN models, named E Pluribus Unum Interpretable CNN (EPU-CNN). An EPU-CNN model consists of CNN sub-networks, each of which receives a different representation of an input image expressing a perceptual feature, such as color or texture. The output of an EPU-CNN model consists of the classification prediction and its interpretation, in terms of relative contributions of perceptual features in different regions of the input image. EPU-CNN models have been extensively evaluated on various publicly available datasets, as well as a contributed benchmark dataset. Medical datasets are used to demonstrate the applicability of EPU-CNN for risk-sensitive decisions in medicine. The experimental results indicate that EPU-CNN models can achieve a comparable or better classification performance than other CNN architectures while providing humanly perceivable interpretations.

</p>
</details>

<details><summary><b>Efficient Joint-Dimensional Search with Solution Space Regularization for Real-Time Semantic Segmentation</b>
<a href="https://arxiv.org/abs/2208.05271">arxiv:2208.05271</a>
&#x1F4C8; 4 <br>
<p>Peng Ye, Baopu Li, Tao Chen, Jiayuan Fan, Zhen Mei, Chen Lin, Chongyan Zuo, Qinghua Chi, Wanli Ouyan</p></summary>
<p>

**Abstract:** Semantic segmentation is a popular research topic in computer vision, and many efforts have been made on it with impressive results. In this paper, we intend to search an optimal network structure that can run in real-time for this problem. Towards this goal, we jointly search the depth, channel, dilation rate and feature spatial resolution, which results in a search space consisting of about 2.78*10^324 possible choices. To handle such a large search space, we leverage differential architecture search methods. However, the architecture parameters searched using existing differential methods need to be discretized, which causes the discretization gap between the architecture parameters found by the differential methods and their discretized version as the final solution for the architecture search. Hence, we relieve the problem of discretization gap from the innovative perspective of solution space regularization. Specifically, a novel Solution Space Regularization (SSR) loss is first proposed to effectively encourage the supernet to converge to its discrete one. Then, a new Hierarchical and Progressive Solution Space Shrinking method is presented to further achieve high efficiency of searching. In addition, we theoretically show that the optimization of SSR loss is equivalent to the L_0-norm regularization, which accounts for the improved search-evaluation gap. Comprehensive experiments show that the proposed search scheme can efficiently find an optimal network structure that yields an extremely fast speed (175 FPS) of segmentation with a small model size (1 M) while maintaining comparable accuracy.

</p>
</details>

<details><summary><b>A Novel Resource Allocation for Anti-jamming in Cognitive-UAVs: an Active Inference Approach</b>
<a href="https://arxiv.org/abs/2208.05269">arxiv:2208.05269</a>
&#x1F4C8; 4 <br>
<p>Ali Krayani, Atm S. Alam, Lucio Marcenaro, Arumugam Nallanathan, Carlo Regazzoni</p></summary>
<p>

**Abstract:** This work proposes a novel resource allocation strategy for anti-jamming in Cognitive Radio using Active Inference ($\textit{AIn}$), and a cognitive-UAV is employed as a case study. An Active Generalized Dynamic Bayesian Network (Active-GDBN) is proposed to represent the external environment that jointly encodes the physical signal dynamics and the dynamic interaction between UAV and jammer in the spectrum. We cast the action and planning as a Bayesian inference problem that can be solved by avoiding surprising states (minimizing abnormality) during online learning. Simulation results verify the effectiveness of the proposed $\textit{AIn}$ approach in minimizing abnormalities (maximizing rewards) and has a high convergence speed by comparing it with the conventional Frequency Hopping and Q-learning.

</p>
</details>

<details><summary><b>Consistency-based Self-supervised Learning for Temporal Anomaly Localization</b>
<a href="https://arxiv.org/abs/2208.05251">arxiv:2208.05251</a>
&#x1F4C8; 4 <br>
<p>Aniello Panariello, Angelo Porrello, Simone Calderara, Rita Cucchiara</p></summary>
<p>

**Abstract:** This work tackles Weakly Supervised Anomaly detection, in which a predictor is allowed to learn not only from normal examples but also from a few labeled anomalies made available during training. In particular, we deal with the localization of anomalous activities within the video stream: this is a very challenging scenario, as training examples come only with video-level annotations (and not frame-level). Several recent works have proposed various regularization terms to address it i.e. by enforcing sparsity and smoothness constraints over the weakly-learned frame-level anomaly scores. In this work, we get inspired by recent advances within the field of self-supervised learning and ask the model to yield the same scores for different augmentations of the same video sequence. We show that enforcing such an alignment improves the performance of the model on XD-Violence.

</p>
</details>

<details><summary><b>PatchDropout: Economizing Vision Transformers Using Patch Dropout</b>
<a href="https://arxiv.org/abs/2208.07220">arxiv:2208.07220</a>
&#x1F4C8; 3 <br>
<p>Yue Liu, Christos Matsoukas, Fredrik Strand, Hossein Azizpour, Kevin Smith</p></summary>
<p>

**Abstract:** Vision transformers have demonstrated the potential to outperform CNNs in a variety of vision tasks. But the computational and memory requirements of these models prohibit their use in many applications, especially those that depend on high-resolution images, such as medical image classification. Efforts to train ViTs more efficiently are overly complicated, necessitating architectural changes or intricate training schemes. In this work, we show that standard ViT models can be efficiently trained at high resolution by randomly dropping input image patches. This simple approach, PatchDropout, reduces FLOPs and memory by at least 50% in standard natural image datasets such as ImageNet, and those savings only increase with image size. On CSAW, a high-resolution medical dataset, we observe a 5 times savings in computation and memory using PatchDropout, along with a boost in performance. For practitioners with a fixed computational or memory budget, PatchDropout makes it possible to choose image resolution, hyperparameters, or model size to get the most performance out of their model.

</p>
</details>

<details><summary><b>Determining HEDP Foams' Quality with Multi-View Deep Learning Classification</b>
<a href="https://arxiv.org/abs/2208.07196">arxiv:2208.07196</a>
&#x1F4C8; 3 <br>
<p>Nadav Schneider, Matan Rusanovsky, Raz Gvishi, Gal Oren</p></summary>
<p>

**Abstract:** High energy density physics (HEDP) experiments commonly involve a dynamic wave-front propagating inside a low-density foam. This effect affects its density and hence, its transparency. A common problem in foam production is the creation of defective foams. Accurate information on their dimension and homogeneity is required to classify the foams' quality. Therefore, those parameters are being characterized using a 3D-measuring laser confocal microscope. For each foam, five images are taken: two 2D images representing the top and bottom surface foam planes and three images of side cross-sections from 3D scannings. An expert has to do the complicated, harsh, and exhausting work of manually classifying the foam's quality through the image set and only then determine whether the foam can be used in experiments or not. Currently, quality has two binary levels of normal vs. defective. At the same time, experts are commonly required to classify a sub-class of normal-defective, i.e., foams that are defective but might be sufficient for the needed experiment. This sub-class is problematic due to inconclusive judgment that is primarily intuitive. In this work, we present a novel state-of-the-art multi-view deep learning classification model that mimics the physicist's perspective by automatically determining the foams' quality classification and thus aids the expert. Our model achieved 86\% accuracy on upper and lower surface foam planes and 82\% on the entire set, suggesting interesting heuristics to the problem. A significant added value in this work is the ability to regress the foam quality instead of binary deduction and even explain the decision visually. The source code used in this work, as well as other relevant sources, are available at: https://github.com/Scientific-Computing-Lab-NRCN/Multi-View-Foams.git

</p>
</details>

<details><summary><b>Neural Networks for Scalar Input and Functional Output</b>
<a href="https://arxiv.org/abs/2208.05776">arxiv:2208.05776</a>
&#x1F4C8; 3 <br>
<p>Sidi Wu, Cédric Beaulac, Jiguo Cao</p></summary>
<p>

**Abstract:** The regression of a functional response on a set of scalar predictors can be a challenging task, especially if there is a large number of predictors, these predictors have interaction effects, or the relationship between those predictors and the response is nonlinear. In this work, we propose a solution to this problem: a feed-forward neural network (NN) designed to predict a functional response using scalar inputs. First, we transform the functional response to a finite-dimension representation and then we construct a NN that outputs this representation. We proposed different objective functions to train the NN. The proposed models are suited for both regularly and irregularly spaced data and also provide multiple ways to apply a roughness penalty to control the smoothness of the predicted curve. The difficulty in implementing both those features lies in the definition of objective functions that can be back-propagated. In our experiments, we demonstrate that our model outperforms the conventional function-on-scalar regression model in multiple scenarios while computationally scaling better with the dimension of the predictors.

</p>
</details>

<details><summary><b>Scalable neural quantum states architecture for quantum chemistry</b>
<a href="https://arxiv.org/abs/2208.05637">arxiv:2208.05637</a>
&#x1F4C8; 3 <br>
<p>Tianchen Zhao, James Stokes, Shravan Veerapaneni</p></summary>
<p>

**Abstract:** Variational optimization of neural-network representations of quantum states has been successfully applied to solve interacting fermionic problems. Despite rapid developments, significant scalability challenges arise when considering molecules of large scale, which correspond to non-locally interacting quantum spin Hamiltonians consisting of sums of thousands or even millions of Pauli operators. In this work, we introduce scalable parallelization strategies to improve neural-network-based variational quantum Monte Carlo calculations for ab-initio quantum chemistry applications. We establish GPU-supported local energy parallelism to compute the optimization objective for Hamiltonians of potentially complex molecules. Using autoregressive sampling techniques, we demonstrate systematic improvement in wall-clock timings required to achieve CCSD baseline target energies. The performance is further enhanced by accommodating the structure of resultant spin Hamiltonians into the autoregressive sampling ordering. The algorithm achieves promising performance in comparison with the classical approximate methods and exhibits both running time and scalability advantages over existing neural-network based methods.

</p>
</details>

<details><summary><b>Polynomial Optimization: Enhancing RLT relaxations with Conic Constraints</b>
<a href="https://arxiv.org/abs/2208.05608">arxiv:2208.05608</a>
&#x1F4C8; 3 <br>
<p>Brais González-Rodríguez, Raúl Alvite-Pazó, Samuel Alvite-Pazó, Bissan Ghaddar, Julio González-Díaz</p></summary>
<p>

**Abstract:** Conic optimization has recently emerged as a powerful tool for designing tractable and guaranteed algorithms for non-convex polynomial optimization problems. On the one hand, tractability is crucial for efficiently solving large-scale problems and, on the other hand, strong bounds are needed to ensure high quality solutions. In this research, we investigate the strengthening of RLT relaxations of polynomial optimization problems through the addition of nine different types of constraints that are based on linear, second-order cone, and semidefinite programming to solve to optimality the instances of well established test sets of polynomial optimization problems. We describe how to design these conic constraints and their performance with respect to each other and with respect to the standard RLT relaxations. Our first finding is that the different variants of nonlinear constraints (second-order cone and semidefinite) are the best performing ones in around $50\%$ of the instances. Additionally, we present a machine learning approach to decide on the most suitable constraints to add for a given instance. The computational results show that the machine learning approach significantly outperforms each and every one of the nine individual approaches.

</p>
</details>

<details><summary><b>Augmented Driver Behavior Models for High-Fidelity Simulation Study of Crash Detection Algorithms</b>
<a href="https://arxiv.org/abs/2208.05540">arxiv:2208.05540</a>
&#x1F4C8; 3 <br>
<p>Ahura Jami, Mahdi Razzaghpour, Hussein Alnuweiri, Yaser P. Fallah</p></summary>
<p>

**Abstract:** Developing safety and efficiency applications for Connected and Automated Vehicles (CAVs) require a great deal of testing and evaluation. The need for the operation of these systems in critical and dangerous situations makes the burden of their evaluation very costly, possibly dangerous, and time-consuming. As an alternative, researchers attempt to study and evaluate their algorithms and designs using simulation platforms. Modeling the behavior of drivers or human operators in CAVs or other vehicles interacting with them is one of the main challenges of such simulations. While developing a perfect model for human behavior is a challenging task and an open problem, we present a significant augmentation of the current models used in simulators for driver behavior. In this paper, we present a simulation platform for a hybrid transportation system that includes both human-driven and automated vehicles. In addition, we decompose the human driving task and offer a modular approach to simulating a large-scale traffic scenario, allowing for a thorough investigation of automated and active safety systems. Such representation through Interconnected modules offers a human-interpretable system that can be tuned to represent different classes of drivers. Additionally, we analyze a large driving dataset to extract expressive parameters that would best describe different driving characteristics. Finally, we recreate a similarly dense traffic scenario within our simulator and conduct a thorough analysis of various human-specific and system-specific factors, studying their effect on traffic network performance and safety.

</p>
</details>

<details><summary><b>Sequence Feature Extraction for Malware Family Analysis via Graph Neural Network</b>
<a href="https://arxiv.org/abs/2208.05476">arxiv:2208.05476</a>
&#x1F4C8; 3 <br>
<p>S. W. Hsiao, P. Y. Chu</p></summary>
<p>

**Abstract:** Malicious software (malware) causes much harm to our devices and life. We are eager to understand the malware behavior and the threat it made. Most of the record files of malware are variable length and text-based files with time stamps, such as event log data and dynamic analysis profiles. Using the time stamps, we can sort such data into sequence-based data for the following analysis. However, dealing with the text-based sequences with variable lengths is difficult. In addition, unlike natural language text data, most sequential data in information security have specific properties and structure, such as loop, repeated call, noise, etc. To deeply analyze the API call sequences with their structure, we use graphs to represent the sequences, which can further investigate the information and structure, such as the Markov model. Therefore, we design and implement an Attention Aware Graph Neural Network (AWGCN) to analyze the API call sequences. Through AWGCN, we can obtain the sequence embeddings to analyze the behavior of the malware. Moreover, the classification experiment result shows that AWGCN outperforms other classifiers in the call-like datasets, and the embedding can further improve the classic model's performance.

</p>
</details>

<details><summary><b>Robust methods for high-dimensional linear learning</b>
<a href="https://arxiv.org/abs/2208.05447">arxiv:2208.05447</a>
&#x1F4C8; 3 <br>
<p>Ibrahim Merad, Stéphane Gaïffas</p></summary>
<p>

**Abstract:** We propose statistically robust and computationally efficient linear learning methods in the high-dimensional batch setting, where the number of features $d$ may exceed the sample size $n$. We employ, in a generic learning setting, two algorithms depending on whether the considered loss function is gradient-Lipschitz or not. Then, we instantiate our framework on several applications including vanilla sparse, group-sparse and low-rank matrix recovery. This leads, for each application, to efficient and robust learning algorithms, that reach near-optimal estimation rates under heavy-tailed distributions and the presence of outliers. For vanilla $s$-sparsity, we are able to reach the $s\log (d)/n$ rate under heavy-tails and $η$-corruption, at a computational cost comparable to that of non-robust analogs. We provide an efficient implementation of our algorithms in an open-source $\mathtt{Python}$ library called $\mathtt{linlearn}$, by means of which we carry out numerical experiments which confirm our theoretical findings together with a comparison to other recent approaches proposed in the literature.

</p>
</details>

<details><summary><b>Detecting COVID-19 from digitized ECG printouts using 1D convolutional neural networks</b>
<a href="https://arxiv.org/abs/2208.05433">arxiv:2208.05433</a>
&#x1F4C8; 3 <br>
<p>Thao Nguyen, Hieu H. Pham, Huy Khiem Le, Anh Tu Nguyen, Ngoc Tien Thanh, Cuong Do</p></summary>
<p>

**Abstract:** The COVID-19 pandemic has exposed the vulnerability of healthcare services worldwide, raising the need to develop novel tools to provide rapid and cost-effective screening and diagnosis. Clinical reports indicated that COVID-19 infection may cause cardiac injury, and electrocardiograms (ECG) may serve as a diagnostic biomarker for COVID-19. This study aims to utilize ECG signals to detect COVID-19 automatically. We propose a novel method to extract ECG signals from ECG paper records, which are then fed into a one-dimensional convolution neural network (1D-CNN) to learn and diagnose the disease. To evaluate the quality of digitized signals, R peaks in the paper-based ECG images are labeled. Afterward, RR intervals calculated from each image are compared to RR intervals of the corresponding digitized signal. Experiments on the COVID-19 ECG images dataset demonstrate that the proposed digitization method is able to capture correctly the original signals, with a mean absolute error of 28.11 ms. Our proposed 1D-CNN model, which is trained on the digitized ECG signals, allows identifying individuals with COVID-19 and other subjects accurately, with classification accuracies of 98.42%, 95.63%, and 98.50% for classifying COVID-19 vs. Normal, COVID-19 vs. Abnormal Heartbeats, and COVID-19 vs. other classes, respectively. Furthermore, the proposed method also achieves a high-level of performance for the multi-classification task. Our findings indicate that a deep learning system trained on digitized ECG signals can serve as a potential tool for diagnosing COVID-19.

</p>
</details>

<details><summary><b>ATLAS: Universal Function Approximator for Memory Retention</b>
<a href="https://arxiv.org/abs/2208.05388">arxiv:2208.05388</a>
&#x1F4C8; 3 <br>
<p>Heinrich van Deventer, Anna Bosman</p></summary>
<p>

**Abstract:** Artificial neural networks (ANNs), despite their universal function approximation capability and practical success, are subject to catastrophic forgetting. Catastrophic forgetting refers to the abrupt unlearning of a previous task when a new task is learned. It is an emergent phenomenon that hinders continual learning. Existing universal function approximation theorems for ANNs guarantee function approximation ability, but do not predict catastrophic forgetting. This paper presents a novel universal approximation theorem for multi-variable functions using only single-variable functions and exponential functions. Furthermore, we present ATLAS: a novel ANN architecture based on the new theorem. It is shown that ATLAS is a universal function approximator capable of some memory retention, and continual learning. The memory of ATLAS is imperfect, with some off-target effects during continual learning, but it is well-behaved and predictable. An efficient implementation of ATLAS is provided. Experiments are conducted to evaluate both the function approximation and memory retention capabilities of ATLAS.

</p>
</details>

<details><summary><b>Multi-task Active Learning for Pre-trained Transformer-based Models</b>
<a href="https://arxiv.org/abs/2208.05379">arxiv:2208.05379</a>
&#x1F4C8; 3 <br>
<p>Guy Rotman, Roi Reichart</p></summary>
<p>

**Abstract:** Multi-task learning, in which several tasks are jointly learned by a single model, allows NLP models to share information from multiple annotations and may facilitate better predictions when the tasks are inter-related. This technique, however, requires annotating the same text with multiple annotation schemes which may be costly and laborious. Active learning (AL) has been demonstrated to optimize annotation processes by iteratively selecting unlabeled examples whose annotation is most valuable for the NLP model. Yet, multi-task active learning (MT-AL) has not been applied to state-of-the-art pre-trained Transformer-based NLP models. This paper aims to close this gap. We explore various multi-task selection criteria in three realistic multi-task scenarios, reflecting different relations between the participating tasks, and demonstrate the effectiveness of multi-task compared to single-task selection. Our results suggest that MT-AL can be effectively used in order to minimize annotation efforts for multi-task NLP models.

</p>
</details>

<details><summary><b>Multi-structure segmentation for renal cancer treatment with modified nn-UNet</b>
<a href="https://arxiv.org/abs/2208.05241">arxiv:2208.05241</a>
&#x1F4C8; 3 <br>
<p>Zhenyu Bu</p></summary>
<p>

**Abstract:** Renal cancer is one of the most prevalent cancers worldwide. Clinical signs of kidney cancer include hematuria and low back discomfort, which are quite distressing to the patient. Due to the rapid growth of artificial intelligence and deep learning, medical image segmentation has evolved dramatically over the past few years. In this paper, we propose modified nn-UNet for kidney multi-structure segmentation. Our solution is founded on the thriving nn-UNet architecture using 3D full resolution U-net. Firstly, various hyperparameters are modified for this particular task. Then, by doubling the number of filters in 3D full resolution nnUNet architecture to achieve a larger network, we may capture a greater receptive field. Finally, we include an axial attention mechanism in the decoder, which can obtain global information during the decoding stage to prevent the loss of local knowledge. Our modified nn-UNet achieves state-of-the-art performance on the KiPA2022 dataset when compared to conventional approaches such as 3D U-Net, MNet, etc.

</p>
</details>

<details><summary><b>Controlling Perceived Emotion in Symbolic Music Generation with Monte Carlo Tree Search</b>
<a href="https://arxiv.org/abs/2208.05162">arxiv:2208.05162</a>
&#x1F4C8; 3 <br>
<p>Lucas N. Ferreira, Lili Mou, Jim Whitehead, Levi H. S. Lelis</p></summary>
<p>

**Abstract:** This paper presents a new approach for controlling emotion in symbolic music generation with Monte Carlo Tree Search. We use Monte Carlo Tree Search as a decoding mechanism to steer the probability distribution learned by a language model towards a given emotion. At every step of the decoding process, we use Predictor Upper Confidence for Trees (PUCT) to search for sequences that maximize the average values of emotion and quality as given by an emotion classifier and a discriminator, respectively. We use a language model as PUCT's policy and a combination of the emotion classifier and the discriminator as its value function. To decode the next token in a piece of music, we sample from the distribution of node visits created during the search. We evaluate the quality of the generated samples with respect to human-composed pieces using a set of objective metrics computed directly from the generated samples. We also perform a user study to evaluate how human subjects perceive the generated samples' quality and emotion. We compare PUCT against Stochastic Bi-Objective Beam Search (SBBS) and Conditional Sampling (CS). Results suggest that PUCT outperforms SBBS and CS in almost all metrics of music quality and emotion.

</p>
</details>

<details><summary><b>Identifying Substitute and Complementary Products for Assortment Optimization with Cleora Embeddings</b>
<a href="https://arxiv.org/abs/2208.06262">arxiv:2208.06262</a>
&#x1F4C8; 2 <br>
<p>Sergiy Tkachuk, Anna Wróblewska, Jacek Dąbrowski, Szymon Łukasik</p></summary>
<p>

**Abstract:** Recent years brought an increasing interest in the application of machine learning algorithms in e-commerce, omnichannel marketing, and the sales industry. It is not only to the algorithmic advances but also to data availability, representing transactions, users, and background product information. Finding products related in different ways, i.e., substitutes and complements is essential for users' recommendations at the vendor's site and for the vendor - to perform efficient assortment optimization.
  The paper introduces a novel method for finding products' substitutes and complements based on the graph embedding Cleora algorithm. We also provide its experimental evaluation with regards to the state-of-the-art Shopper algorithm, studying the relevance of recommendations with surveys from industry experts. It is concluded that the new approach presented here offers suitable choices of recommended products, requiring a minimal amount of additional information. The algorithm can be used in various enterprises, effectively identifying substitute and complementary product options.

</p>
</details>

<details><summary><b>Customized Watermarking for Deep Neural Networks via Label Distribution Perturbation</b>
<a href="https://arxiv.org/abs/2208.05477">arxiv:2208.05477</a>
&#x1F4C8; 2 <br>
<p>Tzu-Yun Chien, Chih-Ya Shen</p></summary>
<p>

**Abstract:** With the increasing application value of machine learning, the intellectual property (IP) rights of deep neural networks (DNN) are getting more and more attention. With our analysis, most of the existing DNN watermarking methods can resist fine-tuning and pruning attack, but distillation attack. To address these problem, we propose a new DNN watermarking framework, Unified Soft-label Perturbation (USP), having a detector paired with the model to be watermarked, and Customized Soft-label Perturbation (CSP), embedding watermark via adding perturbation into the model output probability distribution. Experimental results show that our methods can resist all watermark removal attacks and outperform in distillation attack. Besides, we also have an excellent trade-off between the main task and watermarking that achieving 98.68% watermark accuracy while only affecting the main task accuracy by 0.59%.

</p>
</details>

<details><summary><b>Rapid Exploration of a 32.5M Compound Chemical Space with Active Learning to Discover Density Functional Approximation Insensitive and Synthetically Accessible Transitional Metal Chromophores</b>
<a href="https://arxiv.org/abs/2208.05444">arxiv:2208.05444</a>
&#x1F4C8; 2 <br>
<p>Chenru Duan, Aditya Nandy, Gianmarco Terrones, David W. Kastner, Heather J. Kulik</p></summary>
<p>

**Abstract:** Two outstanding challenges for machine learning (ML) accelerated chemical discovery are the synthesizability of candidate molecules or materials and the fidelity of the data used in ML model training. To address the first challenge, we construct a hypothetical design space of 32.5M transition metal complexes (TMCs), in which all of the constituent fragments (i.e., metals and ligands) and ligand symmetries are synthetically accessible. To address the second challenge, we search for consensus in predictions among 23 density functional approximations across multiple rungs of Jacob's ladder. To accelerate the screening of these 32.5M TMCs, we use efficient global optimization to sample candidate low-spin chromophores that simultaneously have low absorption energies and low static correlation. Despite the scarcity (i.e., $<$ 0.01\%) of potential chromophores in this large chemical space, we identify transition metal chromophores with high likelihood (i.e., $>$ 10\%) as the ML models improve during active learning. This represents a 1,000 fold acceleration in discovery corresponding to discoveries in days instead of years. Analyses of candidate chromophores reveal a preference for Co(III) and large, strong-field ligands with more bond saturation. We compute the absorption spectra of promising chromophores on the Pareto front by time-dependent density functional theory calculations and verify that two thirds of them have desired excited state properties. Although these complexes have never been experimentally explored, their constituent ligands demonstrated interesting optical properties in literature, exemplifying the effectiveness of our construction of realistic TMC design space and active learning approach.

</p>
</details>

<details><summary><b>Flexible Unsupervised Learning for Massive MIMO Subarray Hybrid Beamforming</b>
<a href="https://arxiv.org/abs/2208.05443">arxiv:2208.05443</a>
&#x1F4C8; 2 <br>
<p>Hamed Hojatian, Jérémy Nadal, Jean-François Frigon, François Leduc-Primeau</p></summary>
<p>

**Abstract:** Hybrid beamforming is a promising technology to improve the energy efficiency of massive MIMO systems. In particular, subarray hybrid beamforming can further decrease power consumption by reducing the number of phase-shifters. However, designing the hybrid beamforming vectors is a complex task due to the discrete nature of the subarray connections and the phase-shift amounts. Finding the optimal connections between RF chains and antennas requires solving a non-convex problem in a large search space. In addition, conventional solutions assume that perfect CSI is available, which is not the case in practical systems. Therefore, we propose a novel unsupervised learning approach to design the hybrid beamforming for any subarray structure while supporting quantized phase-shifters and noisy CSI. One major feature of the proposed architecture is that no beamforming codebook is required, and the neural network is trained to take into account the phase-shifter quantization. Simulation results show that the proposed deep learning solutions can achieve higher sum-rates than existing methods.

</p>
</details>

<details><summary><b>Non-Contrastive Self-Supervised Learning of Utterance-Level Speech Representations</b>
<a href="https://arxiv.org/abs/2208.05413">arxiv:2208.05413</a>
&#x1F4C8; 2 <br>
<p>Jaejin Cho, Raghavendra Pappagari, Piotr Żelasko, Laureano Moro-Velazquez, Jesús Villalba, Najim Dehak</p></summary>
<p>

**Abstract:** Considering the abundance of unlabeled speech data and the high labeling costs, unsupervised learning methods can be essential for better system development. One of the most successful methods is contrastive self-supervised methods, which require negative sampling: sampling alternative samples to contrast with the current sample (anchor). However, it is hard to ensure if all the negative samples belong to classes different from the anchor class without labels. This paper applies a non-contrastive self-supervised learning method on an unlabeled speech corpus to learn utterance-level embeddings. We used DIstillation with NO labels (DINO), proposed in computer vision, and adapted it to the speech domain. Unlike the contrastive methods, DINO does not require negative sampling. These embeddings were evaluated on speaker verification and emotion recognition. In speaker verification, the unsupervised DINO embedding with cosine scoring provided 4.38% EER on the VoxCeleb1 test trial. This outperforms the best contrastive self-supervised method by 40% relative in EER. An iterative pseudo-labeling training pipeline, not requiring speaker labels, further improved the EER to 1.89%. In emotion recognition, the DINO embedding performed 60.87, 79.21, and 56.98% in micro-f1 score on IEMOCAP, Crema-D, and MSP-Podcast, respectively. The results imply the generality of the DINO embedding to different speech applications.

</p>
</details>

<details><summary><b>Mappings for Marginal Probabilities with Applications to Models in Statistical Physics</b>
<a href="https://arxiv.org/abs/2208.05333">arxiv:2208.05333</a>
&#x1F4C8; 2 <br>
<p>Mehdi Molkaraie</p></summary>
<p>

**Abstract:** We present local mappings that relate the marginal probabilities of a global probability mass function represented by its primal normal factor graph to the corresponding marginal probabilities in its dual normal factor graph. The mapping is based on the Fourier transform of the local factors of the models. Details of the mapping are provided for the Ising model, where it is proved that the local extrema of the fixed points are attained at the phase transition of the two-dimensional nearest-neighbor Ising model. The results are further extended to the Potts model, to the clock model, and to Gaussian Markov random fields. By employing the mapping, we can transform simultaneously all the estimated marginal probabilities from the dual domain to the primal domain (and vice versa), which is advantageous if estimating the marginals can be carried out more efficiently in the dual domain. An example of particular significance is the ferromagnetic Ising model in a positive external magnetic field. For this model, there exists a rapidly mixing Markov chain (called the subgraphs--world process) to generate configurations in the dual normal factor graph of the model. Our numerical experiments illustrate that the proposed procedure can provide more accurate estimates of marginal probabilities of a global probability mass function in various settings.

</p>
</details>

<details><summary><b>Learning Quantization in LDPC Decoders</b>
<a href="https://arxiv.org/abs/2208.05186">arxiv:2208.05186</a>
&#x1F4C8; 2 <br>
<p>Marvin Geiselhart, Ahmed Elkelesh, Jannis Clausius, Fei Liang, Wen Xu, Jing Liang, Stephan ten Brink</p></summary>
<p>

**Abstract:** Finding optimal message quantization is a key requirement for low complexity belief propagation (BP) decoding. To this end, we propose a floating-point surrogate model that imitates quantization effects as additions of uniform noise, whose amplitudes are trainable variables. We verify that the surrogate model closely matches the behavior of a fixed-point implementation and propose a hand-crafted loss function to realize a trade-off between complexity and error-rate performance. A deep learning-based method is then applied to optimize the message bitwidths. Moreover, we show that parameter sharing can both ensure implementation-friendly solutions and results in faster training convergence than independent parameters. We provide simulation results for 5G low-density parity-check (LDPC) codes and report an error-rate performance within 0.2 dB of floating-point decoding at an average message quantization bitwidth of 3.1 bits. In addition, we show that the learned bitwidths also generalize to other code rates and channels.

</p>
</details>

<details><summary><b>Frequency propagation: Multi-mechanism learning in nonlinear physical networks</b>
<a href="https://arxiv.org/abs/2208.08862">arxiv:2208.08862</a>
&#x1F4C8; 1 <br>
<p>Vidyesh Rao Anisetti, A. Kandala, B. Scellier, J. M. Schwarz</p></summary>
<p>

**Abstract:** We introduce frequency propagation, a learning algorithm for nonlinear physical networks. In a resistive electrical circuit with variable resistors, an activation current is applied at a set of input nodes at one frequency, and an error current is applied at a set of output nodes at another frequency. The voltage response of the circuit to these boundary currents is the superposition of an `activation signal' and an `error signal' whose coefficients can be read in different frequencies of the frequency domain. Each conductance is updated proportionally to the product of the two coefficients. The learning rule is local and proved to perform gradient descent on a loss function. We argue that frequency propagation is an instance of a multi-mechanism learning strategy for physical networks, be it resistive, elastic, or flow networks. Multi-mechanism learning strategies incorporate at least two physical quantities, potentially governed by independent physical mechanisms, to act as activation and error signals in the training process. Locally available information about these two signals is then used to update the trainable parameters to perform gradient descent. We demonstrate how earlier work implementing learning via chemical signaling in flow networks also falls under the rubric of multi-mechanism learning.

</p>
</details>

<details><summary><b>Neural Embedding: Learning the Embedding of the Manifold of Physics Data</b>
<a href="https://arxiv.org/abs/2208.05484">arxiv:2208.05484</a>
&#x1F4C8; 1 <br>
<p>Sang Eon Park, Philip Harris, Bryan Ostdiek</p></summary>
<p>

**Abstract:** In this paper, we present a method of embedding physics data manifolds with metric structure into lower dimensional spaces with simpler metrics, such as Euclidean and Hyperbolic spaces. We then demonstrate that it can be a powerful step in the data analysis pipeline for many applications. Using progressively more realistic simulated collisions at the Large Hadron Collider, we show that this embedding approach learns the underlying latent structure. With the notion of volume in Euclidean spaces, we provide for the first time a viable solution to quantifying the true search capability of model agnostic search algorithms in collider physics (i.e. anomaly detection). Finally, we discuss how the ideas presented in this paper can be employed to solve many practical challenges that require the extraction of physically meaningful representations from information in complex high dimensional datasets.

</p>
</details>

<details><summary><b>Modeling Diverse Chemical Reactions for Single-step Retrosynthesis via Discrete Latent Variables</b>
<a href="https://arxiv.org/abs/2208.05482">arxiv:2208.05482</a>
&#x1F4C8; 1 <br>
<p>Huarui He, Jie Wang, Yunfei Liu, Feng Wu</p></summary>
<p>

**Abstract:** Single-step retrosynthesis is the cornerstone of retrosynthesis planning, which is a crucial task for computer-aided drug discovery. The goal of single-step retrosynthesis is to identify the possible reactants that lead to the synthesis of the target product in one reaction. By representing organic molecules as canonical strings, existing sequence-based retrosynthetic methods treat the product-to-reactant retrosynthesis as a sequence-to-sequence translation problem. However, most of them struggle to identify diverse chemical reactions for a desired product due to the deterministic inference, which contradicts the fact that many compounds can be synthesized through various reaction types with different sets of reactants. In this work, we aim to increase reaction diversity and generate various reactants using discrete latent variables. We propose a novel sequence-based approach, namely RetroDVCAE, which incorporates conditional variational autoencoders into single-step retrosynthesis and associates discrete latent variables with the generation process. Specifically, RetroDVCAE uses the Gumbel-Softmax distribution to approximate the categorical distribution over potential reactions and generates multiple sets of reactants with the variational decoder. Experiments demonstrate that RetroDVCAE outperforms state-of-the-art baselines on both benchmark dataset and homemade dataset. Both quantitative and qualitative results show that RetroDVCAE can model the multi-modal distribution over reaction types and produce diverse reactant candidates.

</p>
</details>

<details><summary><b>Multi-View Pre-Trained Model for Code Vulnerability Identification</b>
<a href="https://arxiv.org/abs/2208.05227">arxiv:2208.05227</a>
&#x1F4C8; 1 <br>
<p>Xuxiang Jiang, Yinhao Xiao, Jun Wang, Wei Zhang</p></summary>
<p>

**Abstract:** Vulnerability identification is crucial for cyber security in the software-related industry. Early identification methods require significant manual efforts in crafting features or annotating vulnerable code. Although the recent pre-trained models alleviate this issue, they overlook the multiple rich structural information contained in the code itself. In this paper, we propose a novel Multi-View Pre-Trained Model (MV-PTM) that encodes both sequential and multi-type structural information of the source code and uses contrastive learning to enhance code representations. The experiments conducted on two public datasets demonstrate the superiority of MV-PTM. In particular, MV-PTM improves GraphCodeBERT by 3.36\% on average in terms of F1 score.

</p>
</details>

<details><summary><b>Capturing Dependencies within Machine Learning via a Formal Process Model</b>
<a href="https://arxiv.org/abs/2208.05219">arxiv:2208.05219</a>
&#x1F4C8; 1 <br>
<p>Fabian Ritz, Thomy Phan, Andreas Sedlmeier, Philipp Altmann, Jan Wieghardt, Reiner Schmid, Horst Sauer, Cornel Klein, Claudia Linnhoff-Popien, Thomas Gabor</p></summary>
<p>

**Abstract:** The development of Machine Learning (ML) models is more than just a special case of software development (SD): ML models acquire properties and fulfill requirements even without direct human interaction in a seemingly uncontrollable manner. Nonetheless, the underlying processes can be described in a formal way. We define a comprehensive SD process model for ML that encompasses most tasks and artifacts described in the literature in a consistent way. In addition to the production of the necessary artifacts, we also focus on generating and validating fitting descriptions in the form of specifications. We stress the importance of further evolving the ML model throughout its life-cycle even after initial training and testing. Thus, we provide various interaction points with standard SD processes in which ML often is an encapsulated task. Further, our SD process model allows to formulate ML as a (meta-) optimization problem. If automated rigorously, it can be used to realize self-adaptive autonomous systems. Finally, our SD process model features a description of time that allows to reason about the progress within ML development processes. This might lead to further applications of formal methods within the field of ML.

</p>
</details>


{% endraw %}
Prev: [2022.08.09]({{ '/2022/08/09/2022.08.09.html' | relative_url }})  Next: [2022.08.11]({{ '/2022/08/11/2022.08.11.html' | relative_url }})