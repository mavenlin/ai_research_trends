Prev: [2021.02.19]({{ '/2021/02/19/2021.02.19.html' | relative_url }})  Next: [2021.02.21]({{ '/2021/02/21/2021.02.21.html' | relative_url }})
{% raw %}
## Summary for 2021-02-20, created on 2021-12-24


<details><summary><b>Learning Neural Network Subspaces</b>
<a href="https://arxiv.org/abs/2102.10472">arxiv:2102.10472</a>
&#x1F4C8; 35 <br>
<p>Mitchell Wortsman, Maxwell Horton, Carlos Guestrin, Ali Farhadi, Mohammad Rastegari</p></summary>
<p>

**Abstract:** Recent observations have advanced our understanding of the neural network optimization landscape, revealing the existence of (1) paths of high accuracy containing diverse solutions and (2) wider minima offering improved performance. Previous methods observing diverse paths require multiple training runs. In contrast we aim to leverage both property (1) and (2) with a single method and in a single training run. With a similar computational cost as training one model, we learn lines, curves, and simplexes of high-accuracy neural networks. These neural network subspaces contain diverse solutions that can be ensembled, approaching the ensemble performance of independently trained networks without the training cost. Moreover, using the subspace midpoint boosts accuracy, calibration, and robustness to label noise, outperforming Stochastic Weight Averaging.

</p>
</details>

<details><summary><b>Provably Strict Generalisation Benefit for Equivariant Models</b>
<a href="https://arxiv.org/abs/2102.10333">arxiv:2102.10333</a>
&#x1F4C8; 17 <br>
<p>Bryn Elesedy, Sheheryar Zaidi</p></summary>
<p>

**Abstract:** It is widely believed that engineering a model to be invariant/equivariant improves generalisation. Despite the growing popularity of this approach, a precise characterisation of the generalisation benefit is lacking. By considering the simplest case of linear models, this paper provides the first provably non-zero improvement in generalisation for invariant/equivariant models when the target distribution is invariant/equivariant with respect to a compact group. Moreover, our work reveals an interesting relationship between generalisation, the number of training examples and properties of the group action. Our results rest on an observation of the structure of function spaces under averaging operators which, along with its consequences for feature averaging, may be of independent interest.

</p>
</details>

<details><summary><b>GIST: Distributed Training for Large-Scale Graph Convolutional Networks</b>
<a href="https://arxiv.org/abs/2102.10424">arxiv:2102.10424</a>
&#x1F4C8; 15 <br>
<p>Cameron R. Wolfe, Jingkang Yang, Arindam Chowdhury, Chen Dun, Artun Bayer, Santiago Segarra, Anastasios Kyrillidis</p></summary>
<p>

**Abstract:** The graph convolutional network (GCN) is a go-to solution for machine learning on graphs, but its training is notoriously difficult to scale both in terms of graph size and the number of model parameters. Although some work has explored training on large-scale graphs (e.g., GraphSAGE, ClusterGCN, etc.), we pioneer efficient training of large-scale GCN models (i.e., ultra-wide, overparameterized models) with the proposal of a novel, distributed training framework. Our proposed training methodology, called GIST, disjointly partitions the parameters of a GCN model into several, smaller sub-GCNs that are trained independently and in parallel. In addition to being compatible with any GCN architecture, GIST improves model performance, scales to training on arbitrarily large graphs, significantly decreases wall-clock training time, and enables the training of markedly overparameterized GCN models. Remarkably, with GIST, we train an astonishgly-wide 32,768-dimensional GraphSAGE model, which exceeds the capacity of a single GPU by a factor of 8X, to SOTA performance on the Amazon2M dataset.

</p>
</details>

<details><summary><b>On Proximal Policy Optimization's Heavy-tailed Gradients</b>
<a href="https://arxiv.org/abs/2102.10264">arxiv:2102.10264</a>
&#x1F4C8; 10 <br>
<p>Saurabh Garg, Joshua Zhanson, Emilio Parisotto, Adarsh Prasad, J. Zico Kolter, Zachary C. Lipton, Sivaraman Balakrishnan, Ruslan Salakhutdinov, Pradeep Ravikumar</p></summary>
<p>

**Abstract:** Modern policy gradient algorithms such as Proximal Policy Optimization (PPO) rely on an arsenal of heuristics, including loss clipping and gradient clipping, to ensure successful learning. These heuristics are reminiscent of techniques from robust statistics, commonly used for estimation in outlier-rich (``heavy-tailed'') regimes. In this paper, we present a detailed empirical study to characterize the heavy-tailed nature of the gradients of the PPO surrogate reward function. We demonstrate that the gradients, especially for the actor network, exhibit pronounced heavy-tailedness and that it increases as the agent's policy diverges from the behavioral policy (i.e., as the agent goes further off policy). Further examination implicates the likelihood ratios and advantages in the surrogate reward as the main sources of the observed heavy-tailedness. We then highlight issues arising due to the heavy-tailed nature of the gradients. In this light, we study the effects of the standard PPO clipping heuristics, demonstrating that these tricks primarily serve to offset heavy-tailedness in gradients. Thus motivated, we propose incorporating GMOM, a high-dimensional robust estimator, into PPO as a substitute for three clipping tricks. Despite requiring less hyperparameter tuning, our method matches the performance of PPO (with all heuristics enabled) on a battery of MuJoCo continuous control tasks.

</p>
</details>

<details><summary><b>Kanerva++: extending The Kanerva Machine with differentiable, locally block allocated latent memory</b>
<a href="https://arxiv.org/abs/2103.03905">arxiv:2103.03905</a>
&#x1F4C8; 8 <br>
<p>Jason Ramapuram, Yan Wu, Alexandros Kalousis</p></summary>
<p>

**Abstract:** Episodic and semantic memory are critical components of the human memory model. The theory of complementary learning systems (McClelland et al., 1995) suggests that the compressed representation produced by a serial event (episodic memory) is later restructured to build a more generalized form of reusable knowledge (semantic memory). In this work we develop a new principled Bayesian memory allocation scheme that bridges the gap between episodic and semantic memory via a hierarchical latent variable model. We take inspiration from traditional heap allocation and extend the idea of locally contiguous memory to the Kanerva Machine, enabling a novel differentiable block allocated latent memory. In contrast to the Kanerva Machine, we simplify the process of memory writing by treating it as a fully feed forward deterministic process, relying on the stochasticity of the read key distribution to disperse information within the memory. We demonstrate that this allocation scheme improves performance in memory conditional image generation, resulting in new state-of-the-art conditional likelihood values on binarized MNIST (<=41.58 nats/image) , binarized Omniglot (<=66.24 nats/image), as well as presenting competitive performance on CIFAR10, DMLab Mazes, Celeb-A and ImageNet32x32.

</p>
</details>

<details><summary><b>BSQ: Exploring Bit-Level Sparsity for Mixed-Precision Neural Network Quantization</b>
<a href="https://arxiv.org/abs/2102.10462">arxiv:2102.10462</a>
&#x1F4C8; 7 <br>
<p>Huanrui Yang, Lin Duan, Yiran Chen, Hai Li</p></summary>
<p>

**Abstract:** Mixed-precision quantization can potentially achieve the optimal tradeoff between performance and compression rate of deep neural networks, and thus, have been widely investigated. However, it lacks a systematic method to determine the exact quantization scheme. Previous methods either examine only a small manually-designed search space or utilize a cumbersome neural architecture search to explore the vast search space. These approaches cannot lead to an optimal quantization scheme efficiently. This work proposes bit-level sparsity quantization (BSQ) to tackle the mixed-precision quantization from a new angle of inducing bit-level sparsity. We consider each bit of quantized weights as an independent trainable variable and introduce a differentiable bit-sparsity regularizer. BSQ can induce all-zero bits across a group of weight elements and realize the dynamic precision reduction, leading to a mixed-precision quantization scheme of the original model. Our method enables the exploration of the full mixed-precision space with a single gradient-based optimization process, with only one hyperparameter to tradeoff the performance and compression. BSQ achieves both higher accuracy and higher bit reduction on various model architectures on the CIFAR-10 and ImageNet datasets comparing to previous methods.

</p>
</details>

<details><summary><b>Decoupling Value and Policy for Generalization in Reinforcement Learning</b>
<a href="https://arxiv.org/abs/2102.10330">arxiv:2102.10330</a>
&#x1F4C8; 7 <br>
<p>Roberta Raileanu, Rob Fergus</p></summary>
<p>

**Abstract:** Standard deep reinforcement learning algorithms use a shared representation for the policy and value function, especially when training directly from images. However, we argue that more information is needed to accurately estimate the value function than to learn the optimal policy. Consequently, the use of a shared representation for the policy and value function can lead to overfitting. To alleviate this problem, we propose two approaches which are combined to create IDAAC: Invariant Decoupled Advantage Actor-Critic. First, IDAAC decouples the optimization of the policy and value function, using separate networks to model them. Second, it introduces an auxiliary loss which encourages the representation to be invariant to task-irrelevant properties of the environment. IDAAC shows good generalization to unseen environments, achieving a new state-of-the-art on the Procgen benchmark and outperforming popular methods on DeepMind Control tasks with distractors. Our implementation is available at https://github.com/rraileanu/idaac.

</p>
</details>

<details><summary><b>On Fast Adversarial Robustness Adaptation in Model-Agnostic Meta-Learning</b>
<a href="https://arxiv.org/abs/2102.10454">arxiv:2102.10454</a>
&#x1F4C8; 6 <br>
<p>Ren Wang, Kaidi Xu, Sijia Liu, Pin-Yu Chen, Tsui-Wei Weng, Chuang Gan, Meng Wang</p></summary>
<p>

**Abstract:** Model-agnostic meta-learning (MAML) has emerged as one of the most successful meta-learning techniques in few-shot learning. It enables us to learn a meta-initialization} of model parameters (that we call meta-model) to rapidly adapt to new tasks using a small amount of labeled training data. Despite the generalization power of the meta-model, it remains elusive that how adversarial robustness can be maintained by MAML in few-shot learning. In addition to generalization, robustness is also desired for a meta-model to defend adversarial examples (attacks). Toward promoting adversarial robustness in MAML, we first study WHEN a robustness-promoting regularization should be incorporated, given the fact that MAML adopts a bi-level (fine-tuning vs. meta-update) learning procedure. We show that robustifying the meta-update stage is sufficient to make robustness adapted to the task-specific fine-tuning stage even if the latter uses a standard training protocol. We also make additional justification on the acquired robustness adaptation by peering into the interpretability of neurons' activation maps. Furthermore, we investigate HOW robust regularization can efficiently be designed in MAML. We propose a general but easily-optimized robustness-regularized meta-learning framework, which allows the use of unlabeled data augmentation, fast adversarial attack generation, and computationally-light fine-tuning. In particular, we for the first time show that the auxiliary contrastive learning task can enhance the adversarial robustness of MAML. Finally, extensive experiments are conducted to demonstrate the effectiveness of our proposed methods in robust few-shot learning.

</p>
</details>

<details><summary><b>CheXseg: Combining Expert Annotations with DNN-generated Saliency Maps for X-ray Segmentation</b>
<a href="https://arxiv.org/abs/2102.10484">arxiv:2102.10484</a>
&#x1F4C8; 5 <br>
<p>Soham Gadgil, Mark Endo, Emily Wen, Andrew Y. Ng, Pranav Rajpurkar</p></summary>
<p>

**Abstract:** Medical image segmentation models are typically supervised by expert annotations at the pixel-level, which can be expensive to acquire. In this work, we propose a method that combines the high quality of pixel-level expert annotations with the scale of coarse DNN-generated saliency maps for training multi-label semantic segmentation models. We demonstrate the application of our semi-supervised method, which we call CheXseg, on multi-label chest X-ray interpretation. We find that CheXseg improves upon the performance (mIoU) of fully-supervised methods that use only pixel-level expert annotations by 9.7% and weakly-supervised methods that use only DNN-generated saliency maps by 73.1%. Our best method is able to match radiologist agreement on three out of ten pathologies and reduces the overall performance gap by 57.2% as compared to weakly-supervised methods.

</p>
</details>

<details><summary><b>The Use of Voice Source Features for Sung Speech Recognition</b>
<a href="https://arxiv.org/abs/2102.10376">arxiv:2102.10376</a>
&#x1F4C8; 4 <br>
<p>Gerardo Roa Dabike, Jon Barker</p></summary>
<p>

**Abstract:** In this paper, we ask whether vocal source features (pitch, shimmer, jitter, etc) can improve the performance of automatic sung speech recognition, arguing that conclusions previously drawn from spoken speech studies may not be valid in the sung speech domain. We first use a parallel singing/speaking corpus (NUS-48E) to illustrate differences in sung vs spoken voicing characteristics including pitch range, syllables duration, vibrato, jitter and shimmer. We then use this analysis to inform speech recognition experiments on the sung speech DSing corpus, using a state of the art acoustic model and augmenting conventional features with various voice source parameters. Experiments are run with three standard (increasingly large) training sets, DSing1 (15.1 hours), DSing3 (44.7 hours) and DSing30 (149.1 hours). Pitch combined with degree of voicing produces a significant decrease in WER from 38.1% to 36.7% when training with DSing1 however smaller decreases in WER observed when training with the larger more varied DSing3 and DSing30 sets were not seen to be statistically significant. Voicing quality characteristics did not improve recognition performance although analysis suggests that they do contribute to an improved discrimination between voiced/unvoiced phoneme pairs.

</p>
</details>

<details><summary><b>How To Train Your HERON</b>
<a href="https://arxiv.org/abs/2102.10357">arxiv:2102.10357</a>
&#x1F4C8; 4 <br>
<p>Antoine Richard, Stephanie Aravecchia, Thomas Schillaci, Matthieu Geist, Cedric Pradalier</p></summary>
<p>

**Abstract:** In this paper we apply Deep Reinforcement Learning (Deep RL) and Domain Randomization to solve a navigation task in a natural environment relying solely on a 2D laser scanner. We train a model-based RL agent in simulation to follow lake and river shores and apply it on a real Unmanned Surface Vehicle in a zero-shot setup. We demonstrate that even though the agent has not been trained in the real world, it can fulfill its task successfully and adapt to changes in the robot's environment and dynamics. Finally, we show that the RL agent is more robust, faster, and more accurate than a state-aware Model-Predictive-Controller.

</p>
</details>

<details><summary><b>An Attention Ensemble Approach for Efficient Text Classification of Indian Languages</b>
<a href="https://arxiv.org/abs/2102.10275">arxiv:2102.10275</a>
&#x1F4C8; 4 <br>
<p>Atharva Kulkarni, Amey Hengle, Rutuja Udyawar</p></summary>
<p>

**Abstract:** The recent surge of complex attention-based deep learning architectures has led to extraordinary results in various downstream NLP tasks in the English language. However, such research for resource-constrained and morphologically rich Indian vernacular languages has been relatively limited. This paper proffers team SPPU\_AKAH's solution for the TechDOfication 2020 subtask-1f: which focuses on the coarse-grained technical domain identification of short text documents in Marathi, a Devanagari script-based Indian language. Availing the large dataset at hand, a hybrid CNN-BiLSTM attention ensemble model is proposed that competently combines the intermediate sentence representations generated by the convolutional neural network and the bidirectional long short-term memory, leading to efficient text classification. Experimental results show that the proposed model outperforms various baseline machine learning and deep learning models in the given task, giving the best validation accuracy of 89.57\% and f1-score of 0.8875. Furthermore, the solution resulted in the best system submission for this subtask, giving a test accuracy of 64.26\% and f1-score of 0.6157, transcending the performances of other teams as well as the baseline system given by the organizers of the shared task.

</p>
</details>

<details><summary><b>Predicting Future Cognitive Decline with Hyperbolic Stochastic Coding</b>
<a href="https://arxiv.org/abs/2102.10503">arxiv:2102.10503</a>
&#x1F4C8; 3 <br>
<p>J. Zhang, Q. Dong, J. Shi, Q. Li, C. M. Stonnington, B. A. Gutman, K. Chen, E. M. Reiman, R. J. Caselli, P. M. Thompson, J. Ye, Y. Wang</p></summary>
<p>

**Abstract:** Hyperbolic geometry has been successfully applied in modeling brain cortical and subcortical surfaces with general topological structures. However such approaches, similar to other surface based brain morphology analysis methods, usually generate high dimensional features. It limits their statistical power in cognitive decline prediction research, especially in datasets with limited subject numbers. To address the above limitation, we propose a novel framework termed as hyperbolic stochastic coding (HSC). Our preliminary experimental results show that our algorithm achieves superior results on various classification tasks. Our work may enrich surface based brain imaging research tools and potentially result in a diagnostic and prognostic indicator to be useful in individualized treatment strategies.

</p>
</details>

<details><summary><b>Decaying Clipping Range in Proximal Policy Optimization</b>
<a href="https://arxiv.org/abs/2102.10456">arxiv:2102.10456</a>
&#x1F4C8; 3 <br>
<p>Mónika Farsang, Luca Szegletes</p></summary>
<p>

**Abstract:** Proximal Policy Optimization (PPO) is among the most widely used algorithms in reinforcement learning, which achieves state-of-the-art performance in many challenging problems. The keys to its success are the reliable policy updates through the clipping mechanism and the multiple epochs of minibatch updates. The aim of this research is to give new simple but effective alternatives to the former. For this, we propose linearly and exponentially decaying clipping range approaches throughout the training. With these, we would like to provide higher exploration at the beginning and stronger restrictions at the end of the learning phase. We investigate their performance in several classical control and locomotive robotic environments. During the analysis, we found that they influence the achieved rewards and are effective alternatives to the constant clipping method in many reinforcement learning tasks.

</p>
</details>

<details><summary><b>Importance of Environment Design in Reinforcement Learning: A Study of a Robotic Environment</b>
<a href="https://arxiv.org/abs/2102.10447">arxiv:2102.10447</a>
&#x1F4C8; 3 <br>
<p>Mónika Farsang, Luca Szegletes</p></summary>
<p>

**Abstract:** An in-depth understanding of the particular environment is crucial in reinforcement learning (RL). To address this challenge, the decision-making process of a mobile collaborative robotic assistant modeled by the Markov decision process (MDP) framework is studied in this paper. The optimal state-action combinations of the MDP are calculated with the non-linear Bellman optimality equations. This system of equations can be solved with relative ease by the computational power of Wolfram Mathematica, where the obtained optimal action-values point to the optimal policy. Unlike other RL algorithms, this methodology does not approximate the optimal behavior, it gives the exact, explicit solution, which provides a strong foundation for our study. With this, we offer new insights into understanding the action selection mechanisms in RL by presenting various small modifications on the very same schema that lead to different optimal policies.

</p>
</details>

<details><summary><b>Retrain or not retrain: Conformal test martingales for change-point detection</b>
<a href="https://arxiv.org/abs/2102.10439">arxiv:2102.10439</a>
&#x1F4C8; 3 <br>
<p>Vladimir Vovk, Ivan Petej, Ilia Nouretdinov, Ernst Ahlberg, Lars Carlsson, Alex Gammerman</p></summary>
<p>

**Abstract:** We argue for supplementing the process of training a prediction algorithm by setting up a scheme for detecting the moment when the distribution of the data changes and the algorithm needs to be retrained. Our proposed schemes are based on exchangeability martingales, i.e., processes that are martingales under any exchangeable distribution for the data. Our method, based on conformal prediction, is general and can be applied on top of any modern prediction algorithm. Its validity is guaranteed, and in this paper we make first steps in exploring its efficiency.

</p>
</details>

<details><summary><b>NUBOT: Embedded Knowledge Graph With RASA Framework for Generating Semantic Intents Responses in Roman Urdu</b>
<a href="https://arxiv.org/abs/2102.10410">arxiv:2102.10410</a>
&#x1F4C8; 3 <br>
<p>Johar Shabbir, Muhammad Umair Arshad, Waseem Shahzad</p></summary>
<p>

**Abstract:** The understanding of the human language is quantified by identifying intents and entities. Even though classification methods that rely on labeled information are often used for the comprehension of language understanding, it is incredibly time consuming and tedious process to generate high propensity supervised datasets. In this paper, we present the generation of accurate intents for the corresponding Roman Urdu unstructured data and integrate this corpus in RASA NLU module for intent classification. We embed knowledge graph with RASA Framework to maintain the dialog history for semantic based natural language mechanism for chatbot communication. We compare results of our work with existing linguistic systems combined with semantic technologies. Minimum accuracy of intents generation is 64 percent of confidence and in the response generation part minimum accuracy is 82.1 percent and maximum accuracy gain is 96.7 percent. All the scores refers to log precision, recall, and f1 measure for each intents once summarized for all. Furthermore, it creates a confusion matrix represents that which intents are ambiguously recognized by approach.

</p>
</details>

<details><summary><b>Unavailable Transit Feed Specification: Making it Available with Recurrent Neural Networks</b>
<a href="https://arxiv.org/abs/2102.10323">arxiv:2102.10323</a>
&#x1F4C8; 3 <br>
<p>Ludovico Iovino, Phuong T. Nguyen, Amleto Di Salle, Francesco Gallo, Michele Flammini</p></summary>
<p>

**Abstract:** Studies on public transportation in Europe suggest that European inhabitants use buses in ca. 56% of all public transport travels. One of the critical factors affecting such a percentage and more, in general, the demand for public transport services, with an increasing reluctance to use them, is their quality. End-users can perceive quality from various perspectives, including the availability of information, i.e., the access to details about the transit and the provided services. The approach proposed in this paper, using innovative methodologies resorting on data mining and machine learning techniques, aims to make available the unavailable data about public transport. In particular, by mining GPS traces, we manage to reconstruct the complete transit graph of public transport. The approach has been successfully validated on a real dataset collected from the local bus system of the city of L'Aquila (Italy). The experimental results demonstrate that the proposed approach and implemented framework are both effective and efficient, thus being ready for deployment.

</p>
</details>

<details><summary><b>Large-width functional asymptotics for deep Gaussian neural networks</b>
<a href="https://arxiv.org/abs/2102.10307">arxiv:2102.10307</a>
&#x1F4C8; 3 <br>
<p>Daniele Bracale, Stefano Favaro, Sandra Fortini, Stefano Peluchetti</p></summary>
<p>

**Abstract:** In this paper, we consider fully connected feed-forward deep neural networks where weights and biases are independent and identically distributed according to Gaussian distributions. Extending previous results (Matthews et al., 2018a;b; Yang, 2019) we adopt a function-space perspective, i.e. we look at neural networks as infinite-dimensional random elements on the input space $\mathbb{R}^I$. Under suitable assumptions on the activation function we show that: i) a network defines a continuous Gaussian process on the input space $\mathbb{R}^I$; ii) a network with re-scaled weights converges weakly to a continuous Gaussian process in the large-width limit; iii) the limiting Gaussian process has almost surely locally $γ$-Hölder continuous paths, for $0 < γ<1$. Our results contribute to recent theoretical studies on the interplay between infinitely wide deep neural networks and Gaussian processes by establishing weak convergence in function-space with respect to a stronger metric.

</p>
</details>

<details><summary><b>Augmenting High-dimensional Nonlinear Optimization with Conditional GANs</b>
<a href="https://arxiv.org/abs/2103.04748">arxiv:2103.04748</a>
&#x1F4C8; 2 <br>
<p>Pouya Rezazadeh Kalehbasti, Michael D. Lepech, Samarpreet Singh Pandher</p></summary>
<p>

**Abstract:** Many mathematical optimization algorithms fail to sufficiently explore the solution space of high-dimensional nonlinear optimization problems due to the curse of dimensionality. This paper proposes generative models as a complement to optimization algorithms to improve performance in problems with high dimensionality. To demonstrate this method, a conditional generative adversarial network (C-GAN) is used to augment the solutions produced by a genetic algorithm (GA) for a 311-dimensional nonconvex multi-objective mixed-integer nonlinear optimization. The C-GAN, composed of two networks with three fully connected hidden layers, is trained on solutions generated by GA, and then given sets of desired labels (i.e., objective function values), generates complementary solutions corresponding to those labels. Six experiments are conducted to evaluate the capabilities of the proposed method. The generated complementary solutions are compared to the original solutions in terms of optimality and diversity. The generative model generates solutions with objective functions up to 100% better, and with hypervolumes up to 100% higher, than the original solutions. These findings show that a C-GAN with even a simple training approach and architecture can, with a much shorter runtime, highly improve the diversity and optimality of solutions found by an optimization algorithm for a high-dimensional nonlinear optimization problem. [Link to GitHub repository: https://github.com/PouyaREZ/GAN_GA]

</p>
</details>

<details><summary><b>Knowledge-Base Enriched Word Embeddings for Biomedical Domain</b>
<a href="https://arxiv.org/abs/2103.00479">arxiv:2103.00479</a>
&#x1F4C8; 2 <br>
<p>Kishlay Jha</p></summary>
<p>

**Abstract:** Word embeddings have been shown adept at capturing the semantic and syntactic regularities of the natural language text, as a result of which these representations have found their utility in a wide variety of downstream content analysis tasks. Commonly, these word embedding techniques derive the distributed representation of words based on the local context information. However, such approaches ignore the rich amount of explicit information present in knowledge-bases. This is problematic, as it might lead to poor representation for words with insufficient local context such as domain specific words. Furthermore, the problem becomes pronounced in domain such as bio-medicine where the presence of these domain specific words are relatively high. Towards this end, in this project, we propose a new word embedding based model for biomedical domain that jointly leverages the information from available corpora and domain knowledge in order to generate knowledge-base powered embeddings. Unlike existing approaches, the proposed methodology is simple but adept at capturing the precise knowledge available in domain resources in an accurate way. Experimental results on biomedical concept similarity and relatedness task validates the effectiveness of the proposed approach.

</p>
</details>

<details><summary><b>Learning Deep Features for Shape Correspondence with Domain Invariance</b>
<a href="https://arxiv.org/abs/2102.10493">arxiv:2102.10493</a>
&#x1F4C8; 2 <br>
<p>Praful Agrawal, Ross T. Whitaker, Shireen Y. Elhabian</p></summary>
<p>

**Abstract:** Correspondence-based shape models are key to various medical imaging applications that rely on a statistical analysis of anatomies. Such shape models are expected to represent consistent anatomical features across the population for population-specific shape statistics. Early approaches for correspondence placement rely on nearest neighbor search for simpler anatomies. Coordinate transformations for shape correspondence hold promise to address the increasing anatomical complexities. Nonetheless, due to the inherent shape-level geometric complexity and population-level shape variation, the coordinate-wise correspondence often does not translate to the anatomical correspondence. An alternative, group-wise approach for correspondence placement explicitly models the trade-off between geometric description and the population's statistical compactness. However, these models achieve limited success in resolving nonlinear shape correspondence. Recent works have addressed this limitation by adopting an application-specific notion of correspondence through lifting positional data to a higher dimensional feature space. However, they heavily rely on manual expertise to create domain-specific features and consistent landmarks. This paper proposes an automated feature learning approach, using deep convolutional neural networks to extract correspondence-friendly features from shape ensembles. Further, an unsupervised domain adaptation scheme is introduced to augment the pretrained geometric features with new anatomies. Results on anatomical datasets of human scapula, femur, and pelvis bones demonstrate that features learned in supervised fashion show improved performance for correspondence estimation compared to the manual features. Further, unsupervised learning is demonstrated to learn complex anatomy features using the supervised domain adaptation from features learned on simpler anatomy.

</p>
</details>

<details><summary><b>Deep ReLU Networks Preserve Expected Length</b>
<a href="https://arxiv.org/abs/2102.10492">arxiv:2102.10492</a>
&#x1F4C8; 2 <br>
<p>Boris Hanin, Ryan Jeong, David Rolnick</p></summary>
<p>

**Abstract:** Assessing the complexity of functions computed by a neural network helps us understand how the network will learn and generalize. One natural measure of complexity is how the network distorts length - if the network takes a unit-length curve as input, what is the length of the resulting curve of outputs? It has been widely believed that this length grows exponentially in network depth. We prove that in fact this is not the case: the expected length distortion does not grow with depth, and indeed shrinks slightly, for ReLU networks with standard random initialization. We also generalize this result by proving upper bounds both for higher moments of the length distortion and for the distortion of higher-dimensional volumes. These theoretical results are corroborated by our experiments.

</p>
</details>

<details><summary><b>Scalable Balanced Training of Conditional Generative Adversarial Neural Networks on Image Data</b>
<a href="https://arxiv.org/abs/2102.10485">arxiv:2102.10485</a>
&#x1F4C8; 2 <br>
<p>Massimiliano Lupo Pasini, Vittorio Gabbi, Junqi Yin, Simona Perotto, Nouamane Laanait</p></summary>
<p>

**Abstract:** We propose a distributed approach to train deep convolutional generative adversarial neural network (DC-CGANs) models. Our method reduces the imbalance between generator and discriminator by partitioning the training data according to data labels, and enhances scalability by performing a parallel training where multiple generators are concurrently trained, each one of them focusing on a single data label. Performance is assessed in terms of inception score and image quality on MNIST, CIFAR10, CIFAR100, and ImageNet1k datasets, showing a significant improvement in comparison to state-of-the-art techniques to training DC-CGANs. Weak scaling is attained on all the four datasets using up to 1,000 processes and 2,000 NVIDIA V100 GPUs on the OLCF supercomputer Summit.

</p>
</details>

<details><summary><b>Trumpets: Injective Flows for Inference and Inverse Problems</b>
<a href="https://arxiv.org/abs/2102.10461">arxiv:2102.10461</a>
&#x1F4C8; 2 <br>
<p>Konik Kothari, AmirEhsan Khorashadizadeh, Maarten de Hoop, Ivan Dokmanić</p></summary>
<p>

**Abstract:** We propose injective generative models called Trumpets that generalize invertible normalizing flows. The proposed generators progressively increase dimension from a low-dimensional latent space. We demonstrate that Trumpets can be trained orders of magnitudes faster than standard flows while yielding samples of comparable or better quality. They retain many of the advantages of the standard flows such as training based on maximum likelihood and a fast, exact inverse of the generator. Since Trumpets are injective and have fast inverses, they can be effectively used for downstream Bayesian inference. To wit, we use Trumpet priors for maximum a posteriori estimation in the context of image reconstruction from compressive measurements, outperforming competitive baselines in terms of reconstruction quality and speed. We then propose an efficient method for posterior characterization and uncertainty quantification with Trumpets by taking advantage of the low-dimensional latent space.

</p>
</details>

<details><summary><b>Squeeze-and-Excitation Normalization for Automated Delineation of Head and Neck Primary Tumors in Combined PET and CT Images</b>
<a href="https://arxiv.org/abs/2102.10446">arxiv:2102.10446</a>
&#x1F4C8; 2 <br>
<p>Andrei Iantsen, Dimitris Visvikis, Mathieu Hatt</p></summary>
<p>

**Abstract:** Development of robust and accurate fully automated methods for medical image segmentation is crucial in clinical practice and radiomics studies. In this work, we contributed an automated approach for Head and Neck (H&N) primary tumor segmentation in combined positron emission tomography / computed tomography (PET/CT) images in the context of the MICCAI 2020 Head and Neck Tumor segmentation challenge (HECKTOR). Our model was designed on the U-Net architecture with residual layers and supplemented with Squeeze-and-Excitation Normalization. The described method achieved competitive results in cross-validation (DSC 0.745, precision 0.760, recall 0.789) performed on different centers, as well as on the test set (DSC 0.759, precision 0.833, recall 0.740) that allowed us to win first prize in the HECKTOR challenge among 21 participating teams. The full implementation based on PyTorch and the trained models are available at https://github.com/iantsen/hecktor

</p>
</details>

<details><summary><b>VisualGPT: Data-efficient Adaptation of Pretrained Language Models for Image Captioning</b>
<a href="https://arxiv.org/abs/2102.10407">arxiv:2102.10407</a>
&#x1F4C8; 2 <br>
<p>Jun Chen, Han Guo, Kai Yi, Boyang Li, Mohamed Elhoseiny</p></summary>
<p>

**Abstract:** The ability to quickly learn from a small quantity oftraining data widens the range of machine learning applications. In this paper, we propose a data-efficient image captioning model, VisualGPT, which leverages the linguistic knowledge from a large pretrained language model(LM). A crucial challenge is to balance between the use of visual information in the image and prior linguistic knowledge acquired from pretraining. We designed a novel self-resurrecting encoder-decoder attention mechanism to quickly adapt the pretrained LM as the language decoder ona small amount of in-domain training data. The proposed self-resurrecting activation unit produces sparse activations but has reduced susceptibility to zero gradients. We train the proposed model, VisualGPT, on 0.1%, 0.5% and 1% of MSCOCO and Conceptual Captions training data. Under these conditions, we outperform the best baseline model by up to 10.8% CIDEr on MS COCO and upto 5.4% CIDEr on Conceptual Captions. Further, Visual-GPT achieves the state-of-the-art result on IU X-ray, a medical report generation dataset. To the best of our knowledge, this is the first work that improves data efficiency of image captioning by utilizing LM pretrained on unimodal data. Our code is available at: https://github.com/Vision-CAIR/VisualGPT.

</p>
</details>

<details><summary><b>Inverse Design of Quantum Holograms in Three-Dimensional Nonlinear Photonic Crystals</b>
<a href="https://arxiv.org/abs/2102.10344">arxiv:2102.10344</a>
&#x1F4C8; 2 <br>
<p>Eyal Rozenberg, Aviv Karnieli, Ofir Yesharim, Sivan Trajtenberg-Mills, Daniel Freedman, Alex M. Bronstein, Ady Arie</p></summary>
<p>

**Abstract:** We introduce a systematic approach for designing 3D nonlinear photonic crystals and pump beams for generating desired quantum correlations between structured photon-pairs. Our model is fully differentiable, allowing accurate and efficient learning and discovery of novel designs.

</p>
</details>

<details><summary><b>Physical Reasoning Using Dynamics-Aware Models</b>
<a href="https://arxiv.org/abs/2102.10336">arxiv:2102.10336</a>
&#x1F4C8; 2 <br>
<p>Eltayeb Ahmed, Anton Bakhtin, Laurens van der Maaten, Rohit Girdhar</p></summary>
<p>

**Abstract:** A common approach to solving physical reasoning tasks is to train a value learner on example tasks. A limitation of such an approach is that it requires learning about object dynamics solely from reward values assigned to the final state of a rollout of the environment. This study aims to address this limitation by augmenting the reward value with self-supervised signals about object dynamics. Specifically, we train the model to characterize the similarity of two environment rollouts, jointly with predicting the outcome of the reasoning task. This similarity can be defined as a distance measure between the trajectory of objects in the two rollouts, or learned directly from pixels using a contrastive formulation. Empirically, we find that this approach leads to substantial performance improvements on the PHYRE benchmark for physical reasoning (Bakhtin et al., 2019), establishing a new state-of-the-art.

</p>
</details>

<details><summary><b>Learnable MFCCs for Speaker Verification</b>
<a href="https://arxiv.org/abs/2102.10322">arxiv:2102.10322</a>
&#x1F4C8; 2 <br>
<p>Xuechen Liu, Md Sahidullah, Tomi Kinnunen</p></summary>
<p>

**Abstract:** We propose a learnable mel-frequency cepstral coefficient (MFCC) frontend architecture for deep neural network (DNN) based automatic speaker verification. Our architecture retains the simplicity and interpretability of MFCC-based features while allowing the model to be adapted to data flexibly. In practice, we formulate data-driven versions of the four linear transforms of a standard MFCC extractor -- windowing, discrete Fourier transform (DFT), mel filterbank and discrete cosine transform (DCT). Results reported reach up to 6.7\% (VoxCeleb1) and 9.7\% (SITW) relative improvement in term of equal error rate (EER) from static MFCCs, without additional tuning effort.

</p>
</details>

<details><summary><b>GroupifyVAE: from Group-based Definition to VAE-based Unsupervised Representation Disentanglement</b>
<a href="https://arxiv.org/abs/2102.10303">arxiv:2102.10303</a>
&#x1F4C8; 2 <br>
<p>Tao Yang, Xuanchi Ren, Yuwang Wang, Wenjun Zeng, Nanning Zheng, Pengju Ren</p></summary>
<p>

**Abstract:** The key idea of the state-of-the-art VAE-based unsupervised representation disentanglement methods is to minimize the total correlation of the latent variable distributions. However, it has been proved that VAE-based unsupervised disentanglement can not be achieved without introducing other inductive bias. In this paper, we address VAE-based unsupervised disentanglement by leveraging the constraints derived from the Group Theory based definition as the non-probabilistic inductive bias. More specifically, inspired by the nth dihedral group (the permutation group for regular polygons), we propose a specific form of the definition and prove its two equivalent conditions: isomorphism and "the constancy of permutations". We further provide an implementation of isomorphism based on two Group constraints: the Abel constraint for the exchangeability and Order constraint for the cyclicity. We then convert them into a self-supervised training loss that can be incorporated into VAE-based models to bridge their gaps from the Group Theory based definition. We train 1800 models covering the most prominent VAE-based models on five datasets to verify the effectiveness of our method. Compared to the original models, the Groupidied VAEs consistently achieve better mean performance with smaller variances, and make meaningful dimensions controllable.

</p>
</details>

<details><summary><b>Artificial Intelligence Enhanced Rapid and Efficient Diagnosis of Mycoplasma Pneumoniae Pneumonia in Children Patients</b>
<a href="https://arxiv.org/abs/2102.10284">arxiv:2102.10284</a>
&#x1F4C8; 2 <br>
<p>Chenglin Pan, Kuan Yan, Xiao Liu, Yanjie Chen, Yanyan Luo, Xiaoming Li, Zhenguo Nie, Xinjun Liu</p></summary>
<p>

**Abstract:** Artificial intelligence methods have been increasingly turning into a potentially powerful tool in the diagnosis and management of diseases. In this study, we utilized logistic regression (LR), decision tree (DT), gradient boosted decision tree (GBDT), support vector machine (SVM), and multilayer perceptron (MLP) as machine learning models to rapidly diagnose the mycoplasma pneumoniae pneumonia (MPP) in children patients. The classification task was carried out after applying the preprocessing procedure to the MPP dataset. The most efficient results are obtained by GBDT. It provides the best performance with an accuracy of 93.7%. In contrast to standard raw feature weighting, the feature importance takes the underlying correlation structure of the features into account. The most crucial feature of GBDT is the "pulmonary infiltrates range" with a score of 0.5925, followed by "cough" (0.0953) and "pleural effusion" (0.0492). We publicly share our full implementation with the dataset and trained models at https://github.com/zhenguonie/2021_AI4MPP.

</p>
</details>

<details><summary><b>Inducing a hierarchy for multi-class classification problems</b>
<a href="https://arxiv.org/abs/2102.10263">arxiv:2102.10263</a>
&#x1F4C8; 2 <br>
<p>Hayden S. Helm, Weiwei Yang, Sujeeth Bharadwaj, Kate Lytvynets, Oriana Riva, Christopher White, Ali Geisa, Carey E. Priebe</p></summary>
<p>

**Abstract:** In applications where categorical labels follow a natural hierarchy, classification methods that exploit the label structure often outperform those that do not. Un-fortunately, the majority of classification datasets do not come pre-equipped with a hierarchical structure and classical flat classifiers must be employed. In this paper, we investigate a class of methods that induce a hierarchy that can similarly improve classification performance over flat classifiers. The class of methods follows the structure of first clustering the conditional distributions and subsequently using a hierarchical classifier with the induced hierarchy. We demonstrate the effectiveness of the class of methods both for discovering a latent hierarchy and for improving accuracy in principled simulation settings and three real data applications.

</p>
</details>

<details><summary><b>Bayesian adversarial multi-node bandit for optimal smart grid protection against cyber attacks</b>
<a href="https://arxiv.org/abs/2104.02774">arxiv:2104.02774</a>
&#x1F4C8; 1 <br>
<p>Jianyu Xu, Bin Liu, Huadong Mo, Daoyi Dong</p></summary>
<p>

**Abstract:** The cybersecurity of smart grids has become one of key problems in developing reliable modern power and energy systems. This paper introduces a non-stationary adversarial cost with a variation constraint for smart grids and enables us to investigate the problem of optimal smart grid protection against cyber attacks in a relatively practical scenario. In particular, a Bayesian multi-node bandit (MNB) model with adversarial costs is constructed and a new regret function is defined for this model. An algorithm called Thompson-Hedge algorithm is presented to solve the problem and the superior performance of the proposed algorithm is proven in terms of the convergence rate of the regret function. The applicability of the algorithm to real smart grid scenarios is verified and the performance of the algorithm is also demonstrated by numerical examples.

</p>
</details>

<details><summary><b>Info-Evo: Using Information Geometry to Guide Evolutionary Program Learning</b>
<a href="https://arxiv.org/abs/2103.04747">arxiv:2103.04747</a>
&#x1F4C8; 1 <br>
<p>Ben Goertzel</p></summary>
<p>

**Abstract:** A novel optimization strategy, Info-Evo, is described, in which natural gradient search using nonparametric Fisher information is used to provide ongoing guidance to an evolutionary learning algorithm, so that the evolutionary process preferentially moves in the directions identified as "shortest paths" according to the natural gradient. Some specifics regarding the application of this approach to automated program learning are reviewed, including a strategy for integrating Info-Evo into the MOSES program learning framework.

</p>
</details>

<details><summary><b>Fast On-Device Adaptation for Spiking Neural Networks via Online-Within-Online Meta-Learning</b>
<a href="https://arxiv.org/abs/2103.03901">arxiv:2103.03901</a>
&#x1F4C8; 1 <br>
<p>Bleema Rosenfeld, Bipin Rajendran, Osvaldo Simeone</p></summary>
<p>

**Abstract:** Spiking Neural Networks (SNNs) have recently gained popularity as machine learning models for on-device edge intelligence for applications such as mobile healthcare management and natural language processing due to their low power profile. In such highly personalized use cases, it is important for the model to be able to adapt to the unique features of an individual with only a minimal amount of training data. Meta-learning has been proposed as a way to train models that are geared towards quick adaptation to new tasks. The few existing meta-learning solutions for SNNs operate offline and require some form of backpropagation that is incompatible with the current neuromorphic edge-devices. In this paper, we propose an online-within-online meta-learning rule for SNNs termed OWOML-SNN, that enables lifelong learning on a stream of tasks, and relies on local, backprop-free, nested updates.

</p>
</details>

<details><summary><b>Sequence-based deep learning antibody design for in silico antibody affinity maturation</b>
<a href="https://arxiv.org/abs/2103.03724">arxiv:2103.03724</a>
&#x1F4C8; 1 <br>
<p>Yue Kang, Dawei Leng, Jinjiang Guo, Lurong Pan</p></summary>
<p>

**Abstract:** Antibody therapeutics has been extensively studied in drug discovery and development within the past decades. One increasingly popular focus in the antibody discovery pipeline is the optimization step for therapeutic leads. Both traditional methods and in silico approaches aim to generate candidates with high binding affinity against specific target antigens. Traditional in vitro approaches use hybridoma or phage display for candidate selection, and surface plasmon resonance (SPR) for evaluation, while in silico computational approaches aim to reduce the high cost and improve efficiency by incorporating mathematical algorithms and computational processing power in the design process. In the present study, we investigated different graph-based designs for depicting antibody-antigen interactions in terms of antibody affinity prediction using deep learning techniques. While other in silico computations require experimentally determined crystal structures, our study took interest in the capability of sequence-based models for in silico antibody maturation. Our preliminary studies achieved satisfying prediction accuracy on binding affinities comparing to conventional approaches and other deep learning approaches. To further study the antibody-antigen binding specificity, and to simulate the optimization process in real-world scenario, we introduced pairwise prediction strategy. We performed analysis based on both baseline and pairwise prediction results. The resulting prediction and efficiency prove the feasibility and computational efficiency of sequence-based method to be adapted as a scalable industry practice.

</p>
</details>

<details><summary><b>PySensors: A Python Package for Sparse Sensor Placement</b>
<a href="https://arxiv.org/abs/2102.13476">arxiv:2102.13476</a>
&#x1F4C8; 1 <br>
<p>Brian M. de Silva, Krithika Manohar, Emily Clark, Bingni W. Brunton, Steven L. Brunton, J. Nathan Kutz</p></summary>
<p>

**Abstract:** PySensors is a Python package for selecting and placing a sparse set of sensors for classification and reconstruction tasks. Specifically, PySensors implements algorithms for data-driven sparse sensor placement optimization for reconstruction (SSPOR) and sparse sensor placement optimization for classification (SSPOC). In this work we provide a brief description of the mathematical algorithms and theory for sparse sensor optimization, along with an overview and demonstration of the features implemented in PySensors (with code examples). We also include practical advice for user and a list of potential extensions to PySensors. Software is available at https://github.com/dynamicslab/pysensors.

</p>
</details>

<details><summary><b>A Comprehensive Review on the NILM Algorithms for Energy Disaggregation</b>
<a href="https://arxiv.org/abs/2102.12578">arxiv:2102.12578</a>
&#x1F4C8; 1 <br>
<p>Akriti Verma, Adnan Anwar, M. A. Parvez Mahmud, Mohiuddin Ahmed, Abbas Kouzani</p></summary>
<p>

**Abstract:** The housing structures have changed with urbanization and the growth due to the construction of high-rise buildings all around the world requires end-use appliance energy conservation and management in real-time. This shift also came along with smart-meters which enabled the estimation of appliance-specific power consumption from the buildings aggregate power consumption reading. Non-intrusive load monitoring (NILM) or energy disaggregation is aimed at separating the household energy measured at the aggregate level into constituent appliances. Over the years, signal processing and machine learning algorithms have been combined to achieve this. Incredible research and publications have been conducted on energy disaggregation, non-intrusive load monitoring, home energy management and appliance classification. There exists an API, NILMTK, a reproducible benchmark algorithm for the same. Many other approaches to perform energy disaggregation has been adapted such as deep neural network architectures and big data approach for household energy disaggregation. This paper provides a survey of the effective NILM system frameworks and reviews the performance of the benchmark algorithms in a comprehensive manner. This paper also summarizes the wide application scope and the effectiveness of the algorithmic performance on three publicly available data sets.

</p>
</details>

<details><summary><b>A Sketching Method for Finding the Closest Point on a Convex Hull</b>
<a href="https://arxiv.org/abs/2102.10502">arxiv:2102.10502</a>
&#x1F4C8; 1 <br>
<p>Roozbeh Yousefzadeh</p></summary>
<p>

**Abstract:** We develop a sketching algorithm to find the point on the convex hull of a dataset, closest to a query point outside it. Studying the convex hull of datasets can provide useful information about their geometric structure and their distribution. Many machine learning datasets have large number of samples with large number of features, but exact algorithms in computational geometry are usually not designed for such setting. Alternatively, the problem can be formulated as a linear least-squares problem with linear constraints. However, solving the problem using standard optimization algorithms can be very expensive for large datasets. Our algorithm uses a sketching procedure to exploit the structure of the data and unburden the optimization process from irrelevant points. This involves breaking the data into pieces and gradually putting the pieces back together, while improving the optimal solution using a gradient project method that can rapidly change its active set of constraints. Our method eventually leads to the optimal solution of our convex problem faster than off-the-shelf algorithms.

</p>
</details>

<details><summary><b>Social Networks Analysis to Retrieve Critical Comments on Online Platforms</b>
<a href="https://arxiv.org/abs/2102.10495">arxiv:2102.10495</a>
&#x1F4C8; 1 <br>
<p>Shova Bhandari, Rini Raju</p></summary>
<p>

**Abstract:** Social networks are rich source of data to analyze user habits in all aspects of life. User's behavior is decisive component of a health system in various countries. Promoting good behavior can improve the public health significantly. In this work, we develop a new model for social network analysis by using text analysis approach. We define each user reaction to global pandemic with analyzing his online behavior. Clustering a group of online users with similar habits, help to find how virus spread in different societies. Promoting the healthy life style in the high risk online users of social media have significant effect on public health and reducing the effect of global pandemic. In this work, we introduce a new approach to clustering habits based on user activities on social media in the time of pandemic and recommend a machine learning model to promote health in the online platforms.

</p>
</details>

<details><summary><b>Neural Sampling Machine with Stochastic Synapse allows Brain-like Learning and Inference</b>
<a href="https://arxiv.org/abs/2102.10477">arxiv:2102.10477</a>
&#x1F4C8; 1 <br>
<p>Sourav Dutta, Georgios Detorakis, Abhishek Khanna, Benjamin Grisafe, Emre Neftci, Suman Datta</p></summary>
<p>

**Abstract:** Many real-world mission-critical applications require continual online learning from noisy data and real-time decision making with a defined confidence level. Probabilistic models and stochastic neural networks can explicitly handle uncertainty in data and allow adaptive learning-on-the-fly, but their implementation in a low-power substrate remains a challenge. Here, we introduce a novel hardware fabric that implements a new class of stochastic NN called Neural-Sampling-Machine that exploits stochasticity in synaptic connections for approximate Bayesian inference. Harnessing the inherent non-linearities and stochasticity occurring at the atomic level in emerging materials and devices allows us to capture the synaptic stochasticity occurring at the molecular level in biological synapses. We experimentally demonstrate in-silico hybrid stochastic synapse by pairing a ferroelectric field-effect transistor -based analog weight cell with a two-terminal stochastic selector element. Such a stochastic synapse can be integrated within the well-established crossbar array architecture for compute-in-memory. We experimentally show that the inherent stochastic switching of the selector element between the insulator and metallic state introduces a multiplicative stochastic noise within the synapses of NSM that samples the conductance states of the FeFET, both during learning and inference. We perform network-level simulations to highlight the salient automatic weight normalization feature introduced by the stochastic synapses of the NSM that paves the way for continual online learning without any offline Batch Normalization. We also showcase the Bayesian inferencing capability introduced by the stochastic synapse during inference mode, thus accounting for uncertainty in data. We report 98.25%accuracy on standard image classification task as well as estimation of data uncertainty in rotated samples.

</p>
</details>

<details><summary><b>Efficient Learning of Non-Interacting Fermion Distributions</b>
<a href="https://arxiv.org/abs/2102.10458">arxiv:2102.10458</a>
&#x1F4C8; 1 <br>
<p>Scott Aaronson, Sabee Grewal</p></summary>
<p>

**Abstract:** We give an efficient classical algorithm that recovers the distribution of a non-interacting fermion state over the computational basis. For a system of $n$ non-interacting fermions and $m$ modes, we show that $O(m^2 n^4 \log(m/δ)/ \varepsilon^4)$ samples and $O(m^4 n^4 \log(m/δ)/ \varepsilon^4)$ time are sufficient to learn the original distribution to total variation distance $\varepsilon$ with probability $1 - δ$. Our algorithm empirically estimates the one- and two-mode correlations and uses them to reconstruct a succinct description of the entire distribution efficiently.

</p>
</details>

<details><summary><b>MHDeep: Mental Health Disorder Detection System based on Body-Area and Deep Neural Networks</b>
<a href="https://arxiv.org/abs/2102.10435">arxiv:2102.10435</a>
&#x1F4C8; 1 <br>
<p>Shayan Hassantabar, Joe Zhang, Hongxu Yin, Niraj K. Jha</p></summary>
<p>

**Abstract:** Mental health problems impact quality of life of millions of people around the world. However, diagnosis of mental health disorders is a challenging problem that often relies on self-reporting by patients about their behavioral patterns. Therefore, there is a need for new strategies for diagnosis of mental health problems. The recent introduction of body-area networks consisting of a plethora of accurate sensors embedded in smartwatches and smartphones and deep neural networks (DNNs) points towards a possible solution. However, disease diagnosis based on WMSs and DNNs, and their deployment on edge devices, remains a challenging problem. To this end, we propose a framework called MHDeep that utilizes commercially available WMSs and efficient DNN models to diagnose three important mental health disorders: schizoaffective, major depressive, and bipolar. MHDeep uses eight different categories of data obtained from sensors integrated in a smartwatch and smartphone. Due to limited available data, MHDeep uses a synthetic data generation module to augment real data with synthetic data drawn from the same probability distribution. We use the synthetic dataset to pre-train the DNN models, thus imposing a prior on the weights. We use a grow-and-prune DNN synthesis approach to learn both the architecture and weights during the training process. We use three different data partitions to evaluate the MHDeep models trained with data collected from 74 individuals. We conduct data instance level and patient level evaluations. MHDeep achieves an average test accuracy of 90.4%, 87.3%, and 82.4%, respectively, for classifications between healthy instances and schizoaffective disorder instances, major depressive disorder instances, and bipolar disorder instances. At the patient level, MHDeep DNNs achieve an accuracy of 100%, 100%, and 90.0% for the three mental health disorders, respectively.

</p>
</details>

<details><summary><b>Towards Teachable Conversational Agents</b>
<a href="https://arxiv.org/abs/2102.10387">arxiv:2102.10387</a>
&#x1F4C8; 1 <br>
<p>Nalin Chhibber, Edith Law</p></summary>
<p>

**Abstract:** The traditional process of building interactive machine learning systems can be viewed as a teacher-learner interaction scenario where the machine-learners are trained by one or more human-teachers. In this work, we explore the idea of using a conversational interface to investigate the interaction between human-teachers and interactive machine-learners. Specifically, we examine whether teachable AI agents can reliably learn from human-teachers through conversational interactions, and how this learning compare with traditional supervised learning algorithms. Results validate the concept of teachable conversational agents and highlight the factors relevant for the development of machine learning systems that intend to learn from conversational interactions.

</p>
</details>

<details><summary><b>WaNet -- Imperceptible Warping-based Backdoor Attack</b>
<a href="https://arxiv.org/abs/2102.10369">arxiv:2102.10369</a>
&#x1F4C8; 1 <br>
<p>Anh Nguyen, Anh Tran</p></summary>
<p>

**Abstract:** With the thriving of deep learning and the widespread practice of using pre-trained networks, backdoor attacks have become an increasing security threat drawing many research interests in recent years. A third-party model can be poisoned in training to work well in normal conditions but behave maliciously when a trigger pattern appears. However, the existing backdoor attacks are all built on noise perturbation triggers, making them noticeable to humans. In this paper, we instead propose using warping-based triggers. The proposed backdoor outperforms the previous methods in a human inspection test by a wide margin, proving its stealthiness. To make such models undetectable by machine defenders, we propose a novel training mode, called the ``noise mode. The trained networks successfully attack and bypass the state-of-the-art defense methods on standard classification datasets, including MNIST, CIFAR-10, GTSRB, and CelebA. Behavior analyses show that our backdoors are transparent to network inspection, further proving this novel attack mechanism's efficiency.

</p>
</details>

<details><summary><b>Deep Learning-based Power Control for Cell-Free Massive MIMO Networks</b>
<a href="https://arxiv.org/abs/2102.10366">arxiv:2102.10366</a>
&#x1F4C8; 1 <br>
<p>Nuwanthika Rajapaksha, K. B. Shashika Manosha, Nandana Rajatheva, Matti Latva-aho</p></summary>
<p>

**Abstract:** A deep learning (DL)-based power control algorithm that solves the max-min user fairness problem in a cell-free massive multiple-input multiple-output (MIMO) system is proposed. Max-min rate optimization problem in a cell-free massive MIMO uplink setup is formulated, where user power allocations are optimized in order to maximize the minimum user rate. Instead of modeling the problem using mathematical optimization theory, and solving it with iterative algorithms, our proposed solution approach is using DL. Specifically, we model a deep neural network (DNN) and train it in an unsupervised manner to learn the optimum user power allocations which maximize the minimum user rate. This novel unsupervised learning-based approach does not require optimal power allocations to be known during model training as in previously used supervised learning techniques, hence it has a simpler and flexible model training stage. Numerical results show that the proposed DNN achieves a performance-complexity trade-off with around 400 times faster implementation and comparable performance to the optimization-based algorithm. An online learning stage is also introduced, which results in near-optimal performance with 4-6 times faster processing.

</p>
</details>

<details><summary><b>Everything is Relative: Understanding Fairness with Optimal Transport</b>
<a href="https://arxiv.org/abs/2102.10349">arxiv:2102.10349</a>
&#x1F4C8; 1 <br>
<p>Kweku Kwegyir-Aggrey, Rebecca Santorella, Sarah M. Brown</p></summary>
<p>

**Abstract:** To study discrimination in automated decision-making systems, scholars have proposed several definitions of fairness, each expressing a different fair ideal. These definitions require practitioners to make complex decisions regarding which notion to employ and are often difficult to use in practice since they make a binary judgement a system is fair or unfair instead of explaining the structure of the detected unfairness. We present an optimal transport-based approach to fairness that offers an interpretable and quantifiable exploration of bias and its structure by comparing a pair of outcomes to one another. In this work, we use the optimal transport map to examine individual, subgroup, and group fairness. Our framework is able to recover well known examples of algorithmic discrimination, detect unfairness when other metrics fail, and explore recourse opportunities.

</p>
</details>

<details><summary><b>Automated identification of transiting exoplanet candidates in NASA Transiting Exoplanets Survey Satellite (TESS) data with machine learning methods</b>
<a href="https://arxiv.org/abs/2102.10326">arxiv:2102.10326</a>
&#x1F4C8; 1 <br>
<p>Leon Ofman, Amir Averbuch, Adi Shliselberg, Idan Benaun, David Segev, Aron Rissman</p></summary>
<p>

**Abstract:** A novel artificial intelligence (AI) technique that uses machine learning (ML) methodologies combines several algorithms, which were developed by ThetaRay, Inc., is applied to NASA's Transiting Exoplanets Survey Satellite (TESS) dataset to identify exoplanetary candidates. The AI/ML ThetaRay system is trained initially with Kepler exoplanetary data and validated with confirmed exoplanets before its application to TESS data. Existing and new features of the data, based on various observational parameters, are constructed and used in the AI/ML analysis by employing semi-supervised and unsupervised machine learning techniques. By the application of ThetaRay system to 10,803 light curves of threshold crossing events (TCEs) produced by the TESS mission, obtained from the Mikulski Archive for Space Telescopes, the algorithm yields about 50 targets for further analysis, and we uncover three new exoplanetary candidates by further manual vetting. This study demonstrates for the first time the successful application of the particular combined multiple AI/ML-based methodologies to a large astrophysical dataset for rapid automated classification of TCEs.

</p>
</details>

<details><summary><b>Versatile and Robust Transient Stability Assessment via Instance Transfer Learning</b>
<a href="https://arxiv.org/abs/2102.10296">arxiv:2102.10296</a>
&#x1F4C8; 1 <br>
<p>Seyedali Meghdadi, Guido Tack, Ariel Liebman, Nicolas Langrené, Christoph Bergmeir</p></summary>
<p>

**Abstract:** To support N-1 pre-fault transient stability assessment, this paper introduces a new data collection method in a data-driven algorithm incorporating the knowledge of power system dynamics. The domain knowledge on how the disturbance effect will propagate from the fault location to the rest of the network is leveraged to recognise the dominant conditions that determine the stability of a system. Accordingly, we introduce a new concept called Fault-Affected Area, which provides crucial information regarding the unstable region of operation. This information is embedded in an augmented dataset to train an ensemble model using an instance transfer learning framework. The test results on the IEEE 39-bus system verify that this model can accurately predict the stability of previously unseen operational scenarios while reducing the risk of false prediction of unstable instances compared to standard approaches.

</p>
</details>

<details><summary><b>When Crowdsensing Meets Federated Learning: Privacy-Preserving Mobile Crowdsensing System</b>
<a href="https://arxiv.org/abs/2102.10109">arxiv:2102.10109</a>
&#x1F4C8; 1 <br>
<p>Bowen Zhao, Ximeng Liu, Wei-neng Chen</p></summary>
<p>

**Abstract:** Mobile crowdsensing (MCS) is an emerging sensing data collection pattern with scalability, low deployment cost, and distributed characteristics. Traditional MCS systems suffer from privacy concerns and fair reward distribution. Moreover, existing privacy-preserving MCS solutions usually focus on the privacy protection of data collection rather than that of data processing. To tackle faced problems of MCS, in this paper, we integrate federated learning (FL) into MCS and propose a privacy-preserving MCS system, called \textsc{CrowdFL}. Specifically, in order to protect privacy, participants locally process sensing data via federated learning and only upload encrypted training models. Particularly, a privacy-preserving federated averaging algorithm is proposed to average encrypted training models. To reduce computation and communication overhead of restraining dropped participants, discard and retransmission strategies are designed. Besides, a privacy-preserving posted pricing incentive mechanism is designed, which tries to break the dilemma of privacy protection and data evaluation. Theoretical analysis and experimental evaluation on a practical MCS application demonstrate the proposed \textsc{CrowdFL} can effectively protect participants privacy and is feasible and efficient.

</p>
</details>

<details><summary><b>Stronger NAS with Weaker Predictors</b>
<a href="https://arxiv.org/abs/2102.10490">arxiv:2102.10490</a>
&#x1F4C8; 0 <br>
<p>Junru Wu, Xiyang Dai, Dongdong Chen, Yinpeng Chen, Mengchen Liu, Ye Yu, Zhangyang Wang, Zicheng Liu, Mei Chen, Lu Yuan</p></summary>
<p>

**Abstract:** Neural Architecture Search (NAS) often trains and evaluates a large number of architectures. Recent predictor-based NAS approaches attempt to alleviate such heavy computation costs with two key steps: sampling some architecture-performance pairs and fitting a proxy accuracy predictor. Given limited samples, these predictors, however, are far from accurate to locate top architectures due to the difficulty of fitting the huge search space. This paper reflects on a simple yet crucial question: if our final goal is to find the best architecture, do we really need to model the whole space well?. We propose a paradigm shift from fitting the whole architecture space using one strong predictor, to progressively fitting a search path towards the high-performance sub-space through a set of weaker predictors. As a key property of the weak predictors, their probabilities of sampling better architectures keep increasing. Hence we only sample a few well-performed architectures guided by the previously learned predictor and estimate a new better weak predictor. This embarrassingly easy framework, dubbed WeakNAS, produces coarse-to-fine iteration to gradually refine the ranking of sampling space. Extensive experiments demonstrate that WeakNAS costs fewer samples to find top-performance architectures on NAS-Bench-101 and NAS-Bench-201. Compared to state-of-the-art (SOTA) predictor-based NAS methods, WeakNAS outperforms all with notable margins, e.g., requiring at least 7.5x less samples to find global optimal on NAS-Bench-101. WeakNAS can also absorb their ideas to boost performance more. Further, WeakNAS strikes the new SOTA result of 81.3% in the ImageNet MobileNet Search Space. The code is available at https://github.com/VITA-Group/WeakNAS.

</p>
</details>

<details><summary><b>Open-Ended Automatic Programming Through Combinatorial Evolution</b>
<a href="https://arxiv.org/abs/2102.10475">arxiv:2102.10475</a>
&#x1F4C8; 0 <br>
<p>Sebastian Fix, Thomas Probst, Oliver Ruggli, Thomas Hanne, Patrik Christen</p></summary>
<p>

**Abstract:** Combinatorial evolution - the creation of new things through the combination of existing things - can be a powerful way to evolve rather than design technical objects such as electronic circuits. Intriguingly, this seems to be an ongoing and thus open-ended process creating novelty with increasing complexity. Here, we employ combinatorial evolution in software development. While current approaches such as genetic programming are efficient in solving particular problems, they all converge towards a solution and do not create anything new anymore afterwards. Combinatorial evolution of complex systems such as languages and technology are considered open-ended. Therefore, open-ended automatic programming might be possible through combinatorial evolution. We implemented a computer program simulating combinatorial evolution of code blocks stored in a database to make them available for combining. Automatic programming in the sense of algorithm-based code generation is achieved by evaluating regular expressions. We found that reserved keywords of a programming language are suitable for defining the basic code blocks at the beginning of the simulation. We also found that placeholders can be used to combine code blocks and that code complexity can be described in terms of the importance to the programming language. As in a previous combinatorial evolution simulation of electronic circuits, complexity increased from simple keywords and special characters to more complex variable declarations, class definitions, methods, and classes containing methods and variable declarations. Combinatorial evolution, therefore, seems to be a promising approach for open-ended automatic programming.

</p>
</details>

<details><summary><b>Factored Policy Gradients: Leveraging Structure for Efficient Learning in MOMDPs</b>
<a href="https://arxiv.org/abs/2102.10362">arxiv:2102.10362</a>
&#x1F4C8; 0 <br>
<p>Thomas Spooner, Nelson Vadori, Sumitra Ganesh</p></summary>
<p>

**Abstract:** Policy gradient methods can solve complex tasks but often fail when the dimensionality of the action-space or objective multiplicity grow very large. This occurs, in part, because the variance on score-based gradient estimators scales quadratically. In this paper, we address this problem through a factor baseline which exploits independence structure encoded in a novel action-target influence network. Factored policy gradients (FPGs), which follow, provide a common framework for analysing key state-of-the-art algorithms, are shown to generalise traditional policy gradients, and yield a principled way of incorporating prior knowledge of a problem domain's generative processes. We provide an analysis of the proposed estimator and identify the conditions under which variance is reduced. The algorithmic aspects of FPGs are discussed, including optimal policy factorisation, as characterised by minimum biclique coverings, and the implications for the bias-variance trade-off of incorrectly specifying the network. Finally, we demonstrate the performance advantages of our algorithm on large-scale bandit and traffic intersection problems, providing a novel contribution to the latter in the form of a spatial approximation.

</p>
</details>

<details><summary><b>SSFG: Stochastically Scaling Features and Gradients for Regularizing Graph Convolutional Networks</b>
<a href="https://arxiv.org/abs/2102.10338">arxiv:2102.10338</a>
&#x1F4C8; 0 <br>
<p>Haimin Zhang, Min Xu, Guoqiang Zhang, Kenta Niwa</p></summary>
<p>

**Abstract:** Graph convolutional networks have been successfully applied in various graph-based tasks. In a typical graph convolutional layer, node features are updated by aggregating neighborhood information. Repeatedly applying graph convolutions can cause the oversmoothing issue, i.e., node features at deep layers converge to similar values. Previous studies have suggested that oversmoothing is one of the major issues that restrict the performance of graph convolutional networks. In this paper, we propose a stochastic regularization method to tackle the oversmoothing problem. In the proposed method, we stochastically scale features and gradients (SSFG) by a factor sampled from a probability distribution in the training procedure. By explicitly applying a scaling factor to break feature convergence, the oversmoothing issue is alleviated. We show that applying stochastic scaling at the gradient level is complementary to that applied at the feature level to improve the overall performance. Our method does not increase the number of trainable parameters. When used together with ReLU, our SSFG can be seen as a stochastic ReLU activation function. We experimentally validate our SSFG regularization method on three commonly used types of graph networks. Extensive experimental results on seven benchmark datasets for four graph-based tasks demonstrate that our SSFG regularization is effective in improving the overall performance of the baseline graph networks.

</p>
</details>


{% endraw %}
Prev: [2021.02.19]({{ '/2021/02/19/2021.02.19.html' | relative_url }})  Next: [2021.02.21]({{ '/2021/02/21/2021.02.21.html' | relative_url }})