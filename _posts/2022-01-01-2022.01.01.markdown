Prev: [2021.12.31]({{ '/2021/12/31/2021.12.31.html' | relative_url }})  Next: [2022.01.02]({{ '/2022/01/02/2022.01.02.html' | relative_url }})
{% raw %}
## Summary for 2022-01-01, created on 2022-01-11


<details><summary><b>Matrix Decomposition and Applications</b>
<a href="https://arxiv.org/abs/2201.00145">arxiv:2201.00145</a>
&#x1F4C8; 87 <br>
<p>Jun Lu</p></summary>
<p>

**Abstract:** In 1954, Alston S. Householder published Principles of Numerical Analysis, one of the first modern treatments on matrix decomposition that favored a (block) LU decomposition-the factorization of a matrix into the product of lower and upper triangular matrices. And now, matrix decomposition has become a core technology in machine learning, largely due to the development of the back propagation algorithm in fitting a neural network. The sole aim of this survey is to give a self-contained introduction to concepts and mathematical tools in numerical linear algebra and matrix analysis in order to seamlessly introduce matrix decomposition techniques and their applications in subsequent sections. However, we clearly realize our inability to cover all the useful and interesting results concerning matrix decomposition and given the paucity of scope to present this discussion, e.g., the separated analysis of the Euclidean space, Hermitian space, Hilbert space, and things in the complex domain. We refer the reader to literature in the field of linear algebra for a more detailed introduction to the related fields.

</p>
</details>

<details><summary><b>Deep Learning Applications for Lung Cancer Diagnosis: A systematic review</b>
<a href="https://arxiv.org/abs/2201.00227">arxiv:2201.00227</a>
&#x1F4C8; 28 <br>
<p>Hesamoddin Hosseini, Reza Monsefi, Shabnam Shadroo</p></summary>
<p>

**Abstract:** Lung cancer has been one of the most prevalent disease in recent years. According to the research of this field, more than 200,000 cases are identified each year in the US. Uncontrolled multiplication and growth of the lung cells result in malignant tumour formation. Recently, deep learning algorithms, especially Convolutional Neural Networks (CNN), have become a superior way to automatically diagnose disease. The purpose of this article is to review different models that lead to different accuracy and sensitivity in the diagnosis of early-stage lung cancer and to help physicians and researchers in this field. The main purpose of this work is to identify the challenges that exist in lung cancer based on deep learning. The survey is systematically written that combines regular mapping and literature review to review 32 conference and journal articles in the field from 2016 to 2021. After analysing and reviewing the articles, the questions raised in the articles are being answered. This research is superior to other review articles in this field due to the complete review of relevant articles and systematic write up.

</p>
</details>

<details><summary><b>Dynamic Least-Squares Regression</b>
<a href="https://arxiv.org/abs/2201.00228">arxiv:2201.00228</a>
&#x1F4C8; 17 <br>
<p>Shunhua Jiang, Binghui Peng, Omri Weinstein</p></summary>
<p>

**Abstract:** A common challenge in large-scale supervised learning, is how to exploit new incremental data to a pre-trained model, without re-training the model from scratch. Motivated by this problem, we revisit the canonical problem of dynamic least-squares regression (LSR), where the goal is to learn a linear model over incremental training data. In this setup, data and labels $(\mathbf{A}^{(t)}, \mathbf{b}^{(t)}) \in \mathbb{R}^{t \times d}\times \mathbb{R}^t$ evolve in an online fashion ($t\gg d$), and the goal is to efficiently maintain an (approximate) solution to $\min_{\mathbf{x}^{(t)}} \| \mathbf{A}^{(t)} \mathbf{x}^{(t)} - \mathbf{b}^{(t)} \|_2$ for all $t\in [T]$. Our main result is a dynamic data structure which maintains an arbitrarily small constant approximate solution to dynamic LSR with amortized update time $O(d^{1+o(1)})$, almost matching the running time of the static (sketching-based) solution. By contrast, for exact (or even $1/\mathrm{poly}(n)$-accuracy) solutions, we show a separation between the static and dynamic settings, namely, that dynamic LSR requires $Ω(d^{2-o(1)})$ amortized update time under the OMv Conjecture (Henzinger et al., STOC'15). Our data structure is conceptually simple, easy to implement, and fast both in theory and practice, as corroborated by experiments over both synthetic and real-world datasets.

</p>
</details>

<details><summary><b>Matrix Completion with Hierarchical Graph Side Information</b>
<a href="https://arxiv.org/abs/2201.01728">arxiv:2201.01728</a>
&#x1F4C8; 8 <br>
<p>Adel Elmahdy, Junhyung Ahn, Changho Suh, Soheil Mohajer</p></summary>
<p>

**Abstract:** We consider a matrix completion problem that exploits social or item similarity graphs as side information. We develop a universal, parameter-free, and computationally efficient algorithm that starts with hierarchical graph clustering and then iteratively refines estimates both on graph clustering and matrix ratings. Under a hierarchical stochastic block model that well respects practically-relevant social graphs and a low-rank rating matrix model (to be detailed), we demonstrate that our algorithm achieves the information-theoretic limit on the number of observed matrix entries (i.e., optimal sample complexity) that is derived by maximum likelihood estimation together with a lower-bound impossibility result. One consequence of this result is that exploiting the hierarchical structure of social graphs yields a substantial gain in sample complexity relative to the one that simply identifies different groups without resorting to the relational structure across them. We conduct extensive experiments both on synthetic and real-world datasets to corroborate our theoretical results as well as to demonstrate significant performance improvements over other matrix completion algorithms that leverage graph side information.

</p>
</details>

<details><summary><b>Multi-view Subspace Adaptive Learning via Autoencoder and Attention</b>
<a href="https://arxiv.org/abs/2201.00171">arxiv:2201.00171</a>
&#x1F4C8; 6 <br>
<p>Jian-wei Liu, Hao-jie Xie, Run-kun Lu, Xiong-lin Luo</p></summary>
<p>

**Abstract:** Multi-view learning can cover all features of data samples more comprehensively, so multi-view learning has attracted widespread attention. Traditional subspace clustering methods, such as sparse subspace clustering (SSC) and low-ranking subspace clustering (LRSC), cluster the affinity matrix for a single view, thus ignoring the problem of fusion between views. In our article, we propose a new Multiview Subspace Adaptive Learning based on Attention and Autoencoder (MSALAA). This method combines a deep autoencoder and a method for aligning the self-representations of various views in Multi-view Low-Rank Sparse Subspace Clustering (MLRSSC), which can not only increase the capability to non-linearity fitting, but also can meets the principles of consistency and complementarity of multi-view learning. We empirically observe significant improvement over existing baseline methods on six real-life datasets.

</p>
</details>

<details><summary><b>Operator Deep Q-Learning: Zero-Shot Reward Transferring in Reinforcement Learning</b>
<a href="https://arxiv.org/abs/2201.00236">arxiv:2201.00236</a>
&#x1F4C8; 5 <br>
<p>Ziyang Tang, Yihao Feng, Qiang Liu</p></summary>
<p>

**Abstract:** Reinforcement learning (RL) has drawn increasing interests in recent years due to its tremendous success in various applications. However, standard RL algorithms can only be applied for single reward function, and cannot adapt to an unseen reward function quickly. In this paper, we advocate a general operator view of reinforcement learning, which enables us to directly approximate the operator that maps from reward function to value function. The benefit of learning the operator is that we can incorporate any new reward function as input and attain its corresponding value function in a zero-shot manner. To approximate this special type of operator, we design a number of novel operator neural network architectures based on its theoretical properties. Our design of operator networks outperform the existing methods and the standard design of general purpose operator network, and we demonstrate the benefit of our operator deep Q-learning framework in several tasks including reward transferring for offline policy evaluation (OPE) and reward transferring for offline policy optimization in a range of tasks.

</p>
</details>

<details><summary><b>Modelling Cournot Games as Multi-agent Multi-armed Bandits</b>
<a href="https://arxiv.org/abs/2201.01182">arxiv:2201.01182</a>
&#x1F4C8; 4 <br>
<p>Kshitija Taywade, Brent Harrison, Adib Bagh</p></summary>
<p>

**Abstract:** We investigate the use of a multi-agent multi-armed bandit (MA-MAB) setting for modeling repeated Cournot oligopoly games, where the firms acting as agents choose from the set of arms representing production quantity (a discrete value). Agents interact with separate and independent bandit problems. In this formulation, each agent makes sequential choices among arms to maximize its own reward. Agents do not have any information about the environment; they can only see their own rewards after taking an action. However, the market demand is a stationary function of total industry output, and random entry or exit from the market is not allowed. Given these assumptions, we found that an $ε$-greedy approach offers a more viable learning mechanism than other traditional MAB approaches, as it does not require any additional knowledge of the system to operate. We also propose two novel approaches that take advantage of the ordered action space: $ε$-greedy+HL and $ε$-greedy+EL. These new approaches help firms to focus on more profitable actions by eliminating less profitable choices and hence are designed to optimize the exploration. We use computer simulations to study the emergence of various equilibria in the outcomes and do the empirical analysis of joint cumulative regrets.

</p>
</details>

<details><summary><b>Thinking inside the box: A tutorial on grey-box Bayesian optimization</b>
<a href="https://arxiv.org/abs/2201.00272">arxiv:2201.00272</a>
&#x1F4C8; 4 <br>
<p>Raul Astudillo, Peter I. Frazier</p></summary>
<p>

**Abstract:** Bayesian optimization (BO) is a framework for global optimization of expensive-to-evaluate objective functions. Classical BO methods assume that the objective function is a black box. However, internal information about objective function computation is often available. For example, when optimizing a manufacturing line's throughput with simulation, we observe the number of parts waiting at each workstation, in addition to the overall throughput. Recent BO methods leverage such internal information to dramatically improve performance. We call these "grey-box" BO methods because they treat objective computation as partially observable and even modifiable, blending the black-box approach with so-called "white-box" first-principles knowledge of objective function computation. This tutorial describes these methods, focusing on BO of composite objective functions, where one can observe and selectively evaluate individual constituents that feed into the overall objective; and multi-fidelity BO, where one can evaluate cheaper approximations of the objective function by varying parameters of the evaluation oracle.

</p>
</details>

<details><summary><b>Rethinking Feature Uncertainty in Stochastic Neural Networks for Adversarial Robustness</b>
<a href="https://arxiv.org/abs/2201.00148">arxiv:2201.00148</a>
&#x1F4C8; 4 <br>
<p>Hao Yang, Min Wang, Zhengfei Yu, Yun Zhou</p></summary>
<p>

**Abstract:** It is well-known that deep neural networks (DNNs) have shown remarkable success in many fields. However, when adding an imperceptible magnitude perturbation on the model input, the model performance might get rapid decrease. To address this issue, a randomness technique has been proposed recently, named Stochastic Neural Networks (SNNs). Specifically, SNNs inject randomness into the model to defend against unseen attacks and improve the adversarial robustness. However, existed studies on SNNs mainly focus on injecting fixed or learnable noises to model weights/activations. In this paper, we find that the existed SNNs performances are largely bottlenecked by the feature representation ability. Surprisingly, simply maximizing the variance per dimension of the feature distribution leads to a considerable boost beyond all previous methods, which we named maximize feature distribution variance stochastic neural network (MFDV-SNN). Extensive experiments on well-known white- and black-box attacks show that MFDV-SNN achieves a significant improvement over existing methods, which indicates that it is a simple but effective method to improve model robustness.

</p>
</details>

<details><summary><b>Joint Learning-Based Stabilization of Multiple Unknown Linear Systems</b>
<a href="https://arxiv.org/abs/2201.01387">arxiv:2201.01387</a>
&#x1F4C8; 3 <br>
<p>Mohamad Kazem Shirani Faradonbeh, Aditya Modi</p></summary>
<p>

**Abstract:** Learning-based control of linear systems received a lot of attentions recently. In popular settings, the true dynamical models are unknown to the decision-maker and need to be interactively learned by applying control inputs to the systems. Unlike the matured literature of efficient reinforcement learning policies for adaptive control of a single system, results on joint learning of multiple systems are not currently available. Especially, the important problem of fast and reliable joint-stabilization remains unaddressed and so is the focus of this work. We propose a novel joint learning-based stabilization algorithm for quickly learning stabilizing policies for all systems understudy, from the data of unstable state trajectories. The presented procedure is shown to be notably effective such that it stabilizes the family of dynamical systems in an extremely short time period.

</p>
</details>

<details><summary><b>Adaptive Single Image Deblurring</b>
<a href="https://arxiv.org/abs/2201.00155">arxiv:2201.00155</a>
&#x1F4C8; 3 <br>
<p>Maitreya Suin, Kuldeep Purohit, A. N. Rajagopalan</p></summary>
<p>

**Abstract:** This paper tackles the problem of dynamic scene deblurring. Although end-to-end fully convolutional designs have recently advanced the state-of-the-art in non-uniform motion deblurring, their performance-complexity trade-off is still sub-optimal. Existing approaches achieve a large receptive field by a simple increment in the number of generic convolution layers, kernel-size, which comes with the burden of the increase in model size and inference speed. In this work, we propose an efficient pixel adaptive and feature attentive design for handling large blur variations within and across different images. We also propose an effective content-aware global-local filtering module that significantly improves the performance by considering not only the global dependencies of the pixel but also dynamically using the neighboring pixels. We use a patch hierarchical attentive architecture composed of the above module that implicitly discover the spatial variations in the blur present in the input image and in turn perform local and global modulation of intermediate features. Extensive qualitative and quantitative comparisons with prior art on deblurring benchmarks demonstrate the superiority of the proposed network.

</p>
</details>

<details><summary><b>Reinforcement Learning for Task Specifications with Action-Constraints</b>
<a href="https://arxiv.org/abs/2201.00286">arxiv:2201.00286</a>
&#x1F4C8; 2 <br>
<p>Arun Raman, Keerthan Shagrithaya, Shalabh Bhatnagar</p></summary>
<p>

**Abstract:** In this paper, we use concepts from supervisory control theory of discrete event systems to propose a method to learn optimal control policies for a finite-state Markov Decision Process (MDP) in which (only) certain sequences of actions are deemed unsafe (respectively safe). We assume that the set of action sequences that are deemed unsafe and/or safe are given in terms of a finite-state automaton; and propose a supervisor that disables a subset of actions at every state of the MDP so that the constraints on action sequence are satisfied. Then we present a version of the Q-learning algorithm for learning optimal policies in the presence of non-Markovian action-sequence and state constraints, where we use the development of reward machines to handle the state constraints. We illustrate the method using an example that captures the utility of automata-based methods for non-Markovian state and action specifications for reinforcement learning and show the results of simulations in this setting.

</p>
</details>

<details><summary><b>Recover the spectrum of covariance matrix: a non-asymptotic iterative method</b>
<a href="https://arxiv.org/abs/2201.00230">arxiv:2201.00230</a>
&#x1F4C8; 2 <br>
<p>Juntao Duan, Ionel Popescu, Heinrich Matzinger</p></summary>
<p>

**Abstract:** It is well known the sample covariance has a consistent bias in the spectrum, for example spectrum of Wishart matrix follows the Marchenko-Pastur law. We in this work introduce an iterative algorithm 'Concent' that actively eliminate this bias and recover the true spectrum for small and moderate dimensions.

</p>
</details>

<details><summary><b>Deep Nonparametric Estimation of Operators between Infinite Dimensional Spaces</b>
<a href="https://arxiv.org/abs/2201.00217">arxiv:2201.00217</a>
&#x1F4C8; 2 <br>
<p>Hao Liu, Haizhao Yang, Minshuo Chen, Tuo Zhao, Wenjing Liao</p></summary>
<p>

**Abstract:** Learning operators between infinitely dimensional spaces is an important learning task arising in wide applications in machine learning, imaging science, mathematical modeling and simulations, etc. This paper studies the nonparametric estimation of Lipschitz operators using deep neural networks. Non-asymptotic upper bounds are derived for the generalization error of the empirical risk minimizer over a properly chosen network class. Under the assumption that the target operator exhibits a low dimensional structure, our error bounds decay as the training sample size increases, with an attractive fast rate depending on the intrinsic dimension in our estimation. Our assumptions cover most scenarios in real applications and our results give rise to fast rates by exploiting low dimensional structures of data in operator estimation. We also investigate the influence of network structures (e.g., network width, depth, and sparsity) on the generalization error of the neural network estimator and propose a general suggestion on the choice of network structures to maximize the learning efficiency quantitatively.

</p>
</details>

<details><summary><b>Learning Free Gait Transition for Quadruped Robots via Phase-Guided Controller</b>
<a href="https://arxiv.org/abs/2201.00206">arxiv:2201.00206</a>
&#x1F4C8; 2 <br>
<p>Yecheng Shao, Yongbin Jin, Xianwei Liu, Weiyan He, Hongtao Wang, Wei Yang</p></summary>
<p>

**Abstract:** Gaits and transitions are key components in legged locomotion. For legged robots, describing and reproducing gaits as well as transitions remain longstanding challenges. Reinforcement learning has become a powerful tool to formulate controllers for legged robots. Learning multiple gaits and transitions, nevertheless, is related to the multi-task learning problems. In this work, we present a novel framework for training a simple control policy for a quadruped robot to locomote in various gaits. Four independent phases are used as the interface between the gait generator and the control policy, which characterizes the movement of four feet. Guided by the phases, the quadruped robot is able to locomote according to the generated gaits, such as walk, trot, pacing and bounding, and to make transitions among those gaits. More general phases can be used to generate complex gaits, such as mixed rhythmic dancing. With the control policy, the Black Panther robot, a medium-dog-sized quadruped robot, can perform all learned motor skills while following the velocity commands smoothly and robustly in natural environment.

</p>
</details>

<details><summary><b>The GatedTabTransformer. An enhanced deep learning architecture for tabular modeling</b>
<a href="https://arxiv.org/abs/2201.00199">arxiv:2201.00199</a>
&#x1F4C8; 2 <br>
<p>Radostin Cholakov, Todor Kolev</p></summary>
<p>

**Abstract:** There is an increasing interest in the application of deep learning architectures to tabular data. One of the state-of-the-art solutions is TabTransformer which incorporates an attention mechanism to better track relationships between categorical features and then makes use of a standard MLP to output its final logits. In this paper we propose multiple modifications to the original TabTransformer performing better on binary classification tasks for three separate datasets with more than 1% AUROC gains. Inspired by gated MLP, linear projections are implemented in the MLP block and multiple activation functions are tested. We also evaluate the importance of specific hyper parameters during training.

</p>
</details>

<details><summary><b>Self-attention Multi-view Representation Learning with Diversity-promoting Complementarity</b>
<a href="https://arxiv.org/abs/2201.00168">arxiv:2201.00168</a>
&#x1F4C8; 2 <br>
<p>Jian-wei Liu, Xi-hao Ding, Run-kun Lu, Xionglin Luo</p></summary>
<p>

**Abstract:** Multi-view learning attempts to generate a model with a better performance by exploiting the consensus and/or complementarity among multi-view data. However, in terms of complementarity, most existing approaches only can find representations with single complementarity rather than complementary information with diversity. In this paper, to utilize both complementarity and consistency simultaneously, give free rein to the potential of deep learning in grasping diversity-promoting complementarity for multi-view representation learning, we propose a novel supervised multi-view representation learning algorithm, called Self-Attention Multi-View network with Diversity-Promoting Complementarity (SAMVDPC), which exploits the consistency by a group of encoders, uses self-attention to find complementary information entailing diversity. Extensive experiments conducted on eight real-world datasets have demonstrated the effectiveness of our proposed method, and show its superiority over several baseline methods, which only consider single complementary information.

</p>
</details>

<details><summary><b>SAFL: A Self-Attention Scene Text Recognizer with Focal Loss</b>
<a href="https://arxiv.org/abs/2201.00132">arxiv:2201.00132</a>
&#x1F4C8; 2 <br>
<p>Bao Hieu Tran, Thanh Le-Cong, Huu Manh Nguyen, Duc Anh Le, Thanh Hung Nguyen, Phi Le Nguyen</p></summary>
<p>

**Abstract:** In the last decades, scene text recognition has gained worldwide attention from both the academic community and actual users due to its importance in a wide range of applications. Despite achievements in optical character recognition, scene text recognition remains challenging due to inherent problems such as distortions or irregular layout. Most of the existing approaches mainly leverage recurrence or convolution-based neural networks. However, while recurrent neural networks (RNNs) usually suffer from slow training speed due to sequential computation and encounter problems as vanishing gradient or bottleneck, CNN endures a trade-off between complexity and performance. In this paper, we introduce SAFL, a self-attention-based neural network model with the focal loss for scene text recognition, to overcome the limitation of the existing approaches. The use of focal loss instead of negative log-likelihood helps the model focus more on low-frequency samples training. Moreover, to deal with the distortions and irregular texts, we exploit Spatial TransformerNetwork (STN) to rectify text before passing to the recognition network. We perform experiments to compare the performance of the proposed model with seven benchmarks. The numerical results show that our model achieves the best performance.

</p>
</details>

<details><summary><b>Interpretable Low-Resource Legal Decision Making</b>
<a href="https://arxiv.org/abs/2201.01164">arxiv:2201.01164</a>
&#x1F4C8; 1 <br>
<p>Rohan Bhambhoria, Hui Liu, Samuel Dahan, Xiaodan Zhu</p></summary>
<p>

**Abstract:** Over the past several years, legal applications of deep learning have been on the rise. However, as with other high-stakes decision making areas, the requirement for interpretability is of crucial importance. Current models utilized by legal practitioners are more of the conventional machine learning type, wherein they are inherently interpretable, yet unable to harness the performance capabilities of data-driven deep learning models. In this work, we utilize deep learning models in the area of trademark law to shed light on the issue of likelihood of confusion between trademarks. Specifically, we introduce a model-agnostic interpretable intermediate layer, a technique which proves to be effective for legal documents. Furthermore, we utilize weakly supervised learning by means of a curriculum learning strategy, effectively demonstrating the improved performance of a deep learning model. This is in contrast to the conventional models which are only able to utilize the limited number of expensive manually-annotated samples by legal experts. Although the methods presented in this work tackles the task of risk of confusion for trademarks, it is straightforward to extend them to other fields of law, or more generally, to other similar high-stakes application scenarios.

</p>
</details>

<details><summary><b>Applications of Gaussian Mutation for Self Adaptation in Evolutionary Genetic Algorithms</b>
<a href="https://arxiv.org/abs/2201.00285">arxiv:2201.00285</a>
&#x1F4C8; 1 <br>
<p>Okezue Bell</p></summary>
<p>

**Abstract:** In recent years, optimization problems have become increasingly more prevalent due to the need for more powerful computational methods. With the more recent advent of technology such as artificial intelligence, new metaheuristics are needed that enhance the capabilities of classical algorithms. More recently, researchers have been looking at Charles Darwin's theory of natural selection and evolution as a means of enhancing current approaches using machine learning. In 1960, the first genetic algorithm was developed by John H. Holland and his student. We explore the mathematical intuition of the genetic algorithm in developing systems capable of evolving using Gaussian mutation, as well as its implications in solving optimization problems.

</p>
</details>

<details><summary><b>Subspace modeling for fast and high-sensitivity X-ray chemical imaging</b>
<a href="https://arxiv.org/abs/2201.00259">arxiv:2201.00259</a>
&#x1F4C8; 1 <br>
<p>Jizhou Li, Bin Chen, Guibin Zan, Guannan Qian, Piero Pianetta, Yijin Liu</p></summary>
<p>

**Abstract:** Resolving morphological chemical phase transformations at the nanoscale is of vital importance to many scientific and industrial applications across various disciplines. The TXM-XANES imaging technique, by combining full field transmission X-ray microscopy (TXM) and X-ray absorption near edge structure (XANES), has been an emerging tool which operates by acquiring a series of microscopy images with multi-energy X-rays and fitting to obtain the chemical map. Its capability, however, is limited by the poor signal-to-noise ratios due to the system errors and low exposure illuminations for fast acquisition. In this work, by exploiting the intrinsic properties and subspace modeling of the TXM-XANES imaging data, we introduce a simple and robust denoising approach to improve the image quality, which enables fast and high-sensitivity chemical imaging. Extensive experiments on both synthetic and real datasets demonstrate the superior performance of the proposed method.

</p>
</details>

<details><summary><b>The Parametric Cost Function Approximation: A new approach for multistage stochastic programming</b>
<a href="https://arxiv.org/abs/2201.00258">arxiv:2201.00258</a>
&#x1F4C8; 1 <br>
<p>Warren B Powell, Saeed Ghadimi</p></summary>
<p>

**Abstract:** The most common approaches for solving multistage stochastic programming problems in the research literature have been to either use value functions ("dynamic programming") or scenario trees ("stochastic programming") to approximate the impact of a decision now on the future. By contrast, common industry practice is to use a deterministic approximation of the future which is easier to understand and solve, but which is criticized for ignoring uncertainty. We show that a parameterized version of a deterministic optimization model can be an effective way of handling uncertainty without the complexity of either stochastic programming or dynamic programming. We present the idea of a parameterized deterministic optimization model, and in particular a deterministic lookahead model, as a powerful strategy for many complex stochastic decision problems. This approach can handle complex, high-dimensional state variables, and avoids the usual approximations associated with scenario trees or value function approximations. Instead, it introduces the offline challenge of designing and tuning the parameterization. We illustrate the idea by using a series of application settings, and demonstrate its use in a nonstationary energy storage problem with rolling forecasts.

</p>
</details>

<details><summary><b>Image Restoration using Feature-guidance</b>
<a href="https://arxiv.org/abs/2201.00187">arxiv:2201.00187</a>
&#x1F4C8; 1 <br>
<p>Maitreya Suin, Kuldeep Purohit, A. N. Rajagopalan</p></summary>
<p>

**Abstract:** Image restoration is the task of recovering a clean image from a degraded version. In most cases, the degradation is spatially varying, and it requires the restoration network to both localize and restore the affected regions. In this paper, we present a new approach suitable for handling the image-specific and spatially-varying nature of degradation in images affected by practically occurring artifacts such as blur, rain-streaks. We decompose the restoration task into two stages of degradation localization and degraded region-guided restoration, unlike existing methods which directly learn a mapping between the degraded and clean images. Our premise is to use the auxiliary task of degradation mask prediction to guide the restoration process. We demonstrate that the model trained for this auxiliary task contains vital region knowledge, which can be exploited to guide the restoration network's training using attentive knowledge distillation technique. Further, we propose mask-guided convolution and global context aggregation module that focuses solely on restoring the degraded regions. The proposed approach's effectiveness is demonstrated by achieving significant improvement over strong baselines.

</p>
</details>

<details><summary><b>Dynamic Scene Video Deblurring using Non-Local Attention</b>
<a href="https://arxiv.org/abs/2201.00169">arxiv:2201.00169</a>
&#x1F4C8; 1 <br>
<p>Maitreya Suin, A. N. Rajagopalan</p></summary>
<p>

**Abstract:** This paper tackles the challenging problem of video deblurring. Most of the existing works depend on implicit or explicit alignment for temporal information fusion which either increase the computational cost or result in suboptimal performance due to wrong alignment. In this study, we propose a factorized spatio-temporal attention to perform non-local operations across space and time to fully utilize the available information without depending on alignment. It shows superior performance compared to existing fusion techniques while being much efficient. Extensive experiments on multiple datasets demonstrate the superiority of our method.

</p>
</details>

<details><summary><b>Development of Diabetic Foot Ulcer Datasets: An Overview</b>
<a href="https://arxiv.org/abs/2201.00163">arxiv:2201.00163</a>
&#x1F4C8; 1 <br>
<p>Moi Hoon Yap, Connah Kendrick, Neil D. Reeves, Manu Goyal, Joseph M. Pappachan, Bill Cassidy</p></summary>
<p>

**Abstract:** This paper provides conceptual foundation and procedures used in the development of diabetic foot ulcer datasets over the past decade, with a timeline to demonstrate progress. We conduct a survey on data capturing methods for foot photographs, an overview of research in developing private and public datasets, the related computer vision tasks (detection, segmentation and classification), the diabetic foot ulcer challenges and the future direction of the development of the datasets. We report the distribution of dataset users by country and year. Our aim is to share the technical challenges that we encountered together with good practices in dataset development, and provide motivation for other researchers to participate in data sharing in this domain.

</p>
</details>

<details><summary><b>Semantic Search for Large Scale Clinical Ontologies</b>
<a href="https://arxiv.org/abs/2201.00118">arxiv:2201.00118</a>
&#x1F4C8; 1 <br>
<p>Duy-Hoa Ngo, Madonna Kemp, Donna Truran, Bevan Koopman, Alejandro Metke-Jimenez</p></summary>
<p>

**Abstract:** Finding concepts in large clinical ontologies can be challenging when queries use different vocabularies. A search algorithm that overcomes this problem is useful in applications such as concept normalisation and ontology matching, where concepts can be referred to in different ways, using different synonyms. In this paper, we present a deep learning based approach to build a semantic search system for large clinical ontologies. We propose a Triplet-BERT model and a method that generates training data directly from the ontologies. The model is evaluated using five real benchmark data sets and the results show that our approach achieves high results on both free text to concept and concept to concept searching tasks, and outperforms all baseline methods.

</p>
</details>

<details><summary><b>Toward the Analysis of Graph Neural Networks</b>
<a href="https://arxiv.org/abs/2201.00115">arxiv:2201.00115</a>
&#x1F4C8; 1 <br>
<p>Thanh-Dat Nguyen, Thanh Le-Cong, ThanhVu H. Nguyen, Xuan-Bach D. Le, Quyet-Thang Huynh</p></summary>
<p>

**Abstract:** Graph Neural Networks (GNNs) have recently emerged as a robust framework for graph-structured data. They have been applied to many problems such as knowledge graph analysis, social networks recommendation, and even Covid19 detection and vaccine developments. However, unlike other deep neural networks such as Feed Forward Neural Networks (FFNNs), few analyses such as verification and property inferences exist, potentially due to dynamic behaviors of GNNs, which can take arbitrary graphs as input, whereas FFNNs which only take fixed size numerical vectors as inputs.
  This paper proposes an approach to analyze GNNs by converting them into FFNNs and reusing existing FFNNs analyses. We discuss various designs to ensure the scalability and accuracy of the conversions. We illustrate our method on a study case of node classification. We believe that our approach opens new research directions for understanding and analyzing GNNs.

</p>
</details>

<details><summary><b>Usability and Aesthetics: Better Together for Automated Repair of Web Pages</b>
<a href="https://arxiv.org/abs/2201.00117">arxiv:2201.00117</a>
&#x1F4C8; 0 <br>
<p>Thanh Le-Cong, Xuan Bach D. Le, Quyet-Thang Huynh, Phi-Le Nguyen</p></summary>
<p>

**Abstract:** With the recent explosive growth of mobile devices such as smartphones or tablets, guaranteeing consistent web appearance across all environments has become a significant problem. This happens simply because it is hard to keep track of the web appearance on different sizes and types of devices that render the web pages. Therefore, fixing the inconsistent appearance of web pages can be difficult, and the cost incurred can be huge, e.g., poor user experience and financial loss due to it. Recently, automated web repair techniques have been proposed to automatically resolve inconsistent web page appearance, focusing on improving usability. However, generated patches tend to disrupt the webpage's layout, rendering the repaired webpage aesthetically unpleasing, e.g., distorted images or misalignment of components.
  In this paper, we propose an automated repair approach for web pages based on meta-heuristic algorithms that can assure both usability and aesthetics. The key novelty that empowers our approach is a novel fitness function that allows us to optimistically evolve buggy web pages to find the best solution that optimizes both usability and aesthetics at the same time. Empirical evaluations show that our approach is able to successfully resolve mobile-friendly problems in 94% of the evaluation subjects, significantly outperforming state-of-the-art baseline techniques in terms of both usability and aesthetics.

</p>
</details>


{% endraw %}
Prev: [2021.12.31]({{ '/2021/12/31/2021.12.31.html' | relative_url }})  Next: [2022.01.02]({{ '/2022/01/02/2022.01.02.html' | relative_url }})