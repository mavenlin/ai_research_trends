Prev: [2022.04.27]({{ '/2022/04/27/2022.04.27.html' | relative_url }})  Next: [2022.04.29]({{ '/2022/04/29/2022.04.29.html' | relative_url }})
{% raw %}
## Summary for 2022-04-28, created on 2022-05-05


<details><summary><b>CogView2: Faster and Better Text-to-Image Generation via Hierarchical Transformers</b>
<a href="https://arxiv.org/abs/2204.14217">arxiv:2204.14217</a>
&#x1F4C8; 127 <br>
<p>Ming Ding, Wendi Zheng, Wenyi Hong, Jie Tang</p></summary>
<p>

**Abstract:** The development of the transformer-based text-to-image models are impeded by its slow generation and complexity for high-resolution images. In this work, we put forward a solution based on hierarchical transformers and local parallel auto-regressive generation. We pretrain a 6B-parameter transformer with a simple and flexible self-supervised task, Cross-modal general language model (CogLM), and finetune it for fast super-resolution. The new text-to-image system, CogView2, shows very competitive generation compared to concurrent state-of-the-art DALL-E-2, and naturally supports interactive text-guided editing on images.

</p>
</details>

<details><summary><b>Predicting single-cell perturbation responses for unseen drugs</b>
<a href="https://arxiv.org/abs/2204.13545">arxiv:2204.13545</a>
&#x1F4C8; 64 <br>
<p>Leon Hetzel, Simon Böhm, Niki Kilbertus, Stephan Günnemann, Mohammad Lotfollahi, Fabian Theis</p></summary>
<p>

**Abstract:** Single-cell transcriptomics enabled the study of cellular heterogeneity in response to perturbations at the resolution of individual cells. However, scaling high-throughput screens (HTSs) to measure cellular responses for many drugs remains a challenge due to technical limitations and, more importantly, the cost of such multiplexed experiments. Thus, transferring information from routinely performed bulk RNA-seq HTS is required to enrich single-cell data meaningfully. We introduce a new encoder-decoder architecture to study the perturbational effects of unseen drugs. We combine the model with a transfer learning scheme and demonstrate how training on existing bulk RNA-seq HTS datasets can improve generalisation performance. Better generalisation reduces the need for extensive and costly screens at single-cell resolution. We envision that our proposed method will facilitate more efficient experiment designs through its ability to generate in-silico hypotheses, ultimately accelerating targeted drug discovery.

</p>
</details>

<details><summary><b>Poly-CAM: High resolution class activation map for convolutional neural networks</b>
<a href="https://arxiv.org/abs/2204.13359">arxiv:2204.13359</a>
&#x1F4C8; 45 <br>
<p>Alexandre Englebert, Olivier Cornu, Christophe De Vleeschouwer</p></summary>
<p>

**Abstract:** The need for Explainable AI is increasing with the development of deep learning. The saliency maps derived from convolutional neural networks generally fail in localizing with accuracy the image features justifying the network prediction. This is because those maps are either low-resolution as for CAM [Zhou et al., 2016], or smooth as for perturbation-based methods [Zeiler and Fergus, 2014], or do correspond to a large number of widespread peaky spots as for gradient-based approaches [Sundararajan et al., 2017, Smilkov et al., 2017]. In contrast, our work proposes to combine the information from earlier network layers with the one from later layers to produce a high resolution Class Activation Map that is competitive with the previous art in term of insertion-deletion faithfulness metrics, while outperforming it in term of precision of class-specific features localization.

</p>
</details>

<details><summary><b>Unaligned Supervision For Automatic Music Transcription in The Wild</b>
<a href="https://arxiv.org/abs/2204.13668">arxiv:2204.13668</a>
&#x1F4C8; 30 <br>
<p>Ben Maman, Amit H. Bermano</p></summary>
<p>

**Abstract:** Multi-instrument Automatic Music Transcription (AMT), or the decoding of a musical recording into semantic musical content, is one of the holy grails of Music Information Retrieval. Current AMT approaches are restricted to piano and (some) guitar recordings, due to difficult data collection. In order to overcome data collection barriers, previous AMT approaches attempt to employ musical scores in the form of a digitized version of the same song or piece. The scores are typically aligned using audio features and strenuous human intervention to generate training labels. We introduce NoteEM, a method for simultaneously training a transcriber and aligning the scores to their corresponding performances, in a fully-automated process. Using this unaligned supervision scheme, complemented by pseudo-labels and pitch-shift augmentation, our method enables training on in-the-wild recordings with unprecedented accuracy and instrumental variety. Using only synthetic data and unaligned supervision, we report SOTA note-level accuracy of the MAPS dataset, and large favorable margins on cross-dataset evaluations. We also demonstrate robustness and ease of use; we report comparable results when training on a small, easily obtainable, self-collected dataset, and we propose alternative labeling to the MusicNet dataset, which we show to be more accurate. Our project page is available at https://benadar293.github.io

</p>
</details>

<details><summary><b>Foundations for learning from noisy quantum experiments</b>
<a href="https://arxiv.org/abs/2204.13691">arxiv:2204.13691</a>
&#x1F4C8; 27 <br>
<p>Hsin-Yuan Huang, Steven T. Flammia, John Preskill</p></summary>
<p>

**Abstract:** Understanding what can be learned from experiments is central to scientific progress. In this work, we use a learning-theoretic perspective to study the task of learning physical operations in a quantum machine when all operations (state preparation, dynamics, and measurement) are a priori unknown. We prove that, without any prior knowledge, if one can explore the full quantum state space by composing the operations, then every operation can be learned. When one cannot explore the full state space but all operations are approximately known and noise in Clifford gates is gate-independent, we find an efficient algorithm for learning all operations up to a single unlearnable parameter characterizing the fidelity of the initial state. For learning a noise channel on Clifford gates to a fixed accuracy, our algorithm uses quadratically fewer experiments than previously known protocols. Under more general conditions, the true description of the noise can be unlearnable; for example, we prove that no benchmarking protocol can learn gate-dependent Pauli noise on Clifford+T gates even under perfect state preparation and measurement. Despite not being able to learn the noise, we show that a noisy quantum computer that performs entangled measurements on multiple copies of an unknown state can yield a large advantage in learning properties of the state compared to a noiseless device that measures individual copies and then processes the measurement data using a classical computer. Concretely, we prove that noisy quantum computers with two-qubit gate error rate $ε$ can achieve a learning task using $N$ copies of the state, while $N^{Ω(1/ε)}$ copies are required classically.

</p>
</details>

<details><summary><b>Music Enhancement via Image Translation and Vocoding</b>
<a href="https://arxiv.org/abs/2204.13289">arxiv:2204.13289</a>
&#x1F4C8; 18 <br>
<p>Nikhil Kandpal, Oriol Nieto, Zeyu Jin</p></summary>
<p>

**Abstract:** Consumer-grade music recordings such as those captured by mobile devices typically contain distortions in the form of background noise, reverb, and microphone-induced EQ. This paper presents a deep learning approach to enhance low-quality music recordings by combining (i) an image-to-image translation model for manipulating audio in its mel-spectrogram representation and (ii) a music vocoding model for mapping synthetically generated mel-spectrograms to perceptually realistic waveforms. We find that this approach to music enhancement outperforms baselines which use classical methods for mel-spectrogram inversion and an end-to-end approach directly mapping noisy waveforms to clean waveforms. Additionally, in evaluating the proposed method with a listening test, we analyze the reliability of common audio enhancement evaluation metrics when used in the music domain.

</p>
</details>

<details><summary><b>Oracle Guided Image Synthesis with Relative Queries</b>
<a href="https://arxiv.org/abs/2204.14189">arxiv:2204.14189</a>
&#x1F4C8; 10 <br>
<p>Alec Helbling, Christopher John Rozell, Matthew O'Shaughnessy, Kion Fallah</p></summary>
<p>

**Abstract:** Isolating and controlling specific features in the outputs of generative models in a user-friendly way is a difficult and open-ended problem. We develop techniques that allow an oracle user to generate an image they are envisioning in their head by answering a sequence of relative queries of the form \textit{"do you prefer image $a$ or image $b$?"} Our framework consists of a Conditional VAE that uses the collected relative queries to partition the latent space into preference-relevant features and non-preference-relevant features. We then use the user's responses to relative queries to determine the preference-relevant features that correspond to their envisioned output image. Additionally, we develop techniques for modeling the uncertainty in images' predicted preference-relevant features, allowing our framework to generalize to scenarios in which the relative query training set contains noise.

</p>
</details>

<details><summary><b>Learning cosmology and clustering with cosmic graphs</b>
<a href="https://arxiv.org/abs/2204.13713">arxiv:2204.13713</a>
&#x1F4C8; 10 <br>
<p>Pablo Villanueva-Domingo, Francisco Villaescusa-Navarro</p></summary>
<p>

**Abstract:** We train deep learning models on thousands of galaxy catalogues from the state-of-the-art hydrodynamic simulations of the CAMELS project to perform regression and inference. We employ Graph Neural Networks (GNNs), architectures designed to work with irregular and sparse data, like the distribution of galaxies in the Universe. We first show that GNNs can learn to compute the power spectrum of galaxy catalogues with a few percent accuracy. We then train GNNs to perform likelihood-free inference at the galaxy-field level. Our models are able to infer the value of $Ω_{\rm m}$ with a $\sim12\%-13\%$ accuracy just from the positions of $\sim1000$ galaxies in a volume of $(25~h^{-1}{\rm Mpc})^3$ at $z=0$ while accounting for astrophysical uncertainties as modelled in CAMELS. Incorporating information from galaxy properties, such as stellar mass, stellar metallicity, and stellar radius, increases the accuracy to $4\%-8\%$. Our models are built to be translational and rotational invariant, and they can extract information from any scale larger than the minimum distance between two galaxies. However, our models are not completely robust: testing on simulations run with a different subgrid physics than the ones used for training does not yield as accurate results.

</p>
</details>

<details><summary><b>Robots: the Century Past and the Century Ahead</b>
<a href="https://arxiv.org/abs/2204.13331">arxiv:2204.13331</a>
&#x1F4C8; 10 <br>
<p>Federico Pigozzi</p></summary>
<p>

**Abstract:** Let us reflect on the state of robotics. This year marks the $101$-st anniversary of R.U.R., a play by the writer Karel Čapek, often credited with introducing the word "robot". The word used to refer to feudal forced labourers in Slavic languages. Indeed, it points to one key characteristic of robotic systems: they are mere slaves, have no rights, and execute our wills instruction by instruction, without asking anything in return. The relationship with us humans is commensalism; in biology, commensalism subsists between two symbiotic species when one species benefits from it (robots boost productivity for humans), while the other species neither benefits nor is harmed (can you really argue that robots benefit from simply functioning?).
  We then distinguish robots from "living machines", that is, machines infused with life. If living machines should ever become a reality, we would need to shift our relationship with them from commensalism to mutualism. The distinction is not subtle: we experience it every day with domesticated animals, that exchange serfdom for forage and protection. This is because life has evolved to resist any attempt at enslaving it; it is stubborn.
  In the path towards living machines, let us ask: what has been achieved by robotics in the last $100$ years? What is left to accomplish in the next $100$ years? For us, the answers boil down to three words: juice, need (or death), and embodiment, as we shall see in the following.

</p>
</details>

<details><summary><b>CAVES: A Dataset to facilitate Explainable Classification and Summarization of Concerns towards COVID Vaccines</b>
<a href="https://arxiv.org/abs/2204.13746">arxiv:2204.13746</a>
&#x1F4C8; 9 <br>
<p>Soham Poddar, Azlaan Mustafa Samad, Rajdeep Mukherjee, Niloy Ganguly, Saptarshi Ghosh</p></summary>
<p>

**Abstract:** Convincing people to get vaccinated against COVID-19 is a key societal challenge in the present times. As a first step towards this goal, many prior works have relied on social media analysis to understand the specific concerns that people have towards these vaccines, such as potential side-effects, ineffectiveness, political factors, and so on. Though there are datasets that broadly classify social media posts into Anti-vax and Pro-Vax labels, there is no dataset (to our knowledge) that labels social media posts according to the specific anti-vaccine concerns mentioned in the posts. In this paper, we have curated CAVES, the first large-scale dataset containing about 10k COVID-19 anti-vaccine tweets labelled into various specific anti-vaccine concerns in a multi-label setting. This is also the first multi-label classification dataset that provides explanations for each of the labels. Additionally, the dataset also provides class-wise summaries of all the tweets. We also perform preliminary experiments on the dataset and show that this is a very challenging dataset for multi-label explainable classification and tweet summarization, as is evident by the moderate scores achieved by some state-of-the-art models. Our dataset and codes are available at: https://github.com/sohampoddar26/caves-data

</p>
</details>

<details><summary><b>Curriculum Learning for Dense Retrieval Distillation</b>
<a href="https://arxiv.org/abs/2204.13679">arxiv:2204.13679</a>
&#x1F4C8; 9 <br>
<p>Hansi Zeng, Hamed Zamani, Vishwa Vinay</p></summary>
<p>

**Abstract:** Recent work has shown that more effective dense retrieval models can be obtained by distilling ranking knowledge from an existing base re-ranking model. In this paper, we propose a generic curriculum learning based optimization framework called CL-DRD that controls the difficulty level of training data produced by the re-ranking (teacher) model. CL-DRD iteratively optimizes the dense retrieval (student) model by increasing the difficulty of the knowledge distillation data made available to it. In more detail, we initially provide the student model coarse-grained preference pairs between documents in the teacher's ranking and progressively move towards finer-grained pairwise document ordering requirements. In our experiments, we apply a simple implementation of the CL-DRD framework to enhance two state-of-the-art dense retrieval models. Experiments on three public passage retrieval datasets demonstrate the effectiveness of our proposed framework.

</p>
</details>

<details><summary><b>On the Normalizing Constant of the Continuous Categorical Distribution</b>
<a href="https://arxiv.org/abs/2204.13290">arxiv:2204.13290</a>
&#x1F4C8; 9 <br>
<p>Elliott Gordon-Rodriguez, Gabriel Loaiza-Ganem, Andres Potapczynski, John P. Cunningham</p></summary>
<p>

**Abstract:** Probability distributions supported on the simplex enjoy a wide range of applications across statistics and machine learning. Recently, a novel family of such distributions has been discovered: the continuous categorical. This family enjoys remarkable mathematical simplicity; its density function resembles that of the Dirichlet distribution, but with a normalizing constant that can be written in closed form using elementary functions only. In spite of this mathematical simplicity, our understanding of the normalizing constant remains far from complete. In this work, we characterize the numerical behavior of the normalizing constant and we present theoretical and methodological advances that can, in turn, help to enable broader applications of the continuous categorical distribution. Our code is available at https://github.com/cunningham-lab/cb_and_cc/.

</p>
</details>

<details><summary><b>High Dimensional Bayesian Optimization with Kernel Principal Component Analysis</b>
<a href="https://arxiv.org/abs/2204.13753">arxiv:2204.13753</a>
&#x1F4C8; 8 <br>
<p>Kirill Antonov, Elena Raponi, Hao Wang, Carola Doerr</p></summary>
<p>

**Abstract:** Bayesian Optimization (BO) is a surrogate-based global optimization strategy that relies on a Gaussian Process regression (GPR) model to approximate the objective function and an acquisition function to suggest candidate points. It is well-known that BO does not scale well for high-dimensional problems because the GPR model requires substantially more data points to achieve sufficient accuracy and acquisition optimization becomes computationally expensive in high dimensions. Several recent works aim at addressing these issues, e.g., methods that implement online variable selection or conduct the search on a lower-dimensional sub-manifold of the original search space. Advancing our previous work of PCA-BO that learns a linear sub-manifold, this paper proposes a novel kernel PCA-assisted BO (KPCA-BO) algorithm, which embeds a non-linear sub-manifold in the search space and performs BO on this sub-manifold. Intuitively, constructing the GPR model on a lower-dimensional sub-manifold helps improve the modeling accuracy without requiring much more data from the objective function. Also, our approach defines the acquisition function on the lower-dimensional sub-manifold, making the acquisition optimization more manageable.
  We compare the performance of KPCA-BO to the vanilla BO and PCA-BO on the multi-modal problems of the COCO/BBOB benchmark suite. Empirical results show that KPCA-BO outperforms BO in terms of convergence speed on most test problems, and this benefit becomes more significant when the dimensionality increases. For the 60D functions, KPCA-BO surpasses PCA-BO in many test cases. Moreover, it efficiently reduces the CPU time required to train the GPR model and optimize the acquisition function compared to the vanilla BO.

</p>
</details>

<details><summary><b>Unlocking High-Accuracy Differentially Private Image Classification through Scale</b>
<a href="https://arxiv.org/abs/2204.13650">arxiv:2204.13650</a>
&#x1F4C8; 8 <br>
<p>Soham De, Leonard Berrada, Jamie Hayes, Samuel L. Smith, Borja Balle</p></summary>
<p>

**Abstract:** Differential Privacy (DP) provides a formal privacy guarantee preventing adversaries with access to a machine learning model from extracting information about individual training points. Differentially Private Stochastic Gradient Descent (DP-SGD), the most popular DP training method, realizes this protection by injecting noise during training. However previous works have found that DP-SGD often leads to a significant degradation in performance on standard image classification benchmarks. Furthermore, some authors have postulated that DP-SGD inherently performs poorly on large models, since the norm of the noise required to preserve privacy is proportional to the model dimension. In contrast, we demonstrate that DP-SGD on over-parameterized models can perform significantly better than previously thought. Combining careful hyper-parameter tuning with simple techniques to ensure signal propagation and improve the convergence rate, we obtain a new SOTA on CIFAR-10 of 81.4% under (8, 10^{-5})-DP using a 40-layer Wide-ResNet, improving over the previous SOTA of 71.7%. When fine-tuning a pre-trained 200-layer Normalizer-Free ResNet, we achieve a remarkable 77.1% top-1 accuracy on ImageNet under (1, 8*10^{-7})-DP, and achieve 81.1% under (8, 8*10^{-7})-DP. This markedly exceeds the previous SOTA of 47.9% under a larger privacy budget of (10, 10^{-6})-DP. We believe our results are a significant step towards closing the accuracy gap between private and non-private image classification.

</p>
</details>

<details><summary><b>AlphaZero-Inspired General Board Game Learning and Playing</b>
<a href="https://arxiv.org/abs/2204.13307">arxiv:2204.13307</a>
&#x1F4C8; 8 <br>
<p>Johannes Scheiermann, Wolfgang Konen</p></summary>
<p>

**Abstract:** Recently, the seminal algorithms AlphaGo and AlphaZero have started a new era in game learning and deep reinforcement learning. While the achievements of AlphaGo and AlphaZero - playing Go and other complex games at super human level - are truly impressive, these architectures have the drawback that they are very complex and require high computational resources. Many researchers are looking for methods that are similar to AlphaZero, but have lower computational demands and are thus more easily reproducible. In this paper, we pick an important element of AlphaZero - the Monte Carlo Tree Search (MCTS) planning stage - and combine it with reinforcement learning (RL) agents. We wrap MCTS for the first time around RL n-tuple networks to create versatile agents that keep at the same time the computational demands low. We apply this new architecture to several complex games (Othello, ConnectFour, Rubik's Cube) and show the advantages achieved with this AlphaZero-inspired MCTS wrapper. In particular, we present results that this AlphaZero-inspired agent is the first one trained on standard hardware (no GPU or TPU) to beat the very strong Othello program Edax up to and including level 7 (where most other algorithms could only defeat Edax up to level 2).

</p>
</details>

<details><summary><b>Neural Label Search for Zero-Shot Multi-Lingual Extractive Summarization</b>
<a href="https://arxiv.org/abs/2204.13512">arxiv:2204.13512</a>
&#x1F4C8; 7 <br>
<p>Ruipeng Jia, Xingxing Zhang, Yanan Cao, Shi Wang, Zheng Lin, Furu Wei</p></summary>
<p>

**Abstract:** In zero-shot multilingual extractive text summarization, a model is typically trained on English summarization dataset and then applied on summarization datasets of other languages. Given English gold summaries and documents, sentence-level labels for extractive summarization are usually generated using heuristics. However, these monolingual labels created on English datasets may not be optimal on datasets of other languages, for that there is the syntactic or semantic discrepancy between different languages. In this way, it is possible to translate the English dataset to other languages and obtain different sets of labels again using heuristics. To fully leverage the information of these different sets of labels, we propose NLSSum (Neural Label Search for Summarization), which jointly learns hierarchical weights for these different sets of labels together with our summarization model. We conduct multilingual zero-shot summarization experiments on MLSUM and WikiLingua datasets, and we achieve state-of-the-art results using both human and automatic evaluations across these two datasets.

</p>
</details>

<details><summary><b>Model Selection, Adaptation, and Combination for Deep Transfer Learning through Neural Networks in Renewable Energies</b>
<a href="https://arxiv.org/abs/2204.13293">arxiv:2204.13293</a>
&#x1F4C8; 7 <br>
<p>Jens Schreiber, Bernhard Sick</p></summary>
<p>

**Abstract:** There is recent interest in using model hubs, a collection of pre-trained models, in computer vision tasks. To utilize the model hub, we first select a source model and then adapt the model for the target to compensate for differences. While there is yet limited research on a model selection and adaption for computer vision tasks, this holds even more for the field of renewable power. At the same time, it is a crucial challenge to provide forecasts for the increasing demand for power forecasts based on weather features from a numerical weather prediction. We close these gaps by conducting the first thorough experiment for model selection and adaptation for transfer learning in renewable power forecast, adopting recent results from the field of computer vision on six datasets. We adopt models based on data from different seasons and limit the amount of training data. As an extension of the current state of the art, we utilize a Bayesian linear regression for forecasting the response based on features extracted from a neural network. This approach outperforms the baseline with only seven days of training data. We further show how combining multiple models through ensembles can significantly improve the model selection and adaptation approach. In fact, with more than 30 days of training data, both proposed model combination techniques achieve similar results to those models trained with a full year of training data.

</p>
</details>

<details><summary><b>Unsupervised Voice-Face Representation Learning by Cross-Modal Prototype Contrast</b>
<a href="https://arxiv.org/abs/2204.14057">arxiv:2204.14057</a>
&#x1F4C8; 6 <br>
<p>Boqing Zhu, Kele Xu, Changjian Wang, Zheng Qin, Tao Sun, Huaimin Wang, Yuxing Peng</p></summary>
<p>

**Abstract:** We present an approach to learn voice-face representations from the talking face videos, without any identity labels. Previous works employ cross-modal instance discrimination tasks to establish the correlation of voice and face. These methods neglect the semantic content of different videos, introducing false-negative pairs as training noise. Furthermore, the positive pairs are constructed based on the natural correlation between audio clips and visual frames. However, this correlation might be weak or inaccurate in a large amount of real-world data, which leads to deviating positives into the contrastive paradigm. To address these issues, we propose the cross-modal prototype contrastive learning (CMPC), which takes advantage of contrastive methods and resists adverse effects of false negatives and deviate positives. On one hand, CMPC could learn the intra-class invariance by constructing semantic-wise positives via unsupervised clustering in different modalities. On the other hand, by comparing the similarities of cross-modal instances from that of cross-modal prototypes, we dynamically recalibrate the unlearnable instances' contribution to overall loss. Experiments show that the proposed approach outperforms state-of-the-art unsupervised methods on various voice-face association evaluation protocols. Additionally, in the low-shot supervision setting, our method also has a significant improvement compared to previous instance-wise contrastive learning.

</p>
</details>

<details><summary><b>Designing for Responsible Trust in AI Systems: A Communication Perspective</b>
<a href="https://arxiv.org/abs/2204.13828">arxiv:2204.13828</a>
&#x1F4C8; 6 <br>
<p>Q. Vera Liao, S. Shyam Sundar</p></summary>
<p>

**Abstract:** Current literature and public discourse on "trust in AI" are often focused on the principles underlying trustworthy AI, with insufficient attention paid to how people develop trust. Given that AI systems differ in their level of trustworthiness, two open questions come to the fore: how should AI trustworthiness be responsibly communicated to ensure appropriate and equitable trust judgments by different users, and how can we protect users from deceptive attempts to earn their trust? We draw from communication theories and literature on trust in technologies to develop a conceptual model called MATCH, which describes how trustworthiness is communicated in AI systems through trustworthiness cues and how those cues are processed by people to make trust judgments. Besides AI-generated content, we highlight transparency and interaction as AI systems' affordances that present a wide range of trustworthiness cues to users. By bringing to light the variety of users' cognitive processes to make trust judgments and their potential limitations, we urge technology creators to make conscious decisions in choosing reliable trustworthiness cues for target users and, as an industry, to regulate this space and prevent malicious use. Towards these goals, we define the concepts of warranted trustworthiness cues and expensive trustworthiness cues, and propose a checklist of requirements to help technology creators identify appropriate cues to use. We present a hypothetical use case to illustrate how practitioners can use MATCH to design AI systems responsibly, and discuss future directions for research and industry efforts aimed at promoting responsible trust in AI.

</p>
</details>

<details><summary><b>Visualization and Optimization Techniques for High Dimensional Parameter Spaces</b>
<a href="https://arxiv.org/abs/2204.13812">arxiv:2204.13812</a>
&#x1F4C8; 6 <br>
<p>Anjul Tyagi</p></summary>
<p>

**Abstract:** High dimensional parameter space optimization is crucial in many applications. The parameters affecting this performance can be both numerical and categorical in their type. The existing techniques of black-box optimization and visual analytics are good in dealing with numerical parameters but analyzing categorical variables in context of the numerical variables are not well studied. Hence, we propose a novel approach, to create an auto-tuning framework for storage systems optimization combining both direct optimization techniques and visual analytics research. While the optimization algorithm will be the core of the system, visual analytics will provide a guideline with the help of an external agent (expert) to provide crucial hints to narrow down the large search space for the optimization engine. As part of the initial step towards creating an auto-tuning engine for storage systems optimization, we created an Interactive Configuration Explorer \textit{ICE}, which directly addresses the need of analysts to learn how the dependent numerical variable is affected by the parameter settings given multiple optimization objectives. No information is lost as ICE shows the complete distribution and statistics of the dependent variable in context with each categorical variable. Analysts can interactively filter the variables to optimize for certain goals such as achieving a system with maximum performance, low variance, etc. Our system was developed in tight collaboration with a group of systems performance researchers and its final effectiveness was evaluated with expert interviews, a comparative user study, and two case studies. We also discuss our research plan for creating an efficient auto-tuning framework combining black-box optimization and visual analytics for storage systems performance optimization.

</p>
</details>

<details><summary><b>Vision-Language Pre-Training for Boosting Scene Text Detectors</b>
<a href="https://arxiv.org/abs/2204.13867">arxiv:2204.13867</a>
&#x1F4C8; 5 <br>
<p>Sibo Song, Jianqiang Wan, Zhibo Yang, Jun Tang, Wenqing Cheng, Xiang Bai, Cong Yao</p></summary>
<p>

**Abstract:** Recently, vision-language joint representation learning has proven to be highly effective in various scenarios. In this paper, we specifically adapt vision-language joint learning for scene text detection, a task that intrinsically involves cross-modal interaction between the two modalities: vision and language, since text is the written form of language. Concretely, we propose to learn contextualized, joint representations through vision-language pre-training, for the sake of enhancing the performance of scene text detectors. Towards this end, we devise a pre-training architecture with an image encoder, a text encoder and a cross-modal encoder, as well as three pretext tasks: image-text contrastive learning (ITC), masked language modeling (MLM) and word-in-image prediction (WIP). The pre-trained model is able to produce more informative representations with richer semantics, which could readily benefit existing scene text detectors (such as EAST and PSENet) in the down-stream text detection task. Extensive experiments on standard benchmarks demonstrate that the proposed paradigm can significantly improve the performance of various representative text detectors, outperforming previous pre-training approaches. The code and pre-trained models will be publicly released.

</p>
</details>

<details><summary><b>Detecting Textual Adversarial Examples Based on Distributional Characteristics of Data Representations</b>
<a href="https://arxiv.org/abs/2204.13853">arxiv:2204.13853</a>
&#x1F4C8; 5 <br>
<p>Na Liu, Mark Dras, Wei Emma Zhang</p></summary>
<p>

**Abstract:** Although deep neural networks have achieved state-of-the-art performance in various machine learning tasks, adversarial examples, constructed by adding small non-random perturbations to correctly classified inputs, successfully fool highly expressive deep classifiers into incorrect predictions. Approaches to adversarial attacks in natural language tasks have boomed in the last five years using character-level, word-level, phrase-level, or sentence-level textual perturbations. While there is some work in NLP on defending against such attacks through proactive methods, like adversarial training, there is to our knowledge no effective general reactive approaches to defence via detection of textual adversarial examples such as is found in the image processing literature. In this paper, we propose two new reactive methods for NLP to fill this gap, which unlike the few limited application baselines from NLP are based entirely on distribution characteristics of learned representations: we adapt one from the image processing literature (Local Intrinsic Dimensionality (LID)), and propose a novel one (MultiDistance Representation Ensemble Method (MDRE)). Adapted LID and MDRE obtain state-of-the-art results on character-level, word-level, and phrase-level attacks on the IMDB dataset as well as on the later two with respect to the MultiNLI dataset. For future research, we publish our code.

</p>
</details>

<details><summary><b>BILP-Q: Quantum Coalition Structure Generation</b>
<a href="https://arxiv.org/abs/2204.13802">arxiv:2204.13802</a>
&#x1F4C8; 5 <br>
<p>Supreeth Mysore Venkatesh, Antonio Macaluso, Matthias Klusch</p></summary>
<p>

**Abstract:** Quantum AI is an emerging field that uses quantum computing to solve typical complex problems in AI. In this work, we propose BILP-Q, the first-ever general quantum approach for solving the Coalition Structure Generation problem (CSGP), which is notably NP-hard. In particular, we reformulate the CSGP in terms of a Quadratic Binary Combinatorial Optimization (QUBO) problem to leverage existing quantum algorithms (e.g., QAOA) to obtain the best coalition structure. Thus, we perform a comparative analysis in terms of time complexity between the proposed quantum approach and the most popular classical baselines. Furthermore, we consider standard benchmark distributions for coalition values to test the BILP-Q on small-scale experiments using the IBM Qiskit environment. Finally, since QUBO problems can be solved operating with quantum annealing, we run BILP-Q on medium-size problems using a real quantum annealer (D-Wave).

</p>
</details>

<details><summary><b>Depth Estimation with Simplified Transformer</b>
<a href="https://arxiv.org/abs/2204.13791">arxiv:2204.13791</a>
&#x1F4C8; 5 <br>
<p>John Yang, Le An, Anurag Dixit, Jinkyu Koo, Su Inn Park</p></summary>
<p>

**Abstract:** Transformer and its variants have shown state-of-the-art results in many vision tasks recently, ranging from image classification to dense prediction. Despite of their success, limited work has been reported on improving the model efficiency for deployment in latency-critical applications, such as autonomous driving and robotic navigation. In this paper, we aim at improving upon the existing transformers in vision, and propose a method for self-supervised monocular Depth Estimation with Simplified Transformer (DEST), which is efficient and particularly suitable for deployment on GPU-based platforms. Through strategic design choices, our model leads to significant reduction in model size, complexity, as well as inference latency, while achieving superior accuracy as compared to state-of-the-art. We also show that our design generalize well to other dense prediction task without bells and whistles.

</p>
</details>

<details><summary><b>Learning to Split for Automatic Bias Detection</b>
<a href="https://arxiv.org/abs/2204.13749">arxiv:2204.13749</a>
&#x1F4C8; 5 <br>
<p>Yujia Bao, Regina Barzilay</p></summary>
<p>

**Abstract:** Classifiers are biased when trained on biased datasets. As a remedy, we propose Learning to Split (ls), an algorithm for automatic bias detection. Given a dataset with input-label pairs, ls learns to split this dataset so that predictors trained on the training split generalize poorly to the testing split. This performance gap provides a proxy for measuring the degree of bias in the learned features and can therefore be used to reduce biases. Identifying non-generalizable splits is challenging as we don't have any explicit annotations about how to split. In this work, we show that the prediction correctness of the testing example can be used as a source of weak supervision: generalization performance will drop if we move examples that are predicted correctly away from the testing split, leaving only those that are mispredicted. We evaluate our approach on Beer Review, Waterbirds, CelebA and MNLI. Empirical results show that ls is able to generate astonishingly challenging splits that correlate with human-identified biases. Moreover, we demonstrate that combining robust learning algorithms (such as group DRO) with splits identified by ls enables automatic de-biasing. Compared with previous state-of-the-arts, we substantially improves the worst-group performance (23.4% on average) when the source of biases is unknown during training and validation.

</p>
</details>

<details><summary><b>KING: Generating Safety-Critical Driving Scenarios for Robust Imitation via Kinematics Gradients</b>
<a href="https://arxiv.org/abs/2204.13683">arxiv:2204.13683</a>
&#x1F4C8; 5 <br>
<p>Niklas Hanselmann, Katrin Renz, Kashyap Chitta, Apratim Bhattacharyya, Andreas Geiger</p></summary>
<p>

**Abstract:** Simulators offer the possibility of safe, low-cost development of self-driving systems. However, current driving simulators exhibit naïve behavior models for background traffic. Hand-tuned scenarios are typically added during simulation to induce safety-critical situations. An alternative approach is to adversarially perturb the background traffic trajectories. In this paper, we study this approach to safety-critical driving scenario generation using the CARLA simulator. We use a kinematic bicycle model as a proxy to the simulator's true dynamics and observe that gradients through this proxy model are sufficient for optimizing the background traffic trajectories. Based on this finding, we propose KING, which generates safety-critical driving scenarios with a 20% higher success rate than black-box optimization. By solving the scenarios generated by KING using a privileged rule-based expert algorithm, we obtain training data for an imitation learning policy. After fine-tuning on this new data, we show that the policy becomes better at avoiding collisions. Importantly, our generated data leads to reduced collisions on both held-out scenarios generated via KING as well as traditional hand-crafted scenarios, demonstrating improved robustness.

</p>
</details>

<details><summary><b>Unified Simulation, Perception, and Generation of Human Behavior</b>
<a href="https://arxiv.org/abs/2204.13678">arxiv:2204.13678</a>
&#x1F4C8; 5 <br>
<p>Ye Yuan</p></summary>
<p>

**Abstract:** Understanding and modeling human behavior is fundamental to almost any computer vision and robotics applications that involve humans. In this thesis, we take a holistic approach to human behavior modeling and tackle its three essential aspects -- simulation, perception, and generation. Throughout the thesis, we show how the three aspects are deeply connected and how utilizing and improving one aspect can greatly benefit the other aspects. We also discuss the lessons learned and our vision for what is next for human behavior modeling.

</p>
</details>

<details><summary><b>Emotion Recognition In Persian Speech Using Deep Neural Networks</b>
<a href="https://arxiv.org/abs/2204.13601">arxiv:2204.13601</a>
&#x1F4C8; 5 <br>
<p>Ali Yazdani, Hossein Simchi, Yaser Shekofteh</p></summary>
<p>

**Abstract:** Speech Emotion Recognition (SER) is of great importance in Human-Computer Interaction (HCI), as it provides a deeper understanding of the situation and results in better interaction. In recent years, various machine learning and deep learning algorithms have been developed to improve SER techniques. Recognition of emotions depends on the type of expression that varies between different languages. In this article, to further study this important factor in Farsi, we examine various deep learning techniques on the SheEMO dataset. Using signal features in low- and high-level descriptions and different deep networks and machine learning techniques, Unweighted Average Recall (UAR) of 65.20 is achieved with an accuracy of 78.29.

</p>
</details>

<details><summary><b>TTAGN: Temporal Transaction Aggregation Graph Network for Ethereum Phishing Scams Detection</b>
<a href="https://arxiv.org/abs/2204.13442">arxiv:2204.13442</a>
&#x1F4C8; 5 <br>
<p>Sijia Li, Gaopeng Gou, Chang Liu, Chengshang Hou, Zhenzhen Li, Gang Xiong</p></summary>
<p>

**Abstract:** In recent years, phishing scams have become the most serious type of crime involved in Ethereum, the second-largest blockchain platform. The existing phishing scams detection technology on Ethereum mostly uses traditional machine learning or network representation learning to mine the key information from the transaction network to identify phishing addresses. However, these methods adopt the last transaction record or even completely ignore these records, and only manual-designed features are taken for the node representation. In this paper, we propose a Temporal Transaction Aggregation Graph Network (TTAGN) to enhance phishing scams detection performance on Ethereum. Specifically, in the temporal edges representation module, we model the temporal relationship of historical transaction records between nodes to construct the edge representation of the Ethereum transaction network. Moreover, the edge representations around the node are aggregated to fuse topological interactive relationships into its representation, also named as trading features, in the edge2node module. We further combine trading features with common statistical and structural features obtained by graph neural networks to identify phishing addresses. Evaluated on real-world Ethereum phishing scams datasets, our TTAGN (92.8% AUC, and 81.6% F1score) outperforms the state-of-the-art methods, and the effectiveness of temporal edges representation and edge2node module is also demonstrated.

</p>
</details>

<details><summary><b>Interpretable collective intelligence of non-rational human agents</b>
<a href="https://arxiv.org/abs/2204.13424">arxiv:2204.13424</a>
&#x1F4C8; 5 <br>
<p>Alexey V. Osipov, Nikolay N. Osipov</p></summary>
<p>

**Abstract:** We outline how to create a mechanism that provides an optimal way to elicit, from an arbitrary group of experts, the probability of the truth of an arbitrary logical proposition together with collective information that has an explicit form and interprets this probability. Such a system could, in particular, incentivize experts from all over the world to collectively solve scientific or medical problems in a very efficient manner. In our main considerations about real experts, they are not assumed to be Bayesian and their behavior is described by utilities that satisfy the von Neumann-Morgenstern axioms only locally.

</p>
</details>

<details><summary><b>Fuzzy Expert System for Stock Portfolio Selection: An Application to Bombay Stock Exchange</b>
<a href="https://arxiv.org/abs/2204.13385">arxiv:2204.13385</a>
&#x1F4C8; 5 <br>
<p>Gour Sundar Mitra Thakur, Rupak Bhattacharyyab, Seema Sarkar</p></summary>
<p>

**Abstract:** Selection of proper stocks, before allocating investment ratios, is always a crucial task for the investors. Presence of many influencing factors in stock performance have motivated researchers to adopt various Artificial Intelligence (AI) techniques to make this challenging task easier. In this paper a novel fuzzy expert system model is proposed to evaluate and rank the stocks under Bombay Stock Exchange (BSE). Dempster-Shafer (DS) evidence theory is used for the first time to automatically generate the consequents of the fuzzy rule base to reduce the effort in knowledge base development of the expert system. Later a portfolio optimization model is constructed where the objective function is considered as the ratio of the difference of fuzzy portfolio return and the risk free return to the weighted mean semi-variance of the assets that has been used. The model is solved by applying Ant Colony Optimization (ACO) algorithm by giving preference to the top ranked stocks. The performance of the model proved to be satisfactory for short-term investment period when compared with the recent performance of the stocks.

</p>
</details>

<details><summary><b>Semantic Communication: An Information Bottleneck View</b>
<a href="https://arxiv.org/abs/2204.13366">arxiv:2204.13366</a>
&#x1F4C8; 5 <br>
<p>Edgar Beck, Carsten Bockelmann, Armin Dekorsy</p></summary>
<p>

**Abstract:** Motivated by recent success of machine learning tools at the PHY layer and driven by high bandwidth demands of the next wireless communication standard 6G, the old idea of semantic communication by Weaver from 1949 has received considerable attention. It breaks with the classic design paradigm according to Shannon by aiming to transmit the meaning of a message rather than its exact copy and thus potentially allows for savings in bandwidth.
  In this work, inspired by Weaver, we propose an information-theoretic framework where the semantic context is explicitly introduced into probabilistic models. In particular, for bandwidth efficient transmission, we define semantic communication system design as an Information Bottleneck optimization problem and consider important implementation aspects. Further, we uncover the restrictions of the classic 5G communication system design w.r.t. semantic context. Notably, based on the example of distributed image classification, we reveal the huge potential of a semantic communication system design. Numerical results show a tremendous saving in bandwidth of 20 dB with our proposed approach ISCNet compared to a classic PHY layer design.

</p>
</details>

<details><summary><b>Repro: An Open-Source Library for Improving the Reproducibility and Usability of Publicly Available Research Code</b>
<a href="https://arxiv.org/abs/2204.13848">arxiv:2204.13848</a>
&#x1F4C8; 4 <br>
<p>Daniel Deutsch, Dan Roth</p></summary>
<p>

**Abstract:** We introduce Repro, an open-source library which aims at improving the reproducibility and usability of research code. The library provides a lightweight Python API for running software released by researchers within Docker containers which contain the exact required runtime configuration and dependencies for the code. Because the environment setup for each package is handled by Docker, users do not have to do any configuration themselves. Once Repro is installed, users can run the code for the 30+ papers currently supported by the library. We hope researchers see the value provided to others by including their research code in Repro and consider adding support for their own research code.

</p>
</details>

<details><summary><b>A Bottom-Up End-User Intelligent Assistant Approach to Empower Gig Workers against AI Inequality</b>
<a href="https://arxiv.org/abs/2204.13842">arxiv:2204.13842</a>
&#x1F4C8; 4 <br>
<p>Toby Jia-Jun Li, Yuwen Lu, Jaylexia Clark, Meng Chen, Victor Cox, Meng Jiang, Yang Yang, Tamara Kay, Danielle Wood, Jay Brockman</p></summary>
<p>

**Abstract:** The growing inequality in gig work between workers and platforms has become a critical social issue as gig work plays an increasingly prominent role in the future of work. The AI inequality is caused by (1) the technology divide in who has access to AI technologies in gig work; and (2) the data divide in who owns the data in gig work leads to unfair working conditions, growing pay gap, neglect of workers' diverse preferences, and workers' lack of trust in the platforms. In this position paper, we argue that a bottom-up approach that empowers individual workers to access AI-enabled work planning support and share data among a group of workers through a network of end-user-programmable intelligent assistants is a practical way to bridge AI inequality in gig work under the current paradigm of privately owned platforms. This position paper articulates a set of research challenges, potential approaches, and community engagement opportunities, seeking to start a dialogue on this important research topic in the interdisciplinary CHIWORK community.

</p>
</details>

<details><summary><b>A Neural Network-enhanced Reproducing Kernel Particle Method for Modeling Strain Localization</b>
<a href="https://arxiv.org/abs/2204.13821">arxiv:2204.13821</a>
&#x1F4C8; 4 <br>
<p>Jonghyuk Baek, Jiun-Shyan Chen, Kristen Susuki</p></summary>
<p>

**Abstract:** Modeling the localized intensive deformation in a damaged solid requires highly refined discretization for accurate prediction, which significantly increases the computational cost. Although adaptive model refinement can be employed for enhanced effectiveness, it is cumbersome for the traditional mesh-based methods to perform while modeling the evolving localizations. In this work, neural network-enhanced reproducing kernel particle method (NN-RKPM) is proposed, where the location, orientation, and shape of the solution transition near a localization is automatically captured by the NN approximation via a block-level neural network optimization. The weights and biases in the blocked parametrization network control the location and orientation of the localization. The designed basic four-kernel NN block is capable of capturing a triple junction or a quadruple junction topological pattern, while more complicated localization topological patters are captured by the superposition of multiple four-kernel NN blocks. The standard RK approximation is then utilized to approximate the smooth part of the solution, which permits a much coarser discretization than the high-resolution discretization needed to capture sharp solution transitions with the conventional methods. A regularization of the neural network approximation is additionally introduced for discretization-independent material responses. The effectiveness of the proposed NN-RKPM is verified by a series of numerical verifications.

</p>
</details>

<details><summary><b>Instilling Type Knowledge in Language Models via Multi-Task QA</b>
<a href="https://arxiv.org/abs/2204.13796">arxiv:2204.13796</a>
&#x1F4C8; 4 <br>
<p>Shuyang Li, Mukund Sridhar, Chandana Satya Prakash, Jin Cao, Wael Hamza, Julian McAuley</p></summary>
<p>

**Abstract:** Understanding human language often necessitates understanding entities and their place in a taxonomy of knowledge -- their types. Previous methods to learn entity types rely on training classifiers on datasets with coarse, noisy, and incomplete labels. We introduce a method to instill fine-grained type knowledge in language models with text-to-text pre-training on type-centric questions leveraging knowledge base documents and knowledge graphs. We create the WikiWiki dataset: entities and passages from 10M Wikipedia articles linked to the Wikidata knowledge graph with 41K types. Models trained on WikiWiki achieve state-of-the-art performance in zero-shot dialog state tracking benchmarks, accurately infer entity types in Wikipedia articles, and can discover new types deemed useful by human judges.

</p>
</details>

<details><summary><b>BEINIT: Avoiding Barren Plateaus in Variational Quantum Algorithms</b>
<a href="https://arxiv.org/abs/2204.13751">arxiv:2204.13751</a>
&#x1F4C8; 4 <br>
<p>Ankit Kulshrestha, Ilya Safro</p></summary>
<p>

**Abstract:** Barren plateaus are a notorious problem in the optimization of variational quantum algorithms and pose a critical obstacle in the quest for more efficient quantum machine learning algorithms. Many potential reasons for barren plateaus have been identified but few solutions have been proposed to avoid them in practice. Existing solutions are mainly focused on the initialization of unitary gate parameters without taking into account the changes induced by input data. In this paper, we propose an alternative strategy which initializes the parameters of a unitary gate by drawing from a beta distribution. The hyperparameters of the beta distribution are estimated from the data. To further prevent barren plateau during training we add a novel perturbation at every gradient descent step. Taking these ideas together, we empirically show that our proposed framework significantly reduces the possibility of a complex quantum neural network getting stuck in a barren plateau.

</p>
</details>

<details><summary><b>Tag-assisted Multimodal Sentiment Analysis under Uncertain Missing Modalities</b>
<a href="https://arxiv.org/abs/2204.13707">arxiv:2204.13707</a>
&#x1F4C8; 4 <br>
<p>Jiandian Zeng, Tianyi Liu, Jiantao Zhou</p></summary>
<p>

**Abstract:** Multimodal sentiment analysis has been studied under the assumption that all modalities are available. However, such a strong assumption does not always hold in practice, and most of multimodal fusion models may fail when partial modalities are missing. Several works have addressed the missing modality problem; but most of them only considered the single modality missing case, and ignored the practically more general cases of multiple modalities missing. To this end, in this paper, we propose a Tag-Assisted Transformer Encoder (TATE) network to handle the problem of missing uncertain modalities. Specifically, we design a tag encoding module to cover both the single modality and multiple modalities missing cases, so as to guide the network's attention to those missing modalities. Besides, we adopt a new space projection pattern to align common vectors. Then, a Transformer encoder-decoder network is utilized to learn the missing modality features. At last, the outputs of the Transformer encoder are used for the final sentiment classification. Extensive experiments are conducted on CMU-MOSI and IEMOCAP datasets, showing that our method can achieve significant improvements compared with several baselines.

</p>
</details>

<details><summary><b>Standardized Evaluation of Machine Learning Methods for Evolving Data Streams</b>
<a href="https://arxiv.org/abs/2204.13625">arxiv:2204.13625</a>
&#x1F4C8; 4 <br>
<p>Johannes Haug, Effi Tramountani, Gjergji Kasneci</p></summary>
<p>

**Abstract:** Due to the unspecified and dynamic nature of data streams, online machine learning requires powerful and flexible solutions. However, evaluating online machine learning methods under realistic conditions is difficult. Existing work therefore often draws on different heuristics and simulations that do not necessarily produce meaningful and reliable results. Indeed, in the absence of common evaluation standards, it often remains unclear how online learning methods will perform in practice or in comparison to similar work. In this paper, we propose a comprehensive set of properties for high-quality machine learning in evolving data streams. In particular, we discuss sensible performance measures and evaluation strategies for online predictive modelling, online feature selection and concept drift detection. As one of the first works, we also look at the interpretability of online learning methods. The proposed evaluation standards are provided in a new Python framework called float. Float is completely modular and allows the simultaneous integration of common libraries, such as scikit-multiflow or river, with custom code. Float is open-sourced and can be accessed at https://github.com/haugjo/float. In this sense, we hope that our work will contribute to more standardized, reliable and realistic testing and comparison of online machine learning methods.

</p>
</details>

<details><summary><b>Justice in Misinformation Detection Systems: An Analysis of Algorithms, Stakeholders, and Potential Harms</b>
<a href="https://arxiv.org/abs/2204.13568">arxiv:2204.13568</a>
&#x1F4C8; 4 <br>
<p>Terrence Neumann, Maria De-Arteaga, Sina Fazelpour</p></summary>
<p>

**Abstract:** Faced with the scale and surge of misinformation on social media, many platforms and fact-checking organizations have turned to algorithms for automating key parts of misinformation detection pipelines. While offering a promising solution to the challenge of scale, the ethical and societal risks associated with algorithmic misinformation detection are not well-understood. In this paper, we employ and extend upon the notion of informational justice to develop a framework for explicating issues of justice relating to representation, participation, distribution of benefits and burdens, and credibility in the misinformation detection pipeline. Drawing on the framework: (1) we show how injustices materialize for stakeholders across three algorithmic stages in the pipeline; (2) we suggest empirical measures for assessing these injustices; and (3) we identify potential sources of these harms. This framework should help researchers, policymakers, and practitioners reason about potential harms or risks associated with these algorithms and provide conceptual guidance for the design of algorithmic fairness audits in this domain.

</p>
</details>

<details><summary><b>TJ4DRadSet: A 4D Radar Dataset for Autonomous Driving</b>
<a href="https://arxiv.org/abs/2204.13483">arxiv:2204.13483</a>
&#x1F4C8; 4 <br>
<p>Lianqing Zheng, Zhixiong Ma, Xichan Zhu, Bin Tan, Sen Li, Kai Long, Weiqi Sun, Sihan Chen, Lu Zhang, Mengyue Wan, Libo Huang, Jie Bai</p></summary>
<p>

**Abstract:** The new generation of 4D high-resolution imaging radar provides not only a huge amount of point cloud but also additional elevation measurement, which has a great potential of 3D sensing in autonomous driving. In this paper, we introduce an autonomous driving dataset named TJ4DRadSet, including multi-modal sensors that are 4D radar, lidar, camera and GNSS, with about 40K frames in total. 7757 frames within 44 consecutive sequences in various driving scenarios are well annotated with 3D bounding boxes and track id. We provide a 4D radar-based 3D object detection baseline for our dataset to demonstrate the effectiveness of deep learning methods for 4D radar point clouds.

</p>
</details>

<details><summary><b>Deep Orientation-Aware Functional Maps: Tackling Symmetry Issues in Shape Matching</b>
<a href="https://arxiv.org/abs/2204.13453">arxiv:2204.13453</a>
&#x1F4C8; 4 <br>
<p>Nicolas Donati, Etienne Corman, Maks Ovsjanikov</p></summary>
<p>

**Abstract:** State-of-the-art fully intrinsic networks for non-rigid shape matching often struggle to disambiguate the symmetries of the shapes leading to unstable correspondence predictions. Meanwhile, recent advances in the functional map framework allow to enforce orientation preservation using a functional representation for tangent vector field transfer, through so-called complex functional maps. Using this representation, we propose a new deep learning approach to learn orientation-aware features in a fully unsupervised setting. Our architecture is built on top of DiffusionNet, making it robust to discretization changes. Additionally, we introduce a vector field-based loss, which promotes orientation preservation without using (often unstable) extrinsic descriptors.

</p>
</details>

<details><summary><b>Keep the Caption Information: Preventing Shortcut Learning in Contrastive Image-Caption Retrieval</b>
<a href="https://arxiv.org/abs/2204.13382">arxiv:2204.13382</a>
&#x1F4C8; 4 <br>
<p>Maurits Bleeker, Andrew Yates, Maarten de Rijke</p></summary>
<p>

**Abstract:** To train image-caption retrieval (ICR) methods, contrastive loss functions are a common choice for optimization functions. Unfortunately, contrastive ICR methods are vulnerable to learning shortcuts: decision rules that perform well on the training data but fail to transfer to other testing conditions. We introduce an approach to reduce shortcut feature representations for the ICR task: latent target decoding (LTD). We add an additional decoder to the learning framework to reconstruct the input caption, which prevents the image and caption encoder from learning shortcut features. Instead of reconstructing input captions in the input space, we decode the semantics of the caption in a latent space. We implement the LTD objective as an optimization constraint, to ensure that the reconstruction loss is below a threshold value while primarily optimizing for the contrastive loss. Importantly, LTD does not depend on additional training data or expensive (hard) negative mining strategies. Our experiments show that, unlike reconstructing the input caption, LTD reduces shortcut learning and improves generalizability by obtaining higher recall@k and r-precision scores. Additionally, we show that the evaluation scores benefit from implementing LTD as an optimization constraint instead of a dual loss.

</p>
</details>

<details><summary><b>Discriminative-Region Attention and Orthogonal-View Generation Model for Vehicle Re-Identification</b>
<a href="https://arxiv.org/abs/2204.13323">arxiv:2204.13323</a>
&#x1F4C8; 4 <br>
<p>Huadong Li, Yuefeng Wang, Ying Wei, Lin Wang, Li Ge</p></summary>
<p>

**Abstract:** Vehicle re-identification (Re-ID) is urgently demanded to alleviate thepressure caused by the increasingly onerous task of urban traffic management. Multiple challenges hamper the applications of vision-based vehicle Re-ID methods: (1) The appearances of different vehicles of the same brand/model are often similar; However, (2) the appearances of the same vehicle differ significantly from different viewpoints. Previous methods mainly use manually annotated multi-attribute datasets to assist the network in getting detailed cues and in inferencing multi-view to improve the vehicle Re-ID performance. However, finely labeled vehicle datasets are usually unattainable in real application scenarios. Hence, we propose a Discriminative-Region Attention and Orthogonal-View Generation (DRA-OVG) model, which only requires identity (ID) labels to conquer the multiple challenges of vehicle Re-ID.The proposed DRA model can automatically extract the discriminative region features, which can distinguish similar vehicles. And the OVG model can generate multi-view features based on the input view features to reduce the impact of viewpoint mismatches. Finally, the distance between vehicle appearances is presented by the discriminative region features and multi-view features together. Therefore, the significance of pairwise distance measure between vehicles is enhanced in acomplete feature space. Extensive experiments substantiate the effectiveness of each proposed ingredient, and experimental results indicate that our approach achieves remarkable improvements over the state- of-the-art vehicle Re-ID methods on VehicleID and VeRi-776 datasets.

</p>
</details>

<details><summary><b>CATNet: Cross-event Attention-based Time-aware Network for Medical Event Prediction</b>
<a href="https://arxiv.org/abs/2204.13847">arxiv:2204.13847</a>
&#x1F4C8; 3 <br>
<p>Sicen Liu, Xiaolong Wang, Yang Xiang, Hui Xu, Hui Wang, Buzhou Tang</p></summary>
<p>

**Abstract:** Medical event prediction (MEP) is a fundamental task in the medical domain, which needs to predict medical events, including medications, diagnosis codes, laboratory tests, procedures, outcomes, and so on, according to historical medical records. The task is challenging as medical data is a type of complex time series data with heterogeneous and temporal irregular characteristics. Many machine learning methods that consider the two characteristics have been proposed for medical event prediction. However, most of them consider the two characteristics separately and ignore the correlations among different types of medical events, especially relations between historical medical events and target medical events. In this paper, we propose a novel neural network based on attention mechanism, called cross-event attention-based time-aware network (CATNet), for medical event prediction. It is a time-aware, event-aware and task-adaptive method with the following advantages: 1) modeling heterogeneous information and temporal information in a unified way and considering temporal irregular characteristics locally and globally respectively, 2) taking full advantage of correlations among different types of events via cross-event attention. Experiments on two public datasets (MIMIC-III and eICU) show CATNet can be adaptive with different MEP tasks and outperforms other state-of-the-art methods on various MEP tasks. The source code of CATNet will be released after this manuscript is accepted.

</p>
</details>

<details><summary><b>Noise-reducing attention cross fusion learning transformer for histological image classification of osteosarcoma</b>
<a href="https://arxiv.org/abs/2204.13838">arxiv:2204.13838</a>
&#x1F4C8; 3 <br>
<p>Liangrui Pan, Hetian Wang, Lian Wang, Boya Ji, Mingting Liu, Mitchai Chongcheawchamnan, Jin Yuan, Shaoliang Peng</p></summary>
<p>

**Abstract:** The degree of malignancy of osteosarcoma and its tendency to metastasize/spread mainly depend on the pathological grade (determined by observing the morphology of the tumor under a microscope). The purpose of this study is to use artificial intelligence to classify osteosarcoma histological images and to assess tumor survival and necrosis, which will help doctors reduce their workload, improve the accuracy of osteosarcoma cancer detection, and make a better prognosis for patients. The study proposes a typical transformer image classification framework by integrating noise reduction convolutional autoencoder and feature cross fusion learning (NRCA-FCFL) to classify osteosarcoma histological images. Noise reduction convolutional autoencoder could well denoise histological images of osteosarcoma, resulting in more pure images for osteosarcoma classification. Moreover, we introduce feature cross fusion learning, which integrates two scale image patches, to sufficiently explore their interactions by using additional classification tokens. As a result, a refined fusion feature is generated, which is fed to the residual neural network for label predictions. We conduct extensive experiments to evaluate the performance of the proposed approach. The experimental results demonstrate that our method outperforms the traditional and deep learning approaches on various evaluation metrics, with an accuracy of 99.17% to support osteosarcoma diagnosis.

</p>
</details>

<details><summary><b>A First Runtime Analysis of the NSGA-II on a Multimodal Problem</b>
<a href="https://arxiv.org/abs/2204.13750">arxiv:2204.13750</a>
&#x1F4C8; 3 <br>
<p>Zhongdi Qu, Benjamin Doerr</p></summary>
<p>

**Abstract:** Very recently, the first mathematical runtime analyses of the multi-objective evolutionary optimizer NSGA-II have been conducted (AAAI 2022, GECCO 2022 (to appear), arxiv 2022). We continue this line of research with a first runtime analysis of this algorithm on a benchmark problem consisting of two multimodal objectives. We prove that if the population size $N$ is at least four times the size of the Pareto front, then the NSGA-II with four different ways to select parents and bit-wise mutation optimizes the OneJumpZeroJump benchmark with jump size~$2 \le k \le n/4$ in time $O(N n^k)$. When using fast mutation, a recently proposed heavy-tailed mutation operator, this guarantee improves by a factor of $k^{Ω(k)}$. Overall, this work shows that the NSGA-II copes with the local optima of the OneJumpZeroJump problem at least as well as the global SEMO algorithm.

</p>
</details>

<details><summary><b>Bilinear value networks</b>
<a href="https://arxiv.org/abs/2204.13695">arxiv:2204.13695</a>
&#x1F4C8; 3 <br>
<p>Zhang-Wei Hong, Ge Yang, Pulkit Agrawal</p></summary>
<p>

**Abstract:** The dominant framework for off-policy multi-goal reinforcement learning involves estimating goal conditioned Q-value function. When learning to achieve multiple goals, data efficiency is intimately connected with the generalization of the Q-function to new goals. The de-facto paradigm is to approximate Q(s, a, g) using monolithic neural networks. To improve the generalization of the Q-function, we propose a bilinear decomposition that represents the Q-value via a low-rank approximation in the form of a dot product between two vector fields. The first vector field, f(s, a), captures the environment's local dynamics at the state s; whereas the second component, φ(s, g), captures the global relationship between the current state and the goal. We show that our bilinear decomposition scheme substantially improves data efficiency, and has superior transfer to out-of-distribution goals compared to prior methods. Empirical evidence is provided on the simulated Fetch robot task-suite and dexterous manipulation with a Shadow hand.

</p>
</details>

<details><summary><b>Toward Compositional Generalization in Object-Oriented World Modeling</b>
<a href="https://arxiv.org/abs/2204.13661">arxiv:2204.13661</a>
&#x1F4C8; 3 <br>
<p>Linfeng Zhao, Lingzhi Kong, Robin Walters, Lawson L. S. Wong</p></summary>
<p>

**Abstract:** Compositional generalization is a critical ability in learning and decision-making. We focus on the setting of reinforcement learning in object-oriented environments to study compositional generalization in world modeling. We (1) formalize the compositional generalization problem with an algebraic approach and (2) study how a world model can achieve that. We introduce a conceptual environment, Object Library, and two instances, and deploy a principled pipeline to measure the generalization ability. Motivated by the formulation, we analyze several methods with exact} or no compositional generalization ability using our framework, and design a differentiable approach, Homomorphic Object-oriented World Model (HOWM), that achieves approximate but more efficient compositional generalization.

</p>
</details>

<details><summary><b>Russian Texts Detoxification with Levenshtein Editing</b>
<a href="https://arxiv.org/abs/2204.13638">arxiv:2204.13638</a>
&#x1F4C8; 3 <br>
<p>Ilya Gusev</p></summary>
<p>

**Abstract:** Text detoxification is a style transfer task of creating neutral versions of toxic texts. In this paper, we use the concept of text editing to build a two-step tagging-based detoxification model using a parallel corpus of Russian texts. With this model, we achieved the best style transfer accuracy among all models in the RUSSE Detox shared task, surpassing larger sequence-to-sequence models.

</p>
</details>

<details><summary><b>Bona fide Riesz projections for density estimation</b>
<a href="https://arxiv.org/abs/2204.13606">arxiv:2204.13606</a>
&#x1F4C8; 3 <br>
<p>P. del Aguila Pla, Michael Unser</p></summary>
<p>

**Abstract:** The projection of sample measurements onto a reconstruction space represented by a basis on a regular grid is a powerful and simple approach to estimate a probability density function. In this paper, we focus on Riesz bases and propose a projection operator that, in contrast to previous works, guarantees the bona fide properties for the estimate, namely, non-negativity and total probability mass $1$. Our bona fide projection is defined as a convex problem. We propose solution techniques and evaluate them. Results suggest an improved performance, specifically in circumstances prone to rippling effects.

</p>
</details>

<details><summary><b>Computer Vision for Road Imaging and Pothole Detection: A State-of-the-Art Review of Systems and Algorithms</b>
<a href="https://arxiv.org/abs/2204.13590">arxiv:2204.13590</a>
&#x1F4C8; 3 <br>
<p>Nachuan Ma, Jiahe Fan, Wenshuo Wang, Jin Wu, Yu Jiang, Lihua Xie, Rui Fan</p></summary>
<p>

**Abstract:** Computer vision algorithms have been prevalently utilized for 3-D road imaging and pothole detection for over two decades. Nonetheless, there is a lack of systematic survey articles on state-of-the-art (SoTA) computer vision techniques, especially deep learning models, developed to tackle these problems. This article first introduces the sensing systems employed for 2-D and 3-D road data acquisition, including camera(s), laser scanners, and Microsoft Kinect. Afterward, it thoroughly and comprehensively reviews the SoTA computer vision algorithms, including (1) classical 2-D image processing, (2) 3-D point cloud modeling and segmentation, and (3) machine/deep learning, developed for road pothole detection. This article also discusses the existing challenges and future development trends of computer vision-based road pothole detection approaches: classical 2-D image processing-based and 3-D point cloud modeling and segmentation-based approaches have already become history; and Convolutional neural networks (CNNs) have demonstrated compelling road pothole detection results and are promising to break the bottleneck with the future advances in self/un-supervised learning for multi-modal semantic segmentation. We believe that this survey can serve as practical guidance for developing the next-generation road condition assessment systems.

</p>
</details>

<details><summary><b>Inverse-Designed Meta-Optics with Spectral-Spatial Engineered Response to Mimic Color Perception</b>
<a href="https://arxiv.org/abs/2204.13520">arxiv:2204.13520</a>
&#x1F4C8; 3 <br>
<p>Chris Munley, Wenchao Ma, Johannes E. Fröch, Quentin A. A. Tanguy, Elyas Bayati, Karl F. Böhringer, Zin Lin, Raphaël Pestourie, Steven G. Johnson, Arka Majumdar</p></summary>
<p>

**Abstract:** Meta-optics have rapidly become a major research field within the optics and photonics community, strongly driven by the seemingly limitless opportunities made possible by controlling optical wavefronts through interaction with arrays of sub-wavelength scatterers. As more and more modalities are explored, the design strategies to achieve desired functionalities become increasingly demanding, necessitating more advanced design techniques. Herein, the inverse-design approach is utilized to create a set of single-layer meta-optics that simultaneously focus light and shape the spectra of focused light without using any filters. Thus, both spatial and spectral properties of the meta-optics are optimized, resulting in spectra that mimic the color matching functions of the CIE 1931 XYZ color space, which links the distributions of wavelengths in light and the color perception of a human eye. Experimental demonstrations of these meta-optics show qualitative agreement with the theoretical predictions and help elucidate the focusing mechanism of these devices.

</p>
</details>

<details><summary><b>Unsupervised Spatial-spectral Hyperspectral Image Reconstruction and Clustering with Diffusion Geometry</b>
<a href="https://arxiv.org/abs/2204.13497">arxiv:2204.13497</a>
&#x1F4C8; 3 <br>
<p>Kangning Cui, Ruoning Li, Sam L. Polk, James M. Murphy, Robert J. Plemmons, Raymond H. Chan</p></summary>
<p>

**Abstract:** Hyperspectral images, which store a hundred or more spectral bands of reflectance, have become an important data source in natural and social sciences. Hyperspectral images are often generated in large quantities at a relatively coarse spatial resolution. As such, unsupervised machine learning algorithms incorporating known structure in hyperspectral imagery are needed to analyze these images automatically. This work introduces the Spatial-Spectral Image Reconstruction and Clustering with Diffusion Geometry (DSIRC) algorithm for partitioning highly mixed hyperspectral images. DSIRC reduces measurement noise through a shape-adaptive reconstruction procedure. In particular, for each pixel, DSIRC locates spectrally correlated pixels within a data-adaptive spatial neighborhood and reconstructs that pixel's spectral signature using those of its neighbors. DSIRC then locates high-density, high-purity pixels far in diffusion distance (a data-dependent distance metric) from other high-density, high-purity pixels and treats these as cluster exemplars, giving each a unique label. Non-modal pixels are assigned the label of their diffusion distance-nearest neighbor of higher density and purity that is already labeled. Strong numerical results indicate that incorporating spatial information through image reconstruction substantially improves the performance of pixel-wise clustering.

</p>
</details>

<details><summary><b>Regotron: Regularizing the Tacotron2 architecture via monotonic alignment loss</b>
<a href="https://arxiv.org/abs/2204.13437">arxiv:2204.13437</a>
&#x1F4C8; 3 <br>
<p>Efthymios Georgiou, Kosmas Kritsis, Georgios Paraskevopoulos, Athanasios Katsamanis, Vassilis Katsouros, Alexandros Potamianos</p></summary>
<p>

**Abstract:** Recent deep learning Text-to-Speech (TTS) systems have achieved impressive performance by generating speech close to human parity. However, they suffer from training stability issues as well as incorrect alignment of the intermediate acoustic representation with the input text sequence. In this work, we introduce Regotron, a regularized version of Tacotron2 which aims to alleviate the training issues and at the same time produce monotonic alignments. Our method augments the vanilla Tacotron2 objective function with an additional term, which penalizes non-monotonic alignments in the location-sensitive attention mechanism. By properly adjusting this regularization term we show that the loss curves become smoother, and at the same time Regotron consistently produces monotonic alignments in unseen examples even at an early stage (13\% of the total number of epochs) of its training process, whereas the fully converged Tacotron2 fails to do so. Moreover, our proposed regularization method has no additional computational overhead, while reducing common TTS mistakes and achieving slighlty improved speech naturalness according to subjective mean opinion scores (MOS) collected from 50 evaluators.

</p>
</details>

<details><summary><b>WeaNF: Weak Supervision with Normalizing Flows</b>
<a href="https://arxiv.org/abs/2204.13409">arxiv:2204.13409</a>
&#x1F4C8; 3 <br>
<p>Andreas Stephan, Benjamin Roth</p></summary>
<p>

**Abstract:** A popular approach to decrease the need for costly manual annotation of large data sets is weak supervision, which introduces problems of noisy labels, coverage and bias. Methods for overcoming these problems have either relied on discriminative models, trained with cost functions specific to weak supervision, and more recently, generative models, trying to model the output of the automatic annotation process. In this work, we explore a novel direction of generative modeling for weak supervision: Instead of modeling the output of the annotation process (the labeling function matches), we generatively model the input-side data distributions (the feature space) covered by labeling functions. Specifically, we estimate a density for each weak labeling source, or labeling function, by using normalizing flows. An integral part of our method is the flow-based modeling of multiple simultaneously matching labeling functions, and therefore phenomena such as labeling function overlap and correlations are captured. We analyze the effectiveness and modeling capabilities on various commonly used weak supervision data sets, and show that weakly supervised normalizing flows compare favorably to standard weak supervision baselines.

</p>
</details>

<details><summary><b>List-Mode PET Image Reconstruction Using Deep Image Prior</b>
<a href="https://arxiv.org/abs/2204.13404">arxiv:2204.13404</a>
&#x1F4C8; 3 <br>
<p>Kibo Ote, Fumio Hashimoto, Yuya Onishi, Takashi Isobe, Yasuomi Ouchi</p></summary>
<p>

**Abstract:** List-mode positron emission tomography (PET) image reconstruction is an important tool for PET scanners with many lines-of-response (LORs) and additional information such as time-of-flight and depth-of-interaction. Deep learning is one possible solution to enhance the quality of PET image reconstruction. However, the application of deep learning techniques to list-mode PET image reconstruction have not been progressed because list data is a sequence of bit codes and unsuitable for processing by convolutional neural networks (CNN). In this study, we propose a novel list-mode PET image reconstruction method using an unsupervised CNN called deep image prior (DIP) and a framework of alternating direction method of multipliers. The proposed list-mode DIP reconstruction (LM-DIPRecon) method alternatively iterates regularized list-mode dynamic row action maximum likelihood algorithm (LM-DRAMA) and magnetic resonance imaging conditioned DIP (MR-DIP). We evaluated LM-DIPRecon using both simulation and clinical data, and it achieved sharper images and better tradeoff curves between contrast and noise than the LM-DRAMA and MR-DIP. These results indicated that the LM-DIPRecon is useful for quantitative PET imaging with limited events. In addition, as list data has finer temporal information than dynamic sinograms, list-mode deep image prior reconstruction is expected to be useful for 4D PET imaging and motion correction.

</p>
</details>

<details><summary><b>Learning General Inventory Management Policy for Large Supply Chain Network</b>
<a href="https://arxiv.org/abs/2204.13378">arxiv:2204.13378</a>
&#x1F4C8; 3 <br>
<p>Soh Kumabe, Shinya Shiroshita, Takanori Hayashi, Shirou Maruyama</p></summary>
<p>

**Abstract:** Inventory management in warehouses directly affects profits made by manufacturers. Particularly, large manufacturers produce a very large variety of products that are handled by a significantly large number of retailers. In such a case, the computational complexity of classical inventory management algorithms is inordinately large. In recent years, learning-based approaches have become popular for addressing such problems. However, previous studies have not been managed systems where both the number of products and retailers are large. This study proposes a reinforcement learning-based warehouse inventory management algorithm that can be used for supply chain systems where both the number of products and retailers are large. To solve the computational problem of handling large systems, we provide a means of approximate simulation of the system in the training phase. Our experiments on both real and artificial data demonstrate that our algorithm with approximated simulation can successfully handle large supply chain networks.

</p>
</details>

<details><summary><b>Machine learning for knowledge acquisition and accelerated inverse-design for non-Hermitian systems</b>
<a href="https://arxiv.org/abs/2204.13376">arxiv:2204.13376</a>
&#x1F4C8; 3 <br>
<p>W. W. Ahmed, M. Farhat, K. Staliunas, X. Zhang, Y. Wu</p></summary>
<p>

**Abstract:** Non-Hermitian systems offer new platforms for unusual physical properties that can be flexibly manipulated by redistribution of the real and imaginary parts of refractive indices, whose presence breaks conventional wave propagation symmetries, leading to asymmetric reflection and symmetric transmission with respect to the wave propagation direction. Here, we use supervised and unsupervised learning techniques for knowledge acquisition in non-Hermitian systems which accelerate the inverse design process. In particular, we construct a deep learning model that relates the transmission and asymmetric reflection in non-conservative settings and proposes sub-manifold learning to recognize non-Hermitian features from transmission spectra. The developed deep learning framework determines the feasibility of a desired spectral response for a given structure and uncovers the role of effective gain-loss parameters to tailor the spectral response. These findings pave the way for intelligent inverse design and shape our understanding of the physical mechanism in general non-Hermitian systems.

</p>
</details>

<details><summary><b>Continual Learning with Bayesian Model based on a Fixed Pre-trained Feature Extractor</b>
<a href="https://arxiv.org/abs/2204.13349">arxiv:2204.13349</a>
&#x1F4C8; 3 <br>
<p>Yang Yang, Zhiying Cui, Junjie Xu, Changhong Zhong, Wei-Shi Zheng, Ruixuan Wang</p></summary>
<p>

**Abstract:** Deep learning has shown its human-level performance in various applications. However, current deep learning models are characterised by catastrophic forgetting of old knowledge when learning new classes. This poses a challenge particularly in intelligent diagnosis systems where initially only training data of a limited number of diseases are available. In this case, updating the intelligent system with data of new diseases would inevitably downgrade its performance on previously learned diseases. Inspired by the process of learning new knowledge in human brains, we propose a Bayesian generative model for continual learning built on a fixed pre-trained feature extractor. In this model, knowledge of each old class can be compactly represented by a collection of statistical distributions, e.g. with Gaussian mixture models, and naturally kept from forgetting in continual learning over time. Unlike existing class-incremental learning methods, the proposed approach is not sensitive to the continual learning process and can be additionally well applied to the data-incremental learning scenario. Experiments on multiple medical and natural image classification tasks showed that the proposed approach outperforms state-of-the-art approaches which even keep some images of old classes during continual learning of new classes.

</p>
</details>

<details><summary><b>MMRotate: A Rotated Object Detection Benchmark using Pytorch</b>
<a href="https://arxiv.org/abs/2204.13317">arxiv:2204.13317</a>
&#x1F4C8; 3 <br>
<p>Yue Zhou, Xue Yang, Gefan Zhang, Jiabao Wang, Yanyi Liu, Liping Hou, Xue Jiang, Xingzhao Liu, Junchi Yan, Chengqi Lyu, Wenwei Zhang, Kai Chen</p></summary>
<p>

**Abstract:** We present an open-source toolbox, named MMRotate, which provides a coherent algorithm framework of training, inferring, and evaluation for the popular rotated object detection algorithm based on deep learning. MMRotate implements 18 state-of-the-art algorithms and supports the three most frequently used angle definition methods. To facilitate future research and industrial applications of rotated object detection-related problems, we also provide a large number of trained models and detailed benchmarks to give insights into the performance of rotated object detection. MMRotate is publicly released at https://github.com/open-mmlab/mmrotate.

</p>
</details>

<details><summary><b>Enhance Ambiguous Community Structure via Multi-strategy Community Related Link Prediction Method with Evolutionary Process</b>
<a href="https://arxiv.org/abs/2204.13301">arxiv:2204.13301</a>
&#x1F4C8; 3 <br>
<p>Qiming Yang, Wei Wei, Ruizhi Zhang, Bowen Pang, Xiangnan Feng</p></summary>
<p>

**Abstract:** Most real-world networks suffer from incompleteness or incorrectness, which is an inherent attribute to real-world datasets. As a consequence, those downstream machine learning tasks in complex network like community detection methods may yield less satisfactory results, i.e., a proper preprocessing measure is required here. To address this issue, in this paper, we design a new community attribute based link prediction strategy HAP and propose a two-step community enhancement algorithm with automatic evolution process based on HAP. This paper aims at providing a community enhancement measure through adding links to clarify ambiguous community structures. The HAP method takes the neighbourhood uncertainty and Shannon entropy to identify boundary nodes, and establishes links by considering the nodes' community attributes and community size at the same time. The experimental results on twelve real-world datasets with ground truth community indicate that the proposed link prediction method outperforms other baseline methods and the enhancement of community follows the expected evolution process.

</p>
</details>

<details><summary><b>Energy Minimization for Federated Asynchronous Learning on Battery-Powered Mobile Devices via Application Co-running</b>
<a href="https://arxiv.org/abs/2204.13878">arxiv:2204.13878</a>
&#x1F4C8; 2 <br>
<p>Cong Wang, Bin Hu, Hongyi Wu</p></summary>
<p>

**Abstract:** Energy is an essential, but often forgotten aspect in large-scale federated systems. As most of the research focuses on tackling computational and statistical heterogeneity from the machine learning algorithms, the impact on the mobile system still remains unclear. In this paper, we design and implement an online optimization framework by connecting asynchronous execution of federated training with application co-running to minimize energy consumption on battery-powered mobile devices. From a series of experiments, we find that co-running the training process in the background with foreground applications gives the system a deep energy discount with negligible performance slowdown. Based on these results, we first study an offline problem assuming all the future occurrences of applications are available, and propose a dynamic programming-based algorithm. Then we propose an online algorithm using the Lyapunov framework to explore the solution space via the energy-staleness trade-off. The extensive experiments demonstrate that the online optimization framework can save over 60% energy with 3 times faster convergence speed compared to the previous schemes.

</p>
</details>

<details><summary><b>One-Way Matching of Datasets with Low Rank Signals</b>
<a href="https://arxiv.org/abs/2204.13858">arxiv:2204.13858</a>
&#x1F4C8; 2 <br>
<p>Shuxiao Chen, Sizun Jiang, Zongming Ma, Garry P. Nolan, Bokai Zhu</p></summary>
<p>

**Abstract:** We study one-way matching of a pair of datasets with low rank signals. Under a stylized model, we first derive information-theoretic limits of matching. We then show that linear assignment with projected data achieves fast rates of convergence and sometimes even minimax rate optimality for this task. The theoretical error bounds are corroborated by simulated examples. Furthermore, we illustrate practical use of the matching procedure on two single-cell data examples.

</p>
</details>

<details><summary><b>H2H: Heterogeneous Model to Heterogeneous System Mapping with Computation and Communication Awareness</b>
<a href="https://arxiv.org/abs/2204.13852">arxiv:2204.13852</a>
&#x1F4C8; 2 <br>
<p>Xinyi Zhang, Cong Hao, Peipei Zhou, Alex Jones, Jingtong Hu</p></summary>
<p>

**Abstract:** The complex nature of real-world problems calls for heterogeneity in both machine learning (ML) models and hardware systems. The heterogeneity in ML models comes from multi-sensor perceiving and multi-task learning, i.e., multi-modality multi-task (MMMT), resulting in diverse deep neural network (DNN) layers and computation patterns. The heterogeneity in systems comes from diverse processing components, as it becomes the prevailing method to integrate multiple dedicated accelerators into one system. Therefore, a new problem emerges: heterogeneous model to heterogeneous system mapping (H2H). While previous mapping algorithms mostly focus on efficient computations, in this work, we argue that it is indispensable to consider computation and communication simultaneously for better system efficiency. We propose a novel H2H mapping algorithm with both computation and communication awareness; by slightly trading computation for communication, the system overall latency and energy consumption can be largely reduced. The superior performance of our work is evaluated based on MAESTRO modeling, demonstrating 15%-74% latency reduction and 23%-64% energy reduction compared with existing computation-prioritized mapping algorithms.

</p>
</details>

<details><summary><b>COVID-Net US-X: Enhanced Deep Neural Network for Detection of COVID-19 Patient Cases from Convex Ultrasound Imaging Through Extended Linear-Convex Ultrasound Augmentation Learning</b>
<a href="https://arxiv.org/abs/2204.13851">arxiv:2204.13851</a>
&#x1F4C8; 2 <br>
<p>E. Zhixuan Zeng, Adrian Florea, Alexander Wong</p></summary>
<p>

**Abstract:** As the global population continues to face significant negative impact by the on-going COVID-19 pandemic, there has been an increasing usage of point-of-care ultrasound (POCUS) imaging as a low-cost and effective imaging modality of choice in the COVID-19 clinical workflow. A major barrier with widespread adoption of POCUS in the COVID-19 clinical workflow is the scarcity of expert clinicians that can interpret POCUS examinations, leading to considerable interest in deep learning-driven clinical decision support systems to tackle this challenge. A major challenge to building deep neural networks for COVID-19 screening using POCUS is the heterogeneity in the types of probes used to capture ultrasound images (e.g., convex vs. linear probes), which can lead to very different visual appearances. In this study, we explore the impact of leveraging extended linear-convex ultrasound augmentation learning on producing enhanced deep neural networks for COVID-19 assessment, where we conduct data augmentation on convex probe data alongside linear probe data that have been transformed to better resemble convex probe data. Experimental results using an efficient deep columnar anti-aliased convolutional neural network designed via a machined-driven design exploration strategy (which we name COVID-Net US-X) show that the proposed extended linear-convex ultrasound augmentation learning significantly increases performance, with a gain of 5.1% in test accuracy and 13.6% in AUC.

</p>
</details>

<details><summary><b>Goldilocks-curriculum Domain Randomization and Fractal Perlin Noise with Application to Sim2Real Pneumonia Lesion Detection</b>
<a href="https://arxiv.org/abs/2204.13849">arxiv:2204.13849</a>
&#x1F4C8; 2 <br>
<p>Takahiro Suzuki, Shouhei Hanaoka, Issei Sato</p></summary>
<p>

**Abstract:** A computer-aided detection (CAD) system based on machine learning is expected to assist radiologists in making a diagnosis. It is desirable to build CAD systems for the various types of diseases accumulating daily in a hospital. An obstacle in developing a CAD system for a disease is that the number of medical images is typically too small to improve the performance of the machine learning model. In this paper, we aim to explore ways to address this problem through a sim2real transfer approach in medical image fields. To build a platform to evaluate the performance of sim2real transfer methods in the field of medical imaging, we construct a benchmark dataset that consists of $101$ chest X-images with difficult-to-identify pneumonia lesions judged by an experienced radiologist and a simulator based on fractal Perlin noise and the X-ray principle for generating pseudo pneumonia lesions. We then develop a novel domain randomization method, called Goldilocks-curriculum domain randomization (GDR) and evaluate our method in this platform.

</p>
</details>

<details><summary><b>RoSA: A Robust Self-Aligned Framework for Node-Node Graph Contrastive Learning</b>
<a href="https://arxiv.org/abs/2204.13846">arxiv:2204.13846</a>
&#x1F4C8; 2 <br>
<p>Yun Zhu, Jianhao Guo, Fei Wu, Siliang Tang</p></summary>
<p>

**Abstract:** Graph contrastive learning has gained significant progress recently. However, existing works have rarely explored non-aligned node-node contrasting. In this paper, we propose a novel graph contrastive learning method named RoSA that focuses on utilizing non-aligned augmented views for node-level representation learning. First, we leverage the earth mover's distance to model the minimum effort to transform the distribution of one view to the other as our contrastive objective, which does not require alignment between views. Then we introduce adversarial training as an auxiliary method to increase sampling diversity and enhance the robustness of our model. Experimental results show that RoSA outperforms a series of graph contrastive learning frameworks on homophilous, non-homophilous and dynamic graphs, which validates the effectiveness of our work. To the best of our awareness, RoSA is the first work focuses on the non-aligned node-node graph contrastive learning problem. Our codes are available at: \href{https://github.com/ZhuYun97/RoSA}{\texttt{https://github.com/ZhuYun97/RoSA}}

</p>
</details>

<details><summary><b>Pragmatic Clinical Trials in the Rubric of Structural Causal Models</b>
<a href="https://arxiv.org/abs/2204.13782">arxiv:2204.13782</a>
&#x1F4C8; 2 <br>
<p>Riddhiman Adib, Sheikh Iqbal Ahamed, Mohammad Adibuzzaman</p></summary>
<p>

**Abstract:** Explanatory studies, such as randomized controlled trials, are targeted to extract the true causal effect of interventions on outcomes and are by design adjusted for covariates through randomization. On the contrary, observational studies are a representation of events that occurred without intervention. Both can be illustrated using the Structural Causal Model (SCM), and do-calculus can be employed to estimate the causal effects. Pragmatic clinical trials (PCT) fall between these two ends of the trial design spectra and are thus hard to define. Due to its pragmatic nature, no standardized representation of PCT through SCM has been yet established. In this paper, we approach this problem by proposing a generalized representation of PCT under the rubric of structural causal models (SCM). We discuss different analysis techniques commonly employed in PCT using the proposed graphical model, such as intention-to-treat, as-treated, and per-protocol analysis. To show the application of our proposed approach, we leverage an experimental dataset from a pragmatic clinical trial. Our proposition of SCM through PCT creates a pathway to leveraging do-calculus and related mathematical operations on clinical datasets.

</p>
</details>

<details><summary><b>One Model to Synthesize Them All: Multi-contrast Multi-scale Transformer for Missing Data Imputation</b>
<a href="https://arxiv.org/abs/2204.13738">arxiv:2204.13738</a>
&#x1F4C8; 2 <br>
<p>Jiang Liu, Srivathsa Pasumarthi, Ben Duffy, Enhao Gong, Greg Zaharchuk, Keshav Datta</p></summary>
<p>

**Abstract:** Multi-contrast magnetic resonance imaging (MRI) is widely used in clinical practice as each contrast provides complementary information. However, the availability of each contrast may vary amongst patients in reality. This poses challenges to both radiologists and automated image analysis algorithms. A general approach for tackling this problem is missing data imputation, which aims to synthesize the missing contrasts from existing ones. While several convolutional neural network (CNN) based algorithms have been proposed, they suffer from the fundamental limitations of CNN models, such as requirement for fixed numbers of input and output channels, inability to capture long-range dependencies, and lack of interpretability. In this paper, we formulate missing data imputation as a sequence-to-sequence learning problem and propose a multi-contrast multi-scale Transformer (MMT), which can take any subset of input contrasts and synthesize those that are missing. MMT consists of a multi-scale Transformer encoder that builds hierarchical representations of inputs combined with a multi-scale Transformer decoder that generates the outputs in a coarse-to-fine fashion. Thanks to the proposed multi-contrast Swin Transformer blocks, it can efficiently capture intra- and inter-contrast dependencies for accurate image synthesis. Moreover, MMT is inherently interpretable. It allows us to understand the importance of each input contrast in different regions by analyzing the in-built attention maps of Transformer blocks in the decoder. Extensive experiments on two large-scale multi-contrast MRI datasets demonstrate that MMT outperforms the state-of-the-art methods quantitatively and qualitatively.

</p>
</details>

<details><summary><b>Coupling Deep Imputation with Multitask Learning for Downstream Tasks on Genomics Data</b>
<a href="https://arxiv.org/abs/2204.13705">arxiv:2204.13705</a>
&#x1F4C8; 2 <br>
<p>Sophie Peacock, Etai Jacob, Nikolay Burlutskiy</p></summary>
<p>

**Abstract:** Genomics data such as RNA gene expression, methylation and micro RNA expression are valuable sources of information for various clinical predictive tasks. For example, predicting survival outcomes, cancer histology type and other patients' related information is possible using not only clinical data but molecular data as well. Moreover, using these data sources together, for example in multitask learning, can boost the performance. However, in practice, there are many missing data points which leads to significantly lower patient numbers when analysing full cases, which in our setting refers to all modalities being present.
  In this paper we investigate how imputing data with missing values using deep learning coupled with multitask learning can help to reach state-of-the-art performance results using combined genomics modalities, RNA, micro RNA and methylation. We propose a generalised deep imputation method to impute values where a patient has all modalities present except one. Interestingly enough, deep imputation alone outperforms multitask learning alone for the classification and regression tasks across most combinations of modalities. In contrast, when using all modalities for survival prediction we observe that multitask learning alone outperforms deep imputation alone with statistical significance (adjusted p-value 0.03). Thus, both approaches are complementary when optimising performance for downstream predictive tasks.

</p>
</details>

<details><summary><b>Linear Temporal Logic Modulo Theories over Finite Traces (Extended Version)</b>
<a href="https://arxiv.org/abs/2204.13693">arxiv:2204.13693</a>
&#x1F4C8; 2 <br>
<p>Luca Geatti, Alessandro Gianola, Nicola Gigante</p></summary>
<p>

**Abstract:** This paper studies Linear Temporal Logic over Finite Traces (LTLf) where proposition letters are replaced with first-order formulas interpreted over arbitrary theories, in the spirit of Satisfiability Modulo Theories. The resulting logic, called LTLf Modulo Theories (LTLfMT), is semi-decidable. Nevertheless, its high expressiveness comes useful in a number of use cases, such as model-checking of data-aware processes and data-aware planning. Despite the general undecidability of these problems, being able to solve satisfiable instances is a compromise worth studying. After motivating and describing such use cases, we provide a sound and complete semi-decision procedure for LTLfMT based on the SMT encoding of a one-pass tree-shaped tableau system. The algorithm is implemented in the BLACK satisfiability checking tool, and an experimental evaluation shows the feasibility of the approach on novel benchmarks.

</p>
</details>

<details><summary><b>Generative Adversarial Networks for Image Super-Resolution: A Survey</b>
<a href="https://arxiv.org/abs/2204.13620">arxiv:2204.13620</a>
&#x1F4C8; 2 <br>
<p>Chunwei Tian, Xuanyu Zhang, Jerry Chun-Wen Lin, Wangmeng Zuo, Yanning Zhang</p></summary>
<p>

**Abstract:** Single image super-resolution (SISR) has played an important role in the field of image processing. Recent generative adversarial networks (GANs) can achieve excellent results on low-resolution images with small samples. However, there are little literatures summarizing different GANs in SISR. In this paper, we conduct a comparative study of GANs from different perspectives. We first take a look at developments of GANs. Second, we present popular architectures for GANs in big and small samples for image applications. Then, we analyze motivations, implementations and differences of GANs based optimization methods and discriminative learning for image super-resolution in terms of supervised, semi-supervised and unsupervised manners. Next, we compare performance of these popular GANs on public datasets via quantitative and qualitative analysis in SISR. Finally, we highlight challenges of GANs and potential research points for SISR.

</p>
</details>

<details><summary><b>An Explainable Regression Framework for Predicting Remaining Useful Life of Machines</b>
<a href="https://arxiv.org/abs/2204.13574">arxiv:2204.13574</a>
&#x1F4C8; 2 <br>
<p>Talhat Khan, Kashif Ahmad, Jebran Khan, Imran Khan, Nasir Ahmad</p></summary>
<p>

**Abstract:** Prediction of a machine's Remaining Useful Life (RUL) is one of the key tasks in predictive maintenance. The task is treated as a regression problem where Machine Learning (ML) algorithms are used to predict the RUL of machine components. These ML algorithms are generally used as a black box with a total focus on the performance without identifying the potential causes behind the algorithms' decisions and their working mechanism. We believe, the performance (in terms of Mean Squared Error (MSE), etc.,) alone is not enough to build the trust of the stakeholders in ML prediction rather more insights on the causes behind the predictions are needed. To this aim, in this paper, we explore the potential of Explainable AI (XAI) techniques by proposing an explainable regression framework for the prediction of machines' RUL. We also evaluate several ML algorithms including classical and Neural Networks (NNs) based solutions for the task. For the explanations, we rely on two model agnostic XAI methods namely Local Interpretable Model-Agnostic Explanations (LIME) and Shapley Additive Explanations (SHAP). We believe, this work will provide a baseline for future research in the domain.

</p>
</details>

<details><summary><b>Mixup-based Deep Metric Learning Approaches for Incomplete Supervision</b>
<a href="https://arxiv.org/abs/2204.13572">arxiv:2204.13572</a>
&#x1F4C8; 2 <br>
<p>Luiz H. Buris, Daniel C. G. Pedronette, Joao P. Papa, Jurandy Almeida, Gustavo Carneiro, Fabio A. Faria</p></summary>
<p>

**Abstract:** Deep learning architectures have achieved promising results in different areas (e.g., medicine, agriculture, and security). However, using those powerful techniques in many real applications becomes challenging due to the large labeled collections required during training. Several works have pursued solutions to overcome it by proposing strategies that can learn more for less, e.g., weakly and semi-supervised learning approaches. As these approaches do not usually address memorization and sensitivity to adversarial examples, this paper presents three deep metric learning approaches combined with Mixup for incomplete-supervision scenarios. We show that some state-of-the-art approaches in metric learning might not work well in such scenarios. Moreover, the proposed approaches outperform most of them in different datasets.

</p>
</details>

<details><summary><b>Attention Based Neural Networks for Wireless Channel Estimation</b>
<a href="https://arxiv.org/abs/2204.13465">arxiv:2204.13465</a>
&#x1F4C8; 2 <br>
<p>Dianxin Luan, John Thompson</p></summary>
<p>

**Abstract:** In this paper, we deploy the self-attention mechanism to achieve improved channel estimation for orthogonal frequency-division multiplexing waveforms in the downlink. Specifically, we propose a new hybrid encoder-decoder structure (called HA02) for the first time which exploits the attention mechanism to focus on the most important input information. In particular, we implement a transformer encoder block as the encoder to achieve the sparsity in the input features and a residual neural network as the decoder respectively, inspired by the success of the attention mechanism. Using 3GPP channel models, our simulations show superior estimation performance compared with other candidate neural network methods for channel estimation.

</p>
</details>

<details><summary><b>Actor-Critic Scheduling for Path-Aware Air-to-Ground Multipath Multimedia Delivery</b>
<a href="https://arxiv.org/abs/2204.13343">arxiv:2204.13343</a>
&#x1F4C8; 2 <br>
<p>Achilles Machumilane, Alberto Gotta, Pietro Cassarà, Claudio Gennaro, Giuseppe Amato</p></summary>
<p>

**Abstract:** Reinforcement Learning (RL) has recently found wide applications in network traffic management and control because some of its variants do not require prior knowledge of network models. In this paper, we present a novel scheduler for real-time multimedia delivery in multipath systems based on an Actor-Critic (AC) RL algorithm. We focus on a challenging scenario of real-time video streaming from an Unmanned Aerial Vehicle (UAV) using multiple wireless paths. The scheduler acting as an RL agent learns in real-time the optimal policy for path selection, path rate allocation and redundancy estimation for flow protection. The scheduler, implemented as a module of the GStreamer framework, can be used in real or simulated settings. The simulation results show that our scheduler can target a very low loss rate at the receiver by dynamically adapting in real-time the scheduling policy to the path conditions without performing training or relying on prior knowledge of network channel models.

</p>
</details>

<details><summary><b>BAGNet: Bidirectional Aware Guidance Network for Malignant Breast lesions Segmentation</b>
<a href="https://arxiv.org/abs/2204.13342">arxiv:2204.13342</a>
&#x1F4C8; 2 <br>
<p>Gongping Chen, Yuming Liu, Yu Dai, Jianxun Zhang, Liang Cui, Xiaotao Yin</p></summary>
<p>

**Abstract:** Breast lesions segmentation is an important step of computer-aided diagnosis system, and it has attracted much attention. However, accurate segmentation of malignant breast lesions is a challenging task due to the effects of heterogeneous structure and similar intensity distributions. In this paper, a novel bidirectional aware guidance network (BAGNet) is proposed to segment the malignant lesion from breast ultrasound images. Specifically, the bidirectional aware guidance network is used to capture the context between global (low-level) and local (high-level) features from the input coarse saliency map. The introduction of the global feature map can reduce the interference of surrounding tissue (background) on the lesion regions. To evaluate the segmentation performance of the network, we compared with several state-of-the-art medical image segmentation methods on the public breast ultrasound dataset using six commonly used evaluation metrics. Extensive experimental results indicate that our method achieves the most competitive segmentation results on malignant breast ultrasound images.

</p>
</details>

<details><summary><b>Causal Discovery on the Effect of Antipsychotic Drugs on Delirium Patients in the ICU using Large EHR Dataset</b>
<a href="https://arxiv.org/abs/2205.01057">arxiv:2205.01057</a>
&#x1F4C8; 1 <br>
<p>Riddhiman Adib, Md Osman Gani, Sheikh Iqbal Ahamed, Mohammad Adibuzzaman</p></summary>
<p>

**Abstract:** Delirium occurs in about 80% cases in the Intensive Care Unit (ICU) and is associated with a longer hospital stay, increased mortality and other related issues. Delirium does not have any biomarker-based diagnosis and is commonly treated with antipsychotic drugs (APD). However, multiple studies have shown controversy over the efficacy or safety of APD in treating delirium. Since randomized controlled trials (RCT) are costly and time-expensive, we aim to approach the research question of the efficacy of APD in the treatment of delirium using retrospective cohort analysis. We plan to use the Causal inference framework to look for the underlying causal structure model, leveraging the availability of large observational data on ICU patients. To explore safety outcomes associated with APD, we aim to build a causal model for delirium in the ICU using large observational data sets connecting various covariates correlated with delirium. We utilized the MIMIC III database, an extensive electronic health records (EHR) dataset with 53,423 distinct hospital admissions. Our null hypothesis is: there is no significant difference in outcomes for delirium patients under different drug-group in the ICU. Through our exploratory, machine learning based and causal analysis, we had findings such as: mean length-of-stay and max length-of-stay is higher for patients in Haloperidol drug group, and haloperidol group has a higher rate of death in a year compared to other two-groups. Our generated causal model explicitly shows the functional relationships between different covariates. For future work, we plan to do time-varying analysis on the dataset.

</p>
</details>

<details><summary><b>Let's Agree to Agree: Targeting Consensus for Incomplete Preferences through Majority Dynamics</b>
<a href="https://arxiv.org/abs/2205.00881">arxiv:2205.00881</a>
&#x1F4C8; 1 <br>
<p>Sirin Botan, Simon Rey, Zoi Terzopoulou</p></summary>
<p>

**Abstract:** We study settings in which agents with incomplete preferences need to make a collective decision. We focus on a process of majority dynamics where issues are addressed one at a time and undecided agents follow the opinion of the majority. We assess the effects of this process on various consensus notions -- such as the Condorcet winner -- and show that in the worst case, myopic adherence to the majority damages existing consensus; yet, simulation experiments indicate that the damage is often mild. We also examine scenarios where the chair of the decision process can control the existence (or the identity) of consensus, by determining the order in which the issues are discussed.

</p>
</details>

<details><summary><b>Graph Learning from Multivariate Dependent Time Series via a Multi-Attribute Formulation</b>
<a href="https://arxiv.org/abs/2205.00007">arxiv:2205.00007</a>
&#x1F4C8; 1 <br>
<p>Jitendra K Tugnait</p></summary>
<p>

**Abstract:** We consider the problem of inferring the conditional independence graph (CIG) of a high-dimensional stationary multivariate Gaussian time series. In a time series graph, each component of the vector series is represented by distinct node, and associations between components are represented by edges between the corresponding nodes. We formulate the problem as one of multi-attribute graph estimation for random vectors where a vector is associated with each node of the graph. At each node, the associated random vector consists of a time series component and its delayed copies. We present an alternating direction method of multipliers (ADMM) solution to minimize a sparse-group lasso penalized negative pseudo log-likelihood objective function to estimate the precision matrix of the random vector associated with the entire multi-attribute graph. The time series CIG is then inferred from the estimated precision matrix. A theoretical analysis is provided. Numerical results illustrate the proposed approach which outperforms existing frequency-domain approaches in correctly detecting the graph edges.

</p>
</details>

<details><summary><b>Randomized Smoothing under Attack: How Good is it in Pratice?</b>
<a href="https://arxiv.org/abs/2204.14187">arxiv:2204.14187</a>
&#x1F4C8; 1 <br>
<p>Thibault Maho, Teddy Furon, Erwan Le Merrer</p></summary>
<p>

**Abstract:** Randomized smoothing is a recent and celebrated solution to certify the robustness of any classifier. While it indeed provides a theoretical robustness against adversarial attacks, the dimensionality of current classifiers necessarily imposes Monte Carlo approaches for its application in practice. This paper questions the effectiveness of randomized smoothing as a defense, against state of the art black-box attacks. This is a novel perspective, as previous research works considered the certification as an unquestionable guarantee. We first formally highlight the mismatch between a theoretical certification and the practice of attacks on classifiers. We then perform attacks on randomized smoothing as a defense. Our main observation is that there is a major mismatch in the settings of the RS for obtaining high certified robustness or when defeating black box attacks while preserving the classifier accuracy.

</p>
</details>

<details><summary><b>Predicting batch queue job wait times for informed scheduling of urgent HPC workloads</b>
<a href="https://arxiv.org/abs/2204.13543">arxiv:2204.13543</a>
&#x1F4C8; 1 <br>
<p>Nick Brown, Gordon Gibb, Evgenij Belikov, Rupert Nash</p></summary>
<p>

**Abstract:** There is increasing interest in the use of HPC machines for urgent workloads to help tackle disasters as they unfold. Whilst batch queue systems are not ideal in supporting such workloads, many disadvantages can be worked around by accurately predicting when a waiting job will start to run. However there are numerous challenges in achieving such a prediction with high accuracy, not least because the queue's state can change rapidly and depend upon many factors. In this work we explore a novel machine learning approach for predicting queue wait times, hypothesising that such a model can capture the complex behaviour resulting from the queue policy and other interactions to generate accurate job start times.
  For ARCHER2 (HPE Cray EX), Cirrus (HPE 8600) and 4-cabinet (HPE Cray EX) we explore how different machine learning approaches and techniques improve the accuracy of our predictions, comparing against the estimation generated by Slurm. We demonstrate that our techniques deliver the most accurate predictions across our machines of interest, with the result of this work being the ability to predict job start times within one minute of the actual start time for around 65\% of jobs on ARCHER2 and 4-cabinet, and 76\% of jobs on Cirrus. When compared against what Slurm can deliver, this represents around 3.8 times better accuracy on ARCHER2 and 18 times better for Cirrus. Furthermore our approach can accurately predicting the start time for three quarters of all job within ten minutes of the actual start time on ARCHER2 and 4-cabinet, and for 90\% of jobs on Cirrus. Whilst the driver of this work has been to better facilitate placement of urgent workloads across HPC machines, the insights gained can be used to provide wider benefits to users and also enrich existing batch queue systems and inform policy too.

</p>
</details>

<details><summary><b>EVI: Multilingual Spoken Dialogue Tasks and Dataset for Knowledge-Based Enrolment, Verification, and Identification</b>
<a href="https://arxiv.org/abs/2204.13496">arxiv:2204.13496</a>
&#x1F4C8; 1 <br>
<p>Georgios P. Spithourakis, Ivan Vulić, Michał Lis, Iñigo Casanueva, Paweł Budzianowski</p></summary>
<p>

**Abstract:** Knowledge-based authentication is crucial for task-oriented spoken dialogue systems that offer personalised and privacy-focused services. Such systems should be able to enrol (E), verify (V), and identify (I) new and recurring users based on their personal information, e.g. postcode, name, and date of birth. In this work, we formalise the three authentication tasks and their evaluation protocols, and we present EVI, a challenging spoken multilingual dataset with 5,506 dialogues in English, Polish, and French. Our proposed models set the first competitive benchmarks, explore the challenges of multilingual natural language processing of spoken dialogue, and set directions for future research.

</p>
</details>

<details><summary><b>GenDR: A Generalized Differentiable Renderer</b>
<a href="https://arxiv.org/abs/2204.13845">arxiv:2204.13845</a>
&#x1F4C8; 0 <br>
<p>Felix Petersen, Bastian Goldluecke, Christian Borgelt, Oliver Deussen</p></summary>
<p>

**Abstract:** In this work, we present and study a generalized family of differentiable renderers. We discuss from scratch which components are necessary for differentiable rendering and formalize the requirements for each component. We instantiate our general differentiable renderer, which generalizes existing differentiable renderers like SoftRas and DIB-R, with an array of different smoothing distributions to cover a large spectrum of reasonable settings. We evaluate an array of differentiable renderer instantiations on the popular ShapeNet 3D reconstruction benchmark and analyze the implications of our results. Surprisingly, the simple uniform distribution yields the best overall results when averaged over 13 classes; in general, however, the optimal choice of distribution heavily depends on the task.

</p>
</details>

<details><summary><b>An Online Ensemble Learning Model for Detecting Attacks in Wireless Sensor Networks</b>
<a href="https://arxiv.org/abs/2204.13814">arxiv:2204.13814</a>
&#x1F4C8; 0 <br>
<p>Hiba Tabbaa, Samir Ifzarne, Imad Hafidi</p></summary>
<p>

**Abstract:** In today's modern world, the usage of technology is unavoidable and the rapid advances in the Internet and communication fields have resulted to expand the Wireless Sensor Network (WSN) technology. A huge number of sensing devices collect and/or generate numerous sensory data throughout time for a wide range of fields and applications. However, WSN has been proven to be vulnerable to security breaches, the harsh and unattended deployment of these networks, combined with their constrained resources and the volume of data generated introduce a major security concern. WSN applications are extremely critical, it is essential to build reliable solutions that involve fast and continuous mechanisms for online data stream analysis enabling the detection of attacks and intrusions. In this context, our aim is to develop an intelligent, efficient, and updatable intrusion detection system by applying an important machine learning concept known as ensemble learning in order to improve detection performance. Although ensemble models have been proven to be useful in offline learning, they have received less attention in streaming applications. In this paper, we examine the application of different homogeneous and heterogeneous online ensembles in sensory data analysis, on a specialized wireless sensor network-detection system (WSN-DS) dataset in order to classify four types of attacks: Blackhole attack, Grayhole, Flooding, and Scheduling among normal network traffic. Among the proposed novel online ensembles, both the heterogeneous ensemble consisting of an Adaptive Random Forest (ARF) combined with the Hoeffding Adaptive Tree (HAT) algorithm and the homogeneous ensemble HAT made up of 10 models achieved higher detection rates of 96.84% and 97.2%, respectively. The above models are efficient and effective in dealing with concept drift, while taking into account the resource constraints of WSNs.

</p>
</details>


{% endraw %}
Prev: [2022.04.27]({{ '/2022/04/27/2022.04.27.html' | relative_url }})  Next: [2022.04.29]({{ '/2022/04/29/2022.04.29.html' | relative_url }})