Prev: [2022.04.27]({{ '/2022/04/27/2022.04.27.html' | relative_url }})  Next: [2022.04.29]({{ '/2022/04/29/2022.04.29.html' | relative_url }})
{% raw %}
## Summary for 2022-04-28, created on 2022-05-02


<details><summary><b>Predicting single-cell perturbation responses for unseen drugs</b>
<a href="https://arxiv.org/abs/2204.13545">arxiv:2204.13545</a>
&#x1F4C8; 47 <br>
<p>Leon Hetzel, Simon Böhm, Niki Kilbertus, Stephan Günnemann, Mohammad Lotfollahi, Fabian Theis</p></summary>
<p>

**Abstract:** Single-cell transcriptomics enabled the study of cellular heterogeneity in response to perturbations at the resolution of individual cells. However, scaling high-throughput screens (HTSs) to measure cellular responses for many drugs remains a challenge due to technical limitations and, more importantly, the cost of such multiplexed experiments. Thus, transferring information from routinely performed bulk RNA-seq HTS is required to enrich single-cell data meaningfully. We introduce a new encoder-decoder architecture to study the perturbational effects of unseen drugs. We combine the model with a transfer learning scheme and demonstrate how training on existing bulk RNA-seq HTS datasets can improve generalisation performance. Better generalisation reduces the need for extensive and costly screens at single-cell resolution. We envision that our proposed method will facilitate more efficient experiment designs through its ability to generate in-silico hypotheses, ultimately accelerating targeted drug discovery.

</p>
</details>

<details><summary><b>Music Enhancement via Image Translation and Vocoding</b>
<a href="https://arxiv.org/abs/2204.13289">arxiv:2204.13289</a>
&#x1F4C8; 27 <br>
<p>Nikhil Kandpal, Oriol Nieto, Zeyu Jin</p></summary>
<p>

**Abstract:** Consumer-grade music recordings such as those captured by mobile devices typically contain distortions in the form of background noise, reverb, and microphone-induced EQ. This paper presents a deep learning approach to enhance low-quality music recordings by combining (i) an image-to-image translation model for manipulating audio in its mel-spectrogram representation and (ii) a music vocoding model for mapping synthetically generated mel-spectrograms to perceptually realistic waveforms. We find that this approach to music enhancement outperforms baselines which use classical methods for mel-spectrogram inversion and an end-to-end approach directly mapping noisy waveforms to clean waveforms. Additionally, in evaluating the proposed method with a listening test, we analyze the reliability of common audio enhancement evaluation metrics when used in the music domain.

</p>
</details>

<details><summary><b>Unaligned Supervision For Automatic Music Transcription in The Wild</b>
<a href="https://arxiv.org/abs/2204.13668">arxiv:2204.13668</a>
&#x1F4C8; 24 <br>
<p>Ben Maman, Amit H. Bermano</p></summary>
<p>

**Abstract:** Multi-instrument Automatic Music Transcription (AMT), or the decoding of a musical recording into semantic musical content, is one of the holy grails of Music Information Retrieval. Current AMT approaches are restricted to piano and (some) guitar recordings, due to difficult data collection. In order to overcome data collection barriers, previous AMT approaches attempt to employ musical scores in the form of a digitized version of the same song or piece. The scores are typically aligned using audio features and strenuous human intervention to generate training labels. We introduce NoteEM, a method for simultaneously training a transcriber and aligning the scores to their corresponding performances, in a fully-automated process. Using this unaligned supervision scheme, complemented by pseudo-labels and pitch-shift augmentation, our method enables training on in-the-wild recordings with unprecedented accuracy and instrumental variety. Using only synthetic data and unaligned supervision, we report SOTA note-level accuracy of the MAPS dataset, and large favorable margins on cross-dataset evaluations. We also demonstrate robustness and ease of use; we report comparable results when training on a small, easily obtainable, self-collected dataset, and we propose alternative labeling to the MusicNet dataset, which we show to be more accurate. Our project page is available at https://benadar293.github.io

</p>
</details>

<details><summary><b>Unlocking High-Accuracy Differentially Private Image Classification through Scale</b>
<a href="https://arxiv.org/abs/2204.13650">arxiv:2204.13650</a>
&#x1F4C8; 20 <br>
<p>Soham De, Leonard Berrada, Jamie Hayes, Samuel L. Smith, Borja Balle</p></summary>
<p>

**Abstract:** Differential Privacy (DP) provides a formal privacy guarantee preventing adversaries with access to a machine learning model from extracting information about individual training points. Differentially Private Stochastic Gradient Descent (DP-SGD), the most popular DP training method, realizes this protection by injecting noise during training. However previous works have found that DP-SGD often leads to a significant degradation in performance on standard image classification benchmarks. Furthermore, some authors have postulated that DP-SGD inherently performs poorly on large models, since the norm of the noise required to preserve privacy is proportional to the model dimension. In contrast, we demonstrate that DP-SGD on over-parameterized models can perform significantly better than previously thought. Combining careful hyper-parameter tuning with simple techniques to ensure signal propagation and improve the convergence rate, we obtain a new SOTA on CIFAR-10 of 81.4% under (8, 10^{-5})-DP using a 40-layer Wide-ResNet, improving over the previous SOTA of 71.7%. When fine-tuning a pre-trained 200-layer Normalizer-Free ResNet, we achieve a remarkable 77.1% top-1 accuracy on ImageNet under (1, 8*10^{-7})-DP, and achieve 81.1% under (8, 8*10^{-7})-DP. This markedly exceeds the previous SOTA of 47.9% under a larger privacy budget of (10, 10^{-6})-DP. We believe our results are a significant step towards closing the accuracy gap between private and non-private image classification.

</p>
</details>

<details><summary><b>Robots: the Century Past and the Century Ahead</b>
<a href="https://arxiv.org/abs/2204.13331">arxiv:2204.13331</a>
&#x1F4C8; 10 <br>
<p>Federico Pigozzi</p></summary>
<p>

**Abstract:** Let us reflect on the state of robotics. This year marks the $101$-st anniversary of R.U.R., a play by the writer Karel Čapek, often credited with introducing the word "robot". The word used to refer to feudal forced labourers in Slavic languages. Indeed, it points to one key characteristic of robotic systems: they are mere slaves, have no rights, and execute our wills instruction by instruction, without asking anything in return. The relationship with us humans is commensalism; in biology, commensalism subsists between two symbiotic species when one species benefits from it (robots boost productivity for humans), while the other species neither benefits nor is harmed (can you really argue that robots benefit from simply functioning?).
  We then distinguish robots from "living machines", that is, machines infused with life. If living machines should ever become a reality, we would need to shift our relationship with them from commensalism to mutualism. The distinction is not subtle: we experience it every day with domesticated animals, that exchange serfdom for forage and protection. This is because life has evolved to resist any attempt at enslaving it; it is stubborn.
  In the path towards living machines, let us ask: what has been achieved by robotics in the last $100$ years? What is left to accomplish in the next $100$ years? For us, the answers boil down to three words: juice, need (or death), and embodiment, as we shall see in the following.

</p>
</details>

<details><summary><b>Foundations for learning from noisy quantum experiments</b>
<a href="https://arxiv.org/abs/2204.13691">arxiv:2204.13691</a>
&#x1F4C8; 9 <br>
<p>Hsin-Yuan Huang, Steven T. Flammia, John Preskill</p></summary>
<p>

**Abstract:** Understanding what can be learned from experiments is central to scientific progress. In this work, we use a learning-theoretic perspective to study the task of learning physical operations in a quantum machine when all operations (state preparation, dynamics, and measurement) are a priori unknown. We prove that, without any prior knowledge, if one can explore the full quantum state space by composing the operations, then every operation can be learned. When one cannot explore the full state space but all operations are approximately known and noise in Clifford gates is gate-independent, we find an efficient algorithm for learning all operations up to a single unlearnable parameter characterizing the fidelity of the initial state. For learning a noise channel on Clifford gates to a fixed accuracy, our algorithm uses quadratically fewer experiments than previously known protocols. Under more general conditions, the true description of the noise can be unlearnable; for example, we prove that no benchmarking protocol can learn gate-dependent Pauli noise on Clifford+T gates even under perfect state preparation and measurement. Despite not being able to learn the noise, we show that a noisy quantum computer that performs entangled measurements on multiple copies of an unknown state can yield a large advantage in learning properties of the state compared to a noiseless device that measures individual copies and then processes the measurement data using a classical computer. Concretely, we prove that noisy quantum computers with two-qubit gate error rate $ε$ can achieve a learning task using $N$ copies of the state, while $N^{Ω(1/ε)}$ copies are required classically.

</p>
</details>

<details><summary><b>Russian Texts Detoxification with Levenshtein Editing</b>
<a href="https://arxiv.org/abs/2204.13638">arxiv:2204.13638</a>
&#x1F4C8; 8 <br>
<p>Ilya Gusev</p></summary>
<p>

**Abstract:** Text detoxification is a style transfer task of creating neutral versions of toxic texts. In this paper, we use the concept of text editing to build a two-step tagging-based detoxification model using a parallel corpus of Russian texts. With this model, we achieved the best style transfer accuracy among all models in the RUSSE Detox shared task, surpassing larger sequence-to-sequence models.

</p>
</details>

<details><summary><b>Neural Label Search for Zero-Shot Multi-Lingual Extractive Summarization</b>
<a href="https://arxiv.org/abs/2204.13512">arxiv:2204.13512</a>
&#x1F4C8; 8 <br>
<p>Ruipeng Jia, Xingxing Zhang, Yanan Cao, Shi Wang, Zheng Lin, Furu Wei</p></summary>
<p>

**Abstract:** In zero-shot multilingual extractive text summarization, a model is typically trained on English summarization dataset and then applied on summarization datasets of other languages. Given English gold summaries and documents, sentence-level labels for extractive summarization are usually generated using heuristics. However, these monolingual labels created on English datasets may not be optimal on datasets of other languages, for that there is the syntactic or semantic discrepancy between different languages. In this way, it is possible to translate the English dataset to other languages and obtain different sets of labels again using heuristics. To fully leverage the information of these different sets of labels, we propose NLSSum (Neural Label Search for Summarization), which jointly learns hierarchical weights for these different sets of labels together with our summarization model. We conduct multilingual zero-shot summarization experiments on MLSUM and WikiLingua datasets, and we achieve state-of-the-art results using both human and automatic evaluations across these two datasets.

</p>
</details>

<details><summary><b>Curriculum Learning for Dense Retrieval Distillation</b>
<a href="https://arxiv.org/abs/2204.13679">arxiv:2204.13679</a>
&#x1F4C8; 7 <br>
<p>Hansi Zeng, Hamed Zamani, Vishwa Vinay</p></summary>
<p>

**Abstract:** Recent work has shown that more effective dense retrieval models can be obtained by distilling ranking knowledge from an existing base re-ranking model. In this paper, we propose a generic curriculum learning based optimization framework called CL-DRD that controls the difficulty level of training data produced by the re-ranking (teacher) model. CL-DRD iteratively optimizes the dense retrieval (student) model by increasing the difficulty of the knowledge distillation data made available to it. In more detail, we initially provide the student model coarse-grained preference pairs between documents in the teacher's ranking and progressively move towards finer-grained pairwise document ordering requirements. In our experiments, we apply a simple implementation of the CL-DRD framework to enhance two state-of-the-art dense retrieval models. Experiments on three public passage retrieval datasets demonstrate the effectiveness of our proposed framework.

</p>
</details>

<details><summary><b>AlphaZero-Inspired General Board Game Learning and Playing</b>
<a href="https://arxiv.org/abs/2204.13307">arxiv:2204.13307</a>
&#x1F4C8; 7 <br>
<p>Johannes Scheiermann, Wolfgang Konen</p></summary>
<p>

**Abstract:** Recently, the seminal algorithms AlphaGo and AlphaZero have started a new era in game learning and deep reinforcement learning. While the achievements of AlphaGo and AlphaZero - playing Go and other complex games at super human level - are truly impressive, these architectures have the drawback that they are very complex and require high computational resources. Many researchers are looking for methods that are similar to AlphaZero, but have lower computational demands and are thus more easily reproducible. In this paper, we pick an important element of AlphaZero - the Monte Carlo Tree Search (MCTS) planning stage - and combine it with reinforcement learning (RL) agents. We wrap MCTS for the first time around RL n-tuple networks to create versatile agents that keep at the same time the computational demands low. We apply this new architecture to several complex games (Othello, ConnectFour, Rubik's Cube) and show the advantages achieved with this AlphaZero-inspired MCTS wrapper. In particular, we present results that this AlphaZero-inspired agent is the first one trained on standard hardware (no GPU or TPU) to beat the very strong Othello program Edax up to and including level 7 (where most other algorithms could only defeat Edax up to level 2).

</p>
</details>

<details><summary><b>Deep Orientation-Aware Functional Maps: Tackling Symmetry Issues in Shape Matching</b>
<a href="https://arxiv.org/abs/2204.13453">arxiv:2204.13453</a>
&#x1F4C8; 6 <br>
<p>Nicolas Donati, Etienne Corman, Maks Ovsjanikov</p></summary>
<p>

**Abstract:** State-of-the-art fully intrinsic networks for non-rigid shape matching often struggle to disambiguate the symmetries of the shapes leading to unstable correspondence predictions. Meanwhile, recent advances in the functional map framework allow to enforce orientation preservation using a functional representation for tangent vector field transfer, through so-called complex functional maps. Using this representation, we propose a new deep learning approach to learn orientation-aware features in a fully unsupervised setting. Our architecture is built on top of DiffusionNet, making it robust to discretization changes. Additionally, we introduce a vector field-based loss, which promotes orientation preservation without using (often unstable) extrinsic descriptors.

</p>
</details>

<details><summary><b>WeaNF: Weak Supervision with Normalizing Flows</b>
<a href="https://arxiv.org/abs/2204.13409">arxiv:2204.13409</a>
&#x1F4C8; 6 <br>
<p>Andreas Stephan, Benjamin Roth</p></summary>
<p>

**Abstract:** A popular approach to decrease the need for costly manual annotation of large data sets is weak supervision, which introduces problems of noisy labels, coverage and bias. Methods for overcoming these problems have either relied on discriminative models, trained with cost functions specific to weak supervision, and more recently, generative models, trying to model the output of the automatic annotation process. In this work, we explore a novel direction of generative modeling for weak supervision: Instead of modeling the output of the annotation process (the labeling function matches), we generatively model the input-side data distributions (the feature space) covered by labeling functions. Specifically, we estimate a density for each weak labeling source, or labeling function, by using normalizing flows. An integral part of our method is the flow-based modeling of multiple simultaneously matching labeling functions, and therefore phenomena such as labeling function overlap and correlations are captured. We analyze the effectiveness and modeling capabilities on various commonly used weak supervision data sets, and show that weakly supervised normalizing flows compare favorably to standard weak supervision baselines.

</p>
</details>

<details><summary><b>KING: Generating Safety-Critical Driving Scenarios for Robust Imitation via Kinematics Gradients</b>
<a href="https://arxiv.org/abs/2204.13683">arxiv:2204.13683</a>
&#x1F4C8; 5 <br>
<p>Niklas Hanselmann, Katrin Renz, Kashyap Chitta, Apratim Bhattacharyya, Andreas Geiger</p></summary>
<p>

**Abstract:** Simulators offer the possibility of safe, low-cost development of self-driving systems. However, current driving simulators exhibit naïve behavior models for background traffic. Hand-tuned scenarios are typically added during simulation to induce safety-critical situations. An alternative approach is to adversarially perturb the background traffic trajectories. In this paper, we study this approach to safety-critical driving scenario generation using the CARLA simulator. We use a kinematic bicycle model as a proxy to the simulator's true dynamics and observe that gradients through this proxy model are sufficient for optimizing the background traffic trajectories. Based on this finding, we propose KING, which generates safety-critical driving scenarios with a 20% higher success rate than black-box optimization. By solving the scenarios generated by KING using a privileged rule-based expert algorithm, we obtain training data for an imitation learning policy. After fine-tuning on this new data, we show that the policy becomes better at avoiding collisions. Importantly, our generated data leads to reduced collisions on both held-out scenarios generated via KING as well as traditional hand-crafted scenarios, demonstrating improved robustness.

</p>
</details>

<details><summary><b>Unified Simulation, Perception, and Generation of Human Behavior</b>
<a href="https://arxiv.org/abs/2204.13678">arxiv:2204.13678</a>
&#x1F4C8; 5 <br>
<p>Ye Yuan</p></summary>
<p>

**Abstract:** Understanding and modeling human behavior is fundamental to almost any computer vision and robotics applications that involve humans. In this thesis, we take a holistic approach to human behavior modeling and tackle its three essential aspects -- simulation, perception, and generation. Throughout the thesis, we show how the three aspects are deeply connected and how utilizing and improving one aspect can greatly benefit the other aspects. We also discuss the lessons learned and our vision for what is next for human behavior modeling.

</p>
</details>

<details><summary><b>Unsupervised Spatial-spectral Hyperspectral Image Reconstruction and Clustering with Diffusion Geometry</b>
<a href="https://arxiv.org/abs/2204.13497">arxiv:2204.13497</a>
&#x1F4C8; 5 <br>
<p>Kangning Cui, Ruoning Li, Sam L. Polk, James M. Murphy, Robert J. Plemmons, Raymond H. Chan</p></summary>
<p>

**Abstract:** Hyperspectral images, which store a hundred or more spectral bands of reflectance, have become an important data source in natural and social sciences. Hyperspectral images are often generated in large quantities at a relatively coarse spatial resolution. As such, unsupervised machine learning algorithms incorporating known structure in hyperspectral imagery are needed to analyze these images automatically. This work introduces the Spatial-Spectral Image Reconstruction and Clustering with Diffusion Geometry (DSIRC) algorithm for partitioning highly mixed hyperspectral images. DSIRC reduces measurement noise through a shape-adaptive reconstruction procedure. In particular, for each pixel, DSIRC locates spectrally correlated pixels within a data-adaptive spatial neighborhood and reconstructs that pixel's spectral signature using those of its neighbors. DSIRC then locates high-density, high-purity pixels far in diffusion distance (a data-dependent distance metric) from other high-density, high-purity pixels and treats these as cluster exemplars, giving each a unique label. Non-modal pixels are assigned the label of their diffusion distance-nearest neighbor of higher density and purity that is already labeled. Strong numerical results indicate that incorporating spatial information through image reconstruction substantially improves the performance of pixel-wise clustering.

</p>
</details>

<details><summary><b>List-Mode PET Image Reconstruction Using Deep Image Prior</b>
<a href="https://arxiv.org/abs/2204.13404">arxiv:2204.13404</a>
&#x1F4C8; 5 <br>
<p>Kibo Ote, Fumio Hashimoto, Yuya Onishi, Takashi Isobe, Yasuomi Ouchi</p></summary>
<p>

**Abstract:** List-mode positron emission tomography (PET) image reconstruction is an important tool for PET scanners with many lines-of-response (LORs) and additional information such as time-of-flight and depth-of-interaction. Deep learning is one possible solution to enhance the quality of PET image reconstruction. However, the application of deep learning techniques to list-mode PET image reconstruction have not been progressed because list data is a sequence of bit codes and unsuitable for processing by convolutional neural networks (CNN). In this study, we propose a novel list-mode PET image reconstruction method using an unsupervised CNN called deep image prior (DIP) and a framework of alternating direction method of multipliers. The proposed list-mode DIP reconstruction (LM-DIPRecon) method alternatively iterates regularized list-mode dynamic row action maximum likelihood algorithm (LM-DRAMA) and magnetic resonance imaging conditioned DIP (MR-DIP). We evaluated LM-DIPRecon using both simulation and clinical data, and it achieved sharper images and better tradeoff curves between contrast and noise than the LM-DRAMA and MR-DIP. These results indicated that the LM-DIPRecon is useful for quantitative PET imaging with limited events. In addition, as list data has finer temporal information than dynamic sinograms, list-mode deep image prior reconstruction is expected to be useful for 4D PET imaging and motion correction.

</p>
</details>

<details><summary><b>Poly-CAM: High resolution class activation map for convolutional neural networks</b>
<a href="https://arxiv.org/abs/2204.13359">arxiv:2204.13359</a>
&#x1F4C8; 5 <br>
<p>Alexandre Englebert, Olivier Cornu, Christophe De Vleeschouwer</p></summary>
<p>

**Abstract:** The need for Explainable AI is increasing with the development of deep learning. The saliency maps derived from convolutional neural networks generally fail in localizing with accuracy the image features justifying the network prediction. This is because those maps are either low-resolution as for CAM [Zhou et al., 2016], or smooth as for perturbation-based methods [Zeiler and Fergus, 2014], or do correspond to a large number of widespread peaky spots as for gradient-based approaches [Sundararajan et al., 2017, Smilkov et al., 2017]. In contrast, our work proposes to combine the information from earlier network layers with the one from later layers to produce a high resolution Class Activation Map that is competitive with the previous art in term of insertion-deletion faithfulness metrics, while outperforming it in term of precision of class-specific features localization.

</p>
</details>

<details><summary><b>Continual Learning with Bayesian Model based on a Fixed Pre-trained Feature Extractor</b>
<a href="https://arxiv.org/abs/2204.13349">arxiv:2204.13349</a>
&#x1F4C8; 5 <br>
<p>Yang Yang, Zhiying Cui, Junjie Xu, Changhong Zhong, Wei-Shi Zheng, Ruixuan Wang</p></summary>
<p>

**Abstract:** Deep learning has shown its human-level performance in various applications. However, current deep learning models are characterised by catastrophic forgetting of old knowledge when learning new classes. This poses a challenge particularly in intelligent diagnosis systems where initially only training data of a limited number of diseases are available. In this case, updating the intelligent system with data of new diseases would inevitably downgrade its performance on previously learned diseases. Inspired by the process of learning new knowledge in human brains, we propose a Bayesian generative model for continual learning built on a fixed pre-trained feature extractor. In this model, knowledge of each old class can be compactly represented by a collection of statistical distributions, e.g. with Gaussian mixture models, and naturally kept from forgetting in continual learning over time. Unlike existing class-incremental learning methods, the proposed approach is not sensitive to the continual learning process and can be additionally well applied to the data-incremental learning scenario. Experiments on multiple medical and natural image classification tasks showed that the proposed approach outperforms state-of-the-art approaches which even keep some images of old classes during continual learning of new classes.

</p>
</details>

<details><summary><b>Generative Adversarial Networks for Image Super-Resolution: A Survey</b>
<a href="https://arxiv.org/abs/2204.13620">arxiv:2204.13620</a>
&#x1F4C8; 4 <br>
<p>Chunwei Tian, Xuanyu Zhang, Jerry Chun-Wen Lin, Wangmeng Zuo, Yanning Zhang</p></summary>
<p>

**Abstract:** Single image super-resolution (SISR) has played an important role in the field of image processing. Recent generative adversarial networks (GANs) can achieve excellent results on low-resolution images with small samples. However, there are little literatures summarizing different GANs in SISR. In this paper, we conduct a comparative study of GANs from different perspectives. We first take a look at developments of GANs. Second, we present popular architectures for GANs in big and small samples for image applications. Then, we analyze motivations, implementations and differences of GANs based optimization methods and discriminative learning for image super-resolution in terms of supervised, semi-supervised and unsupervised manners. Next, we compare performance of these popular GANs on public datasets via quantitative and qualitative analysis in SISR. Finally, we highlight challenges of GANs and potential research points for SISR.

</p>
</details>

<details><summary><b>Computer Vision for Road Imaging and Pothole Detection: A State-of-the-Art Review of Systems and Algorithms</b>
<a href="https://arxiv.org/abs/2204.13590">arxiv:2204.13590</a>
&#x1F4C8; 4 <br>
<p>Nachuan Ma, Jiahe Fan, Wenshuo Wang, Jin Wu, Yu Jiang, Lihua Xie, Rui Fan</p></summary>
<p>

**Abstract:** Computer vision algorithms have been prevalently utilized for 3-D road imaging and pothole detection for over two decades. Nonetheless, there is a lack of systematic survey articles on state-of-the-art (SoTA) computer vision techniques, especially deep learning models, developed to tackle these problems. This article first introduces the sensing systems employed for 2-D and 3-D road data acquisition, including camera(s), laser scanners, and Microsoft Kinect. Afterward, it thoroughly and comprehensively reviews the SoTA computer vision algorithms, including (1) classical 2-D image processing, (2) 3-D point cloud modeling and segmentation, and (3) machine/deep learning, developed for road pothole detection. This article also discusses the existing challenges and future development trends of computer vision-based road pothole detection approaches: classical 2-D image processing-based and 3-D point cloud modeling and segmentation-based approaches have already become history; and Convolutional neural networks (CNNs) have demonstrated compelling road pothole detection results and are promising to break the bottleneck with the future advances in self/un-supervised learning for multi-modal semantic segmentation. We believe that this survey can serve as practical guidance for developing the next-generation road condition assessment systems.

</p>
</details>

<details><summary><b>Mixup-based Deep Metric Learning Approaches for Incomplete Supervision</b>
<a href="https://arxiv.org/abs/2204.13572">arxiv:2204.13572</a>
&#x1F4C8; 4 <br>
<p>Luiz H. Buris, Daniel C. G. Pedronette, Joao P. Papa, Jurandy Almeida, Gustavo Carneiro, Fabio A. Faria</p></summary>
<p>

**Abstract:** Deep learning architectures have achieved promising results in different areas (e.g., medicine, agriculture, and security). However, using those powerful techniques in many real applications becomes challenging due to the large labeled collections required during training. Several works have pursued solutions to overcome it by proposing strategies that can learn more for less, e.g., weakly and semi-supervised learning approaches. As these approaches do not usually address memorization and sensitivity to adversarial examples, this paper presents three deep metric learning approaches combined with Mixup for incomplete-supervision scenarios. We show that some state-of-the-art approaches in metric learning might not work well in such scenarios. Moreover, the proposed approaches outperform most of them in different datasets.

</p>
</details>

<details><summary><b>Inverse-Designed Meta-Optics with Spectral-Spatial Engineered Response to Mimic Color Perception</b>
<a href="https://arxiv.org/abs/2204.13520">arxiv:2204.13520</a>
&#x1F4C8; 4 <br>
<p>Chris Munley, Wenchao Ma, Johannes E. Fröch, Quentin A. A. Tanguy, Elyas Bayati, Karl F. Böhringer, Zin Lin, Raphaël Pestourie, Steven G. Johnson, Arka Majumdar</p></summary>
<p>

**Abstract:** Meta-optics have rapidly become a major research field within the optics and photonics community, strongly driven by the seemingly limitless opportunities made possible by controlling optical wavefronts through interaction with arrays of sub-wavelength scatterers. As more and more modalities are explored, the design strategies to achieve desired functionalities become increasingly demanding, necessitating more advanced design techniques. Herein, the inverse-design approach is utilized to create a set of single-layer meta-optics that simultaneously focus light and shape the spectra of focused light without using any filters. Thus, both spatial and spectral properties of the meta-optics are optimized, resulting in spectra that mimic the color matching functions of the CIE 1931 XYZ color space, which links the distributions of wavelengths in light and the color perception of a human eye. Experimental demonstrations of these meta-optics show qualitative agreement with the theoretical predictions and help elucidate the focusing mechanism of these devices.

</p>
</details>

<details><summary><b>EVI: Multilingual Spoken Dialogue Tasks and Dataset for Knowledge-Based Enrolment, Verification, and Identification</b>
<a href="https://arxiv.org/abs/2204.13496">arxiv:2204.13496</a>
&#x1F4C8; 4 <br>
<p>Georgios P. Spithourakis, Ivan Vulić, Michał Lis, Iñigo Casanueva, Paweł Budzianowski</p></summary>
<p>

**Abstract:** Knowledge-based authentication is crucial for task-oriented spoken dialogue systems that offer personalised and privacy-focused services. Such systems should be able to enrol (E), verify (V), and identify (I) new and recurring users based on their personal information, e.g. postcode, name, and date of birth. In this work, we formalise the three authentication tasks and their evaluation protocols, and we present EVI, a challenging spoken multilingual dataset with 5,506 dialogues in English, Polish, and French. Our proposed models set the first competitive benchmarks, explore the challenges of multilingual natural language processing of spoken dialogue, and set directions for future research.

</p>
</details>

<details><summary><b>TJ4DRadSet: A 4D Radar Dataset for Autonomous Driving</b>
<a href="https://arxiv.org/abs/2204.13483">arxiv:2204.13483</a>
&#x1F4C8; 4 <br>
<p>Lianqing Zheng, Zhixiong Ma, Xichan Zhu, Bin Tan, Sen Li, Kai Long, Weiqi Sun, Sihan Chen, Lu Zhang, Mengyue Wan, Libo Huang, Jie Bai</p></summary>
<p>

**Abstract:** The new generation of 4D high-resolution imaging radar provides not only a huge amount of point cloud but also additional elevation measurement, which has a great potential of 3D sensing in autonomous driving. In this paper, we introduce an autonomous driving dataset named TJ4DRadSet, including multi-modal sensors that are 4D radar, lidar, camera and GNSS, with about 40K frames in total. 7757 frames within 44 consecutive sequences in various driving scenarios are well annotated with 3D bounding boxes and track id. We provide a 4D radar-based 3D object detection baseline for our dataset to demonstrate the effectiveness of deep learning methods for 4D radar point clouds.

</p>
</details>

<details><summary><b>Regotron: Regularizing the Tacotron2 architecture via monotonic alignment loss</b>
<a href="https://arxiv.org/abs/2204.13437">arxiv:2204.13437</a>
&#x1F4C8; 4 <br>
<p>Efthymios Georgiou, Kosmas Kritsis, Georgios Paraskevopoulos, Athanasios Katsamanis, Vassilis Katsouros, Alexandros Potamianos</p></summary>
<p>

**Abstract:** Recent deep learning Text-to-Speech (TTS) systems have achieved impressive performance by generating speech close to human parity. However, they suffer from training stability issues as well as incorrect alignment of the intermediate acoustic representation with the input text sequence. In this work, we introduce Regotron, a regularized version of Tacotron2 which aims to alleviate the training issues and at the same time produce monotonic alignments. Our method augments the vanilla Tacotron2 objective function with an additional term, which penalizes non-monotonic alignments in the location-sensitive attention mechanism. By properly adjusting this regularization term we show that the loss curves become smoother, and at the same time Regotron consistently produces monotonic alignments in unseen examples even at an early stage (13\% of the total number of epochs) of its training process, whereas the fully converged Tacotron2 fails to do so. Moreover, our proposed regularization method has no additional computational overhead, while reducing common TTS mistakes and achieving slighlty improved speech naturalness according to subjective mean opinion scores (MOS) collected from 50 evaluators.

</p>
</details>

<details><summary><b>Semantic Communication: An Information Bottleneck View</b>
<a href="https://arxiv.org/abs/2204.13366">arxiv:2204.13366</a>
&#x1F4C8; 4 <br>
<p>Edgar Beck, Carsten Bockelmann, Armin Dekorsy</p></summary>
<p>

**Abstract:** Motivated by recent success of machine learning tools at the PHY layer and driven by high bandwidth demands of the next wireless communication standard 6G, the old idea of semantic communication by Weaver from 1949 has received considerable attention. It breaks with the classic design paradigm according to Shannon by aiming to transmit the meaning of a message rather than its exact copy and thus potentially allows for savings in bandwidth.
  In this work, inspired by Weaver, we propose an information-theoretic framework where the semantic context is explicitly introduced into probabilistic models. In particular, for bandwidth efficient transmission, we define semantic communication system design as an Information Bottleneck optimization problem and consider important implementation aspects. Further, we uncover the restrictions of the classic 5G communication system design w.r.t. semantic context. Notably, based on the example of distributed image classification, we reveal the huge potential of a semantic communication system design. Numerical results show a tremendous saving in bandwidth of 20 dB with our proposed approach ISCNet compared to a classic PHY layer design.

</p>
</details>

<details><summary><b>Model Selection, Adaptation, and Combination for Deep Transfer Learning through Neural Networks in Renewable Energies</b>
<a href="https://arxiv.org/abs/2204.13293">arxiv:2204.13293</a>
&#x1F4C8; 4 <br>
<p>Jens Schreiber, Bernhard Sick</p></summary>
<p>

**Abstract:** There is recent interest in using model hubs, a collection of pre-trained models, in computer vision tasks. To utilize the model hub, we first select a source model and then adapt the model for the target to compensate for differences. While there is yet limited research on a model selection and adaption for computer vision tasks, this holds even more for the field of renewable power. At the same time, it is a crucial challenge to provide forecasts for the increasing demand for power forecasts based on weather features from a numerical weather prediction. We close these gaps by conducting the first thorough experiment for model selection and adaptation for transfer learning in renewable power forecast, adopting recent results from the field of computer vision on six datasets. We adopt models based on data from different seasons and limit the amount of training data. As an extension of the current state of the art, we utilize a Bayesian linear regression for forecasting the response based on features extracted from a neural network. This approach outperforms the baseline with only seven days of training data. We further show how combining multiple models through ensembles can significantly improve the model selection and adaptation approach. In fact, with more than 30 days of training data, both proposed model combination techniques achieve similar results to those models trained with a full year of training data.

</p>
</details>

<details><summary><b>On the Normalizing Constant of the Continuous Categorical Distribution</b>
<a href="https://arxiv.org/abs/2204.13290">arxiv:2204.13290</a>
&#x1F4C8; 4 <br>
<p>Elliott Gordon-Rodriguez, Gabriel Loaiza-Ganem, Andres Potapczynski, John P. Cunningham</p></summary>
<p>

**Abstract:** Probability distributions supported on the simplex enjoy a wide range of applications across statistics and machine learning. Recently, a novel family of such distributions has been discovered: the continuous categorical. This family enjoys remarkable mathematical simplicity; its density function resembles that of the Dirichlet distribution, but with a normalizing constant that can be written in closed form using elementary functions only. In spite of this mathematical simplicity, our understanding of the normalizing constant remains far from complete. In this work, we characterize the numerical behavior of the normalizing constant and we present theoretical and methodological advances that can, in turn, help to enable broader applications of the continuous categorical distribution. Our code is available at https://github.com/cunningham-lab/cb_and_cc/.

</p>
</details>

<details><summary><b>Toward Compositional Generalization in Object-Oriented World Modeling</b>
<a href="https://arxiv.org/abs/2204.13661">arxiv:2204.13661</a>
&#x1F4C8; 3 <br>
<p>Linfeng Zhao, Lingzhi Kong, Robin Walters, Lawson L. S. Wong</p></summary>
<p>

**Abstract:** Compositional generalization is a critical ability in learning and decision-making. We focus on the setting of reinforcement learning in object-oriented environments to study compositional generalization in world modeling. We (1) formalize the compositional generalization problem with an algebraic approach and (2) study how a world model can achieve that. We introduce a conceptual environment, Object Library, and two instances, and deploy a principled pipeline to measure the generalization ability. Motivated by the formulation, we analyze several methods with exact} or no compositional generalization ability using our framework, and design a differentiable approach, Homomorphic Object-oriented World Model (HOWM), that achieves approximate but more efficient compositional generalization.

</p>
</details>

<details><summary><b>Standardized Evaluation of Machine Learning Methods for Evolving Data Streams</b>
<a href="https://arxiv.org/abs/2204.13625">arxiv:2204.13625</a>
&#x1F4C8; 3 <br>
<p>Johannes Haug, Effi Tramountani, Gjergji Kasneci</p></summary>
<p>

**Abstract:** Due to the unspecified and dynamic nature of data streams, online machine learning requires powerful and flexible solutions. However, evaluating online machine learning methods under realistic conditions is difficult. Existing work therefore often draws on different heuristics and simulations that do not necessarily produce meaningful and reliable results. Indeed, in the absence of common evaluation standards, it often remains unclear how online learning methods will perform in practice or in comparison to similar work. In this paper, we propose a comprehensive set of properties for high-quality machine learning in evolving data streams. In particular, we discuss sensible performance measures and evaluation strategies for online predictive modelling, online feature selection and concept drift detection. As one of the first works, we also look at the interpretability of online learning methods. The proposed evaluation standards are provided in a new Python framework called float. Float is completely modular and allows the simultaneous integration of common libraries, such as scikit-multiflow or river, with custom code. Float is open-sourced and can be accessed at https://github.com/haugjo/float. In this sense, we hope that our work will contribute to more standardized, reliable and realistic testing and comparison of online machine learning methods.

</p>
</details>

<details><summary><b>Emotion Recognition In Persian Speech Using Deep Neural Networks</b>
<a href="https://arxiv.org/abs/2204.13601">arxiv:2204.13601</a>
&#x1F4C8; 3 <br>
<p>Ali Yazdani, Hossein Simchi, Yaser Shekofteh</p></summary>
<p>

**Abstract:** Speech Emotion Recognition (SER) is of great importance in Human-Computer Interaction (HCI), as it provides a deeper understanding of the situation and results in better interaction. In recent years, various machine learning and deep learning algorithms have been developed to improve SER techniques. Recognition of emotions depends on the type of expression that varies between different languages. In this article, to further study this important factor in Farsi, we examine various deep learning techniques on the SheEMO dataset. Using signal features in low- and high-level descriptions and different deep networks and machine learning techniques, Unweighted Average Recall (UAR) of 65.20 is achieved with an accuracy of 78.29.

</p>
</details>

<details><summary><b>Keep the Caption Information: Preventing Shortcut Learning in Contrastive Image-Caption Retrieval</b>
<a href="https://arxiv.org/abs/2204.13382">arxiv:2204.13382</a>
&#x1F4C8; 3 <br>
<p>Maurits Bleeker, Andrew Yates, Maarten de Rijke</p></summary>
<p>

**Abstract:** To train image-caption retrieval (ICR) methods, contrastive loss functions are a common choice for optimization functions. Unfortunately, contrastive ICR methods are vulnerable to learning shortcuts: decision rules that perform well on the training data but fail to transfer to other testing conditions. We introduce an approach to reduce shortcut feature representations for the ICR task: latent target decoding (LTD). We add an additional decoder to the learning framework to reconstruct the input caption, which prevents the image and caption encoder from learning shortcut features. Instead of reconstructing input captions in the input space, we decode the semantics of the caption in a latent space. We implement the LTD objective as an optimization constraint, to ensure that the reconstruction loss is below a threshold value while primarily optimizing for the contrastive loss. Importantly, LTD does not depend on additional training data or expensive (hard) negative mining strategies. Our experiments show that, unlike reconstructing the input caption, LTD reduces shortcut learning and improves generalizability by obtaining higher recall@k and r-precision scores. Additionally, we show that the evaluation scores benefit from implementing LTD as an optimization constraint instead of a dual loss.

</p>
</details>

<details><summary><b>Learning General Inventory Management Policy for Large Supply Chain Network</b>
<a href="https://arxiv.org/abs/2204.13378">arxiv:2204.13378</a>
&#x1F4C8; 3 <br>
<p>Soh Kumabe, Shinya Shiroshita, Takanori Hayashi, Shirou Maruyama</p></summary>
<p>

**Abstract:** Inventory management in warehouses directly affects profits made by manufacturers. Particularly, large manufacturers produce a very large variety of products that are handled by a significantly large number of retailers. In such a case, the computational complexity of classical inventory management algorithms is inordinately large. In recent years, learning-based approaches have become popular for addressing such problems. However, previous studies have not been managed systems where both the number of products and retailers are large. This study proposes a reinforcement learning-based warehouse inventory management algorithm that can be used for supply chain systems where both the number of products and retailers are large. To solve the computational problem of handling large systems, we provide a means of approximate simulation of the system in the training phase. Our experiments on both real and artificial data demonstrate that our algorithm with approximated simulation can successfully handle large supply chain networks.

</p>
</details>

<details><summary><b>Machine learning for knowledge acquisition and accelerated inverse-design for non-Hermitian systems</b>
<a href="https://arxiv.org/abs/2204.13376">arxiv:2204.13376</a>
&#x1F4C8; 3 <br>
<p>W. W. Ahmed, M. Farhat, K. Staliunas, X. Zhang, Y. Wu</p></summary>
<p>

**Abstract:** Non-Hermitian systems offer new platforms for unusual physical properties that can be flexibly manipulated by redistribution of the real and imaginary parts of refractive indices, whose presence breaks conventional wave propagation symmetries, leading to asymmetric reflection and symmetric transmission with respect to the wave propagation direction. Here, we use supervised and unsupervised learning techniques for knowledge acquisition in non-Hermitian systems which accelerate the inverse design process. In particular, we construct a deep learning model that relates the transmission and asymmetric reflection in non-conservative settings and proposes sub-manifold learning to recognize non-Hermitian features from transmission spectra. The developed deep learning framework determines the feasibility of a desired spectral response for a given structure and uncovers the role of effective gain-loss parameters to tailor the spectral response. These findings pave the way for intelligent inverse design and shape our understanding of the physical mechanism in general non-Hermitian systems.

</p>
</details>

<details><summary><b>Actor-Critic Scheduling for Path-Aware Air-to-Ground Multipath Multimedia Delivery</b>
<a href="https://arxiv.org/abs/2204.13343">arxiv:2204.13343</a>
&#x1F4C8; 3 <br>
<p>Achilles Machumilane, Alberto Gotta, Pietro Cassarà, Claudio Gennaro, Giuseppe Amato</p></summary>
<p>

**Abstract:** Reinforcement Learning (RL) has recently found wide applications in network traffic management and control because some of its variants do not require prior knowledge of network models. In this paper, we present a novel scheduler for real-time multimedia delivery in multipath systems based on an Actor-Critic (AC) RL algorithm. We focus on a challenging scenario of real-time video streaming from an Unmanned Aerial Vehicle (UAV) using multiple wireless paths. The scheduler acting as an RL agent learns in real-time the optimal policy for path selection, path rate allocation and redundancy estimation for flow protection. The scheduler, implemented as a module of the GStreamer framework, can be used in real or simulated settings. The simulation results show that our scheduler can target a very low loss rate at the receiver by dynamically adapting in real-time the scheduling policy to the path conditions without performing training or relying on prior knowledge of network channel models.

</p>
</details>

<details><summary><b>BAGNet: Bidirectional Aware Guidance Network for Malignant Breast lesions Segmentation</b>
<a href="https://arxiv.org/abs/2204.13342">arxiv:2204.13342</a>
&#x1F4C8; 3 <br>
<p>Gongping Chen, Yuming Liu, Yu Dai, Jianxun Zhang, Liang Cui, Xiaotao Yin</p></summary>
<p>

**Abstract:** Breast lesions segmentation is an important step of computer-aided diagnosis system, and it has attracted much attention. However, accurate segmentation of malignant breast lesions is a challenging task due to the effects of heterogeneous structure and similar intensity distributions. In this paper, a novel bidirectional aware guidance network (BAGNet) is proposed to segment the malignant lesion from breast ultrasound images. Specifically, the bidirectional aware guidance network is used to capture the context between global (low-level) and local (high-level) features from the input coarse saliency map. The introduction of the global feature map can reduce the interference of surrounding tissue (background) on the lesion regions. To evaluate the segmentation performance of the network, we compared with several state-of-the-art medical image segmentation methods on the public breast ultrasound dataset using six commonly used evaluation metrics. Extensive experimental results indicate that our method achieves the most competitive segmentation results on malignant breast ultrasound images.

</p>
</details>

<details><summary><b>Discriminative-Region Attention and Orthogonal-View Generation Model for Vehicle Re-Identification</b>
<a href="https://arxiv.org/abs/2204.13323">arxiv:2204.13323</a>
&#x1F4C8; 3 <br>
<p>Huadong Li, Yuefeng Wang, Ying Wei, Lin Wang, Li Ge</p></summary>
<p>

**Abstract:** Vehicle re-identification (Re-ID) is urgently demanded to alleviate thepressure caused by the increasingly onerous task of urban traffic management. Multiple challenges hamper the applications of vision-based vehicle Re-ID methods: (1) The appearances of different vehicles of the same brand/model are often similar; However, (2) the appearances of the same vehicle differ significantly from different viewpoints. Previous methods mainly use manually annotated multi-attribute datasets to assist the network in getting detailed cues and in inferencing multi-view to improve the vehicle Re-ID performance. However, finely labeled vehicle datasets are usually unattainable in real application scenarios. Hence, we propose a Discriminative-Region Attention and Orthogonal-View Generation (DRA-OVG) model, which only requires identity (ID) labels to conquer the multiple challenges of vehicle Re-ID.The proposed DRA model can automatically extract the discriminative region features, which can distinguish similar vehicles. And the OVG model can generate multi-view features based on the input view features to reduce the impact of viewpoint mismatches. Finally, the distance between vehicle appearances is presented by the discriminative region features and multi-view features together. Therefore, the significance of pairwise distance measure between vehicles is enhanced in acomplete feature space. Extensive experiments substantiate the effectiveness of each proposed ingredient, and experimental results indicate that our approach achieves remarkable improvements over the state- of-the-art vehicle Re-ID methods on VehicleID and VeRi-776 datasets.

</p>
</details>

<details><summary><b>Bilinear value networks</b>
<a href="https://arxiv.org/abs/2204.13695">arxiv:2204.13695</a>
&#x1F4C8; 2 <br>
<p>Zhang-Wei Hong, Ge Yang, Pulkit Agrawal</p></summary>
<p>

**Abstract:** The dominant framework for off-policy multi-goal reinforcement learning involves estimating goal conditioned Q-value function. When learning to achieve multiple goals, data efficiency is intimately connected with the generalization of the Q-function to new goals. The de-facto paradigm is to approximate Q(s, a, g) using monolithic neural networks. To improve the generalization of the Q-function, we propose a bilinear decomposition that represents the Q-value via a low-rank approximation in the form of a dot product between two vector fields. The first vector field, f(s, a), captures the environment's local dynamics at the state s; whereas the second component, φ(s, g), captures the global relationship between the current state and the goal. We show that our bilinear decomposition scheme substantially improves data efficiency, and has superior transfer to out-of-distribution goals compared to prior methods. Empirical evidence is provided on the simulated Fetch robot task-suite and dexterous manipulation with a Shadow hand.

</p>
</details>

<details><summary><b>Linear Temporal Logic Modulo Theories over Finite Traces (Extended Version)</b>
<a href="https://arxiv.org/abs/2204.13693">arxiv:2204.13693</a>
&#x1F4C8; 2 <br>
<p>Luca Geatti, Alessandro Gianola, Nicola Gigante</p></summary>
<p>

**Abstract:** This paper studies Linear Temporal Logic over Finite Traces (LTLf) where proposition letters are replaced with first-order formulas interpreted over arbitrary theories, in the spirit of Satisfiability Modulo Theories. The resulting logic, called LTLf Modulo Theories (LTLfMT), is semi-decidable. Nevertheless, its high expressiveness comes useful in a number of use cases, such as model-checking of data-aware processes and data-aware planning. Despite the general undecidability of these problems, being able to solve satisfiable instances is a compromise worth studying. After motivating and describing such use cases, we provide a sound and complete semi-decision procedure for LTLfMT based on the SMT encoding of a one-pass tree-shaped tableau system. The algorithm is implemented in the BLACK satisfiability checking tool, and an experimental evaluation shows the feasibility of the approach on novel benchmarks.

</p>
</details>

<details><summary><b>Bona fide Riesz projections for density estimation</b>
<a href="https://arxiv.org/abs/2204.13606">arxiv:2204.13606</a>
&#x1F4C8; 2 <br>
<p>P. del Aguila Pla, Michael Unser</p></summary>
<p>

**Abstract:** The projection of sample measurements onto a reconstruction space represented by a basis on a regular grid is a powerful and simple approach to estimate a probability density function. In this paper, we focus on Riesz bases and propose a projection operator that, in contrast to previous works, guarantees the bona fide properties for the estimate, namely, non-negativity and total probability mass $1$. Our bona fide projection is defined as a convex problem. We propose solution techniques and evaluate them. Results suggest an improved performance, specifically in circumstances prone to rippling effects.

</p>
</details>

<details><summary><b>An Explainable Regression Framework for Predicting Remaining Useful Life of Machines</b>
<a href="https://arxiv.org/abs/2204.13574">arxiv:2204.13574</a>
&#x1F4C8; 2 <br>
<p>Talhat Khan, Kashif Ahmad, Jebran Khan, Imran Khan, Nasir Ahmad</p></summary>
<p>

**Abstract:** Prediction of a machine's Remaining Useful Life (RUL) is one of the key tasks in predictive maintenance. The task is treated as a regression problem where Machine Learning (ML) algorithms are used to predict the RUL of machine components. These ML algorithms are generally used as a black box with a total focus on the performance without identifying the potential causes behind the algorithms' decisions and their working mechanism. We believe, the performance (in terms of Mean Squared Error (MSE), etc.,) alone is not enough to build the trust of the stakeholders in ML prediction rather more insights on the causes behind the predictions are needed. To this aim, in this paper, we explore the potential of Explainable AI (XAI) techniques by proposing an explainable regression framework for the prediction of machines' RUL. We also evaluate several ML algorithms including classical and Neural Networks (NNs) based solutions for the task. For the explanations, we rely on two model agnostic XAI methods namely Local Interpretable Model-Agnostic Explanations (LIME) and Shapley Additive Explanations (SHAP). We believe, this work will provide a baseline for future research in the domain.

</p>
</details>

<details><summary><b>Predicting batch queue job wait times for informed scheduling of urgent HPC workloads</b>
<a href="https://arxiv.org/abs/2204.13543">arxiv:2204.13543</a>
&#x1F4C8; 2 <br>
<p>Nick Brown, Gordon Gibb, Evgenij Belikov, Rupert Nash</p></summary>
<p>

**Abstract:** There is increasing interest in the use of HPC machines for urgent workloads to help tackle disasters as they unfold. Whilst batch queue systems are not ideal in supporting such workloads, many disadvantages can be worked around by accurately predicting when a waiting job will start to run. However there are numerous challenges in achieving such a prediction with high accuracy, not least because the queue's state can change rapidly and depend upon many factors. In this work we explore a novel machine learning approach for predicting queue wait times, hypothesising that such a model can capture the complex behaviour resulting from the queue policy and other interactions to generate accurate job start times.
  For ARCHER2 (HPE Cray EX), Cirrus (HPE 8600) and 4-cabinet (HPE Cray EX) we explore how different machine learning approaches and techniques improve the accuracy of our predictions, comparing against the estimation generated by Slurm. We demonstrate that our techniques deliver the most accurate predictions across our machines of interest, with the result of this work being the ability to predict job start times within one minute of the actual start time for around 65\% of jobs on ARCHER2 and 4-cabinet, and 76\% of jobs on Cirrus. When compared against what Slurm can deliver, this represents around 3.8 times better accuracy on ARCHER2 and 18 times better for Cirrus. Furthermore our approach can accurately predicting the start time for three quarters of all job within ten minutes of the actual start time on ARCHER2 and 4-cabinet, and for 90\% of jobs on Cirrus. Whilst the driver of this work has been to better facilitate placement of urgent workloads across HPC machines, the insights gained can be used to provide wider benefits to users and also enrich existing batch queue systems and inform policy too.

</p>
</details>

<details><summary><b>Interpretable collective intelligence of non-rational human agents</b>
<a href="https://arxiv.org/abs/2204.13424">arxiv:2204.13424</a>
&#x1F4C8; 2 <br>
<p>Alexey V. Osipov, Nikolay N. Osipov</p></summary>
<p>

**Abstract:** We outline how to create a mechanism that provides an optimal way to elicit, from an arbitrary group of experts, the probability of the truth of an arbitrary logical proposition together with collective information that has an explicit form and interprets this probability. Such a system could, in particular, incentivize experts from all over the world to collectively solve scientific or medical problems in a very efficient manner. In our main considerations about real experts, they are not assumed to be Bayesian and their behavior is described by utilities that satisfy the von Neumann-Morgenstern axioms only locally.

</p>
</details>

<details><summary><b>Fuzzy Expert System for Stock Portfolio Selection: An Application to Bombay Stock Exchange</b>
<a href="https://arxiv.org/abs/2204.13385">arxiv:2204.13385</a>
&#x1F4C8; 2 <br>
<p>Gour Sundar Mitra Thakur, Rupak Bhattacharyyab, Seema Sarkar</p></summary>
<p>

**Abstract:** Selection of proper stocks, before allocating investment ratios, is always a crucial task for the investors. Presence of many influencing factors in stock performance have motivated researchers to adopt various Artificial Intelligence (AI) techniques to make this challenging task easier. In this paper a novel fuzzy expert system model is proposed to evaluate and rank the stocks under Bombay Stock Exchange (BSE). Dempster-Shafer (DS) evidence theory is used for the first time to automatically generate the consequents of the fuzzy rule base to reduce the effort in knowledge base development of the expert system. Later a portfolio optimization model is constructed where the objective function is considered as the ratio of the difference of fuzzy portfolio return and the risk free return to the weighted mean semi-variance of the assets that has been used. The model is solved by applying Ant Colony Optimization (ACO) algorithm by giving preference to the top ranked stocks. The performance of the model proved to be satisfactory for short-term investment period when compared with the recent performance of the stocks.

</p>
</details>

<details><summary><b>MMRotate: A Rotated Object Detection Benchmark using Pytorch</b>
<a href="https://arxiv.org/abs/2204.13317">arxiv:2204.13317</a>
&#x1F4C8; 2 <br>
<p>Yue Zhou, Xue Yang, Gefan Zhang, Jiabao Wang, Yanyi Liu, Liping Hou, Xue Jiang, Xingzhao Liu, Junchi Yan, Chengqi Lyu, Wenwei Zhang, Kai Chen</p></summary>
<p>

**Abstract:** We present an open-source toolbox, named MMRotate, which provides a coherent algorithm framework of training, inferring, and evaluation for the popular rotated object detection algorithm based on deep learning. MMRotate implements 18 state-of-the-art algorithms and supports the three most frequently used angle definition methods. To facilitate future research and industrial applications of rotated object detection-related problems, we also provide a large number of trained models and detailed benchmarks to give insights into the performance of rotated object detection. MMRotate is publicly released at https://github.com/open-mmlab/mmrotate.

</p>
</details>

<details><summary><b>Attention Based Neural Networks for Wireless Channel Estimation</b>
<a href="https://arxiv.org/abs/2204.13465">arxiv:2204.13465</a>
&#x1F4C8; 1 <br>
<p>Dianxin Luan, John Thompson</p></summary>
<p>

**Abstract:** In this paper, we deploy the self-attention mechanism to achieve improved channel estimation for orthogonal frequency-division multiplexing waveforms in the downlink. Specifically, we propose a new hybrid encoder-decoder structure (called HA02) for the first time which exploits the attention mechanism to focus on the most important input information. In particular, we implement a transformer encoder block as the encoder to achieve the sparsity in the input features and a residual neural network as the decoder respectively, inspired by the success of the attention mechanism. Using 3GPP channel models, our simulations show superior estimation performance compared with other candidate neural network methods for channel estimation.

</p>
</details>

<details><summary><b>TTAGN: Temporal Transaction Aggregation Graph Network for Ethereum Phishing Scams Detection</b>
<a href="https://arxiv.org/abs/2204.13442">arxiv:2204.13442</a>
&#x1F4C8; 1 <br>
<p>Sijia Li, Gaopeng Gou, Chang Liu, Chengshang Hou, Zhenzhen Li, Gang Xiong</p></summary>
<p>

**Abstract:** In recent years, phishing scams have become the most serious type of crime involved in Ethereum, the second-largest blockchain platform. The existing phishing scams detection technology on Ethereum mostly uses traditional machine learning or network representation learning to mine the key information from the transaction network to identify phishing addresses. However, these methods adopt the last transaction record or even completely ignore these records, and only manual-designed features are taken for the node representation. In this paper, we propose a Temporal Transaction Aggregation Graph Network (TTAGN) to enhance phishing scams detection performance on Ethereum. Specifically, in the temporal edges representation module, we model the temporal relationship of historical transaction records between nodes to construct the edge representation of the Ethereum transaction network. Moreover, the edge representations around the node are aggregated to fuse topological interactive relationships into its representation, also named as trading features, in the edge2node module. We further combine trading features with common statistical and structural features obtained by graph neural networks to identify phishing addresses. Evaluated on real-world Ethereum phishing scams datasets, our TTAGN (92.8% AUC, and 81.6% F1score) outperforms the state-of-the-art methods, and the effectiveness of temporal edges representation and edge2node module is also demonstrated.

</p>
</details>

<details><summary><b>Enhance Ambiguous Community Structure via Multi-strategy Community Related Link Prediction Method with Evolutionary Process</b>
<a href="https://arxiv.org/abs/2204.13301">arxiv:2204.13301</a>
&#x1F4C8; 1 <br>
<p>Qiming Yang, Wei Wei, Ruizhi Zhang, Bowen Pang, Xiangnan Feng</p></summary>
<p>

**Abstract:** Most real-world networks suffer from incompleteness or incorrectness, which is an inherent attribute to real-world datasets. As a consequence, those downstream machine learning tasks in complex network like community detection methods may yield less satisfactory results, i.e., a proper preprocessing measure is required here. To address this issue, in this paper, we design a new community attribute based link prediction strategy HAP and propose a two-step community enhancement algorithm with automatic evolution process based on HAP. This paper aims at providing a community enhancement measure through adding links to clarify ambiguous community structures. The HAP method takes the neighbourhood uncertainty and Shannon entropy to identify boundary nodes, and establishes links by considering the nodes' community attributes and community size at the same time. The experimental results on twelve real-world datasets with ground truth community indicate that the proposed link prediction method outperforms other baseline methods and the enhancement of community follows the expected evolution process.

</p>
</details>

<details><summary><b>Justice in Misinformation Detection Systems: An Analysis of Algorithms, Stakeholders, and Potential Harms</b>
<a href="https://arxiv.org/abs/2204.13568">arxiv:2204.13568</a>
&#x1F4C8; 0 <br>
<p>Terrence Neumann, Maria De-Arteaga, Sina Fazelpour</p></summary>
<p>

**Abstract:** Faced with the scale and surge of misinformation on social media, many platforms and fact-checking organizations have turned to algorithms for automating key parts of misinformation detection pipelines. While offering a promising solution to the challenge of scale, the ethical and societal risks associated with algorithmic misinformation detection are not well-understood. In this paper, we employ and extend upon the notion of informational justice to develop a framework for explicating issues of justice relating to representation, participation, distribution of benefits and burdens, and credibility in the misinformation detection pipeline. Drawing on the framework: (1) we show how injustices materialize for stakeholders across three algorithmic stages in the pipeline; (2) we suggest empirical measures for assessing these injustices; and (3) we identify potential sources of these harms. This framework should help researchers, policymakers, and practitioners reason about potential harms or risks associated with these algorithms and provide conceptual guidance for the design of algorithmic fairness audits in this domain.

</p>
</details>


{% endraw %}
Prev: [2022.04.27]({{ '/2022/04/27/2022.04.27.html' | relative_url }})  Next: [2022.04.29]({{ '/2022/04/29/2022.04.29.html' | relative_url }})