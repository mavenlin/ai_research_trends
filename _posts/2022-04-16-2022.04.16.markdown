Prev: [2022.04.15]({{ '/2022/04/15/2022.04.15.html' | relative_url }})  Next: [2022.04.17]({{ '/2022/04/17/2022.04.17.html' | relative_url }})
{% raw %}
## Summary for 2022-04-16, created on 2022-04-23


<details><summary><b>Persua: A Visual Interactive System to Enhance the Persuasiveness of Arguments in Online Discussion</b>
<a href="https://arxiv.org/abs/2204.07741">arxiv:2204.07741</a>
&#x1F4C8; 7 <br>
<p>Meng Xia, Qian Zhu, Xingbo Wang, Fei Nie, Huamin Qu, Xiaojuan Ma</p></summary>
<p>

**Abstract:** Persuading people to change their opinions is a common practice in online discussion forums on topics ranging from political campaigns to relationship consultation. Enhancing people's ability to write persuasive arguments could not only practice their critical thinking and reasoning but also contribute to the effectiveness and civility in online communication. It is, however, not an easy task in online discussion settings where written words are the primary communication channel. In this paper, we derived four design goals for a tool that helps users improve the persuasiveness of arguments in online discussions through a survey with 123 online forum users and interviews with five debating experts. To satisfy these design goals, we analyzed and built a labeled dataset of fine-grained persuasive strategies (i.e., logos, pathos, ethos, and evidence) in 164 arguments with high ratings on persuasiveness from ChangeMyView, a popular online discussion forum. We then designed an interactive visual system, Persua, which provides example-based guidance on persuasive strategies to enhance the persuasiveness of arguments. In particular, the system constructs portfolios of arguments based on different persuasive strategies applied to a given discussion topic. It then presents concrete examples based on the difference between the portfolios of user input and high-quality arguments in the dataset. A between-subjects study shows suggestive evidence that Persua encourages users to submit more times for feedback and helps users improve more on the persuasiveness of their arguments than a baseline system. Finally, a set of design considerations was summarized to guide future intelligent systems that improve the persuasiveness in text.

</p>
</details>

<details><summary><b>nigam@COLIEE-22: Legal Case Retrieval and Entailment using Cascading of Lexical and Semantic-based models</b>
<a href="https://arxiv.org/abs/2204.07853">arxiv:2204.07853</a>
&#x1F4C8; 5 <br>
<p>Shubham Kumar Nigam, Navansh Goel</p></summary>
<p>

**Abstract:** This paper describes our submission to the Competition on Legal Information Extraction/Entailment 2022 (COLIEE-2022) workshop on case law competition for tasks 1 and 2. Task 1 is a legal case retrieval task, which involves reading a new case and extracting supporting cases from the provided case law corpus to support the decision. Task 2 is the legal case entailment task, which involves the identification of a paragraph from existing cases that entails the decision in a relevant case. We employed the neural models Sentence-BERT and Sent2Vec for semantic understanding and the traditional retrieval model BM25 for exact matching in both tasks. As a result, our team ("nigam") ranked 5th among all the teams in Tasks 1 and 2. Experimental results indicate that the traditional retrieval model BM25 still outperforms neural network-based models.

</p>
</details>

<details><summary><b>Robust PCA Unrolling Network for Super-resolution Vessel Extraction in X-ray Coronary Angiography</b>
<a href="https://arxiv.org/abs/2204.08466">arxiv:2204.08466</a>
&#x1F4C8; 4 <br>
<p>Binjie Qin, Haohao Mao, Yiming Liu, Jun Zhao, Yisong Lv, Yueqi Zhu, Song Ding, Xu Chen</p></summary>
<p>

**Abstract:** Although robust PCA has been increasingly adopted to extract vessels from X-ray coronary angiography (XCA) images, challenging problems such as inefficient vessel-sparsity modelling, noisy and dynamic background artefacts, and high computational cost still remain unsolved. Therefore, we propose a novel robust PCA unrolling network with sparse feature selection for super-resolution XCA vessel imaging. Being embedded within a patch-wise spatiotemporal super-resolution framework that is built upon a pooling layer and a convolutional long short-term memory network, the proposed network can not only gradually prune complex vessel-like artefacts and noisy backgrounds in XCA during network training but also iteratively learn and select the high-level spatiotemporal semantic information of moving contrast agents flowing in the XCA-imaged vessels. The experimental results show that the proposed method significantly outperforms state-of-the-art methods, especially in the imaging of the vessel network and its distal vessels, by restoring the intensity and geometry profiles of heterogeneous vessels against complex and dynamic backgrounds.

</p>
</details>

<details><summary><b>Detection of Small Holes by the Scale-Invariant Robust Density-Aware Distance (RDAD) Filtration</b>
<a href="https://arxiv.org/abs/2204.07821">arxiv:2204.07821</a>
&#x1F4C8; 4 <br>
<p> Chunyin,  Siu, Gennady Samorodnitsky, Christina Yu, Andrey Yao</p></summary>
<p>

**Abstract:** A novel topological-data-analytical (TDA) method is proposed to distinguish, from noise, small holes surrounded by high-density regions of a probability density function whose mass is concentrated near a manifold (or more generally, a CW complex) embedded in a high-dimensional Euclidean space. The proposed method is robust against additive noise and outliers. In particular, sample points are allowed to be perturbed away from the manifold. Traditional TDA tools, like those based on the distance filtration, often struggle to distinguish small features from noise, because of their short persistence. An alternative filtration, called Robust Density-Aware Distance (RDAD) filtration, is proposed to prolong the persistence of small holes surrounded by high-density regions. This is achieved by weighting the distance function by the density in the sense of Bell et al. Distance-to-measure is incorporated to enhance stability and mitigate noise due to the density estimation. The utility of the proposed filtration in identifying small holes, as well as its robustness against noise, are illustrated through an analytical example and extensive numerical experiments. Basic mathematical properties of the proposed filtration are proven.

</p>
</details>

<details><summary><b>Visual Attention Methods in Deep Learning: An In-Depth Survey</b>
<a href="https://arxiv.org/abs/2204.07756">arxiv:2204.07756</a>
&#x1F4C8; 4 <br>
<p>Mohammed Hassanin, Saeed Anwar, Ibrahim Radwan, Fahad S Khan, Ajmal Mian</p></summary>
<p>

**Abstract:** Inspired by the human cognitive system, attention is a mechanism that imitates the human cognitive awareness about specific information, amplifying critical details to focus more on the essential aspects of data. Deep learning has employed attention to boost performance for many applications. Interestingly, the same attention design can suit processing different data modalities and can easily be incorporated into large networks. Furthermore, multiple complementary attention mechanisms can be incorporated in one network. Hence, attention techniques have become extremely attractive. However, the literature lacks a comprehensive survey specific to attention techniques to guide researchers in employing attention in their deep models. Note that, besides being demanding in terms of training data and computational resources, transformers only cover a single category in self-attention out of the many categories available. We fill this gap and provide an in-depth survey of 50 attention techniques categorizing them by their most prominent features. We initiate our discussion by introducing the fundamental concepts behind the success of attention mechanism. Next, we furnish some essentials such as the strengths and limitations of each attention category, describe their fundamental building blocks, basic formulations with primary usage, and applications specifically for computer vision. We also discuss the challenges and open questions related to attention mechanism in general. Finally, we recommend possible future research directions for deep attention.

</p>
</details>

<details><summary><b>Semantic interpretation for convolutional neural networks: What makes a cat a cat?</b>
<a href="https://arxiv.org/abs/2204.07724">arxiv:2204.07724</a>
&#x1F4C8; 4 <br>
<p>Hao Xu, Yuntian Chen, Dongxiao Zhang</p></summary>
<p>

**Abstract:** The interpretability of deep neural networks has attracted increasing attention in recent years, and several methods have been created to interpret the "black box" model. Fundamental limitations remain, however, that impede the pace of understanding the networks, especially the extraction of understandable semantic space. In this work, we introduce the framework of semantic explainable AI (S-XAI), which utilizes row-centered principal component analysis to obtain the common traits from the best combination of superpixels discovered by a genetic algorithm, and extracts understandable semantic spaces on the basis of discovered semantically sensitive neurons and visualization techniques. Statistical interpretation of the semantic space is also provided, and the concept of semantic probability is proposed for the first time. Our experimental results demonstrate that S-XAI is effective in providing a semantic interpretation for the CNN, and offers broad usage, including trustworthiness assessment and semantic sample searching.

</p>
</details>

<details><summary><b>IOP-FL: Inside-Outside Personalization for Federated Medical Image Segmentation</b>
<a href="https://arxiv.org/abs/2204.08467">arxiv:2204.08467</a>
&#x1F4C8; 3 <br>
<p>Meirui Jiang, Hongzheng Yang, Chen Cheng, Qi Dou</p></summary>
<p>

**Abstract:** Federated learning (FL) allows multiple medical institutions to collaboratively learn a global model without centralizing all clients data. It is difficult, if possible at all, for such a global model to commonly achieve optimal performance for each individual client, due to the heterogeneity of medical data from various scanners and patient demographics. This problem becomes even more significant when deploying the global model to unseen clients outside the FL with new distributions not presented during federated training. To optimize the prediction accuracy of each individual client for critical medical tasks, we propose a novel unified framework for both Inside and Outside model Personalization in FL (IOP-FL). Our inside personalization is achieved by a lightweight gradient-based approach that exploits the local adapted model for each client, by accumulating both the global gradients for common knowledge and local gradients for client-specific optimization. Moreover, and importantly, the obtained local personalized models and the global model can form a diverse and informative routing space to personalize a new model for outside FL clients. Hence, we design a new test-time routing scheme inspired by the consistency loss with a shape constraint to dynamically incorporate the models, given the distribution information conveyed by the test data. Our extensive experimental results on two medical image segmentation tasks present significant improvements over SOTA methods on both inside and outside personalization, demonstrating the great potential of our IOP-FL scheme for clinical practice. Code will be released at https://github.com/med-air/IOP-FL.

</p>
</details>

<details><summary><b>StyleT2F: Generating Human Faces from Textual Description Using StyleGAN2</b>
<a href="https://arxiv.org/abs/2204.07924">arxiv:2204.07924</a>
&#x1F4C8; 3 <br>
<p>Mohamed Shawky Sabae, Mohamed Ahmed Dardir, Remonda Talaat Eskarous, Mohamed Ramzy Ebbed</p></summary>
<p>

**Abstract:** AI-driven image generation has improved significantly in recent years. Generative adversarial networks (GANs), like StyleGAN, are able to generate high-quality realistic data and have artistic control over the output, as well. In this work, we present StyleT2F, a method of controlling the output of StyleGAN2 using text, in order to be able to generate a detailed human face from textual description. We utilize StyleGAN's latent space to manipulate different facial features and conditionally sample the required latent code, which embeds the facial features mentioned in the input text. Our method proves to capture the required features correctly and shows consistency between the input text and the output images. Moreover, our method guarantees disentanglement on manipulating a wide range of facial features that sufficiently describes a human face.

</p>
</details>

<details><summary><b>Accelerated MRI With Deep Linear Convolutional Transform Learning</b>
<a href="https://arxiv.org/abs/2204.07923">arxiv:2204.07923</a>
&#x1F4C8; 3 <br>
<p>Hongyi Gu, Burhaneddin Yaman, Steen Moeller, Il Yong Chun, Mehmet Akçakaya</p></summary>
<p>

**Abstract:** Recent studies show that deep learning (DL) based MRI reconstruction outperforms conventional methods, such as parallel imaging and compressed sensing (CS), in multiple applications. Unlike CS that is typically implemented with pre-determined linear representations for regularization, DL inherently uses a non-linear representation learned from a large database. Another line of work uses transform learning (TL) to bridge the gap between these two approaches by learning linear representations from data. In this work, we combine ideas from CS, TL and DL reconstructions to learn deep linear convolutional transforms as part of an algorithm unrolling approach. Using end-to-end training, our results show that the proposed technique can reconstruct MR images to a level comparable to DL methods, while supporting uniform undersampling patterns unlike conventional CS methods. Our proposed method relies on convex sparse image reconstruction with linear representation at inference time, which may be beneficial for characterizing robustness, stability and generalizability.

</p>
</details>

<details><summary><b>Turing's cascade instability supports the coordination of the mind, brain, and behavior</b>
<a href="https://arxiv.org/abs/2204.07904">arxiv:2204.07904</a>
&#x1F4C8; 3 <br>
<p>Damian G. Kelty-Stephen, Madhur Mangalam</p></summary>
<p>

**Abstract:** Turing inspired a computer metaphor of the mind and brain that has been handy and has spawned decades of empirical investigation, but he did much more and offered behavioral and cognitive sciences another metaphor--that of the cascade. The time has come to confront Turing's cascading instability, which suggests a geometrical framework driven by power laws and can be studied using multifractal formalism and multiscale probability density function analysis. Here, we review a rapidly growing body of scientific investigations revealing signatures of cascade instability and their consequences for a perceiving, acting, and thinking organism. We review work related to executive functioning (planning to act), postural control (bodily poise for turning plans into action), and effortful perception (action to gather information in a single modality and action to blend multimodal information). We also review findings on neuronal avalanches in the brain, specifically about neural participation in body-wide cascades. Turing's cascade instability blends the mind, brain, and behavior across space and time scales and provides an alternative to the dominant computer metaphor.

</p>
</details>

<details><summary><b>SymForce: Symbolic Computation and Code Generation for Robotics</b>
<a href="https://arxiv.org/abs/2204.07889">arxiv:2204.07889</a>
&#x1F4C8; 3 <br>
<p>Hayk Martiros, Aaron Miller, Nathan Bucki, Bradley Solliday, Ryan Kennedy, Jack Zhu, Tung Dang, Dominic Pattison, Harrison Zheng, Teo Tomic, Peter Henry, Gareth Cross, Josiah VanderMey, Alvin Sun, Samuel Wang, Kristen Holtz</p></summary>
<p>

**Abstract:** We present SymForce, a fast symbolic computation and code generation library for robotics applications like computer vision, state estimation, motion planning, and controls. SymForce combines the development speed and flexibility of symbolic mathematics with the performance of autogenerated, highly optimized code in C++ or any target runtime language. SymForce provides geometry and camera types, Lie group operations, and branchless singularity handling for creating and analyzing complex symbolic expressions in Python, built on top of SymPy. Generated functions can be integrated as factors into our tangent space nonlinear optimizer, which is highly optimized for real-time production use. We introduce novel methods to automatically compute tangent space Jacobians, eliminating the need for bug-prone handwritten derivatives. This workflow enables faster runtime code, faster development time, and fewer lines of handwritten code versus the state-of-the-art. Our experiments demonstrate that our approach can yield order of magnitude speedups on computational tasks core to robotics. Code is available at https://github.com/symforce-org/symforce .

</p>
</details>

<details><summary><b>COVIBOT: A Smart Chatbot for Assistance and E-Awareness during COVID-19 Pandemic</b>
<a href="https://arxiv.org/abs/2204.07851">arxiv:2204.07851</a>
&#x1F4C8; 3 <br>
<p>Maha Driss, Iman Almomani, Leen Alahmadi, Linah Alhajjam, Raghad Alharbi, Shahad Alanazi</p></summary>
<p>

**Abstract:** The coronavirus pandemic has spread over the past two years in our highly connected and information-dense society. Nonetheless, disseminating accurate and up-to-date information on the spread of this pandemic remains a challenge. In this context, opting for a solution based on conversational artificial intelligence, also known under the name of the chatbot, is proving to be an unavoidable solution, especially since it has already shown its effectiveness in fighting the coronavirus crisis in several countries. This work proposes to design and implement a smart chatbot on the theme of COVID-19, called COVIBOT, which will be useful in the context of Saudi Arabia. COVIBOT is a generative-based contextual chatbot, which is built using machine learning APIs that are offered by the cloud-based Azure Cognitive Services. Two versions of COVIBOT are offered: English and Arabic versions. Use cases of COVIBOT are tested and validated using a scenario-based approach.

</p>
</details>

<details><summary><b>Multimodal Few-Shot Object Detection with Meta-Learning Based Cross-Modal Prompting</b>
<a href="https://arxiv.org/abs/2204.07841">arxiv:2204.07841</a>
&#x1F4C8; 3 <br>
<p>Guangxing Han, Jiawei Ma, Shiyuan Huang, Long Chen, Rama Chellappa, Shih-Fu Chang</p></summary>
<p>

**Abstract:** We study multimodal few-shot object detection (FSOD) in this paper, using both few-shot visual examples and class semantic information for detection. Most of previous works focus on either few-shot or zero-shot object detection, ignoring the complementarity of visual and semantic information. We first show that meta-learning and prompt-based learning, the most commonly-used methods for few-shot learning and zero-shot transferring from pre-trained vision-language models to downstream tasks, are conceptually similar. They both reformulate the objective of downstream tasks the same as the pre-training tasks, and mostly without tuning the parameters of pre-trained models. Based on this observation, we propose to combine meta-learning with prompt-based learning for multimodal FSOD without fine-tuning, by learning transferable class-agnostic multimodal FSOD models over many-shot base classes. Specifically, to better exploit the pre-trained vision-language models, the meta-learning based cross-modal prompting is proposed to generate soft prompts and further used to extract the semantic prototype, conditioned on the few-shot visual examples. Then, the extracted semantic prototype and few-shot visual prototype are fused to generate the multimodal prototype for detection. Our models can efficiently fuse the visual and semantic information at both token-level and feature-level. We comprehensively evaluate the proposed multimodal FSOD models on multiple few-shot object detection benchmarks, achieving promising results.

</p>
</details>

<details><summary><b>A Robust and Scalable Attention Guided Deep Learning Framework for Movement Quality Assessment</b>
<a href="https://arxiv.org/abs/2204.07840">arxiv:2204.07840</a>
&#x1F4C8; 3 <br>
<p>Aditya Kanade, Mansi Sharma, Manivannan Muniyandi</p></summary>
<p>

**Abstract:** Physical rehabilitation programs frequently begin with a brief stay in the hospital and continue with home-based rehabilitation. Lack of feedback on exercise correctness is a significant issue in home-based rehabilitation. Automated movement quality assessment (MQA) using skeletal movement data (hereafter referred to as skeletal data) collected via depth imaging devices can assist with home-based rehabilitation by providing the necessary quantitative feedback. This paper aims to use recent advances in deep learning to address the problem of MQA. Movement quality score generation is an essential component of MQA. We propose three novel skeletal data augmentation schemes. We show that using the proposed augmentations for generating movement quality scores result in significant performance boosts over existing methods. Finally, we propose a novel transformer based architecture for MQA. Four novel feature extractors are proposed and studied that allow the transformer network to operate on skeletal data. We show that adding the attention mechanism in the design of the proposed feature extractor allows the transformer network to pay attention to specific body parts that make a significant contribution towards executing a movement. We report an improvement in movement quality score prediction of 12% on UI-PRMD dataset and 21% on KIMORE dataset compared to the existing methods.

</p>
</details>

<details><summary><b>Graph-incorporated Latent Factor Analysis for High-dimensional and Sparse Matrices</b>
<a href="https://arxiv.org/abs/2204.07818">arxiv:2204.07818</a>
&#x1F4C8; 3 <br>
<p>Di Wu, Yi He, Xin Luo</p></summary>
<p>

**Abstract:** A High-dimensional and sparse (HiDS) matrix is frequently encountered in a big data-related application like an e-commerce system or a social network services system. To perform highly accurate representation learning on it is of great significance owing to the great desire of extracting latent knowledge and patterns from it. Latent factor analysis (LFA), which represents an HiDS matrix by learning the low-rank embeddings based on its observed entries only, is one of the most effective and efficient approaches to this issue. However, most existing LFA-based models perform such embeddings on a HiDS matrix directly without exploiting its hidden graph structures, thereby resulting in accuracy loss. To address this issue, this paper proposes a graph-incorporated latent factor analysis (GLFA) model. It adopts two-fold ideas: 1) a graph is constructed for identifying the hidden high-order interaction (HOI) among nodes described by an HiDS matrix, and 2) a recurrent LFA structure is carefully designed with the incorporation of HOI, thereby improving the representa-tion learning ability of a resultant model. Experimental results on three real-world datasets demonstrate that GLFA outperforms six state-of-the-art models in predicting the missing data of an HiDS matrix, which evidently supports its strong representation learning ability to HiDS data.

</p>
</details>

<details><summary><b>UAMD-Net: A Unified Adaptive Multimodal Neural Network for Dense Depth Completion</b>
<a href="https://arxiv.org/abs/2204.07791">arxiv:2204.07791</a>
&#x1F4C8; 3 <br>
<p>Guancheng Chen, Junli Lin, Huabiao Qin</p></summary>
<p>

**Abstract:** Depth prediction is a critical problem in robotics applications especially autonomous driving. Generally, depth prediction based on binocular stereo matching and fusion of monocular image and laser point cloud are two mainstream methods. However, the former usually suffers from overfitting while building cost volume, and the latter has a limited generalization due to the lack of geometric constraint. To solve these problems, we propose a novel multimodal neural network, namely UAMD-Net, for dense depth completion based on fusion of binocular stereo matching and the weak constrain from the sparse point clouds. Specifically, the sparse point clouds are converted to sparse depth map and sent to the multimodal feature encoder (MFE) with binocular image, constructing a cross-modal cost volume. Then, it will be further processed by the multimodal feature aggregator (MFA) and the depth regression layer. Furthermore, the existing multimodal methods ignore the problem of modal dependence, that is, the network will not work when a certain modal input has a problem. Therefore, we propose a new training strategy called Modal-dropout which enables the network to be adaptively trained with multiple modal inputs and inference with specific modal inputs. Benefiting from the flexible network structure and adaptive training method, our proposed network can realize unified training under various modal input conditions. Comprehensive experiments conducted on KITTI depth completion benchmark demonstrate that our method produces robust results and outperforms other state-of-the-art methods.

</p>
</details>

<details><summary><b>Approaching sales forecasting using recurrent neural networks and transformers</b>
<a href="https://arxiv.org/abs/2204.07786">arxiv:2204.07786</a>
&#x1F4C8; 3 <br>
<p>Iván Vallés-Pérez, Emilio Soria-Olivas, Marcelino Martínez-Sober, Antonio J. Serrano-López, Juan Gómez-Sanchís, Fernando Mateo</p></summary>
<p>

**Abstract:** Accurate and fast demand forecast is one of the hot topics in supply chain for enabling the precise execution of the corresponding downstream processes (inbound and outbound planning, inventory placement, network planning, etc). We develop three alternatives to tackle the problem of forecasting the customer sales at day/store/item level using deep learning techniques and the Corporación Favorita data set, published as part of a Kaggle competition. Our empirical results show how good performance can be achieved by using a simple sequence to sequence architecture with minimal data preprocessing effort. Additionally, we describe a training trick for making the model more time independent and hence improving generalization over time. The proposed solution achieves a RMSLE of around 0.54, which is competitive with other more specific solutions to the problem proposed in the Kaggle competition.

</p>
</details>

<details><summary><b>UFRC: A Unified Framework for Reliable COVID-19 Detection on Crowdsourced Cough Audio</b>
<a href="https://arxiv.org/abs/2204.07763">arxiv:2204.07763</a>
&#x1F4C8; 3 <br>
<p>Jiangeng Chang, Yucheng Ruan, Cui Shaoze, John Soong Tshon Yit, Mengling Feng</p></summary>
<p>

**Abstract:** We suggested a unified system with core components of data augmentation, ImageNet-pretrained ResNet-50, cost-sensitive loss, deep ensemble learning, and uncertainty estimation to quickly and consistently detect COVID-19 using acoustic evidence. To increase the model's capacity to identify a minority class, data augmentation and cost-sensitive loss are incorporated (infected samples). In the COVID-19 detection challenge, ImageNet-pretrained ResNet-50 has been found to be effective. The unified framework also integrates deep ensemble learning and uncertainty estimation to integrate predictions from various base classifiers for generalisation and reliability. We ran a series of tests using the DiCOVA2021 challenge dataset to assess the efficacy of our proposed method, and the results show that our method has an AUC-ROC of 85.43 percent, making it a promising method for COVID-19 detection. The unified framework also demonstrates that audio may be used to quickly diagnose different respiratory disorders.

</p>
</details>

<details><summary><b>Homomorphic Encryption and Federated Learning based Privacy-Preserving CNN Training: COVID-19 Detection Use-Case</b>
<a href="https://arxiv.org/abs/2204.07752">arxiv:2204.07752</a>
&#x1F4C8; 3 <br>
<p>Febrianti Wibawa, Ferhat Ozgur Catak, Salih Sarp, Murat Kuzlu, Umit Cali</p></summary>
<p>

**Abstract:** Medical data is often highly sensitive in terms of data privacy and security concerns. Federated learning, one type of machine learning techniques, has been started to use for the improvement of the privacy and security of medical data. In the federated learning, the training data is distributed across multiple machines, and the learning process is performed in a collaborative manner. There are several privacy attacks on deep learning (DL) models to get the sensitive information by attackers. Therefore, the DL model itself should be protected from the adversarial attack, especially for applications using medical data. One of the solutions for this problem is homomorphic encryption-based model protection from the adversary collaborator. This paper proposes a privacy-preserving federated learning algorithm for medical data using homomorphic encryption. The proposed algorithm uses a secure multi-party computation protocol to protect the deep learning model from the adversaries. In this study, the proposed algorithm using a real-world medical dataset is evaluated in terms of the model performance.

</p>
</details>

<details><summary><b>A Variational Approach to Bayesian Phylogenetic Inference</b>
<a href="https://arxiv.org/abs/2204.07747">arxiv:2204.07747</a>
&#x1F4C8; 3 <br>
<p>Cheng Zhang, Frederick A. Matsen IV</p></summary>
<p>

**Abstract:** Bayesian phylogenetic inference is currently done via Markov chain Monte Carlo (MCMC) with simple proposal mechanisms. This hinders exploration efficiency and often requires long runs to deliver accurate posterior estimates. In this paper, we present an alternative approach: a variational framework for Bayesian phylogenetic analysis. We propose combining subsplit Bayesian networks, an expressive graphical model for tree topology distributions, and a structured amortization of the branch lengths over tree topologies for a suitable variational family of distributions. We train the variational approximation via stochastic gradient ascent and adopt gradient estimators for continuous and discrete variational parameters separately to deal with the composite latent space of phylogenetic models. We show that our variational approach provides competitive performance to MCMC, while requiring much less computation due to a more efficient exploration mechanism enabled by variational inference. Experiments on a benchmark of challenging real data Bayesian phylogenetic inference problems demonstrate the effectiveness and efficiency of our methods.

</p>
</details>

<details><summary><b>GitNet: Geometric Prior-based Transformation for Birds-Eye-View Segmentation</b>
<a href="https://arxiv.org/abs/2204.07733">arxiv:2204.07733</a>
&#x1F4C8; 3 <br>
<p>Shi Gong, Xiaoqing Ye, Xiao Tan, Jingdong Wang, Errui Ding, Yu Zhou, Xiang Bai</p></summary>
<p>

**Abstract:** Birds-eye-view (BEV) semantic segmentation is critical for autonomous driving for its powerful spatial representation ability. It is challenging to estimate the BEV semantic maps from monocular images due to the spatial gap, since it is implicitly required to realize both the perspective-to-BEV transformation and segmentation. We present a novel two-stage Geometry Prior-based Transformation framework named GitNet, consisting of (i) the geometry-guided pre-alignment and (ii) ray-based transformer. In the first stage, we decouple the BEV segmentation into the perspective image segmentation and geometric prior-based mapping, with explicit supervision by projecting the BEV semantic labels onto the image plane to learn visibility-aware features and learnable geometry to translate into BEV space. Second, the pre-aligned coarse BEV features are further deformed by ray-based transformers to take visibility knowledge into account. GitNet achieves the leading performance on the challenging nuScenes and Argoverse Datasets. The code will be publicly available.

</p>
</details>

<details><summary><b>Searching Intrinsic Dimensions of Vision Transformers</b>
<a href="https://arxiv.org/abs/2204.07722">arxiv:2204.07722</a>
&#x1F4C8; 3 <br>
<p>Fanghui Xue, Biao Yang, Yingyong Qi, Jack Xin</p></summary>
<p>

**Abstract:** It has been shown by many researchers that transformers perform as well as convolutional neural networks in many computer vision tasks. Meanwhile, the large computational costs of its attention module hinder further studies and applications on edge devices. Some pruning methods have been developed to construct efficient vision transformers, but most of them have considered image classification tasks only. Inspired by these results, we propose SiDT, a method for pruning vision transformer backbones on more complicated vision tasks like object detection, based on the search of transformer dimensions. Experiments on CIFAR-100 and COCO datasets show that the backbones with 20\% or 40\% dimensions/parameters pruned can have similar or even better performance than the unpruned models. Moreover, we have also provided the complexity analysis and comparisons with the previous pruning methods.

</p>
</details>

<details><summary><b>TVShowGuess: Character Comprehension in Stories as Speaker Guessing</b>
<a href="https://arxiv.org/abs/2204.07721">arxiv:2204.07721</a>
&#x1F4C8; 3 <br>
<p>Yisi Sang, Xiangyang Mou, Mo Yu, Shunyu Yao, Jing Li, Jeffrey Stanton</p></summary>
<p>

**Abstract:** We propose a new task for assessing machines' skills of understanding fictional characters in narrative stories. The task, TVShowGuess, builds on the scripts of TV series and takes the form of guessing the anonymous main characters based on the backgrounds of the scenes and the dialogues. Our human study supports that this form of task covers comprehension of multiple types of character persona, including understanding characters' personalities, facts and memories of personal experience, which are well aligned with the psychological and literary theories about the theory of mind (ToM) of human beings on understanding fictional characters during reading. We further propose new model architectures to support the contextualized encoding of long scene texts. Experiments show that our proposed approaches significantly outperform baselines, yet still largely lag behind the (nearly perfect) human performance. Our work serves as a first step toward the goal of narrative character comprehension.

</p>
</details>

<details><summary><b>Stress-Testing LiDAR Registration</b>
<a href="https://arxiv.org/abs/2204.07719">arxiv:2204.07719</a>
&#x1F4C8; 3 <br>
<p>Amnon Drory, Shai Avidan, Raja Giryes</p></summary>
<p>

**Abstract:** Point cloud registration (PCR) is an important task in many fields including autonomous driving with LiDAR sensors. PCR algorithms have improved significantly in recent years, by combining deep-learned features with robust estimation methods. These algorithms succeed in scenarios such as indoor scenes and object models registration. However, testing in the automotive LiDAR setting, which presents its own challenges, has been limited. The standard benchmark for this setting, KITTI-10m, has essentially been saturated by recent algorithms: many of them achieve near-perfect recall.
  In this work, we stress-test recent PCR techniques with LiDAR data. We propose a method for selecting balanced registration sets, which are challenging sets of frame-pairs from LiDAR datasets. They contain a balanced representation of the different relative motions that appear in a dataset, i.e. small and large rotations, small and large offsets in space and time, and various combinations of these.
  We perform a thorough comparison of accuracy and run-time on these benchmarks. Perhaps unexpectedly, we find that the fastest and simultaneously most accurate approach is a version of advanced RANSAC. We further improve results with a novel pre-filtering method.

</p>
</details>

<details><summary><b>WordAlchemy: A transformer-based Reverse Dictionary</b>
<a href="https://arxiv.org/abs/2204.10181">arxiv:2204.10181</a>
&#x1F4C8; 2 <br>
<p>Dr. Sunil B. Mane, Harshal Patil, Kanhaiya Madaswar, Pranav Sadavarte</p></summary>
<p>

**Abstract:** A reverse dictionary takes a target word's description as input and returns the words that fit the description. Reverse Dictionaries are useful for new language learners, anomia patients, and for solving common tip-of-the-tongue problems (lethologica). Currently, there does not exist any Reverse Dictionary provider with support for any Indian Language. We present a novel open-source cross-lingual reverse dictionary system with support for Indian languages. In this paper, we propose a transformer-based deep learning approach to tackle the limitations faced by the existing systems using the mT5 model. This architecture uses the Translation Language Modeling (TLM) technique, rather than the conventional BERT's Masked Language Modeling (MLM) technique.

</p>
</details>

<details><summary><b>Polynomial-time sparse measure recovery</b>
<a href="https://arxiv.org/abs/2204.07879">arxiv:2204.07879</a>
&#x1F4C8; 2 <br>
<p>Hadi Daneshmand, Francis Bach</p></summary>
<p>

**Abstract:** How to recover a probability measure with sparse support from particular moments? This problem has been the focus of research in theoretical computer science and neural computing. However, there is no polynomial-time algorithm for the recovery. The best algorithm for the recovery requires $O(2^{\text{poly}(1/ε)})$ for $ε$-accurate recovery. We propose the first poly-time recovery method from carefully designed moments that only requires $O(\log(1/ε)/ε^2)$ computations for an $ε$-accurate recovery. This method relies on the recovery of a planted two-layer neural network with two-dimensional inputs, a finite width, and zero-one activation. For such networks, we establish the first global convergence of gradient descent and demonstrate its application in sparse measure recovery.

</p>
</details>

<details><summary><b>Assessing Differentially Private Variational Autoencoders under Membership Inference</b>
<a href="https://arxiv.org/abs/2204.07877">arxiv:2204.07877</a>
&#x1F4C8; 2 <br>
<p>Daniel Bernau, Jonas Robl, Florian Kerschbaum</p></summary>
<p>

**Abstract:** We present an approach to quantify and compare the privacy-accuracy trade-off for differentially private Variational Autoencoders. Our work complements previous work in two aspects. First, we evaluate the the strong reconstruction MI attack against Variational Autoencoders under differential privacy. Second, we address the data scientist's challenge of setting privacy parameter epsilon, which steers the differential privacy strength and thus also the privacy-accuracy trade-off. In our experimental study we consider image and time series data, and three local and central differential privacy mechanisms. We find that the privacy-accuracy trade-offs strongly depend on the dataset and model architecture. We do rarely observe favorable privacy-accuracy trade-off for Variational Autoencoders, and identify a case where LDP outperforms CDP.

</p>
</details>

<details><summary><b>GHM Wavelet Transform for Deep Image Super Resolution</b>
<a href="https://arxiv.org/abs/2204.07862">arxiv:2204.07862</a>
&#x1F4C8; 2 <br>
<p>Ben Lowe, Hadi Salman, Justin Zhan</p></summary>
<p>

**Abstract:** The GHM multi-level discrete wavelet transform is proposed as preprocessing for image super resolution with convolutional neural networks. Previous works perform analysis with the Haar wavelet only. In this work, 37 single-level wavelets are experimentally analyzed from Haar, Daubechies, Biorthogonal, Reverse Biorthogonal, Coiflets, and Symlets wavelet families. All single-level wavelets report similar results indicating that the convolutional neural network is invariant to choice of wavelet in a single-level filter approach. However, the GHM multi-level wavelet achieves higher quality reconstructions than the single-level wavelets. Three large data sets are used for the experiments: DIV2K, a dataset of textures, and a dataset of satellite images. The approximate high resolution images are compared using seven objective error measurements. A convolutional neural network based approach using wavelet transformed images has good results in the literature.

</p>
</details>

<details><summary><b>Multi-organ Segmentation Network with Adversarial Performance Validator</b>
<a href="https://arxiv.org/abs/2204.07850">arxiv:2204.07850</a>
&#x1F4C8; 2 <br>
<p>Haoyu Fang, Yi Fang, Xiaofeng Yang</p></summary>
<p>

**Abstract:** CT organ segmentation on computed tomography (CT) images becomes a significant brick for modern medical image analysis, supporting clinic workflows in multiple domains. Previous segmentation methods include 2D convolution neural networks (CNN) based approaches, fed by CT image slices that lack the structural knowledge in axial view, and 3D CNN-based methods with the expensive computation cost in multi-organ segmentation applications. This paper introduces an adversarial performance validation network into a 2D-to-3D segmentation framework. The classifier and performance validator competition contribute to accurate segmentation results via back-propagation. The proposed network organically converts the 2D-coarse result to 3D high-quality segmentation masks in a coarse-to-fine manner, allowing joint optimization to improve segmentation accuracy. Besides, the structural information of one specific organ is depicted by a statistics-meaningful prior bounding box, which is transformed into a global feature leveraging the learning process in 3D fine segmentation. The experiments on the NIH pancreas segmentation dataset demonstrate the proposed network achieves state-of-the-art accuracy on small organ segmentation and outperforms the previous best. High accuracy is also reported on multi-organ segmentation in a dataset collected by ourselves.

</p>
</details>

<details><summary><b>What If: Generating Code to Answer Simulation Questions</b>
<a href="https://arxiv.org/abs/2204.07835">arxiv:2204.07835</a>
&#x1F4C8; 2 <br>
<p>Gal Peretz, Kira Radinsky</p></summary>
<p>

**Abstract:** Many texts, especially in chemistry and biology, describe complex processes. We focus on texts that describe a chemical reaction process and questions that ask about the process's outcome under different environmental conditions. To answer questions about such processes, one needs to understand the interactions between the different entities involved in the process and to simulate their state transitions during the process execution under different conditions. A state transition is defined as the memory modification the program does to the variables during the execution. We hypothesize that generating code and executing it to simulate the process will allow answering such questions. We, therefore, define a domain-specific language (DSL) to represent processes. We contribute to the community a unique dataset curated by chemists and annotated by computer scientists. The dataset is composed of process texts, simulation questions, and their corresponding computer codes represented by the DSL.We propose a neural program synthesis approach based on reinforcement learning with a novel state-transition semantic reward. The novel reward is based on the run-time semantic similarity between the predicted code and the reference code. This allows simulating complex process transitions and thus answering simulation questions. Our approach yields a significant boost in accuracy for simulation questions: 88\% accuracy as opposed to 83\% accuracy of the state-of-the-art neural program synthesis approaches and 54\% accuracy of state-of-the-art end-to-end text-based approaches.

</p>
</details>

<details><summary><b>Beyond L1: Faster and Better Sparse Models with skglm</b>
<a href="https://arxiv.org/abs/2204.07826">arxiv:2204.07826</a>
&#x1F4C8; 2 <br>
<p>Quentin Bertrand, Quentin Klopfenstein, Pierre-Antoine Bannier, Gauthier Gidel, Mathurin Massias</p></summary>
<p>

**Abstract:** We propose a new fast algorithm to estimate any sparse generalized linear model with convex or non-convex separable penalties. Our algorithm is able to solve problems with millions of samples and features in seconds, by relying on coordinate descent, working sets and Anderson acceleration. It handles previously unaddressed models, and is extensively shown to improve state-of-art algorithms. We provide a flexible, scikit-learn compatible package, which easily handles customized datafits and penalties.

</p>
</details>

<details><summary><b>Few-Shot Transfer Learning to improve Chest X-Ray pathology detection using limited triplets</b>
<a href="https://arxiv.org/abs/2204.07824">arxiv:2204.07824</a>
&#x1F4C8; 2 <br>
<p>Ananth Reddy Bhimireddy, John Lee Burns, Saptarshi Purkayastha, Judy Wawira Gichoya</p></summary>
<p>

**Abstract:** Deep learning approaches applied to medical imaging have reached near-human or better-than-human performance on many diagnostic tasks. For instance, the CheXpert competition on detecting pathologies in chest x-rays has shown excellent multi-class classification performance. However, training and validating deep learning models require extensive collections of images and still produce false inferences, as identified by a human-in-the-loop. In this paper, we introduce a practical approach to improve the predictions of a pre-trained model through Few-Shot Learning (FSL). After training and validating a model, a small number of false inference images are collected to retrain the model using \textbf{\textit{Image Triplets}} - a false positive or false negative, a true positive, and a true negative. The retrained FSL model produces considerable gains in performance with only a few epochs and few images. In addition, FSL opens rapid retraining opportunities for human-in-the-loop systems, where a radiologist can relabel false inferences, and the model can be quickly retrained. We compare our retrained model performance with existing FSL approaches in medical imaging that train and evaluate models at once.

</p>
</details>

<details><summary><b>Exploiting Multiple EEG Data Domains with Adversarial Learning</b>
<a href="https://arxiv.org/abs/2204.07777">arxiv:2204.07777</a>
&#x1F4C8; 2 <br>
<p>David Bethge, Philipp Hallgarten, Ozan Özdenizci, Ralf Mikut, Albrecht Schmidt, Tobias Grosse-Puppendahl</p></summary>
<p>

**Abstract:** Electroencephalography (EEG) is shown to be a valuable data source for evaluating subjects' mental states. However, the interpretation of multi-modal EEG signals is challenging, as they suffer from poor signal-to-noise-ratio, are highly subject-dependent, and are bound to the equipment and experimental setup used, (i.e. domain). This leads to machine learning models often suffer from poor generalization ability, where they perform significantly worse on real-world data than on the exploited training data. Recent research heavily focuses on cross-subject and cross-session transfer learning frameworks to reduce domain calibration efforts for EEG signals. We argue that multi-source learning via learning domain-invariant representations from multiple data-sources is a viable alternative, as the available data from different EEG data-source domains (e.g., subjects, sessions, experimental setups) grow massively. We propose an adversarial inference approach to learn data-source invariant representations in this context, enabling multi-source learning for EEG-based brain-computer interfaces. We unify EEG recordings from different source domains (i.e., emotion recognition datasets SEED, SEED-IV, DEAP, DREAMER), and demonstrate the feasibility of our invariant representation learning approach in suppressing data-source-relevant information leakage by 35% while still achieving stable EEG-based emotion classification performance.

</p>
</details>

<details><summary><b>SETTI: A Self-supervised Adversarial Malware Detection Architecture in an IoT Environment</b>
<a href="https://arxiv.org/abs/2204.07772">arxiv:2204.07772</a>
&#x1F4C8; 2 <br>
<p>Marjan Golmaryami, Rahim Taheri, Zahra Pooranian, Mohammad Shojafar, Pei Xiao</p></summary>
<p>

**Abstract:** In recent years, malware detection has become an active research topic in the area of Internet of Things (IoT) security. The principle is to exploit knowledge from large quantities of continuously generated malware. Existing algorithms practice available malware features for IoT devices and lack real-time prediction behaviors. More research is thus required on malware detection to cope with real-time misclassification of the input IoT data. Motivated by this, in this paper we propose an adversarial self-supervised architecture for detecting malware in IoT networks, SETTI, considering samples of IoT network traffic that may not be labeled. In the SETTI architecture, we design three self-supervised attack techniques, namely Self-MDS, GSelf-MDS and ASelf-MDS. The Self-MDS method considers the IoT input data and the adversarial sample generation in real-time. The GSelf-MDS builds a generative adversarial network model to generate adversarial samples in the self-supervised structure. Finally, ASelf-MDS utilizes three well-known perturbation sample techniques to develop adversarial malware and inject it over the self-supervised architecture. Also, we apply a defence method to mitigate these attacks, namely adversarial self-supervised training to protect the malware detection architecture against injecting the malicious samples. To validate the attack and defence algorithms, we conduct experiments on two recent IoT datasets: IoT23 and NBIoT. Comparison of the results shows that in the IoT23 dataset, the Self-MDS method has the most damaging consequences from the attacker's point of view by reducing the accuracy rate from 98% to 74%. In the NBIoT dataset, the ASelf-MDS method is the most devastating algorithm that can plunge the accuracy rate from 98% to 77%.

</p>
</details>

<details><summary><b>UniGDD: A Unified Generative Framework for Goal-Oriented Document-Grounded Dialogue</b>
<a href="https://arxiv.org/abs/2204.07770">arxiv:2204.07770</a>
&#x1F4C8; 2 <br>
<p>Chang Gao, Wenxuan Zhang, Wai Lam</p></summary>
<p>

**Abstract:** The goal-oriented document-grounded dialogue aims at responding to the user query based on the dialogue context and supporting document. Existing studies tackle this problem by decomposing it into two sub-tasks: knowledge identification and response generation. However, such pipeline methods would unavoidably suffer from the error propagation issue. This paper proposes to unify these two sub-tasks via sequentially generating the grounding knowledge and the response. We further develop a prompt-connected multi-task learning strategy to model the characteristics and connections of different tasks and introduce linear temperature scheduling to reduce the negative effect of irrelevant document information. Experimental results demonstrate the effectiveness of our framework.

</p>
</details>

<details><summary><b>Tensor-networks for High-order Polynomial Approximation: A Many-body Physics Perspective</b>
<a href="https://arxiv.org/abs/2204.07743">arxiv:2204.07743</a>
&#x1F4C8; 2 <br>
<p>Tong Yang</p></summary>
<p>

**Abstract:** We analyze the problem of high-order polynomial approximation from a many-body physics perspective, and demonstrate the descriptive power of entanglement entropy in capturing model capacity and task complexity. Instantiated with a high-order nonlinear dynamics modeling problem, tensor-network models are investigated and exhibit promising modeling advantages. This novel perspective establish a connection between quantum information and functional approximation, which worth further exploration in future research.

</p>
</details>

<details><summary><b>DRFLM: Distributionally Robust Federated Learning with Inter-client Noise via Local Mixup</b>
<a href="https://arxiv.org/abs/2204.07742">arxiv:2204.07742</a>
&#x1F4C8; 2 <br>
<p>Bingzhe Wu, Zhipeng Liang, Yuxuan Han, Yatao Bian, Peilin Zhao, Junzhou Huang</p></summary>
<p>

**Abstract:** Recently, federated learning has emerged as a promising approach for training a global model using data from multiple organizations without leaking their raw data. Nevertheless, directly applying federated learning to real-world tasks faces two challenges: (1) heterogeneity in the data among different organizations; and (2) data noises inside individual organizations.
  In this paper, we propose a general framework to solve the above two challenges simultaneously. Specifically, we propose using distributionally robust optimization to mitigate the negative effects caused by data heterogeneity paradigm to sample clients based on a learnable distribution at each iteration. Additionally, we observe that this optimization paradigm is easily affected by data noises inside local clients, which has a significant performance degradation in terms of global model prediction accuracy. To solve this problem, we propose to incorporate mixup techniques into the local training process of federated learning. We further provide comprehensive theoretical analysis including robustness analysis, convergence analysis, and generalization ability. Furthermore, we conduct empirical studies across different drug discovery tasks, such as ADMET property prediction and drug-target affinity prediction.

</p>
</details>

<details><summary><b>The Tree Loss: Improving Generalization with Many Classes</b>
<a href="https://arxiv.org/abs/2204.07727">arxiv:2204.07727</a>
&#x1F4C8; 2 <br>
<p>Yujie Wang, Mike Izbicki</p></summary>
<p>

**Abstract:** Multi-class classification problems often have many semantically similar classes. For example, 90 of ImageNet's 1000 classes are for different breeds of dog. We should expect that these semantically similar classes will have similar parameter vectors, but the standard cross entropy loss does not enforce this constraint.
  We introduce the tree loss as a drop-in replacement for the cross entropy loss. The tree loss re-parameterizes the parameter matrix in order to guarantee that semantically similar classes will have similar parameter vectors. Using simple properties of stochastic gradient descent, we show that the tree loss's generalization error is asymptotically better than the cross entropy loss's. We then validate these theoretical results on synthetic data, image data (CIFAR100, ImageNet), and text data (Twitter).

</p>
</details>

<details><summary><b>Probing Script Knowledge from Pre-Trained Models</b>
<a href="https://arxiv.org/abs/2204.10176">arxiv:2204.10176</a>
&#x1F4C8; 1 <br>
<p>Zijian Jin, Xingyu Zhang, Mo Yu, Lifu Huang</p></summary>
<p>

**Abstract:** Script knowledge is critical for humans to understand the broad daily tasks and routine activities in the world. Recently researchers have explored the large-scale pre-trained language models (PLMs) to perform various script related tasks, such as story generation, temporal ordering of event, future event prediction and so on. However, it's still not well studied in terms of how well the PLMs capture the script knowledge. To answer this question, we design three probing tasks: inclusive sub-event selection, starting sub-event selection and temporal ordering to investigate the capabilities of PLMs with and without fine-tuning. The three probing tasks can be further used to automatically induce a script for each main event given all the possible sub-events. Taking BERT as a case study, by analyzing its performance on script induction as well as each individual probing task, we conclude that the stereotypical temporal knowledge among the sub-events is well captured in BERT, however the inclusive or starting sub-event knowledge is barely encoded.

</p>
</details>

<details><summary><b>Ergo, SMIRK is Safe: A Safety Case for a Machine Learning Component in a Pedestrian Automatic Emergency Brake System</b>
<a href="https://arxiv.org/abs/2204.07874">arxiv:2204.07874</a>
&#x1F4C8; 1 <br>
<p>Markus Borg, Jens Henriksson, Kasper Socha, Olof Lennartsson, Elias Sonnsjö Lönegren, Thanh Bui, Piotr Tomaszewski, Sankar Raman Sathyamoorthy, Sebastian Brink, Mahshid Helali Moghadam</p></summary>
<p>

**Abstract:** Integration of Machine Learning (ML) components in critical applications introduces novel challenges for software certification and verification. New safety standards and technical guidelines are under development to support the safety of ML-based systems, e.g., ISO 21448 SOTIF for the automotive domain and the Assurance of Machine Learning for use in Autonomous Systems (AMLAS) framework. SOTIF and AMLAS provide high-level guidance but the details must be chiseled out for each specific case. We report results from an industry-academia collaboration on safety assurance of SMIRK, an ML-based pedestrian automatic emergency braking demonstrator running in an industry-grade simulator. We present the outcome of applying AMLAS on SMIRK for a minimalistic operational design domain, i.e., a complete safety case for its integrated ML-based component. Finally, we report lessons learned and provide both SMIRK and the safety case under an open-source licence for the research community to reuse.

</p>
</details>

<details><summary><b>Alternating Channel Estimation and Prediction for Cell-Free mMIMO with Channel Aging: A Deep Learning Based Scheme</b>
<a href="https://arxiv.org/abs/2204.07868">arxiv:2204.07868</a>
&#x1F4C8; 1 <br>
<p>Mohanad Obeed, Yasser Al-Eryani, Anas Chaaban</p></summary>
<p>

**Abstract:** In large scale dynamic wireless networks, the amount of overhead caused by channel estimation (CE) is becoming one of the main performance bottlenecks. This is due to the large number users whose channels should be estimated, the user mobility, and the rapid channel change caused by the usage of the high-frequency spectrum (e.g. millimeter wave). In this work, we propose a new hybrid channel estimation/prediction (CEP) scheme to reduce overhead in time-division duplex (TDD) wireless cell-free massive multiple-input-multiple-output (mMIMO) systems. The scheme proposes sending a pilot signal from each user only once in a given number (window) of coherence intervals (CIs). Then minimum mean-square error (MMSE) estimation is used to estimate the channel of this CI, while a deep neural network (DNN) is used to predict the channels of the remaining CIs in the window. The DNN exploits the temporal correlation between the consecutive CIs and the received pilot signals to improve the channel prediction accuracy. By doing so, CE overhead is reduced by at least 50 percent at the expense of negligible CE error for practical user mobility settings. Consequently, the proposed CEP scheme improves the spectral efficiency compared to the conventional MMSE CE approach, especially when the number of users is large, which is demonstrated numerically.

</p>
</details>

<details><summary><b>IIFNet: A Fusion based Intelligent Service for Noisy Preamble Detection in 6G</b>
<a href="https://arxiv.org/abs/2204.07854">arxiv:2204.07854</a>
&#x1F4C8; 1 <br>
<p>Sunder Ali Khowaja, Kapal Dev, Parus Khuwaja, Quoc-Viet Pham, Nawab Muhammad Faseeh Qureshi, Paolo Bellavista, Maurizio Magarini</p></summary>
<p>

**Abstract:** In this article, we present our vision of preamble detection in a physical random access channel for next-generation (Next-G) networks using machine learning techniques. Preamble detection is performed to maintain communication and synchronization between devices of the Internet of Everything (IoE) and next-generation nodes. Considering the scalability and traffic density, Next-G networks have to deal with preambles corrupted by noise due to channel characteristics or environmental constraints. We show that when injecting 15% random noise, the detection performance degrades to 48%. We propose an informative instance-based fusion network (IIFNet) to cope with random noise and to improve detection performance, simultaneously. A novel sampling strategy for selecting informative instances from feature spaces has also been explored to improve detection performance. The proposed IIFNet is tested on a real dataset for preamble detection that was collected with the help of a reputable company (AZCOM Technology).

</p>
</details>

<details><summary><b>Optimizing differential equations to fit data and predict outcomes</b>
<a href="https://arxiv.org/abs/2204.07833">arxiv:2204.07833</a>
&#x1F4C8; 1 <br>
<p>Steven A. Frank</p></summary>
<p>

**Abstract:** Many scientific problems focus on observed patterns of change or on how to design a system to achieve particular dynamics. Those problems often require fitting differential equation models to target trajectories. Fitting such models can be difficult because each evaluation of the fit must calculate the distance between the model and target patterns at numerous points along a trajectory. The gradient of the fit with respect to the model parameters can be challenging. Recent technical advances in automatic differentiation through numerical differential equation solvers potentially change the fitting process into a relatively easy problem, opening up new possibilities to study dynamics. However, application of the new tools to real data may fail to achieve a good fit. This article illustrates how to overcome a variety of common challenges, using the classic ecological data for oscillations in hare and lynx populations. Models include simple ordinary differential equations (ODEs) and neural ordinary differential equations (NODEs), which use artificial neural networks to estimate the derivatives of differential equation systems. Comparing the fits obtained with ODEs versus NODEs, representing small and large parameter spaces, and changing the number of variable dimensions provide insight into the geometry of the observed and model trajectories. To analyze the quality of the models for predicting future observations, a Bayesian-inspired preconditioned stochastic gradient Langevin dynamics (pSGLD) calculation of the posterior distribution of predicted model trajectories clarifies the tendency for various models to underfit or overfit the data. Coupling fitted differential equation systems with pSGLD sampling provides a powerful way to study the properties of optimization surfaces, raising an analogy with mutation-selection dynamics on fitness landscapes.

</p>
</details>

<details><summary><b>TASTEset -- Recipe Dataset and Food Entities Recognition Benchmark</b>
<a href="https://arxiv.org/abs/2204.07775">arxiv:2204.07775</a>
&#x1F4C8; 1 <br>
<p>Ania Wróblewska, Agnieszka Kaliska, Maciej Pawłowski, Dawid Wiśniewski, Witold Sosnowski, Agnieszka Ławrynowicz</p></summary>
<p>

**Abstract:** Food Computing is currently a fast-growing field of research. Natural language processing (NLP) is also increasingly essential in this field, especially for recognising food entities. However, there are still only a few well-defined tasks that serve as benchmarks for solutions in this area. We introduce a new dataset -- called \textit{TASTEset} -- to bridge this gap. In this dataset, Named Entity Recognition (NER) models are expected to find or infer various types of entities helpful in processing recipes, e.g.~food products, quantities and their units, names of cooking processes, physical quality of ingredients, their purpose, taste.
  The dataset consists of 700 recipes with more than 13,000 entities to extract. We provide a few state-of-the-art baselines of named entity recognition models, which show that our dataset poses a solid challenge to existing models. The best model achieved, on average, 0.95 $F_1$ score, depending on the entity type -- from 0.781 to 0.982. We share the dataset and the task to encourage progress on more in-depth and complex information extraction from recipes.

</p>
</details>

<details><summary><b>Cannikin's Law in Tensor Modeling: A Rank Study for Entanglement and Separability in Tensor Complexity and Model Capacity</b>
<a href="https://arxiv.org/abs/2204.07760">arxiv:2204.07760</a>
&#x1F4C8; 1 <br>
<p>Tong Yang</p></summary>
<p>

**Abstract:** This study clarifies the proper criteria to assess the modeling capacity of a general tensor model. The work analyze the problem based on the study of tensor ranks, which is not a well-defined quantity for higher order tensors. To process, the author introduces the separability issue to discuss the Cannikin's law of tensor modeling. Interestingly, a connection between entanglement studied in information theory and tensor analysis is established, shedding new light on the theoretical understanding for modeling capacity problems.

</p>
</details>

<details><summary><b>A Hierarchical Terminal Recognition Approach based on Network Traffic Analysis</b>
<a href="https://arxiv.org/abs/2204.07726">arxiv:2204.07726</a>
&#x1F4C8; 1 <br>
<p>Lingzi Kong, Daoqi Han, Junmei Ding, Mingrui Fan, Yueming Lu</p></summary>
<p>

**Abstract:** Recognizing the type of connected devices to a network helps to perform security policies. In smart grids, identifying massive number of grid metering terminals based on network traffic analysis is almost blank and existing research has not proposed a targeted end-to-end model to solve the flow classification problem. Therefore, we proposed a hierarchical terminal recognition approach that applies the details of grid data. We have formed a two-level model structure by segmenting the grid data, which uses the statistical characteristics of network traffic and the specific behavior characteristics of grid metering terminals. Moreover, through the selection and reconstruction of features, we combine three algorithms to achieve accurate identification of terminal types that transmit network traffic. We conduct extensive experiments on a real dataset containing three types of grid metering terminals, and the results show that our research has improved performance compared to common recognition models. The combination of an autoencoder, K-Means and GradientBoost algorithm achieved the best recognition rate with F1 value of 98.3%.

</p>
</details>

<details><summary><b>A Hierarchical N-Gram Framework for Zero-Shot Link Prediction</b>
<a href="https://arxiv.org/abs/2204.10293">arxiv:2204.10293</a>
&#x1F4C8; 0 <br>
<p>Mingchen Li, Junfan Chen, Samuel Mensah, Nikolaos Aletras, Xiulong Yang, Yang Ye</p></summary>
<p>

**Abstract:** Due to the incompleteness of knowledge graphs (KGs), zero-shot link prediction (ZSLP) which aims to predict unobserved relations in KGs has attracted recent interest from researchers. A common solution is to use textual features of relations (e.g., surface name or textual descriptions) as auxiliary information to bridge the gap between seen and unseen relations. Current approaches learn an embedding for each word token in the text. These methods lack robustness as they suffer from the out-of-vocabulary (OOV) problem. Meanwhile, models built on character n-grams have the capability of generating expressive representations for OOV words. Thus, in this paper, we propose a Hierarchical N-Gram framework for Zero-Shot Link Prediction (HNZSLP), which considers the dependencies among character n-grams of the relation surface name for ZSLP. Our approach works by first constructing a hierarchical n-gram graph on the surface name to model the organizational structure of n-grams that leads to the surface name. A GramTransformer, based on the Transformer is then presented to model the hierarchical n-gram graph to construct the relation embedding for ZSLP. Experimental results show the proposed HNZSLP achieved state-of-the-art performance on two ZSLP datasets.

</p>
</details>

<details><summary><b>De-biasing facial detection system using VAE</b>
<a href="https://arxiv.org/abs/2204.09556">arxiv:2204.09556</a>
&#x1F4C8; 0 <br>
<p>Vedant V. Kandge, Siddhant V. Kandge, Kajal Kumbharkar, Prof. Tanuja Pattanshetti</p></summary>
<p>

**Abstract:** Bias in AI/ML-based systems is a ubiquitous problem and bias in AI/ML systems may negatively impact society. There are many reasons behind a system being biased. The bias can be due to the algorithm we are using for our problem or may be due to the dataset we are using, having some features over-represented in it. In the face detection system bias due to the dataset is majorly seen. Sometimes models learn only features that are over-represented in data and ignore rare features from data which results in being biased toward those over-represented features. In real life, these biased systems are dangerous to society. The proposed approach uses generative models which are best suited for learning underlying features(latent variables) from the dataset and by using these learned features models try to reduce the threats which are there due to bias in the system. With the help of an algorithm, the bias present in the dataset can be removed. And then we train models on two datasets and compare the results.

</p>
</details>


{% endraw %}
Prev: [2022.04.15]({{ '/2022/04/15/2022.04.15.html' | relative_url }})  Next: [2022.04.17]({{ '/2022/04/17/2022.04.17.html' | relative_url }})