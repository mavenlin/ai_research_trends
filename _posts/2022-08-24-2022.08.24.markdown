Prev: [2022.08.23]({{ '/2022/08/23/2022.08.23.html' | relative_url }})  Next: [2022.08.25]({{ '/2022/08/25/2022.08.25.html' | relative_url }})
{% raw %}
## Summary for 2022-08-24, created on 2022-08-28


<details><summary><b>How (and Why) to Think that the Brain is Literally a Computer</b>
<a href="https://arxiv.org/abs/2208.12032">arxiv:2208.12032</a>
&#x1F4C8; 77 <br>
<p>Corey J. Maley</p></summary>
<p>

**Abstract:** The relationship between brains and computers is often taken to be merely metaphorical. However, genuine computational systems can be implemented in virtually any media; thus, one can take seriously the view that brains literally compute. But without empirical criteria for what makes a physical system genuinely a computational one, computation remains a matter of perspective, especially for natural systems (e.g., brains) that were not explicitly designed and engineered to be computers. Considerations from real examples of physical computers-both analog and digital, contemporary and historical-make clear what those empirical criteria must be. Finally, applying those criteria to the brain shows how we can view the brain as a computer (probably an analog one at that), which, in turn, illuminates how that claim is both informative and falsifiable.

</p>
</details>

<details><summary><b>Automatic music mixing with deep learning and out-of-domain data</b>
<a href="https://arxiv.org/abs/2208.11428">arxiv:2208.11428</a>
&#x1F4C8; 43 <br>
<p>Marco A. Martínez-Ramírez, Wei-Hsiang Liao, Giorgio Fabbro, Stefan Uhlich, Chihiro Nagashima, Yuki Mitsufuji</p></summary>
<p>

**Abstract:** Music mixing traditionally involves recording instruments in the form of clean, individual tracks and blending them into a final mixture using audio effects and expert knowledge (e.g., a mixing engineer). The automation of music production tasks has become an emerging field in recent years, where rule-based methods and machine learning approaches have been explored. Nevertheless, the lack of dry or clean instrument recordings limits the performance of such models, which is still far from professional human-made mixes. We explore whether we can use out-of-domain data such as wet or processed multitrack music recordings and repurpose it to train supervised deep learning models that can bridge the current gap in automatic mixing quality. To achieve this we propose a novel data preprocessing method that allows the models to perform automatic music mixing. We also redesigned a listening test method for evaluating music mixing systems. We validate our results through such subjective tests using highly experienced mixing engineers as participants.

</p>
</details>

<details><summary><b>Efficient Heterogeneous Video Segmentation at the Edge</b>
<a href="https://arxiv.org/abs/2208.11666">arxiv:2208.11666</a>
&#x1F4C8; 19 <br>
<p>Jamie Menjay Lin, Siargey Pisarchyk, Juhyun Lee, David Tian, Tingbo Hou, Karthik Raveendran, Raman Sarokin, George Sung, Trent Tolley, Matthias Grundmann</p></summary>
<p>

**Abstract:** We introduce an efficient video segmentation system for resource-limited edge devices leveraging heterogeneous compute. Specifically, we design network models by searching across multiple dimensions of specifications for the neural architectures and operations on top of already light-weight backbones, targeting commercially available edge inference engines. We further analyze and optimize the heterogeneous data flows in our systems across the CPU, the GPU and the NPU. Our approach has empirically factored well into our real-time AR system, enabling remarkably higher accuracy with quadrupled effective resolutions, yet at much shorter end-to-end latency, much higher frame rate, and even lower power consumption on edge platforms.

</p>
</details>

<details><summary><b>Visual Subtitle Feature Enhanced Video Outline Generation</b>
<a href="https://arxiv.org/abs/2208.11307">arxiv:2208.11307</a>
&#x1F4C8; 10 <br>
<p>Qi Lv, Ziqiang Cao, Wenrui Xie, Derui Wang, Jingwen Wang, Zhiyong Hu, Tangkun Zhang, Yuan Ba, Yuanhang Li, Min Cao, Wenjie Li, Sujian Li, Guohong Fu</p></summary>
<p>

**Abstract:** With the tremendously increasing number of videos, there is a great demand for techniques that help people quickly navigate to the video segments they are interested in. However, current works on video understanding mainly focus on video content summarization, while little effort has been made to explore the structure of a video. Inspired by textual outline generation, we introduce a novel video understanding task, namely video outline generation (VOG). This task is defined to contain two sub-tasks: (1) first segmenting the video according to the content structure and then (2) generating a heading for each segment. To learn and evaluate VOG, we annotate a 10k+ dataset, called DuVOG. Specifically, we use OCR tools to recognize subtitles of videos. Then annotators are asked to divide subtitles into chapters and title each chapter. In videos, highlighted text tends to be the headline since it is more likely to attract attention. Therefore we propose a Visual Subtitle feature Enhanced video outline generation model (VSENet) which takes as input the textual subtitles together with their visual font sizes and positions. We consider the VOG task as a sequence tagging problem that extracts spans where the headings are located and then rewrites them to form the final outlines. Furthermore, based on the similarity between video outlines and textual outlines, we use a large number of articles with chapter headings to pretrain our model. Experiments on DuVOG show that our model largely outperforms other baseline methods, achieving 77.1 of F1-score for the video segmentation level and 85.0 of ROUGE-L_F0.5 for the headline generation level.

</p>
</details>

<details><summary><b>Adverse Childhood Experiences Identification from Clinical Notes with Ontologies and NLP</b>
<a href="https://arxiv.org/abs/2208.11466">arxiv:2208.11466</a>
&#x1F4C8; 9 <br>
<p>Jinge Wu, Rowena Smith, Honghan Wu</p></summary>
<p>

**Abstract:** Adverse Childhood Experiences (ACEs) are defined as a collection of highly stressful, and potentially traumatic, events or circumstances that occur throughout childhood and/or adolescence. They have been shown to be associated with increased risks of mental health diseases or other abnormal behaviours in later lives. However, the identification of ACEs from free-text Electronic Health Records (EHRs) with Natural Language Processing (NLP) is challenging because (a) there is no NLP ready ACE ontologies; (b) there are limited cases available for machine learning, necessitating the data annotation from clinical experts. We are currently developing a tool that would use NLP techniques to assist us in surfacing ACEs from clinical notes. This will enable us further research in identifying evidence of the relationship between ACEs and the subsequent developments of mental illness (e.g., addictions) in large-scale and longitudinal free-text EHRs, which has previously not been possible.

</p>
</details>

<details><summary><b>Bugs in the Data: How ImageNet Misrepresents Biodiversity</b>
<a href="https://arxiv.org/abs/2208.11695">arxiv:2208.11695</a>
&#x1F4C8; 7 <br>
<p>Alexandra Sasha Luccioni, David Rolnick</p></summary>
<p>

**Abstract:** ImageNet-1k is a dataset often used for benchmarking machine learning (ML) models and evaluating tasks such as image recognition and object detection. Wild animals make up 27% of ImageNet-1k but, unlike classes representing people and objects, these data have not been closely scrutinized. In the current paper, we analyze the 13,450 images from 269 classes that represent wild animals in the ImageNet-1k validation set, with the participation of expert ecologists. We find that many of the classes are ill-defined or overlapping, and that 12% of the images are incorrectly labeled, with some classes having >90% of images incorrect. We also find that both the wildlife-related labels and images included in ImageNet-1k present significant geographical and cultural biases, as well as ambiguities such as artificial animals, multiple species in the same image, or the presence of humans. Our findings highlight serious issues with the extensive use of this dataset for evaluating ML systems, the use of such algorithms in wildlife-related tasks, and more broadly the ways in which ML datasets are commonly created and curated.

</p>
</details>

<details><summary><b>On a Built-in Conflict between Deep Learning and Systematic Generalization</b>
<a href="https://arxiv.org/abs/2208.11633">arxiv:2208.11633</a>
&#x1F4C8; 7 <br>
<p>Yuanpeng Li</p></summary>
<p>

**Abstract:** In this paper, we hypothesize that internal function sharing is one of the reasons to weaken o.o.d. or systematic generalization in deep learning for classification tasks. Under equivalent prediction, a model partitions an input space into multiple parts separated by boundaries. The function sharing prefers to reuse boundaries, leading to fewer parts for new outputs, which conflicts with systematic generalization. We show such phenomena in standard deep learning models, such as fully connected, convolutional, residual networks, LSTMs, and (Vision) Transformers. We hope this study provides novel insights into systematic generalization and forms a basis for new research directions.

</p>
</details>

<details><summary><b>Tracking by weakly-supervised learning and graph optimization for whole-embryo C. elegans lineages</b>
<a href="https://arxiv.org/abs/2208.11467">arxiv:2208.11467</a>
&#x1F4C8; 7 <br>
<p>Peter Hirsch, Caroline Malin-Mayor, Anthony Santella, Stephan Preibisch, Dagmar Kainmueller, Jan Funke</p></summary>
<p>

**Abstract:** Tracking all nuclei of an embryo in noisy and dense fluorescence microscopy data is a challenging task. We build upon a recent method for nuclei tracking that combines weakly-supervised learning from a small set of nuclei center point annotations with an integer linear program (ILP) for optimal cell lineage extraction. Our work specifically addresses the following challenging properties of C. elegans embryo recordings: (1) Many cell divisions as compared to benchmark recordings of other organisms, and (2) the presence of polar bodies that are easily mistaken as cell nuclei. To cope with (1), we devise and incorporate a learnt cell division detector. To cope with (2), we employ a learnt polar body detector. We further propose automated ILP weights tuning via a structured SVM, alleviating the need for tedious manual set-up of a respective grid search. Our method outperforms the previous leader of the cell tracking challenge on the Fluo-N3DH-CE embryo dataset. We report a further extensive quantitative evaluation on two more C. elegans datasets. We will make these datasets public to serve as an extended benchmark for future method development. Our results suggest considerable improvements yielded by our method, especially in terms of the correctness of division event detection and the number and length of fully correct track segments. Code: https://github.com/funkelab/linajea

</p>
</details>

<details><summary><b>The premise of approximate MCMC in Bayesian deep learning</b>
<a href="https://arxiv.org/abs/2208.11389">arxiv:2208.11389</a>
&#x1F4C8; 7 <br>
<p>Theodore Papamarkou</p></summary>
<p>

**Abstract:** This paper identifies several characteristics of approximate MCMC in Bayesian deep learning. It proposes an approximate sampling algorithm for neural networks. By analogy to sampling data batches from big datasets, it is proposed to sample parameter subgroups from neural network parameter spaces of high dimensions. While the advantages of minibatch MCMC have been discussed in the literature, blocked Gibbs sampling has received less research attention in Bayesian deep learning.

</p>
</details>

<details><summary><b>Transformer-Boosted Anomaly Detection with Fuzzy Hashes</b>
<a href="https://arxiv.org/abs/2208.11367">arxiv:2208.11367</a>
&#x1F4C8; 7 <br>
<p>Frieder Uhlig, Lukas Struppek, Dominik Hintersdorf, Kristian Kersting</p></summary>
<p>

**Abstract:** Fuzzy hashes are an important tool in digital forensics and are used in approximate matching to determine the similarity between digital artifacts. They translate the byte code of files into computable strings, which makes them particularly interesting for intelligent machine processing. In this work, we propose deep learning approximate matching (DLAM), which achieves much higher accuracy in detecting anomalies in fuzzy hashes than conventional approaches. In addition to the well-known application for clustering malware, we show that fuzzy hashes and deep learning are indeed well-suited to classify files according to the presence of certain content, e.g., malware. DLAM relies on transformer-based models from the field of natural language processing and outperforms existing methods. Traditional fuzzy hashes like TLSH and ssdeep have a limited size and fail to detect file anomalies if they are relatively small compared to the overall file size. DLAM, however, enables the detection of such file correlations in the computed fuzzy hashes of TLSH and ssdeep, even for anomaly sizes of less than 15%. It achieves comparable results to state-of-the-art fuzzy hashing algorithms while relying on more efficient hash computations and can, therefore, be used at a much larger scale.

</p>
</details>

<details><summary><b>Comparison of Object Detection Algorithms for Street-level Objects</b>
<a href="https://arxiv.org/abs/2208.11315">arxiv:2208.11315</a>
&#x1F4C8; 7 <br>
<p>Martinus Grady Naftali, Jason Sebastian Sulistyawan, Kelvin Julian</p></summary>
<p>

**Abstract:** Object detection for street-level objects can be applied to various use cases, from car and traffic detection to the self-driving car system. Therefore, finding the best object detection algorithm is essential to apply it effectively. Many object detection algorithms have been released, and many have compared object detection algorithms, but few have compared the latest algorithms, such as YOLOv5, primarily which focus on street-level objects. This paper compares various one-stage detector algorithms; SSD MobileNetv2 FPN-lite 320x320, YOLOv3, YOLOv4, YOLOv5l, and YOLOv5s for street-level object detection within real-time images. The experiment utilizes a modified Udacity Self Driving Car Dataset with 3,169 images. Dataset is split into train, validation, and test; Then, it is preprocessed and augmented using rescaling, hue shifting, and noise. Each algorithm is then trained and evaluated. Based on the experiments, the algorithms have produced decent results according to the inference time and the values of their precision, recall, F1-Score, and Mean Average Precision (mAP). The results also shows that YOLOv5l outperforms the other algorithms in terms of accuracy with a mAP@.5 of 0.593, MobileNetv2 FPN-lite has the fastest inference time among the others with only 3.20ms inference time. It is also found that YOLOv5s is the most efficient, with it having a YOLOv5l accuracy and a speed almost as quick as the MobileNetv2 FPN-lite. This shows that various algorithm are suitable for street-level object detection and viable enough to be used in self-driving car.

</p>
</details>

<details><summary><b>Federated Learning via Decentralized Dataset Distillation in Resource-Constrained Edge Environments</b>
<a href="https://arxiv.org/abs/2208.11311">arxiv:2208.11311</a>
&#x1F4C8; 7 <br>
<p>Rui Song, Dai Liu, Dave Zhenyu Chen, Andreas Festag, Carsten Trinitis, Martin Schulz, Alois Knoll</p></summary>
<p>

**Abstract:** We introduce a novel federated learning framework, FedD3, which reduces the overall communication volume and with that opens up the concept of federated learning to more application scenarios in network-constrained environments. It achieves this by leveraging local dataset distillation instead of traditional learning approaches (i) to significantly reduce communication volumes and (ii) to limit transfers to one-shot communication, rather than iterative multiway communication. Instead of sharing model updates, as in other federated learning approaches, FedD3 allows the connected clients to distill the local datasets independently, and then aggregates those decentralized distilled datasets (typically in the form a few unrecognizable images, which are normally smaller than a model) across the network only once to form the final model. Our experimental results show that FedD3 significantly outperforms other federated learning frameworks in terms of needed communication volumes, while it provides the additional benefit to be able to balance the trade-off between accuracy and communication cost, depending on usage scenario or target dataset. For instance, for training an AlexNet model on a Non-IID CIFAR-10 dataset with 10 clients, FedD3 can either increase the accuracy by over 71% with a similar communication volume, or save 98% of communication volume, while reaching the same accuracy, comparing to other one-shot federated learning approaches.

</p>
</details>

<details><summary><b>Improving Natural-Language-based Audio Retrieval with Transfer Learning and Audio & Text Augmentations</b>
<a href="https://arxiv.org/abs/2208.11460">arxiv:2208.11460</a>
&#x1F4C8; 6 <br>
<p>Paul Primus, Gerhard Widmer</p></summary>
<p>

**Abstract:** The absence of large labeled datasets remains a significant challenge in many application areas of deep learning. Researchers and practitioners typically resort to transfer learning and data augmentation to alleviate this issue. We study these strategies in the context of audio retrieval with natural language queries (Task 6b of the DCASE 2022 Challenge). Our proposed system uses pre-trained embedding models to project recordings and textual descriptions into a shared audio-caption space in which related examples from different modalities are close. We employ various data augmentation techniques on audio and text inputs and systematically tune their corresponding hyperparameters with sequential model-based optimization. Our results show that the used augmentations strategies reduce overfitting and improve retrieval performance. We further show that pre-training the system on the AudioCaps dataset leads to additional improvements.

</p>
</details>

<details><summary><b>Towards Efficient Use of Multi-Scale Features in Transformer-Based Object Detectors</b>
<a href="https://arxiv.org/abs/2208.11356">arxiv:2208.11356</a>
&#x1F4C8; 6 <br>
<p>Gongjie Zhang, Zhipeng Luo, Yingchen Yu, Zichen Tian, Jingyi Zhang, Shijian Lu</p></summary>
<p>

**Abstract:** Multi-scale features have been proven highly effective for object detection, and most ConvNet-based object detectors adopt Feature Pyramid Network (FPN) as a basic component for exploiting multi-scale features. However, for the recently proposed Transformer-based object detectors, directly incorporating multi-scale features leads to prohibitive computational overhead due to the high complexity of the attention mechanism for processing high-resolution features. This paper presents Iterative Multi-scale Feature Aggregation (IMFA) -- a generic paradigm that enables the efficient use of multi-scale features in Transformer-based object detectors. The core idea is to exploit sparse multi-scale features from just a few crucial locations, and it is achieved with two novel designs. First, IMFA rearranges the Transformer encoder-decoder pipeline so that the encoded features can be iteratively updated based on the detection predictions. Second, IMFA sparsely samples scale-adaptive features for refined detection from just a few keypoint locations under the guidance of prior detection predictions. As a result, the sampled multi-scale features are sparse yet still highly beneficial for object detection. Extensive experiments show that the proposed IMFA boosts the performance of multiple Transformer-based object detectors significantly yet with slight computational overhead. Project page: https://github.com/ZhangGongjie/IMFA.

</p>
</details>

<details><summary><b>Discovering Transferable Forensic Features for CNN-generated Images Detection</b>
<a href="https://arxiv.org/abs/2208.11342">arxiv:2208.11342</a>
&#x1F4C8; 6 <br>
<p>Keshigeyan Chandrasegaran, Ngoc-Trung Tran, Alexander Binder, Ngai-Man Cheung</p></summary>
<p>

**Abstract:** Visual counterfeits are increasingly causing an existential conundrum in mainstream media with rapid evolution in neural image synthesis methods. Though detection of such counterfeits has been a taxing problem in the image forensics community, a recent class of forensic detectors -- universal detectors -- are able to surprisingly spot counterfeit images regardless of generator architectures, loss functions, training datasets, and resolutions. This intriguing property suggests the possible existence of transferable forensic features (T-FF) in universal detectors. In this work, we conduct the first analytical study to discover and understand T-FF in universal detectors. Our contributions are 2-fold: 1) We propose a novel forensic feature relevance statistic (FF-RS) to quantify and discover T-FF in universal detectors and, 2) Our qualitative and quantitative investigations uncover an unexpected finding: color is a critical T-FF in universal detectors. Code and models are available at https://keshik6.github.io/transferable-forensic-features/

</p>
</details>

<details><summary><b>A Bayesian Variational principle for dynamic Self Organizing Maps</b>
<a href="https://arxiv.org/abs/2208.11337">arxiv:2208.11337</a>
&#x1F4C8; 6 <br>
<p>Anthony Fillion, Thibaut Kulak, François Blayo</p></summary>
<p>

**Abstract:** We propose organisation conditions that yield a method for training SOM with adaptative neighborhood radius in a variational Bayesian framework. This method is validated on a non-stationary setting and compared in an high-dimensional setting with an other adaptative method.

</p>
</details>

<details><summary><b>Modeling Paragraph-Level Vision-Language Semantic Alignment for Multi-Modal Summarization</b>
<a href="https://arxiv.org/abs/2208.11303">arxiv:2208.11303</a>
&#x1F4C8; 6 <br>
<p>Xinnian Liang, Chenhao Cui, Shuangzhi Wu, Jiali Zeng, Yufan Jiang, Zhoujun Li</p></summary>
<p>

**Abstract:** Most current multi-modal summarization methods follow a cascaded manner, where an off-the-shelf object detector is first used to extract visual features, then these features are fused with language representations to generate the summary with an encoder-decoder model. The cascaded way cannot capture the semantic alignments between images and paragraphs, which are crucial to a precise summary. In this paper, we propose ViL-Sum to jointly model paragraph-level \textbf{Vi}sion-\textbf{L}anguage Semantic Alignment and Multi-Modal \textbf{Sum}marization. The core of ViL-Sum is a joint multi-modal encoder with two well-designed tasks, image reordering and image selection. The joint multi-modal encoder captures the interactions between modalities, where the reordering task guides the model to learn paragraph-level semantic alignment and the selection task guides the model to selected summary-related images in the final summary. Experimental results show that our proposed ViL-Sum significantly outperforms current state-of-the-art methods. In further analysis, we find that two well-designed tasks and joint multi-modal encoder can effectively guide the model to learn reasonable paragraphs-images and summary-images relations.

</p>
</details>

<details><summary><b>Repair Is Nearly Generation: Multilingual Program Repair with LLMs</b>
<a href="https://arxiv.org/abs/2208.11640">arxiv:2208.11640</a>
&#x1F4C8; 5 <br>
<p>Harshit Joshi, José Cambronero, Sumit Gulwani, Vu Le, Ivan Radicek, Gust Verbruggen</p></summary>
<p>

**Abstract:** Most programmers make mistakes when writing code. Some of these mistakes are small and require few edits to the original program - a class of errors recently termed last mile mistakes. These errors break the flow for experienced developers and can stump novice programmers. Existing automated repair techniques targeting this class of errors are domain-specific and do not easily carry over to new domains. Transferring symbolic approaches requires substantial engineering and neural approaches require data and retraining. We introduce RING, a multilingual repair engine powered by a large language model trained on code (LLMC) such as Codex. Such a multilingual engine enables a flipped model for programming assistance, one where the programmer writes code and the AI assistance suggests fixes, compared to traditional code suggestion technology. Taking inspiration from the way programmers manually fix bugs, we show that a prompt-based strategy that conceptualizes repair as localization, transformation, and candidate ranking, can successfully repair programs in multiple domains with minimal effort. We present the first results for such a multilingual repair engine by evaluating on 6 different domains and comparing performance to domain-specific repair engines. We show that RING can outperform domain-specific repair engines in 3 of these domains. We also identify directions for future research using LLMCs for multilingual repair.

</p>
</details>

<details><summary><b>Fast Nearest Convolution for Real-Time Efficient Image Super-Resolution</b>
<a href="https://arxiv.org/abs/2208.11609">arxiv:2208.11609</a>
&#x1F4C8; 5 <br>
<p>Ziwei Luo, Youwei Li, Lei Yu, Qi Wu, Zhihong Wen, Haoqiang Fan, Shuaicheng Liu</p></summary>
<p>

**Abstract:** Deep learning-based single image super-resolution (SISR) approaches have drawn much attention and achieved remarkable success on modern advanced GPUs. However, most state-of-the-art methods require a huge number of parameters, memories, and computational resources, which usually show inferior inference times when applying them to current mobile device CPUs/NPUs. In this paper, we propose a simple plain convolution network with a fast nearest convolution module (NCNet), which is NPU-friendly and can perform a reliable super-resolution in real-time. The proposed nearest convolution has the same performance as the nearest upsampling but is much faster and more suitable for Android NNAPI. Our model can be easily deployed on mobile devices with 8-bit quantization and is fully compatible with all major mobile AI accelerators. Moreover, we conduct comprehensive experiments on different tensor operations on a mobile device to illustrate the efficiency of our network architecture. Our NCNet is trained and validated on the DIV2K 3x dataset, and the comparison with other efficient SR methods demonstrated that the NCNet can achieve high fidelity SR results while using fewer inference times. Our codes and pretrained models are publicly available at \url{https://github.com/Algolzw/NCNet}.

</p>
</details>

<details><summary><b>A Low-Complexity Approach to Rate-Distortion Optimized Variable Bit-Rate Compression for Split DNN Computing</b>
<a href="https://arxiv.org/abs/2208.11596">arxiv:2208.11596</a>
&#x1F4C8; 5 <br>
<p>Parual Datta, Nilesh Ahuja, V. Srinivasa Somayazulu, Omesh Tickoo</p></summary>
<p>

**Abstract:** Split computing has emerged as a recent paradigm for implementation of DNN-based AI workloads, wherein a DNN model is split into two parts, one of which is executed on a mobile/client device and the other on an edge-server (or cloud). Data compression is applied to the intermediate tensor from the DNN that needs to be transmitted, addressing the challenge of optimizing the rate-accuracy-complexity trade-off. Existing split-computing approaches adopt ML-based data compression, but require that the parameters of either the entire DNN model, or a significant portion of it, be retrained for different compression levels. This incurs a high computational and storage burden: training a full DNN model from scratch is computationally demanding, maintaining multiple copies of the DNN parameters increases storage requirements, and switching the full set of weights during inference increases memory bandwidth. In this paper, we present an approach that addresses all these challenges. It involves the systematic design and training of bottleneck units - simple, low-cost neural networks - that can be inserted at the point of split. Our approach is remarkably lightweight, both during training and inference, highly effective and achieves excellent rate-distortion performance at a small fraction of the compute and storage overhead compared to existing methods.

</p>
</details>

<details><summary><b>A model-based approach to meta-Reinforcement Learning: Transformers and tree search</b>
<a href="https://arxiv.org/abs/2208.11535">arxiv:2208.11535</a>
&#x1F4C8; 5 <br>
<p>Brieuc Pinon, Jean-Charles Delvenne, Raphaël Jungers</p></summary>
<p>

**Abstract:** Meta-learning is a line of research that develops the ability to leverage past experiences to efficiently solve new learning problems. Meta-Reinforcement Learning (meta-RL) methods demonstrate a capability to learn behaviors that efficiently acquire and exploit information in several meta-RL problems.
  In this context, the Alchemy benchmark has been proposed by Wang et al. [2021]. Alchemy features a rich structured latent space that is challenging for state-of-the-art model-free RL methods. These methods fail to learn to properly explore then exploit.
  We develop a model-based algorithm. We train a model whose principal block is a Transformer Encoder to fit the symbolic Alchemy environment dynamics. Then we define an online planner with the learned model using a tree search method. This algorithm significantly outperforms previously applied model-free RL methods on the symbolic Alchemy problem.
  Our results reveal the relevance of model-based approaches with online planning to perform exploration and exploitation successfully in meta-RL. Moreover, we show the efficiency of the Transformer architecture to learn complex dynamics that arise from latent spaces present in meta-RL problems.

</p>
</details>

<details><summary><b>Collaborative Algorithms for Online Personalized Mean Estimation</b>
<a href="https://arxiv.org/abs/2208.11530">arxiv:2208.11530</a>
&#x1F4C8; 5 <br>
<p>Mahsa Asadi, Aurélien Bellet, Odalric-Ambrym Maillard, Marc Tommasi</p></summary>
<p>

**Abstract:** We consider an online estimation problem involving a set of agents. Each agent has access to a (personal) process that generates samples from a real-valued distribution and seeks to estimate its mean. We study the case where some of the distributions have the same mean, and the agents are allowed to actively query information from other agents. The goal is to design an algorithm that enables each agent to improve its mean estimate thanks to communication with other agents. The means as well as the number of distributions with same mean are unknown, which makes the task nontrivial. We introduce a novel collaborative strategy to solve this online personalized mean estimation problem. We analyze its time complexity and introduce variants that enjoy good performance in numerical experiments. We also extend our approach to the setting where clusters of agents with similar means seek to estimate the mean of their cluster.

</p>
</details>

<details><summary><b>Improved Zero-Shot Audio Tagging & Classification with Patchout Spectrogram Transformers</b>
<a href="https://arxiv.org/abs/2208.11402">arxiv:2208.11402</a>
&#x1F4C8; 5 <br>
<p>Paul Primus, Gerhard Widmer</p></summary>
<p>

**Abstract:** Standard machine learning models for tagging and classifying acoustic signals cannot handle classes that were not seen during training. Zero-Shot (ZS) learning overcomes this restriction by predicting classes based on adaptable class descriptions. This study sets out to investigate the effectiveness of self-attention-based audio embedding architectures for ZS learning. To this end, we compare the very recent patchout spectrogram transformer with two classic convolutional architectures. We evaluate these three architectures on three tasks and on three different benchmark datasets: general-purpose tagging on AudioSet, environmental sound classification on ESC-50, and instrument tagging on OpenMIC. Our results show that the self-attention-based embedding methods outperform both compared convolutional architectures in all of these settings. By designing training and test data accordingly, we observe that prediction performance suffers significantly when the `semantic distance' between training and new test classes is large, an effect that will deserve more detailed investigations.

</p>
</details>

<details><summary><b>Self-Supervised Exploration via Temporal Inconsistency in Reinforcement Learning</b>
<a href="https://arxiv.org/abs/2208.11361">arxiv:2208.11361</a>
&#x1F4C8; 5 <br>
<p>Zijian Gao, Kele Xu, HengXing Cai, Yuanzhao Zhai, Dawei Feng, Bo Ding, XinJun Mao, Huaimin Wang</p></summary>
<p>

**Abstract:** In real-world scenarios, reinforcement learning under sparse-reward synergistic settings has remained challenging, despite surging interests in this field. Previous attempts suggest that intrinsic reward can alleviate the issue caused by sparsity. In this paper, we present a novel intrinsic reward that is inspired by human learning, as humans evaluate curiosity by comparing current observations with historical knowledge. Specifically, we train a self-supervised prediction model and save a set of snapshots of the model parameters, without incurring addition training cost. Then we employ nuclear norm to evaluate the temporal inconsistency between the predictions of different snapshots, which can be further deployed as the intrinsic reward. Moreover, a variational weighting mechanism is proposed to assign weight to different snapshots in an adaptive manner. We demonstrate the efficacy of the proposed method in various benchmark environments. The results suggest that our method can provide overwhelming state-of-the-art performance compared with other intrinsic reward-based methods, without incurring additional training costs and maintaining higher noise tolerance. Our code will be released publicly to enhance reproducibility.

</p>
</details>

<details><summary><b>Fast emulation of density functional theory simulations using approximate Gaussian processes</b>
<a href="https://arxiv.org/abs/2208.11302">arxiv:2208.11302</a>
&#x1F4C8; 5 <br>
<p>Steven Stetzler, Michael Grosskopf, Earl Lawrence</p></summary>
<p>

**Abstract:** Fitting a theoretical model to experimental data in a Bayesian manner using Markov chain Monte Carlo typically requires one to evaluate the model thousands (or millions) of times. When the model is a slow-to-compute physics simulation, Bayesian model fitting becomes infeasible. To remedy this, a second statistical model that predicts the simulation output -- an "emulator" -- can be used in lieu of the full simulation during model fitting. A typical emulator of choice is the Gaussian process (GP), a flexible, non-linear model that provides both a predictive mean and variance at each input point. Gaussian process regression works well for small amounts of training data ($n < 10^3$), but becomes slow to train and use for prediction when the data set size becomes large. Various methods can be used to speed up the Gaussian process in the medium-to-large data set regime ($n > 10^5$), trading away predictive accuracy for drastically reduced runtime. This work examines the accuracy-runtime trade-off of several approximate Gaussian process models -- the sparse variational GP, stochastic variational GP, and deep kernel learned GP -- when emulating the predictions of density functional theory (DFT) models. Additionally, we use the emulators to calibrate, in a Bayesian manner, the DFT model parameters using observed data, resolving the computational barrier imposed by the data set size, and compare calibration results to previous work. The utility of these calibrated DFT models is to make predictions, based on observed data, about the properties of experimentally unobserved nuclides of interest e.g. super-heavy nuclei.

</p>
</details>

<details><summary><b>AI-coupled HPC Workflows</b>
<a href="https://arxiv.org/abs/2208.11745">arxiv:2208.11745</a>
&#x1F4C8; 4 <br>
<p>Shantenu Jha, Vincent R. Pascuzzi, Matteo Turilli</p></summary>
<p>

**Abstract:** Increasingly, scientific discovery requires sophisticated and scalable workflows. Workflows have become the ``new applications,'' wherein multi-scale computing campaigns comprise multiple and heterogeneous executable tasks. In particular, the introduction of AI/ML models into the traditional HPC workflows has been an enabler of highly accurate modeling, typically reducing computational needs compared to traditional methods. This chapter discusses various modes of integrating AI/ML models to HPC computations, resulting in diverse types of AI-coupled HPC workflows. The increasing need of coupling AI/ML and HPC across scientific domains is motivated, and then exemplified by a number of production-grade use cases for each mode. We additionally discuss the primary challenges of extreme-scale AI-coupled HPC campaigns -- task heterogeneity, adaptivity, performance -- and several framework and middleware solutions which aim to address them. While both HPC workflow and AI/ML computing paradigms are independently effective, we highlight how their integration, and ultimate convergence, is leading to significant improvements in scientific performance across a range of domains, ultimately resulting in scientific explorations otherwise unattainable.

</p>
</details>

<details><summary><b>gSwin: Gated MLP Vision Model with Hierarchical Structure of Shifted Window</b>
<a href="https://arxiv.org/abs/2208.11718">arxiv:2208.11718</a>
&#x1F4C8; 4 <br>
<p>Mocho Go, Hideyuki Tachibana</p></summary>
<p>

**Abstract:** Following the success in language domain, the self-attention mechanism (transformer) is adopted in the vision domain and achieving great success recently. Additionally, as another stream, multi-layer perceptron (MLP) is also explored in the vision domain. These architectures, other than traditional CNNs, have been attracting attention recently, and many methods have been proposed. As one that combines parameter efficiency and performance with locality and hierarchy in image recognition, we propose gSwin, which merges the two streams; Swin Transformer and (multi-head) gMLP. We showed that our gSwin can achieve better accuracy on three vision tasks, image classification, object detection and semantic segmentation, than Swin Transformer, with smaller model size.

</p>
</details>

<details><summary><b>Constraint-driven multi-task learning</b>
<a href="https://arxiv.org/abs/2208.11656">arxiv:2208.11656</a>
&#x1F4C8; 4 <br>
<p>Bogdan Cretu, Andrew Cropper</p></summary>
<p>

**Abstract:** Inductive logic programming is a form of machine learning based on mathematical logic that generates logic programs from given examples and background knowledge.
  In this project, we extend the Popper ILP system to make use of multi-task learning. We implement the state-of-the-art approach and several new strategies to improve search performance. Furthermore, we introduce constraint preservation, a technique that improves overall performance for all approaches.
  Constraint preservation allows the system to transfer knowledge between updates on the background knowledge set. Consequently, we reduce the amount of repeated work performed by the system. Additionally, constraint preservation allows us to transition from the current state-of-the-art iterative deepening search approach to a more efficient breadth first search approach.
  Finally, we experiment with curriculum learning techniques and show their potential benefit to the field.

</p>
</details>

<details><summary><b>ImitAL: Learned Active Learning Strategy on Synthetic Data</b>
<a href="https://arxiv.org/abs/2208.11636">arxiv:2208.11636</a>
&#x1F4C8; 4 <br>
<p>Julius Gonsior, Maik Thiele, Wolfgang Lehner</p></summary>
<p>

**Abstract:** Active Learning (AL) is a well-known standard method for efficiently obtaining annotated data by first labeling the samples that contain the most information based on a query strategy. In the past, a large variety of such query strategies has been proposed, with each generation of new strategies increasing the runtime and adding more complexity. However, to the best of our our knowledge, none of these strategies excels consistently over a large number of datasets from different application domains. Basically, most of the the existing AL strategies are a combination of the two simple heuristics informativeness and representativeness, and the big differences lie in the combination of the often conflicting heuristics. Within this paper, we propose ImitAL, a domain-independent novel query strategy, which encodes AL as a learning-to-rank problem and learns an optimal combination between both heuristics. We train ImitAL on large-scale simulated AL runs on purely synthetic datasets. To show that ImitAL was successfully trained, we perform an extensive evaluation comparing our strategy on 13 different datasets, from a wide range of domains, with 7 other query strategies.

</p>
</details>

<details><summary><b>Deep Symbolic Learning: Discovering Symbols and Rules from Perceptions</b>
<a href="https://arxiv.org/abs/2208.11561">arxiv:2208.11561</a>
&#x1F4C8; 4 <br>
<p>Alessandro Daniele, Tommaso Campari, Sagar Malhotra, Luciano Serafini</p></summary>
<p>

**Abstract:** Neuro-Symbolic (NeSy) integration combines symbolic reasoning with Neural Networks (NNs) for tasks requiring perception and reasoning. Most NeSy systems rely on continuous relaxation of logical knowledge and no discrete decisions are made within the model pipeline. Furthermore, these methods assume that the symbolic rules are given. In this paper, we propose Deep Symbolic Learning (DSL), a NeSy system that learns NeSy-functions, i.e., the composition of a (set of) perception functions which map continuous data to discrete symbols, and a symbolic function over the set of symbols. DSL learns simultaneously the perception and symbolic functions, while being trained only on their composition (NeSy-function). The key novelty of DSL is that it can create internal (interpretable) symbolic representations and map them to perception inputs within a differentiable NN learning pipeline. The created symbols are automatically selected to generate symbolic functions that best explain the data. We provide experimental analysis to substantiate the efficacy of DSL in simultaneously learning perception and symbolic functions.

</p>
</details>

<details><summary><b>A methodology for identifying resiliency in renewable electrical distribution system using complex network</b>
<a href="https://arxiv.org/abs/2208.11543">arxiv:2208.11543</a>
&#x1F4C8; 4 <br>
<p>Divyanshi Dwivedi, Pradeep Kumar Yemula, Mayukha Pal</p></summary>
<p>

**Abstract:** Recently, Electrical Distribution Systems are extensively penetrated with the Distributed Energy Resources (DERs) to cater the energy demands with general perception that it enhances the system resiliency. However, it may be adverse for the grid operation due to various factors like its intermittent availability, dynamics in weather condition, introduction of nonlinearity, complexity etc. This needs a detailed understanding of system resiliency that our method proposes here. We introduce a methodology using complex network theory to identify the resiliency of distribution system when incorporated with Solar PV generation under various undesirable configurations. Complex correlated networks for different conditions were obtained and various network parameters were computed for identifying the resiliency of those networks. The proposed methodology identifies the hosting capacity of solar panels in the system while maintaining the resiliency under different unwanted conditions hence helps to obtain an optimal allocation topology for solar panels in the system. The proposed method also identifies the critical nodes that are highly sensitive to the changes and could drive the system into non-resiliency. This framework was demonstrated on IEEE-123 Test Feeder system with time-series data generated using GridLAB-D and variety of analysis were performed using complex network and machine learning models.

</p>
</details>

<details><summary><b>Weakly Supervised Airway Orifice Segmentation in Video Bronchoscopy</b>
<a href="https://arxiv.org/abs/2208.11468">arxiv:2208.11468</a>
&#x1F4C8; 4 <br>
<p>Ron Keuth, Mattias Heinrich, Martin Eichenlaub, Marian Himstedt</p></summary>
<p>

**Abstract:** Video bronchoscopy is routinely conducted for biopsies of lung tissue suspected for cancer, monitoring of COPD patients and clarification of acute respiratory problems at intensive care units. The navigation within complex bronchial trees is particularly challenging and physically demanding, requiring long-term experiences of physicians. This paper addresses the automatic segmentation of bronchial orifices in bronchoscopy videos. Deep learning-based approaches to this task are currently hampered due to the lack of readily-available ground truth segmentation data. Thus, we present a data-driven pipeline consisting of a k-means followed by a compact marker-based watershed algorithm which enables to generate airway instance segmentation maps from given depth images. In this way, these traditional algorithms serve as weak supervision for training a shallow CNN directly on RGB images solely based on a phantom dataset. We evaluate generalization capabilities of this model on two in-vivo datasets covering 250 frames on 21 different bronchoscopies. We demonstrate that its performance is comparable to those models being directly trained on in-vivo data, reaching an average error of 11 vs 5 pixels for the detected centers of the airway segmentation by an image resolution of 128x128. Our quantitative and qualitative results indicate that in the context of video bronchoscopy, phantom data and weak supervision using non-learning-based approaches enable to gain a semantic understanding of airway structures.

</p>
</details>

<details><summary><b>Scenario-Adaptive and Self-Supervised Model for Multi-Scenario Personalized Recommendation</b>
<a href="https://arxiv.org/abs/2208.11457">arxiv:2208.11457</a>
&#x1F4C8; 4 <br>
<p>Yuanliang Zhang, Xiaofeng Wang, Jinxin Hu, Ke Gao, Chenyi Lei, Fei Fang</p></summary>
<p>

**Abstract:** Multi-scenario recommendation is dedicated to retrieve relevant items for users in multiple scenarios, which is ubiquitous in industrial recommendation systems. These scenarios enjoy portions of overlaps in users and items, while the distribution of different scenarios is different. The key point of multi-scenario modeling is to efficiently maximize the use of whole-scenario information and granularly generate adaptive representations both for users and items among multiple scenarios. we summarize three practical challenges which are not well solved for multi-scenario modeling: (1) Lacking of fine-grained and decoupled information transfer controls among multiple scenarios. (2) Insufficient exploitation of entire space samples. (3) Item's multi-scenario representation disentanglement problem. In this paper, we propose a Scenario-Adaptive and Self-Supervised (SASS) model to solve the three challenges mentioned above. Specifically, we design a Multi-Layer Scenario Adaptive Transfer (ML-SAT) module with scenario-adaptive gate units to select and fuse effective transfer information from whole scenario to individual scenario in a quite fine-grained and decoupled way. To sufficiently exploit the power of entire space samples, a two-stage training process including pre-training and fine-tune is introduced. The pre-training stage is based on a scenario-supervised contrastive learning task with the training samples drawn from labeled and unlabeled data spaces. The model is created symmetrically both in user side and item side, so that we can get distinguishing representations of items in different scenarios. Extensive experimental results on public and industrial datasets demonstrate the superiority of the SASS model over state-of-the-art methods. This model also achieves more than 8.0% improvement on Average Watching Time Per User in online A/B tests.

</p>
</details>

<details><summary><b>UniCon: Unidirectional Split Learning with Contrastive Loss for Visual Question Answering</b>
<a href="https://arxiv.org/abs/2208.11435">arxiv:2208.11435</a>
&#x1F4C8; 4 <br>
<p>Yuwei Sun, Hideya Ochiai</p></summary>
<p>

**Abstract:** Visual question answering (VQA) that leverages multi-modality data has attracted intensive interest in real-life applications, such as home robots and clinic diagnoses. Nevertheless, one of the challenges is to design robust learning for different client tasks. This work aims to bridge the gap between the prerequisite of large-scale training data and the constraint of client data sharing mainly due to confidentiality. We propose the Unidirectional Split Learning with Contrastive Loss (UniCon) to tackle VQA tasks training on distributed data silos. In particular, UniCon trains a global model over the entire data distribution of different clients learning refined cross-modal representations via contrastive learning. The learned representations of the global model aggregate knowledge from different local tasks. Moreover, we devise a unidirectional split learning framework to enable more efficient knowledge sharing. The comprehensive experiments with five state-of-the-art VQA models on the VQA-v2 dataset demonstrated the efficacy of UniCon, achieving an accuracy of 49.89% in the validation set of VQA-v2. This work is the first study of VQA under the constraint of data confidentiality using self-supervised Split Learning.

</p>
</details>

<details><summary><b>Deep model with built-in self-attention alignment for acoustic echo cancellation</b>
<a href="https://arxiv.org/abs/2208.11308">arxiv:2208.11308</a>
&#x1F4C8; 4 <br>
<p>Evgenii Indenbom, Nicolae-Cătălin Ristea, Ando Saabas, Tanel Pärnamaa, Jegor Gužvin</p></summary>
<p>

**Abstract:** With recent research advances, deep learning models have become an attractive choice for acoustic echo cancellation (AEC) in real-time teleconferencing applications. Since acoustic echo is one of the major sources of poor audio quality, a wide variety of deep models have been proposed. However, an important but often omitted requirement for good echo cancellation quality is the synchronization of the microphone and far end signals. Typically implemented using classical algorithms based on cross-correlation, the alignment module is a separate functional block with known design limitations. In our work we propose a deep learning architecture with built-in self-attention based alignment, which is able to handle unaligned inputs, improving echo cancellation performance while simplifying the communication pipeline. Moreover, we show that our approach achieves significant improvements for difficult delay estimation cases on real recordings from AEC Challenge data set.

</p>
</details>

<details><summary><b>Fix-A-Step: Effective Semi-supervised Learning from Uncurated Unlabeled Sets</b>
<a href="https://arxiv.org/abs/2208.11870">arxiv:2208.11870</a>
&#x1F4C8; 3 <br>
<p>Zhe Huang, Mary-Joy Sidhom, Benjamin S. Wessler, Michael C. Hughes</p></summary>
<p>

**Abstract:** Semi-supervised learning (SSL) promises gains in accuracy compared to training classifiers on small labeled datasets by also training on many unlabeled images. In realistic applications like medical imaging, unlabeled sets will be collected for expediency and thus uncurated: possibly different from the labeled set in represented classes or class frequencies. Unfortunately, modern deep SSL often makes accuracy worse when given uncurated unlabeled sets. Recent remedies suggest filtering approaches that detect out-of-distribution unlabeled examples and then discard or downweight them. Instead, we view all unlabeled examples as potentially helpful. We introduce a procedure called Fix-A-Step that can improve heldout accuracy of common deep SSL methods despite lack of curation. The key innovations are augmentations of the labeled set inspired by all unlabeled data and a modification of gradient descent updates to prevent following the multi-task SSL loss from hurting labeled-set accuracy. Though our method is simpler than alternatives, we show consistent accuracy gains on CIFAR-10 and CIFAR-100 benchmarks across all tested levels of artificial contamination for the unlabeled sets. We further suggest a real medical benchmark for SSL: recognizing the view type of ultrasound images of the heart. Our method can learn from 353,500 truly uncurated unlabeled images to deliver gains that generalize across hospitals.

</p>
</details>

<details><summary><b>Shortcut Learning of Large Language Models in Natural Language Understanding: A Survey</b>
<a href="https://arxiv.org/abs/2208.11857">arxiv:2208.11857</a>
&#x1F4C8; 3 <br>
<p>Mengnan Du, Fengxiang He, Na Zou, Dacheng Tao, Xia Hu</p></summary>
<p>

**Abstract:** Large language models (LLMs) have achieved state-of-the-art performance on a series of natural language understanding tasks. However, these LLMs might rely on dataset bias and artifacts as shortcuts for prediction. This has significantly hurt their Out-of-Distribution (OOD) generalization and adversarial robustness. In this paper, we provide a review of recent developments that address the robustness challenge of LLMs. We first introduce the concepts and robustness challenge of LLMs. We then introduce methods to identify shortcut learning behavior in LLMs, characterize the reasons for shortcut learning, as well as introduce mitigation solutions. Finally, we identify key challenges and introduce the connections of this line of research to other directions.

</p>
</details>

<details><summary><b>Learning Task Automata for Reinforcement Learning using Hidden Markov Models</b>
<a href="https://arxiv.org/abs/2208.11838">arxiv:2208.11838</a>
&#x1F4C8; 3 <br>
<p>Alessandro Abate, Yousif Almulla, James Fox, David Hyland, Michael Wooldridge</p></summary>
<p>

**Abstract:** Training reinforcement learning (RL) agents using scalar reward signals is often infeasible when an environment has sparse and non-Markovian rewards. Moreover, handcrafting these reward functions before training is prone to misspecification, especially when the environment's dynamics are only partially known. This paper proposes a novel pipeline for learning non-Markovian task specifications as succinct finite-state `task automata' from episodes of agent experience within unknown environments. We leverage two key algorithmic insights. First, we learn a product MDP, a model composed of the specification's automaton and the environment's MDP (both initially unknown), by treating it as a partially observable MDP and using off-the-shelf algorithms for hidden Markov models. Second, we propose a novel method for distilling the task automaton (assumed to be a deterministic finite automaton) from the learnt product MDP. Our learnt task automaton enables the decomposition of a task into its constituent sub-tasks, which improves the rate at which an RL agent can later synthesise an optimal policy. It also provides an interpretable encoding of high-level environmental and task features, so a human can readily verify that the agent has learnt coherent tasks with no misspecifications. In addition, we take steps towards ensuring that the learnt automaton is environment-agnostic, making it well-suited for use in transfer learning. Finally, we provide experimental results to illustrate our algorithm's performance in different environments and tasks and its ability to incorporate prior domain knowledge to facilitate more efficient learning.

</p>
</details>

<details><summary><b>Multiresolution Neural Networks for Imaging</b>
<a href="https://arxiv.org/abs/2208.11813">arxiv:2208.11813</a>
&#x1F4C8; 3 <br>
<p>Hallison Paz, Tiago Novello, Vinicius Silva, Luiz Schirmer, Guilherme Schardong, Luiz Velho</p></summary>
<p>

**Abstract:** We present MR-Net, a general architecture for multiresolution neural networks, and a framework for imaging applications based on this architecture. Our coordinate-based networks are continuous both in space and in scale as they are composed of multiple stages that progressively add finer details. Besides that, they are a compact and efficient representation. We show examples of multiresolution image representation and applications to texture magnification and minification, and antialiasing.

</p>
</details>

<details><summary><b>Rethinking Cost-sensitive Classification in Deep Learning via Adversarial Data Augmentation</b>
<a href="https://arxiv.org/abs/2208.11739">arxiv:2208.11739</a>
&#x1F4C8; 3 <br>
<p>Qiyuan Chen, Raed Al Kontar, Maher Nouiehed, Jessie Yang, Corey Lester</p></summary>
<p>

**Abstract:** Cost-sensitive classification is critical in applications where misclassification errors widely vary in cost. However, over-parameterization poses fundamental challenges to the cost-sensitive modeling of deep neural networks (DNNs). The ability of a DNN to fully interpolate a training dataset can render a DNN, evaluated purely on the training set, ineffective in distinguishing a cost-sensitive solution from its overall accuracy maximization counterpart. This necessitates rethinking cost-sensitive classification in DNNs. To address this challenge, this paper proposes a cost-sensitive adversarial data augmentation (CSADA) framework to make over-parameterized models cost-sensitive. The overarching idea is to generate targeted adversarial examples that push the decision boundary in cost-aware directions. These targeted adversarial samples are generated by maximizing the probability of critical misclassifications and used to train a model with more conservative decisions on costly pairs. Experiments on well-known datasets and a pharmacy medication image (PMI) dataset made publicly available show that our method can effectively minimize the overall cost and reduce critical errors, while achieving comparable performance in terms of overall accuracy.

</p>
</details>

<details><summary><b>Ontology-Driven Self-Supervision for Adverse Childhood Experiences Identification Using Social Media Datasets</b>
<a href="https://arxiv.org/abs/2208.11701">arxiv:2208.11701</a>
&#x1F4C8; 3 <br>
<p>Jinge Wu, Rowena Smith, Honghan Wu</p></summary>
<p>

**Abstract:** Adverse Childhood Experiences (ACEs) are defined as a collection of highly stressful, and potentially traumatic, events or circumstances that occur throughout childhood and/or adolescence. They have been shown to be associated with increased risks of mental health diseases or other abnormal behaviours in later lives. However, the identification of ACEs from textual data with Natural Language Processing (NLP) is challenging because (a) there are no NLP ready ACE ontologies; (b) there are few resources available for machine learning, necessitating the data annotation from clinical experts; (c) costly annotations by domain experts and large number of documents for supporting large machine learning models. In this paper, we present an ontology-driven self-supervised approach (derive concept embeddings using an auto-encoder from baseline NLP results) for producing a publicly available resource that would support large-scale machine learning (e.g., training transformer based large language models) on social media corpus. This resource as well as the proposed approach are aimed to facilitate the community in training transferable NLP models for effectively surfacing ACEs in low-resource scenarios like NLP on clinical notes within Electronic Health Records. The resource including a list of ACE ontology terms, ACE concept embeddings and the NLP annotated corpus is available at https://github.com/knowlab/ACE-NLP.

</p>
</details>

<details><summary><b>AGO-Net: Association-Guided 3D Point Cloud Object Detection Network</b>
<a href="https://arxiv.org/abs/2208.11658">arxiv:2208.11658</a>
&#x1F4C8; 3 <br>
<p>Liang Du, Xiaoqing Ye, Xiao Tan, Edward Johns, Bo Chen, Errui Ding, Xiangyang Xue, Jianfeng Feng</p></summary>
<p>

**Abstract:** The human brain can effortlessly recognize and localize objects, whereas current 3D object detection methods based on LiDAR point clouds still report inferior performance for detecting occluded and distant objects: the point cloud appearance varies greatly due to occlusion, and has inherent variance in point densities along the distance to sensors. Therefore, designing feature representations robust to such point clouds is critical. Inspired by human associative recognition, we propose a novel 3D detection framework that associates intact features for objects via domain adaptation. We bridge the gap between the perceptual domain, where features are derived from real scenes with sub-optimal representations, and the conceptual domain, where features are extracted from augmented scenes that consist of non-occlusion objects with rich detailed information. A feasible method is investigated to construct conceptual scenes without external datasets. We further introduce an attention-based re-weighting module that adaptively strengthens the feature adaptation of more informative regions. The network's feature enhancement ability is exploited without introducing extra cost during inference, which is plug-and-play in various 3D detection frameworks. We achieve new state-of-the-art performance on the KITTI 3D detection benchmark in both accuracy and speed. Experiments on nuScenes and Waymo datasets also validate the versatility of our method.

</p>
</details>

<details><summary><b>Debias the Black-box: A Fair Ranking Framework via Knowledge Distillation</b>
<a href="https://arxiv.org/abs/2208.11628">arxiv:2208.11628</a>
&#x1F4C8; 3 <br>
<p>Zhitao Zhu, Shijing Si, Jianzong Wang, Yaodong Yang, Jing Xiao</p></summary>
<p>

**Abstract:** Deep neural networks can capture the intricate interaction history information between queries and documents, because of their many complicated nonlinear units, allowing them to provide correct search recommendations. However, service providers frequently face more complex obstacles in real-world circumstances, such as deployment cost constraints and fairness requirements. Knowledge distillation, which transfers the knowledge of a well-trained complex model (teacher) to a simple model (student), has been proposed to alleviate the former concern, but the best current distillation methods focus only on how to make the student model imitate the predictions of the teacher model. To better facilitate the application of deep models, we propose a fair information retrieval framework based on knowledge distillation. This framework can improve the exposure-based fairness of models while considerably decreasing model size. Our extensive experiments on three huge datasets show that our proposed framework can reduce the model size to a minimum of 1% of its original size while maintaining its black-box state. It also improves fairness performance by 15%~46% while keeping a high level of recommendation effectiveness.

</p>
</details>

<details><summary><b>Calibrated and Enhanced NRLMSIS 2.0 Model with Uncertainty Quantification</b>
<a href="https://arxiv.org/abs/2208.11619">arxiv:2208.11619</a>
&#x1F4C8; 3 <br>
<p>Richard J. Licata, Piyush M. Mehta, Daniel R. Weimer, W. Kent Tobiska, Jean Yoshii</p></summary>
<p>

**Abstract:** The Mass Spectrometer and Incoherent Scatter radar (MSIS) model family has been developed and improved since the early 1970's. The most recent version of MSIS is the Naval Research Laboratory (NRL) MSIS 2.0 empirical atmospheric model. NRLMSIS 2.0 provides species density, mass density, and temperature estimates as function of location and space weather conditions. MSIS models have long been a popular choice of atmosphere model in the research and operations community alike, but - like many models - does not provide uncertainty estimates. In this work, we develop an exospheric temperature model based in machine learning (ML) that can be used with NRLMSIS 2.0 to calibrate it relative to high-fidelity satellite density estimates. Instead of providing point estimates, our model (called MSIS-UQ) outputs a distribution which is assessed using a metric called the calibration error score. We show that MSIS-UQ debiases NRLMSIS 2.0 resulting in reduced differences between model and satellite density of 25% and is 11% closer to satellite density than the Space Force's High Accuracy Satellite Drag Model. We also show the model's uncertainty estimation capabilities by generating altitude profiles for species density, mass density, and temperature. This explicitly demonstrates how exospheric temperature probabilities affect density and temperature profiles within NRLMSIS 2.0. Another study displays improved post-storm overcooling capabilities relative to NRLMSIS 2.0 alone, enhancing the phenomena that it can capture.

</p>
</details>

<details><summary><b>Sliding Window Recurrent Network for Efficient Video Super-Resolution</b>
<a href="https://arxiv.org/abs/2208.11608">arxiv:2208.11608</a>
&#x1F4C8; 3 <br>
<p>Wenyi Lian, Wenjing Lian</p></summary>
<p>

**Abstract:** Video super-resolution (VSR) is the task of restoring high-resolution frames from a sequence of low-resolution inputs. Different from single image super-resolution, VSR can utilize frames' temporal information to reconstruct results with more details. Recently, with the rapid development of convolution neural networks (CNN), the VSR task has drawn increasing attention and many CNN-based methods have achieved remarkable results. However, only a few VSR approaches can be applied to real-world mobile devices due to the computational resources and runtime limitations. In this paper, we propose a \textit{Sliding Window based Recurrent Network} (SWRN) which can be real-time inference while still achieving superior performance. Specifically, we notice that video frames should have both spatial and temporal relations that can help to recover details, and the key point is how to extract and aggregate information. Address it, we input three neighboring frames and utilize a hidden state to recurrently store and update the important temporal information. Our experiment on REDS dataset shows that the proposed method can be well adapted to mobile devices and produce visually pleasant results.

</p>
</details>

<details><summary><b>CheapET-3: Cost-Efficient Use of Remote DNN Models</b>
<a href="https://arxiv.org/abs/2208.11552">arxiv:2208.11552</a>
&#x1F4C8; 3 <br>
<p>Michael Weiss</p></summary>
<p>

**Abstract:** On complex problems, state of the art prediction accuracy of Deep Neural Networks (DNN) can be achieved using very large-scale models, consisting of billions of parameters. Such models can only be run on dedicated servers, typically provided by a 3rd party service, which leads to a substantial monetary cost for every prediction. We propose a new software architecture for client-side applications, where a small local DNN is used alongside a remote large-scale model, aiming to make easy predictions locally at negligible monetary cost, while still leveraging the benefits of a large model for challenging inputs. In a proof of concept we reduce prediction cost by up to 50% without negatively impacting system accuracy.

</p>
</details>

<details><summary><b>Lifelong Learning for Neural powered Mixed Integer Programming</b>
<a href="https://arxiv.org/abs/2208.12226">arxiv:2208.12226</a>
&#x1F4C8; 2 <br>
<p>Sahil Manchanda, Sayan Ranu</p></summary>
<p>

**Abstract:** Mixed Integer programs (MIPs) are typically solved by the Branch-and-Bound algorithm. Recently, Learning to imitate fast approximations of the expert strong branching heuristic has gained attention due to its success in reducing the running time for solving MIPs. However, existing learning-to-branch methods assume that the entire training data is available in a single session of training. This assumption is often not true, and if the training data is supplied in continual fashion over time, existing techniques suffer from catastrophic forgetting. In this work, we study the hitherto unexplored paradigm of Lifelong Learning to Branch on Mixed Integer Programs. To mitigate catastrophic forgetting, we propose LIMIP, which is powered by the idea of modeling an MIP instance in the form of a bipartite graph, which we map to an embedding space using a bipartite Graph Attention Network. This rich embedding space avoids catastrophic forgetting through the application of knowledge distillation and elastic weight consolidation, wherein we learn the parameters key towards retaining efficacy and are therefore protected from significant drift. We evaluate LIMIP on a series of NP-hard problems and establish that in comparison to existing baselines, LIMIP is up to 50% better when confronted with lifelong learning.

</p>
</details>

<details><summary><b>Seamless Tracking of Group Targets and Ungrouped Targets Using Belief Propagation</b>
<a href="https://arxiv.org/abs/2208.12035">arxiv:2208.12035</a>
&#x1F4C8; 2 <br>
<p>Xuqi Zhang, Fanqin Meng, Haiqi Liu, Xiaojing Shen, Yunmin Zhu</p></summary>
<p>

**Abstract:** This paper considers the problem of tracking a large-scale number of group targets. Usually, multi-target in most tracking scenarios are assumed to have independent motion and are well-separated. However, for group target tracking (GTT), the targets within groups are closely spaced and move in a coordinated manner, the groups can split or merge, and the numbers of targets in groups may be large, which lead to more challenging data association, filtering and computation problems. Within the belief propagation (BP) framework, we propose a scalable group target belief propagation (GTBP) method by jointly inferring target existence variables, group structure, data association and target states. The method can efficiently calculate the approximations of the marginal posterior distributions of these variables by performing belief propagation on the devised factor graph. As a consequence, GTBP is capable of capturing the changes in group structure, e.g., group splitting and merging. Furthermore, we model the evolution of targets as the co-action of the group or single-target motions specified by the possible group structures and corresponding probabilities. This flexible modeling enables seamless and simultaneous tracking of multiple group targets and ungrouped targets. Particularly, GTBP has excellent scalability and low computational complexity. It not only maintains the same scalability as BP, i.e., scaling linearly in the number of sensor measurements and quadratically in the number of targets, but also only scales linearly in the number of preserved group partitions. Finally, numerical experiments are presented to demonstrate the effectiveness and scalability of the proposed GTBP method.

</p>
</details>

<details><summary><b>Deep Learning-based approaches for automatic detection of shell nouns and evaluation on WikiText-2</b>
<a href="https://arxiv.org/abs/2208.11867">arxiv:2208.11867</a>
&#x1F4C8; 2 <br>
<p>Chengdong Yao, Cuihua Wang</p></summary>
<p>

**Abstract:** In some areas, such as Cognitive Linguistics, researchers are still using traditional techniques based on manual rules and patterns. Since the definition of shell noun is rather subjective and there are many exceptions, this time-consuming work had to be done by hand in the past when Deep Learning techniques were not mature enough. With the increasing number of networked languages, these rules are becoming less useful. However, there is a better alternative now. With the development of Deep Learning, pre-trained language models have provided a good technical basis for Natural Language Processing. Automated processes based on Deep Learning approaches are more in line with modern needs. This paper collaborates across borders to propose two Neural Network models for the automatic detection of shell nouns and experiment on the WikiText-2 dataset. The proposed approaches not only allow the entire process to be automated, but the precision has reached 94% even on completely unseen articles, comparable to that of human annotators. This shows that the performance and generalization ability of the model is good enough to be used for research purposes. Many new nouns are found that fit the definition of shell noun very well. All discovered shell nouns as well as pre-trained models and code are available on GitHub.

</p>
</details>

<details><summary><b>A Perturbation Resistant Transformation and Classification System for Deep Neural Networks</b>
<a href="https://arxiv.org/abs/2208.11839">arxiv:2208.11839</a>
&#x1F4C8; 2 <br>
<p>Nathaniel Dean, Dilip Sarkar</p></summary>
<p>

**Abstract:** Deep convolutional neural networks accurately classify a diverse range of natural images, but may be easily deceived when designed, imperceptible perturbations are embedded in the images. In this paper, we design a multi-pronged training, input transformation, and image ensemble system that is attack agnostic and not easily estimated. Our system incorporates two novel features. The first is a transformation layer that computes feature level polynomial kernels from class-level training data samples and iteratively updates input image copies at inference time based on their feature kernel differences to create an ensemble of transformed inputs. The second is a classification system that incorporates the prediction of the undefended network with a hard vote on the ensemble of filtered images. Our evaluations on the CIFAR10 dataset show our system improves the robustness of an undefended network against a variety of bounded and unbounded white-box attacks under different distance metrics, while sacrificing little accuracy on clean images. Against adaptive full-knowledge attackers creating end-to-end attacks, our system successfully augments the existing robustness of adversarially trained networks, for which our methods are most effectively applied.

</p>
</details>

<details><summary><b>Enforcing Delayed-Impact Fairness Guarantees</b>
<a href="https://arxiv.org/abs/2208.11744">arxiv:2208.11744</a>
&#x1F4C8; 2 <br>
<p>Aline Weber, Blossom Metevier, Yuriy Brun, Philip S. Thomas, Bruno Castro da Silva</p></summary>
<p>

**Abstract:** Recent research has shown that seemingly fair machine learning models, when used to inform decisions that have an impact on peoples' lives or well-being (e.g., applications involving education, employment, and lending), can inadvertently increase social inequality in the long term. This is because prior fairness-aware algorithms only consider static fairness constraints, such as equal opportunity or demographic parity. However, enforcing constraints of this type may result in models that have negative long-term impact on disadvantaged individuals and communities. We introduce ELF (Enforcing Long-term Fairness), the first classification algorithm that provides high-confidence fairness guarantees in terms of long-term, or delayed, impact. We prove that the probability that ELF returns an unfair solution is less than a user-specified tolerance and that (under mild assumptions), given sufficient training data, ELF is able to find and return a fair solution if one exists. We show experimentally that our algorithm can successfully mitigate long-term unfairness.

</p>
</details>

<details><summary><b>Graphical Models of False Information and Fact Checking Ecosystems</b>
<a href="https://arxiv.org/abs/2208.11582">arxiv:2208.11582</a>
&#x1F4C8; 2 <br>
<p>Haiyue Yuan, Enes Altuncu, Shujun Li, Can Baskent</p></summary>
<p>

**Abstract:** The wide spread of false information online including misinformation and disinformation has become a major problem for our highly digitised and globalised society. A lot of research has been done to better understand different aspects of false information online such as behaviours of different actors and patterns of spreading, and also on better detection and prevention of such information using technical and socio-technical means. One major approach to detect and debunk false information online is to use human fact-checkers, who can be helped by automated tools. Despite a lot of research done, we noticed a significant gap on the lack of conceptual models describing the complicated ecosystems of false information and fact checking. In this paper, we report the first graphical models of such ecosystems, focusing on false information online in multiple contexts, including traditional media outlets and user-generated content. The proposed models cover a wide range of entity types and relationships, and can be a new useful tool for researchers and practitioners to study false information online and the effects of fact checking.

</p>
</details>

<details><summary><b>Contrastive learning-based pretraining improves representation and transferability of diabetic retinopathy classification models</b>
<a href="https://arxiv.org/abs/2208.11563">arxiv:2208.11563</a>
&#x1F4C8; 2 <br>
<p>Minhaj Nur Alam, Rikiya Yamashita, Vignav Ramesh, Tejas Prabhune, Jennifer I. Lim, R. V. P. Chan, Joelle Hallak, Theodore Leng, Daniel Rubin</p></summary>
<p>

**Abstract:** Self supervised contrastive learning based pretraining allows development of robust and generalized deep learning models with small, labeled datasets, reducing the burden of label generation. This paper aims to evaluate the effect of CL based pretraining on the performance of referrable vs non referrable diabetic retinopathy (DR) classification. We have developed a CL based framework with neural style transfer (NST) augmentation to produce models with better representations and initializations for the detection of DR in color fundus images. We compare our CL pretrained model performance with two state of the art baseline models pretrained with Imagenet weights. We further investigate the model performance with reduced labeled training data (down to 10 percent) to test the robustness of the model when trained with small, labeled datasets. The model is trained and validated on the EyePACS dataset and tested independently on clinical data from the University of Illinois, Chicago (UIC). Compared to baseline models, our CL pretrained FundusNet model had higher AUC (CI) values (0.91 (0.898 to 0.930) vs 0.80 (0.783 to 0.820) and 0.83 (0.801 to 0.853) on UIC data). At 10 percent labeled training data, the FundusNet AUC was 0.81 (0.78 to 0.84) vs 0.58 (0.56 to 0.64) and 0.63 (0.60 to 0.66) in baseline models, when tested on the UIC dataset. CL based pretraining with NST significantly improves DL classification performance, helps the model generalize well (transferable from EyePACS to UIC data), and allows training with small, annotated datasets, therefore reducing ground truth annotation burden of the clinicians.

</p>
</details>

<details><summary><b>Prostate Lesion Detection and Salient Feature Assessment Using Zone-Based Classifiers</b>
<a href="https://arxiv.org/abs/2208.11522">arxiv:2208.11522</a>
&#x1F4C8; 2 <br>
<p>Haoli Yin, Nithin Buduma</p></summary>
<p>

**Abstract:** Multi-parametric magnetic resonance imaging (mpMRI) has a growing role in detecting prostate cancer lesions. Thus, it is pertinent that medical professionals who interpret these scans reduce the risk of human error by using computer-aided detection systems. The variety of algorithms used in system implementation, however, has yielded mixed results. Here we investigate the best machine learning classifier for each prostate zone. We also discover salient features to clarify the models' classification rationale. Of the data provided, we gathered and augmented T2 weighted images and apparent diffusion coefficient map images to extract first through third order statistical features as input to machine learning classifiers. For our deep learning classifier, we used a convolutional neural net (CNN) architecture for automatic feature extraction and classification. The interpretability of the CNN results was improved by saliency mapping to understand the classification mechanisms within. Ultimately, we concluded that effective detection of peripheral and anterior fibromuscular stroma (AS) lesions depended more on statistical distribution features, whereas those in the transition zone (TZ) depended more on textural features. Ensemble algorithms worked best for PZ and TZ zones, while CNNs were best in the AS zone. These classifiers can be used to validate a radiologist's predictions and reduce inter-reader variability in patients suspected to have prostate cancer. The salient features reported in this study can also be investigated further to better understand hidden features and biomarkers of prostate lesions with mpMRIs.

</p>
</details>

<details><summary><b>A Deep Learning Approach Using Masked Image Modeling for Reconstruction of Undersampled K-spaces</b>
<a href="https://arxiv.org/abs/2208.11472">arxiv:2208.11472</a>
&#x1F4C8; 2 <br>
<p>Kyler Larsen, Arghya Pal, Yogesh Rathi</p></summary>
<p>

**Abstract:** Magnetic Resonance Imaging (MRI) scans are time consuming and precarious, since the patients remain still in a confined space for extended periods of time. To reduce scanning time, some experts have experimented with undersampled k spaces, trying to use deep learning to predict the fully sampled result. These studies report that as many as 20 to 30 minutes could be saved off a scan that takes an hour or more. However, none of these studies have explored the possibility of using masked image modeling (MIM) to predict the missing parts of MRI k spaces. This study makes use of 11161 reconstructed MRI and k spaces of knee MRI images from Facebook's fastmri dataset. This tests a modified version of an existing model using baseline shifted window (Swin) and vision transformer architectures that makes use of MIM on undersampled k spaces to predict the full k space and consequently the full MRI image. Modifications were made using pytorch and numpy libraries, and were published to a github repository. After the model reconstructed the k space images, the basic Fourier transform was applied to determine the actual MRI image. Once the model reached a steady state, experimentation with hyperparameters helped to achieve pinpoint accuracy for the reconstructed images. The model was evaluated through L1 loss, gradient normalization, and structural similarity values. The model produced reconstructed images with L1 loss values averaging to <0.01 and gradient normalization values <0.1 after training finished. The reconstructed k spaces yielded structural similarity values of over 99% for both training and validation with the fully sampled k spaces, while validation loss continually decreased under 0.01. These data strongly support the idea that the algorithm works for MRI reconstruction, as they indicate the model's reconstructed image aligns extremely well with the original, fully sampled k space.

</p>
</details>

<details><summary><b>Dynamic Template Initialization for Part-Aware Person Re-ID</b>
<a href="https://arxiv.org/abs/2208.11440">arxiv:2208.11440</a>
&#x1F4C8; 2 <br>
<p>Kalana Abeywardena, Shechem Sumanthiran, Sanoojan Baliah, Nadarasar Bahavan, Nalith Udugampola, Ajith Pasqual, Chamira Edussooriya, Ranga Rodrigo</p></summary>
<p>

**Abstract:** Many of the existing Person Re-identification (Re-ID) approaches depend on feature maps which are either partitioned to localize parts of a person or reduced to create a global representation. While part localization has shown significant success, it uses either naıve position-based partitions or static feature templates. These, however, hypothesize the pre-existence of the parts in a given image or their positions, ignoring the input image-specific information which limits their usability in challenging scenarios such as Re-ID with partial occlusions and partial probe images. In this paper, we introduce a spatial attention-based Dynamic Part Template Initialization module that dynamically generates part-templates using mid-level semantic features at the earlier layers of the backbone. Following a self-attention layer, human part-level features of the backbone are used to extract the templates of diverse human body parts using a simplified cross-attention scheme which will then be used to identify and collate representations of various human parts from semantically rich features, increasing the discriminative ability of the entire model. We further explore adaptive weighting of part descriptors to quantify the absence or occlusion of local attributes and suppress the contribution of the corresponding part descriptors to the matching criteria. Extensive experiments on holistic, occluded, and partial Re-ID task benchmarks demonstrate that our proposed architecture is able to achieve competitive performance. Codes will be included in the supplementary material and will be made publicly available.

</p>
</details>

<details><summary><b>Explainable AI for tailored electricity consumption feedback -- an experimental evaluation of visualizations</b>
<a href="https://arxiv.org/abs/2208.11408">arxiv:2208.11408</a>
&#x1F4C8; 2 <br>
<p>Jacqueline Wastensteiner, Tobias M. Weiss, Felix Haag, Konstantin Hopf</p></summary>
<p>

**Abstract:** Machine learning (ML) methods can effectively analyse data, recognize patterns in them, and make high-quality predictions. Good predictions usually come along with "black-box" models that are unable to present the detected patterns in a human-readable way. Technical developments recently led to eXplainable Artificial Intelligence (XAI) techniques that aim to open such black-boxes and enable humans to gain new insights from detected patterns. We investigated the application of XAI in an area where specific insights can have a significant effect on consumer behaviour, namely electricity use. Knowing that specific feedback on individuals' electricity consumption triggers resource conservation, we created five visualizations with ML and XAI methods from electricity consumption time series for highly personalized feedback, considering existing domain-specific design knowledge. Our experimental evaluation with 152 participants showed that humans can assimilate the pattern displayed by XAI visualizations, but such visualizations should follow known visualization patterns to be well-understood by users.

</p>
</details>

<details><summary><b>Monetisation of and Access to in-Vehicle data and resources: the 5GMETA approach</b>
<a href="https://arxiv.org/abs/2208.11335">arxiv:2208.11335</a>
&#x1F4C8; 2 <br>
<p>Djibrilla Amadou Kountche, Fatma Raissi, Mandimby Ranaivo Rakotondravelona, Edoardo Bonetto, Daniele Brevi, Angel Martin, Oihana Otaegui, Gorka Velez</p></summary>
<p>

**Abstract:** Today's vehicles are increasingly embedded with computers and sensors which produce huge amount of data. The data are exploited for internal purposes and with the development of connected infrastructures and smart cities, the vehicles interact with each other as well as with road users generating other types of data. The access to these data and in-vehicle resources and their monetisation faces many challenges which are presented in this paper. Furthermore, the most important commercial solution compared to the open and novel approach faced in the H2020 5GMETA project.

</p>
</details>

<details><summary><b>Enhancing Deep Learning Performance of Massive MIMO CSI Feedback</b>
<a href="https://arxiv.org/abs/2208.11333">arxiv:2208.11333</a>
&#x1F4C8; 2 <br>
<p>Sijie Ji, Mo Li</p></summary>
<p>

**Abstract:** CSI feedback is an important problem of Massive multiple-input multiple-output (MIMO) technology because the feedback overhead is proportional to the number of sub-channels and the number of antennas, both of which scale with the size of the Massive MIMO system. Deep learning-based CSI feedback methods have been widely adopted recently owing to their superior performance. Despite the success, current approaches have not fully exploited the relationship between the characteristics of CSI data and the deep learning framework. In this paper, we propose a jigsaw puzzles aided training strategy (JPTS) to enhance the deep learning-based Massive MIMO CSI feedback approaches by maximizing mutual information between the original CSI and the compressed CSI. We apply JPTS on top of existing state-of-the-art methods. Experimental results show that by adopting this training strategy, the accuracy can be boosted by 12.07% and 7.01% on average in indoor and outdoor environments, respectively. The proposed method is ready to adopt to existing deep learning frameworks of Massive MIMO CSI feedback. Codes of JPTS are available on GitHub for reproducibility.

</p>
</details>

<details><summary><b>Multi-objective optimization of actuation waveform for high-precision drop-on-demand inkjet printing</b>
<a href="https://arxiv.org/abs/2208.11301">arxiv:2208.11301</a>
&#x1F4C8; 2 <br>
<p>Hanzhi Wang, Yosuke Hasegawa</p></summary>
<p>

**Abstract:** Drop-on-demand (DOD) inkjet printing has been considered as one of promising technologies for the fabrication of advanced functional materials. For a DOD printer, high-precision dispensing techniques for achieving satellite-free smaller droplets, have long been desired for patterning thin-film structures. The present study considers the inlet velocity of a liquid chamber located upstream of a dispensing nozzle as a control variable and aims to optimize its waveform using a sample-efficient Bayesian optimization algorithm. Firstly, the droplet dispensing dynamics are numerically reproduced by using an open-source OpenFOAM solver, interFoam, and the results are passed on to another code based on pyFoam. Then, the parameters characterizing the actuation waveform driving a DOD printer are determined by the Bayesian optimization (BO) algorithm so as to maximize a prescribed multi-objective function expressed as the sum of two factors, i.e., the size of a primary droplet and the presence of satellite droplets. The results show that the present BO algorithm can successfully find high-precision dispensing waveforms within 150 simulations. Specifically, satellite droplets can be effectively eliminated and the droplet diameter can be significantly reduced to 24.9% of the nozzle diameter by applying the optimal waveform.

</p>
</details>

<details><summary><b>On Differential Privacy for Federated Learning in Wireless Systems with Multiple Base Stations</b>
<a href="https://arxiv.org/abs/2208.11848">arxiv:2208.11848</a>
&#x1F4C8; 1 <br>
<p>Nima Tavangaran, Mingzhe Chen, Zhaohui Yang, José Mairton B. Da Silva Jr., H. Vincent Poor</p></summary>
<p>

**Abstract:** In this work, we consider a federated learning model in a wireless system with multiple base stations and inter-cell interference. We apply a differential private scheme to transmit information from users to their corresponding base station during the learning phase. We show the convergence behavior of the learning process by deriving an upper bound on its optimality gap. Furthermore, we define an optimization problem to reduce this upper bound and the total privacy leakage. To find the locally optimal solutions of this problem, we first propose an algorithm that schedules the resource blocks and users. We then extend this scheme to reduce the total privacy leakage by optimizing the differential privacy artificial noise. We apply the solutions of these two procedures as parameters of a federated learning system. In this setting, we assume that each user is equipped with a classifier. Moreover, the communication cells are assumed to have mostly fewer resource blocks than numbers of users. The simulation results show that our proposed scheduler improves the average accuracy of the predictions compared with a random scheduler. Furthermore, its extended version with noise optimizer significantly reduces the amount of privacy leakage.

</p>
</details>

<details><summary><b>CNN-based Prediction of Network Robustness With Missing Edges</b>
<a href="https://arxiv.org/abs/2208.11847">arxiv:2208.11847</a>
&#x1F4C8; 1 <br>
<p>Chengpei Wu, Yang Lou, Ruizi Wu, Wenwen Liu, Junli Li</p></summary>
<p>

**Abstract:** Connectivity and controllability of a complex network are two important issues that guarantee a networked system to function. Robustness of connectivity and controllability guarantees the system to function properly and stably under various malicious attacks. Evaluating network robustness using attack simulations is time consuming, while the convolutional neural network (CNN)-based prediction approach provides a cost-efficient method to approximate the network robustness. In this paper, we investigate the performance of CNN-based approaches for connectivity and controllability robustness prediction, when partial network information is missing, namely the adjacency matrix is incomplete. Extensive experimental studies are carried out. A threshold is explored that if a total amount of more than 7.29\% information is lost, the performance of CNN-based prediction will be significantly degenerated for all cases in the experiments. Two scenarios of missing edge representations are compared, 1) a missing edge is marked `no edge' in the input for prediction, and 2) a missing edge is denoted using a special marker of `unknown'. Experimental results reveal that the first representation is misleading to the CNN-based predictors.

</p>
</details>

<details><summary><b>Skeleton Prototype Contrastive Learning with Multi-Level Graph Relation Modeling for Unsupervised Person Re-Identification</b>
<a href="https://arxiv.org/abs/2208.11814">arxiv:2208.11814</a>
&#x1F4C8; 1 <br>
<p>Haocong Rao, Chunyan Miao</p></summary>
<p>

**Abstract:** Person re-identification (re-ID) via 3D skeletons is an important emerging topic with many merits. Existing solutions rarely explore valuable body-component relations in skeletal structure or motion, and they typically lack the ability to learn general representations with unlabeled skeleton data for person re-ID. This paper proposes a generic unsupervised Skeleton Prototype Contrastive learning paradigm with Multi-level Graph Relation learning (SPC-MGR) to learn effective representations from unlabeled skeletons to perform person re-ID. Specifically, we first construct unified multi-level skeleton graphs to fully model body structure within skeletons. Then we propose a multi-head structural relation layer to comprehensively capture relations of physically-connected body-component nodes in graphs. A full-level collaborative relation layer is exploited to infer collaboration between motion-related body parts at various levels, so as to capture rich body features and recognizable walking patterns. Lastly, we propose a skeleton prototype contrastive learning scheme that clusters feature-correlative instances of unlabeled graph representations and contrasts their inherent similarity with representative skeleton features ("skeleton prototypes") to learn discriminative skeleton representations for person re-ID. Empirical evaluations show that SPC-MGR significantly outperforms several state-of-the-art skeleton-based methods, and it also achieves highly competitive person re-ID performance for more general scenarios.

</p>
</details>

<details><summary><b>Learning from Unlabeled 3D Environments for Vision-and-Language Navigation</b>
<a href="https://arxiv.org/abs/2208.11781">arxiv:2208.11781</a>
&#x1F4C8; 1 <br>
<p>Shizhe Chen, Pierre-Louis Guhur, Makarand Tapaswi, Cordelia Schmid, Ivan Laptev</p></summary>
<p>

**Abstract:** In vision-and-language navigation (VLN), an embodied agent is required to navigate in realistic 3D environments following natural language instructions. One major bottleneck for existing VLN approaches is the lack of sufficient training data, resulting in unsatisfactory generalization to unseen environments. While VLN data is typically collected manually, such an approach is expensive and prevents scalability. In this work, we address the data scarcity issue by proposing to automatically create a large-scale VLN dataset from 900 unlabeled 3D buildings from HM3D. We generate a navigation graph for each building and transfer object predictions from 2D to generate pseudo 3D object labels by cross-view consistency. We then fine-tune a pretrained language model using pseudo object labels as prompts to alleviate the cross-modal gap in instruction generation. Our resulting HM3D-AutoVLN dataset is an order of magnitude larger than existing VLN datasets in terms of navigation environments and instructions. We experimentally demonstrate that HM3D-AutoVLN significantly increases the generalization ability of resulting VLN models. On the SPL metric, our approach improves over state of the art by 7.1% and 8.1% on the unseen validation splits of REVERIE and SOON datasets respectively.

</p>
</details>

<details><summary><b>Cats: Complementary CNN and Transformer Encoders for Segmentation</b>
<a href="https://arxiv.org/abs/2208.11572">arxiv:2208.11572</a>
&#x1F4C8; 1 <br>
<p>Hao Li, Dewei Hu, Han Liu, Jiacheng Wang, Ipek Oguz</p></summary>
<p>

**Abstract:** Recently, deep learning methods have achieved state-of-the-art performance in many medical image segmentation tasks. Many of these are based on convolutional neural networks (CNNs). For such methods, the encoder is the key part for global and local information extraction from input images; the extracted features are then passed to the decoder for predicting the segmentations. In contrast, several recent works show a superior performance with the use of transformers, which can better model long-range spatial dependencies and capture low-level details. However, transformer as sole encoder underperforms for some tasks where it cannot efficiently replace the convolution based encoder. In this paper, we propose a model with double encoders for 3D biomedical image segmentation. Our model is a U-shaped CNN augmented with an independent transformer encoder. We fuse the information from the convolutional encoder and the transformer, and pass it to the decoder to obtain the results. We evaluate our methods on three public datasets from three different challenges: BTCV, MoDA and Decathlon. Compared to the state-of-the-art models with and without transformers on each task, our proposed method obtains higher Dice scores across the board.

</p>
</details>

<details><summary><b>Adaptive QoS of WebRTC for Vehicular Media Communications</b>
<a href="https://arxiv.org/abs/2208.11405">arxiv:2208.11405</a>
&#x1F4C8; 1 <br>
<p>Ángel Martín, Daniel Mejías, Zaloa Fernández, Roberto Viola, Josu Pérez, Mikel García, Gorka Velez, Jon Montalbán, Pablo Angueira</p></summary>
<p>

**Abstract:** Vehicles shipping sensors for onboard systems are gaining connectivity. This enables information sharing to realize a more comprehensive understanding of the environment. However, peer communication through public cellular networks brings multiple networking hurdles to address, needing in-network systems to relay communications and connect parties that cannot connect directly. Web Real-Time Communication (WebRTC) is a good candidate for media streaming across vehicles as it enables low latency communications, while bringing standard protocols to security handshake, discovering public IPs and transverse Network Address Translation (NAT) systems. However, the end-to-end Quality of Service (QoS) adaptation in an infrastructure where transmission and reception are decoupled by a relay, needs a mechanism to adapt the video stream to the network capacity efficiently. To this end, this paper investigates a mechanism to apply changes on resolution, framerate and bitrate by exploiting the Real Time Transport Control Protocol (RTCP) metrics, such as bandwidth and round-trip time. The solution aims to ensure that the receiving onboard system gets relevant information in time. The impact on end-to-end throughput efficiency and reaction time when applying different approaches to QoS adaptation are analyzed in a real 5G testbed.

</p>
</details>

<details><summary><b>GAN-based generative modelling for dermatological applications -- comparative study</b>
<a href="https://arxiv.org/abs/2208.11702">arxiv:2208.11702</a>
&#x1F4C8; 0 <br>
<p>Sandra Carrasco Limeros, Sylwia Majchrowska, Mohamad Khir Zoubi, Anna Rosén, Juulia Suvilehto, Lisa Sjöblom, Magnus Kjellberg</p></summary>
<p>

**Abstract:** The lack of sufficiently large open medical databases is one of the biggest challenges in AI-powered healthcare. Synthetic data created using Generative Adversarial Networks (GANs) appears to be a good solution to mitigate the issues with privacy policies. The other type of cure is decentralized protocol across multiple medical institutions without exchanging local data samples. In this paper, we explored unconditional and conditional GANs in centralized and decentralized settings. The centralized setting imitates studies on large but highly unbalanced skin lesion dataset, while the decentralized one simulates a more realistic hospital scenario with three institutions. We evaluated models' performance in terms of fidelity, diversity, speed of training, and predictive ability of classifiers trained on the generated synthetic data. In addition we provided explainability through exploration of latent space and embeddings projection focused both on global and local explanations. Calculated distance between real images and their projections in the latent space proved the authenticity and generalization of trained GANs, which is one of the main concerns in this type of applications. The open source code for conducted studies is publicly available at \url{https://github.com/aidotse/stylegan2-ada-pytorch}.

</p>
</details>

<details><summary><b>Data-Driven Approach to form Energy Resilient Smart Microgrids with Identification of Vulnerable Nodes in Active Electrical Distribution Network</b>
<a href="https://arxiv.org/abs/2208.11682">arxiv:2208.11682</a>
&#x1F4C8; 0 <br>
<p>D Maneesh Reddy, Divyanshi Dwivedi, Pradeep Kumar Yemula, Mayukha Pal</p></summary>
<p>

**Abstract:** We propose a methodology for identifying the optimal DERs allocation with vulnerable node identification into consideration in active electrical distribution network and named those nodes as critical nodes. Power variation in these critical nodes would significantly affect the operation of other linked nodes, thus these nodes are suitable and considered optimal for DERs placement. We demonstrated our method evaluation in a standard IEEE-123 test feeder system. Initially, we partitioned the distribution system into optimal microgrid networks using graph theory. The partitioning was validated using graph neural network architecture for suitable formation of the microgrids. Further, using an effective measurable causality analysis like granger causality, we identified critical nodes in the partitioned microgrid and placement of DERs on these nodes resulted in enhanced network reliability and resiliency. Further, to validate the system performance and energy resiliency, we computed percolation threshold for the microgrid network that indicates the system resiliency after incorporating DERs at those critical nodes. This proposed methodology for the first ensures effective microgrid partitioning, identification of critical nodes, optimal DERs allocation and system resiliency evaluation through data driven analysis approach in a distribution network.

</p>
</details>

<details><summary><b>Augmented cross-selling through explainable AI -- a case from energy retailing</b>
<a href="https://arxiv.org/abs/2208.11404">arxiv:2208.11404</a>
&#x1F4C8; 0 <br>
<p>Felix Haag, Konstantin Hopf, Pedro Menelau Vasconcelos, Thorsten Staake</p></summary>
<p>

**Abstract:** The advance of Machine Learning (ML) has led to a strong interest in this technology to support decision making. While complex ML models provide predictions that are often more accurate than those of traditional tools, such models often hide the reasoning behind the prediction from their users, which can lead to lower adoption and lack of insight. Motivated by this tension, research has put forth Explainable Artificial Intelligence (XAI) techniques that uncover patterns discovered by ML. Despite the high hopes in both ML and XAI, there is little empirical evidence of the benefits to traditional businesses. To this end, we analyze data on 220,185 customers of an energy retailer, predict cross-purchases with up to 86% correctness (AUC), and show that the XAI method SHAP provides explanations that hold for actual buyers. We further outline implications for research in information systems, XAI, and relationship marketing.

</p>
</details>

<details><summary><b>Formation control with connectivity assurance for missile swarm: a natural co-evolutionary strategy approach</b>
<a href="https://arxiv.org/abs/2208.11347">arxiv:2208.11347</a>
&#x1F4C8; 0 <br>
<p>Junda Chen</p></summary>
<p>

**Abstract:** Formation control problem is one of the most concerned topics within the realm of swarm intelligence, which is usually solved by conventional mathematical approaches. In this paper, however, we presents a metaheuristic approach that leverages a natural co-evolutionary strategy to solve the formation control problem for a swarm of missiles. The missile swarm is modeled by a second-order system with heterogeneous reference target, and exponential error function is made to be the objective function such that the swarm converge to optimal equilibrium states satisfying certain formation requirements. Focusing on the issue of local optimum and unstable evolution, we incorporate a novel model-based policy constraint and a population adaptation strategies that greatly alleviates the performance degradation. With application of the Molloy-Reed criterion in the field of network communication, we developed an adaptive topology method that assure the connectivity under node failure and its effectiveness are validated both theoretically and experimentally. Experimental results valid the effectiveness of the proposed formation control approach. More significantly, we showed that it is feasible to treat generic formation control problem as Markov Decision Process(MDP) and solve it through iterative learning.

</p>
</details>


{% endraw %}
Prev: [2022.08.23]({{ '/2022/08/23/2022.08.23.html' | relative_url }})  Next: [2022.08.25]({{ '/2022/08/25/2022.08.25.html' | relative_url }})