## Summary for 2021-03-31, created on 2021-12-23


<details><summary><b>StyleCLIP: Text-Driven Manipulation of StyleGAN Imagery</b>
<a href="https://arxiv.org/abs/2103.17249">arxiv:2103.17249</a>
&#x1F4C8; 199 <br>
<p>Or Patashnik, Zongze Wu, Eli Shechtman, Daniel Cohen-Or, Dani Lischinski</p></summary>
<p>

**Abstract:** Inspired by the ability of StyleGAN to generate highly realistic images in a variety of domains, much recent work has focused on understanding how to use the latent spaces of StyleGAN to manipulate generated and real images. However, discovering semantically meaningful latent manipulations typically involves painstaking human examination of the many degrees of freedom, or an annotated collection of images for each desired manipulation. In this work, we explore leveraging the power of recently introduced Contrastive Language-Image Pre-training (CLIP) models in order to develop a text-based interface for StyleGAN image manipulation that does not require such manual effort. We first introduce an optimization scheme that utilizes a CLIP-based loss to modify an input latent vector in response to a user-provided text prompt. Next, we describe a latent mapper that infers a text-guided latent manipulation step for a given input image, allowing faster and more stable text-based manipulation. Finally, we present a method for mapping a text prompts to input-agnostic directions in StyleGAN's style space, enabling interactive text-driven image manipulation. Extensive results and comparisons demonstrate the effectiveness of our approaches.

</p>
</details>

<details><summary><b>Why is AI hard and Physics simple?</b>
<a href="https://arxiv.org/abs/2104.00008">arxiv:2104.00008</a>
&#x1F4C8; 83 <br>
<p>Daniel A. Roberts</p></summary>
<p>

**Abstract:** We discuss why AI is hard and why physics is simple. We discuss how physical intuition and the approach of theoretical physics can be brought to bear on the field of artificial intelligence and specifically machine learning. We suggest that the underlying project of machine learning and the underlying project of physics are strongly coupled through the principle of sparsity, and we call upon theoretical physicists to work on AI as physicists. As a first step in that direction, we discuss an upcoming book on the principles of deep learning theory that attempts to realize this approach.

</p>
</details>

<details><summary><b>Fitting Elephants</b>
<a href="https://arxiv.org/abs/2104.00526">arxiv:2104.00526</a>
&#x1F4C8; 66 <br>
<p>Partha P Mitra</p></summary>
<p>

**Abstract:** Textbook wisdom advocates for smooth function fits and implies that interpolation of noisy data should lead to poor generalization. A related heuristic is that fitting parameters should be fewer than measurements (Occam's Razor). Surprisingly, contemporary machine learning (ML) approaches, cf. deep nets (DNNs), generalize well despite interpolating noisy data. This may be understood via Statistically Consistent Interpolation (SCI), i.e. data interpolation techniques that generalize optimally for big data. In this article we elucidate SCI using the weighted interpolating nearest neighbors (wiNN) algorithm, which adds singular weight functions to kNN (k-nearest neighbors). This shows that data interpolation can be a valid ML strategy for big data. SCI clarifies the relation between two ways of modeling natural phenomena: the rationalist approach (strong priors) of theoretical physics with few parameters and the empiricist (weak priors) approach of modern ML with more parameters than data. SCI shows that the purely empirical approach can successfully predict. However data interpolation does not provide theoretical insights, and the training data requirements may be prohibitive. Complex animal brains are between these extremes, with many parameters, but modest training data, and with prior structure encoded in species-specific mesoscale circuitry. Thus, modern ML provides a distinct epistemological approach different both from physical theories and animal brains.

</p>
</details>

<details><summary><b>Rethinking Style Transfer: From Pixels to Parameterized Brushstrokes</b>
<a href="https://arxiv.org/abs/2103.17185">arxiv:2103.17185</a>
&#x1F4C8; 45 <br>
<p>Dmytro Kotovenko, Matthias Wright, Arthur Heimbrecht, Bj√∂rn Ommer</p></summary>
<p>

**Abstract:** There have been many successful implementations of neural style transfer in recent years. In most of these works, the stylization process is confined to the pixel domain. However, we argue that this representation is unnatural because paintings usually consist of brushstrokes rather than pixels. We propose a method to stylize images by optimizing parameterized brushstrokes instead of pixels and further introduce a simple differentiable rendering mechanism. Our approach significantly improves visual quality and enables additional control over the stylization process such as controlling the flow of brushstrokes through user input. We provide qualitative and quantitative evaluations that show the efficacy of the proposed parameterized representation.

</p>
</details>

<details><summary><b>Rainbow Memory: Continual Learning with a Memory of Diverse Samples</b>
<a href="https://arxiv.org/abs/2103.17230">arxiv:2103.17230</a>
&#x1F4C8; 28 <br>
<p>Jihwan Bang, Heesu Kim, YoungJoon Yoo, Jung-Woo Ha, Jonghyun Choi</p></summary>
<p>

**Abstract:** Continual learning is a realistic learning scenario for AI models. Prevalent scenario of continual learning, however, assumes disjoint sets of classes as tasks and is less realistic rather artificial. Instead, we focus on 'blurry' task boundary; where tasks shares classes and is more realistic and practical. To address such task, we argue the importance of diversity of samples in an episodic memory. To enhance the sample diversity in the memory, we propose a novel memory management strategy based on per-sample classification uncertainty and data augmentation, named Rainbow Memory (RM). With extensive empirical validations on MNIST, CIFAR10, CIFAR100, and ImageNet datasets, we show that the proposed method significantly improves the accuracy in blurry continual learning setups, outperforming state of the arts by large margins despite its simplicity. Code and data splits will be available in https://github.com/clovaai/rainbow-memory.

</p>
</details>

<details><summary><b>Neural Response Interpretation through the Lens of Critical Pathways</b>
<a href="https://arxiv.org/abs/2103.16886">arxiv:2103.16886</a>
&#x1F4C8; 26 <br>
<p>Ashkan Khakzar, Soroosh Baselizadeh, Saurabh Khanduja, Christian Rupprecht, Seong Tae Kim, Nassir Navab</p></summary>
<p>

**Abstract:** Is critical input information encoded in specific sparse pathways within the neural network? In this work, we discuss the problem of identifying these critical pathways and subsequently leverage them for interpreting the network's response to an input. The pruning objective -- selecting the smallest group of neurons for which the response remains equivalent to the original network -- has been previously proposed for identifying critical pathways. We demonstrate that sparse pathways derived from pruning do not necessarily encode critical input information. To ensure sparse pathways include critical fragments of the encoded input information, we propose pathway selection via neurons' contribution to the response. We proceed to explain how critical pathways can reveal critical input features. We prove that pathways selected via neuron contribution are locally linear (in an L2-ball), a property that we use for proposing a feature attribution method: "pathway gradient". We validate our interpretation method using mainstream evaluation experiments. The validation of pathway gradient interpretation method further confirms that selected pathways using neuron contributions correspond to critical input features. The code is publicly available.

</p>
</details>

<details><summary><b>Learning Generalizable Robotic Reward Functions from "In-The-Wild" Human Videos</b>
<a href="https://arxiv.org/abs/2103.16817">arxiv:2103.16817</a>
&#x1F4C8; 24 <br>
<p>Annie S. Chen, Suraj Nair, Chelsea Finn</p></summary>
<p>

**Abstract:** We are motivated by the goal of generalist robots that can complete a wide range of tasks across many environments. Critical to this is the robot's ability to acquire some metric of task success or reward, which is necessary for reinforcement learning, planning, or knowing when to ask for help. For a general-purpose robot operating in the real world, this reward function must also be able to generalize broadly across environments, tasks, and objects, while depending only on on-board sensor observations (e.g. RGB images). While deep learning on large and diverse datasets has shown promise as a path towards such generalization in computer vision and natural language, collecting high quality datasets of robotic interaction at scale remains an open challenge. In contrast, "in-the-wild" videos of humans (e.g. YouTube) contain an extensive collection of people doing interesting tasks across a diverse range of settings. In this work, we propose a simple approach, Domain-agnostic Video Discriminator (DVD), that learns multitask reward functions by training a discriminator to classify whether two videos are performing the same task, and can generalize by virtue of learning from a small amount of robot data with a broad dataset of human videos. We find that by leveraging diverse human datasets, this reward function (a) can generalize zero shot to unseen environments, (b) generalize zero shot to unseen tasks, and (c) can be combined with visual model predictive control to solve robotic manipulation tasks on a real WidowX200 robot in an unseen environment from a single human demo.

</p>
</details>

<details><summary><b>A Neighbourhood Framework for Resource-Lean Content Flagging</b>
<a href="https://arxiv.org/abs/2103.17055">arxiv:2103.17055</a>
&#x1F4C8; 22 <br>
<p>Sheikh Muhammad Sarwar, Dimitrina Zlatkova, Momchil Hardalov, Yoan Dinkov, Isabelle Augenstein, Preslav Nakov</p></summary>
<p>

**Abstract:** We propose a novel framework for cross-lingual content flagging with limited target-language data, which significantly outperforms prior work in terms of predictive performance. The framework is based on a nearest-neighbour architecture. It is a modern instantiation of the vanilla k-nearest neighbour model, as we use Transformer representations in all its components. Our framework can adapt to new source language instances, without the need to be retrained from scratch. Unlike prior work on neighbourhood based approaches, we encode the neighbourhood information based on query-neighbour interactions. We propose two encoding schemes and show their effectiveness using both qualitative and quantitative analyses. Our evaluation results on eight languages from two different datasets for abusive language detection show sizable improvements of up to 9.5 (for the Italian language) in F1 over strong baselines. On average we achieve 3.6 improvements in F1 for the three languages in the Jigsaw Multilingual dataset and 2.14 improvements in F1 for the WUL dataset.

</p>
</details>

<details><summary><b>Quantum Optimization for Training Quantum Neural Networks</b>
<a href="https://arxiv.org/abs/2103.17047">arxiv:2103.17047</a>
&#x1F4C8; 19 <br>
<p>Yidong Liao, Min-Hsiu Hsieh, Chris Ferrie</p></summary>
<p>

**Abstract:** Training quantum neural networks (QNNs) using gradient-based or gradient-free classical optimisation approaches is severely impacted by the presence of barren plateaus in the cost landscapes. In this paper, we devise a framework for leveraging quantum optimisation algorithms to find optimal parameters of QNNs for certain tasks. To achieve this, we coherently encode the cost function of QNNs onto relative phases of a superposition state in the Hilbert space of the network parameters. The parameters are tuned with an iterative quantum optimisation structure using adaptively selected Hamiltonians. The quantum mechanism of this framework exploits hidden structure in the QNN optimisation problem and hence is expected to provide beyond-Grover speed up, mitigating the barren plateau issue.

</p>
</details>

<details><summary><b>CAMPARI: Camera-Aware Decomposed Generative Neural Radiance Fields</b>
<a href="https://arxiv.org/abs/2103.17269">arxiv:2103.17269</a>
&#x1F4C8; 16 <br>
<p>Michael Niemeyer, Andreas Geiger</p></summary>
<p>

**Abstract:** Tremendous progress in deep generative models has led to photorealistic image synthesis. While achieving compelling results, most approaches operate in the two-dimensional image domain, ignoring the three-dimensional nature of our world. Several recent works therefore propose generative models which are 3D-aware, i.e., scenes are modeled in 3D and then rendered differentiably to the image plane. This leads to impressive 3D consistency, but incorporating such a bias comes at a price: the camera needs to be modeled as well. Current approaches assume fixed intrinsics and a predefined prior over camera pose ranges. As a result, parameter tuning is typically required for real-world data, and results degrade if the data distribution is not matched. Our key hypothesis is that learning a camera generator jointly with the image generator leads to a more principled approach to 3D-aware image synthesis. Further, we propose to decompose the scene into a background and foreground model, leading to more efficient and disentangled scene representations. While training from raw, unposed image collections, we learn a 3D- and camera-aware generative model which faithfully recovers not only the image but also the camera data distribution. At test time, our model generates images with explicit control over the camera as well as the shape and appearance of the scene.

</p>
</details>

<details><summary><b>SRA-LSTM: Social Relationship Attention LSTM for Human Trajectory Prediction</b>
<a href="https://arxiv.org/abs/2103.17045">arxiv:2103.17045</a>
&#x1F4C8; 15 <br>
<p>Yusheng Peng, Gaofeng Zhang, Jun Shi, Benzhu Xu, Liping Zheng</p></summary>
<p>

**Abstract:** Pedestrian trajectory prediction for surveillance video is one of the important research topics in the field of computer vision and a key technology of intelligent surveillance systems. Social relationship among pedestrians is a key factor influencing pedestrian walking patterns but was mostly ignored in the literature. Pedestrians with different social relationships play different roles in the motion decision of target pedestrian. Motivated by this idea, we propose a Social Relationship Attention LSTM (SRA-LSTM) model to predict future trajectories. We design a social relationship encoder to obtain the representation of their social relationship through the relative position between each pair of pedestrians. Afterwards, the social relationship feature and latent movements are adopted to acquire the social relationship attention of this pair of pedestrians. Social interaction modeling is achieved by utilizing social relationship attention to aggregate movement information from neighbor pedestrians. Experimental results on two public walking pedestrian video datasets (ETH and UCY), our model achieves superior performance compared with state-of-the-art methods. Contrast experiments with other attention methods also demonstrate the effectiveness of social relationship attention.

</p>
</details>

<details><summary><b>GrooMeD-NMS: Grouped Mathematically Differentiable NMS for Monocular 3D Object Detection</b>
<a href="https://arxiv.org/abs/2103.17202">arxiv:2103.17202</a>
&#x1F4C8; 14 <br>
<p>Abhinav Kumar, Garrick Brazil, Xiaoming Liu</p></summary>
<p>

**Abstract:** Modern 3D object detectors have immensely benefited from the end-to-end learning idea. However, most of them use a post-processing algorithm called Non-Maximal Suppression (NMS) only during inference. While there were attempts to include NMS in the training pipeline for tasks such as 2D object detection, they have been less widely adopted due to a non-mathematical expression of the NMS. In this paper, we present and integrate GrooMeD-NMS -- a novel Grouped Mathematically Differentiable NMS for monocular 3D object detection, such that the network is trained end-to-end with a loss on the boxes after NMS. We first formulate NMS as a matrix operation and then group and mask the boxes in an unsupervised manner to obtain a simple closed-form expression of the NMS. GrooMeD-NMS addresses the mismatch between training and inference pipelines and, therefore, forces the network to select the best 3D box in a differentiable manner. As a result, GrooMeD-NMS achieves state-of-the-art monocular 3D object detection results on the KITTI benchmark dataset performing comparably to monocular video-based methods. Code and models at https://github.com/abhi1kumar/groomed_nms

</p>
</details>

<details><summary><b>Collaborative Learning to Generate Audio-Video Jointly</b>
<a href="https://arxiv.org/abs/2104.02656">arxiv:2104.02656</a>
&#x1F4C8; 10 <br>
<p>Vinod K Kurmi, Vipul Bajaj, Badri N Patro, K S Venkatesh, Vinay P Namboodiri, Preethi Jyothi</p></summary>
<p>

**Abstract:** There have been a number of techniques that have demonstrated the generation of multimedia data for one modality at a time using GANs, such as the ability to generate images, videos, and audio. However, so far, the task of multi-modal generation of data, specifically for audio and videos both, has not been sufficiently well-explored. Towards this, we propose a method that demonstrates that we are able to generate naturalistic samples of video and audio data by the joint correlated generation of audio and video modalities. The proposed method uses multiple discriminators to ensure that the audio, video, and the joint output are also indistinguishable from real-world samples. We present a dataset for this task and show that we are able to generate realistic samples. This method is validated using various standard metrics such as Inception Score, Frechet Inception Distance (FID) and through human evaluation.

</p>
</details>

<details><summary><b>LIFT-SLAM: a deep-learning feature-based monocular visual SLAM method</b>
<a href="https://arxiv.org/abs/2104.00099">arxiv:2104.00099</a>
&#x1F4C8; 10 <br>
<p>Hudson M. S. Bruno, Esther L. Colombini</p></summary>
<p>

**Abstract:** The Simultaneous Localization and Mapping (SLAM) problem addresses the possibility of a robot to localize itself in an unknown environment and simultaneously build a consistent map of this environment. Recently, cameras have been successfully used to get the environment's features to perform SLAM, which is referred to as visual SLAM (VSLAM). However, classical VSLAM algorithms can be easily induced to fail when either the motion of the robot or the environment is too challenging. Although new approaches based on Deep Neural Networks (DNNs) have achieved promising results in VSLAM, they still are unable to outperform traditional methods. To leverage the robustness of deep learning to enhance traditional VSLAM systems, we propose to combine the potential of deep learning-based feature descriptors with the traditional geometry-based VSLAM, building a new VSLAM system called LIFT-SLAM. Experiments conducted on KITTI and Euroc datasets show that deep learning can be used to improve the performance of traditional VSLAM systems, as the proposed approach was able to achieve results comparable to the state-of-the-art while being robust to sensorial noise. We enhance the proposed VSLAM pipeline by avoiding parameter tuning for specific datasets with an adaptive approach while evaluating how transfer learning can affect the quality of the features extracted.

</p>
</details>

<details><summary><b>Co-Adaptation of Algorithmic and Implementational Innovations in Inference-based Deep Reinforcement Learning</b>
<a href="https://arxiv.org/abs/2103.17258">arxiv:2103.17258</a>
&#x1F4C8; 9 <br>
<p>Hiroki Furuta, Tadashi Kozuno, Tatsuya Matsushima, Yutaka Matsuo, Shixiang Shane Gu</p></summary>
<p>

**Abstract:** Recently many algorithms were devised for reinforcement learning (RL) with function approximation. While they have clear algorithmic distinctions, they also have many implementation differences that are algorithm-independent and sometimes under-emphasized. Such mixing of algorithmic novelty and implementation craftsmanship makes rigorous analyses of the sources of performance improvements across algorithms difficult. In this work, we focus on a series of off-policy inference-based actor-critic algorithms -- MPO, AWR, and SAC -- to decouple their algorithmic innovations and implementation decisions. We present unified derivations through a single control-as-inference objective, where we can categorize each algorithm as based on either Expectation-Maximization (EM) or direct Kullback-Leibler (KL) divergence minimization and treat the rest of specifications as implementation details. We performed extensive ablation studies, and identified substantial performance drops whenever implementation details are mismatched for algorithmic choices. These results show which implementation or code details are co-adapted and co-evolved with algorithms, and which are transferable across algorithms: as examples, we identified that tanh Gaussian policy and network sizes are highly adapted to algorithmic types, while layer normalization and ELU are critical for MPO's performances but also transfer to noticeable gains in SAC. We hope our work can inspire future work to further demystify sources of performance improvements across multiple algorithms and allow researchers to build on one another's both algorithmic and implementational innovations.

</p>
</details>

<details><summary><b>Hierarchical Road Topology Learning for Urban Map-less Driving</b>
<a href="https://arxiv.org/abs/2104.00084">arxiv:2104.00084</a>
&#x1F4C8; 8 <br>
<p>Li Zhang, Faezeh Tafazzoli, Gunther Krehl, Runsheng Xu, Timo Rehfeld, Manuel Schier, Arunava Seal</p></summary>
<p>

**Abstract:** The majority of current approaches in autonomous driving rely on High-Definition (HD) maps which detail the road geometry and surrounding area. Yet, this reliance is one of the obstacles to mass deployment of autonomous vehicles due to poor scalability of such prior maps. In this paper, we tackle the problem of online road map extraction via leveraging the sensory system aboard the vehicle itself. To this end, we design a structured model where a graph representation of the road network is generated in a hierarchical fashion within a fully convolutional network. The method is able to handle complex road topology and does not require a user in the loop.

</p>
</details>

<details><summary><b>Learning with Memory-based Virtual Classes for Deep Metric Learning</b>
<a href="https://arxiv.org/abs/2103.16940">arxiv:2103.16940</a>
&#x1F4C8; 8 <br>
<p>Byungsoo Ko, Geonmo Gu, Han-Gyu Kim</p></summary>
<p>

**Abstract:** The core of deep metric learning (DML) involves learning visual similarities in high-dimensional embedding space. One of the main challenges is to generalize from seen classes of training data to unseen classes of test data. Recent works have focused on exploiting past embeddings to increase the number of instances for the seen classes. Such methods achieve performance improvement via augmentation, while the strong focus on seen classes still remains. This can be undesirable for DML, where training and test data exhibit entirely different classes. In this work, we present a novel training strategy for DML called MemVir. Unlike previous works, MemVir memorizes both embedding features and class weights to utilize them as additional virtual classes. The exploitation of virtual classes not only utilizes augmented information for training but also alleviates a strong focus on seen classes for better generalization. Moreover, we embed the idea of curriculum learning by slowly adding virtual classes for a gradual increase in learning difficulty, which improves the learning stability as well as the final performance. MemVir can be easily applied to many existing loss functions without any modification. Extensive experimental results on famous benchmarks demonstrate the superiority of MemVir over state-of-the-art competitors. Code of MemVir is publicly available.

</p>
</details>

<details><summary><b>Auto-KWS 2021 Challenge: Task, Datasets, and Baselines</b>
<a href="https://arxiv.org/abs/2104.00513">arxiv:2104.00513</a>
&#x1F4C8; 7 <br>
<p>Jingsong Wang, Yuxuan He, Chunyu Zhao, Qijie Shao, Wei-Wei Tu, Tom Ko, Hung-yi Lee, Lei Xie</p></summary>
<p>

**Abstract:** Auto-KWS 2021 challenge calls for automated machine learning (AutoML) solutions to automate the process of applying machine learning to a customized keyword spotting task. Compared with other keyword spotting tasks, Auto-KWS challenge has the following three characteristics: 1) The challenge focuses on the problem of customized keyword spotting, where the target device can only be awakened by an enrolled speaker with his specified keyword. The speaker can use any language and accent to define his keyword. 2) All dataset of the challenge is recorded in realistic environment. It is to simulate different user scenarios. 3) Auto-KWS is a "code competition", where participants need to submit AutoML solutions, then the platform automatically runs the enrollment and prediction steps with the submitted code.This challenge aims at promoting the development of a more personalized and flexible keyword spotting system. Two baseline systems are provided to all participants as references.

</p>
</details>

<details><summary><b>LaPred: Lane-Aware Prediction of Multi-Modal Future Trajectories of Dynamic Agents</b>
<a href="https://arxiv.org/abs/2104.00249">arxiv:2104.00249</a>
&#x1F4C8; 7 <br>
<p>ByeoungDo Kim, Seong Hyeon Park, Seokhwan Lee, Elbek Khoshimjonov, Dongsuk Kum, Junsoo Kim, Jeong Soo Kim, Jun Won Choi</p></summary>
<p>

**Abstract:** In this paper, we address the problem of predicting the future motion of a dynamic agent (called a target agent) given its current and past states as well as the information on its environment. It is paramount to develop a prediction model that can exploit the contextual information in both static and dynamic environments surrounding the target agent and generate diverse trajectory samples that are meaningful in a traffic context. We propose a novel prediction model, referred to as the lane-aware prediction (LaPred) network, which uses the instance-level lane entities extracted from a semantic map to predict the multi-modal future trajectories. For each lane candidate found in the neighborhood of the target agent, LaPred extracts the joint features relating the lane and the trajectories of the neighboring agents. Then, the features for all lane candidates are fused with the attention weights learned through a self-supervised learning task that identifies the lane candidate likely to be followed by the target agent. Using the instance-level lane information, LaPred can produce the trajectories compliant with the surroundings better than 2D raster image-based methods and generate the diverse future trajectories given multiple lane candidates. The experiments conducted on the public nuScenes dataset and Argoverse dataset demonstrate that the proposed LaPred method significantly outperforms the existing prediction models, achieving state-of-the-art performance in the benchmarks.

</p>
</details>

<details><summary><b>An Investigation of Critical Issues in Bias Mitigation Techniques</b>
<a href="https://arxiv.org/abs/2104.00170">arxiv:2104.00170</a>
&#x1F4C8; 7 <br>
<p>Robik Shrestha, Kushal Kafle, Christopher Kanan</p></summary>
<p>

**Abstract:** A critical problem in deep learning is that systems learn inappropriate biases, resulting in their inability to perform well on minority groups. This has led to the creation of multiple algorithms that endeavor to mitigate bias. However, it is not clear how effective these methods are. This is because study protocols differ among papers, systems are tested on datasets that fail to test many forms of bias, and systems have access to hidden knowledge or are tuned specifically to the test set. To address this, we introduce an improved evaluation protocol, sensible metrics, and a new dataset, which enables us to ask and answer critical questions about bias mitigation algorithms. We evaluate seven state-of-the-art algorithms using the same network architecture and hyperparameter selection policy across three benchmark datasets. We introduce a new dataset called Biased MNIST that enables assessment of robustness to multiple bias sources. We use Biased MNIST and a visual question answering (VQA) benchmark to assess robustness to hidden biases. Rather than only tuning to the test set distribution, we study robustness across different tuning distributions, which is critical because for many applications the test distribution may not be known during development. We find that algorithms exploit hidden biases, are unable to scale to multiple forms of bias, and are highly sensitive to the choice of tuning set. Based on our findings, we implore the community to adopt more rigorous assessment of future bias mitigation methods. All data, code, and results are publicly available at: https://github.com/erobic/bias-mitigators.

</p>
</details>

<details><summary><b>Deep adaptive fuzzy clustering for evolutionary unsupervised representation learning</b>
<a href="https://arxiv.org/abs/2103.17086">arxiv:2103.17086</a>
&#x1F4C8; 7 <br>
<p>Dayu Tan, Zheng Huang, Xin Peng, Weimin Zhong, Vladimir Mahalec</p></summary>
<p>

**Abstract:** Cluster assignment of large and complex images is a crucial but challenging task in pattern recognition and computer vision. In this study, we explore the possibility of employing fuzzy clustering in a deep neural network framework. Thus, we present a novel evolutionary unsupervised learning representation model with iterative optimization. It implements the deep adaptive fuzzy clustering (DAFC) strategy that learns a convolutional neural network classifier from given only unlabeled data samples. DAFC consists of a deep feature quality-verifying model and a fuzzy clustering model, where deep feature representation learning loss function and embedded fuzzy clustering with the weighted adaptive entropy is implemented. We joint fuzzy clustering to the deep reconstruction model, in which fuzzy membership is utilized to represent a clear structure of deep cluster assignments and jointly optimize for the deep representation learning and clustering. Also, the joint model evaluates current clustering performance by inspecting whether the re-sampled data from estimated bottleneck space have consistent clustering properties to progressively improve the deep clustering model. Comprehensive experiments on a variety of datasets show that the proposed method obtains a substantially better performance for both reconstruction and clustering quality when compared to the other state-of-the-art deep clustering methods, as demonstrated with the in-depth analysis in the extensive experiments.

</p>
</details>

<details><summary><b>Trusted Artificial Intelligence: Towards Certification of Machine Learning Applications</b>
<a href="https://arxiv.org/abs/2103.16910">arxiv:2103.16910</a>
&#x1F4C8; 7 <br>
<p>Philip Matthias Winter, Sebastian Eder, Johannes Weissenb√∂ck, Christoph Schwald, Thomas Doms, Tom Vogt, Sepp Hochreiter, Bernhard Nessler</p></summary>
<p>

**Abstract:** Artificial Intelligence is one of the fastest growing technologies of the 21st century and accompanies us in our daily lives when interacting with technical applications. However, reliance on such technical systems is crucial for their widespread applicability and acceptance. The societal tools to express reliance are usually formalized by lawful regulations, i.e., standards, norms, accreditations, and certificates. Therefore, the T√úV AUSTRIA Group in cooperation with the Institute for Machine Learning at the Johannes Kepler University Linz, proposes a certification process and an audit catalog for Machine Learning applications. We are convinced that our approach can serve as the foundation for the certification of applications that use Machine Learning and Deep Learning, the techniques that drive the current revolution in Artificial Intelligence. While certain high-risk areas, such as fully autonomous robots in workspaces shared with humans, are still some time away from certification, we aim to cover low-risk applications with our certification procedure. Our holistic approach attempts to analyze Machine Learning applications from multiple perspectives to evaluate and verify the aspects of secure software development, functional requirements, data quality, data protection, and ethics. Inspired by existing work, we introduce four criticality levels to map the criticality of a Machine Learning application regarding the impact of its decisions on people, environment, and organizations. Currently, the audit catalog can be applied to low-risk applications within the scope of supervised learning as commonly encountered in industry. Guided by field experience, scientific developments, and market demands, the audit catalog will be extended and modified accordingly.

</p>
</details>

<details><summary><b>An Energy-Efficient Quad-Camera Visual System for Autonomous Machines on FPGA Platform</b>
<a href="https://arxiv.org/abs/2104.00192">arxiv:2104.00192</a>
&#x1F4C8; 6 <br>
<p>Zishen Wan, Yuyang Zhang, Arijit Raychowdhury, Bo Yu, Yanjun Zhang, Shaoshan Liu</p></summary>
<p>

**Abstract:** In our past few years' of commercial deployment experiences, we identify localization as a critical task in autonomous machine applications, and a great acceleration target. In this paper, based on the observation that the visual frontend is a major performance and energy consumption bottleneck, we present our design and implementation of an energy-efficient hardware architecture for ORB (Oriented-Fast and Rotated- BRIEF) based localization system on FPGAs. To support our multi-sensor autonomous machine localization system, we present hardware synchronization, frame-multiplexing, and parallelization techniques, which are integrated in our design. Compared to Nvidia TX1 and Intel i7, our FPGA-based implementation achieves 5.6x and 3.4x speedup, as well as 3.0x and 34.6x power reduction, respectively.

</p>
</details>

<details><summary><b>LazyDAgger: Reducing Context Switching in Interactive Imitation Learning</b>
<a href="https://arxiv.org/abs/2104.00053">arxiv:2104.00053</a>
&#x1F4C8; 6 <br>
<p>Ryan Hoque, Ashwin Balakrishna, Carl Putterman, Michael Luo, Daniel S. Brown, Daniel Seita, Brijen Thananjeyan, Ellen Novoseller, Ken Goldberg</p></summary>
<p>

**Abstract:** Corrective interventions while a robot is learning to automate a task provide an intuitive method for a human supervisor to assist the robot and convey information about desired behavior. However, these interventions can impose significant burden on a human supervisor, as each intervention interrupts other work the human is doing, incurs latency with each context switch between supervisor and autonomous control, and requires time to perform. We present LazyDAgger, which extends the interactive imitation learning (IL) algorithm SafeDAgger to reduce context switches between supervisor and autonomous control. We find that LazyDAgger improves the performance and robustness of the learned policy during both learning and execution while limiting burden on the supervisor. Simulation experiments suggest that LazyDAgger can reduce context switches by an average of 60% over SafeDAgger on 3 continuous control tasks while maintaining state-of-the-art policy performance. In physical fabric manipulation experiments with an ABB YuMi robot, LazyDAgger reduces context switches by 60% while achieving a 60% higher success rate than SafeDAgger at execution time.

</p>
</details>

<details><summary><b>OLIVAW: Mastering Othello with neither Humans nor a Penny</b>
<a href="https://arxiv.org/abs/2103.17228">arxiv:2103.17228</a>
&#x1F4C8; 6 <br>
<p>Antonio Norelli, Alessandro Panconesi</p></summary>
<p>

**Abstract:** We introduce OLIVAW, an AI Othello player adopting the design principles of the famous AlphaGo series. The main motivation behind OLIVAW was to attain exceptional competence in a non-trivial board game at a tiny fraction of the cost of its illustrious predecessors. In this paper, we show how the AlphaGo Zero's paradigm can be successfully applied to the popular game of Othello using only commodity hardware and free cloud services. While being simpler than Chess or Go, Othello maintains a considerable search space and difficulty in evaluating board positions. To achieve this result, OLIVAW implements some improvements inspired by recent works to accelerate the standard AlphaGo Zero learning process. The main modification implies doubling the positions collected per game during the training phase, by including also positions not played but largely explored by the agent. We tested the strength of OLIVAW in three different ways: by pitting it against Edax, the strongest open-source Othello engine, by playing anonymous games on the web platform OthelloQuest, and finally in two in-person matches against top-notch human players: a national champion and a former world champion.

</p>
</details>

<details><summary><b>Using activation histograms to bound the number of affine regions in ReLU feed-forward neural networks</b>
<a href="https://arxiv.org/abs/2103.17174">arxiv:2103.17174</a>
&#x1F4C8; 6 <br>
<p>Peter Hinz</p></summary>
<p>

**Abstract:** Several current bounds on the maximal number of affine regions of a ReLU feed-forward neural network are special cases of the framework [1] which relies on layer-wise activation histogram bounds. We analyze and partially solve a problem in algebraic topology the solution of which would fully exploit this framework. Our partial solution already induces slightly tighter bounds and suggests insight in how parameter initialization methods can affect the number of regions. Furthermore, we extend the framework to allow the composition of subnetwork instead of layer-wise activation histogram bounds to reduce the number of required compositions which negatively affect the tightness of the resulting bound.

</p>
</details>

<details><summary><b>Differentiable Deconvolution for Improved Stroke Perfusion Analysis</b>
<a href="https://arxiv.org/abs/2103.17111">arxiv:2103.17111</a>
&#x1F4C8; 6 <br>
<p>Ezequiel de la Rosa, David Robben, Diana M. Sima, Jan S. Kirschke, Bjoern Menze</p></summary>
<p>

**Abstract:** Perfusion imaging is the current gold standard for acute ischemic stroke analysis. It allows quantification of the salvageable and non-salvageable tissue regions (penumbra and core areas respectively). In clinical settings, the singular value decomposition (SVD) deconvolution is one of the most accepted and used approaches for generating interpretable and physically meaningful maps. Though this method has been widely validated in experimental and clinical settings, it might produce suboptimal results because the chosen inputs to the model cannot guarantee optimal performance. For the most critical input, the arterial input function (AIF), it is still controversial how and where it should be chosen even though the method is very sensitive to this input. In this work we propose an AIF selection approach that is optimized for maximal core lesion segmentation performance. The AIF is regressed by a neural network optimized through a differentiable SVD deconvolution, aiming to maximize core lesion segmentation agreement with ground truth data. To our knowledge, this is the first work exploiting a differentiable deconvolution model with neural networks. We show that our approach is able to generate AIFs without any manual annotation, and hence avoiding manual rater's influences. The method achieves manual expert performance in the ISLES18 dataset. We conclude that the methodology opens new possibilities for improving perfusion imaging quantification with deep neural networks.

</p>
</details>

<details><summary><b>Fusing RGBD Tracking and Segmentation Tree Sampling for Multi-Hypothesis Volumetric Segmentation</b>
<a href="https://arxiv.org/abs/2104.00205">arxiv:2104.00205</a>
&#x1F4C8; 5 <br>
<p>Andrew Price, Kun Huang, Dmitry Berenson</p></summary>
<p>

**Abstract:** Despite rapid progress in scene segmentation in recent years, 3D segmentation methods are still limited when there is severe occlusion. The key challenge is estimating the segment boundaries of (partially) occluded objects, which are inherently ambiguous when considering only a single frame. In this work, we propose Multihypothesis Segmentation Tracking (MST), a novel method for volumetric segmentation in changing scenes, which allows scene ambiguity to be tracked and our estimates to be adjusted over time as we interact with the scene. Two main innovations allow us to tackle this difficult problem: 1) A novel way to sample possible segmentations from a segmentation tree; and 2) A novel approach to fusing tracking results with multiple segmentation estimates. These methods allow MST to track the segmentation state over time and incorporate new information, such as new objects being revealed. We evaluate our method on several cluttered tabletop environments in simulation and reality. Our results show that MST outperforms baselines in all tested scenes.

</p>
</details>

<details><summary><b>DEALIO: Data-Efficient Adversarial Learning for Imitation from Observation</b>
<a href="https://arxiv.org/abs/2104.00163">arxiv:2104.00163</a>
&#x1F4C8; 5 <br>
<p>Faraz Torabi, Garrett Warnell, Peter Stone</p></summary>
<p>

**Abstract:** In imitation learning from observation IfO, a learning agent seeks to imitate a demonstrating agent using only observations of the demonstrated behavior without access to the control signals generated by the demonstrator. Recent methods based on adversarial imitation learning have led to state-of-the-art performance on IfO problems, but they typically suffer from high sample complexity due to a reliance on data-inefficient, model-free reinforcement learning algorithms. This issue makes them impractical to deploy in real-world settings, where gathering samples can incur high costs in terms of time, energy, and risk. In this work, we hypothesize that we can incorporate ideas from model-based reinforcement learning with adversarial methods for IfO in order to increase the data efficiency of these methods without sacrificing performance. Specifically, we consider time-varying linear Gaussian policies, and propose a method that integrates the linear-quadratic regulator with path integral policy improvement into an existing adversarial IfO framework. The result is a more data-efficient IfO algorithm with better performance, which we show empirically in four simulation domains: using far fewer interactions with the environment, the proposed method exhibits similar or better performance than the existing technique.

</p>
</details>

<details><summary><b>Towards Prior-Free Approximately Truthful One-Shot Auction Learning via Differential Privacy</b>
<a href="https://arxiv.org/abs/2104.00159">arxiv:2104.00159</a>
&#x1F4C8; 5 <br>
<p>Daniel Reusche, Nicol√°s Della Penna</p></summary>
<p>

**Abstract:** Designing truthful, revenue maximizing auctions is a core problem of auction design. Multi-item settings have long been elusive. Recent work (arXiv:1706.03459) introduces effective deep learning techniques to find such auctions for the prior-dependent setting, in which distributions about bidder preferences are known. One remaining problem is to obtain priors in a way that excludes the possibility of manipulating the resulting auctions. Using techniques from differential privacy for the construction of approximately truthful mechanisms, we modify the RegretNet approach to be applicable to the prior-free setting. In this more general setting, no distributional information is assumed, but we trade this property for worse performance. We present preliminary empirical results and qualitative analysis for this work in progress.

</p>
</details>

<details><summary><b>NetAdaptV2: Efficient Neural Architecture Search with Fast Super-Network Training and Architecture Optimization</b>
<a href="https://arxiv.org/abs/2104.00031">arxiv:2104.00031</a>
&#x1F4C8; 5 <br>
<p>Tien-Ju Yang, Yi-Lun Liao, Vivienne Sze</p></summary>
<p>

**Abstract:** Neural architecture search (NAS) typically consists of three main steps: training a super-network, training and evaluating sampled deep neural networks (DNNs), and training the discovered DNN. Most of the existing efforts speed up some steps at the cost of a significant slowdown of other steps or sacrificing the support of non-differentiable search metrics. The unbalanced reduction in the time spent per step limits the total search time reduction, and the inability to support non-differentiable search metrics limits the performance of discovered DNNs.
  In this paper, we present NetAdaptV2 with three innovations to better balance the time spent for each step while supporting non-differentiable search metrics. First, we propose channel-level bypass connections that merge network depth and layer width into a single search dimension to reduce the time for training and evaluating sampled DNNs. Second, ordered dropout is proposed to train multiple DNNs in a single forward-backward pass to decrease the time for training a super-network. Third, we propose the multi-layer coordinate descent optimizer that considers the interplay of multiple layers in each iteration of optimization to improve the performance of discovered DNNs while supporting non-differentiable search metrics. With these innovations, NetAdaptV2 reduces the total search time by up to $5.8\times$ on ImageNet and $2.4\times$ on NYU Depth V2, respectively, and discovers DNNs with better accuracy-latency/accuracy-MAC trade-offs than state-of-the-art NAS works. Moreover, the discovered DNN outperforms NAS-discovered MobileNetV3 by 1.8% higher top-1 accuracy with the same latency. The project website is http://netadapt.mit.edu.

</p>
</details>

<details><summary><b>Bit-Mixer: Mixed-precision networks with runtime bit-width selection</b>
<a href="https://arxiv.org/abs/2103.17267">arxiv:2103.17267</a>
&#x1F4C8; 5 <br>
<p>Adrian Bulat, Georgios Tzimiropoulos</p></summary>
<p>

**Abstract:** Mixed-precision networks allow for a variable bit-width quantization for every layer in the network. A major limitation of existing work is that the bit-width for each layer must be predefined during training time. This allows little flexibility if the characteristics of the device on which the network is deployed change during runtime. In this work, we propose Bit-Mixer, the very first method to train a meta-quantized network where during test time any layer can change its bid-width without affecting at all the overall network's ability for highly accurate inference. To this end, we make 2 key contributions: (a) Transitional Batch-Norms, and (b) a 3-stage optimization process which is shown capable of training such a network. We show that our method can result in mixed precision networks that exhibit the desirable flexibility properties for on-device deployment without compromising accuracy. Code will be made available.

</p>
</details>

<details><summary><b>Reliable Detection of Compressed and Encrypted Data</b>
<a href="https://arxiv.org/abs/2103.17059">arxiv:2103.17059</a>
&#x1F4C8; 5 <br>
<p>Fabio De Gaspari, Dorjan Hitaj, Giulio Pagnotta, Lorenzo De Carli, Luigi V. Mancini</p></summary>
<p>

**Abstract:** Several cybersecurity domains, such as ransomware detection, forensics and data analysis, require methods to reliably identify encrypted data fragments. Typically, current approaches employ statistics derived from byte-level distribution, such as entropy estimation, to identify encrypted fragments. However, modern content types use compression techniques which alter data distribution pushing it closer to the uniform distribution. The result is that current approaches exhibit unreliable encryption detection performance when compressed data appears in the dataset. Furthermore, proposed approaches are typically evaluated over few data types and fragment sizes, making it hard to assess their practical applicability. This paper compares existing statistical tests on a large, standardized dataset and shows that current approaches consistently fail to distinguish encrypted and compressed data on both small and large fragment sizes. We address these shortcomings and design EnCoD, a learning-based classifier which can reliably distinguish compressed and encrypted data. We evaluate EnCoD on a dataset of 16 different file types and fragment sizes ranging from 512B to 8KB. Our results highlight that EnCoD outperforms current approaches by a wide margin, with accuracy ranging from ~82 for 512B fragments up to ~92 for 8KB data fragments. Moreover, EnCoD can pinpoint the exact format of a given data fragment, rather than performing only binary classification like previous approaches.

</p>
</details>

<details><summary><b>Solving Heterogeneous General Equilibrium Economic Models with Deep Reinforcement Learning</b>
<a href="https://arxiv.org/abs/2103.16977">arxiv:2103.16977</a>
&#x1F4C8; 5 <br>
<p>Edward Hill, Marco Bardoscia, Arthur Turrell</p></summary>
<p>

**Abstract:** General equilibrium macroeconomic models are a core tool used by policymakers to understand a nation's economy. They represent the economy as a collection of forward-looking actors whose behaviours combine, possibly with stochastic effects, to determine global variables (such as prices) in a dynamic equilibrium. However, standard semi-analytical techniques for solving these models make it difficult to include the important effects of heterogeneous economic actors. The COVID-19 pandemic has further highlighted the importance of heterogeneity, for example in age and sector of employment, in macroeconomic outcomes and the need for models that can more easily incorporate it. We use techniques from reinforcement learning to solve such models incorporating heterogeneous agents in a way that is simple, extensible, and computationally efficient. We demonstrate the method's accuracy and stability on a toy problem for which there is a known analytical solution, its versatility by solving a general equilibrium problem that includes global stochasticity, and its flexibility by solving a combined macroeconomic and epidemiological model to explore the economic and health implications of a pandemic. The latter successfully captures plausible economic behaviours induced by differential health risks by age.

</p>
</details>

<details><summary><b>Embracing Uncertainty: Decoupling and De-bias for Robust Temporal Grounding</b>
<a href="https://arxiv.org/abs/2103.16848">arxiv:2103.16848</a>
&#x1F4C8; 5 <br>
<p>Hao Zhou, Chongyang Zhang, Yan Luo, Yanjun Chen, Chuanping Hu</p></summary>
<p>

**Abstract:** Temporal grounding aims to localize temporal boundaries within untrimmed videos by language queries, but it faces the challenge of two types of inevitable human uncertainties: query uncertainty and label uncertainty. The two uncertainties stem from human subjectivity, leading to limited generalization ability of temporal grounding. In this work, we propose a novel DeNet (Decoupling and De-bias) to embrace human uncertainty: Decoupling - We explicitly disentangle each query into a relation feature and a modified feature. The relation feature, which is mainly based on skeleton-like words (including nouns and verbs), aims to extract basic and consistent information in the presence of query uncertainty. Meanwhile, modified feature assigned with style-like words (including adjectives, adverbs, etc) represents the subjective information, and thus brings personalized predictions; De-bias - We propose a de-bias mechanism to generate diverse predictions, aim to alleviate the bias caused by single-style annotations in the presence of label uncertainty. Moreover, we put forward new multi-label metrics to diversify the performance evaluation. Extensive experiments show that our approach is more effective and robust than state-of-the-arts on Charades-STA and ActivityNet Captions datasets.

</p>
</details>

<details><summary><b>Exploring Plausible Patches Using Source Code Embeddings in JavaScript</b>
<a href="https://arxiv.org/abs/2103.16846">arxiv:2103.16846</a>
&#x1F4C8; 5 <br>
<p>Viktor Csuvik, D√°niel Horv√°th, M√°rk Lajk√≥, L√°szl√≥ Vid√°cs</p></summary>
<p>

**Abstract:** Despite the immense popularity of the Automated Program Repair (APR) field, the question of patch validation is still open. Most of the present-day approaches follow the so-called Generate-and-Validate approach, where first a candidate solution is being generated and after validated against an oracle. The latter, however, might not give a reliable result, because of the imperfections in such oracles; one of which is usually the test suite. Although (re-) running the test suite is right under one's nose, in real life applications the problem of over- and underfitting often occurs, resulting in inadequate patches. Efforts that have been made to tackle with this problem include patch filtering, test suite expansion, careful patch producing and many more. Most approaches to date use post-filtering relying either on test execution traces or make use of some similarity concept measured on the generated patches. Our goal is to investigate the nature of these similarity-based approaches. To do so, we trained a Doc2Vec model on an open-source JavaScript project and generated 465 patches for 10 bugs in it. These plausible patches alongside with the developer fix are then ranked based on their similarity to the original program. We analyzed these similarity lists and found that plain document embeddings may lead to misclassification - it fails to capture nuanced code semantics. Nevertheless, in some cases it also provided useful information, thus helping to better understand the area of Automated Program Repair.

</p>
</details>

<details><summary><b>Spatial Content Alignment For Pose Transfer</b>
<a href="https://arxiv.org/abs/2103.16828">arxiv:2103.16828</a>
&#x1F4C8; 5 <br>
<p>Wing-Yin Yu, Lai-Man Po, Yuzhi Zhao, Jingjing Xiong, Kin-Wai Lau</p></summary>
<p>

**Abstract:** Due to unreliable geometric matching and content misalignment, most conventional pose transfer algorithms fail to generate fine-trained person images. In this paper, we propose a novel framework Spatial Content Alignment GAN (SCAGAN) which aims to enhance the content consistency of garment textures and the details of human characteristics. We first alleviate the spatial misalignment by transferring the edge content to the target pose in advance. Secondly, we introduce a new Content-Style DeBlk which can progressively synthesize photo-realistic person images based on the appearance features of the source image, the target pose heatmap and the prior transferred content in edge domain. We compare the proposed framework with several state-of-the-art methods to show its superiority in quantitative and qualitative analysis. Moreover, detailed ablation study results demonstrate the efficacy of our contributions. Codes are publicly available at github.com/rocketappslab/SCA-GAN.

</p>
</details>

<details><summary><b>Trajectory Tracking of Underactuated Sea Vessels With Uncertain Dynamics: An Integral Reinforcement Learning Approach</b>
<a href="https://arxiv.org/abs/2104.00190">arxiv:2104.00190</a>
&#x1F4C8; 4 <br>
<p>Mohammed Abouheaf, Wail Gueaieb, Md. Suruz Miah, Davide Spinello</p></summary>
<p>

**Abstract:** Underactuated systems like sea vessels have degrees of motion that are insufficiently matched by a set of independent actuation forces. In addition, the underlying trajectory-tracking control problems grow in complexity in order to decide the optimal rudder and thrust control signals. This enforces several difficult-to-solve constraints that are associated with the error dynamical equations using classical optimal tracking and adaptive control approaches. An online machine learning mechanism based on integral reinforcement learning is proposed to find a solution for a class of nonlinear tracking problems with partial prior knowledge of the system dynamics. The actuation forces are decided using innovative forms of temporal difference equations relevant to the vessel's surge and angular velocities. The solution is implemented using an online value iteration process which is realized by employing means of the adaptive critics and gradient descent approaches. The adaptive learning mechanism exhibited well-functioning and interactive features in react to different desired reference-tracking scenarios.

</p>
</details>

<details><summary><b>Online Learning Probabilistic Event Calculus Theories in Answer Set Programming</b>
<a href="https://arxiv.org/abs/2104.00158">arxiv:2104.00158</a>
&#x1F4C8; 4 <br>
<p>Nikos Katzouris, Alexander Artikis, Georgios Paliouras</p></summary>
<p>

**Abstract:** Complex Event Recognition (CER) systems detect event occurrences in streaming time-stamped input using predefined event patterns. Logic-based approaches are of special interest in CER, since, via Statistical Relational AI, they combine uncertainty-resilient reasoning with time and change, with machine learning, thus alleviating the cost of manual event pattern authoring. We present a system based on Answer Set Programming (ASP), capable of probabilistic reasoning with complex event patterns in the form of weighted rules in the Event Calculus, whose structure and weights are learnt online. We compare our ASP-based implementation with a Markov Logic-based one and with a number of state-of-the-art batch learning algorithms on CER datasets for activity recognition, maritime surveillance and fleet management. Our results demonstrate the superiority of our novel approach, both in terms of efficiency and predictive performance. This paper is under consideration for publication in Theory and Practice of Logic Programming (TPLP).

</p>
</details>

<details><summary><b>Multi-Encoder Learning and Stream Fusion for Transformer-Based End-to-End Automatic Speech Recognition</b>
<a href="https://arxiv.org/abs/2104.00120">arxiv:2104.00120</a>
&#x1F4C8; 4 <br>
<p>Timo Lohrenz, Zhengyang Li, Tim Fingscheidt</p></summary>
<p>

**Abstract:** Stream fusion, also known as system combination, is a common technique in automatic speech recognition for traditional hybrid hidden Markov model approaches, yet mostly unexplored for modern deep neural network end-to-end model architectures. Here, we investigate various fusion techniques for the all-attention-based encoder-decoder architecture known as the transformer, striving to achieve optimal fusion by investigating different fusion levels in an example single-microphone setting with fusion of standard magnitude and phase features. We introduce a novel multi-encoder learning method that performs a weighted combination of two encoder-decoder multi-head attention outputs only during training. Employing then only the magnitude feature encoder in inference, we are able to show consistent improvement on Wall Street Journal (WSJ) with language model and on Librispeech, without increase in runtime or parameters. Combining two such multi-encoder trained models by a simple late fusion in inference, we achieve state-of-the-art performance for transformer-based models on WSJ with a significant WER reduction of 19% relative compared to the current benchmark approach.

</p>
</details>

<details><summary><b>Analysis on Image Set Visual Question Answering</b>
<a href="https://arxiv.org/abs/2104.00107">arxiv:2104.00107</a>
&#x1F4C8; 4 <br>
<p>Abhinav Khattar, Aviral Joshi, Har Simrat Singh, Pulkit Goel, Rohit Prakash Barnwal</p></summary>
<p>

**Abstract:** We tackle the challenge of Visual Question Answering in multi-image setting for the ISVQA dataset. Traditional VQA tasks have focused on a single-image setting where the target answer is generated from a single image. Image set VQA, however, comprises of a set of images and requires finding connection between images, relate the objects across images based on these connections and generate a unified answer. In this report, we work with 4 approaches in a bid to improve the performance on the task. We analyse and compare our results with three baseline models - LXMERT, HME-VideoQA and VisualBERT - and show that our approaches can provide a slight improvement over the baselines. In specific, we try to improve on the spatial awareness of the model and help the model identify color using enhanced pre-training, reduce language dependence using adversarial regularization, and improve counting using regression loss and graph based deduplication. We further delve into an in-depth analysis on the language bias in the ISVQA dataset and show how models trained on ISVQA implicitly learn to associate language more strongly with the final answer.

</p>
</details>

<details><summary><b>Leveraging Neural Machine Translation for Word Alignment</b>
<a href="https://arxiv.org/abs/2103.17250">arxiv:2103.17250</a>
&#x1F4C8; 4 <br>
<p>Vil√©m Zouhar, Daria Pylypenko</p></summary>
<p>

**Abstract:** The most common tools for word-alignment rely on a large amount of parallel sentences, which are then usually processed according to one of the IBM model algorithms. The training data is, however, the same as for machine translation (MT) systems, especially for neural MT (NMT), which itself is able to produce word-alignments using the trained attention heads. This is convenient because word-alignment is theoretically a viable byproduct of any attention-based NMT, which is also able to provide decoder scores for a translated sentence pair.
  We summarize different approaches on how word-alignment can be extracted from alignment scores and then explore ways in which scores can be extracted from NMT, focusing on inferring the word-alignment scores based on output sentence and token probabilities. We compare this to the extraction of alignment scores from attention. We conclude with aggregating all of the sources of alignment scores into a simple feed-forward network which achieves the best results when combined alignment extractors are used.

</p>
</details>

<details><summary><b>Spectral decoupling allows training transferable neural networks in medical imaging</b>
<a href="https://arxiv.org/abs/2103.17171">arxiv:2103.17171</a>
&#x1F4C8; 4 <br>
<p>Joona Pohjonen, Carolin St√ºrenberg, Antti Rannikko, Tuomas Mirtti, Esa Pitk√§nen</p></summary>
<p>

**Abstract:** Many current neural networks for medical imaging generalise poorly to data unseen during training. Such behaviour can be caused by networks overfitting easy-to-learn, or statistically dominant, features while disregarding other potentially informative features. For example, indistinguishable differences in the sharpness of the images from two different scanners can degrade the performance of the network significantly. All neural networks intended for clinical practice need to be robust to variation in data caused by differences in imaging equipment, sample preparation and patient populations.
  To address these challenges, we evaluate the utility of spectral decoupling as an implicit bias mitigation method. Spectral decoupling encourages the neural network to learn more features by simply regularising the networks' unnormalised prediction scores with an L2 penalty, thus having no added computational costs.
  We show that spectral decoupling allows training neural networks on datasets with strong spurious correlations and increases networks' robustness for data distribution shifts. To validate our findings, we train networks with and without spectral decoupling to detect prostate cancer tissue slides and COVID-19 in chest radiographs. Networks trained with spectral decoupling achieve up to 9.5 percent point higher performance on external datasets.
  Our results show that spectral decoupling helps with generalisation issues associated with neural networks, and can be used to complement or replace computationally expensive explicit bias mitigation methods, such as stain normalization in histological images. We recommend using spectral decoupling as an implicit bias mitigation method in any neural network intended for clinical use.

</p>
</details>

<details><summary><b>CrowdTeacher: Robust Co-teaching with Noisy Answers & Sample-specific Perturbations for Tabular Data</b>
<a href="https://arxiv.org/abs/2103.17144">arxiv:2103.17144</a>
&#x1F4C8; 4 <br>
<p>Mani Sotoodeh, Li Xiong, Joyce C. Ho</p></summary>
<p>

**Abstract:** Samples with ground truth labels may not always be available in numerous domains. While learning from crowdsourcing labels has been explored, existing models can still fail in the presence of sparse, unreliable, or diverging annotations. Co-teaching methods have shown promising improvements for computer vision problems with noisy labels by employing two classifiers trained on each others' confident samples in each batch. Inspired by the idea of separating confident and uncertain samples during the training process, we extend it for the crowdsourcing problem. Our model, CrowdTeacher, uses the idea that perturbation in the input space model can improve the robustness of the classifier for noisy labels. Treating crowdsourcing annotations as a source of noisy labeling, we perturb samples based on the certainty from the aggregated annotations. The perturbed samples are fed to a Co-teaching algorithm tuned to also accommodate smaller tabular data. We showcase the boost in predictive power attained using CrowdTeacher for both synthetic and real datasets across various label density settings. Our experiments reveal that our proposed approach beats baselines modeling individual annotations and then combining them, methods simultaneously learning a classifier and inferring truth labels, and the Co-teaching algorithm with aggregated labels through common truth inference methods.

</p>
</details>

<details><summary><b>Perun: Secure Multi-Stakeholder Machine Learning Framework with GPU Support</b>
<a href="https://arxiv.org/abs/2103.16898">arxiv:2103.16898</a>
&#x1F4C8; 4 <br>
<p>Wojciech Ozga, Do Le Quoc, Christof Fetzer</p></summary>
<p>

**Abstract:** Confidential multi-stakeholder machine learning (ML) allows multiple parties to perform collaborative data analytics while not revealing their intellectual property, such as ML source code, model, or datasets. State-of-the-art solutions based on homomorphic encryption incur a large performance overhead. Hardware-based solutions, such as trusted execution environments (TEEs), significantly improve the performance in inference computations but still suffer from low performance in training computations, e.g., deep neural networks model training, because of limited availability of protected memory and lack of GPU support.
  To address this problem, we designed and implemented Perun, a framework for confidential multi-stakeholder machine learning that allows users to make a trade-off between security and performance. Perun executes ML training on hardware accelerators (e.g., GPU) while providing security guarantees using trusted computing technologies, such as trusted platform module and integrity measurement architecture. Less compute-intensive workloads, such as inference, execute only inside TEE, thus at a lower trusted computing base. The evaluation shows that during the ML training on CIFAR-10 and real-world medical datasets, Perun achieved a 161x to 1560x speedup compared to a pure TEE-based approach.

</p>
</details>

<details><summary><b>The Kaleidoscope of Privacy: Differences across French, German, UK, and US GDPR Media Discourse</b>
<a href="https://arxiv.org/abs/2104.04074">arxiv:2104.04074</a>
&#x1F4C8; 3 <br>
<p>Mary Sanford, Taha Yasseri</p></summary>
<p>

**Abstract:** Conceptions of privacy differ by culture. In the Internet age, digital tools continuously challenge the way users, technologists, and governments define, value, and protect privacy. National and supranational entities attempt to regulate privacy and protect data managed online. The European Union passed the General Data Protection Regulation (GDPR), which took effect on 25 May 2018. The research presented here draws on two years of media reporting on GDPR from French, German, UK, and US sources. We use the unsupervised machine learning method of topic modelling to compare the thematic structure of the news articles across time and geographic regions. Our work emphasises the relevance of regional differences regarding valuations of privacy and potential obstacles to the implementation of unilateral data protection regulation such as GDPR. We find that the topics and trends over time in GDPR media coverage of the four countries reflect the differences found across their traditional privacy cultures.

</p>
</details>

<details><summary><b>Zero-Shot Language Transfer vs Iterative Back Translation for Unsupervised Machine Translation</b>
<a href="https://arxiv.org/abs/2104.00106">arxiv:2104.00106</a>
&#x1F4C8; 3 <br>
<p>Aviral Joshi, Chengzhi Huang, Har Simrat Singh</p></summary>
<p>

**Abstract:** This work focuses on comparing different solutions for machine translation on low resource language pairs, namely, with zero-shot transfer learning and unsupervised machine translation. We discuss how the data size affects the performance of both unsupervised MT and transfer learning. Additionally we also look at how the domain of the data affects the result of unsupervised MT. The code to all the experiments performed in this project are accessible on Github.

</p>
</details>

<details><summary><b>Robust Experimentation in the Continuous Time Bandit Problem</b>
<a href="https://arxiv.org/abs/2104.00102">arxiv:2104.00102</a>
&#x1F4C8; 3 <br>
<p>Farzad Pourbabaee</p></summary>
<p>

**Abstract:** We study the experimentation dynamics of a decision maker (DM) in a two-armed bandit setup (Bolton and Harris (1999)), where the agent holds ambiguous beliefs regarding the distribution of the return process of one arm and is certain about the other one. The DM entertains Multiplier preferences a la Hansen and Sargent (2001), thus we frame the decision making environment as a two-player differential game against nature in continuous time. We characterize the DM value function and her optimal experimentation strategy that turns out to follow a cut-off rule with respect to her belief process. The belief threshold for exploring the ambiguous arm is found in closed form and is shown to be increasing with respect to the ambiguity aversion index. We then study the effect of provision of an unambiguous information source about the ambiguous arm. Interestingly, we show that the exploration threshold rises unambiguously as a result of this new information source, thereby leading to more conservatism. This analysis also sheds light on the efficient time to reach for an expert opinion.

</p>
</details>

<details><summary><b>Taking Stock of the Present and Future of Smart Technologies for Older Adults and Caregivers</b>
<a href="https://arxiv.org/abs/2104.00096">arxiv:2104.00096</a>
&#x1F4C8; 3 <br>
<p>Christina N. Harrington, Ben Jelen, Amanda Lazar, Aqueasha Martin-Hammond, Alisha Pradhan, Blaine Reeder, Katie Siek</p></summary>
<p>

**Abstract:** Technology has the opportunity to assist older adults as they age in place, coordinate caregiving resources, and meet unmet needs through access to resources. Currently, older adults use consumer technologies to support everyday life, however these technologies are not always accessible or as useful as they can be. Indeed, industry has attempted to create smart home technologies with older adults as a target user group, however these solutions are often more focused on the technical aspects and are short lived. In this paper, we advocate for older adults being involved in the design process - from initial ideation to product development to deployment. We encourage federally funded researchers and industry to create compensated, diverse older adult advisory boards to address stereotypes about aging while ensuring their needs are considered.
  We envision artificial intelligence systems that augment resources instead of replacing them - especially in under-resourced communities. Older adults rely on their caregiver networks and community organizations for social, emotional, and physical support; thus, AI should be used to coordinate resources better and lower the burden of connecting with these resources. Although sociotechnical smart systems can help identify needs of older adults, the lack of affordable research infrastructure and translation of findings into consumer technology perpetuates inequities in designing for diverse older adults. In addition, there is a disconnect between the creation of smart sensing systems and creating understandable, actionable data for older adults and caregivers to utilize. We ultimately advocate for a well-coordinated research effort across the United States that connects older adults, caregivers, community organizations, and researchers together to catalyze innovative and practical research for all stakeholders.

</p>
</details>

<details><summary><b>Imagine All the People: Citizen Science, Artificial Intelligence, and Computational Research</b>
<a href="https://arxiv.org/abs/2104.00093">arxiv:2104.00093</a>
&#x1F4C8; 3 <br>
<p>Lea A. Shanley, Lucy Fortson, Tanya Berger-Wolf, Kevin Crowston, Pietro Michelucci</p></summary>
<p>

**Abstract:** Machine learning, artificial intelligence, and deep learning have advanced significantly over the past decade. Nonetheless, humans possess unique abilities such as creativity, intuition, context and abstraction, analytic problem solving, and detecting unusual events. To successfully tackle pressing scientific and societal challenges, we need the complementary capabilities of both humans and machines. The Federal Government could accelerate its priorities on multiple fronts through judicious integration of citizen science and crowdsourcing with artificial intelligence (AI), Internet of Things (IoT), and cloud strategies.

</p>
</details>

<details><summary><b>Video Exploration via Video-Specific Autoencoders</b>
<a href="https://arxiv.org/abs/2103.17261">arxiv:2103.17261</a>
&#x1F4C8; 3 <br>
<p>Kevin Wang, Deva Ramanan, Aayush Bansal</p></summary>
<p>

**Abstract:** We present simple video-specific autoencoders that enables human-controllable video exploration. This includes a wide variety of analytic tasks such as (but not limited to) spatial and temporal super-resolution, spatial and temporal editing, object removal, video textures, average video exploration, and correspondence estimation within and across videos. Prior work has independently looked at each of these problems and proposed different formulations. In this work, we observe that a simple autoencoder trained (from scratch) on multiple frames of a specific video enables one to perform a large variety of video processing and editing tasks. Our tasks are enabled by two key observations: (1) latent codes learned by the autoencoder capture spatial and temporal properties of that video and (2) autoencoders can project out-of-sample inputs onto the video-specific manifold. For e.g. (1) interpolating latent codes enables temporal super-resolution and user-controllable video textures; (2) manifold reprojection enables spatial super-resolution, object removal, and denoising without training for any of the tasks. Importantly, a two-dimensional visualization of latent codes via principal component analysis acts as a tool for users to both visualize and intuitively control video edits. Finally, we quantitatively contrast our approach with the prior art and found that without any supervision and task-specific knowledge, our approach can perform comparably to supervised approaches specifically trained for a task.

</p>
</details>

<details><summary><b>XY Neural Networks</b>
<a href="https://arxiv.org/abs/2103.17244">arxiv:2103.17244</a>
&#x1F4C8; 3 <br>
<p>Nikita Stroev, Natalia G. Berloff</p></summary>
<p>

**Abstract:** The classical XY model is a lattice model of statistical mechanics notable for its universality in the rich hierarchy of the optical, laser and condensed matter systems. We show how to build complex structures for machine learning based on the XY model's nonlinear blocks. The final target is to reproduce the deep learning architectures, which can perform complicated tasks usually attributed to such architectures: speech recognition, visual processing, or other complex classification types with high quality. We developed the robust and transparent approach for the construction of such models, which has universal applicability (i.e. does not strongly connect to any particular physical system), allows many possible extensions while at the same time preserving the simplicity of the methodology.

</p>
</details>

<details><summary><b>Joint Deep Multi-Graph Matching and 3D Geometry Learning from Inhomogeneous 2D Image Collections</b>
<a href="https://arxiv.org/abs/2103.17229">arxiv:2103.17229</a>
&#x1F4C8; 3 <br>
<p>Zhenzhang Ye, Tarun Yenamandra, Florian Bernard, Daniel Cremers</p></summary>
<p>

**Abstract:** Graph matching aims to establish correspondences between vertices of graphs such that both the node and edge attributes agree. Various learning-based methods were recently proposed for finding correspondences between image key points based on deep graph matching formulations. While these approaches mainly focus on learning node and edge attributes, they completely ignore the 3D geometry of the underlying 3D objects depicted in the 2D images. We fill this gap by proposing a trainable framework that takes advantage of graph neural networks for learning a deformable 3D geometry model from inhomogeneous image collections, i.e. a set of images that depict different instances of objects from the same category. Experimentally we demonstrate that our method outperforms recent learning-based approaches for graph matching considering both accuracy and cycle-consistency error, while we in addition obtain the underlying 3D geometry of the objects depicted in the 2D images.

</p>
</details>

<details><summary><b>Unpaired Single-Image Depth Synthesis with cycle-consistent Wasserstein GANs</b>
<a href="https://arxiv.org/abs/2103.16938">arxiv:2103.16938</a>
&#x1F4C8; 3 <br>
<p>Christoph Angermann, Ad√©la Moravov√°, Markus Haltmeier, Steinbj√∂rn J√≥nsson, Christian Laubichler</p></summary>
<p>

**Abstract:** Real-time estimation of actual environment depth is an essential module for various autonomous system tasks such as localization, obstacle detection and pose estimation. During the last decade of machine learning, extensive deployment of deep learning methods to computer vision tasks yielded successful approaches for realistic depth synthesis out of a simple RGB modality. While most of these models rest on paired depth data or availability of video sequences and stereo images, there is a lack of methods facing single-image depth synthesis in an unsupervised manner. Therefore, in this study, latest advancements in the field of generative neural networks are leveraged to fully unsupervised single-image depth synthesis. To be more exact, two cycle-consistent generators for RGB-to-depth and depth-to-RGB transfer are implemented and simultaneously optimized using the Wasserstein-1 distance. To ensure plausibility of the proposed method, we apply the models to a self acquised industrial data set as well as to the renown NYU Depth v2 data set, which allows comparison with existing approaches. The observed success in this study suggests high potential for unpaired single-image depth estimation in real world applications.

</p>
</details>

<details><summary><b>Near field Acoustic Holography on arbitrary shapes using Convolutional Neural Network</b>
<a href="https://arxiv.org/abs/2103.16935">arxiv:2103.16935</a>
&#x1F4C8; 3 <br>
<p>Marco Olivieri, Mirco Pezzoli, Fabio Antonacci, Augusto Sarti</p></summary>
<p>

**Abstract:** Near-field Acoustic Holography (NAH) is a well-known problem aimed at estimating the vibrational velocity field of a structure by means of acoustic measurements. In this paper, we propose a NAH technique based on Convolutional Neural Network (CNN). The devised CNN predicts the vibrational field on the surface of arbitrary shaped plates (violin plates) with orthotropic material properties from a limited number of measurements. In particular, the architecture, named Super Resolution CNN (SRCNN), is able to estimate the vibrational field with a higher spatial resolution compared to the input pressure. The pressure and velocity datasets have been generated through Finite Element Method simulations. We validate the proposed method by comparing the estimates with the synthesized ground truth and with a state-of-the-art technique. Moreover, we evaluate the robustness of the devised network against noisy input data.

</p>
</details>

<details><summary><b>Using depth information and colour space variations for improving outdoor robustness for instance segmentation of cabbage</b>
<a href="https://arxiv.org/abs/2103.16923">arxiv:2103.16923</a>
&#x1F4C8; 3 <br>
<p>Nils L√ºling, David Reiser, Alexander Stana, H. W. Griepentrog</p></summary>
<p>

**Abstract:** Image-based yield detection in agriculture could raiseharvest efficiency and cultivation performance of farms. Following this goal, this research focuses on improving instance segmentation of field crops under varying environmental conditions. Five data sets of cabbage plants were recorded under varying lighting outdoor conditions. The images were acquired using a commercial mono camera. Additionally, depth information was generated out of the image stream with Structure-from-Motion (SfM). A Mask R-CNN was used to detect and segment the cabbage heads. The influence of depth information and different colour space representations were analysed. The results showed that depth combined with colour information leads to a segmentation accuracy increase of 7.1%. By describing colour information by colour spaces using light and saturation information combined with depth information, additional segmentation improvements of 16.5% could be reached. The CIELAB colour space combined with a depth information layer showed the best results achieving a mean average precision of 75.

</p>
</details>

<details><summary><b>A Framework for Knowledge Integrated Evolutionary Algorithms</b>
<a href="https://arxiv.org/abs/2103.16897">arxiv:2103.16897</a>
&#x1F4C8; 3 <br>
<p>Ahmed Hallawa, Anil Yaman, Giovanni Iacca, Gerd Ascheid</p></summary>
<p>

**Abstract:** One of the main reasons for the success of Evolutionary Algorithms (EAs) is their general-purposeness, i.e., the fact that they can be applied straightforwardly to a broad range of optimization problems, without any specific prior knowledge. On the other hand, it has been shown that incorporating a priori knowledge, such as expert knowledge or empirical findings, can significantly improve the performance of an EA. However, integrating knowledge in EAs poses numerous challenges. It is often the case that the features of the search space are unknown, hence any knowledge associated with the search space properties can be hardly used. In addition, a priori knowledge is typically problem-specific and hard to generalize. In this paper, we propose a framework, called Knowledge Integrated Evolutionary Algorithm (KIEA), which facilitates the integration of existing knowledge into EAs. Notably, the KIEA framework is EA-agnostic (i.e., it works with any evolutionary algorithm), problem-independent (i.e., it is not dedicated to a specific type of problems), expandable (i.e., its knowledge base can grow over time). Furthermore, the framework integrates knowledge while the EA is running, thus optimizing the use of the needed computational power. In the preliminary experiments shown here, we observe that the KIEA framework produces in the worst case an 80% improvement on the converge time, w.r.t. the corresponding "knowledge-free" EA counterpart.

</p>
</details>

<details><summary><b>Channel-Based Attention for LCC Using Sentinel-2 Time Series</b>
<a href="https://arxiv.org/abs/2103.16836">arxiv:2103.16836</a>
&#x1F4C8; 3 <br>
<p>Hermann Courteille, A. Beno√Æt, N M√©ger, A Atto, D. Ienco</p></summary>
<p>

**Abstract:** Deep Neural Networks (DNNs) are getting increasing attention to deal with Land Cover Classification (LCC) relying on Satellite Image Time Series (SITS). Though high performances can be achieved, the rationale of a prediction yielded by a DNN often remains unclear. An architecture expressing predictions with respect to input channels is thus proposed in this paper. It relies on convolutional layers and an attention mechanism weighting the importance of each channel in the final classification decision. The correlation between channels is taken into account to set up shared kernels and lower model complexity. Experiments based on a Sentinel-2 SITS show promising results.

</p>
</details>

<details><summary><b>Amharic Text Clustering Using Encyclopedic Knowledge with Neural Word Embedding</b>
<a href="https://arxiv.org/abs/2105.00809">arxiv:2105.00809</a>
&#x1F4C8; 2 <br>
<p>Dessalew Yohannes, Yeregal Assabie</p></summary>
<p>

**Abstract:** In this digital era, almost in every discipline people are using automated systems that generate information represented in document format in different natural languages. As a result, there is a growing interest towards better solutions for finding, organizing and analyzing these documents. In this paper, we propose a system that clusters Amharic text documents using Encyclopedic Knowledge (EK) with neural word embedding. EK enables the representation of related concepts and neural word embedding allows us to handle the contexts of the relatedness. During the clustering process, all the text documents pass through preprocessing stages. Enriched text document features are extracted from each document by mapping with EK and word embedding model. TF-IDF weighted vector of enriched feature was generated. Finally, text documents are clustered using popular spherical K-means algorithm. The proposed system is tested with Amharic text corpus and Amharic Wikipedia data. Test results show that the use of EK with word embedding for document clustering improves the average accuracy over the use of only EK. Furthermore, changing the size of the class has a significant effect on accuracy.

</p>
</details>

<details><summary><b>HAConvGNN: Hierarchical Attention Based Convolutional Graph Neural Network for Code Documentation Generation in Jupyter Notebooks</b>
<a href="https://arxiv.org/abs/2104.01002">arxiv:2104.01002</a>
&#x1F4C8; 2 <br>
<p>Xuye Liu, Dakuo Wang, April Wang, Yufang Hou, Lingfei Wu</p></summary>
<p>

**Abstract:** Jupyter notebook allows data scientists to write machine learning code together with its documentation in cells. In this paper, we propose a new task of code documentation generation (CDG) for computational notebooks. In contrast to the previous CDG tasks which focus on generating documentation for single code snippets, in a computational notebook, one documentation in a markdown cell often corresponds to multiple code cells, and these code cells have an inherent structure. We proposed a new model (HAConvGNN) that uses a hierarchical attention mechanism to consider the relevant code cells and the relevant code tokens information when generating the documentation. Tested on a new corpus constructed from well-documented Kaggle notebooks, we show that our model outperforms other baseline models.

</p>
</details>

<details><summary><b>DIVERSE: Bayesian Data IntegratiVE learning for precise drug ResponSE prediction</b>
<a href="https://arxiv.org/abs/2104.00520">arxiv:2104.00520</a>
&#x1F4C8; 2 <br>
<p>Bet√ºl G√ºven√ß Paltun, Samuel Kaski, Hiroshi Mamitsuka</p></summary>
<p>

**Abstract:** Detecting predictive biomarkers from multi-omics data is important for precision medicine, to improve diagnostics of complex diseases and for better treatments. This needs substantial experimental efforts that are made difficult by the heterogeneity of cell lines and huge cost. An effective solution is to build a computational model over the diverse omics data, including genomic, molecular, and environmental information. However, choosing informative and reliable data sources from among the different types of data is a challenging problem. We propose DIVERSE, a framework of Bayesian importance-weighted tri- and bi-matrix factorization(DIVERSE3 or DIVERSE2) to predict drug responses from data of cell lines, drugs, and gene interactions. DIVERSE integrates the data sources systematically, in a step-wise manner, examining the importance of each added data set in turn. More specifically, we sequentially integrate five different data sets, which have not all been combined in earlier bioinformatic methods for predicting drug responses. Empirical experiments show that DIVERSE clearly outperformed five other methods including three state-of-the-art approaches, under cross-validation, particularly in out-of-matrix prediction, which is closer to the setting of real use cases and more challenging than simpler in-matrix prediction. Additionally, case studies for discovering new drugs further confirmed the performance advantage of DIVERSE.

</p>
</details>

<details><summary><b>Spectral Unions of Partial Deformable 3D Shapes</b>
<a href="https://arxiv.org/abs/2104.00514">arxiv:2104.00514</a>
&#x1F4C8; 2 <br>
<p>Luca Moschella, Simone Melzi, Luca Cosmo, Filippo Maggioli, Or Litany, Maks Ovsjanikov, Leonidas Guibas, Emanuele Rodol√†</p></summary>
<p>

**Abstract:** Spectral geometric methods have brought revolutionary changes to the field of geometry processing -- however, when the data to be processed exhibits severe partiality, such methods fail to generalize. As a result, there exists a big performance gap between methods dealing with complete shapes, and methods that address missing geometry. In this paper, we propose a possible way to fill this gap. We introduce the first method to compute compositions of non-rigidly deforming shapes, without requiring to solve first for a dense correspondence between the given partial shapes. We do so by operating in a purely spectral domain, where we define a union operation between short sequences of eigenvalues. Working with eigenvalues allows to deal with unknown correspondence, different sampling, and different discretization (point clouds and meshes alike), making this operation especially robust and general. Our approach is data-driven, and can generalize to isometric and non-isometric deformations of the surface, as long as these stay within the same semantic class (e.g., human bodies), as well as to partiality artifacts not seen at training time.

</p>
</details>

<details><summary><b>Learning Deep Latent Subspaces for Image Denoising</b>
<a href="https://arxiv.org/abs/2104.00253">arxiv:2104.00253</a>
&#x1F4C8; 2 <br>
<p>Yunhao Yang, Yuhan Zheng, Yi Wang, Chandrajit Bajaj</p></summary>
<p>

**Abstract:** Heterogeneity exists in most camera images. This heterogeneity manifests itself across the image space as varied Moire ringing, motion-blur, color-bleaching or lens based projection distortions. Moreover, combinations of these image artifacts can be present in small or large pixel neighborhoods, within an acquired image. Current camera image processing pipelines, including deep trained versions, tend to rectify the issue applying a single filter that is homogeneously applied to the entire image. This is also particularly true when an encoder-decoder type deep architecture is trained for the task. In this paper, we present a structured deep learning model that solves the heterogeneous image artifact filtering problem. We call our deep trained model the Patch Subspace Variational Autoencoder (PS-VAE) for Camera ISP. PS-VAE does not necessarily assume uniform image distortion levels nor similar artifact types within the image. Rather, our model attempts to learn to cluster different patches extracted from images into artifact type and distortion levels, within multiple latent subspaces (e.g. Moire ringing artifacts are often a higher dimensional latent distortion than a Gaussian motion blur artifact). Each image's patches are encoded into soft-clusters in their appropriate latent sub-space, using a prior mixture model. The decoders of the PS-VAE are also trained in an unsupervised manner for each of the image patches in each soft-cluster. Our experimental results demonstrates the flexibility and performance that one can achieve through improved heterogeneous filtering. We compare our results to a conventional one-encoder-one-decoder architecture.

</p>
</details>

<details><summary><b>High-Dimensional Differentially-Private EM Algorithm: Methods and Near-Optimal Statistical Guarantees</b>
<a href="https://arxiv.org/abs/2104.00245">arxiv:2104.00245</a>
&#x1F4C8; 2 <br>
<p>Zhe Zhang, Linjun Zhang</p></summary>
<p>

**Abstract:** In this paper, we develop a general framework to design differentially private expectation-maximization (EM) algorithms in high-dimensional latent variable models, based on the noisy iterative hard-thresholding. We derive the statistical guarantees of the proposed framework and apply it to three specific models: Gaussian mixture, mixture of regression, and regression with missing covariates. In each model, we establish the near-optimal rate of convergence with differential privacy constraints, and show the proposed algorithm is minimax rate optimal up to logarithm factors. The technical tools developed for the high-dimensional setting are then extended to the classic low-dimensional latent variable models, and we propose a near rate-optimal EM algorithm with differential privacy guarantees in this setting. Simulation studies and real data analysis are conducted to support our results.

</p>
</details>

<details><summary><b>Embedded Self-Distillation in Compact Multi-Branch Ensemble Network for Remote Sensing Scene Classification</b>
<a href="https://arxiv.org/abs/2104.00222">arxiv:2104.00222</a>
&#x1F4C8; 2 <br>
<p>Qi Zhao, Yujing Ma, Shuchang Lyu, Lijiang Chen</p></summary>
<p>

**Abstract:** Remote sensing (RS) image scene classification task faces many challenges due to the interference from different characteristics of different geographical elements. To solve this problem, we propose a multi-branch ensemble network to enhance the feature representation ability by fusing features in final output logits and intermediate feature maps. However, simply adding branches will increase the complexity of models and decline the inference efficiency. On this issue, we embed self-distillation (SD) method to transfer knowledge from ensemble network to main-branch in it. Through optimizing with SD, main-branch will have close performance as ensemble network. During inference, we can cut other branches to simplify the whole model. In this paper, we first design compact multi-branch ensemble network, which can be trained in an end-to-end manner. Then, we insert SD method on output logits and feature maps. Compared to previous methods, our proposed architecture (ESD-MBENet) performs strongly on classification accuracy with compact design. Extensive experiments are applied on three benchmark RS datasets AID, NWPU-RESISC45 and UC-Merced with three classic baseline models, VGG16, ResNet50 and DenseNet121. Results prove that our proposed ESD-MBENet can achieve better accuracy than previous state-of-the-art (SOTA) complex models. Moreover, abundant visualization analysis make our method more convincing and interpretable.

</p>
</details>

<details><summary><b>Data-Driven Optimized Tracking Control Heuristic for MIMO Structures: A Balance System Case Study</b>
<a href="https://arxiv.org/abs/2104.00199">arxiv:2104.00199</a>
&#x1F4C8; 2 <br>
<p>Ning Wang, Mohammed Abouheaf, Wail Gueaieb</p></summary>
<p>

**Abstract:** A data-driven computational heuristic is proposed to control MIMO systems without prior knowledge of their dynamics. The heuristic is illustrated on a two-input two-output balance system. It integrates a self-adjusting nonlinear threshold accepting heuristic with a neural network to compromise between the desired transient and steady state characteristics of the system while optimizing a dynamic cost function. The heuristic decides on the control gains of multiple interacting PID control loops. The neural network is trained upon optimizing a weighted-derivative like objective cost function. The performance of the developed mechanism is compared with another controller that employs a combined PID-Riccati approach. One of the salient features of the proposed control schemes is that they do not require prior knowledge of the system dynamics. However, they depend on a known region of stability for the control gains to be used as a search space by the optimization algorithm. The control mechanism is validated using different optimization criteria which address different design requirements.

</p>
</details>

<details><summary><b>Rapid quantification of COVID-19 pneumonia burden from computed tomography with convolutional LSTM networks</b>
<a href="https://arxiv.org/abs/2104.00138">arxiv:2104.00138</a>
&#x1F4C8; 2 <br>
<p>Kajetan Grodecki, Aditya Killekar, Andrew Lin, Sebastien Cadet, Priscilla McElhinney, Aryabod Razipour, Cato Chan, Barry D. Pressman, Peter Julien, Judit Simon, Pal Maurovich-Horvat, Nicola Gaibazzi, Udit Thakur, Elisabetta Mancini, Cecilia Agalbato, Jiro Munechika, Hidenari Matsumoto, Roberto Men√®, Gianfranco Parati, Franco Cernigliaro, Nitesh Nerlekar, Camilla Torlasco, Gianluca Pontone, Damini Dey, Piotr J. Slomka</p></summary>
<p>

**Abstract:** Quantitative lung measures derived from computed tomography (CT) have been demonstrated to improve prognostication in coronavirus disease (COVID-19) patients, but are not part of the clinical routine since required manual segmentation of lung lesions is prohibitively time-consuming. We propose a new fully automated deep learning framework for rapid quantification and differentiation between lung lesions in COVID-19 pneumonia from both contrast and non-contrast CT images using convolutional Long Short-Term Memory (ConvLSTM) networks. Utilizing the expert annotations, model training was performed 5 times with separate hold-out sets using 5-fold cross-validation to segment ground-glass opacity and high opacity (including consolidation and pleural effusion). The performance of the method was evaluated on CT data sets from 197 patients with positive reverse transcription polymerase chain reaction test result for SARS-CoV-2. Strong agreement between expert manual and automatic segmentation was obtained for lung lesions with a Dice score coefficient of 0.876 $\pm$ 0.005; excellent correlations of 0.978 and 0.981 for ground-glass opacity and high opacity volumes. In the external validation set of 67 patients, there was dice score coefficient of 0.767 $\pm$ 0.009 as well as excellent correlations of 0.989 and 0.996 for ground-glass opacity and high opacity volumes. Computations for a CT scan comprising 120 slices were performed under 2 seconds on a personal computer equipped with NVIDIA Titan RTX graphics processing unit. Therefore, our deep learning-based method allows rapid fully-automated quantitative measurement of pneumonia burden from CT and may generate results with an accuracy similar to the expert readers.

</p>
</details>

<details><summary><b>Efficient Large-Scale Face Clustering Using an Online Mixture of Gaussians</b>
<a href="https://arxiv.org/abs/2103.17272">arxiv:2103.17272</a>
&#x1F4C8; 2 <br>
<p>David Montero, Naiara Aginako, Basilio Sierra, Marcos Nieto</p></summary>
<p>

**Abstract:** In this work, we address the problem of large-scale online face clustering: given a continuous stream of unknown faces, create a database grouping the incoming faces by their identity. The database must be updated every time a new face arrives. In addition, the solution must be efficient, accurate and scalable. For this purpose, we present an online gaussian mixture-based clustering method (OGMC). The key idea of this method is the proposal that an identity can be represented by more than just one distribution or cluster. Using feature vectors (f-vectors) extracted from the incoming faces, OGMC generates clusters that may be connected to others depending on their proximity and their robustness. Every time a cluster is updated with a new sample, its connections are also updated. With this approach, we reduce the dependency of the clustering process on the order and the size of the incoming data and we are able to deal with complex data distributions. Experimental results show that the proposed approach outperforms state-of-the-art clustering methods on large-scale face clustering benchmarks not only in accuracy, but also in efficiency and scalability.

</p>
</details>

<details><summary><b>Universal Prediction Band via Semi-Definite Programming</b>
<a href="https://arxiv.org/abs/2103.17203">arxiv:2103.17203</a>
&#x1F4C8; 2 <br>
<p>Tengyuan Liang</p></summary>
<p>

**Abstract:** We propose a computationally efficient method to construct nonparametric, heteroskedastic prediction bands for uncertainty quantification, with or without any user-specified predictive model. The data-adaptive prediction band is universally applicable with minimal distributional assumptions, with strong non-asymptotic coverage properties, and easy to implement using standard convex programs. Our approach can be viewed as a novel variance interpolation with confidence and further leverages techniques from semi-definite programming and sum-of-squares optimization. Theoretical and numerical performances for the proposed approach for uncertainty quantification are analyzed.

</p>
</details>

<details><summary><b>Classification of Hematoma: Joint Learning of Semantic Segmentation and Classification</b>
<a href="https://arxiv.org/abs/2103.17172">arxiv:2103.17172</a>
&#x1F4C8; 2 <br>
<p>Hokuto Hirano, Tsuyoshi Okita</p></summary>
<p>

**Abstract:** Cerebral hematoma grows rapidly in 6-24 hours and misprediction of the growth can be fatal if it is not operated by a brain surgeon. There are two types of cerebral hematomas: one that grows rapidly and the other that does not grow rapidly. We are developing the technique of artificial intelligence to determine whether the CT image includes the cerebral hematoma which leads to the rapid growth. This problem has various difficulties: the few positive cases in this classification problem of cerebral hematoma and the targeted hematoma has deformable object. Other difficulties include the imbalance classification, the covariate shift, the small data, and the spurious correlation problems. It is difficult with the plain CNN classification such as VGG. This paper proposes the joint learning of semantic segmentation and classification and evaluate the performance of this.

</p>
</details>

<details><summary><b>Federated Learning: A Signal Processing Perspective</b>
<a href="https://arxiv.org/abs/2103.17150">arxiv:2103.17150</a>
&#x1F4C8; 2 <br>
<p>Tomer Gafni, Nir Shlezinger, Kobi Cohen, Yonina C. Eldar, H. Vincent Poor</p></summary>
<p>

**Abstract:** The dramatic success of deep learning is largely due to the availability of data. Data samples are often acquired on edge devices, such as smart phones, vehicles and sensors, and in some cases cannot be shared due to privacy considerations. Federated learning is an emerging machine learning paradigm for training models across multiple edge devices holding local datasets, without explicitly exchanging the data. Learning in a federated manner differs from conventional centralized machine learning, and poses several core unique challenges and requirements, which are closely related to classical problems studied in the areas of signal processing and communications. Consequently, dedicated schemes derived from these areas are expected to play an important role in the success of federated learning and the transition of deep learning from the domain of centralized servers to mobile edge devices. In this article, we provide a unified systematic framework for federated learning in a manner that encapsulates and highlights the main challenges that are natural to treat using signal processing tools. We present a formulation for the federated learning paradigm from a signal processing perspective, and survey a set of candidate approaches for tackling its unique challenges. We further provide guidelines for the design and adaptation of signal processing and communication methods to facilitate federated learning at large scale.

</p>
</details>

<details><summary><b>Linear systems with neural network nonlinearities: Improved stability analysis via acausal Zames-Falb multipliers</b>
<a href="https://arxiv.org/abs/2103.17106">arxiv:2103.17106</a>
&#x1F4C8; 2 <br>
<p>Patricia Pauli, Dennis Gramlich, Julian Berberich, Frank Allg√∂wer</p></summary>
<p>

**Abstract:** In this paper, we analyze the stability of feedback interconnections of a linear time-invariant system with a neural network nonlinearity in discrete time. Our analysis is based on abstracting neural networks using integral quadratic constraints (IQCs), exploiting the sector-bounded and slope-restricted structure of the underlying activation functions. In contrast to existing approaches, we leverage the full potential of dynamic IQCs to describe the nonlinear activation functions in a less conservative fashion. To be precise, we consider multipliers based on the full-block Yakubovich / circle criterion in combination with acausal Zames-Falb multipliers, leading to linear matrix inequality based stability certificates. Our approach provides a flexible and versatile framework for stability analysis of feedback interconnections with neural network nonlinearities, allowing to trade off computational efficiency and conservatism. Finally, we provide numerical examples that demonstrate the applicability of the proposed framework and the achievable improvements over previous approaches.

</p>
</details>

<details><summary><b>Tossing Quantum Coins and Dice</b>
<a href="https://arxiv.org/abs/2103.17007">arxiv:2103.17007</a>
&#x1F4C8; 2 <br>
<p>V. I. Yukalov</p></summary>
<p>

**Abstract:** The procedure of tossing quantum coins and dice is described. This case is an important example of a quantum procedure because it presents a typical framework employed in quantum information processing and quantum computing. The emphasis is on the clarification of the difference between quantum and classical conditional probabilities. These probabilities are designed for characterizing different systems, either quantum or classical, and they, generally, cannot be reduced to each other. Thus the L√ºders probability cannot be treated as a generalization of the classical conditional probability. The analogies between quantum theory of measurements and quantum decision theory are elucidated.

</p>
</details>

<details><summary><b>Energy Efficient Edge Computing: When Lyapunov Meets Distributed Reinforcement Learning</b>
<a href="https://arxiv.org/abs/2103.16985">arxiv:2103.16985</a>
&#x1F4C8; 2 <br>
<p>Mohamed Sana, Mattia Merluzzi, Nicola di Pietro, Emilio Calvanese Strinati</p></summary>
<p>

**Abstract:** In this work, we study the problem of energy-efficient computation offloading enabled by edge computing. In the considered scenario, multiple users simultaneously compete for limited radio and edge computing resources to get offloaded tasks processed under a delay constraint, with the possibility of exploiting low power sleep modes at all network nodes. The radio resource allocation takes into account inter- and intra-cell interference, and the duty cycles of the radio and computing equipment have to be jointly optimized to minimize the overall energy consumption. To address this issue, we formulate the underlying problem as a dynamic long-term optimization. Then, based on Lyapunov stochastic optimization tools, we decouple the formulated problem into a CPU scheduling problem and a radio resource allocation problem to be solved in a per-slot basis. Whereas the first one can be optimally and efficiently solved using a fast iterative algorithm, the second one is solved using distributed multi-agent reinforcement learning due to its non-convexity and NP-hardness. The resulting framework achieves up to 96.5% performance of the optimal strategy based on exhaustive search, while drastically reducing complexity. The proposed solution also allows to increase the network's energy efficiency compared to a benchmark heuristic approach.

</p>
</details>

<details><summary><b>Mobility Functional Areas and COVID-19 Spread</b>
<a href="https://arxiv.org/abs/2103.16894">arxiv:2103.16894</a>
&#x1F4C8; 2 <br>
<p>Stefano Maria Iacus, Carlos Santamaria, Francesco Sermi, Spyridon Spyratos, Dario Tarchi, Michele Vespe</p></summary>
<p>

**Abstract:** This work introduces a new concept of functional areas called Mobility Functional Areas (MFAs), i.e., the geographic zones highly interconnected according to the analysis of mobile positioning data. The MFAs do not coincide necessarily with administrative borders as they are built observing natural human mobility and, therefore, they can be used to inform, in a bottom-up approach, local transportation, spatial planning, health and economic policies. After presenting the methodology behind the MFAs, this study focuses on the link between the COVID-19 pandemic and the MFAs in Austria. It emerges that the MFAs registered an average number of infections statistically larger than the areas in the rest of the country, suggesting the usefulness of the MFAs in the context of targeted re-escalation policy responses to this health crisis. The MFAs dataset is openly available to other scholars for further analyses.

</p>
</details>

<details><summary><b>Cascade-Forward Neural Network Based on Resilient Backpropagation for Simultaneous Parameters and State Space Estimations of Brushed DC Machines</b>
<a href="https://arxiv.org/abs/2104.04348">arxiv:2104.04348</a>
&#x1F4C8; 1 <br>
<p>Hacene Mellah, Kamel Eddine Hemsas, Rachid Taleb</p></summary>
<p>

**Abstract:** A sensorless speed, average temperature and resistance estimation technique based on Neural Network (NN) for brushed DC machines is proposed in this paper. The literature on parameters and state spaces estimations of the Brushed DC machines, shows a variety of approaches. However, these observers are sensitive to a noise, on the model accuracy also are difficult to stabilize and to converge. Furthermore, the majority of earlier works, estimate either the speed or the temperature or the winding resistance. According to the literatures, the Resilient backpropagation (RBP) as is the known as the faster BP algorithm, Cascade-Forward Neural Network (CFNN), is known as the among accelerated learning backpropagation algorithms, that's why where it is found in several researches, also in several applications in these few years. The main objective of this paper is to introduce an intelligent sensor based on resilient BP to estimate simultaneously the speed, armature temperature and resistance of brushed DC machines only from the measured current and voltage. A comparison between the obtained results and the results of traditional estimator has been made to prove the ability of the proposed method. This method can be embedded in thermal monitoring systems, in high performance motor drives.

</p>
</details>

<details><summary><b>DeepMI: Deep Multi-lead ECG Fusion for Identifying Myocardial Infarction and its Occurrence-time</b>
<a href="https://arxiv.org/abs/2104.02054">arxiv:2104.02054</a>
&#x1F4C8; 1 <br>
<p>Girmaw Abebe Tadesse, Hamza Javed, Yong Liu, Jin Liu, Jiyan Chen, Komminist Weldemariam, Tingting Zhu</p></summary>
<p>

**Abstract:** Myocardial Infarction (MI) has the highest mortality of all cardiovascular diseases (CVDs). Detection of MI and information regarding its occurrence-time in particular, would enable timely interventions that may improve patient outcomes, thereby reducing the global rise in CVD deaths. Electrocardiogram (ECG) recordings are currently used to screen MI patients. However, manual inspection of ECGs is time-consuming and prone to subjective bias. Machine learning methods have been adopted for automated ECG diagnosis, but most approaches require extraction of ECG beats or consider leads independently of one another. We propose an end-to-end deep learning approach, DeepMI, to classify MI from normal cases as well as identifying the time-occurrence of MI (defined as acute, recent and old), using a collection of fusion strategies on 12 ECG leads at data-, feature-, and decision-level. In order to minimise computational overhead, we employ transfer learning using existing computer vision networks. Moreover, we use recurrent neural networks to encode the longitudinal information inherent in ECGs. We validated DeepMI on a dataset collected from 17,381 patients, in which over 323,000 samples were extracted per ECG lead. We were able to classify normal cases as well as acute, recent and old onset cases of MI, with AUROCs of 96.7%, 82.9%, 68.6% and 73.8%, respectively. We have demonstrated a multi-lead fusion approach to detect the presence and occurrence-time of MI. Our end-to-end framework provides flexibility for different levels of multi-lead ECG fusion and performs feature extraction via transfer learning.

</p>
</details>

<details><summary><b>Gesture Similarity Analysis on Event Data Using a Hybrid Guided Variational Auto Encoder</b>
<a href="https://arxiv.org/abs/2104.00165">arxiv:2104.00165</a>
&#x1F4C8; 1 <br>
<p>Kenneth Stewart, Andreea Danielescu, Lazar Supic, Timothy Shea, Emre Neftci</p></summary>
<p>

**Abstract:** While commercial mid-air gesture recognition systems have existed for at least a decade, they have not become a widespread method of interacting with machines. This is primarily due to the fact that these systems require rigid, dramatic gestures to be performed for accurate recognition that can be fatiguing and unnatural. The global pandemic has seen a resurgence of interest in touchless interfaces, so new methods that allow for natural mid-air gestural interactions are even more important. To address the limitations of recognition systems, we propose a neuromorphic gesture analysis system which naturally declutters the background and analyzes gestures at high temporal resolution. Our novel model consists of an event-based guided Variational Autoencoder (VAE) which encodes event-based data sensed by a Dynamic Vision Sensor (DVS) into a latent space representation suitable to analyze and compute the similarity of mid-air gesture data. Our results show that the features learned by the VAE provides a similarity measure capable of clustering and pseudo labeling of new gestures. Furthermore, we argue that the resulting event-based encoder and pseudo-labeling system are suitable for implementation in neuromorphic hardware for online adaptation and learning of natural mid-air gestures.

</p>
</details>

<details><summary><b>Adversarial Heart Attack: Neural Networks Fooled to Segment Heart Symbols in Chest X-Ray Images</b>
<a href="https://arxiv.org/abs/2104.00139">arxiv:2104.00139</a>
&#x1F4C8; 1 <br>
<p>Gerda Bortsova, Florian Dubost, Laurens Hogeweg, Ioannis Katramados, Marleen de Bruijne</p></summary>
<p>

**Abstract:** Adversarial attacks consist in maliciously changing the input data to mislead the predictions of automated decision systems and are potentially a serious threat for automated medical image analysis. Previous studies have shown that it is possible to adversarially manipulate automated segmentations produced by neural networks in a targeted manner in the white-box attack setting. In this article, we studied the effectiveness of adversarial attacks in targeted modification of segmentations of anatomical structures in chest X-rays. Firstly, we experimented with using anatomically implausible shapes as targets for adversarial manipulation. We showed that, by adding almost imperceptible noise to the image, we can reliably force state-of-the-art neural networks to segment the heart as a heart symbol instead of its real anatomical shape. Moreover, such heart-shaping attack did not appear to require higher adversarial noise level than an untargeted attack based the same attack method. Secondly, we attempted to explore the limits of adversarial manipulation of segmentations. For that, we assessed the effectiveness of shrinking and enlarging segmentation contours for the three anatomical structures. We observed that adversarially extending segmentations of structures into regions with intensity and texture uncharacteristic for them presented a challenge to our attacks, as well as, in some cases, changing segmentations in ways that conflict with class adjacency priors learned by the target network. Additionally, we evaluated performances of the untargeted attacks and targeted heart attacks in the black-box attack scenario, using a surrogate network trained on a different subset of images. In both cases, the attacks were substantially less effective. We believe these findings bring novel insights into the current capabilities and limits of adversarial attacks for semantic segmentation.

</p>
</details>

<details><summary><b>Transfer Learning for Node Regression Applied to Spreading Prediction</b>
<a href="https://arxiv.org/abs/2104.00088">arxiv:2104.00088</a>
&#x1F4C8; 1 <br>
<p>Sebastian Me≈ænar, Nada Lavraƒç, Bla≈æ ≈†krlj</p></summary>
<p>

**Abstract:** Understanding how information propagates in real-life complex networks yields a better understanding of dynamic processes such as misinformation or epidemic spreading. The recently introduced branch of machine learning methods for learning node representations offers many novel applications, one of them being the task of spreading prediction addressed in this paper. We explore the utility of the state-of-the-art node representation learners when used to assess the effects of spreading from a given node, estimated via extensive simulations. Further, as many real-life networks are topologically similar, we systematically investigate whether the learned models generalize to previously unseen networks, showing that in some cases very good model transfer can be obtained. This work is one of the first to explore transferability of the learned representations for the task of node regression; we show there exist pairs of networks with similar structure between which the trained models can be transferred (zero-shot), and demonstrate their competitive performance. To our knowledge, this is one of the first attempts to evaluate the utility of zero-shot transfer for the task of node regression.

</p>
</details>

<details><summary><b>Ultra-Reliable Indoor Millimeter Wave Communications using Multiple Artificial Intelligence-Powered Intelligent Surfaces</b>
<a href="https://arxiv.org/abs/2104.00075">arxiv:2104.00075</a>
&#x1F4C8; 1 <br>
<p>Mehdi Naderi Soorki, Walid Saad, Mehdi Bennis, Choong Seon Hong</p></summary>
<p>

**Abstract:** In this paper, a novel framework for guaranteeing ultra-reliable millimeter wave (mmW) communications using multiple artificial intelligence (AI)-enabled reconfigurable intelligent surfaces (RISs) is proposed. The use of multiple AI-powered RISs allows changing the propagation direction of the signals transmitted from a mmW access point (AP) thereby improving coverage particularly for non-line-of-sight (NLoS) areas. However, due to the possibility of highly stochastic blockage over mmW links, designing an intelligent controller to jointly optimize the mmW AP beam and RIS phase shifts is a daunting task. In this regard, first, a parametric risk-sensitive episodic return is proposed to maximize the expected bit rate and mitigate the risk of mmW link blockage. Then, a closed-form approximation of the policy gradient of the risk-sensitive episodic return is analytically derived. Next, the problem of joint beamforming for mmW AP and phase shift control for mmW RISs is modeled as an identical payoff stochastic game within a cooperative multi-agent environment, in which the agents are the mmW AP and the RISs. Two centralized and distributed controllers are proposed to control the policies of the mmW AP and RISs. To directly find an optimal solution, the parametric functional-form policies for these controllers are modeled using deep recurrent neural networks (RNNs). Simulation results show that the error between policies of the optimal and the RNN-based controllers is less than 1.5%. Moreover, the variance of the achievable rates resulting from the deep RNN-based controllers is 60% less than the variance of the risk-averse baseline.

</p>
</details>

<details><summary><b>Fast and Accurate Emulation of the SDO/HMI Stokes Inversion with Uncertainty Quantification</b>
<a href="https://arxiv.org/abs/2103.17273">arxiv:2103.17273</a>
&#x1F4C8; 1 <br>
<p>Richard E. L. Higgins, David F. Fouhey, Dichang Zhang, Spiro K. Antiochos, Graham Barnes, J. Todd Hoeksema, K. D. Leka, Yang Liu, Peter W. Schuck, Tamas I. Gombosi</p></summary>
<p>

**Abstract:** The Helioseismic and Magnetic Imager (HMI) onboard NASA's Solar Dynamics Observatory (SDO) produces estimates of the photospheric magnetic field which are a critical input to many space weather modelling and forecasting systems. The magnetogram products produced by HMI and its analysis pipeline are the result of a per-pixel optimization that estimates solar atmospheric parameters and minimizes disagreement between a synthesized and observed Stokes vector. In this paper, we introduce a deep learning-based approach that can emulate the existing HMI pipeline results two orders of magnitude faster than the current pipeline algorithms. Our system is a U-Net trained on input Stokes vectors and their accompanying optimization-based VFISV inversions. We demonstrate that our system, once trained, can produce high-fidelity estimates of the magnetic field and kinematic and thermodynamic parameters while also producing meaningful confidence intervals. We additionally show that despite penalizing only per-pixel loss terms, our system is able to faithfully reproduce known systematic oscillations in full-disk statistics produced by the pipeline. This emulation system could serve as an initialization for the full Stokes inversion or as an ultra-fast proxy inversion. This work is part of the NASA Heliophysics DRIVE Science Center (SOLSTICE) at the University of Michigan, under grant NASA 80NSSC20K0600E, and has been open sourced.

</p>
</details>

<details><summary><b>Modeling Users and Online Communities for Abuse Detection: A Position on Ethics and Explainability</b>
<a href="https://arxiv.org/abs/2103.17191">arxiv:2103.17191</a>
&#x1F4C8; 1 <br>
<p>Pushkar Mishra, Helen Yannakoudakis, Ekaterina Shutova</p></summary>
<p>

**Abstract:** Abuse on the Internet is an important societal problem of our time. Millions of Internet users face harassment, racism, personal attacks, and other types of abuse across various platforms. The psychological effects of abuse on individuals can be profound and lasting. Consequently, over the past few years, there has been a substantial research effort towards automated abusive language detection in the field of NLP. In this position paper, we discuss the role that modeling of users and online communities plays in abuse detection. Specifically, we review and analyze the state of the art methods that leverage user or community information to enhance the understanding and detection of abusive language. We then explore the ethical challenges of incorporating user and community information, laying out considerations to guide future research. Finally, we address the topic of explainability in abusive language detection, proposing properties that an explainable method should aim to exhibit. We describe how user and community information can facilitate the realization of these properties and discuss the effective operationalization of explainability in view of the properties.

</p>
</details>

<details><summary><b>MOAI: A methodology for evaluating the impact of indoor airflow in the transmission of COVID-19</b>
<a href="https://arxiv.org/abs/2103.17096">arxiv:2103.17096</a>
&#x1F4C8; 1 <br>
<p>Axel Oehmichen, Florian Guitton, Cedric Wahl, Bertrand Foing, Damian Tziamtzis, Yike Guo</p></summary>
<p>

**Abstract:** Epidemiology models play a key role in understanding and responding to the COVID-19 pandemic. In order to build those models, scientists need to understand contributing factors and their relative importance. A large strand of literature has identified the importance of airflow to mitigate droplets and far-field aerosol transmission risks. However, the specific factors contributing to higher or lower contamination in various settings have not been clearly defined and quantified. As part of the MOAI project (https://moaiapp.com), we are developing a privacy-preserving test and trace app to enable infection cluster investigators to get in touch with patients without having to know their identity. This approach allows involving users in the fight against the pandemic by contributing additional information in the form of anonymous research questionnaires. We first describe how the questionnaire was designed, and the synthetic data was generated based on a review we carried out on the latest available literature. We then present a model to evaluate the risk exposition of a user for a given setting. We finally propose a temporal addition to the model to evaluate the risk exposure over time for a given user.

</p>
</details>

<details><summary><b>A Novel Deep ML Architecture by Integrating Visual Simultaneous Localization and Mapping (vSLAM) into Mask R-CNN for Real-time Surgical Video Analysis</b>
<a href="https://arxiv.org/abs/2103.16847">arxiv:2103.16847</a>
&#x1F4C8; 1 <br>
<p>Ella Selina Lan</p></summary>
<p>

**Abstract:** Seven million people suffer complications after surgery each year. With sufficient surgical training and feedback, half of these complications could be prevented. Automatic surgical video analysis, especially for minimally invasive surgery, plays a key role in training and review, with increasing interests from recent studies on tool and workflow detection. In this research, a novel machine learning architecture, RPM-CNN, is created to perform real-time surgical video analysis. This architecture, for the first time, integrates visual simultaneous localization and mapping (vSLAM) into Mask R-CNN. Spatio-temporal information, in addition to the visual features, is utilized to increase the accuracy to 96.8 mAP for tool detection and 97.5 mean Jaccard for workflow detection, surpassing all previous works via the same benchmark dataset. As a real-time prediction, the RPM-CNN model reaches a 50 FPS runtime performance speed, 10x faster than region based CNN, by modeling the spatio-temporal information directly from surgical videos during the vSLAM 3D mapping. Additionally, this novel Region Proposal Module (RPM) replaces the region proposal network (RPN) in Mask R-CNN, accurately placing bounding-boxes and lessening the annotation requirement. In principle, this architecture integrates the best of both worlds, inclusive of (1) vSLAM on object detection, through focusing on geometric information for region proposals and (2) CNN on object recognition, through focusing on semantic information for image classification; the integration of these two technologies into one joint training process opens a new door in computer vision. Furthermore, to apply RPM-CNN's real-time top performance to the real world, a Microsoft HoloLens 2 application is developed to provide an augmented reality (AR) based solution for both surgical training and assistance.

</p>
</details>

<details><summary><b>Topic Scaling: A Joint Document Scaling -- Topic Model Approach To Learn Time-Specific Topics</b>
<a href="https://arxiv.org/abs/2104.01117">arxiv:2104.01117</a>
&#x1F4C8; 0 <br>
<p>Sami Diaf, Ulrich Fritsche</p></summary>
<p>

**Abstract:** This paper proposes a new methodology to study sequential corpora by implementing a two-stage algorithm that learns time-based topics with respect to a scale of document positions and introduces the concept of Topic Scaling which ranks learned topics within the same document scale. The first stage ranks documents using Wordfish, a Poisson-based document scaling method, to estimate document positions that serve, in the second stage, as a dependent variable to learn relevant topics via a supervised Latent Dirichlet Allocation. This novelty brings two innovations in text mining as it explains document positions, whose scale is a latent variable, and ranks the inferred topics on the document scale to match their occurrences within the corpus and track their evolution. Tested on the U.S. State Of The Union two-party addresses, this inductive approach reveals that each party dominates one end of the learned scale with interchangeable transitions that follow the parties' term of office. Besides a demonstrated high accuracy in predicting in-sample documents' positions from topic scores, this method reveals further hidden topics that differentiate similar documents by increasing the number of learned topics to unfold potential nested hierarchical topic structures. Compared to other popular topic models, Topic Scaling learns topics with respect to document similarities without specifying a time frequency to learn topic evolution, thus capturing broader topic patterns than dynamic topic models and yielding more interpretable outputs than a plain latent Dirichlet allocation.

</p>
</details>

<details><summary><b>Time Series Analysis and Modeling to Forecast: a Survey</b>
<a href="https://arxiv.org/abs/2104.00164">arxiv:2104.00164</a>
&#x1F4C8; 0 <br>
<p>Fatoumata Dama, Christine Sinoquet</p></summary>
<p>

**Abstract:** Time series modeling for predictive purpose has been an active research area of machine learning for many years. However, no sufficiently comprehensive and meanwhile substantive survey was offered so far. This survey strives to meet this need. A unified presentation has been adopted for entire parts of this compilation.
  A red thread guides the reader from time series preprocessing to forecasting. Time series decomposition is a major preprocessing task, to separate nonstationary effects (the deterministic components) from the remaining stochastic constituent, assumed to be stationary. The deterministic components are predictable and contribute to the prediction through estimations or extrapolation. Fitting the most appropriate model to the remaining stochastic component aims at capturing the relationship between past and future values, to allow prediction.
  We cover a sufficiently broad spectrum of models while nonetheless offering substantial methodological developments. We describe three major linear parametric models, together with two nonlinear extensions, and present five categories of nonlinear parametric models. Beyond conventional statistical models, we highlight six categories of deep neural networks appropriate for time series forecasting in nonlinear framework.
  Finally, we enlighten new avenues of research for time series modeling and forecasting. We also report software made publicly available for the models presented.

</p>
</details>

<details><summary><b>Fast Certified Robust Training with Short Warmup</b>
<a href="https://arxiv.org/abs/2103.17268">arxiv:2103.17268</a>
&#x1F4C8; 0 <br>
<p>Zhouxing Shi, Yihan Wang, Huan Zhang, Jinfeng Yi, Cho-Jui Hsieh</p></summary>
<p>

**Abstract:** Recently, bound propagation based certified robust training methods have been proposed for training neural networks with certifiable robustness guarantees. Despite that state-of-the-art (SOTA) methods including interval bound propagation (IBP) and CROWN-IBP have per-batch training complexity similar to standard neural network training, they usually use a long warmup schedule with hundreds or thousands epochs to reach SOTA performance and are thus still costly. In this paper, we identify two important issues in existing methods, namely exploded bounds at initialization, and the imbalance in ReLU activation states and improve IBP training. These two issues make certified training difficult and unstable, and thereby long warmup schedules were needed in prior works. To mitigate these issues and conduct faster certified training with shorter warmup, we propose three improvements based on IBP training: 1) We derive a new weight initialization method for IBP training; 2) We propose to fully add Batch Normalization (BN) to each layer in the model, since we find BN can reduce the imbalance in ReLU activation states; 3) We also design regularization to explicitly tighten certified bounds and balance ReLU activation states during wamrup. We are able to obtain 65.03% verified error on CIFAR-10 ($Œµ=\frac{8}{255}$) and 82.36% verified error on TinyImageNet ($Œµ=\frac{1}{255}$) using very short training schedules (160 and 80 total epochs, respectively), outperforming literature SOTA trained with hundreds or thousands epochs under the same network architecture. The code is available at https://github.com/shizhouxing/Fast-Certified-Robust-Training.

</p>
</details>

<details><summary><b>High-Dimensional Uncertainty Quantification via Tensor Regression with Rank Determination and Adaptive Sampling</b>
<a href="https://arxiv.org/abs/2103.17236">arxiv:2103.17236</a>
&#x1F4C8; 0 <br>
<p>Zichang He, Zheng Zhang</p></summary>
<p>

**Abstract:** Fabrication process variations can significantly influence the performance and yield of nano-scale electronic and photonic circuits. Stochastic spectral methods have achieved great success in quantifying the impact of process variations, but they suffer from the curse of dimensionality. Recently, low-rank tensor methods have been developed to mitigate this issue, but two fundamental challenges remain open: how to automatically determine the tensor rank and how to adaptively pick the informative simulation samples. This paper proposes a novel tensor regression method to address these two challenges. We use a $\ell_{q}/ \ell_{2}$ group-sparsity regularization to determine the tensor rank. The resulting optimization problem can be efficiently solved via an alternating minimization solver. We also propose a two-stage adaptive sampling method to reduce the simulation cost. Our method considers both exploration and exploitation via the estimated Voronoi cell volume and nonlinearity measurement respectively. The proposed model is verified with synthetic and some realistic circuit benchmarks, on which our method can well capture the uncertainty caused by 19 to 100 random variables with only 100 to 600 simulation samples.

</p>
</details>

<details><summary><b>$Œ±$-Geodesical Skew Divergence</b>
<a href="https://arxiv.org/abs/2103.17060">arxiv:2103.17060</a>
&#x1F4C8; 0 <br>
<p>Masanari Kimura, Hideitsu Hino</p></summary>
<p>

**Abstract:** The asymmetric skew divergence smooths one of the distributions by mixing it, to a degree determined by the parameter $Œª$, with the other distribution. Such divergence is an approximation of the KL divergence that does not require the target distribution to be absolutely continuous with respect to the source distribution. In this paper, an information geometric generalization of the skew divergence called the $Œ±$-geodesical skew divergence is proposed, and its properties are studied.

</p>
</details>

<details><summary><b>Learning Scalable $\ell_\infty$-constrained Near-lossless Image Compression via Joint Lossy Image and Residual Compression</b>
<a href="https://arxiv.org/abs/2103.17015">arxiv:2103.17015</a>
&#x1F4C8; 0 <br>
<p>Yuanchao Bai, Xianming Liu, Wangmeng Zuo, Yaowei Wang, Xiangyang Ji</p></summary>
<p>

**Abstract:** We propose a novel joint lossy image and residual compression framework for learning $\ell_\infty$-constrained near-lossless image compression. Specifically, we obtain a lossy reconstruction of the raw image through lossy image compression and uniformly quantize the corresponding residual to satisfy a given tight $\ell_\infty$ error bound. Suppose that the error bound is zero, i.e., lossless image compression, we formulate the joint optimization problem of compressing both the lossy image and the original residual in terms of variational auto-encoders and solve it with end-to-end training. To achieve scalable compression with the error bound larger than zero, we derive the probability model of the quantized residual by quantizing the learned probability model of the original residual, instead of training multiple networks. We further correct the bias of the derived probability model caused by the context mismatch between training and inference. Finally, the quantized residual is encoded according to the bias-corrected probability model and is concatenated with the bitstream of the compressed lossy image. Experimental results demonstrate that our near-lossless codec achieves the state-of-the-art performance for lossless and near-lossless image compression, and achieves competitive PSNR while much smaller $\ell_\infty$ error compared with lossy image codecs at high bit rates.

</p>
</details>


[Next Page](2021/2021-03/2021-03-30.md)
