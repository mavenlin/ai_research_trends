## Summary for 2021-07-19, created on 2021-12-19


<details><summary><b>Epistemic Neural Networks</b>
<a href="https://arxiv.org/abs/2107.08924">arxiv:2107.08924</a>
&#x1F4C8; 352 <br>
<p>Ian Osband, Zheng Wen, Mohammad Asghari, Morteza Ibrahimi, Xiyuan Lu, Benjamin Van Roy</p></summary>
<p>

**Abstract:** We introduce the \textit{epistemic neural network} (ENN) as an interface for uncertainty modeling in deep learning. All existing approaches to uncertainty modeling can be expressed as ENNs, and any ENN can be identified with a Bayesian neural network. However, this new perspective provides several promising directions for future research. Where prior work has developed probabilistic inference tools for neural networks; we ask instead, `which neural networks are suitable as tools for probabilistic inference?'. We propose a clear and simple metric for progress in ENNs: the KL-divergence with respect to a target distribution. We develop a computational testbed based on inference in a neural network Gaussian process and release our code as a benchmark at \url{https://github.com/deepmind/enn}. We evaluate several canonical approaches to uncertainty modeling in deep learning, and find they vary greatly in their performance. We provide insight to the sensitivity of these results and show that our metric is highly correlated with performance in sequential decision problems. Finally, we provide indications that new ENN architectures can improve performance in both the statistical quality and computational cost.

</p>
</details>

<details><summary><b>Frequency-Supervised MR-to-CT Image Synthesis</b>
<a href="https://arxiv.org/abs/2107.08962">arxiv:2107.08962</a>
&#x1F4C8; 76 <br>
<p>Zenglin Shi, Pascal Mettes, Guoyan Zheng, Cees Snoek</p></summary>
<p>

**Abstract:** This paper strives to generate a synthetic computed tomography (CT) image from a magnetic resonance (MR) image. The synthetic CT image is valuable for radiotherapy planning when only an MR image is available. Recent approaches have made large strides in solving this challenging synthesis problem with convolutional neural networks that learn a mapping from MR inputs to CT outputs. In this paper, we find that all existing approaches share a common limitation: reconstruction breaks down in and around the high-frequency parts of CT images. To address this common limitation, we introduce frequency-supervised deep networks to explicitly enhance high-frequency MR-to-CT image reconstruction. We propose a frequency decomposition layer that learns to decompose predicted CT outputs into low- and high-frequency components, and we introduce a refinement module to improve high-frequency reconstruction through high-frequency adversarial learning. Experimental results on a new dataset with 45 pairs of 3D MR-CT brain images show the effectiveness and potential of the proposed approach. Code is available at \url{https://github.com/shizenglin/Frequency-Supervised-MR-to-CT-Image-Synthesis}.

</p>
</details>

<details><summary><b>Sequence-to-Sequence Piano Transcription with Transformers</b>
<a href="https://arxiv.org/abs/2107.09142">arxiv:2107.09142</a>
&#x1F4C8; 73 <br>
<p>Curtis Hawthorne, Ian Simon, Rigel Swavely, Ethan Manilow, Jesse Engel</p></summary>
<p>

**Abstract:** Automatic Music Transcription has seen significant progress in recent years by training custom deep neural networks on large datasets. However, these models have required extensive domain-specific design of network architectures, input/output representations, and complex decoding schemes. In this work, we show that equivalent performance can be achieved using a generic encoder-decoder Transformer with standard decoding methods. We demonstrate that the model can learn to translate spectrogram inputs directly to MIDI-like output events for several transcription tasks. This sequence-to-sequence approach simplifies transcription by jointly modeling audio features and language-like output dependencies, thus removing the need for task-specific architectures. These results point toward possibilities for creating new Music Information Retrieval models by focusing on dataset creation and labeling rather than custom model design.

</p>
</details>

<details><summary><b>Hierarchical Few-Shot Imitation with Skill Transition Models</b>
<a href="https://arxiv.org/abs/2107.08981">arxiv:2107.08981</a>
&#x1F4C8; 45 <br>
<p>Kourosh Hakhamaneshi, Ruihan Zhao, Albert Zhan, Pieter Abbeel, Michael Laskin</p></summary>
<p>

**Abstract:** A desirable property of autonomous agents is the ability to both solve long-horizon problems and generalize to unseen tasks. Recent advances in data-driven skill learning have shown that extracting behavioral priors from offline data can enable agents to solve challenging long-horizon tasks with reinforcement learning. However, generalization to tasks unseen during behavioral prior training remains an outstanding challenge. To this end, we present Few-shot Imitation with Skill Transition Models (FIST), an algorithm that extracts skills from offline data and utilizes them to generalize to unseen tasks given a few downstream demonstrations. FIST learns an inverse skill dynamics model, a distance function, and utilizes a semi-parametric approach for imitation. We show that FIST is capable of generalizing to new tasks and substantially outperforms prior baselines in navigation experiments requiring traversing unseen parts of a large maze and 7-DoF robotic arm experiments requiring manipulating previously unseen objects in a kitchen.

</p>
</details>

<details><summary><b>Translatotron 2: Robust direct speech-to-speech translation</b>
<a href="https://arxiv.org/abs/2107.08661">arxiv:2107.08661</a>
&#x1F4C8; 25 <br>
<p>Ye Jia, Michelle Tadmor Ramanovich, Tal Remez, Roi Pomerantz</p></summary>
<p>

**Abstract:** We present Translatotron 2, a neural direct speech-to-speech translation model that can be trained end-to-end. Translatotron 2 consists of a speech encoder, a phoneme decoder, a mel-spectrogram synthesizer, and an attention module that connects all the previous three components. Experimental results suggest that Translatotron 2 outperforms the original Translatotron by a large margin in terms of translation quality and predicted speech naturalness, and drastically improves the robustness of the predicted speech by mitigating over-generation, such as babbling or long pause. We also propose a new method for retaining the source speaker's voice in the translated speech. The trained model is restricted to retain the source speaker's voice, but unlike the original Translatotron, it is not able to generate speech in a different speaker's voice, making the model more robust for production deployment, by mitigating potential misuse for creating spoofing audio artifacts. When the new method is used together with a simple concatenation-based data augmentation, the trained Translatotron 2 model is able to retain each speaker's voice for input with speaker turns.

</p>
</details>

<details><summary><b>Reasoning-Modulated Representations</b>
<a href="https://arxiv.org/abs/2107.08881">arxiv:2107.08881</a>
&#x1F4C8; 24 <br>
<p>Petar Veličković, Matko Bošnjak, Thomas Kipf, Alexander Lerchner, Raia Hadsell, Razvan Pascanu, Charles Blundell</p></summary>
<p>

**Abstract:** Neural networks leverage robust internal representations in order to generalise. Learning them is difficult, and often requires a large training set that covers the data distribution densely. We study a common setting where our task is not purely opaque. Indeed, very often we may have access to information about the underlying system (e.g. that observations must obey certain laws of physics) that any "tabula rasa" neural network would need to re-learn from scratch, penalising data efficiency. We incorporate this information into a pre-trained reasoning module, and investigate its role in shaping the discovered representations in diverse self-supervised learning settings from pixels. Our approach paves the way for a new class of data-efficient representation learning.

</p>
</details>

<details><summary><b>Face.evoLVe: A High-Performance Face Recognition Library</b>
<a href="https://arxiv.org/abs/2107.08621">arxiv:2107.08621</a>
&#x1F4C8; 22 <br>
<p>Qingzhong Wang, Pengfei Zhang, Haoyi Xiong, Jian Zhao</p></summary>
<p>

**Abstract:** In this paper, we develop face.evoLVe -- a comprehensive library that collects and implements a wide range of popular deep learning-based methods for face recognition. First of all, face.evoLVe is composed of key components that cover the full process of face analytics, including face alignment, data processing, various backbones, losses, and alternatives with bags of tricks for improving performance. Later, face.evoLVe supports multi-GPU training on top of different deep learning platforms, such as PyTorch and PaddlePaddle, which facilitates researchers to work on both large-scale datasets with millions of images and low-shot counterparts with limited well-annotated data. More importantly, along with face.evoLVe, images before & after alignment in the common benchmark datasets are released with source codes and trained models provided. All these efforts lower the technical burdens in reproducing the existing methods for comparison, while users of our library could focus on developing advanced approaches more efficiently. Last but not least, face.evoLVe is well designed and vibrantly evolving, so that new face recognition approaches can be easily plugged into our framework. Note that we have used face.evoLVe to participate in a number of face recognition competitions and secured the first place. The version that supports PyTorch is publicly available at https://github.com/ZhaoJ9014/face.evoLVe.PyTorch and the PaddlePaddle version is available at https://github.com/ZhaoJ9014/face.evoLVe.PyTorch/tree/master/paddle. Face.evoLVe has been widely used for face analytics, receiving 2.4K stars and 622 forks.

</p>
</details>

<details><summary><b>Decoupling Exploration and Exploitation in Reinforcement Learning</b>
<a href="https://arxiv.org/abs/2107.08966">arxiv:2107.08966</a>
&#x1F4C8; 21 <br>
<p>Lukas Schäfer, Filippos Christianos, Josiah Hanna, Stefano V. Albrecht</p></summary>
<p>

**Abstract:** Intrinsic rewards are commonly applied to improve exploration in reinforcement learning. However, these approaches suffer from instability caused by non-stationary reward shaping and strong dependency on hyperparameters. In this work, we propose Decoupled RL (DeRL) which trains separate policies for exploration and exploitation. DeRL can be applied with on-policy and off-policy RL algorithms. We evaluate DeRL algorithms in two sparse-reward environments with multiple types of intrinsic rewards. We show that DeRL is more robust to scaling and speed of decay of intrinsic rewards and converges to the same evaluation returns than intrinsically motivated baselines in fewer interactions.

</p>
</details>

<details><summary><b>Token-Level Supervised Contrastive Learning for Punctuation Restoration</b>
<a href="https://arxiv.org/abs/2107.09099">arxiv:2107.09099</a>
&#x1F4C8; 10 <br>
<p>Qiushi Huang, Tom Ko, H Lilian Tang, Xubo Liu, Bo Wu</p></summary>
<p>

**Abstract:** Punctuation is critical in understanding natural language text. Currently, most automatic speech recognition (ASR) systems do not generate punctuation, which affects the performance of downstream tasks, such as intent detection and slot filling. This gives rise to the need for punctuation restoration. Recent work in punctuation restoration heavily utilizes pre-trained language models without considering data imbalance when predicting punctuation classes. In this work, we address this problem by proposing a token-level supervised contrastive learning method that aims at maximizing the distance of representation of different punctuation marks in the embedding space. The result shows that training with token-level supervised contrastive learning obtains up to 3.2% absolute F1 improvement on the test set.

</p>
</details>

<details><summary><b>Just Train Twice: Improving Group Robustness without Training Group Information</b>
<a href="https://arxiv.org/abs/2107.09044">arxiv:2107.09044</a>
&#x1F4C8; 10 <br>
<p>Evan Zheran Liu, Behzad Haghgoo, Annie S. Chen, Aditi Raghunathan, Pang Wei Koh, Shiori Sagawa, Percy Liang, Chelsea Finn</p></summary>
<p>

**Abstract:** Standard training via empirical risk minimization (ERM) can produce models that achieve high accuracy on average but low accuracy on certain groups, especially in the presence of spurious correlations between the input and label. Prior approaches that achieve high worst-group accuracy, like group distributionally robust optimization (group DRO) require expensive group annotations for each training point, whereas approaches that do not use such group annotations typically achieve unsatisfactory worst-group accuracy. In this paper, we propose a simple two-stage approach, JTT, that first trains a standard ERM model for several epochs, and then trains a second model that upweights the training examples that the first model misclassified. Intuitively, this upweights examples from groups on which standard ERM models perform poorly, leading to improved worst-group performance. Averaged over four image classification and natural language processing tasks with spurious correlations, JTT closes 75% of the gap in worst-group accuracy between standard ERM and group DRO, while only requiring group annotations on a small validation set in order to tune hyperparameters.

</p>
</details>

<details><summary><b>Ab Initio Particle-based Object Manipulation</b>
<a href="https://arxiv.org/abs/2107.08865">arxiv:2107.08865</a>
&#x1F4C8; 10 <br>
<p>Siwei Chen, Xiao Ma, Yunfan Lu, David Hsu</p></summary>
<p>

**Abstract:** This paper presents Particle-based Object Manipulation (Prompt), a new approach to robot manipulation of novel objects ab initio, without prior object models or pre-training on a large object data set. The key element of Prompt is a particle-based object representation, in which each particle represents a point in the object, the local geometric, physical, and other features of the point, and also its relation with other particles. Like the model-based analytic approaches to manipulation, the particle representation enables the robot to reason about the object's geometry and dynamics in order to choose suitable manipulation actions. Like the data-driven approaches, the particle representation is learned online in real-time from visual sensor input, specifically, multi-view RGB images. The particle representation thus connects visual perception with robot control. Prompt combines the benefits of both model-based reasoning and data-driven learning. We show empirically that Prompt successfully handles a variety of everyday objects, some of which are transparent. It handles various manipulation tasks, including grasping, pushing, etc,. Our experiments also show that Prompt outperforms a state-of-the-art data-driven grasping method on the daily objects, even though it does not use any offline training data.

</p>
</details>

<details><summary><b>Learning Attributed Graph Representations with Communicative Message Passing Transformer</b>
<a href="https://arxiv.org/abs/2107.08773">arxiv:2107.08773</a>
&#x1F4C8; 10 <br>
<p>Jianwen Chen, Shuangjia Zheng, Ying Song, Jiahua Rao, Yuedong Yang</p></summary>
<p>

**Abstract:** Constructing appropriate representations of molecules lies at the core of numerous tasks such as material science, chemistry and drug designs. Recent researches abstract molecules as attributed graphs and employ graph neural networks (GNN) for molecular representation learning, which have made remarkable achievements in molecular graph modeling. Albeit powerful, current models either are based on local aggregation operations and thus miss higher-order graph properties or focus on only node information without fully using the edge information. For this sake, we propose a Communicative Message Passing Transformer (CoMPT) neural network to improve the molecular graph representation by reinforcing message interactions between nodes and edges based on the Transformer architecture. Unlike the previous transformer-style GNNs that treat molecules as fully connected graphs, we introduce a message diffusion mechanism to leverage the graph connectivity inductive bias and reduce the message enrichment explosion. Extensive experiments demonstrated that the proposed model obtained superior performances (around 4$\%$ on average) against state-of-the-art baselines on seven chemical property datasets (graph-level tasks) and two chemical shift datasets (node-level tasks). Further visualization studies also indicated a better representation capacity achieved by our model.

</p>
</details>

<details><summary><b>A quantum algorithm for training wide and deep classical neural networks</b>
<a href="https://arxiv.org/abs/2107.09200">arxiv:2107.09200</a>
&#x1F4C8; 9 <br>
<p>Alexander Zlokapa, Hartmut Neven, Seth Lloyd</p></summary>
<p>

**Abstract:** Given the success of deep learning in classical machine learning, quantum algorithms for traditional neural network architectures may provide one of the most promising settings for quantum machine learning. Considering a fully-connected feedforward neural network, we show that conditions amenable to classical trainability via gradient descent coincide with those necessary for efficiently solving quantum linear systems. We propose a quantum algorithm to approximately train a wide and deep neural network up to $O(1/n)$ error for a training set of size $n$ by performing sparse matrix inversion in $O(\log n)$ time. To achieve an end-to-end exponential speedup over gradient descent, the data distribution must permit efficient state preparation and readout. We numerically demonstrate that the MNIST image dataset satisfies such conditions; moreover, the quantum algorithm matches the accuracy of the fully-connected network. Beyond the proven architecture, we provide empirical evidence for $O(\log n)$ training of a convolutional neural network with pooling.

</p>
</details>

<details><summary><b>Playful Interactions for Representation Learning</b>
<a href="https://arxiv.org/abs/2107.09046">arxiv:2107.09046</a>
&#x1F4C8; 8 <br>
<p>Sarah Young, Jyothish Pari, Pieter Abbeel, Lerrel Pinto</p></summary>
<p>

**Abstract:** One of the key challenges in visual imitation learning is collecting large amounts of expert demonstrations for a given task. While methods for collecting human demonstrations are becoming easier with teleoperation methods and the use of low-cost assistive tools, we often still require 100-1000 demonstrations for every task to learn a visual representation and policy. To address this, we turn to an alternate form of data that does not require task-specific demonstrations -- play. Playing is a fundamental method children use to learn a set of skills and behaviors and visual representations in early learning. Importantly, play data is diverse, task-agnostic, and relatively cheap to obtain. In this work, we propose to use playful interactions in a self-supervised manner to learn visual representations for downstream tasks. We collect 2 hours of playful data in 19 diverse environments and use self-predictive learning to extract visual representations. Given these representations, we train policies using imitation learning for two downstream tasks: Pushing and Stacking. We demonstrate that our visual representations generalize better than standard behavior cloning and can achieve similar performance with only half the number of required demonstrations. Our representations, which are trained from scratch, compare favorably against ImageNet pretrained representations. Finally, we provide an experimental analysis on the effects of different pretraining modes on downstream task learning.

</p>
</details>

<details><summary><b>On the Veracity of Local, Model-agnostic Explanations in Audio Classification: Targeted Investigations with Adversarial Examples</b>
<a href="https://arxiv.org/abs/2107.09045">arxiv:2107.09045</a>
&#x1F4C8; 8 <br>
<p>Verena Praher, Katharina Prinz, Arthur Flexer, Gerhard Widmer</p></summary>
<p>

**Abstract:** Local explanation methods such as LIME have become popular in MIR as tools for generating post-hoc, model-agnostic explanations of a model's classification decisions. The basic idea is to identify a small set of human-understandable features of the classified example that are most influential on the classifier's prediction. These are then presented as an explanation. Evaluation of such explanations in publications often resorts to accepting what matches the expectation of a human without actually being able to verify if what the explanation shows is what really caused the model's prediction. This paper reports on targeted investigations where we try to get more insight into the actual veracity of LIME's explanations in an audio classification task. We deliberately design adversarial examples for the classifier, in a way that gives us knowledge about which parts of the input are potentially responsible for the model's (wrong) prediction. Asking LIME to explain the predictions for these adversaries permits us to study whether local explanations do indeed detect these regions of interest. We also look at whether LIME is more successful in finding perturbations that are more prominent and easily noticeable for a human. Our results suggest that LIME does not necessarily manage to identify the most relevant input features and hence it remains unclear whether explanations are useful or even misleading.

</p>
</details>

<details><summary><b>Directly Training Joint Energy-Based Models for Conditional Synthesis and Calibrated Prediction of Multi-Attribute Data</b>
<a href="https://arxiv.org/abs/2108.04227">arxiv:2108.04227</a>
&#x1F4C8; 7 <br>
<p>Jacob Kelly, Richard Zemel, Will Grathwohl</p></summary>
<p>

**Abstract:** Multi-attribute classification generalizes classification, presenting new challenges for making accurate predictions and quantifying uncertainty. We build upon recent work and show that architectures for multi-attribute prediction can be reinterpreted as energy-based models (EBMs). While existing EBM approaches achieve strong discriminative performance, they are unable to generate samples conditioned on novel attribute combinations. We propose a simple extension which expands the capabilities of EBMs to generating accurate conditional samples. Our approach, combined with newly developed techniques in energy-based model training, allows us to directly maximize the likelihood of data and labels under the unnormalized joint distribution. We evaluate our proposed approach on high-dimensional image data with high-dimensional binary attribute labels. We find our models are capable of both accurate, calibrated predictions and high-quality conditional synthesis of novel attribute combinations.

</p>
</details>

<details><summary><b>DeepSocNav: Social Navigation by Imitating Human Behaviors</b>
<a href="https://arxiv.org/abs/2107.09170">arxiv:2107.09170</a>
&#x1F4C8; 7 <br>
<p>Juan Pablo de Vicente, Alvaro Soto</p></summary>
<p>

**Abstract:** Current datasets to train social behaviors are usually borrowed from surveillance applications that capture visual data from a bird's-eye perspective. This leaves aside precious relationships and visual cues that could be captured through a first-person view of a scene. In this work, we propose a strategy to exploit the power of current game engines, such as Unity, to transform pre-existing bird's-eye view datasets into a first-person view, in particular, a depth view. Using this strategy, we are able to generate large volumes of synthetic data that can be used to pre-train a social navigation model. To test our ideas, we present DeepSocNav, a deep learning based model that takes advantage of the proposed approach to generate synthetic data. Furthermore, DeepSocNav includes a self-supervised strategy that is included as an auxiliary task. This consists of predicting the next depth frame that the agent will face. Our experiments show the benefits of the proposed model that is able to outperform relevant baselines in terms of social navigation scores.

</p>
</details>

<details><summary><b>CVEfixes: Automated Collection of Vulnerabilities and Their Fixes from Open-Source Software</b>
<a href="https://arxiv.org/abs/2107.08760">arxiv:2107.08760</a>
&#x1F4C8; 7 <br>
<p>Guru Prasad Bhandari, Amara Naseer, Leon Moonen</p></summary>
<p>

**Abstract:** Data-driven research on the automated discovery and repair of security vulnerabilities in source code requires comprehensive datasets of real-life vulnerable code and their fixes. To assist in such research, we propose a method to automatically collect and curate a comprehensive vulnerability dataset from Common Vulnerabilities and Exposures (CVE) records in the public National Vulnerability Database (NVD). We implement our approach in a fully automated dataset collection tool and share an initial release of the resulting vulnerability dataset named CVEfixes.
  The CVEfixes collection tool automatically fetches all available CVE records from the NVD, gathers the vulnerable code and corresponding fixes from associated open-source repositories, and organizes the collected information in a relational database. Moreover, the dataset is enriched with meta-data such as programming language, and detailed code and security metrics at five levels of abstraction. The collection can easily be repeated to keep up-to-date with newly discovered or patched vulnerabilities. The initial release of CVEfixes spans all published CVEs up to 9 June 2021, covering 5365 CVE records for 1754 open-source projects that were addressed in a total of 5495 vulnerability fixing commits.
  CVEfixes supports various types of data-driven software security research, such as vulnerability prediction, vulnerability classification, vulnerability severity prediction, analysis of vulnerability-related code changes, and automated vulnerability repair.

</p>
</details>

<details><summary><b>Generative Video Transformer: Can Objects be the Words?</b>
<a href="https://arxiv.org/abs/2107.09240">arxiv:2107.09240</a>
&#x1F4C8; 6 <br>
<p>Yi-Fu Wu, Jaesik Yoon, Sungjin Ahn</p></summary>
<p>

**Abstract:** Transformers have been successful for many natural language processing tasks. However, applying transformers to the video domain for tasks such as long-term video generation and scene understanding has remained elusive due to the high computational complexity and the lack of natural tokenization. In this paper, we propose the Object-Centric Video Transformer (OCVT) which utilizes an object-centric approach for decomposing scenes into tokens suitable for use in a generative video transformer. By factoring the video into objects, our fully unsupervised model is able to learn complex spatio-temporal dynamics of multiple interacting objects in a scene and generate future frames of the video. Our model is also significantly more memory-efficient than pixel-based models and thus able to train on videos of length up to 70 frames with a single 48GB GPU. We compare our model with previous RNN-based approaches as well as other possible video transformer baselines. We demonstrate OCVT performs well when compared to baselines in generating future frames. OCVT also develops useful representations for video reasoning, achieving start-of-the-art performance on the CATER task.

</p>
</details>

<details><summary><b>Limiting Dynamics of SGD: Modified Loss, Phase Space Oscillations, and Anomalous Diffusion</b>
<a href="https://arxiv.org/abs/2107.09133">arxiv:2107.09133</a>
&#x1F4C8; 6 <br>
<p>Daniel Kunin, Javier Sagastuy-Brena, Lauren Gillespie, Eshed Margalit, Hidenori Tanaka, Surya Ganguli, Daniel L. K. Yamins</p></summary>
<p>

**Abstract:** In this work we explore the limiting dynamics of deep neural networks trained with stochastic gradient descent (SGD). As observed previously, long after performance has converged, networks continue to move through parameter space by a process of anomalous diffusion in which distance travelled grows as a power law in the number of gradient updates with a nontrivial exponent. We reveal an intricate interaction between the hyperparameters of optimization, the structure in the gradient noise, and the Hessian matrix at the end of training that explains this anomalous diffusion. To build this understanding, we first derive a continuous-time model for SGD with finite learning rates and batch sizes as an underdamped Langevin equation. We study this equation in the setting of linear regression, where we can derive exact, analytic expressions for the phase space dynamics of the parameters and their instantaneous velocities from initialization to stationarity. Using the Fokker-Planck equation, we show that the key ingredient driving these dynamics is not the original training loss, but rather the combination of a modified loss, which implicitly regularizes the velocity, and probability currents, which cause oscillations in phase space. We identify qualitative and quantitative predictions of this theory in the dynamics of a ResNet-18 model trained on ImageNet. Through the lens of statistical physics, we uncover a mechanistic origin for the anomalous limiting dynamics of deep neural networks trained with SGD.

</p>
</details>

<details><summary><b>Separating Skills and Concepts for Novel Visual Question Answering</b>
<a href="https://arxiv.org/abs/2107.09106">arxiv:2107.09106</a>
&#x1F4C8; 6 <br>
<p>Spencer Whitehead, Hui Wu, Heng Ji, Rogerio Feris, Kate Saenko</p></summary>
<p>

**Abstract:** Generalization to out-of-distribution data has been a problem for Visual Question Answering (VQA) models. To measure generalization to novel questions, we propose to separate them into "skills" and "concepts". "Skills" are visual tasks, such as counting or attribute recognition, and are applied to "concepts" mentioned in the question, such as objects and people. VQA methods should be able to compose skills and concepts in novel ways, regardless of whether the specific composition has been seen in training, yet we demonstrate that existing models have much to improve upon towards handling new compositions. We present a novel method for learning to compose skills and concepts that separates these two factors implicitly within a model by learning grounded concept representations and disentangling the encoding of skills from that of concepts. We enforce these properties with a novel contrastive learning procedure that does not rely on external annotations and can be learned from unlabeled image-question pairs. Experiments demonstrate the effectiveness of our approach for improving compositional and grounding performance.

</p>
</details>

<details><summary><b>Know Thyself: Transferable Visuomotor Control Through Robot-Awareness</b>
<a href="https://arxiv.org/abs/2107.09047">arxiv:2107.09047</a>
&#x1F4C8; 6 <br>
<p>Edward S. Hu, Kun Huang, Oleh Rybkin, Dinesh Jayaraman</p></summary>
<p>

**Abstract:** Training visuomotor robot controllers from scratch on a new robot typically requires generating large amounts of robot-specific data. Could we leverage data previously collected on another robot to reduce or even completely remove this need for robot-specific data? We propose a "robot-aware" solution paradigm that exploits readily available robot "self-knowledge" such as proprioception, kinematics, and camera calibration to achieve this. First, we learn modular dynamics models that pair a transferable, robot-agnostic world dynamics module with a robot-specific, analytical robot dynamics module. Next, we set up visual planning costs that draw a distinction between the robot self and the world. Our experiments on tabletop manipulation tasks in simulation and on real robots demonstrate that these plug-in improvements dramatically boost the transferability of visuomotor controllers, even permitting zero-shot transfer onto new robots for the very first time. Project website: https://hueds.github.io/rac/

</p>
</details>

<details><summary><b>Structured Stochastic Gradient MCMC</b>
<a href="https://arxiv.org/abs/2107.09028">arxiv:2107.09028</a>
&#x1F4C8; 6 <br>
<p>Antonios Alexos, Alex Boyd, Stephan Mandt</p></summary>
<p>

**Abstract:** Stochastic gradient Markov chain Monte Carlo (SGMCMC) is considered the gold standard for Bayesian inference in large-scale models, such as Bayesian neural networks. Since practitioners face speed versus accuracy tradeoffs in these models, variational inference (VI) is often the preferable option. Unfortunately, VI makes strong assumptions on both the factorization and functional form of the posterior. In this work, we propose a new non-parametric variational approximation that makes no assumptions about the approximate posterior's functional form and allows practitioners to specify the exact dependencies the algorithm should respect or break. The approach relies on a new Langevin-type algorithm that operates on a modified energy function, where parts of the latent variables are averaged over samples from earlier iterations of the Markov chain. This way, statistical dependencies can be broken in a controlled way, allowing the chain to mix faster. This scheme can be further modified in a "dropout" manner, leading to even more scalability. By implementing the scheme on a ResNet-20 architecture, we obtain better predictive likelihoods and larger effective sample sizes than full SGMCMC.

</p>
</details>

<details><summary><b>A baseline model for computationally inexpensive speech recognition for Kazakh using the Coqui STT framework</b>
<a href="https://arxiv.org/abs/2107.10637">arxiv:2107.10637</a>
&#x1F4C8; 5 <br>
<p>Ilnar Salimzianov</p></summary>
<p>

**Abstract:** Mobile devices are transforming the way people interact with computers, and speech interfaces to applications are ever more important. Automatic Speech Recognition systems recently published are very accurate, but often require powerful machinery (specialised Graphical Processing Units) for inference, which makes them impractical to run on commodity devices, especially in streaming mode. Impressed by the accuracy of, but dissatisfied with the inference times of the baseline Kazakh ASR model of (Khassanov et al.,2021) when not using a GPU, we trained a new baseline acoustic model (on the same dataset as the aforementioned paper) and three language models for use with the Coqui STT framework. Results look promising, but further epochs of training and parameter sweeping or, alternatively, limiting the vocabulary that the ASR system must support, is needed to reach a production-level accuracy.

</p>
</details>

<details><summary><b>Evaluating Probabilistic Inference in Deep Learning: Beyond Marginal Predictions</b>
<a href="https://arxiv.org/abs/2107.09224">arxiv:2107.09224</a>
&#x1F4C8; 5 <br>
<p>Xiuyuan Lu, Ian Osband, Benjamin Van Roy, Zheng Wen</p></summary>
<p>

**Abstract:** A fundamental challenge for any intelligent system is prediction: given some inputs $X_1,..,X_τ$ can you predict outcomes $Y_1,.., Y_τ$. The KL divergence $\mathbf{d}_{\mathrm{KL}}$ provides a natural measure of prediction quality, but the majority of deep learning research looks only at the marginal predictions per input $X_t$. In this technical report we propose a scoring rule $\mathbf{d}_{\mathrm{KL}}^τ$, parameterized by $τ\in \mathcal{N}$ that evaluates the joint predictions at $τ$ inputs simultaneously. We show that the commonly-used $τ=1$ can be insufficient to drive good decisions in many settings of interest. We also show that, as $τ$ grows, performing well according to $\mathbf{d}_{\mathrm{KL}}^τ$ recovers universal guarantees for any possible decision. Finally, we provide problem-dependent guidance on the scale of $τ$ for which our score provides sufficient guarantees for good performance.

</p>
</details>

<details><summary><b>Topological Attention for Time Series Forecasting</b>
<a href="https://arxiv.org/abs/2107.09031">arxiv:2107.09031</a>
&#x1F4C8; 5 <br>
<p>Sebastian Zeng, Florian Graf, Christoph Hofer, Roland Kwitt</p></summary>
<p>

**Abstract:** The problem of (point) forecasting $ \textit{univariate} $ time series is considered. Most approaches, ranging from traditional statistical methods to recent learning-based techniques with neural networks, directly operate on raw time series observations. As an extension, we study whether $\textit{local topological properties}$, as captured via persistent homology, can serve as a reliable signal that provides complementary information for learning to forecast. To this end, we propose $\textit{topological attention}$, which allows attending to local topological features within a time horizon of historical data. Our approach easily integrates into existing end-to-end trainable forecasting models, such as $\texttt{N-BEATS}$, and in combination with the latter exhibits state-of-the-art performance on the large-scale M4 benchmark dataset of 100,000 diverse time series from different domains. Ablation experiments, as well as a comparison to a broad range of forecasting methods in a setting where only a single time series is available for training, corroborate the beneficial nature of including local topological information through an attention mechanism.

</p>
</details>

<details><summary><b>Improving Interpretability of Deep Neural Networks in Medical Diagnosis by Investigating the Individual Units</b>
<a href="https://arxiv.org/abs/2107.08767">arxiv:2107.08767</a>
&#x1F4C8; 5 <br>
<p>Woo-Jeoung Nam, Seong-Whan Lee</p></summary>
<p>

**Abstract:** As interpretability has been pointed out as the obstacle to the adoption of Deep Neural Networks (DNNs), there is an increasing interest in solving a transparency issue to guarantee the impressive performance. In this paper, we demonstrate the efficiency of recent attribution techniques to explain the diagnostic decision by visualizing the significant factors in the input image. By utilizing the characteristics of objectness that DNNs have learned, fully decomposing the network prediction visualizes clear localization of target lesion. To verify our work, we conduct our experiments on Chest X-ray diagnosis with publicly accessible datasets. As an intuitive assessment metric for explanations, we report the performance of intersection of Union between visual explanation and bounding box of lesions. Experiment results show that recently proposed attribution methods visualize the more accurate localization for the diagnostic decision compared to the traditionally used CAM. Furthermore, we analyze the inconsistency of intentions between humans and DNNs, which is easily obscured by high performance. By visualizing the relevant factors, it is possible to confirm that the criterion for decision is in line with the learning strategy. Our analysis of unmasking machine intelligence represents the necessity of explainability in the medical diagnostic decision.

</p>
</details>

<details><summary><b>Adversarial Continual Learning for Multi-Domain Hippocampal Segmentation</b>
<a href="https://arxiv.org/abs/2107.08751">arxiv:2107.08751</a>
&#x1F4C8; 5 <br>
<p>Marius Memmel, Camila Gonzalez, Anirban Mukhopadhyay</p></summary>
<p>

**Abstract:** Deep learning for medical imaging suffers from temporal and privacy-related restrictions on data availability. To still obtain viable models, continual learning aims to train in sequential order, as and when data is available. The main challenge that continual learning methods face is to prevent catastrophic forgetting, i.e., a decrease in performance on the data encountered earlier. This issue makes continuous training of segmentation models for medical applications extremely difficult. Yet, often, data from at least two different domains is available which we can exploit to train the model in a way that it disregards domain-specific information. We propose an architecture that leverages the simultaneous availability of two or more datasets to learn a disentanglement between the content and domain in an adversarial fashion. The domain-invariant content representation then lays the base for continual semantic segmentation. Our approach takes inspiration from domain adaptation and combines it with continual learning for hippocampal segmentation in brain MRI. We showcase that our method reduces catastrophic forgetting and outperforms state-of-the-art continual learning methods.

</p>
</details>

<details><summary><b>Stock Movement Prediction with Financial News using Contextualized Embedding from BERT</b>
<a href="https://arxiv.org/abs/2107.08721">arxiv:2107.08721</a>
&#x1F4C8; 5 <br>
<p>Qinkai Chen</p></summary>
<p>

**Abstract:** News events can greatly influence equity markets. In this paper, we are interested in predicting the short-term movement of stock prices after financial news events using only the headlines of the news. To achieve this goal, we introduce a new text mining method called Fine-Tuned Contextualized-Embedding Recurrent Neural Network (FT-CE-RNN). Compared with previous approaches which use static vector representations of the news (static embedding), our model uses contextualized vector representations of the headlines (contextualized embeddings) generated from Bidirectional Encoder Representations from Transformers (BERT). Our model obtains the state-of-the-art result on this stock movement prediction task. It shows significant improvement compared with other baseline models, in both accuracy and trading simulations. Through various trading simulations based on millions of headlines from Bloomberg News, we demonstrate the ability of this model in real scenarios.

</p>
</details>

<details><summary><b>On the Quantum-like Contextuality of Ambiguous Phrases</b>
<a href="https://arxiv.org/abs/2107.14589">arxiv:2107.14589</a>
&#x1F4C8; 4 <br>
<p>Daphne Wang, Mehrnoosh Sadrzadeh, Samson Abramsky, Victor H. Cervantes</p></summary>
<p>

**Abstract:** Language is contextual as meanings of words are dependent on their contexts. Contextuality is, concomitantly, a well-defined concept in quantum mechanics where it is considered a major resource for quantum computations. We investigate whether natural language exhibits any of the quantum mechanics' contextual features. We show that meaning combinations in ambiguous phrases can be modelled in the sheaf-theoretic framework for quantum contextuality, where they can become possibilistically contextual. Using the framework of Contextuality-by-Default (CbD), we explore the probabilistic variants of these and show that CbD-contextuality is also possible.

</p>
</details>

<details><summary><b>Machine Learning and Deep Learning Methods for Building Intelligent Systems in Medicine and Drug Discovery: A Comprehensive Survey</b>
<a href="https://arxiv.org/abs/2107.14037">arxiv:2107.14037</a>
&#x1F4C8; 4 <br>
<p>G Jignesh Chowdary, Suganya G, Premalatha M, Asnath Victy Phamila Y, Karunamurthy K</p></summary>
<p>

**Abstract:** With the advancements in computer technology, there is a rapid development of intelligent systems to understand the complex relationships in data to make predictions and classifications. Artificail Intelligence based framework is rapidly revolutionizing the healthcare industry. These intelligent systems are built with machine learning and deep learning based robust models for early diagnosis of diseases and demonstrates a promising supplementary diagnostic method for frontline clinical doctors and surgeons. Machine Learning and Deep Learning based systems can streamline and simplify the steps involved in diagnosis of diseases from clinical and image-based data, thus providing significant clinician support and workflow optimization. They mimic human cognition and are even capable of diagnosing diseases that cannot be diagnosed with human intelligence. This paper focuses on the survey of machine learning and deep learning applications in across 16 medical specialties, namely Dental medicine, Haematology, Surgery, Cardiology, Pulmonology, Orthopedics, Radiology, Oncology, General medicine, Psychiatry, Endocrinology, Neurology, Dermatology, Hepatology, Nephrology, Ophthalmology, and Drug discovery. In this paper along with the survey, we discuss the advancements of medical practices with these systems and also the impact of these systems on medical professionals.

</p>
</details>

<details><summary><b>Asymptotic Escape of Spurious Critical Points on the Low-rank Matrix Manifold</b>
<a href="https://arxiv.org/abs/2107.09207">arxiv:2107.09207</a>
&#x1F4C8; 4 <br>
<p>Thomas Y. Hou, Zhenzhen Li, Ziyun Zhang</p></summary>
<p>

**Abstract:** We show that the Riemannian gradient descent algorithm on the low-rank matrix manifold almost surely escapes some spurious critical points on the boundary of the manifold. Given that the low-rank matrix manifold is an incomplete set, this result is the first to overcome this difficulty and partially justify the global use of the Riemannian gradient descent on the manifold. The spurious critical points are some rank-deficient matrices that capture only part of the SVD components of the ground truth. They exhibit very singular behavior and evade the classical analysis of strict saddle points. We show that using the dynamical low-rank approximation and a rescaled gradient flow, some of the spurious critical points can be converted to classical strict saddle points, which leads to the desired result. Numerical experiments are provided to support our theoretical findings.

</p>
</details>

<details><summary><b>Rational Verification for Probabilistic Systems</b>
<a href="https://arxiv.org/abs/2107.09119">arxiv:2107.09119</a>
&#x1F4C8; 4 <br>
<p>Julian Gutierrez, Lewis Hammond, Anthony W. Lin, Muhammad Najib, Michael Wooldridge</p></summary>
<p>

**Abstract:** Rational verification is the problem of determining which temporal logic properties will hold in a multi-agent system, under the assumption that agents in the system act rationally, by choosing strategies that collectively form a game-theoretic equilibrium. Previous work in this area has largely focussed on deterministic systems. In this paper, we develop the theory and algorithms for rational verification in probabilistic systems. We focus on concurrent stochastic games (CSGs), which can be used to model uncertainty and randomness in complex multi-agent environments. We study the rational verification problem for both non-cooperative games and cooperative games in the qualitative probabilistic setting. In the former case, we consider LTL properties satisfied by the Nash equilibria of the game and in the latter case LTL properties satisfied by the core. In both cases, we show that the problem is 2EXPTIME-complete, thus not harder than the much simpler verification problem of model checking LTL properties of systems modelled as Markov decision processes (MDPs).

</p>
</details>

<details><summary><b>Deep Open Snake Tracker for Vessel Tracing</b>
<a href="https://arxiv.org/abs/2107.09049">arxiv:2107.09049</a>
&#x1F4C8; 4 <br>
<p>Li Chen, Wenjin Liu, Niranjan Balu, Mahmud Mossa-Basha, Thomas S. Hatsukami, Jenq-Neng Hwang, Chun Yuan</p></summary>
<p>

**Abstract:** Vessel tracing by modeling vascular structures in 3D medical images with centerlines and radii can provide useful information for vascular health. Existing algorithms have been developed but there are certain persistent problems such as incomplete or inaccurate vessel tracing, especially in complicated vascular beds like the intracranial arteries. We propose here a deep learning based open curve active contour model (DOST) to trace vessels in 3D images. Initial curves were proposed from a centerline segmentation neural network. Then data-driven machine knowledge was used to predict the stretching direction and vessel radius of the initial curve, while the active contour model (as human knowledge) maintained smoothness and intensity fitness of curves. Finally, considering the nonloop topology of most vasculatures, individually traced vessels were connected into a tree topology by applying a minimum spanning tree algorithm on a global connection graph. We evaluated DOST on a Time-of-Flight (TOF) MRA intracranial artery dataset and demonstrated its superior performance over existing segmentation-based and tracking-based vessel tracing methods. In addition, DOST showed strong adaptability on different imaging modalities (CTA, MR T1 SPACE) and vascular beds (coronary arteries).

</p>
</details>

<details><summary><b>Over-Parameterization and Generalization in Audio Classification</b>
<a href="https://arxiv.org/abs/2107.08933">arxiv:2107.08933</a>
&#x1F4C8; 4 <br>
<p>Khaled Koutini, Hamid Eghbal-zadeh, Florian Henkel, Jan Schlüter, Gerhard Widmer</p></summary>
<p>

**Abstract:** Convolutional Neural Networks (CNNs) have been dominating classification tasks in various domains, such as machine vision, machine listening, and natural language processing. In machine listening, while generally exhibiting very good generalization capabilities, CNNs are sensitive to the specific audio recording device used, which has been recognized as a substantial problem in the acoustic scene classification (DCASE) community. In this study, we investigate the relationship between over-parameterization of acoustic scene classification models, and their resulting generalization abilities. Specifically, we test scaling CNNs in width and depth, under different conditions. Our results indicate that increasing width improves generalization to unseen devices, even without an increase in the number of parameters.

</p>
</details>

<details><summary><b>Path Integrals for the Attribution of Model Uncertainties</b>
<a href="https://arxiv.org/abs/2107.08756">arxiv:2107.08756</a>
&#x1F4C8; 4 <br>
<p>Iker Perez, Piotr Skalski, Alec Barns-Graham, Jason Wong, David Sutton</p></summary>
<p>

**Abstract:** Enabling interpretations of model uncertainties is of key importance in Bayesian machine learning applications. Often, this requires to meaningfully attribute predictive uncertainties to source features in an image, text or categorical array. However, popular attribution methods are particularly designed for classification and regression scores. In order to explain uncertainties, state of the art alternatives commonly procure counterfactual feature vectors, and proceed by making direct comparisons. In this paper, we leverage path integrals to attribute uncertainties in Bayesian differentiable models. We present a novel algorithm that relies on in-distribution curves connecting a feature vector to some counterfactual counterpart, and we retain desirable properties of interpretability methods. We validate our approach on benchmark image data sets with varying resolution, and show that it significantly simplifies interpretability over the existing alternatives.

</p>
</details>

<details><summary><b>Self-supervision for health insurance claims data: a Covid-19 use case</b>
<a href="https://arxiv.org/abs/2107.14591">arxiv:2107.14591</a>
&#x1F4C8; 3 <br>
<p>Emilia Apostolova, Fazle Karim, Guido Muscioni, Anubhav Rana, Jeffrey Clyman</p></summary>
<p>

**Abstract:** In this work, we modify and apply self-supervision techniques to the domain of medical health insurance claims. We model patients' healthcare claims history analogous to free-text narratives, and introduce pre-trained `prior knowledge', later utilized for patient outcome predictions on a challenging task: predicting Covid-19 hospitalization, given a patient's pre-Covid-19 insurance claims history. Results suggest that pre-training on insurance claims not only produces better prediction performance, but, more importantly, improves the model's `clinical trustworthiness' and model stability/reliability.

</p>
</details>

<details><summary><b>Reinforcement learning autonomously identifying the source of errors for agents in a group mission</b>
<a href="https://arxiv.org/abs/2107.09232">arxiv:2107.09232</a>
&#x1F4C8; 3 <br>
<p>Keishu Utimula, Ken-taro Hayaschi, Kousuke Nakano, Kenta Hongo, Ryo Maezono</p></summary>
<p>

**Abstract:** When agents are swarmed to carry out a mission, there is often a sudden failure of some of the agents observed from the command base. It is generally difficult to distinguish whether the failure is caused by actuators (hypothesis, $h_a$) or sensors (hypothesis, $h_s$) solely by the communication between the command base and the concerning agent. By making a collision to the agent by another, we would be able to distinguish which hypothesis is likely: For $h_a$, we expect to detect corresponding displacements while for $h_a$ we do not. Such swarm strategies to grasp the situation are preferably to be generated autonomously by artificial intelligence (AI). Preferable actions ($e.g.$, the collision) for the distinction would be those maximizing the difference between the expected behaviors for each hypothesis, as a value function. Such actions exist, however, only very sparsely in the whole possibilities, for which the conventional search based on gradient methods does not make sense. Instead, we have successfully applied the reinforcement learning technique, achieving the maximization of such a sparse value function. The machine learning actually concluded autonomously the colliding action to distinguish the hypothesises. Getting recognized an agent with actuator error by the action, the agents behave as if other ones want to assist the malfunctioning one to achieve a given mission.

</p>
</details>

<details><summary><b>Adaptive wavelet distillation from neural networks through interpretations</b>
<a href="https://arxiv.org/abs/2107.09145">arxiv:2107.09145</a>
&#x1F4C8; 3 <br>
<p>Wooseok Ha, Chandan Singh, Francois Lanusse, Srigokul Upadhyayula, Bin Yu</p></summary>
<p>

**Abstract:** Recent deep-learning models have achieved impressive prediction performance, but often sacrifice interpretability and computational efficiency. Interpretability is crucial in many disciplines, such as science and medicine, where models must be carefully vetted or where interpretation is the goal itself. Moreover, interpretable models are concise and often yield computational efficiency. Here, we propose adaptive wavelet distillation (AWD), a method which aims to distill information from a trained neural network into a wavelet transform. Specifically, AWD penalizes feature attributions of a neural network in the wavelet domain to learn an effective multi-resolution wavelet transform. The resulting model is highly predictive, concise, computationally efficient, and has properties (such as a multi-scale structure) which make it easy to interpret. In close collaboration with domain experts, we showcase how AWD addresses challenges in two real-world settings: cosmological parameter inference and molecular-partner prediction. In both cases, AWD yields a scientifically interpretable and concise model which gives predictive performance better than state-of-the-art neural networks. Moreover, AWD identifies predictive features that are scientifically meaningful in the context of respective domains. All code and models are released in a full-fledged package available on Github (https://github.com/Yu-Group/adaptive-wavelets).

</p>
</details>

<details><summary><b>Reward-Weighted Regression Converges to a Global Optimum</b>
<a href="https://arxiv.org/abs/2107.09088">arxiv:2107.09088</a>
&#x1F4C8; 3 <br>
<p>Miroslav Štrupl, Francesco Faccio, Dylan R. Ashley, Rupesh Kumar Srivastava, Jürgen Schmidhuber</p></summary>
<p>

**Abstract:** Reward-Weighted Regression (RWR) belongs to a family of widely known iterative Reinforcement Learning algorithms based on the Expectation-Maximization framework. In this family, learning at each iteration consists of sampling a batch of trajectories using the current policy and fitting a new policy to maximize a return-weighted log-likelihood of actions. Although RWR is known to yield monotonic improvement of the policy under certain circumstances, whether and under which conditions RWR converges to the optimal policy have remained open questions. In this paper, we provide for the first time a proof that RWR converges to a global optimum when no function approximation is used, in a general compact setting. Furthermore, for the simpler case with finite state and action spaces we prove R-linear convergence of the state-value function to the optimum.

</p>
</details>

<details><summary><b>Dim but not entirely dark: Extracting the Galactic Center Excess' source-count distribution with neural nets</b>
<a href="https://arxiv.org/abs/2107.09070">arxiv:2107.09070</a>
&#x1F4C8; 3 <br>
<p>Florian List, Nicholas L. Rodd, Geraint F. Lewis</p></summary>
<p>

**Abstract:** The two leading hypotheses for the Galactic Center Excess (GCE) in the $\textit{Fermi}$ data are an unresolved population of faint millisecond pulsars (MSPs) and dark-matter (DM) annihilation. The dichotomy between these explanations is typically reflected by modeling them as two separate emission components. However, point-sources (PSs) such as MSPs become statistically degenerate with smooth Poisson emission in the ultra-faint limit (formally where each source is expected to contribute much less than one photon on average), leading to an ambiguity that can render questions such as whether the emission is PS-like or Poissonian in nature ill-defined. We present a conceptually new approach that describes the PS and Poisson emission in a unified manner and only afterwards derives constraints on the Poissonian component from the so obtained results. For the implementation of this approach, we leverage deep learning techniques, centered around a neural network-based method for histogram regression that expresses uncertainties in terms of quantiles. We demonstrate that our method is robust against a number of systematics that have plagued previous approaches, in particular DM / PS misattribution. In the $\textit{Fermi}$ data, we find a faint GCE described by a median source-count distribution (SCD) peaked at a flux of $\sim4 \times 10^{-11} \ \text{counts} \ \text{cm}^{-2} \ \text{s}^{-1}$ (corresponding to $\sim3 - 4$ expected counts per PS), which would require $N \sim \mathcal{O}(10^4)$ sources to explain the entire excess (median value $N = \text{29,300}$ across the sky). Although faint, this SCD allows us to derive the constraint $η_P \leq 66\%$ for the Poissonian fraction of the GCE flux $η_P$ at 95% confidence, suggesting that a substantial amount of the GCE flux is due to PSs.

</p>
</details>

<details><summary><b>LAPNet: Non-rigid Registration derived in k-space for Magnetic Resonance Imaging</b>
<a href="https://arxiv.org/abs/2107.09060">arxiv:2107.09060</a>
&#x1F4C8; 3 <br>
<p>Thomas Küstner, Jiazhen Pan, Haikun Qi, Gastao Cruz, Christopher Gilliam, Thierry Blu, Bin Yang, Sergios Gatidis, René Botnar, Claudia Prieto</p></summary>
<p>

**Abstract:** Physiological motion, such as cardiac and respiratory motion, during Magnetic Resonance (MR) image acquisition can cause image artifacts. Motion correction techniques have been proposed to compensate for these types of motion during thoracic scans, relying on accurate motion estimation from undersampled motion-resolved reconstruction. A particular interest and challenge lie in the derivation of reliable non-rigid motion fields from the undersampled motion-resolved data. Motion estimation is usually formulated in image space via diffusion, parametric-spline, or optical flow methods. However, image-based registration can be impaired by remaining aliasing artifacts due to the undersampled motion-resolved reconstruction. In this work, we describe a formalism to perform non-rigid registration directly in the sampled Fourier space, i.e. k-space. We propose a deep-learning based approach to perform fast and accurate non-rigid registration from the undersampled k-space data. The basic working principle originates from the Local All-Pass (LAP) technique, a recently introduced optical flow-based registration. The proposed LAPNet is compared against traditional and deep learning image-based registrations and tested on fully-sampled and highly-accelerated (with two undersampling strategies) 3D respiratory motion-resolved MR images in a cohort of 40 patients with suspected liver or lung metastases and 25 healthy subjects. The proposed LAPNet provided consistent and superior performance to image-based approaches throughout different sampling trajectories and acceleration factors.

</p>
</details>

<details><summary><b>AI in Finance: Challenges, Techniques and Opportunities</b>
<a href="https://arxiv.org/abs/2107.09051">arxiv:2107.09051</a>
&#x1F4C8; 3 <br>
<p>Longbing Cao</p></summary>
<p>

**Abstract:** AI in finance broadly refers to the applications of AI techniques in financial businesses. This area has been lasting for decades with both classic and modern AI techniques applied to increasingly broader areas of finance, economy and society. In contrast to either discussing the problems, aspects and opportunities of finance that have benefited from specific AI techniques and in particular some new-generation AI and data science (AIDS) areas or reviewing the progress of applying specific techniques to resolving certain financial problems, this review offers a comprehensive and dense roadmap of the overwhelming challenges, techniques and opportunities of AI research in finance over the past decades. The landscapes and challenges of financial businesses and data are firstly outlined, followed by a comprehensive categorization and a dense overview of the decades of AI research in finance. We then structure and illustrate the data-driven analytics and learning of financial businesses and data. The comparison, criticism and discussion of classic vs. modern AI techniques for finance are followed. Lastly, open issues and opportunities address future AI-empowered finance and finance-motivated AI research.

</p>
</details>

<details><summary><b>Constraints Penalized Q-Learning for Safe Offline Reinforcement Learning</b>
<a href="https://arxiv.org/abs/2107.09003">arxiv:2107.09003</a>
&#x1F4C8; 3 <br>
<p>Haoran Xu, Xianyuan Zhan, Xiangyu Zhu</p></summary>
<p>

**Abstract:** We study the problem of safe offline reinforcement learning (RL), the goal is to learn a policy that maximizes long-term reward while satisfying safety constraints given only offline data, without further interaction with the environment. This problem is more appealing for real world RL applications, in which data collection is costly or dangerous. Enforcing constraint satisfaction is non-trivial, especially in offline settings, as there is a potential large discrepancy between the policy distribution and the data distribution, causing errors in estimating the value of safety constraints. We show that naïve approaches that combine techniques from safe RL and offline RL can only learn sub-optimal solutions. We thus develop a simple yet effective algorithm, Constraints Penalized Q-Learning (CPQ), to solve the problem. Our method admits the use of data generated by mixed behavior policies. We present a theoretical analysis and demonstrate empirically that our approach can learn robustly across a variety of benchmark control tasks, outperforming several baselines.

</p>
</details>

<details><summary><b>Clinical Relation Extraction Using Transformer-based Models</b>
<a href="https://arxiv.org/abs/2107.08957">arxiv:2107.08957</a>
&#x1F4C8; 3 <br>
<p>Xi Yang, Zehao Yu, Yi Guo, Jiang Bian, Yonghui Wu</p></summary>
<p>

**Abstract:** The newly emerged transformer technology has a tremendous impact on NLP research. In the general English domain, transformer-based models have achieved state-of-the-art performances on various NLP benchmarks. In the clinical domain, researchers also have investigated transformer models for clinical applications. The goal of this study is to systematically explore three widely used transformer-based models (i.e., BERT, RoBERTa, and XLNet) for clinical relation extraction and develop an open-source package with clinical pre-trained transformer-based models to facilitate information extraction in the clinical domain. We developed a series of clinical RE models based on three transformer architectures, namely BERT, RoBERTa, and XLNet. We evaluated these models using 2 publicly available datasets from 2018 MADE1.0 and 2018 n2c2 challenges. We compared two classification strategies (binary vs. multi-class classification) and investigated two approaches to generate candidate relations in different experimental settings. In this study, we compared three transformer-based (BERT, RoBERTa, and XLNet) models for relation extraction. We demonstrated that the RoBERTa-clinical RE model achieved the best performance on the 2018 MADE1.0 dataset with an F1-score of 0.8958. On the 2018 n2c2 dataset, the XLNet-clinical model achieved the best F1-score of 0.9610. Our results indicated that the binary classification strategy consistently outperformed the multi-class classification strategy for clinical relation extraction. Our methods and models are publicly available at https://github.com/uf-hobi-informatics-lab/ClinicalTransformerRelationExtraction. We believe this work will improve current practice on clinical relation extraction and other related NLP tasks in the biomedical domain.

</p>
</details>

<details><summary><b>Introducing a Family of Synthetic Datasets for Research on Bias in Machine Learning</b>
<a href="https://arxiv.org/abs/2107.08928">arxiv:2107.08928</a>
&#x1F4C8; 3 <br>
<p>William Blanzeisky, Pádraig Cunningham, Kenneth Kennedy</p></summary>
<p>

**Abstract:** A significant impediment to progress in research on bias in machine learning (ML) is the availability of relevant datasets. This situation is unlikely to change much given the sensitivity of such data. For this reason, there is a role for synthetic data in this research. In this short paper, we present one such family of synthetic data sets. We provide an overview of the data, describe how the level of bias can be varied, and present a simple example of an experiment on the data.

</p>
</details>

<details><summary><b>Channel-wise Gated Res2Net: Towards Robust Detection of Synthetic Speech Attacks</b>
<a href="https://arxiv.org/abs/2107.08803">arxiv:2107.08803</a>
&#x1F4C8; 3 <br>
<p>Xu Li, Xixin Wu, Hui Lu, Xunying Liu, Helen Meng</p></summary>
<p>

**Abstract:** Existing approaches for anti-spoofing in automatic speaker verification (ASV) still lack generalizability to unseen attacks. The Res2Net approach designs a residual-like connection between feature groups within one block, which increases the possible receptive fields and improves the system's detection generalizability. However, such a residual-like connection is performed by a direct addition between feature groups without channel-wise priority. We argue that the information across channels may not contribute to spoofing cues equally, and the less relevant channels are expected to be suppressed before adding onto the next feature group, so that the system can generalize better to unseen attacks. This argument motivates the current work that presents a novel, channel-wise gated Res2Net (CG-Res2Net), which modifies Res2Net to enable a channel-wise gating mechanism in the connection between feature groups. This gating mechanism dynamically selects channel-wise features based on the input, to suppress the less relevant channels and enhance the detection generalizability. Three gating mechanisms with different structures are proposed and integrated into Res2Net. Experimental results conducted on ASVspoof 2019 logical access (LA) demonstrate that the proposed CG-Res2Net significantly outperforms Res2Net on both the overall LA evaluation set and individual difficult unseen attacks, which also outperforms other state-of-the-art single systems, depicting the effectiveness of our method.

</p>
</details>

<details><summary><b>Non-asymptotic estimates for TUSLA algorithm for non-convex learning with applications to neural networks with ReLU activation function</b>
<a href="https://arxiv.org/abs/2107.08649">arxiv:2107.08649</a>
&#x1F4C8; 3 <br>
<p>Dong-Young Lim, Ariel Neufeld, Sotirios Sabanis, Ying Zhang</p></summary>
<p>

**Abstract:** We consider non-convex stochastic optimization problems where the objective functions have super-linearly growing and discontinuous stochastic gradients. In such a setting, we provide a non-asymptotic analysis for the tamed unadjusted stochastic Langevin algorithm (TUSLA) introduced in Lovas et al. (2021). In particular, we establish non-asymptotic error bounds for the TUSLA algorithm in Wasserstein-1 and Wasserstein-2 distances. The latter result enables us to further derive non-asymptotic estimates for the expected excess risk. To illustrate the applicability of the main results, we consider an example from transfer learning with ReLU neural networks, which represents a key paradigm in machine learning. Numerical experiments are presented for the aforementioned example which supports our theoretical findings. Hence, in this setting, we demonstrate both theoretically and numerically that the TUSLA algorithm can solve the optimization problem involving neural networks with ReLU activation function. Besides, we provide simulation results for synthetic examples where popular algorithms, e.g. ADAM, AMSGrad, RMSProp, and (vanilla) SGD, may fail to find the minimizer of the objective functions due to the super-linear growth and the discontinuity of the corresponding stochastic gradient, while the TUSLA algorithm converges rapidly to the optimal solution.

</p>
</details>

<details><summary><b>Facial Expressions Recognition with Convolutional Neural Networks</b>
<a href="https://arxiv.org/abs/2107.08640">arxiv:2107.08640</a>
&#x1F4C8; 3 <br>
<p>Subodh Lonkar</p></summary>
<p>

**Abstract:** Over the centuries, humans have developed and acquired a number of ways to communicate. But hardly any of them can be as natural and instinctive as facial expressions. On the other hand, neural networks have taken the world by storm. And no surprises, that the area of Computer Vision and the problem of facial expressions recognitions hasn't remained untouched. Although a wide range of techniques have been applied, achieving extremely high accuracies and preparing highly robust FER systems still remains a challenge due to heterogeneous details in human faces. In this paper, we will be deep diving into implementing a system for recognition of facial expressions (FER) by leveraging neural networks, and more specifically, Convolutional Neural Networks (CNNs). We adopt the fundamental concepts of deep learning and computer vision with various architectures, fine-tune it's hyperparameters and experiment with various optimization methods and demonstrate a state-of-the-art single-network-accuracy of 70.10% on the FER2013 dataset without using any additional training data.

</p>
</details>

<details><summary><b>Class dependency based learning using Bi-LSTM coupled with the transfer learning of VGG16 for the diagnosis of Tuberculosis from chest x-rays</b>
<a href="https://arxiv.org/abs/2108.04329">arxiv:2108.04329</a>
&#x1F4C8; 2 <br>
<p>G Jignesh Chowdary, Suganya G, Premalatha M, Karunamurthy K</p></summary>
<p>

**Abstract:** Tuberculosis is an infectious disease that is leading to the death of millions of people across the world. The mortality rate of this disease is high in patients suffering from immuno-compromised disorders. The early diagnosis of this disease can save lives and can avoid further complications. But the diagnosis of TB is a very complex task. The standard diagnostic tests still rely on traditional procedures developed in the last century. These procedures are slow and expensive. So this paper presents an automatic approach for the diagnosis of TB from posteroanterior chest x-rays. This is a two-step approach, where in the first step the lung regions are segmented from the chest x-rays using the graph cut method, and then in the second step the transfer learning of VGG16 combined with Bi-directional LSTM is used for extracting high-level discriminative features from the segmented lung regions and then classification is performed using a fully connected layer. The proposed model is evaluated using data from two publicly available databases namely Montgomery Country set and Schezien set. The proposed model achieved accuracy and sensitivity of 97.76%, 97.01% and 96.42%, 94.11% on Schezien and Montgomery county datasets. This model enhanced the diagnostic accuracy of TB by 0.7% and 11.68% on Schezien and Montgomery county datasets.

</p>
</details>

<details><summary><b>Generative Adversarial Neural Cellular Automata</b>
<a href="https://arxiv.org/abs/2108.04328">arxiv:2108.04328</a>
&#x1F4C8; 2 <br>
<p>Maximilian Otte, Quentin Delfosse, Johannes Czech, Kristian Kersting</p></summary>
<p>

**Abstract:** Motivated by the interaction between cells, the recently introduced concept of Neural Cellular Automata shows promising results in a variety of tasks. So far, this concept was mostly used to generate images for a single scenario. As each scenario requires a new model, this type of generation seems contradictory to the adaptability of cells in nature. To address this contradiction, we introduce a concept using different initial environments as input while using a single Neural Cellular Automata to produce several outputs. Additionally, we introduce GANCA, a novel algorithm that combines Neural Cellular Automata with Generative Adversarial Networks, allowing for more generalization through adversarial training. The experiments show that a single model is capable of learning several images when presented with different inputs, and that the adversarially trained model improves drastically on out-of-distribution data compared to a supervised trained model.

</p>
</details>

<details><summary><b>Residual Tree Aggregation of Layers for Neural Machine Translation</b>
<a href="https://arxiv.org/abs/2107.14590">arxiv:2107.14590</a>
&#x1F4C8; 2 <br>
<p>GuoLiang Li, Yiyang Li</p></summary>
<p>

**Abstract:** Although attention-based Neural Machine Translation has achieved remarkable progress in recent layers, it still suffers from issue of making insufficient use of the output of each layer. In transformer, it only uses the top layer of encoder and decoder in the subsequent process, which makes it impossible to take advantage of the useful information in other layers. To address this issue, we propose a residual tree aggregation of layers for Transformer(RTAL), which helps to fuse information across layers. Specifically, we try to fuse the information across layers by constructing a post-order binary tree. In additional to the last node, we add the residual connection to the process of generating child nodes. Our model is based on the Neural Machine Translation model Transformer and we conduct our experiments on WMT14 English-to-German and WMT17 English-to-France translation tasks. Experimental results across language pairs show that the proposed approach outperforms the strong baseline model significantly

</p>
</details>

<details><summary><b>S2Looking: A Satellite Side-Looking Dataset for Building Change Detection</b>
<a href="https://arxiv.org/abs/2107.09244">arxiv:2107.09244</a>
&#x1F4C8; 2 <br>
<p>Li Shen, Yao Lu, Hao Chen, Hao Wei, Donghai Xie, Jiabao Yue, Rui Chen, Yue Zhang, Ao Zhang, Shouye Lv, Bitao Jiang</p></summary>
<p>

**Abstract:** Building change detection underpins many important applications, especially in the military and crisis management domains. Recent methods used for change detection have shifted towards deep-learning, which depends on the quality of its training data. The assembly of large-scale annotated satellite imagery datasets is therefore essential for global building change surveillance. Existing datasets almost exclusively offer near-nadir viewing angles. This limits the range of changes that can be detected. By offering larger observation ranges, the scroll imaging mode of optical satellites presents an opportunity to overcome this restriction. This paper therefore introduces S2Looking, a building change detection dataset that contains large-scale side-looking satellite images captured at various off-nadir angles. The dataset consists of 5000 bitemporal image pairs of rural areas and more than 65,920 annotated instances of changes throughout the world. The dataset can be used to train deep-learning-based change detection algorithms. It expands upon existing datasets by providing: 1) larger viewing angles; 2) large illumination variances; and 3) the added complexity of rural images. To facilitate use of the dataset, a benchmark task has been established and preliminary tests suggest deep-learning algorithms find the dataset significantly more challenging than the closest competing near-nadir dataset, LEVIR-CD+. S2Looking may therefore promote important advances in existing building change detection algorithms. The dataset is available at https://github.com/S2Looking/.

</p>
</details>

<details><summary><b>A Comparison of Supervised and Unsupervised Deep Learning Methods for Anomaly Detection in Images</b>
<a href="https://arxiv.org/abs/2107.09204">arxiv:2107.09204</a>
&#x1F4C8; 2 <br>
<p>Vincent Wilmet, Sauraj Verma, Tabea Redl, Håkon Sandaker, Zhenning Li</p></summary>
<p>

**Abstract:** Anomaly detection in images plays a significant role for many applications across all industries, such as disease diagnosis in healthcare or quality assurance in manufacturing. Manual inspection of images, when extended over a monotonously repetitive period of time is very time consuming and can lead to anomalies being overlooked.Artificial neural networks have proven themselves very successful on simple, repetitive tasks, in some cases even outperforming humans. Therefore, in this paper we investigate different methods of deep learning, including supervised and unsupervised learning, for anomaly detection applied to a quality assurance use case. We utilize the MVTec anomaly dataset and develop three different models, a CNN for supervised anomaly detection, KD-CAE for autoencoder anomaly detection, NI-CAE for noise induced anomaly detection and a DCGAN for generating reconstructed images. By experiments, we found that KD-CAE performs better on the anomaly datasets compared to CNN and NI-CAE, with NI-CAE performing the best on the Transistor dataset. We also implemented a DCGAN for the creation of new training data but due to computational limitation and lack of extrapolating the mechanics of AnoGAN, we restricted ourselves just to the generation of GAN based images. We conclude that unsupervised methods are more powerful for anomaly detection in images, especially in a setting where only a small amount of anomalous data is available, or the data is unlabeled.

</p>
</details>

<details><summary><b>Can we globally optimize cross-validation loss? Quasiconvexity in ridge regression</b>
<a href="https://arxiv.org/abs/2107.09194">arxiv:2107.09194</a>
&#x1F4C8; 2 <br>
<p>William T. Stephenson, Zachary Frangella, Madeleine Udell, Tamara Broderick</p></summary>
<p>

**Abstract:** Models like LASSO and ridge regression are extensively used in practice due to their interpretability, ease of use, and strong theoretical guarantees. Cross-validation (CV) is widely used for hyperparameter tuning in these models, but do practical optimization methods minimize the true out-of-sample loss? A recent line of research promises to show that the optimum of the CV loss matches the optimum of the out-of-sample loss (possibly after simple corrections). It remains to show how tractable it is to minimize the CV loss. In the present paper, we show that, in the case of ridge regression, the CV loss may fail to be quasiconvex and thus may have multiple local optima. We can guarantee that the CV loss is quasiconvex in at least one case: when the spectrum of the covariate matrix is nearly flat and the noise in the observed responses is not too high. More generally, we show that quasiconvexity status is independent of many properties of the observed data (response norm, covariate-matrix right singular vectors and singular-value scaling) and has a complex dependence on the few that remain. We empirically confirm our theory using simulated experiments.

</p>
</details>

<details><summary><b>Improving exploration in policy gradient search: Application to symbolic optimization</b>
<a href="https://arxiv.org/abs/2107.09158">arxiv:2107.09158</a>
&#x1F4C8; 2 <br>
<p>Mikel Landajuela Larma, Brenden K. Petersen, Soo K. Kim, Claudio P. Santiago, Ruben Glatt, T. Nathan Mundhenk, Jacob F. Pettit, Daniel M. Faissol</p></summary>
<p>

**Abstract:** Many machine learning strategies designed to automate mathematical tasks leverage neural networks to search large combinatorial spaces of mathematical symbols. In contrast to traditional evolutionary approaches, using a neural network at the core of the search allows learning higher-level symbolic patterns, providing an informed direction to guide the search. When no labeled data is available, such networks can still be trained using reinforcement learning. However, we demonstrate that this approach can suffer from an early commitment phenomenon and from initialization bias, both of which limit exploration. We present two exploration methods to tackle these issues, building upon ideas of entropy regularization and distribution initialization. We show that these techniques can improve the performance, increase sample efficiency, and lower the complexity of solutions for the task of symbolic regression.

</p>
</details>

<details><summary><b>Convolutional module for heart localization and segmentation in MRI</b>
<a href="https://arxiv.org/abs/2107.09134">arxiv:2107.09134</a>
&#x1F4C8; 2 <br>
<p>Daniel Lima, Catharine Graves, Marco Gutierrez, Bruno Brandoli, Jose Rodrigues-Jr</p></summary>
<p>

**Abstract:** Magnetic resonance imaging (MRI) is a widely known medical imaging technique used to assess the heart function. Deep learning (DL) models perform several tasks in cardiac MRI (CMR) images with good efficacy, such as segmentation, estimation, and detection of diseases. Many DL models based on convolutional neural networks (CNN) were improved by detecting regions-of-interest (ROI) either automatically or by hand. In this paper we describe Visual-Motion-Focus (VMF), a module that detects the heart motion in the 4D MRI sequence, and highlights ROIs by focusing a Radial Basis Function (RBF) on the estimated motion field. We experimented and evaluated VMF on three CMR datasets, observing that the proposed ROIs cover 99.7% of data labels (Recall score), improved the CNN segmentation (mean Dice score) by 1.7 (p < .001) after the ROI extraction, and improved the overall training speed by 2.5 times (+150%).

</p>
</details>

<details><summary><b>Latency-Memory Optimized Splitting of Convolution Neural Networks for Resource Constrained Edge Devices</b>
<a href="https://arxiv.org/abs/2107.09123">arxiv:2107.09123</a>
&#x1F4C8; 2 <br>
<p>Tanmay Jain,  Avaneesh, Rohit Verma, Rajeev Shorey</p></summary>
<p>

**Abstract:** With the increasing reliance of users on smart devices, bringing essential computation at the edge has become a crucial requirement for any type of business. Many such computations utilize Convolution Neural Networks (CNNs) to perform AI tasks, having high resource and computation requirements, that are infeasible for edge devices. Splitting the CNN architecture to perform part of the computation on edge and remaining on the cloud is an area of research that has seen increasing interest in the field. In this paper, we assert that running CNNs between an edge device and the cloud is synonymous to solving a resource-constrained optimization problem that minimizes the latency and maximizes resource utilization at the edge. We formulate a multi-objective optimization problem and propose the LMOS algorithm to achieve a Pareto efficient solution. Experiments done on real-world edge devices show that, LMOS ensures feasible execution of different CNN models at the edge and also improves upon existing state-of-the-art approaches.

</p>
</details>

<details><summary><b>Confidence Aware Neural Networks for Skin Cancer Detection</b>
<a href="https://arxiv.org/abs/2107.09118">arxiv:2107.09118</a>
&#x1F4C8; 2 <br>
<p>Donya Khaledyan, AmirReza Tajally, Ali Sarkhosh, Afshar Shamsi, Hamzeh Asgharnezhad, Abbas Khosravi, Saeid Nahavandi</p></summary>
<p>

**Abstract:** Deep learning (DL) models have received particular attention in medical imaging due to their promising pattern recognition capabilities. However, Deep Neural Networks (DNNs) require a huge amount of data, and because of the lack of sufficient data in this field, transfer learning can be a great solution. DNNs used for disease diagnosis meticulously concentrate on improving the accuracy of predictions without providing a figure about their confidence of predictions. Knowing how much a DNN model is confident in a computer-aided diagnosis model is necessary for gaining clinicians' confidence and trust in DL-based solutions. To address this issue, this work presents three different methods for quantifying uncertainties for skin cancer detection from images. It also comprehensively evaluates and compares performance of these DNNs using novel uncertainty-related metrics. The obtained results reveal that the predictive uncertainty estimation methods are capable of flagging risky and erroneous predictions with a high uncertainty estimate. We also demonstrate that ensemble approaches are more reliable in capturing uncertainties through inference.

</p>
</details>

<details><summary><b>Accelerating deep neural networks for efficient scene understanding in automotive cyber-physical systems</b>
<a href="https://arxiv.org/abs/2107.09101">arxiv:2107.09101</a>
&#x1F4C8; 2 <br>
<p>Stavros Nousias, Erion-Vasilis Pikoulis, Christos Mavrokefalidis, Aris S. Lalos</p></summary>
<p>

**Abstract:** Automotive Cyber-Physical Systems (ACPS) have attracted a significant amount of interest in the past few decades, while one of the most critical operations in these systems is the perception of the environment. Deep learning and, especially, the use of Deep Neural Networks (DNNs) provides impressive results in analyzing and understanding complex and dynamic scenes from visual data. The prediction horizons for those perception systems are very short and inference must often be performed in real time, stressing the need of transforming the original large pre-trained networks into new smaller models, by utilizing Model Compression and Acceleration (MCA) techniques. Our goal in this work is to investigate best practices for appropriately applying novel weight sharing techniques, optimizing the available variables and the training procedures towards the significant acceleration of widely adopted DNNs. Extensive evaluation studies carried out using various state-of-the-art DNN models in object detection and tracking experiments, provide details about the type of errors that manifest after the application of weight sharing techniques, resulting in significant acceleration gains with negligible accuracy losses.

</p>
</details>

<details><summary><b>Support Recovery in Universal One-bit Compressed Sensing</b>
<a href="https://arxiv.org/abs/2107.09091">arxiv:2107.09091</a>
&#x1F4C8; 2 <br>
<p>Arya Mazumdar, Soumyabrata Pal</p></summary>
<p>

**Abstract:** One-bit compressed sensing (1bCS) is an extreme-quantized signal acquisition method that has been intermittently studied in the past decade. In 1bCS, linear samples of a high dimensional signal are quantized to only one bit per sample (sign of the measurement). The extreme quantization makes it an interesting case study of the more general single-index or generalized linear models. At the same time it can also be thought of as a `design' version of learning a binary linear classifier or halfspace-learning.
  Assuming the original signal vector to be sparse, existing results in 1bCS either aim to find the support of the vector, or approximate the signal within an $ε$-ball. The focus of this paper is support recovery, which often also computationally facilitate approximate signal recovery. A \emph{universal} measurement matrix for 1bCS refers to one set of measurements that work \emph{for all} sparse signals. With universality, it is known that $\tildeΘ(k^2)$ 1bCS measurements are necessary and sufficient for support recovery (where $k$ denotes the sparsity). In this work, we show that it is possible to universally recover the support with a small number of false positives with $\tilde{O}(k^{3/2})$ measurements. If the dynamic range of the signal vector is known, then with a different technique, this result can be improved to only $\tilde{O}(k)$ measurements. Other results on universal but approximate support recovery are also provided in this paper. All of our main recovery algorithms are simple and polynomial-time.

</p>
</details>

<details><summary><b>An Analysis of Reinforcement Learning for Malaria Control</b>
<a href="https://arxiv.org/abs/2107.08988">arxiv:2107.08988</a>
&#x1F4C8; 2 <br>
<p>Ndivhuwo Makondo, Arinze Lawrence Folarin, Simphiwe Nhlahla Zitha, Sekou Lionel Remy</p></summary>
<p>

**Abstract:** Previous work on policy learning for Malaria control has often formulated the problem as an optimization problem assuming the objective function and the search space have a specific structure. The problem has been formulated as multi-armed bandits, contextual bandits and a Markov Decision Process in isolation. Furthermore, an emphasis is put on developing new algorithms specific to an instance of Malaria control, while ignoring a plethora of simpler and general algorithms in the literature. In this work, we formally study the formulation of Malaria control and present a comprehensive analysis of several formulations used in the literature. In addition, we implement and analyze several reinforcement learning algorithms in all formulations and compare them to black box optimization. In contrast to previous work, our results show that simple algorithms based on Upper Confidence Bounds are sufficient for learning good Malaria policies, and tend to outperform their more advanced counterparts on the malaria OpenAI Gym environment.

</p>
</details>

<details><summary><b>GenRadar: Self-supervised Probabilistic Camera Synthesis based on Radar Frequencies</b>
<a href="https://arxiv.org/abs/2107.08948">arxiv:2107.08948</a>
&#x1F4C8; 2 <br>
<p>Carsten Ditzel, Klaus Dietmayer</p></summary>
<p>

**Abstract:** Autonomous systems require a continuous and dependable environment perception for navigation and decision-making, which is best achieved by combining different sensor types. Radar continues to function robustly in compromised circumstances in which cameras become impaired, guaranteeing a steady inflow of information. Yet, camera images provide a more intuitive and readily applicable impression of the world. This work combines the complementary strengths of both sensor types in a unique self-learning fusion approach for a probabilistic scene reconstruction in adverse surrounding conditions. After reducing the memory requirements of both high-dimensional measurements through a decoupled stochastic self-supervised compression technique, the proposed algorithm exploits similarities and establishes correspondences between both domains at different feature levels during training. Then, at inference time, relying exclusively on radio frequencies, the model successively predicts camera constituents in an autoregressive and self-contained process. These discrete tokens are finally transformed back into an instructive view of the respective surrounding, allowing to visually perceive potential dangers for important tasks downstream.

</p>
</details>

<details><summary><b>Detection of Double Compression in MPEG-4 Videos Using Refined Features-based CNN</b>
<a href="https://arxiv.org/abs/2107.08939">arxiv:2107.08939</a>
&#x1F4C8; 2 <br>
<p>Seung-Hun Nam, Wonhyuk Ahn, Myung-Joon Kwon, In-Jae Yu</p></summary>
<p>

**Abstract:** Double compression is accompanied by various types of video manipulation and its traces can be exploited to determine whether a video is a forgery. This Letter presents a convolutional neural network for detecting double compression in MPEG-4 videos. Through analysis of the intra-coding process, we utilize two refined features for capturing the subtle artifacts caused by double compression. The discrete cosine transform (DCT) histogram feature effectively detects the change of statistical characteristics in DCT coefficients and the parameter-based feature is utilized as auxiliary information to help the network learn double compression artifacts. When compared with state-of-the-art networks and forensic method, the results show that the proposed approach achieves a higher performance.

</p>
</details>

<details><summary><b>Multimodal Reward Shaping for Efficient Exploration in Reinforcement Learning</b>
<a href="https://arxiv.org/abs/2107.08888">arxiv:2107.08888</a>
&#x1F4C8; 2 <br>
<p>Mingqi Yuan, Mon-on Pun, Dong Wang, Yi Chen, Haojun Li</p></summary>
<p>

**Abstract:** Maintaining the long-term exploration capability of the agent remains one of the critical challenges in deep reinforcement learning. A representative solution is to leverage reward shaping to provide intrinsic rewards for the agent to encourage exploration. However, most existing methods suffer from vanishing intrinsic rewards, which cannot provide sustainable exploration incentives. Moreover, they rely heavily on complex models and additional memory to record learning procedures, resulting in high computational complexity and low robustness. To tackle this problem, entropy-based methods are proposed to evaluate the global exploration performance, encouraging the agent to visit the state space more equitably. However, the sample complexity of estimating the state visitation entropy is prohibitive when handling environments with high-dimensional observations. In this paper, we introduce a novel metric entitled Jain's fairness index (JFI) to replace the entropy regularizer, which solves the exploration problem from a brand new perspective. In sharp contrast to the entropy regularizer, JFI is more computable and robust and can be easily applied generalized into arbitrary tasks. Furthermore, we leverage a variational auto-encoder (VAE) model to capture the life-long novelty of states, which is combined with the global JFI score to form multimodal intrinsic rewards. Finally, extensive simulation results demonstrate that our multimodal reward shaping (MMRS) method can achieve higher performance than other benchmark schemes.

</p>
</details>

<details><summary><b>Automatic and explainable grading of meningiomas from histopathology images</b>
<a href="https://arxiv.org/abs/2107.08850">arxiv:2107.08850</a>
&#x1F4C8; 2 <br>
<p>Jonathan Ganz, Tobias Kirsch, Lucas Hoffmann, Christof A. Bertram, Christoph Hoffmann, Andreas Maier, Katharina Breininger, Ingmar Blümcke, Samir Jabari, Marc Aubreville</p></summary>
<p>

**Abstract:** Meningioma is one of the most prevalent brain tumors in adults. To determine its malignancy, it is graded by a pathologist into three grades according to WHO standards. This grade plays a decisive role in treatment, and yet may be subject to inter-rater discordance. In this work, we present and compare three approaches towards fully automatic meningioma grading from histology whole slide images. All approaches are following a two-stage paradigm, where we first identify a region of interest based on the detection of mitotic figures in the slide using a state-of-the-art object detection deep learning network. This region of highest mitotic rate is considered characteristic for biological tumor behavior. In the second stage, we calculate a score corresponding to tumor malignancy based on information contained in this region using three different settings. In a first approach, image patches are sampled from this region and regression is based on morphological features encoded by a ResNet-based network. We compare this to learning a logistic regression from the determined mitotic count, an approach which is easily traceable and explainable. Lastly, we combine both approaches in a single network. We trained the pipeline on 951 slides from 341 patients and evaluated them on a separate set of 141 slides from 43 patients. All approaches yield a high correlation to the WHO grade. The logistic regression and the combined approach had the best results in our experiments, yielding correct predictions in 32 and 33 of all cases, respectively, with the image-based approach only predicting 25 cases correctly. Spearman's correlation was 0.716, 0.792 and 0.790 respectively. It may seem counterintuitive at first that morphological features provided by image patches do not improve model performance. Yet, this mirrors the criteria of the grading scheme, where mitotic count is the only unequivocal parameter.

</p>
</details>

<details><summary><b>Relative Localization of Mobile Robots with Multiple Ultra-WideBand Ranging Measurements</b>
<a href="https://arxiv.org/abs/2107.08842">arxiv:2107.08842</a>
&#x1F4C8; 2 <br>
<p>Zhiqiang Cao, Ran Liu, Chau Yuen, Achala Athukorala, Benny Kai Kiat Ng, Muraleetharan Mathanraj, U-Xuan Tan</p></summary>
<p>

**Abstract:** Relative localization between autonomous robots without infrastructure is crucial to achieve their navigation, path planning, and formation in many applications, such as emergency response, where acquiring a prior knowledge of the environment is not possible. The traditional Ultra-WideBand (UWB)-based approach provides a good estimation of the distance between the robots, but obtaining the relative pose (including the displacement and orientation) remains challenging. We propose an approach to estimate the relative pose between a group of robots by equipping each robot with multiple UWB ranging nodes. We determine the pose between two robots by minimizing the residual error of the ranging measurements from all UWB nodes. To improve the localization accuracy, we propose to utilize the odometry constraints through a sliding window-based optimization. The optimized pose is then fused with the odometry in a particle filtering for pose tracking among a group of mobile robots. We have conducted extensive experiments to validate the effectiveness of the proposed approach.

</p>
</details>

<details><summary><b>A Multi-UAV System for Exploration and Target Finding in Cluttered and GPS-Denied Environments</b>
<a href="https://arxiv.org/abs/2107.08834">arxiv:2107.08834</a>
&#x1F4C8; 2 <br>
<p>Xiaolong Zhu, Fernando Vanegas, Felipe Gonzalez, Conrad Sanderson</p></summary>
<p>

**Abstract:** The use of multi-rotor Unmanned Aerial Vehicles (UAVs) for search and rescue as well as remote sensing is rapidly increasing. Multi-rotor UAVs, however, have limited endurance. The range of UAV applications can be widened if teams of multiple UAVs are used. We propose a framework for a team of UAVs to cooperatively explore and find a target in complex GPS-denied environments with obstacles. The team of UAVs autonomously navigates, explores, detects, and finds the target in a cluttered environment with a known map. Examples of such environments include indoor scenarios, urban or natural canyons, caves, and tunnels, where the GPS signal is limited or blocked. The framework is based on a probabilistic decentralised Partially Observable Markov Decision Process which accounts for the uncertainties in sensing and the environment. The team can cooperate efficiently, with each UAV sharing only limited processed observations and their locations during the mission. The system is simulated using the Robotic Operating System and Gazebo. Performance of the system with an increasing number of UAVs in several indoor scenarios with obstacles is tested. Results indicate that the proposed multi-UAV system has improvements in terms of time-cost, the proportion of search area surveyed, as well as successful rates for search and rescue missions.

</p>
</details>

<details><summary><b>Experimental Investigation and Evaluation of Model-based Hyperparameter Optimization</b>
<a href="https://arxiv.org/abs/2107.08761">arxiv:2107.08761</a>
&#x1F4C8; 2 <br>
<p>Eva Bartz, Martin Zaefferer, Olaf Mersmann, Thomas Bartz-Beielstein</p></summary>
<p>

**Abstract:** Machine learning algorithms such as random forests or xgboost are gaining more importance and are increasingly incorporated into production processes in order to enable comprehensive digitization and, if possible, automation of processes. Hyperparameters of these algorithms used have to be set appropriately, which can be referred to as hyperparameter tuning or optimization. Based on the concept of tunability, this article presents an overview of theoretical and practical results for popular machine learning algorithms. This overview is accompanied by an experimental analysis of 30 hyperparameters from six relevant machine learning algorithms. In particular, it provides (i) a survey of important hyperparameters, (ii) two parameter tuning studies, and (iii) one extensive global parameter tuning study, as well as (iv) a new way, based on consensus ranking, to analyze results from multiple algorithms. The R package mlr is used as a uniform interface to the machine learning models. The R package SPOT is used to perform the actual tuning (optimization). All additional code is provided together with this paper.

</p>
</details>

<details><summary><b>CETransformer: Casual Effect Estimation via Transformer Based Representation Learning</b>
<a href="https://arxiv.org/abs/2107.08714">arxiv:2107.08714</a>
&#x1F4C8; 2 <br>
<p>Zhenyu Guo, Shuai Zheng, Zhizhe Liu, Kun Yan, Zhenfeng Zhu</p></summary>
<p>

**Abstract:** Treatment effect estimation, which refers to the estimation of causal effects and aims to measure the strength of the causal relationship, is of great importance in many fields but is a challenging problem in practice. As present, data-driven causal effect estimation faces two main challenges, i.e., selection bias and the missing of counterfactual. To address these two issues, most of the existing approaches tend to reduce the selection bias by learning a balanced representation, and then to estimate the counterfactual through the representation. However, they heavily rely on the finely hand-crafted metric functions when learning balanced representations, which generally doesn't work well for the situations where the original distribution is complicated. In this paper, we propose a CETransformer model for casual effect estimation via transformer based representation learning. To learn the representation of covariates(features) robustly, a self-supervised transformer is proposed, by which the correlation between covariates can be well exploited through self-attention mechanism. In addition, an adversarial network is adopted to balance the distribution of the treated and control groups in the representation space. Experimental results on three real-world datasets demonstrate the advantages of the proposed CETransformer, compared with the state-of-the-art treatment effect estimation methods.

</p>
</details>

<details><summary><b>Quantum Deep Learning: Sampling Neural Nets with a Quantum Annealer</b>
<a href="https://arxiv.org/abs/2107.08710">arxiv:2107.08710</a>
&#x1F4C8; 2 <br>
<p>Catherine F. Higham, Adrian Bedford</p></summary>
<p>

**Abstract:** We demonstrate the feasibility of framing a classically learned deep neural network as an energy based model that can be processed on a one-step quantum annealer in order to exploit fast sampling times. We propose approaches to overcome two hurdles for high resolution image classification on a quantum processing unit (QPU): the required number and binary nature of the model states. With this novel method we successfully transfer a convolutional neural network to the QPU and show the potential for classification speedup of at least one order of magnitude.

</p>
</details>

<details><summary><b>Improved Learning Rates for Stochastic Optimization: Two Theoretical Viewpoints</b>
<a href="https://arxiv.org/abs/2107.08686">arxiv:2107.08686</a>
&#x1F4C8; 2 <br>
<p>Shaojie Li, Yong Liu</p></summary>
<p>

**Abstract:** Generalization performance of stochastic optimization stands a central place in learning theory. In this paper, we investigate the excess risk performance and towards improved learning rates for two popular approaches of stochastic optimization: empirical risk minimization (ERM) and stochastic gradient descent (SGD). Although there exists plentiful generalization analysis of ERM and SGD for supervised learning, current theoretical understandings of ERM and SGD either have stronger assumptions in convex learning, e.g., strong convexity, or show slow rates and less studied in nonconvex learning. Motivated by these problems, we aim to provide improved rates under milder assumptions in convex learning and derive faster rates in nonconvex learning. It is notable that our analysis span two popular theoretical viewpoints: \emph{stability} and \emph{uniform convergence}. Specifically, in stability regime, we present high probability learning rates of order $\mathcal{O} (1/n)$ w.r.t. the sample size $n$ for ERM and SGD with milder assumptions in convex learning and similar high probability rates of order $\mathcal{O} (1/n)$ in nonconvex learning, rather than in expectation. Furthermore, this type of learning rate is improved to faster order $\mathcal{O} (1/n^2)$ in uniform convergence regime. To our best knowledge, for ERM and SGD, the learning rates presented in this paper are all state-of-the-art.

</p>
</details>

<details><summary><b>Input Agnostic Deep Learning for Alzheimer's Disease Classification Using Multimodal MRI Images</b>
<a href="https://arxiv.org/abs/2107.08673">arxiv:2107.08673</a>
&#x1F4C8; 2 <br>
<p>Aidana Massalimova, Huseyin Atakan Varol</p></summary>
<p>

**Abstract:** Alzheimer's disease (AD) is a progressive brain disorder that causes memory and functional impairments. The advances in machine learning and publicly available medical datasets initiated multiple studies in AD diagnosis. In this work, we utilize a multi-modal deep learning approach in classifying normal cognition, mild cognitive impairment and AD classes on the basis of structural MRI and diffusion tensor imaging (DTI) scans from the OASIS-3 dataset. In addition to a conventional multi-modal network, we also present an input agnostic architecture that allows diagnosis with either sMRI or DTI scan, which distinguishes our method from previous multi-modal machine learning-based methods. The results show that the input agnostic model achieves 0.96 accuracy when both structural MRI and DTI scans are provided as inputs.

</p>
</details>

<details><summary><b>Data Sharing Markets</b>
<a href="https://arxiv.org/abs/2107.08630">arxiv:2107.08630</a>
&#x1F4C8; 2 <br>
<p>Mohammad Rasouli, Michael I. Jordan</p></summary>
<p>

**Abstract:** With the growing use of distributed machine learning techniques, there is a growing need for data markets that allows agents to share data with each other. Nevertheless data has unique features that separates it from other commodities including replicability, cost of sharing, and ability to distort. We study a setup where each agent can be both buyer and seller of data. For this setup, we consider two cases: bilateral data exchange (trading data with data) and unilateral data exchange (trading data with money). We model bilateral sharing as a network formation game and show the existence of strongly stable outcome under the top agents property by allowing limited complementarity. We propose ordered match algorithm which can find the stable outcome in O(N^2) (N is the number of agents). For the unilateral sharing, under the assumption of additive cost structure, we construct competitive prices that can implement any social welfare maximizing outcome. Finally for this setup when agents have private information, we propose mixed-VCG mechanism which uses zero cost data distortion of data sharing with its isolated impact to achieve budget balance while truthfully implementing socially optimal outcomes to the exact level of budget imbalance of standard VCG mechanisms. Mixed-VCG uses data distortions as data money for this purpose. We further relax zero cost data distortion assumption by proposing distorted-mixed-VCG. We also extend our model and results to data sharing via incremental inquiries and differential privacy costs.

</p>
</details>

<details><summary><b>Federated Learning using Smart Contracts on Blockchains, based on Reward Driven Approach</b>
<a href="https://arxiv.org/abs/2107.10243">arxiv:2107.10243</a>
&#x1F4C8; 1 <br>
<p>Monik Raj Behera, Sudhir Upadhyay, Suresh Shetty</p></summary>
<p>

**Abstract:** Over the recent years, Federated machine learning continues to gain interest and momentum where there is a need to draw insights from data while preserving the data provider's privacy. However, one among other existing challenges in the adoption of federated learning has been the lack of fair, transparent and universally agreed incentivization schemes for rewarding the federated learning contributors. Smart contracts on a blockchain network provide transparent, immutable and independently verifiable proofs by all participants of the network. We leverage this open and transparent nature of smart contracts on a blockchain to define incentivization rules for the contributors, which is based on a novel scalar quantity - federated contribution. Such a smart contract based reward-driven model has the potential to revolutionize the federated learning adoption in enterprises. Our contribution is two-fold: first is to show how smart contract based blockchain can be a very natural communication channel for federated learning. Second, leveraging this infrastructure, we can show how an intuitive measure of each agents' contribution can be built and integrated with the life cycle of the training and reward process.

</p>
</details>

<details><summary><b>Predicting the 2020 US Presidential Election with Twitter</b>
<a href="https://arxiv.org/abs/2107.09640">arxiv:2107.09640</a>
&#x1F4C8; 1 <br>
<p>Michael Caballero</p></summary>
<p>

**Abstract:** One major sub-domain in the subject of polling public opinion with social media data is electoral prediction. Electoral prediction utilizing social media data potentially would significantly affect campaign strategies, complementing traditional polling methods and providing cheaper polling in real-time. First, this paper explores past successful methods from research for analysis and prediction of the 2020 US Presidential Election using Twitter data. Then, this research proposes a new method for electoral prediction which combines sentiment, from NLP on the text of tweets, and structural data with aggregate polling, a time series analysis, and a special focus on Twitter users critical to the election. Though this method performed worse than its baseline of polling predictions, it is inconclusive whether this is an accurate method for predicting elections due to scarcity of data. More research and more data are needed to accurately measure this method's overall effectiveness.

</p>
</details>

<details><summary><b>Modality Fusion Network and Personalized Attention in Momentary Stress Detection in the Wild</b>
<a href="https://arxiv.org/abs/2107.09510">arxiv:2107.09510</a>
&#x1F4C8; 1 <br>
<p>Han Yu, Thomas Vaessen, Inez Myin-Germeys, Akane Sano</p></summary>
<p>

**Abstract:** Multimodal wearable physiological data in daily life have been used to estimate self-reported stress labels. However, missing data modalities in data collection makes it challenging to leverage all the collected samples. Besides, heterogeneous sensor data and labels among individuals add challenges in building robust stress detection models. In this paper, we proposed a modality fusion network (MFN) to train models and infer self-reported binary stress labels under both complete and incomplete modality conditions. In addition, we applied personalized attention (PA) strategy to leverage personalized representation along with the generalized one-size-fits-all model. We evaluated our methods on a multimodal wearable sensor dataset (N=41) including galvanic skin response (GSR) and electrocardiogram (ECG). Compared to the baseline method using the samples with complete modalities, the performance of the MFN improved by 1.6% in f1-scores. On the other hand, the proposed PA strategy showed a 2.3% higher stress detection f1-score and approximately up to 70% reduction in personalized model parameter size (9.1 MB) compared to the previous state-of-the-art transfer learning strategy (29.3 MB).

</p>
</details>

<details><summary><b>Predicting Friction System Performance with Symbolic Regression and Genetic Programming with Factor Variables</b>
<a href="https://arxiv.org/abs/2107.09484">arxiv:2107.09484</a>
&#x1F4C8; 1 <br>
<p>Gabriel Kronberger, Michael Kommenda, Andreas Promberger, Falk Nickel</p></summary>
<p>

**Abstract:** Friction systems are mechanical systems wherein friction is used for force transmission (e.g. mechanical braking systems or automatic gearboxes). For finding optimal and safe design parameters, engineers have to predict friction system performance. This is especially difficult in real-world applications, because it is affected by many parameters. We have used symbolic regression and genetic programming for finding accurate and trustworthy prediction models for this task. However, it is not straight-forward how nominal variables can be included. In particular, a one-hot-encoding is unsatisfactory because genetic programming tends to remove such indicator variables. We have therefore used so-called factor variables for representing nominal variables in symbolic regression models. Our results show that GP is able to produce symbolic regression models for predicting friction performance with predictive accuracy that is comparable to artificial neural networks. The symbolic regression models with factor variables are less complex than models using a one-hot encoding.

</p>
</details>

<details><summary><b>OSLO: On-the-Sphere Learning for Omnidirectional images and its application to 360-degree image compression</b>
<a href="https://arxiv.org/abs/2107.09179">arxiv:2107.09179</a>
&#x1F4C8; 1 <br>
<p>Navid Mahmoudian Bidgoli, Roberto G. de A. Azevedo, Thomas Maugey, Aline Roumy, Pascal Frossard</p></summary>
<p>

**Abstract:** State-of-the-art 2D image compression schemes rely on the power of convolutional neural networks (CNNs). Although CNNs offer promising perspectives for 2D image compression, extending such models to omnidirectional images is not straightforward. First, omnidirectional images have specific spatial and statistical properties that can not be fully captured by current CNN models. Second, basic mathematical operations composing a CNN architecture, e.g., translation and sampling, are not well-defined on the sphere. In this paper, we study the learning of representation models for omnidirectional images and propose to use the properties of HEALPix uniform sampling of the sphere to redefine the mathematical tools used in deep learning models for omnidirectional images. In particular, we: i) propose the definition of a new convolution operation on the sphere that keeps the high expressiveness and the low complexity of a classical 2D convolution; ii) adapt standard CNN techniques such as stride, iterative aggregation, and pixel shuffling to the spherical domain; and then iii) apply our new framework to the task of omnidirectional image compression. Our experiments show that our proposed on-the-sphere solution leads to a better compression gain that can save 13.7% of the bit rate compared to similar learned models applied to equirectangular images. Also, compared to learning models based on graph convolutional networks, our solution supports more expressive filters that can preserve high frequencies and provide a better perceptual quality of the compressed images. Such results demonstrate the efficiency of the proposed framework, which opens new research venues for other omnidirectional vision tasks to be effectively implemented on the sphere manifold.

</p>
</details>

<details><summary><b>Quality and Complexity Assessment of Learning-Based Image Compression Solutions</b>
<a href="https://arxiv.org/abs/2107.09136">arxiv:2107.09136</a>
&#x1F4C8; 1 <br>
<p>João Dick, Brunno Abreu, Mateus Grellert, Sergio Bampi</p></summary>
<p>

**Abstract:** This work presents an analysis of state-of-the-art learning-based image compression techniques. We compare 8 models available in the Tensorflow Compression package in terms of visual quality metrics and processing time, using the KODAK data set. The results are compared with the Better Portable Graphics (BPG) and the JPEG2000 codecs. Results show that JPEG2000 has the lowest execution times compared with the fastest learning-based model, with a speedup of 1.46x in compression and 30x in decompression. However, the learning-based models achieved improvements over JPEG2000 in terms of quality, specially for lower bitrates. Our findings also show that BPG is more efficient in terms of PSNR, but the learning models are better for other quality metrics, and sometimes even faster. The results indicate that learning-based techniques are promising solutions towards a future mainstream compression method.

</p>
</details>

<details><summary><b>GNN4IP: Graph Neural Network for Hardware Intellectual Property Piracy Detection</b>
<a href="https://arxiv.org/abs/2107.09130">arxiv:2107.09130</a>
&#x1F4C8; 1 <br>
<p>Rozhin Yasaei, Shih-Yuan Yu, Emad Kasaeyan Naeini, Mohammad Abdullah Al Faruque</p></summary>
<p>

**Abstract:** Aggressive time-to-market constraints and enormous hardware design and fabrication costs have pushed the semiconductor industry toward hardware Intellectual Properties (IP) core design. However, the globalization of the integrated circuits (IC) supply chain exposes IP providers to theft and illegal redistribution of IPs. Watermarking and fingerprinting are proposed to detect IP piracy. Nevertheless, they come with additional hardware overhead and cannot guarantee IP security as advanced attacks are reported to remove the watermark, forge, or bypass it. In this work, we propose a novel methodology, GNN4IP, to assess similarities between circuits and detect IP piracy. We model the hardware design as a graph and construct a graph neural network model to learn its behavior using the comprehensive dataset of register transfer level codes and gate-level netlists that we have gathered. GNN4IP detects IP piracy with 96% accuracy in our dataset and recognizes the original IP in its obfuscated version with 100% accuracy.

</p>
</details>

<details><summary><b>DPNNet-2.0 Part I: Finding hidden planets from simulated images of protoplanetary disk gaps</b>
<a href="https://arxiv.org/abs/2107.09086">arxiv:2107.09086</a>
&#x1F4C8; 1 <br>
<p>Sayantan Auddy, Ramit Dey, Min-Kai Lin, Cassandra Hall</p></summary>
<p>

**Abstract:** The observed sub-structures, like annular gaps, in dust emissions from protoplanetary disk, are often interpreted as signatures of embedded planets. Fitting a model of planetary gaps to these observed features using customized simulations or empirical relations can reveal the characteristics of the hidden planets. However, customized fitting is often impractical owing to the increasing sample size and the complexity of disk-planet interaction. In this paper we introduce the architecture of DPNNet-2.0, second in the series after DPNNet \citep{aud20}, designed using a Convolutional Neural Network ( CNN, here specifically ResNet50) for predicting exoplanet masses directly from simulated images of protoplanetary disks hosting a single planet. DPNNet-2.0 additionally consists of a multi-input framework that uses both a CNN and multi-layer perceptron (a class of artificial neural network) for processing image and disk parameters simultaneously. This enables DPNNet-2.0 to be trained using images directly, with the added option of considering disk parameters (disk viscosities, disk temperatures, disk surface density profiles, dust abundances, and particle Stokes numbers) generated from disk-planet hydrodynamic simulations as inputs. This work provides the required framework and is the first step towards the use of computer vision (implementing CNN) to directly extract mass of an exoplanet from planetary gaps observed in dust-surface density maps by telescopes such as the Atacama Large (sub-)Millimeter Array.

</p>
</details>

<details><summary><b>Reconstruction of the Density Power Spectrum from Quasar Spectra using Machine Learning</b>
<a href="https://arxiv.org/abs/2107.09082">arxiv:2107.09082</a>
&#x1F4C8; 1 <br>
<p>Maria Han Veiga, Xi Meng, Oleg Y. Gnedin, Nickolay Y. Gnedin, Xun Huan</p></summary>
<p>

**Abstract:** We describe a novel end-to-end approach using Machine Learning to reconstruct the power spectrum of cosmological density perturbations at high redshift from observed quasar spectra. State-of-the-art cosmological simulations of structure formation are used to generate a large synthetic dataset of line-of-sight absorption spectra paired with 1-dimensional fluid quantities along the same line-of-sight, such as the total density of matter and the density of neutral atomic hydrogen. With this dataset, we build a series of data-driven models to predict the power spectrum of total matter density. We are able to produce models which yield reconstruction to accuracy of about 1% for wavelengths $k \leq 2 h Mpc^{-1}$, while the error increases at larger $k$. We show the size of data sample required to reach a particular error rate, giving a sense of how much data is necessary to reach a desired accuracy. This work provides a foundation for developing methods to analyse very large upcoming datasets with the next-generation observational facilities.

</p>
</details>

<details><summary><b>Sample Complexity of Learning Quantum Circuits</b>
<a href="https://arxiv.org/abs/2107.09078">arxiv:2107.09078</a>
&#x1F4C8; 1 <br>
<p>Haoyuan Cai, Qi Ye, Dong-Ling Deng</p></summary>
<p>

**Abstract:** Quantum computers hold unprecedented potentials for machine learning applications. Here, we prove that physical quantum circuits are PAC (probably approximately correct) learnable on a quantum computer via empirical risk minimization: to learn a quantum circuit with at most $n^c$ gates and each gate acting on a constant number of qubits, the sample complexity is bounded by $\tilde{O}(n^{c+1})$. In particular, we explicitly construct a family of variational quantum circuits with $O(n^{c+1})$ elementary gates arranged in a fixed pattern, which can represent all physical quantum circuits consisting of at most $n^c$ elementary gates. Our results provide a valuable guide for quantum machine learning in both theory and experiment.

</p>
</details>

<details><summary><b>T-RECS: A Simulation Tool to Study the Societal Impact of Recommender Systems</b>
<a href="https://arxiv.org/abs/2107.08959">arxiv:2107.08959</a>
&#x1F4C8; 1 <br>
<p>Eli Lucherini, Matthew Sun, Amy Winecoff, Arvind Narayanan</p></summary>
<p>

**Abstract:** Simulation has emerged as a popular method to study the long-term societal consequences of recommender systems. This approach allows researchers to specify their theoretical model explicitly and observe the evolution of system-level outcomes over time. However, performing simulation-based studies often requires researchers to build their own simulation environments from the ground up, which creates a high barrier to entry, introduces room for implementation error, and makes it difficult to disentangle whether observed outcomes are due to the model or the implementation.
  We introduce T-RECS, an open-sourced Python package designed for researchers to simulate recommendation systems and other types of sociotechnical systems in which an algorithm mediates the interactions between multiple stakeholders, such as users and content creators. To demonstrate the flexibility of T-RECS, we perform a replication of two prior simulation-based research on sociotechnical systems. We additionally show how T-RECS can be used to generate novel insights with minimal overhead. Our tool promotes reproducibility in this area of research, provides a unified language for simulating sociotechnical systems, and removes the friction of implementing simulations from scratch.

</p>
</details>

<details><summary><b>MEGEX: Data-Free Model Extraction Attack against Gradient-Based Explainable AI</b>
<a href="https://arxiv.org/abs/2107.08909">arxiv:2107.08909</a>
&#x1F4C8; 1 <br>
<p>Takayuki Miura, Satoshi Hasegawa, Toshiki Shibahara</p></summary>
<p>

**Abstract:** The advance of explainable artificial intelligence, which provides reasons for its predictions, is expected to accelerate the use of deep neural networks in the real world like Machine Learning as a Service (MLaaS) that returns predictions on queried data with the trained model. Deep neural networks deployed in MLaaS face the threat of model extraction attacks. A model extraction attack is an attack to violate intellectual property and privacy in which an adversary steals trained models in a cloud using only their predictions. In particular, a data-free model extraction attack has been proposed recently and is more critical. In this attack, an adversary uses a generative model instead of preparing input data. The feasibility of this attack, however, needs to be studied since it requires more queries than that with surrogate datasets. In this paper, we propose MEGEX, a data-free model extraction attack against a gradient-based explainable AI. In this method, an adversary uses the explanations to train the generative model and reduces the number of queries to steal the model. Our experiments show that our proposed method reconstructs high-accuracy models -- 0.97$\times$ and 0.98$\times$ the victim model accuracy on SVHN and CIFAR-10 datasets given 2M and 20M queries, respectively. This implies that there is a trade-off between the interpretability of models and the difficulty of stealing them.

</p>
</details>

<details><summary><b>Synthesizing Human Faces using Latent Space Factorization and Local Weights (Extended Version)</b>
<a href="https://arxiv.org/abs/2107.08737">arxiv:2107.08737</a>
&#x1F4C8; 1 <br>
<p>Minyoung Kim, Young J. Kim</p></summary>
<p>

**Abstract:** We propose a 3D face generative model with local weights to increase the model's variations and expressiveness. The proposed model allows partial manipulation of the face while still learning the whole face mesh. For this purpose, we address an effective way to extract local facial features from the entire data and explore a way to manipulate them during a holistic generation. First, we factorize the latent space of the whole face to the subspace indicating different parts of the face. In addition, local weights generated by non-negative matrix factorization are applied to the factorized latent space so that the decomposed part space is semantically meaningful. We experiment with our model and observe that effective facial part manipulation is possible and that the model's expressiveness is improved.

</p>
</details>

<details><summary><b>Deceptive Logic Locking for Hardware Integrity Protection against Machine Learning Attacks</b>
<a href="https://arxiv.org/abs/2107.08695">arxiv:2107.08695</a>
&#x1F4C8; 1 <br>
<p>Dominik Sisejkovic, Farhad Merchant, Lennart M. Reimann, Rainer Leupers</p></summary>
<p>

**Abstract:** Logic locking has emerged as a prominent key-driven technique to protect the integrity of integrated circuits. However, novel machine-learning-based attacks have recently been introduced to challenge the security foundations of locking schemes. These attacks are able to recover a significant percentage of the key without having access to an activated circuit. This paper address this issue through two focal points. First, we present a theoretical model to test locking schemes for key-related structural leakage that can be exploited by machine learning. Second, based on the theoretical model, we introduce D-MUX: a deceptive multiplexer-based logic-locking scheme that is resilient against structure-exploiting machine learning attacks. Through the design of D-MUX, we uncover a major fallacy in existing multiplexer-based locking schemes in the form of a structural-analysis attack. Finally, an extensive cost evaluation of D-MUX is presented. To the best of our knowledge, D-MUX is the first machine-learning-resilient locking scheme capable of protecting against all known learning-based attacks. Hereby, the presented work offers a starting point for the design and evaluation of future-generation logic locking in the era of machine learning.

</p>
</details>

<details><summary><b>Learned Sorted Table Search and Static Indexes in Small Model Space</b>
<a href="https://arxiv.org/abs/2107.09480">arxiv:2107.09480</a>
&#x1F4C8; 0 <br>
<p>Domenico Amato, Giosuè Lo Bosco, Raffaele Giancarlo</p></summary>
<p>

**Abstract:** Machine Learning Techniques, properly combined with Data Structures, have resulted in Learned Static Indexes, innovative and powerful tools that speed-up Binary Search, with the use of additional space with respect to the table being searched into. Such space is devoted to the ML model. Although in their infancy, they are methodologically and practically important, due to the pervasiveness of Sorted Table Search procedures. In modern applications, model space is a key factor and, in fact, a major open question concerning this area is to assess to what extent one can enjoy the speed-up of Learned Indexes while using constant or nearly constant space models. We address it here by (a) introducing two new models, i.e., denoted {\bf KO-BFS} and {\bf SY-RMI}, respectively; (b) by systematically exploring, for the first time, the time-space trade-offs of a hierarchy of existing models, i.e., the ones in {\bf SOSD}, together with the new ones. We document a novel and rather complex time-space trade-off picture, which is very informative for users. We experimentally show that the {\bf KO-BFS }can speed up Interpolation Search and Uniform Binary Search in constant space. For other versions of Binary Search, our second model, together with the bi-criteria {\bf PGM} index, can achieve a speed-up with a model space of $0.05\%$ more than the one taken by the table, being competitive in terms of time-space trade-off with existing proposals. The {\bf SY-RMI} and the bi-criteria {\bf PGM} complement each other quite well across the various levels of the internal memory hierarchy. Finally, our findings are of interest to designers, since they highlight the need for further studies regarding the time-space relation in Learned Indexes.

</p>
</details>

<details><summary><b>Music Tempo Estimation via Neural Networks -- A Comparative Analysis</b>
<a href="https://arxiv.org/abs/2107.09208">arxiv:2107.09208</a>
&#x1F4C8; 0 <br>
<p>Mila Soares de Oliveira de Souza, Pedro Nuno de Souza Moura, Jean-Pierre Briot</p></summary>
<p>

**Abstract:** This paper presents a comparative analysis on two artificial neural networks (with different architectures) for the task of tempo estimation. For this purpose, it also proposes the modeling, training and evaluation of a B-RNN (Bidirectional Recurrent Neural Network) model capable of estimating tempo in bpm (beats per minutes) of musical pieces, without using external auxiliary modules. An extensive database (12,550 pieces in total) was curated to conduct a quantitative and qualitative analysis over the experiment. Percussion-only tracks were also included in the dataset. The performance of the B-RNN is compared to that of state-of-the-art models. For further comparison, a state-of-the-art CNN was also retrained with the same datasets used for the B-RNN training. Evaluation results for each model and datasets are presented and discussed, as well as observations and ideas for future research. Tempo estimation was more accurate for the percussion only dataset, suggesting that the estimation can be more accurate for percussion-only tracks, although further experiments (with more of such datasets) should be made to gather stronger evidence.

</p>
</details>

<details><summary><b>Wave-Informed Matrix Factorization with Global Optimality Guarantees</b>
<a href="https://arxiv.org/abs/2107.09144">arxiv:2107.09144</a>
&#x1F4C8; 0 <br>
<p>Harsha Vardhan Tetali, Joel B. Harley, Benjamin D. Haeffele</p></summary>
<p>

**Abstract:** With the recent success of representation learning methods, which includes deep learning as a special case, there has been considerable interest in developing representation learning techniques that can incorporate known physical constraints into the learned representation. As one example, in many applications that involve a signal propagating through physical media (e.g., optics, acoustics, fluid dynamics, etc), it is known that the dynamics of the signal must satisfy constraints imposed by the wave equation. Here we propose a matrix factorization technique that decomposes such signals into a sum of components, where each component is regularized to ensure that it satisfies wave equation constraints. Although our proposed formulation is non-convex, we prove that our model can be efficiently solved to global optimality in polynomial time. We demonstrate the benefits of our work by applications in structural health monitoring, where prior work has attempted to solve this problem using sparse dictionary learning approaches that do not come with any theoretical guarantees regarding convergence to global optimality and employ heuristics to capture desired physical constraints.

</p>
</details>

<details><summary><b>Analysis of training and seed bias in small molecules generated with a conditional graph-based variational autoencoder -- Insights for practical AI-driven molecule generation</b>
<a href="https://arxiv.org/abs/2107.08987">arxiv:2107.08987</a>
&#x1F4C8; 0 <br>
<p>Seung-gu Kang, Joseph A. Morrone, Jeffrey K. Weber, Wendy D. Cornell</p></summary>
<p>

**Abstract:** The application of deep learning to generative molecule design has shown early promise for accelerating lead series development. However, questions remain concerning how factors like training, dataset, and seed bias impact the technology's utility to medicine and computational chemists. In this work, we analyze the impact of seed and training bias on the output of an activity-conditioned graph-based variational autoencoder (VAE). Leveraging a massive, labeled dataset corresponding to the dopamine D2 receptor, our graph-based generative model is shown to excel in producing desired conditioned activities and favorable unconditioned physical properties in generated molecules. We implement an activity swapping method that allows for the activation, deactivation, or retention of activity of molecular seeds, and we apply independent deep learning classifiers to verify the generative results. Overall, we uncover relationships between noise, molecular seeds, and training set selection across a range of latent-space sampling procedures, providing important insights for practical AI-driven molecule generation.

</p>
</details>

<details><summary><b>DiCE4EL: Interpreting Process Predictions using a Milestone-Aware Counterfactual Approach</b>
<a href="https://arxiv.org/abs/2107.08697">arxiv:2107.08697</a>
&#x1F4C8; 0 <br>
<p>Chihcheng Hsieh, Catarina Moreira, Chun Ouyang</p></summary>
<p>

**Abstract:** Predictive process analytics often apply machine learning to predict the future states of a running business~process. However, the internal mechanisms of many existing predictive algorithms are opaque and a human decision-maker is unable to understand \emph{why} a certain activity was predicted. Recently, counterfactuals have been proposed in the literature to derive human-understandable explanations from predictive models. Current counterfactual approaches consist of finding the minimum feature change that can make a certain prediction flip its outcome. Although many algorithms have been proposed, their application to multi-dimensional sequence data like event logs has not been explored in the literature.
  In this paper, we explore the use of a recent, popular model-agnostic counterfactual algorithm, DiCE, in the context of predictive process analytics. The analysis reveals that DiCE is unable to derive explanations for process predictions, due to (1) process domain knowledge not being taken into account, (2) long traces of process execution that often tend to be less understandable, and (3) difficulties in optimising the counterfactual search with categorical variables. We design an extension of DiCE, namely DiCE4EL (DiCE for Event Logs), that can generate counterfactual explanations for process prediction, and propose an approach that supports deriving milestone-aware counterfactual explanations at key intermediate stages along process execution to promote interpretability. We apply our approach to a publicly available real-life event log and the analysis results demonstrate the effectiveness of the proposed approach.

</p>
</details>


[Next Page]({{ '/2021/07/18/2021.07.18.html' | relative_url }})
