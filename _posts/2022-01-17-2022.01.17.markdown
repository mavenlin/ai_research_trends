Prev: [2022.01.16]({{ '/2022/01/16/2022.01.16.html' | relative_url }})  Next: [2022.01.18]({{ '/2022/01/18/2022.01.18.html' | relative_url }})
{% raw %}
## Summary for 2022-01-17, created on 2022-01-27


<details><summary><b>Collapse by Conditioning: Training Class-conditional GANs with Limited Data</b>
<a href="https://arxiv.org/abs/2201.06578">arxiv:2201.06578</a>
&#x1F4C8; 13 <br>
<p>Mohamad Shahbazi, Martin Danelljan, Danda Pani Paudel, Luc Van Gool</p></summary>
<p>

**Abstract:** Class-conditioning offers a direct means of controlling a Generative Adversarial Network (GAN) based on a discrete input variable. While necessary in many applications, the additional information provided by the class labels could even be expected to benefit the training of the GAN itself. Contrary to this belief, we observe that class-conditioning causes mode collapse in limited data settings, where unconditional learning leads to satisfactory generative ability. Motivated by this observation, we propose a training strategy for conditional GANs (cGANs) that effectively prevents the observed mode-collapse by leveraging unconditional learning. Our training strategy starts with an unconditional GAN and gradually injects conditional information into the generator and the objective function. The proposed method for training cGANs with limited data results not only in stable training but also in generating high-quality images, thanks to the early-stage exploitation of the shared information across classes. We analyze the aforementioned mode collapse problem in comprehensive experiments on four datasets. Our approach demonstrates outstanding results compared with state-of-the-art methods and established baselines. The code is available at: https://github.com/mshahbazi72/transitional-cGAN

</p>
</details>

<details><summary><b>Generalizable Neuro-symbolic Systems for Commonsense Question Answering</b>
<a href="https://arxiv.org/abs/2201.06230">arxiv:2201.06230</a>
&#x1F4C8; 10 <br>
<p>Alessandro Oltramari, Jonathan Francis, Filip Ilievski, Kaixin Ma, Roshanak Mirzaee</p></summary>
<p>

**Abstract:** This chapter illustrates how suitable neuro-symbolic models for language understanding can enable domain generalizability and robustness in downstream tasks. Different methods for integrating neural language models and knowledge graphs are discussed. The situations in which this combination is most appropriate are characterized, including quantitative evaluation and qualitative error analysis on a variety of commonsense question answering benchmark datasets.

</p>
</details>

<details><summary><b>The CLEAR Benchmark: Continual LEArning on Real-World Imagery</b>
<a href="https://arxiv.org/abs/2201.06289">arxiv:2201.06289</a>
&#x1F4C8; 8 <br>
<p>Zhiqiu Lin, Jia Shi, Deepak Pathak, Deva Ramanan</p></summary>
<p>

**Abstract:** Continual learning (CL) is widely regarded as crucial challenge for lifelong AI. However, existing CL benchmarks, e.g. Permuted-MNIST and Split-CIFAR, make use of artificial temporal variation and do not align with or generalize to the real-world. In this paper, we introduce CLEAR, the first continual image classification benchmark dataset with a natural temporal evolution of visual concepts in the real world that spans a decade (2004-2014). We build CLEAR from existing large-scale image collections (YFCC100M) through a novel and scalable low-cost approach to visio-linguistic dataset curation. Our pipeline makes use of pretrained vision-language models (e.g. CLIP) to interactively build labeled datasets, which are further validated with crowd-sourcing to remove errors and even inappropriate images (hidden in original YFCC100M). The major strength of CLEAR over prior CL benchmarks is the smooth temporal evolution of visual concepts with real-world imagery, including both high-quality labeled data along with abundant unlabeled samples per time period for continual semi-supervised learning. We find that a simple unsupervised pre-training step can already boost state-of-the-art CL algorithms that only utilize fully-supervised data. Our analysis also reveals that mainstream CL evaluation protocols that train and test on iid data artificially inflate performance of CL system. To address this, we propose novel "streaming" protocols for CL that always test on the (near) future. Interestingly, streaming protocols (a) can simplify dataset curation since today's testset can be repurposed for tomorrow's trainset and (b) can produce more generalizable models with more accurate estimates of performance since all labeled data from each time-period is used for both training and testing (unlike classic iid train-test splits).

</p>
</details>

<details><summary><b>Towards deep observation: A systematic survey on artificial intelligence techniques to monitor fetus via Ultrasound Images</b>
<a href="https://arxiv.org/abs/2201.07935">arxiv:2201.07935</a>
&#x1F4C8; 5 <br>
<p>Mahmood Alzubaidi, Marco Agus, Khalid Alyafei, Khaled A Althelaya, Uzair Shah, Alaa A. Abdalrazaq, Mohammed Anbar, Zafar Iqbal, Mowafa Househ</p></summary>
<p>

**Abstract:** Developing innovative informatics approaches aimed to enhance fetal monitoring is a burgeoning field of study in reproductive medicine. Several reviews have been conducted regarding Artificial intelligence (AI) techniques to improve pregnancy outcomes. They are limited by focusing on specific data such as mother's care during pregnancy. This systematic survey aims to explore how artificial intelligence (AI) can assist with fetal growth monitoring via Ultrasound (US) image. We used eight medical and computer science bibliographic databases, including PubMed, Embase, PsycINFO, ScienceDirect, IEEE explore, ACM Library, Google Scholar, and the Web of Science. We retrieved studies published between 2010 to 2021. Data extracted from studies were synthesized using a narrative approach. Out of 1269 retrieved studies, we included 107 distinct studies from queries that were relevant to the topic in the survey. We found that 2D ultrasound images were more popular (n=88) than 3D and 4D ultrasound images (n=19). Classification is the most used method (n=42), followed by segmentation (n=31), classification integrated with segmentation (n=16) and other miscellaneous such as object-detection, regression and reinforcement learning (n=18). The most common areas within the pregnancy domain were the fetus head (n=43), then fetus body (n=31), fetus heart (n=13), fetus abdomen (n=10), and lastly the fetus face (n=10). In the most recent studies, deep learning techniques were primarily used (n=81), followed by machine learning (n=16), artificial neural network (n=7), and reinforcement learning (n=2). AI techniques played a crucial role in predicting fetal diseases and identifying fetus anatomy structures during pregnancy. More research is required to validate this technology from a physician's perspective, such as pilot studies and randomized controlled trials on AI and its applications in a hospital setting.

</p>
</details>

<details><summary><b>Millions of Co-purchases and Reviews Reveal the Spread of Polarization and Lifestyle Politics across Online Markets</b>
<a href="https://arxiv.org/abs/2201.06556">arxiv:2201.06556</a>
&#x1F4C8; 5 <br>
<p>Alexander Ruch, Ari Decter-Frain, Raghav Batra</p></summary>
<p>

**Abstract:** Polarization in America has reached a high point as markets are also becoming polarized. Existing research, however, focuses on specific market segments and products and has not evaluated this trend's full breadth. If such fault lines do spread into other segments that are not explicitly political, it would indicate the presence of lifestyle politics -- when ideas and behaviors not inherently political become politically aligned through their connections with explicitly political things. We study the pervasiveness of polarization and lifestyle politics over different product segments in a diverse market and test the extent to which consumer- and platform-level network effects and morality may explain lifestyle politics. Specifically, using graph and language data from Amazon (82.5M reviews of 9.5M products and product and category metadata from 1996-2014), we sample 234.6 million relations among 21.8 million market entities to find product categories that are most politically relevant, aligned, and polarized. We then extract moral values present in reviews' text and use these data and other reviewer-, product-, and category-level data to test whether individual- and platform- level network factors explain lifestyle politics better than products' implicit morality. We find pervasive lifestyle politics. Cultural products are 4 times more polarized than any other segment, products' political attributes have up to 3.7 times larger associations with lifestyle politics than author-level covariates, and morality has statistically significant but relatively small correlations with lifestyle politics. Examining lifestyle politics in these contexts helps us better understand the extent and root of partisan differences, why Americans may be so polarized, and how this polarization affects market systems.

</p>
</details>

<details><summary><b>Differentiable Rule Induction with Learned Relational Features</b>
<a href="https://arxiv.org/abs/2201.06515">arxiv:2201.06515</a>
&#x1F4C8; 5 <br>
<p>Remy Kusters, Yusik Kim, Marine Collery, Christian de Sainte Marie, Shubham Gupta</p></summary>
<p>

**Abstract:** Rule-based decision models are attractive due to their interpretability. However, existing rule induction methods often results in long and consequently less interpretable set of rules. This problem can, in many cases, be attributed to the rule learner's lack of appropriately expressive vocabulary, i.e., relevant predicates. Most existing rule induction algorithms presume the availability of predicates used to represent the rules, naturally decoupling the predicate definition and the rule learning phases. In contrast, we propose the Relational Rule Network (RRN), a neural architecture that learns relational predicates that represent a linear relationship among attributes along with the rules that use them. This approach opens the door to increasing the expressiveness of induced decision models by coupling predicate learning directly with rule learning in an end to end differentiable fashion. On benchmark tasks, we show that these relational predicates are simple enough to retain interpretability, yet improve prediction accuracy and provide sets of rules that are more concise compared to state of the art rule induction algorithms.

</p>
</details>

<details><summary><b>On Training Targets and Activation Functions for Deep Representation Learning in Text-Dependent Speaker Verification</b>
<a href="https://arxiv.org/abs/2201.06426">arxiv:2201.06426</a>
&#x1F4C8; 5 <br>
<p>Achintya kr. Sarkar, Zheng-Hua Tan</p></summary>
<p>

**Abstract:** Deep representation learning has gained significant momentum in advancing text-dependent speaker verification (TD-SV) systems. When designing deep neural networks (DNN) for extracting bottleneck features, key considerations include training targets, activation functions, and loss functions. In this paper, we systematically study the impact of these choices on the performance of TD-SV. For training targets, we consider speaker identity, time-contrastive learning (TCL) and auto-regressive prediction coding with the first being supervised and the last two being self-supervised. Furthermore, we study a range of loss functions when speaker identity is used as the training target. With regard to activation functions, we study the widely used sigmoid function, rectified linear unit (ReLU), and Gaussian error linear unit (GELU). We experimentally show that GELU is able to reduce the error rates of TD-SV significantly compared to sigmoid, irrespective of training target. Among the three training targets, TCL performs the best. Among the various loss functions, cross entropy, joint-softmax and focal loss functions outperform the others. Finally, score-level fusion of different systems is also able to reduce the error rates. Experiments are conducted on the RedDots 2016 challenge database for TD-SV using short utterances. For the speaker classifications, the well-known Gaussian mixture model-universal background model (GMM-UBM) and i-vector techniques are used.

</p>
</details>

<details><summary><b>A survey study of success factors in data science projects</b>
<a href="https://arxiv.org/abs/2201.06310">arxiv:2201.06310</a>
&#x1F4C8; 5 <br>
<p>Iñigo Martinez, Elisabeth Viles, Igor G. Olaizola</p></summary>
<p>

**Abstract:** In recent years, the data science community has pursued excellence and made significant research efforts to develop advanced analytics, focusing on solving technical problems at the expense of organizational and socio-technical challenges. According to previous surveys on the state of data science project management, there is a significant gap between technical and organizational processes. In this article we present new empirical data from a survey to 237 data science professionals on the use of project management methodologies for data science. We provide additional profiling of the survey respondents' roles and their priorities when executing data science projects. Based on this survey study, the main findings are: (1) Agile data science lifecycle is the most widely used framework, but only 25% of the survey participants state to follow a data science project methodology. (2) The most important success factors are precisely describing stakeholders' needs, communicating the results to end-users, and team collaboration and coordination. (3) Professionals who adhere to a project methodology place greater emphasis on the project's potential risks and pitfalls, version control, the deployment pipeline to production, and data security and privacy.

</p>
</details>

<details><summary><b>Explainable Ensemble Machine Learning for Breast Cancer Diagnosis based on Ultrasound Image Texture Features</b>
<a href="https://arxiv.org/abs/2201.07227">arxiv:2201.07227</a>
&#x1F4C8; 4 <br>
<p>Alireza Rezazadeh, Yasamin Jafarian, Ali Kord</p></summary>
<p>

**Abstract:** Image classification is widely used to build predictive models for breast cancer diagnosis. Most existing approaches overwhelmingly rely on deep convolutional networks to build such diagnosis pipelines. These model architectures, although remarkable in performance, are black-box systems that provide minimal insight into the inner logic behind their predictions. This is a major drawback as the explainability of prediction is vital for applications such as cancer diagnosis. In this paper, we address this issue by proposing an explainable machine learning pipeline for breast cancer diagnosis based on ultrasound images. We extract first- and second-order texture features of the ultrasound images and use them to build a probabilistic ensemble of decision tree classifiers. Each decision tree learns to classify the input ultrasound image by learning a set of robust decision thresholds for texture features of the image. The decision path of the model predictions can then be interpreted by decomposing the learned decision trees. Our results show that our proposed framework achieves high predictive performance while being explainable.

</p>
</details>

<details><summary><b>GTrans: Spatiotemporal Autoregressive Transformer with Graph Embeddings for Nowcasting Extreme Events</b>
<a href="https://arxiv.org/abs/2201.06717">arxiv:2201.06717</a>
&#x1F4C8; 4 <br>
<p>Bo Feng, Geoffrey Fox</p></summary>
<p>

**Abstract:** Spatiotemporal time series nowcasting should preserve temporal and spatial dynamics in the sense that generated new sequences from models respect the covariance relationship from history. Conventional feature extractors are built with deep convolutional neural networks (CNN). However, CNN models have limits to image-like applications where data can be formed with high-dimensional arrays. In contrast, applications in social networks, road traffic, physics, and chemical property prediction where data features can be organized with nodes and edges of graphs. Transformer architecture is an emerging method for predictive models, bringing high accuracy and efficiency due to attention mechanism design. This paper proposes a spatiotemporal model, namely GTrans, that transforms data features into graph embeddings and predicts temporal dynamics with a transformer model. According to our experiments, we demonstrate that GTrans can model spatial and temporal dynamics and nowcasts extreme events for datasets. Furthermore, in all the experiments, GTrans can achieve the highest F1 and F2 scores in binary-class prediction tests than the baseline models.

</p>
</details>

<details><summary><b>Neural Computed Tomography</b>
<a href="https://arxiv.org/abs/2201.06574">arxiv:2201.06574</a>
&#x1F4C8; 4 <br>
<p>Kunal Gupta, Brendan Colvert, Francisco Contijoch</p></summary>
<p>

**Abstract:** Motion during acquisition of a set of projections can lead to significant motion artifacts in computed tomography reconstructions despite fast acquisition of individual views. In cases such as cardiac imaging, motion may be unavoidable and evaluating motion may be of clinical interest. Reconstructing images with reduced motion artifacts has typically been achieved by developing systems with faster gantry rotation or using algorithms which measure and/or estimate the displacements. However, these approaches have had limited success due to both physical constraints as well as the challenge of estimating/measuring non-rigid, temporally varying, and patient-specific motions. We propose a novel reconstruction framework, NeuralCT, to generate time-resolved images free from motion artifacts. Our approaches utilizes a neural implicit approach and does not require estimation or modeling of the underlying motion. Instead, boundaries are represented using a signed distance metric and neural implicit framework. We utilize `analysis-by-synthesis' to identify a solution consistent with the acquired sinogram as well as spatial and temporal consistency constraints. We illustrate the utility of NeuralCT in three progressively more complex scenarios: translation of a small circle, heartbeat-like change in an ellipse's diameter, and complex topological deformation. Without hyperparameter tuning or change to the architecture, NeuralCT provides high quality image reconstruction for all three motions, as compared to filtered backprojection, using mean-square-error and Dice metrics.

</p>
</details>

<details><summary><b>BDA-SketRet: Bi-Level Domain Adaptation for Zero-Shot SBIR</b>
<a href="https://arxiv.org/abs/2201.06570">arxiv:2201.06570</a>
&#x1F4C8; 4 <br>
<p>Ushasi Chaudhuri, Ruchika Chavan, Biplab Banerjee, Anjan Dutta, Zeynep Akata</p></summary>
<p>

**Abstract:** The efficacy of zero-shot sketch-based image retrieval (ZS-SBIR) models is governed by two challenges. The immense distributions-gap between the sketches and the images requires a proper domain alignment. Moreover, the fine-grained nature of the task and the high intra-class variance of many categories necessitates a class-wise discriminative mapping among the sketch, image, and the semantic spaces. Under this premise, we propose BDA-SketRet, a novel ZS-SBIR framework performing a bi-level domain adaptation for aligning the spatial and semantic features of the visual data pairs progressively. In order to highlight the shared features and reduce the effects of any sketch or image-specific artifacts, we propose a novel symmetric loss function based on the notion of information bottleneck for aligning the semantic features while a cross-entropy-based adversarial loss is introduced to align the spatial feature maps. Finally, our CNN-based model confirms the discriminativeness of the shared latent space through a novel topology-preserving semantic projection network. Experimental results on the extended Sketchy, TU-Berlin, and QuickDraw datasets exhibit sharp improvements over the literature.

</p>
</details>

<details><summary><b>Demographic Confounding Causes Extreme Instances of Lifestyle Politics on Facebook</b>
<a href="https://arxiv.org/abs/2201.06517">arxiv:2201.06517</a>
&#x1F4C8; 4 <br>
<p>Alexander Ruch, Yujia Zhang, Michael Macy</p></summary>
<p>

**Abstract:** Lifestyle politics emerge when activities that have no substantive relevance to ideology become politically aligned and polarized. Homophily and social influence are able generate these fault lines on their own; however, social identities from demographics may serve as coordinating mechanisms through which lifestyle politics are mobilized are spread. Using a dataset of 137,661,886 observations from 299,327 Facebook interests aggregated across users of different racial/ethnic, education, age, gender, and income demographics, we find that the most extreme instances of lifestyle politics are those which are highly confounded by demographics such as race/ethnicity (e.g., Black artists and performers). After adjusting political alignment for demographic effects, lifestyle politics decreased by 27.36% toward the political "center" and demographically confounded interests were no longer among the most polarized interests. Instead, after demographic deconfounding, we found that the most liberal interests included electric cars, Planned Parenthood, and liberal satire while the most conservative interests included the Republican Party and conservative commentators. We validate our measures of political alignment and lifestyle politics using the General Social Survey and find similar demographic entanglements with lifestyle politics existed before social media such as Facebook were ubiquitous, giving us strong confidence that our results are not due to echo chambers or filter bubbles. Likewise, since demographic characteristics exist prior to ideological values, we argue that the demographic confounding we observe is causally responsible for the extreme instances of lifestyle politics that we find among the aggregated interests. We conclude our paper by relating our results to Simpson's paradox, cultural omnivorousness, and network autocorrelation.

</p>
</details>

<details><summary><b>Distortion-Aware Brushing for Interactive Cluster Analysis in Multidimensional Projections</b>
<a href="https://arxiv.org/abs/2201.06379">arxiv:2201.06379</a>
&#x1F4C8; 4 <br>
<p>Hyeon Jeon, Michael Aupetit, Soohyun Lee, Hyung-Kwon Ko, Youngtaek Kim, Jinwook Seo</p></summary>
<p>

**Abstract:** Brushing is an everyday interaction in 2D scatterplots, which allows users to select and filter data points within a continuous, enclosed region and conduct further analysis on the points. However, such conventional brushing cannot be directly applied to Multidimensional Projections (MDP), as they hardly escape from False and Missing Neighbors distortions that make the relative positions of the points unreliable. To alleviate this problem, we introduce Distortion-aware brushing, a novel brushing technique for MDP. While users perform brushing, Distortion-aware brushing resolves distortions around currently brushed points by dynamically relocating points in the projection; the points whose data are close to the brushed data in the multidimensional (MD) space go near the corresponding brushed points in the projection, and the opposites move away. Hence, users can overcome distortions and readily extract out clustered data in the MD space using the technique. We demonstrate the effectiveness and applicability of Distortion-aware brushing through usage scenarios with two datasets. Finally, by conducting user studies with 30 participants, we verified that Distortion-aware brushing significantly outperforms previous brushing techniques in precisely separating clusters in the MD space, and works robustly regardless of the types or the amount of distortions in MDP.

</p>
</details>

<details><summary><b>Homogenization of Existing Inertial-Based Datasets to Support Human Activity Recognition</b>
<a href="https://arxiv.org/abs/2201.07891">arxiv:2201.07891</a>
&#x1F4C8; 3 <br>
<p>Hamza Amrani, Daniela Micucci, Marco Mobilio, Paolo Napoletano</p></summary>
<p>

**Abstract:** Several techniques have been proposed to address the problem of recognizing activities of daily living from signals. Deep learning techniques applied to inertial signals have proven to be effective, achieving significant classification accuracy. Recently, research in human activity recognition (HAR) models has been almost totally model-centric. It has been proven that the number of training samples and their quality are critical for obtaining deep learning models that both perform well independently of their architecture, and that are more robust to intraclass variability and interclass similarity. Unfortunately, publicly available datasets do not always contain hight quality data and a sufficiently large and diverse number of samples (e.g., number of subjects, type of activity performed, and duration of trials). Furthermore, datasets are heterogeneous among them and therefore cannot be trivially combined to obtain a larger set. The final aim of our work is the definition and implementation of a platform that integrates datasets of inertial signals in order to make available to the scientific community large datasets of homogeneous signals, enriched, when possible, with context information (e.g., characteristics of the subjects and device position). The main focus of our platform is to emphasise data quality, which is essential for training efficient models.

</p>
</details>

<details><summary><b>Convolutional Neural Networks for Spherical Signal Processing via Spherical Haar Tight Framelets</b>
<a href="https://arxiv.org/abs/2201.07890">arxiv:2201.07890</a>
&#x1F4C8; 3 <br>
<p>Jianfei Li, Han Feng, Xiaosheng Zhuang</p></summary>
<p>

**Abstract:** In this paper, we develop a general theoretical framework for constructing Haar-type tight framelets on any compact set with a hierarchical partition. In particular, we construct a novel area-regular hierarchical partition on the 2-sphere and establish its corresponding spherical Haar tight framelets with directionality. We conclude by evaluating and illustrating the effectiveness of our area-regular spherical Haar tight framelets in several denoising experiments. Furthermore, we propose a convolutional neural network (CNN) model for spherical signal denoising which employs the fast framelet decomposition and reconstruction algorithms. Experiment results show that our proposed CNN model outperforms threshold methods, and processes strong generalization and robustness properties.

</p>
</details>

<details><summary><b>Dialog Intent Induction via Density-based Deep Clustering Ensemble</b>
<a href="https://arxiv.org/abs/2201.06731">arxiv:2201.06731</a>
&#x1F4C8; 3 <br>
<p>Jiashu Pu, Guandan Chen, Yongzhu Chang, Xiaoxi Mao</p></summary>
<p>

**Abstract:** Existing task-oriented chatbots heavily rely on spoken language understanding (SLU) systems to determine a user's utterance's intent and other key information for fulfilling specific tasks. In real-life applications, it is crucial to occasionally induce novel dialog intents from the conversation logs to improve the user experience. In this paper, we propose the Density-based Deep Clustering Ensemble (DDCE) method for dialog intent induction. Compared to existing K-means based methods, our proposed method is more effective in dealing with real-life scenarios where a large number of outliers exist. To maximize data utilization, we jointly optimize texts' representations and the hyperparameters of the clustering algorithm. In addition, we design an outlier-aware clustering ensemble framework to handle the overfitting issue. Experimental results over seven datasets show that our proposed method significantly outperforms other state-of-the-art baselines.

</p>
</details>

<details><summary><b>OmniPrint: A Configurable Printed Character Synthesizer</b>
<a href="https://arxiv.org/abs/2201.06648">arxiv:2201.06648</a>
&#x1F4C8; 3 <br>
<p>Haozhe Sun, Wei-Wei Tu, Isabelle Guyon</p></summary>
<p>

**Abstract:** We introduce OmniPrint, a synthetic data generator of isolated printed characters, geared toward machine learning research. It draws inspiration from famous datasets such as MNIST, SVHN and Omniglot, but offers the capability of generating a wide variety of printed characters from various languages, fonts and styles, with customized distortions. We include 935 fonts from 27 scripts and many types of distortions. As a proof of concept, we show various use cases, including an example of meta-learning dataset designed for the upcoming MetaDL NeurIPS 2021 competition. OmniPrint is available at https://github.com/SunHaozhe/OmniPrint.

</p>
</details>

<details><summary><b>Chaining Value Functions for Off-Policy Learning</b>
<a href="https://arxiv.org/abs/2201.06468">arxiv:2201.06468</a>
&#x1F4C8; 3 <br>
<p>Simon Schmitt, John Shawe-Taylor, Hado van Hasselt</p></summary>
<p>

**Abstract:** To accumulate knowledge and improve its policy of behaviour, a reinforcement learning agent can learn `off-policy' about policies that differ from the policy used to generate its experience. This is important to learn counterfactuals, or because the experience was generated out of its own control. However, off-policy learning is non-trivial, and standard reinforcement-learning algorithms can be unstable and divergent.
  In this paper we discuss a novel family of off-policy prediction algorithms which are convergent by construction. The idea is to first learn on-policy about the data-generating behaviour, and then bootstrap an off-policy value estimate on this on-policy estimate, thereby constructing a value estimate that is partially off-policy. This process can be repeated to build a chain of value functions, each time bootstrapping a new estimate on the previous estimate in the chain. Each step in the chain is stable and hence the complete algorithm is guaranteed to be stable. Under mild conditions this comes arbitrarily close to the off-policy TD solution when we increase the length of the chain. Hence it can compute the solution even in cases where off-policy TD diverges.
  We prove that the proposed scheme is convergent and corresponds to an iterative decomposition of the inverse key matrix. Furthermore it can be interpreted as estimating a novel objective -- that we call a `k-step expedition' -- of following the target policy for finitely many steps before continuing indefinitely with the behaviour policy. Empirically we evaluate the idea on challenging MDPs such as Baird's counter example and observe favourable results.

</p>
</details>

<details><summary><b>Bayesian Calibration of imperfect computer models using Physics-informed priors</b>
<a href="https://arxiv.org/abs/2201.06463">arxiv:2201.06463</a>
&#x1F4C8; 3 <br>
<p>Michail Spitieris, Ingelin Steinsland</p></summary>
<p>

**Abstract:** In this work we introduce a computational efficient data-driven framework suitable for quantifying the uncertainty in physical parameters of computer models, represented by differential equations. We construct physics-informed priors for differential equations, which are multi-output Gaussian process (GP) priors that encode the model's structure in the covariance function. We extend this into a fully Bayesian framework which allows quantifying the uncertainty of physical parameters and model predictions. Since physical models are usually imperfect descriptions of the real process, we allow the model to deviate from the observed data by considering a discrepancy function. For inference Hamiltonian Monte Carlo (HMC) sampling is used. This work is motivated by the need for interpretable parameters for the hemodynamics of the heart for personal treatment of hypertension. The model used is the arterial Windkessel model, which represents the hemodynamics of the heart through differential equations with physically interpretable parameters of medical interest. As most physical models, the Windkessel model is an imperfect description of the real process. To demonstrate our approach we simulate noisy data from a more complex physical model with known mathematical connections to our modeling choice. We show that without accounting for discrepancy, the posterior of the physical parameters deviates from the true value while when accounting for discrepancy gives reasonable quantification of physical parameters uncertainty and reduces the uncertainty in subsequent model predictions.

</p>
</details>

<details><summary><b>Lifelong Generative Learning via Knowledge Reconstruction</b>
<a href="https://arxiv.org/abs/2201.06418">arxiv:2201.06418</a>
&#x1F4C8; 3 <br>
<p>Libo Huang, Zhulin An, Xiang Zhi, Yongjun Xu</p></summary>
<p>

**Abstract:** Generative models often incur the catastrophic forgetting problem when they are used to sequentially learning multiple tasks, i.e., lifelong generative learning. Although there are some endeavors to tackle this problem, they suffer from high time-consumptions or error accumulation. In this work, we develop an efficient and effective lifelong generative model based on variational autoencoder (VAE). Unlike the generative adversarial network, VAE enjoys high efficiency in the training process, providing natural benefits with few resources. We deduce a lifelong generative model by expending the intrinsic reconstruction character of VAE to the historical knowledge retention. Further, we devise a feedback strategy about the reconstructed data to alleviate the error accumulation. Experiments on the lifelong generating tasks of MNIST, FashionMNIST, and SVHN verified the efficacy of our approach, where the results were comparable to SOTA.

</p>
</details>

<details><summary><b>Efficient Data-Plane Memory Scheduling for In-Network Aggregation</b>
<a href="https://arxiv.org/abs/2201.06398">arxiv:2201.06398</a>
&#x1F4C8; 3 <br>
<p>Hao Wang, Yuxuan Qin, ChonLam Lao, Yanfang Le, Wenfei Wu, Kai Chen</p></summary>
<p>

**Abstract:** As the scale of distributed training grows, communication becomes a bottleneck. To accelerate the communication, recent works introduce In-Network Aggregation (INA), which moves the gradients summation into network middle-boxes, e.g., programmable switches to reduce the traffic volume. However, switch memory is scarce compared to the volume of gradients transmitted in distributed training. Although literature applies methods like pool-based streaming or dynamic sharing to tackle the mismatch, switch memory is still a potential performance bottleneck. Furthermore, we observe the under-utilization of switch memory due to the synchronization requirement for aggregator deallocation in recent works. To improve the switch memory utilization, we propose ESA, an $\underline{E}$fficient Switch Memory $\underline{S}$cheduler for In-Network $\underline{A}$ggregation. At its cores, ESA enforces the preemptive aggregator allocation primitive and introduces priority scheduling at the data-plane, which improves the switch memory utilization and average job completion time (JCT). Experiments show that ESA can improve the average JCT by up to $1.35\times$.

</p>
</details>

<details><summary><b>Few-shot image segmentation for cross-institution male pelvic organs using registration-assisted prototypical learning</b>
<a href="https://arxiv.org/abs/2201.06358">arxiv:2201.06358</a>
&#x1F4C8; 3 <br>
<p>Yiwen Li, Yunguan Fu, Qianye Yang, Zhe Min, Wen Yan, Henkjan Huisman, Dean Barratt, Victor Adrian Prisacariu, Yipeng Hu</p></summary>
<p>

**Abstract:** The ability to adapt medical image segmentation networks for a novel class such as an unseen anatomical or pathological structure, when only a few labelled examples of this class are available from local healthcare providers, is sought-after. This potentially addresses two widely recognised limitations in deploying modern deep learning models to clinical practice, expertise-and-labour-intensive labelling and cross-institution generalisation. This work presents the first 3D few-shot interclass segmentation network for medical images, using a labelled multi-institution dataset from prostate cancer patients with eight regions of interest. We propose an image alignment module registering the predicted segmentation of both query and support data, in a standard prototypical learning algorithm, to a reference atlas space. The built-in registration mechanism can effectively utilise the prior knowledge of consistent anatomy between subjects, regardless whether they are from the same institution or not. Experimental results demonstrated that the proposed registration-assisted prototypical learning significantly improved segmentation accuracy (p-values<0.01) on query data from a holdout institution, with varying availability of support data from multiple institutions. We also report the additional benefits of the proposed 3D networks with 75% fewer parameters and an arguably simpler implementation, compared with existing 2D few-shot approaches that segment 2D slices of volumetric medical images.

</p>
</details>

<details><summary><b>Chatbot System Architecture</b>
<a href="https://arxiv.org/abs/2201.06348">arxiv:2201.06348</a>
&#x1F4C8; 3 <br>
<p>Moataz Mohammed, Mostafa M. Aref</p></summary>
<p>

**Abstract:** The conversational agents is one of the most interested topics in computer science field in the recent decade. Which can be composite from more than one subject in this field, which you need to apply Natural Language Processing Concepts and some Artificial Intelligence Techniques such as Deep Learning methods to make decision about how should be the response. This paper is dedicated to discuss the system architecture for the conversational agent and explain each component in details.

</p>
</details>

<details><summary><b>Transfer Learning in Quantum Parametric Classifiers: An Information-Theoretic Generalization Analysis</b>
<a href="https://arxiv.org/abs/2201.06297">arxiv:2201.06297</a>
&#x1F4C8; 3 <br>
<p>Sharu Theresa Jose, Osvaldo Simeone</p></summary>
<p>

**Abstract:** A key step in quantum machine learning with classical inputs is the design of an embedding circuit mapping inputs to a quantum state. This paper studies a transfer learning setting in which classical-to-quantum embedding is carried out by an arbitrary parametric quantum circuit that is pre-trained based on data from a source task. At run time, the binary classifier is then optimized based on data from the target task of interest. Using an information-theoretic approach, we demonstrate that the average excess risk, or optimality gap, can be bounded in terms of two Rényi mutual information terms between classical input and quantum embedding under source and target tasks, as well as in terms of a measure of similarity between the source and target tasks related to the trace distance. The main theoretical results are validated on a simple binary classification example.

</p>
</details>

<details><summary><b>Efficient DNN Training with Knowledge-Guided Layer Freezing</b>
<a href="https://arxiv.org/abs/2201.06227">arxiv:2201.06227</a>
&#x1F4C8; 3 <br>
<p>Yiding Wang, Decang Sun, Kai Chen, Fan Lai, Mosharaf Chowdhury</p></summary>
<p>

**Abstract:** Training deep neural networks (DNNs) is time-consuming. While most existing solutions try to overlap/schedule computation and communication for efficient training, this paper goes one step further by skipping computing and communication through DNN layer freezing. Our key insight is that the training progress of internal DNN layers differs significantly, and front layers often become well-trained much earlier than deep layers. To explore this, we first introduce the notion of training plasticity to quantify the training progress of internal DNN layers. Then we design KGT, a knowledge-guided DNN training system that employs semantic knowledge from a reference model to accurately evaluate individual layers' training plasticity and safely freeze the converged ones, saving their corresponding backward computation and communication. Our reference model is generated on the fly using quantization techniques and runs forward operations asynchronously on available CPUs to minimize the overhead. In addition, KGT caches the intermediate outputs of the frozen layers with prefetching to further skip the forward computation. Our implementation and testbed experiments with popular vision and language models show that KGT achieves 19%-43% training speedup w.r.t. the state-of-the-art without sacrificing accuracy.

</p>
</details>

<details><summary><b>Unintended Bias in Language Model-driven Conversational Recommendation</b>
<a href="https://arxiv.org/abs/2201.06224">arxiv:2201.06224</a>
&#x1F4C8; 3 <br>
<p>Tianshu Shen, Jiaru Li, Mohamed Reda Bouadjenek, Zheda Mai, Scott Sanner</p></summary>
<p>

**Abstract:** Conversational Recommendation Systems (CRSs) have recently started to leverage pretrained language models (LM) such as BERT for their ability to semantically interpret a wide range of preference statement variations. However, pretrained LMs are well-known to be prone to intrinsic biases in their training data, which may be exacerbated by biases embedded in domain-specific language data(e.g., user reviews) used to fine-tune LMs for CRSs. We study a recently introduced LM-driven recommendation backbone (termed LMRec) of a CRS to investigate how unintended bias i.e., language variations such as name references or indirect indicators of sexual orientation or location that should not affect recommendations manifests in significantly shifted price and category distributions of restaurant recommendations. The alarming results we observe strongly indicate that LMRec has learned to reinforce harmful stereotypes through its recommendations. For example, offhand mention of names associated with the black community significantly lowers the price distribution of recommended restaurants, while offhand mentions of common male-associated names lead to an increase in recommended alcohol-serving establishments. These and many related results presented in this work raise a red flag that advances in the language handling capability of LM-drivenCRSs do not come without significant challenges related to mitigating unintended bias in future deployed CRS assistants with a potential reach of hundreds of millions of end-users.

</p>
</details>

<details><summary><b>Learning to Reformulate for Linear Programming</b>
<a href="https://arxiv.org/abs/2201.06216">arxiv:2201.06216</a>
&#x1F4C8; 3 <br>
<p>Xijun Li, Qingyu Qu, Fangzhou Zhu, Jia Zeng, Mingxuan Yuan, Kun Mao, Jie Wang</p></summary>
<p>

**Abstract:** It has been verified that the linear programming (LP) is able to formulate many real-life optimization problems, which can obtain the optimum by resorting to corresponding solvers such as OptVerse, Gurobi and CPLEX. In the past decades, a serial of traditional operation research algorithms have been proposed to obtain the optimum of a given LP in a fewer solving time. Recently, there is a trend of using machine learning (ML) techniques to improve the performance of above solvers. However, almost no previous work takes advantage of ML techniques to improve the performance of solver from the front end, i.e., the modeling (or formulation). In this paper, we are the first to propose a reinforcement learning-based reformulation method for LP to improve the performance of solving process. Using an open-source solver COIN-OR LP (CLP) as an environment, we implement the proposed method over two public research LP datasets and one large-scale LP dataset collected from practical production planning scenario. The evaluation results suggest that the proposed method can effectively reduce both the solving iteration number ($25\%\downarrow$) and the solving time ($15\%\downarrow$) over above datasets in average, compared to directly solving the original LP instances.

</p>
</details>

<details><summary><b>NSGZero: Efficiently Learning Non-Exploitable Policy in Large-Scale Network Security Games with Neural Monte Carlo Tree Search</b>
<a href="https://arxiv.org/abs/2201.07224">arxiv:2201.07224</a>
&#x1F4C8; 2 <br>
<p>Wanqi Xue, Bo An, Chai Kiat Yeo</p></summary>
<p>

**Abstract:** How resources are deployed to secure critical targets in networks can be modelled by Network Security Games (NSGs). While recent advances in deep learning (DL) provide a powerful approach to dealing with large-scale NSGs, DL methods such as NSG-NFSP suffer from the problem of data inefficiency. Furthermore, due to centralized control, they cannot scale to scenarios with a large number of resources. In this paper, we propose a novel DL-based method, NSGZero, to learn a non-exploitable policy in NSGs. NSGZero improves data efficiency by performing planning with neural Monte Carlo Tree Search (MCTS). Our main contributions are threefold. First, we design deep neural networks (DNNs) to perform neural MCTS in NSGs. Second, we enable neural MCTS with decentralized control, making NSGZero applicable to NSGs with many resources. Third, we provide an efficient learning paradigm, to achieve joint training of the DNNs in NSGZero. Compared to state-of-the-art algorithms, our method achieves significantly better data efficiency and scalability.

</p>
</details>

<details><summary><b>Convolutional Cobweb: A Model of Incremental Learning from 2D Images</b>
<a href="https://arxiv.org/abs/2201.06740">arxiv:2201.06740</a>
&#x1F4C8; 2 <br>
<p>Christopher J. MacLellan, Harshil Thakur</p></summary>
<p>

**Abstract:** This paper presents a new concept formation approach that supports the ability to incrementally learn and predict labels for visual images. This work integrates the idea of convolutional image processing, from computer vision research, with a concept formation approach that is based on psychological studies of how humans incrementally form and use concepts. We experimentally evaluate this new approach by applying it to an incremental variation of the MNIST digit recognition task. We compare its performance to Cobweb, a concept formation approach that does not support convolutional processing, as well as two convolutional neural networks that vary in the complexity of their convolutional processing. This work represents a first step towards unifying modern computer vision ideas with classical concept formation research.

</p>
</details>

<details><summary><b>Design Space Exploration of Dense and Sparse Mapping Schemes for RRAM Architectures</b>
<a href="https://arxiv.org/abs/2201.06703">arxiv:2201.06703</a>
&#x1F4C8; 2 <br>
<p>Corey Lammie, Jason K. Eshraghian, Chenqi Li, Amirali Amirsoleimani, Roman Genov, Wei D. Lu, Mostafa Rahimi Azghadi</p></summary>
<p>

**Abstract:** The impact of device and circuit-level effects in mixed-signal Resistive Random Access Memory (RRAM) accelerators typically manifest as performance degradation of Deep Learning (DL) algorithms, but the degree of impact varies based on algorithmic features. These include network architecture, capacity, weight distribution, and the type of inter-layer connections. Techniques are continuously emerging to efficiently train sparse neural networks, which may have activation sparsity, quantization, and memristive noise. In this paper, we present an extended Design Space Exploration (DSE) methodology to quantify the benefits and limitations of dense and sparse mapping schemes for a variety of network architectures. While sparsity of connectivity promotes less power consumption and is often optimized for extracting localized features, its performance on tiled RRAM arrays may be more susceptible to noise due to under-parameterization, when compared to dense mapping schemes. Moreover, we present a case study quantifying and formalizing the trade-offs of typical non-idealities introduced into 1-Transistor-1-Resistor (1T1R) tiled memristive architectures and the size of modular crossbar tiles using the CIFAR-10 dataset.

</p>
</details>

<details><summary><b>Data-Centric Machine Learning in the Legal Domain</b>
<a href="https://arxiv.org/abs/2201.06653">arxiv:2201.06653</a>
&#x1F4C8; 2 <br>
<p>Hannes Westermann, Jaromir Savelka, Vern R. Walker, Kevin D. Ashley, Karim Benyekhlef</p></summary>
<p>

**Abstract:** Machine learning research typically starts with a fixed data set created early in the process. The focus of the experiments is finding a model and training procedure that result in the best possible performance in terms of some selected evaluation metric. This paper explores how changes in a data set influence the measured performance of a model. Using three publicly available data sets from the legal domain, we investigate how changes to their size, the train/test splits, and the human labelling accuracy impact the performance of a trained deep learning classifier. We assess the overall performance (weighted average) as well as the per-class performance. The observed effects are surprisingly pronounced, especially when the per-class performance is considered. We investigate how "semantic homogeneity" of a class, i.e., the proximity of sentences in a semantic embedding space, influences the difficulty of its classification. The presented results have far reaching implications for efforts related to data collection and curation in the field of AI & Law. The results also indicate that enhancements to a data set could be considered, alongside the advancement of the ML models, as an additional path for increasing classification performance on various tasks in AI & Law. Finally, we discuss the need for an established methodology to assess the potential effects of data set properties.

</p>
</details>

<details><summary><b>Equitable Community Resilience: The Case of Winter Storm Uri in Texas</b>
<a href="https://arxiv.org/abs/2201.06652">arxiv:2201.06652</a>
&#x1F4C8; 2 <br>
<p>Ali Nejat, Laura Solitare, Edward Pettitt, Hamed Mohsenian-Rad</p></summary>
<p>

**Abstract:** Community resilience in the face of natural hazards relies on a community's potential to bounce back. A failure to integrate equity into resilience considerations results in unequal recovery and disproportionate impacts on vulnerable populations, which has long been a concern in the United States. This research investigated aspects of equity related to community resilience in the aftermath of Winter Storm Uri in Texas which led to extended power outages for more than 4 million households. County level outage and recovery data was analyzed to explore potential significant links between various county attributes and their share of the outages during the recovery and restoration phases. Next, satellite imagery was used to examine data at a much higher geographical resolution focusing on census tracts in the city of Houston. The goal was to use computer vision to extract the extent of outages within census tracts and investigate their linkages to census tracts attributes. Results from various statistical procedures revealed statistically significant negative associations between counties' percentage of non-Hispanic whites and median household income with the ratio of outages. Additionally, at census tract level, variables including percentages of linguistically isolated population and public transport users exhibited positive associations with the group of census tracts that were affected by the outage as detected by computer vision analysis. Informed by these results, engineering solutions such as the applicability of grid modernization technologies, together with distributed and renewable energy resources, when controlled for the region's topographical characteristics, are proposed to enhance equitable power grid resiliency in the face of natural hazards.

</p>
</details>

<details><summary><b>Using Machine Learning to Detect Rotational Symmetries from Reflectional Symmetries in 2D Images</b>
<a href="https://arxiv.org/abs/2201.06594">arxiv:2201.06594</a>
&#x1F4C8; 2 <br>
<p>Koen Ponse, Anna V. Kononova, Maria Loleyt, Bas van Stein</p></summary>
<p>

**Abstract:** Automated symmetry detection is still a difficult task in 2021. However, it has applications in computer vision, and it also plays an important part in understanding art. This paper focuses on aiding the latter by comparing different state-of-the-art automated symmetry detection algorithms. For one of such algorithms aimed at reflectional symmetries, we propose post-processing improvements to find localised symmetries in images, improve the selection of detected symmetries and identify another symmetry type (rotational). In order to detect rotational symmetries, we contribute a machine learning model which detects rotational symmetries based on provided reflection symmetry axis pairs. We demonstrate and analyze the performance of the extended algorithm to detect localised symmetries and the machine learning model to classify rotational symmetries.

</p>
</details>

<details><summary><b>PerPaDa: A Persian Paraphrase Dataset based on Implicit Crowdsourcing Data Collection</b>
<a href="https://arxiv.org/abs/2201.06573">arxiv:2201.06573</a>
&#x1F4C8; 2 <br>
<p>Salar Mohtaj, Fatemeh Tavakkoli, Habibollah Asghari</p></summary>
<p>

**Abstract:** In this paper we introduce PerPaDa, a Persian paraphrase dataset that is collected from users' input in a plagiarism detection system. As an implicit crowdsourcing experience, we have gathered a large collection of original and paraphrased sentences from Hamtajoo; a Persian plagiarism detection system, in which users try to conceal cases of text re-use in their documents by paraphrasing and re-submitting manuscripts for analysis. The compiled dataset contains 2446 instances of paraphrasing. In order to improve the overall quality of the collected data, some heuristics have been used to exclude sentences that don't meet the proposed criteria. The introduced corpus is much larger than the available datasets for the task of paraphrase identification in Persian. Moreover, there is less bias in the data compared to the similar datasets, since the users did not try some fixed predefined rules in order to generate similar texts to their original inputs.

</p>
</details>

<details><summary><b>Spatiotemporal Costmap Inference for MPC via Deep Inverse Reinforcement Learning</b>
<a href="https://arxiv.org/abs/2201.06539">arxiv:2201.06539</a>
&#x1F4C8; 2 <br>
<p>Keuntaek Lee, David Isele, Evangelos A. Theodorou, Sangjae Bae</p></summary>
<p>

**Abstract:** It can be difficult to autonomously produce driver behavior so that it appears natural to other traffic participants. Through Inverse Reinforcement Learning (IRL), we can automate this process by learning the underlying reward function from human demonstrations. We propose a new IRL algorithm that learns a goal-conditioned spatiotemporal reward function. The resulting costmap is used by Model Predictive Controllers (MPCs) to perform a task without any hand-designing or hand-tuning of the cost function. We evaluate our proposed Goal-conditioned SpatioTemporal Zeroing Maximum Entropy Deep IRL (GSTZ)-MEDIRL framework together with MPC in the CARLA simulator for autonomous driving, lane keeping, and lane changing tasks in a challenging dense traffic highway scenario. Our proposed methods show higher success rates compared to other baseline methods including behavior cloning, state-of-the-art RL policies, and MPC with a learning-based behavior prediction model.

</p>
</details>

<details><summary><b>Patterns of near-crash events in a naturalistic driving dataset: applying rules mining</b>
<a href="https://arxiv.org/abs/2201.06523">arxiv:2201.06523</a>
&#x1F4C8; 2 <br>
<p>Xiaoqiang Kong, Subasish Das, Hongmin Zhou, Yunlong Zhang</p></summary>
<p>

**Abstract:** This study aims to explore the associations between near-crash events and road geometry and trip features by investigating a naturalistic driving dataset and a corresponding roadway inventory dataset using an association rule mining method.

</p>
</details>

<details><summary><b>Growing Neural Network with Shared Parameter</b>
<a href="https://arxiv.org/abs/2201.06500">arxiv:2201.06500</a>
&#x1F4C8; 2 <br>
<p>Ruilin Tong</p></summary>
<p>

**Abstract:** We propose a general method for growing neural network with shared parameter by matching trained network to new input. By leveraging Hoeffding's inequality, we provide a theoretical base for improving performance by adding subnetwork to existing network. With the theoretical base of adding new subnetwork, we implement a matching method to apply trained subnetwork of existing network to new input. Our method has shown the ability to improve performance with higher parameter efficiency. It can also be applied to trans-task case and realize transfer learning by changing the combination of subnetworks without training on new task.

</p>
</details>

<details><summary><b>RuMedBench: A Russian Medical Language Understanding Benchmark</b>
<a href="https://arxiv.org/abs/2201.06499">arxiv:2201.06499</a>
&#x1F4C8; 2 <br>
<p>Pavel Blinov, Arina Reshetnikova, Aleksandr Nesterov, Galina Zubkova, Vladimir Kokh</p></summary>
<p>

**Abstract:** The paper describes the open Russian medical language understanding benchmark covering several task types (classification, question answering, natural language inference, named entity recognition) on a number of novel text sets. Given the sensitive nature of the data in healthcare, such a benchmark partially closes the problem of Russian medical dataset absence. We prepare the unified format labeling, data split, and evaluation metrics for new tasks. The remaining tasks are from existing datasets with a few modifications. A single-number metric expresses a model's ability to cope with the benchmark. Moreover, we implement several baseline models, from simple ones to neural networks with transformer architecture, and release the code. Expectedly, the more advanced models yield better performance, but even a simple model is enough for a decent result in some tasks. Furthermore, for all tasks, we provide a human evaluation. Interestingly the models outperform humans in the large-scale classification tasks. However, the advantage of natural intelligence remains in the tasks requiring more knowledge and reasoning.

</p>
</details>

<details><summary><b>Using machine learning to parametrize postmerger signals from binary neutron stars</b>
<a href="https://arxiv.org/abs/2201.06461">arxiv:2201.06461</a>
&#x1F4C8; 2 <br>
<p>Tim Whittaker, William E. East, Stephen R. Green, Luis Lehner, Huan Yang</p></summary>
<p>

**Abstract:** There is growing interest in the detection and characterization of gravitational waves from postmerger oscillations of binary neutron stars. These signals contain information about the nature of the remnant and the high-density and out-of-equilibrium physics of the postmerger processes, which would complement any electromagnetic signal. However, the construction of binary neutron star postmerger waveforms is much more complicated than for binary black holes: (i) there are theoretical uncertainties in the neutron-star equation of state and other aspects of the high-density physics, (ii) numerical simulations are expensive and available ones only cover a small fraction of the parameter space with limited numerical accuracy, and (iii) it is unclear how to parametrize the theoretical uncertainties and interpolate across parameter space. In this work, we describe the use of a machine-learning method called a conditional variational autoencoder (CVAE) to construct postmerger models for hyper/massive neutron star remnant signals based on numerical-relativity simulations. The CVAE provides a probabilistic model, which encodes uncertainties in the training data within a set of latent parameters. We estimate that training such a model will ultimately require $\sim 10^4$ waveforms. However, using synthetic training waveforms as a proof-of-principle, we show that the CVAE can be used as an accurate generative model and that it encodes the equation of state in a useful latent representation.

</p>
</details>

<details><summary><b>Black-box error diagnosis in deep neural networks: a survey of tools</b>
<a href="https://arxiv.org/abs/2201.06444">arxiv:2201.06444</a>
&#x1F4C8; 2 <br>
<p>Piero Fraternali, Federico Milani, Rocio Nahime Torres, Niccolò Zangrando</p></summary>
<p>

**Abstract:** The application of Deep Neural Networks (DNNs) to a broad variety of tasks demands methods for coping with the complex and opaque nature of these architectures. The analysis of performance can be pursued in two ways. On one side, model interpretation techniques aim at "opening the box" to assess the relationship between the input, the inner layers, and the output. For example, saliency and attention models exploit knowledge of the architecture to capture the essential regions of the input that have the most impact on the inference process and output. On the other hand, models can be analysed as "black boxes", e.g., by associating the input samples with extra annotations that do not contribute to model training but can be exploited for characterizing the model response. Such performance-driven meta-annotations enable the detailed characterization of performance metrics and errors and help scientists identify the features of the input responsible for prediction failures and focus their model improvement efforts. This paper presents a structured survey of the tools that support the "black box" analysis of DNNs and discusses the gaps in the current proposals and the relevant future directions in this research field.

</p>
</details>

<details><summary><b>Dual Perceptual Loss for Single Image Super-Resolution Using ESRGAN</b>
<a href="https://arxiv.org/abs/2201.06383">arxiv:2201.06383</a>
&#x1F4C8; 2 <br>
<p>Jie Song, Huawei Yi, Wenqian Xu, Xiaohui Li, Bo Li, Yuanyuan Liu</p></summary>
<p>

**Abstract:** The proposal of perceptual loss solves the problem that per-pixel difference loss function causes the reconstructed image to be overly-smooth, which acquires a significant progress in the field of single image super-resolution reconstruction. Furthermore, the generative adversarial networks (GAN) is applied to the super-resolution field, which effectively improves the visual quality of the reconstructed image. However, under the condtion of high upscaling factors, the excessive abnormal reasoning of the network produces some distorted structures, so that there is a certain deviation between the reconstructed image and the ground-truth image. In order to fundamentally improve the quality of reconstructed images, this paper proposes a effective method called Dual Perceptual Loss (DP Loss), which is used to replace the original perceptual loss to solve the problem of single image super-resolution reconstruction. Due to the complementary property between the VGG features and the ResNet features, the proposed DP Loss considers the advantages of learning two features simultaneously, which significantly improves the reconstruction effect of images. The qualitative and quantitative analysis on benchmark datasets demonstrates the superiority of our proposed method over state-of-the-art super-resolution methods.

</p>
</details>

<details><summary><b>Fair Group-Shared Representations with Normalizing Flows</b>
<a href="https://arxiv.org/abs/2201.06336">arxiv:2201.06336</a>
&#x1F4C8; 2 <br>
<p>Mattia Cerrato, Marius Köppel, Alexander Segner, Stefan Kramer</p></summary>
<p>

**Abstract:** The issue of fairness in machine learning stems from the fact that historical data often displays biases against specific groups of people which have been underprivileged in the recent past, or still are. In this context, one of the possible approaches is to employ fair representation learning algorithms which are able to remove biases from data, making groups statistically indistinguishable. In this paper, we instead develop a fair representation learning algorithm which is able to map individuals belonging to different groups in a single group. This is made possible by training a pair of Normalizing Flow models and constraining them to not remove information about the ground truth by training a ranking or classification model on top of them. The overall, ``chained'' model is invertible and has a tractable Jacobian, which allows to relate together the probability densities for different groups and ``translate'' individuals from one group to another. We show experimentally that our methodology is competitive with other fair representation learning algorithms. Furthermore, our algorithm achieves stronger invariance w.r.t. the sensitive attribute.

</p>
</details>

<details><summary><b>Landscape of Neural Architecture Search across sensors: how much do they differ ?</b>
<a href="https://arxiv.org/abs/2201.06321">arxiv:2201.06321</a>
&#x1F4C8; 2 <br>
<p>Kalifou René Traoré, Andrés Camero, Xiao Xiang Zhu</p></summary>
<p>

**Abstract:** With the rapid rise of neural architecture search, the ability to understand its complexity from the perspective of a search algorithm is desirable. Recently, Traoré et al. have proposed the framework of Fitness Landscape Footprint to help describe and compare neural architecture search problems. It attempts at describing why a search strategy might be successful, struggle or fail on a target task. Our study leverages this methodology in the context of searching across sensors, including sensor data fusion. In particular, we apply the Fitness Landscape Footprint to the real-world image classification problem of So2Sat LCZ42, in order to identify the most beneficial sensor to our neural network hyper-parameter optimization problem. From the perspective of distributions of fitness, our findings indicate a similar behaviour of the search space for all sensors: the longer the training time, the larger the overall fitness, and more flatness in the landscapes (less ruggedness and deviation). Regarding sensors, the better the fitness they enable (Sentinel-2), the better the search trajectories (smoother, higher persistence). Results also indicate very similar search behaviour for sensors that can be decently fitted by the search space (Sentinel-2 and fusion).

</p>
</details>

<details><summary><b>MuLVE, A Multi-Language Vocabulary Evaluation Data Set</b>
<a href="https://arxiv.org/abs/2201.06286">arxiv:2201.06286</a>
&#x1F4C8; 2 <br>
<p>Anik Jacobsen, Salar Mohtaj, Sebastian Möller</p></summary>
<p>

**Abstract:** Vocabulary learning is vital to foreign language learning. Correct and adequate feedback is essential to successful and satisfying vocabulary training. However, many vocabulary and language evaluation systems perform on simple rules and do not account for real-life user learning data. This work introduces Multi-Language Vocabulary Evaluation Data Set (MuLVE), a data set consisting of vocabulary cards and real-life user answers, labeled indicating whether the user answer is correct or incorrect. The data source is user learning data from the Phase6 vocabulary trainer. The data set contains vocabulary questions in German and English, Spanish, and French as target language and is available in four different variations regarding pre-processing and deduplication. We experiment to fine-tune pre-trained BERT language models on the downstream task of vocabulary evaluation with the proposed MuLVE data set. The results provide outstanding results of > 95.5 accuracy and F2-score. The data set is available on the European Language Grid.

</p>
</details>

<details><summary><b>Railway Operation Rescheduling System via Dynamic Simulation and Reinforcement Learning</b>
<a href="https://arxiv.org/abs/2201.06276">arxiv:2201.06276</a>
&#x1F4C8; 2 <br>
<p>Shumpei Kubosawa, Takashi Onishi, Makoto Sakahara, Yoshimasa Tsuruoka</p></summary>
<p>

**Abstract:** The number of railway service disruptions has been increasing owing to intensification of natural disasters. In addition, abrupt changes in social situations such as the COVID-19 pandemic require railway companies to modify the traffic schedule frequently. Therefore, automatic support for optimal scheduling is anticipated. In this study, an automatic railway scheduling system is presented. The system leverages reinforcement learning and a dynamic simulator that can simulate the railway traffic and passenger flow of a whole line. The proposed system enables rapid generation of the traffic schedule of a whole line because the optimization process is conducted in advance as the training. The system is evaluated using an interruption scenario, and the results demonstrate that the system can generate optimized schedules of the whole line in a few minutes.

</p>
</details>

<details><summary><b>Selecting and combining complementary feature representations and classifiers for hate speech detection</b>
<a href="https://arxiv.org/abs/2201.06721">arxiv:2201.06721</a>
&#x1F4C8; 1 <br>
<p>Rafael M. O. Cruz, Woshington V. de Sousa, George D. C. Cavalcanti</p></summary>
<p>

**Abstract:** Hate speech is a major issue in social networks due to the high volume of data generated daily. Recent works demonstrate the usefulness of machine learning (ML) in dealing with the nuances required to distinguish between hateful posts from just sarcasm or offensive language. Many ML solutions for hate speech detection have been proposed by either changing how features are extracted from the text or the classification algorithm employed. However, most works consider only one type of feature extraction and classification algorithm. This work argues that a combination of multiple feature extraction techniques and different classification models is needed. We propose a framework to analyze the relationship between multiple feature extraction and classification techniques to understand how they complement each other. The framework is used to select a subset of complementary techniques to compose a robust multiple classifiers system (MCS) for hate speech detection. The experimental study considering four hate speech classification datasets demonstrates that the proposed framework is a promising methodology for analyzing and designing high-performing MCS for this task. MCS system obtained using the proposed framework significantly outperforms the combination of all models and the homogeneous and heterogeneous selection heuristics, demonstrating the importance of having a proper selection scheme. Source code, figures, and dataset splits can be found in the GitHub repository: https://github.com/Menelau/Hate-Speech-MCS.

</p>
</details>

<details><summary><b>Learning to Approximate: Auto Direction Vector Set Generation for Hypervolume Contribution Approximation</b>
<a href="https://arxiv.org/abs/2201.06707">arxiv:2201.06707</a>
&#x1F4C8; 1 <br>
<p>Ke Shang, Tianye Shu, Hisao Ishibuchi</p></summary>
<p>

**Abstract:** Hypervolume contribution is an important concept in evolutionary multi-objective optimization (EMO). It involves in hypervolume-based EMO algorithms and hypervolume subset selection algorithms. Its main drawback is that it is computationally expensive in high-dimensional spaces, which limits its applicability to many-objective optimization. Recently, an R2 indicator variant (i.e., $R_2^{\text{HVC}}$ indicator) is proposed to approximate the hypervolume contribution. The $R_2^{\text{HVC}}$ indicator uses line segments along a number of direction vectors for hypervolume contribution approximation. It has been shown that different direction vector sets lead to different approximation quality. In this paper, we propose \textit{Learning to Approximate (LtA)}, a direction vector set generation method for the $R_2^{\text{HVC}}$ indicator. The direction vector set is automatically learned from training data. The learned direction vector set can then be used in the $R_2^{\text{HVC}}$ indicator to improve its approximation quality. The usefulness of the proposed LtA method is examined by comparing it with other commonly-used direction vector set generation methods for the $R_2^{\text{HVC}}$ indicator. Experimental results suggest the superiority of LtA over the other methods for generating high quality direction vector sets.

</p>
</details>

<details><summary><b>Benchmarking Subset Selection from Large Candidate Solution Sets in Evolutionary Multi-objective Optimization</b>
<a href="https://arxiv.org/abs/2201.06700">arxiv:2201.06700</a>
&#x1F4C8; 1 <br>
<p>Ke Shang, Tianye Shu, Hisao Ishibuchi, Yang Nan, Lie Meng Pang</p></summary>
<p>

**Abstract:** In the evolutionary multi-objective optimization (EMO) field, the standard practice is to present the final population of an EMO algorithm as the output. However, it has been shown that the final population often includes solutions which are dominated by other solutions generated and discarded in previous generations. Recently, a new EMO framework has been proposed to solve this issue by storing all the non-dominated solutions generated during the evolution in an archive and selecting a subset of solutions from the archive as the output. The key component in this framework is the subset selection from the archive which usually stores a large number of candidate solutions. However, most studies on subset selection focus on small candidate solution sets for environmental selection. There is no benchmark test suite for large-scale subset selection. This paper aims to fill this research gap by proposing a benchmark test suite for subset selection from large candidate solution sets, and comparing some representative methods using the proposed test suite. The proposed test suite together with the benchmarking studies provides a baseline for researchers to understand, use, compare, and develop subset selection methods in the EMO field.

</p>
</details>

<details><summary><b>AESPA: Accuracy Preserving Low-degree Polynomial Activation for Fast Private Inference</b>
<a href="https://arxiv.org/abs/2201.06699">arxiv:2201.06699</a>
&#x1F4C8; 1 <br>
<p>Jaiyoung Park, Michael Jaemin Kim, Wonkyung Jung, Jung Ho Ahn</p></summary>
<p>

**Abstract:** Hybrid private inference (PI) protocol, which synergistically utilizes both multi-party computation (MPC) and homomorphic encryption, is one of the most prominent techniques for PI. However, even the state-of-the-art PI protocols are bottlenecked by the non-linear layers, especially the activation functions. Although a standard non-linear activation function can generate higher model accuracy, it must be processed via a costly garbled-circuit MPC primitive. A polynomial activation can be processed via Beaver's multiplication triples MPC primitive but has been incurring severe accuracy drops so far.
  In this paper, we propose an accuracy preserving low-degree polynomial activation function (AESPA) that exploits the Hermite expansion of the ReLU and basis-wise normalization. We apply AESPA to popular ML models, such as VGGNet, ResNet, and pre-activation ResNet, to show an inference accuracy comparable to those of the standard models with ReLU activation, achieving superior accuracy over prior low-degree polynomial studies. When applied to the all-RELU baseline on the state-of-the-art Delphi PI protocol, AESPA shows up to 42.1x and 28.3x lower online latency and communication cost.

</p>
</details>

<details><summary><b>Learning Neural Ranking Models Online from Implicit User Feedback</b>
<a href="https://arxiv.org/abs/2201.06658">arxiv:2201.06658</a>
&#x1F4C8; 1 <br>
<p>Yiling Jia, Hongning Wang</p></summary>
<p>

**Abstract:** Existing online learning to rank (OL2R) solutions are limited to linear models, which are incompetent to capture possible non-linear relations between queries and documents. In this work, to unleash the power of representation learning in OL2R, we propose to directly learn a neural ranking model from users' implicit feedback (e.g., clicks) collected on the fly. We focus on RankNet and LambdaRank, due to their great empirical success and wide adoption in offline settings, and control the notorious explore-exploit trade-off based on the convergence analysis of neural networks using neural tangent kernel. Specifically, in each round of result serving, exploration is only performed on document pairs where the predicted rank order between the two documents is uncertain; otherwise, the ranker's predicted order will be followed in result ranking. We prove that under standard assumptions our OL2R solution achieves a gap-dependent upper regret bound of $O(\log^2(T))$, in which the regret is defined on the total number of mis-ordered pairs over $T$ rounds. Comparisons against an extensive set of state-of-the-art OL2R baselines on two public learning to rank benchmark datasets demonstrate the effectiveness of the proposed solution.

</p>
</details>

<details><summary><b>Evaluating Inexact Unlearning Requires Revisiting Forgetting</b>
<a href="https://arxiv.org/abs/2201.06640">arxiv:2201.06640</a>
&#x1F4C8; 1 <br>
<p>Shashwat Goel, Ameya Prabhu, Ponnurangam Kumaraguru</p></summary>
<p>

**Abstract:** Existing works in inexact machine unlearning focus on achieving indistinguishability from models retrained after removing the deletion set. We argue that indistinguishability is unnecessary, infeasible to measure, and its practical relaxations can be insufficient. We redefine the goal of unlearning as forgetting all information specific to the deletion set while maintaining high utility and resource efficiency.
  Motivated by the practical application of removing mislabelled and biased data from models, we introduce a novel test to measure the degree of forgetting called Interclass Confusion (IC). It allows us to analyze two aspects of forgetting: (i) memorization and (ii) property generalization. Despite being a black-box test, IC can investigate whether information from the deletion set was erased until the early layers of the network. We empirically show that two simple unlearning methods, exact-unlearning and catastrophic-forgetting the final k layers of a network, scale well to large deletion sets unlike prior unlearning methods. k controls the forgetting-efficiency tradeoff at similar utility. Overall, we believe our formulation of unlearning and the IC test will guide the design of better unlearning algorithms.

</p>
</details>

<details><summary><b>Learning Wave Propagation with Attention-Based Convolutional Recurrent Autoencoder Net</b>
<a href="https://arxiv.org/abs/2201.06628">arxiv:2201.06628</a>
&#x1F4C8; 1 <br>
<p>Indu Kant Deo, Rajeev Jaiman</p></summary>
<p>

**Abstract:** In this paper, we present an end-to-end attention-based convolutional recurrent autoencoder (AB-CRAN) network for data-driven modeling of wave propagation phenomena. The proposed network architecture relies on the attention-based recurrent neural network (RNN) with long short-term memory (LSTM) cells. To construct the low-dimensional learning model, we employ a denoising-based convolutional autoencoder from the full-order snapshots given by time-dependent hyperbolic partial differential equations for wave propagation. To begin, we attempt to address the difficulty in evolving the low-dimensional representation in time with a plain RNN-LSTM for wave propagation phenomenon. We build an attention-based sequence-to-sequence RNN-LSTM architecture to predict the solution over a long time horizon. To demonstrate the effectiveness of the proposed learning model, we consider three benchmark problems namely one-dimensional linear convection, nonlinear viscous Burgers, and two-dimensional Saint-Venant shallow water system. Using the time-series datasets from the benchmark problems, our novel AB-CRAN architecture accurately captures the wave amplitude and preserves the wave characteristics of the solution for long time horizons. The attention-based sequence-to-sequence network increases the time-horizon of prediction by five times compared to the plain RNN-LSTM. Denoising autoencoder further reduces the mean squared error of prediction and improves the generalization capability in the parameter space.

</p>
</details>

<details><summary><b>Closed-Loop ACAS Xu NNCS is Unsafe: Quantized State Backreachability for Verification</b>
<a href="https://arxiv.org/abs/2201.06626">arxiv:2201.06626</a>
&#x1F4C8; 1 <br>
<p>Stanley Bak, Hoang-Dung Tran</p></summary>
<p>

**Abstract:** ACAS Xu is an air-to-air collision avoidance system designed for unmanned aircraft that issues horizontal turn advisories to avoid an intruder aircraft. Due the use of a large lookup table in the design, a neural network compression of the policy was proposed. Analysis of this system has spurred a significant body of research in the formal methods community on neural network verification. While many powerful methods have been developed, most work focuses on open-loop properties of the networks, rather than the main point of the system -- collision avoidance -- which requires closed-loop analysis.
  In this work, we develop a technique to verify a closed-loop approximation of ACAS Xu using state quantization and backreachability. We use favorable assumptions for the analysis -- perfect sensor information, instant following of advisories, ideal aircraft maneuvers and an intruder that only flies straight. When the method fails to prove the system is safe, we refine the quantization parameters until generating counterexamples where the original (non-quantized) system also has collisions.

</p>
</details>

<details><summary><b>Planning Not to Talk: Multiagent Systems that are Robust to Communication Loss</b>
<a href="https://arxiv.org/abs/2201.06619">arxiv:2201.06619</a>
&#x1F4C8; 1 <br>
<p>Mustafa O. Karabag, Cyrus Neary, Ufuk Topcu</p></summary>
<p>

**Abstract:** In a cooperative multiagent system, a collection of agents executes a joint policy in order to achieve some common objective. The successful deployment of such systems hinges on the availability of reliable inter-agent communication. However, many sources of potential disruption to communication exist in practice, such as radio interference, hardware failure, and adversarial attacks. In this work, we develop joint policies for cooperative multiagent systems that are robust to potential losses in communication. More specifically, we develop joint policies for cooperative Markov games with reach-avoid objectives. First, we propose an algorithm for the decentralized execution of joint policies during periods of communication loss. Next, we use the total correlation of the state-action process induced by a joint policy as a measure of the intrinsic dependencies between the agents. We then use this measure to lower-bound the performance of a joint policy when communication is lost. Finally, we present an algorithm that maximizes a proxy to this lower bound in order to synthesize minimum-dependency joint policies that are robust to communication loss. Numerical experiments show that the proposed minimum-dependency policies require minimal coordination between the agents while incurring little to no loss in performance; the total correlation value of the synthesized policy is one fifth of the total correlation value of the baseline policy which does not take potential communication losses into account. As a result, the performance of the minimum-dependency policies remains consistently high regardless of whether or not communication is available. By contrast, the performance of the baseline policy decreases by twenty percent when communication is lost.

</p>
</details>

<details><summary><b>VAQF: Fully Automatic Software-hardware Co-design Framework for Low-bit Vision Transformer</b>
<a href="https://arxiv.org/abs/2201.06618">arxiv:2201.06618</a>
&#x1F4C8; 1 <br>
<p>Mengshu Sun, Haoyu Ma, Guoliang Kang, Yifan Jiang, Tianlong Chen, Xiaolong Ma, Zhangyang Wang, Yanzhi Wang</p></summary>
<p>

**Abstract:** The transformer architectures with attention mechanisms have obtained success in Nature Language Processing (NLP), and Vision Transformers (ViTs) have recently extended the application domains to various vision tasks. While achieving high performance, ViTs suffer from large model size and high computation complexity that hinders the deployment of them on edge devices. To achieve high throughput on hardware and preserve the model accuracy simultaneously, we propose VAQF, a framework that builds inference accelerators on FPGA platforms for quantized ViTs with binary weights and low-precision activations. Given the model structure and the desired frame rate, VAQF will automatically output the required quantization precision for activations as well as the optimized parameter settings of the accelerator that fulfill the hardware requirements. The implementations are developed with Vivado High-Level Synthesis (HLS) on the Xilinx ZCU102 FPGA board, and the evaluation results with the DeiT-base model indicate that a frame rate requirement of 24 frames per second (FPS) is satisfied with 8-bit activation quantization, and a target of 30 FPS is met with 6-bit activation quantization. To the best of our knowledge, this is the first time quantization has been incorporated into ViT acceleration on FPGAs with the help of a fully automatic framework to guide the quantization strategy on the software side and the accelerator implementations on the hardware side given the target frame rate. Very small compilation time cost is incurred compared with quantization training, and the generated accelerators show the capability of achieving real-time execution for state-of-the-art ViT models on FPGAs.

</p>
</details>

<details><summary><b>Improving the quality control of seismic data through active learning</b>
<a href="https://arxiv.org/abs/2201.06616">arxiv:2201.06616</a>
&#x1F4C8; 1 <br>
<p>Mathieu Chambefort, Raphaël Butez, Emilie Chautru, Stephan Clémençon</p></summary>
<p>

**Abstract:** In image denoising problems, the increasing density of available images makes an exhaustive visual inspection impossible and therefore automated methods based on machine-learning must be deployed for this purpose. This is particulary the case in seismic signal processing. Engineers/geophysicists have to deal with millions of seismic time series. Finding the sub-surface properties useful for the oil industry may take up to a year and is very costly in terms of computing/human resources. In particular, the data must go through different steps of noise attenuation. Each denoise step is then ideally followed by a quality control (QC) stage performed by means of human expertise. To learn a quality control classifier in a supervised manner, labeled training data must be available, but collecting the labels from human experts is extremely time-consuming. We therefore propose a novel active learning methodology to sequentially select the most relevant data, which are then given back to a human expert for labeling. Beyond the application in geophysics, the technique we promote in this paper, based on estimates of the local error and its uncertainty, is generic. Its performance is supported by strong empirical evidence, as illustrated by the numerical experiments presented in this article, where it is compared to alternative active learning strategies both on synthetic and real seismic datasets.

</p>
</details>

<details><summary><b>Who supervises the supervisor? Model monitoring in production using deep feature embeddings with applications to workpiece inspection</b>
<a href="https://arxiv.org/abs/2201.06599">arxiv:2201.06599</a>
&#x1F4C8; 1 <br>
<p>Michael Banf, Gregor Steinhagen</p></summary>
<p>

**Abstract:** The automation of condition monitoring and workpiece inspection plays an essential role in maintaining high quality as well as high throughput of the manufacturing process. To this end, the recent rise of developments in machine learning has lead to vast improvements in the area of autonomous process supervision. However, the more complex and powerful these models become, the less transparent and explainable they generally are as well. One of the main challenges is the monitoring of live deployments of these machine learning systems and raising alerts when encountering events that might impact model performance. In particular, supervised classifiers are typically build under the assumption of stationarity in the underlying data distribution. For example, a visual inspection system trained on a set of material surface defects generally does not adapt or even recognize gradual changes in the data distribution - an issue known as "data drift" - such as the emergence of new types of surface defects. This, in turn, may lead to detrimental mispredictions, e.g. samples from new defect classes being classified as non-defective. To this end, it is desirable to provide real-time tracking of a classifier's performance to inform about the putative onset of additional error classes and the necessity for manual intervention with respect to classifier re-training. Here, we propose an unsupervised framework that acts on top of a supervised classification system, thereby harnessing its internal deep feature representations as a proxy to track changes in the data distribution during deployment and, hence, to anticipate classifier performance degradation.

</p>
</details>

<details><summary><b>A New Look at Dynamic Regret for Non-Stationary Stochastic Bandits</b>
<a href="https://arxiv.org/abs/2201.06532">arxiv:2201.06532</a>
&#x1F4C8; 1 <br>
<p>Yasin Abbasi-Yadkori, Andras Gyorgy, Nevena Lazic</p></summary>
<p>

**Abstract:** We study the non-stationary stochastic multi-armed bandit problem, where the reward statistics of each arm may change several times during the course of learning. The performance of a learning algorithm is evaluated in terms of their dynamic regret, which is defined as the difference of the expected cumulative reward of an agent choosing the optimal arm in every round and the cumulative reward of the learning algorithm. One way to measure the hardness of such environments is to consider how many times the identity of the optimal arm can change. We propose a method that achieves, in $K$-armed bandit problems, a near-optimal $\widetilde O(\sqrt{K N(S+1)})$ dynamic regret, where $N$ is the number of rounds and $S$ is the number of times the identity of the optimal arm changes, without prior knowledge of $S$ and $N$. Previous works for this problem obtain regret bounds that scale with the number of changes (or the amount of change) in the reward functions, which can be much larger, or assume prior knowledge of $S$ to achieve similar bounds.

</p>
</details>

<details><summary><b>Data Harmonisation for Information Fusion in Digital Healthcare: A State-of-the-Art Systematic Review, Meta-Analysis and Future Research Directions</b>
<a href="https://arxiv.org/abs/2201.06505">arxiv:2201.06505</a>
&#x1F4C8; 1 <br>
<p>Yang Nan, Javier Del Ser, Simon Walsh, Carola Schönlieb, Michael Roberts, Ian Selby, Kit Howard, John Owen, Jon Neville, Julien Guiot, Benoit Ernst, Ana Pastor, Angel Alberich-Bayarri, Marion I. Menzel, Sean Walsh, Wim Vos, Nina Flerin, Jean-Paul Charbonnier, Eva van Rikxoort, Avishek Chatterjee, Henry Woodruff, Philippe Lambin, Leonor Cerdá-Alberich, Luis Martí-Bonmatí, Francisco Herrera</p></summary>
<p>

**Abstract:** Removing the bias and variance of multicentre data has always been a challenge in large scale digital healthcare studies, which requires the ability to integrate clinical features extracted from data acquired by different scanners and protocols to improve stability and robustness. Previous studies have described various computational approaches to fuse single modality multicentre datasets. However, these surveys rarely focused on evaluation metrics and lacked a checklist for computational data harmonisation studies. In this systematic review, we summarise the computational data harmonisation approaches for multi-modality data in the digital healthcare field, including harmonisation strategies and evaluation metrics based on different theories. In addition, a comprehensive checklist that summarises common practices for data harmonisation studies is proposed to guide researchers to report their research findings more effectively. Last but not least, flowcharts presenting possible ways for methodology and metric selection are proposed and the limitations of different methods have been surveyed for future research.

</p>
</details>

<details><summary><b>AugLy: Data Augmentations for Robustness</b>
<a href="https://arxiv.org/abs/2201.06494">arxiv:2201.06494</a>
&#x1F4C8; 1 <br>
<p>Zoe Papakipos, Joanna Bitton</p></summary>
<p>

**Abstract:** We introduce AugLy, a data augmentation library with a focus on adversarial robustness. AugLy provides a wide array of augmentations for multiple modalities (audio, image, text, & video). These augmentations were inspired by those that real users perform on social media platforms, some of which were not already supported by existing data augmentation libraries. AugLy can be used for any purpose where data augmentations are useful, but it is particularly well-suited for evaluating robustness and systematically generating adversarial attacks. In this paper we present how AugLy works, benchmark it compared against existing libraries, and use it to evaluate the robustness of various state-of-the-art models to showcase AugLy's utility. The AugLy repository can be found at https://github.com/facebookresearch/AugLy.

</p>
</details>

<details><summary><b>Minimax risk classifiers with 0-1 loss</b>
<a href="https://arxiv.org/abs/2201.06487">arxiv:2201.06487</a>
&#x1F4C8; 1 <br>
<p>Santiago Mazuelas, Mauricio Romero, Peter Grünwald</p></summary>
<p>

**Abstract:** Supervised classification techniques use training samples to learn a classification rule with small expected 0-1-loss (error probability). Conventional methods enable tractable learning and provide out-of-sample generalization by using surrogate losses instead of the 0-1-loss and considering specific families of rules (hypothesis classes). This paper presents minimax risk classifiers (MRCs) that minimize the worst-case 0-1-loss over general classification rules and provide tight performance guarantees at learning. We show that MRCs are strongly universally consistent using feature mappings given by characteristic kernels. The paper also proposes efficient optimization techniques for MRC learning and shows that the methods presented can provide accurate classification together with tight performance guarantees

</p>
</details>

<details><summary><b>SigGAN : Adversarial Model for Learning Signed Relationships in Networks</b>
<a href="https://arxiv.org/abs/2201.06437">arxiv:2201.06437</a>
&#x1F4C8; 1 <br>
<p>Roshni Chakraborty, Ritwika Das, Joydeep Chandra</p></summary>
<p>

**Abstract:** Signed link prediction in graphs is an important problem that has applications in diverse domains. It is a binary classification problem that predicts whether an edge between a pair of nodes is positive or negative. Existing approaches for link prediction in unsigned networks cannot be directly applied for signed link prediction due to their inherent differences. Further, additional structural constraints, like, the structural balance property of the signed networks must be considered for signed link prediction. Recent signed link prediction approaches generate node representations using either generative models or discriminative models. Inspired by the recent success of Generative Adversarial Network (GAN) based models which comprises of a discriminator and generator in several applications, we propose a Generative Adversarial Network (GAN) based model for signed networks, SigGAN. It considers the requirements of signed networks, such as, integration of information from negative edges, high imbalance in number of positive and negative edges and structural balance theory. Comparing the performance with state of the art techniques on several real-world datasets validates the effectiveness of SigGAN.

</p>
</details>

<details><summary><b>Masked Faces with Faced Masks</b>
<a href="https://arxiv.org/abs/2201.06427">arxiv:2201.06427</a>
&#x1F4C8; 1 <br>
<p>Jiayi Zhu, Qing Guo, Felix Juefei-Xu, Yihao Huang, Yang Liu, Geguang Pu</p></summary>
<p>

**Abstract:** Modern face recognition systems (FRS) still fall short when the subjects are wearing facial masks, a common theme in the age of respiratory pandemics. An intuitive partial remedy is to add a mask detector to flag any masked faces so that the FRS can act accordingly for those low-confidence masked faces. In this work, we set out to investigate the potential vulnerability of such FRS, equipped with a mask detector, on large-scale masked faces. As existing face recognizers and mask detectors have high performance in their respective tasks, it is a challenge to simultaneously fool them and preserve the transferability of the attack. To this end, we devise realistic facial masks that exhibit partial face patterns (i.e., faced masks) and stealthily add adversarial textures that can not only lead to significant performance deterioration of the SOTA deep learning-based FRS, but also remain undetected by the SOTA facial mask detector, thus successfully fooling both systems at the same time. The proposed method unveils the vulnerability of the FRS when dealing with masked faces wearing faced masks.

</p>
</details>

<details><summary><b>Deep Learning-based Quality Assessment of Clinical Protocol Adherence in Fetal Ultrasound Dating Scans</b>
<a href="https://arxiv.org/abs/2201.06406">arxiv:2201.06406</a>
&#x1F4C8; 1 <br>
<p>Sevim Cengiz, Mohammad Yaqub</p></summary>
<p>

**Abstract:** To assess fetal health during pregnancy, doctors use the gestational age (GA) calculation based on the Crown Rump Length (CRL) measurement in order to check for fetal size and growth trajectory. However, GA estimation based on CRL, requires proper positioning of calipers on the fetal crown and rump view, which is not always an easy plane to find, especially for an inexperienced sonographer. Finding a slightly oblique view from the true CRL view could lead to a different CRL value and therefore incorrect estimation of GA. This study presents an AI-based method for a quality assessment of the CRL view by verifying 7 clinical scoring criteria that are used to verify the correctness of the acquired plane. We show how our proposed solution achieves high accuracy on the majority of the scoring criteria when compared to an expert. We also show that if such scoring system is used, it helps identify poorly acquired images accurately and hence may help sonographers acquire better images which could potentially lead to a better assessment of conditions such as Intrauterine Growth Restriction (IUGR).

</p>
</details>

<details><summary><b>Self-Supervised Anomaly Detection by Self-Distillation and Negative Sampling</b>
<a href="https://arxiv.org/abs/2201.06378">arxiv:2201.06378</a>
&#x1F4C8; 1 <br>
<p>Nima Rafiee, Rahil Gholamipoorfard, Nikolas Adaloglou, Simon Jaxy, Julius Ramakers, Markus Kollmann</p></summary>
<p>

**Abstract:** Detecting whether examples belong to a given in-distribution or are Out-Of-Distribution (OOD) requires identifying features specific to the in-distribution. In the absence of labels, these features can be learned by self-supervised techniques under the generic assumption that the most abstract features are those which are statistically most over-represented in comparison to other distributions from the same domain. In this work, we show that self-distillation of the in-distribution training set together with contrasting against negative examples derived from shifting transformation of auxiliary data strongly improves OOD detection. We find that this improvement depends on how the negative samples are generated. In particular, we observe that by leveraging negative samples, which keep the statistics of low-level features while changing the high-level semantics, higher average detection performance is obtained. Furthermore, good negative sampling strategies can be identified from the sensitivity of the OOD detection score. The efficiency of our approach is demonstrated across a diverse range of OOD detection problems, setting new benchmarks for unsupervised OOD detection in the visual domain.

</p>
</details>

<details><summary><b>Fair Interpretable Learning via Correction Vectors</b>
<a href="https://arxiv.org/abs/2201.06343">arxiv:2201.06343</a>
&#x1F4C8; 1 <br>
<p>Mattia Cerrato, Marius Köppel, Alexander Segner, Stefan Kramer</p></summary>
<p>

**Abstract:** Neural network architectures have been extensively employed in the fair representation learning setting, where the objective is to learn a new representation for a given vector which is independent of sensitive information. Various "representation debiasing" techniques have been proposed in the literature. However, as neural networks are inherently opaque, these methods are hard to comprehend, which limits their usefulness. We propose a new framework for fair representation learning which is centered around the learning of "correction vectors", which have the same dimensionality as the given data vectors. The corrections are then simply summed up to the original features, and can therefore be analyzed as an explicit penalty or bonus to each feature. We show experimentally that a fair representation learning problem constrained in such a way does not impact performance.

</p>
</details>

<details><summary><b>Language Model-Based Paired Variational Autoencoders for Robotic Language Learning</b>
<a href="https://arxiv.org/abs/2201.06317">arxiv:2201.06317</a>
&#x1F4C8; 1 <br>
<p>Ozan Özdemir, Matthias Kerzel, Cornelius Weber, Jae Hee Lee, Stefan Wermter</p></summary>
<p>

**Abstract:** Human infants learn language while interacting with their environment in which their caregivers may describe the objects and actions they perform. Similar to human infants, artificial agents can learn language while interacting with their environment. In this work, first, we present a neural model that bidirectionally binds robot actions and their language descriptions in a simple object manipulation scenario. Building on our previous Paired Variational Autoencoders (PVAE) model, we demonstrate the superiority of the variational autoencoder over standard autoencoders by experimenting with cubes of different colours, and by enabling the production of alternative vocabularies. Additional experiments show that the model's channel-separated visual feature extraction module can cope with objects of different shapes. Next, we introduce PVAE-BERT, which equips the model with a pretrained large-scale language model, i.e., Bidirectional Encoder Representations from Transformers (BERT), enabling the model to go beyond comprehending only the predefined descriptions that the network has been trained on; the recognition of action descriptions generalises to unconstrained natural language as the model becomes capable of understanding unlimited variations of the same descriptions. Our experiments suggest that using a pretrained language model as the language encoder allows our approach to scale up for real-world scenarios with instructions from human users.

</p>
</details>

<details><summary><b>Efficient Hyperparameter Tuning for Large Scale Kernel Ridge Regression</b>
<a href="https://arxiv.org/abs/2201.06314">arxiv:2201.06314</a>
&#x1F4C8; 1 <br>
<p>Giacomo Meanti, Luigi Carratino, Ernesto De Vito, Lorenzo Rosasco</p></summary>
<p>

**Abstract:** Kernel methods provide a principled approach to nonparametric learning. While their basic implementations scale poorly to large problems, recent advances showed that approximate solvers can efficiently handle massive datasets. A shortcoming of these solutions is that hyperparameter tuning is not taken care of, and left for the user to perform. Hyperparameters are crucial in practice and the lack of automated tuning greatly hinders efficiency and usability. In this paper, we work to fill in this gap focusing on kernel ridge regression based on the Nyström approximation. After reviewing and contrasting a number of hyperparameter tuning strategies, we propose a complexity regularization criterion based on a data dependent penalty, and discuss its efficient optimization. Then, we proceed to a careful and extensive empirical evaluation highlighting strengths and weaknesses of the different tuning strategies. Our analysis shows the benefit of the proposed approach, that we hence incorporate in a library for large scale kernel methods to derive adaptively tuned solutions.

</p>
</details>

<details><summary><b>Continual Transformers: Redundancy-Free Attention for Online Inference</b>
<a href="https://arxiv.org/abs/2201.06268">arxiv:2201.06268</a>
&#x1F4C8; 1 <br>
<p>Lukas Hedegaard, Arian Bakhtiarnia, Alexandros Iosifidis</p></summary>
<p>

**Abstract:** Transformers are attention-based sequence transduction models, which have found widespread success in Natural Language Processing and Computer Vision applications. Yet, Transformers in their current form are inherently limited to operate on whole token sequences rather than on one token at a time. Consequently, their use during online inference entails considerable redundancy due to the overlap in successive token sequences. In this work, we propose novel formulations of the Scaled Dot-Product Attention, which enable Transformers to perform efficient online token-by-token inference in a continual input stream. Importantly, our modification is purely to the order of computations, while the produced outputs and learned weights are identical to those of the original Multi-Head Attention. To validate our approach, we conduct experiments on visual, audio, and audio-visual classification and detection tasks, i.e. Online Action Detection on THUMOS14 and TVSeries and Online Audio Classification on GTZAN, with remarkable results. Our continual one-block transformers reduce the floating point operations by respectively 63.5x and 51.5x in the Online Action Detection and Audio Classification experiments at similar predictive performance.

</p>
</details>

<details><summary><b>Segmentation of the Carotid Lumen and Vessel Wall using Deep Learning and Location Priors</b>
<a href="https://arxiv.org/abs/2201.06259">arxiv:2201.06259</a>
&#x1F4C8; 1 <br>
<p>Florian Thamm, Felix Denzinger, Leonhard Rist, Celia Martin Vicario, Florian Kordon, Andreas Maier</p></summary>
<p>

**Abstract:** In this report we want to present our method and results for the Carotid Artery Vessel Wall Segmentation Challenge. We propose an image-based pipeline utilizing the U-Net architecture and location priors to solve the segmentation problem at hand.

</p>
</details>

<details><summary><b>Automatic Segmentation of Head and Neck Tumor: How Powerful Transformers Are?</b>
<a href="https://arxiv.org/abs/2201.06251">arxiv:2201.06251</a>
&#x1F4C8; 1 <br>
<p>Ikboljon Sobirov, Otabek Nazarov, Hussain Alasmawi, Mohammad Yaqub</p></summary>
<p>

**Abstract:** Cancer is one of the leading causes of death worldwide, and head and neck (H&N) cancer is amongst the most prevalent types. Positron emission tomography and computed tomography are used to detect and segment the tumor region. Clinically, tumor segmentation is extensively time-consuming and prone to error. Machine learning, and deep learning in particular, can assist to automate this process, yielding results as accurate as the results of a clinician. In this research study, we develop a vision transformers-based method to automatically delineate H&N tumor, and compare its results to leading convolutional neural network (CNN)-based models. We use multi-modal data of CT and PET scans to do this task. We show that the selected transformer-based model can achieve results on a par with CNN-based ones. With cross validation, the model achieves a mean dice similarity coefficient of 0.736, mean precision of 0.766 and mean recall of 0.766. This is only 0.021 less than the 2020 competition winning model in terms of the DSC score. This indicates that the exploration of transformer-based models is a promising research area.

</p>
</details>

<details><summary><b>Improving Clinical Diagnosis Performance with Automated X-ray Scan Quality Enhancement Algorithms</b>
<a href="https://arxiv.org/abs/2201.06250">arxiv:2201.06250</a>
&#x1F4C8; 1 <br>
<p>Karthik K, Sowmya Kamath S</p></summary>
<p>

**Abstract:** In clinical diagnosis, diagnostic images that are obtained from the scanning devices serve as preliminary evidence for further investigation in the process of delivering quality healthcare. However, often the medical image may contain fault artifacts, introduced due to noise, blur and faulty equipment. The reason for this may be the low-quality or older scanning devices, the test environment or technicians lack of training etc; however, the net result is that the process of fast and reliable diagnosis is hampered. Resolving these issues automatically can have a significant positive impact in a hospital clinical workflow, where often, there is no other way but to work with faulty/older equipment or inadequately qualified radiology technicians. In this paper, automated image quality improvement approaches for adapted and benchmarked for the task of medical image super-resolution. During experimental evaluation on standard open datasets, the observations showed that certain algorithms perform better and show significant improvement in the diagnostic quality of medical scans, thereby enabling better visualization for human diagnostic purposes.

</p>
</details>

<details><summary><b>Contrastive Regularization for Semi-Supervised Learning</b>
<a href="https://arxiv.org/abs/2201.06247">arxiv:2201.06247</a>
&#x1F4C8; 1 <br>
<p>Doyup Lee, Sungwoong Kim, Ildoo Kim, Yeongjae Cheon, Minsu Cho, Wook-Shin Han</p></summary>
<p>

**Abstract:** Consistency regularization on label predictions becomes a fundamental technique in semi-supervised learning, but it still requires a large number of training iterations for high performance. In this study, we analyze that the consistency regularization restricts the propagation of labeling information due to the exclusion of samples with unconfident pseudo-labels in the model updates. Then, we propose contrastive regularization to improve both efficiency and accuracy of the consistency regularization by well-clustered features of unlabeled data. In specific, after strongly augmented samples are assigned to clusters by their pseudo-labels, our contrastive regularization updates the model so that the features with confident pseudo-labels aggregate the features in the same cluster, while pushing away features in different clusters. As a result, the information of confident pseudo-labels can be effectively propagated into more unlabeled samples during training by the well-clustered features. On benchmarks of semi-supervised learning tasks, our contrastive regularization improves the previous consistency-based methods and achieves state-of-the-art results, especially with fewer training iterations. Our method also shows robust performance on open-set semi-supervised learning where unlabeled data includes out-of-distribution samples.

</p>
</details>

<details><summary><b>ICLEA: Interactive Contrastive Learning for Self-supervised Entity Alignment</b>
<a href="https://arxiv.org/abs/2201.06225">arxiv:2201.06225</a>
&#x1F4C8; 1 <br>
<p>Kaisheng Zeng, Zhenhao Dong, Lei Hou, Yixin Cao, Minghao Hu, Jifan Yu, Xin Lv, Juanzi Li, Ling Feng</p></summary>
<p>

**Abstract:** Self-supervised entity alignment (EA) aims to link equivalent entities across different knowledge graphs (KGs) without seed alignments. The current SOTA self-supervised EA method draws inspiration from contrastive learning, originally designed in computer vision based on instance discrimination and contrastive loss, and suffers from two shortcomings. Firstly, it puts unidirectional emphasis on pushing sampled negative entities far away rather than pulling positively aligned pairs close, as is done in the well-established supervised EA. Secondly, KGs contain rich side information (e.g., entity description), and how to effectively leverage those information has not been adequately investigated in self-supervised EA. In this paper, we propose an interactive contrastive learning model for self-supervised EA. The model encodes not only structures and semantics of entities (including entity name, entity description, and entity neighborhood), but also conducts cross-KG contrastive learning by building pseudo-aligned entity pairs. Experimental results show that our approach outperforms previous best self-supervised results by a large margin (over 9% average improvement) and performs on par with previous SOTA supervised counterparts, demonstrating the effectiveness of the interactive contrastive learning for self-supervised EA.

</p>
</details>

<details><summary><b>Face Detection in Extreme Conditions: A Machine-learning Approach</b>
<a href="https://arxiv.org/abs/2201.06220">arxiv:2201.06220</a>
&#x1F4C8; 1 <br>
<p>Sameer Aqib Hashmi, Dr. Mahdy Rahman Chowdhury</p></summary>
<p>

**Abstract:** Face detection in unrestricted conditions has been a trouble for years due to various expressions, brightness, and coloration fringing. Recent studies show that deep learning knowledge of strategies can acquire spectacular performance inside the identification of different gadgets and patterns. This face detection in unconstrained surroundings is difficult due to various poses, illuminations, and occlusions. Figuring out someone with a picture has been popularized through the mass media. However, it's miles less sturdy to fingerprint or retina scanning. The latest research shows that deep mastering techniques can gain mind-blowing performance on those two responsibilities. In this paper, I recommend a deep cascaded multi-venture framework that exploits the inherent correlation among them to boost up their performance. In particular, my framework adopts a cascaded shape with 3 layers of cautiously designed deep convolutional networks that expect face and landmark region in a coarse-to-fine way. Besides, within the gaining knowledge of the procedure, I propose a new online tough sample mining method that can enhance the performance robotically without manual pattern choice.

</p>
</details>

<details><summary><b>An Empirical Study on the Overlapping Problem of Open-Domain Dialogue Datasets</b>
<a href="https://arxiv.org/abs/2201.06219">arxiv:2201.06219</a>
&#x1F4C8; 1 <br>
<p>Yuqiao Wen, Guoqing Luo, Lili Mou</p></summary>
<p>

**Abstract:** Open-domain dialogue systems aim to converse with humans through text, and its research has heavily relied on benchmark datasets. In this work, we first identify the overlapping problem in DailyDialog and OpenSubtitles, two popular open-domain dialogue benchmark datasets. Our systematic analysis then shows that such overlapping can be exploited to obtain fake state-of-the-art performance. Finally, we address this issue by cleaning these datasets and setting up a proper data processing procedure for future research.

</p>
</details>

<details><summary><b>Machine learning prediction for mean motion resonance behaviour -- The planar case</b>
<a href="https://arxiv.org/abs/2201.06743">arxiv:2201.06743</a>
&#x1F4C8; 0 <br>
<p>Xin Li, Jian Li, Zhihong Jeff Xia, Nikolaos Georgakarakos</p></summary>
<p>

**Abstract:** Most recently, machine learning has been used to study the dynamics of integrable Hamiltonian systems and the chaotic 3-body problem. In this work, we consider an intermediate case of regular motion in a non-integrable system: the behaviour of objects in the 2:3 mean motion resonance with Neptune. We show that, given initial data from a short 6250 yr numerical integration, the best-trained artificial neural network (ANN) can predict the trajectories of the 2:3 resonators over the subsequent 18750 yr evolution, covering a full libration cycle over the combined time period. By comparing our ANN's prediction of the resonant angle to the outcome of numerical integrations, the former can predict the resonant angle with an accuracy as small as of a few degrees only, while it has the advantage of considerably saving computational time. More specifically, the trained ANN can effectively measure the resonant amplitudes of the 2:3 resonators, and thus provides a fast approach that can identify the resonant candidates. This may be helpful in classifying a huge population of KBOs to be discovered in future surveys.

</p>
</details>

<details><summary><b>H&E-adversarial network: a convolutional neural network to learn stain-invariant features through Hematoxylin & Eosin regression</b>
<a href="https://arxiv.org/abs/2201.06329">arxiv:2201.06329</a>
&#x1F4C8; 0 <br>
<p>Niccoló Marini, Manfredo Atzori, Sebastian Otálora, Stephane Marchand-Maillet, Henning Müller</p></summary>
<p>

**Abstract:** Computational pathology is a domain that aims to develop algorithms to automatically analyze large digitized histopathology images, called whole slide images (WSI). WSIs are produced scanning thin tissue samples that are stained to make specific structures visible. They show stain colour heterogeneity due to different preparation and scanning settings applied across medical centers. Stain colour heterogeneity is a problem to train convolutional neural networks (CNN), the state-of-the-art algorithms for most computational pathology tasks, since CNNs usually underperform when tested on images including different stain variations than those within data used to train the CNN. Despite several methods that were developed, stain colour heterogeneity is still an unsolved challenge that limits the development of CNNs that can generalize on data from several medical centers. This paper aims to present a novel method to train CNNs that better generalize on data including several colour variations. The method, called H&E-adversarial CNN, exploits H&E matrix information to learn stain-invariant features during the training. The method is evaluated on the classification of colon and prostate histopathology images, involving eleven heterogeneous datasets, and compared with five other techniques used to handle stain colour heterogeneity. H&E-adversarial CNNs show an improvement in performance compared to the other algorithms, demonstrating that it can help to better deal with stain colour heterogeneous images.

</p>
</details>

<details><summary><b>Parametrized Convex Universal Approximators for Decision-Making Problems</b>
<a href="https://arxiv.org/abs/2201.06298">arxiv:2201.06298</a>
&#x1F4C8; 0 <br>
<p>Jinrae Kim, Youdan Kim</p></summary>
<p>

**Abstract:** Parametrized max-affine (PMA) and parametrized log-sum-exp (PLSE) networks are proposed for general decision-making problems. The proposed approximators generalize existing convex approximators, namely, max-affine (MA) and log-sum-exp (LSE) networks, by considering function arguments of condition and decision variables and replacing the network parameters of MA and LSE networks with continuous functions with respect to the condition variable. The universal approximation theorem of PMA and PLSE is proven, which implies that PMA and PLSE are shape-preserving universal approximators for parametrized convex continuous functions. Practical guidelines for incorporating deep neural networks within PMA and PLSE networks are provided. A numerical simulation is performed to demonstrate the performance of the proposed approximators. The simulation results support that PLSE outperforms other existing approximators in terms of minimizer and optimal value errors with scalable and efficient computation for high-dimensional cases.

</p>
</details>


{% endraw %}
Prev: [2022.01.16]({{ '/2022/01/16/2022.01.16.html' | relative_url }})  Next: [2022.01.18]({{ '/2022/01/18/2022.01.18.html' | relative_url }})