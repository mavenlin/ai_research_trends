Prev: [2022.06.24]({{ '/2022/06/24/2022.06.24.html' | relative_url }})  Next: [2022.06.26]({{ '/2022/06/26/2022.06.26.html' | relative_url }})
{% raw %}
## Summary for 2022-06-25, created on 2022-06-29


<details><summary><b>Generalized Beliefs for Cooperative AI</b>
<a href="https://arxiv.org/abs/2206.12765">arxiv:2206.12765</a>
&#x1F4C8; 10 <br>
<p>Darius Muglich, Luisa Zintgraf, Christian Schroeder de Witt, Shimon Whiteson, Jakob Foerster</p></summary>
<p>

**Abstract:** Self-play is a common paradigm for constructing solutions in Markov games that can yield optimal policies in collaborative settings. However, these policies often adopt highly-specialized conventions that make playing with a novel partner difficult. To address this, recent approaches rely on encoding symmetry and convention-awareness into policy training, but these require strong environmental assumptions and can complicate policy training. We therefore propose moving the learning of conventions to the belief space. Specifically, we propose a belief learning model that can maintain beliefs over rollouts of policies not seen at training time, and can thus decode and adapt to novel conventions at test time. We show how to leverage this model for both search and training of a best response over various pools of policies to greatly improve ad-hoc teamplay. We also show how our setup promotes explainability and interpretability of nuanced agent conventions.

</p>
</details>

<details><summary><b>The Bandwagon Effect: Not Just Another Bias</b>
<a href="https://arxiv.org/abs/2206.12701">arxiv:2206.12701</a>
&#x1F4C8; 8 <br>
<p>Norman Knyazev, Harrie Oosterhuis</p></summary>
<p>

**Abstract:** Optimizing recommender systems based on user interaction data is mainly seen as a problem of dealing with selection bias, where most existing work assumes that interactions from different users are independent. However, it has been shown that in reality user feedback is often influenced by earlier interactions of other users, e.g. via average ratings, number of views or sales per item, etc. This phenomenon is known as the bandwagon effect. In contrast with previous literature, we argue that the bandwagon effect should not be seen as a problem of statistical bias. In fact, we prove that this effect leaves both individual interactions and their sample mean unbiased. Nevertheless, we show that it can make estimators inconsistent, introducing a distinct set of problems for convergence in relevance estimation. Our theoretical analysis investigates the conditions under which the bandwagon effect poses a consistency problem and explores several approaches for mitigating these issues. This work aims to show that the bandwagon effect poses an underinvestigated open problem that is fundamentally distinct from the well-studied selection bias in recommendation.

</p>
</details>

<details><summary><b>Binary and Multinomial Classification through Evolutionary Symbolic Regression</b>
<a href="https://arxiv.org/abs/2206.12706">arxiv:2206.12706</a>
&#x1F4C8; 6 <br>
<p>Moshe Sipper</p></summary>
<p>

**Abstract:** We present three evolutionary symbolic regression-based classification algorithms for binary and multinomial datasets: GPLearnClf, CartesianClf, and ClaSyCo. Tested over 162 datasets and compared to three state-of-the-art machine learning algorithms -- XGBoost, LightGBM, and a deep neural network -- we find our algorithms to be competitive. Further, we demonstrate how to find the best method for one's dataset automatically, through the use of a state-of-the-art hyperparameter optimizer.

</p>
</details>

<details><summary><b>Self-supervised Context-aware Style Representation for Expressive Speech Synthesis</b>
<a href="https://arxiv.org/abs/2206.12559">arxiv:2206.12559</a>
&#x1F4C8; 4 <br>
<p>Yihan Wu, Xi Wang, Shaofei Zhang, Lei He, Ruihua Song, Jian-Yun Nie</p></summary>
<p>

**Abstract:** Expressive speech synthesis, like audiobook synthesis, is still challenging for style representation learning and prediction. Deriving from reference audio or predicting style tags from text requires a huge amount of labeled data, which is costly to acquire and difficult to define and annotate accurately. In this paper, we propose a novel framework for learning style representation from abundant plain text in a self-supervised manner. It leverages an emotion lexicon and uses contrastive learning and deep clustering. We further integrate the style representation as a conditioned embedding in a multi-style Transformer TTS. Comparing with multi-style TTS by predicting style tags trained on the same dataset but with human annotations, our method achieves improved results according to subjective evaluations on both in-domain and out-of-domain test sets in audiobook speech. Moreover, with implicit context-aware style representation, the emotion transition of synthesized audio in a long paragraph appears more natural. The audio samples are available on the demo web.

</p>
</details>

<details><summary><b>Spatiotemporal Data Mining: A Survey</b>
<a href="https://arxiv.org/abs/2206.12753">arxiv:2206.12753</a>
&#x1F4C8; 3 <br>
<p>Arun Sharma, Zhe Jiang, Shashi Shekhar</p></summary>
<p>

**Abstract:** Spatiotemporal data mining aims to discover interesting, useful but non-trivial patterns in big spatial and spatiotemporal data. They are used in various application domains such as public safety, ecology, epidemiology, earth science, etc. This problem is challenging because of the high societal cost of spurious patterns and exorbitant computational cost. Recent surveys of spatiotemporal data mining need update due to rapid growth. In addition, they did not adequately survey parallel techniques for spatiotemporal data mining. This paper provides a more up-to-date survey of spatiotemporal data mining methods. Furthermore, it has a detailed survey of parallel formulations of spatiotemporal data mining.

</p>
</details>

<details><summary><b>Cascading Failures in Smart Grids under Random, Targeted and Adaptive Attacks</b>
<a href="https://arxiv.org/abs/2206.12735">arxiv:2206.12735</a>
&#x1F4C8; 3 <br>
<p>Sushmita Ruj, Arindam Pal</p></summary>
<p>

**Abstract:** We study cascading failures in smart grids, where an attacker selectively compromises the nodes with probabilities proportional to their degrees, betweenness, or clustering coefficient. This implies that nodes with high degrees, betweenness, or clustering coefficients are attacked with higher probability. We mathematically and experimentally analyze the sizes of the giant components of the networks under different types of targeted attacks, and compare the results with the corresponding sizes under random attacks. We show that networks disintegrate faster for targeted attacks compared to random attacks. A targeted attack on a small fraction of high degree nodes disintegrates one or both of the networks, whereas both the networks contain giant components for random attack on the same fraction of nodes. An important observation is that an attacker has an advantage if it compromises nodes based on their betweenness, rather than based on degree or clustering coefficient.
  We next study adaptive attacks, where an attacker compromises nodes in rounds. Here, some nodes are compromised in each round based on their degree, betweenness or clustering coefficients, instead of compromising all nodes together. In this case, the degree, betweenness, or clustering coefficient is calculated before the start of each round, instead of at the beginning. We show experimentally that an adversary has an advantage in this adaptive approach, compared to compromising the same number of nodes all at once.

</p>
</details>

<details><summary><b>Defending Multimodal Fusion Models against Single-Source Adversaries</b>
<a href="https://arxiv.org/abs/2206.12714">arxiv:2206.12714</a>
&#x1F4C8; 3 <br>
<p>Karren Yang, Wan-Yi Lin, Manash Barman, Filipe Condessa, Zico Kolter</p></summary>
<p>

**Abstract:** Beyond achieving high performance across many vision tasks, multimodal models are expected to be robust to single-source faults due to the availability of redundant information between modalities. In this paper, we investigate the robustness of multimodal neural networks against worst-case (i.e., adversarial) perturbations on a single modality. We first show that standard multimodal fusion models are vulnerable to single-source adversaries: an attack on any single modality can overcome the correct information from multiple unperturbed modalities and cause the model to fail. This surprising vulnerability holds across diverse multimodal tasks and necessitates a solution. Motivated by this finding, we propose an adversarially robust fusion strategy that trains the model to compare information coming from all the input sources, detect inconsistencies in the perturbed modality compared to the other modalities, and only allow information from the unperturbed modalities to pass through. Our approach significantly improves on state-of-the-art methods in single-source robustness, achieving gains of 7.8-25.2% on action recognition, 19.7-48.2% on object detection, and 1.6-6.7% on sentiment analysis, without degrading performance on unperturbed (i.e., clean) data.

</p>
</details>

<details><summary><b>Defense against adversarial attacks on deep convolutional neural networks through nonlocal denoising</b>
<a href="https://arxiv.org/abs/2206.12685">arxiv:2206.12685</a>
&#x1F4C8; 3 <br>
<p>Sandhya Aneja, Nagender Aneja, Pg Emeroylariffion Abas, Abdul Ghani Naim</p></summary>
<p>

**Abstract:** Despite substantial advances in network architecture performance, the susceptibility of adversarial attacks makes deep learning challenging to implement in safety-critical applications. This paper proposes a data-centric approach to addressing this problem. A nonlocal denoising method with different luminance values has been used to generate adversarial examples from the Modified National Institute of Standards and Technology database (MNIST) and Canadian Institute for Advanced Research (CIFAR-10) data sets. Under perturbation, the method provided absolute accuracy improvements of up to 9.3% in the MNIST data set and 13% in the CIFAR-10 data set. Training using transformed images with higher luminance values increases the robustness of the classifier. We have shown that transfer learning is disadvantageous for adversarial machine learning. The results indicate that simple adversarial examples can improve resilience and make deep learning easier to apply in various applications.

</p>
</details>

<details><summary><b>Learning to Infer 3D Shape Programs with Differentiable Renderer</b>
<a href="https://arxiv.org/abs/2206.12675">arxiv:2206.12675</a>
&#x1F4C8; 3 <br>
<p>Yichao Liang</p></summary>
<p>

**Abstract:** Given everyday artifacts, such as tables and chairs, humans recognize high-level regularities within them, such as the symmetries of a table, the repetition of its legs, while possessing low-level priors of their geometries, e.g., surfaces are smooth and edges are sharp. This kind of knowledge constitutes an important part of human perceptual understanding and reasoning. Representations of and how to reason in such knowledge, and the acquisition thereof, are still open questions in artificial intelligence (AI) and cognitive science. Building on the previous proposal of the \emph{3D shape programs} representation alone with the accompanying neural generator and executor from \citet{tian2019learning}, we propose an analytical yet differentiable executor that is more faithful and controllable in interpreting shape programs (particularly in extrapolation) and more sample efficient (requires no training). These facilitate the generator's learning when ground truth programs are not available, and should be especially useful when new shape-program components are enrolled either by human designers or -- in the context of library learning -- algorithms themselves. Preliminary experiments on using it for adaptation illustrate the aforesaid advantages of the proposed module, encouraging similar methods being explored in building machines that learn to reason with the kind of knowledge described above, and even learn this knowledge itself.

</p>
</details>

<details><summary><b>Machine Learning-based Biological Ageing Estimation Technologies: A Survey</b>
<a href="https://arxiv.org/abs/2206.12650">arxiv:2206.12650</a>
&#x1F4C8; 3 <br>
<p>Zhaonian Zhang, Richard Jiang, Danny Crookes, Paul Chazot</p></summary>
<p>

**Abstract:** In recent years, there are various methods of estimating Biological Age (BA) have been developed. Especially with the development of machine learning (ML), there are more and more types of BA predictions, and the accuracy has been greatly improved. The models for the estimation of BA play an important role in monitoring healthy aging, and could provide new tools to detect health status in the general population and give warnings to sub-healthy people. We will mainly review three age prediction methods by using ML. They are based on blood biomarkers, facial images, and structural neuroimaging features. For now, the model using blood biomarkers is the simplest, most direct, and most accurate method. The face image method is affected by various aspects such as race, environment, etc., the prediction accuracy is not very good, which cannot make a great contribution to the medical field. In summary, we are here to track the way forward in the era of big data for us and other potential general populations and show ways to leverage the vast amounts of data available today.

</p>
</details>

<details><summary><b>Language Models as Knowledge Embeddings</b>
<a href="https://arxiv.org/abs/2206.12617">arxiv:2206.12617</a>
&#x1F4C8; 3 <br>
<p>Xintao Wang, Qianyu He, Jiaqing Liang, Yanghua Xiao</p></summary>
<p>

**Abstract:** Knowledge embeddings (KE) represent a knowledge graph (KG) by embedding entities and relations into continuous vector spaces. Existing methods are mainly structure-based or description-based. Structure-based methods learn representations that preserve the inherent structure of KGs. They cannot well represent abundant long-tail entities in real-world KGs with limited structural information. Description-based methods leverage textual information and language models. Prior approaches in this direction barely outperform structure-based ones, and suffer from problems like expensive negative sampling and restrictive description demand. In this paper, we propose LMKE, which adopts Language Models to derive Knowledge Embeddings, aiming at both enriching representations of long-tail entities and solving problems of prior description-based methods. We formulate description-based KE learning with a contrastive learning framework to improve efficiency in training and evaluation. Experimental results show that LMKE achieves state-of-the-art performance on KE benchmarks of link prediction and triple classification, especially for long-tail entities.

</p>
</details>

<details><summary><b>Malware Detection and Prevention using Artificial Intelligence Techniques</b>
<a href="https://arxiv.org/abs/2206.12770">arxiv:2206.12770</a>
&#x1F4C8; 2 <br>
<p>Md Jobair Hossain Faruk, Hossain Shahriar, Maria Valero, Farhat Lamia Barsha, Shahriar Sobhan, Md Abdullah Khan, Michael Whitman, Alfredo Cuzzocreak, Dan Lo, Akond Rahman, Fan Wu</p></summary>
<p>

**Abstract:** With the rapid technological advancement, security has become a major issue due to the increase in malware activity that poses a serious threat to the security and safety of both computer systems and stakeholders. To maintain stakeholders, particularly, end users security, protecting the data from fraudulent efforts is one of the most pressing concerns. A set of malicious programming code, scripts, active content, or intrusive software that is designed to destroy intended computer systems and programs or mobile and web applications is referred to as malware. According to a study, naive users are unable to distinguish between malicious and benign applications. Thus, computer systems and mobile applications should be designed to detect malicious activities towards protecting the stakeholders. A number of algorithms are available to detect malware activities by utilizing novel concepts including Artificial Intelligence, Machine Learning, and Deep Learning. In this study, we emphasize Artificial Intelligence (AI) based techniques for detecting and preventing malware activity. We present a detailed review of current malware detection technologies, their shortcomings, and ways to improve efficiency. Our study shows that adopting futuristic approaches for the development of malware detection applications shall provide significant advantages. The comprehension of this synthesis shall help researchers for further research on malware detection and prevention using AI.

</p>
</details>

<details><summary><b>HyGNN: Drug-Drug Interaction Prediction via Hypergraph Neural Network</b>
<a href="https://arxiv.org/abs/2206.12747">arxiv:2206.12747</a>
&#x1F4C8; 2 <br>
<p>Khaled Mohammed Saifuddin, Bri Bumgardnerr, Farhan Tanvir, Esra Akbas</p></summary>
<p>

**Abstract:** Drug-Drug Interactions (DDIs) may hamper the functionalities of drugs, and in the worst scenario, they may lead to adverse drug reactions (ADRs). Predicting all DDIs is a challenging and critical problem. Most existing computational models integrate drug-centric information from different sources and leverage them as features in machine learning classifiers to predict DDIs. However, these models have a high chance of failure, especially for the new drugs when all the information is not available. This paper proposes a novel Hypergraph Neural Network (HyGNN) model based on only the SMILES string of drugs, available for any drug, for the DDI prediction problem. To capture the drug similarities, we create a hypergraph from drugs' chemical substructures extracted from the SMILES strings. Then, we develop HyGNN consisting of a novel attention-based hypergraph edge encoder to get the representation of drugs as hyperedges and a decoder to predict the interactions between drug pairs. Furthermore, we conduct extensive experiments to evaluate our model and compare it with several state-of-the-art methods. Experimental results demonstrate that our proposed HyGNN model effectively predicts DDIs and impressively outperforms the baselines with a maximum ROC-AUC and PR-AUC of 97.9% and 98.1%, respectively.

</p>
</details>

<details><summary><b>Modeling Oceanic Variables with Dynamic Graph Neural Networks</b>
<a href="https://arxiv.org/abs/2206.12746">arxiv:2206.12746</a>
&#x1F4C8; 2 <br>
<p>Caio F. D. Netto, Marcel R. de Barros, Jefferson F. Coelho, Lucas P. de Freitas, Felipe M. Moreno, Marlon S. Mathias, Marcelo Dottori, Fábio G. Cozman, Anna H. R. Costa, Edson S. Gomi, Eduardo A. Tannuri</p></summary>
<p>

**Abstract:** Researchers typically resort to numerical methods to understand and predict ocean dynamics, a key task in mastering environmental phenomena. Such methods may not be suitable in scenarios where the topographic map is complex, knowledge about the underlying processes is incomplete, or the application is time critical. On the other hand, if ocean dynamics are observed, they can be exploited by recent machine learning methods. In this paper we describe a data-driven method to predict environmental variables such as current velocity and sea surface height in the region of Santos-Sao Vicente-Bertioga Estuarine System in the southeastern coast of Brazil. Our model exploits both temporal and spatial inductive biases by joining state-of-the-art sequence models (LSTM and Transformers) and relational models (Graph Neural Networks) in an end-to-end framework that learns both the temporal features and the spatial relationship shared among observation sites. We compare our results with the Santos Operational Forecasting System (SOFS). Experiments show that better results are attained by our model, while maintaining flexibility and little domain knowledge dependency.

</p>
</details>

<details><summary><b>Self-Supervised 3D Monocular Object Detection by Recycling Bounding Boxes</b>
<a href="https://arxiv.org/abs/2206.12738">arxiv:2206.12738</a>
&#x1F4C8; 2 <br>
<p>Sugirtha T, Sridevi M, Khailash Santhakumar, Hao Liu, B Ravi Kiran, Thomas Gauthier, Senthil Yogamani</p></summary>
<p>

**Abstract:** Modern object detection architectures are moving towards employing self-supervised learning (SSL) to improve performance detection with related pretext tasks. Pretext tasks for monocular 3D object detection have not yet been explored yet in literature. The paper studies the application of established self-supervised bounding box recycling by labeling random windows as the pretext task. The classifier head of the 3D detector is trained to classify random windows containing different proportions of the ground truth objects, thus handling the foreground-background imbalance. We evaluate the pretext task using the RTM3D detection model as baseline, with and without the application of data augmentation. We demonstrate improvements of between 2-3 % in mAP 3D and 0.9-1.5 % BEV scores using SSL over the baseline scores. We propose the inverse class frequency re-weighted (ICFW) mAP score that highlights improvements in detection for low frequency classes in a class imbalanced dataset with long tails. We demonstrate improvements in ICFW both mAP 3D and BEV scores to take into account the class imbalance in the KITTI validation dataset. We see 4-5 % increase in ICFW metric with the pretext task.

</p>
</details>

<details><summary><b>Hierarchical Reinforcement Learning with Opponent Modeling for Distributed Multi-agent Cooperation</b>
<a href="https://arxiv.org/abs/2206.12718">arxiv:2206.12718</a>
&#x1F4C8; 2 <br>
<p>Zhixuan Liang, Jiannong Cao, Shan Jiang, Divya Saxena, Huafeng Xu</p></summary>
<p>

**Abstract:** Many real-world applications can be formulated as multi-agent cooperation problems, such as network packet routing and coordination of autonomous vehicles. The emergence of deep reinforcement learning (DRL) provides a promising approach for multi-agent cooperation through the interaction of the agents and environments. However, traditional DRL solutions suffer from the high dimensions of multiple agents with continuous action space during policy search. Besides, the dynamicity of agents' policies makes the training non-stationary. To tackle the issues, we propose a hierarchical reinforcement learning approach with high-level decision-making and low-level individual control for efficient policy search. In particular, the cooperation of multiple agents can be learned in high-level discrete action space efficiently. At the same time, the low-level individual control can be reduced to single-agent reinforcement learning. In addition to hierarchical reinforcement learning, we propose an opponent modeling network to model other agents' policies during the learning process. In contrast to end-to-end DRL approaches, our approach reduces the learning complexity by decomposing the overall task into sub-tasks in a hierarchical way. To evaluate the efficiency of our approach, we conduct a real-world case study in the cooperative lane change scenario. Both simulation and real-world experiments show the superiority of our approach in the collision rate and convergence speed.

</p>
</details>

<details><summary><b>Bayesian Optimization Over Iterative Learners with Structured Responses: A Budget-aware Planning Approach</b>
<a href="https://arxiv.org/abs/2206.12708">arxiv:2206.12708</a>
&#x1F4C8; 2 <br>
<p>Syrine Belakaria, Rishit Sheth, Janardhan Rao Doppa, Nicolo Fusi</p></summary>
<p>

**Abstract:** The rising growth of deep neural networks (DNNs) and datasets in size motivates the need for efficient solutions for simultaneous model selection and training. Many methods for hyperparameter optimization (HPO) of iterative learners including DNNs attempt to solve this problem by querying and learning a response surface while searching for the optimum of that surface. However, many of these methods make myopic queries, do not consider prior knowledge about the response structure, and/or perform biased cost-aware search, all of which exacerbate identifying the best-performing model when a total cost budget is specified. This paper proposes a novel approach referred to as Budget-Aware Planning for Iterative Learners (BAPI) to solve HPO problems under a constrained cost budget. BAPI is an efficient non-myopic Bayesian optimization solution that accounts for the budget and leverages the prior knowledge about the objective function and cost function to select better configurations and to take more informed decisions during the evaluation (training). Experiments on diverse HPO benchmarks for iterative learners show that BAPI performs better than state-of-the-art baselines in most of the cases.

</p>
</details>

<details><summary><b>p-Meta: Towards On-device Deep Model Adaptation</b>
<a href="https://arxiv.org/abs/2206.12705">arxiv:2206.12705</a>
&#x1F4C8; 2 <br>
<p>Zhongnan Qu, Zimu Zhou, Yongxin Tong, Lothar Thiele</p></summary>
<p>

**Abstract:** Data collected by IoT devices are often private and have a large diversity across users. Therefore, learning requires pre-training a model with available representative data samples, deploying the pre-trained model on IoT devices, and adapting the deployed model on the device with local data. Such an on-device adaption for deep learning empowered applications demands data and memory efficiency. However, existing gradient-based meta learning schemes fail to support memory-efficient adaptation. To this end, we propose p-Meta, a new meta learning method that enforces structure-wise partial parameter updates while ensuring fast generalization to unseen tasks. Evaluations on few-shot image classification and reinforcement learning tasks show that p-Meta not only improves the accuracy but also substantially reduces the peak dynamic memory by a factor of 2.5 on average compared to state-of-the-art few-shot adaptation methods.

</p>
</details>

<details><summary><b>Anatomy-Guided Weakly-Supervised Abnormality Localization in Chest X-rays</b>
<a href="https://arxiv.org/abs/2206.12704">arxiv:2206.12704</a>
&#x1F4C8; 2 <br>
<p>Ke Yu, Shantanu Ghosh, Zhexiong Liu, Christopher Deible, Kayhan Batmanghelich</p></summary>
<p>

**Abstract:** Creating a large-scale dataset of abnormality annotation on medical images is a labor-intensive and costly task. Leveraging weak supervision from readily available data such as radiology reports can compensate lack of large-scale data for anomaly detection methods. However, most of the current methods only use image-level pathological observations, failing to utilize the relevant anatomy mentions in reports. Furthermore, Natural Language Processing (NLP)-mined weak labels are noisy due to label sparsity and linguistic ambiguity. We propose an Anatomy-Guided chest X-ray Network (AGXNet) to address these issues of weak annotation. Our framework consists of a cascade of two networks, one responsible for identifying anatomical abnormalities and the second responsible for pathological observations. The critical component in our framework is an anatomy-guided attention module that aids the downstream observation network in focusing on the relevant anatomical regions generated by the anatomy network. We use Positive Unlabeled (PU) learning to account for the fact that lack of mention does not necessarily mean a negative label. Our quantitative and qualitative results on the MIMIC-CXR dataset demonstrate the effectiveness of AGXNet in disease and anatomical abnormality localization. Experiments on the NIH Chest X-ray dataset show that the learned feature representations are transferable and can achieve the state-of-the-art performances in disease classification and competitive disease localization results. Our code is available at https://github.com/batmanlab/AGXNet

</p>
</details>

<details><summary><b>Topology-aware Generalization of Decentralized SGD</b>
<a href="https://arxiv.org/abs/2206.12680">arxiv:2206.12680</a>
&#x1F4C8; 2 <br>
<p>Tongtian Zhu, Fengxiang He, Lan Zhang, Zhengyang Niu, Mingli Song, Dacheng Tao</p></summary>
<p>

**Abstract:** This paper studies the algorithmic stability and generalizability of decentralized stochastic gradient descent (D-SGD). We prove that the consensus model learned by D-SGD is $\mathcal{O}{(m/N+1/m+λ^2)}$-stable in expectation in the non-convex non-smooth setting, where $N$ is the total sample size of the whole system, $m$ is the worker number, and $1-λ$ is the spectral gap that measures the connectivity of the communication topology. These results then deliver an $\mathcal{O}{(1/N+{({(m^{-1}λ^2)}^{\fracα{2}}+ m^{-α})}/{N^{1-\fracα{2}}})}$ in-average generalization bound, which is non-vacuous even when $λ$ is closed to $1$, in contrast to vacuous as suggested by existing literature on the projected version of D-SGD. Our theory indicates that the generalizability of D-SGD has a positive correlation with the spectral gap, and can explain why consensus control in initial training phase can ensure better generalization. Experiments of VGG-11 and ResNet-18 on CIFAR-10, CIFAR-100 and Tiny-ImageNet justify our theory. To our best knowledge, this is the first work on the topology-aware generalization of vanilla D-SGD. Code is available at https://github.com/Raiden-Zhu/Generalization-of-DSGD.

</p>
</details>

<details><summary><b>Guided Exploration in Reinforcement Learning via Monte Carlo Critic Optimization</b>
<a href="https://arxiv.org/abs/2206.12674">arxiv:2206.12674</a>
&#x1F4C8; 2 <br>
<p>Igor Kuznetsov</p></summary>
<p>

**Abstract:** The class of deep deterministic off-policy algorithms is effectively applied to solve challenging continuous control problems. However, current approaches use random noise as a common exploration method that has several weaknesses, such as a need for manual adjusting on a given task and the absence of exploratory calibration during the training process. We address these challenges by proposing a novel guided exploration method that uses a differential directional controller to incorporate scalable exploratory action correction. An ensemble of Monte Carlo Critics that provides exploratory direction is presented as a controller. The proposed method improves the traditional exploration scheme by changing exploration dynamically. We then present a novel algorithm exploiting the proposed directional controller for both policy and critic modification. The presented algorithm outperforms modern reinforcement learning algorithms across a variety of problems from DMControl suite.

</p>
</details>

<details><summary><b>Trace Recovery from Stochastically Known Logs</b>
<a href="https://arxiv.org/abs/2206.12672">arxiv:2206.12672</a>
&#x1F4C8; 2 <br>
<p>Eli Bogdanov, Izack Cohen, Avigdor Gal</p></summary>
<p>

**Abstract:** In this work we propose an algorithm for trace recovery from stochastically known logs, a setting that is becoming more common with the increasing number of sensors and predictive models that generate uncertain data. The suggested approach calculates the conformance between a process model and a stochastically known trace and recovers the best alignment within this stochastic trace as the true trace. The paper offers an analysis of the impact of various cost models on trace recovery accuracy and makes use of a product multi-graph to compare alternative trace recovery options. The average accuracy of our approach, evaluated using two publicly available datasets, is impressive, with an average recovery accuracy score of 90-97%, significantly improving a common heuristic that chooses the most likely value for each uncertain activity. We believe that the effectiveness of the proposed algorithm in recovering correct traces from stochastically known logs may be a powerful aid for developing credible decision-making tools in uncertain settings.

</p>
</details>

<details><summary><b>Evaluation of Semantic Answer Similarity Metrics</b>
<a href="https://arxiv.org/abs/2206.12664">arxiv:2206.12664</a>
&#x1F4C8; 2 <br>
<p>Farida Mustafazade, Peter Ebbinghaus</p></summary>
<p>

**Abstract:** There are several issues with the existing general machine translation or natural language generation evaluation metrics, and question-answering (QA) systems are indifferent in that context. To build robust QA systems, we need the ability to have equivalently robust evaluation systems to verify whether model predictions to questions are similar to ground-truth annotations. The ability to compare similarity based on semantics as opposed to pure string overlap is important to compare models fairly and to indicate more realistic acceptance criteria in real-life applications. We build upon the first to our knowledge paper that uses transformer-based model metrics to assess semantic answer similarity and achieve higher correlations to human judgement in the case of no lexical overlap. We propose cross-encoder augmented bi-encoder and BERTScore models for semantic answer similarity, trained on a new dataset consisting of name pairs of US-American public figures. As far as we are concerned, we provide the first dataset of co-referent name string pairs along with their similarities, which can be used for training.
  Machine Learning & Applications 4th International Conference on Machine Learning & Applications (CMLA 2022) June 25~26, 2022, Copenhagen, Denmark Volume Editors : David C. Wyld, Dhinaharan Nagamalai (Eds) ISBN : 978-1-925953-69-5

</p>
</details>

<details><summary><b>Statistical inference with implicit SGD: proximal Robbins-Monro vs. Polyak-Ruppert</b>
<a href="https://arxiv.org/abs/2206.12663">arxiv:2206.12663</a>
&#x1F4C8; 2 <br>
<p>Yoonhyung Lee, Sungdong Lee, Joong-Ho Won</p></summary>
<p>

**Abstract:** The implicit stochastic gradient descent (ISGD), a proximal version of SGD, is gaining interest in the literature due to its stability over (explicit) SGD. In this paper, we conduct an in-depth analysis of the two modes of ISGD for smooth convex functions, namely proximal Robbins-Monro (proxRM) and proximal Poylak-Ruppert (proxPR) procedures, for their use in statistical inference on model parameters. Specifically, we derive non-asymptotic point estimation error bounds of both proxRM and proxPR iterates and their limiting distributions, and propose on-line estimators of their asymptotic covariance matrices that require only a single run of ISGD. The latter estimators are used to construct valid confidence intervals for the model parameters. Our analysis is free of the generalized linear model assumption that has limited the preceding analyses, and employs feasible procedures. Our on-line covariance matrix estimators appear to be the first of this kind in the ISGD literature.

</p>
</details>

<details><summary><b>Enhanced Deep Animation Video Interpolation</b>
<a href="https://arxiv.org/abs/2206.12657">arxiv:2206.12657</a>
&#x1F4C8; 2 <br>
<p>Wang Shen, Cheng Ming, Wenbo Bao, Guangtao Zhai, Li Chen, Zhiyong Gao</p></summary>
<p>

**Abstract:** Existing learning-based frame interpolation algorithms extract consecutive frames from high-speed natural videos to train the model. Compared to natural videos, cartoon videos are usually in a low frame rate. Besides, the motion between consecutive cartoon frames is typically nonlinear, which breaks the linear motion assumption of interpolation algorithms. Thus, it is unsuitable for generating a training set directly from cartoon videos. For better adapting frame interpolation algorithms from nature video to animation video, we present AutoFI, a simple and effective method to automatically render training data for deep animation video interpolation. AutoFI takes a layered architecture to render synthetic data, which ensures the assumption of linear motion. Experimental results show that AutoFI performs favorably in training both DAIN and ANIN. However, most frame interpolation algorithms will still fail in error-prone areas, such as fast motion or large occlusion. Besides AutoFI, we also propose a plug-and-play sketch-based post-processing module, named SktFI, to refine the final results using user-provided sketches manually. With AutoFI and SktFI, the interpolated animation frames show high perceptual quality.

</p>
</details>

<details><summary><b>Review on Social Behavior Analysis of Laboratory Animals: From Methodologies to Applications</b>
<a href="https://arxiv.org/abs/2206.12651">arxiv:2206.12651</a>
&#x1F4C8; 2 <br>
<p>Ziping Jiang, Paul L. Chazot, Richard Jiang</p></summary>
<p>

**Abstract:** As the bridge between genetic and physiological aspects, animal behaviour analysis is one of the most significant topics in biology and ecological research. However, identifying, tracking and recording animal behaviour are labour intensive works that require professional knowledge. To mitigate the spend for annotating data, researchers turn to computer vision techniques for automatic label algorithms, since most of the data are recorded visually. In this work, we explore a variety of behaviour detection algorithms, covering traditional vision methods, statistical methods and deep learning methods. The objective of this work is to provide a thorough investigation of related work, furnishing biologists with a scratch of efficient animal behaviour detection methods. Apart from that, we also discuss the strengths and weaknesses of those algorithms to provide some insights for those who already delve into this field.

</p>
</details>

<details><summary><b>Sentiment Analysis with R: Natural Language Processing for Semi-Automated Assessments of Qualitative Data</b>
<a href="https://arxiv.org/abs/2206.12649">arxiv:2206.12649</a>
&#x1F4C8; 2 <br>
<p>Dennis Klinkhammer</p></summary>
<p>

**Abstract:** Sentiment analysis is a sub-discipline in the field of natural language processing and computational linguistics and can be used for automated or semi-automated analyses of text documents. One of the aims of these analyses is to recognize an expressed attitude as positive or negative as it can be contained in comments on social media platforms or political documents and speeches as well as fictional and nonfictional texts. Regarding analyses of comments on social media platforms, this is an extension of the previous tutorial on semi-automated screenings of social media network data. A longitudinal perspective regarding social media comments as well as cross-sectional perspectives regarding fictional and nonfictional texts, e.g. entire books and libraries, can lead to extensive text documents. Their analyses can be simplified and accelerated by using sentiment analysis with acceptable inter-rater reliability. Therefore, this tutorial introduces the basic functions for performing a sentiment analysis with R and explains how text documents can be analysed step by step - regardless of their underlying formatting. All prerequisites and steps are described in detail and associated codes are available on GitHub. A comparison of two political speeches illustrates a possible use case.

</p>
</details>

<details><summary><b>Distilling a Pretrained Language Model to a Multilingual ASR Model</b>
<a href="https://arxiv.org/abs/2206.12638">arxiv:2206.12638</a>
&#x1F4C8; 2 <br>
<p>Kwanghee Choi, Hyung-Min Park</p></summary>
<p>

**Abstract:** Multilingual speech data often suffer from long-tailed language distribution, resulting in performance degradation. However, multilingual text data is much easier to obtain, yielding a more useful general language model. Hence, we are motivated to distill the rich knowledge embedded inside a well-trained teacher text model to the student speech model. We propose a novel method called the Distilling a Language model to a Speech model (Distill-L2S), which aligns the latent representations of two different modalities. The subtle differences are handled by the shrinking mechanism, nearest-neighbor interpolation, and a learnable linear projection layer. We demonstrate the effectiveness of our distillation method by applying it to the multilingual automatic speech recognition (ASR) task. We distill the transformer-based cross-lingual language model (InfoXLM) while fine-tuning the large-scale multilingual ASR model (XLSR-wav2vec 2.0) for each language. We show the superiority of our method on 20 low-resource languages of the CommonVoice dataset with less than 100 hours of speech data.

</p>
</details>

<details><summary><b>Mitigating sampling bias in risk-based active learning via an EM algorithm</b>
<a href="https://arxiv.org/abs/2206.12598">arxiv:2206.12598</a>
&#x1F4C8; 2 <br>
<p>Aidan J. Hughes, Lawrence A. Bull, Paul Gardner, Nikolaos Dervilis, Keith Worden</p></summary>
<p>

**Abstract:** Risk-based active learning is an approach to developing statistical classifiers for online decision-support. In this approach, data-label querying is guided according to the expected value of perfect information for incipient data points. For SHM applications, the value of information is evaluated with respect to a maintenance decision process, and the data-label querying corresponds to the inspection of a structure to determine its health state. Sampling bias is a known issue within active-learning paradigms; this occurs when an active learning process over- or undersamples specific regions of a feature-space, thereby resulting in a training set that is not representative of the underlying distribution. This bias ultimately degrades decision-making performance, and as a consequence, results in unnecessary costs incurred. The current paper outlines a risk-based approach to active learning that utilises a semi-supervised Gaussian mixture model. The semi-supervised approach counteracts sampling bias by incorporating pseudo-labels for unlabelled data via an EM algorithm. The approach is demonstrated on a numerical example representative of the decision processes found in SHM.

</p>
</details>

<details><summary><b>Making Look-Ahead Active Learning Strategies Feasible with Neural Tangent Kernels</b>
<a href="https://arxiv.org/abs/2206.12569">arxiv:2206.12569</a>
&#x1F4C8; 2 <br>
<p>Mohamad Amin Mohamadi, Wonho Bae, Danica J. Sutherland</p></summary>
<p>

**Abstract:** We propose a new method for approximating active learning acquisition strategies that are based on retraining with hypothetically-labeled candidate data points. Although this is usually infeasible with deep networks, we use the neural tangent kernel to approximate the result of retraining, and prove that this approximation works asymptotically even in an active learning setup -- approximating "look-ahead" selection criteria with far less computation required. This also enables us to conduct sequential active learning, i.e. updating the model in a streaming regime, without needing to retrain the model with SGD after adding each new data point. Moreover, our querying strategy, which better understands how the model's predictions will change by adding new data points in comparison to the standard ("myopic") criteria, beats other look-ahead strategies by large margins, and achieves equal or better performance compared to state-of-the-art methods on several benchmark datasets in pool-based active learning.

</p>
</details>

<details><summary><b>Self-supervision and Learnable STRFs for Age, Emotion, and Country Prediction</b>
<a href="https://arxiv.org/abs/2206.12568">arxiv:2206.12568</a>
&#x1F4C8; 2 <br>
<p>Roshan Sharma, Tyler Vuong, Mark Lindsey, Hira Dhamyal, Rita Singh, Bhiksha Raj</p></summary>
<p>

**Abstract:** This work presents a multitask approach to the simultaneous estimation of age, country of origin, and emotion given vocal burst audio for the 2022 ICML Expressive Vocalizations Challenge ExVo-MultiTask track. The method of choice utilized a combination of spectro-temporal modulation and self-supervised features, followed by an encoder-decoder network organized in a multitask paradigm. We evaluate the complementarity between the tasks posed by examining independent task-specific and joint models, and explore the relative strengths of different feature sets. We also introduce a simple score fusion mechanism to leverage the complementarity of different feature sets for this task.
  We find that robust data preprocessing in conjunction with score fusion over spectro-temporal receptive field and HuBERT models achieved our best ExVo-MultiTask test score of 0.412.

</p>
</details>

<details><summary><b>Generating Diverse Vocal Bursts with StyleGAN2 and MEL-Spectrograms</b>
<a href="https://arxiv.org/abs/2206.12563">arxiv:2206.12563</a>
&#x1F4C8; 2 <br>
<p>Marco Jiralerspong, Gauthier Gidel</p></summary>
<p>

**Abstract:** We describe our approach for the generative emotional vocal burst task (ExVo Generate) of the ICML Expressive Vocalizations Competition. We train a conditional StyleGAN2 architecture on mel-spectrograms of preprocessed versions of the audio samples. The mel-spectrograms generated by the model are then inverted back to the audio domain. As a result, our generated samples substantially improve upon the baseline provided by the competition from a qualitative and quantitative perspective for all emotions. More precisely, even for our worst-performing emotion (awe), we obtain an FAD of 1.76 compared to the baseline of 4.81 (as a reference, the FAD between the train/validation sets for awe is 0.776).

</p>
</details>

<details><summary><b>Protoformer: Embedding Prototypes for Transformers</b>
<a href="https://arxiv.org/abs/2206.12710">arxiv:2206.12710</a>
&#x1F4C8; 1 <br>
<p>Ashkan Farhangi, Ning Sui, Nan Hua, Haiyan Bai, Arthur Huang, Zhishan Guo</p></summary>
<p>

**Abstract:** Transformers have been widely applied in text classification. Unfortunately, real-world data contain anomalies and noisy labels that cause challenges for state-of-art Transformers. This paper proposes Protoformer, a novel self-learning framework for Transformers that can leverage problematic samples for text classification. Protoformer features a selection mechanism for embedding samples that allows us to efficiently extract and utilize anomalies prototypes and difficult class prototypes. We demonstrated such capabilities on datasets with diverse textual structures (e.g., Twitter, IMDB, ArXiv). We also applied the framework to several models. The results indicate that Protoformer can improve current Transformers in various empirical settings.

</p>
</details>

<details><summary><b>Minority Report: A Graph Network Oracle for In Situ Visualization</b>
<a href="https://arxiv.org/abs/2206.12683">arxiv:2206.12683</a>
&#x1F4C8; 1 <br>
<p>Krishna Kumar, Paul Navrátil, Andrew Solis, Joseph Vantassel</p></summary>
<p>

**Abstract:** In situ visualization techniques are hampered by a lack of foresight: crucial simulation phenomena can be missed due to a poor sampling rate or insufficient detail at critical timesteps. Keeping a human in the loop is impractical, and defining statistical triggers can be difficult. This paper demonstrates the potential for using a machine-learning-based simulation surrogate as an oracle to identify expected critical regions of a large-scale simulation. These critical regions are used to drive the in situ analysis, providing greater data fidelity and analysis resolution with an equivalent I/O budget to a traditional in situ framework. We develop a distributed asynchronous in situ visualization by integrating TACC Galaxy with CB-Geo MPM for material point simulation of granular flows. We employ a PyTorch-based 3D Graph Network Simulator (GNS) trained on granular flow problems as an oracle to predict the dynamics of granular flows. Critical regions of interests are manually tagged in GNS for in situ rendering in MPM.

</p>
</details>

<details><summary><b>Asymptotic-Preserving Neural Networks for multiscale hyperbolic models of epidemic spread</b>
<a href="https://arxiv.org/abs/2206.12625">arxiv:2206.12625</a>
&#x1F4C8; 1 <br>
<p>Giulia Bertaglia, Chuan Lu, Lorenzo Pareschi, Xueyu Zhu</p></summary>
<p>

**Abstract:** When investigating epidemic dynamics through differential models, the parameters needed to understand the phenomenon and to simulate forecast scenarios require a delicate calibration phase, often made even more challenging by the scarcity and uncertainty of the observed data reported by official sources. In this context, Physics-Informed Neural Networks (PINNs), by embedding the knowledge of the differential model that governs the physical phenomenon in the learning process, can effectively address the inverse and forward problem of data-driven learning and solving the corresponding epidemic problem. In many circumstances, however, the spatial propagation of an infectious disease is characterized by movements of individuals at different scales governed by multiscale PDEs. This reflects the heterogeneity of a region or territory in relation to the dynamics within cities and in neighboring zones. In presence of multiple scales, a direct application of PINNs generally leads to poor results due to the multiscale nature of the differential model in the loss function of the neural network. To allow the neural network to operate uniformly with respect to the small scales, it is desirable that the neural network satisfies an Asymptotic-Preservation (AP) property in the learning process. To this end, we consider a new class of AP Neural Networks (APNNs) for multiscale hyperbolic transport models of epidemic spread that, thanks to an appropriate AP formulation of the loss function, is capable to work uniformly at the different scales of the system. A series of numerical tests for different epidemic scenarios confirms the validity of the proposed approach, highlighting the importance of the AP property in the neural network when dealing with multiscale problems especially in presence of sparse and partially observed systems.

</p>
</details>

<details><summary><b>Adversarial Self-Attention for Language Understanding</b>
<a href="https://arxiv.org/abs/2206.12608">arxiv:2206.12608</a>
&#x1F4C8; 1 <br>
<p>Hongqiu Wu, Hai Zhao</p></summary>
<p>

**Abstract:** An ultimate language system aims at the high generalization and robustness when adapting to diverse scenarios. Unfortunately, the recent white hope pre-trained language models (PrLMs) barely escape from stacking excessive parameters to the over-parameterized Transformer architecture to achieve higher performances. This paper thus proposes \textit{Adversarial Self-Attention} mechanism (ASA), which adversarially reconstructs the Transformer attentions and facilitates model training from contaminated model structures, coupled with a fast and simple implementation for better PrLM building. We conduct comprehensive evaluation across a wide range of tasks on both pre-training and fine-tuning stages. For pre-training, ASA unfolds remarkable performance gain compared to regular training for longer periods. For fine-tuning, ASA-empowered models consistently outweigh naive models by a large margin considering both generalization and robustness.

</p>
</details>

<details><summary><b>Construct a Sentence with Multiple Specified Words</b>
<a href="https://arxiv.org/abs/2206.12565">arxiv:2206.12565</a>
&#x1F4C8; 1 <br>
<p>Yuanliang Meng</p></summary>
<p>

**Abstract:** This paper demonstrates a task to finetune a BART model so it can construct a sentence from an arbitrary set of words, which used to be a difficult NLP task. The training task is making sentences with four words, but the trained model can generate sentences when fewer or more words are provided. The output sentences have high quality in general. The model can have some real-world applications, and this task can be used as an evaluation mechanism for any language model as well.

</p>
</details>


{% endraw %}
Prev: [2022.06.24]({{ '/2022/06/24/2022.06.24.html' | relative_url }})  Next: [2022.06.26]({{ '/2022/06/26/2022.06.26.html' | relative_url }})