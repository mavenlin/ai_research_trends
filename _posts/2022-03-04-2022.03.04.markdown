Prev: [2022.03.03]({{ '/2022/03/03/2022.03.03.html' | relative_url }})  Next: [2022.03.05]({{ '/2022/03/05/2022.03.05.html' | relative_url }})
{% raw %}
## Summary for 2022-03-04, created on 2022-03-14


<details><summary><b>A Typology to Explore and Guide Explanatory Interactive Machine Learning</b>
<a href="https://arxiv.org/abs/2203.03668">arxiv:2203.03668</a>
&#x1F4C8; 131 <br>
<p>Felix Friedrich, Wolfgang Stammer, Patrick Schramowski, Kristian Kersting</p></summary>
<p>

**Abstract:** Recently, more and more eXplanatory Interactive machine Learning (XIL) methods have been proposed with the goal of extending a model's learning process by integrating human user supervision on the model's explanations. These methods were often developed independently, provide different motivations and stem from different applications. Notably, up to now, there has not been a comprehensive evaluation of these works. By identifying a common set of basic modules and providing a thorough discussion of these modules, our work, for the first time, comes up with a unification of the various methods into a single typology. This typology can thus be used to categorize existing and future XIL methods based on the identified modules. Moreover, our work contributes by surveying six existing XIL methods. In addition to benchmarking these methods on their overall ability to revise a model, we perform additional benchmarks regarding wrong reason revision, interaction efficiency, robustness to feedback quality, and the ability to revise a strongly corrupted model. Apart from introducing these novel benchmarking tasks, for improved quantitative evaluations, we further introduce a novel Wrong Reason (\wrnospace) metric which measures the average wrong reason activation in a model's explanations to complement a qualitative inspection. In our evaluations, all methods prove to revise a model successfully. However, we found significant differences between the methods on individual benchmark tasks, revealing valuable application-relevant aspects not only for comparing current methods but also to motivate the necessity of incorporating these benchmarks in the development of future XIL methods.

</p>
</details>

<details><summary><b>Training language models to follow instructions with human feedback</b>
<a href="https://arxiv.org/abs/2203.02155">arxiv:2203.02155</a>
&#x1F4C8; 78 <br>
<p>Long Ouyang, Jeff Wu, Xu Jiang, Diogo Almeida, Carroll L. Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, John Schulman, Jacob Hilton, Fraser Kelton, Luke Miller, Maddie Simens, Amanda Askell, Peter Welinder, Paul Christiano, Jan Leike, Ryan Lowe</p></summary>
<p>

**Abstract:** Making language models bigger does not inherently make them better at following a user's intent. For example, large language models can generate outputs that are untruthful, toxic, or simply not helpful to the user. In other words, these models are not aligned with their users. In this paper, we show an avenue for aligning language models with user intent on a wide range of tasks by fine-tuning with human feedback. Starting with a set of labeler-written prompts and prompts submitted through the OpenAI API, we collect a dataset of labeler demonstrations of the desired model behavior, which we use to fine-tune GPT-3 using supervised learning. We then collect a dataset of rankings of model outputs, which we use to further fine-tune this supervised model using reinforcement learning from human feedback. We call the resulting models InstructGPT. In human evaluations on our prompt distribution, outputs from the 1.3B parameter InstructGPT model are preferred to outputs from the 175B GPT-3, despite having 100x fewer parameters. Moreover, InstructGPT models show improvements in truthfulness and reductions in toxic output generation while having minimal performance regressions on public NLP datasets. Even though InstructGPT still makes simple mistakes, our results show that fine-tuning with human feedback is a promising direction for aligning language models with human intent.

</p>
</details>

<details><summary><b>R-GCN: The R Could Stand for Random</b>
<a href="https://arxiv.org/abs/2203.02424">arxiv:2203.02424</a>
&#x1F4C8; 65 <br>
<p>Vic Degraeve, Gilles Vandewiele, Femke Ongenae, Sofie Van Hoecke</p></summary>
<p>

**Abstract:** The inception of Relational Graph Convolutional Networks (R-GCNs) marked a milestone in the Semantic Web domain as it allows for end-to-end training of machine learning models that operate on Knowledge Graphs (KGs). R-GCNs generate a representation for a node of interest by repeatedly aggregating parametrised, relation-specific transformations of its neighbours. However, in this paper, we argue that the the R-GCN's main contribution lies in this "message passing" paradigm, rather than the learned parameters. To this end, we introduce the "Random Relational Graph Convolutional Network" (RR-GCN), which constructs embeddings for nodes in the KG by aggregating randomly transformed random information from neigbours, i.e., with no learned parameters. We empirically show that RR-GCNs can compete with fully trained R-GCNs in both node classification and link prediction settings. The implications of these results are two-fold: on the one hand, our technique can be used as a quick baseline that novel KG embedding methods should be able to beat. On the other hand, it demonstrates that further research might reveal more parameter-efficient inductive biases for KGs.

</p>
</details>

<details><summary><b>Building 3D Generative Models from Minimal Data</b>
<a href="https://arxiv.org/abs/2203.02554">arxiv:2203.02554</a>
&#x1F4C8; 53 <br>
<p>Skylar Sutherland, Bernhard Egger, Joshua Tenenbaum</p></summary>
<p>

**Abstract:** We propose a method for constructing generative models of 3D objects from a single 3D mesh and improving them through unsupervised low-shot learning from 2D images. Our method produces a 3D morphable model that represents shape and albedo in terms of Gaussian processes. Whereas previous approaches have typically built 3D morphable models from multiple high-quality 3D scans through principal component analysis, we build 3D morphable models from a single scan or template. As we demonstrate in the face domain, these models can be used to infer 3D reconstructions from 2D data (inverse graphics) or 3D data (registration). Specifically, we show that our approach can be used to perform face recognition using only a single 3D template (one scan total, not one per person). We extend our model to a preliminary unsupervised learning framework that enables the learning of the distribution of 3D faces using one 3D template and a small number of 2D images. This approach could also provide a model for the origins of face perception in human infants, who appear to start with an innate face template and subsequently develop a flexible system for perceiving the 3D structure of any novel face from experience with only 2D images of a relatively small number of familiar faces.

</p>
</details>

<details><summary><b>Rethinking Efficient Lane Detection via Curve Modeling</b>
<a href="https://arxiv.org/abs/2203.02431">arxiv:2203.02431</a>
&#x1F4C8; 45 <br>
<p>Zhengyang Feng, Shaohua Guo, Xin Tan, Ke Xu, Min Wang, Lizhuang Ma</p></summary>
<p>

**Abstract:** This paper presents a novel parametric curve-based method for lane detection in RGB images. Unlike state-of-the-art segmentation-based and point detection-based methods that typically require heuristics to either decode predictions or formulate a large sum of anchors, the curve-based methods can learn holistic lane representations naturally. To handle the optimization difficulties of existing polynomial curve methods, we propose to exploit the parametric BÃ©zier curve due to its ease of computation, stability, and high freedom degrees of transformations. In addition, we propose the deformable convolution-based feature flip fusion, for exploiting the symmetry properties of lanes in driving scenes. The proposed method achieves a new state-of-the-art performance on the popular LLAMAS benchmark. It also achieves favorable accuracy on the TuSimple and CULane datasets, while retaining both low latency (> 150 FPS) and small model size (< 10M). Our method can serve as a new baseline, to shed the light on the parametric curves modeling for lane detection. Codes of our model and PytorchAutoDrive: a unified framework for self-driving perception, are available at: https://github.com/voldemortX/pytorch-auto-drive .

</p>
</details>

<details><summary><b>AutoDIME: Automatic Design of Interesting Multi-Agent Environments</b>
<a href="https://arxiv.org/abs/2203.02481">arxiv:2203.02481</a>
&#x1F4C8; 22 <br>
<p>Ingmar Kanitscheider, Harri Edwards</p></summary>
<p>

**Abstract:** Designing a distribution of environments in which RL agents can learn interesting and useful skills is a challenging and poorly understood task, for multi-agent environments the difficulties are only exacerbated. One approach is to train a second RL agent, called a teacher, who samples environments that are conducive for the learning of student agents. However, most previous proposals for teacher rewards do not generalize straightforwardly to the multi-agent setting. We examine a set of intrinsic teacher rewards derived from prediction problems that can be applied in multi-agent settings and evaluate them in Mujoco tasks such as multi-agent Hide and Seek as well as a diagnostic single-agent maze task. Of the intrinsic rewards considered we found value disagreement to be most consistent across tasks, leading to faster and more reliable emergence of advanced skills in Hide and Seek and the maze task. Another candidate intrinsic reward considered, value prediction error, also worked well in Hide and Seek but was susceptible to noisy-TV style distractions in stochastic environments. Policy disagreement performed well in the maze task but did not speed up learning in Hide and Seek. Our results suggest that intrinsic teacher rewards, and in particular value disagreement, are a promising approach for automating both single and multi-agent environment design.

</p>
</details>

<details><summary><b>iSTFTNet: Fast and Lightweight Mel-Spectrogram Vocoder Incorporating Inverse Short-Time Fourier Transform</b>
<a href="https://arxiv.org/abs/2203.02395">arxiv:2203.02395</a>
&#x1F4C8; 21 <br>
<p>Takuhiro Kaneko, Kou Tanaka, Hirokazu Kameoka, Shogo Seki</p></summary>
<p>

**Abstract:** In recent text-to-speech synthesis and voice conversion systems, a mel-spectrogram is commonly applied as an intermediate representation, and the necessity for a mel-spectrogram vocoder is increasing. A mel-spectrogram vocoder must solve three inverse problems: recovery of the original-scale magnitude spectrogram, phase reconstruction, and frequency-to-time conversion. A typical convolutional mel-spectrogram vocoder solves these problems jointly and implicitly using a convolutional neural network, including temporal upsampling layers, when directly calculating a raw waveform. Such an approach allows skipping redundant processes during waveform synthesis (e.g., the direct reconstruction of high-dimensional original-scale spectrograms). By contrast, the approach solves all problems in a black box and cannot effectively employ the time-frequency structures existing in a mel-spectrogram. We thus propose iSTFTNet, which replaces some output-side layers of the mel-spectrogram vocoder with the inverse short-time Fourier transform (iSTFT) after sufficiently reducing the frequency dimension using upsampling layers, reducing the computational cost from black-box modeling and avoiding redundant estimations of high-dimensional spectrograms. During our experiments, we applied our ideas to three HiFi-GAN variants and made the models faster and more lightweight with a reasonable speech quality. Audio samples are available at https://www.kecl.ntt.co.jp/people/kaneko.takuhiro/projects/istftnet/.

</p>
</details>

<details><summary><b>The Familiarity Hypothesis: Explaining the Behavior of Deep Open Set Methods</b>
<a href="https://arxiv.org/abs/2203.02486">arxiv:2203.02486</a>
&#x1F4C8; 18 <br>
<p>Thomas G. Dietterich, Alexander Guyer</p></summary>
<p>

**Abstract:** In many object recognition applications, the set of possible categories is an open set, and the deployed recognition system will encounter novel objects belonging to categories unseen during training. Detecting such "novel category" objects is usually formulated as an anomaly detection problem. Anomaly detection algorithms for feature-vector data identify anomalies as outliers, but outlier detection has not worked well in deep learning. Instead, methods based on the computed logits of visual object classifiers give state-of-the-art performance. This paper proposes the Familiarity Hypothesis that these methods succeed because they are detecting the absence of familiar learned features rather than the presence of novelty. The paper reviews evidence from the literature and presents additional evidence from our own experiments that provide strong support for this hypothesis. The paper concludes with a discussion of whether familiarity detection is an inevitable consequence of representation learning.

</p>
</details>

<details><summary><b>Do Explanations Explain? Model Knows Best</b>
<a href="https://arxiv.org/abs/2203.02269">arxiv:2203.02269</a>
&#x1F4C8; 15 <br>
<p>Ashkan Khakzar, Pedram Khorsandi, Rozhin Nobahari, Nassir Navab</p></summary>
<p>

**Abstract:** It is a mystery which input features contribute to a neural network's output. Various explanation (feature attribution) methods are proposed in the literature to shed light on the problem. One peculiar observation is that these explanations (attributions) point to different features as being important. The phenomenon raises the question, which explanation to trust? We propose a framework for evaluating the explanations using the neural network model itself. The framework leverages the network to generate input features that impose a particular behavior on the output. Using the generated features, we devise controlled experimental setups to evaluate whether an explanation method conforms to an axiom. Thus we propose an empirical framework for axiomatic evaluation of explanation methods. We evaluate well-known and promising explanation solutions using the proposed framework. The framework provides a toolset to reveal properties and drawbacks within existing and future explanation solutions.

</p>
</details>

<details><summary><b>BoostMIS: Boosting Medical Image Semi-supervised Learning with Adaptive Pseudo Labeling and Informative Active Annotation</b>
<a href="https://arxiv.org/abs/2203.02533">arxiv:2203.02533</a>
&#x1F4C8; 10 <br>
<p>Wenqiao Zhang, Lei Zhu, James Hallinan, Andrew Makmur, Shengyu Zhang, Qingpeng Cai, Beng Chin Ooi</p></summary>
<p>

**Abstract:** In this paper, we propose a novel semi-supervised learning (SSL) framework named BoostMIS that combines adaptive pseudo labeling and informative active annotation to unleash the potential of medical image SSL models: (1) BoostMIS can adaptively leverage the cluster assumption and consistency regularization of the unlabeled data according to the current learning status. This strategy can adaptively generate one-hot ``hard'' labels converted from task model predictions for better task model training. (2) For the unselected unlabeled images with low confidence, we introduce an Active learning (AL) algorithm to find the informative samples as the annotation candidates by exploiting virtual adversarial perturbation and model's density-aware entropy. These informative candidates are subsequently fed into the next training cycle for better SSL label propagation. Notably, the adaptive pseudo-labeling and informative active annotation form a learning closed-loop that are mutually collaborative to boost medical image SSL. To verify the effectiveness of the proposed method, we collected a metastatic epidural spinal cord compression (MESCC) dataset that aims to optimize MESCC diagnosis and classification for improved specialist referral and treatment. We conducted an extensive experimental study of BoostMIS on MESCC and another public dataset COVIDx. The experimental results verify our framework's effectiveness and generalisability for different medical image datasets with a significant improvement over various state-of-the-art methods.

</p>
</details>

<details><summary><b>Show Me What and Tell Me How: Video Synthesis via Multimodal Conditioning</b>
<a href="https://arxiv.org/abs/2203.02573">arxiv:2203.02573</a>
&#x1F4C8; 9 <br>
<p>Ligong Han, Jian Ren, Hsin-Ying Lee, Francesco Barbieri, Kyle Olszewski, Shervin Minaee, Dimitris Metaxas, Sergey Tulyakov</p></summary>
<p>

**Abstract:** Most methods for conditional video synthesis use a single modality as the condition. This comes with major limitations. For example, it is problematic for a model conditioned on an image to generate a specific motion trajectory desired by the user since there is no means to provide motion information. Conversely, language information can describe the desired motion, while not precisely defining the content of the video. This work presents a multimodal video generation framework that benefits from text and images provided jointly or separately. We leverage the recent progress in quantized representations for videos and apply a bidirectional transformer with multiple modalities as inputs to predict a discrete video representation. To improve video quality and consistency, we propose a new video token trained with self-learning and an improved mask-prediction algorithm for sampling video tokens. We introduce text augmentation to improve the robustness of the textual representation and diversity of generated videos. Our framework can incorporate various visual modalities, such as segmentation masks, drawings, and partially occluded images. It can generate much longer sequences than the one used for training. In addition, our model can extract visual information as suggested by the text prompt, e.g., "an object in image one is moving northeast", and generate corresponding videos. We run evaluations on three public datasets and a newly collected dataset labeled with facial attributes, achieving state-of-the-art generation results on all four.

</p>
</details>

<details><summary><b>Visibility-Inspired Models of Touch Sensors for Navigation</b>
<a href="https://arxiv.org/abs/2203.04751">arxiv:2203.04751</a>
&#x1F4C8; 7 <br>
<p>Kshitij Tiwari, Basak Sakcak, Prasanna Routray, Manivannan M., Steven M. LaValle</p></summary>
<p>

**Abstract:** This paper introduces mathematical models of touch sensors for mobile robotics based on visibility. Serving a purpose similar to the pinhole camera model for computer vision, the introduced models are expected to provide a useful, idealized characterization of task-relevant information that can be inferred from their outputs or observations. This allows direct comparisons to be made between traditional depth sensors, highlighting cases in which touch sensing may be interchangeable with time of flight or vision sensors, and characterizing unique advantages provided by touch sensing. The models include contact detection, compression, load bearing, and deflection. The results could serve as a basic building block for innovative touch sensor designs for mobile robot sensor fusion systems.

</p>
</details>

<details><summary><b>CoNIC Solution</b>
<a href="https://arxiv.org/abs/2203.03415">arxiv:2203.03415</a>
&#x1F4C8; 7 <br>
<p>Wenhua Zhang</p></summary>
<p>

**Abstract:** Nuclei segmentation and classification has been a challenge due to the high inter-class similarity and intra-class variability. Thus, a large-scale annotation and a specially-designed algorithm are needed to solve this problem. Lizard is therefore a great promotion in this area, containing around half a million nuclei annotated. In this paper, we propose a two-stage pipeline used in the CoNIC competition, which achieves much better results than the baseline method. We adopt a similar model as the original baseline method: HoVerNet, as the segmentaion model and then develop a new classification model to fine-tune the classification results. Code for this method will be made public soon. This is a conic solution in testing.

</p>
</details>

<details><summary><b>Exploring Scalable, Distributed Real-Time Anomaly Detection for Bridge Health Monitoring</b>
<a href="https://arxiv.org/abs/2203.02380">arxiv:2203.02380</a>
&#x1F4C8; 7 <br>
<p>Amirhossein Moallemi, Alessio Burrello, Davide Brunelli, Luca Benini</p></summary>
<p>

**Abstract:** Modern real-time Structural Health Monitoring systems can generate a considerable amount of information that must be processed and evaluated for detecting early anomalies and generating prompt warnings and alarms about the civil infrastructure conditions. The current cloud-based solutions cannot scale if the raw data has to be collected from thousands of buildings. This paper presents a full-stack deployment of an efficient and scalable anomaly detection pipeline for SHM systems which does not require sending raw data to the cloud but relies on edge computation. First, we benchmark three algorithmic approaches of anomaly detection, i.e., Principal Component Analysis (PCA), Fully-Connected AutoEncoder (FC-AE), and Convolutional AutoEncoder (C-AE). Then, we deploy them on an edge-sensor, the STM32L4, with limited computing capabilities. Our approach decreases network traffic by $\approx8\cdot10^5\times$ , from 780KB/hour to less than 10 Bytes/hour for a single installation and minimize network and cloud resource utilization, enabling the scaling of the monitoring infrastructure. A real-life case study, a highway bridge in Italy, demonstrates that combining near-sensor computation of anomaly detection algorithms, smart pre-processing, and low-power wide-area network protocols (LPWAN) we can greatly reduce data communication and cloud computing costs, while anomaly detection accuracy is not adversely affected.

</p>
</details>

<details><summary><b>Uncertainty Estimation for Heatmap-based Landmark Localization</b>
<a href="https://arxiv.org/abs/2203.02351">arxiv:2203.02351</a>
&#x1F4C8; 7 <br>
<p>Lawrence Schobs, Andrew J. Swift, Haiping Lu</p></summary>
<p>

**Abstract:** Automatic anatomical landmark localization has made great strides by leveraging deep learning methods in recent years. The ability to quantify the uncertainty of these predictions is a vital ingredient needed to see these methods adopted in clinical use, where it is imperative that erroneous predictions are caught and corrected. We propose Quantile Binning, a data-driven method to categorise predictions by uncertainty with estimated error bounds. This framework can be applied to any continuous uncertainty measure, allowing straightforward identification of the best subset of predictions with accompanying estimated error bounds. We facilitate easy comparison between uncertainty measures by constructing two evaluation metrics derived from Quantile Binning. We demonstrate this framework by comparing and contrasting three uncertainty measures (a baseline, the current gold standard, and a proposed method combining aspects of the two), across two datasets (one easy, one hard) and two heatmap-based landmark localization model paradigms (U-Net and patch-based). We conclude by illustrating how filtering out gross mispredictions caught in our Quantile Bins significantly improves the proportion of predictions under an acceptable error threshold, and offer recommendations on which uncertainty measure to use and how to use it.

</p>
</details>

<details><summary><b>Voice-Face Homogeneity Tells Deepfake</b>
<a href="https://arxiv.org/abs/2203.02195">arxiv:2203.02195</a>
&#x1F4C8; 7 <br>
<p>Harry Cheng, Yangyang Guo, Tianyi Wang, Qi Li, Tao Ye, Liqiang Nie</p></summary>
<p>

**Abstract:** Detecting forgery videos is highly desired due to the abuse of deepfake. Existing detection approaches contribute to exploring the specific artifacts in deepfake videos and fit well on certain data. However, the growing technique on these artifacts keeps challenging the robustness of traditional deepfake detectors. As a result, the development of generalizability of these approaches has reached a blockage. To address this issue, given the empirical results that the identities behind voices and faces are often mismatched in deepfake videos, and the voices and faces have homogeneity to some extent, in this paper, we propose to perform the deepfake detection from an unexplored voice-face matching view. To this end, a voice-face matching detection model is devised to measure the matching degree of these two on a generic audio-visual dataset. Thereafter, this model can be smoothly transferred to deepfake datasets without any fine-tuning, and the generalization across datasets is accordingly enhanced. We conduct extensive experiments over two widely exploited datasets - DFDC and FakeAVCeleb. Our model obtains significantly improved performance as compared to other state-of-the-art competitors and maintains favorable generalizability. The code has been released at https://github.com/xaCheng1996/VFD.

</p>
</details>

<details><summary><b>Safe Reinforcement Learning for Legged Locomotion</b>
<a href="https://arxiv.org/abs/2203.02638">arxiv:2203.02638</a>
&#x1F4C8; 6 <br>
<p>Tsung-Yen Yang, Tingnan Zhang, Linda Luu, Sehoon Ha, Jie Tan, Wenhao Yu</p></summary>
<p>

**Abstract:** Designing control policies for legged locomotion is complex due to the under-actuated and non-continuous robot dynamics. Model-free reinforcement learning provides promising tools to tackle this challenge. However, a major bottleneck of applying model-free reinforcement learning in real world is safety. In this paper, we propose a safe reinforcement learning framework that switches between a safe recovery policy that prevents the robot from entering unsafe states, and a learner policy that is optimized to complete the task. The safe recovery policy takes over the control when the learner policy violates safety constraints, and hands over the control back when there are no future safety violations. We design the safe recovery policy so that it ensures safety of legged locomotion while minimally intervening in the learning process. Furthermore, we theoretically analyze the proposed framework and provide an upper bound on the task performance. We verify the proposed framework in four locomotion tasks on a simulated and real quadrupedal robot: efficient gait, catwalk, two-leg balance, and pacing. On average, our method achieves 48.6% fewer falls and comparable or better rewards than the baseline methods in simulation. When deployed it on real-world quadruped robot, our training pipeline enables 34% improvement in energy efficiency for the efficient gait, 40.9% narrower of the feet placement in the catwalk, and two times more jumping duration in the two-leg balance. Our method achieves less than five falls over the duration of 115 minutes of hardware time.

</p>
</details>

<details><summary><b>Pedestrian Stop and Go Forecasting with Hybrid Feature Fusion</b>
<a href="https://arxiv.org/abs/2203.02489">arxiv:2203.02489</a>
&#x1F4C8; 6 <br>
<p>Dongxu Guo, Taylor Mordan, Alexandre Alahi</p></summary>
<p>

**Abstract:** Forecasting pedestrians' future motions is essential for autonomous driving systems to safely navigate in urban areas. However, existing prediction algorithms often overly rely on past observed trajectories and tend to fail around abrupt dynamic changes, such as when pedestrians suddenly start or stop walking. We suggest that predicting these highly non-linear transitions should form a core component to improve the robustness of motion prediction algorithms. In this paper, we introduce the new task of pedestrian stop and go forecasting. Considering the lack of suitable existing datasets for it, we release TRANS, a benchmark for explicitly studying the stop and go behaviors of pedestrians in urban traffic. We build it from several existing datasets annotated with pedestrians' walking motions, in order to have various scenarios and behaviors. We also propose a novel hybrid model that leverages pedestrian-specific and scene features from several modalities, both video sequences and high-level attributes, and gradually fuses them to integrate multiple levels of context. We evaluate our model and several baselines on TRANS, and set a new benchmark for the community to work on pedestrian stop and go forecasting.

</p>
</details>

<details><summary><b>Behavioural Curves Analysis Using Near-Infrared-Iris Image Sequences</b>
<a href="https://arxiv.org/abs/2203.02488">arxiv:2203.02488</a>
&#x1F4C8; 6 <br>
<p>L. Causa, J. E. Tapia, E. Lopez-Droguett, A. Valenzuela, D. Benalcazar, C. Busch</p></summary>
<p>

**Abstract:** This paper proposes a new method to estimate behavioural curves from a stream of Near-Infra-Red (NIR) iris video frames. This method can be used in a Fitness For Duty system (FFD). The research focuses on determining the effect of external factors such as alcohol, drugs, and sleepiness on the Central Nervous System (CNS). The aim is to analyse how this behaviour is represented on iris and pupil movements and if it is possible to capture these changes with a standard NIR camera. The behaviour analysis showed essential differences in pupil and iris behaviour to classify the workers in "Fit" or "Unfit" conditions. The best results can distinguish subjects robustly under alcohol, drug consumption, and sleep conditions. The Multi-Layer-Perceptron and Gradient Boosted Machine reached the best results in all groups with an overall accuracy for Fit and Unfit classes of 74.0% and 75.5%, respectively. These results open a new application for iris capture devices.

</p>
</details>

<details><summary><b>Differentiable Control Barrier Functions for Vision-based End-to-End Autonomous Driving</b>
<a href="https://arxiv.org/abs/2203.02401">arxiv:2203.02401</a>
&#x1F4C8; 6 <br>
<p>Wei Xiao, Tsun-Hsuan Wang, Makram Chahine, Alexander Amini, Ramin Hasani, Daniela Rus</p></summary>
<p>

**Abstract:** Guaranteeing safety of perception-based learning systems is challenging due to the absence of ground-truth state information unlike in state-aware control scenarios. In this paper, we introduce a safety guaranteed learning framework for vision-based end-to-end autonomous driving. To this end, we design a learning system equipped with differentiable control barrier functions (dCBFs) that is trained end-to-end by gradient descent. Our models are composed of conventional neural network architectures and dCBFs. They are interpretable at scale, achieve great test performance under limited training data, and are safety guaranteed in a series of autonomous driving scenarios such as lane keeping and obstacle avoidance. We evaluated our framework in a sim-to-real environment, and tested on a real autonomous car, achieving safe lane following and obstacle avoidance via Augmented Reality (AR) and real parked vehicles.

</p>
</details>

<details><summary><b>Plan Your Target and Learn Your Skills: Transferable State-Only Imitation Learning via Decoupled Policy Optimization</b>
<a href="https://arxiv.org/abs/2203.02214">arxiv:2203.02214</a>
&#x1F4C8; 6 <br>
<p>Minghuan Liu, Zhengbang Zhu, Yuzheng Zhuang, Weinan Zhang, Jianye Hao, Yong Yu, Jun Wang</p></summary>
<p>

**Abstract:** Recent progress in state-only imitation learning extends the scope of applicability of imitation learning to real-world settings by relieving the need for observing expert actions. However, existing solutions only learn to extract a state-to-action mapping policy from the data, without considering how the expert plans to the target. This hinders the ability to leverage demonstrations and limits the flexibility of the policy. In this paper, we introduce Decoupled Policy Optimization (DePO), which explicitly decouples the policy as a high-level state planner and an inverse dynamics model. With embedded decoupled policy gradient and generative adversarial training, DePO enables knowledge transfer to different action spaces or state transition dynamics, and can generalize the planner to out-of-demonstration state regions. Our in-depth experimental analysis shows the effectiveness of DePO on learning a generalized target state planner while achieving the best imitation performance. We demonstrate the appealing usage of DePO for transferring across different tasks by pre-training, and the potential for co-training agents with various skills.

</p>
</details>

<details><summary><b>Low-cost prediction of molecular and transition state partition functions via machine learning</b>
<a href="https://arxiv.org/abs/2203.02621">arxiv:2203.02621</a>
&#x1F4C8; 5 <br>
<p>Evan Komp, StÃ©phanie Valleau</p></summary>
<p>

**Abstract:** We have generated an open-source dataset of over 30000 organic chemistry gas phase partition functions. With this data, a machine learning deep neural network estimator was trained to predict partition functions of unknown organic chemistry gas phase transition states. This estimator only relies on reactant and product geometries and partition functions. A second machine learning deep neural network was trained to predict partition functions of chemical species from their geometry. Our models accurately predict the logarithm of test set partition functions with a maximum mean absolute error of 2.7%. Thus, this approach provides a means to reduce the cost of computing reaction rate constants ab initio. The models were also used to compute transition state theory reaction rate constants prefactors and the results were in quantitative agreement with the corresponding ab initio calculations with an accuracy of 98.3% on the log scale.

</p>
</details>

<details><summary><b>Better Supervisory Signals by Observing Learning Paths</b>
<a href="https://arxiv.org/abs/2203.02485">arxiv:2203.02485</a>
&#x1F4C8; 5 <br>
<p>Yi Ren, Shangmin Guo, Danica J. Sutherland</p></summary>
<p>

**Abstract:** Better-supervised models might have better performance. In this paper, we first clarify what makes for good supervision for a classification problem, and then explain two existing label refining methods, label smoothing and knowledge distillation, in terms of our proposed criterion. To further answer why and how better supervision emerges, we observe the learning path, i.e., the trajectory of the model's predictions during training, for each training sample. We find that the model can spontaneously refine "bad" labels through a "zig-zag" learning path, which occurs on both toy and real datasets. Observing the learning path not only provides a new perspective for understanding knowledge distillation, overfitting, and learning dynamics, but also reveals that the supervisory signal of a teacher network can be very unstable near the best points in training on real tasks. Inspired by this, we propose a new knowledge distillation scheme, Filter-KD, which improves downstream classification performance in various settings.

</p>
</details>

<details><summary><b>Contextformer: A Transformer with Spatio-Channel Attention for Context Modeling in Learned Image Compression</b>
<a href="https://arxiv.org/abs/2203.02452">arxiv:2203.02452</a>
&#x1F4C8; 5 <br>
<p>A. Burakhan Koyuncu, Han Gao, Eckehard Steinbach</p></summary>
<p>

**Abstract:** Entropy modeling is a key component for high-performance image compression algorithms. Recent developments in autoregressive context modeling helped learning-based methods to surpass their classical counterparts. However, the performance of those models can be further improved due to the underexploited spatio-channel dependencies in latent space, and the suboptimal implementation of context adaptivity. Inspired by the adaptive characteristics of the transformers, we propose a transformer-based context model, a.k.a. Contextformer, which generalizes the de facto standard attention mechanism to spatio-channel attention. We replace the context model of a modern compression framework with the Contextformer and test it on the widely used Kodak image dataset. Our experimental results show that the proposed model provides up to 10% rate savings compared to the standard Versatile Video Coding (VVC) Test Model (VTM) 9.1, and outperforms various learning-based models.

</p>
</details>

<details><summary><b>Quantum Approximate Optimization Algorithm for Bayesian network structure learning</b>
<a href="https://arxiv.org/abs/2203.02400">arxiv:2203.02400</a>
&#x1F4C8; 5 <br>
<p>Vicente P. Soloviev, Concha Bielza, Pedro LarraÃ±aga</p></summary>
<p>

**Abstract:** Bayesian network structure learning is an NP-hard problem that has been faced by a number of traditional approaches in recent decades. Currently, quantum technologies offer a wide range of advantages that can be exploited to solve optimization tasks that cannot be addressed in an efficient way when utilizing classic computing approaches. In this work, a specific type of variational quantum algorithm, the quantum approximate optimization algorithm, was used to solve the Bayesian network structure learning problem, by employing $3n(n-1)/2$ qubits, where $n$ is the number of nodes in the Bayesian network to be learned. Our results showed that the quantum approximate optimization algorithm approach offers competitive results with state-of-the-art methods and quantitative resilience to quantum noise. The approach was applied to a cancer benchmark problem, and the results justified the use of variational quantum algorithms for solving the Bayesian network structure learning problem.

</p>
</details>

<details><summary><b>Mobile authentication of copy detection patterns</b>
<a href="https://arxiv.org/abs/2203.02397">arxiv:2203.02397</a>
&#x1F4C8; 5 <br>
<p>Olga Taran, Joakim Tutt, Taras Holotyak, Roman Chaban, Slavi Bonev, Slava Voloshynovskiy</p></summary>
<p>

**Abstract:** In the recent years, the copy detection patterns (CDP) attracted a lot of attention as a link between the physical and digital worlds, which is of great interest for the internet of things and brand protection applications. However, the security of CDP in terms of their reproducibility by unauthorized parties or clonability remains largely unexplored. In this respect this paper addresses a problem of anti-counterfeiting of physical objects and aims at investigating the authentication aspects and the resistances to illegal copying of the modern CDP from machine learning perspectives. A special attention is paid to a reliable authentication under the real life verification conditions when the codes are printed on an industrial printer and enrolled via modern mobile phones under regular light conditions. The theoretical and empirical investigation of authentication aspects of CDP is performed with respect to four types of copy fakes from the point of view of (i) multi-class supervised classification as a baseline approach and (ii) one-class classification as a real-life application case. The obtained results show that the modern machine-learning approaches and the technical capacities of modern mobile phones allow to reliably authenticate CDP on end-user mobile phones under the considered classes of fakes.

</p>
</details>

<details><summary><b>AutoMO-Mixer: An automated multi-objective Mixer model for balanced, safe and robust prediction in medicine</b>
<a href="https://arxiv.org/abs/2203.02384">arxiv:2203.02384</a>
&#x1F4C8; 5 <br>
<p>Xi Chen, Jiahuan Lv, Dehua Feng, Xuanqin Mou, Ling Bai, Shu Zhang, Zhiguo Zhou</p></summary>
<p>

**Abstract:** Accurately identifying patient's status through medical images plays an important role in diagnosis and treatment. Artificial intelligence (AI), especially the deep learning, has achieved great success in many fields. However, more reliable AI model is needed in image guided diagnosis and therapy. To achieve this goal, developing a balanced, safe and robust model with a unified framework is desirable. In this study, a new unified model termed as automated multi-objective Mixer (AutoMO-Mixer) model was developed, which utilized a recent developed multiple layer perceptron Mixer (MLP-Mixer) as base. To build a balanced model, sensitivity and specificity were considered as the objective functions simultaneously in training stage. Meanwhile, a new evidential reasoning based on entropy was developed to achieve a safe and robust model in testing stage. The experiment on an optical coherence tomography dataset demonstrated that AutoMO-Mixer can obtain safer, more balanced, and robust results compared with MLP-Mixer and other available models.

</p>
</details>

<details><summary><b>Mixed Reality Depth Contour Occlusion Using Binocular Similarity Matching and Three-dimensional Contour Optimisation</b>
<a href="https://arxiv.org/abs/2203.02300">arxiv:2203.02300</a>
&#x1F4C8; 5 <br>
<p>Naye Ji, Fan Zhang, Haoxiang Zhang, Youbing Zhao, Dingguo Yu</p></summary>
<p>

**Abstract:** Mixed reality applications often require virtual objects that are partly occluded by real objects. However, previous research and commercial products have limitations in terms of performance and efficiency. To address these challenges, we propose a novel depth contour occlusion (DCO) algorithm. The proposed method is based on the sensitivity of contour occlusion and a binocular stereoscopic vision device. In this method, a depth contour map is combined with a sparse depth map obtained from a two-stage adaptive filter area stereo matching algorithm and the depth contour information of the objects extracted by a digital image stabilisation optical flow method. We also propose a quadratic optimisation model with three constraints to generate an accurate dense map of the depth contour for high-quality real-virtual occlusion. The whole process is accelerated by GPU. To evaluate the effectiveness of the algorithm, we demonstrate a time con-sumption statistical analysis for each stage of the DCO algorithm execution. To verify the relia-bility of the real-virtual occlusion effect, we conduct an experimental analysis on single-sided, enclosed, and complex occlusions; subsequently, we compare it with the occlusion method without quadratic optimisation. With our GPU implementation for real-time DCO, the evaluation indicates that applying the presented DCO algorithm can enhance the real-time performance and the visual quality of real-virtual occlusion.

</p>
</details>

<details><summary><b>HDNet: High-resolution Dual-domain Learning for Spectral Compressive Imaging</b>
<a href="https://arxiv.org/abs/2203.02149">arxiv:2203.02149</a>
&#x1F4C8; 5 <br>
<p>Xiaowan Hu, Yuanhao Cai, Jing Lin, Haoqian Wang, Xin Yuan, Yulun Zhang, Radu Timofte, Luc Van Gool</p></summary>
<p>

**Abstract:** The rapid development of deep learning provides a better solution for the end-to-end reconstruction of hyperspectral image (HSI). However, existing learning-based methods have two major defects. Firstly, networks with self-attention usually sacrifice internal resolution to balance model performance against complexity, losing fine-grained high-resolution (HR) features. Secondly, even if the optimization focusing on spatial-spectral domain learning (SDL) converges to the ideal solution, there is still a significant visual difference between the reconstructed HSI and the truth. Therefore, we propose a high-resolution dual-domain learning network (HDNet) for HSI reconstruction. On the one hand, the proposed HR spatial-spectral attention module with its efficient feature fusion provides continuous and fine pixel-level features. On the other hand, frequency domain learning (FDL) is introduced for HSI reconstruction to narrow the frequency domain discrepancy. Dynamic FDL supervision forces the model to reconstruct fine-grained frequencies and compensate for excessive smoothing and distortion caused by pixel-level losses. The HR pixel-level attention and frequency-level refinement in our HDNet mutually promote HSI perceptual quality. Extensive quantitative and qualitative evaluation experiments show that our method achieves SOTA performance on simulated and real HSI datasets. Code and models will be released.

</p>
</details>

<details><summary><b>Continual Few-shot Relation Learning via Embedding Space Regularization and Data Augmentation</b>
<a href="https://arxiv.org/abs/2203.02135">arxiv:2203.02135</a>
&#x1F4C8; 5 <br>
<p>Chengwei Qin, Shafiq Joty</p></summary>
<p>

**Abstract:** Existing continual relation learning (CRL) methods rely on plenty of labeled training data for learning a new task, which can be hard to acquire in real scenario as getting large and representative labeled data is often expensive and time-consuming. It is therefore necessary for the model to learn novel relational patterns with very few labeled data while avoiding catastrophic forgetting of previous task knowledge. In this paper, we formulate this challenging yet practical problem as continual few-shot relation learning (CFRL). Based on the finding that learning for new emerging few-shot tasks often results in feature distributions that are incompatible with previous tasks' learned distributions, we propose a novel method based on embedding space regularization and data augmentation. Our method generalizes to new few-shot tasks and avoids catastrophic forgetting of previous tasks by enforcing extra constraints on the relational embeddings and by adding extra {relevant} data in a self-supervised manner. With extensive experiments we demonstrate that our method can significantly outperform previous state-of-the-art methods in CFRL task settings.

</p>
</details>

<details><summary><b>Mammograms Classification: A Review</b>
<a href="https://arxiv.org/abs/2203.03618">arxiv:2203.03618</a>
&#x1F4C8; 4 <br>
<p>Marawan Elbatel</p></summary>
<p>

**Abstract:** An advanced reliable low-cost form of screening method, Digital mammography has been used as an effective imaging method for breast cancer detection. With an increased focus on technologies to aid healthcare, Mammogram images have been utilized in developing computer-aided diagnosis systems that will potentially help in clinical diagnosis. Researchers have proved that artificial intelligence with its emerging technologies can be used in the early detection of the disease and improve radiologists' performance in assessing breast cancer. In this paper, we review the methods developed for mammogram mass classification in two categories. The first one is classifying manually provided cropped region of interests (ROI) as either malignant or benign, and the second one is the classification of automatically segmented ROIs as either malignant or benign. We also provide an overview of datasets and evaluation metrics used in the classification task. Finally, we compare and discuss the deep learning approach to classical image processing and learning approach in this domain.

</p>
</details>

<details><summary><b>Acceleration of Federated Learning with Alleviated Forgetting in Local Training</b>
<a href="https://arxiv.org/abs/2203.02645">arxiv:2203.02645</a>
&#x1F4C8; 4 <br>
<p>Chencheng Xu, Zhiwei Hong, Minlie Huang, Tao Jiang</p></summary>
<p>

**Abstract:** Federated learning (FL) enables distributed optimization of machine learning models while protecting privacy by independently training local models on each client and then aggregating parameters on a central server, thereby producing an effective global model. Although a variety of FL algorithms have been proposed, their training efficiency remains low when the data are not independently and identically distributed (non-i.i.d.) across different clients. We observe that the slow convergence rates of the existing methods are (at least partially) caused by the catastrophic forgetting issue during the local training stage on each individual client, which leads to a large increase in the loss function concerning the previous training data at the other clients. Here, we propose FedReg, an algorithm to accelerate FL with alleviated knowledge forgetting in the local training stage by regularizing locally trained parameters with the loss on generated pseudo data, which encode the knowledge of previous training data learned by the global model. Our comprehensive experiments demonstrate that FedReg not only significantly improves the convergence rate of FL, especially when the neural network architecture is deep and the clients' data are extremely non-i.i.d., but is also able to protect privacy better in classification problems and more robust against gradient inversion attacks. The code is available at: https://github.com/Zoesgithub/FedReg.

</p>
</details>

<details><summary><b>Machine Learning Simulates Agent-Based Model Towards Policy</b>
<a href="https://arxiv.org/abs/2203.02576">arxiv:2203.02576</a>
&#x1F4C8; 4 <br>
<p>Bernardo Alves Furtado, Gustavo Onofre AndreÃ£o</p></summary>
<p>

**Abstract:** Public Policies are not intrinsically positive or negative. Rather, policies provide varying levels of effects across different recipients. Methodologically, computational modeling enables the application of a combination of multiple influences on empirical data, thus allowing for heterogeneous response to policies. We use a random forest machine learning algorithm to emulate an agent-based model (ABM) and evaluate competing policies across 46 Metropolitan Regions (MRs) in Brazil. In doing so, we use input parameters and output indicators of 11,076 actual simulation runs and one million emulated runs. As a result, we obtain the optimal (and non-optimal) performance of each region over the policies. Optimum is defined as a combination of production and inequality indicators for the full ensemble of MRs. Results suggest that MRs already have embedded structures that favor optimal or non-optimal results, but they also illustrate which policy is more beneficial to each place. In addition to providing MR-specific policies' results, the use of machine learning to simulate an ABM reduces the computational burden, whereas allowing for a much larger variation among model parameters. The coherence of results within the context of larger uncertainty -- vis-Ã -vis those of the original ABM -- suggests an additional test of robustness of the model. At the same time the exercise indicates which parameters should policymakers intervene, in order to work towards optimum of MRs.

</p>
</details>

<details><summary><b>Style-ERD: Responsive and Coherent Online Motion Style Transfer</b>
<a href="https://arxiv.org/abs/2203.02574">arxiv:2203.02574</a>
&#x1F4C8; 4 <br>
<p>Tianxin Tao, Xiaohang Zhan, Zhongquan Chen, Michiel van de Panne</p></summary>
<p>

**Abstract:** Motion style transfer is a common method for enriching character animation. Motion style transfer algorithms are often designed for offline settings where motions are processed in segments. However, for online animation applications, such as realtime avatar animation from motion capture, motions need to be processed as a stream with minimal latency. In this work, we realize a flexible, high-quality motion style transfer method for this setting. We propose a novel style transfer model, Style-ERD, to stylize motions in an online manner with an Encoder-Recurrent-Decoder structure, along with a novel discriminator that combines feature attention and temporal attention. Our method stylizes motions into multiple target styles with a unified model. Although our method targets online settings, it outperforms previous offline methods in motion realism and style expressiveness and provides significant gains in runtime efficiency

</p>
</details>

<details><summary><b>Rate-Distortion Theoretic Generalization Bounds for Stochastic Learning Algorithms</b>
<a href="https://arxiv.org/abs/2203.02474">arxiv:2203.02474</a>
&#x1F4C8; 4 <br>
<p>Milad Sefidgaran, Amin Gohari, GaÃ«l Richard, Umut ÅimÅekli</p></summary>
<p>

**Abstract:** Understanding generalization in modern machine learning settings has been one of the major challenges in statistical learning theory. In this context, recent years have witnessed the development of various generalization bounds suggesting different complexity notions such as the mutual information between the data sample and the algorithm output, compressibility of the hypothesis space, and the fractal dimension of the hypothesis space. While these bounds have illuminated the problem at hand from different angles, their suggested complexity notions might appear seemingly unrelated, thereby restricting their high-level impact. In this study, we prove novel generalization bounds through the lens of rate-distortion theory, and explicitly relate the concepts of mutual information, compressibility, and fractal dimensions in a single mathematical framework. Our approach consists of (i) defining a generalized notion of compressibility by using source coding concepts, and (ii) showing that the `compression error rate' can be linked to the generalization error both in expectation and with high probability. We show that in the `lossless compression' setting, we recover and improve existing mutual information-based bounds, whereas a `lossy compression' scheme allows us to link generalization to the rate-distortion dimension -- a particular notion of fractal dimension. Our results bring a more unified perspective on generalization and open up several future research directions.

</p>
</details>

<details><summary><b>Graph clustering with Boltzmann machines</b>
<a href="https://arxiv.org/abs/2203.02471">arxiv:2203.02471</a>
&#x1F4C8; 4 <br>
<p>Pierre Miasnikof, Mohammad Bagherbeik, Ali Sheikholeslami</p></summary>
<p>

**Abstract:** Graph clustering is the process of grouping vertices into densely connected sets called clusters. We tailor two mathematical programming formulations from the literature, to this problem. In doing so, we obtain a heuristic approximation to the intra-cluster density maximization problem. We use two variations of a Boltzmann machine heuristic to obtain numerical solutions. For benchmarking purposes, we compare solution quality and computational performances to those obtained using a commercial solver, Gurobi. We also compare clustering quality to the clusters obtained using the popular Louvain modularity maximization method. Our initial results clearly demonstrate the superiority of our problem formulations. They also establish the superiority of the Boltzmann machine over the traditional exact solver. In the case of smaller less complex graphs, Boltzmann machines provide the same solutions as Gurobi, but with solution times that are orders of magnitude lower. In the case of larger and more complex graphs, Gurobi fails to return meaningful results within a reasonable time frame. Finally, we also note that both our clustering formulations, the distance minimization and $K$-medoids, yield clusters of superior quality to those obtained with the Louvain algorithm.

</p>
</details>

<details><summary><b>Characterizing Renal Structures with 3D Block Aggregate Transformers</b>
<a href="https://arxiv.org/abs/2203.02430">arxiv:2203.02430</a>
&#x1F4C8; 4 <br>
<p>Xin Yu, Yucheng Tang, Yinchi Zhou, Riqiang Gao, Qi Yang, Ho Hin Lee, Thomas Li, Shunxing Bao, Yuankai Huo, Zhoubing Xu, Thomas A. Lasko, Richard G. Abramson, Bennett A. Landman</p></summary>
<p>

**Abstract:** Efficiently quantifying renal structures can provide distinct spatial context and facilitate biomarker discovery for kidney morphology. However, the development and evaluation of the transformer model to segment the renal cortex, medulla, and collecting system remains challenging due to data inefficiency. Inspired by the hierarchical structures in vision transformer, we propose a novel method using a 3D block aggregation transformer for segmenting kidney components on contrast-enhanced CT scans. We construct the first cohort of renal substructures segmentation dataset with 116 subjects under institutional review board (IRB) approval. Our method yields the state-of-the-art performance (Dice of 0.8467) against the baseline approach of 0.8308 with the data-efficient design. The Pearson R achieves 0.9891 between the proposed method and manual standards and indicates the strong correlation and reproducibility for volumetric analysis. We extend the proposed method to the public KiTS dataset, the method leads to improved accuracy compared to transformer-based approaches. We show that the 3D block aggregation transformer can achieve local communication between sequence representations without modifying self-attention, and it can serve as an accurate and efficient quantification tool for characterizing renal structures.

</p>
</details>

<details><summary><b>Benchmark Evaluation of Counterfactual Algorithms for XAI: From a White Box to a Black Box</b>
<a href="https://arxiv.org/abs/2203.02399">arxiv:2203.02399</a>
&#x1F4C8; 4 <br>
<p>Yu-Liang Chou, Chihcheng Hsieh, Catarina Moreira, Chun Ouyang, Joaquim Jorge, JoÃ£o Madeiras Pereira</p></summary>
<p>

**Abstract:** Counterfactual explanations have recently been brought to light as a potentially crucial response to obtaining human-understandable explanations from predictive models in Explainable Artificial Intelligence (XAI). Despite the fact that various counterfactual algorithms have been proposed, the state of the art research still lacks standardised protocols to evaluate the quality of counterfactual explanations. In this work, we conducted a benchmark evaluation across different model agnostic counterfactual algorithms in the literature (DiCE, WatcherCF, prototype, unjustifiedCF), and we investigated the counterfactual generation process on different types of machine learning models ranging from a white box (decision tree) to a grey-box (random forest) and a black box (neural network). We evaluated the different counterfactual algorithms using several metrics including proximity, interpretability and functionality for five datasets. The main findings of this work are the following: (1) without guaranteeing plausibility in the counterfactual generation process, one cannot have meaningful evaluation results. This means that all explainable counterfactual algorithms that do not take into consideration plausibility in their internal mechanisms cannot be evaluated with the current state of the art evaluation metrics; (2) the counterfactual generated are not impacted by the different types of machine learning models; (3) DiCE was the only tested algorithm that was able to generate actionable and plausible counterfactuals, because it provides mechanisms to constraint features; (4) WatcherCF and UnjustifiedCF are limited to continuous variables and can not deal with categorical data.

</p>
</details>

<details><summary><b>Safety-aware metrics for object detectors in autonomous driving</b>
<a href="https://arxiv.org/abs/2203.02205">arxiv:2203.02205</a>
&#x1F4C8; 4 <br>
<p>Andrea Ceccarelli, Leonardo Montecchi</p></summary>
<p>

**Abstract:** We argue that object detectors in the safety critical domain should prioritize detection of objects that are most likely to interfere with the actions of the autonomous actor. Especially, this applies to objects that can impact the actor's safety and reliability. In the context of autonomous driving, we propose new object detection metrics that reward the correct identification of objects that are most likely to interact with the subject vehicle (i.e., the actor), and that may affect its driving decision. To achieve this, we build a criticality model to reward the detection of the objects based on proximity, orientation, and relative velocity with respect to the subject vehicle. Then, we apply our model on the recent autonomous driving dataset nuScenes, and we compare eight different object detectors. Results show that, in several settings, object detectors that perform best according to the nuScenes ranking are not the preferable ones when the focus is shifted on safety and reliability.

</p>
</details>

<details><summary><b>Carbon Footprint of Selecting and Training Deep Learning Models for Medical Image Analysis</b>
<a href="https://arxiv.org/abs/2203.02202">arxiv:2203.02202</a>
&#x1F4C8; 4 <br>
<p>Raghavendra Selvan, Nikhil Bhagwat, Lasse F. Wolff Anthony, Benjamin Kanding, Erik B. Dam</p></summary>
<p>

**Abstract:** The increasing energy consumption and carbon footprint of deep learning (DL) due to growing compute requirements has become a cause of concern. In this work, we focus on the carbon footprint of developing DL models for medical image analysis (MIA), where volumetric images of high spatial resolution are handled. In this study, we present and compare the features of four tools from literature to quantify the carbon footprint of DL. Using one of these tools we estimate the carbon footprint of medical image segmentation pipelines. We choose nnU-net as the proxy for a medical image segmentation pipeline and experiment on three common datasets. With our work we hope to inform on the increasing energy costs incurred by MIA. We discuss simple strategies to cut-down the environmental impact that can make model selection and training processes more efficient.

</p>
</details>

<details><summary><b>Rethinking Reconstruction Autoencoder-Based Out-of-Distribution Detection</b>
<a href="https://arxiv.org/abs/2203.02194">arxiv:2203.02194</a>
&#x1F4C8; 4 <br>
<p>Yibo Zhou</p></summary>
<p>

**Abstract:** In some scenarios, classifier requires detecting out-of-distribution samples far from its training data. With desirable characteristics, reconstruction autoencoder-based methods deal with this problem by using input reconstruction error as a metric of novelty vs. normality. We formulate the essence of such approach as a quadruplet domain translation with an intrinsic bias to only query for a proxy of conditional data uncertainty. Accordingly, an improvement direction is formalized as maximumly compressing the autoencoder's latent space while ensuring its reconstructive power for acting as a described domain translator. From it, strategies are introduced including semantic reconstruction, data certainty decomposition and normalized L2 distance to substantially improve original methods, which together establish state-of-the-art performance on various benchmarks, e.g., the FPR@95%TPR of CIFAR-100 vs. TinyImagenet-crop on Wide-ResNet is 0.2%. Importantly, our method works without any additional data, hard-to-implement structure, time-consuming pipeline, and even harming the classification accuracy of known classes.

</p>
</details>

<details><summary><b>Triple Motion Estimation and Frame Interpolation based on Adaptive Threshold for Frame Rate Up-Conversion</b>
<a href="https://arxiv.org/abs/2203.03621">arxiv:2203.03621</a>
&#x1F4C8; 3 <br>
<p>Hanieh Naderi, Mohammad Rahmati</p></summary>
<p>

**Abstract:** In this paper, we propose a novel motion-compensated frame rate up-conversion (MC-FRUC) algorithm. The proposed algorithm creates interpolated frames by first estimating motion vectors using unilateral (jointing forward and backward) and bilateral motion estimation. Then motion vectors are combined based on adaptive threshold, in order to creates high-quality interpolated frames and reduce block artifacts. Since motion-compensated frame interpolation along unilateral motion trajectories yields holes, a new algorithm is introduced to resolve this problem. The experimental results show that the quality of the interpolated frames using the proposed algorithm is much higher than the existing algorithms.

</p>
</details>

<details><summary><b>Ensemble Knowledge Guided Sub-network Search and Fine-tuning for Filter Pruning</b>
<a href="https://arxiv.org/abs/2203.02651">arxiv:2203.02651</a>
&#x1F4C8; 3 <br>
<p>Seunghyun Lee, Byung Cheol Song</p></summary>
<p>

**Abstract:** Conventional NAS-based pruning algorithms aim to find the sub-network with the best validation performance. However, validation performance does not successfully represent test performance, i.e., potential performance. Also, although fine-tuning the pruned network to restore the performance drop is an inevitable process, few studies have handled this issue. This paper proposes a novel sub-network search and fine-tuning method that is named Ensemble Knowledge Guidance (EKG). First, we experimentally prove that the fluctuation of the loss landscape is an effective metric to evaluate the potential performance. In order to search a sub-network with the smoothest loss landscape at a low cost, we propose a pseudo-supernet built by an ensemble sub-network knowledge distillation. Next, we propose a novel fine-tuning that re-uses the information of the search phase. We store the interim sub-networks, that is, the by-products of the search phase, and transfer their knowledge into the pruned network. Note that EKG is easy to be plugged-in and computationally efficient. For example, in the case of ResNet-50, about 45% of FLOPS is removed without any performance drop in only 315 GPU hours. The implemented code is available at https://github.com/sseung0703/EKG.

</p>
</details>

<details><summary><b>Concept-based Explanations for Out-Of-Distribution Detectors</b>
<a href="https://arxiv.org/abs/2203.02586">arxiv:2203.02586</a>
&#x1F4C8; 3 <br>
<p>Jihye Choi, Jayaram Raghuram, Ryan Feng, Jiefeng Chen, Somesh Jha, Atul Prakash</p></summary>
<p>

**Abstract:** Out-of-distribution (OOD) detection plays a crucial role in ensuring the safe deployment of deep neural network (DNN) classifiers. While a myriad of methods have focused on improving the performance of OOD detectors, a critical gap remains in interpreting their decisions. We help bridge this gap by providing explanations for OOD detectors based on learned high-level concepts. We first propose two new metrics for assessing the effectiveness of a particular set of concepts for explaining OOD detectors: 1) detection completeness, which quantifies the sufficiency of concepts for explaining an OOD-detector's decisions, and 2) concept separability, which captures the distributional separation between in-distribution and OOD data in the concept space. Based on these metrics, we propose a framework for learning a set of concepts that satisfy the desired properties of detection completeness and concept separability and demonstrate the framework's effectiveness in providing concept-based explanations for diverse OOD techniques. We also show how to identify prominent concepts that contribute to the detection results via a modified Shapley value-based importance score.

</p>
</details>

<details><summary><b>Bayesian Optimization Meets Hybrid Zero Dynamics: Safe Parameter Learning for Bipedal Locomotion Control</b>
<a href="https://arxiv.org/abs/2203.02570">arxiv:2203.02570</a>
&#x1F4C8; 3 <br>
<p>Lizhi Yang, Zhongyu Li, Jun Zeng, Koushil Sreenath</p></summary>
<p>

**Abstract:** In this paper, we propose a multi-domain control parameter learning framework that combines Bayesian Optimization (BO) and Hybrid Zero Dynamics (HZD) for locomotion control of bipedal robots. We leverage BO to learn the control parameters used in the HZD-based controller. The learning process is firstly deployed in simulation to optimize different control parameters for a large repertoire of gaits. Next, to tackle the discrepancy between the simulation and the real world, the learning process is applied on the physical robot to learn for corrections to the control parameters learned in simulation while also respecting a safety constraint for gait stability. This method empowers an efficient sim-to-real transition with a small number of samples in the real world, and does not require a valid controller to initialize the training in simulation. Our proposed learning framework is experimentally deployed and validated on a bipedal robot Cassie to perform versatile locomotion skills with improved performance on smoothness of walking gaits and reduction of steady-state tracking errors.

</p>
</details>

<details><summary><b>Cellular Segmentation and Composition in Routine Histology Images using Deep Learning</b>
<a href="https://arxiv.org/abs/2203.02510">arxiv:2203.02510</a>
&#x1F4C8; 3 <br>
<p>Muhammad Dawood, Raja Muhammad Saad Bashir, Srijay Deshpande, Manahil Raza, Adam Shephard</p></summary>
<p>

**Abstract:** Identification and quantification of nuclei in colorectal cancer haematoxylin \& eosin (H\&E) stained histology images is crucial to prognosis and patient management. In computational pathology these tasks are referred to as nuclear segmentation, classification and composition and are used to extract meaningful interpretable cytological and architectural features for downstream analysis. The CoNIC challenge poses the task of automated nuclei segmentation, classification and composition into six different types of nuclei from the largest publicly known nuclei dataset - Lizard. In this regard, we have developed pipelines for the prediction of nuclei segmentation using HoVer-Net and ALBRT for cellular composition. On testing on the preliminary test set, HoVer-Net achieved a PQ of 0.58, a PQ+ of 0.58 and finally a mPQ+ of 0.35. For the prediction of cellular composition with ALBRT on the preliminary test set, we achieved an overall $R^2$ score of 0.53, consisting of 0.84 for lymphocytes, 0.70 for epithelial cells, 0.70 for plasma and .060 for eosinophils.

</p>
</details>

<details><summary><b>Computational Fluid Dynamics and Machine Learning as tools for Optimization of Micromixers geometry</b>
<a href="https://arxiv.org/abs/2203.02498">arxiv:2203.02498</a>
&#x1F4C8; 3 <br>
<p>Daniela de Oliveira Maionchi, Luca Ainstein, Fabio Pereira dos Santos, MaurÃ­cio Bezerra de Souza JÃºnior</p></summary>
<p>

**Abstract:** This work explores a new approach for optimization in the field of microfluidics, using the combination of CFD (Computational Fluid Dynamics), and Machine Learning techniques. The objective of this combination is to enable global optimization with lower computational cost. The initial geometry is inspired in a Y-type micromixer with cylindrical grooves on the surface of the main channel and obstructions inside it. Simulations for circular obstructions were carried out using the OpenFOAM software to observe the influences of obstacles. The effects of obstruction diameter (OD), and offset (OF) in the range of [20,140] mm and [10,160] mm, respectively, on percentage of mixing ($\varphi$), pressure drop ($ÎP$) and energy cost ($ÎP/\varphi$) were investigated. Numerical experiments were analyzed using machine learning. Firstly, a neural network was used to train the dataset composed by the inputs OD and OF and outputs $\varphi$ and $ÎP$. The objective functions (ObF) chosen to numerically optimize the performance of micromixers with grooves and obstructions were $\varphi$, $ÎP$, $ÎP/\varphi$. The genetic algorithm obtained the geometry that offers the maximum value of $\varphi$ and the minimum value of $ÎP_s$. The results show that $\varphi$ increases monotonically with increasing OD at all values of OF. The inverse is observed with increasing offset. Furthermore, the results reveal that $ÎP$ e $ÎP/\varphi$ also increase with OD. On the other hand, the pressure drop and the cost of mixing energy present a maximum close to the lowest values of OF. Finally, the optimal value obtained for the diameter was OD=131 mm and for the offset OF=10 mm, which corresponds to obstruction of medium size close to the channel wall.

</p>
</details>

<details><summary><b>Ontological Learning from Weak Labels</b>
<a href="https://arxiv.org/abs/2203.02483">arxiv:2203.02483</a>
&#x1F4C8; 3 <br>
<p>Larry Tang, Po Hao Chou, Yi Yu Zheng, Ziqian Ge, Ankit Shah, Bhiksha Raj</p></summary>
<p>

**Abstract:** Ontologies encompass a formal representation of knowledge through the definition of concepts or properties of a domain, and the relationships between those concepts. In this work, we seek to investigate whether using this ontological information will improve learning from weakly labeled data, which are easier to collect since it requires only the presence or absence of an event to be known. We use the AudioSet ontology and dataset, which contains audio clips weakly labeled with the ontology concepts and the ontology providing the "Is A" relations between the concepts. We first re-implemented the model proposed by soundevent_ontology with modification to fit the multi-label scenario and then expand on that idea by using a Graph Convolutional Network (GCN) to model the ontology information to learn the concepts. We find that the baseline Siamese does not perform better by incorporating ontology information in the weak and multi-label scenario, but that the GCN does capture the ontology knowledge better for weak, multi-labeled data. In our experiments, we also investigate how different modules can tolerate noises introduced from weak labels and better incorporate ontology information. Our best Siamese-GCN model achieves mAP=0.45 and AUC=0.87 for lower-level concepts and mAP=0.72 and AUC=0.86 for higher-level concepts, which is an improvement over the baseline Siamese but about the same as our models that do not use ontology information.

</p>
</details>

<details><summary><b>Cooperative Task and Motion Planning for Multi-Arm Assembly Systems</b>
<a href="https://arxiv.org/abs/2203.02475">arxiv:2203.02475</a>
&#x1F4C8; 3 <br>
<p>Jingkai Chen, Jiaoyang Li, Yijiang Huang, Caelan Garrett, Dawei Sun, Chuchu Fan, Andreas Hofmann, Caitlin Mueller, Sven Koenig, Brian C. Williams</p></summary>
<p>

**Abstract:** Multi-robot assembly systems are becoming increasingly appealing in manufacturing due to their ability to automatically, flexibly, and quickly construct desired structural designs. However, effectively planning for these systems in a manner that ensures each robot is simultaneously productive, and not idle, is challenging due to (1) the close proximity that the robots must operate in to manipulate the structure and (2) the inherent structural partial orderings on when each part can be installed. In this paper, we present a task and motion planning framework that jointly plans safe, low-makespan plans for a team of robots to assemble complex spatial structures. Our framework takes a hierarchical approach that, at the high level, uses Mixed-integer Linear Programs to compute an abstract plan comprised of an allocation of robots to tasks subject to precedence constraints and, at the low level, builds on a state-of-the-art algorithm for Multi-Agent Path Finding to plan collision-free robot motions that realize this abstract plan. Critical to our approach is the inclusion of certain collision constraints and movement durations during high-level planning, which better informs the search for abstract plans that are likely to be both feasible and low-makespan while keeping the search tractable. We demonstrate our planning system on several challenging assembly domains with several (sometimes heterogeneous) robots with grippers or suction plates for assembling structures with up to 23 objects involving Lego bricks, bars, plates, or irregularly shaped blocks.

</p>
</details>

<details><summary><b>Interpretable Off-Policy Learning via Hyperbox Search</b>
<a href="https://arxiv.org/abs/2203.02473">arxiv:2203.02473</a>
&#x1F4C8; 3 <br>
<p>Daniel Tschernutter, Tobias Hatt, Stefan Feuerriegel</p></summary>
<p>

**Abstract:** Personalized treatment decisions have become an integral part of modern medicine. Thereby, the aim is to make treatment decisions based on individual patient characteristics. Numerous methods have been developed for learning such policies from observational data that achieve the best outcome across a certain policy class. Yet these methods are rarely interpretable. However, interpretability is often a prerequisite for policy learning in clinical practice. In this paper, we propose an algorithm for interpretable off-policy learning via hyperbox search. In particular, our policies can be represented in disjunctive normal form (i.e., OR-of-ANDs) and are thus intelligible. We prove a universal approximation theorem that shows that our policy class is flexible enough to approximate any measurable function arbitrarily well. For optimization, we develop a tailored column generation procedure within a branch-and-bound framework. Using a simulation study, we demonstrate that our algorithm outperforms state-of-the-art methods from interpretable off-policy learning in terms of regret. Using real-word clinical data, we perform a user study with actual clinical experts, who rate our policies as highly interpretable.

</p>
</details>

<details><summary><b>Boosting the Performance of Quantum Annealers using Machine Learning</b>
<a href="https://arxiv.org/abs/2203.02360">arxiv:2203.02360</a>
&#x1F4C8; 3 <br>
<p>Jure Brence, Dragan MihailoviÄ, Viktor Kabanov, LjupÄo Todorovski, SaÅ¡o DÅ¾eroski, Jaka Vodeb</p></summary>
<p>

**Abstract:** Noisy intermediate-scale quantum (NISQ) devices are spearheading the second quantum revolution. Of these, quantum annealers are the only ones currently offering real world, commercial applications on as many as 5000 qubits. The size of problems that can be solved by quantum annealers is limited mainly by errors caused by environmental noise and intrinsic imperfections of the processor. We address the issue of intrinsic imperfections with a novel error correction approach, based on machine learning methods. Our approach adjusts the input Hamiltonian to maximize the probability of finding the solution. In our experiments, the proposed error correction method improved the performance of annealing by up to three orders of magnitude and enabled the solving of a previously intractable, maximally complex problem.

</p>
</details>

<details><summary><b>Evaluating Local Model-Agnostic Explanations of Learning to Rank Models with Decision Paths</b>
<a href="https://arxiv.org/abs/2203.02295">arxiv:2203.02295</a>
&#x1F4C8; 3 <br>
<p>Amir Hossein Akhavan Rahnama, Judith Butepage</p></summary>
<p>

**Abstract:** Local explanations of learning-to-rank (LTR) models are thought to extract the most important features that contribute to the ranking predicted by the LTR model for a single data point. Evaluating the accuracy of such explanations is challenging since the ground truth feature importance scores are not available for most modern LTR models. In this work, we propose a systematic evaluation technique for explanations of LTR models. Instead of using black-box models, such as neural networks, we propose to focus on tree-based LTR models, from which we can extract the ground truth feature importance scores using decision paths. Once extracted, we can directly compare the ground truth feature importance scores to the feature importance scores generated with explanation techniques. We compare two recently proposed explanation techniques for LTR models and benchmark them using decision trees and gradient boosting models on the MQ2008 dataset. We show that neither of the explanation techniques can achieve an acceptable explanation accuracy when the chosen similarity metric is AUC score or Spearman's rank correlation.

</p>
</details>

<details><summary><b>Integrating Statistical Uncertainty into Neural Network-Based Speech Enhancement</b>
<a href="https://arxiv.org/abs/2203.02288">arxiv:2203.02288</a>
&#x1F4C8; 3 <br>
<p>Huajian Fang, Tal Peer, Stefan Wermter, Timo Gerkmann</p></summary>
<p>

**Abstract:** Speech enhancement in the time-frequency domain is often performed by estimating a multiplicative mask to extract clean speech. However, most neural network-based methods perform point estimation, i.e., their output consists of a single mask. In this paper, we study the benefits of modeling uncertainty in neural network-based speech enhancement. For this, our neural network is trained to map a noisy spectrogram to the Wiener filter and its associated variance, which quantifies uncertainty, based on the maximum a posteriori (MAP) inference of spectral coefficients. By estimating the distribution instead of the point estimate, one can model the uncertainty associated with each estimate. We further propose to use the estimated Wiener filter and its uncertainty to build an approximate MAP (A-MAP) estimator of spectral magnitudes, which in turn is combined with the MAP inference of spectral coefficients to form a hybrid loss function to jointly reinforce the estimation. Experimental results on different datasets show that the proposed method can not only capture the uncertainty associated with the estimated filters, but also yield a higher enhancement performance over comparable models that do not take uncertainty into account.

</p>
</details>

<details><summary><b>MF-Hovernet: An Extension of Hovernet for Colon Nuclei Identification and Counting (CoNiC) Challenge</b>
<a href="https://arxiv.org/abs/2203.02161">arxiv:2203.02161</a>
&#x1F4C8; 3 <br>
<p>Vi Thi-Tuong Vo, Soo-Hyung Kim, Taebum Lee</p></summary>
<p>

**Abstract:** Nuclei Identification and Counting is the most important morphological feature of cancers, especially in the colon. Many deep learning-based methods have been proposed to deal with this problem. In this work, we construct an extension of Hovernet for nuclei identification and counting to address the problem named MF-Hovernet. Our proposed model is the combination of multiple filer block to Hovernet architecture. The current result shows the efficiency of multiple filter block to improve the performance of the original Hovernet model.

</p>
</details>

<details><summary><b>Audio-visual speech separation based on joint feature representation with cross-modal attention</b>
<a href="https://arxiv.org/abs/2203.02655">arxiv:2203.02655</a>
&#x1F4C8; 2 <br>
<p>Junwen Xiong, Peng Zhang, Lei Xie, Wei Huang, Yufei Zha, Yanning Zhang</p></summary>
<p>

**Abstract:** Multi-modal based speech separation has exhibited a specific advantage on isolating the target character in multi-talker noisy environments. Unfortunately, most of current separation strategies prefer a straightforward fusion based on feature learning of each single modality, which is far from sufficient consideration of inter-relationships between modalites. Inspired by learning joint feature representations from audio and visual streams with attention mechanism, in this study, a novel cross-modal fusion strategy is proposed to benefit the whole framework with semantic correlations between different modalities. To further improve audio-visual speech separation, the dense optical flow of lip motion is incorporated to strengthen the robustness of visual representation. The evaluation of the proposed work is performed on two public audio-visual speech separation benchmark datasets. The overall improvement of the performance has demonstrated that the additional motion network effectively enhances the visual representation of the combined lip images and audio signal, as well as outperforming the baseline in terms of all metrics with the proposed cross-modal fusion.

</p>
</details>

<details><summary><b>Important Object Identification with Semi-Supervised Learning for Autonomous Driving</b>
<a href="https://arxiv.org/abs/2203.02634">arxiv:2203.02634</a>
&#x1F4C8; 2 <br>
<p>Jiachen Li, Haiming Gang, Hengbo Ma, Masayoshi Tomizuka, Chiho Choi</p></summary>
<p>

**Abstract:** Accurate identification of important objects in the scene is a prerequisite for safe and high-quality decision making and motion planning of intelligent agents (e.g., autonomous vehicles) that navigate in complex and dynamic environments. Most existing approaches attempt to employ attention mechanisms to learn importance weights associated with each object indirectly via various tasks (e.g., trajectory prediction), which do not enforce direct supervision on the importance estimation. In contrast, we tackle this task in an explicit way and formulate it as a binary classification ("important" or "unimportant") problem. We propose a novel approach for important object identification in egocentric driving scenarios with relational reasoning on the objects in the scene. Besides, since human annotations are limited and expensive to obtain, we present a semi-supervised learning pipeline to enable the model to learn from unlimited unlabeled data. Moreover, we propose to leverage the auxiliary tasks of ego vehicle behavior prediction to further improve the accuracy of importance estimation. The proposed approach is evaluated on a public egocentric driving dataset (H3D) collected in complex traffic scenarios. A detailed ablative study is conducted to demonstrate the effectiveness of each model component and the training strategy. Our approach also outperforms rule-based baselines by a large margin.

</p>
</details>

<details><summary><b>Scaling R-GCN Training with Graph Summarization</b>
<a href="https://arxiv.org/abs/2203.02622">arxiv:2203.02622</a>
&#x1F4C8; 2 <br>
<p>Alessandro Generale, Till Blume, Michael Cochez</p></summary>
<p>

**Abstract:** Training of Relation Graph Convolutional Networks (R-GCN) does not scale well with the size of the graph. The amount of gradient information that needs to be stored during training for real-world graphs is often too large for the amount of memory available on most GPUs. In this work, we experiment with the use of graph summarization techniques to compress the graph and hence reduce the amount of memory needed. After training the R-GCN on the graph summary, we transfer the weights back to the original graph and attempt to perform inference on it. We obtain reasonable results on the AIFB, MUTAG and AM datasets. This supports the importance and relevancy of graph summarization methods, whose smaller graph representations scale and reduce the computational overhead involved with novel machine learning models dealing with large Knowledge Graphs. However, further experiments are needed to evaluate whether this also holds true for very large graphs.

</p>
</details>

<details><summary><b>Chance-Constrained Optimization in Contact-Rich Systems for Robust Manipulation</b>
<a href="https://arxiv.org/abs/2203.02616">arxiv:2203.02616</a>
&#x1F4C8; 2 <br>
<p>Yuki Shirai, Devesh K. Jha, Arvind Raghunathan, Diego Romeres</p></summary>
<p>

**Abstract:** This paper presents a chance-constrained formulation for robust trajectory optimization during manipulation. In particular, we present a chance-constrained optimization for Stochastic Discrete-time Linear Complementarity Systems (SDLCS). To solve the optimization problem, we formulate Mixed-Integer Quadratic Programming with Chance Constraints (MIQPCC). In our formulation, we explicitly consider joint chance constraints for complementarity as well as states to capture the stochastic evolution of dynamics. We evaluate robustness of our optimized trajectories in simulation on several systems. The proposed approach outperforms some recent approaches for robust trajectory optimization for SDLCS.

</p>
</details>

<details><summary><b>No More Than 6ft Apart: Robust K-Means via Radius Upper Bounds</b>
<a href="https://arxiv.org/abs/2203.02502">arxiv:2203.02502</a>
&#x1F4C8; 2 <br>
<p>Ahmed Imtiaz Humayun, Randall Balestriero, Anastasios Kyrillidis, Richard Baraniuk</p></summary>
<p>

**Abstract:** Centroid based clustering methods such as k-means, k-medoids and k-centers are heavily applied as a go-to tool in exploratory data analysis. In many cases, those methods are used to obtain representative centroids of the data manifold for visualization or summarization of a dataset. Real world datasets often contain inherent abnormalities, e.g., repeated samples and sampling bias, that manifest imbalanced clustering. We propose to remedy such a scenario by introducing a maximal radius constraint $r$ on the clusters formed by the centroids, i.e., samples from the same cluster should not be more than $2r$ apart in terms of $\ell_2$ distance. We achieve this constraint by solving a semi-definite program, followed by a linear assignment problem with quadratic constraints. Through qualitative results, we show that our proposed method is robust towards dataset imbalances and sampling artifacts. To the best of our knowledge, ours is the first constrained k-means clustering method with hard radius constraints. Codes at https://bit.ly/kmeans-constrained

</p>
</details>

<details><summary><b>Simultaneous Alignment and Surface Regression Using Hybrid 2D-3D Networks for 3D Coherent Layer Segmentation of Retina OCT Images</b>
<a href="https://arxiv.org/abs/2203.02390">arxiv:2203.02390</a>
&#x1F4C8; 2 <br>
<p>Hong Liu, Dong Wei, Donghuan Lu, Yuexiang Li, Kai Ma, Liansheng Wang, Yefeng Zheng</p></summary>
<p>

**Abstract:** Automated surface segmentation of retinal layer is important and challenging in analyzing optical coherence tomography (OCT). Recently, many deep learning based methods have been developed for this task and yield remarkable performance. However, due to large spatial gap and potential mismatch between the B-scans of OCT data, all of them are based on 2D segmentation of individual B-scans, which may loss the continuity information across the B-scans. In addition, 3D surface of the retina layers can provide more diagnostic information, which is crucial in quantitative image analysis. In this study, a novel framework based on hybrid 2D-3D convolutional neural networks (CNNs) is proposed to obtain continuous 3D retinal layer surfaces from OCT. The 2D features of individual B-scans are extracted by an encoder consisting of 2D convolutions. These 2D features are then used to produce the alignment displacement field and layer segmentation by two 3D decoders, which are coupled via a spatial transformer module. The entire framework is trained end-to-end. To the best of our knowledge, this is the first study that attempts 3D retinal layer segmentation in volumetric OCT images based on CNNs. Experiments on a publicly available dataset show that our framework achieves superior results to state-of-the-art 2D methods in terms of both layer segmentation accuracy and cross-B-scan 3D continuity, thus offering more clinical values than previous works.

</p>
</details>

<details><summary><b>MM-DFN: Multimodal Dynamic Fusion Network for Emotion Recognition in Conversations</b>
<a href="https://arxiv.org/abs/2203.02385">arxiv:2203.02385</a>
&#x1F4C8; 2 <br>
<p>Dou Hu, Xiaolong Hou, Lingwei Wei, Lianxin Jiang, Yang Mo</p></summary>
<p>

**Abstract:** Emotion Recognition in Conversations (ERC) has considerable prospects for developing empathetic machines. For multimodal ERC, it is vital to understand context and fuse modality information in conversations. Recent graph-based fusion methods generally aggregate multimodal information by exploring unimodal and cross-modal interactions in a graph. However, they accumulate redundant information at each layer, limiting the context understanding between modalities. In this paper, we propose a novel Multimodal Dynamic Fusion Network (MM-DFN) to recognize emotions by fully understanding multimodal conversational context. Specifically, we design a new graph-based dynamic fusion module to fuse multimodal contextual features in a conversation. The module reduces redundancy and enhances complementarity between modalities by capturing the dynamics of contextual information in different semantic spaces. Extensive experiments on two public benchmark datasets demonstrate the effectiveness and superiority of MM-DFN.

</p>
</details>

<details><summary><b>Detecting GAN-generated Images by Orthogonal Training of Multiple CNNs</b>
<a href="https://arxiv.org/abs/2203.02246">arxiv:2203.02246</a>
&#x1F4C8; 2 <br>
<p>Sara Mandelli, NicolÃ² Bonettini, Paolo Bestagini, Stefano Tubaro</p></summary>
<p>

**Abstract:** In the last few years, we have witnessed the rise of a series of deep learning methods to generate synthetic images that look extremely realistic. These techniques prove useful in the movie industry and for artistic purposes. However, they also prove dangerous if used to spread fake news or to generate fake online accounts. For this reason, detecting if an image is an actual photograph or has been synthetically generated is becoming an urgent necessity. This paper proposes a detector of synthetic images based on an ensemble of Convolutional Neural Networks (CNNs). We consider the problem of detecting images generated with techniques not available at training time. This is a common scenario, given that new image generators are published more and more frequently. To solve this issue, we leverage two main ideas: (i) CNNs should provide orthogonal results to better contribute to the ensemble; (ii) original images are better defined than synthetic ones, thus they should be better trusted at testing time. Experiments show that pursuing these two ideas improves the detector accuracy on NVIDIA's newly generated StyleGAN3 images, never used in training.

</p>
</details>

<details><summary><b>Sharper Bounds for Proximal Gradient Algorithms with Errors</b>
<a href="https://arxiv.org/abs/2203.02204">arxiv:2203.02204</a>
&#x1F4C8; 2 <br>
<p>Anis Hamadouche, Yun Wu, Andrew M. Wallace, Joao F. C. Mota</p></summary>
<p>

**Abstract:** We analyse the convergence of the proximal gradient algorithm for convex composite problems in the presence of gradient and proximal computational inaccuracies. We derive new tighter deterministic and probabilistic bounds that we use to verify a simulated (MPC) and a synthetic (LASSO) optimization problems solved on a reduced-precision machine in combination with an inaccurate proximal operator. We also show how the probabilistic bounds are more robust for algorithm verification and more accurate for application performance guarantees. Under some statistical assumptions, we also prove that some cumulative error terms follow a martingale property. And conforming to observations, e.g., in \cite{schmidt2011convergence}, we also show how the acceleration of the algorithm amplifies the gradient and proximal computational errors.

</p>
</details>

<details><summary><b>Convolutional Analysis Operator Learning by End-To-End Training of Iterative Neural Networks</b>
<a href="https://arxiv.org/abs/2203.02166">arxiv:2203.02166</a>
&#x1F4C8; 2 <br>
<p>Andreas Kofler, Christian Wald, Tobias Schaeffter, Markus Haltmeier, Christoph Kolbitsch</p></summary>
<p>

**Abstract:** The concept of sparsity has been extensively applied for regularization in image reconstruction. Typically, sparsifying transforms are either pre-trained on ground-truth images or adaptively trained during the reconstruction. Thereby, learning algorithms are designed to minimize some target function which encodes the desired properties of the transform. However, this procedure ignores the subsequently employed reconstruction algorithm as well as the physical model which is responsible for the image formation process. Iterative neural networks - which contain the physical model - can overcome these issues. In this work, we demonstrate how convolutional sparsifying filters can be efficiently learned by end-to-end training of iterative neural networks. We evaluated our approach on a non-Cartesian 2D cardiac cine MRI example and show that the obtained filters are better suitable for the corresponding reconstruction algorithm than the ones obtained by decoupled pre-training.

</p>
</details>

<details><summary><b>Adaptive Cross-Layer Attention for Image Restoration</b>
<a href="https://arxiv.org/abs/2203.03619">arxiv:2203.03619</a>
&#x1F4C8; 1 <br>
<p>Yancheng Wang, Ning Xu, Chong Chen, Yingzhen Yang</p></summary>
<p>

**Abstract:** Non-local attention module has been proven to be crucial for image restoration. Conventional non-local attention processes features of each layer separately, so it risks missing correlation between features among different layers. To address this problem, we propose Cross-Layer Attention (CLA) module in this paper. Instead of finding correlated key pixels within the same layer, each query pixel can attend to key pixels at previous layers of the network. In order to further enhance the learning capability and reduce the inference cost of CLA, we further propose Adaptive CLA, or ACLA, as an improved CLA. Two adaptive designs are proposed for ACLA: 1) adaptively selecting the keys for non-local attention at each layer; 2) automatically searching for the insertion locations for ACLA modules. By these two adaptive designs, ACLA dynamically selects the number of keys to be aggregated for non-local attention at layer. In addition, ACLA searches for the optimal insert positions of ACLA modules by a neural architecture search method to render a compact neural network with compelling performance. Extensive experiments on image restoration tasks, including single image super-resolution, image denoising, image demosaicing, and image compression artifacts reduction, validate the effectiveness and efficiency of ACLA.

</p>
</details>

<details><summary><b>Targeted Data Poisoning Attack on News Recommendation System by Content Perturbation</b>
<a href="https://arxiv.org/abs/2203.03560">arxiv:2203.03560</a>
&#x1F4C8; 1 <br>
<p>Xudong Zhang, Zan Wang, Jingke Zhao, Lanjun Wang</p></summary>
<p>

**Abstract:** News Recommendation System(NRS) has become a fundamental technology to many online news services. Meanwhile, several studies show that recommendation systems(RS) are vulnerable to data poisoning attacks, and the attackers have the ability to mislead the system to perform as their desires. A widely studied attack approach, injecting fake users, can be applied on the NRS when the NRS is treated the same as the other systems whose items are fixed. However, in the NRS, as each item (i.e. news) is more informative, we propose a novel approach to poison the NRS, which is to perturb contents of some browsed news that results in the manipulation of the rank of the target news. Intuitively, an attack is useless if it is highly likely to be caught, i.e., exposed. To address this, we introduce a notion of the exposure risk and propose a novel problem of attacking a history news dataset by means of perturbations where the goal is to maximize the manipulation of the target news rank while keeping the risk of exposure under a given budget. We design a reinforcement learning framework, called TDP-CP, which contains a two-stage hierarchical model to reduce the searching space. Meanwhile, influence estimation is also applied to save the time on retraining the NRS for rewards. We test the performance of TDP-CP under three NRSs and on different target news. Our experiments show that TDP-CP can increase the rank of the target news successfully with a limited exposure budget.

</p>
</details>

<details><summary><b>Training privacy-preserving video analytics pipelines by suppressing features that reveal information about private attributes</b>
<a href="https://arxiv.org/abs/2203.02635">arxiv:2203.02635</a>
&#x1F4C8; 1 <br>
<p>Chau Yi Li, Andrea Cavallaro</p></summary>
<p>

**Abstract:** Deep neural networks are increasingly deployed for scene analytics, including to evaluate the attention and reaction of people exposed to out-of-home advertisements. However, the features extracted by a deep neural network that was trained to predict a specific, consensual attribute (e.g. emotion) may also encode and thus reveal information about private, protected attributes (e.g. age or gender). In this work, we focus on such leakage of private information at inference time. We consider an adversary with access to the features extracted by the layers of a deployed neural network and use these features to predict private attributes. To prevent the success of such an attack, we modify the training of the network using a confusion loss that encourages the extraction of features that make it difficult for the adversary to accurately predict private attributes. We validate this training approach on image-based tasks using a publicly available dataset. Results show that, compared to the original network, the proposed PrivateNet can reduce the leakage of private information of a state-of-the-art emotion recognition classifier by 2.88% for gender and by 13.06% for age group, with a minimal effect on task accuracy.

</p>
</details>

<details><summary><b>How to Train Unstable Looped Tensor Network</b>
<a href="https://arxiv.org/abs/2203.02617">arxiv:2203.02617</a>
&#x1F4C8; 1 <br>
<p>Anh-Huy Phan, Konstantin Sobolev, Dmitry Ermilov, Igor Vorona, Nikolay Kozyrskiy, Petr Tichavsky, Andrzej Cichocki</p></summary>
<p>

**Abstract:** A rising problem in the compression of Deep Neural Networks is how to reduce the number of parameters in convolutional kernels and the complexity of these layers by low-rank tensor approximation. Canonical polyadic tensor decomposition (CPD) and Tucker tensor decomposition (TKD) are two solutions to this problem and provide promising results. However, CPD often fails due to degeneracy, making the networks unstable and hard to fine-tune. TKD does not provide much compression if the core tensor is big. This motivates using a hybrid model of CPD and TKD, a decomposition with multiple Tucker models with small core tensor, known as block term decomposition (BTD). This paper proposes a more compact model that further compresses the BTD by enforcing core tensors in BTD identical. We establish a link between the BTD with shared parameters and a looped chain tensor network (TC). Unfortunately, such strongly constrained tensor networks (with loop) encounter severe numerical instability, as proved by y (Landsberg, 2012) and (Handschuh, 2015a). We study perturbation of chain tensor networks, provide interpretation of instability in TC, demonstrate the problem. We propose novel methods to gain the stability of the decomposition results, keep the network robust and attain better approximation. Experimental results will confirm the superiority of the proposed methods in compression of well-known CNNs, and TC decomposition under challenging scenarios

</p>
</details>

<details><summary><b>Plant Species Recognition with Optimized 3D Polynomial Neural Networks and Variably Overlapping Time-Coherent Sliding Window</b>
<a href="https://arxiv.org/abs/2203.02611">arxiv:2203.02611</a>
&#x1F4C8; 1 <br>
<p>Habib Ben Abdallah, Christopher J. Henry, Sheela Ramanna</p></summary>
<p>

**Abstract:** Recently, the EAGL-I system was developed to rapidly create massive labeled datasets of plants intended to be commonly used by farmers and researchers to create AI-driven solutions in agriculture. As a result, a publicly available plant species recognition dataset composed of 40,000 images with different sizes consisting of 8 plant species was created with the system in order to demonstrate its capabilities. This paper proposes a novel method, called Variably Overlapping Time-Coherent Sliding Window (VOTCSW), that transforms a dataset composed of images with variable size to a 3D representation with fixed size that is suitable for convolutional neural networks, and demonstrates that this representation is more informative than resizing the images of the dataset to a given size. We theoretically formalized the use cases of the method as well as its inherent properties and we proved that it has an oversampling and a regularization effect on the data. By combining the VOTCSW method with the 3D extension of a recently proposed machine learning model called 1-Dimensional Polynomial Neural Networks, we were able to create a model that achieved a state-of-the-art accuracy of 99.9% on the dataset created by the EAGL-I system, surpassing well-known architectures such as ResNet and Inception. In addition, we created a heuristic algorithm that enables the degree reduction of any pre-trained N-Dimensional Polynomial Neural Network and which compresses it without altering its performance, thus making the model faster and lighter. Furthermore, we established that the currently available dataset could not be used for machine learning in its present form, due to a substantial class imbalance between the training set and the test set. Hence, we created a specific preprocessing and a model development framework that enabled us to improve the accuracy from 49.23% to 99.9%.

</p>
</details>

<details><summary><b>Geodesic Gramian Denoising Applied to the Images Contaminated With Noise Sampled From Diverse Probability Distributions</b>
<a href="https://arxiv.org/abs/2203.02600">arxiv:2203.02600</a>
&#x1F4C8; 1 <br>
<p>Yonggi Park, Kelum Gajamannage, Alexey Sadovski</p></summary>
<p>

**Abstract:** As quotidian use of sophisticated cameras surges, people in modern society are more interested in capturing fine-quality images. However, the quality of the images might be inferior to people's expectations due to the noise contamination in the images. Thus, filtering out the noise while preserving vital image features is an essential requirement. Current existing denoising methods have their own assumptions on the probability distribution in which the contaminated noise is sampled for the method to attain its expected denoising performance. In this paper, we utilize our recent Gramian-based filtering scheme to remove noise sampled from five prominent probability distributions from selected images. This method preserves image smoothness by adopting patches partitioned from the image, rather than pixels, and retains vital image features by performing denoising on the manifold underlying the patch space rather than in the image domain. We validate its denoising performance, using three benchmark computer vision test images applied to two state-of-the-art denoising methods, namely BM3D and K-SVD.

</p>
</details>

<details><summary><b>Improving the Energy Efficiency and Robustness of tinyML Computer Vision using Log-Gradient Input Images</b>
<a href="https://arxiv.org/abs/2203.02571">arxiv:2203.02571</a>
&#x1F4C8; 1 <br>
<p>Qianyun Lu, Boris Murmann</p></summary>
<p>

**Abstract:** This paper studies the merits of applying log-gradient input images to convolutional neural networks (CNNs) for tinyML computer vision (CV). We show that log gradients enable: (i) aggressive 1.5-bit quantization of first-layer inputs, (ii) potential CNN resource reductions, and (iii) inherent robustness to illumination changes (1.7% accuracy loss across 1/32...8 brightness variation vs. up to 10% for JPEG). We establish these results using the PASCAL RAW image data set and through a combination of experiments using neural architecture search and a fixed three-layer network. The latter reveal that training on log-gradient images leads to higher filter similarity, making the CNN more prunable. The combined benefits of aggressive first-layer quantization, CNN resource reductions, and operation without tight exposure control and image signal processing (ISP) are helpful for pushing tinyML CV toward its ultimate efficiency limits.

</p>
</details>

<details><summary><b>The Machine Learning for Combinatorial Optimization Competition (ML4CO): Results and Insights</b>
<a href="https://arxiv.org/abs/2203.02433">arxiv:2203.02433</a>
&#x1F4C8; 1 <br>
<p>Maxime Gasse, Quentin Cappart, Jonas Charfreitag, Laurent Charlin, Didier ChÃ©telat, Antonia Chmiela, Justin Dumouchelle, Ambros Gleixner, Aleksandr M. Kazachkov, Elias Khalil, Pawel Lichocki, Andrea Lodi, Miles Lubin, Chris J. Maddison, Christopher Morris, Dimitri J. Papageorgiou, Augustin Parjadis, Sebastian Pokutta, Antoine Prouvost, Lara Scavuzzo, Giulia Zarpellon, Linxin Yangm, Sha Lai, Akang Wang, Xiaodong Luo</p></summary>
<p>

**Abstract:** Combinatorial optimization is a well-established area in operations research and computer science. Until recently, its methods have focused on solving problem instances in isolation, ignoring that they often stem from related data distributions in practice. However, recent years have seen a surge of interest in using machine learning as a new approach for solving combinatorial problems, either directly as solvers or by enhancing exact solvers. Based on this context, the ML4CO aims at improving state-of-the-art combinatorial optimization solvers by replacing key heuristic components. The competition featured three challenging tasks: finding the best feasible solution, producing the tightest optimality certificate, and giving an appropriate solver configuration. Three realistic datasets were considered: balanced item placement, workload apportionment, and maritime inventory routing. This last dataset was kept anonymous for the contestants.

</p>
</details>

<details><summary><b>Analysis of closed-loop inertial gradient dynamics</b>
<a href="https://arxiv.org/abs/2203.02140">arxiv:2203.02140</a>
&#x1F4C8; 1 <br>
<p>Subhransu S. Bhattacharjee, Ian R. Petersen</p></summary>
<p>

**Abstract:** In this paper, we analyse the performance of the closed-loop Whiplash gradient descent algorithm for L-smooth convex cost functions. Using numerical experiments, we study the algorithm's performance for convex cost functions, for different condition numbers. We analyse the convergence of the momentum sequence using symplectic integration and introduce the concept of relaxation sequences which analyses the non-classical character of the whiplash method. Under the additional assumption of invexity, we establish a momentum-driven adaptive convergence rate. Furthermore, we introduce an energy method for predicting the convergence rate with convex cost functions for closed-loop inertial gradient dynamics, using an integral anchored energy function and a novel lower bound asymptotic notation, by exploiting the bounded nature of the solutions. Using this, we establish a polynomial convergence rate for the whiplash inertial gradient system, for a family of scalar quadratic cost functions and an exponential rate for a quadratic scalar cost function.

</p>
</details>

<details><summary><b>On the relevance of language in speaker recognition</b>
<a href="https://arxiv.org/abs/2203.01992">arxiv:2203.01992</a>
&#x1F4C8; 1 <br>
<p>Antonio Satue-Villar, Marcos Faundez-Zanuy</p></summary>
<p>

**Abstract:** This paper presents a new database collected from a bilingual speakers set (49), in two different languages: Spanish and Catalan. Phonetically there are significative differences between both languages. These differences have let us to establish several conclusions on the relevance of language in speaker recognition, using two methods: vector quantization and covariance matrices

</p>
</details>

<details><summary><b>Unfreeze with Care: Space-Efficient Fine-Tuning of Semantic Parsing Models</b>
<a href="https://arxiv.org/abs/2203.02652">arxiv:2203.02652</a>
&#x1F4C8; 0 <br>
<p>Weiqi Sun, Haidar Khan, Nicolas Guenon des Mesnards, Melanie Rubino, Konstantine Arkoudas</p></summary>
<p>

**Abstract:** Semantic parsing is a key NLP task that maps natural language to structured meaning representations. As in many other NLP tasks, SOTA performance in semantic parsing is now attained by fine-tuning a large pretrained language model (PLM). While effective, this approach is inefficient in the presence of multiple downstream tasks, as a new set of values for all parameters of the PLM needs to be stored for each task separately. Recent work has explored methods for adapting PLMs to downstream tasks while keeping most (or all) of their parameters frozen. We examine two such promising techniques, prefix tuning and bias-term tuning, specifically on semantic parsing. We compare them against each other on two different semantic parsing datasets, and we also compare them against full and partial fine-tuning, both in few-shot and conventional data settings. While prefix tuning is shown to do poorly for semantic parsing tasks off the shelf, we modify it by adding special token embeddings, which results in very strong performance without compromising parameter savings.

</p>
</details>

<details><summary><b>Target Network and Truncation Overcome The Deadly triad in $Q$-Learning</b>
<a href="https://arxiv.org/abs/2203.02628">arxiv:2203.02628</a>
&#x1F4C8; 0 <br>
<p>Zaiwei Chen, John Paul Clarke, Siva Theja Maguluri</p></summary>
<p>

**Abstract:** $Q$-learning with function approximation is one of the most empirically successful while theoretically mysterious reinforcement learning (RL) algorithms, and was identified in Sutton (1999) as one of the most important theoretical open problems in the RL community. Even in the basic linear function approximation setting, there are well-known divergent examples. In this work, we propose a stable design for $Q$-learning with linear function approximation using target network and truncation, and establish its finite-sample guarantees. Our result implies an $\mathcal{O}(Îµ^{-2})$ sample complexity up to a function approximation error. This is the first variant of $Q$-learning with linear function approximation that is provably stable without requiring strong assumptions or modifying the problem parameters, and achieves the optimal sample complexity.

</p>
</details>

<details><summary><b>Reinforcement Learning in Modern Biostatistics: Constructing Optimal Adaptive Interventions</b>
<a href="https://arxiv.org/abs/2203.02605">arxiv:2203.02605</a>
&#x1F4C8; 0 <br>
<p>Nina Deliu, Joseph Jay Williams, Bibhas Chakraborty</p></summary>
<p>

**Abstract:** Reinforcement learning (RL) is acquiring a key role in the space of adaptive interventions (AIs), attracting a substantial interest within methodological and theoretical literature and becoming increasingly popular within health sciences. Despite potential benefits, its application in real life is still limited due to several operational and statistical challenges--in addition to ethical and cost issues among others--that remain open in part due to poor communication and synergy between methodological and applied scientists. In this work, we aim to bridge the different domains that contribute to and may benefit from RL, under a unique framework that intersects the areas of RL, causal inference, and AIs, among others. We provide the first unified instructive survey on RL methods for building AIs, encompassing both dynamic treatment regimes (DTRs) and just-in-time adaptive interventions in mobile health (mHealth). We outline similarities and differences between the two areas, and discuss their implications for using RL. We combine our relevant methodological knowledge with motivating studies in both DTRs and mHealth to illustrate the tremendous collaboration opportunities between statistical, RL, and healthcare researchers in the space of AIs.

</p>
</details>

<details><summary><b>Sparsity-Inducing Categorical Prior Improves Robustness of the Information Bottleneck</b>
<a href="https://arxiv.org/abs/2203.02592">arxiv:2203.02592</a>
&#x1F4C8; 0 <br>
<p>Anirban Samaddar, Sandeep Madireddy, Prasanna Balaprakash</p></summary>
<p>

**Abstract:** The information bottleneck framework provides a systematic approach to learn representations that compress nuisance information in inputs and extract semantically meaningful information about the predictions. However, the choice of the prior distribution that fix the dimensionality across all the data can restrict the flexibility of this approach to learn robust representations. We present a novel sparsity-inducing spike-slab prior that uses sparsity as a mechanism to provide flexibility that allows each data point to learn its own dimension distribution. In addition, it provides a mechanism to learn a joint distribution of the latent variable and the sparsity. Thus, unlike other approaches, it can account for the full uncertainty in the latent space. Through a series of experiments using in-distribution and out-of-distribution learning scenarios on the MNIST and Fashion-MNIST data we show that the proposed approach improves the accuracy and robustness compared with the traditional fixed -imensional priors as well as other sparsity-induction mechanisms proposed in the literature.

</p>
</details>

<details><summary><b>A Small Gain Analysis of Single Timescale Actor Critic</b>
<a href="https://arxiv.org/abs/2203.02591">arxiv:2203.02591</a>
&#x1F4C8; 0 <br>
<p>Alex Olshevsky, Bahman Gharesifard</p></summary>
<p>

**Abstract:** We consider a version of actor-critic which uses proportional step-sizes and only one critic update with a single sample from the stationary distribution per actor step. We provide an analysis of this method using the small-gain theorem. Specifically, we prove that this method can be used to find a stationary point, and that the resulting sample complexity improves the state of the art for actor-critic methods to $O \left(Î¼^{-2} Îµ^{-2} \right)$ to find an $Îµ$-approximate stationary point where $Î¼$ is the condition number associated with the critic.

</p>
</details>

<details><summary><b>Machine Learning for CUDA+MPI Design Rules</b>
<a href="https://arxiv.org/abs/2203.02530">arxiv:2203.02530</a>
&#x1F4C8; 0 <br>
<p>Carl Pearson, Aurya Javeed, Karen Devine</p></summary>
<p>

**Abstract:** We present a new strategy for automatically exploring the design space of key CUDA+MPI programs and providing design rules that discriminate slow from fast implementations. In such programs, the order of operations (e.g., GPU kernels, MPI communication) and assignment of operations to resources (e.g., GPU streams) makes the space of possible designs enormous. Systems experts have the task of redesigning and reoptimizing these programs to effectively utilize each new platform. This work provides a prototype tool to reduce that burden.
  In our approach, a directed acyclic graph of CUDA and MPI operations defines the design space for the program. Monte-Carlo tree search discovers regions of the design space that have large impact on the program's performance. A sequence-to-vector transformation defines features for each explored implementation, and each implementation is assigned a class label according to its relative performance. A decision tree is trained on the features and labels to produce design rules for each class; these rules can be used by systems experts to guide their implementations. We demonstrate our strategy using a key kernel from scientific computing -- sparse-matrix vector multiplication -- on a platform with multiple MPI ranks and GPU streams.

</p>
</details>

<details><summary><b>Improving Ant Colony Optimization Efficiency for Solving Large TSP Instances</b>
<a href="https://arxiv.org/abs/2203.02228">arxiv:2203.02228</a>
&#x1F4C8; 0 <br>
<p>RafaÅ Skinderowicz</p></summary>
<p>

**Abstract:** Ant Colony Optimization (ACO) is a family of nature-inspired metaheuristics often applied to finding approximate solutions to difficult optimization problems. Despite being significantly faster than exact methods, the ACOs can still be prohibitively slow, especially if compared to basic problem-specific heuristics. As recent research has shown, it is possible to significantly improve the performance through algorithm refinements and careful parallel implementation benefiting from multi-core CPUs and dedicated accelerators. In this paper, we present a novel ACO variant, namely the Focused ACO (FACO). One of the core elements of the FACO is a mechanism for controlling the number of differences between a newly constructed and a selected previous solution. The mechanism results in a more focused search process, allowing to find improvements while preserving the quality of the existing solution. An additional benefit is a more efficient integration with a problem-specific local search.
  Computational study based on a range of the Traveling Salesman Problem instances shows that the FACO outperforms the state-of-the-art ACOs when solving large TSP instances. Specifically, the FACO required less than an hour of an 8-core commodity CPU time to find high-quality solutions (within 1% from the best-known results) for TSP Art Instances ranging from 100000 to 200000 nodes.

</p>
</details>

<details><summary><b>Look\&Listen: Multi-Modal Correlation Learning for Active Speaker Detection and Speech Enhancement</b>
<a href="https://arxiv.org/abs/2203.02216">arxiv:2203.02216</a>
&#x1F4C8; 0 <br>
<p>Junwen Xiong, Yu Zhou, Peng Zhang, Lei Xie, Wei Huang, Yufei Zha</p></summary>
<p>

**Abstract:** Active speaker detection and speech enhancement have become two increasingly attractive topics in audio-visual scenario understanding. According to their respective characteristics, the scheme of independently designed architecture has been widely used in correspondence to each single task. This may lead to the learned feature representation being task-specific, and inevitably result in the lack of generalization ability of the feature based on multi-modal modeling. More recent studies have shown that establishing cross-modal relationship between auditory and visual stream is a promising solution for the challenge of audio-visual multi-task learning. Therefore, as a motivation to bridge the multi-modal cross-attention, in this work, a unified framework ADENet is proposed to achieve target speaker detection and speech enhancement with joint learning of audio-visual modeling.

</p>
</details>

<details><summary><b>EAG: Extract and Generate Multi-way Aligned Corpus for Complete Multi-lingual Neural Machine Translation</b>
<a href="https://arxiv.org/abs/2203.02180">arxiv:2203.02180</a>
&#x1F4C8; 0 <br>
<p>Yulin Xu, Zhen Yang, Fandong Meng,  JieZhou</p></summary>
<p>

**Abstract:** Complete Multi-lingual Neural Machine Translation (C-MNMT) achieves superior performance against the conventional MNMT by constructing multi-way aligned corpus, i.e., aligning bilingual training examples from different language pairs when either their source or target sides are identical. However, since exactly identical sentences from different language pairs are scarce, the power of the multi-way aligned corpus is limited by its scale. To handle this problem, this paper proposes "Extract and Generate" (EAG), a two-step approach to construct large-scale and high-quality multi-way aligned corpus from bilingual data. Specifically, we first extract candidate aligned examples by pairing the bilingual examples from different language pairs with highly similar source or target sentences; and then generate the final aligned examples from the candidates with a well-trained generation model. With this two-step pipeline, EAG can construct a large-scale and multi-way aligned corpus whose diversity is almost identical to the original bilingual corpus. Experiments on two publicly available datasets i.e., WMT-5 and OPUS-100, show that the proposed method achieves significant improvements over strong baselines, with +1.1 and +1.4 BLEU points improvements on the two datasets respectively.

</p>
</details>

<details><summary><b>Transformations in Learned Image Compression from a Modulation Perspective</b>
<a href="https://arxiv.org/abs/2203.02158">arxiv:2203.02158</a>
&#x1F4C8; 0 <br>
<p>Youneng Bao, Fangyang Meng, Wen Tan, Chao Li, Yonghong Tian, Yongsheng Liang</p></summary>
<p>

**Abstract:** In this paper, a unified transformation method in learned image compression(LIC) is proposed from the perspective of modulation. Firstly, the quantization in LIC is considered as a generalized channel with additive uniform noise. Moreover, the LIC is interpreted as a particular communication system according to the consistency in structures and optimization objectives. Thus, the technology of communication systems can be applied to guide the design of modules in LIC. Furthermore, a unified transform method based on signal modulation (TSM) is defined. In the view of TSM, the existing transformation methods are mathematically reduced to a linear modulation. A series of transformation methods, e.g. TPM and TJM, are obtained by extending to nonlinear modulation. The experimental results on various datasets and backbone architectures verify that the effectiveness and robustness of the proposed method. More importantly, it further confirms the feasibility of guiding LIC design from a communication perspective. For example, when backbone architecture is hyperprior combining context model, our method achieves 3.52$\%$ BD-rate reduction over GDN on Kodak dataset without increasing complexity.

</p>
</details>


{% endraw %}
Prev: [2022.03.03]({{ '/2022/03/03/2022.03.03.html' | relative_url }})  Next: [2022.03.05]({{ '/2022/03/05/2022.03.05.html' | relative_url }})