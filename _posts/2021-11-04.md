## Summary for 2021-11-04, created on 2021-12-17


<details><summary><b>EditGAN: High-Precision Semantic Image Editing</b>
<a href="https://arxiv.org/abs/2111.03186">arxiv:2111.03186</a>
&#x1F4C8; 367 <br>
<p>Huan Ling, Karsten Kreis, Daiqing Li, Seung Wook Kim, Antonio Torralba, Sanja Fidler</p></summary>
<p>

**Abstract:** Generative adversarial networks (GANs) have recently found applications in image editing. However, most GAN based image editing methods often require large scale datasets with semantic segmentation annotations for training, only provide high level control, or merely interpolate between different images. Here, we propose EditGAN, a novel method for high quality, high precision semantic image editing, allowing users to edit images by modifying their highly detailed part segmentation masks, e.g., drawing a new mask for the headlight of a car. EditGAN builds on a GAN framework that jointly models images and their semantic segmentations, requiring only a handful of labeled examples, making it a scalable tool for editing. Specifically, we embed an image into the GAN latent space and perform conditional latent code optimization according to the segmentation edit, which effectively also modifies the image. To amortize optimization, we find editing vectors in latent space that realize the edits. The framework allows us to learn an arbitrary number of editing vectors, which can then be directly applied on other images at interactive rates. We experimentally show that EditGAN can manipulate images with an unprecedented level of detail and freedom, while preserving full image quality.We can also easily combine multiple edits and perform plausible edits beyond EditGAN training data. We demonstrate EditGAN on a wide variety of image types and quantitatively outperform several previous editing methods on standard editing benchmark tasks.

</p>
</details>

<details><summary><b>A Unified View of Relational Deep Learning for Drug Pair Scoring</b>
<a href="https://arxiv.org/abs/2111.02916">arxiv:2111.02916</a>
&#x1F4C8; 347 <br>
<p>Benedek Rozemberczki, Stephen Bonner, Andriy Nikolov, Michael Ughetto, Sebastian Nilsson, Eliseo Papa</p></summary>
<p>

**Abstract:** In recent years, numerous machine learning models which attempt to solve polypharmacy side effect identification, drug-drug interaction prediction and combination therapy design tasks have been proposed. Here, we present a unified theoretical view of relational machine learning models which can address these tasks. We provide fundamental definitions, compare existing model architectures and discuss performance metrics, datasets and evaluation protocols. In addition, we emphasize possible high impact applications and important future research directions in this domain.

</p>
</details>

<details><summary><b>Unsupervised Learning of Compositional Energy Concepts</b>
<a href="https://arxiv.org/abs/2111.03042">arxiv:2111.03042</a>
&#x1F4C8; 149 <br>
<p>Yilun Du, Shuang Li, Yash Sharma, Joshua B. Tenenbaum, Igor Mordatch</p></summary>
<p>

**Abstract:** Humans are able to rapidly understand scenes by utilizing concepts extracted from prior experience. Such concepts are diverse, and include global scene descriptors, such as the weather or lighting, as well as local scene descriptors, such as the color or size of a particular object. So far, unsupervised discovery of concepts has focused on either modeling the global scene-level or the local object-level factors of variation, but not both. In this work, we propose COMET, which discovers and represents concepts as separate energy functions, enabling us to represent both global concepts as well as objects under a unified framework. COMET discovers energy functions through recomposing the input image, which we find captures independent factors without additional supervision. Sample generation in COMET is formulated as an optimization process on underlying energy functions, enabling us to generate images with permuted and composed concepts. Finally, discovered visual concepts in COMET generalize well, enabling us to compose concepts between separate modalities of images as well as with other concepts discovered by a separate instance of COMET trained on a different dataset. Code and data available at https://energy-based-model.github.io/comet/.

</p>
</details>

<details><summary><b>A System for General In-Hand Object Re-Orientation</b>
<a href="https://arxiv.org/abs/2111.03043">arxiv:2111.03043</a>
&#x1F4C8; 68 <br>
<p>Tao Chen, Jie Xu, Pulkit Agrawal</p></summary>
<p>

**Abstract:** In-hand object reorientation has been a challenging problem in robotics due to high dimensional actuation space and the frequent change in contact state between the fingers and the objects. We present a simple model-free framework that can learn to reorient objects with both the hand facing upwards and downwards. We demonstrate the capability of reorienting over 2000 geometrically different objects in both cases. The learned policies show strong zero-shot transfer performance on new objects. We provide evidence that these policies are amenable to real-world operation by distilling them to use observations easily available in the real world. The videos of the learned policies are available at: https://taochenshh.github.io/projects/in-hand-reorientation.

</p>
</details>

<details><summary><b>Generalization in Dexterous Manipulation via Geometry-Aware Multi-Task Learning</b>
<a href="https://arxiv.org/abs/2111.03062">arxiv:2111.03062</a>
&#x1F4C8; 43 <br>
<p>Wenlong Huang, Igor Mordatch, Pieter Abbeel, Deepak Pathak</p></summary>
<p>

**Abstract:** Dexterous manipulation of arbitrary objects, a fundamental daily task for humans, has been a grand challenge for autonomous robotic systems. Although data-driven approaches using reinforcement learning can develop specialist policies that discover behaviors to control a single object, they often exhibit poor generalization to unseen ones. In this work, we show that policies learned by existing reinforcement learning algorithms can in fact be generalist when combined with multi-task learning and a well-chosen object representation. We show that a single generalist policy can perform in-hand manipulation of over 100 geometrically-diverse real-world objects and generalize to new objects with unseen shape or size. Interestingly, we find that multi-task learning with object point cloud representations not only generalizes better but even outperforms the single-object specialist policies on both training as well as held-out test objects. Video results at https://huangwl18.github.io/geometry-dex

</p>
</details>

<details><summary><b>B-Pref: Benchmarking Preference-Based Reinforcement Learning</b>
<a href="https://arxiv.org/abs/2111.03026">arxiv:2111.03026</a>
&#x1F4C8; 40 <br>
<p>Kimin Lee, Laura Smith, Anca Dragan, Pieter Abbeel</p></summary>
<p>

**Abstract:** Reinforcement learning (RL) requires access to a reward function that incentivizes the right behavior, but these are notoriously hard to specify for complex tasks. Preference-based RL provides an alternative: learning policies using a teacher's preferences without pre-defined rewards, thus overcoming concerns associated with reward engineering. However, it is difficult to quantify the progress in preference-based RL due to the lack of a commonly adopted benchmark. In this paper, we introduce B-Pref: a benchmark specially designed for preference-based RL. A key challenge with such a benchmark is providing the ability to evaluate candidate algorithms quickly, which makes relying on real human input for evaluation prohibitive. At the same time, simulating human input as giving perfect preferences for the ground truth reward function is unrealistic. B-Pref alleviates this by simulating teachers with a wide array of irrationalities, and proposes metrics not solely for performance but also for robustness to these potential irrationalities. We showcase the utility of B-Pref by using it to analyze algorithmic design choices, such as selecting informative queries, for state-of-the-art preference-based RL algorithms. We hope that B-Pref can serve as a common starting point to study preference-based RL more systematically. Source code is available at https://github.com/rll-research/B-Pref.

</p>
</details>

<details><summary><b>MT3: Multi-Task Multitrack Music Transcription</b>
<a href="https://arxiv.org/abs/2111.03017">arxiv:2111.03017</a>
&#x1F4C8; 35 <br>
<p>Josh Gardner, Ian Simon, Ethan Manilow, Curtis Hawthorne, Jesse Engel</p></summary>
<p>

**Abstract:** Automatic Music Transcription (AMT), inferring musical notes from raw audio, is a challenging task at the core of music understanding. Unlike Automatic Speech Recognition (ASR), which typically focuses on the words of a single speaker, AMT often requires transcribing multiple instruments simultaneously, all while preserving fine-scale pitch and timing information. Further, many AMT datasets are "low-resource", as even expert musicians find music transcription difficult and time-consuming. Thus, prior work has focused on task-specific architectures, tailored to the individual instruments of each task. In this work, motivated by the promising results of sequence-to-sequence transfer learning for low-resource Natural Language Processing (NLP), we demonstrate that a general-purpose Transformer model can perform multi-task AMT, jointly transcribing arbitrary combinations of musical instruments across several transcription datasets. We show this unified training framework achieves high-quality transcription results across a range of datasets, dramatically improving performance for low-resource instruments (such as guitar), while preserving strong performance for abundant instruments (such as piano). Finally, by expanding the scope of AMT, we expose the need for more consistent evaluation metrics and better dataset alignment, and provide a strong baseline for this new direction of multi-task AMT.

</p>
</details>

<details><summary><b>LILA: Language-Informed Latent Actions</b>
<a href="https://arxiv.org/abs/2111.03205">arxiv:2111.03205</a>
&#x1F4C8; 33 <br>
<p>Siddharth Karamcheti, Megha Srivastava, Percy Liang, Dorsa Sadigh</p></summary>
<p>

**Abstract:** We introduce Language-Informed Latent Actions (LILA), a framework for learning natural language interfaces in the context of human-robot collaboration. LILA falls under the shared autonomy paradigm: in addition to providing discrete language inputs, humans are given a low-dimensional controller $-$ e.g., a 2 degree-of-freedom (DoF) joystick that can move left/right and up/down $-$ for operating the robot. LILA learns to use language to modulate this controller, providing users with a language-informed control space: given an instruction like "place the cereal bowl on the tray," LILA may learn a 2-DoF space where one dimension controls the distance from the robot's end-effector to the bowl, and the other dimension controls the robot's end-effector pose relative to the grasp point on the bowl. We evaluate LILA with real-world user studies, where users can provide a language instruction while operating a 7-DoF Franka Emika Panda Arm to complete a series of complex manipulation tasks. We show that LILA models are not only more sample efficient and performant than imitation learning and end-effector control baselines, but that they are also qualitatively preferred by users.

</p>
</details>

<details><summary><b>GraN-GAN: Piecewise Gradient Normalization for Generative Adversarial Networks</b>
<a href="https://arxiv.org/abs/2111.03162">arxiv:2111.03162</a>
&#x1F4C8; 21 <br>
<p>Vineeth S. Bhaskara, Tristan Aumentado-Armstrong, Allan Jepson, Alex Levinshtein</p></summary>
<p>

**Abstract:** Modern generative adversarial networks (GANs) predominantly use piecewise linear activation functions in discriminators (or critics), including ReLU and LeakyReLU. Such models learn piecewise linear mappings, where each piece handles a subset of the input space, and the gradients per subset are piecewise constant. Under such a class of discriminator (or critic) functions, we present Gradient Normalization (GraN), a novel input-dependent normalization method, which guarantees a piecewise K-Lipschitz constraint in the input space. In contrast to spectral normalization, GraN does not constrain processing at the individual network layers, and, unlike gradient penalties, strictly enforces a piecewise Lipschitz constraint almost everywhere. Empirically, we demonstrate improved image generation performance across multiple datasets (incl. CIFAR-10/100, STL-10, LSUN bedrooms, and CelebA), GAN loss functions, and metrics. Further, we analyze altering the often untuned Lipschitz constant K in several standard GANs, not only attaining significant performance gains, but also finding connections between K and training dynamics, particularly in low-gradient loss plateaus, with the common Adam optimizer.

</p>
</details>

<details><summary><b>Scaffolding Sets</b>
<a href="https://arxiv.org/abs/2111.03135">arxiv:2111.03135</a>
&#x1F4C8; 21 <br>
<p>Maya Burhanpurkar, Zhun Deng, Cynthia Dwork, Linjun Zhang</p></summary>
<p>

**Abstract:** Predictors map individual instances in a population to the interval $[0,1]$. For a collection $\mathcal C$ of subsets of a population, a predictor is multi-calibrated with respect to $\mathcal C$ if it is simultaneously calibrated on each set in $\mathcal C$. We initiate the study of the construction of scaffolding sets, a small collection $\mathcal S$ of sets with the property that multi-calibration with respect to $\mathcal S$ ensures correctness, and not just calibration, of the predictor. Our approach is inspired by the folk wisdom that the intermediate layers of a neural net learn a highly structured and useful data representation.

</p>
</details>

<details><summary><b>Deep Learning Methods for Daily Wildfire Danger Forecasting</b>
<a href="https://arxiv.org/abs/2111.02736">arxiv:2111.02736</a>
&#x1F4C8; 10 <br>
<p>Ioannis Prapas, Spyros Kondylatos, Ioannis Papoutsis, Gustau Camps-Valls, Michele Ronco, Miguel-Ángel Fernández-Torres, Maria Piles Guillem, Nuno Carvalhais</p></summary>
<p>

**Abstract:** Wildfire forecasting is of paramount importance for disaster risk reduction and environmental sustainability. We approach daily fire danger prediction as a machine learning task, using historical Earth observation data from the last decade to predict next-day's fire danger. To that end, we collect, pre-process and harmonize an open-access datacube, featuring a set of covariates that jointly affect the fire occurrence and spread, such as weather conditions, satellite-derived products, topography features and variables related to human activity. We implement a variety of Deep Learning (DL) models to capture the spatial, temporal or spatio-temporal context and compare them against a Random Forest (RF) baseline. We find that either spatial or temporal context is enough to surpass the RF, while a ConvLSTM that exploits the spatio-temporal context performs best with a test Area Under the Receiver Operating Characteristic of 0.926. Our DL-based proof-of-concept provides national-scale daily fire danger maps at a much higher spatial resolution than existing operational solutions.

</p>
</details>

<details><summary><b>CoreLM: Coreference-aware Language Model Fine-Tuning</b>
<a href="https://arxiv.org/abs/2111.02687">arxiv:2111.02687</a>
&#x1F4C8; 8 <br>
<p>Nikolaos Stylianou, Ioannis Vlahavas</p></summary>
<p>

**Abstract:** Language Models are the underpin of all modern Natural Language Processing (NLP) tasks. The introduction of the Transformers architecture has contributed significantly into making Language Modeling very effective across many NLP task, leading to significant advancements in the field. However, Transformers come with a big computational cost, which grows quadratically with respect to the input length. This presents a challenge as to understand long texts requires a lot of context. In this paper, we propose a Fine-Tuning framework, named CoreLM, that extends the architecture of current Pretrained Language Models so that they incorporate explicit entity information. By introducing entity representations, we make available information outside the contextual space of the model, which results in a better Language Model for a fraction of the computational cost. We implement our approach using GPT2 and compare the fine-tuned model to the original. Our proposed model achieves a lower Perplexity in GUMBY and LAMBDADA datasets when compared to GPT2 and a fine-tuned version of GPT2 without any changes. We also compare the models' performance in terms of Accuracy in LAMBADA and Children's Book Test, with and without the use of model-created coreference annotations.

</p>
</details>

<details><summary><b>Adversarial Attacks on Knowledge Graph Embeddings via Instance Attribution Methods</b>
<a href="https://arxiv.org/abs/2111.03120">arxiv:2111.03120</a>
&#x1F4C8; 7 <br>
<p>Peru Bhardwaj, John Kelleher, Luca Costabello, Declan O'Sullivan</p></summary>
<p>

**Abstract:** Despite the widespread use of Knowledge Graph Embeddings (KGE), little is known about the security vulnerabilities that might disrupt their intended behaviour. We study data poisoning attacks against KGE models for link prediction. These attacks craft adversarial additions or deletions at training time to cause model failure at test time. To select adversarial deletions, we propose to use the model-agnostic instance attribution methods from Interpretable Machine Learning, which identify the training instances that are most influential to a neural model's predictions on test instances. We use these influential triples as adversarial deletions. We further propose a heuristic method to replace one of the two entities in each influential triple to generate adversarial additions. Our experiments show that the proposed strategies outperform the state-of-art data poisoning attacks on KGE models and improve the MRR degradation due to the attacks by up to 62% over the baselines.

</p>
</details>

<details><summary><b>Unsupervised Change Detection of Extreme Events Using ML On-Board</b>
<a href="https://arxiv.org/abs/2111.02995">arxiv:2111.02995</a>
&#x1F4C8; 7 <br>
<p>Vít Růžička, Anna Vaughan, Daniele De Martini, James Fulton, Valentina Salvatelli, Chris Bridges, Gonzalo Mateo-Garcia, Valentina Zantedeschi</p></summary>
<p>

**Abstract:** In this paper, we introduce RaVAEn, a lightweight, unsupervised approach for change detection in satellite data based on Variational Auto-Encoders (VAEs) with the specific purpose of on-board deployment. Applications such as disaster management enormously benefit from the rapid availability of satellite observations. Traditionally, data analysis is performed on the ground after all data is transferred - downlinked - to a ground station. Constraint on the downlink capabilities therefore affects any downstream application. In contrast, RaVAEn pre-processes the sampled data directly on the satellite and flags changed areas to prioritise for downlink, shortening the response time. We verified the efficacy of our system on a dataset composed of time series of catastrophic events - which we plan to release alongside this publication - demonstrating that RaVAEn outperforms pixel-wise baselines. Finally we tested our approach on resource-limited hardware for assessing computational and memory limitations.

</p>
</details>

<details><summary><b>Mixed-Integer Optimization with Constraint Learning</b>
<a href="https://arxiv.org/abs/2111.04469">arxiv:2111.04469</a>
&#x1F4C8; 6 <br>
<p>Donato Maragno, Holly Wiberg, Dimitris Bertsimas, S. Ilker Birbil, Dick den Hertog, Adejuyigbe Fajemisin</p></summary>
<p>

**Abstract:** We establish a broad methodological foundation for mixed-integer optimization with learned constraints. We propose an end-to-end pipeline for data-driven decision making in which constraints and objectives are directly learned from data using machine learning, and the trained models are embedded in an optimization formulation. We exploit the mixed-integer optimization-representability of many machine learning methods, including linear models, decision trees, ensembles, and multi-layer perceptrons. The consideration of multiple methods allows us to capture various underlying relationships between decisions, contextual variables, and outcomes. We also characterize a decision trust region using the convex hull of the observations, to ensure credible recommendations and avoid extrapolation. We efficiently incorporate this representation using column generation and clustering. In combination with domain-driven constraints and objective terms, the embedded models and trust region define a mixed-integer optimization problem for prescription generation. We implement this framework as a Python package (OptiCL) for practitioners. We demonstrate the method in both chemotherapy optimization and World Food Programme planning. The case studies illustrate the benefit of the framework in generating high-quality prescriptions, the value added by the trust region, the incorporation of multiple machine learning methods, and the inclusion of multiple learned constraints.

</p>
</details>

<details><summary><b>An overview of event extraction and its applications</b>
<a href="https://arxiv.org/abs/2111.03212">arxiv:2111.03212</a>
&#x1F4C8; 6 <br>
<p>Jiangwei Liu, Liangyu Min, Xiaohong Huang</p></summary>
<p>

**Abstract:** With the rapid development of information technology, online platforms have produced enormous text resources. As a particular form of Information Extraction (IE), Event Extraction (EE) has gained increasing popularity due to its ability to automatically extract events from human language. However, there are limited literature surveys on event extraction. Existing review works either spend much effort describing the details of various approaches or focus on a particular field. This study provides a comprehensive overview of the state-of-the-art event extraction methods and their applications from text, including closed-domain and open-domain event extraction. A trait of this survey is that it provides an overview in moderate complexity, avoiding involving too many details of particular approaches. This study focuses on discussing the common characters, application fields, advantages, and disadvantages of representative works, ignoring the specificities of individual approaches. Finally, we summarize the common issues, current solutions, and future research directions. We hope this work could help researchers and practitioners obtain a quick overview of recent event extraction.

</p>
</details>

<details><summary><b>Value Function Spaces: Skill-Centric State Abstractions for Long-Horizon Reasoning</b>
<a href="https://arxiv.org/abs/2111.03189">arxiv:2111.03189</a>
&#x1F4C8; 6 <br>
<p>Dhruv Shah, Peng Xu, Yao Lu, Ted Xiao, Alexander Toshev, Sergey Levine, Brian Ichter</p></summary>
<p>

**Abstract:** Reinforcement learning can train policies that effectively perform complex tasks. However for long-horizon tasks, the performance of these methods degrades with horizon, often necessitating reasoning over and composing lower-level skills. Hierarchical reinforcement learning aims to enable this by providing a bank of low-level skills as action abstractions. Hierarchies can further improve on this by abstracting the space states as well. We posit that a suitable state abstraction should depend on the capabilities of the available lower-level policies. We propose Value Function Spaces: a simple approach that produces such a representation by using the value functions corresponding to each lower-level skill. These value functions capture the affordances of the scene, thus forming a representation that compactly abstracts task relevant information and robustly ignores distractors. Empirical evaluations for maze-solving and robotic manipulation tasks demonstrate that our approach improves long-horizon performance and enables better zero-shot generalization than alternative model-free and model-based methods.

</p>
</details>

<details><summary><b>Are You Smarter Than a Random Expert? The Robust Aggregation of Substitutable Signals</b>
<a href="https://arxiv.org/abs/2111.03153">arxiv:2111.03153</a>
&#x1F4C8; 6 <br>
<p>Eric Neyman, Tim Roughgarden</p></summary>
<p>

**Abstract:** The problem of aggregating expert forecasts is ubiquitous in fields as wide-ranging as machine learning, economics, climate science, and national security. Despite this, our theoretical understanding of this question is fairly shallow. This paper initiates the study of forecast aggregation in a context where experts' knowledge is chosen adversarially from a broad class of information structures. While in full generality it is impossible to achieve a nontrivial performance guarantee, we show that doing so is possible under a condition on the experts' information structure that we call \emph{projective substitutes}. The projective substitutes condition is a notion of informational substitutes: that there are diminishing marginal returns to learning the experts' signals. We show that under the projective substitutes condition, taking the average of the experts' forecasts improves substantially upon the strategy of trusting a random expert. We then consider a more permissive setting, in which the aggregator has access to the prior. We show that by averaging the experts' forecasts and then \emph{extremizing} the average by moving it away from the prior by a constant factor, the aggregator's performance guarantee is substantially better than is possible without knowledge of the prior. Our results give a theoretical grounding to past empirical research on extremization and help give guidance on the appropriate amount to extremize.

</p>
</details>

<details><summary><b>Adversarial Attacks on Graph Classification via Bayesian Optimisation</b>
<a href="https://arxiv.org/abs/2111.02842">arxiv:2111.02842</a>
&#x1F4C8; 6 <br>
<p>Xingchen Wan, Henry Kenlay, Binxin Ru, Arno Blaas, Michael A. Osborne, Xiaowen Dong</p></summary>
<p>

**Abstract:** Graph neural networks, a popular class of models effective in a wide range of graph-based learning tasks, have been shown to be vulnerable to adversarial attacks. While the majority of the literature focuses on such vulnerability in node-level classification tasks, little effort has been dedicated to analysing adversarial attacks on graph-level classification, an important problem with numerous real-life applications such as biochemistry and social network analysis. The few existing methods often require unrealistic setups, such as access to internal information of the victim models, or an impractically-large number of queries. We present a novel Bayesian optimisation-based attack method for graph classification models. Our method is black-box, query-efficient and parsimonious with respect to the perturbation applied. We empirically validate the effectiveness and flexibility of the proposed method on a wide range of graph classification tasks involving varying graph properties, constraints and modes of attack. Finally, we analyse common interpretable patterns behind the adversarial samples produced, which may shed further light on the adversarial robustness of graph classification models.

</p>
</details>

<details><summary><b>A Riemannian Accelerated Proximal Extragradient Framework and its Implications</b>
<a href="https://arxiv.org/abs/2111.02763">arxiv:2111.02763</a>
&#x1F4C8; 6 <br>
<p>Jikai Jin, Suvrit Sra</p></summary>
<p>

**Abstract:** The study of accelerated gradient methods in Riemannian optimization has recently witnessed notable progress. However, in contrast with the Euclidean setting, a systematic understanding of acceleration is still lacking in the Riemannian setting. We revisit the \emph{Accelerated Hybrid Proximal Extragradient} (A-HPE) method of \citet{monteiro2013accelerated}, a powerful framework for obtaining accelerated Euclidean methods. Subsequently, we propose a Riemannian version of A-HPE. The basis of our analysis of Riemannian A-HPE is a set of insights into Euclidean A-HPE, which we combine with a careful control of distortion caused by Riemannian geometry. We describe a number of Riemannian accelerated gradient methods as concrete instances of our framework.

</p>
</details>

<details><summary><b>Context-Aware Transformer Transducer for Speech Recognition</b>
<a href="https://arxiv.org/abs/2111.03250">arxiv:2111.03250</a>
&#x1F4C8; 5 <br>
<p>Feng-Ju Chang, Jing Liu, Martin Radfar, Athanasios Mouchtaris, Maurizio Omologo, Ariya Rastrow, Siegfried Kunzmann</p></summary>
<p>

**Abstract:** End-to-end (E2E) automatic speech recognition (ASR) systems often have difficulty recognizing uncommon words, that appear infrequently in the training data. One promising method, to improve the recognition accuracy on such rare words, is to latch onto personalized/contextual information at inference. In this work, we present a novel context-aware transformer transducer (CATT) network that improves the state-of-the-art transformer-based ASR system by taking advantage of such contextual signals. Specifically, we propose a multi-head attention-based context-biasing network, which is jointly trained with the rest of the ASR sub-networks. We explore different techniques to encode contextual data and to create the final attention context vectors. We also leverage both BLSTM and pretrained BERT based models to encode contextual data and guide the network training. Using an in-house far-field dataset, we show that CATT, using a BERT based context encoder, improves the word error rate of the baseline transformer transducer and outperforms an existing deep contextual model by 24.2% and 19.4% respectively.

</p>
</details>

<details><summary><b>My House, My Rules: Learning Tidying Preferences with Graph Neural Networks</b>
<a href="https://arxiv.org/abs/2111.03112">arxiv:2111.03112</a>
&#x1F4C8; 5 <br>
<p>Ivan Kapelyukh, Edward Johns</p></summary>
<p>

**Abstract:** Robots that arrange household objects should do so according to the user's preferences, which are inherently subjective and difficult to model. We present NeatNet: a novel Variational Autoencoder architecture using Graph Neural Network layers, which can extract a low-dimensional latent preference vector from a user by observing how they arrange scenes. Given any set of objects, this vector can then be used to generate an arrangement which is tailored to that user's spatial preferences, with word embeddings used for generalisation to new objects. We develop a tidying simulator to gather rearrangement examples from 75 users, and demonstrate empirically that our method consistently produces neat and personalised arrangements across a variety of rearrangement scenarios.

</p>
</details>

<details><summary><b>Reducing the impact of out of vocabulary words in the translation of natural language questions into SPARQL queries</b>
<a href="https://arxiv.org/abs/2111.03000">arxiv:2111.03000</a>
&#x1F4C8; 5 <br>
<p>Manuel A. Borroto Santana, Francesco Ricca, Bernardo Cuteri</p></summary>
<p>

**Abstract:** Accessing the large volumes of information available in public knowledge bases might be complicated for those users unfamiliar with the SPARQL query language. Automatic translation of questions posed in natural language in SPARQL has the potential of overcoming this problem. Existing systems based on neural-machine translation are very effective but easily fail in recognizing words that are Out Of the Vocabulary (OOV) of the training set. This is a serious issue while querying large ontologies. In this paper, we combine Named Entity Linking, Named Entity Recognition, and Neural Machine Translation to perform automatic translation of natural language questions into SPARQL queries. We demonstrate empirically that our approach is more effective and resilient to OOV words than existing approaches by running the experiments on Monument, QALD-9, and LC-QuAD v1, which are well-known datasets for Question Answering over DBpedia.

</p>
</details>

<details><summary><b>Towards dynamic multi-modal phenotyping using chest radiographs and physiological data</b>
<a href="https://arxiv.org/abs/2111.02710">arxiv:2111.02710</a>
&#x1F4C8; 5 <br>
<p>Nasir Hayat, Krzysztof J. Geras, Farah E. Shamout</p></summary>
<p>

**Abstract:** The healthcare domain is characterized by heterogeneous data modalities, such as imaging and physiological data. In practice, the variety of medical data assists clinicians in decision-making. However, most of the current state-of-the-art deep learning models solely rely upon carefully curated data of a single modality. In this paper, we propose a dynamic training approach to learn modality-specific data representations and to integrate auxiliary features, instead of solely relying on a single modality. Our preliminary experiments results for a patient phenotyping task using physiological data in MIMIC-IV & chest radiographs in the MIMIC- CXR dataset show that our proposed approach achieves the highest area under the receiver operating characteristic curve (AUROC) (0.764 AUROC) compared to the performance of the benchmark method in previous work, which only used physiological data (0.740 AUROC). For a set of five recurring or chronic diseases with periodic acute episodes, including cardiac dysrhythmia, conduction disorders, and congestive heart failure, the AUROC improves from 0.747 to 0.798. This illustrates the benefit of leveraging the chest imaging modality in the phenotyping task and highlights the potential of multi-modal learning in medical applications.

</p>
</details>

<details><summary><b>TimeMatch: Unsupervised Cross-Region Adaptation by Temporal Shift Estimation</b>
<a href="https://arxiv.org/abs/2111.02682">arxiv:2111.02682</a>
&#x1F4C8; 5 <br>
<p>Joachim Nyborg, Charlotte Pelletier, Sébastien Lefèvre, Ira Assent</p></summary>
<p>

**Abstract:** The recent developments of deep learning models that capture the complex temporal patterns of crop phenology have greatly advanced crop classification of Satellite Image Time Series (SITS). However, when applied to target regions spatially different from the training region, these models perform poorly without any target labels due to the temporal shift of crop phenology between regions. To address this unsupervised cross-region adaptation setting, existing methods learn domain-invariant features without any target supervision, but not the temporal shift itself. As a consequence, these techniques provide only limited benefits for SITS. In this paper, we propose TimeMatch, a new unsupervised domain adaptation method for SITS that directly accounts for the temporal shift. TimeMatch consists of two components: 1) temporal shift estimation, which estimates the temporal shift of the unlabeled target region with a source-trained model, and 2) TimeMatch learning, which combines temporal shift estimation with semi-supervised learning to adapt a classifier to an unlabeled target region. We also introduce an open-access dataset for cross-region adaptation with SITS from four different regions in Europe. On this dataset, we demonstrate that TimeMatch outperforms all competing methods by 11% in F1-score across five different adaptation scenarios, setting a new state-of-the-art for cross-region adaptation.

</p>
</details>

<details><summary><b>A deep ensemble approach to X-ray polarimetry</b>
<a href="https://arxiv.org/abs/2111.03047">arxiv:2111.03047</a>
&#x1F4C8; 4 <br>
<p>A. L. Peirson, R. W. Romani</p></summary>
<p>

**Abstract:** X-ray polarimetry will soon open a new window on the high energy universe with the launch of NASA's Imaging X-ray Polarimetry Explorer (IXPE). Polarimeters are currently limited by their track reconstruction algorithms, which typically use linear estimators and do not consider individual event quality. We present a modern deep learning method for maximizing the sensitivity of X-ray telescopic observations with imaging polarimeters, with a focus on the gas pixel detectors (GPDs) to be flown on IXPE. We use a weighted maximum likelihood combination of predictions from a deep ensemble of ResNets, trained on Monte Carlo event simulations. We derive and apply the optimal event weighting for maximizing the polarization signal-to-noise ratio (SNR) in track reconstruction algorithms. For typical power-law source spectra, our method improves on the current state of the art, providing a ~40% decrease in required exposure times for a given SNR.

</p>
</details>

<details><summary><b>Identifying nonlinear dynamical systems from multi-modal time series data</b>
<a href="https://arxiv.org/abs/2111.02922">arxiv:2111.02922</a>
&#x1F4C8; 4 <br>
<p>Philine Lou Bommer, Daniel Kramer, Carlo Tombolini, Georgia Koppe, Daniel Durstewitz</p></summary>
<p>

**Abstract:** Empirically observed time series in physics, biology, or medicine, are commonly generated by some underlying dynamical system (DS) which is the target of scientific interest. There is an increasing interest to harvest machine learning methods to reconstruct this latent DS in a completely data-driven, unsupervised way. In many areas of science it is common to sample time series observations from many data modalities simultaneously, e.g. electrophysiological and behavioral time series in a typical neuroscience experiment. However, current machine learning tools for reconstructing DSs usually focus on just one data modality. Here we propose a general framework for multi-modal data integration for the purpose of nonlinear DS identification and cross-modal prediction. This framework is based on dynamically interpretable recurrent neural networks as general approximators of nonlinear DSs, coupled to sets of modality-specific decoder models from the class of generalized linear models. Both an expectation-maximization and a variational inference algorithm for model training are advanced and compared. We show on nonlinear DS benchmarks that our algorithms can efficiently compensate for too noisy or missing information in one data channel by exploiting other channels, and demonstrate on experimental neuroscience data how the algorithm learns to link different data domains to the underlying dynamics

</p>
</details>

<details><summary><b>Extended Abstract Version: CNN-based Human Detection System for UAVs in Search and Rescue</b>
<a href="https://arxiv.org/abs/2111.02870">arxiv:2111.02870</a>
&#x1F4C8; 4 <br>
<p>Nikite Mesvan</p></summary>
<p>

**Abstract:** This paper proposes an approach for the task of searching and detecting human using a convolutional neural network and a Quadcopter hardware platform. A pre-trained CNN model is applied to a Raspberry Pi B and a single camera is equipped at the bottom of the Quadcopter. The Quadcopter uses accelerometer-gyroscope sensor and ultrasonic sensor for balancing control. However, these sensors are susceptible to noise caused by the driving forces such as the vibration of the motors, thus, noise processing is implemented. Experiments proved that the system works well on the Raspberry Pi B with a processing speed of 3 fps.

</p>
</details>

<details><summary><b>Testing using Privileged Information by Adapting Features with Statistical Dependence</b>
<a href="https://arxiv.org/abs/2111.02865">arxiv:2111.02865</a>
&#x1F4C8; 4 <br>
<p>Kwang In Kim, James Tompkin</p></summary>
<p>

**Abstract:** Given an imperfect predictor, we exploit additional features at test time to improve the predictions made, without retraining and without knowledge of the prediction function. This scenario arises if training labels or data are proprietary, restricted, or no longer available, or if training itself is prohibitively expensive. We assume that the additional features are useful if they exhibit strong statistical dependence to the underlying perfect predictor. Then, we empirically estimate and strengthen the statistical dependence between the initial noisy predictor and the additional features via manifold denoising. As an example, we show that this approach leads to improvement in real-world visual attribute ranking. Project webpage: http://www.jamestompkin.com/tupi

</p>
</details>

<details><summary><b>Adversarial GLUE: A Multi-Task Benchmark for Robustness Evaluation of Language Models</b>
<a href="https://arxiv.org/abs/2111.02840">arxiv:2111.02840</a>
&#x1F4C8; 4 <br>
<p>Boxin Wang, Chejian Xu, Shuohang Wang, Zhe Gan, Yu Cheng, Jianfeng Gao, Ahmed Hassan Awadallah, Bo Li</p></summary>
<p>

**Abstract:** Large-scale pre-trained language models have achieved tremendous success across a wide range of natural language understanding (NLU) tasks, even surpassing human performance. However, recent studies reveal that the robustness of these models can be challenged by carefully crafted textual adversarial examples. While several individual datasets have been proposed to evaluate model robustness, a principled and comprehensive benchmark is still missing. In this paper, we present Adversarial GLUE (AdvGLUE), a new multi-task benchmark to quantitatively and thoroughly explore and evaluate the vulnerabilities of modern large-scale language models under various types of adversarial attacks. In particular, we systematically apply 14 textual adversarial attack methods to GLUE tasks to construct AdvGLUE, which is further validated by humans for reliable annotations. Our findings are summarized as follows. (i) Most existing adversarial attack algorithms are prone to generating invalid or ambiguous adversarial examples, with around 90% of them either changing the original semantic meanings or misleading human annotators as well. Therefore, we perform a careful filtering process to curate a high-quality benchmark. (ii) All the language models and robust training methods we tested perform poorly on AdvGLUE, with scores lagging far behind the benign accuracy. We hope our work will motivate the development of new adversarial attacks that are more stealthy and semantic-preserving, as well as new robust language models against sophisticated adversarial attacks. AdvGLUE is available at https://adversarialglue.github.io.

</p>
</details>

<details><summary><b>A Cyber Threat Intelligence Sharing Scheme based on Federated Learning for Network Intrusion Detection</b>
<a href="https://arxiv.org/abs/2111.02791">arxiv:2111.02791</a>
&#x1F4C8; 4 <br>
<p>Mohanad Sarhan, Siamak Layeghy, Nour Moustafa, Marius Portmann</p></summary>
<p>

**Abstract:** The uses of Machine Learning (ML) in detection of network attacks have been effective when designed and evaluated in a single organisation. However, it has been very challenging to design an ML-based detection system by utilising heterogeneous network data samples originating from several sources. This is mainly due to privacy concerns and the lack of a universal format of datasets. In this paper, we propose a collaborative federated learning scheme to address these issues. The proposed framework allows multiple organisations to join forces in the design, training, and evaluation of a robust ML-based network intrusion detection system. The threat intelligence scheme utilises two critical aspects for its application; the availability of network data traffic in a common format to allow for the extraction of meaningful patterns across data sources. Secondly, the adoption of a federated learning mechanism to avoid the necessity of sharing sensitive users' information between organisations. As a result, each organisation benefits from other organisations cyber threat intelligence while maintaining the privacy of its data internally. The model is trained locally and only the updated weights are shared with the remaining participants in the federated averaging process. The framework has been designed and evaluated in this paper by using two key datasets in a NetFlow format known as NF-UNSW-NB15-v2 and NF-BoT-IoT-v2. Two other common scenarios are considered in the evaluation process; a centralised training method where the local data samples are shared with other organisations and a localised training method where no threat intelligence is shared. The results demonstrate the efficiency and effectiveness of the proposed framework by designing a universal ML model effectively classifying benign and intrusive traffic originating from multiple organisations without the need for local data exchange.

</p>
</details>

<details><summary><b>Multi-scale 2D Representation Learning for weakly-supervised moment retrieval</b>
<a href="https://arxiv.org/abs/2111.02741">arxiv:2111.02741</a>
&#x1F4C8; 4 <br>
<p>Ding Li, Rui Wu, Yongqiang Tang, Zhizhong Zhang, Wensheng Zhang</p></summary>
<p>

**Abstract:** Video moment retrieval aims to search the moment most relevant to a given language query. However, most existing methods in this community often require temporal boundary annotations which are expensive and time-consuming to label. Hence weakly supervised methods have been put forward recently by only using coarse video-level label. Despite effectiveness, these methods usually process moment candidates independently, while ignoring a critical issue that the natural temporal dependencies between candidates in different temporal scales. To cope with this issue, we propose a Multi-scale 2D Representation Learning method for weakly supervised video moment retrieval. Specifically, we first construct a two-dimensional map for each temporal scale to capture the temporal dependencies between candidates. Two dimensions in this map indicate the start and end time points of these candidates. Then, we select top-K candidates from each scale-varied map with a learnable convolutional neural network. With a newly designed Moments Evaluation Module, we obtain the alignment scores of the selected candidates. At last, the similarity between captions and language query is served as supervision for further training the candidates' selector. Experiments on two benchmark datasets Charades-STA and ActivityNet Captions demonstrate that our approach achieves superior performance to state-of-the-art results.

</p>
</details>

<details><summary><b>A Fine-tuned Wav2vec 2.0/HuBERT Benchmark For Speech Emotion Recognition, Speaker Verification and Spoken Language Understanding</b>
<a href="https://arxiv.org/abs/2111.02735">arxiv:2111.02735</a>
&#x1F4C8; 4 <br>
<p>Yingzhi Wang, Abdelmoumene Boumadane, Abdelwahab Heba</p></summary>
<p>

**Abstract:** Self-supervised speech representations such as wav2vec 2.0 and HuBERT are making revolutionary progress in Automatic Speech Recognition (ASR). However, self-supervised models have not been totally proved to produce better performance on tasks other than ASR. In this work, we explore partial fine-tuning and entire fine-tuning on wav2vec 2.0 and HuBERT pre-trained models for three non-ASR speech tasks : Speech Emotion Recognition, Speaker Verification and Spoken Language Understanding. We also compare pre-trained models with/without ASR fine-tuning. With simple down-stream frameworks, the best scores reach 79.58% weighted accuracy for Speech Emotion Recognition on IEMOCAP, 2.36% equal error rate for Speaker Verification on VoxCeleb1, 87.51% accuracy for Intent Classification and 75.32% F1 for Slot Filling on SLURP, thus setting a new state-of-the-art for these three benchmarks, proving that fine-tuned wav2vec 2.0 and HuBERT models can better learn prosodic, voice-print and semantic representations.

</p>
</details>

<details><summary><b>When Neural Networks Using Different Sensors Create Similar Features</b>
<a href="https://arxiv.org/abs/2111.02732">arxiv:2111.02732</a>
&#x1F4C8; 4 <br>
<p>Hugues Moreau, Andréa Vassilev, Liming Chen</p></summary>
<p>

**Abstract:** Multimodal problems are omnipresent in the real world: autonomous driving, robotic grasping, scene understanding, etc... We draw from the well-developed analysis of similarity to provide an example of a problem where neural networks are trained from different sensors, and where the features extracted from these sensors still carry similar information. More precisely, we demonstrate that for each sensor, the linear combination of the features from the last layer that correlates the most with other sensors corresponds to the classification components of the classification layer.

</p>
</details>

<details><summary><b>Tea Chrysanthemum Detection under Unstructured Environments Using the TC-YOLO Model</b>
<a href="https://arxiv.org/abs/2111.02724">arxiv:2111.02724</a>
&#x1F4C8; 4 <br>
<p>Chao Qi, Junfeng Gao, Simon Pearson, Helen Harman, Kunjie Chen, Lei Shu</p></summary>
<p>

**Abstract:** Tea chrysanthemum detection at its flowering stage is one of the key components for selective chrysanthemum harvesting robot development. However, it is a challenge to detect flowering chrysanthemums under unstructured field environments given the variations on illumination, occlusion and object scale. In this context, we propose a highly fused and lightweight deep learning architecture based on YOLO for tea chrysanthemum detection (TC-YOLO). First, in the backbone component and neck component, the method uses the Cross-Stage Partially Dense Network (CSPDenseNet) as the main network, and embeds custom feature fusion modules to guide the gradient flow. In the final head component, the method combines the recursive feature pyramid (RFP) multiscale fusion reflow structure and the Atrous Spatial Pyramid Pool (ASPP) module with cavity convolution to achieve the detection task. The resulting model was tested on 300 field images, showing that under the NVIDIA Tesla P100 GPU environment, if the inference speed is 47.23 FPS for each image (416 * 416), TC-YOLO can achieve the average precision (AP) of 92.49% on our own tea chrysanthemum dataset. In addition, this method (13.6M) can be deployed on a single mobile GPU, and it could be further developed as a perception system for a selective chrysanthemum harvesting robot in the future.

</p>
</details>

<details><summary><b>Benchmarking Multimodal AutoML for Tabular Data with Text Fields</b>
<a href="https://arxiv.org/abs/2111.02705">arxiv:2111.02705</a>
&#x1F4C8; 4 <br>
<p>Xingjian Shi, Jonas Mueller, Nick Erickson, Mu Li, Alexander J. Smola</p></summary>
<p>

**Abstract:** We consider the use of automated supervised learning systems for data tables that not only contain numeric/categorical columns, but one or more text fields as well. Here we assemble 18 multimodal data tables that each contain some text fields and stem from a real business application. Our publicly-available benchmark enables researchers to comprehensively evaluate their own methods for supervised learning with numeric, categorical, and text features. To ensure that any single modeling strategy which performs well over all 18 datasets will serve as a practical foundation for multimodal text/tabular AutoML, the diverse datasets in our benchmark vary greatly in: sample size, problem types (a mix of classification and regression tasks), number of features (with the number of text columns ranging from 1 to 28 between datasets), as well as how the predictive signal is decomposed between text vs. numeric/categorical features (and predictive interactions thereof). Over this benchmark, we evaluate various straightforward pipelines to model such data, including standard two-stage approaches where NLP is used to featurize the text such that AutoML for tabular data can then be applied. Compared with human data science teams, the fully automated methodology that performed best on our benchmark (stack ensembling a multimodal Transformer with various tree models) also manages to rank 1st place when fit to the raw text/tabular data in two MachineHack prediction competitions and 2nd place (out of 2380 teams) in Kaggle's Mercari Price Suggestion Challenge.

</p>
</details>

<details><summary><b>Sensory attenuation develops as a result of sensorimotor experience</b>
<a href="https://arxiv.org/abs/2111.02666">arxiv:2111.02666</a>
&#x1F4C8; 4 <br>
<p>Hayato Idei, Wataru Ohata, Yuichi Yamashita, Tetsuya Ogata, Jun Tani</p></summary>
<p>

**Abstract:** The brain attenuates its responses to self-produced exteroceptions (e.g., we cannot tickle ourselves). Is this phenomenon, known as sensory attenuation, enabled innately, or is it acquired through learning? For decades, theoretical and biological studies have suggested related neural functions of sensory attenuation, such as an efference copy of the motor command and neuromodulation; however, the developmental aspect of sensory attenuation remains unexamined. Here, our simulation study using a recurrent neural network, operated according to a computational principle called free-energy minimization, shows that sensory attenuation can be developed as a free-energy state in the network through learning of two distinct types of sensorimotor patterns, characterized by self-produced or externally produced exteroceptive feedback. Simulation of the network, consisting of sensory (proprioceptive and exteroceptive), association, and executive areas, showed that shifts between these two types of sensorimotor patterns triggered transitions from one free-energy state to another in the network. Consequently, this induced shifts between attenuating and amplifying responses in the sensory areas. Furthermore, the executive area, proactively adjusted the precision of the prediction in lower levels while being modulated by the bottom-up sensory prediction error signal in minimizing the free-energy, thereby serving as an information hub in generating the observed shifts. We also found that innate alterations in modulation of sensory-information flow induced some characteristics analogous to schizophrenia and autism spectrum disorder. This study provides a novel perspective on neural mechanisms underlying emergence of perceptual phenomena and psychiatric disorders.

</p>
</details>

<details><summary><b>Community detection using low-dimensional network embedding algorithms</b>
<a href="https://arxiv.org/abs/2111.05267">arxiv:2111.05267</a>
&#x1F4C8; 3 <br>
<p>Aman Barot, Shankar Bhamidi, Souvik Dhara</p></summary>
<p>

**Abstract:** With the increasing relevance of large networks in important areas such as the study of contact networks for spread of disease, or social networks for their impact on geopolitics, it has become necessary to study machine learning tools that are scalable to very large networks, often containing millions of nodes. One major class of such scalable algorithms is known as network representation learning or network embedding. These algorithms try to learn representations of network functionals (e.g.~nodes) by first running multiple random walks and then using the number of co-occurrences of each pair of nodes in observed random walk segments to obtain a low-dimensional representation of nodes on some Euclidean space. The aim of this paper is to rigorously understand the performance of two major algorithms, DeepWalk and node2vec, in recovering communities for canonical network models with ground truth communities. Depending on the sparsity of the graph, we find the length of the random walk segments required such that the corresponding observed co-occurrence window is able to perform almost exact recovery of the underlying community assignments. We prove that, given some fixed co-occurrence window, node2vec using random walks with a low non-backtracking probability can succeed for much sparser networks compared to DeepWalk using simple random walks. Moreover, if the sparsity parameter is low, we provide evidence that these algorithms might not succeed in almost exact recovery. The analysis requires developing general tools for path counting on random networks having an underlying low-rank structure, which are of independent interest.

</p>
</details>

<details><summary><b>Generalized Radiograph Representation Learning via Cross-supervision between Images and Free-text Radiology Reports</b>
<a href="https://arxiv.org/abs/2111.03452">arxiv:2111.03452</a>
&#x1F4C8; 3 <br>
<p>Hong-Yu Zhou, Xiaoyu Chen, Yinghao Zhang, Ruibang Luo, Liansheng Wang, Yizhou Yu</p></summary>
<p>

**Abstract:** Pre-training lays the foundation for recent successes in radiograph analysis supported by deep learning. It learns transferable image representations by conducting large-scale fully-supervised or self-supervised learning on a source domain. However, supervised pre-training requires a complex and labor intensive two-stage human-assisted annotation process while self-supervised learning cannot compete with the supervised paradigm. To tackle these issues, we propose a cross-supervised methodology named REviewing FreE-text Reports for Supervision (REFERS), which acquires free supervision signals from original radiology reports accompanying the radiographs. The proposed approach employs a vision transformer and is designed to learn joint representations from multiple views within every patient study. REFERS outperforms its transfer learning and self-supervised learning counterparts on 4 well-known X-ray datasets under extremely limited supervision. Moreover, REFERS even surpasses methods based on a source domain of radiographs with human-assisted structured labels. Thus REFERS has the potential to replace canonical pre-training methodologies.

</p>
</details>

<details><summary><b>Multi-Objective Constrained Optimization for Energy Applications via Tree Ensembles</b>
<a href="https://arxiv.org/abs/2111.03140">arxiv:2111.03140</a>
&#x1F4C8; 3 <br>
<p>Alexander Thebelt, Calvin Tsay, Robert M. Lee, Nathan Sudermann-Merx, David Walz, Tom Tranter, Ruth Misener</p></summary>
<p>

**Abstract:** Energy systems optimization problems are complex due to strongly non-linear system behavior and multiple competing objectives, e.g. economic gain vs. environmental impact. Moreover, a large number of input variables and different variable types, e.g. continuous and categorical, are challenges commonly present in real-world applications. In some cases, proposed optimal solutions need to obey explicit input constraints related to physical properties or safety-critical operating conditions. This paper proposes a novel data-driven strategy using tree ensembles for constrained multi-objective optimization of black-box problems with heterogeneous variable spaces for which underlying system dynamics are either too complex to model or unknown. In an extensive case study comprised of synthetic benchmarks and relevant energy applications we demonstrate the competitive performance and sampling efficiency of the proposed algorithm compared to other state-of-the-art tools, making it a useful all-in-one solution for real-world applications with limited evaluation budgets.

</p>
</details>

<details><summary><b>Big-Step-Little-Step: Efficient Gradient Methods for Objectives with Multiple Scales</b>
<a href="https://arxiv.org/abs/2111.03137">arxiv:2111.03137</a>
&#x1F4C8; 3 <br>
<p>Jonathan Kelner, Annie Marsden, Vatsal Sharan, Aaron Sidford, Gregory Valiant, Honglin Yuan</p></summary>
<p>

**Abstract:** We provide new gradient-based methods for efficiently solving a broad class of ill-conditioned optimization problems. We consider the problem of minimizing a function $f : \mathbb{R}^d \rightarrow \mathbb{R}$ which is implicitly decomposable as the sum of $m$ unknown non-interacting smooth, strongly convex functions and provide a method which solves this problem with a number of gradient evaluations that scales (up to logarithmic factors) as the product of the square-root of the condition numbers of the components. This complexity bound (which we prove is nearly optimal) can improve almost exponentially on that of accelerated gradient methods, which grow as the square root of the condition number of $f$. Additionally, we provide efficient methods for solving stochastic, quadratic variants of this multiscale optimization problem. Rather than learn the decomposition of $f$ (which would be prohibitively expensive), our methods apply a clean recursive "Big-Step-Little-Step" interleaving of standard methods. The resulting algorithms use $\tilde{\mathcal{O}}(d m)$ space, are numerically stable, and open the door to a more fine-grained understanding of the complexity of convex optimization beyond condition number.

</p>
</details>

<details><summary><b>Generative Adversarial Network for Probabilistic Forecast of Random Dynamical System</b>
<a href="https://arxiv.org/abs/2111.03126">arxiv:2111.03126</a>
&#x1F4C8; 3 <br>
<p>Kyongmin Yeo, Zan Li, Wesley M. Gifford</p></summary>
<p>

**Abstract:** We present a deep learning model for data-driven simulations of random dynamical systems without a distributional assumption. The deep learning model consists of a recurrent neural network, which aims to learn the time marching structure, and a generative adversarial network to learn and sample from the probability distribution of the random dynamical system. Although generative adversarial networks provide a powerful tool to model a complex probability distribution, the training often fails without a proper regularization. Here, we propose a regularization strategy for a generative adversarial network based on consistency conditions for the sequential inference problems. First, the maximum mean discrepancy (MMD) is used to enforce the consistency between conditional and marginal distributions of a stochastic process. Then, the marginal distributions of the multiple-step predictions are regularized by using MMD or from multiple discriminators. The behavior of the proposed model is studied by using three stochastic processes with complex noise structures.

</p>
</details>

<details><summary><b>Skeleton-Split Framework using Spatial Temporal Graph Convolutional Networks for Action Recogntion</b>
<a href="https://arxiv.org/abs/2111.03106">arxiv:2111.03106</a>
&#x1F4C8; 3 <br>
<p>Motasem Alsawadi, Miguel Rio</p></summary>
<p>

**Abstract:** There has been a dramatic increase in the volume of videos and their related content uploaded to the internet. Accordingly, the need for efficient algorithms to analyse this vast amount of data has attracted significant research interest. An action recognition system based upon human body motions has been proven to interpret videos contents accurately. This work aims to recognize activities of daily living using the ST-GCN model, providing a comparison between four different partitioning strategies: spatial configuration partitioning, full distance split, connection split, and index split. To achieve this aim, we present the first implementation of the ST-GCN framework upon the HMDB-51 dataset. We have achieved 48.88 % top-1 accuracy by using the connection split partitioning approach. Through experimental simulation, we show that our proposals have achieved the highest accuracy performance on the UCF-101 dataset using the ST-GCN framework than the state-of-the-art approach. Finally, accuracy of 73.25 % top-1 is achieved by using the index split partitioning strategy.

</p>
</details>

<details><summary><b>Causal versus Marginal Shapley Values for Robotic Lever Manipulation Controlled using Deep Reinforcement Learning</b>
<a href="https://arxiv.org/abs/2111.02936">arxiv:2111.02936</a>
&#x1F4C8; 3 <br>
<p>Sindre Benjamin Remman, Inga Strümke, Anastasios M. Lekkas</p></summary>
<p>

**Abstract:** We investigate the effect of including domain knowledge about a robotic system's causal relations when generating explanations. To this end, we compare two methods from explainable artificial intelligence, the popular KernelSHAP and the recent causal SHAP, on a deep neural network trained using deep reinforcement learning on the task of controlling a lever using a robotic manipulator. A primary disadvantage of KernelSHAP is that its explanations represent only the features' direct effects on a model's output, not considering the indirect effects a feature can have on the output by affecting other features. Causal SHAP uses a partial causal ordering to alter KernelSHAP's sampling procedure to incorporate these indirect effects. This partial causal ordering defines the causal relations between the features, and we specify this using domain knowledge about the lever control task. We show that enabling an explanation method to account for indirect effects and incorporating some domain knowledge can lead to explanations that better agree with human intuition. This is especially favorable for a real-world robotics task, where there is considerable causality at play, and in addition, the required domain knowledge is often handily available.

</p>
</details>

<details><summary><b>Attacking Deep Reinforcement Learning-Based Traffic Signal Control Systems with Colluding Vehicles</b>
<a href="https://arxiv.org/abs/2111.02845">arxiv:2111.02845</a>
&#x1F4C8; 3 <br>
<p>Ao Qu, Yihong Tang, Wei Ma</p></summary>
<p>

**Abstract:** The rapid advancements of Internet of Things (IoT) and artificial intelligence (AI) have catalyzed the development of adaptive traffic signal control systems (ATCS) for smart cities. In particular, deep reinforcement learning (DRL) methods produce the state-of-the-art performance and have great potentials for practical applications. In the existing DRL-based ATCS, the controlled signals collect traffic state information from nearby vehicles, and then optimal actions (e.g., switching phases) can be determined based on the collected information. The DRL models fully "trust" that vehicles are sending the true information to the signals, making the ATCS vulnerable to adversarial attacks with falsified information. In view of this, this paper first time formulates a novel task in which a group of vehicles can cooperatively send falsified information to "cheat" DRL-based ATCS in order to save their total travel time. To solve the proposed task, we develop CollusionVeh, a generic and effective vehicle-colluding framework composed of a road situation encoder, a vehicle interpreter, and a communication mechanism. We employ our method to attack established DRL-based ATCS and demonstrate that the total travel time for the colluding vehicles can be significantly reduced with a reasonable number of learning episodes, and the colluding effect will decrease if the number of colluding vehicles increases. Additionally, insights and suggestions for the real-world deployment of DRL-based ATCS are provided. The research outcomes could help improve the reliability and robustness of the ATCS and better protect the smart mobility systems.

</p>
</details>

<details><summary><b>A text autoencoder from transformer for fast encoding language representation</b>
<a href="https://arxiv.org/abs/2111.02844">arxiv:2111.02844</a>
&#x1F4C8; 3 <br>
<p>Tan Huang</p></summary>
<p>

**Abstract:** In recent years BERT shows apparent advantages and great potential in natural language processing tasks. However, both training and applying BERT requires intensive time and resources for computing contextual language representations, which hinders its universality and applicability. To overcome this bottleneck, we propose a deep bidirectional language model by using window masking mechanism at attention layer. This work computes contextual language representations without random masking as does in BERT and maintains the deep bidirectional architecture like BERT. To compute the same sentence representation, our method shows O(n) complexity less compared to other transformer-based models with O($n^2$). To further demonstrate its superiority, computing context language representations on CPU environments is conducted, by using the embeddings from the proposed method, logistic regression shows much higher accuracy in terms of SMS classification. Moverover, the proposed method also achieves significant higher performance in semantic similarity tasks.

</p>
</details>

<details><summary><b>Towards Learning to Speak and Hear Through Multi-Agent Communication over a Continuous Acoustic Channel</b>
<a href="https://arxiv.org/abs/2111.02827">arxiv:2111.02827</a>
&#x1F4C8; 3 <br>
<p>Kevin Eloff, Arnu Pretorius, Okko Räsänen, Herman A. Engelbrecht, Herman Kamper</p></summary>
<p>

**Abstract:** While multi-agent reinforcement learning has been used as an effective means to study emergent communication between agents, existing work has focused almost exclusively on communication with discrete symbols. Human communication often takes place (and emerged) over a continuous acoustic channel; human infants acquire language in large part through continuous signalling with their caregivers. We therefore ask: Are we able to observe emergent language between agents with a continuous communication channel trained through reinforcement learning? And if so, what is the impact of channel characteristics on the emerging language? We propose an environment and training methodology to serve as a means to carry out an initial exploration of these questions. We use a simple messaging environment where a "speaker" agent needs to convey a concept to a "listener". The Speaker is equipped with a vocoder that maps symbols to a continuous waveform, this is passed over a lossy continuous channel, and the Listener needs to map the continuous signal to the concept. Using deep Q-learning, we show that basic compositionality emerges in the learned language representations. We find that noise is essential in the communication channel when conveying unseen concept combinations. And we show that we can ground the emergent communication by introducing a caregiver predisposed to "hearing" or "speaking" English. Finally, we describe how our platform serves as a starting point for future work that uses a combination of deep reinforcement learning and multi-agent systems to study our questions of continuous signalling in language learning and emergence.

</p>
</details>

<details><summary><b>The role of MRI physics in brain segmentation CNNs: achieving acquisition invariance and instructive uncertainties</b>
<a href="https://arxiv.org/abs/2111.02771">arxiv:2111.02771</a>
&#x1F4C8; 3 <br>
<p>Pedro Borges, Richard Shaw, Thomas Varsavsky, Kerstin Klaser, David Thomas, Ivana Drobnjak, Sebastien Ourselin, M Jorge Cardoso</p></summary>
<p>

**Abstract:** Being able to adequately process and combine data arising from different sites is crucial in neuroimaging, but is difficult, owing to site, sequence and acquisition-parameter dependent biases. It is important therefore to design algorithms that are not only robust to images of differing contrasts, but also be able to generalise well to unseen ones, with a quantifiable measure of uncertainty. In this paper we demonstrate the efficacy of a physics-informed, uncertainty-aware, segmentation network that employs augmentation-time MR simulations and homogeneous batch feature stratification to achieve acquisition invariance. We show that the proposed approach also accurately extrapolates to out-of-distribution sequence samples, providing well calibrated volumetric bounds on these. We demonstrate a significant improvement in terms of coefficients of variation, backed by uncertainty based volumetric validation.

</p>
</details>

<details><summary><b>Learning of Frequency-Time Attention Mechanism for Automatic Modulation Recognition</b>
<a href="https://arxiv.org/abs/2111.03258">arxiv:2111.03258</a>
&#x1F4C8; 2 <br>
<p>Shangao Lin, Yuan Zeng, Yi Gong</p></summary>
<p>

**Abstract:** Recent learning-based image classification and speech recognition approaches make extensive use of attention mechanisms to achieve state-of-the-art recognition power, which demonstrates the effectiveness of attention mechanisms. Motivated by the fact that the frequency and time information of modulated radio signals are crucial for modulation mode recognition, this paper proposes a frequency-time attention mechanism for a convolutional neural network (CNN)-based modulation recognition framework. The proposed frequency-time attention module is designed to learn which channel, frequency and time information is more meaningful in CNN for modulation recognition. We analyze the effectiveness of the proposed frequency-time attention mechanism and compare the proposed method with two existing learning-based methods. Experiments on an open-source modulation recognition dataset show that the recognition performance of the proposed framework is better than those of the framework without frequency-time attention and existing learning-based methods.

</p>
</details>

<details><summary><b>Multi-Spectral Multi-Image Super-Resolution of Sentinel-2 with Radiometric Consistency Losses and Its Effect on Building Delineation</b>
<a href="https://arxiv.org/abs/2111.03231">arxiv:2111.03231</a>
&#x1F4C8; 2 <br>
<p>Muhammed Razzak, Gonzalo Mateo-Garcia, Luis Gómez-Chova, Yarin Gal, Freddie Kalaitzis</p></summary>
<p>

**Abstract:** High resolution remote sensing imagery is used in broad range of tasks, including detection and classification of objects. High-resolution imagery is however expensive, while lower resolution imagery is often freely available and can be used by the public for range of social good applications. To that end, we curate a multi-spectral multi-image super-resolution dataset, using PlanetScope imagery from the SpaceNet 7 challenge as the high resolution reference and multiple Sentinel-2 revisits of the same imagery as the low-resolution imagery. We present the first results of applying multi-image super-resolution (MISR) to multi-spectral remote sensing imagery. We, additionally, introduce a radiometric consistency module into MISR model the to preserve the high radiometric resolution of the Sentinel-2 sensor. We show that MISR is superior to single-image super-resolution and other baselines on a range of image fidelity metrics. Furthermore, we conduct the first assessment of the utility of multi-image super-resolution on building delineation, showing that utilising multiple images results in better performance in these downstream tasks.

</p>
</details>

<details><summary><b>Community detection in censored hypergraph</b>
<a href="https://arxiv.org/abs/2111.03179">arxiv:2111.03179</a>
&#x1F4C8; 2 <br>
<p>Mingao Yuan, Bin Zhao, Xiaofeng Zhao</p></summary>
<p>

**Abstract:** Community detection refers to the problem of clustering the nodes of a network (either graph or hypergrah) into groups. Various algorithms are available for community detection and all these methods apply to uncensored networks. In practice, a network may has censored (or missing) values and it is shown that censored values have non-negligible effect on the structural properties of a network. In this paper, we study community detection in censored $m$-uniform hypergraph from information-theoretic point of view. We derive the information-theoretic threshold for exact recovery of the community structure. Besides, we propose a polynomial-time algorithm to exactly recover the community structure up to the threshold. The proposed algorithm consists of a spectral algorithm plus a refinement step. It is also interesting to study whether a single spectral algorithm without refinement achieves the threshold. To this end, we also explore the semi-definite relaxation algorithm and analyze its performance.

</p>
</details>

<details><summary><b>Rate of Convergence of Polynomial Networks to Gaussian Processes</b>
<a href="https://arxiv.org/abs/2111.03175">arxiv:2111.03175</a>
&#x1F4C8; 2 <br>
<p>Adam Klukowski</p></summary>
<p>

**Abstract:** We examine one-hidden-layer neural networks with random weights. It is well-known that in the limit of infinitely many neurons they simplify to Gaussian processes. For networks with a polynomial activation, we demonstrate that the rate of this convergence in 2-Wasserstein metric is $O(n^{-\frac{1}{2}})$, where $n$ is the number of hidden neurons. We suspect this rate is asymptotically sharp. We improve the known convergence rate for other activations, to power-law in $n$ for ReLU and inverse-square-root up to logarithmic factors for erf. We explore the interplay between spherical harmonics, Stein kernels and optimal transport in the non-isotropic setting.

</p>
</details>

<details><summary><b>Predictive Machine Learning of Objective Boundaries for Solving COPs</b>
<a href="https://arxiv.org/abs/2111.03160">arxiv:2111.03160</a>
&#x1F4C8; 2 <br>
<p>Helge Spieker, Arnaud Gotlieb</p></summary>
<p>

**Abstract:** Solving Constraint Optimization Problems (COPs) can be dramatically simplified by boundary estimation, that is, providing tight boundaries of cost functions. By feeding a supervised Machine Learning (ML) model with data composed of known boundaries and extracted features of COPs, it is possible to train the model to estimate boundaries of a new COP instance. In this paper, we first give an overview of the existing body of knowledge on ML for Constraint Programming (CP) which learns from problem instances. Second, we introduce a boundary estimation framework that is applied as a tool to support a CP solver. Within this framework, different ML models are discussed and evaluated regarding their suitability for boundary estimation, and countermeasures to avoid unfeasible estimations that avoid the solver to find an optimal solution are shown. Third, we present an experimental study with distinct CP solvers on seven COPs. Our results show that near-optimal boundaries can be learned for these COPs with only little overhead. These estimated boundaries reduce the objective domain size by 60-88% and can help the solver to find near-optimal solutions early during search.

</p>
</details>

<details><summary><b>Amortized Variational Inference for Simple Hierarchical Models</b>
<a href="https://arxiv.org/abs/2111.03144">arxiv:2111.03144</a>
&#x1F4C8; 2 <br>
<p>Abhinav Agrawal, Justin Domke</p></summary>
<p>

**Abstract:** It is difficult to use subsampling with variational inference in hierarchical models since the number of local latent variables scales with the dataset. Thus, inference in hierarchical models remains a challenge at large scale. It is helpful to use a variational family with structure matching the posterior, but optimization is still slow due to the huge number of local distributions. Instead, this paper suggests an amortized approach where shared parameters simultaneously represent all local distributions. This approach is similarly accurate as using a given joint distribution (e.g., a full-rank Gaussian) but is feasible on datasets that are several orders of magnitude larger. It is also dramatically faster than using a structured variational distribution.

</p>
</details>

<details><summary><b>Functional connectivity ensemble method to enhance BCI performance (FUCONE)</b>
<a href="https://arxiv.org/abs/2111.03122">arxiv:2111.03122</a>
&#x1F4C8; 2 <br>
<p>Marie-Constance Corsi, Sylvain Chevallier, Fabrizio De Vico Fallani, Florian Yger</p></summary>
<p>

**Abstract:** Functional connectivity is a key approach to investigate oscillatory activities of the brain that provides important insights on the underlying dynamic of neuronal interactions and that is mostly applied for brain activity analysis. Building on the advances in information geometry for brain-computer interface, we propose a novel framework that combines functional connectivity estimators and covariance-based pipelines to classify mental states, such as motor imagery. A Riemannian classifier is trained for each estimator and an ensemble classifier combines the decisions in each feature space. A thorough assessment of the functional connectivity estimators is provided and the best performing pipeline, called FUCONE, is evaluated on different conditions and datasets. Using a meta-analysis to aggregate results across datasets, FUCONE performed significantly better than all state-of-the-art methods. The performance gain is mostly imputable to the improved diversity of the feature spaces, increasing the robustness of the ensemble classifier with respect to the inter- and intra-subject variability.

</p>
</details>

<details><summary><b>Successor Feature Neural Episodic Control</b>
<a href="https://arxiv.org/abs/2111.03110">arxiv:2111.03110</a>
&#x1F4C8; 2 <br>
<p>David Emukpere, Xavier Alameda-Pineda, Chris Reinke</p></summary>
<p>

**Abstract:** A longstanding goal in reinforcement learning is to build intelligent agents that show fast learning and a flexible transfer of skills akin to humans and animals. This paper investigates the integration of two frameworks for tackling those goals: episodic control and successor features. Episodic control is a cognitively inspired approach relying on episodic memory, an instance-based memory model of an agent's experiences. Meanwhile, successor features and generalized policy improvement (SF&GPI) is a meta and transfer learning framework allowing to learn policies for tasks that can be efficiently reused for later tasks which have a different reward function. Individually, these two techniques have shown impressive results in vastly improving sample efficiency and the elegant reuse of previously learned policies. Thus, we outline a combination of both approaches in a single reinforcement learning framework and empirically illustrate its benefits.

</p>
</details>

<details><summary><b>PDBL: Improving Histopathological Tissue Classification with Plug-and-Play Pyramidal Deep-Broad Learning</b>
<a href="https://arxiv.org/abs/2111.03063">arxiv:2111.03063</a>
&#x1F4C8; 2 <br>
<p>Jiatai Lin, Guoqiang Han, Xipeng Pan, Hao Chen, Danyi Li, Xiping Jia, Zhenwei Shi, Zhizhen Wang, Yanfen Cui, Haiming Li, Changhong Liang, Li Liang, Zaiyi Liu, Chu Han</p></summary>
<p>

**Abstract:** Histopathological tissue classification is a fundamental task in pathomics cancer research. Precisely differentiating different tissue types is a benefit for the downstream researches, like cancer diagnosis, prognosis and etc. Existing works mostly leverage the popular classification backbones in computer vision to achieve histopathological tissue classification. In this paper, we proposed a super lightweight plug-and-play module, named Pyramidal Deep-Broad Learning (PDBL), for any well-trained classification backbone to further improve the classification performance without a re-training burden. We mimic how pathologists observe pathology slides in different magnifications and construct an image pyramid for the input image in order to obtain the pyramidal contextual information. For each level in the pyramid, we extract the multi-scale deep-broad features by our proposed Deep-Broad block (DB-block). We equipped PDBL in three popular classification backbones, ShuffLeNetV2, EfficientNetb0, and ResNet50 to evaluate the effectiveness and efficiency of our proposed module on two datasets (Kather Multiclass Dataset and the LC25000 Dataset). Experimental results demonstrate the proposed PDBL can steadily improve the tissue-level classification performance for any CNN backbones, especially for the lightweight models when given a small among of training samples (less than 10%), which greatly saves the computational time and annotation efforts.

</p>
</details>

<details><summary><b>Causal inference with imperfect instrumental variables</b>
<a href="https://arxiv.org/abs/2111.03029">arxiv:2111.03029</a>
&#x1F4C8; 2 <br>
<p>Nikolai Miklin, Mariami Gachechiladze, George Moreno, Rafael Chaves</p></summary>
<p>

**Abstract:** Instrumental variables allow for quantification of cause and effect relationships even in the absence of interventions. To achieve this, a number of causal assumptions must be met, the most important of which is the independence assumption, which states that the instrument and any confounding factor must be independent. However, if this independence condition is not met, can we still work with imperfect instrumental variables? Imperfect instruments can manifest themselves by violations of the instrumental inequalities that constrain the set of correlations in the scenario. In this paper, we establish a quantitative relationship between such violations of instrumental inequalities and the minimal amount of measurement dependence required to explain them. As a result, we provide adapted inequalities that are valid in the presence of a relaxed measurement dependence assumption in the instrumental scenario. This allows for the adaptation of existing and new lower bounds on the average causal effect for instrumental scenarios with binary outcomes. Finally, we discuss our findings in the context of quantum mechanics.

</p>
</details>

<details><summary><b>Efficacy the of Confinement Policies on the COVID-19 Spread Dynamics in the Early Period of the Pandemic</b>
<a href="https://arxiv.org/abs/2111.03020">arxiv:2111.03020</a>
&#x1F4C8; 2 <br>
<p>Mehedi Hassan, Md Enamul Haque, Mehmet Engin Tozal</p></summary>
<p>

**Abstract:** In this study, we propose a clustering-based approach on time-series data to capture COVID-19 spread patterns in the early period of the pandemic. We analyze the spread dynamics based on the early and post stages of COVID-19 for different countries based on different geographical locations. Furthermore, we investigate the confinement policies and the effect they made on the spread. We found that implementations of the same confinement policies exhibit different results in different countries. Specifically, lockdowns become less effective in densely populated regions, because of the reluctance to comply with social distancing measures. Lack of testing, contact tracing, and social awareness in some countries forestall people from self-isolation and maintaining social distance. Large labor camps with unhealthy living conditions also aid in high community transmissions in countries depending on foreign labor. Distrust in government policies and fake news instigate the spread in both developed and under-developed countries. Large social gatherings play a vital role in causing rapid outbreaks almost everywhere. While some countries were able to contain the spread by implementing strict and widely adopted confinement policies, some others contained the spread with the help of social distancing measures and rigorous testing capacity. An early and rapid response at the beginning of the pandemic is necessary to contain the spread, yet it is not always sufficient.

</p>
</details>

<details><summary><b>Scanflow: A multi-graph framework for Machine Learning workflow management, supervision, and debugging</b>
<a href="https://arxiv.org/abs/2111.03003">arxiv:2111.03003</a>
&#x1F4C8; 2 <br>
<p>Gusseppe Bravo-Rocca, Peini Liu, Jordi Guitart, Ajay Dholakia, David Ellison, Jeffrey Falkanger, Miroslav Hodak</p></summary>
<p>

**Abstract:** Machine Learning (ML) is more than just training models, the whole workflow must be considered. Once deployed, a ML model needs to be watched and constantly supervised and debugged to guarantee its validity and robustness in unexpected situations. Debugging in ML aims to identify (and address) the model weaknesses in not trivial contexts. Several techniques have been proposed to identify different types of model weaknesses, such as bias in classification, model decay, adversarial attacks, etc., yet there is not a generic framework that allows them to work in a collaborative, modular, portable, iterative way and, more importantly, flexible enough to allow both human- and machine-driven techniques. In this paper, we propose a novel containerized directed graph framework to support and accelerate end-to-end ML workflow management, supervision, and debugging. The framework allows defining and deploying ML workflows in containers, tracking their metadata, checking their behavior in production, and improving the models by using both learned and human-provided knowledge. We demonstrate these capabilities by integrating in the framework two hybrid systems to detect data drift distribution which identify the samples that are far from the latent space of the original distribution, ask for human intervention, and whether retrain the model or wrap it with a filter to remove the noise of corrupted data at inference time. We test these systems on MNIST-C, CIFAR-10-C, and FashionMNIST-C datasets, obtaining promising accuracy results with the help of human involvement.

</p>
</details>

<details><summary><b>Consistent Estimation for PCA and Sparse Regression with Oblivious Outliers</b>
<a href="https://arxiv.org/abs/2111.02966">arxiv:2111.02966</a>
&#x1F4C8; 2 <br>
<p>Tommaso d'Orsi, Chih-Hung Liu, Rajai Nasser, Gleb Novikov, David Steurer, Stefan Tiegel</p></summary>
<p>

**Abstract:** We develop machinery to design efficiently computable and consistent estimators, achieving estimation error approaching zero as the number of observations grows, when facing an oblivious adversary that may corrupt responses in all but an $α$ fraction of the samples. As concrete examples, we investigate two problems: sparse regression and principal component analysis (PCA). For sparse regression, we achieve consistency for optimal sample size $n\gtrsim (k\log d)/α^2$ and optimal error rate $O(\sqrt{(k\log d)/(n\cdot α^2)})$ where $n$ is the number of observations, $d$ is the number of dimensions and $k$ is the sparsity of the parameter vector, allowing the fraction of inliers to be inverse-polynomial in the number of samples. Prior to this work, no estimator was known to be consistent when the fraction of inliers $α$ is $o(1/\log \log n)$, even for (non-spherical) Gaussian design matrices. Results holding under weak design assumptions and in the presence of such general noise have only been shown in dense setting (i.e., general linear regression) very recently by d'Orsi et al. [dNS21]. In the context of PCA, we attain optimal error guarantees under broad spikiness assumptions on the parameter matrix (usually used in matrix completion). Previous works could obtain non-trivial guarantees only under the assumptions that the measurement noise corresponding to the inliers is polynomially small in $n$ (e.g., Gaussian with variance $1/n^2$).
  To devise our estimators, we equip the Huber loss with non-smooth regularizers such as the $\ell_1$ norm or the nuclear norm, and extend d'Orsi et al.'s approach [dNS21] in a novel way to analyze the loss function. Our machinery appears to be easily applicable to a wide range of estimation problems.

</p>
</details>

<details><summary><b>Variational Inference with Holder Bounds</b>
<a href="https://arxiv.org/abs/2111.02947">arxiv:2111.02947</a>
&#x1F4C8; 2 <br>
<p>Junya Chen, Danni Lu, Zidi Xiu, Ke Bai, Lawrence Carin, Chenyang Tao</p></summary>
<p>

**Abstract:** The recent introduction of thermodynamic integration techniques has provided a new framework for understanding and improving variational inference (VI). In this work, we present a careful analysis of the thermodynamic variational objective (TVO), bridging the gap between existing variational objectives and shedding new insights to advance the field. In particular, we elucidate how the TVO naturally connects the three key variational schemes, namely the importance-weighted VI, Renyi-VI, and MCMC-VI, which subsumes most VI objectives employed in practice. To explain the performance gap between theory and practice, we reveal how the pathological geometry of thermodynamic curves negatively affects TVO. By generalizing the integration path from the geometric mean to the weighted Holder mean, we extend the theory of TVO and identify new opportunities for improving VI. This motivates our new VI objectives, named the Holder bounds, which flatten the thermodynamic curves and promise to achieve a one-step approximation of the exact marginal log-likelihood. A comprehensive discussion on the choices of numerical estimators is provided. We present strong empirical evidence on both synthetic and real-world datasets to support our claims.

</p>
</details>

<details><summary><b>Deep Artificial Intelligence for Fantasy Football Language Understanding</b>
<a href="https://arxiv.org/abs/2111.02874">arxiv:2111.02874</a>
&#x1F4C8; 2 <br>
<p>Aaron Baughman, Micah Forester, Jeff Powell, Eduardo Morales, Shaun McPartlin, Daniel Bohm</p></summary>
<p>

**Abstract:** Fantasy sports allow fans to manage a team of their favorite athletes and compete with friends. The fantasy platform aligns the real-world statistical performance of athletes to fantasy scoring and has steadily risen in popularity to an estimated 9.1 million players per month with 4.4 billion player card views on the ESPN Fantasy Football platform from 2018-2019. In parallel, the sports media community produces news stories, blogs, forum posts, tweets, videos, podcasts and opinion pieces that are both within and outside the context of fantasy sports. However, human fantasy football players can only analyze an average of 3.9 sources of information. Our work discusses the results of a machine learning pipeline to manage an ESPN Fantasy Football team. The use of trained statistical entity detectors and document2vector models applied to over 100,000 news sources and 2.3 million articles, videos and podcasts each day enables the system to comprehend natural language with an analogy test accuracy of 100% and keyword test accuracy of 80%. Deep learning feedforward neural networks provide player classifications such as if a player will be a bust, boom, play with a hidden injury or play meaningful touches with a cumulative 72% accuracy. Finally, a multiple regression ensemble uses the deep learning output and ESPN projection data to provide a point projection for each of the top 500+ fantasy football players in 2018. The point projection maintained a RMSE of 6.78 points. The best fit probability density function from a set of 24 is selected to visualize score spreads. Within the first 6 weeks of the product launch, the total number of users spent a cumulative time of over 4.6 years viewing our AI insights. The training data for our models was provided by a 2015 to 2016 web archive from Webhose, ESPN statistics, and Rotowire injury reports. We used 2017 fantasy football data as a test set.

</p>
</details>

<details><summary><b>A semi-automatic ultrasound image analysis system for the grading diagnosis of COVID-19 pneumonia</b>
<a href="https://arxiv.org/abs/2111.02676">arxiv:2111.02676</a>
&#x1F4C8; 2 <br>
<p>Yuanyuan Wang, Yao Zhang, Qiong He, Hongen Liao, Jianwen Luo</p></summary>
<p>

**Abstract:** This paper proposes a semi-automatic system based on quantitative characterization of the specific image patterns in lung ultrasound (LUS) images, in order to assess the lung conditions of patients with COVID-19 pneumonia, as well as to differentiate between the severe / and no-severe cases. Specifically, four parameters are extracted from each LUS image, namely the thickness (TPL) and roughness (RPL) of the pleural line, and the accumulated with (AWBL) and acoustic coefficient (ACBL) of B lines. 27 patients are enrolled in this study, which are grouped into 13 moderate patients, 7 severe patients and 7 critical patients. Furthermore, the severe and critical patients are regarded as the severe cases, and the moderate patients are regarded as the non-severe cases. Biomarkers among different groups are compared. Each single biomarker and a classifier with all the biomarkers as input are utilized for the binary diagnosis of severe case and non-severe case, respectively. The classifier achieves the best classification performance among all the compared methods (area under the receiver operating characteristics curve = 0.93, sensitivity = 0.93, specificity = 0.85). The proposed image analysis system could be potentially applied to the grading and prognosis evaluation of patients with COVID-19 pneumonia.

</p>
</details>

<details><summary><b>GraphSearchNet: Enhancing GNNs via Capturing Global Dependency for Semantic Code Search</b>
<a href="https://arxiv.org/abs/2111.02671">arxiv:2111.02671</a>
&#x1F4C8; 2 <br>
<p>Shangqing Liu, Xiaofei Xie, Jingkai Siow, Lei Ma, Guozhu Meng, Yang Liu</p></summary>
<p>

**Abstract:** Code search aims to retrieve the accurate code fragments based on a natural language query to improve the software productivity and quality. However, automated deep code search is still challenging due to the semantic gap between the program and the natural language query. Most existing deep learning-based approaches for code search rely on the sequential text eg., feeding the program and the query as a flat sequence of tokens to learn the program semantics and the structural information for both program and the query is not fully considered. Furthermore, the widely adopted Graph Neural Networks (GNNs) have proved the effectiveness in learning program semantics, however they also suffer from capturing the global dependency between any pair of nodes in the constructed graph, which hinder the model learning capacity.
  In this paper, to address these challenges, we design a novel neural network framework, named GraphSearchNet, to enable an effective and accurate source code search by jointly learning rich semantics of both source code and natural language queries. Specifically, we propose to encode both source code and queries into two separated graphs with Bidirectional GGNN to capture the local structural information of the programs and queries. We further enhance it by utilizing the effective multi-head attention mechanism to supplement the global dependency that BiGGNN missed to improve the model learning capacity. The extensive experiments on both Java and Python language from the public benchmark illustrate that GraphSearchNet outperforms current state-of-the-art works by a significant margin. We further conduct a quantitative analysis based on the real queries to further illustrate the effectiveness of our approach.

</p>
</details>

<details><summary><b>Logically Sound Arguments for the Effectiveness of ML Safety Measures</b>
<a href="https://arxiv.org/abs/2111.02649">arxiv:2111.02649</a>
&#x1F4C8; 2 <br>
<p>Chih-Hong Cheng, Tobias Schuster, Simon Burton</p></summary>
<p>

**Abstract:** We investigate the issues of achieving sufficient rigor in the arguments for the safety of machine learning functions. By considering the known weaknesses of DNN-based 2D bounding box detection algorithms, we sharpen the metric of imprecise pedestrian localization by associating it with the safety goal. The sharpening leads to introducing a conservative post-processor after the standard non-max-suppression as a counter-measure. We then propose a semi-formal assurance case for arguing the effectiveness of the post-processor, which is further translated into formal proof obligations for demonstrating the soundness of the arguments. Applying theorem proving not only discovers the need to introduce missing claims and mathematical concepts but also reveals the limitation of Dempster-Shafer's rules used in semi-formal argumentation.

</p>
</details>

<details><summary><b>Doxastic Extensions of Łukasiewicz Logic</b>
<a href="https://arxiv.org/abs/2111.08564">arxiv:2111.08564</a>
&#x1F4C8; 1 <br>
<p>Doratossadat Dastgheib, Hadi Farahani</p></summary>
<p>

**Abstract:** We propose two new doxastic extensions of fuzzy Łukasiewicz logic in which their semantics are Kripke-based with both fuzzy atomic propositions and fuzzy accessibility relations. A class of these extensions is equipped with uninformed belief operator, and the other class is based on a new notion of skeptical belief. We model a fuzzy version of muddy children problem and a CPA-security experiment using uniformed belief and skeptical belief, respectively. Moreover, we prove soundness and completeness for both of these belief extensions.

</p>
</details>

<details><summary><b>Improving RNA Secondary Structure Design using Deep Reinforcement Learning</b>
<a href="https://arxiv.org/abs/2111.04504">arxiv:2111.04504</a>
&#x1F4C8; 1 <br>
<p>Alexander Whatley, Zhekun Luo, Xiangru Tang</p></summary>
<p>

**Abstract:** Rising costs in recent years of developing new drugs and treatments have led to extensive research in optimization techniques in biomolecular design. Currently, the most widely used approach in biomolecular design is directed evolution, which is a greedy hill-climbing algorithm that simulates biological evolution. In this paper, we propose a new benchmark of applying reinforcement learning to RNA sequence design, in which the objective function is defined to be the free energy in the sequence's secondary structure. In addition to experimenting with the vanilla implementations of each reinforcement learning algorithm from standard libraries, we analyze variants of each algorithm in which we modify the algorithm's reward function and tune the model's hyperparameters. We show results of the ablation analysis that we do for these algorithms, as well as graphs indicating the algorithm's performance across batches and its ability to search the possible space of RNA sequences. We find that our DQN algorithm performs by far the best in this setting, contrasting with, in which PPO performs the best among all tested algorithms. Our results should be of interest to those in the biomolecular design community and should serve as a baseline for future experiments involving machine learning in molecule design.

</p>
</details>

<details><summary><b>Multi-Airport Delay Prediction with Transformers</b>
<a href="https://arxiv.org/abs/2111.04494">arxiv:2111.04494</a>
&#x1F4C8; 1 <br>
<p>Liya Wang, Alex Tien, Jason Chou</p></summary>
<p>

**Abstract:** Airport performance prediction with a reasonable look-ahead time is a challenging task and has been attempted by various prior research. Traffic, demand, weather, and traffic management actions are all critical inputs to any prediction model. In this paper, a novel approach based on Temporal Fusion Transformer (TFT) was proposed to predict departure and arrival delays simultaneously for multiple airports at once. This approach can capture complex temporal dynamics of the inputs known at the time of prediction and then forecast selected delay metrics up to four hours into the future. When dealing with weather inputs, a self-supervised learning (SSL) model was developed to encode high-dimensional weather data into a much lower-dimensional representation to make the training of TFT more efficiently and effectively. The initial results show that the TFT-based delay prediction model achieves satisfactory performance measured by smaller prediction errors on a testing dataset. In addition, the interpretability analysis of the model outputs identifies the important input factors for delay prediction. The proposed approach is expected to help air traffic managers or decision makers gain insights about traffic management actions on delay mitigation and once operationalized, provide enough lead time to plan for predicted performance degradation.

</p>
</details>

<details><summary><b>Identifying the Leading Factors of Significant Weight Gains Using a New Rule Discovery Method</b>
<a href="https://arxiv.org/abs/2111.04475">arxiv:2111.04475</a>
&#x1F4C8; 1 <br>
<p>Mina Samizadeh, Jessica C Jones-Smith, Bethany Sheridan, Rahmatollah Beheshti</p></summary>
<p>

**Abstract:** Overweight and obesity remain a major global public health concern and identifying the individualized patterns that increase the risk of future weight gains has a crucial role in preventing obesity and numerous sub-sequent diseases associated with obesity. In this work, we use a rule discovery method to study this problem, by presenting an approach that offers genuine interpretability and concurrently optimizes the accuracy(being correct often) and support (applying to many samples) of the identified patterns. Specifically, we extend an established subgroup-discovery method to generate the desired rules of type X -> Y and show how top features can be extracted from the X side, functioning as the best predictors of Y. In our obesity problem, X refers to the extracted features from very large and multi-site EHR data, and Y indicates significant weight gains. Using our method, we also extensively compare the differences and inequities in patterns across 22 strata determined by the individual's gender, age, race, insurance type, neighborhood type, and income level. Through extensive series of experiments, we show new and complementary findings regarding the predictors of future dangerous weight gains.

</p>
</details>

<details><summary><b>Weapon Engagement Zone Maximum Launch Range Estimation Using a Deep Neural Network</b>
<a href="https://arxiv.org/abs/2111.04474">arxiv:2111.04474</a>
&#x1F4C8; 1 <br>
<p>Joao P. A. Dantas, Andre N. Costa, Diego Geraldo, Marcos R. O. A. Maximo, Takashi Yoneyama</p></summary>
<p>

**Abstract:** This work investigates the use of a Deep Neural Network (DNN) to perform an estimation of the Weapon Engagement Zone (WEZ) maximum launch range. The WEZ allows the pilot to identify an airspace in which the available missile has a more significant probability of successfully engaging a particular target, i.e., a hypothetical area surrounding an aircraft in which an adversary is vulnerable to a shot. We propose an approach to determine the WEZ of a given missile using 50,000 simulated launches in variate conditions. These simulations are used to train a DNN that can predict the WEZ when the aircraft finds itself on different firing conditions, with a coefficient of determination of 0.99. It provides another procedure concerning preceding research since it employs a non-discretized model, i.e., it considers all directions of the WEZ at once, which has not been done previously. Additionally, the proposed method uses an experimental design that allows for fewer simulation runs, providing faster model training.

</p>
</details>

<details><summary><b>Flight Demand Forecasting with Transformers</b>
<a href="https://arxiv.org/abs/2111.04471">arxiv:2111.04471</a>
&#x1F4C8; 1 <br>
<p>Liya Wang, Amy Mykityshyn, Craig Johnson, Jillian Cheng</p></summary>
<p>

**Abstract:** Transformers have become the de-facto standard in the natural language processing (NLP) field. They have also gained momentum in computer vision and other domains. Transformers can enable artificial intelligence (AI) models to dynamically focus on certain parts of their input and thus reason more effectively. Inspired by the success of transformers, we adopted this technique to predict strategic flight departure demand in multiple horizons. This work was conducted in support of a MITRE-developed mobile application, Pacer, which displays predicted departure demand to general aviation (GA) flight operators so they can have better situation awareness of the potential for departure delays during busy periods. Field demonstrations involving Pacer's previously designed rule-based prediction method showed that the prediction accuracy of departure demand still has room for improvement. This research strives to improve prediction accuracy from two key aspects: better data sources and robust forecasting algorithms. We leveraged two data sources, Aviation System Performance Metrics (ASPM) and System Wide Information Management (SWIM), as our input. We then trained forecasting models with temporal fusion transformer (TFT) for five different airports. Case studies show that TFTs can perform better than traditional forecasting methods by large margins, and they can result in better prediction across diverse airports and with better interpretability.

</p>
</details>

<details><summary><b>Artificial Neural Network-Based Voltage Control of DC/DC Converter for DC Microgrid Applications</b>
<a href="https://arxiv.org/abs/2111.03207">arxiv:2111.03207</a>
&#x1F4C8; 1 <br>
<p>Hussain Sarwar Khan, Ihab S. Mohamed, Kimmo Kauhaniemi, Lantao Liu</p></summary>
<p>

**Abstract:** The rapid growth of renewable energy technology enables the concept of microgrid (MG) to be widely accepted in the power systems. Due to the advantages of the DC distribution system such as easy integration of energy storage and less system loss, DC MG attracts significant attention nowadays. The linear controller such as PI or PID is matured and extensively used by the power electronics industry, but their performance is not optimal as system parameters are changed. In this study, an artificial neural network (ANN) based voltage control strategy is proposed for the DC-DC boost converter. In this paper, the model predictive control (MPC) is used as an expert, which provides the data to train the proposed ANN. As ANN is tuned finely, then it is utilized directly to control the step-up DC converter. The main advantage of the ANN is that the neural network system identification decreases the inaccuracy of the system model even with inaccurate parameters and has less computational burden compared to MPC due to its parallel structure. To validate the performance of the proposed ANN, extensive MATLAB/Simulink simulations are carried out. The simulation results show that the ANN-based control strategy has better performance under different loading conditions comparison to the PI controller. The accuracy of the trained ANN model is about 97%, which makes it suitable to be used for DC microgrid applications.

</p>
</details>

<details><summary><b>On the Complexity of Dynamic Submodular Maximization</b>
<a href="https://arxiv.org/abs/2111.03198">arxiv:2111.03198</a>
&#x1F4C8; 1 <br>
<p>Xi Chen, Binghui Peng</p></summary>
<p>

**Abstract:** We study dynamic algorithms for the problem of maximizing a monotone submodular function over a stream of $n$ insertions and deletions. We show that any algorithm that maintains a $(0.5+ε)$-approximate solution under a cardinality constraint, for any constant $ε>0$, must have an amortized query complexity that is $\mathit{polynomial}$ in $n$. Moreover, a linear amortized query complexity is needed in order to maintain a $0.584$-approximate solution. This is in sharp contrast with recent dynamic algorithms of [LMNF+20, Mon20] that achieve $(0.5-ε)$-approximation with a $\mathsf{poly}\log(n)$ amortized query complexity.
  On the positive side, when the stream is insertion-only, we present efficient algorithms for the problem under a cardinality constraint and under a matroid constraint with approximation guarantee $1-1/e-ε$ and amortized query complexities $\smash{O(\log (k/ε)/ε^2)}$ and $\smash{k^{\tilde{O}(1/ε^2)}\log n}$, respectively, where $k$ denotes the cardinality parameter or the rank of the matroid.

</p>
</details>

<details><summary><b>An Empirical Study of the Effectiveness of an Ensemble of Stand-alone Sentiment Detection Tools for Software Engineering Datasets</b>
<a href="https://arxiv.org/abs/2111.03196">arxiv:2111.03196</a>
&#x1F4C8; 1 <br>
<p>Gias Uddin, Yann-Gael Gueheneuc, Foutse Khomh, Chanchal K Roy</p></summary>
<p>

**Abstract:** Sentiment analysis in software engineering (SE) has shown promise to analyze and support diverse development activities. We report the results of an empirical study that we conducted to determine the feasibility of developing an ensemble engine by combining the polarity labels of stand-alone SE-specific sentiment detectors. Our study has two phases. In the first phase, we pick five SE-specific sentiment detection tools from two recently published papers by Lin et al. [31, 32], who first reported negative results with standalone sentiment detectors and then proposed an improved SE-specific sentiment detector, POME [31]. We report the study results on 17,581 units (sentences/documents) coming from six currently available sentiment benchmarks for SE. We find that the existing tools can be complementary to each other in 85-95% of the cases, i.e., one is wrong, but another is right. However, a majority voting-based ensemble of those tools fails to improve the accuracy of sentiment detection. We develop Sentisead, a supervised tool by combining the polarity labels and bag of words as features. Sentisead improves the performance (F1-score) of the individual tools by 4% (over Senti4SD [5]) - 100% (over POME [31]). In a second phase, we compare and improve Sentisead infrastructure using Pre-trained Transformer Models (PTMs). We find that a Sentisead infrastructure with RoBERTa as the ensemble of the five stand-alone rule-based and shallow learning SE-specific tools from Lin et al. [31, 32] offers the best F1-score of 0.805 across the six datasets, while a stand-alone RoBERTa shows an F1-score of 0.801.

</p>
</details>

<details><summary><b>Secure Machine Learning in the Cloud Using One Way Scrambling by Deconvolution</b>
<a href="https://arxiv.org/abs/2111.03125">arxiv:2111.03125</a>
&#x1F4C8; 1 <br>
<p>Yiftach Savransky, Roni Mateless, Gilad Katz</p></summary>
<p>

**Abstract:** Cloud-based machine learning services (CMLS) enable organizations to take advantage of advanced models that are pre-trained on large quantities of data. The main shortcoming of using these services, however, is the difficulty of keeping the transmitted data private and secure. Asymmetric encryption requires the data to be decrypted in the cloud, while Homomorphic encryption is often too slow and difficult to implement. We propose One Way Scrambling by Deconvolution (OWSD), a deconvolution-based scrambling framework that offers the advantages of Homomorphic encryption at a fraction of the computational overhead. Extensive evaluation on multiple image datasets demonstrates OWSD's ability to achieve near-perfect classification performance when the output vector of the CMLS is sufficiently large. Additionally, we provide empirical analysis of the robustness of our approach.

</p>
</details>

<details><summary><b>Graph neural network initialisation of quantum approximate optimisation</b>
<a href="https://arxiv.org/abs/2111.03016">arxiv:2111.03016</a>
&#x1F4C8; 1 <br>
<p>Nishant Jain, Brian Coyle, Elham Kashefi, Niraj Kumar</p></summary>
<p>

**Abstract:** Approximate combinatorial optimisation has emerged as one of the most promising application areas for quantum computers, particularly those in the near term. In this work, we focus on the quantum approximate optimisation algorithm (QAOA) for solving the Max-Cut problem. Specifically, we address two problems in the QAOA, how to select initial parameters, and how to subsequently train the parameters to find an optimal solution. For the former, we propose graph neural networks (GNNs) as an initialisation routine for the QAOA parameters, adding to the literature on warm-starting techniques. We show the GNN approach generalises across not only graph instances, but also to increasing graph sizes, a feature not available to other warm-starting techniques. For training the QAOA, we test several optimisers for the MaxCut problem. These include quantum aware/agnostic optimisers proposed in literature and we also incorporate machine learning techniques such as reinforcement and meta-learning. With the incorporation of these initialisation and optimisation toolkits, we demonstrate how the QAOA can be trained as an end-to-end differentiable pipeline.

</p>
</details>

<details><summary><b>Symmetry-Aware Autoencoders: s-PCA and s-nlPCA</b>
<a href="https://arxiv.org/abs/2111.02893">arxiv:2111.02893</a>
&#x1F4C8; 1 <br>
<p>Simon Kneer, Taraneh Sayadi, Denis Sipp, Peter Schmid, Georgios Rigas</p></summary>
<p>

**Abstract:** Nonlinear principal component analysis (nlPCA) via autoencoders has attracted attention in the dynamical systems community due to its larger compression rate when compared to linear principal component analysis (PCA). These model reduction methods experience an increase in the dimensionality of the latent space when applied to datasets that exhibit globally invariant samples due to the presence of symmetries. In this study, we introduce a novel machine learning embedding in the autoencoder, which uses spatial transformer networks and Siamese networks to account for continuous and discrete symmetries, respectively. The spatial transformer network discovers the optimal shift for the continuous translation or rotation so that invariant samples are aligned in the periodic directions. Similarly, the Siamese networks collapse samples that are invariant under discrete shifts and reflections. Thus, the proposed symmetry-aware autoencoder is invariant to predetermined input transformations dictating the dynamics of the underlying physical system. This embedding can be employed with both linear and nonlinear reduction methods, which we term symmetry-aware PCA (s-PCA) and symmetry-aware nlPCA (s-nlPCA). We apply the proposed framework to 3 fluid flow problems: Burgers' equation, the simulation of the flow through a step diffuser and the Kolmogorov flow to showcase the capabilities for cases exhibiting only continuous symmetries, only discrete symmetries or a combination of both.

</p>
</details>

<details><summary><b>Human Age Estimation from Gene Expression Data using Artificial Neural Networks</b>
<a href="https://arxiv.org/abs/2111.02692">arxiv:2111.02692</a>
&#x1F4C8; 1 <br>
<p>Salman Mohamadi, Gianfranco. Doretto, Nasser M. Nasrabadi, Donald A. Adjeroh</p></summary>
<p>

**Abstract:** The study of signatures of aging in terms of genomic biomarkers can be uniquely helpful in understanding the mechanisms of aging and developing models to accurately predict the age. Prior studies have employed gene expression and DNA methylation data aiming at accurate prediction of age. In this line, we propose a new framework for human age estimation using information from human dermal fibroblast gene expression data. First, we propose a new spatial representation as well as a data augmentation approach for gene expression data. Next in order to predict the age, we design an architecture of neural network and apply it to this new representation of the original and augmented data, as an ensemble classification approach. Our experimental results suggest the superiority of the proposed framework over state-of-the-art age estimation methods using DNA methylation and gene expression data.

</p>
</details>

<details><summary><b>Impact of the Sensing Spectrum on Signal Recovery in Generalized Linear Models</b>
<a href="https://arxiv.org/abs/2111.03237">arxiv:2111.03237</a>
&#x1F4C8; 0 <br>
<p>Junjie Ma, Ji Xu, Arian Maleki</p></summary>
<p>

**Abstract:** We consider a nonlinear inverse problem $\mathbf{y}= f(\mathbf{Ax})$, where observations $\mathbf{y} \in \mathbb{R}^m$ are the componentwise nonlinear transformation of $\mathbf{Ax} \in \mathbb{R}^m$, $\mathbf{x} \in \mathbb{R}^n$ is the signal of interest and $\mathbf{A}$ is a known linear mapping. By properly specifying the nonlinear processing function, this model can be particularized to many signal processing problems, including compressed sensing and phase retrieval.
  Our main goal in this paper is to understand the impact of sensing matrices, or more specifically the spectrum of sensing matrices, on the difficulty of recovering $\mathbf{x}$ from $\mathbf{y}$. Towards this goal, we study the performance of one of the most successful recovery methods, i.e. the expectation propagation algorithm (EP). We define a notion for the spikiness of the spectrum of $\mathbf{A}$ and show the importance of this measure in the performance of the EP. Whether the spikiness of the spectrum can hurt or help the recovery performance of EP depends on $f$. We define certain quantities based on the function $f$ that enables us to describe the impact of the spikiness of the spectrum on EP recovery. Based on our framework, we are able to show that for instance, in phase-retrieval problems, matrices with spikier spectrums are better for EP, while in 1-bit compressed sensing problems, less spiky (flatter) spectrums offer better recoveries. Our results unify and substantially generalize the existing results that compare sub-Gaussian and orthogonal matrices, and provide a platform toward designing optimal sensing systems.

</p>
</details>

<details><summary><b>Online Continual Learning via Multiple Deep Metric Learning and Uncertainty-guided Episodic Memory Replay -- 3rd Place Solution for ICCV 2021 Workshop SSLAD Track 3A Continual Object Classification</b>
<a href="https://arxiv.org/abs/2111.02757">arxiv:2111.02757</a>
&#x1F4C8; 0 <br>
<p>Muhammad Rifki Kurniawan, Xing Wei, Yihong Gong</p></summary>
<p>

**Abstract:** Online continual learning in the wild is a very difficult task in machine learning. Non-stationarity in online continual learning potentially brings about catastrophic forgetting in neural networks. Specifically, online continual learning for autonomous driving with SODA10M dataset exhibits extra problems on extremely long-tailed distribution with continuous distribution shift. To address these problems, we propose multiple deep metric representation learning via both contrastive and supervised contrastive learning alongside soft labels distillation to improve model generalization. Moreover, we exploit modified class-balanced focal loss for sensitive penalization in class imbalanced and hard-easy samples. We also store some samples under guidance of uncertainty metric for rehearsal and perform online and periodical memory updates. Our proposed method achieves considerable generalization with average mean class accuracy (AMCA) 64.01% on validation and 64.53% AMCA on test set.

</p>
</details>

<details><summary><b>FEAFA+: An Extended Well-Annotated Dataset for Facial Expression Analysis and 3D Facial Animation</b>
<a href="https://arxiv.org/abs/2111.02751">arxiv:2111.02751</a>
&#x1F4C8; 0 <br>
<p>Wei Gan, Jian Xue, Ke Lu, Yanfu Yan, Pengcheng Gao, Jiayi Lyu</p></summary>
<p>

**Abstract:** Nearly all existing Facial Action Coding System-based datasets that include facial action unit (AU) intensity information annotate the intensity values hierarchically using A--E levels. However, facial expressions change continuously and shift smoothly from one state to another. Therefore, it is more effective to regress the intensity value of local facial AUs to represent whole facial expression changes, particularly in the fields of expression transfer and facial animation. We introduce an extension of FEAFA in combination with the relabeled DISFA database, which is available at https://www.iiplab.net/feafa+/ now. Extended FEAFA (FEAFA+) includes 150 video sequences from FEAFA and DISFA, with a total of 230,184 frames being manually annotated on floating-point intensity value of 24 redefined AUs using the Expression Quantitative Tool. We also list crude numerical results for posed and spontaneous subsets and provide a baseline comparison for the AU intensity regression task.

</p>
</details>

<details><summary><b>Quasi-Newton Methods for Saddle Point Problems and Beyond</b>
<a href="https://arxiv.org/abs/2111.02708">arxiv:2111.02708</a>
&#x1F4C8; 0 <br>
<p>Chengchang Liu, Luo Luo</p></summary>
<p>

**Abstract:** This paper studies quasi-Newton methods for solving strongly-convex-strongly-concave saddle point problems (SPP). We propose greedy and random Broyden family updates for SPP, which have explicit local superlinear convergence rate of ${\mathcal O}\big(\big(1-\frac{1}{nκ^2}\big)^{k(k-1)/2}\big)$, where $n$ is dimensions of the problem, $κ$ is the condition number and $k$ is the number of iterations. The design and analysis of proposed algorithm are based on estimating the square of indefinite Hessian matrix, which is different from classical quasi-Newton methods in convex optimization. We also present two specific Broyden family algorithms with BFGS-type and SR1-type updates, which enjoy the faster local convergence rate of $\mathcal O\big(\big(1-\frac{1}{n}\big)^{k(k-1)/2}\big)$. Additionally, we extend our algorithms to solve general nonlinear equations and prove it enjoys the similar convergence rate.

</p>
</details>

<details><summary><b>Ex$^2$MCMC: Sampling through Exploration Exploitation</b>
<a href="https://arxiv.org/abs/2111.02702">arxiv:2111.02702</a>
&#x1F4C8; 0 <br>
<p>Evgeny Lagutin, Daniil Selikhanovych, Achille Thin, Sergey Samsonov, Alexey Naumov, Denis Belomestny, Maxim Panov, Eric Moulines</p></summary>
<p>

**Abstract:** We develop an Explore-Exploit Markov chain Monte Carlo algorithm ($\operatorname{Ex^2MCMC}$) that combines multiple global proposals and local moves. The proposed method is massively parallelizable and extremely computationally efficient. We prove $V$-uniform geometric ergodicity of $\operatorname{Ex^2MCMC}$ under realistic conditions and compute explicit bounds on the mixing rate showing the improvement brought by the multiple global moves. We show that $\operatorname{Ex^2MCMC}$ allows fine-tuning of exploitation (local moves) and exploration (global moves) via a novel approach to proposing dependent global moves. Finally, we develop an adaptive scheme, $\operatorname{FlEx^2MCMC}$, that learns the distribution of global moves using normalizing flows. We illustrate the efficiency of $\operatorname{Ex^2MCMC}$ and its adaptive versions on many classical sampling benchmarks. We also show that these algorithms improve the quality of sampling GANs as energy-based models.

</p>
</details>

<details><summary><b>A novel control method for solving high-dimensional Hamiltonian systems through deep neural networks</b>
<a href="https://arxiv.org/abs/2111.02636">arxiv:2111.02636</a>
&#x1F4C8; 0 <br>
<p>Shaolin Ji, Shige Peng, Ying Peng, Xichuan Zhang</p></summary>
<p>

**Abstract:** In this paper, we mainly focus on solving high-dimensional stochastic Hamiltonian systems with boundary condition, which is essentially a Forward Backward Stochastic Differential Equation (FBSDE in short), and propose a novel method from the view of the stochastic control. In order to obtain the approximated solution of the Hamiltonian system, we first introduce a corresponding stochastic optimal control problem such that the extended Hamiltonian system of the control problem is exactly what we need to solve, then we develop two different algorithms suitable for different cases of the control problem and approximate the stochastic control via deep neural networks. From the numerical results, comparing with the Deep FBSDE method developed previously from the view of solving FBSDEs, the novel algorithms converge faster, which means that they require fewer training steps, and demonstrate more stable convergences for different Hamiltonian systems.

</p>
</details>


[Next Page](2021/2021-11/2021-11-03.md)
