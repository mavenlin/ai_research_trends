Prev: [2022.10.21]({{ '/2022/10/21/2022.10.21.html' | relative_url }})  Next: [2022.10.23]({{ '/2022/10/23/2022.10.23.html' | relative_url }})
{% raw %}
## Summary for 2022-10-22, created on 2022-11-01


<details><summary><b>Bayesian Optimization with Conformal Coverage Guarantees</b>
<a href="https://arxiv.org/abs/2210.12496">arxiv:2210.12496</a>
&#x1F4C8; 46 <br>
<p>Samuel Stanton, Wesley Maddox, Andrew Gordon Wilson</p></summary>
<p>

**Abstract:** Bayesian optimization is a coherent, ubiquitous approach to decision-making under uncertainty, with applications including multi-arm bandits, active learning, and black-box optimization. Bayesian optimization selects decisions (i.e. objective function queries) with maximal expected utility with respect to the posterior distribution of a Bayesian model, which quantifies reducible, epistemic uncertainty about query outcomes. In practice, subjectively implausible outcomes can occur regularly for two reasons: 1) model misspecification and 2) covariate shift. Conformal prediction is an uncertainty quantification method with coverage guarantees even for misspecified models and a simple mechanism to correct for covariate shift. We propose conformal Bayesian optimization, which directs queries towards regions of search space where the model predictions have guaranteed validity, and investigate its behavior on a suite of black-box optimization tasks and tabular ranking tasks. In many cases we find that query coverage can be significantly improved without harming sample-efficiency.

</p>
</details>

<details><summary><b>LMPriors: Pre-Trained Language Models as Task-Specific Priors</b>
<a href="https://arxiv.org/abs/2210.12530">arxiv:2210.12530</a>
&#x1F4C8; 26 <br>
<p>Kristy Choi, Chris Cundy, Sanjari Srivastava, Stefano Ermon</p></summary>
<p>

**Abstract:** Particularly in low-data regimes, an outstanding challenge in machine learning is developing principled techniques for augmenting our models with suitable priors. This is to encourage them to learn in ways that are compatible with our understanding of the world. But in contrast to generic priors such as shrinkage or sparsity, we draw inspiration from the recent successes of large-scale language models (LMs) to construct task-specific priors distilled from the rich knowledge of LMs. Our method, Language Model Priors (LMPriors), incorporates auxiliary natural language metadata about the task -- such as variable names and descriptions -- to encourage downstream model outputs to be consistent with the LM's common-sense reasoning based on the metadata. Empirically, we demonstrate that LMPriors improve model performance in settings where such natural language descriptions are available, and perform well on several tasks that benefit from such prior knowledge, such as feature selection, causal inference, and safe reinforcement learning.

</p>
</details>

<details><summary><b>Faster and more diverse de novo molecular optimization with double-loop reinforcement learning using augmented SMILES</b>
<a href="https://arxiv.org/abs/2210.12458">arxiv:2210.12458</a>
&#x1F4C8; 22 <br>
<p>Esben Jannik Bjerrum, Christian Margreitter, Thomas Blaschke, Raquel Lopez-Rios de Castro</p></summary>
<p>

**Abstract:** Molecular generation via deep learning models in combination with reinforcement learning is a powerful way of generating proposed molecules with desirable properties. By defining a multi-objective scoring function, it is possible to generate thousands of ideas for molecules that scores well, which makes the approach interesting for drug discovery or material science purposes. However, if the scoring function is expensive regarding resources, such as time or computation, the high number of function evaluations needed for feedback in the reinforcement learning loop becomes a bottleneck. Here we propose to use double-loop reinforcement learning with simplified molecular line entry system (SMILES) augmentation to use scoring calculations more efficiently and arrive at well scoring molecules faster. By adding an inner loop where the SMILES strings generated are augmented to alternative non-canonical SMILES and used for additional rounds of reinforcement learning, we can effectively reuse the scoring calculations that are done on the molecular level. This approach speeds up the learning process regarding scoring function calls, as well as it protects moderately against mode collapse. We find that augmentation repeats between 5-10x seem safe for most scoring functions and additionally increase the diversity of the generated compounds, as well as making the sampling runs of chemical space more reproducible

</p>
</details>

<details><summary><b>The Curious Case of Absolute Position Embeddings</b>
<a href="https://arxiv.org/abs/2210.12574">arxiv:2210.12574</a>
&#x1F4C8; 19 <br>
<p>Koustuv Sinha, Amirhossein Kazemnejad, Siva Reddy, Joelle Pineau, Dieuwke Hupkes, Adina Williams</p></summary>
<p>

**Abstract:** Transformer language models encode the notion of word order using positional information. Most commonly, this positional information is represented by absolute position embeddings (APEs), that are learned from the pretraining data. However, in natural language, it is not absolute position that matters, but relative position, and the extent to which APEs can capture this type of information has not been investigated. In this work, we observe that models trained with APE over-rely on positional information to the point that they break-down when subjected to sentences with shifted position information. Specifically, when models are subjected to sentences starting from a non-zero position (excluding the effect of priming), they exhibit noticeably degraded performance on zero to full-shot tasks, across a range of model families and model sizes. Our findings raise questions about the efficacy of APEs to model the relativity of position information, and invite further introspection on the sentence and word order processing strategies employed by these models.

</p>
</details>

<details><summary><b>Bayesian Convolutional Deep Sets with Task-Dependent Stationary Prior</b>
<a href="https://arxiv.org/abs/2210.12363">arxiv:2210.12363</a>
&#x1F4C8; 14 <br>
<p>Yohan Jung, Jinkyoo Park</p></summary>
<p>

**Abstract:** Convolutional deep sets are the architecture of a deep neural network (DNN) that can model stationary stochastic process. This architecture uses the kernel smoother and the DNN to construct the translation equivariant functional representations, and thus reflects the inductive bias of the stationarity into DNN. However, since this architecture employs the kernel smoother known as the non-parametric model, it may produce ambiguous representations when the number of data points is not given sufficiently. To remedy this issue, we introduce Bayesian convolutional deep sets that construct the random translation equivariant functional representations with stationary prior. Furthermore, we present how to impose the task-dependent prior for each dataset because a wrongly imposed prior forms an even worse representation than that of the kernel smoother. We validate the proposed architecture and its training on various experiments with time-series and image datasets.

</p>
</details>

<details><summary><b>MILD: Multimodal Interactive Latent Dynamics for Learning Human-Robot Interaction</b>
<a href="https://arxiv.org/abs/2210.12418">arxiv:2210.12418</a>
&#x1F4C8; 10 <br>
<p>Vignesh Prasad, Dorothea Koert, Ruth Stock-Homburg, Jan Peters, Georgia Chalvatzaki</p></summary>
<p>

**Abstract:** Modeling interaction dynamics to generate robot trajectories that enable a robot to adapt and react to a human's actions and intentions is critical for efficient and effective collaborative Human-Robot Interactions (HRI). Learning from Demonstration (LfD) methods from Human-Human Interactions (HHI) have shown promising results, especially when coupled with representation learning techniques. However, such methods for learning HRI either do not scale well to high dimensional data or cannot accurately adapt to changing via-poses of the interacting partner. We propose Multimodal Interactive Latent Dynamics (MILD), a method that couples deep representation learning and probabilistic machine learning to address the problem of two-party physical HRIs. We learn the interaction dynamics from demonstrations, using Hidden Semi-Markov Models (HSMMs) to model the joint distribution of the interacting agents in the latent space of a Variational Autoencoder (VAE). Our experimental evaluations for learning HRI from HHI demonstrations show that MILD effectively captures the multimodality in the latent representations of HRI tasks, allowing us to decode the varying dynamics occurring in such tasks. Compared to related work, MILD generates more accurate trajectories for the controlled agent (robot) when conditioned on the observed agent's (human) trajectory. Notably, MILD can learn directly from camera-based pose estimations to generate trajectories, which we then map to a humanoid robot without the need for any additional training.

</p>
</details>

<details><summary><b>SurCo: Learning Linear Surrogates For Combinatorial Nonlinear Optimization Problems</b>
<a href="https://arxiv.org/abs/2210.12547">arxiv:2210.12547</a>
&#x1F4C8; 9 <br>
<p>Aaron Ferber, Taoan Huang, Daochen Zha, Martin Schubert, Benoit Steiner, Bistra Dilkina, Yuandong Tian</p></summary>
<p>

**Abstract:** Optimization problems with expensive nonlinear cost functions and combinatorial constraints appear in many real-world applications, but remain challenging to solve efficiently. Existing combinatorial solvers like Mixed Integer Linear Programming can be fast in practice but cannot readily optimize nonlinear cost functions, while general nonlinear optimizers like gradient descent often do not handle complex combinatorial structures, may require many queries of the cost function, and are prone to local optima. To bridge this gap, we propose SurCo that learns linear Surrogate costs which can be used by existing Combinatorial solvers to output good solutions to the original nonlinear combinatorial optimization problem, combining the flexibility of gradient-based methods with the structure of linear combinatorial optimization. We learn these linear surrogates end-to-end with the nonlinear loss by differentiating through the linear surrogate solver. Three variants of SurCo are proposed: SurCo-zero operates on individual nonlinear problems, SurCo-prior trains a linear surrogate predictor on distributions of problems, and SurCo-hybrid uses a model trained offline to warm start online solving for SurCo-zero. We analyze our method theoretically and empirically, showing smooth convergence and improved performance. Experiments show that compared to state-of-the-art approaches and expert-designed heuristics, SurCo obtains lower cost solutions with comparable or faster solve time for two realworld industry-level applications: embedding table sharding and inverse photonic design.

</p>
</details>

<details><summary><b>Factor Investing with a Deep Multi-Factor Model</b>
<a href="https://arxiv.org/abs/2210.12462">arxiv:2210.12462</a>
&#x1F4C8; 9 <br>
<p>Zikai Wei, Bo Dai, Dahua Lin</p></summary>
<p>

**Abstract:** Modeling and characterizing multiple factors is perhaps the most important step in achieving excess returns over market benchmarks. Both academia and industry are striving to find new factors that have good explanatory power for future stock returns and good stability of their predictive power. In practice, factor investing is still largely based on linear multi-factor models, although many deep learning methods show promising results compared to traditional methods in stock trend prediction and portfolio risk management. However, the existing non-linear methods have two drawbacks: 1) there is a lack of interpretation of the newly discovered factors, 2) the financial insights behind the mining process are unclear, making practitioners reluctant to apply the existing methods to factor investing. To address these two shortcomings, we develop a novel deep multi-factor model that adopts industry neutralization and market neutralization modules with clear financial insights, which help us easily build a dynamic and multi-relational stock graph in a hierarchical structure to learn the graph representation of stock relationships at different levels, e.g., industry level and universal level. Subsequently, graph attention modules are adopted to estimate a series of deep factors that maximize the cumulative factor returns. And a factor-attention module is developed to approximately compose the estimated deep factors from the input factors, as a way to interpret the deep factors explicitly. Extensive experiments on real-world stock market data demonstrate the effectiveness of our deep multi-factor model in the task of factor investing.

</p>
</details>

<details><summary><b>Deep Learning in Single-Cell Analysis</b>
<a href="https://arxiv.org/abs/2210.12385">arxiv:2210.12385</a>
&#x1F4C8; 9 <br>
<p>Dylan Molho, Jiayuan Ding, Zhaoheng Li, Hongzhi Wen, Wenzhuo Tang, Yixin Wang, Julian Venegas, Wei Jin, Renming Liu, Runze Su, Patrick Danaher, Robert Yang, Yu Leo Lei, Yuying Xie, Jiliang Tang</p></summary>
<p>

**Abstract:** Single-cell technologies are revolutionizing the entire field of biology. The large volumes of data generated by single-cell technologies are high-dimensional, sparse, heterogeneous, and have complicated dependency structures, making analyses using conventional machine learning approaches challenging and impractical. In tackling these challenges, deep learning often demonstrates superior performance compared to traditional machine learning methods. In this work, we give a comprehensive survey on deep learning in single-cell analysis. We first introduce background on single-cell technologies and their development, as well as fundamental concepts of deep learning including the most popular deep architectures. We present an overview of the single-cell analytic pipeline pursued in research applications while noting divergences due to data sources or specific applications. We then review seven popular tasks spanning through different stages of the single-cell analysis pipeline, including multimodal integration, imputation, clustering, spatial domain identification, cell-type deconvolution, cell segmentation, and cell-type annotation. Under each task, we describe the most recent developments in classical and deep learning methods and discuss their advantages and disadvantages. Deep learning tools and benchmark datasets are also summarized for each task. Finally, we discuss the future directions and the most recent challenges. This survey will serve as a reference for biologists and computer scientists, encouraging collaborations.

</p>
</details>

<details><summary><b>Language Model Pre-Training with Sparse Latent Typing</b>
<a href="https://arxiv.org/abs/2210.12582">arxiv:2210.12582</a>
&#x1F4C8; 8 <br>
<p>Liliang Ren, Zixuan Zhang, Han Wang, Clare R. Voss, Chengxiang Zhai, Heng Ji</p></summary>
<p>

**Abstract:** Modern large-scale Pre-trained Language Models (PLMs) have achieved tremendous success on a wide range of downstream tasks. However, most of the LM pre-training objectives only focus on text reconstruction, but have not sought to learn latent-level interpretable representations of sentences. In this paper, we manage to push the language models to obtain a deeper understanding of sentences by proposing a new pre-training objective, Sparse Latent Typing, which enables the model to sparsely extract sentence-level keywords with diverse latent types. Experimental results show that our model is able to learn interpretable latent type categories in a self-supervised manner without using any external knowledge. Besides, the language model pre-trained with such an objective also significantly improves Information Extraction related downstream tasks in both supervised and few-shot settings. Our code is publicly available at: https://github.com/renll/SparseLT.

</p>
</details>

<details><summary><b>Explanation Shift: Detecting distribution shifts on tabular data via the explanation space</b>
<a href="https://arxiv.org/abs/2210.12369">arxiv:2210.12369</a>
&#x1F4C8; 8 <br>
<p>Carlos Mougan, Klaus Broelemann, Gjergji Kasneci, Thanassis Tiropanis, Steffen Staab</p></summary>
<p>

**Abstract:** As input data distributions evolve, the predictive performance of machine learning models tends to deteriorate. In the past, predictive performance was considered the key indicator to monitor. However, explanation aspects have come to attention within the last years. In this work, we investigate how model predictive performance and model explanation characteristics are affected under distribution shifts and how these key indicators are related to each other for tabular data. We find that the modeling of explanation shifts can be a better indicator for the detection of predictive performance changes than state-of-the-art techniques based on representations of distribution shifts. We provide a mathematical analysis of different types of distribution shifts as well as synthetic experimental examples.

</p>
</details>

<details><summary><b>Hard Gate Knowledge Distillation -- Leverage Calibration for Robust and Reliable Language Model</b>
<a href="https://arxiv.org/abs/2210.12427">arxiv:2210.12427</a>
&#x1F4C8; 6 <br>
<p>Dongkyu Lee, Zhiliang Tian, Yingxiu Zhao, Ka Chun Cheung, Nevin L. Zhang</p></summary>
<p>

**Abstract:** In knowledge distillation, a student model is trained with supervisions from both knowledge from a teacher and observations drawn from a training data distribution. Knowledge of a teacher is considered a subject that holds inter-class relations which send a meaningful supervision to a student; hence, much effort has been put to find such knowledge to be distilled. In this paper, we explore a question that has been given little attention: "when to distill such knowledge." The question is answered in our work with the concept of model calibration; we view a teacher model not only as a source of knowledge but also as a gauge to detect miscalibration of a student. This simple and yet novel view leads to a hard gate knowledge distillation scheme that switches between learning from a teacher model and training data. We verify the gating mechanism in the context of natural language generation at both the token-level and the sentence-level. Empirical comparisons with strong baselines show that hard gate knowledge distillation not only improves model generalization, but also significantly lowers model calibration error.

</p>
</details>

<details><summary><b>Testing Independence of Exchangeable Random Variables</b>
<a href="https://arxiv.org/abs/2210.12392">arxiv:2210.12392</a>
&#x1F4C8; 6 <br>
<p>Marcus Hutter</p></summary>
<p>

**Abstract:** Given well-shuffled data, can we determine whether the data items are statistically (in)dependent? Formally, we consider the problem of testing whether a set of exchangeable random variables are independent. We will show that this is possible and develop tests that can confidently reject the null hypothesis that data is independent and identically distributed and have high power for (some) exchangeable distributions. We will make no structural assumptions on the underlying sample space. One potential application is in Deep Learning, where data is often scraped from the whole internet, with duplications abound, which can render data non-iid and test-set evaluation prone to give wrong answers.

</p>
</details>

<details><summary><b>MS-DC-UNeXt: An MLP-based Multi-Scale Feature Learning Framework For X-ray Images</b>
<a href="https://arxiv.org/abs/2210.12361">arxiv:2210.12361</a>
&#x1F4C8; 6 <br>
<p>Yuanyuan Jia, Xiaoyu Pan</p></summary>
<p>

**Abstract:** The advancement of deep learning theory and infrastructure is crucial in the progress of automatic segmentation techniques. Compared with traditional segmentation methods, automatic segmentation methods have considerable strengths such as convenience, accuracy, and so on. However, the drawbacks cannot be neglected. In the laboratory environment, most of the segmentation frameworks are based on deep learning at the cost of sacrificing the lightweight network architecture, adding a lot of parameters in the network to trade for excellent segmentation accuracy. In practical clinical applications, the lack of high computing performance (GPU) machines to maintain operational efficiency poses a huge challenge for the migration from laboratory to clinic. Recently, an alternative to the CNN and Transformer frameworks has been enthusiastically touted, with MLP-based network parameters being significantly decreased as all parameters are learned in the linear layer of the MLP and generate striking outcomes similar to both. Inspired by the MLP-based framework, we recommend leveraging the MS-DC-UNeXt as an alternative solution for medical image segmentation, which is mainly composed of Tokenized MLP block, Dual Channel block(DC-block), and Bottleneck (Res-ASPP). Please refer to the paper for the complete abstract

</p>
</details>

<details><summary><b>Information-Transport-based Policy for Simultaneous Translation</b>
<a href="https://arxiv.org/abs/2210.12357">arxiv:2210.12357</a>
&#x1F4C8; 6 <br>
<p>Shaolei Zhang, Yang Feng</p></summary>
<p>

**Abstract:** Simultaneous translation (ST) outputs translation while receiving the source inputs, and hence requires a policy to determine whether to translate a target token or wait for the next source token. The major challenge of ST is that each target token can only be translated based on the current received source tokens, where the received source information will directly affect the translation quality. So naturally, how much source information is received for the translation of the current target token is supposed to be the pivotal evidence for the ST policy to decide between translating and waiting. In this paper, we treat the translation as information transport from source to target and accordingly propose an Information-Transport-based Simultaneous Translation (ITST). ITST quantifies the transported information weight from each source token to the current target token, and then decides whether to translate the target token according to its accumulated received information. Experiments on both text-to-text ST and speech-to-text ST (a.k.a., streaming speech translation) tasks show that ITST outperforms strong baselines and achieves state-of-the-art performance.

</p>
</details>

<details><summary><b>The Art NFTs and Their Marketplaces</b>
<a href="https://arxiv.org/abs/2210.14942">arxiv:2210.14942</a>
&#x1F4C8; 5 <br>
<p>Lanqing Du, Michelle Kim, Jinwook Lee</p></summary>
<p>

**Abstract:** Non-Fungible Tokens (NFTs) are crypto assets with a unique digital identifier for ownership, powered by blockchain technology. Technically speaking, anything digital could be minted and sold as an NFT, which provides proof of ownership and authenticity of a digital file. For this reason, it helps us distinguish between the originals and their copies, making it possible to trade them. This paper focuses on art NFTs that change how artists can sell their products. It also changes how the art trade market works since NFT technology cuts out the middleman. Recently, the utility of NFTs has become an essential issue in the NFT ecosystem, which refers to the owners' usefulness, profitability, and benefits. Using recent major art NFT marketplace datasets, we summarize and interpret the current market trends and patterns in a way that brings insight into the future art market. Numerical examples are presented.

</p>
</details>

<details><summary><b>DOROTHIE: Spoken Dialogue for Handling Unexpected Situations in Interactive Autonomous Driving Agents</b>
<a href="https://arxiv.org/abs/2210.12511">arxiv:2210.12511</a>
&#x1F4C8; 5 <br>
<p>Ziqiao Ma, Ben VanDerPloeg, Cristian-Paul Bara, Huang Yidong, Eui-In Kim, Felix Gervits, Matthew Marge, Joyce Chai</p></summary>
<p>

**Abstract:** In the real world, autonomous driving agents navigate in highly dynamic environments full of unexpected situations where pre-trained models are unreliable. In these situations, what is immediately available to vehicles is often only human operators. Empowering autonomous driving agents with the ability to navigate in a continuous and dynamic environment and to communicate with humans through sensorimotor-grounded dialogue becomes critical. To this end, we introduce Dialogue On the ROad To Handle Irregular Events (DOROTHIE), a novel interactive simulation platform that enables the creation of unexpected situations on the fly to support empirical studies on situated communication with autonomous driving agents. Based on this platform, we created the Situated Dialogue Navigation (SDN), a navigation benchmark of 183 trials with a total of 8415 utterances, around 18.7 hours of control streams, and 2.9 hours of trimmed audio. SDN is developed to evaluate the agent's ability to predict dialogue moves from humans as well as generate its own dialogue moves and physical navigation actions. We further developed a transformer-based baseline model for these SDN tasks. Our empirical results indicate that language guided-navigation in a highly dynamic environment is an extremely difficult task for end-to-end models. These results will provide insight towards future work on robust autonomous driving agents. The DOROTHIE platform, SDN benchmark, and code for the baseline model are available at https://github.com/sled-group/DOROTHIE.

</p>
</details>

<details><summary><b>Prompt-Tuning Can Be Much Better Than Fine-Tuning on Cross-lingual Understanding With Multilingual Language Models</b>
<a href="https://arxiv.org/abs/2210.12360">arxiv:2210.12360</a>
&#x1F4C8; 5 <br>
<p>Lifu Tu, Caiming Xiong, Yingbo Zhou</p></summary>
<p>

**Abstract:** Pre-trained multilingual language models show significant performance gains for zero-shot cross-lingual model transfer on a wide range of natural language understanding (NLU) tasks. Previously, for zero-shot cross-lingual evaluation, pre-trained models are only fine-tuned on English data and tested on a variety of target languages. In this paper, we do cross-lingual evaluation on various NLU tasks (sentence classification, sequence labeling, question answering) using prompt-tuning and compare it with fine-tuning. The results show that prompt tuning achieves much better cross-lingual transfer than fine-tuning across datasets, with only 0.1% to 0.3% tuned parameters. Additionally, we demonstrate through the analysis that prompt tuning can have better cross-lingual transferability of representations on downstream tasks with better aligned decision boundaries.

</p>
</details>

<details><summary><b>Leveraging Large Language Models for Multiple Choice Question Answering</b>
<a href="https://arxiv.org/abs/2210.12353">arxiv:2210.12353</a>
&#x1F4C8; 5 <br>
<p>Joshua Robinson, Christopher Michael Rytting, David Wingate</p></summary>
<p>

**Abstract:** While large language models (LLMs) like GPT-3 have achieved impressive results on multiple choice question answering (MCQA) tasks in the zero, one, and few-shot settings, they generally lag behind the MCQA state of the art (SOTA). MCQA tasks have traditionally been presented to LLMs like cloze tasks. An LLM is conditioned on a question (without the associated answer options) and its chosen option is the one assigned the highest probability after normalization (for length, etc.). A more natural prompting approach is to present the question and answer options to the LLM jointly and have it output the symbol (e.g., "A") associated with its chosen answer option. This approach allows the model to explicitly compare answer options, reduces computational costs, and mitigates the effects of tokenization scheme and answer option representations on answer selection. For the natural approach to be effective the LLM it is used with must be able to associate answer options with the symbols that represent them. The LLM needs what we term multiple choice symbol binding (MCSB) ability. This ability varies greatly by model. We show that a model with high MCSB ability performs much better with the natural approach than with the traditional approach across 20 diverse datasets and largely closes the gap with the SOTA, suggesting that the MCQA ability of LLMs has been previously underestimated.

</p>
</details>

<details><summary><b>Adaptive Label Smoothing with Self-Knowledge in Natural Language Generation</b>
<a href="https://arxiv.org/abs/2210.13459">arxiv:2210.13459</a>
&#x1F4C8; 4 <br>
<p>Dongkyu Lee, Ka Chun Cheung, Nevin L. Zhang</p></summary>
<p>

**Abstract:** Overconfidence has been shown to impair generalization and calibration of a neural network. Previous studies remedy this issue by adding a regularization term to a loss function, preventing a model from making a peaked distribution. Label smoothing smoothes target labels with a pre-defined prior label distribution; as a result, a model is learned to maximize the likelihood of predicting the soft label. Nonetheless, the amount of smoothing is the same in all samples and remains fixed in training. In other words, label smoothing does not reflect the change in probability distribution mapped by a model over the course of training. To address this issue, we propose a regularization scheme that brings dynamic nature into the smoothing parameter by taking model probability distribution into account, thereby varying the parameter per instance. A model in training self-regulates the extent of smoothing on the fly during forward propagation. Furthermore, inspired by recent work in bridging label smoothing and knowledge distillation, our work utilizes self-knowledge as a prior label distribution in softening target labels, and presents theoretical support for the regularization effect by knowledge distillation and the dynamic smoothing parameter. Our regularizer is validated comprehensively, and the result illustrates marked improvements in model generalization and calibration, enhancing robustness and trustworthiness of a model.

</p>
</details>

<details><summary><b>A Visual Tour Of Current Challenges In Multimodal Language Models</b>
<a href="https://arxiv.org/abs/2210.12565">arxiv:2210.12565</a>
&#x1F4C8; 4 <br>
<p>Shashank Sonkar, Naiming Liu, Richard G. Baraniuk</p></summary>
<p>

**Abstract:** Transformer models trained on massive text corpora have become the de facto models for a wide range of natural language processing tasks. However, learning effective word representations for function words remains challenging. Multimodal learning, which visually grounds transformer models in imagery, can overcome the challenges to some extent; however, there is still much work to be done. In this study, we explore the extent to which visual grounding facilitates the acquisition of function words using stable diffusion models that employ multimodal models for text-to-image generation. Out of seven categories of function words, along with numerous subcategories, we find that stable diffusion models effectively model only a small fraction of function words -- a few pronoun subcategories and relatives. We hope that our findings will stimulate the development of new datasets and approaches that enable multimodal models to learn better representations of function words.

</p>
</details>

<details><summary><b>Policy Optimization with Advantage Regularization for Long-Term Fairness in Decision Systems</b>
<a href="https://arxiv.org/abs/2210.12546">arxiv:2210.12546</a>
&#x1F4C8; 4 <br>
<p>Eric Yang Yu, Zhizhen Qin, Min Kyung Lee, Sicun Gao</p></summary>
<p>

**Abstract:** Long-term fairness is an important factor of consideration in designing and deploying learning-based decision systems in high-stake decision-making contexts. Recent work has proposed the use of Markov Decision Processes (MDPs) to formulate decision-making with long-term fairness requirements in dynamically changing environments, and demonstrated major challenges in directly deploying heuristic and rule-based policies that worked well in static environments. We show that policy optimization methods from deep reinforcement learning can be used to find strictly better decision policies that can often achieve both higher overall utility and less violation of the fairness requirements, compared to previously-known strategies. In particular, we propose new methods for imposing fairness requirements in policy optimization by regularizing the advantage evaluation of different actions. Our proposed methods make it easy to impose fairness constraints without reward engineering or sacrificing training efficiency. We perform detailed analyses in three established case studies, including attention allocation in incident monitoring, bank loan approval, and vaccine distribution in population networks.

</p>
</details>

<details><summary><b>EtriCA: Event-Triggered Context-Aware Story Generation Augmented by Cross Attention</b>
<a href="https://arxiv.org/abs/2210.12463">arxiv:2210.12463</a>
&#x1F4C8; 4 <br>
<p>Chen Tang, Chenghua Lin, Henglin Huang, Frank Guerin, Zhihao Zhang</p></summary>
<p>

**Abstract:** One of the key challenges of automatic story generation is how to generate a long narrative that can maintain fluency, relevance, and coherence. Despite recent progress, current story generation systems still face the challenge of how to effectively capture contextual and event features, which has a profound impact on a model's generation performance. To address these challenges, we present EtriCA, a novel neural generation model, which improves the relevance and coherence of the generated stories through residually mapping context features to event sequences with a cross-attention mechanism. Such a feature capturing mechanism allows our model to better exploit the logical relatedness between events when generating stories. Extensive experiments based on both automatic and human evaluations show that our model significantly outperforms state-of-the-art baselines, demonstrating the effectiveness of our model in leveraging context and event features.

</p>
</details>

<details><summary><b>The Devil is in the Conflict: Disentangled Information Graph Neural Networks for Fraud Detection</b>
<a href="https://arxiv.org/abs/2210.12384">arxiv:2210.12384</a>
&#x1F4C8; 4 <br>
<p>Zhixun Li, Dingshuo Chen, Qiang Liu, Shu Wu</p></summary>
<p>

**Abstract:** Graph-based fraud detection has heretofore received considerable attention. Owning to the great success of Graph Neural Networks (GNNs), many approaches adopting GNNs for fraud detection has been gaining momentum. However, most existing methods are based on the strong inductive bias of homophily, which indicates that the context neighbors tend to have same labels or similar features. In real scenarios, fraudsters often engage in camouflage behaviors in order to avoid detection system. Therefore, the homophilic assumption no longer holds, which is known as the inconsistency problem. In this paper, we argue that the performance degradation is mainly attributed to the inconsistency between topology and attribute. To address this problem, we propose to disentangle the fraud network into two views, each corresponding to topology and attribute respectively. Then we propose a simple and effective method that uses the attention mechanism to adaptively fuse two views which captures data-specific preference. In addition, we further improve it by introducing mutual information constraints for topology and attribute. To this end, we propose a Disentangled Information Graph Neural Network (DIGNN) model, which utilizes variational bounds to find an approximate solution to our proposed optimization objective function. Extensive experiments demonstrate that our model can significantly outperform stateof-the-art baselines on real-world fraud detection datasets.

</p>
</details>

<details><summary><b>OpenAUC: Towards AUC-Oriented Open-Set Recognition</b>
<a href="https://arxiv.org/abs/2210.13458">arxiv:2210.13458</a>
&#x1F4C8; 3 <br>
<p>Zitai Wang, Qianqian Xu, Zhiyong Yang, Yuan He, Xiaochun Cao, Qingming Huang</p></summary>
<p>

**Abstract:** Traditional machine learning follows a close-set assumption that the training and test set share the same label space. While in many practical scenarios, it is inevitable that some test samples belong to unknown classes (open-set). To fix this issue, Open-Set Recognition (OSR), whose goal is to make correct predictions on both close-set samples and open-set samples, has attracted rising attention. In this direction, the vast majority of literature focuses on the pattern of open-set samples. However, how to evaluate model performance in this challenging task is still unsolved. In this paper, a systematic analysis reveals that most existing metrics are essentially inconsistent with the aforementioned goal of OSR: (1) For metrics extended from close-set classification, such as Open-set F-score, Youden's index, and Normalized Accuracy, a poor open-set prediction can escape from a low performance score with a superior close-set prediction. (2) Novelty detection AUC, which measures the ranking performance between close-set and open-set samples, ignores the close-set performance. To fix these issues, we propose a novel metric named OpenAUC. Compared with existing metrics, OpenAUC enjoys a concise pairwise formulation that evaluates open-set performance and close-set performance in a coupling manner. Further analysis shows that OpenAUC is free from the aforementioned inconsistency properties. Finally, an end-to-end learning method is proposed to minimize the OpenAUC risk, and the experimental results on popular benchmark datasets speak to its effectiveness.

</p>
</details>

<details><summary><b>Learning to Perform Complex Tasks through Compositional Fine-Tuning of Language Models</b>
<a href="https://arxiv.org/abs/2210.12607">arxiv:2210.12607</a>
&#x1F4C8; 3 <br>
<p>Victor S. Bursztyn, David Demeter, Doug Downey, Larry Birnbaum</p></summary>
<p>

**Abstract:** How to usefully encode compositional task structure has long been a core challenge in AI. Recent work in chain of thought prompting has shown that for very large neural language models (LMs), explicitly demonstrating the inferential steps involved in a target task may improve performance over end-to-end learning that focuses on the target task alone. However, chain of thought prompting has significant limitations due to its dependency on huge pretrained LMs. In this work, we present compositional fine-tuning (CFT): an approach based on explicitly decomposing a target task into component tasks, and then fine-tuning smaller LMs on a curriculum of such component tasks. We apply CFT to recommendation tasks in two domains, world travel and local dining, as well as a previously studied inferential task (sports understanding). We show that CFT outperforms end-to-end learning even with equal amounts of data, and gets consistently better as more component tasks are modeled via fine-tuning. Compared with chain of thought prompting, CFT performs at least as well using LMs only 7.4% of the size, and is moreover applicable to task domains for which data are not available during pretraining.

</p>
</details>

<details><summary><b>Efficient Nearest Neighbor Search for Cross-Encoder Models using Matrix Factorization</b>
<a href="https://arxiv.org/abs/2210.12579">arxiv:2210.12579</a>
&#x1F4C8; 3 <br>
<p>Nishant Yadav, Nicholas Monath, Rico Angell, Manzil Zaheer, Andrew McCallum</p></summary>
<p>

**Abstract:** Efficient k-nearest neighbor search is a fundamental task, foundational for many problems in NLP. When the similarity is measured by dot-product between dual-encoder vectors or $\ell_2$-distance, there already exist many scalable and efficient search methods. But not so when similarity is measured by more accurate and expensive black-box neural similarity models, such as cross-encoders, which jointly encode the query and candidate neighbor. The cross-encoders' high computational cost typically limits their use to reranking candidates retrieved by a cheaper model, such as dual encoder or TF-IDF. However, the accuracy of such a two-stage approach is upper-bounded by the recall of the initial candidate set, and potentially requires additional training to align the auxiliary retrieval model with the cross-encoder model. In this paper, we present an approach that avoids the use of a dual-encoder for retrieval, relying solely on the cross-encoder. Retrieval is made efficient with CUR decomposition, a matrix decomposition approach that approximates all pairwise cross-encoder distances from a small subset of rows and columns of the distance matrix. Indexing items using our approach is computationally cheaper than training an auxiliary dual-encoder model through distillation. Empirically, for k > 10, our approach provides test-time recall-vs-computational cost trade-offs superior to the current widely-used methods that re-rank items retrieved using a dual-encoder or TF-IDF.

</p>
</details>

<details><summary><b>Solving Continuous Control via Q-learning</b>
<a href="https://arxiv.org/abs/2210.12566">arxiv:2210.12566</a>
&#x1F4C8; 3 <br>
<p>Tim Seyde, Peter Werner, Wilko Schwarting, Igor Gilitschenski, Martin Riedmiller, Daniela Rus, Markus Wulfmeier</p></summary>
<p>

**Abstract:** While there has been substantial success in applying actor-critic methods to continuous control, simpler critic-only methods such as Q-learning often remain intractable in the associated high-dimensional action spaces. However, most actor-critic methods come at the cost of added complexity: heuristics for stabilization, compute requirements as well as wider hyperparameter search spaces. We show that these issues can be largely alleviated via Q-learning by combining action discretization with value decomposition, framing single-agent control as cooperative multi-agent reinforcement learning (MARL). With bang-bang actions, performance of this critic-only approach matches state-of-the-art continuous actor-critic methods when learning from features or pixels. We extend classical bandit examples from cooperative MARL to provide intuition for how decoupled critics leverage state information to coordinate joint optimization, and demonstrate surprisingly strong performance across a wide variety of continuous control tasks.

</p>
</details>

<details><summary><b>Baby Physical Safety Monitoring in Smart Home Using Action Recognition System</b>
<a href="https://arxiv.org/abs/2210.12527">arxiv:2210.12527</a>
&#x1F4C8; 3 <br>
<p>Victor Adewopo, Nelly Elsayed, Kelly Anderson</p></summary>
<p>

**Abstract:** Humans are able to intuitively deduce actions that took place between two states in observations via deductive reasoning. This is because the brain operates on a bidirectional communication model, which has radically improved the accuracy of recognition and prediction based on features connected to previous experiences. During the past decade, deep learning models for action recognition have significantly improved. However, deep neural networks struggle with these tasks on a smaller dataset for specific Action Recognition (AR) tasks. As with most action recognition tasks, the ambiguity of accurately describing activities in spatial-temporal data is a drawback that can be overcome by curating suitable datasets, including careful annotations and preprocessing of video data for analyzing various recognition tasks. In this study, we present a novel lightweight framework combining transfer learning techniques with a Conv2D LSTM layer to extract features from the pre-trained I3D model on the Kinetics dataset for a new AR task (Smart Baby Care) that requires a smaller dataset and less computational resources. Furthermore, we developed a benchmark dataset and an automated model that uses LSTM convolution with I3D (ConvLSTM-I3D) for recognizing and predicting baby activities in a smart baby room. Finally, we implemented video augmentation to improve model performance on the smart baby care task. Compared to other benchmark models, our experimental framework achieved better performance with less computational resources.

</p>
</details>

<details><summary><b>H-SAUR: Hypothesize, Simulate, Act, Update, and Repeat for Understanding Object Articulations from Interactions</b>
<a href="https://arxiv.org/abs/2210.12521">arxiv:2210.12521</a>
&#x1F4C8; 3 <br>
<p>Kei Ota, Hsiao-Yu Tung, Kevin A. Smith, Anoop Cherian, Tim K. Marks, Alan Sullivan, Asako Kanezaki, Joshua B. Tenenbaum</p></summary>
<p>

**Abstract:** The world is filled with articulated objects that are difficult to determine how to use from vision alone, e.g., a door might open inwards or outwards. Humans handle these objects with strategic trial-and-error: first pushing a door then pulling if that doesn't work. We enable these capabilities in autonomous agents by proposing "Hypothesize, Simulate, Act, Update, and Repeat" (H-SAUR), a probabilistic generative framework that simultaneously generates a distribution of hypotheses about how objects articulate given input observations, captures certainty over hypotheses over time, and infer plausible actions for exploration and goal-conditioned manipulation. We compare our model with existing work in manipulating objects after a handful of exploration actions, on the PartNet-Mobility dataset. We further propose a novel PuzzleBoxes benchmark that contains locked boxes that require multiple steps to solve. We show that the proposed model significantly outperforms the current state-of-the-art articulated object manipulation framework, despite using zero training data. We further improve the test-time efficiency of H-SAUR by integrating a learned prior from learning-based vision models.

</p>
</details>

<details><summary><b>Generative Modeling of High-resolution Global Precipitation Forecasts</b>
<a href="https://arxiv.org/abs/2210.12504">arxiv:2210.12504</a>
&#x1F4C8; 3 <br>
<p>James Duncan, Shashank Subramanian, Peter Harrington</p></summary>
<p>

**Abstract:** Forecasting global precipitation patterns and, in particular, extreme precipitation events is of critical importance to preparing for and adapting to climate change. Making accurate high-resolution precipitation forecasts using traditional physical models remains a major challenge in operational weather forecasting as they incur substantial computational costs and struggle to achieve sufficient forecast skill. Recently, deep-learning-based models have shown great promise in closing the gap with numerical weather prediction (NWP) models in terms of precipitation forecast skill, opening up exciting new avenues for precipitation modeling. However, it is challenging for these deep learning models to fully resolve the fine-scale structures of precipitation phenomena and adequately characterize the extremes of the long-tailed precipitation distribution. In this work, we present several improvements to the architecture and training process of a current state-of-the art deep learning precipitation model (FourCastNet) using a novel generative adversarial network (GAN) to better capture fine scales and extremes. Our improvements achieve superior performance in capturing the extreme percentiles of global precipitation, while comparable to state-of-the-art NWP models in terms of forecast skill at 1--2 day lead times. Together, these improvements set a new state-of-the-art in global precipitation forecasting.

</p>
</details>

<details><summary><b>Generalized Likelihood Ratio Test With One-Class Classifiers</b>
<a href="https://arxiv.org/abs/2210.12494">arxiv:2210.12494</a>
&#x1F4C8; 3 <br>
<p>Francesco Ardizzon, Stefano Tomasin</p></summary>
<p>

**Abstract:** One-class classification (OCC) is the problem of deciding whether an observed sample belongs to a target class or not. We consider the problem of learning an OCC model when the dataset available at the learning stage contains only samples from the target class. We aim at obtaining a classifier that performs as the generalized likelihood ratio test (GLRT), which is a well-known and provably optimal (under specific assumptions) classifier when the statistic of the target class is available. To this end, we consider both the multilayer perceptron neural network (NN) and the support vector machine (SVM) models. They are trained as two-class classifiers using an artificial dataset for the alternative class, obtained by generating random samples, uniformly over the domain of the target-class dataset. We prove that, under suitable assumptions, the models converge (with a large dataset) to the GLRT. Moreover, we show that the one-class least squares SVM (OCLSSVM) at convergence performs as the GLRT, with a suitable transformation function. Lastly, we compare the obtained solutions with the autoencoder (AE) classifier, which does not in general provide the GLRT

</p>
</details>

<details><summary><b>Learning Correlated Stackelberg Equilibrium in General-Sum Multi-Leader-Single-Follower Games</b>
<a href="https://arxiv.org/abs/2210.12470">arxiv:2210.12470</a>
&#x1F4C8; 3 <br>
<p>Yaolong Yu, Haifeng Xu, Haipeng Chen</p></summary>
<p>

**Abstract:** Many real-world strategic games involve interactions between multiple players. We study a hierarchical multi-player game structure, where players with asymmetric roles can be separated into leaders and followers, a setting often referred to as Stackelberg game or leader-follower game. In particular, we focus on a Stackelberg game scenario where there are multiple leaders and a single follower, called the Multi-Leader-Single-Follower (MLSF) game. We propose a novel asymmetric equilibrium concept for the MLSF game called Correlated Stackelberg Equilibrium (CSE). We design online learning algorithms that enable the players to interact in a distributed manner, and prove that it can achieve no-external Stackelberg-regret learning. This further translates to the convergence to approximate CSE via a reduction from no-external regret to no-swap regret. At the core of our works, we solve the intricate problem of how to learn equilibrium in leader-follower games with noisy bandit feedback by balancing exploration and exploitation in different learning structures.

</p>
</details>

<details><summary><b>Weakly-Supervised Temporal Article Grounding</b>
<a href="https://arxiv.org/abs/2210.12444">arxiv:2210.12444</a>
&#x1F4C8; 3 <br>
<p>Long Chen, Yulei Niu, Brian Chen, Xudong Lin, Guangxing Han, Christopher Thomas, Hammad Ayyubi, Heng Ji, Shih-Fu Chang</p></summary>
<p>

**Abstract:** Given a long untrimmed video and natural language queries, video grounding (VG) aims to temporally localize the semantically-aligned video segments. Almost all existing VG work holds two simple but unrealistic assumptions: 1) All query sentences can be grounded in the corresponding video. 2) All query sentences for the same video are always at the same semantic scale. Unfortunately, both assumptions make today's VG models fail to work in practice. For example, in real-world multimodal assets (eg, news articles), most of the sentences in the article can not be grounded in their affiliated videos, and they typically have rich hierarchical relations (ie, at different semantic scales). To this end, we propose a new challenging grounding task: Weakly-Supervised temporal Article Grounding (WSAG). Specifically, given an article and a relevant video, WSAG aims to localize all ``groundable'' sentences to the video, and these sentences are possibly at different semantic scales. Accordingly, we collect the first WSAG dataset to facilitate this task: YouwikiHow, which borrows the inherent multi-scale descriptions in wikiHow articles and plentiful YouTube videos. In addition, we propose a simple but effective method DualMIL for WSAG, which consists of a two-level MIL loss and a single-/cross- sentence constraint loss. These training objectives are carefully designed for these relaxed assumptions. Extensive ablations have verified the effectiveness of DualMIL.

</p>
</details>

<details><summary><b>Speech Emotion Recognition via an Attentive Time-Frequency Neural Network</b>
<a href="https://arxiv.org/abs/2210.12430">arxiv:2210.12430</a>
&#x1F4C8; 3 <br>
<p>Cheng Lu, Wenming Zheng, Hailun Lian, Yuan Zong, Chuangao Tang, Sunan Li, Yan Zhao</p></summary>
<p>

**Abstract:** Spectrogram is commonly used as the input feature of deep neural networks to learn the high(er)-level time-frequency pattern of speech signal for speech emotion recognition (SER). \textcolor{black}{Generally, different emotions correspond to specific energy activations both within frequency bands and time frames on spectrogram, which indicates the frequency and time domains are both essential to represent the emotion for SER. However, recent spectrogram-based works mainly focus on modeling the long-term dependency in time domain, leading to these methods encountering the following two issues: (1) neglecting to model the emotion-related correlations within frequency domain during the time-frequency joint learning; (2) ignoring to capture the specific frequency bands associated with emotions.} To cope with the issues, we propose an attentive time-frequency neural network (ATFNN) for SER, including a time-frequency neural network (TFNN) and time-frequency attention. Specifically, aiming at the first issue, we design a TFNN with a frequency-domain encoder (F-Encoder) based on the Transformer encoder and a time-domain encoder (T-Encoder) based on the Bidirectional Long Short-Term Memory (Bi-LSTM). The F-Encoder and T-Encoder model the correlations within frequency bands and time frames, respectively, and they are embedded into a time-frequency joint learning strategy to obtain the time-frequency patterns for speech emotions. Moreover, to handle the second issue, we also adopt time-frequency attention with a frequency-attention network (F-Attention) and a time-attention network (T-Attention) to focus on the emotion-related frequency band ranges and time frame ranges, which can enhance the discriminability of speech emotion features.

</p>
</details>

<details><summary><b>ADDMU: Detection of Far-Boundary Adversarial Examples with Data and Model Uncertainty Estimation</b>
<a href="https://arxiv.org/abs/2210.12396">arxiv:2210.12396</a>
&#x1F4C8; 3 <br>
<p>Fan Yin, Yao Li, Cho-Jui Hsieh, Kai-Wei Chang</p></summary>
<p>

**Abstract:** Adversarial Examples Detection (AED) is a crucial defense technique against adversarial attacks and has drawn increasing attention from the Natural Language Processing (NLP) community. Despite the surge of new AED methods, our studies show that existing methods heavily rely on a shortcut to achieve good performance. In other words, current search-based adversarial attacks in NLP stop once model predictions change, and thus most adversarial examples generated by those attacks are located near model decision boundaries. To surpass this shortcut and fairly evaluate AED methods, we propose to test AED methods with \textbf{F}ar \textbf{B}oundary (\textbf{FB}) adversarial examples. Existing methods show worse than random guess performance under this scenario. To overcome this limitation, we propose a new technique, \textbf{ADDMU}, \textbf{a}dversary \textbf{d}etection with \textbf{d}ata and \textbf{m}odel \textbf{u}ncertainty, which combines two types of uncertainty estimation for both regular and FB adversarial example detection. Our new method outperforms previous methods by 3.6 and 6.0 \emph{AUC} points under each scenario. Finally, our analysis shows that the two types of uncertainty provided by \textbf{ADDMU} can be leveraged to characterize adversarial examples and identify the ones that contribute most to model's robustness in adversarial training.

</p>
</details>

<details><summary><b>Diversity-Promoting Ensemble for Medical Image Segmentation</b>
<a href="https://arxiv.org/abs/2210.12388">arxiv:2210.12388</a>
&#x1F4C8; 3 <br>
<p>Mariana-Iuliana Georgescu, Radu Tudor Ionescu, Andreea-Iuliana Miron</p></summary>
<p>

**Abstract:** Medical image segmentation is an actively studied task in medical imaging, where the precision of the annotations is of utter importance towards accurate diagnosis and treatment. In recent years, the task has been approached with various deep learning systems, among the most popular models being U-Net. In this work, we propose a novel strategy to generate ensembles of different architectures for medical image segmentation, by leveraging the diversity (decorrelation) of the models forming the ensemble. More specifically, we utilize the Dice score among model pairs to estimate the correlation between the outputs of the two models forming each pair. To promote diversity, we select models with low Dice scores among each other. We carry out gastro-intestinal tract image segmentation experiments to compare our diversity-promoting ensemble (DiPE) with another strategy to create ensembles based on selecting the top scoring U-Net models. Our empirical results show that DiPE surpasses both individual models as well as the ensemble creation strategy based on selecting the top scoring models.

</p>
</details>

<details><summary><b>Counterfactual Generation Under Confounding</b>
<a href="https://arxiv.org/abs/2210.12368">arxiv:2210.12368</a>
&#x1F4C8; 3 <br>
<p>Abbavaram Gowtham Reddy, Saloni Dash, Amit Sharma, Vineeth N Balasubramanian</p></summary>
<p>

**Abstract:** A machine learning model, under the influence of observed or unobserved confounders in the training data, can learn spurious correlations and fail to generalize when deployed. For image classifiers, augmenting a training dataset using counterfactual examples has been empirically shown to break spurious correlations. However, the counterfactual generation task itself becomes more difficult as the level of confounding increases. Existing methods for counterfactual generation under confounding consider a fixed set of interventions (e.g., texture, rotation) and are not flexible enough to capture diverse data-generating processes. Given a causal generative process, we formally characterize the adverse effects of confounding on any downstream tasks and show that the correlation between generative factors (attributes) can be used to quantitatively measure confounding between generative factors. To minimize such correlation, we propose a counterfactual generation method that learns to modify the value of any attribute in an image and generate new images given a set of observed attributes, even when the dataset is highly confounded. These counterfactual images are then used to regularize the downstream classifier such that the learned representations are the same across various generative factors conditioned on the class label. Our method is computationally efficient, simple to implement, and works well for any number of generative factors and confounding variables. Our experimental results on both synthetic (MNIST variants) and real-world (CelebA) datasets show the usefulness of our approach.

</p>
</details>

<details><summary><b>GANI: Global Attacks on Graph Neural Networks via Imperceptible Node Injections</b>
<a href="https://arxiv.org/abs/2210.12598">arxiv:2210.12598</a>
&#x1F4C8; 2 <br>
<p>Junyuan Fang, Haixian Wen, Jiajing Wu, Qi Xuan, Zibin Zheng, Chi K. Tse</p></summary>
<p>

**Abstract:** Graph neural networks (GNNs) have found successful applications in various graph-related tasks. However, recent studies have shown that many GNNs are vulnerable to adversarial attacks. In a vast majority of existing studies, adversarial attacks on GNNs are launched via direct modification of the original graph such as adding/removing links, which may not be applicable in practice. In this paper, we focus on a realistic attack operation via injecting fake nodes. The proposed Global Attack strategy via Node Injection (GANI) is designed under the comprehensive consideration of an unnoticeable perturbation setting from both structure and feature domains. Specifically, to make the node injections as imperceptible and effective as possible, we propose a sampling operation to determine the degree of the newly injected nodes, and then generate features and select neighbors for these injected nodes based on the statistical information of features and evolutionary perturbations obtained from a genetic algorithm, respectively. In particular, the proposed feature generation mechanism is suitable for both binary and continuous node features. Extensive experimental results on benchmark datasets against both general and defended GNNs show strong attack performance of GANI. Moreover, the imperceptibility analyses also demonstrate that GANI achieves a relatively unnoticeable injection on benchmark datasets.

</p>
</details>

<details><summary><b>DMODE: Differential Monocular Object Distance Estimation Module without Class Specific Information</b>
<a href="https://arxiv.org/abs/2210.12596">arxiv:2210.12596</a>
&#x1F4C8; 2 <br>
<p>Pedram Agand, Michael Chang, Mo Chen</p></summary>
<p>

**Abstract:** Using a single camera to estimate the distances of objects reduces costs compared to stereo-vision and LiDAR. Although monocular distance estimation has been studied in the literature, previous methods mostly rely on knowing an object's class in some way. This can result in deteriorated performance for dataset with multi-class objects and objects with an undefined class. In this paper, we aim to overcome the potential downsides of class-specific approaches, and provide an alternative technique called DMODE that does not require any information relating to its class. Using differential approaches, we combine the changes in an object's size over time together with the camera's motion to estimate the object's distance. Since DMODE is class agnostic method, it is easily adaptable to new environments. Therefore, it is able to maintain performance across different object detectors, and be easily adapted to new object classes. We tested our model across different scenarios of training and testing on the KITTI MOTS dataset's ground-truth bounding box annotations, and bounding box outputs of TrackRCNN and EagerMOT. The instantaneous change of bounding box sizes and camera position are then used to obtain an object's position in 3D without measuring its detection source or class properties. Our results show that we are able to outperform traditional alternatives methods e.g. IPM \cite{TuohyIPM}, SVR \cite{svr}, and \cite{zhu2019learning} in test environments with multi-class object distance detections.

</p>
</details>

<details><summary><b>MetaEMS: A Meta Reinforcement Learning-based Control Framework for Building Energy Management System</b>
<a href="https://arxiv.org/abs/2210.12590">arxiv:2210.12590</a>
&#x1F4C8; 2 <br>
<p>Huiliang Zhang, Di Wu, Benoit Boulet</p></summary>
<p>

**Abstract:** The building sector has been recognized as one of the primary sectors for worldwide energy consumption. Improving the energy efficiency of the building sector can help reduce the operation cost and reduce the greenhouse gas emission. The energy management system (EMS) can monitor and control the operations of built-in appliances in buildings, so an efficient EMS is of crucial importance to improve the building operation efficiency and maintain safe operations. With the growing penetration of renewable energy and electrical appliances, increasing attention has been paid to the development of intelligent building EMS. Recently, reinforcement learning (RL) has been applied for building EMS and has shown promising potential. However, most of the current RL-based EMS solutions would need a large amount of data to learn a reliable control policy, which limits the applicability of these solutions in the real world. In this work, we propose MetaEMS, which can help achieve better energy management performance with the benefits of RL and meta-learning. Experiment results showcase that our proposed MetaEMS can adapt faster to environment changes and perform better in most situations compared with other baselines.

</p>
</details>

<details><summary><b>Active Learning of Discrete-Time Dynamics for Uncertainty-Aware Model Predictive Control</b>
<a href="https://arxiv.org/abs/2210.12583">arxiv:2210.12583</a>
&#x1F4C8; 2 <br>
<p>Alessandro Saviolo, Jonathan Frey, Abhishek Rathod, Moritz Diehl, Giuseppe Loianno</p></summary>
<p>

**Abstract:** Model-based control requires an accurate model of the system dynamics for precisely and safely controlling the robot in complex and dynamic environments. Moreover, in presence of variations in the operating conditions, the model should be continuously refined to compensate for dynamics changes. In this paper, we propose a self-supervised learning approach to actively model robot discrete-time dynamics. We combine offline learning from past experience and online learning from present robot interaction with the unknown environment. These two ingredients enable highly sample-efficient and adaptive learning for accurate inference of the model dynamics in real-time even in operating regimes significantly different from the training distribution. Moreover, we design an uncertainty-aware model predictive controller that is conditioned to the aleatoric (data) uncertainty of the learned dynamics. The controller actively selects the optimal control actions that (i) optimize the control performance and (ii) boost the online learning sample efficiency. We apply the proposed method to a quadrotor system in multiple challenging real-world experiments. Our approach exhibits high flexibility and generalization capabilities by consistently adapting to unseen flight conditions, while it significantly outperforms classical and adaptive control baselines.

</p>
</details>

<details><summary><b>Understanding Domain Learning in Language Models Through Subpopulation Analysis</b>
<a href="https://arxiv.org/abs/2210.12553">arxiv:2210.12553</a>
&#x1F4C8; 2 <br>
<p>Zheng Zhao, Yftah Ziser, Shay B. Cohen</p></summary>
<p>

**Abstract:** We investigate how different domains are encoded in modern neural network architectures. We analyze the relationship between natural language domains, model size, and the amount of training data used. The primary analysis tool we develop is based on subpopulation analysis with Singular Vector Canonical Correlation Analysis (SVCCA), which we apply to Transformer-based language models (LMs). We compare the latent representations of such a language model at its different layers from a pair of models: a model trained on multiple domains (an experimental model) and a model trained on a single domain (a control model). Through our method, we find that increasing the model capacity impacts how domain information is stored in upper and lower layers differently. In addition, we show that larger experimental models simultaneously embed domain-specific information as if they were conjoined control models. These findings are confirmed qualitatively, demonstrating the validity of our method.

</p>
</details>

<details><summary><b>Federated Calibration and Evaluation of Binary Classifiers</b>
<a href="https://arxiv.org/abs/2210.12526">arxiv:2210.12526</a>
&#x1F4C8; 2 <br>
<p>Graham Cormode, Igor Markov</p></summary>
<p>

**Abstract:** We address two major obstacles to practical use of supervised classifiers on distributed private data. Whether a classifier was trained by a federation of cooperating clients or trained centrally out of distribution, (1) the output scores must be calibrated, and (2) performance metrics must be evaluated -- all without assembling labels in one place. In particular, we show how to perform calibration and compute precision, recall, accuracy and ROC-AUC in the federated setting under three privacy models (i) secure aggregation, (ii) distributed differential privacy, (iii) local differential privacy. Our theorems and experiments clarify tradeoffs between privacy, accuracy, and data efficiency. They also help decide whether a given application has sufficient data to support federated calibration and evaluation.

</p>
</details>

<details><summary><b>Exploring The Landscape of Distributional Robustness for Question Answering Models</b>
<a href="https://arxiv.org/abs/2210.12517">arxiv:2210.12517</a>
&#x1F4C8; 2 <br>
<p>Anas Awadalla, Mitchell Wortsman, Gabriel Ilharco, Sewon Min, Ian Magnusson, Hannaneh Hajishirzi, Ludwig Schmidt</p></summary>
<p>

**Abstract:** We conduct a large empirical evaluation to investigate the landscape of distributional robustness in question answering. Our investigation spans over 350 models and 16 question answering datasets, including a diverse set of architectures, model sizes, and adaptation methods (e.g., fine-tuning, adapter tuning, in-context learning, etc.). We find that, in many cases, model variations do not affect robustness and in-distribution performance alone determines out-of-distribution performance. Moreover, our findings indicate that i) zero-shot and in-context learning methods are more robust to distribution shifts than fully fine-tuned models; ii) few-shot prompt fine-tuned models exhibit better robustness than few-shot fine-tuned span prediction models; iii) parameter-efficient and robustness enhancing training methods provide no significant robustness improvements. In addition, we publicly release all evaluations to encourage researchers to further analyze robustness trends for question answering models.

</p>
</details>

<details><summary><b>SpectraNet: Multivariate Forecasting and Imputation under Distribution Shifts and Missing Data</b>
<a href="https://arxiv.org/abs/2210.12515">arxiv:2210.12515</a>
&#x1F4C8; 2 <br>
<p>Cristian Challu, Peihong Jiang, Ying Nian Wu, Laurent Callot</p></summary>
<p>

**Abstract:** In this work, we tackle two widespread challenges in real applications for time-series forecasting that have been largely understudied: distribution shifts and missing data. We propose SpectraNet, a novel multivariate time-series forecasting model that dynamically infers a latent space spectral decomposition to capture current temporal dynamics and correlations on the recent observed history. A Convolution Neural Network maps the learned representation by sequentially mixing its components and refining the output. Our proposed approach can simultaneously produce forecasts and interpolate past observations and can, therefore, greatly simplify production systems by unifying imputation and forecasting tasks into a single model. SpectraNet achieves SoTA performance simultaneously on both tasks on five benchmark datasets, compared to forecasting and imputation models, with up to 92% fewer parameters and comparable training times. On settings with up to 80% missing data, SpectraNet has average performance improvements of almost 50% over the second-best alternative. Our code is available at https://github.com/cchallu/spectranet.

</p>
</details>

<details><summary><b>Cut-and-Approximate: 3D Shape Reconstruction from Planar Cross-sections with Deep Reinforcement Learning</b>
<a href="https://arxiv.org/abs/2210.12509">arxiv:2210.12509</a>
&#x1F4C8; 2 <br>
<p>Azimkhon Ostonov</p></summary>
<p>

**Abstract:** Current methods for 3D object reconstruction from a set of planar cross-sections still struggle to capture detailed topology or require a considerable number of cross-sections. In this paper, we present, to the best of our knowledge the first 3D shape reconstruction network to solve this task which additionally uses orthographic projections of the shape. Our method is based on applying a Reinforcement Learning algorithm to learn how to effectively parse the shape using a trial-and-error scheme relying on scalar rewards. This method cuts a part of a 3D shape in each step which is then approximated as a polygon mesh. The agent aims to maximize the reward that depends on the accuracy of surface reconstruction for the approximated parts. We also consider pre-training of the network for faster learning using demonstrations generated by a heuristic approach. Experiments show that our training algorithm which benefits from both imitation learning and also self exploration, learns efficient policies faster, which results the agent to produce visually compelling results.

</p>
</details>

<details><summary><b>Outsourcing Training without Uploading Data via Efficient Collaborative Open-Source Sampling</b>
<a href="https://arxiv.org/abs/2210.12575">arxiv:2210.12575</a>
&#x1F4C8; 1 <br>
<p>Junyuan Hong, Lingjuan Lyu, Jiayu Zhou, Michael Spranger</p></summary>
<p>

**Abstract:** As deep learning blooms with growing demand for computation and data resources, outsourcing model training to a powerful cloud server becomes an attractive alternative to training at a low-power and cost-effective end device. Traditional outsourcing requires uploading device data to the cloud server, which can be infeasible in many real-world applications due to the often sensitive nature of the collected data and the limited communication bandwidth. To tackle these challenges, we propose to leverage widely available open-source data, which is a massive dataset collected from public and heterogeneous sources (e.g., Internet images). We develop a novel strategy called Efficient Collaborative Open-source Sampling (ECOS) to construct a proximal proxy dataset from open-source data for cloud training, in lieu of client data. ECOS probes open-source data on the cloud server to sense the distribution of client data via a communication- and computation-efficient sampling process, which only communicates a few compressed public features and client scalar responses. Extensive empirical studies show that the proposed ECOS improves the quality of automated client labeling, model compression, and label outsourcing when applied in various learning scenarios.

</p>
</details>

<details><summary><b>HuPR: A Benchmark for Human Pose Estimation Using Millimeter Wave Radar</b>
<a href="https://arxiv.org/abs/2210.12564">arxiv:2210.12564</a>
&#x1F4C8; 1 <br>
<p>Shih-Po Lee, Niraj Prakash Kini, Wen-Hsiao Peng, Ching-Wen Ma, Jenq-Neng Hwang</p></summary>
<p>

**Abstract:** This paper introduces a novel human pose estimation benchmark, Human Pose with Millimeter Wave Radar (HuPR), that includes synchronized vision and radio signal components. This dataset is created using cross-calibrated mmWave radar sensors and a monocular RGB camera for cross-modality training of radar-based human pose estimation. There are two advantages of using mmWave radar to perform human pose estimation. First, it is robust to dark and low-light conditions. Second, it is not visually perceivable by humans and thus, can be widely applied to applications with privacy concerns, e.g., surveillance systems in patient rooms. In addition to the benchmark, we propose a cross-modality training framework that leverages the ground-truth 2D keypoints representing human body joints for training, which are systematically generated from the pre-trained 2D pose estimation network based on a monocular camera input image, avoiding laborious manual label annotation efforts. The framework consists of a new radar pre-processing method that better extracts the velocity information from radar data, Cross- and Self-Attention Module (CSAM), to fuse multi-scale radar features, and Pose Refinement Graph Convolutional Networks (PRGCN), to refine the predicted keypoint confidence heatmaps. Our intensive experiments on the HuPR benchmark show that the proposed scheme achieves better human pose estimation performance with only radar data, as compared to traditional pre-processing solutions and previous radio-frequency-based methods.

</p>
</details>

<details><summary><b>JoJoNet: Joint-contrast and Joint-sampling-and-reconstruction Network for Multi-contrast MRI</b>
<a href="https://arxiv.org/abs/2210.12548">arxiv:2210.12548</a>
&#x1F4C8; 1 <br>
<p>Lin Zhao, Xiao Chen, Eric Z. Chen, Yikang Liu, Dinggang Shen, Terrence Chen, Shanhui Sun</p></summary>
<p>

**Abstract:** Multi-contrast Magnetic Resonance Imaging (MRI) generates multiple medical images with rich and complementary information for routine clinical use; however, it suffers from a long acquisition time. Recent works for accelerating MRI, mainly designed for single contrast, may not be optimal for multi-contrast scenario since the inherent correlations among the multi-contrast images are not exploited. In addition, independent reconstruction of each contrast usually does not translate to optimal performance of downstream tasks. Motivated by these aspects, in this paper we design an end-to-end framework for accelerating multi-contrast MRI which simultaneously optimizes the entire MR imaging workflow including sampling, reconstruction and downstream tasks to achieve the best overall outcomes. The proposed framework consists of a sampling mask generator for each image contrast and a reconstructor exploiting the inter-contrast correlations with a recurrent structure which enables the information sharing in a holistic way. The sampling mask generator and the reconstructor are trained jointly across the multiple image contrasts. The acceleration ratio of each image contrast is also learnable and can be driven by a downstream task performance. We validate our approach on a multi-contrast brain dataset and a multi-contrast knee dataset. Experiments show that (1) our framework consistently outperforms the baselines designed for single contrast on both datasets; (2) our newly designed recurrent reconstruction network effectively improves the reconstruction quality for multi-contrast images; (3) the learnable acceleration ratio improves the downstream task performance significantly. Overall, this work has potentials to open up new avenues for optimizing the entire multi-contrast MR imaging workflow.

</p>
</details>

<details><summary><b>NeuroMapper: In-browser Visualizer for Neural Network Training</b>
<a href="https://arxiv.org/abs/2210.12492">arxiv:2210.12492</a>
&#x1F4C8; 1 <br>
<p>Zhiyan Zhou, Kevin Li, Haekyu Park, Megan Dass, Austin Wright, Nilaksh Das, Duen Horng Chau</p></summary>
<p>

**Abstract:** We present our ongoing work NeuroMapper, an in-browser visualization tool that helps machine learning (ML) developers interpret the evolution of a model during training, providing a new way to monitor the training process and visually discover reasons for suboptimal training. While most existing deep neural networks (DNNs) interpretation tools are designed for already-trained model, NeuroMapper scalably visualizes the evolution of the embeddings of a model's blocks across training epochs, enabling real-time visualization of 40,000 embedded points. To promote the embedding visualizations' spatial coherence across epochs, NeuroMapper adapts AlignedUMAP, a recent nonlinear dimensionality reduction technique to align the embeddings. With NeuroMapper, users can explore the training dynamics of a Resnet-50 model, and adjust the embedding visualizations' parameters in real time. NeuroMapper is open-sourced at https://github.com/poloclub/NeuroMapper and runs in all modern web browsers. A demo of the tool in action is available at: https://poloclub.github.io/NeuroMapper/.

</p>
</details>

<details><summary><b>NeuPhysics: Editable Neural Geometry and Physics from Monocular Videos</b>
<a href="https://arxiv.org/abs/2210.12352">arxiv:2210.12352</a>
&#x1F4C8; 1 <br>
<p>Yi-Ling Qiao, Alexander Gao, Ming C. Lin</p></summary>
<p>

**Abstract:** We present a method for learning 3D geometry and physics parameters of a dynamic scene from only a monocular RGB video input. To decouple the learning of underlying scene geometry from dynamic motion, we represent the scene as a time-invariant signed distance function (SDF) which serves as a reference frame, along with a time-conditioned deformation field. We further bridge this neural geometry representation with a differentiable physics simulator by designing a two-way conversion between the neural field and its corresponding hexahedral mesh, enabling us to estimate physics parameters from the source video by minimizing a cycle consistency loss. Our method also allows a user to interactively edit 3D objects from the source video by modifying the recovered hexahedral mesh, and propagating the operation back to the neural field representation. Experiments show that our method achieves superior mesh and video reconstruction of dynamic scenes compared to competing Neural Field approaches, and we provide extensive examples which demonstrate its ability to extract useful 3D representations from videos captured with consumer-grade cameras.

</p>
</details>

<details><summary><b>Feedback Assisted Adversarial Learning to Improve the Quality of Cone-beam CT Images</b>
<a href="https://arxiv.org/abs/2210.12578">arxiv:2210.12578</a>
&#x1F4C8; 0 <br>
<p>Takumi Hase, Megumi Nakao, Mitsuhiro Nakamura, Tetsuya Matsuda</p></summary>
<p>

**Abstract:** Unsupervised image translation using adversarial learning has been attracting attention to improve the image quality of medical images. However, adversarial training based on the global evaluation values of discriminators does not provide sufficient translation performance for locally different image features. We propose adversarial learning with a feedback mechanism from a discriminator to improve the quality of CBCT images. This framework employs U-net as the discriminator and outputs a probability map representing the local discrimination results. The probability map is fed back to the generator and used for training to improve the image translation. Our experiments using 76 corresponding CT-CBCT images confirmed that the proposed framework could capture more diverse image features than conventional adversarial learning frameworks and produced synthetic images with pixel values close to the reference image and a correlation coefficient of 0.93.

</p>
</details>

<details><summary><b>Deep Linear Networks for Matrix Completion -- An Infinite Depth Limit</b>
<a href="https://arxiv.org/abs/2210.12497">arxiv:2210.12497</a>
&#x1F4C8; 0 <br>
<p>Nadav Cohen, Govind Menon, Zsolt Veraszto</p></summary>
<p>

**Abstract:** The deep linear network (DLN) is a model for implicit regularization in gradient based optimization of overparametrized learning architectures. Training the DLN corresponds to a Riemannian gradient flow, where the Riemannian metric is defined by the architecture of the network and the loss function is defined by the learning task. We extend this geometric framework, obtaining explicit expressions for the volume form, including the case when the network has infinite depth. We investigate the link between the Riemannian geometry and the training asymptotics for matrix completion with rigorous analysis and numerics. We propose that implicit regularization is a result of bias towards high state space volume.

</p>
</details>


{% endraw %}
Prev: [2022.10.21]({{ '/2022/10/21/2022.10.21.html' | relative_url }})  Next: [2022.10.23]({{ '/2022/10/23/2022.10.23.html' | relative_url }})