## Summary for 2021-11-27, created on 2021-12-17


<details><summary><b>AdaDM: Enabling Normalization for Image Super-Resolution</b>
<a href="https://arxiv.org/abs/2111.13905">arxiv:2111.13905</a>
&#x1F4C8; 180 <br>
<p>Jie Liu, Jie Tang, Gangshan Wu</p></summary>
<p>

**Abstract:** Normalization like Batch Normalization (BN) is a milestone technique to normalize the distributions of intermediate layers in deep learning, enabling faster training and better generalization accuracy. However, in fidelity image Super-Resolution (SR), it is believed that normalization layers get rid of range flexibility by normalizing the features and they are simply removed from modern SR networks. In this paper, we study this phenomenon quantitatively and qualitatively. We found that the standard deviation of the residual feature shrinks a lot after normalization layers, which causes the performance degradation in SR networks. Standard deviation reflects the amount of variation of pixel values. When the variation becomes smaller, the edges will become less discriminative for the network to resolve. To address this problem, we propose an Adaptive Deviation Modulator (AdaDM), in which a modulation factor is adaptively predicted to amplify the pixel deviation. For better generalization performance, we apply BN in state-of-the-art SR networks with the proposed AdaDM. Meanwhile, the deviation amplification strategy in AdaDM makes the edge information in the feature more distinguishable. As a consequence, SR networks with BN and our AdaDM can get substantial performance improvements on benchmark datasets. Extensive experiments have been conducted to show the effectiveness of our method.

</p>
</details>

<details><summary><b>The Physics of Machine Learning: An Intuitive Introduction for the Physical Scientist</b>
<a href="https://arxiv.org/abs/2112.00851">arxiv:2112.00851</a>
&#x1F4C8; 7 <br>
<p>Stephon Alexander, Sarah Bawabe, Batia Friedman-Shaw, Michael W. Toomey</p></summary>
<p>

**Abstract:** This article is intended for physical scientists who wish to gain deeper insights into machine learning algorithms which we present via the domain they know best, physics. We begin with a review of two energy-based machine learning algorithms, Hopfield networks and Boltzmann machines, and their connection to the Ising model. This serves as a foundation to understand the phenomenon of learning more generally. Equipped with this intuition we then delve into additional, more "practical," machine learning architectures including feedforward neural networks, convolutional neural networks, and autoencoders. We also provide code that explicitly demonstrates training a neural network with gradient descent.

</p>
</details>

<details><summary><b>Roadmap for Edge AI: A Dagstuhl Perspective</b>
<a href="https://arxiv.org/abs/2112.00616">arxiv:2112.00616</a>
&#x1F4C8; 6 <br>
<p>Aaron Yi Ding, Ella Peltonen, Tobias Meuser, Atakan Aral, Christian Becker, Schahram Dustdar, Thomas Hiessl, Dieter Kranzlmuller, Madhusanka Liyanage, Setareh Magshudi, Nitinder Mohan, Joerg Ott, Jan S. Rellermeyer, Stefan Schulte, Henning Schulzrinne, Gurkan Solmaz, Sasu Tarkoma, Blesson Varghese, Lars Wolf</p></summary>
<p>

**Abstract:** Based on the collective input of Dagstuhl Seminar (21342), this paper presents a comprehensive discussion on AI methods and capabilities in the context of edge computing, referred as Edge AI. In a nutshell, we envision Edge AI to provide adaptation for data-driven applications, enhance network and radio access, and allow the creation, optimization, and deployment of distributed AI/ML pipelines with given quality of experience, trust, security and privacy targets. The Edge AI community investigates novel ML methods for the edge computing environment, spanning multiple sub-fields of computer science, engineering and ICT. The goal is to share an envisioned roadmap that can bring together key actors and enablers to further advance the domain of Edge AI.

</p>
</details>

<details><summary><b>NCVX: A User-Friendly and Scalable Package for Nonconvex Optimization in Machine Learning</b>
<a href="https://arxiv.org/abs/2111.13984">arxiv:2111.13984</a>
&#x1F4C8; 6 <br>
<p>Buyun Liang, Ju Sun</p></summary>
<p>

**Abstract:** Optimizing nonconvex (NCVX) problems, especially those nonsmooth (NSMT) and constrained (CSTR), is an essential part of machine learning and deep learning. But it is hard to reliably solve this type of problems without optimization expertise. Existing general-purpose NCVX optimization packages are powerful, but typically cannot handle nonsmoothness. GRANSO is among the first packages targeting NCVX, NSMT, CSTR problems. However, it has several limitations such as the lack of auto-differentiation and GPU acceleration, which preclude the potential broad deployment by non-experts. To lower the technical barrier for the machine learning community, we revamp GRANSO into a user-friendly and scalable python package named NCVX, featuring auto-differentiation, GPU acceleration, tensor input, scalable QP solver, and zero dependency on proprietary packages. As a highlight, NCVX can solve general CSTR deep learning problems, the first of its kind. NCVX is available at https://ncvx.org, with detailed documentation and numerous examples from machine learning and other fields.

</p>
</details>

<details><summary><b>Why MDAC? A Multi-domain Activation Function</b>
<a href="https://arxiv.org/abs/2111.13858">arxiv:2111.13858</a>
&#x1F4C8; 6 <br>
<p>Zhenhua Wang, Dong Gao, Haozhe Liu, Fanglin Liu</p></summary>
<p>

**Abstract:** In this study, a novel, general and ingenious activation function termed MDAC is proposed to surmount the troubles of gradient vanishing and non-differentiable existence. MDAC approximately inherits the properties of exponential activation function (such as Tanh family) and piecewise linear activation function (such as ReLU family). Specifically, in the positive region, the adaptive linear structure is designed to respond to various domain distributions. In the negative region, the combination of exponent and linearity is considered to conquer the obstacle of gradient vanishing. Furthermore, the non-differentiable existence is eliminated by smooth approximation. Experiments show that MDAC improves performance on both classical models and pre-training optimization models in six domain datasets by simply changing the activation function, which indicates MDAC's effectiveness and pro-gressiveness. MDAC is superior to other prevalent activation functions in robustness and generalization, and can reflect excellent activation performance in multiple domains.

</p>
</details>

<details><summary><b>Federated Gaussian Process: Convergence, Automatic Personalization and Multi-fidelity Modeling</b>
<a href="https://arxiv.org/abs/2111.14008">arxiv:2111.14008</a>
&#x1F4C8; 5 <br>
<p>Xubo Yue, Raed Al Kontar</p></summary>
<p>

**Abstract:** In this paper, we propose \texttt{FGPR}: a Federated Gaussian process ($\mathcal{GP}$) regression framework that uses an averaging strategy for model aggregation and stochastic gradient descent for local client computations. Notably, the resulting global model excels in personalization as \texttt{FGPR} jointly learns a global $\mathcal{GP}$ prior across all clients. The predictive posterior then is obtained by exploiting this prior and conditioning on local data which encodes personalized features from a specific client. Theoretically, we show that \texttt{FGPR} converges to a critical point of the full log-likelihood function, subject to statistical error. Through extensive case studies we show that \texttt{FGPR} excels in a wide range of applications and is a promising approach for privacy-preserving multi-fidelity data modeling.

</p>
</details>

<details><summary><b>Answer Generation for Questions With Multiple Information Sources in E-Commerce</b>
<a href="https://arxiv.org/abs/2111.14003">arxiv:2111.14003</a>
&#x1F4C8; 5 <br>
<p>Anand A. Rajasekar, Nikesh Garera</p></summary>
<p>

**Abstract:** Automatic question answering is an important yet challenging task in E-commerce given the millions of questions posted by users about the product that they are interested in purchasing. Hence, there is a great demand for automatic answer generation systems that provide quick responses using related information about the product. There are three sources of knowledge available for answering a user posted query, they are reviews, duplicate or similar questions, and specifications. Effectively utilizing these information sources will greatly aid us in answering complex questions. However, there are two main challenges present in exploiting these sources: (i) The presence of irrelevant information and (ii) the presence of ambiguity of sentiment present in reviews and similar questions. Through this work we propose a novel pipeline (MSQAP) that utilizes the rich information present in the aforementioned sources by separately performing relevancy and ambiguity prediction before generating a response.
  Experimental results show that our relevancy prediction model (BERT-QA) outperforms all other variants and has an improvement of 12.36% in F1 score compared to the BERT-base baseline. Our generation model (T5-QA) outperforms the baselines in all content preservation metrics such as BLEU, ROUGE and has an average improvement of 35.02% in ROUGE and 198.75% in BLEU compared to the highest performing baseline (HSSC-q). Human evaluation of our pipeline shows us that our method has an overall improvement in accuracy of 30.7% over the generation model (T5-QA), resulting in our full pipeline-based approach (MSQAP) providing more accurate answers. To the best of our knowledge, this is the first work in the e-commerce domain that automatically generates natural language answers combining the information present in diverse sources such as specifications, similar questions, and reviews data.

</p>
</details>

<details><summary><b>Label Assistant: A Workflow for Assisted Data Annotation in Image Segmentation Tasks</b>
<a href="https://arxiv.org/abs/2111.13970">arxiv:2111.13970</a>
&#x1F4C8; 5 <br>
<p>Marcel P. Schilling, Luca Rettenberger, Friedrich Münke, Haijun Cui, Anna A. Popova, Pavel A. Levkin, Ralf Mikut, Markus Reischl</p></summary>
<p>

**Abstract:** Recent research in the field of computer vision strongly focuses on deep learning architectures to tackle image processing problems. Deep neural networks are often considered in complex image processing scenarios since traditional computer vision approaches are expensive to develop or reach their limits due to complex relations. However, a common criticism is the need for large annotated datasets to determine robust parameters. Annotating images by human experts is time-consuming, burdensome, and expensive. Thus, support is needed to simplify annotation, increase user efficiency, and annotation quality. In this paper, we propose a generic workflow to assist the annotation process and discuss methods on an abstract level. Thereby, we review the possibilities of focusing on promising samples, image pre-processing, pre-labeling, label inspection, or post-processing of annotations. In addition, we present an implementation of the proposal by means of a developed flexible and extendable software prototype nested in hybrid touchscreen/laptop device.

</p>
</details>

<details><summary><b>Safe Screening for Sparse Conditional Random Fields</b>
<a href="https://arxiv.org/abs/2111.13958">arxiv:2111.13958</a>
&#x1F4C8; 5 <br>
<p>Weizhong Zhang, Shuang Qiu</p></summary>
<p>

**Abstract:** Sparse Conditional Random Field (CRF) is a powerful technique in computer vision and natural language processing for structured prediction. However, solving sparse CRFs in large-scale applications remains challenging. In this paper, we propose a novel safe dynamic screening method that exploits an accurate dual optimum estimation to identify and remove the irrelevant features during the training process. Thus, the problem size can be reduced continuously, leading to great savings in the computational cost without sacrificing any accuracy on the finally learned model. To the best of our knowledge, this is the first screening method which introduces the dual optimum estimation technique -- by carefully exploring and exploiting the strong convexity and the complex structure of the dual problem -- in static screening methods to dynamic screening. In this way, we can absorb the advantages of both the static and dynamic screening methods and avoid their drawbacks. Our estimation would be much more accurate than those developed based on the duality gap, which contributes to a much stronger screening rule. Moreover, our method is also the first screening method in sparse CRFs and even structure prediction models. Experimental results on both synthetic and real-world datasets demonstrate that the speedup gained by our method is significant.

</p>
</details>

<details><summary><b>Sparse Subspace Clustering Friendly Deep Dictionary Learning for Hyperspectral Image Classification</b>
<a href="https://arxiv.org/abs/2111.13920">arxiv:2111.13920</a>
&#x1F4C8; 5 <br>
<p>Anurag Goel, Angshul Majumdar</p></summary>
<p>

**Abstract:** Subspace clustering techniques have shown promise in hyperspectral image segmentation. The fundamental assumption in subspace clustering is that the samples belonging to different clusters/segments lie in separable subspaces. What if this condition does not hold? We surmise that even if the condition does not hold in the original space, the data may be nonlinearly transformed to a space where it will be separable into subspaces. In this work, we propose a transformation based on the tenets of deep dictionary learning (DDL). In particular, we incorporate the sparse subspace clustering (SSC) loss in the DDL formulation. Here DDL nonlinearly transforms the data such that the transformed representation (of the data) is separable into subspaces. We show that the proposed formulation improves over the state-of-the-art deep learning techniques in hyperspectral image clustering.

</p>
</details>

<details><summary><b>Average Outward Flux Skeletons for Environment Mapping and Topology Matching</b>
<a href="https://arxiv.org/abs/2111.13826">arxiv:2111.13826</a>
&#x1F4C8; 5 <br>
<p>Morteza Rezanejad, Babak Samari, Elham Karimi, Ioannis Rekleitis, Gregory Dudek, Kaleem Siddiqi</p></summary>
<p>

**Abstract:** We consider how to directly extract a road map (also known as a topological representation) of an initially-unknown 2-dimensional environment via an online procedure that robustly computes a retraction of its boundaries. In this article, we first present the online construction of a topological map and the implementation of a control law for guiding the robot to the nearest unexplored area, first presented in [1]. The proposed method operates by allowing the robot to localize itself on a partially constructed map, calculate a path to unexplored parts of the environment (frontiers), compute a robust terminating condition when the robot has fully explored the environment, and achieve loop closure detection. The proposed algorithm results in smooth safe paths for the robot's navigation needs. The presented approach is any time algorithm that has the advantage that it allows for the active creation of topological maps from laser scan data, as it is being acquired. We also propose a navigation strategy based on a heuristic where the robot is directed towards nodes in the topological map that open to empty space. We then extend the work in [1] by presenting a topology matching algorithm that leverages the strengths of a particular spectral correspondence method [2], to match the mapped environments generated from our topology-making algorithm. Here, we concentrated on implementing a system that could be used to match the topologies of the mapped environment by using AOF Skeletons. In topology matching between two given maps and their AOF skeletons, we first find correspondences between points on the AOF skeletons of two different environments. We then align the (2D) points of the environments themselves. We also compute a distance measure between two given environments, based on their extracted AOF skeletons and their topology, as the sum of the matching errors between corresponding points.

</p>
</details>

<details><summary><b>Investigating the usefulness of Quantum Blur</b>
<a href="https://arxiv.org/abs/2112.01646">arxiv:2112.01646</a>
&#x1F4C8; 4 <br>
<p>James R. Wootton, Marcel Pfaffhauser</p></summary>
<p>

**Abstract:** Though some years remain before quantum computation can outperform conventional computation, it already provides resources that be used for exploratory purposes in various fields. This includes certain tasks for procedural generation in computer games, music and art. The Quantum Blur method was introduced as a proof-of-principle example, to show that it can be useful to design methods for procedural generation using the principles of quantum software. Here we analyse the effects of the method and compare it to conventional blur effects. We also determine how the effects seen derive from the manipulation of quantum superposition and entanglement.

</p>
</details>

<details><summary><b>Zero-Shot Learning of Continuous 3D Refractive Index Maps from Discrete Intensity-Only Measurements</b>
<a href="https://arxiv.org/abs/2112.00002">arxiv:2112.00002</a>
&#x1F4C8; 4 <br>
<p>Renhao Liu, Yu Sun, Jiabei Zhu, Lei Tian, Ulugbek Kamilov</p></summary>
<p>

**Abstract:** Intensity diffraction tomography (IDT) refers to a class of optical microscopy techniques for imaging the 3D refractive index (RI) distribution of a sample from a set of 2D intensity-only measurements. The reconstruction of artifact-free RI maps is a fundamental challenge in IDT due to the loss of phase information and the missing cone problem. Neural fields (NF) has recently emerged as a new deep learning (DL) paradigm for learning continuous representations of complex 3D scenes without external training datasets. We present DeCAF as the first NF-based IDT method that can learn a high-quality continuous representation of a RI volume directly from its intensity-only and limited-angle measurements. We show on three different IDT modalities and multiple biological samples that DeCAF can generate high-contrast and artifact-free RI maps.

</p>
</details>

<details><summary><b>ORCHARD: A Benchmark For Measuring Systematic Generalization of Multi-Hierarchical Reasoning</b>
<a href="https://arxiv.org/abs/2111.14034">arxiv:2111.14034</a>
&#x1F4C8; 4 <br>
<p>Bill Tuck Weng Pung, Alvin Chan</p></summary>
<p>

**Abstract:** The ability to reason with multiple hierarchical structures is an attractive and desirable property of sequential inductive biases for natural language processing. Do the state-of-the-art Transformers and LSTM architectures implicitly encode for these biases? To answer this, we propose ORCHARD, a diagnostic dataset for systematically evaluating hierarchical reasoning in state-of-the-art neural sequence models. While there have been prior evaluation frameworks such as ListOps or Logical Inference, our work presents a novel and more natural setting where our models learn to reason with multiple explicit hierarchical structures instead of only one, i.e., requiring the ability to do both long-term sequence memorizing, relational reasoning while reasoning with hierarchical structure. Consequently, backed by a set of rigorous experiments, we show that (1) Transformer and LSTM models surprisingly fail in systematic generalization, and (2) with increased references between hierarchies, Transformer performs no better than random.

</p>
</details>

<details><summary><b>AI-supported Framework of Semi-Automatic Monoplotting for Monocular Oblique Visual Data Analysis</b>
<a href="https://arxiv.org/abs/2111.14021">arxiv:2111.14021</a>
&#x1F4C8; 4 <br>
<p>Behzad Golparvar, Ruo-Qian Wang</p></summary>
<p>

**Abstract:** In the last decades, the development of smartphones, drones, aerial patrols, and digital cameras enabled high-quality photographs available to large populations and, thus, provides an opportunity to collect massive data of the nature and society with global coverage. However, the data collected with new photography tools is usually oblique - they are difficult to be georeferenced, and huge amounts of data is often obsolete. Georeferencing oblique imagery data may be solved by a technique called monoplotting, which only requires a single image and Digital Elevation Model (DEM). In traditional monoplotting, a human user has to manually choose a series of ground control point (GCP) pairs in the image and DEM and then determine the extrinsic and intrinsic parameters of the camera to establish a pixel-level correspondence between photos and the DEM to enable the mapping and georeferencing of objects in photos. This traditional method is difficult to scale due to several challenges including the labor-intensive inputs, the need of rich experience to identify well-defined GCPs, and limitations in camera pose estimation. Therefore, existing monoplotting methods are rarely used in analyzing large-scale databases or near-real-time warning systems. In this paper, we propose and demonstrate a novel semi-automatic monoplotting framework that provides pixel-level correspondence between photos and DEMs requiring minimal human interventions. A pipeline of analyses was developed including key point detection in images and DEM rasters, retrieving georeferenced 3D DEM GCPs, regularized gradient-based optimization, pose estimation, ray tracing, and the correspondence identification between image pixels and real world coordinates. Two numerical experiments show that the framework is superior in georeferencing visual data in 3-D coordinates, paving a way toward fully automatic monoplotting methodology.

</p>
</details>

<details><summary><b>Benchmarking Accuracy and Generalizability of Four Graph Neural Networks Using Large In Vitro ADME Datasets from Different Chemical Spaces</b>
<a href="https://arxiv.org/abs/2111.13964">arxiv:2111.13964</a>
&#x1F4C8; 4 <br>
<p>Fabio Broccatelli, Richard Trager, Michael Reutlinger, George Karypis, Mufei Li</p></summary>
<p>

**Abstract:** In this work, we benchmark a variety of single- and multi-task graph neural network (GNN) models against lower-bar and higher-bar traditional machine learning approaches employing human engineered molecular features. We consider four GNN variants -- Graph Convolutional Network (GCN), Graph Attention Network (GAT), Message Passing Neural Network (MPNN), and Attentive Fingerprint (AttentiveFP). So far deep learning models have been primarily benchmarked using lower-bar traditional models solely based on fingerprints, while more realistic benchmarks employing fingerprints, whole-molecule descriptors and predictions from other related endpoints (e.g., LogD7.4) appear to be scarce for industrial ADME datasets. In addition to time-split test sets based on Genentech data, this study benefits from the availability of measurements from an external chemical space (Roche data). We identify GAT as a promising approach to implementing deep learning models. While all GNN models significantly outperform lower-bar benchmark traditional models solely based on fingerprints, only GATs seem to offer a small but consistent improvement over higher-bar benchmark traditional models. Finally, the accuracy of in vitro assays from different laboratories predicting the same experimental endpoints appears to be comparable with the accuracy of GAT single-task models, suggesting that most of the observed error from the models is a function of the experimental error propagation.

</p>
</details>

<details><summary><b>A Quantum-like Model for Predicting Human Decisions in the Entangled Social Systems</b>
<a href="https://arxiv.org/abs/2111.13902">arxiv:2111.13902</a>
&#x1F4C8; 4 <br>
<p>Aghdas. Meghdadi, M. R. Akbarzadeh-T., Kourosh Javidan</p></summary>
<p>

**Abstract:** Human-centered systems of systems such as social networks, Internet of Things, or healthcare systems are growingly becoming major facets of modern life. Realistic models of human behavior in such systems play a significant role in their accurate modeling and prediction. Yet, human behavior under uncertainty often violates the predictions by the conventional probabilistic models. Recently, quantum-like decision theories have shown a considerable potential to explain the contradictions in human behavior by applying quantum probability. But providing a quantum-like decision theory that could predict, rather than describe the current, state of human behavior is still one of the unsolved challenges. The main novelty of our approach is introducing an entangled Bayesian network inspired by the entanglement concept in quantum information theory, in which each human is a part of the entire society. Accordingly, society's effect on the dynamic evolution of the decision-making process, which is less often considered in decision theories, is modeled by the entanglement measures. The proposed predictive entangled quantum-like Bayesian network (PEQBN) is evaluated on 22 experimental tasks. Results confirm that PEQBN provides more realistic predictions of human decisions under uncertainty, when compared with classical Bayesian networks and three recent quantum-like approaches.

</p>
</details>

<details><summary><b>Temporal Context Mining for Learned Video Compression</b>
<a href="https://arxiv.org/abs/2111.13850">arxiv:2111.13850</a>
&#x1F4C8; 4 <br>
<p>Xihua Sheng, Jiahao Li, Bin Li, Li Li, Dong Liu, Yan Lu</p></summary>
<p>

**Abstract:** We address end-to-end learned video compression with a special focus on better learning and utilizing temporal contexts. For temporal context mining, we propose to store not only the previously reconstructed frames, but also the propagated features into the generalized decoded picture buffer. From the stored propagated features, we propose to learn multi-scale temporal contexts, and re-fill the learned temporal contexts into the modules of our compression scheme, including the contextual encoder-decoder, the frame generator, and the temporal context encoder. Our scheme discards the parallelization-unfriendly auto-regressive entropy model to pursue a more practical decoding time. We compare our scheme with x264 and x265 (representing industrial software for H.264 and H.265, respectively) as well as the official reference software for H.264, H.265, and H.266 (JM, HM, and VTM, respectively). When intra period is 32 and oriented to PSNR, our scheme outperforms H.265--HM by 14.4% bit rate saving; when oriented to MS-SSIM, our scheme outperforms H.266--VTM by 21.1% bit rate saving.

</p>
</details>

<details><summary><b>Towards Principled Disentanglement for Domain Generalization</b>
<a href="https://arxiv.org/abs/2111.13839">arxiv:2111.13839</a>
&#x1F4C8; 4 <br>
<p>Hanlin Zhang, Yi-Fan Zhang, Weiyang Liu, Adrian Weller, Bernhard Schölkopf, Eric P. Xing</p></summary>
<p>

**Abstract:** A fundamental challenge for machine learning models is generalizing to out-of-distribution (OOD) data, in part due to spurious correlations. To tackle this challenge, we first formalize the OOD generalization problem as constrained optimization, called Disentanglement-constrained Domain Generalization (DDG). We relax this non-trivial constrained optimization to a tractable form with finite-dimensional parameterization and empirical approximation. Then a theoretical analysis of the extent to which the above transformations deviates from the original problem is provided. Based on the transformation, we propose a primal-dual algorithm for joint representation disentanglement and domain generalization. In contrast to traditional approaches based on domain adversarial training and domain labels, DDG jointly learns semantic and variation encoders for disentanglement, enabling flexible manipulation and augmentation on training data. DDG aims to learn intrinsic representations of semantic concepts that are invariant to nuisance factors and generalizable across different domains. Comprehensive experiments on popular benchmarks show that DDG can achieve competitive OOD performance and uncover interpretable salient structures within data.

</p>
</details>

<details><summary><b>On Learning Domain-Invariant Representations for Transfer Learning with Multiple Sources</b>
<a href="https://arxiv.org/abs/2111.13822">arxiv:2111.13822</a>
&#x1F4C8; 4 <br>
<p>Trung Phung, Trung Le, Long Vuong, Toan Tran, Anh Tran, Hung Bui, Dinh Phung</p></summary>
<p>

**Abstract:** Domain adaptation (DA) benefits from the rigorous theoretical works that study its insightful characteristics and various aspects, e.g., learning domain-invariant representations and its trade-off. However, it seems not the case for the multiple source DA and domain generalization (DG) settings which are remarkably more complicated and sophisticated due to the involvement of multiple source domains and potential unavailability of target domain during training. In this paper, we develop novel upper-bounds for the target general loss which appeal to us to define two kinds of domain-invariant representations. We further study the pros and cons as well as the trade-offs of enforcing learning each domain-invariant representation. Finally, we conduct experiments to inspect the trade-off of these representations for offering practical hints regarding how to use them in practice and explore other interesting properties of our developed theory.

</p>
</details>

<details><summary><b>FastTrees: Parallel Latent Tree-Induction for Faster Sequence Encoding</b>
<a href="https://arxiv.org/abs/2111.14031">arxiv:2111.14031</a>
&#x1F4C8; 3 <br>
<p>Bill Tuck Weng Pung, Alvin Chan</p></summary>
<p>

**Abstract:** Inducing latent tree structures from sequential data is an emerging trend in the NLP research landscape today, largely popularized by recent methods such as Gumbel LSTM and Ordered Neurons (ON-LSTM). This paper proposes FASTTREES, a new general purpose neural module for fast sequence encoding. Unlike most previous works that consider recurrence to be necessary for tree induction, our work explores the notion of parallel tree induction, i.e., imbuing our model with hierarchical inductive biases in a parallelizable, non-autoregressive fashion. To this end, our proposed FASTTREES achieves competitive or superior performance to ON-LSTM on four well-established sequence modeling tasks, i.e., language modeling, logical inference, sentiment analysis and natural language inference. Moreover, we show that the FASTTREES module can be applied to enhance Transformer models, achieving performance gains on three sequence transduction tasks (machine translation, subject-verb agreement and mathematical language understanding), paving the way for modular tree induction modules. Overall, we outperform existing state-of-the-art models on logical inference tasks by +4% and mathematical language understanding by +8%.

</p>
</details>

<details><summary><b>Factor-augmented tree ensembles</b>
<a href="https://arxiv.org/abs/2111.14000">arxiv:2111.14000</a>
&#x1F4C8; 3 <br>
<p>Filippo Pellegrino</p></summary>
<p>

**Abstract:** This article proposes an extension for standard time-series regression tree modelling to handle predictors that show irregularities such as missing observations, periodic patterns in the form of seasonality and cycles, and non-stationary trends. In doing so, this approach permits also to enrich the information set used in tree-based autoregressions via unobserved components. Furthermore, this manuscript also illustrates a relevant approach to control over-fitting based on ensemble learning and recent developments in the jackknife literature. This is strongly beneficial when the number of observed time periods is small and advantageous compared to benchmark resampling methods. Empirical results show the benefits of predicting equity squared returns as a function of their own past and a set of macroeconomic data via factor-augmented tree ensembles, with respect to simpler benchmarks. As a by-product, this approach allows to study the real-time importance of economic news on equity volatility.

</p>
</details>

<details><summary><b>Language models in word sense disambiguation for Polish</b>
<a href="https://arxiv.org/abs/2111.13982">arxiv:2111.13982</a>
&#x1F4C8; 3 <br>
<p>Agnieszka Mykowiecka, Agnieszka A. Mykowiecka, Piotr Rychlik</p></summary>
<p>

**Abstract:** In the paper, we test two different approaches to the {unsupervised} word sense disambiguation task for Polish. In both methods, we use neural language models to predict words similar to those being disambiguated and, on the basis of these words, we predict the partition of word senses in different ways. In the first method, we cluster selected similar words, while in the second, we cluster vectors representing their subsets. The evaluation was carried out on texts annotated with plWordNet senses and provided a relatively good result (F1=0.68 for all ambiguous words). The results are significantly better than those obtained for the neural model-based unsupervised method proposed in \cite{waw:myk:17:Sense} and are at the level of the supervised method presented there. The proposed method may be a way of solving word sense disambiguation problem for languages that lack sense annotated data.

</p>
</details>

<details><summary><b>Learning A 3D-CNN and Transformer Prior for Hyperspectral Image Super-Resolution</b>
<a href="https://arxiv.org/abs/2111.13923">arxiv:2111.13923</a>
&#x1F4C8; 3 <br>
<p>Qing Ma, Junjun Jiang, Xianming Liu, Jiayi Ma</p></summary>
<p>

**Abstract:** To solve the ill-posed problem of hyperspectral image super-resolution (HSISR), an usually method is to use the prior information of the hyperspectral images (HSIs) as a regularization term to constrain the objective function. Model-based methods using hand-crafted priors cannot fully characterize the properties of HSIs. Learning-based methods usually use a convolutional neural network (CNN) to learn the implicit priors of HSIs. However, the learning ability of CNN is limited, it only considers the spatial characteristics of the HSIs and ignores the spectral characteristics, and convolution is not effective for long-range dependency modeling. There is still a lot of room for improvement. In this paper, we propose a novel HSISR method that uses Transformer instead of CNN to learn the prior of HSIs. Specifically, we first use the proximal gradient algorithm to solve the HSISR model, and then use an unfolding network to simulate the iterative solution processes. The self-attention layer of Transformer makes it have the ability of spatial global interaction. In addition, we add 3D-CNN behind the Transformer layers to better explore the spatio-spectral correlation of HSIs. Both quantitative and visual results on two widely used HSI datasets and the real-world dataset demonstrate that the proposed method achieves a considerable gain compared to all the mainstream algorithms including the most competitive conventional methods and the recently proposed deep learning-based methods.

</p>
</details>

<details><summary><b>A dual semismooth Newton based augmented Lagrangian method for large-scale linearly constrained sparse group square-root Lasso problems</b>
<a href="https://arxiv.org/abs/2111.13878">arxiv:2111.13878</a>
&#x1F4C8; 3 <br>
<p>Chengjing Wang, Peipei Tang</p></summary>
<p>

**Abstract:** Square-root Lasso problems are proven robust regression problems. Furthermore, square-root regression problems with structured sparsity also plays an important role in statistics and machine learning. In this paper, we focus on the numerical computation of large-scale linearly constrained sparse group square-root Lasso problems. In order to overcome the difficulty that there are two nonsmooth terms in the objective function, we propose a dual semismooth Newton (SSN) based augmented Lagrangian method (ALM) for it. That is, we apply the ALM to the dual problem with the subproblem solved by the SSN method. To apply the SSN method, the positive definiteness of the generalized Jacobian is very important. Hence we characterize the equivalence of its positive definiteness and the constraint nondegeneracy condition of the corresponding primal problem. In numerical implementation, we fully employ the second order sparsity so that the Newton direction can be efficiently obtained. Numerical experiments demonstrate the efficiency of the proposed algorithm.

</p>
</details>

<details><summary><b>AIS: A nonlinear activation function for industrial safety engineering</b>
<a href="https://arxiv.org/abs/2111.13861">arxiv:2111.13861</a>
&#x1F4C8; 3 <br>
<p>Zhenhua Wang, Beike Zhang, Dong Gao</p></summary>
<p>

**Abstract:** In the task of Chinese named entity recognition based on deep learning, activation function plays an irreplaceable role, it introduces nonlinear characteristics into neural network, so that the fitted model can be applied to various tasks. However, the information density of industrial safety analysis text is relatively high, and the correlation and similarity between the information are large, which is easy to cause the problem of high deviation and high standard deviation of the model, no specific activation function has been designed in previous studies, and the traditional activation function has the problems of gradient vanishing and negative region, which also lead to the recognition accuracy of the model can not be further improved. To solve these problems, a novel activation function AIS is proposed in this paper. AIS is an activation function applied in industrial safety engineering, which is composed of two piecewise nonlinear functions. In the positive region, the structure combining exponential function and quadratic function is used to alleviate the problem of deviation and standard deviation, and the linear function is added to modify it, which makes the whole activation function smoother and overcomes the problem of gradient vanishing. In the negative region, the cubic function structure is used to solve the negative region problem and accelerate the convergence of the model. Based on the deep learning model of BERT-BiLSTM-CRF, the performance of AIS is evaluated. The results show that, compared with other activation functions, AIS overcomes the problems of gradient vanishing and negative region, reduces the deviation of the model, speeds up the model fitting, and improves the extraction ability of the model for industrial entities.

</p>
</details>

<details><summary><b>Natural Language Processing in-and-for Design Research</b>
<a href="https://arxiv.org/abs/2111.13827">arxiv:2111.13827</a>
&#x1F4C8; 3 <br>
<p>L Siddharth, Lucienne T. M. Blessing, Jianxi Luo</p></summary>
<p>

**Abstract:** We review the scholarly contributions that utilise Natural Language Processing (NLP) methods to support the design process. Using a heuristic approach, we collected 223 articles published in 32 journals and within the period 1991-present. We present state-of-the-art NLP in-and-for design research by reviewing these articles according to the type of natural language text sources: internal reports, design concepts, discourse transcripts, technical publications, consumer opinions, and others. Upon summarizing and identifying the gaps in these contributions, we utilise an existing design innovation framework to identify the applications that are currently being supported by NLP. We then propose a few methodological and theoretical directions for future NLP in-and-for design research.

</p>
</details>

<details><summary><b>Neural Tangent Kernel of Matrix Product States: Convergence and Applications</b>
<a href="https://arxiv.org/abs/2111.14046">arxiv:2111.14046</a>
&#x1F4C8; 2 <br>
<p>Erdong Guo, David Draper</p></summary>
<p>

**Abstract:** In this work, we study the Neural Tangent Kernel (NTK) of Matrix Product States (MPS) and the convergence of its NTK in the infinite bond dimensional limit. We prove that the NTK of MPS asymptotically converges to a constant matrix during the gradient descent (training) process (and also the initialization phase) as the bond dimensions of MPS go to infinity by the observation that the variation of the tensors in MPS asymptotically goes to zero during training in the infinite limit. By showing the positive-definiteness of the NTK of MPS, the convergence of MPS during the training in the function space (space of functions represented by MPS) is guaranteed without any extra assumptions of the data set. We then consider the settings of (supervised) Regression with Mean Square Error (RMSE) and (unsupervised) Born Machines (BM) and analyze their dynamics in the infinite bond dimensional limit. The ordinary differential equations (ODEs) which describe the dynamics of the responses of MPS in the RMSE and BM are derived and solved in the closed-form. For the Regression, we consider Mercer Kernels (Gaussian Kernels) and find that the evolution of the mean of the responses of MPS follows the largest eigenvalue of the NTK. Due to the orthogonality of the kernel functions in BM, the evolution of different modes (samples) decouples and the "characteristic time" of convergence in training is obtained.

</p>
</details>

<details><summary><b>Deep Q-Learning based Reinforcement Learning Approach for Network Intrusion Detection</b>
<a href="https://arxiv.org/abs/2111.13978">arxiv:2111.13978</a>
&#x1F4C8; 2 <br>
<p>Hooman Alavizadeh, Julian Jang-Jaccard, Hootan Alavizadeh</p></summary>
<p>

**Abstract:** The rise of the new generation of cyber threats demands more sophisticated and intelligent cyber defense solutions equipped with autonomous agents capable of learning to make decisions without the knowledge of human experts. Several reinforcement learning methods (e.g., Markov) for automated network intrusion tasks have been proposed in recent years. In this paper, we introduce a new generation of network intrusion detection methods that combines a Q-learning-based reinforcement learning with a deep-feed forward neural network method for network intrusion detection. Our proposed Deep Q-Learning (DQL) model provides an ongoing auto-learning capability for a network environment that can detect different types of network intrusions using an automated trial-error approach and continuously enhance its detection capabilities. We provide the details of fine-tuning different hyperparameters involved in the DQL model for more effective self-learning. According to our extensive experimental results based on the NSL-KDD dataset, we confirm that the lower discount factor which is set as 0.001 under 250 episodes of training yields the best performance results. Our experimental results also show that our proposed DQL is highly effective in detecting different intrusion classes and outperforms other similar machine learning approaches.

</p>
</details>

<details><summary><b>Leveraging Unsupervised Learning to Summarize APIs Discussed in Stack Overflow</b>
<a href="https://arxiv.org/abs/2111.13962">arxiv:2111.13962</a>
&#x1F4C8; 2 <br>
<p>AmirHossein Naghshzan, Latifa Guerrouj, Olga Baysal</p></summary>
<p>

**Abstract:** Automated source code summarization is a task that generates summarized information about the purpose, usage, and--or implementation of methods and classes to support understanding of these code entities. Multiple approaches and techniques have been proposed for supervised and unsupervised learning in code summarization, however, they were mostly focused on generating a summary for a piece of code. In addition, very few works have leveraged unofficial documentation. This paper proposes an automatic and novel approach for summarizing Android API methods discussed in Stack Overflow that we consider as unofficial documentation in this research. Our approach takes the API method's name as an input and generates a natural language summary based on Stack Overflow discussions of that API method. We have conducted a survey that involves 16 Android developers to evaluate the quality of our automatically generated summaries and compare them with the official Android documentation. Our results demonstrate that while developers find the official documentation more useful in general, the generated summaries are also competitive, in particular for offering implementation details, and can be used as a complementary source for guiding developers in software development and maintenance tasks.

</p>
</details>

<details><summary><b>Transformed K-means Clustering</b>
<a href="https://arxiv.org/abs/2111.13921">arxiv:2111.13921</a>
&#x1F4C8; 2 <br>
<p>Anurag Goel, Angshul Majumdar</p></summary>
<p>

**Abstract:** In this work we propose a clustering framework based on the paradigm of transform learning. In simple terms the representation from transform learning is used for K-means clustering; however, the problem is not solved in such a naïve piecemeal fashion. The K-means clustering loss is embedded into the transform learning framework and the joint problem is solved using the alternating direction method of multipliers. Results on document clustering show that our proposed approach improves over the state-of-the-art.

</p>
</details>

<details><summary><b>ML-based Handover Prediction and AP Selection in Cognitive Wi-Fi Networks</b>
<a href="https://arxiv.org/abs/2111.13879">arxiv:2111.13879</a>
&#x1F4C8; 2 <br>
<p>Muhammad Asif Khan, Ridha Hamila, Adel Gastli, Serkan Kiranyaz, Nasser Ahmed Al-Emadi</p></summary>
<p>

**Abstract:** Device mobility in dense Wi-Fi networks offers several challenges. Two well-known problems related to device mobility are handover prediction and access point selection. Due to the complex nature of the radio environment, analytical models may not characterize the wireless channel, which makes the solution of these problems very difficult. Recently, cognitive network architectures using sophisticated learning techniques are increasingly being applied to such problems. In this paper, we propose a data-driven machine learning (ML) schemes to efficiently solve these problems in WLAN networks. The proposed schemes are evaluated and results are compared with traditional approaches to the aforementioned problems. The results report significant improvement in network performance by applying the proposed schemes. For instance, the proposed scheme for handover prediction outperforms traditional methods i.e. RSS method and traveling distance method by reducing the number of unnecessary handovers by 60% and 50% respectively. Similarly, in AP selection, the proposed scheme outperforms the SSF and LLF algorithms by achieving higher throughput gains upto 9.2% and 8% respectively.

</p>
</details>

<details><summary><b>Normative Disagreement as a Challenge for Cooperative AI</b>
<a href="https://arxiv.org/abs/2111.13872">arxiv:2111.13872</a>
&#x1F4C8; 2 <br>
<p>Julian Stastny, Maxime Riché, Alexander Lyzhov, Johannes Treutlein, Allan Dafoe, Jesse Clifton</p></summary>
<p>

**Abstract:** Cooperation in settings where agents have both common and conflicting interests (mixed-motive environments) has recently received considerable attention in multi-agent learning. However, the mixed-motive environments typically studied have a single cooperative outcome on which all agents can agree. Many real-world multi-agent environments are instead bargaining problems (BPs): they have several Pareto-optimal payoff profiles over which agents have conflicting preferences. We argue that typical cooperation-inducing learning algorithms fail to cooperate in BPs when there is room for normative disagreement resulting in the existence of multiple competing cooperative equilibria, and illustrate this problem empirically. To remedy the issue, we introduce the notion of norm-adaptive policies. Norm-adaptive policies are capable of behaving according to different norms in different circumstances, creating opportunities for resolving normative disagreement. We develop a class of norm-adaptive policies and show in experiments that these significantly increase cooperation. However, norm-adaptiveness cannot address residual bargaining failure arising from a fundamental tradeoff between exploitability and cooperative robustness.

</p>
</details>

<details><summary><b>Deep Learning with Multiple Data Set: A Weighted Goal Programming Approach</b>
<a href="https://arxiv.org/abs/2111.13834">arxiv:2111.13834</a>
&#x1F4C8; 2 <br>
<p>Marco Repetto, Davide La Torre, Muhammad Tariq</p></summary>
<p>

**Abstract:** Large-scale data analysis is growing at an exponential rate as data proliferates in our societies. This abundance of data has the advantage of allowing the decision-maker to implement complex models in scenarios that were prohibitive before. At the same time, such an amount of data requires a distributed thinking approach. In fact, Deep Learning models require plenty of resources, and distributed training is needed. This paper presents a Multicriteria approach for distributed learning. Our approach uses the Weighted Goal Programming approach in its Chebyshev formulation to build an ensemble of decision rules that optimize aprioristically defined performance metrics. Such a formulation is beneficial because it is both model and metric agnostic and provides an interpretable output for the decision-maker. We test our approach by showing a practical application in electricity demand forecasting. Our results suggest that when we allow for dataset split overlapping, the performances of our methodology are consistently above the baseline model trained on the whole dataset.

</p>
</details>

<details><summary><b>Understanding Anharmonic Effects on Hydrogen Desorption Characteristics of Mg$_n$H$_{2n}$ Nanoclusters by ab initio trained Deep Neural Network</b>
<a href="https://arxiv.org/abs/2111.13956">arxiv:2111.13956</a>
&#x1F4C8; 0 <br>
<p>Andrea Pedrielli, Paolo E. Trevisanutto, Lorenzo Monacelli, Giovanni Garberoglio, Nicola M. Pugno, Simone Taioli</p></summary>
<p>

**Abstract:** Magnesium hydride (MgH$_2$) has been widely studied for effective hydrogen storage. However, its bulk desorption temperature (553 K) is deemed too high for practical applications. Besides doping, a strategy to decrease such reaction energy for releasing hydrogen is the use of MgH$_2$-based nanoparticles (NPs). Here, we investigate first the thermodynamic properties of Mg$_n$H$_{2n}$ NPs ($n<10$) from first-principles, in particular by assessing the anharmonic effects on the enthalpy, entropy and thermal expansion by means of the Stochastic Self Consistent Harmonic Approximation (SSCHA). The latter method goes beyond previous approaches, typically based on molecular mechanics and the quasi-harmonic approximation, allowing the ab initio calculation of the fully-anharmonic free energy. We find an almost linear dependence on temperature of the interatomic bond lengths - with a relative variation of few percent over 300K -, alongside with a bond distance decrease of the Mg-H bonds. In order to increase the size of NPs toward experiments of hydrogen desorption from MgH$_2$ we devise a computationally effective Machine Learning model trained to accurately determine the forces and total energies (i.e. the potential energy surfaces), integrating the latter with the SSCHA model to fully include the anharmonic effects. We find a significative decrease of the H-desorption temperature for sub-nanometric clusters Mg$_n$H$_{2n}$ with $n \leq 10$, with a non-negligible, although little effect due to anharmonicities (up to 10%).

</p>
</details>


[Next Page]({{ '/2021/11/26/2021.11.26.html' | relative_url }})
