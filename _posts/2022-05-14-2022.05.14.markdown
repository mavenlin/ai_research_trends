Prev: [2022.05.13]({{ '/2022/05/13/2022.05.13.html' | relative_url }})  Next: [2022.05.15]({{ '/2022/05/15/2022.05.15.html' | relative_url }})
{% raw %}
## Summary for 2022-05-14, created on 2022-05-24


<details><summary><b>Cliff Diving: Exploring Reward Surfaces in Reinforcement Learning Environments</b>
<a href="https://arxiv.org/abs/2205.07015">arxiv:2205.07015</a>
&#x1F4C8; 1650 <br>
<p>Ryan Sullivan, J. K. Terry, Benjamin Black, John P. Dickerson</p></summary>
<p>

**Abstract:** Visualizing optimization landscapes has led to many fundamental insights in numeric optimization, and novel improvements to optimization techniques. However, visualizations of the objective that reinforcement learning optimizes (the "reward surface") have only ever been generated for a small number of narrow contexts. This work presents reward surfaces and related visualizations of 27 of the most widely used reinforcement learning environments in Gym for the first time. We also explore reward surfaces in the policy gradient direction and show for the first time that many popular reinforcement learning environments have frequent "cliffs" (sudden large drops in expected return). We demonstrate that A2C often "dives off" these cliffs into low reward regions of the parameter space while PPO avoids them, confirming a popular intuition for PPO's improved performance over previous methods. We additionally introduce a highly extensible library that allows researchers to easily generate these visualizations in the future. Our findings provide new intuition to explain the successes and failures of modern RL methods, and our visualizations concretely characterize several failure modes of reinforcement learning agents in novel ways.

</p>
</details>

<details><summary><b>ACCoRD: A Multi-Document Approach to Generating Diverse Descriptions of Scientific Concepts</b>
<a href="https://arxiv.org/abs/2205.06982">arxiv:2205.06982</a>
&#x1F4C8; 6 <br>
<p>Sonia K. Murthy, Kyle Lo, Daniel King, Chandra Bhagavatula, Bailey Kuehl, Sophie Johnson, Jonathan Borchardt, Daniel S. Weld, Tom Hope, Doug Downey</p></summary>
<p>

**Abstract:** Systems that can automatically define unfamiliar terms hold the promise of improving the accessibility of scientific texts, especially for readers who may lack prerequisite background knowledge. However, current systems assume a single "best" description per concept, which fails to account for the many potentially useful ways a concept can be described. We present ACCoRD, an end-to-end system tackling the novel task of generating sets of descriptions of scientific concepts. Our system takes advantage of the myriad ways a concept is mentioned across the scientific literature to produce distinct, diverse descriptions of target scientific concepts in terms of different reference concepts. To support research on the task, we release an expert-annotated resource, the ACCoRD corpus, which includes 1,275 labeled contexts and 1,787 hand-authored concept descriptions. We conduct a user study demonstrating that (1) users prefer descriptions produced by our end-to-end system, and (2) users prefer multiple descriptions to a single "best" description.

</p>
</details>

<details><summary><b>Learning Lip-Based Audio-Visual Speaker Embeddings with AV-HuBERT</b>
<a href="https://arxiv.org/abs/2205.07180">arxiv:2205.07180</a>
&#x1F4C8; 5 <br>
<p>Bowen Shi, Abdelrahman Mohamed, Wei-Ning Hsu</p></summary>
<p>

**Abstract:** This paper investigates self-supervised pre-training for audio-visual speaker representation learning where a visual stream showing the speaker's mouth area is used alongside speech as inputs. Our study focuses on the Audio-Visual Hidden Unit BERT (AV-HuBERT) approach, a recently developed general-purpose audio-visual speech pre-training framework. We conducted extensive experiments probing the effectiveness of pre-training and visual modality. Experimental results suggest that AV-HuBERT generalizes decently to speaker related downstream tasks, improving label efficiency by roughly ten fold for both audio-only and audio-visual speaker verification. We also show that incorporating visual information, even just the lip area, greatly improves the performance and noise robustness, reducing EER by 38% in the clean condition and 75% in noisy conditions. Our code and models will be publicly available.

</p>
</details>

<details><summary><b>GAN-Aimbots: Using Machine Learning for Cheating in First Person Shooters</b>
<a href="https://arxiv.org/abs/2205.07060">arxiv:2205.07060</a>
&#x1F4C8; 5 <br>
<p>Anssi Kanervisto, Tomi Kinnunen, Ville Hautamäki</p></summary>
<p>

**Abstract:** Playing games with cheaters is not fun, and in a multi-billion-dollar video game industry with hundreds of millions of players, game developers aim to improve the security and, consequently, the user experience of their games by preventing cheating. Both traditional software-based methods and statistical systems have been successful in protecting against cheating, but recent advances in the automatic generation of content, such as images or speech, threaten the video game industry; they could be used to generate artificial gameplay indistinguishable from that of legitimate human players. To better understand this threat, we begin by reviewing the current state of multiplayer video game cheating, and then proceed to build a proof-of-concept method, GAN-Aimbot. By gathering data from various players in a first-person shooter game we show that the method improves players' performance while remaining hidden from automatic and manual protection mechanisms. By sharing this work we hope to raise awareness on this issue and encourage further research into protecting the gaming communities.

</p>
</details>

<details><summary><b>Breaking with Fixed Set Pathology Recognition through Report-Guided Contrastive Training</b>
<a href="https://arxiv.org/abs/2205.07139">arxiv:2205.07139</a>
&#x1F4C8; 3 <br>
<p>Constantin Seibold, Simon Reiß, M. Saquib Sarfraz, Rainer Stiefelhagen, Jens Kleesiek</p></summary>
<p>

**Abstract:** When reading images, radiologists generate text reports describing the findings therein. Current state-of-the-art computer-aided diagnosis tools utilize a fixed set of predefined categories automatically extracted from these medical reports for training. This form of supervision limits the potential usage of models as they are unable to pick up on anomalies outside of their predefined set, thus, making it a necessity to retrain the classifier with additional data when faced with novel classes. In contrast, we investigate direct text supervision to break away from this closed set assumption. By doing so, we avoid noisy label extraction via text classifiers and incorporate more contextual information.
  We employ a contrastive global-local dual-encoder architecture to learn concepts directly from unstructured medical reports while maintaining its ability to perform free form classification.
  We investigate relevant properties of open set recognition for radiological data and propose a method to employ currently weakly annotated data into training.
  We evaluate our approach on the large-scale chest X-Ray datasets MIMIC-CXR, CheXpert, and ChestX-Ray14 for disease classification. We show that despite using unstructured medical report supervision, we perform on par with direct label supervision through a sophisticated inference setting.

</p>
</details>

<details><summary><b>Pattern reconstruction with restricted Boltzmann machines</b>
<a href="https://arxiv.org/abs/2205.07087">arxiv:2205.07087</a>
&#x1F4C8; 3 <br>
<p>Giuseppe Genovese</p></summary>
<p>

**Abstract:** We show that the ability of a restricted Boltzmann machine to reconstruct a random pattern depends on the tail of the hidden prior distribution: hidden priors with strictly sub-Gaussian tails give only a logarithmic loss in pattern retrieval, while an efficient retrieval is much harder with hidden units with strictly super-Gaussian tails; reconstruction with sub-Gaussian hidden prior is regulated by the number of hidden units (as in the Hopfield model). This is proved by localisation estimates for the local minima of the energy function.

</p>
</details>

<details><summary><b>PrefixRL: Optimization of Parallel Prefix Circuits using Deep Reinforcement Learning</b>
<a href="https://arxiv.org/abs/2205.07000">arxiv:2205.07000</a>
&#x1F4C8; 3 <br>
<p>Rajarshi Roy, Jonathan Raiman, Neel Kant, Ilyas Elkin, Robert Kirby, Michael Siu, Stuart Oberman, Saad Godil, Bryan Catanzaro</p></summary>
<p>

**Abstract:** In this work, we present a reinforcement learning (RL) based approach to designing parallel prefix circuits such as adders or priority encoders that are fundamental to high-performance digital design. Unlike prior methods, our approach designs solutions tabula rasa purely through learning with synthesis in the loop. We design a grid-based state-action representation and an RL environment for constructing legal prefix circuits. Deep Convolutional RL agents trained on this environment produce prefix adder circuits that Pareto-dominate existing baselines with up to 16.0% and 30.2% lower area for the same delay in the 32b and 64b settings respectively. We observe that agents trained with open-source synthesis tools and cell library can design adder circuits that achieve lower area and delay than commercial tool adders in an industrial cell library.

</p>
</details>

<details><summary><b>RiCS: A 2D Self-Occlusion Map for Harmonizing Volumetric Objects</b>
<a href="https://arxiv.org/abs/2205.06975">arxiv:2205.06975</a>
&#x1F4C8; 3 <br>
<p>Yunseok Jang, Ruben Villegas, Jimei Yang, Duygu Ceylan, Xin Sun, Honglak Lee</p></summary>
<p>

**Abstract:** There have been remarkable successes in computer vision with deep learning. While such breakthroughs show robust performance, there have still been many challenges in learning in-depth knowledge, like occlusion or predicting physical interactions. Although some recent works show the potential of 3D data in serving such context, it is unclear how we efficiently provide 3D input to the 2D models due to the misalignment in dimensionality between 2D and 3D. To leverage the successes of 2D models in predicting self-occlusions, we design Ray-marching in Camera Space (RiCS), a new method to represent the self-occlusions of foreground objects in 3D into a 2D self-occlusion map. We test the effectiveness of our representation on the human image harmonization task by predicting shading that is coherent with a given background image. Our experiments demonstrate that our representation map not only allows us to enhance the image quality but also to model temporally coherent complex shadow effects compared with the simulation-to-real and harmonization methods, both quantitatively and qualitatively. We further show that we can significantly improve the performance of human parts segmentation networks trained on existing synthetic datasets by enhancing the harmonization quality with our method.

</p>
</details>

<details><summary><b>Trajectory Inference via Mean-field Langevin in Path Space</b>
<a href="https://arxiv.org/abs/2205.07146">arxiv:2205.07146</a>
&#x1F4C8; 2 <br>
<p>Lénaïc Chizat, Stephen Zhang, Matthieu Heitz, Geoffrey Schiebinger</p></summary>
<p>

**Abstract:** Trajectory inference aims at recovering the dynamics of a population from snapshots of its temporal marginals. To solve this task, a min-entropy estimator relative to the Wiener measure in path space was introduced by Lavenant et al. arXiv:2102.09204, and shown to consistently recover the dynamics of a large class of drift-diffusion processes from the solution of an infinite dimensional convex optimization problem. In this paper, we introduce a grid-free algorithm to compute this estimator. Our method consists in a family of point clouds (one per snapshot) coupled via Schrödinger bridges which evolve with noisy gradient descent. We study the mean-field limit of the dynamics and prove its global convergence at an exponential rate to the desired estimator. Overall, this leads to an inference method with end-to-end theoretical guarantees that solves an interpretable model for trajectory inference. We also present how to adapt the method to deal with mass variations, a useful extension when dealing with single cell RNA-sequencing data where cells can branch and die.

</p>
</details>

<details><summary><b>Robust Regularized Low-Rank Matrix Models for Regression and Classification</b>
<a href="https://arxiv.org/abs/2205.07106">arxiv:2205.07106</a>
&#x1F4C8; 2 <br>
<p>Hsin-Hsiung Huang, Feng Yu, Xing Fan, Teng Zhang</p></summary>
<p>

**Abstract:** While matrix variate regression models have been studied in many existing works, classical statistical and computational methods for the analysis of the regression coefficient estimation are highly affected by high dimensional and noisy matrix-valued predictors. To address these issues, this paper proposes a framework of matrix variate regression models based on a rank constraint, vector regularization (e.g., sparsity), and a general loss function with three special cases considered: ordinary matrix regression, robust matrix regression, and matrix logistic regression. We also propose an alternating projected gradient descent algorithm. Based on analyzing our objective functions on manifolds with bounded curvature, we show that the algorithm is guaranteed to converge, all accumulation points of the iterates have estimation errors in the order of $O(1/\sqrt{n})$ asymptotically and substantially attaining the minimax rate. Our theoretical analysis can be applied to general optimization problems on manifolds with bounded curvature and can be considered an important technical contribution to this work. We validate the proposed method through simulation studies and real image data examples.

</p>
</details>

<details><summary><b>Evolutionary optimization of the Verlet closure relation for the hard-sphere and square-well fluids</b>
<a href="https://arxiv.org/abs/2205.07104">arxiv:2205.07104</a>
&#x1F4C8; 2 <br>
<p>Edwin Bedolla, Luis Carlos Padierna, Ramón Castañeda-Priego</p></summary>
<p>

**Abstract:** The Ornstein-Zernike equation is solved for the hard-sphere and square-well fluids using a diverse selection of closure relations; the attraction range of the square-well is chosen to be $λ=1.5.$ In particular, for both fluids we mainly focus on the solution based on a three-parameter version of the Verlet closure relation [Mol. Phys. 42, 1291-1302 (1981)]. To find the free parameters of the latter, an unconstrained optimization problem is defined as a condition of thermodynamic consistency based on the compressibility and solved using Evolutionary Algorithms. For the hard-sphere fluid, the results show good agreement when compared with mean-field equations of state and accurate computer simulation results; at high densities, i.e., close to the freezing transition, expected (small) deviations are seen. In the case of the square-well fluid, a good agreement is observed at low and high densities when compared with event-driven molecular dynamics computer simulations. For intermediate densities, the explored closure relations vary in terms of accuracy. Our findings suggest that a modification of the optimization problem to include, for example, additional thermodynamic consistency criteria could improve the results for the type of fluids here explored.

</p>
</details>

<details><summary><b>Multiformer: A Head-Configurable Transformer-Based Model for Direct Speech Translation</b>
<a href="https://arxiv.org/abs/2205.07100">arxiv:2205.07100</a>
&#x1F4C8; 2 <br>
<p>Gerard Sant, Gerard I. Gállego, Belen Alastruey, Marta R. Costa-Jussà</p></summary>
<p>

**Abstract:** Transformer-based models have been achieving state-of-the-art results in several fields of Natural Language Processing. However, its direct application to speech tasks is not trivial. The nature of this sequences carries problems such as long sequence lengths and redundancy between adjacent tokens. Therefore, we believe that regular self-attention mechanism might not be well suited for it.
  Different approaches have been proposed to overcome these problems, such as the use of efficient attention mechanisms. However, the use of these methods usually comes with a cost, which is a performance reduction caused by information loss. In this study, we present the Multiformer, a Transformer-based model which allows the use of different attention mechanisms on each head. By doing this, the model is able to bias the self-attention towards the extraction of more diverse token interactions, and the information loss is reduced. Finally, we perform an analysis of the head contributions, and we observe that those architectures where all heads relevance is uniformly distributed obtain better results. Our results show that mixing attention patterns along the different heads and layers outperforms our baseline by up to 0.7 BLEU.

</p>
</details>

<details><summary><b>GoalNet: Inferring Conjunctive Goal Predicates from Human Plan Demonstrations for Robot Instruction Following</b>
<a href="https://arxiv.org/abs/2205.07081">arxiv:2205.07081</a>
&#x1F4C8; 2 <br>
<p>Shreya Sharma, Jigyasa Gupta, Shreshth Tuli, Rohan Paul,  Mausam</p></summary>
<p>

**Abstract:** Our goal is to enable a robot to learn how to sequence its actions to perform tasks specified as natural language instructions, given successful demonstrations from a human partner. The ability to plan high-level tasks can be factored as (i) inferring specific goal predicates that characterize the task implied by a language instruction for a given world state and (ii) synthesizing a feasible goal-reaching action-sequence with such predicates. For the former, we leverage a neural network prediction model, while utilizing a symbolic planner for the latter. We introduce a novel neuro-symbolic model, GoalNet, for contextual and task dependent inference of goal predicates from human demonstrations and linguistic task descriptions. GoalNet combines (i) learning, where dense representations are acquired for language instruction and the world state that enables generalization to novel settings and (ii) planning, where the cause-effect modeling by the symbolic planner eschews irrelevant predicates facilitating multi-stage decision making in large domains. GoalNet demonstrates a significant improvement (51%) in the task completion rate in comparison to a state-of-the-art rule-based approach on a benchmark data set displaying linguistic variations, particularly for multi-stage instructions.

</p>
</details>

<details><summary><b>SaiNet: Stereo aware inpainting behind objects with generative networks</b>
<a href="https://arxiv.org/abs/2205.07014">arxiv:2205.07014</a>
&#x1F4C8; 2 <br>
<p>Violeta Menéndez González, Andrew Gilbert, Graeme Phillipson, Stephen Jolly, Simon Hadfield</p></summary>
<p>

**Abstract:** In this work, we present an end-to-end network for stereo-consistent image inpainting with the objective of inpainting large missing regions behind objects. The proposed model consists of an edge-guided UNet-like network using Partial Convolutions. We enforce multi-view stereo consistency by introducing a disparity loss. More importantly, we develop a training scheme where the model is learned from realistic stereo masks representing object occlusions, instead of the more common random masks. The technique is trained in a supervised way. Our evaluation shows competitive results compared to previous state-of-the-art techniques.

</p>
</details>

<details><summary><b>On Evaluating Power Loss with HATSGA Algorithm for Power Network Reconfiguration in the Smart Grid</b>
<a href="https://arxiv.org/abs/2205.10126">arxiv:2205.10126</a>
&#x1F4C8; 1 <br>
<p>Flavio Galvao Calhau, Alysson Pezzutti, Joberto S. B. Martins</p></summary>
<p>

**Abstract:** This paper presents the power network reconfiguration algorithm HATSGA with a "R" modeling approach and evaluates its behavior in computing new reconfiguration topologies for the power network in the Smart Grid context. The modeling of the power distribution network with the language "R" is used to represent the network and support the computation of distinct algorithm configurations towards the evaluation of new reconfiguration topologies. The HATSGA algorithm adopts a hybrid Tabu Search and Genetic Algorithm strategy and can be configured in different ways to compute network reconfiguration solutions. The evaluation of power loss with HATSGA uses the IEEE 14-Bus topology as the power test scenario. The evaluation of reconfiguration topologies with minimum power loss with HATSGA indicates that an efficient solution can be reached with a feasible computational time. This suggests that HATSGA can be potentially used for computing reconfiguration network topologies and, beyond that, it can be used for autonomic self-healing management approaches where a feasible computational time is required.

</p>
</details>

<details><summary><b>Proxyless Neural Architecture Adaptation for Supervised Learning and Self-Supervised Learning</b>
<a href="https://arxiv.org/abs/2205.07168">arxiv:2205.07168</a>
&#x1F4C8; 1 <br>
<p>Do-Guk Kim, Heung-Chang Lee</p></summary>
<p>

**Abstract:** Recently, Neural Architecture Search (NAS) methods have been introduced and show impressive performance on many benchmarks. Among those NAS studies, Neural Architecture Transformer (NAT) aims to adapt the given neural architecture to improve performance while maintaining computational costs. However, NAT lacks reproducibility and it requires an additional architecture adaptation process before network weight training. In this paper, we propose proxyless neural architecture adaptation that is reproducible and efficient. Our method can be applied to both supervised learning and self-supervised learning. The proposed method shows stable performance on various architectures. Extensive reproducibility experiments on two datasets, i.e., CIFAR-10 and Tiny Imagenet, present that the proposed method definitely outperforms NAT and is applicable to other models and datasets.

</p>
</details>

<details><summary><b>From Cognitive to Computational Modeling: Text-based Risky Decision-Making Guided by Fuzzy Trace Theory</b>
<a href="https://arxiv.org/abs/2205.07164">arxiv:2205.07164</a>
&#x1F4C8; 1 <br>
<p>Jaron Mar, Jiamou Liu</p></summary>
<p>

**Abstract:** Understanding, modelling and predicting human risky decision-making is challenging due to intrinsic individual differences and irrationality. Fuzzy trace theory (FTT) is a powerful paradigm that explains human decision-making by incorporating gists, i.e., fuzzy representations of information which capture only its quintessential meaning. Inspired by Broniatowski and Reyna's FTT cognitive model, we propose a computational framework which combines the effects of the underlying semantics and sentiments on text-based decision-making. In particular, we introduce Category-2-Vector to learn categorical gists and categorical sentiments, and demonstrate how our computational model can be optimised to predict risky decision-making in groups and individuals.

</p>
</details>

<details><summary><b>Interpretable Stochastic Model Predictive Control using Distributional Reinforced Estimation for Quadrotor Tracking Systems</b>
<a href="https://arxiv.org/abs/2205.07150">arxiv:2205.07150</a>
&#x1F4C8; 1 <br>
<p>Yanran Wang, James O'Keeffe, Qiuchen Qian, David Boyle</p></summary>
<p>

**Abstract:** This paper presents a novel trajectory tracker for autonomous quadrotor navigation in dynamic and complex environments. The proposed framework integrates a distributional Reinforcement Learning (RL) estimator for unknown aerodynamic effects into a Stochastic Model Predictive Controller (SMPC) for trajectory tracking. Aerodynamic effects derived from drag forces and moment variations are difficult to model directly and accurately. Most current quadrotor tracking systems therefore treat them as simple `disturbances' in conventional control approaches. We propose Quantile-approximation-based Distributional Reinforced-disturbance-estimator, an aerodynamic disturbance estimator, to accurately identify disturbances, i.e., uncertainties between the true and estimated values of aerodynamic effects. Simplified Affine Disturbance Feedback is employed for control parameterization to guarantee convexity, which we then integrate with a SMPC to achieve sufficient and non-conservative control signals. We demonstrate our system to improve the cumulative tracking errors by at least 66% with unknown and diverse aerodynamic forces compared with recent state-of-the-art. Concerning traditional Reinforcement Learning's non-interpretability, we provide convergence and stability guarantees of Distributional RL and SMPC, respectively, with non-zero mean disturbances.

</p>
</details>

<details><summary><b>Classification of Astronomical Bodies by Efficient Layer Fine-Tuning of Deep Neural Networks</b>
<a href="https://arxiv.org/abs/2205.07124">arxiv:2205.07124</a>
&#x1F4C8; 1 <br>
<p>Sabeesh Ethiraj, Bharath Kumar Bolla</p></summary>
<p>

**Abstract:** The SDSS-IV dataset contains information about various astronomical bodies such as Galaxies, Stars, and Quasars captured by observatories. Inspired by our work on deep multimodal learning, which utilized transfer learning to classify the SDSS-IV dataset, we further extended our research in the fine tuning of these architectures to study the effect in the classification scenario. Architectures such as Resnet-50, DenseNet-121 VGG-16, Xception, EfficientNetB2, MobileNetV2 and NasnetMobile have been built using layer wise fine tuning at different levels. Our findings suggest that freezing all layers with Imagenet weights and adding a final trainable layer may not be the optimal solution. Further, baseline models and models that have higher number of trainable layers performed similarly in certain architectures. Model need to be fine tuned at different levels and a specific training ratio is required for a model to be termed ideal. Different architectures had different responses to the change in the number of trainable layers w.r.t accuracies. While models such as DenseNet-121, Xception, EfficientNetB2 achieved peak accuracies that were relatively consistent with near perfect training curves, models such as Resnet-50,VGG-16, MobileNetV2 and NasnetMobile had lower, delayed peak accuracies with poorly fitting training curves. It was also found that though mobile neural networks have lesser parameters and model size, they may not always be ideal for deployment on a low computational device as they had consistently lower validation accuracies. Customized evaluation metrics such as Tuning Parameter Ratio and Tuning Layer Ratio are used for model evaluation.

</p>
</details>

<details><summary><b>Revisiting Facial Key Point Detection: An Efficient Approach Using Deep Neural Networks</b>
<a href="https://arxiv.org/abs/2205.07121">arxiv:2205.07121</a>
&#x1F4C8; 1 <br>
<p>Prathima Dileep, Bharath Kumar Bolla, Sabeesh Ethiraj</p></summary>
<p>

**Abstract:** Facial landmark detection is a widely researched field of deep learning as this has a wide range of applications in many fields. These key points are distinguishing characteristic points on the face, such as the eyes center, the eye's inner and outer corners, the mouth center, and the nose tip from which human emotions and intent can be explained. The focus of our work has been evaluating transfer learning models such as MobileNetV2 and NasNetMobile, including custom CNN architectures. The objective of the research has been to develop efficient deep learning models in terms of model size, parameters, and inference time and to study the effect of augmentation imputation and fine-tuning on these models. It was found that while augmentation techniques produced lower RMSE scores than imputation techniques, they did not affect the inference time. MobileNetV2 architecture produced the lowest RMSE and inference time. Moreover, our results indicate that manually optimized CNN architectures performed similarly to Auto Keras tuned architecture. However, manually optimized architectures yielded better inference time and training curves.

</p>
</details>

<details><summary><b>Efficient Deep Learning Methods for Identification of Defective Casting Products</b>
<a href="https://arxiv.org/abs/2205.07118">arxiv:2205.07118</a>
&#x1F4C8; 1 <br>
<p>Bharath Kumar Bolla, Mohan Kingam, Sabeesh Ethiraj</p></summary>
<p>

**Abstract:** Quality inspection has become crucial in any large-scale manufacturing industry recently. In order to reduce human error, it has become imperative to use efficient and low computational AI algorithms to identify such defective products. In this paper, we have compared and contrasted various pre-trained and custom-built architectures using model size, performance and CPU latency in the detection of defective casting products. Our results show that custom architectures are efficient than pre-trained mobile architectures. Moreover, custom models perform 6 to 9 times faster than lightweight models such as MobileNetV2 and NasNet. The number of training parameters and the model size of the custom architectures is significantly lower (~386 times & ~119 times respectively) than the best performing models such as MobileNetV2 and NasNet. Augmentation experimentations have also been carried out on the custom architectures to make the models more robust and generalizable. Our work sheds light on the efficiency of these custom-built architectures for deployment on Edge and IoT devices and that transfer learning models may not always be ideal. Instead, they should be specific to the kind of dataset and the classification problem at hand.

</p>
</details>

<details><summary><b>Spiking Approximations of the MaxPooling Operation in Deep SNNs</b>
<a href="https://arxiv.org/abs/2205.07076">arxiv:2205.07076</a>
&#x1F4C8; 1 <br>
<p>Ramashish Gaurav, Bryan Tripp, Apurva Narayan</p></summary>
<p>

**Abstract:** Spiking Neural Networks (SNNs) are an emerging domain of biologically inspired neural networks that have shown promise for low-power AI. A number of methods exist for building deep SNNs, with Artificial Neural Network (ANN)-to-SNN conversion being highly successful. MaxPooling layers in Convolutional Neural Networks (CNNs) are an integral component to downsample the intermediate feature maps and introduce translational invariance, but the absence of their hardware-friendly spiking equivalents limits such CNNs' conversion to deep SNNs. In this paper, we present two hardware-friendly methods to implement Max-Pooling in deep SNNs, thus facilitating easy conversion of CNNs with MaxPooling layers to SNNs. In a first, we also execute SNNs with spiking-MaxPooling layers on Intel's Loihi neuromorphic hardware (with MNIST, FMNIST, & CIFAR10 dataset); thus, showing the feasibility of our approach.

</p>
</details>

<details><summary><b>A Unifying Multi-sampling-ratio CS-MRI Framework With Two-grid-cycle Correction and Geometric Prior Distillation</b>
<a href="https://arxiv.org/abs/2205.07062">arxiv:2205.07062</a>
&#x1F4C8; 1 <br>
<p>Xiaohong Fan, Yin Yang, Ke Chen, Jianping Zhang, Ke Dong</p></summary>
<p>

**Abstract:** CS is an efficient method to accelerate the acquisition of MR images from under-sampled k-space data. Although existing deep learning CS-MRI methods have achieved considerably impressive performance, explainability and generalizability continue to be challenging for such methods since most of them are not flexible enough to handle multi-sampling-ratio reconstruction assignments, often the transition from mathematical analysis to network design not always natural enough. In this work, to tackle explainability and generalizability, we propose a unifying deep unfolding multi-sampling-ratio CS-MRI framework, by merging advantages of model-based and deep learning-based methods. The combined approach offers more generalizability than previous works whereas deep learning gains explainability through a geometric prior module. Inspired by multigrid algorithm, we first embed the CS-MRI-based optimization algorithm into correction-distillation scheme that consists of three ingredients: pre-relaxation module, correction module and geometric prior distillation module. Furthermore, we employ a condition module to learn adaptively step-length and noise level from compressive sampling ratio in every stage, which enables the proposed framework to jointly train multi-ratio tasks through a single model. The proposed model can not only compensate the lost contextual information of reconstructed image which is refined from low frequency error in geometric characteristic k-space, but also integrate the theoretical guarantee of model-based methods and the superior reconstruction performances of deep learning-based methods. All physical-model parameters are learnable, and numerical experiments show that our framework outperforms state-of-the-art methods in terms of qualitative and quantitative evaluations.

</p>
</details>

<details><summary><b>Generalization error bounds for DECONET: a deep unfolded network for analysis Compressive Sensing</b>
<a href="https://arxiv.org/abs/2205.07050">arxiv:2205.07050</a>
&#x1F4C8; 1 <br>
<p>Vasiliki Kouni</p></summary>
<p>

**Abstract:** In this paper, we propose a new deep unfolding neural network -- based on a state-of-the-art optimization algorithm -- for analysis Compressed Sensing. The proposed network called Decoding Network (DECONET) implements a decoder that reconstructs vectors from their incomplete, noisy measurements. Moreover, DECONET jointly learns a redundant analysis operator for sparsification, which is shared across the layers of DECONET. We study the generalization ability of DECONET. Towards that end, we first estimate the Rademacher complexity of the hypothesis class consisting of all the decoders that DECONET can implement. Then, we provide generalization error bounds, in terms of the aforementioned estimate. Finally, we present numerical experiments which confirm the validity of our theoretical results.

</p>
</details>

<details><summary><b>Self-supervised Assisted Active Learning for Skin Lesion Segmentation</b>
<a href="https://arxiv.org/abs/2205.07021">arxiv:2205.07021</a>
&#x1F4C8; 1 <br>
<p>Ziyuan Zhao, Wenjing Lu, Zeng Zeng, Kaixin Xu, Bharadwaj Veeravalli, Cuntai Guan</p></summary>
<p>

**Abstract:** Label scarcity has been a long-standing issue for biomedical image segmentation, due to high annotation costs and professional requirements. Recently, active learning (AL) strategies strive to reduce annotation costs by querying a small portion of data for annotation, receiving much traction in the field of medical imaging. However, most of the existing AL methods have to initialize models with some randomly selected samples followed by active selection based on various criteria, such as uncertainty and diversity. Such random-start initialization methods inevitably introduce under-value redundant samples and unnecessary annotation costs. For the purpose of addressing the issue, we propose a novel self-supervised assisted active learning framework in the cold-start setting, in which the segmentation model is first warmed up with self-supervised learning (SSL), and then SSL features are used for sample selection via latent feature clustering without accessing labels. We assess our proposed methodology on skin lesions segmentation task. Extensive experiments demonstrate that our approach is capable of achieving promising performance with substantial improvements over existing baselines.

</p>
</details>

<details><summary><b>Verifying Neural Networks Against Backdoor Attacks</b>
<a href="https://arxiv.org/abs/2205.06992">arxiv:2205.06992</a>
&#x1F4C8; 1 <br>
<p>Long H. Pham, Jun Sun</p></summary>
<p>

**Abstract:** Neural networks have achieved state-of-the-art performance in solving many problems, including many applications in safety/security-critical systems. Researchers also discovered multiple security issues associated with neural networks. One of them is backdoor attacks, i.e., a neural network may be embedded with a backdoor such that a target output is almost always generated in the presence of a trigger. Existing defense approaches mostly focus on detecting whether a neural network is 'backdoored' based on heuristics, e.g., activation patterns. To the best of our knowledge, the only line of work which certifies the absence of backdoor is based on randomized smoothing, which is known to significantly reduce neural network performance. In this work, we propose an approach to verify whether a given neural network is free of backdoor with a certain level of success rate. Our approach integrates statistical sampling as well as abstract interpretation. The experiment results show that our approach effectively verifies the absence of backdoor or generates backdoor triggers.

</p>
</details>

<details><summary><b>Evaluating Membership Inference Through Adversarial Robustness</b>
<a href="https://arxiv.org/abs/2205.06986">arxiv:2205.06986</a>
&#x1F4C8; 1 <br>
<p>Zhaoxi Zhang, Leo Yu Zhang, Xufei Zheng, Bilal Hussain Abbasi, Shengshan Hu</p></summary>
<p>

**Abstract:** The usage of deep learning is being escalated in many applications. Due to its outstanding performance, it is being used in a variety of security and privacy-sensitive areas in addition to conventional applications. One of the key aspects of deep learning efficacy is to have abundant data. This trait leads to the usage of data which can be highly sensitive and private, which in turn causes wariness with regard to deep learning in the general public. Membership inference attacks are considered lethal as they can be used to figure out whether a piece of data belongs to the training dataset or not. This can be problematic with regards to leakage of training data information and its characteristics. To highlight the significance of these types of attacks, we propose an enhanced methodology for membership inference attacks based on adversarial robustness, by adjusting the directions of adversarial perturbations through label smoothing under a white-box setting. We evaluate our proposed method on three datasets: Fashion-MNIST, CIFAR-10, and CIFAR-100. Our experimental results reveal that the performance of our method surpasses that of the existing adversarial robustness-based method when attacking normally trained models. Additionally, through comparing our technique with the state-of-the-art metric-based membership inference methods, our proposed method also shows better performance when attacking adversarially trained models. The code for reproducing the results of this work is available at \url{https://github.com/plll4zzx/Evaluating-Membership-Inference-Through-Adversarial-Robustness}.

</p>
</details>

<details><summary><b>RASAT: Integrating Relational Structures into Pretrained Seq2Seq Model for Text-to-SQL</b>
<a href="https://arxiv.org/abs/2205.06983">arxiv:2205.06983</a>
&#x1F4C8; 1 <br>
<p>Jiexing Qi, Jingyao Tang, Ziwei He, Xiangpeng Wan, Chenghu Zhou, Xinbing Wang, Quanshi Zhang, Zhouhan Lin</p></summary>
<p>

**Abstract:** Relational structures such as schema linking and schema encoding have been validated as a key component to qualitatively translating natural language into SQL queries. However, introducing these structural relations comes with prices: they often result in a specialized model structure, which largely prohibits the use of large pretrained models in text-to-SQL. To address this problem, we propose RASAT: a Transformer seq2seq architecture augmented with relation-aware self-attention that could leverage a variety of relational structures while at the meantime being able to effectively inherit the pretrained parameters from the T5 model. Our model is able to incorporate almost all types of existing relations in the literature, and in addition, we propose to introduce co-reference relations for the multi-turn scenario. Experimental results on three widely used text-to-SQL datasets, covering both single-turn and multi-turn scenarios, have shown that RASAT could achieve competitive results in all three benchmarks, achieving state-of-the-art performance in execution accuracy (80.5\% EX on Spider, 53.1\% IEX on SParC, and 37.5\% IEX on CoSQL).

</p>
</details>

<details><summary><b>BackLink: Supervised Local Training with Backward Links</b>
<a href="https://arxiv.org/abs/2205.07141">arxiv:2205.07141</a>
&#x1F4C8; 0 <br>
<p>Wenzhe Guo, Mohammed E Fouda, Ahmed M. Eltawil, Khaled N. Salama</p></summary>
<p>

**Abstract:** Empowered by the backpropagation (BP) algorithm, deep neural networks have dominated the race in solving various cognitive tasks. The restricted training pattern in the standard BP requires end-to-end error propagation, causing large memory cost and prohibiting model parallelization. Existing local training methods aim to resolve the training obstacle by completely cutting off the backward path between modules and isolating their gradients to reduce memory cost and accelerate the training process. These methods prevent errors from flowing between modules and hence information exchange, resulting in inferior performance. This work proposes a novel local training algorithm, BackLink, which introduces inter-module backward dependency and allows errors to flow between modules. The algorithm facilitates information to flow backward along with the network. To preserve the computational advantage of local training, BackLink restricts the error propagation length within the module. Extensive experiments performed in various deep convolutional neural networks demonstrate that our method consistently improves the classification performance of local training algorithms over other methods. For example, in ResNet32 with 16 local modules, our method surpasses the conventional greedy local training method by 4.00\% and a recent work by 1.83\% in accuracy on CIFAR10, respectively. Analysis of computational costs reveals that small overheads are incurred in GPU memory costs and runtime on multiple GPUs. Our method can lead up to a 79\% reduction in memory cost and 52\% in simulation runtime in ResNet110 compared to the standard BP. Therefore, our method could create new opportunities for improving training algorithms towards better efficiency and biological plausibility.

</p>
</details>

<details><summary><b>A Learning Approach for Joint Design of Event-triggered Control and Power-Efficient Resource Allocation</b>
<a href="https://arxiv.org/abs/2205.07070">arxiv:2205.07070</a>
&#x1F4C8; 0 <br>
<p>Atefeh Termehchi, Mehdi Rasti</p></summary>
<p>

**Abstract:** In emerging Industrial Cyber-Physical Systems (ICPSs), the joint design of communication and control sub-systems is essential, as these sub-systems are interconnected. In this paper, we study the joint design problem of an event-triggered control and an energy-efficient resource allocation in a fifth generation (5G) wireless network. We formally state the problem as a multi-objective optimization one, aiming to minimize the number of updates on the actuators' input and the power consumption in the downlink transmission. To address the problem, we propose a model-free hierarchical reinforcement learning approach \textcolor{blue}{with uniformly ultimate boundedness stability guarantee} that learns four policies simultaneously. These policies contain an update time policy on the actuators' input, a control policy, and energy-efficient sub-carrier and power allocation policies. Our simulation results show that the proposed approach can properly control a simulated ICPS and significantly decrease the number of updates on the actuators' input as well as the downlink power consumption.

</p>
</details>

<details><summary><b>MIND: Maximum Mutual Information Based Neural Decoder</b>
<a href="https://arxiv.org/abs/2205.07061">arxiv:2205.07061</a>
&#x1F4C8; 0 <br>
<p>Andrea M. Tonello, Nunzio A. Letizia</p></summary>
<p>

**Abstract:** We are assisting at a growing interest in the development of learning architectures with application to digital communication systems. Herein, we consider the detection/decoding problem. We aim at developing an optimal neural architecture for such a task. The definition of the optimal criterion is a fundamental step. We propose to use the mutual information (MI) of the channel input-output signal pair. The computation of the MI is a formidable task, and for the majority of communication channels it is unknown. Therefore, the MI has to be learned. For such an objective, we propose a novel neural MI estimator based on a discriminative formulation. This leads to the derivation of the mutual information neural decoder (MIND). The developed neural architecture is capable not only to solve the decoding problem in unknown channels, but also to return an estimate of the average MI achieved with the coding scheme, as well as the decoding error probability. Several numerical results are reported and compared with maximum a-posteriori (MAP) and maximum likelihood (MaxL) decoding strategies.

</p>
</details>

<details><summary><b>Integration of Text and Graph-based Features for Detecting Mental Health Disorders from Voice</b>
<a href="https://arxiv.org/abs/2205.07006">arxiv:2205.07006</a>
&#x1F4C8; 0 <br>
<p>Nasser Ghadiri, Rasoul Samani, Fahime Shahrokh</p></summary>
<p>

**Abstract:** With the availability of voice-enabled devices such as smart phones, mental health disorders could be detected and treated earlier, particularly post-pandemic. The current methods involve extracting features directly from audio signals. In this paper, two methods are used to enrich voice analysis for depression detection: graph transformation of voice signals, and natural language processing of the transcript based on representational learning, fused together to produce final class labels. The results of experiments with the DAIC-WOZ dataset suggest that integration of text-based voice classification and learning from low level and graph-based voice signal features can improve the detection of mental disorders like depression.

</p>
</details>

<details><summary><b>QHD: A brain-inspired hyperdimensional reinforcement learning algorithm</b>
<a href="https://arxiv.org/abs/2205.06978">arxiv:2205.06978</a>
&#x1F4C8; 0 <br>
<p>Yang Ni, Danny Abraham, Mariam Issa, Yeseong Kim, Pietro Mecati, Mohsen Imani</p></summary>
<p>

**Abstract:** Reinforcement Learning (RL) has opened up new opportunities to solve a wide range of complex decision-making tasks. However, modern RL algorithms, e.g., Deep Q-Learning, are based on deep neural networks, putting high computational costs when running on edge devices. In this paper, we propose QHD, a Hyperdimensional Reinforcement Learning, that mimics brain properties toward robust and real-time learning. QHD relies on a lightweight brain-inspired model to learn an optimal policy in an unknown environment. We first develop a novel mathematical foundation and encoding module that maps state-action space into high-dimensional space. We accordingly develop a hyperdimensional regression model to approximate the Q-value function. The QHD-powered agent makes decisions by comparing Q-values of each possible action. We evaluate the effect of the different RL training batch sizes and local memory capacity on the QHD quality of learning. Our QHD is also capable of online learning with tiny local memory capacity, which can be as small as the training batch size. QHD provides real-time learning by further decreasing the memory capacity and the batch size. This makes QHD suitable for highly-efficient reinforcement learning in the edge environment, where it is crucial to support online and real-time learning. Our solution also supports a small experience replay batch size that provides 12.3 times speedup compared to DQN while ensuring minimal quality loss. Our evaluation shows QHD capability for real-time learning, providing 34.6 times speedup and significantly better quality of learning than state-of-the-art deep RL algorithms.

</p>
</details>


{% endraw %}
Prev: [2022.05.13]({{ '/2022/05/13/2022.05.13.html' | relative_url }})  Next: [2022.05.15]({{ '/2022/05/15/2022.05.15.html' | relative_url }})