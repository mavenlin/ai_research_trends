Prev: [2021.12.29]({{ '/2021/12/29/2021.12.29.html' | relative_url }})  Next: [2021.12.31]({{ '/2021/12/31/2021.12.31.html' | relative_url }})
{% raw %}
## Summary for 2021-12-30, created on 2022-01-09


<details><summary><b>Deep Learning Interviews: Hundreds of fully solved job interview questions from a wide range of key topics in AI</b>
<a href="https://arxiv.org/abs/2201.00650">arxiv:2201.00650</a>
&#x1F4C8; 7860 <br>
<p>Shlomo Kashani, Amir Ivry</p></summary>
<p>

**Abstract:** The second edition of Deep Learning Interviews is home to hundreds of fully-solved problems, from a wide range of key topics in AI. It is designed to both rehearse interview or exam specific topics and provide machine learning MSc / PhD. students, and those awaiting an interview a well-organized overview of the field. The problems it poses are tough enough to cut your teeth on and to dramatically improve your skills-but they're framed within thought-provoking questions and engaging stories. That is what makes the volume so specifically valuable to students and job seekers: it provides them with the ability to speak confidently and quickly on any relevant topic, to answer technical questions clearly and correctly, and to fully understand the purpose and meaning of interview questions and answers. Those are powerful, indispensable advantages to have when walking into the interview room. The book's contents is a large inventory of numerous topics relevant to DL job interviews and graduate level exams. That places this work at the forefront of the growing trend in science to teach a core set of practical mathematical and computational skills. It is widely accepted that the training of every computer scientist must include the fundamental theorems of ML, and AI appears in the curriculum of nearly every university. This volume is designed as an excellent reference for graduates of such programs.

</p>
</details>

<details><summary><b>SimSR: Simple Distance-based State Representation for Deep Reinforcement Learning</b>
<a href="https://arxiv.org/abs/2112.15303">arxiv:2112.15303</a>
&#x1F4C8; 46 <br>
<p>Hongyu Zang, Xin Li, Mingzhong Wang</p></summary>
<p>

**Abstract:** This work explores how to learn robust and generalizable state representation from image-based observations with deep reinforcement learning methods. Addressing the computational complexity, stringent assumptions, and representation collapse challenges in the existing work of bisimulation metric, we devise Simple State Representation (SimSR) operator, which achieves equivalent functionality while reducing the complexity by an order in comparison with bisimulation metric. SimSR enables us to design a stochastic-approximation-based method that can practically learn the mapping functions (encoders) from observations to latent representation space. Besides the theoretical analysis, we experimented and compared our work with recent state-of-the-art solutions in visual MuJoCo tasks. The results show that our model generally achieves better performance and has better robustness and good generalization.

</p>
</details>

<details><summary><b>Data-Free Knowledge Transfer: A Survey</b>
<a href="https://arxiv.org/abs/2112.15278">arxiv:2112.15278</a>
&#x1F4C8; 30 <br>
<p>Yuang Liu, Wei Zhang, Jun Wang, Jianyong Wang</p></summary>
<p>

**Abstract:** In the last decade, many deep learning models have been well trained and made a great success in various fields of machine intelligence, especially for computer vision and natural language processing. To better leverage the potential of these well-trained models in intra-domain or cross-domain transfer learning situations, knowledge distillation (KD) and domain adaptation (DA) are proposed and become research highlights. They both aim to transfer useful information from a well-trained model with original training data. However, the original data is not always available in many cases due to privacy, copyright or confidentiality. Recently, the data-free knowledge transfer paradigm has attracted appealing attention as it deals with distilling valuable knowledge from well-trained models without requiring to access to the training data. In particular, it mainly consists of the data-free knowledge distillation (DFKD) and source data-free domain adaptation (SFDA). On the one hand, DFKD aims to transfer the intra-domain knowledge of original data from a cumbersome teacher network to a compact student network for model compression and efficient inference. On the other hand, the goal of SFDA is to reuse the cross-domain knowledge stored in a well-trained source model and adapt it to a target domain. In this paper, we provide a comprehensive survey on data-free knowledge transfer from the perspectives of knowledge distillation and unsupervised domain adaptation, to help readers have a better understanding of the current research status and ideas. Applications and challenges of the two areas are briefly reviewed, respectively. Furthermore, we provide some insights to the subject of future research.

</p>
</details>

<details><summary><b>Towards Robustness of Neural Networks</b>
<a href="https://arxiv.org/abs/2112.15188">arxiv:2112.15188</a>
&#x1F4C8; 25 <br>
<p>Steven Basart</p></summary>
<p>

**Abstract:** We introduce several new datasets namely ImageNet-A/O and ImageNet-R as well as a synthetic environment and testing suite we called CAOS. ImageNet-A/O allow researchers to focus in on the blind spots remaining in ImageNet. ImageNet-R was specifically created with the intention of tracking robust representation as the representations are no longer simply natural but include artistic, and other renditions. The CAOS suite is built off of CARLA simulator which allows for the inclusion of anomalous objects and can create reproducible synthetic environment and scenes for testing robustness. All of the datasets were created for testing robustness and measuring progress in robustness. The datasets have been used in various other works to measure their own progress in robustness and allowing for tangential progress that does not focus exclusively on natural accuracy.
  Given these datasets, we created several novel methods that aim to advance robustness research. We build off of simple baselines in the form of Maximum Logit, and Typicality Score as well as create a novel data augmentation method in the form of DeepAugment that improves on the aforementioned benchmarks. Maximum Logit considers the logit values instead of the values after the softmax operation, while a small change produces noticeable improvements. The Typicality Score compares the output distribution to a posterior distribution over classes. We show that this improves performance over the baseline in all but the segmentation task. Speculating that perhaps at the pixel level the semantic information of a pixel is less meaningful than that of class level information. Finally the new augmentation technique of DeepAugment utilizes neural networks to create augmentations on images that are radically different than the traditional geometric and camera based transformations used previously.

</p>
</details>

<details><summary><b>Pose Estimation of Specific Rigid Objects</b>
<a href="https://arxiv.org/abs/2112.15075">arxiv:2112.15075</a>
&#x1F4C8; 12 <br>
<p>Tomas Hodan</p></summary>
<p>

**Abstract:** In this thesis, we address the problem of estimating the 6D pose of rigid objects from a single RGB or RGB-D input image, assuming that 3D models of the objects are available. This problem is of great importance to many application fields such as robotic manipulation, augmented reality, and autonomous driving. First, we propose EPOS, a method for 6D object pose estimation from an RGB image. The key idea is to represent an object by compact surface fragments and predict the probability distribution of corresponding fragments at each pixel of the input image by a neural network. Each pixel is linked with a data-dependent number of fragments, which allows systematic handling of symmetries, and the 6D poses are estimated from the links by a RANSAC-based fitting method. EPOS outperformed all RGB and most RGB-D and D methods on several standard datasets. Second, we present HashMatch, an RGB-D method that slides a window over the input image and searches for a match against templates, which are pre-generated by rendering 3D object models in different orientations. The method applies a cascade of evaluation stages to each window location, which avoids exhaustive matching against all templates. Third, we propose ObjectSynth, an approach to synthesize photorealistic images of 3D object models for training methods based on neural networks. The images yield substantial improvements compared to commonly used images of objects rendered on top of random photographs. Fourth, we introduce T-LESS, the first dataset for 6D object pose estimation that includes 3D models and RGB-D images of industry-relevant objects. Fifth, we define BOP, a benchmark that captures the status quo in the field. BOP comprises eleven datasets in a unified format, an evaluation methodology, an online evaluation system, and public challenges held at international workshops organized at the ICCV and ECCV conferences.

</p>
</details>

<details><summary><b>Domain Adaptation with Category Attention Network for Deep Sentiment Analysis</b>
<a href="https://arxiv.org/abs/2112.15290">arxiv:2112.15290</a>
&#x1F4C8; 7 <br>
<p>Dongbo Xi, Fuzhen Zhuang, Ganbin Zhou, Xiaohu Cheng, Fen Lin, Qing He</p></summary>
<p>

**Abstract:** Domain adaptation tasks such as cross-domain sentiment classification aim to utilize existing labeled data in the source domain and unlabeled or few labeled data in the target domain to improve the performance in the target domain via reducing the shift between the data distributions. Existing cross-domain sentiment classification methods need to distinguish pivots, i.e., the domain-shared sentiment words, and non-pivots, i.e., the domain-specific sentiment words, for excellent adaptation performance. In this paper, we first design a Category Attention Network (CAN), and then propose a model named CAN-CNN to integrate CAN and a Convolutional Neural Network (CNN). On the one hand, the model regards pivots and non-pivots as unified category attribute words and can automatically capture them to improve the domain adaptation performance; on the other hand, the model makes an attempt at interpretability to learn the transferred category attribute words. Specifically, the optimization objective of our model has three different components: 1) the supervised classification loss; 2) the distributions loss of category feature weights; 3) the domain invariance loss. Finally, the proposed model is evaluated on three public sentiment analysis datasets and the results demonstrate that CAN-CNN can outperform other various baseline methods.

</p>
</details>

<details><summary><b>Aim in Climate Change and City Pollution</b>
<a href="https://arxiv.org/abs/2112.15115">arxiv:2112.15115</a>
&#x1F4C8; 6 <br>
<p>Pablo Torres, Beril Sirmacek, Sergio Hoyas, Ricardo Vinuesa</p></summary>
<p>

**Abstract:** The sustainability of urban environments is an increasingly relevant problem. Air pollution plays a key role in the degradation of the environment as well as the health of the citizens exposed to it. In this chapter we provide a review of the methods available to model air pollution, focusing on the application of machine-learning methods. In fact, machine-learning methods have proved to importantly increase the accuracy of traditional air-pollution approaches while limiting the development cost of the models. Machine-learning tools have opened new approaches to study air pollution, such as flow-dynamics modelling or remote-sensing methodologies.

</p>
</details>

<details><summary><b>What is Event Knowledge Graph: A Survey</b>
<a href="https://arxiv.org/abs/2112.15280">arxiv:2112.15280</a>
&#x1F4C8; 5 <br>
<p>Saiping Guan, Xueqi Cheng, Long Bai, Fujun Zhang, Zixuan Li, Yutao Zeng, Xiaolong Jin, Jiafeng Guo</p></summary>
<p>

**Abstract:** Besides entity-centric knowledge, usually organized as Knowledge Graph (KG), events are also an essential kind of knowledge in the world, which trigger the spring up of event-centric knowledge representation form like Event KG (EKG). It plays an increasingly important role in many machine learning and artificial intelligence applications, such as intelligent search, question-answering, recommendation, and text generation. This paper provides a comprehensive survey of EKG from history, ontology, instance, and application views. Specifically, to characterize EKG thoroughly, we focus on its history, definitions, schema induction, acquisition, related representative graphs/systems, and applications. The development processes and trends are studied therein. We further summarize perspective directions to facilitate future research on EKG.

</p>
</details>

<details><summary><b>Dimensionality reduction for prediction: Application to Bitcoin and Ethereum</b>
<a href="https://arxiv.org/abs/2112.15036">arxiv:2112.15036</a>
&#x1F4C8; 5 <br>
<p>Hugo Inzirillo, Benjamin Mat</p></summary>
<p>

**Abstract:** The objective of this paper is to assess the performances of dimensionality reduction techniques to establish a link between cryptocurrencies. We have focused our analysis on the two most traded cryptocurrencies: Bitcoin and Ethereum. To perform our analysis, we took log returns and added some covariates to build our data set. We first introduced the pearson correlation coefficient in order to have a preliminary assessment of the link between Bitcoin and Ethereum. We then reduced the dimension of our data set using canonical correlation analysis and principal component analysis. After performing an analysis of the links between Bitcoin and Ethereum with both statistical techniques, we measured their performance on forecasting Ethereum returns with Bitcoin s features.

</p>
</details>

<details><summary><b>Two Instances of Interpretable Neural Network for Universal Approximations</b>
<a href="https://arxiv.org/abs/2112.15026">arxiv:2112.15026</a>
&#x1F4C8; 5 <br>
<p>Erico Tjoa, Guan Cuntai</p></summary>
<p>

**Abstract:** This paper proposes two bottom-up interpretable neural network (NN) constructions for universal approximation, namely Triangularly-constructed NN (TNN) and Semi-Quantized Activation NN (SQANN). The notable properties are (1) resistance to catastrophic forgetting (2) existence of proof for arbitrarily high accuracies on training dataset (3) for an input \(x\), users can identify specific samples of training data whose activation ``fingerprints" are similar to that of \(x\)'s activations. Users can also identify samples that are out of distribution.

</p>
</details>

<details><summary><b>Delving into Sample Loss Curve to Embrace Noisy and Imbalanced Data</b>
<a href="https://arxiv.org/abs/2201.00849">arxiv:2201.00849</a>
&#x1F4C8; 4 <br>
<p>Shenwang Jiang, Jianan Li, Ying Wang, Bo Huang, Zhang Zhang, Tingfa Xu</p></summary>
<p>

**Abstract:** Corrupted labels and class imbalance are commonly encountered in practically collected training data, which easily leads to over-fitting of deep neural networks (DNNs). Existing approaches alleviate these issues by adopting a sample re-weighting strategy, which is to re-weight sample by designing weighting function. However, it is only applicable for training data containing only either one type of data biases. In practice, however, biased samples with corrupted labels and of tailed classes commonly co-exist in training data. How to handle them simultaneously is a key but under-explored problem. In this paper, we find that these two types of biased samples, though have similar transient loss, have distinguishable trend and characteristics in loss curves, which could provide valuable priors for sample weight assignment. Motivated by this, we delve into the loss curves and propose a novel probe-and-allocate training strategy: In the probing stage, we train the network on the whole biased training data without intervention, and record the loss curve of each sample as an additional attribute; In the allocating stage, we feed the resulting attribute to a newly designed curve-perception network, named CurveNet, to learn to identify the bias type of each sample and assign proper weights through meta-learning adaptively. The training speed of meta learning also blocks its application. To solve it, we propose a method named skip layer meta optimization (SLMO) to accelerate training speed by skipping the bottom layers. Extensive synthetic and real experiments well validate the proposed method, which achieves state-of-the-art performance on multiple challenging benchmarks.

</p>
</details>

<details><summary><b>When are Iterative Gaussian Processes Reliably Accurate?</b>
<a href="https://arxiv.org/abs/2112.15246">arxiv:2112.15246</a>
&#x1F4C8; 4 <br>
<p>Wesley J. Maddox, Sanyam Kapoor, Andrew Gordon Wilson</p></summary>
<p>

**Abstract:** While recent work on conjugate gradient methods and Lanczos decompositions have achieved scalable Gaussian process inference with highly accurate point predictions, in several implementations these iterative methods appear to struggle with numerical instabilities in learning kernel hyperparameters, and poor test likelihoods. By investigating CG tolerance, preconditioner rank, and Lanczos decomposition rank, we provide a particularly simple prescription to correct these issues: we recommend that one should use a small CG tolerance ($Îµ\leq 0.01$) and a large root decomposition size ($r \geq 5000$). Moreover, we show that L-BFGS-B is a compelling optimizer for Iterative GPs, achieving convergence with fewer gradient updates.

</p>
</details>

<details><summary><b>Audio-to-symbolic Arrangement via Cross-modal Music Representation Learning</b>
<a href="https://arxiv.org/abs/2112.15110">arxiv:2112.15110</a>
&#x1F4C8; 4 <br>
<p>Ziyu Wang, Dejing Xu, Gus Xia, Ying Shan</p></summary>
<p>

**Abstract:** Could we automatically derive the score of a piano accompaniment based on the audio of a pop song? This is the audio-to-symbolic arrangement problem we tackle in this paper. A good arrangement model should not only consider the audio content but also have prior knowledge of piano composition (so that the generation "sounds like" the audio and meanwhile maintains musicality.) To this end, we contribute a cross-modal representation-learning model, which 1) extracts chord and melodic information from the audio, and 2) learns texture representation from both audio and a corrupted ground truth arrangement. We further introduce a tailored training strategy that gradually shifts the source of texture information from corrupted score to audio. In the end, the score-based texture posterior is reduced to a standard normal distribution, and only audio is needed for inference. Experiments show that our model captures major audio information and outperforms baselines in generation quality.

</p>
</details>

<details><summary><b>ChunkFormer: Learning Long Time Series with Multi-stage Chunked Transformer</b>
<a href="https://arxiv.org/abs/2112.15087">arxiv:2112.15087</a>
&#x1F4C8; 4 <br>
<p>Yue Ju, Alka Isac, Yimin Nie</p></summary>
<p>

**Abstract:** The analysis of long sequence data remains challenging in many real-world applications. We propose a novel architecture, ChunkFormer, that improves the existing Transformer framework to handle the challenges while dealing with long time series. Original Transformer-based models adopt an attention mechanism to discover global information along a sequence to leverage the contextual data. Long sequential data traps local information such as seasonality and fluctuations in short data sequences. In addition, the original Transformer consumes more resources by carrying the entire attention matrix during the training course. To overcome these challenges, ChunkFormer splits the long sequences into smaller sequence chunks for the attention calculation, progressively applying different chunk sizes in each stage. In this way, the proposed model gradually learns both local and global information without changing the total length of the input sequences. We have extensively tested the effectiveness of this new architecture on different business domains and have proved the advantage of such a model over the existing Transformer-based models.

</p>
</details>

<details><summary><b>Does QA-based intermediate training help fine-tuning language models for text classification?</b>
<a href="https://arxiv.org/abs/2112.15051">arxiv:2112.15051</a>
&#x1F4C8; 4 <br>
<p>Shiwei Zhang, Xiuzhen Zhang</p></summary>
<p>

**Abstract:** Fine-tuning pre-trained language models for downstream tasks has become a norm for NLP. Recently it is found that intermediate training based on high-level inference tasks such as Question Answering (QA) can improve the performance of some language models for target tasks. However it is not clear if intermediate training generally benefits various language models. In this paper, using the SQuAD-2.0 QA task for intermediate training for target text classification tasks, we experimented on eight tasks for single-sequence classification and eight tasks for sequence-pair classification using two base and two compact language models. Our experiments show that QA-based intermediate training generates varying transfer performance across different language models, except for similar QA tasks.

</p>
</details>

<details><summary><b>Investigating Pose Representations and Motion Contexts Modeling for 3D Motion Prediction</b>
<a href="https://arxiv.org/abs/2112.15012">arxiv:2112.15012</a>
&#x1F4C8; 4 <br>
<p>Zhenguang Liu, Shuang Wu, Shuyuan Jin, Shouling Ji, Qi Liu, Shijian Lu, Li Cheng</p></summary>
<p>

**Abstract:** Predicting human motion from historical pose sequence is crucial for a machine to succeed in intelligent interactions with humans. One aspect that has been obviated so far, is the fact that how we represent the skeletal pose has a critical impact on the prediction results. Yet there is no effort that investigates across different pose representation schemes. We conduct an indepth study on various pose representations with a focus on their effects on the motion prediction task. Moreover, recent approaches build upon off-the-shelf RNN units for motion prediction. These approaches process input pose sequence sequentially and inherently have difficulties in capturing long-term dependencies. In this paper, we propose a novel RNN architecture termed AHMR (Attentive Hierarchical Motion Recurrent network) for motion prediction which simultaneously models local motion contexts and a global context. We further explore a geodesic loss and a forward kinematics loss for the motion prediction task, which have more geometric significance than the widely employed L2 loss. Interestingly, we applied our method to a range of articulate objects including human, fish, and mouse. Empirical results show that our approach outperforms the state-of-the-art methods in short-term prediction and achieves much enhanced long-term prediction proficiency, such as retaining natural human-like motions over 50 seconds predictions. Our codes are released.

</p>
</details>

<details><summary><b>MORAL: Aligning AI with Human Norms through Multi-Objective Reinforced Active Learning</b>
<a href="https://arxiv.org/abs/2201.00012">arxiv:2201.00012</a>
&#x1F4C8; 3 <br>
<p>Markus Peschl, Arkady Zgonnikov, Frans A. Oliehoek, Luciano C. Siebert</p></summary>
<p>

**Abstract:** Inferring reward functions from demonstrations and pairwise preferences are auspicious approaches for aligning Reinforcement Learning (RL) agents with human intentions. However, state-of-the art methods typically focus on learning a single reward model, thus rendering it difficult to trade off different reward functions from multiple experts. We propose Multi-Objective Reinforced Active Learning (MORAL), a novel method for combining diverse demonstrations of social norms into a Pareto-optimal policy. Through maintaining a distribution over scalarization weights, our approach is able to interactively tune a deep RL agent towards a variety of preferences, while eliminating the need for computing multiple policies. We empirically demonstrate the effectiveness of MORAL in two scenarios, which model a delivery and an emergency task that require an agent to act in the presence of normative conflicts. Overall, we consider our research a step towards multi-objective RL with learned rewards, bridging the gap between current reward learning and machine ethics literature.

</p>
</details>

<details><summary><b>CSformer: Bridging Convolution and Transformer for Compressive Sensing</b>
<a href="https://arxiv.org/abs/2112.15299">arxiv:2112.15299</a>
&#x1F4C8; 3 <br>
<p>Dongjie Ye, Zhangkai Ni, Hanli Wang, Jian Zhang, Shiqi Wang, Sam Kwong</p></summary>
<p>

**Abstract:** Convolution neural networks (CNNs) have succeeded in compressive image sensing. However, due to the inductive bias of locality and weight sharing, the convolution operations demonstrate the intrinsic limitations in modeling the long-range dependency. Transformer, designed initially as a sequence-to-sequence model, excels at capturing global contexts due to the self-attention-based architectures even though it may be equipped with limited localization abilities. This paper proposes CSformer, a hybrid framework that integrates the advantages of leveraging both detailed spatial information from CNN and the global context provided by transformer for enhanced representation learning. The proposed approach is an end-to-end compressive image sensing method, composed of adaptive sampling and recovery. In the sampling module, images are measured block-by-block by the learned sampling matrix. In the reconstruction stage, the measurement is projected into dual stems. One is the CNN stem for modeling the neighborhood relationships by convolution, and the other is the transformer stem for adopting global self-attention mechanism. The dual branches structure is concurrent, and the local features and global representations are fused under different resolutions to maximize the complementary of features. Furthermore, we explore a progressive strategy and window-based transformer block to reduce the parameter and computational complexity. The experimental results demonstrate the effectiveness of the dedicated transformer-based architecture for compressive sensing, which achieves superior performance compared to state-of-the-art methods on different datasets.

</p>
</details>

<details><summary><b>Machine Learning Application Development: Practitioners' Insights</b>
<a href="https://arxiv.org/abs/2112.15277">arxiv:2112.15277</a>
&#x1F4C8; 3 <br>
<p>Md Saidur Rahman, Foutse Khomh, Alaleh Hamidi, Jinghui Cheng, Giuliano Antoniol, Hironori Washizaki</p></summary>
<p>

**Abstract:** Nowadays, intelligent systems and services are getting increasingly popular as they provide data-driven solutions to diverse real-world problems, thanks to recent breakthroughs in Artificial Intelligence (AI) and Machine Learning (ML). However, machine learning meets software engineering not only with promising potentials but also with some inherent challenges. Despite some recent research efforts, we still do not have a clear understanding of the challenges of developing ML-based applications and the current industry practices. Moreover, it is unclear where software engineering researchers should focus their efforts to better support ML application developers. In this paper, we report about a survey that aimed to understand the challenges and best practices of ML application development. We synthesize the results obtained from 80 practitioners (with diverse skills, experience, and application domains) into 17 findings; outlining challenges and best practices for ML application development. Practitioners involved in the development of ML-based software systems can leverage the summarized best practices to improve the quality of their system. We hope that the reported challenges will inform the research community about topics that need to be investigated to improve the engineering process and the quality of ML-based applications.

</p>
</details>

<details><summary><b>ViNMT: Neural Machine Translation Tookit</b>
<a href="https://arxiv.org/abs/2112.15272">arxiv:2112.15272</a>
&#x1F4C8; 3 <br>
<p>Nguyen Hoang Quan, Nguyen Thanh Dat, Nguyen Hoang Minh Cong, Nguyen Van Vinh, Ngo Thi Vinh, Nguyen Phuong Thai, Tran Hong Viet</p></summary>
<p>

**Abstract:** We present an open-source toolkit for neural machine translation (NMT). The new toolkit is mainly based on vaulted Transformer (Vaswani et al., 2017) along with many other improvements detailed below, in order to create a self-contained, simple to use, consistent and comprehensive framework for Machine Translation tasks of various domains. It is tooled to support both bilingual and multilingual translation tasks, starting from building the model from respective corpora, to inferring new predictions or packaging the model to serving-capable JIT format.

</p>
</details>

<details><summary><b>Benign Overfitting in Adversarially Robust Linear Classification</b>
<a href="https://arxiv.org/abs/2112.15250">arxiv:2112.15250</a>
&#x1F4C8; 3 <br>
<p>Jinghui Chen, Yuan Cao, Quanquan Gu</p></summary>
<p>

**Abstract:** "Benign overfitting", where classifiers memorize noisy training data yet still achieve a good generalization performance, has drawn great attention in the machine learning community. To explain this surprising phenomenon, a series of works have provided theoretical justification in over-parameterized linear regression, classification, and kernel methods. However, it is not clear if benign overfitting still occurs in the presence of adversarial examples, i.e., examples with tiny and intentional perturbations to fool the classifiers. In this paper, we show that benign overfitting indeed occurs in adversarial training, a principled approach to defend against adversarial examples. In detail, we prove the risk bounds of the adversarially trained linear classifier on the mixture of sub-Gaussian data under $\ell_p$ adversarial perturbations. Our result suggests that under moderate perturbations, adversarially trained linear classifiers can achieve the near-optimal standard and adversarial risks, despite overfitting the noisy training data. Numerical experiments validate our theoretical findings.

</p>
</details>

<details><summary><b>Learning Agent State Online with Recurrent Generate-and-Test</b>
<a href="https://arxiv.org/abs/2112.15236">arxiv:2112.15236</a>
&#x1F4C8; 3 <br>
<p>Amir Samani, Richard S. Sutton</p></summary>
<p>

**Abstract:** Learning continually and online from a continuous stream of data is challenging, especially for a reinforcement learning agent with sequential data. When the environment only provides observations giving partial information about the state of the environment, the agent must learn the agent state based on the data stream of experience. We refer to the state learned directly from the data stream of experience as the agent state. Recurrent neural networks can learn the agent state, but the training methods are computationally expensive and sensitive to the hyper-parameters, making them unideal for online learning. This work introduces methods based on the generate-and-test approach to learn the agent state. A generate-and-test algorithm searches for state features by generating features and testing their usefulness. In this process, features useful for the agent's performance on the task are preserved, and the least useful features get replaced with newly generated features. We study the effectiveness of our methods on two online multi-step prediction problems. The first problem, trace conditioning, focuses on the agent's ability to remember a cue for a prediction multiple steps into the future. In the second problem, trace patterning, the agent needs to learn patterns in the observation signals and remember them for future predictions. We show that our proposed methods can effectively learn the agent state online and produce accurate predictions.

</p>
</details>

<details><summary><b>From Behavioral Theories to Econometrics: Inferring Preferences of Human Agents from Data on Repeated Interactions</b>
<a href="https://arxiv.org/abs/2112.15151">arxiv:2112.15151</a>
&#x1F4C8; 3 <br>
<p>Gali Noti</p></summary>
<p>

**Abstract:** We consider the problem of estimating preferences of human agents from data of strategic systems where the agents repeatedly interact. Recently, it was demonstrated that a new estimation method called "quantal regret" produces more accurate estimates for human agents than the classic approach that assumes that agents are rational and reach a Nash equilibrium; however, this method has not been compared to methods that take into account behavioral aspects of human play. In this paper we leverage equilibrium concepts from behavioral economics for this purpose and ask how well they perform compared to the quantal regret and Nash equilibrium methods. We develop four estimation methods based on established behavioral equilibrium models to infer the utilities of human agents from observed data of normal-form games. The equilibrium models we study are quantal-response equilibrium, action-sampling equilibrium, payoff-sampling equilibrium, and impulse-balance equilibrium. We show that in some of these concepts the inference is achieved analytically via closed formulas, while in the others the inference is achieved only algorithmically. We use experimental data of 2x2 games to evaluate the estimation success of these behavioral equilibrium methods. The results show that the estimates they produce are more accurate than the estimates of the Nash equilibrium. The comparison with the quantal-regret method shows that the behavioral methods have better hit rates, but the quantal-regret method performs better in terms of the overall mean squared error, and we discuss the differences between the methods.

</p>
</details>

<details><summary><b>Leveraging in-domain supervision for unsupervised image-to-image translation tasks via multi-stream generators</b>
<a href="https://arxiv.org/abs/2112.15091">arxiv:2112.15091</a>
&#x1F4C8; 3 <br>
<p>Dvir Yerushalmi, Dov Danon, Amit H. Bermano</p></summary>
<p>

**Abstract:** Supervision for image-to-image translation (I2I) tasks is hard to come by, but bears significant effect on the resulting quality. In this paper, we observe that for many Unsupervised I2I (UI2I) scenarios, one domain is more familiar than the other, and offers in-domain prior knowledge, such as semantic segmentation. We argue that for complex scenes, figuring out the semantic structure of the domain is hard, especially with no supervision, but is an important part of a successful I2I operation. We hence introduce two techniques to incorporate this invaluable in-domain prior knowledge for the benefit of translation quality: through a novel Multi-Stream generator architecture, and through a semantic segmentation-based regularization loss term. In essence, we propose splitting the input data according to semantic masks, explicitly guiding the network to different behavior for the different regions of the image. In addition, we propose training a semantic segmentation network along with the translation task, and to leverage this output as a loss term that improves robustness. We validate our approach on urban data, demonstrating superior quality in the challenging UI2I tasks of converting day images to night ones. In addition, we also demonstrate how reinforcing the target dataset with our augmented images improves the training of downstream tasks such as the classical detection one.

</p>
</details>

<details><summary><b>Deconfounded Training for Graph Neural Networks</b>
<a href="https://arxiv.org/abs/2112.15089">arxiv:2112.15089</a>
&#x1F4C8; 3 <br>
<p>Yongduo Sui, Xiang Wang, Jiancan Wu, Xiangnan He, Tat-Seng Chua</p></summary>
<p>

**Abstract:** Learning powerful representations is one central theme of graph neural networks (GNNs). It requires refining the critical information from the input graph, instead of the trivial patterns, to enrich the representations. Towards this end, graph attention and pooling methods prevail. They mostly follow the paradigm of "learning to attend". It maximizes the mutual information between the attended subgraph and the ground-truth label. However, this training paradigm is prone to capture the spurious correlations between the trivial subgraph and the label. Such spurious correlations are beneficial to in-distribution (ID) test evaluations, but cause poor generalization in the out-of-distribution (OOD) test data. In this work, we revisit the GNN modeling from the causal perspective. On the top of our causal assumption, the trivial information serves as a confounder between the critical information and the label, which opens a backdoor path between them and makes them spuriously correlated. Hence, we present a new paradigm of deconfounded training (DTP) that better mitigates the confounding effect and latches on the critical information, to enhance the representation and generalization ability. Specifically, we adopt the attention modules to disentangle the critical subgraph and trivial subgraph. Then we make each critical subgraph fairly interact with diverse trivial subgraphs to achieve a stable prediction. It allows GNNs to capture a more reliable subgraph whose relation with the label is robust across different distributions. We conduct extensive experiments on synthetic and real-world datasets to demonstrate the effectiveness.

</p>
</details>

<details><summary><b>TextRGNN: Residual Graph Neural Networks for Text Classification</b>
<a href="https://arxiv.org/abs/2112.15060">arxiv:2112.15060</a>
&#x1F4C8; 3 <br>
<p>Jiayuan Chen, Boyu Zhang, Yinfei Xu, Meng Wang</p></summary>
<p>

**Abstract:** Recently, text classification model based on graph neural network (GNN) has attracted more and more attention. Most of these models adopt a similar network paradigm, that is, using pre-training node embedding initialization and two-layer graph convolution. In this work, we propose TextRGNN, an improved GNN structure that introduces residual connection to deepen the convolution network depth. Our structure can obtain a wider node receptive field and effectively suppress the over-smoothing of node features. In addition, we integrate the probabilistic language model into the initialization of graph node embedding, so that the non-graph semantic information of can be better extracted. The experimental results show that our model is general and efficient. It can significantly improve the classification accuracy whether in corpus level or text level, and achieve SOTA performance on a wide range of text classification datasets.

</p>
</details>

<details><summary><b>Self Reward Design with Fine-grained Interpretability</b>
<a href="https://arxiv.org/abs/2112.15034">arxiv:2112.15034</a>
&#x1F4C8; 3 <br>
<p>Erico Tjoa, Guan Cuntai</p></summary>
<p>

**Abstract:** Transparency and fairness issues in Deep Reinforcement Learning may stem from the black-box nature of deep neural networks used to learn its policy, value functions etc. This paper proposes a way to circumvent the issues through the bottom-up design of neural networks (NN) with detailed interpretability, where each neuron or layer has its own meaning and utility that corresponds to humanly understandable concept. With deliberate design, we show that lavaland problems can be solved using NN model with few parameters. Furthermore, we introduce the Self Reward Design (SRD), inspired by the Inverse Reward Design, so that our interpretable design can (1) solve the problem by pure design (although imperfectly) (2) be optimized via SRD (3) perform avoidance of unknown states by recognizing the inactivations of neurons aggregated as the activation in \(w_{unknown}\).

</p>
</details>

<details><summary><b>Measuring and Sampling: A Metric-guided Subgraph Learning Framework for Graph Neural Network</b>
<a href="https://arxiv.org/abs/2112.15015">arxiv:2112.15015</a>
&#x1F4C8; 3 <br>
<p>Jiyang Bai, Yuxiang Ren, Jiawei Zhang</p></summary>
<p>

**Abstract:** Graph neural network (GNN) has shown convincing performance in learning powerful node representations that preserve both node attributes and graph structural information. However, many GNNs encounter problems in effectiveness and efficiency when they are designed with a deeper network structure or handle large-sized graphs. Several sampling algorithms have been proposed for improving and accelerating the training of GNNs, yet they ignore understanding the source of GNN performance gain. The measurement of information within graph data can help the sampling algorithms to keep high-value information while removing redundant information and even noise. In this paper, we propose a Metric-Guided (MeGuide) subgraph learning framework for GNNs. MeGuide employs two novel metrics: Feature Smoothness and Connection Failure Distance to guide the subgraph sampling and mini-batch based training. Feature Smoothness is designed for analyzing the feature of nodes in order to retain the most valuable information, while Connection Failure Distance can measure the structural information to control the size of subgraphs. We demonstrate the effectiveness and efficiency of MeGuide in training various GNNs on multiple datasets.

</p>
</details>

<details><summary><b>Soundness in Object-centric Workflow Petri Nets</b>
<a href="https://arxiv.org/abs/2112.14994">arxiv:2112.14994</a>
&#x1F4C8; 3 <br>
<p>Irina A. Lomazova, Alexey A. Mitsyuk, Andrey Rivkin</p></summary>
<p>

**Abstract:** Recently introduced Petri net-based formalisms advocate the importance of proper representation and management of case objects as well as their co-evolution. In this work we build on top of one of such formalisms and introduce the notion of soundness for it. We demonstrate that for nets with non-deterministic synchronization between case objects, the soundness problem is decidable.

</p>
</details>

<details><summary><b>Automatic Mixed-Precision Quantization Search of BERT</b>
<a href="https://arxiv.org/abs/2112.14938">arxiv:2112.14938</a>
&#x1F4C8; 3 <br>
<p>Changsheng Zhao, Ting Hua, Yilin Shen, Qian Lou, Hongxia Jin</p></summary>
<p>

**Abstract:** Pre-trained language models such as BERT have shown remarkable effectiveness in various natural language processing tasks. However, these models usually contain millions of parameters, which prevents them from practical deployment on resource-constrained devices. Knowledge distillation, Weight pruning, and Quantization are known to be the main directions in model compression. However, compact models obtained through knowledge distillation may suffer from significant accuracy drop even for a relatively small compression ratio. On the other hand, there are only a few quantization attempts that are specifically designed for natural language processing tasks. They suffer from a small compression ratio or a large error rate since manual setting on hyper-parameters is required and fine-grained subgroup-wise quantization is not supported. In this paper, we proposed an automatic mixed-precision quantization framework designed for BERT that can simultaneously conduct quantization and pruning in a subgroup-wise level. Specifically, our proposed method leverages Differentiable Neural Architecture Search to assign scale and precision for parameters in each sub-group automatically, and at the same time pruning out redundant groups of parameters. Extensive evaluations on BERT downstream tasks reveal that our proposed method outperforms baselines by providing the same performance with much smaller model size. We also show the feasibility of obtaining the extremely light-weight model by combining our solution with orthogonal methods such as DistilBERT.

</p>
</details>

<details><summary><b>RheFrameDetect: A Text Classification System for Automatic Detection of Rhetorical Frames in AI from Open Sources</b>
<a href="https://arxiv.org/abs/2112.14933">arxiv:2112.14933</a>
&#x1F4C8; 3 <br>
<p>Saurav Ghosh, Philippe Loustaunau</p></summary>
<p>

**Abstract:** Rhetorical Frames in AI can be thought of as expressions that describe AI development as a competition between two or more actors, such as governments or companies. Examples of such Frames include robotic arms race, AI rivalry, technological supremacy, cyberwarfare dominance and 5G race. Detection of Rhetorical Frames from open sources can help us track the attitudes of governments or companies towards AI, specifically whether attitudes are becoming more cooperative or competitive over time. Given the rapidly increasing volumes of open sources (online news media, twitter, blogs), it is difficult for subject matter experts to identify Rhetorical Frames in (near) real-time. Moreover, these sources are in general unstructured (noisy) and therefore, detecting Frames from these sources will require state-of-the-art text classification techniques. In this paper, we develop RheFrameDetect, a text classification system for (near) real-time capture of Rhetorical Frames from open sources. Given an input document, RheFrameDetect employs text classification techniques at multiple levels (document level and paragraph level) to identify all occurrences of Frames used in the discussion of AI. We performed extensive evaluation of the text classification techniques used in RheFrameDetect against human annotated Frames from multiple news sources. To further demonstrate the effectiveness of RheFrameDetect, we show multiple case studies depicting the Frames identified by RheFrameDetect compared against human annotated Frames.

</p>
</details>

<details><summary><b>An Efficient Federated Distillation Learning System for Multi-task Time Series Classification</b>
<a href="https://arxiv.org/abs/2201.00011">arxiv:2201.00011</a>
&#x1F4C8; 2 <br>
<p>Huanlai Xing, Zhiwen Xiao, Rong Qu, Zonghai Zhu, Bowen Zhao</p></summary>
<p>

**Abstract:** This paper proposes an efficient federated distillation learning system (EFDLS) for multi-task time series classification (TSC). EFDLS consists of a central server and multiple mobile users, where different users may run different TSC tasks. EFDLS has two novel components, namely a feature-based student-teacher (FBST) framework and a distance-based weights matching (DBWM) scheme. Within each user, the FBST framework transfers knowledge from its teacher's hidden layers to its student's hidden layers via knowledge distillation, with the teacher and student having identical network structure. For each connected user, its student model's hidden layers' weights are uploaded to the EFDLS server periodically. The DBWM scheme is deployed on the server, with the least square distance used to measure the similarity between the weights of two given models. This scheme finds a partner for each connected user such that the user's and its partner's weights are the closest among all the weights uploaded. The server exchanges and sends back the user's and its partner's weights to these two users which then load the received weights to their teachers' hidden layers. Experimental results show that the proposed EFDLS achieves excellent performance on a set of selected UCR2018 datasets regarding top-1 accuracy.

</p>
</details>

<details><summary><b>Augmentative eXplanation and the Distributional Gap of Confidence Optimization Score</b>
<a href="https://arxiv.org/abs/2201.00009">arxiv:2201.00009</a>
&#x1F4C8; 2 <br>
<p>Erico Tjoa, Hong Jing Khok, Tushar Chouhan, Guan Cuntai</p></summary>
<p>

**Abstract:** This paper introduces the Confidence Optimization (CO) score to directly measure the contribution of heatmaps/saliency maps to the classification performance of a model. Common heatmap generation methods used in the eXplainable Artificial Intelligence (XAI) community are tested through a process we call the Augmentative eXplanation (AX). We find a surprising \textit{gap} in CO scores distribution on these heatmap methods. The gap potentially serves as a novel indicator for the correctness of deep neural network (DNN) prediction. We further introduces Generative AX (GAX) method to generate saliency maps capable of attaining high CO scores. Using GAX, we also qualitatively demonstrate the unintuitiveness of DNN architectures.

</p>
</details>

<details><summary><b>A Lightweight and Accurate Spatial-Temporal Transformer for Traffic Forecasting</b>
<a href="https://arxiv.org/abs/2201.00008">arxiv:2201.00008</a>
&#x1F4C8; 2 <br>
<p>Guanyao Li, Shuhan Zhong, Letian Xiang, S. -H. Gary Chan, Ruiyuan Li, Chih-Chieh Hung, Wen-Chih Peng</p></summary>
<p>

**Abstract:** We study the forecasting problem for traffic with dynamic, possibly periodical, and joint spatial-temporal dependency between regions. Given the aggregated inflow and outflow traffic of regions in a city from time slots 0 to t-1, we predict the traffic at time t at any region. Prior arts in the area often consider the spatial and temporal dependencies in a decoupled manner or are rather computationally intensive in training with a large number of hyper-parameters to tune. We propose ST-TIS, a novel, lightweight, and accurate Spatial-Temporal Transformer with information fusion and region sampling for traffic forecasting. ST-TIS extends the canonical Transformer with information fusion and region sampling. The information fusion module captures the complex spatial-temporal dependency between regions. The region sampling module is to improve the efficiency and prediction accuracy, cutting the computation complexity for dependency learning from $O(n^2)$ to $O(n\sqrt{n})$, where n is the number of regions. With far fewer parameters than state-of-the-art models, the offline training of our model is significantly faster in terms of tuning and computation (with a reduction of up to $90\%$ on training time and network parameters). Notwithstanding such training efficiency, extensive experiments show that ST-TIS is substantially more accurate in online prediction than state-of-the-art approaches (with an average improvement of up to $9.5\%$ on RMSE, and $12.4\%$ on MAPE).

</p>
</details>

<details><summary><b>Confidence-Aware Multi-Teacher Knowledge Distillation</b>
<a href="https://arxiv.org/abs/2201.00007">arxiv:2201.00007</a>
&#x1F4C8; 2 <br>
<p>Hailin Zhang, Defang Chen, Can Wang</p></summary>
<p>

**Abstract:** Knowledge distillation is initially introduced to utilize additional supervision from a single teacher model for the student model training. To boost the student performance, some recent variants attempt to exploit diverse knowledge sources from multiple teachers. However, existing studies mainly integrate knowledge from diverse sources by averaging over multiple teacher predictions or combining them using other various label-free strategies, which may mislead student in the presence of low-quality teacher predictions. To tackle this problem, we propose Confidence-Aware Multi-teacher Knowledge Distillation (CA-MKD), which adaptively assigns sample-wise reliability for each teacher prediction with the help of ground-truth labels, with those teacher predictions close to one-hot labels assigned large weights. Besides, CA-MKD incorporates intermediate layers to further improve student performance. Extensive experiments show that our CA-MKD consistently outperforms all compared state-of-the-art methods across various teacher-student architectures.

</p>
</details>

<details><summary><b>Knowledge intensive state design for traffic signal control</b>
<a href="https://arxiv.org/abs/2201.00006">arxiv:2201.00006</a>
&#x1F4C8; 2 <br>
<p>Liang Zhang, Qiang Wu, Jianming Deng</p></summary>
<p>

**Abstract:** There is a general trend of applying reinforcement learning (RL) techniques for traffic signal control (TSC). Recently, most studies pay attention to the neural network design and rarely concentrate on the state representation. Does the design of state representation has a good impact on TSC? In this paper, we (1) propose an effective state representation as queue length of vehicles with intensive knowledge; (2) present a TSC method called MaxQueue based on our state representation approach; (3) develop a general RL-based TSC template called QL-XLight with queue length as state and reward and generate QL-FRAP, QL-CoLight, and QL-DQN by our QL-XLight template based on traditional and latest RL models.Through comprehensive experiments on multiple real-world datasets, we demonstrate that: (1) our MaxQueue method outperforms the latest RL based methods; (2) QL-FRAP and QL-CoLight achieves a new state-of-the-art (SOTA). In general, state representation with intensive knowledge is also essential for TSC methods. Our code is released on Github.

</p>
</details>

<details><summary><b>Distributed Random Reshuffling over Networks</b>
<a href="https://arxiv.org/abs/2112.15287">arxiv:2112.15287</a>
&#x1F4C8; 2 <br>
<p>Kun Huang, Xiao Li, Andre Milzarek, Shi Pu, Junwen Qiu</p></summary>
<p>

**Abstract:** In this paper, we consider the distributed optimization problem where $n$ agents, each possessing a local cost function, collaboratively minimize the average of the local cost functions over a connected network. To solve the problem, we propose a distributed random reshuffling (D-RR) algorithm that combines the classical distributed gradient descent (DGD) method and Random Reshuffling (RR). We show that D-RR inherits the superiority of RR for both smooth strongly convex and smooth nonconvex objective functions. In particular, for smooth strongly convex objective functions, D-RR achieves $\mathcal{O}(1/T^2)$ rate of convergence (here, $T$ counts the total number of iterations) in terms of the squared distance between the iterate and the unique minimizer. When the objective function is assumed to be smooth nonconvex and has Lipschitz continuous component functions, we show that D-RR drives the squared norm of gradient to $0$ at a rate of $\mathcal{O}(1/T^{2/3})$. These convergence results match those of centralized RR (up to constant factors).

</p>
</details>

<details><summary><b>Learned Coarse Models for Efficient Turbulence Simulation</b>
<a href="https://arxiv.org/abs/2112.15275">arxiv:2112.15275</a>
&#x1F4C8; 2 <br>
<p>Kimberly Stachenfeld, Drummond B. Fielding, Dmitrii Kochkov, Miles Cranmer, Tobias Pfaff, Jonathan Godwin, Can Cui, Shirley Ho, Peter Battaglia, Alvaro Sanchez-Gonzalez</p></summary>
<p>

**Abstract:** Turbulence simulation with classical numerical solvers requires very high-resolution grids to accurately resolve dynamics. Here we train learned simulators at low spatial and temporal resolutions to capture turbulent dynamics generated at high resolution. We show that our proposed model can simulate turbulent dynamics more accurately than classical numerical solvers at the same low resolutions across various scientifically relevant metrics. Our model is trained end-to-end from data and is capable of learning a range of challenging chaotic and turbulent dynamics at low resolution, including trajectories generated by the state-of-the-art Athena++ engine. We show that our simpler, general-purpose architecture outperforms various more specialized, turbulence-specific architectures from the learned turbulence simulation literature. In general, we see that learned simulators yield unstable trajectories; however, we show that tuning training noise and temporal downsampling solves this problem. We also find that while generalization beyond the training distribution is a challenge for learned models, training noise, convolutional architectures, and added loss constraints can help. Broadly, we conclude that our learned simulator outperforms traditional solvers run on coarser grids, and emphasize that simple design choices can offer stability and robust generalization.

</p>
</details>

<details><summary><b>Entropy Regularized Optimal Transport Independence Criterion</b>
<a href="https://arxiv.org/abs/2112.15265">arxiv:2112.15265</a>
&#x1F4C8; 2 <br>
<p>Lang Liu, Soumik Pal, Zaid Harchaoui</p></summary>
<p>

**Abstract:** Optimal transport (OT) and its entropy regularized offspring have recently gained a lot of attention in both machine learning and AI domains. In particular, optimal transport has been used to develop probability metrics between probability distributions. We introduce in this paper an independence criterion based on entropy regularized optimal transport. Our criterion can be used to test for independence between two samples. We establish non-asymptotic bounds for our test statistic, and study its statistical behavior under both the null and alternative hypothesis. Our theoretical results involve tools from U-process theory and optimal transport theory. We present experimental results on existing benchmarks, illustrating the interest of the proposed criterion.

</p>
</details>

<details><summary><b>Studying the Interplay between Information Loss and Operation Loss in Representations for Classification</b>
<a href="https://arxiv.org/abs/2112.15238">arxiv:2112.15238</a>
&#x1F4C8; 2 <br>
<p>Jorge F. Silva, Felipe Tobar, Mario VicuÃ±a, Felipe Cordova</p></summary>
<p>

**Abstract:** Information-theoretic measures have been widely adopted in the design of features for learning and decision problems. Inspired by this, we look at the relationship between i) a weak form of information loss in the Shannon sense and ii) the operation loss in the minimum probability of error (MPE) sense when considering a family of lossy continuous representations (features) of a continuous observation. We present several results that shed light on this interplay. Our first result offers a lower bound on a weak form of information loss as a function of its respective operation loss when adopting a discrete lossy representation (quantization) instead of the original raw observation. From this, our main result shows that a specific form of vanishing information loss (a weak notion of asymptotic informational sufficiency) implies a vanishing MPE loss (or asymptotic operational sufficiency) when considering a general family of lossy continuous representations. Our theoretical findings support the observation that the selection of feature representations that attempt to capture informational sufficiency is appropriate for learning, but this selection is a rather conservative design principle if the intended goal is achieving MPE in classification. Supporting this last point, and under some structural conditions, we show that it is possible to adopt an alternative notion of informational sufficiency (strictly weaker than pure sufficiency in the mutual information sense) to achieve operational sufficiency in learning.

</p>
</details>

<details><summary><b>A general technique for the estimation of farm animal body part weights from CT scans and its applications in a rabbit breeding program</b>
<a href="https://arxiv.org/abs/2112.15095">arxiv:2112.15095</a>
&#x1F4C8; 2 <br>
<p>ÃdÃ¡m CsÃ³ka, GyÃ¶rgy KovÃ¡cs, VirÃ¡g Ãcs, Zsolt Matics, Zsolt GerencsÃ©r, Zsolt SzendrÅ, IstvÃ¡n Nagy, Ãrs PetnehÃ¡zy, Imre Repa, Mariann Moizs, TamÃ¡s DonkÃ³</p></summary>
<p>

**Abstract:** Various applications of farm animal imaging are based on the estimation of weights of certain body parts and cuts from the CT images of animals. In many cases, the complexity of the problem is increased by the enormous variability of postures in CT images due to the scanning of non-sedated, living animals. In this paper, we propose a general and robust approach for the estimation of the weights of cuts and body parts from the CT images of (possibly) living animals. We adapt multi-atlas based segmentation driven by elastic registration and joint feature and model selection for the regression component to cape with the large number of features and low number of samples. The proposed technique is evaluated and illustrated through real applications in rabbit breeding programs, showing r^2 scores 12% higher than previous techniques and methods that used to drive the selection so far. The proposed technique is easily adaptable to similar problems, consequently, it is shared in an open source software package for the benefit of the community.

</p>
</details>

<details><summary><b>Bayesian Algorithms Learn to Stabilize Unknown Continuous-Time Systems</b>
<a href="https://arxiv.org/abs/2112.15094">arxiv:2112.15094</a>
&#x1F4C8; 2 <br>
<p>Mohamad Kazem Shirani Faradonbeh, Mohamad Sadegh Shirani Faradonbeh</p></summary>
<p>

**Abstract:** Linear dynamical systems are canonical models for learning-based control of plants with uncertain dynamics. The setting consists of a stochastic differential equation that captures the state evolution of the plant understudy, while the true dynamics matrices are unknown and need to be learned from the observed data of state trajectory. An important issue is to ensure that the system is stabilized and destabilizing control actions due to model uncertainties are precluded as soon as possible. A reliable stabilization procedure for this purpose that can effectively learn from unstable data to stabilize the system in a finite time is not currently available. In this work, we propose a novel Bayesian learning algorithm that stabilizes unknown continuous-time stochastic linear systems. The presented algorithm is flexible and exposes effective stabilization performance after a remarkably short time period of interacting with the system.

</p>
</details>

<details><summary><b>Digital Rock Typing DRT Algorithm Formulation with Optimal Supervised Semantic Segmentation</b>
<a href="https://arxiv.org/abs/2112.15068">arxiv:2112.15068</a>
&#x1F4C8; 2 <br>
<p>Omar Alfarisi, Djamel Ouzzane, Mohamed Sassi, Tiejun Zhang</p></summary>
<p>

**Abstract:** Each grid block in a 3D geological model requires a rock type that represents all physical and chemical properties of that block. The properties that classify rock types are lithology, permeability, and capillary pressure. Scientists and engineers determined these properties using conventional laboratory measurements, which embedded destructive methods to the sample or altered some of its properties (i.e., wettability, permeability, and porosity) because the measurements process includes sample crushing, fluid flow, or fluid saturation. Lately, Digital Rock Physics (DRT) has emerged to quantify these properties from micro-Computerized Tomography (uCT) and Magnetic Resonance Imaging (MRI) images. However, the literature did not attempt rock typing in a wholly digital context. We propose performing Digital Rock Typing (DRT) by: (1) integrating the latest DRP advances in a novel process that honors digital rock properties determination, while; (2) digitalizing the latest rock typing approaches in carbonate, and (3) introducing a novel carbonate rock typing process that utilizes computer vision capabilities to provide more insight about the heterogeneous carbonate rock texture.

</p>
</details>

<details><summary><b>Development of a face mask detection pipeline for mask-wearing monitoring in the era of the COVID-19 pandemic: A modular approach</b>
<a href="https://arxiv.org/abs/2112.15031">arxiv:2112.15031</a>
&#x1F4C8; 2 <br>
<p>Benjaphan Sommana, Ukrit Watchareeruetai, Ankush Ganguly, Samuel W. F. Earp, Taya Kitiyakara, Suparee Boonmanunt, Ratchainant Thammasudjarit</p></summary>
<p>

**Abstract:** During the SARS-Cov-2 pandemic, mask-wearing became an effective tool to prevent spreading and contracting the virus. The ability to monitor the mask-wearing rate in the population would be useful for determining public health strategies against the virus. However, artificial intelligence technologies for detecting face masks have not been deployed at a large scale in real-life to measure the mask-wearing rate in public. In this paper, we present a two-step face mask detection approach consisting of two separate modules: 1) face detection and alignment and 2) face mask classification. This approach allowed us to experiment with different combinations of face detection and face mask classification modules. More specifically, we experimented with PyramidKey and RetinaFace as face detectors while maintaining a lightweight backbone for the face mask classification module. Moreover, we also provide a relabeled annotation of the test set of the AIZOO dataset, where we rectified the incorrect labels for some face images. The evaluation results on the AIZOO and Moxa 3K datasets showed that the proposed face mask detection pipeline surpassed the state-of-the-art methods. The proposed pipeline also yielded a higher mAP on the relabeled test set of the AIZOO dataset than the original test set. Since we trained the proposed model using in-the-wild face images, we can successfully deploy our model to monitor the mask-wearing rate using public CCTV images.

</p>
</details>

<details><summary><b>Radiology Report Generation with a Learned Knowledge Base and Multi-modal Alignment</b>
<a href="https://arxiv.org/abs/2112.15011">arxiv:2112.15011</a>
&#x1F4C8; 2 <br>
<p>Shuxin Yang, Xian Wu, Shen Ge, Xingwang Wu, S. Kevin Zhou, Li Xiao</p></summary>
<p>

**Abstract:** In clinics, a radiology report is crucial for guiding a patient's treatment. Unfortunately, report writing imposes a heavy burden on radiologists. To effectively reduce such a burden, we hereby present an automatic, multi-modal approach for report generation from chest x-ray. Our approach, motivated by the observation that the descriptions in radiology reports are highly correlated with the x-ray images, features two distinct modules: (i) Learned knowledge base. To absorb the knowledge embedded in the above-mentioned correlation, we automatically build a knowledge base based on textual embedding. (ii) Multi-modal alignment. To promote the semantic alignment among reports, disease labels and images, we explicitly utilize textual embedding to guide the learning of the visual feature space. We evaluate the performance of the proposed model using metrics from both natural language generation and clinic efficacy on the public IU and MIMIC-CXR datasets. Our ablation study shows that each module contributes to improving the quality of generated reports. Furthermore, with the aid of both modules, our approach clearly outperforms state-of-the-art methods.

</p>
</details>

<details><summary><b>Knowledge Matters: Radiology Report Generation with General and Specific Knowledge</b>
<a href="https://arxiv.org/abs/2112.15009">arxiv:2112.15009</a>
&#x1F4C8; 2 <br>
<p>Shuxin Yang, Xian Wu, Shen Ge, Shaohua Kevin Zhou, Li Xiao</p></summary>
<p>

**Abstract:** Automatic radiology report generation is critical in clinics which can relieve experienced radiologists from the heavy workload and remind inexperienced radiologists of misdiagnosis or missed diagnose. Existing approaches mainly formulate radiology report generation as an image captioning task and adopt the encoder-decoder framework. However, in the medical domain, such pure data-driven approaches suffer from the following problems: 1) visual and textual bias problem; 2) lack of expert knowledge. In this paper, we propose a knowledge-enhanced radiology report generation approach introduces two types of medical knowledge: 1) General knowledge, which is input independent and provides the broad knowledge for report generation; 2) Specific knowledge, which is input dependent and provides the fine-grained knowledge for report generation. To fully utilize both the general and specific knowledge, we also propose a knowledge-enhanced multi-head attention mechanism. By merging the visual features of the radiology image with general knowledge and specific knowledge, the proposed model can improve the quality of generated reports. Experimental results on two publicly available datasets IU-Xray and MIMIC-CXR show that the proposed knowledge enhanced approach outperforms state-of-the-art image captioning based methods. Ablation studies also demonstrate that both general and specific knowledge can help to improve the performance of radiology report generation.

</p>
</details>

<details><summary><b>Exploring the pattern of Emotion in children with ASD as an early biomarker through Recurring-Convolution Neural Network (R-CNN)</b>
<a href="https://arxiv.org/abs/2112.14983">arxiv:2112.14983</a>
&#x1F4C8; 2 <br>
<p>Abirami S P, Kousalya G, Karthick R</p></summary>
<p>

**Abstract:** Autism Spectrum Disorder (ASD) is found to be a major concern among various occupational therapists. The foremost challenge of this neurodevelopmental disorder lies in the fact of analyzing and exploring various symptoms of the children at their early stage of development. Such early identification could prop up the therapists and clinicians to provide proper assistive support to make the children lead an independent life. Facial expressions and emotions perceived by the children could contribute to such early intervention of autism. In this regard, the paper implements in identifying basic facial expression and exploring their emotions upon a time variant factor. The emotions are analyzed by incorporating the facial expression identified through CNN using 68 landmark points plotted on the frontal face with a prediction network formed by RNN known as RCNN-FER system. The paper adopts R-CNN to take the advantage of increased accuracy and performance with decreased time complexity in predicting emotion as a textual network analysis. The papers proves better accuracy in identifying the emotion in autistic children when compared over simple machine learning models built for such identifications contributing to autistic society.

</p>
</details>

<details><summary><b>Decentralized Optimization Over the Stiefel Manifold by an Approximate Augmented Lagrangian Function</b>
<a href="https://arxiv.org/abs/2112.14949">arxiv:2112.14949</a>
&#x1F4C8; 2 <br>
<p>Lei Wang, Xin Liu</p></summary>
<p>

**Abstract:** In this paper, we focus on the decentralized optimization problem over the Stiefel manifold, which is defined on a connected network of $d$ agents. The objective is an average of $d$ local functions, and each function is privately held by an agent and encodes its data. The agents can only communicate with their neighbors in a collaborative effort to solve this problem. In existing methods, multiple rounds of communications are required to guarantee the convergence, giving rise to high communication costs. In contrast, this paper proposes a decentralized algorithm, called DESTINY, which only invokes a single round of communications per iteration. DESTINY combines gradient tracking techniques with a novel approximate augmented Lagrangian function. The global convergence to stationary points is rigorously established. Comprehensive numerical experiments demonstrate that DESTINY has a strong potential to deliver a cutting-edge performance in solving a variety of testing problems.

</p>
</details>

<details><summary><b>Accelerated Primal-Dual Gradient Method for Smooth and Convex-Concave Saddle-Point Problems with Bilinear Coupling</b>
<a href="https://arxiv.org/abs/2112.15199">arxiv:2112.15199</a>
&#x1F4C8; 1 <br>
<p>Dmitry Kovalev, Alexander Gasnikov, Peter RichtÃ¡rik</p></summary>
<p>

**Abstract:** In this paper we study a convex-concave saddle-point problem $\min_x\max_y f(x) + y^\top\mathbf{A} x - g(y)$, where $f(x)$ and $g(y)$ are smooth and convex functions. We propose an Accelerated Primal-Dual Gradient Method for solving this problem which (i) achieves an optimal linear convergence rate in the strongly-convex-strongly-concave regime matching the lower complexity bound (Zhang et al., 2021) and (ii) achieves an accelerated linear convergence rate in the case when only one of the functions $f(x)$ and $g(y)$ is strongly convex or even none of them are. Finally, we obtain a linearly-convergent algorithm for the general smooth and convex-concave saddle point problem $\min_x\max_y F(x,y)$ without requirement of strong convexity or strong concavity.

</p>
</details>

<details><summary><b>A Resolution Enhancement Plug-in for Deformable Registration of Medical Images</b>
<a href="https://arxiv.org/abs/2112.15180">arxiv:2112.15180</a>
&#x1F4C8; 1 <br>
<p>Kaicong Sun, Sven Simon</p></summary>
<p>

**Abstract:** Image registration is a fundamental task for medical imaging. Resampling of the intensity values is required during registration and better spatial resolution with finer and sharper structures can improve the resampling performance and hence the registration accuracy. Super-resolution (SR) is an algorithmic technique targeting at spatial resolution enhancement which can achieve an image resolution beyond the hardware limitation. In this work, we consider SR as a preprocessing technique and present a CNN-based resolution enhancement module (REM) which can be easily plugged into the registration network in a cascaded manner. Different residual schemes and network configurations of REM are investigated to obtain an effective architecture design of REM. In fact, REM is not confined to image registration, it can also be straightforwardly integrated into other vision tasks for enhanced resolution. The proposed REM is thoroughly evaluated for deformable registration on medical images quantitatively and qualitatively at different upscaling factors. Experiments on LPBA40 brain MRI dataset demonstrate that REM not only improves the registration accuracy, especially when the input images suffer from degraded spatial resolution, but also generates resolution enhanced images which can be exploited for successive diagnosis.

</p>
</details>

<details><summary><b>Chatbot for fitness management using IBM Watson</b>
<a href="https://arxiv.org/abs/2112.15167">arxiv:2112.15167</a>
&#x1F4C8; 1 <br>
<p>Sai Rugved Lola, Rahul Dhadvai, Wei Wang, Ting Zhu</p></summary>
<p>

**Abstract:** Chatbots have revolutionized the way humans interact with computer systems and they have substituted the use of service agents, call-center representatives etc. Fitness industry has always been a growing industry although it has not adapted to the latest technologies like AI, ML and cloud computing. In this paper, we propose an idea to develop a chatbot for fitness management using IBM Watson and integrate it with a web application. We proposed using Natural Language Processing (NLP) and Natural Language Understanding (NLU) along with frameworks of IBM Cloud Watson provided for the Chatbot Assistant. This software uses a serverless architecture to combine the services of a professional by offering diet plans, home exercises, interactive counseling sessions, fitness recommendations.

</p>
</details>

<details><summary><b>Colour alignment for relative colour constancy via non-standard references</b>
<a href="https://arxiv.org/abs/2112.15106">arxiv:2112.15106</a>
&#x1F4C8; 1 <br>
<p>Yunfeng Zhao, Stuart Ferguson, Huiyu Zhou, Chris Elliott, Karen Rafferty</p></summary>
<p>

**Abstract:** Relative colour constancy is an essential requirement for many scientific imaging applications. However, most digital cameras differ in their image formations and native sensor output is usually inaccessible, e.g., in smartphone camera applications. This makes it hard to achieve consistent colour assessment across a range of devices, and that undermines the performance of computer vision algorithms. To resolve this issue, we propose a colour alignment model that considers the camera image formation as a black-box and formulates colour alignment as a three-step process: camera response calibration, response linearisation, and colour matching. The proposed model works with non-standard colour references, i.e., colour patches without knowing the true colour values, by utilising a novel balance-of-linear-distances feature. It is equivalent to determining the camera parameters through an unsupervised process. It also works with a minimum number of corresponding colour patches across the images to be colour aligned to deliver the applicable processing. Two challenging image datasets collected by multiple cameras under various illumination and exposure conditions were used to evaluate the model. Performance benchmarks demonstrated that our model achieved superior performance compared to other popular and state-of-the-art methods.

</p>
</details>

<details><summary><b>Contrastive Learning of Semantic and Visual Representations for Text Tracking</b>
<a href="https://arxiv.org/abs/2112.14976">arxiv:2112.14976</a>
&#x1F4C8; 1 <br>
<p>Zhuang Li, Weijia Wu, Mike Zheng Shou, Jiahong Li, Size Li, Zhongyuan Wang, Hong Zhou</p></summary>
<p>

**Abstract:** Semantic representation is of great benefit to the video text tracking(VTT) task that requires simultaneously classifying, detecting, and tracking texts in the video. Most existing approaches tackle this task by appearance similarity in continuous frames, while ignoring the abundant semantic features. In this paper, we explore to robustly track video text with contrastive learning of semantic and visual representations. Correspondingly, we present an end-to-end video text tracker with Semantic and Visual Representations(SVRep), which detects and tracks texts by exploiting the visual and semantic relationships between different texts in a video sequence. Besides, with a light-weight architecture, SVRep achieves state-of-the-art performance while maintaining competitive inference speed. Specifically, with a backbone of ResNet-18, SVRep achieves an ${\rm ID_{F1}}$ of $\textbf{65.9\%}$, running at $\textbf{16.7}$ FPS, on the ICDAR2015(video) dataset with $\textbf{8.6\%}$ improvement than the previous state-of-the-art methods.

</p>
</details>

<details><summary><b>Dense Depth Estimation from Multiple 360-degree Images Using Virtual Depth</b>
<a href="https://arxiv.org/abs/2112.14931">arxiv:2112.14931</a>
&#x1F4C8; 1 <br>
<p>Seongyeop Yang, Kunhee Kim, Yeejin Lee</p></summary>
<p>

**Abstract:** In this paper, we propose a dense depth estimation pipeline for multiview 360\degree\: images. The proposed pipeline leverages a spherical camera model that compensates for radial distortion in 360\degree\: images. The key contribution of this paper is the extension of a spherical camera model to multiview by introducing a translation scaling scheme. Moreover, we propose an effective dense depth estimation method by setting virtual depth and minimizing photonic reprojection error. We validate the performance of the proposed pipeline using the images of natural scenes as well as the synthesized dataset for quantitive evaluation. The experimental results verify that the proposed pipeline improves estimation accuracy compared to the current state-of-art dense depth estimation methods.

</p>
</details>

<details><summary><b>Semantic Communications: Principles and Challenges</b>
<a href="https://arxiv.org/abs/2201.01389">arxiv:2201.01389</a>
&#x1F4C8; 0 <br>
<p>Zhijin Qin, Xiaoming Tao, Jianhua Lu, Geoffrey Ye Li</p></summary>
<p>

**Abstract:** Semantic communication, regarded as the breakthrough beyond Shannon paradigm, aims at the successful transmission of semantic information conveyed by the source rather than the accurate reception of each single symbol or bit regardless of its meaning. This article provides an overview on semantic communications. After a brief review on Shannon information theory, we discuss semantic communications with theory, frameworks, and system design enabled by deep learning. Different from the symbol/bit error rate used for measuring the conventional communication systems, new performance metrics for semantic communications are also discussed. The article is concluded by several open questions.

</p>
</details>

<details><summary><b>An Intelligent Self-driving Truck System For Highway Transportation</b>
<a href="https://arxiv.org/abs/2112.15304">arxiv:2112.15304</a>
&#x1F4C8; 0 <br>
<p>Dawei Wang, Lingping Gao, Ziquan Lan, Wei Li, Jiaping Ren, Jiahui Zhang, Peng Zhang, Pei Zhou, Shengao Wang, Jia Pan, Dinesh Manocha, Ruigang Yang</p></summary>
<p>

**Abstract:** Recently, there have been many advances in autonomous driving society, attracting a lot of attention from academia and industry. However, existing works mainly focus on cars, extra development is still required for self-driving truck algorithms and models. In this paper, we introduce an intelligent self-driving truck system. Our presented system consists of three main components, 1) a realistic traffic simulation module for generating realistic traffic flow in testing scenarios, 2) a high-fidelity truck model which is designed and evaluated for mimicking real truck response in real-world deployment, 3) an intelligent planning module with learning-based decision making algorithm and multi-mode trajectory planner, taking into account the truck's constraints, road slope changes, and the surrounding traffic flow. We provide quantitative evaluations for each component individually to demonstrate the fidelity and performance of each part. We also deploy our proposed system on a real truck and conduct real world experiments which shows our system's capacity of mitigating sim-to-real gap. Our code is available at https://github.com/InceptioResearch/IITS

</p>
</details>


{% endraw %}
Prev: [2021.12.29]({{ '/2021/12/29/2021.12.29.html' | relative_url }})  Next: [2021.12.31]({{ '/2021/12/31/2021.12.31.html' | relative_url }})