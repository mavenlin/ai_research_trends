## Summary for 2021-04-26, created on 2021-12-22


<details><summary><b>MDETR -- Modulated Detection for End-to-End Multi-Modal Understanding</b>
<a href="https://arxiv.org/abs/2104.12763">arxiv:2104.12763</a>
&#x1F4C8; 60 <br>
<p>Aishwarya Kamath, Mannat Singh, Yann LeCun, Gabriel Synnaeve, Ishan Misra, Nicolas Carion</p></summary>
<p>

**Abstract:** Multi-modal reasoning systems rely on a pre-trained object detector to extract regions of interest from the image. However, this crucial module is typically used as a black box, trained independently of the downstream task and on a fixed vocabulary of objects and attributes. This makes it challenging for such systems to capture the long tail of visual concepts expressed in free form text. In this paper we propose MDETR, an end-to-end modulated detector that detects objects in an image conditioned on a raw text query, like a caption or a question. We use a transformer-based architecture to reason jointly over text and image by fusing the two modalities at an early stage of the model. We pre-train the network on 1.3M text-image pairs, mined from pre-existing multi-modal datasets having explicit alignment between phrases in text and objects in the image. We then fine-tune on several downstream tasks such as phrase grounding, referring expression comprehension and segmentation, achieving state-of-the-art results on popular benchmarks. We also investigate the utility of our model as an object detector on a given label set when fine-tuned in a few-shot setting. We show that our pre-training approach provides a way to handle the long tail of object categories which have very few labelled instances. Our approach can be easily extended for visual question answering, achieving competitive performance on GQA and CLEVR. The code and models are available at https://github.com/ashkamath/mdetr.

</p>
</details>

<details><summary><b>EigenGAN: Layer-Wise Eigen-Learning for GANs</b>
<a href="https://arxiv.org/abs/2104.12476">arxiv:2104.12476</a>
&#x1F4C8; 42 <br>
<p>Zhenliang He, Meina Kan, Shiguang Shan</p></summary>
<p>

**Abstract:** Recent studies on Generative Adversarial Network (GAN) reveal that different layers of a generative CNN hold different semantics of the synthesized images. However, few GAN models have explicit dimensions to control the semantic attributes represented in a specific layer. This paper proposes EigenGAN which is able to unsupervisedly mine interpretable and controllable dimensions from different generator layers. Specifically, EigenGAN embeds one linear subspace with orthogonal basis into each generator layer. Via generative adversarial training to learn a target distribution, these layer-wise subspaces automatically discover a set of "eigen-dimensions" at each layer corresponding to a set of semantic attributes or interpretable variations. By traversing the coefficient of a specific eigen-dimension, the generator can produce samples with continuous changes corresponding to a specific semantic attribute. Taking the human face for example, EigenGAN can discover controllable dimensions for high-level concepts such as pose and gender in the subspace of deep layers, as well as low-level concepts such as hue and color in the subspace of shallow layers. Moreover, in the linear case, we theoretically prove that our algorithm derives the principal components as PCA does. Codes can be found in https://github.com/LynnHo/EigenGAN-Tensorflow.

</p>
</details>

<details><summary><b>CompOFA: Compound Once-For-All Networks for Faster Multi-Platform Deployment</b>
<a href="https://arxiv.org/abs/2104.12642">arxiv:2104.12642</a>
&#x1F4C8; 16 <br>
<p>Manas Sahni, Shreya Varshini, Alind Khare, Alexey Tumanov</p></summary>
<p>

**Abstract:** The emergence of CNNs in mainstream deployment has necessitated methods to design and train efficient architectures tailored to maximize the accuracy under diverse hardware & latency constraints. To scale these resource-intensive tasks with an increasing number of deployment targets, Once-For-All (OFA) proposed an approach to jointly train several models at once with a constant training cost. However, this cost remains as high as 40-50 GPU days and also suffers from a combinatorial explosion of sub-optimal model configurations. We seek to reduce this search space -- and hence the training budget -- by constraining search to models close to the accuracy-latency Pareto frontier. We incorporate insights of compound relationships between model dimensions to build CompOFA, a design space smaller by several orders of magnitude. Through experiments on ImageNet, we demonstrate that even with simple heuristics we can achieve a 2x reduction in training time and 216x speedup in model search/extraction time compared to the state of the art, without loss of Pareto optimality! We also show that this smaller design space is dense enough to support equally accurate models for a similar diversity of hardware and latency targets, while also reducing the complexity of the training and subsequent extraction algorithms.

</p>
</details>

<details><summary><b>Towards Rigorous Interpretations: a Formalisation of Feature Attribution</b>
<a href="https://arxiv.org/abs/2104.12437">arxiv:2104.12437</a>
&#x1F4C8; 16 <br>
<p>Darius Afchar, Romain Hennequin, Vincent Guigue</p></summary>
<p>

**Abstract:** Feature attribution is often loosely presented as the process of selecting a subset of relevant features as a rationale of a prediction. Task-dependent by nature, precise definitions of "relevance" encountered in the literature are however not always consistent. This lack of clarity stems from the fact that we usually do not have access to any notion of ground-truth attribution and from a more general debate on what good interpretations are. In this paper we propose to formalise feature selection/attribution based on the concept of relaxed functional dependence. In particular, we extend our notions to the instance-wise setting and derive necessary properties for candidate selection solutions, while leaving room for task-dependence. By computing ground-truth attributions on synthetic datasets, we evaluate many state-of-the-art attribution methods and show that, even when optimised, some fail to verify the proposed properties and provide wrong solutions.

</p>
</details>

<details><summary><b>Multi-Task Learning for End-to-End ASR Word and Utterance Confidence with Deletion Prediction</b>
<a href="https://arxiv.org/abs/2104.12870">arxiv:2104.12870</a>
&#x1F4C8; 13 <br>
<p>David Qiu, Yanzhang He, Qiujia Li, Yu Zhang, Liangliang Cao, Ian McGraw</p></summary>
<p>

**Abstract:** Confidence scores are very useful for downstream applications of automatic speech recognition (ASR) systems. Recent works have proposed using neural networks to learn word or utterance confidence scores for end-to-end ASR. In those studies, word confidence by itself does not model deletions, and utterance confidence does not take advantage of word-level training signals. This paper proposes to jointly learn word confidence, word deletion, and utterance confidence. Empirical results show that multi-task learning with all three objectives improves confidence metrics (NCE, AUC, RMSE) without the need for increasing the model size of the confidence estimation module. Using the utterance-level confidence for rescoring also decreases the word error rates on Google's Voice Search and Long-tail Maps datasets by 3-5% relative, without needing a dedicated neural rescorer.

</p>
</details>

<details><summary><b>GPT2MVS: Generative Pre-trained Transformer-2 for Multi-modal Video Summarization</b>
<a href="https://arxiv.org/abs/2104.12465">arxiv:2104.12465</a>
&#x1F4C8; 12 <br>
<p>Jia-Hong Huang, Luka Murn, Marta Mrak, Marcel Worring</p></summary>
<p>

**Abstract:** Traditional video summarization methods generate fixed video representations regardless of user interest. Therefore such methods limit users' expectations in content search and exploration scenarios. Multi-modal video summarization is one of the methods utilized to address this problem. When multi-modal video summarization is used to help video exploration, a text-based query is considered as one of the main drivers of video summary generation, as it is user-defined. Thus, encoding the text-based query and the video effectively are both important for the task of multi-modal video summarization. In this work, a new method is proposed that uses a specialized attention network and contextualized word representations to tackle this task. The proposed model consists of a contextualized video summary controller, multi-modal attention mechanisms, an interactive attention network, and a video summary generator. Based on the evaluation of the existing multi-modal video summarization benchmark, experimental results show that the proposed model is effective with the increase of +5.88% in accuracy and +4.06% increase of F1-score, compared with the state-of-the-art method.

</p>
</details>

<details><summary><b>DABT: A Dependency-aware Bug Triaging Method</b>
<a href="https://arxiv.org/abs/2104.12744">arxiv:2104.12744</a>
&#x1F4C8; 9 <br>
<p>Hadi Jahanshahi, Kritika Chhabra, Mucahit Cevik, Ayşe Başar</p></summary>
<p>

**Abstract:** In software engineering practice, fixing a bug promptly reduces the associated costs. On the other hand, the manual bug fixing process can be time-consuming, cumbersome, and error-prone. In this work, we introduce a bug triaging method, called Dependency-aware Bug Triaging (DABT), which leverages natural language processing and integer programming to assign bugs to appropriate developers. Unlike previous works that mainly focus on one aspect of the bug reports, DABT considers the textual information, cost associated with each bug, and dependency among them. Therefore, this comprehensive formulation covers the most important aspect of the previous works while considering the blocking effect of the bugs. We report the performance of the algorithm on three open-source software systems, i.e., EclipseJDT, LibreOffice, and Mozilla. Our result shows that DABT is able to reduce the number of overdue bugs up to 12\%. It also decreases the average fixing time of the bugs by half. Moreover, it reduces the complexity of the bug dependency graph by prioritizing blocking bugs.

</p>
</details>

<details><summary><b>Points2Sound: From mono to binaural audio using 3D point cloud scenes</b>
<a href="https://arxiv.org/abs/2104.12462">arxiv:2104.12462</a>
&#x1F4C8; 9 <br>
<p>Francesc Lluís, Vasileios Chatziioannou, Alex Hofmann</p></summary>
<p>

**Abstract:** For immersive applications, the generation of binaural sound that matches the visual counterpart is crucial to bring meaningful experiences to people in a virtual environment. Recent works have shown the possibility to use neural networks for synthesizing binaural audio from mono audio using 2D visual information as guidance. Extending this approach by guiding the audio using 3D visual information and operating in the waveform domain may allow for a more accurate auralization of a virtual audio scene. In this paper, we present Points2Sound, a multi-modal deep learning model which generates a binaural version from mono audio using 3D point cloud scenes. Specifically, Points2Sound consists of a vision network with 3D sparse convolutions which extracts visual features from the point cloud scene to condition an audio network, which operates in the waveform domain, to synthesize the binaural version. Experimental results indicate that 3D visual information can successfully guide multi-modal deep learning models for the task of binaural synthesis. In addition, we investigate different loss functions and 3D point cloud attributes, showing that directly predicting the full binaural signal and using rgb-depth features increases the performance of our proposed model.

</p>
</details>

<details><summary><b>Phrase break prediction with bidirectional encoder representations in Japanese text-to-speech synthesis</b>
<a href="https://arxiv.org/abs/2104.12395">arxiv:2104.12395</a>
&#x1F4C8; 9 <br>
<p>Kosuke Futamata, Byeongseon Park, Ryuichi Yamamoto, Kentaro Tachibana</p></summary>
<p>

**Abstract:** We propose a novel phrase break prediction method that combines implicit features extracted from a pre-trained large language model, a.k.a BERT, and explicit features extracted from BiLSTM with linguistic features. In conventional BiLSTM based methods, word representations and/or sentence representations are used as independent components. The proposed method takes account of both representations to extract the latent semantics, which cannot be captured by previous methods. The objective evaluation results show that the proposed method obtains an absolute improvement of 3.2 points for the F1 score compared with BiLSTM-based conventional methods using linguistic features. Moreover, the perceptual listening test results verify that a TTS system that applied our proposed method achieved a mean opinion score of 4.39 in prosody naturalness, which is highly competitive with the score of 4.37 for synthesized speech with ground-truth phrase breaks.

</p>
</details>

<details><summary><b>Adapting ImageNet-scale models to complex distribution shifts with self-learning</b>
<a href="https://arxiv.org/abs/2104.12928">arxiv:2104.12928</a>
&#x1F4C8; 7 <br>
<p>Evgenia Rusak, Steffen Schneider, Peter Gehler, Oliver Bringmann, Wieland Brendel, Matthias Bethge</p></summary>
<p>

**Abstract:** While self-learning methods are an important component in many recent domain adaptation techniques, they are not yet comprehensively evaluated on ImageNet-scale datasets common in robustness research. In extensive experiments on ResNet and EfficientNet models, we find that three components are crucial for increasing performance with self-learning: (i) using short update times between the teacher and the student network, (ii) fine-tuning only few affine parameters distributed across the network, and (iii) leveraging methods from robust classification to counteract the effect of label noise. We use these insights to obtain drastically improved state-of-the-art results on ImageNet-C (22.0% mCE), ImageNet-R (17.4% error) and ImageNet-A (14.8% error). Our techniques yield further improvements in combination with previously proposed robustification methods. Self-learning is able to reduce the top-1 error to a point where no substantial further progress can be expected. We therefore re-purpose the dataset from the Visual Domain Adaptation Challenge 2019 and use a subset of it as a new robustness benchmark (ImageNet-D) which proves to be a more challenging dataset for all current state-of-the-art models (58.2% error) to guide future research efforts at the intersection of robustness and domain adaptation on ImageNet scale.

</p>
</details>

<details><summary><b>One Billion Audio Sounds from GPU-enabled Modular Synthesis</b>
<a href="https://arxiv.org/abs/2104.12922">arxiv:2104.12922</a>
&#x1F4C8; 7 <br>
<p>Joseph Turian, Jordie Shier, George Tzanetakis, Kirk McNally, Max Henry</p></summary>
<p>

**Abstract:** We release synth1B1, a multi-modal audio corpus consisting of 1 billion 4-second synthesized sounds, paired with the synthesis parameters used to generate them. The dataset is 100x larger than any audio dataset in the literature. We also introduce torchsynth, an open source modular synthesizer that generates the synth1B1 samples on-the-fly at 16200x faster than real-time (714MHz) on a single GPU. Finally, we release two new audio datasets: FM synth timbre and subtractive synth pitch. Using these datasets, we demonstrate new rank-based evaluation criteria for existing audio representations. Finally, we propose a novel approach to synthesizer hyperparameter optimization.

</p>
</details>

<details><summary><b>TrustyAI Explainability Toolkit</b>
<a href="https://arxiv.org/abs/2104.12717">arxiv:2104.12717</a>
&#x1F4C8; 7 <br>
<p>Rob Geada, Tommaso Teofili, Rui Vieira, Rebecca Whitworth, Daniele Zonca</p></summary>
<p>

**Abstract:** Artificial intelligence (AI) is becoming increasingly more popular and can be found in workplaces and homes around the world. However, how do we ensure trust in these systems? Regulation changes such as the GDPR mean that users have a right to understand how their data has been processed as well as saved. Therefore if, for example, you are denied a loan you have the right to ask why. This can be hard if the method for working this out uses "black box" machine learning techniques such as neural networks. TrustyAI is a new initiative which looks into explainable artificial intelligence (XAI) solutions to address trustworthiness in ML as well as decision services landscapes.
  In this paper we will look at how TrustyAI can support trust in decision services and predictive models. We investigate techniques such as LIME, SHAP and counterfactuals, benchmarking both LIME and counterfactual techniques against existing implementations. We also look into an extended version of SHAP, which supports background data selection to be evaluated based on quantitative data and allows for error bounds.

</p>
</details>

<details><summary><b>Good Artists Copy, Great Artists Steal: Model Extraction Attacks Against Image Translation Generative Adversarial Networks</b>
<a href="https://arxiv.org/abs/2104.12623">arxiv:2104.12623</a>
&#x1F4C8; 7 <br>
<p>Sebastian Szyller, Vasisht Duddu, Tommi Gröndahl, N. Asokan</p></summary>
<p>

**Abstract:** Machine learning models are typically made available to potential client users via inference APIs. Model extraction attacks occur when a malicious client uses information gleaned from queries to the inference API of a victim model $F_V$ to build a surrogate model $F_A$ that has comparable functionality. Recent research has shown successful model extraction attacks against image classification, and NLP models. In this paper, we show the first model extraction attack against real-world generative adversarial network (GAN) image translation models. We present a framework for conducting model extraction attacks against image translation models, and show that the adversary can successfully extract functional surrogate models. The adversary is not required to know $F_V$'s architecture or any other information about it beyond its intended image translation task, and queries $F_V$'s inference interface using data drawn from the same domain as the training data for $F_V$. We evaluate the effectiveness of our attacks using three different instances of two popular categories of image translation: (1) Selfie-to-Anime and (2) Monet-to-Photo (image style transfer), and (3) Super-Resolution (super resolution). Using standard performance metrics for GANs, we show that our attacks are effective in each of the three cases -- the differences between $F_V$ and $F_A$, compared to the target are in the following ranges: Selfie-to-Anime: FID $13.36-68.66$, Monet-to-Photo: FID $3.57-4.40$, and Super-Resolution: SSIM: $0.06-0.08$ and PSNR: $1.43-4.46$. Furthermore, we conducted a large scale (125 participants) user study on Selfie-to-Anime and Monet-to-Photo to show that human perception of the images produced by the victim and surrogate models can be considered equivalent, within an equivalence bound of Cohen's $d=0.3$.

</p>
</details>

<details><summary><b>A deep learning model for gastric diffuse-type adenocarcinoma classification in whole slide images</b>
<a href="https://arxiv.org/abs/2104.12478">arxiv:2104.12478</a>
&#x1F4C8; 7 <br>
<p>Fahdi Kanavati, Masayuki Tsuneki</p></summary>
<p>

**Abstract:** Gastric diffuse-type adenocarcinoma represents a disproportionately high percentage of cases of gastric cancers occurring in the young, and its relative incidence seems to be on the rise. Usually it affects the body of the stomach, and presents shorter duration and worse prognosis compared with the differentiated (intestinal) type adenocarcinoma. The main difficulty encountered in the differential diagnosis of gastric adenocarcinomas occurs with the diffuse-type. As the cancer cells of diffuse-type adenocarcinoma are often single and inconspicuous in a background desmoplaia and inflammation, it can often be mistaken for a wide variety of non-neoplastic lesions including gastritis or reactive endothelial cells seen in granulation tissue. In this study we trained deep learning models to classify gastric diffuse-type adenocarcinoma from WSIs. We evaluated the models on five test sets obtained from distinct sources, achieving receiver operator curve (ROC) area under the curves (AUCs) in the range of 0.95-0.99. The highly promising results demonstrate the potential of AI-based computational pathology for aiding pathologists in their diagnostic workflow system.

</p>
</details>

<details><summary><b>Invariant polynomials and machine learning</b>
<a href="https://arxiv.org/abs/2104.12733">arxiv:2104.12733</a>
&#x1F4C8; 6 <br>
<p>Ward Haddadin</p></summary>
<p>

**Abstract:** We present an application of invariant polynomials in machine learning. Using the methods developed in previous work, we obtain two types of generators of the Lorentz- and permutation-invariant polynomials in particle momenta; minimal algebra generators and Hironaka decompositions. We discuss and prove some approximation theorems to make use of these invariant generators in machine learning algorithms in general and in neural networks specifically. By implementing these generators in neural networks applied to regression tasks, we test the improvements in performance under a wide range of hyperparameter choices and find a reduction of the loss on training data and a significant reduction of the loss on validation data. For a different approach on quantifying the performance of these neural networks, we treat the problem from a Bayesian inference perspective and employ nested sampling techniques to perform model comparison. Beyond a certain network size, we find that networks utilising Hironaka decompositions perform the best.

</p>
</details>

<details><summary><b>On the Importance of 3D Surface Information for Remote Sensing Classification Tasks</b>
<a href="https://arxiv.org/abs/2104.13969">arxiv:2104.13969</a>
&#x1F4C8; 5 <br>
<p>Jan Petrich, Ryan Sander, Eliza Bradley, Adam Dawood, Shawn Hough</p></summary>
<p>

**Abstract:** There has been a surge in remote sensing machine learning applications that operate on data from active or passive sensors as well as multi-sensor combinations (Ma et al. (2019)). Despite this surge, however, there has been relatively little study on the comparative value of 3D surface information for machine learning classification tasks. Adding 3D surface information to RGB imagery can provide crucial geometric information for semantic classes such as buildings, and can thus improve out-of-sample predictive performance. In this paper, we examine in-sample and out-of-sample classification performance of Fully Convolutional Neural Networks (FCNNs) and Support Vector Machines (SVMs) trained with and without 3D normalized digital surface model (nDSM) information. We assess classification performance using multispectral imagery from the International Society for Photogrammetry and Remote Sensing (ISPRS) 2D Semantic Labeling contest and the United States Special Operations Command (USSOCOM) Urban 3D Challenge. We find that providing RGB classifiers with additional 3D nDSM information results in little increase in in-sample classification performance, suggesting that spectral information alone may be sufficient for the given classification tasks. However, we observe that providing these RGB classifiers with additional nDSM information leads to significant gains in out-of-sample predictive performance. Specifically, we observe an average improvement in out-of-sample all-class accuracy of 14.4% on the ISPRS dataset and an average improvement in out-of-sample F1 score of 8.6% on the USSOCOM dataset. In addition, the experiments establish that nDSM information is critical in machine learning and classification settings that face training sample scarcity.

</p>
</details>

<details><summary><b>A Review of the Non-Invasive Techniques for Monitoring Different Aspects of Sleep</b>
<a href="https://arxiv.org/abs/2104.12964">arxiv:2104.12964</a>
&#x1F4C8; 5 <br>
<p>Zawar Hussain, Quan Z. Sheng, Wei Emma Zhang, Jorge Ortiz, Seyedamin Pouriyeh</p></summary>
<p>

**Abstract:** Quality sleep is very important for a healthy life. Nowadays, many people around the world are not getting enough sleep which is having negative impacts on their lifestyles. Studies are being conducted for sleep monitoring and have now become an important tool for understanding sleep behavior. The gold standard method for sleep analysis is polysomnography (PSG) conducted in a clinical environment but this method is both expensive and complex for long-term use. With the advancements in the field of sensors and the introduction of off-the-shelf technologies, unobtrusive solutions are becoming common as alternatives for in-home sleep monitoring. Various solutions have been proposed using both wearable and non-wearable methods which are cheap and easy to use for in-home sleep monitoring. In this paper, we present a comprehensive survey of the latest research works (2015 and after) conducted in various categories of sleep monitoring including sleep stage classification, sleep posture recognition, sleep disorders detection, and vital signs monitoring. We review the latest works done using the non-invasive approach and cover both wearable and non-wearable methods. We discuss the design approaches and key attributes of the work presented and provide an extensive analysis based on 10 key factors, to give a comprehensive overview of the recent developments and trends in all four categories of sleep monitoring. We also present some publicly available datasets for different categories of sleep monitoring. In the end, we discuss several open issues and provide future research directions in the area of sleep monitoring.

</p>
</details>

<details><summary><b>Exploring Uncertainty in Deep Learning for Construction of Prediction Intervals</b>
<a href="https://arxiv.org/abs/2104.12953">arxiv:2104.12953</a>
&#x1F4C8; 5 <br>
<p>Yuandu Lai, Yucheng Shi, Yahong Han, Yunfeng Shao, Meiyu Qi, Bingshuai Li</p></summary>
<p>

**Abstract:** Deep learning has achieved impressive performance on many tasks in recent years. However, it has been found that it is still not enough for deep neural networks to provide only point estimates. For high-risk tasks, we need to assess the reliability of the model predictions. This requires us to quantify the uncertainty of model prediction and construct prediction intervals. In this paper, We explore the uncertainty in deep learning to construct the prediction intervals. In general, We comprehensively consider two categories of uncertainties: aleatory uncertainty and epistemic uncertainty. We design a special loss function, which enables us to learn uncertainty without uncertainty label. We only need to supervise the learning of regression task. We learn the aleatory uncertainty implicitly from the loss function. And that epistemic uncertainty is accounted for in ensembled form. Our method correlates the construction of prediction intervals with the uncertainty estimation. Impressive results on some publicly available datasets show that the performance of our method is competitive with other state-of-the-art methods.

</p>
</details>

<details><summary><b>Clean Images are Hard to Reblur: A New Clue for Deblurring</b>
<a href="https://arxiv.org/abs/2104.12665">arxiv:2104.12665</a>
&#x1F4C8; 5 <br>
<p>Seungjun Nah, Sanghyun Son, Jaerin Lee, Kyoung Mu Lee</p></summary>
<p>

**Abstract:** The goal of dynamic scene deblurring is to remove the motion blur present in a given image. Most learning-based approaches implement their solutions by minimizing the L1 or L2 distance between the output and reference sharp image. Recent attempts improve the perceptual quality of the deblurred image by using features learned from visual recognition tasks. However, those features are originally designed to capture the high-level contexts rather than the low-level structures of the given image, such as blurriness. We propose a novel low-level perceptual loss to make image sharper. To better focus on image blurriness, we train a reblurring module amplifying the unremoved motion blur. Motivated that a well-deblurred clean image should contain zero-magnitude motion blur that is hard to be amplified, we design two types of reblurring loss functions. The supervised reblurring loss at training stage compares the amplified blur between the deblurred image and the reference sharp image. The self-supervised reblurring loss at inference stage inspects if the deblurred image still contains noticeable blur to be amplified. Our experimental results demonstrate the proposed reblurring losses improve the perceptual quality of the deblurred images in terms of NIQE and LPIPS scores as well as visual sharpness.

</p>
</details>

<details><summary><b>FedDPGAN: Federated Differentially Private Generative Adversarial Networks Framework for the Detection of COVID-19 Pneumonia</b>
<a href="https://arxiv.org/abs/2104.12581">arxiv:2104.12581</a>
&#x1F4C8; 5 <br>
<p>Longling Zhang, Bochen Shen, Ahmed Barnawi, Shan Xi, Neeraj Kumar, Yi Wu</p></summary>
<p>

**Abstract:** Existing deep learning technologies generally learn the features of chest X-ray data generated by Generative Adversarial Networks (GAN) to diagnose COVID-19 pneumonia. However, the above methods have a critical challenge: data privacy. GAN will leak the semantic information of the training data which can be used to reconstruct the training samples by attackers, thereby this method will leak the privacy of the patient. Furthermore, for this reason that is the limitation of the training data sample, different hospitals jointly train the model through data sharing, which will also cause the privacy leakage. To solve this problem, we adopt the Federated Learning (FL) frame-work which is a new technique being used to protect the data privacy. Under the FL framework and Differentially Private thinking, we propose a FederatedDifferentially Private Generative Adversarial Network (FedDPGAN) to detectCOVID-19 pneumonia for sustainable smart cities. Specifically, we use DP-GAN to privately generate diverse patient data in which differential privacy technology is introduced to make sure the privacy protection of the semantic information of training dataset. Furthermore, we leverage FL to allow hospitals to collaboratively train COVID-19 models without sharing the original data. Under Independent and Identically Distributed (IID) and non-IID settings, The evaluation of the proposed model is on three types of chest X-ray (CXR) images dataset (COVID-19, normal, and normal pneumonia). A large number of the truthful reports make the verification of our model can effectively diagnose COVID-19 without compromising privacy.

</p>
</details>

<details><summary><b>Efficient Hyperparameter Optimization for Physics-based Character Animation</b>
<a href="https://arxiv.org/abs/2104.12365">arxiv:2104.12365</a>
&#x1F4C8; 5 <br>
<p>Zeshi Yang, Zhiqi Yin</p></summary>
<p>

**Abstract:** Physics-based character animation has seen significant advances in recent years with the adoption of Deep Reinforcement Learning (DRL). However, DRL-based learning methods are usually computationally expensive and their performance crucially depends on the choice of hyperparameters. Tuning hyperparameters for these methods often requires repetitive training of control policies, which is even more computationally prohibitive. In this work, we propose a novel Curriculum-based Multi-Fidelity Bayesian Optimization framework (CMFBO) for efficient hyperparameter optimization of DRL-based character control systems. Using curriculum-based task difficulty as fidelity criterion, our method improves searching efficiency by gradually pruning search space through evaluation on easier motor skill tasks. We evaluate our method on two physics-based character control tasks: character morphology optimization and hyperparameter tuning of DeepMimic. Our algorithm significantly outperforms state-of-the-art hyperparameter optimization methods applicable for physics-based character animation. In particular, we show that hyperparameters optimized through our algorithm result in at least 5x efficiency gain comparing to author-released settings in DeepMimic.

</p>
</details>

<details><summary><b>Equity and Artificial Intelligence in Education: Will "AIEd" Amplify or Alleviate Inequities in Education?</b>
<a href="https://arxiv.org/abs/2104.12920">arxiv:2104.12920</a>
&#x1F4C8; 4 <br>
<p>Kenneth Holstein, Shayan Doroudi</p></summary>
<p>

**Abstract:** The development of educational AI (AIEd) systems has often been motivated by their potential to promote educational equity and reduce achievement gaps across different groups of learners -- for example, by scaling up the benefits of one-on-one human tutoring to a broader audience, or by filling gaps in existing educational services. Given these noble intentions, why might AIEd systems have inequitable impacts in practice? In this chapter, we discuss four lenses that can be used to examine how and why AIEd systems risk amplifying existing inequities. Building from these lenses, we then outline possible paths towards more equitable futures for AIEd, while highlighting debates surrounding each proposal. In doing so, we hope to provoke new conversations around the design of equitable AIEd, and to push ongoing conversations in the field forward.

</p>
</details>

<details><summary><b>Algorithm is Experiment: Machine Learning, Market Design, and Policy Eligibility Rules</b>
<a href="https://arxiv.org/abs/2104.12909">arxiv:2104.12909</a>
&#x1F4C8; 4 <br>
<p>Yusuke Narita, Kohei Yata</p></summary>
<p>

**Abstract:** Algorithms produce a growing portion of decisions and recommendations both in policy and business. Such algorithmic decisions are natural experiments (conditionally quasi-randomly assigned instruments) since the algorithms make decisions based only on observable input variables. We use this observation to develop a treatment-effect estimator for a class of stochastic and deterministic decision-making algorithms. Our estimator is shown to be consistent and asymptotically normal for well-defined causal effects. A key special case of our estimator is a multidimensional regression discontinuity design. We apply our estimator to evaluate the effect of the Coronavirus Aid, Relief, and Economic Security (CARES) Act, where hundreds of billions of dollars worth of relief funding is allocated to hospitals via an algorithmic rule. Our estimates suggest that the relief funding has little effect on COVID-19-related hospital activity levels. Naive OLS and IV estimates exhibit substantial selection bias.

</p>
</details>

<details><summary><b>Instance-wise Causal Feature Selection for Model Interpretation</b>
<a href="https://arxiv.org/abs/2104.12759">arxiv:2104.12759</a>
&#x1F4C8; 4 <br>
<p>Pranoy Panda, Sai Srinivas Kancheti, Vineeth N Balasubramanian</p></summary>
<p>

**Abstract:** We formulate a causal extension to the recently introduced paradigm of instance-wise feature selection to explain black-box visual classifiers. Our method selects a subset of input features that has the greatest causal effect on the models output. We quantify the causal influence of a subset of features by the Relative Entropy Distance measure. Under certain assumptions this is equivalent to the conditional mutual information between the selected subset and the output variable. The resulting causal selections are sparser and cover salient objects in the scene. We show the efficacy of our approach on multiple vision datasets by measuring the post-hoc accuracy and Average Causal Effect of selected features on the models output.

</p>
</details>

<details><summary><b>Auto Response Generation in Online Medical Chat Services</b>
<a href="https://arxiv.org/abs/2104.12755">arxiv:2104.12755</a>
&#x1F4C8; 4 <br>
<p>Hadi Jahanshahi, Syed Kazmi, Mucahit Cevik</p></summary>
<p>

**Abstract:** Telehealth helps to facilitate access to medical professionals by enabling remote medical services for the patients. These services have become gradually popular over the years with the advent of necessary technological infrastructure. The benefits of telehealth have been even more apparent since the beginning of the COVID-19 crisis, as people have become less inclined to visit doctors in person during the pandemic. In this paper, we focus on facilitating the chat sessions between a doctor and a patient. We note that the quality and efficiency of the chat experience can be critical as the demand for telehealth services increases. Accordingly, we develop a smart auto-response generation mechanism for medical conversations that helps doctors respond to consultation requests efficiently, particularly during busy sessions. We explore over 900,000 anonymous, historical online messages between doctors and patients collected over nine months. We implement clustering algorithms to identify the most frequent responses by doctors and manually label the data accordingly. We then train machine learning algorithms using this preprocessed data to generate the responses. The considered algorithm has two steps: a filtering (i.e., triggering) model to filter out infeasible patient messages and a response generator to suggest the top-3 doctor responses for the ones that successfully pass the triggering phase. The method provides an accuracy of 83.28\% for precision@3 and shows robustness to its parameters.

</p>
</details>

<details><summary><b>GermanQuAD and GermanDPR: Improving Non-English Question Answering and Passage Retrieval</b>
<a href="https://arxiv.org/abs/2104.12741">arxiv:2104.12741</a>
&#x1F4C8; 4 <br>
<p>Timo Möller, Julian Risch, Malte Pietsch</p></summary>
<p>

**Abstract:** A major challenge of research on non-English machine reading for question answering (QA) is the lack of annotated datasets. In this paper, we present GermanQuAD, a dataset of 13,722 extractive question/answer pairs. To improve the reproducibility of the dataset creation approach and foster QA research on other languages, we summarize lessons learned and evaluate reformulation of question/answer pairs as a way to speed up the annotation process. An extractive QA model trained on GermanQuAD significantly outperforms multilingual models and also shows that machine-translated training data cannot fully substitute hand-annotated training data in the target language. Finally, we demonstrate the wide range of applications of GermanQuAD by adapting it to GermanDPR, a training dataset for dense passage retrieval (DPR), and train and evaluate the first non-English DPR model.

</p>
</details>

<details><summary><b>Towards Sustainable Census Independent Population Estimation in Mozambique</b>
<a href="https://arxiv.org/abs/2104.12696">arxiv:2104.12696</a>
&#x1F4C8; 4 <br>
<p>Isaac Neal, Sohan Seth, Gary Watmough, Mamadou Saliou Diallo</p></summary>
<p>

**Abstract:** Reliable and frequent population estimation is key for making policies around vaccination and planning infrastructure delivery. Since censuses lack the spatio-temporal resolution required for these tasks, census-independent approaches, using remote sensing and microcensus data, have become popular. We estimate intercensal population count in two pilot districts in Mozambique. To encourage sustainability, we assess the feasibility of using publicly available datasets to estimate population. We also explore transfer learning with existing annotated datasets for predicting building footprints, and training with additional `dot' annotations from regions of interest to enhance these estimations. We observe that population predictions improve when using footprint area estimated with this approach versus only publicly available features.

</p>
</details>

<details><summary><b>Solving a class of non-convex min-max games using adaptive momentum methods</b>
<a href="https://arxiv.org/abs/2104.12676">arxiv:2104.12676</a>
&#x1F4C8; 4 <br>
<p>Babak Barazandeh, Davoud Ataee Tarzanagh, George Michailidis</p></summary>
<p>

**Abstract:** Adaptive momentum methods have recently attracted a lot of attention for training of deep neural networks. They use an exponential moving average of past gradients of the objective function to update both search directions and learning rates. However, these methods are not suited for solving min-max optimization problems that arise in training generative adversarial networks. In this paper, we propose an adaptive momentum min-max algorithm that generalizes adaptive momentum methods to the non-convex min-max regime. Further, we establish non-asymptotic rates of convergence for the proposed algorithm when used in a reasonably broad class of non-convex min-max optimization problems. Experimental results illustrate its superior performance vis-a-vis benchmark methods for solving such problems.

</p>
</details>

<details><summary><b>Generative modeling of spatio-temporal weather patterns with extreme event conditioning</b>
<a href="https://arxiv.org/abs/2104.12469">arxiv:2104.12469</a>
&#x1F4C8; 4 <br>
<p>Konstantin Klemmer, Sudipan Saha, Matthias Kahl, Tianlin Xu, Xiao Xiang Zhu</p></summary>
<p>

**Abstract:** Deep generative models are increasingly used to gain insights in the geospatial data domain, e.g., for climate data. However, most existing approaches work with temporal snapshots or assume 1D time-series; few are able to capture spatio-temporal processes simultaneously. Beyond this, Earth-systems data often exhibit highly irregular and complex patterns, for example caused by extreme weather events. Because of climate change, these phenomena are only increasing in frequency. Here, we proposed a novel GAN-based approach for generating spatio-temporal weather patterns conditioned on detected extreme events. Our approach augments GAN generator and discriminator with an encoded extreme weather event segmentation mask. These segmentation masks can be created from raw input using existing event detection frameworks. As such, our approach is highly modular and can be combined with custom GAN architectures. We highlight the applicability of our proposed approach in experiments with real-world surface radiation and zonal wind data.

</p>
</details>

<details><summary><b>Heterogeneous-Agent Trajectory Forecasting Incorporating Class Uncertainty</b>
<a href="https://arxiv.org/abs/2104.12446">arxiv:2104.12446</a>
&#x1F4C8; 4 <br>
<p>Boris Ivanovic, Kuan-Hui Lee, Pavel Tokmakov, Blake Wulfe, Rowan McAllister, Adrien Gaidon, Marco Pavone</p></summary>
<p>

**Abstract:** Reasoning about the future behavior of other agents is critical to safe robot navigation. The multiplicity of plausible futures is further amplified by the uncertainty inherent to agent state estimation from data, including positions, velocities, and semantic class. Forecasting methods, however, typically neglect class uncertainty, conditioning instead only on the agent's most likely class, even though perception models often return full class distributions. To exploit this information, we present HAICU, a method for heterogeneous-agent trajectory forecasting that explicitly incorporates agents' class probabilities. We additionally present PUP, a new challenging real-world autonomous driving dataset, to investigate the impact of Perceptual Uncertainty in Prediction. It contains challenging crowded scenes with unfiltered agent class probabilities that reflect the long-tail of current state-of-the-art perception systems. We demonstrate that incorporating class probabilities in trajectory forecasting significantly improves performance in the face of uncertainty, and enables new forecasting capabilities such as counterfactual predictions.

</p>
</details>

<details><summary><b>ECLIPSE : Envisioning Cloud Induced Perturbations in Solar Energy</b>
<a href="https://arxiv.org/abs/2104.12419">arxiv:2104.12419</a>
&#x1F4C8; 4 <br>
<p>Quentin Paletta, Anthony Hu, Guillaume Arbod, Joan Lasenby</p></summary>
<p>

**Abstract:** Efficient integration of solar energy into the electricity mix depends on a reliable anticipation of its intermittency. A promising approach to forecast the temporal variability of solar irradiance resulting from the cloud cover dynamics is based on the analysis of sequences of ground-taken sky images or satellite images. Despite encouraging results, a recurrent limitation of existing deep learning approaches lies in the ubiquitous tendency of reacting to past observations rather than actively anticipating future events. This leads to a frequent temporal lag and limited ability to predict sudden events. To address this challenge, we introduce ECLIPSE, a spatio-temporal neural network architecture that models cloud motion from sky images to not only predict future irradiance levels but also segmented images, which provide richer information on the local irradiance map. We show that ECLIPSE anticipates critical events and reduces temporal delay while generating visually realistic futures.

</p>
</details>

<details><summary><b>Predicting Depressive Symptom Severity through Individuals' Nearby Bluetooth Devices Count Data Collected by Mobile Phones: A Preliminary Longitudinal Study</b>
<a href="https://arxiv.org/abs/2104.12407">arxiv:2104.12407</a>
&#x1F4C8; 4 <br>
<p>Yuezhou Zhang, Amos A Folarin, Shaoxiong Sun, Nicholas Cummins, Yatharth Ranjan, Zulqarnain Rashid, Pauline Conde, Callum Stewart, Petroula Laiou, Faith Matcham, Carolin Oetzmann, Femke Lamers, Sara Siddi, Sara Simblett, Aki Rintala, David C Mohr, Inez Myin-Germeys, Til Wykes, Josep Maria Haro, Brenda WJH Pennix, Vaibhav A Narayan, Peter Annas, Matthew Hotopf, Richard JB Dobson</p></summary>
<p>

**Abstract:** The Bluetooth sensor embedded in mobile phones provides an unobtrusive, continuous, and cost-efficient means to capture individuals' proximity information, such as the nearby Bluetooth devices count (NBDC). The continuous NBDC data can partially reflect individuals' behaviors and status, such as social connections and interactions, working status, mobility, and social isolation and loneliness, which were found to be significantly associated with depression by previous survey-based studies. This paper aims to explore the NBDC data's value in predicting depressive symptom severity as measured via the 8-item Patient Health Questionnaire (PHQ-8). The data used in this paper included 2,886 bi-weekly PHQ-8 records collected from 316 participants recruited from three study sites in the Netherlands, Spain, and the UK as part of the EU RADAR-CNS study. From the NBDC data two weeks prior to each PHQ-8 score, we extracted 49 Bluetooth features, including statistical features and nonlinear features for measuring periodicity and regularity of individuals' life rhythms. Linear mixed-effect models were used to explore associations between Bluetooth features and the PHQ-8 score. We then applied hierarchical Bayesian linear regression models to predict the PHQ-8 score from the extracted Bluetooth features. A number of significant associations were found between Bluetooth features and depressive symptom severity. Compared with commonly used machine learning models, the proposed hierarchical Bayesian linear regression model achieved the best prediction metrics, R2= 0.526, and root mean squared error (RMSE) of 3.891. Bluetooth features can explain an extra 18.8% of the variance in the PHQ-8 score relative to the baseline model without Bluetooth features (R2=0.338, RMSE = 4.547).

</p>
</details>

<details><summary><b>Wasserstein distance estimates for the distributions of numerical approximations to ergodic stochastic differential equations</b>
<a href="https://arxiv.org/abs/2104.12384">arxiv:2104.12384</a>
&#x1F4C8; 4 <br>
<p>J. M. Sanz-Serna, Konstantinos C. Zygalakis</p></summary>
<p>

**Abstract:** We present a framework that allows for the non-asymptotic study of the $2$-Wasserstein distance between the invariant distribution of an ergodic stochastic differential equation and the distribution of its numerical approximation in the strongly log-concave case. This allows us to study in a unified way a number of different integrators proposed in the literature for the overdamped and underdamped Langevin dynamics. In addition, we analyse a novel splitting method for the underdamped Langevin dynamics which only requires one gradient evaluation per time step. Under an additional smoothness assumption on a $d$--dimensional strongly log-concave distribution with condition number $κ$, the algorithm is shown to produce with an $\mathcal{O}\big(κ^{5/4} d^{1/4}ε^{-1/2} \big)$ complexity samples from a distribution that, in Wasserstein distance, is at most $ε>0$ away from the target distribution.

</p>
</details>

<details><summary><b>Recalibration of Aleatoric and Epistemic Regression Uncertainty in Medical Imaging</b>
<a href="https://arxiv.org/abs/2104.12376">arxiv:2104.12376</a>
&#x1F4C8; 4 <br>
<p>Max-Heinrich Laves, Sontje Ihler, Jacob F. Fast, Lüder A. Kahrs, Tobias Ortmaier</p></summary>
<p>

**Abstract:** The consideration of predictive uncertainty in medical imaging with deep learning is of utmost importance. We apply estimation of both aleatoric and epistemic uncertainty by variational Bayesian inference with Monte Carlo dropout to regression tasks and show that predictive uncertainty is systematically underestimated. We apply $ σ$ scaling with a single scalar value; a simple, yet effective calibration method for both types of uncertainty. The performance of our approach is evaluated on a variety of common medical regression data sets using different state-of-the-art convolutional network architectures. In our experiments, $ σ$ scaling is able to reliably recalibrate predictive uncertainty. It is easy to implement and maintains the accuracy. Well-calibrated uncertainty in regression allows robust rejection of unreliable predictions or detection of out-of-distribution samples. Our source code is available at https://github.com/mlaves/well-calibrated-regression-uncertainty

</p>
</details>

<details><summary><b>Handling Long-Tail Queries with Slice-Aware Conversational Systems</b>
<a href="https://arxiv.org/abs/2104.13216">arxiv:2104.13216</a>
&#x1F4C8; 3 <br>
<p>Cheng Wang, Sun Kim, Taiwoo Park, Sajal Choudhary, Sunghyun Park, Young-Bum Kim, Ruhi Sarikaya, Sungjin Lee</p></summary>
<p>

**Abstract:** We have been witnessing the usefulness of conversational AI systems such as Siri and Alexa, directly impacting our daily lives. These systems normally rely on machine learning models evolving over time to provide quality user experience. However, the development and improvement of the models are challenging because they need to support both high (head) and low (tail) usage scenarios, requiring fine-grained modeling strategies for specific data subsets or slices. In this paper, we explore the recent concept of slice-based learning (SBL) (Chen et al., 2019) to improve our baseline conversational skill routing system on the tail yet critical query traffic. We first define a set of labeling functions to generate weak supervision data for the tail intents. We then extend the baseline model towards a slice-aware architecture, which monitors and improves the model performance on the selected tail intents. Applied to de-identified live traffic from a commercial conversational AI system, our experiments show that the slice-aware model is beneficial in improving model performance for the tail intents while maintaining the overall performance.

</p>
</details>

<details><summary><b>Discriminative Bayesian Filtering Lends Momentum to the Stochastic Newton Method for Minimizing Log-Convex Functions</b>
<a href="https://arxiv.org/abs/2104.12949">arxiv:2104.12949</a>
&#x1F4C8; 3 <br>
<p>Michael C. Burkhart</p></summary>
<p>

**Abstract:** To minimize the average of a set of log-convex functions, the stochastic Newton method iteratively updates its estimate using subsampled versions of the full objective's gradient and Hessian. We contextualize this optimization problem as sequential Bayesian inference on a latent state-space model with a discriminatively-specified observation process. Applying Bayesian filtering then yields a novel optimization algorithm that considers the entire history of gradients and Hessians when forming an update. We establish matrix-based conditions under which the effect of older observations diminishes over time, in a manner analogous to Polyak's heavy ball momentum. We illustrate various aspects of our approach with an example and review other relevant innovations for the stochastic Newton method.

</p>
</details>

<details><summary><b>Computational Performance of Deep Reinforcement Learning to find Nash Equilibria</b>
<a href="https://arxiv.org/abs/2104.12895">arxiv:2104.12895</a>
&#x1F4C8; 3 <br>
<p>Christoph Graf, Viktor Zobernig, Johannes Schmidt, Claude Klöckl</p></summary>
<p>

**Abstract:** We test the performance of deep deterministic policy gradient (DDPG), a deep reinforcement learning algorithm, able to handle continuous state and action spaces, to learn Nash equilibria in a setting where firms compete in prices. These algorithms are typically considered model-free because they do not require transition probability functions (as in e.g., Markov games) or predefined functional forms. Despite being model-free, a large set of parameters are utilized in various steps of the algorithm. These are e.g., learning rates, memory buffers, state-space dimensioning, normalizations, or noise decay rates and the purpose of this work is to systematically test the effect of these parameter configurations on convergence to the analytically derived Bertrand equilibrium. We find parameter choices that can reach convergence rates of up to 99%. The reliable convergence may make the method a useful tool to study strategic behavior of firms even in more complex settings. Keywords: Bertrand Equilibrium, Competition in Uniform Price Auctions, Deep Deterministic Policy Gradient Algorithm, Parameter Sensitivity Analysis

</p>
</details>

<details><summary><b>Multi-Output Random Forest Regression to Emulate the Earliest Stages of Planet Formation</b>
<a href="https://arxiv.org/abs/2104.12845">arxiv:2104.12845</a>
&#x1F4C8; 3 <br>
<p>Kevin Hoffman, Jae Yoon Sung, André Zazzera</p></summary>
<p>

**Abstract:** In the current paradigm of planet formation research, it is believed that the first step to forming massive bodies (such as asteroids and planets) requires that small interstellar dust grains floating through space collide with each other and grow to larger sizes. The initial formation of these pebbles is governed by an integro-differential equation known as the Smoluchowski coagulation equation, to which analytical solutions are intractable for all but the simplest possible scenarios. While brute-force methods of approximation have been developed, they are computationally costly, currently making it infeasible to simulate this process including other physical processes relevant to planet formation, and across the very large range of scales on which it occurs. In this paper, we take a machine learning approach to designing a system for a much faster approximation. We develop a multi-output random forest regression model trained on brute-force simulation data to approximate distributions of dust particle sizes in protoplanetary disks at different points in time. The performance of our random forest model is measured against the existing brute-force models, which are the standard for realistic simulations. Results indicate that the random forest model can generate highly accurate predictions relative to the brute-force simulation results, with an $R^{2}$ of 0.97, and do so significantly faster than brute-force methods.

</p>
</details>

<details><summary><b>Adaptive Learning in Continuous Games: Optimal Regret Bounds and Convergence to Nash Equilibrium</b>
<a href="https://arxiv.org/abs/2104.12761">arxiv:2104.12761</a>
&#x1F4C8; 3 <br>
<p>Yu-Guan Hsieh, Kimon Antonakopoulos, Panayotis Mertikopoulos</p></summary>
<p>

**Abstract:** In game-theoretic learning, several agents are simultaneously following their individual interests, so the environment is non-stationary from each player's perspective. In this context, the performance of a learning algorithm is often measured by its regret. However, no-regret algorithms are not created equal in terms of game-theoretic guarantees: depending on how they are tuned, some of them may drive the system to an equilibrium, while others could produce cyclic, chaotic, or otherwise divergent trajectories. To account for this, we propose a range of no-regret policies based on optimistic mirror descent, with the following desirable properties: i) they do not require any prior tuning or knowledge of the game; ii) they all achieve O(\sqrt{T}) regret against arbitrary, adversarial opponents; and iii) they converge to the best response against convergent opponents. Also, if employed by all players, then iv) they guarantee O(1) social regret; while v) the induced sequence of play converges to Nash equilibrium with O(1) individual regret in all variationally stable games (a class of games that includes all monotone and convex-concave zero-sum games).

</p>
</details>

<details><summary><b>Semi-Decentralized Federated Edge Learning for Fast Convergence on Non-IID Data</b>
<a href="https://arxiv.org/abs/2104.12678">arxiv:2104.12678</a>
&#x1F4C8; 3 <br>
<p>Yuchang Sun, Jiawei Shao, Yuyi Mao, Jessie Hui Wang, Jun Zhang</p></summary>
<p>

**Abstract:** Federated edge learning (FEEL) has emerged as an effective approach to reduce the large communication latency in Cloud-based machine learning solutions, while preserving data privacy. Unfortunately, the learning performance of FEEL may be compromised due to limited training data in a single edge cluster. In this paper, we investigate a novel framework of FEEL, namely semi-decentralized federated edge learning (SD-FEEL). By allowing model aggregation across different edge clusters, SD-FEEL enjoys the benefit of FEEL in reducing the training latency, while improving the learning performance by accessing richer training data from multiple edge clusters. A training algorithm for SD-FEEL with three main procedures in each round is presented, including local model updates, intra-cluster and inter-cluster model aggregations, which is proved to converge on non-independent and identically distributed (non-IID) data. We also characterize the interplay between the network topology of the edge servers and the communication overhead of inter-cluster model aggregation on the training performance. Experiment results corroborate our analysis and demonstrate the effectiveness of SD-FFEL in achieving faster convergence than traditional federated learning architectures. Besides, guidelines on choosing critical hyper-parameters of the training algorithm are also provided.

</p>
</details>

<details><summary><b>Exploiting Explanations for Model Inversion Attacks</b>
<a href="https://arxiv.org/abs/2104.12669">arxiv:2104.12669</a>
&#x1F4C8; 3 <br>
<p>Xuejun Zhao, Wencan Zhang, Xiaokui Xiao, Brian Y. Lim</p></summary>
<p>

**Abstract:** The successful deployment of artificial intelligence (AI) in many domains from healthcare to hiring requires their responsible use, particularly in model explanations and privacy. Explainable artificial intelligence (XAI) provides more information to help users to understand model decisions, yet this additional knowledge exposes additional risks for privacy attacks. Hence, providing explanation harms privacy. We study this risk for image-based model inversion attacks and identified several attack architectures with increasing performance to reconstruct private image data from model explanations. We have developed several multi-modal transposed CNN architectures that achieve significantly higher inversion performance than using the target model prediction only. These XAI-aware inversion models were designed to exploit the spatial knowledge in image explanations. To understand which explanations have higher privacy risk, we analyzed how various explanation types and factors influence inversion performance. In spite of some models not providing explanations, we further demonstrate increased inversion performance even for non-explainable target models by exploiting explanations of surrogate models through attention transfer. This method first inverts an explanation from the target prediction, then reconstructs the target image. These threats highlight the urgent and significant privacy risks of explanations and calls attention for new privacy preservation techniques that balance the dual-requirement for AI explainability and privacy.

</p>
</details>

<details><summary><b>Vision-based Driver Assistance Systems: Survey, Taxonomy and Advances</b>
<a href="https://arxiv.org/abs/2104.12583">arxiv:2104.12583</a>
&#x1F4C8; 3 <br>
<p>Jonathan Horgan, Ciarán Hughes, John McDonald, Senthil Yogamani</p></summary>
<p>

**Abstract:** Vision-based driver assistance systems is one of the rapidly growing research areas of ITS, due to various factors such as the increased level of safety requirements in automotive, computational power in embedded systems, and desire to get closer to autonomous driving. It is a cross disciplinary area encompassing specialised fields like computer vision, machine learning, robotic navigation, embedded systems, automotive electronics and safety critical software. In this paper, we survey the list of vision based advanced driver assistance systems with a consistent terminology and propose a taxonomy. We also propose an abstract model in an attempt to formalize a top-down view of application development to scale towards autonomous driving system.

</p>
</details>

<details><summary><b>Evaluating the performance of personal, social, health-related, biomarker and genetic data for predicting an individuals future health using machine learning: A longitudinal analysis</b>
<a href="https://arxiv.org/abs/2104.12516">arxiv:2104.12516</a>
&#x1F4C8; 3 <br>
<p>Mark Green</p></summary>
<p>

**Abstract:** As we gain access to a greater depth and range of health-related information about individuals, three questions arise: (1) Can we build better models to predict individual-level risk of ill health? (2) How much data do we need to effectively predict ill health? (3) Are new methods required to process the added complexity that new forms of data bring? The aim of the study is to apply a machine learning approach to identify the relative contribution of personal, social, health-related, biomarker and genetic data as predictors of future health in individuals. Using longitudinal data from 6830 individuals in the UK from Understanding Society (2010-12 to 2015-17), the study compares the predictive performance of five types of measures: personal (e.g. age, sex), social (e.g. occupation, education), health-related (e.g. body weight, grip strength), biomarker (e.g. cholesterol, hormones) and genetic single nucleotide polymorphisms (SNPs). The predicted outcome variable was limiting long-term illness one and five years from baseline. Two machine learning approaches were used to build predictive models: deep learning via neural networks and XGBoost (gradient boosting decision trees). Model fit was compared to traditional logistic regression models. Results found that health-related measures had the strongest prediction of future health status, with genetic data performing poorly. Machine learning models only offered marginal improvements in model accuracy when compared to logistic regression models, but also performed well on other metrics e.g. neural networks were best on AUC and XGBoost on precision. The study suggests that increasing complexity of data and methods does not necessarily translate to improved understanding of the determinants of health or performance of predictive models of ill health.

</p>
</details>

<details><summary><b>Represent Items by Items: An Enhanced Representation of the Target Item for Recommendation</b>
<a href="https://arxiv.org/abs/2104.12483">arxiv:2104.12483</a>
&#x1F4C8; 3 <br>
<p>Yinjiang Cai, Zeyu Cui, Shu Wu, Zhen Lei, Xibo Ma</p></summary>
<p>

**Abstract:** Item-based collaborative filtering (ICF) has been widely used in industrial applications such as recommender system and online advertising. It models users' preference on target items by the items they have interacted with. Recent models use methods such as attention mechanism and deep neural network to learn the user representation and scoring function more accurately. However, despite their effectiveness, such models still overlook a problem that performance of ICF methods heavily depends on the quality of item representation especially the target item representation. In fact, due to the long-tail distribution in the recommendation, most item embeddings can not represent the semantics of items accurately and thus degrade the performance of current ICF methods. In this paper, we propose an enhanced representation of the target item which distills relevant information from the co-occurrence items. We design sampling strategies to sample fix number of co-occurrence items for the sake of noise reduction and computational cost. Considering the different importance of sampled items to the target item, we apply attention mechanism to selectively adopt the semantic information of the sampled items. Our proposed Co-occurrence based Enhanced Representation model (CER) learns the scoring function by a deep neural network with the attentive user representation and fusion of raw representation and enhanced representation of target item as input. With the enhanced representation, CER has stronger representation power for the tail items compared to the state-of-the-art ICF methods. Extensive experiments on two public benchmarks demonstrate the effectiveness of CER.

</p>
</details>

<details><summary><b>Contextualized Keyword Representations for Multi-modal Retinal Image Captioning</b>
<a href="https://arxiv.org/abs/2104.12471">arxiv:2104.12471</a>
&#x1F4C8; 3 <br>
<p>Jia-Hong Huang, Ting-Wei Wu, Marcel Worring</p></summary>
<p>

**Abstract:** Medical image captioning automatically generates a medical description to describe the content of a given medical image. A traditional medical image captioning model creates a medical description only based on a single medical image input. Hence, an abstract medical description or concept is hard to be generated based on the traditional approach. Such a method limits the effectiveness of medical image captioning. Multi-modal medical image captioning is one of the approaches utilized to address this problem. In multi-modal medical image captioning, textual input, e.g., expert-defined keywords, is considered as one of the main drivers of medical description generation. Thus, encoding the textual input and the medical image effectively are both important for the task of multi-modal medical image captioning. In this work, a new end-to-end deep multi-modal medical image captioning model is proposed. Contextualized keyword representations, textual feature reinforcement, and masked self-attention are used to develop the proposed approach. Based on the evaluation of the existing multi-modal medical image captioning dataset, experimental results show that the proposed model is effective with the increase of +53.2% in BLEU-avg and +18.6% in CIDEr, compared with the state-of-the-art method.

</p>
</details>

<details><summary><b>Weakly Supervised Multi-task Learning for Concept-based Explainability</b>
<a href="https://arxiv.org/abs/2104.12459">arxiv:2104.12459</a>
&#x1F4C8; 3 <br>
<p>Catarina Belém, Vladimir Balayan, Pedro Saleiro, Pedro Bizarro</p></summary>
<p>

**Abstract:** In ML-aided decision-making tasks, such as fraud detection or medical diagnosis, the human-in-the-loop, usually a domain-expert without technical ML knowledge, prefers high-level concept-based explanations instead of low-level explanations based on model features. To obtain faithful concept-based explanations, we leverage multi-task learning to train a neural network that jointly learns to predict a decision task based on the predictions of a precedent explainability task (i.e., multi-label concepts). There are two main challenges to overcome: concept label scarcity and the joint learning. To address both, we propose to: i) use expert rules to generate a large dataset of noisy concept labels, and ii) apply two distinct multi-task learning strategies combining noisy and golden labels. We compare these strategies with a fully supervised approach in a real-world fraud detection application with few golden labels available for the explainability task. With improvements of 9.26% and of 417.8% at the explainability and decision tasks, respectively, our results show it is possible to improve performance at both tasks by combining labels of heterogeneous quality.

</p>
</details>

<details><summary><b>Variational Pedestrian Detection</b>
<a href="https://arxiv.org/abs/2104.12389">arxiv:2104.12389</a>
&#x1F4C8; 3 <br>
<p>Yuang Zhang, Huanyu He, Jianguo Li, Yuxi Li, John See, Weiyao Lin</p></summary>
<p>

**Abstract:** Pedestrian detection in a crowd is a challenging task due to a high number of mutually-occluding human instances, which brings ambiguity and optimization difficulties to the current IoU-based ground truth assignment procedure in classical object detection methods. In this paper, we develop a unique perspective of pedestrian detection as a variational inference problem. We formulate a novel and efficient algorithm for pedestrian detection by modeling the dense proposals as a latent variable while proposing a customized Auto Encoding Variational Bayes (AEVB) algorithm. Through the optimization of our proposed algorithm, a classical detector can be fashioned into a variational pedestrian detector. Experiments conducted on CrowdHuman and CityPersons datasets show that the proposed algorithm serves as an efficient solution to handle the dense pedestrian detection problem for the case of single-stage detectors. Our method can also be flexibly applied to two-stage detectors, achieving notable performance enhancement.

</p>
</details>

<details><summary><b>Yes, BM25 is a Strong Baseline for Legal Case Retrieval</b>
<a href="https://arxiv.org/abs/2105.05686">arxiv:2105.05686</a>
&#x1F4C8; 2 <br>
<p>Guilherme Moraes Rosa, Ruan Chaves Rodrigues, Roberto Lotufo, Rodrigo Nogueira</p></summary>
<p>

**Abstract:** We describe our single submission to task 1 of COLIEE 2021. Our vanilla BM25 got second place, well above the median of submissions. Code is available at https://github.com/neuralmind-ai/coliee.

</p>
</details>

<details><summary><b>AWCD: An Efficient Point Cloud Processing Approach via Wasserstein Curvature</b>
<a href="https://arxiv.org/abs/2105.04402">arxiv:2105.04402</a>
&#x1F4C8; 2 <br>
<p>Yihao Luo, Ailing Yang, Fupeng Sun, Huafei Sun</p></summary>
<p>

**Abstract:** In this paper, we introduce the adaptive Wasserstein curvature denoising (AWCD), an original processing approach for point cloud data. By collecting curvatures information from Wasserstein distance, AWCD consider more precise structures of data and preserves stability and effectiveness even for data with noise in high density. This paper contains some theoretical analysis about the Wasserstein curvature and the complete algorithm of AWCD. In addition, we design digital experiments to show the denoising effect of AWCD. According to comparison results, we present the advantages of AWCD against traditional algorithms.

</p>
</details>

<details><summary><b>Toward Code Generation: A Survey and Lessons from Semantic Parsing</b>
<a href="https://arxiv.org/abs/2105.03317">arxiv:2105.03317</a>
&#x1F4C8; 2 <br>
<p>Celine Lee, Justin Gottschlich, Dan Roth</p></summary>
<p>

**Abstract:** With the growth of natural language processing techniques and demand for improved software engineering efficiency, there is an emerging interest in translating intention from human languages to programming languages. In this survey paper, we attempt to provide an overview of the growing body of research in this space. We begin by reviewing natural language semantic parsing techniques and draw parallels with program synthesis efforts. We then consider semantic parsing works from an evolutionary perspective, with specific analyses on neuro-symbolic methods, architecture, and supervision. We then analyze advancements in frameworks for semantic parsing for code generation. In closing, we present what we believe are some of the emerging open challenges in this domain.

</p>
</details>

<details><summary><b>Implementing Reinforcement Learning Algorithms in Retail Supply Chains with OpenAI Gym Toolkit</b>
<a href="https://arxiv.org/abs/2104.14398">arxiv:2104.14398</a>
&#x1F4C8; 2 <br>
<p>Shaun D'Souza</p></summary>
<p>

**Abstract:** From cutting costs to improving customer experience, forecasting is the crux of retail supply chain management (SCM) and the key to better supply chain performance. Several retailers are using AI/ML models to gather datasets and provide forecast guidance in applications such as Cognitive Demand Forecasting, Product End-of-Life, Forecasting, and Demand Integrated Product Flow. Early work in these areas looked at classical algorithms to improve on a gamut of challenges such as network flow and graphs. But the recent disruptions have made it critical for supply chains to have the resiliency to handle unexpected events. The biggest challenge lies in matching supply with demand.
  Reinforcement Learning (RL) with its ability to train systems to respond to unforeseen environments, is being increasingly adopted in SCM to improve forecast accuracy, solve supply chain optimization challenges, and train systems to respond to unforeseen circumstances. Companies like UPS and Amazon have developed RL algorithms to define winning AI strategies and keep up with rising consumer delivery expectations. While there are many ways to build RL algorithms for supply chain use cases, the OpenAI Gym toolkit is becoming the preferred choice because of the robust framework for event-driven simulations.
  This white paper explores the application of RL in supply chain forecasting and describes how to build suitable RL models and algorithms by using the OpenAI Gym toolkit.

</p>
</details>

<details><summary><b>Model-centric Data Manifold: the Data Through the Eyes of the Model</b>
<a href="https://arxiv.org/abs/2104.13289">arxiv:2104.13289</a>
&#x1F4C8; 2 <br>
<p>Luca Grementieri, Rita Fioresi</p></summary>
<p>

**Abstract:** We discover that deep ReLU neural network classifiers can see a low-dimensional Riemannian manifold structure on data. Such structure comes via the local data matrix, a variation of the Fisher information matrix, where the role of the model parameters is taken by the data variables. We obtain a foliation of the data domain and we show that the dataset on which the model is trained lies on a leaf, the data leaf, whose dimension is bounded by the number of classification labels. We validate our results with some experiments with the MNIST dataset: paths on the data leaf connect valid images, while other leaves cover noisy images.

</p>
</details>

<details><summary><b>Infinitesimal gradient boosting</b>
<a href="https://arxiv.org/abs/2104.13208">arxiv:2104.13208</a>
&#x1F4C8; 2 <br>
<p>Clément Dombry, Jean-Jil Duchamps</p></summary>
<p>

**Abstract:** We define infinitesimal gradient boosting as a limit of the popular tree-based gradient boosting algorithm from machine learning. The limit is considered in the vanishing-learning-rate asymptotic, that is when the learning rate tends to zero and the number of gradient trees is rescaled accordingly. For this purpose, we introduce a new class of randomized regression trees bridging totally randomized trees and Extra Trees and using a softmax distribution for binary splitting. Our main result is the convergence of the associated stochastic algorithm and the characterization of the limiting procedure as the unique solution of a nonlinear ordinary differential equation in a infinite dimensional function space. Infinitesimal gradient boosting defines a smooth path in the space of continuous functions along which the training error decreases, the residuals remain centered and the total variation is well controlled.

</p>
</details>

<details><summary><b>Semantic Analysis for Automated Evaluation of the Potential Impact of Research Articles</b>
<a href="https://arxiv.org/abs/2104.12869">arxiv:2104.12869</a>
&#x1F4C8; 2 <br>
<p>Neslihan Suzen, Alexander Gorban, Jeremy Levesley, Evgeny Mirkes</p></summary>
<p>

**Abstract:** Can the analysis of the semantics of words used in the text of a scientific paper predict its future impact measured by citations? This study details examples of automated text classification that achieved 80% success rate in distinguishing between highly-cited and little-cited articles. Automated intelligent systems allow the identification of promising works that could become influential in the scientific community.
  The problems of quantifying the meaning of texts and representation of human language have been clear since the inception of Natural Language Processing. This paper presents a novel method for vector representation of text meaning based on information theory and show how this informational semantics is used for text classification on the basis of the Leicester Scientific Corpus.
  We describe the experimental framework used to evaluate the impact of scientific articles through their informational semantics. Our interest is in citation classification to discover how important semantics of texts are in predicting the citation count. We propose the semantics of texts as an important factor for citation prediction.
  For each article, our system extracts the abstract of paper, represents the words of the abstract as vectors in Meaning Space, automatically analyses the distribution of scientific categories (Web of Science categories) within the text of abstract, and then classifies papers according to citation counts (highly-cited, little-cited).
  We show that an informational approach to representing the meaning of a text has offered a way to effectively predict the scientific impact of research papers.

</p>
</details>

<details><summary><b>End-to-end grasping policies for human-in-the-loop robots via deep reinforcement learning</b>
<a href="https://arxiv.org/abs/2104.12842">arxiv:2104.12842</a>
&#x1F4C8; 2 <br>
<p>Mohammadreza Sharif, Deniz Erdogmus, Christopher Amato, Taskin Padir</p></summary>
<p>

**Abstract:** State-of-the-art human-in-the-loop robot grasping is hugely suffered by Electromyography (EMG) inference robustness issues. As a workaround, researchers have been looking into integrating EMG with other signals, often in an ad hoc manner. In this paper, we are presenting a method for end-to-end training of a policy for human-in-the-loop robot grasping on real reaching trajectories. For this purpose we use Reinforcement Learning (RL) and Imitation Learning (IL) in DEXTRON (DEXTerity enviRONment), a stochastic simulation environment with real human trajectories that are augmented and selected using a Monte Carlo (MC) simulation method. We also offer a success model which once trained on the expert policy data and the RL policy roll-out transitions, can provide transparency to how the deep policy works and when it is probably going to fail.

</p>
</details>

<details><summary><b>One-dimensional Active Contour Models for Raman Spectrum Baseline Correction</b>
<a href="https://arxiv.org/abs/2104.12839">arxiv:2104.12839</a>
&#x1F4C8; 2 <br>
<p>M. Hamed Mozaffari, Li-Lin Tay</p></summary>
<p>

**Abstract:** Raman spectroscopy is a powerful and non-invasive method for analysis of chemicals and detection of unknown substances. However, Raman signal is so weak that background noise can distort the actual Raman signal. These baseline shifts that exist in the Raman spectrum might deteriorate analytical results. In this paper, a modified version of active contour models in one-dimensional space has been proposed for the baseline correction of Raman spectra. Our technique, inspired by principles of physics and heuristic optimization methods, iteratively deforms an initialized curve toward the desired baseline. The performance of the proposed algorithm was evaluated and compared with similar techniques using simulated Raman spectra. The results showed that the 1D active contour model outperforms many iterative baseline correction methods. The proposed algorithm was successfully applied to experimental Raman spectral data, and the results indicate that the baseline of Raman spectra can be automatically subtracted.

</p>
</details>

<details><summary><b>Unsupervised Instance Selection with Low-Label, Supervised Learning for Outlier Detection</b>
<a href="https://arxiv.org/abs/2104.12837">arxiv:2104.12837</a>
&#x1F4C8; 2 <br>
<p>Trent J. Bradberry, Christopher H. Hase, LeAnna Kent, Joel A. Góngora</p></summary>
<p>

**Abstract:** The laborious process of labeling data often bottlenecks projects that aim to leverage the power of supervised machine learning. Active Learning (AL) has been established as a technique to ameliorate this condition through an iterative framework that queries a human annotator for labels of instances with the most uncertain class assignment. Via this mechanism, AL produces a binary classifier trained on less labeled data but with little, if any, loss in predictive performance. Despite its advantages, AL can have difficulty with class-imbalanced datasets and results in an inefficient labeling process. To address these drawbacks, we investigate our unsupervised instance selection (UNISEL) technique followed by a Random Forest (RF) classifier on 10 outlier detection datasets under low-label conditions. These results are compared to AL performed on the same datasets. Further, we investigate the combination of UNISEL and AL. Results indicate that UNISEL followed by an RF performs comparably to AL with an RF and that the combination of UNISEL and AL demonstrates superior performance. The practical implications of these findings in terms of time savings and generalizability afforded by UNISEL are discussed.

</p>
</details>

<details><summary><b>A Low-Complexity MIMO Channel Estimator with Implicit Structure of a Convolutional Neural Network</b>
<a href="https://arxiv.org/abs/2104.12667">arxiv:2104.12667</a>
&#x1F4C8; 2 <br>
<p>B. Fesl, N. Turan, M. Koller, W. Utschick</p></summary>
<p>

**Abstract:** A low-complexity convolutional neural network estimator which learns the minimum mean squared error channel estimator for single-antenna users was recently proposed. We generalize the architecture to the estimation of MIMO channels with multiple-antenna users and incorporate complexity-reducing assumptions based on the channel model. Learning is used in this context to combat the mismatch between the assumptions and real scenarios where the assumptions may not hold. We derive a high-level description of the estimator for arbitrary choices of the pilot sequence. It turns out that the proposed estimator has the implicit structure of a two-layered convolutional neural network, where the derived quantities can be relaxed to learnable parameters. We show that by using discrete Fourier transform based pilots the number of learnable network parameters decreases significantly and the online run time of the estimator is reduced considerably, where we can achieve linearithmic order of complexity in the number of antennas. Numerical results demonstrate performance gains compared to state-of-the-art algorithms from the field of compressive sensing or covariance estimation of the same or even higher computational complexity. The simulation code is available online.

</p>
</details>

<details><summary><b>Exploring Bayesian Deep Learning for Urgent Instructor Intervention Need in MOOC Forums</b>
<a href="https://arxiv.org/abs/2104.12643">arxiv:2104.12643</a>
&#x1F4C8; 2 <br>
<p>Jialin Yu, Laila Alrajhi, Anoushka Harit, Zhongtian Sun, Alexandra I. Cristea, Lei Shi</p></summary>
<p>

**Abstract:** Massive Open Online Courses (MOOCs) have become a popular choice for e-learning thanks to their great flexibility. However, due to large numbers of learners and their diverse backgrounds, it is taxing to offer real-time support. Learners may post their feelings of confusion and struggle in the respective MOOC forums, but with the large volume of posts and high workloads for MOOC instructors, it is unlikely that the instructors can identify all learners requiring intervention. This problem has been studied as a Natural Language Processing (NLP) problem recently, and is known to be challenging, due to the imbalance of the data and the complex nature of the task. In this paper, we explore for the first time Bayesian deep learning on learner-based text posts with two methods: Monte Carlo Dropout and Variational Inference, as a new solution to assessing the need of instructor interventions for a learner's post. We compare models based on our proposed methods with probabilistic modelling to its baseline non-Bayesian models under similar circumstances, for different cases of applying prediction. The results suggest that Bayesian deep learning offers a critical uncertainty measure that is not supplied by traditional neural networks. This adds more explainability, trust and robustness to AI, which is crucial in education-based applications. Additionally, it can achieve similar or better performance compared to non-probabilistic neural networks, as well as grant lower variance.

</p>
</details>

<details><summary><b>Generalized ADMM in Distributed Learning via Variational Inequality</b>
<a href="https://arxiv.org/abs/2104.12608">arxiv:2104.12608</a>
&#x1F4C8; 2 <br>
<p>Saeedeh Parsaeefard, Alberto Leon Garcia</p></summary>
<p>

**Abstract:** Due to the explosion in size and complexity of modern data sets and privacy concerns of data holders, it is increasingly important to be able to solve machine learning problems in distributed manners. The Alternating Direction Method of Multipliers (ADMM) through the concept of consensus variables is a practical algorithm in this context where its diverse variations and its performance have been studied in different application areas. In this paper, we study the effect of the local data sets of users in the distributed learning of ADMM. Our aim is to deploy variational inequality (VI) to attain an unified view of ADMM variations. Through the simulation results, we demonstrate how more general definitions of consensus parameters and introducing the uncertain parameters in distribute approach can help to get the better results in learning processes.

</p>
</details>

<details><summary><b>Consistency issues in Gaussian Mixture Models reduction algorithms</b>
<a href="https://arxiv.org/abs/2104.12586">arxiv:2104.12586</a>
&#x1F4C8; 2 <br>
<p>A. D'Ortenzio, C. Manes</p></summary>
<p>

**Abstract:** In many contexts Gaussian Mixtures (GM) are used to approximate probability distributions, possibly time-varying. In some applications the number of GM components exponentially increases over time, and reduction procedures are required to keep them reasonably limited. The GM reduction (GMR) problem can be formulated by choosing different measures of the dissimilarity of GMs before and after reduction, like the Kullback-Leibler Divergence (KLD) and the Integral Squared Error (ISE). Since in no case the solution is obtained in closed form, many approximate GMR algorithms have been proposed in the past three decades, although none of them provides optimality guarantees. In this work we discuss the importance of the choice of the dissimilarity measure and the issue of consistency of all steps of a reduction algorithm with the chosen measure. Indeed, most of the existing GMR algorithms are composed by several steps which are not consistent with a unique measure, and for this reason may produce reduced GMs far from optimality. In particular, the use of the KLD, of the ISE and normalized ISE is discussed and compared in this perspective.

</p>
</details>

<details><summary><b>Fast Falsification of Neural Networks using Property Directed Testing</b>
<a href="https://arxiv.org/abs/2104.12418">arxiv:2104.12418</a>
&#x1F4C8; 2 <br>
<p>Moumita Das, Rajarshi Ray, Swarup Kumar Mohalik, Ansuman Banerjee</p></summary>
<p>

**Abstract:** Neural networks are now extensively used in perception, prediction and control of autonomous systems. Their deployment in safety-critical systems brings forth the need for verification techniques for such networks. As an alternative to exhaustive and costly verification algorithms, lightweight falsification algorithms have been heavily used to search for an input to the system that produces an unsafe output, i.e., a counterexample to the safety of the system. In this work, we propose a falsification algorithm for neural networks that directs the search for a counterexample, guided by a safety property specification. Our algorithm uses a derivative-free sampling-based optimization method. We evaluate our algorithm on 45 trained neural network benchmarks of the ACAS Xu system against 10 safety properties. We show that our falsification procedure detects all the unsafe instances that other verification tools also report as unsafe. Moreover, in terms of performance, our falsification procedure identifies most of the unsafe instances faster, in comparison to the state-of-the-art verification tools for feed-forward neural networks such as NNENUM and Neurify and in many instances, by orders of magnitude.

</p>
</details>

<details><summary><b>Model Guided Road Intersection Classification</b>
<a href="https://arxiv.org/abs/2104.12417">arxiv:2104.12417</a>
&#x1F4C8; 2 <br>
<p>Augusto Luis Ballardini, Álvaro Hernández, Miguel Ángel Sotelo</p></summary>
<p>

**Abstract:** Understanding complex scenarios from in-vehicle cameras is essential for safely operating autonomous driving systems in densely populated areas. Among these, intersection areas are one of the most critical as they concentrate a considerable number of traffic accidents and fatalities. Detecting and understanding the scene configuration of these usually crowded areas is then of extreme importance for both autonomous vehicles and modern ADAS aimed at preventing road crashes and increasing the safety of vulnerable road users. This work investigates inter-section classification from RGB images using well-consolidate neural network approaches along with a method to enhance the results based on the teacher/student training paradigm. An extensive experimental activity aimed at identifying the best input configuration and evaluating different network parameters on both the well-known KITTI dataset and the new KITTI-360 sequences shows that our method outperforms current state-of-the-art approaches on a per-frame basis and prove the effectiveness of the proposed learning scheme.

</p>
</details>

<details><summary><b>Finite sample approximations of exact and entropic Wasserstein distances between covariance operators and Gaussian processes</b>
<a href="https://arxiv.org/abs/2104.12368">arxiv:2104.12368</a>
&#x1F4C8; 2 <br>
<p>Minh Ha Quang</p></summary>
<p>

**Abstract:** This work studies finite sample approximations of the exact and entropic regularized Wasserstein distances between centered Gaussian processes and, more generally, covariance operators of functional random processes. We first show that these distances/divergences are fully represented by reproducing kernel Hilbert space (RKHS) covariance and cross-covariance operators associated with the corresponding covariance functions. Using this representation, we show that the Sinkhorn divergence between two centered Gaussian processes can be consistently and efficiently estimated from the divergence between their corresponding normalized finite-dimensional covariance matrices, or alternatively, their sample covariance operators. Consequently, this leads to a consistent and efficient algorithm for estimating the Sinkhorn divergence from finite samples generated by the two processes. For a fixed regularization parameter, the convergence rates are {\it dimension-independent} and of the same order as those for the Hilbert-Schmidt distance. If at least one of the RKHS is finite-dimensional, we obtain a {\it dimension-dependent} sample complexity for the exact Wasserstein distance between the Gaussian processes.

</p>
</details>

<details><summary><b>To mock a Mocking bird : Studies in Biomimicry</b>
<a href="https://arxiv.org/abs/2104.13228">arxiv:2104.13228</a>
&#x1F4C8; 1 <br>
<p>Inavamsi Enaganti, Bud Mishra</p></summary>
<p>

**Abstract:** This paper dwells on certain novel game-theoretic investigations in bio-mimicry, discussed from the perspectives of information asymmetry, individual utility and its optimization via strategic interactions involving co-evolving preys (e.g., insects) and predators (e.g., reptiles) who learn. Formally, we consider a panmictic ecosystem, occupied by species of prey with relatively short lifespan, which evolve mimicry signals over generations as they interact with predators with relatively longer lifespans, thus endowing predators with the ability to learn prey signals. Every prey sends a signal and provides utility to the predator. The prey can be either nutritious or toxic to the predator, but the prey may signal (possibly) deceptively without revealing its true "type." The model is used to study the situation where multi-armed bandit predators with zero prior information are introduced into the ecosystem. As a result of exploration and exploitation the predators naturally select the prey that result in the evolution of those signals. This co-evolution of strategies produces a variety of interesting phenomena which are subjects of this paper.

</p>
</details>

<details><summary><b>Three-Dimensional Embedded Attentive RNN (3D-EAR) Segmentor for Left Ventricle Delineation from Myocardial Velocity Mapping</b>
<a href="https://arxiv.org/abs/2104.13214">arxiv:2104.13214</a>
&#x1F4C8; 1 <br>
<p>Mengmeng Kuang, Yinzhe Wu, Diego Alonso-Álvarez, David Firmin, Jennifer Keegan, Peter Gatehouse, Guang Yang</p></summary>
<p>

**Abstract:** Myocardial Velocity Mapping Cardiac MR (MVM-CMR) can be used to measure global and regional myocardial velocities with proved reproducibility. Accurate left ventricle delineation is a prerequisite for robust and reproducible myocardial velocity estimation. Conventional manual segmentation on this dataset can be time-consuming and subjective, and an effective fully automated delineation method is highly in demand. By leveraging recently proposed deep learning-based semantic segmentation approaches, in this study, we propose a novel fully automated framework incorporating a 3D-UNet backbone architecture with Embedded multichannel Attention mechanism and LSTM based Recurrent neural networks (RNN) for the MVM-CMR datasets (dubbed 3D-EAR segmentor). The proposed method also utilises the amalgamation of magnitude and phase images as input to realise an information fusion of this multichannel dataset and exploring the correlations of temporal frames via the embedded RNN. By comparing the baseline model of 3D-UNet and ablation studies with and without embedded attentive LSTM modules and various loss functions, we can demonstrate that the proposed model has outperformed the state-of-the-art baseline models with significant improvement.

</p>
</details>

<details><summary><b>Provably Convergent Learned Inexact Descent Algorithm for Low-Dose CT Reconstruction</b>
<a href="https://arxiv.org/abs/2104.12939">arxiv:2104.12939</a>
&#x1F4C8; 1 <br>
<p>Qingchao Zhang, Mehrdad Alvandipour, Wenjun Xia, Yi Zhang, Xiaojing Ye, Yunmei Chen</p></summary>
<p>

**Abstract:** We propose a provably convergent method, called Efficient Learned Descent Algorithm (ELDA), for low-dose CT (LDCT) reconstruction. ELDA is a highly interpretable neural network architecture with learned parameters and meanwhile retains convergence guarantee as classical optimization algorithms. To improve reconstruction quality, the proposed ELDA also employs a new non-local feature mapping and an associated regularizer. We compare ELDA with several state-of-the-art deep image methods, such as RED-CNN and Learned Primal-Dual, on a set of LDCT reconstruction problems. Numerical experiments demonstrate improvement of reconstruction quality using ELDA with merely 19 layers, suggesting the promising performance of ELDA in solution accuracy and parameter efficiency.

</p>
</details>

<details><summary><b>Multi-resource allocation for federated settings: A non-homogeneous Markov chain model</b>
<a href="https://arxiv.org/abs/2104.12828">arxiv:2104.12828</a>
&#x1F4C8; 1 <br>
<p>Syed Eqbal Alam, Fabian Wirth, Jia Yuan Yu</p></summary>
<p>

**Abstract:** In a federated setting, agents coordinate with a central agent or a server to solve an optimization problem in which agents do not share their information with each other. Wirth and his co-authors, in a recent paper, describe how the basic additive-increase multiplicative-decrease (AIMD) algorithm can be modified in a straightforward manner to solve a class of optimization problems for federated settings for a single shared resource with no inter-agent communication. The AIMD algorithm is one of the most successful distributed resource allocation algorithms currently deployed in practice. It is best known as the backbone of the Internet and is also widely explored in other application areas. We extend the single-resource algorithm to multiple heterogeneous shared resources that emerge in smart cities, sharing economy, and many other applications. Our main results show the convergence of the average allocations to the optimal values. We model the system as a non-homogeneous Markov chain with place-dependent probabilities. Furthermore, simulation results are presented to demonstrate the efficacy of the algorithms and to highlight the main features of our analysis.

</p>
</details>

<details><summary><b>Recommending Burgers based on Pizza Preferences: Addressing Data Sparsity with a Product of Experts</b>
<a href="https://arxiv.org/abs/2104.12822">arxiv:2104.12822</a>
&#x1F4C8; 1 <br>
<p>Martin Milenkoski, Diego Antognini, Claudiu Musat</p></summary>
<p>

**Abstract:** In this paper, we describe a method to tackle data sparsity and create recommendations in domains with limited knowledge about user preferences. We expand the variational autoencoder collaborative filtering from a single-domain to a multi-domain setting. The intuition is that user-item interactions in a source domain can augment the recommendation quality in a target domain. The intuition can be taken to its extreme, where, in a cross-domain setup, the user history in a source domain is enough to generate high-quality recommendations in a target one. We thus create a Product-of-Experts (POE) architecture for recommendations that jointly models user-item interactions across multiple domains. The method is resilient to missing data for one or more of the domains, which is a situation often found in real life. We present results on two widely-used datasets - Amazon and Yelp, which support the claim that holistic user preference knowledge leads to better recommendations. Surprisingly, we find that in some cases, a POE recommender that does not access the target domain user representation can surpass a strong VAE recommender baseline trained on the target domain.

</p>
</details>

<details><summary><b>Cloud computing as a platform for monetizing data services: A two-sided game business model</b>
<a href="https://arxiv.org/abs/2104.12762">arxiv:2104.12762</a>
&#x1F4C8; 1 <br>
<p>Ahmed Saleh Bataineh, Jamal Bentahar, Rabeb Mizouni, Omar Abdel Wahab, Gaith Rjoub, May El Barachi</p></summary>
<p>

**Abstract:** With the unprecedented reliance on cloud computing as the backbone for storing today's big data, we argue in this paper that the role of the cloud should be reshaped from being a passive virtual market to become an active platform for monetizing the big data through Artificial Intelligence (AI) services. The objective is to enable the cloud to be an active platform that can help big data service providers reach a wider set of customers and cloud users (i.e., data consumers) to be exposed to a larger and richer variety of data to run their data analytic tasks. To achieve this vision, we propose a novel game theoretical model, which consists of a mix of cooperative and competitive strategies. The players of the game are the big data service providers, cloud computing platform, and cloud users. The strategies of the players are modeled using the two-sided market theory that takes into consideration the network effects among involved parties, while integrating the externalities between the cloud resources and consumer demands into the design of the game. Simulations conducted using Amazon and google clustered data show that the proposed model improves the total surplus of all the involved parties in terms of cloud resources provision and monetary profits compared to the current merchant model.

</p>
</details>

<details><summary><b>ANT: Learning Accurate Network Throughput for Better Adaptive Video Streaming</b>
<a href="https://arxiv.org/abs/2104.12507">arxiv:2104.12507</a>
&#x1F4C8; 1 <br>
<p>Jiaoyang Yin, Yiling Xu, Hao Chen, Yunfei Zhang, Steve Appleby, Zhan Ma</p></summary>
<p>

**Abstract:** Adaptive Bit Rate (ABR) decision plays a crucial role for ensuring satisfactory Quality of Experience (QoE) in video streaming applications, in which past network statistics are mainly leveraged for future network bandwidth prediction. However, most algorithms, either rules-based or learning-driven approaches, feed throughput traces or classified traces based on traditional statistics (i.e., mean/standard deviation) to drive ABR decision, leading to compromised performances in specific scenarios. Given the diverse network connections (e.g., WiFi, cellular and wired link) from time to time, this paper thus proposes to learn the ANT (a.k.a., Accurate Network Throughput) model to characterize the full spectrum of network throughput dynamics in the past for deriving the proper network condition associated with a specific cluster of network throughput segments (NTS). Each cluster of NTS is then used to generate a dedicated ABR model, by which we wish to better capture the network dynamics for diverse connections. We have integrated the ANT model with existing reinforcement learning (RL)-based ABR decision engine, where different ABR models are applied to respond to the accurate network sensing for better rate decision. Extensive experiment results show that our approach can significantly improve the user QoE by 65.5% and 31.3% respectively, compared with the state-of-the-art Pensive and Oboe, across a wide range of network scenarios.

</p>
</details>

<details><summary><b>Axes for Sociotechnical Inquiry in AI Research</b>
<a href="https://arxiv.org/abs/2105.06551">arxiv:2105.06551</a>
&#x1F4C8; 0 <br>
<p>Sarah Dean, Thomas Krendl Gilbert, Nathan Lambert, Tom Zick</p></summary>
<p>

**Abstract:** The development of artificial intelligence (AI) technologies has far exceeded the investigation of their relationship with society. Sociotechnical inquiry is needed to mitigate the harms of new technologies whose potential impacts remain poorly understood. To date, subfields of AI research develop primarily individual views on their relationship with sociotechnics, while tools for external investigation, comparison, and cross-pollination are lacking. In this paper, we propose four directions for inquiry into new and evolving areas of technological development: value--what progress and direction does a field promote, optimization--how the defined system within a problem formulation relates to broader dynamics, consensus--how agreement is achieved and who is included in building it, and failure--what methods are pursued when the problem specification is found wanting. The paper provides a lexicon for sociotechnical inquiry and illustrates it through the example of consumer drone technology.

</p>
</details>

<details><summary><b>A Graph Federated Architecture with Privacy Preserving Learning</b>
<a href="https://arxiv.org/abs/2104.13215">arxiv:2104.13215</a>
&#x1F4C8; 0 <br>
<p>Elsa Rizk, Ali H. Sayed</p></summary>
<p>

**Abstract:** Federated learning involves a central processor that works with multiple agents to find a global model. The process consists of repeatedly exchanging estimates, which results in the diffusion of information pertaining to the local private data. Such a scheme can be inconvenient when dealing with sensitive data, and therefore, there is a need for the privatization of the algorithms. Furthermore, the current architecture of a server connected to multiple clients is highly sensitive to communication failures and computational overloads at the server. Thus in this work, we develop a private multi-server federated learning scheme, which we call graph federated learning. We use cryptographic and differential privacy concepts to privatize the federated learning algorithm that we extend to the graph structure. We study the effect of privatization on the performance of the learning algorithm for general private schemes that can be modeled as additive noise. We show under convexity and Lipschitz conditions, that the privatized process matches the performance of the non-private algorithm, even when we increase the noise variance.

</p>
</details>

<details><summary><b>Less is more: Selecting informative and diverse subsets with balancing constraints</b>
<a href="https://arxiv.org/abs/2104.12835">arxiv:2104.12835</a>
&#x1F4C8; 0 <br>
<p>Srikumar Ramalingam, Daniel Glasner, Kaushal Patel, Raviteja Vemulapalli, Sadeep Jayasumana, Sanjiv Kumar</p></summary>
<p>

**Abstract:** Deep learning has yielded extraordinary results in vision and natural language processing, but this achievement comes at a cost. Most models require enormous resources during training, both in terms of computation and in human labeling effort. We show that we can identify informative and diverse subsets of data that lead to deep learning models with similar performance as the ones trained with the original dataset. Prior methods have exploited diversity and uncertainty in submodular objective functions for choosing subsets. In addition to these measures, we show that balancing constraints on predicted class labels and decision boundaries are beneficial. We propose a novel formulation of these constraints using matroids, an algebraic structure that generalizes linear independence in vector spaces, and present an efficient greedy algorithm with constant approximation guarantees. We outperform competing baselines on standard classification datasets such as CIFAR-10, CIFAR-100, ImageNet, as well as long-tailed datasets such as CIFAR-100-LT.

</p>
</details>

<details><summary><b>Vision Transformers with Patch Diversification</b>
<a href="https://arxiv.org/abs/2104.12753">arxiv:2104.12753</a>
&#x1F4C8; 0 <br>
<p>Chengyue Gong, Dilin Wang, Meng Li, Vikas Chandra, Qiang Liu</p></summary>
<p>

**Abstract:** Vision transformer has demonstrated promising performance on challenging computer vision tasks. However, directly training the vision transformers may yield unstable and sub-optimal results. Recent works propose to improve the performance of the vision transformers by modifying the transformer structures, e.g., incorporating convolution layers. In contrast, we investigate an orthogonal approach to stabilize the vision transformer training without modifying the networks. We observe the instability of the training can be attributed to the significant similarity across the extracted patch representations. More specifically, for deep vision transformers, the self-attention blocks tend to map different patches into similar latent representations, yielding information loss and performance degradation. To alleviate this problem, in this work, we introduce novel loss functions in vision transformer training to explicitly encourage diversity across patch representations for more discriminative feature extraction. We empirically show that our proposed techniques stabilize the training and allow us to train wider and deeper vision transformers. We further show the diversified features significantly benefit the downstream tasks in transfer learning. For semantic segmentation, we enhance the state-of-the-art (SOTA) results on Cityscapes and ADE20k. Our code is available at https://github.com/ChengyueGongR/PatchVisionTransformer.

</p>
</details>

<details><summary><b>tsrobprep - an R package for robust preprocessing of time series data</b>
<a href="https://arxiv.org/abs/2104.12657">arxiv:2104.12657</a>
&#x1F4C8; 0 <br>
<p>Michał Narajewski, Jens Kley-Holsteg, Florian Ziel</p></summary>
<p>

**Abstract:** Data cleaning is a crucial part of every data analysis exercise. Yet, the currently available R packages do not provide fast and robust methods for cleaning and preparation of time series data. The open source package tsrobprep introduces efficient methods for handling missing values and outliers using model based approaches. For data imputation a probabilistic replacement model is proposed, which may consist of autoregressive components and external inputs. For outlier detection a clustering algorithm based on finite mixture modelling is introduced, which considers time series properties in terms of the gradient and the underlying seasonality as features. The procedure allows to return a probability for each observation being outlying data as well as a specific cause for an outlier assignment in terms of the provided feature space. The methods work robust and are fully tunable. Moreover, by providing the auto_data_cleaning function the data preprocessing can be carried out in one cast, without comprehensive tuning and providing suitable results. The primary motivation of the package is the preprocessing of energy system data. We present application for electricity load, wind and solar power data.

</p>
</details>


[Next Page](2021/2021-04/2021-04-25.md)
