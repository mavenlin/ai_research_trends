## Summary for 2021-02-08, created on 2021-12-23


<details><summary><b>Learning Curve Theory</b>
<a href="https://arxiv.org/abs/2102.04074">arxiv:2102.04074</a>
&#x1F4C8; 275 <br>
<p>Marcus Hutter</p></summary>
<p>

**Abstract:** Recently a number of empirical "universal" scaling law papers have been published, most notably by OpenAI. `Scaling laws' refers to power-law decreases of training or test error w.r.t. more data, larger neural networks, and/or more compute. In this work we focus on scaling w.r.t. data size $n$. Theoretical understanding of this phenomenon is largely lacking, except in finite-dimensional models for which error typically decreases with $n^{-1/2}$ or $n^{-1}$, where $n$ is the sample size. We develop and theoretically analyse the simplest possible (toy) model that can exhibit $n^{-β}$ learning curves for arbitrary power $β>0$, and determine whether power laws are universal or depend on the data distribution.

</p>
</details>

<details><summary><b>Colorization Transformer</b>
<a href="https://arxiv.org/abs/2102.04432">arxiv:2102.04432</a>
&#x1F4C8; 133 <br>
<p>Manoj Kumar, Dirk Weissenborn, Nal Kalchbrenner</p></summary>
<p>

**Abstract:** We present the Colorization Transformer, a novel approach for diverse high fidelity image colorization based on self-attention. Given a grayscale image, the colorization proceeds in three steps. We first use a conditional autoregressive transformer to produce a low resolution coarse coloring of the grayscale image. Our architecture adopts conditional transformer layers to effectively condition grayscale input. Two subsequent fully parallel networks upsample the coarse colored low resolution image into a finely colored high resolution image. Sampling from the Colorization Transformer produces diverse colorings whose fidelity outperforms the previous state-of-the-art on colorising ImageNet based on FID results and based on a human evaluation in a Mechanical Turk test. Remarkably, in more than 60% of cases human evaluators prefer the highest rated among three generated colorings over the ground truth. The code and pre-trained checkpoints for Colorization Transformer are publicly available at https://github.com/google-research/google-research/tree/master/coltran

</p>
</details>

<details><summary><b>Adversarially Guided Actor-Critic</b>
<a href="https://arxiv.org/abs/2102.04376">arxiv:2102.04376</a>
&#x1F4C8; 78 <br>
<p>Yannis Flet-Berliac, Johan Ferret, Olivier Pietquin, Philippe Preux, Matthieu Geist</p></summary>
<p>

**Abstract:** Despite definite success in deep reinforcement learning problems, actor-critic algorithms are still confronted with sample inefficiency in complex environments, particularly in tasks where efficient exploration is a bottleneck. These methods consider a policy (the actor) and a value function (the critic) whose respective losses are built using different motivations and approaches. This paper introduces a third protagonist: the adversary. While the adversary mimics the actor by minimizing the KL-divergence between their respective action distributions, the actor, in addition to learning to solve the task, tries to differentiate itself from the adversary predictions. This novel objective stimulates the actor to follow strategies that could not have been correctly predicted from previous trajectories, making its behavior innovative in tasks where the reward is extremely rare. Our experimental analysis shows that the resulting Adversarially Guided Actor-Critic (AGAC) algorithm leads to more exhaustive exploration. Notably, AGAC outperforms current state-of-the-art methods on a set of various hard-exploration and procedurally-generated tasks.

</p>
</details>

<details><summary><b>Unlocking Pixels for Reinforcement Learning via Implicit Attention</b>
<a href="https://arxiv.org/abs/2102.04353">arxiv:2102.04353</a>
&#x1F4C8; 64 <br>
<p>Krzysztof Marcin Choromanski, Deepali Jain, Wenhao Yu, Xingyou Song, Jack Parker-Holder, Tingnan Zhang, Valerii Likhosherstov, Aldo Pacchiano, Anirban Santara, Yunhao Tang, Jie Tan, Adrian Weller</p></summary>
<p>

**Abstract:** There has recently been significant interest in training reinforcement learning (RL) agents in vision-based environments. This poses many challenges, such as high dimensionality and the potential for observational overfitting through spurious correlations. A promising approach to solve both of these problems is an attention bottleneck, which provides a simple and effective framework for learning high performing policies, even in the presence of distractions. However, due to poor scalability of attention architectures, these methods cannot be applied beyond low resolution visual inputs, using large patches (thus small attention matrices). In this paper we make use of new efficient attention algorithms, recently shown to be highly effective for Transformers, and demonstrate that these techniques can be successfully adopted for the RL setting. This allows our attention-based controllers to scale to larger visual inputs, and facilitate the use of smaller patches, even individual pixels, improving generalization. We show this on a range of tasks from the Distracting Control Suite to vision-based quadruped robots locomotion. We provide rigorous theoretical analysis of the proposed algorithm.

</p>
</details>

<details><summary><b>Improving Artificial Teachers by Considering How People Learn and Forget</b>
<a href="https://arxiv.org/abs/2102.04174">arxiv:2102.04174</a>
&#x1F4C8; 22 <br>
<p>Aurélien Nioche, Pierre-Alexandre Murena, Carlos de la Torre-Ortiz, Antti Oulasvirta</p></summary>
<p>

**Abstract:** The paper presents a novel model-based method for intelligent tutoring, with particular emphasis on the problem of selecting teaching interventions in interaction with humans. Whereas previous work has focused on either personalization of teaching or optimization of teaching intervention sequences, the proposed individualized model-based planning approach represents convergence of these two lines of research. Model-based planning picks the best interventions via interactive learning of a user memory model's parameters. The approach is novel in its use of a cognitive model that can account for several key individual- and material-specific characteristics related to recall/forgetting, along with a planning technique that considers users' practice schedules. Taking a rule-based approach as a baseline, the authors evaluated the method's benefits in a controlled study of artificial teaching in second-language vocabulary learning (N=53).

</p>
</details>

<details><summary><b>Discovering a set of policies for the worst case reward</b>
<a href="https://arxiv.org/abs/2102.04323">arxiv:2102.04323</a>
&#x1F4C8; 18 <br>
<p>Tom Zahavy, Andre Barreto, Daniel J Mankowitz, Shaobo Hou, Brendan O'Donoghue, Iurii Kemaev, Satinder Singh</p></summary>
<p>

**Abstract:** We study the problem of how to construct a set of policies that can be composed together to solve a collection of reinforcement learning tasks. Each task is a different reward function defined as a linear combination of known features. We consider a specific class of policy compositions which we call set improving policies (SIPs): given a set of policies and a set of tasks, a SIP is any composition of the former whose performance is at least as good as that of its constituents across all the tasks. We focus on the most conservative instantiation of SIPs, set-max policies (SMPs), so our analysis extends to any SIP. This includes known policy-composition operators like generalized policy improvement. Our main contribution is a policy iteration algorithm that builds a set of policies in order to maximize the worst-case performance of the resulting SMP on the set of tasks. The algorithm works by successively adding new policies to the set. We show that the worst-case performance of the resulting SMP strictly improves at each iteration, and the algorithm only stops when there does not exist a policy that leads to improved performance. We empirically evaluate our algorithm on a grid world and also on a set of domains from the DeepMind control suite. We confirm our theoretical results regarding the monotonically improving performance of our algorithm. Interestingly, we also show empirically that the sets of policies computed by the algorithm are diverse, leading to different trajectories in the grid world and very distinct locomotion skills in the control suite.

</p>
</details>

<details><summary><b>Improving filling level classification with adversarial training</b>
<a href="https://arxiv.org/abs/2102.04057">arxiv:2102.04057</a>
&#x1F4C8; 16 <br>
<p>Apostolos Modas, Alessio Xompero, Ricardo Sanchez-Matilla, Pascal Frossard, Andrea Cavallaro</p></summary>
<p>

**Abstract:** We investigate the problem of classifying - from a single image - the level of content in a cup or a drinking glass. This problem is made challenging by several ambiguities caused by transparencies, shape variations and partial occlusions, and by the availability of only small training datasets. In this paper, we tackle this problem with an appropriate strategy for transfer learning. Specifically, we use adversarial training in a generic source dataset and then refine the training with a task-specific dataset. We also discuss and experimentally evaluate several training strategies and their combination on a range of container types of the CORSMAL Containers Manipulation dataset. We show that transfer learning with adversarial training in the source domain consistently improves the classification accuracy on the test set and limits the overfitting of the classifier to specific features of the training data.

</p>
</details>

<details><summary><b>LightSpeech: Lightweight and Fast Text to Speech with Neural Architecture Search</b>
<a href="https://arxiv.org/abs/2102.04040">arxiv:2102.04040</a>
&#x1F4C8; 15 <br>
<p>Renqian Luo, Xu Tan, Rui Wang, Tao Qin, Jinzhu Li, Sheng Zhao, Enhong Chen, Tie-Yan Liu</p></summary>
<p>

**Abstract:** Text to speech (TTS) has been broadly used to synthesize natural and intelligible speech in different scenarios. Deploying TTS in various end devices such as mobile phones or embedded devices requires extremely small memory usage and inference latency. While non-autoregressive TTS models such as FastSpeech have achieved significantly faster inference speed than autoregressive models, their model size and inference latency are still large for the deployment in resource constrained devices. In this paper, we propose LightSpeech, which leverages neural architecture search~(NAS) to automatically design more lightweight and efficient models based on FastSpeech. We first profile the components of current FastSpeech model and carefully design a novel search space containing various lightweight and potentially effective architectures. Then NAS is utilized to automatically discover well performing architectures within the search space. Experiments show that the model discovered by our method achieves 15x model compression ratio and 6.5x inference speedup on CPU with on par voice quality. Audio demos are provided at https://speechresearch.github.io/lightspeech.

</p>
</details>

<details><summary><b>Learned Camera Gain and Exposure Control for Improved Visual Feature Detection and Matching</b>
<a href="https://arxiv.org/abs/2102.04341">arxiv:2102.04341</a>
&#x1F4C8; 10 <br>
<p>Justin Tomasi, Brandon Wagstaff, Steven L. Waslander, Jonathan Kelly</p></summary>
<p>

**Abstract:** Successful visual navigation depends upon capturing images that contain sufficient useful information. In this paper, we explore a data-driven approach to account for environmental lighting changes, improving the quality of images for use in visual odometry (VO) or visual simultaneous localization and mapping (SLAM). We train a deep convolutional neural network model to predictively adjust camera gain and exposure time parameters such that consecutive images contain a maximal number of matchable features. The training process is fully self-supervised: our training signal is derived from an underlying VO or SLAM pipeline and, as a result, the model is optimized to perform well with that specific pipeline. We demonstrate through extensive real-world experiments that our network can anticipate and compensate for dramatic lighting changes (e.g., transitions into and out of road tunnels), maintaining a substantially higher number of inlier feature matches than competing camera parameter control algorithms.

</p>
</details>

<details><summary><b>Partition-based formulations for mixed-integer optimization of trained ReLU neural networks</b>
<a href="https://arxiv.org/abs/2102.04373">arxiv:2102.04373</a>
&#x1F4C8; 9 <br>
<p>Calvin Tsay, Jan Kronqvist, Alexander Thebelt, Ruth Misener</p></summary>
<p>

**Abstract:** This paper introduces a class of mixed-integer formulations for trained ReLU neural networks. The approach balances model size and tightness by partitioning node inputs into a number of groups and forming the convex hull over the partitions via disjunctive programming. At one extreme, one partition per input recovers the convex hull of a node, i.e., the tightest possible formulation for each node. For fewer partitions, we develop smaller relaxations that approximate the convex hull, and show that they outperform existing formulations. Specifically, we propose strategies for partitioning variables based on theoretical motivations and validate these strategies using extensive computational experiments. Furthermore, the proposed scheme complements known algorithmic approaches, e.g., optimization-based bound tightening captures dependencies within a partition.

</p>
</details>

<details><summary><b>Generating Fake Cyber Threat Intelligence Using Transformer-Based Models</b>
<a href="https://arxiv.org/abs/2102.04351">arxiv:2102.04351</a>
&#x1F4C8; 9 <br>
<p>Priyanka Ranade, Aritran Piplai, Sudip Mittal, Anupam Joshi, Tim Finin</p></summary>
<p>

**Abstract:** Cyber-defense systems are being developed to automatically ingest Cyber Threat Intelligence (CTI) that contains semi-structured data and/or text to populate knowledge graphs. A potential risk is that fake CTI can be generated and spread through Open-Source Intelligence (OSINT) communities or on the Web to effect a data poisoning attack on these systems. Adversaries can use fake CTI examples as training input to subvert cyber defense systems, forcing the model to learn incorrect inputs to serve their malicious needs.
  In this paper, we automatically generate fake CTI text descriptions using transformers. We show that given an initial prompt sentence, a public language model like GPT-2 with fine-tuning, can generate plausible CTI text with the ability of corrupting cyber-defense systems. We utilize the generated fake CTI text to perform a data poisoning attack on a Cybersecurity Knowledge Graph (CKG) and a cybersecurity corpus. The poisoning attack introduced adverse impacts such as returning incorrect reasoning outputs, representation poisoning, and corruption of other dependent AI-based cyber defense systems. We evaluate with traditional approaches and conduct a human evaluation study with cybersecurity professionals and threat hunters. Based on the study, professional threat hunters were equally likely to consider our fake generated CTI as true.

</p>
</details>

<details><summary><b>Deep Iteration Assisted by Multi-level Obey-pixel Network Discriminator (DIAMOND) for Medical Image Recovery</b>
<a href="https://arxiv.org/abs/2102.06102">arxiv:2102.06102</a>
&#x1F4C8; 8 <br>
<p>Moran Xu, Dianlin Hu, Weifei Wu, Weiwen Wu</p></summary>
<p>

**Abstract:** Image restoration is a typical ill-posed problem, and it contains various tasks. In the medical imaging field, an ill-posed image interrupts diagnosis and even following image processing. Both traditional iterative and up-to-date deep networks have attracted much attention and obtained a significant improvement in reconstructing satisfying images. This study combines their advantages into one unified mathematical model and proposes a general image restoration strategy to deal with such problems. This strategy consists of two modules. First, a novel generative adversarial net(GAN) with WGAN-GP training is built to recover image structures and subtle details. Then, a deep iteration module promotes image quality with a combination of pre-trained deep networks and compressed sensing algorithms by ADMM optimization. (D)eep (I)teration module suppresses image artifacts and further recovers subtle image details, (A)ssisted by (M)ulti-level (O)bey-pixel feature extraction networks (D)iscriminator to recover general structures. Therefore, the proposed strategy is named DIAMOND.

</p>
</details>

<details><summary><b>(AF)2-S3Net: Attentive Feature Fusion with Adaptive Feature Selection for Sparse Semantic Segmentation Network</b>
<a href="https://arxiv.org/abs/2102.04530">arxiv:2102.04530</a>
&#x1F4C8; 8 <br>
<p>Ran Cheng, Ryan Razani, Ehsan Taghavi, Enxu Li, Bingbing Liu</p></summary>
<p>

**Abstract:** Autonomous robotic systems and self driving cars rely on accurate perception of their surroundings as the safety of the passengers and pedestrians is the top priority. Semantic segmentation is one the essential components of environmental perception that provides semantic information of the scene. Recently, several methods have been introduced for 3D LiDAR semantic segmentation. While, they can lead to improved performance, they are either afflicted by high computational complexity, therefore are inefficient, or lack fine details of smaller instances. To alleviate this problem, we propose AF2-S3Net, an end-to-end encoder-decoder CNN network for 3D LiDAR semantic segmentation. We present a novel multi-branch attentive feature fusion module in the encoder and a unique adaptive feature selection module with feature map re-weighting in the decoder. Our AF2-S3Net fuses the voxel based learning and point-based learning into a single framework to effectively process the large 3D scene. Our experimental results show that the proposed method outperforms the state-of-the-art approaches on the large-scale SemanticKITTI benchmark, ranking 1st on the competitive public leaderboard competition upon publication.

</p>
</details>

<details><summary><b>SGD in the Large: Average-case Analysis, Asymptotics, and Stepsize Criticality</b>
<a href="https://arxiv.org/abs/2102.04396">arxiv:2102.04396</a>
&#x1F4C8; 8 <br>
<p>Courtney Paquette, Kiwon Lee, Fabian Pedregosa, Elliot Paquette</p></summary>
<p>

**Abstract:** We propose a new framework, inspired by random matrix theory, for analyzing the dynamics of stochastic gradient descent (SGD) when both number of samples and dimensions are large. This framework applies to any fixed stepsize and the finite sum setting. Using this new framework, we show that the dynamics of SGD on a least squares problem with random data become deterministic in the large sample and dimensional limit. Furthermore, the limiting dynamics are governed by a Volterra integral equation. This model predicts that SGD undergoes a phase transition at an explicitly given critical stepsize that ultimately affects its convergence rate, which we also verify experimentally. Finally, when input data is isotropic, we provide explicit expressions for the dynamics and average-case convergence rates (i.e., the complexity of an algorithm averaged over all possible inputs). These rates show significant improvement over the worst-case complexities.

</p>
</details>

<details><summary><b>RANP: Resource Aware Neuron Pruning at Initialization for 3D CNNs</b>
<a href="https://arxiv.org/abs/2103.08457">arxiv:2103.08457</a>
&#x1F4C8; 7 <br>
<p>Zhiwei Xu, Thalaiyasingam Ajanthan, Vibhav Vineet, Richard Hartley</p></summary>
<p>

**Abstract:** Although 3D Convolutional Neural Networks are essential for most learning based applications involving dense 3D data, their applicability is limited due to excessive memory and computational requirements. Compressing such networks by pruning therefore becomes highly desirable. However, pruning 3D CNNs is largely unexplored possibly because of the complex nature of typical pruning algorithms that embeds pruning into an iterative optimization paradigm. In this work, we introduce a Resource Aware Neuron Pruning (RANP) algorithm that prunes 3D CNNs at initialization to high sparsity levels. Specifically, the core idea is to obtain an importance score for each neuron based on their sensitivity to the loss function. This neuron importance is then reweighted according to the neuron resource consumption related to FLOPs or memory. We demonstrate the effectiveness of our pruning method on 3D semantic segmentation with widely used 3D-UNets on ShapeNet and BraTS'18 datasets, video classification with MobileNetV2 and I3D on UCF101 dataset, and two-view stereo matching with Pyramid Stereo Matching (PSM) network on SceneFlow dataset. In these experiments, our RANP leads to roughly 50%-95% reduction in FLOPs and 35%-80% reduction in memory with negligible loss in accuracy compared to the unpruned networks. This significantly reduces the computational resources required to train 3D CNNs. The pruned network obtained by our algorithm can also be easily scaled up and transferred to another dataset for training.

</p>
</details>

<details><summary><b>Escaping Stochastic Traps with Aleatoric Mapping Agents</b>
<a href="https://arxiv.org/abs/2102.04399">arxiv:2102.04399</a>
&#x1F4C8; 7 <br>
<p>Augustine N. Mavor-Parker, Kimberly A. Young, Caswell Barry, Lewis D. Griffin</p></summary>
<p>

**Abstract:** Exploration in environments with sparse rewards is difficult for artificial agents. Curiosity driven learning -- using feed-forward prediction errors as intrinsic rewards -- has achieved some success in these scenarios, but fails when faced with action-dependent noise sources. We present aleatoric mapping agents (AMAs), a neuroscience inspired solution modeled on the cholinergic system of the mammalian brain. AMAs aim to explicitly ascertain which dynamics of the environment are unpredictable, regardless of whether those dynamics are induced by the actions of the agent. This is achieved by generating separate forward predictions for the mean and variance of future states and reducing intrinsic rewards for those transitions with high aleatoric variance. We show AMAs are able to effectively circumvent action-dependent stochastic traps that immobilise conventional curiosity driven agents. The code for all experiments presented in this paper is open sourced: http://github.com/self-supervisor/Escaping-Stochastic-Traps-With-Aleatoric-Mapping-Agents.

</p>
</details>

<details><summary><b>Generate and Revise: Reinforcement Learning in Neural Poetry</b>
<a href="https://arxiv.org/abs/2102.04114">arxiv:2102.04114</a>
&#x1F4C8; 7 <br>
<p>Andrea Zugarini, Luca Pasqualini, Stefano Melacci, Marco Maggini</p></summary>
<p>

**Abstract:** Writers, poets, singers usually do not create their compositions in just one breath. Text is revisited, adjusted, modified, rephrased, even multiple times, in order to better convey meanings, emotions and feelings that the author wants to express. Amongst the noble written arts, Poetry is probably the one that needs to be elaborated the most, since the composition has to formally respect predefined meter and rhyming schemes. In this paper, we propose a framework to generate poems that are repeatedly revisited and corrected, as humans do, in order to improve their overall quality. We frame the problem of revising poems in the context of Reinforcement Learning and, in particular, using Proximal Policy Optimization. Our model generates poems from scratch and it learns to progressively adjust the generated text in order to match a target criterion. We evaluate this approach in the case of matching a rhyming scheme, without having any information on which words are responsible of creating rhymes and on how to coherently alter the poem words. The proposed framework is general and, with an appropriate reward shaping, it can be applied to other text generation problems.

</p>
</details>

<details><summary><b>Contrasting Centralized and Decentralized Critics in Multi-Agent Reinforcement Learning</b>
<a href="https://arxiv.org/abs/2102.04402">arxiv:2102.04402</a>
&#x1F4C8; 6 <br>
<p>Xueguang Lyu, Yuchen Xiao, Brett Daley, Christopher Amato</p></summary>
<p>

**Abstract:** Centralized Training for Decentralized Execution, where agents are trained offline using centralized information but execute in a decentralized manner online, has gained popularity in the multi-agent reinforcement learning community. In particular, actor-critic methods with a centralized critic and decentralized actors are a common instance of this idea. However, the implications of using a centralized critic in this context are not fully discussed and understood even though it is the standard choice of many algorithms. We therefore formally analyze centralized and decentralized critic approaches, providing a deeper understanding of the implications of critic choice. Because our theory makes unrealistic assumptions, we also empirically compare the centralized and decentralized critic methods over a wide set of environments to validate our theories and to provide practical advice. We show that there exist misconceptions regarding centralized critics in the current literature and show that the centralized critic design is not strictly beneficial, but rather both centralized and decentralized critics have different pros and cons that should be taken into account by algorithm designers.

</p>
</details>

<details><summary><b>Contrastive Embeddings for Neural Architectures</b>
<a href="https://arxiv.org/abs/2102.04208">arxiv:2102.04208</a>
&#x1F4C8; 6 <br>
<p>Daniel Hesslow, Iacopo Poli</p></summary>
<p>

**Abstract:** The performance of algorithms for neural architecture search strongly depends on the parametrization of the search space. We use contrastive learning to identify networks across different initializations based on their data Jacobians, and automatically produce the first architecture embeddings independent from the parametrization of the search space. Using our contrastive embeddings, we show that traditional black-box optimization algorithms, without modification, can reach state-of-the-art performance in Neural Architecture Search. As our method provides a unified embedding space, we perform for the first time transfer learning between search spaces. Finally, we show the evolution of embeddings during training, motivating future studies into using embeddings at different training stages to gain a deeper understanding of the networks in a search space.

</p>
</details>

<details><summary><b>A Constant Approximation Algorithm for Sequential Random-Order No-Substitution k-Median Clustering</b>
<a href="https://arxiv.org/abs/2102.04050">arxiv:2102.04050</a>
&#x1F4C8; 6 <br>
<p>Tom Hess, Michal Moshkovitz, Sivan Sabato</p></summary>
<p>

**Abstract:** We study k-median clustering under the sequential no-substitution setting. In this setting, a data stream is sequentially observed, and some of the points are selected by the algorithm as cluster centers. However, a point can be selected as a center only immediately after it is observed, before observing the next point. In addition, a selected center cannot be substituted later. We give the first algorithm for this setting that obtains a constant approximation factor on the optimal risk under a random arrival order, an exponential improvement over previous work. This is also the first constant approximation guarantee that holds without any structural assumptions on the input data. Moreover, the number of selected centers is only quasi-linear in k. Our algorithm and analysis are based on a careful risk estimation that avoids outliers, a new concept of a linear bin division, and a multiscale approach to center selection.

</p>
</details>

<details><summary><b>Towards Designing Computer Vision-based Explainable-AI Solution: A Use Case of Livestock Mart Industry</b>
<a href="https://arxiv.org/abs/2103.03096">arxiv:2103.03096</a>
&#x1F4C8; 5 <br>
<p>Devam Dave, Het Naik, Smiti Singhal, Rudresh Dwivedi, Pankesh Patel</p></summary>
<p>

**Abstract:** The objective of an online Mart is to match buyers and sellers, to weigh animals and to oversee their sale. A reliable pricing method can be developed by ML models that can read through historical sales data. However, when AI models suggest or recommend a price, that in itself does not reveal too much (i.e., it acts like a black box) about the qualities and the abilities of an animal. An interested buyer would like to know more about the salient features of an animal before making the right choice based on his requirements. A model capable of explaining the different factors that impact the price point is essential for the needs of the market. It can also inspire confidence in buyers and sellers about the price point offered. To achieve these objectives, we have been working with the team at MartEye, a startup based in Portershed in Galway City, Ireland. Through this paper, we report our work-in-progress research towards building a smart video analytic platform, leveraging Explainable AI techniques.

</p>
</details>

<details><summary><b>Eliminating Sharp Minima from SGD with Truncated Heavy-tailed Noise</b>
<a href="https://arxiv.org/abs/2102.04297">arxiv:2102.04297</a>
&#x1F4C8; 5 <br>
<p>Xingyu Wang, Sewoong Oh, Chang-Han Rhee</p></summary>
<p>

**Abstract:** The empirical success of deep learning is often attributed to SGD's mysterious ability to avoid sharp local minima in the loss landscape, as sharp minima are known to lead to poor generalization. Recently, empirical evidence of heavy-tailed gradient noise was reported in many deep learning tasks, and it was shown in Şimşekli (2019a,b) that SGD can escape sharp local minima under the presence of such heavy-tailed gradient noise, providing a partial solution to the mystery. In this work, we analyze a popular variant of SGD where gradients are truncated above a fixed threshold. We show that it achieves a stronger notion of avoiding sharp minima: it can effectively eliminate sharp local minima entirely from its training trajectory. We characterize the dynamics of truncated SGD driven by heavy-tailed noises. First, we show that the truncation threshold and width of the attraction field dictate the order of the first exit time from the associated local minimum. Moreover, when the objective function satisfies appropriate structural conditions, we prove that as the learning rate decreases, the dynamics of heavy-tailed truncated SGD closely resemble those of a continuous-time Markov chain that never visits any sharp minima. Real data experiments on deep learning confirm our theoretical prediction that heavy-tailed SGD with gradient clipping finds a "flatter" local minima and achieves better generalization.

</p>
</details>

<details><summary><b>EigenGame Unloaded: When playing games is better than optimizing</b>
<a href="https://arxiv.org/abs/2102.04152">arxiv:2102.04152</a>
&#x1F4C8; 5 <br>
<p>Ian Gemp, Brian McWilliams, Claire Vernade, Thore Graepel</p></summary>
<p>

**Abstract:** We build on the recently proposed EigenGame that views eigendecomposition as a competitive game. EigenGame's updates are biased if computed using minibatches of data, which hinders convergence and more sophisticated parallelism in the stochastic setting. In this work, we propose an unbiased stochastic update that is asymptotically equivalent to EigenGame, enjoys greater parallelism allowing computation on datasets of larger sample sizes, and outperforms EigenGame in experiments. We present applications to finding the principal components of massive datasets and performing spectral clustering of graphs. We analyze and discuss our proposed update in the context of EigenGame and the shift in perspective from optimization to games.

</p>
</details>

<details><summary><b>Exploiting epistemic uncertainty of the deep learning models to generate adversarial samples</b>
<a href="https://arxiv.org/abs/2102.04150">arxiv:2102.04150</a>
&#x1F4C8; 5 <br>
<p>Omer Faruk Tuna, Ferhat Ozgur Catak, M. Taner Eskil</p></summary>
<p>

**Abstract:** Deep neural network architectures are considered to be robust to random perturbations. Nevertheless, it was shown that they could be severely vulnerable to slight but carefully crafted perturbations of the input, termed as adversarial samples. In recent years, numerous studies have been conducted in this new area called "Adversarial Machine Learning" to devise new adversarial attacks and to defend against these attacks with more robust DNN architectures. However, almost all the research work so far has been concentrated on utilising model loss function to craft adversarial examples or create robust models. This study explores the usage of quantified epistemic uncertainty obtained from Monte-Carlo Dropout Sampling for adversarial attack purposes by which we perturb the input to the areas where the model has not seen before. We proposed new attack ideas based on the epistemic uncertainty of the model. Our results show that our proposed hybrid attack approach increases the attack success rates from 82.59% to 85.40%, 82.86% to 89.92% and 88.06% to 90.03% on MNIST Digit, MNIST Fashion and CIFAR-10 datasets, respectively.

</p>
</details>

<details><summary><b>Points2Vec: Unsupervised Object-level Feature Learning from Point Clouds</b>
<a href="https://arxiv.org/abs/2102.04136">arxiv:2102.04136</a>
&#x1F4C8; 5 <br>
<p>Joël Bachmann, Kenneth Blomqvist, Julian Förster, Roland Siegwart</p></summary>
<p>

**Abstract:** Unsupervised representation learning techniques, such as learning word embeddings, have had a significant impact on the field of natural language processing. Similar representation learning techniques have not yet become commonplace in the context of 3D vision. This, despite the fact that the physical 3D spaces have a similar semantic structure to bodies of text: words are surrounded by words that are semantically related, just like objects are surrounded by other objects that are similar in concept and usage.
  In this work, we exploit this structure in learning semantically meaningful low dimensional vector representations of objects. We learn these vector representations by mining a dataset of scanned 3D spaces using an unsupervised algorithm. We represent objects as point clouds, a flexible and general representation for 3D data, which we encode into a vector representation. We show that using our method to include context increases the ability of a clustering algorithm to distinguish different semantic classes from each other. Furthermore, we show that our algorithm produces continuous and meaningful object embeddings through interpolation experiments.

</p>
</details>

<details><summary><b>Enhancing Human-Machine Teaming for Medical Prognosis Through Neural Ordinary Differential Equations (NODEs)</b>
<a href="https://arxiv.org/abs/2102.04121">arxiv:2102.04121</a>
&#x1F4C8; 5 <br>
<p>D. Fompeyrine, E. S. Vorm, N. Ricka, F. Rose, G. Pellegrin</p></summary>
<p>

**Abstract:** Machine Learning (ML) has recently been demonstrated to rival expert-level human accuracy in prediction and detection tasks in a variety of domains, including medicine. Despite these impressive findings, however, a key barrier to the full realization of ML's potential in medical prognoses is technology acceptance. Recent efforts to produce explainable AI (XAI) have made progress in improving the interpretability of some ML models, but these efforts suffer from limitations intrinsic to their design: they work best at identifying why a system fails, but do poorly at explaining when and why a model's prediction is correct. We posit that the acceptability of ML predictions in expert domains is limited by two key factors: the machine's horizon of prediction that extends beyond human capability, and the inability for machine predictions to incorporate human intuition into their models. We propose the use of a novel ML architecture, Neural Ordinary Differential Equations (NODEs) to enhance human understanding and encourage acceptability. Our approach prioritizes human cognitive intuition at the center of the algorithm design, and offers a distribution of predictions rather than single outputs. We explain how this approach may significantly improve human-machine collaboration in prediction tasks in expert domains such as medical prognoses. We propose a model and demonstrate, by expanding a concrete example from the literature, how our model advances the vision of future hybrid Human-AI systems.

</p>
</details>

<details><summary><b>HumanACGAN: conditional generative adversarial network with human-based auxiliary classifier and its evaluation in phoneme perception</b>
<a href="https://arxiv.org/abs/2102.04051">arxiv:2102.04051</a>
&#x1F4C8; 5 <br>
<p>Yota Ueda, Kazuki Fujii, Yuki Saito, Shinnosuke Takamichi, Yukino Baba, Hiroshi Saruwatari</p></summary>
<p>

**Abstract:** We propose a conditional generative adversarial network (GAN) incorporating humans' perceptual evaluations. A deep neural network (DNN)-based generator of a GAN can represent a real-data distribution accurately but can never represent a human-acceptable distribution, which are ranges of data in which humans accept the naturalness regardless of whether the data are real or not. A HumanGAN was proposed to model the human-acceptable distribution. A DNN-based generator is trained using a human-based discriminator, i.e., humans' perceptual evaluations, instead of the GAN's DNN-based discriminator. However, the HumanGAN cannot represent conditional distributions. This paper proposes the HumanACGAN, a theoretical extension of the HumanGAN, to deal with conditional human-acceptable distributions. Our HumanACGAN trains a DNN-based conditional generator by regarding humans as not only a discriminator but also an auxiliary classifier. The generator is trained by deceiving the human-based discriminator that scores the unconditioned naturalness and the human-based classifier that scores the class-conditioned perceptual acceptability. The training can be executed using the backpropagation algorithm involving humans' perceptual evaluations. Our experimental results in phoneme perception demonstrate that our HumanACGAN can successfully train this conditional generator.

</p>
</details>

<details><summary><b>Hybrid quantum convolutional neural networks model for COVID-19 prediction using chest X-Ray images</b>
<a href="https://arxiv.org/abs/2102.06535">arxiv:2102.06535</a>
&#x1F4C8; 4 <br>
<p>Essam H. Houssein, Zainab Abohashima, Mohamed Elhoseny, Waleed M. Mohamed</p></summary>
<p>

**Abstract:** Despite the great efforts to find an effective way for COVID-19 prediction, the virus nature and mutation represent a critical challenge to diagnose the covered cases. However, developing a model to predict COVID-19 via Chest X-Ray (CXR) images with accurate performance is necessary to help in early diagnosis. In this paper, a hybrid quantum-classical convolutional Neural Networks (HQCNN) model used the random quantum circuits (RQCs) as a base to detect COVID-19 patients with CXR images. A collection of 6952 CXR images, including 1161 COVID-19, 1575 normal, and 5216 pneumonia images, were used as a dataset in this work. The proposed HQCNN model achieved higher performance with an accuracy of 98.4\% and a sensitivity of 99.3\% on the first dataset cases. Besides, it obtained an accuracy of 99\% and a sensitivity of 99.7\% on the second dataset cases. Also, it achieved accuracy, and sensitivity of 88.6\%, and 88.7\%, respectively, on the third multi-class dataset cases. Furthermore, the HQCNN model outperforms various models in balanced accuracy, precision, F1-measure, and AUC-ROC score. The experimental results are achieved by the proposed model prove its ability in predicting positive COVID-19 cases.

</p>
</details>

<details><summary><b>Last-iterate Convergence of Decentralized Optimistic Gradient Descent/Ascent in Infinite-horizon Competitive Markov Games</b>
<a href="https://arxiv.org/abs/2102.04540">arxiv:2102.04540</a>
&#x1F4C8; 4 <br>
<p>Chen-Yu Wei, Chung-Wei Lee, Mengxiao Zhang, Haipeng Luo</p></summary>
<p>

**Abstract:** We study infinite-horizon discounted two-player zero-sum Markov games, and develop a decentralized algorithm that provably converges to the set of Nash equilibria under self-play. Our algorithm is based on running an Optimistic Gradient Descent Ascent algorithm on each state to learn the policies, with a critic that slowly learns the value of each state. To the best of our knowledge, this is the first algorithm in this setting that is simultaneously rational (converging to the opponent's best response when it uses a stationary policy), convergent (converging to the set of Nash equilibria under self-play), agnostic (no need to know the actions played by the opponent), symmetric (players taking symmetric roles in the algorithm), and enjoying a finite-time last-iterate convergence guarantee, all of which are desirable properties of decentralized algorithms.

</p>
</details>

<details><summary><b>Efficient Certified Defenses Against Patch Attacks on Image Classifiers</b>
<a href="https://arxiv.org/abs/2102.04154">arxiv:2102.04154</a>
&#x1F4C8; 4 <br>
<p>Jan Hendrik Metzen, Maksym Yatsura</p></summary>
<p>

**Abstract:** Adversarial patches pose a realistic threat model for physical world attacks on autonomous systems via their perception component. Autonomous systems in safety-critical domains such as automated driving should thus contain a fail-safe fallback component that combines certifiable robustness against patches with efficient inference while maintaining high performance on clean inputs. We propose BagCert, a novel combination of model architecture and certification procedure that allows efficient certification. We derive a loss that enables end-to-end optimization of certified robustness against patches of different sizes and locations. On CIFAR10, BagCert certifies 10.000 examples in 43 seconds on a single GPU and obtains 86% clean and 60% certified accuracy against 5x5 patches.

</p>
</details>

<details><summary><b>IDOL: Inertial Deep Orientation-Estimation and Localization</b>
<a href="https://arxiv.org/abs/2102.04024">arxiv:2102.04024</a>
&#x1F4C8; 4 <br>
<p>Scott Sun, Dennis Melamed, Kris Kitani</p></summary>
<p>

**Abstract:** Many smartphone applications use inertial measurement units (IMUs) to sense movement, but the use of these sensors for pedestrian localization can be challenging due to their noise characteristics. Recent data-driven inertial odometry approaches have demonstrated the increasing feasibility of inertial navigation. However, they still rely upon conventional smartphone orientation estimates that they assume to be accurate, while in fact these orientation estimates can be a significant source of error. To address the problem of inaccurate orientation estimates, we present a two-stage, data-driven pipeline using a commodity smartphone that first estimates device orientations and then estimates device position. The orientation module relies on a recurrent neural network and Extended Kalman Filter to obtain orientation estimates that are used to then rotate raw IMU measurements into the appropriate reference frame. The position module then passes those measurements through another recurrent network architecture to perform localization. Our proposed method outperforms state-of-the-art methods in both orientation and position error on a large dataset we constructed that contains 20 hours of pedestrian motion across 3 buildings and 15 subjects.

</p>
</details>

<details><summary><b>Introduction to Machine Learning for the Sciences</b>
<a href="https://arxiv.org/abs/2102.04883">arxiv:2102.04883</a>
&#x1F4C8; 3 <br>
<p>Titus Neupert, Mark H Fischer, Eliska Greplova, Kenny Choo, Michael Denner</p></summary>
<p>

**Abstract:** This is an introductory machine learning course specifically developed with STEM students in mind. We discuss supervised, unsupervised, and reinforcement learning. The notes start with an exposition of machine learning methods without neural networks, such as principle component analysis, t-SNE, and linear regression. We continue with an introduction to both basic and advanced neural network structures such as conventional neural networks, (variational) autoencoders, generative adversarial networks, restricted Boltzmann machines, and recurrent neural networks. Questions of interpretability are discussed using the examples of dreaming and adversarial attacks.

</p>
</details>

<details><summary><b>Federated Deep AUC Maximization for Heterogeneous Data with a Constant Communication Complexity</b>
<a href="https://arxiv.org/abs/2102.04635">arxiv:2102.04635</a>
&#x1F4C8; 3 <br>
<p>Zhuoning Yuan, Zhishuai Guo, Yi Xu, Yiming Ying, Tianbao Yang</p></summary>
<p>

**Abstract:** Deep AUC (area under the ROC curve) Maximization (DAM) has attracted much attention recently due to its great potential for imbalanced data classification. However, the research on Federated Deep AUC Maximization (FDAM) is still limited. Compared with standard federated learning (FL) approaches that focus on decomposable minimization objectives, FDAM is more complicated due to its minimization objective is non-decomposable over individual examples. In this paper, we propose improved FDAM algorithms for heterogeneous data by solving the popular non-convex strongly-concave min-max formulation of DAM in a distributed fashion, which can also be applied to a class of non-convex strongly-concave min-max problems. A striking result of this paper is that the communication complexity of the proposed algorithm is a constant independent of the number of machines and also independent of the accuracy level, which improves an existing result by orders of magnitude. The experiments have demonstrated the effectiveness of our FDAM algorithm on benchmark datasets, and on medical chest X-ray images from different organizations. Our experiment shows that the performance of FDAM using data from multiple hospitals can improve the AUC score on testing data from a single hospital for detecting life-threatening diseases based on chest radiographs. The proposed method is implemented in our open-sourced library LibAUC (www.libauc.org) whose github address is https://github.com/Optimization-AI/ICML2021_FedDeepAUC_CODASCA.

</p>
</details>

<details><summary><b>Physics-informed neural networks with hard constraints for inverse design</b>
<a href="https://arxiv.org/abs/2102.04626">arxiv:2102.04626</a>
&#x1F4C8; 3 <br>
<p>Lu Lu, Raphael Pestourie, Wenjie Yao, Zhicheng Wang, Francesc Verdugo, Steven G. Johnson</p></summary>
<p>

**Abstract:** Inverse design arises in a variety of areas in engineering such as acoustic, mechanics, thermal/electronic transport, electromagnetism, and optics. Topology optimization is a major form of inverse design, where we optimize a designed geometry to achieve targeted properties and the geometry is parameterized by a density function. This optimization is challenging, because it has a very high dimensionality and is usually constrained by partial differential equations (PDEs) and additional inequalities. Here, we propose a new deep learning method -- physics-informed neural networks with hard constraints (hPINNs) -- for solving topology optimization. hPINN leverages the recent development of PINNs for solving PDEs, and thus does not rely on any numerical PDE solver. However, all the constraints in PINNs are soft constraints, and hence we impose hard constraints by using the penalty method and the augmented Lagrangian method. We demonstrate the effectiveness of hPINN for a holography problem in optics and a fluid problem of Stokes flow. We achieve the same objective as conventional PDE-constrained optimization methods based on adjoint methods and numerical PDE solvers, but find that the design obtained from hPINN is often simpler and smoother for problems whose solution is not unique. Moreover, the implementation of inverse design with hPINN can be easier than that of conventional methods.

</p>
</details>

<details><summary><b>Benford's law: what does it say on adversarial images?</b>
<a href="https://arxiv.org/abs/2102.04615">arxiv:2102.04615</a>
&#x1F4C8; 3 <br>
<p>João G. Zago, Fabio L. Baldissera, Eric A. Antonelo, Rodrigo T. Saad</p></summary>
<p>

**Abstract:** Convolutional neural networks (CNNs) are fragile to small perturbations in the input images. These networks are thus prone to malicious attacks that perturb the inputs to force a misclassification. Such slightly manipulated images aimed at deceiving the classifier are known as adversarial images. In this work, we investigate statistical differences between natural images and adversarial ones. More precisely, we show that employing a proper image transformation and for a class of adversarial attacks, the distribution of the leading digit of the pixels in adversarial images deviates from Benford's law. The stronger the attack, the more distant the resulting distribution is from Benford's law. Our analysis provides a detailed investigation of this new approach that can serve as a basis for alternative adversarial example detection methods that do not need to modify the original CNN classifier neither work on the raw high-dimensional pixels as features to defend against attacks.

</p>
</details>

<details><summary><b>Regularized Generative Adversarial Network</b>
<a href="https://arxiv.org/abs/2102.04593">arxiv:2102.04593</a>
&#x1F4C8; 3 <br>
<p>Gabriele Di Cerbo, Ali Hirsa, Ahmad Shayaan</p></summary>
<p>

**Abstract:** We propose a framework for generating samples from a probability distribution that differs from the probability distribution of the training set. We use an adversarial process that simultaneously trains three networks, a generator and two discriminators. We refer to this new model as regularized generative adversarial network (RegGAN). We evaluate RegGAN on a synthetic dataset composed of gray scale images and we further show that it can be used to learn some pre-specified notions in topology (basic topology properties). The work is motivated by practical problems encountered while using generative methods in the art world.

</p>
</details>

<details><summary><b>UVTomo-GAN: An adversarial learning based approach for unknown view X-ray tomographic reconstruction</b>
<a href="https://arxiv.org/abs/2102.04590">arxiv:2102.04590</a>
&#x1F4C8; 3 <br>
<p>Mona Zehni, Zhizhen Zhao</p></summary>
<p>

**Abstract:** Tomographic reconstruction recovers an unknown image given its projections from different angles. State-of-the-art methods addressing this problem assume the angles associated with the projections are known a-priori. Given this knowledge, the reconstruction process is straightforward as it can be formulated as a convex problem. Here, we tackle a more challenging setting: 1) the projection angles are unknown, 2) they are drawn from an unknown probability distribution. In this set-up our goal is to recover the image and the projection angle distribution using an unsupervised adversarial learning approach. For this purpose, we formulate the problem as a distribution matching between the real projection lines and the generated ones from the estimated image and projection distribution. This is then solved by reaching the equilibrium in a min-max game between a generator and a discriminator. Our novel contribution is to recover the unknown projection distribution and the image simultaneously using adversarial learning. To accommodate this, we use Gumbel-softmax approximation of samples from categorical distribution to approximate the generator's loss as a function of the unknown image and the projection distribution. Our approach can be generalized to different inverse problems. Our simulation results reveal the ability of our method in successfully recovering the image and the projection distribution in various settings.

</p>
</details>

<details><summary><b>A Ranking Approach to Fair Classification</b>
<a href="https://arxiv.org/abs/2102.04565">arxiv:2102.04565</a>
&#x1F4C8; 3 <br>
<p>Jakob Schoeffer, Niklas Kuehl, Isabel Valera</p></summary>
<p>

**Abstract:** Algorithmic decision systems are increasingly used in areas such as hiring, school admission, or loan approval. Typically, these systems rely on labeled data for training a classification model. However, in many scenarios, ground-truth labels are unavailable, and instead we have only access to imperfect labels as the result of (potentially biased) human-made decisions. Despite being imperfect, historical decisions often contain some useful information on the unobserved true labels. In this paper, we focus on scenarios where only imperfect labels are available and propose a new fair ranking-based decision system based on monotonic relationships between legitimate features and the outcome. Our approach is both intuitive and easy to implement, and thus particularly suitable for adoption in real-world settings. More in detail, we introduce a distance-based decision criterion, which incorporates useful information from historical decisions and accounts for unwanted correlation between protected and legitimate features. Through extensive experiments on synthetic and real-world data, we show that our method is fair in the sense that a) it assigns the desirable outcome to the most qualified individuals, and b) it removes the effect of stereotypes in decision-making, thereby outperforming traditional classification algorithms. Additionally, we are able to show theoretically that our method is consistent with a prominent concept of individual fairness which states that "similar individuals should be treated similarly."

</p>
</details>

<details><summary><b>Playing the Blame Game with Robots</b>
<a href="https://arxiv.org/abs/2102.04527">arxiv:2102.04527</a>
&#x1F4C8; 3 <br>
<p>Markus Kneer, Michael T. Stuart</p></summary>
<p>

**Abstract:** Recent research shows -- somewhat astonishingly -- that people are willing to ascribe moral blame to AI-driven systems when they cause harm [1]-[4]. In this paper, we explore the moral-psychological underpinnings of these findings. Our hypothesis was that the reason why people ascribe moral blame to AI systems is that they consider them capable of entertaining inculpating mental states (what is called mens rea in the law). To explore this hypothesis, we created a scenario in which an AI system runs a risk of poisoning people by using a novel type of fertilizer. Manipulating the computational (or quasi-cognitive) abilities of the AI system in a between-subjects design, we tested whether people's willingness to ascribe knowledge of a substantial risk of harm (i.e., recklessness) and blame to the AI system. Furthermore, we investigated whether the ascription of recklessness and blame to the AI system would influence the perceived blameworthiness of the system's user (or owner). In an experiment with 347 participants, we found (i) that people are willing to ascribe blame to AI systems in contexts of recklessness, (ii) that blame ascriptions depend strongly on the willingness to attribute recklessness and (iii) that the latter, in turn, depends on the perceived "cognitive" capacities of the system. Furthermore, our results suggest (iv) that the higher the computational sophistication of the AI system, the more blame is shifted from the human user to the AI system.

</p>
</details>

<details><summary><b>Detecting Fake News Using Machine Learning : A Systematic Literature Review</b>
<a href="https://arxiv.org/abs/2102.04458">arxiv:2102.04458</a>
&#x1F4C8; 3 <br>
<p>Alim Al Ayub Ahmed, Ayman Aljabouh, Praveen Kumar Donepudi, Myung Suh Choi</p></summary>
<p>

**Abstract:** Internet is one of the important inventions and a large number of persons are its users. These persons use this for different purposes. There are different social media platforms that are accessible to these users. Any user can make a post or spread the news through the online platforms. These platforms do not verify the users or their posts. So some of the users try to spread fake news through these platforms. These news can be propaganda against an individual, society, organization or political party. A human being is unable to detect all these fake news. So there is a need for machine learning classifiers that can detect these fake news automatically. Use of machine learning classifiers for detecting fake news is described in this systematic literature review.

</p>
</details>

<details><summary><b>Common Spatial Generative Adversarial Networks based EEG Data Augmentation for Cross-Subject Brain-Computer Interface</b>
<a href="https://arxiv.org/abs/2102.04456">arxiv:2102.04456</a>
&#x1F4C8; 3 <br>
<p>Yonghao Song, Lie Yang, Xueyu Jia, Longhan Xie</p></summary>
<p>

**Abstract:** The cross-subject application of EEG-based brain-computer interface (BCI) has always been limited by large individual difference and complex characteristics that are difficult to perceive. Therefore, it takes a long time to collect the training data of each user for calibration. Even transfer learning method pre-training with amounts of subject-independent data cannot decode different EEG signal categories without enough subject-specific data. Hence, we proposed a cross-subject EEG classification framework with a generative adversarial networks (GANs) based method named common spatial GAN (CS-GAN), which used adversarial training between a generator and a discriminator to obtain high-quality data for augmentation. A particular module in the discriminator was employed to maintain the spatial features of the EEG signals and increase the difference between different categories, with two losses for further enhancement. Through adaptive training with sufficient augmentation data, our cross-subject classification accuracy yielded a significant improvement of 15.85% than leave-one subject-out (LOO) test and 8.57% than just adapting 100 original samples on the dataset 2a of BCI competition IV. Moreover, We designed a convolutional neural networks (CNNs) based classification method as a benchmark with a similar spatial enhancement idea, which achieved remarkable results to classify motor imagery EEG data. In summary, our framework provides a promising way to deal with the cross-subject problem and promote the practical application of BCI.

</p>
</details>

<details><summary><b>Improving memory banks for unsupervised learning with large mini-batch, consistency and hard negative mining</b>
<a href="https://arxiv.org/abs/2102.04442">arxiv:2102.04442</a>
&#x1F4C8; 3 <br>
<p>Adrian Bulat, Enrique Sánchez-Lozano, Georgios Tzimiropoulos</p></summary>
<p>

**Abstract:** An important component of unsupervised learning by instance-based discrimination is a memory bank for storing a feature representation for each training sample in the dataset. In this paper, we introduce 3 improvements to the vanilla memory bank-based formulation which brings massive accuracy gains: (a) Large mini-batch: we pull multiple augmentations for each sample within the same batch and show that this leads to better models and enhanced memory bank updates. (b) Consistency: we enforce the logits obtained by different augmentations of the same sample to be close without trying to enforce discrimination with respect to negative samples as proposed by previous approaches. (c) Hard negative mining: since instance discrimination is not meaningful for samples that are too visually similar, we devise a novel nearest neighbour approach for improving the memory bank that gradually merges extremely similar data samples that were previously forced to be apart by the instance level classification loss. Overall, our approach greatly improves the vanilla memory-bank based instance discrimination and outperforms all existing methods for both seen and unseen testing categories with cosine similarity.

</p>
</details>

<details><summary><b>Learning with Density Matrices and Random Features</b>
<a href="https://arxiv.org/abs/2102.04394">arxiv:2102.04394</a>
&#x1F4C8; 3 <br>
<p>Fabio A. González, Alejandro Gallego, Santiago Toledo-Cortés, Vladimir Vargas-Calderón</p></summary>
<p>

**Abstract:** A density matrix describes the statistical state of a quantum system. It is a powerful formalism to represent both the quantum and classical uncertainty of quantum systems and to express different statistical operations such as measurement, system combination and expectations as linear algebra operations. This paper explores how density matrices can be used as a building block to build machine learning models exploiting their ability to straightforwardly combine linear algebra and probability. One of the main results of the paper is to show that density matrices coupled with random Fourier features could approximate arbitrary probability distributions over $\mathbb{R}^n$. Based on this finding the paper builds different models for density estimation, classification and regression. These models are differentiable, so it is possible to integrate them with other differentiable components, such as deep learning architectures and to learn their parameters using gradient-based optimization. In addition, the paper presents optimization-less training strategies based on estimation and model averaging. The models are evaluated in benchmark tasks and the results are reported and discussed.

</p>
</details>

<details><summary><b>Protecting Intellectual Property of Generative Adversarial Networks from Ambiguity Attack</b>
<a href="https://arxiv.org/abs/2102.04362">arxiv:2102.04362</a>
&#x1F4C8; 3 <br>
<p>Ding Sheng Ong, Chee Seng Chan, Kam Woh Ng, Lixin Fan, Qiang Yang</p></summary>
<p>

**Abstract:** Ever since Machine Learning as a Service (MLaaS) emerges as a viable business that utilizes deep learning models to generate lucrative revenue, Intellectual Property Right (IPR) has become a major concern because these deep learning models can easily be replicated, shared, and re-distributed by any unauthorized third parties. To the best of our knowledge, one of the prominent deep learning models - Generative Adversarial Networks (GANs) which has been widely used to create photorealistic image are totally unprotected despite the existence of pioneering IPR protection methodology for Convolutional Neural Networks (CNNs). This paper therefore presents a complete protection framework in both black-box and white-box settings to enforce IPR protection on GANs. Empirically, we show that the proposed method does not compromise the original GANs performance (i.e. image generation, image super-resolution, style transfer), and at the same time, it is able to withstand both removal and ambiguity attacks against embedded watermarks.

</p>
</details>

<details><summary><b>The Limits of Computation in Solving Equity Trade-Offs in Machine Learning and Justice System Risk Assessment</b>
<a href="https://arxiv.org/abs/2102.04342">arxiv:2102.04342</a>
&#x1F4C8; 3 <br>
<p>Jesse Russell</p></summary>
<p>

**Abstract:** This paper explores how different ideas of racial equity in machine learning, in justice settings in particular, can present trade-offs that are difficult to solve computationally. Machine learning is often used in justice settings to create risk assessments, which are used to determine interventions, resources, and punitive actions. Overall aspects and performance of these machine learning-based tools, such as distributions of scores, outcome rates by levels, and the frequency of false positives and true positives, can be problematic when examined by racial group. Models that produce different distributions of scores or produce a different relationship between level and outcome are problematic when those scores and levels are directly linked to the restriction of individual liberty and to the broader context of racial inequity. While computation can help highlight these aspects, data and computation are unlikely to solve them. This paper explores where values and mission might have to fill the spaces computation leaves.

</p>
</details>

<details><summary><b>Long-time simulations with high fidelity on quantum hardware</b>
<a href="https://arxiv.org/abs/2102.04313">arxiv:2102.04313</a>
&#x1F4C8; 3 <br>
<p>Joe Gibbs, Kaitlin Gili, Zoë Holmes, Benjamin Commeau, Andrew Arrasmith, Lukasz Cincio, Patrick J. Coles, Andrew Sornborger</p></summary>
<p>

**Abstract:** Moderate-size quantum computers are now publicly accessible over the cloud, opening the exciting possibility of performing dynamical simulations of quantum systems. However, while rapidly improving, these devices have short coherence times, limiting the depth of algorithms that may be successfully implemented. Here we demonstrate that, despite these limitations, it is possible to implement long-time, high fidelity simulations on current hardware. Specifically, we simulate an XY-model spin chain on the Rigetti and IBM quantum computers, maintaining a fidelity of at least 0.9 for over 600 time steps. This is a factor of 150 longer than is possible using the iterated Trotter method. Our simulations are performed using a new algorithm that we call the fixed state Variational Fast Forwarding (fsVFF) algorithm. This algorithm decreases the circuit depth and width required for a quantum simulation by finding an approximate diagonalization of a short time evolution unitary. Crucially, fsVFF only requires finding a diagonalization on the subspace spanned by the initial state, rather than on the total Hilbert space as with previous methods, substantially reducing the required resources. We further demonstrate the viability of fsVFF through large numerical implementations of the algorithm, as well as an analysis of its noise resilience and the scaling of simulation errors.

</p>
</details>

<details><summary><b>Learning Optimal Strategies for Temporal Tasks in Stochastic Games</b>
<a href="https://arxiv.org/abs/2102.04307">arxiv:2102.04307</a>
&#x1F4C8; 3 <br>
<p>Alper Kamil Bozkurt, Yu Wang, Miroslav Pajic</p></summary>
<p>

**Abstract:** Linear temporal logic (LTL) is widely used to formally specify complex tasks for autonomy. Unlike usual tasks defined by reward functions only, LTL tasks are noncumulative and require memory-dependent strategies. In this work, we introduce a method to learn optimal controller strategies that maximize the satisfaction probability of LTL specifications of the desired tasks in stochastic games, which are natural extensions of Markov Decision Processes (MDPs) to systems with adversarial inputs. Our approach constructs a product game using the deterministic automaton derived from the given LTL task and a reward machine based on the acceptance condition of the automaton; thus, allowing for the use of a model-free RL algorithm to learn an optimal controller strategy. Since the rewards and the transition probabilities of the reward machine do not depend on the number of sets defining the acceptance condition, our approach is scalable to a wide range of LTL tasks, as we demonstrate on several case studies.

</p>
</details>

<details><summary><b>Correlated Bandits for Dynamic Pricing via the ARC algorithm</b>
<a href="https://arxiv.org/abs/2102.04263">arxiv:2102.04263</a>
&#x1F4C8; 3 <br>
<p>Samuel Cohen, Tanut Treetanthiploet</p></summary>
<p>

**Abstract:** The Asymptotic Randomised Control (ARC) algorithm provides a rigorous approximation to the optimal strategy for a wide class of Bayesian bandits, while retaining reasonable computational complexity. In particular, it allows a decision maker to observe signals in addition to their rewards, to incorporate correlations between the outcomes of different choices, and to have nontrivial dynamics for their estimates. The algorithm is guaranteed to asymptotically optimise the expected discounted payoff, with error depending on the initial uncertainty of the bandit. In this paper, we consider a batched bandit problem where observations arrive from a generalised linear model; we extend the ARC algorithm to this setting. We apply this to a classic dynamic pricing problem based on a Bayesian hierarchical model and demonstrate that the ARC algorithm outperforms alternative approaches.

</p>
</details>

<details><summary><b>Model Rectification via Unknown Unknowns Extraction from Deployment Samples</b>
<a href="https://arxiv.org/abs/2102.04145">arxiv:2102.04145</a>
&#x1F4C8; 3 <br>
<p>Bruno Abrahao, Zheng Wang, Haider Ahmed, Yuchen Zhu</p></summary>
<p>

**Abstract:** Model deficiency that results from incomplete training data is a form of structural blindness that leads to costly errors, oftentimes with high confidence. During the training of classification tasks, underrepresented class-conditional distributions that a given hypothesis space can recognize results in a mismatch between the model and the target space. To mitigate the consequences of this discrepancy, we propose Random Test Sampling and Cross-Validation (RTSCV) as a general algorithmic framework that aims to perform a post-training model rectification at deployment time in a supervised way. RTSCV extracts unknown unknowns (u.u.s), i.e., examples from the class-conditional distributions that a classifier is oblivious to, and works in combination with a diverse family of modern prediction models. RTSCV augments the training set with a sample of the test set (or deployment data) and uses this redefined class layout to discover u.u.s via cross-validation, without relying on active learning or budgeted queries to an oracle. We contribute a theoretical analysis that establishes performance guarantees based on the design bases of modern classifiers. Our experimental evaluation demonstrates RTSCV's effectiveness, using 7 benchmark tabular and computer vision datasets, by reducing a performance gap as large as 41% from the respective pre-rectification models. Last we show that RTSCV consistently outperforms state-of-the-art approaches.

</p>
</details>

<details><summary><b>Statistically Profiling Biases in Natural Language Reasoning Datasets and Models</b>
<a href="https://arxiv.org/abs/2102.04632">arxiv:2102.04632</a>
&#x1F4C8; 2 <br>
<p>Shanshan Huang, Kenny Q. Zhu</p></summary>
<p>

**Abstract:** Recent work has indicated that many natural language understanding and reasoning datasets contain statistical cues that may be taken advantaged of by NLP models whose capability may thus be grossly overestimated. To discover the potential weakness in the models, some human-designed stress tests have been proposed but they are expensive to create and do not generalize to arbitrary models. We propose a light-weight and general statistical profiling framework, ICQ (I-See-Cue), which automatically identifies possible biases in any multiple-choice NLU datasets without the need to create any additional test cases, and further evaluates through blackbox testing the extent to which models may exploit these biases.

</p>
</details>

<details><summary><b>A New Framework for Variance-Reduced Hamiltonian Monte Carlo</b>
<a href="https://arxiv.org/abs/2102.04613">arxiv:2102.04613</a>
&#x1F4C8; 2 <br>
<p>Zhengmian Hu, Feihu Huang, Heng Huang</p></summary>
<p>

**Abstract:** We propose a new framework of variance-reduced Hamiltonian Monte Carlo (HMC) methods for sampling from an $L$-smooth and $m$-strongly log-concave distribution, based on a unified formulation of biased and unbiased variance reduction methods. We study the convergence properties for HMC with gradient estimators which satisfy the Mean-Squared-Error-Bias (MSEB) property. We show that the unbiased gradient estimators, including SAGA and SVRG, based HMC methods achieve highest gradient efficiency with small batch size under high precision regime, and require $\tilde{O}(N + κ^2 d^{\frac{1}{2}} \varepsilon^{-1} + N^{\frac{2}{3}} κ^{\frac{4}{3}} d^{\frac{1}{3}} \varepsilon^{-\frac{2}{3}} )$ gradient complexity to achieve $ε$-accuracy in 2-Wasserstein distance. Moreover, our HMC methods with biased gradient estimators, such as SARAH and SARGE, require $\tilde{O}(N+\sqrt{N} κ^2 d^{\frac{1}{2}} \varepsilon^{-1})$ gradient complexity, which has the same dependency on condition number $κ$ and dimension $d$ as full gradient method, but improves the dependency of sample size $N$ for a factor of $N^\frac{1}{2}$. Experimental results on both synthetic and real-world benchmark data show that our new framework significantly outperforms the full gradient and stochastic gradient HMC approaches. The earliest version of this paper was submitted to ICML 2020 with three weak accept but was not finally accepted.

</p>
</details>

<details><summary><b>Joint Intent Detection and Slot Filling with Wheel-Graph Attention Networks</b>
<a href="https://arxiv.org/abs/2102.04610">arxiv:2102.04610</a>
&#x1F4C8; 2 <br>
<p>Pengfei Wei, Bi Zeng, Wenxiong Liao</p></summary>
<p>

**Abstract:** Intent detection and slot filling are two fundamental tasks for building a spoken language understanding (SLU) system. Multiple deep learning-based joint models have demonstrated excellent results on the two tasks. In this paper, we propose a new joint model with a wheel-graph attention network (Wheel-GAT) which is able to model interrelated connections directly for intent detection and slot filling. To construct a graph structure for utterances, we create intent nodes, slot nodes, and directed edges. Intent nodes can provide utterance-level semantic information for slot filling, while slot nodes can also provide local keyword information for intent. Experiments show that our model outperforms multiple baselines on two public datasets. Besides, we also demonstrate that using Bidirectional Encoder Representation from Transformer (BERT) model further boosts the performance in the SLU task.

</p>
</details>

<details><summary><b>RMOPP: Robust Multi-Objective Post-Processing for Effective Object Detection</b>
<a href="https://arxiv.org/abs/2102.04582">arxiv:2102.04582</a>
&#x1F4C8; 2 <br>
<p>Mayuresh Savargaonkar, Abdallah Chehade, Samir Rawashdeh</p></summary>
<p>

**Abstract:** Over the last few decades, many architectures have been developed that harness the power of neural networks to detect objects in near real-time. Training such systems requires substantial time across multiple GPUs and massive labeled training datasets. Although the goal of these systems is generalizability, they are often impractical in real-life applications due to flexibility, robustness, or speed issues. This paper proposes RMOPP: A robust multi-objective post-processing algorithm to boost the performance of fast pre-trained object detectors with a negligible impact on their speed. Specifically, RMOPP is a statistically driven, post-processing algorithm that allows for simultaneous optimization of precision and recall. A unique feature of RMOPP is the Pareto frontier that identifies dominant possible post-processed detectors to optimize for both precision and recall. RMOPP explores the full potential of a pre-trained object detector and is deployable for near real-time predictions. We also provide a compelling test case on YOLOv2 using the MS-COCO dataset.

</p>
</details>

<details><summary><b>Quantum machine learning with adaptive linear optics</b>
<a href="https://arxiv.org/abs/2102.04579">arxiv:2102.04579</a>
&#x1F4C8; 2 <br>
<p>Ulysse Chabaud, Damian Markham, Adel Sohbi</p></summary>
<p>

**Abstract:** We study supervised learning algorithms in which a quantum device is used to perform a computational subroutine - either for prediction via probability estimation, or to compute a kernel via estimation of quantum states overlap. We design implementations of these quantum subroutines using Boson Sampling architectures in linear optics, supplemented by adaptive measurements. We then challenge these quantum algorithms by deriving classical simulation algorithms for the tasks of output probability estimation and overlap estimation. We obtain different classical simulability regimes for these two computational tasks in terms of the number of adaptive measurements and input photons. In both cases, our results set explicit limits to the range of parameters for which a quantum advantage can be envisaged with adaptive linear optics compared to classical machine learning algorithms: we show that the number of input photons and the number of adaptive measurements cannot be simultaneously small compared to the number of modes. Interestingly, our analysis leaves open the possibility of a near-term quantum advantage with a single adaptive measurement.

</p>
</details>

<details><summary><b>Tracking e-cigarette warning label compliance on Instagram with deep learning</b>
<a href="https://arxiv.org/abs/2102.04568">arxiv:2102.04568</a>
&#x1F4C8; 2 <br>
<p>Chris J. Kennedy, Julia Vassey, Ho-Chun Herbert Chang, Jennifer B. Unger, Emilio Ferrara</p></summary>
<p>

**Abstract:** The U.S. Food & Drug Administration (FDA) requires that e-cigarette advertisements include a prominent warning label that reminds consumers that nicotine is addictive. However, the high volume of vaping-related posts on social media makes compliance auditing expensive and time-consuming, suggesting that an automated, scalable method is needed. We sought to develop and evaluate a deep learning system designed to automatically determine if an Instagram post promotes vaping, and if so, if an FDA-compliant warning label was included or if a non-compliant warning label was visible in the image. We compiled and labeled a dataset of 4,363 Instagram images, of which 44% were vaping-related, 3% contained FDA-compliant warning labels, and 4% contained non-compliant labels. Using a 20% test set for evaluation, we tested multiple neural network variations: image processing backbone model (Inceptionv3, ResNet50, EfficientNet), data augmentation, progressive layer unfreezing, output bias initialization designed for class imbalance, and multitask learning. Our final model achieved an area under the curve (AUC) and [accuracy] of 0.97 [92%] on vaping classification, 0.99 [99%] on FDA-compliant warning labels, and 0.94 [97%] on non-compliant warning labels. We conclude that deep learning models can effectively identify vaping posts on Instagram and track compliance with FDA warning label requirements.

</p>
</details>

<details><summary><b>Synthesizing Skeletal Motion and Physiological Signals as a Function of a Virtual Human's Actions and Emotions</b>
<a href="https://arxiv.org/abs/2102.04548">arxiv:2102.04548</a>
&#x1F4C8; 2 <br>
<p>Bonny Banerjee, Masoumeh Heidari Kapourchali, Murchana Baruah, Mousumi Deb, Kenneth Sakauye, Mette Olufsen</p></summary>
<p>

**Abstract:** Round-the-clock monitoring of human behavior and emotions is required in many healthcare applications which is very expensive but can be automated using machine learning (ML) and sensor technologies. Unfortunately, the lack of infrastructure for collection and sharing of such data is a bottleneck for ML research applied to healthcare. Our goal is to circumvent this bottleneck by simulating a human body in virtual environment. This will allow generation of potentially infinite amounts of shareable data from an individual as a function of his actions, interactions and emotions in a care facility or at home, with no risk of confidentiality breach or privacy invasion. In this paper, we develop for the first time a system consisting of computational models for synchronously synthesizing skeletal motion, electrocardiogram, blood pressure, respiration, and skin conductance signals as a function of an open-ended set of actions and emotions. Our experimental evaluations, involving user studies, benchmark datasets and comparison to findings in the literature, show that our models can generate skeletal motion and physiological signals with high fidelity. The proposed framework is modular and allows the flexibility to experiment with different models. In addition to facilitating ML research for round-the-clock monitoring at a reduced cost, the proposed framework will allow reusability of code and data, and may be used as a training tool for ML practitioners and healthcare professionals.

</p>
</details>

<details><summary><b>A Hybrid Task-Oriented Dialog System with Domain and Task Adaptive Pretraining</b>
<a href="https://arxiv.org/abs/2102.04506">arxiv:2102.04506</a>
&#x1F4C8; 2 <br>
<p>Boliang Zhang, Ying Lyu, Ning Ding, Tianhao Shen, Zhaoyang Jia, Kun Han, Kevin Knight</p></summary>
<p>

**Abstract:** This paper describes our submission for the End-to-end Multi-domain Task Completion Dialog shared task at the 9th Dialog System Technology Challenge (DSTC-9). Participants in the shared task build an end-to-end task completion dialog system which is evaluated by human evaluation and a user simulator based automatic evaluation. Different from traditional pipelined approaches where modules are optimized individually and suffer from cascading failure, we propose an end-to-end dialog system that 1) uses Generative Pretraining 2 (GPT-2) as the backbone to jointly solve Natural Language Understanding, Dialog State Tracking, and Natural Language Generation tasks, 2) adopts Domain and Task Adaptive Pretraining to tailor GPT-2 to the dialog domain before finetuning, 3) utilizes heuristic pre/post-processing rules that greatly simplify the prediction tasks and improve generalizability, and 4) equips a fault tolerance module to correct errors and inappropriate responses. Our proposed method significantly outperforms baselines and ties for first place in the official evaluation. We make our source code publicly available.

</p>
</details>

<details><summary><b>Adaptive Quantization of Model Updates for Communication-Efficient Federated Learning</b>
<a href="https://arxiv.org/abs/2102.04487">arxiv:2102.04487</a>
&#x1F4C8; 2 <br>
<p>Divyansh Jhunjhunwala, Advait Gadhikar, Gauri Joshi, Yonina C. Eldar</p></summary>
<p>

**Abstract:** Communication of model updates between client nodes and the central aggregating server is a major bottleneck in federated learning, especially in bandwidth-limited settings and high-dimensional models. Gradient quantization is an effective way of reducing the number of bits required to communicate each model update, albeit at the cost of having a higher error floor due to the higher variance of the stochastic gradients. In this work, we propose an adaptive quantization strategy called AdaQuantFL that aims to achieve communication efficiency as well as a low error floor by changing the number of quantization levels during the course of training. Experiments on training deep neural networks show that our method can converge in much fewer communicated bits as compared to fixed quantization level setups, with little or no impact on training and test accuracy.

</p>
</details>

<details><summary><b>Learning-augmented count-min sketches via Bayesian nonparametrics</b>
<a href="https://arxiv.org/abs/2102.04462">arxiv:2102.04462</a>
&#x1F4C8; 2 <br>
<p>Emanuele Dolera, Stefano Favaro, Stefano Peluchetti</p></summary>
<p>

**Abstract:** The count-min sketch (CMS) is a time and memory efficient randomized data structure that provides estimates of tokens' frequencies in a data stream, i.e. point queries, based on random hashed data. Learning-augmented CMSs improve the CMS by learning models that allow to better exploit data properties. In this paper, we focus on the learning-augmented CMS of Cai, Mitzenmacher and Adams (\textit{NeurIPS} 2018), which relies on Bayesian nonparametric (BNP) modeling of a data stream via Dirichlet process (DP) priors. This is referred to as the CMS-DP, and it leads to BNP estimates of a point query as posterior means of the point query given the hashed data. While BNPs is proved to be a powerful tool for developing robust learning-augmented CMSs, ideas and methods behind the CMS-DP are tailored to point queries under DP priors, and they can not be used for other priors or more general queries. In this paper, we present an alternative, and more flexible, derivation of the CMS-DP such that: i) it allows to make use of the Pitman-Yor process (PYP) prior, which is arguably the most popular generalization of the DP prior; ii) it can be readily applied to the more general problem of estimating range queries. This leads to develop a novel learning-augmented CMS under power-law data streams, referred to as the CMS-PYP, which relies on BNP modeling of the stream via PYP priors. Applications to synthetic and real data show that the CMS-PYP outperforms the CMS and the CMS-DP in the estimation of low-frequency tokens; this known to be a critical feature in natural language processing, where it is indeed common to encounter power-law data streams.

</p>
</details>

<details><summary><b>RECAST: Enabling User Recourse and Interpretability of Toxicity Detection Models with Interactive Visualization</b>
<a href="https://arxiv.org/abs/2102.04427">arxiv:2102.04427</a>
&#x1F4C8; 2 <br>
<p>Austin P Wright, Omar Shaikh, Haekyu Park, Will Epperson, Muhammed Ahmed, Stephane Pinel, Duen Horng Chau, Diyi Yang</p></summary>
<p>

**Abstract:** With the widespread use of toxic language online, platforms are increasingly using automated systems that leverage advances in natural language processing to automatically flag and remove toxic comments. However, most automated systems -- when detecting and moderating toxic language -- do not provide feedback to their users, let alone provide an avenue of recourse for these users to make actionable changes. We present our work, RECAST, an interactive, open-sourced web tool for visualizing these models' toxic predictions, while providing alternative suggestions for flagged toxic language. Our work also provides users with a new path of recourse when using these automated moderation tools. RECAST highlights text responsible for classifying toxicity, and allows users to interactively substitute potentially toxic phrases with neutral alternatives. We examined the effect of RECAST via two large-scale user evaluations, and found that RECAST was highly effective at helping users reduce toxicity as detected through the model. Users also gained a stronger understanding of the underlying toxicity criterion used by black-box models, enabling transparency and recourse. In addition, we found that when users focus on optimizing language for these models instead of their own judgement (which is the implied incentive and goal of deploying automated models), these models cease to be effective classifiers of toxicity compared to human annotations. This opens a discussion for how toxicity detection models work and should work, and their effect on the future of online discourse.

</p>
</details>

<details><summary><b>The Optimality of Polynomial Regression for Agnostic Learning under Gaussian Marginals</b>
<a href="https://arxiv.org/abs/2102.04401">arxiv:2102.04401</a>
&#x1F4C8; 2 <br>
<p>Ilias Diakonikolas, Daniel M. Kane, Thanasis Pittas, Nikos Zarifis</p></summary>
<p>

**Abstract:** We study the problem of agnostic learning under the Gaussian distribution. We develop a method for finding hard families of examples for a wide class of problems by using LP duality. For Boolean-valued concept classes, we show that the $L^1$-regression algorithm is essentially best possible, and therefore that the computational difficulty of agnostically learning a concept class is closely related to the polynomial degree required to approximate any function from the class in $L^1$-norm. Using this characterization along with additional analytic tools, we obtain optimal SQ lower bounds for agnostically learning linear threshold functions and the first non-trivial SQ lower bounds for polynomial threshold functions and intersections of halfspaces. We also develop an analogous theory for agnostically learning real-valued functions, and as an application prove near-optimal SQ lower bounds for agnostically learning ReLUs and sigmoids.

</p>
</details>

<details><summary><b>Rapid Classification of Glaucomatous Fundus Images</b>
<a href="https://arxiv.org/abs/2102.04400">arxiv:2102.04400</a>
&#x1F4C8; 2 <br>
<p>Hardit Singh, Simarjeet Saini, Vasudevan Lakshminarayanan</p></summary>
<p>

**Abstract:** We propose a new method for training convolutional neural networks which integrates reinforcement learning along with supervised learning and use ti for transfer learning for classification of glaucoma from colored fundus images. The training method uses hill climbing techniques via two different climber types, viz "random movment" and "random detection" integrated with supervised learning model though stochastic gradient descent with momentum (SGDM) model. The model was trained and tested using the Drishti GS and RIM-ONE-r2 datasets having glaucomatous and normal fundus images. The performance metrics for prediction was tested by transfer learning on five CNN architectures, namely GoogLenet, DesnseNet-201, NASNet, VGG-19 and Inception-resnet-v2. A fivefold classification was used for evaluating the perfroamnace and high sensitivities while high maintaining high accuracies were achieved. Of the models tested, the denseNet-201 architecture performed the best in terms of sensitivity and area under the curve (AUC). This method of training allows transfer learning on small datasets and can be applied for tele-ophthalmology applications including training with local datasets.

</p>
</details>

<details><summary><b>Optimal Transport in the Face of Noisy Data</b>
<a href="https://arxiv.org/abs/2102.04363">arxiv:2102.04363</a>
&#x1F4C8; 2 <br>
<p>Bart P. G. Van Parys</p></summary>
<p>

**Abstract:** Optimal transport distances are popular and theoretically well understood in the context of data-driven prediction. A flurry of recent work has popularized these distances for data-driven decision-making as well although their merits in this context are far less well understood. This in contrast to the more classical entropic distances which are known to enjoy optimal statistical properties. This begs the question when, if ever, optimal transport distances enjoy similar statistical guarantees. Optimal transport methods are shown here to enjoy optimal statistical guarantees for decision problems faced with noisy data.

</p>
</details>

<details><summary><b>Constrained Ensemble Langevin Monte Carlo</b>
<a href="https://arxiv.org/abs/2102.04279">arxiv:2102.04279</a>
&#x1F4C8; 2 <br>
<p>Zhiyan Ding, Qin Li</p></summary>
<p>

**Abstract:** The classical Langevin Monte Carlo method looks for samples from a target distribution by descending the samples along the gradient of the target distribution. The method enjoys a fast convergence rate. However, the numerical cost is sometimes high because each iteration requires the computation of a gradient. One approach to eliminate the gradient computation is to employ the concept of ``ensemble." A large number of particles are evolved together so the neighboring particles provide gradient information to each other. In this article, we discuss two algorithms that integrate the ensemble feature into LMC and the associated properties.
  In particular, we find that if one directly surrogates the gradient using the ensemble approximation, the algorithm, termed Ensemble Langevin Monte Carlo, is unstable due to a high variance term. If the gradients are replaced by the ensemble approximations only in a constrained manner, to protect from the unstable points, the algorithm, termed Constrained Ensemble Langevin Monte Carlo, resembles the classical LMC up to an ensemble error but removes most of the gradient computation.

</p>
</details>

<details><summary><b>Overhead MNIST: A Benchmark Satellite Dataset</b>
<a href="https://arxiv.org/abs/2102.04266">arxiv:2102.04266</a>
&#x1F4C8; 2 <br>
<p>David Noever, Samantha E. Miller Noever</p></summary>
<p>

**Abstract:** The research presents an overhead view of 10 important objects and follows the general formatting requirements of the most popular machine learning task: digit recognition with MNIST. This dataset offers a public benchmark extracted from over a million human-labelled and curated examples. The work outlines the key multi-class object identification task while matching with prior work in handwriting, cancer detection, and retail datasets. A prototype deep learning approach with transfer learning and convolutional neural networks (MobileNetV2) correctly identifies the ten overhead classes with an average accuracy of 96.7%. This model exceeds the peak human performance of 93.9%. For upgrading satellite imagery and object recognition, this new dataset benefits diverse endeavors such as disaster relief, land use management, and other traditional remote sensing tasks. The work extends satellite benchmarks with new capabilities to identify efficient and compact algorithms that might work on-board small satellites, a practical task for future multi-sensor constellations. The dataset is available on Kaggle and Github.

</p>
</details>

<details><summary><b>HINT: Hierarchical Interaction Network for Trial Outcome Prediction Leveraging Web Data</b>
<a href="https://arxiv.org/abs/2102.04252">arxiv:2102.04252</a>
&#x1F4C8; 2 <br>
<p>Tianfan Fu, Kexin Huang, Cao Xiao, Lucas M. Glass, Jimeng Sun</p></summary>
<p>

**Abstract:** Clinical trials are crucial for drug development but are time consuming, expensive, and often burdensome on patients. More importantly, clinical trials face uncertain outcomes due to issues with efficacy, safety, or problems with patient recruitment. If we were better at predicting the results of clinical trials, we could avoid having to run trials that will inevitably fail more resources could be devoted to trials that are likely to succeed. In this paper, we propose Hierarchical INteraction Network (HINT) for more general, clinical trial outcome predictions for all diseases based on a comprehensive and diverse set of web data including molecule information of the drugs, target disease information, trial protocol and biomedical knowledge. HINT first encode these multi-modal data into latent embeddings, where an imputation module is designed to handle missing data. Next, these embeddings will be fed into the knowledge embedding module to generate knowledge embeddings that are pretrained using external knowledge on pharmaco-kinetic properties and trial risk from the web. Then the interaction graph module will connect all the embedding via domain knowledge to fully capture various trial components and their complex relations as well as their influences on trial outcomes. Finally, HINT learns a dynamic attentive graph neural network to predict trial outcome. Comprehensive experimental results show that HINT achieves strong predictive performance, obtaining 0.772, 0.607, 0.623, 0.703 on PR-AUC for Phase I, II, III, and indication outcome prediction, respectively. It also consistently outperforms the best baseline method by up to 12.4\% on PR-AUC.

</p>
</details>

<details><summary><b>Neurogenetic Programming Framework for Explainable Reinforcement Learning</b>
<a href="https://arxiv.org/abs/2102.04231">arxiv:2102.04231</a>
&#x1F4C8; 2 <br>
<p>Vadim Liventsev, Aki Härmä, Milan Petković</p></summary>
<p>

**Abstract:** Automatic programming, the task of generating computer programs compliant with a specification without a human developer, is usually tackled either via genetic programming methods based on mutation and recombination of programs, or via neural language models. We propose a novel method that combines both approaches using a concept of a virtual neuro-genetic programmer: using evolutionary methods as an alternative to gradient descent for neural network training}, or scrum team. We demonstrate its ability to provide performant and explainable solutions for various OpenAI Gym tasks, as well as inject expert knowledge into the otherwise data-driven search for solutions.

</p>
</details>

<details><summary><b>Counterfactual Contextual Multi-Armed Bandit: a Real-World Application to Diagnose Apple Diseases</b>
<a href="https://arxiv.org/abs/2102.04214">arxiv:2102.04214</a>
&#x1F4C8; 2 <br>
<p>Gabriele Sottocornola, Fabio Stella, Markus Zanker</p></summary>
<p>

**Abstract:** Post-harvest diseases of apple are one of the major issues in the economical sector of apple production, causing severe economical losses to producers. Thus, we developed DSSApple, a picture-based decision support system able to help users in the diagnosis of apple diseases. Specifically, this paper addresses the problem of sequentially optimizing for the best diagnosis, leveraging past interactions with the system and their contextual information (i.e. the evidence provided by the users). The problem of learning an online model while optimizing for its outcome is commonly addressed in the literature through a stochastic active learning paradigm - i.e. Contextual Multi-Armed Bandit (CMAB). This methodology interactively updates the decision model considering the success of each past interaction with respect to the context provided in each round. However, this information is very often partial and inadequate to handle such complex decision making problems. On the other hand, human decisions implicitly include unobserved factors (referred in the literature as unobserved confounders) that significantly contribute to the human's final decision. In this paper, we take advantage of the information embedded in the observed human decisions to marginalize confounding factors and improve the capability of the CMAB model to identify the correct diagnosis. Specifically, we propose a Counterfactual Contextual Multi-Armed Bandit, a model based on the causal concept of counterfactual. The proposed model is validated with offline experiments based on data collected through a large user study on the application. The results prove that our model is able to outperform both traditional CMAB algorithms and observed user decisions, in real-world tasks of predicting the correct apple disease.

</p>
</details>

<details><summary><b>MetaTune: Meta-Learning Based Cost Model for Fast and Efficient Auto-tuning Frameworks</b>
<a href="https://arxiv.org/abs/2102.04199">arxiv:2102.04199</a>
&#x1F4C8; 2 <br>
<p>Jaehun Ryu, Hyojin Sung</p></summary>
<p>

**Abstract:** Deep learning compiler frameworks are gaining ground as a more portable back-end for deep learning applications on increasingly diverse hardware. However, they face the daunting challenge of matching performance offered by hand-tuned target-specific libraries. While auto-tuning frameworks with statistical cost models can provide dynamic and efficient code optimization, they suffer from large space exploration and cost model training overheads. This paper proposes MetaTune, a meta-learning based cost model that more quickly and accurately predicts the performance of optimized codes with pre-trained model parameters. MetaTune encodes convolution kernel codes as structurally similar graphs to facilitate meta-learning, meta-trains a GNN model with a very small input data set, and then predicts optimization parameters for unseen convolution operations with varying sizes and structures during compilation. The resulting framework with MetaTune provides 8 to 13% better inference time on average for four CNN models with comparable or lower optimization time while outperforming transfer learning by 10% in cross-platform cases.

</p>
</details>

<details><summary><b>Plotting time: On the usage of CNNs for time series classification</b>
<a href="https://arxiv.org/abs/2102.04179">arxiv:2102.04179</a>
&#x1F4C8; 2 <br>
<p>Nuno M. Rodrigues, João E. Batista, Leonardo Trujillo, Bernardo Duarte, Mario Giacobini, Leonardo Vanneschi, Sara Silva</p></summary>
<p>

**Abstract:** We present a novel approach for time series classification where we represent time series data as plot images and feed them to a simple CNN, outperforming several state-of-the-art methods. We propose a simple and highly replicable way of plotting the time series, and feed these images as input to a non-optimized shallow CNN, without any normalization or residual connections. These representations are no more than default line plots using the time series data, where the only pre-processing applied is to reduce the number of white pixels in the image. We compare our method with different state-of-the-art methods specialized in time series classification on two real-world non public datasets, as well as 98 datasets of the UCR dataset collection. The results show that our approach is very promising, achieving the best results on both real-world datasets and matching / beating the best state-of-the-art methods in six UCR datasets. We argue that, if a simple naive design like ours can obtain such good results, it is worth further exploring the capabilities of using image representation of time series data, along with more powerful CNNs, for classification and other related tasks.

</p>
</details>

<details><summary><b>Switching Variational Auto-Encoders for Noise-Agnostic Audio-visual Speech Enhancement</b>
<a href="https://arxiv.org/abs/2102.04144">arxiv:2102.04144</a>
&#x1F4C8; 2 <br>
<p>Mostafa Sadeghi, Xavier Alameda-Pineda</p></summary>
<p>

**Abstract:** Recently, audio-visual speech enhancement has been tackled in the unsupervised settings based on variational auto-encoders (VAEs), where during training only clean data is used to train a generative model for speech, which at test time is combined with a noise model, e.g. nonnegative matrix factorization (NMF), whose parameters are learned without supervision. Consequently, the proposed model is agnostic to the noise type. When visual data are clean, audio-visual VAE-based architectures usually outperform the audio-only counterpart. The opposite happens when the visual data are corrupted by clutter, e.g. the speaker not facing the camera. In this paper, we propose to find the optimal combination of these two architectures through time. More precisely, we introduce the use of a latent sequential variable with Markovian dependencies to switch between different VAE architectures through time in an unsupervised manner: leading to switching variational auto-encoder (SwVAE). We propose a variational factorization to approximate the computationally intractable posterior distribution. We also derive the corresponding variational expectation-maximization algorithm to estimate the parameters of the model and enhance the speech signal. Our experiments demonstrate the promising performance of SwVAE.

</p>
</details>

<details><summary><b>Dynamic Sasvi: Strong Safe Screening for Norm-Regularized Least Squares</b>
<a href="https://arxiv.org/abs/2102.04108">arxiv:2102.04108</a>
&#x1F4C8; 2 <br>
<p>Hiroaki Yamada, Makoto Yamada</p></summary>
<p>

**Abstract:** A recently introduced technique for a sparse optimization problem called "safe screening" allows us to identify irrelevant variables in the early stage of optimization. In this paper, we first propose a flexible framework for safe screening based on the Fenchel-Rockafellar duality and then derive a strong safe screening rule for norm-regularized least squares by the framework. We call the proposed screening rule for norm-regularized least squares "dynamic Sasvi" because it can be interpreted as a generalization of Sasvi. Unlike the original Sasvi, it does not require the exact solution of a more strongly regularized problem; hence, it works safely in practice. We show that our screening rule can eliminate more features and increase the speed of the solver in comparison with other screening rules both theoretically and experimentally.

</p>
</details>

<details><summary><b>STAN: Spatio-Temporal Attention Network for Next Location Recommendation</b>
<a href="https://arxiv.org/abs/2102.04095">arxiv:2102.04095</a>
&#x1F4C8; 2 <br>
<p>Yingtao Luo, Qiang Liu, Zhaocheng Liu</p></summary>
<p>

**Abstract:** The next location recommendation is at the core of various location-based applications. Current state-of-the-art models have attempted to solve spatial sparsity with hierarchical gridding and model temporal relation with explicit time intervals, while some vital questions remain unsolved. Non-adjacent locations and non-consecutive visits provide non-trivial correlations for understanding a user's behavior but were rarely considered. To aggregate all relevant visits from user trajectory and recall the most plausible candidates from weighted representations, here we propose a Spatio-Temporal Attention Network (STAN) for location recommendation. STAN explicitly exploits relative spatiotemporal information of all the check-ins with self-attention layers along the trajectory. This improvement allows a point-to-point interaction between non-adjacent locations and non-consecutive check-ins with explicit spatiotemporal effect. STAN uses a bi-layer attention architecture that firstly aggregates spatiotemporal correlation within user trajectory and then recalls the target with consideration of personalized item frequency (PIF). By visualization, we show that STAN is in line with the above intuition. Experimental results unequivocally show that our model outperforms the existing state-of-the-art methods by 9-17%.

</p>
</details>

<details><summary><b>Enhance Information Propagation for Graph Neural Network by Heterogeneous Aggregations</b>
<a href="https://arxiv.org/abs/2102.04064">arxiv:2102.04064</a>
&#x1F4C8; 2 <br>
<p>Dawei Leng, Jinjiang Guo, Lurong Pan, Jie Li, Xinyu Wang</p></summary>
<p>

**Abstract:** Graph neural networks are emerging as continuation of deep learning success w.r.t. graph data. Tens of different graph neural network variants have been proposed, most following a neighborhood aggregation scheme, where the node features are updated via aggregating features of its neighboring nodes from layer to layer. Though related research surges, the power of GNNs are still not on-par-with their counterpart CNNs in computer vision and RNNs in natural language processing. We rethink this problem from the perspective of information propagation, and propose to enhance information propagation among GNN layers by combining heterogeneous aggregations. We argue that as richer information are propagated from shallow to deep layers, the discriminative capability of features formulated by GNN can benefit from it. As our first attempt in this direction, a new generic GNN layer formulation and upon this a new GNN variant referred as HAG-Net is proposed. We empirically validate the effectiveness of HAG-Net on a number of graph classification benchmarks, and elaborate all the design options and criterions along with.

</p>
</details>

<details><summary><b>The Autonomous Siemens Tram</b>
<a href="https://arxiv.org/abs/2102.04034">arxiv:2102.04034</a>
&#x1F4C8; 2 <br>
<p>Andrew W. Palmer, Albi Sema, Wolfram Martens, Peter Rudolph, Wolfgang Waizenegger</p></summary>
<p>

**Abstract:** This paper presents the Autonomous Siemens Tram that was publicly demonstrated in Potsdam, Germany during the InnoTrans 2018 exhibition. The system was built on a Siemens Combino tram and used a multi-modal sensor suite to localize the vehicle, and to detect and respond to traffic signals and obstacles. An overview of the hardware and the developed localization, signal handling, and obstacle handling components is presented, along with a summary of their performance.

</p>
</details>

<details><summary><b>Non-linear frequency warping using constant-Q transformation for speech emotion recognition</b>
<a href="https://arxiv.org/abs/2102.04029">arxiv:2102.04029</a>
&#x1F4C8; 2 <br>
<p>Premjeet Singh, Goutam Saha, Md Sahidullah</p></summary>
<p>

**Abstract:** In this work, we explore the constant-Q transform (CQT) for speech emotion recognition (SER). The CQT-based time-frequency analysis provides variable spectro-temporal resolution with higher frequency resolution at lower frequencies. Since lower-frequency regions of speech signal contain more emotion-related information than higher-frequency regions, the increased low-frequency resolution of CQT makes it more promising for SER than standard short-time Fourier transform (STFT). We present a comparative analysis of short-term acoustic features based on STFT and CQT for SER with deep neural network (DNN) as a back-end classifier. We optimize different parameters for both features. The CQT-based features outperform the STFT-based spectral features for SER experiments. Further experiments with cross-corpora evaluation demonstrate that the CQT-based systems provide better generalization with out-of-domain training data.

</p>
</details>

<details><summary><b>Nature-Inspired Optimization Algorithms: Research Direction and Survey</b>
<a href="https://arxiv.org/abs/2102.04013">arxiv:2102.04013</a>
&#x1F4C8; 2 <br>
<p>Sachan Rohit Kumar, Kushwaha Dharmender Singh</p></summary>
<p>

**Abstract:** Nature-inspired algorithms are commonly used for solving the various optimization problems. In past few decades, various researchers have proposed a large number of nature-inspired algorithms. Some of these algorithms have proved to be very efficient as compared to other classical optimization methods. A young researcher attempting to undertake or solve a problem using nature-inspired algorithms is bogged down by a plethora of proposals that exist today. Not every algorithm is suited for all kinds of problem. Some score over others. In this paper, an attempt has been made to summarize various leading research proposals that shall pave way for any new entrant to easily understand the journey so far. Here, we classify the nature-inspired algorithms as natural evolution based, swarm intelligence based, biological based, science based and others. In this survey, widely acknowledged nature-inspired algorithms namely- ACO, ABC, EAM, FA, FPA, GA, GSA, JAYA, PSO, SFLA, TLBO and WCA, have been studied. The purpose of this review is to present an exhaustive analysis of various nature-inspired algorithms based on its source of inspiration, basic operators, control parameters, features, variants and area of application where these algorithms have been successfully applied. It shall also assist in identifying and short listing the methodologies that are best suited for the problem.

</p>
</details>

<details><summary><b>SLUA: A Super Lightweight Unsupervised Word Alignment Model via Cross-Lingual Contrastive Learning</b>
<a href="https://arxiv.org/abs/2102.04009">arxiv:2102.04009</a>
&#x1F4C8; 2 <br>
<p>Di Wu, Liang Ding, Shuo Yang, Dacheng Tao</p></summary>
<p>

**Abstract:** Word alignment is essential for the down-streaming cross-lingual language understanding and generation tasks. Recently, the performance of the neural word alignment models has exceeded that of statistical models. However, they heavily rely on sophisticated translation models. In this study, we propose a super lightweight unsupervised word alignment (SLUA) model, in which bidirectional symmetric attention trained with a contrastive learning objective is introduced, and an agreement loss is employed to bind the attention maps, such that the alignments follow mirror-like symmetry hypothesis. Experimental results on several public benchmarks demonstrate that our model achieves competitive, if not better, performance compared to the state of the art in word alignment while significantly reducing the training and decoding time on average. Further ablation analysis and case studies show the superiority of our proposed SLUA. Notably, we recognize our model as a pioneer attempt to unify bilingual word embedding and word alignments. Encouragingly, our approach achieves 16.4x speedup against GIZA++, and 50x parameter compression} compared with the Transformer-based alignment methods. We will release our code to facilitate the community.

</p>
</details>

<details><summary><b>Discovering conservation laws from trajectories via machine learning</b>
<a href="https://arxiv.org/abs/2102.04008">arxiv:2102.04008</a>
&#x1F4C8; 2 <br>
<p>Seungwoong Ha, Hawoong Jeong</p></summary>
<p>

**Abstract:** Invariants and conservation laws convey critical information about the underlying dynamics of a system, yet it is generally infeasible to find them from large-scale data without any prior knowledge or human insight. We propose ConservNet to achieve this goal, a neural network that spontaneously discovers a conserved quantity from grouped data where the members of each group share invariants, similar to a general experimental setting where trajectories from different trials are observed. As a neural network trained with a novel and intuitive loss function called noise-variance loss, ConservNet learns the hidden invariants in each group of multi-dimensional observables in a data-driven, end-to-end manner. Our model successfully discovers underlying invariants from the simulated systems having invariants as well as a real-world double pendulum trajectory. Since the model is robust to various noises and data conditions compared to baseline, our approach is directly applicable to experimental data for discovering hidden conservation laws and further, general relationships between variables.

</p>
</details>

<details><summary><b>ParaVS: A Simple, Fast, Efficient and Flexible Graph Neural Network Framework for Structure-Based Virtual Screening</b>
<a href="https://arxiv.org/abs/2102.06086">arxiv:2102.06086</a>
&#x1F4C8; 1 <br>
<p>Junfeng Wu, Dawei Leng, Lurong Pan</p></summary>
<p>

**Abstract:** Structure-based virtual screening (SBVS) is a promising in silico technique that integrates computational methods into drug design. An extensively used method in SBVS is molecular docking. However, the docking process can hardly be computationally efficient and accurate simultaneously because classic mechanics scoring function is used to approximate, but hardly reach, the quantum mechanics precision in this method. In order to reduce the computational cost of the protein-ligand scoring process and use data driven approach to boost the scoring function accuracy, we introduce a docking-based SBVS method and, furthermore, a deep learning non-docking-based method that is able to avoid the computational cost of the docking process. Then, we try to integrate these two methods into an easy-to-use framework, ParaVS, that provides both choices for researchers. Graph neural network (GNN) is employed in ParaVS, and we explained how our in-house GNN works and how to model ligands and molecular targets. To verify our approaches, cross validation experiments are done on two datasets, an open dataset Directory of Useful Decoys: Enhanced (DUD.E) and an in-house proprietary dataset without computational generated artificial decoys (NoDecoy). On DUD.E we achieved a state-of-the-art AUC of 0.981 and a state-of-the-art enrichment factor at 2% of 36.2; on NoDecoy we achieved an AUC of 0.974. We further finish inference of an open database, Enamine REAL Database (RDB), that comprises over 1.36 billion molecules in 4050 core-hours using our ParaVS non-docking method (ParaVS-ND). The inference speed of ParaVS-ND is about 3.6e5 molecule / core-hour, while this number of a conventional docking-based method is around 20, which is about 16000 times faster. The experiments indicate that ParaVS is accurate, computationally efficient and can be generalized to different molecular.

</p>
</details>

<details><summary><b>On Computation Complexity of True Proof Number Search</b>
<a href="https://arxiv.org/abs/2102.04907">arxiv:2102.04907</a>
&#x1F4C8; 1 <br>
<p>Chao Gao</p></summary>
<p>

**Abstract:** We point out that the computation of true \emph{proof} and \emph{disproof} numbers for proof number search in arbitrary directed acyclic graphs is NP-hard, an important theoretical result for proof number search. The proof requires a reduction from SAT, which demonstrates that finding true proof/disproof number for arbitrary DAG is at least as hard as deciding if arbitrary SAT instance is satisfiable, thus NP-hard.

</p>
</details>

<details><summary><b>Graph Energy-based Model for Substructure Preserving Molecular Design</b>
<a href="https://arxiv.org/abs/2102.04600">arxiv:2102.04600</a>
&#x1F4C8; 1 <br>
<p>Ryuichiro Hataya, Hideki Nakayama, Kazuki Yoshizoe</p></summary>
<p>

**Abstract:** It is common practice for chemists to search chemical databases based on substructures of compounds for finding molecules with desired properties. The purpose of de novo molecular generation is to generate instead of search. Existing machine learning based molecular design methods have no or limited ability in generating novel molecules that preserves a target substructure. Our Graph Energy-based Model, or GEM, can fix substructures and generate the rest. The experimental results show that the GEMs trained from chemistry datasets successfully generate novel molecules while preserving the target substructures. This method would provide a new way of incorporating the domain knowledge of chemists in molecular design.

</p>
</details>

<details><summary><b>Feature Engineering for Scalable Application-Level Post-Silicon Debugging</b>
<a href="https://arxiv.org/abs/2102.04554">arxiv:2102.04554</a>
&#x1F4C8; 1 <br>
<p>Debjit Pal, Shobha Vasudevan</p></summary>
<p>

**Abstract:** We present systematic and efficient solutions for both observability enhancement and root-cause diagnosis of post-silicon System-on-Chips (SoCs) validation with diverse usage scenarios. We model specification of interacting flows in typical applications for message selection. Our method for message selection optimizes flow specification coverage and trace buffer utilization. We define the diagnosis problem as identifying buggy traces as outliers and bug-free traces as inliers/normal behaviors, for which we use unsupervised learning algorithms for outlier detection. Instead of direct application of machine learning algorithms over trace data using the signals as raw features, we use feature engineering to transform raw features into more sophisticated features using domain specific operations. The engineered features are highly relevant to the diagnosis task and are generic to be applied across any hardware designs. We present debugging and root cause analysis of subtle post-silicon bugs in industry-scale OpenSPARC T2 SoC. We achieve a trace buffer utilization of 98.96\% with a flow specification coverage of 94.3\% (average). Our diagnosis method was able to diagnose up to 66.7\% more bugs and took up to 847$\times$ less diagnosis time as compared to the manual debugging with a diagnosis precision of 0.769.

</p>
</details>

<details><summary><b>Unified Focal loss: Generalising Dice and cross entropy-based losses to handle class imbalanced medical image segmentation</b>
<a href="https://arxiv.org/abs/2102.04525">arxiv:2102.04525</a>
&#x1F4C8; 1 <br>
<p>Michael Yeung, Evis Sala, Carola-Bibiane Schönlieb, Leonardo Rundo</p></summary>
<p>

**Abstract:** Automatic segmentation methods are an important advancement in medical image analysis. Machine learning techniques, and deep neural networks in particular, are the state-of-the-art for most medical image segmentation tasks. Issues with class imbalance pose a significant challenge in medical datasets, with lesions often occupying a considerably smaller volume relative to the background. Loss functions used in the training of deep learning algorithms differ in their robustness to class imbalance, with direct consequences for model convergence. The most commonly used loss functions for segmentation are based on either the cross entropy loss, Dice loss or a combination of the two. We propose the Unified Focal loss, a new hierarchical framework that generalises Dice and cross entropy-based losses for handling class imbalance. We evaluate our proposed loss function on five publicly available, class imbalanced medical imaging datasets: CVC-ClinicDB, Digital Retinal Images for Vessel Extraction (DRIVE), Breast Ultrasound 2017 (BUS2017), Brain Tumour Segmentation 2020 (BraTS20) and Kidney Tumour Segmentation 2019 (KiTS19). We compare our loss function performance against six Dice or cross entropy-based loss functions, across 2D binary, 3D binary and 3D multiclass segmentation tasks, demonstrating that our proposed loss function is robust to class imbalance and consistently outperforms the other loss functions. Source code is available at: https://github.com/mlyg/unified-focal-loss

</p>
</details>

<details><summary><b>Community Detection: Exact Recovery in Weighted Graphs</b>
<a href="https://arxiv.org/abs/2102.04439">arxiv:2102.04439</a>
&#x1F4C8; 1 <br>
<p>Mohammad Esmaeili, Aria Nosratinia</p></summary>
<p>

**Abstract:** In community detection, the exact recovery of communities (clusters) has been mainly investigated under the general stochastic block model with edges drawn from Bernoulli distributions. This paper considers the exact recovery of communities in a complete graph in which the graph edges are drawn from either a set of Gaussian distributions with community-dependent means and variances, or a set of exponential distributions with community-dependent means. For each case, we introduce a new semi-metric that describes sufficient and necessary conditions of exact recovery. The necessary and sufficient conditions are asymptotically tight. The analysis is also extended to incomplete, fully connected weighted graphs.

</p>
</details>

<details><summary><b>Improved Brain Age Estimation with Slice-based Set Networks</b>
<a href="https://arxiv.org/abs/2102.04438">arxiv:2102.04438</a>
&#x1F4C8; 1 <br>
<p>Umang Gupta, Pradeep K. Lam, Greg Ver Steeg, Paul M. Thompson</p></summary>
<p>

**Abstract:** Deep Learning for neuroimaging data is a promising but challenging direction. The high dimensionality of 3D MRI scans makes this endeavor compute and data-intensive. Most conventional 3D neuroimaging methods use 3D-CNN-based architectures with a large number of parameters and require more time and data to train. Recently, 2D-slice-based models have received increasing attention as they have fewer parameters and may require fewer samples to achieve comparable performance. In this paper, we propose a new architecture for BrainAGE prediction. The proposed architecture works by encoding each 2D slice in an MRI with a deep 2D-CNN model. Next, it combines the information from these 2D-slice encodings using set networks or permutation invariant layers. Experiments on the BrainAGE prediction problem, using the UK Biobank dataset, showed that the model with the permutation invariant layers trains faster and provides better predictions compared to other state-of-the-art approaches.

</p>
</details>

<details><summary><b>Monte Carlo Rollout Policy for Recommendation Systems with Dynamic User Behavior</b>
<a href="https://arxiv.org/abs/2102.04321">arxiv:2102.04321</a>
&#x1F4C8; 1 <br>
<p>Rahul Meshram, Kesav Kaza</p></summary>
<p>

**Abstract:** We model online recommendation systems using the hidden Markov multi-state restless multi-armed bandit problem. To solve this we present Monte Carlo rollout policy. We illustrate numerically that Monte Carlo rollout policy performs better than myopic policy for arbitrary transition dynamics with no specific structure. But, when some structure is imposed on the transition dynamics, myopic policy performs better than Monte Carlo rollout policy.

</p>
</details>

<details><summary><b>A Systematic Comparison Study on Hyperparameter Optimisation of Graph Neural Networks for Molecular Property Prediction</b>
<a href="https://arxiv.org/abs/2102.04283">arxiv:2102.04283</a>
&#x1F4C8; 1 <br>
<p>Yingfang Yuan, Wenjun Wang, Wei Pang</p></summary>
<p>

**Abstract:** Graph neural networks (GNNs) have been proposed for a wide range of graph-related learning tasks. In particular, in recent years, an increasing number of GNN systems were applied to predict molecular properties. However, a direct impediment is to select appropriate hyperparameters to achieve satisfactory performance with lower computational cost. Meanwhile, many molecular datasets are far smaller than many other datasets in typical deep learning applications. Most hyperparameter optimization (HPO) methods have not been explored in terms of their efficiencies on such small datasets in the molecular domain. In this paper, we conducted a theoretical analysis of common and specific features for two state-of-the-art and popular algorithms for HPO: TPE and CMA-ES, and we compared them with random search (RS), which is used as a baseline. Experimental studies are carried out on several benchmarks in MoleculeNet, from different perspectives to investigate the impact of RS, TPE, and CMA-ES on HPO of GNNs for molecular property prediction. In our experiments, we concluded that RS, TPE, and CMA-ES have their individual advantages in tackling different specific molecular problems. Finally, we believe our work will motivate further research on GNN as applied to molecular machine learning problems in chemistry and materials sciences.

</p>
</details>

<details><summary><b>Learning the exchange-correlation functional from nature with fully differentiable density functional theory</b>
<a href="https://arxiv.org/abs/2102.04229">arxiv:2102.04229</a>
&#x1F4C8; 1 <br>
<p>Muhammad F. Kasim, Sam M. Vinko</p></summary>
<p>

**Abstract:** Improving the predictive capability of molecular properties in ab initio simulations is essential for advanced material discovery. Despite recent progress making use of machine learning, utilizing deep neural networks to improve quantum chemistry modelling remains severely limited by the scarcity and heterogeneity of appropriate experimental data. Here we show how training a neural network to replace the exchange-correlation functional within a fully-differentiable three-dimensional Kohn-Sham density functional theory (DFT) framework can greatly improve simulation accuracy. Using only eight experimental data points on diatomic molecules, our trained exchange-correlation networks enable improved prediction accuracy of atomization energies across a collection of 104 molecules containing new bonds and atoms that are not present in the training dataset.

</p>
</details>

<details><summary><b>Segmentasi Citra Menggunakan Metode Watershed Transform Berdasarkan Image Enhancement Dalam Mendeteksi Embrio Telur</b>
<a href="https://arxiv.org/abs/2102.04202">arxiv:2102.04202</a>
&#x1F4C8; 1 <br>
<p>Shoffan Saifullah</p></summary>
<p>

**Abstract:** Image processing can be applied in the detection of egg embryos. The egg embryos detection is processed using a segmentation process. The segmentation divides the image according to the area that is divided. This process requires improvement of the image that is processed to obtain optimal results. This study will analyze the detection of egg embryos based on image processing with image enhancement and the concept of segmentation using the watershed method. Image enhancement in preprocessing in image improvement uses a combination of Contrast Limited Adaptive Histogram Equalization (CLAHE) and Histogram Equalization (HE) methods. The grayscale egg image is corrected using the CLAHE method, and the results are reprocessed using HE. The image improvement results show that the CLAHE-HE combination method gives a clear picture of the object area of the egg image that has an embryo. The segmentation process using image conversion to black and white image and watershed segmentation can clearly show the object of a chicken egg that has an embryo. The results of segmentation can divide the area of the egg having embryos in a real and accurate way with a percentage \approx 98\%.

</p>
</details>

<details><summary><b>Directed particle swarm optimization with Gaussian-process-based function forecasting</b>
<a href="https://arxiv.org/abs/2102.04172">arxiv:2102.04172</a>
&#x1F4C8; 1 <br>
<p>Johannes Jakubik, Adrian Binding, Stefan Feuerriegel</p></summary>
<p>

**Abstract:** Particle swarm optimization (PSO) is an iterative search method that moves a set of candidate solution around a search-space towards the best known global and local solutions with randomized step lengths. PSO frequently accelerates optimization in practical applications, where gradients are not available and function evaluations expensive. Yet the traditional PSO algorithm ignores the potential knowledge that could have been gained of the objective function from the observations by individual particles. Hence, we draw upon concepts from Bayesian optimization and introduce a stochastic surrogate model of the objective function. That is, we fit a Gaussian process to past evaluations of the objective function, forecast its shape and then adapt the particle movements based on it. Our computational experiments demonstrate that baseline implementations of PSO (i.e., SPSO2011) are outperformed. Furthermore, compared to, state-of-art surrogate-assisted evolutionary algorithms, we achieve substantial performance improvements on several popular benchmark functions. Overall, we find that our algorithm attains desirable properties for exploratory and exploitative behavior.

</p>
</details>

<details><summary><b>Learning Task-Oriented Communication for Edge Inference: An Information Bottleneck Approach</b>
<a href="https://arxiv.org/abs/2102.04170">arxiv:2102.04170</a>
&#x1F4C8; 1 <br>
<p>Jiawei Shao, Yuyi Mao, Jun Zhang</p></summary>
<p>

**Abstract:** This paper investigates task-oriented communication for edge inference, where a low-end edge device transmits the extracted feature vector of a local data sample to a powerful edge server for processing. It is critical to encode the data into an informative and compact representation for low-latency inference given the limited bandwidth. We propose a learning-based communication scheme that jointly optimizes feature extraction, source coding, and channel coding in a task-oriented manner, i.e., targeting the downstream inference task rather than data reconstruction. Specifically, we leverage an information bottleneck (IB) framework to formalize a rate-distortion tradeoff between the informativeness of the encoded feature and the inference performance. As the IB optimization is computationally prohibitive for the high-dimensional data, we adopt a variational approximation, namely the variational information bottleneck (VIB), to build a tractable upper bound. To reduce the communication overhead, we leverage a sparsity-inducing distribution as the variational prior for the VIB framework to sparsify the encoded feature vector. Furthermore, considering dynamic channel conditions in practical communication systems, we propose a variable-length feature encoding scheme based on dynamic neural networks to adaptively adjust the activated dimensions of the encoded feature to different channel conditions. Extensive experiments evidence that the proposed task-oriented communication system achieves a better rate-distortion tradeoff than baseline methods and significantly reduces the feature transmission latency in dynamic channel conditions.

</p>
</details>

<details><summary><b>Bias Out-of-the-Box: An Empirical Analysis of Intersectional Occupational Biases in Popular Generative Language Models</b>
<a href="https://arxiv.org/abs/2102.04130">arxiv:2102.04130</a>
&#x1F4C8; 1 <br>
<p>Hannah Kirk, Yennie Jun, Haider Iqbal, Elias Benussi, Filippo Volpin, Frederic A. Dreyer, Aleksandar Shtedritski, Yuki M. Asano</p></summary>
<p>

**Abstract:** The capabilities of natural language models trained on large-scale data have increased immensely over the past few years. Open source libraries such as HuggingFace have made these models easily available and accessible. While prior research has identified biases in large language models, this paper considers biases contained in the most popular versions of these models when applied `out-of-the-box' for downstream tasks. We focus on generative language models as they are well-suited for extracting biases inherited from training data. Specifically, we conduct an in-depth analysis of GPT-2, which is the most downloaded text generation model on HuggingFace, with over half a million downloads per month. We assess biases related to occupational associations for different protected categories by intersecting gender with religion, sexuality, ethnicity, political affiliation, and continental name origin. Using a template-based data collection pipeline, we collect 396K sentence completions made by GPT-2 and find: (i) The machine-predicted jobs are less diverse and more stereotypical for women than for men, especially for intersections; (ii) Intersectional interactions are highly relevant for occupational associations, which we quantify by fitting 262 logistic models; (iii) For most occupations, GPT-2 reflects the skewed gender and ethnicity distribution found in US Labor Bureau data, and even pulls the societally-skewed distribution towards gender parity in cases where its predictions deviate from real labor market observations. This raises the normative question of what language models should learn - whether they should reflect or correct for existing inequalities.

</p>
</details>

<details><summary><b>The FairCeptron: A Framework for Measuring Human Perceptions of Algorithmic Fairness</b>
<a href="https://arxiv.org/abs/2102.04119">arxiv:2102.04119</a>
&#x1F4C8; 1 <br>
<p>Georg Ahnert, Ivan Smirnov, Florian Lemmerich, Claudia Wagner, Markus Strohmaier</p></summary>
<p>

**Abstract:** Measures of algorithmic fairness often do not account for human perceptions of fairness that can substantially vary between different sociodemographics and stakeholders. The FairCeptron framework is an approach for studying perceptions of fairness in algorithmic decision making such as in ranking or classification. It supports (i) studying human perceptions of fairness and (ii) comparing these human perceptions with measures of algorithmic fairness. The framework includes fairness scenario generation, fairness perception elicitation and fairness perception analysis. We demonstrate the FairCeptron framework by applying it to a hypothetical university admission context where we collect human perceptions of fairness in the presence of minorities. An implementation of the FairCeptron framework is openly available, and it can easily be adapted to study perceptions of algorithmic fairness in other application contexts. We hope our work paves the way towards elevating the role of studies of human fairness perceptions in the process of designing algorithmic decision making systems.

</p>
</details>

<details><summary><b>Rethinking the Optimization of Average Precision: Only Penalizing Negative Instances before Positive Ones is Enough</b>
<a href="https://arxiv.org/abs/2102.04640">arxiv:2102.04640</a>
&#x1F4C8; 0 <br>
<p>Zhuo Li, Weiqing Min, Jiajun Song, Yaohui Zhu, Liping Kang, Xiaoming Wei, Xiaolin Wei, Shuqiang Jiang</p></summary>
<p>

**Abstract:** Optimising the approximation of Average Precision (AP) has been widely studied for image retrieval. Limited by the definition of AP, such methods consider both negative and positive instances ranking before each positive instance. However, we claim that only penalizing negative instances before positive ones is enough, because the loss only comes from these negative instances. To this end, we propose a novel loss, namely Penalizing Negative instances before Positive ones (PNP), which can directly minimize the number of negative instances before each positive one. In addition, AP-based methods adopt a fixed and sub-optimal gradient assignment strategy. Therefore, we systematically investigate different gradient assignment solutions via constructing derivative functions of the loss, resulting in PNP-I with increasing derivative functions and PNP-D with decreasing ones. PNP-I focuses more on the hard positive instances by assigning larger gradients to them and tries to make all relevant instances closer. In contrast, PNP-D pays less attention to such instances and slowly corrects them. For most real-world data, one class usually contains several local clusters. PNP-I blindly gathers these clusters while PNP-D keeps them as they were. Therefore, PNP-D is more superior. Experiments on three standard retrieval datasets show consistent results with the above analysis. Extensive evaluations demonstrate that PNP-D achieves the state-of-the-art performance. Code is available at https://github.com/interestingzhuo/PNP_loss

</p>
</details>

<details><summary><b>A* Search Without Expansions: Learning Heuristic Functions with Deep Q-Networks</b>
<a href="https://arxiv.org/abs/2102.04518">arxiv:2102.04518</a>
&#x1F4C8; 0 <br>
<p>Forest Agostinelli, Alexander Shmakov, Stephen McAleer, Roy Fox, Pierre Baldi</p></summary>
<p>

**Abstract:** A* search is an informed search algorithm that uses a heuristic function to guide the order in which nodes are expanded. Since the computation required to expand a node and compute the heuristic values for all of its generated children grows linearly with the size of the action space, A* search can become impractical for problems with large action spaces. This computational burden becomes even more apparent when heuristic functions are learned by general, but computationally expensive, deep neural networks. To address this problem, we introduce DeepCubeAQ, a deep reinforcement learning and search algorithm that builds on the DeepCubeA algorithm and deep Q-networks. DeepCubeAQ learns a heuristic function that, with a single forward pass through a deep neural network, computes the sum of the transition cost and the heuristic value of all of the children of a node without explicitly generating any of the children, eliminating the need for node expansions. DeepCubeAQ then uses a novel variant of A* search, called AQ* search, that uses the deep Q-network to guide search. We use DeepCubeAQ to solve the Rubik's cube when formulated with a large action space that includes 1872 meta-actions and show that this 157-fold increase in the size of the action space incurs less than a 4-fold increase in computation time when performing AQ* search and that AQ* search is orders of magnitude faster than A* search.

</p>
</details>

<details><summary><b>Analysis of the Effectiveness of Face-Coverings on the Death Ratio of COVID-19 Using Machine Learning</b>
<a href="https://arxiv.org/abs/2102.04419">arxiv:2102.04419</a>
&#x1F4C8; 0 <br>
<p>Ali Lafzi, Miad Boodaghi, Siavash Zamani, Niyousha Mohammadshafie, Veeraraghava Raju Hasti</p></summary>
<p>

**Abstract:** The recent outbreak of the COVID-19 led to the death of millions of people worldwide. To stave off the spread of the virus, the authorities in the US employed different strategies, including the mask mandate order issued by the states' governors. In the current work, we defined a parameter called the average death ratio as the monthly average of the number of daily deaths to the monthly average number of daily cases. We utilized survey data to quantify people's abidance by the mask mandate order. Additionally, we implicitly addressed the extent to which people abide by the mask mandate order that may depend on some parameters like population, income, and education level. Using different machine learning classification algorithms, we investigated how the decrease or increase in death ratio for the counties in the US West Coast correlates with the input parameters. The results showed that for most counties there, the mask mandate order decreased the death ratio reflecting the effectiveness of this preventive measure on the West Coast. Additionally, the changes in the death ratio demonstrated a noticeable correlation with the socio-economic condition of each county. Moreover, the results showed a promising classification accuracy score as high as around 90%.

</p>
</details>

<details><summary><b>An Unbiased Estimator of the Full-sky CMB Angular Power Spectrum at Large Scales using Neural Networks</b>
<a href="https://arxiv.org/abs/2102.04327">arxiv:2102.04327</a>
&#x1F4C8; 0 <br>
<p>Pallav Chanda, Rajib Saha</p></summary>
<p>

**Abstract:** Accurate estimation of the Cosmic Microwave Background (CMB) angular power spectrum is enticing due to the prospect for precision cosmology it presents. Galactic foreground emissions, however, contaminate the CMB signal and need to be subtracted reliably in order to lessen systematic errors on the CMB temperature estimates. Typically bright foregrounds in a region lead to further uncertainty in temperature estimates in the area even after some foreground removal technique is performed and hence determining the underlying full-sky angular power spectrum poses a challenge. We explore the feasibility of utilizing artificial neural networks to predict the angular power spectrum of the full sky CMB temperature maps from the observed angular power spectrum of the partial sky in which CMB temperatures in some bright foreground regions are masked. We present our analysis at large angular scales with two different masks. We produce unbiased predictions of the full-sky angular power spectrum and recover the underlying theoretical power spectrum using neural networks. Our predictions are also uncorrelated to a large extent. We further show that the multipole-space covariances of the predictions of full-sky spectra made by the ANNs are much smaller than those of the estimates obtained using the pseudo-$C_\ell$ method.

</p>
</details>

<details><summary><b>An Update on a Progressively Expanded Database for Automated Lung Sound Analysis</b>
<a href="https://arxiv.org/abs/2102.04062">arxiv:2102.04062</a>
&#x1F4C8; 0 <br>
<p>Fu-Shun Hsu, Shang-Ran Huang, Chien-Wen Huang, Yuan-Ren Cheng, Chun-Chieh Chen, Jack Hsiao, Chung-Wei Chen, Feipei Lai</p></summary>
<p>

**Abstract:** Purpose: We previously established an open-access lung sound database, HF_Lung_V1, and developed deep learning models for inhalation, exhalation, continuous adventitious sound (CAS), and discontinuous adventitious sound (DAS) detection. The amount of data used for training contributes to model accuracy. Herein, we collected larger quantities of data to further improve model performance. Moreover, the issues of noisy labels and sound overlapping were explored. Methods: HF_Lung_V1 was expanded to HF_Lung_V2 with a 1.45x increase in the number of audio files. Convolutional neural network-bidirectional gated recurrent unit network models were trained separately using the HF_Lung_V1 (V1_Train) and HF_Lung_V2 (V2_Train) training sets and then tested using the HF_Lung_V1 (V1_Test) and HF_Lung_V2 (V2_Test) test sets, respectively. Segment and event detection performance was evaluated using the F1 scores. Label quality was assessed. Moreover, the overlap ratios between inhalation, exhalation, CAS, and DAS labels were computed. Results: The model trained using V2_Train exhibited improved F1 scores in inhalation, exhalation, and CAS detection on both V1_Test and V2_Test but not in DAS detection. Poor CAS detection was attributed to the quality of CAS labels. DAS detection was strongly influenced by the overlapping of DAS labels with inhalation and exhalation labels. Conclusion: Collecting greater quantities of lung sound data is vital for developing more accurate lung sound analysis models. To build real ground-truth labels, the labels must be reworked; this process is ongoing. Furthermore, a method for addressing the sound overlapping problem in DAS detection must be formulated.

</p>
</details>


[Next Page](2021/2021-02/2021-02-07.md)
