## Summary for 2021-04-30, created on 2021-12-22


<details><summary><b>Self-supervised Augmentation Consistency for Adapting Semantic Segmentation</b>
<a href="https://arxiv.org/abs/2105.00097">arxiv:2105.00097</a>
&#x1F4C8; 167 <br>
<p>Nikita Araslanov, Stefan Roth</p></summary>
<p>

**Abstract:** We propose an approach to domain adaptation for semantic segmentation that is both practical and highly accurate. In contrast to previous work, we abandon the use of computationally involved adversarial objectives, network ensembles and style transfer. Instead, we employ standard data augmentation techniques $-$ photometric noise, flipping and scaling $-$ and ensure consistency of the semantic predictions across these image transformations. We develop this principle in a lightweight self-supervised framework trained on co-evolving pseudo labels without the need for cumbersome extra training rounds. Simple in training from a practitioner's standpoint, our approach is remarkably effective. We achieve significant improvements of the state-of-the-art segmentation accuracy after adaptation, consistent both across different choices of the backbone architecture and adaptation scenarios.

</p>
</details>

<details><summary><b>Does "AI" stand for augmenting inequality in the era of covid-19 healthcare?</b>
<a href="https://arxiv.org/abs/2105.07844">arxiv:2105.07844</a>
&#x1F4C8; 66 <br>
<p>David Leslie, Anjali Mazumder, Aidan Peppin, Maria Wolters, Alexa Hagerty</p></summary>
<p>

**Abstract:** Among the most damaging characteristics of the covid-19 pandemic has been its disproportionate effect on disadvantaged communities. As the outbreak has spread globally, factors such as systemic racism, marginalisation, and structural inequality have created path dependencies that have led to poor health outcomes. These social determinants of infectious disease and vulnerability to disaster have converged to affect already disadvantaged communities with higher levels of economic instability, disease exposure, infection severity, and death. Artificial intelligence (AI) technologies are an important part of the health informatics toolkit used to fight contagious disease. AI is well known, however, to be susceptible to algorithmic biases that can entrench and augment existing inequality. Uncritically deploying AI in the fight against covid-19 thus risks amplifying the pandemic's adverse effects on vulnerable groups, exacerbating health inequity. In this paper, we claim that AI systems can introduce or reflect bias and discrimination in three ways: in patterns of health discrimination that become entrenched in datasets, in data representativeness, and in human choices made during the design, development, and deployment of these systems. We highlight how the use of AI technologies threaten to exacerbate the disparate effect of covid-19 on marginalised, under-represented, and vulnerable groups, particularly black, Asian, and other minoritised ethnic people, older populations, and those of lower socioeconomic status. We conclude that, to mitigate the compounding effects of AI on inequalities associated with covid-19, decision makers, technology developers, and health officials must account for the potential biases and inequities at all stages of the AI process.

</p>
</details>

<details><summary><b>Continuous black-box optimization with quantum annealing and random subspace coding</b>
<a href="https://arxiv.org/abs/2104.14778">arxiv:2104.14778</a>
&#x1F4C8; 28 <br>
<p>Syun Izawa, Koki Kitai, Shu Tanaka, Ryo Tamura, Koji Tsuda</p></summary>
<p>

**Abstract:** A black-box optimization algorithm such as Bayesian optimization finds extremum of an unknown function by alternating inference of the underlying function and optimization of an acquisition function. In a high-dimensional space, such algorithms perform poorly due to the difficulty of acquisition function optimization. Herein, we apply quantum annealing (QA) to overcome the difficulty in the continuous black-box optimization. As QA specializes in optimization of binary problems, a continuous vector has to be encoded to binary, and the solution of QA has to be translated back. Our method has the following three parts: 1) Random subspace coding based on axis-parallel hyperrectangles from continuous vector to binary vector. 2) A quadratic unconstrained binary optimization (QUBO) defined by acquisition function based on nonnegative-weighted linear regression model which is solved by QA. 3) A penalization scheme to ensure that the QA solution can be translated back. It is shown in benchmark tests that its performance using D-Wave Advantage$^{\rm TM}$ quantum annealer is competitive with a state-of-the-art method based on the Gaussian process in high-dimensional problems. Our method may open up a new possibility of quantum annealing and other QUBO solvers including quantum approximate optimization algorithm (QAOA) using a gated-quantum computers, and expand its range of application to continuous-valued problems.

</p>
</details>

<details><summary><b>Generative Art Using Neural Visual Grammars and Dual Encoders</b>
<a href="https://arxiv.org/abs/2105.00162">arxiv:2105.00162</a>
&#x1F4C8; 26 <br>
<p>Chrisantha Fernando, S. M. Ali Eslami, Jean-Baptiste Alayrac, Piotr Mirowski, Dylan Banarse, Simon Osindero</p></summary>
<p>

**Abstract:** Whilst there are perhaps only a few scientific methods, there seem to be almost as many artistic methods as there are artists. Artistic processes appear to inhabit the highest order of open-endedness. To begin to understand some of the processes of art making it is helpful to try to automate them even partially. In this paper, a novel algorithm for producing generative art is described which allows a user to input a text string, and which in a creative response to this string, outputs an image which interprets that string. It does so by evolving images using a hierarchical neural Lindenmeyer system, and evaluating these images along the way using an image text dual encoder trained on billions of images and their associated text from the internet. In doing so we have access to and control over an instance of an artistic process, allowing analysis of which aspects of the artistic process become the task of the algorithm, and which elements remain the responsibility of the artist.

</p>
</details>

<details><summary><b>Mitigating Political Bias in Language Models Through Reinforced Calibration</b>
<a href="https://arxiv.org/abs/2104.14795">arxiv:2104.14795</a>
&#x1F4C8; 22 <br>
<p>Ruibo Liu, Chenyan Jia, Jason Wei, Guangxuan Xu, Lili Wang, Soroush Vosoughi</p></summary>
<p>

**Abstract:** Current large-scale language models can be politically biased as a result of the data they are trained on, potentially causing serious problems when they are deployed in real-world settings. In this paper, we describe metrics for measuring political bias in GPT-2 generation and propose a reinforcement learning (RL) framework for mitigating political biases in generated text. By using rewards from word embeddings or a classifier, our RL framework guides debiased generation without having access to the training data or requiring the model to be retrained. In empirical experiments on three attributes sensitive to political bias (gender, location, and topic), our methods reduced bias according to both our metrics and human evaluation, while maintaining readability and semantic coherence.

</p>
</details>

<details><summary><b>Dynamic Graph Convolutional Recurrent Network for Traffic Prediction: Benchmark and Solution</b>
<a href="https://arxiv.org/abs/2104.14917">arxiv:2104.14917</a>
&#x1F4C8; 21 <br>
<p>Fuxian Li, Jie Feng, Huan Yan, Guangyin Jin, Depeng Jin, Yong Li</p></summary>
<p>

**Abstract:** Traffic prediction is the cornerstone of an intelligent transportation system. Accurate traffic forecasting is essential for the applications of smart cities, i.e., intelligent traffic management and urban planning. Although various methods are proposed for spatio-temporal modeling, they ignore the dynamic characteristics of correlations among locations on road networks. Meanwhile, most Recurrent Neural Network (RNN) based works are not efficient enough due to their recurrent operations. Additionally, there is a severe lack of fair comparison among different methods on the same datasets. To address the above challenges, in this paper, we propose a novel traffic prediction framework, named Dynamic Graph Convolutional Recurrent Network (DGCRN). In DGCRN, hyper-networks are designed to leverage and extract dynamic characteristics from node attributes, while the parameters of dynamic filters are generated at each time step. We filter the node embeddings and then use them to generate a dynamic graph, which is integrated with a pre-defined static graph. As far as we know, we are the first to employ a generation method to model fine topology of dynamic graph at each time step. Further, to enhance efficiency and performance, we employ a training strategy for DGCRN by restricting the iteration number of decoder during forward and backward propagation. Finally, a reproducible standardized benchmark and a brand new representative traffic dataset are opened for fair comparison and further research. Extensive experiments on three datasets demonstrate that our model outperforms 15 baselines consistently.

</p>
</details>

<details><summary><b>Active WeaSuL: Improving Weak Supervision with Active Learning</b>
<a href="https://arxiv.org/abs/2104.14847">arxiv:2104.14847</a>
&#x1F4C8; 19 <br>
<p>Samantha Biegel, Rafah El-Khatib, Luiz Otavio Vilas Boas Oliveira, Max Baak, Nanne Aben</p></summary>
<p>

**Abstract:** The availability of labelled data is one of the main limitations in machine learning. We can alleviate this using weak supervision: a framework that uses expert-defined rules $\boldsymbolλ$ to estimate probabilistic labels $p(y|\boldsymbolλ)$ for the entire data set. These rules, however, are dependent on what experts know about the problem, and hence may be inaccurate or may fail to capture important parts of the problem-space. To mitigate this, we propose Active WeaSuL: an approach that incorporates active learning into weak supervision. In Active WeaSuL, experts do not only define rules, but they also iteratively provide the true label for a small set of points where the weak supervision model is most likely to be mistaken, which are then used to better estimate the probabilistic labels. In this way, the weak labels provide a warm start, which active learning then improves upon. We make two contributions: 1) a modification of the weak supervision loss function, such that the expert-labelled data inform and improve the combination of weak labels; and 2) the maxKL divergence sampling strategy, which determines for which data points expert labelling is most beneficial. Our experiments show that when the budget for labelling data is limited (e.g. $\leq 60$ data points), Active WeaSuL outperforms weak supervision, active learning, and competing strategies, with only a handful of labelled data points. This makes Active WeaSuL ideal for situations where obtaining labelled data is difficult.

</p>
</details>

<details><summary><b>Explanation-Based Human Debugging of NLP Models: A Survey</b>
<a href="https://arxiv.org/abs/2104.15135">arxiv:2104.15135</a>
&#x1F4C8; 9 <br>
<p>Piyawat Lertvittayakumjorn, Francesca Toni</p></summary>
<p>

**Abstract:** Debugging a machine learning model is hard since the bug usually involves the training data and the learning process. This becomes even harder for an opaque deep learning model if we have no clue about how the model actually works. In this survey, we review papers that exploit explanations to enable humans to give feedback and debug NLP models. We call this problem explanation-based human debugging (EBHD). In particular, we categorize and discuss existing work along three dimensions of EBHD (the bug context, the workflow, and the experimental setting), compile findings on how EBHD components affect the feedback providers, and highlight open problems that could be future research directions.

</p>
</details>

<details><summary><b>Black-box adversarial attacks using Evolution Strategies</b>
<a href="https://arxiv.org/abs/2104.15064">arxiv:2104.15064</a>
&#x1F4C8; 9 <br>
<p>Hao Qiu, Leonardo Lucio Custode, Giovanni Iacca</p></summary>
<p>

**Abstract:** In the last decade, deep neural networks have proven to be very powerful in computer vision tasks, starting a revolution in the computer vision and machine learning fields. However, deep neural networks, usually, are not robust to perturbations of the input data. In fact, several studies showed that slightly changing the content of the images can cause a dramatic decrease in the accuracy of the attacked neural network. Several methods able to generate adversarial samples make use of gradients, which usually are not available to an attacker in real-world scenarios. As opposed to this class of attacks, another class of adversarial attacks, called black-box adversarial attacks, emerged, which does not make use of information on the gradients, being more suitable for real-world attack scenarios. In this work, we compare three well-known evolution strategies on the generation of black-box adversarial attacks for image classification tasks. While our results show that the attacked neural networks can be, in most cases, easily fooled by all the algorithms under comparison, they also show that some black-box optimization algorithms may be better in "harder" setups, both in terms of attack success rate and efficiency (i.e., number of queries).

</p>
</details>

<details><summary><b>Dynamic Slate Recommendation with Gated Recurrent Units and Thompson Sampling</b>
<a href="https://arxiv.org/abs/2104.15046">arxiv:2104.15046</a>
&#x1F4C8; 9 <br>
<p>Simen Eide, David S. Leslie, Arnoldo Frigessi</p></summary>
<p>

**Abstract:** We consider the problem of recommending relevant content to users of an internet platform in the form of lists of items, called slates. We introduce a variational Bayesian Recurrent Neural Net recommender system that acts on time series of interactions between the internet platform and the user, and which scales to real world industrial situations. The recommender system is tested both online on real users, and on an offline dataset collected from a Norwegian web-based marketplace, FINN.no, that is made public for research. This is one of the first publicly available datasets which includes all the slates that are presented to users as well as which items (if any) in the slates were clicked on. Such a data set allows us to move beyond the common assumption that implicitly assumes that users are considering all possible items at each interaction. Instead we build our likelihood using the items that are actually in the slate, and evaluate the strengths and weaknesses of both approaches theoretically and in experiments. We also introduce a hierarchical prior for the item parameters based on group memberships. Both item parameters and user preferences are learned probabilistically. Furthermore, we combine our model with bandit strategies to ensure learning, and introduce `in-slate Thompson Sampling' which makes use of the slates to maximise explorative opportunities. We show experimentally that explorative recommender strategies perform on par or above their greedy counterparts. Even without making use of exploration to learn more effectively, click rates increase simply because of improved diversity in the recommended slates.

</p>
</details>

<details><summary><b>Deep learning with self-supervision and uncertainty regularization to count fish in underwater images</b>
<a href="https://arxiv.org/abs/2104.14964">arxiv:2104.14964</a>
&#x1F4C8; 9 <br>
<p>Penny Tarling, Mauricio Cantor, Albert Clapés, Sergio Escalera</p></summary>
<p>

**Abstract:** Effective conservation actions require effective population monitoring. However, accurately counting animals in the wild to inform conservation decision-making is difficult. Monitoring populations through image sampling has made data collection cheaper, wide-reaching and less intrusive but created a need to process and analyse this data efficiently. Counting animals from such data is challenging, particularly when densely packed in noisy images. Attempting this manually is slow and expensive, while traditional computer vision methods are limited in their generalisability. Deep learning is the state-of-the-art method for many computer vision tasks, but it has yet to be properly explored to count animals. To this end, we employ deep learning, with a density-based regression approach, to count fish in low-resolution sonar images. We introduce a large dataset of sonar videos, deployed to record wild mullet schools (Mugil liza), with a subset of 500 labelled images. We utilise abundant unlabelled data in a self-supervised task to improve the supervised counting task. For the first time in this context, by introducing uncertainty quantification, we improve model training and provide an accompanying measure of prediction uncertainty for more informed biological decision-making. Finally, we demonstrate the generalisability of our proposed counting framework through testing it on a recent benchmark dataset of high-resolution annotated underwater images from varying habitats (DeepFish). From experiments on both contrasting datasets, we demonstrate our network outperforms the few other deep learning models implemented for solving this task. By providing an open-source framework along with training data, our study puts forth an efficient deep learning template for crowd counting aquatic animals thereby contributing effective methods to assess natural populations from the ever-increasing visual data.

</p>
</details>

<details><summary><b>Ethics-Based Auditing to Develop Trustworthy AI</b>
<a href="https://arxiv.org/abs/2105.00002">arxiv:2105.00002</a>
&#x1F4C8; 8 <br>
<p>Jakob Mokander, Luciano Floridi</p></summary>
<p>

**Abstract:** A series of recent developments points towards auditing as a promising mechanism to bridge the gap between principles and practice in AI ethics. Building on ongoing discussions concerning ethics-based auditing, we offer three contributions. First, we argue that ethics-based auditing can improve the quality of decision making, increase user satisfaction, unlock growth potential, enable law-making, and relieve human suffering. Second, we highlight current best practices to support the design and implementation of ethics-based auditing: To be feasible and effective, ethics-based auditing should take the form of a continuous and constructive process, approach ethical alignment from a system perspective, and be aligned with public policies and incentives for ethically desirable behaviour. Third, we identify and discuss the constraints associated with ethics-based auditing. Only by understanding and accounting for these constraints can ethics-based auditing facilitate ethical alignment of AI, while enabling society to reap the full economic and social benefits of automation.

</p>
</details>

<details><summary><b>Post-training deep neural network pruning via layer-wise calibration</b>
<a href="https://arxiv.org/abs/2104.15023">arxiv:2104.15023</a>
&#x1F4C8; 8 <br>
<p>Ivan Lazarevich, Alexander Kozlov, Nikita Malinin</p></summary>
<p>

**Abstract:** We present a post-training weight pruning method for deep neural networks that achieves accuracy levels tolerable for the production setting and that is sufficiently fast to be run on commodity hardware such as desktop CPUs or edge devices. We propose a data-free extension of the approach for computer vision models based on automatically-generated synthetic fractal images. We obtain state-of-the-art results for data-free neural network pruning, with ~1.5% top@1 accuracy drop for a ResNet50 on ImageNet at 50% sparsity rate. When using real data, we are able to get a ResNet50 model on ImageNet with 65% sparsity rate in 8-bit precision in a post-training setting with a ~1% top@1 accuracy drop. We release the code as a part of the OpenVINO(TM) Post-Training Optimization tool.

</p>
</details>

<details><summary><b>Determining Chess Game State From an Image</b>
<a href="https://arxiv.org/abs/2104.14963">arxiv:2104.14963</a>
&#x1F4C8; 8 <br>
<p>Georg Wölflein, Ognjen Arandjelović</p></summary>
<p>

**Abstract:** Identifying the configuration of chess pieces from an image of a chessboard is a problem in computer vision that has not yet been solved accurately. However, it is important for helping amateur chess players improve their games by facilitating automatic computer analysis without the overhead of manually entering the pieces. Current approaches are limited by the lack of large datasets and are not designed to adapt to unseen chess sets. This paper puts forth a new dataset synthesised from a 3D model that is an order of magnitude larger than existing ones. Trained on this dataset, a novel end-to-end chess recognition system is presented that combines traditional computer vision techniques with deep learning. It localises the chessboard using a RANSAC-based algorithm that computes a projective transformation of the board onto a regular grid. Using two convolutional neural networks, it then predicts an occupancy mask for the squares in the warped image and finally classifies the pieces. The described system achieves an error rate of 0.23% per square on the test set, 28 times better than the current state of the art. Further, a few-shot transfer learning approach is developed that is able to adapt the inference system to a previously unseen chess set using just two photos of the starting position, obtaining a per-square accuracy of 99.83% on images of that new chess set. The code, dataset, and trained models are made available online.

</p>
</details>

<details><summary><b>PSEUDo: Interactive Pattern Search in Multivariate Time Series with Locality-Sensitive Hashing and Relevance Feedback</b>
<a href="https://arxiv.org/abs/2104.14962">arxiv:2104.14962</a>
&#x1F4C8; 8 <br>
<p>Yuncong Yu, Dylan Kruyff, Tim Becker, Michael Behrisch</p></summary>
<p>

**Abstract:** We present PSEUDo, an adaptive feature learning technique for exploring visual patterns in multi-track sequential data. Our approach is designed with the primary focus to overcome the uneconomic retraining requirements and inflexible representation learning in current deep learning-based systems. Multi-track time series data are generated on an unprecedented scale due to increased sensors and data storage. These datasets hold valuable patterns, like in neuromarketing, where researchers try to link patterns in multivariate sequential data from physiological sensors to the purchase behavior of products and services. But a lack of ground truth and high variance make automatic pattern detection unreliable. Our advancements are based on a novel query-aware locality-sensitive hashing technique to create a feature-based representation of multivariate time series windows. Most importantly, our algorithm features sub-linear training and inference time. We can even accomplish both the modeling and comparison of 10,000 different 64-track time series, each with 100 time steps (a typical EEG dataset) under 0.8 seconds. This performance gain allows for a rapid relevance feedback-driven adaption of the underlying pattern similarity model and enables the user to modify the speed-vs-accuracy trade-off gradually. We demonstrate superiority of PSEUDo in terms of efficiency, accuracy, and steerability through a quantitative performance comparison and a qualitative visual quality comparison to the state-of-the-art algorithms in the field. Moreover, we showcase the usability of PSEUDo through a case study demonstrating our visual pattern retrieval concepts in a large meteorological dataset. We find that our adaptive models can accurately capture the user's notion of similarity and allow for an understandable exploratory visual pattern retrieval in large multivariate time series datasets.

</p>
</details>

<details><summary><b>Faster Meta Update Strategy for Noise-Robust Deep Learning</b>
<a href="https://arxiv.org/abs/2104.15092">arxiv:2104.15092</a>
&#x1F4C8; 7 <br>
<p>Youjiang Xu, Linchao Zhu, Lu Jiang, Yi Yang</p></summary>
<p>

**Abstract:** It has been shown that deep neural networks are prone to overfitting on biased training data. Towards addressing this issue, meta-learning employs a meta model for correcting the training bias. Despite the promising performances, super slow training is currently the bottleneck in the meta learning approaches. In this paper, we introduce a novel Faster Meta Update Strategy (FaMUS) to replace the most expensive step in the meta gradient computation with a faster layer-wise approximation. We empirically find that FaMUS yields not only a reasonably accurate but also a low-variance approximation of the meta gradient. We conduct extensive experiments to verify the proposed method on two tasks. We show our method is able to save two-thirds of the training time while still maintaining the comparable or achieving even better generalization performance. In particular, our method achieves the state-of-the-art performance on both synthetic and realistic noisy labels, and obtains promising performance on long-tailed recognition on standard benchmarks.

</p>
</details>

<details><summary><b>Ranking the information content of distance measures</b>
<a href="https://arxiv.org/abs/2104.15079">arxiv:2104.15079</a>
&#x1F4C8; 7 <br>
<p>Aldo Glielmo, Claudio Zeni, Bingqing Cheng, Gabor Csanyi, Alessandro Laio</p></summary>
<p>

**Abstract:** Real-world data typically contain a large number of features that are often heterogeneous in nature, relevance, and also units of measure. When assessing the similarity between data points, one can build various distance measures using subsets of these features. Using the fewest features but still retaining sufficient information about the system is crucial in many statistical learning approaches, particularly when data are sparse. We introduce a statistical test that can assess the relative information retained when using two different distance measures, and determine if they are equivalent, independent, or if one is more informative than the other. This in turn allows finding the most informative distance measure out of a pool of candidates. The approach is applied to find the most relevant policy variables for controlling the Covid-19 epidemic and to find compact yet informative representations of atomic structures, but its potential applications are wide ranging in many branches of science.

</p>
</details>

<details><summary><b>Black-box Gradient Attack on Graph Neural Networks: Deeper Insights in Graph-based Attack and Defense</b>
<a href="https://arxiv.org/abs/2104.15061">arxiv:2104.15061</a>
&#x1F4C8; 7 <br>
<p>Haoxi Zhan, Xiaobing Pei</p></summary>
<p>

**Abstract:** Graph Neural Networks (GNNs) have received significant attention due to their state-of-the-art performance on various graph representation learning tasks. However, recent studies reveal that GNNs are vulnerable to adversarial attacks, i.e. an attacker is able to fool the GNNs by perturbing the graph structure or node features deliberately. While being able to successfully decrease the performance of GNNs, most existing attacking algorithms require access to either the model parameters or the training data, which is not practical in the real world.
  In this paper, we develop deeper insights into the Mettack algorithm, which is a representative grey-box attacking method, and then we propose a gradient-based black-box attacking algorithm. Firstly, we show that the Mettack algorithm will perturb the edges unevenly, thus the attack will be highly dependent on a specific training set. As a result, a simple yet useful strategy to defense against Mettack is to train the GNN with the validation set. Secondly, to overcome the drawbacks, we propose the Black-Box Gradient Attack (BBGA) algorithm. Extensive experiments demonstrate that out proposed method is able to achieve stable attack performance without accessing the training sets of the GNNs. Further results shows that our proposed method is also applicable when attacking against various defense methods.

</p>
</details>

<details><summary><b>Degenerate Gaussian factors for probabilistic inference</b>
<a href="https://arxiv.org/abs/2104.15010">arxiv:2104.15010</a>
&#x1F4C8; 7 <br>
<p>J. C. Schoeman, C. E. van Daalen, J. A. du Preez</p></summary>
<p>

**Abstract:** In this paper, we propose a parametrised factor that enables inference on Gaussian networks where linear dependencies exist among the random variables. Our factor representation is a generalisation of traditional Gaussian parametrisations where the positive-definite constraint (of covariance and precision matrices) has been relaxed. For this purpose, we derive various statistical operations and results (such as marginalisation, multiplication and affine transformations of random variables) which extend the capabilities of Gaussian factors to these degenerate settings. By using this principled factor definition, degeneracies can be accommodated accurately and automatically at little additional computational cost. As illustration, we apply our methodology to a representative example involving recursive state estimation of cooperative mobile robots.

</p>
</details>

<details><summary><b>A Riemannian Newton Trust-Region Method for Fitting Gaussian Mixture Models</b>
<a href="https://arxiv.org/abs/2104.14957">arxiv:2104.14957</a>
&#x1F4C8; 7 <br>
<p>Lena Sembach, Jan Pablo Burgard, Volker H. Schulz</p></summary>
<p>

**Abstract:** Gaussian Mixture Models are a powerful tool in Data Science and Statistics that are mainly used for clustering and density approximation. The task of estimating the model parameters is in practice often solved by the Expectation Maximization (EM) algorithm which has its benefits in its simplicity and low per-iteration costs. However, the EM converges slowly if there is a large share of hidden information or overlapping clusters. Recent advances in Manifold Optimization for Gaussian Mixture Models have gained increasing interest. We introduce a formula for the Riemannian Hessian for Gaussian Mixture Models. On top, we propose a new Riemannian Newton Trust-Region method which outperforms current approaches both in terms of runtime and number of iterations.

</p>
</details>

<details><summary><b>Low-Rank Autoregressive Tensor Completion for Spatiotemporal Traffic Data Imputation</b>
<a href="https://arxiv.org/abs/2104.14936">arxiv:2104.14936</a>
&#x1F4C8; 7 <br>
<p>Xinyu Chen, Mengying Lei, Nicolas Saunier, Lijun Sun</p></summary>
<p>

**Abstract:** Spatiotemporal traffic time series (e.g., traffic volume/speed) collected from sensing systems are often incomplete with considerable corruption and large amounts of missing values, preventing users from harnessing the full power of the data. Missing data imputation has been a long-standing research topic and critical application for real-world intelligent transportation systems. A widely applied imputation method is low-rank matrix/tensor completion; however, the low-rank assumption only preserves the global structure while ignores the strong local consistency in spatiotemporal data. In this paper, we propose a low-rank autoregressive tensor completion (LATC) framework by introducing \textit{temporal variation} as a new regularization term into the completion of a third-order (sensor $\times$ time of day $\times$ day) tensor. The third-order tensor structure allows us to better capture the global consistency of traffic data, such as the inherent seasonality and day-to-day similarity. To achieve local consistency, we design the temporal variation by imposing an AR($p$) model for each time series with coefficients as learnable parameters. Different from previous spatial and temporal regularization schemes, the minimization of temporal variation can better characterize temporal generative mechanisms beyond local smoothness, allowing us to deal with more challenging scenarios such "blackout" missing. To solve the optimization problem in LATC, we introduce an alternating minimization scheme that estimates the low-rank tensor and autoregressive coefficients iteratively. We conduct extensive numerical experiments on several real-world traffic data sets, and our results demonstrate the effectiveness of LATC in diverse missing scenarios.

</p>
</details>

<details><summary><b>On In-network learning. A Comparative Study with Federated and Split Learning</b>
<a href="https://arxiv.org/abs/2104.14929">arxiv:2104.14929</a>
&#x1F4C8; 7 <br>
<p>Matei Moldoveanu, Abdellatif Zaidi</p></summary>
<p>

**Abstract:** In this paper, we consider a problem in which distributively extracted features are used for performing inference in wireless networks. We elaborate on our proposed architecture, which we herein refer to as "in-network learning", provide a suitable loss function and discuss its optimization using neural networks. We compare its performance with both Federated- and Split learning; and show that this architecture offers both better accuracy and bandwidth savings.

</p>
</details>

<details><summary><b>BERT Meets Relational DB: Contextual Representations of Relational Databases</b>
<a href="https://arxiv.org/abs/2104.14914">arxiv:2104.14914</a>
&#x1F4C8; 7 <br>
<p>Siddhant Arora, Vinayak Gupta, Garima Gaur, Srikanta Bedathur</p></summary>
<p>

**Abstract:** In this paper, we address the problem of learning low dimension representation of entities on relational databases consisting of multiple tables. Embeddings help to capture semantics encoded in the database and can be used in a variety of settings like auto-completion of tables, fully-neural query processing of relational joins queries, seamlessly handling missing values, and more. Current work is restricted to working with just single table, or using pretrained embeddings over an external corpus making them unsuitable for use in real-world databases. In this work, we look into ways of using these attention-based model to learn embeddings for entities in the relational database. We are inspired by BERT style pretraining methods and are interested in observing how they can be extended for representation learning on structured databases. We evaluate our approach of the autocompletion of relational databases and achieve improvement over standard baselines.

</p>
</details>

<details><summary><b>Learning for Detecting Norm Violation in Online Communities</b>
<a href="https://arxiv.org/abs/2104.14911">arxiv:2104.14911</a>
&#x1F4C8; 7 <br>
<p>Thiago Freitas dos Santos, Nardine Osman, Marco Schorlemmer</p></summary>
<p>

**Abstract:** In this paper, we focus on normative systems for online communities. The paper addresses the issue that arises when different community members interpret these norms in different ways, possibly leading to unexpected behavior in interactions, usually with norm violations that affect the individual and community experiences. To address this issue, we propose a framework capable of detecting norm violations and providing the violator with information about the features of their action that makes this action violate a norm. We build our framework using Machine Learning, with Logistic Model Trees as the classification algorithm. Since norm violations can be highly contextual, we train our model using data from the Wikipedia online community, namely data on Wikipedia edits. Our work is then evaluated with the Wikipedia use case where we focus on the norm that prohibits vandalism in Wikipedia edits.

</p>
</details>

<details><summary><b>Event-driven timeseries analysis and the comparison of public reactions on COVID-19</b>
<a href="https://arxiv.org/abs/2104.14777">arxiv:2104.14777</a>
&#x1F4C8; 7 <br>
<p>Md. Khayrul Bashar</p></summary>
<p>

**Abstract:** The rapid spread of COVID-19 has already affected human lives throughout the globe. Governments of different countries have taken various measures, but how they affected people lives is not clear. In this study, a rule-based and a machine-learning based models are applied to answer the above question using public tweets from Japan, USA, UK, and Australia. Two polarity timeseries (meanPol and pnRatio) and two events, namely "lockdown or emergency (LED)" and "the economic support package (ESP)", are considered in this study. Statistical testing on the sub-series around LED and ESP events showed their positive impacts to the people of (UK and Australia) and (USA and UK), respectively unlike Japanese people that showed opposite effects. Manual validation with the relevant tweets showed an agreement with the statistical results. A case study with Japanese tweets using supervised logistic regression classifies tweets into heath-worry, economy-worry and other classes with 83.11% accuracy. Predicted tweets around events re-confirm the statistical outcomes.

</p>
</details>

<details><summary><b>Memory-Efficient Deep Learning Inference in Trusted Execution Environments</b>
<a href="https://arxiv.org/abs/2104.15109">arxiv:2104.15109</a>
&#x1F4C8; 6 <br>
<p>Jean-Baptiste Truong, William Gallagher, Tian Guo, Robert J. Walls</p></summary>
<p>

**Abstract:** This study identifies and proposes techniques to alleviate two key bottlenecks to executing deep neural networks in trusted execution environments (TEEs): page thrashing during the execution of convolutional layers and the decryption of large weight matrices in fully-connected layers. For the former, we propose a novel partitioning scheme, y-plane partitioning, designed to (i) provide consistent execution time when the layer output is large compared to the TEE secure memory; and (ii) significantly reduce the memory footprint of convolutional layers. For the latter, we leverage quantization and compression. In our evaluation, the proposed optimizations incurred latency overheads ranging from 1.09X to 2X baseline for a wide range of TEE sizes; in contrast, an unmodified implementation incurred latencies of up to 26X when running inside of the TEE.

</p>
</details>

<details><summary><b>Generative Models Improve Radiomics Reproducibility in Low Dose CTs: A Simulation Study</b>
<a href="https://arxiv.org/abs/2104.15050">arxiv:2104.15050</a>
&#x1F4C8; 6 <br>
<p>Junhua Chen, Chong Zhang, Alberto Traverso, Ivan Zhovannik, Andre Dekker, Leonard Wee, Inigo Bermejo</p></summary>
<p>

**Abstract:** Radiomics is an active area of research in medical image analysis, the low reproducibility of radiomics has limited its applicability to clinical practice. This issue is especially prominent when radiomic features are calculated from noisy images, such as low dose computed tomography (CT) scans. In this article, we investigate the possibility of improving the reproducibility of radiomic features calculated on noisy CTs by using generative models for denoising.One traditional denoising method - non-local means - and two generative models - encoder-decoder networks (EDN) and conditional generative adversarial networks (CGANs) - were selected as the test models. We added noise to the sinograms of full dose CTs to mimic low dose CTs with two different levels of noise: low-noise CT and high-noise CT. Models were trained on high-noise CTs and used to denoise low-noise CTs without re-training. We also test the performance of our model in real data, using dataset of same-day repeat low dose CTs to assess the reproducibility of radiomic features in denoised images. The EDN and the CGAN improved the concordance correlation coefficients (CCC) of radiomic features for low-noise images from 0.87 to 0.92 and for high-noise images from 0.68 to 0.92 respectively. Moreover, the EDN and the CGAN improved the test-retest reliability of radiomic features (mean CCC increased from 0.89 to 0.94) based on real low dose CTs. The results show that denoising using EDN and CGANs can improve the reproducibility of radiomic features calculated on noisy CTs. Moreover, images with different noise levels can be denoised to improve the reproducibility using these models without re-training, as long as the noise intensity is equal or lower than that in high-noise CTs. To the authors' knowledge, this is the first effort to improve the reproducibility of radiomic features calculated on low dose CT scans.

</p>
</details>

<details><summary><b>ModelGuard: Runtime Validation of Lipschitz-continuous Models</b>
<a href="https://arxiv.org/abs/2104.15006">arxiv:2104.15006</a>
&#x1F4C8; 6 <br>
<p>Taylor J. Carpenter, Radoslav Ivanov, Insup Lee, James Weimer</p></summary>
<p>

**Abstract:** This paper presents ModelGuard, a sampling-based approach to runtime model validation for Lipschitz-continuous models. Although techniques exist for the validation of many classes of models the majority of these methods cannot be applied to the whole of Lipschitz-continuous models, which includes neural network models. Additionally, existing techniques generally consider only white-box models. By taking a sampling-based approach, we can address black-box models, represented only by an input-output relationship and a Lipschitz constant. We show that by randomly sampling from a parameter space and evaluating the model, it is possible to guarantee the correctness of traces labeled consistent and provide a confidence on the correctness of traces labeled inconsistent. We evaluate the applicability and scalability of ModelGuard in three case studies, including a physical platform.

</p>
</details>

<details><summary><b>Automatically Differentiable Quantum Circuit for Many-qubit State Preparation</b>
<a href="https://arxiv.org/abs/2104.14949">arxiv:2104.14949</a>
&#x1F4C8; 6 <br>
<p>Peng-Fei Zhou, Rui Hong, Shi-Ju Ran</p></summary>
<p>

**Abstract:** Constructing quantum circuits for efficient state preparation belongs to the central topics in the field of quantum information and computation. As the number of qubits grows fast, methods to derive large-scale quantum circuits are strongly desired. In this work, we propose the automatically differentiable quantum circuit (ADQC) approach to efficiently prepare arbitrary quantum many-qubit states. A key ingredient is to introduce the latent gates whose decompositions give the unitary gates that form the quantum circuit. The circuit is optimized by updating the latent gates using back propagation to minimize the distance between the evolved and target states. Taking the ground states of quantum lattice models and random matrix product states as examples, with the number of qubits where processing the full coefficients is unlikely, ADQC obtains high fidelities with small numbers of layers $N_L \sim O(1)$. Superior accuracy is reached compared with the existing state-preparation approach based on the matrix product disentangler. The parameter complexity of MPS can be significantly reduced by ADQC with the compression ratio $r \sim O(10^{-3})$. Our work sheds light on the "intelligent construction" of quantum circuits for many-qubit systems by combining with the machine learning methods.

</p>
</details>

<details><summary><b>Crackle Detection In Lung Sounds Using Transfer Learning And Multi-Input Convolitional Neural Networks</b>
<a href="https://arxiv.org/abs/2104.14921">arxiv:2104.14921</a>
&#x1F4C8; 6 <br>
<p>Truc Nguyen, Franz Pernkopf</p></summary>
<p>

**Abstract:** Large annotated lung sound databases are publicly available and might be used to train algorithms for diagnosis systems. However, it might be a challenge to develop a well-performing algorithm for small non-public data, which have only a few subjects and show differences in recording devices and setup. In this paper, we use transfer learning to tackle the mismatch of the recording setup. This allows us to transfer knowledge from one dataset to another dataset for crackle detection in lung sounds. In particular, a single input convolutional neural network (CNN) model is pre-trained on a source domain using ICBHI 2017, the largest publicly available database of lung sounds. We use log-mel spectrogram features of respiratory cycles of lung sounds. The pre-trained network is used to build a multi-input CNN model, which shares the same network architecture for respiratory cycles and their corresponding respiratory phases. The multi-input model is then fine-tuned on the target domain of our self-collected lung sound database for classifying crackles and normal lung sounds. Our experimental results show significant performance improvements of 9.84% (absolute) in F-score on the target domain using the multi-input CNN model based on transfer learning for crackle detection in adventitious lung sound classification task.

</p>
</details>

<details><summary><b>Action in Mind: A Neural Network Approach to Action Recognition and Segmentation</b>
<a href="https://arxiv.org/abs/2104.14870">arxiv:2104.14870</a>
&#x1F4C8; 6 <br>
<p>Zahra Gharaee</p></summary>
<p>

**Abstract:** Recognizing and categorizing human actions is an important task with applications in various fields such as human-robot interaction, video analysis, surveillance, video retrieval, health care system and entertainment industry. This thesis presents a novel computational approach for human action recognition through different implementations of multi-layer architectures based on artificial neural networks. Each system level development is designed to solve different aspects of the action recognition problem including online real-time processing, action segmentation and the involvement of objects. The analysis of the experimental results are illustrated and described in six articles. The proposed action recognition architecture of this thesis is composed of several processing layers including a preprocessing layer, an ordered vector representation layer and three layers of neural networks. It utilizes self-organizing neural networks such as Kohonen feature maps and growing grids as the main neural network layers. Thus the architecture presents a biological plausible approach with certain features such as topographic organization of the neurons, lateral interactions, semi-supervised learning and the ability to represent high dimensional input space in lower dimensional maps. For each level of development the system is trained with the input data consisting of consecutive 3D body postures and tested with generalized input data that the system has never met before. The experimental results of different system level developments show that the system performs well with quite high accuracy for recognizing human actions.

</p>
</details>

<details><summary><b>TREND: Truncated Generalized Normal Density Estimation of Inception Embeddings for Accurate GAN Evaluation</b>
<a href="https://arxiv.org/abs/2104.14767">arxiv:2104.14767</a>
&#x1F4C8; 6 <br>
<p>Junghyuk Lee, Jong-Seok Lee</p></summary>
<p>

**Abstract:** Evaluating image generation models such as generative adversarial networks (GANs) is a challenging problem. A common approach is to compare the distributions of the set of ground truth images and the set of generated test images. The Frechét Inception distance is one of the most widely used metrics for evaluation of GANs, which assumes that the features from a trained Inception model for a set of images follow a normal distribution. In this paper, we argue that this is an over-simplified assumption, which may lead to unreliable evaluation results, and more accurate density estimation can be achieved using a truncated generalized normal distribution. Based on this, we propose a novel metric for accurate evaluation of GANs, named TREND (TRuncated gEneralized Normal Density estimation of inception embeddings). We demonstrate that our approach significantly reduces errors of density estimation, which consequently eliminates the risk of faulty evaluation results. Furthermore, we show that the proposed metric significantly improves robustness of evaluation results against variation of the number of image samples.

</p>
</details>

<details><summary><b>Emergence in artificial life</b>
<a href="https://arxiv.org/abs/2105.03216">arxiv:2105.03216</a>
&#x1F4C8; 5 <br>
<p>Carlos Gershenson</p></summary>
<p>

**Abstract:** Concepts similar to emergence have been used since antiquity, but we lack an agreed definition of emergence. Still, emergence has been identified as one of the features of complex systems. Most would agree on the statement "life is complex". Thus, understanding emergence and complexity should benefit the study of living systems. It can be said that life emerges from the interactions of complex molecules. But how useful is this to understand living systems? Artificial life (ALife) has been developed in recent decades to study life using a synthetic approach: build it to understand it. ALife systems are not so complex, be them soft (simulations), hard (robots), or wet (protocells). Then, we can aim at first understanding emergence in ALife, for then using this knowledge in biology. I argue that to understand emergence and life, it becomes useful to use information as a framework. In a general sense, emergence can be defined as information that is not present at one scale but is present at another scale. This perspective avoids problems of studying emergence from a materialistic framework, and can be useful to study self-organization and complexity.

</p>
</details>

<details><summary><b>Submodular Mutual Information for Targeted Data Subset Selection</b>
<a href="https://arxiv.org/abs/2105.00043">arxiv:2105.00043</a>
&#x1F4C8; 5 <br>
<p>Suraj Kothawade, Vishal Kaushal, Ganesh Ramakrishnan, Jeff Bilmes, Rishabh Iyer</p></summary>
<p>

**Abstract:** With the rapid growth of data, it is becoming increasingly difficult to train or improve deep learning models with the right subset of data. We show that this problem can be effectively solved at an additional labeling cost by targeted data subset selection(TSS) where a subset of unlabeled data points similar to an auxiliary set are added to the training data. We do so by using a rich class of Submodular Mutual Information (SMI) functions and demonstrate its effectiveness for image classification on CIFAR-10 and MNIST datasets. Lastly, we compare the performance of SMI functions for TSS with other state-of-the-art methods for closely related problems like active learning. Using SMI functions, we observe ~20-30% gain over the model's performance before re-training with added targeted subset; ~12% more than other methods.

</p>
</details>

<details><summary><b>Learning Linear Temporal Properties from Noisy Data: A MaxSAT Approach</b>
<a href="https://arxiv.org/abs/2104.15083">arxiv:2104.15083</a>
&#x1F4C8; 5 <br>
<p>Jean-Raphaël Gaglione, Daniel Neider, Rajarshi Roy, Ufuk Topcu, Zhe Xu</p></summary>
<p>

**Abstract:** We address the problem of inferring descriptions of system behavior using Linear Temporal Logic (LTL) from a finite set of positive and negative examples. Most of the existing approaches for solving such a task rely on predefined templates for guiding the structure of the inferred formula. The approaches that can infer arbitrary LTL formulas, on the other hand, are not robust to noise in the data. To alleviate such limitations, we devise two algorithms for inferring concise LTL formulas even in the presence of noise. Our first algorithm infers minimal LTL formulas by reducing the inference problem to a problem in maximum satisfiability and then using off-the-shelf MaxSAT solvers to find a solution. To the best of our knowledge, we are the first to incorporate the usage of MaxSAT solvers for inferring formulas in LTL. Our second learning algorithm relies on the first algorithm to derive a decision tree over LTL formulas based on a decision tree learning algorithm. We have implemented both our algorithms and verified that our algorithms are efficient in extracting concise LTL descriptions even in the presence of noise.

</p>
</details>

<details><summary><b>Robust joint registration of multiple stains and MRI for multimodal 3D histology reconstruction: Application to the Allen human brain atlas</b>
<a href="https://arxiv.org/abs/2104.14873">arxiv:2104.14873</a>
&#x1F4C8; 5 <br>
<p>Adrià Casamitjana, Marco Lorenzi, Sebastiano Ferraris, Loc Peter, Marc Modat, Allison Stevens, Bruce Fischl, Tom Vercauteren, Juan Eugenio Iglesias</p></summary>
<p>

**Abstract:** Joint registration of a stack of 2D histological sections to recover 3D structure (``3D histology reconstruction'') finds application in areas such as atlas building and validation of \emph{in vivo} imaging. Straightforward pairwise registration of neighbouring sections yields smooth reconstructions but has well-known problems such as ``banana effect'' (straightening of curved structures) and ``z-shift'' (drift). While these problems can be alleviated with an external, linearly aligned reference (e.g., Magnetic Resonance (MR) images), registration is often inaccurate due to contrast differences and the strong nonlinear distortion of the tissue, including artefacts such as folds and tears. In this paper, we present a probabilistic model of spatial deformation that yields reconstructions for multiple histological stains that that are jointly smooth, robust to outliers, and follow the reference shape. The model relies on a spanning tree of latent transforms connecting all the sections and slices of the reference volume, and assumes that the registration between any pair of images can be see as a noisy version of the composition of (possibly inverted) latent transforms connecting the two images. Bayesian inference is used to compute the most likely latent transforms given a set of pairwise registrations between image pairs within and across modalities. The framework is used for accurate 3D reconstruction of two stains (Nissl and parvalbumin) from the Allen human brain atlas, showing its benefits on real data with severe distortions. Moreover, we also provide the registration of the reconstructed volume to MNI space, bridging the gaps between two of the most widely used atlases in histology and MRI. The 3D reconstructed volumes and atlas registration can be downloaded from https://openneuro.org/datasets/ds003590. The code is freely available at https://github.com/acasamitjana/3dhirest.

</p>
</details>

<details><summary><b>On Stochastic Moving-Average Estimators for Non-Convex Optimization</b>
<a href="https://arxiv.org/abs/2104.14840">arxiv:2104.14840</a>
&#x1F4C8; 5 <br>
<p>Zhishuai Guo, Yi Xu, Wotao Yin, Rong Jin, Tianbao Yang</p></summary>
<p>

**Abstract:** In this paper, we demonstrate the power of a widely used stochastic estimator based on moving average (SEMA) on a range of stochastic non-convex optimization problems, which only requires {\bf a general unbiased stochastic oracle}. We analyze various stochastic methods (existing or newly proposed) based on the {\bf variance recursion property} of SEMA for three families of non-convex optimization, namely standard stochastic non-convex minimization, stochastic non-convex strongly-concave min-max optimization, and stochastic bilevel optimization. Our contributions include: (i) for standard stochastic non-convex minimization, we present a simple and intuitive proof of convergence for a family Adam-style methods (including Adam) with an increasing or large "momentum" parameter for the first-order moment, which gives an alternative yet more natural way to guarantee Adam converge; (ii) for stochastic non-convex strongly-concave min-max optimization, we present a single-loop stochastic gradient descent ascent method based on the moving average estimators and establish its oracle complexity of $O(1/ε^4)$ without using a large mini-batch size, addressing a gap in the literature; (iii) for stochastic bilevel optimization, we present a single-loop stochastic method based on the moving average estimators and establish its oracle complexity of $\widetilde O(1/ε^4)$ without computing the inverse or SVD of the Hessian matrix, improving state-of-the-art results. For all these problems, we also establish a variance diminishing result for the used stochastic gradient estimators.

</p>
</details>

<details><summary><b>Interpretability of Epidemiological Models : The Curse of Non-Identifiability</b>
<a href="https://arxiv.org/abs/2104.14821">arxiv:2104.14821</a>
&#x1F4C8; 5 <br>
<p>Ayush Deva, Siddhant Shingi, Avtansh Tiwari, Nayana Bannur, Sansiddh Jain, Jerome White, Alpan Raval, Srujana Merugu</p></summary>
<p>

**Abstract:** Interpretability of epidemiological models is a key consideration, especially when these models are used in a public health setting. Interpretability is strongly linked to the identifiability of the underlying model parameters, i.e., the ability to estimate parameter values with high confidence given observations. In this paper, we define three separate notions of identifiability that explore the different roles played by the model definition, the loss function, the fitting methodology, and the quality and quantity of data. We define an epidemiological compartmental model framework in which we highlight these non-identifiability issues and their mitigation.

</p>
</details>

<details><summary><b>Deep learning neural networks for the third-order nonlinear Schrodinger equation: Solitons, breathers, and rogue waves</b>
<a href="https://arxiv.org/abs/2104.14809">arxiv:2104.14809</a>
&#x1F4C8; 5 <br>
<p>Zijian Zhou, Zhenya Yan</p></summary>
<p>

**Abstract:** The third-order nonlinear Schrodinger equation (alias the Hirota equation) is investigated via deep leaning neural networks, which describes the strongly dispersive ion-acoustic wave in plasma and the wave propagation of ultrashort light pulses in optical fibers, as well as broader-banded waves on deep water. In this paper, we use the physics-informed neural networks (PINNs) deep learning method to explore the data-driven solutions (e.g., soliton, breather, and rogue waves) of the Hirota equation when the two types of the unperturbated and unperturbated (a 2% noise) training data are considered. Moreover, we use the PINNs deep learning to study the data-driven discovery of parameters appearing in the Hirota equation with the aid of solitons.

</p>
</details>

<details><summary><b>An Adversarial Transfer Network for Knowledge Representation Learning</b>
<a href="https://arxiv.org/abs/2104.14757">arxiv:2104.14757</a>
&#x1F4C8; 5 <br>
<p>Huijuan Wang, Shuangyin Li, Rong Pan</p></summary>
<p>

**Abstract:** Knowledge representation learning has received a lot of attention in the past few years. The success of existing methods heavily relies on the quality of knowledge graphs. The entities with few triplets tend to be learned with less expressive power. Fortunately, there are many knowledge graphs constructed from various sources, the representations of which could contain much information. We propose an adversarial embedding transfer network ATransN, which transfers knowledge from one or more teacher knowledge graphs to a target one through an aligned entity set without explicit data leakage. Specifically, we add soft constraints on aligned entity pairs and neighbours to the existing knowledge representation learning methods. To handle the problem of possible distribution differences between teacher and target knowledge graphs, we introduce an adversarial adaption module. The discriminator of this module evaluates the degree of consistency between the embeddings of an aligned entity pair. The consistency score is then used as the weights of soft constraints. It is not necessary to acquire the relations and triplets in teacher knowledge graphs because we only utilize the entity representations. Knowledge graph completion results show that ATransN achieves better performance against baselines without transfer on three datasets, CN3l, WK3l, and DWY100k. The ablation study demonstrates that ATransN can bring steady and consistent improvement in different settings. The extension of combining other knowledge graph embedding algorithms and the extension with three teacher graphs display the promising generalization of the adversarial transfer network.

</p>
</details>

<details><summary><b>Seeing All From a Few: Nodes Selection Using Graph Pooling for Graph Clustering</b>
<a href="https://arxiv.org/abs/2105.05320">arxiv:2105.05320</a>
&#x1F4C8; 4 <br>
<p>Yiming Wang, Dongxia Chang, Zhiqian Fu, Yao Zhao</p></summary>
<p>

**Abstract:** Recently, there has been considerable research interest in graph clustering aimed at data partition using the graph information. However, one limitation of the most of graph-based methods is that they assume the graph structure to operate is fixed and reliable. And there are inevitably some edges in the graph that are not conducive to graph clustering, which we call spurious edges. This paper is the first attempt to employ graph pooling technique for node clustering and we propose a novel dual graph embedding network (DGEN), which is designed as a two-step graph encoder connected by a graph pooling layer to learn the graph embedding. In our model, it is assumed that if a node and its nearest neighboring node are close to the same clustering center, this node is an informative node and this edge can be considered as a cluster-friendly edge. Based on this assumption, the neighbor cluster pooling (NCPool) is devised to select the most informative subset of nodes and the corresponding edges based on the distance of nodes and their nearest neighbors to the cluster centers. This can effectively alleviate the impact of the spurious edges on the clustering. Finally, to obtain the clustering assignment of all nodes, a classifier is trained using the clustering results of the selected nodes. Experiments on five benchmark graph datasets demonstrate the superiority of the proposed method over state-of-the-art algorithms.

</p>
</details>

<details><summary><b>Stealthy Backdoors as Compression Artifacts</b>
<a href="https://arxiv.org/abs/2104.15129">arxiv:2104.15129</a>
&#x1F4C8; 4 <br>
<p>Yulong Tian, Fnu Suya, Fengyuan Xu, David Evans</p></summary>
<p>

**Abstract:** In a backdoor attack on a machine learning model, an adversary produces a model that performs well on normal inputs but outputs targeted misclassifications on inputs containing a small trigger pattern. Model compression is a widely-used approach for reducing the size of deep learning models without much accuracy loss, enabling resource-hungry models to be compressed for use on resource-constrained devices. In this paper, we study the risk that model compression could provide an opportunity for adversaries to inject stealthy backdoors. We design stealthy backdoor attacks such that the full-sized model released by adversaries appears to be free from backdoors (even when tested using state-of-the-art techniques), but when the model is compressed it exhibits highly effective backdoors. We show this can be done for two common model compression techniques -- model pruning and model quantization. Our findings demonstrate how an adversary may be able to hide a backdoor as a compression artifact, and show the importance of performing security tests on the models that will actually be deployed not their precompressed version.

</p>
</details>

<details><summary><b>Improved Matrix Gaussian Mechanism for Differential Privacy</b>
<a href="https://arxiv.org/abs/2104.14808">arxiv:2104.14808</a>
&#x1F4C8; 4 <br>
<p>Jungang Yang, Liyao Xiang, Weiting Li, Wei Liu, Xinbing Wang</p></summary>
<p>

**Abstract:** The wide deployment of machine learning in recent years gives rise to a great demand for large-scale and high-dimensional data, for which the privacy raises serious concern. Differential privacy (DP) mechanisms are conventionally developed for scalar values, not for structural data like matrices. Our work proposes Improved Matrix Gaussian Mechanism (IMGM) for matrix-valued DP, based on the necessary and sufficient condition of $ (\varepsilon,δ) $-differential privacy. IMGM only imposes constraints on the singular values of the covariance matrices of the noise, which leaves room for design. Among the legitimate noise distributions for matrix-valued DP, we find the optimal one turns out to be i.i.d. Gaussian noise, and the DP constraint becomes a noise lower bound on each element. We further derive a tight composition method for IMGM. Apart from the theoretical analysis, experiments on a variety of models and datasets also verify that IMGM yields much higher utility than the state-of-the-art mechanisms at the same privacy guarantee.

</p>
</details>

<details><summary><b>Classifying States of Cooking Objects Using Convolutional Neural Network</b>
<a href="https://arxiv.org/abs/2105.14196">arxiv:2105.14196</a>
&#x1F4C8; 3 <br>
<p>Qi Zheng</p></summary>
<p>

**Abstract:** Automated cooking machine is a goal for the future. The main aim is to make the cooking process easier, safer, and create human welfare. To allow robots to accurately perform the cooking activities, it is important for them to understand the cooking environment and recognize the objects, especially correctly identifying the state of the cooking objects. This will significantly improve the correctness of the following cooking recipes. In this project, several parts of the experiment were conducted to design a robust deep convolutional neural network for classifying the state of the cooking objects from scratch. The model is evaluated by using various techniques, such as adjusting architecture layers, tuning key hyperparameters, and using different optimization techniques to maximize the accuracy of state classification.

</p>
</details>

<details><summary><b>Capturing Logical Structure of Visually Structured Documents with Multimodal Transition Parser</b>
<a href="https://arxiv.org/abs/2105.00150">arxiv:2105.00150</a>
&#x1F4C8; 3 <br>
<p>Yuta Koreeda, Christopher D. Manning</p></summary>
<p>

**Abstract:** While many NLP pipelines assume raw, clean texts, many texts we encounter in the wild, including a vast majority of legal documents, are not so clean, with many of them being visually structured documents (VSDs) such as PDFs. Conventional preprocessing tools for VSDs mainly focused on word segmentation and coarse layout analysis, whereas fine-grained logical structure analysis (such as identifying paragraph boundaries and their hierarchies) of VSDs is underexplored. To that end, we proposed to formulate the task as prediction of "transition labels" between text fragments that maps the fragments to a tree, and developed a feature-based machine learning system that fuses visual, textual and semantic cues.Our system is easily customizable to different types of VSDs and it significantly outperformed baselines in identifying different structures in VSDs. For example, our system obtained a paragraph boundary detection F1 score of 0.953 which is significantly better than a popular PDF-to-text tool with an F1 score of 0.739.

</p>
</details>

<details><summary><b>IPatch: A Remote Adversarial Patch</b>
<a href="https://arxiv.org/abs/2105.00113">arxiv:2105.00113</a>
&#x1F4C8; 3 <br>
<p>Yisroel Mirsky</p></summary>
<p>

**Abstract:** Applications such as autonomous vehicles and medical screening use deep learning models to localize and identify hundreds of objects in a single frame. In the past, it has been shown how an attacker can fool these models by placing an adversarial patch within a scene. However, these patches must be placed in the target location and do not explicitly alter the semantics elsewhere in the image.
  In this paper, we introduce a new type of adversarial patch which alters a model's perception of an image's semantics. These patches can be placed anywhere within an image to change the classification or semantics of locations far from the patch. We call this new class of adversarial examples `remote adversarial patches' (RAP).
  We implement our own RAP called IPatch and perform an in-depth analysis on image segmentation RAP attacks using five state-of-the-art architectures with eight different encoders on the CamVid street view dataset. Moreover, we demonstrate that the attack can be extended to object recognition models with preliminary results on the popular YOLOv3 model. We found that the patch can change the classification of a remote target region with a success rate of up to 93% on average.

</p>
</details>

<details><summary><b>Updatable Siamese Tracker with Two-stage One-shot Learning</b>
<a href="https://arxiv.org/abs/2104.15049">arxiv:2104.15049</a>
&#x1F4C8; 3 <br>
<p>Xinglong Sun, Guangliang Han, Lihong Guo, Tingfa Xu, Jianan Li, Peixun Liu</p></summary>
<p>

**Abstract:** Offline Siamese networks have achieved very promising tracking performance, especially in accuracy and efficiency. However, they often fail to track an object in complex scenes due to the incapacity in online update. Traditional updaters are difficult to process the irregular variations and sampling noises of objects, so it is quite risky to adopt them to update Siamese networks. In this paper, we first present a two-stage one-shot learner, which can predict the local parameters of primary classifier with object samples from diverse stages. Then, an updatable Siamese network is proposed based on the learner (SiamTOL), which is able to complement online update by itself. Concretely, we introduce an extra inputting branch to sequentially capture the latest object features, and design a residual module to update the initial exemplar using these features. Besides, an effective multi-aspect training loss is designed for our network to avoid overfit. Extensive experimental results on several popular benchmarks including OTB100, VOT2018, VOT2019, LaSOT, UAV123 and GOT10k manifest that the proposed tracker achieves the leading performance and outperforms other state-of-the-art methods

</p>
</details>

<details><summary><b>GM-MLIC: Graph Matching based Multi-Label Image Classification</b>
<a href="https://arxiv.org/abs/2104.14762">arxiv:2104.14762</a>
&#x1F4C8; 3 <br>
<p>Yanan Wu, He Liu, Songhe Feng, Yi Jin, Gengyu Lyu, Zizhang Wu</p></summary>
<p>

**Abstract:** Multi-Label Image Classification (MLIC) aims to predict a set of labels that present in an image. The key to deal with such problem is to mine the associations between image contents and labels, and further obtain the correct assignments between images and their labels. In this paper, we treat each image as a bag of instances, and reformulate the task of MLIC as an instance-label matching selection problem. To model such problem, we propose a novel deep learning framework named Graph Matching based Multi-Label Image Classification (GM-MLIC), where Graph Matching (GM) scheme is introduced owing to its excellent capability of excavating the instance and label relationship. Specifically, we first construct an instance spatial graph and a label semantic graph respectively, and then incorporate them into a constructed assignment graph by connecting each instance to all labels. Subsequently, the graph network block is adopted to aggregate and update all nodes and edges state on the assignment graph to form structured representations for each instance and label. Our network finally derives a prediction score for each instance-label correspondence and optimizes such correspondence with a weighted cross-entropy loss. Extensive experiments conducted on various image datasets demonstrate the superiority of our proposed method.

</p>
</details>

<details><summary><b>Performance evaluation results of evolutionary clustering algorithm star for clustering heterogeneous datasets</b>
<a href="https://arxiv.org/abs/2105.02810">arxiv:2105.02810</a>
&#x1F4C8; 2 <br>
<p>Bryar A. Hassan, TarikA. Rashid, Seyedali Mirjalili</p></summary>
<p>

**Abstract:** This article presents the data used to evaluate the performance of evolutionary clustering algorithm star (ECA*) compared to five traditional and modern clustering algorithms. Two experimental methods are employed to examine the performance of ECA* against genetic algorithm for clustering++ (GENCLUST++), learning vector quantisation (LVQ) , expectation maximisation (EM) , K-means++ (KM++) and K-means (KM). These algorithms are applied to 32 heterogenous and multi-featured datasets to determine which one performs well on the three tests. For one, ther paper examines the efficiency of ECA* in contradiction of its corresponding algorithms using clustering evaluation measures. These validation criteria are objective function and cluster quality measures. For another, it suggests a performance rating framework to measurethe the performance sensitivity of these algorithms on varos dataset features (cluster dimensionality, number of clusters, cluster overlap, cluster shape and cluster structure). The contributions of these experiments are two-folds: (i) ECA* exceeds its counterpart aloriths in ability to find out the right cluster number; (ii) ECA* is less sensitive towards dataset features compared to its competitive techniques. Nonetheless, the results of the experiments performed demonstrate some limitations in the ECA*: (i) ECA* is not fully applied based on the premise that no prior knowledge exists; (ii) Adapting and utilising ECA* on several real applications has not been achieved yet.

</p>
</details>

<details><summary><b>Pedestrian Collision Avoidance for Autonomous Vehicles at Unsignalized Intersection Using Deep Q-Network</b>
<a href="https://arxiv.org/abs/2105.00153">arxiv:2105.00153</a>
&#x1F4C8; 2 <br>
<p>Kasra Mokhtari, Alan R. Wagner</p></summary>
<p>

**Abstract:** Prior research has extensively explored Autonomous Vehicle (AV) navigation in the presence of other vehicles, however, navigation among pedestrians, who are the most vulnerable element in urban environments, has been less examined. This paper explores AV navigation in crowded, unsignalized intersections. We compare the performance of different deep reinforcement learning methods trained on our reward function and state representation. The performance of these methods and a standard rule-based approach were evaluated in two ways, first at the unsignalized intersection on which the methods were trained, and secondly at an unknown unsignalized intersection with a different topology. For both scenarios, the rule-based method achieves less than 40\% collision-free episodes, whereas our methods result in a performance of approximately 100\%. Of the three methods used, DDQN/PER outperforms the other two methods while it also shows the smallest average intersection crossing time, the greatest average speed, and the greatest distance from the closest pedestrian.

</p>
</details>

<details><summary><b>An analysis of full-size Russian complexly NER labelled corpus of Internet user reviews on the drugs based on deep learning and language neural nets</b>
<a href="https://arxiv.org/abs/2105.00059">arxiv:2105.00059</a>
&#x1F4C8; 2 <br>
<p>Alexander Sboev, Sanna Sboeva, Ivan Moloshnikov, Artem Gryaznov, Roman Rybka, Alexander Naumov, Anton Selivanov, Gleb Rylkov, Viacheslav Ilyin</p></summary>
<p>

**Abstract:** We present the full-size Russian complexly NER-labeled corpus of Internet user reviews, along with an evaluation of accuracy levels reached on this corpus by a set of advanced deep learning neural networks to extract the pharmacologically meaningful entities from Russian texts. The corpus annotation includes mentions of the following entities: Medication (33005 mentions), Adverse Drug Reaction (1778), Disease (17403), and Note (4490). Two of them - Medication and Disease - comprise a set of attributes. A part of the corpus has the coreference annotation with 1560 coreference chains in 300 documents. Special multi-label model based on a language model and the set of features is developed, appropriate for presented corpus labeling. The influence of the choice of different modifications of the models: word vector representations, types of language models pre-trained for Russian, text normalization styles, and other preliminary processing are analyzed. The sufficient size of our corpus allows to study the effects of particularities of corpus labeling and balancing entities in the corpus. As a result, the state of the art for the pharmacological entity extraction problem for Russian is established on a full-size labeled corpus. In case of the adverse drug reaction (ADR) recognition, it is 61.1 by the F1-exact metric that, as our analysis shows, is on par with the accuracy level for other language corpora with similar characteristics and the ADR representativnes. The evaluated baseline precision of coreference relation extraction on the corpus is 71, that is higher the results reached on other Russian corpora.

</p>
</details>

<details><summary><b>Data Augmentation in High Dimensional Low Sample Size Setting Using a Geometry-Based Variational Autoencoder</b>
<a href="https://arxiv.org/abs/2105.00026">arxiv:2105.00026</a>
&#x1F4C8; 2 <br>
<p>Clément Chadebec, Elina Thibeau-Sutre, Ninon Burgos, Stéphanie Allassonnière</p></summary>
<p>

**Abstract:** In this paper, we propose a new method to perform data augmentation in a reliable way in the High Dimensional Low Sample Size (HDLSS) setting using a geometry-based variational autoencoder. Our approach combines a proper latent space modeling of the VAE seen as a Riemannian manifold with a new generation scheme which produces more meaningful samples especially in the context of small data sets. The proposed method is tested through a wide experimental study where its robustness to data sets, classifiers and training samples size is stressed. It is also validated on a medical imaging classification task on the challenging ADNI database where a small number of 3D brain MRIs are considered and augmented using the proposed VAE framework. In each case, the proposed method allows for a significant and reliable gain in the classification metrics. For instance, balanced accuracy jumps from 66.3% to 74.3% for a state-of-the-art CNN classifier trained with 50 MRIs of cognitively normal (CN) and 50 Alzheimer disease (AD) patients and from 77.7% to 86.3% when trained with 243 CN and 210 AD while improving greatly sensitivity and specificity metrics.

</p>
</details>

<details><summary><b>Revisiting Citizen Science Through the Lens of Hybrid Intelligence</b>
<a href="https://arxiv.org/abs/2104.14961">arxiv:2104.14961</a>
&#x1F4C8; 2 <br>
<p>Janet Rafner, Miroslav Gajdacz, Gitte Kragh, Arthur Hjorth, Anna Gander, Blanka Palfi, Aleks Berditchevskaia, François Grey, Kobi Gal, Avi Segal, Mike Walmsley, Josh Aaron Miller, Dominik Dellerman, Muki Haklay, Pietro Michelucci, Jacob Sherson</p></summary>
<p>

**Abstract:** Artificial Intelligence (AI) can augment and sometimes even replace human cognition. Inspired by efforts to value human agency alongside productivity, we discuss the benefits of solving Citizen Science (CS) tasks with Hybrid Intelligence (HI), a synergetic mixture of human and artificial intelligence. Currently there is no clear framework or methodology on how to create such an effective mixture. Due to the unique participant-centered set of values and the abundance of tasks drawing upon both human common sense and complex 21st century skills, we believe that the field of CS offers an invaluable testbed for the development of HI and human-centered AI of the 21st century, while benefiting CS as well. In order to investigate this potential, we first relate CS to adjacent computational disciplines. Then, we demonstrate that CS projects can be grouped according to their potential for HI-enhancement by examining two key dimensions: the level of digitization and the amount of knowledge or experience required for participation. Finally, we propose a framework for types of human-AI interaction in CS based on established criteria of HI. This "HI lens" provides the CS community with an overview of several ways to utilize the combination of AI and human intelligence in their projects. It also allows the AI community to gain ideas on how developing AI in CS projects can further their own field.

</p>
</details>

<details><summary><b>Deep Learning Based Steel Pipe Weld Defect Detection</b>
<a href="https://arxiv.org/abs/2104.14907">arxiv:2104.14907</a>
&#x1F4C8; 2 <br>
<p>Dingming Yang, Yanrong Cui, Zeyu Yu, Hongqiang Yuan</p></summary>
<p>

**Abstract:** Steel pipes are widely used in high-risk and high-pressure scenarios such as oil, chemical, natural gas, shale gas, etc. If there is some defect in steel pipes, it will lead to serious adverse consequences. Applying object detection in the field of deep learning to pipe weld defect detection and identification can effectively improve inspection efficiency and promote the development of industrial automation. Most predecessors used traditional computer vision methods applied to detect defects of steel pipe weld seams. However, traditional computer vision methods rely on prior knowledge and can only detect defects with a single feature, so it is difficult to complete the task of multi-defect classification, while deep learning is end-to-end. In this paper, the state-of-the-art single-stage object detection algorithm YOLOv5 is proposed to be applied to the field of steel pipe weld defect detection, and compared with the two-stage representative object detection algorithm Faster R-CNN. The experimental results show that applying YOLOv5 to steel pipe weld defect detection can greatly improve the accuracy, complete the multi-classification task, and meet the criteria of real-time detection.

</p>
</details>

<details><summary><b>Vehicle Re-identification Method Based on Vehicle Attribute and Mutual Exclusion Between Cameras</b>
<a href="https://arxiv.org/abs/2104.14882">arxiv:2104.14882</a>
&#x1F4C8; 2 <br>
<p>Junru Chen, Shiqing Geng, Yongluan Yan, Danyang Huang, Hao Liu, Yadong Li</p></summary>
<p>

**Abstract:** Vehicle Re-identification aims to identify a specific vehicle across time and camera view. With the rapid growth of intelligent transportation systems and smart cities, vehicle Re-identification technology gets more and more attention. However, due to the difference of shooting angle and the high similarity of vehicles belonging to the same brand, vehicle re-identification becomes a great challenge for existing method. In this paper, we propose a vehicle attribute-guided method to re-rank vehicle Re-ID result. The attributes used include vehicle orientation and vehicle brand . We also focus on the camera information and introduce camera mutual exclusion theory to further fine-tune the search results. In terms of feature extraction, we combine the data augmentations of multi-resolutions with the large model ensemble to get a more robust vehicle features. Our method achieves mAP of 63.73% and rank-1 accuracy 76.61% in the CVPR 2021 AI City Challenge.

</p>
</details>

<details><summary><b>Computational Simulation and Analysis of Major Control Parameters of Time-Dependent PV/T Collectors</b>
<a href="https://arxiv.org/abs/2105.05358">arxiv:2105.05358</a>
&#x1F4C8; 1 <br>
<p>Jimeng Shi, Cheng-Xian Lin</p></summary>
<p>

**Abstract:** In order to improve performance of photovoltaic/thermal (or PV/T for simplicity) collectors, this paper firstly validated a previous computational thermal model and then introduced an improved computational thermal model to investigate the effects of the major control parameters on the thermal performance of PV/T collectors, including solar cell temperature, back surface temperature, and outlet water temperature. Besides, a computational electrical model of PV/T system was also introduced to elaborate the relationship of voltage, current and power of a PV module (MSX60 polycrystalline solar cell) used in an experiment in the literature. Simulation results agree with the experimental data very well. The effects of the time-steps from 1 hour to minute, which is closed to the real time, were also reported. At last, several suggestions to improve the efficiency of PV/T system were illustrated.

</p>
</details>

<details><summary><b>A Sensorless Control System for an Implantable Heart Pump using a Real-time Deep Convolutional Neural Network</b>
<a href="https://arxiv.org/abs/2105.00875">arxiv:2105.00875</a>
&#x1F4C8; 1 <br>
<p>Masoud Fetanat, Michael Stevens, Christopher Hayward, Nigel H. Lovell</p></summary>
<p>

**Abstract:** Left ventricular assist devices (LVADs) are mechanical pumps, which can be used to support heart failure (HF) patients as bridge to transplant and destination therapy. To automatically adjust the LVAD speed, a physiological control system needs to be designed to respond to variations of patient hemodynamics across a variety of clinical scenarios. These control systems require pressure feedback signals from the cardiovascular system. However, there are no suitable long-term implantable sensors available. In this study, a novel real-time deep convolutional neural network (CNN) for estimation of preload based on the LVAD flow was proposed. A new sensorless adaptive physiological control system for an LVAD pump was developed using the full dynamic form of model free adaptive control (FFDL-MFAC) and the proposed preload estimator to maintain the patient conditions in safe physiological ranges. The CNN model for preload estimation was trained and evaluated through 10-fold cross validation on 100 different patient conditions and the proposed sensorless control system was assessed on a new testing set of 30 different patient conditions across six different patient scenarios. The proposed preload estimator was extremely accurate with a correlation coefficient of 0.97, root mean squared error of 0.84 mmHg, reproducibility coefficient of 1.56 mmHg, coefficient of variation of 14.44 %, and bias of 0.29 mmHg for the testing dataset. The results also indicate that the proposed sensorless physiological controller works similarly to the preload-based physiological control system for LVAD using measured preload to prevent ventricular suction and pulmonary congestion. This study shows that the LVADs can respond appropriately to changing patient states and physiological demands without the need for additional pressure or flow measurements.

</p>
</details>

<details><summary><b>Bermuda Triangles: GNNs Fail to Detect Simple Topological Structures</b>
<a href="https://arxiv.org/abs/2105.00134">arxiv:2105.00134</a>
&#x1F4C8; 1 <br>
<p>Arseny Tolmachev, Akira Sakai, Masaru Todoriki, Koji Maruhashi</p></summary>
<p>

**Abstract:** Most graph neural network architectures work by message-passing node vector embeddings over the adjacency matrix, and it is assumed that they capture graph topology by doing that. We design two synthetic tasks, focusing purely on topological problems -- triangle detection and clique distance -- on which graph neural networks perform surprisingly badly, failing to detect those "bermuda" triangles. Datasets and their generation scripts are publicly available on github.com/FujitsuLaboratories/bermudatriangles and dataset.labs.fujitsu.com.

</p>
</details>

<details><summary><b>Tensor Random Projection for Low Memory Dimension Reduction</b>
<a href="https://arxiv.org/abs/2105.00105">arxiv:2105.00105</a>
&#x1F4C8; 1 <br>
<p>Yiming Sun, Yang Guo, Joel A. Tropp, Madeleine Udell</p></summary>
<p>

**Abstract:** Random projections reduce the dimension of a set of vectors while preserving structural information, such as distances between vectors in the set. This paper proposes a novel use of row-product random matrices in random projection, where we call it Tensor Random Projection (TRP). It requires substantially less memory than existing dimension reduction maps. The TRP map is formed as the Khatri-Rao product of several smaller random projections, and is compatible with any base random projection including sparse maps, which enable dimension reduction with very low query cost and no floating point operations. We also develop a reduced variance extension. We provide a theoretical analysis of the bias and variance of the TRP, and a non-asymptotic error analysis for a TRP composed of two smaller maps. Experiments on both synthetic and MNIST data show that our method performs as well as conventional methods with substantially less storage.

</p>
</details>

<details><summary><b>Applying physics-based loss functions to neural networks for improved generalizability in mechanics problems</b>
<a href="https://arxiv.org/abs/2105.00075">arxiv:2105.00075</a>
&#x1F4C8; 1 <br>
<p>Samuel J. Raymond, David B. Camarillo</p></summary>
<p>

**Abstract:** Physics-Informed Machine Learning (PIML) has gained momentum in the last 5 years with scientists and researchers aiming to utilize the benefits afforded by advances in machine learning, particularly in deep learning. With large scientific data sets with rich spatio-temporal data and high-performance computing providing large amounts of data to be inferred and interpreted, the task of PIML is to ensure that these predictions, categorizations, and inferences are enforced by, and conform to the limits imposed by physical laws. In this work a new approach to utilizing PIML is discussed that deals with the use of physics-based loss functions. While typical usage of physical equations in the loss function requires complex layers of derivatives and other functions to ensure that the known governing equation is satisfied, here we show that a similar level of enforcement can be found by implementing more simpler loss functions on specific kinds of output data. The generalizability that this approach affords is shown using examples of simple mechanical models that can be thought of as sufficiently simplified surrogate models for a wide class of problems.

</p>
</details>

<details><summary><b>Flow-Packet Hybrid Traffic Classification for Class-Aware Network Routing</b>
<a href="https://arxiv.org/abs/2105.00074">arxiv:2105.00074</a>
&#x1F4C8; 1 <br>
<p>Sayantan Chowdhury, Ben Liang, Ali Tizghadam, Ilijc Albanese</p></summary>
<p>

**Abstract:** Network traffic classification using machine learning techniques has been widely studied. Most existing schemes classify entire traffic flows, but there are major limitations to their practicality. At a network router, the packets need to be processed with minimum delay, so the classifier cannot wait until the end of the flow to make a decision. Furthermore, a complicated machine learning algorithm can be too computationally expensive to implement inside the router. In this paper, we introduce flow-packet hybrid traffic classification (FPHTC), where the router makes a decision per packet based on a routing policy that is designed through transferring the learned knowledge from a flow-based classifier residing outside the router. We analyze the generalization bound of FPHTC and show its advantage over regular packet-based traffic classification. We present experimental results using a real-world traffic dataset to illustrate the classification performance of FPHTC. We show that it is robust toward traffic pattern changes and can be deployed with limited computational resource.

</p>
</details>

<details><summary><b>Vessel and Port Efficiency Metrics through Validated AIS data</b>
<a href="https://arxiv.org/abs/2105.00063">arxiv:2105.00063</a>
&#x1F4C8; 1 <br>
<p>Tomaz Martincic, Dejan Stepec, Joao Pita Costa, Kristijan Cagran, Athanasios Chaldeakis</p></summary>
<p>

**Abstract:** Automatic Identification System (AIS) data represents a rich source of information about maritime traffic and offers a great potential for data analytics and predictive modeling solutions, which can help optimizing logistic chains and to reduce environmental impacts. In this work, we address the main limitations of the validity of AIS navigational data fields, by proposing a machine learning-based data-driven methodology to detect and (to the possible extent) also correct erroneous data. Additionally, we propose a metric that can be used by vessel operators and ports to express numerically their business and environmental efficiency through time and spatial dimensions, enabled with the obtained validated AIS data. We also demonstrate Port Area Vessel Movements (PARES) tool, which demonstrates the proposed solutions.

</p>
</details>

<details><summary><b>PositNN: Training Deep Neural Networks with Mixed Low-Precision Posit</b>
<a href="https://arxiv.org/abs/2105.00053">arxiv:2105.00053</a>
&#x1F4C8; 1 <br>
<p>Gonçalo Raposo, Pedro Tomás, Nuno Roma</p></summary>
<p>

**Abstract:** Low-precision formats have proven to be an efficient way to reduce not only the memory footprint but also the hardware resources and power consumption of deep learning computations. Under this premise, the posit numerical format appears to be a highly viable substitute for the IEEE floating-point, but its application to neural networks training still requires further research. Some preliminary results have shown that 8-bit (and even smaller) posits may be used for inference and 16-bit for training, while maintaining the model accuracy. The presented research aims to evaluate the feasibility to train deep convolutional neural networks using posits. For such purpose, a software framework was developed to use simulated posits and quires in end-to-end training and inference. This implementation allows using any bit size, configuration, and even mixed precision, suitable for different precision requirements in various stages. The obtained results suggest that 8-bit posits can substitute 32-bit floats during training with no negative impact on the resulting loss and accuracy.

</p>
</details>

<details><summary><b>Participatory Budgeting with Donations and Diversity Constraints</b>
<a href="https://arxiv.org/abs/2104.15075">arxiv:2104.15075</a>
&#x1F4C8; 1 <br>
<p>Jiehua Chen, Martin Lackner, Jan Maly</p></summary>
<p>

**Abstract:** Participatory budgeting (PB) is a democratic process where citizens jointly decide on how to allocate public funds to indivisible projects. This paper focuses on PB processes where citizens may give additional money to projects they want to see funded. We introduce a formal framework for this kind of PB with donations. Our framework also allows for diversity constraints, meaning that each project belongs to one or more types, and there are lower and upper bounds on the number of projects of the same type that can be funded. We propose three general classes of methods for aggregating the citizens' preferences in the presence of donations and analyze their axiomatic properties. Furthermore, we investigate the computational complexity of determining the outcome of a PB process with donations and of finding a citizen's optimal donation strategy.

</p>
</details>

<details><summary><b>Using brain inspired principles to unsupervisedly learn good representations for visual pattern recognition</b>
<a href="https://arxiv.org/abs/2104.14970">arxiv:2104.14970</a>
&#x1F4C8; 1 <br>
<p>Luis Sa-Couto, Andreas Wichert</p></summary>
<p>

**Abstract:** Although deep learning has solved difficult problems in visual pattern recognition, it is mostly successful in tasks where there are lots of labeled training data available. Furthermore, the global back-propagation based training rule and the amount of employed layers represents a departure from biological inspiration. The brain is able to perform most of these tasks in a very general way from limited to no labeled data. For these reasons it is still a key research question to look into computational principles in the brain that can help guide models to unsupervisedly learn good representations which can then be used to perform tasks like classification. In this work we explore some of these principles to generate such representations for the MNIST data set. We compare the obtained results with similar recent works and verify extremely competitive results.

</p>
</details>

<details><summary><b>Certifying Emergency Landing for Safe Urban UAV</b>
<a href="https://arxiv.org/abs/2104.14928">arxiv:2104.14928</a>
&#x1F4C8; 1 <br>
<p>Joris Guerin, Kevin Delmas, Jérémie Guiochet</p></summary>
<p>

**Abstract:** Unmanned Aerial Vehicles (UAVs) have the potential to be used for many applications in urban environments. However, allowing UAVs to fly above densely populated areas raises concerns regarding safety. One of the main safety issues is the possibility for a failure to cause the loss of navigation capabilities, which can result in the UAV falling/landing in hazardous areas such as busy roads, where it can cause fatal accidents. Current standards, such as the SORA published in 2019, do not consider applicable mitigation techniques to handle this kind of hazardous situations. Consequently, certifying UAV urban operations implies to demonstrate very high levels of integrity, which results in prohibitive development costs. To address this issue, this paper explores the concept of Emergency Landing (EL). A safety analysis is conducted on an urban UAV case study, and requirements are proposed to enable the integration of EL as an acceptable mitigation mean in the SORA. Based on these requirements, an EL implementation was developed, together with a runtime monitoring architecture to enhance confidence in the system. Preliminary qualitative results are presented and the monitor seem to be able to detect errors of the EL system effectively.

</p>
</details>

<details><summary><b>Improving Conversational Recommendation System by Pretraining on Billions Scale of Knowledge Graph</b>
<a href="https://arxiv.org/abs/2104.14899">arxiv:2104.14899</a>
&#x1F4C8; 1 <br>
<p>Chi-Man Wong, Fan Feng, Wen Zhang, Chi-Man Vong, Hui Chen, Yichi Zhang, Peng He, Huan Chen, Kun Zhao, Huajun Chen</p></summary>
<p>

**Abstract:** Conversational Recommender Systems (CRSs) in E-commerce platforms aim to recommend items to users via multiple conversational interactions. Click-through rate (CTR) prediction models are commonly used for ranking candidate items. However, most CRSs are suffer from the problem of data scarcity and sparseness. To address this issue, we propose a novel knowledge-enhanced deep cross network (K-DCN), a two-step (pretrain and fine-tune) CTR prediction model to recommend items. We first construct a billion-scale conversation knowledge graph (CKG) from information about users, items and conversations, and then pretrain CKG by introducing knowledge graph embedding method and graph convolution network to encode semantic and structural information respectively.To make the CTR prediction model sensible of current state of users and the relationship between dialogues and items, we introduce user-state and dialogue-interaction representations based on pre-trained CKG and propose K-DCN.In K-DCN, we fuse the user-state representation, dialogue-interaction representation and other normal feature representations via deep cross network, which will give the rank of candidate items to be recommended.We experimentally prove that our proposal significantly outperforms baselines and show it's real application in Alime.

</p>
</details>

<details><summary><b>Number and quality of diagrams in scholarly publications is associated with number of citations</b>
<a href="https://arxiv.org/abs/2104.14815">arxiv:2104.14815</a>
&#x1F4C8; 1 <br>
<p>Guy Clarke Marshall, Caroline Jay, Andre Freitas</p></summary>
<p>

**Abstract:** Diagrams are often used in scholarly communication. We analyse a corpus of diagrams found in scholarly computational linguistics conference proceedings (ACL 2017), and find inclusion of a system diagram to be correlated with higher numbers of citations after 3 years. Inclusion of over three diagrams in this 8-page limit conference was found to correlate with a lower citation count. Focusing on neural network system diagrams, we find a correlation between highly cited papers and "good diagramming practice" quantified by level of compliance with a set of diagramming guidelines. Two diagram classification types (one visually based, one mental model based) were not found to correlate with number of citations, but enabled quantification of heterogeneity in those dimensions. Exploring scholarly paper-writing guides, we find diagrams to be a neglected media. This study suggests that diagrams may be a useful source of quality data for predicting citations, and that "graphicacy" is a key skill for scholars with insufficient support at present.

</p>
</details>

<details><summary><b>Scholarly AI system diagrams as an access point to mental models</b>
<a href="https://arxiv.org/abs/2104.14811">arxiv:2104.14811</a>
&#x1F4C8; 1 <br>
<p>Guy Clarke Marshall, Caroline Jay, Andre Freitas</p></summary>
<p>

**Abstract:** Complex systems, such as Artificial Intelligence (AI) systems, are comprised of many interrelated components. In order to represent these systems, demonstrating the relations between components is essential. Perhaps because of this, diagrams, as "icons of relation", are a prevalent medium for signifying complex systems. Diagrams used to communicate AI system architectures are currently extremely varied. The diversity in diagrammatic conceptual modelling choices provides an opportunity to gain insight into the aspects which are being prioritised for communication. In this philosophical exploration of AI systems diagrams, we integrate theories of conceptual models, communication theory, and semiotics. We discuss consequences of standardised diagrammatic languages for AI systems, concluding that while we expect engineers implementing systems to benefit from standards, researchers would have a larger benefit from guidelines.

</p>
</details>

<details><summary><b>Structuralist analysis for neural network system diagrams</b>
<a href="https://arxiv.org/abs/2104.14810">arxiv:2104.14810</a>
&#x1F4C8; 1 <br>
<p>Guy Clarke Marshall, Caroline Jay, Andre Freitas</p></summary>
<p>

**Abstract:** This short paper examines diagrams describing neural network systems in academic conference proceedings. Many aspects of scholarly communication are controlled, particularly with relation to text and formatting, but often diagrams are not centrally curated beyond a peer review. Using a corpus-based approach, we argue that the heterogeneous diagrammatic notations used for neural network systems has implications for signification in this domain. We divide this into (i) what content is being represented and (ii) how relations are encoded. Using a novel structuralist framework, we use a corpus analysis to quantitatively cluster diagrams according to the author's representational choices. This quantitative diagram classification in a heterogeneous domain may provide a foundation for further analysis.

</p>
</details>

<details><summary><b>NuSPAN: A Proximal Average Network for Nonuniform Sparse Model -- Application to Seismic Reflectivity Inversion</b>
<a href="https://arxiv.org/abs/2105.00003">arxiv:2105.00003</a>
&#x1F4C8; 0 <br>
<p>Swapnil Mache, Praveen Kumar Pokala, Kusala Rajendran, Chandra Sekhar Seelamantula</p></summary>
<p>

**Abstract:** We solve the problem of sparse signal deconvolution in the context of seismic reflectivity inversion, which pertains to high-resolution recovery of the subsurface reflection coefficients. Our formulation employs a nonuniform, non-convex synthesis sparse model comprising a combination of convex and non-convex regularizers, which results in accurate approximations of the l0 pseudo-norm. The resulting iterative algorithm requires the proximal average strategy. When unfolded, the iterations give rise to a learnable proximal average network architecture that can be optimized in a data-driven fashion. We demonstrate the efficacy of the proposed approach through numerical experiments on synthetic 1-D seismic traces and 2-D wedge models in comparison with the benchmark techniques. We also present validations considering the simulated Marmousi2 model as well as real 3-D seismic volume data acquired from the Penobscot 3D survey off the coast of Nova Scotia, Canada.

</p>
</details>

<details><summary><b>Technical Reports Compilation: Detecting the Fire Drill anti-pattern using Source Code and issue-tracking data</b>
<a href="https://arxiv.org/abs/2104.15090">arxiv:2104.15090</a>
&#x1F4C8; 0 <br>
<p>Sebastian Hönel</p></summary>
<p>

**Abstract:** Detecting the presence of project management anti-patterns (AP) currently requires experts on the matter and is an expensive endeavor. Worse, experts may introduce their individual subjectivity or bias. Using the Fire Drill AP, we first introduce a novel way to translate descriptions into detectable AP that are comprised of arbitrary metrics and events such as logged time or maintenance activities, which are mined from the underlying source code or issue-tracking data, thus making the description objective as it becomes data-based. Secondly, we demonstrate a novel method to quantify and score the deviations of real-world projects to data-based AP descriptions. Using nine real-world projects that exhibit a Fire Drill to some degree, we show how to further enhance the translated AP. The ground truth in these projects was extracted from two individual experts and consensus was found between them. Our evaluation spans three kinds of pattern, where the first is purely derived from description, the second type is enhanced by data, and the third kind is derived from data only. The Fire Drill AP as translated from description only for either, source code- or issue-tracking-based detection, shows weak potential of confidently detecting the presence of the anti-pattern in a project. Enriching the AP with data from real-world projects significantly improves detection. Using patterns derived from data only leads to almost perfect correlations of the scores with the ground truth. Some APs share symptoms with the Fire Drill AP, and we conclude that the presence of similar patterns is most certainly detectable. Furthermore, any pattern that can be characteristically modeled using the proposed approach is potentially well detectable.

</p>
</details>

<details><summary><b>Nearest-Neighbor-based Collision Avoidance for Quadrotors via Reinforcement Learning</b>
<a href="https://arxiv.org/abs/2104.14912">arxiv:2104.14912</a>
&#x1F4C8; 0 <br>
<p>Ramzi Ourari, Kai Cui, Ahmed Elshamanhory, Heinz Koeppl</p></summary>
<p>

**Abstract:** Collision avoidance algorithms are of central interest to many drone applications. In particular, decentralized approaches may be the key to enabling robust drone swarm solutions in cases where centralized communication becomes computationally prohibitive. In this work, we draw biological inspiration from flocks of starlings (Sturnus vulgaris) and apply the insight to end-to-end learned decentralized collision avoidance. More specifically, we propose a new, scalable observation model following a biomimetic nearest-neighbor information constraint that leads to fast learning and good collision avoidance behavior. By proposing a general reinforcement learning approach, we obtain an end-to-end learning-based approach to integrating collision avoidance with arbitrary tasks such as package collection and formation change. To validate the generality of this approach, we successfully apply our methodology through motion models of medium complexity, modeling momentum and nonetheless allowing direct application to real world quadrotors in conjunction with a standard PID controller. In contrast to prior works, we find that in our sufficiently rich motion model, nearest-neighbor information is indeed enough to learn effective collision avoidance behavior. Our learned policies are tested in simulation and subsequently transferred to real-world drones to validate their real-world applicability.

</p>
</details>

<details><summary><b>ICOS: Efficient and Highly Robust Rotation Search and Point Cloud Registration with Correspondences</b>
<a href="https://arxiv.org/abs/2104.14763">arxiv:2104.14763</a>
&#x1F4C8; 0 <br>
<p>Lei Sun</p></summary>
<p>

**Abstract:** Rotation search and point cloud registration are two fundamental problems in robotics and computer vision, which aim to estimate the rotation and the transformation between the 3D vector sets and point clouds, respectively. Due to the presence of outliers, probably in very large numbers, among the putative vector or point correspondences in real-world applications, robust estimation is of great importance. In this paper, we present ICOS (Inlier searching using COmpatible Structures), a novel, efficient and highly robust solver for both the correspondence-based rotation search and point cloud registration problems. Specifically, we (i) propose and construct a series of compatible structures for the two problems where various invariants can be established, and (ii) design three time-efficient frameworks, the first for rotation search, the second for known-scale registration and the third for unknown-scale registration, to filter out outliers and seek inliers from the invariant-constrained random sampling based on the compatible structures proposed. In this manner, even with extreme outlier ratios, inliers can be sifted out and collected for solving the optimal rotation and transformation effectively, leading to our robust solver ICOS. Through plentiful experiments over standard datasets, we demonstrate that: (i) our solver ICOS is fast, accurate, robust against over 95% outliers with nearly 100% recall ratio of inliers for rotation search and both known-scale and unknown-scale registration, outperforming other state-of-the-art methods, and (ii) ICOS is practical for use in multiple real-world applications.

</p>
</details>


[Next Page](2021/2021-04/2021-04-29.md)
