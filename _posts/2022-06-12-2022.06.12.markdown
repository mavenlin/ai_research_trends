Prev: [2022.06.11]({{ '/2022/06/11/2022.06.11.html' | relative_url }})  Next: [2022.06.13]({{ '/2022/06/13/2022.06.13.html' | relative_url }})
{% raw %}
## Summary for 2022-06-12, created on 2022-06-19


<details><summary><b>X-Risk Analysis for AI Research</b>
<a href="https://arxiv.org/abs/2206.05862">arxiv:2206.05862</a>
&#x1F4C8; 104 <br>
<p>Dan Hendrycks, Mantas Mazeika</p></summary>
<p>

**Abstract:** Artificial intelligence (AI) has the potential to greatly improve society, but as with any powerful technology, it comes with heightened risks and responsibilities. Current AI research lacks a systematic discussion of how to manage long-tail risks from AI systems, including speculative long-term risks. Keeping in mind the potential benefits of AI, there is some concern that building ever more intelligent and powerful AI systems could eventually result in systems that are more powerful than us; some say this is like playing with fire and speculate that this could create existential risks (x-risks). To add precision and ground these discussions, we provide a guide for how to analyze AI x-risk, which consists of three parts: First, we review how systems can be made safer today, drawing on time-tested concepts from hazard analysis and systems safety that have been designed to steer large processes in safer directions. Next, we discuss strategies for having long-term impacts on the safety of future systems. Finally, we discuss a crucial concept in making AI systems safer by improving the balance between safety and general capabilities. We hope this document and the presented concepts and tools serve as a useful guide for understanding how to analyze AI x-risk.

</p>
</details>

<details><summary><b>GLIPv2: Unifying Localization and Vision-Language Understanding</b>
<a href="https://arxiv.org/abs/2206.05836">arxiv:2206.05836</a>
&#x1F4C8; 18 <br>
<p>Haotian Zhang, Pengchuan Zhang, Xiaowei Hu, Yen-Chun Chen, Liunian Harold Li, Xiyang Dai, Lijuan Wang, Lu Yuan, Jenq-Neng Hwang, Jianfeng Gao</p></summary>
<p>

**Abstract:** We present GLIPv2, a grounded VL understanding model, that serves both localization tasks (e.g., object detection, instance segmentation) and Vision-Language (VL) understanding tasks (e.g., VQA, image captioning). GLIPv2 elegantly unifies localization pre-training and Vision-Language Pre-training (VLP) with three pre-training tasks: phrase grounding as a VL reformulation of the detection task, region-word contrastive learning as a novel region-word level contrastive learning task, and the masked language modeling. This unification not only simplifies the previous multi-stage VLP procedure but also achieves mutual benefits between localization and understanding tasks. Experimental results show that a single GLIPv2 model (all model weights are shared) achieves near SoTA performance on various localization and understanding tasks. The model also shows (1) strong zero-shot and few-shot adaption performance on open-vocabulary object detection tasks and (2) superior grounding capability on VL understanding tasks. Code will be released at https://github.com/microsoft/GLIP.

</p>
</details>

<details><summary><b>Self-critiquing models for assisting human evaluators</b>
<a href="https://arxiv.org/abs/2206.05802">arxiv:2206.05802</a>
&#x1F4C8; 9 <br>
<p>William Saunders, Catherine Yeh, Jeff Wu, Steven Bills, Long Ouyang, Jonathan Ward, Jan Leike</p></summary>
<p>

**Abstract:** We fine-tune large language models to write natural language critiques (natural language critical comments) using behavioral cloning. On a topic-based summarization task, critiques written by our models help humans find flaws in summaries that they would have otherwise missed. Our models help find naturally occurring flaws in both model and human written summaries, and intentional flaws in summaries written by humans to be deliberately misleading. We study scaling properties of critiquing with both topic-based summarization and synthetic tasks. Larger models write more helpful critiques, and on most tasks, are better at self-critiquing, despite having harder-to-critique outputs. Larger models can also integrate their own self-critiques as feedback, refining their own summaries into better ones. Finally, we motivate and introduce a framework for comparing critiquing ability to generation and discrimination ability. Our measurements suggest that even large models may still have relevant knowledge they cannot or do not articulate as critiques. These results are a proof of concept for using AI-assisted human feedback to scale the supervision of machine learning systems to tasks that are difficult for humans to evaluate directly. We release our training datasets, as well as samples from our critique assistance experiments.

</p>
</details>

<details><summary><b>PAC-Net: A Model Pruning Approach to Inductive Transfer Learning</b>
<a href="https://arxiv.org/abs/2206.05703">arxiv:2206.05703</a>
&#x1F4C8; 7 <br>
<p>Sanghoon Myung, In Huh, Wonik Jang, Jae Myung Choe, Jisu Ryu, Dae Sin Kim, Kee-Eung Kim, Changwook Jeong</p></summary>
<p>

**Abstract:** Inductive transfer learning aims to learn from a small amount of training data for the target task by utilizing a pre-trained model from the source task. Most strategies that involve large-scale deep learning models adopt initialization with the pre-trained model and fine-tuning for the target task. However, when using over-parameterized models, we can often prune the model without sacrificing the accuracy of the source task. This motivates us to adopt model pruning for transfer learning with deep learning models. In this paper, we propose PAC-Net, a simple yet effective approach for transfer learning based on pruning. PAC-Net consists of three steps: Prune, Allocate, and Calibrate (PAC). The main idea behind these steps is to identify essential weights for the source task, fine-tune on the source task by updating the essential weights, and then calibrate on the target task by updating the remaining redundant weights. Under the various and extensive set of inductive transfer learning experiments, we show that our method achieves state-of-the-art performance by a large margin.

</p>
</details>

<details><summary><b>Don't "research fast and break things": On the ethics of Computational Social Science</b>
<a href="https://arxiv.org/abs/2206.06370">arxiv:2206.06370</a>
&#x1F4C8; 4 <br>
<p>David Leslie</p></summary>
<p>

**Abstract:** This article is concerned with setting up practical guardrails within the research activities and environments of CSS. It aims to provide CSS scholars, as well as policymakers and other stakeholders who apply CSS methods, with the critical and constructive means needed to ensure that their practices are ethical, trustworthy, and responsible. It begins by providing a taxonomy of the ethical challenges faced by researchers in the field of CSS. These are challenges related to (1) the treatment of research subjects, (2) the impacts of CSS research on affected individuals and communities, (3) the quality of CSS research and to its epistemological status, (4) research integrity, and (5) research equity. Taking these challenges as a motivation for cultural transformation, it then argues for the end-to-end incorporation of habits of responsible research and innovation (RRI) into CSS practices, focusing on the role that contextual considerations, anticipatory reflection, impact assessment, public engagement, and justifiable and well-documented action should play across the research lifecycle. In proposing the inclusion of habits of RRI in CSS practices, the chapter lays out several practical steps needed for ethical, trustworthy, and responsible CSS research activities. These include stakeholder engagement processes, research impact assessments, data lifecycle documentation, bias self-assessments, and transparent research reporting protocols.

</p>
</details>

<details><summary><b>Pixel to Binary Embedding Towards Robustness for CNNs</b>
<a href="https://arxiv.org/abs/2206.05898">arxiv:2206.05898</a>
&#x1F4C8; 4 <br>
<p>Ikki Kishida, Hideki Nakayama</p></summary>
<p>

**Abstract:** There are several problems with the robustness of Convolutional Neural Networks (CNNs). For example, the prediction of CNNs can be changed by adding a small magnitude of noise to an input, and the performances of CNNs are degraded when the distribution of input is shifted by a transformation never seen during training (e.g., the blur effect). There are approaches to replace pixel values with binary embeddings to tackle the problem of adversarial perturbations, which successfully improve robustness. In this work, we propose Pixel to Binary Embedding (P2BE) to improve the robustness of CNNs. P2BE is a learnable binary embedding method as opposed to previous hand-coded binary embedding methods. P2BE outperforms other binary embedding methods in robustness against adversarial perturbations and visual corruptions that are not shown during training.

</p>
</details>

<details><summary><b>Content Popularity Prediction in Fog-RANs: A Clustered Federated Learning Based Approach</b>
<a href="https://arxiv.org/abs/2206.05894">arxiv:2206.05894</a>
&#x1F4C8; 4 <br>
<p>Zhiheng Wang, Yanxiang Jiang, Fu-Chun Zheng, Mehdi Bennis, Xiaohu You</p></summary>
<p>

**Abstract:** In this paper, the content popularity prediction problem in fog radio access networks (F-RANs) is investigated. Based on clustered federated learning, we propose a novel mobility-aware popularity prediction policy, which integrates content popularities in terms of local users and mobile users. For local users, the content popularity is predicted by learning the hidden representations of local users and contents. Initial features of local users and contents are generated by incorporating neighbor information with self information. Then, dual-channel neural network (DCNN) model is introduced to learn the hidden representations by producing deep latent features from initial features. For mobile users, the content popularity is predicted via user preference learning. In order to distinguish regional variations of content popularity, clustered federated learning (CFL) is employed, which enables fog access points (F-APs) with similar regional types to benefit from one another and provides a more specialized DCNN model for each F-AP. Simulation results show that our proposed policy achieves significant performance improvement over the traditional policies.

</p>
</details>

<details><summary><b>Deploying Convolutional Networks on Untrusted Platforms Using 2D Holographic Reduced Representations</b>
<a href="https://arxiv.org/abs/2206.05893">arxiv:2206.05893</a>
&#x1F4C8; 4 <br>
<p>Mohammad Mahmudul Alam, Edward Raff, Tim Oates, James Holt</p></summary>
<p>

**Abstract:** Due to the computational cost of running inference for a neural network, the need to deploy the inferential steps on a third party's compute environment or hardware is common. If the third party is not fully trusted, it is desirable to obfuscate the nature of the inputs and outputs, so that the third party can not easily determine what specific task is being performed. Provably secure protocols for leveraging an untrusted party exist but are too computational demanding to run in practice. We instead explore a different strategy of fast, heuristic security that we call Connectionist Symbolic Pseudo Secrets. By leveraging Holographic Reduced Representations (HRR), we create a neural network with a pseudo-encryption style defense that empirically shows robustness to attack, even under threat models that unrealistically favor the adversary.

</p>
</details>

<details><summary><b>Description and Discussion on DCASE 2022 Challenge Task 2: Unsupervised Anomalous Sound Detection for Machine Condition Monitoring Applying Domain Generalization Techniques</b>
<a href="https://arxiv.org/abs/2206.05876">arxiv:2206.05876</a>
&#x1F4C8; 4 <br>
<p>Kota Dohi, Keisuke Imoto, Noboru Harada, Daisuke Niizumi, Yuma Koizumi, Tomoya Nishida, Harsh Purohit, Takashi Endo, Masaaki Yamamoto, Yohei Kawaguchi</p></summary>
<p>

**Abstract:** We present the task description of the Detection and Classification of Acoustic Scenes and Events (DCASE) 2022 Challenge Task 2: "Unsupervised anomalous sound detection (ASD) for machine condition monitoring applying domain generalization techniques". Domain shifts are a critical problem for the application of ASD systems. Because domain shifts can change the acoustic characteristics of data, a model trained in a source domain performs poorly for a target domain. In DCASE 2021 Challenge Task 2, we organized an ASD task for handling domain shifts. In this task, it was assumed that the occurrences of domain shifts are known. However, in practice, the domain of each sample may not be given, and the domain shifts can occur implicitly. In 2022 Task 2, we focus on domain generalization techniques that detects anomalies regardless of the domain shifts. Specifically, the domain of each sample is not given in the test data and only one threshold is allowed for all domains. We will add challenge results and analysis of the submissions after the challenge submission deadline.

</p>
</details>

<details><summary><b>InBiaseD: Inductive Bias Distillation to Improve Generalization and Robustness through Shape-awareness</b>
<a href="https://arxiv.org/abs/2206.05846">arxiv:2206.05846</a>
&#x1F4C8; 4 <br>
<p>Shruthi Gowda, Bahram Zonooz, Elahe Arani</p></summary>
<p>

**Abstract:** Humans rely less on spurious correlations and trivial cues, such as texture, compared to deep neural networks which lead to better generalization and robustness. It can be attributed to the prior knowledge or the high-level cognitive inductive bias present in the brain. Therefore, introducing meaningful inductive bias to neural networks can help learn more generic and high-level representations and alleviate some of the shortcomings. We propose InBiaseD to distill inductive bias and bring shape-awareness to the neural networks. Our method includes a bias alignment objective that enforces the networks to learn more generic representations that are less vulnerable to unintended cues in the data which results in improved generalization performance. InBiaseD is less susceptible to shortcut learning and also exhibits lower texture bias. The better representations also aid in improving robustness to adversarial attacks and we hence plugin InBiaseD seamlessly into the existing adversarial training schemes to show a better trade-off between generalization and robustness.

</p>
</details>

<details><summary><b>A Unified Approach to Reinforcement Learning, Quantal Response Equilibria, and Two-Player Zero-Sum Games</b>
<a href="https://arxiv.org/abs/2206.05825">arxiv:2206.05825</a>
&#x1F4C8; 4 <br>
<p>Samuel Sokota, Ryan D'Orazio, J. Zico Kolter, Nicolas Loizou, Marc Lanctot, Ioannis Mitliagkas, Noam Brown, Christian Kroer</p></summary>
<p>

**Abstract:** Algorithms designed for single-agent reinforcement learning (RL) generally fail to converge to equilibria in two-player zero-sum (2p0s) games. Conversely, game-theoretic algorithms for approximating Nash and quantal response equilibria (QREs) in 2p0s games are not typically competitive for RL and can be difficult to scale. As a result, algorithms for these two cases are generally developed and evaluated separately. In this work, we show that a single algorithm -- a simple extension to mirror descent with proximal regularization that we call magnetic mirror descent (MMD) -- can produce strong results in both settings, despite their fundamental differences. From a theoretical standpoint, we prove that MMD converges linearly to QREs in extensive-form games -- this is the first time linear convergence has been proven for a first order solver. Moreover, applied as a tabular Nash equilibrium solver via self-play, we show empirically that MMD produces results competitive with CFR in both normal-form and extensive-form games with full feedback (this is the first time that a standard RL algorithm has done so) and also that MMD empirically converges in black-box feedback settings. Furthermore, for single-agent deep RL, on a small collection of Atari and Mujoco games, we show that MMD can produce results competitive with those of PPO. Lastly, for multi-agent deep RL, we show MMD can outperform NFSP in 3x3 Abrupt Dark Hex.

</p>
</details>

<details><summary><b>SGD Noise and Implicit Low-Rank Bias in Deep Neural Networks</b>
<a href="https://arxiv.org/abs/2206.05794">arxiv:2206.05794</a>
&#x1F4C8; 4 <br>
<p>Tomer Galanti, Tomaso Poggio</p></summary>
<p>

**Abstract:** We analyze deep ReLU neural networks trained with mini-batch Stochastic Gradient Descent (SGD) and weight decay. We study the source of SGD noise and prove that when training with weight decay, the only solutions of SGD at convergence are zero functions. Furthermore, we show, both theoretically and empirically, that when training a neural network using SGD with weight decay and small batch size, the resulting weight matrices are expected to be of small rank. Our analysis relies on a minimal set of assumptions and the neural networks may be arbitrarily wide or deep, and may include residual connections, as well as batch normalization layers.

</p>
</details>

<details><summary><b>Consistent Attack: Universal Adversarial Perturbation on Embodied Vision Navigation</b>
<a href="https://arxiv.org/abs/2206.05751">arxiv:2206.05751</a>
&#x1F4C8; 4 <br>
<p>You Qiaoben, Chengyang Ying, Xinning Zhou, Hang Su, Jun Zhu, Bo Zhang</p></summary>
<p>

**Abstract:** Embodied agents in vision navigation coupled with deep neural networks have attracted increasing attention. However, deep neural networks are vulnerable to malicious adversarial noises, which may potentially cause catastrophic failures in Embodied Vision Navigation. Among these adversarial noises, universal adversarial perturbations (UAP), i.e., the image-agnostic perturbation applied on each frame received by the agent, are more critical for Embodied Vision Navigation since they are computation-efficient and application-practical during the attack. However, existing UAP methods do not consider the system dynamics of Embodied Vision Navigation. For extending UAP in the sequential decision setting, we formulate the disturbed environment under the universal noise $δ$, as a $δ$-disturbed Markov Decision Process ($δ$-MDP). Based on the formulation, we analyze the properties of $δ$-MDP and propose two novel Consistent Attack methods for attacking Embodied agents, which first consider the dynamic of the MDP by estimating the disturbed Q function and the disturbed distribution. In spite of victim models, our Consistent Attack can cause a significant drop in the performance for the Goalpoint task in habitat. Extensive experimental results indicate that there exist potential risks for applying Embodied Vision Navigation methods to the real world.

</p>
</details>

<details><summary><b>A Directed-Evolution Method for Sparsification and Compression of Neural Networks with Application to Object Identification and Segmentation and considerations of optimal quantization using small number of bits</b>
<a href="https://arxiv.org/abs/2206.05859">arxiv:2206.05859</a>
&#x1F4C8; 3 <br>
<p>Luiz M Franca-Neto</p></summary>
<p>

**Abstract:** This work introduces Directed-Evolution (DE) method for sparsification of neural networks, where the relevance of parameters to the network accuracy is directly assessed and the parameters that produce the least effect on accuracy when tentatively zeroed are indeed zeroed. DE method avoids a potentially combinatorial explosion of all possible candidate sets of parameters to be zeroed in large networks by mimicking evolution in the natural world. DE uses a distillation context [5]. In this context, the original network is the teacher and DE evolves the student neural network to the sparsification goal while maintaining minimal divergence between teacher and student. After the desired sparsification level is reached in each layer of the network by DE, a variety of quantization alternatives are used on the surviving parameters to find the lowest number of bits for their representation with acceptable loss of accuracy. A procedure to find optimal distribution of quantization levels in each sparsified layer is presented. Suitable final lossless encoding of the surviving quantized parameters is used for the final parameter representation. DE was used in sample of representative neural networks using MNIST, FashionMNIST and COCO data sets with progressive larger networks. An 80 classes YOLOv3 with more than 60 million parameters network trained on COCO dataset reached 90% sparsification and correctly identifies and segments all objects identified by the original network with more than 80% confidence using 4bit parameter quantization. Compression between 40x and 80x. It has not escaped the authors that techniques from different methods can be nested. Once the best parameter set for sparsification is identified in a cycle of DE, a decision on zeroing only a sub-set of those parameters can be made using a combination of criteria like parameter magnitude and Hessian approximations.

</p>
</details>

<details><summary><b>Modeling Generalized Specialist Approach To Train Quality Resilient Snapshot Ensemble</b>
<a href="https://arxiv.org/abs/2206.05853">arxiv:2206.05853</a>
&#x1F4C8; 3 <br>
<p>Ghalib Ahmed Tahir, Chu Kiong Loo, Zongying Liu</p></summary>
<p>

**Abstract:** Convolutional neural networks (CNNs) apply well with food image recognition due to the ability to learn discriminative visual features. Nevertheless, recognizing distorted images is challenging for existing CNNs. Hence, the study modelled a generalized specialist approach to train a quality resilient ensemble. The approach aids the models in the ensemble framework retain general skills of recognizing clean images and shallow skills of classifying noisy images with one deep expertise area on a particular distortion. Subsequently, a novel data augmentation random quality mixup (RQMixUp) is combined with snapshot ensembling to train G-Specialist. During each training cycle of G-Specialist, a model is fine-tuned on the synthetic images generated by RQMixup, intermixing clean and distorted images of a particular distortion at a randomly chosen level. Resultantly, each snapshot in the ensemble gained expertise on several distortion levels, with shallow skills on other quality distortions. Next, the filter outputs from diverse experts were fused for higher accuracy. The learning process has no additional cost due to a single training process to train experts, compatible with a wide range of supervised CNNs for transfer learning. Finally, the experimental analysis on three real-world food and a Malaysian food database showed significant improvement for distorted images with competitive classification performance on pristine food images.

</p>
</details>

<details><summary><b>Efficiency Comparison of AI classification algorithms for Image Detection and Recognition in Real-time</b>
<a href="https://arxiv.org/abs/2206.05842">arxiv:2206.05842</a>
&#x1F4C8; 3 <br>
<p>Musarrat Saberin Nipun, Rejwan Bin Sulaiman, Amer Kareem</p></summary>
<p>

**Abstract:** Face detection and identification is the most difficult and often used task in Artificial Intelligence systems. The goal of this study is to present and compare the results of several face detection and recognition algorithms used in the system. This system begins with a training image of a human, then continues on to the test image, identifying the face, comparing it to the trained face, and finally classifying it using OpenCV classifiers. This research will discuss the most effective and successful tactics used in the system, which are implemented using Python, OpenCV, and Matplotlib. It may also be used in locations with CCTV, such as public spaces, shopping malls, and ATM booths.

</p>
</details>

<details><summary><b>Deep Reinforcement Learning for Optimal Investment and Saving Strategy Selection in Heterogeneous Profiles: Intelligent Agents working towards retirement</b>
<a href="https://arxiv.org/abs/2206.05835">arxiv:2206.05835</a>
&#x1F4C8; 3 <br>
<p>Fatih Ozhamaratli, Paolo Barucca</p></summary>
<p>

**Abstract:** The transition from defined benefit to defined contribution pension plans shifts the responsibility for saving toward retirement from governments and institutions to the individuals. Determining optimal saving and investment strategy for individuals is paramount for stable financial stance and for avoiding poverty during work-life and retirement, and it is a particularly challenging task in a world where form of employment and income trajectory experienced by different occupation groups are highly diversified. We introduce a model in which agents learn optimal portfolio allocation and saving strategies that are suitable for their heterogeneous profiles. We use deep reinforcement learning to train agents. The environment is calibrated with occupation and age dependent income evolution dynamics. The research focuses on heterogeneous income trajectories dependent on agent profiles and incorporates the behavioural parameterisation of agents. The model provides a flexible methodology to estimate lifetime consumption and investment choices for heterogeneous profiles under varying scenarios.

</p>
</details>

<details><summary><b>Analysis of Branch Specialization and its Application in Image Decomposition</b>
<a href="https://arxiv.org/abs/2206.05810">arxiv:2206.05810</a>
&#x1F4C8; 3 <br>
<p>Jonathan Brokman, Guy Gilboa</p></summary>
<p>

**Abstract:** Branched neural networks have been used extensively for a variety of tasks. Branches are sub-parts of the model that perform independent processing followed by aggregation. It is known that this setting induces a phenomenon called Branch Specialization, where different branches become experts in different sub-tasks. Such observations were qualitative by nature. In this work, we present a methodological analysis of Branch Specialization. We explain the role of gradient descent in this phenomenon. We show that branched generative networks naturally decompose animal images to meaningful channels of fur, whiskers and spots and face images to channels such as different illumination components and face parts.

</p>
</details>

<details><summary><b>Revisiting Whole-Slide Image Pyramids for Cancer Prognosis via Dual-Stream Networks</b>
<a href="https://arxiv.org/abs/2206.05782">arxiv:2206.05782</a>
&#x1F4C8; 3 <br>
<p>Pei Liu, Bo Fu, Feng Ye, Rui Yang, Bin Xu, Luping Ji</p></summary>
<p>

**Abstract:** The cancer prognosis on gigapixel Whole-Slide Images (WSIs) has always been a challenging task. Most existing approaches focus solely on single-resolution images. The multi-resolution schemes, utilizing image pyramids to enhance WSI visual representations, have not yet been paid enough attention to. In order to explore a multi-resolution solution for improving cancer prognosis accuracy, this paper proposes a dual-stream architecture to model WSIs by an image pyramid strategy. This architecture consists of two sub-streams: one is for low-resolution WSIs, and the other is especially for high-resolution ones. Compared to other approaches, our scheme has three highlights: (i) there exists a one-to-one relation between stream and resolution; (ii) a square pooling layer is added to align the patches from two resolution streams, largely reducing computation cost and enabling a natural stream feature fusion; (iii) a cross-attention-based method is proposed to pool high-resolution patches spatially under the guidance of low-resolution ones. We validate our scheme on three publicly-available datasets, a total number of 3,101 WSIs from 1,911 patients. Experimental results verify that (1) hierarchical dual-stream representation is more effective than single-stream ones for cancer prognosis, gaining an average C-Index rise of 5.0% and 1.8% on a single low-resolution and high-resolution stream, respectively; (2) our dual-stream scheme could outperform current state-of-the-art ones, by a 5.1% average improvement of C-Index; (3) the cancer diseases with observable survival differences could have different preferences for model complexity. Our scheme could serve as an alternative tool for further facilitating WSI prognosis research.

</p>
</details>

<details><summary><b>Learning-Based Data Storage [Vision] (Technical Report)</b>
<a href="https://arxiv.org/abs/2206.05778">arxiv:2206.05778</a>
&#x1F4C8; 3 <br>
<p>Xiang Lian, Xiaofei Zhang</p></summary>
<p>

**Abstract:** Deep neural network (DNN) and its variants have been extensively used for a wide spectrum of real applications such as image classification, face/speech recognition, fraud detection, and so on. In addition to many important machine learning tasks, as artificial networks emulating the way brain cells function, DNNs also show the capability of storing non-linear relationships between input and output data, which exhibits the potential of storing data via DNNs. We envision a new paradigm of data storage, "DNN-as-a-Database", where data are encoded in well-trained machine learning models. Compared with conventional data storage that directly records data in raw formats, learning-based structures (e.g., DNN) can implicitly encode data pairs of inputs and outputs and compute/materialize actual output data of different resolutions only if input data are provided. This new paradigm can greatly enhance the data security by allowing flexible data privacy settings on different levels, achieve low space consumption and fast computation with the acceleration of new hardware (e.g., Diffractive Neural Network and AI chips), and can be generalized to distributed DNN-based storage/computing. In this paper, we propose this novel concept of learning-based data storage, which utilizes a learning structure called learning-based memory unit (LMU), to store, organize, and retrieve data. As a case study, we use DNNs as the engine in the LMU, and study the data capacity and accuracy of the DNN-based data storage. Our preliminary experimental results show the feasibility of the learning-based data storage by achieving high (100%) accuracy of the DNN storage. We explore and design effective solutions to utilize the DNN-based data storage to manage and query relational tables. We discuss how to generalize our solutions to other data types (e.g., graphs) and environments such as distributed DNN storage/computing.

</p>
</details>

<details><summary><b>A Semantic Consistency Feature Alignment Object Detection Model Based on Mixed-Class Distribution Metrics</b>
<a href="https://arxiv.org/abs/2206.05765">arxiv:2206.05765</a>
&#x1F4C8; 3 <br>
<p>Lijun Gou, Jinrong Yang, Hangcheng Yu, Pan Wang, Xiaoping Li, Chao Deng</p></summary>
<p>

**Abstract:** Unsupervised domain adaptation is critical in various computer vision tasks, such as object detection, instance segmentation, etc. They attempt to reduce domain bias-induced performance degradation while also promoting model application speed. Previous works in domain adaptation object detection attempt to align image-level and instance-level shifts to eventually minimize the domain discrepancy, but they may align single-class features to mixed-class features in image-level domain adaptation because each image in the object detection task may be more than one class and object. In order to achieve single-class with single-class alignment and mixed-class with mixed-class alignment, we treat the mixed-class of the feature as a new class and propose a mixed-classes $H-divergence$ for object detection to achieve homogenous feature alignment and reduce negative transfer. Then, a Semantic Consistency Feature Alignment Model (SCFAM) based on mixed-classes $H-divergence$ was also presented. To improve single-class and mixed-class semantic information and accomplish semantic separation, the SCFAM model proposes Semantic Prediction Models (SPM) and Semantic Bridging Components (SBC). And the weight of the pix domain discriminator loss is then changed based on the SPM result to reduce sample imbalance. Extensive unsupervised domain adaption experiments on widely used datasets illustrate our proposed approach's robust object detection in domain bias settings.

</p>
</details>

<details><summary><b>PD-DWI: Predicting response to neoadjuvant chemotherapy in invasive breast cancer with Physiologically-Decomposed Diffusion-Weighted MRI machine-learning model</b>
<a href="https://arxiv.org/abs/2206.05695">arxiv:2206.05695</a>
&#x1F4C8; 3 <br>
<p>Maya Gilad, Moti Freiman</p></summary>
<p>

**Abstract:** Early prediction of pathological complete response (pCR) following neoadjuvant chemotherapy (NAC) for breast cancer plays a critical role in surgical planning and optimizing treatment strategies. Recently, machine and deep-learning based methods were suggested for early pCR prediction from multi-parametric MRI (mp-MRI) data including dynamic contrast-enhanced MRI and diffusion-weighted MRI (DWI) with moderate success. We introduce PD-DWI, a physiologically decomposed DWI machine-learning model to predict pCR from DWI and clinical data. Our model first decomposes the raw DWI data into the various physiological cues that are influencing the DWI signal and then uses the decomposed data, in addition to clinical variables, as the input features of a radiomics-based XGBoost model. We demonstrated the added-value of our PD-DWI model over conventional machine-learning approaches for pCR prediction from mp-MRI data using the publicly available Breast Multi-parametric MRI for prediction of NAC Response (BMMR2) challenge. Our model substantially improves the area under the curve (AUC), compared to the current best result on the leaderboard (0.8849 vs. 0.8397) for the challenge test set. PD-DWI has the potential to improve prediction of pCR following NAC for breast cancer, reduce overall mp-MRI acquisition times and eliminate the need for contrast-agent injection.

</p>
</details>

<details><summary><b>Provable Benefit of Multitask Representation Learning in Reinforcement Learning</b>
<a href="https://arxiv.org/abs/2206.05900">arxiv:2206.05900</a>
&#x1F4C8; 2 <br>
<p>Yuan Cheng, Songtao Feng, Jing Yang, Hong Zhang, Yingbin Liang</p></summary>
<p>

**Abstract:** As representation learning becomes a powerful technique to reduce sample complexity in reinforcement learning (RL) in practice, theoretical understanding of its advantage is still limited. In this paper, we theoretically characterize the benefit of representation learning under the low-rank Markov decision process (MDP) model. We first study multitask low-rank RL (as upstream training), where all tasks share a common representation, and propose a new multitask reward-free algorithm called REFUEL. REFUEL learns both the transition kernel and the near-optimal policy for each task, and outputs a well-learned representation for downstream tasks. Our result demonstrates that multitask representation learning is provably more sample-efficient than learning each task individually, as long as the total number of tasks is above a certain threshold. We then study the downstream RL in both online and offline settings, where the agent is assigned with a new task sharing the same representation as the upstream tasks. For both online and offline settings, we develop a sample-efficient algorithm, and show that it finds a near-optimal policy with the suboptimality gap bounded by the sum of the estimation error of the learned representation in upstream and a vanishing term as the number of downstream samples becomes large. Our downstream results of online and offline RL further capture the benefit of employing the learned representation from upstream as opposed to learning the representation of the low-rank model directly. To the best of our knowledge, this is the first theoretical study that characterizes the benefit of representation learning in exploration-based reward-free multitask RL for both upstream and downstream tasks.

</p>
</details>

<details><summary><b>Accelerating Federated Learning via Sampling Anchor Clients with Large Batches</b>
<a href="https://arxiv.org/abs/2206.05891">arxiv:2206.05891</a>
&#x1F4C8; 2 <br>
<p>Feijie Wu, Song Guo, Zhihao Qu, Shiqi He, Ziming Liu</p></summary>
<p>

**Abstract:** Using large batches in recent federated learning studies has improved convergence rates, but it requires additional computation overhead compared to using small batches. To overcome this limitation, we propose a unified framework FedAMD, which disjoints the participants into anchor and miner groups based on time-varying probabilities. Each client in the anchor group computes the gradient using a large batch, which is regarded as its bullseye. Clients in the miner group perform multiple local updates using serial mini-batches, and each local update is also indirectly regulated by the global target derived from the average of clients' bullseyes. As a result, the miner group follows a near-optimal update towards the global minimizer, adapted to update the global model. Measured by $ε$-approximation, FedAMD achieves a convergence rate of $O(1/ε)$ under non-convex objectives by sampling an anchor with a constant probability. The theoretical result considerably surpasses the state-of-the-art algorithm BVR-L-SGD at $O(1/ε^{3/2})$, while FedAMD reduces at least $O(1/ε)$ communication overhead. Empirical studies on real-world datasets validate the effectiveness of FedAMD and demonstrate the superiority of our proposed algorithm.

</p>
</details>

<details><summary><b>Computation Offloading and Resource Allocation in F-RANs: A Federated Deep Reinforcement Learning Approach</b>
<a href="https://arxiv.org/abs/2206.05881">arxiv:2206.05881</a>
&#x1F4C8; 2 <br>
<p>Lingling Zhang, Yanxiang Jiang, Fu-Chun Zheng, Mehdi Bennis, Xiaohu You</p></summary>
<p>

**Abstract:** The fog radio access network (F-RAN) is a promising technology in which the user mobile devices (MDs) can offload computation tasks to the nearby fog access points (F-APs). Due to the limited resource of F-APs, it is important to design an efficient task offloading scheme. In this paper, by considering time-varying network environment, a dynamic computation offloading and resource allocation problem in F-RANs is formulated to minimize the task execution delay and energy consumption of MDs. To solve the problem, a federated deep reinforcement learning (DRL) based algorithm is proposed, where the deep deterministic policy gradient (DDPG) algorithm performs computation offloading and resource allocation in each F-AP. Federated learning is exploited to train the DDPG agents in order to decrease the computing complexity of training process and protect the user privacy. Simulation results show that the proposed federated DDPG algorithm can achieve lower task execution delay and energy consumption of MDs more quickly compared with the other existing strategies.

</p>
</details>

<details><summary><b>IGN : Implicit Generative Networks</b>
<a href="https://arxiv.org/abs/2206.05860">arxiv:2206.05860</a>
&#x1F4C8; 2 <br>
<p>Haozheng Luo, Tianyi Wu, Feiyu Han, Zhijun Yan, Jianfen Zhang</p></summary>
<p>

**Abstract:** In this work, we build recent advances in distributional reinforcement learning to give a state-of-art distributional variant of the model based on the IQN. We achieve this by using the GAN model's generator and discriminator function with the quantile regression to approximate the full quantile value for the state-action return distribution. We demonstrate improved performance on our baseline dataset - 57 Atari 2600 games in the ALE. Also, we use our algorithm to show the state-of-art training performance of risk-sensitive policies in Atari games with the policy optimization and evaluation.

</p>
</details>

<details><summary><b>Achieving Zero Constraint Violation for Constrained Reinforcement Learning via Conservative Natural Policy Gradient Primal-Dual Algorithm</b>
<a href="https://arxiv.org/abs/2206.05850">arxiv:2206.05850</a>
&#x1F4C8; 2 <br>
<p>Qinbo Bai, Amrit Singh Bedi, Vaneet Aggarwal</p></summary>
<p>

**Abstract:** We consider the problem of constrained Markov decision process (CMDP) in continuous state-actions spaces where the goal is to maximize the expected cumulative reward subject to some constraints. We propose a novel Conservative Natural Policy Gradient Primal-Dual Algorithm (C-NPG-PD) to achieve zero constraint violation while achieving state of the art convergence results for the objective value function. For general policy parametrization, we prove convergence of value function to global optimal upto an approximation error due to restricted policy class. We even improve the sample complexity of existing constrained NPG-PD algorithm \cite{Ding2020} from $\mathcal{O}(1/ε^6)$ to $\mathcal{O}(1/ε^4)$. To the best of our knowledge, this is the first work to establish zero constraint violation with Natural policy gradient style algorithms for infinite horizon discounted CMDPs. We demonstrate the merits of proposed algorithm via experimental evaluations.

</p>
</details>

<details><summary><b>GAN based Data Augmentation to Resolve Class Imbalance</b>
<a href="https://arxiv.org/abs/2206.05840">arxiv:2206.05840</a>
&#x1F4C8; 2 <br>
<p>Sairamvinay Vijayaraghavan, Terry Guan,  Jason,  Song</p></summary>
<p>

**Abstract:** The number of credit card fraud has been growing as technology grows and people can take advantage of it. Therefore, it is very important to implement a robust and effective method to detect such frauds. The machine learning algorithms are appropriate for these tasks since they try to maximize the accuracy of predictions and hence can be relied upon. However, there is an impending flaw where in machine learning models may not perform well due to the presence of an imbalance across classes distribution within the sample set. So, in many related tasks, the datasets have a very small number of observed fraud cases (sometimes around 1 percent positive fraud instances found). Therefore, this imbalance presence may impact any learning model's behavior by predicting all labels as the majority class, hence allowing no scope for generalization in the predictions made by the model. We trained Generative Adversarial Network(GAN) to generate a large number of convincing (and reliable) synthetic examples of the minority class that can be used to alleviate the class imbalance within the training set and hence generalize the learning of the data more effectively.

</p>
</details>

<details><summary><b>Bounding and Approximating Intersectional Fairness through Marginal Fairness</b>
<a href="https://arxiv.org/abs/2206.05828">arxiv:2206.05828</a>
&#x1F4C8; 2 <br>
<p>Mathieu Molina, Patrick Loiseau</p></summary>
<p>

**Abstract:** Discrimination in machine learning often arises along multiple dimensions (a.k.a. protected attributes); it is then desirable to ensure \emph{intersectional fairness} -- i.e., that no subgroup is discriminated against. It is known that ensuring \emph{marginal fairness} for every dimension independently is not sufficient in general. Due to the exponential number of subgroups, however, directly measuring intersectional fairness from data is impossible.
  In this paper, our primary goal is to understand in detail the relationship between marginal and intersectional fairness through statistical analysis. We first identify a set of sufficient conditions under which an exact relationship can be obtained. Then, we prove bounds (easily computable through marginal fairness and other meaningful statistical quantities) in high-probability on intersectional fairness in the general case. Beyond their descriptive value, we show that these theoretical bounds can be leveraged to derive a heuristic improving the approximation and bounds of intersectional fairness by choosing, in a relevant manner, protected attributes for which we describe intersectional subgroups. Finally, we test the performance of our approximations and bounds on real and synthetic data-sets.

</p>
</details>

<details><summary><b>Geometric Policy Iteration for Markov Decision Processes</b>
<a href="https://arxiv.org/abs/2206.05809">arxiv:2206.05809</a>
&#x1F4C8; 2 <br>
<p>Yue Wu, Jesús A. De Loera</p></summary>
<p>

**Abstract:** Recently discovered polyhedral structures of the value function for finite state-action discounted Markov decision processes (MDP) shed light on understanding the success of reinforcement learning. We investigate the value function polytope in greater detail and characterize the polytope boundary using a hyperplane arrangement. We further show that the value space is a union of finitely many cells of the same hyperplane arrangement and relate it to the polytope of the classical linear programming formulation for MDPs. Inspired by these geometric properties, we propose a new algorithm, \emph{Geometric Policy Iteration} (GPI), to solve discounted MDPs. GPI updates the policy of a single state by switching to an action that is mapped to the boundary of the value function polytope, followed by an immediate update of the value function. This new update rule aims at a faster value improvement without compromising computational efficiency. Moreover, our algorithm allows asynchronous updates of state values which is more flexible and advantageous compared to traditional policy iteration when the state set is large. We prove that the complexity of GPI achieves the best known bound $\bigO{\frac{|\actions|}{1 - γ}\log \frac{1}{1-γ}}$ of policy iteration and empirically demonstrate the strength of GPI on MDPs of various sizes.

</p>
</details>

<details><summary><b>Mining Multi-Label Samples from Single Positive Labels</b>
<a href="https://arxiv.org/abs/2206.05764">arxiv:2206.05764</a>
&#x1F4C8; 2 <br>
<p>Youngin Cho, Daejin Kim, Mohammad Azam Khan</p></summary>
<p>

**Abstract:** Conditional generative adversarial networks (cGANs) have shown superior results in class-conditional generation tasks. In order to simultaneously control multiple conditions, cGANs require multi-label training datasets, where multiple labels can be assigned to each data instance. Nevertheless, the tremendous annotation cost limits the accessibility of multi-label datasets in the real-world scenarios. Hence, we explore the practical setting called single positive setting, where each data instance is annotated by only one positive label with no explicit negative labels. To generate multi-label data in the single positive setting, we propose a novel sampling approach called single-to-multi-label (S2M) sampling, based on the Markov chain Monte Carlo method. As a widely applicable "add-on" method, our proposed S2M sampling enables existing unconditional and conditional GANs to draw high-quality multi-label data with a minimal annotation cost. Extensive experiments on real image datasets verify the effectiveness and correctness of our method, even when compared to a model trained with fully annotated datasets.

</p>
</details>

<details><summary><b>Finite-Time Analysis of Fully Decentralized Single-Timescale Actor-Critic</b>
<a href="https://arxiv.org/abs/2206.05733">arxiv:2206.05733</a>
&#x1F4C8; 2 <br>
<p>Qijun Luo, Xiao Li</p></summary>
<p>

**Abstract:** Decentralized Actor-Critic (AC) algorithms have been widely utilized for multi-agent reinforcement learning (MARL) and have achieved remarkable success. Apart from its empirical success, the theoretical convergence property of decentralized AC algorithms is largely unexplored. The existing finite-time convergence results are derived based on either double-loop update or two-timescale step sizes rule, which is not often adopted in real implementation. In this work, we introduce a fully decentralized AC algorithm, where actor, critic, and global reward estimator are updated in an alternating manner with step sizes being of the same order, namely, we adopt the \emph{single-timescale} update. Theoretically, using linear approximation for value and reward estimation, we show that our algorithm has sample complexity of $\tilde{\mathcal{O}}(ε^{-2})$ under Markovian sampling, which matches the optimal complexity with double-loop implementation (here, $\tilde{\mathcal{O}}$ hides a log term). The sample complexity can be improved to ${\mathcal{O}}(ε^{-2})$ under the i.i.d. sampling scheme. The central to establishing our complexity results is \emph{the hidden smoothness of the optimal critic variable} we revealed. We also provide a local action privacy-preserving version of our algorithm and its analysis. Finally, we conduct experiments to show the superiority of our algorithm over the existing decentralized AC algorithms.

</p>
</details>

<details><summary><b>Machine learning based surrogate modeling with SVD enabled training for nonlinear civil structures subject to dynamic loading</b>
<a href="https://arxiv.org/abs/2206.05720">arxiv:2206.05720</a>
&#x1F4C8; 2 <br>
<p>Siddharth S. Parida, Supratik Bose, Megan Butcher, Georgios Apostolakis, Prashant Shekhar</p></summary>
<p>

**Abstract:** The computationally expensive estimation of engineering demand parameters (EDPs) via finite element (FE) models, while considering earthquake and parameter uncertainty limits the use of the Performance Based Earthquake Engineering framework. Attempts have been made to substitute FE models with surrogate models, however, most of these models are a function of building parameters only. This necessitates re-training for earthquakes not previously seen by the surrogate. In this paper, the authors propose a machine learning based surrogate model framework, which considers both these uncertainties in order to predict for unseen earthquakes. Accordingly,earthquakes are characterized by their projections on an orthonormal basis, computed using SVD of a representative ground motion suite. This enables one to generate large varieties of earthquakes by randomly sampling these weights and multiplying them with the basis. The weights along with the constitutive parameters serve as inputs to a machine learning model with EDPs as the desired output. Four competing machine learning models were tested and it was observed that a deep neural network (DNN) gave the most accurate prediction. The framework is validated by using it to successfully predict the peak response of one-story and three-story buildings represented using stick models, subjected to unseen far-field ground motions.

</p>
</details>

<details><summary><b>DRNet: Decomposition and Reconstruction Network for Remote Physiological Measurement</b>
<a href="https://arxiv.org/abs/2206.05687">arxiv:2206.05687</a>
&#x1F4C8; 2 <br>
<p>Yuhang Dong, Gongping Yang, Yilong Yin</p></summary>
<p>

**Abstract:** Remote photoplethysmography (rPPG) based physiological measurement has great application values in affective computing, non-contact health monitoring, telehealth monitoring, etc, which has become increasingly important especially during the COVID-19 pandemic. Existing methods are generally divided into two groups. The first focuses on mining the subtle blood volume pulse (BVP) signals from face videos, but seldom explicitly models the noises that dominate face video content. They are susceptible to the noises and may suffer from poor generalization ability in unseen scenarios. The second focuses on modeling noisy data directly, resulting in suboptimal performance due to the lack of regularity of these severe random noises. In this paper, we propose a Decomposition and Reconstruction Network (DRNet) focusing on the modeling of physiological features rather than noisy data. A novel cycle loss is proposed to constrain the periodicity of physiological information. Besides, a plug-and-play Spatial Attention Block (SAB) is proposed to enhance features along with the spatial location information. Furthermore, an efficient Patch Cropping (PC) augmentation strategy is proposed to synthesize augmented samples with different noise and features. Extensive experiments on different public datasets as well as the cross-database testing demonstrate the effectiveness of our approach.

</p>
</details>

<details><summary><b>A Survey on Uncertainty Reasoning and Quantification for Decision Making: Belief Theory Meets Deep Learning</b>
<a href="https://arxiv.org/abs/2206.05675">arxiv:2206.05675</a>
&#x1F4C8; 2 <br>
<p>Zhen Guo, Zelin Wan, Qisheng Zhang, Xujiang Zhao, Feng Chen, Jin-Hee Cho, Qi Zhang, Lance M. Kaplan, Dong H. Jeong, Audun Jøsang</p></summary>
<p>

**Abstract:** An in-depth understanding of uncertainty is the first step to making effective decisions under uncertainty. Deep/machine learning (ML/DL) has been hugely leveraged to solve complex problems involved with processing high-dimensional data. However, reasoning and quantifying different types of uncertainties to achieve effective decision-making have been much less explored in ML/DL than in other Artificial Intelligence (AI) domains. In particular, belief/evidence theories have been studied in KRR since the 1960s to reason and measure uncertainties to enhance decision-making effectiveness. We found that only a few studies have leveraged the mature uncertainty research in belief/evidence theories in ML/DL to tackle complex problems under different types of uncertainty. In this survey paper, we discuss several popular belief theories and their core ideas dealing with uncertainty causes and types and quantifying them, along with the discussions of their applicability in ML/DL. In addition, we discuss three main approaches that leverage belief theories in Deep Neural Networks (DNNs), including Evidential DNNs, Fuzzy DNNs, and Rough DNNs, in terms of their uncertainty causes, types, and quantification methods along with their applicability in diverse problem domains. Based on our in-depth survey, we discuss insights, lessons learned, limitations of the current state-of-the-art bridging belief theories and ML/DL, and finally, future research directions.

</p>
</details>

<details><summary><b>Universality and approximation bounds for echo state networks with random weights</b>
<a href="https://arxiv.org/abs/2206.05669">arxiv:2206.05669</a>
&#x1F4C8; 2 <br>
<p>Zhen Li, Yunfei Yang</p></summary>
<p>

**Abstract:** We study the uniform approximation of echo state networks with randomly generated internal weights. These models, in which only the readout weights are optimized during training, have made empirical success in learning dynamical systems. We address the representational capacity of these models by showing that they are universal under weak conditions. Our main result gives a sufficient condition for the activation function and a sampling procedure for the internal weights so that echo state networks can approximate any continuous casual time-invariant operators with high probability. In particular, for ReLU activation, we quantify the approximation error of echo state networks for sufficiently regular operators.

</p>
</details>

<details><summary><b>Causal Inference-Based Root Cause Analysis for Online Service Systems with Intervention Recognition</b>
<a href="https://arxiv.org/abs/2206.05871">arxiv:2206.05871</a>
&#x1F4C8; 1 <br>
<p>Mingjie Li, Zeyan Li, Kanglin Yin, Xiaohui Nie, Wenchi Zhang, Kaixin Sui, Dan Pei</p></summary>
<p>

**Abstract:** Fault diagnosis is critical in many domains, as faults may lead to safety threats or economic losses. In the field of online service systems, operators rely on enormous monitoring data to detect and mitigate failures. Quickly recognizing a small set of root cause indicators for the underlying fault can save much time for failure mitigation. In this paper, we formulate the root cause analysis problem as a new causal inference task named intervention recognition. We proposed a novel unsupervised causal inference-based method named Causal Inference-based Root Cause Analysis (CIRCA). The core idea is a sufficient condition for a monitoring variable to be a root cause indicator, i.e., the change of probability distribution conditioned on the parents in the Causal Bayesian Network (CBN). Towards the application in online service systems, CIRCA constructs a graph among monitoring metrics based on the knowledge of system architecture and a set of causal assumptions. The simulation study illustrates the theoretical reliability of CIRCA. The performance on a real-world dataset further shows that CIRCA can improve the recall of the top-1 recommendation by 25% over the best baseline method.

</p>
</details>

<details><summary><b>A non-graphical representation of conditional independence via the neighbourhood lattice</b>
<a href="https://arxiv.org/abs/2206.05829">arxiv:2206.05829</a>
&#x1F4C8; 1 <br>
<p>Arash A. Amini, Bryon Aragam, Qing Zhou</p></summary>
<p>

**Abstract:** We introduce and study the neighbourhood lattice decomposition of a distribution, which is a compact, non-graphical representation of conditional independence that is valid in the absence of a faithful graphical representation. The idea is to view the set of neighbourhoods of a variable as a subset lattice, and partition this lattice into convex sublattices, each of which directly encodes a collection of conditional independence relations. We show that this decomposition exists in any compositional graphoid and can be computed efficiently and consistently in high-dimensions. {In particular, this gives a way to encode all of independence relations implied by a distribution that satisfies the composition axiom, which is strictly weaker than the faithfulness assumption that is typically assumed by graphical approaches.} We also discuss various special cases such as graphical models and projection lattices, each of which has intuitive interpretations. Along the way, we see how this problem is closely related to neighbourhood regression, which has been extensively studied in the context of graphical models and structural equations.

</p>
</details>

<details><summary><b>Science through Machine Learning: Quantification of Poststorm Thermospheric Cooling</b>
<a href="https://arxiv.org/abs/2206.05824">arxiv:2206.05824</a>
&#x1F4C8; 1 <br>
<p>Richard J. Licata, Piyush M. Mehta, Daniel R. Weimer, Douglas P. Drob, W. Kent Tobiska, Jean Yoshii</p></summary>
<p>

**Abstract:** Machine learning (ML) is often viewed as a black-box regression technique that is unable to provide considerable scientific insight. ML models are universal function approximators and - if used correctly - can provide scientific information related to the ground-truth dataset used for fitting. A benefit to ML over parametric models is that there are no predefined basis functions limiting the phenomena that can be modeled. In this work, we develop ML models on three datasets: the Space Environment Technologies (SET) High Accuracy Satellite Drag Model (HASDM) density database, a spatiotemporally matched dataset of outputs from the Jacchia-Bowman 2008 Empirical Thermospheric Density Model (JB2008), and an accelerometer-derived density dataset from CHAllenging Minisatellite Payload (CHAMP). These ML models are compared to the Naval Research Laboratory Mass Spectrometer and Incoherent Scatter radar (NRLMSIS 2.0) model to study the presence of post-storm cooling in the middle-thermosphere. We find that both NRLMSIS 2.0 and JB2008-ML do not account for post-storm cooling and consequently perform poorly in periods following strong geomagnetic storms (e.g. the 2003 Halloween storms). Conversely, HASDM-ML and CHAMP-ML do show evidence of post-storm cooling indicating that this phenomenon is present in the original datasets. Results show that density reductions up to 40% can occur 1--3 days post-storm depending on location and the strength of the storm.

</p>
</details>

<details><summary><b>The Rough Topology for Numerical Data</b>
<a href="https://arxiv.org/abs/2206.05776">arxiv:2206.05776</a>
&#x1F4C8; 1 <br>
<p>Uğur Yiğit</p></summary>
<p>

**Abstract:** In this paper, we give a generalization of the rough topology and the core to numerical data by classifying objects in terms of the attribute values. New approach to find the core for numerical data is discussed. Then a measurement to find whether an attribute is in the core or not is given. This new method for finding the core is used for attribute reduction. It is tested and compared by using machine learning algorithms. Finally, the algorithms and codes to convert a data to pertinent data and to find core is also provided.

</p>
</details>

<details><summary><b>RL-EA: A Reinforcement Learning-Based Evolutionary Algorithm Framework for Electromagnetic Detection Satellite Scheduling Problem</b>
<a href="https://arxiv.org/abs/2206.05694">arxiv:2206.05694</a>
&#x1F4C8; 1 <br>
<p>Yanjie Song, Luona Wei, Qing Yang, Jian Wu, Lining Xing, Yingwu Chen</p></summary>
<p>

**Abstract:** The study of electromagnetic detection satellite scheduling problem (EDSSP) has attracted attention due to the detection requirements for a large number of targets. This paper proposes a mixed-integer programming model for the EDSSP problem and an evolutionary algorithm framework based on reinforcement learning (RL-EA). Numerous factors that affect electromagnetic detection are considered in the model, such as detection mode, bandwidth, and other factors. The evolutionary algorithm framework based on reinforcement learning uses the Q-learning framework, and each individual in the population is regarded as an agent. Based on the proposed framework, a Q-learning-based genetic algorithm(QGA) is designed. Q-learning is used to guide the population search process by choosing variation operators. In the algorithm, we design a reward function to update the Q value. According to the problem characteristics, a new combination of <state, action> is proposed. The QGA also uses an elite individual retention strategy to improve search performance. After that, a task time window selection algorithm is proposed To evaluate the performance of population evolution. Various scales experiments are used to examine the planning effect of the proposed algorithm. Through the experimental verification of multiple instances, it can be seen that the QGA can solve the EDSSP problem effectively. Compared with the state-of-the-art algorithms, the QGA algorithm performs better in several aspects.

</p>
</details>


{% endraw %}
Prev: [2022.06.11]({{ '/2022/06/11/2022.06.11.html' | relative_url }})  Next: [2022.06.13]({{ '/2022/06/13/2022.06.13.html' | relative_url }})