Prev: [2022.05.07]({{ '/2022/05/07/2022.05.07.html' | relative_url }})  Next: [2022.05.09]({{ '/2022/05/09/2022.05.09.html' | relative_url }})
{% raw %}
## Summary for 2022-05-08, created on 2022-05-18


<details><summary><b>Building Machine Translation Systems for the Next Thousand Languages</b>
<a href="https://arxiv.org/abs/2205.03983">arxiv:2205.03983</a>
&#x1F4C8; 100 <br>
<p>Ankur Bapna, Isaac Caswell, Julia Kreutzer, Orhan Firat, Daan van Esch, Aditya Siddhant, Mengmeng Niu, Pallavi Baljekar, Xavier Garcia, Wolfgang Macherey, Theresa Breiner, Vera Axelrod, Jason Riesa, Yuan Cao, Mia Xu Chen, Klaus Macherey, Maxim Krikun, Pidong Wang, Alexander Gutkin, Apurva Shah, Yanping Huang, Zhifeng Chen, Yonghui Wu, Macduff Hughes</p></summary>
<p>

**Abstract:** In this paper we share findings from our effort to build practical machine translation (MT) systems capable of translating across over one thousand languages. We describe results in three research domains: (i) Building clean, web-mined datasets for 1500+ languages by leveraging semi-supervised pre-training for language identification and developing data-driven filtering techniques; (ii) Developing practical MT models for under-served languages by leveraging massively multilingual models trained with supervised parallel data for over 100 high-resource languages and monolingual datasets for an additional 1000+ languages; and (iii) Studying the limitations of evaluation metrics for these languages and conducting qualitative analysis of the outputs from our MT models, highlighting several frequent error modes of these types of models. We hope that our work provides useful insights to practitioners working towards building MT systems for currently understudied languages, and highlights research directions that can complement the weaknesses of massively multilingual models in data-sparse settings.

</p>
</details>

<details><summary><b>Unsupervised Discovery and Composition of Object Light Fields</b>
<a href="https://arxiv.org/abs/2205.03923">arxiv:2205.03923</a>
&#x1F4C8; 22 <br>
<p>Cameron Smith, Hong-Xing Yu, Sergey Zakharov, Fredo Durand, Joshua B. Tenenbaum, Jiajun Wu, Vincent Sitzmann</p></summary>
<p>

**Abstract:** Neural scene representations, both continuous and discrete, have recently emerged as a powerful new paradigm for 3D scene understanding. Recent efforts have tackled unsupervised discovery of object-centric neural scene representations. However, the high cost of ray-marching, exacerbated by the fact that each object representation has to be ray-marched separately, leads to insufficiently sampled radiance fields and thus, noisy renderings, poor framerates, and high memory and time complexity during training and rendering. Here, we propose to represent objects in an object-centric, compositional scene representation as light fields. We propose a novel light field compositor module that enables reconstructing the global light field from a set of object-centric light fields. Dubbed Compositional Object Light Fields (COLF), our method enables unsupervised learning of object-centric neural scene representations, state-of-the-art reconstruction and novel view synthesis performance on standard datasets, and rendering and training speeds at orders of magnitude faster than existing 3D approaches.

</p>
</details>

<details><summary><b>On Conditioning the Input Noise for Controlled Image Generation with Diffusion Models</b>
<a href="https://arxiv.org/abs/2205.03859">arxiv:2205.03859</a>
&#x1F4C8; 19 <br>
<p>Vedant Singh, Surgan Jandial, Ayush Chopra, Siddharth Ramesh, Balaji Krishnamurthy, Vineeth N. Balasubramanian</p></summary>
<p>

**Abstract:** Conditional image generation has paved the way for several breakthroughs in image editing, generating stock photos and 3-D object generation. This continues to be a significant area of interest with the rise of new state-of-the-art methods that are based on diffusion models. However, diffusion models provide very little control over the generated image, which led to subsequent works exploring techniques like classifier guidance, that provides a way to trade off diversity with fidelity. In this work, we explore techniques to condition diffusion models with carefully crafted input noise artifacts. This allows generation of images conditioned on semantic attributes. This is different from existing approaches that input Gaussian noise and further introduce conditioning at the diffusion model's inference step. Our experiments over several examples and conditional settings show the potential of our approach.

</p>
</details>

<details><summary><b>Differentiable Electron Microscopy Simulation: Methods and Applications for Visualization</b>
<a href="https://arxiv.org/abs/2205.04464">arxiv:2205.04464</a>
&#x1F4C8; 7 <br>
<p>Ngan Nguyen, Feng Liang, Dominik Engel, Ciril Bohak, Peter Wonka, Timo Ropinski, Ivan Viola</p></summary>
<p>

**Abstract:** We propose a new microscopy simulation system that can depict atomistic models in a micrograph visual style, similar to results of physical electron microscopy imaging. This system is scalable, able to represent simulation of electron microscopy of tens of viral particles and synthesizes the image faster than previous methods. On top of that, the simulator is differentiable, both its deterministic as well as stochastic stages that form signal and noise representations in the micrograph. This notable property has the capability for solving inverse problems by means of optimization and thus allows for generation of microscopy simulations using the parameter settings estimated from real data. We demonstrate this learning capability through two applications: (1) estimating the parameters of the modulation transfer function defining the detector properties of the simulated and real micrographs, and (2) denoising the real data based on parameters trained from the simulated examples. While current simulators do not support any parameter estimation due to their forward design, we show that the results obtained using estimated parameters are very similar to the results of real micrographs. Additionally, we evaluate the denoising capabilities of our approach and show that the results showed an improvement over state-of-the-art methods. Denoised micrographs exhibit less noise in the tilt-series tomography reconstructions, ultimately reducing the visual dominance of noise in direct volume rendering of microscopy tomograms.

</p>
</details>

<details><summary><b>Learning 6-DoF Object Poses to Grasp Category-level Objects by Language Instructions</b>
<a href="https://arxiv.org/abs/2205.04028">arxiv:2205.04028</a>
&#x1F4C8; 5 <br>
<p>Chilam Cheang, Haitao Lin, Yanwei Fu, Xiangyang Xue</p></summary>
<p>

**Abstract:** This paper studies the task of any objects grasping from the known categories by free-form language instructions. This task demands the technique in computer vision, natural language processing, and robotics. We bring these disciplines together on this open challenge, which is essential to human-robot interaction. Critically, the key challenge lies in inferring the category of objects from linguistic instructions and accurately estimating the 6-DoF information of unseen objects from the known classes. In contrast, previous works focus on inferring the pose of object candidates at the instance level. This significantly limits its applications in real-world scenarios.In this paper, we propose a language-guided 6-DoF category-level object localization model to achieve robotic grasping by comprehending human intention. To this end, we propose a novel two-stage method. Particularly, the first stage grounds the target in the RGB image through language description of names, attributes, and spatial relations of objects. The second stage extracts and segments point clouds from the cropped depth image and estimates the full 6-DoF object pose at category-level. Under such a manner, our approach can locate the specific object by following human instructions, and estimate the full 6-DoF pose of a category-known but unseen instance which is not utilized for training the model. Extensive experimental results show that our method is competitive with the state-of-the-art language-conditioned grasp method. Importantly, we deploy our approach on a physical robot to validate the usability of our framework in real-world applications. Please refer to the supplementary for the demo videos of our robot experiments.

</p>
</details>

<details><summary><b>I Know What You Draw: Learning Grasp Detection Conditioned on a Few Freehand Sketches</b>
<a href="https://arxiv.org/abs/2205.04026">arxiv:2205.04026</a>
&#x1F4C8; 5 <br>
<p>Haitao Lin, Chilam Cheang, Yanwei Fu, Xiangyang Xue</p></summary>
<p>

**Abstract:** In this paper, we are interested in the problem of generating target grasps by understanding freehand sketches. The sketch is useful for the persons who cannot formulate language and the cases where a textual description is not available on the fly. However, very few works are aware of the usability of this novel interactive way between humans and robots. To this end, we propose a method to generate a potential grasp configuration relevant to the sketch-depicted objects. Due to the inherent ambiguity of sketches with abstract details, we take the advantage of the graph by incorporating the structure of the sketch to enhance the representation ability. This graph-represented sketch is further validated to improve the generalization of the network, capable of learning the sketch-queried grasp detection by using a small collection (around 100 samples) of hand-drawn sketches. Additionally, our model is trained and tested in an end-to-end manner which is easy to be implemented in real-world applications. Experiments on the multi-object VMRD and GraspNet-1Billion datasets demonstrate the good generalization of the proposed method. The physical robot experiments confirm the utility of our method in object-cluttered scenes.

</p>
</details>

<details><summary><b>Posterior Collapse of a Linear Latent Variable Model</b>
<a href="https://arxiv.org/abs/2205.04009">arxiv:2205.04009</a>
&#x1F4C8; 5 <br>
<p>Zihao Wang, Liu Ziyin</p></summary>
<p>

**Abstract:** This work identifies the existence and cause of a type of posterior collapse that frequently occurs in the Bayesian deep learning practice. For a general linear latent variable model that includes linear variational autoencoders as a special case, we precisely identify the nature of posterior collapse to be the competition between the likelihood and the regularization of the mean due to the prior. Our result also suggests that posterior collapse may be a general problem of learning for deeper architectures and deepens our understanding of Bayesian deep learning.

</p>
</details>

<details><summary><b>Robust (Controlled) Table-to-Text Generation with Structure-Aware Equivariance Learning</b>
<a href="https://arxiv.org/abs/2205.03972">arxiv:2205.03972</a>
&#x1F4C8; 5 <br>
<p>Fei Wang, Zhewei Xu, Pedro Szekely, Muhao Chen</p></summary>
<p>

**Abstract:** Controlled table-to-text generation seeks to generate natural language descriptions for highlighted subparts of a table. Previous SOTA systems still employ a sequence-to-sequence generation method, which merely captures the table as a linear structure and is brittle when table layouts change. We seek to go beyond this paradigm by (1) effectively expressing the relations of content pieces in the table, and (2) making our model robust to content-invariant structural transformations. Accordingly, we propose an equivariance learning framework, which encodes tables with a structure-aware self-attention mechanism. This prunes the full self-attention structure into an order-invariant graph attention that captures the connected graph structure of cells belonging to the same row or column, and it differentiates between relevant cells and irrelevant cells from the structural perspective. Our framework also modifies the positional encoding mechanism to preserve the relative position of tokens in the same cell but enforce position invariance among different cells. Our technology is free to be plugged into existing table-to-text generation models, and has improved T5-based models to offer better performance on ToTTo and HiTab. Moreover, on a harder version of ToTTo, we preserve promising performance, while previous SOTA systems, even with transformation-based data augmentation, have seen significant performance drops. Our code is available at https://github.com/luka-group/Lattice.

</p>
</details>

<details><summary><b>Preservation of High Frequency Content for Deep Learning-Based Medical Image Classification</b>
<a href="https://arxiv.org/abs/2205.03898">arxiv:2205.03898</a>
&#x1F4C8; 5 <br>
<p>Declan McIntosh, Tunai Porto Marques, Alexandra Branzan Albu</p></summary>
<p>

**Abstract:** Chest radiographs are used for the diagnosis of multiple critical illnesses (e.g., Pneumonia, heart failure, lung cancer), for this reason, systems for the automatic or semi-automatic analysis of these data are of particular interest. An efficient analysis of large amounts of chest radiographs can aid physicians and radiologists, ultimately allowing for better medical care of lung-, heart- and chest-related conditions. We propose a novel Discrete Wavelet Transform (DWT)-based method for the efficient identification and encoding of visual information that is typically lost in the down-sampling of high-resolution radiographs, a common step in computer-aided diagnostic pipelines. Our proposed approach requires only slight modifications to the input of existing state-of-the-art Convolutional Neural Networks (CNNs), making it easily applicable to existing image classification frameworks. We show that the extra high-frequency components offered by our method increased the classification performance of several CNNs in benchmarks employing the NIH Chest-8 and ImageNet-2017 datasets. Based on our results we hypothesize that providing frequency-specific coefficients allows the CNNs to specialize in the identification of structures that are particular to a frequency band, ultimately increasing classification performance, without an increase in computational load. The implementation of our work is available at github.com/DeclanMcIntosh/LeGallCuda.

</p>
</details>

<details><summary><b>Fully Automated Binary Pattern Extraction For Finger Vein Identification using Double Optimization Stages-Based Unsupervised Learning Approach</b>
<a href="https://arxiv.org/abs/2205.03840">arxiv:2205.03840</a>
&#x1F4C8; 5 <br>
<p>Ali Salah Hameed, Adil Al-Azzawi</p></summary>
<p>

**Abstract:** Today, finger vein identification is gaining popularity as a potential biometric identification framework solution. Machine learning-based unsupervised, supervised, and deep learning algorithms have had a significant influence on finger vein detection and recognition at the moment. Deep learning, on the other hand, necessitates a large number of training datasets that must be manually produced and labeled. In this research, we offer a completely automated unsupervised learning strategy for training dataset creation. Our method is intended to extract and build a decent binary mask training dataset completely automated. In this technique, two optimization steps are devised and employed. The initial stage of optimization is to create a completely automated unsupervised image clustering based on finger vein image localization. Worldwide finger vein pattern orientation estimation is employed in the second optimization to optimize the retrieved finger vein lines. Finally, the proposed system achieves 99.6 - percent pattern extraction accuracy, which is significantly higher than other common unsupervised learning methods like k-means and Fuzzy C-Means (FCM).

</p>
</details>

<details><summary><b>GRAPHCACHE: Message Passing as Caching for Sentence-Level Relation Extraction</b>
<a href="https://arxiv.org/abs/2205.03786">arxiv:2205.03786</a>
&#x1F4C8; 5 <br>
<p>Yiwei Wang, Muhao Chen, Wenxuan Zhou, Yujun Cai, Yuxuan Liang, Bryan Hooi</p></summary>
<p>

**Abstract:** Entity types and textual context are essential properties for sentence-level relation extraction (RE). Existing work only encodes these properties within individual instances, which limits the performance of RE given the insufficient features in a single sentence. In contrast, we model these properties from the whole dataset and use the dataset-level information to enrich the semantics of every instance. We propose the GRAPHCACHE (Graph Neural Network as Caching) module, that propagates the features across sentences to learn better representations for RE. GRAPHCACHE aggregates the features from sentences in the whole dataset to learn global representations of properties, and use them to augment the local features within individual sentences. The global property features act as dataset-level prior knowledge for RE, and a complement to the sentence-level features. Inspired by the classical caching technique in computer systems, we develop GRAPHCACHE to update the property representations in an online manner. Overall, GRAPHCACHE yields significant effectiveness gains on RE and enables efficient message passing across all sentences in the dataset.

</p>
</details>

<details><summary><b>Should We Rely on Entity Mentions for Relation Extraction? Debiasing Relation Extraction with Counterfactual Analysis</b>
<a href="https://arxiv.org/abs/2205.03784">arxiv:2205.03784</a>
&#x1F4C8; 5 <br>
<p>Yiwei Wang, Muhao Chen, Wenxuan Zhou, Yujun Cai, Yuxuan Liang, Dayiheng Liu, Baosong Yang, Juncheng Liu, Bryan Hooi</p></summary>
<p>

**Abstract:** Recent literature focuses on utilizing the entity information in the sentence-level relation extraction (RE), but this risks leaking superficial and spurious clues of relations. As a result, RE still suffers from unintended entity bias, i.e., the spurious correlation between entity mentions (names) and relations. Entity bias can mislead the RE models to extract the relations that do not exist in the text. To combat this issue, some previous work masks the entity mentions to prevent the RE models from overfitting entity mentions. However, this strategy degrades the RE performance because it loses the semantic information of entities. In this paper, we propose the CORE (Counterfactual Analysis based Relation Extraction) debiasing method that guides the RE models to focus on the main effects of textual context without losing the entity information. We first construct a causal graph for RE, which models the dependencies between variables in RE models. Then, we propose to conduct counterfactual analysis on our causal graph to distill and mitigate the entity bias, that captures the causal effects of specific entity mentions in each instance. Note that our CORE method is model-agnostic to debias existing RE systems during inference without changing their training processes. Extensive experimental results demonstrate that our CORE yields significant gains on both effectiveness and generalization for RE. The source code is provided at: https://github.com/vanoracai/CoRE.

</p>
</details>

<details><summary><b>Multimodal Semi-Supervised Learning for Text Recognition</b>
<a href="https://arxiv.org/abs/2205.03873">arxiv:2205.03873</a>
&#x1F4C8; 4 <br>
<p>Aviad Aberdam, Roy Ganz, Shai Mazor, Ron Litman</p></summary>
<p>

**Abstract:** Until recently, the number of public real-world text images was insufficient for training scene text recognizers. Therefore, most modern training methods rely on synthetic data and operate in a fully supervised manner. Nevertheless, the amount of public real-world text images has increased significantly lately, including a great deal of unlabeled data. Leveraging these resources requires semi-supervised approaches; however, the few existing methods do not account for vision-language multimodality structure and therefore suboptimal for state-of-the-art multimodal architectures. To bridge this gap, we present semi-supervised learning for multimodal text recognizers (SemiMTR) that leverages unlabeled data at each modality training phase. Notably, our method refrains from extra training stages and maintains the current three-stage multimodal training procedure. Our algorithm starts by pretraining the vision model through a single-stage training that unifies self-supervised learning with supervised training. More specifically, we extend an existing visual representation learning algorithm and propose the first contrastive-based method for scene text recognition. After pretraining the language model on a text corpus, we fine-tune the entire network via a sequential, character-level, consistency regularization between weakly and strongly augmented views of text images. In a novel setup, consistency is enforced on each modality separately. Extensive experiments validate that our method outperforms the current training schemes and achieves state-of-the-art results on multiple scene text recognition benchmarks.

</p>
</details>

<details><summary><b>On the Use of BERT for Automated Essay Scoring: Joint Learning of Multi-Scale Essay Representation</b>
<a href="https://arxiv.org/abs/2205.03835">arxiv:2205.03835</a>
&#x1F4C8; 4 <br>
<p>Yongjie Wang, Chuan Wang, Ruobing Li, Hui Lin</p></summary>
<p>

**Abstract:** In recent years, pre-trained models have become dominant in most natural language processing (NLP) tasks. However, in the area of Automated Essay Scoring (AES), pre-trained models such as BERT have not been properly used to outperform other deep learning models such as LSTM. In this paper, we introduce a novel multi-scale essay representation for BERT that can be jointly learned. We also employ multiple losses and transfer learning from out-of-domain essays to further improve the performance. Experiment results show that our approach derives much benefit from joint learning of multi-scale essay representation and obtains almost the state-of-the-art result among all deep learning models in the ASAP task. Our multi-scale essay representation also generalizes well to CommonLit Readability Prize data set, which suggests that the novel text representation proposed in this paper may be a new and effective choice for long-text tasks.

</p>
</details>

<details><summary><b>FP-GNN: a versatile deep learning architecture for enhanced molecular property prediction</b>
<a href="https://arxiv.org/abs/2205.03834">arxiv:2205.03834</a>
&#x1F4C8; 4 <br>
<p>Hanxuan Cai, Huimin Zhang, Duancheng Zhao, Jingxing Wu, Ling Wang</p></summary>
<p>

**Abstract:** Deep learning is an important method for molecular design and exhibits considerable ability to predict molecular properties, including physicochemical, bioactive, and ADME/T (absorption, distribution, metabolism, excretion, and toxicity) properties. In this study, we advanced a novel deep learning architecture, termed FP-GNN, which combined and simultaneously learned information from molecular graphs and fingerprints. To evaluate the FP-GNN model, we conducted experiments on 13 public datasets, an unbiased LIT-PCBA dataset, and 14 phenotypic screening datasets for breast cell lines. Extensive evaluation results showed that compared to advanced deep learning and conventional machine learning algorithms, the FP-GNN algorithm achieved state-of-the-art performance on these datasets. In addition, we analyzed the influence of different molecular fingerprints, and the effects of molecular graphs and molecular fingerprints on the performance of the FP-GNN model. Analysis of the anti-noise ability and interpretation ability also indicated that FP-GNN was competitive in real-world situations.

</p>
</details>

<details><summary><b>Learning Regionally Decentralized AC Optimal Power Flows with ADMM</b>
<a href="https://arxiv.org/abs/2205.03787">arxiv:2205.03787</a>
&#x1F4C8; 4 <br>
<p>Terrence W. K. Mak, Minas Chatzos, Mathieu Tanneau, Pascal Van Hentenryck</p></summary>
<p>

**Abstract:** One potential future for the next generation of smart grids is the use of decentralized optimization algorithms and secured communications for coordinating renewable generation (e.g., wind/solar), dispatchable devices (e.g., coal/gas/nuclear generations), demand response, battery & storage facilities, and topology optimization. The Alternating Direction Method of Multipliers (ADMM) has been widely used in the community to address such decentralized optimization problems and, in particular, the AC Optimal Power Flow (AC-OPF). This paper studies how machine learning may help in speeding up the convergence of ADMM for solving AC-OPF. It proposes a novel decentralized machine-learning approach, namely ML-ADMM, where each agent uses deep learning to learn the consensus parameters on the coupling branches. The paper also explores the idea of learning only from ADMM runs that exhibit high-quality convergence properties, and proposes filtering mechanisms to select these runs. Experimental results on test cases based on the French system demonstrate the potential of the approach in speeding up the convergence of ADMM significantly.

</p>
</details>

<details><summary><b>Row-wise Accelerator for Vision Transformer</b>
<a href="https://arxiv.org/abs/2205.03998">arxiv:2205.03998</a>
&#x1F4C8; 3 <br>
<p>Hong-Yi Wang, Tian-Sheuan Chang</p></summary>
<p>

**Abstract:** Following the success of the natural language processing, the transformer for vision applications has attracted significant attention in recent years due to its excellent performance. However, existing deep learning hardware accelerators for vision cannot execute this structure efficiently due to significant model architecture differences. As a result, this paper proposes the hardware accelerator for vision transformers with row-wise scheduling, which decomposes major operations in vision transformers as a single dot product primitive for a unified and efficient execution. Furthermore, by sharing weights in columns, we can reuse the data and reduce the usage of memory. The implementation with TSMC 40nm CMOS technology only requires 262K gate count and 149KB SRAM buffer for 403.2 GOPS throughput at 600MHz clock frequency.

</p>
</details>

<details><summary><b>Hardware-Robust In-RRAM-Computing for Object Detection</b>
<a href="https://arxiv.org/abs/2205.03996">arxiv:2205.03996</a>
&#x1F4C8; 3 <br>
<p>Yu-Hsiang Chiang, Cheng En Ni, Yun Sung, Tuo-Hung Hou, Tian-Sheuan Chang, Shyh Jye Jou</p></summary>
<p>

**Abstract:** In-memory computing is becoming a popular architecture for deep-learning hardware accelerators recently due to its highly parallel computing, low power, and low area cost. However, in-RRAM computing (IRC) suffered from large device variation and numerous nonideal effects in hardware. Although previous approaches including these effects in model training successfully improved variation tolerance, they only considered part of the nonideal effects and relatively simple classification tasks. This paper proposes a joint hardware and software optimization strategy to design a hardware-robust IRC macro for object detection. We lower the cell current by using a low word-line voltage to enable a complete convolution calculation in one operation that minimizes the impact of nonlinear addition. We also implement ternary weight mapping and remove batch normalization for better tolerance against device variation, sense amplifier variation, and IR drop problem. An extra bias is included to overcome the limitation of the current sensing range. The proposed approach has been successfully applied to a complex object detection task with only 3.85\% mAP drop, whereas a naive design suffers catastrophic failure under these nonideal effects.

</p>
</details>

<details><summary><b>Methodology to Create Analysis-Naive Holdout Records as well as Train and Test Records for Machine Learning Analyses in Healthcare</b>
<a href="https://arxiv.org/abs/2205.03987">arxiv:2205.03987</a>
&#x1F4C8; 3 <br>
<p>Michele Bennett, Mehdi Nekouei, Armand Prieditis Rajesh Mehta, Ewa Kleczyk, Karin Hayes</p></summary>
<p>

**Abstract:** It is common for researchers to holdout data from a study pool to be used for external validation as well as for future research, and the same desire is true to those using machine learning modeling research. For this discussion, the purpose of the holdout sample it is preserve data for research studies that will be analysis-naive and randomly selected from the full dataset. Analysis-naive are records that are not used for testing or training machine learning (ML) models and records that do not participate in any aspect of the current machine learning study. The methodology suggested for creating holdouts is a modification of k-fold cross validation, which takes into account randomization and efficiently allows a three-way split (holdout, test and training) as part of the method without forcing. The paper also provides a working example using set of automated functions in Python and some scenarios for applicability in healthcare.

</p>
</details>

<details><summary><b>SoftPool++: An Encoder-Decoder Network for Point Cloud Completion</b>
<a href="https://arxiv.org/abs/2205.03899">arxiv:2205.03899</a>
&#x1F4C8; 3 <br>
<p>Yida Wang, David Joseph Tan, Nassir Navab, Federico Tombari</p></summary>
<p>

**Abstract:** We propose a novel convolutional operator for the task of point cloud completion. One striking characteristic of our approach is that, conversely to related work it does not require any max-pooling or voxelization operation. Instead, the proposed operator used to learn the point cloud embedding in the encoder extracts permutation-invariant features from the point cloud via a soft-pooling of feature activations, which are able to preserve fine-grained geometric details. These features are then passed on to a decoder architecture. Due to the compression in the encoder, a typical limitation of this type of architectures is that they tend to lose parts of the input shape structure. We propose to overcome this limitation by using skip connections specifically devised for point clouds, where links between corresponding layers in the encoder and the decoder are established. As part of these connections, we introduce a transformation matrix that projects the features from the encoder to the decoder and vice-versa. The quantitative and qualitative results on the task of object completion from partial scans on the ShapeNet dataset show that incorporating our approach achieves state-of-the-art performance in shape completion both at low and high resolutions.

</p>
</details>

<details><summary><b>WKGM: Weight-K-space Generative Model for Parallel Imaging Reconstruction</b>
<a href="https://arxiv.org/abs/2205.03883">arxiv:2205.03883</a>
&#x1F4C8; 3 <br>
<p>Zongjiang Tu, Die Liu, Xiaoqing Wang, Chen Jiang, Minghui Zhang, Qiegen Liu, Dong Liang</p></summary>
<p>

**Abstract:** Parallel Imaging (PI) is one of the most im-portant and successful developments in accelerating magnetic resonance imaging (MRI). Recently deep learning PI has emerged as an effective technique to accelerate MRI. Nevertheless, most approaches have so far been based image domain. In this work, we propose to explore the k-space domain via robust generative modeling for flexible PI reconstruction, coined weight-k-space generative model (WKGM). Specifically, WKGM is a generalized k-space domain model, where the k-space weighting technology and high-dimensional space strategy are efficiently incorporated for score-based generative model training, resulting in good and robust reconstruction. In addition, WKGM is flexible and thus can synergistically combine various traditional k-space PI models, generating learning-based priors to produce high-fidelity reconstructions. Experimental results on datasets with varying sampling patterns and acceleration factors demonstrate that WKGM can attain state-of-the-art reconstruction results under the well-learned k-space generative prior.

</p>
</details>

<details><summary><b>Zero and R2D2: A Large-scale Chinese Cross-modal Benchmark and A Vision-Language Framework</b>
<a href="https://arxiv.org/abs/2205.03860">arxiv:2205.03860</a>
&#x1F4C8; 3 <br>
<p>Chunyu Xie, Heng Cai, Jianfei Song, Jincheng Li, Fanjing Kong, Xiaoyu Wu, Henrique Morimitsu, Lin Yao, Dexin Wang, Dawei Leng, Xiangyang Ji, Yafeng Deng</p></summary>
<p>

**Abstract:** Vision-language pre-training (VLP) relying on large-scale pre-training datasets has shown premier performance on various downstream tasks. In this sense, a complete and fair benchmark (i.e., including large-scale pre-training datasets and a variety of downstream datasets) is essential for VLP. But how to construct such a benchmark in Chinese remains a critical problem. To this end, we develop a large-scale Chinese cross-modal benchmark called Zero for AI researchers to fairly compare VLP models. We release two pre-training datasets and five fine-tuning datasets for downstream tasks. Furthermore, we propose a novel pre-training framework of pre-Ranking + Ranking for cross-modal learning. Specifically, we apply global contrastive pre-ranking to learn the individual representations of images and Chinese texts, respectively. We then fuse the representations in a fine-grained ranking manner via an image-text cross encoder and a text-image cross encoder. To further enhance the capability of the model, we propose a two-way distillation strategy consisting of target-guided Distillation and feature-guided Distillation. For simplicity, we call our model R2D2. We achieve state-of-the-art performance on four public cross-modal datasets and our five downstream datasets. The datasets, models and codes will be made available.

</p>
</details>

<details><summary><b>Some performance considerations when using multi-armed bandit algorithms in the presence of missing data</b>
<a href="https://arxiv.org/abs/2205.03820">arxiv:2205.03820</a>
&#x1F4C8; 3 <br>
<p>Xijin Chen, Kim May Lee, Sofia S. Villar, David S. Robertson</p></summary>
<p>

**Abstract:** When using multi-armed bandit algorithms, the potential impact of missing data is often overlooked. In practice, the simplest approach is to ignore missing outcomes and continue to sample following the bandit algorithm. We investigate the impact of missing data on several bandit algorithms via a simulation study assuming the rewards are missing at random. We focus on two-armed bandit algorithms with binary outcomes in the context of patient allocation for clinical trials with relatively small sample sizes. However, our results can apply to other applications of bandit algorithms where missing data is expected to occur. We assess the resulting operating characteristics, including the expected reward (i.e., allocation results). Different probabilities of missingness in both arms are considered. The key finding of our work is that when using the simplest strategy of ignoring missing data, the corresponding impact on the performance of multi-armed bandit strategies varies according to their way of balancing the exploration-exploitation trade-off. Algorithms that are geared towards exploration continue to assign samples to the arm with more missing responses, and this arm is perceived as the superior arm by the algorithm. By contrast, algorithms that are geared towards exploitation would do the opposite and not assign samples to the arms with more missing responses. Furthermore, for algorithms focusing more on exploration, we illustrate that the problem of missing responses can be alleviated using a simple mean imputation approach.

</p>
</details>

<details><summary><b>Simultaneous Double Q-learning with Conservative Advantage Learning for Actor-Critic Methods</b>
<a href="https://arxiv.org/abs/2205.03819">arxiv:2205.03819</a>
&#x1F4C8; 3 <br>
<p>Qing Li, Wengang Zhou, Zhenbo Lu, Houqiang Li</p></summary>
<p>

**Abstract:** Actor-critic Reinforcement Learning (RL) algorithms have achieved impressive performance in continuous control tasks. However, they still suffer two nontrivial obstacles, i.e., low sample efficiency and overestimation bias. To this end, we propose Simultaneous Double Q-learning with Conservative Advantage Learning (SDQ-CAL). Our SDQ-CAL boosts the Double Q-learning for off-policy actor-critic RL based on a modification of the Bellman optimality operator with Advantage Learning. Specifically, SDQ-CAL improves sample efficiency by modifying the reward to facilitate the distinction from experience between the optimal actions and the others. Besides, it mitigates the overestimation issue by updating a pair of critics simultaneously upon double estimators. Extensive experiments reveal that our algorithm realizes less biased value estimation and achieves state-of-the-art performance in a range of continuous control benchmark tasks. We release the source code of our method at: \url{https://github.com/LQNew/SDQ-CAL}.

</p>
</details>

<details><summary><b>PGADA: Perturbation-Guided Adversarial Alignment for Few-shot Learning Under the Support-Query Shift</b>
<a href="https://arxiv.org/abs/2205.03817">arxiv:2205.03817</a>
&#x1F4C8; 3 <br>
<p>Siyang Jiang, Wei Ding, Hsi-Wen Chen, Ming-Syan Chen</p></summary>
<p>

**Abstract:** Few-shot learning methods aim to embed the data to a low-dimensional embedding space and then classify the unseen query data to the seen support set. While these works assume that the support set and the query set lie in the same embedding space, a distribution shift usually occurs between the support set and the query set, i.e., the Support-Query Shift, in the real world. Though optimal transportation has shown convincing results in aligning different distributions, we find that the small perturbations in the images would significantly misguide the optimal transportation and thus degrade the model performance. To relieve the misalignment, we first propose a novel adversarial data augmentation method, namely Perturbation-Guided Adversarial Alignment (PGADA), which generates the hard examples in a self-supervised manner. In addition, we introduce Regularized Optimal Transportation to derive a smooth optimal transportation plan. Extensive experiments on three benchmark datasets manifest that our framework significantly outperforms the eleven state-of-the-art methods on three datasets.

</p>
</details>

<details><summary><b>Beyond Distributional Hypothesis: Let Language Models Learn Meaning-Text Correspondence</b>
<a href="https://arxiv.org/abs/2205.03815">arxiv:2205.03815</a>
&#x1F4C8; 3 <br>
<p>Myeongjun Jang, Frank Mtumbuka, Thomas Lukasiewicz</p></summary>
<p>

**Abstract:** The logical negation property (LNP), which implies generating different predictions for semantically opposite inputs, is an important property that a trustworthy language model must satisfy. However, much recent evidence shows that large-size pre-trained language models (PLMs) do not satisfy this property. In this paper, we perform experiments using probing tasks to assess PLM's LNP understanding. Unlike previous studies that only examined negation expressions, we expand the boundary of the investigation to lexical semantics. Through experiments, we observe that PLMs violate the LNP frequently. To alleviate the issue, we propose a novel intermediate training task, names meaning-matching, designed to directly learn a meaning-text correspondence, instead of relying on the distributional hypothesis. Through multiple experiments, we find that the task enables PLMs to learn lexical semantic information. Also, through fine-tuning experiments on 7 GLUE tasks, we confirm that it is a safe intermediate task that guarantees a similar or better performance of downstream tasks. Finally, we observe that our proposed approach outperforms our previous counterparts despite its time and resource efficiency.

</p>
</details>

<details><summary><b>Ensemble Classifier Design Tuned to Dataset Characteristics for Network Intrusion Detection</b>
<a href="https://arxiv.org/abs/2205.06177">arxiv:2205.06177</a>
&#x1F4C8; 2 <br>
<p>Zeinab Zoghi, Gursel Serpen</p></summary>
<p>

**Abstract:** Machine Learning-based supervised approaches require highly customized and fine-tuned methodologies to deliver outstanding performance. This paper presents a dataset-driven design and performance evaluation of a machine learning classifier for the network intrusion dataset UNSW-NB15. Analysis of the dataset suggests that it suffers from class representation imbalance and class overlap in the feature space. We employed ensemble methods using Balanced Bagging (BB), eXtreme Gradient Boosting (XGBoost), and Random Forest empowered by Hellinger Distance Decision Tree (RF-HDDT). BB and XGBoost are tuned to handle the imbalanced data, and Random Forest (RF) classifier is supplemented by the Hellinger metric to address the imbalance issue. Two new algorithms are proposed to address the class overlap issue in the dataset. These two algorithms are leveraged to help improve the performance of the testing dataset by modifying the final classification decision made by three base classifiers as part of the ensemble classifier which employs a majority vote combiner. The proposed design is evaluated for both binary and multi-category classification. Comparing the proposed model to those reported on the same dataset in the literature demonstrate that the proposed model outperforms others by a significant margin for both binary and multi-category classification cases.

</p>
</details>

<details><summary><b>Accelerated functional brain aging in major depressive disorder: evidence from a large scale fMRI analysis of Chinese participants</b>
<a href="https://arxiv.org/abs/2205.04871">arxiv:2205.04871</a>
&#x1F4C8; 2 <br>
<p>Yunsong Luo, Wenyu Chen, Jiang Qiu, Tao Jia</p></summary>
<p>

**Abstract:** Major depressive disorder (MDD) is one of the most common mental health conditions that has been intensively investigated for its association with brain atrophy and mortality. Recent studies reveal that the deviation between the predicted and the chronological age can be a marker of accelerated brain aging to characterize MDD. However, current conclusions are usually drawn based on structural MRI information collected from Caucasian participants. The universality of this biomarker needs to be further validated by subjects with different ethnic/racial backgrounds and by different types of data. Here we make use of the REST-meta-MDD, a large scale resting-state fMRI dataset collected from multiple cohort participants in China. We develop a stacking machine learning model based on 1101 healthy controls, which estimates a subject's chronological age from fMRI with promising accuracy. The trained model is then applied to 1276 MDD patients from 24 sites. We observe that MDD patients exhibit a $+4.43$ years ($\text{$p$} < 0.0001$, $\text{Cohen's $d$} = 0.35$, $\text{95\% CI}:1.86 - 3.91$) higher brain-predicted age difference (brain-PAD) compared to controls. In the MDD subgroup, we observe a statistically significant $+2.09$ years ($\text{$p$} < 0.05$, $\text{Cohen's $d$} = 0.134483$) brain-PAD in antidepressant users compared to medication-free patients. The statistical relationship observed is further checked by three different machine learning algorithms. The positive brain-PAD observed in participants in China confirms the presence of accelerated brain aging in MDD patients. The utilization of functional brain connectivity for age estimation verifies existing findings from a new dimension.

</p>
</details>

<details><summary><b>Joint Study of Above Ground Biomass and Soil Organic Carbon for Total Carbon Estimation using Satellite Imagery in Scotland</b>
<a href="https://arxiv.org/abs/2205.04870">arxiv:2205.04870</a>
&#x1F4C8; 2 <br>
<p>Terrence Chan, Carla Arus Gomez, Anish Kothikar, Pedro Baiz</p></summary>
<p>

**Abstract:** Land Carbon verification has long been a challenge in the carbon credit market. Carbon verification methods currently available are expensive, and may generate low-quality credit. Scalable and accurate remote sensing techniques enable new approaches to monitor changes in Above Ground Biomass (AGB) and Soil Organic Carbon (SOC). The majority of state-of-the-art research employs remote sensing on AGB and SOC separately, although some studies indicate a positive correlation between the two. We intend to combine the two domains in our research to improve state-of-the-art total carbon estimation and to provide insight into the voluntary carbon trading market. We begin by establishing baseline model in our study area in Scotland, using state-of-the-art methodologies in the SOC and AGB domains. The effects of feature engineering techniques such as variance inflation factor and feature selection on machine learning models are then investigated. This is extended by combining predictor variables from the two domains. Finally, we leverage the possible correlation between AGB and SOC to establish a relationship between the two and propose novel models in an attempt outperform the state-of-the-art results. We compared three machine learning techniques, boosted regression tree, random forest, and xgboost. These techniques have been demonstrated to be the most effective in both domains.

</p>
</details>

<details><summary><b>CoCoA-MT: A Dataset and Benchmark for Contrastive Controlled MT with Application to Formality</b>
<a href="https://arxiv.org/abs/2205.04022">arxiv:2205.04022</a>
&#x1F4C8; 2 <br>
<p>Maria Nădejde, Anna Currey, Benjamin Hsu, Xing Niu, Marcello Federico, Georgiana Dinu</p></summary>
<p>

**Abstract:** The machine translation (MT) task is typically formulated as that of returning a single translation for an input segment. However, in many cases, multiple different translations are valid and the appropriate translation may depend on the intended target audience, characteristics of the speaker, or even the relationship between speakers. Specific problems arise when dealing with honorifics, particularly translating from English into languages with formality markers. For example, the sentence "Are you sure?" can be translated in German as "Sind Sie sich sicher?" (formal register) or "Bist du dir sicher?" (informal). Using wrong or inconsistent tone may be perceived as inappropriate or jarring for users of certain cultures and demographics. This work addresses the problem of learning to control target language attributes, in this case formality, from a small amount of labeled contrastive data. We introduce an annotated dataset (CoCoA-MT) and an associated evaluation metric for training and evaluating formality-controlled MT models for six diverse target languages. We show that we can train formality-controlled models by fine-tuning on labeled contrastive data, achieving high accuracy (82% in-domain and 73% out-of-domain) while maintaining overall quality.

</p>
</details>

<details><summary><b>Photo-to-Shape Material Transfer for Diverse Structures</b>
<a href="https://arxiv.org/abs/2205.04018">arxiv:2205.04018</a>
&#x1F4C8; 2 <br>
<p>Ruizhen Hu, Xiangyu Su, Xiangkai Chen, Oliver Van Kaick, Hui Huang</p></summary>
<p>

**Abstract:** We introduce a method for assigning photorealistic relightable materials to 3D shapes in an automatic manner. Our method takes as input a photo exemplar of a real object and a 3D object with segmentation, and uses the exemplar to guide the assignment of materials to the parts of the shape, so that the appearance of the resulting shape is as similar as possible to the exemplar. To accomplish this goal, our method combines an image translation neural network with a material assignment neural network. The image translation network translates the color from the exemplar to a projection of the 3D shape and the part segmentation from the projection to the exemplar. Then, the material prediction network assigns materials from a collection of realistic materials to the projected parts, based on the translated images and perceptual similarity of the materials. One key idea of our method is to use the translation network to establish a correspondence between the exemplar and shape projection, which allows us to transfer materials between objects with diverse structures. Another key idea of our method is to use the two pairs of (color, segmentation) images provided by the image translation to guide the material assignment, which enables us to ensure the consistency in the assignment. We demonstrate that our method allows us to assign materials to shapes so that their appearances better resemble the input exemplars, improving the quality of the results over the state-of-the-art method, and allowing us to automatically create thousands of shapes with high-quality photorealistic materials. Code and data for this paper are available at https://github.com/XiangyuSu611/TMT.

</p>
</details>

<details><summary><b>Data Augmentation with Paraphrase Generation and Entity Extraction for Multimodal Dialogue System</b>
<a href="https://arxiv.org/abs/2205.04006">arxiv:2205.04006</a>
&#x1F4C8; 2 <br>
<p>Eda Okur, Saurav Sahay, Lama Nachman</p></summary>
<p>

**Abstract:** Contextually aware intelligent agents are often required to understand the users and their surroundings in real-time. Our goal is to build Artificial Intelligence (AI) systems that can assist children in their learning process. Within such complex frameworks, Spoken Dialogue Systems (SDS) are crucial building blocks to handle efficient task-oriented communication with children in game-based learning settings. We are working towards a multimodal dialogue system for younger kids learning basic math concepts. Our focus is on improving the Natural Language Understanding (NLU) module of the task-oriented SDS pipeline with limited datasets. This work explores the potential benefits of data augmentation with paraphrase generation for the NLU models trained on small task-specific datasets. We also investigate the effects of extracting entities for conceivably further data expansion. We have shown that paraphrasing with model-in-the-loop (MITL) strategies using small seed data is a promising approach yielding improved performance results for the Intent Recognition task.

</p>
</details>

<details><summary><b>A Nonlocal Graph-PDE and Higher-Order Geometric Integration for Image Labeling</b>
<a href="https://arxiv.org/abs/2205.03991">arxiv:2205.03991</a>
&#x1F4C8; 2 <br>
<p>Dmitrij Sitenko, Bastian Boll, Christoph Schnörr</p></summary>
<p>

**Abstract:** This paper introduces a novel nonlocal partial difference equation (PDE) for labeling metric data on graphs. The PDE is derived as nonlocal reparametrization of the assignment flow approach that was introduced in \textit{J.~Math.~Imaging \& Vision} 58(2), 2017. Due to this parameterization, solving the PDE numerically is shown to be equivalent to computing the Riemannian gradient flow with respect to a nonconvex potential. We devise an entropy-regularized difference-of-convex-functions (DC) decomposition of this potential and show that the basic geometric Euler scheme for integrating the assignment flow is equivalent to solving the PDE by an established DC programming scheme. Moreover, the viewpoint of geometric integration reveals a basic way to exploit higher-order information of the vector field that drives the assignment flow, in order to devise a novel accelerated DC programming scheme. A detailed convergence analysis of both numerical schemes is provided and illustrated by numerical experiments.

</p>
</details>

<details><summary><b>A Structured Span Selector</b>
<a href="https://arxiv.org/abs/2205.03977">arxiv:2205.03977</a>
&#x1F4C8; 2 <br>
<p>Tianyu Liu, Yuchen Eleanor Jiang, Ryan Cotterell, Mrinmaya Sachan</p></summary>
<p>

**Abstract:** Many natural language processing tasks, e.g., coreference resolution and semantic role labeling, require selecting text spans and making decisions about them. A typical approach to such tasks is to score all possible spans and greedily select spans for task-specific downstream processing. This approach, however, does not incorporate any inductive bias about what sort of spans ought to be selected, e.g., that selected spans tend to be syntactic constituents. In this paper, we propose a novel grammar-based structured span selection model which learns to make use of the partial span-level annotation provided for such problems. Compared to previous approaches, our approach gets rid of the heuristic greedy span selection scheme, allowing us to model the downstream task on an optimal set of spans. We evaluate our model on two popular span prediction tasks: coreference resolution and semantic role labeling; and show improvements on both.

</p>
</details>

<details><summary><b>SELF-CARE: Selective Fusion with Context-Aware Low-Power Edge Computing for Stress Detection</b>
<a href="https://arxiv.org/abs/2205.03974">arxiv:2205.03974</a>
&#x1F4C8; 2 <br>
<p>Nafiul Rashid, Trier Mortlock, Mohammad Abdullah Al Faruque</p></summary>
<p>

**Abstract:** Detecting human stress levels and emotional states with physiological body-worn sensors is a complex task, but one with many health-related benefits. Robustness to sensor measurement noise and energy efficiency of low-power devices remain key challenges in stress detection. We propose SELFCARE, a fully wrist-based method for stress detection that employs context-aware selective sensor fusion that dynamically adapts based on data from the sensors. Our method uses motion to determine the context of the system and learns to adjust the fused sensors accordingly, improving performance while maintaining energy efficiency. SELF-CARE obtains state-of-the-art performance across the publicly available WESAD dataset, achieving 86.34% and 94.12% accuracy for the 3-class and 2-class classification problems, respectively. Evaluation on real hardware shows that our approach achieves up to 2.2x (3-class) and 2.7x (2-class) energy efficiency compared to traditional sensor fusion.

</p>
</details>

<details><summary><b>Private Eye: On the Limits of Textual Screen Peeking via Eyeglass Reflections in Video Conferencing</b>
<a href="https://arxiv.org/abs/2205.03971">arxiv:2205.03971</a>
&#x1F4C8; 2 <br>
<p>Yan Long, Chen Yan, Shivan Prasad, Wenyuan Xu, Kevin Fu</p></summary>
<p>

**Abstract:** Personal video conferencing has become the new norm after COVID-19 caused a seismic shift from in-person meetings and phone calls to video conferencing for daily communications and sensitive business. Video leaks participants' on-screen information because eyeglasses and other reflective objects unwittingly expose partial screen contents. Using mathematical modeling and human subjects experiments, this research explores the extent to which emerging webcams might leak recognizable textual information gleamed from eyeglass reflections captured by webcams. The primary goal of our work is to measure, compute, and predict the factors, limits, and thresholds of recognizability as webcam technology evolves in the future. Our work explores and characterizes the viable threat models based on optical attacks using multi-frame super resolution techniques on sequences of video frames. Our experimental results and models show it is possible to reconstruct and recognize on-screen text with a height as small as 10 mm with a 720p webcam. We further apply this threat model to web textual content with varying attacker capabilities to find thresholds at which text becomes recognizable. Our user study with 20 participants suggests present-day 720p webcams are sufficient for adversaries to reconstruct textual content on big-font websites. Our models further show that the evolution toward 4K cameras will tip the threshold of text leakage to reconstruction of most header texts on popular websites. Our research proposes near-term mitigations, and justifies the importance of following the principle of least privilege for long-term defense against this attack. For privacy-sensitive scenarios, it's further recommended to develop technologies that blur all objects by default, then only unblur what is absolutely necessary to facilitate natural-looking conversations.

</p>
</details>

<details><summary><b>Network Traffic Anomaly Detection Method Based on Multi scale Residual Feature</b>
<a href="https://arxiv.org/abs/2205.03907">arxiv:2205.03907</a>
&#x1F4C8; 2 <br>
<p>Xueyuan Duan, Yu Fu, Kun Wang</p></summary>
<p>

**Abstract:** To address the problem that traditional network traffic anomaly detection algorithms do not suffi-ciently mine potential features in long time domain, an anomaly detection method based on mul-ti-scale residual features of network traffic is proposed. The original traffic is divided into subse-quences of different time spans using sliding windows, and each subsequence is decomposed and reconstructed into data sequences of different levels using wavelet transform technique; the stacked autoencoder (SAE) constructs similar feature space using normal network traffic, and gen-erates reconstructed error vector using the difference between reconstructed samples and input samples in the similar feature space; the multi-path residual group is used to learn reconstructed error The traffic classification is completed by a lightweight classifier. The experimental results show that the detection performance of the proposed method for anomalous network traffic is sig-nificantly improved compared with traditional methods; it confirms that the longer time span and more S transformation scales have positive effects on discovering potential diversity information in the original network traffic.

</p>
</details>

<details><summary><b>VPN: Verification of Poisoning in Neural Networks</b>
<a href="https://arxiv.org/abs/2205.03894">arxiv:2205.03894</a>
&#x1F4C8; 2 <br>
<p>Youcheng Sun, Muhammad Usman, Divya Gopinath, Corina S. Păsăreanu</p></summary>
<p>

**Abstract:** Neural networks are successfully used in a variety of applications, many of them having safety and security concerns. As a result researchers have proposed formal verification techniques for verifying neural network properties. While previous efforts have mainly focused on checking local robustness in neural networks, we instead study another neural network security issue, namely data poisoning. In this case an attacker inserts a trigger into a subset of the training data, in such a way that at test time, this trigger in an input causes the trained model to misclassify to some target class. We show how to formulate the check for data poisoning as a property that can be checked with off-the-shelf verification tools, such as Marabou and nneum, where counterexamples of failed checks constitute the triggers. We further show that the discovered triggers are `transferable' from a small model to a larger, better-trained model, allowing us to analyze state-of-the art performant models trained for image classification tasks.

</p>
</details>

<details><summary><b>Assigning Species Information to Corresponding Genes by a Sequence Labeling Framework</b>
<a href="https://arxiv.org/abs/2205.03853">arxiv:2205.03853</a>
&#x1F4C8; 2 <br>
<p>Ling Luo, Chih-Hsuan Wei, Po-Ting Lai, Qingyu Chen, Rezarta Islamaj Doğan, Zhiyong Lu</p></summary>
<p>

**Abstract:** The automatic assignment of species information to the corresponding genes in a research article is a critically important step in the gene normalization task, whereby a gene mention is normalized and linked to a database record or identifier by a text-mining algorithm. Existing methods typically rely on heuristic rules based on gene and species co-occurrence in the article, but their accuracy is suboptimal. We therefore developed a high-performance method, using a novel deep learning-based framework, to classify whether there is a relation between a gene and a species. Instead of the traditional binary classification framework in which all possible pairs of genes and species in the same article are evaluated, we treat the problem as a sequence-labeling task such that only a fraction of the pairs needs to be considered. Our benchmarking results show that our approach obtains significantly higher performance compared to that of the rule-based baseline method for the species assignment task (from 65.8% to 81.3% in accuracy). The source code and data for species assignment are freely available at https://github.com/ncbi/SpeciesAssignment.

</p>
</details>

<details><summary><b>Fast and Structured Block-Term Tensor Decomposition For Hyperspectral Unmixing</b>
<a href="https://arxiv.org/abs/2205.03798">arxiv:2205.03798</a>
&#x1F4C8; 2 <br>
<p>Meng Ding, Xiao Fu, Xi-Le Zhao</p></summary>
<p>

**Abstract:** The block-term tensor decomposition model with multilinear rank-$(L_r,L_r,1)$ terms (or, the "LL1 tensor decomposition" in short) offers a valuable alternative for hyperspectral unmixing (HU) under the linear mixture model. Particularly, the LL1 decomposition ensures the endmember/abundance identifiability in scenarios where such guarantees are not supported by the classic matrix factorization (MF) approaches. However, existing LL1-based HU algorithms use a three-factor parameterization of the tensor (i.e., the hyperspectral image cube), which leads to a number of challenges including high per-iteration complexity, slow convergence, and difficulties in incorporating structural prior information. This work puts forth an LL1 tensor decomposition-based HU algorithm that uses a constrained two-factor re-parameterization of the tensor data. As a consequence, a two-block alternating gradient projection (GP)-based LL1 algorithm is proposed for HU. With carefully designed projection solvers, the GP algorithm enjoys a relatively low per-iteration complexity. Like in MF-based HU, the factors under our parameterization correspond to the endmembers and abundances. Thus, the proposed framework is natural to incorporate physics-motivated priors that arise in HU. The proposed algorithm often attains orders-of-magnitude speedup and substantial HU performance gains compared to the existing three-factor parameterization-based HU algorithms.

</p>
</details>

<details><summary><b>Pervasive Machine Learning for Smart Radio Environments Enabled by Reconfigurable Intelligent Surfaces</b>
<a href="https://arxiv.org/abs/2205.03793">arxiv:2205.03793</a>
&#x1F4C8; 2 <br>
<p>George C. Alexandropoulos, Kyriakos Stylianopoulos, Chongwen Huang, Chau Yuen, Mehdi Bennis, Mérouane Debbah</p></summary>
<p>

**Abstract:** The emerging technology of Reconfigurable Intelligent Surfaces (RISs) is provisioned as an enabler of smart wireless environments, offering a highly scalable, low-cost, hardware-efficient, and almost energy-neutral solution for dynamic control of the propagation of electromagnetic signals over the wireless medium, ultimately providing increased environmental intelligence for diverse operation objectives. One of the major challenges with the envisioned dense deployment of RISs in such reconfigurable radio environments is the efficient configuration of multiple metasurfaces with limited, or even the absence of, computing hardware. In this paper, we consider multi-user and multi-RIS-empowered wireless systems, and present a thorough survey of the online machine learning approaches for the orchestration of their various tunable components. Focusing on the sum-rate maximization as a representative design objective, we present a comprehensive problem formulation based on Deep Reinforcement Learning (DRL). We detail the correspondences among the parameters of the wireless system and the DRL terminology, and devise generic algorithmic steps for the artificial neural network training and deployment, while discussing their implementation details. Further practical considerations for multi-RIS-empowered wireless communications in the sixth Generation (6G) era are presented along with some key open research challenges. Differently from the DRL-based status quo, we leverage the independence between the configuration of the system design parameters and the future states of the wireless environment, and present efficient multi-armed bandits approaches, whose resulting sum-rate performances are numerically shown to outperform random configurations, while being sufficiently close to the conventional Deep Q-Network (DQN) algorithm, but with lower implementation complexity.

</p>
</details>

<details><summary><b>Univariate and Multivariate LSTM Model for Short-Term Stock Market Prediction</b>
<a href="https://arxiv.org/abs/2205.06673">arxiv:2205.06673</a>
&#x1F4C8; 1 <br>
<p>Vishal Kuber, Divakar Yadav, Arun Kr Yadav</p></summary>
<p>

**Abstract:** Designing robust and accurate prediction models has been a viable research area since a long time. While proponents of a well-functioning market predictors believe that it is difficult to accurately predict market prices but many scholars disagree. Robust and accurate prediction systems will not only be helpful to the businesses but also to the individuals in making their financial investments. This paper presents an LSTM model with two different input approaches for predicting the short-term stock prices of two Indian companies, Reliance Industries and Infosys Ltd. Ten years of historic data (2012-2021) is taken from the yahoo finance website to carry out analysis of proposed approaches. In the first approach, closing prices of two selected companies are directly applied on univariate LSTM model. For the approach second, technical indicators values are calculated from the closing prices and then collectively applied on Multivariate LSTM model. Short term market behaviour for upcoming days is evaluated. Experimental outcomes revel that approach one is useful to determine the future trend but multivariate LSTM model with technical indicators found to be useful in accurately predicting the future price behaviours.

</p>
</details>

<details><summary><b>A Real Time Super Resolution Accelerator with Tilted Layer Fusion</b>
<a href="https://arxiv.org/abs/2205.03997">arxiv:2205.03997</a>
&#x1F4C8; 1 <br>
<p>An-Jung Huang, Kai-Chieh Hsu, Tian-Sheuan Chang</p></summary>
<p>

**Abstract:** Deep learning based superresolution achieves high-quality results, but its heavy computational workload, large buffer, and high external memory bandwidth inhibit its usage in mobile devices. To solve the above issues, this paper proposes a real-time hardware accelerator with the tilted layer fusion method that reduces the external DRAM bandwidth by 92\% and just needs 102KB on-chip memory. The design implemented with a 40nm CMOS process achieves 1920x1080@60fps throughput with 544.3K gate count when running at 600MHz; it has higher throughput and lower area cost than previous designs.

</p>
</details>

<details><summary><b>Dynamic categories, dynamic operads: From deep learning to prediction markets</b>
<a href="https://arxiv.org/abs/2205.03906">arxiv:2205.03906</a>
&#x1F4C8; 1 <br>
<p>Brandon Shapiro, David I. Spivak</p></summary>
<p>

**Abstract:** Natural organized systems adapt to internal and external pressures and this seems to happens all the way down. Wanting to think clearly about this idea motivates our paper, and so the idea is elaborated extensively in the introduction, which should be broadly accessible to a philosophically-interested audience.
  In the remaining sections, we turn to more compressed category theory. We define the monoidal double category $\mathbf{Org}$ of dynamic organizations, we provide definitions of $\mathbf{Org}$-enriched, or "dynamic", categorical structures -- e.g. dynamic categories, operads, and monoidal categories -- and we show how they instantiate the motivating philosophical ideas. We give two examples of dynamic categorical structures: prediction markets as a dynamic operad and deep learning as a dynamic monoidal category.

</p>
</details>

<details><summary><b>Demo: Real-Time Semantic Communications with a Vision Transformer</b>
<a href="https://arxiv.org/abs/2205.03886">arxiv:2205.03886</a>
&#x1F4C8; 1 <br>
<p>Hanju Yoo, Taehun Jung, Linglong Dai, Songkuk Kim, Chan-Byoung Chae</p></summary>
<p>

**Abstract:** Semantic communications are expected to enable the more effective delivery of meaning rather than a precise transfer of symbols. In this paper, we propose an end-to-end deep neural network-based architecture for image transmission and demonstrate its feasibility in a real-time wireless channel by implementing a prototype based on a field-programmable gate array (FPGA). We demonstrate that this system outperforms the traditional 256-quadrature amplitude modulation system in the low signal-to-noise ratio regime with the popular CIFAR-10 dataset. To the best of our knowledge, this is the first work that implements and investigates real-time semantic communications with a vision transformer.

</p>
</details>

<details><summary><b>SeqNet: An Efficient Neural Network for Automatic Malware Detection</b>
<a href="https://arxiv.org/abs/2205.03850">arxiv:2205.03850</a>
&#x1F4C8; 1 <br>
<p>Jiawei Xu, Wenxuan Fu, Haoyu Bu, Zhi Wang, Lingyun Ying</p></summary>
<p>

**Abstract:** Malware continues to evolve rapidly, and more than 450,000 new samples are captured every day, which makes manual malware analysis impractical. However, existing deep learning detection models need manual feature engineering or require high computational overhead for long training processes, which might be laborious to select feature space and difficult to retrain for mitigating model aging. Therefore, a crucial requirement for a detector is to realize automatic and efficient detection. In this paper, we propose a lightweight malware detection model called SeqNet which could be trained at high speed with low memory required on the raw binaries. By avoiding contextual confusion and reducing semantic loss, SeqNet maintains the detection accuracy when reducing the number of parameters to only 136K. We demonstrate the effectiveness of our methods and the low training cost requirement of SeqNet in our experiments. Besides, we make our datasets and codes public to stimulate further academic research.

</p>
</details>

<details><summary><b>Over-the-Air Federated Multi-Task Learning via Model Sparsification and Turbo Compressed Sensing</b>
<a href="https://arxiv.org/abs/2205.03810">arxiv:2205.03810</a>
&#x1F4C8; 1 <br>
<p>Haoming Ma, Xiaojun Yuan, Zhi Ding, Dian Fan, Jun Fang</p></summary>
<p>

**Abstract:** To achieve communication-efficient federated multitask learning (FMTL), we propose an over-the-air FMTL (OAFMTL) framework, where multiple learning tasks deployed on edge devices share a non-orthogonal fading channel under the coordination of an edge server (ES). In OA-FMTL, the local updates of edge devices are sparsified, compressed, and then sent over the uplink channel in a superimposed fashion. The ES employs over-the-air computation in the presence of intertask interference. More specifically, the model aggregations of all the tasks are reconstructed from the channel observations concurrently, based on a modified version of the turbo compressed sensing (Turbo-CS) algorithm (named as M-Turbo-CS). We analyze the performance of the proposed OA-FMTL framework together with the M-Turbo-CS algorithm. Furthermore, based on the analysis, we formulate a communication-learning optimization problem to improve the system performance by adjusting the power allocation among the tasks at the edge devices. Numerical simulations show that our proposed OAFMTL effectively suppresses the inter-task interference, and achieves a learning performance comparable to its counterpart with orthogonal multi-task transmission. It is also shown that the proposed inter-task power allocation optimization algorithm substantially reduces the overall communication overhead by appropriately adjusting the power allocation among the tasks.

</p>
</details>

<details><summary><b>MLSmellHound: A Context-Aware Code Analysis Tool</b>
<a href="https://arxiv.org/abs/2205.03790">arxiv:2205.03790</a>
&#x1F4C8; 1 <br>
<p>Jai Kannan, Scott Barnett, Luís Cruz, Anj Simmons, Akash Agarwal</p></summary>
<p>

**Abstract:** Meeting the rise of industry demand to incorporate machine learning (ML) components into software systems requires interdisciplinary teams contributing to a shared code base. To maintain consistency, reduce defects and ensure maintainability, developers use code analysis tools to aid them in identifying defects and maintaining standards. With the inclusion of machine learning, tools must account for the cultural differences within the teams which manifests as multiple programming languages, and conflicting definitions and objectives. Existing tools fail to identify these cultural differences and are geared towards software engineering which reduces their adoption in ML projects. In our approach we attempt to resolve this problem by exploring the use of context which includes i) purpose of the source code, ii) technical domain, iii) problem domain, iv) team norms, v) operational environment, and vi) development lifecycle stage to provide contextualised error reporting for code analysis. To demonstrate our approach, we adapt Pylint as an example and apply a set of contextual transformations to the linting results based on the domain of individual project files under analysis. This allows for contextualised and meaningful error reporting for the end-user.

</p>
</details>

<details><summary><b>ACM -- Attribute Conditioning for Abstractive Multi Document Summarization</b>
<a href="https://arxiv.org/abs/2205.03978">arxiv:2205.03978</a>
&#x1F4C8; 0 <br>
<p>Aiswarya Sankar, Ankit Chadha</p></summary>
<p>

**Abstract:** Abstractive multi document summarization has evolved as a task through the basic sequence to sequence approaches to transformer and graph based techniques. Each of these approaches has primarily focused on the issues of multi document information synthesis and attention based approaches to extract salient information. A challenge that arises with multi document summarization which is not prevalent in single document summarization is the need to effectively summarize multiple documents that might have conflicting polarity, sentiment or subjective information about a given topic. In this paper we propose ACM, attribute conditioned multi document summarization,a model that incorporates attribute conditioning modules in order to decouple conflicting information by conditioning for a certain attribute in the output summary. This approach shows strong gains in ROUGE score over baseline multi document summarization approaches and shows gains in fluency, informativeness and reduction in repetitiveness as shown through a human annotation analysis study.

</p>
</details>

<details><summary><b>Rebellion and Disobedience as Useful Tools in Human-Robot Interaction Research -- The Handheld Robotics Case</b>
<a href="https://arxiv.org/abs/2205.03968">arxiv:2205.03968</a>
&#x1F4C8; 0 <br>
<p>Walterio W. Mayol-Cuevas</p></summary>
<p>

**Abstract:** This position paper argues on the utility of rebellion and disobedience (RaD) in human-robot interaction (HRI). In general, we see two main opportunities in the use of controlled and well designed rebellion and disobedience: i) illuminate insight into the effectiveness of the collaboration (or lack of) and ii) prevent mistakes and correct user actions when in the user's own interest. Through the use of a close interaction modality, that of handheld robots, we discuss use cases for utility of rebellion and disobedience that can be applicable to other instances of HRI.

</p>
</details>


{% endraw %}
Prev: [2022.05.07]({{ '/2022/05/07/2022.05.07.html' | relative_url }})  Next: [2022.05.09]({{ '/2022/05/09/2022.05.09.html' | relative_url }})