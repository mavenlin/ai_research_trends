Prev: [2022.08.24]({{ '/2022/08/24/2022.08.24.html' | relative_url }})  Next: [2022.08.26]({{ '/2022/08/26/2022.08.26.html' | relative_url }})
{% raw %}
## Summary for 2022-08-25, created on 2022-09-04


<details><summary><b>DreamBooth: Fine Tuning Text-to-Image Diffusion Models for Subject-Driven Generation</b>
<a href="https://arxiv.org/abs/2208.12242">arxiv:2208.12242</a>
&#x1F4C8; 2780 <br>
<p>Nataniel Ruiz, Yuanzhen Li, Varun Jampani, Yael Pritch, Michael Rubinstein, Kfir Aberman</p></summary>
<p>

**Abstract:** Large text-to-image models achieved a remarkable leap in the evolution of AI, enabling high-quality and diverse synthesis of images from a given text prompt. However, these models lack the ability to mimic the appearance of subjects in a given reference set and synthesize novel renditions of them in different contexts. In this work, we present a new approach for "personalization" of text-to-image diffusion models (specializing them to users' needs). Given as input just a few images of a subject, we fine-tune a pretrained text-to-image model (Imagen, although our method is not limited to a specific model) such that it learns to bind a unique identifier with that specific subject. Once the subject is embedded in the output domain of the model, the unique identifier can then be used to synthesize fully-novel photorealistic images of the subject contextualized in different scenes. By leveraging the semantic prior embedded in the model with a new autogenous class-specific prior preservation loss, our technique enables synthesizing the subject in diverse scenes, poses, views, and lighting conditions that do not appear in the reference images. We apply our technique to several previously-unassailable tasks, including subject recontextualization, text-guided view synthesis, appearance modification, and artistic rendering (all while preserving the subject's key features). Project page: https://dreambooth.github.io/

</p>
</details>

<details><summary><b>Understanding Diffusion Models: A Unified Perspective</b>
<a href="https://arxiv.org/abs/2208.11970">arxiv:2208.11970</a>
&#x1F4C8; 553 <br>
<p>Calvin Luo</p></summary>
<p>

**Abstract:** Diffusion models have shown incredible capabilities as generative models; indeed, they power the current state-of-the-art models on text-conditioned image generation such as Imagen and DALL-E 2. In this work we review, demystify, and unify the understanding of diffusion models across both variational and score-based perspectives. We first derive Variational Diffusion Models (VDM) as a special case of a Markovian Hierarchical Variational Autoencoder, where three key assumptions enable tractable computation and scalable optimization of the ELBO. We then prove that optimizing a VDM boils down to learning a neural network to predict one of three potential objectives: the original source input from any arbitrary noisification of it, the original source noise from any arbitrarily noisified input, or the score function of a noisified input at any arbitrary noise level. We then dive deeper into what it means to learn the score function, and connect the variational perspective of a diffusion model explicitly with the Score-based Generative Modeling perspective through Tweedie's Formula. Lastly, we cover how to learn a conditional distribution using diffusion models via guidance.

</p>
</details>

<details><summary><b>MuLan: A Joint Embedding of Music Audio and Natural Language</b>
<a href="https://arxiv.org/abs/2208.12415">arxiv:2208.12415</a>
&#x1F4C8; 129 <br>
<p>Qingqing Huang, Aren Jansen, Joonseok Lee, Ravi Ganti, Judith Yue Li, Daniel P. W. Ellis</p></summary>
<p>

**Abstract:** Music tagging and content-based retrieval systems have traditionally been constructed using pre-defined ontologies covering a rigid set of music attributes or text queries. This paper presents MuLan: a first attempt at a new generation of acoustic models that link music audio directly to unconstrained natural language music descriptions. MuLan takes the form of a two-tower, joint audio-text embedding model trained using 44 million music recordings (370K hours) and weakly-associated, free-form text annotations. Through its compatibility with a wide range of music genres and text styles (including conventional music tags), the resulting audio-text representation subsumes existing ontologies while graduating to true zero-shot functionalities. We demonstrate the versatility of the MuLan embeddings with a range of experiments including transfer learning, zero-shot music tagging, language understanding in the music domain, and cross-modal retrieval applications.

</p>
</details>

<details><summary><b>Music Separation Enhancement with Generative Modeling</b>
<a href="https://arxiv.org/abs/2208.12387">arxiv:2208.12387</a>
&#x1F4C8; 124 <br>
<p>Noah Schaffer, Boaz Cogan, Ethan Manilow, Max Morrison, Prem Seetharaman, Bryan Pardo</p></summary>
<p>

**Abstract:** Despite phenomenal progress in recent years, state-of-the-art music separation systems produce source estimates with significant perceptual shortcomings, such as adding extraneous noise or removing harmonics. We propose a post-processing model (the Make it Sound Good (MSG) post-processor) to enhance the output of music source separation systems. We apply our post-processing model to state-of-the-art waveform-based and spectrogram-based music source separators, including a separator unseen by MSG during training. Our analysis of the errors produced by source separators shows that waveform models tend to introduce more high-frequency noise, while spectrogram models tend to lose transients and high frequency content. We introduce objective measures to quantify both kinds of errors and show MSG improves the source reconstruction of both kinds of errors. Crowdsourced subjective evaluations demonstrate that human listeners prefer source estimates of bass and drums that have been post-processed by MSG.

</p>
</details>

<details><summary><b>Decoding speech from non-invasive brain recordings</b>
<a href="https://arxiv.org/abs/2208.12266">arxiv:2208.12266</a>
&#x1F4C8; 111 <br>
<p>Alexandre Défossez, Charlotte Caucheteux, Jérémy Rapin, Ori Kabeli, Jean-Rémi King</p></summary>
<p>

**Abstract:** Decoding language from brain activity is a long-awaited goal in both healthcare and neuroscience. Major milestones have recently been reached thanks to intracranial devices: subject-specific pipelines trained on invasive brain responses to basic language tasks now start to efficiently decode interpretable features (e.g. letters, words, spectrograms). However, scaling this approach to natural speech and non-invasive brain recordings remains a major challenge. Here, we propose a single end-to-end architecture trained with contrastive learning across a large cohort of individuals to predict self-supervised representations of natural speech. We evaluate our model on four public datasets, encompassing 169 volunteers recorded with magneto- or electro-encephalography (M/EEG), while they listened to natural speech. The results show that our model can identify, from 3s of MEG signals, the corresponding speech segment with up to 72.5% top-10 accuracy out of 1,594 distinct segments (and 44% top-1 accuracy), and up to 19.1% out of 2,604 segments for EEG recordings -- hence allowing the decoding of phrases absent from the training set. Model comparison and ablation analyses show that these performances directly benefit from our original design choices, namely the use of (i) a contrastive objective, (ii) pretrained representations of speech and (iii) a common convolutional architecture simultaneously trained across several participants. Together, these results delineate a promising path to decode natural language processing in real time from non-invasive recordings of brain activity.

</p>
</details>

<details><summary><b>Supervised Dimensionality Reduction and Classification with Convolutional Autoencoders</b>
<a href="https://arxiv.org/abs/2208.12152">arxiv:2208.12152</a>
&#x1F4C8; 105 <br>
<p>Ioannis A. Nellas, Sotiris K. Tasoulis, Vassilis P. Plagianakos, Spiros V. Georgakopoulos</p></summary>
<p>

**Abstract:** The joint optimization of the reconstruction and classification error is a hard non convex problem, especially when a non linear mapping is utilized. In order to overcome this obstacle, a novel optimization strategy is proposed, in which a Convolutional Autoencoder for dimensionality reduction and a classifier composed by a Fully Connected Network, are combined to simultaneously produce supervised dimensionality reduction and predictions. It turned out that this methodology can also be greatly beneficial in enforcing explainability of deep learning architectures. Additionally, the resulting Latent Space, optimized for the classification task, can be utilized to improve traditional, interpretable classification algorithms. The experimental results, showed that the proposed methodology achieved competitive results against the state of the art deep learning methods, while being much more efficient in terms of parameter count. Finally, it was empirically justified that the proposed methodology introduces advanced explainability regarding, not only the data structure through the produced latent space, but also about the classification behaviour.

</p>
</details>

<details><summary><b>Anytime-Lidar: Deadline-aware 3D Object Detection</b>
<a href="https://arxiv.org/abs/2208.12181">arxiv:2208.12181</a>
&#x1F4C8; 62 <br>
<p>Ahmet Soyyigit, Shuochao Yao, Heechul Yun</p></summary>
<p>

**Abstract:** In this work, we present a novel scheduling framework enabling anytime perception for deep neural network (DNN) based 3D object detection pipelines. We focus on computationally expensive region proposal network (RPN) and per-category multi-head detector components, which are common in 3D object detection pipelines, and make them deadline-aware. We propose a scheduling algorithm, which intelligently selects the subset of the components to make effective time and accuracy trade-off on the fly. We minimize accuracy loss of skipping some of the neural network sub-components by projecting previously detected objects onto the current scene through estimations. We apply our approach to a state-of-art 3D object detection network, PointPillars, and evaluate its performance on Jetson Xavier AGX using nuScenes dataset. Compared to the baselines, our approach significantly improve the network's accuracy under various deadline constraints.

</p>
</details>

<details><summary><b>Compositional Active Inference II: Polynomial Dynamics. Approximate Inference Doctrines</b>
<a href="https://arxiv.org/abs/2208.12173">arxiv:2208.12173</a>
&#x1F4C8; 57 <br>
<p>Toby St. Clere Smithe</p></summary>
<p>

**Abstract:** We develop the compositional theory of active inference by introducing activity, functorially relating statistical games to the dynamical systems which play them, using the new notion of approximate inference doctrine. In order to exhibit such functors, we first develop the necessary theory of dynamical systems, using a generalization of the language of polynomial functors to supply compositional interfaces of the required types: with the resulting polynomially indexed categories of coalgebras, we construct monoidal bicategories of differential and dynamical ``hierarchical inference systems'', in which approximate inference doctrines have semantics. We then describe ``externally parameterized'' statistical games, and use them to construct two approximate inference doctrines found in the computational neuroscience literature, which we call the `Laplace' and the `Hebb-Laplace' doctrines: the former produces dynamical systems which optimize the posteriors of Gaussian models; and the latter produces systems which additionally optimize the parameters (or `weights') which determine their predictions.

</p>
</details>

<details><summary><b>On Reality and the Limits of Language Data</b>
<a href="https://arxiv.org/abs/2208.11981">arxiv:2208.11981</a>
&#x1F4C8; 41 <br>
<p>Nigel H. Collier, Fangyu Liu, Ehsan Shareghi</p></summary>
<p>

**Abstract:** Recent advances in neural network language models have shown that it is possible to derive expressive meaning representations by leveraging linguistic associations in large-scale natural language data. These potentially Gestalt representations have enabled state-of-the-art performance for many practical applications. It would appear that we are on a pathway to empirically deriving a robust and expressive computable semantics. A key question that arises is how far can language data alone enable computers to understand the necessary truth about the physical world? Attention to this question is warranted because our future interactions with intelligent machines depends on how well our techniques correctly represent and process the concepts (objects, properties, and processes) that humans commonly observe to be true. After reviewing existing protocols, the objective of this work is to explore this question using a novel and tightly controlled reasoning test and to highlight what models might learn directly from pure linguistic data.

</p>
</details>

<details><summary><b>Contrastive Audio-Language Learning for Music</b>
<a href="https://arxiv.org/abs/2208.12208">arxiv:2208.12208</a>
&#x1F4C8; 40 <br>
<p>Ilaria Manco, Emmanouil Benetos, Elio Quinton, György Fazekas</p></summary>
<p>

**Abstract:** As one of the most intuitive interfaces known to humans, natural language has the potential to mediate many tasks that involve human-computer interaction, especially in application-focused fields like Music Information Retrieval. In this work, we explore cross-modal learning in an attempt to bridge audio and language in the music domain. To this end, we propose MusCALL, a framework for Music Contrastive Audio-Language Learning. Our approach consists of a dual-encoder architecture that learns the alignment between pairs of music audio and descriptive sentences, producing multimodal embeddings that can be used for text-to-audio and audio-to-text retrieval out-of-the-box. Thanks to this property, MusCALL can be transferred to virtually any task that can be cast as text-based retrieval. Our experiments show that our method performs significantly better than the baselines at retrieving audio that matches a textual description and, conversely, text that matches an audio query. We also demonstrate that the multimodal alignment capability of our model can be successfully extended to the zero-shot transfer scenario for genre classification and auto-tagging on two public datasets.

</p>
</details>

<details><summary><b>Deep neural networks for fast acquisition of aortic 3D pressure and velocity flow fields</b>
<a href="https://arxiv.org/abs/2208.12156">arxiv:2208.12156</a>
&#x1F4C8; 20 <br>
<p>Endrit Pajaziti, Javier Montalt-Tordera, Claudio Capelli, Raphael Sivera, Emilie Sauvage, Silvia Schievano, Vivek Muthurangu</p></summary>
<p>

**Abstract:** Computational fluid dynamics (CFD) can be used to simulate vascular haemodynamics and analyse potential treatment options. CFD has shown to be beneficial in improving patient outcomes. However, the implementation of CFD for routine clinical use is yet to be realised. Barriers for CFD include high computational resources, specialist experience needed for designing simulation set-ups, and long processing times. The aim of this study was to explore the use of machine learning (ML) to replicate conventional aortic CFD with automatic and fast regression models. Data used to train/test the model comprised of 3,000 CFD simulations performed on synthetically generated 3D aortic shapes. These subjects were generated from a statistical shape model (SSM) built on real patient-specific aortas (N=67). Inference performed on 200 test shapes resulted in average errors of 6.01% +/-3.12 SD and 3.99% +/-0.93 SD for pressure and velocity, respectively. Our ML-based models performed CFD in ~0.075 seconds (4,000x faster than the solver). This study shows that results from conventional vascular CFD can be reproduced using ML at a much faster rate, in an automatic process, and with high accuracy.

</p>
</details>

<details><summary><b>Light-weight probing of unsupervised representations for Reinforcement Learning</b>
<a href="https://arxiv.org/abs/2208.12345">arxiv:2208.12345</a>
&#x1F4C8; 17 <br>
<p>Wancong Zhang, Anthony GX-Chen, Vlad Sobal, Yann LeCun, Nicolas Carion</p></summary>
<p>

**Abstract:** Unsupervised visual representation learning offers the opportunity to leverage large corpora of unlabeled trajectories to form useful visual representations, which can benefit the training of reinforcement learning (RL) algorithms. However, evaluating the fitness of such representations requires training RL algorithms which is computationally intensive and has high variance outcomes. To alleviate this issue, we design an evaluation protocol for unsupervised RL representations with lower variance and up to 600x lower computational cost. Inspired by the vision community, we propose two linear probing tasks: predicting the reward observed in a given state, and predicting the action of an expert in a given state. These two tasks are generally applicable to many RL domains, and we show through rigorous experimentation that they correlate strongly with the actual downstream control performance on the Atari100k Benchmark. This provides a better method for exploring the space of pretraining algorithms without the need of running RL evaluations for every setting. Leveraging this framework, we further improve existing self-supervised learning (SSL) recipes for RL, highlighting the importance of the forward model, the size of the visual backbone, and the precise formulation of the unsupervised objective.

</p>
</details>

<details><summary><b>Algorithmic Differentiation for Automatized Modelling of Machine Learned Force Fields</b>
<a href="https://arxiv.org/abs/2208.12104">arxiv:2208.12104</a>
&#x1F4C8; 14 <br>
<p>Niklas Frederik Schmitz, Klaus-Robert Müller, Stefan Chmiela</p></summary>
<p>

**Abstract:** Reconstructing force fields (FF) from atomistic simulation data is a challenge since accurate data can be highly expensive. Here, machine learning (ML) models can help to be data economic as they can be successfully constrained using the underlying symmetry and conservation laws of physics. However, so far, every descriptor newly proposed for an ML model has required a cumbersome and mathematically tedious remodeling. We therefore propose to use modern techniques from algorithmic differentiation within the ML modeling process -- effectively enabling the usage of novel descriptors or models fully automatically at an order of magnitude higher computational efficiency. This paradigmatic approach enables not only a versatile usage of novel representations, the efficient computation of larger systems -- all of high value to the FF community -- but also the simple inclusion of further physical knowledge such as higher-order information (e.g.~Hessians, more complex partial differential equations constraints etc.), even beyond the presented FF domain.

</p>
</details>

<details><summary><b>A Compact Pretraining Approach for Neural Language Models</b>
<a href="https://arxiv.org/abs/2208.12367">arxiv:2208.12367</a>
&#x1F4C8; 9 <br>
<p>Shahriar Golchin, Mihai Surdeanu, Nazgol Tavabi, Ata Kiapour</p></summary>
<p>

**Abstract:** Domain adaptation for large neural language models (NLMs) is coupled with massive amounts of unstructured data in the pretraining phase. In this study, however, we show that pretrained NLMs learn in-domain information more effectively and faster from a compact subset of the data that focuses on the key information in the domain. We construct these compact subsets from the unstructured data using a combination of abstractive summaries and extractive keywords. In particular, we rely on BART to generate abstractive summaries, and KeyBERT to extract keywords from these summaries (or the original unstructured text directly). We evaluate our approach using six different settings: three datasets combined with two distinct NLMs. Our results reveal that the task-specific classifiers trained on top of NLMs pretrained using our method outperform methods based on traditional pretraining, i.e., random masking on the entire data, as well as methods without pretraining. Further, we show that our strategy reduces pretraining time by up to five times compared to vanilla pretraining. The code for all of our experiments is publicly available at https://github.com/shahriargolchin/compact-pretraining.

</p>
</details>

<details><summary><b>JAXFit: Trust Region Method for Nonlinear Least-Squares Curve Fitting on the GPU</b>
<a href="https://arxiv.org/abs/2208.12187">arxiv:2208.12187</a>
&#x1F4C8; 9 <br>
<p>Lucas R. Hofer, Milan Krstajić, Robert P. Smith</p></summary>
<p>

**Abstract:** We implement a trust region method on the GPU for nonlinear least squares curve fitting problems using a new deep learning Python library called JAX. Our open source package, JAXFit, works for both unconstrained and constrained curve fitting problems and allows the fit functions to be defined in Python alone -- without any specialized knowledge of either the GPU or CUDA programming. Since JAXFit runs on the GPU, it is much faster than CPU based libraries and even other GPU based libraries, despite being very easy to use. Additionally, due to JAX's deep learning foundations, the Jacobian in JAXFit's trust region algorithm is calculated with automatic differentiation, rather than than using derivative approximations or requiring the user to define the fit function's partial derivatives.

</p>
</details>

<details><summary><b>Cross-Modality Gated Attention Fusion for Multimodal Sentiment Analysis</b>
<a href="https://arxiv.org/abs/2208.11893">arxiv:2208.11893</a>
&#x1F4C8; 9 <br>
<p>Ming Jiang, Shaoxiong Ji</p></summary>
<p>

**Abstract:** Multimodal sentiment analysis is an important research task to predict the sentiment score based on the different modality data from a specific opinion video. Many previous pieces of research have proved the significance of utilizing the shared and unique information across different modalities. However, the high-order combined signals from multimodal data would also help extract satisfied representations. In this paper, we propose CMGA, a Cross-Modality Gated Attention fusion model for MSA that tends to make adequate interaction across different modality pairs. CMGA also adds a forget gate to filter the noisy and redundant signals introduced in the interaction procedure. We experiment on two benchmark datasets in MSA, MOSI, and MOSEI, illustrating the performance of CMGA over several baseline models. We also conduct the ablation study to demonstrate the function of different components inside CMGA.

</p>
</details>

<details><summary><b>A CNN-LSTM-based hybrid deep learning approach to detect sentiment polarities on Monkeypox tweets</b>
<a href="https://arxiv.org/abs/2208.12019">arxiv:2208.12019</a>
&#x1F4C8; 7 <br>
<p>Krishna Kumar Mohbey, Gaurav Meena, Sunil Kumar, K Lokesh</p></summary>
<p>

**Abstract:** People have recently begun communicating their thoughts and viewpoints through user-generated multimedia material on social networking websites. This information can be images, text, videos, or audio. Recent years have seen a rise in the frequency of occurrence of this pattern. Twitter is one of the most extensively utilized social media sites, and it is also one of the finest locations to get a sense of how people feel about events that are linked to the Monkeypox sickness. This is because tweets on Twitter are shortened and often updated, both of which contribute to the platform's character. The fundamental objective of this study is to get a deeper comprehension of the diverse range of reactions people have in response to the presence of this condition. This study focuses on finding out what individuals think about monkeypox illnesses, which presents a hybrid technique based on CNN and LSTM. We have considered all three possible polarities of a user's tweet: positive, negative, and neutral. An architecture built on CNN and LSTM is utilized to determine how accurate the prediction models are. The recommended model's accuracy was 94% on the monkeypox tweet dataset. Other performance metrics such as accuracy, recall, and F1-score were utilized to test our models and results in the most time and resource-effective manner. The findings are then compared to more traditional approaches to machine learning. The findings of this research contribute to an increased awareness of the monkeypox infection in the general population.

</p>
</details>

<details><summary><b>On confidence intervals for precision matrices and the eigendecomposition of covariance matrices</b>
<a href="https://arxiv.org/abs/2208.11977">arxiv:2208.11977</a>
&#x1F4C8; 7 <br>
<p>Teodora Popordanoska, Aleksei Tiulpin, Wacha Bounliphone, Matthew B. Blaschko</p></summary>
<p>

**Abstract:** The eigendecomposition of a matrix is the central procedure in probabilistic models based on matrix factorization, for instance principal component analysis and topic models. Quantifying the uncertainty of such a decomposition based on a finite sample estimate is essential to reasoning under uncertainty when employing such models. This paper tackles the challenge of computing confidence bounds on the individual entries of eigenvectors of a covariance matrix of fixed dimension. Moreover, we derive a method to bound the entries of the inverse covariance matrix, the so-called precision matrix. The assumptions behind our method are minimal and require that the covariance matrix exists, and its empirical estimator converges to the true covariance. We make use of the theory of U-statistics to bound the $L_2$ perturbation of the empirical covariance matrix. From this result, we obtain bounds on the eigenvectors using Weyl's theorem and the eigenvalue-eigenvector identity and we derive confidence intervals on the entries of the precision matrix using matrix inversion perturbation bounds. As an application of these results, we demonstrate a new statistical test, which allows us to test for non-zero values of the precision matrix. We compare this test to the well-known Fisher-z test for partial correlations, and demonstrate the soundness and scalability of the proposed statistical test, as well as its application to real-world data from medical and physics domains.

</p>
</details>

<details><summary><b>Time Series Clustering with an EM algorithm for Mixtures of Linear Gaussian State Space Models</b>
<a href="https://arxiv.org/abs/2208.11907">arxiv:2208.11907</a>
&#x1F4C8; 7 <br>
<p>Ryohei Umatani, Takashi Imai, Kaoru Kawamoto, Shutaro Kunimasa</p></summary>
<p>

**Abstract:** In this paper, we consider the task of clustering a set of individual time series while modeling each cluster, that is, model-based time series clustering. The task requires a parametric model with sufficient flexibility to describe the dynamics in various time series. To address this problem, we propose a novel model-based time series clustering method with mixtures of linear Gaussian state space models, which have high flexibility. The proposed method uses a new expectation-maximization algorithm for the mixture model to estimate the model parameters, and determines the number of clusters using the Bayesian information criterion. Experiments on a simulated dataset demonstrate the effectiveness of the method in clustering, parameter estimation, and model selection. The method is applied to a real dataset for which previously proposed time series clustering methods exhibited low accuracy. Results showed that our method produces more accurate clustering results than those obtained using the previous methods.

</p>
</details>

<details><summary><b>Speech Emotion Recognition using Supervised Deep Recurrent System for Mental Health Monitoring</b>
<a href="https://arxiv.org/abs/2208.12812">arxiv:2208.12812</a>
&#x1F4C8; 6 <br>
<p>Nelly Elsayed, Zag ElSayed, Navid Asadizanjani, Murat Ozer, Ahmed Abdelgawad, Magdy Bayoumi</p></summary>
<p>

**Abstract:** Understanding human behavior and monitoring mental health are essential to maintaining the community and society's safety. As there has been an increase in mental health problems during the COVID-19 pandemic due to uncontrolled mental health, early detection of mental issues is crucial. Nowadays, the usage of Intelligent Virtual Personal Assistants (IVA) has increased worldwide. Individuals use their voices to control these devices to fulfill requests and acquire different services. This paper proposes a novel deep learning model based on the gated recurrent neural network and convolution neural network to understand human emotion from speech to improve their IVA services and monitor their mental health.

</p>
</details>

<details><summary><b>Automatic Testing and Validation of Level of Detail Reductions Through Supervised Learning</b>
<a href="https://arxiv.org/abs/2208.12674">arxiv:2208.12674</a>
&#x1F4C8; 6 <br>
<p>Matilda Tamm, Olivia Shamon, Hector Anadon Leon, Konrad Tollmar, Linus Gisslén</p></summary>
<p>

**Abstract:** Modern video games are rapidly growing in size and scale, and to create rich and interesting environments, a large amount of content is needed. As a consequence, often several thousands of detailed 3D assets are used to create a single scene. As each asset's polygon mesh can contain millions of polygons, the number of polygons that need to be drawn every frame may exceed several billions. Therefore, the computational resources often limit how many detailed objects that can be displayed in a scene. To push this limit and to optimize performance one can reduce the polygon count of the assets when possible. Basically, the idea is that an object at farther distance from the capturing camera, consequently with relatively smaller screen size, its polygon count may be reduced without affecting the perceived quality. Level of Detail (LOD) refers to the complexity level of a 3D model representation. The process of removing complexity is often called LOD reduction and can be done automatically with an algorithm or by hand by artists. However, this process may lead to deterioration of the visual quality if the different LODs differ significantly, or if LOD reduction transition is not seamless. Today the validation of these results is mainly done manually requiring an expert to visually inspect the results. However, this process is slow, mundane, and therefore prone to error. Herein we propose a method to automate this process based on the use of deep convolutional networks. We report promising results and envision that this method can be used to automate the process of LOD reduction testing and validation.

</p>
</details>

<details><summary><b>Multimedia Generative Script Learning for Task Planning</b>
<a href="https://arxiv.org/abs/2208.12306">arxiv:2208.12306</a>
&#x1F4C8; 6 <br>
<p>Qingyun Wang, Manling Li, Hou Pong Chan, Lifu Huang, Julia Hockenmaier, Girish Chowdhary, Heng Ji</p></summary>
<p>

**Abstract:** Goal-oriented generative script learning aims to generate subsequent steps based on a goal, which is an essential task to assist robots in performing stereotypical activities of daily life. We show that the performance of this task can be improved if historical states are not just captured by the linguistic instructions given to people, but are augmented with the additional information provided by accompanying images. Therefore, we propose a new task, Multimedia Generative Script Learning, to generate subsequent steps by tracking historical states in both text and vision modalities, as well as presenting the first benchmark containing 2,338 tasks and 31,496 steps with descriptive images. We aim to generate scripts that are visual-state trackable, inductive for unseen tasks, and diverse in their individual steps. We propose to encode visual state changes through a multimedia selective encoder, transferring knowledge from previously observed tasks using a retrieval-augmented decoder, and presenting the distinct information at each step by optimizing a diversity-oriented contrastive learning objective. We define metrics to evaluate both generation quality and inductive quality. Experiment results demonstrate that our approach significantly outperforms strong baselines.

</p>
</details>

<details><summary><b>Learning Continuous Implicit Representation for Near-Periodic Patterns</b>
<a href="https://arxiv.org/abs/2208.12278">arxiv:2208.12278</a>
&#x1F4C8; 6 <br>
<p>Bowei Chen, Tiancheng Zhi, Martial Hebert, Srinivasa G. Narasimhan</p></summary>
<p>

**Abstract:** Near-Periodic Patterns (NPP) are ubiquitous in man-made scenes and are composed of tiled motifs with appearance differences caused by lighting, defects, or design elements. A good NPP representation is useful for many applications including image completion, segmentation, and geometric remapping. But representing NPP is challenging because it needs to maintain global consistency (tiled motifs layout) while preserving local variations (appearance differences). Methods trained on general scenes using a large dataset or single-image optimization struggle to satisfy these constraints, while methods that explicitly model periodicity are not robust to periodicity detection errors. To address these challenges, we learn a neural implicit representation using a coordinate-based MLP with single image optimization. We design an input feature warping module and a periodicity-guided patch loss to handle both global consistency and local variations. To further improve the robustness, we introduce a periodicity proposal module to search and use multiple candidate periodicities in our pipeline. We demonstrate the effectiveness of our method on more than 500 images of building facades, friezes, wallpapers, ground, and Mondrian patterns on single and multi-planar scenes.

</p>
</details>

<details><summary><b>Image Based Food Energy Estimation With Depth Domain Adaptation</b>
<a href="https://arxiv.org/abs/2208.12153">arxiv:2208.12153</a>
&#x1F4C8; 6 <br>
<p>Gautham Vinod, Zeman Shao, Fengqing Zhu</p></summary>
<p>

**Abstract:** Assessment of dietary intake has primarily relied on self-report instruments, which are prone to measurement errors. Dietary assessment methods have increasingly incorporated technological advances particularly mobile, image based approaches to address some of these limitations and further automation. Mobile, image-based methods can reduce user burden and bias by automatically estimating dietary intake from eating occasion images that are captured by mobile devices. In this paper, we propose an "Energy Density Map" which is a pixel-to-pixel mapping from the RGB image to the energy density of the food. We then incorporate the "Energy Density Map" with an associated depth map that is captured by a depth sensor to estimate the food energy. The proposed method is evaluated on the Nutrition5k dataset. Experimental results show improved results compared to baseline methods with an average error of 13.29 kCal and an average percentage error of 13.57% between the ground-truth and the estimated energy of the food.

</p>
</details>

<details><summary><b>Automatic Mapping of Unstructured Cyber Threat Intelligence: An Experimental Study</b>
<a href="https://arxiv.org/abs/2208.12144">arxiv:2208.12144</a>
&#x1F4C8; 6 <br>
<p>Vittorio Orbinato, Mariarosaria Barbaraci, Roberto Natella, Domenico Cotroneo</p></summary>
<p>

**Abstract:** Proactive approaches to security, such as adversary emulation, leverage information about threat actors and their techniques (Cyber Threat Intelligence, CTI). However, most CTI still comes in unstructured forms (i.e., natural language), such as incident reports and leaked documents. To support proactive security efforts, we present an experimental study on the automatic classification of unstructured CTI into attack techniques using machine learning (ML). We contribute with two new datasets for CTI analysis, and we evaluate several ML models, including both traditional and deep learning-based ones. We present several lessons learned about how ML can perform at this task, which classifiers perform best and under which conditions, which are the main causes of classification errors, and the challenges ahead for CTI analysis.

</p>
</details>

<details><summary><b>A Study on Broadcast Networks for Music Genre Classification</b>
<a href="https://arxiv.org/abs/2208.12086">arxiv:2208.12086</a>
&#x1F4C8; 6 <br>
<p>Ahmed Heakl, Abdelrahman Abdelgawad, Victor Parque</p></summary>
<p>

**Abstract:** Due to the increased demand for music streaming/recommender services and the recent developments of music information retrieval frameworks, Music Genre Classification (MGC) has attracted the community's attention. However, convolutional-based approaches are known to lack the ability to efficiently encode and localize temporal features. In this paper, we study the broadcast-based neural networks aiming to improve the localization and generalizability under a small set of parameters (about 180k) and investigate twelve variants of broadcast networks discussing the effect of block configuration, pooling method, activation function, normalization mechanism, label smoothing, channel interdependency, LSTM block inclusion, and variants of inception schemes. Our computational experiments using relevant datasets such as GTZAN, Extended Ballroom, HOMBURG, and Free Music Archive (FMA) show state-of-the-art classification accuracies in Music Genre Classification. Our approach offers insights and the potential to enable compact and generalizable broadcast networks for music and audio classification.

</p>
</details>

<details><summary><b>Learning to Prune Instances of Steiner Tree Problem in Graphs</b>
<a href="https://arxiv.org/abs/2208.11985">arxiv:2208.11985</a>
&#x1F4C8; 6 <br>
<p>Jiwei Zhang, Deepak Ajwani</p></summary>
<p>

**Abstract:** We consider the Steiner tree problem on graphs where we are given a set of nodes and the goal is to find a tree sub-graph of minimum weight that contains all nodes in the given set, potentially including additional nodes. This is a classical NP-hard combinatorial optimisation problem. In recent years, a machine learning framework called learning-to-prune has been successfully used for solving a diverse range of combinatorial optimisation problems. In this paper, we use this learning framework on the Steiner tree problem and show that even on this problem, the learning-to-prune framework results in computing near-optimal solutions at a fraction of the time required by commercial ILP solvers. Our results underscore the potential of the learning-to-prune framework in solving various combinatorial optimisation problems.

</p>
</details>

<details><summary><b>Rail break and derailment prediction using Probabilistic Graphical Modelling</b>
<a href="https://arxiv.org/abs/2208.11940">arxiv:2208.11940</a>
&#x1F4C8; 6 <br>
<p>Rebecca M. C. Taylor, Johan A. du Preez</p></summary>
<p>

**Abstract:** Rail breaks are one of the most common causes of derailments internationally. This is no different for the South African Iron Ore line. Many rail breaks occur as a heavy-haul train passes over a crack, large defect or defective weld. In such cases, it is usually too late for the train to slow down in time to prevent a de-railment. Knowing the risk of a rail break occurring associated with a train passing over a section of rail allows for better implementation of maintenance initiatives and mitigating measures. In this paper the Ore Line's specific challenges are discussed and the currently available data that can be used to create a rail break risk prediction model is reviewed. The development of a basic rail break risk prediction model for the Ore Line is then presented. Finally the insight gained from the model is demonstrated by means of discussing various scenarios of various rail break risk. In future work, we are planning on extending this basic model to allow input from live monitoring systems such as the ultrasonic broken rail detection system.

</p>
</details>

<details><summary><b>Dynamic collaborative filtering Thompson Sampling for cross-domain advertisements recommendation</b>
<a href="https://arxiv.org/abs/2208.11926">arxiv:2208.11926</a>
&#x1F4C8; 6 <br>
<p>Shion Ishikawa, Young-joo Chung, Yu Hirate</p></summary>
<p>

**Abstract:** Recently online advertisers utilize Recommender systems (RSs) for display advertising to improve users' engagement. The contextual bandit model is a widely used RS to exploit and explore users' engagement and maximize the long-term rewards such as clicks or conversions. However, the current models aim to optimize a set of ads only in a specific domain and do not share information with other models in multiple domains. In this paper, we propose dynamic collaborative filtering Thompson Sampling (DCTS), the novel yet simple model to transfer knowledge among multiple bandit models. DCTS exploits similarities between users and between ads to estimate a prior distribution of Thompson sampling. Such similarities are obtained based on contextual features of users and ads. Similarities enable models in a domain that didn't have much data to converge more quickly by transferring knowledge. Moreover, DCTS incorporates temporal dynamics of users to track the user's recent change of preference. We first show transferring knowledge and incorporating temporal dynamics improve the performance of the baseline models on a synthetic dataset. Then we conduct an empirical analysis on a real-world dataset and the result showed that DCTS improves click-through rate by 9.7% than the state-of-the-art models. We also analyze hyper-parameters that adjust temporal dynamics and similarities and show the best parameter which maximizes CTR.

</p>
</details>

<details><summary><b>Adaptively-weighted Integral Space for Fast Multiview Clustering</b>
<a href="https://arxiv.org/abs/2208.12808">arxiv:2208.12808</a>
&#x1F4C8; 5 <br>
<p>Man-Sheng Chen, Tuo Liu, Chang-Dong Wang, Dong Huang, Jian-Huang Lai</p></summary>
<p>

**Abstract:** Multiview clustering has been extensively studied to take advantage of multi-source information to improve the clustering performance. In general, most of the existing works typically compute an n * n affinity graph by some similarity/distance metrics (e.g. the Euclidean distance) or learned representations, and explore the pairwise correlations across views. But unfortunately, a quadratic or even cubic complexity is often needed, bringing about difficulty in clustering largescale datasets. Some efforts have been made recently to capture data distribution in multiple views by selecting view-wise anchor representations with k-means, or by direct matrix factorization on the original observations. Despite the significant success, few of them have considered the view-insufficiency issue, implicitly holding the assumption that each individual view is sufficient to recover the cluster structure. Moreover, the latent integral space as well as the shared cluster structure from multiple insufficient views is not able to be simultaneously discovered. In view of this, we propose an Adaptively-weighted Integral Space for Fast Multiview Clustering (AIMC) with nearly linear complexity. Specifically, view generation models are designed to reconstruct the view observations from the latent integral space with diverse adaptive contributions. Meanwhile, a centroid representation with orthogonality constraint and cluster partition are seamlessly constructed to approximate the latent integral space. An alternate minimizing algorithm is developed to solve the optimization problem, which is proved to have linear time complexity w.r.t. the sample size. Extensive experiments conducted on several realworld datasets confirm the superiority of the proposed AIMC method compared with the state-of-the-art methods.

</p>
</details>

<details><summary><b>Supervised Contrastive Learning for Affect Modelling</b>
<a href="https://arxiv.org/abs/2208.12238">arxiv:2208.12238</a>
&#x1F4C8; 5 <br>
<p>Kosmas Pinitas, Konstantinos Makantasis, Antonios Liapis, Georgios N. Yannakakis</p></summary>
<p>

**Abstract:** Affect modeling is viewed, traditionally, as the process of mapping measurable affect manifestations from multiple modalities of user input to affect labels. That mapping is usually inferred through end-to-end (manifestation-to-affect) machine learning processes. What if, instead, one trains general, subject-invariant representations that consider affect information and then uses such representations to model affect? In this paper we assume that affect labels form an integral part, and not just the training signal, of an affect representation and we explore how the recent paradigm of contrastive learning can be employed to discover general high-level affect-infused representations for the purpose of modeling affect. We introduce three different supervised contrastive learning approaches for training representations that consider affect information. In this initial study we test the proposed methods for arousal prediction in the RECOLA dataset based on user information from multiple modalities. Results demonstrate the representation capacity of contrastive learning and its efficiency in boosting the accuracy of affect models. Beyond their evidenced higher performance compared to end-to-end arousal classification, the resulting representations are general-purpose and subject-agnostic, as training is guided though general affect information available in any multimodal corpus.

</p>
</details>

<details><summary><b>Skin Lesion Analysis: A State-of-the-Art Survey, Systematic Review, and Future Trends</b>
<a href="https://arxiv.org/abs/2208.12232">arxiv:2208.12232</a>
&#x1F4C8; 5 <br>
<p>Md. Kamrul Hasan, Md. Asif Ahamad, Choon Hwai Yap, Guang Yang</p></summary>
<p>

**Abstract:** The Computer-aided Diagnosis (CAD) system for skin lesion analysis is an emerging field of research that has the potential to relieve the burden and cost of skin cancer screening. Researchers have recently indicated increasing interest in developing such CAD systems, with the intention of providing a user-friendly tool to dermatologists in order to reduce the challenges that are raised by manual inspection. The purpose of this article is to provide a complete literature review of cutting-edge CAD techniques published between 2011 and 2020. The Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) method was used to identify a total of 365 publications, 221 for skin lesion segmentation and 144 for skin lesion classification. These articles are analyzed and summarized in a number of different ways so that we can contribute vital information about the methods for the evolution of CAD systems. These ways include: relevant and essential definitions and theories, input data (datasets utilization, preprocessing, augmentations, and fixing imbalance problems), method configuration (techniques, architectures, module frameworks, and losses), training tactics (hyperparameter settings), and evaluation criteria (metrics). We also intend to investigate a variety of performance-enhancing methods, including ensemble and post-processing. In addition, in this survey, we highlight the primary problems associated with evaluating skin lesion segmentation and classification systems using minimal datasets, as well as the potential solutions to these plights. In conclusion, enlightening findings, recommendations, and trends are discussed for the purpose of future research surveillance in related fields of interest. It is foreseen that it will guide researchers of all levels, from beginners to experts, in the process of developing an automated and robust CAD system for skin lesion analysis.

</p>
</details>

<details><summary><b>UAS Navigation in the Real World Using Visual Observation</b>
<a href="https://arxiv.org/abs/2208.12125">arxiv:2208.12125</a>
&#x1F4C8; 5 <br>
<p>Yuci Han, Jianli Wei, Alper Yilmaz</p></summary>
<p>

**Abstract:** This paper presents a novel end-to-end Unmanned Aerial System (UAS) navigation approach for long-range visual navigation in the real world. Inspired by dual-process visual navigation system of human's instinct: environment understanding and landmark recognition, we formulate the UAS navigation task into two same phases. Our system combines the reinforcement learning (RL) and image matching approaches. First, the agent learns the navigation policy using RL in the specified environment. To achieve this, we design an interactive UASNAV environment for the training process. Once the agent learns the navigation policy, which means 'familiarized themselves with the environment', we let the UAS fly in the real world to recognize the landmarks using image matching method and take action according to the learned policy. During the navigation process, the UAS is embedded with single camera as the only visual sensor. We demonstrate that the UAS can learn navigating to the destination hundreds meters away from the starting point with the shortest path in the real world scenario.

</p>
</details>

<details><summary><b>Two-stage Fall Events Classification with Human Skeleton Data</b>
<a href="https://arxiv.org/abs/2208.12027">arxiv:2208.12027</a>
&#x1F4C8; 5 <br>
<p>Leiyu Xie, Yang Sun, Jonathon A. Chambers, Syed Mohsen Naqvi</p></summary>
<p>

**Abstract:** Fall detection and classification become an imper- ative problem for healthcare applications particularity with the increasingly ageing population. Currently, most of the fall clas- sification algorithms provide binary fall or no-fall classification. For better healthcare, it is thus not enough to do binary fall classification but to extend it to multiple fall events classification. In this work, we utilize the privacy mitigating human skeleton data for multiple fall events classification. The skeleton features are extracted from the original RGB images to not only mitigate the personal privacy, but also to reduce the impact of the dynamic illuminations. The proposed fall events classification method is divided into two stages. In the first stage, the model is trained to achieve the binary classification to filter out the no-fall events. Then, in the second stage, the deep neural network (DNN) model is trained to further classify the five types of fall events. In order to confirm the efficiency of the proposed method, the experiments on the UP-Fall dataset outperform the state-of-the-art.

</p>
</details>

<details><summary><b>CH-MARL: A Multimodal Benchmark for Cooperative, Heterogeneous Multi-Agent Reinforcement Learning</b>
<a href="https://arxiv.org/abs/2208.13626">arxiv:2208.13626</a>
&#x1F4C8; 4 <br>
<p>Vasu Sharma, Prasoon Goyal, Kaixiang Lin, Govind Thattai, Qiaozi Gao, Gaurav S. Sukhatme</p></summary>
<p>

**Abstract:** We propose a multimodal (vision-and-language) benchmark for cooperative and heterogeneous multi-agent learning. We introduce a benchmark multimodal dataset with tasks involving collaboration between multiple simulated heterogeneous robots in a rich multi-room home environment. We provide an integrated learning framework, multimodal implementations of state-of-the-art multi-agent reinforcement learning techniques, and a consistent evaluation protocol. Our experiments investigate the impact of different modalities on multi-agent learning performance. We also introduce a simple message passing method between agents. The results suggest that multimodality introduces unique challenges for cooperative multi-agent learning and there is significant room for advancing multi-agent reinforcement learning methods in such settings.

</p>
</details>

<details><summary><b>Riesz-Quincunx-UNet Variational Auto-Encoder for Satellite Image Denoising</b>
<a href="https://arxiv.org/abs/2208.12810">arxiv:2208.12810</a>
&#x1F4C8; 4 <br>
<p>Duy H. Thai, Xiqi Fei, Minh Tri Le, Andreas Züfle, Konrad Wessels</p></summary>
<p>

**Abstract:** Multiresolution deep learning approaches, such as the U-Net architecture, have achieved high performance in classifying and segmenting images. However, these approaches do not provide a latent image representation and cannot be used to decompose, denoise, and reconstruct image data. The U-Net and other convolutional neural network (CNNs) architectures commonly use pooling to enlarge the receptive field, which usually results in irreversible information loss. This study proposes to include a Riesz-Quincunx (RQ) wavelet transform, which combines 1) higher-order Riesz wavelet transform and 2) orthogonal Quincunx wavelets (which have both been used to reduce blur in medical images) inside the U-net architecture, to reduce noise in satellite images and their time-series. In the transformed feature space, we propose a variational approach to understand how random perturbations of the features affect the image to further reduce noise. Combining both approaches, we introduce a hybrid RQUNet-VAE scheme for image and time series decomposition used to reduce noise in satellite imagery. We present qualitative and quantitative experimental results that demonstrate that our proposed RQUNet-VAE was more effective at reducing noise in satellite imagery compared to other state-of-the-art methods. We also apply our scheme to several applications for multi-band satellite images, including: image denoising, image and time-series decomposition by diffusion and image segmentation.

</p>
</details>

<details><summary><b>Leveraging Symmetrical Convolutional Transformer Networks for Speech to Singing Voice Style Transfer</b>
<a href="https://arxiv.org/abs/2208.12410">arxiv:2208.12410</a>
&#x1F4C8; 4 <br>
<p>Shrutina Agarwal, Sriram Ganapathy, Naoya Takahashi</p></summary>
<p>

**Abstract:** In this paper, we propose a model to perform style transfer of speech to singing voice. Contrary to the previous signal processing-based methods, which require high-quality singing templates or phoneme synchronization, we explore a data-driven approach for the problem of converting natural speech to singing voice. We develop a novel neural network architecture, called SymNet, which models the alignment of the input speech with the target melody while preserving the speaker identity and naturalness. The proposed SymNet model is comprised of symmetrical stack of three types of layers - convolutional, transformer, and self-attention layers. The paper also explores novel data augmentation and generative loss annealing methods to facilitate the model training. Experiments are performed on the
  NUS and NHSS datasets which consist of parallel data of speech and singing voice. In these experiments, we show that the proposed SymNet model improves the objective reconstruction quality significantly over the previously published methods and baseline architectures. Further, a subjective listening test confirms the improved quality of the audio obtained using the proposed approach (absolute improvement of 0.37 in mean opinion score measure over the baseline system).

</p>
</details>

<details><summary><b>Universal Mini-Batch Consistency for Set Encoding Functions</b>
<a href="https://arxiv.org/abs/2208.12401">arxiv:2208.12401</a>
&#x1F4C8; 4 <br>
<p>Jeffrey Willette, Andreis Bruno, Juho Lee, Sung Ju Hwang</p></summary>
<p>

**Abstract:** Previous works have established solid foundations for neural set functions, as well as effective architectures which preserve the necessary properties for operating on sets, such as being invariant to permutations of the set elements. Subsequently, Mini-Batch Consistency (MBC), the ability to sequentially process any permutation of any random set partition scheme while maintaining consistency guarantees on the output, has been established but with limited options for network architectures. We further study the MBC property in neural set encoding functions, establishing a method for converting arbitrary non-MBC models to satisfy MBC. In doing so, we provide a framework for a universally-MBC (UMBC) class of set functions. Additionally, we explore an interesting dropout strategy made possible by our framework, and investigate its effects on probabilistic calibration under test-time distributional shifts. We validate UMBC with proofs backed by unit tests, also providing qualitative/quantitative experiments on toy data, clean and corrupted point cloud classification, and amortized clustering on ImageNet. The results demonstrate the utility of UMBC, and we further discover that our dropout strategy improves uncertainty calibration.

</p>
</details>

<details><summary><b>Reduce Communication Costs and Preserve Privacy: Prompt Tuning Method in Federated Learning</b>
<a href="https://arxiv.org/abs/2208.12268">arxiv:2208.12268</a>
&#x1F4C8; 4 <br>
<p>Haodong Zhao, Wei Du, Fangqi Li, Peixuan Li, Gongshen Liu</p></summary>
<p>

**Abstract:** Federated learning (FL) has enabled global model training on decentralized data in a privacy-preserving way by aggregating model updates. However, for many natural language processing (NLP) tasks that utilize pre-trained language models (PLMs) with large numbers of parameters, there are considerable communication costs associated with FL. Recently, prompt tuning, which tunes some soft prompts without modifying PLMs, has achieved excellent performance as a new learning paradigm. Therefore we want to combine the two methods and explore the effect of prompt tuning under FL. In this paper, we propose "FedPrompt" as the first work study prompt tuning in a model split learning way using FL, and prove that split learning greatly reduces the communication cost, only 0.01% of the PLMs' parameters, with little decrease on accuracy both on IID and Non-IID data distribution. This improves the efficiency of FL method while also protecting the data privacy in prompt tuning.In addition, like PLMs, prompts are uploaded and downloaded between public platforms and personal users, so we try to figure out whether there is still a backdoor threat using only soft prompt in FL scenarios. We further conduct backdoor attacks by data poisoning on FedPrompt. Our experiments show that normal backdoor attack can not achieve a high attack success rate, proving the robustness of FedPrompt.We hope this work can promote the application of prompt in FL and raise the awareness of the possible security threats.

</p>
</details>

<details><summary><b>The ReprGesture entry to the GENEA Challenge 2022</b>
<a href="https://arxiv.org/abs/2208.12133">arxiv:2208.12133</a>
&#x1F4C8; 4 <br>
<p>Sicheng Yang, Zhiyong Wu, Minglei Li, Mengchen Zhao, Jiuxin Lin, Liyang Chen, Weihong Bao</p></summary>
<p>

**Abstract:** This paper describes the ReprGesture entry to the Generation and Evaluation of Non-verbal Behaviour for Embodied Agents (GENEA) challenge 2022. The GENEA challenge provides the processed datasets and performs crowdsourced evaluations to compare the performance of different gesture generation systems. In this paper, we explore an automatic gesture generation system based on multimodal representation learning. We use WavLM features for audio, FastText features for text and position and rotation matrix features for gesture. Each modality is projected to two distinct subspaces: modality-invariant and modality-specific. To learn inter-modality-invariant commonalities and capture the characters of modality-specific representations, gradient reversal layer based adversarial classifier and modality reconstruction decoders are used during training. The gesture decoder generates proper gestures using all representations and features related to the rhythm in the audio. Our code, pre-trained models and demo are available at https://github.com/YoungSeng/ReprGesture.

</p>
</details>

<details><summary><b>Towards Benchmarking Explainable Artificial Intelligence Methods</b>
<a href="https://arxiv.org/abs/2208.12120">arxiv:2208.12120</a>
&#x1F4C8; 4 <br>
<p>Lars Holmberg</p></summary>
<p>

**Abstract:** The currently dominating artificial intelligence and machine learning technology, neural networks, builds on inductive statistical learning. Neural networks of today are information processing systems void of understanding and reasoning capabilities, consequently, they cannot explain promoted decisions in a humanly valid form. In this work, we revisit and use fundamental philosophy of science theories as an analytical lens with the goal of revealing, what can be expected, and more importantly, not expected, from methods that aim to explain decisions promoted by a neural network. By conducting a case study we investigate a selection of explainability method's performance over two mundane domains, animals and headgear. Through our study, we lay bare that the usefulness of these methods relies on human domain knowledge and our ability to understand, generalise and reason. The explainability methods can be useful when the goal is to gain further insights into a trained neural network's strengths and weaknesses. If our aim instead is to use these explainability methods to promote actionable decisions or build trust in ML-models they need to be less ambiguous than they are today. In this work, we conclude from our study, that benchmarking explainability methods, is a central quest towards trustworthy artificial intelligence and machine learning.

</p>
</details>

<details><summary><b>Combating Mode Collapse in GANs via Manifold Entropy Estimation</b>
<a href="https://arxiv.org/abs/2208.12055">arxiv:2208.12055</a>
&#x1F4C8; 4 <br>
<p>Haozhe Liu, Bing Li, Haoqian Wu, Hanbang Liang, Yawen Huang, Yuexiang Li, Bernard Ghanem, Yefeng Zheng</p></summary>
<p>

**Abstract:** Generative Adversarial Networks (GANs) have shown compelling results in various tasks and applications in recent years. However, mode collapse remains a critical problem in GANs. In this paper, we propose a novel training pipeline to address the mode collapse issue of GANs. Different from existing methods, we propose to generalize the discriminator as feature embedding, and maximize the entropy of distributions in the embedding space learned by the discriminator. Specifically, two regularization terms, i.e.Deep Local Linear Embedding (DLLE) and Deep Isometric feature Mapping (DIsoMap), are designed to encourage the discriminator to learn the structural information embedded in the data, such that the embedding space learned by the discriminator can be well formed. Based on the well-learned embedding space supported by the discriminator, a non-parametric entropy estimator is designed to efficiently maximize the entropy of embedding vectors, playing as an approximation of maximizing the entropy of the generated distribution. Through improving the discriminator and maximizing the distance of the most similar samples in the embedding space, our pipeline effectively reduces the mode collapse without sacrificing the quality of generated samples. Extensive experimental results show the effectiveness of our method which outperforms the GAN baseline, MaF-GAN on CelebA (9.13 vs. 12.43 in FID) and surpasses the recent state-of-the-art energy-based model on the ANIME-FACE dataset (2.80 vs. 2.26 in Inception score).

</p>
</details>

<details><summary><b>Efficient Activation Quantization via Adaptive Rounding Border for Post-Training Quantization</b>
<a href="https://arxiv.org/abs/2208.11945">arxiv:2208.11945</a>
&#x1F4C8; 4 <br>
<p>Zhengyi Li, Cong Guo, Zhanda Zhu, Yangjie Zhou, Yuxian Qiu, Xiaotian Gao, Jingwen Leng, Minyi Guo</p></summary>
<p>

**Abstract:** Post-training quantization (PTQ) attracts increasing attention due to its convenience in deploying quantized neural networks. Rounding, the primary source of quantization error, is optimized only for model weights, while activations still use the rounding-to-nearest operation. In this work, for the first time, we demonstrate that well-chosen rounding schemes for activations can improve the final accuracy. To deal with the challenge of the dynamicity of the activation rounding scheme, we adaptively adjust the rounding border through a simple function to generate rounding schemes at the inference stage. The border function covers the impact of weight errors, activation errors, and propagated errors to eliminate the bias of the element-wise error, which further benefits model accuracy. We also make the border aware of global errors to better fit different arriving activations. Finally, we propose the AQuant framework to learn the border function. Extensive experiments show that AQuant achieves noticeable improvements with negligible overhead compared with state-of-the-art works and pushes the accuracy of ResNet-18 up to 60.3\% under the 2-bit weight and activation post-training quantization.

</p>
</details>

<details><summary><b>FuncFooler: A Practical Black-box Attack Against Learning-based Binary Code Similarity Detection Methods</b>
<a href="https://arxiv.org/abs/2208.14191">arxiv:2208.14191</a>
&#x1F4C8; 3 <br>
<p>Lichen Jia, Bowen Tang, Chenggang Wu, Zhe Wang, Zihan Jiang, Yuanming Lai, Yan Kang, Ning Liu, Jingfeng Zhang</p></summary>
<p>

**Abstract:** The binary code similarity detection (BCSD) method measures the similarity of two binary executable codes. Recently, the learning-based BCSD methods have achieved great success, outperforming traditional BCSD in detection accuracy and efficiency. However, the existing studies are rather sparse on the adversarial vulnerability of the learning-based BCSD methods, which cause hazards in security-related applications. To evaluate the adversarial robustness, this paper designs an efficient and black-box adversarial code generation algorithm, namely, FuncFooler. FuncFooler constrains the adversarial codes 1) to keep unchanged the program's control flow graph (CFG), and 2) to preserve the same semantic meaning. Specifically, FuncFooler consecutively 1) determines vulnerable candidates in the malicious code, 2) chooses and inserts the adversarial instructions from the benign code, and 3) corrects the semantic side effect of the adversarial code to meet the constraints. Empirically, our FuncFooler can successfully attack the three learning-based BCSD models, including SAFE, Asm2Vec, and jTrans, which calls into question whether the learning-based BCSD is desirable.

</p>
</details>

<details><summary><b>BITS: Bi-level Imitation for Traffic Simulation</b>
<a href="https://arxiv.org/abs/2208.12403">arxiv:2208.12403</a>
&#x1F4C8; 3 <br>
<p>Danfei Xu, Yuxiao Chen, Boris Ivanovic, Marco Pavone</p></summary>
<p>

**Abstract:** Simulation is the key to scaling up validation and verification for robotic systems such as autonomous vehicles. Despite advances in high-fidelity physics and sensor simulation, a critical gap remains in simulating realistic behaviors of road users. This is because, unlike simulating physics and graphics, devising first principle models for human-like behaviors is generally infeasible. In this work, we take a data-driven approach and propose a method that can learn to generate traffic behaviors from real-world driving logs. The method achieves high sample efficiency and behavior diversity by exploiting the bi-level hierarchy of driving behaviors by decoupling the traffic simulation problem into high-level intent inference and low-level driving behavior imitation. The method also incorporates a planning module to obtain stable long-horizon behaviors. We empirically validate our method, named Bi-level Imitation for Traffic Simulation (BITS), with scenarios from two large-scale driving datasets and show that BITS achieves balanced traffic simulation performance in realism, diversity, and long-horizon stability. We also explore ways to evaluate behavior realism and introduce a suite of evaluation metrics for traffic simulation. Finally, as part of our core contributions, we develop and open source a software tool that unifies data formats across different driving datasets and converts scenes from existing datasets into interactive simulation environments. For additional information and videos, see https://sites.google.com/view/nvr-bits2022/home

</p>
</details>

<details><summary><b>Fundamentals of Task-Agnostic Data Valuation</b>
<a href="https://arxiv.org/abs/2208.12354">arxiv:2208.12354</a>
&#x1F4C8; 3 <br>
<p>Mohammad Mohammadi Amiri, Frederic Berdoz, Ramesh Raskar</p></summary>
<p>

**Abstract:** We study valuing the data of a data owner/seller for a data seeker/buyer. Data valuation is often carried out for a specific task assuming a particular utility metric, such as test accuracy on a validation set, that may not exist in practice. In this work, we focus on task-agnostic data valuation without any validation requirements. The data buyer has access to a limited amount of data (which could be publicly available) and seeks more data samples from a data seller. We formulate the problem as estimating the differences in the statistical properties of the data at the seller with respect to the baseline data available at the buyer. We capture these statistical differences through second moment by measuring diversity and relevance of the seller's data for the buyer; we estimate these measures through queries to the seller without requesting raw data. We design the queries with the proposed approach so that the seller is blind to the buyer's raw data and has no knowledge to fabricate responses to queries to obtain a desired outcome of the diversity and relevance trade-off.We will show through extensive experiments on real tabular and image datasets that the proposed estimates capture the diversity and relevance of the seller's data for the buyer.

</p>
</details>

<details><summary><b>Efficient Truncated Linear Regression with Unknown Noise Variance</b>
<a href="https://arxiv.org/abs/2208.12042">arxiv:2208.12042</a>
&#x1F4C8; 3 <br>
<p>Constantinos Daskalakis, Patroklos Stefanou, Rui Yao, Manolis Zampetakis</p></summary>
<p>

**Abstract:** Truncated linear regression is a classical challenge in Statistics, wherein a label, $y = w^T x + \varepsilon$, and its corresponding feature vector, $x \in \mathbb{R}^k$, are only observed if the label falls in some subset $S \subseteq \mathbb{R}$; otherwise the existence of the pair $(x, y)$ is hidden from observation. Linear regression with truncated observations has remained a challenge, in its general form, since the early works of~\citet{tobin1958estimation,amemiya1973regression}. When the distribution of the error is normal with known variance, recent work of~\citet{daskalakis2019truncatedregression} provides computationally and statistically efficient estimators of the linear model, $w$.
  In this paper, we provide the first computationally and statistically efficient estimators for truncated linear regression when the noise variance is unknown, estimating both the linear model and the variance of the noise. Our estimator is based on an efficient implementation of Projected Stochastic Gradient Descent on the negative log-likelihood of the truncated sample. Importantly, we show that the error of our estimates is asymptotically normal, and we use this to provide explicit confidence regions for our estimates.

</p>
</details>

<details><summary><b>TEP-GNN: Accurate Execution Time Prediction of Functional Tests using Graph Neural Networks</b>
<a href="https://arxiv.org/abs/2208.11947">arxiv:2208.11947</a>
&#x1F4C8; 3 <br>
<p>Hazem Peter Samoaa, Antonio Longa, Mazen Mohamad, Morteza Haghir Chehreghani, Philipp Leitner</p></summary>
<p>

**Abstract:** Predicting the performance of production code prior to actually executing or benchmarking it is known to be highly challenging. In this paper, we propose a predictive model, dubbed TEP-GNN, which demonstrates that high-accuracy performance prediction is possible for the special case of predicting unit test execution times. TEP-GNN uses FA-ASTs, or flow-augmented ASTs, as a graph-based code representation approach, and predicts test execution times using a powerful graph neural network (GNN) deep learning model. We evaluate TEP-GNN using four real-life Java open source programs, based on 922 test files mined from the projects' public repositories. We find that our approach achieves a high Pearson correlation of 0.789, considerable outperforming a baseline deep learning model. However, we also find that more work is needed for trained models to generalize to unseen projects. Our work demonstrates that FA-ASTs and GNNs are a feasible approach for predicting absolute performance values, and serves as an important intermediary step towards being able to predict the performance of arbitrary code prior to execution.

</p>
</details>

<details><summary><b>PRIME: Uncovering Circadian Oscillation Patterns and Associations with AD in Untimed Genome-wide Gene Expression across Multiple Brain Regions</b>
<a href="https://arxiv.org/abs/2208.12811">arxiv:2208.12811</a>
&#x1F4C8; 2 <br>
<p>Xinxing Wu, Chong Peng, Gregory Jicha, Donna Wilcock, Qiang Cheng</p></summary>
<p>

**Abstract:** The disruption of circadian rhythm is a cardinal symptom for Alzheimer's disease (AD) patients. The full circadian rhythm orchestration of gene expression in the human brain and its inherent associations with AD remain largely unknown. We present a novel comprehensive approach, PRIME, to detect and analyze rhythmic oscillation patterns in untimed high-dimensional gene expression data across multiple datasets. To demonstrate the utility of PRIME, firstly, we validate it by a time course expression dataset from mouse liver as a cross-species and cross-organ validation. Then, we apply it to study oscillation patterns in untimed genome-wide gene expression from 19 human brain regions of controls and AD patients. Our findings reveal clear, synchronized oscillation patterns in 15 pairs of brain regions of control, while these oscillation patterns either disappear or dim for AD. It is worth noting that PRIME discovers the circadian rhythmic patterns without requiring the sample's timestamps. The codes for PRIME, along with codes to reproduce the figures in this paper, are available at https://github.com/xinxingwu-uk/PRIME.

</p>
</details>

<details><summary><b>Spatio-Temporal Representation Learning Enhanced Source Cell-phone Recognition from Speech Recordings</b>
<a href="https://arxiv.org/abs/2208.12753">arxiv:2208.12753</a>
&#x1F4C8; 2 <br>
<p>Chunyan Zeng, Shixiong Feng, Zhifeng Wang, Xiangkui Wan, Yunfan Chen, Nan Zhao</p></summary>
<p>

**Abstract:** The existing source cell-phone recognition method lacks the long-term feature characterization of the source device, resulting in inaccurate representation of the source cell-phone related features which leads to insufficient recognition accuracy. In this paper, we propose a source cell-phone recognition method based on spatio-temporal representation learning, which includes two main parts: extraction of sequential Gaussian mean matrix features and construction of a recognition model based on spatio-temporal representation learning. In the feature extraction part, based on the analysis of time-series representation of recording source signals, we extract sequential Gaussian mean matrix with long-term and short-term representation ability by using the sensitivity of Gaussian mixture model to data distribution. In the model construction part, we design a structured spatio-temporal representation learning network C3D-BiLSTM to fully characterize the spatio-temporal information, combine 3D convolutional network and bidirectional long short-term memory network for short-term spectral information and long-time fluctuation information representation learning, and achieve accurate recognition of cell-phones by fusing spatio-temporal feature information of recording source signals. The method achieves an average accuracy of 99.03% for the closed-set recognition of 45 cell-phones under the CCNU\_Mobile dataset, and 98.18% in small sample size experiments, with recognition performance better than the existing state-of-the-art methods. The experimental results show that the method exhibits excellent recognition performance in multi-class cell-phones recognition.

</p>
</details>

<details><summary><b>Robust Prototypical Few-Shot Organ Segmentation with Regularized Neural-ODEs</b>
<a href="https://arxiv.org/abs/2208.12428">arxiv:2208.12428</a>
&#x1F4C8; 2 <br>
<p>Prashant Pandey, Mustafa Chasmai, Tanuj Sur, Brejesh Lall</p></summary>
<p>

**Abstract:** Despite the tremendous progress made by deep learning models in image semantic segmentation, they typically require large annotated examples, and increasing attention is being diverted to problem settings like Few-Shot Learning (FSL) where only a small amount of annotation is needed for generalisation to novel classes. This is especially seen in medical domains where dense pixel-level annotations are expensive to obtain. In this paper, we propose Regularized Prototypical Neural Ordinary Differential Equation (R-PNODE), a method that leverages intrinsic properties of Neural-ODEs, assisted and enhanced by additional cluster and consistency losses to perform Few-Shot Segmentation (FSS) of organs. R-PNODE constrains support and query features from the same classes to lie closer in the representation space thereby improving the performance over the existing Convolutional Neural Network (CNN) based FSS methods. We further demonstrate that while many existing Deep CNN based methods tend to be extremely vulnerable to adversarial attacks, R-PNODE exhibits increased adversarial robustness for a wide array of these attacks. We experiment with three publicly available multi-organ segmentation datasets in both in-domain and cross-domain FSS settings to demonstrate the efficacy of our method. In addition, we perform experiments with seven commonly used adversarial attacks in various settings to demonstrate R-PNODE's robustness. R-PNODE outperforms the baselines for FSS by significant margins and also shows superior performance for a wide array of attacks varying in intensity and design.

</p>
</details>

<details><summary><b>Coefficient-based Regularized Distribution Regression</b>
<a href="https://arxiv.org/abs/2208.12427">arxiv:2208.12427</a>
&#x1F4C8; 2 <br>
<p>Yuan Mao, Lei Shi, Zheng-Chu Guo</p></summary>
<p>

**Abstract:** In this paper, we consider the coefficient-based regularized distribution regression which aims to regress from probability measures to real-valued responses over a reproducing kernel Hilbert space (RKHS), where the regularization is put on the coefficients and kernels are assumed to be indefinite. The algorithm involves two stages of sampling, the first stage sample consists of distributions and the second stage sample is obtained from these distributions. Asymptotic behaviors of the algorithm in different regularity ranges of the regression function are comprehensively studied and learning rates are derived via integral operator techniques. We get the optimal rates under some mild conditions, which matches the one-stage sampled minimax optimal rate. Compared with the kernel methods for distribution regression in the literature, the algorithm under consideration does not require the kernel to be symmetric and positive semi-definite and hence provides a simple paradigm for designing indefinite kernel methods, which enriches the theme of the distribution regression. To the best of our knowledge, this is the first result for distribution regression with indefinite kernels, and our algorithm can improve the saturation effect.

</p>
</details>

<details><summary><b>Parotid Gland MR Image Segmentation Based on Contrastive Learning</b>
<a href="https://arxiv.org/abs/2208.12413">arxiv:2208.12413</a>
&#x1F4C8; 2 <br>
<p>Zi'an Xu, Yin Dai, Fayu Liu, Boyuan Wu, Weibing Chen, Lifu Shi</p></summary>
<p>

**Abstract:** Compared with natural images, medical images are difficult to acquire and costly to label. Contrastive learning, as an unsupervised learning method, can more effectively utilize unlabeled medical images. In this paper, we used a Transformer-based contrastive learning method and innovatively trained the contrastive learning network with transfer learning. Then, the output model was transferred to the downstream parotid segmentation task, which improved the performance of the parotid segmentation model on the test set. The improved DSC was 89.60%, MPA was 99.36%, MIoU was 85.11%, and HD was 2.98. All four metrics showed significant improvement compared to the results of using a supervised learning model as a pre-trained model for the parotid segmentation network. In addition, we found that the improvement of the segmentation network by the contrastive learning model was mainly in the encoder part, so this paper also tried to build a contrastive learning network for the decoder part and discussed the problems encountered in the process of building.

</p>
</details>

<details><summary><b>Static Seeding and Clustering of LSTM Embeddings to Learn from Loosely Time-Decoupled Events</b>
<a href="https://arxiv.org/abs/2208.12389">arxiv:2208.12389</a>
&#x1F4C8; 2 <br>
<p>Christian Manasseh, Razvan Veliche, Jared Bennett, Hamilton Clouse</p></summary>
<p>

**Abstract:** Humans learn from the occurrence of events in a different place and time to predict similar trajectories of events. We define Loosely Decoupled Timeseries (LDT) phenomena as two or more events that could happen in different places and across different timelines but share similarities in the nature of the event and the properties of the location. In this work we improve on the use of Recurring Neural Networks (RNN), in particular Long Short-Term Memory (LSTM) networks, to enable AI solutions that generate better timeseries predictions for LDT. We use similarity measures between timeseries based on the trends and introduce embeddings representing those trends. The embeddings represent properties of the event which, coupled with the LSTM structure, can be clustered to identify similar temporally unaligned events. In this paper, we explore methods of seeding a multivariate LSTM from time-invariant data related to the geophysical and demographic phenomena being modeled by the LSTM. We apply these methods on the timeseries data derived from the COVID-19 detected infection and death cases. We use publicly available socio-economic data to seed the LSTM models, creating embeddings, to determine whether such seeding improves case predictions. The embeddings produced by these LSTMs are clustered to identify best-matching candidates for forecasting an evolving timeseries. Applying this method, we show an improvement in 10-day moving average predictions of disease propagation at the US County level.

</p>
</details>

<details><summary><b>Variance Reduction based Experience Replay for Policy Optimization</b>
<a href="https://arxiv.org/abs/2208.12341">arxiv:2208.12341</a>
&#x1F4C8; 2 <br>
<p>Hua Zheng, Wei Xie, M. Ben Feng</p></summary>
<p>

**Abstract:** For reinforcement learning on complex stochastic systems where many factors dynamically impact the output trajectories, it is desirable to effectively leverage the information from historical samples collected in previous iterations to accelerate policy optimization. Classical experience replay allows agents to remember by reusing historical observations. However, the uniform reuse strategy that treats all observations equally overlooks the relative importance of different samples. To overcome this limitation, we propose a general variance reduction based experience replay (VRER) framework that can selectively reuse the most relevant samples to improve policy gradient estimation. This selective mechanism can adaptively put more weight on past samples that are more likely to be generated by the current target distribution. Our theoretical and empirical studies show that the proposed VRER can accelerate the learning of optimal policy and enhance the performance of state-of-the-art policy optimization approaches.

</p>
</details>

<details><summary><b>Semantic Preserving Adversarial Attack Generation with Autoencoder and Genetic Algorithm</b>
<a href="https://arxiv.org/abs/2208.12230">arxiv:2208.12230</a>
&#x1F4C8; 2 <br>
<p>Xinyi Wang, Simon Yusuf Enoch, Dong Seong Kim</p></summary>
<p>

**Abstract:** Widely used deep learning models are found to have poor robustness. Little noises can fool state-of-the-art models into making incorrect predictions. While there is a great deal of high-performance attack generation methods, most of them directly add perturbations to original data and measure them using L_p norms; this can break the major structure of data, thus, creating invalid attacks. In this paper, we propose a black-box attack, which, instead of modifying original data, modifies latent features of data extracted by an autoencoder; then, we measure noises in semantic space to protect the semantics of data. We trained autoencoders on MNIST and CIFAR-10 datasets and found optimal adversarial perturbations using a genetic algorithm. Our approach achieved a 100% attack success rate on the first 100 data of MNIST and CIFAR-10 datasets with less perturbation than FGSM.

</p>
</details>

<details><summary><b>A Comparison of Reinforcement Learning Frameworks for Software Testing Tasks</b>
<a href="https://arxiv.org/abs/2208.12136">arxiv:2208.12136</a>
&#x1F4C8; 2 <br>
<p>Paulina Stevia Nouwou Mindom, Amin Nikanjam, Foutse Khomh</p></summary>
<p>

**Abstract:** Software testing activities aim to find the possible defects of a software product and ensure that the product meets its expected requirements. Some software testing approached are lacking automation or are partly automated which increases the testing time and overall software testing costs. Recently, Reinforcement Learning (RL) has been successfully employed in complex testing tasks such as game testing, regression testing, and test case prioritization to automate the process and provide continuous adaptation. Practitioners can employ RL by implementing from scratch an RL algorithm or use an RL framework. Developers have widely used these frameworks to solve problems in various domains including software testing. However, to the best of our knowledge, there is no study that empirically evaluates the effectiveness and performance of pre-implemented algorithms in RL frameworks. In this paper, we empirically investigate the applications of carefully selected RL algorithms on two important software testing tasks: test case prioritization in the context of Continuous Integration (CI) and game testing. For the game testing task, we conduct experiments on a simple game and use RL algorithms to explore the game to detect bugs. Results show that some of the selected RL frameworks such as Tensorforce outperform recent approaches in the literature. To prioritize test cases, we run experiments on a CI environment where RL algorithms from different frameworks are used to rank the test cases. Our results show that the performance difference between pre-implemented algorithms in some cases is considerable, motivating further investigation. Moreover, empirical evaluations on some benchmark problems are recommended for researchers looking to select RL frameworks, to make sure that RL algorithms perform as intended.

</p>
</details>

<details><summary><b>ARRID: ANN-based Rotordynamics for Robust and Integrated Design</b>
<a href="https://arxiv.org/abs/2208.12640">arxiv:2208.12640</a>
&#x1F4C8; 1 <br>
<p>Soheyl Massoudi, Jürg Schiffmann</p></summary>
<p>

**Abstract:** The purpose of this study is to introduce ANN-based software for the fast evaluation of rotordynamics in the context of robust and integrated design. It is based on a surrogate model made of ensembles of artificial neural networks running in a Bokeh web application. The use of a surrogate model has sped up the computation by three orders of magnitude compared to the current models. ARRID offers fast performance information, including the effect of manufacturing deviations. As such, it helps the designer to make optimal design choices early in the design process. The designer can manipulate the parameters of the design and the operating conditions to obtain performance information in a matter of seconds.

</p>
</details>

<details><summary><b>Using Atom-Like Local Image Features to Study Human Genetics and Neuroanatomy in Large Sets of 3D Medical Image Volumes</b>
<a href="https://arxiv.org/abs/2208.12361">arxiv:2208.12361</a>
&#x1F4C8; 1 <br>
<p>Laurent Chauvin</p></summary>
<p>

**Abstract:** The contributions of this thesis stem from technology developed to analyse large sets of volumetric images in terms of atom-like features extracted in 3D image space, following SIFT algorithm in 2D image space. New feature properties are introduced including a binary feature sign, analogous to an electrical charge, and a discrete set of symmetric feature orientation states in 3D space. These new properties are leveraged to extend feature invariance to include the sign inversion and parity (SP) transform, analogous to the charge conjugation and parity (CP) transform between a particle and its antiparticle in quantum mechanics, thereby accounting for local intensity contrast inversion between imaging modalities and axis reflections due to shape symmetry. A novel exponential kernel is proposed to quantify the similarity of a pair of features extracted in different images from their properties including location, scale, orientation, sign and appearance. A novel measure entitled the soft Jaccard is proposed to quantify the similarity of a pair of feature sets based on their overlap or intersection-over-union, where a kernel establishes non-binary or soft equivalence between a pair of feature elements. The soft Jaccard may be used to identify pairs of feature sets extracted from the same individuals or families with high accuracy, and a simple distance threshold led to the surprising discovery of previously unknown individual and family labeling errors in major public neuroimage datasets. A new algorithm is proposed to register or spatially align a pair of feature sets, entitled SIFT Coherent Point Drift (SIFT-CPD), by identifying a transform that maximizes the soft Jaccard between a fixed feature set and a transformed set. SIFT-CPD achieves faster and more accurate registration than the original CPD algorithm based on feature location information alone, in a variety of challenging.

</p>
</details>

<details><summary><b>Image Reconstruction by Splitting Expectation Propagation Techniques from Iterative Inversion</b>
<a href="https://arxiv.org/abs/2208.12340">arxiv:2208.12340</a>
&#x1F4C8; 1 <br>
<p>Robert G. Aykroyd, Kehinde Olobatuyi</p></summary>
<p>

**Abstract:** Reconstructing images from downsampled and noisy measurements, such as MRI and low dose Computed Tomography (CT), is a mathematically ill-posed inverse problem. We propose an easy-to-use reconstruction method based on Expectation Propagation (EP) techniques. We incorporate the Monte Carlo (MC) method, Markov Chain Monte Carlo (MCMC), and Alternating Direction Method of Multiplier (ADMM) algorithm into EP method to address the intractability issue encountered in EP. We demonstrate the approach on complex Bayesian models for image reconstruction. Our technique is applied to images from Gamma-camera scans. We compare EPMC, EP-MCMC, EP-ADMM methods with MCMC only. The metrics are the better image reconstruction, speed, and parameters estimation. Experiments with Gamma-camera imaging in real and simulated data show that our proposed method is convincingly less computationally expensive than MCMC and produces relatively a better image reconstruction.

</p>
</details>

<details><summary><b>Enabling Weakly-Supervised Temporal Action Localization from On-Device Learning of the Video Stream</b>
<a href="https://arxiv.org/abs/2208.12673">arxiv:2208.12673</a>
&#x1F4C8; 0 <br>
<p>Yue Tang, Yawen Wu, Peipei Zhou, Jingtong Hu</p></summary>
<p>

**Abstract:** Detecting actions in videos have been widely applied in on-device applications. Practical on-device videos are always untrimmed with both action and background. It is desirable for a model to both recognize the class of action and localize the temporal position where the action happens. Such a task is called temporal action location (TAL), which is always trained on the cloud where multiple untrimmed videos are collected and labeled. It is desirable for a TAL model to continuously and locally learn from new data, which can directly improve the action detection precision while protecting customers' privacy. However, it is non-trivial to train a TAL model, since tremendous video samples with temporal annotations are required. However, annotating videos frame by frame is exorbitantly time-consuming and expensive. Although weakly-supervised TAL (W-TAL) has been proposed to learn from untrimmed videos with only video-level labels, such an approach is also not suitable for on-device learning scenarios. In practical on-device learning applications, data are collected in streaming. Dividing such a long video stream into multiple video segments requires lots of human effort, which hinders the exploration of applying the TAL tasks to realistic on-device learning applications. To enable W-TAL models to learn from a long, untrimmed streaming video, we propose an efficient video learning approach that can directly adapt to new environments. We first propose a self-adaptive video dividing approach with a contrast score-based segment merging approach to convert the video stream into multiple segments. Then, we explore different sampling strategies on the TAL tasks to request as few labels as possible. To the best of our knowledge, we are the first attempt to directly learn from the on-device, long video stream.

</p>
</details>

<details><summary><b>DiVa: An Accelerator for Differentially Private Machine Learning</b>
<a href="https://arxiv.org/abs/2208.12392">arxiv:2208.12392</a>
&#x1F4C8; 0 <br>
<p>Beomsik Park, Ranggi Hwang, Dongho Yoon, Yoonhyuk Choi, Minsoo Rhu</p></summary>
<p>

**Abstract:** The widespread deployment of machine learning (ML) is raising serious concerns on protecting the privacy of users who contributed to the collection of training data. Differential privacy (DP) is rapidly gaining momentum in the industry as a practical standard for privacy protection. Despite DP's importance, however, little has been explored within the computer systems community regarding the implication of this emerging ML algorithm on system designs. In this work, we conduct a detailed workload characterization on a state-of-the-art differentially private ML training algorithm named DP-SGD. We uncover several unique properties of DP-SGD (e.g., its high memory capacity and computation requirements vs. non-private ML), root-causing its key bottlenecks. Based on our analysis, we propose an accelerator for differentially private ML named DiVa, which provides a significant improvement in compute utilization, leading to 2.6x higher energy-efficiency vs. conventional systolic arrays.

</p>
</details>

<details><summary><b>Lib-SibGMU -- A University Library Circulation Dataset for Recommender Systems Developmen</b>
<a href="https://arxiv.org/abs/2208.12356">arxiv:2208.12356</a>
&#x1F4C8; 0 <br>
<p>Eduard Zubchuk, Mikhail Arhipkin, Dmitry Menshikov, Aleksandr Karaush, Nikolay Mikhaylovskiy</p></summary>
<p>

**Abstract:** We opensource under CC BY 4.0 license Lib-SibGMU - a university library circulation dataset - for a wide research community, and benchmark major algorithms for recommender systems on this dataset. For a recommender architecture that consists of a vectorizer that turns the history of the books borrowed into a vector, and a neighborhood-based recommender, trained separately, we show that using the fastText model as a vectorizer delivers competitive results.

</p>
</details>

<details><summary><b>2nd Place Solutions for UG2+ Challenge 2022 -- D$^{3}$Net for Mitigating Atmospheric Turbulence from Images</b>
<a href="https://arxiv.org/abs/2208.12332">arxiv:2208.12332</a>
&#x1F4C8; 0 <br>
<p>Sunder Ali Khowaja, Ik Hyun Lee, Jiseok Yoon</p></summary>
<p>

**Abstract:** This technical report briefly introduces to the D$^{3}$Net proposed by our team "TUK-IKLAB" for Atmospheric Turbulence Mitigation in $UG2^{+}$ Challenge at CVPR 2022. In the light of test and validation results on textual images to improve text recognition performance and hot-air balloon images for image enhancement, we can say that the proposed method achieves state-of-the-art performance. Furthermore, we also provide a visual comparison with publicly available denoising, deblurring, and frame averaging methods with respect to the proposed work. The proposed method ranked 2nd on the final leader-board of the aforementioned challenge in the testing phase, respectively.

</p>
</details>

<details><summary><b>Autonomous Unmanned Aerial Vehicle Navigation using Reinforcement Learning: A Systematic Review</b>
<a href="https://arxiv.org/abs/2208.12328">arxiv:2208.12328</a>
&#x1F4C8; 0 <br>
<p>Fadi AlMahamid, Katarina Grolinger</p></summary>
<p>

**Abstract:** There is an increasing demand for using Unmanned Aerial Vehicle (UAV), known as drones, in different applications such as packages delivery, traffic monitoring, search and rescue operations, and military combat engagements. In all of these applications, the UAV is used to navigate the environment autonomously - without human interaction, perform specific tasks and avoid obstacles. Autonomous UAV navigation is commonly accomplished using Reinforcement Learning (RL), where agents act as experts in a domain to navigate the environment while avoiding obstacles. Understanding the navigation environment and algorithmic limitations plays an essential role in choosing the appropriate RL algorithm to solve the navigation problem effectively. Consequently, this study first identifies the main UAV navigation tasks and discusses navigation frameworks and simulation software. Next, RL algorithms are classified and discussed based on the environment, algorithm characteristics, abilities, and applications in different UAV navigation problems, which will help the practitioners and researchers select the appropriate RL algorithms for their UAV navigation use cases. Moreover, identified gaps and opportunities will drive UAV navigation research.

</p>
</details>

<details><summary><b>Neuro-Dynamic State Estimation for Networked Microgrids</b>
<a href="https://arxiv.org/abs/2208.12288">arxiv:2208.12288</a>
&#x1F4C8; 0 <br>
<p>Fei Feng, Yifan Zhou, Peng Zhang</p></summary>
<p>

**Abstract:** We devise neuro-dynamic state estimation (Neuro-DSE), a learning-based dynamic state estimation (DSE) algorithm for networked microgrids (NMs) under unknown subsystems. Our contributions include: 1) a data-driven Neuro-DSE algorithm for NMs DSE with partially unidentified dynamic models, which incorporates the neural-ordinary-differential-equations (ODE-Net) into Kalman filters; 2) a self-refining Neuro-DSE algorithm (Neuro-DSE+) which enables data-driven DSE under limited and noisy measurements by establishing an automatic filtering, augmenting and correcting framework; 3) a Neuro-KalmanNet-DSE algorithm which further integrates KalmanNet with Neuro-DSE to relieve the model mismatch of both neural- and physics-based dynamic models; and 4) an augmented Neuro-DSE for joint estimation of NMs states and unknown parameters (e.g., inertia). Extensive case studies demonstrate the efficacy of Neuro-DSE and its variants under different noise levels, control modes, power sources, observabilities and model knowledge, respectively.

</p>
</details>


{% endraw %}
Prev: [2022.08.24]({{ '/2022/08/24/2022.08.24.html' | relative_url }})  Next: [2022.08.26]({{ '/2022/08/26/2022.08.26.html' | relative_url }})