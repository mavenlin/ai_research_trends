Prev: [2022.08.24]({{ '/2022/08/24/2022.08.24.html' | relative_url }})  Next: [2022.08.26]({{ '/2022/08/26/2022.08.26.html' | relative_url }})
{% raw %}
## Summary for 2022-08-25, created on 2022-08-29


<details><summary><b>DreamBooth: Fine Tuning Text-to-Image Diffusion Models for Subject-Driven Generation</b>
<a href="https://arxiv.org/abs/2208.12242">arxiv:2208.12242</a>
&#x1F4C8; 2500 <br>
<p>Nataniel Ruiz, Yuanzhen Li, Varun Jampani, Yael Pritch, Michael Rubinstein, Kfir Aberman</p></summary>
<p>

**Abstract:** Large text-to-image models achieved a remarkable leap in the evolution of AI, enabling high-quality and diverse synthesis of images from a given text prompt. However, these models lack the ability to mimic the appearance of subjects in a given reference set and synthesize novel renditions of them in different contexts. In this work, we present a new approach for "personalization" of text-to-image diffusion models (specializing them to users' needs). Given as input just a few images of a subject, we fine-tune a pretrained text-to-image model (Imagen, although our method is not limited to a specific model) such that it learns to bind a unique identifier with that specific subject. Once the subject is embedded in the output domain of the model, the unique identifier can then be used to synthesize fully-novel photorealistic images of the subject contextualized in different scenes. By leveraging the semantic prior embedded in the model with a new autogenous class-specific prior preservation loss, our technique enables synthesizing the subject in diverse scenes, poses, views, and lighting conditions that do not appear in the reference images. We apply our technique to several previously-unassailable tasks, including subject recontextualization, text-guided view synthesis, appearance modification, and artistic rendering (all while preserving the subject's key features). Project page: https://dreambooth.github.io/

</p>
</details>

<details><summary><b>Understanding Diffusion Models: A Unified Perspective</b>
<a href="https://arxiv.org/abs/2208.11970">arxiv:2208.11970</a>
&#x1F4C8; 109 <br>
<p>Calvin Luo</p></summary>
<p>

**Abstract:** Diffusion models have shown incredible capabilities as generative models; indeed, they power the current state-of-the-art models on text-conditioned image generation such as Imagen and DALL-E 2. In this work we review, demystify, and unify the understanding of diffusion models across both variational and score-based perspectives. We first derive Variational Diffusion Models (VDM) as a special case of a Markovian Hierarchical Variational Autoencoder, where three key assumptions enable tractable computation and scalable optimization of the ELBO. We then prove that optimizing a VDM boils down to learning a neural network to predict one of three potential objectives: the original source input from any arbitrary noisification of it, the original source noise from any arbitrarily noisified input, or the score function of a noisified input at any arbitrary noise level. We then dive deeper into what it means to learn the score function, and connect the variational perspective of a diffusion model explicitly with the Score-based Generative Modeling perspective through Tweedie's Formula. Lastly, we cover how to learn a conditional distribution using diffusion models via guidance.

</p>
</details>

<details><summary><b>Contrastive Audio-Language Learning for Music</b>
<a href="https://arxiv.org/abs/2208.12208">arxiv:2208.12208</a>
&#x1F4C8; 43 <br>
<p>Ilaria Manco, Emmanouil Benetos, Elio Quinton, György Fazekas</p></summary>
<p>

**Abstract:** As one of the most intuitive interfaces known to humans, natural language has the potential to mediate many tasks that involve human-computer interaction, especially in application-focused fields like Music Information Retrieval. In this work, we explore cross-modal learning in an attempt to bridge audio and language in the music domain. To this end, we propose MusCALL, a framework for Music Contrastive Audio-Language Learning. Our approach consists of a dual-encoder architecture that learns the alignment between pairs of music audio and descriptive sentences, producing multimodal embeddings that can be used for text-to-audio and audio-to-text retrieval out-of-the-box. Thanks to this property, MusCALL can be transferred to virtually any task that can be cast as text-based retrieval. Our experiments show that our method performs significantly better than the baselines at retrieving audio that matches a textual description and, conversely, text that matches an audio query. We also demonstrate that the multimodal alignment capability of our model can be successfully extended to the zero-shot transfer scenario for genre classification and auto-tagging on two public datasets.

</p>
</details>

<details><summary><b>Algorithmic Differentiation for Automatized Modelling of Machine Learned Force Fields</b>
<a href="https://arxiv.org/abs/2208.12104">arxiv:2208.12104</a>
&#x1F4C8; 10 <br>
<p>Niklas Frederik Schmitz, Klaus-Robert Müller, Stefan Chmiela</p></summary>
<p>

**Abstract:** Reconstructing force fields (FF) from atomistic simulation data is a challenge since accurate data can be highly expensive. Here, machine learning (ML) models can help to be data economic as they can be successfully constrained using the underlying symmetry and conservation laws of physics. However, so far, every descriptor newly proposed for an ML model has required a cumbersome and mathematically tedious remodeling. We therefore propose to use modern techniques from algorithmic differentiation within the ML modeling process -- effectively enabling the usage of novel descriptors or models fully automatically at an order of magnitude higher computational efficiency. This paradigmatic approach enables not only a versatile usage of novel representations, the efficient computation of larger systems -- all of high value to the FF community -- but also the simple inclusion of further physical knowledge such as higher-order information (e.g.~Hessians, more complex partial differential equations constraints etc.), even beyond the presented FF domain.

</p>
</details>

<details><summary><b>Cross-Modality Gated Attention Fusion for Multimodal Sentiment Analysis</b>
<a href="https://arxiv.org/abs/2208.11893">arxiv:2208.11893</a>
&#x1F4C8; 9 <br>
<p>Ming Jiang, Shaoxiong Ji</p></summary>
<p>

**Abstract:** Multimodal sentiment analysis is an important research task to predict the sentiment score based on the different modality data from a specific opinion video. Many previous pieces of research have proved the significance of utilizing the shared and unique information across different modalities. However, the high-order combined signals from multimodal data would also help extract satisfied representations. In this paper, we propose CMGA, a Cross-Modality Gated Attention fusion model for MSA that tends to make adequate interaction across different modality pairs. CMGA also adds a forget gate to filter the noisy and redundant signals introduced in the interaction procedure. We experiment on two benchmark datasets in MSA, MOSI, and MOSEI, illustrating the performance of CMGA over several baseline models. We also conduct the ablation study to demonstrate the function of different components inside CMGA.

</p>
</details>

<details><summary><b>On Reality and the Limits of Language Data</b>
<a href="https://arxiv.org/abs/2208.11981">arxiv:2208.11981</a>
&#x1F4C8; 8 <br>
<p>Nigel H. Collier, Fangyu Liu, Ehsan Shareghi</p></summary>
<p>

**Abstract:** Recent advances in neural network language models have shown that it is possible to derive expressive meaning representations by leveraging linguistic associations in large-scale natural language data. These potentially Gestalt representations have enabled state-of-the-art performance for many practical applications. It would appear that we are on a pathway to empirically deriving a robust and expressive computable semantics. A key question that arises is how far can language data alone enable computers to understand the necessary truth about the physical world? Attention to this question is warranted because our future interactions with intelligent machines depends on how well our techniques correctly represent and process the concepts (objects, properties, and processes) that humans commonly observe to be true. After reviewing existing protocols, the objective of this work is to explore this question using a novel and tightly controlled reasoning test and to highlight what models might learn directly from pure linguistic data.

</p>
</details>

<details><summary><b>Compositional Active Inference II: Polynomial Dynamics. Approximate Inference Doctrines</b>
<a href="https://arxiv.org/abs/2208.12173">arxiv:2208.12173</a>
&#x1F4C8; 7 <br>
<p>Toby St. Clere Smithe</p></summary>
<p>

**Abstract:** We develop the compositional theory of active inference by introducing activity, functorially relating statistical games to the dynamical systems which play them, using the new notion of approximate inference doctrine. In order to exhibit such functors, we first develop the necessary theory of dynamical systems, using a generalization of the language of polynomial functors to supply compositional interfaces of the required types: with the resulting polynomially indexed categories of coalgebras, we construct monoidal bicategories of differential and dynamical ``hierarchical inference systems'', in which approximate inference doctrines have semantics. We then describe ``externally parameterized'' statistical games, and use them to construct two approximate inference doctrines found in the computational neuroscience literature, which we call the `Laplace' and the `Hebb-Laplace' doctrines: the former produces dynamical systems which optimize the posteriors of Gaussian models; and the latter produces systems which additionally optimize the parameters (or `weights') which determine their predictions.

</p>
</details>

<details><summary><b>Automatic Mapping of Unstructured Cyber Threat Intelligence: An Experimental Study</b>
<a href="https://arxiv.org/abs/2208.12144">arxiv:2208.12144</a>
&#x1F4C8; 7 <br>
<p>Vittorio Orbinato, Mariarosaria Barbaraci, Roberto Natella, Domenico Cotroneo</p></summary>
<p>

**Abstract:** Proactive approaches to security, such as adversary emulation, leverage information about threat actors and their techniques (Cyber Threat Intelligence, CTI). However, most CTI still comes in unstructured forms (i.e., natural language), such as incident reports and leaked documents. To support proactive security efforts, we present an experimental study on the automatic classification of unstructured CTI into attack techniques using machine learning (ML). We contribute with two new datasets for CTI analysis, and we evaluate several ML models, including both traditional and deep learning-based ones. We present several lessons learned about how ML can perform at this task, which classifiers perform best and under which conditions, which are the main causes of classification errors, and the challenges ahead for CTI analysis.

</p>
</details>

<details><summary><b>JAXFit: Trust Region Method for Nonlinear Least-Squares Curve Fitting on the GPU</b>
<a href="https://arxiv.org/abs/2208.12187">arxiv:2208.12187</a>
&#x1F4C8; 6 <br>
<p>Lucas R. Hofer, Milan Krstajić, Robert P. Smith</p></summary>
<p>

**Abstract:** We implement a trust region method on the GPU for nonlinear least squares curve fitting problems using a new deep learning Python library called JAX. Our open source package, JAXFit, works for both unconstrained and constrained curve fitting problems and allows the fit functions to be defined in Python alone -- without any specialized knowledge of either the GPU or CUDA programming. Since JAXFit runs on the GPU, it is much faster than CPU based libraries and even other GPU based libraries, despite being very easy to use. Additionally, due to JAX's deep learning foundations, the Jacobian in JAXFit's trust region algorithm is calculated with automatic differentiation, rather than than using derivative approximations or requiring the user to define the fit function's partial derivatives.

</p>
</details>

<details><summary><b>Supervised Contrastive Learning for Affect Modelling</b>
<a href="https://arxiv.org/abs/2208.12238">arxiv:2208.12238</a>
&#x1F4C8; 5 <br>
<p>Kosmas Pinitas, Konstantinos Makantasis, Antonios Liapis, Georgios N. Yannakakis</p></summary>
<p>

**Abstract:** Affect modeling is viewed, traditionally, as the process of mapping measurable affect manifestations from multiple modalities of user input to affect labels. That mapping is usually inferred through end-to-end (manifestation-to-affect) machine learning processes. What if, instead, one trains general, subject-invariant representations that consider affect information and then uses such representations to model affect? In this paper we assume that affect labels form an integral part, and not just the training signal, of an affect representation and we explore how the recent paradigm of contrastive learning can be employed to discover general high-level affect-infused representations for the purpose of modeling affect. We introduce three different supervised contrastive learning approaches for training representations that consider affect information. In this initial study we test the proposed methods for arousal prediction in the RECOLA dataset based on user information from multiple modalities. Results demonstrate the representation capacity of contrastive learning and its efficiency in boosting the accuracy of affect models. Beyond their evidenced higher performance compared to end-to-end arousal classification, the resulting representations are general-purpose and subject-agnostic, as training is guided though general affect information available in any multimodal corpus.

</p>
</details>

<details><summary><b>Image Based Food Energy Estimation With Depth Domain Adaptation</b>
<a href="https://arxiv.org/abs/2208.12153">arxiv:2208.12153</a>
&#x1F4C8; 5 <br>
<p>Gautham Vinod, Zeman Shao, Fengqing Zhu</p></summary>
<p>

**Abstract:** Assessment of dietary intake has primarily relied on self-report instruments, which are prone to measurement errors. Dietary assessment methods have increasingly incorporated technological advances particularly mobile, image based approaches to address some of these limitations and further automation. Mobile, image-based methods can reduce user burden and bias by automatically estimating dietary intake from eating occasion images that are captured by mobile devices. In this paper, we propose an "Energy Density Map" which is a pixel-to-pixel mapping from the RGB image to the energy density of the food. We then incorporate the "Energy Density Map" with an associated depth map that is captured by a depth sensor to estimate the food energy. The proposed method is evaluated on the Nutrition5k dataset. Experimental results show improved results compared to baseline methods with an average error of 13.29 kCal and an average percentage error of 13.57% between the ground-truth and the estimated energy of the food.

</p>
</details>

<details><summary><b>Supervised Dimensionality Reduction and Classification with Convolutional Autoencoders</b>
<a href="https://arxiv.org/abs/2208.12152">arxiv:2208.12152</a>
&#x1F4C8; 5 <br>
<p>Ioannis A. Nellas, Sotiris K. Tasoulis, Vassilis P. Plagianakos, Spiros V. Georgakopoulos</p></summary>
<p>

**Abstract:** The joint optimization of the reconstruction and classification error is a hard non convex problem, especially when a non linear mapping is utilized. In order to overcome this obstacle, a novel optimization strategy is proposed, in which a Convolutional Autoencoder for dimensionality reduction and a classifier composed by a Fully Connected Network, are combined to simultaneously produce supervised dimensionality reduction and predictions. It turned out that this methodology can also be greatly beneficial in enforcing explainability of deep learning architectures. Additionally, the resulting Latent Space, optimized for the classification task, can be utilized to improve traditional, interpretable classification algorithms. The experimental results, showed that the proposed methodology achieved competitive results against the state of the art deep learning methods, while being much more efficient in terms of parameter count. Finally, it was empirically justified that the proposed methodology introduces advanced explainability regarding, not only the data structure through the produced latent space, but also about the classification behaviour.

</p>
</details>

<details><summary><b>The ReprGesture entry to the GENEA Challenge 2022</b>
<a href="https://arxiv.org/abs/2208.12133">arxiv:2208.12133</a>
&#x1F4C8; 5 <br>
<p>Sicheng Yang, Zhiyong Wu, Minglei Li, Mengchen Zhao, Jiuxin Lin, Liyang Chen, Weihong Bao</p></summary>
<p>

**Abstract:** This paper describes the ReprGesture entry to the Generation and Evaluation of Non-verbal Behaviour for Embodied Agents (GENEA) challenge 2022. The GENEA challenge provides the processed datasets and performs crowdsourced evaluations to compare the performance of different gesture generation systems. In this paper, we explore an automatic gesture generation system based on multimodal representation learning. We use WavLM features for audio, FastText features for text and position and rotation matrix features for gesture. Each modality is projected to two distinct subspaces: modality-invariant and modality-specific. To learn inter-modality-invariant commonalities and capture the characters of modality-specific representations, gradient reversal layer based adversarial classifier and modality reconstruction decoders are used during training. The gesture decoder generates proper gestures using all representations and features related to the rhythm in the audio. Our code, pre-trained models and demo are available at https://github.com/YoungSeng/ReprGesture.

</p>
</details>

<details><summary><b>Combating Mode Collapse in GANs via Manifold Entropy Estimation</b>
<a href="https://arxiv.org/abs/2208.12055">arxiv:2208.12055</a>
&#x1F4C8; 5 <br>
<p>Haozhe Liu, Bing Li, Haoqian Wu, Hanbang Liang, Yawen Huang, Yuexiang Li, Bernard Ghanem, Yefeng Zheng</p></summary>
<p>

**Abstract:** Generative Adversarial Networks (GANs) have shown compelling results in various tasks and applications in recent years. However, mode collapse remains a critical problem in GANs. In this paper, we propose a novel training pipeline to address the mode collapse issue of GANs. Different from existing methods, we propose to generalize the discriminator as feature embedding, and maximize the entropy of distributions in the embedding space learned by the discriminator. Specifically, two regularization terms, i.e.Deep Local Linear Embedding (DLLE) and Deep Isometric feature Mapping (DIsoMap), are designed to encourage the discriminator to learn the structural information embedded in the data, such that the embedding space learned by the discriminator can be well formed. Based on the well-learned embedding space supported by the discriminator, a non-parametric entropy estimator is designed to efficiently maximize the entropy of embedding vectors, playing as an approximation of maximizing the entropy of the generated distribution. Through improving the discriminator and maximizing the distance of the most similar samples in the embedding space, our pipeline effectively reduces the mode collapse without sacrificing the quality of generated samples. Extensive experimental results show the effectiveness of our method which outperforms the GAN baseline, MaF-GAN on CelebA (9.13 vs. 12.43 in FID) and surpasses the recent state-of-the-art energy-based model on the ANIME-FACE dataset (2.80 vs. 2.26 in Inception score).

</p>
</details>

<details><summary><b>A CNN-LSTM-based hybrid deep learning approach to detect sentiment polarities on Monkeypox tweets</b>
<a href="https://arxiv.org/abs/2208.12019">arxiv:2208.12019</a>
&#x1F4C8; 5 <br>
<p>Krishna Kumar Mohbey, Gaurav Meena, Sunil Kumar, K Lokesh</p></summary>
<p>

**Abstract:** People have recently begun communicating their thoughts and viewpoints through user-generated multimedia material on social networking websites. This information can be images, text, videos, or audio. Recent years have seen a rise in the frequency of occurrence of this pattern. Twitter is one of the most extensively utilized social media sites, and it is also one of the finest locations to get a sense of how people feel about events that are linked to the Monkeypox sickness. This is because tweets on Twitter are shortened and often updated, both of which contribute to the platform's character. The fundamental objective of this study is to get a deeper comprehension of the diverse range of reactions people have in response to the presence of this condition. This study focuses on finding out what individuals think about monkeypox illnesses, which presents a hybrid technique based on CNN and LSTM. We have considered all three possible polarities of a user's tweet: positive, negative, and neutral. An architecture built on CNN and LSTM is utilized to determine how accurate the prediction models are. The recommended model's accuracy was 94% on the monkeypox tweet dataset. Other performance metrics such as accuracy, recall, and F1-score were utilized to test our models and results in the most time and resource-effective manner. The findings are then compared to more traditional approaches to machine learning. The findings of this research contribute to an increased awareness of the monkeypox infection in the general population.

</p>
</details>

<details><summary><b>On confidence intervals for precision matrices and the eigendecomposition of covariance matrices</b>
<a href="https://arxiv.org/abs/2208.11977">arxiv:2208.11977</a>
&#x1F4C8; 5 <br>
<p>Teodora Popordanoska, Aleksei Tiulpin, Wacha Bounliphone, Matthew B. Blaschko</p></summary>
<p>

**Abstract:** The eigendecomposition of a matrix is the central procedure in probabilistic models based on matrix factorization, for instance principal component analysis and topic models. Quantifying the uncertainty of such a decomposition based on a finite sample estimate is essential to reasoning under uncertainty when employing such models. This paper tackles the challenge of computing confidence bounds on the individual entries of eigenvectors of a covariance matrix of fixed dimension. Moreover, we derive a method to bound the entries of the inverse covariance matrix, the so-called precision matrix. The assumptions behind our method are minimal and require that the covariance matrix exists, and its empirical estimator converges to the true covariance. We make use of the theory of U-statistics to bound the $L_2$ perturbation of the empirical covariance matrix. From this result, we obtain bounds on the eigenvectors using Weyl's theorem and the eigenvalue-eigenvector identity and we derive confidence intervals on the entries of the precision matrix using matrix inversion perturbation bounds. As an application of these results, we demonstrate a new statistical test, which allows us to test for non-zero values of the precision matrix. We compare this test to the well-known Fisher-z test for partial correlations, and demonstrate the soundness and scalability of the proposed statistical test, as well as its application to real-world data from medical and physics domains.

</p>
</details>

<details><summary><b>Rail break and derailment prediction using Probabilistic Graphical Modelling</b>
<a href="https://arxiv.org/abs/2208.11940">arxiv:2208.11940</a>
&#x1F4C8; 5 <br>
<p>Rebecca M. C. Taylor, Johan A. du Preez</p></summary>
<p>

**Abstract:** Rail breaks are one of the most common causes of derailments internationally. This is no different for the South African Iron Ore line. Many rail breaks occur as a heavy-haul train passes over a crack, large defect or defective weld. In such cases, it is usually too late for the train to slow down in time to prevent a de-railment. Knowing the risk of a rail break occurring associated with a train passing over a section of rail allows for better implementation of maintenance initiatives and mitigating measures. In this paper the Ore Line's specific challenges are discussed and the currently available data that can be used to create a rail break risk prediction model is reviewed. The development of a basic rail break risk prediction model for the Ore Line is then presented. Finally the insight gained from the model is demonstrated by means of discussing various scenarios of various rail break risk. In future work, we are planning on extending this basic model to allow input from live monitoring systems such as the ultrasonic broken rail detection system.

</p>
</details>

<details><summary><b>Time Series Clustering with an EM algorithm for Mixtures of Linear Gaussian State Space Models</b>
<a href="https://arxiv.org/abs/2208.11907">arxiv:2208.11907</a>
&#x1F4C8; 5 <br>
<p>Ryohei Umatani, Takashi Imai, Kaoru Kawamoto, Shutaro Kunimasa</p></summary>
<p>

**Abstract:** In this paper, we consider the task of clustering a set of individual time series while modeling each cluster, that is, model-based time series clustering. The task requires a parametric model with sufficient flexibility to describe the dynamics in various time series. To address this problem, we propose a novel model-based time series clustering method with mixtures of linear Gaussian state space models, which have high flexibility. The proposed method uses a new expectation-maximization algorithm for the mixture model to estimate the model parameters, and determines the number of clusters using the Bayesian information criterion. Experiments on a simulated dataset demonstrate the effectiveness of the method in clustering, parameter estimation, and model selection. The method is applied to a real dataset for which previously proposed time series clustering methods exhibited low accuracy. Results showed that our method produces more accurate clustering results than those obtained using the previous methods.

</p>
</details>

<details><summary><b>UAS Navigation in the Real World Using Visual Observation</b>
<a href="https://arxiv.org/abs/2208.12125">arxiv:2208.12125</a>
&#x1F4C8; 4 <br>
<p>Yuci Han, Jianli Wei, Alper Yilmaz</p></summary>
<p>

**Abstract:** This paper presents a novel end-to-end Unmanned Aerial System (UAS) navigation approach for long-range visual navigation in the real world. Inspired by dual-process visual navigation system of human's instinct: environment understanding and landmark recognition, we formulate the UAS navigation task into two same phases. Our system combines the reinforcement learning (RL) and image matching approaches. First, the agent learns the navigation policy using RL in the specified environment. To achieve this, we design an interactive UASNAV environment for the training process. Once the agent learns the navigation policy, which means 'familiarized themselves with the environment', we let the UAS fly in the real world to recognize the landmarks using image matching method and take action according to the learned policy. During the navigation process, the UAS is embedded with single camera as the only visual sensor. We demonstrate that the UAS can learn navigating to the destination hundreds meters away from the starting point with the shortest path in the real world scenario.

</p>
</details>

<details><summary><b>Towards Benchmarking Explainable Artificial Intelligence Methods</b>
<a href="https://arxiv.org/abs/2208.12120">arxiv:2208.12120</a>
&#x1F4C8; 4 <br>
<p>Lars Holmberg</p></summary>
<p>

**Abstract:** The currently dominating artificial intelligence and machine learning technology, neural networks, builds on inductive statistical learning. Neural networks of today are information processing systems void of understanding and reasoning capabilities, consequently, they cannot explain promoted decisions in a humanly valid form. In this work, we revisit and use fundamental philosophy of science theories as an analytical lens with the goal of revealing, what can be expected, and more importantly, not expected, from methods that aim to explain decisions promoted by a neural network. By conducting a case study we investigate a selection of explainability method's performance over two mundane domains, animals and headgear. Through our study, we lay bare that the usefulness of these methods relies on human domain knowledge and our ability to understand, generalise and reason. The explainability methods can be useful when the goal is to gain further insights into a trained neural network's strengths and weaknesses. If our aim instead is to use these explainability methods to promote actionable decisions or build trust in ML-models they need to be less ambiguous than they are today. In this work, we conclude from our study, that benchmarking explainability methods, is a central quest towards trustworthy artificial intelligence and machine learning.

</p>
</details>

<details><summary><b>A Study on Broadcast Networks for Music Genre Classification</b>
<a href="https://arxiv.org/abs/2208.12086">arxiv:2208.12086</a>
&#x1F4C8; 4 <br>
<p>Ahmed Heakl, Abdelrahman Abdelgawad, Victor Parque</p></summary>
<p>

**Abstract:** Due to the increased demand for music streaming/recommender services and the recent developments of music information retrieval frameworks, Music Genre Classification (MGC) has attracted the community's attention. However, convolutional-based approaches are known to lack the ability to efficiently encode and localize temporal features. In this paper, we study the broadcast-based neural networks aiming to improve the localization and generalizability under a small set of parameters (about 180k) and investigate twelve variants of broadcast networks discussing the effect of block configuration, pooling method, activation function, normalization mechanism, label smoothing, channel interdependency, LSTM block inclusion, and variants of inception schemes. Our computational experiments using relevant datasets such as GTZAN, Extended Ballroom, HOMBURG, and Free Music Archive (FMA) show state-of-the-art classification accuracies in Music Genre Classification. Our approach offers insights and the potential to enable compact and generalizable broadcast networks for music and audio classification.

</p>
</details>

<details><summary><b>Learning to Prune Instances of Steiner Tree Problem in Graphs</b>
<a href="https://arxiv.org/abs/2208.11985">arxiv:2208.11985</a>
&#x1F4C8; 4 <br>
<p>Jiwei Zhang, Deepak Ajwani</p></summary>
<p>

**Abstract:** We consider the Steiner tree problem on graphs where we are given a set of nodes and the goal is to find a tree sub-graph of minimum weight that contains all nodes in the given set, potentially including additional nodes. This is a classical NP-hard combinatorial optimisation problem. In recent years, a machine learning framework called learning-to-prune has been successfully used for solving a diverse range of combinatorial optimisation problems. In this paper, we use this learning framework on the Steiner tree problem and show that even on this problem, the learning-to-prune framework results in computing near-optimal solutions at a fraction of the time required by commercial ILP solvers. Our results underscore the potential of the learning-to-prune framework in solving various combinatorial optimisation problems.

</p>
</details>

<details><summary><b>Skin Lesion Analysis: A State-of-the-Art Survey, Systematic Review, and Future Trends</b>
<a href="https://arxiv.org/abs/2208.12232">arxiv:2208.12232</a>
&#x1F4C8; 3 <br>
<p>Md. Kamrul Hasan, Md. Asif Ahamad, Choon Hwai Yap, Guang Yang</p></summary>
<p>

**Abstract:** The Computer-aided Diagnosis (CAD) system for skin lesion analysis is an emerging field of research that has the potential to relieve the burden and cost of skin cancer screening. Researchers have recently indicated increasing interest in developing such CAD systems, with the intention of providing a user-friendly tool to dermatologists in order to reduce the challenges that are raised by manual inspection. The purpose of this article is to provide a complete literature review of cutting-edge CAD techniques published between 2011 and 2020. The Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) method was used to identify a total of 365 publications, 221 for skin lesion segmentation and 144 for skin lesion classification. These articles are analyzed and summarized in a number of different ways so that we can contribute vital information about the methods for the evolution of CAD systems. These ways include: relevant and essential definitions and theories, input data (datasets utilization, preprocessing, augmentations, and fixing imbalance problems), method configuration (techniques, architectures, module frameworks, and losses), training tactics (hyperparameter settings), and evaluation criteria (metrics). We also intend to investigate a variety of performance-enhancing methods, including ensemble and post-processing. In addition, in this survey, we highlight the primary problems associated with evaluating skin lesion segmentation and classification systems using minimal datasets, as well as the potential solutions to these plights. In conclusion, enlightening findings, recommendations, and trends are discussed for the purpose of future research surveillance in related fields of interest. It is foreseen that it will guide researchers of all levels, from beginners to experts, in the process of developing an automated and robust CAD system for skin lesion analysis.

</p>
</details>

<details><summary><b>Semantic Preserving Adversarial Attack Generation with Autoencoder and Genetic Algorithm</b>
<a href="https://arxiv.org/abs/2208.12230">arxiv:2208.12230</a>
&#x1F4C8; 3 <br>
<p>Xinyi Wang, Simon Yusuf Enoch, Dong Seong Kim</p></summary>
<p>

**Abstract:** Widely used deep learning models are found to have poor robustness. Little noises can fool state-of-the-art models into making incorrect predictions. While there is a great deal of high-performance attack generation methods, most of them directly add perturbations to original data and measure them using L_p norms; this can break the major structure of data, thus, creating invalid attacks. In this paper, we propose a black-box attack, which, instead of modifying original data, modifies latent features of data extracted by an autoencoder; then, we measure noises in semantic space to protect the semantics of data. We trained autoencoders on MNIST and CIFAR-10 datasets and found optimal adversarial perturbations using a genetic algorithm. Our approach achieved a 100% attack success rate on the first 100 data of MNIST and CIFAR-10 datasets with less perturbation than FGSM.

</p>
</details>

<details><summary><b>Anytime-Lidar: Deadline-aware 3D Object Detection</b>
<a href="https://arxiv.org/abs/2208.12181">arxiv:2208.12181</a>
&#x1F4C8; 3 <br>
<p>Ahmet Soyyigit, Shuochao Yao, Heechul Yun</p></summary>
<p>

**Abstract:** In this work, we present a novel scheduling framework enabling anytime perception for deep neural network (DNN) based 3D object detection pipelines. We focus on computationally expensive region proposal network (RPN) and per-category multi-head detector components, which are common in 3D object detection pipelines, and make them deadline-aware. We propose a scheduling algorithm, which intelligently selects the subset of the components to make effective time and accuracy trade-off on the fly. We minimize accuracy loss of skipping some of the neural network sub-components by projecting previously detected objects onto the current scene through estimations. We apply our approach to a state-of-art 3D object detection network, PointPillars, and evaluate its performance on Jetson Xavier AGX using nuScenes dataset. Compared to the baselines, our approach significantly improve the network's accuracy under various deadline constraints.

</p>
</details>

<details><summary><b>A Comparison of Reinforcement Learning Frameworks for Software Testing Tasks</b>
<a href="https://arxiv.org/abs/2208.12136">arxiv:2208.12136</a>
&#x1F4C8; 3 <br>
<p>Paulina Stevia Nouwou Mindom, Amin Nikanjam, Foutse Khomh</p></summary>
<p>

**Abstract:** Software testing activities aim to find the possible defects of a software product and ensure that the product meets its expected requirements. Some software testing approached are lacking automation or are partly automated which increases the testing time and overall software testing costs. Recently, Reinforcement Learning (RL) has been successfully employed in complex testing tasks such as game testing, regression testing, and test case prioritization to automate the process and provide continuous adaptation. Practitioners can employ RL by implementing from scratch an RL algorithm or use an RL framework. Developers have widely used these frameworks to solve problems in various domains including software testing. However, to the best of our knowledge, there is no study that empirically evaluates the effectiveness and performance of pre-implemented algorithms in RL frameworks. In this paper, we empirically investigate the applications of carefully selected RL algorithms on two important software testing tasks: test case prioritization in the context of Continuous Integration (CI) and game testing. For the game testing task, we conduct experiments on a simple game and use RL algorithms to explore the game to detect bugs. Results show that some of the selected RL frameworks such as Tensorforce outperform recent approaches in the literature. To prioritize test cases, we run experiments on a CI environment where RL algorithms from different frameworks are used to rank the test cases. Our results show that the performance difference between pre-implemented algorithms in some cases is considerable, motivating further investigation. Moreover, empirical evaluations on some benchmark problems are recommended for researchers looking to select RL frameworks, to make sure that RL algorithms perform as intended.

</p>
</details>

<details><summary><b>Efficient Truncated Linear Regression with Unknown Noise Variance</b>
<a href="https://arxiv.org/abs/2208.12042">arxiv:2208.12042</a>
&#x1F4C8; 3 <br>
<p>Constantinos Daskalakis, Patroklos Stefanou, Rui Yao, Manolis Zampetakis</p></summary>
<p>

**Abstract:** Truncated linear regression is a classical challenge in Statistics, wherein a label, $y = w^T x + \varepsilon$, and its corresponding feature vector, $x \in \mathbb{R}^k$, are only observed if the label falls in some subset $S \subseteq \mathbb{R}$; otherwise the existence of the pair $(x, y)$ is hidden from observation. Linear regression with truncated observations has remained a challenge, in its general form, since the early works of~\citet{tobin1958estimation,amemiya1973regression}. When the distribution of the error is normal with known variance, recent work of~\citet{daskalakis2019truncatedregression} provides computationally and statistically efficient estimators of the linear model, $w$.
  In this paper, we provide the first computationally and statistically efficient estimators for truncated linear regression when the noise variance is unknown, estimating both the linear model and the variance of the noise. Our estimator is based on an efficient implementation of Projected Stochastic Gradient Descent on the negative log-likelihood of the truncated sample. Importantly, we show that the error of our estimates is asymptotically normal, and we use this to provide explicit confidence regions for our estimates.

</p>
</details>

<details><summary><b>Two-stage Fall Events Classification with Human Skeleton Data</b>
<a href="https://arxiv.org/abs/2208.12027">arxiv:2208.12027</a>
&#x1F4C8; 3 <br>
<p>Leiyu Xie, Yang Sun, Jonathon A. Chambers, Syed Mohsen Naqvi</p></summary>
<p>

**Abstract:** Fall detection and classification become an imper- ative problem for healthcare applications particularity with the increasingly ageing population. Currently, most of the fall clas- sification algorithms provide binary fall or no-fall classification. For better healthcare, it is thus not enough to do binary fall classification but to extend it to multiple fall events classification. In this work, we utilize the privacy mitigating human skeleton data for multiple fall events classification. The skeleton features are extracted from the original RGB images to not only mitigate the personal privacy, but also to reduce the impact of the dynamic illuminations. The proposed fall events classification method is divided into two stages. In the first stage, the model is trained to achieve the binary classification to filter out the no-fall events. Then, in the second stage, the deep neural network (DNN) model is trained to further classify the five types of fall events. In order to confirm the efficiency of the proposed method, the experiments on the UP-Fall dataset outperform the state-of-the-art.

</p>
</details>

<details><summary><b>TEP-GNN: Accurate Execution Time Prediction of Functional Tests using Graph Neural Networks</b>
<a href="https://arxiv.org/abs/2208.11947">arxiv:2208.11947</a>
&#x1F4C8; 3 <br>
<p>Hazem Peter Samoaa, Antonio Longa, Mazen Mohamad, Morteza Haghir Chehreghani, Philipp Leitner</p></summary>
<p>

**Abstract:** Predicting the performance of production code prior to actually executing or benchmarking it is known to be highly challenging. In this paper, we propose a predictive model, dubbed TEP-GNN, which demonstrates that high-accuracy performance prediction is possible for the special case of predicting unit test execution times. TEP-GNN uses FA-ASTs, or flow-augmented ASTs, as a graph-based code representation approach, and predicts test execution times using a powerful graph neural network (GNN) deep learning model. We evaluate TEP-GNN using four real-life Java open source programs, based on 922 test files mined from the projects' public repositories. We find that our approach achieves a high Pearson correlation of 0.789, considerable outperforming a baseline deep learning model. However, we also find that more work is needed for trained models to generalize to unseen projects. Our work demonstrates that FA-ASTs and GNNs are a feasible approach for predicting absolute performance values, and serves as an important intermediary step towards being able to predict the performance of arbitrary code prior to execution.

</p>
</details>

<details><summary><b>Efficient Activation Quantization via Adaptive Rounding Border for Post-Training Quantization</b>
<a href="https://arxiv.org/abs/2208.11945">arxiv:2208.11945</a>
&#x1F4C8; 3 <br>
<p>Zhengyi Li, Cong Guo, Zhanda Zhu, Yangjie Zhou, Yuxian Qiu, Xiaotian Gao, Jingwen Leng, Minyi Guo</p></summary>
<p>

**Abstract:** Post-training quantization (PTQ) attracts increasing attention due to its convenience in deploying quantized neural networks. Rounding, the primary source of quantization error, is optimized only for model weights, while activations still use the rounding-to-nearest operation. In this work, for the first time, we demonstrate that well-chosen rounding schemes for activations can improve the final accuracy. To deal with the challenge of the dynamicity of the activation rounding scheme, we adaptively adjust the rounding border through a simple function to generate rounding schemes at the inference stage. The border function covers the impact of weight errors, activation errors, and propagated errors to eliminate the bias of the element-wise error, which further benefits model accuracy. We also make the border aware of global errors to better fit different arriving activations. Finally, we propose the AQuant framework to learn the border function. Extensive experiments show that AQuant achieves noticeable improvements with negligible overhead compared with state-of-the-art works and pushes the accuracy of ResNet-18 up to 60.3\% under the 2-bit weight and activation post-training quantization.

</p>
</details>

<details><summary><b>Deep neural networks for fast acquisition of aortic 3D pressure and velocity flow fields</b>
<a href="https://arxiv.org/abs/2208.12156">arxiv:2208.12156</a>
&#x1F4C8; 2 <br>
<p>Endrit Pajaziti, Javier Montalt-Tordera, Claudio Capelli, Raphael Sivera, Emilie Sauvage, Silvia Schievano, Vivek Muthurangu</p></summary>
<p>

**Abstract:** Computational fluid dynamics (CFD) can be used to simulate vascular haemodynamics and analyse potential treatment options. CFD has shown to be beneficial in improving patient outcomes. However, the implementation of CFD for routine clinical use is yet to be realised. Barriers for CFD include high computational resources, specialist experience needed for designing simulation set-ups, and long processing times. The aim of this study was to explore the use of machine learning (ML) to replicate conventional aortic CFD with automatic and fast regression models. Data used to train/test the model comprised of 3,000 CFD simulations performed on synthetically generated 3D aortic shapes. These subjects were generated from a statistical shape model (SSM) built on real patient-specific aortas (N=67). Inference performed on 200 test shapes resulted in average errors of 6.01% +/-3.12 SD and 3.99% +/-0.93 SD for pressure and velocity, respectively. Our ML-based models performed CFD in ~0.075 seconds (4,000x faster than the solver). This study shows that results from conventional vascular CFD can be reproduced using ML at a much faster rate, in an automatic process, and with high accuracy.

</p>
</details>

<details><summary><b>Dynamic collaborative filtering Thompson Sampling for cross-domain advertisements recommendation</b>
<a href="https://arxiv.org/abs/2208.11926">arxiv:2208.11926</a>
&#x1F4C8; 2 <br>
<p>Shion Ishikawa, Young-joo Chung, Yu Hirate</p></summary>
<p>

**Abstract:** Recently online advertisers utilize Recommender systems (RSs) for display advertising to improve users' engagement. The contextual bandit model is a widely used RS to exploit and explore users' engagement and maximize the long-term rewards such as clicks or conversions. However, the current models aim to optimize a set of ads only in a specific domain and do not share information with other models in multiple domains. In this paper, we propose dynamic collaborative filtering Thompson Sampling (DCTS), the novel yet simple model to transfer knowledge among multiple bandit models. DCTS exploits similarities between users and between ads to estimate a prior distribution of Thompson sampling. Such similarities are obtained based on contextual features of users and ads. Similarities enable models in a domain that didn't have much data to converge more quickly by transferring knowledge. Moreover, DCTS incorporates temporal dynamics of users to track the user's recent change of preference. We first show transferring knowledge and incorporating temporal dynamics improve the performance of the baseline models on a synthetic dataset. Then we conduct an empirical analysis on a real-world dataset and the result showed that DCTS improves click-through rate by 9.7% than the state-of-the-art models. We also analyze hyper-parameters that adjust temporal dynamics and similarities and show the best parameter which maximizes CTR.

</p>
</details>


{% endraw %}
Prev: [2022.08.24]({{ '/2022/08/24/2022.08.24.html' | relative_url }})  Next: [2022.08.26]({{ '/2022/08/26/2022.08.26.html' | relative_url }})