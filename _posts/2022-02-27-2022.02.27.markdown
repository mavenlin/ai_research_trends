Prev: [2022.02.26]({{ '/2022/02/26/2022.02.26.html' | relative_url }})  Next: [2022.02.28]({{ '/2022/02/28/2022.02.28.html' | relative_url }})
{% raw %}
## Summary for 2022-02-27, created on 2022-03-09


<details><summary><b>Point Label Aware Superpixels for Multi-species Segmentation of Underwater Imagery</b>
<a href="https://arxiv.org/abs/2202.13487">arxiv:2202.13487</a>
&#x1F4C8; 22 <br>
<p>Scarlett Raine, Ross Marchant, Brano Kusy, Frederic Maire, Tobias Fischer</p></summary>
<p>

**Abstract:** Monitoring coral reefs using underwater vehicles increases the range of marine surveys and availability of historical ecological data by collecting significant quantities of images. Analysis of this imagery can be automated using a model trained to perform semantic segmentation, however it is too costly and time-consuming to densely label images for training supervised models. In this letter, we leverage photo-quadrat imagery labeled by ecologists with sparse point labels. We propose a point label aware method for propagating labels within superpixel regions to obtain augmented ground truth for training a semantic segmentation model. Our point label aware superpixel method utilizes the sparse point labels, and clusters pixels using learned features to accurately generate single-species segments in cluttered, complex coral images. Our method outperforms prior methods on the UCSD Mosaics dataset by 3.62% for pixel accuracy and 8.35% for mean IoU for the label propagation task. Furthermore, our approach reduces computation time reported by previous approaches by 76%. We train a DeepLabv3+ architecture and outperform state-of-the-art for semantic segmentation by 2.91% for pixel accuracy and 9.65% for mean IoU on the UCSD Mosaics dataset and by 4.19% for pixel accuracy and 14.32% mean IoU for the Eilat dataset.

</p>
</details>

<details><summary><b>Conditional Simulation Using Diffusion Schrödinger Bridges</b>
<a href="https://arxiv.org/abs/2202.13460">arxiv:2202.13460</a>
&#x1F4C8; 18 <br>
<p>Yuyang Shi, Valentin De Bortoli, George Deligiannidis, Arnaud Doucet</p></summary>
<p>

**Abstract:** Denoising diffusion models have recently emerged as a powerful class of generative models. They provide state-of-the-art results, not only for unconditional simulation, but also when used to solve conditional simulation problems arising in a wide range of inverse problems such as image inpainting or deblurring. A limitation of these models is that they are computationally intensive at generation time as they require simulating a diffusion process over a long time horizon. When performing unconditional simulation, a Schrödinger bridge formulation of generative modeling leads to a theoretically grounded algorithm shortening generation time which is complementary to other proposed acceleration techniques. We extend here the Schrödinger bridge framework to conditional simulation. We demonstrate this novel methodology on various applications including image super-resolution and optimal filtering for state-space models.

</p>
</details>

<details><summary><b>The Unfairness of Active Users and Popularity Bias in Point-of-Interest Recommendation</b>
<a href="https://arxiv.org/abs/2202.13307">arxiv:2202.13307</a>
&#x1F4C8; 7 <br>
<p>Hossein A. Rahmani, Yashar Deldjoo, Ali Tourani, Mohammadmehdi Naghiaei</p></summary>
<p>

**Abstract:** Point-of-Interest (POI) recommender systems provide personalized recommendations to users and help businesses attract potential customers. Despite their success, recent studies suggest that highly data-driven recommendations could be impacted by data biases, resulting in unfair outcomes for different stakeholders, mainly consumers (users) and providers (items). Most existing fairness-related research works in recommender systems treat user fairness and item fairness issues individually, disregarding that RS work in a two-sided marketplace. This paper studies the interplay between (i) the unfairness of active users, (ii) the unfairness of popular items, and (iii) the accuracy (personalization) of recommendation as three angles of our study triangle. We group users into advantaged and disadvantaged levels to measure user fairness based on their activity level. For item fairness, we divide items into short-head, mid-tail, and long-tail groups and study the exposure of these item groups into the top-k recommendation list of users. Experimental validation of eight different recommendation models commonly used for POI recommendation (e.g., contextual, CF) on two publicly available POI recommendation datasets, Gowalla and Yelp, indicate that most well-performing models suffer seriously from the unfairness of popularity bias (provider unfairness). Furthermore, our study shows that most recommendation models cannot satisfy both consumer and producer fairness, indicating a trade-off between these variables possibly due to natural biases in data. We choose the POI recommendation as our test scenario; however, the insights should be trivially extendable on other domains.

</p>
</details>

<details><summary><b>Bayesian Active Learning for Discrete Latent Variable Models</b>
<a href="https://arxiv.org/abs/2202.13426">arxiv:2202.13426</a>
&#x1F4C8; 6 <br>
<p>Aditi Jha, Zoe C. Ashwood, Jonathan W. Pillow</p></summary>
<p>

**Abstract:** Active learning seeks to reduce the number of samples required to estimate the parameters of a model, thus forming an important class of techniques in modern machine learning. However, past work on active learning has largely overlooked latent variable models, which play a vital role in neuroscience, psychology, and a variety of other engineering and scientific disciplines. Here we address this gap in the literature and propose a novel framework for maximum-mutual-information input selection for learning discrete latent variable regression models. We first examine a class of models known as "mixtures of linear regressions" (MLR). This example is striking because it is well known that active learning confers no advantage for standard least-squares regression. However, we show -- both in simulations and analytically using Fisher information -- that optimal input selection can nevertheless provide dramatic gains for mixtures of regression models; we also validate this on a real-world application of MLRs. We then consider a powerful class of temporally structured latent variable models known as Input-Output Hidden Markov Models (IO-HMMs), which have recently gained prominence in neuroscience. We show that our method substantially speeds up learning, and outperforms a variety of approximate methods based on variational and amortized inference.

</p>
</details>

<details><summary><b>Bayesian Robust Tensor Ring Model for Incomplete Multiway Data</b>
<a href="https://arxiv.org/abs/2202.13321">arxiv:2202.13321</a>
&#x1F4C8; 6 <br>
<p>Zhenhao Huang, Guoxu Zhou, Yuning Qiu</p></summary>
<p>

**Abstract:** Low-rank tensor completion aims to recover missing entries from the observed data. However, the observed data may be disturbed by noise and outliers. Therefore, robust tensor completion (RTC) is proposed to solve this problem. The recently proposed tensor ring (TR) structure is applied to RTC due to its superior abilities in dealing with high-dimensional data with predesigned TR rank. To avoid manual rank selection and achieve a balance between low-rank component and sparse component, in this paper, we propose a Bayesian robust tensor ring (BRTR) decomposition method for RTC problem. Furthermore, we develop a variational Bayesian (VB) algorithm to infer the probability distribution of posteriors. During the learning process, the frontal slices of previous tensor and horizontal slices of latter tensor shared with the same TR rank with zero components are pruned, resulting in automatic rank determination. Compared with existing methods, BRTR can automatically learn TR rank without manual fine-tuning of parameters. Extensive experiments indicate that BRTR has better recovery performance and ability to remove noise than other state-of-the-art methods.

</p>
</details>

<details><summary><b>Limitations of Deep Learning for Inverse Problems on Digital Hardware</b>
<a href="https://arxiv.org/abs/2202.13490">arxiv:2202.13490</a>
&#x1F4C8; 5 <br>
<p>Holger Boche, Adalbert Fono, Gitta Kutyniok</p></summary>
<p>

**Abstract:** Deep neural networks have seen tremendous success over the last years. Since the training is performed on digital hardware, in this paper, we analyze what actually can be computed on current hardware platforms modeled as Turing machines, which would lead to inherent restrictions of deep learning. For this, we focus on the class of inverse problems, which, in particular, encompasses any task to reconstruct data from measurements. We prove that finite-dimensional inverse problems are not Banach-Mazur computable for small relaxation parameters. In fact, our result even holds for Borel-Turing computability., i.e., there does not exist an algorithm which performs the training of a neural network on digital hardware for any given accuracy. This establishes a conceptual barrier on the capabilities of neural networks for finite-dimensional inverse problems given that the computations are performed on digital hardware.

</p>
</details>

<details><summary><b>Application of DatasetGAN in medical imaging: preliminary studies</b>
<a href="https://arxiv.org/abs/2202.13463">arxiv:2202.13463</a>
&#x1F4C8; 5 <br>
<p>Zong Fan, Varun Kelkar, Mark A. Anastasio, Hua Li</p></summary>
<p>

**Abstract:** Generative adversarial networks (GANs) have been widely investigated for many potential applications in medical imaging. DatasetGAN is a recently proposed framework based on modern GANs that can synthesize high-quality segmented images while requiring only a small set of annotated training images. The synthesized annotated images could be potentially employed for many medical imaging applications, where images with segmentation information are required. However, to the best of our knowledge, there are no published studies focusing on its applications to medical imaging. In this work, preliminary studies were conducted to investigate the utility of DatasetGAN in medical imaging. Three improvements were proposed to the original DatasetGAN framework, considering the unique characteristics of medical images. The synthesized segmented images by DatasetGAN were visually evaluated. The trained DatasetGAN was further analyzed by evaluating the performance of a pre-defined image segmentation technique, which was trained by the use of the synthesized datasets. The effectiveness, concerns, and potential usage of DatasetGAN were discussed.

</p>
</details>

<details><summary><b>Meta-path Analysis on Spatio-Temporal Graphs for Pedestrian Trajectory Prediction</b>
<a href="https://arxiv.org/abs/2202.13427">arxiv:2202.13427</a>
&#x1F4C8; 5 <br>
<p>Aamir Hasan, Pranav Sriram, Katherine Driggs-Campbell</p></summary>
<p>

**Abstract:** Spatio-temporal graphs (ST-graphs) have been used to model time series tasks such as traffic forecasting, human motion modeling, and action recognition. The high-level structure and corresponding features from ST-graphs have led to improved performance over traditional architectures. However, current methods tend to be limited by simple features, despite the rich information provided by the full graph structure, which leads to inefficiencies and suboptimal performance in downstream tasks. We propose the use of features derived from meta-paths, walks across different types of edges, in ST-graphs to improve the performance of Structural Recurrent Neural Network. In this paper, we present the Meta-path Enhanced Structural Recurrent Neural Network (MESRNN), a generic framework that can be applied to any spatio-temporal task in a simple and scalable manner. We employ MESRNN for pedestrian trajectory prediction, utilizing these meta-path based features to capture the relationships between the trajectories of pedestrians at different points in time and space. We compare our MESRNN against state-of-the-art ST-graph methods on standard datasets to show the performance boost provided by meta-path information. The proposed model consistently outperforms the baselines in trajectory prediction over long time horizons by over 32\%, and produces more socially compliant trajectories in dense crowds. For more information please refer to the project website at https://sites.google.com/illinois.edu/mesrnn/home.

</p>
</details>

<details><summary><b>Sampling in Dirichlet Process Mixture Models for Clustering Streaming Data</b>
<a href="https://arxiv.org/abs/2202.13312">arxiv:2202.13312</a>
&#x1F4C8; 5 <br>
<p>Or Dinari, Oren Freifeld</p></summary>
<p>

**Abstract:** Practical tools for clustering streaming data must be fast enough to handle the arrival rate of the observations. Typically, they also must adapt on the fly to possible lack of stationarity; i.e., the data statistics may be time-dependent due to various forms of drifts, changes in the number of clusters, etc. The Dirichlet Process Mixture Model (DPMM), whose Bayesian nonparametric nature allows it to adapt its complexity to the data, seems a natural choice for the streaming-data case. In its classical formulation, however, the DPMM cannot capture common types of drifts in the data statistics. Moreover, and regardless of that limitation, existing methods for online DPMM inference are too slow to handle rapid data streams. In this work we propose adapting both the DPMM and a known DPMM sampling-based non-streaming inference method for streaming-data clustering. We demonstrate the utility of the proposed method on several challenging settings, where it obtains state-of-the-art results while being on par with other methods in terms of speed.

</p>
</details>

<details><summary><b>Evaluating High-Order Predictive Distributions in Deep Learning</b>
<a href="https://arxiv.org/abs/2202.13509">arxiv:2202.13509</a>
&#x1F4C8; 4 <br>
<p>Ian Osband, Zheng Wen, Seyed Mohammad Asghari, Vikranth Dwaracherla, Xiuyuan Lu, Benjamin Van Roy</p></summary>
<p>

**Abstract:** Most work on supervised learning research has focused on marginal predictions. In decision problems, joint predictive distributions are essential for good performance. Previous work has developed methods for assessing low-order predictive distributions with inputs sampled i.i.d. from the testing distribution. With low-dimensional inputs, these methods distinguish agents that effectively estimate uncertainty from those that do not. We establish that the predictive distribution order required for such differentiation increases greatly with input dimension, rendering these methods impractical. To accommodate high-dimensional inputs, we introduce \textit{dyadic sampling}, which focuses on predictive distributions associated with random \textit{pairs} of inputs. We demonstrate that this approach efficiently distinguishes agents in high-dimensional examples involving simple logistic regression as well as complex synthetic and empirical data.

</p>
</details>

<details><summary><b>Variational Interpretable Learning from Multi-view Data</b>
<a href="https://arxiv.org/abs/2202.13503">arxiv:2202.13503</a>
&#x1F4C8; 4 <br>
<p>Lin Qiu, Lynn Lin, Vernon M. Chinchilli</p></summary>
<p>

**Abstract:** The main idea of canonical correlation analysis (CCA) is to map different views onto a common latent space with maximum correlation. We propose a deep interpretable variational canonical correlation analysis (DICCA) for multi-view learning. The developed model extends the existing latent variable model for linear CCA to nonlinear models through the use of deep generative networks. DICCA is designed to disentangle both the shared and view-specific variations for multi-view data. To further make the model more interpretable, we place a sparsity-inducing prior on the latent weight with a structured variational autoencoder that is comprised of view-specific generators. Empirical results on real-world datasets show that our methods are competitive across domains.

</p>
</details>

<details><summary><b>Federated Online Sparse Decision Making</b>
<a href="https://arxiv.org/abs/2202.13448">arxiv:2202.13448</a>
&#x1F4C8; 4 <br>
<p>Chi-Hua Wang, Wenjie Li, Guang Cheng, Guang Lin</p></summary>
<p>

**Abstract:** This paper presents a novel federated linear contextual bandits model, where individual clients face different K-armed stochastic bandits with high-dimensional decision context and coupled through common global parameters. By leveraging the sparsity structure of the linear reward , a collaborative algorithm named \texttt{Fedego Lasso} is proposed to cope with the heterogeneity across clients without exchanging local decision context vectors or raw reward data. \texttt{Fedego Lasso} relies on a novel multi-client teamwork-selfish bandit policy design, and achieves near-optimal regrets for shared parameter cases with logarithmic communication costs. In addition, a new conceptual tool called federated-egocentric policies is introduced to delineate exploration-exploitation trade-off. Experiments demonstrate the effectiveness of the proposed algorithms on both synthetic and real-world datasets.

</p>
</details>

<details><summary><b>A Multimodal German Dataset for Automatic Lip Reading Systems and Transfer Learning</b>
<a href="https://arxiv.org/abs/2202.13403">arxiv:2202.13403</a>
&#x1F4C8; 4 <br>
<p>Gerald Schwiebert, Cornelius Weber, Leyuan Qu, Henrique Siqueira, Stefan Wermter</p></summary>
<p>

**Abstract:** Large datasets as required for deep learning of lip reading do not exist in many languages. In this paper we present the dataset GLips (German Lips) consisting of 250,000 publicly available videos of the faces of speakers of the Hessian Parliament, which was processed for word-level lip reading using an automatic pipeline. The format is similar to that of the English language LRW (Lip Reading in the Wild) dataset, with each video encoding one word of interest in a context of 1.16 seconds duration, which yields compatibility for studying transfer learning between both datasets. By training a deep neural network, we investigate whether lip reading has language-independent features, so that datasets of different languages can be used to improve lip reading models. We demonstrate learning from scratch and show that transfer learning from LRW to GLips and vice versa improves learning speed and performance, in particular for the validation set.

</p>
</details>

<details><summary><b>Weakly Supervised Learning for cell recognition in immunohistochemical cytoplasm staining images</b>
<a href="https://arxiv.org/abs/2202.13372">arxiv:2202.13372</a>
&#x1F4C8; 4 <br>
<p>Shichuan Zhang, Chenglu Zhu, Honglin Li, Jiatong Cai, Lin Yang</p></summary>
<p>

**Abstract:** Cell classification and counting in immunohistochemical cytoplasm staining images play a pivotal role in cancer diagnosis. Weakly supervised learning is a potential method to deal with labor-intensive labeling. However, the inconstant cell morphology and subtle differences between classes also bring challenges. To this end, we present a novel cell recognition framework based on multi-task learning, which utilizes two additional auxiliary tasks to guide robust representation learning of the main task. To deal with misclassification, the tissue prior learning branch is introduced to capture the spatial representation of tumor cells without additional tissue annotation. Moreover, dynamic masks and consistency learning are adopted to learn the invariance of cell scale and shape. We have evaluated our framework on immunohistochemical cytoplasm staining images, and the results demonstrate that our method outperforms recent cell recognition approaches. Besides, we have also done some ablation studies to show significant improvements after adding the auxiliary branches.

</p>
</details>

<details><summary><b>Data Overlap: A Prerequisite For Disentanglement</b>
<a href="https://arxiv.org/abs/2202.13341">arxiv:2202.13341</a>
&#x1F4C8; 4 <br>
<p>Nathan Michlo, Steven James, Richard Klein</p></summary>
<p>

**Abstract:** Learning disentangled representations with variational autoencoders (VAEs) is often attributed to the regularisation component of the loss. In this work, we highlight the interaction between data and the reconstruction term of the loss as the main contributor to disentanglement in VAEs. We note that standardised benchmark datasets are constructed in a way that is conducive to learning what appear to be disentangled representations. We design an intuitive adversarial dataset that exploits this mechanism to break existing state-of-the-art disentanglement frameworks. Finally, we provide solutions in the form of a modified reconstruction loss suggesting that VAEs are accidental distance learners.

</p>
</details>

<details><summary><b>Long-Tailed Classification with Gradual Balanced Loss and Adaptive Feature Generation</b>
<a href="https://arxiv.org/abs/2203.00452">arxiv:2203.00452</a>
&#x1F4C8; 3 <br>
<p>Zihan Zhang, Xiang Xiang</p></summary>
<p>

**Abstract:** The real-world data distribution is essentially long-tailed, which poses great challenge to the deep model. In this work, we propose a new method, Gradual Balanced Loss and Adaptive Feature Generator (GLAG) to alleviate imbalance. GLAG first learns a balanced and robust feature model with Gradual Balanced Loss, then fixes the feature model and augments the under-represented tail classes on the feature level with the knowledge from well-represented head classes. And the generated samples are mixed up with real training samples during training epochs. Gradual Balanced Loss is a general loss and it can combine with different decoupled training methods to improve the original performance. State-of-the-art results have been achieved on long-tail datasets such as CIFAR100-LT, ImageNetLT, and iNaturalist, which demonstrates the effectiveness of GLAG for long-tailed visual recognition.

</p>
</details>

<details><summary><b>Risk-Aware Scene Sampling for Dynamic Assurance of Autonomous Systems</b>
<a href="https://arxiv.org/abs/2202.13510">arxiv:2202.13510</a>
&#x1F4C8; 3 <br>
<p>Shreyas Ramakrishna, Baiting Luo, Yogesh Barve, Gabor Karsai, Abhishek Dubey</p></summary>
<p>

**Abstract:** Autonomous Cyber-Physical Systems must often operate under uncertainties like sensor degradation and shifts in the operating conditions, which increases its operational risk. Dynamic Assurance of these systems requires designing runtime safety components like Out-of-Distribution detectors and risk estimators, which require labeled data from different operating modes of the system that belong to scenes with adverse operating conditions, sensors, and actuator faults. Collecting real-world data of these scenes can be expensive and sometimes not feasible. So, scenario description languages with samplers like random and grid search are available to generate synthetic data from simulators, replicating these real-world scenes. However, we point out three limitations in using these conventional samplers. First, they are passive samplers, which do not use the feedback of previous results in the sampling process. Second, the variables to be sampled may have constraints that are often not included. Third, they do not balance the tradeoff between exploration and exploitation, which we hypothesize is necessary for better search space coverage. We present a scene generation approach with two samplers called Random Neighborhood Search (RNS) and Guided Bayesian Optimization (GBO), which extend the conventional random search and Bayesian Optimization search to include the limitations. Also, to facilitate the samplers, we use a risk-based metric that evaluates how risky the scene was for the system. We demonstrate our approach using an Autonomous Vehicle example in CARLA simulation. To evaluate our samplers, we compared them against the baselines of random search, grid search, and Halton sequence search. Our samplers of RNS and GBO sampled a higher percentage of high-risk scenes of 83% and 92%, compared to 56%, 66% and 71% of the grid, random and Halton samplers, respectively.

</p>
</details>

<details><summary><b>Interpretable Concept-based Prototypical Networks for Few-Shot Learning</b>
<a href="https://arxiv.org/abs/2202.13474">arxiv:2202.13474</a>
&#x1F4C8; 3 <br>
<p>Mohammad Reza Zarei, Majid Komeili</p></summary>
<p>

**Abstract:** Few-shot learning aims at recognizing new instances from classes with limited samples. This challenging task is usually alleviated by performing meta-learning on similar tasks. However, the resulting models are black-boxes. There has been growing concerns about deploying black-box machine learning models and FSL is not an exception in this regard. In this paper, we propose a method for FSL based on a set of human-interpretable concepts. It constructs a set of metric spaces associated with the concepts and classifies samples of novel classes by aggregating concept-specific decisions. The proposed method does not require concept annotations for query samples. This interpretable method achieved results on a par with six previously state-of-the-art black-box FSL methods on the CUB fine-grained bird classification dataset.

</p>
</details>

<details><summary><b>The Spectral Bias of Polynomial Neural Networks</b>
<a href="https://arxiv.org/abs/2202.13473">arxiv:2202.13473</a>
&#x1F4C8; 3 <br>
<p>Moulik Choraria, Leello Tadesse Dadi, Grigorios Chrysos, Julien Mairal, Volkan Cevher</p></summary>
<p>

**Abstract:** Polynomial neural networks (PNNs) have been recently shown to be particularly effective at image generation and face recognition, where high-frequency information is critical. Previous studies have revealed that neural networks demonstrate a $\textit{spectral bias}$ towards low-frequency functions, which yields faster learning of low-frequency components during training. Inspired by such studies, we conduct a spectral analysis of the Neural Tangent Kernel (NTK) of PNNs. We find that the $Π$-Net family, i.e., a recently proposed parametrization of PNNs, speeds up the learning of the higher frequencies. We verify the theoretical bias through extensive experiments. We expect our analysis to provide novel insights into designing architectures and learning frameworks by incorporating multiplicative interactions via polynomials.

</p>
</details>

<details><summary><b>Synergistic Network Learning and Label Correction for Noise-robust Image Classification</b>
<a href="https://arxiv.org/abs/2202.13472">arxiv:2202.13472</a>
&#x1F4C8; 3 <br>
<p>Chen Gong, Kong Bin, Eric J. Seibel, Xin Wang, Youbing Yin, Qi Song</p></summary>
<p>

**Abstract:** Large training datasets almost always contain examples with inaccurate or incorrect labels. Deep Neural Networks (DNNs) tend to overfit training label noise, resulting in poorer model performance in practice. To address this problem, we propose a robust label correction framework combining the ideas of small loss selection and noise correction, which learns network parameters and reassigns ground truth labels iteratively. Taking the expertise of DNNs to learn meaningful patterns before fitting noise, our framework first trains two networks over the current dataset with small loss selection. Based on the classification loss and agreement loss of two networks, we can measure the confidence of training data. More and more confident samples are selected for label correction during the learning process. We demonstrate our method on both synthetic and real-world datasets with different noise types and rates, including CIFAR-10, CIFAR-100 and Clothing1M, where our method outperforms the baseline approaches.

</p>
</details>

<details><summary><b>UCTopic: Unsupervised Contrastive Learning for Phrase Representations and Topic Mining</b>
<a href="https://arxiv.org/abs/2202.13469">arxiv:2202.13469</a>
&#x1F4C8; 3 <br>
<p>Jiacheng Li, Jingbo Shang, Julian McAuley</p></summary>
<p>

**Abstract:** High-quality phrase representations are essential to finding topics and related terms in documents (a.k.a. topic mining). Existing phrase representation learning methods either simply combine unigram representations in a context-free manner or rely on extensive annotations to learn context-aware knowledge. In this paper, we propose UCTopic, a novel unsupervised contrastive learning framework for context-aware phrase representations and topic mining. UCTopic is pretrained in a large scale to distinguish if the contexts of two phrase mentions have the same semantics. The key to pretraining is positive pair construction from our phrase-oriented assumptions. However, we find traditional in-batch negatives cause performance decay when finetuning on a dataset with small topic numbers. Hence, we propose cluster-assisted contrastive learning(CCL) which largely reduces noisy negatives by selecting negatives from clusters and further improves phrase representations for topics accordingly. UCTopic outperforms the state-of-the-art phrase representation model by 38.2% NMI in average on four entity cluster-ing tasks. Comprehensive evaluation on topic mining shows that UCTopic can extract coherent and diverse topical phrases.

</p>
</details>

<details><summary><b>A Unified Wasserstein Distributional Robustness Framework for Adversarial Training</b>
<a href="https://arxiv.org/abs/2202.13437">arxiv:2202.13437</a>
&#x1F4C8; 3 <br>
<p>Tuan Anh Bui, Trung Le, Quan Tran, He Zhao, Dinh Phung</p></summary>
<p>

**Abstract:** It is well-known that deep neural networks (DNNs) are susceptible to adversarial attacks, exposing a severe fragility of deep learning systems. As the result, adversarial training (AT) method, by incorporating adversarial examples during training, represents a natural and effective approach to strengthen the robustness of a DNN-based classifier. However, most AT-based methods, notably PGD-AT and TRADES, typically seek a pointwise adversary that generates the worst-case adversarial example by independently perturbing each data sample, as a way to "probe" the vulnerability of the classifier. Arguably, there are unexplored benefits in considering such adversarial effects from an entire distribution. To this end, this paper presents a unified framework that connects Wasserstein distributional robustness with current state-of-the-art AT methods. We introduce a new Wasserstein cost function and a new series of risk functions, with which we show that standard AT methods are special cases of their counterparts in our framework. This connection leads to an intuitive relaxation and generalization of existing AT methods and facilitates the development of a new family of distributional robustness AT-based algorithms. Extensive experiments show that our distributional robustness AT algorithms robustify further their standard AT counterparts in various settings.

</p>
</details>

<details><summary><b>Benign Underfitting of Stochastic Gradient Descent</b>
<a href="https://arxiv.org/abs/2202.13361">arxiv:2202.13361</a>
&#x1F4C8; 3 <br>
<p>Tomer Koren, Roi Livni, Yishay Mansour, Uri Sherman</p></summary>
<p>

**Abstract:** We study to what extent may stochastic gradient descent (SGD) be understood as a "conventional" learning rule that achieves generalization performance by obtaining a good fit to training data. We consider the fundamental stochastic convex optimization framework, where (one pass, without-replacement) SGD is classically known to minimize the population risk at rate $O(1/\sqrt n)$, and prove that, surprisingly, there exist problem instances where the SGD solution exhibits both empirical risk and generalization gap of $Ω(1)$. Consequently, it turns out that SGD is not algorithmically stable in any sense, and its generalization ability cannot be explained by uniform convergence or any other currently known generalization bound technique for that matter (other than that of its classical analysis). We then continue to analyze the closely related with-replacement SGD, for which we show that an analogous phenomenon does not occur and prove that its population risk does in fact converge at the optimal rate. Finally, we interpret our main results in the context of without-replacement SGD for finite-sum convex optimization problems, and derive upper and lower bounds for the multi-epoch regime that significantly improve upon previously known results.

</p>
</details>

<details><summary><b>HiCLRE: A Hierarchical Contrastive Learning Framework for Distantly Supervised Relation Extraction</b>
<a href="https://arxiv.org/abs/2202.13352">arxiv:2202.13352</a>
&#x1F4C8; 3 <br>
<p>Dongyang Li, Taolin Zhang, Nan Hu, Chengyu Wang, Xiaofeng He</p></summary>
<p>

**Abstract:** Distant supervision assumes that any sentence containing the same entity pairs reflects identical relationships. Previous works of distantly supervised relation extraction (DSRE) task generally focus on sentence-level or bag-level de-noising techniques independently, neglecting the explicit interaction with cross levels. In this paper, we propose a hierarchical contrastive learning Framework for Distantly Supervised relation extraction (HiCLRE) to reduce noisy sentences, which integrate the global structural information and local fine-grained interaction. Specifically, we propose a three-level hierarchical learning framework to interact with cross levels, generating the de-noising context-aware representations via adapting the existing multi-head self-attention, named Multi-Granularity Recontextualization. Meanwhile, pseudo positive samples are also provided in the specific level for contrastive learning via a dynamic gradient-based data augmentation strategy, named Dynamic Gradient Adversarial Perturbation. Experiments demonstrate that HiCLRE significantly outperforms strong baselines in various mainstream DSRE datasets.

</p>
</details>

<details><summary><b>Split HE: Fast Secure Inference Combining Split Learning and Homomorphic Encryption</b>
<a href="https://arxiv.org/abs/2202.13351">arxiv:2202.13351</a>
&#x1F4C8; 3 <br>
<p>George-Liviu Pereteanu, Amir Alansary, Jonathan Passerat-Palmbach</p></summary>
<p>

**Abstract:** This work presents a novel protocol for fast secure inference of neural networks applied to computer vision applications. It focuses on improving the overall performance of the online execution by deploying a subset of the model weights in plaintext on the client's machine, in the fashion of SplitNNs. We evaluate our protocol on benchmark neural networks trained on the CIFAR-10 dataset using SEAL via TenSEAL and discuss runtime and security performances. Empirical security evaluation using Membership Inference and Model Extraction attacks showed that the protocol was more resilient under the same attacks than a similar approach also based on SplitNN. When compared to related work, we demonstrate improvements of 2.5x-10x for the inference time and 14x-290x in communication costs.

</p>
</details>

<details><summary><b>LobsDICE: Offline Imitation Learning from Observation via Stationary Distribution Correction Estimation</b>
<a href="https://arxiv.org/abs/2202.13536">arxiv:2202.13536</a>
&#x1F4C8; 2 <br>
<p>Geon-Hyeong Kim, Jongmin Lee, Youngsoo Jang, Hongseok Yang, Kee-Eung Kim</p></summary>
<p>

**Abstract:** We consider the problem of imitation from observation (IfO), in which the agent aims to mimic the expert's behavior from the state-only demonstrations by experts. We additionally assume that the agent cannot interact with the environment but has access to the action-labeled transition data collected by some agent with unknown quality. This offline setting for IfO is appealing in many real-world scenarios where the ground-truth expert actions are inaccessible and the arbitrary environment interactions are costly or risky. In this paper, we present LobsDICE, an offline IfO algorithm that learns to imitate the expert policy via optimization in the space of stationary distributions. Our algorithm solves a single convex minimization problem, which minimizes the divergence between the two state-transition distributions induced by the expert and the agent policy. On an extensive set of offline IfO tasks, LobsDICE shows promising results, outperforming strong baseline algorithms.

</p>
</details>

<details><summary><b>CTformer: Convolution-free Token2Token Dilated Vision Transformer for Low-dose CT Denoising</b>
<a href="https://arxiv.org/abs/2202.13517">arxiv:2202.13517</a>
&#x1F4C8; 2 <br>
<p>Dayang Wang, Fenglei Fan, Zhan Wu, Rui Liu, Fei Wang, Hengyong Yu</p></summary>
<p>

**Abstract:** Low-dose computed tomography (LDCT) denoising is an important problem in CT research. Compared to the normal dose CT (NDCT), LDCT images are subjected to severe noise and artifacts. Recently in many studies, vision transformers have shown superior feature representation ability over convolutional neural networks (CNNs). However, unlike CNNs, the potential of vision transformers in LDCT denoising was little explored so far. To fill this gap, we propose a Convolution-free Token2Token Dilated Vision Transformer for low-dose CT denoising. The CTformer uses a more powerful token rearrangement to encompass local contextual information and thus avoids convolution. It also dilates and shifts feature maps to capture longer-range interaction. We interpret the CTformer by statically inspecting patterns of its internal attention maps and dynamically tracing the hierarchical attention flow with an explanatory graph. Furthermore, an overlapped inference mechanism is introduced to effectively eliminate the boundary artifacts that are common for encoder-decoder-based denoising models. Experimental results on Mayo LDCT dataset suggest that the CTformer outperforms the state-of-the-art denoising methods with a low computation overhead.

</p>
</details>

<details><summary><b>Keyword Optimization in Sponsored Search Advertising: A Multi-Level Computational Framework</b>
<a href="https://arxiv.org/abs/2202.13506">arxiv:2202.13506</a>
&#x1F4C8; 2 <br>
<p>Yanwu Yang, Bernard J. Jansen, Yinghui Yang, Xunhua Guo, Daniel Zeng</p></summary>
<p>

**Abstract:** In sponsored search advertising, keywords serve as an essential bridge linking advertisers, search users and search engines. Advertisers have to deal with a series of keyword decisions throughout the entire lifecycle of search advertising campaigns. This paper proposes a multi-level and closed-form computational framework for keyword optimization (MKOF) to support various keyword decisions. Based on this framework, we develop corresponding optimization strategies for keyword targeting, keyword assignment and keyword grouping at different levels (e.g., market, campaign and adgroup). With two real-world datasets obtained from past search advertising campaigns, we conduct computational experiments to evaluate our keyword optimization framework and instantiated strategies. Experimental results show that our method can approach the optimal solution in a steady way, and it outperforms two baseline keyword strategies commonly used in practice. The proposed MKOF framework also provides a valid experimental environment to implement and assess various keyword strategies in sponsored search advertising.

</p>
</details>

<details><summary><b>Machine learning techniques to identify antibiotic resistance in patients diagnosed with various skin and soft tissue infections</b>
<a href="https://arxiv.org/abs/2202.13496">arxiv:2202.13496</a>
&#x1F4C8; 2 <br>
<p>Farnaz H. Foomani, Shahzad Mirza, Sahjid Mukhida, Kannuri Sriram, Zeyun Yu, Aayush Gupta, Sandeep Gopalakrishnan</p></summary>
<p>

**Abstract:** Skin and soft tissue infections (SSTIs) are among the most frequently observed diseases in ambulatory and hospital settings. Resistance of diverse bacterial pathogens to antibiotics is a significant cause of severe SSTIs, and treatment failure results in morbidity, mortality, and increased cost of hospitalization. Therefore, antimicrobial surveillance is essential to predict antibiotic resistance trends and monitor the results of medical interventions. To address this, we developed machine learning (ML) models (deep and conventional algorithms) to predict antimicrobial resistance using antibiotic susceptibility testing (ABST) data collected from patients clinically diagnosed with primary and secondary pyoderma over a period of one year. We trained an individual ML algorithm on each antimicrobial family to determine whether a Gram-Positive Cocci (GPC) or Gram-Negative Bacilli (GNB) bacteria will resist the corresponding antibiotic. For this purpose, clinical and demographic features from the patient and data from ABST were employed in training. We achieved an Area Under the Curve (AUC) of 0.68-0.98 in GPC and 0.56-0.93 in GNB bacteria, depending on the antimicrobial family. We also conducted a correlation analysis to determine the linear relationship between each feature and antimicrobial families in different bacteria. ML techniques suggest that a predictable nonlinear relationship exists between patients' clinical-demographic characteristics and antibiotic resistance; however, the accuracy of this prediction depends on the type of the antimicrobial family.

</p>
</details>

<details><summary><b>PARIS and ELSA: An Elastic Scheduling Algorithm for Reconfigurable Multi-GPU Inference Servers</b>
<a href="https://arxiv.org/abs/2202.13481">arxiv:2202.13481</a>
&#x1F4C8; 2 <br>
<p>Yunseong Kim, Yujeong Choi, Minsoo Rhu</p></summary>
<p>

**Abstract:** In cloud machine learning (ML) inference systems, providing low latency to end-users is of utmost importance. However, maximizing server utilization and system throughput is also crucial for ML service providers as it helps lower the total-cost-of-ownership. GPUs have oftentimes been criticized for ML inference usages as its massive compute and memory throughput is hard to be fully utilized under low-batch inference scenarios. To address such limitation, NVIDIA's recently announced Ampere GPU architecture provides features to "reconfigure" one large, monolithic GPU into multiple smaller "GPU partitions". Such feature provides cloud ML service providers the ability to utilize the reconfigurable GPU not only for large-batch training but also for small-batch inference with the potential to achieve high resource utilization. In this paper, we study this emerging GPU architecture with reconfigurability to develop a high-performance multi-GPU ML inference server. Our first proposition is a sophisticated partitioning algorithm for reconfigurable GPUs that systematically determines a heterogeneous set of multi-granular GPU partitions, best suited for the inference server's deployment. Furthermore, we co-design an elastic scheduling algorithm tailored for our heterogeneously partitioned GPU server which effectively balances low latency and high GPU utilization.

</p>
</details>

<details><summary><b>PheroCom: Decentralised and asynchronous swarm robotics coordination based on virtual pheromone and vibroacoustic communication</b>
<a href="https://arxiv.org/abs/2202.13456">arxiv:2202.13456</a>
&#x1F4C8; 2 <br>
<p>Claudiney R. Tinoco, Gina M. B. Oliveira</p></summary>
<p>

**Abstract:** Representation and control of the dynamics of stigmergic substances used by bio-inspired approaches is a challenge when applied to robotics. In order to overcome this challenge, this work proposes a model to coordinate swarms of robots based on the virtualisation and control of these substances in a local scope. The model presents a new pheromone modelling, which enables the decentralisation and asynchronicity of navigation decisions. Each robot maintains an independent virtual pheromone map, which is continuously updated with the robot's deposits and pheromone evaporation. Moreover, the individual pheromone map is also updated by aggregating information from other robots that are exploring nearby areas. Thus, individual and independent maps replace the need of a centralising agent that controls and distributes the pheromone information, which is not always practicable. Pheromone information propagation is inspired by ants' vibroacoustic communication, which, in turn, is characterised as an indirect communication through a type of gossip protocol. The proposed model was evaluated through an agent simulation software, implemented by the authors, and in the Webots platform. Experiments were carried out to validate the model in different environments, with different shapes and sizes, as well as varying the number of robots. The analysis of the results has shown that the model was able to perform the coordination of the swarm, and the robots have exhibited an expressive performance executing the surveillance task.

</p>
</details>

<details><summary><b>The Unfairness of Popularity Bias in Book Recommendation</b>
<a href="https://arxiv.org/abs/2202.13446">arxiv:2202.13446</a>
&#x1F4C8; 2 <br>
<p>Mohammadmehdi Naghiaei, Hossein A. Rahmani, Mahdi Dehghan</p></summary>
<p>

**Abstract:** Recent studies have shown that recommendation systems commonly suffer from popularity bias. Popularity bias refers to the problem that popular items (i.e., frequently rated items) are recommended frequently while less popular items are recommended rarely or not at all. Researchers adopted two approaches to examining popularity bias: (i) from the users' perspective, by analyzing how far a recommendation system deviates from user's expectations in receiving popular items, and (ii) by analyzing the amount of exposure that long-tail items receive, measured by overall catalog coverage and novelty. In this paper, we examine the first point of view in the book domain, although the findings may be applied to other domains as well. To this end, we analyze the well-known Book-Crossing dataset and define three user groups based on their tendency towards popular items (i.e., Niche, Diverse, Bestseller-focused). Further, we evaluate the performance of nine state-of-the-art recommendation algorithms and two baselines (i.e., Random, MostPop) from both the accuracy (e.g., NDCG, Precision, Recall) and popularity bias perspectives. Our results indicate that most state-of-the-art recommendation algorithms suffer from popularity bias in the book domain, and fail to meet users' expectations with Niche and Diverse tastes despite having a larger profile size. Conversely, Bestseller-focused users are more likely to receive high-quality recommendations, both in terms of fairness and personalization. Furthermore, our study shows a tradeoff between personalization and unfairness of popularity bias in recommendation algorithms for users belonging to the Diverse and Bestseller groups, that is, algorithms with high capability of personalization suffer from the unfairness of popularity bias.

</p>
</details>

<details><summary><b>Neural-Progressive Hedging: Enforcing Constraints in Reinforcement Learning with Stochastic Programming</b>
<a href="https://arxiv.org/abs/2202.13436">arxiv:2202.13436</a>
&#x1F4C8; 2 <br>
<p>Supriyo Ghosh, Laura Wynter, Shiau Hong Lim, Duc Thien Nguyen</p></summary>
<p>

**Abstract:** We propose a framework, called neural-progressive hedging (NP), that leverages stochastic programming during the online phase of executing a reinforcement learning (RL) policy. The goal is to ensure feasibility with respect to constraints and risk-based objectives such as conditional value-at-risk (CVaR) during the execution of the policy, using probabilistic models of the state transitions to guide policy adjustments. The framework is particularly amenable to the class of sequential resource allocation problems since feasibility with respect to typical resource constraints cannot be enforced in a scalable manner. The NP framework provides an alternative that adds modest overhead during the online phase. Experimental results demonstrate the efficacy of the NP framework on two continuous real-world tasks: (i) the portfolio optimization problem with liquidity constraints for financial planning, characterized by non-stationary state distributions; and (ii) the dynamic repositioning problem in bike sharing systems, that embodies the class of supply-demand matching problems. We show that the NP framework produces policies that are better than deep RL and other baseline approaches, adapting to non-stationarity, whilst satisfying structural constraints and accommodating risk measures in the resulting policies. Additional benefits of the NP framework are ease of implementation and better explainability of the policies.

</p>
</details>

<details><summary><b>Distribution Preserving Graph Representation Learning</b>
<a href="https://arxiv.org/abs/2202.13428">arxiv:2202.13428</a>
&#x1F4C8; 2 <br>
<p>Chengsheng Mao, Yuan Luo</p></summary>
<p>

**Abstract:** Graph neural network (GNN) is effective to model graphs for distributed representations of nodes and an entire graph. Recently, research on the expressive power of GNN attracted growing attention. A highly-expressive GNN has the ability to generate discriminative graph representations. However, in the end-to-end training process for a certain graph learning task, a highly-expressive GNN risks generating graph representations overfitting the training data for the target task, while losing information important for the model generalization. In this paper, we propose Distribution Preserving GNN (DP-GNN) - a GNN framework that can improve the generalizability of expressive GNN models by preserving several kinds of distribution information in graph representations and node representations. Besides the generalizability, by applying an expressive GNN backbone, DP-GNN can also have high expressive power. We evaluate the proposed DP-GNN framework on multiple benchmark datasets for graph classification tasks. The experimental results demonstrate that our model achieves state-of-the-art performances.

</p>
</details>

<details><summary><b>Dual-Branched Spatio-temporal Fusion Network for Multi-horizon Tropical Cyclone Track Forecast</b>
<a href="https://arxiv.org/abs/2202.13336">arxiv:2202.13336</a>
&#x1F4C8; 2 <br>
<p>Zili Liu, Kun Hao, Xiaoyi Geng, Zhenwei Shi</p></summary>
<p>

**Abstract:** Tropical cyclone (TC) is an extreme tropical weather system and its trajectory can be described by a variety of spatio-temporal data. Effective mining of these data is the key to accurate TCs track forecasting. However, existing methods face the problem that the model complexity is too high or it is difficult to efficiently extract features from multi-modal data. In this paper, we propose the Dual-Branched spatio-temporal Fusion Network (DBF-Net) -- a novel multi-horizon tropical cyclone track forecasting model which fuses the multi-modal features efficiently. DBF-Net contains a TC features branch that extracts temporal features from 1D inherent features of TCs and a pressure field branch that extracts spatio-temporal features from reanalysis 2D pressure field. Through the encoder-decoder-based architecture and efficient feature fusion, DBF-Net can fully mine the information of the two types of data, and achieve good TCs track prediction results. Extensive experiments on historical TCs track data in the Northwest Pacific show that our DBF-Net achieves significant improvement compared with existing statistical and deep learning TCs track forecast methods.

</p>
</details>

<details><summary><b>Topology-Preserving Segmentation Network: A Deep Learning Segmentation Framework for Connected Component</b>
<a href="https://arxiv.org/abs/2202.13331">arxiv:2202.13331</a>
&#x1F4C8; 2 <br>
<p>Han Zhang, Lok Ming Lui</p></summary>
<p>

**Abstract:** Medical image segmentation, which aims to automatically extract anatomical or pathological structures, plays a key role in computer-aided diagnosis and disease analysis. Despite the problem has been widely studied, existing methods are prone to topological errors. In medical imaging, the topology of the structure, such as the kidney or lung, is usually known. Preserving the topology of the structure in the segmentation process is of utmost importance for accurate image analysis. In this work, a novel learning-based segmentation model is proposed. A {\it topology-preserving segmentation network (TPSN)} is trained to give an accurate segmentation result of an input image that preserves the prescribed topology. TPSN is a deformation-based model that yields a deformation map through a UNet, which takes the medical image and a template mask as inputs. The main idea is to deform a template mask describing the prescribed topology by a diffeomorphism to segment the object in the image. The topology of the shape in the template mask is well preserved under the diffeomorphic map. The diffeomorphic property of the map is controlled by introducing a regularization term related to the Jacobian in the loss function. As such, a topology-preserving segmentation result can be guaranteed. Furthermore, a multi-scale TPSN is developed in this paper that incorporates multi-level information of images to produce more precise segmentation results. To evaluate our method, we applied the 2D TPSN on Ham10000 and 3D TPSN on KiTS21. Experimental results illustrate our method outperforms the baseline UNet segmentation model with/without connected-component analysis (CCA) by both the dice score and IoU score. Besides, results show that our method can produce reliable results even in challenging cases, where pixel-wise segmentation models by UNet and CCA fail to obtain accurate results.

</p>
</details>

<details><summary><b>DXM-TransFuse U-net: Dual Cross-Modal Transformer Fusion U-net for Automated Nerve Identification</b>
<a href="https://arxiv.org/abs/2202.13304">arxiv:2202.13304</a>
&#x1F4C8; 2 <br>
<p>Baijun Xie, Gary Milam, Bo Ning, Jaepyeong Cha, Chung Hyuk Park</p></summary>
<p>

**Abstract:** Accurate nerve identification is critical during surgical procedures for preventing any damages to nerve tissues. Nerve injuries can lead to long-term detrimental effects for patients as well as financial overburdens. In this study, we develop a deep-learning network framework using the U-Net architecture with a Transformer block based fusion module at the bottleneck to identify nerve tissues from a multi-modal optical imaging system. By leveraging and extracting the feature maps of each modality independently and using each modalities information for cross-modal interactions, we aim to provide a solution that would further increase the effectiveness of the imaging systems for enabling the noninvasive intraoperative nerve identification.

</p>
</details>

<details><summary><b>DAGAM: A Domain Adversarial Graph Attention Model for Subject Independent EEG-Based Emotion Recognition</b>
<a href="https://arxiv.org/abs/2202.12948">arxiv:2202.12948</a>
&#x1F4C8; 2 <br>
<p>Tao Xu, Wang Dang, Jiabao Wang, Yun Zhou</p></summary>
<p>

**Abstract:** One of the most significant challenges of EEG-based emotion recognition is the cross-subject EEG variations, leading to poor performance and generalizability. This paper proposes a novel EEG-based emotion recognition model called the domain adversarial graph attention model (DAGAM). The basic idea is to generate a graph to model multichannel EEG signals using biological topology. Graph theory can topologically describe and analyze relationships and mutual dependency between channels of EEG. Then, unlike other graph convolutional networks, self-attention pooling is applied to benefit salient EEG feature extraction from the graph, which effectively improves the performance. Finally, after graph pooling, the domain adversarial based on the graph is employed to identify and handle EEG variation across subjects, efficiently reaching good generalizability. We conduct extensive evaluations on two benchmark datasets (SEED and SEED IV) and obtain state-of-the-art results in subject-independent emotion recognition. Our model boosts the SEED accuracy to 92.59% (4.69% improvement) with the lowest standard deviation of 3.21% (2.92% decrements) and SEED IV accuracy to 80.74% (6.90% improvement) with the lowest standard deviation of 4.14% (3.88% decrements) respectively.

</p>
</details>

<details><summary><b>Anti-Malware Sandbox Games</b>
<a href="https://arxiv.org/abs/2202.13520">arxiv:2202.13520</a>
&#x1F4C8; 1 <br>
<p>Sujoy Sikdar, Sikai Ruan, Qishen Han, Paween Pitimanaaree, Jeremy Blackthorne, Bulent Yener, Lirong Xia</p></summary>
<p>

**Abstract:** We develop a game theoretic model of malware protection using the state-of-the-art sandbox method, to characterize and compute optimal defense strategies for anti-malware. We model the strategic interaction between developers of malware (M) and anti-malware (AM) as a two player game, where AM commits to a strategy of generating sandbox environments, and M responds by choosing to either attack or hide malicious activity based on the environment it senses. We characterize the condition for AM to protect all its machines, and identify conditions under which an optimal AM strategy can be computed efficiently. For other cases, we provide a quadratically constrained quadratic program (QCQP)-based optimization framework to compute the optimal AM strategy. In addition, we identify a natural and easy to compute strategy for AM, which as we show empirically, achieves AM utility that is close to the optimal AM utility, in equilibrium.

</p>
</details>

<details><summary><b>ONE-NAS: An Online NeuroEvolution based Neural Architecture Search for Time Series Forecasting</b>
<a href="https://arxiv.org/abs/2202.13471">arxiv:2202.13471</a>
&#x1F4C8; 1 <br>
<p>Zimeng Lyu, Travis Desell</p></summary>
<p>

**Abstract:** Time series forecasting (TSF) is one of the most important tasks in data science, as accurate time series (TS) predictions can drive and advance a wide variety of domains including finance, transportation, health care, and power systems. However, real-world utilization of machine learning (ML) models for TSF suffers due to pretrained models being able to learn and adapt to unpredictable patterns as previously unseen data arrives over longer time scales. To address this, models must be periodically retained or redesigned, which takes significant human and computational resources. This work presents the Online NeuroEvolution based Neural Architecture Search (ONE-NAS) algorithm, which to the authors' knowledge is the first neural architecture search algorithm capable of automatically designing and training new recurrent neural networks (RNNs) in an online setting. Without any pretraining, ONE-NAS utilizes populations of RNNs which are continuously updated with new network structures and weights in response to new multivariate input data. ONE-NAS is tested on real-world large-scale multivariate wind turbine data as well a univariate Dow Jones Industrial Average (DJIA) dataset, and is shown to outperform traditional statistical time series forecasting, including naive, moving average, and exponential smoothing methods, as well as state of the art online ARIMA strategies.

</p>
</details>

<details><summary><b>Arrhythmia Classifier Using Convolutional Neural Network with Adaptive Loss-aware Multi-bit Networks Quantization</b>
<a href="https://arxiv.org/abs/2202.12943">arxiv:2202.12943</a>
&#x1F4C8; 1 <br>
<p>Hanshi Sun, Ao Wang, Ninghao Pu, Zhiqing Li, Junguang Huang, Hao Liu, Zhi Qi</p></summary>
<p>

**Abstract:** Cardiovascular disease (CVDs) is one of the universal deadly diseases, and the detection of it in the early stage is a challenging task to tackle. Recently, deep learning and convolutional neural networks have been employed widely for the classification of objects. Moreover, it is promising that lots of networks can be deployed on wearable devices. An increasing number of methods can be used to realize ECG signal classification for the sake of arrhythmia detection. However, the existing neural networks proposed for arrhythmia detection are not hardware-friendly enough due to a remarkable quantity of parameters resulting in memory and power consumption.
  In this paper, we present a 1-D adaptive loss-aware quantization, achieving a high compression rate that reduces memory consumption by 23.36 times. In order to adapt to our compression method, we need a smaller and simpler network. We propose a 17 layer end-to-end neural network classifier to classify 17 different rhythm classes trained on the MIT-BIH dataset, realizing a classification accuracy of 93.5%, which is higher than most existing methods. Due to the adaptive bitwidth method making important layers get more attention and offered a chance to prune useless parameters, the proposed quantization method avoids accuracy degradation. It even improves the accuracy rate, which is 95.84%, 2.34% higher than before. Our study achieves a 1-D convolutional neural network with high performance and low resources consumption, which is hardware-friendly and illustrates the possibility of deployment on wearable devices to realize a real-time arrhythmia diagnosis.

</p>
</details>

<details><summary><b>Pattern Based Multivariable Regression using Deep Learning (PBMR-DP)</b>
<a href="https://arxiv.org/abs/2202.13541">arxiv:2202.13541</a>
&#x1F4C8; 0 <br>
<p>Jiztom Kavalakkatt Francis, Chandan Kumar, Jansel Hererra-Garena, Kundan Kumar, Matthew J Darr</p></summary>
<p>

**Abstract:** We propose a deep learning methodology for multivariate regression that is based on pattern recognition that triggers fast learning over sensor data. We used a conversion of sensors-to-image which enables us to take advantage of Computer Vision architectures and training processes. In addition to this data preparation methodology, we explore the use of state-of-the-art architectures to generate regression outputs to predict agricultural crop continuous yield information. Finally, we compare with some of the top models reported in MLCAS2021. We found that using a straightforward training process, we were able to accomplish an MAE of 4.394, RMSE of 5.945, and R^2 of 0.861.

</p>
</details>


{% endraw %}
Prev: [2022.02.26]({{ '/2022/02/26/2022.02.26.html' | relative_url }})  Next: [2022.02.28]({{ '/2022/02/28/2022.02.28.html' | relative_url }})