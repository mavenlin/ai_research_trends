## Summary for 2021-05-22, created on 2021-12-21


<details><summary><b>Sockpuppet Detection: a Telegram case study</b>
<a href="https://arxiv.org/abs/2105.10799">arxiv:2105.10799</a>
&#x1F4C8; 9 <br>
<p>Gabriele Pisciotta, Miriana Somenzi, Elisa Barisani, Giulio Rossetti</p></summary>
<p>

**Abstract:** In Online Social Networks (OSN) numerous are the cases in which users create multiple accounts that publicly seem to belong to different people but are actually fake identities of the same person. These fictitious characters can be exploited to carry out abusive behaviors such as manipulating opinions, spreading fake news and disturbing other users. In literature this problem is known as the Sockpuppet problem. In our work we focus on Telegram, a wide-spread instant messaging application, often known for its exploitation by members of organized crime and terrorism, and more in general for its high presence of people who have offensive behaviors.

</p>
</details>

<details><summary><b>Inclusion of Domain-Knowledge into GNNs using Mode-Directed Inverse Entailment</b>
<a href="https://arxiv.org/abs/2105.10709">arxiv:2105.10709</a>
&#x1F4C8; 8 <br>
<p>Tirtharaj Dash, Ashwin Srinivasan, A Baskar</p></summary>
<p>

**Abstract:** We present a general technique for constructing Graph Neural Networks (GNNs) capable of using multi-relational domain knowledge. The technique is based on mode-directed inverse entailment (MDIE) developed in Inductive Logic Programming (ILP). Given a data instance $e$ and background knowledge $B$, MDIE identifies a most-specific logical formula $\bot_B(e)$ that contains all the relational information in $B$ that is related to $e$. We represent $\bot_B(e)$ by a "bottom-graph" that can be converted into a form suitable for GNN implementations. This transformation allows a principled way of incorporating generic background knowledge into GNNs: we use the term `BotGNN' for this form of graph neural networks. For several GNN variants, using real-world datasets with substantial background knowledge, we show that BotGNNs perform significantly better than both GNNs without background knowledge and a recently proposed simplified technique for including domain knowledge into GNNs. We also provide experimental evidence comparing BotGNNs favourably to multi-layer perceptrons (MLPs) that use features representing a "propositionalised" form of the background knowledge; and BotGNNs to a standard ILP based on the use of most-specific clauses. Taken together, these results point to BotGNNs as capable of combining the computational efficacy of GNNs with the representational versatility of ILP.

</p>
</details>

<details><summary><b>Learning Baseline Values for Shapley Values</b>
<a href="https://arxiv.org/abs/2105.10719">arxiv:2105.10719</a>
&#x1F4C8; 7 <br>
<p>Jie Ren, Zhanpeng Zhou, Qirui Chen, Quanshi Zhang</p></summary>
<p>

**Abstract:** This paper aims to formulate the problem of estimating the optimal baseline values for the Shapley value in game theory. The Shapley value measures the attribution of each input variable of a complex model, which is computed as the marginal benefit from the presence of this variable w.r.t.its absence under different contexts. To this end, people usually set the input variable to its baseline value to represent the absence of this variable (i.e.the no-signal state of this variable). Previous studies usually determine the baseline values in an empirical manner, which hurts the trustworthiness of the Shapley value. In this paper, we revisit the feature representation of a deep model from the perspective of game theory, and define the multi-variate interaction patterns of input variables to define the no-signal state of an input variable. Based on the multi-variate interaction, we learn the optimal baseline value of each input variable. Experimental results have demonstrated the effectiveness of our method.

</p>
</details>

<details><summary><b>Orthogonal Ensemble Networks for Biomedical Image Segmentation</b>
<a href="https://arxiv.org/abs/2105.10827">arxiv:2105.10827</a>
&#x1F4C8; 6 <br>
<p>Agostina J. Larrazabal, César Martínez, Jose Dolz, Enzo Ferrante</p></summary>
<p>

**Abstract:** Despite the astonishing performance of deep-learning based approaches for visual tasks such as semantic segmentation, they are known to produce miscalibrated predictions, which could be harmful for critical decision-making processes. Ensemble learning has shown to not only boost the performance of individual models but also reduce their miscalibration by averaging independent predictions. In this scenario, model diversity has become a key factor, which facilitates individual models converging to different functional solutions. In this work, we introduce Orthogonal Ensemble Networks (OEN), a novel framework to explicitly enforce model diversity by means of orthogonal constraints. The proposed method is based on the hypothesis that inducing orthogonality among the constituents of the ensemble will increase the overall model diversity. We resort to a new pairwise orthogonality constraint which can be used to regularize a sequential ensemble training process, resulting on improved predictive performance and better calibrated model outputs. We benchmark the proposed framework in two challenging brain lesion segmentation tasks --brain tumor and white matter hyper-intensity segmentation in MR images. The experimental results show that our approach produces more robust and well-calibrated ensemble models and can deal with challenging tasks in the context of biomedical image segmentation.

</p>
</details>

<details><summary><b>Denoising Noisy Neural Networks: A Bayesian Approach with Compensation</b>
<a href="https://arxiv.org/abs/2105.10699">arxiv:2105.10699</a>
&#x1F4C8; 6 <br>
<p>Yulin Shao, Soung Chang Liew, Deniz Gunduz</p></summary>
<p>

**Abstract:** Deep neural networks (DNNs) with noisy weights, which we refer to as noisy neural networks (NoisyNNs), arise from the training and inference of DNNs in the presence of noise. NoisyNNs emerge in many new applications, including the wireless transmission of DNNs, the efficient deployment or storage of DNNs in analog devices, and the truncation or quantization of DNN weights. This paper studies a fundamental problem of NoisyNNs: how to reconstruct the DNN weights from their noisy manifestations. While all prior works relied on the maximum likelihood (ML) estimation, this paper puts forth a denoising approach to reconstruct DNNs with the aim of maximizing the inference accuracy of the reconstructed models. The superiority of our denoiser is rigorously proven in two small-scale problems, wherein we consider a quadratic neural network function and a shallow feedforward neural network, respectively. When applied to advanced learning tasks with modern DNN architectures, our denoiser exhibits significantly better performance than the ML estimator. Consider the average test accuracy of the denoised DNN model versus the weight variance to noise power ratio (WNR) performance. When denoising a noisy BERT model arising from noisy inference, our denoiser outperforms ML estimation by 1.1 dB to achieve a test accuracy of 75%. When denoising a noisy ResNet18 model arising from noisy training, our denoiser outperforms ML estimation by 13.4 dB and 8.3 dB to achieve a test accuracy of 60% and 80%, respectively.

</p>
</details>

<details><summary><b>Universal set of Observables for the Koopman Operator through Causal Embedding</b>
<a href="https://arxiv.org/abs/2105.10759">arxiv:2105.10759</a>
&#x1F4C8; 3 <br>
<p>G Manjunath, A de Clercq</p></summary>
<p>

**Abstract:** Obtaining repeated measurements through observables of underlying physical and natural systems to build dynamical models is engraved in modern science. A key to the success of such methods is that the dynamics in the observed space can often be described by a map that has much lower functional complexity than the one that describes the unknown underlying system. Finding observables that can empirically reduce the functional complexity of the map to be learned, and at the same time, theoretically guarantee exact reconstruction in the new phase space is an open challenge. Here, we determine a set of observables for the Koopman operator of the inverse-limit system of a dynamical system that guarantees exact reconstruction of the underlying dynamical system. Similar to the delay coordinate maps being universal observables in Takens delay embedding, the observables we determine are universal, and hence do not need to be changed while the underlying system is changed. They are determined by a class of driven systems that are comparable to those used in reservoir computing, but which also can causally embed a dynamical system, a phenomenon which we newly describe. Dynamics in the observed space is then shown to be topologically conjugate to the underlying system. Deep learning methods can be used to learn accurate equations from data as a consequence of the topological conjugacy. Besides stability, amenability for hardware implementations, causal embedding-based models provide long-term consistency even for systems that have failed with previously reported data-driven or machine learning methods.

</p>
</details>

<details><summary><b>MIASSR: An Approach for Medical Image Arbitrary Scale Super-Resolution</b>
<a href="https://arxiv.org/abs/2105.10738">arxiv:2105.10738</a>
&#x1F4C8; 3 <br>
<p>Jin Zhu, Chuan Tan, Junwei Yang, Guang Yang, Pietro Lio'</p></summary>
<p>

**Abstract:** Single image super-resolution (SISR) aims to obtain a high-resolution output from one low-resolution image. Currently, deep learning-based SISR approaches have been widely discussed in medical image processing, because of their potential to achieve high-quality, high spatial resolution images without the cost of additional scans. However, most existing methods are designed for scale-specific SR tasks and are unable to generalise over magnification scales. In this paper, we propose an approach for medical image arbitrary-scale super-resolution (MIASSR), in which we couple meta-learning with generative adversarial networks (GANs) to super-resolve medical images at any scale of magnification in (1, 4]. Compared to state-of-the-art SISR algorithms on single-modal magnetic resonance (MR) brain images (OASIS-brains) and multi-modal MR brain images (BraTS), MIASSR achieves comparable fidelity performance and the best perceptual quality with the smallest model size. We also employ transfer learning to enable MIASSR to tackle SR tasks of new medical modalities, such as cardiac MR images (ACDC) and chest computed tomography images (COVID-CT). The source code of our work is also public. Thus, MIASSR has the potential to become a new foundational pre-/post-processing step in clinical image analysis tasks such as reconstruction, image quality enhancement, and segmentation.

</p>
</details>

<details><summary><b>Transparent Model of Unabridged Data (TMUD)</b>
<a href="https://arxiv.org/abs/2106.07558">arxiv:2106.07558</a>
&#x1F4C8; 2 <br>
<p>Jie Xu, Min Ding</p></summary>
<p>

**Abstract:** Recent advancements in computational power and algorithms have enabled unabridged data (e.g., raw images or audio) to be used as input in some models (e.g., deep learning). However, the black box nature of such models reduces their likelihood of adoption by marketing scholars. Our paradigm of analysis, the Transparent Model of Unabridged Data (TMUD), enables researchers to investigate the inner workings of such black box models by incorporating an ex ante filtration module and an ex post experimentation module. We empirically demonstrate the TMUD by investigating the role of facial components and sexual dimorphism in face perceptions, which have implications for four marketing contexts: advertisement (perceptions of approachability, trustworthiness, and competence), brand (perceptions of whether a face represents a brand's typical customer), category (perceptions of whether a face represents a category's typical customer), and customer persona (perceptions of whether a face represents the persona of a brand's customer segment). Our results reveal new and useful findings that enrich the existing literature on face perception, most of which is based on abridged attributes (e.g., width of mouth). The TMUD has great potential to be a useful paradigm for generating theoretical insights and may encourage more marketing researchers and practitioners to use unabridged data.

</p>
</details>

<details><summary><b>Spectral Pruning for Recurrent Neural Networks</b>
<a href="https://arxiv.org/abs/2105.10832">arxiv:2105.10832</a>
&#x1F4C8; 2 <br>
<p>Takashi Furuya, Kazuma Suetake, Koichi Taniguchi, Hiroyuki Kusumoto, Ryuji Saiin, Tomohiro Daimon</p></summary>
<p>

**Abstract:** Recurrent neural networks (RNNs) are a class of neural networks used in sequential tasks. However, in general, RNNs have a large number of parameters and involve enormous computational costs by repeating the recurrent structures in many time steps. As a method to overcome this difficulty, RNN pruning has attracted increasing attention in recent years, and it brings us benefits in terms of the reduction of computational cost as the time step progresses. However, most existing methods of RNN pruning are heuristic. The purpose of this paper is to study the theoretical scheme for RNN pruning method. We propose an appropriate pruning algorithm for RNNs inspired by "spectral pruning", and provide the generalization error bounds for compressed RNNs. We also provide numerical experiments to demonstrate our theoretical results and show the effectiveness of our pruning method compared with existing methods.

</p>
</details>

<details><summary><b>Whole-Body Control on Non-holonomic Mobile Manipulation for Grapevine Winter Pruning Automation</b>
<a href="https://arxiv.org/abs/2105.10777">arxiv:2105.10777</a>
&#x1F4C8; 2 <br>
<p>Tao Teng, Miguel Fernandes, Matteo Gatti, Stefano Poni, Claudio Semini, Darwin Caldwell, Fei Chen</p></summary>
<p>

**Abstract:** Mobile manipulators that combine mobility and manipulability, are increasingly being used for various unstructured application scenarios in the field, e.g. vineyards. Therefore, the coordinated motion of the mobile base and manipulator is an essential feature of the overall performance. In this paper, we explore a whole-body motion controller of a robot which is composed of a 2-DoFs non-holonomic wheeled mobile base with a 7-DoFs manipulator (non-holonomic wheeled mobile manipulator, NWMM) This robotic platform is designed to efficiently undertake complex grapevine pruning tasks. In the control framework, a task priority coordinated motion of the NWMM is guaranteed. Lower-priority tasks are projected into the null space of the top-priority tasks so that higher-priority tasks are completed without interruption from lower-priority tasks. The proposed controller was evaluated in a grapevine spur pruning experiment scenario.

</p>
</details>

<details><summary><b>AutoLRS: Automatic Learning-Rate Schedule by Bayesian Optimization on the Fly</b>
<a href="https://arxiv.org/abs/2105.10762">arxiv:2105.10762</a>
&#x1F4C8; 2 <br>
<p>Yuchen Jin, Tianyi Zhou, Liangyu Zhao, Yibo Zhu, Chuanxiong Guo, Marco Canini, Arvind Krishnamurthy</p></summary>
<p>

**Abstract:** The learning rate (LR) schedule is one of the most important hyper-parameters needing careful tuning in training DNNs. However, it is also one of the least automated parts of machine learning systems and usually costs significant manual effort and computing. Though there are pre-defined LR schedules and optimizers with adaptive LR, they introduce new hyperparameters that need to be tuned separately for different tasks/datasets. In this paper, we consider the question: Can we automatically tune the LR over the course of training without human involvement? We propose an efficient method, AutoLRS, which automatically optimizes the LR for each training stage by modeling training dynamics. AutoLRS aims to find an LR applied to every $τ$ steps that minimizes the resulted validation loss. We solve this black-box optimization on the fly by Bayesian optimization (BO). However, collecting training instances for BO requires a system to evaluate each LR queried by BO's acquisition function for $τ$ steps, which is prohibitively expensive in practice. Instead, we apply each candidate LR for only $τ'\llτ$ steps and train an exponential model to predict the validation loss after $τ$ steps. This mutual-training process between BO and the loss-prediction model allows us to limit the training steps invested in the BO search. We demonstrate the advantages and the generality of AutoLRS through extensive experiments of training DNNs for tasks from diverse domains using different optimizers. The LR schedules auto-generated by AutoLRS lead to a speedup of $1.22\times$, $1.43\times$, and $1.5\times$ when training ResNet-50, Transformer, and BERT, respectively, compared to the LR schedules in their original papers, and an average speedup of $1.31\times$ over state-of-the-art heavily-tuned LR schedules.

</p>
</details>

<details><summary><b>PAL: Intelligence Augmentation using Egocentric Visual Context Detection</b>
<a href="https://arxiv.org/abs/2105.10735">arxiv:2105.10735</a>
&#x1F4C8; 2 <br>
<p>Mina Khan, Pattie Maes</p></summary>
<p>

**Abstract:** Egocentric visual context detection can support intelligence augmentation applications. We created a wearable system, called PAL, for wearable, personalized, and privacy-preserving egocentric visual context detection. PAL has a wearable device with a camera, heart-rate sensor, on-device deep learning, and audio input/output. PAL also has a mobile/web application for personalized context labeling. We used on-device deep learning models for generic object and face detection, low-shot custom face and context recognition (e.g., activities like brushing teeth), and custom context clustering (e.g., indoor locations). The models had over 80\% accuracy in in-the-wild contexts (~1000 images) and we tested PAL for intelligence augmentation applications like behavior change. We have made PAL is open-source to further support intelligence augmentation using personalized and privacy-preserving egocentric visual contexts.

</p>
</details>

<details><summary><b>From Finite to Countable-Armed Bandits</b>
<a href="https://arxiv.org/abs/2105.10721">arxiv:2105.10721</a>
&#x1F4C8; 2 <br>
<p>Anand Kalvit, Assaf Zeevi</p></summary>
<p>

**Abstract:** We consider a stochastic bandit problem with countably many arms that belong to a finite set of types, each characterized by a unique mean reward. In addition, there is a fixed distribution over types which sets the proportion of each type in the population of arms. The decision maker is oblivious to the type of any arm and to the aforementioned distribution over types, but perfectly knows the total number of types occurring in the population of arms. We propose a fully adaptive online learning algorithm that achieves O(log n) distribution-dependent expected cumulative regret after any number of plays n, and show that this order of regret is best possible. The analysis of our algorithm relies on newly discovered concentration and convergence properties of optimism-based policies like UCB in finite-armed bandit problems with "zero gap," which may be of independent interest.

</p>
</details>

<details><summary><b>Attention-based Reinforcement Learning for Real-Time UAV Semantic Communication</b>
<a href="https://arxiv.org/abs/2105.10716">arxiv:2105.10716</a>
&#x1F4C8; 2 <br>
<p>Won Joon Yun, Byungju Lim, Soyi Jung, Young-Chai Ko, Jihong Park, Joongheon Kim, Mehdi Bennis</p></summary>
<p>

**Abstract:** In this article, we study the problem of air-to-ground ultra-reliable and low-latency communication (URLLC) for a moving ground user. This is done by controlling multiple unmanned aerial vehicles (UAVs) in real time while avoiding inter-UAV collisions. To this end, we propose a novel multi-agent deep reinforcement learning (MADRL) framework, coined a graph attention exchange network (GAXNet). In GAXNet, each UAV constructs an attention graph locally measuring the level of attention to its neighboring UAVs, while exchanging the attention weights with other UAVs so as to reduce the attention mismatch between them. Simulation results corroborates that GAXNet achieves up to 4.5x higher rewards during training. At execution, without incurring inter-UAV collisions, GAXNet achieves 6.5x lower latency with the target 0.0000001 error rate, compared to a state-of-the-art baseline framework.

</p>
</details>

<details><summary><b>Adversarial Attacks and Mitigation for Anomaly Detectors of Cyber-Physical Systems</b>
<a href="https://arxiv.org/abs/2105.10707">arxiv:2105.10707</a>
&#x1F4C8; 2 <br>
<p>Yifan Jia, Jingyi Wang, Christopher M. Poskitt, Sudipta Chattopadhyay, Jun Sun, Yuqi Chen</p></summary>
<p>

**Abstract:** The threats faced by cyber-physical systems (CPSs) in critical infrastructure have motivated research into a multitude of attack detection mechanisms, including anomaly detectors based on neural network models. The effectiveness of anomaly detectors can be assessed by subjecting them to test suites of attacks, but less consideration has been given to adversarial attackers that craft noise specifically designed to deceive them. While successfully applied in domains such as images and audio, adversarial attacks are much harder to implement in CPSs due to the presence of other built-in defence mechanisms such as rule checkers(or invariant checkers). In this work, we present an adversarial attack that simultaneously evades the anomaly detectors and rule checkers of a CPS. Inspired by existing gradient-based approaches, our adversarial attack crafts noise over the sensor and actuator values, then uses a genetic algorithm to optimise the latter, ensuring that the neural network and the rule checking system are both deceived.We implemented our approach for two real-world critical infrastructure testbeds, successfully reducing the classification accuracy of their detectors by over 50% on average, while simultaneously avoiding detection by rule checkers. Finally, we explore whether these attacks can be mitigated by training the detectors on adversarial samples.

</p>
</details>

<details><summary><b>Automated Knee X-ray Report Generation</b>
<a href="https://arxiv.org/abs/2105.10702">arxiv:2105.10702</a>
&#x1F4C8; 2 <br>
<p>Aydan Gasimova, Giovanni Montana, Daniel Rueckert</p></summary>
<p>

**Abstract:** Gathering manually annotated images for the purpose of training a predictive model is far more challenging in the medical domain than for natural images as it requires the expertise of qualified radiologists. We therefore propose to take advantage of past radiological exams (specifically, knee X-ray examinations) and formulate a framework capable of learning the correspondence between the images and reports, and hence be capable of generating diagnostic reports for a given X-ray examination consisting of an arbitrary number of image views. We demonstrate how aggregating the image features of individual exams and using them as conditional inputs when training a language generation model results in auto-generated exam reports that correlate well with radiologist-generated reports.

</p>
</details>

<details><summary><b>Towards Automatic Recognition of Pure & Mixed Stones using Intraoperative Endoscopic Digital Images</b>
<a href="https://arxiv.org/abs/2105.10686">arxiv:2105.10686</a>
&#x1F4C8; 2 <br>
<p>Vincent Estrade, Michel Daudon, Emmanuel Richard, Jean-Christophe Bernhard, Franck Bladou, Gregoire Robert, Baudouin Denis de Senneville</p></summary>
<p>

**Abstract:** Objective: To assess automatic computer-aided in-situ recognition of morphological features of pure and mixed urinary stones using intraoperative digital endoscopic images acquired in a clinical setting. Materials and methods: In this single-centre study, an experienced urologist intraoperatively and prospectively examined the surface and section of all kidney stones encountered. Calcium oxalate monohydrate (COM/Ia), dihydrate (COD/IIb) and uric acid (UA/IIIb) morphological criteria were collected and classified to generate annotated datasets. A deep convolutional neural network (CNN) was trained to predict the composition of both pure and mixed stones. To explain the predictions of the deep neural network model, coarse localisation heat-maps were plotted to pinpoint key areas identified by the network. Results: This study included 347 and 236 observations of stone surface and stone section, respectively. A highest sensitivity of 98 % was obtained for the type "pure IIIb/UA" using surface images. The most frequently encountered morphology was that of the type "pure Ia/COM"; it was correctly predicted in 91 % and 94 % of cases using surface and section images, respectively. Of the mixed type "Ia/COM+IIb/COD", Ia/COM was predicted in 84 % of cases using surface images, IIb/COD in 70 % of cases, and both in 65 % of cases. Concerning mixed Ia/COM+IIIb/UA stones, Ia/COM was predicted in 91 % of cases using section images, IIIb/UA in 69 % of cases, and both in 74 % of cases. Conclusions: This preliminary study demonstrates that deep convolutional neural networks are promising to identify kidney stone composition from endoscopic images acquired intraoperatively. Both pure and mixed stone composition could be discriminated. Collected in a clinical setting, surface and section images analysed by deep CNN provide valuable information about stone morphology for computer-aided diagnosis.

</p>
</details>

<details><summary><b>SOK: Fake News Outbreak 2021: Can We Stop the Viral Spread?</b>
<a href="https://arxiv.org/abs/2105.10671">arxiv:2105.10671</a>
&#x1F4C8; 2 <br>
<p>Tanveer Khan, Antonis Michalas, Adnan Akhunzada</p></summary>
<p>

**Abstract:** Social Networks' omnipresence and ease of use has revolutionized the generation and distribution of information in today's world. However, easy access to information does not equal an increased level of public knowledge. Unlike traditional media channels, social networks also facilitate faster and wider spread of disinformation and misinformation. Viral spread of false information has serious implications on the behaviors, attitudes and beliefs of the public, and ultimately can seriously endanger the democratic processes. Limiting false information's negative impact through early detection and control of extensive spread presents the main challenge facing researchers today. In this survey paper, we extensively analyze a wide range of different solutions for the early detection of fake news in the existing literature. More precisely, we examine Machine Learning (ML) models for the identification and classification of fake news, online fake news detection competitions, statistical outputs as well as the advantages and disadvantages of some of the available data sets. Finally, we evaluate the online web browsing tools available for detecting and mitigating fake news and present some open research challenges.

</p>
</details>

<details><summary><b>Semi-Supervised Few-Shot Classification with Deep Invertible Hybrid Models</b>
<a href="https://arxiv.org/abs/2105.10644">arxiv:2105.10644</a>
&#x1F4C8; 2 <br>
<p>Yusuke Ohtsubo, Tetsu Matsukawa, Einoshin Suzuki</p></summary>
<p>

**Abstract:** In this paper, we propose a deep invertible hybrid model which integrates discriminative and generative learning at a latent space level for semi-supervised few-shot classification. Various tasks for classifying new species from image data can be modeled as a semi-supervised few-shot classification, which assumes a labeled and unlabeled training examples and a small support set of the target classes. Predicting target classes with a few support examples per class makes the learning task difficult for existing semi-supervised classification methods, including selftraining, which iteratively estimates class labels of unlabeled training examples to learn a classifier for the training classes. To exploit unlabeled training examples effectively, we adopt as the objective function the composite likelihood, which integrates discriminative and generative learning and suits better with deep neural networks than the parameter coupling prior, the other popular integrated learning approach. In our proposed model, the discriminative and generative models are respectively Prototypical Networks, which have shown excellent performance in various kinds of few-shot learning, and Normalizing Flow a deep invertible model which returns the exact marginal likelihood unlike the other three major methods, i.e., VAE, GAN, and autoregressive model. Our main originality lies in our integration of these components at a latent space level, which is effective in preventing overfitting. Experiments using mini-ImageNet and VGG-Face datasets show that our method outperforms selftraining based Prototypical Networks.

</p>
</details>

<details><summary><b>Embedding Information onto a Dynamical System</b>
<a href="https://arxiv.org/abs/2105.10766">arxiv:2105.10766</a>
&#x1F4C8; 1 <br>
<p>G Manjunath</p></summary>
<p>

**Abstract:** The celebrated Takens' embedding theorem concerns embedding an attractor of a dynamical system in a Euclidean space of appropriate dimension through a generic delay-observation map. The embedding also establishes a topological conjugacy. In this paper, we show how an arbitrary sequence can be mapped into another space as an attractive solution of a nonautonomous dynamical system. Such mapping also entails a topological conjugacy and an embedding between the sequence and the attractive solution spaces. This result is not a generalization of Takens embedding theorem but helps us understand what exactly is required by discrete-time state space models widely used in applications to embed an external stimulus onto its solution space. Our results settle another basic problem concerning the perturbation of an autonomous dynamical system. We describe what exactly happens to the dynamics when exogenous noise perturbs continuously a local irreducible attracting set (such as a stable fixed point) of a discrete-time autonomous dynamical system.

</p>
</details>

<details><summary><b>V2V Spatiotemporal Interactive Pattern Recognition and Risk Analysis in Lane Changes</b>
<a href="https://arxiv.org/abs/2105.10688">arxiv:2105.10688</a>
&#x1F4C8; 1 <br>
<p>Yue Zhang, Yajie Zou, Lingtao Wu</p></summary>
<p>

**Abstract:** In complex lane change (LC) scenarios, semantic interpretation and safety analysis of dynamic interactive pattern are necessary for autonomous vehicles to make appropriate decisions. This study proposes an unsupervised learning framework that combines primitive-based interactive pattern recognition methods and risk analysis methods. The Hidden Markov Model with the Gaussian mixture model (GMM-HMM) approach is developed to decompose the LC scenarios into primitives. Then the Dynamic Time Warping (DTW) distance based K-means clustering is applied to gather the primitives to 13 types of interactive patterns. Finally, this study considers two types of time-to-collision (TTC) involved in the LC process as indicators to analyze the risk of the interactive patterns and extract high-risk LC interactive patterns. The results obtained from The Highway Drone Dataset (highD) demonstrate that the identified LC interactive patterns contain interpretable semantic information. This study explores the spatiotemporal evolution law and risk formation mechanism of the LC interactive patterns and the findings are useful for comprehensively understanding the latent interactive patterns, improving the rationality and safety of autonomous vehicle's decision-making.

</p>
</details>

<details><summary><b>Post-Radiotherapy PET Image Outcome Prediction by Deep Learning under Biological Model Guidance: A Feasibility Study of Oropharyngeal Cancer Application</b>
<a href="https://arxiv.org/abs/2105.10650">arxiv:2105.10650</a>
&#x1F4C8; 1 <br>
<p>Hangjie Ji, Kyle Lafata, Yvonne Mowery, David Brizel, Andrea L. Bertozzi, Fang-Fang Yin, Chunhao Wang</p></summary>
<p>

**Abstract:** This paper develops a method of biologically guided deep learning for post-radiation FDG-PET image outcome prediction based on pre-radiation images and radiotherapy dose information. Based on the classic reaction-diffusion mechanism, a novel biological model was proposed using a partial differential equation that incorporates spatial radiation dose distribution as a patient-specific treatment information variable. A 7-layer encoder-decoder-based convolutional neural network (CNN) was designed and trained to learn the proposed biological model. As such, the model could generate post-radiation FDG-PET image outcome predictions with possible time-series transition from pre-radiotherapy image states to post-radiotherapy states. The proposed method was developed using 64 oropharyngeal patients with paired FDG-PET studies before and after 20Gy delivery (2Gy/daily fraction) by IMRT. In a two-branch deep learning execution, the proposed CNN learns specific terms in the biological model from paired FDG-PET images and spatial dose distribution as in one branch, and the biological model generates post-20Gy FDG-PET image prediction in the other branch. The proposed method successfully generated post-20Gy FDG-PET image outcome prediction with breakdown illustrations of biological model components. Time-series FDG-PET image predictions were generated to demonstrate the feasibility of disease response rendering. The developed biologically guided deep learning method achieved post-20Gy FDG-PET image outcome predictions in good agreement with ground-truth results. With break-down biological modeling components, the outcome image predictions could be used in adaptive radiotherapy decision-making to optimize personalized plans for the best outcome in the future.

</p>
</details>


[Next Page](2021/2021-05/2021-05-21.md)
