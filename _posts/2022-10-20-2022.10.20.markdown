Prev: [2022.10.19]({{ '/2022/10/19/2022.10.19.html' | relative_url }})  Next: [2022.10.21]({{ '/2022/10/21/2022.10.21.html' | relative_url }})
{% raw %}
## Summary for 2022-10-20, created on 2022-10-27


<details><summary><b>Using Large Language Models to Enhance Programming Error Messages</b>
<a href="https://arxiv.org/abs/2210.11630">arxiv:2210.11630</a>
&#x1F4C8; 481 <br>
<p>Juho Leinonen, Arto Hellas, Sami Sarsa, Brent Reeves, Paul Denny, James Prather, Brett A. Becker</p></summary>
<p>

**Abstract:** A key part of learning to program is learning to understand programming error messages. They can be hard to interpret and identifying the cause of errors can be time-consuming. One factor in this challenge is that the messages are typically intended for an audience that already knows how to program, or even for programming environments that then use the information to highlight areas in code. Researchers have been working on making these errors more novice friendly since the 1960s, however progress has been slow. The present work contributes to this stream of research by using large language models to enhance programming error messages with explanations of the errors and suggestions on how to fix the error. Large language models can be used to create useful and novice-friendly enhancements to programming error messages that sometimes surpass the original programming error messages in interpretability and actionability. These results provide further evidence of the benefits of large language models for computing educators, highlighting their use in areas known to be challenging for students. We further discuss the benefits and downsides of large language models and highlight future streams of research for enhancing programming error messages.

</p>
</details>

<details><summary><b>Robust One-Shot Singing Voice Conversion</b>
<a href="https://arxiv.org/abs/2210.11096">arxiv:2210.11096</a>
&#x1F4C8; 67 <br>
<p>Naoya Takahashi, Mayank Kumar Singh, Yuki Mitsufuji</p></summary>
<p>

**Abstract:** Many existing works on singing voice conversion (SVC) require clean recordings of target singer's voice for training. However, it is often difficult to collect them in advance and singing voices are often distorted with reverb and accompaniment music. In this work, we propose robust one-shot SVC (ROSVC) that performs any-to-any SVC robustly even on such distorted singing voices using less than 10s of a reference voice. To this end, we propose two-stage training method called Robustify. In the first stage, a novel one-shot SVC model based on a generative adversarial network is trained on clean data to ensure high-quality conversion. In the second stage, enhancement modules are introduced to the encoders of the model to improve the robustness against distortions in the feature space. Experimental results show that the proposed method outperforms one-shot SVC baselines for both seen and unseen singers and greatly improves the robustness against the distortions.

</p>
</details>

<details><summary><b>Object Goal Navigation Based on Semantics and RGB Ego View</b>
<a href="https://arxiv.org/abs/2210.11543">arxiv:2210.11543</a>
&#x1F4C8; 59 <br>
<p>Snehasis Banerjee, Brojeshwar Bhowmick, Ruddra Dev Roychoudhury</p></summary>
<p>

**Abstract:** This paper presents an architecture and methodology to empower a service robot to navigate an indoor environment with semantic decision making, given RGB ego view. This method leverages the knowledge of robot's actuation capability and that of scenes, objects and their relations -- represented in a semantic form. The robot navigates based on GeoSem map - a relational combination of geometric and semantic map. The goal given to the robot is to find an object in a unknown environment with no navigational map and only egocentric RGB camera perception. The approach is tested both on a simulation environment and real life indoor settings. The presented approach was found to outperform human users in gamified evaluations with respect to average completion time.

</p>
</details>

<details><summary><b>On Feature Learning in the Presence of Spurious Correlations</b>
<a href="https://arxiv.org/abs/2210.11369">arxiv:2210.11369</a>
&#x1F4C8; 50 <br>
<p>Pavel Izmailov, Polina Kirichenko, Nate Gruver, Andrew Gordon Wilson</p></summary>
<p>

**Abstract:** Deep classifiers are known to rely on spurious features $\unicode{x2013}$ patterns which are correlated with the target on the training data but not inherently relevant to the learning problem, such as the image backgrounds when classifying the foregrounds. In this paper we evaluate the amount of information about the core (non-spurious) features that can be decoded from the representations learned by standard empirical risk minimization (ERM) and specialized group robustness training. Following recent work on Deep Feature Reweighting (DFR), we evaluate the feature representations by re-training the last layer of the model on a held-out set where the spurious correlation is broken. On multiple vision and NLP problems, we show that the features learned by simple ERM are highly competitive with the features learned by specialized group robustness methods targeted at reducing the effect of spurious correlations. Moreover, we show that the quality of learned feature representations is greatly affected by the design decisions beyond the training method, such as the model architecture and pre-training strategy. On the other hand, we find that strong regularization is not necessary for learning high quality feature representations. Finally, using insights from our analysis, we significantly improve upon the best results reported in the literature on the popular Waterbirds, CelebA hair color prediction and WILDS-FMOW problems, achieving 97%, 92% and 50% worst-group accuracies, respectively.

</p>
</details>

<details><summary><b>Composing Ensembles of Pre-trained Models via Iterative Consensus</b>
<a href="https://arxiv.org/abs/2210.11522">arxiv:2210.11522</a>
&#x1F4C8; 42 <br>
<p>Shuang Li, Yilun Du, Joshua B. Tenenbaum, Antonio Torralba, Igor Mordatch</p></summary>
<p>

**Abstract:** Large pre-trained models exhibit distinct and complementary capabilities dependent on the data they are trained on. Language models such as GPT-3 are capable of textual reasoning but cannot understand visual information, while vision models such as DALL-E can generate photorealistic photos but fail to understand complex language descriptions. In this work, we propose a unified framework for composing ensembles of different pre-trained models -- combining the strengths of each individual model to solve various multimodal problems in a zero-shot manner. We use pre-trained models as "generators" or "scorers" and compose them via closed-loop iterative consensus optimization. The generator constructs proposals and the scorers iteratively provide feedback to refine the generated result. Such closed-loop communication enables models to correct errors caused by other models, significantly boosting performance on downstream tasks, e.g. improving accuracy on grade school math problems by 7.5%, without requiring any model finetuning. We demonstrate that consensus achieved by an ensemble of scorers outperforms the feedback of a single scorer, by leveraging the strengths of each expert model. Results show that the proposed method can be used as a general purpose framework for a wide range of zero-shot multimodal tasks, such as image generation, video question answering, mathematical reasoning, and robotic manipulation. Project page: https://energy-based-model.github.io/composing-pretrained-models.

</p>
</details>

<details><summary><b>Learning Rationalizable Equilibria in Multiplayer Games</b>
<a href="https://arxiv.org/abs/2210.11402">arxiv:2210.11402</a>
&#x1F4C8; 40 <br>
<p>Yuanhao Wang, Dingwen Kong, Yu Bai, Chi Jin</p></summary>
<p>

**Abstract:** A natural goal in multiagent learning besides finding equilibria is to learn rationalizable behavior, where players learn to avoid iteratively dominated actions. However, even in the basic setting of multiplayer general-sum games, existing algorithms require a number of samples exponential in the number of players to learn rationalizable equilibria under bandit feedback. This paper develops the first line of efficient algorithms for learning rationalizable Coarse Correlated Equilibria (CCE) and Correlated Equilibria (CE) whose sample complexities are polynomial in all problem parameters including the number of players. To achieve this result, we also develop a new efficient algorithm for the simpler task of finding one rationalizable action profile (not necessarily an equilibrium), whose sample complexity substantially improves over the best existing results of Wu et al. (2021). Our algorithms incorporate several novel techniques to guarantee rationalizability and no (swap-)regret simultaneously, including a correlated exploration scheme and adaptive learning rates, which may be of independent interest. We complement our results with a sample complexity lower bound showing the sharpness of our guarantees.

</p>
</details>

<details><summary><b>Efficiently Tuned Parameters are Task Embeddings</b>
<a href="https://arxiv.org/abs/2210.11705">arxiv:2210.11705</a>
&#x1F4C8; 39 <br>
<p>Wangchunshu Zhou, Canwen Xu, Julian McAuley</p></summary>
<p>

**Abstract:** Intermediate-task transfer can benefit a wide range of NLP tasks with properly selected source datasets. However, it is computationally infeasible to experiment with all intermediate transfer combinations, making choosing a useful source task a challenging problem. In this paper, we anticipate that task-specific parameters updated in parameter-efficient tuning methods are likely to encode task-specific information. Therefore, such parameters can be predictive for inter-task transferability. Thus, we propose to exploit these efficiently tuned parameters as off-the-shelf task embeddings for the efficient selection of source datasets for intermediate-task transfer. We experiment with 11 text classification tasks and 11 question answering tasks. Experimental results show that our approach can consistently outperform existing inter-task transferability prediction methods while being conceptually simple and computationally efficient. Our analysis also reveals that the ability of efficiently tuned parameters on transferability prediction is disentangled with their in-task performance. This allows us to use parameters from early checkpoints as task embeddings to further improve efficiency.

</p>
</details>

<details><summary><b>TANGO: Text-driven Photorealistic and Robust 3D Stylization via Lighting Decomposition</b>
<a href="https://arxiv.org/abs/2210.11277">arxiv:2210.11277</a>
&#x1F4C8; 31 <br>
<p>Yongwei Chen, Rui Chen, Jiabao Lei, Yabin Zhang, Kui Jia</p></summary>
<p>

**Abstract:** Creation of 3D content by stylization is a promising yet challenging problem in computer vision and graphics research. In this work, we focus on stylizing photorealistic appearance renderings of a given surface mesh of arbitrary topology. Motivated by the recent surge of cross-modal supervision of the Contrastive Language-Image Pre-training (CLIP) model, we propose TANGO, which transfers the appearance style of a given 3D shape according to a text prompt in a photorealistic manner. Technically, we propose to disentangle the appearance style as the spatially varying bidirectional reflectance distribution function, the local geometric variation, and the lighting condition, which are jointly optimized, via supervision of the CLIP loss, by a spherical Gaussians based differentiable renderer. As such, TANGO enables photorealistic 3D style transfer by automatically predicting reflectance effects even for bare, low-quality meshes, without training on a task-specific dataset. Extensive experiments show that TANGO outperforms existing methods of text-driven 3D style transfer in terms of photorealistic quality, consistency of 3D geometry, and robustness when stylizing low-quality meshes. Our codes and results are available at our project webpage https://cyw-3d.github.io/tango/.

</p>
</details>

<details><summary><b>i-MAE: Are Latent Representations in Masked Autoencoders Linearly Separable?</b>
<a href="https://arxiv.org/abs/2210.11470">arxiv:2210.11470</a>
&#x1F4C8; 30 <br>
<p>Kevin Zhang, Zhiqiang Shen</p></summary>
<p>

**Abstract:** Masked image modeling (MIM) has been recognized as a strong and popular self-supervised pre-training approach in the vision domain. However, the interpretability of the mechanism and properties of the learned representations by such a scheme are so far not well-explored. In this work, through comprehensive experiments and empirical studies on Masked Autoencoders (MAE), we address two critical questions to explore the behaviors of the learned representations: (i) Are the latent representations in Masked Autoencoders linearly separable if the input is a mixture of two images instead of one? This can be concrete evidence used to explain why MAE-learned representations have superior performance on downstream tasks, as proven by many literature impressively. (ii) What is the degree of semantics encoded in the latent feature space by Masked Autoencoders? To explore these two problems, we propose a simple yet effective Interpretable MAE (i-MAE) framework with a two-way image reconstruction and a latent feature reconstruction with distillation loss to help us understand the behaviors inside MAE's structure. Extensive experiments are conducted on CIFAR-10/100, Tiny-ImageNet and ImageNet-1K datasets to verify the observations we discovered. Furthermore, in addition to qualitatively analyzing the characteristics of the latent representations, we examine the existence of linear separability and the degree of semantics in the latent space by proposing two novel metrics. The surprising and consistent results across the qualitative and quantitative experiments demonstrate that i-MAE is a superior framework design for interpretability research of MAE frameworks, as well as achieving better representational ability. Code is available at https://github.com/vision-learning-acceleration-lab/i-mae.

</p>
</details>

<details><summary><b>Hypernetworks in Meta-Reinforcement Learning</b>
<a href="https://arxiv.org/abs/2210.11348">arxiv:2210.11348</a>
&#x1F4C8; 22 <br>
<p>Jacob Beck, Matthew Thomas Jackson, Risto Vuorio, Shimon Whiteson</p></summary>
<p>

**Abstract:** Training a reinforcement learning (RL) agent on a real-world robotics task remains generally impractical due to sample inefficiency. Multi-task RL and meta-RL aim to improve sample efficiency by generalizing over a distribution of related tasks. However, doing so is difficult in practice: In multi-task RL, state of the art methods often fail to outperform a degenerate solution that simply learns each task separately. Hypernetworks are a promising path forward since they replicate the separate policies of the degenerate solution while also allowing for generalization across tasks, and are applicable to meta-RL. However, evidence from supervised learning suggests hypernetwork performance is highly sensitive to the initialization. In this paper, we 1) show that hypernetwork initialization is also a critical factor in meta-RL, and that naive initializations yield poor performance; 2) propose a novel hypernetwork initialization scheme that matches or exceeds the performance of a state-of-the-art approach proposed for supervised settings, as well as being simpler and more general; and 3) use this method to show that hypernetworks can improve performance in meta-RL by evaluating on multiple simulated robotics benchmarks.

</p>
</details>

<details><summary><b>Hypothesis Testing using Causal and Causal Variational Generative Models</b>
<a href="https://arxiv.org/abs/2210.11275">arxiv:2210.11275</a>
&#x1F4C8; 21 <br>
<p>Jeffrey Jiang, Omead Pooladzandi, Sunay Bhat, Gregory Pottie</p></summary>
<p>

**Abstract:** Hypothesis testing and the usage of expert knowledge, or causal priors, has not been well explored in the context of generative models. We propose a novel set of generative architectures, Causal Gen and Causal Variational Gen, that can utilize nonparametric structural causal knowledge combined with a deep learning functional approximation. We show how, using a deliberate (non-random) split of training and testing data, these models can generalize better to similar, but out-of-distribution data points, than non-causal generative models and prediction models such as Variational autoencoders and Fully Connected Neural Networks. We explore using this generalization error as a proxy for causal model hypothesis testing. We further show how dropout can be used to learn functional relationships of structural models that are difficult to learn with traditional methods. We validate our methods on a synthetic pendulum dataset, as well as a trauma surgery ground level fall dataset.

</p>
</details>

<details><summary><b>Reproducibility of the Methods in Medical Imaging with Deep Learning</b>
<a href="https://arxiv.org/abs/2210.11146">arxiv:2210.11146</a>
&#x1F4C8; 21 <br>
<p>Attila Simko, Anders Garpebring, Joakim Jonsson, Tufve Nyholm, Tommy Löfstedt</p></summary>
<p>

**Abstract:** Concerns about the reproducibility of deep learning research are more prominent than ever, with no clear solution in sight. The relevance of machine learning research can only be improved if we also employ empirical rigor that incorporates reproducibility guidelines, especially so in the medical imaging field. The Medical Imaging with Deep Learning (MIDL) conference has made advancements in this direction by advocating open access, and recently also recommending authors to make their code public - both aspects being adopted by the majority of the conference submissions. This helps the reproducibility of the methods, however, there is currently little or no support for further evaluation of these supplementary material, making them vulnerable to poor quality, which affects the impact of the entire submission. We have evaluated all accepted full paper submissions to MIDL between 2018 and 2022 using established, but slightly adjusted guidelines on reproducibility and the quality of the public repositories. The evaluations show that publishing repositories and using public datasets are becoming more popular, which helps traceability, but the quality of the repositories has not improved over the years, leaving room for improvement in every aspect of designing repositories. Merely 22% of all submissions contain a repository that were deemed repeatable using our evaluations. From the commonly encountered issues during the evaluations, we propose a set of guidelines for machine learning-related research for medical imaging applications, adjusted specifically for future submissions to MIDL.

</p>
</details>

<details><summary><b>Evidence of Vocal Tract Articulation in Self-Supervised Learning of Speech</b>
<a href="https://arxiv.org/abs/2210.11723">arxiv:2210.11723</a>
&#x1F4C8; 20 <br>
<p>Cheol Jun Cho, Peter Wu, Abdelrahman Mohamed, Gopala K. Anumanchipalli</p></summary>
<p>

**Abstract:** Numerous self-supervised learning (SSL) models for speech have been proposed for pre-training models of speech representations, and recent SSL models are very successful in diverse downstream tasks. To understand such utilities, previous works probe representations of speech models to reveal which & how speech related information is encoded in the learned representations. While encoding properties have been extensively explored from the perspective of acoustics, phonetics, and semantics, the physical grounding by speech production has not yet received full attention. To bridge this gap, we conduct a comprehensive analysis to link speech representations to articulatory trajectories measured by electromagnetic articulography (EMA). Our analysis is based on a linear probing approach where we measure articulatory score as an average correlation of linear mapping to EMA. We analyze a set of SSL models selected from the leaderboard of the SU- PERB benchmark and perform further detailed analyses on two major models, Wav2Vec 2.0 and HuBERT. Surprisingly, representations from the recent speech SSL models are highly correlated with EMA traces (best: r = 0.81), and only 5 minutes were sufficient to train a linear model with high performance (r = 0.77). Our findings suggest that SSL models learn to closely align with continuous articulations and provide a novel insight into speech SSL.

</p>
</details>

<details><summary><b>Breaking Bad: A Dataset for Geometric Fracture and Reassembly</b>
<a href="https://arxiv.org/abs/2210.11463">arxiv:2210.11463</a>
&#x1F4C8; 20 <br>
<p>Silvia Sellán, Yun-Chun Chen, Ziyi Wu, Animesh Garg, Alec Jacobson</p></summary>
<p>

**Abstract:** We introduce Breaking Bad, a large-scale dataset of fractured objects. Our dataset consists of over one million fractured objects simulated from ten thousand base models. The fracture simulation is powered by a recent physically based algorithm that efficiently generates a variety of fracture modes of an object. Existing shape assembly datasets decompose objects according to semantically meaningful parts, effectively modeling the construction process. In contrast, Breaking Bad models the destruction process of how a geometric object naturally breaks into fragments. Our dataset serves as a benchmark that enables the study of fractured object reassembly and presents new challenges for geometric shape understanding. We analyze our dataset with several geometry measurements and benchmark three state-of-the-art shape assembly deep learning methods under various settings. Extensive experimental results demonstrate the difficulty of our dataset, calling on future research in model designs specifically for the geometric shape assembly task. We host our dataset at https://breaking-bad-dataset.github.io/.

</p>
</details>

<details><summary><b>MoCoDA: Model-based Counterfactual Data Augmentation</b>
<a href="https://arxiv.org/abs/2210.11287">arxiv:2210.11287</a>
&#x1F4C8; 20 <br>
<p>Silviu Pitis, Elliot Creager, Ajay Mandlekar, Animesh Garg</p></summary>
<p>

**Abstract:** The number of states in a dynamic process is exponential in the number of objects, making reinforcement learning (RL) difficult in complex, multi-object domains. For agents to scale to the real world, they will need to react to and reason about unseen combinations of objects. We argue that the ability to recognize and use local factorization in transition dynamics is a key element in unlocking the power of multi-object reasoning. To this end, we show that (1) known local structure in the environment transitions is sufficient for an exponential reduction in the sample complexity of training a dynamics model, and (2) a locally factored dynamics model provably generalizes out-of-distribution to unseen states and actions. Knowing the local structure also allows us to predict which unseen states and actions this dynamics model will generalize to. We propose to leverage these observations in a novel Model-based Counterfactual Data Augmentation (MoCoDA) framework. MoCoDA applies a learned locally factored dynamics model to an augmented distribution of states and actions to generate counterfactual transitions for RL. MoCoDA works with a broader set of local structures than prior work and allows for direct control over the augmented training distribution. We show that MoCoDA enables RL agents to learn policies that generalize to unseen states and actions. We use MoCoDA to train an offline RL agent to solve an out-of-distribution robotics manipulation task on which standard offline RL algorithms fail.

</p>
</details>

<details><summary><b>Private Algorithms with Private Predictions</b>
<a href="https://arxiv.org/abs/2210.11222">arxiv:2210.11222</a>
&#x1F4C8; 20 <br>
<p>Kareem Amin, Travis Dick, Mikhail Khodak, Sergei Vassilvitskii</p></summary>
<p>

**Abstract:** When applying differential privacy to sensitive data, a common way of getting improved performance is to use external information such as other sensitive data, public data, or human priors. We propose to use the algorithms with predictions framework -- previously applied largely to improve time complexity or competitive ratios -- as a powerful way of designing and analyzing privacy-preserving methods that can take advantage of such external information to improve utility. For four important tasks -- quantile release, its extension to multiple quantiles, covariance estimation, and data release -- we construct prediction-dependent differentially private methods whose utility scales with natural measures of prediction quality. The analyses enjoy several advantages, including minimal assumptions about the data, natural ways of adding robustness to noisy predictions, and novel "meta" algorithms that can learn predictions from other (potentially sensitive) data. Overall, our results demonstrate how to enable differentially private algorithms to make use of and learn noisy predictions, which holds great promise for improving utility while preserving privacy across a variety of tasks.

</p>
</details>

<details><summary><b>PAC-Bayesian Learning of Optimization Algorithms</b>
<a href="https://arxiv.org/abs/2210.11113">arxiv:2210.11113</a>
&#x1F4C8; 19 <br>
<p>Michael Sucker, Peter Ochs</p></summary>
<p>

**Abstract:** We apply the PAC-Bayes theory to the setting of learning-to-optimize. To the best of our knowledge, we present the first framework to learn optimization algorithms with provable generalization guarantees (PAC-bounds) and explicit trade-off between a high probability of convergence and a high convergence speed. Even in the limit case, where convergence is guaranteed, our learned optimization algorithms provably outperform related algorithms based on a (deterministic) worst-case analysis. Our results rely on PAC-Bayes bounds for general, unbounded loss-functions based on exponential families. By generalizing existing ideas, we reformulate the learning procedure into a one-dimensional minimization problem and study the possibility to find a global minimum, which enables the algorithmic realization of the learning procedure. As a proof-of-concept, we learn hyperparameters of standard optimization algorithms to empirically underline our theory.

</p>
</details>

<details><summary><b>A survey on Self Supervised learning approaches for improving Multimodal representation learning</b>
<a href="https://arxiv.org/abs/2210.11024">arxiv:2210.11024</a>
&#x1F4C8; 19 <br>
<p>Naman Goyal</p></summary>
<p>

**Abstract:** Recently self supervised learning has seen explosive growth and use in variety of machine learning tasks because of its ability to avoid the cost of annotating large-scale datasets.
  This paper gives an overview for best self supervised learning approaches for multimodal learning. The presented approaches have been aggregated by extensive study of the literature and tackle the application of self supervised learning in different ways. The approaches discussed are cross modal generation, cross modal pretraining, cyclic translation, and generating unimodal labels in self supervised fashion.

</p>
</details>

<details><summary><b>Improving Data Quality with Training Dynamics of Gradient Boosting Decision Trees</b>
<a href="https://arxiv.org/abs/2210.11327">arxiv:2210.11327</a>
&#x1F4C8; 16 <br>
<p>Moacir Antonelli Ponti, Lucas de Angelis Oliveira, Juan Martín Román, Luis Argerich</p></summary>
<p>

**Abstract:** Real world datasets contain incorrectly labeled instances that hamper the performance of the model and, in particular, the ability to generalize out of distribution. Also, each example might have different contribution towards learning. This motivates studies to better understanding of the role of data instances with respect to their contribution in good metrics in models. In this paper we propose a method based on metrics computed from training dynamics of Gradient Boosting Decision Trees (GBDTs) to assess the behavior of each training example. We focus on datasets containing mostly tabular or structured data, for which the use of Decision Trees ensembles are still the state-of-the-art in terms of performance. We show results on detecting noisy labels in order to either remove them, improving models' metrics in synthetic and real datasets, as well as a productive dataset. Our methods achieved the best results overall when compared with confident learning and heuristics.

</p>
</details>

<details><summary><b>SMaLL-100: Introducing Shallow Multilingual Machine Translation Model for Low-Resource Languages</b>
<a href="https://arxiv.org/abs/2210.11621">arxiv:2210.11621</a>
&#x1F4C8; 15 <br>
<p>Alireza Mohammadshahi, Vassilina Nikoulina, Alexandre Berard, Caroline Brun, James Henderson, Laurent Besacier</p></summary>
<p>

**Abstract:** In recent years, multilingual machine translation models have achieved promising performance on low-resource language pairs by sharing information between similar languages, thus enabling zero-shot translation. To overcome the "curse of multilinguality", these models often opt for scaling up the number of parameters, which makes their use in resource-constrained environments challenging. We introduce SMaLL-100, a distilled version of the M2M-100 (12B) model, a massively multilingual machine translation model covering 100 languages. We train SMaLL-100 with uniform sampling across all language pairs and therefore focus on preserving the performance of low-resource languages. We evaluate SMaLL-100 on different low-resource benchmarks: FLORES-101, Tatoeba, and TICO-19 and demonstrate that it outperforms previous massively multilingual models of comparable sizes (200-600M) while improving inference latency and memory usage. Additionally, our model achieves comparable results to M2M-100 (1.2B), while being 3.6x smaller and 4.3x faster at inference. Code and pre-trained models: https://github.com/alirezamshi/small100

</p>
</details>

<details><summary><b>Context-driven Visual Object Recognition based on Knowledge Graphs</b>
<a href="https://arxiv.org/abs/2210.11233">arxiv:2210.11233</a>
&#x1F4C8; 15 <br>
<p>Sebastian Monka, Lavdim Halilaj, Achim Rettinger</p></summary>
<p>

**Abstract:** Current deep learning methods for object recognition are purely data-driven and require a large number of training samples to achieve good results. Due to their sole dependence on image data, these methods tend to fail when confronted with new environments where even small deviations occur. Human perception, however, has proven to be significantly more robust to such distribution shifts. It is assumed that their ability to deal with unknown scenarios is based on extensive incorporation of contextual knowledge. Context can be based either on object co-occurrences in a scene or on memory of experience. In accordance with the human visual cortex which uses context to form different object representations for a seen image, we propose an approach that enhances deep learning methods by using external contextual knowledge encoded in a knowledge graph. Therefore, we extract different contextual views from a generic knowledge graph, transform the views into vector space and infuse it into a DNN. We conduct a series of experiments to investigate the impact of different contextual views on the learned object representations for the same image dataset. The experimental results provide evidence that the contextual views influence the image representations in the DNN differently and therefore lead to different predictions for the same images. We also show that context helps to strengthen the robustness of object recognition models for out-of-distribution images, usually occurring in transfer learning tasks or real-world scenarios.

</p>
</details>

<details><summary><b>Modelling Multi-relations for Convolutional-based Knowledge Graph Embedding</b>
<a href="https://arxiv.org/abs/2210.11711">arxiv:2210.11711</a>
&#x1F4C8; 10 <br>
<p>Sirui Li, Kok Wai Wong, Dengya Zhu, Chun Che Fung</p></summary>
<p>

**Abstract:** Representation learning of knowledge graphs aims to embed entities and relations into low-dimensional vectors. Most existing works only consider the direct relations or paths between an entity pair. It is considered that such approaches disconnect the semantic connection of multi-relations between an entity pair, and we propose a convolutional and multi-relational representation learning model, ConvMR. The proposed ConvMR model addresses the multi-relation issue in two aspects: (1) Encoding the multi-relations between an entity pair into a unified vector that maintains the semantic connection. (2) Since not all relations are necessary while joining multi-relations, we propose an attention-based relation encoder to automatically assign weights to different relations based on semantic hierarchy. Experimental results on two popular datasets, FB15k-237 and WN18RR, achieved consistent improvements on the mean rank. We also found that ConvMR is efficient to deal with less frequent entities.

</p>
</details>

<details><summary><b>Context-Enhanced Stereo Transformer</b>
<a href="https://arxiv.org/abs/2210.11719">arxiv:2210.11719</a>
&#x1F4C8; 9 <br>
<p>Weiyu Guo, Zhaoshuo Li, Yongkui Yang, Zheng Wang, Russell H. Taylor, Mathias Unberath, Alan Yuille, Yingwei Li</p></summary>
<p>

**Abstract:** Stereo depth estimation is of great interest for computer vision research. However, existing methods struggles to generalize and predict reliably in hazardous regions, such as large uniform regions. To overcome these limitations, we propose Context Enhanced Path (CEP). CEP improves the generalization and robustness against common failure cases in existing solutions by capturing the long-range global information. We construct our stereo depth estimation model, Context Enhanced Stereo Transformer (CSTR), by plugging CEP into the state-of-the-art stereo depth estimation method Stereo Transformer. CSTR is examined on distinct public datasets, such as Scene Flow, Middlebury-2014, KITTI-2015, and MPI-Sintel. We find CSTR outperforms prior approaches by a large margin. For example, in the zero-shot synthetic-to-real setting, CSTR outperforms the best competing approaches on Middlebury-2014 dataset by 11%. Our extensive experiments demonstrate that the long-range information is critical for stereo matching task and CEP successfully captures such information.

</p>
</details>

<details><summary><b>XC: Exploring Quantitative Use Cases for Explanations in 3D Object Detection</b>
<a href="https://arxiv.org/abs/2210.11590">arxiv:2210.11590</a>
&#x1F4C8; 9 <br>
<p>Sunsheng Gu, Vahdat Abdelzad, Krzysztof Czarnecki</p></summary>
<p>

**Abstract:** Explainable AI (XAI) methods are frequently applied to obtain qualitative insights about deep models' predictions. However, such insights need to be interpreted by a human observer to be useful. In this paper, we aim to use explanations directly to make decisions without human observers. We adopt two gradient-based explanation methods, Integrated Gradients (IG) and backprop, for the task of 3D object detection. Then, we propose a set of quantitative measures, named Explanation Concentration (XC) scores, that can be used for downstream tasks. These scores quantify the concentration of attributions within the boundaries of detected objects. We evaluate the effectiveness of XC scores via the task of distinguishing true positive (TP) and false positive (FP) detected objects in the KITTI and Waymo datasets. The results demonstrate an improvement of more than 100\% on both datasets compared to other heuristics such as random guesses and the number of LiDAR points in the bounding box, raising confidence in XC's potential for application in more use cases. Our results also indicate that computationally expensive XAI methods like IG may not be more valuable when used quantitatively compare to simpler methods.

</p>
</details>

<details><summary><b>Self-Supervised Learning via Maximum Entropy Coding</b>
<a href="https://arxiv.org/abs/2210.11464">arxiv:2210.11464</a>
&#x1F4C8; 9 <br>
<p>Xin Liu, Zhongdao Wang, Yali Li, Shengjin Wang</p></summary>
<p>

**Abstract:** A mainstream type of current self-supervised learning methods pursues a general-purpose representation that can be well transferred to downstream tasks, typically by optimizing on a given pretext task such as instance discrimination. In this work, we argue that existing pretext tasks inevitably introduce biases into the learned representation, which in turn leads to biased transfer performance on various downstream tasks. To cope with this issue, we propose Maximum Entropy Coding (MEC), a more principled objective that explicitly optimizes on the structure of the representation, so that the learned representation is less biased and thus generalizes better to unseen downstream tasks. Inspired by the principle of maximum entropy in information theory, we hypothesize that a generalizable representation should be the one that admits the maximum entropy among all plausible representations. To make the objective end-to-end trainable, we propose to leverage the minimal coding length in lossy data coding as a computationally tractable surrogate for the entropy, and further derive a scalable reformulation of the objective that allows fast computation. Extensive experiments demonstrate that MEC learns a more generalizable representation than previous methods based on specific pretext tasks. It achieves state-of-the-art performance consistently on various downstream tasks, including not only ImageNet linear probe, but also semi-supervised classification, object detection, instance segmentation, and object tracking. Interestingly, we show that existing batch-wise and feature-wise self-supervised objectives could be seen equivalent to low-order approximations of MEC. Code and pre-trained models are available at https://github.com/xinliu20/MEC.

</p>
</details>

<details><summary><b>On Representations of Mean-Field Variational Inference</b>
<a href="https://arxiv.org/abs/2210.11385">arxiv:2210.11385</a>
&#x1F4C8; 9 <br>
<p>Soumyadip Ghosh, Yingdong Lu, Tomasz Nowicki, Edith Zhang</p></summary>
<p>

**Abstract:** The mean field variational inference (MFVI) formulation restricts the general Bayesian inference problem to the subspace of product measures. We present a framework to analyze MFVI algorithms, which is inspired by a similar development for general variational Bayesian formulations. Our approach enables the MFVI problem to be represented in three different manners: a gradient flow on Wasserstein space, a system of Fokker-Planck-like equations and a diffusion process. Rigorous guarantees are established to show that a time-discretized implementation of the coordinate ascent variational inference algorithm in the product Wasserstein space of measures yields a gradient flow in the limit. A similar result is obtained for their associated densities, with the limit being given by a quasi-linear partial differential equation. A popular class of practical algorithms falls in this framework, which provides tools to establish convergence. We hope this framework could be used to guarantee convergence of algorithms in a variety of approaches, old and new, to solve variational inference problems.

</p>
</details>

<details><summary><b>How Does a Deep Learning Model Architecture Impact Its Privacy?</b>
<a href="https://arxiv.org/abs/2210.11049">arxiv:2210.11049</a>
&#x1F4C8; 9 <br>
<p>Guangsheng Zhang, Bo Liu, Huan Tian, Tianqing Zhu, Ming Ding, Wanlei Zhou</p></summary>
<p>

**Abstract:** As a booming research area in the past decade, deep learning technologies have been driven by big data collected and processed on an unprecedented scale. However, the sensitive information in the collected training data raises privacy concerns. Recent research indicated that deep learning models are vulnerable to various privacy attacks, including membership inference attacks, attribute inference attacks, and gradient inversion attacks. It is noteworthy that the performance of the attacks varies from model to model. In this paper, we conduct empirical analyses to answer a fundamental question: Does model architecture affect model privacy? We investigate several representative model architectures from CNNs to Transformers, and show that Transformers are generally more vulnerable to privacy attacks than CNNs. We further demonstrate that the micro design of activation layers, stem layers, and bias parameters, are the major reasons why CNNs are more resilient to privacy attacks than Transformers. We also find that the presence of attention modules is another reason why Transformers are more vulnerable to privacy attacks. We hope our discovery can shed some new light on how to defend against the investigated privacy attacks and help the community build privacy-friendly model architectures.

</p>
</details>

<details><summary><b>Boosting Natural Language Generation from Instructions with Meta-Learning</b>
<a href="https://arxiv.org/abs/2210.11617">arxiv:2210.11617</a>
&#x1F4C8; 8 <br>
<p>Budhaditya Deb, Guoqing Zheng, Ahmed Hassan Awadallah</p></summary>
<p>

**Abstract:** Recent work has shown that language models (LMs) trained with multi-task \textit{instructional learning} (MTIL) can solve diverse NLP tasks in zero- and few-shot settings with improved performance compared to prompt tuning. MTIL illustrates that LMs can extract and use information about the task from instructions beyond the surface patterns of the inputs and outputs. This suggests that meta-learning may further enhance the utilization of instructions for effective task transfer. In this paper we investigate whether meta-learning applied to MTIL can further improve generalization to unseen tasks in a zero-shot setting. Specifically, we propose to adapt meta-learning to MTIL in three directions: 1) Model Agnostic Meta Learning (MAML), 2) Hyper-Network (HNet) based adaptation to generate task specific parameters conditioned on instructions, and 3) an approach combining HNet and MAML. Through extensive experiments on the large scale Natural Instructions V2 dataset, we show that our proposed approaches significantly improve over strong baselines in zero-shot settings. In particular, meta-learning improves the effectiveness of instructions and is most impactful when the test tasks are strictly zero-shot (i.e. no similar tasks in the training set) and are "hard" for LMs, illustrating the potential of meta-learning for MTIL for out-of-distribution tasks.

</p>
</details>

<details><summary><b>Machine-Learning Compression for Particle Physics Discoveries</b>
<a href="https://arxiv.org/abs/2210.11489">arxiv:2210.11489</a>
&#x1F4C8; 8 <br>
<p>Jack H. Collins, Yifeng Huang, Simon Knapen, Benjamin Nachman, Daniel Whiteson</p></summary>
<p>

**Abstract:** In collider-based particle and nuclear physics experiments, data are produced at such extreme rates that only a subset can be recorded for later analysis. Typically, algorithms select individual collision events for preservation and store the complete experimental response. A relatively new alternative strategy is to additionally save a partial record for a larger subset of events, allowing for later specific analysis of a larger fraction of events. We propose a strategy that bridges these paradigms by compressing entire events for generic offline analysis but at a lower fidelity. An optimal-transport-based $β$ Variational Autoencoder (VAE) is used to automate the compression and the hyperparameter $β$ controls the compression fidelity. We introduce a new approach for multi-objective learning functions by simultaneously learning a VAE appropriate for all values of $β$ through parameterization. We present an example use case, a di-muon resonance search at the Large Hadron Collider (LHC), where we show that simulated data compressed by our $β$-VAE has enough fidelity to distinguish distinct signal morphologies.

</p>
</details>

<details><summary><b>MixMask: Revisiting Masked Siamese Self-supervised Learning in Asymmetric Distance</b>
<a href="https://arxiv.org/abs/2210.11456">arxiv:2210.11456</a>
&#x1F4C8; 8 <br>
<p>Kirill Vishniakov, Eric Xing, Zhiqiang Shen</p></summary>
<p>

**Abstract:** Recent advances in self-supervised learning integrate Masked Modeling and Siamese Networks into a single framework to fully reap the advantages of both the two techniques. However, previous erasing-based masking scheme in masked image modeling is not originally designed for siamese networks. Existing approaches simply inherit the default loss design from previous siamese networks, and ignore the information loss and distance change after employing masking operation in the frameworks. In this paper, we propose a filling-based masking strategy called MixMask to prevent information loss due to the randomly erased areas of an image in vanilla masking method. We further introduce a dynamic loss function design with soft distance to adapt the integrated architecture and avoid mismatches between transformed input and objective in Masked Siamese ConvNets (MSCN). The dynamic loss distance is calculated according to the proposed mix-masking scheme. Extensive experiments are conducted on various datasets of CIFAR-100, Tiny-ImageNet and ImageNet-1K. The results demonstrate that the proposed framework can achieve better accuracy on linear probing, semi-supervised and {supervised finetuning}, which outperforms the state-of-the-art MSCN by a significant margin. We also show the superiority on downstream tasks of object detection and segmentation. Our source code is available at https://github.com/LightnessOfBeing/MixMask.

</p>
</details>

<details><summary><b>Snapshot of Algebraic Vision</b>
<a href="https://arxiv.org/abs/2210.11443">arxiv:2210.11443</a>
&#x1F4C8; 8 <br>
<p>Joe Kileel, Kathlén Kohn</p></summary>
<p>

**Abstract:** In this survey article, we present interactions between algebraic geometry and computer vision, which have recently come under the header of Algebraic Vision. The subject has given new insights in multiple view geometry and its application to 3D scene reconstruction, and carried a host of novel problems and ideas back into algebraic geometry.

</p>
</details>

<details><summary><b>TTTFlow: Unsupervised Test-Time Training with Normalizing Flow</b>
<a href="https://arxiv.org/abs/2210.11389">arxiv:2210.11389</a>
&#x1F4C8; 8 <br>
<p>David Osowiechi, Gustavo A. Vargas Hakim, Mehrdad Noori, Milad Cheraghalikhani, Ismail Ben Ayed, Christian Desrosiers</p></summary>
<p>

**Abstract:** A major problem of deep neural networks for image classification is their vulnerability to domain changes at test-time. Recent methods have proposed to address this problem with test-time training (TTT), where a two-branch model is trained to learn a main classification task and also a self-supervised task used to perform test-time adaptation. However, these techniques require defining a proxy task specific to the target application. To tackle this limitation, we propose TTTFlow: a Y-shaped architecture using an unsupervised head based on Normalizing Flows to learn the normal distribution of latent features and detect domain shifts in test examples. At inference, keeping the unsupervised head fixed, we adapt the model to domain-shifted examples by maximizing the log likelihood of the Normalizing Flow. Our results show that our method can significantly improve the accuracy with respect to previous works.

</p>
</details>

<details><summary><b>SS-VAERR: Self-Supervised Apparent Emotional Reaction Recognition from Video</b>
<a href="https://arxiv.org/abs/2210.11341">arxiv:2210.11341</a>
&#x1F4C8; 8 <br>
<p>Marija Jegorova, Stavros Petridis, Maja Pantic</p></summary>
<p>

**Abstract:** This work focuses on the apparent emotional reaction recognition (AERR) from the video-only input, conducted in a self-supervised fashion. The network is first pre-trained on different self-supervised pretext tasks and later fine-tuned on the downstream target task. Self-supervised learning facilitates the use of pre-trained architectures and larger datasets that might be deemed unfit for the target task and yet might be useful to learn informative representations and hence provide useful initializations for further fine-tuning on smaller more suitable data. Our presented contribution is two-fold: (1) an analysis of different state-of-the-art (SOTA) pretext tasks for the video-only apparent emotional reaction recognition architecture, and (2) an analysis of various combinations of the regression and classification losses that are likely to improve the performance further. Together these two contributions result in the current state-of-the-art performance for the video-only spontaneous apparent emotional reaction recognition with continuous annotations.

</p>
</details>

<details><summary><b>Play It Back: Iterative Attention for Audio Recognition</b>
<a href="https://arxiv.org/abs/2210.11328">arxiv:2210.11328</a>
&#x1F4C8; 8 <br>
<p>Alexandros Stergiou, Dima Damen</p></summary>
<p>

**Abstract:** A key function of auditory cognition is the association of characteristic sounds with their corresponding semantics over time. Humans attempting to discriminate between fine-grained audio categories, often replay the same discriminative sounds to increase their prediction confidence. We propose an end-to-end attention-based architecture that through selective repetition attends over the most discriminative sounds across the audio sequence. Our model initially uses the full audio sequence and iteratively refines the temporal segments replayed based on slot attention. At each playback, the selected segments are replayed using a smaller hop length which represents higher resolution features within these segments. We show that our method can consistently achieve state-of-the-art performance across three audio-classification benchmarks: AudioSet, VGG-Sound, and EPIC-KITCHENS-100.

</p>
</details>

<details><summary><b>Safe Policy Improvement in Constrained Markov Decision Processes</b>
<a href="https://arxiv.org/abs/2210.11259">arxiv:2210.11259</a>
&#x1F4C8; 8 <br>
<p>Luigi Berducci, Radu Grosu</p></summary>
<p>

**Abstract:** The automatic synthesis of a policy through reinforcement learning (RL) from a given set of formal requirements depends on the construction of a reward signal and consists of the iterative application of many policy-improvement steps. The synthesis algorithm has to balance target, safety, and comfort requirements in a single objective and to guarantee that the policy improvement does not increase the number of safety-requirements violations, especially for safety-critical applications. In this work, we present a solution to the synthesis problem by solving its two main challenges: reward-shaping from a set of formal requirements and safe policy update. For the former, we propose an automatic reward-shaping procedure, defining a scalar reward signal compliant with the task specification. For the latter, we introduce an algorithm ensuring that the policy is improved in a safe fashion with high-confidence guarantees. We also discuss the adoption of a model-based RL algorithm to efficiently use the collected data and train a model-free agent on the predicted trajectories, where the safety violation does not have the same impact as in the real world. Finally, we demonstrate in standard control benchmarks that the resulting learning procedure is effective and robust even under heavy perturbations of the hyperparameters.

</p>
</details>

<details><summary><b>Multi-hypothesis 3D human pose estimation metrics favor miscalibrated distributions</b>
<a href="https://arxiv.org/abs/2210.11179">arxiv:2210.11179</a>
&#x1F4C8; 8 <br>
<p>Paweł A. Pierzchlewicz, R. James Cotton, Mohammad Bashiri, Fabian H. Sinz</p></summary>
<p>

**Abstract:** Due to depth ambiguities and occlusions, lifting 2D poses to 3D is a highly ill-posed problem. Well-calibrated distributions of possible poses can make these ambiguities explicit and preserve the resulting uncertainty for downstream tasks. This study shows that previous attempts, which account for these ambiguities via multiple hypotheses generation, produce miscalibrated distributions. We identify that miscalibration can be attributed to the use of sample-based metrics such as minMPJPE. In a series of simulations, we show that minimizing minMPJPE, as commonly done, should converge to the correct mean prediction. However, it fails to correctly capture the uncertainty, thus resulting in a miscalibrated distribution. To mitigate this problem, we propose an accurate and well-calibrated model called Conditional Graph Normalizing Flow (cGNFs). Our model is structured such that a single cGNF can estimate both conditional and marginal densities within the same model - effectively solving a zero-shot density estimation problem. We evaluate cGNF on the Human~3.6M dataset and show that cGNF provides a well-calibrated distribution estimate while being close to state-of-the-art in terms of overall minMPJPE. Furthermore, cGNF outperforms previous methods on occluded joints while it remains well-calibrated.

</p>
</details>

<details><summary><b>Multitasking Models are Robust to Structural Failure: A Neural Model for Bilingual Cognitive Reserve</b>
<a href="https://arxiv.org/abs/2210.11618">arxiv:2210.11618</a>
&#x1F4C8; 7 <br>
<p>Giannis Daras, Negin Raoof, Zoi Gkalitsiou, Alexandros G. Dimakis</p></summary>
<p>

**Abstract:** We find a surprising connection between multitask learning and robustness to neuron failures. Our experiments show that bilingual language models retain higher performance under various neuron perturbations, such as random deletions, magnitude pruning and weight noise compared to equivalent monolingual ones. We provide a theoretical justification for this robustness by mathematically analyzing linear representation learning and showing that multitasking creates more robust representations. Our analysis connects robustness to spectral properties of the learned representation and proves that multitasking leads to higher robustness for diverse task vectors. We open-source our code and models: https://github.com/giannisdaras/multilingual_robustness

</p>
</details>

<details><summary><b>VIBUS: Data-efficient 3D Scene Parsing with VIewpoint Bottleneck and Uncertainty-Spectrum Modeling</b>
<a href="https://arxiv.org/abs/2210.11472">arxiv:2210.11472</a>
&#x1F4C8; 7 <br>
<p>Beiwen Tian, Liyi Luo, Hao Zhao, Guyue Zhou</p></summary>
<p>

**Abstract:** Recently, 3D scenes parsing with deep learning approaches has been a heating topic. However, current methods with fully-supervised models require manually annotated point-wise supervision which is extremely user-unfriendly and time-consuming to obtain. As such, training 3D scene parsing models with sparse supervision is an intriguing alternative. We term this task as data-efficient 3D scene parsing and propose an effective two-stage framework named VIBUS to resolve it by exploiting the enormous unlabeled points. In the first stage, we perform self-supervised representation learning on unlabeled points with the proposed Viewpoint Bottleneck loss function. The loss function is derived from an information bottleneck objective imposed on scenes under different viewpoints, making the process of representation learning free of degradation and sampling. In the second stage, pseudo labels are harvested from the sparse labels based on uncertainty-spectrum modeling. By combining data-driven uncertainty measures and 3D mesh spectrum measures (derived from normal directions and geodesic distances), a robust local affinity metric is obtained. Finite gamma/beta mixture models are used to decompose category-wise distributions of these measures, leading to automatic selection of thresholds. We evaluate VIBUS on the public benchmark ScanNet and achieve state-of-the-art results on both validation set and online test server. Ablation studies show that both Viewpoint Bottleneck and uncertainty-spectrum modeling bring significant improvements. Codes and models are publicly available at https://github.com/AIR-DISCOVER/VIBUS.

</p>
</details>

<details><summary><b>Deep conditional transformation models for survival analysis</b>
<a href="https://arxiv.org/abs/2210.11366">arxiv:2210.11366</a>
&#x1F4C8; 7 <br>
<p>Gabriele Campanella, Lucas Kook, Ida Häggström, Torsten Hothorn, Thomas J. Fuchs</p></summary>
<p>

**Abstract:** An every increasing number of clinical trials features a time-to-event outcome and records non-tabular patient data, such as magnetic resonance imaging or text data in the form of electronic health records. Recently, several neural-network based solutions have been proposed, some of which are binary classifiers. Parametric, distribution-free approaches which make full use of survival time and censoring status have not received much attention. We present deep conditional transformation models (DCTMs) for survival outcomes as a unifying approach to parametric and semiparametric survival analysis. DCTMs allow the specification of non-linear and non-proportional hazards for both tabular and non-tabular data and extend to all types of censoring and truncation. On real and semi-synthetic data, we show that DCTMs compete with state-of-the-art DL approaches to survival analysis.

</p>
</details>

<details><summary><b>Tighter PAC-Bayes Generalisation Bounds by Leveraging Example Difficulty</b>
<a href="https://arxiv.org/abs/2210.11289">arxiv:2210.11289</a>
&#x1F4C8; 7 <br>
<p>Felix Biggs, Benjamin Guedj</p></summary>
<p>

**Abstract:** We introduce a modified version of the excess risk, which can be used to obtain tighter, fast-rate PAC-Bayesian generalisation bounds. This modified excess risk leverages information about the relative hardness of data examples to reduce the variance of its empirical counterpart, tightening the bound. We combine this with a new bound for $[-1, 1]$-valued (and potentially non-independent) signed losses, which is more favourable when they empirically have low variance around $0$. The primary new technical tool is a novel result for sequences of interdependent random vectors which may be of independent interest. We empirically evaluate these new bounds on a number of real-world datasets.

</p>
</details>

<details><summary><b>Attacking Motion Estimation with Adversarial Snow</b>
<a href="https://arxiv.org/abs/2210.11242">arxiv:2210.11242</a>
&#x1F4C8; 7 <br>
<p>Jenny Schmalfuss, Lukas Mehl, Andrés Bruhn</p></summary>
<p>

**Abstract:** Current adversarial attacks for motion estimation (optical flow) optimize small per-pixel perturbations, which are unlikely to appear in the real world. In contrast, we exploit a real-world weather phenomenon for a novel attack with adversarially optimized snow. At the core of our attack is a differentiable renderer that consistently integrates photorealistic snowflakes with realistic motion into the 3D scene. Through optimization we obtain adversarial snow that significantly impacts the optical flow while being indistinguishable from ordinary snow. Surprisingly, the impact of our novel attack is largest on methods that previously showed a high robustness to small L_p perturbations.

</p>
</details>

<details><summary><b>Pruning by Active Attention Manipulation</b>
<a href="https://arxiv.org/abs/2210.11114">arxiv:2210.11114</a>
&#x1F4C8; 7 <br>
<p>Zahra Babaiee, Lucas Liebenwein, Ramin Hasani, Daniela Rus, Radu Grosu</p></summary>
<p>

**Abstract:** Filter pruning of a CNN is typically achieved by applying discrete masks on the CNN's filter weights or activation maps, post-training. Here, we present a new filter-importance-scoring concept named pruning by active attention manipulation (PAAM), that sparsifies the CNN's set of filters through a particular attention mechanism, during-training. PAAM learns analog filter scores from the filter weights by optimizing a cost function regularized by an additive term in the scores. As the filters are not independent, we use attention to dynamically learn their correlations. Moreover, by training the pruning scores of all layers simultaneously, PAAM can account for layer inter-dependencies, which is essential to finding a performant sparse sub-network. PAAM can also train and generate a pruned network from scratch in a straightforward, one-stage training process without requiring a pre-trained network. Finally, PAAM does not need layer-specific hyperparameters and pre-defined layer budgets, since it can implicitly determine the appropriate number of filters in each layer. Our experimental results on different network architectures suggest that PAAM outperforms state-of-the-art structured-pruning methods (SOTA). On CIFAR-10 dataset, without requiring a pre-trained baseline network, we obtain 1.02% and 1.19% accuracy gain and 52.3% and 54% parameters reduction, on ResNet56 and ResNet110, respectively. Similarly, on the ImageNet dataset, PAAM achieves 1.06% accuracy gain while pruning 51.1% of the parameters on ResNet50. For Cifar-10, this is better than the SOTA with a margin of 9.5% and 6.6%, respectively, and on ImageNet with a margin of 11%.

</p>
</details>

<details><summary><b>DisC-VC: Disentangled and F0-Controllable Neural Voice Conversion</b>
<a href="https://arxiv.org/abs/2210.11059">arxiv:2210.11059</a>
&#x1F4C8; 7 <br>
<p>Chihiro Watanabe, Hirokazu Kameoka</p></summary>
<p>

**Abstract:** Voice conversion is a task to convert a non-linguistic feature of a given utterance. Since naturalness of speech strongly depends on its pitch pattern, in some applications, it would be desirable to keep the original rise/fall pitch pattern while changing the speaker identity. Some of the existing methods address this problem by either using a source-filter model or developing a neural network that takes an F0 pattern as input to the model. Although the latter approach can achieve relatively high sound quality compared to the former one, there is no consideration for discrepancy between the target and generated F0 patterns in its training process. In this paper, we propose a new variational-autoencoder-based voice conversion model accompanied by an auxiliary network, which ensures that the conversion result correctly reflects the specified F0/timbre information. We show the effectiveness of the proposed method by objective and subjective evaluations.

</p>
</details>

<details><summary><b>Enhancing Out-of-Distribution Detection in Natural Language Understanding via Implicit Layer Ensemble</b>
<a href="https://arxiv.org/abs/2210.11034">arxiv:2210.11034</a>
&#x1F4C8; 7 <br>
<p>Hyunsoo Cho, Choonghyun Park, Jaewook Kang, Kang Min Yoo, Taeuk Kim, Sang-goo Lee</p></summary>
<p>

**Abstract:** Out-of-distribution (OOD) detection aims to discern outliers from the intended data distribution, which is crucial to maintaining high reliability and a good user experience. Most recent studies in OOD detection utilize the information from a single representation that resides in the penultimate layer to determine whether the input is anomalous or not. Although such a method is straightforward, the potential of diverse information in the intermediate layers is overlooked. In this paper, we propose a novel framework based on contrastive learning that encourages intermediate features to learn layer-specialized representations and assembles them implicitly into a single representation to absorb rich information in the pre-trained language model. Extensive experiments in various intent classification and OOD datasets demonstrate that our approach is significantly more effective than other works.

</p>
</details>

<details><summary><b>Adaptive re-calibration of channel-wise features for Adversarial Audio Classification</b>
<a href="https://arxiv.org/abs/2210.11722">arxiv:2210.11722</a>
&#x1F4C8; 6 <br>
<p>Vardhan Dongre, Abhinav Thimma Reddy, Nikhitha Reddeddy</p></summary>
<p>

**Abstract:** DeepFake Audio, unlike DeepFake images and videos, has been relatively less explored from detection perspective, and the solutions which exist for the synthetic speech classification either use complex networks or dont generalize to different varieties of synthetic speech obtained using different generative and optimization-based methods. Through this work, we propose a channel-wise recalibration of features using attention feature fusion for synthetic speech detection and compare its performance against different detection methods including End2End models and Resnet-based models on synthetic speech generated using Text to Speech and Vocoder systems like WaveNet, WaveRNN, Tactotron, and WaveGlow. We also experiment with Squeeze Excitation (SE) blocks in our Resnet models and found that the combination was able to get better performance. In addition to the analysis, we also demonstrate that the combination of Linear frequency cepstral coefficients (LFCC) and Mel Frequency cepstral coefficients (MFCC) using the attentional feature fusion technique creates better input features representations which can help even simpler models generalize well on synthetic speech classification tasks. Our models (Resnet based using feature fusion) trained on Fake or Real (FoR) dataset and were able to achieve 95% test accuracy with the FoR data, and an average of 90% accuracy with samples we generated using different generative models after adapting this framework.

</p>
</details>

<details><summary><b>CRT-6D: Fast 6D Object Pose Estimation with Cascaded Refinement Transformers</b>
<a href="https://arxiv.org/abs/2210.11718">arxiv:2210.11718</a>
&#x1F4C8; 6 <br>
<p>Pedro Castro, Tae-Kyun Kim</p></summary>
<p>

**Abstract:** Learning based 6D object pose estimation methods rely on computing large intermediate pose representations and/or iteratively refining an initial estimation with a slow render-compare pipeline. This paper introduces a novel method we call Cascaded Pose Refinement Transformers, or CRT-6D. We replace the commonly used dense intermediate representation with a sparse set of features sampled from the feature pyramid we call OSKFs(Object Surface Keypoint Features) where each element corresponds to an object keypoint. We employ lightweight deformable transformers and chain them together to iteratively refine proposed poses over the sampled OSKFs. We achieve inference runtimes 2x faster than the closest real-time state of the art methods while supporting up to 21 objects on a single model. We demonstrate the effectiveness of CRT-6D by performing extensive experiments on the LM-O and YCBV datasets. Compared to real-time methods, we achieve state of the art on LM-O and YCB-V, falling slightly behind methods with inference runtimes one order of magnitude higher. The source code is available at: https://github.com/PedroCastro/CRT-6D

</p>
</details>

<details><summary><b>Multi-View Reasoning: Consistent Contrastive Learning for Math Word Problem</b>
<a href="https://arxiv.org/abs/2210.11694">arxiv:2210.11694</a>
&#x1F4C8; 6 <br>
<p>Wenqi Zhang, Yongliang Shen, Yanna Ma, Xiaoxia Cheng, Zeqi Tan, Qingpeng Nong, Weiming Lu</p></summary>
<p>

**Abstract:** Math word problem solver requires both precise relation reasoning about quantities in the text and reliable generation for the diverse equation. Current sequence-to-tree or relation extraction methods regard this only from a fixed view, struggling to simultaneously handle complex semantics and diverse equations. However, human solving naturally involves two consistent reasoning views: top-down and bottom-up, just as math equations also can be expressed in multiple equivalent forms: pre-order and post-order. We propose a multi-view consistent contrastive learning for a more complete semantics-to-equation mapping. The entire process is decoupled into two independent but consistent views: top-down decomposition and bottom-up construction, and the two reasoning views are aligned in multi-granularity for consistency, enhancing global generation and precise reasoning. Experiments on multiple datasets across two languages show our approach significantly outperforms the existing baselines, especially on complex problems. We also show after consistent alignment, multi-view can absorb the merits of both views and generate more diverse results consistent with the mathematical laws.

</p>
</details>

<details><summary><b>RGB-Only Reconstruction of Tabletop Scenes for Collision-Free Manipulator Control</b>
<a href="https://arxiv.org/abs/2210.11668">arxiv:2210.11668</a>
&#x1F4C8; 6 <br>
<p>Zhenggang Tang, Balakumar Sundaralingam, Jonathan Tremblay, Bowen Wen, Ye Yuan, Stephen Tyree, Charles Loop, Alexander Schwing, Stan Birchfield</p></summary>
<p>

**Abstract:** We present a system for collision-free control of a robot manipulator that uses only RGB views of the world. Perceptual input of a tabletop scene is provided by multiple images of an RGB camera (without depth) that is either handheld or mounted on the robot end effector. A NeRF-like process is used to reconstruct the 3D geometry of the scene, from which the Euclidean full signed distance function (ESDF) is computed. A model predictive control algorithm is then used to control the manipulator to reach a desired pose while avoiding obstacles in the ESDF. We show results on a real dataset collected and annotated in our lab.

</p>
</details>

<details><summary><b>PaCo: Parameter-Compositional Multi-Task Reinforcement Learning</b>
<a href="https://arxiv.org/abs/2210.11653">arxiv:2210.11653</a>
&#x1F4C8; 6 <br>
<p>Lingfeng Sun, Haichao Zhang, Wei Xu, Masayoshi Tomizuka</p></summary>
<p>

**Abstract:** The purpose of multi-task reinforcement learning (MTRL) is to train a single policy that can be applied to a set of different tasks. Sharing parameters allows us to take advantage of the similarities among tasks. However, the gaps between contents and difficulties of different tasks bring us challenges on both which tasks should share the parameters and what parameters should be shared, as well as the optimization challenges due to parameter sharing. In this work, we introduce a parameter-compositional approach (PaCo) as an attempt to address these challenges. In this framework, a policy subspace represented by a set of parameters is learned. Policies for all the single tasks lie in this subspace and can be composed by interpolating with the learned set. It allows not only flexible parameter sharing but also a natural way to improve training. We demonstrate the state-of-the-art performance on Meta-World benchmarks, verifying the effectiveness of the proposed approach.

</p>
</details>

<details><summary><b>Overexposure Mask Fusion: Generalizable Reverse ISP Multi-Step Refinement</b>
<a href="https://arxiv.org/abs/2210.11511">arxiv:2210.11511</a>
&#x1F4C8; 6 <br>
<p>Jinha Kim, Jun Jiang, Jinwei Gu</p></summary>
<p>

**Abstract:** With the advent of deep learning methods replacing the ISP in transforming sensor RAW readings into RGB images, numerous methodologies solidified into real-life applications. Equally potent is the task of inverting this process which will have applications in enhancing computational photography tasks that are conducted in the RAW domain, addressing lack of available RAW data while reaping from the benefits of performing tasks directly on sensor readings. This paper's proposed methodology is a state-of-the-art solution to the task of RAW reconstruction, and the multi-step refinement process integrating an overexposure mask is novel in three ways: instead of from RGB to bayer, the pipeline trains from RGB to demosaiced RAW allowing use of perceptual loss functions; the multi-step processes has greatly enhanced the performance of the baseline U-Net from start to end; the pipeline is a generalizable process of refinement that can enhance other high performance methodologies that support end-to-end learning.

</p>
</details>

<details><summary><b>Global Convergence of SGD On Two Layer Neural Nets</b>
<a href="https://arxiv.org/abs/2210.11452">arxiv:2210.11452</a>
&#x1F4C8; 6 <br>
<p>Pulkit Gopalani, Anirbit Mukherjee</p></summary>
<p>

**Abstract:** In this note we demonstrate provable convergence of SGD to the global minima of appropriately regularized $\ell_2-$empirical risk of depth $2$ nets -- for arbitrary data and with any number of gates, if they are using adequately smooth and bounded activations like sigmoid and tanh. We build on the results in [1] and leverage a constant amount of Frobenius norm regularization on the weights, along with sampling of the initial weights from an appropriate distribution. We also give a continuous time SGD convergence result that also applies to smooth unbounded activations like SoftPlus. Our key idea is to show the existence loss functions on constant sized neural nets which are "Villani Functions". [1] Bin Shi, Weijie J. Su, and Michael I. Jordan. On learning rates and schrödinger operators, 2020. arXiv:2004.06977

</p>
</details>

<details><summary><b>Augmentative Topology Agents For Open-Ended Learning</b>
<a href="https://arxiv.org/abs/2210.11442">arxiv:2210.11442</a>
&#x1F4C8; 6 <br>
<p>Muhammad Umair Nasir, Michael Beukman, Steven James, Christopher Wesley Cleghorn</p></summary>
<p>

**Abstract:** In this work, we tackle the problem of open-ended learning by introducing a method that simultaneously evolves agents and increasingly challenging environments. Unlike previous open-ended approaches that optimize agents using a fixed neural network topology, we hypothesize that generalization can be improved by allowing agents' controllers to become more complex as they encounter more difficult environments. Our method, Augmentative Topology EPOET (ATEP), extends the Enhanced Paired Open-Ended Trailblazer (EPOET) algorithm by allowing agents to evolve their own neural network structures over time, adding complexity and capacity as necessary. Empirical results demonstrate that ATEP results in general agents capable of solving more environments than a fixed-topology baseline. We also investigate mechanisms for transferring agents between environments and find that a species-based approach further improves the performance and generalization of agents.

</p>
</details>

<details><summary><b>Krylov-Bellman boosting: Super-linear policy evaluation in general state spaces</b>
<a href="https://arxiv.org/abs/2210.11377">arxiv:2210.11377</a>
&#x1F4C8; 6 <br>
<p>Eric Xia, Martin J. Wainwright</p></summary>
<p>

**Abstract:** We present and analyze the Krylov-Bellman Boosting (KBB) algorithm for policy evaluation in general state spaces. It alternates between fitting the Bellman residual using non-parametric regression (as in boosting), and estimating the value function via the least-squares temporal difference (LSTD) procedure applied with a feature set that grows adaptively over time. By exploiting the connection to Krylov methods, we equip this method with two attractive guarantees. First, we provide a general convergence bound that allows for separate estimation errors in residual fitting and LSTD computation. Consistent with our numerical experiments, this bound shows that convergence rates depend on the restricted spectral structure, and are typically super-linear. Second, by combining this meta-result with sample-size dependent guarantees for residual fitting and LSTD computation, we obtain concrete statistical guarantees that depend on the sample size along with the complexity of the function class used to fit the residuals. We illustrate the behavior of the KBB algorithm for various types of policy evaluation problems, and typically find large reductions in sample complexity relative to the standard approach of fitted value iterationn.

</p>
</details>

<details><summary><b>Comparing Machine Learning Techniques for Alfalfa Biomass Yield Prediction</b>
<a href="https://arxiv.org/abs/2210.11226">arxiv:2210.11226</a>
&#x1F4C8; 6 <br>
<p>Jonathan Vance, Khaled Rasheed, Ali Missaoui, Frederick Maier, Christian Adkins, Chris Whitmire</p></summary>
<p>

**Abstract:** The alfalfa crop is globally important as livestock feed, so highly efficient planting and harvesting could benefit many industries, especially as the global climate changes and traditional methods become less accurate. Recent work using machine learning (ML) to predict yields for alfalfa and other crops has shown promise. Previous efforts used remote sensing, weather, planting, and soil data to train machine learning models for yield prediction. However, while remote sensing works well, the models require large amounts of data and cannot make predictions until the harvesting season begins. Using weather and planting data from alfalfa variety trials in Kentucky and Georgia, our previous work compared feature selection techniques to find the best technique and best feature set. In this work, we trained a variety of machine learning models, using cross validation for hyperparameter optimization, to predict biomass yields, and we showed better accuracy than similar work that employed more complex techniques. Our best individual model was a random forest with a mean absolute error of 0.081 tons/acre and R{$^2$} of 0.941. Next, we expanded this dataset to include Wisconsin and Mississippi, and we repeated our experiments, obtaining a higher best R{$^2$} of 0.982 with a regression tree. We then isolated our testing datasets by state to explore this problem's eligibility for domain adaptation (DA), as we trained on multiple source states and tested on one target state. This Trivial DA (TDA) approach leaves plenty of room for improvement through exploring more complex DA techniques in forthcoming work.

</p>
</details>

<details><summary><b>Doctors Handwritten Prescription Recognition System In Multi Language Using Deep Learning</b>
<a href="https://arxiv.org/abs/2210.11666">arxiv:2210.11666</a>
&#x1F4C8; 5 <br>
<p>Pavithiran G, Sharan Padmanabhan, Nuvvuru Divya, Aswathy V, Irene Jerusha P, Chandar B</p></summary>
<p>

**Abstract:** Doctors typically write in incomprehensible handwriting, making it difficult for both the general public and some pharmacists to understand the medications they have prescribed. It is not ideal for them to write the prescription quietly and methodically because they will be dealing with dozens of patients every day and will be swamped with work.As a result, their handwriting is illegible. This may result in reports or prescriptions consisting of short forms and cursive writing that a typical person or pharmacist won't be able to read properly, which will cause prescribed medications to be misspelled. However, some individuals are accustomed to writing prescriptions in regional languages because we all live in an area with a diversity of regional languages. It makes analyzing the content much more challenging. So, in this project, we'll use a recognition system to build a tool that can translate the handwriting of physicians in any language. This system will be made into an application which is fully autonomous in functioning. As the user uploads the prescription image the program will pre-process the image by performing image pre-processing, and word segmentations initially before processing the image for training. And it will be done for every language we require the model to detect. And as of the deduction model will be made using deep learning techniques including CNN, RNN, and LSTM, which are utilized to train the model. To match words from various languages that will be written in the system, Unicode will be used. Furthermore, fuzzy search and market basket analysis are employed to offer an end result that will be optimized from the pharmaceutical database and displayed to the user as a structured output.

</p>
</details>

<details><summary><b>Graphically Structured Diffusion Models</b>
<a href="https://arxiv.org/abs/2210.11633">arxiv:2210.11633</a>
&#x1F4C8; 5 <br>
<p>Christian Weilbach, William Harvey, Frank Wood</p></summary>
<p>

**Abstract:** We introduce a framework for automatically defining and learning deep generative models with problem-specific structure. We tackle problem domains that are more traditionally solved by algorithms such as sorting, constraint satisfaction for Sudoku, and matrix factorization. Concretely, we train diffusion models with an architecture tailored to the problem specification. This problem specification should contain a graphical model describing relationships between variables, and often benefits from explicit representation of subcomputations. Permutation invariances can also be exploited. Across a diverse set of experiments we improve the scaling relationship between problem dimension and our model's performance, in terms of both training time and final accuracy.

</p>
</details>

<details><summary><b>3DALL-E: Integrating Text-to-Image AI in 3D Design Workflows</b>
<a href="https://arxiv.org/abs/2210.11603">arxiv:2210.11603</a>
&#x1F4C8; 5 <br>
<p>Vivian Liu, Jo Vermeulen, George Fitzmaurice, Justin Matejka</p></summary>
<p>

**Abstract:** Text-to-image AI systems are capable of generating novel images for inspiration, but their applications for 3D design workflows and how designers can build 3D models using AI-provided inspiration is less understood. To investigate this, we integrated DALL-E, GPT-3, and CLIP within a CAD software in 3DALL-E, a plugin that allows users to construct text and image prompts based on what they are modelling. In a study with 13 designers, we found that designers saw great potential to incorporate 3DALL-E into their workflows and to use text-to-image AI for reference images, renders, materials, and design considerations. Additionally, we elaborate on prompting patterns and provide measures of prompt complexity observed across participants. We conclude on a discussion of how 3DALL-E can merge with existing generative design workflows and propose prompt bibliographies as a form of human-AI design history.

</p>
</details>

<details><summary><b>Rethinking Learning Approaches for Long-Term Action Anticipation</b>
<a href="https://arxiv.org/abs/2210.11566">arxiv:2210.11566</a>
&#x1F4C8; 5 <br>
<p>Megha Nawhal, Akash Abdu Jyothi, Greg Mori</p></summary>
<p>

**Abstract:** Action anticipation involves predicting future actions having observed the initial portion of a video. Typically, the observed video is processed as a whole to obtain a video-level representation of the ongoing activity in the video, which is then used for future prediction. We introduce ANTICIPATR which performs long-term action anticipation leveraging segment-level representations learned using individual segments from different activities, in addition to a video-level representation. We propose a two-stage learning approach to train a novel transformer-based model that uses these two types of representations to directly predict a set of future action instances over any given anticipation duration. Results on Breakfast, 50Salads, Epic-Kitchens-55, and EGTEA Gaze+ datasets demonstrate the effectiveness of our approach.

</p>
</details>

<details><summary><b>Similarity of Neural Architectures Based on Input Gradient Transferability</b>
<a href="https://arxiv.org/abs/2210.11407">arxiv:2210.11407</a>
&#x1F4C8; 5 <br>
<p>Jaehui Hwang, Dongyoon Han, Byeongho Heo, Song Park, Sanghyuk Chun, Jong-Seok Lee</p></summary>
<p>

**Abstract:** In this paper, we aim to design a quantitative similarity function between two neural architectures. Specifically, we define a model similarity using input gradient transferability. We generate adversarial samples of two networks and measure the average accuracy of the networks on adversarial samples of each other. If two networks are highly correlated, then the attack transferability will be high, resulting in high similarity. Using the similarity score, we investigate two topics: (1) Which network component contributes to the model diversity? (2) How does model diversity affect practical scenarios? We answer the first question by providing feature importance analysis and clustering analysis. The second question is validated by two different scenarios: model ensemble and knowledge distillation. Our findings show that model diversity takes a key role when interacting with different neural architectures. For example, we found that more diversity leads to better ensemble performance. We also observe that the relationship between teacher and student networks and distillation performance depends on the choice of the base architecture of the teacher and student networks. We expect our analysis tool helps a high-level understanding of differences between various neural architectures as well as practical guidance when using multiple architectures.

</p>
</details>

<details><summary><b>Physics-informed deep diffusion MRI reconstruction: break the bottleneck of training data in artificial intelligence</b>
<a href="https://arxiv.org/abs/2210.11388">arxiv:2210.11388</a>
&#x1F4C8; 5 <br>
<p>Chen Qian, Zi Wang, Xinlin Zhang, Qingrui Cai, Taishan Kang, Boyu Jiang, Ran Tao, Zhigang Wu, Di Guo, Xiaobo Qu</p></summary>
<p>

**Abstract:** In this work, we propose a Physics-Informed Deep Diffusion magnetic resonance imaging (DWI) reconstruction method (PIDD). PIDD contains two main components: The multi-shot DWI data synthesis and a deep learning reconstruction network. For data synthesis, we first mathematically analyze the motion during the multi-shot data acquisition and approach it by a simplified physical motion model. The motion model inspires a polynomial model for motion-induced phase synthesis. Then, lots of synthetic phases are combined with a few real data to generate a large amount of training data. For reconstruction network, we exploit the smoothness property of each shot image phase as learnable convolution kernels in the k-space and complementary sparsity in the image domain. Results on both synthetic and in vivo brain data show that, the proposed PIDD trained on synthetic data enables sub-second ultra-fast, high-quality, and robust reconstruction with different b-values and undersampling patterns.

</p>
</details>

<details><summary><b>Network Synthetic Interventions: A Framework for Panel Data with Network Interference</b>
<a href="https://arxiv.org/abs/2210.11355">arxiv:2210.11355</a>
&#x1F4C8; 5 <br>
<p>Anish Agarwal, Sarah Cen, Devavrat Shah, Christina Lee Yu</p></summary>
<p>

**Abstract:** We propose a generalization of the synthetic controls and synthetic interventions methodology to incorporate network interference. We consider the estimation of unit-specific treatment effects from panel data where there are spillover effects across units and in the presence of unobserved confounding. Key to our approach is a novel latent factor model that takes into account network interference and generalizes the factor models typically used in panel data settings. We propose an estimator, "network synthetic interventions", and show that it consistently estimates the mean outcomes for a unit under an arbitrary sequence of treatments for itself and its neighborhood, given certain observation patterns hold in the data. We corroborate our theoretical findings with simulations.

</p>
</details>

<details><summary><b>Removing grid structure in angle-resolved photoemission spectra via deep learning method</b>
<a href="https://arxiv.org/abs/2210.11200">arxiv:2210.11200</a>
&#x1F4C8; 5 <br>
<p>Junde Liu, Dongchen Huang, Yi-feng Yang, Tian Qian</p></summary>
<p>

**Abstract:** Spectroscopic data may often contain unwanted extrinsic signals. For example, in ARPES experiment, a wire mesh is typically placed in front of the CCD to block stray photo-electrons, but could cause a grid-like structure in the spectra during quick measurement mode. In the past, this structure was often removed using the mathematical Fourier filtering method by erasing the periodic structure. However, this method may lead to information loss and vacancies in the spectra because the grid structure is not strictly linearly superimposed. Here, we propose a deep learning method to effectively overcome this problem. Our method takes advantage of the self-correlation information within the spectra themselves and can greatly optimize the quality of the spectra while removing the grid structure and noise simultaneously. It has the potential to be extended to all spectroscopic measurements to eliminate other extrinsic signals and enhance the spectral quality based on the self-correlation of the spectra solely.

</p>
</details>

<details><summary><b>General Image Descriptors for Open World Image Retrieval using ViT CLIP</b>
<a href="https://arxiv.org/abs/2210.11141">arxiv:2210.11141</a>
&#x1F4C8; 5 <br>
<p>Marcos V. Conde, Ivan Aerlic, Simon Jégou</p></summary>
<p>

**Abstract:** The Google Universal Image Embedding (GUIE) Challenge is one of the first competitions in multi-domain image representations in the wild, covering a wide distribution of objects: landmarks, artwork, food, etc. This is a fundamental computer vision problem with notable applications in image retrieval, search engines and e-commerce. In this work, we explain our 4th place solution to the GUIE Challenge, and our "bag of tricks" to fine-tune zero-shot Vision Transformers (ViT) pre-trained using CLIP.

</p>
</details>

<details><summary><b>Entire Space Counterfactual Learning: Tuning, Analytical Properties and Industrial Applications</b>
<a href="https://arxiv.org/abs/2210.11039">arxiv:2210.11039</a>
&#x1F4C8; 5 <br>
<p>Hao Wang, Zhichao Chen, Jiajun Fan, Yuxin Huang, Weiming Liu, Xinggao Liu</p></summary>
<p>

**Abstract:** As a basic research problem for building effective recommender systems, post-click conversion rate (CVR) estimation has long been plagued by sample selection bias and data sparsity issues. To address the data sparsity issue, prevalent methods based on entire space multi-task model leverage the sequential pattern of user actions, i.e. exposure $\rightarrow$ click $\rightarrow$ conversion to construct auxiliary learning tasks. However, they still fall short of guaranteeing the unbiasedness of CVR estimates. This paper theoretically demonstrates two defects of these entire space multi-task models: (1) inherent estimation bias (IEB) for CVR estimation, where the CVR estimate is inherently higher than the ground truth; (2) potential independence priority (PIP) for CTCVR estimation, where the causality from click to conversion might be overlooked. This paper further proposes a principled method named entire space counterfactual multi-task model (ESCM$^2$), which employs a counterfactual risk minimizer to handle both IEB and PIP issues at once. To demonstrate the effectiveness of the proposed method, this paper explores its parameter tuning in practice, derives its analytic properties, and showcases its effectiveness in industrial CVR estimation, where ESCM$^2$ can effectively alleviate the intrinsic IEB and PIP issues and outperform baseline models.

</p>
</details>

<details><summary><b>Learning Robust Dynamics through Variational Sparse Gating</b>
<a href="https://arxiv.org/abs/2210.11698">arxiv:2210.11698</a>
&#x1F4C8; 4 <br>
<p>Arnav Kumar Jain, Shivakanth Sujit, Shruti Joshi, Vincent Michalski, Danijar Hafner, Samira Ebrahimi-Kahou</p></summary>
<p>

**Abstract:** Learning world models from their sensory inputs enables agents to plan for actions by imagining their future outcomes. World models have previously been shown to improve sample-efficiency in simulated environments with few objects, but have not yet been applied successfully to environments with many objects. In environments with many objects, often only a small number of them are moving or interacting at the same time. In this paper, we investigate integrating this inductive bias of sparse interactions into the latent dynamics of world models trained from pixels. First, we introduce Variational Sparse Gating (VSG), a latent dynamics model that updates its feature dimensions sparsely through stochastic binary gates. Moreover, we propose a simplified architecture Simple Variational Sparse Gating (SVSG) that removes the deterministic pathway of previous models, resulting in a fully stochastic transition function that leverages the VSG mechanism. We evaluate the two model architectures in the BringBackShapes (BBS) environment that features a large number of moving objects and partial observability, demonstrating clear improvements over prior models.

</p>
</details>

<details><summary><b>Learning Action Duration and Synergy in Task Planning for Human-Robot Collaboration</b>
<a href="https://arxiv.org/abs/2210.11660">arxiv:2210.11660</a>
&#x1F4C8; 4 <br>
<p>Samuele Sandrini, Marco Faroni, Nicola Pedrocchi</p></summary>
<p>

**Abstract:** A good estimation of the actions' cost is key in task planning for human-robot collaboration. The duration of an action depends on agents' capabilities and the correlation between actions performed simultaneously by the human and the robot. This paper proposes an approach to learning actions' costs and coupling between actions executed concurrently by humans and robots. We leverage the information from past executions to learn the average duration of each action and a synergy coefficient representing the effect of an action performed by the human on the duration of the action performed by the robot (and vice versa). We implement the proposed method in a simulated scenario where both agents can access the same area simultaneously. Safety measures require the robot to slow down when the human is close, denoting a bad synergy of tasks operating in the same area. We show that our approach can learn such bad couplings so that a task planner can leverage this information to find better plans.

</p>
</details>

<details><summary><b>Dense Paraphrasing for Textual Enrichment</b>
<a href="https://arxiv.org/abs/2210.11563">arxiv:2210.11563</a>
&#x1F4C8; 4 <br>
<p>Jingxuan Tu, Kyeongmin Rim, Eben Holderness, James Pustejovsky</p></summary>
<p>

**Abstract:** Understanding inferences and answering questions from text requires more than merely recovering surface arguments, adjuncts, or strings associated with the query terms. As humans, we interpret sentences as contextualized components of a narrative or discourse, by both filling in missing information, and reasoning about event consequences. In this paper, we define the process of rewriting a textual expression (lexeme or phrase) such that it reduces ambiguity while also making explicit the underlying semantics that is not (necessarily) expressed in the economy of sentence structure as Dense Paraphrasing (DP). We build the first complete DP dataset, provide the scope and design of the annotation task, and present results demonstrating how this DP process can enrich a source text to improve inferencing and QA task performance. The data and the source code will be publicly available.

</p>
</details>

<details><summary><b>Local SGD in Overparameterized Linear Regression</b>
<a href="https://arxiv.org/abs/2210.11562">arxiv:2210.11562</a>
&#x1F4C8; 4 <br>
<p>Mike Nguyen, Charly Kirst, Nicole Mücke</p></summary>
<p>

**Abstract:** We consider distributed learning using constant stepsize SGD (DSGD) over several devices, each sending a final model update to a central server. In a final step, the local estimates are aggregated. We prove in the setting of overparameterized linear regression general upper bounds with matching lower bounds and derive learning rates for specific data generating distributions. We show that the excess risk is of order of the variance provided the number of local nodes grows not too large with the global sample size. We further compare the sample complexity of DSGD with the sample complexity of distributed ridge regression (DRR) and show that the excess SGD-risk is smaller than the excess RR-risk, where both sample complexities are of the same order.

</p>
</details>

<details><summary><b>Low-Rank Representations Towards Classification Problem of Complex Networks</b>
<a href="https://arxiv.org/abs/2210.11561">arxiv:2210.11561</a>
&#x1F4C8; 4 <br>
<p>Murat Çelik, Ali Baran Taşdemir, Lale Özkahya</p></summary>
<p>

**Abstract:** Complex networks representing social interactions, brain activities, molecular structures have been studied widely to be able to understand and predict their characteristics as graphs. Models and algorithms for these networks are used in real-life applications, such as search engines, and recommender systems. In general, such networks are modelled by constructing a low-dimensional Euclidean embedding of the vertices of the network, where proximity of the vertices in the Euclidean space hints the likelihood of an edge (link). In this work, we study the performance of such low-rank representations of real-life networks on a network classification problem.

</p>
</details>

<details><summary><b>An Improved Algorithm for Clustered Federated Learning</b>
<a href="https://arxiv.org/abs/2210.11538">arxiv:2210.11538</a>
&#x1F4C8; 4 <br>
<p> Harshvardhan, Avishek Ghosh, Arya Mazumdar</p></summary>
<p>

**Abstract:** In this paper, we address the dichotomy between heterogeneous models and simultaneous training in Federated Learning (FL) via a clustering framework. We define a new clustering model for FL based on the (optimal) local models of the users: two users belong to the same cluster if their local models are close; otherwise they belong to different clusters. A standard algorithm for clustered FL is proposed in \cite{ghosh_efficient_2021}, called \texttt{IFCA}, which requires \emph{suitable} initialization and the knowledge of hyper-parameters like the number of clusters (which is often quite difficult to obtain in practical applications) to converge. We propose an improved algorithm, \emph{Successive Refine Federated Clustering Algorithm} (\texttt{SR-FCA}), which removes such restrictive assumptions. \texttt{SR-FCA} treats each user as a singleton cluster as an initialization, and then successively refine the cluster estimation via exploiting similar users belonging to the same cluster. In any intermediate step, \texttt{SR-FCA} uses a robust federated learning algorithm within each cluster to exploit simultaneous training and to correct clustering errors. Furthermore, \texttt{SR-FCA} does not require any \emph{good} initialization (warm start), both in theory and practice. We show that with proper choice of learning rate, \texttt{SR-FCA} incurs arbitrarily small clustering error. Additionally, we validate the performance of our algorithm on standard FL datasets in non-convex problems like neural nets, and we show the benefits of \texttt{SR-FCA} over baselines.

</p>
</details>

<details><summary><b>DNN-ForwardTesting: A New Trading Strategy Validation using Statistical Timeseries Analysis and Deep Neural Networks</b>
<a href="https://arxiv.org/abs/2210.11532">arxiv:2210.11532</a>
&#x1F4C8; 4 <br>
<p>Ivan Letteri, Giuseppe Della Penna, Giovanni De Gasperis, Abeer Dyoub</p></summary>
<p>

**Abstract:** In general, traders test their trading strategies by applying them on the historical market data (backtesting), and then apply to the future trades the strategy that achieved the maximum profit on such past data.
  In this paper, we propose a new trading strategy, called DNN-forwardtesting, that determines the strategy to apply by testing it on the possible future predicted by a deep neural network that has been designed to perform stock price forecasts and trained with the market historical data.
  In order to generate such an historical dataset, we first perform an exploratory data analysis on a set of ten securities and, in particular, analize their volatility through a novel k-means-based procedure. Then, we restrict the dataset to a small number of assets with the same volatility coefficient and use such data to train a deep feed-forward neural network that forecasts the prices for the next 30 days of open stocks market. Finally, our trading system calculates the most effective technical indicator by applying it to the DNNs predictions and uses such indicator to guide its trades.
  The results confirm that neural networks outperform classical statistical techniques when performing such forecasts, and their predictions allow to select a trading strategy that, when applied to the real future, increases Expectancy, Sharpe, Sortino, and Calmar ratios with respect to the strategy selected through traditional backtesting.

</p>
</details>

<details><summary><b>Theoretical analysis of deep neural networks for temporally dependent observations</b>
<a href="https://arxiv.org/abs/2210.11530">arxiv:2210.11530</a>
&#x1F4C8; 4 <br>
<p>Mingliang Ma, Abolfazl Safikhani</p></summary>
<p>

**Abstract:** Deep neural networks are powerful tools to model observations over time with non-linear patterns. Despite the widespread use of neural networks in such settings, most theoretical developments of deep neural networks are under the assumption of independent observations, and theoretical results for temporally dependent observations are scarce. To bridge this gap, we study theoretical properties of deep neural networks on modeling non-linear time series data. Specifically, non-asymptotic bounds for prediction error of (sparse) feed-forward neural network with ReLU activation function is established under mixing-type assumptions. These assumptions are mild such that they include a wide range of time series models including auto-regressive models. Compared to independent observations, established convergence rates have additional logarithmic factors to compensate for additional complexity due to dependence among data points. The theoretical results are supported via various numerical simulation settings as well as an application to a macroeconomic data set.

</p>
</details>

<details><summary><b>Multimodal Neural Network For Demand Forecasting</b>
<a href="https://arxiv.org/abs/2210.11502">arxiv:2210.11502</a>
&#x1F4C8; 4 <br>
<p>Nitesh Kumar, Kumar Dheenadayalan, Suprabath Reddy, Sumant Kulkarni</p></summary>
<p>

**Abstract:** Demand forecasting applications have immensely benefited from the state-of-the-art Deep Learning methods used for time series forecasting. Traditional uni-modal models are predominantly seasonality driven which attempt to model the demand as a function of historic sales along with information on holidays and promotional events. However, accurate and robust sales forecasting calls for accommodating multiple other factors, such as natural calamities, pandemics, elections, etc., impacting the demand for products and product categories in general. We propose a multi-modal sales forecasting network that combines real-life events from news articles with traditional data such as historical sales and holiday information. Further, we fuse information from general product trends published by Google trends. Empirical results show statistically significant improvements in the SMAPE error metric with an average improvement of 7.37% against the existing state-of-the-art sales forecasting techniques on a real-world supermarket dataset.

</p>
</details>

<details><summary><b>ObSynth: An Interactive Synthesis System for Generating Object Models from Natural Language Specifications</b>
<a href="https://arxiv.org/abs/2210.11468">arxiv:2210.11468</a>
&#x1F4C8; 4 <br>
<p>Alex Gu, Tamara Mitrovska, Daniela Velez, Jacob Andreas, Armando Solar-Lezama</p></summary>
<p>

**Abstract:** We introduce ObSynth, an interactive system leveraging the domain knowledge embedded in large language models (LLMs) to help users design object models from high level natural language prompts. This is an example of specification reification, the process of taking a high-level, potentially vague specification and reifying it into a more concrete form. We evaluate ObSynth via a user study, leading to three key findings: first, object models designed using ObSynth are more detailed, showing that it often synthesizes fields users might have otherwise omitted. Second, a majority of objects, methods, and fields generated by ObSynth are kept by the user in the final object model, highlighting the quality of generated components. Third, ObSynth altered the workflow of participants: they focus on checking that synthesized components were correct rather than generating them from scratch, though ObSynth did not reduce the time participants took to generate object models.

</p>
</details>

<details><summary><b>Surgical Fine-Tuning Improves Adaptation to Distribution Shifts</b>
<a href="https://arxiv.org/abs/2210.11466">arxiv:2210.11466</a>
&#x1F4C8; 4 <br>
<p>Yoonho Lee, Annie S. Chen, Fahim Tajwar, Ananya Kumar, Huaxiu Yao, Percy Liang, Chelsea Finn</p></summary>
<p>

**Abstract:** A common approach to transfer learning under distribution shift is to fine-tune the last few layers of a pre-trained model, preserving learned features while also adapting to the new task. This paper shows that in such settings, selectively fine-tuning a subset of layers (which we term surgical fine-tuning) matches or outperforms commonly used fine-tuning approaches. Moreover, the type of distribution shift influences which subset is more effective to tune: for example, for image corruptions, fine-tuning only the first few layers works best. We validate our findings systematically across seven real-world data tasks spanning three types of distribution shifts. Theoretically, we prove that for two-layer neural networks in an idealized setting, first-layer tuning can outperform fine-tuning all layers. Intuitively, fine-tuning more parameters on a small target dataset can cause information learned during pre-training to be forgotten, and the relevant information depends on the type of shift.

</p>
</details>

<details><summary><b>Dynamic selection of p-norm in linear adaptive filtering via online kernel-based reinforcement learning</b>
<a href="https://arxiv.org/abs/2210.11317">arxiv:2210.11317</a>
&#x1F4C8; 4 <br>
<p>Minh Vu, Yuki Akiyama, Konstantinos Slavakis</p></summary>
<p>

**Abstract:** This study addresses the problem of selecting dynamically, at each time instance, the ``optimal'' p-norm to combat outliers in linear adaptive filtering without any knowledge on the potentially time-varying probability distribution function of the outliers. To this end, an online and data-driven framework is designed via kernel-based reinforcement learning (KBRL). Novel Bellman mappings on reproducing kernel Hilbert spaces (RKHSs) are introduced that need no knowledge on transition probabilities of Markov decision processes, and are nonexpansive with respect to the underlying Hilbertian norm. An approximate policy-iteration framework is finally offered via the introduction of a finite-dimensional affine superset of the fixed-point set of the proposed Bellman mappings. The well-known ``curse of dimensionality'' in RKHSs is addressed by building a basis of vectors via an approximate linear dependency criterion. Numerical tests on synthetic data demonstrate that the proposed framework selects always the ``optimal'' p-norm for the outlier scenario at hand, outperforming at the same time several non-RL and KBRL schemes.

</p>
</details>

<details><summary><b>RMBench: Benchmarking Deep Reinforcement Learning for Robotic Manipulator Control</b>
<a href="https://arxiv.org/abs/2210.11262">arxiv:2210.11262</a>
&#x1F4C8; 4 <br>
<p>Yanfei Xiang, Xin Wang, Shu Hu, Bin Zhu, Xiaomeng Huang, Xi Wu, Siwei Lyu</p></summary>
<p>

**Abstract:** Reinforcement learning is applied to solve actual complex tasks from high-dimensional, sensory inputs. The last decade has developed a long list of reinforcement learning algorithms. Recent progress benefits from deep learning for raw sensory signal representation. One question naturally arises: how well do they perform concerning different robotic manipulation tasks? Benchmarks use objective performance metrics to offer a scientific way to compare algorithms. In this paper, we present RMBench, the first benchmark for robotic manipulations, which have high-dimensional continuous action and state spaces. We implement and evaluate reinforcement learning algorithms that directly use observed pixels as inputs. We report their average performance and learning curves to show their performance and stability of training. Our study concludes that none of the studied algorithms can handle all tasks well, soft Actor-Critic outperforms most algorithms in average reward and stability, and an algorithm combined with data augmentation may facilitate learning policies. Our code is publicly available at https://github.com/xiangyanfei212/RMBench-2022, including all benchmark tasks and studied algorithms.

</p>
</details>

<details><summary><b>Neural ODEs as Feedback Policies for Nonlinear Optimal Control</b>
<a href="https://arxiv.org/abs/2210.11245">arxiv:2210.11245</a>
&#x1F4C8; 4 <br>
<p>Ilya Orson Sandoval, Panagiotis Petsagkourakis, Ehecatl Antonio del Rio-Chanona</p></summary>
<p>

**Abstract:** Neural ordinary differential equations (Neural ODEs) model continuous time dynamics as differential equations parametrized with neural networks. Thanks to their modeling flexibility, they have been adopted for multiple tasks where the continuous time nature of the process is specially relevant, as in system identification and time series analysis. When applied in a control setting, it is possible to adapt their use to approximate optimal nonlinear feedback policies. This formulation follows the same approach as policy gradients in reinforcement learning, covering the case where the environment consists of known deterministic dynamics given by a system of differential equations. The white box nature of the model specification allows the direct calculation of policy gradients through sensitivity analysis, avoiding the inexact and inefficient gradient estimation through sampling. In this work we propose the use of a neural control policy posed as a Neural ODE to solve general nonlinear optimal control problems while satisfying both state and control constraints, which are crucial for real world scenarios. Since the state feedback policy partially modifies the model dynamics, the whole space phase of the system is reshaped upon the optimization. This approach is a sensible approximation to the historically intractable closed loop solution of nonlinear control problems that efficiently exploits the availability of a dynamical system model.

</p>
</details>

<details><summary><b>Wait-info Policy: Balancing Source and Target at Information Level for Simultaneous Machine Translation</b>
<a href="https://arxiv.org/abs/2210.11220">arxiv:2210.11220</a>
&#x1F4C8; 4 <br>
<p>Shaolei Zhang, Shoutao Guo, Yang Feng</p></summary>
<p>

**Abstract:** Simultaneous machine translation (SiMT) outputs the translation while receiving the source inputs, and hence needs to balance the received source information and translated target information to make a reasonable decision between waiting for inputs or outputting translation. Previous methods always balance source and target information at the token level, either directly waiting for a fixed number of tokens or adjusting the waiting based on the current token. In this paper, we propose a Wait-info Policy to balance source and target at the information level. We first quantify the amount of information contained in each token, named info. Then during simultaneous translation, the decision of waiting or outputting is made based on the comparison results between the total info of previous target outputs and received source inputs. Experiments show that our method outperforms strong baselines under and achieves better balance via the proposed info.

</p>
</details>

<details><summary><b>Graph Neural Networks with Trainable Adjacency Matrices for Fault Diagnosis on Multivariate Sensor Data</b>
<a href="https://arxiv.org/abs/2210.11164">arxiv:2210.11164</a>
&#x1F4C8; 4 <br>
<p>Alexander Kovalenko, Vitaliy Pozdnyakov, Ilya Makarov</p></summary>
<p>

**Abstract:** Timely detected anomalies in the chemical technological processes, as well as the earliest detection of the cause of the fault, significantly reduce the production cost in the industrial factories. Data on the state of the technological process and the operation of production equipment are received by a large number of different sensors. To better predict the behavior of the process and equipment, it is necessary not only to consider the behavior of the signals in each sensor separately, but also to take into account their correlation and hidden relationships with each other. Graph-based data representation helps with this. The graph nodes can be represented as data from the different sensors, and the edges can display the influence of these data on each other. In this work, the possibility of applying graph neural networks to the problem of fault diagnosis in a chemical process is studied. It was proposed to construct a graph during the training of graph neural network. This allows to train models on data where the dependencies between the sensors are not known in advance. In this work, several methods for obtaining adjacency matrices were considered, as well as their quality was studied. It has also been proposed to use multiple adjacency matrices in one model. We showed state-of-the-art performance on the fault diagnosis task with the Tennessee Eastman Process dataset. The proposed graph neural networks outperformed the results of recurrent neural networks.

</p>
</details>

<details><summary><b>Standardized Medical Image Classification across Medical Disciplines</b>
<a href="https://arxiv.org/abs/2210.11091">arxiv:2210.11091</a>
&#x1F4C8; 4 <br>
<p>Simone Mayer, Dominik Müller, Frank Kramer</p></summary>
<p>

**Abstract:** AUCMEDI is a Python-based framework for medical image classification. In this paper, we evaluate the capabilities of AUCMEDI, by applying it to multiple datasets. Datasets were specifically chosen to cover a variety of medical disciplines and imaging modalities. We designed a simple pipeline using Jupyter notebooks and applied it to all datasets. Results show that AUCMEDI was able to train a model with accurate classification capabilities for each dataset: Averaged AUC per dataset range between 0.82 and 1.0, averaged F1 scores range between 0.61 and 1.0. With its high adaptability and strong performance, AUCMEDI proves to be a powerful instrument to build widely applicable neural networks. The notebooks serve as application examples for AUCMEDI.

</p>
</details>

<details><summary><b>Frequency of Interest-based Noise Attenuation Method to Improve Anomaly Detection Performance</b>
<a href="https://arxiv.org/abs/2210.11068">arxiv:2210.11068</a>
&#x1F4C8; 4 <br>
<p>YeongHyeon Park, Myung Jin Kim, Won Seok Park</p></summary>
<p>

**Abstract:** Accurately extracting driving events is the way to maximize computational efficiency and anomaly detection performance in the tire frictional nose-based anomaly detection task. This study proposes a concise and highly useful method for improving the precision of the event extraction that is hindered by extra noise such as wind noise, which is difficult to characterize clearly due to its randomness. The core of the proposed method is based on the identification of the road friction sound corresponding to the frequency of interest and removing the opposite characteristics with several frequency filters. Our method enables precision maximization of driving event extraction while improving anomaly detection performance by an average of 8.506%. Therefore, we conclude our method is a practical solution suitable for road surface anomaly detection purposes in outdoor edge computing environments.

</p>
</details>

<details><summary><b>Independence Testing-Based Approach to Causal Discovery under Measurement Error and Linear Non-Gaussian Models</b>
<a href="https://arxiv.org/abs/2210.11021">arxiv:2210.11021</a>
&#x1F4C8; 4 <br>
<p>Haoyue Dai, Peter Spirtes, Kun Zhang</p></summary>
<p>

**Abstract:** Causal discovery aims to recover causal structures generating the observational data. Despite its success in certain problems, in many real-world scenarios the observed variables are not the target variables of interest, but the imperfect measures of the target variables. Causal discovery under measurement error aims to recover the causal graph among unobserved target variables from observations made with measurement error. We consider a specific formulation of the problem, where the unobserved target variables follow a linear non-Gaussian acyclic model, and the measurement process follows the random measurement error model. Existing methods on this formulation rely on non-scalable over-complete independent component analysis (OICA). In this work, we propose the Transformed Independent Noise (TIN) condition, which checks for independence between a specific linear transformation of some measured variables and certain other measured variables. By leveraging the non-Gaussianity and higher-order statistics of data, TIN is informative about the graph structure among the unobserved target variables. By utilizing TIN, the ordered group decomposition of the causal model is identifiable. In other words, we could achieve what once required OICA to achieve by only conducting independence tests. Experimental results on both synthetic and real-world data demonstrate the effectiveness and reliability of our method.

</p>
</details>

<details><summary><b>Meta Input: How to Leverage Off-the-Shelf Deep Neural Networks</b>
<a href="https://arxiv.org/abs/2210.13186">arxiv:2210.13186</a>
&#x1F4C8; 3 <br>
<p>Minsu Kim, Youngjoon Yu, Sungjune Park, Yong Man Ro</p></summary>
<p>

**Abstract:** These days, although deep neural networks (DNNs) have achieved a noticeable progress in a wide range of research area, it lacks the adaptability to be employed in the real-world applications because of the environment discrepancy problem. Such a problem originates from the difference between training and testing environments, and it is widely known that it causes serious performance degradation, when a pretrained DNN model is applied to a new testing environment. Therefore, in this paper, we introduce a novel approach that allows end-users to exploit pretrained DNN models in their own testing environment without modifying the models. To this end, we present a \textit{meta input} which is an additional input transforming the distribution of testing data to be aligned with that of training data. The proposed meta input can be optimized with a small number of testing data only by considering the relation between testing input data and its output prediction. Also, it does not require any knowledge of the network's internal architecture and modification of its weight parameters. Then, the obtained meta input is added to testing data in order to shift the distribution of testing data to that of originally used training data. As a result, end-users can exploit well-trained models in their own testing environment which can differ from the training environment. We validate the effectiveness and versatility of the proposed meta input by showing the robustness against the environment discrepancy through the comprehensive experiments with various tasks.

</p>
</details>

<details><summary><b>Deep-Learning-Based Precipitation Nowcasting with Ground Weather Station Data and Radar Data</b>
<a href="https://arxiv.org/abs/2210.12853">arxiv:2210.12853</a>
&#x1F4C8; 3 <br>
<p>Jihoon Ko, Kyuhan Lee, Hyunjin Hwang, Kijung Shin</p></summary>
<p>

**Abstract:** Recently, many deep-learning techniques have been applied to various weather-related prediction tasks, including precipitation nowcasting (i.e., predicting precipitation levels and locations in the near future). Most existing deep-learning-based approaches for precipitation nowcasting, however, consider only radar and/or satellite images as inputs, and meteorological observations collected from ground weather stations, which are sparsely located, are relatively unexplored. In this paper, we propose ASOC, a novel attentive method for effectively exploiting ground-based meteorological observations from multiple weather stations. ASOC is designed to capture temporal dynamics of the observations and also contextual relationships between them. ASOC is easily combined with existing image-based precipitation nowcasting models without changing their architectures. We show that such a combination improves the average critical success index (CSI) of predicting heavy (at least 10 mm/hr) and light (at least 1 mm/hr) rainfall events at 1-6 hr lead times by 5.7%, compared to the original image-based model, using the radar images and ground-based observations around South Korea collected from 2014 to 2020.

</p>
</details>

<details><summary><b>Fuzzy Granular-Ball Computing Framework and Its Implementation in SVM</b>
<a href="https://arxiv.org/abs/2210.11675">arxiv:2210.11675</a>
&#x1F4C8; 3 <br>
<p>Shuyin Xia, Xiaoyu Lian, Yabin Shao</p></summary>
<p>

**Abstract:** Most existing fuzzy computing methods use points as input, which is the finest granularity from the perspective of granular computing. Consequently, these classifiers are neither efficient nor robust to label noise. Therefore, we propose a framework for a fuzzy granular-ball computational classifier by introducing granular-ball computing into fuzzy set. The computational framework is based on the granular-balls input rather than points; therefore, it is more efficient and robust than traditional fuzzy methods. Furthermore, the framework is extended to the fuzzy support vector machine (FSVM), and granular ball fuzzy SVM (GBFSVM) is derived. The experimental results demonstrate the effectiveness and efficiency of GBFSVM.

</p>
</details>

<details><summary><b>Stochastic Adaptive Activation Function</b>
<a href="https://arxiv.org/abs/2210.11672">arxiv:2210.11672</a>
&#x1F4C8; 3 <br>
<p>Kyungsu Lee, Jaeseung Yang, Haeyun Lee, Jae Youn Hwang</p></summary>
<p>

**Abstract:** The simulation of human neurons and neurotransmission mechanisms has been realized in deep neural networks based on the theoretical implementations of activation functions. However, recent studies have reported that the threshold potential of neurons exhibits different values according to the locations and types of individual neurons, and that the activation functions have limitations in terms of representing this variability. Therefore, this study proposes a simple yet effective activation function that facilitates different thresholds and adaptive activations according to the positions of units and the contexts of inputs. Furthermore, the proposed activation function mathematically exhibits a more generalized form of Swish activation function, and thus we denoted it as Adaptive SwisH (ASH). ASH highlights informative features that exhibit large values in the top percentiles in an input, whereas it rectifies low values. Most importantly, ASH exhibits trainable, adaptive, and context-aware properties compared to other activation functions. Furthermore, ASH represents general formula of the previously studied activation function and provides a reasonable mathematical background for the superior performance. To validate the effectiveness and robustness of ASH, we implemented ASH into many deep learning models for various tasks, including classification, detection, segmentation, and image generation. Experimental analysis demonstrates that our activation function can provide the benefits of more accurate prediction and earlier convergence in many deep learning applications.

</p>
</details>

<details><summary><b>InfraRed Investigation in Singapore (IRIS) Observatory: Urban heat island contributors and mitigators analysis using neighborhood-scale thermal imaging</b>
<a href="https://arxiv.org/abs/2210.11663">arxiv:2210.11663</a>
&#x1F4C8; 3 <br>
<p>Miguel Martin, Vasantha Ramani, Clayton Miller</p></summary>
<p>

**Abstract:** This paper studies heat fluxes from contributors and mitigators of urban heat islands using thermal images and weather data. Thermal images were collected from an observatory operating on the rooftop of a building between November 2021 and April 2022. Over the same period, an automatic weather station network was used to measure weather conditions at several locations on a university campus in Singapore. From data collected by the observatory and the automatic weather station network, a method was developed to estimate the heat emitted by building facades, vegetation, and traffic. Before performing the analysis of urban heat fluxes, it was observed that the surface temperature collected from the observatory is sensitive to some variables. After the sensitivity analysis, thermal images were calibrated against measurements of the surface temperature in an outdoor environment. Finally, several contributors and mitigators of urban heat islands were analyzed from heat fluxes assessed with thermal images and weather data. According to thermal images collected by the rooftop observatory, concrete walls are an important contributor to urban heat islands due to the longwave radiation they emit at night. Vegetation, on the other hand, seems to be an effective mitigator because of latent heat fluxes generated by evapotranspiration. Traffic looks to be a negligible source of heat if considered over a small portion of a road. In the future, more efforts can be made to estimate the magnitude of the heat released by an air-conditioning system from thermal images.

</p>
</details>

<details><summary><b>LiBeamsNet: AUV Velocity Vector Estimation in Situations of Limited DVL Beam Measurements</b>
<a href="https://arxiv.org/abs/2210.11572">arxiv:2210.11572</a>
&#x1F4C8; 3 <br>
<p>Nadav Cohen, Itzik Klein</p></summary>
<p>

**Abstract:** Autonomous underwater vehicles (AUVs) are employed for marine applications and can operate in deep underwater environments beyond human reach. A standard solution for the autonomous navigation problem can be obtained by fusing the inertial navigation system and the Doppler velocity log sensor (DVL). The latter measures four beam velocities to estimate the vehicle's velocity vector. In real-world scenarios, the DVL may receive less than three beam velocities if the AUV operates in complex underwater environments. In such conditions, the vehicle's velocity vector could not be estimated leading to a navigation solution drift and in some situations the AUV is required to abort the mission and return to the surface. To circumvent such a situation, in this paper we propose a deep learning framework, LiBeamsNet, that utilizes the inertial data and the partial beam velocities to regress the missing beams in two missing beams scenarios. Once all the beams are obtained, the vehicle's velocity vector can be estimated. The approach performance was validated by sea experiments in the Mediterranean Sea. The results show up to 7.2% speed error in the vehicle's velocity vector estimation in a scenario that otherwise could not provide an estimate.

</p>
</details>

<details><summary><b>Transferring learned patterns from ground-based field imagery to predict UAV-based imagery for crop and weed semantic segmentation in precision crop farming</b>
<a href="https://arxiv.org/abs/2210.11545">arxiv:2210.11545</a>
&#x1F4C8; 3 <br>
<p>Junfeng Gao, Wenzhi Liao, David Nuyttens, Peter Lootens, Erik Alexandersson, Jan Pieters</p></summary>
<p>

**Abstract:** Weed and crop segmentation is becoming an increasingly integral part of precision farming that leverages the current computer vision and deep learning technologies. Research has been extensively carried out based on images captured with a camera from various platforms. Unmanned aerial vehicles (UAVs) and ground-based vehicles including agricultural robots are the two popular platforms for data collection in fields. They all contribute to site-specific weed management (SSWM) to maintain crop yield. Currently, the data from these two platforms is processed separately, though sharing the same semantic objects (weed and crop). In our paper, we have developed a deep convolutional network that enables to predict both field and aerial images from UAVs for weed segmentation and mapping with only field images provided in the training phase. The network learning process is visualized by feature maps at shallow and deep layers. The results show that the mean intersection of union (IOU) values of the segmentation for the crop (maize), weeds, and soil background in the developed model for the field dataset are 0.744, 0.577, 0.979, respectively, and the performance of aerial images from an UAV with the same model, the IOU values of the segmentation for the crop (maize), weeds and soil background are 0.596, 0.407, and 0.875, respectively. To estimate the effect on the use of plant protection agents, we quantify the relationship between herbicide spraying saving rate and grid size (spraying resolution) based on the predicted weed map. The spraying saving rate is up to 90% when the spraying resolution is at 1.78 x 1.78 cm2. The study shows that the developed deep convolutional neural network could be used to classify weeds from both field and aerial images and delivers satisfactory results.

</p>
</details>

<details><summary><b>A Survey on Over-the-Air Computation</b>
<a href="https://arxiv.org/abs/2210.11350">arxiv:2210.11350</a>
&#x1F4C8; 3 <br>
<p>Alphan Sahin, Rui Yang</p></summary>
<p>

**Abstract:** Communication and computation are often viewed as separate tasks. This approach is very effective from the perspective of engineering as isolated optimizations can be performed. On the other hand, there are many cases where the main interest is a function of the local information at the devices instead of the local information itself. For such scenarios, information theoretical results show that harnessing the interference in a multiple-access channel for computation, i.e., over-the-air computation (OAC), can provide a significantly higher achievable computation rate than the one with the separation of communication and computation tasks. Besides, the gap between OAC and separation in terms of computation rate increases with more participating nodes. Given this motivation, in this study, we provide a comprehensive survey on practical OAC methods. After outlining fundamentals related to OAC, we discuss the available OAC schemes with their pros and cons. We then provide an overview of the enabling mechanisms and relevant metrics to achieve reliable computation in the wireless channel. Finally, we summarize the potential applications of OAC and point out some future directions.

</p>
</details>

<details><summary><b>DialogUSR: Complex Dialogue Utterance Splitting and Reformulation for Multiple Intent Detection</b>
<a href="https://arxiv.org/abs/2210.11279">arxiv:2210.11279</a>
&#x1F4C8; 3 <br>
<p>Haoran Meng, Zheng Xin, Tianyu Liu, Zizhen Wang, He Feng, Binghuai Lin, Xuemin Zhao, Yunbo Cao, Zhifang Sui</p></summary>
<p>

**Abstract:** While interacting with chatbots, users may elicit multiple intents in a single dialogue utterance. Instead of training a dedicated multi-intent detection model, we propose DialogUSR, a dialogue utterance splitting and reformulation task that first splits multi-intent user query into several single-intent sub-queries and then recovers all the coreferred and omitted information in the sub-queries. DialogUSR can serve as a plug-in and domain-agnostic module that empowers the multi-intent detection for the deployed chatbots with minimal efforts. We collect a high-quality naturally occurring dataset that covers 23 domains with a multi-step crowd-souring procedure. To benchmark the proposed dataset, we propose multiple action-based generative models that involve end-to-end and two-stage training, and conduct in-depth analyses on the pros and cons of the proposed baselines.

</p>
</details>

<details><summary><b>In-Vehicle Interface Adaptation to Environment-Induced Cognitive Workload</b>
<a href="https://arxiv.org/abs/2210.11271">arxiv:2210.11271</a>
&#x1F4C8; 3 <br>
<p>Elena Meiser, Alexandra Alles, Samuel Selter, Marco Molz, Amr Gomaa, Guillermo Reyes</p></summary>
<p>

**Abstract:** Many car accidents are caused by human distractions, including cognitive distractions. In-vehicle human-machine interfaces (HMIs) have evolved throughout the years, providing more and more functions. Interaction with the HMIs can, however, also lead to further distractions and, as a consequence, accidents. To tackle this problem, we propose using adaptive HMIs that change according to the mental workload of the driver. In this work, we present the current status as well as preliminary results of a user study using naturalistic secondary tasks while driving (i.e., the primary task) that attempt to understand the effects of one such interface.

</p>
</details>

<details><summary><b>From Modelling to Understanding Children's Behaviour in the Context of Robotics and Social Artificial Intelligence</b>
<a href="https://arxiv.org/abs/2210.11161">arxiv:2210.11161</a>
&#x1F4C8; 3 <br>
<p>Serge Thill, Vicky Charisi, Tony Belpaeme, Ana Paiva</p></summary>
<p>

**Abstract:** Understanding and modelling children's cognitive processes and their behaviour in the context of their interaction with robots and social artificial intelligence systems is a fundamental prerequisite for meaningful and effective robot interventions. However, children's development involve complex faculties such as exploration, creativity and curiosity which are challenging to model. Also, often children express themselves in a playful way which is different from a typical adult behaviour. Different children also have different needs, and it remains a challenge in the current state of the art that those of neurodiverse children are under-addressed. With this workshop, we aim to promote a common ground among different disciplines such as developmental sciences, artificial intelligence and social robotics and discuss cutting-edge research in the area of user modelling and adaptive systems for children.

</p>
</details>

<details><summary><b>Reversed Image Signal Processing and RAW Reconstruction. AIM 2022 Challenge Report</b>
<a href="https://arxiv.org/abs/2210.11153">arxiv:2210.11153</a>
&#x1F4C8; 3 <br>
<p>Marcos V. Conde, Radu Timofte, Yibin Huang, Jingyang Peng, Chang Chen, Cheng Li, Eduardo Pérez-Pellitero, Fenglong Song, Furui Bai, Shuai Liu, Chaoyu Feng, Xiaotao Wang, Lei Lei, Yu Zhu, Chenghua Li, Yingying Jiang, Yong A, Peisong Wang, Cong Leng, Jian Cheng, Xiaoyu Liu, Zhicun Yin, Zhilu Zhang, Junyi Li, Ming Liu</p></summary>
<p>

**Abstract:** Cameras capture sensor RAW images and transform them into pleasant RGB images, suitable for the human eyes, using their integrated Image Signal Processor (ISP). Numerous low-level vision tasks operate in the RAW domain (e.g. image denoising, white balance) due to its linear relationship with the scene irradiance, wide-range of information at 12bits, and sensor designs. Despite this, RAW image datasets are scarce and more expensive to collect than the already large and public RGB datasets.
  This paper introduces the AIM 2022 Challenge on Reversed Image Signal Processing and RAW Reconstruction. We aim to recover raw sensor images from the corresponding RGBs without metadata and, by doing this, "reverse" the ISP transformation. The proposed methods and benchmark establish the state-of-the-art for this low-level vision inverse problem, and generating realistic raw sensor readings can potentially benefit other tasks such as denoising and super-resolution.

</p>
</details>

<details><summary><b>A lower confidence sequence for the changing mean of non-negative right heavy-tailed observations with bounded mean</b>
<a href="https://arxiv.org/abs/2210.11133">arxiv:2210.11133</a>
&#x1F4C8; 3 <br>
<p>Paul Mineiro</p></summary>
<p>

**Abstract:** A confidence sequence (CS) is an anytime-valid sequential inference primitive which produces an adapted sequence of sets for a predictable parameter sequence with a time-uniform coverage guarantee. This work constructs a non-parametric non-asymptotic lower CS for the running average conditional expectation whose slack converges to zero given non-negative right heavy-tailed observations with bounded mean. Specifically, when the variance is finite the approach dominates the empirical Bernstein supermartingale of Howard et. al.; with infinite variance, can adapt to a known or unknown $(1 + δ)$-th moment bound; and can be efficiently approximated using a sublinear number of sufficient statistics. In certain cases this lower CS can be converted into a closed-interval CS whose width converges to zero, e.g., any bounded realization, or post contextual-bandit inference with bounded rewards and unbounded importance weights. A reference implementation and example simulations demonstrate the technique.

</p>
</details>

<details><summary><b>The Pump Scheduling Problem: A Real-World Scenario for Reinforcement Learning</b>
<a href="https://arxiv.org/abs/2210.11111">arxiv:2210.11111</a>
&#x1F4C8; 3 <br>
<p>Henrique Donâncio, Laurent Vercouter, Harald Roclawski</p></summary>
<p>

**Abstract:** Deep Reinforcement Learning (DRL) has achieved remarkable success in scenarios such as games and has emerged as a potential solution for control tasks. That is due to its ability to leverage scalability and handle complex dynamics. However, few works have targeted environments grounded in real-world settings. Indeed, real-world scenarios can be challenging, especially when faced with the high dimensionality of the state space and unknown reward function. We release a testbed consisting of an environment simulator and demonstrations of human operation concerning pump scheduling of a real-world water distribution facility to facilitate research. The pump scheduling problem can be viewed as a decision process to decide when to operate pumps to supply water while limiting electricity consumption and meeting system constraints. To provide a starting point, we release a well-documented codebase, present an overview of some challenges that can be addressed and provide a baseline representation of the problem. The code and dataset are available at https://gitlab.com/hdonancio/pumpscheduling.

</p>
</details>

<details><summary><b>Vertical Federated Linear Contextual Bandits</b>
<a href="https://arxiv.org/abs/2210.11050">arxiv:2210.11050</a>
&#x1F4C8; 3 <br>
<p>Zeyu Cao, Zhipeng Liang, Shu Zhang, Hangyu Li, Ouyang Wen, Yu Rong, Peilin Zhao, Bingzhe Wu</p></summary>
<p>

**Abstract:** In this paper, we investigate a novel problem of building contextual bandits in the vertical federated setting, i.e., contextual information is vertically distributed over different departments. This problem remains largely unexplored in the research community. To this end, we carefully design a customized encryption scheme named orthogonal matrix-based mask mechanism(O3M) for encrypting local contextual information while avoiding expensive conventional cryptographic techniques. We further apply the mechanism to two commonly-used bandit algorithms, LinUCB and LinTS, and instantiate two practical protocols for online recommendation under the vertical federated setting. The proposed protocols can perfectly recover the service quality of centralized bandit algorithms while achieving a satisfactory runtime efficiency, which is theoretically proved and analyzed in this paper. By conducting extensive experiments on both synthetic and real-world datasets, we show the superiority of the proposed method in terms of privacy protection and recommendation performance.

</p>
</details>

<details><summary><b>DIICAN: Dual Time-scale State-Coupled Co-estimation of SOC, SOH and RUL for Lithium-Ion Batteries</b>
<a href="https://arxiv.org/abs/2210.11941">arxiv:2210.11941</a>
&#x1F4C8; 2 <br>
<p>Ningbo Cai, Yuwen Qin, Xin Chen, Kai Wu</p></summary>
<p>

**Abstract:** Accurate co-estimations of battery states, such as state-of-charge (SOC), state-of-health (SOH,) and remaining useful life (RUL), are crucial to the battery management systems to assure safe and reliable management. Although the external properties of the battery charge with the aging degree, batteries' degradation mechanism shares similar evolving patterns. Since batteries are complicated chemical systems, these states are highly coupled with intricate electrochemical processes. A state-coupled co-estimation method named Deep Inter and Intra-Cycle Attention Network (DIICAN) is proposed in this paper to estimate SOC, SOH, and RUL, which organizes battery measurement data into the intra-cycle and inter-cycle time scales. And to extract degradation-related features automatically and adapt to practical working conditions, the convolutional neural network is applied. The state degradation attention unit is utilized to extract the battery state evolution pattern and evaluate the battery degradation degree. To account for the influence of battery aging on the SOC estimation, the battery degradation-related state is incorporated in the SOC estimation for capacity calibration. The DIICAN method is validated on the Oxford battery dataset. The experimental results show that the proposed method can achieve SOH and RUL co-estimation with high accuracy and effectively improve SOC estimation accuracy for the whole lifespan.

</p>
</details>

<details><summary><b>Sparse Dynamical Features generation, application to Parkinson's Disease diagnosis</b>
<a href="https://arxiv.org/abs/2210.11624">arxiv:2210.11624</a>
&#x1F4C8; 2 <br>
<p>Houssem Meghnoudj, Bogdan Robu, Mazen Alamir</p></summary>
<p>

**Abstract:** In this study we focus on the diagnosis of Parkinson's Disease (PD) based on electroencephalogram (EEG) signals. We propose a new approach inspired by the functioning of the brain that uses the dynamics, frequency and temporal content of EEGs to extract new demarcating features of the disease. The method was evaluated on a publicly available dataset containing EEG signals recorded during a 3-oddball auditory task involving N = 50 subjects, of whom 25 suffer from PD. By extracting two features, and separating them with a straight line using a Linear Discriminant Analysis (LDA) classifier, we can separate the healthy from the unhealthy subjects with an accuracy of 90% (p < 1.8$\times$10-5) using a single channel. By aggregating the information from three channels and making them vote, we obtain an accuracy of 94 %, a sensitivity of 96 % and a specificity of 92 %. The evaluation was carried out using a nested leave-one-out cross-validation procedure, thus preventing data leakage problems and giving a less biased evaluation. Several tests were carried out to assess the validity and robustness of our approach, including the test where we use only half the available data for training. Under this constraint, the model achieves an accuracy of 89.4 %.

</p>
</details>

<details><summary><b>LOT: Layer-wise Orthogonal Training on Improving l2 Certified Robustness</b>
<a href="https://arxiv.org/abs/2210.11620">arxiv:2210.11620</a>
&#x1F4C8; 2 <br>
<p>Xiaojun Xu, Linyi Li, Bo Li</p></summary>
<p>

**Abstract:** Recent studies show that training deep neural networks (DNNs) with Lipschitz constraints are able to enhance adversarial robustness and other model properties such as stability. In this paper, we propose a layer-wise orthogonal training method (LOT) to effectively train 1-Lipschitz convolution layers via parametrizing an orthogonal matrix with an unconstrained matrix. We then efficiently compute the inverse square root of a convolution kernel by transforming the input domain to the Fourier frequency domain. On the other hand, as existing works show that semi-supervised training helps improve empirical robustness, we aim to bridge the gap and prove that semi-supervised learning also improves the certified robustness of Lipschitz-bounded models. We conduct comprehensive evaluations for LOT under different settings. We show that LOT significantly outperforms baselines regarding deterministic l2 certified robustness, and scales to deeper neural networks. Under the supervised scenario, we improve the state-of-the-art certified robustness for all architectures (e.g. from 59.04% to 63.50% on CIFAR-10 and from 32.57% to 34.59% on CIFAR-100 at radius rho = 36/255 for 40-layer networks). With semi-supervised learning over unlabelled data, we are able to improve state-of-the-art certified robustness on CIFAR-10 at rho = 108/255 from 36.04% to 42.39%. In addition, LOT consistently outperforms baselines on different model architectures with only 1/3 evaluation time.

</p>
</details>

<details><summary><b>Monotonic Risk Relationships under Distribution Shifts for Regularized Risk Minimization</b>
<a href="https://arxiv.org/abs/2210.11589">arxiv:2210.11589</a>
&#x1F4C8; 2 <br>
<p>Daniel LeJeune, Jiayu Liu, Reinhard Heckel</p></summary>
<p>

**Abstract:** Machine learning systems are often applied to data that is drawn from a different distribution than the training distribution. Recent work has shown that for a variety of classification and signal reconstruction problems, the out-of-distribution performance is strongly linearly correlated with the in-distribution performance. If this relationship or more generally a monotonic one holds, it has important consequences. For example, it allows to optimize performance on one distribution as a proxy for performance on the other. In this paper, we study conditions under which a monotonic relationship between the performances of a model on two distributions is expected. We prove an exact asymptotic linear relation for squared error and a monotonic relation for misclassification error for ridge-regularized general linear models under covariate shift, as well as an approximate linear relation for linear inverse problems.

</p>
</details>

<details><summary><b>A Methodology for the Prediction of Drug Target Interaction using CDK Descriptors</b>
<a href="https://arxiv.org/abs/2210.11482">arxiv:2210.11482</a>
&#x1F4C8; 2 <br>
<p>Tanya Liyaqat, Tanvir Ahmad, Chandni Saxena</p></summary>
<p>

**Abstract:** Detecting probable Drug Target Interaction (DTI) is a critical task in drug discovery. Conventional DTI studies are expensive, labor-intensive, and take a lot of time, hence there are significant reasons to construct useful computational techniques that may successfully anticipate possible DTIs. Although certain methods have been developed for this cause, numerous interactions are yet to be discovered, and prediction accuracy is still low. To meet these challenges, we propose a DTI prediction model built on molecular structure of drugs and sequence of target proteins. In the proposed model, we use Simplified Molecular Input Line Entry System (SMILES) to create CDK descriptors, Molecular ACCess System (MACCS) fingerprints, Electrotopological state (Estate) fingerprints and amino acid sequences of targets to get Pseudo Amino Acid Composition (PseAAC). We target to evaluate performance of DTI prediction models using CDK descriptors. For comparison, we use benchmark data and evaluate models performance on two widely used fingerprints, MACCS fingerprints and Estate fingerprints. The evaluation of performances shows that CDK descriptors are superior at predicting DTIs. The proposed method also outperforms other previously published techniques significantly.

</p>
</details>

<details><summary><b>How can a Radar Mask its Cognition?</b>
<a href="https://arxiv.org/abs/2210.11444">arxiv:2210.11444</a>
&#x1F4C8; 2 <br>
<p>Kunal Pattanayak, Vikram Krishnamurthy, Christopher Berry</p></summary>
<p>

**Abstract:** A cognitive radar is a constrained utility maximizer that adapts its sensing mode in response to a changing environment. If an adversary can estimate the utility function of a cognitive radar, it can determine the radar's sensing strategy and mitigate the radar performance via electronic countermeasures (ECM). This paper discusses how a cognitive radar can {\em hide} its strategy from an adversary that detects cognition. The radar does so by transmitting purposefully designed sub-optimal responses to spoof the adversary's Neyman-Pearson detector. We provide theoretical guarantees by ensuring the Type-I error probability of the adversary's detector exceeds a pre-defined level for a specified tolerance on the radar's performance loss. We illustrate our cognition masking scheme via numerical examples involving waveform adaptation and beam allocation. We show that small purposeful deviations from the optimal strategy of the radar confuse the adversary by significant amounts, thereby masking the radar's cognition. Our approach uses novel ideas from revealed preference in microeconomics and adversarial inverse reinforcement learning. Our proposed algorithms provide a principled approach for system-level electronic counter-countermeasures (ECCM) to mask the radar's cognition, i.e., hide the radar's strategy from an adversary. We also provide performance bounds for our cognition masking scheme when the adversary has misspecified measurements of the radar's response.

</p>
</details>

<details><summary><b>Trust Region Policy Optimization with Optimal Transport Discrepancies: Duality and Algorithm for Continuous Actions</b>
<a href="https://arxiv.org/abs/2210.11137">arxiv:2210.11137</a>
&#x1F4C8; 2 <br>
<p>Antonio Terpin, Nicolas Lanzetti, Batuhan Yardim, Florian Dörfler, Giorgia Ramponi</p></summary>
<p>

**Abstract:** Policy Optimization (PO) algorithms have been proven particularly suited to handle the high-dimensionality of real-world continuous control tasks. In this context, Trust Region Policy Optimization methods represent a popular approach to stabilize the policy updates. These usually rely on the Kullback-Leibler (KL) divergence to limit the change in the policy. The Wasserstein distance represents a natural alternative, in place of the KL divergence, to define trust regions or to regularize the objective function. However, state-of-the-art works either resort to its approximations or do not provide an algorithm for continuous state-action spaces, reducing the applicability of the method. In this paper, we explore optimal transport discrepancies (which include the Wasserstein distance) to define trust regions, and we propose a novel algorithm - Optimal Transport Trust Region Policy Optimization (OT-TRPO) - for continuous state-action spaces. We circumvent the infinite-dimensional optimization problem for PO by providing a one-dimensional dual reformulation for which strong duality holds. We then analytically derive the optimal policy update given the solution of the dual problem. This way, we bypass the computation of optimal transport costs and of optimal transport maps, which we implicitly characterize by solving the dual formulation. Finally, we provide an experimental evaluation of our approach across various control tasks. Our results show that optimal transport discrepancies can offer an advantage over state-of-the-art approaches.

</p>
</details>

<details><summary><b>Toward Multiple Specialty Learners for Explaining GNNs via Online Knowledge Distillation</b>
<a href="https://arxiv.org/abs/2210.11094">arxiv:2210.11094</a>
&#x1F4C8; 2 <br>
<p>Tien-Cuong Bui, Van-Duc Le, Wen-syan Li, Sang Kyun Cha</p></summary>
<p>

**Abstract:** Graph Neural Networks (GNNs) have become increasingly ubiquitous in numerous applications and systems, necessitating explanations of their predictions, especially when making critical decisions. However, explaining GNNs is challenging due to the complexity of graph data and model execution. Despite additional computational costs, post-hoc explanation approaches have been widely adopted due to the generality of their architectures. Intrinsically interpretable models provide instant explanations but are usually model-specific, which can only explain particular GNNs. Therefore, we propose a novel GNN explanation framework named SCALE, which is general and fast for explaining predictions. SCALE trains multiple specialty learners to explain GNNs since constructing one powerful explainer to examine attributions of interactions in input graphs is complicated. In training, a black-box GNN model guides learners based on an online knowledge distillation paradigm. In the explanation phase, explanations of predictions are provided by multiple explainers corresponding to trained learners. Specifically, edge masking and random walk with restart procedures are executed to provide structural explanations for graph-level and node-level predictions, respectively. A feature attribution module provides overall summaries and instance-level feature contributions. We compare SCALE with state-of-the-art baselines via quantitative and qualitative experiments to prove its explanation correctness and execution performance. We also conduct a series of ablation studies to understand the strengths and weaknesses of the proposed framework.

</p>
</details>

<details><summary><b>Robust Image Registration with Absent Correspondences in Pre-operative and Follow-up Brain MRI Scans of Diffuse Glioma Patients</b>
<a href="https://arxiv.org/abs/2210.11045">arxiv:2210.11045</a>
&#x1F4C8; 2 <br>
<p>Tony C. W. Mok, Albert C. S. Chung</p></summary>
<p>

**Abstract:** Registration of pre-operative and follow-up brain MRI scans is challenging due to the large variation of tissue appearance and missing correspondences in tumour recurrence regions caused by tumour mass effect. Although recent deep learning-based deformable registration methods have achieved remarkable success in various medical applications, most of them are not capable of registering images with pathologies. In this paper, we propose a 3-step registration pipeline for pre-operative and follow-up brain MRI scans that consists of 1) a multi-level affine registration, 2) a conditional deep Laplacian pyramid image registration network (cLapIRN) with forward-backward consistency constraint, and 3) a non-linear instance optimization method. We apply the method to the Brain Tumor Sequence Registration (BraTS-Reg) Challenge. Our method achieves accurate and robust registration of brain MRI scans with pathologies, which achieves a median absolute error of 1.64 mm and 88% of successful registration rate in the validation set of BraTS-Reg challenge.

</p>
</details>

<details><summary><b>Single Image Super-Resolution Using Lightweight Networks Based on Swin Transformer</b>
<a href="https://arxiv.org/abs/2210.11019">arxiv:2210.11019</a>
&#x1F4C8; 2 <br>
<p>Bolong Zhang, Juan Chen, Quan Wen</p></summary>
<p>

**Abstract:** Image super-resolution reconstruction is an important task in the field of image processing technology, which can restore low resolution image to high quality image with high resolution. In recent years, deep learning has been applied in the field of image super-resolution reconstruction. With the continuous development of deep neural network, the quality of the reconstructed images has been greatly improved, but the model complexity has also been increased. In this paper, we propose two lightweight models named as MSwinSR and UGSwinSR based on Swin Transformer. The most important structure in MSwinSR is called Multi-size Swin Transformer Block (MSTB), which mainly contains four parallel multi-head self-attention (MSA) blocks. UGSwinSR combines U-Net and GAN with Swin Transformer. Both of them can reduce the model complexity, but MSwinSR can reach a higher objective quality, while UGSwinSR can reach a higher perceptual quality. The experimental results demonstrate that MSwinSR increases PSNR by $\mathbf{0.07dB}$ compared with the state-of-the-art model SwinIR, while the number of parameters can reduced by $\mathbf{30.68\%}$, and the calculation cost can reduced by $\mathbf{9.936\%}$. UGSwinSR can effectively reduce the amount of calculation of the network, which can reduced by $\mathbf{90.92\%}$ compared with SwinIR.

</p>
</details>

<details><summary><b>MnEdgeNet -- Accurate Decomposition of Mixed Oxidation States for Mn XAS and EELS L2,3 Edges without Reference and Calibration</b>
<a href="https://arxiv.org/abs/2210.11657">arxiv:2210.11657</a>
&#x1F4C8; 0 <br>
<p>Huolin L. Xin, Mike Hu</p></summary>
<p>

**Abstract:** Accurate decomposition of the mixed Mn oxidation states is highly important for characterizing the electronic structures, charge transfer, and redox centers for electronic, electrocatalytic, and energy storage materials that contain Mn. Electron energy loss spectroscopy (EELS) and soft X-ray absorption spectroscopy (XAS) measurements of the Mn L2,3 edges are widely used for this purpose. To date, although the measurement of the Mn L2,3 edges is straightforward given the sample is prepared properly, an accurate decomposition of the mix valence states of Mn remains non-trivial. For both EELS and XAS, 2+, 3+, 4+ reference spectra need to be taken on the same instrument/beamline and preferably in the same experimental session because the instrumental resolution and the energy axis offset could vary from one session to another. To circumvent this hurdle, in this study, we adopted a deep learning approach and developed a calibration-free and reference-free method to decompose the oxidation state of Mn L2,3 edges for both EELS and XAS. To synthesize physics-informed and ground-truth labeled training datasets, we created a forward model that takes into account plural scattering, instrumentation broadening, noise, and energy axis offset. With that, we created a 1.2 million-spectrum database with a three-element oxidation state composition label. The library includes a sufficient variety of data including both EELS and XAS spectra. By training on this large database, our convolutional neural network achieves 85% accuracy on the validation dataset. We tested the model and found it is robust against noise (down to PSNR of 10) and plural scattering (up to t/λ = 1). We further validated the model against spectral data that were not used in training.

</p>
</details>

<details><summary><b>Global Convergence of Direct Policy Search for State-Feedback $\mathcal{H}_\infty$ Robust Control: A Revisit of Nonsmooth Synthesis with Goldstein Subdifferential</b>
<a href="https://arxiv.org/abs/2210.11577">arxiv:2210.11577</a>
&#x1F4C8; 0 <br>
<p>Xingang Guo, Bin Hu</p></summary>
<p>

**Abstract:** Direct policy search has been widely applied in modern reinforcement learning and continuous control. However, the theoretical properties of direct policy search on nonsmooth robust control synthesis have not been fully understood. The optimal $\mathcal{H}_\infty$ control framework aims at designing a policy to minimize the closed-loop $\mathcal{H}_\infty$ norm, and is arguably the most fundamental robust control paradigm. In this work, we show that direct policy search is guaranteed to find the global solution of the robust $\mathcal{H}_\infty$ state-feedback control design problem. Notice that policy search for optimal $\mathcal{H}_\infty$ control leads to a constrained nonconvex nonsmooth optimization problem, where the nonconvex feasible set consists of all the policies stabilizing the closed-loop dynamics. We show that for this nonsmooth optimization problem, all Clarke stationary points are global minimum. Next, we identify the coerciveness of the closed-loop $\mathcal{H}_\infty$ objective function, and prove that all the sublevel sets of the resultant policy search problem are compact. Based on these properties, we show that Goldstein's subgradient method and its implementable variants can be guaranteed to stay in the nonconvex feasible set and eventually find the global optimal solution of the $\mathcal{H}_\infty$ state-feedback synthesis problem. Our work builds a new connection between nonconvex nonsmooth optimization theory and robust control, leading to an interesting global convergence result for direct policy search on optimal $\mathcal{H}_\infty$ synthesis.

</p>
</details>

<details><summary><b>Transcending Scaling Laws with 0.1% Extra Compute</b>
<a href="https://arxiv.org/abs/2210.11399">arxiv:2210.11399</a>
&#x1F4C8; 0 <br>
<p>Yi Tay, Jason Wei, Hyung Won Chung, Vinh Q. Tran, David R. So, Siamak Shakeri, Xavier Garcia, Huaixiu Steven Zheng, Jinfeng Rao, Aakanksha Chowdhery, Denny Zhou, Donald Metzler, Slav Petrov, Neil Houlsby, Quoc V. Le, Mostafa Dehghani</p></summary>
<p>

**Abstract:** Scaling language models improves performance but comes with significant computational costs. This paper proposes UL2R, a method that substantially improves existing language models and their scaling curves with a relatively tiny amount of extra compute. The key idea is to continue training a state-of-the-art large language model (e.g., PaLM) on a few more steps with UL2's mixture-of-denoiser objective. We show that, with almost negligible extra computational costs and no new sources of data, we are able to substantially improve the scaling properties of large language models on downstream metrics. In this paper, we continue training PaLM with UL2R, introducing a new set of models at 8B, 62B, and 540B scale which we call U-PaLM. Impressively, at 540B scale, we show an approximately 2x computational savings rate where U-PaLM achieves the same performance as the final PaLM 540B model at around half its computational budget (i.e., saving $\sim$4.4 million TPUv4 hours). We further show that this improved scaling curve leads to 'emergent abilities' on challenging BIG-Bench tasks -- for instance, U-PaLM does much better than PaLM on some tasks or demonstrates better quality at much smaller scale (62B as opposed to 540B). Overall, we show that U-PaLM outperforms PaLM on many few-shot setups, i.e., English NLP tasks (e.g., commonsense reasoning, question answering), reasoning tasks with chain-of-thought (e.g., GSM8K), multilingual tasks (MGSM, TydiQA), MMLU and challenging BIG-Bench tasks. Finally, we provide qualitative examples showing the new capabilities of U-PaLM for single and multi-span infilling.

</p>
</details>

<details><summary><b>Machine Learning for $K$-adaptability in Two-stage Robust Optimization</b>
<a href="https://arxiv.org/abs/2210.11152">arxiv:2210.11152</a>
&#x1F4C8; 0 <br>
<p>Esther Julien, Krzysztof Postek, Ş. İlker Birbil</p></summary>
<p>

**Abstract:** Two-stage robust optimization problems constitute one of the hardest optimization problem classes. One of the solution approaches to this class of problems is $K$-adaptability. This approach simultaneously seeks the best partitioning of the uncertainty set of scenarios into $K$ subsets, and optimizes decisions corresponding to each of these subsets. In general case, it is solved using the $K$-adaptability branch-and-bound algorithm, which requires exploration of exponentially-growing solution trees. To accelerate finding high-quality solutions in such trees, we propose a machine learning-based node selection strategy. In particular, we construct a feature engineering scheme based on general two-stage robust optimization insights that allows us to train our machine learning tool on a database of resolved B\&B trees, and to apply it as-is to problems of different sizes and/or types. We experimentally show that using our learned node selection strategy outperforms a vanilla, random node selection strategy when tested on problems of the same type as the training problems, also in case the $K$-value or the problem size differs from the training ones.

</p>
</details>


{% endraw %}
Prev: [2022.10.19]({{ '/2022/10/19/2022.10.19.html' | relative_url }})  Next: [2022.10.21]({{ '/2022/10/21/2022.10.21.html' | relative_url }})