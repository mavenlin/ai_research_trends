Prev: [2022.05.01]({{ '/2022/05/01/2022.05.01.html' | relative_url }})  Next: [2022.05.03]({{ '/2022/05/03/2022.05.03.html' | relative_url }})
{% raw %}
## Summary for 2022-05-02, created on 2022-05-06


<details><summary><b>OPT: Open Pre-trained Transformer Language Models</b>
<a href="https://arxiv.org/abs/2205.01068">arxiv:2205.01068</a>
&#x1F4C8; 372 <br>
<p>Susan Zhang, Stephen Roller, Naman Goyal, Mikel Artetxe, Moya Chen, Shuohui Chen, Christopher Dewan, Mona Diab, Xian Li, Xi Victoria Lin, Todor Mihaylov, Myle Ott, Sam Shleifer, Kurt Shuster, Daniel Simig, Punit Singh Koura, Anjali Sridhar, Tianlu Wang, Luke Zettlemoyer</p></summary>
<p>

**Abstract:** Large language models, which are often trained for hundreds of thousands of compute days, have shown remarkable capabilities for zero- and few-shot learning. Given their computational cost, these models are difficult to replicate without significant capital. For the few that are available through APIs, no access is granted to the full model weights, making them difficult to study. We present Open Pre-trained Transformers (OPT), a suite of decoder-only pre-trained transformers ranging from 125M to 175B parameters, which we aim to fully and responsibly share with interested researchers. We show that OPT-175B is comparable to GPT-3, while requiring only 1/7th the carbon footprint to develop. We are also releasing our logbook detailing the infrastructure challenges we faced, along with code for experimenting with all of the released models.

</p>
</details>

<details><summary><b>The Theory of Artificial Immutability: Protecting Algorithmic Groups Under Anti-Discrimination Law</b>
<a href="https://arxiv.org/abs/2205.01166">arxiv:2205.01166</a>
&#x1F4C8; 45 <br>
<p>Sandra Wachter</p></summary>
<p>

**Abstract:** Artificial Intelligence (AI) is increasingly used to make important decisions about people. While issues of AI bias and proxy discrimination are well explored, less focus has been paid to the harms created by profiling based on groups that do not map to or correlate with legally protected groups such as sex or ethnicity. This raises a question: are existing equality laws able to protect against emergent AI-driven inequality? This article examines the legal status of algorithmic groups in North American and European non-discrimination doctrine, law, and jurisprudence and will show that algorithmic groups are not comparable to traditional protected groups. Nonetheless, these new groups are worthy of protection. I propose a new theory of harm - "the theory of artificial immutability" - that aims to bring AI groups within the scope of the law. My theory describes how algorithmic groups act as de facto immutable characteristics in practice that limit people's autonomy and prevent them from achieving important goals.

</p>
</details>

<details><summary><b>Neurocompositional computing: From the Central Paradox of Cognition to a new generation of AI systems</b>
<a href="https://arxiv.org/abs/2205.01128">arxiv:2205.01128</a>
&#x1F4C8; 22 <br>
<p>Paul Smolensky, R. Thomas McCoy, Roland Fernandez, Matthew Goldrick, Jianfeng Gao</p></summary>
<p>

**Abstract:** What explains the dramatic progress from 20th-century to 21st-century AI, and how can the remaining limitations of current AI be overcome? The widely accepted narrative attributes this progress to massive increases in the quantity of computational and data resources available to support statistical learning in deep artificial neural networks. We show that an additional crucial factor is the development of a new type of computation. Neurocompositional computing adopts two principles that must be simultaneously respected to enable human-level cognition: the principles of Compositionality and Continuity. These have seemed irreconcilable until the recent mathematical discovery that compositionality can be realized not only through discrete methods of symbolic computing, but also through novel forms of continuous neural computing. The revolutionary recent progress in AI has resulted from the use of limited forms of neurocompositional computing. New, deeper forms of neurocompositional computing create AI systems that are more robust, accurate, and comprehensible.

</p>
</details>

<details><summary><b>ComPhy: Compositional Physical Reasoning of Objects and Events from Videos</b>
<a href="https://arxiv.org/abs/2205.01089">arxiv:2205.01089</a>
&#x1F4C8; 14 <br>
<p>Zhenfang Chen, Kexin Yi, Yunzhu Li, Mingyu Ding, Antonio Torralba, Joshua B. Tenenbaum, Chuang Gan</p></summary>
<p>

**Abstract:** Objects' motions in nature are governed by complex interactions and their properties. While some properties, such as shape and material, can be identified via the object's visual appearances, others like mass and electric charge are not directly visible. The compositionality between the visible and hidden properties poses unique challenges for AI models to reason from the physical world, whereas humans can effortlessly infer them with limited observations. Existing studies on video reasoning mainly focus on visually observable elements such as object appearance, movement, and contact interaction. In this paper, we take an initial step to highlight the importance of inferring the hidden physical properties not directly observable from visual appearances, by introducing the Compositional Physical Reasoning (ComPhy) dataset. For a given set of objects, ComPhy includes few videos of them moving and interacting under different initial conditions. The model is evaluated based on its capability to unravel the compositional hidden properties, such as mass and charge, and use this knowledge to answer a set of questions posted on one of the videos. Evaluation results of several state-of-the-art video reasoning models on ComPhy show unsatisfactory performance as they fail to capture these hidden properties. We further propose an oracle neural-symbolic framework named Compositional Physics Learner (CPL), combining visual perception, physical property learning, dynamic prediction, and symbolic execution into a unified framework. CPL can effectively identify objects' physical properties from their interactions and predict their dynamics to answer questions.

</p>
</details>

<details><summary><b>Wav2Seq: Pre-training Speech-to-Text Encoder-Decoder Models Using Pseudo Languages</b>
<a href="https://arxiv.org/abs/2205.01086">arxiv:2205.01086</a>
&#x1F4C8; 10 <br>
<p>Felix Wu, Kwangyoun Kim, Shinji Watanabe, Kyu Han, Ryan McDonald, Kilian Q. Weinberger, Yoav Artzi</p></summary>
<p>

**Abstract:** We introduce Wav2Seq, the first self-supervised approach to pre-train both parts of encoder-decoder models for speech data. We induce a pseudo language as a compact discrete representation, and formulate a self-supervised pseudo speech recognition task -- transcribing audio inputs into pseudo subword sequences. This process stands on its own, or can be applied as low-cost second-stage pre-training. We experiment with automatic speech recognition (ASR), spoken named entity recognition, and speech-to-text translation. We set new state-of-the-art results for end-to-end spoken named entity recognition, and show consistent improvements on 20 language pairs for speech-to-text translation, even when competing methods use additional text data for training. Finally, on ASR, our approach enables encoder-decoder methods to benefit from pre-training for all parts of the network, and shows comparable performance to highly optimized recent methods.

</p>
</details>

<details><summary><b>Hausa Visual Genome: A Dataset for Multi-Modal English to Hausa Machine Translation</b>
<a href="https://arxiv.org/abs/2205.01133">arxiv:2205.01133</a>
&#x1F4C8; 7 <br>
<p>Idris Abdulmumin, Satya Ranjan Dash, Musa Abdullahi Dawud, Shantipriya Parida, Shamsuddeen Hassan Muhammad, Ibrahim Sa'id Ahmad, Subhadarshi Panda, Ondřej Bojar, Bashir Shehu Galadanci, Bello Shehu Bello</p></summary>
<p>

**Abstract:** Multi-modal Machine Translation (MMT) enables the use of visual information to enhance the quality of translations. The visual information can serve as a valuable piece of context information to decrease the ambiguity of input sentences. Despite the increasing popularity of such a technique, good and sizeable datasets are scarce, limiting the full extent of their potential. Hausa, a Chadic language, is a member of the Afro-Asiatic language family. It is estimated that about 100 to 150 million people speak the language, with more than 80 million indigenous speakers. This is more than any of the other Chadic languages. Despite a large number of speakers, the Hausa language is considered low-resource in natural language processing (NLP). This is due to the absence of sufficient resources to implement most NLP tasks. While some datasets exist, they are either scarce, machine-generated, or in the religious domain. Therefore, there is a need to create training and evaluation data for implementing machine learning tasks and bridging the research gap in the language. This work presents the Hausa Visual Genome (HaVG), a dataset that contains the description of an image or a section within the image in Hausa and its equivalent in English. To prepare the dataset, we started by translating the English description of the images in the Hindi Visual Genome (HVG) into Hausa automatically. Afterward, the synthetic Hausa data was carefully post-edited considering the respective images. The dataset comprises 32,923 images and their descriptions that are divided into training, development, test, and challenge test set. The Hausa Visual Genome is the first dataset of its kind and can be used for Hausa-English machine translation, multi-modal research, and image description, among various other natural language processing and generation tasks.

</p>
</details>

<details><summary><b>A Novel Speech-Driven Lip-Sync Model with CNN and LSTM</b>
<a href="https://arxiv.org/abs/2205.00916">arxiv:2205.00916</a>
&#x1F4C8; 7 <br>
<p>Xiaohong Li, Xiang Wang, Kai Wang, Shiguo Lian</p></summary>
<p>

**Abstract:** Generating synchronized and natural lip movement with speech is one of the most important tasks in creating realistic virtual characters. In this paper, we present a combined deep neural network of one-dimensional convolutions and LSTM to generate vertex displacement of a 3D template face model from variable-length speech input. The motion of the lower part of the face, which is represented by the vertex movement of 3D lip shapes, is consistent with the input speech. In order to enhance the robustness of the network to different sound signals, we adapt a trained speech recognition model to extract speech feature, and a velocity loss term is adopted to reduce the jitter of generated facial animation. We recorded a series of videos of a Chinese adult speaking Mandarin and created a new speech-animation dataset to compensate the lack of such public data. Qualitative and quantitative evaluations indicate that our model is able to generate smooth and natural lip movements synchronized with speech.

</p>
</details>

<details><summary><b>Norm-Agnostic Linear Bandits</b>
<a href="https://arxiv.org/abs/2205.01257">arxiv:2205.01257</a>
&#x1F4C8; 6 <br>
<p> Spencer,  Gales, Sunder Sethuraman, Kwang-Sung Jun</p></summary>
<p>

**Abstract:** Linear bandits have a wide variety of applications including recommendation systems yet they make one strong assumption: the algorithms must know an upper bound $S$ on the norm of the unknown parameter $θ^*$ that governs the reward generation. Such an assumption forces the practitioner to guess $S$ involved in the confidence bound, leaving no choice but to wish that $\|θ^*\|\le S$ is true to guarantee that the regret will be low. In this paper, we propose novel algorithms that do not require such knowledge for the first time. Specifically, we propose two algorithms and analyze their regret bounds: one for the changing arm set setting and the other for the fixed arm set setting. Our regret bound for the former shows that the price of not knowing $S$ does not affect the leading term in the regret bound and inflates only the lower order term. For the latter, we do not pay any price in the regret for now knowing $S$. Our numerical experiments show standard algorithms assuming knowledge of $S$ can fail catastrophically when $\|θ^*\|\le S$ is not true whereas our algorithms enjoy low regret.

</p>
</details>

<details><summary><b>COMET Flows: Towards Generative Modeling of Multivariate Extremes and Tail Dependence</b>
<a href="https://arxiv.org/abs/2205.01224">arxiv:2205.01224</a>
&#x1F4C8; 6 <br>
<p>Andrew McDonald, Pang-Ning Tan, Lifeng Luo</p></summary>
<p>

**Abstract:** Normalizing flows, a popular class of deep generative models, often fail to represent extreme phenomena observed in real-world processes. In particular, existing normalizing flow architectures struggle to model multivariate extremes, characterized by heavy-tailed marginal distributions and asymmetric tail dependence among variables. In light of this shortcoming, we propose COMET (COpula Multivariate ExTreme) Flows, which decompose the process of modeling a joint distribution into two parts: (i) modeling its marginal distributions, and (ii) modeling its copula distribution. COMET Flows capture heavy-tailed marginal distributions by combining a parametric tail belief at extreme quantiles of the marginals with an empirical kernel density function at mid-quantiles. In addition, COMET Flows capture asymmetric tail dependence among multivariate extremes by viewing such dependence as inducing a low-dimensional manifold structure in feature space. Experimental results on both synthetic and real-world datasets demonstrate the effectiveness of COMET Flows in capturing both heavy-tailed marginals and asymmetric tail dependence compared to other state-of-the-art baseline architectures. All code is available on GitHub at https://github.com/andrewmcdonald27/COMETFlows.

</p>
</details>

<details><summary><b>FINETUNA: Fine-tuning Accelerated Molecular Simulations</b>
<a href="https://arxiv.org/abs/2205.01223">arxiv:2205.01223</a>
&#x1F4C8; 6 <br>
<p>Joseph Musielewicz, Xiaoxiao Wang, Tian Tian, Zachary Ulissi</p></summary>
<p>

**Abstract:** Machine learning approaches have the potential to approximate Density Functional Theory (DFT) for atomistic simulations in a computationally efficient manner, which could dramatically increase the impact of computational simulations on real-world problems. However, they are limited by their accuracy and the cost of generating labeled data. Here, we present an online active learning framework for accelerating the simulation of atomic systems efficiently and accurately by incorporating prior physical information learned by large-scale pre-trained graph neural network models from the Open Catalyst Project. Accelerating these simulations enables useful data to be generated more cheaply, allowing better models to be trained and more atomistic systems to be screened. We also present a method of comparing local optimization techniques on the basis of both their speed and accuracy. Experiments on 30 benchmark adsorbate-catalyst systems show that our method of transfer learning to incorporate prior information from pre-trained models accelerates simulations by reducing the number of DFT calculations by 91%, while meeting an accuracy threshold of 0.02 eV 93% of the time. Finally, we demonstrate a technique for leveraging the interactive functionality built in to VASP to efficiently compute single point calculations within our online active learning framework without the significant startup costs. This allows VASP to work in tandem with our framework while requiring 75% fewer self-consistent cycles than conventional single point calculations. The online active learning implementation, and examples using the VASP interactive code, are available in the open source FINETUNA package on Github.

</p>
</details>

<details><summary><b>Data-driven emotional body language generation for social robotics</b>
<a href="https://arxiv.org/abs/2205.00763">arxiv:2205.00763</a>
&#x1F4C8; 6 <br>
<p>Mina Marmpena, Fernando Garcia, Angelica Lim, Nikolas Hemion, Thomas Wennekers</p></summary>
<p>

**Abstract:** In social robotics, endowing humanoid robots with the ability to generate bodily expressions of affect can improve human-robot interaction and collaboration, since humans attribute, and perhaps subconsciously anticipate, such traces to perceive an agent as engaging, trustworthy, and socially present. Robotic emotional body language needs to be believable, nuanced and relevant to the context. We implemented a deep learning data-driven framework that learns from a few hand-designed robotic bodily expressions and can generate numerous new ones of similar believability and lifelikeness. The framework uses the Conditional Variational Autoencoder model and a sampling approach based on the geometric properties of the model's latent space to condition the generative process on targeted levels of valence and arousal. The evaluation study found that the anthropomorphism and animacy of the generated expressions are not perceived differently from the hand-designed ones, and the emotional conditioning was adequately differentiable between most levels except the pairs of neutral-positive valence and low-medium arousal. Furthermore, an exploratory analysis of the results reveals a possible impact of the conditioning on the perceived dominance of the robot, as well as on the participants' attention.

</p>
</details>

<details><summary><b>An Application to Generate Style Guided Compatible Outfit</b>
<a href="https://arxiv.org/abs/2205.00663">arxiv:2205.00663</a>
&#x1F4C8; 6 <br>
<p>Debopriyo Banerjee, Harsh Maheshwari, Lucky Dhakad1, Arnab Bhattacharya1, Niloy Ganguly, Muthusamy Chelliah, Suyash Agarwal1</p></summary>
<p>

**Abstract:** Fashion recommendation has witnessed a phenomenal growth of research, particularly in the domains of shop-the-look, contextaware outfit creation, personalizing outfit creation etc. Majority of the work in this area focuses on better understanding of the notion of complimentary relationship between lifestyle items. Quite recently, some works have realised that style plays a vital role in fashion, especially in the understanding of compatibility learning and outfit creation. In this paper, we would like to present the end-to-end design of a methodology in which we aim to generate outfits guided by styles or themes using a novel style encoder network. We present an extensive analysis of different aspects of our method through various experiments. We also provide a demonstration api to showcase the ability of our work in generating outfits based on an anchor item and styles.

</p>
</details>

<details><summary><b>Convergence of Stochastic Approximation via Martingale and Converse Lyapunov Methods</b>
<a href="https://arxiv.org/abs/2205.01303">arxiv:2205.01303</a>
&#x1F4C8; 5 <br>
<p>M. Vidyasagar</p></summary>
<p>

**Abstract:** This paper is dedicated to Prof. Eduardo Sontag on the occasion of his seventieth birthday. In this paper, we build upon the ideas first proposed in Gladyshev (1965) to develop a very general framework for proving the almost sure boundedness and the convergence of stochastic approximation algorithms. These ideas are based on martingale methods and are in some ways simpler than convergence proofs based on the ODE method, e.g., Borkar-Meyn (2000). First we study the original version of the SA algorithm introduced in Robbins-Monro (1951), where the objective is to determine a zero of a function, when only noisy measurements of the function are available. The proof makes use of the general framework developed here, together with a new theorem on converse Lyapunov stability, which might be of independent interest. Next we study an alternate version of SA, first introduced in Kiefer-Wolfowitz (1952). The objective here is to find a stationary point of a scalar-valued function, using first-order differences to approximate its gradient. This problem is analyzed in Blum (1954), but with a very opaque proof. We reproduce Blum's conclusions using the proposed framework.

</p>
</details>

<details><summary><b>One Weird Trick to Improve Your Semi-Weakly Supervised Semantic Segmentation Model</b>
<a href="https://arxiv.org/abs/2205.01233">arxiv:2205.01233</a>
&#x1F4C8; 5 <br>
<p>Wonho Bae, Junhyug Noh, Milad Jalali Asadabadi, Danica J. Sutherland</p></summary>
<p>

**Abstract:** Semi-weakly supervised semantic segmentation (SWSSS) aims to train a model to identify objects in images based on a small number of images with pixel-level labels, and many more images with only image-level labels. Most existing SWSSS algorithms extract pixel-level pseudo-labels from an image classifier - a very difficult task to do well, hence requiring complicated architectures and extensive hyperparameter tuning on fully-supervised validation sets. We propose a method called prediction filtering, which instead of extracting pseudo-labels, just uses the classifier as a classifier: it ignores any segmentation predictions from classes which the classifier is confident are not present. Adding this simple post-processing method to baselines gives results competitive with or better than prior SWSSS algorithms. Moreover, it is compatible with pseudo-label methods: adding prediction filtering to existing SWSSS algorithms further improves segmentation performance.

</p>
</details>

<details><summary><b>Reproducing Kernels and New Approaches in Compositional Data Analysis</b>
<a href="https://arxiv.org/abs/2205.01158">arxiv:2205.01158</a>
&#x1F4C8; 5 <br>
<p>Binglin Li, Jeongyoun Ahn</p></summary>
<p>

**Abstract:** Compositional data, such as human gut microbiomes, consist of non-negative variables whose only the relative values to other variables are available. Analyzing compositional data such as human gut microbiomes needs a careful treatment of the geometry of the data. A common geometrical understanding of compositional data is via a regular simplex. Majority of existing approaches rely on a log-ratio or power transformations to overcome the innate simplicial geometry. In this work, based on the key observation that a compositional data are projective in nature, and on the intrinsic connection between projective and spherical geometry, we re-interpret the compositional domain as the quotient topology of a sphere modded out by a group action. This re-interpretation allows us to understand the function space on compositional domains in terms of that on spheres and to use spherical harmonics theory along with reflection group actions for constructing a compositional Reproducing Kernel Hilbert Space (RKHS). This construction of RKHS for compositional data will widely open research avenues for future methodology developments. In particular, well-developed kernel embedding methods can be now introduced to compositional data analysis. The polynomial nature of compositional RKHS has both theoretical and computational benefits. The wide applicability of the proposed theoretical framework is exemplified with nonparametric density estimation and kernel exponential family for compositional data.

</p>
</details>

<details><summary><b>A Change Dynamic Model for the Online Detection of Gradual Change</b>
<a href="https://arxiv.org/abs/2205.01054">arxiv:2205.01054</a>
&#x1F4C8; 5 <br>
<p>Chris Browne</p></summary>
<p>

**Abstract:** In the field of change-detection changes in the statistical properties of a stochastic process are typically assumed to occur via change-points, which demark instantaneous moments of complete and total change in distribution. In contrast, many real world processes undergo more gradual change in their behavior. With this observation in mind, we introduce a novel change-dynamic model for the online detection of gradual change in which change-points are used within a hierarchical model to indicate moments of gradual change onset or termination. We apply this model to synthetic data and EEG readings drawn during epileptic seizure, finding that our model can afford faster and more accurate identification of gradual change than traditional change-point models allow.

</p>
</details>

<details><summary><b>HarmoF0: Logarithmic Scale Dilated Convolution For Pitch Estimation</b>
<a href="https://arxiv.org/abs/2205.01019">arxiv:2205.01019</a>
&#x1F4C8; 5 <br>
<p>Weixing Wei, Peilin Li, Yi Yu, Wei Li</p></summary>
<p>

**Abstract:** Sounds, especially music, contain various harmonic components scattered in the frequency dimension. It is difficult for normal convolutional neural networks to observe these overtones. This paper introduces a multiple rates dilated causal convolution (MRDC-Conv) method to capture the harmonic structure in logarithmic scale spectrograms efficiently. The harmonic is helpful for pitch estimation, which is important for many sound processing applications. We propose HarmoF0, a fully convolutional network, to evaluate the MRDC-Conv and other dilated convolutions in pitch estimation. The results show that this model outperforms the DeepF0, yields state-of-the-art performance in three datasets, and simultaneously reduces more than 90% parameters. We also find that it has stronger noise resistance and fewer octave errors.

</p>
</details>

<details><summary><b>CCLF: A Contrastive-Curiosity-Driven Learning Framework for Sample-Efficient Reinforcement Learning</b>
<a href="https://arxiv.org/abs/2205.00943">arxiv:2205.00943</a>
&#x1F4C8; 5 <br>
<p>Chenyu Sun, Hangwei Qian, Chunyan Miao</p></summary>
<p>

**Abstract:** In reinforcement learning (RL), it is challenging to learn directly from high-dimensional observations, where data augmentation has recently been shown to remedy this via encoding invariances from raw pixels. Nevertheless, we empirically find that not all samples are equally important and hence simply injecting more augmented inputs may instead cause instability in Q-learning. In this paper, we approach this problem systematically by developing a model-agnostic Contrastive-Curiosity-Driven Learning Framework (CCLF), which can fully exploit sample importance and improve learning efficiency in a self-supervised manner. Facilitated by the proposed contrastive curiosity, CCLF is capable of prioritizing the experience replay, selecting the most informative augmented inputs, and more importantly regularizing the Q-function as well as the encoder to concentrate more on under-learned data. Moreover, it encourages the agent to explore with a curiosity-based reward. As a result, the agent can focus on more informative samples and learn representation invariances more efficiently, with significantly reduced augmented inputs. We apply CCLF to several base RL algorithms and evaluate on the DeepMind Control Suite, Atari, and MiniGrid benchmarks, where our approach demonstrates superior sample efficiency and learning performances compared with other state-of-the-art methods.

</p>
</details>

<details><summary><b>VICE: Variational Inference for Concept Embeddings</b>
<a href="https://arxiv.org/abs/2205.00756">arxiv:2205.00756</a>
&#x1F4C8; 5 <br>
<p>Lukas Muttenthaler, Charles Y. Zheng, Patrick McClure, Robert A. Vandermeulen, Martin N. Hebart, Francisco Pereira</p></summary>
<p>

**Abstract:** In this paper, we introduce Variational Inference for Concept Embeddings (VICE), an approximate Bayesian method for learning object concept embeddings from human behavior in an odd-one-out triplet task. We use variational inference to obtain a sparse, non-negative solution with uncertainty estimates about each embedding value. We exploit these estimates to automatically select the dimensions that explain the data while yielding reproducible embeddings. We introduce a PAC learning bound for VICE that can be used to estimate generalization performance or determine a sufficient sample size for different experimental designs. VICE rivals or outperforms its predecessor, SPoSE, at predicting human behavior in a triplet task. VICE object representations are substantially more reproducible and consistent across different random initializations.

</p>
</details>

<details><summary><b>FedDKD: Federated Learning with Decentralized Knowledge Distillation</b>
<a href="https://arxiv.org/abs/2205.00706">arxiv:2205.00706</a>
&#x1F4C8; 5 <br>
<p>Xinjia Li, Boyu Chen, Wenlian Lu</p></summary>
<p>

**Abstract:** The performance of federated learning in neural networks is generally influenced by the heterogeneity of the data distribution. For a well-performing global model, taking a weighted average of the local models, as done by most existing federated learning algorithms, may not guarantee consistency with local models in the space of neural network maps. In this paper, we propose a novel framework of federated learning equipped with the process of decentralized knowledge distillation (FedDKD) (i.e., without data on the server). The FedDKD introduces a module of decentralized knowledge distillation (DKD) to distill the knowledge of the local models to train the global model by approaching the neural network map average based on the metric of divergence defined in the loss function, other than only averaging parameters as done in literature. Numeric experiments on various heterogeneous datasets reveal that FedDKD outperforms the state-of-the-art methods with more efficient communication and training in a few DKD steps, especially on some extremely heterogeneous datasets.

</p>
</details>

<details><summary><b>DeepGraviLens: a Multi-Modal Architecture for Classifying Gravitational Lensing Data</b>
<a href="https://arxiv.org/abs/2205.00701">arxiv:2205.00701</a>
&#x1F4C8; 5 <br>
<p>Nicolò Oreste Pinciroli Vago, Piero Fraternali</p></summary>
<p>

**Abstract:** Gravitational lensing is the relativistic effect generated by massive bodies, which bend the space-time surrounding them. It is a deeply investigated topic in astrophysics and allows validating theoretical relativistic results and studying faint astrophysical objects that would not be visible otherwise. In recent years Machine Learning methods have been applied to support the analysis of the gravitational lensing phenomena by detecting lensing effects in data sets consisting of images associated with brightness variation time series. However, the state-of-art approaches either consider only images and neglect time-series data or achieve relatively low accuracy on the most difficult data sets. This paper introduces DeepGraviLens, a novel multi-modal network that classifies spatio-temporal data belonging to one non-lensed system type and three lensed system types. It surpasses the current state of the art accuracy results by $\approx$ 19% to $\approx$ 43%, depending on the considered data set. Such an improvement will enable the acceleration of the analysis of lensed objects in upcoming astrophysical surveys, which will exploit the petabytes of data collected, e.g., from the Vera C. Rubin Observatory.

</p>
</details>

<details><summary><b>A Multi-stage deep architecture for summary generation of soccer videos</b>
<a href="https://arxiv.org/abs/2205.00694">arxiv:2205.00694</a>
&#x1F4C8; 5 <br>
<p>Melissa Sanabria, Frédéric Precioso, Pierre-Alexandre Mattei, Thomas Menguy</p></summary>
<p>

**Abstract:** Video content is present in an ever-increasing number of fields, both scientific and commercial. Sports, particularly soccer, is one of the industries that has invested the most in the field of video analytics, due to the massive popularity of the game and the emergence of new markets. Previous state-of-the-art methods on soccer matches video summarization rely on handcrafted heuristics to generate summaries which are poorly generalizable, but these works have yet proven that multiple modalities help detect the best actions of the game. On the other hand, machine learning models with higher generalization potential have entered the field of summarization of general-purpose videos, offering several deep learning approaches. However, most of them exploit content specificities that are not appropriate for sport whole-match videos. Although video content has been for many years the main source for automatizing knowledge extraction in soccer, the data that records all the events happening on the field has become lately very important in sports analytics, since this event data provides richer context information and requires less processing. We propose a method to generate the summary of a soccer match exploiting both the audio and the event metadata. The results show that our method can detect the actions of the match, identify which of these actions should belong to the summary and then propose multiple candidate summaries which are similar enough but with relevant variability to provide different options to the final editor. Furthermore, we show the generalization capability of our work since it can transfer knowledge between datasets from different broadcasting companies, different competitions, acquired in different conditions, and corresponding to summaries of different lengths

</p>
</details>

<details><summary><b>From Noisy Prediction to True Label: Noisy Prediction Calibration via Generative Model</b>
<a href="https://arxiv.org/abs/2205.00690">arxiv:2205.00690</a>
&#x1F4C8; 5 <br>
<p>HeeSun Bae, Seungjae Shin, JoonHo Jang, Byeonghu Na, Kyungwoo Song, Il-Chul Moon</p></summary>
<p>

**Abstract:** Noisy labels are inevitable yet problematic in machine learning society. It ruins the generalization power of a classifier by making the classifier be trained to be overfitted to wrong labels. Existing methods on noisy label have focused on modifying classifier training procedure. It results in two possible problems. First, these methods are not applicable to a pre-trained classifier without further access into training. Second, it is not easy to train a classifier and remove all of negative effects from noisy labels simultaneously. From these problems, we suggests a new branch of approach, Noisy Prediction Calibration (NPC) in learning with noisy labels. Through the introduction and estimation of a new type of transition matrix via generative model, NPC corrects the noisy prediction from the pre-trained classifier to the true label as a post-processing scheme. We prove that NPC theoretically aligns with the transition matrix based methods. Yet, NPC provides more accurate pathway to estimate true label, even without involvement in classifier learning. Also, NPC is applicable to any classifier trained with noisy label methods, if training instances and its predictions are available. Our method, NPC, boosts the classification performances of all baseline models on both synthetic and real-world datasets.

</p>
</details>

<details><summary><b>Scheduling with Speed Predictions</b>
<a href="https://arxiv.org/abs/2205.01247">arxiv:2205.01247</a>
&#x1F4C8; 4 <br>
<p>Eric Balkanski, Tingting Ou, Clifford Stein, Hao-Ting Wei</p></summary>
<p>

**Abstract:** Algorithms with predictions is a recent framework that has been used to overcome pessimistic worst-case bounds in incomplete information settings. In the context of scheduling, very recent work has leveraged machine-learned predictions to design algorithms that achieve improved approximation ratios in settings where the processing times of the jobs are initially unknown. In this paper, we study the speed-robust scheduling problem where the speeds of the machines, instead of the processing times of the jobs, are unknown and augment this problem with predictions.
  Our main result is an algorithm that achieves a $\min\{η^2(1+ε)^2(1+α), (1+ε)(2 + 2/α)\}$ approximation, for any constants $α, ε\in (0,1)$, where $η\geq 1$ is the prediction error. When the predictions are accurate, this approximation improves over the previously best known approximation of $2-1/m$ for speed-robust scheduling, where $m$ is the number of machines, while simultaneously maintaining a worst-case approximation of $(1+ε)(2 + 2/α)$ even when the predictions are wrong. In addition, we obtain improved approximations for the special cases of equal and infinitesimal job sizes, and we complement our algorithmic results with lower bounds. Finally, we empirically evaluate our algorithm against existing algorithms for speed-robust scheduling.

</p>
</details>

<details><summary><b>ADDAI: Anomaly Detection using Distributed AI</b>
<a href="https://arxiv.org/abs/2205.01231">arxiv:2205.01231</a>
&#x1F4C8; 4 <br>
<p>Maede Zolanvari, Ali Ghubaish, Raj Jain</p></summary>
<p>

**Abstract:** When dealing with the Internet of Things (IoT), especially industrial IoT (IIoT), two manifest challenges leap to mind. First is the massive amount of data streaming to and from IoT devices, and second is the fast pace at which these systems must operate. Distributed computing in the form of edge/cloud structure is a popular technique to overcome these two challenges. In this paper, we propose ADDAI (Anomaly Detection using Distributed AI) that can easily span out geographically to cover a large number of IoT sources. Due to its distributed nature, it guarantees critical IIoT requirements such as high speed, robustness against a single point of failure, low communication overhead, privacy, and scalability. Through empirical proof, we show the communication cost is minimized, and the performance improves significantly while maintaining the privacy of raw data at the local layer. ADDAI provides predictions for new random samples with an average success rate of 98.4% while reducing the communication overhead by half compared with the traditional technique of offloading all the raw sensor data to the cloud.

</p>
</details>

<details><summary><b>Leveraging Stochastic Predictions of Bayesian Neural Networks for Fluid Simulations</b>
<a href="https://arxiv.org/abs/2205.01222">arxiv:2205.01222</a>
&#x1F4C8; 4 <br>
<p>Maximilian Mueller, Robin Greif, Frank Jenko, Nils Thuerey</p></summary>
<p>

**Abstract:** We investigate uncertainty estimation and multimodality via the non-deterministic predictions of Bayesian neural networks (BNNs) in fluid simulations. To this end, we deploy BNNs in three challenging experimental test-cases of increasing complexity: We show that BNNs, when used as surrogate models for steady-state fluid flow predictions, provide accurate physical predictions together with sensible estimates of uncertainty. Further, we experiment with perturbed temporal sequences from Navier-Stokes simulations and evaluate the capabilities of BNNs to capture multimodal evolutions. While our findings indicate that this is problematic for large perturbations, our results show that the networks learn to correctly predict high uncertainties in such situations. Finally, we study BNNs in the context of solver interactions with turbulent plasma flows. We find that BNN-based corrector networks can stabilize coarse-grained simulations and successfully create multimodal trajectories.

</p>
</details>

<details><summary><b>Applications of Deep Learning to the Design of Enhanced Wireless Communication Systems</b>
<a href="https://arxiv.org/abs/2205.01210">arxiv:2205.01210</a>
&#x1F4C8; 4 <br>
<p>Mathieu Goutay</p></summary>
<p>

**Abstract:** Innovation in the physical layer of communication systems has traditionally been achieved by breaking down the transceivers into sets of processing blocks, each optimized independently based on mathematical models. Conversely, deep learning (DL)-based systems are able to handle increasingly complex tasks for which no tractable models are available. This thesis aims at comparing different approaches to unlock the full potential of DL in the physical layer.
  First, we describe a neural network (NN)-based block strategy, where an NN is optimized to replace a block in a communication system. We apply this strategy to introduce a multi-user multiple-input multiple-output (MU-MIMO) detector that builds on top of an existing DL-based architecture. Second, we detail an end-to-end strategy, in which the transmitter and receiver are modeled as an autoencoder. This approach is illustrated with the design of waveforms that achieve high throughputs while satisfying peak-to-average power ratio (PAPR) and adjacent channel leakage ratio (ACLR) constraints. Lastly, we propose a hybrid strategy, where multiple DL components are inserted into a traditional architecture but are trained to optimize the end-to-end performance. To demonstrate its benefits, we propose a DL-enhanced MU-MIMO receiver that both enable lower bit error rates (BERs) compared to a conventional receiver and remains scalable to any number of users.
  Each approach has its own strengths and shortcomings. While the first one is the easiest to implement, its individual block optimization does not ensure the overall system optimality. On the other hand, systems designed with the second approach are computationally complex but allow for new opportunities such as pilotless transmissions. Finally, the combined flexibility and end-to-end performance gains of the third approach motivate its use for short-term practical implementations.

</p>
</details>

<details><summary><b>VAE-Loco: Versatile Quadruped Locomotion by Learning a Disentangled Gait Representation</b>
<a href="https://arxiv.org/abs/2205.01179">arxiv:2205.01179</a>
&#x1F4C8; 4 <br>
<p>Alexander L. Mitchell, Wolfgang Merkt, Mathieu Geisert, Siddhant Gangapurwala, Martin Engelcke, Oiwi Parker Jones, Ioannis Havoutis, Ingmar Posner</p></summary>
<p>

**Abstract:** Quadruped locomotion is rapidly maturing to a degree where robots now routinely traverse a variety of unstructured terrains. However, while gaits can be varied typically by selecting from a range of pre-computed styles, current planners are unable to vary key gait parameters continuously while the robot is in motion. The synthesis, on-the-fly, of gaits with unexpected operational characteristics or even the blending of dynamic manoeuvres lies beyond the capabilities of the current state-of-the-art. In this work we address this limitation by learning a latent space capturing the key stance phases constituting a particular gait. This is achieved via a generative model trained on a single trot style, which encourages disentanglement such that application of a drive signal to a single dimension of the latent state induces holistic plans synthesising a continuous variety of trot styles. We demonstrate that specific properties of the drive signal map directly to gait parameters such as cadence, footstep height and full stance duration. Due to the nature of our approach these synthesised gaits are continuously variable online during robot operation and robustly capture a richness of movement significantly exceeding the relatively narrow behaviour seen during training. In addition, the use of a generative model facilitates the detection and mitigation of disturbances to provide a versatile and robust planning framework. We evaluate our approach on two versions of the real ANYmal quadruped robots and demonstrate that our method achieves a continuous blend of dynamic trot styles whilst being robust and reactive to external perturbations.

</p>
</details>

<details><summary><b>Emotion-Controllable Generalized Talking Face Generation</b>
<a href="https://arxiv.org/abs/2205.01155">arxiv:2205.01155</a>
&#x1F4C8; 4 <br>
<p>Sanjana Sinha, Sandika Biswas, Ravindra Yadav, Brojeshwar Bhowmick</p></summary>
<p>

**Abstract:** Despite the significant progress in recent years, very few of the AI-based talking face generation methods attempt to render natural emotions. Moreover, the scope of the methods is majorly limited to the characteristics of the training dataset, hence they fail to generalize to arbitrary unseen faces. In this paper, we propose a one-shot facial geometry-aware emotional talking face generation method that can generalize to arbitrary faces. We propose a graph convolutional neural network that uses speech content feature, along with an independent emotion input to generate emotion and speech-induced motion on facial geometry-aware landmark representation. This representation is further used in our optical flow-guided texture generation network for producing the texture. We propose a two-branch texture generation network, with motion and texture branches designed to consider the motion and texture content independently. Compared to the previous emotion talking face methods, our method can adapt to arbitrary faces captured in-the-wild by fine-tuning with only a single image of the target identity in neutral emotion.

</p>
</details>

<details><summary><b>Open-Set Semi-Supervised Learning for 3D Point Cloud Understanding</b>
<a href="https://arxiv.org/abs/2205.01006">arxiv:2205.01006</a>
&#x1F4C8; 4 <br>
<p>Xian Shi, Xun Xu, Wanyue Zhang, Xiatian Zhu, Chuan Sheng Foo, Kui Jia</p></summary>
<p>

**Abstract:** Semantic understanding of 3D point cloud relies on learning models with massively annotated data, which, in many cases, are expensive or difficult to collect. This has led to an emerging research interest in semi-supervised learning (SSL) for 3D point cloud. It is commonly assumed in SSL that the unlabeled data are drawn from the same distribution as that of the labeled ones; This assumption, however, rarely holds true in realistic environments. Blindly using out-of-distribution (OOD) unlabeled data could harm SSL performance. In this work, we propose to selectively utilize unlabeled data through sample weighting, so that only conducive unlabeled data would be prioritized. To estimate the weights, we adopt a bi-level optimization framework which iteratively optimizes a metaobjective on a held-out validation set and a task-objective on a training set. Faced with the instability of efficient bi-level optimizers, we further propose three regularization techniques to enhance the training stability. Extensive experiments on 3D point cloud classification and segmentation tasks verify the effectiveness of our proposed method. We also demonstrate the feasibility of a more efficient training strategy.

</p>
</details>

<details><summary><b>Understanding CNNs from excitations</b>
<a href="https://arxiv.org/abs/2205.00932">arxiv:2205.00932</a>
&#x1F4C8; 4 <br>
<p>Zijian Ying, Qianmu Li, Zhichao Lian</p></summary>
<p>

**Abstract:** For instance-level explanation, in order to reveal the relations between high-level semantics and detailed spatial information, this paper proposes a novel cognitive approach to neural networks, which named PANE. Under the guidance of PANE, a novel saliency map representation method, named IOM, is proposed for CNN-like models. We make the comparison with eight state-of-the-art saliency map representation methods. The experimental results show that IOM far outperforms baselines. The work of this paper may bring a new perspective to understand deep neural networks.

</p>
</details>

<details><summary><b>Deep Video Harmonization with Color Mapping Consistency</b>
<a href="https://arxiv.org/abs/2205.00687">arxiv:2205.00687</a>
&#x1F4C8; 4 <br>
<p>Xinyuan Lu, Shengyuan Huang, Li Niu, Wenyan Cong, Liqing Zhang</p></summary>
<p>

**Abstract:** Video harmonization aims to adjust the foreground of a composite video to make it compatible with the background. So far, video harmonization has only received limited attention and there is no public dataset for video harmonization. In this work, we construct a new video harmonization dataset HYouTube by adjusting the foreground of real videos to create synthetic composite videos. Moreover, we consider the temporal consistency in video harmonization task. Unlike previous works which establish the spatial correspondence, we design a novel framework based on the assumption of color mapping consistency, which leverages the color mapping of neighboring frames to refine the current frame. Extensive experiments on our HYouTube dataset prove the effectiveness of our proposed framework. Our dataset and code are available at https://github.com/bcmi/Video-Harmonization-Dataset-HYouTube.

</p>
</details>

<details><summary><b>Skeptical binary inferences in multi-label problems with sets of probabilities</b>
<a href="https://arxiv.org/abs/2205.00662">arxiv:2205.00662</a>
&#x1F4C8; 4 <br>
<p>Yonatan Carlos Carranza Alarcón, Sébastien Destercke</p></summary>
<p>

**Abstract:** In this paper, we consider the problem of making distributionally robust, skeptical inferences for the multi-label problem, or more generally for Boolean vectors. By distributionally robust, we mean that we consider a set of possible probability distributions, and by skeptical we understand that we consider as valid only those inferences that are true for every distribution within this set. Such inferences will provide partial predictions whenever the considered set is sufficiently big. We study in particular the Hamming loss case, a common loss function in multi-label problems, showing how skeptical inferences can be made in this setting. Our experimental results are organised in three sections; (1) the first one indicates the gain computational obtained from our theoretical results by using synthetical data sets, (2) the second one indicates that our approaches produce relevant cautiousness on those hard-to-predict instances where its precise counterpart fails, and (3) the last one demonstrates experimentally how our approach copes with imperfect information (generated by a downsampling procedure) better than the partial abstention [31] and the rejection rules.

</p>
</details>

<details><summary><b>The Limits of Word Level Differential Privacy</b>
<a href="https://arxiv.org/abs/2205.02130">arxiv:2205.02130</a>
&#x1F4C8; 3 <br>
<p>Justus Mattern, Benjamin Weggenmann, Florian Kerschbaum</p></summary>
<p>

**Abstract:** As the issues of privacy and trust are receiving increasing attention within the research community, various attempts have been made to anonymize textual data. A significant subset of these approaches incorporate differentially private mechanisms to perturb word embeddings, thus replacing individual words in a sentence. While these methods represent very important contributions, have various advantages over other techniques and do show anonymization capabilities, they have several shortcomings. In this paper, we investigate these weaknesses and demonstrate significant mathematical constraints diminishing the theoretical privacy guarantee as well as major practical shortcomings with regard to the protection against deanonymization attacks, the preservation of content of the original sentences as well as the quality of the language output. Finally, we propose a new method for text anonymization based on transformer based language models fine-tuned for paraphrasing that circumvents most of the identified weaknesses and also offers a formal privacy guarantee. We evaluate the performance of our method via thorough experimentation and demonstrate superior performance over the discussed mechanisms.

</p>
</details>

<details><summary><b>CANShield: Signal-based Intrusion Detection for Controller Area Networks</b>
<a href="https://arxiv.org/abs/2205.01306">arxiv:2205.01306</a>
&#x1F4C8; 3 <br>
<p>Md Hasan Shahriar, Yang Xiao, Pablo Moriano, Wenjing Lou, Y. Thomas Hou</p></summary>
<p>

**Abstract:** Modern vehicles rely on a fleet of electronic control units (ECUs) connected through controller area network (CAN) buses for critical vehicular control. However, with the expansion of advanced connectivity features in automobiles and the elevated risks of internal system exposure, the CAN bus is increasingly prone to intrusions and injection attacks. The ordinary injection attacks disrupt the typical timing properties of the CAN data stream, and the rule-based intrusion detection systems (IDS) can easily detect them. However, advanced attackers can inject false data to the time series sensory data (signal), while looking innocuous by the pattern/frequency of the CAN messages. Such attacks can bypass the rule-based IDS or any anomaly-based IDS built on binary payload data. To make the vehicles robust against such intelligent attacks, we propose CANShield, a signal-based intrusion detection framework for the CAN bus. CANShield consists of three modules: a data preprocessing module that handles the high-dimensional CAN data stream at the signal level and makes them suitable for a deep learning model; a data analyzer module consisting of multiple deep autoencoder (AE) networks, each analyzing the time-series data from a different temporal perspective; and finally an attack detection module that uses an ensemble method to make the final decision. Evaluation results on two high-fidelity signal-based CAN attack datasets show the high accuracy and responsiveness of CANShield in detecting wide-range of advanced intrusion attacks.

</p>
</details>

<details><summary><b>Real-time Cooperative Vehicle Coordination at Unsignalized Road Intersections</b>
<a href="https://arxiv.org/abs/2205.01278">arxiv:2205.01278</a>
&#x1F4C8; 3 <br>
<p>Jiping Luo, Tingting Zhang, Rui Hao, Donglin Li, Chunsheng Chen, Zhenyu Na, Qinyu Zhang</p></summary>
<p>

**Abstract:** Cooperative coordination at unsignalized road intersections, which aims to improve the driving safety and traffic throughput for connected and automated vehicles, has attracted increasing interests in recent years. However, most existing investigations either suffer from computational complexity or cannot harness the full potential of the road infrastructure. To this end, we first present a dedicated intersection coordination framework, where the involved vehicles hand over their control authorities and follow instructions from a centralized coordinator. Then a unified cooperative trajectory optimization problem will be formulated to maximize the traffic throughput while ensuring the driving safety and long-term stability of the coordination system. To address the key computational challenges in the real-world deployment, we reformulate this non-convex sequential decision problem into a model-free Markov Decision Process (MDP) and tackle it by devising a Twin Delayed Deep Deterministic Policy Gradient (TD3)-based strategy in the deep reinforcement learning (DRL) framework. Simulation and practical experiments show that the proposed strategy could achieve near-optimal performance in sub-static coordination scenarios and significantly improve the traffic throughput in the realistic continuous traffic flow. The most remarkable advantage is that our strategy could reduce the time complexity of computation to milliseconds, and is shown scalable when the road lanes increase.

</p>
</details>

<details><summary><b>A Performance-Consistent and Computation-Efficient CNN System for High-Quality Automated Brain Tumor Segmentation</b>
<a href="https://arxiv.org/abs/2205.01239">arxiv:2205.01239</a>
&#x1F4C8; 3 <br>
<p>Juncheng Tong, Chunyan Wang</p></summary>
<p>

**Abstract:** The research on developing CNN-based fully-automated Brain-Tumor-Segmentation systems has been progressed rapidly. For the systems to be applicable in practice, a good The research on developing CNN-based fully-automated Brain-Tumor-Segmentation systems has been progressed rapidly. For the systems to be applicable in practice, a good processing quality and reliability are the must. Moreover, for wide applications of such systems, a minimization of computation complexity is desirable, which can also result in a minimization of randomness in computation and, consequently, a better performance consistency. To this end, the CNN in the proposed system has a unique structure with 2 distinguished characters. Firstly, the three paths of its feature extraction block are designed to extract, from the multi-modality input, comprehensive feature information of mono-modality, paired-modality and cross-modality data, respectively. Also, it has a particular three-branch classification block to identify the pixels of 4 classes. Each branch is trained separately so that the parameters are updated specifically with the corresponding ground truth data of a target tumor areas. The convolution layers of the system are custom-designed with specific purposes, resulting in a very simple config of 61,843 parameters in total. The proposed system is tested extensively with BraTS2018 and BraTS2019 datasets. The mean Dice scores, obtained from the ten experiments on BraTS2018 validation samples, are 0.787+0.003, 0.886+0.002, 0.801+0.007, for enhancing tumor, whole tumor and tumor core, respectively, and 0.751+0.007, 0.885+0.002, 0.776+0.004 on BraTS2019. The test results demonstrate that the proposed system is able to perform high-quality segmentation in a consistent manner. Furthermore, its extremely low computation complexity will facilitate its implementation/application in various environments.

</p>
</details>

<details><summary><b>Triangular Dropout: Variable Network Width without Retraining</b>
<a href="https://arxiv.org/abs/2205.01235">arxiv:2205.01235</a>
&#x1F4C8; 3 <br>
<p>Edward W. Staley, Jared Markowitz</p></summary>
<p>

**Abstract:** One of the most fundamental design choices in neural networks is layer width: it affects the capacity of what a network can learn and determines the complexity of the solution. This latter property is often exploited when introducing information bottlenecks, forcing a network to learn compressed representations. However, such an architecture decision is typically immutable once training begins; switching to a more compressed architecture requires retraining. In this paper we present a new layer design, called Triangular Dropout, which does not have this limitation. After training, the layer can be arbitrarily reduced in width to exchange performance for narrowness. We demonstrate the construction and potential use cases of such a mechanism in three areas. Firstly, we describe the formulation of Triangular Dropout in autoencoders, creating models with selectable compression after training. Secondly, we add Triangular Dropout to VGG19 on ImageNet, creating a powerful network which, without retraining, can be significantly reduced in parameters. Lastly, we explore the application of Triangular Dropout to reinforcement learning (RL) policies on selected control problems.

</p>
</details>

<details><summary><b>Streaming Inference for Infinite Non-Stationary Clustering</b>
<a href="https://arxiv.org/abs/2205.01212">arxiv:2205.01212</a>
&#x1F4C8; 3 <br>
<p>Rylan Schaeffer, Gabrielle Kaili-May Liu, Yilun Du, Scott Linderman, Ila Rani Fiete</p></summary>
<p>

**Abstract:** Learning from a continuous stream of non-stationary data in an unsupervised manner is arguably one of the most common and most challenging settings facing intelligent agents. Here, we attack learning under all three conditions (unsupervised, streaming, non-stationary) in the context of clustering, also known as mixture modeling. We introduce a novel clustering algorithm that endows mixture models with the ability to create new clusters online, as demanded by the data, in a probabilistic, time-varying, and principled manner. To achieve this, we first define a novel stochastic process called the Dynamical Chinese Restaurant Process (Dynamical CRP), which is a non-exchangeable distribution over partitions of a set; next, we show that the Dynamical CRP provides a non-stationary prior over cluster assignments and yields an efficient streaming variational inference algorithm. We conclude with experiments showing that the Dynamical CRP can be applied on diverse synthetic and real data with Gaussian and non-Gaussian likelihoods.

</p>
</details>

<details><summary><b>Multi-Task Text Classification using Graph Convolutional Networks for Large-Scale Low Resource Language</b>
<a href="https://arxiv.org/abs/2205.01204">arxiv:2205.01204</a>
&#x1F4C8; 3 <br>
<p>Mounika Marreddy, Subba Reddy Oota, Lakshmi Sireesha Vakada, Venkata Charan Chinni, Radhika Mamidi</p></summary>
<p>

**Abstract:** Graph Convolutional Networks (GCN) have achieved state-of-art results on single text classification tasks like sentiment analysis, emotion detection, etc. However, the performance is achieved by testing and reporting on resource-rich languages like English. Applying GCN for multi-task text classification is an unexplored area. Moreover, training a GCN or adopting an English GCN for Indian languages is often limited by data availability, rich morphological variation, syntax, and semantic differences. In this paper, we study the use of GCN for the Telugu language in single and multi-task settings for four natural language processing (NLP) tasks, viz. sentiment analysis (SA), emotion identification (EI), hate-speech (HS), and sarcasm detection (SAR). In order to evaluate the performance of GCN with one of the Indian languages, Telugu, we analyze the GCN based models with extensive experiments on four downstream tasks. In addition, we created an annotated Telugu dataset, TEL-NLP, for the four NLP tasks. Further, we propose a supervised graph reconstruction method, Multi-Task Text GCN (MT-Text GCN) on the Telugu that leverages to simultaneously (i) learn the low-dimensional word and sentence graph embeddings from word-sentence graph reconstruction using graph autoencoder (GAE) and (ii) perform multi-task text classification using these latent sentence graph embeddings. We argue that our proposed MT-Text GCN achieves significant improvements on TEL-NLP over existing Telugu pretrained word embeddings, and multilingual pretrained Transformer models: mBERT, and XLM-R. On TEL-NLP, we achieve a high F1-score for four NLP tasks: SA (0.84), EI (0.55), HS (0.83) and SAR (0.66). Finally, we show our model's quantitative and qualitative analysis on the four NLP tasks in Telugu.

</p>
</details>

<details><summary><b>SELC: Self-Ensemble Label Correction Improves Learning with Noisy Labels</b>
<a href="https://arxiv.org/abs/2205.01156">arxiv:2205.01156</a>
&#x1F4C8; 3 <br>
<p>Yangdi Lu, Wenbo He</p></summary>
<p>

**Abstract:** Deep neural networks are prone to overfitting noisy labels, resulting in poor generalization performance. To overcome this problem, we present a simple and effective method self-ensemble label correction (SELC) to progressively correct noisy labels and refine the model. We look deeper into the memorization behavior in training with noisy labels and observe that the network outputs are reliable in the early stage. To retain this reliable knowledge, SELC uses ensemble predictions formed by an exponential moving average of network outputs to update the original noisy labels. We show that training with SELC refines the model by gradually reducing supervision from noisy labels and increasing supervision from ensemble predictions. Despite its simplicity, compared with many state-of-the-art methods, SELC obtains more promising and stable results in the presence of class-conditional, instance-dependent, and real-world label noise. The code is available at https://github.com/MacLLL/SELC.

</p>
</details>

<details><summary><b>D-DPCC: Deep Dynamic Point Cloud Compression via 3D Motion Prediction</b>
<a href="https://arxiv.org/abs/2205.01135">arxiv:2205.01135</a>
&#x1F4C8; 3 <br>
<p>Tingyu Fan, Linyao Gao, Yiling Xu, Zhu Li, Dong Wang</p></summary>
<p>

**Abstract:** The non-uniformly distributed nature of the 3D dynamic point cloud (DPC) brings significant challenges to its high-efficient inter-frame compression. This paper proposes a novel 3D sparse convolution-based Deep Dynamic Point Cloud Compression (D-DPCC) network to compensate and compress the DPC geometry with 3D motion estimation and motion compensation in the feature space. In the proposed D-DPCC network, we design a {\it Multi-scale Motion Fusion} (MMF) module to accurately estimate the 3D optical flow between the feature representations of adjacent point cloud frames. Specifically, we utilize a 3D sparse convolution-based encoder to obtain the latent representation for motion estimation in the feature space and introduce the proposed MMF module for fused 3D motion embedding. Besides, for motion compensation, we propose a 3D {\it Adaptively Weighted Interpolation} (3DAWI) algorithm with a penalty coefficient to adaptively decrease the impact of distant neighbors. We compress the motion embedding and the residual with a lossy autoencoder-based network. To our knowledge, this paper is the first work proposing an end-to-end deep dynamic point cloud compression framework. The experimental result shows that the proposed D-DPCC framework achieves an average 76\% BD-Rate (Bjontegaard Delta Rate) gains against state-of-the-art Video-based Point Cloud Compression (V-PCC) v13 in inter mode.

</p>
</details>

<details><summary><b>Knowledge Graph Contrastive Learning for Recommendation</b>
<a href="https://arxiv.org/abs/2205.00976">arxiv:2205.00976</a>
&#x1F4C8; 3 <br>
<p>Yuhao Yang, Chao Huang, Lianghao Xia, Chenliang Li</p></summary>
<p>

**Abstract:** Knowledge Graphs (KGs) have been utilized as useful side information to improve recommendation quality. In those recommender systems, knowledge graph information often contains fruitful facts and inherent semantic relatedness among items. However, the success of such methods relies on the high quality knowledge graphs, and may not learn quality representations with two challenges: i) The long-tail distribution of entities results in sparse supervision signals for KG-enhanced item representation; ii) Real-world knowledge graphs are often noisy and contain topic-irrelevant connections between items and entities. Such KG sparsity and noise make the item-entity dependent relations deviate from reflecting their true characteristics, which significantly amplifies the noise effect and hinders the accurate representation of user's preference.
  To fill this research gap, we design a general Knowledge Graph Contrastive Learning framework (KGCL) that alleviates the information noise for knowledge graph-enhanced recommender systems. Specifically, we propose a knowledge graph augmentation schema to suppress KG noise in information aggregation, and derive more robust knowledge-aware representations for items. In addition, we exploit additional supervision signals from the KG augmentation process to guide a cross-view contrastive learning paradigm, giving a greater role to unbiased user-item interactions in gradient descent and further suppressing the noise. Extensive experiments on three public datasets demonstrate the consistent superiority of our KGCL over state-of-the-art techniques. KGCL also achieves strong performance in recommendation scenarios with sparse user-item interactions, long-tail and noisy KG entities. Our implementation codes are available at https://github.com/yuh-yang/KGCL-SIGIR22

</p>
</details>

<details><summary><b>Assessing unconstrained surgical cuttings in VR using CNNs</b>
<a href="https://arxiv.org/abs/2205.00934">arxiv:2205.00934</a>
&#x1F4C8; 3 <br>
<p>Ilias Chrysovergis, Manos Kamarianakis, Mike Kentros, Dimitris Angelis, Antonis Protopsaltis, George Papagiannakis</p></summary>
<p>

**Abstract:** We present a Convolutional Neural Network (CNN) suitable to assess unconstrained surgical cuttings, trained on a dataset created with a data augmentation technique.

</p>
</details>

<details><summary><b>Revisiting Gaussian Neurons for Online Clustering with Unknown Number of Clusters</b>
<a href="https://arxiv.org/abs/2205.00920">arxiv:2205.00920</a>
&#x1F4C8; 3 <br>
<p>Ole Christian Eidheim</p></summary>
<p>

**Abstract:** Despite the recent success of artificial neural networks, more biologically plausible learning methods may be needed to resolve the weaknesses of backpropagation trained models such as catastrophic forgetting and adversarial attacks. A novel local learning rule is presented that performs online clustering with a maximum limit of the number of cluster to be found rather than a fixed cluster count. Instead of using orthogonal weight or output activation constraints, activation sparsity is achieved by mutual repulsion of lateral Gaussian neurons ensuring that multiple neuron centers cannot occupy the same location in the input domain. An update method is also presented for adjusting the widths of the Gaussian neurons in cases where the data samples can be represented by means and variances. The algorithms were applied on the MNIST and CIFAR-10 datasets to create filters capturing the input patterns of pixel patches of various sizes. The experimental results demonstrate stability in the learned parameters across a large number of training samples.

</p>
</details>

<details><summary><b>Zebra: Memory Bandwidth Reduction for CNN Accelerators With Zero Block Regularization of Activation Maps</b>
<a href="https://arxiv.org/abs/2205.00779">arxiv:2205.00779</a>
&#x1F4C8; 3 <br>
<p>Hsu-Tung Shih, Tian-Sheuan Chang</p></summary>
<p>

**Abstract:** The large amount of memory bandwidth between local buffer and external DRAM has become the speedup bottleneck of CNN hardware accelerators, especially for activation maps. To reduce memory bandwidth, we propose to learn pruning unimportant blocks dynamically with zero block regularization of activation maps (Zebra). This strategy has low computational overhead and could easily integrate with other pruning methods for better performance. The experimental results show that the proposed method can reduce 70\% of memory bandwidth for Resnet-18 on Tiny-Imagenet within 1\% accuracy drops and 2\% accuracy gain with the combination of Network Slimming.

</p>
</details>

<details><summary><b>Sparse Compressed Spiking Neural Network Accelerator for Object Detection</b>
<a href="https://arxiv.org/abs/2205.00778">arxiv:2205.00778</a>
&#x1F4C8; 3 <br>
<p>Hong-Han Lien, Tian-Sheuan Chang</p></summary>
<p>

**Abstract:** Spiking neural networks (SNNs), which are inspired by the human brain, have recently gained popularity due to their relatively simple and low-power hardware for transmitting binary spikes and highly sparse activation maps. However, because SNNs contain extra time dimension information, the SNN accelerator will require more buffers and take longer to infer, especially for the more difficult high-resolution object detection task. As a result, this paper proposes a sparse compressed spiking neural network accelerator that takes advantage of the high sparsity of activation maps and weights by utilizing the proposed gated one-to-all product for low power and highly parallel model execution. The experimental result of the neural network shows 71.5$\%$ mAP with mixed (1,3) time steps on the IVS 3cls dataset. The accelerator with the TSMC 28nm CMOS process can achieve 1024$\times$576@29 frames per second processing when running at 500MHz with 35.88TOPS/W energy efficiency and 1.05mJ energy consumption per frame.

</p>
</details>

<details><summary><b>BSRA: Block-based Super Resolution Accelerator with Hardware Efficient Pixel Attention</b>
<a href="https://arxiv.org/abs/2205.00777">arxiv:2205.00777</a>
&#x1F4C8; 3 <br>
<p>Dun-Hao Yang, Tian-Sheuan Chang</p></summary>
<p>

**Abstract:** Increasingly, convolution neural network (CNN) based super resolution models have been proposed for better reconstruction results, but their large model size and complicated structure inhibit their real-time hardware implementation. Current hardware designs are limited to a plain network and suffer from lower quality and high memory bandwidth requirements. This paper proposes a super resolution hardware accelerator with hardware efficient pixel attention that just needs 25.9K parameters and simple structure but achieves 0.38dB better reconstruction images than the widely used FSRCNN. The accelerator adopts full model block wise convolution for full model layer fusion to reduce external memory access to model input and output only. In addition, CNN and pixel attention are well supported by PE arrays with distributed weights. The final implementation can support full HD image reconstruction at 30 frames per second with TSMC 40nm CMOS process.

</p>
</details>

<details><summary><b>Superredundancy: A tool for Boolean formula minimization complexity analysis</b>
<a href="https://arxiv.org/abs/2205.00762">arxiv:2205.00762</a>
&#x1F4C8; 3 <br>
<p>Paolo Liberatore</p></summary>
<p>

**Abstract:** A superredundant clause is a clause that is redundant in the resolution closure of a formula. The converse concept of superirredundancy ensures membership of the clause in all minimal CNF formulae that are equivalent to the given one. This allows for building formulae where some clauses are fixed when minimizing size. An example are proofs of complexity hardness of the problems of minimal formula size. Others are proofs of size when forgetting variables or revising a formula. Most clauses can be made superirredundant by splitting them over a new variable.

</p>
</details>

<details><summary><b>Unsupervised Denoising of Optical Coherence Tomography Images with Dual_Merged CycleWGAN</b>
<a href="https://arxiv.org/abs/2205.00698">arxiv:2205.00698</a>
&#x1F4C8; 3 <br>
<p>Jie Du, Xujian Yang, Kecheng Jin, Xuanzheng Qi, Hu Chen</p></summary>
<p>

**Abstract:** Nosie is an important cause of low quality Optical coherence tomography (OCT) image. The neural network model based on Convolutional neural networks(CNNs) has demonstrated its excellent performance in image denoising. However, OCT image denoising still faces great challenges because many previous neural network algorithms required a large number of labeled data, which might cost much time or is expensive. Besides, these CNN-based algorithms need numerous parameters and good tuning techniques, which is hardware resources consuming. To solved above problems, We proposed a new Cycle-Consistent Generative Adversarial Nets called Dual-Merged Cycle-WGAN for retinal OCT image denoiseing, which has remarkable performance with less unlabeled traning data. Our model consists of two Cycle-GAN networks with imporved generator, descriminator and wasserstein loss to achieve good training stability and better performance. Using image merge technique between two Cycle-GAN networks, our model could obtain more detailed information and hence better training effect. The effectiveness and generality of our proposed network has been proved via ablation experiments and comparative experiments. Compared with other state-of-the-art methods, our unsupervised method obtains best subjective visual effect and higher evaluation objective indicators.

</p>
</details>

<details><summary><b>Simple Techniques Work Surprisingly Well for Neural Network Test Prioritization and Active Learning (Replicability Study)</b>
<a href="https://arxiv.org/abs/2205.00664">arxiv:2205.00664</a>
&#x1F4C8; 3 <br>
<p>Michael Weiss, Paolo Tonella</p></summary>
<p>

**Abstract:** Test Input Prioritizers (TIP) for Deep Neural Networks (DNN) are an important technique to handle the typically very large test datasets efficiently, saving computation and labeling costs. This is particularly true for large-scale, deployed systems, where inputs observed in production are recorded to serve as potential test or training data for the next versions of the system. Feng et. al. propose DeepGini, a very fast and simple TIP, and show that it outperforms more elaborate techniques such as neuron- and surprise coverage. In a large-scale study (4 case studies, 8 test datasets, 32'200 trained models) we verify their findings. However, we also find that other comparable or even simpler baselines from the field of uncertainty quantification, such as the predicted softmax likelihood or the entropy of the predicted softmax likelihoods perform equally well as DeepGini.

</p>
</details>

<details><summary><b>ASTROMER: A transformer-based embedding for the representation of light curves</b>
<a href="https://arxiv.org/abs/2205.01677">arxiv:2205.01677</a>
&#x1F4C8; 2 <br>
<p>C. Donoso-Oliva, I. Becker, P. Protopapas, G. Cabrera-Vives, Vishnu M., Harsh Vardhan</p></summary>
<p>

**Abstract:** Taking inspiration from natural language embeddings, we present ASTROMER, a transformer-based model to create representations of light curves. ASTROMER was trained on millions of MACHO R-band samples, and it can be easily fine-tuned to match specific domains associated with downstream tasks. As an example, this paper shows the benefits of using pre-trained representations to classify variable stars. In addition, we provide a python library including all functionalities employed in this work. Our library includes the pre-trained models that can be used to enhance the performance of deep learning models, decreasing computational resources while achieving state-of-the-art results.

</p>
</details>

<details><summary><b>A Deep Learning-based Integrated Framework for Quality-aware Undersampled Cine Cardiac MRI Reconstruction and Analysis</b>
<a href="https://arxiv.org/abs/2205.01673">arxiv:2205.01673</a>
&#x1F4C8; 2 <br>
<p>Inês P. Machado, Esther Puyol-Antón, Kerstin Hammernik, Gastão Cruz, Devran Ugurlu, Ihsane Olakorede, Ilkay Oksuz, Bram Ruijsink, Miguel Castelo-Branco, Alistair A. Young, Claudia Prieto, Julia A. Schnabel, Andrew P. King</p></summary>
<p>

**Abstract:** Cine cardiac magnetic resonance (CMR) imaging is considered the gold standard for cardiac function evaluation. However, cine CMR acquisition is inherently slow and in recent decades considerable effort has been put into accelerating scan times without compromising image quality or the accuracy of derived results. In this paper, we present a fully-automated, quality-controlled integrated framework for reconstruction, segmentation and downstream analysis of undersampled cine CMR data. The framework enables active acquisition of radial k-space data, in which acquisition can be stopped as soon as acquired data are sufficient to produce high quality reconstructions and segmentations. This results in reduced scan times and automated analysis, enabling robust and accurate estimation of functional biomarkers. To demonstrate the feasibility of the proposed approach, we perform realistic simulations of radial k-space acquisitions on a dataset of subjects from the UK Biobank and present results on in-vivo cine CMR k-space data collected from healthy subjects. The results demonstrate that our method can produce quality-controlled images in a mean scan time reduced from 12 to 4 seconds per slice, and that image quality is sufficient to allow clinically relevant parameters to be automatically estimated to within 5% mean absolute difference.

</p>
</details>

<details><summary><b>RangeSeg: Range-Aware Real Time Segmentation of 3D LiDAR Point Clouds</b>
<a href="https://arxiv.org/abs/2205.01570">arxiv:2205.01570</a>
&#x1F4C8; 2 <br>
<p>Tzu-Hsuan Chen, Tian Sheuan Chang</p></summary>
<p>

**Abstract:** Semantic outdoor scene understanding based on 3D LiDAR point clouds is a challenging task for autonomous driving due to the sparse and irregular data structure. This paper takes advantages of the uneven range distribution of different LiDAR laser beams to propose a range aware instance segmentation network, RangeSeg. RangeSeg uses a shared encoder backbone with two range dependent decoders. A heavy decoder only computes top of a range image where the far and small objects locate to improve small object detection accuracy, and a light decoder computes whole range image for low computational cost. The results are further clustered by the DBSCAN method with a resolution weighted distance function to get instance-level segmentation results. Experiments on the KITTI dataset show that RangeSeg outperforms the state-of-the-art semantic segmentation methods with enormous speedup and improves the instance-level segmentation performance on small and far objects. The whole RangeSeg pipeline meets the real time requirement on NVIDIA\textsuperscript{\textregistered} JETSON AGX Xavier with 19 frames per second in average.

</p>
</details>

<details><summary><b>Embedding Hallucination for Few-Shot Language Fine-tuning</b>
<a href="https://arxiv.org/abs/2205.01307">arxiv:2205.01307</a>
&#x1F4C8; 2 <br>
<p>Yiren Jian, Chongyang Gao, Soroush Vosoughi</p></summary>
<p>

**Abstract:** Few-shot language learners adapt knowledge from a pre-trained model to recognize novel classes from a few-labeled sentences. In such settings, fine-tuning a pre-trained language model can cause severe over-fitting. In this paper, we propose an Embedding Hallucination (EmbedHalluc) method, which generates auxiliary embedding-label pairs to expand the fine-tuning dataset. The hallucinator is trained by playing an adversarial game with the discriminator, such that the hallucinated embedding is indiscriminative to the real ones in the fine-tuning dataset. By training with the extended dataset, the language learner effectively learns from the diverse hallucinated embeddings to overcome the over-fitting issue. Experiments demonstrate that our proposed method is effective in a wide range of language tasks, outperforming current fine-tuning methods. Further, we show that EmbedHalluc outperforms other methods that address this over-fitting problem, such as common data augmentation, semi-supervised pseudo-labeling, and regularization. The code will be made available at: https://github.com/yiren-jian/EmbedHalluc.

</p>
</details>

<details><summary><b>Modus ponens and modus tollens for the compositional rule of inference with aggregation functions</b>
<a href="https://arxiv.org/abs/2205.01269">arxiv:2205.01269</a>
&#x1F4C8; 2 <br>
<p>Dechao Li, Qingxue Zeng</p></summary>
<p>

**Abstract:** The compositional rule of inference (CRI) proposed by Zadeh has been widely applied in artificial intelligence, control, data mining, image processing, decision making and so on. Recently, Li and Zeng [Li, D., Zeng, Q. Approximate reasoning with aggregation functions satisfying GMP rules, Artificial Intelligence Review (2022), https://doi.org/10.1007/s10462-022-10136-1] shown an A-compositional rule of inference (ACRI) method in which generalizes the t-norm to any aggregation function in CRI method and studied its validity using GMP rules. In this paper, we continue to investigate the validity of ACRI method from a logical view and an interpolative view. Specifically, to discuss the modus ponens (MP) and modus tollens (MT) properties of ACRI method based on well-known fuzzy implications with aggregation functions.

</p>
</details>

<details><summary><b>A Sharp Memory-Regret Trade-Off for Multi-Pass Streaming Bandits</b>
<a href="https://arxiv.org/abs/2205.00984">arxiv:2205.00984</a>
&#x1F4C8; 2 <br>
<p>Arpit Agarwal, Sanjeev Khanna, Prathamesh Patil</p></summary>
<p>

**Abstract:** The stochastic $K$-armed bandit problem has been studied extensively due to its applications in various domains ranging from online advertising to clinical trials. In practice however, the number of arms can be very large resulting in large memory requirements for simultaneously processing them. In this paper we consider a streaming setting where the arms are presented in a stream and the algorithm uses limited memory to process these arms. Here, the goal is not only to minimize regret, but also to do so in minimal memory. Previous algorithms for this problem operate in one of the two settings: they either use $Ω(\log \log T)$ passes over the stream (Rathod, 2021; Chaudhuri and Kalyanakrishnan, 2020; Liau et al., 2018), or just a single pass (Maiti et al., 2021).
  In this paper we study the trade-off between memory and regret when $B$ passes over the stream are allowed, for any $B \geq 1$, and establish tight regret upper and lower bounds for any $B$-pass algorithm. Our results uncover a surprising *sharp transition phenomenon*: $O(1)$ memory is sufficient to achieve $\widetildeΘ\Big(T^{\frac{1}{2} + \frac{1}{2^{B+2}-2}}\Big)$ regret in $B$ passes, and increasing the memory to any quantity that is $o(K)$ has almost no impact on further reducing this regret, unless we use $Ω(K)$ memory. Our main technical contribution is our lower bound which requires the use of information-theoretic techniques as well as ideas from round elimination to show that the *residual problem* remains challenging over subsequent passes.

</p>
</details>

<details><summary><b>FastGCL: Fast Self-Supervised Learning on Graphs via Contrastive Neighborhood Aggregation</b>
<a href="https://arxiv.org/abs/2205.00905">arxiv:2205.00905</a>
&#x1F4C8; 2 <br>
<p>Yuansheng Wang, Wangbin Sun, Kun Xu, Zulun Zhu, Liang Chen, Zibin Zheng</p></summary>
<p>

**Abstract:** Graph contrastive learning (GCL), as a popular approach to graph self-supervised learning, has recently achieved a non-negligible effect. To achieve superior performance, the majority of existing GCL methods elaborate on graph data augmentation to construct appropriate contrastive pairs. However, existing methods place more emphasis on the complex graph data augmentation which requires extra time overhead, and pay less attention to developing contrastive schemes specific to encoder characteristics. We argue that a better contrastive scheme should be tailored to the characteristics of graph neural networks (e.g., neighborhood aggregation) and propose a simple yet effective method named FastGCL. Specifically, by constructing weighted-aggregated and non-aggregated neighborhood information as positive and negative samples respectively, FastGCL identifies the potential semantic information of data without disturbing the graph topology and node attributes, resulting in faster training and convergence speeds. Extensive experiments have been conducted on node classification and graph classification tasks, showing that FastGCL has competitive classification performance and significant training speedup compared to existing state-of-the-art methods.

</p>
</details>

<details><summary><b>Positive-Unlabeled Learning with Adversarial Data Augmentation for Knowledge Graph Completion</b>
<a href="https://arxiv.org/abs/2205.00904">arxiv:2205.00904</a>
&#x1F4C8; 2 <br>
<p>Zhenwei Tang, Shichao Pei, Zhao Zhang, Yongchun Zhu, Fuzhen Zhuang, Robert Hoehndorf, Xiangliang Zhang</p></summary>
<p>

**Abstract:** Most real-world knowledge graphs (KG) are far from complete and comprehensive. This problem has motivated efforts in predicting the most plausible missing facts to complete a given KG, i.e., knowledge graph completion (KGC). However, existing KGC methods suffer from two main issues, 1) the false negative issue, i.e., the candidates for sampling negative training instances include potential true facts; and 2) the data sparsity issue, i.e., true facts account for only a tiny part of all possible facts. To this end, we propose positive-unlabeled learning with adversarial data augmentation (PUDA) for KGC. In particular, PUDA tailors positive-unlabeled risk estimator for the KGC task to deal with the false negative issue. Furthermore, to address the data sparsity issue, PUDA achieves a data augmentation strategy by unifying adversarial training and positive-unlabeled learning under the positive-unlabeled minimax game. Extensive experimental results demonstrate its effectiveness and compatibility.

</p>
</details>

<details><summary><b>Modeling and mitigation of occupational safety risks in dynamic industrial environments</b>
<a href="https://arxiv.org/abs/2205.00894">arxiv:2205.00894</a>
&#x1F4C8; 2 <br>
<p>Ashutosh Tewari, Antonio R. Paiva</p></summary>
<p>

**Abstract:** Identifying and mitigating safety risks is paramount in a number of industries. In addition to guidelines and best practices, many industries already have safety management systems (SMSs) designed to monitor and reinforce good safety behaviors. The analytic capabilities to analyze the data acquired through such systems, however, are still lacking in terms of their ability to robustly quantify risks posed by various occupational hazards. Moreover, best practices and modern SMSs are unable to account for dynamically evolving environments/behavioral characteristics commonly found in many industrial settings. This article proposes a method to address these issues by enabling continuous and quantitative assessment of safety risks in a data-driven manner. The backbone of our method is an intuitive hierarchical probabilistic model that explains sparse and noisy safety data collected by a typical SMS. A fully Bayesian approach is developed to calibrate this model from safety data in an online fashion. Thereafter, the calibrated model holds necessary information that serves to characterize risk posed by different safety hazards. Additionally, the proposed model can be leveraged for automated decision making, for instance solving resource allocation problems -- targeted towards risk mitigation -- that are often encountered in resource-constrained industrial environments. The methodology is rigorously validated on a simulated test-bed and its scalability is demonstrated on real data from large maintenance projects at a petrochemical plant.

</p>
</details>

<details><summary><b>WeatherBench Probability: A benchmark dataset for probabilistic medium-range weather forecasting along with deep learning baseline models</b>
<a href="https://arxiv.org/abs/2205.00865">arxiv:2205.00865</a>
&#x1F4C8; 2 <br>
<p>Sagar Garg, Stephan Rasp, Nils Thuerey</p></summary>
<p>

**Abstract:** WeatherBench is a benchmark dataset for medium-range weather forecasting of geopotential, temperature and precipitation, consisting of preprocessed data, predefined evaluation metrics and a number of baseline models. WeatherBench Probability extends this to probabilistic forecasting by adding a set of established probabilistic verification metrics (continuous ranked probability score, spread-skill ratio and rank histograms) and a state-of-the-art operational baseline using the ECWMF IFS ensemble forecast. In addition, we test three different probabilistic machine learning methods -- Monte Carlo dropout, parametric prediction and categorical prediction, in which the probability distribution is discretized. We find that plain Monte Carlo dropout severely underestimates uncertainty. The parametric and categorical models both produce fairly reliable forecasts of similar quality. The parametric models have fewer degrees of freedom while the categorical model is more flexible when it comes to predicting non-Gaussian distributions. None of the models are able to match the skill of the operational IFS model. We hope that this benchmark will enable other researchers to evaluate their probabilistic approaches.

</p>
</details>

<details><summary><b>Deep-Attack over the Deep Reinforcement Learning</b>
<a href="https://arxiv.org/abs/2205.00807">arxiv:2205.00807</a>
&#x1F4C8; 2 <br>
<p>Yang Li, Quan Pan, Erik Cambria</p></summary>
<p>

**Abstract:** Recent adversarial attack developments have made reinforcement learning more vulnerable, and different approaches exist to deploy attacks against it, where the key is how to choose the right timing of the attack. Some work tries to design an attack evaluation function to select critical points that will be attacked if the value is greater than a certain threshold. This approach makes it difficult to find the right place to deploy an attack without considering the long-term impact. In addition, there is a lack of appropriate indicators of assessment during attacks. To make the attacks more intelligent as well as to remedy the existing problems, we propose the reinforcement learning-based attacking framework by considering the effectiveness and stealthy spontaneously, while we also propose a new metric to evaluate the performance of the attack model in these two aspects. Experimental results show the effectiveness of our proposed model and the goodness of our proposed evaluation metric. Furthermore, we validate the transferability of the model, and also its robustness under the adversarial training.

</p>
</details>

<details><summary><b>Type-aware Embeddings for Multi-Hop Reasoning over Knowledge Graphs</b>
<a href="https://arxiv.org/abs/2205.00782">arxiv:2205.00782</a>
&#x1F4C8; 2 <br>
<p>Zhiwei Hu, Víctor Gutiérrez-Basulto, Zhiliang Xiang, Xiaoli Li, Ru Li, Jeff Z. Pan</p></summary>
<p>

**Abstract:** Multi-hop reasoning over real-life knowledge graphs (KGs) is a highly challenging problem as traditional subgraph matching methods are not capable to deal with noise and missing information. To address this problem, it has been recently introduced a promising approach based on jointly embedding logical queries and KGs into a low-dimensional space to identify answer entities. However, existing proposals ignore critical semantic knowledge inherently available in KGs, such as type information. To leverage type information, we propose a novel TypE-aware Message Passing (TEMP) model, which enhances the entity and relation representations in queries, and simultaneously improves generalization, deductive and inductive reasoning. Remarkably, TEMP is a plug-and-play model that can be easily incorporated into existing embedding-based models to improve their performance. Extensive experiments on three real-world datasets demonstrate TEMP's effectiveness.

</p>
</details>

<details><summary><b>Large Neighborhood Search based on Neural Construction Heuristics</b>
<a href="https://arxiv.org/abs/2205.00772">arxiv:2205.00772</a>
&#x1F4C8; 2 <br>
<p>Jonas K. Falkner, Daniela Thyssens, Lars Schmidt-Thieme</p></summary>
<p>

**Abstract:** We propose a Large Neighborhood Search (LNS) approach utilizing a learned construction heuristic based on neural networks as repair operator to solve the vehicle routing problem with time windows (VRPTW). Our method uses graph neural networks to encode the problem and auto-regressively decodes a solution and is trained with reinforcement learning on the construction task without requiring any labels for supervision. The neural repair operator is combined with a local search routine, heuristic destruction operators and a selection procedure applied to a small population to arrive at a sophisticated solution approach. The key idea is to use the learned model to re-construct the partially destructed solution and to introduce randomness via the destruction heuristics (or the stochastic policy itself) to effectively explore a large neighborhood.

</p>
</details>

<details><summary><b>Efficient Accelerator for Dilated and Transposed Convolution with Decomposition</b>
<a href="https://arxiv.org/abs/2205.02103">arxiv:2205.02103</a>
&#x1F4C8; 1 <br>
<p>Kuo-Wei Chang, Tian-Sheuan Chang</p></summary>
<p>

**Abstract:** Hardware acceleration for dilated and transposed convolution enables real time execution of related tasks like segmentation, but current designs are specific for these convolutional types or suffer from complex control for reconfigurable designs. This paper presents a design that decomposes input or weight for dilated and transposed convolutions respectively to skip redundant computations and thus executes efficiently on existing dense CNN hardware as well. The proposed architecture can cut down 87.8\% of the cycle counts to achieve 8.2X speedup over a naive execution for the ENet case.

</p>
</details>

<details><summary><b>Pre-RTL DNN Hardware Evaluator With Fused Layer Support</b>
<a href="https://arxiv.org/abs/2205.01729">arxiv:2205.01729</a>
&#x1F4C8; 1 <br>
<p>Chih-Chyau Yang, Tian-Sheuan Chang</p></summary>
<p>

**Abstract:** With the popularity of the deep neural network (DNN), hardware accelerators are demanded for real time execution. However, lengthy design process and fast evolving DNN models make hardware evaluation hard to meet the time to market need. This paper proposes a pre-RTL DNN hardware evaluator that supports conventional layer-by-layer processing as well as the fused layer processing for low external bandwidth requirement. The evaluator supports two state-of-the-art accelerator architectures and finds the best hardware and layer fusion group The experimental results show the layer fusion scheme can achieve 55.6% memory bandwidth reduction, 36.7% latency improvement and 49.2% energy reduction compared with layer-by-layer operation.

</p>
</details>

<details><summary><b>Physics to the Rescue: Deep Non-line-of-sight Reconstruction for High-speed Imaging</b>
<a href="https://arxiv.org/abs/2205.01679">arxiv:2205.01679</a>
&#x1F4C8; 1 <br>
<p>Fangzhou Mu, Sicheng Mo, Jiayong Peng, Xiaochun Liu, Ji Hyun Nam, Siddeshwar Raghavan, Andreas Velten, Yin Li</p></summary>
<p>

**Abstract:** Computational approach to imaging around the corner, or non-line-of-sight (NLOS) imaging, is becoming a reality thanks to major advances in imaging hardware and reconstruction algorithms. A recent development towards practical NLOS imaging, Nam et al. demonstrated a high-speed non-confocal imaging system that operates at 5Hz, 100x faster than the prior art. This enormous gain in acquisition rate, however, necessitates numerous approximations in light transport, breaking many existing NLOS reconstruction methods that assume an idealized image formation model. To bridge the gap, we present a novel deep model that incorporates the complementary physics priors of wave propagation and volume rendering into a neural network for high-quality and robust NLOS reconstruction. This orchestrated design regularizes the solution space by relaxing the image formation model, resulting in a deep model that generalizes well on real captures despite being exclusively trained on synthetic data. Further, we devise a unified learning framework that enables our model to be flexibly trained using diverse supervision signals, including target intensity images or even raw NLOS transient measurements. Once trained, our model renders both intensity and depth images at inference time in a single forward pass, capable of processing more than 5 captures per second on a high-end GPU. Through extensive qualitative and quantitative experiments, we show that our method outperforms prior physics and learning based approaches on both synthetic and real measurements. We anticipate that our method along with the fast capturing system will accelerate future development of NLOS imaging for real world applications that require high-speed imaging.

</p>
</details>

<details><summary><b>FundusQ-Net: a Regression Quality Assessment Deep Learning Algorithm for Fundus Images Quality Grading</b>
<a href="https://arxiv.org/abs/2205.01676">arxiv:2205.01676</a>
&#x1F4C8; 1 <br>
<p>Or Abramovich, Hadas Pizem, Jan Van Eijgen, Ingeborg Stalmans, Eytan Blumenthal, Joachim A. Behar</p></summary>
<p>

**Abstract:** Objective: Ophthalmological pathologies such as glaucoma, diabetic retinopathy and age-related macular degeneration are major causes of blindness and vision impairment. There is a need for novel decision support tools that can simplify and speed up the diagnosis of these pathologies. A key step in this process is to automatically estimate the quality of the fundus images to make sure these are interpretable by a human operator or a machine learning model. We present a novel fundus image quality scale and deep learning (DL) model that can estimate fundus image quality relative to this new scale.
  Methods: A total of 1,245 images were graded for quality by two ophthalmologists within the range 1-10, with a resolution of 0.5. A DL regression model was trained for fundus image quality assessment. The architecture used was Inception-V3. The model was developed using a total of 89,947 images from 6 databases, of which 1,245 were labeled by the specialists and the remaining 88,702 images were used for pre-training and semi-supervised learning. The final DL model was evaluated on an internal test set (n=209) as well as an external test set (n=194).
  Results: The final DL model, denoted FundusQ-Net, achieved a mean absolute error of 0.61 (0.54-0.68) on the internal test set. When evaluated as a binary classification model on the public DRIMDB database as an external test set the model obtained an accuracy of 99%.
  Significance: the proposed algorithm provides a new robust tool for automated quality grading of fundus images.

</p>
</details>

<details><summary><b>Deep Learning Framework for Real-time Fetal Brain Segmentation in MRI</b>
<a href="https://arxiv.org/abs/2205.01675">arxiv:2205.01675</a>
&#x1F4C8; 1 <br>
<p>Razieh Faghihpirayesh, Davood Karimi, Deniz Erdogmus, Ali Gholipour</p></summary>
<p>

**Abstract:** Fetal brain segmentation is an important first step for slice-level motion correction and slice-to-volume reconstruction in fetal MRI. Fast and accurate segmentation of the fetal brain on fetal MRI is required to achieve real-time fetal head pose estimation and motion tracking for slice re-acquisition and steering. To address this critical unmet need, in this work we analyzed the speed-accuracy performance of a variety of deep neural network models, and devised a symbolically small convolutional neural network that combines spatial details at high resolution with context features extracted at lower resolutions. We used multiple branches with skip connections to maintain high accuracy while devising a parallel combination of convolution and pooling operations as an input downsampling module to further reduce inference time. We trained our model as well as eight alternative, state-of-the-art networks with manually-labeled fetal brain MRI slices and tested on two sets of normal and challenging test cases. Experimental results show that our network achieved the highest accuracy and lowest inference time among all of the compared state-of-the-art real-time segmentation methods. We achieved average Dice scores of 97.99\% and 84.04\% on the normal and challenging test sets, respectively, with an inference time of 3.36 milliseconds per image on an NVIDIA GeForce RTX 2080 Ti. Code, data, and the trained models are available at https://github.com/bchimagine/real_time_fetal_brain_segmentation.

</p>
</details>

<details><summary><b>MIRST-DM: Multi-Instance RST with Drop-Max Layer for Robust Classification of Breast Cancer</b>
<a href="https://arxiv.org/abs/2205.01674">arxiv:2205.01674</a>
&#x1F4C8; 1 <br>
<p>Shoukun Sun, Min Xian, Aleksandar Vakanski, Hossny Ghanem</p></summary>
<p>

**Abstract:** Robust self-training (RST) can augment the adversarial robustness of image classification models without significantly sacrificing models' generalizability. However, RST and other state-of-the-art defense approaches failed to preserve the generalizability and reproduce their good adversarial robustness on small medical image sets. In this work, we propose the Multi-instance RST with a drop-max layer, namely MIRST-DM, which involves a sequence of iteratively generated adversarial instances during training to learn smoother decision boundaries on small datasets. The proposed drop-max layer eliminates unstable features and helps learn representations that are robust to image perturbations. The proposed approach was validated using a small breast ultrasound dataset with 1,190 images. The results demonstrate that the proposed approach achieves state-of-the-art adversarial robustness against three prevalent attacks.

</p>
</details>

<details><summary><b>PSCNN: A 885.86 TOPS/W Programmable SRAM-based Computing-In-Memory Processor for Keyword Spotting</b>
<a href="https://arxiv.org/abs/2205.01569">arxiv:2205.01569</a>
&#x1F4C8; 1 <br>
<p>Shu-Hung Kuo, Tian-Sheuan Chang</p></summary>
<p>

**Abstract:** Computing-in-memory (CIM) has attracted significant attentions in recent years due to its massive parallelism and low power consumption. However, current CIM designs suffer from large area overhead of small CIM macros and bad programmablity for model execution. This paper proposes a programmable CIM processor with a single large sized CIM macro instead of multiple smaller ones for power efficient computation and a flexible instruction set to support various binary 1-D convolution Neural Network (CNN) models in an easy way. Furthermore, the proposed architecture adopts the pooling write-back method to support fused or independent convolution/pooling operations to reduce 35.9\% of latency, and the flexible ping-pong feature SRAM to fit different feature map sizes during layer-by-layer execution.The design fabricated in TSMC 28nm technology achieves 150.8 GOPS throughput and 885.86 TOPS/W power efficiency at 10 MHz when executing our binary keyword spotting model, which has higher power efficiency and flexibility than previous designs.

</p>
</details>

<details><summary><b>Using Constraint Programming and Graph Representation Learning for Generating Interpretable Cloud Security Policies</b>
<a href="https://arxiv.org/abs/2205.01240">arxiv:2205.01240</a>
&#x1F4C8; 1 <br>
<p>Mikhail Kazdagli, Mohit Tiwari, Akshat Kumar</p></summary>
<p>

**Abstract:** Modern software systems rely on mining insights from business sensitive data stored in public clouds. A data breach usually incurs significant (monetary) loss for a commercial organization. Conceptually, cloud security heavily relies on Identity Access Management (IAM) policies that IT admins need to properly configure and periodically update. Security negligence and human errors often lead to misconfiguring IAM policies which may open a backdoor for attackers. To address these challenges, first, we develop a novel framework that encodes generating optimal IAM policies using constraint programming (CP). We identify reducing dark permissions of cloud users as an optimality criterion, which intuitively implies minimizing unnecessary datastore access permissions. Second, to make IAM policies interpretable, we use graph representation learning applied to historical access patterns of users to augment our CP model with similarity constraints: similar users should be grouped together and share common IAM policies. Third, we describe multiple attack models and show that our optimized IAM policies significantly reduce the impact of security attacks using real data from 8 commercial organizations, and synthetic instances.

</p>
</details>

<details><summary><b>A walk through of time series analysis on quantum computers</b>
<a href="https://arxiv.org/abs/2205.00986">arxiv:2205.00986</a>
&#x1F4C8; 1 <br>
<p>Ammar Daskin</p></summary>
<p>

**Abstract:** Because of the rotational components on quantum circuits, some quantum neural networks based on variational circuits can be considered equivalent to the classical Fourier networks. In addition, they can be used to predict Fourier coefficients of continuous functions. Time series data indicates a state of a variable in time. Since some time series data can be also considered as continuous functions, we can expect quantum machine learning models to do do many data analysis tasks successfully on time series data. Therefore, it is important to investigate new quantum logics for temporal data processing and analyze intrinsic relationships of data on quantum computers.
  In this paper, we go through the quantum analogues of classical data preprocessing and forecasting with ARIMA models by using simple quantum operators requiring a few number of quantum gates. Then we discuss future directions and some of the tools/algorithms that can be used for temporal data analysis on quantum computers.

</p>
</details>

<details><summary><b>Fast Continuous and Integer L-shaped Heuristics Through Supervised Learning</b>
<a href="https://arxiv.org/abs/2205.00897">arxiv:2205.00897</a>
&#x1F4C8; 1 <br>
<p>Eric Larsen, Emma Frejinger, Bernard Gendron, Andrea Lodi</p></summary>
<p>

**Abstract:** We propose a methodology at the nexus of operations research and machine learning (ML) leveraging generic approximators available from ML to accelerate the solution of mixed-integer linear two-stage stochastic programs. We aim at solving problems where the second stage is highly demanding. Our core idea is to gain large reductions in online solution time while incurring small reductions in first-stage solution accuracy by substituting the exact second-stage solutions with fast, yet accurate supervised ML predictions. This upfront investment in ML would be justified when similar problems are solved repeatedly over time, for example, in transport planning related to fleet management, routing and container yard management.
  Our numerical results focus on the problem class seminally addressed with the integer and continuous L-shaped cuts. Our extensive empirical analysis is grounded in standardized families of problems derived from stochastic server location (SSLP) and stochastic multi knapsack (SMKP) problems available in the literature. The proposed method can solve the hardest instances of SSLP in less than 9% of the time it takes the state-of-the-art exact method, and in the case of SMKP the same figure is 20%. Average optimality gaps are in most cases less than 0.1%.

</p>
</details>

<details><summary><b>Lightweight Image Enhancement Network for Mobile Devices Using Self-Feature Extraction and Dense Modulation</b>
<a href="https://arxiv.org/abs/2205.00853">arxiv:2205.00853</a>
&#x1F4C8; 1 <br>
<p>Sangwook Baek, Yongsup Park, Youngo Park, Jungmin Lee, Kwangpyo Choi</p></summary>
<p>

**Abstract:** Convolutional neural network (CNN) based image enhancement methods such as super-resolution and detail enhancement have achieved remarkable performances. However, amounts of operations including convolution and parameters within the networks cost high computing power and need huge memory resource, which limits the applications with on-device requirements. Lightweight image enhancement network should restore details, texture, and structural information from low-resolution input images while keeping their fidelity. To address these issues, a lightweight image enhancement network is proposed. The proposed network include self-feature extraction module which produces modulation parameters from low-quality image itself, and provides them to modulate the features in the network. Also, dense modulation block is proposed for unit block of the proposed network, which uses dense connections of concatenated features applied in modulation layers. Experimental results demonstrate better performance over existing approaches in terms of both quantitative and qualitative evaluations.

</p>
</details>

<details><summary><b>Model-based Deep Learning Receiver Design for Rate-Splitting Multiple Access</b>
<a href="https://arxiv.org/abs/2205.00849">arxiv:2205.00849</a>
&#x1F4C8; 1 <br>
<p>Rafael Cerna Loli, Onur Dizdar, Bruno Clerckx, Cong Ling</p></summary>
<p>

**Abstract:** Effective and adaptive interference management is required in next generation wireless communication systems. To address this challenge, Rate-Splitting Multiple Access (RSMA), relying on multi-antenna rate-splitting (RS) at the transmitter and successive interference cancellation (SIC) at the receivers, has been intensively studied in recent years, albeit mostly under the assumption of perfect Channel State Information at the Receiver (CSIR) and ideal capacity-achieving modulation and coding schemes. To assess its practical performance, benefits, and limits under more realistic conditions, this work proposes a novel design for a practical RSMA receiver based on model-based deep learning (MBDL) methods, which aims to unite the simple structure of the conventional SIC receiver and the robustness and model agnosticism of deep learning techniques. The MBDL receiver is evaluated in terms of uncoded Symbol Error Rate (SER), throughput performance through Link-Level Simulations (LLS), and average training overhead. Also, a comparison with the SIC receiver, with perfect and imperfect CSIR, is given. Results reveal that the MBDL outperforms by a significant margin the SIC receiver with imperfect CSIR, due to its ability to generate on demand non-linear symbol detection boundaries in a pure data-driven manner.

</p>
</details>

<details><summary><b>Gradient Descent, Stochastic Optimization, and Other Tales</b>
<a href="https://arxiv.org/abs/2205.00832">arxiv:2205.00832</a>
&#x1F4C8; 1 <br>
<p>Jun Lu</p></summary>
<p>

**Abstract:** The goal of this paper is to debunk and dispel the magic behind black-box optimizers and stochastic optimizers. It aims to build a solid foundation on how and why the techniques work. This manuscript crystallizes this knowledge by deriving from simple intuitions, the mathematics behind the strategies. This tutorial doesn't shy away from addressing both the formal and informal aspects of gradient descent and stochastic optimization methods. By doing so, it hopes to provide readers with a deeper understanding of these techniques as well as the when, the how and the why of applying these algorithms.
  Gradient descent is one of the most popular algorithms to perform optimization and by far the most common way to optimize machine learning tasks. Its stochastic version receives attention in recent years, and this is particularly true for optimizing deep neural networks. In deep neural networks, the gradient followed by a single sample or a batch of samples is employed to save computational resources and escape from saddle points. In 1951, Robbins and Monro published \textit{A stochastic approximation method}, one of the first modern treatments on stochastic optimization that estimates local gradients with a new batch of samples. And now, stochastic optimization has become a core technology in machine learning, largely due to the development of the back propagation algorithm in fitting a neural network. The sole aim of this article is to give a self-contained introduction to concepts and mathematical tools in gradient descent and stochastic optimization.

</p>
</details>

<details><summary><b>A Novel Approach to Fairness in Automated Decision-Making using Affective Normalization</b>
<a href="https://arxiv.org/abs/2205.00819">arxiv:2205.00819</a>
&#x1F4C8; 1 <br>
<p>Jesse Hoey, Gabrielle Chan</p></summary>
<p>

**Abstract:** Any decision, such as one about who to hire, involves two components. First, a rational component, i.e., they have a good education, they speak clearly. Second, an affective component, based on observables such as visual features of race and gender, and possibly biased by stereotypes. Here we propose a method for measuring the affective, socially biased, component, thus enabling its removal. That is, given a decision-making process, these affective measurements remove the affective bias in the decision, rendering it fair across a set of categories defined by the method itself. We thus propose that this may solve three key problems in intersectional fairness: (1) the definition of categories over which fairness is a consideration; (2) an infinite regress into smaller and smaller groups; and (3) ensuring a fair distribution based on basic human rights or other prior information. The primary idea in this paper is that fairness biases can be measured using affective coherence, and that this can be used to normalize outcome mappings. We aim for this conceptual work to expose a novel method for handling fairness problems that uses emotional coherence as an independent measure of bias that goes beyond statistical parity.

</p>
</details>

<details><summary><b>On verifying expectations and observations of intelligent agents</b>
<a href="https://arxiv.org/abs/2205.00784">arxiv:2205.00784</a>
&#x1F4C8; 1 <br>
<p>Sourav Chakraborty, Avijeet Ghosh, Sujata Ghosh, François Schwarzentruber</p></summary>
<p>

**Abstract:** Public observation logic (POL) is a variant of dynamic epistemic logic to reason about agent expectations and agent observations. Agents have certain expectations, regarding the situation at hand, that are actuated by the relevant protocols, and they eliminate possible worlds in which their expectations do not match with their observations. In this work, we investigate the computational complexity of the model checking problem for POL and prove its PSPACE-completeness. We also study various syntactic fragments of POL. We exemplify the applicability of POL model checking in verifying different characteristics and features of an interactive system with respect to the distinct expectations and (matching) observations of the system. Finally, we provide a discussion on the implementation of the model checking algorithms.

</p>
</details>

<details><summary><b>A Real Time 1280x720 Object Detection Chip With 585MB/s Memory Traffic</b>
<a href="https://arxiv.org/abs/2205.01571">arxiv:2205.01571</a>
&#x1F4C8; 0 <br>
<p>Kuo-Wei Chang, Hsu-Tung Shih, Tian-Sheuan Chang, Shang-Hong Tsai, Chih-Chyau Yang, Chien-Ming Wu, Chun-Ming Huang</p></summary>
<p>

**Abstract:** Memory bandwidth has become the real-time bottleneck of current deep learning accelerators (DLA), particularly for high definition (HD) object detection. Under resource constraints, this paper proposes a low memory traffic DLA chip with joint hardware and software optimization. To maximize hardware utilization under memory bandwidth, we morph and fuse the object detection model into a group fusion-ready model to reduce intermediate data access. This reduces the YOLOv2's feature memory traffic from 2.9 GB/s to 0.15 GB/s. To support group fusion, our previous DLA based hardware employes a unified buffer with write-masking for simple layer-by-layer processing in a fusion group. When compared to our previous DLA with the same PE numbers, the chip implemented in a TSMC 40nm process supports 1280x720@30FPS object detection and consumes 7.9X less external DRAM access energy, from 2607 mJ to 327.6 mJ.

</p>
</details>

<details><summary><b>A Survey of Deep Learning Models for Structural Code Understanding</b>
<a href="https://arxiv.org/abs/2205.01293">arxiv:2205.01293</a>
&#x1F4C8; 0 <br>
<p>Ruoting Wu, Yuxin Zhang, Qibiao Peng, Liang Chen, Zibin Zheng</p></summary>
<p>

**Abstract:** In recent years, the rise of deep learning and automation requirements in the software industry has elevated Intelligent Software Engineering to new heights. The number of approaches and applications in code understanding is growing, with deep learning techniques being used in many of them to better capture the information in code data. In this survey, we present a comprehensive overview of the structures formed from code data. We categorize the models for understanding code in recent years into two groups: sequence-based and graph-based models, further make a summary and comparison of them. We also introduce metrics, datasets and the downstream tasks. Finally, we make some suggestions for future research in structural code understanding field.

</p>
</details>

<details><summary><b>From {Solution Synthesis} to {Student Attempt Synthesis} for Block-Based Visual Programming Tasks</b>
<a href="https://arxiv.org/abs/2205.01265">arxiv:2205.01265</a>
&#x1F4C8; 0 <br>
<p>Adish Singla, Nikitas Theodoropoulos</p></summary>
<p>

**Abstract:** Block-based visual programming environments are increasingly used to introduce computing concepts to beginners. Given that programming tasks are open-ended and conceptual, novice students often struggle when learning in these environments. AI-driven programming tutors hold great promise in automatically assisting struggling students, and need several components to realize this potential. We investigate the crucial component of student modeling, in particular, the ability to automatically infer students' misconceptions for predicting (synthesizing) their behavior. We introduce a novel benchmark, StudentSyn, centered around the following challenge: For a given student, synthesize the student's attempt on a new target task after observing the student's attempt on a fixed reference task. This challenge is akin to that of program synthesis; however, instead of synthesizing a {solution} (i.e., program an expert would write), the goal here is to synthesize a {student attempt} (i.e., program that a given student would write). We first show that human experts (TutorSS) can achieve high performance on the benchmark, whereas simple baselines perform poorly. Then, we develop two neuro/symbolic techniques (NeurSS and SymSS) in a quest to close this gap with TutorSS. We will publicly release the benchmark to facilitate future research in this area.

</p>
</details>


{% endraw %}
Prev: [2022.05.01]({{ '/2022/05/01/2022.05.01.html' | relative_url }})  Next: [2022.05.03]({{ '/2022/05/03/2022.05.03.html' | relative_url }})