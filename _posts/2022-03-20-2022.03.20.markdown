Prev: [2022.03.19]({{ '/2022/03/19/2022.03.19.html' | relative_url }})  Next: [2022.03.21]({{ '/2022/03/21/2022.03.21.html' | relative_url }})
{% raw %}
## Summary for 2022-03-20, created on 2022-03-30


<details><summary><b>Inferring Articulated Rigid Body Dynamics from RGBD Video</b>
<a href="https://arxiv.org/abs/2203.10488">arxiv:2203.10488</a>
&#x1F4C8; 9 <br>
<p>Eric Heiden, Ziang Liu, Vibhav Vineet, Erwin Coumans, Gaurav S. Sukhatme</p></summary>
<p>

**Abstract:** Being able to reproduce physical phenomena ranging from light interaction to contact mechanics, simulators are becoming increasingly useful in more and more application domains where real-world interaction or labeled data are difficult to obtain. Despite recent progress, significant human effort is needed to configure simulators to accurately reproduce real-world behavior. We introduce a pipeline that combines inverse rendering with differentiable simulation to create digital twins of real-world articulated mechanisms from depth or RGB videos. Our approach automatically discovers joint types and estimates their kinematic parameters, while the dynamic properties of the overall mechanism are tuned to attain physically accurate simulations. Control policies optimized in our derived simulation transfer successfully back to the original system, as we demonstrate on a simulated system. Further, our approach accurately reconstructs the kinematic tree of an articulated mechanism being manipulated by a robot, and highly nonlinear dynamics of a real-world coupled pendulum mechanism.
  Website: https://eric-heiden.github.io/video2sim

</p>
</details>

<details><summary><b>Inspection-L: Practical GNN-Based Money Laundering Detection System for Bitcoin</b>
<a href="https://arxiv.org/abs/2203.10465">arxiv:2203.10465</a>
&#x1F4C8; 8 <br>
<p>Wai Weng Lo, Siamak Layeghy, Marius Portmann</p></summary>
<p>

**Abstract:** Criminals have become increasingly experienced in using cryptocurrencies, such as Bitcoin, for money laundering. The use of cryptocurrencies can hide criminal identities and transfer hundreds of millions of dollars of dirty funds through their criminal digital wallets. However, this is considered a paradox because cryptocurrencies are gold mines for open-source intelligence, allowing law enforcement agencies to have more power in conducting forensic analyses. This paper proposed Inspection-L, a graph neural network (GNN) framework based on self-supervised Deep Graph Infomax (DGI), with Random Forest (RF), to detect illicit transactions for Anti-Money laundering (AML). To the best of our knowledge, our proposal is the first of applying self-supervised GNNs to the problem of AML in Bitcoin. The proposed method has been evaluated on the Elliptic dataset and shows that our approach outperforms the state-of-the-art in terms of key classification metrics, which demonstrates the potential of self-supervised GNN in cryptocurrency illicit transaction detection.

</p>
</details>

<details><summary><b>Leveraging Expert Guided Adversarial Augmentation For Improving Generalization in Named Entity Recognition</b>
<a href="https://arxiv.org/abs/2203.10693">arxiv:2203.10693</a>
&#x1F4C8; 7 <br>
<p>Aaron Reich, Jiaao Chen, Aastha Agrawal, Yanzhe Zhang, Diyi Yang</p></summary>
<p>

**Abstract:** Named Entity Recognition (NER) systems often demonstrate great performance on in-distribution data, but perform poorly on examples drawn from a shifted distribution. One way to evaluate the generalization ability of NER models is to use adversarial examples, on which the specific variations associated with named entities are rarely considered. To this end, we propose leveraging expert-guided heuristics to change the entity tokens and their surrounding contexts thereby altering their entity types as adversarial attacks. Using expert-guided heuristics, we augmented the CoNLL 2003 test set and manually annotated it to construct a high-quality challenging set. We found that state-of-the-art NER systems trained on CoNLL 2003 training data drop performance dramatically on our challenging set. By training on adversarial augmented training examples and using mixup for regularization, we were able to significantly improve the performance on the challenging set as well as improve out-of-domain generalization which we evaluated by using OntoNotes data. We have publicly released our dataset and code at https://github.com/GT-SALT/Guided-Adversarial-Augmentation.

</p>
</details>

<details><summary><b>Accelerating Integrated Task and Motion Planning with Neural Feasibility Checking</b>
<a href="https://arxiv.org/abs/2203.10568">arxiv:2203.10568</a>
&#x1F4C8; 7 <br>
<p>Lei Xu, Tianyu Ren, Georgia Chalvatzaki, Jan Peters</p></summary>
<p>

**Abstract:** As robots play an increasingly important role in the industrial, the expectations about their applications for everyday living tasks are getting higher. Robots need to perform long-horizon tasks that consist of several sub-tasks that need to be accomplished. Task and Motion Planning (TAMP) provides a hierarchical framework to handle the sequential nature of manipulation tasks by interleaving a symbolic task planner that generates a possible action sequence, with a motion planner that checks the kinematic feasibility in the geometric world, generating robot trajectories if several constraints are satisfied, e.g., a collision-free trajectory from one state to another. Hence, the reasoning about the task plan's geometric grounding is taken over by the motion planner. However, motion planning is computationally intense and is usability as feasibility checker casts TAMP methods inapplicable to real-world scenarios. In this paper, we introduce neural feasibility classifier (NFC), a simple yet effective visual heuristic for classifying the feasibility of proposed actions in TAMP. Namely, NFC will identify infeasible actions of the task planner without the need for costly motion planning, hence reducing planning time in multi-step manipulation tasks. NFC encodes the image of the robot's workspace into a feature map thanks to convolutional neural network (CNN). We train NFC using simulated data from TAMP problems and label the instances based on IK feasibility checking. Our empirical results in different simulated manipulation tasks show that our NFC generalizes to the entire robot workspace and has high prediction accuracy even in scenes with multiple obstructions. When combined with state-of-the-art integrated TAMP, our NFC enhances its performance while reducing its planning time.

</p>
</details>

<details><summary><b>Small Batch Sizes Improve Training of Low-Resource Neural MT</b>
<a href="https://arxiv.org/abs/2203.10579">arxiv:2203.10579</a>
&#x1F4C8; 6 <br>
<p>Àlex R. Atrio, Andrei Popescu-Belis</p></summary>
<p>

**Abstract:** We study the role of an essential hyper-parameter that governs the training of Transformers for neural machine translation in a low-resource setting: the batch size. Using theoretical insights and experimental evidence, we argue against the widespread belief that batch size should be set as large as allowed by the memory of the GPUs. We show that in a low-resource setting, a smaller batch size leads to higher scores in a shorter training time, and argue that this is due to better regularization of the gradients during training.

</p>
</details>

<details><summary><b>Towards Clinical Practice: Design and Implementation of Convolutional Neural Network-Based Assistive Diagnosis System for COVID-19 Case Detection from Chest X-Ray Images</b>
<a href="https://arxiv.org/abs/2203.10596">arxiv:2203.10596</a>
&#x1F4C8; 5 <br>
<p>Daniel Kvak, Marian Bendik, Anna Chromcova</p></summary>
<p>

**Abstract:** One of the critical tools for early detection and subsequent evaluation of the incidence of lung diseases is chest radiography. This study presents a real-world implementation of a convolutional neural network (CNN) based Carebot Covid app to detect COVID-19 from chest X-ray (CXR) images. Our proposed model takes the form of a simple and intuitive application. Used CNN can be deployed as a STOW-RS prediction endpoint for direct implementation into DICOM viewers. The results of this study show that the deep learning model based on DenseNet and ResNet architecture can detect SARS-CoV-2 from CXR images with precision of 0.981, recall of 0.962 and AP of 0.993.

</p>
</details>

<details><summary><b>Soft-CP: A Credible and Effective Data Augmentation for Semantic Segmentation of Medical Lesions</b>
<a href="https://arxiv.org/abs/2203.10507">arxiv:2203.10507</a>
&#x1F4C8; 5 <br>
<p>Pingping Dai, Licong Dong, Ruihan Zhang, Haiming Zhu, Jie Wu, Kehong Yuan</p></summary>
<p>

**Abstract:** The medical datasets are usually faced with the problem of scarcity and data imbalance. Moreover, annotating large datasets for semantic segmentation of medical lesions is domain-knowledge and time-consuming. In this paper, we propose a new object-blend method(short in soft-CP) that combines the Copy-Paste augmentation method for semantic segmentation of medical lesions offline, ensuring the correct edge information around the lession to solve the issue above-mentioned. We proved the method's validity with several datasets in different imaging modalities. In our experiments on the KiTS19[2] dataset, Soft-CP outperforms existing medical lesions synthesis approaches. The Soft-CP augementation provides gains of +26.5% DSC in the low data regime(10% of data) and +10.2% DSC in the high data regime(all of data), In offline training data, the ratio of real images to synthetic images is 3:1.

</p>
</details>

<details><summary><b>Hierarchical Inductive Transfer for Continual Dialogue Learning</b>
<a href="https://arxiv.org/abs/2203.10484">arxiv:2203.10484</a>
&#x1F4C8; 5 <br>
<p>Shaoxiong Feng, Xuancheng Ren, Kan Li, Xu Sun</p></summary>
<p>

**Abstract:** Pre-trained models have achieved excellent performance on the dialogue task. However, for the continual increase of online chit-chat scenarios, directly fine-tuning these models for each of the new tasks not only explodes the capacity of the dialogue system on the embedded devices but also causes knowledge forgetting on pre-trained models and knowledge interference among diverse dialogue tasks. In this work, we propose a hierarchical inductive transfer framework to learn and deploy the dialogue skills continually and efficiently. First, we introduce the adapter module into pre-trained models for learning new dialogue tasks. As the only trainable module, it is beneficial for the dialogue system on the embedded devices to acquire new dialogue skills with negligible additional parameters. Then, for alleviating knowledge interference between tasks yet benefiting the regularization between them, we further design hierarchical inductive transfer that enables new tasks to use general knowledge in the base adapter without being misled by diverse knowledge in task-specific adapters. Empirical evaluation and analysis indicate that our framework obtains comparable performance under deployment-friendly model capacity.

</p>
</details>

<details><summary><b>FaceMap: Towards Unsupervised Face Clustering via Map Equation</b>
<a href="https://arxiv.org/abs/2203.10090">arxiv:2203.10090</a>
&#x1F4C8; 5 <br>
<p>Xiaotian Yu, Yifan Yang, Aibo Wang, Ling Xing, Hanling Yi, Guangming Lu, Xiaoyu Wang</p></summary>
<p>

**Abstract:** Face clustering is an essential task in computer vision due to the explosion of related applications such as augmented reality or photo album management. The main challenge of this task lies in the imperfectness of similarities among image feature representations. Given an existing feature extraction model, it is still an unresolved problem that how can the inherent characteristics of similarities of unlabelled images be leveraged to improve the clustering performance. Motivated by answering the question, we develop an effective unsupervised method, named as FaceMap, by formulating face clustering as a process of non-overlapping community detection, and minimizing the entropy of information flows on a network of images. The entropy is denoted by the map equation and its minimum represents the least description of paths among images in expectation. Inspired by observations on the ranked transition probabilities in the affinity graph constructed from facial images, we develop an outlier detection strategy to adaptively adjust transition probabilities among images. Experiments with ablation studies demonstrate that FaceMap significantly outperforms existing methods and achieves new state-of-the-arts on three popular large-scale datasets for face clustering, e.g., an absolute improvement of more than $10\%$ and $4\%$ comparing with prior unsupervised and supervised methods respectively in terms of average of Pairwise F-score. Our code is publicly available on github.

</p>
</details>

<details><summary><b>VinDr-Mammo: A large-scale benchmark dataset for computer-aided diagnosis in full-field digital mammography</b>
<a href="https://arxiv.org/abs/2203.11205">arxiv:2203.11205</a>
&#x1F4C8; 4 <br>
<p>Hieu T. Nguyen, Ha Q. Nguyen, Hieu H. Pham, Khanh Lam, Linh T. Le, Minh Dao, Van Vu</p></summary>
<p>

**Abstract:** Mammography, or breast X-ray, is the most widely used imaging modality to detect cancer and other breast diseases. Recent studies have shown that deep learning-based computer-assisted detection and diagnosis (CADe or CADx) tools have been developed to support physicians and improve the accuracy of interpreting mammography. However, most published datasets of mammography are either limited on sample size or digitalized from screen-film mammography (SFM), hindering the development of CADe and CADx tools which are developed based on full-field digital mammography (FFDM). To overcome this challenge, we introduce VinDr-Mammo - a new benchmark dataset of FFDM for detecting and diagnosing breast cancer and other diseases in mammography. The dataset consists of 5,000 mammography exams, each of which has four standard views and is double read with disagreement (if any) being resolved by arbitration. It is created for the assessment of Breast Imaging Reporting and Data System (BI-RADS) and density at the breast level. In addition, the dataset also provides the category, location, and BI-RADS assessment of non-benign findings. We make VinDr-Mammo publicly available on PhysioNet as a new imaging resource to promote advances in developing CADe and CADx tools for breast cancer screening.

</p>
</details>

<details><summary><b>CNN Attention Guidance for Improved Orthopedics Radiographic Fracture Classification</b>
<a href="https://arxiv.org/abs/2203.10690">arxiv:2203.10690</a>
&#x1F4C8; 4 <br>
<p>Zhibin Liao, Kewen Liao, Haifeng Shen, Marouska F. van Boxel, Jasper Prijs, Ruurd L. Jaarsma, Job N. Doornberg, Anton van den Hengel, Johan W. Verjans</p></summary>
<p>

**Abstract:** Convolutional neural networks (CNNs) have gained significant popularity in orthopedic imaging in recent years due to their ability to solve fracture classification problems. A common criticism of CNNs is their opaque learning and reasoning process, making it difficult to trust machine diagnosis and the subsequent adoption of such algorithms in clinical setting. This is especially true when the CNN is trained with limited amount of medical data, which is a common issue as curating sufficiently large amount of annotated medical imaging data is a long and costly process. While interest has been devoted to explaining CNN learnt knowledge by visualizing network attention, the utilization of the visualized attention to improve network learning has been rarely investigated. This paper explores the effectiveness of regularizing CNN network with human-provided attention guidance on where in the image the network should look for answering clues. On two orthopedics radiographic fracture classification datasets, through extensive experiments we demonstrate that explicit human-guided attention indeed can direct correct network attention and consequently significantly improve classification performance. The development code for the proposed attention guidance is publicly available on GitHub.

</p>
</details>

<details><summary><b>Learning latent causal relationships in multiple time series</b>
<a href="https://arxiv.org/abs/2203.10679">arxiv:2203.10679</a>
&#x1F4C8; 4 <br>
<p>Jacek P. Dmochowski</p></summary>
<p>

**Abstract:** Identifying the causal structure of systems with multiple dynamic elements is critical to several scientific disciplines. The conventional approach is to conduct statistical tests of causality, for example with Granger Causality, between observed signals that are selected a priori. Here it is posited that, in many systems, the causal relations are embedded in a latent space that is expressed in the observed data as a linear mixture. A technique for blindly identifying the latent sources is presented: the observations are projected into pairs of components -- driving and driven -- to maximize the strength of causality between the pairs. This leads to an optimization problem with closed form expressions for the objective function and gradient that can be solved with off-the-shelf techniques. After demonstrating proof-of-concept on synthetic data with known latent structure, the technique is applied to recordings from the human brain and historical cryptocurrency prices. In both cases, the approach recovers multiple strong causal relationships that are not evident in the observed data. The proposed technique is unsupervised and can be readily applied to any multiple time series to shed light on the causal relationships underlying the data.

</p>
</details>

<details><summary><b>Geometric Methods for Sampling, Optimisation, Inference and Adaptive Agents</b>
<a href="https://arxiv.org/abs/2203.10592">arxiv:2203.10592</a>
&#x1F4C8; 4 <br>
<p>Alessandro Barp, Lancelot Da Costa, Guilherme França, Karl Friston, Mark Girolami, Michael I. Jordan, Grigorios A. Pavliotis</p></summary>
<p>

**Abstract:** In this chapter, we identify fundamental geometric structures that underlie the problems of sampling, optimisation, inference and adaptive decision-making. Based on this identification, we derive algorithms that exploit these geometric structures to solve these problems efficiently. We show that a wide range of geometric theories emerge naturally in these fields, ranging from measure-preserving processes, information divergences, Poisson geometry, and geometric integration. Specifically, we explain how \emph{(i)} leveraging the symplectic geometry of Hamiltonian systems enable us to construct (accelerated) sampling and optimisation methods, \emph{(ii)} the theory of Hilbertian subspaces and Stein operators provides a general methodology to obtain robust estimators, \emph{(iii)} preserving the information geometry of decision-making yields adaptive agents that perform active inference. Throughout, we emphasise the rich connections between these fields; e.g., inference draws on sampling and optimisation, and adaptive decision-making assesses decisions by inferring their counterfactual consequences. Our exposition provides a conceptual overview of underlying ideas, rather than a technical discussion, which can be found in the references herein.

</p>
</details>

<details><summary><b>Cluster & Tune: Boost Cold Start Performance in Text Classification</b>
<a href="https://arxiv.org/abs/2203.10581">arxiv:2203.10581</a>
&#x1F4C8; 4 <br>
<p>Eyal Shnarch, Ariel Gera, Alon Halfon, Lena Dankin, Leshem Choshen, Ranit Aharonov, Noam Slonim</p></summary>
<p>

**Abstract:** In real-world scenarios, a text classification task often begins with a cold start, when labeled data is scarce. In such cases, the common practice of fine-tuning pre-trained models, such as BERT, for a target classification task, is prone to produce poor performance. We suggest a method to boost the performance of such models by adding an intermediate unsupervised classification task, between the pre-training and fine-tuning phases. As such an intermediate task, we perform clustering and train the pre-trained model on predicting the cluster labels. We test this hypothesis on various data sets, and show that this additional classification phase can significantly improve performance, mainly for topical classification tasks, when the number of labeled instances available for fine-tuning is only a couple of dozen to a few hundred.

</p>
</details>

<details><summary><b>Multi-view Multi-behavior Contrastive Learning in Recommendation</b>
<a href="https://arxiv.org/abs/2203.10576">arxiv:2203.10576</a>
&#x1F4C8; 4 <br>
<p>Yiqing Wu, Ruobing Xie, Yongchun Zhu, Xiang Ao, Xin Chen, Xu Zhang, Fuzhen Zhuang, Leyu Lin, Qing He</p></summary>
<p>

**Abstract:** Multi-behavior recommendation (MBR) aims to jointly consider multiple behaviors to improve the target behavior's performance. We argue that MBR models should: (1) model the coarse-grained commonalities between different behaviors of a user, (2) consider both individual sequence view and global graph view in multi-behavior modeling, and (3) capture the fine-grained differences between multiple behaviors of a user. In this work, we propose a novel Multi-behavior Multi-view Contrastive Learning Recommendation (MMCLR) framework, including three new CL tasks to solve the above challenges, respectively. The multi-behavior CL aims to make different user single-behavior representations of the same user in each view to be similar. The multi-view CL attempts to bridge the gap between a user's sequence-view and graph-view representations. The behavior distinction CL focuses on modeling fine-grained differences of different behaviors. In experiments, we conduct extensive evaluations and ablation tests to verify the effectiveness of MMCLR and various CL tasks on two real-world datasets, achieving SOTA performance over existing baselines. Our code will be available on \url{https://github.com/wyqing20/MMCLR}

</p>
</details>

<details><summary><b>Stochastic Video Prediction with Structure and Motion</b>
<a href="https://arxiv.org/abs/2203.10528">arxiv:2203.10528</a>
&#x1F4C8; 4 <br>
<p>Adil Kaan Akan, Sadra Safadoust, Erkut Erdem, Aykut Erdem, Fatma Güney</p></summary>
<p>

**Abstract:** While stochastic video prediction models enable future prediction under uncertainty, they mostly fail to model the complex dynamics of real-world scenes. For example, they cannot provide reliable predictions for scenes with a moving camera and independently moving foreground objects in driving scenarios. The existing methods fail to fully capture the dynamics of the structured world by only focusing on changes in pixels. In this paper, we assume that there is an underlying process creating observations in a video and propose to factorize it into static and dynamic components. We model the static part based on the scene structure and the ego-motion of the vehicle, and the dynamic part based on the remaining motion of the dynamic objects. By learning separate distributions of changes in foreground and background, we can decompose the scene into static and dynamic parts and separately model the change in each. Our experiments demonstrate that disentangling structure and motion helps stochastic video prediction, leading to better future predictions in complex driving scenarios on two real-world driving datasets, KITTI and Cityscapes.

</p>
</details>

<details><summary><b>Federated Spatial Reuse Optimization in Next-Generation Decentralized IEEE 802.11 WLANs</b>
<a href="https://arxiv.org/abs/2203.10472">arxiv:2203.10472</a>
&#x1F4C8; 4 <br>
<p>Francesc Wilhelmi, Jernej Hribar, Selim F. Yilmaz, Emre Ozfatura, Kerem Ozfatura, Ozlem Yildiz, Deniz Gündüz, Hao Chen, Xiaoying Ye, Lizhao You, Yulin Shao, Paolo Dini, Boris Bellalta</p></summary>
<p>

**Abstract:** As wireless standards evolve, more complex functionalities are introduced to address the increasing requirements in terms of throughput, latency, security, and efficiency. To unleash the potential of such new features, artificial intelligence (AI) and machine learning (ML) are currently being exploited for deriving models and protocols from data, rather than by hand-programming. In this paper, we explore the feasibility of applying ML in next-generation wireless local area networks (WLANs). More specifically, we focus on the IEEE 802.11ax spatial reuse (SR) problem and predict its performance through federated learning (FL) models. The set of FL solutions overviewed in this work is part of the 2021 International Telecommunication Union (ITU) AI for 5G Challenge.

</p>
</details>

<details><summary><b>Explainable Misinformation Detection Across Multiple Social Media Platforms</b>
<a href="https://arxiv.org/abs/2203.11724">arxiv:2203.11724</a>
&#x1F4C8; 3 <br>
<p>Rahee Walambe, Ananya Srivastava, Bhargav Yagnik, Mohammed Hasan, Zainuddin Saiyed, Gargi Joshi, Ketan Kotecha</p></summary>
<p>

**Abstract:** In this work, the integration of two machine learning approaches, namely domain adaptation and explainable AI, is proposed to address these two issues of generalized detection and explainability. Firstly the Domain Adversarial Neural Network (DANN) develops a generalized misinformation detector across multiple social media platforms DANN is employed to generate the classification results for test domains with relevant but unseen data. The DANN-based model, a traditional black-box model, cannot justify its outcome, i.e., the labels for the target domain. Hence a Local Interpretable Model-Agnostic Explanations (LIME) explainable AI model is applied to explain the outcome of the DANN mode. To demonstrate these two approaches and their integration for effective explainable generalized detection, COVID-19 misinformation is considered a case study. We experimented with two datasets, namely CoAID and MiSoVac, and compared results with and without DANN implementation. DANN significantly improves the accuracy measure F1 classification score and increases the accuracy and AUC performance. The results obtained show that the proposed framework performs well in the case of domain shift and can learn domain-invariant features while explaining the target labels with LIME implementation enabling trustworthy information processing and extraction to combat misinformation effectively.

</p>
</details>

<details><summary><b>Semantic Segmentation with Active Semi-Supervised Learning</b>
<a href="https://arxiv.org/abs/2203.10730">arxiv:2203.10730</a>
&#x1F4C8; 3 <br>
<p>Aneesh Rangnekar, Christopher Kanan, Matthew Hoffman</p></summary>
<p>

**Abstract:** Using deep learning, we now have the ability to create exceptionally good semantic segmentation systems; however, collecting the prerequisite pixel-wise annotations for training images remains expensive and time-consuming. Therefore, it would be ideal to minimize the number of human annotations needed when creating a new dataset. Here, we address this problem by proposing a novel algorithm that combines active learning and semi-supervised learning. Active learning is an approach for identifying the best unlabeled samples to annotate. While there has been work on active learning for segmentation, most methods require annotating all pixel objects in each image, rather than only the most informative regions. We argue that this is inefficient. Instead, our active learning approach aims to minimize the number of annotations per-image. Our method is enriched with semi-supervised learning, where we use pseudo labels generated with a teacher-student framework to identify image regions that help disambiguate confused classes. We also integrate mechanisms that enable better performance on imbalanced label distributions, which have not been studied previously for active learning in semantic segmentation. In experiments on the CamVid and CityScapes datasets, our method obtains over 95% of the network's performance on the full-training set using less than 19% of the training data, whereas the previous state of the art required 40% of the training data.

</p>
</details>

<details><summary><b>TransFusion: Multi-view Divergent Fusion for Medical Image Segmentation with Transformers</b>
<a href="https://arxiv.org/abs/2203.10726">arxiv:2203.10726</a>
&#x1F4C8; 3 <br>
<p>Di Liu, Yunhe Gao, Qilong Zhangli, Zhennan Yan, Mu Zhou, Dimitris Metaxas</p></summary>
<p>

**Abstract:** Combining information from multi-view images is crucial to improve the performance and robustness of automated methods for disease diagnosis. However, due to the non-alignment characteristics of multi-view images, building correlation and data fusion across views largely remain an open problem. In this study, we present TransFusion, a Transformer-based architecture to merge divergent multi-view imaging information using convolutional layers and powerful attention mechanisms. In particular, the Divergent Fusion Attention (DiFA) module is proposed for rich cross-view context modeling and semantic dependency mining, addressing the critical issue of capturing long-range correlations between unaligned data from different image views. We further propose the Multi-Scale Attention (MSA) to collect global correspondence of multi-scale feature representations. We evaluate TransFusion on the Multi-Disease, Multi-View \& Multi-Center Right Ventricular Segmentation in Cardiac MRI (M\&Ms-2) challenge cohort. TransFusion demonstrates leading performance against the state-of-the-art methods and opens up new perspectives for multi-view imaging integration towards robust medical image segmentation.

</p>
</details>

<details><summary><b>An Intermediate-level Attack Framework on The Basis of Linear Regression</b>
<a href="https://arxiv.org/abs/2203.10723">arxiv:2203.10723</a>
&#x1F4C8; 3 <br>
<p>Yiwen Guo, Qizhang Li, Wangmeng Zuo, Hao Chen</p></summary>
<p>

**Abstract:** This paper substantially extends our work published at ECCV, in which an intermediate-level attack was proposed to improve the transferability of some baseline adversarial examples. We advocate to establish a direct linear mapping from the intermediate-level discrepancies (between adversarial features and benign features) to classification prediction loss of the adversarial example. In this paper, we delve deep into the core components of such a framework by performing comprehensive studies and extensive experiments. We show that 1) a variety of linear regression models can all be considered in order to establish the mapping, 2) the magnitude of the finally obtained intermediate-level discrepancy is linearly correlated with adversarial transferability, 3) further boost of the performance can be achieved by performing multiple runs of the baseline attack with random initialization. By leveraging these findings, we achieve new state-of-the-arts on transfer-based $\ell_\infty$ and $\ell_2$ attacks.

</p>
</details>

<details><summary><b>LocATe: End-to-end Localization of Actions in 3D with Transformers</b>
<a href="https://arxiv.org/abs/2203.10719">arxiv:2203.10719</a>
&#x1F4C8; 3 <br>
<p>Jiankai Sun, Bolei Zhou, Michael J. Black, Arjun Chandrasekaran</p></summary>
<p>

**Abstract:** Understanding a person's behavior from their 3D motion is a fundamental problem in computer vision with many applications. An important component of this problem is 3D Temporal Action Localization (3D-TAL), which involves recognizing what actions a person is performing, and when. State-of-the-art 3D-TAL methods employ a two-stage approach in which the action span detection task and the action recognition task are implemented as a cascade. This approach, however, limits the possibility of error-correction. In contrast, we propose LocATe, an end-to-end approach that jointly localizes and recognizes actions in a 3D sequence. Further, unlike existing autoregressive models that focus on modeling the local context in a sequence, LocATe's transformer model is capable of capturing long-term correlations between actions in a sequence. Unlike transformer-based object-detection and classification models which consider image or patch features as input, the input in 3D-TAL is a long sequence of highly correlated frames. To handle the high-dimensional input, we implement an effective input representation, and overcome the diffuse attention across long time horizons by introducing sparse attention in the model. LocATe outperforms previous approaches on the existing PKU-MMD 3D-TAL benchmark (mAP=93.2%). Finally, we argue that benchmark datasets are most useful where there is clear room for performance improvement. To that end, we introduce a new, challenging, and more realistic benchmark dataset, BABEL-TAL-20 (BT20), where the performance of state-of-the-art methods is significantly worse. The dataset and code for the method will be available for research purposes.

</p>
</details>

<details><summary><b>Monocular Vision-based Prediction of Cut-in Maneuvers with LSTM Networks</b>
<a href="https://arxiv.org/abs/2203.10707">arxiv:2203.10707</a>
&#x1F4C8; 3 <br>
<p>Yagiz Nalcakan, Yalin Bastanlar</p></summary>
<p>

**Abstract:** Advanced driver assistance and automated driving systems should be capable of predicting and avoiding dangerous situations. This study proposes a method to predict potentially dangerous cut-in maneuvers happening in the ego lane. We follow a computer vision-based approach that only employs a single in-vehicle RGB camera, and we classify the target vehicle's maneuver based on the recent video frames. Our algorithm consists of a CNN-based vehicle detection and tracking step and an LSTM-based maneuver classification step. It is more computationally efficient than other vision-based methods since it exploits a small number of features for the classification step rather than feeding CNNs with RGB frames. We evaluated our approach on a publicly available driving dataset and a lane change detection dataset. We obtained 0.9585 accuracy with side-aware two-class (cut-in vs. lane-pass) classification models. Experiment results also reveal that our approach outperforms state-of-the-art approaches when used for lane change detection.

</p>
</details>

<details><summary><b>Compression of Generative Pre-trained Language Models via Quantization</b>
<a href="https://arxiv.org/abs/2203.10705">arxiv:2203.10705</a>
&#x1F4C8; 3 <br>
<p>Chaofan Tao, Lu Hou, Wei Zhang, Lifeng Shang, Xin Jiang, Qun Liu, Ping Luo, Ngai Wong</p></summary>
<p>

**Abstract:** The increasing size of generative Pre-trained Language Models (PLMs) has greatly increased the demand for model compression. Despite various methods to compress BERT or its variants, there are few attempts to compress generative PLMs, and the underlying difficulty remains unclear. In this paper, we compress generative PLMs by quantization. We find that previous quantization methods fail on generative tasks due to the \textit{homogeneous word embeddings} caused by reduced capacity, and \textit{varied distribution of weights}. Correspondingly, we propose a token-level contrastive distillation to learn distinguishable word embeddings, and a module-wise dynamic scaling to make quantizers adaptive to different modules. Empirical results on various tasks show that our proposed method outperforms the state-of-the-art compression methods on generative PLMs by a clear margin. With comparable performance with the full-precision models, we achieve 14.4x and 13.4x compression rates on GPT-2 and BART, respectively.

</p>
</details>

<details><summary><b>Nonstationary Temporal Matrix Factorization for Multivariate Time Series Forecasting</b>
<a href="https://arxiv.org/abs/2203.10651">arxiv:2203.10651</a>
&#x1F4C8; 3 <br>
<p>Xinyu Chen, Chengyuan Zhang, Xi-Le Zhao, Nicolas Saunier, Lijun Sun</p></summary>
<p>

**Abstract:** Modern time series datasets are often high-dimensional, incomplete/sparse, and nonstationary. These properties hinder the development of scalable and efficient solutions for time series forecasting and analysis. To address these challenges, we propose a Nonstationary Temporal Matrix Factorization (NoTMF) model, in which matrix factorization is used to reconstruct the whole time series matrix and vector autoregressive (VAR) process is imposed on a properly differenced copy of the temporal factor matrix. This approach not only preserves the low-rank property of the data but also offers consistent temporal dynamics. The learning process of NoTMF involves the optimization of two factor matrices and a collection of VAR coefficient matrices. To efficiently solve the optimization problem, we derive an alternating minimization framework, in which subproblems are solved using conjugate gradient and least squares methods. In particular, the use of conjugate gradient method offers an efficient routine and allows us to apply NoTMF on large-scale problems. Through extensive experiments on Uber movement speed dataset, we demonstrate the superior accuracy and effectiveness of NoTMF over other baseline models. Our results also confirm the importance of addressing the nonstationarity of real-world time series data such as spatiotemporal traffic flow/speed.

</p>
</details>

<details><summary><b>Automated Detection of Acute Promyelocytic Leukemia in Blood Films and Bone Marrow Aspirates with Annotation-free Deep Learning</b>
<a href="https://arxiv.org/abs/2203.10626">arxiv:2203.10626</a>
&#x1F4C8; 3 <br>
<p>Petru Manescu, Priya Narayanan, Christopher Bendkowski, Muna Elmi, Remy Claveau, Vijay Pawar, Biobele J. Brown, Mike Shaw, Anupama Rao, Delmiro Fernandez-Reyes</p></summary>
<p>

**Abstract:** While optical microscopy inspection of blood films and bone marrow aspirates by a hematologist is a crucial step in establishing diagnosis of acute leukemia, especially in low-resource settings where other diagnostic modalities might not be available, the task remains time-consuming and prone to human inconsistencies. This has an impact especially in cases of Acute Promyelocytic Leukemia (APL) that require urgent treatment. Integration of automated computational hematopathology into clinical workflows can improve the throughput of these services and reduce cognitive human error. However, a major bottleneck in deploying such systems is a lack of sufficient cell morphological object-labels annotations to train deep learning models. We overcome this by leveraging patient diagnostic labels to train weakly-supervised models that detect different types of acute leukemia. We introduce a deep learning approach, Multiple Instance Learning for Leukocyte Identification (MILLIE), able to perform automated reliable analysis of blood films with minimal supervision. Without being trained to classify individual cells, MILLIE differentiates between acute lymphoblastic and myeloblastic leukemia in blood films. More importantly, MILLIE detects APL in blood films (AUC 0.94+/-0.04) and in bone marrow aspirates (AUC 0.99+/-0.01). MILLIE is a viable solution to augment the throughput of clinical pathways that require assessment of blood film microscopy.

</p>
</details>

<details><summary><b>Immersive Text Game and Personality Classification</b>
<a href="https://arxiv.org/abs/2203.10621">arxiv:2203.10621</a>
&#x1F4C8; 3 <br>
<p>Wanshui Li, Yifan Bai, Jiaxuan Lu, Kexin Yi</p></summary>
<p>

**Abstract:** We designed and built a game called \textit{Immersive Text Game}, which allows the player to choose a story and a character, and interact with other characters in the story in an immersive manner of dialogues. The game is based on several latest models, including text generation language model, information extraction model, commonsense reasoning model, and psychology evaluation model. In the past, similar text games usually let players choose from limited actions instead of answering on their own, and not every time what characters said are determined by the player. Through the combination of these models and elaborate game mechanics and modes, the player will find some novel experiences as driven through the storyline.

</p>
</details>

<details><summary><b>Towards Large-Scale Interpretable Knowledge Graph Reasoning for Dialogue Systems</b>
<a href="https://arxiv.org/abs/2203.10610">arxiv:2203.10610</a>
&#x1F4C8; 3 <br>
<p>Yi-Lin Tuan, Sajjad Beygi, Maryam Fazel-Zarandi, Qiaozi Gao, Alessandra Cervone, William Yang Wang</p></summary>
<p>

**Abstract:** Users interacting with voice assistants today need to phrase their requests in a very specific manner to elicit an appropriate response. This limits the user experience, and is partly due to the lack of reasoning capabilities of dialogue platforms and the hand-crafted rules that require extensive labor. One possible way to improve user experience and relieve the manual efforts of designers is to build an end-to-end dialogue system that can do reasoning itself while perceiving user's utterances. In this work, we propose a novel method to incorporate the knowledge reasoning capability into dialogue systems in a more scalable and generalizable manner. Our proposed method allows a single transformer model to directly walk on a large-scale knowledge graph to generate responses. To the best of our knowledge, this is the first work to have transformer models generate responses by reasoning over differentiable knowledge graphs. We investigate the reasoning abilities of the proposed method on both task-oriented and domain-specific chit-chat dialogues. Empirical results show that this method can effectively and efficiently incorporate a knowledge graph into a dialogue system with fully-interpretable reasoning paths.

</p>
</details>

<details><summary><b>Qualia as physical measurements: a mathematical model of qualia and pure concepts</b>
<a href="https://arxiv.org/abs/2203.10602">arxiv:2203.10602</a>
&#x1F4C8; 3 <br>
<p>Pedro Resende</p></summary>
<p>

**Abstract:** A space of qualia is defined to be a sober topological space whose points are the qualia and whose open sets are the pure concepts in the sense of Lewis, carrying additional algebraic structure that conveys the conscious experience of subjective time and logical abstraction. This structure is analogous to that of a space of physical measurements. It is conjectured that qualia and measurements have the same nature, corresponding to fundamental processes via which classical information is produced and physically stored, and that therefore the hard problem of consciousness and the measurement problem are two facets of the same problem. The space of qualia is independent from any preexisting notions of spacetime and conscious agent, but its structure caters for a derived geometric model of observer. Intersubjectivity is based on relating different observers in a way that leads to a logical version of quantum superposition.

</p>
</details>

<details><summary><b>Neuro-physical dynamic load modeling using differentiable parametric optimization</b>
<a href="https://arxiv.org/abs/2203.10582">arxiv:2203.10582</a>
&#x1F4C8; 3 <br>
<p>Shrirang Abhyankar, Jan Drgona, Andrew August, Elliot Skomski, Aaron Tuor</p></summary>
<p>

**Abstract:** In this work, we investigate a data-driven approach for obtaining a reduced equivalent load model of distribution systems for electromechanical transient stability analysis. The proposed reduced equivalent is a neuro-physical model comprising of a traditional ZIP load model augmented with a neural network. This neuro-physical model is trained through differentiable programming. We discuss the formulation, modeling details, and training of the proposed model set up as a differential parametric program. The performance and accuracy of this neurophysical ZIP load model is presented on a medium-scale 350-bus transmission-distribution network.

</p>
</details>

<details><summary><b>End-to-End Video Text Spotting with Transformer</b>
<a href="https://arxiv.org/abs/2203.10539">arxiv:2203.10539</a>
&#x1F4C8; 3 <br>
<p>Weijia Wu, Debing Zhang, Ying Fu, Chunhua Shen, Hong Zhou, Yuanqiang Cai, Ping Luo</p></summary>
<p>

**Abstract:** Recent video text spotting methods usually require the three-staged pipeline, i.e., detecting text in individual images, recognizing localized text, tracking text streams with post-processing to generate final results. These methods typically follow the tracking-by-match paradigm and develop sophisticated pipelines. In this paper, rooted in Transformer sequence modeling, we propose a simple, but effective end-to-end video text DEtection, Tracking, and Recognition framework (TransDETR). TransDETR mainly includes two advantages: 1) Different from the explicit match paradigm in the adjacent frame, TransDETR tracks and recognizes each text implicitly by the different query termed text query over long-range temporal sequence (more than 7 frames). 2) TransDETR is the first end-to-end trainable video text spotting framework, which simultaneously addresses the three sub-tasks (e.g., text detection, tracking, recognition). Extensive experiments in four video text datasets (i.e.,ICDAR2013 Video, ICDAR2015 Video, Minetto, and YouTube Video Text) are conducted to demonstrate that TransDETR achieves state-of-the-art performance with up to around 8.0% improvements on video text spotting tasks. The code of TransDETR can be found at https://github.com/weijiawu/TransDETR.

</p>
</details>

<details><summary><b>Optimizing Camera Placements for Overlapped Coverage with 3D Camera Projections</b>
<a href="https://arxiv.org/abs/2203.10479">arxiv:2203.10479</a>
&#x1F4C8; 3 <br>
<p>Akshay Malhotra, Dhananjay Singh, Tushar Dadlani, Luis Yoichi Morales</p></summary>
<p>

**Abstract:** This paper proposes a method to compute camera 6Dof poses to achieve a user defined coverage. The camera placement problem is modeled as a combinatorial optimization where given the maximum number of cameras, a camera set is selected from a larger pool of possible camera poses. We propose to minimize the squared error between the desired and the achieved coverage, and formulate the non-linear cost function as a mixed integer linear programming problem. A camera lens model is utilized to project the cameras view on a 3D voxel map to compute a coverage score which makes the optimization problem in real environments tractable. Experimental results in two real retail store environments demonstrate the better performance of the proposed formulation in terms of coverage and overlap for triangulation compared to existing methods.

</p>
</details>

<details><summary><b>ECAPA-TDNN for Multi-speaker Text-to-speech Synthesis</b>
<a href="https://arxiv.org/abs/2203.10473">arxiv:2203.10473</a>
&#x1F4C8; 3 <br>
<p>Jinlong Xue, Yayue Deng, Yichen Han, Ya Li, Jianqing Sun, Jiaen Liang</p></summary>
<p>

**Abstract:** In recent years, neural network based methods for multi-speaker text-to-speech synthesis (TTS) have made significant progress. However, the current speaker encoder models used in these methods still cannot capture enough speaker information. In this paper, we focus on accurate speaker encoder modeling and propose an end-to-end method that can generate high-quality speech and better similarity for both seen and unseen speakers. The proposed architecture consists of three separately trained components: a speaker encoder based on the state-of-the-art ECAPA-TDNN model which is derived from speaker verification task, a FastSpeech2 based synthesizer, and a HiFi-GAN vocoder. The comparison among different speaker encoder models shows our proposed method can achieve better naturalness and similarity. To efficiently evaluate our synthesized speech, we are the first to adopt deep learning based automatic MOS evaluation methods to assess our results, and these methods show great potential in automatic speech quality assessment.

</p>
</details>

<details><summary><b>Unidirectional Thin Adapter for Efficient Adaptation of Deep Neural Networks</b>
<a href="https://arxiv.org/abs/2203.10463">arxiv:2203.10463</a>
&#x1F4C8; 3 <br>
<p>Han Gyel Sun, Hyunjae Ahn, HyunGyu Lee, Injung Kim</p></summary>
<p>

**Abstract:** In this paper, we propose a new adapter network for adapting a pre-trained deep neural network to a target domain with minimal computation. The proposed model, unidirectional thin adapter (UDTA), helps the classifier adapt to new data by providing auxiliary features that complement the backbone network. UDTA takes outputs from multiple layers of the backbone as input features but does not transmit any feature to the backbone. As a result, UDTA can learn without computing the gradient of the backbone, which saves computation for training significantly. In addition, since UDTA learns the target task without modifying the backbone, a single backbone can adapt to multiple tasks by learning only UDTAs separately. In experiments on five fine-grained classification datasets consisting of a small number of samples, UDTA significantly reduced computation and training time required for backpropagation while showing comparable or even improved accuracy compared with conventional adapter models.

</p>
</details>

<details><summary><b>Semantic Similarity Computing for Scientific Academic Conferences fused with domain features</b>
<a href="https://arxiv.org/abs/2203.12593">arxiv:2203.12593</a>
&#x1F4C8; 2 <br>
<p>Runyu Yu, Yawen Li, Ang Li</p></summary>
<p>

**Abstract:** Aiming at the problem that the current general-purpose semantic text similarity calculation methods are difficult to use the semantic information of scientific academic conference data, a semantic similarity calculation algorithm for scientific academic conferences by fusion with domain features is proposed. First, the domain feature information of the conference is obtained through entity recognition and keyword extraction, and it is input into the BERT network as a feature and the conference information. The structure of the Siamese network is used to solve the anisotropy problem of BERT. The output of the network is pooled and normalized, and finally the cosine similarity is used to calculate the similarity between the two sessions. Experimental results show that the SBFD algorithm has achieved good results on different data sets, and the Spearman correlation coefficient has a certain improvement compared with the comparison algorithm.

</p>
</details>

<details><summary><b>Web Page Content Extraction Based on Multi-feature Fusion</b>
<a href="https://arxiv.org/abs/2203.12591">arxiv:2203.12591</a>
&#x1F4C8; 2 <br>
<p>Bowen Yu, Junping Du, Yingxia Shao</p></summary>
<p>

**Abstract:** With the rapid development of Internet technology, people have more and more access to a variety of web page resources. At the same time, the current rapid development of deep learning technology is often inseparable from the huge amount of Web data resources. On the other hand, NLP is also an important part of data processing technology, such as web page data extraction. At present, the extraction technology of web page text mainly uses a single heuristic function or strategy, and most of them need to determine the threshold manually. With the rapid growth of the number and types of web resources, there are still problems to be solved when using a single strategy to extract the text information of different pages. This paper proposes a web page text extraction algorithm based on multi-feature fusion. According to the text information characteristics of web resources, DOM nodes are used as the extraction unit to design multiple statistical features, and high-order features are designed according to heuristic strategies. This method establishes a small neural network, takes multiple features of DOM nodes as input, predicts whether the nodes contain text information, makes full use of different statistical information and extraction strategies, and adapts to more types of pages. Experimental results show that this method has a good ability of web page text extraction and avoids the problem of manually determining the threshold.

</p>
</details>

<details><summary><b>Phase Recognition in Contrast-Enhanced CT Scans based on Deep Learning and Random Sampling</b>
<a href="https://arxiv.org/abs/2203.11206">arxiv:2203.11206</a>
&#x1F4C8; 2 <br>
<p>Binh T. Dao, Thang V. Nguyen, Hieu H. Pham, Ha Q. Nguyen</p></summary>
<p>

**Abstract:** A fully automated system for interpreting abdominal computed tomography (CT) scans with multiple phases of contrast enhancement requires an accurate classification of the phases. This work aims at developing and validating a precise, fast multi-phase classifier to recognize three main types of contrast phases in abdominal CT scans. We propose in this study a novel method that uses a random sampling mechanism on top of deep CNNs for the phase recognition of abdominal CT scans of four different phases: non-contrast, arterial, venous, and others. The CNNs work as a slice-wise phase prediction, while the random sampling selects input slices for the CNN models. Afterward, majority voting synthesizes the slice-wise results of the CNNs, to provide the final prediction at scan level. Our classifier was trained on 271,426 slices from 830 phase-annotated CT scans, and when combined with majority voting on 30% of slices randomly chosen from each scan, achieved a mean F1-score of 92.09% on our internal test set of 358 scans. The proposed method was also evaluated on 2 external test sets: CTPAC-CCRCC (N = 242) and LiTS (N = 131), which were annotated by our experts. Although a drop in performance has been observed, the model performance remained at a high level of accuracy with a mean F1-score of 76.79% and 86.94% on CTPAC-CCRCC and LiTS datasets, respectively. Our experimental results also showed that the proposed method significantly outperformed the state-of-the-art 3D approaches while requiring less computation time for inference.

</p>
</details>

<details><summary><b>Prediction Algorithm for Heat Demand of Science and Technology Topics Based on Time Convolution Network</b>
<a href="https://arxiv.org/abs/2203.10718">arxiv:2203.10718</a>
&#x1F4C8; 2 <br>
<p>Cui Haiyan, Li Yawen, Xu Xin</p></summary>
<p>

**Abstract:** Thanks to the rapid development of deep learning, big data analysis technology is not only widely used in the field of natural language processing, but also more mature in the field of numerical prediction. It is of great significance for the subject heat prediction and analysis of science and technology demand data. How to apply theme features to accurately predict the theme heat of science and technology demand is the core to solve this problem. In this paper, a prediction method of subject heat of science and technology demand based on time convolution network (TCN) is proposed to obtain the subject feature representation of science and technology demand. Time series prediction is carried out based on TCN network and self attention mechanism, which increases the accuracy of subject heat prediction of science and technology demand data Experiments show that the prediction accuracy of this algorithm is better than other time series prediction methods on the real science and technology demand datasets.

</p>
</details>

<details><summary><b>An Intellectual Property Entity Recognition Method Based on Transformer and Technological Word Information</b>
<a href="https://arxiv.org/abs/2203.10717">arxiv:2203.10717</a>
&#x1F4C8; 2 <br>
<p>Yuhui Wang, Junping Du, Yingxia Shao</p></summary>
<p>

**Abstract:** Patent texts contain a large amount of entity information. Through named entity recognition, intellectual property entity information containing key information can be extracted from it, helping researchers to understand the patent content faster. Therefore, it is difficult for existing named entity extraction methods to make full use of the semantic information at the word level brought about by professional vocabulary changes. This paper proposes a method for extracting intellectual property entities based on Transformer and technical word information , and provides accurate word vector representation in combination with the BERT language method. In the process of word vector generation, the technical word information extracted by IDCNN is added to improve the understanding of intellectual property entities Representation ability. Finally, the Transformer encoder that introduces relative position encoding is used to learn the deep semantic information of the text from the sequence of word vectors, and realize entity label prediction. Experimental results on public datasets and annotated patent datasets show that the method improves the accuracy of entity recognition.

</p>
</details>

<details><summary><b>Online Continual Learning for Embedded Devices</b>
<a href="https://arxiv.org/abs/2203.10681">arxiv:2203.10681</a>
&#x1F4C8; 2 <br>
<p>Tyler L. Hayes, Christopher Kanan</p></summary>
<p>

**Abstract:** Real-time on-device continual learning is needed for new applications such as home robots, user personalization on smartphones, and augmented/virtual reality headsets. However, this setting poses unique challenges: embedded devices have limited memory and compute capacity and conventional machine learning models suffer from catastrophic forgetting when updated on non-stationary data streams. While several online continual learning models have been developed, their effectiveness for embedded applications has not been rigorously studied. In this paper, we first identify criteria that online continual learners must meet to effectively perform real-time, on-device learning. We then study the efficacy of several online continual learning methods when used with mobile neural networks. We measure their performance, memory usage, compute requirements, and ability to generalize to out-of-domain inputs.

</p>
</details>

<details><summary><b>Mitigating Gender Bias in Machine Translation through Adversarial Learning</b>
<a href="https://arxiv.org/abs/2203.10675">arxiv:2203.10675</a>
&#x1F4C8; 2 <br>
<p>Eve Fleisig, Christiane Fellbaum</p></summary>
<p>

**Abstract:** Machine translation and other NLP systems often contain significant biases regarding sensitive attributes, such as gender or race, that worsen system performance and perpetuate harmful stereotypes. Recent preliminary research suggests that adversarial learning can be used as part of a model-agnostic bias mitigation method that requires no data modifications. However, adapting this strategy for machine translation and other modern NLP domains requires (1) restructuring training objectives in the context of fine-tuning pretrained large language models and (2) developing measures for gender or other protected variables for tasks in which these attributes must be deduced from the data itself.
  We present an adversarial learning framework that addresses these challenges to mitigate gender bias in seq2seq machine translation. Our framework improves the disparity in translation quality for sentences with male vs. female entities by 86% for English-German translation and 91% for English-French translation, with minimal effect on translation quality. The results suggest that adversarial learning is a promising technique for mitigating gender bias in machine translation.

</p>
</details>

<details><summary><b>Fully Convolutional Fractional Scaling</b>
<a href="https://arxiv.org/abs/2203.10670">arxiv:2203.10670</a>
&#x1F4C8; 2 <br>
<p>Michael Soloveitchik, Michael Werman</p></summary>
<p>

**Abstract:** We introduce a fully convolutional fractional scaling component, FCFS. Fully convolutional networks can be applied to any size input and previously did not support non-integer scaling. Our architecture is simple with an efficient single layer implementation. Examples and code implementations of three common scaling methods are published.

</p>
</details>

<details><summary><b>A direct geometry processing cartilage generation method using segmented bone models from datasets with poor cartilage visibility</b>
<a href="https://arxiv.org/abs/2203.10667">arxiv:2203.10667</a>
&#x1F4C8; 2 <br>
<p>Faezeh Moshfeghifar, Max Kragballe Nielsen, José D. Tascón-Vidarte, Sune Darkner, Kenny Erleben</p></summary>
<p>

**Abstract:** We present a method to generate subject-specific cartilage for the hip joint. Given bone geometry, our approach is agnostic to image modality, creates conforming interfaces, and is well suited for finite element analysis. We demonstrate our method on ten hip joints showing anatomical shape consistency and well-behaved stress patterns. Our method is fast and may assist in large-scale biomechanical population studies of the hip joint when manual segmentation or training data is not feasible.

</p>
</details>

<details><summary><b>From Stance to Concern: Adaptation of Propositional Analysis to New Tasks and Domains</b>
<a href="https://arxiv.org/abs/2203.10659">arxiv:2203.10659</a>
&#x1F4C8; 2 <br>
<p>Brodie Mather, Bonnie J Dorr, Adam Dalton, William de Beaumont, Owen Rambow, Sonja M. Schmer-Galunder</p></summary>
<p>

**Abstract:** We present a generalized paradigm for adaptation of propositional analysis (predicate-argument pairs) to new tasks and domains. We leverage an analogy between stances (belief-driven sentiment) and concerns (topical issues with moral dimensions/endorsements) to produce an explanatory representation. A key contribution is the combination of semi-automatic resource building for extraction of domain-dependent concern types (with 2-4 hours of human labor per domain) and an entirely automatic procedure for extraction of domain-independent moral dimensions and endorsement values. Prudent (automatic) selection of terms from propositional structures for lexical expansion (via semantic similarity) produces new moral dimension lexicons at three levels of granularity beyond a strong baseline lexicon. We develop a ground truth (GT) based on expert annotators and compare our concern detection output to GT, to yield 231% improvement in recall over baseline, with only a 10% loss in precision. F1 yields 66% improvement over baseline and 97.8% of human performance. Our lexically based approach yields large savings over approaches that employ costly human labor and model building. We provide to the community a newly expanded moral dimension/value lexicon, annotation guidelines, and GT.

</p>
</details>

<details><summary><b>Continual Sequence Generation with Adaptive Compositional Modules</b>
<a href="https://arxiv.org/abs/2203.10652">arxiv:2203.10652</a>
&#x1F4C8; 2 <br>
<p>Yanzhe Zhang, Xuezhi Wang, Diyi Yang</p></summary>
<p>

**Abstract:** Continual learning is essential for real-world deployment when there is a need to quickly adapt the model to new tasks without forgetting knowledge of old tasks. Existing work on continual sequence generation either always reuses existing parameters to learn new tasks, which is vulnerable to catastrophic forgetting on dissimilar tasks, or blindly adds new parameters for every new task, which could prevent knowledge sharing between similar tasks. To get the best of both worlds, in this work, we propose continual sequence generation with adaptive compositional modules to adaptively add modules in transformer architectures and compose both old and new modules for new tasks. We also incorporate pseudo experience replay to facilitate knowledge transfer in those shared modules. Experiment results on various sequences of generation tasks show that our framework can adaptively add modules or reuse modules based on task similarity, outperforming state-of-the-art baselines in terms of both performance and parameter efficiency. We make our code public at https://github.com/GT-SALT/Adaptive-Compositional-Modules.

</p>
</details>

<details><summary><b>Breast Cancer Induced Bone Osteolysis Prediction Using Temporal Variational Auto-Encoders</b>
<a href="https://arxiv.org/abs/2203.10645">arxiv:2203.10645</a>
&#x1F4C8; 2 <br>
<p>Wei Xiong, Neil Yeung, Shubo Wang, Haofu Liao, Liyun Wang, Jiebo Luo</p></summary>
<p>

**Abstract:** Objective and Impact Statement. We adopt a deep learning model for bone osteolysis prediction on computed tomography (CT) images of murine breast cancer bone metastases. Given the bone CT scans at previous time steps, the model incorporates the bone-cancer interactions learned from the sequential images and generates future CT images. Its ability of predicting the development of bone lesions in cancer-invading bones can assist in assessing the risk of impending fractures and choosing proper treatments in breast cancer bone metastasis. Introduction. Breast cancer often metastasizes to bone, causes osteolytic lesions, and results in skeletal related events (SREs) including severe pain and even fatal fractures. Although current imaging techniques can detect macroscopic bone lesions, predicting the occurrence and progression of bone lesions remains a challenge. Methods. We adopt a temporal variational auto-encoder (T-VAE) model that utilizes a combination of variational auto-encoders and long short-term memory networks to predict bone lesion emergence on our micro-CT dataset containing sequential images of murine tibiae. Given the CT scans of murine tibiae at early weeks, our model can learn the distribution of their future states from data. Results. We test our model against other deep learning-based prediction models on the bone lesion progression prediction task. Our model produces much more accurate predictions than existing models under various evaluation metrics. Conclusion. We develop a deep learning framework that can accurately predict and visualize the progression of osteolytic bone lesions. It will assist in planning and evaluating treatment strategies to prevent SREs in breast cancer patients.

</p>
</details>

<details><summary><b>Enriching Unsupervised User Embedding via Medical Concepts</b>
<a href="https://arxiv.org/abs/2203.10627">arxiv:2203.10627</a>
&#x1F4C8; 2 <br>
<p>Xiaolei Huang, Franck Dernoncourt, Mark Dredze</p></summary>
<p>

**Abstract:** Clinical notes in Electronic Health Records (EHR) present rich documented information of patients to inference phenotype for disease diagnosis and study patient characteristics for cohort selection. Unsupervised user embedding aims to encode patients into fixed-length vectors without human supervisions. Medical concepts extracted from the clinical notes contain rich connections between patients and their clinical categories. However, existing unsupervised approaches of user embeddings from clinical notes do not explicitly incorporate medical concepts. In this study, we propose a concept-aware unsupervised user embedding that jointly leverages text documents and medical concepts from two clinical corpora, MIMIC-III and Diabetes. We evaluate user embeddings on both extrinsic and intrinsic tasks, including phenotype classification, in-hospital mortality prediction, patient retrieval, and patient relatedness. Experiments on the two clinical corpora show our approach exceeds unsupervised baselines, and incorporating medical concepts can significantly improve the baseline performance.

</p>
</details>

<details><summary><b>Calibration of Machine Reading Systems at Scale</b>
<a href="https://arxiv.org/abs/2203.10623">arxiv:2203.10623</a>
&#x1F4C8; 2 <br>
<p>Shehzaad Dhuliawala, Leonard Adolphs, Rajarshi Das, Mrinmaya Sachan</p></summary>
<p>

**Abstract:** In typical machine learning systems, an estimate of the probability of the prediction is used to assess the system's confidence in the prediction. This confidence measure is usually uncalibrated; i.e.\ the system's confidence in the prediction does not match the true probability of the predicted output. In this paper, we present an investigation into calibrating open setting machine reading systems such as open-domain question answering and claim verification systems. We show that calibrating such complex systems which contain discrete retrieval and deep reading components is challenging and current calibration techniques fail to scale to these settings. We propose simple extensions to existing calibration approaches that allows us to adapt them to these settings. Our experimental results reveal that the approach works well, and can be useful to selectively predict answers when question answering systems are posed with unanswerable or out-of-the-training distribution questions.

</p>
</details>

<details><summary><b>Multi-Modal Learning Using Physicians Diagnostics for Optical Coherence Tomography Classification</b>
<a href="https://arxiv.org/abs/2203.10622">arxiv:2203.10622</a>
&#x1F4C8; 2 <br>
<p>Y. Logan, K. Kokilepersaud, G. Kwon, G. AlRegib, C. Wykoff, H. Yu</p></summary>
<p>

**Abstract:** In this paper, we propose a framework that incorporates experts diagnostics and insights into the analysis of Optical Coherence Tomography (OCT) using multi-modal learning. To demonstrate the effectiveness of this approach, we create a medical diagnostic attribute dataset to improve disease classification using OCT. Although there have been successful attempts to deploy machine learning for disease classification in OCT, such methodologies lack the experts insights. We argue that injecting ophthalmological assessments as another supervision in a learning framework is of great importance for the machine learning process to perform accurate and interpretable classification. We demonstrate the proposed framework through comprehensive experiments that compare the effectiveness of combining diagnostic attribute features with latent visual representations and show that they surpass the state-of-the-art approach. Finally, we analyze the proposed dual-stream architecture and provide an insight that determine the components that contribute most to classification performance.

</p>
</details>

<details><summary><b>Hierarchical Reinforcement Learning of Locomotion Policies in Response to Approaching Objects: A Preliminary Study</b>
<a href="https://arxiv.org/abs/2203.10616">arxiv:2203.10616</a>
&#x1F4C8; 2 <br>
<p>Shangqun Yu, Sreehari Rammohan, Kaiyu Zheng, George Konidaris</p></summary>
<p>

**Abstract:** Animals such as rabbits and birds can instantly generate locomotion behavior in reaction to a dynamic, approaching object, such as a person or a rock, despite having possibly never seen the object before and having limited perception of the object's properties. Recently, deep reinforcement learning has enabled complex kinematic systems such as humanoid robots to successfully move from point A to point B. Inspired by the observation of the innate reactive behavior of animals in nature, we hope to extend this progress in robot locomotion to settings where external, dynamic objects are involved whose properties are partially observable to the robot. As a first step toward this goal, we build a simulation environment in MuJoCo where a legged robot must avoid getting hit by a ball moving toward it. We explore whether prior locomotion experiences that animals typically possess benefit the learning of a reactive control policy under a proposed hierarchical reinforcement learning framework. Preliminary results support the claim that the learning becomes more efficient using this hierarchical reinforcement learning method, even when partial observability (radius-based object visibility) is taken into account.

</p>
</details>

<details><summary><b>VinDr-PCXR: An open, large-scale chest radiograph dataset for interpretation of common thoracic diseases in children</b>
<a href="https://arxiv.org/abs/2203.10612">arxiv:2203.10612</a>
&#x1F4C8; 2 <br>
<p>Ngoc H. Nguyen, Hieu H. Pham, Thanh T. Tran, Tuan N. M. Nguyen, Ha Q. Nguyen</p></summary>
<p>

**Abstract:** Computer-aided diagnosis systems in adult chest radiography (CXR) have recently achieved great success thanks to the availability of large-scale, annotated datasets and the advent of high-performance supervised learning algorithms. However, the development of diagnostic models for detecting and diagnosing pediatric diseases in CXR scans is undertaken due to the lack of high-quality physician-annotated datasets. To overcome this challenge, we introduce and release VinDr-PCXR, a new pediatric CXR dataset of 9,125 studies retrospectively collected from a major pediatric hospital in Vietnam between 2020 and 2021. Each scan was manually annotated by a pediatric radiologist who has more than ten years of experience. The dataset was labeled for the presence of 36 critical findings and 15 diseases. In particular, each abnormal finding was identified via a rectangle bounding box on the image. To the best of our knowledge, this is the first and largest pediatric CXR dataset containing lesion-level annotations and image-level labels for the detection of multiple findings and diseases. For algorithm development, the dataset was divided into a training set of 7,728 and a test set of 1,397. To encourage new advances in pediatric CXR interpretation using data-driven approaches, we provide a detailed description of the VinDr-PCXR data sample and make the dataset publicly available on https://physionet.org/.

</p>
</details>

<details><summary><b>A Learning Convolutional Neural Network Approach for Network Robustness Prediction</b>
<a href="https://arxiv.org/abs/2203.10552">arxiv:2203.10552</a>
&#x1F4C8; 2 <br>
<p>Yang Lou, Ruizi Wu, Junli Li, Lin Wang, Xiang Li, Guanrong Chen</p></summary>
<p>

**Abstract:** Network robustness is critical for various societal and industrial networks again malicious attacks. In particular, connectivity robustness and controllability robustness reflect how well a networked system can maintain its connectedness and controllability against destructive attacks, which can be quantified by a sequence of values that record the remaining connectivity and controllability of the network after a sequence of node- or edge-removal attacks. Traditionally, robustness is determined by attack simulations, which are computationally very time-consuming or even practically infeasible. In this paper, an improved method for network robustness prediction is developed based on learning feature representation using convolutional neural network (LFR-CNN). In this scheme, higher-dimensional network data are compressed to lower-dimensional representations, and then passed to a CNN to perform robustness prediction. Extensive experimental studies on both synthetic and real-world networks, both directed and undirected, demonstrate that 1) the proposed LFR-CNN performs better than other two state-of-the-art prediction methods, with significantly lower prediction errors; 2) LFR-CNN is insensitive to the variation of the network size, which significantly extends its applicability; 3) although LFR-CNN needs more time to perform feature learning, it can achieve accurate prediction faster than attack simulations; 4) LFR-CNN not only can accurately predict network robustness, but also provides a good indicator for connectivity robustness, better than the classical spectral measures.

</p>
</details>

<details><summary><b>Reinforcement learning reward function in unmanned aerial vehicle control tasks</b>
<a href="https://arxiv.org/abs/2203.10519">arxiv:2203.10519</a>
&#x1F4C8; 2 <br>
<p>Mikhail S. Tovarnov, Nikita V. Bykov</p></summary>
<p>

**Abstract:** This paper presents a new reward function that can be used for deep reinforcement learning in unmanned aerial vehicle (UAV) control and navigation problems. The reward function is based on the construction and estimation of the time of simplified trajectories to the target, which are third-order Bezier curves. This reward function can be applied unchanged to solve problems in both two-dimensional and three-dimensional virtual environments. The effectiveness of the reward function was tested in a newly developed virtual environment, namely, a simplified two-dimensional environment describing the dynamics of UAV control and flight, taking into account the forces of thrust, inertia, gravity, and aerodynamic drag. In this formulation, three tasks of UAV control and navigation were successfully solved: UAV flight to a given point in space, avoidance of interception by another UAV, and organization of interception of one UAV by another. The three most relevant modern deep reinforcement learning algorithms, Soft actor-critic, Deep Deterministic Policy Gradient, and Twin Delayed Deep Deterministic Policy Gradient were used. All three algorithms performed well, indicating the effectiveness of the selected reward function.

</p>
</details>

<details><summary><b>Learning on the Job: Long-Term Behavioural Adaptation in Human-Robot Interactions</b>
<a href="https://arxiv.org/abs/2203.10518">arxiv:2203.10518</a>
&#x1F4C8; 2 <br>
<p>Francesco Del Duchetto, Marc Hanheide</p></summary>
<p>

**Abstract:** In this work, we propose a framework for allowing autonomous robots deployed for extended periods of time in public spaces to adapt their own behaviour online from user interactions. The robot behaviour planning is embedded in a Reinforcement Learning (RL) framework, where the objective is maximising the level of overall user engagement during the interactions. We use the Upper-Confidence-Bound Value-Iteration (UCBVI) algorithm, which gives a helpful way of managing the exploration-exploitation trade-off for real-time interactions. An engagement model trained end-to-end generates the reward function in real-time during policy execution. We test this approach in a public museum in Lincoln (UK), where the robot is deployed as a tour guide for the visitors. Results show that after a couple of months of exploration, the robot policy learned to maintain the engagement of users for longer, with an increase of 22.8% over the initial static policy in the number of items visited during the tour and a 30% increase in the probability of completing the tour. This work is a promising step toward behavioural adaptation in long-term scenarios for robotics applications in social settings.

</p>
</details>

<details><summary><b>Learning Whole Heart Mesh Generation From Patient Images For Computational Simulations</b>
<a href="https://arxiv.org/abs/2203.10517">arxiv:2203.10517</a>
&#x1F4C8; 2 <br>
<p>Fanwei Kong, Shawn Shadden</p></summary>
<p>

**Abstract:** Patient-specific cardiac modeling combines geometries of the heart derived from medical images and biophysical simulations to predict various aspects of cardiac function. However, generating simulation-suitable models of the heart from patient image data often requires complicated procedures and significant human effort. We present a fast and automated deep-learning method to construct simulation-suitable models of the heart from medical images. The approach constructs meshes from 3D patient images by learning to deform a small set of deformation handles on a whole heart template. For both 3D CT and MR data, this method achieves promising accuracy for whole heart reconstruction, consistently outperforming prior methods in constructing simulation-suitable meshes of the heart. When evaluated on time-series CT data, this method produced more anatomically and temporally consistent geometries than prior methods, and was able to produce geometries that better satisfy modeling requirements for cardiac flow simulations. Our source code will be available on GitHub.

</p>
</details>

<details><summary><b>Adversarial Mutual Leakage Network for Cell Image Segmentation</b>
<a href="https://arxiv.org/abs/2203.10455">arxiv:2203.10455</a>
&#x1F4C8; 2 <br>
<p>Hiroki Tsuda, Kazuhiro Hotta</p></summary>
<p>

**Abstract:** We propose three segmentation methods using GAN and information leakage between generator and discriminator. First, we propose an Adversarial Training Attention Module (ATA-Module) that uses an attention mechanism from the discriminator to the generator to enhance and leak important information in the discriminator. ATA-Module transmits important information to the generator from the discriminator. Second, we propose a Top-Down Pixel-wise Difficulty Attention Module (Top-Down PDA-Module) that leaks an attention map based on pixel-wise difficulty in the generator to the discriminator. The generator trains to focus on pixel-wise difficulty, and the discriminator uses the difficulty information leaked from the generator for classification. Finally, we propose an Adversarial Mutual Leakage Network (AML-Net) that mutually leaks the information each other between the generator and the discriminator. By using the information of the other network, it is able to train more efficiently than ordinary segmentation models. Three proposed methods have been evaluated on two datasets for cell image segmentation. The experimental results show that the segmentation accuracy of AML-Net was much improved in comparison with conventional methods.

</p>
</details>

<details><summary><b>Research Scholar Interest Mining Method based on Load Centrality</b>
<a href="https://arxiv.org/abs/2203.10731">arxiv:2203.10731</a>
&#x1F4C8; 1 <br>
<p>Yang Jiang, Zhe Xue, Ang Li</p></summary>
<p>

**Abstract:** In the era of big data, it is possible to carry out cooperative research on the research results of researchers through papers, patents and other data, so as to study the role of researchers, and produce results in the analysis of results. For the important problems found in the research and application of reality, this paper also proposes a research scholar interest mining algorithm based on load centrality (LCBIM), which can accurately solve the problem according to the researcher's research papers and patent data. Graphs of creative algorithms in various fields of the study aggregated ideas, generated topic graphs by aggregating neighborhoods, used the generated topic information to construct with similar or similar topic spaces, and utilize keywords to construct one or more topics. The regional structure of each topic can be used to closely calculate the weight of the centrality research model of the node, which can analyze the field in the complete coverage principle. The scientific research cooperation based on the load rate center proposed in this paper can effectively extract the interests of scientific research scholars from papers and corpus.

</p>
</details>

<details><summary><b>A Policy Driven AI-Assisted PoW Framework</b>
<a href="https://arxiv.org/abs/2203.10698">arxiv:2203.10698</a>
&#x1F4C8; 1 <br>
<p>Trisha Chakraborty, Shaswata Mitra, Sudip Mittal, Maxwell Young</p></summary>
<p>

**Abstract:** Proof of Work (PoW) based cyberdefense systems require incoming network requests to expend effort solving an arbitrary mathematical puzzle. Current state of the art is unable to differentiate between trustworthy and untrustworthy connections, requiring all to solve complex puzzles. In this paper, we introduce an Artificial Intelligence (AI)-assisted PoW framework that utilizes IP traffic based features to inform an adaptive issuer which can then generate puzzles with varying hardness. The modular framework uses these capabilities to ensure that untrustworthy clients solve harder puzzles thereby incurring longer latency than authentic requests to receive a response from the server. Our preliminary findings reveal our approach effectively throttles untrustworthy traffic.

</p>
</details>

<details><summary><b>Repairing Brain-Computer Interfaces with Fault-Based Data Acquisition</b>
<a href="https://arxiv.org/abs/2203.10677">arxiv:2203.10677</a>
&#x1F4C8; 1 <br>
<p>Cailin Winston, Caleb Winston, Chloe N Winston, Claris Winston, Cleah Winston, Rajesh PN Rao, René Just</p></summary>
<p>

**Abstract:** Brain-computer interfaces (BCIs) decode recorded neural signals from the brain and/or stimulate the brain with encoded neural signals. BCIs span both hardware and software and have a wide range of applications in restorative medicine, from restoring movement through prostheses and robotic limbs to restoring sensation and communication through spellers. BCIs also have applications in diagnostic medicine, e.g., providing clinicians with data for detecting seizures, sleep patterns, or emotions.
  Despite their promise, BCIs have not yet been adopted for long-term, day-to-day use because of challenges related to reliability and robustness, which are needed for safe operation in all scenarios. Ensuring safe operation currently requires hours of manual data collection and recalibration, involving both patients and clinicians. However, data collection is not targeted at eliminating specific faults in a BCI. This paper presents a new methodology for characterizing, detecting, and localizing faults in BCIs. Specifically, it proposes partial test oracles as a method for detecting faults and slice functions as a method for localizing faults to characteristic patterns in the input data or relevant tasks performed by the user. Through targeted data acquisition and retraining, the proposed methodology improves the correctness of BCIs. We evaluated the proposed methodology on five BCI applications. The results show that the proposed methodology (1) precisely localizes faults and (2) can significantly reduce the frequency of faults through retraining based on targeted, fault-based data acquisition. These results suggest that the proposed methodology is a promising step towards repairing faulty BCIs.

</p>
</details>

<details><summary><b>Model-based Multi-agent Reinforcement Learning: Recent Progress and Prospects</b>
<a href="https://arxiv.org/abs/2203.10603">arxiv:2203.10603</a>
&#x1F4C8; 1 <br>
<p>Xihuai Wang, Zhicheng Zhang, Weinan Zhang</p></summary>
<p>

**Abstract:** Significant advances have recently been achieved in Multi-Agent Reinforcement Learning (MARL) which tackles sequential decision-making problems involving multiple participants. However, MARL requires a tremendous number of samples for effective training. On the other hand, model-based methods have been shown to achieve provable advantages of sample efficiency. However, the attempts of model-based methods to MARL have just started very recently. This paper presents a review of the existing research on model-based MARL, including theoretical analyses, algorithms, and applications, and analyzes the advantages and potential of model-based MARL. Specifically, we provide a detailed taxonomy of the algorithms and point out the pros and cons for each algorithm according to the challenges inherent to multi-agent scenarios. We also outline promising directions for future development of this field.

</p>
</details>

<details><summary><b>The Dark Side: Security Concerns in Machine Learning for EDA</b>
<a href="https://arxiv.org/abs/2203.10597">arxiv:2203.10597</a>
&#x1F4C8; 1 <br>
<p>Zhiyao Xie, Jingyu Pan, Chen-Chia Chang, Yiran Chen</p></summary>
<p>

**Abstract:** The growing IC complexity has led to a compelling need for design efficiency improvement through new electronic design automation (EDA) methodologies. In recent years, many unprecedented efficient EDA methods have been enabled by machine learning (ML) techniques. While ML demonstrates its great potential in circuit design, however, the dark side about security problems, is seldomly discussed. This paper gives a comprehensive and impartial summary of all security concerns we have observed in ML for EDA. Many of them are hidden or neglected by practitioners in this field. In this paper, we first provide our taxonomy to define four major types of security concerns, then we analyze different application scenarios and special properties in ML for EDA. After that, we present our detailed analysis of each security concern with experiments.

</p>
</details>

<details><summary><b>Variational Quantum Policy Gradients with an Application to Quantum Control</b>
<a href="https://arxiv.org/abs/2203.10591">arxiv:2203.10591</a>
&#x1F4C8; 1 <br>
<p>André Sequeira, Luis Paulo Santos, Luís Soares Barbosa</p></summary>
<p>

**Abstract:** Quantum Machine Learning models are composed by Variational Quantum Circuits (VQCs) in a very natural way. There are already some empirical results proving that such models provide an advantage in supervised/unsupervised learning tasks. However, when applied to Reinforcement Learning (RL), less is known. In this work, we consider Policy Gradients using a hardware-efficient ansatz. We prove that the complexity of obtaining an ε-approximation of the gradient using quantum hardware scales only logarithmically with the number of parameters, considering the number of quantum circuits executions. We test the performance of such models in benchmarking environments and verify empirically that such quantum models outperform typical classical neural networks used in those environments, using a fraction of the number of parameters. Moreover, we propose the utilization of the Fisher Information spectrum to show that the quantum model is less prone to barren plateaus than its classical counterpart. As a different use case, we consider the application of such variational quantum models to the problem of quantum control and show its feasibility in the quantum-quantum domain.

</p>
</details>

<details><summary><b>Attention Aided CSI Wireless Localization</b>
<a href="https://arxiv.org/abs/2203.10506">arxiv:2203.10506</a>
&#x1F4C8; 1 <br>
<p>Artan Salihu, Stefan Schwarz, Markus Rupp</p></summary>
<p>

**Abstract:** Deep neural networks (DNNs) have become a popular approach for wireless localization based on channel state information (CSI). A common practice is to use the raw CSI in the input and allow the network to learn relevant channel representations for mapping to location information. However, various works show that raw CSI can be very sensitive to system impairments and small changes in the environment. On the contrary, hand-designing features may hinder the limits of channel representation learning of the DNN. In this work, we propose attention-based CSI for robust feature learning. We evaluate the performance of attended features in centralized and distributed massive MIMO systems for ray-tracing channels in two non-stationary railway track environments. By comparison to a base DNN, our approach provides exceptional performance.

</p>
</details>

<details><summary><b>Differentiable Reasoning over Long Stories -- Assessing Systematic Generalisation in Neural Models</b>
<a href="https://arxiv.org/abs/2203.10620">arxiv:2203.10620</a>
&#x1F4C8; 0 <br>
<p>Wanshui Li, Pasquale Minervini</p></summary>
<p>

**Abstract:** Contemporary neural networks have achieved a series of developments and successes in many aspects; however, when exposed to data outside the training distribution, they may fail to predict correct answers. In this work, we were concerned about this generalisation issue and thus analysed a broad set of models systematically and robustly over long stories. Related experiments were conducted based on the CLUTRR, which is a diagnostic benchmark suite that can analyse generalisation of natural language understanding (NLU) systems by training over small story graphs and testing on larger ones. In order to handle the multi-relational story graph, we consider two classes of neural models: "E-GNN", the graph-based models that can process graph-structured data and consider the edge attributes simultaneously; and "L-Graph", the sequence-based models which can process linearized version of the graphs. We performed an extensive empirical evaluation, and we found that the modified recurrent neural network yield surprisingly accurate results across every systematic generalisation tasks which outperform the modified graph neural network, while the latter produced more robust models.

</p>
</details>


{% endraw %}
Prev: [2022.03.19]({{ '/2022/03/19/2022.03.19.html' | relative_url }})  Next: [2022.03.21]({{ '/2022/03/21/2022.03.21.html' | relative_url }})