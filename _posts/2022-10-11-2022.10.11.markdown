Prev: [2022.10.10]({{ '/2022/10/10/2022.10.10.html' | relative_url }})  Next: [2022.10.12]({{ '/2022/10/12/2022.10.12.html' | relative_url }})
{% raw %}
## Summary for 2022-10-11, created on 2022-10-15


<details><summary><b>Mind's Eye: Grounded Language Model Reasoning through Simulation</b>
<a href="https://arxiv.org/abs/2210.05359">arxiv:2210.05359</a>
&#x1F4C8; 728 <br>
<p>Ruibo Liu, Jason Wei, Shixiang Shane Gu, Te-Yen Wu, Soroush Vosoughi, Claire Cui, Denny Zhou, Andrew M. Dai</p></summary>
<p>

**Abstract:** Successful and effective communication between humans and AI relies on a shared experience of the world. By training solely on written text, current language models (LMs) miss the grounded experience of humans in the real-world -- their failure to relate language to the physical world causes knowledge to be misrepresented and obvious mistakes in their reasoning. We present Mind's Eye, a paradigm to ground language model reasoning in the physical world. Given a physical reasoning question, we use a computational physics engine (DeepMind's MuJoCo) to simulate the possible outcomes, and then use the simulation results as part of the input, which enables language models to perform reasoning. Experiments on 39 tasks in a physics alignment benchmark demonstrate that Mind's Eye can improve reasoning ability by a large margin (27.9% zero-shot, and 46.0% few-shot absolute accuracy improvement on average). Smaller language models armed with Mind's Eye can obtain similar performance to models that are 100x larger. Finally, we confirm the robustness of Mind's Eye through ablation studies.

</p>
</details>

<details><summary><b>Pre-Training for Robots: Offline RL Enables Learning New Tasks from a Handful of Trials</b>
<a href="https://arxiv.org/abs/2210.05178">arxiv:2210.05178</a>
&#x1F4C8; 515 <br>
<p>Aviral Kumar, Anikait Singh, Frederik Ebert, Yanlai Yang, Chelsea Finn, Sergey Levine</p></summary>
<p>

**Abstract:** Recent progress in deep learning highlights the tremendous potential of utilizing diverse datasets for achieving effective generalization and makes it enticing to consider leveraging broad datasets for attaining more robust generalization in robotic learning as well. However, in practice we likely will want to learn a new skill in a new environment that is unlikely to be contained in the prior data. Therefore we ask: how can we leverage existing diverse offline datasets in combination with small amounts of task-specific data to solve new tasks, while still enjoying the generalization benefits of training on large amounts of data? In this paper, we demonstrate that end-to-end offline RL can be an effective approach for doing this, without the need for any representation learning or vision-based pre-training. We present pre-training for robots (PTR), a framework based on offline RL that attempts to effectively learn new tasks by combining pre-training on existing robotic datasets with rapid fine-tuning on a new task, with as a few as 10 demonstrations. At its core, PTR applies an existing offline RL method such as conservative Q-learning (CQL), but extends it to include several crucial design decisions that enable PTR to actually work and outperform a variety of prior methods. To the best of our knowledge, PTR is the first offline RL method that succeeds at learning new tasks in a new domain on a real WidowX robot with as few as 10 task demonstrations, by effectively leveraging an existing dataset of diverse multi-task robot data collected in a variety of toy kitchens. Our implementation can be found at: https://github.com/Asap7772/PTR.

</p>
</details>

<details><summary><b>Disentangling Causal Effects from Sets of Interventions in the Presence of Unobserved Confounders</b>
<a href="https://arxiv.org/abs/2210.05446">arxiv:2210.05446</a>
&#x1F4C8; 107 <br>
<p>Olivier Jeunen, Ciar√°n M. Gilligan-Lee, Rishabh Mehrotra, Mounia Lalmas</p></summary>
<p>

**Abstract:** The ability to answer causal questions is crucial in many domains, as causal inference allows one to understand the impact of interventions. In many applications, only a single intervention is possible at a given time. However, in some important areas, multiple interventions are concurrently applied. Disentangling the effects of single interventions from jointly applied interventions is a challenging task -- especially as simultaneously applied interventions can interact. This problem is made harder still by unobserved confounders, which influence both treatments and outcome. We address this challenge by aiming to learn the effect of a single-intervention from both observational data and sets of interventions. We prove that this is not generally possible, but provide identification proofs demonstrating that it can be achieved under non-linear continuous structural causal models with additive, multivariate Gaussian noise -- even when unobserved confounders are present. Importantly, we show how to incorporate observed covariates and learn heterogeneous treatment effects. Based on the identifiability proofs, we provide an algorithm that learns the causal model parameters by pooling data from different regimes and jointly maximizing the combined likelihood. The effectiveness of our method is empirically demonstrated on both synthetic and real-world data.

</p>
</details>

<details><summary><b>GENIE: Higher-Order Denoising Diffusion Solvers</b>
<a href="https://arxiv.org/abs/2210.05475">arxiv:2210.05475</a>
&#x1F4C8; 100 <br>
<p>Tim Dockhorn, Arash Vahdat, Karsten Kreis</p></summary>
<p>

**Abstract:** Denoising diffusion models (DDMs) have emerged as a powerful class of generative models. A forward diffusion process slowly perturbs the data, while a deep model learns to gradually denoise. Synthesis amounts to solving a differential equation (DE) defined by the learnt model. Solving the DE requires slow iterative solvers for high-quality generation. In this work, we propose Higher-Order Denoising Diffusion Solvers (GENIE): Based on truncated Taylor methods, we derive a novel higher-order solver that significantly accelerates synthesis. Our solver relies on higher-order gradients of the perturbed data distribution, that is, higher-order score functions. In practice, only Jacobian-vector products (JVPs) are required and we propose to extract them from the first-order score network via automatic differentiation. We then distill the JVPs into a separate neural network that allows us to efficiently compute the necessary higher-order terms for our novel sampler during synthesis. We only need to train a small additional head on top of the first-order score network. We validate GENIE on multiple image generation benchmarks and demonstrate that GENIE outperforms all previous solvers. Unlike recent methods that fundamentally alter the generation process in DDMs, our GENIE solves the true generative DE and still enables applications such as encoding and guided sampling. Project page and code: https://nv-tlabs.github.io/GENIE.

</p>
</details>

<details><summary><b>Unifying Diffusion Models' Latent Space, with Applications to CycleDiffusion and Guidance</b>
<a href="https://arxiv.org/abs/2210.05559">arxiv:2210.05559</a>
&#x1F4C8; 92 <br>
<p>Chen Henry Wu, Fernando De la Torre</p></summary>
<p>

**Abstract:** Diffusion models have achieved unprecedented performance in generative modeling. The commonly-adopted formulation of the latent code of diffusion models is a sequence of gradually denoised samples, as opposed to the simpler (e.g., Gaussian) latent space of GANs, VAEs, and normalizing flows. This paper provides an alternative, Gaussian formulation of the latent space of various diffusion models, as well as an invertible DPM-Encoder that maps images into the latent space. While our formulation is purely based on the definition of diffusion models, we demonstrate several intriguing consequences. (1) Empirically, we observe that a common latent space emerges from two diffusion models trained independently on related domains. In light of this finding, we propose CycleDiffusion, which uses DPM-Encoder for unpaired image-to-image translation. Furthermore, applying CycleDiffusion to text-to-image diffusion models, we show that large-scale text-to-image diffusion models can be used as zero-shot image-to-image editors. (2) One can guide pre-trained diffusion models and GANs by controlling the latent codes in a unified, plug-and-play formulation based on energy-based models. Using the CLIP model and a face recognition model as guidance, we demonstrate that diffusion models have better coverage of low-density sub-populations and individuals than GANs.

</p>
</details>

<details><summary><b>MTet: Multi-domain Translation for English and Vietnamese</b>
<a href="https://arxiv.org/abs/2210.05610">arxiv:2210.05610</a>
&#x1F4C8; 51 <br>
<p>Chinh Ngo, Trieu H. Trinh, Long Phan, Hieu Tran, Tai Dang, Hieu Nguyen, Minh Nguyen, Minh-Thang Luong</p></summary>
<p>

**Abstract:** We introduce MTet, the largest publicly available parallel corpus for English-Vietnamese translation. MTet consists of 4.2M high-quality training sentence pairs and a multi-domain test set refined by the Vietnamese research community. Combining with previous works on English-Vietnamese translation, we grow the existing parallel dataset to 6.2M sentence pairs. We also release the first pretrained model EnViT5 for English and Vietnamese languages. Combining both resources, our model significantly outperforms previous state-of-the-art results by up to 2 points in translation BLEU score, while being 1.6 times smaller.

</p>
</details>

<details><summary><b>Markup-to-Image Diffusion Models with Scheduled Sampling</b>
<a href="https://arxiv.org/abs/2210.05147">arxiv:2210.05147</a>
&#x1F4C8; 39 <br>
<p>Yuntian Deng, Noriyuki Kojima, Alexander M. Rush</p></summary>
<p>

**Abstract:** Building on recent advances in image generation, we present a fully data-driven approach to rendering markup into images. The approach is based on diffusion models, which parameterize the distribution of data using a sequence of denoising operations on top of a Gaussian noise distribution. We view the diffusion denoising process as a sequential decision making process, and show that it exhibits compounding errors similar to exposure bias issues in imitation learning problems. To mitigate these issues, we adapt the scheduled sampling algorithm to diffusion training. We conduct experiments on four markup datasets: mathematical formulas (LaTeX), table layouts (HTML), sheet music (LilyPond), and molecular images (SMILES). These experiments each verify the effectiveness of the diffusion process and the use of scheduled sampling to fix generation issues. These results also show that the markup-to-image task presents a useful controlled compositional setting for diagnosing and analyzing generative image models.

</p>
</details>

<details><summary><b>Discovered Policy Optimisation</b>
<a href="https://arxiv.org/abs/2210.05639">arxiv:2210.05639</a>
&#x1F4C8; 38 <br>
<p>Chris Lu, Jakub Grudzien Kuba, Alistair Letcher, Luke Metz, Christian Schroeder de Witt, Jakob Foerster</p></summary>
<p>

**Abstract:** Tremendous progress has been made in reinforcement learning (RL) over the past decade. Most of these advancements came through the continual development of new algorithms, which were designed using a combination of mathematical derivations, intuitions, and experimentation. Such an approach of creating algorithms manually is limited by human understanding and ingenuity. In contrast, meta-learning provides a toolkit for automatic machine learning method optimisation, potentially addressing this flaw. However, black-box approaches which attempt to discover RL algorithms with minimal prior structure have thus far not outperformed existing hand-crafted algorithms. Mirror Learning, which includes RL algorithms, such as PPO, offers a potential middle-ground starting point: while every method in this framework comes with theoretical guarantees, components that differentiate them are subject to design. In this paper we explore the Mirror Learning space by meta-learning a "drift" function. We refer to the immediate result as Learnt Policy Optimisation (LPO). By analysing LPO we gain original insights into policy optimisation which we use to formulate a novel, closed-form RL algorithm, Discovered Policy Optimisation (DPO). Our experiments in Brax environments confirm state-of-the-art performance of LPO and DPO, as well as their transfer to unseen settings.

</p>
</details>

<details><summary><b>CLIP-Fields: Weakly Supervised Semantic Fields for Robotic Memory</b>
<a href="https://arxiv.org/abs/2210.05663">arxiv:2210.05663</a>
&#x1F4C8; 21 <br>
<p>Nur Muhammad Mahi Shafiullah, Chris Paxton, Lerrel Pinto, Soumith Chintala, Arthur Szlam</p></summary>
<p>

**Abstract:** We propose CLIP-Fields, an implicit scene model that can be trained with no direct human supervision. This model learns a mapping from spatial locations to semantic embedding vectors. The mapping can then be used for a variety of tasks, such as segmentation, instance identification, semantic search over space, and view localization. Most importantly, the mapping can be trained with supervision coming only from web-image and web-text trained models such as CLIP, Detic, and Sentence-BERT. When compared to baselines like Mask-RCNN, our method outperforms on few-shot instance identification or semantic segmentation on the HM3D dataset with only a fraction of the examples. Finally, we show that using CLIP-Fields as a scene memory, robots can perform semantic navigation in real-world environments. Our code and demonstrations are available here: https://mahis.life/clip-fields/

</p>
</details>

<details><summary><b>The Unreasonable Effectiveness of Fully-Connected Layers for Low-Data Regimes</b>
<a href="https://arxiv.org/abs/2210.05657">arxiv:2210.05657</a>
&#x1F4C8; 19 <br>
<p>Peter Kocsis, Peter S√∫ken√≠k, Guillem Bras√≥, Matthias Nie√üner, Laura Leal-Taix√©, Ismail Elezi</p></summary>
<p>

**Abstract:** Convolutional neural networks were the standard for solving many computer vision tasks until recently, when Transformers of MLP-based architectures have started to show competitive performance. These architectures typically have a vast number of weights and need to be trained on massive datasets; hence, they are not suitable for their use in low-data regimes. In this work, we propose a simple yet effective framework to improve generalization from small amounts of data. We augment modern CNNs with fully-connected (FC) layers and show the massive impact this architectural change has in low-data regimes. We further present an online joint knowledge-distillation method to utilize the extra FC layers at train time but avoid them during test time. This allows us to improve the generalization of a CNN-based model without any increase in the number of weights at test time. We perform classification experiments for a large range of network backbones and several standard datasets on supervised learning and active learning. Our experiments significantly outperform the networks without fully-connected layers, reaching a relative improvement of up to $16\%$ validation accuracy in the supervised setting without adding any extra parameters during inference.

</p>
</details>

<details><summary><b>Transformers generalize differently from information stored in context vs in weights</b>
<a href="https://arxiv.org/abs/2210.05675">arxiv:2210.05675</a>
&#x1F4C8; 13 <br>
<p>Stephanie C. Y. Chan, Ishita Dasgupta, Junkyung Kim, Dharshan Kumaran, Andrew K. Lampinen, Felix Hill</p></summary>
<p>

**Abstract:** Transformer models can use two fundamentally different kinds of information: information stored in weights during training, and information provided ``in-context'' at inference time. In this work, we show that transformers exhibit different inductive biases in how they represent and generalize from the information in these two sources. In particular, we characterize whether they generalize via parsimonious rules (rule-based generalization) or via direct comparison with observed examples (exemplar-based generalization). This is of important practical consequence, as it informs whether to encode information in weights or in context, depending on how we want models to use that information. In transformers trained on controlled stimuli, we find that generalization from weights is more rule-based whereas generalization from context is largely exemplar-based. In contrast, we find that in transformers pre-trained on natural language, in-context learning is significantly rule-based, with larger models showing more rule-basedness. We hypothesise that rule-based generalization from in-context information might be an emergent consequence of large-scale training on language, which has sparse rule-like structure. Using controlled stimuli, we verify that transformers pretrained on data containing sparse rule-like structure exhibit more rule-based generalization.

</p>
</details>

<details><summary><b>Human Body Measurement Estimation with Adversarial Augmentation</b>
<a href="https://arxiv.org/abs/2210.05667">arxiv:2210.05667</a>
&#x1F4C8; 9 <br>
<p>Nataniel Ruiz, Miriam Bellver, Timo Bolkart, Ambuj Arora, Ming C. Lin, Javier Romero, Raja Bala</p></summary>
<p>

**Abstract:** We present a Body Measurement network (BMnet) for estimating 3D anthropomorphic measurements of the human body shape from silhouette images. Training of BMnet is performed on data from real human subjects, and augmented with a novel adversarial body simulator (ABS) that finds and synthesizes challenging body shapes. ABS is based on the skinned multiperson linear (SMPL) body model, and aims to maximize BMnet measurement prediction error with respect to latent SMPL shape parameters. ABS is fully differentiable with respect to these parameters, and trained end-to-end via backpropagation with BMnet in the loop. Experiments show that ABS effectively discovers adversarial examples, such as bodies with extreme body mass indices (BMI), consistent with the rarity of extreme-BMI bodies in BMnet's training set. Thus ABS is able to reveal gaps in training data and potential failures in predicting under-represented body shapes. Results show that training BMnet with ABS improves measurement prediction accuracy on real bodies by up to 10%, when compared to no augmentation or random body shape sampling. Furthermore, our method significantly outperforms SOTA measurement estimation methods by as much as 3x. Finally, we release BodyM, the first challenging, large-scale dataset of photo silhouettes and body measurements of real human subjects, to further promote research in this area. Project website: https://adversarialbodysim.github.io

</p>
</details>

<details><summary><b>Semantic Segmentation under Adverse Conditions: A Weather and Nighttime-aware Synthetic Data-based Approach</b>
<a href="https://arxiv.org/abs/2210.05626">arxiv:2210.05626</a>
&#x1F4C8; 9 <br>
<p>Abdulrahman Kerim, Felipe Chamone, Washington Ramos, Leandro Soriano Marcolino, Erickson R. Nascimento, Richard Jiang</p></summary>
<p>

**Abstract:** Recent semantic segmentation models perform well under standard weather conditions and sufficient illumination but struggle with adverse weather conditions and nighttime. Collecting and annotating training data under these conditions is expensive, time-consuming, error-prone, and not always practical. Usually, synthetic data is used as a feasible data source to increase the amount of training data. However, just directly using synthetic data may actually harm the model's performance under normal weather conditions while getting only small gains in adverse situations. Therefore, we present a novel architecture specifically designed for using synthetic training data for domain adaptation. We propose a simple yet powerful addition to DeepLabV3+ by using weather and time-of-the-day supervisors trained with multi-task learning, making it both weather and nighttime aware, which improves its mIoU accuracy by $14$ percentage points on the ACDC dataset while maintaining a score of $75\%$ mIoU on the Cityscapes dataset. Our code is available at https://github.com/lsmcolab/Semantic-Segmentation-under-Adverse-Conditions.

</p>
</details>

<details><summary><b>SGD with large step sizes learns sparse features</b>
<a href="https://arxiv.org/abs/2210.05337">arxiv:2210.05337</a>
&#x1F4C8; 9 <br>
<p>Maksym Andriushchenko, Aditya Varre, Loucas Pillaud-Vivien, Nicolas Flammarion</p></summary>
<p>

**Abstract:** We showcase important features of the dynamics of the Stochastic Gradient Descent (SGD) in the training of neural networks. We present empirical observations that commonly used large step sizes (i) lead the iterates to jump from one side of a valley to the other causing loss stabilization, and (ii) this stabilization induces a hidden stochastic dynamics orthogonal to the bouncing directions that biases it implicitly toward simple predictors. Furthermore, we show empirically that the longer large step sizes keep SGD high in the loss landscape valleys, the better the implicit regularization can operate and find sparse representations. Notably, no explicit regularization is used so that the regularization effect comes solely from the SGD training dynamics influenced by the step size schedule. Therefore, these observations unveil how, through the step size schedules, both gradient and noise drive together the SGD dynamics through the loss landscape of neural networks. We justify these findings theoretically through the study of simple neural network models as well as qualitative arguments inspired from stochastic processes. Finally, this analysis allows to shed a new light on some common practice and observed phenomena when training neural networks. The code of our experiments is available at https://github.com/tml-epfl/sgd-sparse-features.

</p>
</details>

<details><summary><b>Digitization of Raster Logs: A Deep Learning Approach</b>
<a href="https://arxiv.org/abs/2210.05597">arxiv:2210.05597</a>
&#x1F4C8; 8 <br>
<p>M Quamer Nasim, Narendra Patwardhan, Tannistha Maiti, Tarry Singh</p></summary>
<p>

**Abstract:** Raster well-log images are digital representations of well-logs data generated over the years. Raster digital well logs represent bitmaps of the log image in a rectangular array of black (zeros) and white dots (ones) called pixels. Experts study the raster logs manually or with software applications that still require a tremendous amount of manual input. Besides the loss of thousands of person-hours, this process is erroneous and tedious. To digitize these raster logs, one must buy a costly digitizer that is not only manual and time-consuming but also a hidden technical debt since enterprises stand to lose more money in additional servicing and consulting charges. We propose a deep neural network architecture called VeerNet to semantically segment the raster images from the background grid and classify and digitize the well-log curves. Raster logs have a substantially greater resolution than images traditionally consumed by image segmentation pipelines. Since the input has a low signal-to-resolution ratio, we require rapid downsampling to alleviate unnecessary computation. We thus employ a modified UNet-inspired architecture that balances retaining key signals and reducing result dimensionality. We use attention augmented read-process-write architecture. This architecture efficiently classifies and digitizes the curves with an overall F1 score of 35% and IoU of 30%. When compared to the actual las values for Gamma-ray and derived value of Gamma-ray from VeerNet, a high Pearson coefficient score of 0.62 was achieved.

</p>
</details>

<details><summary><b>Benefits of Permutation-Equivariance in Auction Mechanisms</b>
<a href="https://arxiv.org/abs/2210.05579">arxiv:2210.05579</a>
&#x1F4C8; 8 <br>
<p>Tian Qin, Fengxiang He, Dingfeng Shi, Wenbing Huang, Dacheng Tao</p></summary>
<p>

**Abstract:** Designing an incentive-compatible auction mechanism that maximizes the auctioneer's revenue while minimizes the bidders' ex-post regret is an important yet intricate problem in economics. Remarkable progress has been achieved through learning the optimal auction mechanism by neural networks. In this paper, we consider the popular additive valuation and symmetric valuation setting; i.e., the valuation for a set of items is defined as the sum of all items' valuations in the set, and the valuation distribution is invariant when the bidders and/or the items are permutated. We prove that permutation-equivariant neural networks have significant advantages: the permutation-equivariance decreases the expected ex-post regret, improves the model generalizability, while maintains the expected revenue invariant. This implies that the permutation-equivariance helps approach the theoretically optimal dominant strategy incentive compatible condition, and reduces the required sample complexity for desired generalization. Extensive experiments fully support our theory. To our best knowledge, this is the first work towards understanding the benefits of permutation-equivariance in auction mechanisms.

</p>
</details>

<details><summary><b>OPERA: Omni-Supervised Representation Learning with Hierarchical Supervisions</b>
<a href="https://arxiv.org/abs/2210.05557">arxiv:2210.05557</a>
&#x1F4C8; 8 <br>
<p>Chengkun Wang, Wenzhao Zheng, Zheng Zhu, Jie Zhou, Jiwen Lu</p></summary>
<p>

**Abstract:** The pretrain-finetune paradigm in modern computer vision facilitates the success of self-supervised learning, which tends to achieve better transferability than supervised learning. However, with the availability of massive labeled data, a natural question emerges: how to train a better model with both self and full supervision signals? In this paper, we propose Omni-suPErvised Representation leArning with hierarchical supervisions (OPERA) as a solution. We provide a unified perspective of supervisions from labeled and unlabeled data and propose a unified framework of fully supervised and self-supervised learning. We extract a set of hierarchical proxy representations for each image and impose self and full supervisions on the corresponding proxy representations. Extensive experiments on both convolutional neural networks and vision transformers demonstrate the superiority of OPERA in image classification, segmentation, and object detection. Code is available at: https://github.com/wangck20/OPERA.

</p>
</details>

<details><summary><b>What does a deep neural network confidently perceive? The effective dimension of high certainty class manifolds and their low confidence boundaries</b>
<a href="https://arxiv.org/abs/2210.05546">arxiv:2210.05546</a>
&#x1F4C8; 8 <br>
<p>Stanislav Fort, Ekin Dogus Cubuk, Surya Ganguli, Samuel S. Schoenholz</p></summary>
<p>

**Abstract:** Deep neural network classifiers partition input space into high confidence regions for each class. The geometry of these class manifolds (CMs) is widely studied and intimately related to model performance; for example, the margin depends on CM boundaries. We exploit the notions of Gaussian width and Gordon's escape theorem to tractably estimate the effective dimension of CMs and their boundaries through tomographic intersections with random affine subspaces of varying dimension. We show several connections between the dimension of CMs, generalization, and robustness. In particular we investigate how CM dimension depends on 1) the dataset, 2) architecture (including ResNet, WideResNet \& Vision Transformer), 3) initialization, 4) stage of training, 5) class, 6) network width, 7) ensemble size, 8) label randomization, 9) training set size, and 10) robustness to data corruption. Together a picture emerges that higher performing and more robust models have higher dimensional CMs. Moreover, we offer a new perspective on ensembling via intersections of CMs. Our code is at https://github.com/stanislavfort/slice-dice-optimize/

</p>
</details>

<details><summary><b>Mastering the Game of No-Press Diplomacy via Human-Regularized Reinforcement Learning and Planning</b>
<a href="https://arxiv.org/abs/2210.05492">arxiv:2210.05492</a>
&#x1F4C8; 8 <br>
<p>Anton Bakhtin, David J Wu, Adam Lerer, Jonathan Gray, Athul Paul Jacob, Gabriele Farina, Alexander H Miller, Noam Brown</p></summary>
<p>

**Abstract:** No-press Diplomacy is a complex strategy game involving both cooperation and competition that has served as a benchmark for multi-agent AI research. While self-play reinforcement learning has resulted in numerous successes in purely adversarial games like chess, Go, and poker, self-play alone is insufficient for achieving optimal performance in domains involving cooperation with humans. We address this shortcoming by first introducing a planning algorithm we call DiL-piKL that regularizes a reward-maximizing policy toward a human imitation-learned policy. We prove that this is a no-regret learning algorithm under a modified utility function. We then show that DiL-piKL can be extended into a self-play reinforcement learning algorithm we call RL-DiL-piKL that provides a model of human play while simultaneously training an agent that responds well to this human model. We used RL-DiL-piKL to train an agent we name Diplodocus. In a 200-game no-press Diplomacy tournament involving 62 human participants spanning skill levels from beginner to expert, two Diplodocus agents both achieved a higher average score than all other participants who played more than two games, and ranked first and third according to an Elo ratings model.

</p>
</details>

<details><summary><b>GAN You Hear Me? Reclaiming Unconditional Speech Synthesis from Diffusion Models</b>
<a href="https://arxiv.org/abs/2210.05271">arxiv:2210.05271</a>
&#x1F4C8; 8 <br>
<p>Matthew Baas, Herman Kamper</p></summary>
<p>

**Abstract:** We propose AudioStyleGAN (ASGAN), a new generative adversarial network (GAN) for unconditional speech synthesis. As in the StyleGAN family of image synthesis models, ASGAN maps sampled noise to a disentangled latent vector which is then mapped to a sequence of audio features so that signal aliasing is suppressed at every layer. To successfully train ASGAN, we introduce a number of new techniques, including a modification to adaptive discriminator augmentation to probabilistically skip discriminator updates. ASGAN achieves state-of-the-art results in unconditional speech synthesis on the Google Speech Commands dataset. It is also substantially faster than the top-performing diffusion models. Through a design that encourages disentanglement, ASGAN is able to perform voice conversion and speech editing without being explicitly trained to do so. ASGAN demonstrates that GANs are still highly competitive with diffusion models. Code, models, samples: https://github.com/RF5/simple-asgan/.

</p>
</details>

<details><summary><b>Motion Aware Self-Supervision for Generic Event Boundary Detection</b>
<a href="https://arxiv.org/abs/2210.05574">arxiv:2210.05574</a>
&#x1F4C8; 7 <br>
<p>Ayush K. Rai, Tarun Krishna, Julia Dietlmeier, Kevin McGuinness, Alan F. Smeaton, Noel E. O'Connor</p></summary>
<p>

**Abstract:** The task of Generic Event Boundary Detection (GEBD) aims to detect moments in videos that are naturally perceived by humans as generic and taxonomy-free event boundaries. Modeling the dynamically evolving temporal and spatial changes in a video makes GEBD a difficult problem to solve. Existing approaches involve very complex and sophisticated pipelines in terms of architectural design choices, hence creating a need for more straightforward and simplified approaches. In this work, we address this issue by revisiting a simple and effective self-supervised method and augment it with a differentiable motion feature learning module to tackle the spatial and temporal diversities in the GEBD task. We perform extensive experiments on the challenging Kinetics-GEBD and TAPOS datasets to demonstrate the efficacy of the proposed approach compared to the other self-supervised state-of-the-art methods. We also show that this simple self-supervised approach learns motion features without any explicit motion-specific pretext task.

</p>
</details>

<details><summary><b>Causal and counterfactual views of missing data models</b>
<a href="https://arxiv.org/abs/2210.05558">arxiv:2210.05558</a>
&#x1F4C8; 7 <br>
<p>Razieh Nabi, Rohit Bhattacharya, Ilya Shpitser, James Robins</p></summary>
<p>

**Abstract:** It is often said that the fundamental problem of causal inference is a missing data problem -- the comparison of responses to two hypothetical treatment assignments is made difficult because for every experimental unit only one potential response is observed. In this paper, we consider the implications of the converse view: that missing data problems are a form of causal inference. We make explicit how the missing data problem of recovering the complete data law from the observed law can be viewed as identification of a joint distribution over counterfactual variables corresponding to values had we (possibly contrary to fact) been able to observe them. Drawing analogies with causal inference, we show how identification assumptions in missing data can be encoded in terms of graphical models defined over counterfactual and observed variables. We review recent results in missing data identification from this viewpoint. In doing so, we note interesting similarities and differences between missing data and causal identification theories.

</p>
</details>

<details><summary><b>COVID-19-related Nepali Tweets Classification in a Low Resource Setting</b>
<a href="https://arxiv.org/abs/2210.05425">arxiv:2210.05425</a>
&#x1F4C8; 7 <br>
<p>Rabin Adhikari, Safal Thapaliya, Nirajan Basnet, Samip Poudel, Aman Shakya, Bishesh Khanal</p></summary>
<p>

**Abstract:** Billions of people across the globe have been using social media platforms in their local languages to voice their opinions about the various topics related to the COVID-19 pandemic. Several organizations, including the World Health Organization, have developed automated social media analysis tools that classify COVID-19-related tweets into various topics. However, these tools that help combat the pandemic are limited to very few languages, making several countries unable to take their benefit. While multi-lingual or low-resource language-specific tools are being developed, they still need to expand their coverage, such as for the Nepali language. In this paper, we identify the eight most common COVID-19 discussion topics among the Twitter community using the Nepali language, set up an online platform to automatically gather Nepali tweets containing the COVID-19-related keywords, classify the tweets into the eight topics, and visualize the results across the period in a web-based dashboard. We compare the performance of two state-of-the-art multi-lingual language models for Nepali tweet classification, one generic (mBERT) and the other Nepali language family-specific model (MuRIL). Our results show that the models' relative performance depends on the data size, with MuRIL doing better for a larger dataset. The annotated data, models, and the web-based dashboard are open-sourced at https://github.com/naamiinepal/covid-tweet-classification.

</p>
</details>

<details><summary><b>Knowledge-Driven New Drug Recommendation</b>
<a href="https://arxiv.org/abs/2210.05572">arxiv:2210.05572</a>
&#x1F4C8; 6 <br>
<p>Zhenbang Wu, Huaxiu Yao, Zhe Su, David M Liebovitz, Lucas M Glass, James Zou, Chelsea Finn, Jimeng Sun</p></summary>
<p>

**Abstract:** Drug recommendation assists doctors in prescribing personalized medications to patients based on their health conditions. Existing drug recommendation solutions adopt the supervised multi-label classification setup and only work with existing drugs with sufficient prescription data from many patients. However, newly approved drugs do not have much historical prescription data and cannot leverage existing drug recommendation methods. To address this, we formulate the new drug recommendation as a few-shot learning problem. Yet, directly applying existing few-shot learning algorithms faces two challenges: (1) complex relations among diseases and drugs and (2) numerous false-negative patients who were eligible but did not yet use the new drugs. To tackle these challenges, we propose EDGE, which can quickly adapt to the recommendation for a new drug with limited prescription data from a few support patients. EDGE maintains a drug-dependent multi-phenotype few-shot learner to bridge the gap between existing and new drugs. Specifically, EDGE leverages the drug ontology to link new drugs to existing drugs with similar treatment effects and learns ontology-based drug representations. Such drug representations are used to customize the metric space of the phenotype-driven patient representations, which are composed of a set of phenotypes capturing complex patient health status. Lastly, EDGE eliminates the false-negative supervision signal using an external drug-disease knowledge base. We evaluate EDGE on two real-world datasets: the public EHR data (MIMIC-IV) and private industrial claims data. Results show that EDGE achieves 7.3% improvement on the ROC-AUC score over the best baseline.

</p>
</details>

<details><summary><b>Continual Training of Language Models for Few-Shot Learning</b>
<a href="https://arxiv.org/abs/2210.05549">arxiv:2210.05549</a>
&#x1F4C8; 6 <br>
<p>Zixuan Ke, Haowei Lin, Yijia Shao, Hu Xu, Lei Shu, Bing Liu</p></summary>
<p>

**Abstract:** Recent work on applying large language models (LMs) achieves impressive performance in many NLP applications. Adapting or posttraining an LM using an unlabeled domain corpus can produce even better performance for end-tasks in the domain. This paper proposes the problem of continually extending an LM by incrementally post-train the LM with a sequence of unlabeled domain corpora to expand its knowledge without forgetting its previous skills. The goal is to improve the few-shot end-task learning in these domains. The resulting system is called CPT (Continual PostTraining), which to our knowledge, is the first continual post-training system. Experimental results verify its effectiveness.

</p>
</details>

<details><summary><b>Frequency-Aware Self-Supervised Monocular Depth Estimation</b>
<a href="https://arxiv.org/abs/2210.05479">arxiv:2210.05479</a>
&#x1F4C8; 6 <br>
<p>Xingyu Chen, Thomas H. Li, Ruonan Zhang, Ge Li</p></summary>
<p>

**Abstract:** We present two versatile methods to generally enhance self-supervised monocular depth estimation (MDE) models. The high generalizability of our methods is achieved by solving the fundamental and ubiquitous problems in photometric loss function. In particular, from the perspective of spatial frequency, we first propose Ambiguity-Masking to suppress the incorrect supervision under photometric loss at specific object boundaries, the cause of which could be traced to pixel-level ambiguity. Second, we present a novel frequency-adaptive Gaussian low-pass filter, designed to robustify the photometric loss in high-frequency regions. We are the first to propose blurring images to improve depth estimators with an interpretable analysis. Both modules are lightweight, adding no parameters and no need to manually change the network structures. Experiments show that our methods provide performance boosts to a large number of existing models, including those who claimed state-of-the-art, while introducing no extra inference computation at all.

</p>
</details>

<details><summary><b>Aggregating Layers for Deepfake Detection</b>
<a href="https://arxiv.org/abs/2210.05478">arxiv:2210.05478</a>
&#x1F4C8; 6 <br>
<p>Amir Jevnisek, Shai Avidan</p></summary>
<p>

**Abstract:** The increasing popularity of facial manipulation (Deepfakes) and synthetic face creation raises the need to develop robust forgery detection solutions. Crucially, most work in this domain assume that the Deepfakes in the test set come from the same Deepfake algorithms that were used for training the network. This is not how things work in practice. Instead, we consider the case where the network is trained on one Deepfake algorithm, and tested on Deepfakes generated by another algorithm. Typically, supervised techniques follow a pipeline of visual feature extraction from a deep backbone, followed by a binary classification head. Instead, our algorithm aggregates features extracted across all layers of one backbone network to detect a fake. We evaluate our approach on two domains of interest - Deepfake detection and Synthetic image detection, and find that we achieve SOTA results.

</p>
</details>

<details><summary><b>DHRL: A Graph-Based Approach for Long-Horizon and Sparse Hierarchical Reinforcement Learning</b>
<a href="https://arxiv.org/abs/2210.05150">arxiv:2210.05150</a>
&#x1F4C8; 6 <br>
<p>Seungjae Lee, Jigang Kim, Inkyu Jang, H. Jin Kim</p></summary>
<p>

**Abstract:** Hierarchical Reinforcement Learning (HRL) has made notable progress in complex control tasks by leveraging temporal abstraction. However, previous HRL algorithms often suffer from serious data inefficiency as environments get large. The extended components, $i.e.$, goal space and length of episodes, impose a burden on either one or both high-level and low-level policies since both levels share the total horizon of the episode. In this paper, we present a method of Decoupling Horizons Using a Graph in Hierarchical Reinforcement Learning (DHRL) which can alleviate this problem by decoupling the horizons of high-level and low-level policies and bridging the gap between the length of both horizons using a graph. DHRL provides a freely stretchable high-level action interval, which facilitates longer temporal abstraction and faster training in complex tasks. Our method outperforms state-of-the-art HRL algorithms in typical HRL environments. Moreover, DHRL achieves long and complex locomotion and manipulation tasks.

</p>
</details>

<details><summary><b>Visual Language Maps for Robot Navigation</b>
<a href="https://arxiv.org/abs/2210.05714">arxiv:2210.05714</a>
&#x1F4C8; 5 <br>
<p>Chenguang Huang, Oier Mees, Andy Zeng, Wolfram Burgard</p></summary>
<p>

**Abstract:** Grounding language to the visual observations of a navigating agent can be performed using off-the-shelf visual-language models pretrained on Internet-scale data (e.g., image captions). While this is useful for matching images to natural language descriptions of object goals, it remains disjoint from the process of mapping the environment, so that it lacks the spatial precision of classic geometric maps. To address this problem, we propose VLMaps, a spatial map representation that directly fuses pretrained visual-language features with a 3D reconstruction of the physical world. VLMaps can be autonomously built from video feed on robots using standard exploration approaches and enables natural language indexing of the map without additional labeled data. Specifically, when combined with large language models (LLMs), VLMaps can be used to (i) translate natural language commands into a sequence of open-vocabulary navigation goals (which, beyond prior work, can be spatial by construction, e.g., "in between the sofa and TV" or "three meters to the right of the chair") directly localized in the map, and (ii) can be shared among multiple robots with different embodiments to generate new obstacle maps on-the-fly (by using a list of obstacle categories). Extensive experiments carried out in simulated and real world environments show that VLMaps enable navigation according to more complex language instructions than existing methods. Videos are available at https://vlmaps.github.io.

</p>
</details>

<details><summary><b>HiFECap: Monocular High-Fidelity and Expressive Capture of Human Performances</b>
<a href="https://arxiv.org/abs/2210.05665">arxiv:2210.05665</a>
&#x1F4C8; 5 <br>
<p>Yue Jiang, Marc Habermann, Vladislav Golyanik, Christian Theobalt</p></summary>
<p>

**Abstract:** Monocular 3D human performance capture is indispensable for many applications in computer graphics and vision for enabling immersive experiences. However, detailed capture of humans requires tracking of multiple aspects, including the skeletal pose, the dynamic surface, which includes clothing, hand gestures as well as facial expressions. No existing monocular method allows joint tracking of all these components. To this end, we propose HiFECap, a new neural human performance capture approach, which simultaneously captures human pose, clothing, facial expression, and hands just from a single RGB video. We demonstrate that our proposed network architecture, the carefully designed training strategy, and the tight integration of parametric face and hand models to a template mesh enable the capture of all these individual aspects. Importantly, our method also captures high-frequency details, such as deforming wrinkles on the clothes, better than the previous works. Furthermore, we show that HiFECap outperforms the state-of-the-art human performance capture approaches qualitatively and quantitatively while for the first time capturing all aspects of the human.

</p>
</details>

<details><summary><b>Entity Disambiguation with Entity Definitions</b>
<a href="https://arxiv.org/abs/2210.05648">arxiv:2210.05648</a>
&#x1F4C8; 5 <br>
<p>Luigi Procopio, Simone Conia, Edoardo Barba, Roberto Navigli</p></summary>
<p>

**Abstract:** Local models have recently attained astounding performances in Entity Disambiguation (ED), with generative and extractive formulations being the most promising research directions. However, previous works limited their studies to using, as the textual representation of each candidate, only its Wikipedia title. Although certainly effective, this strategy presents a few critical issues, especially when titles are not sufficiently informative or distinguishable from one another. In this paper, we address this limitation and investigate to what extent more expressive textual representations can mitigate it. We thoroughly evaluate our approach against standard benchmarks in ED and find extractive formulations to be particularly well-suited to these representations: we report a new state of the art on 2 out of 6 benchmarks we consider and strongly improve the generalization capability over unseen patterns. We release our code, data and model checkpoints at https://github.com/SapienzaNLP/extend.

</p>
</details>

<details><summary><b>Continual Learning by Modeling Intra-Class Variation</b>
<a href="https://arxiv.org/abs/2210.05398">arxiv:2210.05398</a>
&#x1F4C8; 5 <br>
<p>Longhui Yu, Tianyang Hu, Lanqing Hong, Zhen Liu, Adrian Weller, Weiyang Liu</p></summary>
<p>

**Abstract:** It has been observed that neural networks perform poorly when the data or tasks are presented sequentially. Unlike humans, neural networks suffer greatly from catastrophic forgetting, making it impossible to perform life-long learning. To address this issue, memory-based continual learning has been actively studied and stands out as one of the best-performing methods. We examine memory-based continual learning and identify that large variation in the representation space is crucial for avoiding catastrophic forgetting. Motivated by this, we propose to diversify representations by using two types of perturbations: model-agnostic variation (i.e., the variation is generated without the knowledge of the learned neural network) and model-based variation (i.e., the variation is conditioned on the learned neural network). We demonstrate that enlarging representational variation serves as a general principle to improve continual learning. Finally, we perform empirical studies which demonstrate that our method, as a simple plug-and-play component, can consistently improve a number of memory-based continual learning methods by a large margin.

</p>
</details>

<details><summary><b>Factors of Influence of the Overestimation Bias of Q-Learning</b>
<a href="https://arxiv.org/abs/2210.05262">arxiv:2210.05262</a>
&#x1F4C8; 5 <br>
<p>Julius Wagenbach, Matthia Sabatelli</p></summary>
<p>

**Abstract:** We study whether the learning rate $Œ±$, the discount factor $Œ≥$ and the reward signal $r$ have an influence on the overestimation bias of the Q-Learning algorithm. Our preliminary results in environments which are stochastic and that require the use of neural networks as function approximators, show that all three parameters influence overestimation significantly. By carefully tuning $Œ±$ and $Œ≥$, and by using an exponential moving average of $r$ in Q-Learning's temporal difference target, we show that the algorithm can learn value estimates that are more accurate than the ones of several other popular model-free methods that have addressed its overestimation bias in the past.

</p>
</details>

<details><summary><b>Deep Spectro-temporal Artifacts for Detecting Synthesized Speech</b>
<a href="https://arxiv.org/abs/2210.05254">arxiv:2210.05254</a>
&#x1F4C8; 5 <br>
<p>Xiaohui Liu, Meng Liu, Lin Zhang, Linjuan Zhang, Chang Zeng, Kai Li, Nan Li, Kong Aik Lee, Longbiao Wang, Jianwu Dang</p></summary>
<p>

**Abstract:** The Audio Deep Synthesis Detection (ADD) Challenge has been held to detect generated human-like speech. With our submitted system, this paper provides an overall assessment of track 1 (Low-quality Fake Audio Detection) and track 2 (Partially Fake Audio Detection). In this paper, spectro-temporal artifacts were detected using raw temporal signals, spectral features, as well as deep embedding features. To address track 1, low-quality data augmentation, domain adaptation via finetuning, and various complementary feature information fusion were aggregated in our system. Furthermore, we analyzed the clustering characteristics of subsystems with different features by visualization method and explained the effectiveness of our proposed greedy fusion strategy. As for track 2, frame transition and smoothing were detected using self-supervised learning structure to capture the manipulation of PF attacks in the time domain. We ranked 4th and 5th in track 1 and track 2, respectively.

</p>
</details>

<details><summary><b>Self-supervised debiasing using low rank regularization</b>
<a href="https://arxiv.org/abs/2210.05248">arxiv:2210.05248</a>
&#x1F4C8; 5 <br>
<p>Geon Yeong Park, Chanyong Jung, Jong Chul Ye, Sang Wan Lee</p></summary>
<p>

**Abstract:** Spurious correlations can cause strong biases in deep neural networks, impairing generalization ability. While most of existing debiasing methods require full supervisions on either spurious attributes or target labels, training a debiased model from a limited amount of both annotations is still an open issue. To overcome such limitations, we first examined an interesting phenomenon by the spectral analysis of latent representations: spuriously correlated, easy-to-learn attributes make neural networks inductively biased towards encoding lower effective rank representations. We also show that a rank regularization can amplify this bias in a way that encourages highly correlated features. Motivated by these observations, we propose a self-supervised debiasing framework that is potentially compatible with unlabeled samples. We first pretrain a biased encoder in a self-supervised manner with the rank regularization, serving as a semantic bottleneck to enforce the encoder to learn the spuriously correlated attributes. This biased encoder is then used to discover and upweight bias-conflicting samples in a downstream task, serving as a boosting to effectively debias the main model. Remarkably, the proposed debiasing framework significantly improves the generalization performance of self-supervised learning baselines and, in some cases, even outperforms state-of-the-art supervised debiasing approaches.

</p>
</details>

<details><summary><b>Cluster-level pseudo-labelling for source-free cross-domain facial expression recognition</b>
<a href="https://arxiv.org/abs/2210.05246">arxiv:2210.05246</a>
&#x1F4C8; 5 <br>
<p>Alessandro Conti, Paolo Rota, Yiming Wang, Elisa Ricci</p></summary>
<p>

**Abstract:** Automatically understanding emotions from visual data is a fundamental task for human behaviour understanding. While models devised for Facial Expression Recognition (FER) have demonstrated excellent performances on many datasets, they often suffer from severe performance degradation when trained and tested on different datasets due to domain shift. In addition, as face images are considered highly sensitive data, the accessibility to large-scale datasets for model training is often denied. In this work, we tackle the above-mentioned problems by proposing the first Source-Free Unsupervised Domain Adaptation (SFUDA) method for FER. Our method exploits self-supervised pretraining to learn good feature representations from the target data and proposes a novel and robust cluster-level pseudo-labelling strategy that accounts for in-cluster statistics. We validate the effectiveness of our method in four adaptation setups, proving that it consistently outperforms existing SFUDA methods when applied to FER, and is on par with methods addressing FER in the UDA setting.

</p>
</details>

<details><summary><b>PatternRank: Leveraging Pretrained Language Models and Part of Speech for Unsupervised Keyphrase Extraction</b>
<a href="https://arxiv.org/abs/2210.05245">arxiv:2210.05245</a>
&#x1F4C8; 5 <br>
<p>Tim Schopf, Simon Klimek, Florian Matthes</p></summary>
<p>

**Abstract:** Keyphrase extraction is the process of automatically selecting a small set of most relevant phrases from a given text. Supervised keyphrase extraction approaches need large amounts of labeled training data and perform poorly outside the domain of the training data. In this paper, we present PatternRank, which leverages pretrained language models and part-of-speech for unsupervised keyphrase extraction from single documents. Our experiments show PatternRank achieves higher precision, recall and F1-scores than previous state-of-the-art approaches. In addition, we present the KeyphraseVectorizers package, which allows easy modification of part-of-speech patterns for candidate keyphrase selection, and hence adaptation of our approach to any domain.

</p>
</details>

<details><summary><b>Understanding the Failure of Batch Normalization for Transformers in NLP</b>
<a href="https://arxiv.org/abs/2210.05153">arxiv:2210.05153</a>
&#x1F4C8; 5 <br>
<p>Jiaxi Wang, Ji Wu, Lei Huang</p></summary>
<p>

**Abstract:** Batch Normalization (BN) is a core and prevalent technique in accelerating the training of deep neural networks and improving the generalization on Computer Vision (CV) tasks. However, it fails to defend its position in Natural Language Processing (NLP), which is dominated by Layer Normalization (LN). In this paper, we are trying to answer why BN usually performs worse than LN in NLP tasks with Transformer models. We find that the inconsistency between training and inference of BN is the leading cause that results in the failure of BN in NLP. We define Training Inference Discrepancy (TID) to quantitatively measure this inconsistency and reveal that TID can indicate BN's performance, supported by extensive experiments, including image classification, neural machine translation, language modeling, sequence labeling, and text classification tasks. We find that BN can obtain much better test performance than LN when TID keeps small through training. To suppress the explosion of TID, we propose Regularized BN (RBN) that adds a simple regularization term to narrow the gap between batch statistics and population statistics of BN. RBN improves the performance of BN consistently and outperforms or is on par with LN on 17 out of 20 settings, involving ten datasets and two common variants of Transformer
  Our code is available at https://github.com/wjxts/RegularizedBN.

</p>
</details>

<details><summary><b>DiffRoll: Diffusion-based Generative Music Transcription with Unsupervised Pretraining Capability</b>
<a href="https://arxiv.org/abs/2210.05148">arxiv:2210.05148</a>
&#x1F4C8; 5 <br>
<p>Kin Wai Cheuk, Ryosuke Sawata, Toshimitsu Uesaka, Naoki Murata, Naoya Takahashi, Shusuke Takahashi, Dorien Herremans, Yuki Mitsufuji</p></summary>
<p>

**Abstract:** In this paper we propose a novel generative approach, DiffRoll, to tackle automatic music transcription (AMT). Instead of treating AMT as a discriminative task in which the model is trained to convert spectrograms into piano rolls, we think of it as a conditional generative task where we train our model to generate realistic looking piano rolls from pure Gaussian noise conditioned on spectrograms. This new AMT formulation enables DiffRoll to transcribe, generate and even inpaint music. Due to the classifier-free nature, DiffRoll is also able to be trained on unpaired datasets where only piano rolls are available. Our experiments show that DiffRoll outperforms its discriminative counterpart by 17.9 percentage points (ppt.) and our ablation studies also indicate that it outperforms similar existing methods by 3.70 ppt.

</p>
</details>

<details><summary><b>Finite time analysis of temporal difference learning with linear function approximation: Tail averaging and regularisation</b>
<a href="https://arxiv.org/abs/2210.05918">arxiv:2210.05918</a>
&#x1F4C8; 4 <br>
<p>Gandharv Patil, Prashanth L. A., Dheeraj Nagaraj, Doina Precup</p></summary>
<p>

**Abstract:** We study the finite-time behaviour of the popular temporal difference (TD) learning algorithm when combined with tail-averaging. We derive finite time bounds on the parameter error of the tail-averaged TD iterate under a step-size choice that does not require information about the eigenvalues of the matrix underlying the projected TD fixed point. Our analysis shows that tail-averaged TD converges at the optimal $O\left(1/t\right)$ rate, both in expectation and with high probability. In addition, our bounds exhibit a sharper rate of decay for the initial error (bias), which is an improvement over averaging all iterates. We also propose and analyse a variant of TD that incorporates regularisation. From analysis, we conclude that the regularised version of TD is useful for problems with ill-conditioned features.

</p>
</details>

<details><summary><b>Hate-CLIPper: Multimodal Hateful Meme Classification based on Cross-modal Interaction of CLIP Features</b>
<a href="https://arxiv.org/abs/2210.05916">arxiv:2210.05916</a>
&#x1F4C8; 4 <br>
<p>Gokul Karthik Kumar, Karthik Nandakumar</p></summary>
<p>

**Abstract:** Hateful memes are a growing menace on social media. While the image and its corresponding text in a meme are related, they do not necessarily convey the same meaning when viewed individually. Hence, detecting hateful memes requires careful consideration of both visual and textual information. Multimodal pre-training can be beneficial for this task because it effectively captures the relationship between the image and the text by representing them in a similar feature space. Furthermore, it is essential to model the interactions between the image and text features through intermediate fusion. Most existing methods either employ multimodal pre-training or intermediate fusion, but not both. In this work, we propose the Hate-CLIPper architecture, which explicitly models the cross-modal interactions between the image and text representations obtained using Contrastive Language-Image Pre-training (CLIP) encoders via a feature interaction matrix (FIM). A simple classifier based on the FIM representation is able to achieve state-of-the-art performance on the Hateful Memes Challenge (HMC) dataset with an AUROC of 85.8, which even surpasses the human performance of 82.65. Experiments on other meme datasets such as Propaganda Memes and TamilMemes also demonstrate the generalizability of the proposed approach. Finally, we analyze the interpretability of the FIM representation and show that cross-modal interactions can indeed facilitate the learning of meaningful concepts. The code for this work is available at https://github.com/gokulkarthik/hateclipper.

</p>
</details>

<details><summary><b>Social-Group-Agnostic Word Embedding Debiasing via the Stereotype Content Model</b>
<a href="https://arxiv.org/abs/2210.05831">arxiv:2210.05831</a>
&#x1F4C8; 4 <br>
<p>Ali Omrani, Brendan Kennedy, Mohammad Atari, Morteza Dehghani</p></summary>
<p>

**Abstract:** Existing word embedding debiasing methods require social-group-specific word pairs (e.g., "man"-"woman") for each social attribute (e.g., gender), which cannot be used to mitigate bias for other social groups, making these methods impractical or costly to incorporate understudied social groups in debiasing. We propose that the Stereotype Content Model (SCM), a theoretical framework developed in social psychology for understanding the content of stereotypes, which structures stereotype content along two psychological dimensions - "warmth" and "competence" - can help debiasing efforts to become social-group-agnostic by capturing the underlying connection between bias and stereotypes. Using only pairs of terms for warmth (e.g., "genuine"-"fake") and competence (e.g.,"smart"-"stupid"), we perform debiasing with established methods and find that, across gender, race, and age, SCM-based debiasing performs comparably to group-specific debiasing

</p>
</details>

<details><summary><b>Deep Counterfactual Estimation with Categorical Background Variables</b>
<a href="https://arxiv.org/abs/2210.05811">arxiv:2210.05811</a>
&#x1F4C8; 4 <br>
<p>Edward De Brouwer</p></summary>
<p>

**Abstract:** Referred to as the third rung of the causal inference ladder, counterfactual queries typically ask the "What if ?" question retrospectively. The standard approach to estimate counterfactuals resides in using a structural equation model that accurately reflects the underlying data generating process. However, such models are seldom available in practice and one usually wishes to infer them from observational data alone. Unfortunately, the correct structural equation model is in general not identifiable from the observed factual distribution. Nevertheless, in this work, we show that under the assumption that the main latent contributors to the treatment responses are categorical, the counterfactuals can be still reliably predicted. Building upon this assumption, we introduce CounterFactual Query Prediction (CFQP), a novel method to infer counterfactuals from continuous observations when the background variables are categorical. We show that our method significantly outperforms previously available deep-learning-based counterfactual methods, both theoretically and empirically on time series and image data. Our code is available at https://github.com/edebrouwer/cfqp.

</p>
</details>

<details><summary><b>Robustify Transformers with Robust Kernel Density Estimation</b>
<a href="https://arxiv.org/abs/2210.05794">arxiv:2210.05794</a>
&#x1F4C8; 4 <br>
<p>Xing Han, Tongzheng Ren, Tan Minh Nguyen, Khai Nguyen, Joydeep Ghosh, Nhat Ho</p></summary>
<p>

**Abstract:** Recent advances in Transformer architecture have empowered its empirical success in various tasks across different domains. However, existing works mainly focus on improving the standard accuracy and computational cost, without considering the robustness of contaminated samples. Existing work has shown that the self-attention mechanism, which is the center of the Transformer architecture, can be viewed as a non-parametric estimator based on the well-known kernel density estimation (KDE). This motivates us to leverage the robust kernel density estimation (RKDE) in the self-attention mechanism, to alleviate the issue of the contamination of data by down-weighting the weight of bad samples in the estimation process. The modified self-attention mechanism can be incorporated into different Transformer variants. Empirical results on language modeling and image classification tasks demonstrate the effectiveness of this approach.

</p>
</details>

<details><summary><b>Transfer Learning with Joint Fine-Tuning for Multimodal Sentiment Analysis</b>
<a href="https://arxiv.org/abs/2210.05790">arxiv:2210.05790</a>
&#x1F4C8; 4 <br>
<p>Guilherme Louren√ßo de Toledo, Ricardo Marcondes Marcacini</p></summary>
<p>

**Abstract:** Most existing methods focus on sentiment analysis of textual data. However, recently there has been a massive use of images and videos on social platforms, motivating sentiment analysis from other modalities. Current studies show that exploring other modalities (e.g., images) increases sentiment analysis performance. State-of-the-art multimodal models, such as CLIP and VisualBERT, are pre-trained on datasets with the text paired with images. Although the results obtained by these models are promising, pre-training and sentiment analysis fine-tuning tasks of these models are computationally expensive. This paper introduces a transfer learning approach using joint fine-tuning for sentiment analysis. Our proposal achieved competitive results using a more straightforward alternative fine-tuning strategy that leverages different pre-trained unimodal models and efficiently combines them in a multimodal space. Moreover, our proposal allows flexibility when incorporating any pre-trained model for texts and images during the joint fine-tuning stage, being especially interesting for sentiment classification in low-resource scenarios.

</p>
</details>

<details><summary><b>C-Mixup: Improving Generalization in Regression</b>
<a href="https://arxiv.org/abs/2210.05775">arxiv:2210.05775</a>
&#x1F4C8; 4 <br>
<p>Huaxiu Yao, Yiping Wang, Linjun Zhang, James Zou, Chelsea Finn</p></summary>
<p>

**Abstract:** Improving the generalization of deep networks is an important open challenge, particularly in domains without plentiful data. The mixup algorithm improves generalization by linearly interpolating a pair of examples and their corresponding labels. These interpolated examples augment the original training set. Mixup has shown promising results in various classification tasks, but systematic analysis of mixup in regression remains underexplored. Using mixup directly on regression labels can result in arbitrarily incorrect labels. In this paper, we propose a simple yet powerful algorithm, C-Mixup, to improve generalization on regression tasks. In contrast with vanilla mixup, which picks training examples for mixing with uniform probability, C-Mixup adjusts the sampling probability based on the similarity of the labels. Our theoretical analysis confirms that C-Mixup with label similarity obtains a smaller mean square error in supervised regression and meta-regression than vanilla mixup and using feature similarity. Another benefit of C-Mixup is that it can improve out-of-distribution robustness, where the test distribution is different from the training distribution. By selectively interpolating examples with similar labels, it mitigates the effects of domain-associated information and yields domain-invariant representations. We evaluate C-Mixup on eleven datasets, ranging from tabular to video data. Compared to the best prior approach, C-Mixup achieves 6.56%, 4.76%, 5.82% improvements in in-distribution generalization, task generalization, and out-of-distribution robustness, respectively. Code is released at https://github.com/huaxiuyao/C-Mixup.

</p>
</details>

<details><summary><b>Decoupled Context Processing for Context Augmented Language Modeling</b>
<a href="https://arxiv.org/abs/2210.05758">arxiv:2210.05758</a>
&#x1F4C8; 4 <br>
<p>Zonglin Li, Ruiqi Guo, Sanjiv Kumar</p></summary>
<p>

**Abstract:** Language models can be augmented with a context retriever to incorporate knowledge from large external databases. By leveraging retrieved context, the neural network does not have to memorize the massive amount of world knowledge within its internal parameters, leading to better parameter efficiency, interpretability and modularity. In this paper we examined a simple yet effective architecture for incorporating external context into language models based on decoupled Encoder Decoder architecture. We showed that such a simple architecture achieves competitive results on auto-regressive language modeling and open domain question answering tasks. We also analyzed the behavior of the proposed model which performs grounded context transfer. Finally we discussed the computational implications of such retrieval augmented models.

</p>
</details>

<details><summary><b>Toward Sustainable Continual Learning: Detection and Knowledge Repurposing of Similar Tasks</b>
<a href="https://arxiv.org/abs/2210.05751">arxiv:2210.05751</a>
&#x1F4C8; 4 <br>
<p>Sijia Wang, Yoojin Choi, Junya Chen, Mostafa El-Khamy, Ricardo Henao</p></summary>
<p>

**Abstract:** Most existing works on continual learning (CL) focus on overcoming the catastrophic forgetting (CF) problem, with dynamic models and replay methods performing exceptionally well. However, since current works tend to assume exclusivity or dissimilarity among learning tasks, these methods require constantly accumulating task-specific knowledge in memory for each task. This results in the eventual prohibitive expansion of the knowledge repository if we consider learning from a long sequence of tasks. In this work, we introduce a paradigm where the continual learner gets a sequence of mixed similar and dissimilar tasks. We propose a new continual learning framework that uses a task similarity detection function that does not require additional learning, with which we analyze whether there is a specific task in the past that is similar to the current task. We can then reuse previous task knowledge to slow down parameter expansion, ensuring that the CL system expands the knowledge repository sublinearly to the number of learned tasks. Our experiments show that the proposed framework performs competitively on widely used computer vision benchmarks such as CIFAR10, CIFAR100, and EMNIST.

</p>
</details>

<details><summary><b>Shapley Head Pruning: Identifying and Removing Interference in Multilingual Transformers</b>
<a href="https://arxiv.org/abs/2210.05709">arxiv:2210.05709</a>
&#x1F4C8; 4 <br>
<p>William Held, Diyi Yang</p></summary>
<p>

**Abstract:** Multilingual transformer-based models demonstrate remarkable zero and few-shot transfer across languages by learning and reusing language-agnostic features. However, as a fixed-size model acquires more languages, its performance across all languages degrades, a phenomenon termed interference. Often attributed to limited model capacity, interference is commonly addressed by adding additional parameters despite evidence that transformer-based models are overparameterized. In this work, we show that it is possible to reduce interference by instead identifying and pruning language-specific parameters. First, we use Shapley Values, a credit allocation metric from coalitional game theory, to identify attention heads that introduce interference. Then, we show that removing identified attention heads from a fixed model improves performance for a target language on both sentence classification and structural prediction, seeing gains as large as 24.7\%. Finally, we provide insights on language-agnostic and language-specific attention heads using attention visualization.

</p>
</details>

<details><summary><b>An Experimental Study on Private Aggregation of Teacher Ensemble Learning for End-to-End Speech Recognition</b>
<a href="https://arxiv.org/abs/2210.05614">arxiv:2210.05614</a>
&#x1F4C8; 4 <br>
<p>Chao-Han Huck Yang, I-Fan Chen, Andreas Stolcke, Sabato Marco Siniscalchi, Chin-Hui Lee</p></summary>
<p>

**Abstract:** Differential privacy (DP) is one data protection avenue to safeguard user information used for training deep models by imposing noisy distortion on privacy data. Such a noise perturbation often results in a severe performance degradation in automatic speech recognition (ASR) in order to meet a privacy budget $\varepsilon$. Private aggregation of teacher ensemble (PATE) utilizes ensemble probabilities to improve ASR accuracy when dealing with the noise effects controlled by small values of $\varepsilon$. In this work, we extend PATE learning to work with dynamic patterns, namely speech, and perform one very first experimental study on ASR to avoid acoustic data leakage. We evaluate three end-to-end deep models, including LAS, hybrid attention/CTC, and RNN transducer, on the open-source LibriSpeech and TIMIT corpora. PATE learning-enhanced ASR models outperform the benchmark DP-SGD mechanisms, especially under strict DP budgets, giving relative word error rate reductions between 26.2% and 27.5% for RNN transducer model evaluated with LibriSpeech. We also introduce another DP-preserving ASR solution with public speech corpus pre-training.

</p>
</details>

<details><summary><b>Contrastive Training Improves Zero-Shot Classification of Semi-structured Documents</b>
<a href="https://arxiv.org/abs/2210.05613">arxiv:2210.05613</a>
&#x1F4C8; 4 <br>
<p>Muhammad Khalifa, Yogarshi Vyas, Shuai Wang, Graham Horwood, Sunil Mallya, Miguel Ballesteros</p></summary>
<p>

**Abstract:** We investigate semi-structured document classification in a zero-shot setting. Classification of semi-structured documents is more challenging than that of standard unstructured documents, as positional, layout, and style information play a vital role in interpreting such documents. The standard classification setting where categories are fixed during both training and testing falls short in dynamic environments where new document categories could potentially emerge. We focus exclusively on the zero-shot setting where inference is done on new unseen classes. To address this task, we propose a matching-based approach that relies on a pairwise contrastive objective for both pretraining and fine-tuning. Our results show a significant boost in Macro F$_1$ from the proposed pretraining step in both supervised and unsupervised zero-shot settings.

</p>
</details>

<details><summary><b>Improving Sample Efficiency of Deep Learning Models in Electricity Market</b>
<a href="https://arxiv.org/abs/2210.05599">arxiv:2210.05599</a>
&#x1F4C8; 4 <br>
<p>Guangchun Ruan, Jianxiao Wang, Haiwang Zhong, Qing Xia, Chongqing Kang</p></summary>
<p>

**Abstract:** The superior performance of deep learning relies heavily on a large collection of sample data, but the data insufficiency problem turns out to be relatively common in global electricity markets. How to prevent overfitting in this case becomes a fundamental challenge when training deep learning models in different market applications. With this in mind, we propose a general framework, namely Knowledge-Augmented Training (KAT), to improve the sample efficiency, and the main idea is to incorporate domain knowledge into the training procedures of deep learning models. Specifically, we propose a novel data augmentation technique to generate some synthetic data, which are later processed by an improved training strategy. This KAT methodology follows and realizes the idea of combining analytical and deep learning models together. Modern learning theories demonstrate the effectiveness of our method in terms of effective prediction error feedbacks, a reliable loss function, and rich gradient noises. At last, we study two popular applications in detail: user modeling and probabilistic price forecasting. The proposed method outperforms other competitors in all numerical tests, and the underlying reasons are explained by further statistical and visualization results.

</p>
</details>

<details><summary><b>Digital Twin-Based Multiple Access Optimization and Monitoring via Model-Driven Bayesian Learning</b>
<a href="https://arxiv.org/abs/2210.05582">arxiv:2210.05582</a>
&#x1F4C8; 4 <br>
<p>Clement Ruah, Osvaldo Simeone, Bashir Al-Hashimi</p></summary>
<p>

**Abstract:** Commonly adopted in the manufacturing and aerospace sectors, digital twin (DT) platforms are increasingly seen as a promising paradigm to control and monitor software-based, "open", communication systems, which play the role of the physical twin (PT). In the general framework presented in this work, the DT builds a Bayesian model of the communication system, which is leveraged to enable core DT functionalities such as control via multi-agent reinforcement learning (MARL) and monitoring of the PT for anomaly detection. We specifically investigate the application of the proposed framework to a simple case-study system encompassing multiple sensing devices that report to a common receiver. The Bayesian model trained at the DT has the key advantage of capturing epistemic uncertainty regarding the communication system, e.g., regarding current traffic conditions, which arise from limited PT-to-DT data transfer. Experimental results validate the effectiveness of the proposed Bayesian framework as compared to standard frequentist model-based solutions.

</p>
</details>

<details><summary><b>Autonomous Asteroid Characterization Through Nanosatellite Swarming</b>
<a href="https://arxiv.org/abs/2210.05518">arxiv:2210.05518</a>
&#x1F4C8; 4 <br>
<p>Kaitlin Dennison, Nathan Stacey, Simone D'Amico</p></summary>
<p>

**Abstract:** This paper first defines a class of estimation problem called simultaneous navigation and characterization (SNAC), which is a superset of simultaneous localization and mapping (SLAM). A SNAC framework is then developed for the Autonomous Nanosatellite Swarming (ANS) mission concept to autonomously navigate about and characterize an asteroid including the asteroid gravity field, rotational motion, and 3D shape. The ANS SNAC framework consists of three modules: 1) multi-agent optical landmark tracking and 3D point reconstruction using stereovision, 2) state estimation through a computationally efficient and robust unscented Kalman filter, and 3) reconstruction of an asteroid spherical harmonic shape model by leveraging a priori knowledge of the shape properties of celestial bodies. Despite significant interest in asteroids, there are several limitations to current asteroid rendezvous mission concepts. First, completed missions heavily rely on human oversight and Earth-based resources. Second, proposed solutions to increase autonomy make oversimplifying assumptions about state knowledge and information processing. Third, asteroid mission concepts often opt for high size, weight, power, and cost (SWaP-C) avionics for environmental measurements. Finally, such missions often utilize a single spacecraft, neglecting the benefits of distributed space systems. In contrast, ANS is composed of multiple autonomous nanosatellites equipped with low SWaP-C avionics. The ANS SNAC framework is validated through a numerical simulation of three spacecraft orbiting asteroid 433 Eros. The simulation results demonstrate that the proposed architecture provides autonomous and accurate SNAC in a safe manner without an a priori shape model and using only low SWaP-C avionics.

</p>
</details>

<details><summary><b>Extracting Meaningful Attention on Source Code: An Empirical Study of Developer and Neural Model Code Exploration</b>
<a href="https://arxiv.org/abs/2210.05506">arxiv:2210.05506</a>
&#x1F4C8; 4 <br>
<p>Matteo Paltenghi, Rahul Pandita, Austin Z. Henley, Albert Ziegler</p></summary>
<p>

**Abstract:** The high effectiveness of neural models of code, such as OpenAI Codex and AlphaCode, suggests coding capabilities of models that are at least comparable to those of humans. However, previous work has only used these models for their raw completion, ignoring how the model reasoning, in the form of attention weights, can be used for other downstream tasks. Disregarding the attention weights means discarding a considerable portion of what those models compute when queried. To profit more from the knowledge embedded in these large pre-trained models, this work compares multiple approaches to post-process these valuable attention weights for supporting code exploration. Specifically, we compare to which extent the transformed attention signal of CodeGen, a large and publicly available pretrained neural model, agrees with how developers look at and explore code when each answering the same sense-making questions about code. At the core of our experimental evaluation, we collect, manually annotate, and open-source a novel eye-tracking dataset comprising 25 developers answering sense-making questions on code over 92 sessions. We empirically evaluate five attention-agnostic heuristics and ten attention-based post processing approaches of the attention signal against our ground truth of developers exploring code, including the novel concept of follow-up attention which exhibits the highest agreement. Beyond the dataset contribution and the empirical study, we also introduce a novel practical application of the attention signal of pre-trained models with completely analytical solutions, going beyond how neural models' attention mechanisms have traditionally been used.

</p>
</details>

<details><summary><b>CIRCA: comprehensible online system in support of chest X-rays-based COVID-19 diagnosis</b>
<a href="https://arxiv.org/abs/2210.05440">arxiv:2210.05440</a>
&#x1F4C8; 4 <br>
<p>Wojciech Prazuch, Aleksandra Suwalska, Marek Socha, Joanna Tobiasz, Pawel Foszner, Jerzy Jaroszewicz, Katarzyna Gruszczynska, Magdalena Sliwinska, Jerzy Walecki, Tadeusz Popiela, Grzegorz Przybylski, Andrzej Cieszanowski, Mateusz Nowak, Malgorzata Pawlowska, Robert Flisiak, Krzysztof Simon, Gabriela Zapolska, Barbara Gizycka, Edyta Szurowska, POLCOVID Study Group, Michal Marczyk, Joanna Polanska</p></summary>
<p>

**Abstract:** Due to the large accumulation of patients requiring hospitalization, the COVID-19 pandemic disease caused a high overload of health systems, even in developed countries. Deep learning techniques based on medical imaging data can help in the faster detection of COVID-19 cases and monitoring of disease progression. Regardless of the numerous proposed solutions for lung X-rays, none of them is a product that can be used in the clinic. Five different datasets (POLCOVID, AIforCOVID, COVIDx, NIH, and artificially generated data) were used to construct a representative dataset of 23 799 CXRs for model training; 1 050 images were used as a hold-out test set, and 44 247 as independent test set (BIMCV database). A U-Net-based model was developed to identify a clinically relevant region of the CXR. Each image class (normal, pneumonia, and COVID-19) was divided into 3 subtypes using a 2D Gaussian mixture model. A decision tree was used to aggregate predictions from the InceptionV3 network based on processed CXRs and a dense neural network on radiomic features. The lung segmentation model gave the Sorensen-Dice coefficient of 94.86% in the validation dataset, and 93.36% in the testing dataset. In 5-fold cross-validation, the accuracy for all classes ranged from 91% to 93%, keeping slightly higher specificity than sensitivity and NPV than PPV. In the hold-out test set, the balanced accuracy ranged between 68% and 100%. The highest performance was obtained for the subtypes N1, P1, and C1. A similar performance was obtained on the independent dataset for normal and COVID-19 class subtypes. Seventy-six percent of COVID-19 patients wrongly classified as normal cases were annotated by radiologists as with no signs of disease. Finally, we developed the online service (https://circa.aei.polsl.pl) to provide access to fast diagnosis support tools.

</p>
</details>

<details><summary><b>Retinex Image Enhancement Based on Sequential Decomposition With a Plug-and-Play Framework</b>
<a href="https://arxiv.org/abs/2210.05436">arxiv:2210.05436</a>
&#x1F4C8; 4 <br>
<p>Tingting Wu, Wenna Wu, Ying Yang, Feng-Lei Fan, Tieyong Zeng</p></summary>
<p>

**Abstract:** The Retinex model is one of the most representative and effective methods for low-light image enhancement. However, the Retinex model does not explicitly tackle the noise problem, and shows unsatisfactory enhancing results. In recent years, due to the excellent performance, deep learning models have been widely used in low-light image enhancement. However, these methods have two limitations: i) The desirable performance can only be achieved by deep learning when a large number of labeled data are available. However, it is not easy to curate massive low/normal-light paired data; ii) Deep learning is notoriously a black-box model [1]. It is difficult to explain their inner-working mechanism and understand their behaviors. In this paper, using a sequential Retinex decomposition strategy, we design a plug-and-play framework based on the Retinex theory for simultaneously image enhancement and noise removal. Meanwhile, we develop a convolutional neural network-based (CNN-based) denoiser into our proposed plug-and-play framework to generate a reflectance component. The final enhanced image is produced by integrating the illumination and reflectance with gamma correction. The proposed plug-and-play framework can facilitate both post hoc and ad hoc interpretability. Extensive experiments on different datasets demonstrate that our framework outcompetes the state-of-the-art methods in both image enhancement and denoising.

</p>
</details>

<details><summary><b>LECO: Learnable Episodic Count for Task-Specific Intrinsic Reward</b>
<a href="https://arxiv.org/abs/2210.05409">arxiv:2210.05409</a>
&#x1F4C8; 4 <br>
<p>Daejin Jo, Sungwoong Kim, Daniel Wontae Nam, Taehwan Kwon, Seungeun Rho, Jongmin Kim, Donghoon Lee</p></summary>
<p>

**Abstract:** Episodic count has been widely used to design a simple yet effective intrinsic motivation for reinforcement learning with a sparse reward. However, the use of episodic count in a high-dimensional state space as well as over a long episode time requires a thorough state compression and fast hashing, which hinders rigorous exploitation of it in such hard and complex exploration environments. Moreover, the interference from task-irrelevant observations in the episodic count may cause its intrinsic motivation to overlook task-related important changes of states, and the novelty in an episodic manner can lead to repeatedly revisit the familiar states across episodes. In order to resolve these issues, in this paper, we propose a learnable hash-based episodic count, which we name LECO, that efficiently performs as a task-specific intrinsic reward in hard exploration problems. In particular, the proposed intrinsic reward consists of the episodic novelty and the task-specific modulation where the former employs a vector quantized variational autoencoder to automatically obtain the discrete state codes for fast counting while the latter regulates the episodic novelty by learning a modulator to optimize the task-specific extrinsic reward. The proposed LECO specifically enables the automatic transition from exploration to exploitation during reinforcement learning. We experimentally show that in contrast to the previous exploration methods LECO successfully solves hard exploration problems and also scales to large state spaces through the most difficult tasks in MiniGrid and DMLab environments.

</p>
</details>

<details><summary><b>EOCSA: Predicting Prognosis of Epithelial Ovarian Cancer with Whole Slide Histopathological Images</b>
<a href="https://arxiv.org/abs/2210.05258">arxiv:2210.05258</a>
&#x1F4C8; 4 <br>
<p>Tianling Liu, Ran Su, Changming Sun, Xiuting Li, Leyi Wei</p></summary>
<p>

**Abstract:** Ovarian cancer is one of the most serious cancers that threaten women around the world. Epithelial ovarian cancer (EOC), as the most commonly seen subtype of ovarian cancer, has rather high mortality rate and poor prognosis among various gynecological cancers. Survival analysis outcome is able to provide treatment advices to doctors. In recent years, with the development of medical imaging technology, survival prediction approaches based on pathological images have been proposed. In this study, we designed a deep framework named EOCSA which analyzes the prognosis of EOC patients based on pathological whole slide images (WSIs). Specifically, we first randomly extracted patches from WSIs and grouped them into multiple clusters. Next, we developed a survival prediction model, named DeepConvAttentionSurv (DCAS), which was able to extract patch-level features, removed less discriminative clusters and predicted the EOC survival precisely. Particularly, channel attention, spatial attention, and neuron attention mechanisms were used to improve the performance of feature extraction. Then patient-level features were generated from our weight calculation method and the survival time was finally estimated using LASSO-Cox model. The proposed EOCSA is efficient and effective in predicting prognosis of EOC and the DCAS ensures more informative and discriminative features can be extracted. As far as we know, our work is the first to analyze the survival of EOC based on WSIs and deep neural network technologies. The experimental results demonstrate that our proposed framework has achieved state-of-the-art performance of 0.980 C-index. The implementation of the approach can be found at https://github.com/RanSuLab/EOCprognosis.

</p>
</details>

<details><summary><b>Efficient debiasing with contrastive weight pruning</b>
<a href="https://arxiv.org/abs/2210.05247">arxiv:2210.05247</a>
&#x1F4C8; 4 <br>
<p>Geon Yeong Park, Sangmin Lee, Sang Wan Lee, Jong Chul Ye</p></summary>
<p>

**Abstract:** Neural networks are often biased to spuriously correlated features that provide misleading statistical evidence that does not generalize. This raises a fundamental question: "Does an optimal unbiased functional subnetwork exist in a severely biased network? If so, how to extract such subnetwork?" While few studies have revealed the existence of such optimal subnetworks with the guidance of ground-truth unbiased samples, the way to discover the optimal subnetworks with biased training dataset is still unexplored in practice. To address this, here we first present our theoretical insight that alerts potential limitations of existing algorithms in exploring unbiased subnetworks in the presence of strong spurious correlations. We then further elucidate the importance of bias-conflicting samples on structure learning. Motivated by these observations, we propose a Debiased Contrastive Weight Pruning (DCWP) algorithm, which probes unbiased subnetworks without expensive group annotations. Experimental results demonstrate that our approach significantly outperforms state-of-the-art debiasing methods despite its considerable reduction in the number of parameters.

</p>
</details>

<details><summary><b>From Mimicking to Integrating: Knowledge Integration for Pre-Trained Language Models</b>
<a href="https://arxiv.org/abs/2210.05230">arxiv:2210.05230</a>
&#x1F4C8; 4 <br>
<p>Lei Li, Yankai Lin, Xuancheng Ren, Guangxiang Zhao, Peng Li, Jie Zhou, Xu Sun</p></summary>
<p>

**Abstract:** Investigating better ways to reuse the released pre-trained language models (PLMs) can significantly reduce the computational cost and the potential environmental side-effects. This paper explores a novel PLM reuse paradigm, Knowledge Integration (KI). Without human annotations available, KI aims to merge the knowledge from different teacher-PLMs, each of which specializes in a different classification problem, into a versatile student model. To achieve this, we first derive the correlation between virtual golden supervision and teacher predictions. We then design a Model Uncertainty--aware Knowledge Integration (MUKI) framework to recover the golden supervision for the student. Specifically, MUKI adopts Monte-Carlo Dropout to estimate model uncertainty for the supervision integration. An instance-wise re-weighting mechanism based on the margin of uncertainty scores is further incorporated, to deal with the potential conflicting supervision from teachers. Experimental results demonstrate that MUKI achieves substantial improvements over baselines on benchmark datasets. Further analysis shows that MUKI can generalize well for merging teacher models with heterogeneous architectures, and even teachers major in cross-lingual datasets.

</p>
</details>

<details><summary><b>Broad-persistent Advice for Interactive Reinforcement Learning Scenarios</b>
<a href="https://arxiv.org/abs/2210.05187">arxiv:2210.05187</a>
&#x1F4C8; 4 <br>
<p>Francisco Cruz, Adam Bignold, Hung Son Nguyen, Richard Dazeley, Peter Vamplew</p></summary>
<p>

**Abstract:** The use of interactive advice in reinforcement learning scenarios allows for speeding up the learning process for autonomous agents. Current interactive reinforcement learning research has been limited to real-time interactions that offer relevant user advice to the current state only. Moreover, the information provided by each interaction is not retained and instead discarded by the agent after a single use. In this paper, we present a method for retaining and reusing provided knowledge, allowing trainers to give general advice relevant to more than just the current state. Results obtained show that the use of broad-persistent advice substantially improves the performance of the agent while reducing the number of interactions required for the trainer.

</p>
</details>

<details><summary><b>LARF: Two-level Attention-based Random Forests with a Mixture of Contamination Models</b>
<a href="https://arxiv.org/abs/2210.05168">arxiv:2210.05168</a>
&#x1F4C8; 4 <br>
<p>Andrei V. Konstantinov, Lev V. Utkin</p></summary>
<p>

**Abstract:** New models of the attention-based random forests called LARF (Leaf Attention-based Random Forest) are proposed. The first idea behind the models is to introduce a two-level attention, where one of the levels is the "leaf" attention and the attention mechanism is applied to every leaf of trees. The second level is the tree attention depending on the "leaf" attention. The second idea is to replace the softmax operation in the attention with the weighted sum of the softmax operations with different parameters. It is implemented by applying a mixture of the Huber's contamination models and can be regarded as an analog of the multi-head attention with "heads" defined by selecting a value of the softmax parameter. Attention parameters are simply trained by solving the quadratic optimization problem. To simplify the tuning process of the models, it is proposed to make the tuning contamination parameters to be training and to compute them by solving the quadratic optimization problem. Many numerical experiments with real datasets are performed for studying LARFs. The code of proposed algorithms can be found in https://github.com/andruekonst/leaf-attention-forest.

</p>
</details>

<details><summary><b>Combining datasets to increase the number of samples and improve model fitting</b>
<a href="https://arxiv.org/abs/2210.05165">arxiv:2210.05165</a>
&#x1F4C8; 4 <br>
<p>Thu Nguyen, Rabindra Khadka, Nhan Phan, Anis Yazidi, P√•l Halvorsen, Michael A. Riegler</p></summary>
<p>

**Abstract:** For many use cases, combining information from different datasets can be of interest to improve a machine learning model's performance, especially when the number of samples from at least one of the datasets is small. However, a potential challenge in such cases is that the features from these datasets are not identical, even though there are some commonly shared features among the datasets. To tackle this challenge, we propose a novel framework called Combine datasets based on Imputation (ComImp). In addition, we propose a variant of ComImp that uses Principle Component Analysis (PCA), PCA-ComImp in order to reduce dimension before combining datasets. This is useful when the datasets have a large number of features that are not shared between them. Furthermore, our framework can also be utilized for data preprocessing by imputing missing data, i.e., filling in the missing entries while combining different datasets. To illustrate the power of the proposed methods and their potential usages, we conduct experiments for various tasks: regression, classification, and for different data types: tabular data, time series data, when the datasets to be combined have missing data. We also investigate how the devised methods can be used with transfer learning to provide even further model training improvement. Our results indicate that the proposed methods are somewhat similar to transfer learning in that the merge can significantly improve the accuracy of a prediction model on smaller datasets. In addition, the methods can boost performance by a significant margin when combining small datasets together and can provide extra improvement when being used with transfer learning.

</p>
</details>

<details><summary><b>Can Language Models Be Specific? How?</b>
<a href="https://arxiv.org/abs/2210.05159">arxiv:2210.05159</a>
&#x1F4C8; 4 <br>
<p>Jie Huang, Kevin Chen-Chuan Chang, Jinjun Xiong, Wen-mei Hwu</p></summary>
<p>

**Abstract:** A good speaker not only needs to be correct, but also has the ability to be specific when desired, and so are language models. In this paper, we propose to measure how specific the language of pre-trained language models (PLMs) is. To achieve this, we introduce a novel approach to build a benchmark for specificity testing by forming masked token prediction tasks with prompts. For instance, given ``J. K. Rowling was born in [MASK].'', we want to test whether a more specific answer will be better filled in by PLMs, e.g., Yate instead of England. From our evaluations, we show that existing PLMs have only a slight preference for more specific answers. We identify underlying factors affecting the specificity and design two prompt-based methods to improve the specificity. Results show that the specificity of the models can be improved by the proposed methods without additional training. We believe this work can provide new insights for language modeling and encourage the research community to further explore this important but understudied problem.

</p>
</details>

<details><summary><b>ConserWeightive Behavioral Cloning for Reliable Offline Reinforcement Learning</b>
<a href="https://arxiv.org/abs/2210.05158">arxiv:2210.05158</a>
&#x1F4C8; 4 <br>
<p>Tung Nguyen, Qinqing Zheng, Aditya Grover</p></summary>
<p>

**Abstract:** The goal of offline reinforcement learning (RL) is to learn near-optimal policies from static logged datasets, thus sidestepping expensive online interactions. Behavioral cloning (BC) provides a straightforward solution to offline RL by mimicking offline trajectories via supervised learning. Recent advances (Chen et al., 2021; Janner et al., 2021; Emmons et al., 2021) have shown that by conditioning on desired future returns, BC can perform competitively to their value-based counterparts, while enjoying much more simplicity and training stability. However, the distribution of returns in the offline dataset can be arbitrarily skewed and suboptimal, which poses a unique challenge for conditioning BC on expert returns at test time. We propose ConserWeightive Behavioral Cloning (CWBC), a simple and effective method for improving the performance of conditional BC for offline RL with two key components: trajectory weighting and conservative regularization. Trajectory weighting addresses the bias-variance tradeoff in conditional BC and provides a principled mechanism to learn from both low return trajectories (typically plentiful) and high return trajectories (typically few). Further, we analyze the notion of conservatism in existing BC methods, and propose a novel conservative regularize that explicitly encourages the policy to stay close to the data distribution. The regularizer helps achieve more reliable performance, and removes the need for ad-hoc tuning of the conditioning value during evaluation. We instantiate CWBC in the context of Reinforcement Learning via Supervised Learning (RvS) (Emmons et al., 2021) and Decision Transformer (DT) (Chen et al., 2021), and empirically show that it significantly boosts the performance and stability of prior methods on various offline RL benchmarks. Code is available at https://github.com/tung-nd/cwbc.

</p>
</details>

<details><summary><b>Enemy Spotted: in-game gun sound dataset for gunshot classification and localization</b>
<a href="https://arxiv.org/abs/2210.05917">arxiv:2210.05917</a>
&#x1F4C8; 3 <br>
<p>Junwoo Park, Youngwoo Cho, Gyuhyeon Sim, Hojoon Lee, Jaegul Choo</p></summary>
<p>

**Abstract:** Recently, deep learning-based methods have drawn huge attention due to their simple yet high performance without domain knowledge in sound classification and localization tasks. However, a lack of gun sounds in existing datasets has been a major obstacle to implementing a support system to spot criminals from their gunshots by leveraging deep learning models. Since the occurrence of gunshot is rare and unpredictable, it is impractical to collect gun sounds in the real world. As an alternative, gun sounds can be obtained from an FPS game that is designed to mimic real-world warfare. The recent FPS game offers a realistic environment where we can safely collect gunshot data while simulating even dangerous situations. By exploiting the advantage of the game environment, we construct a gunshot dataset, namely BGG, for the firearm classification and gunshot localization tasks. The BGG dataset consists of 37 different types of firearms, distances, and directions between the sound source and a receiver. We carefully verify that the in-game gunshot data has sufficient information to identify the location and type of gunshots by training several sound classification and localization baselines on the BGG dataset. Afterward, we demonstrate that the accuracy of real-world firearm classification and localization tasks can be enhanced by utilizing the BGG dataset.

</p>
</details>

<details><summary><b>Common Corruption Robustness of Point Cloud Detectors: Benchmark and Enhancement</b>
<a href="https://arxiv.org/abs/2210.05896">arxiv:2210.05896</a>
&#x1F4C8; 3 <br>
<p>Shuangzhi Li, Zhijie Wang, Felix Juefei-Xu, Qing Guo, Xingyu Li, Lei Ma</p></summary>
<p>

**Abstract:** Object detection through LiDAR-based point cloud has recently been important in autonomous driving. Although achieving high accuracy on public benchmarks, the state-of-the-art detectors may still go wrong and cause a heavy loss due to the widespread corruptions in the real world like rain, snow, sensor noise, etc. Nevertheless, there is a lack of a large-scale dataset covering diverse scenes and realistic corruption types with different severities to develop practical and robust point cloud detectors, which is challenging due to the heavy collection costs. To alleviate the challenge and start the first step for robust point cloud detection, we propose the physical-aware simulation methods to generate degraded point clouds under different real-world common corruptions. Then, for the first attempt, we construct a benchmark based on the physical-aware common corruptions for point cloud detectors, which contains a total of 1,122,150 examples covering 7,481 scenes, 25 common corruption types, and 6 severities. With such a novel benchmark, we conduct extensive empirical studies on 8 state-of-the-art detectors that contain 6 different detection frameworks. Thus we get several insight observations revealing the vulnerabilities of the detectors and indicating the enhancement directions. Moreover, we further study the effectiveness of existing robustness enhancement methods based on data augmentation and data denoising. The benchmark can potentially be a new platform for evaluating point cloud detectors, opening a door for developing novel robustness enhancement methods.

</p>
</details>

<details><summary><b>Perplexity from PLM Is Unreliable for Evaluating Text Quality</b>
<a href="https://arxiv.org/abs/2210.05892">arxiv:2210.05892</a>
&#x1F4C8; 3 <br>
<p>Yequan Wang, Jiawen Deng, Aixin Sun, Xuying Meng</p></summary>
<p>

**Abstract:** Recently, amounts of works utilize perplexity~(PPL) to evaluate the quality of the generated text. They suppose that if the value of PPL is smaller, the quality(i.e. fluency) of the text to be evaluated is better. However, we find that the PPL referee is unqualified and it cannot evaluate the generated text fairly for the following reasons: (i) The PPL of short text is larger than long text, which goes against common sense, (ii) The repeated text span could damage the performance of PPL, and (iii) The punctuation marks could affect the performance of PPL heavily. Experiments show that the PPL is unreliable for evaluating the quality of given text. Last, we discuss the key problems with evaluating text quality using language models.

</p>
</details>

<details><summary><b>SlotFormer: Unsupervised Visual Dynamics Simulation with Object-Centric Models</b>
<a href="https://arxiv.org/abs/2210.05861">arxiv:2210.05861</a>
&#x1F4C8; 3 <br>
<p>Ziyi Wu, Nikita Dvornik, Klaus Greff, Thomas Kipf, Animesh Garg</p></summary>
<p>

**Abstract:** Understanding dynamics from visual observations is a challenging problem that requires disentangling individual objects from the scene and learning their interactions. While recent object-centric models can successfully decompose a scene into objects, modeling their dynamics effectively still remains a challenge. We address this problem by introducing SlotFormer -- a Transformer-based autoregressive model operating on learned object-centric representations. Given a video clip, our approach reasons over object features to model spatio-temporal relationships and predicts accurate future object states. In this paper, we successfully apply SlotFormer to perform video prediction on datasets with complex object interactions. Moreover, the unsupervised SlotFormer's dynamics model can be used to improve the performance on supervised downstream tasks, such as Visual Question Answering (VQA), and goal-conditioned planning. Compared to past works on dynamics modeling, our method achieves significantly better long-term synthesis of object dynamics, while retaining high quality visual generation. Besides, SlotFormer enables VQA models to reason about the future without object-level labels, even outperforming counterparts that use ground-truth annotations. Finally, we show its ability to serve as a world model for model-based planning, which is competitive with methods designed specifically for such tasks.

</p>
</details>

<details><summary><b>Synthetic Power Analyses: Empirical Evaluation and Application to Cognitive Neuroimaging</b>
<a href="https://arxiv.org/abs/2210.05835">arxiv:2210.05835</a>
&#x1F4C8; 3 <br>
<p>Peiye Zhuang, Bliss Chapman, Ran Li, Oluwasanmi Koyejo</p></summary>
<p>

**Abstract:** In the experimental sciences, statistical power analyses are often used before data collection to determine the required sample size. However, traditional power analyses can be costly when data are difficult or expensive to collect. We propose synthetic power analyses; a framework for estimating statistical power at various sample sizes, and empirically explore the performance of synthetic power analysis for sample size selection in cognitive neuroscience experiments. To this end, brain imaging data is synthesized using an implicit generative model conditioned on observed cognitive processes. Further, we propose a simple procedure to modify the statistical tests which result in conservative statistics. Our empirical results suggest that synthetic power analysis could be a low-cost alternative to pilot data collection when the proposed experiments share cognitive processes with previously conducted experiments.

</p>
</details>

<details><summary><b>AMICO: Amodal Instance Composition</b>
<a href="https://arxiv.org/abs/2210.05828">arxiv:2210.05828</a>
&#x1F4C8; 3 <br>
<p>Peiye Zhuang, Jia-bin Huang, Ayush Saraf, Xuejian Rong, Changil Kim, Denis Demandolx</p></summary>
<p>

**Abstract:** Image composition aims to blend multiple objects to form a harmonized image. Existing approaches often assume precisely segmented and intact objects. Such assumptions, however, are hard to satisfy in unconstrained scenarios. We present Amodal Instance Composition for compositing imperfect -- potentially incomplete and/or coarsely segmented -- objects onto a target image. We first develop object shape prediction and content completion modules to synthesize the amodal contents. We then propose a neural composition model to blend the objects seamlessly. Our primary technical novelty lies in using separate foreground/background representations and blending mask prediction to alleviate segmentation errors. Our results show state-of-the-art performance on public COCOA and KINS benchmarks and attain favorable visual results across diverse scenes. We demonstrate various image composition applications such as object insertion and de-occlusion.

</p>
</details>

<details><summary><b>Finding and Listing Front-door Adjustment Sets</b>
<a href="https://arxiv.org/abs/2210.05816">arxiv:2210.05816</a>
&#x1F4C8; 3 <br>
<p>Hyunchai Jeong, Jin Tian, Elias Bareinboim</p></summary>
<p>

**Abstract:** Identifying the effects of new interventions from data is a significant challenge found across a wide range of the empirical sciences. A well-known strategy for identifying such effects is Pearl's front-door (FD) criterion (Pearl, 1995). The definition of the FD criterion is declarative, only allowing one to decide whether a specific set satisfies the criterion. In this paper, we present algorithms for finding and enumerating possible sets satisfying the FD criterion in a given causal diagram. These results are useful in facilitating the practical applications of the FD criterion for causal effects estimation and helping scientists to select estimands with desired properties, e.g., based on cost, feasibility of measurement, or statistical power.

</p>
</details>

<details><summary><b>Exploration via Elliptical Episodic Bonuses</b>
<a href="https://arxiv.org/abs/2210.05805">arxiv:2210.05805</a>
&#x1F4C8; 3 <br>
<p>Mikael Henaff, Roberta Raileanu, Minqi Jiang, Tim Rockt√§schel</p></summary>
<p>

**Abstract:** In recent years, a number of reinforcement learning (RL) methods have been proposed to explore complex environments which differ across episodes. In this work, we show that the effectiveness of these methods critically relies on a count-based episodic term in their exploration bonus. As a result, despite their success in relatively simple, noise-free settings, these methods fall short in more realistic scenarios where the state space is vast and prone to noise. To address this limitation, we introduce Exploration via Elliptical Episodic Bonuses (E3B), a new method which extends count-based episodic bonuses to continuous state spaces and encourages an agent to explore states that are diverse under a learned embedding within each episode. The embedding is learned using an inverse dynamics model in order to capture controllable aspects of the environment. Our method sets a new state-of-the-art across 16 challenging tasks from the MiniHack suite, without requiring task-specific inductive biases. E3B also matches existing methods on sparse reward, pixel-based VizDoom environments, and outperforms existing methods in reward-free exploration on Habitat, demonstrating that it can scale to high-dimensional pixel-based observations and realistic environments.

</p>
</details>

<details><summary><b>Bil-DOS: A Bi-lingual Dialogue Ordering System (for Subway)</b>
<a href="https://arxiv.org/abs/2210.05773">arxiv:2210.05773</a>
&#x1F4C8; 3 <br>
<p>Zirong Chen, Haotian Xue</p></summary>
<p>

**Abstract:** Due to the unfamiliarity to particular words(or proper nouns) for ingredients, non-native English speakers can be extremely confused about the ordering process in restaurants like Subway. Thus, We developed a dialogue system, which supports Chinese(Mandarin)1 and English2 at the same time. In other words, users can switch arbitrarily between Chinese(Mandarin) and English as the conversation is being conducted. This system is specifically designed for Subway ordering3. In BilDOS, we designed a Discriminator module to tell the language is being used in inputted user utterance, a Translator module to translate used language into English if it is not English, and a Dialogue Manager module to detect the intention within inputted user utterances, handle outlier inputs by throwing clarification requests, map detected Intention and detailed Keyword4 into a particular intention class, locate the current ordering process, continue to give queries to finish the order, conclude the order details once the order is completed, activate the evaluation process when the conversation is done.

</p>
</details>

<details><summary><b>Applying FrameNet to Chinese(Poetry)</b>
<a href="https://arxiv.org/abs/2210.05772">arxiv:2210.05772</a>
&#x1F4C8; 3 <br>
<p>Zirong Chen</p></summary>
<p>

**Abstract:** FrameNet( Fillmore and Baker [2009] ) is well-known for its wide use for knowledge representation in the form of inheritance-based ontologies and lexica( Trott et al. [2020] ). Although FrameNet is usually applied to languages like English, Spanish and Italian, there are still plenty of FrameNet data sets available for other languages like Chinese, which differs significantly from those languages based on Latin alphabets. In this paper, the translation from ancient Chinese Poetry to modern Chinese will be first conducted to further apply the Chinese FrameNet(CFN, provided by Shanxi University). Afterwards, the translation from modern Chinese will be conducted as well for the comparison between the applications of CFN and English FrameNet. Finally, the overall comparison will be draw between CFN to modern Chinese and English FrameNet.

</p>
</details>

<details><summary><b>TetGAN: A Convolutional Neural Network for Tetrahedral Mesh Generation</b>
<a href="https://arxiv.org/abs/2210.05735">arxiv:2210.05735</a>
&#x1F4C8; 3 <br>
<p>William Gao, April Wang, Gal Metzer, Raymond A. Yeh, Rana Hanocka</p></summary>
<p>

**Abstract:** We present TetGAN, a convolutional neural network designed to generate tetrahedral meshes. We represent shapes using an irregular tetrahedral grid which encodes an occupancy and displacement field. Our formulation enables defining tetrahedral convolution, pooling, and upsampling operations to synthesize explicit mesh connectivity with variable topological genus. The proposed neural network layers learn deep features over each tetrahedron and learn to extract patterns within spatial regions across multiple scales. We illustrate the capabilities of our technique to encode tetrahedral meshes into a semantically meaningful latent-space which can be used for shape editing and synthesis. Our project page is at https://threedle.github.io/tetGAN/.

</p>
</details>

<details><summary><b>Geometry of Radial Basis Neural Networks for Safety Biased Approximation of Unsafe Regions</b>
<a href="https://arxiv.org/abs/2210.05596">arxiv:2210.05596</a>
&#x1F4C8; 3 <br>
<p>Ahmad Abuaish, Mohit Srinivasan, Patricio A. Vela</p></summary>
<p>

**Abstract:** Barrier function-based inequality constraints are a means to enforce safety specifications for control systems. When used in conjunction with a convex optimization program, they provide a computationally efficient method to enforce safety for the general class of control-affine systems. One of the main assumptions when taking this approach is the a priori knowledge of the barrier function itself, i.e., knowledge of the safe set. In the context of navigation through unknown environments where the locally safe set evolves with time, such knowledge does not exist. This manuscript focuses on the synthesis of a zeroing barrier function characterizing the safe set based on safe and unsafe sample measurements, e.g., from perception data in navigation applications. Prior work formulated a supervised machine learning algorithm whose solution guaranteed the construction of a zeroing barrier function with specific level-set properties. However, it did not explore the geometry of the neural network design used for the synthesis process. This manuscript describes the specific geometry of the neural network used for zeroing barrier function synthesis, and shows how the network provides the necessary representation for splitting the state space into safe and unsafe regions.

</p>
</details>

<details><summary><b>On Adaptivity in Non-stationary Stochastic Optimization With Bandit Feedback</b>
<a href="https://arxiv.org/abs/2210.05584">arxiv:2210.05584</a>
&#x1F4C8; 3 <br>
<p>Yining Wang</p></summary>
<p>

**Abstract:** In this paper we study the non-stationary stochastic optimization question with bandit feedback and dynamic regret measures. The seminal work of Besbes et al. (2015) shows that, when aggregated function changes is known a priori, a simple re-starting algorithm attains the optimal dynamic regret. In this work, we designed a stochastic optimization algorithm with fixed step sizes, which combined together with the multi-scale sampling framework of Wei and Luo (2021) achieves the optimal dynamic regret in non-stationary stochastic optimization without requiring prior knowledge of function change budget, thereby closes a question that has been open for a while. We also establish an additional result showing that any algorithm achieving good regret against stationary benchmarks with high probability could be automatically converted to an algorithm that achieves good regret against dynamic benchmarks, which is applicable to a wide class of bandit convex optimization algorithms.

</p>
</details>

<details><summary><b>Misspecified Phase Retrieval with Generative Priors</b>
<a href="https://arxiv.org/abs/2210.05571">arxiv:2210.05571</a>
&#x1F4C8; 3 <br>
<p>Zhaoqiang Liu, Xinshao Wang, Jiulong Liu</p></summary>
<p>

**Abstract:** In this paper, we study phase retrieval under model misspecification and generative priors. In particular, we aim to estimate an $n$-dimensional signal $\mathbf{x}$ from $m$ i.i.d.~realizations of the single index model $y = f(\mathbf{a}^T\mathbf{x})$, where $f$ is an unknown and possibly random nonlinear link function and $\mathbf{a} \in \mathbb{R}^n$ is a standard Gaussian vector. We make the assumption $\mathrm{Cov}[y,(\mathbf{a}^T\mathbf{x})^2] \ne 0$, which corresponds to the misspecified phase retrieval problem. In addition, the underlying signal $\mathbf{x}$ is assumed to lie in the range of an $L$-Lipschitz continuous generative model with bounded $k$-dimensional inputs. We propose a two-step approach, for which the first step plays the role of spectral initialization and the second step refines the estimated vector produced by the first step iteratively. We show that both steps enjoy a statistical rate of order $\sqrt{(k\log L)\cdot (\log m)/m}$ under suitable conditions. Experiments on image datasets are performed to demonstrate that our approach performs on par with or even significantly outperforms several competing methods.

</p>
</details>

<details><summary><b>Bi-Phase Enhanced IVFPQ for Time-Efficient Ad-hoc Retrieval</b>
<a href="https://arxiv.org/abs/2210.05521">arxiv:2210.05521</a>
&#x1F4C8; 3 <br>
<p>Peitian Zhang, Zheng Liu</p></summary>
<p>

**Abstract:** IVFPQ is a popular index paradigm for time-efficient ad-hoc retrieval. Instead of traversing the entire database for relevant documents, it accelerates the retrieval operation by 1) accessing a fraction of the database guided the activation of latent topics in IVF (inverted file system), and 2) approximating the exact relevance measurement based on PQ (product quantization). However, the conventional IVFPQ is limited in retrieval performance due to the coarse granularity of its latent topics. On the one hand, it may result in severe loss of retrieval quality when visiting a small number of topics; on the other hand, it will lead to a huge retrieval cost when visiting a large number of topics.
  To mitigate the above problem, we propose a novel framework named Bi-Phase IVFPQ. It jointly uses two types of features: the latent topics and the explicit terms, to build the inverted file system. Both types of features are complementary to each other, which helps to achieve better coverage of the relevant documents. Besides, the documents' memberships to different IVF entries are learned by distilling knowledge from deep semantic models, which substantially improves the index quality and retrieval accuracy. We perform comprehensive empirical studies on popular ad-hoc retrieval benchmarks, whose results verify the effectiveness and efficiency of our proposed framework.

</p>
</details>

<details><summary><b>Detect, Distill and Update: Learned DB Systems Facing Out of Distribution Data</b>
<a href="https://arxiv.org/abs/2210.05508">arxiv:2210.05508</a>
&#x1F4C8; 3 <br>
<p>Meghdad Kurmanji, Peter Triantafillou</p></summary>
<p>

**Abstract:** Machine Learning (ML) is changing DBs as many DB components are being replaced by ML models. One open problem in this setting is how to update such ML models in the presence of data updates. We start this investigation focusing on data insertions (dominating updates in analytical DBs). We study how to update neural network (NN) models when new data follows a different distribution (a.k.a. it is "out-of-distribution" -- OOD), rendering previously-trained NNs inaccurate. A requirement in our problem setting is that learned DB components should ensure high accuracy for tasks on old and new data (e.g., for approximate query processing (AQP), cardinality estimation (CE), synthetic data generation (DG), etc.). This paper proposes a novel updatability framework (DDUp). DDUp can provide updatability for different learned DB system components, even based on different NNs, without the high costs to retrain the NNs from scratch. DDUp entails two components: First, a novel, efficient, and principled statistical-testing approach to detect OOD data. Second, a novel model updating approach, grounded on the principles of transfer learning with knowledge distillation, to update learned models efficiently, while still ensuring high accuracy. We develop and showcase DDUp's applicability for three different learned DB components, AQP, CE, and DG, each employing a different type of NN. Detailed experimental evaluation using real and benchmark datasets for AQP, CE, and DG detail DDUp's performance advantages.

</p>
</details>

<details><summary><b>High-precision Density Mapping of Marine Debris and Floating Plastics via Satellite Imagery</b>
<a href="https://arxiv.org/abs/2210.05468">arxiv:2210.05468</a>
&#x1F4C8; 3 <br>
<p>Henry Booth, Wanli Ma, Oktay Karakus</p></summary>
<p>

**Abstract:** Combining multi-spectral satellite data and machine learning has been suggested as a method for monitoring plastic pollutants in the ocean environment. Recent studies have made theoretical progress regarding the identification of marine plastic via machine learning. However, no study has assessed the application of these methods for mapping and monitoring marine-plastic density. As such, this paper comprised of three main components: (1) the development of a machine learning model, (2) the construction of the MAP-Mapper, an automated tool for mapping marine-plastic density, and finally (3) an evaluation of the whole system for out-of-distribution test locations. The findings from this paper leverage the fact that machine learning models need to be high-precision to reduce the impact of false positives on results. The developed MAP-Mapper architectures provide users choices to reach high-precision ($\textit{abbv.}$ -HP) or optimum precision-recall ($\textit{abbv.}$ -Opt) values in terms of the training/test data set. Our MAP-Mapper-HP model greatly increased the precision of plastic detection to 95\%, whilst MAP-Mapper-Opt reaches precision-recall pair of 87\%-88\%. The MAP-Mapper contributes to the literature with the first tool to exploit advanced deep/machine learning and multi-spectral imagery to map marine-plastic density in automated software. The proposed data pipeline has taken a novel approach to map plastic density in ocean regions. As such, this enables an initial assessment of the challenges and opportunities of this method to help guide future work and scientific study.

</p>
</details>

<details><summary><b>Non-Asymptotic Analysis of a UCB-based Top Two Algorithm</b>
<a href="https://arxiv.org/abs/2210.05431">arxiv:2210.05431</a>
&#x1F4C8; 3 <br>
<p>Marc Jourdan, R√©my Degenne</p></summary>
<p>

**Abstract:** A Top Two sampling rule for bandit identification is a method which selects the next arm to sample from among two candidate arms, a leader and a challenger. Due to their simplicity and good empirical performance, they have received increased attention in recent years. For fixed-confidence best arm identification, theoretical guarantees for Top Two methods have only been obtained in the asymptotic regime, when the error level vanishes. We derive the first non-asymptotic upper bound on the expected sample complexity of a Top Two algorithm holding for any error level. Our analysis highlights sufficient properties for a regret minimization algorithm to be used as leader. They are satisfied by the UCB algorithm and our proposed UCB-based Top Two algorithm enjoys simultaneously non-asymptotic guarantees and competitive empirical performance.

</p>
</details>

<details><summary><b>Rethinking the Event Coding Pipeline with Prompt Entailment</b>
<a href="https://arxiv.org/abs/2210.05257">arxiv:2210.05257</a>
&#x1F4C8; 3 <br>
<p>Cl√©ment Lefebvre, Niklas Stoehr</p></summary>
<p>

**Abstract:** For monitoring crises, political events are extracted from the news. The large amount of unstructured full-text event descriptions makes a case-by-case analysis unmanageable, particularly for low-resource humanitarian aid organizations. This creates a demand to classify events into event types, a task referred to as event coding. Typically, domain experts craft an event type ontology, annotators label a large dataset and technical experts develop a supervised coding system. In this work, we propose PR-ENT, a new event coding approach that is more flexible and resource-efficient, while maintaining competitive accuracy: first, we extend an event description such as "Military injured two civilians'' by a template, e.g. "People were [Z]" and prompt a pre-trained (cloze) language model to fill the slot Z. Second, we select answer candidates Z* = {"injured'', "hurt"...} by treating the event description as premise and the filled templates as hypothesis in a textual entailment task. This allows domain experts to draft the codebook directly as labeled prompts and interpretable answer candidates. This human-in-the-loop process is guided by our interactive codebook design tool. We evaluate PR-ENT in several robustness checks: perturbing the event description and prompt template, restricting the vocabulary and removing contextual information.

</p>
</details>

<details><summary><b>Multi-site Diagnostic Classification Of Schizophrenia Using 3D CNN On Aggregated Task-based fMRI Data</b>
<a href="https://arxiv.org/abs/2210.05240">arxiv:2210.05240</a>
&#x1F4C8; 3 <br>
<p>Vigneshwaran Shankaran, Bhaskaran V</p></summary>
<p>

**Abstract:** In spite of years of research, the mechanisms that underlie the development of schizophrenia, as well as its relapse, symptomatology, and treatment, continue to be a mystery. The absence of appropriate analytic tools to deal with the variable and complicated nature of schizophrenia may be one of the factors that contribute to the development of this disorder. Deep learning is a subfield of artificial intelligence that was inspired by the nervous system. In recent years, deep learning has made it easier to model and analyse complicated, high-dimensional, and nonlinear systems. Research on schizophrenia is one of the many areas of study that has been revolutionised as a result of the outstanding accuracy that deep learning algorithms have demonstrated in classification and prediction tasks. Deep learning has the potential to become a powerful tool for understanding the mechanisms that are at the root of schizophrenia. In addition, a growing variety of techniques aimed at improving model interpretability and causal reasoning are contributing to this trend. Using multi-site fMRI data and a variety of deep learning approaches, this study seeks to identify different types of schizophrenia. Our proposed method of temporal aggregation of the 4D fMRI data outperforms existing work. In addition, this study aims to shed light on the strength of connections between various brain areas in schizophrenia individuals.

</p>
</details>

<details><summary><b>Planning Assembly Sequence with Graph Transformer</b>
<a href="https://arxiv.org/abs/2210.05236">arxiv:2210.05236</a>
&#x1F4C8; 3 <br>
<p>Lin Ma, Jiangtao Gong, Hao Xu, Hao Chen, Hao Zhao, Wenbing Huang, Guyue Zhou</p></summary>
<p>

**Abstract:** Assembly sequence planning (ASP) is the essential process for modern manufacturing, proven to be NP-complete thus its effective and efficient solution has been a challenge for researchers in the field. In this paper, we present a graph-transformer based framework for the ASP problem which is trained and demonstrated on a self-collected ASP database. The ASP database contains a self-collected set of LEGO models. The LEGO model is abstracted to a heterogeneous graph structure after a thorough analysis of the original structure and feature extraction. The ground truth assembly sequence is first generated by brute-force search and then adjusted manually to in line with human rational habits. Based on this self-collected ASP dataset, we propose a heterogeneous graph-transformer framework to learn the latent rules for assembly planning. We evaluated the proposed framework in a series of experiment. The results show that the similarity of the predicted and ground truth sequences can reach 0.44, a medium correlation measured by Kendall's $œÑ$. Meanwhile, we compared the different effects of node features and edge features and generated a feasible and reasonable assembly sequence as a benchmark for further research. Our data set and code is available on https://github.com/AIR-DISCOVER/ICRA\_ASP.

</p>
</details>

<details><summary><b>Mixed-modality Representation Learning and Pre-training for Joint Table-and-Text Retrieval in OpenQA</b>
<a href="https://arxiv.org/abs/2210.05197">arxiv:2210.05197</a>
&#x1F4C8; 3 <br>
<p>Junjie Huang, Wanjun Zhong, Qian Liu, Ming Gong, Daxin Jiang, Nan Duan</p></summary>
<p>

**Abstract:** Retrieving evidences from tabular and textual resources is essential for open-domain question answering (OpenQA), which provides more comprehensive information. However, training an effective dense table-text retriever is difficult due to the challenges of table-text discrepancy and data sparsity problem. To address the above challenges, we introduce an optimized OpenQA Table-Text Retriever (OTTeR) to jointly retrieve tabular and textual evidences. Firstly, we propose to enhance mixed-modality representation learning via two mechanisms: modality-enhanced representation and mixed-modality negative sampling strategy. Secondly, to alleviate data sparsity problem and enhance the general retrieval ability, we conduct retrieval-centric mixed-modality synthetic pre-training. Experimental results demonstrate that OTTeR substantially improves the performance of table-and-text retrieval on the OTT-QA dataset. Comprehensive analyses examine the effectiveness of all the proposed mechanisms. Besides, equipped with OTTeR, our OpenQA system achieves the state-of-the-art result on the downstream QA task, with 10.1% absolute improvement in terms of the exact match over the previous best system. 
  All the code and data are available at https://github.com/Jun-jie-Huang/OTTeR.

</p>
</details>

<details><summary><b>Legal Element-oriented Modeling with Multi-view Contrastive Learning for Legal Case Retrieval</b>
<a href="https://arxiv.org/abs/2210.05188">arxiv:2210.05188</a>
&#x1F4C8; 3 <br>
<p>Zhaowei Wang</p></summary>
<p>

**Abstract:** Legal case retrieval, which aims to retrieve relevant cases given a query case, plays an essential role in the legal system. While recent research efforts improve the performance of traditional ad-hoc retrieval models, legal case retrieval is still challenging since queries are legal cases, which contain hundreds of tokens. Legal cases are much longer and more complicated than keywords queries. Apart from that, the definition of legal relevance is beyond the general definition. In addition to general topical relevance, the relevant cases also involve similar situations and legal elements, which can support the judgment of the current case. In this paper, we propose an interaction-focused network for legal case retrieval with a multi-view contrastive learning objective. The contrastive learning views, including case-view and element-view, aim to overcome the above challenges. The case-view contrastive learning minimizes the hidden space distance between relevant legal case representations produced by a pre-trained language model (PLM) encoder. The element-view builds positive and negative instances by changing legal elements of cases to help the network better compute legal relevance. To achieve this, we employ a legal element knowledge-aware indicator to detect legal elements of cases. We conduct extensive experiments on the benchmark of relevant case retrieval. Evaluation results indicate our proposed method obtains significant improvement over the existing methods.

</p>
</details>

<details><summary><b>Make Sharpness-Aware Minimization Stronger: A Sparsified Perturbation Approach</b>
<a href="https://arxiv.org/abs/2210.05177">arxiv:2210.05177</a>
&#x1F4C8; 3 <br>
<p>Peng Mi, Li Shen, Tianhe Ren, Yiyi Zhou, Xiaoshuai Sun, Rongrong Ji, Dacheng Tao</p></summary>
<p>

**Abstract:** Deep neural networks often suffer from poor generalization caused by complex and non-convex loss landscapes. One of the popular solutions is Sharpness-Aware Minimization (SAM), which smooths the loss landscape via minimizing the maximized change of training loss when adding a perturbation to the weight. However, we find the indiscriminate perturbation of SAM on all parameters is suboptimal, which also results in excessive computation, i.e., double the overhead of common optimizers like Stochastic Gradient Descent (SGD). In this paper, we propose an efficient and effective training scheme coined as Sparse SAM (SSAM), which achieves sparse perturbation by a binary mask. To obtain the sparse mask, we provide two solutions which are based onFisher information and dynamic sparse training, respectively. In addition, we theoretically prove that SSAM can converge at the same rate as SAM, i.e., $O(\log T/\sqrt{T})$. Sparse SAM not only has the potential for training acceleration but also smooths the loss landscape effectively. Extensive experimental results on CIFAR10, CIFAR100, and ImageNet-1K confirm the superior efficiency of our method to SAM, and the performance is preserved or even better with a perturbation of merely 50% sparsity. Code is availiable at https://github.com/Mi-Peng/Sparse-Sharpness-Aware-Minimization.

</p>
</details>

<details><summary><b>Fine-Grained Image Style Transfer with Visual Transformers</b>
<a href="https://arxiv.org/abs/2210.05176">arxiv:2210.05176</a>
&#x1F4C8; 3 <br>
<p>Jianbo Wang, Huan Yang, Jianlong Fu, Toshihiko Yamasaki, Baining Guo</p></summary>
<p>

**Abstract:** With the development of the convolutional neural network, image style transfer has drawn increasing attention. However, most existing approaches adopt a global feature transformation to transfer style patterns into content images (e.g., AdaIN and WCT). Such a design usually destroys the spatial information of the input images and fails to transfer fine-grained style patterns into style transfer results. To solve this problem, we propose a novel STyle TRansformer (STTR) network which breaks both content and style images into visual tokens to achieve a fine-grained style transformation. Specifically, two attention mechanisms are adopted in our STTR. We first propose to use self-attention to encode content and style tokens such that similar tokens can be grouped and learned together. We then adopt cross-attention between content and style tokens that encourages fine-grained style transformations. To compare STTR with existing approaches, we conduct user studies on Amazon Mechanical Turk (AMT), which are carried out with 50 human subjects with 1,000 votes in total. Extensive evaluations demonstrate the effectiveness and efficiency of the proposed STTR in generating visually pleasing style transfer results.

</p>
</details>

<details><summary><b>On Explainability in AI-Solutions: A Cross-Domain Survey</b>
<a href="https://arxiv.org/abs/2210.05173">arxiv:2210.05173</a>
&#x1F4C8; 3 <br>
<p>Simon Daniel Duque Anton, Daniel Schneider, Hans Dieter Schotten</p></summary>
<p>

**Abstract:** Artificial Intelligence (AI) increasingly shows its potential to outperform predicate logic algorithms and human control alike. In automatically deriving a system model, AI algorithms learn relations in data that are not detectable for humans. This great strength, however, also makes use of AI methods dubious. The more complex a model, the more difficult it is for a human to understand the reasoning for the decisions. As currently, fully automated AI algorithms are sparse, every algorithm has to provide a reasoning for human operators. For data engineers, metrics such as accuracy and sensitivity are sufficient. However, if models are interacting with non-experts, explanations have to be understandable. This work provides an extensive survey of literature on this topic, which, to a large part, consists of other surveys. The findings are mapped to ways of explaining decisions and reasons for explaining decisions. It shows that the heterogeneity of reasons and methods of and for explainability lead to individual explanatory frameworks.

</p>
</details>

<details><summary><b>Contrastive Trajectory Similarity Learning with Dual-Feature Attention</b>
<a href="https://arxiv.org/abs/2210.05155">arxiv:2210.05155</a>
&#x1F4C8; 3 <br>
<p>Yanchuan Chang, Jianzhong Qi, Yuxuan Liang, Egemen Tanin</p></summary>
<p>

**Abstract:** Trajectory similarity measures act as query predicates in trajectory databases, making them the key player in determining the query results. They also have a heavy impact on the query efficiency. An ideal measure should have the capability to accurately evaluate the similarity between any two trajectories in a very short amount of time. However, existing heuristic measures are mainly based on pointwise comparisons following hand-crafted rules, thus resulting in either poor quality results or low efficiency in many cases. Although several deep learning-based measures have recently aimed at these problems, their improvements are limited by the difficulties to learn the fine-grained spatial patterns of trajectories.
  To address these issues, we propose a contrastive learning-based trajectory modelling method named TrajCL, which is robust in application scenarios where the data set contains low-quality trajectories. Specifically, we present four trajectory augmentation methods and a novel dual-feature self-attention-based trajectory backbone encoder. The resultant model can jointly learn both the spatial and the structural patterns of trajectories. Our model does not involve any recurrent structures and thus has a high efficiency. Besides, our pre-trained backbone encoder can be fine-tuned towards other computationally expensive measures with minimal supervision data. Experimental results show that TrajCL is consistently and significantly more accurate and faster than the state-of-the-art trajectory similarity measures. After fine-tuning, i.e., when being used as an estimator for heuristic measures, TrajCL can even outperform the state-of-the-art supervised method by up to 32% in the accuracy for processing trajectory similarity queries.

</p>
</details>

<details><summary><b>Scenario-based Evaluation of Prediction Models for Automated Vehicles</b>
<a href="https://arxiv.org/abs/2210.06553">arxiv:2210.06553</a>
&#x1F4C8; 2 <br>
<p>Manuel Mu√±oz S√°nchez, Jos Elfring, Emilia Silvas, Ren√© van de Molengraft</p></summary>
<p>

**Abstract:** To operate safely, an automated vehicle (AV) must anticipate how the environment around it will evolve. For that purpose, it is important to know which prediction models are most appropriate for every situation. Currently, assessment of prediction models is often performed over a set of trajectories without distinction of the type of movement they capture, resulting in the inability to determine the suitability of each model for different situations. In this work we illustrate how standardized evaluation methods result in wrong conclusions regarding a model's predictive capabilities, preventing a clear assessment of prediction models and potentially leading to dangerous on-road situations. We argue that following evaluation practices in safety assessment for AVs, assessment of prediction models should be performed in a scenario-based fashion. To encourage scenario-based assessment of prediction models and illustrate the dangers of improper assessment, we categorize trajectories of the Waymo Open Motion dataset according to the type of movement they capture. Next, three different models are thoroughly evaluated for different trajectory types and prediction horizons. Results show that common evaluation methods are insufficient and the assessment should be performed depending on the application in which the model will operate.

</p>
</details>

<details><summary><b>The evolution of AI approaches for motor imagery EEG-based BCIs</b>
<a href="https://arxiv.org/abs/2210.06290">arxiv:2210.06290</a>
&#x1F4C8; 2 <br>
<p>Aurora Saibene, Silvia Corchs, Mirko Caglioni, Francesca Gasparini</p></summary>
<p>

**Abstract:** The Motor Imagery (MI) electroencephalography (EEG) based Brain Computer Interfaces (BCIs) allow the direct communication between humans and machines by exploiting the neural pathways connected to motor imagination. Therefore, these systems open the possibility of developing applications that could span from the medical field to the entertainment industry. In this context, Artificial Intelligence (AI) approaches become of fundamental importance especially when wanting to provide a correct and coherent feedback to BCI users. Moreover, publicly available datasets in the field of MI EEG-based BCIs have been widely exploited to test new techniques from the AI domain. In this work, AI approaches applied to datasets collected in different years and with different devices but with coherent experimental paradigms are investigated with the aim of providing a concise yet sufficiently comprehensive survey on the evolution and influence of AI techniques on MI EEG-based BCI data.

</p>
</details>

<details><summary><b>Travel the Same Path: A Novel TSP Solving Strategy</b>
<a href="https://arxiv.org/abs/2210.05906">arxiv:2210.05906</a>
&#x1F4C8; 2 <br>
<p>Pingbang Hu</p></summary>
<p>

**Abstract:** In this paper, we provide a novel strategy for solving Traveling Salesman Problem, which is a famous combinatorial optimization problem studied intensely in the TCS community. In particular, we consider the imitation learning framework, which helps a deterministic algorithm making good choices whenever it needs to, resulting in a speed up while maintaining the exactness of the solution without suffering from the unpredictability and a potential large deviation.
  Furthermore, we demonstrate a strong generalization ability of a graph neural network trained under the imitation learning framework. Specifically, the model is capable of solving a large instance of TSP faster than the baseline while has only seen small TSP instances when training.

</p>
</details>

<details><summary><b>Deep Learning for Iris Recognition: A Survey</b>
<a href="https://arxiv.org/abs/2210.05866">arxiv:2210.05866</a>
&#x1F4C8; 2 <br>
<p>Kien Nguyen, Hugo Proen√ßa, Fernando Alonso-Fernandez</p></summary>
<p>

**Abstract:** In this survey, we provide a comprehensive review of more than 200 papers, technical reports, and GitHub repositories published over the last 10 years on the recent developments of deep learning techniques for iris recognition, covering broad topics on algorithm designs, open-source tools, open challenges, and emerging research. First, we conduct a comprehensive analysis of deep learning techniques developed for two main sub-tasks in iris biometrics: segmentation and recognition. Second, we focus on deep learning techniques for the robustness of iris recognition systems against presentation attacks and via human-machine pairing. Third, we delve deep into deep learning techniques for forensic application, especially in post-mortem iris recognition. Fourth, we review open-source resources and tools in deep learning techniques for iris recognition. Finally, we highlight the technical challenges, emerging research trends, and outlook for the future of deep learning in iris recognition.

</p>
</details>

<details><summary><b>Contrastive introspection (ConSpec) to rapidly identify invariant steps for success</b>
<a href="https://arxiv.org/abs/2210.05845">arxiv:2210.05845</a>
&#x1F4C8; 2 <br>
<p>Chen Sun, Wannan Yang, Benjamin Alsbury-Nealy, Yoshua Bengio, Blake Richards</p></summary>
<p>

**Abstract:** Reinforcement learning (RL) algorithms have achieved notable success in recent years, but still struggle with fundamental issues in long-term credit assignment. It remains difficult to learn in situations where success is contingent upon multiple critical steps that are distant in time from each other and from a sparse reward; as is often the case in real life. Moreover, how RL algorithms assign credit in these difficult situations is typically not coded in a way that can rapidly generalize to new situations. Here, we present an approach using offline contrastive learning, which we call contrastive introspection (ConSpec), that can be added to any existing RL algorithm and addresses both issues. In ConSpec, a contrastive loss is used during offline replay to identify invariances among successful episodes. This takes advantage of the fact that it is easier to retrospectively identify the small set of steps that success is contingent upon than it is to prospectively predict reward at every step taken in the environment. ConSpec stores this knowledge in a collection of prototypes summarizing the intermediate states required for success. During training, arrival at any state that matches these prototypes generates an intrinsic reward that is added to any external rewards. As well, the reward shaping provided by ConSpec can be made to preserve the optimal policy of the underlying RL agent. The prototypes in ConSpec provide two key benefits for credit assignment: (1) They enable rapid identification of all the critical states. (2) They do so in a readily interpretable manner, enabling out of distribution generalization when sensory features are altered. In summary, ConSpec is a modular system that can be added to any existing RL algorithm to improve its long-term credit assignment.

</p>
</details>

<details><summary><b>Controllable Radiance Fields for Dynamic Face Synthesis</b>
<a href="https://arxiv.org/abs/2210.05825">arxiv:2210.05825</a>
&#x1F4C8; 2 <br>
<p>Peiye Zhuang, Liqian Ma, Oluwasanmi Koyejo, Alexander G. Schwing</p></summary>
<p>

**Abstract:** Recent work on 3D-aware image synthesis has achieved compelling results using advances in neural rendering. However, 3D-aware synthesis of face dynamics hasn't received much attention. Here, we study how to explicitly control generative model synthesis of face dynamics exhibiting non-rigid motion (e.g., facial expression change), while simultaneously ensuring 3D-awareness. For this we propose a Controllable Radiance Field (CoRF): 1) Motion control is achieved by embedding motion features within the layered latent motion space of a style-based generator; 2) To ensure consistency of background, motion features and subject-specific attributes such as lighting, texture, shapes, albedo, and identity, a face parsing net, a head regressor and an identity encoder are incorporated. On head image/video data we show that CoRFs are 3D-aware while enabling editing of identity, viewing directions, and motion.

</p>
</details>

<details><summary><b>Short-term prediction of stream turbidity using surrogate data and a meta-model approach</b>
<a href="https://arxiv.org/abs/2210.05821">arxiv:2210.05821</a>
&#x1F4C8; 2 <br>
<p>Bhargav Rele, Caleb Hogan, Sevvandi Kandanaarachchi, Catherine Leigh</p></summary>
<p>

**Abstract:** Many water-quality monitoring programs aim to measure turbidity to help guide effective management of waterways and catchments, yet distributing turbidity sensors throughout networks is typically cost prohibitive. To this end, we built and compared the ability of dynamic regression (ARIMA), long short-term memory neural nets (LSTM), and generalized additive models (GAM) to forecast stream turbidity one step ahead, using surrogate data from relatively low-cost in-situ sensors and publicly available databases. We iteratively trialled combinations of four surrogate covariates (rainfall, water level, air temperature and total global solar exposure) selecting a final model for each type that minimised the corrected Akaike Information Criterion. Cross-validation using a rolling time-window indicated that ARIMA, which included the rainfall and water-level covariates only, produced the most accurate predictions, followed closely by GAM, which included all four covariates. We constructed a meta-model, trained on time-series features of turbidity, to take advantage of the strengths of each model over different time points and predict the best model (that with the lowest forecast error one-step prior) for each time step. The meta-model outperformed all other models, indicating that this methodology can yield high accuracy and may be a viable alternative to using measurements sourced directly from turbidity-sensors where costs prohibit their deployment and maintenance, and when predicting turbidity across the short term. Our findings also indicated that temperature and light-associated variables, for example underwater illuminance, may hold promise as cost-effective, high-frequency surrogates of turbidity, especially when combined with other covariates, like rainfall, that are typically measured at coarse levels of spatial resolution.

</p>
</details>

<details><summary><b>Trading Off Resource Budgets for Improved Regret Bounds</b>
<a href="https://arxiv.org/abs/2210.05789">arxiv:2210.05789</a>
&#x1F4C8; 2 <br>
<p>Damon Falck, Thomas Orton</p></summary>
<p>

**Abstract:** In this work we consider a variant of adversarial online learning where in each round one picks $B$ out of $N$ arms and incurs cost equal to the $\textit{minimum}$ of the costs of each arm chosen. We propose an algorithm called Follow the Perturbed Multiple Leaders (FPML) for this problem, which we show (by adapting the techniques of Kalai and Vempala [2005]) achieves expected regret $\mathcal{O}(T^{\frac{1}{B+1}}\ln(N)^{\frac{B}{B+1}})$ over time horizon $T$ relative to the $\textit{single}$ best arm in hindsight. This introduces a trade-off between the budget $B$ and the single-best-arm regret, and we proceed to investigate several applications of this trade-off. First, we observe that algorithms which use standard regret minimizers as subroutines can sometimes be adapted by replacing these subroutines with FPML, and we use this to generalize existing algorithms for Online Submodular Function Maximization [Streeter and Golovin, 2008] in both the full feedback and semi-bandit feedback settings. Next, we empirically evaluate our new algorithms on an online black-box hyperparameter optimization problem. Finally, we show how FPML can lead to new algorithms for Linear Programming which require stronger oracles at the benefit of fewer oracle calls.

</p>
</details>

<details><summary><b>Towards Discriminative and Transferable One-Stage Few-Shot Object Detectors</b>
<a href="https://arxiv.org/abs/2210.05783">arxiv:2210.05783</a>
&#x1F4C8; 2 <br>
<p>Karim Guirguis, Mohamed Abdelsamad, George Eskandar, Ahmed Hendawy, Matthias Kayser, Bin Yang, Juergen Beyerer</p></summary>
<p>

**Abstract:** Recent object detection models require large amounts of annotated data for training a new classes of objects. Few-shot object detection (FSOD) aims to address this problem by learning novel classes given only a few samples. While competitive results have been achieved using two-stage FSOD detectors, typically one-stage FSODs underperform compared to them. We make the observation that the large gap in performance between two-stage and one-stage FSODs are mainly due to their weak discriminability, which is explained by a small post-fusion receptive field and a small number of foreground samples in the loss function. To address these limitations, we propose the Few-shot RetinaNet (FSRN) that consists of: a multi-way support training strategy to augment the number of foreground samples for dense meta-detectors, an early multi-level feature fusion providing a wide receptive field that covers the whole anchor area and two augmentation techniques on query and source images to enhance transferability. Extensive experiments show that the proposed approach addresses the limitations and boosts both discriminability and transferability. FSRN is almost two times faster than two-stage FSODs while remaining competitive in accuracy, and it outperforms the state-of-the-art of one-stage meta-detectors and also some two-stage FSODs on the MS-COCO and PASCAL VOC benchmarks.

</p>
</details>

<details><summary><b>Gradient-Guided Importance Sampling for Learning Binary Energy-Based Models</b>
<a href="https://arxiv.org/abs/2210.05782">arxiv:2210.05782</a>
&#x1F4C8; 2 <br>
<p>Meng Liu, Haoran Liu, Shuiwang Ji</p></summary>
<p>

**Abstract:** Learning energy-based models (EBMs) is known to be difficult especially on discrete data where gradient-based learning strategies cannot be applied directly. Although ratio matching is a sound method to learn discrete EBMs, it suffers from expensive computation and excessive memory requirement, thereby resulting in difficulties for learning EBMs on high-dimensional data. Motivated from these limitations, in this study, we propose ratio matching with gradient-guided importance sampling (RMwGGIS). Particularly, we use the gradient of the energy function w.r.t. the discrete data space to approximately construct the provably optimal proposal distribution, which is subsequently used by importance sampling to efficiently estimate the original ratio matching objective. We perform experiments on density modeling over synthetic discrete data, graph generation, and training Ising models to evaluate our proposed method. The experimental results demonstrate that our method can significantly alleviate the limitations of ratio matching, perform more effectively in practice, and scale to high-dimensional problems. Our implementation is available at {https://github.com/divelab/RMwGGIS.

</p>
</details>

<details><summary><b>Match Cutting: Finding Cuts with Smooth Visual Transitions</b>
<a href="https://arxiv.org/abs/2210.05766">arxiv:2210.05766</a>
&#x1F4C8; 2 <br>
<p>Boris Chen, Amir Ziai, Rebecca Tucker, Yuchen Xie</p></summary>
<p>

**Abstract:** A match cut is a transition between a pair of shots that uses similar framing, composition, or action to fluidly bring the viewer from one scene to the next. Match cuts are frequently used in film, television, and advertising. However, finding shots that work together is a highly manual and time-consuming process that can take days. We propose a modular and flexible system to efficiently find high-quality match cut candidates starting from millions of shot pairs. We annotate and release a dataset of approximately 20k labeled pairs that we use to evaluate our system, using both classification and metric learning approaches that leverage a variety of image, video, audio, and audio-visual feature extractors. In addition, we release code and embeddings for reproducing our experiments at github.com/netflix/matchcut.

</p>
</details>

<details><summary><b>On RKHS Choices for Assessing Graph Generators via Kernel Stein Statistics</b>
<a href="https://arxiv.org/abs/2210.05746">arxiv:2210.05746</a>
&#x1F4C8; 2 <br>
<p>Moritz Weckbecker, Wenkai Xu, Gesine Reinert</p></summary>
<p>

**Abstract:** Score-based kernelised Stein discrepancy (KSD) tests have emerged as a powerful tool for the goodness of fit tests, especially in high dimensions; however, the test performance may depend on the choice of kernels in an underlying reproducing kernel Hilbert space (RKHS). Here we assess the effect of RKHS choice for KSD tests of random networks models, developed for exponential random graph models (ERGMs) in Xu and Reinert (2021)and for synthetic graph generators in Xu and Reinert (2022). We investigate the power performance and the computational runtime of the test in different scenarios, including both dense and sparse graph regimes. Experimental results on kernel performance for model assessment tasks are shown and discussed on synthetic and real-world network applications.

</p>
</details>

<details><summary><b>Stochastic Constrained DRO with a Complexity Independent of Sample Size</b>
<a href="https://arxiv.org/abs/2210.05740">arxiv:2210.05740</a>
&#x1F4C8; 2 <br>
<p>Qi Qi, Jiameng Lyu, Kung sik Chan, Er Wei Bai, Tianbao Yang</p></summary>
<p>

**Abstract:** Distributionally Robust Optimization (DRO), as a popular method to train robust models against distribution shift between training and test sets, has received tremendous attention in recent years. In this paper, we propose and analyze stochastic algorithms that apply to both non-convex and convex losses for solving Kullback Leibler divergence constrained DRO problem. Compared with existing methods solving this problem, our stochastic algorithms not only enjoy competitive if not better complexity independent of sample size but also just require a constant batch size at every iteration, which is more practical for broad applications. We establish a nearly optimal complexity bound for finding an $Œµ$ stationary solution for non-convex losses and an optimal complexity for finding an $Œµ$ optimal solution for convex losses. Empirical studies demonstrate the effectiveness of the proposed algorithms for solving non-convex and convex constrained DRO problems.

</p>
</details>

<details><summary><b>Context-aware Bayesian choice models</b>
<a href="https://arxiv.org/abs/2210.05737">arxiv:2210.05737</a>
&#x1F4C8; 2 <br>
<p>Miros≈Çawa ≈Åukawska, Anders Fjendbo Jensen, Filipe Rodrigues</p></summary>
<p>

**Abstract:** The mixed multinomial logit (MMNL) model assumes constant preference parameters of a decision-maker throughout different choice situations, which may be considered too strong for certain choice modelling applications. This paper proposes an effective approach to model context-dependent intra-respondent heterogeneity and introduces the idea of Context-aware Bayesian Mixed Multinomial Logit (C-MMNL) Model, where a neural network maps contextual information to shifts in the preference parameters of each individual in each choice occasion. The proposed model offers several key advantages. First, it supports for both continuous and discrete variables, as well as complex non-linear interactions between both types of variables. Secondly, each specification of the context is considered jointly as a whole by the neural network rather than each variable being considered independently. Finally, since the parameters of the neural network are shared across all decision-makers, it can leverage information from other decision-makers and use it to infer the effect of a particular context. Even though the C-MMNL model allows for flexible interactions between attributes, there is hardly an increase in the complexity of the model and the computation time, compared to the MMNL model. We present two real-world case studies from travel behaviour domain - a travel mode choice model and a bicycle route choice model. The bicycle route choice model is based on a large-scale, crowdsourced dataset of GPS trajectories including 110,083 trips made by 8,555 cyclists.

</p>
</details>

<details><summary><b>Embeddings as Epistemic States: Limitations on the Use of Pooling Operators for Accumulating Knowledge</b>
<a href="https://arxiv.org/abs/2210.05723">arxiv:2210.05723</a>
&#x1F4C8; 2 <br>
<p>Steven Schockaert</p></summary>
<p>

**Abstract:** Various neural network architectures rely on pooling operators to aggregate information coming from different sources. It is often implicitly assumed in such contexts that vectors encode epistemic states, i.e. that vectors capture the evidence that has been obtained about some properties of interest, and that pooling these vectors yields a vector that combines this evidence. We study, for a number of standard pooling operators, under what conditions they are compatible with this idea, which we call the epistemic pooling principle. While we find that all the considered pooling operators can satisfy the epistemic pooling principle, this only holds when embeddings are sufficiently high-dimensional and, for most pooling operators, when the embeddings satisfy particular constraints (e.g. having non-negative coordinates). We then study the implications of these constraints, starting from the idea that we should be able to verify whether an arbitrary propositional formula is satisfied in the epistemic state encoded by a given vector. We find that when the epistemic pooling principle is satisfied, in most cases it is impossible to verify the satisfaction of propositional formulas using linear scoring functions, with two exceptions: (i) max-pooling with embeddings that are upper-bounded and (ii) Hadamard pooling with non-negative embeddings. Finally, we also study an extension of the epistemic pooling principle to weighted epistemic states, where max-pooling emerges as the most suitable operator.

</p>
</details>

<details><summary><b>Relational Embeddings for Language Independent Stance Detection</b>
<a href="https://arxiv.org/abs/2210.05715">arxiv:2210.05715</a>
&#x1F4C8; 2 <br>
<p>Joseba Fernandez de Landa, Rodrigo Agerri</p></summary>
<p>

**Abstract:** The large majority of the research performed on stance detection has been focused on developing more or less sophisticated text classification systems, even when many benchmarks are based on social network data such as Twitter. This paper aims to take on the stance detection task by placing the emphasis not so much on the text itself but on the interaction data available on social networks. More specifically, we propose a new method to leverage social information such as friends and retweets by generating relational embeddings, namely, dense vector representations of interaction pairs. Our method can be applied to any language and target without any manual tuning. Our experiments on seven publicly available datasets and four different languages show that combining our relational embeddings with textual methods helps to substantially improve performance, obtaining best results for six out of seven evaluation settings, outperforming strong baselines based on large pre-trained language models.

</p>
</details>

<details><summary><b>Neural Importance Sampling for Rapid and Reliable Gravitational-Wave Inference</b>
<a href="https://arxiv.org/abs/2210.05686">arxiv:2210.05686</a>
&#x1F4C8; 2 <br>
<p>Maximilian Dax, Stephen R. Green, Jonathan Gair, Michael P√ºrrer, Jonas Wildberger, Jakob H. Macke, Alessandra Buonanno, Bernhard Sch√∂lkopf</p></summary>
<p>

**Abstract:** We combine amortized neural posterior estimation with importance sampling for fast and accurate gravitational-wave inference. We first generate a rapid proposal for the Bayesian posterior using neural networks, and then attach importance weights based on the underlying likelihood and prior. This provides (1) a corrected posterior free from network inaccuracies, (2) a performance diagnostic (the sample efficiency) for assessing the proposal and identifying failure cases, and (3) an unbiased estimate of the Bayesian evidence. By establishing this independent verification and correction mechanism we address some of the most frequent criticisms against deep learning for scientific inference. We carry out a large study analyzing 42 binary black hole mergers observed by LIGO and Virgo with the SEOBNRv4PHM and IMRPhenomXPHM waveform models. This shows a median sample efficiency of $\approx 10\%$ (two orders-of-magnitude better than standard samplers) as well as a ten-fold reduction in the statistical uncertainty in the log evidence. Given these advantages, we expect a significant impact on gravitational-wave inference, and for this approach to serve as a paradigm for harnessing deep learning methods in scientific applications.

</p>
</details>

<details><summary><b>Towards Consistency and Complementarity: A Multiview Graph Information Bottleneck Approach</b>
<a href="https://arxiv.org/abs/2210.05676">arxiv:2210.05676</a>
&#x1F4C8; 2 <br>
<p>Xiaolong Fan, Maoguo Gong, Yue Wu, Mingyang Zhang, Hao Li, Xiangming Jiang</p></summary>
<p>

**Abstract:** The empirical studies of Graph Neural Networks (GNNs) broadly take the original node feature and adjacency relationship as singleview input, ignoring the rich information of multiple graph views. To circumvent this issue, the multiview graph analysis framework has been developed to fuse graph information across views. How to model and integrate shared (i.e. consistency) and view-specific (i.e. complementarity) information is a key issue in multiview graph analysis. In this paper, we propose a novel Multiview Variational Graph Information Bottleneck (MVGIB) principle to maximize the agreement for common representations and the disagreement for view-specific representations. Under this principle, we formulate the common and view-specific information bottleneck objectives across multiviews by using constraints from mutual information. However, these objectives are hard to directly optimize since the mutual information is computationally intractable. To tackle this challenge, we derive variational lower and upper bounds of mutual information terms, and then instead optimize variational bounds to find the approximate solutions for the information objectives. Extensive experiments on graph benchmark datasets demonstrate the superior effectiveness of the proposed method.

</p>
</details>

<details><summary><b>Unsupervised detection of structural damage using Variational Autoencoder and a One-Class Support Vector Machine</b>
<a href="https://arxiv.org/abs/2210.05674">arxiv:2210.05674</a>
&#x1F4C8; 2 <br>
<p>Andrea Pollastro, Giusiana Testa, Antonio Bilotta, Roberto Prevete</p></summary>
<p>

**Abstract:** In recent years, Artificial Neural Networks (ANNs) have been introduced in Structural Health Monitoring (SHM) systems. An unsupervised method with a data-driven approach allows the ANN training on data acquired from an undamaged structural condition to detect structural damages. In standard approaches, after the training stage, a decision rule is manually defined to detect anomalous data. However, this process could be made automatic using machine learning methods, whom performances are maximised using hyperparameter optimization techniques. The paper proposes an unsupervised method with a data-driven approach to detect structural anomalies. The methodology consists of: (i) a Variational Autoencoder (VAE) to approximate undamaged data distribution and (ii) a One-Class Support Vector Machine (OC-SVM) to discriminate different health conditions using damage sensitive features extracted from VAE's signal reconstruction. The method is applied to a scale steel structure that was tested in nine damage's scenarios by IASC-ASCE Structural Health Monitoring Task Group.

</p>
</details>

<details><summary><b>Understanding or Manipulation: Rethinking Online Performance Gains of Modern Recommender Systems</b>
<a href="https://arxiv.org/abs/2210.05662">arxiv:2210.05662</a>
&#x1F4C8; 2 <br>
<p>Zhengbang Zhu, Rongjun Qin, Junjie Huang, Xinyi Dai, Yang Yu, Yong Yu, Weinan Zhang</p></summary>
<p>

**Abstract:** Recommender systems are expected to be assistants that help human users find relevant information in an automatic manner without explicit queries. As recommender systems evolve, increasingly sophisticated learning techniques are applied and have achieved better performance in terms of user engagement metrics such as clicks and browsing time. The increase of the measured performance, however, can have two possible attributions: a better understanding of user preferences, and a more proactive ability to utilize human bounded rationality to seduce user over-consumption. A natural following question is whether current recommendation algorithms are manipulating user preferences. If so, can we measure the manipulation level? In this paper, we present a general framework for benchmarking the degree of manipulations of recommendation algorithms, in both slate recommendation and sequential recommendation scenarios. The framework consists of three stages, initial preference calculation, algorithm training and interaction, and metrics calculation that involves two proposed metrics, Manipulation Score and Preference Shift. We benchmark some representative recommendation algorithms in both synthetic and real-world datasets under the proposed framework. We have observed that a high online click-through rate does not mean a better understanding of user initial preference, but ends in prompting users to choose more documents they initially did not favor. Moreover, we find that the properties of training data have notable impacts on the manipulation degrees, and algorithms with more powerful modeling abilities are more sensitive to such impacts. The experiments also verified the usefulness of the proposed metrics for measuring the degree of manipulations. We advocate that future recommendation algorithm studies should be treated as an optimization problem with constrained user preference manipulations.

</p>
</details>

<details><summary><b>EllipsoNet: Deep-learning-enabled optical ellipsometry for complex thin films</b>
<a href="https://arxiv.org/abs/2210.05630">arxiv:2210.05630</a>
&#x1F4C8; 2 <br>
<p>Ziyang Wang, Yuxuan Cosmi Lin, Kunyan Zhang, Wenjing Wu, Shengxi Huang</p></summary>
<p>

**Abstract:** Optical spectroscopy is indispensable for research and development in nanoscience and nanotechnology, microelectronics, energy, and advanced manufacturing. Advanced optical spectroscopy tools often require both specifically designed high-end instrumentation and intricate data analysis techniques. Beyond the common analytical tools, deep learning methods are well suited for interpreting high-dimensional and complicated spectroscopy data. They offer great opportunities to extract subtle and deep information about optical properties of materials with simpler optical setups, which would otherwise require sophisticated instrumentation. In this work, we propose a computational ellipsometry approach based on a conventional tabletop optical microscope and a deep learning model called EllipsoNet. Without any prior knowledge about the multilayer substrates, EllipsoNet can predict the complex refractive indices of thin films on top of these nontrivial substrates from experimentally measured optical reflectance spectra with high accuracies. This task was not feasible previously with traditional reflectometry or ellipsometry methods. Fundamental physical principles, such as the Kramers-Kronig relations, are spontaneously learned by the model without any further training. This approach enables in-operando optical characterization of functional materials within complex photonic structures or optoelectronic devices.

</p>
</details>

<details><summary><b>Enriching Biomedical Knowledge for Low-resource Language Through Translation</b>
<a href="https://arxiv.org/abs/2210.05598">arxiv:2210.05598</a>
&#x1F4C8; 2 <br>
<p>Long Phan, Tai Dang, Hieu Tran, Vy Phan, Lam D. Chau, Trieu H. Trinh</p></summary>
<p>

**Abstract:** Biomedical data and benchmarks are highly valuable yet very limited in low-resource languages other than English such as Vietnamese. In this paper, we make use of a state-of-the-art translation model in English-Vietnamese to translate and produce both pretrained as well as supervised data in the biomedical domains. Thanks to such large-scale translation, we introduce ViPubmedT5, a pretrained Encoder-Decoder Transformer model trained on 20 million translated abstracts from the high-quality public PubMed corpus. ViPubMedT5 demonstrates state-of-the-art results on two different biomedical benchmarks in summarization and acronym disambiguation. Further, we release ViMedNLI - a new NLP task in Vietnamese translated from MedNLI using the recently public En-vi translation model and carefully refined by human experts, with evaluations of existing methods against ViPubmedT5.

</p>
</details>

<details><summary><b>Model Cascading: Towards Jointly Improving Efficiency and Accuracy of NLP Systems</b>
<a href="https://arxiv.org/abs/2210.05528">arxiv:2210.05528</a>
&#x1F4C8; 2 <br>
<p>Neeraj Varshney, Chitta Baral</p></summary>
<p>

**Abstract:** Do all instances need inference through the big models for a correct prediction? Perhaps not; some instances are easy and can be answered correctly by even small capacity models. This provides opportunities for improving the computational efficiency of systems. In this work, we present an explorative study on 'model cascading', a simple technique that utilizes a collection of models of varying capacities to accurately yet efficiently output predictions. Through comprehensive experiments in multiple task settings that differ in the number of models available for cascading (K value), we show that cascading improves both the computational efficiency and the prediction accuracy. For instance, in K=3 setting, cascading saves up to 88.93% computation cost and consistently achieves superior prediction accuracy with an improvement of up to 2.18%. We also study the impact of introducing additional models in the cascade and show that it further increases the efficiency improvements. Finally, we hope that our work will facilitate development of efficient NLP systems making their widespread adoption in real-world applications possible.

</p>
</details>

<details><summary><b>A hybrid neural-network and finite-difference method for solving Poisson equation with jump discontinuities on interfaces</b>
<a href="https://arxiv.org/abs/2210.05523">arxiv:2210.05523</a>
&#x1F4C8; 2 <br>
<p>Wei-Fan Hu, Te-Sheng Lin, Yu-Hau Tseng, Ming-Chih Lai</p></summary>
<p>

**Abstract:** In this work, a new hybrid neural-network and finite-difference method is developed for solving Poisson equation in a regular domain with jump discontinuities on an embedded irregular interface. Since the solution has low regularity across the interface, when applying finite difference discretization to this problem, an additional treatment accounting for the jump discontinuities must be employed at grid points near the interface. Here, we aim to elevate such an extra effort to ease our implementation. The key idea is to decompose the solution into two parts: singular (non-smooth) and regular (smooth) parts. The neural network learning machinery incorporating given jump conditions finds the singular solution, while the standard finite difference method is used to obtain the regular solution with associated boundary conditions. Regardless of the interface geometry, these two tasks only require a supervised learning task of function approximation and a fast direct solver of the Poisson equation, making the hybrid method easy to implement and efficient. The two- and three-dimensional numerical results show that the present hybrid method preserves second-order accuracy for the solution and its derivatives, and it is comparable with the traditional immersed interface method in the literature.

</p>
</details>

<details><summary><b>Adversarial Contrastive Learning for Evidence-aware Fake News Detection with Graph Neural Networks</b>
<a href="https://arxiv.org/abs/2210.05498">arxiv:2210.05498</a>
&#x1F4C8; 2 <br>
<p>Junfei Wu, Weizhi Xu, Qiang Liu, Shu Wu, Liang Wang</p></summary>
<p>

**Abstract:** The prevalence and perniciousness of fake news have been a critical issue on the Internet, which stimulates the development of automatic fake news detection in turn. In this paper, we focus on evidence-based fake news detection, where several evidences are utilized to probe the veracity of news (i.e., a claim). Most previous methods first employ sequential models to embed the semantic information and then capture the claim-evidence interaction based on attention mechanisms. Despite their effectiveness, they still suffer from three weaknesses. Firstly, sequential models fail to integrate the relevant information that is scattered far apart in evidences. Secondly, they underestimate much redundant information in evidences may be useless or harmful. Thirdly, insufficient data utilization limits the separability and reliability of representations captured by the model. To solve these problems, we propose a unified Graph-based sEmantic structure mining framework with ConTRAstive Learning, namely GETRAL in short. Specifically, we first model claims and evidences as graph-structured data to capture the long-distance semantic dependency. Consequently, we reduce information redundancy by performing graph structure learning. Then the fine-grained semantic representations are fed into the claim-evidence interaction module for predictions. Finally, an adversarial contrastive learning module is applied to make full use of data and strengthen representation learning. Comprehensive experiments have demonstrated the superiority of GETRAL over the state-of-the-arts and validated the efficacy of semantic mining with graph structure and contrastive learning.

</p>
</details>

<details><summary><b>Pooling Strategies for Simplicial Convolutional Networks</b>
<a href="https://arxiv.org/abs/2210.05490">arxiv:2210.05490</a>
&#x1F4C8; 2 <br>
<p>Domenico Mattia Cinque, Claudio Battiloro, Paolo Di Lorenzo</p></summary>
<p>

**Abstract:** The goal of this paper is to introduce pooling strategies for simplicial convolutional neural networks. Inspired by graph pooling methods, we introduce a general formulation for a simplicial pooling layer that performs: i) local aggregation of simplicial signals; ii) principled selection of sampling sets; iii) downsampling and simplicial topology adaptation. The general layer is then customized to design four different pooling strategies (i.e., max, top-k, self-attention, and separated top-k) grounded in the theory of topological signal processing. Also, we leverage the proposed layers in a hierarchical architecture that reduce complexity while representing data at different resolutions. Numerical results on real data benchmarks (i.e., flow and graph classification) illustrate the advantage of the proposed methods with respect to the state of the art.

</p>
</details>

<details><summary><b>Instance Regularization for Discriminative Language Model Pre-training</b>
<a href="https://arxiv.org/abs/2210.05471">arxiv:2210.05471</a>
&#x1F4C8; 2 <br>
<p>Zhuosheng Zhang, Hai Zhao, Ming Zhou</p></summary>
<p>

**Abstract:** Discriminative pre-trained language models (PrLMs) can be generalized as denoising auto-encoders that work with two procedures, ennoising and denoising. First, an ennoising process corrupts texts with arbitrary noising functions to construct training instances. Then, a denoising language model is trained to restore the corrupted tokens. Existing studies have made progress by optimizing independent strategies of either ennoising or denosing. They treat training instances equally throughout the training process, with little attention on the individual contribution of those instances. To model explicit signals of instance contribution, this work proposes to estimate the complexity of restoring the original sentences from corrupted ones in language model pre-training. The estimations involve the corruption degree in the ennoising data construction process and the prediction confidence in the denoising counterpart. Experimental results on natural language understanding and reading comprehension benchmarks show that our approach improves pre-training efficiency, effectiveness, and robustness. Code is publicly available at https://github.com/cooelf/InstanceReg

</p>
</details>

<details><summary><b>A General Learning Framework for Open Ad Hoc Teamwork Using Graph-based Policy Learning</b>
<a href="https://arxiv.org/abs/2210.05448">arxiv:2210.05448</a>
&#x1F4C8; 2 <br>
<p>Arrasy Rahman, Ignacio Carlucho, Niklas H√∂pner, Stefano V. Albrecht</p></summary>
<p>

**Abstract:** Open ad hoc teamwork is the problem of training a single agent to efficiently collaborate with an unknown group of teammates whose composition may change over time. A variable team composition creates challenges for the agent, such as the requirement to adapt to new team dynamics and dealing with changing state vector sizes. These challenges are aggravated in real-world applications where the controlled agent has no access to the full state of the environment. In this work, we develop a class of solutions for open ad hoc teamwork under full and partial observability. We start by developing a solution for the fully observable case that leverages graph neural network architectures to obtain an optimal policy based on reinforcement learning. We then extend this solution to partially observable scenarios by proposing different methodologies that maintain belief estimates over the latent environment states and team composition. These belief estimates are combined with our solution for the fully observable case to compute an agent's optimal policy under partial observability in open ad hoc teamwork. Empirical results demonstrate that our approach can learn efficient policies in open ad hoc teamwork in full and partially observable cases. Further analysis demonstrates that our methods' success is a result of effectively learning the effects of teammates' actions while also inferring the inherent state of the environment under partial observability

</p>
</details>

<details><summary><b>QuCNN : A Quantum Convolutional Neural Network with Entanglement Based Backpropagation</b>
<a href="https://arxiv.org/abs/2210.05443">arxiv:2210.05443</a>
&#x1F4C8; 2 <br>
<p>Samuel A. Stein, Ying Mao, James Ang, Ang Li</p></summary>
<p>

**Abstract:** Quantum Machine Learning continues to be a highly active area of interest within Quantum Computing. Many of these approaches have adapted classical approaches to the quantum settings, such as QuantumFlow, etc. We push forward this trend and demonstrate an adaption of the Classical Convolutional Neural Networks to quantum systems - namely QuCNN. QuCNN is a parameterised multi-quantum-state based neural network layer computing similarities between each quantum filter state and each quantum data state. With QuCNN, back propagation can be achieved through a single-ancilla qubit quantum routine. QuCNN is validated by applying a convolutional layer with a data state and a filter state over a small subset of MNIST images, comparing the back propagated gradients, and training a filter state against an ideal target state.

</p>
</details>

<details><summary><b>Stable and Efficient Adversarial Training through Local Linearization</b>
<a href="https://arxiv.org/abs/2210.05373">arxiv:2210.05373</a>
&#x1F4C8; 2 <br>
<p>Zhuorong Li, Daiwei Yu</p></summary>
<p>

**Abstract:** There has been a recent surge in single-step adversarial training as it shows robustness and efficiency. However, a phenomenon referred to as ``catastrophic overfitting" has been observed, which is prevalent in single-step defenses and may frustrate attempts to use FGSM adversarial training. To address this issue, we propose a novel method, Stable and Efficient Adversarial Training (SEAT), which mitigates catastrophic overfitting by harnessing on local properties that distinguish a robust model from that of a catastrophic overfitted model. The proposed SEAT has strong theoretical justifications, in that minimizing the SEAT loss can be shown to favour smooth empirical risk, thereby leading to robustness. Experimental results demonstrate that the proposed method successfully mitigates catastrophic overfitting, yielding superior performance amongst efficient defenses. Our single-step method can reach 51% robust accuracy for CIFAR-10 with $l_\infty$ perturbations of radius $8/255$ under a strong PGD-50 attack, matching the performance of a 10-step iterative adversarial training at merely 3% computational cost.

</p>
</details>

<details><summary><b>Race Bias Analysis of Bona Fide Errors in face anti-spoofing</b>
<a href="https://arxiv.org/abs/2210.05366">arxiv:2210.05366</a>
&#x1F4C8; 2 <br>
<p>Latifah Abduh, Ioannis Ivrissimtzis</p></summary>
<p>

**Abstract:** The study of bias in Machine Learning is receiving a lot of attention in recent years, however, few only papers deal explicitly with the problem of race bias in face anti-spoofing. In this paper, we present a systematic study of race bias in face anti-spoofing with three key characteristics: the focus is on analysing potential bias in the bona fide errors, where significant ethical and legal issues lie; the analysis is not restricted to the final binary outcomes of the classifier, but also covers the classifier's scalar responses and its latent space; the threshold determining the operating point of the classifier is considered a variable. We demonstrate the proposed bias analysis process on a VQ-VAE based face anti-spoofing algorithm, trained on the Replay Attack and the Spoof in the Wild (SiW) databases, and analysed for bias on the SiW and Racial Faces in the Wild (RFW), databases. The results demonstrate that race bias is not necessarily the result of different mean response values among the various populations. Instead, it can be better understood as the combined effect of several possible characteristics of the response distributions: different means; different variances; bimodal behaviour; existence of outliers.

</p>
</details>

<details><summary><b>Neighbourhood Representative Sampling for Efficient End-to-end Video Quality Assessment</b>
<a href="https://arxiv.org/abs/2210.05357">arxiv:2210.05357</a>
&#x1F4C8; 2 <br>
<p>Haoning Wu, Chaofeng Chen, Liang Liao, Jingwen Hou, Wenxiu Sun, Qiong Yan, Jinwei Gu, Weisi Lin</p></summary>
<p>

**Abstract:** The increased resolution of real-world videos presents a dilemma between efficiency and accuracy for deep Video Quality Assessment (VQA). On the one hand, keeping the original resolution will lead to unacceptable computational costs. On the other hand, existing practices, such as resizing and cropping, will change the quality of original videos due to the loss of details and contents, and are therefore harmful to quality assessment. With the obtained insight from the study of spatial-temporal redundancy in the human visual system and visual coding theory, we observe that quality information around a neighbourhood is typically similar, motivating us to investigate an effective quality-sensitive neighbourhood representatives scheme for VQA. In this work, we propose a unified scheme, spatial-temporal grid mini-cube sampling (St-GMS) to get a novel type of sample, named fragments. Full-resolution videos are first divided into mini-cubes with preset spatial-temporal grids, then the temporal-aligned quality representatives are sampled to compose the fragments that serve as inputs for VQA. In addition, we design the Fragment Attention Network (FANet), a network architecture tailored specifically for fragments. With fragments and FANet, the proposed efficient end-to-end FAST-VQA and FasterVQA achieve significantly better performance than existing approaches on all VQA benchmarks while requiring only 1/1612 FLOPs compared to the current state-of-the-art. Codes, models and demos are available at https://github.com/timothyhtimothy/FAST-VQA-and-FasterVQA.

</p>
</details>

<details><summary><b>Printing variability of copy detection patterns</b>
<a href="https://arxiv.org/abs/2210.05343">arxiv:2210.05343</a>
&#x1F4C8; 2 <br>
<p>Roman Chaban, Olga Taran, Joakim Tutt, Yury Belousov, Brian Pulfer, Taras Holotyak, Slava Voloshynovskiy</p></summary>
<p>

**Abstract:** Copy detection pattern (CDP) is a novel solution for products' protection against counterfeiting, which gains its popularity in recent years. CDP attracts the anti-counterfeiting industry due to its numerous benefits in comparison to alternative protection techniques. Besides its attractiveness, there is an essential gap in the fundamental analysis of CDP authentication performance in large-scale industrial applications. It concerns variability of CDP parameters under different production conditions that include a type of printer, substrate, printing resolution, etc. Since digital off-set printing represents great flexibility in terms of product personalized in comparison with traditional off-set printing, it looks very interesting to address the above concerns for digital off-set printers that are used by several companies for the CDP protection of physical objects. In this paper, we thoroughly investigate certain factors impacting CDP. The experimental results obtained during our study reveal some previously unknown results and raise new and even more challenging questions. The results prove that it is a matter of great importance to choose carefully the substrate or printer for CDP production. This paper presents a new dataset produced by two industrial HP Indigo printers. The similarity between printed CDP and the digital templates, from which they have been produced, is chosen as a simple measure in our study. We found several particularities that might be of interest for large-scale industrial applications.

</p>
</details>

<details><summary><b>FusionDeepMF: A Dual Embedding based Deep Fusion Model for Recommendation</b>
<a href="https://arxiv.org/abs/2210.05338">arxiv:2210.05338</a>
&#x1F4C8; 2 <br>
<p>Supriyo Mandal, Abyayananda Maiti</p></summary>
<p>

**Abstract:** Traditional Collaborative Filtering (CF) based methods are applied to understand the personal preferences of users/customers for items or products from the rating matrix. Usually, the rating matrix is sparse in nature. So there are some improved variants of the CF method that apply the increasing amount of side information to handle the sparsity problem. Only linear kernel or only non-linear kernel is applied in most of the available recommendation-related work to understand user-item latent feature embeddings from data. Only linear kernel or only non-linear kernel is not sufficient to learn complex user-item features from side information of users. Recently, some researchers have focused on hybrid models that learn some features with non-linear kernels and some other features with linear kernels. But it is very difficult to understand which features can be learned accurately with linear kernels or with non-linear kernels. To overcome this problem, we propose a novel deep fusion model named FusionDeepMF and the novel attempts of this model are i) learning user-item rating matrix and side information through linear and non-linear kernel simultaneously, ii) application of a tuning parameter determining the trade-off between the dual embeddings that are generated from linear and non-linear kernels. Extensive experiments on online review datasets establish that FusionDeepMF can be remarkably futuristic compared to other baseline approaches. Empirical evidence also shows that FusionDeepMF achieves better performances compared to the linear kernels of Matrix Factorization (MF) and the non-linear kernels of Multi-layer Perceptron (MLP).

</p>
</details>

<details><summary><b>Learning Control Policies for Stochastic Systems with Reach-avoid Guarantees</b>
<a href="https://arxiv.org/abs/2210.05308">arxiv:2210.05308</a>
&#x1F4C8; 2 <br>
<p>ƒêorƒëe ≈Ωikeliƒá, Mathias Lechner, Thomas A. Henzinger, Krishnendu Chatterjee</p></summary>
<p>

**Abstract:** We study the problem of learning controllers for discrete-time non-linear stochastic dynamical systems with formal reach-avoid guarantees. This work presents the first method for providing formal reach-avoid guarantees, which combine and generalize stability and safety guarantees, with a tolerable probability threshold $p\in[0,1]$ over the infinite time horizon. Our method leverages advances in machine learning literature and it represents formal certificates as neural networks. In particular, we learn a certificate in the form of a reach-avoid supermartingale (RASM), a novel notion that we introduce in this work. Our RASMs provide reachability and avoidance guarantees by imposing constraints on what can be viewed as a stochastic extension of level sets of Lyapunov functions for deterministic systems. Our approach solves several important problems -- it can be used to learn a control policy from scratch, to verify a reach-avoid specification for a fixed control policy, or to fine-tune a pre-trained policy if it does not satisfy the reach-avoid specification. We validate our approach on $3$ stochastic non-linear reinforcement learning tasks.

</p>
</details>

<details><summary><b>Learning Control Policies for Region Stabilization in Stochastic Systems</b>
<a href="https://arxiv.org/abs/2210.05304">arxiv:2210.05304</a>
&#x1F4C8; 2 <br>
<p>Matin Ansaripour, Mathias Lechner, ƒêorƒëe ≈Ωikeliƒá, Krishnendu Chatterjee, Thomas A. Henzinger</p></summary>
<p>

**Abstract:** We consider the problem of learning control policies in stochastic systems which guarantee that the system stabilizes within some specified stabilization region with probability $1$. Our approach is based on the novel notion of stabilizing ranking supermartingales (sRSMs) that we introduce in this work. Our sRSMs overcome the limitation of methods proposed in previous works whose applicability is restricted to systems in which the stabilizing region cannot be left once entered under any control policy. We present a learning procedure that learns a control policy together with an sRSM that formally certifies probability-$1$ stability, both learned as neural networks. Our experimental evaluation shows that our learning procedure can successfully learn provably stabilizing policies in practice.

</p>
</details>

<details><summary><b>Intrinsic Dimension for Large-Scale Geometric Learning</b>
<a href="https://arxiv.org/abs/2210.05301">arxiv:2210.05301</a>
&#x1F4C8; 2 <br>
<p>Maximilian Stubbemann, Tom Hanika, Friedrich Martin Schneider</p></summary>
<p>

**Abstract:** The concept of dimension is essential to grasp the complexity of data. A naive approach to determine the dimension of a dataset is based on the number of attributes. More sophisticated methods derive a notion of intrinsic dimension (ID) that employs more complex feature functions, e.g., distances between data points. Yet, many of these approaches are based on empirical observations, cannot cope with the geometric character of contemporary datasets, and do lack an axiomatic foundation. A different approach was proposed by V. Pestov, who links the intrinsic dimension axiomatically to the mathematical concentration of measure phenomenon. First methods to compute this and related notions for ID were computationally intractable for large-scale real-world datasets. In the present work, we derive a computationally feasible method for determining said axiomatic ID functions. Moreover, we demonstrate how the geometric properties of complex data are accounted for in our modeling. In particular, we propose a principle way to incorporate neighborhood information, as in graph data, into the ID. This allows for new insights into common graph learning procedures, which we illustrate by experiments on the Open Graph Benchmark.

</p>
</details>

<details><summary><b>Computer Vision based inspection on post-earthquake with UAV synthetic dataset</b>
<a href="https://arxiv.org/abs/2210.05282">arxiv:2210.05282</a>
&#x1F4C8; 2 <br>
<p>Mateusz ≈ªarski, Bartosz W√≥jcik, Jaros≈Çaw A. Miszczak, Bart≈Çomiej Blachowski, Mariusz Ostrowski</p></summary>
<p>

**Abstract:** The area affected by the earthquake is vast and often difficult to entirely cover, and the earthquake itself is a sudden event that causes multiple defects simultaneously, that cannot be effectively traced using traditional, manual methods. This article presents an innovative approach to the problem of detecting damage after sudden events by using an interconnected set of deep machine learning models organized in a single pipeline and allowing for easy modification and swapping models seamlessly. Models in the pipeline were trained with a synthetic dataset and were adapted to be further evaluated and used with unmanned aerial vehicles (UAVs) in real-world conditions. Thanks to the methods presented in the article, it is possible to obtain high accuracy in detecting buildings defects, segmenting constructions into their components and estimating their technical condition based on a single drone flight.

</p>
</details>

<details><summary><b>Once is Enough: A Light-Weight Cross-Attention for Fast Sentence Pair Modeling</b>
<a href="https://arxiv.org/abs/2210.05261">arxiv:2210.05261</a>
&#x1F4C8; 2 <br>
<p>Yuanhang Yang, shiyi qi, Cuiyun Gao, Zenglin Xu, Yulan He, Qifan Wang, Chuanyi Liu</p></summary>
<p>

**Abstract:** Transformer-based models have achieved great success on sentence pair modeling tasks, such as answer selection and natural language inference (NLI). These models generally perform cross-attention over input pairs, leading to prohibitive computational costs. Recent studies propose dual-encoder and late interaction architectures for faster computation. However, the balance between the expressive of cross-attention and computation speedup still needs better coordinated. To this end, this paper introduces a novel paradigm MixEncoder for efficient sentence pair modeling. MixEncoder involves a light-weight cross-attention mechanism. It conducts query encoding only once while modeling the query-candidate interaction in parallel. Extensive experiments conducted on four tasks demonstrate that our MixEncoder can speed up sentence pairing by over 113x while achieving comparable performance as the more expensive cross-attention models.

</p>
</details>

<details><summary><b>Constrained Deployment Optimization in Integrated Access and Backhaul Networks</b>
<a href="https://arxiv.org/abs/2210.05253">arxiv:2210.05253</a>
&#x1F4C8; 2 <br>
<p>Charitha Madapatha, Behrooz Makki, Hao Guo, Tommy Svensson</p></summary>
<p>

**Abstract:** Integrated access and backhaul (IAB) is one of the promising techniques for 5G networks and beyond (6G), in which the same node/hardware is used to provide both backhaul and cellular services in a multi-hop fashion. Due to the sensitivity of the backhaul links with high rate/reliability demands, proper network planning is needed to make the IAB network performing appropriately and as good as possible. In this paper, we study the effect of deployment optimization on the coverage of IAB networks. We concentrate on the cases where, due to either geographical or interference management limitations, unconstrained IAB node placement is not feasible in some areas. To that end, we propose various millimeter wave (mmWave) blocking-aware constrained deployment optimization approaches. Our results indicate that, even with limitations on deployment optimization, network planning boosts the coverage of IAB networks considerably.

</p>
</details>

<details><summary><b>Leveraging the Video-level Semantic Consistency of Event for Audio-visual Event Localization</b>
<a href="https://arxiv.org/abs/2210.05242">arxiv:2210.05242</a>
&#x1F4C8; 2 <br>
<p>Yuanyuan Jiang, Jianqin Yin, Yonghao Dang</p></summary>
<p>

**Abstract:** Audio-visual event localization has attracted much attention in recent years. Most existing methods are often limited to independently encoding and classifying each video segment separated from the full video (which can be regarded as the segment-level representations of events). However, they ignore the semantic consistency of the event within the same full video (which can be considered as the video-level representations of events). In contrast to existing methods, we propose a novel video-level semantic consistency guidance network for the AVE task. Specifically, we propose an event semantic consistency modeling (ESCM) module to explore the video-level semantic consistency of events. It consists of two components: cross-modal event representation extractor (CERE) and intra-modal semantic consistency enhancer (ISCE). CERE is proposed to obtain the event semantic representation at the video level including, audio and visual modules. Furthermore, ISCE takes the video-level event semantic representation as the prior knowledge to guide the model to focus on the semantic continuity of the event within each modality. Moreover, we propose a new negative pair filter loss to encourage the network to filter out the irrelevant segment pairs and a new smooth loss to further increase the gap between different categories of events under the weakly-supervised setting. We perform extensive experiments on the public AVE dataset and outperform the state-of-the-art methods in both fully and weakly supervised settings, thus verifying the effectiveness of our method.

</p>
</details>

<details><summary><b>STSC-SNN: Spatio-Temporal Synaptic Connection with Temporal Convolution and Attention for Spiking Neural Networks</b>
<a href="https://arxiv.org/abs/2210.05241">arxiv:2210.05241</a>
&#x1F4C8; 2 <br>
<p>Chengting Yu, Zheming Gu, Da Li, Gaoang Wang, Aili Wang, Erping Li</p></summary>
<p>

**Abstract:** Spiking Neural Networks (SNNs), as one of the algorithmic models in neuromorphic computing, have gained a great deal of research attention owing to temporal information processing capability, low power consumption, and high biological plausibility. The potential to efficiently extract spatio-temporal features makes it suitable for processing the event streams. However, existing synaptic structures in SNNs are almost full-connections or spatial 2D convolution, neither of which can extract temporal dependencies adequately. In this work, we take inspiration from biological synapses and propose a spatio-temporal synaptic connection SNN (STSC-SNN) model, to enhance the spatio-temporal receptive fields of synaptic connections, thereby establishing temporal dependencies across layers. Concretely, we incorporate temporal convolution and attention mechanisms to implement synaptic filtering and gating functions. We show that endowing synaptic models with temporal dependencies can improve the performance of SNNs on classification tasks. In addition, we investigate the impact of performance vias varied spatial-temporal receptive fields and reevaluate the temporal modules in SNNs. Our approach is tested on neuromorphic datasets, including DVS128 Gesture (gesture recognition), N-MNIST, CIFAR10-DVS (image classification), and SHD (speech digit recognition). The results show that the proposed model outperforms the state-of-the-art accuracy on nearly all datasets.

</p>
</details>

<details><summary><b>CHAE: Fine-Grained Controllable Story Generation with Characters, Actions and Emotions</b>
<a href="https://arxiv.org/abs/2210.05221">arxiv:2210.05221</a>
&#x1F4C8; 2 <br>
<p>Xinpeng Wang, Han Jiang, Zhihua Wei, Shanlin Zhou</p></summary>
<p>

**Abstract:** Story generation has emerged as an interesting yet challenging NLP task in recent years. Some existing studies aim at generating fluent and coherent stories from keywords and outlines; while others attempt to control the global features of the story, such as emotion, style and topic. However, these works focus on coarse-grained control on the story, neglecting control on the details of the story, which is also crucial for the task. To fill the gap, this paper proposes a model for fine-grained control on the story, which allows the generation of customized stories with characters, corresponding actions and emotions arbitrarily assigned. Extensive experimental results on both automatic and human manual evaluations show the superiority of our method. It has strong controllability to generate stories according to the fine-grained personalized guidance, unveiling the effectiveness of our methodology. Our code is available at https://github.com/victorup/CHAE.

</p>
</details>

<details><summary><b>On Scrambling Phenomena for Randomly Initialized Recurrent Networks</b>
<a href="https://arxiv.org/abs/2210.05212">arxiv:2210.05212</a>
&#x1F4C8; 2 <br>
<p>Vaggos Chatziafratis, Ioannis Panageas, Clayton Sanford, Stelios Andrew Stavroulakis</p></summary>
<p>

**Abstract:** Recurrent Neural Networks (RNNs) frequently exhibit complicated dynamics, and their sensitivity to the initialization process often renders them notoriously hard to train. Recent works have shed light on such phenomena analyzing when exploding or vanishing gradients may occur, either of which is detrimental for training dynamics. In this paper, we point to a formal connection between RNNs and chaotic dynamical systems and prove a qualitatively stronger phenomenon about RNNs than what exploding gradients seem to suggest. Our main result proves that under standard initialization (e.g., He, Xavier etc.), RNNs will exhibit \textit{Li-Yorke chaos} with \textit{constant} probability \textit{independent} of the network's width. This explains the experimentally observed phenomenon of \textit{scrambling}, under which trajectories of nearby points may appear to be arbitrarily close during some timesteps, yet will be far away in future timesteps. In stark contrast to their feedforward counterparts, we show that chaotic behavior in RNNs is preserved under small perturbations and that their expressive power remains exponential in the number of feedback iterations. Our technical arguments rely on viewing RNNs as random walks under non-linear activations, and studying the existence of certain types of higher-order fixed points called \textit{periodic points} that lead to phase transitions from order to chaos.

</p>
</details>

<details><summary><b>Efficient Deep Unfolding for SISO-OFDM Channel Estimation</b>
<a href="https://arxiv.org/abs/2210.06588">arxiv:2210.06588</a>
&#x1F4C8; 1 <br>
<p>Baptiste Chatelier, Luc Le Magoarou, Getachew Redieteab</p></summary>
<p>

**Abstract:** In modern communication systems, channel state information is of paramount importance to achieve capacity. It is then crucial to accurately estimate the channel. It is possible to perform SISO-OFDM channel estimation using sparse recovery techniques. However, this approach relies on the use of a physical wave propagation model to build a dictionary, which requires perfect knowledge of the system's parameters. In this paper, an unfolded neural network is used to lighten this constraint. Its architecture, based on a sparse recovery algorithm, allows SISO-OFDM channel estimation even if the system's parameters are not perfectly known. Indeed, its unsupervised online learning allows to learn the system's imperfections in order to enhance the estimation performance. The practicality of the proposed method is improved with respect to the state of the art in two aspects: constrained dictionaries are introduced in order to reduce sample complexity and hierarchical search within dictionaries is proposed in order to reduce time complexity. Finally, the performance of the proposed unfolded network is evaluated and compared to several baselines using realistic channel data, showing the great potential of the approach.

</p>
</details>

<details><summary><b>VR-SFT: Reproducing Swinging Flashlight Test in Virtual Reality to Detect Relative Afferent Pupillary Defect</b>
<a href="https://arxiv.org/abs/2210.06474">arxiv:2210.06474</a>
&#x1F4C8; 1 <br>
<p>Prithul Sarker, Nasif Zaman, Alireza Tavakkoli</p></summary>
<p>

**Abstract:** The relative afferent asymmetry between two eyes can be diagnosed using swinging flashlight test, also known as the alternating light test. This remains one of the most used clinical tests to this day. Despite the swinging flashlight test's straightforward approach, a number of factors can add variability into the clinical methodology and reduce the measurement's validity and reliability. This includes small and poorly responsive pupils, dark iris, anisocoria, uneven illumination in both eyes. Due to these limitations, the true condition of relative afferent asymmetry may create confusion and various observers may quantify the relative afferent pupillary defect differently. Consequently, the results of the swinging flashlight test are subjective and ambiguous. In order to eliminate the limitations of traditional swinging flashlight test and introduce objectivity, we propose a novel approach to the swinging flashlight exam, VR-SFT, by making use of virtual reality (VR). We suggest that the clinical records of the subjects and the results of VR-SFT are comparable. In this paper, we describe how we exploit the features of immersive VR experience to create a reliable and objective swinging flashlight test.

</p>
</details>

<details><summary><b>Inner speech recognition through electroencephalographic signals</b>
<a href="https://arxiv.org/abs/2210.06472">arxiv:2210.06472</a>
&#x1F4C8; 1 <br>
<p>Francesca Gasparini, Elisa Cazzaniga, Aurora Saibene</p></summary>
<p>

**Abstract:** This work focuses on inner speech recognition starting from EEG signals. Inner speech recognition is defined as the internalized process in which the person thinks in pure meanings, generally associated with an auditory imagery of own inner "voice". The decoding of the EEG into text should be understood as the classification of a limited number of words (commands) or the presence of phonemes (units of sound that make up words). Speech-related BCIs provide effective vocal communication strategies for controlling devices through speech commands interpreted from brain signals, improving the quality of life of people who have lost the capability to speak, by restoring communication with their environment. Two public inner speech datasets are analysed. Using this data, some classification models are studied and implemented starting from basic methods such as Support Vector Machines, to ensemble methods such as the eXtreme Gradient Boosting classifier up to the use of neural networks such as Long Short Term Memory (LSTM) and Bidirectional Long Short Term Memory (BiLSTM). With the LSTM and BiLSTM models, generally not used in the literature of inner speech recognition, results in line with or superior to those present in the stateof-the-art are obtained.

</p>
</details>

<details><summary><b>Building Heterogeneous Cloud System for Machine Learning Inference</b>
<a href="https://arxiv.org/abs/2210.05889">arxiv:2210.05889</a>
&#x1F4C8; 1 <br>
<p>Baolin Li, Siddharth Samsi, Vijay Gadepally, Devesh Tiwari</p></summary>
<p>

**Abstract:** Online inference is becoming a key service product for many businesses, deployed in cloud platforms to meet customer demands. Despite their revenue-generation capability, these services need to operate under tight Quality-of-Service (QoS) and cost budget constraints. This paper introduces KAIROS, a novel runtime framework that maximizes the query throughput while meeting QoS target and a cost budget. KAIROS designs and implements novel techniques to build a pool of heterogeneous compute hardware without online exploration overhead, and distribute inference queries optimally at runtime. Our evaluation using industry-grade deep learning (DL) models shows that KAIROS yields up to 2X the throughput of an optimal homogeneous solution, and outperforms state-of-the-art schemes by up to 70\%, despite advantageous implementations of the competing schemes to ignore their exploration overhead.

</p>
</details>

<details><summary><b>Pathology Steered Stratification Network for Subtype Identification in Alzheimer's Disease</b>
<a href="https://arxiv.org/abs/2210.05880">arxiv:2210.05880</a>
&#x1F4C8; 1 <br>
<p>Enze Xu, Jingwen Zhang, Jiadi Li, Defu Yang, Guorong Wu, Minghan Chen</p></summary>
<p>

**Abstract:** Alzheimer's disease (AD) is a heterogeneous, multifactorial neurodegenerative disorder characterized by beta-amyloid, pathologic tau, and neurodegeneration. The massive heterogeneity between neurobiological examinations and clinical assessment is the current biggest challenge in the early diagnosis of Alzheimer's disease, urging for a comprehensive stratification of the aging population that is defined by reliable neurobiological biomarkers and closely associated with clinical outcomes. However, existing statistical inference approaches in neuroimaging studies of AD subtype identification fail to take into account the neuropathological domain knowledge, which could lead to ill-posed results that are sometimes inconsistent with neurological principles. To fill this knowledge gap, we propose a novel pathology steered stratification network (PSSN) that integrates mainstream AD pathology with multimodal longitudinal neuroimaging data to categorize the aging population. By combining theory-based biological modeling and data-driven deep learning, this cross-disciplinary approach can not only generate long-term biomarker prediction consistent with the end-state of individuals but also stratifies subjects into fine-grained subtypes with distinct neurological underpinnings, where ag-ing brains within the same subtype share com-mon biological behaviors that emerge as similar trajectories of cognitive decline. Our stratification outperforms K-means and SuStaIn in both inter-cluster heterogeneity and intra-cluster homogeneity of various clinical scores. Importantly, we identify six subtypes spanning AD spectrum, where each subtype exhibits a distinctive biomarker pattern that is consistent with its clinical outcome. A disease evolutionary graph is further provided by quantifying subtype transition probabilities, which may assist pre-symptomatic diagnosis and guide therapeutic treatments.

</p>
</details>

<details><summary><b>Statistical Modeling of Soft Error Influence on Neural Networks</b>
<a href="https://arxiv.org/abs/2210.05876">arxiv:2210.05876</a>
&#x1F4C8; 1 <br>
<p>Haitong Huang, Xinghua Xue, Cheng Liu, Ying Wang, Tao Luo, Long Cheng, Huawei Li, Xiaowei Li</p></summary>
<p>

**Abstract:** Soft errors in large VLSI circuits pose dramatic influence on computing- and memory-intensive neural network (NN) processing. Understanding the influence of soft errors on NNs is critical to protect against soft errors for reliable NN processing. Prior work mainly rely on fault simulation to analyze the influence of soft errors on NN processing. They are accurate but usually specific to limited configurations of errors and NN models due to the prohibitively slow simulation speed especially for large NN models and datasets. With the observation that the influence of soft errors propagates across a large number of neurons and accumulates as well, we propose to characterize the soft error induced data disturbance on each neuron with normal distribution model according to central limit theorem and develop a series of statistical models to analyze the behavior of NN models under soft errors in general. The statistical models reveal not only the correlation between soft errors and NN model accuracy, but also how NN parameters such as quantization and architecture affect the reliability of NNs. The proposed models are compared with fault simulation and verified comprehensively. In addition, we observe that the statistical models that characterize the soft error influence can also be utilized to predict fault simulation results in many cases and we explore the use of the proposed statistical models to accelerate fault simulations of NNs. According to our experiments, the accelerated fault simulation shows almost two orders of magnitude speedup with negligible simulation accuracy loss over the baseline fault simulations.

</p>
</details>

<details><summary><b>Joint localization and classification of breast tumors on ultrasound images using a novel auxiliary attention-based framework</b>
<a href="https://arxiv.org/abs/2210.05762">arxiv:2210.05762</a>
&#x1F4C8; 1 <br>
<p>Zong Fan, Ping Gong, Shanshan Tang, Christine U. Lee, Xiaohui Zhang, Pengfei Song, Shigao Chen, Hua Li</p></summary>
<p>

**Abstract:** Automatic breast lesion detection and classification is an important task in computer-aided diagnosis, in which breast ultrasound (BUS) imaging is a common and frequently used screening tool. Recently, a number of deep learning-based methods have been proposed for joint localization and classification of breast lesions using BUS images. In these methods, features extracted by a shared network trunk are appended by two independent network branches to achieve classification and localization. Improper information sharing might cause conflicts in feature optimization in the two branches and leads to performance degradation. Also, these methods generally require large amounts of pixel-level annotated data for model training. To overcome these limitations, we proposed a novel joint localization and classification model based on the attention mechanism and disentangled semi-supervised learning strategy. The model used in this study is composed of a classification network and an auxiliary lesion-aware network. By use of the attention mechanism, the auxiliary lesion-aware network can optimize multi-scale intermediate feature maps and extract rich semantic information to improve classification and localization performance. The disentangled semi-supervised learning strategy only requires incomplete training datasets for model training. The proposed modularized framework allows flexible network replacement to be generalized for various applications. Experimental results on two different breast ultrasound image datasets demonstrate the effectiveness of the proposed method. The impacts of various network factors on model performance are also investigated to gain deep insights into the designed framework.

</p>
</details>

<details><summary><b>Application of Deep Learning on Single-Cell RNA-sequencing Data Analysis: A Review</b>
<a href="https://arxiv.org/abs/2210.05677">arxiv:2210.05677</a>
&#x1F4C8; 1 <br>
<p>Matthew Brendel, Chang Su, Zilong Bai, Hao Zhang, Olivier Elemento, Fei Wang</p></summary>
<p>

**Abstract:** Single-cell RNA-sequencing (scRNA-seq) has become a routinely used technique to quantify the gene expression profile of thousands of single cells simultaneously. Analysis of scRNA-seq data plays an important role in the study of cell states and phenotypes, and has helped elucidate biological processes, such as those occurring during development of complex organisms and improved our understanding of disease states, such as cancer, diabetes, and COVID, among others. Deep learning, a recent advance of artificial intelligence that has been used to address many problems involving large datasets, has also emerged as a promising tool for scRNA-seq data analysis, as it has a capacity to extract informative, compact features from noisy, heterogeneous, and high-dimensional scRNA-seq data to improve downstream analysis. The present review aims at surveying recently developed deep learning techniques in scRNA-seq data analysis, identifying key steps within the scRNA-seq data analysis pipeline that have been advanced by deep learning, and explaining the benefits of deep learning over more conventional analysis tools. Finally, we summarize the challenges in current deep learning approaches faced within scRNA-seq data and discuss potential directions for improvements in deep algorithms for scRNA-seq data analysis.

</p>
</details>

<details><summary><b>Zero-Order One-Point Estimate with Distributed Stochastic Gradient-Tracking Technique</b>
<a href="https://arxiv.org/abs/2210.05618">arxiv:2210.05618</a>
&#x1F4C8; 1 <br>
<p>Elissa Mhanna, Mohamad Assaad</p></summary>
<p>

**Abstract:** In this work, we consider a distributed multi-agent stochastic optimization problem, where each agent holds a local objective function that is smooth and convex, and that is subject to a stochastic process. The goal is for all agents to collaborate to find a common solution that optimizes the sum of these local functions. With the practical assumption that agents can only obtain noisy numerical function queries at exactly one point at a time, we extend the distributed stochastic gradient-tracking method to the bandit setting where we don't have an estimate of the gradient, and we introduce a zero-order (ZO) one-point estimate (1P-DSGT). We analyze the convergence of this novel technique for smooth and convex objectives using stochastic approximation tools, and we prove that it converges almost surely to the optimum. We then study the convergence rate for when the objectives are additionally strongly convex. We obtain a rate of $O(\frac{1}{\sqrt{k}})$ after a sufficient number of iterations $k > K_2$ which is usually optimal for techniques utilizing one-point estimators. We also provide a regret bound of $O(\sqrt{k})$, which is exceptionally good compared to the aforementioned techniques. We further illustrate the usefulness of the proposed technique using numerical experiments.

</p>
</details>

<details><summary><b>Low Complexity Convolutional Neural Networks for Equalization in Optical Fiber Transmission</b>
<a href="https://arxiv.org/abs/2210.05454">arxiv:2210.05454</a>
&#x1F4C8; 1 <br>
<p>Mohannad Abu-romoh, Nelson Costa, Antonio Napoli, Jo√£o Pedro, Yves Jaou√´n, Mansoor Yousefi</p></summary>
<p>

**Abstract:** A convolutional neural network is proposed to mitigate fiber transmission effects, achieving a five-fold reduction in trainable parameters compared to alternative equalizers, and 3.5 dB improvement in MSE compared to DBP with comparable complexity.

</p>
</details>

<details><summary><b>Code Librarian: A Software Package Recommendation System</b>
<a href="https://arxiv.org/abs/2210.05406">arxiv:2210.05406</a>
&#x1F4C8; 1 <br>
<p>Lili Tao, Alexandru-Petre Cazan, Senad Ibraimoski, Sean Moran</p></summary>
<p>

**Abstract:** The use of packaged libraries can significantly shorten the software development cycle by improving the quality and readability of code. In this paper, we present a recommendation engine called Librarian for open source libraries. A candidate library package is recommended for a given context if: 1) it has been frequently used with the imported libraries in the program; 2) it has similar functionality to the imported libraries in the program; 3) it has similar functionality to the developer's implementation, and 4) it can be used efficiently in the context of the provided code. We apply the state-of-the-art CodeBERT-based model for analysing the context of the source code to deliver relevant library recommendations to users.

</p>
</details>

<details><summary><b>A new perspective on Digital Twins: Imparting intelligence and agency to entities</b>
<a href="https://arxiv.org/abs/2210.05350">arxiv:2210.05350</a>
&#x1F4C8; 1 <br>
<p>Ashwin Agrawal, Vishal Singh, Martin Fischer</p></summary>
<p>

**Abstract:** Despite the Digital Twin (DT) concept being in the industry for a long time, it remains ambiguous, unable to differentiate itself from information models, general computing, and simulation technologies. Part of this confusion stems from previous studies overlooking the DT's bidirectional nature, that enables the shift of agency (delegating control) from humans to physical elements, something that was not possible with earlier technologies. Thus, we present DTs in a new light by viewing them as a means of imparting intelligence and agency to entities, emphasizing that DTs are not just expert-centric tools but are active systems that extend the capabilities of the entities being twinned. This new perspective on DTs can help reduce confusion and humanize the concept by starting discussions about how intelligent a DT should be, and its roles and responsibilities, as well as setting a long-term direction for DTs.

</p>
</details>

<details><summary><b>Client Error Clustering Approaches in Content Delivery Networks (CDN)</b>
<a href="https://arxiv.org/abs/2210.05314">arxiv:2210.05314</a>
&#x1F4C8; 1 <br>
<p>Ermiyas Birihanu, Jiyan Mahmud, P√©ter Kiss, Adolf Kamuzora, Wadie Skaf, Tom√°≈° Horv√°th, Tam√°s Jursonovics, Peter Pogrzeba, Imre Lend√°k</p></summary>
<p>

**Abstract:** Content delivery networks (CDNs) are the backbone of the Internet and are key in delivering high quality video on demand (VoD), web content and file services to billions of users. CDNs usually consist of hierarchically organized content servers positioned as close to the customers as possible. CDN operators face a significant challenge when analyzing billions of web server and proxy logs generated by their systems. The main objective of this study was to analyze the applicability of various clustering methods in CDN error log analysis. We worked with real-life CDN proxy logs, identified key features included in the logs (e.g., content type, HTTP status code, time-of-day, host) and clustered the log lines corresponding to different host types offering live TV, video on demand, file caching and web content. Our experiments were run on a dataset consisting of proxy logs collected over a 7-day period from a single, physical CDN server running multiple types of services (VoD, live TV, file). The dataset consisted of 2.2 billion log lines. Our analysis showed that CDN error clustering is a viable approach towards identifying recurring errors and improving overall quality of service.

</p>
</details>

<details><summary><b>The Fast and Accurate Approach to Detection and Segmentation of Melanoma Skin Cancer using Fine-tuned Yolov3 and SegNet Based on Deep Transfer Learning</b>
<a href="https://arxiv.org/abs/2210.05167">arxiv:2210.05167</a>
&#x1F4C8; 1 <br>
<p>Mohamad Taghizadeh, Karim Mohammadi</p></summary>
<p>

**Abstract:** Melanoma is one of the most serious skin cancers that can occur in any part of the human skin. Early diagnosing melanoma lesions will significantly increase their chances of being cured. Improving melanoma segmentation will help doctors or surgical robots remove the lesion more accurately from body parts. Recently, the learning-based segmentation methods achieved desired results in image segmentation compared to traditional algorithms. This study proposes a new method to improve melanoma skin lesions detection and segmentation by defining a two-step pipeline based on deep learning models. Our methods were evaluated on ISIC 2018 (Skin Lesion Analysis Towards Melanoma Detection Challenge Dataset) well-known dataset. The proposed methods consist of two main parts for real-time detection of lesion location and segmentation. In the detection section, the location of the skin lesion is precisely detected by the fine-tuned You Only Look Once version 3 (F-YOLOv3) and then fed into the fine-tuned Segmentation Network (F-SegNet). Skin lesion localization helps to reduce the unnecessary calculation of whole images for segmentation. The results show that our proposed F-YOLOv3 achieves better performance as 96% in mAP. Compared to state-of-the-art segmentation approaches, our F-SegNet achieves higher performance for accuracy, dice coefficient, and Jaccard index at 95.16%, 92.81%, and 86.2%, respectively.

</p>
</details>

<details><summary><b>Adversarial Attack Against Image-Based Localization Neural Networks</b>
<a href="https://arxiv.org/abs/2210.06589">arxiv:2210.06589</a>
&#x1F4C8; 0 <br>
<p>Meir Brand, Itay Naeh, Daniel Teitelman</p></summary>
<p>

**Abstract:** In this paper, we present a proof of concept for adversarially attacking the image-based localization module of an autonomous vehicle. This attack aims to cause the vehicle to perform a wrong navigational decisions and prevent it from reaching a desired predefined destination in a simulated urban environment. A database of rendered images allowed us to train a deep neural network that performs a localization task and implement, develop and assess the adversarial pattern. Our tests show that using this adversarial attack we can prevent the vehicle from turning at a given intersection. This is done by manipulating the vehicle's navigational module to falsely estimate its current position and thus fail to initialize the turning procedure until the vehicle misses the last opportunity to perform a safe turn in a given intersection.

</p>
</details>

<details><summary><b>Simulating Structural Plasticity of the Brain more Scalable than Expected</b>
<a href="https://arxiv.org/abs/2210.05267">arxiv:2210.05267</a>
&#x1F4C8; 0 <br>
<p>Fabian Czappa, Alexander Gei√ü, Felix Wolf</p></summary>
<p>

**Abstract:** Structural plasticity of the brain describes the creation of new and the deletion of old synapses over time. Rinke et al. (JPDC 2018) introduced a scalable algorithm that simulates structural plasticity for up to one billion neurons on current hardware using a variant of the Barnes--Hut algorithm. They demonstrate good scalability and prove a runtime complexity of $O(n \log^2 n)$. In this comment paper, we show that with careful consideration of the algorithm, the theoretical runtime can even be classified as $O(n \log n)$.

</p>
</details>


{% endraw %}
Prev: [2022.10.10]({{ '/2022/10/10/2022.10.10.html' | relative_url }})  Next: [2022.10.12]({{ '/2022/10/12/2022.10.12.html' | relative_url }})