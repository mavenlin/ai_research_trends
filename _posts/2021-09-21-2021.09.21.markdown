## Summary for 2021-09-21, created on 2021-12-18


<details><summary><b>Introduction to Neural Network Verification</b>
<a href="https://arxiv.org/abs/2109.10317">arxiv:2109.10317</a>
&#x1F4C8; 85 <br>
<p>Aws Albarghouthi</p></summary>
<p>

**Abstract:** Deep learning has transformed the way we think of software and what it can do. But deep neural networks are fragile and their behaviors are often surprising. In many settings, we need to provide formal guarantees on the safety, security, correctness, or robustness of neural networks. This book covers foundational ideas from formal verification and their adaptation to reasoning about neural networks and deep learning.

</p>
</details>

<details><summary><b>TrOCR: Transformer-based Optical Character Recognition with Pre-trained Models</b>
<a href="https://arxiv.org/abs/2109.10282">arxiv:2109.10282</a>
&#x1F4C8; 60 <br>
<p>Minghao Li, Tengchao Lv, Lei Cui, Yijuan Lu, Dinei Florencio, Cha Zhang, Zhoujun Li, Furu Wei</p></summary>
<p>

**Abstract:** Text recognition is a long-standing research problem for document digitalization. Existing approaches for text recognition are usually built based on CNN for image understanding and RNN for char-level text generation. In addition, another language model is usually needed to improve the overall accuracy as a post-processing step. In this paper, we propose an end-to-end text recognition approach with pre-trained image Transformer and text Transformer models, namely TrOCR, which leverages the Transformer architecture for both image understanding and wordpiece-level text generation. The TrOCR model is simple but effective, and can be pre-trained with large-scale synthetic data and fine-tuned with human-labeled datasets. Experiments show that the TrOCR model outperforms the current state-of-the-art models on both printed and handwritten text recognition tasks. The code and models will be publicly available at https://aka.ms/TrOCR.

</p>
</details>

<details><summary><b>Learning offline: memory replay in biological and artificial reinforcement learning</b>
<a href="https://arxiv.org/abs/2109.10034">arxiv:2109.10034</a>
&#x1F4C8; 26 <br>
<p>Emma L. Roscow, Raymond Chua, Rui Ponte Costa, Matt W. Jones, Nathan Lepora</p></summary>
<p>

**Abstract:** Learning to act in an environment to maximise rewards is among the brain's key functions. This process has often been conceptualised within the framework of reinforcement learning, which has also gained prominence in machine learning and artificial intelligence (AI) as a way to optimise decision-making. A common aspect of both biological and machine reinforcement learning is the reactivation of previously experienced episodes, referred to as replay. Replay is important for memory consolidation in biological neural networks, and is key to stabilising learning in deep neural networks. Here, we review recent developments concerning the functional roles of replay in the fields of neuroscience and AI. Complementary progress suggests how replay might support learning processes, including generalisation and continual learning, affording opportunities to transfer knowledge across the two fields to advance the understanding of biological and artificial learning and memory.

</p>
</details>

<details><summary><b>Example-Driven Model-Based Reinforcement Learning for Solving Long-Horizon Visuomotor Tasks</b>
<a href="https://arxiv.org/abs/2109.10312">arxiv:2109.10312</a>
&#x1F4C8; 22 <br>
<p>Bohan Wu, Suraj Nair, Li Fei-Fei, Chelsea Finn</p></summary>
<p>

**Abstract:** In this paper, we study the problem of learning a repertoire of low-level skills from raw images that can be sequenced to complete long-horizon visuomotor tasks. Reinforcement learning (RL) is a promising approach for acquiring short-horizon skills autonomously. However, the focus of RL algorithms has largely been on the success of those individual skills, more so than learning and grounding a large repertoire of skills that can be sequenced to complete extended multi-stage tasks. The latter demands robustness and persistence, as errors in skills can compound over time, and may require the robot to have a number of primitive skills in its repertoire, rather than just one. To this end, we introduce EMBR, a model-based RL method for learning primitive skills that are suitable for completing long-horizon visuomotor tasks. EMBR learns and plans using a learned model, critic, and success classifier, where the success classifier serves both as a reward function for RL and as a grounding mechanism to continuously detect if the robot should retry a skill when unsuccessful or under perturbations. Further, the learned model is task-agnostic and trained using data from all skills, enabling the robot to efficiently learn a number of distinct primitives. These visuomotor primitive skills and their associated pre- and post-conditions can then be directly combined with off-the-shelf symbolic planners to complete long-horizon tasks. On a Franka Emika robot arm, we find that EMBR enables the robot to complete three long-horizon visuomotor tasks at 85% success rate, such as organizing an office desk, a file cabinet, and drawers, which require sequencing up to 12 skills, involve 14 unique learned primitives, and demand generalization to novel objects.

</p>
</details>

<details><summary><b>AI in Osteoporosis</b>
<a href="https://arxiv.org/abs/2109.10478">arxiv:2109.10478</a>
&#x1F4C8; 17 <br>
<p>Sokratis Makrogiannis, Keni Zheng</p></summary>
<p>

**Abstract:** In this chapter we explore and evaluate methods for trabecular bone characterization and osteoporosis diagnosis with increased interest in sparse approximations. We first describe texture representation and classification techniques, patch-based methods such as Bag of Keypoints, and more recent deep neural networks. Then we introduce the concept of sparse representations for pattern recognition and we detail integrative sparse analysis methods and classifier decision fusion methods. We report cross-validation results on osteoporosis datasets of bone radiographs and compare the results produced by the different categories of methods. We conclude that advances in the AI and machine learning fields have enabled the development of methods that can be used as diagnostic tools in clinical settings.

</p>
</details>

<details><summary><b>Personalized Online Machine Learning</b>
<a href="https://arxiv.org/abs/2109.10452">arxiv:2109.10452</a>
&#x1F4C8; 12 <br>
<p>Ivana Malenica, Rachael V. Phillips, Romain Pirracchio, Antoine Chambaz, Alan Hubbard, Mark J. van der Laan</p></summary>
<p>

**Abstract:** In this work, we introduce the Personalized Online Super Learner (POSL) -- an online ensembling algorithm for streaming data whose optimization procedure accommodates varying degrees of personalization. Namely, POSL optimizes predictions with respect to baseline covariates, so personalization can vary from completely individualized (i.e., optimization with respect to baseline covariate subject ID) to many individuals (i.e., optimization with respect to common baseline covariates). As an online algorithm, POSL learns in real-time. POSL can leverage a diversity of candidate algorithms, including online algorithms with different training and update times, fixed algorithms that are never updated during the procedure, pooled algorithms that learn from many individuals' time-series, and individualized algorithms that learn from within a single time-series. POSL's ensembling of this hybrid of base learning strategies depends on the amount of data collected, the stationarity of the time-series, and the mutual characteristics of a group of time-series. In essence, POSL decides whether to learn across samples, through time, or both, based on the underlying (unknown) structure in the data. For a wide range of simulations that reflect realistic forecasting scenarios, and in a medical data application, we examine the performance of POSL relative to other current ensembling and online learning methods. We show that POSL is able to provide reliable predictions for time-series data and adjust to changing data-generating environments. We further cultivate POSL's practicality by extending it to settings where time-series enter/exit dynamically over chronological time.

</p>
</details>

<details><summary><b>Relation-Guided Pre-Training for Open-Domain Question Answering</b>
<a href="https://arxiv.org/abs/2109.10346">arxiv:2109.10346</a>
&#x1F4C8; 12 <br>
<p>Ziniu Hu, Yizhou Sun, Kai-Wei Chang</p></summary>
<p>

**Abstract:** Answering complex open-domain questions requires understanding the latent relations between involving entities. However, we found that the existing QA datasets are extremely imbalanced in some types of relations, which hurts the generalization performance over questions with long-tail relations. To remedy this problem, in this paper, we propose a Relation-Guided Pre-Training (RGPT-QA) framework. We first generate a relational QA dataset covering a wide range of relations from both the Wikidata triplets and Wikipedia hyperlinks. We then pre-train a QA model to infer the latent relations from the question, and then conduct extractive QA to get the target answer entity. We demonstrate that by pretraining with propoed RGPT-QA techique, the popular open-domain QA model, Dense Passage Retriever (DPR), achieves 2.2%, 2.4%, and 6.3% absolute improvement in Exact Match accuracy on Natural Questions, TriviaQA, and WebQuestions. Particularly, we show that RGPT-QA improves significantly on questions with long-tail relations

</p>
</details>

<details><summary><b>What Would it Take to get Biomedical QA Systems into Practice?</b>
<a href="https://arxiv.org/abs/2109.10415">arxiv:2109.10415</a>
&#x1F4C8; 10 <br>
<p>Gregory Kell, Iain J. Marshall, Byron C. Wallace, Andre Jaun</p></summary>
<p>

**Abstract:** Medical question answering (QA) systems have the potential to answer clinicians uncertainties about treatment and diagnosis on demand, informed by the latest evidence. However, despite the significant progress in general QA made by the NLP community, medical QA systems are still not widely used in clinical environments. One likely reason for this is that clinicians may not readily trust QA system outputs, in part because transparency, trustworthiness, and provenance have not been key considerations in the design of such models. In this paper we discuss a set of criteria that, if met, we argue would likely increase the utility of biomedical QA systems, which may in turn lead to adoption of such systems in practice. We assess existing models, tasks, and datasets with respect to these criteria, highlighting shortcomings of previously proposed approaches and pointing toward what might be more usable QA systems.

</p>
</details>

<details><summary><b>Digital Signal Processing Using Deep Neural Networks</b>
<a href="https://arxiv.org/abs/2109.10404">arxiv:2109.10404</a>
&#x1F4C8; 10 <br>
<p>Brian Shevitski, Yijing Watkins, Nicole Man, Michael Girard</p></summary>
<p>

**Abstract:** Currently there is great interest in the utility of deep neural networks (DNNs) for the physical layer of radio frequency (RF) communications. In this manuscript, we describe a custom DNN specially designed to solve problems in the RF domain. Our model leverages the mechanisms of feature extraction and attention through the combination of an autoencoder convolutional network with a transformer network, to accomplish several important communications network and digital signals processing (DSP) tasks. We also present a new open dataset and physical data augmentation model that enables training of DNNs that can perform automatic modulation classification, infer and correct transmission channel effects, and directly demodulate baseband RF signals.

</p>
</details>

<details><summary><b>Mixed-supervised segmentation: Confidence maximization helps knowledge distillation</b>
<a href="https://arxiv.org/abs/2109.10902">arxiv:2109.10902</a>
&#x1F4C8; 9 <br>
<p>Bingyuan Liu, Christian Desrosiers, Ismail Ben Ayed, Jose Dolz</p></summary>
<p>

**Abstract:** Despite achieving promising results in a breadth of medical image segmentation tasks, deep neural networks require large training datasets with pixel-wise annotations. Obtaining these curated datasets is a cumbersome process which limits the application in scenarios where annotated images are scarce. Mixed supervision is an appealing alternative for mitigating this obstacle, where only a small fraction of the data contains complete pixel-wise annotations and other images have a weaker form of supervision. In this work, we propose a dual-branch architecture, where the upper branch (teacher) receives strong annotations, while the bottom one (student) is driven by limited supervision and guided by the upper branch. Combined with a standard cross-entropy loss over the labeled pixels, our novel formulation integrates two important terms: (i) a Shannon entropy loss defined over the less-supervised images, which encourages confident student predictions in the bottom branch; and (ii) a Kullback-Leibler (KL) divergence term, which transfers the knowledge of the strongly supervised branch to the less-supervised branch and guides the entropy (student-confidence) term to avoid trivial solutions. We show that the synergy between the entropy and KL divergence yields substantial improvements in performance. We also discuss an interesting link between Shannon-entropy minimization and standard pseudo-mask generation, and argue that the former should be preferred over the latter for leveraging information from unlabeled pixels. Quantitative and qualitative results on two publicly available datasets demonstrate that our method significantly outperforms other strategies for semantic segmentation within a mixed-supervision framework, as well as recent semi-supervised approaches. Moreover, we show that the branch trained with reduced supervision and guided by the top branch largely outperforms the latter.

</p>
</details>

<details><summary><b>Unsupervised Contextualized Document Representation</b>
<a href="https://arxiv.org/abs/2109.10509">arxiv:2109.10509</a>
&#x1F4C8; 9 <br>
<p>Ankur Gupta, Vivek Gupta</p></summary>
<p>

**Abstract:** Several NLP tasks need the effective representation of text documents. Arora et. al., 2017 demonstrate that simple weighted averaging of word vectors frequently outperforms neural models. SCDV (Mekala et. al., 2017) further extends this from sentences to documents by employing soft and sparse clustering over pre-computed word vectors. However, both techniques ignore the polysemy and contextual character of words. In this paper, we address this issue by proposing SCDV+BERT(ctxd), a simple and effective unsupervised representation that combines contextualized BERT (Devlin et al., 2019) based word embedding for word sense disambiguation with SCDV soft clustering approach. We show that our embeddings outperform original SCDV, pre-train BERT, and several other baselines on many classification datasets. We also demonstrate our embeddings effectiveness on other tasks, such as concept matching and sentence similarity. In addition, we show that SCDV+BERT(ctxd) outperforms fine-tune BERT and different embedding approaches in scenarios with limited data and only few shots examples.

</p>
</details>

<details><summary><b>Generating Compositional Color Representations from Text</b>
<a href="https://arxiv.org/abs/2109.10477">arxiv:2109.10477</a>
&#x1F4C8; 9 <br>
<p>Paridhi Maheshwari, Nihal Jain, Praneetha Vaddamanu, Dhananjay Raut, Shraiysh Vaishay, Vishwa Vinay</p></summary>
<p>

**Abstract:** We consider the cross-modal task of producing color representations for text phrases. Motivated by the fact that a significant fraction of user queries on an image search engine follow an (attribute, object) structure, we propose a generative adversarial network that generates color profiles for such bigrams. We design our pipeline to learn composition - the ability to combine seen attributes and objects to unseen pairs. We propose a novel dataset curation pipeline from existing public sources. We describe how a set of phrases of interest can be compiled using a graph propagation technique, and then mapped to images. While this dataset is specialized for our investigations on color, the method can be extended to other visual dimensions where composition is of interest. We provide detailed ablation studies that test the behavior of our GAN architecture with loss functions from the contrastive learning literature. We show that the generative model achieves lower Frechet Inception Distance than discriminative ones, and therefore predicts color profiles that better match those from real images. Finally, we demonstrate improved performance in image retrieval and classification, indicating the crucial role that color plays in these downstream tasks.

</p>
</details>

<details><summary><b>Scalable and Efficient MoE Training for Multitask Multilingual Models</b>
<a href="https://arxiv.org/abs/2109.10465">arxiv:2109.10465</a>
&#x1F4C8; 9 <br>
<p>Young Jin Kim, Ammar Ahmad Awan, Alexandre Muzio, Andres Felipe Cruz Salinas, Liyang Lu, Amr Hendy, Samyam Rajbhandari, Yuxiong He, Hany Hassan Awadalla</p></summary>
<p>

**Abstract:** The Mixture of Experts (MoE) models are an emerging class of sparsely activated deep learning models that have sublinear compute costs with respect to their parameters. In contrast with dense models, the sparse architecture of MoE offers opportunities for drastically growing model size with significant accuracy gain while consuming much lower compute budget. However, supporting large scale MoE training also has its own set of system and modeling challenges. To overcome the challenges and embrace the opportunities of MoE, we first develop a system capable of scaling MoE models efficiently to trillions of parameters. It combines multi-dimensional parallelism and heterogeneous memory technologies harmoniously with MoE to empower 8x larger models on the same hardware compared with existing work. Besides boosting system efficiency, we also present new training methods to improve MoE sample efficiency and leverage expert pruning strategy to improve inference time efficiency. By combining the efficient system and training methods, we are able to significantly scale up large multitask multilingual models for language generation which results in a great improvement in model accuracy. A model trained with 10 billion parameters on 50 languages can achieve state-of-the-art performance in Machine Translation (MT) and multilingual natural language generation tasks. The system support of efficient MoE training has been implemented and open-sourced with the DeepSpeed library.

</p>
</details>

<details><summary><b>Multilingual Document-Level Translation Enables Zero-Shot Transfer From Sentences to Documents</b>
<a href="https://arxiv.org/abs/2109.10341">arxiv:2109.10341</a>
&#x1F4C8; 9 <br>
<p>Biao Zhang, Ankur Bapna, Melvin Johnson, Ali Dabirmoghaddam, Naveen Arivazhagan, Orhan Firat</p></summary>
<p>

**Abstract:** Document-level neural machine translation (DocNMT) delivers coherent translations by incorporating cross-sentence context. However, for most language pairs there's a shortage of parallel documents, although parallel sentences are readily available. In this paper, we study whether and how contextual modeling in DocNMT is transferable from sentences to documents in a zero-shot fashion (i.e. no parallel documents for student languages) through multilingual modeling. Using simple concatenation-based DocNMT, we explore the effect of 3 factors on multilingual transfer: the number of document-supervised teacher languages, the data schedule for parallel documents at training, and the data condition of parallel documents (genuine vs. backtranslated). Our experiments on Europarl-7 and IWSLT-10 datasets show the feasibility of multilingual transfer for DocNMT, particularly on document-specific metrics. We observe that more teacher languages and adequate data schedule both contribute to better transfer quality. Surprisingly, the transfer is less sensitive to the data condition and multilingual DocNMT achieves comparable performance with both back-translated and genuine document pairs.

</p>
</details>

<details><summary><b>CondNet: Conditional Classifier for Scene Segmentation</b>
<a href="https://arxiv.org/abs/2109.10322">arxiv:2109.10322</a>
&#x1F4C8; 9 <br>
<p>Changqian Yu, Yuanjie Shao, Changxin Gao, Nong Sang</p></summary>
<p>

**Abstract:** The fully convolutional network (FCN) has achieved tremendous success in dense visual recognition tasks, such as scene segmentation. The last layer of FCN is typically a global classifier (1x1 convolution) to recognize each pixel to a semantic label. We empirically show that this global classifier, ignoring the intra-class distinction, may lead to sub-optimal results.
  In this work, we present a conditional classifier to replace the traditional global classifier, where the kernels of the classifier are generated dynamically conditioned on the input. The main advantages of the new classifier consist of: (i) it attends on the intra-class distinction, leading to stronger dense recognition capability; (ii) the conditional classifier is simple and flexible to be integrated into almost arbitrary FCN architectures to improve the prediction. Extensive experiments demonstrate that the proposed classifier performs favourably against the traditional classifier on the FCN architecture. The framework equipped with the conditional classifier (called CondNet) achieves new state-of-the-art performances on two datasets. The code and models are available at https://git.io/CondNet.

</p>
</details>

<details><summary><b>Learning PAC-Bayes Priors for Probabilistic Neural Networks</b>
<a href="https://arxiv.org/abs/2109.10304">arxiv:2109.10304</a>
&#x1F4C8; 8 <br>
<p>Maria Perez-Ortiz, Omar Rivasplata, Benjamin Guedj, Matthew Gleeson, Jingyu Zhang, John Shawe-Taylor, Miroslaw Bober, Josef Kittler</p></summary>
<p>

**Abstract:** Recent works have investigated deep learning models trained by optimising PAC-Bayes bounds, with priors that are learnt on subsets of the data. This combination has been shown to lead not only to accurate classifiers, but also to remarkably tight risk certificates, bearing promise towards self-certified learning (i.e. use all the data to learn a predictor and certify its quality). In this work, we empirically investigate the role of the prior. We experiment on 6 datasets with different strategies and amounts of data to learn data-dependent PAC-Bayes priors, and we compare them in terms of their effect on test performance of the learnt predictors and tightness of their risk certificate. We ask what is the optimal amount of data which should be allocated for building the prior and show that the optimum may be dataset dependent. We demonstrate that using a small percentage of the prior-building data for validation of the prior leads to promising results. We include a comparison of underparameterised and overparameterised models, along with an empirical study of different training objectives and regularisation strategies to learn the prior distribution.

</p>
</details>

<details><summary><b>Towards a Real-Time Facial Analysis System</b>
<a href="https://arxiv.org/abs/2109.10393">arxiv:2109.10393</a>
&#x1F4C8; 7 <br>
<p>Bishwo Adhikari, Xingyang Ni, Esa Rahtu, Heikki Huttunen</p></summary>
<p>

**Abstract:** Facial analysis is an active research area in computer vision, with many practical applications. Most of the existing studies focus on addressing one specific task and maximizing its performance. For a complete facial analysis system, one needs to solve these tasks efficiently to ensure a smooth experience. In this work, we present a system-level design of a real-time facial analysis system. With a collection of deep neural networks for object detection, classification, and regression, the system recognizes age, gender, facial expression, and facial similarity for each person that appears in the camera view. We investigate the parallelization and interplay of individual tasks. Results on common off-the-shelf architecture show that the system's accuracy is comparable to the state-of-the-art methods, and the recognition speed satisfies real-time requirements. Moreover, we propose a multitask network for jointly predicting the first three attributes, i.e., age, gender, and facial expression. Source code and trained models are available at https://github.com/mahehu/TUT-live-age-estimator.

</p>
</details>

<details><summary><b>Salience-Aware Event Chain Modeling for Narrative Understanding</b>
<a href="https://arxiv.org/abs/2109.10475">arxiv:2109.10475</a>
&#x1F4C8; 6 <br>
<p>Xiyang Zhang, Muhao Chen, Jonathan May</p></summary>
<p>

**Abstract:** Storytelling, whether via fables, news reports, documentaries, or memoirs, can be thought of as the communication of interesting and related events that, taken together, form a concrete process. It is desirable to extract the event chains that represent such processes. However, this extraction remains a challenging problem. We posit that this is due to the nature of the texts from which chains are discovered. Natural language text interleaves a narrative of concrete, salient events with background information, contextualization, opinion, and other elements that are important for a variety of necessary discourse and pragmatics acts but are not part of the principal chain of events being communicated. We introduce methods for extracting this principal chain from natural language text, by filtering away non-salient events and supportive sentences. We demonstrate the effectiveness of our methods at isolating critical event chains by comparing their effect on downstream tasks. We show that by pre-training large language models on our extracted chains, we obtain improvements in two tasks that benefit from a clear understanding of event chains: narrative prediction and event-based temporal question answering. The demonstrated improvements and ablative studies confirm that our extraction method isolates critical event chains.

</p>
</details>

<details><summary><b>Does Vision-and-Language Pretraining Improve Lexical Grounding?</b>
<a href="https://arxiv.org/abs/2109.10246">arxiv:2109.10246</a>
&#x1F4C8; 6 <br>
<p>Tian Yun, Chen Sun, Ellie Pavlick</p></summary>
<p>

**Abstract:** Linguistic representations derived from text alone have been criticized for their lack of grounding, i.e., connecting words to their meanings in the physical world. Vision-and-Language (VL) models, trained jointly on text and image or video data, have been offered as a response to such criticisms. However, while VL pretraining has shown success on multimodal tasks such as visual question answering, it is not yet known how the internal linguistic representations themselves compare to their text-only counterparts. This paper compares the semantic representations learned via VL vs. text-only pretraining for two recent VL models using a suite of analyses (clustering, probing, and performance on a commonsense question answering task) in a language-only setting. We find that the multimodal models fail to significantly outperform the text-only variants, suggesting that future work is required if multimodal pretraining is to be pursued as a means of improving NLP in general.

</p>
</details>

<details><summary><b>Self-supervised Representation Learning for Reliable Robotic Monitoring of Fruit Anomalies</b>
<a href="https://arxiv.org/abs/2109.10135">arxiv:2109.10135</a>
&#x1F4C8; 6 <br>
<p>Taeyeong Choi, Owen Would, Adrian Salazar-Gomez, Grzegorz Cielniak</p></summary>
<p>

**Abstract:** Data augmentation can be a simple yet powerful tool for autonomous robots to fully utilise available data for self-supervised identification of atypical scenes or objects. State-of-the-art augmentation methods arbitrarily embed structural peculiarity in focal objects on typical images so that classifying these artefacts can provide guidance for learning representations for the detection of anomalous visual inputs. In this paper, however, we argue that learning such structure-sensitive representations can be a suboptimal approach to some classes of anomaly (e.g., unhealthy fruits) which are better recognised by a different type of visual element such as "colour". We thus propose Channel Randomisation as a novel data augmentation method for restricting neural network models to learn encoding of "colour irregularity" whilst predicting channel-randomised images to ultimately build reliable fruit-monitoring robots identifying atypical fruit qualities. Our experiments show that (1) the colour-based alternative can better learn representations for consistently accurate identification of fruit anomalies in various fruit species, and (2) validation accuracy can be monitored for early stopping of training due to positive correlation between the colour-learning task and fruit anomaly detection. Moreover, the proposed approach is evaluated on a new anomaly dataset Riseholme-2021, consisting of 3:5K strawberry images collected from a mobile robot, which we share with the community to encourage active agri-robotics research.

</p>
</details>

<details><summary><b>StereOBJ-1M: Large-scale Stereo Image Dataset for 6D Object Pose Estimation</b>
<a href="https://arxiv.org/abs/2109.10115">arxiv:2109.10115</a>
&#x1F4C8; 6 <br>
<p>Xingyu Liu, Shun Iwase, Kris M. Kitani</p></summary>
<p>

**Abstract:** We present a large-scale stereo RGB image object pose estimation dataset named the $\textbf{StereOBJ-1M}$ dataset. The dataset is designed to address challenging cases such as object transparency, translucency, and specular reflection, in addition to the common challenges of occlusion, symmetry, and variations in illumination and environments. In order to collect data of sufficient scale for modern deep learning models, we propose a novel method for efficiently annotating pose data in a multi-view fashion that allows data capturing in complex and flexible environments. Fully annotated with 6D object poses, our dataset contains over 396K frames and over 1.5M annotations of 18 objects recorded in 183 scenes constructed in 11 different environments. The 18 objects include 8 symmetric objects, 7 transparent objects, and 8 reflective objects. We benchmark two state-of-the-art pose estimation frameworks on StereOBJ-1M as baselines for future work. We also propose a novel object-level pose optimization method for computing 6D pose from keypoint predictions in multiple images.

</p>
</details>

<details><summary><b>Active inference, Bayesian optimal design, and expected utility</b>
<a href="https://arxiv.org/abs/2110.04074">arxiv:2110.04074</a>
&#x1F4C8; 5 <br>
<p>Noor Sajid, Lancelot Da Costa, Thomas Parr, Karl Friston</p></summary>
<p>

**Abstract:** Active inference, a corollary of the free energy principle, is a formal way of describing the behavior of certain kinds of random dynamical systems that have the appearance of sentience. In this chapter, we describe how active inference combines Bayesian decision theory and optimal Bayesian design principles under a single imperative to minimize expected free energy. It is this aspect of active inference that allows for the natural emergence of information-seeking behavior. When removing prior outcomes preferences from expected free energy, active inference reduces to optimal Bayesian design, i.e., information gain maximization. Conversely, active inference reduces to Bayesian decision theory in the absence of ambiguity and relative risk, i.e., expected utility maximization. Using these limiting cases, we illustrate how behaviors differ when agents select actions that optimize expected utility, expected information gain, and expected free energy. Our T-maze simulations show optimizing expected free energy produces goal-directed information-seeking behavior while optimizing expected utility induces purely exploitive behavior and maximizing information gain engenders intrinsically motivated behavior.

</p>
</details>

<details><summary><b>Identifying Potential Exomoon Signals with Convolutional Neural Networks</b>
<a href="https://arxiv.org/abs/2109.10503">arxiv:2109.10503</a>
&#x1F4C8; 5 <br>
<p>Alex Teachey, David Kipping</p></summary>
<p>

**Abstract:** Targeted observations of possible exomoon host systems will remain difficult to obtain and time-consuming to analyze in the foreseeable future. As such, time-domain surveys such as Kepler, K2 and TESS will continue to play a critical role as the first step in identifying candidate exomoon systems, which may then be followed-up with premier ground- or space-based telescopes. In this work, we train an ensemble of convolutional neural networks (CNNs) to identify candidate exomoon signals in single-transit events observed by Kepler. Our training set consists of ${\sim}$27,000 examples of synthetic, planet-only and planet+moon single transits, injected into Kepler light curves. We achieve up to 88\% classification accuracy with individual CNN architectures and 97\% precision in identifying the moons in the validation set when the CNN ensemble is in total agreement. We then apply the CNN ensemble to light curves from 1880 Kepler Objects of Interest with periods $>10$ days ($\sim$57,000 individual transits), and further test the accuracy of the CNN classifier by injecting planet transits into each light curve, thus quantifying the extent to which residual stellar activity may result in false positive classifications. We find a small fraction of these transits contain moon-like signals, though we caution against strong inferences of the exomoon occurrence rate from this result. We conclude by discussing some ongoing challenges to utilizing neural networks for the exomoon search.

</p>
</details>

<details><summary><b>HyperExpan: Taxonomy Expansion with Hyperbolic Representation Learning</b>
<a href="https://arxiv.org/abs/2109.10500">arxiv:2109.10500</a>
&#x1F4C8; 5 <br>
<p>Mingyu Derek Ma, Muhao Chen, Te-Lin Wu, Nanyun Peng</p></summary>
<p>

**Abstract:** Taxonomies are valuable resources for many applications, but the limited coverage due to the expensive manual curation process hinders their general applicability. Prior works attempt to automatically expand existing taxonomies to improve their coverage by learning concept embeddings in Euclidean space, while taxonomies, inherently hierarchical, more naturally align with the geometric properties of a hyperbolic space. In this paper, we present HyperExpan, a taxonomy expansion algorithm that seeks to preserve the structure of a taxonomy in a more expressive hyperbolic embedding space and learn to represent concepts and their relations with a Hyperbolic Graph Neural Network (HGNN). Specifically, HyperExpan leverages position embeddings to exploit the structure of the existing taxonomies, and characterizes the concept profile information to support the inference on unseen concepts during training. Experiments show that our proposed HyperExpan outperforms baseline models with representation learning in a Euclidean feature space and achieves state-of-the-art performance on the taxonomy expansion benchmarks.

</p>
</details>

<details><summary><b>DialogueBERT: A Self-Supervised Learning based Dialogue Pre-training Encoder</b>
<a href="https://arxiv.org/abs/2109.10480">arxiv:2109.10480</a>
&#x1F4C8; 5 <br>
<p>Zhenyu Zhang, Tao Guo, Meng Chen</p></summary>
<p>

**Abstract:** With the rapid development of artificial intelligence, conversational bots have became prevalent in mainstream E-commerce platforms, which can provide convenient customer service timely. To satisfy the user, the conversational bots need to understand the user's intention, detect the user's emotion, and extract the key entities from the conversational utterances. However, understanding dialogues is regarded as a very challenging task. Different from common language understanding, utterances in dialogues appear alternately from different roles and are usually organized as hierarchical structures. To facilitate the understanding of dialogues, in this paper, we propose a novel contextual dialogue encoder (i.e. DialogueBERT) based on the popular pre-trained language model BERT. Five self-supervised learning pre-training tasks are devised for learning the particularity of dialouge utterances. Four different input embeddings are integrated to catch the relationship between utterances, including turn embedding, role embedding, token embedding and position embedding. DialogueBERT was pre-trained with 70 million dialogues in real scenario, and then fine-tuned in three different downstream dialogue understanding tasks. Experimental results show that DialogueBERT achieves exciting results with 88.63% accuracy for intent recognition, 94.25% accuracy for emotion recognition and 97.04% F1 score for named entity recognition, which outperforms several strong baselines by a large margin.

</p>
</details>

<details><summary><b>The First Vision For Vitals (V4V) Challenge for Non-Contact Video-Based Physiological Estimation</b>
<a href="https://arxiv.org/abs/2109.10471">arxiv:2109.10471</a>
&#x1F4C8; 5 <br>
<p>Ambareesh Revanur, Zhihua Li, Umur A. Ciftci, Lijun Yin, Laszlo A. Jeni</p></summary>
<p>

**Abstract:** Telehealth has the potential to offset the high demand for help during public health emergencies, such as the COVID-19 pandemic. Remote Photoplethysmography (rPPG) - the problem of non-invasively estimating blood volume variations in the microvascular tissue from video - would be well suited for these situations. Over the past few years a number of research groups have made rapid advances in remote PPG methods for estimating heart rate from digital video and obtained impressive results. How these various methods compare in naturalistic conditions, where spontaneous behavior, facial expressions, and illumination changes are present, is relatively unknown. To enable comparisons among alternative methods, the 1st Vision for Vitals Challenge (V4V) presented a novel dataset containing high-resolution videos time-locked with varied physiological signals from a diverse population. In this paper, we outline the evaluation protocol, the data used, and the results. V4V is to be held in conjunction with the 2021 International Conference on Computer Vision.

</p>
</details>

<details><summary><b>Assured Neural Network Architectures for Control and Identification of Nonlinear Systems</b>
<a href="https://arxiv.org/abs/2109.10298">arxiv:2109.10298</a>
&#x1F4C8; 5 <br>
<p>James Ferlez, Yasser Shoukry</p></summary>
<p>

**Abstract:** In this paper, we consider the problem of automatically designing a Rectified Linear Unit (ReLU) Neural Network (NN) architecture (number of layers and number of neurons per layer) with the assurance that it is sufficiently parametrized to control a nonlinear system; i.e. control the system to satisfy a given formal specification. This is unlike current techniques, which provide no assurances on the resultant architecture. Moreover, our approach requires only limited knowledge of the underlying nonlinear system and specification. We assume only that the specification can be satisfied by a Lipschitz-continuous controller with a known bound on its Lipschitz constant; the specific controller need not be known. From this assumption, we bound the number of affine functions needed to construct a Continuous Piecewise Affine (CPWA) function that can approximate any Lipschitz-continuous controller that satisfies the specification. Then we connect this CPWA to a NN architecture using the authors' recent results on the Two-Level Lattice (TLL) NN architecture; the TLL architecture was shown to be parameterized by the number of affine functions present in the CPWA function it realizes.

</p>
</details>

<details><summary><b>Comparison of single and multitask learning for predicting cognitive decline based on MRI data</b>
<a href="https://arxiv.org/abs/2109.10266">arxiv:2109.10266</a>
&#x1F4C8; 5 <br>
<p>Vandad Imani, Mithilesh Prakash, Marzieh Zare, Jussi Tohka</p></summary>
<p>

**Abstract:** The Alzheimer's Disease Assessment Scale-Cognitive subscale (ADAS-Cog) is a neuropsychological tool that has been designed to assess the severity of cognitive symptoms of dementia. Personalized prediction of the changes in ADAS-Cog scores could help in timing therapeutic interventions in dementia and at-risk populations. In the present work, we compared single and multitask learning approaches to predict the changes in ADAS-Cog scores based on T1-weighted anatomical magnetic resonance imaging (MRI). In contrast to most machine learning-based prediction methods ADAS-Cog changes, we stratified the subjects based on their baseline diagnoses and evaluated the prediction performances in each group. Our experiments indicated a positive relationship between the predicted and observed ADAS-Cog score changes in each diagnostic group, suggesting that T1-weighted MRI has a predictive value for evaluating cognitive decline in the entire AD continuum. We further studied whether correction of the differences in the magnetic field strength of MRI would improve the ADAS-Cog score prediction. The partial least square-based domain adaptation slightly improved the prediction performance, but the improvement was marginal. In summary, this study demonstrated that ADAS-Cog change could be, to some extent, predicted based on anatomical MRI. Based on this study, the recommended method for learning the predictive models is a single-task regularized linear regression due to its simplicity and good performance. It appears important to combine the training data across all subject groups for the most effective predictive models.

</p>
</details>

<details><summary><b>KDFNet: Learning Keypoint Distance Field for 6D Object Pose Estimation</b>
<a href="https://arxiv.org/abs/2109.10127">arxiv:2109.10127</a>
&#x1F4C8; 5 <br>
<p>Xingyu Liu, Shun Iwase, Kris M. Kitani</p></summary>
<p>

**Abstract:** We present KDFNet, a novel method for 6D object pose estimation from RGB images. To handle occlusion, many recent works have proposed to localize 2D keypoints through pixel-wise voting and solve a Perspective-n-Point (PnP) problem for pose estimation, which achieves leading performance. However, such voting process is direction-based and cannot handle long and thin objects where the direction intersections cannot be robustly found. To address this problem, we propose a novel continuous representation called Keypoint Distance Field (KDF) for projected 2D keypoint locations. Formulated as a 2D array, each element of the KDF stores the 2D Euclidean distance between the corresponding image pixel and a specified projected 2D keypoint. We use a fully convolutional neural network to regress the KDF for each keypoint. Using this KDF encoding of projected object keypoint locations, we propose to use a distance-based voting scheme to localize the keypoints by calculating circle intersections in a RANSAC fashion. We validate the design choices of our framework by extensive ablation experiments. Our proposed method achieves state-of-the-art performance on Occlusion LINEMOD dataset with an average ADD(-S) accuracy of 50.3% and TOD dataset mug subset with an average ADD accuracy of 75.72%. Extensive experiments and visualizations demonstrate that the proposed method is able to robustly estimate the 6D pose in challenging scenarios including occlusion.

</p>
</details>

<details><summary><b>LOTR: Face Landmark Localization Using Localization Transformer</b>
<a href="https://arxiv.org/abs/2109.10057">arxiv:2109.10057</a>
&#x1F4C8; 5 <br>
<p>Ukrit Watchareeruetai, Benjaphan Sommana, Sanjana Jain, Pavit Noinongyao, Ankush Ganguly, Aubin Samacoits, Samuel W. F. Earp, Nakarin Sritrakool</p></summary>
<p>

**Abstract:** This paper presents a novel Transformer-based facial landmark localization network named Localization Transformer (LOTR). The proposed framework is a direct coordinate regression approach leveraging a Transformer network to better utilize the spatial information in the feature map. An LOTR model consists of three main modules: 1) a visual backbone that converts an input image into a feature map, 2) a Transformer module that improves the feature representation from the visual backbone, and 3) a landmark prediction head that directly predicts the landmark coordinates from the Transformer's representation. Given cropped-and-aligned face images, the proposed LOTR can be trained end-to-end without requiring any post-processing steps. This paper also introduces the smooth-Wing loss function, which addresses the gradient discontinuity of the Wing loss, leading to better convergence than standard loss functions such as L1, L2, and Wing loss. Experimental results on the JD landmark dataset provided by the First Grand Challenge of 106-Point Facial Landmark Localization indicate the superiority of LOTR over the existing methods on the leaderboard and two recent heatmap-based approaches. On the WFLW dataset, the proposed LOTR framework demonstrates promising results compared with several state-of-the-art methods. Additionally, we report the improvement in state-of-the-art face recognition performance when using our proposed LOTRs for face alignment.

</p>
</details>

<details><summary><b>Generalization in Text-based Games via Hierarchical Reinforcement Learning</b>
<a href="https://arxiv.org/abs/2109.09968">arxiv:2109.09968</a>
&#x1F4C8; 5 <br>
<p>Yunqiu Xu, Meng Fang, Ling Chen, Yali Du, Chengqi Zhang</p></summary>
<p>

**Abstract:** Deep reinforcement learning provides a promising approach for text-based games in studying natural language communication between humans and artificial agents. However, the generalization still remains a big challenge as the agents depend critically on the complexity and variety of training tasks. In this paper, we address this problem by introducing a hierarchical framework built upon the knowledge graph-based RL agent. In the high level, a meta-policy is executed to decompose the whole game into a set of subtasks specified by textual goals, and select one of them based on the KG. Then a sub-policy in the low level is executed to conduct goal-conditioned reinforcement learning. We carry out experiments on games with various difficulty levels and show that the proposed method enjoys favorable generalizability.

</p>
</details>

<details><summary><b>A Hierarchical Network-Oriented Analysis of User Participation in Misinformation Spread on WhatsApp</b>
<a href="https://arxiv.org/abs/2109.10462">arxiv:2109.10462</a>
&#x1F4C8; 4 <br>
<p>Gabriel Peres Nobre, Carlos H. G. Ferreira, Jussara M. Almeida</p></summary>
<p>

**Abstract:** WhatsApp emerged as a major communication platform in many countries in the recent years. Despite offering only one-to-one and small group conversations, WhatsApp has been shown to enable the formation of a rich underlying network, crossing the boundaries of existing groups, and with structural properties that favor information dissemination at large. Indeed, WhatsApp has reportedly been used as a forum of misinformation campaigns with significant social, political and economic consequences in several countries. In this article, we aim at complementing recent studies on misinformation spread on WhatsApp, mostly focused on content properties and propagation dynamics, by looking into the network that connects users sharing the same piece of content. Specifically, we present a hierarchical network-oriented characterization of the users engaged in misinformation spread by focusing on three perspectives: individuals, WhatsApp groups and user communities, i.e., groupings of users who, intentionally or not, share the same content disproportionately often. By analyzing sharing and network topological properties, our study offers valuable insights into how WhatsApp users leverage the underlying network connecting different groups to gain large reach in the spread of misinformation on the platform.

</p>
</details>

<details><summary><b>Homography augumented momentum constrastive learning for SAR image retrieval</b>
<a href="https://arxiv.org/abs/2109.10329">arxiv:2109.10329</a>
&#x1F4C8; 4 <br>
<p>Seonho Park, Maciej Rysz, Kathleen M. Dipple, Panos M. Pardalos</p></summary>
<p>

**Abstract:** Deep learning-based image retrieval has been emphasized in computer vision. Representation embedding extracted by deep neural networks (DNNs) not only aims at containing semantic information of the image, but also can manage large-scale image retrieval tasks. In this work, we propose a deep learning-based image retrieval approach using homography transformation augmented contrastive learning to perform large-scale synthetic aperture radar (SAR) image search tasks. Moreover, we propose a training method for the DNNs induced by contrastive learning that does not require any labeling procedure. This may enable tractability of large-scale datasets with relative ease. Finally, we verify the performance of the proposed method by conducting experiments on the polarimetric SAR image datasets.

</p>
</details>

<details><summary><b>Survey on Semantic Stereo Matching / Semantic Depth Estimation</b>
<a href="https://arxiv.org/abs/2109.10123">arxiv:2109.10123</a>
&#x1F4C8; 4 <br>
<p>Viny Saajan Victor, Peter Neigel</p></summary>
<p>

**Abstract:** Stereo matching is one of the widely used techniques for inferring depth from stereo images owing to its robustness and speed. It has become one of the major topics of research since it finds its applications in autonomous driving, robotic navigation, 3D reconstruction, and many other fields. Finding pixel correspondences in non-textured, occluded and reflective areas is the major challenge in stereo matching. Recent developments have shown that semantic cues from image segmentation can be used to improve the results of stereo matching. Many deep neural network architectures have been proposed to leverage the advantages of semantic segmentation in stereo matching. This paper aims to give a comparison among the state of art networks both in terms of accuracy and in terms of speed which are of higher importance in real-time applications.

</p>
</details>

<details><summary><b>SPLADE v2: Sparse Lexical and Expansion Model for Information Retrieval</b>
<a href="https://arxiv.org/abs/2109.10086">arxiv:2109.10086</a>
&#x1F4C8; 4 <br>
<p>Thibault Formal, Carlos Lassance, Benjamin Piwowarski, Stéphane Clinchant</p></summary>
<p>

**Abstract:** In neural Information Retrieval (IR), ongoing research is directed towards improving the first retriever in ranking pipelines. Learning dense embeddings to conduct retrieval using efficient approximate nearest neighbors methods has proven to work well. Meanwhile, there has been a growing interest in learning \emph{sparse} representations for documents and queries, that could inherit from the desirable properties of bag-of-words models such as the exact matching of terms and the efficiency of inverted indexes. Introduced recently, the SPLADE model provides highly sparse representations and competitive results with respect to state-of-the-art dense and sparse approaches. In this paper, we build on SPLADE and propose several significant improvements in terms of effectiveness and/or efficiency. More specifically, we modify the pooling mechanism, benchmark a model solely based on document expansion, and introduce models trained with distillation. We also report results on the BEIR benchmark. Overall, SPLADE is considerably improved with more than $9$\% gains on NDCG@10 on TREC DL 2019, leading to state-of-the-art results on the BEIR benchmark.

</p>
</details>

<details><summary><b>Search For Deep Graph Neural Networks</b>
<a href="https://arxiv.org/abs/2109.10047">arxiv:2109.10047</a>
&#x1F4C8; 4 <br>
<p>Guosheng Feng, Chunnan Wang, Hongzhi Wang</p></summary>
<p>

**Abstract:** Current GNN-oriented NAS methods focus on the search for different layer aggregate components with shallow and simple architectures, which are limited by the 'over-smooth' problem. To further explore the benefits from structural diversity and depth of GNN architectures, we propose a GNN generation pipeline with a novel two-stage search space, which aims at automatically generating high-performance while transferable deep GNN models in a block-wise manner. Meanwhile, to alleviate the 'over-smooth' problem, we incorporate multiple flexible residual connection in our search space and apply identity mapping in the basic GNN layers. For the search algorithm, we use deep-q-learning with epsilon-greedy exploration strategy and reward reshaping. Extensive experiments on real-world datasets show that our generated GNN models outperforms existing manually designed and NAS-based ones.

</p>
</details>

<details><summary><b>Self-Supervised Action-Space Prediction for Automated Driving</b>
<a href="https://arxiv.org/abs/2109.10024">arxiv:2109.10024</a>
&#x1F4C8; 4 <br>
<p>Faris Janjoš, Maxim Dolgov, J. Marius Zöllner</p></summary>
<p>

**Abstract:** Making informed driving decisions requires reliable prediction of other vehicles' trajectories. In this paper, we present a novel learned multi-modal trajectory prediction architecture for automated driving. It achieves kinematically feasible predictions by casting the learning problem into the space of accelerations and steering angles -- by performing action-space prediction, we can leverage valuable model knowledge. Additionally, the dimensionality of the action manifold is lower than that of the state manifold, whose intrinsically correlated states are more difficult to capture in a learned manner. For the purpose of action-space prediction, we present the simple Feed-Forward Action-Space Prediction (FFW-ASP) architecture. Then, we build on this notion and introduce the novel Self-Supervised Action-Space Prediction (SSP-ASP) architecture that outputs future environment context features in addition to trajectories. A key element in the self-supervised architecture is that, based on an observed action history and past context features, future context features are predicted prior to future trajectories. The proposed methods are evaluated on real-world datasets containing urban intersections and roundabouts, and show accurate predictions, outperforming state-of-the-art for kinematically feasible predictions in several prediction metrics.

</p>
</details>

<details><summary><b>Unsupervised Abstract Reasoning for Raven's Problem Matrices</b>
<a href="https://arxiv.org/abs/2109.10011">arxiv:2109.10011</a>
&#x1F4C8; 4 <br>
<p>Tao Zhuo, Qiang Huang, Mohan Kankanhalli</p></summary>
<p>

**Abstract:** Raven's Progressive Matrices (RPM) is highly correlated with human intelligence, and it has been widely used to measure the abstract reasoning ability of humans. In this paper, to study the abstract reasoning capability of deep neural networks, we propose the first unsupervised learning method for solving RPM problems. Since the ground truth labels are not allowed, we design a pseudo target based on the prior constraints of the RPM formulation to approximate the ground truth label, which effectively converts the unsupervised learning strategy into a supervised one. However, the correct answer is wrongly labelled by the pseudo target, and thus the noisy contrast will lead to inaccurate model training. To alleviate this issue, we propose to improve the model performance with negative answers. Moreover, we develop a decentralization method to adapt the feature representation to different RPM problems. Extensive experiments on three datasets demonstrate that our method even outperforms some of the supervised approaches. Our code is available at https://github.com/visiontao/ncd.

</p>
</details>

<details><summary><b>Fast nonlinear risk assessment for autonomous vehicles using learned conditional probabilistic models of agent futures</b>
<a href="https://arxiv.org/abs/2109.09975">arxiv:2109.09975</a>
&#x1F4C8; 4 <br>
<p>Ashkan Jasour, Xin Huang, Allen Wang, Brian C. Williams</p></summary>
<p>

**Abstract:** This paper presents fast non-sampling based methods to assess the risk for trajectories of autonomous vehicles when probabilistic predictions of other agents' futures are generated by deep neural networks (DNNs). The presented methods address a wide range of representations for uncertain predictions including both Gaussian and non-Gaussian mixture models to predict both agent positions and control inputs conditioned on the scene contexts. We show that the problem of risk assessment when Gaussian mixture models (GMMs) of agent positions are learned can be solved rapidly to arbitrary levels of accuracy with existing numerical methods. To address the problem of risk assessment for non-Gaussian mixture models of agent position, we propose finding upper bounds on risk using nonlinear Chebyshev's Inequality and sums-of-squares (SOS) programming; they are both of interest as the former is much faster while the latter can be arbitrarily tight. These approaches only require higher order statistical moments of agent positions to determine upper bounds on risk. To perform risk assessment when models are learned for agent control inputs as opposed to positions, we propagate the moments of uncertain control inputs through the nonlinear motion dynamics to obtain the exact moments of uncertain position over the planning horizon. To this end, we construct deterministic linear dynamical systems that govern the exact time evolution of the moments of uncertain position in the presence of uncertain control inputs. The presented methods are demonstrated on realistic predictions from DNNs trained on the Argoverse and CARLA datasets and are shown to be effective for rapidly assessing the probability of low probability events.

</p>
</details>

<details><summary><b>An Add-On for Empowering Google Forms to be an Automatic Question Generator in Online Assessments</b>
<a href="https://arxiv.org/abs/2110.15220">arxiv:2110.15220</a>
&#x1F4C8; 3 <br>
<p>Pornpat Sirithumgul, Pimpaka Prasertsilp, Lorne Olfman</p></summary>
<p>

**Abstract:** This research suggests an add-on to empower Google Forms to be an automatic machine for generating multiple-choice questions (MCQs) used in online assessments. In this paper, we elaborate an add-on design mainly comprising question-formulating software and data storage. The algorithm as an intellectual mechanism of this software can produce MCQs at an analytical level. In an experiment, we found the MCQs could assess levels of students' knowledge comparably with those generated by human experts. This add-on can be applied generally to formulate MCQs for any rational concepts. With no effort from an instructor at runtime, the add-on can transform a few data instances describing rational concepts to be variety sets of MCQs.

</p>
</details>

<details><summary><b>Towards the Classification of Error-Related Potentials using Riemannian Geometry</b>
<a href="https://arxiv.org/abs/2109.13085">arxiv:2109.13085</a>
&#x1F4C8; 3 <br>
<p>Yichen Tang, Jerry J. Zhang, Paul M. Corballis, Luke E. Hallum</p></summary>
<p>

**Abstract:** The error-related potential (ErrP) is an event-related potential (ERP) evoked by an experimental participant's recognition of an error during task performance. ErrPs, originally described by cognitive psychologists, have been adopted for use in brain-computer interfaces (BCIs) for the detection and correction of errors, and the online refinement of decoding algorithms. Riemannian geometry-based feature extraction and classification is a new approach to BCI which shows good performance in a range of experimental paradigms, but has yet to be applied to the classification of ErrPs. Here, we describe an experiment that elicited ErrPs in seven normal participants performing a visual discrimination task. Audio feedback was provided on each trial. We used multi-channel electroencephalogram (EEG) recordings to classify ErrPs (success/failure), comparing a Riemannian geometry-based method to a traditional approach that computes time-point features. Overall, the Riemannian approach outperformed the traditional approach (78.2% versus 75.9% accuracy, p < 0.05); this difference was statistically significant (p < 0.05) in three of seven participants. These results indicate that the Riemannian approach better captured the features from feedback-elicited ErrPs, and may have application in BCI for error detection and correction.

</p>
</details>

<details><summary><b>Safe Policy Learning through Extrapolation: Application to Pre-trial Risk Assessment</b>
<a href="https://arxiv.org/abs/2109.11679">arxiv:2109.11679</a>
&#x1F4C8; 3 <br>
<p>Eli Ben-Michael, D. James Greiner, Kosuke Imai, Zhichao Jiang</p></summary>
<p>

**Abstract:** Algorithmic recommendations and decisions have become ubiquitous in today's society. Many of these and other data-driven policies, especially in the realm of public policy, are based on known, deterministic rules to ensure their transparency and interpretability. For example, algorithmic pre-trial risk assessments, which serve as our motivating application, provide relatively simple, deterministic classification scores and recommendations to help judges make release decisions. How can we use the data based on existing deterministic policies and learn new and better policies? Unfortunately, prior methods for policy learning are not applicable because they require existing policies to be stochastic rather than deterministic. We develop a robust optimization approach that partially identifies the expected utility of a policy, and then finds an optimal policy by minimizing the worst-case regret. The resulting policy is conservative but has a statistical safety guarantee, allowing the policy-maker to limit the probability of producing a worse outcome than the existing policy. We extend this approach to common and important settings where humans make decisions with the aid of algorithmic recommendations. Lastly, we apply the proposed methodology to a unique field experiment on pre-trial risk assessment instruments. We derive new classification and recommendation rules that retain the transparency and interpretability of the existing instrument while potentially leading to better overall outcomes at a lower cost.

</p>
</details>

<details><summary><b>wsGAT: Weighted and Signed Graph Attention Networks for Link Prediction</b>
<a href="https://arxiv.org/abs/2109.11519">arxiv:2109.11519</a>
&#x1F4C8; 3 <br>
<p>Marco Grassia, Giuseppe Mangioni</p></summary>
<p>

**Abstract:** Graph Neural Networks (GNNs) have been widely used to learn representations on graphs and tackle many real-world problems from a wide range of domains. In this paper we propose wsGAT, an extension of the Graph Attention Network (GAT) layers, meant to address the lack of GNNs that can handle graphs with signed and weighted links, which are ubiquitous, for instance, in trust and correlation networks. We first evaluate the performance of our proposal by comparing against GCNII in the weighed link prediction task, and against SGCN in the link sign prediction task. After that, we combine the two tasks and show their performance on predicting the signed weight of links, and their existence. Our results on real-world networks show that models with wsGAT layers outperform the ones with GCNII and SGCN layers, and that there is no loss in performance when signed weights are predicted.

</p>
</details>

<details><summary><b>Tecnologica cosa: Modeling Storyteller Personalities in Boccaccio's Decameron</b>
<a href="https://arxiv.org/abs/2109.10506">arxiv:2109.10506</a>
&#x1F4C8; 3 <br>
<p>A. Feder Cooper, Maria Antoniak, Christopher De Sa, Marilyn Migiel, David Mimno</p></summary>
<p>

**Abstract:** We explore Boccaccio's Decameron to see how digital humanities tools can be used for tasks that have limited data in a language no longer in contemporary use: medieval Italian. We focus our analysis on the question: Do the different storytellers in the text exhibit distinct personalities? To answer this question, we curate and release a dataset based on the authoritative edition of the text. We use supervised classification methods to predict storytellers based on the stories they tell, confirming the difficulty of the task, and demonstrate that topic modeling can extract thematic storyteller "profiles."

</p>
</details>

<details><summary><b>Fairness without Imputation: A Decision Tree Approach for Fair Prediction with Missing Values</b>
<a href="https://arxiv.org/abs/2109.10431">arxiv:2109.10431</a>
&#x1F4C8; 3 <br>
<p>Haewon Jeong, Hao Wang, Flavio P. Calmon</p></summary>
<p>

**Abstract:** We investigate the fairness concerns of training a machine learning model using data with missing values. Even though there are a number of fairness intervention methods in the literature, most of them require a complete training set as input. In practice, data can have missing values, and data missing patterns can depend on group attributes (e.g. gender or race). Simply applying off-the-shelf fair learning algorithms to an imputed dataset may lead to an unfair model. In this paper, we first theoretically analyze different sources of discrimination risks when training with an imputed dataset. Then, we propose an integrated approach based on decision trees that does not require a separate process of imputation and learning. Instead, we train a tree with missing incorporated as attribute (MIA), which does not require explicit imputation, and we optimize a fairness-regularized objective function. We demonstrate that our approach outperforms existing fairness intervention methods applied to an imputed dataset, through several experiments on real-world datasets.

</p>
</details>

<details><summary><b>RETRONLU: Retrieval Augmented Task-Oriented Semantic Parsing</b>
<a href="https://arxiv.org/abs/2109.10410">arxiv:2109.10410</a>
&#x1F4C8; 3 <br>
<p>Vivek Gupta, Akshat Shrivastava, Adithya Sagar, Armen Aghajanyan, Denis Savenkov</p></summary>
<p>

**Abstract:** While large pre-trained language models accumulate a lot of knowledge in their parameters, it has been demonstrated that augmenting it with non-parametric retrieval-based memory has a number of benefits from accuracy improvements to data efficiency for knowledge-focused tasks, such as question answering. In this paper, we are applying retrieval-based modeling ideas to the problem of multi-domain task-oriented semantic parsing for conversational assistants. Our approach, RetroNLU, extends a sequence-to-sequence model architecture with a retrieval component, used to fetch existing similar examples and provide them as an additional input to the model. In particular, we analyze two settings, where we augment an input with (a) retrieved nearest neighbor utterances (utterance-nn), and (b) ground-truth semantic parses of nearest neighbor utterances (semparse-nn). Our technique outperforms the baseline method by 1.5% absolute macro-F1, especially at the low resource setting, matching the baseline model accuracy with only 40% of the data. Furthermore, we analyze the nearest neighbor retrieval component's quality, model sensitivity and break down the performance for semantic parses of different utterance complexity.

</p>
</details>

<details><summary><b>Learned Benchmarks for Subseasonal Forecasting</b>
<a href="https://arxiv.org/abs/2109.10399">arxiv:2109.10399</a>
&#x1F4C8; 3 <br>
<p>Soukayna Mouatadid, Paulo Orenstein, Genevieve Flaspohler, Miruna Oprescu, Judah Cohen, Franklyn Wang, Sean Knight, Maria Geogdzhayeva, Sam Levang, Ernest Fraenkel, Lester Mackey</p></summary>
<p>

**Abstract:** We develop a subseasonal forecasting toolkit of simple learned benchmark models that outperform both operational practice and state-of-the-art machine learning and deep learning methods. Our new models include (a) Climatology++, an adaptive alternative to climatology that, for precipitation, is 9% more accurate and 250% more skillful than the United States operational Climate Forecasting System (CFSv2); (b) CFSv2++, a learned CFSv2 correction that improves temperature and precipitation accuracy by 7-8% and skill by 50-275%; and (c) Persistence++, an augmented persistence model that combines CFSv2 forecasts with lagged measurements to improve temperature and precipitation accuracy by 6-9% and skill by 40-130%. Across the contiguous U.S., our Climatology++, CFSv2++, and Persistence++ toolkit consistently outperforms standard meteorological baselines, state-of-the-art machine and deep learning methods, and the European Centre for Medium-Range Weather Forecasts ensemble. Overall, we find that augmenting traditional forecasting approaches with learned enhancements yields an effective and computationally inexpensive strategy for building the next generation of subseasonal forecasting benchmarks.

</p>
</details>

<details><summary><b>Data-driven controllers and the need for perception systems in underwater manipulation</b>
<a href="https://arxiv.org/abs/2109.10327">arxiv:2109.10327</a>
&#x1F4C8; 3 <br>
<p>James P. Oubre, Ignacio Carlucho, Corina Barbalata</p></summary>
<p>

**Abstract:** The underwater environment poses a complex problem for developing autonomous capabilities for Underwater Vehicle Manipulator Systems (UVMSs). The modeling of UVMSs is a complicated and costly process due to the highly nonlinear dynamics and the presence of unknown hydrodynamical effects. This is aggravated in tasks where the manipulation of objects is necessary, as this may not only introduce external disturbances that can lead to a fast degradation of the control system performance, but also requires the coordinating with a vision system for the correct grasping and operation of the object. In this article, we introduce a control strategy for UVMSs working with unknown payloads. The proposed control strategy is based on a data-driven optimal controller. We present a number of experimental results showing the benefits of the proposed strategy. Furthermore, we include a discussion regarding the visual perception requirements for the UVMS in order to achieve full autonomy in underwater manipulation tasks of unknown payloads.

</p>
</details>

<details><summary><b>Consistency of spectral clustering for directed network community detection</b>
<a href="https://arxiv.org/abs/2109.10319">arxiv:2109.10319</a>
&#x1F4C8; 3 <br>
<p>Huan Qing, Jingli Wang</p></summary>
<p>

**Abstract:** Directed networks appear in various areas, such as biology, sociology, physiology and computer science. In this paper, we construct a spectral clustering method based on the singular decomposition of the adjacency matrix to detect community in directed stochastic block model (DiSBM). By considering a sparsity parameter, under mild conditions, we show the proposed approach can consistently recover hidden row and column communities for different scaling of degrees. By considering the degree heterogeneity of both row and column nodes, we further modify the proposed method and establish a theoretical framework for directed degree corrected stochastic block model (DiDCSBM), and also show the consistency of the modified method for this case. Our theoretical results under DiSBM and DiDCSBM provide some innovations on some special directed networks, such as directed network with balanced clusters, directed network with nodes enjoying similar degrees, and the directed Erdös-Rényi graph. Furthermore, the theoretical results under DiDCSBM are consistent with those under DiSBM.

</p>
</details>

<details><summary><b>Multiblock-Networks: A Neural Network Analog to Component Based Methods for Multi-Source Data</b>
<a href="https://arxiv.org/abs/2109.10279">arxiv:2109.10279</a>
&#x1F4C8; 3 <br>
<p>Anna Jenul, Stefan Schrunner, Runar Helin, Kristian Hovde Liland, Cecilia Marie Futsæther, Oliver Tomic</p></summary>
<p>

**Abstract:** Training predictive models on datasets from multiple sources is a common, yet challenging setup in applied machine learning. Even though model interpretation has attracted more attention in recent years, many modeling approaches still focus mainly on performance. To further improve the interpretability of machine learning models, we suggest the adoption of concepts and tools from the well-established framework of component based multiblock analysis, also known as chemometrics. Nevertheless, artificial neural networks provide greater flexibility in model architecture and thus, often deliver superior predictive performance. In this study, we propose a setup to transfer the concepts of component based statistical models, including multiblock variants of principal component regression and partial least squares regression, to neural network architectures. Thereby, we combine the flexibility of neural networks with the concepts for interpreting block relevance in multiblock methods. In two use cases we demonstrate how the concept can be implemented in practice, and compare it to both common feed-forward neural networks without blocks, as well as statistical component based multiblock methods. Our results underline that multiblock networks allow for basic model interpretation while matching the performance of ordinary feed-forward neural networks.

</p>
</details>

<details><summary><b>Uncertainty Toolbox: an Open-Source Library for Assessing, Visualizing, and Improving Uncertainty Quantification</b>
<a href="https://arxiv.org/abs/2109.10254">arxiv:2109.10254</a>
&#x1F4C8; 3 <br>
<p>Youngseog Chung, Ian Char, Han Guo, Jeff Schneider, Willie Neiswanger</p></summary>
<p>

**Abstract:** With increasing deployment of machine learning systems in various real-world tasks, there is a greater need for accurate quantification of predictive uncertainty. While the common goal in uncertainty quantification (UQ) in machine learning is to approximate the true distribution of the target data, many works in UQ tend to be disjoint in the evaluation metrics utilized, and disparate implementations for each metric lead to numerical results that are not directly comparable across different works. To address this, we introduce Uncertainty Toolbox, an open-source python library that helps to assess, visualize, and improve UQ. Uncertainty Toolbox additionally provides pedagogical resources, such as a glossary of key terms and an organized collection of key paper references. We hope that this toolbox is useful for accelerating and uniting research efforts in uncertainty in machine learning.

</p>
</details>

<details><summary><b>Adaptive Reliability Analysis for Multi-fidelity Models using a Collective Learning Strategy</b>
<a href="https://arxiv.org/abs/2109.10219">arxiv:2109.10219</a>
&#x1F4C8; 3 <br>
<p>Chi Zhang, Chaolin Song, Abdollah Shafieezadeh</p></summary>
<p>

**Abstract:** In many fields of science and engineering, models with different fidelities are available. Physical experiments or detailed simulations that accurately capture the behavior of the system are regarded as high-fidelity models with low model uncertainty, however, they are expensive to run. On the other hand, simplified physical experiments or numerical models are seen as low-fidelity models that are cheaper to evaluate. Although low-fidelity models are often not suitable for direct use in reliability analysis due to their low accuracy, they can offer information about the trend of the high-fidelity model thus providing the opportunity to explore the design space at a low cost. This study presents a new approach called adaptive multi-fidelity Gaussian process for reliability analysis (AMGPRA). Contrary to selecting training points and information sources in two separate stages as done in state-of-the-art mfEGRA method, the proposed approach finds the optimal training point and information source simultaneously using the novel collective learning function (CLF). CLF is able to assess the global impact of a candidate training point from an information source and it accommodates any learning function that satisfies a certain profile. In this context, CLF provides a new direction for quantifying the impact of new training points and can be easily extended with new learning functions to adapt to different reliability problems. The performance of the proposed method is demonstrated by three mathematical examples and one engineering problem concerning the wind reliability of transmission towers. It is shown that the proposed method achieves similar or higher accuracy with reduced computational costs compared to state-of-the-art single and multi-fidelity methods. A key application of AMGPRA is high-fidelity fragility modeling using complex and costly physics-based computational models.

</p>
</details>

<details><summary><b>Shape Inference and Grammar Induction for Example-based Procedural Generation</b>
<a href="https://arxiv.org/abs/2109.10217">arxiv:2109.10217</a>
&#x1F4C8; 3 <br>
<p>Gillis Hermans, Thomas Winters, Luc De Raedt</p></summary>
<p>

**Abstract:** Designers increasingly rely on procedural generation for automatic generation of content in various industries. These techniques require extensive knowledge of the desired content, and about how to actually implement such procedural methods. Algorithms for learning interpretable generative models from example content could alleviate both difficulties. We propose SIGI, a novel method for inferring shapes and inducing a shape grammar from grid-based 3D building examples. This interpretable grammar is well-suited for co-creative design. Applied to Minecraft buildings, we show how the shape grammar can be used to automatically generate new buildings in a similar style.

</p>
</details>

<details><summary><b>Oriented Object Detection in Aerial Images Based on Area Ratio of Parallelogram</b>
<a href="https://arxiv.org/abs/2109.10187">arxiv:2109.10187</a>
&#x1F4C8; 3 <br>
<p>Xinyi Yu, Mi Lin, Jiangping Lu, Linlin Ou</p></summary>
<p>

**Abstract:** Oriented object detection is a challenging task in aerial images since the objects in aerial images are displayed in arbitrary directions and are frequently densely packed. The mainstream detectors describe rotating objects using a five-parament or eight-parament representations, which suffer from representation ambiguity for orientated object definition. In this paper, we propose a novel representation method based on area ratio of parallelogram, called ARP. Specifically, ARP regresses the minimum bounding rectangle of the oriented object and three area ratios. Three area ratios include the area ratio of a directed object to the smallest circumscribed rectangle and two parallelograms to the minimum circumscribed rectangle. It simplifies offset learning and eliminates the issue of angular periodicity or label point sequences for oriented objects. To further remedy the confusion issue of nearly horizontal objects, the area ratio between the object and its minimal circumscribed rectangle is employed to guide the selection of horizontal or oriented detection for each object. Moreover, the rotated efficient Intersection over Union (R-EIoU) loss with horizontal bounding box and three area ratios are designed to optimize the bounding box regression for rotating objects. Experimental results on remote sensing datasets, including HRSC2016, DOTA, and UCAS-AOD, show that our method achieves superior detection performance than many state-of-the-art approaches.

</p>
</details>

<details><summary><b>Long-Term Exploration in Persistent MDPs</b>
<a href="https://arxiv.org/abs/2109.10173">arxiv:2109.10173</a>
&#x1F4C8; 3 <br>
<p>Leonid Ugadiarov, Alexey Skrynnik, Aleksandr I. Panov</p></summary>
<p>

**Abstract:** Exploration is an essential part of reinforcement learning, which restricts the quality of learned policy. Hard-exploration environments are defined by huge state space and sparse rewards. In such conditions, an exhaustive exploration of the environment is often impossible, and the successful training of an agent requires a lot of interaction steps. In this paper, we propose an exploration method called Rollback-Explore (RbExplore), which utilizes the concept of the persistent Markov decision process, in which agents during training can roll back to visited states. We test our algorithm in the hard-exploration Prince of Persia game, without rewards and domain knowledge. At all used levels of the game, our agent outperforms or shows comparable results with state-of-the-art curiosity methods with knowledge-based intrinsic motivation: ICM and RND. An implementation of RbExplore can be found at https://github.com/cds-mipt/RbExplore.

</p>
</details>

<details><summary><b>Learning low-degree functions from a logarithmic number of random queries</b>
<a href="https://arxiv.org/abs/2109.10162">arxiv:2109.10162</a>
&#x1F4C8; 3 <br>
<p>Alexandros Eskenazis, Paata Ivanisvili</p></summary>
<p>

**Abstract:** We prove that every bounded function $f:\{-1,1\}^n\to[-1,1]$ of degree at most $d$ can be learned with $L_2$-accuracy $\varepsilon$ and confidence $1-δ$ from $\log(\tfrac{n}δ)\,\varepsilon^{-d-1} C^{d^{3/2}\sqrt{\log d}}$ random queries, where $C>1$ is a universal finite constant.

</p>
</details>

<details><summary><b>NADE: A Benchmark for Robust Adverse Drug Events Extraction in Face of Negations</b>
<a href="https://arxiv.org/abs/2109.10080">arxiv:2109.10080</a>
&#x1F4C8; 3 <br>
<p>Simone Scaboro, Beatrice Portelli, Emmanuele Chersoni, Enrico Santus, Giuseppe Serra</p></summary>
<p>

**Abstract:** Adverse Drug Event (ADE) extraction models can rapidly examine large collections of social media texts, detecting mentions of drug-related adverse reactions and trigger medical investigations. However, despite the recent advances in NLP, it is currently unknown if such models are robust in face of negation, which is pervasive across language varieties.
  In this paper we evaluate three state-of-the-art systems, showing their fragility against negation, and then we introduce two possible strategies to increase the robustness of these models: a pipeline approach, relying on a specific component for negation detection; an augmentation of an ADE extraction dataset to artificially create negated samples and further train the models.
  We show that both strategies bring significant increases in performance, lowering the number of spurious entities predicted by the models. Our dataset and code will be publicly released to encourage research on the topic.

</p>
</details>

<details><summary><b>Learning Interpretable Concept Groups in CNNs</b>
<a href="https://arxiv.org/abs/2109.10078">arxiv:2109.10078</a>
&#x1F4C8; 3 <br>
<p>Saurabh Varshneya, Antoine Ledent, Robert A. Vandermeulen, Yunwen Lei, Matthias Enders, Damian Borth, Marius Kloft</p></summary>
<p>

**Abstract:** We propose a novel training methodology -- Concept Group Learning (CGL) -- that encourages training of interpretable CNN filters by partitioning filters in each layer into concept groups, each of which is trained to learn a single visual concept. We achieve this through a novel regularization strategy that forces filters in the same group to be active in similar image regions for a given layer. We additionally use a regularizer to encourage a sparse weighting of the concept groups in each layer so that a few concept groups can have greater importance than others. We quantitatively evaluate CGL's model interpretability using standard interpretability evaluation techniques and find that our method increases interpretability scores in most cases. Qualitatively we compare the image regions that are most active under filters learned using CGL versus filters learned without CGL and find that CGL activation regions more strongly concentrate around semantically relevant features.

</p>
</details>

<details><summary><b>Scale-aware direct monocular odometry</b>
<a href="https://arxiv.org/abs/2109.10077">arxiv:2109.10077</a>
&#x1F4C8; 3 <br>
<p>Carlos Campos, Juan D. Tardós</p></summary>
<p>

**Abstract:** We present a framework for direct monocular odometry based on depth prediction from a deep neural network. In contrast with existing methods where depth information is only partially exploited, we formulate a novel depth prediction residual which allows us to incorporate multi-view depth information. In addition, we propose to use a truncated robust cost function which prevents considering inconsistent depth estimations. The photometric and depth-prediction measurements are integrated in a tightly-coupled optimization leading to a scale-aware monocular system which does not accumulate scale drift. We demonstrate the validity of our proposal evaluating it on the KITTI odometry dataset and comparing it with state-of-the-art monocular and stereo SLAM systems. Experiments show that our proposal largely outperforms classic monocular SLAM, being 5 to 9 times more precise, with an accuracy which is closer to that of stereo systems.

</p>
</details>

<details><summary><b>Online Multi-horizon Transaction Metric Estimation with Multi-modal Learning in Payment Networks</b>
<a href="https://arxiv.org/abs/2109.10020">arxiv:2109.10020</a>
&#x1F4C8; 3 <br>
<p>Chin-Chia Michael Yeh, Zhongfang Zhuang, Junpeng Wang, Yan Zheng, Javid Ebrahimi, Ryan Mercer, Liang Wang, Wei Zhang</p></summary>
<p>

**Abstract:** Predicting metrics associated with entities' transnational behavior within payment processing networks is essential for system monitoring. Multivariate time series, aggregated from the past transaction history, can provide valuable insights for such prediction. The general multivariate time series prediction problem has been well studied and applied across several domains, including manufacturing, medical, and entomology. However, new domain-related challenges associated with the data such as concept drift and multi-modality have surfaced in addition to the real-time requirements of handling the payment transaction data at scale. In this work, we study the problem of multivariate time series prediction for estimating transaction metrics associated with entities in the payment transaction database. We propose a model with five unique components to estimate the transaction metrics from multi-modality data. Four of these components capture interaction, temporal, scale, and shape perspectives, and the fifth component fuses these perspectives together. We also propose a hybrid offline/online training scheme to address concept drift in the data and fulfill the real-time requirements. Combining the estimation model with a graphical user interface, the prototype transaction metric estimation system has demonstrated its potential benefit as a tool for improving a payment processing company's system monitoring capability.

</p>
</details>

<details><summary><b>Automated segmentation and extraction of posterior eye segment using OCT scans</b>
<a href="https://arxiv.org/abs/2109.10000">arxiv:2109.10000</a>
&#x1F4C8; 3 <br>
<p>Bilal Hassan, Taimur Hassan, Ramsha Ahmed, Shiyin Qin, Naoufel Werghi</p></summary>
<p>

**Abstract:** This paper proposes an automated method for the segmentation and extraction of the posterior segment of the human eye, including the vitreous, retina, choroid, and sclera compartments, using multi-vendor optical coherence tomography (OCT) scans. The proposed method works in two phases. First extracts the retinal pigment epithelium (RPE) layer by applying the adaptive thresholding technique to identify the retina-choroid junction. Then, it exploits the structure tensor guided approach to extract the inner limiting membrane (ILM) and the choroidal stroma (CS) layers, locating the vitreous-retina and choroid-sclera junctions in the candidate OCT scan. Furthermore, these three junction boundaries are utilized to conduct posterior eye compartmentalization effectively for both healthy and disease eye OCT scans. The proposed framework is evaluated over 1000 OCT scans, where it obtained the mean intersection over union (IoU) and mean Dice similarity coefficient (DSC) scores of 0.874 and 0.930, respectively.

</p>
</details>

<details><summary><b>Learning Adaptive Control for SE(3) Hamiltonian Dynamics</b>
<a href="https://arxiv.org/abs/2109.09974">arxiv:2109.09974</a>
&#x1F4C8; 3 <br>
<p>Thai Duong, Nikolay Atanasov</p></summary>
<p>

**Abstract:** Fast adaptive control is a critical component for reliable robot autonomy in rapidly changing operational conditions. While a robot dynamics model may be obtained from first principles or learned from data, updating its parameters is often too slow for online adaptation to environment changes. This motivates the use of machine learning techniques to learn disturbance descriptors from trajectory data offline as well as the design of adaptive control to estimate and compensate the disturbances online. This paper develops adaptive geometric control for rigid-body systems, such as ground, aerial, and underwater vehicles, that satisfy Hamilton's equations of motion over the SE(3) manifold. Our design consists of an offline system identification stage, followed by an online adaptive control stage. In the first stage, we learn a Hamiltonian model of the system dynamics using a neural ordinary differential equation (ODE) network trained from state-control trajectory data with different disturbance realizations. The disturbances are modeled as a linear combination of nonlinear descriptors. In the second stage, we design a trajectory tracking controller with disturbance compensation from an energy-based perspective. An adaptive control law is employed to adjust the disturbance model online proportional to the geometric tracking errors on the SE(3) manifold. We verify our adaptive geometric controller for trajectory tracking on a fully-actuated pendulum and an under-actuated quadrotor.

</p>
</details>

<details><summary><b>Towards The Automatic Coding of Medical Transcripts to Improve Patient-Centered Communication</b>
<a href="https://arxiv.org/abs/2109.10514">arxiv:2109.10514</a>
&#x1F4C8; 2 <br>
<p>Gilchan Park, Julia Taylor Rayz, Cleveland G. Shields</p></summary>
<p>

**Abstract:** This paper aims to provide an approach for automatic coding of physician-patient communication transcripts to improve patient-centered communication (PCC). PCC is a central part of high-quality health care. To improve PCC, dialogues between physicians and patients have been recorded and tagged with predefined codes. Trained human coders have manually coded the transcripts. Since it entails huge labor costs and poses possible human errors, automatic coding methods should be considered for efficiency and effectiveness. We adopted three machine learning algorithms (Naïve Bayes, Random Forest, and Support Vector Machine) to categorize lines in transcripts into corresponding codes. The result showed that there is evidence to distinguish the codes, and this is considered to be sufficient for training of human annotators.

</p>
</details>

<details><summary><b>Classification with Nearest Disjoint Centroids</b>
<a href="https://arxiv.org/abs/2109.10436">arxiv:2109.10436</a>
&#x1F4C8; 2 <br>
<p>Nicolas Fraiman, Zichao Li</p></summary>
<p>

**Abstract:** In this paper, we develop a new classification method based on nearest centroid, and it is called the nearest disjoint centroid classifier. Our method differs from the nearest centroid classifier in the following two aspects: (1) the centroids are defined based on disjoint subsets of features instead of all the features, and (2) the distance is induced by the dimensionality-normalized norm instead of the Euclidean norm. We provide a few theoretical results regarding our method. In addition, we propose a simple algorithm based on adapted k-means clustering that can find the disjoint subsets of features used in our method, and extend the algorithm to perform feature selection. We evaluate and compare the performance of our method to other closely related classifiers on both simulated data and real-world gene expression datasets. The results demonstrate that our method is able to outperform other competing classifiers by having smaller misclassification rates and/or using fewer features in various settings and situations.

</p>
</details>

<details><summary><b>Robust marginalization of baryonic effects for cosmological inference at the field level</b>
<a href="https://arxiv.org/abs/2109.10360">arxiv:2109.10360</a>
&#x1F4C8; 2 <br>
<p>Francisco Villaescusa-Navarro, Shy Genel, Daniel Angles-Alcazar, David N. Spergel, Yin Li, Benjamin Wandelt, Leander Thiele, Andrina Nicola, Jose Manuel Zorrilla Matilla, Helen Shao, Sultan Hassan, Desika Narayanan, Romeel Dave, Mark Vogelsberger</p></summary>
<p>

**Abstract:** We train neural networks to perform likelihood-free inference from $(25\,h^{-1}{\rm Mpc})^2$ 2D maps containing the total mass surface density from thousands of hydrodynamic simulations of the CAMELS project. We show that the networks can extract information beyond one-point functions and power spectra from all resolved scales ($\gtrsim 100\,h^{-1}{\rm kpc}$) while performing a robust marginalization over baryonic physics at the field level: the model can infer the value of $Ω_{\rm m} (\pm 4\%)$ and $σ_8 (\pm 2.5\%)$ from simulations completely different to the ones used to train it.

</p>
</details>

<details><summary><b>Discovery of temporal structure intricacy in arterial blood pressure waveforms representing acuity of liver transplant and forecasting short term surgical outcome via unsupervised manifold learning</b>
<a href="https://arxiv.org/abs/2109.10258">arxiv:2109.10258</a>
&#x1F4C8; 2 <br>
<p>Shen-Chih Wang, Chien-Kun Ting, Cheng-Yen Chen, Chin-Su Liu, Niang-Cheng Lin, Che-Chuan Loon, Hau-Tieng Wu, Yu-Ting Lin</p></summary>
<p>

**Abstract:** Background: Arterial blood pressure (ABP) waveform evolves across each consecutive pulse during the liver transplant surgery. We hypothesized that the quantification of the waveform evolution reflects 1) the acuity of the recipient undergoing liver transplant and 2) the intraoperative dynamics that forecasts short-term surgical outcomes. Methods: In this prospective observational single cohort study on living donor liver transplant surgery, we extracted the waveform morphological evolution from the ABP data with the unsupervised manifold learning waveform analysis. Two quantitative indices, trend movement and fluctuation movement, were developed to represent the slow-varying and fast-varying dynamics respectively. We investigated the associations with the liver disease acuity represented with the Model for End-Stage Liver Disease (MELD) score and the primary outcomes, the early allograft failure (EAF), as well as the recently developed EAF scores, including the Liver Graft Assessment Following Transplantation (L-GrAFT) score, the Early Allograft Failure Simplified Estimation (EASE) score, and the Model for Early Allograft Function (MEAF) score. Results: Sixty recipients were enrolled. The presurgical trend movement was correlated with the MELD scores. It decreased in the anhepatic phase. The neohepatic trend movement correlated with the L-GrAFT scores, the EASE score, and the MEAF score. Regarding the constituent of the EAF scores, the trend movement most correlated with the postoperative day 7 bilirubin. Conclusions: The ABP waveform evolution intricacy in the presurgical phase reflects recipients' acuity condition while that in the neohepatic phase reveal the short-term surgical outcome calculated from laboratory data in postoperative day 7-10. The waveform evolution reflects the intraoperative contribution to the early outcome.

</p>
</details>

<details><summary><b>Off-line approximate dynamic programming for the vehicle routing problem with stochastic customers and demands via decentralized decision-making</b>
<a href="https://arxiv.org/abs/2109.10200">arxiv:2109.10200</a>
&#x1F4C8; 2 <br>
<p>Mohsen Dastpak, Fausto Errico</p></summary>
<p>

**Abstract:** This paper studies a stochastic variant of the vehicle routing problem (VRP) where both customer locations and demands are uncertain. In particular, potential customers are not restricted to a predefined customer set but are continuously spatially distributed in a given service area. The objective is to maximize the served demands while fulfilling vehicle capacities and time restrictions. We call this problem the VRP with stochastic customers and demands (VRPSCD). For this problem, we first propose a Markov Decision Process (MDP) formulation representing the classical centralized decision-making perspective where one decision-maker establishes the routes of all vehicles. While the resulting formulation turns out to be intractable, it provides us with the ground to develop a new MDP formulation of the VRPSCD representing a decentralized decision-making framework, where vehicles autonomously establish their own routes. This new formulation allows us to develop several strategies to reduce the dimension of the state and action spaces, resulting in a considerably more tractable problem. We solve the decentralized problem via Reinforcement Learning, and in particular, we develop a Q-learning algorithm featuring state-of-the-art acceleration techniques such as Replay Memory and Double Q Network. Computational results show that our method considerably outperforms two commonly adopted benchmark policies (random and heuristic). Moreover, when comparing with existing literature, we show that our approach can compete with specialized methods developed for the particular case of the VRPSCD where customer locations and expected demands are known in advance. Finally, we show that the value functions and policies obtained by our algorithm can be easily embedded in Rollout algorithms, thus further improving their performances.

</p>
</details>

<details><summary><b>Design and implementation of a parsimonious neuromorphic PID for onboard altitude control for MAVs using neuromorphic processors</b>
<a href="https://arxiv.org/abs/2109.10199">arxiv:2109.10199</a>
&#x1F4C8; 2 <br>
<p>Stein Stroobants, Julien Dupeyroux, Guido de Croon</p></summary>
<p>

**Abstract:** The great promises of neuromorphic sensing and processing for robotics have led researchers and engineers to investigate novel models for robust and reliable control of autonomous robots (navigation, obstacle detection and avoidance, etc.), especially for quadrotors in challenging contexts such as drone racing and aggressive maneuvers. Using spiking neural networks, these models can be run on neuromorphic hardware to benefit from outstanding update rates and high energy efficiency. Yet, low-level controllers are often neglected and remain outside of the neuromorphic loop. Designing low-level neuromorphic controllers is crucial to remove the standard PID, and therefore benefit from all the advantages of closing the neuromorphic loop. In this paper, we propose a parsimonious and adjustable neuromorphic PID controller, endowed with a minimal number of 93 neurons sparsely connected to achieve autonomous, onboard altitude control of a quadrotor equipped with Intel's Loihi neuromorphic chip. We successfully demonstrate the robustness of our proposed network in a set of experiments where the quadrotor is requested to reach a target altitude from take-off. Our results confirm the suitability of such low-level neuromorphic controllers, ultimately with a very high update frequency.

</p>
</details>

<details><summary><b>Distributed Mission Planning of Complex Tasks for Heterogeneous Multi-Robot Teams</b>
<a href="https://arxiv.org/abs/2109.10106">arxiv:2109.10106</a>
&#x1F4C8; 2 <br>
<p>Barbara Arbanas Ferreira, Tamara Petrović, Stjepan Bogdan</p></summary>
<p>

**Abstract:** In this paper, we propose a distributed multi-stage optimization method for planning complex missions for heterogeneous multi-robot teams. This class of problems involves tasks that can be executed in different ways and are associated with cross-schedule dependencies that constrain the schedules of the different robots in the system. The proposed approach involves a multi-objective heuristic search of the mission, represented as a hierarchical tree that defines the mission goal. This procedure outputs several favorable ways to fulfill the mission, which directly feed into the next stage of the method. We propose a distributed metaheuristic based on evolutionary computation to allocate tasks and generate schedules for the set of chosen decompositions. The method is evaluated in a simulation setup of an automated greenhouse use case, where we demonstrate the method's ability to adapt the planning strategy depending on the available robots and the given optimization criteria.

</p>
</details>

<details><summary><b>A Novel Structured Natural Gradient Descent for Deep Learning</b>
<a href="https://arxiv.org/abs/2109.10100">arxiv:2109.10100</a>
&#x1F4C8; 2 <br>
<p>Weihua Liu, Xiabi Liu</p></summary>
<p>

**Abstract:** Natural gradient descent (NGD) provided deep insights and powerful tools to deep neural networks. However the computation of Fisher information matrix becomes more and more difficult as the network structure turns large and complex. This paper proposes a new optimization method whose main idea is to accurately replace the natural gradient optimization by reconstructing the network. More specifically, we reconstruct the structure of the deep neural network, and optimize the new network using traditional gradient descent (GD). The reconstructed network achieves the effect of the optimization way with natural gradient descent. Experimental results show that our optimization method can accelerate the convergence of deep network models and achieve better performance than GD while sharing its computational simplicity.

</p>
</details>

<details><summary><b>CONQUER: Contextual Query-aware Ranking for Video Corpus Moment Retrieval</b>
<a href="https://arxiv.org/abs/2109.10016">arxiv:2109.10016</a>
&#x1F4C8; 2 <br>
<p>Zhijian Hou, Chong-Wah Ngo, Wing Kwong Chan</p></summary>
<p>

**Abstract:** This paper tackles a recently proposed Video Corpus Moment Retrieval task. This task is essential because advanced video retrieval applications should enable users to retrieve a precise moment from a large video corpus. We propose a novel CONtextual QUery-awarE Ranking~(CONQUER) model for effective moment localization and ranking. CONQUER explores query context for multi-modal fusion and representation learning in two different steps. The first step derives fusion weights for the adaptive combination of multi-modal video content. The second step performs bi-directional attention to tightly couple video and query as a single joint representation for moment localization. As query context is fully engaged in video representation learning, from feature fusion to transformation, the resulting feature is user-centered and has a larger capacity in capturing multi-modal signals specific to query. We conduct studies on two datasets, TVR for closed-world TV episodes and DiDeMo for open-world user-generated videos, to investigate the potential advantages of fusing video and query online as a joint representation for moment retrieval.

</p>
</details>

<details><summary><b>Signal Classification using Smooth Coefficients of Multiple wavelets</b>
<a href="https://arxiv.org/abs/2109.09988">arxiv:2109.09988</a>
&#x1F4C8; 2 <br>
<p>Paul Grant, Md Zahidul Islam</p></summary>
<p>

**Abstract:** Classification of time series signals has become an important construct and has many practical applications. With existing classifiers we may be able to accurately classify signals, however that accuracy may decline if using a reduced number of attributes. Transforming the data then undertaking reduction in dimensionality may improve the quality of the data analysis, decrease time required for classification and simplify models. We propose an approach, which chooses suitable wavelets to transform the data, then combines the output from these transforms to construct a dataset to then apply ensemble classifiers to. We demonstrate this on different data sets, across different classifiers and use differing evaluation methods. Our experimental results demonstrate the effectiveness of the proposed technique, compared to the approaches that use either raw signal data or a single wavelet transform.

</p>
</details>

<details><summary><b>Rebuilding Trust: Queer in AI Approach to Artificial Intelligence Risk Management</b>
<a href="https://arxiv.org/abs/2110.09271">arxiv:2110.09271</a>
&#x1F4C8; 1 <br>
<p> Ashwin, William Agnew, Juan Pajaro, Arjun Subramonian</p></summary>
<p>

**Abstract:** AI, machine learning, and data science methods are already pervasive in our society and technology, affecting all of our lives in many subtle ways. Trustworthy AI has become an important topic because trust in AI systems and their creators has been lost, or was never present in the first place. Researchers, corporations, and governments have long and painful histories of excluding marginalized groups from technology development, deployment, and oversight. As a direct result of this exclusion, these technologies have long histories of being less useful or even harmful to minoritized groups. This infuriating history illustrates that industry cannot be trusted to self-regulate and why trust in commercial AI systems and development has been lost. We argue that any AI development, deployment, and monitoring framework that aspires to trust must incorporate both feminist, non-exploitative participatory design principles and strong, outside, and continual monitoring and testing. We additionally explain the importance of considering aspects of trustworthiness beyond just transparency, fairness, and accountability, specifically, to consider justice and shifting power to the people and disempowered as core values to any trustworthy AI system. Creating trustworthy AI starts by funding, supporting, and empowering groups like Queer in AI so the field of AI has the diversity and inclusion to credibly and effectively develop trustworthy AI. Through our years of work and advocacy, we have developed expert knowledge around questions of if and how gender, sexuality, and other aspects of identity should be used in AI systems and how harms along these lines should be mitigated. Based on this, we discuss a gendered approach to AI, and further propose a queer epistemology and analyze the benefits it can bring to AI.

</p>
</details>

<details><summary><b>EEG Signal Processing using Wavelets for Accurate Seizure Detection through Cost Sensitive Data Mining</b>
<a href="https://arxiv.org/abs/2109.13818">arxiv:2109.13818</a>
&#x1F4C8; 1 <br>
<p>Paul Grant, Md Zahidul Islam</p></summary>
<p>

**Abstract:** Epilepsy is one of the most common and yet diverse set of chronic neurological disorders. This excessive or synchronous neuronal activity is termed seizure. Electroencephalogram signal processing plays a significant role in detection and prediction of epileptic seizures. In this paper we introduce an approach that relies upon the properties of wavelets for seizure detection. We utilise the Maximum Overlap Discrete Wavelet Transform which enables us to reduce signal noise Then from the variance exhibited in wavelet coefficients we develop connectivity and communication efficiency between the electrodes as these properties differ significantly during a seizure period in comparison to a non-seizure period. We use basic statistical parameters derived from the reconstructed noise reduced signal, electrode connectivity and the efficiency of information transfer to build the attribute space.
  We have utilised data that are publicly available to test our method that is found to be significantly better than some existing approaches.

</p>
</details>

<details><summary><b>Efficiently solving the thief orienteering problem with a max-min ant colony optimization approach</b>
<a href="https://arxiv.org/abs/2109.13103">arxiv:2109.13103</a>
&#x1F4C8; 1 <br>
<p>Jonatas B. C. Chagas, Markus Wagner</p></summary>
<p>

**Abstract:** We tackle the Thief Orienteering Problem (ThOP), an academic multi-component problem that combines two classical combinatorial problems, namely the Knapsack Problem and the Orienteering Problem. In the ThOP, a thief has a time limit to steal items that distributed in a given set of cities. While traveling, the thief collects items by storing them in their knapsack, which in turn reduces the travel speed. The thief has as the objective to maximize the total profit of the stolen items. In this article, we present an approach that combines swarm-intelligence with a randomized packing heuristic. Our solution approach outperforms existing works on almost all the 432 benchmarking instances, with significant improvements.

</p>
</details>

<details><summary><b>Graph Neural Netwrok with Interaction Pattern for Group Recommendation</b>
<a href="https://arxiv.org/abs/2109.11345">arxiv:2109.11345</a>
&#x1F4C8; 1 <br>
<p>Bojie Wang, Yuheng Lu</p></summary>
<p>

**Abstract:** With the development of social platforms, people are more and more inclined to combine into groups to participate in some activities, so group recommendation has gradually become a problem worthy of research. For group recommendation, an important issue is how to obtain the characteristic representation of the group and the item through personal interaction history, and obtain the group's preference for the item. For this problem, we proposed the model GIP4GR (Graph Neural Network with Interaction Pattern For Group Recommendation). Specifically, our model use the graph neural network framework with powerful representation capabilities to represent the interaction between group-user-items in the topological structure of the graph, and at the same time, analyze the interaction pattern of the graph to adjust the feature output of the graph neural network, the feature representations of groups, and items are obtained to calculate the group's preference for items. We conducted a lot of experiments on two real-world datasets to illustrate the superior performance of our model.

</p>
</details>

<details><summary><b>Joint Optical Neuroimaging Denoising with Semantic Tasks</b>
<a href="https://arxiv.org/abs/2109.10499">arxiv:2109.10499</a>
&#x1F4C8; 1 <br>
<p>Tianfang Zhu, Yue Guan, Anan Li</p></summary>
<p>

**Abstract:** Optical neuroimaging is a vital tool for understanding the brain structure and the connection between regions and nuclei. However, the image noise introduced in the sample preparation and the imaging system hinders the extraction of the possible knowlege from the dataset, thus denoising for the optical neuroimaging is usually necessary. The supervised denoisng methods often outperform the unsupervised ones, but the training of the supervised denoising models needs the corresponding clean labels, which is not always avaiable due to the high labeling cost. On the other hand, those semantic labels, such as the located soma positions, the reconstructed neuronal fibers, and the nuclei segmentation result, are generally available and accumulated from everyday neuroscience research. This work connects a supervised denoising and a semantic segmentation model together to form a end-to-end model, which can make use of the semantic labels while still provides a denoised image as an intermediate product. We use both the supervised and the self-supervised models for the denoising and introduce a new cost term for the joint denoising and the segmentation setup. We test the proposed approach on both the synthetic data and the real-world data, including the optical neuroimaing dataset and the electron microscope dataset. The result shows that the joint denoising result outperforms the one using the denoising method alone and the joint model benefits the segmentation and other downstream task as well.

</p>
</details>

<details><summary><b>Learning Robust Agents for Visual Navigation in Dynamic Environments: The Winning Entry of iGibson Challenge 2021</b>
<a href="https://arxiv.org/abs/2109.10493">arxiv:2109.10493</a>
&#x1F4C8; 1 <br>
<p>Naoki Yokoyama, Qian Luo, Dhruv Batra, Sehoon Ha</p></summary>
<p>

**Abstract:** This paper presents an approach for improving navigation in dynamic and interactive environments, which won the 1st place in the iGibson Interactive Navigation Challenge 2021. While the last few years have produced impressive progress on PointGoal Navigation in static environments, relatively little effort has been made on more realistic dynamic environments. The iGibson Challenge proposed two new navigation tasks, Interactive Navigation and Social Navigation, which add displaceable obstacles and moving pedestrians into the simulator environment. Our approach to study these problems uses two key ideas. First, we employ large-scale reinforcement learning by leveraging the Habitat simulator, which supports high performance parallel computing for both simulation and synchronized learning. Second, we employ a new data augmentation technique that adds more dynamic objects into the environment, which can also be combined with traditional image-based augmentation techniques to boost the performance further. Lastly, we achieve sim-to-sim transfer from Habitat to the iGibson simulator, and demonstrate that our proposed methods allow us to train robust agents in dynamic environments with interactive objects or moving humans. Video link: https://www.youtube.com/watch?v=HxUX2HeOSE4

</p>
</details>

<details><summary><b>Benchmarking Lane-changing Decision-making for Deep Reinforcement Learning</b>
<a href="https://arxiv.org/abs/2109.10490">arxiv:2109.10490</a>
&#x1F4C8; 1 <br>
<p>Junjie Wang, Qichao Zhang, Dongbin Zhao</p></summary>
<p>

**Abstract:** The development of autonomous driving has attracted extensive attention in recent years, and it is essential to evaluate the performance of autonomous driving. However, testing on the road is expensive and inefficient. Virtual testing is the primary way to validate and verify self-driving cars, and the basis of virtual testing is to build simulation scenarios. In this paper, we propose a training, testing, and evaluation pipeline for the lane-changing task from the perspective of deep reinforcement learning. First, we design lane change scenarios for training and testing, where the test scenarios include stochastic and deterministic parts. Then, we deploy a set of benchmarks consisting of learning and non-learning approaches. We train several state-of-the-art deep reinforcement learning methods in the designed training scenarios and provide the benchmark metrics evaluation results of the trained models in the test scenarios. The designed lane-changing scenarios and benchmarks are both opened to provide a consistent experimental environment for the lane-changing task.

</p>
</details>

<details><summary><b>Rapid detection and recognition of whole brain activity in a freely behaving Caenorhabditis elegans</b>
<a href="https://arxiv.org/abs/2109.10474">arxiv:2109.10474</a>
&#x1F4C8; 1 <br>
<p>Yuxiang Wu, Shang Wu, Xin Wang, Chengtian Lang, Quanshi Zhang, Quan Wen, Tianqi Xu</p></summary>
<p>

**Abstract:** Advanced volumetric imaging methods and genetically encoded activity indicators have permitted a comprehensive characterization of whole brain activity at single neuron resolution in \textit{Caenorhabditis elegans}. The constant motion and deformation of the mollusc nervous system, however, impose a great challenge for a consistent identification of densely packed neurons in a behaving animal. Here, we propose a cascade solution for long-term and rapid recognition of head ganglion neurons in a freely moving \textit{C. elegans}. First, potential neuronal regions from a stack of fluorescence images are detected by a deep learning algorithm. Second, 2 dimensional neuronal regions are fused into 3 dimensional neuron entities. Third, by exploiting the neuronal density distribution surrounding a neuron and relative positional information between neurons, a multi-class artificial neural network transforms engineered neuronal feature vectors into digital neuronal identities. Under the constraint of a small number (20-40 volumes) of training samples, our bottom-up approach is able to process each volume - $1024 \times 1024 \times 18$ in voxels - in less than 1 second and achieves an accuracy of $91\%$ in neuronal detection and $74\%$ in neuronal recognition. Our work represents an important development towards a rapid and fully automated algorithm for decoding whole brain activity underlying natural animal behaviors.

</p>
</details>

<details><summary><b>Rotor Localization and Phase Mapping of Cardiac Excitation Waves using Deep Neural Networks</b>
<a href="https://arxiv.org/abs/2109.10472">arxiv:2109.10472</a>
&#x1F4C8; 1 <br>
<p>Jan Lebert, Namita Ravi, Flavio Fenton, Jan Christoph</p></summary>
<p>

**Abstract:** The analysis of electrical impulse phenomena in cardiac muscle tissue is important for the diagnosis of heart rhythm disorders and other cardiac pathophysiology. Cardiac mapping techniques acquire local temporal measurements and combine them to visualize the spread of electrophysiological wave phenomena across the heart surface. However, low spatial resolution, sparse measurement locations, noise and other artifacts make it challenging to accurately visualize spatio-temporal activity. For instance, electro-anatomical catheter mapping is severely limited by the sparsity of the measurements, and optical mapping is prone to noise and motion artifacts. In the past, several approaches have been proposed to obtain more reliable maps from noisy or sparse mapping data. Here, we demonstrate that deep learning can be used to compute phase maps and detect phase singularities in optical mapping videos of ventricular fibrillation, as well as in very noisy, low-resolution and extremely sparse simulated data of reentrant wave chaos mimicking catheter mapping data. The deep learning approach learns to directly associate phase maps and the positions of phase singularities with short spatio-temporal sequences of electrical data. We tested several neural network architectures, based on a convolutional neural network with an encoding and decoding structure, to predict phase maps or rotor core positions either directly or indirectly via the prediction of phase maps and a subsequent classical calculation of phase singularities. Predictions can be performed across different data, with models being trained on one species and then successfully applied to another, or being trained solely on simulated data and then applied to experimental data. Future uses may include the analysis of optical mapping studies in basic cardiovascular research, as well as the mapping of atrial fibrillation in the clinical setting.

</p>
</details>

<details><summary><b>Achieving Counterfactual Fairness for Causal Bandit</b>
<a href="https://arxiv.org/abs/2109.10458">arxiv:2109.10458</a>
&#x1F4C8; 1 <br>
<p>Wen Huang, Lu Zhang, Xintao Wu</p></summary>
<p>

**Abstract:** In online recommendation, customers arrive in a sequential and stochastic manner from an underlying distribution and the online decision model recommends a chosen item for each arriving individual based on some strategy. We study how to recommend an item at each step to maximize the expected reward while achieving user-side fairness for customers, i.e., customers who share similar profiles will receive a similar reward regardless of their sensitive attributes and items being recommended. By incorporating causal inference into bandits and adopting soft intervention to model the arm selection strategy, we first propose the d-separation based UCB algorithm (D-UCB) to explore the utilization of the d-separation set in reducing the amount of exploration needed to achieve low cumulative regret. Based on that, we then propose the fair causal bandit (F-UCB) for achieving the counterfactual individual fairness. Both theoretical analysis and empirical evaluation demonstrate effectiveness of our algorithms.

</p>
</details>

<details><summary><b>Beyond Discriminant Patterns: On the Robustness of Decision Rule Ensembles</b>
<a href="https://arxiv.org/abs/2109.10432">arxiv:2109.10432</a>
&#x1F4C8; 1 <br>
<p>Xin Du, Subramanian Ramamoorthy, Wouter Duivesteijn, Jin Tian, Mykola Pechenizkiy</p></summary>
<p>

**Abstract:** Local decision rules are commonly understood to be more explainable, due to the local nature of the patterns involved. With numerical optimization methods such as gradient boosting, ensembles of local decision rules can gain good predictive performance on data involving global structure. Meanwhile, machine learning models are being increasingly used to solve problems in high-stake domains including healthcare and finance. Here, there is an emerging consensus regarding the need for practitioners to understand whether and how those models could perform robustly in the deployment environments, in the presence of distributional shifts. Past research on local decision rules has focused mainly on maximizing discriminant patterns, without due consideration of robustness against distributional shifts. In order to fill this gap, we propose a new method to learn and ensemble local decision rules, that are robust both in the training and deployment environments. Specifically, we propose to leverage causal knowledge by regarding the distributional shifts in subpopulations and deployment environments as the results of interventions on the underlying system. We propose two regularization terms based on causal knowledge to search for optimal and stable rules. Experiments on both synthetic and benchmark datasets show that our method is effective and robust against distributional shifts in multiple environments.

</p>
</details>

<details><summary><b>Deep Policies for Online Bipartite Matching: A Reinforcement Learning Approach</b>
<a href="https://arxiv.org/abs/2109.10380">arxiv:2109.10380</a>
&#x1F4C8; 1 <br>
<p>Mohammad Ali Alomrani, Reza Moravej, Elias B. Khalil</p></summary>
<p>

**Abstract:** From assigning computing tasks to servers and advertisements to users, sequential online matching problems arise in a wide variety of domains. The challenge in online matching lies in making irrevocable assignments while there is uncertainty about future inputs. In the theoretical computer science literature, most policies are myopic or greedy in nature. In real-world applications where the matching process is repeated on a regular basis, the underlying data distribution can be leveraged for better decision-making. We present an end-to-end Reinforcement Learning framework for deriving better matching policies based on trial-and-error on historical data. We devise a set of neural network architectures, design feature representations, and empirically evaluate them across two online matching problems: Edge-Weighted Online Bipartite Matching and Online Submodular Bipartite Matching. We show that most of the learning approaches perform significantly better than classical greedy algorithms on four synthetic and real-world datasets. Our code is publicly available at https://github.com/lyeskhalil/CORL.git.

</p>
</details>

<details><summary><b>Learning through structure: towards deep neuromorphic knowledge graph embeddings</b>
<a href="https://arxiv.org/abs/2109.10376">arxiv:2109.10376</a>
&#x1F4C8; 1 <br>
<p>Victor Caceres Chian, Marcel Hildebrandt, Thomas Runkler, Dominik Dold</p></summary>
<p>

**Abstract:** Computing latent representations for graph-structured data is an ubiquitous learning task in many industrial and academic applications ranging from molecule synthetization to social network analysis and recommender systems. Knowledge graphs are among the most popular and widely used data representations related to the Semantic Web. Next to structuring factual knowledge in a machine-readable format, knowledge graphs serve as the backbone of many artificial intelligence applications and allow the ingestion of context information into various learning algorithms. Graph neural networks attempt to encode graph structures in low-dimensional vector spaces via a message passing heuristic between neighboring nodes. Over the recent years, a multitude of different graph neural network architectures demonstrated ground-breaking performances in many learning tasks. In this work, we propose a strategy to map deep graph learning architectures for knowledge graph reasoning to neuromorphic architectures. Based on the insight that randomly initialized and untrained (i.e., frozen) graph neural networks are able to preserve local graph structures, we compose a frozen neural network with shallow knowledge graph embedding models. We experimentally show that already on conventional computing hardware, this leads to a significant speedup and memory reduction while maintaining a competitive performance level. Moreover, we extend the frozen architecture to spiking neural networks, introducing a novel, event-based and highly sparse knowledge graph embedding algorithm that is suitable for implementation in neuromorphic hardware.

</p>
</details>

<details><summary><b>An Ultra-Fast Method for Simulation of Realistic Ultrasound Images</b>
<a href="https://arxiv.org/abs/2109.10353">arxiv:2109.10353</a>
&#x1F4C8; 1 <br>
<p>Mostafa Sharifzadeh, Habib Benali, Hassan Rivaz</p></summary>
<p>

**Abstract:** Convolutional neural networks (CNNs) have attracted a rapidly growing interest in a variety of different processing tasks in the medical ultrasound community. However, the performance of CNNs is highly reliant on both the amount and fidelity of the training data. Therefore, scarce data is almost always a concern, particularly in the medical field, where clinical data is not easily accessible. The utilization of synthetic data is a popular approach to address this challenge. However, but simulating a large number of images using packages such as Field II is time-consuming, and the distribution of simulated images is far from that of the real images. Herein, we introduce a novel ultra-fast ultrasound image simulation method based on the Fourier transform and evaluate its performance in a lesion segmentation task. We demonstrate that data augmentation using the images generated by the proposed method substantially outperforms Field II in terms of Dice similarity coefficient, while the simulation is almost 36000 times faster (both on CPU).

</p>
</details>

<details><summary><b>Computing Complexity-aware Plans Using Kolmogorov Complexity</b>
<a href="https://arxiv.org/abs/2109.10303">arxiv:2109.10303</a>
&#x1F4C8; 1 <br>
<p>Elis Stefansson, Karl H. Johansson</p></summary>
<p>

**Abstract:** In this paper, we introduce complexity-aware planning for finite-horizon deterministic finite automata with rewards as outputs, based on Kolmogorov complexity. Kolmogorov complexity is considered since it can detect computational regularities of deterministic optimal policies. We present a planning objective yielding an explicit trade-off between a policy's performance and complexity. It is proven that maximising this objective is non-trivial in the sense that dynamic programming is infeasible. We present two algorithms obtaining low-complexity policies, where the first algorithm obtains a low-complexity optimal policy, and the second algorithm finds a policy maximising performance while maintaining local (stage-wise) complexity constraints. We evaluate the algorithms on a simple navigation task for a mobile robot, where our algorithms yield low-complexity policies that concur with intuition.

</p>
</details>

<details><summary><b>SalienTrack: providing salient information for semi-automated self-tracking feedback with model explanations</b>
<a href="https://arxiv.org/abs/2109.10231">arxiv:2109.10231</a>
&#x1F4C8; 1 <br>
<p>Yunlong Wang, Jiaying Liu, Homin Park, Jordan Schultz-McArdle, Stephanie Rosenthal, Brian Y. Lim</p></summary>
<p>

**Abstract:** Self-tracking can improve people's awareness of their unhealthy behaviors to provide insights towards behavior change. Prior work has explored how self-trackers reflect on their logged data, but it remains unclear how much they learn from the tracking feedback, and which information is more useful. Indeed, the feedback can still be overwhelming, and making it concise can improve learning by increasing focus and reducing interpretation burden. To streamline the feedback, we propose a Self-Tracking Feedback Saliency Framework to define when to provide feedback, on which specific information, why those details, and how to present them (manual elicitation or automatic feedback). We collected survey and meal image data from a field study of mobile food tracking, and implemented SalienTrack, a machine learning model to predict when a user would learn from tracked events. Using explainable AI (XAI) techniques, SalienTrack identifies which features of the event are most salient, why they lead to positive learning outcomes, and prioritizes how to present the feedback based on attribution scores. We demonstrate use cases and conducted a formative study to show the usability and usefulness of SalienTrack. We discuss implications for learnability in self-tracking, and how adding model explainability expands opportunities for improving feedback experience.

</p>
</details>

<details><summary><b>Interpretable Directed Diversity: Leveraging Model Explanations for Iterative Crowd Ideation</b>
<a href="https://arxiv.org/abs/2109.10149">arxiv:2109.10149</a>
&#x1F4C8; 1 <br>
<p>Yunlong Wang, Priyadarshini Venkatesh, Brian Y. Lim</p></summary>
<p>

**Abstract:** Feedback can help crowdworkers to improve their ideations. However, current feedback methods require human assessment from facilitators or peers. This is not scalable to large crowds. We propose Interpretable Directed Diversity to automatically predict ideation quality and diversity scores, and provide AI explanations - Attribution, Contrastive Attribution, and Counterfactual Suggestions - for deeper feedback on why ideations were scored (low), and how to get higher scores. These explanations provide multi-faceted feedback as users iteratively improve their ideation. We conducted think aloud and controlled user studies to understand how various explanations are used, and evaluated whether explanations improve ideation diversity and quality. Users appreciated that explanation feedback helped focus their efforts and provided directions for improvement. This resulted in explanations improving diversity compared to no feedback or feedback with predictions only. Hence, our approach opens opportunities for explainable AI towards scalable and rich feedback for iterative crowd ideation.

</p>
</details>

<details><summary><b>Comparison of Neural Network based Soft Computing Techniques for Electromagnetic Modeling of a Microstrip Patch Antenna</b>
<a href="https://arxiv.org/abs/2109.10065">arxiv:2109.10065</a>
&#x1F4C8; 1 <br>
<p>Yuvraj Singh Malhi, Navneet Gupta</p></summary>
<p>

**Abstract:** This paper presents the comparison of various neural networks and algorithms based on accuracy, quickness, and consistency for antenna modelling. Using MATLAB Nntool, 22 different combinations of networks and training algorithms are used to predict the dimensions of a rectangular microstrip antenna using dielectric constant, height of substrate, and frequency of oper-ation as input. Comparison and characterization of networks is done based on accuracy, mean square error, and training time. Algorithms, on the other hand, are analyzed by their accuracy, speed, reliability, and smoothness in the training process. Finally, these results are analyzed, and recommendations are made for each neural network and algorithm based on uses, advantages, and disadvantages. For example, it is observed that Reduced Radial Bias network is the most accurate network and Scaled Conjugate Gradient is the most reliable algorithm for electromagnetic modelling. This paper will help a researcher find the optimum network and algorithm directly without doing time-taking experimentation.

</p>
</details>

<details><summary><b>Generating Local Maps of Science using Deep Bibliographic Coupling</b>
<a href="https://arxiv.org/abs/2109.10007">arxiv:2109.10007</a>
&#x1F4C8; 1 <br>
<p>Gaëlle Candel, David Naccache</p></summary>
<p>

**Abstract:** Bibliographic and co-citation coupling are two analytical methods widely used to measure the degree of similarity between scientific papers. These approaches are intuitive, easy to put into practice, and computationally cheap. Moreover, they have been used to generate a map of science, allowing visualizing research field interactions. Nonetheless, these methods do not work unless two papers share a standard reference, limiting the two papers usability with no direct connection. In this work, we propose to extend bibliographic coupling to the deep neighborhood, by using graph diffusion methods. This method allows defining similarity between any two papers, making it possible to generate a local map of science, highlighting field organization.

</p>
</details>

<details><summary><b>Vaccine allocation policy optimization and budget sharing mechanism using Thompson sampling</b>
<a href="https://arxiv.org/abs/2109.10004">arxiv:2109.10004</a>
&#x1F4C8; 1 <br>
<p>David Rey, Ahmed W Hammad, Meead Saberi</p></summary>
<p>

**Abstract:** The optimal allocation of vaccines to population subgroups over time is a challenging health care management problem. In the context of a pandemic, the interaction between vaccination policies adopted by multiple agents and the cooperation (or lack thereof) creates a complex environment that affects the global transmission dynamics of the disease. In this study, we take the perspective of decision-making agents that aim to minimize the size of their susceptible populations and must allocate vaccine under limited supply. We assume that vaccine efficiency rates are unknown to agents and we propose an optimization policy based on Thompson sampling to learn mean vaccine efficiency rates over time. Furthermore, we develop a budget-balanced resource sharing mechanism to promote cooperation among agents. We apply the proposed framework to the COVID-19 pandemic. We use a raster model of the world where agents represent the main countries worldwide and interact in a global mobility network to generate multiple problem instances. Our numerical results show that the proposed vaccine allocation policy achieves a larger reduction in the number of susceptible individuals, infections and deaths globally compared to a population-based policy. In addition, we show that, under a fixed global vaccine allocation budget, most countries can reduce their national number of infections and deaths by sharing their budget with countries with which they have a relatively high mobility exchange. The proposed framework can be used to improve policy-making in health care management by national and global health authorities.

</p>
</details>

<details><summary><b>Optimization Strategies in Multi-Task Learning: Averaged or Independent Losses?</b>
<a href="https://arxiv.org/abs/2109.11678">arxiv:2109.11678</a>
&#x1F4C8; 0 <br>
<p>Lucas Pascal, Pietro Michiardi, Xavier Bost, Benoit Huet, Maria A. Zuluaga</p></summary>
<p>

**Abstract:** In Multi-Task Learning (MTL), it is a common practice to train multi-task networks by optimizing an objective function, which is a weighted average of the task-specific objective functions. Although the computational advantages of this strategy are clear, the complexity of the resulting loss landscape has not been studied in the literature. Arguably, its optimization may be more difficult than a separate optimization of the constituting task-specific objectives. In this work, we investigate the benefits of such an alternative, by alternating independent gradient descent steps on the different task-specific objective functions and we formulate a novel way to combine this approach with state-of-the-art optimizers. As the separation of task-specific objectives comes at the cost of increased computational time, we propose a random task grouping as a trade-off between better optimization and computational efficiency. Experimental results over three well-known visual MTL datasets show better overall absolute performance on losses and standard metrics compared to an averaged objective function and other state-of-the-art MTL methods. In particular, our method shows the most benefits when dealing with tasks of different nature and it enables a wider exploration of the shared parameter space. We also show that our random grouping strategy allows to trade-off between these benefits and computational efficiency.

</p>
</details>

<details><summary><b>Towards Explainable Scientific Venue Recommendations</b>
<a href="https://arxiv.org/abs/2109.11343">arxiv:2109.11343</a>
&#x1F4C8; 0 <br>
<p>Bastian Schäfermeier, Gerd Stumme, Tom Hanika</p></summary>
<p>

**Abstract:** Selecting the best scientific venue (i.e., conference/journal) for the submission of a research article constitutes a multifaceted challenge. Important aspects to consider are the suitability of research topics, a venue's prestige, and the probability of acceptance. The selection problem is exacerbated through the continuous emergence of additional venues. Previously proposed approaches for supporting authors in this process rely on complex recommender systems, e.g., based on Word2Vec or TextCNN. These, however, often elude an explanation for their recommendations. In this work, we propose an unsophisticated method that advances the state-of-the-art in two aspects: First, we enhance the interpretability of recommendations through non-negative matrix factorization based topic models; Second, we surprisingly can obtain competitive recommendation performance while using simpler learning methods.

</p>
</details>

<details><summary><b>Query Evaluation in DatalogMTL -- Taming Infinite Query Results</b>
<a href="https://arxiv.org/abs/2109.10691">arxiv:2109.10691</a>
&#x1F4C8; 0 <br>
<p>Luigi Bellomarini, Markus Nissl, Emanuel Sallinger</p></summary>
<p>

**Abstract:** In this paper, we investigate finite representations of DatalogMTL. First, we introduce programs that have finite models and propose a toolkit for structuring the execution of DatalogMTL rules into sequential phases. Then, we study infinite models that eventually become constant and introduce sufficient criteria for programs that allow for such representation. We proceed by considering infinite models that are eventually periodic and show that such a representation encompasses all DatalogMTLFP programs, a widely discussed fragment. Finally, we provide a novel algorithm for reasoning over finite representable DatalogMTL programs that incorporates all of the previously discussed representations.

</p>
</details>


[Next Page]({{ '/2021/09/20/2021.09.20.html' | relative_url }})
