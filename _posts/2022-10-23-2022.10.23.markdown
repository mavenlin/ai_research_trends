Prev: [2022.10.22]({{ '/2022/10/22/2022.10.22.html' | relative_url }})  Next: [2022.10.24]({{ '/2022/10/24/2022.10.24.html' | relative_url }})
{% raw %}
## Summary for 2022-10-23, created on 2022-10-30


<details><summary><b>DALL-E 2 Fails to Reliably Capture Common Syntactic Processes</b>
<a href="https://arxiv.org/abs/2210.12889">arxiv:2210.12889</a>
&#x1F4C8; 112 <br>
<p>Evelina Leivada, Elliot Murphy, Gary Marcus</p></summary>
<p>

**Abstract:** Machine intelligence is increasingly being linked to claims about sentience, language processing, and an ability to comprehend and transform natural language into a range of stimuli. We systematically analyze the ability of DALL-E 2 to capture 8 grammatical phenomena pertaining to compositionality that are widely discussed in linguistics and pervasive in human language: binding principles and coreference, passives, word order, coordination, comparatives, negation, ellipsis, and structural ambiguity. Whereas young children routinely master these phenomena, learning systematic mappings between syntax and semantics, DALL-E 2 is unable to reliably infer meanings that are consistent with the syntax. These results challenge recent claims concerning the capacity of such systems to understand of human language. We make available the full set of test materials as a benchmark for future testing.

</p>
</details>

<details><summary><b>Towards Real-Time Text2Video via CLIP-Guided, Pixel-Level Optimization</b>
<a href="https://arxiv.org/abs/2210.12826">arxiv:2210.12826</a>
&#x1F4C8; 73 <br>
<p>Peter Schaldenbrand, Zhixuan Liu, Jean Oh</p></summary>
<p>

**Abstract:** We introduce an approach to generating videos based on a series of given language descriptions. Frames of the video are generated sequentially and optimized by guidance from the CLIP image-text encoder; iterating through language descriptions, weighting the current description higher than others. As opposed to optimizing through an image generator model itself, which tends to be computationally heavy, the proposed approach computes the CLIP loss directly at the pixel level, achieving general content at a speed suitable for near real-time systems. The approach can generate videos in up to 720p resolution, variable frame-rates, and arbitrary aspect ratios at a rate of 1-2 frames per second. Please visit our website to view videos and access our open-source code: https://pschaldenbrand.github.io/text2video/ .

</p>
</details>

<details><summary><b>Active Exploration for Robotic Manipulation</b>
<a href="https://arxiv.org/abs/2210.12806">arxiv:2210.12806</a>
&#x1F4C8; 57 <br>
<p>Tim Schneider, Boris Belousov, Georgia Chalvatzaki, Diego Romeres, Devesh K. Jha, Jan Peters</p></summary>
<p>

**Abstract:** Robotic manipulation stands as a largely unsolved problem despite significant advances in robotics and machine learning in recent years. One of the key challenges in manipulation is the exploration of the dynamics of the environment when there is continuous contact between the objects being manipulated. This paper proposes a model-based active exploration approach that enables efficient learning in sparse-reward robotic manipulation tasks. The proposed method estimates an information gain objective using an ensemble of probabilistic models and deploys model predictive control (MPC) to plan actions online that maximize the expected reward while also performing directed exploration. We evaluate our proposed algorithm in simulation and on a real robot, trained from scratch with our method, on a challenging ball pushing task on tilted tables, where the target ball position is not known to the agent a-priori. Our real-world robot experiment serves as a fundamental application of active exploration in model-based reinforcement learning of complex robotic manipulation tasks.

</p>
</details>

<details><summary><b>Retrieval Augmentation for Commonsense Reasoning: A Unified Approach</b>
<a href="https://arxiv.org/abs/2210.12887">arxiv:2210.12887</a>
&#x1F4C8; 54 <br>
<p>Wenhao Yu, Chenguang Zhu, Zhihan Zhang, Shuohang Wang, Zhuosheng Zhang, Yuwei Fang, Meng Jiang</p></summary>
<p>

**Abstract:** A common thread of retrieval-augmented methods in the existing literature focuses on retrieving encyclopedic knowledge, such as Wikipedia, which facilitates well-defined entity and relation spaces that can be modeled. However, applying such methods to commonsense reasoning tasks faces two unique challenges, i.e., the lack of a general large-scale corpus for retrieval and a corresponding effective commonsense retriever. In this paper, we systematically investigate how to leverage commonsense knowledge retrieval to improve commonsense reasoning tasks. We proposed a unified framework of retrieval-augmented commonsense reasoning (called RACo), including a newly constructed commonsense corpus with over 20 million documents and novel strategies for training a commonsense retriever. We conducted experiments on four different commonsense reasoning tasks. Extensive evaluation results showed that our proposed RACo can significantly outperform other knowledge-enhanced method counterparts, achieving new SoTA performance on the CommonGen and CREAK leaderboards.

</p>
</details>

<details><summary><b>Principal Component Classification</b>
<a href="https://arxiv.org/abs/2210.12746">arxiv:2210.12746</a>
&#x1F4C8; 26 <br>
<p>Rozenn Dahyot</p></summary>
<p>

**Abstract:** We propose to directly compute classification estimates by learning features encoded with their class scores using PCA. Our resulting model has a encoder-decoder structure suitable for supervised learning, it is computationally efficient and performs well for classification on several datasets.

</p>
</details>

<details><summary><b>Learning General World Models in a Handful of Reward-Free Deployments</b>
<a href="https://arxiv.org/abs/2210.12719">arxiv:2210.12719</a>
&#x1F4C8; 12 <br>
<p>Yingchen Xu, Jack Parker-Holder, Aldo Pacchiano, Philip J. Ball, Oleh Rybkin, Stephen J. Roberts, Tim Rocktäschel, Edward Grefenstette</p></summary>
<p>

**Abstract:** Building generally capable agents is a grand challenge for deep reinforcement learning (RL). To approach this challenge practically, we outline two key desiderata: 1) to facilitate generalization, exploration should be task agnostic; 2) to facilitate scalability, exploration policies should collect large quantities of data without costly centralized retraining. Combining these two properties, we introduce the reward-free deployment efficiency setting, a new paradigm for RL research. We then present CASCADE, a novel approach for self-supervised exploration in this new setting. CASCADE seeks to learn a world model by collecting data with a population of agents, using an information theoretic objective inspired by Bayesian Active Learning. CASCADE achieves this by specifically maximizing the diversity of trajectories sampled by the population through a novel cascading objective. We provide theoretical intuition for CASCADE which we show in a tabular setting improves upon naïve approaches that do not account for population diversity. We then demonstrate that CASCADE collects diverse task-agnostic datasets and learns agents that generalize zero-shot to novel, unseen downstream tasks on Atari, MiniGrid, Crafter and the DM Control Suite. Code and videos are available at https://ycxuyingchen.github.io/cascade/

</p>
</details>

<details><summary><b>FLIP: A Provable Defense Framework for Backdoor Mitigation in Federated Learning</b>
<a href="https://arxiv.org/abs/2210.12873">arxiv:2210.12873</a>
&#x1F4C8; 9 <br>
<p>Kaiyuan Zhang, Guanhong Tao, Qiuling Xu, Siyuan Cheng, Shengwei An, Yingqi Liu, Shiwei Feng, Guangyu Shen, Pin-Yu Chen, Shiqing Ma, Xiangyu Zhang</p></summary>
<p>

**Abstract:** Federated Learning (FL) is a distributed learning paradigm that enables different parties to train a model together for high quality and strong privacy protection. In this scenario, individual participants may get compromised and perform backdoor attacks by poisoning the data (or gradients). Existing work on robust aggregation and certified FL robustness does not study how hardening benign clients can affect the global model (and the malicious clients). In this work, we theoretically analyze the connection among cross-entropy loss, attack success rate, and clean accuracy in this setting. Moreover, we propose a trigger reverse engineering based defense and show that our method can achieve robustness improvement with guarantee (i.e., reducing the attack success rate) without affecting benign accuracy. We conduct comprehensive experiments across different datasets and attack settings. Our results on eight competing SOTA defense methods show the empirical superiority of our method on both single-shot and continuous FL backdoor attacks.

</p>
</details>

<details><summary><b>Adversarial Pretraining of Self-Supervised Deep Networks: Past, Present and Future</b>
<a href="https://arxiv.org/abs/2210.13463">arxiv:2210.13463</a>
&#x1F4C8; 8 <br>
<p>Guo-Jun Qi, Mubarak Shah</p></summary>
<p>

**Abstract:** In this paper, we review adversarial pretraining of self-supervised deep networks including both convolutional neural networks and vision transformers. Unlike the adversarial training with access to labeled examples, adversarial pretraining is complicated as it only has access to unlabeled examples. To incorporate adversaries into pretraining models on either input or feature level, we find that existing approaches are largely categorized into two groups: memory-free instance-wise attacks imposing worst-case perturbations on individual examples, and memory-based adversaries shared across examples over iterations. In particular, we review several representative adversarial pretraining models based on Contrastive Learning (CL) and Masked Image Modeling (MIM), respectively, two popular self-supervised pretraining methods in literature. We also review miscellaneous issues about computing overheads, input-/feature-level adversaries, as well as other adversarial pretraining approaches beyond the above two groups. Finally, we discuss emerging trends and future directions about the relations between adversarial and cooperative pretraining, unifying adversarial CL and MIM pretraining, and the trade-off between accuracy and robustness in adversarial pretraining.

</p>
</details>

<details><summary><b>Artificial Intelligence-Based Methods for Fusion of Electronic Health Records and Imaging Data</b>
<a href="https://arxiv.org/abs/2210.13462">arxiv:2210.13462</a>
&#x1F4C8; 7 <br>
<p>Farida Mohsen, Hazrat Ali, Nady El Hajj, Zubair Shah</p></summary>
<p>

**Abstract:** Healthcare data are inherently multimodal, including electronic health records (EHR), medical images, and multi-omics data. Combining these multimodal data sources contributes to a better understanding of human health and provides optimal personalized healthcare. Advances in artificial intelligence (AI) technologies, particularly machine learning (ML), enable the fusion of these different data modalities to provide multimodal insights. To this end, in this scoping review, we focus on synthesizing and analyzing the literature that uses AI techniques to fuse multimodal medical data for different clinical applications. More specifically, we focus on studies that only fused EHR with medical imaging data to develop various AI methods for clinical applications. We present a comprehensive analysis of the various fusion strategies, the diseases and clinical outcomes for which multimodal fusion was used, the ML algorithms used to perform multimodal fusion for each clinical application, and the available multimodal medical datasets. We followed the PRISMA-ScR guidelines. We searched Embase, PubMed, Scopus, and Google Scholar to retrieve relevant studies. We extracted data from 34 studies that fulfilled the inclusion criteria. In our analysis, a typical workflow was observed: feeding raw data, fusing different data modalities by applying conventional machine learning (ML) or deep learning (DL) algorithms, and finally, evaluating the multimodal fusion through clinical outcome predictions. Specifically, early fusion was the most used technique in most applications for multimodal learning (22 out of 34 studies). We found that multimodality fusion models outperformed traditional single-modality models for the same task. Disease diagnosis and prediction were the most common clinical outcomes (reported in 20 and 10 studies, respectively) from a clinical outcome perspective.

</p>
</details>

<details><summary><b>Symmetry and Variance: Generative Parametric Modelling of Historical Brick Wall Patterns</b>
<a href="https://arxiv.org/abs/2210.12856">arxiv:2210.12856</a>
&#x1F4C8; 7 <br>
<p>Sevgi Altun, Mustafa Cem Gunes, Yusuf H. Sahin, Alican Mertan, Gozde Unal, Mine Ozkar</p></summary>
<p>

**Abstract:** This study integrates artificial intelligence and computational design tools to extract information from architectural heritage. Photogrammetry-based point cloud models of brick walls from the Anatolian Seljuk period are analysed in terms of the interrelated units of construction, simultaneously considering both the inherent symmetries and irregularities. The real-world data is used as input for acquiring the stochastic parameters of spatial relations and a set of parametric shape rules to recreate designs of existing and hypothetical brick walls within the style. The motivation is to be able to generate large data sets for machine learning of the style and to devise procedures for robotic production of such designs with repetitive units.

</p>
</details>

<details><summary><b>Falsehoods that ML researchers believe about OOD detection</b>
<a href="https://arxiv.org/abs/2210.12767">arxiv:2210.12767</a>
&#x1F4C8; 7 <br>
<p>Andi Zhang, Damon Wischik</p></summary>
<p>

**Abstract:** Modelling the density $p(x)$ by probabilistic generative models is an intuitive way to detect out-of-distribution (OOD) data, but it fails in the deep learning context. In this paper, we list some falsehoods that machine learning researchers believe about density-based OOD detection. Many recent works have proposed likelihood-ratio-based methods to `fix' this issue. We propose a framework, the OOD proxy framework, to unify these methods, and we argue that likelihood ratio is a principled method for OOD detection and not a mere `fix'. Finally, we discuss the relationship between domain detection and semantics.

</p>
</details>

<details><summary><b>GFlowOut: Dropout with Generative Flow Networks</b>
<a href="https://arxiv.org/abs/2210.12928">arxiv:2210.12928</a>
&#x1F4C8; 6 <br>
<p>Dianbo Liu, Moksh Jain, Bonaventure Dossou, Qianli Shen, Salem Lahlou, Anirudh Goyal, Nikolay Malkin, Chris Emezue, Dinghuai Zhang, Nadhir Hassen, Xu Ji, Kenji Kawaguchi, Yoshua Bengio</p></summary>
<p>

**Abstract:** Bayesian Inference offers principled tools to tackle many critical problems with modern neural networks such as poor calibration and generalization, and data inefficiency. However, scaling Bayesian inference to large architectures is challenging and requires restrictive approximations. Monte Carlo Dropout has been widely used as a relatively cheap way for approximate Inference and to estimate uncertainty with deep neural networks. Traditionally, the dropout mask is sampled independently from a fixed distribution. Recent works show that the dropout mask can be viewed as a latent variable, which can be inferred with variational inference. These methods face two important challenges: (a) the posterior distribution over masks can be highly multi-modal which can be difficult to approximate with standard variational inference and (b) it is not trivial to fully utilize sample-dependent information and correlation among dropout masks to improve posterior estimation. In this work, we propose GFlowOut to address these issues. GFlowOut leverages the recently proposed probabilistic framework of Generative Flow Networks (GFlowNets) to learn the posterior distribution over dropout masks. We empirically demonstrate that GFlowOut results in predictive distributions that generalize better to out-of-distribution data, and provide uncertainty estimates which lead to better performance in downstream tasks.

</p>
</details>

<details><summary><b>Unsupervised Object Representation Learning using Translation and Rotation Group Equivariant VAE</b>
<a href="https://arxiv.org/abs/2210.12918">arxiv:2210.12918</a>
&#x1F4C8; 6 <br>
<p>Alireza Nasiri, Tristan Bepler</p></summary>
<p>

**Abstract:** In many imaging modalities, objects of interest can occur in a variety of locations and poses (i.e. are subject to translations and rotations in 2d or 3d), but the location and pose of an object does not change its semantics (i.e. the object's essence). That is, the specific location and rotation of an airplane in satellite imagery, or the 3d rotation of a chair in a natural image, or the rotation of a particle in a cryo-electron micrograph, do not change the intrinsic nature of those objects. Here, we consider the problem of learning semantic representations of objects that are invariant to pose and location in a fully unsupervised manner. We address shortcomings in previous approaches to this problem by introducing TARGET-VAE, a translation and rotation group-equivariant variational autoencoder framework. TARGET-VAE combines three core innovations: 1) a rotation and translation group-equivariant encoder architecture, 2) a structurally disentangled distribution over latent rotation, translation, and a rotation-translation-invariant semantic object representation, which are jointly inferred by the approximate inference network, and 3) a spatially equivariant generator network. In comprehensive experiments, we show that TARGET-VAE learns disentangled representations without supervision that significantly improve upon, and avoid the pathologies of, previous methods. When trained on images highly corrupted by rotation and translation, the semantic representations learned by TARGET-VAE are similar to those learned on consistently posed objects, dramatically improving clustering in the semantic latent space. Furthermore, TARGET-VAE is able to perform remarkably accurate unsupervised pose and location inference. We expect methods like TARGET-VAE will underpin future approaches for unsupervised object generation, pose prediction, and object detection.

</p>
</details>

<details><summary><b>MM-Align: Learning Optimal Transport-based Alignment Dynamics for Fast and Accurate Inference on Missing Modality Sequences</b>
<a href="https://arxiv.org/abs/2210.12798">arxiv:2210.12798</a>
&#x1F4C8; 6 <br>
<p>Wei Han, Hui Chen, Min-Yen Kan, Soujanya Poria</p></summary>
<p>

**Abstract:** Existing multimodal tasks mostly target at the complete input modality setting, i.e., each modality is either complete or completely missing in both training and test sets. However, the randomly missing situations have still been underexplored. In this paper, we present a novel approach named MM-Align to address the missing-modality inference problem. Concretely, we propose 1) an alignment dynamics learning module based on the theory of optimal transport (OT) for indirect missing data imputation; 2) a denoising training algorithm to simultaneously enhance the imputation results and backbone network performance. Compared with previous methods which devote to reconstructing the missing inputs, MM-Align learns to capture and imitate the alignment dynamics between modality sequences. Results of comprehensive experiments on three datasets covering two multimodal tasks empirically demonstrate that our method can perform more accurate and faster inference and relieve overfitting under various missing conditions.

</p>
</details>

<details><summary><b>Multi-Objective GFlowNets</b>
<a href="https://arxiv.org/abs/2210.12765">arxiv:2210.12765</a>
&#x1F4C8; 6 <br>
<p>Moksh Jain, Sharath Chandra Raparthy, Alex Hernandez-Garcia, Jarrid Rector-Brooks, Yoshua Bengio, Santiago Miret, Emmanuel Bengio</p></summary>
<p>

**Abstract:** In many applications of machine learning, like drug discovery and material design, the goal is to generate candidates that simultaneously maximize a set of objectives. As these objectives are often conflicting, there is no single candidate that simultaneously maximizes all objectives, but rather a set of Pareto-optimal candidates where one objective cannot be improved without worsening another. Moreover, in practice, these objectives are often under-specified, making the diversity of candidates a key consideration. The existing multi-objective optimization methods focus predominantly on covering the Pareto front, failing to capture diversity in the space of candidates. Motivated by the success of GFlowNets for generation of diverse candidates in a single objective setting, in this paper we consider Multi-Objective GFlowNets (MOGFNs). MOGFNs consist of a novel Conditional GFlowNet which models a family of single-objective sub-problems derived by decomposing the multi-objective optimization problem. Our work is the first to empirically demonstrate conditional GFlowNets. Through a series of experiments on synthetic and benchmark tasks, we empirically demonstrate that MOGFNs outperform existing methods in terms of Hypervolume, R2-distance and candidate diversity. We also demonstrate the effectiveness of MOGFNs over existing methods in active learning settings. Finally, we supplement our empirical results with a careful analysis of each component of MOGFNs.

</p>
</details>

<details><summary><b>Knowledge Transfer from Answer Ranking to Answer Generation</b>
<a href="https://arxiv.org/abs/2210.12865">arxiv:2210.12865</a>
&#x1F4C8; 5 <br>
<p>Matteo Gabburo, Rik Koncel-Kedziorski, Siddhant Garg, Luca Soldaini, Alessandro Moschitti</p></summary>
<p>

**Abstract:** Recent studies show that Question Answering (QA) based on Answer Sentence Selection (AS2) can be improved by generating an improved answer from the top-k ranked answer sentences (termed GenQA). This allows for synthesizing the information from multiple candidates into a concise, natural-sounding answer. However, creating large-scale supervised training data for GenQA models is very challenging. In this paper, we propose to train a GenQA model by transferring knowledge from a trained AS2 model, to overcome the aforementioned issue. First, we use an AS2 model to produce a ranking over answer candidates for a set of questions. Then, we use the top ranked candidate as the generation target, and the next k top ranked candidates as context for training a GenQA model. We also propose to use the AS2 model prediction scores for loss weighting and score-conditioned input/output shaping, to aid the knowledge transfer. Our evaluation on three public and one large industrial datasets demonstrates the superiority of our approach over the AS2 baseline, and GenQA trained using supervised data.

</p>
</details>

<details><summary><b>Explicit Second-Order Min-Max Optimization Methods with Optimal Convergence Guarantee</b>
<a href="https://arxiv.org/abs/2210.12860">arxiv:2210.12860</a>
&#x1F4C8; 5 <br>
<p>Tianyi Lin, Panayotis Mertikopoulos, Michael I. Jordan</p></summary>
<p>

**Abstract:** We propose and analyze exact and inexact regularized Newton-type methods for finding a global saddle point of a \textit{convex-concave} unconstrained min-max optimization problem. Compared to their first-order counterparts, investigations of second-order methods for min-max optimization are relatively limited, as obtaining global rates of convergence with second-order information is much more involved. In this paper, we highlight how second-order information can be used to speed up the dynamics of dual extrapolation methods {despite inexactness}. Specifically, we show that the proposed algorithms generate iterates that remain within a bounded set and the averaged iterates converge to an $ε$-saddle point within $O(ε^{-2/3})$ iterations in terms of a gap function. Our algorithms match the theoretically established lower bound in this context and our analysis provides a simple and intuitive convergence analysis for second-order methods without requiring any compactness assumptions. Finally, we present a series of numerical experiments on synthetic and real data that demonstrate the efficiency of the proposed algorithms.

</p>
</details>

<details><summary><b>Respecting Transfer Gap in Knowledge Distillation</b>
<a href="https://arxiv.org/abs/2210.12787">arxiv:2210.12787</a>
&#x1F4C8; 5 <br>
<p>Yulei Niu, Long Chen, Chang Zhou, Hanwang Zhang</p></summary>
<p>

**Abstract:** Knowledge distillation (KD) is essentially a process of transferring a teacher model's behavior, e.g., network response, to a student model. The network response serves as additional supervision to formulate the machine domain, which uses the data collected from the human domain as a transfer set. Traditional KD methods hold an underlying assumption that the data collected in both human domain and machine domain are both independent and identically distributed (IID). We point out that this naive assumption is unrealistic and there is indeed a transfer gap between the two domains. Although the gap offers the student model external knowledge from the machine domain, the imbalanced teacher knowledge would make us incorrectly estimate how much to transfer from teacher to student per sample on the non-IID transfer set. To tackle this challenge, we propose Inverse Probability Weighting Distillation (IPWD) that estimates the propensity score of a training sample belonging to the machine domain, and assigns its inverse amount to compensate for under-represented samples. Experiments on CIFAR-100 and ImageNet demonstrate the effectiveness of IPWD for both two-stage distillation and one-stage self-distillation.

</p>
</details>

<details><summary><b>Drastically Reducing the Number of Trainable Parameters in Deep CNNs by Inter-layer Kernel-sharing</b>
<a href="https://arxiv.org/abs/2210.14151">arxiv:2210.14151</a>
&#x1F4C8; 4 <br>
<p>Alireza Azadbakht, Saeed Reza Kheradpisheh, Ismail Khalfaoui-Hassani, Timothée Masquelier</p></summary>
<p>

**Abstract:** Deep convolutional neural networks (DCNNs) have become the state-of-the-art (SOTA) approach for many computer vision tasks: image classification, object detection, semantic segmentation, etc. However, most SOTA networks are too large for edge computing. Here, we suggest a simple way to reduce the number of trainable parameters and thus the memory footprint: sharing kernels between multiple convolutional layers. Kernel-sharing is only possible between ``isomorphic" layers, i.e.layers having the same kernel size, input and output channels. This is typically the case inside each stage of a DCNN. Our experiments on CIFAR-10 and CIFAR-100, using the ConvMixer and SE-ResNet architectures show that the number of parameters of these models can drastically be reduced with minimal cost on accuracy. The resulting networks are appealing for certain edge computing applications that are subject to severe memory constraints, and even more interesting if leveraging "frozen weights" hardware accelerators. Kernel-sharing is also an efficient regularization method, which can reduce overfitting. The codes are publicly available at https://github.com/AlirezaAzadbakht/kernel-sharing.

</p>
</details>

<details><summary><b>Active Predictive Coding: A Unified Neural Framework for Learning Hierarchical World Models for Perception and Planning</b>
<a href="https://arxiv.org/abs/2210.13461">arxiv:2210.13461</a>
&#x1F4C8; 4 <br>
<p>Rajesh P. N. Rao, Dimitrios C. Gklezakos, Vishwas Sathish</p></summary>
<p>

**Abstract:** Predictive coding has emerged as a prominent model of how the brain learns through predictions, anticipating the importance accorded to predictive learning in recent AI architectures such as transformers. Here we propose a new framework for predictive coding called active predictive coding which can learn hierarchical world models and solve two radically different open problems in AI: (1) how do we learn compositional representations, e.g., part-whole hierarchies, for equivariant vision? and (2) how do we solve large-scale planning problems, which are hard for traditional reinforcement learning, by composing complex action sequences from primitive policies? Our approach exploits hypernetworks, self-supervised learning and reinforcement learning to learn hierarchical world models that combine task-invariant state transition networks and task-dependent policy networks at multiple abstraction levels. We demonstrate the viability of our approach on a variety of vision datasets (MNIST, FashionMNIST, Omniglot) as well as on a scalable hierarchical planning problem. Our results represent, to our knowledge, the first demonstration of a unified solution to the part-whole learning problem posed by Hinton, the nested reference frames problem posed by Hawkins, and the integrated state-action hierarchy learning problem in reinforcement learning.

</p>
</details>

<details><summary><b>Tail Batch Sampling: Approximating Global Contrastive Losses as Optimization over Batch Assignments</b>
<a href="https://arxiv.org/abs/2210.12874">arxiv:2210.12874</a>
&#x1F4C8; 4 <br>
<p>Vin Sachidananda, Ziyi Yang, Chenguang Zhu</p></summary>
<p>

**Abstract:** Contrastive Learning has recently achieved state-of-the-art performance in a wide range of tasks. Many contrastive learning approaches use mined hard negatives to make batches more informative during training but these approaches are inefficient as they increase epoch length proportional to the number of mined negatives and require frequent updates of nearest neighbor indices or mining from recent batches. In this work, we provide an alternative to hard negative mining in supervised contrastive learning, Tail Batch Sampling (TBS), an efficient approximation to the batch assignment problem that upper bounds the gap between the global and training losses, $\mathcal{L}^{Global} - \mathcal{L}^{Train}$. TBS \textbf{improves state-of-the-art performance} in sentence embedding (+0.37 Spearman) and code-search tasks (+2.2\% MRR), is easy to implement - requiring only a few additional lines of code, does not maintain external data structures such as nearest neighbor indices, is more computationally efficient when compared to the most minimal hard negative mining approaches, and makes no changes to the model being trained.

</p>
</details>

<details><summary><b>Decentralized Stochastic Bilevel Optimization with Improved Per-Iteration Complexity</b>
<a href="https://arxiv.org/abs/2210.12839">arxiv:2210.12839</a>
&#x1F4C8; 4 <br>
<p>Xuxing Chen, Minhui Huang, Shiqian Ma, Krishnakumar Balasubramanian</p></summary>
<p>

**Abstract:** Bilevel optimization recently has received tremendous attention due to its great success in solving important machine learning problems like meta learning, reinforcement learning, and hyperparameter optimization. Extending single-agent training on bilevel problems to the decentralized setting is a natural generalization, and there has been a flurry of work studying decentralized bilevel optimization algorithms. However, it remains unknown how to design the distributed algorithm with sample complexity and convergence rate comparable to SGD for stochastic optimization, and at the same time without directly computing the exact Hessian or Jacobian matrices. In this paper we propose such an algorithm. More specifically, we propose a novel decentralized stochastic bilevel optimization (DSBO) algorithm that only requires first order stochastic oracle, Hessian-vector product and Jacobian-vector product oracle. The sample complexity of our algorithm matches the currently best known results for DSBO, and the advantage of our algorithm is that it does not require estimating the full Hessian and Jacobian matrices, thereby having improved per-iteration complexity.

</p>
</details>

<details><summary><b>Symmetric (Optimistic) Natural Policy Gradient for Multi-agent Learning with Parameter Convergence</b>
<a href="https://arxiv.org/abs/2210.12812">arxiv:2210.12812</a>
&#x1F4C8; 4 <br>
<p>Sarath Pattathil, Kaiqing Zhang, Asuman Ozdaglar</p></summary>
<p>

**Abstract:** Multi-agent interactions are increasingly important in the context of reinforcement learning, and the theoretical foundations of policy gradient methods have attracted surging research interest. We investigate the global convergence of natural policy gradient (NPG) algorithms in multi-agent learning. We first show that vanilla NPG may not have parameter convergence, i.e., the convergence of the vector that parameterizes the policy, even when the costs are regularized (which enabled strong convergence guarantees in the policy space in the literature). This non-convergence of parameters leads to stability issues in learning, which becomes especially relevant in the function approximation setting, where we can only operate on low-dimensional parameters, instead of the high-dimensional policy. We then propose variants of the NPG algorithm, for several standard multi-agent learning scenarios: two-player zero-sum matrix and Markov games, and multi-player monotone games, with global last-iterate parameter convergence guarantees. We also generalize the results to certain function approximation settings. Note that in our algorithms, the agents take symmetric roles. Our results might also be of independent interest for solving nonconvex-nonconcave minimax optimization problems with certain structures. Simulations are also provided to corroborate our theoretical findings.

</p>
</details>

<details><summary><b>Manifold Alignment with Label Information</b>
<a href="https://arxiv.org/abs/2210.12774">arxiv:2210.12774</a>
&#x1F4C8; 4 <br>
<p>Andres F. Duque, Myriam Lizotte, Guy Wolf, Kevin R. Moon</p></summary>
<p>

**Abstract:** Multi-domain data is becoming increasingly common and presents both challenges and opportunities in the data science community. The integration of distinct data-views can be used for exploratory data analysis, and benefit downstream analysis including machine learning related tasks. With this in mind, we present a novel manifold alignment method called MALI (Manifold alignment with label information) that learns a correspondence between two distinct domains. MALI can be considered as belonging to a middle ground between the more commonly addressed semi-supervised manifold alignment problem with some known correspondences between the two domains, and the purely unsupervised case, where no known correspondences are provided. To do this, MALI learns the manifold structure in both domains via a diffusion process and then leverages discrete class labels to guide the alignment. By aligning two distinct domains, MALI recovers a pairing and a common representation that reveals related samples in both domains. Additionally, MALI can be used for the transfer learning problem known as domain adaptation. We show that MALI outperforms the current state-of-the-art manifold alignment methods across multiple datasets.

</p>
</details>

<details><summary><b>On Cross-Domain Pre-Trained Language Models for Clinical Text Mining: How Do They Perform on Data-Constrained Fine-Tuning?</b>
<a href="https://arxiv.org/abs/2210.12770">arxiv:2210.12770</a>
&#x1F4C8; 4 <br>
<p>Yuping Wu, Lifeng Han, Valerio Antonini, Goran Nenadic</p></summary>
<p>

**Abstract:** Pre-trained language models (PLMs) have been deployed in many natural language processing (NLP) tasks and in various domains. Language model pre-training from general or mixed domain rich data plus fine-tuning using small amounts of available data in a low resource domain demonstrated beneficial results by researchers. In this work, we question this statement and verify if BERT-based PLMs from the biomedical domain can perform well in clinical text mining tasks via fine-tuning. We test the state-of-the-art models, i.e. Bioformer which is pre-trained on a large amount of biomedical data from PubMed corpus. We use a historical n2c2 clinical NLP challenge dataset for fine-tuning its task-adapted version (BioformerApt), and show that their performances are actually very low. We also present our own end-to-end model, TransformerCRF, which is developed using Transformer and conditional random fields (CRFs) as encoder and decoder. We further create a new variation model by adding a CRF layer on top of PLM Bioformer (BioformerCRF). We investigate the performances of TransformerCRF on clinical text mining tasks by training from scratch using a limited amount of data, as well as the model BioformerCRF. Experimental evaluation shows that, in a \textit{constrained setting}, all tested models are \textit{far from ideal} regarding extreme low-frequency special token recognition, even though they can achieve relatively higher accuracy on overall text tagging. Our models including source codes will be hosted at \url{https://github.com/poethan/TransformerCRF}.

</p>
</details>

<details><summary><b>Functional Indirection Neural Estimator for Better Out-of-distribution Generalization</b>
<a href="https://arxiv.org/abs/2210.12739">arxiv:2210.12739</a>
&#x1F4C8; 4 <br>
<p>Kha Pham, Hung Le, Man Ngo, Truyen Tran</p></summary>
<p>

**Abstract:** The capacity to achieve out-of-distribution (OOD) generalization is a hallmark of human intelligence and yet remains out of reach for machines. This remarkable capability has been attributed to our abilities to make conceptual abstraction and analogy, and to a mechanism known as indirection, which binds two representations and uses one representation to refer to the other. Inspired by these mechanisms, we hypothesize that OOD generalization may be achieved by performing analogy-making and indirection in the functional space instead of the data space as in current methods. To realize this, we design FINE (Functional Indirection Neural Estimator), a neural framework that learns to compose functions that map data input to output on-the-fly. FINE consists of a backbone network and a trainable semantic memory of basis weight matrices. Upon seeing a new input-output data pair, FINE dynamically constructs the backbone weights by mixing the basis weights. The mixing coefficients are indirectly computed through querying a separate corresponding semantic memory using the data pair. We demonstrate empirically that FINE can strongly improve out-of-distribution generalization on IQ tasks that involve geometric transformations. In particular, we train FINE and competing models on IQ tasks using images from the MNIST, Omniglot and CIFAR100 datasets and test on tasks with unseen image classes from one or different datasets and unseen transformation rules. FINE not only achieves the best performance on all tasks but also is able to adapt to small-scale data scenarios.

</p>
</details>

<details><summary><b>Generative Knowledge Graph Construction: A Review</b>
<a href="https://arxiv.org/abs/2210.12714">arxiv:2210.12714</a>
&#x1F4C8; 4 <br>
<p>Hongbin Ye, Ningyu Zhang, Hui Chen, Huajun Chen</p></summary>
<p>

**Abstract:** Generative Knowledge Graph Construction (KGC) refers to those methods that leverage the sequence-to-sequence framework for building knowledge graphs, which is flexible and can be adapted to widespread tasks. In this study, we summarize the recent compelling progress in generative knowledge graph construction. We present the advantages and weaknesses of each paradigm in terms of different generation targets and provide theoretical insight and empirical analysis. Based on the review, we suggest promising research directions for the future. Our contributions are threefold: (1) We present a detailed, complete taxonomy for the generative KGC methods; (2) We provide a theoretical and empirical analysis of the generative KGC methods; (3) We propose several research directions that can be developed in the future.

</p>
</details>

<details><summary><b>Accelerating the training of single-layer binary neural networks using the HHL quantum algorithm</b>
<a href="https://arxiv.org/abs/2210.12707">arxiv:2210.12707</a>
&#x1F4C8; 4 <br>
<p>Sonia Lopez Alarcon, Cory Merkel, Martin Hoffnagle, Sabrina Ly, Alejandro Pozas-Kerstjens</p></summary>
<p>

**Abstract:** Binary Neural Networks are a promising technique for implementing efficient deep models with reduced storage and computational requirements. The training of these is however, still a compute-intensive problem that grows drastically with the layer size and data input. At the core of this calculation is the linear regression problem. The Harrow-Hassidim-Lloyd (HHL) quantum algorithm has gained relevance thanks to its promise of providing a quantum state containing the solution of a linear system of equations. The solution is encoded in superposition at the output of a quantum circuit. Although this seems to provide the answer to the linear regression problem for the training neural networks, it also comes with multiple, difficult-to-avoid hurdles. This paper shows, however, that useful information can be extracted from the quantum-mechanical implementation of HHL, and used to reduce the complexity of finding the solution on the classical side.

</p>
</details>

<details><summary><b>TPU-MLIR: A Compiler For TPU Using MLIR</b>
<a href="https://arxiv.org/abs/2210.15016">arxiv:2210.15016</a>
&#x1F4C8; 3 <br>
<p>Pengchao Hu, Man Lu, Lei Wang, Guoyue Jiang</p></summary>
<p>

**Abstract:** Multi-level intermediate representations (MLIR) show great promise for reducing the cost of building domain-specific compilers by providing a reusable and extensible compiler infrastructure. This work presents TPU-MLIR, an end-to-end compiler based on MLIR that deploys pre-trained neural network (NN) models to a custom ASIC called a Tensor Processing Unit (TPU). TPU-MLIR defines two new dialects to implement its functionality: 1. a Tensor operation (TOP) dialect that encodes the deep learning graph semantics and independent of the deep learning framework and 2. a TPU kernel dialect to provide a standard kernel computation on TPU. A NN model is translated to the TOP dialect and then lowered to the TPU dialect for different TPUs according to the chip's configuration. We demonstrate how to use the MLIR pass pipeline to organize and perform optimization on TPU to generate machine code. The paper also presents a verification procedure to ensure the correctness of each transform stage.

</p>
</details>

<details><summary><b>Attention Based Relation Network for Facial Action Units Recognition</b>
<a href="https://arxiv.org/abs/2210.13988">arxiv:2210.13988</a>
&#x1F4C8; 3 <br>
<p>Yao Wei, Haoxiang Wang, Mingze Sun, Jiawang Liu</p></summary>
<p>

**Abstract:** Facial action unit (AU) recognition is essential to facial expression analysis. Since there are highly positive or negative correlations between AUs, some existing AU recognition works have focused on modeling AU relations. However, previous relationship-based approaches typically embed predefined rules into their models and ignore the impact of various AU relations in different crowds. In this paper, we propose a novel Attention Based Relation Network (ABRNet) for AU recognition, which can automatically capture AU relations without unnecessary or even disturbing predefined rules. ABRNet uses several relation learning layers to automatically capture different AU relations. The learned AU relation features are then fed into a self-attention fusion module, which aims to refine individual AU features with attention weights to enhance the feature robustness. Furthermore, we propose an AU relation dropout strategy and AU relation loss (AUR-Loss) to better model AU relations, which can further improve AU recognition. Extensive experiments show that our approach achieves state-of-the-art performance on the DISFA and DISFA+ datasets.

</p>
</details>

<details><summary><b>Enhancing Label Consistency on Document-level Named Entity Recognition</b>
<a href="https://arxiv.org/abs/2210.12949">arxiv:2210.12949</a>
&#x1F4C8; 3 <br>
<p>Minbyul Jeong, Jaewoo Kang</p></summary>
<p>

**Abstract:** Named entity recognition (NER) is a fundamental part of extracting information from documents in biomedical applications. A notable advantage of NER is its consistency in extracting biomedical entities in a document context. Although existing document NER models show consistent predictions, they still do not meet our expectations. We investigated whether the adjectives and prepositions within an entity cause a low label consistency, which results in inconsistent predictions. In this paper, we present our method, ConNER, which enhances the label dependency of modifiers (e.g., adjectives and prepositions) to achieve higher label agreement. ConNER refines the draft labels of the modifiers to improve the output representations of biomedical entities. The effectiveness of our method is demonstrated on four popular biomedical NER datasets; in particular, its efficacy is proved on two datasets with 7.5-8.6% absolute improvements in the F1 score. We interpret that our ConNER method is effective on datasets that have intrinsically low label consistency. In the qualitative analysis, we demonstrate how our approach makes the NER model generate consistent predictions. Our code and resources are available at https://github.com/dmis-lab/ConNER/.

</p>
</details>

<details><summary><b>IT-RUDA: Information Theory Assisted Robust Unsupervised Domain Adaptation</b>
<a href="https://arxiv.org/abs/2210.12947">arxiv:2210.12947</a>
&#x1F4C8; 3 <br>
<p>Shima Rashidi, Ruwan Tennakoon, Aref Miri Rekavandi, Papangkorn Jessadatavornwong, Amanda Freis, Garret Huff, Mark Easton, Adrian Mouritz, Reza Hoseinnezhad, Alireza Bab-Hadiashar</p></summary>
<p>

**Abstract:** Distribution shift between train (source) and test (target) datasets is a common problem encountered in machine learning applications. One approach to resolve this issue is to use the Unsupervised Domain Adaptation (UDA) technique that carries out knowledge transfer from a label-rich source domain to an unlabeled target domain. Outliers that exist in either source or target datasets can introduce additional challenges when using UDA in practice. In this paper, $α$-divergence is used as a measure to minimize the discrepancy between the source and target distributions while inheriting robustness, adjustable with a single parameter $α$, as the prominent feature of this measure. Here, it is shown that the other well-known divergence-based UDA techniques can be derived as special cases of the proposed method. Furthermore, a theoretical upper bound is derived for the loss in the target domain in terms of the source loss and the initial $α$-divergence between the two domains. The robustness of the proposed method is validated through testing on several benchmarked datasets in open-set and partial UDA setups where extra classes existing in target and source datasets are considered as outliers.

</p>
</details>

<details><summary><b>Finding Memo: Extractive Memorization in Constrained Sequence Generation Tasks</b>
<a href="https://arxiv.org/abs/2210.12929">arxiv:2210.12929</a>
&#x1F4C8; 3 <br>
<p>Vikas Raunak, Arul Menezes</p></summary>
<p>

**Abstract:** Memorization presents a challenge for several constrained Natural Language Generation (NLG) tasks such as Neural Machine Translation (NMT), wherein the proclivity of neural models to memorize noisy and atypical samples reacts adversely with the noisy (web crawled) datasets. However, previous studies of memorization in constrained NLG tasks have only focused on counterfactual memorization, linking it to the problem of hallucinations. In this work, we propose a new, inexpensive algorithm for extractive memorization (exact training data generation under insufficient context) in constrained sequence generation tasks and use it to study extractive memorization and its effects in NMT. We demonstrate that extractive memorization poses a serious threat to NMT reliability by qualitatively and quantitatively characterizing the memorized samples as well as the model behavior in their vicinity. Based on empirical observations, we develop a simple algorithm which elicits non-memorized translations of memorized samples from the same model, for a large fraction of such samples. Finally, we show that the proposed algorithm could also be leveraged to mitigate memorization in the model through finetuning. We have released the code to reproduce our results at https://github.com/vyraun/Finding-Memo.

</p>
</details>

<details><summary><b>Stochastic Mirror Descent for Large-Scale Sparse Recovery</b>
<a href="https://arxiv.org/abs/2210.12882">arxiv:2210.12882</a>
&#x1F4C8; 3 <br>
<p>Sasila Ilandarideva, Yannis Bekri, Anatoli Juditsky, Vianney Perchet</p></summary>
<p>

**Abstract:** In this paper we discuss an application of Stochastic Approximation to statistical estimation of high-dimensional sparse parameters. The proposed solution reduces to resolving a penalized stochastic optimization problem on each stage of a multistage algorithm; each problem being solved to a prescribed accuracy by the non-Euclidean Composite Stochastic Mirror Descent (CSMD) algorithm. Assuming that the problem objective is smooth and quadratically minorated and stochastic perturbations are sub-Gaussian, our analysis prescribes the method parameters which ensure fast convergence of the estimation error (the radius of a confidence ball of a given norm around the approximate solution). This convergence is linear during the first "preliminary" phase of the routine and is sublinear during the second "asymptotic" phase. We consider an application of the proposed approach to sparse Generalized Linear Regression problem. In this setting, we show that the proposed algorithm attains the optimal convergence of the estimation error under weak assumptions on the regressor distribution. We also present a numerical study illustrating the performance of the algorithm on high-dimensional simulation data.

</p>
</details>

<details><summary><b>Kadabra: Adapting Kademlia for the Decentralized Web</b>
<a href="https://arxiv.org/abs/2210.12858">arxiv:2210.12858</a>
&#x1F4C8; 3 <br>
<p>Yunqi Zhang, Shaileshh Bojja Venkatakrishnan</p></summary>
<p>

**Abstract:** Blockchains have become the catalyst for a growing movement to create a more decentralized Internet. A fundamental operation of applications in a decentralized Internet is data storage and retrieval. As today's blockchains are limited in their storage functionalities, in recent years a number of peer-to-peer data storage networks have emerged based on the Kademlia distributed hash table protocol. However, existing Kademlia implementations are not efficient enough to support fast data storage and retrieval operations necessary for (decentralized) Web applications. In this paper, we present Kadabra, a decentralized protocol for computing the routing table entries in Kademlia to accelerate lookups. Kadabra is motivated by the multi-armed bandit problem, and can automatically adapt to heterogeneity and dynamism in the network. Experimental results show Kadabra achieving between 15-50% lower lookup latencies compared to state-of-the-art baselines.

</p>
</details>

<details><summary><b>Automated Essay Scoring using Transformers</b>
<a href="https://arxiv.org/abs/2210.12809">arxiv:2210.12809</a>
&#x1F4C8; 3 <br>
<p>Kshitij Gupta</p></summary>
<p>

**Abstract:** Despite being investigated for over five decades, the task of automated essay scoring continues to draw a lot of attention in the NLP community, in part because of its commercial and educational values as well as the associated research challenges. Large pre-trained models have made remarkable progress in NLP. Data augmentation techniques have also helped build state-of-the-art models for automated essay scoring. Many works in the past have attempted to solve this problem by using RNNs, LSTMs, etc. This work examines the transformer models like BERT, RoBERTa, etc. We empirically demonstrate the effectiveness of transformer models and data augmentation for automated essay grading across many topics using a single model.

</p>
</details>

<details><summary><b>Retrieve, Reason, and Refine: Generating Accurate and Faithful Patient Instructions</b>
<a href="https://arxiv.org/abs/2210.12777">arxiv:2210.12777</a>
&#x1F4C8; 3 <br>
<p>Fenglin Liu, Bang Yang, Chenyu You, Xian Wu, Shen Ge, Zhangdaihong Liu, Xu Sun, Yang Yang, David A. Clifton</p></summary>
<p>

**Abstract:** The "Patient Instruction" (PI), which contains critical instructional information provided both to carers and to the patient at the time of discharge, is essential for the patient to manage their condition outside hospital. An accurate and easy-to-follow PI can improve the self-management of patients which can in turn reduce hospital readmission rates. However, writing an appropriate PI can be extremely time-consuming for physicians, and is subject to being incomplete or error-prone for (potentially overworked) physicians. Therefore, we propose a new task that can provide an objective means of avoiding incompleteness, while reducing clinical workload: the automatic generation of the PI, which is imagined as being a document that the clinician can review, modify, and approve as necessary (rather than taking the human "out of the loop"). We build a benchmark clinical dataset and propose the Re3Writer, which imitates the working patterns of physicians to first retrieve related working experience from historical PIs written by physicians, then reason related medical knowledge. Finally, it refines the retrieved working experience and reasoned medical knowledge to extract useful information, which is used to generate the PI for previously-unseen patient according to their health records during hospitalization. Our experiments show that, using our method, the performance of five different models can be substantially boosted across all metrics, with up to 20%, 11%, and 19% relative improvements in BLEU-4, ROUGE-L, and METEOR, respectively. Meanwhile, we show results from human evaluations to measure the effectiveness in terms of its usefulness for clinical practice. The code is available at https://github.com/AI-in-Hospitals/Patient-Instructions

</p>
</details>

<details><summary><b>McQueen: a Benchmark for Multimodal Conversational Query Rewrite</b>
<a href="https://arxiv.org/abs/2210.12775">arxiv:2210.12775</a>
&#x1F4C8; 3 <br>
<p>Yifei Yuan, Chen Shi, Runze Wang, Liyi Chen, Feijun Jiang, Yuan You, Wai Lam</p></summary>
<p>

**Abstract:** The task of query rewrite aims to convert an in-context query to its fully-specified version where ellipsis and coreference are completed and referred-back according to the history context. Although much progress has been made, less efforts have been paid to real scenario conversations that involve drawing information from more than one modalities. In this paper, we propose the task of multimodal conversational query rewrite (McQR), which performs query rewrite under the multimodal visual conversation setting. We collect a large-scale dataset named McQueen based on manual annotation, which contains 15k visual conversations and over 80k queries where each one is associated with a fully-specified rewrite version. In addition, for entities appearing in the rewrite, we provide the corresponding image box annotation. We then use the McQueen dataset to benchmark a state-of-the-art method for effectively tackling the McQR task, which is based on a multimodal pre-trained model with pointer generator. Extensive experiments are performed to demonstrate the effectiveness of our model on this task\footnote{The dataset and code of this paper are both available in \url{https://github.com/yfyuan01/MQR}

</p>
</details>

<details><summary><b>Discriminative Language Model as Semantic Consistency Scorer for Prompt-based Few-Shot Text Classification</b>
<a href="https://arxiv.org/abs/2210.12763">arxiv:2210.12763</a>
&#x1F4C8; 3 <br>
<p>Zhipeng Xie, Yahe Li</p></summary>
<p>

**Abstract:** This paper proposes a novel prompt-based finetuning method (called DLM-SCS) for few-shot text classification by utilizing the discriminative language model ELECTRA that is pretrained to distinguish whether a token is original or generated. The underlying idea is that the prompt instantiated with the true label should have higher semantic consistency score than other prompts with false labels. Since a prompt usually consists of several components (or parts), its semantic consistency can be decomposed accordingly. The semantic consistency of each component is then computed by making use of the pretrained ELECTRA model, without introducing extra parameters. Extensive experiments have shown that our model outperforms several state-of-the-art prompt-based few-shot methods.

</p>
</details>

<details><summary><b>BotsTalk: Machine-sourced Framework for Automatic Curation of Large-scale Multi-skill Dialogue Datasets</b>
<a href="https://arxiv.org/abs/2210.12687">arxiv:2210.12687</a>
&#x1F4C8; 3 <br>
<p>Minju Kim, Chaehyeong Kim, Yongho Song, Seung-won Hwang, Jinyoung Yeo</p></summary>
<p>

**Abstract:** To build open-domain chatbots that are able to use diverse communicative skills, we propose a novel framework BotsTalk, where multiple agents grounded to the specific target skills participate in a conversation to automatically annotate multi-skill dialogues. We further present Blended Skill BotsTalk (BSBT), a large-scale multi-skill dialogue dataset comprising 300K conversations. Through extensive experiments, we demonstrate that our dataset can be effective for multi-skill dialogue systems which require an understanding of skill blending as well as skill grounding. Our code and data are available at https://github.com/convei-lab/BotsTalk.

</p>
</details>

<details><summary><b>Holistic Interaction Transformer Network for Action Detection</b>
<a href="https://arxiv.org/abs/2210.12686">arxiv:2210.12686</a>
&#x1F4C8; 3 <br>
<p>Gueter Josmy Faure, Min-Hung Chen, Shang-Hong Lai</p></summary>
<p>

**Abstract:** Actions are about how we interact with the environment, including other people, objects, and ourselves. In this paper, we propose a novel multi-modal Holistic Interaction Transformer Network (HIT) that leverages the largely ignored, but critical hand and pose information essential to most human actions. The proposed "HIT" network is a comprehensive bi-modal framework that comprises an RGB stream and a pose stream. Each of them separately models person, object, and hand interactions. Within each sub-network, an Intra-Modality Aggregation module (IMA) is introduced that selectively merges individual interaction units. The resulting features from each modality are then glued using an Attentive Fusion Mechanism (AFM). Finally, we extract cues from the temporal context to better classify the occurring actions using cached memory. Our method significantly outperforms previous approaches on the J-HMDB, UCF101-24, and MultiSports datasets. We also achieve competitive results on AVA. The code will be available at https://github.com/joslefaure/HIT.

</p>
</details>

<details><summary><b>Extending Phrase Grounding with Pronouns in Visual Dialogues</b>
<a href="https://arxiv.org/abs/2210.12658">arxiv:2210.12658</a>
&#x1F4C8; 3 <br>
<p>Panzhong Lu, Xin Zhang, Meishan Zhang, Min Zhang</p></summary>
<p>

**Abstract:** Conventional phrase grounding aims to localize noun phrases mentioned in a given caption to their corresponding image regions, which has achieved great success recently. Apparently, sole noun phrase grounding is not enough for cross-modal visual language understanding. Here we extend the task by considering pronouns as well. First, we construct a dataset of phrase grounding with both noun phrases and pronouns to image regions. Based on the dataset, we test the performance of phrase grounding by using a state-of-the-art literature model of this line. Then, we enhance the baseline grounding model with coreference information which should help our task potentially, modeling the coreference structures with graph convolutional networks. Experiments on our dataset, interestingly, show that pronouns are easier to ground than noun phrases, where the possible reason might be that these pronouns are much less ambiguous. Additionally, our final model with coreference information can significantly boost the grounding performance of both noun phrases and pronouns.

</p>
</details>

<details><summary><b>Unsupervised Non-transferable Text Classification</b>
<a href="https://arxiv.org/abs/2210.12651">arxiv:2210.12651</a>
&#x1F4C8; 3 <br>
<p>Guangtao Zeng, Wei Lu</p></summary>
<p>

**Abstract:** Training a good deep learning model requires substantial data and computing resources, which makes the resulting neural model a valuable intellectual property. To prevent the neural network from being undesirably exploited, non-transferable learning has been proposed to reduce the model generalization ability in specific target domains. However, existing approaches require labeled data for the target domain which can be difficult to obtain. Furthermore, they do not have the mechanism to still recover the model's ability to access the target domain. In this paper, we propose a novel unsupervised non-transferable learning method for the text classification task that does not require annotated target domain data. We further introduce a secret key component in our approach for recovering the access to the target domain, where we design both an explicit and an implicit method for doing so. Extensive experiments demonstrate the effectiveness of our approach.

</p>
</details>

<details><summary><b>Ares: A System-Oriented Wargame Framework for Adversarial ML</b>
<a href="https://arxiv.org/abs/2210.12952">arxiv:2210.12952</a>
&#x1F4C8; 2 <br>
<p>Farhan Ahmed, Pratik Vaishnavi, Kevin Eykholt, Amir Rahmati</p></summary>
<p>

**Abstract:** Since the discovery of adversarial attacks against machine learning models nearly a decade ago, research on adversarial machine learning has rapidly evolved into an eternal war between defenders, who seek to increase the robustness of ML models against adversarial attacks, and adversaries, who seek to develop better attacks capable of weakening or defeating these defenses. This domain, however, has found little buy-in from ML practitioners, who are neither overtly concerned about these attacks affecting their systems in the real world nor are willing to trade off the accuracy of their models in pursuit of robustness against these attacks.
  In this paper, we motivate the design and implementation of Ares, an evaluation framework for adversarial ML that allows researchers to explore attacks and defenses in a realistic wargame-like environment. Ares frames the conflict between the attacker and defender as two agents in a reinforcement learning environment with opposing objectives. This allows the introduction of system-level evaluation metrics such as time to failure and evaluation of complex strategies such as moving target defenses. We provide the results of our initial exploration involving a white-box attacker against an adversarially trained defender.

</p>
</details>

<details><summary><b>Multi-Agent Path Finding via Tree LSTM</b>
<a href="https://arxiv.org/abs/2210.12933">arxiv:2210.12933</a>
&#x1F4C8; 2 <br>
<p>Yuhao Jiang, Kunjie Zhang, Qimai Li, Jiaxin Chen, Xiaolong Zhu</p></summary>
<p>

**Abstract:** In recent years, Multi-Agent Path Finding (MAPF) has attracted attention from the fields of both Operations Research (OR) and Reinforcement Learning (RL). However, in the 2021 Flatland3 Challenge, a competition on MAPF, the best RL method scored only 27.9, far less than the best OR method. This paper proposes a new RL solution to Flatland3 Challenge, which scores 125.3, several times higher than the best RL solution before. We creatively apply a novel network architecture, TreeLSTM, to MAPF in our solution. Together with several other RL techniques, including reward shaping, multiple-phase training, and centralized control, our solution is comparable to the top 2-3 OR methods.

</p>
</details>

<details><summary><b>Removing Radio Frequency Interference from Auroral Kilometric Radiation with Stacked Autoencoders</b>
<a href="https://arxiv.org/abs/2210.12931">arxiv:2210.12931</a>
&#x1F4C8; 2 <br>
<p>Allen Chang, Mary Knapp, James LaBelle, John Swoboda, Ryan Volz, Philip J. Erickson</p></summary>
<p>

**Abstract:** Radio frequency data in astronomy enable scientists to analyze astrophysical phenomena. However, these data can be corrupted by a host of radio frequency interference (RFI) sources that limit the ability to observe underlying natural processes. In this study, we extended recent work in image processing to remove RFI from time-frequency spectrograms containing auroral kilometric radiation (AKR), a coherent radio emission originating from the Earth's auroral zones that is used to study astrophysical plasmas. We present a Denoising Autoencoder for Auroral Radio Emissions (DAARE) trained with synthetic spectrograms to denoise AKR spectrograms collected at the South Pole Station. DAARE achieved 42.2 peak-signal-to-noise ratio (PSNR) and 0.981 structural similarity (SSIM) on synthesized AKR observations, improving PSNR by 3.9 and SSIM by 0.064 compared to state-of-the-art filtering and denoising networks. Qualitative comparisons demonstrate DAARE's denoising capability to effectively remove RFI from real AKR observations, despite being trained completely on a dataset of simulated AKR. The framework for simulating AKR, training DAARE, and employing DAARE can be accessed at https://github.com/Cylumn/daare.

</p>
</details>

<details><summary><b>TIARA: Multi-grained Retrieval for Robust Question Answering over Large Knowledge Bases</b>
<a href="https://arxiv.org/abs/2210.12925">arxiv:2210.12925</a>
&#x1F4C8; 2 <br>
<p>Yiheng Shu, Zhiwei Yu, Yuhan Li, Börje F. Karlsson, Tingting Ma, Yuzhong Qu, Chin-Yew Lin</p></summary>
<p>

**Abstract:** Pre-trained language models (PLMs) have shown their effectiveness in multiple scenarios. However, KBQA remains challenging, especially regarding coverage and generalization settings. This is due to two main factors: i) understanding the semantics of both questions and relevant knowledge from the KB; ii) generating executable logical forms with both semantic and syntactic correctness. In this paper, we present a new KBQA model, TIARA, which addresses those issues by applying multi-grained retrieval to help the PLM focus on the most relevant KB contexts, viz., entities, exemplary logical forms, and schema items. Moreover, constrained decoding is used to control the output space and reduce generation errors. Experiments over important benchmarks demonstrate the effectiveness of our approach. TIARA outperforms previous SOTA, including those using PLMs or oracle entity annotations, by at least 4.1 and 1.1 F1 points on GrailQA and WebQuestionsSP, respectively.

</p>
</details>

<details><summary><b>BARS: A Benchmark for Airport Runway Segmentation</b>
<a href="https://arxiv.org/abs/2210.12922">arxiv:2210.12922</a>
&#x1F4C8; 2 <br>
<p>Wenhui Chen, Zhijiang Zhang, Liang Yu, Yichun Tai</p></summary>
<p>

**Abstract:** Airport runway segmentation can effectively reduce the accident rate during the landing phase, which has the largest risk of flight accidents. With the rapid development of deep learning, related methods have good performance on segmentation tasks and can be well adapted to complex scenes. However, the lack of large-scale, publicly available datasets in this field makes the development of methods based on deep learning difficult. Therefore, we propose a Benchmark for Airport Runway Segmentation, named BARS. Meanwhile, a semi-automatic annotation pipeline is designed to reduce the workload of annotation. BARS has the largest dataset with the richest categories and the only instance annotation in the field. The dataset, which is collected using the X-Plane simulation platform, contains 10,002 images and 29,347 instances with three categories. We evaluate eight representative instance segmentation methods on BARS and analyze their performance. Based on the characteristic of the airport runway with a regular shape, we propose a plug-and-play smoothing post-processing module (SPPM) and a contour point constraint loss (CPCL) function to smooth segmentation results for mask-based and contour-based methods, respectively. Furthermore, a novel evaluation metric named average smoothness (AS) is developed to measure smoothness. The experiments show that existing instance segmentation methods can achieve prediction results with good performance on BARS. SPPM and CPCL can improve the average accuracy by 0.9% and 1.13%, respectively. And the average smoothness enhancements for SPPM and CPCL are more than 50% and 28%, respectively. Our work will be released at https://github.com/c-wenhui/BARS.

</p>
</details>

<details><summary><b>Specializing Multi-domain NMT via Penalizing Low Mutual Information</b>
<a href="https://arxiv.org/abs/2210.12910">arxiv:2210.12910</a>
&#x1F4C8; 2 <br>
<p>Jiyoung Lee, Hantae Kim, Hyunchang Cho, Edward Choi, Cheonbok Park</p></summary>
<p>

**Abstract:** Multi-domain Neural Machine Translation (NMT) trains a single model with multiple domains. It is appealing because of its efficacy in handling multiple domains within one model. An ideal multi-domain NMT should learn distinctive domain characteristics simultaneously, however, grasping the domain peculiarity is a non-trivial task. In this paper, we investigate domain-specific information through the lens of mutual information (MI) and propose a new objective that penalizes low MI to become higher. Our method achieved the state-of-the-art performance among the current competitive multi-domain NMT models. Also, we empirically show our objective promotes low MI to be higher resulting in domain-specialized multi-domain NMT.

</p>
</details>

<details><summary><b>AACHER: Assorted Actor-Critic Deep Reinforcement Learning with Hindsight Experience Replay</b>
<a href="https://arxiv.org/abs/2210.12892">arxiv:2210.12892</a>
&#x1F4C8; 2 <br>
<p>Adarsh Sehgal, Muskan Sehgal, Hung Manh La</p></summary>
<p>

**Abstract:** Actor learning and critic learning are two components of the outstanding and mostly used Deep Deterministic Policy Gradient (DDPG) reinforcement learning method. Since actor and critic learning plays a significant role in the overall robot's learning, the performance of the DDPG approach is relatively sensitive and unstable as a result. We propose a multi-actor-critic DDPG for reliable actor-critic learning to further enhance the performance and stability of DDPG. This multi-actor-critic DDPG is then integrated with Hindsight Experience Replay (HER) to form our new deep learning framework called AACHER. AACHER uses the average value of multiple actors or critics to substitute the single actor or critic in DDPG to increase resistance in the case when one actor or critic performs poorly. Numerous independent actors and critics can also gain knowledge from the environment more broadly. We implemented our proposed AACHER on goal-based environments: AuboReach, FetchReach-v1, FetchPush-v1, FetchSlide-v1, and FetchPickAndPlace-v1. For our experiments, we used various instances of actor/critic combinations, among which A10C10 and A20C20 were the best-performing combinations. Overall results show that AACHER outperforms the traditional algorithm (DDPG+HER) in all of the actor/critic number combinations that are used for evaluation. When used on FetchPickAndPlace-v1, the performance boost for A20C20 is as high as roughly 3.8 times the success rate in DDPG+HER.

</p>
</details>

<details><summary><b>A Greek Parliament Proceedings Dataset for Computational Linguistics and Political Analysis</b>
<a href="https://arxiv.org/abs/2210.12883">arxiv:2210.12883</a>
&#x1F4C8; 2 <br>
<p>Konstantina Dritsa, Kaiti Thoma, John Pavlopoulos, Panos Louridas</p></summary>
<p>

**Abstract:** Large, diachronic datasets of political discourse are hard to come across, especially for resource-lean languages such as Greek. In this paper, we introduce a curated dataset of the Greek Parliament Proceedings that extends chronologically from 1989 up to 2020. It consists of more than 1 million speeches with extensive metadata, extracted from 5,355 parliamentary record files. We explain how it was constructed and the challenges that we had to overcome. The dataset can be used for both computational linguistics and political analysis-ideally, combining the two. We present such an application, showing (i) how the dataset can be used to study the change of word usage through time, (ii) between significant historical events and political parties, (iii) by evaluating and employing algorithms for detecting semantic shifts.

</p>
</details>

<details><summary><b>Deep Equilibrium Approaches to Diffusion Models</b>
<a href="https://arxiv.org/abs/2210.12867">arxiv:2210.12867</a>
&#x1F4C8; 2 <br>
<p>Ashwini Pokle, Zhengyang Geng, Zico Kolter</p></summary>
<p>

**Abstract:** Diffusion-based generative models are extremely effective in generating high-quality images, with generated samples often surpassing the quality of those produced by other models under several metrics. One distinguishing feature of these models, however, is that they typically require long sampling chains to produce high-fidelity images. This presents a challenge not only from the lenses of sampling time, but also from the inherent difficulty in backpropagating through these chains in order to accomplish tasks such as model inversion, i.e. approximately finding latent states that generate known images. In this paper, we look at diffusion models through a different perspective, that of a (deep) equilibrium (DEQ) fixed point model. Specifically, we extend the recent denoising diffusion implicit model (DDIM; Song et al. 2020), and model the entire sampling chain as a joint, multivariate fixed point system. This setup provides an elegant unification of diffusion and equilibrium models, and shows benefits in 1) single image sampling, as it replaces the fully-serial typical sampling process with a parallel one; and 2) model inversion, where we can leverage fast gradients in the DEQ setting to much more quickly find the noise that generates a given image. The approach is also orthogonal and thus complementary to other methods used to reduce the sampling time, or improve model inversion. We demonstrate our method's strong performance across several datasets, including CIFAR10, CelebA, and LSUN Bedrooms and Churches.

</p>
</details>

<details><summary><b>K-SAM: Sharpness-Aware Minimization at the Speed of SGD</b>
<a href="https://arxiv.org/abs/2210.12864">arxiv:2210.12864</a>
&#x1F4C8; 2 <br>
<p>Renkun Ni, Ping-yeh Chiang, Jonas Geiping, Micah Goldblum, Andrew Gordon Wilson, Tom Goldstein</p></summary>
<p>

**Abstract:** Sharpness-Aware Minimization (SAM) has recently emerged as a robust technique for improving the accuracy of deep neural networks. However, SAM incurs a high computational cost in practice, requiring up to twice as much computation as vanilla SGD. The computational challenge posed by SAM arises because each iteration requires both ascent and descent steps and thus double the gradient computations. To address this challenge, we propose to compute gradients in both stages of SAM on only the top-k samples with highest loss. K-SAM is simple and extremely easy-to-implement while providing significant generalization boosts over vanilla SGD at little to no additional cost.

</p>
</details>

<details><summary><b>Towards Pragmatic Production Strategies for Natural Language Generation Tasks</b>
<a href="https://arxiv.org/abs/2210.12828">arxiv:2210.12828</a>
&#x1F4C8; 2 <br>
<p>Mario Giulianelli</p></summary>
<p>

**Abstract:** This position paper proposes a conceptual framework for the design of Natural Language Generation (NLG) systems that follow efficient and effective production strategies in order to achieve complex communicative goals. In this general framework, efficiency is characterised as the parsimonious regulation of production and comprehension costs while effectiveness is measured with respect to task-oriented and contextually grounded communicative goals. We provide concrete suggestions for the estimation of goals, costs, and utility via modern statistical methods, demonstrating applications of our framework to the classic pragmatic task of visually grounded referential games and to abstractive text summarisation, two popular generation tasks with real-world applications. In sum, we advocate for the development of NLG systems that learn to make pragmatic production decisions from experience, by reasoning about goals, costs, and utility in a human-like way.

</p>
</details>

<details><summary><b>O-type Stars Stellar Parameter Estimation Using Recurrent Neural Networks</b>
<a href="https://arxiv.org/abs/2210.12791">arxiv:2210.12791</a>
&#x1F4C8; 2 <br>
<p>Miguel Flores R., Luis J. Corral, Celia R. Fierro-Santillán, Silvana G. Navarro</p></summary>
<p>

**Abstract:** In this paper, we present a deep learning system approach to estimating luminosity, effective temperature, and surface gravity of O-type stars using the optical region of the stellar spectra. In previous work, we compare a set of machine learning and deep learning algorithms in order to establish a reliable way to fit a stellar model using two methods: the classification of the stellar spectra models and the estimation of the physical parameters in a regression-type task. Here we present the process to estimate individual physical parameters from an artificial neural network perspective with the capacity to handle stellar spectra with a low signal-to-noise ratio (S/N), in the $<$20 S/N boundaries. The development of three different recurrent neural network systems, the training process using stellar spectra models, the test over nine different observed stellar spectra, and the comparison with estimations in previous works are presented. Additionally, characterization methods for stellar spectra in order to reduce the dimensionality of the input data for the system and optimize the computational resources are discussed.

</p>
</details>

<details><summary><b>Compressing Explicit Voxel Grid Representations: fast NeRFs become also small</b>
<a href="https://arxiv.org/abs/2210.12782">arxiv:2210.12782</a>
&#x1F4C8; 2 <br>
<p>Chenxi Lola Deng, Enzo Tartaglione</p></summary>
<p>

**Abstract:** NeRFs have revolutionized the world of per-scene radiance field reconstruction because of their intrinsic compactness. One of the main limitations of NeRFs is their slow rendering speed, both at training and inference time. Recent research focuses on the optimization of an explicit voxel grid (EVG) that represents the scene, which can be paired with neural networks to learn radiance fields. This approach significantly enhances the speed both at train and inference time, but at the cost of large memory occupation. In this work we propose Re:NeRF, an approach that specifically targets EVG-NeRFs compressibility, aiming to reduce memory storage of NeRF models while maintaining comparable performance. We benchmark our approach with three different EVG-NeRF architectures on four popular benchmarks, showing Re:NeRF's broad usability and effectiveness.

</p>
</details>

<details><summary><b>VP-SLAM: A Monocular Real-time Visual SLAM with Points, Lines and Vanishing Points</b>
<a href="https://arxiv.org/abs/2210.12756">arxiv:2210.12756</a>
&#x1F4C8; 2 <br>
<p>Andreas Georgis, Panagiotis Mermigkas, Petros Maragos</p></summary>
<p>

**Abstract:** Traditional monocular Visual Simultaneous Localization and Mapping (vSLAM) systems can be divided into three categories: those that use features, those that rely on the image itself, and hybrid models. In the case of feature-based methods, new research has evolved to incorporate more information from their environment using geometric primitives beyond points, such as lines and planes. This is because in many environments, which are man-made environments, characterized as Manhattan world, geometric primitives such as lines and planes occupy most of the space in the environment. The exploitation of these schemes can lead to the introduction of algorithms capable of optimizing the trajectory of a Visual SLAM system and also helping to construct an exuberant map. Thus, we present a real-time monocular Visual SLAM system that incorporates real-time methods for line and VP extraction, as well as two strategies that exploit vanishing points to estimate the robot's translation and improve its rotation.Particularly, we build on ORB-SLAM2, which is considered the current state-of-the-art solution in terms of both accuracy and efficiency, and extend its formulation to handle lines and VPs to create two strategies the first optimize the rotation and the second refine the translation part from the known rotation. First, we extract VPs using a real-time method and use them for a global rotation optimization strategy. Second, we present a translation estimation method that takes advantage of last-stage rotation optimization to model a linear system. Finally, we evaluate our system on the TUM RGB-D benchmark and demonstrate that the proposed system achieves state-of-the-art results and runs in real time, and its performance remains close to the original ORB-SLAM2 system

</p>
</details>

<details><summary><b>A Faithful Deep Sensitivity Estimation for Accelerated Magnetic Resonance Imaging</b>
<a href="https://arxiv.org/abs/2210.12723">arxiv:2210.12723</a>
&#x1F4C8; 2 <br>
<p>Zi Wang, Haoming Fang, Chen Qian, Boxuan Shi, Lijun Bao, Liuhong Zhu, Jianjun Zhou, Wenping Wei, Jianzhong Lin, Di Guo, Xiaobo Qu</p></summary>
<p>

**Abstract:** Recent deep learning is superior in providing high-quality images and ultra-fast reconstructions in accelerated magnetic resonance imaging (MRI). Faithful coil sensitivity estimation is vital for MRI reconstruction. However, most deep learning methods still rely on pre-estimated sensitivity maps and ignore their inaccuracy, resulting in the significant quality degradation of reconstructed images. In this work, we propose a Joint Deep Sensitivity estimation and Image reconstruction network, called JDSI. During the image artifacts removal, it gradually provides more faithful sensitivity maps, leading to greatly improved image reconstructions. To understand the behavior of the network, the mutual promotion of sensitivity estimation and image reconstruction is revealed through the visualization of network intermediate results. Results on in vivo datasets and radiologist reader study demonstrate that, the proposed JDSI achieves the state-of-the-art performance visually and quantitatively, especially when the accelerated factor is high. Additionally, JDSI owns nice robustness to abnormal subjects and different number of autocalibration signals.

</p>
</details>

<details><summary><b>Improving Chinese Named Entity Recognition by Search Engine Augmentation</b>
<a href="https://arxiv.org/abs/2210.12662">arxiv:2210.12662</a>
&#x1F4C8; 2 <br>
<p>Qinghua Mao, Jiatong Li, Kui Meng</p></summary>
<p>

**Abstract:** Compared with English, Chinese suffers from more grammatical ambiguities, like fuzzy word boundaries and polysemous words. In this case, contextual information is not sufficient to support Chinese named entity recognition (NER), especially for rare and emerging named entities. Semantic augmentation using external knowledge is a potential way to alleviate this problem, while how to obtain and leverage external knowledge for the NER task remains a challenge. In this paper, we propose a neural-based approach to perform semantic augmentation using external knowledge from search engine for Chinese NER. In particular, a multi-channel semantic fusion model is adopted to generate the augmented input representations, which aggregates external related texts retrieved from the search engine. Experiments have shown the superiority of our model across 4 NER datasets, including formal and social media language contexts, which further prove the effectiveness of our approach.

</p>
</details>

<details><summary><b>Mapping Process for the Task: Wikidata Statements to Text as Wikipedia Sentences</b>
<a href="https://arxiv.org/abs/2210.12659">arxiv:2210.12659</a>
&#x1F4C8; 2 <br>
<p>Hoang Thang Ta, Alexander Gelbukha, Grigori Sidorov</p></summary>
<p>

**Abstract:** Acknowledged as one of the most successful online cooperative projects in human society, Wikipedia has obtained rapid growth in recent years and desires continuously to expand content and disseminate knowledge values for everyone globally. The shortage of volunteers brings to Wikipedia many issues, including developing content for over 300 languages at the present. Therefore, the benefit that machines can automatically generate content to reduce human efforts on Wikipedia language projects could be considerable. In this paper, we propose our mapping process for the task of converting Wikidata statements to natural language text (WS2T) for Wikipedia projects at the sentence level. The main step is to organize statements, represented as a group of quadruples and triples, and then to map them to corresponding sentences in English Wikipedia. We evaluate the output corpus in various aspects: sentence structure analysis, noise filtering, and relationships between sentence components based on word embedding models. The results are helpful not only for the data-to-text generation task but also for other relevant works in the field.

</p>
</details>

<details><summary><b>SAT: Improving Semi-Supervised Text Classification with Simple Instance-Adaptive Self-Training</b>
<a href="https://arxiv.org/abs/2210.12653">arxiv:2210.12653</a>
&#x1F4C8; 2 <br>
<p>Hui Chen, Wei Han, Soujanya Poria</p></summary>
<p>

**Abstract:** Self-training methods have been explored in recent years and have exhibited great performance in improving semi-supervised learning. This work presents a Simple instance-Adaptive self-Training method (SAT) for semi-supervised text classification. SAT first generates two augmented views for each unlabeled data and then trains a meta-learner to automatically identify the relative strength of augmentations based on the similarity between the original view and the augmented views. The weakly-augmented view is fed to the model to produce a pseudo-label and the strongly-augmented view is used to train the model to predict the same pseudo-label. We conducted extensive experiments and analyses on three text classification datasets and found that with varying sizes of labeled training data, SAT consistently shows competitive performance compared to existing semi-supervised learning methods. Our code can be found at \url{https://github.com/declare-lab/SAT.git}.

</p>
</details>

<details><summary><b>PoKE: Prior Knowledge Enhanced Emotional Support Conversation with Latent Variable</b>
<a href="https://arxiv.org/abs/2210.12640">arxiv:2210.12640</a>
&#x1F4C8; 2 <br>
<p>Xiaohan Xu, Xuying Meng, Yequan Wang</p></summary>
<p>

**Abstract:** Emotional support conversation (ESC) task can utilize various support strategies to help people relieve emotional distress and overcome the problem they face, which have attracted much attention in these years. The emotional support is a critical communication skill that should be trained into dialogue systems. Most existing studies predict support strategy according to current context and provide corresponding emotional support in response. However, these works ignore two significant characteristics of ESC. (a) Abundant prior knowledge exists in historical conversations, such as the responses to similar cases and the general order of support strategies, which has a great reference value for current conversation. (b) There is a one-to-many mapping relationship between context and support strategy, i.e.multiple strategies are reasonable for a single context. It lays a better foundation for the diversity of generations. To take into account these two key factors, we Prior Knowledge Enhanced emotional support conversation with latent variable model, PoKE. The proposed model fully taps the potential of prior knowledge in terms of exemplars and strategy sequence and then utilizes a latent variable to model the one-to-many relationship of support strategy. Furthermore, we introduce a memory schema to effectively incorporate encoded knowledge into decoder. Experiment results on benchmark dataset~(i.e., ESConv) show that our PoKE outperforms existing baselines on both automatic evaluation and human evaluation. Further experiments prove that abundant prior knowledge is conducive to high-quality emotional support, and a well-learned latent variable is critical to the diversity of generations.

</p>
</details>

<details><summary><b>Quantitative Evidence on Overlooked Aspects of Enrollment Speaker Embeddings for Target Speaker Separation</b>
<a href="https://arxiv.org/abs/2210.12635">arxiv:2210.12635</a>
&#x1F4C8; 2 <br>
<p>Xiaoyu Liu, Xu Li, Joan Serrà</p></summary>
<p>

**Abstract:** Single channel target speaker separation (TSS) aims at extracting a speaker's voice from a mixture of multiple talkers given an enrollment utterance of that speaker. A typical deep learning TSS framework consists of an upstream model that obtains enrollment speaker embeddings and a downstream model that performs the separation conditioned on the embeddings. In this paper, we look into several important but overlooked aspects of the enrollment embeddings, including the suitability of the widely used speaker identification embeddings, the introduction of the log-mel filterbank and self-supervised embeddings, and the embeddings' cross-dataset generalization capability. Our results show that the speaker identification embeddings could lose relevant information due to a sub-optimal metric, training objective, or common pre-processing. In contrast, both the filterbank and the self-supervised embeddings preserve the integrity of the speaker information, but the former consistently outperforms the latter in a cross-dataset evaluation. The competitive separation and generalization performance of the previously overlooked filterbank embedding is consistent across our study, which calls for future research on better upstream features.

</p>
</details>

<details><summary><b>Spending Thinking Time Wisely: Accelerating MCTS with Virtual Expansions</b>
<a href="https://arxiv.org/abs/2210.12628">arxiv:2210.12628</a>
&#x1F4C8; 2 <br>
<p>Weirui Ye, Pieter Abbeel, Yang Gao</p></summary>
<p>

**Abstract:** One of the most important AI research questions is to trade off computation versus performance since ``perfect rationality" exists in theory but is impossible to achieve in practice. Recently, Monte-Carlo tree search (MCTS) has attracted considerable attention due to the significant performance improvement in various challenging domains. However, the expensive time cost during search severely restricts its scope for applications. This paper proposes the Virtual MCTS (V-MCTS), a variant of MCTS that spends more search time on harder states and less search time on simpler states adaptively. We give theoretical bounds of the proposed method and evaluate the performance and computations on $9 \times 9$ Go board games and Atari games. Experiments show that our method can achieve comparable performances to the original search algorithm while requiring less than $50\%$ search time on average. We believe that this approach is a viable alternative for tasks under limited time and resources. The code is available at \url{https://github.com/YeWR/V-MCTS.git}.

</p>
</details>

<details><summary><b>A Neural Network Based Automated IFT-20 Sensory Neuron Classifier for Caenorhabditis elegans</b>
<a href="https://arxiv.org/abs/2210.14961">arxiv:2210.14961</a>
&#x1F4C8; 1 <br>
<p>Arvind Seshan</p></summary>
<p>

**Abstract:** Determining neuronal identity in imaging data is an essential task in neuroscience, facilitating the comparison of neural activity across organisms. Cross-organism comparison, in turn, enables a wide variety of research including whole-brain analysis of functional networks and linking the activity of specific neurons to behavior or environmental stimuli. The recent development of three-dimensional, pan-neuronal imaging with single-cell resolution within Caenorhabditis elegans has brought neuron identification, tracking, and activity monitoring all within reach. The nematode C. elegans is often used as a model organism to study neuronal activity due to factors such as its transparency and well-understood nervous system. The principal barrier to high-accuracy neuron identification is that in adult C. elegans, the position of neuronal cell bodies is not stereotyped. Existing approaches to address this issue use genetically encoded markers as an additional identifying feature. For example, the NeuroPAL strain uses multicolored fluorescent reporters. However, this approach has limited use due to the negative effects of excessive genetic modification. In this study, I propose an alternative neuronal identification technique using only single-color fluorescent images. I designed a novel neural network based classifier that automatically labels sensory neurons using an iterative, landmark-based neuron identification process inspired by the manual annotation procedures that humans employ. This design labels sensory neurons in C. elegans with 91.61% accuracy.

</p>
</details>

<details><summary><b>Deep Edge Intelligence: Architecture, Key Features, Enabling Technologies and Challenges</b>
<a href="https://arxiv.org/abs/2210.12944">arxiv:2210.12944</a>
&#x1F4C8; 1 <br>
<p>Prabath Abeysekara, Hai Dong, A. K. Qin</p></summary>
<p>

**Abstract:** With the breakthroughs in Deep Learning, recent years have witnessed a massive surge in Artificial Intelligence applications and services. Meanwhile, the rapid advances in Mobile Computing and Internet of Things has also given rise to billions of mobile and smart sensing devices connected to the Internet, generating zettabytes of data at the network edge. The opportunity to combine these two domains of technologies to power interconnected devices with intelligence is likely to pave the way for a new wave of technology revolutions. Embracing this technology revolution, in this article, we present a novel computing vision named Deep Edge Intelligence (DEI). DEI employs Deep Learning, Artificial Intelligence, Cloud and Edge Computing, 5G/6G networks, Internet of Things, Microservices, etc. aiming to provision reliable and secure intelligence services to every person and organisation at any place with better user experience. The vision, system architecture, key layers and features of DEI are also detailed. Finally, we reveal the key enabling technologies and research challenges associated with it.

</p>
</details>

<details><summary><b>Heterogeneous Information Crossing on Graphs for Session-based Recommender Systems</b>
<a href="https://arxiv.org/abs/2210.12940">arxiv:2210.12940</a>
&#x1F4C8; 1 <br>
<p>Xiaolin Zheng, Rui Wu, Zhongxuan Han, Chaochao Chen, Linxun Chen, Bing Han</p></summary>
<p>

**Abstract:** Recommender systems are fundamental information filtering techniques to recommend content or items that meet users' personalities and potential needs. As a crucial solution to address the difficulty of user identification and unavailability of historical information, session-based recommender systems provide recommendation services that only rely on users' behaviors in the current session. However, most existing studies are not well-designed for modeling heterogeneous user behaviors and capturing the relationships between them in practical scenarios. To fill this gap, in this paper, we propose a novel graph-based method, namely Heterogeneous Information Crossing on Graphs (HICG). HICG utilizes multiple types of user behaviors in the sessions to construct heterogeneous graphs, and captures users' current interests with their long-term preferences by effectively crossing the heterogeneous information on the graphs. In addition, we also propose an enhanced version, named HICG-CL, which incorporates contrastive learning (CL) technique to enhance item representation ability. By utilizing the item co-occurrence relationships across different sessions, HICG-CL improves the recommendation performance of HICG. We conduct extensive experiments on three real-world recommendation datasets, and the results verify that (i) HICG achieves the state-of-the-art performance by utilizing multiple types of behaviors on the heterogeneous graph. (ii) HICG-CL further significantly improves the recommendation performance of HICG by the proposed contrastive learning module.

</p>
</details>

<details><summary><b>GradMix for nuclei segmentation and classification in imbalanced pathology image datasets</b>
<a href="https://arxiv.org/abs/2210.12938">arxiv:2210.12938</a>
&#x1F4C8; 1 <br>
<p>Tan Nhu Nhat Doan, Kyungeun Kim, Boram Song, Jin Tae Kwak</p></summary>
<p>

**Abstract:** An automated segmentation and classification of nuclei is an essential task in digital pathology. The current deep learning-based approaches require a vast amount of annotated datasets by pathologists. However, the existing datasets are imbalanced among different types of nuclei in general, leading to a substantial performance degradation. In this paper, we propose a simple but effective data augmentation technique, termed GradMix, that is specifically designed for nuclei segmentation and classification. GradMix takes a pair of a major-class nucleus and a rare-class nucleus, creates a customized mixing mask, and combines them using the mask to generate a new rare-class nucleus. As it combines two nuclei, GradMix considers both nuclei and the neighboring environment by using the customized mixing mask. This allows us to generate realistic rare-class nuclei with varying environments. We employed two datasets to evaluate the effectiveness of GradMix. The experimental results suggest that GradMix is able to improve the performance of nuclei segmentation and classification in imbalanced pathology image datasets.

</p>
</details>

<details><summary><b>Predicting the Citation Count and CiteScore of Journals One Year in Advance</b>
<a href="https://arxiv.org/abs/2210.12908">arxiv:2210.12908</a>
&#x1F4C8; 1 <br>
<p>William Croft, Jörg-Rüdiger Sack</p></summary>
<p>

**Abstract:** Prediction of the future performance of academic journals is a task that can benefit a variety of stakeholders including editorial staff, publishers, indexing services, researchers, university administrators and granting agencies. Using historical data on journal performance, this can be framed as a machine learning regression problem. In this work, we study two such regression tasks: 1) prediction of the number of citations a journal will receive during the next calendar year, and 2) prediction of the Elsevier CiteScore a journal will be assigned for the next calendar year. To address these tasks, we first create a dataset of historical bibliometric data for journals indexed in Scopus. We propose the use of neural network models trained on our dataset to predict the future performance of journals. To this end, we perform feature selection and model configuration for a Multi-Layer Perceptron and a Long Short-Term Memory. Through experimental comparisons to heuristic prediction baselines and classical machine learning models, we demonstrate superior performance in our proposed models for the prediction of future citation and CiteScore values.

</p>
</details>

<details><summary><b>SpikeSim: An end-to-end Compute-in-Memory Hardware Evaluation Tool for Benchmarking Spiking Neural Networks</b>
<a href="https://arxiv.org/abs/2210.12899">arxiv:2210.12899</a>
&#x1F4C8; 1 <br>
<p>Abhishek Moitra, Abhiroop Bhattacharjee, Runcong Kuang, Gokul Krishnan, Yu Cao, Priyadarshini Panda</p></summary>
<p>

**Abstract:** SNNs are an active research domain towards energy efficient machine intelligence. Compared to conventional ANNs, SNNs use temporal spike data and bio-plausible neuronal activation functions such as Leaky-Integrate Fire/Integrate Fire (LIF/IF) for data processing. However, SNNs incur significant dot-product operations causing high memory and computation overhead in standard von-Neumann computing platforms. Today, In-Memory Computing (IMC) architectures have been proposed to alleviate the "memory-wall bottleneck" prevalent in von-Neumann architectures. Although recent works have proposed IMC-based SNN hardware accelerators, the following have been overlooked- 1) the adverse effects of crossbar non-ideality on SNN performance due to repeated analog dot-product operations over multiple time-steps, 2) hardware overheads of essential SNN-specific components such as the LIF/IF and data communication modules. To this end, we propose SpikeSim, a tool that can perform realistic performance, energy, latency and area evaluation of IMC-mapped SNNs. SpikeSim consists of a practical monolithic IMC architecture called SpikeFlow for mapping SNNs. Additionally, the non-ideality computation engine (NICE) and energy-latency-area (ELA) engine performs hardware-realistic evaluation of SpikeFlow-mapped SNNs. Based on 65nm CMOS implementation and experiments on CIFAR10, CIFAR100 and TinyImagenet datasets, we find that the LIF/IF neuronal module has significant area contribution (>11% of the total hardware area). We propose SNN topological modifications leading to 1.24x and 10x reduction in the neuronal module's area and the overall energy-delay-product value, respectively. Furthermore, in this work, we perform a holistic comparison between IMC implemented ANN and SNNs and conclude that lower number of time-steps are the key to achieve higher throughput and energy-efficiency for SNNs compared to 4-bit ANNs.

</p>
</details>

<details><summary><b>Socio-cognitive Optimization of Time-delay Control Problems using Evolutionary Metaheuristics</b>
<a href="https://arxiv.org/abs/2210.12872">arxiv:2210.12872</a>
&#x1F4C8; 1 <br>
<p>Piotr Kipinski, Hubert Guzowski, Aleksandra Urbanczyk, Maciej Smolka, Marek Kisiel-Dorohinicki, Aleksander Byrski, Zuzana Kominkova Oplatkova, Roman Senkerik, Libor Pekar, Radek Matusu, Frantisek Gazdos</p></summary>
<p>

**Abstract:** Metaheuristics are universal optimization algorithms which should be used for solving difficult problems, unsolvable by classic approaches. In this paper we aim at constructing novel socio-cognitive metaheuristic based on castes, and apply several versions of this algorithm to optimization of time-delay system model. Besides giving the background and the details of the proposed algorithms we apply them to optimization of selected variants of the problem and discuss the results.

</p>
</details>

<details><summary><b>Tighter Abstract Queries in Neural Network Verification</b>
<a href="https://arxiv.org/abs/2210.12871">arxiv:2210.12871</a>
&#x1F4C8; 1 <br>
<p>Elazar Cohen, Yizhak Yisrael Elboher, Clark Barrett, Guy Katz</p></summary>
<p>

**Abstract:** Neural networks have become critical components of reactive systems in various domains within computer science. Despite their excellent performance, using neural networks entails numerous risks that stem from our lack of ability to understand and reason about their behavior. Due to these risks, various formal methods have been proposed for verifying neural networks; but unfortunately, these typically struggle with scalability barriers. Recent attempts have demonstrated that abstraction-refinement approaches could play a significant role in mitigating these limitations; but these approaches can often produce networks that are so abstract, that they become unsuitable for verification. To deal with this issue, we present CEGARETTE, a novel verification mechanism where both the system and the property are abstracted and refined simultaneously. We observe that this approach allows us to produce abstract networks which are both small and sufficiently accurate, allowing for quick verification times while avoiding a large number of refinement steps. For evaluation purposes, we implemented CEGARETTE as an extension to the recently proposed CEGAR-NN framework. Our results are very promising, and demonstrate a significant improvement in performance over multiple benchmarks.

</p>
</details>

<details><summary><b>Learning to Advise Humans By Leveraging Algorithm Discretion</b>
<a href="https://arxiv.org/abs/2210.12849">arxiv:2210.12849</a>
&#x1F4C8; 1 <br>
<p>Nicholas Wolczynski, Maytal Saar-Tsechansky, Tong Wang</p></summary>
<p>

**Abstract:** Expert decision-makers (DMs) in high-stakes AI-advised (AIDeT) settings receive and reconcile recommendations from AI systems before making their final decisions. We identify distinct properties of these settings which are key to developing AIDeT models that effectively benefit team performance. First, DMs in AIDeT settings exhibit algorithm discretion behavior (ADB), i.e., an idiosyncratic tendency to imperfectly accept or reject algorithmic recommendations for any given decision task. Second, DMs incur contradiction costs from exerting decision-making resources (e.g., time and effort) when reconciling AI recommendations that contradict their own judgment. Third, the human's imperfect discretion and reconciliation costs introduce the need for the AI to offer advice selectively. We refer to the task of developing AI to advise humans in AIDeT settings as learning to advise and we address this task by first introducing the AIDeT-Learning Framework. Additionally, we argue that leveraging the human partner's ADB is key to maximizing the AIDeT's decision accuracy while regularizing for contradiction costs. Finally, we instantiate our framework to develop TeamRules (TR): an algorithm that produces rule-based models and recommendations for AIDeT settings. TR is optimized to selectively advise a human and to trade-off contradiction costs and team accuracy for a given environment by leveraging the human partner's ADB. Evaluations on synthetic and real-world benchmark datasets with a variety of simulated human accuracy and discretion behaviors show that TR robustly improves the team's objective across settings over interpretable, rule-based alternatives.

</p>
</details>

<details><summary><b>LQGNet: Hybrid Model-Based and Data-Driven Linear Quadratic Stochastic Control</b>
<a href="https://arxiv.org/abs/2210.12803">arxiv:2210.12803</a>
&#x1F4C8; 1 <br>
<p>Solomon Goldgraber Casspi, Oliver Husser, Guy Revach, Nir Shlezinger</p></summary>
<p>

**Abstract:** Stochastic control deals with finding an optimal control signal for a dynamical system in a setting with uncertainty, playing a key role in numerous applications. The linear quadratic Gaussian (LQG) is a widely-used setting, where the system dynamics is represented as a linear Gaussian statespace (SS) model, and the objective function is quadratic. For this setting, the optimal controller is obtained in closed form by the separation principle. However, in practice, the underlying system dynamics often cannot be faithfully captured by a fully known linear Gaussian SS model, limiting its performance. Here, we present LQGNet, a stochastic controller that leverages data to operate under partially known dynamics. LQGNet augments the state tracking module of separation-based control with a dedicated trainable algorithm. The resulting system preserves the operation of classic LQG control while learning to cope with partially known SS models without having to fully identify the dynamics. We empirically show that LQGNet outperforms classic stochastic control by overcoming mismatched SS models.

</p>
</details>

<details><summary><b>Joint Rigid Motion Correction and Sparse-View CT via Self-Calibrating Neural Field</b>
<a href="https://arxiv.org/abs/2210.12731">arxiv:2210.12731</a>
&#x1F4C8; 1 <br>
<p>Qing Wu, Xin Li, Hongjiang Wei, Jingyi Yu, Yuyao Zhang</p></summary>
<p>

**Abstract:** Neural Radiance Field (NeRF) has widely received attention in Sparse-View (SV) CT reconstruction problems as a self-supervised deep learning framework. NeRF-based SVCT methods model the desired CT image as a continuous function that maps coordinates to intensities and then train a Multi-Layer Perceptron (MLP) to learn the function by minimizing loss on the SV measurement. Thanks to the continuous representation provided by NeRF, the function can be approximated well and thus the high-quality CT image is reconstructed. However, existing NeRF-based SVCT methods strictly suppose there is completely no relative motion during the CT acquisition because they require accurate projection poses to simulate the X-rays that scan the SV sinogram. Therefore, these methods suffer from severe performance drops for real SVCT imaging with motion. To this end, this work proposes a self-calibrating neural field that recovers the artifacts-free image from the rigid motion-corrupted SV measurement without using any external data. Specifically, we parametrize the coarse projection poses caused by rigid motion as trainable variables and then jointly optimize these variables and the MLP. We perform numerical experiments on a public COVID-19 CT dataset. The results indicate that our model significantly outperforms two latest NeRF-based methods for SVCT reconstruction with four different levels of rigid motion.

</p>
</details>

<details><summary><b>DyCSC: Modeling the Evolutionary Process of Dynamic Networks Based on Cluster Structure</b>
<a href="https://arxiv.org/abs/2210.12690">arxiv:2210.12690</a>
&#x1F4C8; 1 <br>
<p>Shanfan Zhang, Zhan Bu</p></summary>
<p>

**Abstract:** Temporal networks are an important type of network whose topological structure changes over time. Compared with methods on static networks, temporal network embedding (TNE) methods are facing three challenges: 1) it cannot describe the temporal dependence across network snapshots; 2) the node embedding in the latent space fails to indicate changes in the network topology; and 3) it cannot avoid a lot of redundant computation via parameter inheritance on a series of snapshots. To this end, we propose a novel temporal network embedding method named Dynamic Cluster Structure Constraint model (DyCSC), whose core idea is to capture the evolution of temporal networks by imposing a temporal constraint on the tendency of the nodes in the network to a given number of clusters. It not only generates low-dimensional embedding vectors for nodes but also preserves the dynamic nonlinear features of temporal networks. Experimental results on multiple realworld datasets have demonstrated the superiority of DyCSC for temporal graph embedding, as it consistently outperforms competing methods by significant margins in multiple temporal link prediction tasks. Moreover, the ablation study further validates the effectiveness of the proposed temporal constraint.

</p>
</details>

<details><summary><b>Fast Beam Alignment via Pure Exploration in Multi-armed Bandits</b>
<a href="https://arxiv.org/abs/2210.12625">arxiv:2210.12625</a>
&#x1F4C8; 1 <br>
<p>Yi Wei, Zixin Zhong, Vincent Y. F. Tan</p></summary>
<p>

**Abstract:** The beam alignment (BA) problem consists in accurately aligning the transmitter and receiver beams to establish a reliable communication link in wireless communication systems. Existing BA methods search the entire beam space to identify the optimal transmit-receive beam pair. This incurs a significant latency when the number of antennas is large. In this work, we develop a bandit-based fast BA algorithm to reduce BA latency for millimeter-wave (mmWave) communications. Our algorithm is named Two-Phase Heteroscedastic Track-and-Stop (2PHT\&S). We first formulate the BA problem as a pure exploration problem in multi-armed bandits in which the objective is to minimize the required number of time steps given a certain fixed confidence level. By taking advantage of the correlation structure among beams that the information from nearby beams is similar and the heteroscedastic property that the variance of the reward of an arm (beam) is related to its mean, the proposed algorithm groups all beams into several beam sets such that the optimal beam set is first selected and the optimal beam is identified in this set after that. Theoretical analysis and simulation results on synthetic and semi-practical channel data demonstrate the clear superiority of the proposed algorithm vis-à-vis other baseline competitors.

</p>
</details>

<details><summary><b>Mitigating Gradient Bias in Multi-objective Learning: A Provably Convergent Stochastic Approach</b>
<a href="https://arxiv.org/abs/2210.12624">arxiv:2210.12624</a>
&#x1F4C8; 1 <br>
<p>Heshan Fernando, Han Shen, Miao Liu, Subhajit Chaudhury, Keerthiram Murugesan, Tianyi Chen</p></summary>
<p>

**Abstract:** Machine learning problems with multiple objective functions appear either in learning with multiple criteria where learning has to make a trade-off between multiple performance metrics such as fairness, safety and accuracy; or, in multi-task learning where multiple tasks are optimized jointly, sharing inductive bias between them. This problems are often tackled by the multi-objective optimization framework. However, existing stochastic multi-objective gradient methods and its variants (e.g., MGDA, PCGrad, CAGrad, etc.) all adopt a biased noisy gradient direction, which leads to degraded empirical performance. To this end, we develop a stochastic Multi-objective gradient Correction (MoCo) method for multi-objective optimization. The unique feature of our method is that it can guarantee convergence without increasing the batch size even in the non-convex setting. Simulations on multi-task supervised and reinforcement learning demonstrate the effectiveness of our method relative to state-of-the-art methods.

</p>
</details>

<details><summary><b>Coupling User Preference with External Rewards to Enable Driver-centered and Resource-aware EV Charging Recommendation</b>
<a href="https://arxiv.org/abs/2210.12693">arxiv:2210.12693</a>
&#x1F4C8; 0 <br>
<p>Chengyin Li, Zheng Dong, Nathan Fisher, Dongxiao Zhu</p></summary>
<p>

**Abstract:** Electric Vehicle (EV) charging recommendation that both accommodates user preference and adapts to the ever-changing external environment arises as a cost-effective strategy to alleviate the range anxiety of private EV drivers. Previous studies focus on centralized strategies to achieve optimized resource allocation, particularly useful for privacy-indifferent taxi fleets and fixed-route public transits. However, private EV driver seeks a more personalized and resource-aware charging recommendation that is tailor-made to accommodate the user preference (when and where to charge) yet sufficiently adaptive to the spatiotemporal mismatch between charging supply and demand. Here we propose a novel Regularized Actor-Critic (RAC) charging recommendation approach that would allow each EV driver to strike an optimal balance between the user preference (historical charging pattern) and the external reward (driving distance and wait time). Experimental results on two real-world datasets demonstrate the unique features and superior performance of our approach to the competing methods.

</p>
</details>


{% endraw %}
Prev: [2022.10.22]({{ '/2022/10/22/2022.10.22.html' | relative_url }})  Next: [2022.10.24]({{ '/2022/10/24/2022.10.24.html' | relative_url }})