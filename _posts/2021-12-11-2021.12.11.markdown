## Summary for 2021-12-11, created on 2021-12-23


<details><summary><b>Programming with Neural Surrogates of Programs</b>
<a href="https://arxiv.org/abs/2112.06148">arxiv:2112.06148</a>
&#x1F4C8; 46 <br>
<p>Alex Renda, Yi Ding, Michael Carbin</p></summary>
<p>

**Abstract:** Surrogates, models that mimic the behavior of programs, form the basis of a variety of development workflows. We study three surrogate-based design patterns, evaluating each in case studies on a large-scale CPU simulator.
  With surrogate compilation, programmers develop a surrogate that mimics the behavior of a program to deploy to end-users in place of the original program. Surrogate compilation accelerates the CPU simulator under study by $1.6\times$. With surrogate adaptation, programmers develop a surrogate of a program then retrain that surrogate on a different task. Surrogate adaptation decreases the simulator's error by up to $50\%$. With surrogate optimization, programmers develop a surrogate of a program, optimize input parameters of the surrogate, then plug the optimized input parameters back into the original program. Surrogate optimization finds simulation parameters that decrease the simulator's error by $5\%$ compared to the error induced by expert-set parameters.
  In this paper we formalize this taxonomy of surrogate-based design patterns. We further describe the programming methodology common to all three design patterns. Our work builds a foundation for the emerging class of workflows based on programming with surrogates of programs.

</p>
</details>

<details><summary><b>Auto-Tag: Tagging-Data-By-Example in Data Lakes</b>
<a href="https://arxiv.org/abs/2112.06049">arxiv:2112.06049</a>
&#x1F4C8; 40 <br>
<p>Yeye He, Jie Song, Yue Wang, Surajit Chaudhuri, Vishal Anil, Blake Lassiter, Yaron Goland, Gaurav Malhotra</p></summary>
<p>

**Abstract:** As data lakes become increasingly popular in large enterprises today, there is a growing need to tag or classify data assets (e.g., files and databases) in data lakes with additional metadata (e.g., semantic column-types), as the inferred metadata can enable a range of downstream applications like data governance (e.g., GDPR compliance), and dataset search. Given the sheer size of today's enterprise data lakes with petabytes of data and millions of data assets, it is imperative that data assets can be ``auto-tagged'', using lightweight inference algorithms and minimal user input. In this work, we develop Auto-Tag, a corpus-driven approach that automates data-tagging of \textit{custom} data types in enterprise data lakes. Using Auto-Tag, users only need to provide \textit{one} example column to demonstrate the desired data-type to tag. Leveraging an index structure built offline using a lightweight scan of the data lake, which is analogous to pre-training in machine learning, Auto-Tag can infer suitable data patterns to best ``describe'' the underlying ``domain'' of the given column at an interactive speed, which can then be used to tag additional data of the same ``type'' in data lakes. The Auto-Tag approach can adapt to custom data-types, and is shown to be both accurate and efficient. Part of Auto-Tag ships as a ``custom-classification'' feature in a cloud-based data governance and catalog solution \textit{Azure Purview}.

</p>
</details>

<details><summary><b>OstrichRL: A Musculoskeletal Ostrich Simulation to Study Bio-mechanical Locomotion</b>
<a href="https://arxiv.org/abs/2112.06061">arxiv:2112.06061</a>
&#x1F4C8; 31 <br>
<p>Vittorio La Barbera, Fabio Pardo, Yuval Tassa, Monica Daley, Christopher Richards, Petar Kormushev, John Hutchinson</p></summary>
<p>

**Abstract:** Muscle-actuated control is a research topic of interest spanning different fields, in particular biomechanics, robotics and graphics. This type of control is particularly challenging because models are often overactuated, and dynamics are delayed and non-linear. It is however a very well tested and tuned actuation model that has undergone millions of years of evolution and that involves interesting properties exploiting passive forces of muscle-tendon units and efficient energy storage and release. To facilitate research on muscle-actuated simulation, we release a 3D musculoskeletal simulation of an ostrich based on the MuJoCo simulator. Ostriches are one of the fastest bipeds on earth and are therefore an excellent model for studying muscle-actuated bipedal locomotion. The model is based on CT scans and dissections used to gather actual muscle data such as insertion sites, lengths and pennation angles. Along with this model, we also provide a set of reinforcement learning tasks, including reference motion tracking and a reaching task with the neck. The reference motion data are based on motion capture clips of various behaviors which we pre-processed and adapted to our model. This paper describes how the model was built and iteratively improved using the tasks. We evaluate the accuracy of the muscle actuation patterns by comparing them to experimentally collected electromyographic data from locomoting birds. We believe that this work can be a useful bridge between the biomechanics, reinforcement learning, graphics and robotics communities, by providing a fast and easy to use simulation.

</p>
</details>

<details><summary><b>ElegantRL-Podracer: Scalable and Elastic Library for Cloud-Native Deep Reinforcement Learning</b>
<a href="https://arxiv.org/abs/2112.05923">arxiv:2112.05923</a>
&#x1F4C8; 10 <br>
<p>Xiao-Yang Liu, Zechu Li, Zhuoran Yang, Jiahao Zheng, Zhaoran Wang, Anwar Walid, Jian Guo, Michael I. Jordan</p></summary>
<p>

**Abstract:** Deep reinforcement learning (DRL) has revolutionized learning and actuation in applications such as game playing and robotic control. The cost of data collection, i.e., generating transitions from agent-environment interactions, remains a major challenge for wider DRL adoption in complex real-world problems. Following a cloud-native paradigm to train DRL agents on a GPU cloud platform is a promising solution. In this paper, we present a scalable and elastic library ElegantRL-podracer for cloud-native deep reinforcement learning, which efficiently supports millions of GPU cores to carry out massively parallel training at multiple levels. At a high-level, ElegantRL-podracer employs a tournament-based ensemble scheme to orchestrate the training process on hundreds or even thousands of GPUs, scheduling the interactions between a leaderboard and a training pool with hundreds of pods. At a low-level, each pod simulates agent-environment interactions in parallel by fully utilizing nearly 7,000 GPU CUDA cores in a single GPU. Our ElegantRL-podracer library features high scalability, elasticity and accessibility by following the development principles of containerization, microservices and MLOps. Using an NVIDIA DGX SuperPOD cloud, we conduct extensive experiments on various tasks in locomotion and stock trading and show that ElegantRL-podracer substantially outperforms RLlib. Our codes are available on GitHub.

</p>
</details>

<details><summary><b>Convergence of Generalized Belief Propagation Algorithm on Graphs with Motifs</b>
<a href="https://arxiv.org/abs/2112.06087">arxiv:2112.06087</a>
&#x1F4C8; 7 <br>
<p>Yitao Chen, Deepanshu Vasal</p></summary>
<p>

**Abstract:** Belief propagation is a fundamental message-passing algorithm for numerous applications in machine learning. It is known that belief propagation algorithm is exact on tree graphs. However, belief propagation is run on loopy graphs in most applications. So, understanding the behavior of belief propagation on loopy graphs has been a major topic for researchers in different areas. In this paper, we study the convergence behavior of generalized belief propagation algorithm on graphs with motifs (triangles, loops, etc.) We show under a certain initialization, generalized belief propagation converges to the global optimum of the Bethe free energy for ferromagnetic Ising models on graphs with motifs.

</p>
</details>

<details><summary><b>Magnifying Networks for Images with Billions of Pixels</b>
<a href="https://arxiv.org/abs/2112.06121">arxiv:2112.06121</a>
&#x1F4C8; 6 <br>
<p>Neofytos Dimitriou, Ognjen Arandjelovic</p></summary>
<p>

**Abstract:** The shift towards end-to-end deep learning has brought unprecedented advances in many areas of computer vision. However, there are cases where the input images are excessively large, deeming end-to-end approaches impossible. In this paper, we introduce a new network, the Magnifying Network (MagNet), which can be trained end-to-end independently of the input image size. MagNets combine convolutional neural networks with differentiable spatial transformers, in a new way, to navigate and successfully learn from images with billions of pixels. Drawing inspiration from the magnifying nature of an ordinary brightfield microscope, a MagNet processes a downsampled version of an image, and without supervision learns how to identify areas that may carry value to the task at hand, upsamples them, and recursively repeats this process on each of the extracted patches. Our results on the publicly available Camelyon16 and Camelyon17 datasets first corroborate to the effectiveness of MagNets and the proposed optimization framework and second, demonstrate the advantage of Magnets' built-in transparency, an attribute of utmost importance for critical processes such as medical diagnosis.

</p>
</details>

<details><summary><b>Selecting Parallel In-domain Sentences for Neural Machine Translation Using Monolingual Texts</b>
<a href="https://arxiv.org/abs/2112.06096">arxiv:2112.06096</a>
&#x1F4C8; 5 <br>
<p>Javad Pourmostafa Roshan Sharami, Dimitar Shterionov, Pieter Spronck</p></summary>
<p>

**Abstract:** Continuously-growing data volumes lead to larger generic models. Specific use-cases are usually left out, since generic models tend to perform poorly in domain-specific cases. Our work addresses this gap with a method for selecting in-domain data from generic-domain (parallel text) corpora, for the task of machine translation. The proposed method ranks sentences in parallel general-domain data according to their cosine similarity with a monolingual domain-specific data set. We then select the top K sentences with the highest similarity score to train a new machine translation system tuned to the specific in-domain data. Our experimental results show that models trained on this in-domain data outperform models trained on generic or a mixture of generic and domain data. That is, our method selects high-quality domain-specific training instances at low computational cost and data size.

</p>
</details>

<details><summary><b>On Automatic Data Augmentation for 3D Point Cloud Classification</b>
<a href="https://arxiv.org/abs/2112.06029">arxiv:2112.06029</a>
&#x1F4C8; 5 <br>
<p>Wanyue Zhang, Xun Xu, Fayao Liu, Le Zhang, Chuan-Sheng Foo</p></summary>
<p>

**Abstract:** Data augmentation is an important technique to reduce overfitting and improve learning performance, but existing works on data augmentation for 3D point cloud data are based on heuristics. In this work, we instead propose to automatically learn a data augmentation strategy using bilevel optimization. An augmentor is designed in a similar fashion to a conditional generator and is optimized by minimizing a base model's loss on a validation set when the augmented input is used for training the model. This formulation provides a more principled way to learn data augmentation on 3D point clouds. We evaluate our approach on standard point cloud classification tasks and a more challenging setting with pose misalignment between training and validation/test sets. The proposed strategy achieves competitive performance on both tasks and we provide further insight into the augmentor's ability to learn the validation set distribution.

</p>
</details>

<details><summary><b>Stereoscopic Universal Perturbations across Different Architectures and Datasets</b>
<a href="https://arxiv.org/abs/2112.06116">arxiv:2112.06116</a>
&#x1F4C8; 4 <br>
<p>Zachary Berger, Parth Agrawal, Tian Yu Liu, Stefano Soatto, Alex Wong</p></summary>
<p>

**Abstract:** We study the effect of adversarial perturbations of images on deep stereo matching networks for the disparity estimation task. We present a method to craft a single set of perturbations that, when added to any stereo image pair in a dataset, can fool a stereo network to significantly alter the perceived scene geometry. Our perturbation images are "universal" in that they not only corrupt estimates of the network on the dataset they are optimized for, but also generalize to stereo networks with different architectures across different datasets. We evaluate our approach on multiple public benchmark datasets and show that our perturbations can increase D1-error (akin to fooling rate) of state-of-the-art stereo networks from 1% to as much as 87%. We investigate the effect of perturbations on the estimated scene geometry and identify object classes that are most vulnerable. Our analysis on the activations of registered points between left and right images led us to find that certain architectural components, i.e. deformable convolution and explicit matching, can increase robustness against adversaries. We demonstrate that by simply designing networks with such components, one can reduce the effect of adversaries by up to 60.5%, which rivals the robustness of networks fine-tuned with costly adversarial data augmentation.

</p>
</details>

<details><summary><b>Improving the Transferability of Adversarial Examples with Resized-Diverse-Inputs, Diversity-Ensemble and Region Fitting</b>
<a href="https://arxiv.org/abs/2112.06011">arxiv:2112.06011</a>
&#x1F4C8; 4 <br>
<p>Junhua Zou, Zhisong Pan, Junyang Qiu, Xin Liu, Ting Rui, Wei Li</p></summary>
<p>

**Abstract:** We introduce a three stage pipeline: resized-diverse-inputs (RDIM), diversity-ensemble (DEM) and region fitting, that work together to generate transferable adversarial examples. We first explore the internal relationship between existing attacks, and propose RDIM that is capable of exploiting this relationship. Then we propose DEM, the multi-scale version of RDIM, to generate multi-scale gradients. After the first two steps we transform value fitting into region fitting across iterations. RDIM and region fitting do not require extra running time and these three steps can be well integrated into other attacks. Our best attack fools six black-box defenses with a 93% success rate on average, which is higher than the state-of-the-art gradient-based attacks. Besides, we rethink existing attacks rather than simply stacking new methods on the old ones to get better performance. It is expected that our findings will serve as the beginning of exploring the internal relationship between attack methods. Codes are available at https://github.com/278287847/DEM.

</p>
</details>

<details><summary><b>Formalising the Foundations of Discrete Reinforcement Learning in Isabelle/HOL</b>
<a href="https://arxiv.org/abs/2112.05996">arxiv:2112.05996</a>
&#x1F4C8; 4 <br>
<p>Mark Chevallier, Jacques Fleuriot</p></summary>
<p>

**Abstract:** We present a formalisation of finite Markov decision processes with rewards in the Isabelle theorem prover. We focus on the foundations required for dynamic programming and the use of reinforcement learning agents over such processes. In particular, we derive the Bellman equation from first principles (in both scalar and vector form), derive a vector calculation that produces the expected value of any policy p, and go on to prove the existence of a universally optimal policy where there is a discounting factor less than one. Lastly, we prove that the value iteration and the policy iteration algorithms work in finite time, producing an epsilon-optimal and a fully optimal policy respectively.

</p>
</details>

<details><summary><b>Interactive Visualization and Representation Analysis Applied to Glacier Segmentation</b>
<a href="https://arxiv.org/abs/2112.08184">arxiv:2112.08184</a>
&#x1F4C8; 3 <br>
<p>Minxing Zheng, Xinran Miao, Kris Sankaran</p></summary>
<p>

**Abstract:** Interpretability has attracted increasing attention in earth observation problems. We apply interactive visualization and representation analysis to guide interpretation of glacier segmentation models. We visualize the activations from a U-Net to understand and evaluate the model performance. We build an online interface using the Shiny R package to provide comprehensive error analysis of the predictions. Users can interact with the panels and discover model failure modes. Further, we discuss how visualization can provide sanity checks during data preprocessing and model training.

</p>
</details>

<details><summary><b>Markov subsampling based Huber Criterion</b>
<a href="https://arxiv.org/abs/2112.06134">arxiv:2112.06134</a>
&#x1F4C8; 3 <br>
<p>Tieliang Gong, Yuxin Dong, Hong Chen, Bo Dong, Chen Li</p></summary>
<p>

**Abstract:** Subsampling is an important technique to tackle the computational challenges brought by big data. Many subsampling procedures fall within the framework of importance sampling, which assigns high sampling probabilities to the samples appearing to have big impacts. When the noise level is high, those sampling procedures tend to pick many outliers and thus often do not perform satisfactorily in practice. To tackle this issue, we design a new Markov subsampling strategy based on Huber criterion (HMS) to construct an informative subset from the noisy full data; the constructed subset then serves as a refined working data for efficient processing. HMS is built upon a Metropolis-Hasting procedure, where the inclusion probability of each sampling unit is determined using the Huber criterion to prevent over scoring the outliers. Under mild conditions, we show that the estimator based on the subsamples selected by HMS is statistically consistent with a sub-Gaussian deviation bound. The promising performance of HMS is demonstrated by extensive studies on large scale simulations and real data examples.

</p>
</details>

<details><summary><b>Controlled-rearing studies of newborn chicks and deep neural networks</b>
<a href="https://arxiv.org/abs/2112.06106">arxiv:2112.06106</a>
&#x1F4C8; 3 <br>
<p>Donsuk Lee, Pranav Gujarathi, Justin N. Wood</p></summary>
<p>

**Abstract:** Convolutional neural networks (CNNs) can now achieve human-level performance on challenging object recognition tasks. CNNs are also the leading quantitative models in terms of predicting neural and behavioral responses in visual recognition tasks. However, there is a widely accepted critique of CNN models: unlike newborn animals, which learn rapidly and efficiently, CNNs are thought to be "data hungry," requiring massive amounts of training data to develop accurate models for object recognition. This critique challenges the promise of using CNNs as models of visual development. Here, we directly examined whether CNNs are more data hungry than newborn animals by performing parallel controlled-rearing experiments on newborn chicks and CNNs. We raised newborn chicks in strictly controlled visual environments, then simulated the training data available in that environment by constructing a virtual animal chamber in a video game engine. We recorded the visual images acquired by an agent moving through the virtual chamber and used those images to train CNNs. When CNNs received similar visual training data as chicks, the CNNs successfully solved the same challenging view-invariant object recognition tasks as the chicks. Thus, the CNNs were not more data hungry than animals: both CNNs and chicks successfully developed robust object models from training data of a single object.

</p>
</details>

<details><summary><b>Synthetic Map Generation to Provide Unlimited Training Data for Historical Map Text Detection</b>
<a href="https://arxiv.org/abs/2112.06104">arxiv:2112.06104</a>
&#x1F4C8; 3 <br>
<p>Zekun Li, Runyu Guan, Qianmu Yu, Yao-Yi Chiang, Craig A. Knoblock</p></summary>
<p>

**Abstract:** Many historical map sheets are publicly available for studies that require long-term historical geographic data. The cartographic design of these maps includes a combination of map symbols and text labels. Automatically reading text labels from map images could greatly speed up the map interpretation and helps generate rich metadata describing the map content. Many text detection algorithms have been proposed to locate text regions in map images automatically, but most of the algorithms are trained on out-ofdomain datasets (e.g., scenic images). Training data determines the quality of machine learning models, and manually annotating text regions in map images is labor-extensive and time-consuming. On the other hand, existing geographic data sources, such as Open- StreetMap (OSM), contain machine-readable map layers, which allow us to separate out the text layer and obtain text label annotations easily. However, the cartographic styles between OSM map tiles and historical maps are significantly different. This paper proposes a method to automatically generate an unlimited amount of annotated historical map images for training text detection models. We use a style transfer model to convert contemporary map images into historical style and place text labels upon them. We show that the state-of-the-art text detection models (e.g., PSENet) can benefit from the synthetic historical maps and achieve significant improvement for historical map text detection.

</p>
</details>

<details><summary><b>Curvature-guided dynamic scale networks for Multi-view Stereo</b>
<a href="https://arxiv.org/abs/2112.05999">arxiv:2112.05999</a>
&#x1F4C8; 3 <br>
<p>Khang Truong Giang, Soohwan Song, Sungho Jo</p></summary>
<p>

**Abstract:** Multi-view stereo (MVS) is a crucial task for precise 3D reconstruction. Most recent studies tried to improve the performance of matching cost volume in MVS by designing aggregated 3D cost volumes and their regularization. This paper focuses on learning a robust feature extraction network to enhance the performance of matching costs without heavy computation in the other steps. In particular, we present a dynamic scale feature extraction network, namely, CDSFNet. It is composed of multiple novel convolution layers, each of which can select a proper patch scale for each pixel guided by the normal curvature of the image surface. As a result, CDFSNet can estimate the optimal patch scales to learn discriminative features for accurate matching computation between reference and source images. By combining the robust extracted features with an appropriate cost formulation strategy, our resulting MVS architecture can estimate depth maps more precisely. Extensive experiments showed that the proposed method outperforms other state-of-the-art methods on complex outdoor scenes. It significantly improves the completeness of reconstructed models. As a result, the method can process higher resolution inputs within faster run-time and lower memory than other MVS methods. Our source code is available at url{https://github.com/TruongKhang/cds-mvsnet}.

</p>
</details>

<details><summary><b>Overview of The MediaEval 2021 Predicting Media Memorability Task</b>
<a href="https://arxiv.org/abs/2112.05982">arxiv:2112.05982</a>
&#x1F4C8; 3 <br>
<p>Rukiye Savran Kiziltepe, Mihai Gabriel Constantin, Claire-Helene Demarty, Graham Healy, Camilo Fosco, Alba Garcia Seco de Herrera, Sebastian Halder, Bogdan Ionescu, Ana Matran-Fernandez, Alan F. Smeaton, Lorin Sweeney</p></summary>
<p>

**Abstract:** This paper describes the MediaEval 2021 Predicting Media Memorability}task, which is in its 4th edition this year, as the prediction of short-term and long-term video memorability remains a challenging task. In 2021, two datasets of videos are used: first, a subset of the TRECVid 2019 Video-to-Text dataset; second, the Memento10K dataset in order to provide opportunities to explore cross-dataset generalisation. In addition, an Electroencephalography (EEG)-based prediction pilot subtask is introduced. In this paper, we outline the main aspects of the task and describe the datasets, evaluation metrics, and requirements for participants' submissions.

</p>
</details>

<details><summary><b>You Only Need End-to-End Training for Long-Tailed Recognition</b>
<a href="https://arxiv.org/abs/2112.05958">arxiv:2112.05958</a>
&#x1F4C8; 3 <br>
<p>Zhiwei Zhang</p></summary>
<p>

**Abstract:** The generalization gap on the long-tailed data sets is largely owing to most categories only occupying a few training samples. Decoupled training achieves better performance by training backbone and classifier separately. What causes the poorer performance of end-to-end model training (e.g., logits margin-based methods)? In this work, we identify a key factor that affects the learning of the classifier: the channel-correlated features with low entropy before inputting into the classifier. From the perspective of information theory, we analyze why cross-entropy loss tends to produce highly correlated features on the imbalanced data. In addition, we theoretically analyze and prove its impacts on the gradients of classifier weights, the condition number of Hessian, and logits margin-based approach. Therefore, we firstly propose to use Channel Whitening to decorrelate ("scatter") the classifier's inputs for decoupling the weight update and reshaping the skewed decision boundary, which achieves satisfactory results combined with logits margin-based method. However, when the number of minor classes are large, batch imbalance and more participation in training cause over-fitting of the major classes. We also propose two novel modules, Block-based Relatively Balanced Batch Sampler (B3RS) and Batch Embedded Training (BET) to solve the above problems, which makes the end-to-end training achieve even better performance than decoupled training. Experimental results on the long-tailed classification benchmarks, CIFAR-LT and ImageNet-LT, demonstrate the effectiveness of our method.

</p>
</details>

<details><summary><b>SPDCinv: Inverse Quantum-Optical Design of High-Dimensional Qudits</b>
<a href="https://arxiv.org/abs/2112.05934">arxiv:2112.05934</a>
&#x1F4C8; 3 <br>
<p>Eyal Rozenberg, Aviv Karnieli, Ofir Yesharim, Joshua Foley-Comer, Sivan Trajtenberg-Mills, Daniel Freedman, Alex M. Bronstein, Ady Arie</p></summary>
<p>

**Abstract:** Spontaneous parametric down-conversion in quantum optics is an invaluable resource for the realization of high-dimensional qudits with spatial modes of light. One of the main open challenges is how to directly generate a desirable qudit state in the SPDC process. This problem can be addressed through advanced computational learning methods; however, due to difficulties in modeling the SPDC process by a fully differentiable algorithm that takes into account all interaction effects, progress has been limited. Here, we overcome these limitations and introduce a physically-constrained and differentiable model, validated against experimental results for shaped pump beams and structured crystals, capable of learning every interaction parameter in the process. We avoid any restrictions induced by the stochastic nature of our physical model and integrate the dynamic equations governing the evolution under the SPDC Hamiltonian. We solve the inverse problem of designing a nonlinear quantum optical system that achieves the desired quantum state of down-converted photon pairs. The desired states are defined using either the second-order correlations between different spatial modes or by specifying the required density matrix. By learning nonlinear volume holograms as well as different pump shapes, we successfully show how to generate maximally entangled states. Furthermore, we simulate all-optical coherent control over the generated quantum state by actively changing the profile of the pump beam. Our work can be useful for applications such as novel designs of high-dimensional quantum key distribution and quantum information processing protocols. In addition, our method can be readily applied for controlling other degrees of freedom of light in the SPDC process, such as the spectral and temporal properties, and may even be used in condensed-matter systems having a similar interaction Hamiltonian.

</p>
</details>

<details><summary><b>Technical Language Supervision for Intelligent Fault Diagnosis in Process Industry</b>
<a href="https://arxiv.org/abs/2112.07356">arxiv:2112.07356</a>
&#x1F4C8; 2 <br>
<p>Karl Löwenmark, Cees Taal, Stephan Schnabel, Marcus Liwicki, Fredrik Sandin</p></summary>
<p>

**Abstract:** In the process industry, condition monitoring systems with automated fault diagnosis methods assisthuman experts and thereby improve maintenance efficiency, process sustainability, and workplace safety.Improving the automated fault diagnosis methods using data and machine learning-based models is a centralaspect of intelligent fault diagnosis (IFD). A major challenge in IFD is to develop realistic datasets withaccurate labels needed to train and validate models, and to transfer models trained with labeled lab datato heterogeneous process industry environments. However, fault descriptions and work-orders written bydomain experts are increasingly digitized in modern condition monitoring systems, for example in the contextof rotating equipment monitoring. Thus, domain-specific knowledge about fault characteristics and severitiesexists as technical language annotations in industrial datasets. Furthermore, recent advances in naturallanguage processing enable weakly supervised model optimization using natural language annotations, mostnotably in the form ofnatural language supervision(NLS). This creates a timely opportunity to developtechnical language supervision(TLS) solutions for IFD systems grounded in industrial data, for exampleas a complement to pre-training with lab data to address problems like overfitting and inaccurate out-of-sample generalisation. We surveyed the literature and identify a considerable improvement in the maturityof NLS over the last two years, facilitating applications beyond natural language; a rapid development ofweak supervision methods; and transfer learning as a current trend in IFD which can benefit from thesedevelopments. Finally, we describe a framework for integration of TLS in IFD which is inspired by recentNLS innovations.

</p>
</details>

<details><summary><b>Two New Stenosis Detection Methods of Coronary Angiograms</b>
<a href="https://arxiv.org/abs/2112.06149">arxiv:2112.06149</a>
&#x1F4C8; 2 <br>
<p>Yaofang Liu, Xinyue Zhang, Wenlong Wan, Shaoyu Liu, Yingdi Liu, Hu Liu, Xueying Zeng, Qing Zhang</p></summary>
<p>

**Abstract:** Coronary angiography is the "gold standard" for diagnosing coronary artery disease (CAD). At present, the methods for detecting and evaluating coronary artery stenosis cannot satisfy the clinical needs, e.g., there is no prior study of detecting stenoses in prespecified vessel segments, which is necessary in clinical practice. Two vascular stenosis detection methods are proposed to assist the diagnosis. The first one is an automatic method, which can automatically extract the entire coronary artery tree and mark all the possible stenoses. The second one is an interactive method. With this method, the user can choose any vessel segment to do further analysis of its stenoses. Experiments show that the proposed methods are robust for angiograms with various vessel structures. The precision, sensitivity, and $F_1$ score of the automatic stenosis detection method are 0.821, 0.757, and 0.788, respectively. Further investigation proves that the interactive method can provide a more precise outcome of stenosis detection, and our quantitative analysis is closer to reality. The proposed automatic method and interactive method are effective and can complement each other in clinical practice. The first method can be used for preliminary screening, and the second method can be used for further quantitative analysis. We believe the proposed solution is more suitable for the clinical diagnosis of CAD.

</p>
</details>

<details><summary><b>Semi-supervised teacher-student deep neural network for materials discovery</b>
<a href="https://arxiv.org/abs/2112.06142">arxiv:2112.06142</a>
&#x1F4C8; 2 <br>
<p>Daniel Gleaves, Edirisuriya M. Dilanga Siriwardane, Yong Zhao, Nihang Fu, Jianjun Hu</p></summary>
<p>

**Abstract:** Data driven generative machine learning models have recently emerged as one of the most promising approaches for new materials discovery. While the generator models can generate millions of candidates, it is critical to train fast and accurate machine learning models to filter out stable, synthesizable materials with desired properties. However, such efforts to build supervised regression or classification screening models have been severely hindered by the lack of unstable or unsynthesizable samples, which usually are not collected and deposited in materials databases such as ICSD and Materials Project (MP). At the same time, there are a significant amount of unlabelled data available in these databases. Here we propose a semi-supervised deep neural network (TSDNN) model for high-performance formation energy and synthesizability prediction, which is achieved via its unique teacher-student dual network architecture and its effective exploitation of the large amount of unlabeled data. For formation energy based stability screening, our semi-supervised classifier achieves an absolute 10.3\% accuracy improvement compared to the baseline CGCNN regression model. For synthesizability prediction, our model significantly increases the baseline PU learning's true positive rate from 87.9\% to 97.9\% using 1/49 model parameters.
  To further prove the effectiveness of our models, we combined our TSDNN-energy and TSDNN-synthesizability models with our CubicGAN generator to discover novel stable cubic structures. Out of 1000 recommended candidate samples by our models, 512 of them have negative formation energies as validated by our DFT formation energy calculations. Our experimental results show that our semi-supervised deep neural networks can significantly improve the screening accuracy in large-scale generative materials design.

</p>
</details>

<details><summary><b>NeuroHSMD: Neuromorphic Hybrid Spiking Motion Detector</b>
<a href="https://arxiv.org/abs/2112.06102">arxiv:2112.06102</a>
&#x1F4C8; 2 <br>
<p>Pedro Machado, Eiman Kanjo, Andreas Oikonomou Ahmad Lotfi</p></summary>
<p>

**Abstract:** Vertebrate retinas are highly-efficient in processing trivial visual tasks such as detecting moving objects, yet a complex task for modern computers. The detection of object motion is done by specialised retinal ganglion cells named Object-motion-sensitive ganglion cells (OMS-GC). OMS-GC process continuous signals and generate spike patterns that are post-processed by the Visual Cortex. The Neuromorphic Hybrid Spiking Motion Detector (NeuroHSMD) proposed in this work accelerates the HSMD algorithm using Field-Programmable Gate Arrays (FPGAs). The Hybrid Spiking Motion Detector (HSMD) algorithm was the first hybrid algorithm to enhance dynamic background subtraction (DBS) algorithms with a customised 3-layer spiking neural network (SNN) that generates OMS-GC spiking-like responses. The NeuroHSMD algorithm was compared against the HSMD algorithm, using the same 2012 change detection (CDnet2012) and 2014 change detection (CDnet2014) benchmark datasets. The results show that the NeuroHSMD has produced the same results as the HSMD algorithm in real-time without degradation of quality. Moreover, the NeuroHSMD proposed in this paper was completely implemented in Open Computer Language (OpenCL) and therefore is easily replicated in other devices such as Graphical Processor Units (GPUs) and clusters of Central Processor Units (CPUs).

</p>
</details>

<details><summary><b>Confidence intervals for the random forest generalization error</b>
<a href="https://arxiv.org/abs/2112.06101">arxiv:2112.06101</a>
&#x1F4C8; 2 <br>
<p>Marques F., Paulo C</p></summary>
<p>

**Abstract:** We show that underneath the training process of a random forest there lies not only the well known and almost computationally free out-of-bag point estimate of its generalization error, but also a path to compute a confidence interval for the generalization error which does not demand a retraining of the forest or any forms of data splitting. Besides the low computational cost involved in its construction, this confidence interval is shown through simulations to have good coverage and appropriate shrinking rate of its width in terms of the training sample size.

</p>
</details>

<details><summary><b>UPV at TREC Health Misinformation Track 2021 Ranking with SBERT and Quality Estimators</b>
<a href="https://arxiv.org/abs/2112.06080">arxiv:2112.06080</a>
&#x1F4C8; 2 <br>
<p>Ipek Baris Schlicht, Angel Felipe Magnossão de Paula, Paolo Rosso</p></summary>
<p>

**Abstract:** Health misinformation on search engines is a significant problem that could negatively affect individuals or public health. To mitigate the problem, TREC organizes a health misinformation track. This paper presents our submissions to this track. We use a BM25 and a domain-specific semantic search engine for retrieving initial documents. Later, we examine a health news schema for quality assessment and apply it to re-rank documents. We merge the scores from the different components by using reciprocal rank fusion. Finally, we discuss the results and conclude with future works.

</p>
</details>

<details><summary><b>Early Stopping for Deep Image Prior</b>
<a href="https://arxiv.org/abs/2112.06074">arxiv:2112.06074</a>
&#x1F4C8; 2 <br>
<p>Hengkang Wang, Taihui Li, Zhong Zhuang, Tiancong Chen, Hengyue Liang, Ju Sun</p></summary>
<p>

**Abstract:** Deep image prior (DIP) and its variants have showed remarkable potential for solving inverse problems in computer vision, without any extra training data. Practical DIP models are often substantially overparameterized. During the fitting process, these models learn mostly the desired visual content first, and then pick up the potential modeling and observational noise, i.e., overfitting. Thus, the practicality of DIP often depends critically on good early stopping (ES) that captures the transition period. In this regard, the majority of DIP works for vision tasks only demonstrates the potential of the models -- reporting the peak performance against the ground truth, but provides no clue about how to operationally obtain near-peak performance without access to the groundtruth. In this paper, we set to break this practicality barrier of DIP, and propose an efficient ES strategy, which consistently detects near-peak performance across several vision tasks and DIP variants. Based on a simple measure of dispersion of consecutive DIP reconstructions, our ES method not only outpaces the existing ones -- which only work in very narrow domains, but also remains effective when combined with a number of methods that try to mitigate the overfitting. The code is available at https://github.com/sun-umn/Early_Stopping_for_DIP.

</p>
</details>

<details><summary><b>MedAttacker: Exploring Black-Box Adversarial Attacks on Risk Prediction Models in Healthcare</b>
<a href="https://arxiv.org/abs/2112.06063">arxiv:2112.06063</a>
&#x1F4C8; 2 <br>
<p>Muchao Ye, Junyu Luo, Guanjie Zheng, Cao Xiao, Ting Wang, Fenglong Ma</p></summary>
<p>

**Abstract:** Deep neural networks (DNNs) have been broadly adopted in health risk prediction to provide healthcare diagnoses and treatments. To evaluate their robustness, existing research conducts adversarial attacks in the white/gray-box setting where model parameters are accessible. However, a more realistic black-box adversarial attack is ignored even though most real-world models are trained with private data and released as black-box services on the cloud. To fill this gap, we propose the first black-box adversarial attack method against health risk prediction models named MedAttacker to investigate their vulnerability. MedAttacker addresses the challenges brought by EHR data via two steps: hierarchical position selection which selects the attacked positions in a reinforcement learning (RL) framework and substitute selection which identifies substitute with a score-based principle. Particularly, by considering the temporal context inside EHRs, it initializes its RL position selection policy by using the contribution score of each visit and the saliency score of each code, which can be well integrated with the deterministic substitute selection process decided by the score changes. In experiments, MedAttacker consistently achieves the highest average success rate and even outperforms a recent white-box EHR adversarial attack technique in certain cases when attacking three advanced health risk prediction models in the black-box setting across multiple real-world datasets. In addition, based on the experiment results we include a discussion on defending EHR adversarial attacks.

</p>
</details>

<details><summary><b>Behavior measures are predicted by how information is encoded in an individual's brain</b>
<a href="https://arxiv.org/abs/2112.06048">arxiv:2112.06048</a>
&#x1F4C8; 2 <br>
<p>Jennifer Williams, Leila Wehbe</p></summary>
<p>

**Abstract:** Similar to how differences in the proficiency of the cardiovascular and musculoskeletal system predict an individual's athletic ability, differences in how the same brain region encodes information across individuals may explain their behavior. However, when studying how the brain encodes information, researchers choose different neuroimaging tasks (e.g., language or motor tasks), which can rely on processing different types of information and can modulate different brain regions. We hypothesize that individual differences in how information is encoded in the brain are task-specific and predict different behavior measures. We propose a framework using encoding-models to identify individual differences in brain encoding and test if these differences can predict behavior. We evaluate our framework using task functional magnetic resonance imaging data. Our results indicate that individual differences revealed by encoding-models are a powerful tool for predicting behavior, and that researchers should optimize their choice of task and encoding-model for their behavior of interest.

</p>
</details>

<details><summary><b>Spatial Graph Convolutional Neural Network via Structured Subdomain Adaptation and Domain Adversarial Learning for Bearing Fault Diagnosis</b>
<a href="https://arxiv.org/abs/2112.06033">arxiv:2112.06033</a>
&#x1F4C8; 2 <br>
<p>Mohammadreza Ghorvei, Mohammadreza Kavianpour, Mohammad TH Beheshti, Amin Ramezani</p></summary>
<p>

**Abstract:** Unsupervised domain adaptation (UDA) has shown remarkable results in bearing fault diagnosis under changing working conditions in recent years. However, most UDA methods do not consider the geometric structure of the data. Furthermore, the global domain adaptation technique is commonly applied, which ignores the relation between subdomains. This paper addresses mentioned challenges by presenting the novel deep subdomain adaptation graph convolution neural network (DSAGCN), which has two key characteristics: First, graph convolution neural network (GCNN) is employed to model the structure of data. Second, adversarial domain adaptation and local maximum mean discrepancy (LMMD) methods are applied concurrently to align the subdomain's distribution and reduce structure discrepancy between relevant subdomains and global domains. CWRU and Paderborn bearing datasets are used to validate the DSAGCN method's efficiency and superiority between comparison models. The experimental results demonstrate the significance of aligning structured subdomains along with domain adaptation methods to obtain an accurate data-driven model in unsupervised fault diagnosis.

</p>
</details>

<details><summary><b>Unsupervised Image to Image Translation for Multiple Retinal Pathology Synthesis in Optical Coherence Tomography Scans</b>
<a href="https://arxiv.org/abs/2112.06031">arxiv:2112.06031</a>
&#x1F4C8; 2 <br>
<p>Hemanth Pasupuleti, G. N. Girish</p></summary>
<p>

**Abstract:** Image to Image Translation (I2I) is a challenging computer vision problem used in numerous domains for multiple tasks. Recently, ophthalmology became one of the major fields where the application of I2I is increasing rapidly. One such application is the generation of synthetic retinal optical coherence tomographic (OCT) scans. Existing I2I methods require training of multiple models to translate images from normal scans to a specific pathology: limiting the use of these models due to their complexity. To address this issue, we propose an unsupervised multi-domain I2I network with pre-trained style encoder that translates retinal OCT images in one domain to multiple domains. We assume that the image splits into domain-invariant content and domain-specific style codes, and pre-train these style codes. The performed experiments show that the proposed model outperforms state-of-the-art models like MUNIT and CycleGAN synthesizing diverse pathological scans.

</p>
</details>

<details><summary><b>Determinantal point processes based on orthogonal polynomials for sampling minibatches in SGD</b>
<a href="https://arxiv.org/abs/2112.06007">arxiv:2112.06007</a>
&#x1F4C8; 2 <br>
<p>Remi Bardenet, Subhro Ghosh, Meixia Lin</p></summary>
<p>

**Abstract:** Stochastic gradient descent (SGD) is a cornerstone of machine learning. When the number N of data items is large, SGD relies on constructing an unbiased estimator of the gradient of the empirical risk using a small subset of the original dataset, called a minibatch. Default minibatch construction involves uniformly sampling a subset of the desired size, but alternatives have been explored for variance reduction. In particular, experimental evidence suggests drawing minibatches from determinantal point processes (DPPs), distributions over minibatches that favour diversity among selected items. However, like in recent work on DPPs for coresets, providing a systematic and principled understanding of how and why DPPs help has been difficult. In this work, we contribute an orthogonal polynomial-based DPP paradigm for minibatch sampling in SGD. Our approach leverages the specific data distribution at hand, which endows it with greater sensitivity and power over existing data-agnostic methods. We substantiate our method via a detailed theoretical analysis of its convergence properties, interweaving between the discrete data set and the underlying continuous domain. In particular, we show how specific DPPs and a string of controlled approximations can lead to gradient estimators with a variance that decays faster with the batchsize than under uniform sampling. Coupled with existing finite-time guarantees for SGD on convex objectives, this entails that, DPP minibatches lead to a smaller bound on the mean square approximation error than uniform minibatches. Moreover, our estimators are amenable to a recent algorithm that directly samples linear statistics of DPPs (i.e., the gradient estimator) without sampling the underlying DPP (i.e., the minibatch), thereby reducing computational overhead. We provide detailed synthetic as well as real data experiments to substantiate our theoretical claims.

</p>
</details>

<details><summary><b>Test Set Sizing Via Random Matrix Theory</b>
<a href="https://arxiv.org/abs/2112.05977">arxiv:2112.05977</a>
&#x1F4C8; 2 <br>
<p>Alexander Dubbs</p></summary>
<p>

**Abstract:** This paper uses techniques from Random Matrix Theory to find the ideal training-testing data split for a simple linear regression with m data points, each an independent n-dimensional multivariate Gaussian. It defines "ideal" as satisfying the integrity metric, i.e. the empirical model error is the actual measurement noise, and thus fairly reflects the value or lack of same of the model. This paper is the first to solve for the training and test size for any model in a way that is truly optimal. The number of data points in the training set is the root of a quartic polynomial Theorem 1 derives which depends only on m and n; the covariance matrix of the multivariate Gaussian, the true model parameters, and the true measurement noise drop out of the calculations. The critical mathematical difficulties were realizing that the problems herein were discussed in the context of the Jacobi Ensemble, a probability distribution describing the eigenvalues of a known random matrix model, and evaluating a new integral in the style of Selberg and Aomoto. Mathematical results are supported with thorough computational evidence. This paper is a step towards automatic choices of training/test set sizes in machine learning.

</p>
</details>

<details><summary><b>Server-Side Local Gradient Averaging and Learning Rate Acceleration for Scalable Split Learning</b>
<a href="https://arxiv.org/abs/2112.05929">arxiv:2112.05929</a>
&#x1F4C8; 2 <br>
<p>Shraman Pal, Mansi Uniyal, Jihong Park, Praneeth Vepakomma, Ramesh Raskar, Mehdi Bennis, Moongu Jeon, Jinho Choi</p></summary>
<p>

**Abstract:** In recent years, there have been great advances in the field of decentralized learning with private data. Federated learning (FL) and split learning (SL) are two spearheads possessing their pros and cons, and are suited for many user clients and large models, respectively. To enjoy both benefits, hybrid approaches such as SplitFed have emerged of late, yet their fundamentals have still been illusive. In this work, we first identify the fundamental bottlenecks of SL, and thereby propose a scalable SL framework, coined SGLR. The server under SGLR broadcasts a common gradient averaged at the split-layer, emulating FL without any additional communication across clients as opposed to SplitFed. Meanwhile, SGLR splits the learning rate into its server-side and client-side rates, and separately adjusts them to support many clients in parallel. Simulation results corroborate that SGLR achieves higher accuracy than other baseline SL methods including SplitFed, which is even on par with FL consuming higher energy and communication costs. As a secondary result, we observe greater reduction in leakage of sensitive information via mutual information using SLGR over the baselines.

</p>
</details>

<details><summary><b>Building a Decision Support System for Automated Mobile Asthma Monitoring in Remote Areas</b>
<a href="https://arxiv.org/abs/2112.11195">arxiv:2112.11195</a>
&#x1F4C8; 1 <br>
<p>Chinazunwa Uwaoma, Gunjan Mansingh</p></summary>
<p>

**Abstract:** Advances in mobile computing have paved the way for the development of several health applications using smartphone as a platform for data acquisition, analysis and presentation. Such areas where mhealth systems have been extensively deployed include monitoring of long term health conditions like Cardio Vascular Diseases and pulmonary disorders, as well as detection of changes from baseline measurements of such conditions. Asthma is one of the respiratory conditions with growing concern across the globe due to the economic, social and emotional burden associated with the ailment. The management and control of asthma can be improved by consistent monitoring of the condition in realtime since attack could occur anytime and anywhere. This paper proposes the use of smartphone equipped with embedded sensors, to capture and analyze early symptoms of asthma triggered by exercise. The system design is based on Decision Support System techniques for measuring and analyzing the level and type of patients physical activity as well as weather conditions that predispose asthma attack. Preliminary results show that smartphones can be used to monitor and detect asthma symptoms without other networked devices. This would enhance the usability of the health system while ensuring users data privacy, and reducing the overall cost of system deployment. Further, the proposed system can serve as a handy tool for a quick medical response for asthmatics in low income countries where there are limited access to specialized medical devices and shortages of health professionals. Development of such monitoring systems signals a positive response to lessen the global burden of asthma.

</p>
</details>

<details><summary><b>Estimation of Physical Activity Level and Ambient Condition Thresholds for Respiratory Health using Smartphone Sensors</b>
<a href="https://arxiv.org/abs/2112.09068">arxiv:2112.09068</a>
&#x1F4C8; 1 <br>
<p>Chinazunwa Uwaoma</p></summary>
<p>

**Abstract:** While physical activity has been described as a primary prevention against chronic diseases, strenuous physical exertion under adverse ambient conditions has also been reported as a major contributor to exacerbation of chronic respiratory conditions. Maintaining a balance by monitoring the type and the level of physical activities of affected individuals, could help in reducing the cost and burden of managing respiratory ailments. This paper explores the potentiality of motion sensors in Smartphones to estimate physical activity thresholds that could trigger symptoms of exercise induced respiratory conditions (EiRCs). The focus is on the extraction of measurements from the embedded motion sensors to determine the activity level and the type of activity that is tolerable to individuals respiratory health. The calculations are based on the correlation between Signal Magnitude Area (SMA) and Energy Expenditure (EE). We also consider the effect of changes in the ambient conditions like temperature and humidity, as contributing factors to respiratory distress during physical exercise. Real time data collected from healthy individuals were used to demonstrate the potentiality of a mobile phone as tool to regulate the level of physical activities of individuals with EiRCs. We describe a practical situation where the experimental outcomes can be applied to promote good respiratory health.

</p>
</details>

<details><summary><b>Tree-based Focused Web Crawling with Reinforcement Learning</b>
<a href="https://arxiv.org/abs/2112.07620">arxiv:2112.07620</a>
&#x1F4C8; 1 <br>
<p>Andreas Kontogiannis, Dimitrios Kelesis, Vasilis Pollatos, Georgios Paliouras, George Giannakopoulos</p></summary>
<p>

**Abstract:** A focused crawler aims at discovering as many web pages relevant to a target topic as possible, while avoiding irrelevant ones; i.e. maximizing the harvest rate. Reinforcement Learning (RL) has been utilized to optimize the crawling process, yet it deals with huge state and action spaces, which can constitute a serious challenge. In this paper, we propose TRES, an end-to-end RL-empowered framework for focused crawling. Unlike other approaches, we properly model a crawling environment as a Markov Decision Process, by representing the state as a subgraph of the Web and actions as its expansion edges. TRES adopts a keyword expansion strategy based on the cosine similarity of keyword embeddings. To learn a reward function, we propose a deep neural network, called KwBiLSTM, leveraging the discovered keywords. To reduce the time complexity of selecting a best action, we propose Tree-Frontier, a two-fold decision tree, which also speeds up training by discretizing the state and action spaces. Experimentally, we show that TRES outperforms state-of-the-art methods in terms of harvest rate by at least 58%, while it has competitive results in the domain maximization. Our implementation code can be found on https://github.com/ddaedalus/TRES.

</p>
</details>

<details><summary><b>CHAMP: Coherent Hardware-Aware Magnitude Pruning of Integrated Photonic Neural Networks</b>
<a href="https://arxiv.org/abs/2112.06098">arxiv:2112.06098</a>
&#x1F4C8; 1 <br>
<p>Sanmitra Banerjee, Mahdi Nikdast, Sudeep Pasricha, Krishnendu Chakrabarty</p></summary>
<p>

**Abstract:** We propose a novel hardware-aware magnitude pruning technique for coherent photonic neural networks. The proposed technique can prune 99.45% of network parameters and reduce the static power consumption by 98.23% with a negligible accuracy loss.

</p>
</details>

<details><summary><b>Optimization of Residual Convolutional Neural Network for Electrocardiogram Classification</b>
<a href="https://arxiv.org/abs/2112.06024">arxiv:2112.06024</a>
&#x1F4C8; 1 <br>
<p>Zeineb Fki, Boudour Ammar, Mounir Ben Ayed</p></summary>
<p>

**Abstract:** The interpretation of the electrocardiogram (ECG) gives clinical information and helps in the assessing of the heart function. There are distinct ECG patterns associated with a specific class of arrythmia. The convolutional neural network is actually one of the most applied deep learning algorithms in ECG processing. However, with deep learning models there are many more hyperparameters to tune. Selecting an optimum or best hyperparameter for the convolutional neural network algorithm is challenging. Often, we end up tuning the model manually with different possible range of values until a best fit model is obtained. Automatic hyperparameters tuning using Bayesian optimization (BO) and evolutionary algorithms brings a solution to the harbor manual configuration. In this paper, we propose to optimize the Recurrent one Dimensional Convolutional Neural Network model (R-1D-CNN) with two levels. At the first level, a residual convolutional layer and one-dimensional convolutional neural layers are trained to learn patient-specific ECG features over which the multilayer perceptron layers can learn to produce the final class vectors of each input. This level is manual and aims to lower the search space. The second level is automatic and based on proposed algorithm based BO. Our proposed optimized R-1D-CNN architecture is evaluated on two publicly available ECG Datasets. The experimental results display that the proposed algorithm based BO achieves an optimum rate of 99.95\%, while the baseline model achieves 99.70\% for the MIT-BIH database. Moreover, experiments demonstrate that the proposed architecture fine-tuned with BO achieves a higher accuracy than the other proposed architectures. Our architecture achieves a good result compared to previous works and based on different experiments.

</p>
</details>

<details><summary><b>Efficient Device Scheduling with Multi-Job Federated Learning</b>
<a href="https://arxiv.org/abs/2112.05928">arxiv:2112.05928</a>
&#x1F4C8; 1 <br>
<p>Chendi Zhou, Ji Liu, Juncheng Jia, Jingbo Zhou, Yang Zhou, Huaiyu Dai, Dejing Dou</p></summary>
<p>

**Abstract:** Recent years have witnessed a large amount of decentralized data in multiple (edge) devices of end-users, while the aggregation of the decentralized data remains difficult for machine learning jobs due to laws or regulations. Federated Learning (FL) emerges as an effective approach to handling decentralized data without sharing the sensitive raw data, while collaboratively training global machine learning models. The servers in FL need to select (and schedule) devices during the training process. However, the scheduling of devices for multiple jobs with FL remains a critical and open problem. In this paper, we propose a novel multi-job FL framework to enable the parallel training process of multiple jobs. The framework consists of a system model and two scheduling methods. In the system model, we propose a parallel training process of multiple jobs, and construct a cost model based on the training time and the data fairness of various devices during the training process of diverse jobs. We propose a reinforcement learning-based method and a Bayesian optimization-based method to schedule devices for multiple jobs while minimizing the cost. We conduct extensive experimentation with multiple jobs and datasets. The experimental results show that our proposed approaches significantly outperform baseline approaches in terms of training time (up to 8.67 times faster) and accuracy (up to 44.6% higher).

</p>
</details>


[Next Page](2021/2021-12/2021-12-10.md)
