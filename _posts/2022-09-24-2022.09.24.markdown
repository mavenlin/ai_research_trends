Prev: [2022.09.23]({{ '/2022/09/23/2022.09.23.html' | relative_url }})  Next: [2022.09.25]({{ '/2022/09/25/2022.09.25.html' | relative_url }})
{% raw %}
## Summary for 2022-09-24, created on 2022-10-01


<details><summary><b>A Deep Learning Approach to Analyzing Continuous-Time Systems</b>
<a href="https://arxiv.org/abs/2209.12128">arxiv:2209.12128</a>
&#x1F4C8; 40 <br>
<p>Cory Shain, William Schuler</p></summary>
<p>

**Abstract:** Scientists often use observational time series data to study complex natural processes, from climate change to civil conflict to brain activity. But regression analyses of these data often assume simplistic dynamics. Recent advances in deep learning have yielded startling improvements to the performance of models of complex processes, from speech comprehension to nuclear physics to competitive gaming. But deep learning is generally not used for scientific analysis. Here, we bridge this gap by showing that deep learning can be used, not just to imitate, but to analyze complex processes, providing flexible function approximation while preserving interpretability. Our approach -- the continuous-time deconvolutional regressive neural network (CDRNN) -- relaxes standard simplifying assumptions (e.g., linearity, stationarity, and homoscedasticity) that are implausible for many natural systems and may critically affect the interpretation of data. We evaluate CDRNNs on incremental human language processing, a domain with complex continuous dynamics. We demonstrate dramatic improvements to predictive likelihood in behavioral and neuroimaging data, and we show that CDRNNs enable flexible discovery of novel patterns in exploratory analyses, provide robust control of possible confounds in confirmatory analyses, and open up research questions that are otherwise hard to study using observational data.

</p>
</details>

<details><summary><b>Controllable Text Generation for Open-Domain Creativity and Fairness</b>
<a href="https://arxiv.org/abs/2209.12099">arxiv:2209.12099</a>
&#x1F4C8; 7 <br>
<p>Nanyun Peng</p></summary>
<p>

**Abstract:** Recent advances in large pre-trained language models have demonstrated strong results in generating natural languages and significantly improved performances for many natural language generation (NLG) applications such as machine translation and text summarization. However, when the generation tasks are more open-ended and the content is under-specified, existing techniques struggle to generate long-term coherent and creative content. Moreover, the models exhibit and even amplify social biases that are learned from the training corpora. This happens because the generation models are trained to capture the surface patterns (i.e. sequences of words), instead of capturing underlying semantics and discourse structures, as well as background knowledge including social norms. In this paper, I introduce our recent works on controllable text generation to enhance the creativity and fairness of language generation models. We explore hierarchical generation and constrained decoding, with applications to creative language generation including story, poetry, and figurative languages, and bias mitigation for generation models.

</p>
</details>

<details><summary><b>Identifying latent activity behaviors and lifestyles using mobility data to describe urban dynamics</b>
<a href="https://arxiv.org/abs/2209.12095">arxiv:2209.12095</a>
&#x1F4C8; 7 <br>
<p>Yanni Yang, Alex Pentland, Esteban Moro</p></summary>
<p>

**Abstract:** Urbanization and its problems require an in-depth and comprehensive understanding of urban dynamics, especially the complex and diversified lifestyles in modern cities. Digitally acquired data can accurately capture complex human activity, but it lacks the interpretability of demographic data. In this paper, we study a privacy-enhanced dataset of the mobility visitation patterns of 1.2 million people to 1.1 million places in 11 metro areas in the U.S. to detect the latent mobility behaviors and lifestyles in the largest American cities. Despite the considerable complexity of mobility visitations, we found that lifestyles can be automatically decomposed into only 12 latent interpretable activity behaviors on how people combine shopping, eating, working, or using their free time. Rather than describing individuals with a single lifestyle, we find that city dwellers' behavior is a mixture of those behaviors. Those detected latent activity behaviors are equally present across cities and cannot be fully explained by main demographic features. Finally, we find those latent behaviors are associated with dynamics like experienced income segregation, transportation, or healthy behaviors in cities, even after controlling for demographic features. Our results signal the importance of complementing traditional census data with activity behaviors to understand urban dynamics.

</p>
</details>

<details><summary><b>From Local to Global: Spectral-Inspired Graph Neural Networks</b>
<a href="https://arxiv.org/abs/2209.12054">arxiv:2209.12054</a>
&#x1F4C8; 7 <br>
<p>Ningyuan Huang, Soledad Villar, Carey E. Priebe, Da Zheng, Chengyue Huang, Lin Yang, Vladimir Braverman</p></summary>
<p>

**Abstract:** Graph Neural Networks (GNNs) are powerful deep learning methods for Non-Euclidean data. Popular GNNs are message-passing algorithms (MPNNs) that aggregate and combine signals in a local graph neighborhood. However, shallow MPNNs tend to miss long-range signals and perform poorly on some heterophilous graphs, while deep MPNNs can suffer from issues like over-smoothing or over-squashing. To mitigate such issues, existing works typically borrow normalization techniques from training neural networks on Euclidean data or modify the graph structures. Yet these approaches are not well-understood theoretically and could increase the overall computational complexity. In this work, we draw inspirations from spectral graph embedding and propose $\texttt{PowerEmbed}$ -- a simple layer-wise normalization technique to boost MPNNs. We show $\texttt{PowerEmbed}$ can provably express the top-$k$ leading eigenvectors of the graph operator, which prevents over-smoothing and is agnostic to the graph topology; meanwhile, it produces a list of representations ranging from local features to global signals, which avoids over-squashing. We apply $\texttt{PowerEmbed}$ in a wide range of simulated and real graphs and demonstrate its competitive performance, particularly for heterophilous graphs.

</p>
</details>

<details><summary><b>Explainable Reinforcement Learning via Model Transforms</b>
<a href="https://arxiv.org/abs/2209.12006">arxiv:2209.12006</a>
&#x1F4C8; 7 <br>
<p>Mira Finkelstein, Lucy Liu, Nitsan Levy Schlot, Yoav Kolumbus, David C. Parkes, Jeffrey S. Rosenshein, Sarah Keren</p></summary>
<p>

**Abstract:** Understanding emerging behaviors of reinforcement learning (RL) agents may be difficult since such agents are often trained in complex environments using highly complex decision making procedures. This has given rise to a variety of approaches to explainability in RL that aim to reconcile discrepancies that may arise between the behavior of an agent and the behavior that is anticipated by an observer. Most recent approaches have relied either on domain knowledge, that may not always be available, on an analysis of the agent's policy, or on an analysis of specific elements of the underlying environment, typically modeled as a Markov Decision Process (MDP). Our key claim is that even if the underlying MDP is not fully known (e.g., the transition probabilities have not been accurately learned) or is not maintained by the agent (i.e., when using model-free methods), it can nevertheless be exploited to automatically generate explanations. For this purpose, we suggest using formal MDP abstractions and transforms, previously used in the literature for expediting the search for optimal policies, to automatically produce explanations. Since such transforms are typically based on a symbolic representation of the environment, they may represent meaningful explanations for gaps between the anticipated and actual agent behavior. We formally define this problem, suggest a class of transforms that can be used for explaining emergent behaviors, and suggest methods that enable efficient search for an explanation. We demonstrate the approach on a set of standard benchmarks.

</p>
</details>

<details><summary><b>TransPOS: Transformers for Consolidating Different POS Tagset Datasets</b>
<a href="https://arxiv.org/abs/2209.11959">arxiv:2209.11959</a>
&#x1F4C8; 6 <br>
<p>Alex Li, Ilyas Bankole-Hameed, Ranadeep Singh, Gabriel Shen Han Ng, Akshat Gupta</p></summary>
<p>

**Abstract:** In hope of expanding training data, researchers often want to merge two or more datasets that are created using different labeling schemes. This paper considers two datasets that label part-of-speech (POS) tags under different tagging schemes and leverage the supervised labels of one dataset to help generate labels for the other dataset. This paper further discusses the theoretical difficulties of this approach and proposes a novel supervised architecture employing Transformers to tackle the problem of consolidating two completely disjoint datasets. The results diverge from initial expectations and discourage exploration into the use of disjoint labels to consolidate datasets with different labels.

</p>
</details>

<details><summary><b>Hybrid Multimodal Fusion for Humor Detection</b>
<a href="https://arxiv.org/abs/2209.11949">arxiv:2209.11949</a>
&#x1F4C8; 6 <br>
<p>Haojie Xu, Weifeng Liu, Jingwei Liu, Mingzheng Li, Yu Feng, Yasi Peng, Yunwei Shi, Xiao Sun, Meng Wang</p></summary>
<p>

**Abstract:** In this paper, we present our solution to the MuSe-Humor sub-challenge of the Multimodal Emotional Challenge (MuSe) 2022. The goal of the MuSe-Humor sub-challenge is to detect humor and calculate AUC from audiovisual recordings of German football Bundesliga press conferences. It is annotated for humor displayed by the coaches. For this sub-challenge, we first build a discriminant model using the transformer module and BiLSTM module, and then propose a hybrid fusion strategy to use the prediction results of each modality to improve the performance of the model. Our experiments demonstrate the effectiveness of our proposed model and hybrid fusion strategy on multimodal fusion, and the AUC of our proposed model on the test set is 0.8972.

</p>
</details>

<details><summary><b>Climate Impact Modelling Framework</b>
<a href="https://arxiv.org/abs/2209.12080">arxiv:2209.12080</a>
&#x1F4C8; 5 <br>
<p>Blair Edwards, Paolo Fraccaro, Nikola Stoyanov, Nelson Bore, Julian Kuehnert, Kommy Weldemariam, Anne Jones</p></summary>
<p>

**Abstract:** The application of models to assess the risk of the physical impacts of weather and climate and their subsequent consequences for society and business is of the utmost importance in our changing climate. The operation of such models is historically bespoke and constrained to specific compute infrastructure, driving datasets and predefined configurations. These constraints introduce challenges with scaling model runs and putting the models in the hands of interested users. Here we present a cloud-based modular framework for the deployment and operation of geospatial models, initially applied to climate impacts. The Climate Impact Modelling Frameworks (CIMF) enables the deployment of modular workflows in a dynamic and flexible manner. Users can specify workflow components in a streamlined manner, these components can then be easily organised into different configurations to assess risk in different ways and at different scales. This also enables different models (physical simulation or machine learning models) and workflows to be connected to produce combined risk assessment. Flood modelling is used as an end-to-end example to demonstrate the operation of CIMF.

</p>
</details>

<details><summary><b>Asset Pricing and Deep Learning</b>
<a href="https://arxiv.org/abs/2209.12014">arxiv:2209.12014</a>
&#x1F4C8; 5 <br>
<p>Chen Zhang</p></summary>
<p>

**Abstract:** Traditional machine learning methods have been widely studied in financial innovation. My study focuses on the application of deep learning methods on asset pricing. I investigate various deep learning methods for asset pricing, especially for risk premia measurement. All models take the same set of predictive signals (firm characteristics, systematic risks and macroeconomics). I demonstrate high performance of all kinds of state-of-the-art (SOTA) deep learning methods, and figure out that RNNs with memory mechanism and attention have the best performance in terms of predictivity. Furthermore, I demonstrate large economic gains to investors using deep learning forecasts. The results of my comparative experiments highlight the importance of domain knowledge and financial theory when designing deep learning models. I also show return prediction tasks bring new challenges to deep learning. The time varying distribution causes distribution shift problem, which is essential for financial time series prediction. I demonstrate that deep learning methods can improve asset risk premium measurement. Due to the booming deep learning studies, they can constantly promote the study of underlying financial mechanisms behind asset pricing. I also propose a promising research method that learning from data and figuring out the underlying economic mechanisms through explainable artificial intelligence (AI) methods. My findings not only justify the value of deep learning in blooming fintech development, but also highlight their prospects and advantages over traditional machine learning methods.

</p>
</details>

<details><summary><b>Graph Neural Networks for Multi-Robot Active Information Acquisition</b>
<a href="https://arxiv.org/abs/2209.12091">arxiv:2209.12091</a>
&#x1F4C8; 4 <br>
<p>Mariliza Tzes, Nikolaos Bousias, Evangelos Chatzipantazis, George J. Pappas</p></summary>
<p>

**Abstract:** This paper addresses the Multi-Robot Active Information Acquisition (AIA) problem, where a team of mobile robots, communicating through an underlying graph, estimates a hidden state expressing a phenomenon of interest. Applications like target tracking, coverage and SLAM can be expressed in this framework. Existing approaches, though, are either not scalable, unable to handle dynamic phenomena or not robust to changes in the communication graph. To counter these shortcomings, we propose an Information-aware Graph Block Network (I-GBNet), an AIA adaptation of Graph Neural Networks, that aggregates information over the graph representation and provides sequential-decision making in a distributed manner. The I-GBNet, trained via imitation learning with a centralized sampling-based expert solver, exhibits permutation equivariance and time invariance, while harnessing the superior scalability, robustness and generalizability to previously unseen environments and robot configurations. Experiments on significantly larger graphs and dimensionality of the hidden state and more complex environments than those seen in training validate the properties of the proposed architecture and its efficacy in the application of localization and tracking of dynamic targets.

</p>
</details>

<details><summary><b>One-Shot Learning of Stochastic Differential Equations with Computational Graph Completion</b>
<a href="https://arxiv.org/abs/2209.12086">arxiv:2209.12086</a>
&#x1F4C8; 4 <br>
<p>Matthieu Darcy, Boumediene Hamzi, Giulia Livieri, Houman Owhadi, Peyman Tavallali</p></summary>
<p>

**Abstract:** We consider the problem of learning Stochastic Differential Equations of the form $dX_t = f(X_t)dt+σ(X_t)dW_t $ from one sample trajectory. This problem is more challenging than learning deterministic dynamical systems because one sample trajectory only provides indirect information on the unknown functions $f$, $σ$, and stochastic process $dW_t$ representing the drift, the diffusion, and the stochastic forcing terms, respectively. We propose a simple kernel-based solution to this problem that can be decomposed as follows: (1) Represent the time-increment map $X_t \rightarrow X_{t+dt}$ as a Computational Graph in which $f$, $σ$ and $dW_t$ appear as unknown functions and random variables. (2) Complete the graph (approximate unknown functions and random variables) via Maximum a Posteriori Estimation (given the data) with Gaussian Process (GP) priors on the unknown functions. (3) Learn the covariance functions (kernels) of the GP priors from data with randomized cross-validation. Numerical experiments illustrate the efficacy, robustness, and scope of our method.

</p>
</details>

<details><summary><b>Unsupervised Model-based Pre-training for Data-efficient Control from Pixels</b>
<a href="https://arxiv.org/abs/2209.12016">arxiv:2209.12016</a>
&#x1F4C8; 4 <br>
<p>Sai Rajeswar, Pietro Mazzaglia, Tim Verbelen, Alexandre Piché, Bart Dhoedt, Aaron Courville, Alexandre Lacoste</p></summary>
<p>

**Abstract:** Controlling artificial agents from visual sensory data is an arduous task. Reinforcement learning (RL) algorithms can succeed in this but require large amounts of interactions between the agent and the environment. To alleviate the issue, unsupervised RL proposes to employ self-supervised interaction and learning, for adapting faster to future tasks. Yet, whether current unsupervised strategies improve generalization capabilities is still unclear, especially in visual control settings. In this work, we design an effective unsupervised RL strategy for data-efficient visual control. First, we show that world models pre-trained with data collected using unsupervised RL can facilitate adaptation for future tasks. Then, we analyze several design choices to adapt efficiently, effectively reusing the agents' pre-trained components, and learning and planning in imagination, with our hybrid planner, which we dub Dyna-MPC. By combining the findings of a large-scale empirical study, we establish an approach that strongly improves performance on the Unsupervised RL Benchmark, requiring 20$\times$ less data to match the performance of supervised methods. The approach also demonstrates robust performance on the Real-Word RL benchmark, hinting that the approach generalizes to noisy environments.

</p>
</details>

<details><summary><b>A Deep Investigation of RNN and Self-attention for the Cyrillic-Traditional Mongolian Bidirectional Conversion</b>
<a href="https://arxiv.org/abs/2209.11963">arxiv:2209.11963</a>
&#x1F4C8; 4 <br>
<p>Muhan Na, Rui Liu,  Feilong, Guanglai Gao</p></summary>
<p>

**Abstract:** Cyrillic and Traditional Mongolian are the two main members of the Mongolian writing system. The Cyrillic-Traditional Mongolian Bidirectional Conversion (CTMBC) task includes two conversion processes, including Cyrillic Mongolian to Traditional Mongolian (C2T) and Traditional Mongolian to Cyrillic Mongolian conversions (T2C). Previous researchers adopted the traditional joint sequence model, since the CTMBC task is a natural Sequence-to-Sequence (Seq2Seq) modeling problem. Recent studies have shown that Recurrent Neural Network (RNN) and Self-attention (or Transformer) based encoder-decoder models have shown significant improvement in machine translation tasks between some major languages, such as Mandarin, English, French, etc. However, an open problem remains as to whether the CTMBC quality can be improved by utilizing the RNN and Transformer models. To answer this question, this paper investigates the utility of these two powerful techniques for CTMBC task combined with agglutinative characteristics of Mongolian language. We build the encoder-decoder based CTMBC model based on RNN and Transformer respectively and compare the different network configurations deeply. The experimental results show that both RNN and Transformer models outperform the traditional joint sequence model, where the Transformer achieves the best performance. Compared with the joint sequence baseline, the word error rate (WER) of the Transformer for C2T and T2C decreased by 5.72\% and 5.06\% respectively.

</p>
</details>

<details><summary><b>Machine Learning and Artificial Intelligence-Driven Multi-Scale Modeling for High Burnup Accident-Tolerant Fuels for Light Water-Based SMR Applications</b>
<a href="https://arxiv.org/abs/2209.12146">arxiv:2209.12146</a>
&#x1F4C8; 3 <br>
<p>Md. Shamim Hassan, Abid Hossain Khan, Richa Verma, Dinesh Kumar, Kazuma Kobayashi, Shoaib Usman, Syed Alam</p></summary>
<p>

**Abstract:** The concept of small modular reactor has changed the outlook for tackling future energy crises. This new reactor technology is very promising considering its lower investment requirements, modularity, design simplicity, and enhanced safety features. The application of artificial intelligence-driven multi-scale modeling (neutronics, thermal hydraulics, fuel performance, etc.) incorporating Digital Twin and associated uncertainties in the research of small modular reactors is a recent concept. In this work, a comprehensive study is conducted on the multiscale modeling of accident-tolerant fuels. The application of these fuels in the light water-based small modular reactors is explored. This chapter also focuses on the application of machine learning and artificial intelligence in the design optimization, control, and monitoring of small modular reactors. Finally, a brief assessment of the research gap on the application of artificial intelligence to the development of high burnup composite accident-tolerant fuels is provided. Necessary actions to fulfill these gaps are also discussed.

</p>
</details>

<details><summary><b>An Asymptotically Optimal Batched Algorithm for the Dueling Bandit Problem</b>
<a href="https://arxiv.org/abs/2209.12108">arxiv:2209.12108</a>
&#x1F4C8; 3 <br>
<p>Arpit Agarwal, Rohan Ghuge, Viswanath Nagarajan</p></summary>
<p>

**Abstract:** We study the $K$-armed dueling bandit problem, a variation of the traditional multi-armed bandit problem in which feedback is obtained in the form of pairwise comparisons. Previous learning algorithms have focused on the $\textit{fully adaptive}$ setting, where the algorithm can make updates after every comparison. The "batched" dueling bandit problem is motivated by large-scale applications like web search ranking and recommendation systems, where performing sequential updates may be infeasible. In this work, we ask: $\textit{is there a solution using only a few adaptive rounds that matches the asymptotic regret bounds of the best sequential algorithms for $K$-armed dueling bandits?}$ We answer this in the affirmative $\textit{under the Condorcet condition}$, a standard setting of the $K$-armed dueling bandit problem. We obtain asymptotic regret of $O(K^2\log^2(K)) + O(K\log(T))$ in $O(\log(T))$ rounds, where $T$ is the time horizon. Our regret bounds nearly match the best regret bounds known in the fully sequential setting under the Condorcet condition. Finally, in computational experiments over a variety of real-world datasets, we observe that our algorithm using $O(\log(T))$ rounds achieves almost the same performance as fully sequential algorithms (that use $T$ rounds).

</p>
</details>

<details><summary><b>Unsupervised domain adaptation for speech recognition with unsupervised error correction</b>
<a href="https://arxiv.org/abs/2209.12043">arxiv:2209.12043</a>
&#x1F4C8; 3 <br>
<p>Long Mai, Julie Carson-Berndsen</p></summary>
<p>

**Abstract:** The transcription quality of automatic speech recognition (ASR) systems degrades significantly when transcribing audios coming from unseen domains. We propose an unsupervised error correction method for unsupervised ASR domain adaption, aiming to recover transcription errors caused by domain mismatch. Unlike existing correction methods that rely on transcribed audios for training, our approach requires only unlabeled data of the target domains in which a pseudo-labeling technique is applied to generate correction training samples. To reduce over-fitting to the pseudo data, we also propose an encoder-decoder correction model that can take into account additional information such as dialogue context and acoustic features. Experiment results show that our method obtains a significant word error rate (WER) reduction over non-adapted ASR systems. The correction model can also be applied on top of other adaptation approaches to bring an additional improvement of 10% relatively.

</p>
</details>

<details><summary><b>Spiking SiamFC++: Deep Spiking Neural Network for Object Tracking</b>
<a href="https://arxiv.org/abs/2209.12010">arxiv:2209.12010</a>
&#x1F4C8; 3 <br>
<p>Shuiying Xiang, Tao Zhang, Shuqing Jiang, Yanan Han, Yahui Zhang, Chenyang Du, Xingxing Guo, Licun Yu, Yuechun Shi, Yue Hao</p></summary>
<p>

**Abstract:** Spiking neural network (SNN) is a biologically-plausible model and exhibits advantages of high computational capability and low power consumption. While the training of deep SNN is still an open problem, which limits the real-world applications of deep SNN. Here we propose a deep SNN architecture named Spiking SiamFC++ for object tracking with end-to-end direct training. Specifically, the AlexNet network is extended in the time domain to extract the feature, and the surrogate gradient function is adopted to realize direct supervised training of the deep SNN. To examine the performance of the Spiking SiamFC++, several tracking benchmarks including OTB2013, OTB2015, VOT2015, VOT2016, and UAV123 are considered. It is found that, the precision loss is small compared with the original SiamFC++. Compared with the existing SNN-based target tracker, e.g., the SiamSNN, the precision (succession) of the proposed Spiking SiamFC++ reaches 85.24% (64.37%), which is much higher than that of 52.78% (44.32%) achieved by the SiamSNN. To our best knowledge, the performance of the Spiking SiamFC++ outperforms the existing state-of-the-art approaches in SNN-based object tracking, which provides a novel path for SNN application in the field of target tracking. This work may further promote the development of SNN algorithms and neuromorphic chips.

</p>
</details>

<details><summary><b>Contrastive learning for unsupervised medical image clustering and reconstruction</b>
<a href="https://arxiv.org/abs/2209.12005">arxiv:2209.12005</a>
&#x1F4C8; 3 <br>
<p>Matteo Ferrante, Tommaso Boccato, Simeon Spasov, Andrea Duggento, Nicola Toschi</p></summary>
<p>

**Abstract:** The lack of large labeled medical imaging datasets, along with significant inter-individual variability compared to clinically established disease classes, poses significant challenges in exploiting medical imaging information in a precision medicine paradigm, where in principle dense patient-specific data can be employed to formulate individual predictions and/or stratify patients into finer-grained groups which may follow more homogeneous trajectories and therefore empower clinical trials. In order to efficiently explore the effective degrees of freedom underlying variability in medical images in an unsupervised manner, in this work we propose an unsupervised autoencoder framework which is augmented with a contrastive loss to encourage high separability in the latent space. The model is validated on (medical) benchmark datasets. As cluster labels are assigned to each example according to cluster assignments, we compare performance with a supervised transfer learning baseline. Our method achieves similar performance to the supervised architecture, indicating that separation in the latent space reproduces expert medical observer-assigned labels. The proposed method could be beneficial for patient stratification, exploring new subdivisions of larger classes or pathological continua or, due to its sampling abilities in a variation setting, data augmentation in medical image processing.

</p>
</details>

<details><summary><b>Statistical Analysis of Time-Frequency Features Based On Multivariate Synchrosqueezing Transform for Hand Gesture Classification</b>
<a href="https://arxiv.org/abs/2209.13350">arxiv:2209.13350</a>
&#x1F4C8; 2 <br>
<p>Lutfiye Saripinar, Deniz Hande Kisa, Mehmet Akif Ozdemir, Onan Guren</p></summary>
<p>

**Abstract:** In this study, the four joint time-frequency (TF) moments; mean, variance, skewness, and kurtosis of TF matrix obtained from Multivariate Synchrosqueezing Transform (MSST) are proposed as features for hand gesture recognition. A publicly available dataset containing surface EMG (sEMG) signals of 40 subjects performing 10 hand gestures, was used. The distinguishing power of the feature variables for the tested gestures was evaluated according to their p values obtained from the Kruskal-Wallis (KW) test. It is concluded that the mean, variance, skewness, and kurtosis of TF matrices can be candidate feature sets for the recognition of hand gestures.

</p>
</details>

<details><summary><b>Answer-Set Programs for Repair Updates and Counterfactual Interventions</b>
<a href="https://arxiv.org/abs/2209.12110">arxiv:2209.12110</a>
&#x1F4C8; 2 <br>
<p>Leopoldo Bertossi</p></summary>
<p>

**Abstract:** We briefly describe -- mainly through very simple examples -- different kinds of answer-set programs with annotations that have been proposed for specifying: database repairs and consistent query answering; secrecy view and query evaluation with them; counterfactual interventions for causality in databases; and counterfactual-based explanations in machine learning.

</p>
</details>

<details><summary><b>Conversion Between CT and MRI Images Using Diffusion and Score-Matching Models</b>
<a href="https://arxiv.org/abs/2209.12104">arxiv:2209.12104</a>
&#x1F4C8; 2 <br>
<p>Qing Lyu, Ge Wang</p></summary>
<p>

**Abstract:** MRI and CT are most widely used medical imaging modalities. It is often necessary to acquire multi-modality images for diagnosis and treatment such as radiotherapy planning. However, multi-modality imaging is not only costly but also introduces misalignment between MRI and CT images. To address this challenge, computational conversion is a viable approach between MRI and CT images, especially from MRI to CT images. In this paper, we propose to use an emerging deep learning framework called diffusion and score-matching models in this context. Specifically, we adapt denoising diffusion probabilistic and score-matching models, use four different sampling strategies, and compare their performance metrics with that using a convolutional neural network and a generative adversarial network model. Our results show that the diffusion and score-matching models generate better synthetic CT images than the CNN and GAN models. Furthermore, we investigate the uncertainties associated with the diffusion and score-matching networks using the Monte-Carlo method, and improve the results by averaging their Monte-Carlo outputs. Our study suggests that diffusion and score-matching models are powerful to generate high quality images conditioned on an image obtained using a complementary imaging modality, analytically rigorous with clear explainability, and highly competitive with CNNs and GANs for image synthesis.

</p>
</details>

<details><summary><b>Song Emotion Recognition: a Performance Comparison Between Audio Features and Artificial Neural Networks</b>
<a href="https://arxiv.org/abs/2209.12045">arxiv:2209.12045</a>
&#x1F4C8; 2 <br>
<p>Karen Rosero, Arthur Nicholas dos Santos, Pedro Benevenuto Valadares, Bruno Sanches Masiero</p></summary>
<p>

**Abstract:** When songs are composed or performed, there is often an intent by the singer/songwriter of expressing feelings or emotions through it. For humans, matching the emotiveness in a musical composition or performance with the subjective perception of an audience can be quite challenging. Fortunately, the machine learning approach for this problem is simpler. Usually, it takes a data-set, from which audio features are extracted to present this information to a data-driven model, that will, in turn, train to predict what is the probability that a given song matches a target emotion. In this paper, we studied the most common features and models used in recent publications to tackle this problem, revealing which ones are best suited for recognizing emotion in a cappella songs.

</p>
</details>

<details><summary><b>Open-Ended Diverse Solution Discovery with Regulated Behavior Patterns for Cross-Domain Adaptation</b>
<a href="https://arxiv.org/abs/2209.12029">arxiv:2209.12029</a>
&#x1F4C8; 2 <br>
<p>Kang Xu, Yan Ma, Wei Li, Bingsheng Wei</p></summary>
<p>

**Abstract:** While Reinforcement Learning can achieve impressive results for complex tasks, the learned policies are generally prone to fail in downstream tasks with even minor model mismatch or unexpected perturbations. Recent works have demonstrated that a policy population with diverse behavior characteristics can generalize to downstream environments with various discrepancies. However, such policies might result in catastrophic damage during the deployment in practical scenarios like real-world systems due to the unrestricted behaviors of trained policies. Furthermore, training diverse policies without regulation of the behavior can result in inadequate feasible policies for extrapolating to a wide range of test conditions with dynamics shifts. In this work, we aim to train diverse policies under the regularization of the behavior patterns. We motivate our paradigm by observing the inverse dynamics in the environment with partial state information and propose Diversity in Regulation(DiR) training diverse policies with regulated behaviors to discover desired patterns that benefit the generalization. Considerable empirical results on various variations of different environments indicate that our method attains improvements over other diversity-driven counterparts.

</p>
</details>

<details><summary><b>Application of the nnU-Net for automatic segmentation of lung lesion on CT images, and implication on radiomic models</b>
<a href="https://arxiv.org/abs/2209.12027">arxiv:2209.12027</a>
&#x1F4C8; 2 <br>
<p>Matteo Ferrante, Lisa Rinaldi, Francesca Botta, Xiaobin Hu, Andreas Dolp, Marta Minotti, Francesca De Piano, Gianluigi Funicelli, Stefania Volpe, Federica Bellerba, Paolo De Marco, Sara Raimondi, Stefania Rizzo, Kuangyu Shi, Marta Cremonesi, Barbara A. Jereczek-Fossa, Lorenzo Spaggiari, Filippo De Marinis, Roberto Orecchia, Daniela Origgi</p></summary>
<p>

**Abstract:** Lesion segmentation is a crucial step of the radiomic workflow. Manual segmentation requires long execution time and is prone to variability, impairing the realisation of radiomic studies and their robustness. In this study, a deep-learning automatic segmentation method was applied on computed tomography images of non-small-cell lung cancer patients. The use of manual vs automatic segmentation in the performance of survival radiomic models was assessed, as well. METHODS A total of 899 NSCLC patients were included (2 proprietary: A and B, 1 public datasets: C). Automatic segmentation of lung lesions was performed by training a previously developed architecture, the nnU-Net, including 2D, 3D and cascade approaches. The quality of automatic segmentation was evaluated with DICE coefficient, considering manual contours as reference. The impact of automatic segmentation on the performance of a radiomic model for patient survival was explored by extracting radiomic hand-crafted and deep-learning features from manual and automatic contours of dataset A, and feeding different machine learning algorithms to classify survival above/below median. Models' accuracies were assessed and compared. RESULTS The best agreement between automatic and manual contours with DICE=0.78 +(0.12) was achieved by averaging predictions from 2D and 3D models, and applying a post-processing technique to extract the maximum connected component. No statistical differences were observed in the performances of survival models when using manual or automatic contours, hand-crafted, or deep features. The best classifier showed an accuracy between 0.65 and 0.78. CONCLUSION The promising role of nnU-Net for automatic segmentation of lung lesions was confirmed, dramatically reducing the time-consuming physicians' workload without impairing the accuracy of survival predictive models based on radiomics.

</p>
</details>

<details><summary><b>Non-monotonic Resource Utilization in the Bandits with Knapsacks Problem</b>
<a href="https://arxiv.org/abs/2209.12013">arxiv:2209.12013</a>
&#x1F4C8; 2 <br>
<p>Raunak Kumar, Robert Kleinberg</p></summary>
<p>

**Abstract:** Bandits with knapsacks (BwK) is an influential model of sequential decision-making under uncertainty that incorporates resource consumption constraints. In each round, the decision-maker observes an outcome consisting of a reward and a vector of nonnegative resource consumptions, and the budget of each resource is decremented by its consumption. In this paper we introduce a natural generalization of the stochastic BwK problem that allows non-monotonic resource utilization. In each round, the decision-maker observes an outcome consisting of a reward and a vector of resource drifts that can be positive, negative or zero, and the budget of each resource is incremented by its drift. Our main result is a Markov decision process (MDP) policy that has constant regret against a linear programming (LP) relaxation when the decision-maker knows the true outcome distributions. We build upon this to develop a learning algorithm that has logarithmic regret against the same LP relaxation when the decision-maker does not know the true outcome distributions. We also present a reduction from BwK to our model that shows our regret bound matches existing results.

</p>
</details>

<details><summary><b>Toward Intention Discovery for Early Malice Detection in Bitcoin</b>
<a href="https://arxiv.org/abs/2209.12001">arxiv:2209.12001</a>
&#x1F4C8; 2 <br>
<p>Ling Cheng, Feida Zhu, Yong Wang, Huiwen Liu</p></summary>
<p>

**Abstract:** Bitcoin has been subject to illicit activities more often than probably any other financial assets, due to the pseudo-anonymous nature of its transacting entities. An ideal detection model is expected to achieve all the three properties of (I) early detection, (II) good interpretability, and (III) versatility for various illicit activities. However, existing solutions cannot meet all these requirements, as most of them heavily rely on deep learning without satisfying interpretability and are only available for retrospective analysis of a specific illicit type.
  First, we present asset transfer paths, which aim to describe addresses' early characteristics. Next, with a decision tree based strategy for feature selection and segmentation, we split the entire observation period into different segments and encode each as a segment vector. After clustering all these segment vectors, we get the global status vectors, essentially the basic unit to describe the whole intention. Finally, a hierarchical self-attention predictor predicts the label for the given address in real time. A survival module tells the predictor when to stop and proposes the status sequence, namely intention. %
  With the type-dependent selection strategy and global status vectors, our model can be applied to detect various illicit activities with strong interpretability. The well-designed predictor and particular loss functions strengthen the model's prediction speed and interpretability one step further. Extensive experiments on three real-world datasets show that our proposed algorithm outperforms state-of-the-art methods. Besides, additional case studies justify our model can not only explain existing illicit patterns but can also find new suspicious characters.

</p>
</details>

<details><summary><b>Deep Attentive Belief Propagation: Integrating Reasoning and Learning for Solving Constraint Optimization Problems</b>
<a href="https://arxiv.org/abs/2209.12000">arxiv:2209.12000</a>
&#x1F4C8; 2 <br>
<p>Yanchen Deng, Shufeng Kong, Caihua Liu, Bo An</p></summary>
<p>

**Abstract:** Belief Propagation (BP) is an important message-passing algorithm for various reasoning tasks over graphical models, including solving the Constraint Optimization Problems (COPs). It has been shown that BP can achieve state-of-the-art performance on various benchmarks by mixing old and new messages before sending the new one, i.e., damping. However, existing methods of tuning a static damping factor for BP not only are laborious but also harm their performance. Moreover, existing BP algorithms treat each variable node's neighbors equally when composing a new message, which also limits their exploration ability. To address these issues, we seamlessly integrate BP, Gated Recurrent Units (GRUs), and Graph Attention Networks (GATs) within the message-passing framework to reason about dynamic weights and damping factors for composing new BP messages. Our model, Deep Attentive Belief Propagation (DABP), takes the factor graph and the BP messages in each iteration as the input and infers the optimal weights and damping factors through GRUs and GATs, followed by a multi-head attention layer. Furthermore, unlike existing neural-based BP variants, we propose a novel self-supervised learning algorithm for DABP with a smoothed solution cost, which does not require expensive training labels and also avoids the common out-of-distribution issue through efficient online learning. Extensive experiments show that our model significantly outperforms state-of-the-art baselines.

</p>
</details>

<details><summary><b>Removal of Ocular Artifacts in EEG Using Deep Learning</b>
<a href="https://arxiv.org/abs/2209.11980">arxiv:2209.11980</a>
&#x1F4C8; 2 <br>
<p>Mehmet Akif Ozdemir, Sumeyye Kizilisik, Onan Guren</p></summary>
<p>

**Abstract:** EEG signals are complex and low-frequency signals. Therefore, they are easily influenced by external factors. EEG artifact removal is crucial in neuroscience because artifacts have a significant impact on the results of EEG analysis. The removal of ocular artifacts is the most challenging among these artifacts. In this study, a novel ocular artifact removal method is presented by developing bidirectional long-short term memory (BiLSTM)-based deep learning (DL) models. We created a benchmarking dataset to train and test proposed DL models by combining the EEGdenoiseNet and DEAP datasets. We also augmented the data by contaminating ground-truth clean EEG signals with EOG at various SNR levels. The BiLSTM network is then fed to features extracted from augmented signals using highly-localized time-frequency (TF) coefficients obtained by wavelet synchrosqueezed transform (WSST). We also compare the WSST-based DL model results with traditional TF analysis (TFA) methods namely short-time Fourier transformation (STFT) and continuous wavelet transform (CWT) as well as augmented raw signals. The best average MSE value of 0.3066 was obtained by the first time-proposed BiLSTM-based WSST-Net model. Our results demonstrated the WSST-Net model significantly improves artifact removal performance compared to traditional TF and raw signal methods. Also, the proposed EOG removal approach reveals that it outperforms many conventional and DL-based ocular artifact removal methods in the literature.

</p>
</details>

<details><summary><b>Approximate better, Attack stronger: Adversarial Example Generation via Asymptotically Gaussian Mixture Distribution</b>
<a href="https://arxiv.org/abs/2209.11964">arxiv:2209.11964</a>
&#x1F4C8; 2 <br>
<p>Zhengwei Fang, Rui Wang, Tao Huang, Liping Jing</p></summary>
<p>

**Abstract:** Strong adversarial examples are the keys to evaluating and enhancing the robustness of deep neural networks. The popular adversarial attack algorithms maximize the non-concave loss function using the gradient ascent. However, the performance of each attack is usually sensitive to, for instance, minor image transformations due to insufficient information (only one input example, few white-box source models and unknown defense strategies). Hence, the crafted adversarial examples are prone to overfit the source model, which limits their transferability to unidentified architectures. In this paper, we propose Multiple Asymptotically Normal Distribution Attacks (MultiANDA), a novel method that explicitly characterizes adversarial perturbations from a learned distribution. Specifically, we approximate the posterior distribution over the perturbations by taking advantage of the asymptotic normality property of stochastic gradient ascent (SGA), then apply the ensemble strategy on this procedure to estimate a Gaussian mixture model for a better exploration of the potential optimization space. Drawing perturbations from the learned distribution allow us to generate any number of adversarial examples for each input. The approximated posterior essentially describes the stationary distribution of SGA iterations, which captures the geometric information around the local optimum. Thus, the samples drawn from the distribution reliably maintain the transferability. Our proposed method outperforms nine state-of-the-art black-box attacks on deep learning models with or without defenses through extensive experiments on seven normally trained and seven defence models.

</p>
</details>

<details><summary><b>Raising the Bar on the Evaluation of Out-of-Distribution Detection</b>
<a href="https://arxiv.org/abs/2209.11960">arxiv:2209.11960</a>
&#x1F4C8; 2 <br>
<p>Jishnu Mukhoti, Tsung-Yu Lin, Bor-Chun Chen, Ashish Shah, Philip H. S. Torr, Puneet K. Dokania, Ser-Nam Lim</p></summary>
<p>

**Abstract:** In image classification, a lot of development has happened in detecting out-of-distribution (OoD) data. However, most OoD detection methods are evaluated on a standard set of datasets, arbitrarily different from training data. There is no clear definition of what forms a ``good" OoD dataset. Furthermore, the state-of-the-art OoD detection methods already achieve near perfect results on these standard benchmarks. In this paper, we define 2 categories of OoD data using the subtly different concepts of perceptual/visual and semantic similarity to in-distribution (iD) data. We define Near OoD samples as perceptually similar but semantically different from iD samples, and Shifted samples as points which are visually different but semantically akin to iD data. We then propose a GAN based framework for generating OoD samples from each of these 2 categories, given an iD dataset. Through extensive experiments on MNIST, CIFAR-10/100 and ImageNet, we show that a) state-of-the-art OoD detection methods which perform exceedingly well on conventional benchmarks are significantly less robust to our proposed benchmark. Moreover, b) models performing well on our setup also perform well on conventional real-world OoD detection benchmarks and vice versa, thereby indicating that one might not even need a separate OoD set, to reliably evaluate performance in OoD detection.

</p>
</details>

<details><summary><b>Are Machine Programming Systems using Right Source-Code Measures to Select Code Repositories?</b>
<a href="https://arxiv.org/abs/2209.11946">arxiv:2209.11946</a>
&#x1F4C8; 2 <br>
<p>Niranjan Hasabnis</p></summary>
<p>

**Abstract:** Machine programming (MP) is an emerging field at the intersection of deterministic and probabilistic computing, and it aims to assist software and hardware engineers, among other applications. Along with powerful compute resources, MP systems often rely on vast amount of open-source code to learn interesting properties about code and programming and solve problems in the areas of debugging, code recommendation, auto-completion, etc. Unfortunately, several of the existing MP systems either do not consider quality of code repositories or use atypical quality measures than those typically used in software engineering community to select them. As such, impact of quality of code repositories on the performance of these systems needs to be studied.
  In this preliminary paper, we evaluate impact of different quality repositories on the performance of a candidate MP system. Towards that objective, we develop a framework, named GitRank, to rank open-source repositories on quality, maintainability, and popularity by leveraging existing research on this topic. We then apply GitRank to evaluate correlation between the quality measures used by the candidate MP system and the quality measures used by our framework. Our preliminary results reveal some correlation between the quality measures used in GitRank and ControlFlag's performance, suggesting that some of the measures used in GitRank are applicable to ControlFlag. But it also raises questions around right quality measures for code repositories used in MP systems. We believe that our findings also generate interesting insights towards code quality measures that affect performance of MP systems.

</p>
</details>

<details><summary><b>Interventional Causal Representation Learning</b>
<a href="https://arxiv.org/abs/2209.11924">arxiv:2209.11924</a>
&#x1F4C8; 2 <br>
<p>Kartik Ahuja, Yixin Wang, Divyat Mahajan, Yoshua Bengio</p></summary>
<p>

**Abstract:** The theory of identifiable representation learning aims to build general-purpose methods that extract high-level latent (causal) factors from low-level sensory data. Most existing works focus on identifiable representation learning with observational data, relying on distributional assumptions on latent (causal) factors. However, in practice, we often also have access to interventional data for representation learning. How can we leverage interventional data to help identify high-level latents? To this end, we explore the role of interventional data for identifiable representation learning in this work. We study the identifiability of latent causal factors with and without interventional data, under minimal distributional assumptions on the latents. We prove that, if the true latent variables map to the observed high-dimensional data via a polynomial function, then representation learning via minimizing the standard reconstruction loss of autoencoders identifies the true latents up to affine transformation. If we further have access to interventional data generated by hard $do$ interventions on some of the latents, then we can identify these intervened latents up to permutation, shift and scaling.

</p>
</details>

<details><summary><b>Online Allocation and Learning in the Presence of Strategic Agents</b>
<a href="https://arxiv.org/abs/2209.12112">arxiv:2209.12112</a>
&#x1F4C8; 1 <br>
<p>Steven Yin, Shipra Agrawal, Assaf Zeevi</p></summary>
<p>

**Abstract:** We study the problem of allocating $T$ sequentially arriving items among $n$ homogeneous agents under the constraint that each agent must receive a pre-specified fraction of all items, with the objective of maximizing the agents' total valuation of items allocated to them. The agents' valuations for the item in each round are assumed to be i.i.d. but their distribution is a priori unknown to the central planner. Therefore, the central planner needs to implicitly learn these distributions from the observed values in order to pick a good allocation policy. However, an added challenge here is that the agents are strategic with incentives to misreport their valuations in order to receive better allocations. This sets our work apart both from the online auction design settings which typically assume known valuation distributions and/or involve payments, and from the online learning settings that do not consider strategic agents. To that end, our main contribution is an online learning based allocation mechanism that is approximately Bayesian incentive compatible, and when all agents are truthful, guarantees a sublinear regret for individual agents' utility compared to that under the optimal offline allocation policy.

</p>
</details>

<details><summary><b>Valuation of Public Bus Electrification with Open Data</b>
<a href="https://arxiv.org/abs/2209.12107">arxiv:2209.12107</a>
&#x1F4C8; 1 <br>
<p>Upadhi Vijay, Soomin Woo, Scott J. Moura, Akshat Jain, David Rodriguez, Sergio Gambacorta, Giuseppe Ferrara, Luigi Lanuzza, Christian Zulberti, Erika Mellekas, Carlo Papa</p></summary>
<p>

**Abstract:** This research provides a novel framework to estimate the economic, environmental, and social values of electrifying public transit buses, for cities across the world, based on open-source data. Electric buses are a compelling candidate to replace diesel buses for the environmental and social benefits. However, the state-of-art models to evaluate the value of bus electrification are limited in applicability because they require granular and bespoke data on bus operation that can be difficult to procure. Our valuation tool uses General Transit Feed Specification, a standard data format used by transit agencies worldwide, to provide high-level guidance on developing a prioritization strategy for electrifying a bus fleet. We develop physics-informed machine learning models to evaluate the energy consumption, the carbon emissions, the health impacts, and the total cost of ownership for each transit route. We demonstrate the scalability of our tool with a case study of the bus lines in the Greater Boston and Milan metropolitan areas.

</p>
</details>

<details><summary><b>Energy-Environment evaluation and Forecast of a Novel Regenerative turboshaft engine combine cycle with DNN application</b>
<a href="https://arxiv.org/abs/2209.12020">arxiv:2209.12020</a>
&#x1F4C8; 1 <br>
<p>Mahdi Alibeigi, Mohammadreza Sabzehali</p></summary>
<p>

**Abstract:** In this integrated study, a turboshaft engine was evaluated by adding inlet air cooling and regenerative cooling based on energy-environment analysis. First, impacts of flight-Mach number, flight altitude, the compression ratio of compressor-1 in the main cycle, the turbine inlet temperature of turbine-1 in the main cycle, temperature fraction of turbine-2, the compression ratio of the accessory cycle, and inlet air temperature variation in inlet air cooling system on some functional performance parameters of Regenerative turboshaft engine cycle equipped with inlet air cooling system such as power-specific fuel consumption, Power output, thermal efficiency, and mass flow rate of Nitride oxides (NOx) including NO and NO2 has been investigated via using hydrogen as fuel working. Consequently, based on the analysis, a model was developed to predict the energy-environment performance of the Regenerative turboshaft engine cycle equipped with a cooling air cooling system based on a deep neural network (DNN) with 2 hidden layers with 625 neurons for each hidden layer. The model proposed to predict the amount of thermal efficiency and the mass flow rate of nitride oxide (NOx) containing NO and NO2. The results demonstrated the accuracy of the integrated DNN model with the proper amount of the MSE, MAE, and RMSD cost function for both predicted outputs to validate both testing and training data. Also, R and R^2 are noticeably calculated very close to 1 for both thermal Efficiency and NOx emission mass flow rate for both validations of thermal efficiency and NOx emission mass flow rate prediction values with its training and its testing data.

</p>
</details>

<details><summary><b>On Gender Bias in Fake News</b>
<a href="https://arxiv.org/abs/2209.11984">arxiv:2209.11984</a>
&#x1F4C8; 1 <br>
<p>Navya Sahadevan, Deepak P</p></summary>
<p>

**Abstract:** Data science research into fake news has gathered much momentum in recent years, arguably facilitated by the emergence of large public benchmark datasets. While it has been well-established within media studies that gender bias is an issue that pervades news media, there has been very little exploration into the relationship between gender bias and fake news. In this work, we provide the first empirical analysis of gender bias vis-a-vis fake news, leveraging simple and transparent lexicon-based methods over public benchmark datasets. Our analysis establishes the increased prevalance of gender bias in fake news across three facets viz., abundance, affect and proximal words. The insights from our analysis provide a strong argument that gender bias needs to be an important consideration in research into fake news.

</p>
</details>

<details><summary><b>S^2-Transformer for Mask-Aware Hyperspectral Image Reconstruction</b>
<a href="https://arxiv.org/abs/2209.12075">arxiv:2209.12075</a>
&#x1F4C8; 0 <br>
<p>Jiamian Wang, Kunpeng Li, Yulun Zhang, Xin Yuan, Zhiqiang Tao</p></summary>
<p>

**Abstract:** The technology of hyperspectral imaging (HSI) records the visual information upon long-range-distributed spectral wavelengths. A representative hyperspectral image acquisition procedure conducts a 3D-to-2D encoding by the coded aperture snapshot spectral imager (CASSI), and requires a software decoder for the 3D signal reconstruction. Based on this encoding procedure, two major challenges stand in the way of a high-fidelity reconstruction: (i) To obtain 2D measurements, CASSI dislocates multiple channels by disperser-titling and squeezes them onto the same spatial region, yielding an entangled data loss. (ii) The physical coded aperture (mask) will lead to a masked data loss by selectively blocking the pixel-wise light exposure. To tackle these challenges, we propose a spatial-spectral (S2-) transformer architecture with a mask-aware learning strategy. Firstly, we simultaneously leverage spatial and spectral attention modelings to disentangle the blended information in the 2D measurement along both two dimensions. A series of Transformer structures across spatial & spectral clues are systematically designed, which considers the information inter-dependency between the two-fold cues. Secondly, the masked pixels will induce higher prediction difficulty and should be treated differently from unmasked ones. Thereby, we adaptively prioritize the loss penalty attributing to the mask structure by inferring the difficulty-level upon the mask-aware prediction. Our proposed method not only sets a new state-of-the-art quantitatively, but also yields a better perceptual quality upon structured areas.

</p>
</details>

<details><summary><b>Communication-Efficient {Federated} Learning Using Censored Heavy Ball Descent</b>
<a href="https://arxiv.org/abs/2209.11944">arxiv:2209.11944</a>
&#x1F4C8; 0 <br>
<p>Yicheng Chen, Rick S. Blum, Brian M. Sadler</p></summary>
<p>

**Abstract:** Distributed machine learning enables scalability and computational offloading, but requires significant levels of communication. Consequently, communication efficiency in distributed learning settings is an important consideration, especially when the communications are wireless and battery-driven devices are employed. In this paper we develop a censoring-based heavy ball (CHB) method for distributed learning in a server-worker architecture. Each worker self-censors unless its local gradient is sufficiently different from the previously transmitted one. The significant practical advantages of the HB method for learning problems are well known, but the question of reducing communications has not been addressed. CHB takes advantage of the HB smoothing to eliminate reporting small changes, and provably achieves a linear convergence rate equivalent to that of the classical HB method for smooth and strongly convex objective functions. The convergence guarantee of CHB is theoretically justified for both convex and nonconvex cases. In addition we prove that, under some conditions, at least half of all communications can be eliminated without any impact on convergence rate. Extensive numerical results validate the communication efficiency of CHB on both synthetic and real datasets, for convex, nonconvex, and nondifferentiable cases. Given a target accuracy, CHB can significantly reduce the number of communications compared to existing algorithms, achieving the same accuracy without slowing down the optimization process.

</p>
</details>


{% endraw %}
Prev: [2022.09.23]({{ '/2022/09/23/2022.09.23.html' | relative_url }})  Next: [2022.09.25]({{ '/2022/09/25/2022.09.25.html' | relative_url }})