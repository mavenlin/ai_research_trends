## Summary for 2021-11-08, created on 2021-12-17


<details><summary><b>Understanding the Effects of Dataset Characteristics on Offline Reinforcement Learning</b>
<a href="https://arxiv.org/abs/2111.04714">arxiv:2111.04714</a>
&#x1F4C8; 533 <br>
<p>Kajetan Schweighofer, Markus Hofmarcher, Marius-Constantin Dinu, Philipp Renz, Angela Bitto-Nemling, Vihang Patil, Sepp Hochreiter</p></summary>
<p>

**Abstract:** In real world, affecting the environment by a weak policy can be expensive or very risky, therefore hampers real world applications of reinforcement learning. Offline Reinforcement Learning (RL) can learn policies from a given dataset without interacting with the environment. However, the dataset is the only source of information for an Offline RL algorithm and determines the performance of the learned policy. We still lack studies on how dataset characteristics influence different Offline RL algorithms. Therefore, we conducted a comprehensive empirical analysis of how dataset characteristics effect the performance of Offline RL algorithms for discrete action environments. A dataset is characterized by two metrics: (1) the average dataset return measured by the Trajectory Quality (TQ) and (2) the coverage measured by the State-Action Coverage (SACo). We found that variants of the off-policy Deep Q-Network family require datasets with high SACo to perform well. Algorithms that constrain the learned policy towards the given dataset perform well for datasets with high TQ or SACo. For datasets with high TQ, Behavior Cloning outperforms or performs similarly to the best Offline RL algorithms.

</p>
</details>

<details><summary><b>Information-Theoretic Bayes Risk Lower Bounds for Realizable Models</b>
<a href="https://arxiv.org/abs/2111.04579">arxiv:2111.04579</a>
&#x1F4C8; 206 <br>
<p>Matthew Nokleby, Ahmad Beirami</p></summary>
<p>

**Abstract:** We derive information-theoretic lower bounds on the Bayes risk and generalization error of realizable machine learning models. In particular, we employ an analysis in which the rate-distortion function of the model parameters bounds the required mutual information between the training samples and the model parameters in order to learn a model up to a Bayes risk constraint. For realizable models, we show that both the rate distortion function and mutual information admit expressions that are convenient for analysis. For models that are (roughly) lower Lipschitz in their parameters, we bound the rate distortion function from below, whereas for VC classes, the mutual information is bounded above by $d_\mathrm{vc}\log(n)$. When these conditions match, the Bayes risk with respect to the zero-one loss scales no faster than $Î©(d_\mathrm{vc}/n)$, which matches known outer bounds and minimax lower bounds up to logarithmic factors. We also consider the impact of label noise, providing lower bounds when training and/or test samples are corrupted.

</p>
</details>

<details><summary><b>DeepSteal: Advanced Model Extractions Leveraging Efficient Weight Stealing in Memories</b>
<a href="https://arxiv.org/abs/2111.04625">arxiv:2111.04625</a>
&#x1F4C8; 67 <br>
<p>Adnan Siraj Rakin, Md Hafizul Islam Chowdhuryy, Fan Yao, Deliang Fan</p></summary>
<p>

**Abstract:** Recent advancements of Deep Neural Networks (DNNs) have seen widespread deployment in multiple security-sensitive domains. The need of resource-intensive training and use of valuable domain-specific training data have made these models a top intellectual property (IP) for model owners. One of the major threats to the DNN privacy is model extraction attacks where adversaries attempt to steal sensitive information in DNN models. Recent studies show hardware-based side channel attacks can reveal internal knowledge about DNN models (e.g., model architectures) However, to date, existing attacks cannot extract detailed model parameters (e.g., weights/biases). In this work, for the first time, we propose an advanced model extraction attack framework DeepSteal that effectively steals DNN weights with the aid of memory side-channel attack. Our proposed DeepSteal comprises two key stages. Firstly, we develop a new weight bit information extraction method, called HammerLeak, through adopting the rowhammer based hardware fault technique as the information leakage vector. HammerLeak leverages several novel system-level techniques tailed for DNN applications to enable fast and efficient weight stealing. Secondly, we propose a novel substitute model training algorithm with Mean Clustering weight penalty, which leverages the partial leaked bit information effectively and generates a substitute prototype of the target victim model. We evaluate this substitute model extraction method on three popular image datasets (e.g., CIFAR-10/100/GTSRB) and four DNN architectures (e.g., ResNet-18/34/Wide-ResNet/VGG-11). The extracted substitute model has successfully achieved more than 90 % test accuracy on deep residual networks for the CIFAR-10 dataset. Moreover, our extracted substitute model could also generate effective adversarial input samples to fool the victim model.

</p>
</details>

<details><summary><b>Mixed Transformer U-Net For Medical Image Segmentation</b>
<a href="https://arxiv.org/abs/2111.04734">arxiv:2111.04734</a>
&#x1F4C8; 63 <br>
<p>Hongyi Wang, Shiao Xie, Lanfen Lin, Yutaro Iwamoto, Xian-Hua Han, Yen-Wei Chen, Ruofeng Tong</p></summary>
<p>

**Abstract:** Though U-Net has achieved tremendous success in medical image segmentation tasks, it lacks the ability to explicitly model long-range dependencies. Therefore, Vision Transformers have emerged as alternative segmentation structures recently, for their innate ability of capturing long-range correlations through Self-Attention (SA). However, Transformers usually rely on large-scale pre-training and have high computational complexity. Furthermore, SA can only model self-affinities within a single sample, ignoring the potential correlations of the overall dataset. To address these problems, we propose a novel Transformer module named Mixed Transformer Module (MTM) for simultaneous inter- and intra- affinities learning. MTM first calculates self-affinities efficiently through our well-designed Local-Global Gaussian-Weighted Self-Attention (LGG-SA). Then, it mines inter-connections between data samples through External Attention (EA). By using MTM, we construct a U-shaped model named Mixed Transformer U-Net (MT-UNet) for accurate medical image segmentation. We test our method on two different public datasets, and the experimental results show that the proposed method achieves better performance over other state-of-the-art methods. The code is available at: https://github.com/Dootmaan/MT-UNet.

</p>
</details>

<details><summary><b>Realizable Learning is All You Need</b>
<a href="https://arxiv.org/abs/2111.04746">arxiv:2111.04746</a>
&#x1F4C8; 44 <br>
<p>Max Hopkins, Daniel Kane, Shachar Lovett, Gaurav Mahajan</p></summary>
<p>

**Abstract:** The equivalence of realizable and agnostic learnability is a fundamental phenomenon in learning theory. With variants ranging from classical settings like PAC learning and regression to recent trends such as adversarially robust and private learning, it's surprising that we still lack a unified theory; traditional proofs of the equivalence tend to be disparate, and rely on strong model-specific assumptions like uniform convergence and sample compression.
  In this work, we give the first model-independent framework explaining the equivalence of realizable and agnostic learnability: a three-line blackbox reduction that simplifies, unifies, and extends our understanding across a wide variety of settings. This includes models with no known characterization of learnability such as learning with arbitrary distributional assumptions or general loss, as well as a host of other popular settings such as robust learning, partial learning, fair learning, and the statistical query model.
  More generally, we argue that the equivalence of realizable and agnostic learning is actually a special case of a broader phenomenon we call property generalization: any desirable property of a learning algorithm (e.g.\ noise tolerance, privacy, stability) that can be satisfied over finite hypothesis classes extends (possibly in some variation) to any learnable hypothesis class.

</p>
</details>

<details><summary><b>Deep Marching Tetrahedra: a Hybrid Representation for High-Resolution 3D Shape Synthesis</b>
<a href="https://arxiv.org/abs/2111.04276">arxiv:2111.04276</a>
&#x1F4C8; 21 <br>
<p>Tianchang Shen, Jun Gao, Kangxue Yin, Ming-Yu Liu, Sanja Fidler</p></summary>
<p>

**Abstract:** We introduce DMTet, a deep 3D conditional generative model that can synthesize high-resolution 3D shapes using simple user guides such as coarse voxels. It marries the merits of implicit and explicit 3D representations by leveraging a novel hybrid 3D representation. Compared to the current implicit approaches, which are trained to regress the signed distance values, DMTet directly optimizes for the reconstructed surface, which enables us to synthesize finer geometric details with fewer artifacts. Unlike deep 3D generative models that directly generate explicit representations such as meshes, our model can synthesize shapes with arbitrary topology. The core of DMTet includes a deformable tetrahedral grid that encodes a discretized signed distance function and a differentiable marching tetrahedra layer that converts the implicit signed distance representation to the explicit surface mesh representation. This combination allows joint optimization of the surface geometry and topology as well as generation of the hierarchy of subdivisions using reconstruction and adversarial losses defined explicitly on the surface mesh. Our approach significantly outperforms existing work on conditional shape synthesis from coarse voxel inputs, trained on a dataset of complex 3D animal shapes. Project page: https://nv-tlabs.github.io/DMTet/.

</p>
</details>

<details><summary><b>Estimating High Order Gradients of the Data Distribution by Denoising</b>
<a href="https://arxiv.org/abs/2111.04726">arxiv:2111.04726</a>
&#x1F4C8; 20 <br>
<p>Chenlin Meng, Yang Song, Wenzhe Li, Stefano Ermon</p></summary>
<p>

**Abstract:** The first order derivative of a data density can be estimated efficiently by denoising score matching, and has become an important component in many applications, such as image generation and audio synthesis. Higher order derivatives provide additional local information about the data distribution and enable new applications. Although they can be estimated via automatic differentiation of a learned density model, this can amplify estimation errors and is expensive in high dimensional settings. To overcome these limitations, we propose a method to directly estimate high order derivatives (scores) of a data density from samples. We first show that denoising score matching can be interpreted as a particular case of Tweedie's formula. By leveraging Tweedie's formula on higher order moments, we generalize denoising score matching to estimate higher order derivatives. We demonstrate empirically that models trained with the proposed method can approximate second order derivatives more efficiently and accurately than via automatic differentiation. We show that our models can be used to quantify uncertainty in denoising and to improve the mixing speed of Langevin dynamics via Ozaki discretization for sampling synthetic data and natural images.

</p>
</details>

<details><summary><b>Get a Model! Model Hijacking Attack Against Machine Learning Models</b>
<a href="https://arxiv.org/abs/2111.04394">arxiv:2111.04394</a>
&#x1F4C8; 20 <br>
<p>Ahmed Salem, Michael Backes, Yang Zhang</p></summary>
<p>

**Abstract:** Machine learning (ML) has established itself as a cornerstone for various critical applications ranging from autonomous driving to authentication systems. However, with this increasing adoption rate of machine learning models, multiple attacks have emerged. One class of such attacks is training time attack, whereby an adversary executes their attack before or during the machine learning model training. In this work, we propose a new training time attack against computer vision based machine learning models, namely model hijacking attack. The adversary aims to hijack a target model to execute a different task than its original one without the model owner noticing. Model hijacking can cause accountability and security risks since a hijacked model owner can be framed for having their model offering illegal or unethical services. Model hijacking attacks are launched in the same way as existing data poisoning attacks. However, one requirement of the model hijacking attack is to be stealthy, i.e., the data samples used to hijack the target model should look similar to the model's original training dataset. To this end, we propose two different model hijacking attacks, namely Chameleon and Adverse Chameleon, based on a novel encoder-decoder style ML model, namely the Camouflager. Our evaluation shows that both of our model hijacking attacks achieve a high attack success rate, with a negligible drop in model utility.

</p>
</details>

<details><summary><b>A Private and Computationally-Efficient Estimator for Unbounded Gaussians</b>
<a href="https://arxiv.org/abs/2111.04609">arxiv:2111.04609</a>
&#x1F4C8; 10 <br>
<p>Gautam Kamath, Argyris Mouzakis, Vikrant Singhal, Thomas Steinke, Jonathan Ullman</p></summary>
<p>

**Abstract:** We give the first polynomial-time, polynomial-sample, differentially private estimator for the mean and covariance of an arbitrary Gaussian distribution $\mathcal{N}(Î¼,Î£)$ in $\mathbb{R}^d$. All previous estimators are either nonconstructive, with unbounded running time, or require the user to specify a priori bounds on the parameters $Î¼$ and $Î£$. The primary new technical tool in our algorithm is a new differentially private preconditioner that takes samples from an arbitrary Gaussian $\mathcal{N}(0,Î£)$ and returns a matrix $A$ such that $A Î£A^T$ has constant condition number.

</p>
</details>

<details><summary><b>Losses, Dissonances, and Distortions</b>
<a href="https://arxiv.org/abs/2111.05128">arxiv:2111.05128</a>
&#x1F4C8; 9 <br>
<p>Pablo Samuel Castro</p></summary>
<p>

**Abstract:** In this paper I present a study in using the losses and gradients obtained during the training of a simple function approximator as a mechanism for creating musical dissonance and visual distortion in a solo piano performance setting. These dissonances and distortions become part of an artistic performance not just by affecting the visualizations, but also by affecting the artistic musical performance. The system is designed such that the performer can in turn affect the training process itself, thereby creating a closed feedback loop between two processes: the training of a machine learning model and the performance of an improvised piano piece.

</p>
</details>

<details><summary><b>SustainBench: Benchmarks for Monitoring the Sustainable Development Goals with Machine Learning</b>
<a href="https://arxiv.org/abs/2111.04724">arxiv:2111.04724</a>
&#x1F4C8; 9 <br>
<p>Christopher Yeh, Chenlin Meng, Sherrie Wang, Anne Driscoll, Erik Rozi, Patrick Liu, Jihyeon Lee, Marshall Burke, David B. Lobell, Stefano Ermon</p></summary>
<p>

**Abstract:** Progress toward the United Nations Sustainable Development Goals (SDGs) has been hindered by a lack of data on key environmental and socioeconomic indicators, which historically have come from ground surveys with sparse temporal and spatial coverage. Recent advances in machine learning have made it possible to utilize abundant, frequently-updated, and globally available data, such as from satellites or social media, to provide insights into progress toward SDGs. Despite promising early results, approaches to using such data for SDG measurement thus far have largely evaluated on different datasets or used inconsistent evaluation metrics, making it hard to understand whether performance is improving and where additional research would be most fruitful. Furthermore, processing satellite and ground survey data requires domain knowledge that many in the machine learning community lack. In this paper, we introduce SustainBench, a collection of 15 benchmark tasks across 7 SDGs, including tasks related to economic development, agriculture, health, education, water and sanitation, climate action, and life on land. Datasets for 11 of the 15 tasks are released publicly for the first time. Our goals for SustainBench are to (1) lower the barriers to entry for the machine learning community to contribute to measuring and achieving the SDGs; (2) provide standard benchmarks for evaluating machine learning models on tasks across a variety of SDGs; and (3) encourage the development of novel machine learning methods where improved model performance facilitates progress towards the SDGs.

</p>
</details>

<details><summary><b>Explaining Hyperparameter Optimization via Partial Dependence Plots</b>
<a href="https://arxiv.org/abs/2111.04820">arxiv:2111.04820</a>
&#x1F4C8; 8 <br>
<p>Julia Moosbauer, Julia Herbinger, Giuseppe Casalicchio, Marius Lindauer, Bernd Bischl</p></summary>
<p>

**Abstract:** Automated hyperparameter optimization (HPO) can support practitioners to obtain peak performance in machine learning models. However, there is often a lack of valuable insights into the effects of different hyperparameters on the final model performance. This lack of explainability makes it difficult to trust and understand the automated HPO process and its results. We suggest using interpretable machine learning (IML) to gain insights from the experimental data obtained during HPO with Bayesian optimization (BO). BO tends to focus on promising regions with potential high-performance configurations and thus induces a sampling bias. Hence, many IML techniques, such as the partial dependence plot (PDP), carry the risk of generating biased interpretations. By leveraging the posterior uncertainty of the BO surrogate model, we introduce a variant of the PDP with estimated confidence bands. We propose to partition the hyperparameter space to obtain more confident and reliable PDPs in relevant sub-regions. In an experimental study, we provide quantitative evidence for the increased quality of the PDPs within sub-regions.

</p>
</details>

<details><summary><b>American Hate Crime Trends Prediction with Event Extraction</b>
<a href="https://arxiv.org/abs/2111.04951">arxiv:2111.04951</a>
&#x1F4C8; 7 <br>
<p>Songqiao Han, Hailiang Huang, Jiangwei Liu, Shengsheng Xiao</p></summary>
<p>

**Abstract:** Social media platforms may provide potential space for discourses that contain hate speech, and even worse, can act as a propagation mechanism for hate crimes. The FBI's Uniform Crime Reporting (UCR) Program collects hate crime data and releases statistic report yearly. These statistics provide information in determining national hate crime trends. The statistics can also provide valuable holistic and strategic insight for law enforcement agencies or justify lawmakers for specific legislation. However, the reports are mostly released next year and lag behind many immediate needs. Recent research mainly focuses on hate speech detection in social media text or empirical studies on the impact of a confirmed crime. This paper proposes a framework that first utilizes text mining techniques to extract hate crime events from New York Times news, then uses the results to facilitate predicting American national-level and state-level hate crime trends. Experimental results show that our method can significantly enhance the prediction performance compared with time series or regression methods without event-related factors. Our framework broadens the methods of national-level and state-level hate crime trends prediction.

</p>
</details>

<details><summary><b>Auto-Encoding Knowledge Graph for Unsupervised Medical Report Generation</b>
<a href="https://arxiv.org/abs/2111.04318">arxiv:2111.04318</a>
&#x1F4C8; 7 <br>
<p>Fenglin Liu, Chenyu You, Xian Wu, Shen Ge, Sheng Wang, Xu Sun</p></summary>
<p>

**Abstract:** Medical report generation, which aims to automatically generate a long and coherent report of a given medical image, has been receiving growing research interests. Existing approaches mainly adopt a supervised manner and heavily rely on coupled image-report pairs. However, in the medical domain, building a large-scale image-report paired dataset is both time-consuming and expensive. To relax the dependency on paired data, we propose an unsupervised model Knowledge Graph Auto-Encoder (KGAE) which accepts independent sets of images and reports in training. KGAE consists of a pre-constructed knowledge graph, a knowledge-driven encoder and a knowledge-driven decoder. The knowledge graph works as the shared latent space to bridge the visual and textual domains; The knowledge-driven encoder projects medical images and reports to the corresponding coordinates in this latent space and the knowledge-driven decoder generates a medical report given a coordinate in this space. Since the knowledge-driven encoder and decoder can be trained with independent sets of images and reports, KGAE is unsupervised. The experiments show that the unsupervised KGAE generates desirable medical reports without using any image-report training pairs. Moreover, KGAE can also work in both semi-supervised and supervised settings, and accept paired images and reports in training. By further fine-tuning with image-report pairs, KGAE consistently outperforms the current state-of-the-art models on two datasets.

</p>
</details>

<details><summary><b>FPM: A Collection of Large-scale Foundation Pre-trained Language Models</b>
<a href="https://arxiv.org/abs/2111.04909">arxiv:2111.04909</a>
&#x1F4C8; 6 <br>
<p>Dezhou Shen</p></summary>
<p>

**Abstract:** Recent work in language modeling has shown that training large-scale Transformer models has promoted the latest developments in natural language processing applications. However, there is very little work to unify the current effective models. In this work, we use the current effective model structure to launch a model set through the current most mainstream technology. We think this will become the basic model in the future. For Chinese, using the GPT-2[9] model, a 10.3 billion parameter language model was trained on the Chinese dataset, and, in particular, a 2.9 billion parameter language model based on dialogue data was trained; the BERT model was trained on the Chinese dataset with 495 million parameters; the Transformer model has trained a language model with 5.6 billion parameters on the Chinese dataset. In English, corresponding training work has also been done. Using the GPT-2 model, a language model with 6.4 billion parameters was trained on the English dataset; the BERT[3] model trained a language model with 1.24 billion parameters on the English dataset, and in particular, it trained a 688 million parameter based on single card training technology Language model; Transformer model trained a language model with 5.6 billion parameters on the English dataset. In the TNEWS classification task evaluated by CLUE[13], the BERT-C model exceeded the 59.46% accuracy of ALBERT-xxlarge with an accuracy rate of 59.99%, an increase of 0.53%. In the QQP classification task evaluated by GLUE[11], the accuracy rate of 78.95% surpassed the accuracy rate of BERT-Large of 72.1%, an increase of 6.85%. Compared with the current accuracy rate of ERNIE, the first place in the GLUE evaluation of 75.2%, an increase of 3.75%.

</p>
</details>

<details><summary><b>Safe Policy Optimization with Local Generalized Linear Function Approximations</b>
<a href="https://arxiv.org/abs/2111.04894">arxiv:2111.04894</a>
&#x1F4C8; 6 <br>
<p>Akifumi Wachi, Yunyue Wei, Yanan Sui</p></summary>
<p>

**Abstract:** Safe exploration is a key to applying reinforcement learning (RL) in safety-critical systems. Existing safe exploration methods guaranteed safety under the assumption of regularity, and it has been difficult to apply them to large-scale real problems. We propose a novel algorithm, SPO-LF, that optimizes an agent's policy while learning the relation between a locally available feature obtained by sensors and environmental reward/safety using generalized linear function approximations. We provide theoretical guarantees on its safety and optimality. We experimentally show that our algorithm is 1) more efficient in terms of sample complexity and computational cost and 2) more applicable to large-scale problems than previous safe RL methods with theoretical guarantees, and 3) comparably sample-efficient and safer compared with existing advanced deep RL methods with safety constraints.

</p>
</details>

<details><summary><b>Cascaded Multilingual Audio-Visual Learning from Videos</b>
<a href="https://arxiv.org/abs/2111.04823">arxiv:2111.04823</a>
&#x1F4C8; 6 <br>
<p>Andrew Rouditchenko, Angie Boggust, David Harwath, Samuel Thomas, Hilde Kuehne, Brian Chen, Rameswar Panda, Rogerio Feris, Brian Kingsbury, Michael Picheny, James Glass</p></summary>
<p>

**Abstract:** In this paper, we explore self-supervised audio-visual models that learn from instructional videos. Prior work has shown that these models can relate spoken words and sounds to visual content after training on a large-scale dataset of videos, but they were only trained and evaluated on videos in English. To learn multilingual audio-visual representations, we propose a cascaded approach that leverages a model trained on English videos and applies it to audio-visual data in other languages, such as Japanese videos. With our cascaded approach, we show an improvement in retrieval performance of nearly 10x compared to training on the Japanese videos solely. We also apply the model trained on English videos to Japanese and Hindi spoken captions of images, achieving state-of-the-art performance.

</p>
</details>

<details><summary><b>OMD: Orthogonal Malware Detection Using Audio, Image, and Static Features</b>
<a href="https://arxiv.org/abs/2111.04710">arxiv:2111.04710</a>
&#x1F4C8; 6 <br>
<p>Lakshmanan Nataraj, Tajuddin Manhar Mohammed, Tejaswi Nanjundaswamy, Satish Chikkagoudar, Shivkumar Chandrasekaran, B. S. Manjunath</p></summary>
<p>

**Abstract:** With the growing number of malware and cyber attacks, there is a need for "orthogonal" cyber defense approaches, which are complementary to existing methods by detecting unique malware samples that are not predicted by other methods. In this paper, we propose a novel and orthogonal malware detection (OMD) approach to identify malware using a combination of audio descriptors, image similarity descriptors and other static/statistical features. First, we show how audio descriptors are effective in classifying malware families when the malware binaries are represented as audio signals. Then, we show that the predictions made on the audio descriptors are orthogonal to the predictions made on image similarity descriptors and other static features. Further, we develop a framework for error analysis and a metric to quantify how orthogonal a new feature set (or type) is with respect to other feature sets. This allows us to add new features and detection methods to our overall framework. Experimental results on malware datasets show that our approach provides a robust framework for orthogonal malware detection.

</p>
</details>

<details><summary><b>Learning Filterbanks for End-to-End Acoustic Beamforming</b>
<a href="https://arxiv.org/abs/2111.04614">arxiv:2111.04614</a>
&#x1F4C8; 6 <br>
<p>Samuele Cornell, Manuel Pariente, FranÃ§ois Grondin, Stefano Squartini</p></summary>
<p>

**Abstract:** Recent work on monaural source separation has shown that performance can be increased by using fully learned filterbanks with short windows. On the other hand it is widely known that, for conventional beamforming techniques, performance increases with long analysis windows. This applies also to most hybrid neural beamforming methods which rely on a deep neural network (DNN) to estimate the spatial covariance matrices. In this work we try to bridge the gap between these two worlds and explore fully end-to-end hybrid neural beamforming in which, instead of using the Short-Time-Fourier Transform, also the analysis and synthesis filterbanks are learnt jointly with the DNN. In detail, we explore two different types of learned filterbanks: fully learned and analytic. We perform a detailed analysis using the recent Clarity Challenge data and show that by using learnt filterbanks is possible to surpass oracle-mask based beamforming for short windows.

</p>
</details>

<details><summary><b>DSBERT:Unsupervised Dialogue Structure learning with BERT</b>
<a href="https://arxiv.org/abs/2111.04933">arxiv:2111.04933</a>
&#x1F4C8; 5 <br>
<p>Bingkun Chen, Shaobing Dai, Shenghua Zheng, Lei Liao, Yang Li</p></summary>
<p>

**Abstract:** Unsupervised dialogue structure learning is an important and meaningful task in natural language processing. The extracted dialogue structure and process can help analyze human dialogue, and play a vital role in the design and evaluation of dialogue systems. The traditional dialogue system requires experts to manually design the dialogue structure, which is very costly. But through unsupervised dialogue structure learning, dialogue structure can be automatically obtained, reducing the cost of developers constructing dialogue process. The learned dialogue structure can be used to promote the dialogue generation of the downstream task system, and improve the logic and consistency of the dialogue robot's reply.In this paper, we propose a Bert-based unsupervised dialogue structure learning algorithm DSBERT (Dialogue Structure BERT). Different from the previous SOTA models VRNN and SVRNN, we combine BERT and AutoEncoder, which can effectively combine context information. In order to better prevent the model from falling into the local optimal solution and make the dialogue state distribution more uniform and reasonable, we also propose three balanced loss functions that can be used for dialogue structure learning. Experimental results show that DSBERT can generate a dialogue structure closer to the real structure, can distinguish sentences with different semantics and map them to different hidden states.

</p>
</details>

<details><summary><b>Lymph Node Detection in T2 MRI with Transformers</b>
<a href="https://arxiv.org/abs/2111.04885">arxiv:2111.04885</a>
&#x1F4C8; 5 <br>
<p>Tejas Sudharshan Mathai, Sungwon Lee, Daniel C. Elton, Thomas C. Shen, Yifan Peng, Zhiyong Lu, Ronald M. Summers</p></summary>
<p>

**Abstract:** Identification of lymph nodes (LN) in T2 Magnetic Resonance Imaging (MRI) is an important step performed by radiologists during the assessment of lymphoproliferative diseases. The size of the nodes play a crucial role in their staging, and radiologists sometimes use an additional contrast sequence such as diffusion weighted imaging (DWI) for confirmation. However, lymph nodes have diverse appearances in T2 MRI scans, making it tough to stage for metastasis. Furthermore, radiologists often miss smaller metastatic lymph nodes over the course of a busy day. To deal with these issues, we propose to use the DEtection TRansformer (DETR) network to localize suspicious metastatic lymph nodes for staging in challenging T2 MRI scans acquired by different scanners and exam protocols. False positives (FP) were reduced through a bounding box fusion technique, and a precision of 65.41\% and sensitivity of 91.66\% at 4 FP per image was achieved. To the best of our knowledge, our results improve upon the current state-of-the-art for lymph node detection in T2 MRI scans.

</p>
</details>

<details><summary><b>An Instance-Dependent Analysis for the Cooperative Multi-Player Multi-Armed Bandit</b>
<a href="https://arxiv.org/abs/2111.04873">arxiv:2111.04873</a>
&#x1F4C8; 5 <br>
<p>Aldo Pacchiano, Peter Bartlett, Michael I. Jordan</p></summary>
<p>

**Abstract:** We study the problem of information sharing and cooperation in Multi-Player Multi-Armed bandits. We propose the first algorithm that achieves logarithmic regret for this problem. Our results are based on two innovations. First, we show that a simple modification to a successive elimination strategy can be used to allow the players to estimate their suboptimality gaps, up to constant factors, in the absence of collisions. Second, we leverage the first result to design a communication protocol that successfully uses the small reward of collisions to coordinate among players, while preserving meaningful instance-dependent logarithmic regret guarantees.

</p>
</details>

<details><summary><b>E(2) Equivariant Self-Attention for Radio Astronomy</b>
<a href="https://arxiv.org/abs/2111.04742">arxiv:2111.04742</a>
&#x1F4C8; 4 <br>
<p>Micah Bowles, Matthew Bromley, Max Allen, Anna Scaife</p></summary>
<p>

**Abstract:** In this work we introduce group-equivariant self-attention models to address the problem of explainable radio galaxy classification in astronomy. We evaluate various orders of both cyclic and dihedral equivariance, and show that including equivariance as a prior both reduces the number of epochs required to fit the data and results in improved performance. We highlight the benefits of equivariance when using self-attention as an explainable model and illustrate how equivariant models statistically attend the same features in their classifications as human astronomers.

</p>
</details>

<details><summary><b>HAPSSA: Holistic Approach to PDF Malware Detection Using Signal and Statistical Analysis</b>
<a href="https://arxiv.org/abs/2111.04703">arxiv:2111.04703</a>
&#x1F4C8; 4 <br>
<p>Tajuddin Manhar Mohammed, Lakshmanan Nataraj, Satish Chikkagoudar, Shivkumar Chandrasekaran, B. S. Manjunath</p></summary>
<p>

**Abstract:** Malicious PDF documents present a serious threat to various security organizations that require modern threat intelligence platforms to effectively analyze and characterize the identity and behavior of PDF malware. State-of-the-art approaches use machine learning (ML) to learn features that characterize PDF malware. However, ML models are often susceptible to evasion attacks, in which an adversary obfuscates the malware code to avoid being detected by an Antivirus. In this paper, we derive a simple yet effective holistic approach to PDF malware detection that leverages signal and statistical analysis of malware binaries. This includes combining orthogonal feature space models from various static and dynamic malware detection methods to enable generalized robustness when faced with code obfuscations. Using a dataset of nearly 30,000 PDF files containing both malware and benign samples, we show that our holistic approach maintains a high detection rate (99.92%) of PDF malware and even detects new malicious files created by simple methods that remove the obfuscation conducted by malware authors to hide their malware, which are undetected by most antiviruses.

</p>
</details>

<details><summary><b>Automated pharyngeal phase detection and bolus localization in videofluoroscopic swallowing study: Killing two birds with one stone?</b>
<a href="https://arxiv.org/abs/2111.04699">arxiv:2111.04699</a>
&#x1F4C8; 4 <br>
<p>Andrea Bandini, Sana Smaoui, Catriona M. Steele</p></summary>
<p>

**Abstract:** The videofluoroscopic swallowing study (VFSS) is a gold-standard imaging technique for assessing swallowing, but analysis and rating of VFSS recordings is time consuming and requires specialized training and expertise. Researchers have demonstrated that it is possible to automatically detect the pharyngeal phase of swallowing and to localize the bolus in VFSS recordings via computer vision approaches, fostering the development of novel techniques for automatic VFSS analysis. However, training of algorithms to perform these tasks requires large amounts of annotated data that are seldom available. We demonstrate that the challenges of pharyngeal phase detection and bolus localization can be solved together using a single approach. We propose a deep-learning framework that jointly tackles pharyngeal phase detection and bolus localization in a weakly-supervised manner, requiring only the initial and final frames of the pharyngeal phase as ground truth annotations for the training. Our approach stems from the observation that bolus presence in the pharynx is the most prominent visual feature upon which to infer whether individual VFSS frames belong to the pharyngeal phase. We conducted extensive experiments with multiple convolutional neural networks (CNNs) on a dataset of 1245 VFSS clips from 59 healthy subjects. We demonstrated that the pharyngeal phase can be detected with an F1-score higher than 0.9. Moreover, by processing the class activation maps of the CNNs, we were able to localize the bolus with promising results, obtaining correlations with ground truth trajectories higher than 0.9, without any manual annotations of bolus location used for training purposes. Once validated on a larger sample of participants with swallowing disorders, our framework will pave the way for the development of intelligent tools for VFSS analysis to support clinicians in swallowing assessment.

</p>
</details>

<details><summary><b>Approximate Neural Architecture Search via Operation Distribution Learning</b>
<a href="https://arxiv.org/abs/2111.04670">arxiv:2111.04670</a>
&#x1F4C8; 4 <br>
<p>Xingchen Wan, Binxin Ru, Pedro M. EsperanÃ§a, Fabio M. Carlucci</p></summary>
<p>

**Abstract:** The standard paradigm in Neural Architecture Search (NAS) is to search for a fully deterministic architecture with specific operations and connections. In this work, we instead propose to search for the optimal operation distribution, thus providing a stochastic and approximate solution, which can be used to sample architectures of arbitrary length. We propose and show, that given an architectural cell, its performance largely depends on the ratio of used operations, rather than any specific connection pattern in typical search spaces; that is, small changes in the ordering of the operations are often irrelevant. This intuition is orthogonal to any specific search strategy and can be applied to a diverse set of NAS algorithms. Through extensive validation on 4 data-sets and 4 NAS techniques (Bayesian optimisation, differentiable search, local search and random search), we show that the operation distribution (1) holds enough discriminating power to reliably identify a solution and (2) is significantly easier to optimise than traditional encodings, leading to large speed-ups at little to no cost in performance. Indeed, this simple intuition significantly reduces the cost of current approaches and potentially enable NAS to be used in a broader range of applications.

</p>
</details>

<details><summary><b>Neyman-Pearson Multi-class Classification via Cost-sensitive Learning</b>
<a href="https://arxiv.org/abs/2111.04597">arxiv:2111.04597</a>
&#x1F4C8; 4 <br>
<p>Ye Tian, Yang Feng</p></summary>
<p>

**Abstract:** Most existing classification methods aim to minimize the overall misclassification error rate, however, in applications, different types of errors can have different consequences. To take into account this asymmetry issue, two popular paradigms have been developed, namely the Neyman-Pearson (NP) paradigm and cost-sensitive (CS) paradigm. Compared to CS paradigm, NP paradigm does not require a specification of costs. Most previous works on NP paradigm focused on the binary case. In this work, we study the multi-class NP problem by connecting it to the CS problem, and propose two algorithms. We extend the NP oracle inequalities and consistency from the binary case to the multi-class case, and show that our two algorithms enjoy these properties under certain conditions. The simulation and real data studies demonstrate the effectiveness of our algorithms. To our knowledge, this is the first work to solve the multi-class NP problem via cost-sensitive learning techniques with theoretical guarantees. The proposed algorithms are implemented in the R package "npcs" on CRAN.

</p>
</details>

<details><summary><b>Improved Regularization and Robustness for Fine-tuning in Neural Networks</b>
<a href="https://arxiv.org/abs/2111.04578">arxiv:2111.04578</a>
&#x1F4C8; 4 <br>
<p>Dongyue Li, Hongyang R. Zhang</p></summary>
<p>

**Abstract:** A widely used algorithm for transfer learning is fine-tuning, where a pre-trained model is fine-tuned on a target task with a small amount of labeled data. When the capacity of the pre-trained model is much larger than the size of the target data set, fine-tuning is prone to overfitting and "memorizing" the training labels. Hence, an important question is to regularize fine-tuning and ensure its robustness to noise. To address this question, we begin by analyzing the generalization properties of fine-tuning. We present a PAC-Bayes generalization bound that depends on the distance traveled in each layer during fine-tuning and the noise stability of the fine-tuned model. We empirically measure these quantities. Based on the analysis, we propose regularized self-labeling -- the interpolation between regularization and self-labeling methods, including (i) layer-wise regularization to constrain the distance traveled in each layer; (ii) self label-correction and label-reweighting to correct mislabeled data points (that the model is confident) and reweight less confident data points. We validate our approach on an extensive collection of image and text data sets using multiple pre-trained model architectures. Our approach improves baseline methods by 1.76% (on average) for seven image classification tasks and 0.75% for a few-shot classification task. When the target data set includes noisy labels, our approach outperforms baseline methods by 3.56% on average in two noisy settings.

</p>
</details>

<details><summary><b>Clustering and Structural Robustness in Causal Diagrams</b>
<a href="https://arxiv.org/abs/2111.04513">arxiv:2111.04513</a>
&#x1F4C8; 4 <br>
<p>Santtu Tikka, Jouni Helske, Juha Karvanen</p></summary>
<p>

**Abstract:** Graphs are commonly used to represent and visualize causal relations. For a small number of variables, this approach provides a succinct and clear view of the scenario at hand. As the number of variables under study increases, the graphical approach may become impractical, and the clarity of the representation is lost. Clustering of variables is a natural way to reduce the size of the causal diagram but it may erroneously change the essential properties of the causal relations if implemented arbitrarily. We define a specific type of cluster, called transit cluster, that is guaranteed to preserve the identifiability properties of causal effects under certain conditions. We provide a sound and complete algorithm for finding all transit clusters in a given graph and demonstrate how clustering can simplify the identification of causal effects. We also study the inverse problem, where one starts with a clustered graph and looks for extended graphs where the identifiability properties of causal effects remain unchanged. We show that this kind of structural robustness is closely related to transit clusters.

</p>
</details>

<details><summary><b>Can semi-supervised learning reduce the amount of manual labelling required for effective radio galaxy morphology classification?</b>
<a href="https://arxiv.org/abs/2111.04357">arxiv:2111.04357</a>
&#x1F4C8; 4 <br>
<p>Inigo V. Slijepcevic, Anna M. M. Scaife</p></summary>
<p>

**Abstract:** In this work, we examine the robustness of state-of-the-art semi-supervised learning (SSL) algorithms when applied to morphological classification in modern radio astronomy. We test whether SSL can achieve performance comparable to the current supervised state of the art when using many fewer labelled data points and if these results generalise to using truly unlabelled data. We find that although SSL provides additional regularisation, its performance degrades rapidly when using very few labels, and that using truly unlabelled data leads to a significant drop in performance.

</p>
</details>

<details><summary><b>Unsupervised Learning for Identifying High Eigenvector Centrality Nodes: A Graph Neural Network Approach</b>
<a href="https://arxiv.org/abs/2111.05264">arxiv:2111.05264</a>
&#x1F4C8; 3 <br>
<p>Appan Rakaraddi, Mahardhika Pratama</p></summary>
<p>

**Abstract:** The existing methods to calculate the Eigenvector Centrality(EC) tend to not be robust enough for determination of EC in low time complexity or not well-scalable for large networks, hence rendering them practically unreliable/ computationally expensive. So, it is of the essence to develop a method that is scalable in low computational time. Hence, we propose a deep learning model for the identification of nodes with high Eigenvector Centrality. There have been a few previous works in identifying the high ranked nodes with supervised learning methods, but in real-world cases, the graphs are not labelled and hence deployment of supervised learning methods becomes a hazard and its usage becomes impractical. So, we devise CUL(Centrality with Unsupervised Learning) method to learn the relative EC scores in a network in an unsupervised manner. To achieve this, we develop an Encoder-Decoder based framework that maps the nodes to their respective estimated EC scores. Extensive experiments were conducted on different synthetic and real-world networks. We compared CUL against a baseline supervised method for EC estimation similar to some of the past works. It was observed that even with training on a minuscule number of training datasets, CUL delivers a relatively better accuracy score when identifying the higher ranked nodes than its supervised counterpart. We also show that CUL is much faster and has a smaller runtime than the conventional baseline method for EC computation. The code is available at https://github.com/codexhammer/CUL.

</p>
</details>

<details><summary><b>Self-Interpretable Model with TransformationEquivariant Interpretation</b>
<a href="https://arxiv.org/abs/2111.04927">arxiv:2111.04927</a>
&#x1F4C8; 3 <br>
<p>Yipei Wang, Xiaoqian Wang</p></summary>
<p>

**Abstract:** In this paper, we propose a self-interpretable model SITE with transformation-equivariant interpretations. We focus on the robustness and self-consistency of the interpretations of geometric transformations. Apart from the transformation equivariance, as a self-interpretable model, SITE has comparable expressive power as the benchmark black-box classifiers, while being able to present faithful and robust interpretations with high quality. It is worth noticing that although applied in most of the CNN visualization methods, the bilinear upsampling approximation is a rough approximation, which can only provide interpretations in the form of heatmaps (instead of pixel-wise). It remains an open question whether such interpretations can be direct to the input space (as shown in the MNIST experiments). Besides, we consider the translation and rotation transformations in our model. In future work, we will explore the robust interpretations under more complex transformations such as scaling and distortion. Moreover, we clarify that SITE is not limited to geometric transformation (that we used in the computer vision domain), and will explore SITEin other domains in future work.

</p>
</details>

<details><summary><b>Label-Aware Distribution Calibration for Long-tailed Classification</b>
<a href="https://arxiv.org/abs/2111.04901">arxiv:2111.04901</a>
&#x1F4C8; 3 <br>
<p>Chaozheng Wang, Shuzheng Gao, Cuiyun Gao, Pengyun Wang, Wenjie Pei, Lujia Pan, Zenglin Xu</p></summary>
<p>

**Abstract:** Real-world data usually present long-tailed distributions. Training on imbalanced data tends to render neural networks perform well on head classes while much worse on tail classes. The severe sparseness of training instances for the tail classes is the main challenge, which results in biased distribution estimation during training. Plenty of efforts have been devoted to ameliorating the challenge, including data re-sampling and synthesizing new training instances for tail classes. However, no prior research has exploited the transferable knowledge from head classes to tail classes for calibrating the distribution of tail classes. In this paper, we suppose that tail classes can be enriched by similar head classes and propose a novel distribution calibration approach named as label-Aware Distribution Calibration LADC. LADC transfers the statistics from relevant head classes to infer the distribution of tail classes. Sampling from calibrated distribution further facilitates re-balancing the classifier. Experiments on both image and text long-tailed datasets demonstrate that LADC significantly outperforms existing methods.The visualization also shows that LADC provides a more accurate distribution estimation.

</p>
</details>

<details><summary><b>Combining Machine Learning with Physics: A Framework for Tracking and Sorting Multiple Dark Solitons</b>
<a href="https://arxiv.org/abs/2111.04881">arxiv:2111.04881</a>
&#x1F4C8; 3 <br>
<p>Shangjie Guo, Sophia M. Koh, Amilson R. Fritsch, I. B. Spielman, Justyna P. Zwolak</p></summary>
<p>

**Abstract:** In ultracold atom experiments, data often comes in the form of images which suffer information loss inherent in the techniques used to prepare and measure the system. This is particularly problematic when the processes of interest are complicated, such as interactions among excitations in Bose-Einstein condensates (BECs). In this paper, we describe a framework combining machine learning (ML) models with physics-based traditional analyses to identify and track multiple solitonic excitations in images of BECs. We use an ML-based object detector to locate the solitonic excitations and develop a physics-informed classifier to sort solitonic excitations into physically motivated sub-categories. Lastly, we introduce a quality metric quantifying the likelihood that a specific feature is a kink soliton. Our trained implementation of this framework -- SolDet -- is publicly available as an open-source python package. SolDet is broadly applicable to feature identification in cold atom images when trained on a suitable user-provided dataset.

</p>
</details>

<details><summary><b>Explaining Face Presentation Attack Detection Using Natural Language</b>
<a href="https://arxiv.org/abs/2111.04862">arxiv:2111.04862</a>
&#x1F4C8; 3 <br>
<p>Hengameh Mirzaalian, Mohamed E. Hussein, Leonidas Spinoulas, Jonathan May, Wael Abd-Almageed</p></summary>
<p>

**Abstract:** A large number of deep neural network based techniques have been developed to address the challenging problem of face presentation attack detection (PAD). Whereas such techniques' focus has been on improving PAD performance in terms of classification accuracy and robustness against unseen attacks and environmental conditions, there exists little attention on the explainability of PAD predictions. In this paper, we tackle the problem of explaining PAD predictions through natural language. Our approach passes feature representations of a deep layer of the PAD model to a language model to generate text describing the reasoning behind the PAD prediction. Due to the limited amount of annotated data in our study, we apply a light-weight LSTM network as our natural language generation model. We investigate how the quality of the generated explanations is affected by different loss functions, including the commonly used word-wise cross entropy loss, a sentence discriminative loss, and a sentence semantic loss. We perform our experiments using face images from a dataset consisting of 1,105 bona-fide and 924 presentation attack samples. Our quantitative and qualitative results show the effectiveness of our model for generating proper PAD explanations through text as well as the power of the sentence-wise losses. To the best of our knowledge, this is the first introduction of a joint biometrics-NLP task. Our dataset can be obtained through our GitHub page.

</p>
</details>

<details><summary><b>Hybrid BYOL-ViT: Efficient approach to deal with small datasets</b>
<a href="https://arxiv.org/abs/2111.04845">arxiv:2111.04845</a>
&#x1F4C8; 3 <br>
<p>Safwen Naimi, Rien van Leeuwen, Wided Souidene, Slim Ben Saoud</p></summary>
<p>

**Abstract:** Supervised learning can learn large representational spaces, which are crucial for handling difficult learning tasks. However, due to the design of the model, classical image classification approaches struggle to generalize to new problems and new situations when dealing with small datasets. In fact, supervised learning can lose the location of image features which leads to supervision collapse in very deep architectures. In this paper, we investigate how self-supervision with strong and sufficient augmentation of unlabeled data can train effectively the first layers of a neural network even better than supervised learning, with no need for millions of labeled data. The main goal is to disconnect pixel data from annotation by getting generic task-agnostic low-level features. Furthermore, we look into Vision Transformers (ViT) and show that the low-level features derived from a self-supervised architecture can improve the robustness and the overall performance of this emergent architecture. We evaluated our method on one of the smallest open-source datasets STL-10 and we obtained a significant boost of performance from 41.66% to 83.25% when inputting low-level features from a self-supervised learning architecture to the ViT instead of the raw images.

</p>
</details>

<details><summary><b>Efficient estimates of optimal transport via low-dimensional embeddings</b>
<a href="https://arxiv.org/abs/2111.04838">arxiv:2111.04838</a>
&#x1F4C8; 3 <br>
<p>Patric M. Fulop, Vincent Danos</p></summary>
<p>

**Abstract:** Optimal transport distances (OT) have been widely used in recent work in Machine Learning as ways to compare probability distributions. These are costly to compute when the data lives in high dimension. Recent work by Paty et al., 2019, aims specifically at reducing this cost by computing OT using low-rank projections of the data (seen as discrete measures). We extend this approach and show that one can approximate OT distances by using more general families of maps provided they are 1-Lipschitz. The best estimate is obtained by maximising OT over the given family. As OT calculations are done after mapping data to a lower dimensional space, our method scales well with the original data dimension. We demonstrate the idea with neural networks.

</p>
</details>

<details><summary><b>Unsupervised Approaches for Out-Of-Distribution Dermoscopic Lesion Detection</b>
<a href="https://arxiv.org/abs/2111.04807">arxiv:2111.04807</a>
&#x1F4C8; 3 <br>
<p>Max Torop, Sandesh Ghimire, Wenqian Liu, Dana H. Brooks, Octavia Camps, Milind Rajadhyaksha, Jennifer Dy, Kivanc Kose</p></summary>
<p>

**Abstract:** There are limited works showing the efficacy of unsupervised Out-of-Distribution (OOD) methods on complex medical data. Here, we present preliminary findings of our unsupervised OOD detection algorithm, SimCLR-LOF, as well as a recent state of the art approach (SSD), applied on medical images. SimCLR-LOF learns semantically meaningful features using SimCLR and uses LOF for scoring if a test sample is OOD. We evaluated on the multi-source International Skin Imaging Collaboration (ISIC) 2019 dataset, and show results that are competitive with SSD as well as with recent supervised approaches applied on the same data.

</p>
</details>

<details><summary><b>TAGLETS: A System for Automatic Semi-Supervised Learning with Auxiliary Data</b>
<a href="https://arxiv.org/abs/2111.04798">arxiv:2111.04798</a>
&#x1F4C8; 3 <br>
<p>Wasu Piriyakulkij, Cristina Menghini, Ross Briden, Nihal V. Nayak, Jeffrey Zhu, Elaheh Raisi, Stephen H. Bach</p></summary>
<p>

**Abstract:** Machine learning practitioners often have access to a spectrum of data: labeled data for the target task (which is often limited), unlabeled data, and auxiliary data, the many available labeled datasets for other tasks. We describe TAGLETS, a system built to study techniques for automatically exploiting all three types of data and creating high-quality, servable classifiers. The key components of TAGLETS are: (1) auxiliary data organized according to a knowledge graph, (2) modules encapsulating different methods for exploiting auxiliary and unlabeled data, and (3) a distillation stage in which the ensembled modules are combined into a servable model. We compare TAGLETS with state-of-the-art transfer learning and semi-supervised learning methods on four image classification tasks. Our study covers a range of settings, varying the amount of labeled data and the semantic relatedness of the auxiliary data to the target task. We find that the intelligent incorporation of auxiliary and unlabeled data into multiple learning techniques enables TAGLETS to match-and most often significantly surpass-these alternatives. TAGLETS is available as an open-source system at github.com/BatsResearch/taglets.

</p>
</details>

<details><summary><b>Visual Question Answering based on Formal Logic</b>
<a href="https://arxiv.org/abs/2111.04785">arxiv:2111.04785</a>
&#x1F4C8; 3 <br>
<p>Muralikrishnna G. Sethuraman, Ali Payani, Faramarz Fekri, J. Clayton Kerce</p></summary>
<p>

**Abstract:** Visual question answering (VQA) has been gaining a lot of traction in the machine learning community in the recent years due to the challenges posed in understanding information coming from multiple modalities (i.e., images, language). In VQA, a series of questions are posed based on a set of images and the task at hand is to arrive at the answer. To achieve this, we take a symbolic reasoning based approach using the framework of formal logic. The image and the questions are converted into symbolic representations on which explicit reasoning is performed. We propose a formal logic framework where (i) images are converted to logical background facts with the help of scene graphs, (ii) the questions are translated to first-order predicate logic clauses using a transformer based deep learning model, and (iii) perform satisfiability checks, by using the background knowledge and the grounding of predicate clauses, to obtain the answer. Our proposed method is highly interpretable and each step in the pipeline can be easily analyzed by a human. We validate our approach on the CLEVR and the GQA dataset. We achieve near perfect accuracy of 99.6% on the CLEVR dataset comparable to the state of art models, showcasing that formal logic is a viable tool to tackle visual question answering. Our model is also data efficient, achieving 99.1% accuracy on CLEVR dataset when trained on just 10% of the training data.

</p>
</details>

<details><summary><b>BRACS: A Dataset for BReAst Carcinoma Subtyping in H&E Histology Images</b>
<a href="https://arxiv.org/abs/2111.04740">arxiv:2111.04740</a>
&#x1F4C8; 3 <br>
<p>Nadia Brancati, Anna Maria Anniciello, Pushpak Pati, Daniel Riccio, GiosuÃ¨ Scognamiglio, Guillaume Jaume, Giuseppe De Pietro, Maurizio Di Bonito, Antonio Foncubierta, Gerardo Botti, Maria Gabrani, Florinda Feroce, Maria Frucci</p></summary>
<p>

**Abstract:** Breast cancer is the most commonly diagnosed cancer and registers the highest number of deaths for women with cancer. Recent advancements in diagnostic activities combined with large-scale screening policies have significantly lowered the mortality rates for breast cancer patients. However, the manual inspection of tissue slides by the pathologists is cumbersome, time-consuming, and is subject to significant inter- and intra-observer variability. Recently, the advent of whole-slide scanning systems have empowered the rapid digitization of pathology slides, and enabled to develop digital workflows. These advances further enable to leverage Artificial Intelligence (AI) to assist, automate, and augment pathological diagnosis. But the AI techniques, especially Deep Learning (DL), require a large amount of high-quality annotated data to learn from. Constructing such task-specific datasets poses several challenges, such as, data-acquisition level constrains, time-consuming and expensive annotations, and anonymization of private information. In this paper, we introduce the BReAst Carcinoma Subtyping (BRACS) dataset, a large cohort of annotated Hematoxylin & Eosin (H&E)-stained images to facilitate the characterization of breast lesions. BRACS contains 547 Whole-Slide Images (WSIs), and 4539 Regions of Interest (ROIs) extracted from the WSIs. Each WSI, and respective ROIs, are annotated by the consensus of three board-certified pathologists into different lesion categories. Specifically, BRACS includes three lesion types, i.e., benign, malignant and atypical, which are further subtyped into seven categories. It is, to the best of our knowledge, the largest annotated dataset for breast cancer subtyping both at WSI- and ROI-level. Further, by including the understudied atypical lesions, BRACS offers an unique opportunity for leveraging AI to better understand their characteristics.

</p>
</details>

<details><summary><b>DR-VNet: Retinal Vessel Segmentation via Dense Residual UNet</b>
<a href="https://arxiv.org/abs/2111.04739">arxiv:2111.04739</a>
&#x1F4C8; 3 <br>
<p>Ali Karaali, Rozenn Dahyot, Donal J. Sexton</p></summary>
<p>

**Abstract:** Accurate retinal vessel segmentation is an important task for many computer-aided diagnosis systems. Yet, it is still a challenging problem due to the complex vessel structures of an eye. Numerous vessel segmentation methods have been proposed recently, however more research is needed to deal with poor segmentation of thin and tiny vessels. To address this, we propose a new deep learning pipeline combining the efficiency of residual dense net blocks and, residual squeeze and excitation blocks. We validate experimentally our approach on three datasets and show that our pipeline outperforms current state of the art techniques on the sensitivity metric relevant to assess capture of small vessels.

</p>
</details>

<details><summary><b>SMU: smooth activation function for deep networks using smoothing maximum technique</b>
<a href="https://arxiv.org/abs/2111.04682">arxiv:2111.04682</a>
&#x1F4C8; 3 <br>
<p>Koushik Biswas, Sandeep Kumar, Shilpak Banerjee, Ashish Kumar Pandey</p></summary>
<p>

**Abstract:** Deep learning researchers have a keen interest in proposing two new novel activation functions which can boost network performance. A good choice of activation function can have significant consequences in improving network performance. A handcrafted activation is the most common choice in neural network models. ReLU is the most common choice in the deep learning community due to its simplicity though ReLU has some serious drawbacks. In this paper, we have proposed a new novel activation function based on approximation of known activation functions like Leaky ReLU, and we call this function Smooth Maximum Unit (SMU). Replacing ReLU by SMU, we have got 6.22% improvement in the CIFAR100 dataset with the ShuffleNet V2 model.

</p>
</details>

<details><summary><b>Consistent Sufficient Explanations and Minimal Local Rules for explaining regression and classification models</b>
<a href="https://arxiv.org/abs/2111.04658">arxiv:2111.04658</a>
&#x1F4C8; 3 <br>
<p>Salim I. Amoukou, Nicolas J. B Brunel</p></summary>
<p>

**Abstract:** To explain the decision of any model, we extend the notion of probabilistic Sufficient Explanations (P-SE). For each instance, this approach selects the minimal subset of features that is sufficient to yield the same prediction with high probability, while removing other features. The crux of P-SE is to compute the conditional probability of maintaining the same prediction. Therefore, we introduce an accurate and fast estimator of this probability via random Forests for any data $(\boldsymbol{X}, Y)$ and show its efficiency through a theoretical analysis of its consistency. As a consequence, we extend the P-SE to regression problems. In addition, we deal with non-binary features, without learning the distribution of $X$ nor having the model for making predictions. Finally, we introduce local rule-based explanations for regression/classification based on the P-SE and compare our approaches w.r.t other explainable AI methods. These methods are publicly available as a Python package at \url{www.github.com/salimamoukou/acv00}.

</p>
</details>

<details><summary><b>S3RP: Self-Supervised Super-Resolution and Prediction for Advection-Diffusion Process</b>
<a href="https://arxiv.org/abs/2111.04639">arxiv:2111.04639</a>
&#x1F4C8; 3 <br>
<p>Chulin Wang, Kyongmin Yeo, Xiao Jin, Andres Codas, Levente J. Klein, Bruce Elmegreen</p></summary>
<p>

**Abstract:** We present a super-resolution model for an advection-diffusion process with limited information. While most of the super-resolution models assume high-resolution (HR) ground-truth data in the training, in many cases such HR dataset is not readily accessible. Here, we show that a Recurrent Convolutional Network trained with physics-based regularizations is able to reconstruct the HR information without having the HR ground-truth data. Moreover, considering the ill-posed nature of a super-resolution problem, we employ the Recurrent Wasserstein Autoencoder to model the uncertainty.

</p>
</details>

<details><summary><b>Sexism Prediction in Spanish and English Tweets Using Monolingual and Multilingual BERT and Ensemble Models</b>
<a href="https://arxiv.org/abs/2111.04551">arxiv:2111.04551</a>
&#x1F4C8; 3 <br>
<p>Angel Felipe MagnossÃ£o de Paula, Roberto Fray da Silva, Ipek Baris Schlicht</p></summary>
<p>

**Abstract:** The popularity of social media has created problems such as hate speech and sexism. The identification and classification of sexism in social media are very relevant tasks, as they would allow building a healthier social environment. Nevertheless, these tasks are considerably challenging. This work proposes a system to use multilingual and monolingual BERT and data points translation and ensemble strategies for sexism identification and classification in English and Spanish. It was conducted in the context of the sEXism Identification in Social neTworks shared 2021 (EXIST 2021) task, proposed by the Iberian Languages Evaluation Forum (IberLEF). The proposed system and its main components are described, and an in-depth hyperparameters analysis is conducted. The main results observed were: (i) the system obtained better results than the baseline model (multilingual BERT); (ii) ensemble models obtained better results than monolingual models; and (iii) an ensemble model considering all individual models and the best standardized values obtained the best accuracies and F1-scores for both tasks. This work obtained first place in both tasks at EXIST, with the highest accuracies (0.780 for task 1 and 0.658 for task 2) and F1-scores (F1-binary of 0.780 for task 1 and F1-macro of 0.579 for task 2).

</p>
</details>

<details><summary><b>AI-UPV at IberLEF-2021 DETOXIS task: Toxicity Detection in Immigration-Related Web News Comments Using Transformers and Statistical Models</b>
<a href="https://arxiv.org/abs/2111.04530">arxiv:2111.04530</a>
&#x1F4C8; 3 <br>
<p>Angel Felipe MagnossÃ£o de Paula, Ipek Baris Schlicht</p></summary>
<p>

**Abstract:** This paper describes our participation in the DEtection of TOXicity in comments In Spanish (DETOXIS) shared task 2021 at the 3rd Workshop on Iberian Languages Evaluation Forum. The shared task is divided into two related classification tasks: (i) Task 1: toxicity detection and; (ii) Task 2: toxicity level detection. They focus on the xenophobic problem exacerbated by the spread of toxic comments posted in different online news articles related to immigration. One of the necessary efforts towards mitigating this problem is to detect toxicity in the comments. Our main objective was to implement an accurate model to detect xenophobia in comments about web news articles within the DETOXIS shared task 2021, based on the competition's official metrics: the F1-score for Task 1 and the Closeness Evaluation Metric (CEM) for Task 2. To solve the tasks, we worked with two types of machine learning models: (i) statistical models and (ii) Deep Bidirectional Transformers for Language Understanding (BERT) models. We obtained our best results in both tasks using BETO, an BERT model trained on a big Spanish corpus. We obtained the 3rd place in Task 1 official ranking with the F1-score of 0.5996, and we achieved the 6th place in Task 2 official ranking with the CEM of 0.7142. Our results suggest: (i) BERT models obtain better results than statistical models for toxicity detection in text comments; (ii) Monolingual BERT models have an advantage over multilingual BERT models in toxicity detection in text comments in their pre-trained language.

</p>
</details>

<details><summary><b>There is no Double-Descent in Random Forests</b>
<a href="https://arxiv.org/abs/2111.04409">arxiv:2111.04409</a>
&#x1F4C8; 3 <br>
<p>Sebastian BuschjÃ¤ger, Katharina Morik</p></summary>
<p>

**Abstract:** Random Forests (RFs) are among the state-of-the-art in machine learning and offer excellent performance with nearly zero parameter tuning. Remarkably, RFs seem to be impervious to overfitting even though their basic building blocks are well-known to overfit. Recently, a broadly received study argued that a RF exhibits a so-called double-descent curve: First, the model overfits the data in a u-shaped curve and then, once a certain model complexity is reached, it suddenly improves its performance again. In this paper, we challenge the notion that model capacity is the correct tool to explain the success of RF and argue that the algorithm which trains the model plays a more important role than previously thought. We show that a RF does not exhibit a double-descent curve but rather has a single descent. Hence, it does not overfit in the classic sense. We further present a RF variation that also does not overfit although its decision boundary approximates that of an overfitted DT. Similar, we show that a DT which approximates the decision boundary of a RF will still overfit. Last, we study the diversity of an ensemble as a tool the estimate its performance. To do so, we introduce Negative Correlation Forest (NCForest) which allows for precise control over the diversity in the ensemble. We show, that the diversity and the bias indeed have a crucial impact on the performance of the RF. Having too low diversity collapses the performance of the RF into a a single tree, whereas having too much diversity means that most trees do not produce correct outputs anymore. However, in-between these two extremes we find a large range of different trade-offs with all roughly equal performance. Hence, the specific trade-off between bias and diversity does not matter as long as the algorithm reaches this good trade-off regime.

</p>
</details>

<details><summary><b>Robust and Information-theoretically Safe Bias Classifier against Adversarial Attacks</b>
<a href="https://arxiv.org/abs/2111.04404">arxiv:2111.04404</a>
&#x1F4C8; 3 <br>
<p>Lijia Yu, Xiao-Shan Gao</p></summary>
<p>

**Abstract:** In this paper, the bias classifier is introduced, that is, the bias part of a DNN with Relu as the activation function is used as a classifier. The work is motivated by the fact that the bias part is a piecewise constant function with zero gradient and hence cannot be directly attacked by gradient-based methods to generate adversaries such as FGSM. The existence of the bias classifier is proved an effective training method for the bias classifier is proposed. It is proved that by adding a proper random first-degree part to the bias classifier, an information-theoretically safe classifier against the original-model gradient-based attack is obtained in the sense that the attack generates a totally random direction for generating adversaries. This seems to be the first time that the concept of information-theoretically safe classifier is proposed. Several attack methods for the bias classifier are proposed and numerical experiments are used to show that the bias classifier is more robust than DNNs against these attacks in most cases.

</p>
</details>

<details><summary><b>Lattice gauge symmetry in neural networks</b>
<a href="https://arxiv.org/abs/2111.04389">arxiv:2111.04389</a>
&#x1F4C8; 3 <br>
<p>Matteo Favoni, Andreas Ipp, David I. MÃ¼ller, Daniel Schuh</p></summary>
<p>

**Abstract:** We review a novel neural network architecture called lattice gauge equivariant convolutional neural networks (L-CNNs), which can be applied to generic machine learning problems in lattice gauge theory while exactly preserving gauge symmetry. We discuss the concept of gauge equivariance which we use to explicitly construct a gauge equivariant convolutional layer and a bilinear layer. The performance of L-CNNs and non-equivariant CNNs is compared using seemingly simple non-linear regression tasks, where L-CNNs demonstrate generalizability and achieve a high degree of accuracy in their predictions compared to their non-equivariant counterparts.

</p>
</details>

<details><summary><b>Geometrically Adaptive Dictionary Attack on Face Recognition</b>
<a href="https://arxiv.org/abs/2111.04371">arxiv:2111.04371</a>
&#x1F4C8; 3 <br>
<p>Junyoung Byun, Hyojun Go, Changick Kim</p></summary>
<p>

**Abstract:** CNN-based face recognition models have brought remarkable performance improvement, but they are vulnerable to adversarial perturbations. Recent studies have shown that adversaries can fool the models even if they can only access the models' hard-label output. However, since many queries are needed to find imperceptible adversarial noise, reducing the number of queries is crucial for these attacks. In this paper, we point out two limitations of existing decision-based black-box attacks. We observe that they waste queries for background noise optimization, and they do not take advantage of adversarial perturbations generated for other images. We exploit 3D face alignment to overcome these limitations and propose a general strategy for query-efficient black-box attacks on face recognition named Geometrically Adaptive Dictionary Attack (GADA). Our core idea is to create an adversarial perturbation in the UV texture map and project it onto the face in the image. It greatly improves query efficiency by limiting the perturbation search space to the facial area and effectively recycling previous perturbations. We apply the GADA strategy to two existing attack methods and show overwhelming performance improvement in the experiments on the LFW and CPLFW datasets. Furthermore, we also present a novel attack strategy that can circumvent query similarity-based stateful detection that identifies the process of query-based black-box attacks.

</p>
</details>

<details><summary><b>Off-policy Imitation Learning from Visual Inputs</b>
<a href="https://arxiv.org/abs/2111.04345">arxiv:2111.04345</a>
&#x1F4C8; 3 <br>
<p>Zhihao Cheng, Li Shen, Dacheng Tao</p></summary>
<p>

**Abstract:** Recently, various successful applications utilizing expert states in imitation learning (IL) have been witnessed. However, another IL setting -- IL from visual inputs (ILfVI), which has a greater promise to be applied in reality by utilizing online visual resources, suffers from low data-efficiency and poor performance resulted from an on-policy learning manner and high-dimensional visual inputs. We propose OPIfVI (Off-Policy Imitation from Visual Inputs), which is composed of an off-policy learning manner, data augmentation, and encoder techniques, to tackle the mentioned challenges, respectively. More specifically, to improve data-efficiency, OPIfVI conducts IL in an off-policy manner, with which sampled data can be used multiple times. In addition, we enhance the stability of OPIfVI with spectral normalization to mitigate the side-effect of off-policy training. The core factor, contributing to the poor performance of ILfVI, that we think is the agent could not extract meaningful features from visual inputs. Hence, OPIfVI employs data augmentation from computer vision to help train encoders that can better extract features from visual inputs. In addition, a specific structure of gradient backpropagation for the encoder is designed to stabilize the encoder training. At last, we demonstrate that OPIfVI is able to achieve expert-level performance and outperform existing baselines no matter visual demonstrations or visual observations are provided via extensive experiments using DeepMind Control Suite.

</p>
</details>

<details><summary><b>A Relational Model for One-Shot Classification</b>
<a href="https://arxiv.org/abs/2111.04313">arxiv:2111.04313</a>
&#x1F4C8; 3 <br>
<p>Arturs Polis, Alexander Ilin</p></summary>
<p>

**Abstract:** We show that a deep learning model with built-in relational inductive bias can bring benefits to sample-efficient learning, without relying on extensive data augmentation. The proposed one-shot classification model performs relational matching of a pair of inputs in the form of local and pairwise attention. Our approach solves perfectly the one-shot image classification Omniglot challenge. Our model exceeds human level accuracy, as well as the previous state of the art, with no data augmentation.

</p>
</details>

<details><summary><b>Learning via Long Short-Term Memory (LSTM) network for predicting strains in Railway Bridge members under train induced vibration</b>
<a href="https://arxiv.org/abs/2111.06259">arxiv:2111.06259</a>
&#x1F4C8; 2 <br>
<p>Amartya Dutta, Kamaljyoti Nath</p></summary>
<p>

**Abstract:** Bridge health monitoring using machine learning tools has become an efficient and cost-effective approach in recent times. In the present study, strains in railway bridge member, available from a previous study conducted by IIT Guwahati has been utilized. These strain data were collected from an existing bridge while trains were passing over the bridge. LSTM is used to train the network and to predict strains in different members of the railway bridge. Actual field data has been used for the purpose of predicting strain in different members using strain data from a single member, yet it has been observed that they are quite agreeable to those of ground truth values. This is in spite of the fact that a lot of noise existed in the data, thus showing the efficacy of LSTM in training and predicting even from noisy field data. This may easily open up the possibility of collecting data from the bridge with a much lesser number of sensors and predicting the strain data in other members through LSTM network.

</p>
</details>

<details><summary><b>Adversarial sampling of unknown and high-dimensional conditional distributions</b>
<a href="https://arxiv.org/abs/2111.05962">arxiv:2111.05962</a>
&#x1F4C8; 2 <br>
<p>Malik Hassanaly, Andrew Glaws, Karen Stengel, Ryan N. King</p></summary>
<p>

**Abstract:** Many engineering problems require the prediction of realization-to-realization variability or a refined description of modeled quantities. In that case, it is necessary to sample elements from unknown high-dimensional spaces with possibly millions of degrees of freedom. While there exist methods able to sample elements from probability density functions (PDF) with known shapes, several approximations need to be made when the distribution is unknown. In this paper the sampling method, as well as the inference of the underlying distribution, are both handled with a data-driven method known as generative adversarial networks (GAN), which trains two competing neural networks to produce a network that can effectively generate samples from the training set distribution. In practice, it is often necessary to draw samples from conditional distributions. When the conditional variables are continuous, only one (if any) data point corresponding to a particular value of a conditioning variable may be available, which is not sufficient to estimate the conditional distribution. This work handles this problem using an a priori estimation of the conditional moments of a PDF. Two approaches, stochastic estimation, and an external neural network are compared here for computing these moments; however, any preferred method can be used. The algorithm is demonstrated in the case of the deconvolution of a filtered turbulent flow field. It is shown that all the versions of the proposed algorithm effectively sample the target conditional distribution with minimal impact on the quality of the samples compared to state-of-the-art methods. Additionally, the procedure can be used as a metric for the diversity of samples generated by a conditional GAN (cGAN) conditioned with continuous variables.

</p>
</details>

<details><summary><b>Stain-free Detection of Embryo Polarization using Deep Learning</b>
<a href="https://arxiv.org/abs/2111.05315">arxiv:2111.05315</a>
&#x1F4C8; 2 <br>
<p>Cheng Shen, Adiyant Lamba, Meng Zhu, Ray Zhang, Changhuei Yang, Magdalena Zernicka Goetz</p></summary>
<p>

**Abstract:** Polarization of the mammalian embryo at the right developmental time is critical for its development to term and would be valuable in assessing the potential of human embryos. However, tracking polarization requires invasive fluorescence staining, impermissible in the in vitro fertilization clinic. Here, we report the use of artificial intelligence to detect polarization from unstained time-lapse movies of mouse embryos. We assembled a dataset of bright-field movie frames from 8-cell-stage embryos, side-by-side with corresponding images of fluorescent markers of cell polarization. We then used an ensemble learning model to detect whether any bright-field frame showed an embryo before or after onset of polarization. Our resulting model has an accuracy of 85% for detecting polarization, significantly outperforming human volunteers trained on the same data (61% accuracy). We discovered that our self-learning model focuses upon the angle between cells as one known cue for compaction, which precedes polarization, but it outperforms the use of this cue alone. By compressing three-dimensional time-lapsed image data into two-dimensions, we are able to reduce data to an easily manageable size for deep learning processing. In conclusion, we describe a method for detecting a key developmental feature of embryo development that avoids clinically impermissible fluorescence staining.

</p>
</details>

<details><summary><b>Segmentation of Multiple Myeloma Plasma Cells in Microscopy Images with Noisy Labels</b>
<a href="https://arxiv.org/abs/2111.05125">arxiv:2111.05125</a>
&#x1F4C8; 2 <br>
<p>Ãlvaro GarcÃ­a Faura, Dejan Å tepec, TomaÅ¾ MartinÄiÄ, Danijel SkoÄaj</p></summary>
<p>

**Abstract:** A key component towards an improved and fast cancer diagnosis is the development of computer-assisted tools. In this article, we present the solution that won the SegPC-2021 competition for the segmentation of multiple myeloma plasma cells in microscopy images. The labels used in the competition dataset were generated semi-automatically and presented noise. To deal with it, a heavy image augmentation procedure was carried out and predictions from several models were combined using a custom ensemble strategy. State-of-the-art feature extractors and instance segmentation architectures were used, resulting in a mean Intersection-over-Union of 0.9389 on the SegPC-2021 final test set.

</p>
</details>

<details><summary><b>How to Train Your Neural Network: A Comparative Evaluation</b>
<a href="https://arxiv.org/abs/2111.04949">arxiv:2111.04949</a>
&#x1F4C8; 2 <br>
<p>Shu-Huai Lin, Daniel Nichols, Siddharth Singh, Abhinav Bhatele</p></summary>
<p>

**Abstract:** The field of deep learning has witnessed a remarkable shift towards extremely compute- and memory-intensive neural networks. These newer larger models have enabled researchers to advance state-of-the-art tools across a variety of fields. This phenomenon has spurred the development of algorithms for distributed training of neural networks over a larger number of hardware accelerators. In this paper, we discuss and compare current state-of-the-art frameworks for large scale distributed deep learning. First, we survey current practices in distributed learning and identify the different types of parallelism used. Then, we present empirical results comparing their performance on large image and language training tasks. Additionally, we address their statistical efficiency and memory consumption behavior. Based on our results, we discuss algorithmic and implementation portions of each framework which hinder performance.

</p>
</details>

<details><summary><b>Solving PDE-constrained Control Problems using Operator Learning</b>
<a href="https://arxiv.org/abs/2111.04941">arxiv:2111.04941</a>
&#x1F4C8; 2 <br>
<p>Rakhoon Hwang, Jae Yong Lee, Jin Young Shin, Hyung Ju Hwang</p></summary>
<p>

**Abstract:** The modeling and control of complex physical systems are essential in real-world problems. We propose a novel framework that is generally applicable to solving PDE-constrained optimal control problems by introducing surrogate models for PDE solution operators with special regularizers. The procedure of the proposed framework is divided into two phases: solution operator learning for PDE constraints (Phase 1) and searching for optimal control (Phase 2). Once the surrogate model is trained in Phase 1, the optimal control can be inferred in Phase 2 without intensive computations. Our framework can be applied to both data-driven and data-free cases. We demonstrate the successful application of our method to various optimal control problems for different control variables with diverse PDE constraints from the Poisson equation to Burgers' equation.

</p>
</details>

<details><summary><b>Optimizing Bayesian acquisition functions in Gaussian Processes</b>
<a href="https://arxiv.org/abs/2111.04930">arxiv:2111.04930</a>
&#x1F4C8; 2 <br>
<p>Ashish Anil Pawar, Ujwal Warbhe</p></summary>
<p>

**Abstract:** Bayesian Optimization is an effective method for searching the global maxima of an objective function especially if the function is unknown. The process comprises of using a surrogate function and choosing an acquisition function followed by optimizing the acquisition function to find the next sampling point. This paper analyzes different acquistion functions like Maximum Probability of Improvement and Expected Improvement and various optimizers like L-BFGS and TNC to optimize the acquisitions functions for finding the next sampling point. Along with the analysis of time taken, the paper also shows the importance of position of initial samples chosen.

</p>
</details>

<details><summary><b>Practical, Provably-Correct Interactive Learning in the Realizable Setting: The Power of True Believers</b>
<a href="https://arxiv.org/abs/2111.04915">arxiv:2111.04915</a>
&#x1F4C8; 2 <br>
<p>Julian Katz-Samuels, Blake Mason, Kevin Jamieson, Rob Nowak</p></summary>
<p>

**Abstract:** We consider interactive learning in the realizable setting and develop a general framework to handle problems ranging from best arm identification to active classification. We begin our investigation with the observation that agnostic algorithms \emph{cannot} be minimax-optimal in the realizable setting. Hence, we design novel computationally efficient algorithms for the realizable setting that match the minimax lower bound up to logarithmic factors and are general-purpose, accommodating a wide variety of function classes including kernel methods, H{Ã¶}lder smooth functions, and convex functions. The sample complexities of our algorithms can be quantified in terms of well-known quantities like the extended teaching dimension and haystack dimension. However, unlike algorithms based directly on those combinatorial quantities, our algorithms are computationally efficient. To achieve computational efficiency, our algorithms sample from the version space using Monte Carlo "hit-and-run" algorithms instead of maintaining the version space explicitly. Our approach has two key strengths. First, it is simple, consisting of two unifying, greedy algorithms. Second, our algorithms have the capability to seamlessly leverage prior knowledge that is often available and useful in practice. In addition to our new theoretical results, we demonstrate empirically that our algorithms are competitive with Gaussian process UCB methods.

</p>
</details>

<details><summary><b>Real-time Instance Segmentation of Surgical Instruments using Attention and Multi-scale Feature Fusion</b>
<a href="https://arxiv.org/abs/2111.04911">arxiv:2111.04911</a>
&#x1F4C8; 2 <br>
<p>Juan Carlos Angeles-Ceron, Gilberto Ochoa-Ruiz, Leonardo Chang, Sharib Ali</p></summary>
<p>

**Abstract:** Precise instrument segmentation aid surgeons to navigate the body more easily and increase patient safety. While accurate tracking of surgical instruments in real-time plays a crucial role in minimally invasive computer-assisted surgeries, it is a challenging task to achieve, mainly due to 1) complex surgical environment, and 2) model design with both optimal accuracy and speed. Deep learning gives us the opportunity to learn complex environment from large surgery scene environments and placements of these instruments in real world scenarios. The Robust Medical Instrument Segmentation 2019 challenge (ROBUST-MIS) provides more than 10,000 frames with surgical tools in different clinical settings. In this paper, we use a light-weight single stage instance segmentation model complemented with a convolutional block attention module for achieving both faster and accurate inference. We further improve accuracy through data augmentation and optimal anchor localisation strategies. To our knowledge, this is the first work that explicitly focuses on both real-time performance and improved accuracy. Our approach out-performed top team performances in the ROBUST-MIS challenge with over 44% improvement on both area-based metric MI_DSC and distance-based metric MI_NSD. We also demonstrate real-time performance (> 60 frames-per-second) with different but competitive variants of our final approach.

</p>
</details>

<details><summary><b>The Role of Adaptive Optimizers for Honest Private Hyperparameter Selection</b>
<a href="https://arxiv.org/abs/2111.04906">arxiv:2111.04906</a>
&#x1F4C8; 2 <br>
<p>Shubhankar Mohapatra, Sajin Sasy, Xi He, Gautam Kamath, Om Thakkar</p></summary>
<p>

**Abstract:** Hyperparameter optimization is a ubiquitous challenge in machine learning, and the performance of a trained model depends crucially upon their effective selection. While a rich set of tools exist for this purpose, there are currently no practical hyperparameter selection methods under the constraint of differential privacy (DP). We study honest hyperparameter selection for differentially private machine learning, in which the process of hyperparameter tuning is accounted for in the overall privacy budget. To this end, we i) show that standard composition tools outperform more advanced techniques in many settings, ii) empirically and theoretically demonstrate an intrinsic connection between the learning rate and clipping norm hyperparameters, iii) show that adaptive optimizers like DPAdam enjoy a significant advantage in the process of honest hyperparameter tuning, and iv) draw upon novel limiting behaviour of Adam in the DP setting to design a new and more efficient optimizer.

</p>
</details>

<details><summary><b>Mitigating domain shift in AI-based tuberculosis screening with unsupervised domain adaptation</b>
<a href="https://arxiv.org/abs/2111.04893">arxiv:2111.04893</a>
&#x1F4C8; 2 <br>
<p>Nishanjan Ravin, Sourajit Saha, Alan Schweitzer, Ameena Elahi, Farouk Dako, Daniel Mollura, David Chapman</p></summary>
<p>

**Abstract:** We demonstrate that Domain Invariant Feature Learning (DIFL) can improve the out-of-domain generalizability of a deep learning Tuberculosis screening algorithm. It is well known that state of the art deep learning algorithms often have difficulty generalizing to unseen data distributions due to "domain shift". In the context of medical imaging, this could lead to unintended biases such as the inability to generalize from one patient population to another. We analyze the performance of a ResNet-50 classifier for the purposes of Tuberculosis screening using the four most popular public datasets with geographically diverse sources of imagery. We show that without domain adaptation, ResNet-50 has difficulty in generalizing between imaging distributions from a number of public Tuberculosis screening datasets with imagery from geographically distributed regions. However, with the incorporation of DIFL, the out-of-domain performance is greatly enhanced. Analysis criteria includes a comparison of accuracy, sensitivity, specificity and AUC over both the baseline, as well as the DIFL enhanced algorithms. We conclude that DIFL improves generalizability of Tuberculosis screening while maintaining acceptable accuracy over the source domain imagery when applied across a variety of public datasets.

</p>
</details>

<details><summary><b>EvoLearner: Learning Description Logics with Evolutionary Algorithms</b>
<a href="https://arxiv.org/abs/2111.04879">arxiv:2111.04879</a>
&#x1F4C8; 2 <br>
<p>Stefan Heindorf, Lukas BlÃ¼baum, Nick DÃ¼sterhus, Till Werner, Varun Nandkumar Golani, Caglar Demir, Axel-Cyrille Ngonga Ngomo</p></summary>
<p>

**Abstract:** Classifying nodes in knowledge graphs is an important task, e.g., predicting missing types of entities, predicting which molecules cause cancer, or predicting which drugs are promising treatment candidates. While black-box models often achieve high predictive performance, they are only post-hoc and locally explainable and do not allow the learned model to be easily enriched with domain knowledge. Towards this end, learning description logic concepts from positive and negative examples has been proposed. However, learning such concepts often takes a long time and state-of-the-art approaches provide limited support for literal data values, although they are crucial for many applications. In this paper, we propose EvoLearner - an evolutionary approach to learn ALCQ(D), which is the attributive language with complement (ALC) paired with qualified cardinality restrictions (Q) and data properties (D). We contribute a novel initialization method for the initial population: starting from positive examples (nodes in the knowledge graph), we perform biased random walks and translate them to description logic concepts. Moreover, we improve support for data properties by maximizing information gain when deciding where to split the data. We show that our approach significantly outperforms the state of the art on the benchmarking framework SML-Bench for structured machine learning. Our ablation study confirms that this is due to our novel initialization method and support for data properties.

</p>
</details>

<details><summary><b>Query-augmented Active Metric Learning</b>
<a href="https://arxiv.org/abs/2111.04871">arxiv:2111.04871</a>
&#x1F4C8; 2 <br>
<p>Yujia Deng, Yubai Yuan, Haoda Fu, Annie Qu</p></summary>
<p>

**Abstract:** In this paper we propose an active metric learning method for clustering with pairwise constraints. The proposed method actively queries the label of informative instance pairs, while estimating underlying metrics by incorporating unlabeled instance pairs, which leads to a more accurate and efficient clustering process. In particular, we augment the queried constraints by generating more pairwise labels to provide additional information in learning a metric to enhance clustering performance. Furthermore, we increase the robustness of metric learning by updating the learned metric sequentially and penalizing the irrelevant features adaptively. In addition, we propose a novel active query strategy that evaluates the information gain of instance pairs more accurately by incorporating the neighborhood structure, which improves clustering efficiency without extra labeling cost. In theory, we provide a tighter error bound of the proposed metric learning method utilizing augmented queries compared with methods using existing constraints only. Furthermore, we also investigate the improvement using the active query strategy instead of random selection. Numerical studies on simulation settings and real datasets indicate that the proposed method is especially advantageous when the signal-to-noise ratio between significant features and irrelevant features is low.

</p>
</details>

<details><summary><b>Solving Marginal MAP Exactly by Probabilistic Circuit Transformations</b>
<a href="https://arxiv.org/abs/2111.04833">arxiv:2111.04833</a>
&#x1F4C8; 2 <br>
<p>YooJung Choi, Tal Friedman, Guy Van den Broeck</p></summary>
<p>

**Abstract:** Probabilistic circuits (PCs) are a class of tractable probabilistic models that allow efficient, often linear-time, inference of queries such as marginals and most probable explanations (MPE). However, marginal MAP, which is central to many decision-making problems, remains a hard query for PCs unless they satisfy highly restrictive structural constraints. In this paper, we develop a pruning algorithm that removes parts of the PC that are irrelevant to a marginal MAP query, shrinking the PC while maintaining the correct solution. This pruning technique is so effective that we are able to build a marginal MAP solver based solely on iteratively transforming the circuit -- no search is required. We empirically demonstrate the efficacy of our approach on real-world datasets.

</p>
</details>

<details><summary><b>Solution to the Non-Monotonicity and Crossing Problems in Quantile Regression</b>
<a href="https://arxiv.org/abs/2111.04805">arxiv:2111.04805</a>
&#x1F4C8; 2 <br>
<p>Resve A. Saleh, A. K. Md. Ehsanes Saleh</p></summary>
<p>

**Abstract:** This paper proposes a new method to address the long-standing problem of lack of monotonicity in estimation of the conditional and structural quantile function, also known as quantile crossing problem. Quantile regression is a very powerful tool in data science in general and econometrics in particular. Unfortunately, the crossing problem has been confounding researchers and practitioners alike for over 4 decades. Numerous attempts have been made to find a simple and general solution. This paper describes a unique and elegant solution to the problem based on a flexible check function that is easy to understand and implement in R and Python, while greatly reducing or even eliminating the crossing problem entirely. It will be very important in all areas where quantile regression is routinely used and may also find application in robust regression, especially in the context of machine learning. From this perspective, we also utilize the flexible check function to provide insights into the root causes of the crossing problem.

</p>
</details>

<details><summary><b>Deep Learning Approach for Aggressive Driving Behaviour Detection</b>
<a href="https://arxiv.org/abs/2111.04794">arxiv:2111.04794</a>
&#x1F4C8; 2 <br>
<p>Farid Talebloo, Emad A. Mohammed, Behrouz Far</p></summary>
<p>

**Abstract:** Driving behaviour is one of the primary causes of road crashes and accidents, and these can be decreased by identifying and minimizing aggressive driving behaviour. This study identifies the timesteps when a driver in different circumstances (rush, mental conflicts, reprisal) begins to drive aggressively. An observer (real or virtual) is needed to examine driving behaviour to discover aggressive driving occasions; we overcome this problem by using a smartphone's GPS sensor to detect locations and classify drivers' driving behaviour every three minutes. To detect timeseries patterns in our dataset, we employ RNN (GRU, LSTM) algorithms to identify patterns during the driving course. The algorithm is independent of road, vehicle, position, or driver characteristics. We conclude that three minutes (or more) of driving (120 seconds of GPS data) is sufficient to identify driver behaviour. The results show high accuracy and a high F1 score.

</p>
</details>

<details><summary><b>ML-EXray: Visibility into ML Deployment on the Edge</b>
<a href="https://arxiv.org/abs/2111.04779">arxiv:2111.04779</a>
&#x1F4C8; 2 <br>
<p>Hang Qiu, Ioanna Vavelidou, Jian Li, Evgenya Pergament, Pete Warden, Sandeep Chinchali, Zain Asgar, Sachin Katti</p></summary>
<p>

**Abstract:** Benefiting from expanding cloud infrastructure, deep neural networks (DNNs) today have increasingly high performance when trained in the cloud. Researchers spend months of effort competing for an extra few percentage points of model accuracy. However, when these models are actually deployed on edge devices in practice, very often, the performance can abruptly drop over 10% without obvious reasons. The key challenge is that there is not much visibility into ML inference execution on edge devices, and very little awareness of potential issues during the edge deployment process. We present ML-EXray, an end-to-end framework, which provides visibility into layer-level details of the ML execution, and helps developers analyze and debug cloud-to-edge deployment issues. More often than not, the reason for sub-optimal edge performance does not only lie in the model itself, but every operation throughout the data flow and the deployment process. Evaluations show that ML-EXray can effectively catch deployment issues, such as pre-processing bugs, quantization issues, suboptimal kernels, etc. Using ML-EXray, users need to write less than 15 lines of code to fully examine the edge deployment pipeline. Eradicating these issues, ML-EXray can correct model performance by up to 30%, pinpoint error-prone layers, and guide users to optimize kernel execution latency by two orders of magnitude. Code and APIs will be released as an open-source multi-lingual instrumentation library and a Python deployment validation library.

</p>
</details>

<details><summary><b>HEROHE Challenge: assessing HER2 status in breast cancer without immunohistochemistry or in situ hybridization</b>
<a href="https://arxiv.org/abs/2111.04738">arxiv:2111.04738</a>
&#x1F4C8; 2 <br>
<p>Eduardo Conde-Sousa, JoÃ£o Vale, Ming Feng, Kele Xu, Yin Wang, Vincenzo Della Mea, David La Barbera, Ehsan Montahaei, Mahdieh Soleymani Baghshah, Andreas Turzynski, Jacob Gildenblat, Eldad Klaiman, Yiyu Hong, Guilherme Aresta, Teresa AraÃºjo, Paulo Aguiar, Catarina Eloy, AntÃ³nio PolÃ³nia</p></summary>
<p>

**Abstract:** Breast cancer is the most common malignancy in women, being responsible for more than half a million deaths every year. As such, early and accurate diagnosis is of paramount importance. Human expertise is required to diagnose and correctly classify breast cancer and define appropriate therapy, which depends on the evaluation of the expression of different biomarkers such as the transmembrane protein receptor HER2. This evaluation requires several steps, including special techniques such as immunohistochemistry or in situ hybridization to assess HER2 status. With the goal of reducing the number of steps and human bias in diagnosis, the HEROHE Challenge was organized, as a parallel event of the 16th European Congress on Digital Pathology, aiming to automate the assessment of the HER2 status based only on hematoxylin and eosin stained tissue sample of invasive breast cancer. Methods to assess HER2 status were presented by 21 teams worldwide and the results achieved by some of the proposed methods open potential perspectives to advance the state-of-the-art.

</p>
</details>

<details><summary><b>Synthetic magnetic resonance images for domain adaptation: Application to fetal brain tissue segmentation</b>
<a href="https://arxiv.org/abs/2111.04737">arxiv:2111.04737</a>
&#x1F4C8; 2 <br>
<p>Priscille de Dumast, Hamza Kebiri, Kelly Payette, Andras Jakab, HÃ©lÃ¨ne Lajous, Meritxell Bach Cuadra</p></summary>
<p>

**Abstract:** The quantitative assessment of the developing human brain in utero is crucial to fully understand neurodevelopment. Thus, automated multi-tissue fetal brain segmentation algorithms are being developed, which in turn require annotated data to be trained. However, the available annotated fetal brain datasets are limited in number and heterogeneity, hampering domain adaptation strategies for robust segmentation. In this context, we use FaBiAN, a Fetal Brain magnetic resonance Acquisition Numerical phantom, to simulate various realistic magnetic resonance images of the fetal brain along with its class labels. We demonstrate that these multiple synthetic annotated data, generated at no cost and further reconstructed using the target super-resolution technique, can be successfully used for domain adaptation of a deep learning method that segments seven brain tissues. Overall, the accuracy of the segmentation is significantly enhanced, especially in the cortical gray matter, the white matter, the cerebellum, the deep gray matter and the brain stem.

</p>
</details>

<details><summary><b>Multi-Modality Cardiac Image Analysis with Deep Learning</b>
<a href="https://arxiv.org/abs/2111.04736">arxiv:2111.04736</a>
&#x1F4C8; 2 <br>
<p>Lei Li, Fuping Wu, Sihang Wang, Xiahai Zhuang</p></summary>
<p>

**Abstract:** Accurate cardiac computing, analysis and modeling from multi-modality images are important for the diagnosis and treatment of cardiac disease. Late gadolinium enhancement magnetic resonance imaging (LGE MRI) is a promising technique to visualize and quantify myocardial infarction (MI) and atrial scars. Automating quantification of MI and atrial scars can be challenging due to the low image quality and complex enhancement patterns of LGE MRI. Moreover, compared with the other sequences LGE MRIs with gold standard labels are particularly limited, which represents another obstacle for developing novel algorithms for automatic segmentation and quantification of LGE MRIs. This chapter aims to summarize the state-of-the-art and our recent advanced contributions on deep learning based multi-modality cardiac image analysis. Firstly, we introduce two benchmark works for multi-sequence cardiac MRI based myocardial and pathology segmentation. Secondly, two novel frameworks for left atrial scar segmentation and quantification from LGE MRI were presented. Thirdly, we present three unsupervised domain adaptation techniques for cross-modality cardiac image segmentation.

</p>
</details>

<details><summary><b>Feature-enhanced Generation and Multi-modality Fusion based Deep Neural Network for Brain Tumor Segmentation with Missing MR Modalities</b>
<a href="https://arxiv.org/abs/2111.04735">arxiv:2111.04735</a>
&#x1F4C8; 2 <br>
<p>Tongxue Zhou, StÃ©phane Canu, Pierre Vera, Su Ruan</p></summary>
<p>

**Abstract:** Using multimodal Magnetic Resonance Imaging (MRI) is necessary for accurate brain tumor segmentation. The main problem is that not all types of MRIs are always available in clinical exams. Based on the fact that there is a strong correlation between MR modalities of the same patient, in this work, we propose a novel brain tumor segmentation network in the case of missing one or more modalities. The proposed network consists of three sub-networks: a feature-enhanced generator, a correlation constraint block and a segmentation network. The feature-enhanced generator utilizes the available modalities to generate 3D feature-enhanced image representing the missing modality. The correlation constraint block can exploit the multi-source correlation between the modalities and also constrain the generator to synthesize a feature-enhanced modality which must have a coherent correlation with the available modalities. The segmentation network is a multi-encoder based U-Net to achieve the final brain tumor segmentation. The proposed method is evaluated on BraTS 2018 dataset. Experimental results demonstrate the effectiveness of the proposed method which achieves the average Dice Score of 82.9, 74.9 and 59.1 on whole tumor, tumor core and enhancing tumor, respectively across all the situations, and outperforms the best method by 3.5%, 17% and 18.2%.

</p>
</details>

<details><summary><b>Real-time landmark detection for precise endoscopic submucosal dissection via shape-aware relation network</b>
<a href="https://arxiv.org/abs/2111.04733">arxiv:2111.04733</a>
&#x1F4C8; 2 <br>
<p>Jiacheng Wang, Yueming Jin, Shuntian Cai, Hongzhi Xu, Pheng-Ann Heng, Jing Qin, Liansheng Wang</p></summary>
<p>

**Abstract:** We propose a novel shape-aware relation network for accurate and real-time landmark detection in endoscopic submucosal dissection (ESD) surgery. This task is of great clinical significance but extremely challenging due to bleeding, lighting reflection, and motion blur in the complicated surgical environment. Compared with existing solutions, which either neglect geometric relationships among targeting objects or capture the relationships by using complicated aggregation schemes, the proposed network is capable of achieving satisfactory accuracy while maintaining real-time performance by taking full advantage of the spatial relations among landmarks. We first devise an algorithm to automatically generate relation keypoint heatmaps, which are able to intuitively represent the prior knowledge of spatial relations among landmarks without using any extra manual annotation efforts. We then develop two complementary regularization schemes to progressively incorporate the prior knowledge into the training process. While one scheme introduces pixel-level regularization by multi-task learning, the other integrates global-level regularization by harnessing a newly designed grouped consistency evaluator, which adds relation constraints to the proposed network in an adversarial manner. Both schemes are beneficial to the model in training, and can be readily unloaded in inference to achieve real-time detection. We establish a large in-house dataset of ESD surgery for esophageal cancer to validate the effectiveness of our proposed method. Extensive experimental results demonstrate that our approach outperforms state-of-the-art methods in terms of accuracy and efficiency, achieving better detection results faster. Promising results on two downstream applications further corroborate the great potential of our method in ESD clinical practice.

</p>
</details>

<details><summary><b>Stock Portfolio Optimization Using a Deep Learning LSTM Model</b>
<a href="https://arxiv.org/abs/2111.04709">arxiv:2111.04709</a>
&#x1F4C8; 2 <br>
<p>Jaydip Sen, Abhishek Dutta, Sidra Mehtab</p></summary>
<p>

**Abstract:** Predicting future stock prices and their movement patterns is a complex problem. Hence, building a portfolio of capital assets using the predicted prices to achieve the optimization between its return and risk is an even more difficult task. This work has carried out an analysis of the time series of the historical prices of the top five stocks from the nine different sectors of the Indian stock market from January 1, 2016, to December 31, 2020. Optimum portfolios are built for each of these sectors. For predicting future stock prices, a long-and-short-term memory (LSTM) model is also designed and fine-tuned. After five months of the portfolio construction, the actual and the predicted returns and risks of each portfolio are computed. The predicted and the actual returns of each portfolio are found to be high, indicating the high precision of the LSTM model.

</p>
</details>

<details><summary><b>Universal and data-adaptive algorithms for model selection in linear contextual bandits</b>
<a href="https://arxiv.org/abs/2111.04688">arxiv:2111.04688</a>
&#x1F4C8; 2 <br>
<p>Vidya Muthukumar, Akshay Krishnamurthy</p></summary>
<p>

**Abstract:** Model selection in contextual bandits is an important complementary problem to regret minimization with respect to a fixed model class. We consider the simplest non-trivial instance of model-selection: distinguishing a simple multi-armed bandit problem from a linear contextual bandit problem. Even in this instance, current state-of-the-art methods explore in a suboptimal manner and require strong "feature-diversity" conditions. In this paper, we introduce new algorithms that a) explore in a data-adaptive manner, and b) provide model selection guarantees of the form $\mathcal{O}(d^Î± T^{1- Î±})$ with no feature diversity conditions whatsoever, where $d$ denotes the dimension of the linear model and $T$ denotes the total number of rounds. The first algorithm enjoys a "best-of-both-worlds" property, recovering two prior results that hold under distinct distributional assumptions, simultaneously. The second removes distributional assumptions altogether, expanding the scope for tractable model selection. Our approach extends to model selection among nested linear contextual bandits under some additional assumptions.

</p>
</details>

<details><summary><b>Smooth tensor estimation with unknown permutations</b>
<a href="https://arxiv.org/abs/2111.04681">arxiv:2111.04681</a>
&#x1F4C8; 2 <br>
<p>Chanwoo Lee, Miaoyan Wang</p></summary>
<p>

**Abstract:** We consider the problem of structured tensor denoising in the presence of unknown permutations. Such data problems arise commonly in recommendation system, neuroimaging, community detection, and multiway comparison applications. Here, we develop a general family of smooth tensor models up to arbitrary index permutations; the model incorporates the popular tensor block models and Lipschitz hypergraphon models as special cases. We show that a constrained least-squares estimator in the block-wise polynomial family achieves the minimax error bound. A phase transition phenomenon is revealed with respect to the smoothness threshold needed for optimal recovery. In particular, we find that a polynomial of degree up to $(m-2)(m+1)/2$ is sufficient for accurate recovery of order-$m$ tensors, whereas higher degree exhibits no further benefits. This phenomenon reveals the intrinsic distinction for smooth tensor estimation problems with and without unknown permutations. Furthermore, we provide an efficient polynomial-time Borda count algorithm that provably achieves optimal rate under monotonicity assumptions. The efficacy of our procedure is demonstrated through both simulations and Chicago crime data analysis.

</p>
</details>

<details><summary><b>Machine Learning Guided 3D Image Recognition for Carbonate Pore and Mineral Volumes Determination</b>
<a href="https://arxiv.org/abs/2111.04612">arxiv:2111.04612</a>
&#x1F4C8; 2 <br>
<p>Omar Alfarisi, Aikifa Raza, Hongtao Zhang, Djamel Ozzane, Mohamed Sassi, Tiejun Zhang</p></summary>
<p>

**Abstract:** Automated image processing algorithms can improve the quality, efficiency, and consistency of classifying the morphology of heterogeneous carbonate rock and can deal with a massive amount of data and images seamlessly. Geoscientists face difficulties in setting the direction of the optimum method for determining petrophysical properties from rock images, Micro-Computed Tomography (uCT), or Magnetic Resonance Imaging (MRI). Most of the successful work is from the homogeneous rocks focusing on 2D images with less focus on 3D and requiring numerical simulation. Currently, image analysis methods converge to three approaches: image processing, artificial intelligence, and combined image processing with artificial intelligence. In this work, we propose two methods to determine the porosity from 3D uCT and MRI images: an image processing method with Image Resolution Optimized Gaussian Algorithm (IROGA); advanced image recognition method enabled by Machine Learning Difference of Gaussian Random Forest (MLDGRF). We have built reference 3D micro models and collected images for calibration of IROGA and MLDGRF methods. To evaluate the predictive capability of these calibrated approaches, we ran them on 3D uCT and MRI images of natural heterogeneous carbonate rock. We measured the porosity and lithology of the carbonate rock using three and two industry-standard ways, respectively, as reference values. Notably, IROGA and MLDGRF have produced porosity results with an accuracy of 96.2% and 97.1% on the training set and 91.7% and 94.4% on blind test validation, respectively, in comparison with the three experimental measurements. We measured limestone and pyrite reference values using two methods, X-ray powder diffraction, and grain density measurements. MLDGRF has produced lithology (limestone and Pyrite) volumes with 97.7% accuracy.

</p>
</details>

<details><summary><b>Nonnegative Tensor Completion via Integer Optimization</b>
<a href="https://arxiv.org/abs/2111.04580">arxiv:2111.04580</a>
&#x1F4C8; 2 <br>
<p>Caleb Bugg, Chen Chen, Anil Aswani</p></summary>
<p>

**Abstract:** Unlike matrix completion, no algorithm for the tensor completion problem has so far been shown to achieve the information-theoretic sample complexity rate. This paper develops a new algorithm for the special case of completion for nonnegative tensors. We prove that our algorithm converges in a linear (in numerical tolerance) number of oracle steps, while achieving the information-theoretic rate. Our approach is to define a new norm for nonnegative tensors using the gauge of a specific 0-1 polytope that we construct. Because the norm is defined using a 0-1 polytope, this means we can use integer linear programming to solve linear separation problems over the polytope. We combine this insight with a variant of the Frank-Wolfe algorithm to construct our numerical algorithm, and we demonstrate its effectiveness and scalability through experiments.

</p>
</details>

<details><summary><b>CoCo Games: Graphical Game-Theoretic Swarm Control for Communication-Aware Coverage</b>
<a href="https://arxiv.org/abs/2111.04576">arxiv:2111.04576</a>
&#x1F4C8; 2 <br>
<p>Malintha Fernando, Ransalu Senanayake, Martin Swany</p></summary>
<p>

**Abstract:** We present a novel approach to maximize the communication-aware coverage for robots operating over large-scale geographical regions of interest (ROIs). Our approach complements the underlying network topology in neighborhood selection and control, rendering it highly robust in dynamic environments. We formulate the coverage as a multi-stage, cooperative graphical game and employ Variational Inference (VI) to reach the equilibrium. We experimentally validate our approach in an mobile ad-hoc wireless network scenario using Unmanned Aerial Vehicles (UAV) and User Equipment (UE) robots. We show that it can cater to ROIs defined by stationary and moving User Equipment (UE) robots under realistic network conditions.

</p>
</details>

<details><summary><b>Fast and Scalable Spike and Slab Variable Selection in High-Dimensional Gaussian Processes</b>
<a href="https://arxiv.org/abs/2111.04558">arxiv:2111.04558</a>
&#x1F4C8; 2 <br>
<p>Hugh Dance, Brooks Paige</p></summary>
<p>

**Abstract:** Variable selection in Gaussian processes (GPs) is typically undertaken by thresholding the inverse lengthscales of `automatic relevance determination' kernels, but in high-dimensional datasets this approach can be unreliable. A more probabilistically principled alternative is to use spike and slab priors and infer a posterior probability of variable inclusion. However, existing implementations in GPs are extremely costly to run in both high-dimensional and large-$n$ datasets, or are intractable for most kernels. As such, we develop a fast and scalable variational inference algorithm for the spike and slab GP that is tractable with arbitrary differentiable kernels. We improve our algorithm's ability to adapt to the sparsity of relevant variables by Bayesian model averaging over hyperparameters, and achieve substantial speed ups using zero temperature posterior restrictions, dropout pruning and nearest neighbour minibatching. In experiments our method consistently outperforms vanilla and sparse variational GPs whilst retaining similar runtimes (even when $n=10^6$) and performs competitively with a spike and slab GP using MCMC but runs up to $1000$ times faster.

</p>
</details>

<details><summary><b>Triple-level Model Inferred Collaborative Network Architecture for Video Deraining</b>
<a href="https://arxiv.org/abs/2111.04459">arxiv:2111.04459</a>
&#x1F4C8; 2 <br>
<p>Pan Mu, Zhu Liu, Yaohua Liu, Risheng Liu, Xin Fan</p></summary>
<p>

**Abstract:** Video deraining is an important issue for outdoor vision systems and has been investigated extensively. However, designing optimal architectures by the aggregating model formation and data distribution is a challenging task for video deraining. In this paper, we develop a model-guided triple-level optimization framework to deduce network architecture with cooperating optimization and auto-searching mechanism, named Triple-level Model Inferred Cooperating Searching (TMICS), for dealing with various video rain circumstances. In particular, to mitigate the problem that existing methods cannot cover various rain streaks distribution, we first design a hyper-parameter optimization model about task variable and hyper-parameter. Based on the proposed optimization model, we design a collaborative structure for video deraining. This structure includes Dominant Network Architecture (DNA) and Companionate Network Architecture (CNA) that is cooperated by introducing an Attention-based Averaging Scheme (AAS). To better explore inter-frame information from videos, we introduce a macroscopic structure searching scheme that searches from Optical Flow Module (OFM) and Temporal Grouping Module (TGM) to help restore latent frame. In addition, we apply the differentiable neural architecture searching from a compact candidate set of task-specific operations to discover desirable rain streaks removal architectures automatically. Extensive experiments on various datasets demonstrate that our model shows significant improvements in fidelity and temporal consistency over the state-of-the-art works. Source code is available at https://github.com/vis-opt-group/TMICS.

</p>
</details>

<details><summary><b>SEOFP-NET: Compression and Acceleration of Deep Neural Networks for Speech Enhancement Using Sign-Exponent-Only Floating-Points</b>
<a href="https://arxiv.org/abs/2111.04436">arxiv:2111.04436</a>
&#x1F4C8; 2 <br>
<p>Yu-Chen Lin, Cheng Yu, Yi-Te Hsu, Szu-Wei Fu, Yu Tsao, Tei-Wei Kuo</p></summary>
<p>

**Abstract:** Numerous compression and acceleration strategies have achieved outstanding results on classification tasks in various fields, such as computer vision and speech signal processing. Nevertheless, the same strategies have yielded ungratified performance on regression tasks because the nature between these and classification tasks differs. In this paper, a novel sign-exponent-only floating-point network (SEOFP-NET) technique is proposed to compress the model size and accelerate the inference time for speech enhancement, a regression task of speech signal processing. The proposed method compressed the sizes of deep neural network (DNN)-based speech enhancement models by quantizing the fraction bits of single-precision floating-point parameters during training. Before inference implementation, all parameters in the trained SEOFP-NET model are slightly adjusted to accelerate the inference time by replacing the floating-point multiplier with an integer-adder. For generalization, the SEOFP-NET technique is introduced to different speech enhancement tasks in speech signal processing with different model architectures under various corpora. The experimental results indicate that the size of SEOFP-NET models can be significantly compressed by up to 81.249% without noticeably downgrading their speech enhancement performance, and the inference time can be accelerated to 1.212x compared with the baseline models. The results also verify that the proposed SEOFP-NET can cooperate with other efficiency strategies to achieve a synergy effect for model compression. In addition, the just noticeable difference (JND) was applied to the user study experiment to statistically analyze the effect of speech enhancement on listening. The results indicate that the listeners cannot facilely differentiate between the enhanced speech signals processed by the baseline model and the proposed SEOFP-NET.

</p>
</details>

<details><summary><b>Characterizing the adversarial vulnerability of speech self-supervised learning</b>
<a href="https://arxiv.org/abs/2111.04330">arxiv:2111.04330</a>
&#x1F4C8; 2 <br>
<p>Haibin Wu, Bo Zheng, Xu Li, Xixin Wu, Hung-yi Lee, Helen Meng</p></summary>
<p>

**Abstract:** A leaderboard named Speech processing Universal PERformance Benchmark (SUPERB), which aims at benchmarking the performance of a shared self-supervised learning (SSL) speech model across various downstream speech tasks with minimal modification of architectures and small amount of data, has fueled the research for speech representation learning. The SUPERB demonstrates speech SSL upstream models improve the performance of various downstream tasks through just minimal adaptation. As the paradigm of the self-supervised learning upstream model followed by downstream tasks arouses more attention in the speech community, characterizing the adversarial robustness of such paradigm is of high priority. In this paper, we make the first attempt to investigate the adversarial vulnerability of such paradigm under the attacks from both zero-knowledge adversaries and limited-knowledge adversaries. The experimental results illustrate that the paradigm proposed by SUPERB is seriously vulnerable to limited-knowledge adversaries, and the attacks generated by zero-knowledge adversaries are with transferability. The XAB test verifies the imperceptibility of crafted adversarial attacks.

</p>
</details>

<details><summary><b>The Hardness Analysis of Thompson Sampling for Combinatorial Semi-bandits with Greedy Oracle</b>
<a href="https://arxiv.org/abs/2111.04295">arxiv:2111.04295</a>
&#x1F4C8; 2 <br>
<p>Fang Kong, Yueran Yang, Wei Chen, Shuai Li</p></summary>
<p>

**Abstract:** Thompson sampling (TS) has attracted a lot of interest in the bandit area. It was introduced in the 1930s but has not been theoretically proven until recent years. All of its analysis in the combinatorial multi-armed bandit (CMAB) setting requires an exact oracle to provide optimal solutions with any input. However, such an oracle is usually not feasible since many combinatorial optimization problems are NP-hard and only approximation oracles are available. An example (Wang and Chen, 2018) has shown the failure of TS to learn with an approximation oracle. However, this oracle is uncommon and is designed only for a specific problem instance. It is still an open question whether the convergence analysis of TS can be extended beyond the exact oracle in CMAB. In this paper, we study this question under the greedy oracle, which is a common (approximation) oracle with theoretical guarantees to solve many (offline) combinatorial optimization problems. We provide a problem-dependent regret lower bound of order $Î©(\log T/Î^2)$ to quantify the hardness of TS to solve CMAB problems with greedy oracle, where $T$ is the time horizon and $Î$ is some reward gap. We also provide an almost matching regret upper bound. These are the first theoretical results for TS to solve CMAB with a common approximation oracle and break the misconception that TS cannot work with approximation oracles.

</p>
</details>

<details><summary><b>Distribution-Invariant Differential Privacy</b>
<a href="https://arxiv.org/abs/2111.05791">arxiv:2111.05791</a>
&#x1F4C8; 1 <br>
<p>Xuan Bi, Xiaotong Shen</p></summary>
<p>

**Abstract:** Differential privacy is becoming one gold standard for protecting the privacy of publicly shared data. It has been widely used in social science, data science, public health, information technology, and the U.S. decennial census. Nevertheless, to guarantee differential privacy, existing methods may unavoidably alter the conclusion of original data analysis, as privatization often changes the sample distribution. This phenomenon is known as the trade-off between privacy protection and statistical accuracy. In this work, we break this trade-off by developing a distribution-invariant privatization (DIP) method to reconcile both high statistical accuracy and strict differential privacy. As a result, any downstream statistical or machine learning task yields essentially the same conclusion as if one used the original data. Numerically, under the same strictness of privacy protection, DIP achieves superior statistical accuracy in two simulations and on three real-world benchmarks.

</p>
</details>

<details><summary><b>Building an AI-ready RSE Workforce</b>
<a href="https://arxiv.org/abs/2111.04916">arxiv:2111.04916</a>
&#x1F4C8; 1 <br>
<p>Ying Zhang, Matthew A. Gitzendanner, Dan S. Maxwell, Justin W. Richardson, Kaleb E. Smith, Eric A. Stubbs, Brian J. Stucky, Jingchao Zhang, Erik Deumens</p></summary>
<p>

**Abstract:** Artificial Intelligence has been transforming industries and academic research across the globe, and research software development is no exception. Machine learning and deep learning are being applied in every aspect of the research software development lifecycles, from new algorithm design paradigms to software development processes. In this paper, we discuss our views on today's challenges and opportunities that AI has presented on research software development and engineers, and the approaches we, at the University of Florida, are taking to prepare our workforce for the new era of AI.

</p>
</details>

<details><summary><b>Active Sampling for Linear Regression Beyond the $\ell_2$ Norm</b>
<a href="https://arxiv.org/abs/2111.04888">arxiv:2111.04888</a>
&#x1F4C8; 1 <br>
<p>Cameron Musco, Christopher Musco, David P. Woodruff, Taisuke Yasuda</p></summary>
<p>

**Abstract:** We study active sampling algorithms for linear regression, which aim to query only a small number of entries of a target vector $b\in\mathbb{R}^n$ and output a near minimizer to $\min_{x\in\mathbb{R}^d}\|Ax-b\|$, where $A\in\mathbb{R}^{n \times d}$ is a design matrix and $\|\cdot\|$ is some loss function.
  For $\ell_p$ norm regression for any $0<p<\infty$, we give an algorithm based on Lewis weight sampling that outputs a $(1+Îµ)$ approximate solution using just $\tilde{O}(d^{\max(1,{p/2})}/\mathrm{poly}(Îµ))$ queries to $b$. We show that this dependence on $d$ is optimal, up to logarithmic factors. Our result resolves a recent open question of Chen and DereziÅski, who gave near optimal bounds for the $\ell_1$ norm, and suboptimal bounds for $\ell_p$ regression with $p\in(1,2)$.
  We also provide the first total sensitivity upper bound of $O(d^{\max\{1,p/2\}}\log^2 n)$ for loss functions with at most degree $p$ polynomial growth. This improves a recent result of Tukan, Maalouf, and Feldman. By combining this with our techniques for the $\ell_p$ regression result, we obtain an active regression algorithm making $\tilde O(d^{1+\max\{1,p/2\}}/\mathrm{poly}(Îµ))$ queries, answering another open question of Chen and DereziÅski. For the important special case of the Huber loss, we further improve our bound to an active sample complexity of $\tilde O(d^{(1+\sqrt2)/2}/Îµ^c)$ and a non-active sample complexity of $\tilde O(d^{4-2\sqrt 2}/Îµ^c)$, improving a previous $d^4$ bound for Huber regression due to Clarkson and Woodruff. Our sensitivity bounds have further implications, improving a variety of previous results using sensitivity sampling, including Orlicz norm subspace embeddings and robust subspace approximation. Finally, our active sampling results give the first sublinear time algorithms for Kronecker product regression under every $\ell_p$ norm.

</p>
</details>

<details><summary><b>Synthesizing Collective Communication Algorithms for Heterogeneous Networks with TACCL</b>
<a href="https://arxiv.org/abs/2111.04867">arxiv:2111.04867</a>
&#x1F4C8; 1 <br>
<p>Aashaka Shah, Vijay Chidambaram, Meghan Cowan, Saeed Maleki, Madan Musuvathi, Todd Mytkowicz, Jacob Nelson, Olli Saarikivi, Rachee Singh</p></summary>
<p>

**Abstract:** Large ML models and datasets have necessitated the use of multi-GPU systems for distributed model training. To harness the power offered by multi-GPU systems, it is critical to eliminate bottlenecks in inter-GPU communication - a problem made challenging by the heterogeneous nature of interconnects. In this work, we present TACCL, a synthesizer for collective communication primitives for large-scale multi-GPU systems. TACCL encodes a profiled topology and input size into a synthesis problem to generate optimized communication algorithms. TACCL is built on top of the standard NVIDIA Collective Communication Library (NCCL), allowing it to be a drop-in replacement for GPU communication in frameworks like PyTorch with minimal changes. TACCL generates algorithms for communication primitives like Allgather, Alltoall, and Allreduce that are up to $3\times$ faster than NCCL. Using TACCL's algorithms speeds up the end-to-end training of an internal mixture of experts model by $17\%$. By decomposing the optimization problem into parts and leveraging the symmetry in multi-GPU topologies, TACCL synthesizes collectives for up to 80-GPUs in less than 3 minutes, at least two orders of magnitude faster than other synthesis-based state-of-the-art collective communication libraries.

</p>
</details>

<details><summary><b>Approximating Fair Clustering with Cascaded Norm Objectives</b>
<a href="https://arxiv.org/abs/2111.04804">arxiv:2111.04804</a>
&#x1F4C8; 1 <br>
<p>Eden ChlamtÃ¡Ä, Yury Makarychev, Ali Vakilian</p></summary>
<p>

**Abstract:** We introduce the $(p,q)$-Fair Clustering problem. In this problem, we are given a set of points $P$ and a collection of different weight functions $W$. We would like to find a clustering which minimizes the $\ell_q$-norm of the vector over $W$ of the $\ell_p$-norms of the weighted distances of points in $P$ from the centers. This generalizes various clustering problems, including Socially Fair $k$-Median and $k$-Means, and is closely connected to other problems such as Densest $k$-Subgraph and Min $k$-Union.
  We utilize convex programming techniques to approximate the $(p,q)$-Fair Clustering problem for different values of $p$ and $q$. When $p\geq q$, we get an $O(k^{(p-q)/(2pq)})$, which nearly matches a $k^{Î©((p-q)/(pq))}$ lower bound based on conjectured hardness of Min $k$-Union and other problems. When $q\geq p$, we get an approximation which is independent of the size of the input for bounded $p,q$, and also matches the recent $O((\log n/(\log\log n))^{1/p})$-approximation for $(p, \infty)$-Fair Clustering by Makarychev and Vakilian (COLT 2021).

</p>
</details>

<details><summary><b>Data-driven Set-based Estimation of Polynomial Systems with Application to SIR Epidemics</b>
<a href="https://arxiv.org/abs/2111.04704">arxiv:2111.04704</a>
&#x1F4C8; 1 <br>
<p>Amr Alanwar, Muhammad Umar B. Niazi, Karl H. Johansson</p></summary>
<p>

**Abstract:** This paper proposes a data-driven set-based estimation algorithm for a class of nonlinear systems with polynomial nonlinearities. Using the system's input-output data, the proposed method computes in real-time a set that guarantees the inclusion of the system's state. Although the system is assumed to be polynomial type, the exact polynomial functions and their coefficients need not be known. To this end, the estimator relies on offline and online phases. The offline phase utilizes past input-output data to estimate a set of possible coefficients of the polynomial system. Then, using this estimated set of coefficients and the side information about the system, the online phase provides a set estimate of the state. Finally, the proposed methodology is evaluated through its application on SIR (Susceptible, Infected, Recovered) epidemic model.

</p>
</details>

<details><summary><b>Reinforcement Learning for Mixed Autonomy Intersections</b>
<a href="https://arxiv.org/abs/2111.04686">arxiv:2111.04686</a>
&#x1F4C8; 1 <br>
<p>Zhongxia Yan, Cathy Wu</p></summary>
<p>

**Abstract:** We propose a model-free reinforcement learning method for controlling mixed autonomy traffic in simulated traffic networks with through-traffic-only two-way and four-way intersections. Our method utilizes multi-agent policy decomposition which allows decentralized control based on local observations for an arbitrary number of controlled vehicles. We demonstrate that, even without reward shaping, reinforcement learning learns to coordinate the vehicles to exhibit traffic signal-like behaviors, achieving near-optimal throughput with 33-50% controlled vehicles. With the help of multi-task learning and transfer learning, we show that this behavior generalizes across inflow rates and size of the traffic network. Our code, models, and videos of results are available at https://github.com/ZhongxiaYan/mixed_autonomy_intersections.

</p>
</details>

<details><summary><b>Revisiting Methods for Finding Influential Examples</b>
<a href="https://arxiv.org/abs/2111.04683">arxiv:2111.04683</a>
&#x1F4C8; 1 <br>
<p>Karthikeyan K, Anders SÃ¸gaard</p></summary>
<p>

**Abstract:** Several instance-based explainability methods for finding influential training examples for test-time decisions have been proposed recently, including Influence Functions, TraceIn, Representer Point Selection, Grad-Dot, and Grad-Cos. Typically these methods are evaluated using LOO influence (Cook's distance) as a gold standard, or using various heuristics. In this paper, we show that all of the above methods are unstable, i.e., extremely sensitive to initialization, ordering of the training data, and batch size. We suggest that this is a natural consequence of how in the literature, the influence of examples is assumed to be independent of model state and other examples -- and argue it is not. We show that LOO influence and heuristics are, as a result, poor metrics to measure the quality of instance-based explanations, and instead propose to evaluate such explanations by their ability to detect poisoning attacks. Further, we provide a simple, yet effective baseline to improve all of the above methods and show how it leads to very significant improvements on downstream tasks.

</p>
</details>

<details><summary><b>Evaluating Predictive Uncertainty and Robustness to Distributional Shift Using Real World Data</b>
<a href="https://arxiv.org/abs/2111.04665">arxiv:2111.04665</a>
&#x1F4C8; 1 <br>
<p>Kumud Lakara, Akshat Bhandari, Pratinav Seth, Ujjwal Verma</p></summary>
<p>

**Abstract:** Most machine learning models operate under the assumption that the training, testing and deployment data is independent and identically distributed (i.i.d.). This assumption doesn't generally hold true in a natural setting. Usually, the deployment data is subject to various types of distributional shifts. The magnitude of a model's performance is proportional to this shift in the distribution of the dataset. Thus it becomes necessary to evaluate a model's uncertainty and robustness to distributional shifts to get a realistic estimate of its expected performance on real-world data. Present methods to evaluate uncertainty and model's robustness are lacking and often fail to paint the full picture. Moreover, most analysis so far has primarily focused on classification tasks. In this paper, we propose more insightful metrics for general regression tasks using the Shifts Weather Prediction Dataset. We also present an evaluation of the baseline methods using these metrics.

</p>
</details>

<details><summary><b>Inertial Newton Algorithms Avoiding Strict Saddle Points</b>
<a href="https://arxiv.org/abs/2111.04596">arxiv:2111.04596</a>
&#x1F4C8; 1 <br>
<p>Camille Castera</p></summary>
<p>

**Abstract:** We study the asymptotic behavior of second-order algorithms mixing Newton's method and inertial gradient descent in non-convex landscapes. We show that, despite the Newtonian behavior of these methods, they almost always escape strict saddle points. We also evidence the role played by the hyper-parameters of these methods in their qualitative behavior near critical points. The theoretical results are supported by numerical illustrations.

</p>
</details>

<details><summary><b>threaTrace: Detecting and Tracing Host-based Threats in Node Level Through Provenance Graph Learning</b>
<a href="https://arxiv.org/abs/2111.04333">arxiv:2111.04333</a>
&#x1F4C8; 1 <br>
<p>Su Wang, Zhiliang Wang, Tao Zhou, Xia Yin, Dongqi Han, Han Zhang, Hongbin Sun, Xingang Shi, Jiahai Yang</p></summary>
<p>

**Abstract:** Host-based threats such as Program Attack, Malware Implantation, and Advanced Persistent Threats (APT), are commonly adopted by modern attackers. Recent studies propose leveraging the rich contextual information in data provenance to detect threats in a host. Data provenance is a directed acyclic graph constructed from system audit data. Nodes in a provenance graph represent system entities (e.g., $processes$ and $files$) and edges represent system calls in the direction of information flow. However, previous studies, which extract features of the whole provenance graph, are not sensitive to the small number of threat-related entities and thus result in low performance when hunting stealthy threats.
  We present threaTrace, an anomaly-based detector that detects host-based threats at system entity level without prior knowledge of attack patterns. We tailor GraphSAGE, an inductive graph neural network, to learn every benign entity's role in a provenance graph. threaTrace is a real-time system, which is scalable of monitoring a long-term running host and capable of detecting host-based intrusion in their early phase. We evaluate threaTrace on three public datasets. The results show that threaTrace outperforms three state-of-the-art host intrusion detection systems.

</p>
</details>

<details><summary><b>Graph Robustness Benchmark: Benchmarking the Adversarial Robustness of Graph Machine Learning</b>
<a href="https://arxiv.org/abs/2111.04314">arxiv:2111.04314</a>
&#x1F4C8; 1 <br>
<p>Qinkai Zheng, Xu Zou, Yuxiao Dong, Yukuo Cen, Da Yin, Jiarong Xu, Yang Yang, Jie Tang</p></summary>
<p>

**Abstract:** Adversarial attacks on graphs have posed a major threat to the robustness of graph machine learning (GML) models. Naturally, there is an ever-escalating arms race between attackers and defenders. However, the strategies behind both sides are often not fairly compared under the same and realistic conditions. To bridge this gap, we present the Graph Robustness Benchmark (GRB) with the goal of providing a scalable, unified, modular, and reproducible evaluation for the adversarial robustness of GML models. GRB standardizes the process of attacks and defenses by 1) developing scalable and diverse datasets, 2) modularizing the attack and defense implementations, and 3) unifying the evaluation protocol in refined scenarios. By leveraging the GRB pipeline, the end-users can focus on the development of robust GML models with automated data processing and experimental evaluations. To support open and reproducible research on graph adversarial learning, GRB also hosts public leaderboards across different scenarios. As a starting point, we conduct extensive experiments to benchmark baseline techniques. GRB is open-source and welcomes contributions from the community. Datasets, codes, leaderboards are available at https://cogdl.ai/grb/home.

</p>
</details>

<details><summary><b>Defense Against Explanation Manipulation</b>
<a href="https://arxiv.org/abs/2111.04303">arxiv:2111.04303</a>
&#x1F4C8; 1 <br>
<p>Ruixiang Tang, Ninghao Liu, Fan Yang, Na Zou, Xia Hu</p></summary>
<p>

**Abstract:** Explainable machine learning attracts increasing attention as it improves transparency of models, which is helpful for machine learning to be trusted in real applications. However, explanation methods have recently been demonstrated to be vulnerable to manipulation, where we can easily change a model's explanation while keeping its prediction constant. To tackle this problem, some efforts have been paid to use more stable explanation methods or to change model configurations. In this work, we tackle the problem from the training perspective, and propose a new training scheme called Adversarial Training on EXplanations (ATEX) to improve the internal explanation stability of a model regardless of the specific explanation method being applied. Instead of directly specifying explanation values over data instances, ATEX only puts requirement on model predictions which avoids involving second-order derivatives in optimization. As a further discussion, we also find that explanation stability is closely related to another property of the model, i.e., the risk of being exposed to adversarial attack. Through experiments, besides showing that ATEX improves model robustness against manipulation targeting explanation, it also brings additional benefits including smoothing explanations and improving the efficacy of adversarial training if applied to the model.

</p>
</details>

<details><summary><b>BlueFog: Make Decentralized Algorithms Practical for Optimization and Deep Learning</b>
<a href="https://arxiv.org/abs/2111.04287">arxiv:2111.04287</a>
&#x1F4C8; 1 <br>
<p>Bicheng Ying, Kun Yuan, Hanbin Hu, Yiming Chen, Wotao Yin</p></summary>
<p>

**Abstract:** Decentralized algorithm is a form of computation that achieves a global goal through local dynamics that relies on low-cost communication between directly-connected agents. On large-scale optimization tasks involving distributed datasets, decentralized algorithms have shown strong, sometimes superior, performance over distributed algorithms with a central node. Recently, developing decentralized algorithms for deep learning has attracted great attention. They are considered as low-communication-overhead alternatives to those using a parameter server or the Ring-Allreduce protocol. However, the lack of an easy-to-use and efficient software package has kept most decentralized algorithms merely on paper. To fill the gap, we introduce BlueFog, a python library for straightforward, high-performance implementations of diverse decentralized algorithms. Based on a unified abstraction of various communication operations, BlueFog offers intuitive interfaces to implement a spectrum of decentralized algorithms, from those using a static, undirected graph for synchronous operations to those using dynamic and directed graphs for asynchronous operations. BlueFog also adopts several system-level acceleration techniques to further optimize the performance on the deep learning tasks. On mainstream DNN training tasks, BlueFog reaches a much higher throughput and achieves an overall $1.2\times \sim 1.8\times$ speedup over Horovod, a state-of-the-art distributed deep learning package based on Ring-Allreduce. BlueFog is open source at https://github.com/Bluefog-Lib/bluefog.

</p>
</details>

<details><summary><b>Deep Unsupervised Active Learning on Learnable Graphs</b>
<a href="https://arxiv.org/abs/2111.04286">arxiv:2111.04286</a>
&#x1F4C8; 1 <br>
<p>Handong Ma, Changsheng Li, Xinchu Shi, Ye Yuan, Guoren Wang</p></summary>
<p>

**Abstract:** Recently deep learning has been successfully applied to unsupervised active learning. However, current method attempts to learn a nonlinear transformation via an auto-encoder while ignoring the sample relation, leaving huge room to design more effective representation learning mechanisms for unsupervised active learning. In this paper, we propose a novel deep unsupervised Active Learning model via Learnable Graphs, named ALLG. ALLG benefits from learning optimal graph structures to acquire better sample representation and select representative samples. To make the learnt graph structure more stable and effective, we take into account $k$-nearest neighbor graph as a priori, and learn a relation propagation graph structure. We also incorporate shortcut connections among different layers, which can alleviate the well-known over-smoothing problem to some extent. To the best of our knowledge, this is the first attempt to leverage graph structure learning for unsupervised active learning. Extensive experiments performed on six datasets demonstrate the efficacy of our method.

</p>
</details>

<details><summary><b>Batch Reinforcement Learning from Crowds</b>
<a href="https://arxiv.org/abs/2111.04279">arxiv:2111.04279</a>
&#x1F4C8; 1 <br>
<p>Guoxi Zhang, Hisashi Kashima</p></summary>
<p>

**Abstract:** A shortcoming of batch reinforcement learning is its requirement for rewards in data, thus not applicable to tasks without reward functions. Existing settings for lack of reward, such as behavioral cloning, rely on optimal demonstrations collected from humans. Unfortunately, extensive expertise is required for ensuring optimality, which hinder the acquisition of large-scale data for complex tasks. This paper addresses the lack of reward in a batch reinforcement learning setting by learning a reward function from preferences. Generating preferences only requires a basic understanding of a task. Being a mental process, generating preferences is faster than performing demonstrations. So preferences can be collected at scale from non-expert humans using crowdsourcing. This paper tackles a critical challenge that emerged when collecting data from non-expert humans: the noise in preferences. A novel probabilistic model is proposed for modelling the reliability of labels, which utilizes labels collaboratively. Moreover, the proposed model smooths the estimation with a learned reward function. Evaluation on Atari datasets demonstrates the effectiveness of the proposed model, followed by an ablation study to analyze the relative importance of the proposed ideas.

</p>
</details>

<details><summary><b>Universal Lesion Detection in CT Scans using Neural Network Ensembles</b>
<a href="https://arxiv.org/abs/2111.04886">arxiv:2111.04886</a>
&#x1F4C8; 0 <br>
<p>Tarun Mattikalli, Tejas Sudharshan Mathai, Ronald M. Summers</p></summary>
<p>

**Abstract:** In clinical practice, radiologists are reliant on the lesion size when distinguishing metastatic from non-metastatic lesions. A prerequisite for lesion sizing is their detection, as it promotes the downstream assessment of tumor spread. However, lesions vary in their size and appearance in CT scans, and radiologists often miss small lesions during a busy clinical day. To overcome these challenges, we propose the use of state-of-the-art detection neural networks to flag suspicious lesions present in the NIH DeepLesion dataset for sizing. Additionally, we incorporate a bounding box fusion technique to minimize false positives (FP) and improve detection accuracy. Finally, to resemble clinical usage, we constructed an ensemble of the best detection models to localize lesions for sizing with a precision of 65.17% and sensitivity of 91.67% at 4 FP per image. Our results improve upon or maintain the performance of current state-of-the-art methods for lesion detection in challenging CT scans.

</p>
</details>

<details><summary><b>User Centered Design (VI): Human Factors Approaches for Intelligent Human-Computer Interaction</b>
<a href="https://arxiv.org/abs/2111.04880">arxiv:2111.04880</a>
&#x1F4C8; 0 <br>
<p>Wei Xu</p></summary>
<p>

**Abstract:** Starting from the design philosophy of "user-centered design", this paper analyzes the human factors characteristics of intelligent human-computer interaction (iHCI) and proposes a concept of "user-oriented iHCI". It further proposes a new human factors framework for iHCI based on the theories of joint cognitive systems, situation awareness, and intelligent agents. With the help of the new concept and framework, the paper analyzes the human factors issues in the ecosystem of autonomous vehicle co-driving and layouts future research agenda. Finally, the paper analyzes the two important research areas in iHCI (i.e., user intention recognition, human-computer collaboration) and points out the focus of human factors research in the future.

</p>
</details>

<details><summary><b>A Comparison of Model-Free and Model Predictive Control for Price Responsive Water Heaters</b>
<a href="https://arxiv.org/abs/2111.04689">arxiv:2111.04689</a>
&#x1F4C8; 0 <br>
<p>David J. Biagioni, Xiangyu Zhang, Peter Graf, Devon Sigler, Wesley Jones</p></summary>
<p>

**Abstract:** We present a careful comparison of two model-free control algorithms, Evolution Strategies (ES) and Proximal Policy Optimization (PPO), with receding horizon model predictive control (MPC) for operating simulated, price responsive water heaters. Four MPC variants are considered: a one-shot controller with perfect forecasting yielding optimal control; a limited-horizon controller with perfect forecasting; a mean forecasting-based controller; and a two-stage stochastic programming controller using historical scenarios. In all cases, the MPC model for water temperature and electricity price are exact; only water demand is uncertain. For comparison, both ES and PPO learn neural network-based policies by directly interacting with the simulated environment under the same scenarios used by MPC. All methods are then evaluated on a separate one-week continuation of the demand time series. We demonstrate that optimal control for this problem is challenging, requiring more than 8-hour lookahead for MPC with perfect forecasting to attain the minimum cost. Despite this challenge, both ES and PPO learn good general purpose policies that outperform mean forecast and two-stage stochastic MPC controllers in terms of average cost and are more than two orders of magnitude faster at computing actions. We show that ES in particular can leverage parallelism to learn a policy in under 90 seconds using 1150 CPU cores.

</p>
</details>

<details><summary><b>Intelligent Reflecting Surfaces for Enhanced NOMA-based Visible Light Communications</b>
<a href="https://arxiv.org/abs/2111.04646">arxiv:2111.04646</a>
&#x1F4C8; 0 <br>
<p>Hanaa Abumarshoud, Bassant Selim, Mallik Tatipamula, Harald Haas</p></summary>
<p>

**Abstract:** The emerging intelligent reflecting surface (IRS) technology introduces the potential of controlled light propagation in visible light communication (VLC) systems. This concept opens the door for new applications in which the channel itself can be altered to achieve specific key performance indicators. In this paper, for the first time in the open literature, we investigate the role that IRSs can play in enhancing the link reliability in VLC systems employing non-orthogonal multiple access (NOMA). We propose a framework for the joint optimisation of the NOMA and IRS parameters and show that it provides significant enhancements in link reliability. The enhancement is even more pronounced when the VLC channel is subject to blockage and random device orientation.

</p>
</details>

<details><summary><b>The Global Structure of Codimension-2 Local Bifurcations in Continuous-Time Recurrent Neural Networks</b>
<a href="https://arxiv.org/abs/2111.04547">arxiv:2111.04547</a>
&#x1F4C8; 0 <br>
<p>Randall D. Beer</p></summary>
<p>

**Abstract:** If we are ever to move beyond the study of isolated special cases in theoretical neuroscience, we need to develop more general theories of neural circuits over a given neural model. The present paper considers this challenge in the context of continuous-time recurrent neural networks (CTRNNs), a simple but dynamically-universal model that has been widely utilized in both computational neuroscience and neural networks. Here we extend previous work on the parameter space structure of codimension-1 local bifurcations in CTRNNs to include codimension-2 local bifurcation manifolds. Specifically, we derive the necessary conditions for all generic local codimension-2 bifurcations for general CTRNNs, specialize these conditions to circuits containing from one to four neurons, illustrate in full detail the application of these conditions to example circuits, derive closed-form expressions for these bifurcation manifolds where possible, and demonstrate how this analysis allows us to find and trace several global codimension-1 bifurcation manifolds that originate from the codimension-2 bifurcations.

</p>
</details>


[Next Page]({{ '/2021/11/07/2021.11.07.html' | relative_url }})
