Prev: [2022.08.08]({{ '/2022/08/08/2022.08.08.html' | relative_url }})  Next: [2022.08.10]({{ '/2022/08/10/2022.08.10.html' | relative_url }})
{% raw %}
## Summary for 2022-08-09, created on 2022-08-16


<details><summary><b>Continual Prune-and-Select: Class-incremental learning with specialized subnetworks</b>
<a href="https://arxiv.org/abs/2208.04952">arxiv:2208.04952</a>
&#x1F4C8; 47 <br>
<p>Aleksandr Dekhovich, David M. J. Tax, Marcel H. F. Sluiter, Miguel A. Bessa</p></summary>
<p>

**Abstract:** The human brain is capable of learning tasks sequentially mostly without forgetting. However, deep neural networks (DNNs) suffer from catastrophic forgetting when learning one task after another. We address this challenge considering a class-incremental learning scenario where the DNN sees test data without knowing the task from which this data originates. During training, Continual-Prune-and-Select (CP&S) finds a subnetwork within the DNN that is responsible for solving a given task. Then, during inference, CP&S selects the correct subnetwork to make predictions for that task. A new task is learned by training available neuronal connections of the DNN (previously untrained) to create a new subnetwork by pruning, which can include previously trained connections belonging to other subnetwork(s) because it does not update shared connections. This enables to eliminate catastrophic forgetting by creating specialized regions in the DNN that do not conflict with each other while still allowing knowledge transfer across them. The CP&S strategy is implemented with different subnetwork selection strategies, revealing superior performance to state-of-the-art continual learning methods tested on various datasets (CIFAR-100, CUB-200-2011, ImageNet-100 and ImageNet-1000). In particular, CP&S is capable of sequentially learning 10 tasks from ImageNet-1000 keeping an accuracy around 94% with negligible forgetting, a first-of-its-kind result in class-incremental learning. To the best of the authors' knowledge, this represents an improvement in accuracy above 20% when compared to the best alternative method.

</p>
</details>

<details><summary><b>Wavelet Score-Based Generative Modeling</b>
<a href="https://arxiv.org/abs/2208.05003">arxiv:2208.05003</a>
&#x1F4C8; 19 <br>
<p>Florentin Guth, Simon Coste, Valentin De Bortoli, Stephane Mallat</p></summary>
<p>

**Abstract:** Score-based generative models (SGMs) synthesize new data samples from Gaussian white noise by running a time-reversed Stochastic Differential Equation (SDE) whose drift coefficient depends on some probabilistic score. The discretization of such SDEs typically requires a large number of time steps and hence a high computational cost. This is because of ill-conditioning properties of the score that we analyze mathematically. We show that SGMs can be considerably accelerated, by factorizing the data distribution into a product of conditional probabilities of wavelet coefficients across scales. The resulting Wavelet Score-based Generative Model (WSGM) synthesizes wavelet coefficients with the same number of time steps at all scales, and its time complexity therefore grows linearly with the image size. This is proved mathematically over Gaussian distributions, and shown numerically over physical processes at phase transition and natural image datasets.

</p>
</details>

<details><summary><b>Cascade-based Echo Chamber Detection</b>
<a href="https://arxiv.org/abs/2208.04620">arxiv:2208.04620</a>
&#x1F4C8; 18 <br>
<p>Marco Minici, Federico Cinus, Corrado Monti, Francesco Bonchi, Giuseppe Manco</p></summary>
<p>

**Abstract:** Despite echo chambers in social media have been under considerable scrutiny, general models for their detection and analysis are missing. In this work, we aim to fill this gap by proposing a probabilistic generative model that explains social media footprints -- i.e., social network structure and propagations of information -- through a set of latent communities, characterized by a degree of echo-chamber behavior and by an opinion polarity. Specifically, echo chambers are modeled as communities that are permeable to pieces of information with similar ideological polarity, and impermeable to information of opposed leaning: this allows discriminating echo chambers from communities that lack a clear ideological alignment.
  To learn the model parameters we propose a scalable, stochastic adaptation of the Generalized Expectation Maximization algorithm, that optimizes the joint likelihood of observing social connections and information propagation. Experiments on synthetic data show that our algorithm is able to correctly reconstruct ground-truth latent communities with their degree of echo-chamber behavior and opinion polarity. Experiments on real-world data about polarized social and political debates, such as the Brexit referendum or the COVID-19 vaccine campaign, confirm the effectiveness of our proposal in detecting echo chambers. Finally, we show how our model can improve accuracy in auxiliary predictive tasks, such as stance detection and prediction of future propagations.

</p>
</details>

<details><summary><b>Learning Mean-Field Control for Delayed Information Load Balancing in Large Queuing Systems</b>
<a href="https://arxiv.org/abs/2208.04777">arxiv:2208.04777</a>
&#x1F4C8; 11 <br>
<p>Anam Tahir, Kai Cui, Heinz Koeppl</p></summary>
<p>

**Abstract:** Recent years have seen a great increase in the capacity and parallel processing power of data centers and cloud services. To fully utilize the said distributed systems, optimal load balancing for parallel queuing architectures must be realized. Existing state-of-the-art solutions fail to consider the effect of communication delays on the behaviour of very large systems with many clients. In this work, we consider a multi-agent load balancing system, with delayed information, consisting of many clients (load balancers) and many parallel queues. In order to obtain a tractable solution, we model this system as a mean-field control problem with enlarged state-action space in discrete time through exact discretization. Subsequently, we apply policy gradient reinforcement learning algorithms to find an optimal load balancing solution. Here, the discrete-time system model incorporates a synchronization delay under which the queue state information is synchronously broadcasted and updated at all clients. We then provide theoretical performance guarantees for our methodology in large systems. Finally, using experiments, we prove that our approach is not only scalable but also shows good performance when compared to the state-of-the-art power-of-d variant of the Join-the-Shortest-Queue (JSQ) and other policies in the presence of synchronization delays.

</p>
</details>

<details><summary><b>Robust Reinforcement Learning using Offline Data</b>
<a href="https://arxiv.org/abs/2208.05129">arxiv:2208.05129</a>
&#x1F4C8; 8 <br>
<p>Kishan Panaganti, Zaiyan Xu, Dileep Kalathil, Mohammad Ghavamzadeh</p></summary>
<p>

**Abstract:** The goal of robust reinforcement learning (RL) is to learn a policy that is robust against the uncertainty in model parameters. Parameter uncertainty commonly occurs in many real-world RL applications due to simulator modeling errors, changes in the real-world system dynamics over time, and adversarial disturbances. Robust RL is typically formulated as a max-min problem, where the objective is to learn the policy that maximizes the value against the worst possible models that lie in an uncertainty set. In this work, we propose a robust RL algorithm called Robust Fitted Q-Iteration (RFQI), which uses only an offline dataset to learn the optimal robust policy. Robust RL with offline data is significantly more challenging than its non-robust counterpart because of the minimization over all models present in the robust Bellman operator. This poses challenges in offline data collection, optimization over the models, and unbiased estimation. In this work, we propose a systematic approach to overcome these challenges, resulting in our RFQI algorithm. We prove that RFQI learns a near-optimal robust policy under standard assumptions and demonstrate its superior performance on standard benchmark problems.

</p>
</details>

<details><summary><b>A Model-Constrained Tangent Manifold Learning Approach for Dynamical Systems</b>
<a href="https://arxiv.org/abs/2208.04995">arxiv:2208.04995</a>
&#x1F4C8; 8 <br>
<p>Hai Van Nguyen, Tan Bui-Thanh</p></summary>
<p>

**Abstract:** Real time accurate solutions of large scale complex dynamical systems are in critical need for control, optimization, uncertainty quantification, and decision-making in practical engineering and science applications. This paper contributes in this direction a model constrained tangent manifold learning (mcTangent) approach. At the heart of mcTangent is the synergy of several desirable strategies: i) a tangent manifold learning to take advantage of the neural network speed and the time accurate nature of the method of lines; ii) a model constrained approach to encode the neural network tangent with the underlying governing equations; iii) sequential learning strategies to promote long time stability and accuracy; and iv) data randomization approach to implicitly enforce the smoothness of the neural network tangent and its likeliness to the truth tangent up second order derivatives in order to further enhance the stability and accuracy of mcTangent solutions. Both semi heuristic and rigorous arguments are provided to analyze and justify the proposed approach. Several numerical results for transport equation, viscous Burgers equation, and Navier Stokes equation are presented to study and demonstrate the capability of the proposed mcTangent learning approach.

</p>
</details>

<details><summary><b>SBPF: Sensitiveness Based Pruning Framework For Convolutional Neural Network On Image Classification</b>
<a href="https://arxiv.org/abs/2208.04588">arxiv:2208.04588</a>
&#x1F4C8; 8 <br>
<p>Yiheng Lu, Maoguo Gong, Wei Zhao, Kaiyuan Feng, Hao Li</p></summary>
<p>

**Abstract:** Pruning techniques are used comprehensively to compress convolutional neural networks (CNNs) on image classification. However, the majority of pruning methods require a well pre-trained model to provide useful supporting parameters, such as C1-norm, BatchNorm value and gradient information, which may lead to inconsistency of filter evaluation if the parameters of the pre-trained model are not well optimized. Therefore, we propose a sensitiveness based method to evaluate the importance of each layer from the perspective of inference accuracy by adding extra damage for the original model. Because the performance of the accuracy is determined by the distribution of parameters across all layers rather than individual parameter, the sensitiveness based method will be robust to update of parameters. Namely, we can obtain similar importance evaluation of each convolutional layer between the imperfect-trained and fully trained models. For VGG-16 on CIFAR-10, even when the original model is only trained with 50 epochs, we can get same evaluation of layer importance as the results when the model is trained fully. Then we will remove filters proportional from each layer by the quantified sensitiveness. Our sensitiveness based pruning framework is verified efficiently on VGG-16, a customized Conv-4 and ResNet-18 with CIFAR-10, MNIST and CIFAR-100, respectively.

</p>
</details>

<details><summary><b>Alternating Cross-attention Vision-Language Model for Efficient Learning with Medical Image and Report without Curation</b>
<a href="https://arxiv.org/abs/2208.05140">arxiv:2208.05140</a>
&#x1F4C8; 7 <br>
<p>Sangjoon Park, Eun Sun Lee, Jeong Eun Lee, Jong Chul Ye</p></summary>
<p>

**Abstract:** Recent advances in vision-language pre-training have demonstrated astounding performances in diverse vision-language tasks, shedding a light on the long-standing problems of a comprehensive understanding of both visual and textual concepts in artificial intelligence research. However, there has been limited success in the application of vision-language pre-training in the medical domain, as the current vision-language models and learning strategies for photographic images and captions are not optimal to process the medical data which are usually insufficient in the amount and the diversity, which impedes successful learning of joint vision-language concepts. In this study, we introduce MAX-VL, a model tailored for efficient vision-language pre-training in the medical domain. We experimentally demonstrated that the pre-trained MAX-VL model outperforms the current state-of-the-art vision language models in various vision-language tasks. We also suggested the clinical utility for the diagnosis of newly emerging diseases and human error detection as well as showed the widespread applicability of the model in different domain data.

</p>
</details>

<details><summary><b>Quantum artificial vision for defect detection in manufacturing</b>
<a href="https://arxiv.org/abs/2208.04988">arxiv:2208.04988</a>
&#x1F4C8; 7 <br>
<p>Daniel Guijo, Victor Onofre, Gianni Del Bimbo, Samuel Mugel, Daniel Estepa, Xabier De Carlos, Ana Adell, Aizea Lojo, Josu Bilbao, Roman Orus</p></summary>
<p>

**Abstract:** In this paper we consider several algorithms for quantum computer vision using Noisy Intermediate-Scale Quantum (NISQ) devices, and benchmark them for a real problem against their classical counterparts. Specifically, we consider two approaches: a quantum Support Vector Machine (QSVM) on a universal gate-based quantum computer, and QBoost on a quantum annealer. The quantum vision systems are benchmarked for an unbalanced dataset of images where the aim is to detect defects in manufactured car pieces. We see that the quantum algorithms outperform their classical counterparts in several ways, with QBoost allowing for larger problems to be analyzed with present-day quantum annealers. Data preprocessing, including dimensionality reduction and contrast enhancement, is also discussed, as well as hyperparameter tuning in QBoost. To the best of our knowledge, this is the first implementation of quantum computer vision systems for a problem of industrial relevance in a manufacturing production line.

</p>
</details>

<details><summary><b>Deep Probabilistic Models for Forward and Inverse Problems in Parametric PDEs</b>
<a href="https://arxiv.org/abs/2208.04856">arxiv:2208.04856</a>
&#x1F4C8; 7 <br>
<p>Arnaud Vadeboncoeur, Ömer Deniz Akyildiz, Ieva Kazlauskaite, Mark Girolami, Fehmi Cirak</p></summary>
<p>

**Abstract:** We formulate a class of physics-driven deep latent variable models (PDDLVM) to learn parameter-to-solution (forward) and solution-to-parameter (inverse) maps of parametric partial differential equations (PDEs). Our formulation leverages the finite element method (FEM), deep neural networks, and probabilistic modeling to assemble a deep probabilistic framework in which the forward and inverse maps are approximated with coherent uncertainty quantification. Our probabilistic model explicitly incorporates a parametric PDE-based density and a trainable solution-to-parameter network while the introduced amortized variational family postulates a parameter-to-solution network, all of which are jointly trained. Furthermore, the proposed methodology does not require any expensive PDE solves and is physics-informed only at training time, which allows real-time emulation of PDEs and generation of inverse problem solutions after training, bypassing the need for FEM solve operations with comparable accuracy to FEM solutions. The proposed framework further allows for a seamless integration of observed data for solving inverse problems and building generative models. We demonstrate the effectiveness of our method on a nonlinear Poisson problem, elastic shells with complex 3D geometries, and integrating generic physics-informed neural networks (PINN) architectures. We achieve up to three orders of magnitude speed-ups after training compared to traditional FEM solvers, while outputting coherent uncertainty estimates.

</p>
</details>

<details><summary><b>Extending GCC-PHAT using Shift Equivariant Neural Networks</b>
<a href="https://arxiv.org/abs/2208.04654">arxiv:2208.04654</a>
&#x1F4C8; 7 <br>
<p>Axel Berg, Mark O'Connor, Kalle Åström, Magnus Oskarsson</p></summary>
<p>

**Abstract:** Speaker localization using microphone arrays depends on accurate time delay estimation techniques. For decades, methods based on the generalized cross correlation with phase transform (GCC-PHAT) have been widely adopted for this purpose. Recently, the GCC-PHAT has also been used to provide input features to neural networks in order to remove the effects of noise and reverberation, but at the cost of losing theoretical guarantees in noise-free conditions. We propose a novel approach to extending the GCC-PHAT, where the received signals are filtered using a shift equivariant neural network that preserves the timing information contained in the signals. By extensive experiments we show that our model consistently reduces the error of the GCC-PHAT in adverse environments, with guarantees of exact time delay recovery in ideal conditions.

</p>
</details>

<details><summary><b>Machine Learning-based EEG Applications and Markets</b>
<a href="https://arxiv.org/abs/2208.05144">arxiv:2208.05144</a>
&#x1F4C8; 6 <br>
<p>Weiqing Gu, Bohan Yang, Ryan Chang</p></summary>
<p>

**Abstract:** This paper addresses both the various EEG applications and the current EEG market ecosystem propelled by machine learning. Increasingly available open medical and health datasets using EEG encourage data-driven research with a promise of improving neurology for patient care through knowledge discovery and machine learning data science algorithm development. This effort leads to various kinds of EEG developments and currently forms a new EEG market. This paper attempts to do a comprehensive survey on the EEG market and covers the six significant applications of EEG, including diagnosis/screening, drug development, neuromarketing, daily health, metaverse, and age/disability assistance. The highlight of this survey is on the compare and contrast between the research field and the business market. Our survey points out the current limitations of EEG and indicates the future direction of research and business opportunity for every EEG application listed above. Based on our survey, more research on machine learning-based EEG applications will lead to a more robust EEG-related market. More companies will use the research technology and apply it to real-life settings. As the EEG-related market grows, the EEG-related devices will collect more EEG data, and there will be more EEG data available for researchers to use in their study, coming back as a virtuous cycle. Our market analysis indicates that research related to the use of EEG data and machine learning in the six applications listed above points toward a clear trend in the growth and development of the EEG ecosystem and machine learning world.

</p>
</details>

<details><summary><b>Automatic Ultrasound Image Segmentation of Supraclavicular Nerve Using Dilated U-Net Deep Learning Architecture</b>
<a href="https://arxiv.org/abs/2208.05050">arxiv:2208.05050</a>
&#x1F4C8; 6 <br>
<p>Mizuki Miyatake, Subhash Nerella, David Simpson, Natalia Pawlowicz, Sarah Stern, Patrick Tighe, Parisa Rashidi</p></summary>
<p>

**Abstract:** Automated object recognition in medical images can facilitate medical diagnosis and treatment. In this paper, we automatically segmented supraclavicular nerves in ultrasound images to assist in injecting peripheral nerve blocks. Nerve blocks are generally used for pain treatment after surgery, where ultrasound guidance is used to inject local anesthetics next to target nerves. This treatment blocks the transmission of pain signals to the brain, which can help improve the rate of recovery from surgery and significantly decrease the requirement for postoperative opioids. However, Ultrasound Guided Regional Anesthesia (UGRA) requires anesthesiologists to visually recognize the actual nerve position in the ultrasound images. This is a complex task given the myriad visual presentations of nerves in ultrasound images, and their visual similarity to many neighboring tissues. In this study, we used an automated nerve detection system for the UGRA Nerve Block treatment. The system can recognize the position of the nerve in ultrasound images using Deep Learning techniques. We developed a model to capture features of nerves by training two deep neural networks with skip connections: two extended U-Net architectures with and without dilated convolutions. This solution could potentially lead to an improved blockade of targeted nerves in regional anesthesia.

</p>
</details>

<details><summary><b>Explainable prediction of Qcodes for NOTAMs using column generation</b>
<a href="https://arxiv.org/abs/2208.04955">arxiv:2208.04955</a>
&#x1F4C8; 6 <br>
<p>Krunal Kishor Patel, Guy Desaulniers, Andrea Lodi, Freddy Lecue</p></summary>
<p>

**Abstract:** A NOtice To AirMen (NOTAM) contains important flight route related information. To search and filter them, NOTAMs are grouped into categories called QCodes. In this paper, we develop a tool to predict, with some explanations, a Qcode for a NOTAM. We present a way to extend the interpretable binary classification using column generation proposed in Dash, Gunluk, and Wei (2018) to a multiclass text classification method. We describe the techniques used to tackle the issues related to one vs-rest classification, such as multiple outputs and class imbalances. Furthermore, we introduce some heuristics, including the use of a CP-SAT solver for the subproblems, to reduce the training time. Finally, we show that our approach compares favorably with state-of-the-art machine learning algorithms like Linear SVM and small neural networks while adding the needed interpretability component.

</p>
</details>

<details><summary><b>A Bayesian Bradley-Terry model to compare multiple ML algorithms on multiple data sets</b>
<a href="https://arxiv.org/abs/2208.04935">arxiv:2208.04935</a>
&#x1F4C8; 6 <br>
<p>Jacques Wainer</p></summary>
<p>

**Abstract:** This paper proposes a Bayesian model to compare multiple algorithms on multiple data sets, on any metric. The model is based on the Bradley-Terry model, that counts the number of times one algorithm performs better than another on different data sets. Because of its Bayesian foundations, the Bayesian Bradley Terry model (BBT) has different characteristics than frequentist approaches to comparing multiple algorithms on multiple data sets, such as Demsar (2006) tests on mean rank, and Benavoli et al. (2016) multiple pairwise Wilcoxon tests with p-adjustment procedures. In particular, a Bayesian approach allows for more nuanced statements regarding the algorithms beyond claiming that the difference is or it is not statistically significant. Bayesian approaches also allow to define when two algorithms are equivalent for practical purposes, or the region of practical equivalence (ROPE). Different than a Bayesian signed rank comparison procedure proposed by Benavoli et al. (2017), our approach can define a ROPE for any metric, since it is based on probability statements, and not on differences of that metric. This paper also proposes a local ROPE concept, that evaluates whether a positive difference between a mean measure across some cross validation to the mean of some other algorithms is should be really seen as the first algorithm being better than the second, based on effect sizes. This local ROPE proposal is independent of a Bayesian use, and can be used in frequentist approaches based on ranks. A R package and a Python program that implements the BBT is available.

</p>
</details>

<details><summary><b>Literature Review: Graph Kernels in Chemoinformatics</b>
<a href="https://arxiv.org/abs/2208.04929">arxiv:2208.04929</a>
&#x1F4C8; 6 <br>
<p>James Young</p></summary>
<p>

**Abstract:** The purpose of this review is to introduce the reader to graph kernels, with a view of applying them in classification problems in chemoinformatics. Graph kernels are functions that allow us to infer chemical properties of molecules, which can help with tasks such as finding suitable compounds for drug design. The use of kernel methods is but one particular way two quantify similarity between graphs. We restrict our discussion to this one method, although popular alternatives have emerged in recent years, most notably Graph Neural Networks.

</p>
</details>

<details><summary><b>Res-Dense Net for 3D Covid Chest CT-scan classification</b>
<a href="https://arxiv.org/abs/2208.04613">arxiv:2208.04613</a>
&#x1F4C8; 6 <br>
<p>Quoc-Huy Trinh, Minh-Van Nguyen, Thien-Phuc Nguyen Dinh</p></summary>
<p>

**Abstract:** One of the most contentious areas of research in Medical Image Preprocessing is 3D CT-scan. With the rapid spread of COVID-19, the function of CT-scan in properly and swiftly diagnosing the disease has become critical. It has a positive impact on infection prevention. There are many tasks to diagnose the illness through CT-scan images, include COVID-19. In this paper, we propose a method that using a Stacking Deep Neural Network to detect the Covid 19 through the series of 3D CT-scans images . In our method, we experiment with two backbones are DenseNet 121 and ResNet 101. This method achieves a competitive performance on some evaluation metrics

</p>
</details>

<details><summary><b>Statistical Properties of the log-cosh Loss Function Used in Machine Learning</b>
<a href="https://arxiv.org/abs/2208.04564">arxiv:2208.04564</a>
&#x1F4C8; 6 <br>
<p>Resve A. Saleh, A. K. Md. Ehsanes Saleh</p></summary>
<p>

**Abstract:** This paper analyzes a popular loss function used in machine learning called the log-cosh loss function. A number of papers have been published using this loss function but, to date, no statistical analysis has been presented in the literature. In this paper, we present the distribution function from which the log-cosh loss arises. We compare it to a similar distribution, called the Cauchy distribution, and carry out various statistical procedures that characterize its properties. In particular, we examine its associated pdf, cdf, likelihood function and Fisher information. Side-by-side we consider the Cauchy and Cosh distributions as well as the MLE of the location parameter with asymptotic bias, asymptotic variance, and confidence intervals. We also provide a comparison of robust estimators from several other loss functions, including the Huber loss function and the rank dispersion function. Further, we examine the use of the log-cosh function for quantile regression. In particular, we identify a quantile distribution function from which a maximum likelihood estimator for quantile regression can be derived. Finally, we compare a quantile M-estimator based on log-cosh with robust monotonicity against another approach to quantile regression based on convolutional smoothing.

</p>
</details>

<details><summary><b>Fast Heterogeneous Federated Learning with Hybrid Client Selection</b>
<a href="https://arxiv.org/abs/2208.05135">arxiv:2208.05135</a>
&#x1F4C8; 5 <br>
<p>Guangyuan Shen, Dehong Gao, DuanXiao Song, libin yang, Xukai Zhou, Shirui Pan, Wei Lou, Fang Zhou</p></summary>
<p>

**Abstract:** Client selection schemes are widely adopted to handle the communication-efficient problems in recent studies of Federated Learning (FL). However, the large variance of the model updates aggregated from the randomly-selected unrepresentative subsets directly slows the FL convergence. We present a novel clustering-based client selection scheme to accelerate the FL convergence by variance reduction. Simple yet effective schemes are designed to improve the clustering effect and control the effect fluctuation, therefore, generating the client subset with certain representativeness of sampling. Theoretically, we demonstrate the improvement of the proposed scheme in variance reduction. We also present the tighter convergence guarantee of the proposed method thanks to the variance reduction. Experimental results confirm the exceed efficiency of our scheme compared to alternatives.

</p>
</details>

<details><summary><b>Reducing Exploitability with Population Based Training</b>
<a href="https://arxiv.org/abs/2208.05083">arxiv:2208.05083</a>
&#x1F4C8; 5 <br>
<p>Pavel Czempin, Adam Gleave</p></summary>
<p>

**Abstract:** Self-play reinforcement learning has achieved state-of-the-art, and often superhuman, performance in a variety of zero-sum games. Yet prior work has found that policies that are highly capable against regular opponents can fail catastrophically against adversarial policies: an opponent trained explicitly against the victim. Prior defenses using adversarial training were able to make the victim robust to a specific adversary, but the victim remained vulnerable to new ones. We conjecture this limitation was due to insufficient diversity of adversaries seen during training. We propose a defense using population based training to pit the victim against a diverse set of opponents. We evaluate this defense's robustness against new adversaries in two low-dimensional environments. Our defense increases robustness against adversaries, as measured by number of attacker training timesteps to exploit the victim. Furthermore, we show that robustness is correlated with the size of the opponent population.

</p>
</details>

<details><summary><b>Model-Free Generative Replay for Lifelong Reinforcement Learning: Application to Starcraft-2</b>
<a href="https://arxiv.org/abs/2208.05056">arxiv:2208.05056</a>
&#x1F4C8; 5 <br>
<p>Zachary Daniels, Aswin Raghavan, Jesse Hostetler, Abrar Rahman, Indranil Sur, Michael Piacentino, Ajay Divakaran</p></summary>
<p>

**Abstract:** One approach to meet the challenges of deep lifelong reinforcement learning (LRL) is careful management of the agent's learning experiences, in order to learn (without forgetting) and build internal meta-models (of the tasks, environments, agents, and world). Generative replay (GR) is a biologically-inspired replay mechanism that augments learning experiences with self-labelled examples drawn from an internal generative model that is updated over time. In this paper, we present a version of GR for LRL that satisfies two desiderata: (a) Introspective density modelling of the latent representations of policies learned using deep RL, and (b) Model-free end-to-end learning. In this work, we study three deep learning architectures for model-free GR. We evaluate our proposed algorithms on three different scenarios comprising tasks from the StarCraft2 and Minigrid domains. We report several key findings showing the impact of the design choices on quantitative metrics that include transfer learning, generalization to unseen tasks, fast adaptation after task change, performance comparable to a task expert, and minimizing catastrophic forgetting. We observe that our GR prevents drift in the features-to-action mapping from the latent vector space of a deep actor-critic agent. We also show improvements in established lifelong learning metrics. We find that the introduction of a small random replay buffer is needed to significantly increase the stability of training, when used in conjunction with the replay buffer and the generated replay buffer. Overall, we find that "hidden replay" (a well-known architecture for class-incremental classification) is the most promising approach that pushes the state-of-the-art in GR for LRL.

</p>
</details>

<details><summary><b>Neural-Rendezvous: Learning-based Robust Guidance and Control to Encounter Interstellar Objects</b>
<a href="https://arxiv.org/abs/2208.04883">arxiv:2208.04883</a>
&#x1F4C8; 5 <br>
<p>Hiroyasu Tsukamoto, Soon-Jo Chung, Benjamin Donitz, Michel Ingham, Declan Mages, Yashwanth Kumar Nakka</p></summary>
<p>

**Abstract:** Interstellar objects (ISOs), astronomical objects not gravitationally bound to the Sun, are likely representatives of primitive materials invaluable in understanding exoplanetary star systems. Due to their poorly constrained orbits with generally high inclinations and relative velocities, however, exploring ISOs with conventional human-in-the-loop approaches is significantly challenging. This paper presents Neural-Rendezvous -- a deep learning-based guidance and control framework for encountering any fast-moving objects, including ISOs, robustly, accurately, and autonomously in real-time. It uses pointwise minimum norm tracking control on top of a guidance policy modeled by a spectrally-normalized deep neural network, where its hyperparameters are tuned with a newly introduced loss function directly penalizing the state trajectory tracking error. We rigorously show that, even in the challenging case of ISO exploration, Neural-Rendezvous provides 1) a high probability exponential bound on the expected spacecraft delivery error; and 2) a finite optimality gap with respect to the solution of model predictive control, both of which are indispensable especially for such a critical space mission. In numerical simulations, Neural-Rendezvous is demonstrated to achieve a terminal-time delivery error of less than 0.2 km for 99% of the ISO candidates with realistic state uncertainty, whilst retaining computational efficiency sufficient for real-time implementation.

</p>
</details>

<details><summary><b>Combining Variational Modeling with Partial Gradient Perturbation to Prevent Deep Gradient Leakage</b>
<a href="https://arxiv.org/abs/2208.04767">arxiv:2208.04767</a>
&#x1F4C8; 5 <br>
<p>Daniel Scheliga, Patrick Mäder, Marco Seeland</p></summary>
<p>

**Abstract:** Exploiting gradient leakage to reconstruct supposedly private training data, gradient inversion attacks are an ubiquitous threat in collaborative learning of neural networks. To prevent gradient leakage without suffering from severe loss in model performance, recent work proposed a PRivacy EnhanCing mODulE (PRECODE) based on variational modeling as extension for arbitrary model architectures. In this work, we investigate the effect of PRECODE on gradient inversion attacks to reveal its underlying working principle. We show that variational modeling induces stochasticity on PRECODE's and its subsequent layers' gradients that prevents gradient attacks from convergence. By purposefully omitting those stochastic gradients during attack optimization, we formulate an attack that can disable PRECODE's privacy preserving effects. To ensure privacy preservation against such targeted attacks, we propose PRECODE with Partial Perturbation (PPP), as strategic combination of variational modeling and partial gradient perturbation. We conduct an extensive empirical study on four seminal model architectures and two image classification datasets. We find all architectures to be prone to gradient leakage, which can be prevented by PPP. In result, we show that our approach requires less gradient perturbation to effectively preserve privacy without harming model performance.

</p>
</details>

<details><summary><b>KL-divergence Based Deep Learning for Discrete Time Model</b>
<a href="https://arxiv.org/abs/2208.05100">arxiv:2208.05100</a>
&#x1F4C8; 4 <br>
<p>Li Liu, Xiangeng Fang, Di Wang, Weijing Tang, Kevin He</p></summary>
<p>

**Abstract:** Neural Network (Deep Learning) is a modern model in Artificial Intelligence and it has been exploited in Survival Analysis. Although several improvements have been shown by previous works, training an excellent deep learning model requires a huge amount of data, which may not hold in practice. To address this challenge, we develop a Kullback-Leibler-based (KL) deep learning procedure to integrate external survival prediction models with newly collected time-to-event data. Time-dependent KL discrimination information is utilized to measure the discrepancy between the external and internal data. This is the first work considering using prior information to deal with short data problem in Survival Analysis for deep learning. Simulation and real data results show that the proposed model achieves better performance and higher robustness compared with previous works.

</p>
</details>

<details><summary><b>Interpretable Polynomial Neural Ordinary Differential Equations</b>
<a href="https://arxiv.org/abs/2208.05072">arxiv:2208.05072</a>
&#x1F4C8; 4 <br>
<p>Colby Fronk, Linda Petzold</p></summary>
<p>

**Abstract:** Neural networks have the ability to serve as universal function approximators, but they are not interpretable and don't generalize well outside of their training region. Both of these issues are problematic when trying to apply standard neural ordinary differential equations (neural ODEs) to dynamical systems. We introduce the polynomial neural ODE, which is a deep polynomial neural network inside of the neural ODE framework. We demonstrate the capability of polynomial neural ODEs to predict outside of the training region, as well as perform direct symbolic regression without additional tools such as SINDy.

</p>
</details>

<details><summary><b>Human Activity Recognition Using Cascaded Dual Attention CNN and Bi-Directional GRU Framework</b>
<a href="https://arxiv.org/abs/2208.05034">arxiv:2208.05034</a>
&#x1F4C8; 4 <br>
<p>Hayat Ullah, Arslan Munir</p></summary>
<p>

**Abstract:** Vision-based human activity recognition has emerged as one of the essential research areas in video analytics domain. Over the last decade, numerous advanced deep learning algorithms have been introduced to recognize complex human actions from video streams. These deep learning algorithms have shown impressive performance for the human activity recognition task. However, these newly introduced methods either exclusively focus on model performance or the effectiveness of these models in terms of computational efficiency and robustness, resulting in a biased tradeoff in their proposals to deal with challenging human activity recognition problem. To overcome the limitations of contemporary deep learning models for human activity recognition, this paper presents a computationally efficient yet generic spatial-temporal cascaded framework that exploits the deep discriminative spatial and temporal features for human activity recognition. For efficient representation of human actions, we have proposed an efficient dual attentional convolutional neural network (CNN) architecture that leverages a unified channel-spatial attention mechanism to extract human-centric salient features in video frames. The dual channel-spatial attention layers together with the convolutional layers learn to be more attentive in the spatial receptive fields having objects over the number of feature maps. The extracted discriminative salient features are then forwarded to stacked bi-directional gated recurrent unit (Bi-GRU) for long-term temporal modeling and recognition of human actions using both forward and backward pass gradient learning. Extensive experiments are conducted, where the obtained results show that the proposed framework attains an improvement in execution time up to 167 times in terms of frames per second as compared to most of the contemporary action recognition methods.

</p>
</details>

<details><summary><b>Machine Learning 1- and 2-electron reduced density matrices of polymeric molecules</b>
<a href="https://arxiv.org/abs/2208.04976">arxiv:2208.04976</a>
&#x1F4C8; 4 <br>
<p>David Pekker, Chungwen Liang, Sankha Pattanayak, Swagatam Mukhopadhyay</p></summary>
<p>

**Abstract:** Encoding the electronic structure of molecules using 2-electron reduced density matrices (2RDMs) as opposed to many-body wave functions has been a decades-long quest as the 2RDM contains sufficient information to compute the exact molecular energy but requires only polynomial storage. We focus on linear polymers with varying conformations and numbers of monomers and show that we can use machine learning to predict both the 1-electron and the 2-electron reduced density matrices. Moreover, by applying the Hamiltonian operator to the predicted reduced density matrices we show that we can recover the molecular energy. Thus, we demonstrate the feasibility of a machine learning approach to predicting electronic structure that is generalizable both to new conformations as well as new molecules. At the same time our work circumvents the N-representability problem that has stymied the adaption of 2RDM methods, by directly machine-learning valid Reduced Density Matrices.

</p>
</details>

<details><summary><b>From Scratch to Sketch: Deep Decoupled Hierarchical Reinforcement Learning for Robotic Sketching Agent</b>
<a href="https://arxiv.org/abs/2208.04833">arxiv:2208.04833</a>
&#x1F4C8; 4 <br>
<p>Ganghun Lee, Minji Kim, Minsu Lee, Byoung-Tak Zhang</p></summary>
<p>

**Abstract:** We present an automated learning framework for a robotic sketching agent that is capable of learning stroke-based rendering and motor control simultaneously. We formulate the robotic sketching problem as a deep decoupled hierarchical reinforcement learning; two policies for stroke-based rendering and motor control are learned independently to achieve sub-tasks for drawing, and form a hierarchy when cooperating for real-world drawing. Without hand-crafted features, drawing sequences or trajectories, and inverse kinematics, the proposed method trains the robotic sketching agent from scratch. We performed experiments with a 6-DoF robot arm with 2F gripper to sketch doodles. Our experimental results show that the two policies successfully learned the sub-tasks and collaborated to sketch the target images. Also, the robustness and flexibility were examined by varying drawing tools and surfaces.

</p>
</details>

<details><summary><b>Improved Multiple-Image-Based Reflection Removal Algorithm Using Deep Neural Networks</b>
<a href="https://arxiv.org/abs/2208.04679">arxiv:2208.04679</a>
&#x1F4C8; 4 <br>
<p>Tingtian Li, Yuk-Hee Chan, Daniel P. K. Lun</p></summary>
<p>

**Abstract:** When imaging through a semi-reflective medium such as glass, the reflection of another scene can often be found in the captured images. It degrades the quality of the images and affects their subsequent analyses. In this paper, a novel deep neural network approach for solving the reflection problem in imaging is presented. Traditional reflection removal methods not only require long computation time for solving different optimization functions, their performance is also not guaranteed. As array cameras are readily available in nowadays imaging devices, we first suggest in this paper a multiple-image based depth estimation method using a convolutional neural network (CNN). The proposed network avoids the depth ambiguity problem due to the reflection in the image, and directly estimates the depths along the image edges. They are then used to classify the edges as belonging to the background or reflection. Since edges having similar depth values are error prone in the classification, they are removed from the reflection removal process. We suggest a generative adversarial network (GAN) to regenerate the removed background edges. Finally, the estimated background edge map is fed to another auto-encoder network to assist the extraction of the background from the original image. Experimental results show that the proposed reflection removal algorithm achieves superior performance both quantitatively and qualitatively as compared to the state-of-the-art methods. The proposed algorithm also shows much faster speed compared to the existing approaches using the traditional optimization methods.

</p>
</details>

<details><summary><b>DeepHider: A Multi-module and Invisibility Watermarking Scheme for Language Model</b>
<a href="https://arxiv.org/abs/2208.04676">arxiv:2208.04676</a>
&#x1F4C8; 4 <br>
<p>Long Dai, Jiarong Mao, Xuefeng Fan, Xiaoyi Zhou</p></summary>
<p>

**Abstract:** With the rapid development of natural language processing (NLP) technology, NLP models have shown great economic value in business. However, the owner's models are vulnerable to the threat of pirated redistribution, which breaks the symmetry relationship between model owners and consumers. Therefore, a model protection mechanism is needed to keep the symmetry from being broken. Currently, language model protection schemes based on black-box verification perform poorly in terms of invisibility of trigger samples, which are easily detected by humans or anomaly detectors and thus prevent verification. To solve this problem, this paper proposes a trigger sample of the triggerless mode for ownership verification. In addition, a thief may replace the classification module for a watermarked model to satisfy its specific classification task and remove the watermark present in the model. Therefore, this paper further proposes a new threat of replacing the model classification module and performing global fine-tuning of the model, and successfully verifies the model ownership through a white-box approach. Meanwhile, we use the properties of blockchain such as tamper-proof and traceability to prevent the ownership statement of thieves. Experiments show that the proposed scheme successfully verifies ownership with 100% watermark verification accuracy without affecting the original performance of the model, and has strong robustness and low False trigger rate.

</p>
</details>

<details><summary><b>Multi-Task Fusion via Reinforcement Learning for Long-Term User Satisfaction in Recommender Systems</b>
<a href="https://arxiv.org/abs/2208.04560">arxiv:2208.04560</a>
&#x1F4C8; 4 <br>
<p>Qihua Zhang, Junning Liu, Yuzhuo Dai, Yiyan Qi, Yifan Yuan, Kunlun Zheng, Fan Huang, Xianfeng Tan</p></summary>
<p>

**Abstract:** Recommender System (RS) is an important online application that affects billions of users every day. The mainstream RS ranking framework is composed of two parts: a Multi-Task Learning model (MTL) that predicts various user feedback, i.e., clicks, likes, sharings, and a Multi-Task Fusion model (MTF) that combines the multi-task outputs into one final ranking score with respect to user satisfaction. There has not been much research on the fusion model while it has great impact on the final recommendation as the last crucial process of the ranking. To optimize long-term user satisfaction rather than obtain instant returns greedily, we formulate MTF task as Markov Decision Process (MDP) within a recommendation session and propose a Batch Reinforcement Learning (RL) based Multi-Task Fusion framework (BatchRL-MTF) that includes a Batch RL framework and an online exploration. The former exploits Batch RL to learn an optimal recommendation policy from the fixed batch data offline for long-term user satisfaction, while the latter explores potential high-value actions online to break through the local optimal dilemma. With a comprehensive investigation on user behaviors, we model the user satisfaction reward with subtle heuristics from two aspects of user stickiness and user activeness. Finally, we conduct extensive experiments on a billion-sample level real-world dataset to show the effectiveness of our model. We propose a conservative offline policy estimator (Conservative-OPEstimator) to test our model offline. Furthermore, we take online experiments in a real recommendation environment to compare performance of different models. As one of few Batch RL researches applied in MTF task successfully, our model has also been deployed on a large-scale industrial short video platform, serving hundreds of millions of users.

</p>
</details>

<details><summary><b>High Recall Data-to-text Generation with Progressive Edit</b>
<a href="https://arxiv.org/abs/2208.04558">arxiv:2208.04558</a>
&#x1F4C8; 4 <br>
<p>Choonghan Kim, Gary Geunbae Lee</p></summary>
<p>

**Abstract:** Data-to-text (D2T) generation is the task of generating texts from structured inputs. We observed that when the same target sentence was repeated twice, Transformer (T5) based model generates an output made up of asymmetric sentences from structured inputs. In other words, these sentences were different in length and quality. We call this phenomenon "Asymmetric Generation" and we exploit this in D2T generation. Once asymmetric sentences are generated, we add the first part of the output with a no-repeated-target. As this goes through progressive edit (ProEdit), the recall increases. Hence, this method better covers structured inputs than before editing. ProEdit is a simple but effective way to improve performance in D2T generation and it achieves the new stateof-the-art result on the ToTTo dataset

</p>
</details>

<details><summary><b>Machine Learning with DBOS</b>
<a href="https://arxiv.org/abs/2208.05101">arxiv:2208.05101</a>
&#x1F4C8; 3 <br>
<p>Robert Redmond, Nathan W. Weckwerth, Brian S. Xia, Qian Li, Peter Kraft, Deeptaanshu Kumar, Çağatay Demiralp, Michael Stonebraker</p></summary>
<p>

**Abstract:** We recently proposed a new cluster operating system stack, DBOS, centered on a DBMS. DBOS enables unique support for ML applications by encapsulating ML code within stored procedures, centralizing ancillary ML data, providing security built into the underlying DBMS, co-locating ML code and data, and tracking data and workflow provenance. Here we demonstrate a subset of these benefits around two ML applications. We first show that image classification and object detection models using GPUs can be served as DBOS stored procedures with performance competitive to existing systems. We then present a 1D CNN trained to detect anomalies in HTTP requests on DBOS-backed web services, achieving SOTA results. We use this model to develop an interactive anomaly detection system and evaluate it through qualitative user feedback, demonstrating its usefulness as a proof of concept for future work to develop learned real-time security services on top of DBOS.

</p>
</details>

<details><summary><b>Adaptive Target-Condition Neural Network: DNN-Aided Load Balancing for Hybrid LiFi and WiFi Networks</b>
<a href="https://arxiv.org/abs/2208.05035">arxiv:2208.05035</a>
&#x1F4C8; 3 <br>
<p>Han Ji, Qiang Wang, Stephen J. Redmond, Iman Tavakkolnia, Xiping Wu</p></summary>
<p>

**Abstract:** Load balancing (LB) is a challenging issue in the hybrid light fidelity (LiFi) and wireless fidelity (WiFi) networks (HLWNets), due to the nature of heterogeneous access points (APs). Machine learning has the potential to provide a complexity-friendly LB solution with near-optimal network performance, at the cost of a training process. The state-of-the-art (SOTA) learning-aided LB methods, however, need retraining when the network environment (especially the number of users) changes, significantly limiting its practicability. In this paper, a novel deep neural network (DNN) structure named adaptive target-condition neural network (A-TCNN) is proposed, which conducts AP selection for one target user upon the condition of other users. Also, an adaptive mechanism is developed to map a smaller number of users to a larger number through splitting their data rate requirements, without affecting the AP selection result for the target user. This enables the proposed method to handle different numbers of users without the need for retraining. Results show that A-TCNN achieves a network throughput very close to that of the testing dataset, with a gap less than 3%. It is also proven that A-TCNN can obtain a network throughput comparable to two SOTA benchmarks, while reducing the runtime by up to three orders of magnitude.

</p>
</details>

<details><summary><b>A Unified Comparison of User Modeling Techniques for Predicting Data Interaction and Detecting Exploration Bias</b>
<a href="https://arxiv.org/abs/2208.05021">arxiv:2208.05021</a>
&#x1F4C8; 3 <br>
<p>Sunwoo Ha, Shayan Monadjemi, Roman Garnett, Alvitta Ottley</p></summary>
<p>

**Abstract:** The visual analytics community has proposed several user modeling algorithms to capture and analyze users' interaction behavior in order to assist users in data exploration and insight generation. For example, some can detect exploration biases while others can predict data points that the user will interact with before that interaction occurs. Researchers believe this collection of algorithms can help create more intelligent visual analytics tools. However, the community lacks a rigorous evaluation and comparison of these existing techniques. As a result, there is limited guidance on which method to use and when. Our paper seeks to fill in this missing gap by comparing and ranking eight user modeling algorithms based on their performance on a diverse set of four user study datasets. We analyze exploration bias detection, data interaction prediction, and algorithmic complexity, among other measures. Based on our findings, we highlight open challenges and new directions for analyzing user interactions and visualization provenance.

</p>
</details>

<details><summary><b>Localizing the conceptual difference of two scenes using deep learning for house keeping usages</b>
<a href="https://arxiv.org/abs/2208.04884">arxiv:2208.04884</a>
&#x1F4C8; 3 <br>
<p>Ali Atghaei, Ehsan Rahnama, Kiavash azimi</p></summary>
<p>

**Abstract:** Finding the conceptual difference between the two images in an industrial environment has been especially important for HSE purposes and there is still no reliable and conformable method to find the major differences to alert the related controllers. Due to the abundance and variety of objects in different environments, the use of supervised learning methods in this field is facing a major problem. Due to the sharp and even slight change in lighting conditions in the two scenes, it is not possible to naively subtract the two images in order to find these differences. The goal of this paper is to find and localize the conceptual differences of two frames of one scene but in two different times and classify the differences to addition, reduction and change in the field. In this paper, we demonstrate a comprehensive solution for this application by presenting the deep learning method and using transfer learning and structural modification of the error function, as well as a process for adding and synthesizing data. An appropriate data set was provided and labeled, and the model results were evaluated on this data set and the possibility of using it in real and industrial applications was explained.

</p>
</details>

<details><summary><b>Kill Chaos with Kindness: Agreeableness Improves Team Performance Under Uncertainty</b>
<a href="https://arxiv.org/abs/2208.04873">arxiv:2208.04873</a>
&#x1F4C8; 3 <br>
<p>Soo Ling Lim, Randall S. Peterson, Peter J. Bentley, Xiaoran Hu, JoEllyn Prouty McLaren</p></summary>
<p>

**Abstract:** Teams are central to human accomplishment. Over the past half-century, psychologists have identified the Big-Five cross-culturally valid personality variables: Neuroticism, Extraversion, Openness, Conscientiousness, and Agreeableness. The first four have shown consistent relationships with team performance. Agreeableness (being harmonious, altruistic, humble, and cooperative), however, has demonstrated a non-significant and highly variable relationship with team performance. We resolve this inconsistency through computational modelling. An agent-based model (ABM) is used to predict the effects of personality traits on teamwork and a genetic algorithm is then used to explore the limits of the ABM in order to discover which traits correlate with best and worst performing teams for a problem with different levels of uncertainty (noise). New dependencies revealed by the exploration are corroborated by analyzing previously-unseen data from one the largest datasets on team performance to date comprising 3,698 individuals in 593 teams working on more than 5,000 group tasks with and without uncertainty, collected over a 10-year period. Our finding is that the dependency between team performance and Agreeableness is moderated by task uncertainty. Combining evolutionary computation with ABMs in this way provides a new methodology for the scientific investigation of teamwork, making new predictions, and improving our understanding of human behaviors. Our results confirm the potential usefulness of computer modelling for developing theory, as well as shedding light on the future of teams as work environments are becoming increasingly fluid and uncertain.

</p>
</details>

<details><summary><b>Design of High-Throughput Mixed-Precision CNN Accelerators on FPGA</b>
<a href="https://arxiv.org/abs/2208.04854">arxiv:2208.04854</a>
&#x1F4C8; 3 <br>
<p>Cecilia Latotzke, Tim Ciesielski, Tobias Gemmeke</p></summary>
<p>

**Abstract:** Convolutional Neural Networks (CNNs) reach high accuracies in various application domains, but require large amounts of computation and incur costly data movements. One method to decrease these costs while trading accuracy is weight and/or activation word-length reduction. Thereby, layer-wise mixed-precision quantization allows for more efficient results while inflating the design space. In this work, we present an in-depth quantitative methodology to efficiently explore the design space considering the limited hardware resources of a given FPGA. Our holistic exploration approach vertically traverses the various design entry levels from the architectural down to the logic level, and laterally covers optimization from processing elements to dataflow for an efficient mixed-precision CNN accelerator. Our resulting hardware accelerators implement truly mixed-precision operations that enable efficient execution of layer-wise and channel-wise quantized CNNs. Mapping feed-forward and identity-shortcut-connection mixed-precision CNNs result in competitive accuracy-throughout trade-offs: 245 frames/s with 87.48% Top-5 accuracy for ResNet-18 and 92.9% Top-5 accuracy with 1.13 TOps/s for ResNet-152, respectively. Thereby, the required memory footprint for parameters is reduced by 4.9x and 9.4x compared to the respective floating-point baseline.

</p>
</details>

<details><summary><b>Longitudinal Prediction of Postnatal Brain Magnetic Resonance Images via a Metamorphic Generative Adversarial Network</b>
<a href="https://arxiv.org/abs/2208.04825">arxiv:2208.04825</a>
&#x1F4C8; 3 <br>
<p>Yunzhi Huang, Sahar Ahmad, Luyi Han, Shuai Wang, Zhengwang Wu, Weili Lin, Gang Li, Li Wang, Pew-Thian Yap</p></summary>
<p>

**Abstract:** Missing scans are inevitable in longitudinal studies due to either subject dropouts or failed scans. In this paper, we propose a deep learning framework to predict missing scans from acquired scans, catering to longitudinal infant studies. Prediction of infant brain MRI is challenging owing to the rapid contrast and structural changes particularly during the first year of life. We introduce a trustworthy metamorphic generative adversarial network (MGAN) for translating infant brain MRI from one time-point to another. MGAN has three key features: (i) Image translation leveraging spatial and frequency information for detail-preserving mapping; (ii) Quality-guided learning strategy that focuses attention on challenging regions. (iii) Multi-scale hybrid loss function that improves translation of tissue contrast and structural details. Experimental results indicate that MGAN outperforms existing GANs by accurately predicting both contrast and anatomical details.

</p>
</details>

<details><summary><b>Improving COVID-19 CT Classification of CNNs by Learning Parameter-Efficient Representation</b>
<a href="https://arxiv.org/abs/2208.04718">arxiv:2208.04718</a>
&#x1F4C8; 3 <br>
<p>Yujia Xu, Hak-Keung Lam, Guangyu Jia, Jian Jiang, Junkai Liao, Xinqi Bao</p></summary>
<p>

**Abstract:** COVID-19 pandemic continues to spread rapidly over the world and causes a tremendous crisis in global human health and the economy. Its early detection and diagnosis are crucial for controlling the further spread. Many deep learning-based methods have been proposed to assist clinicians in automatic COVID-19 diagnosis based on computed tomography imaging. However, challenges still remain, including low data diversity in existing datasets, and unsatisfied detection resulting from insufficient accuracy and sensitivity of deep learning models. To enhance the data diversity, we design augmentation techniques of incremental levels and apply them to the largest open-access benchmark dataset, COVIDx CT-2A. Meanwhile, similarity regularization (SR) derived from contrastive learning is proposed in this study to enable CNNs to learn more parameter-efficient representations, thus improving the accuracy and sensitivity of CNNs. The results on seven commonly used CNNs demonstrate that CNN performance can be improved stably through applying the designed augmentation and SR techniques. In particular, DenseNet121 with SR achieves an average test accuracy of 99.44% in three trials for three-category classification, including normal, non-COVID-19 pneumonia, and COVID-19 pneumonia. And the achieved precision, sensitivity, and specificity for the COVID-19 pneumonia category are 98.40%, 99.59%, and 99.50%, respectively. These statistics suggest that our method has surpassed the existing state-of-the-art methods on the COVIDx CT-2A dataset.

</p>
</details>

<details><summary><b>Representation learning of rare temporal conditions for travel time prediction</b>
<a href="https://arxiv.org/abs/2208.04667">arxiv:2208.04667</a>
&#x1F4C8; 3 <br>
<p>Niklas Petersen, Filipe Rodrigues, Francisco Pereira</p></summary>
<p>

**Abstract:** Predicting travel time under rare temporal conditions (e.g., public holidays, school vacation period, etc.) constitutes a challenge due to the limitation of historical data. If at all available, historical data often form a heterogeneous time series due to high probability of other changes over long periods of time (e.g., road works, introduced traffic calming initiatives, etc.). This is especially prominent in cities and suburban areas. We present a vector-space model for encoding rare temporal conditions, that allows coherent representation learning across different temporal conditions. We show increased performance for travel time prediction over different baselines when utilizing the vector-space encoding for representing the temporal setting.

</p>
</details>

<details><summary><b>Generative models-based data labeling for deep networks regression: application to seed maturity estimation from UAV multispectral images</b>
<a href="https://arxiv.org/abs/2208.04611">arxiv:2208.04611</a>
&#x1F4C8; 3 <br>
<p>Eric Dericquebourg, Adel Hafiane, Raphael Canals</p></summary>
<p>

**Abstract:** Monitoring seed maturity is an increasing challenge in agriculture due to climate change and more restrictive practices. Seeds monitoring in the field is essential to optimize the farming process and to guarantee yield quality through high germination. Traditional methods are based on limited sampling in the field and analysis in laboratory. Moreover, they are time consuming and only allow monitoring sub-sections of the crop field. This leads to a lack of accuracy on the condition of the crop as a whole due to intra-field heterogeneities. Multispectral imagery by UAV allows uniform scan of fields and better capture of crop maturity information. On the other hand, deep learning methods have shown tremendous potential in estimating agronomic parameters, especially maturity. However, they require large labeled datasets. Although large sets of aerial images are available, labeling them with ground truth is a tedious, if not impossible task. In this paper, we propose a method for estimating parsley seed maturity using multispectral UAV imagery, with a new approach for automatic data labeling. This approach is based on parametric and non-parametric models to provide weak labels. We also consider the data acquisition protocol and the performance evaluation of the different steps of the method. Results show good performance, and the non-parametric kernel density estimator model can improve neural network generalization when used as a labeling method, leading to more robust and better performing deep neural models.

</p>
</details>

<details><summary><b>Comparison of semi-supervised learning methods for High Content Screening quality control</b>
<a href="https://arxiv.org/abs/2208.04592">arxiv:2208.04592</a>
&#x1F4C8; 3 <br>
<p>Umar Masud, Ethan Cohen, Ihab Bendidi, Guillaume Bollot, Auguste Genovesio</p></summary>
<p>

**Abstract:** Progress in automated microscopy and quantitative image analysis has promoted high-content screening (HCS) as an efficient drug discovery and research tool. While HCS offers to quantify complex cellular phenotypes from images at high throughput, this process can be obstructed by image aberrations such as out-of-focus image blur, fluorophore saturation, debris, a high level of noise, unexpected auto-fluorescence or empty images. While this issue has received moderate attention in the literature, overlooking these artefacts can seriously hamper downstream image processing tasks and hinder detection of subtle phenotypes. It is therefore of primary concern, and a prerequisite, to use quality control in HCS. In this work, we evaluate deep learning options that do not require extensive image annotations to provide a straightforward and easy to use semi-supervised learning solution to this issue. Concretely, we compared the efficacy of recent self-supervised and transfer learning approaches to provide a base encoder to a high throughput artefact image detector. The results of this study suggest that transfer learning methods should be preferred for this task as they not only performed best here but present the advantage of not requiring sensitive hyperparameter settings nor extensive additional training.

</p>
</details>

<details><summary><b>Long-term Causal Effects Estimation via Latent Surrogates Representation Learning</b>
<a href="https://arxiv.org/abs/2208.04589">arxiv:2208.04589</a>
&#x1F4C8; 3 <br>
<p>Ruichu Cai, Weilin Chen, Zeqin Yang, Shu Wan, Chen Zheng, Xiaoqing Yang, Jiecheng Guo</p></summary>
<p>

**Abstract:** Estimating long-term causal effects based on short-term surrogates is a significant but challenging problem in many real-world applications, e.g., marketing and medicine. Despite its success in certain domains, most existing methods estimate causal effects in an idealistic and simplistic way - ignoring the causal structure among short-term outcomes and treating all of them as surrogates. However, such methods cannot be well applied to real-world scenarios, in which the partially observed surrogates are mixed with their proxies among short-term outcomes. To this end, we develop our flexible method, Laser, to estimate long-term causal effects in the more realistic situation that the surrogates are observed or have observed proxies.Given the indistinguishability between the surrogates and proxies, we utilize identifiable variational auto-encoder (iVAE) to recover the whole valid surrogates on all the surrogates candidates without the need of distinguishing the observed surrogates or the proxies of latent surrogates. With the help of the recovered surrogates, we further devise an unbiased estimation of long-term causal effects. Extensive experimental results on the real-world and semi-synthetic datasets demonstrate the effectiveness of our proposed method.

</p>
</details>

<details><summary><b>More Interpretable Graph Similarity Computation via Maximum Common Subgraph Inference</b>
<a href="https://arxiv.org/abs/2208.04580">arxiv:2208.04580</a>
&#x1F4C8; 3 <br>
<p>Zixun Lan, Binjie Hong, Ye Ma, Fei Ma</p></summary>
<p>

**Abstract:** Graph similarity measurement, which computes the distance/similarity between two graphs, arises in various graph-related tasks. Recent learning-based methods lack interpretability, as they directly transform interaction information between two graphs into one hidden vector and then map it to similarity. To cope with this problem, this study proposes a more interpretable end-to-end paradigm for graph similarity learning, named Similarity Computation via Maximum Common Subgraph Inference (INFMCS). Our critical insight into INFMCS is the strong correlation between similarity score and Maximum Common Subgraph (MCS). We implicitly infer MCS to obtain the normalized MCS size, with the supervision information being only the similarity score during training. To capture more global information, we also stack some vanilla transformer encoder layers with graph convolution layers and propose a novel permutation-invariant node Positional Encoding. The entire model is quite simple yet effective. Comprehensive experiments demonstrate that INFMCS consistently outperforms state-of-the-art baselines for graph-graph classification and regression tasks. Ablation experiments verify the effectiveness of the proposed computation paradigm and other components. Also, visualization and statistics of results reveal the interpretability of INFMCS.

</p>
</details>

<details><summary><b>Effects of Annotations' Density on Named Entity Recognition Models' Performance in the Context of African Languages</b>
<a href="https://arxiv.org/abs/2208.04568">arxiv:2208.04568</a>
&#x1F4C8; 3 <br>
<p>Manuel A. Fokam</p></summary>
<p>

**Abstract:** African languages have recently been the subject of several studies in Natural Language Processing (NLP) and, this has caused a significant increase in their representation in the field. However, most studies tend to focus more on the models than the quality of the datasets when assessing the models' performance in tasks such as Named Entity Recognition (NER). While this works well in most cases, it does not account for the limitations of doing NLP with low-resource languages, that is, the quality and the quantity of the dataset at our disposal. This paper provides an analysis of the performance of various models based on the quality of the dataset. We evaluate different pre-trained models with respect to the entity density per sentence of some African NER datasets. We hope with this study to improve the way NLP studies are done in the context of low-resourced languages.

</p>
</details>

<details><summary><b>Analyzing and Enhancing Closed-loop Stability in Reactive Simulation</b>
<a href="https://arxiv.org/abs/2208.04559">arxiv:2208.04559</a>
&#x1F4C8; 3 <br>
<p>Wei-Jer Chang, Yeping Hu, Chenran Li, Wei Zhan, Masayoshi Tomizuka</p></summary>
<p>

**Abstract:** Simulation has played an important role in efficiently evaluating self-driving vehicles in terms of scalability. Existing methods mostly rely on heuristic-based simulation, where traffic participants follow certain human-encoded rules that fail to generate complex human behaviors. Therefore, the reactive simulation concept is proposed to bridge the human behavior gap between simulation and real-world traffic scenarios by leveraging real-world data. However, these reactive models can easily generate unreasonable behaviors after a few steps of simulation, where we regard the model as losing its stability. To the best of our knowledge, no work has explicitly discussed and analyzed the stability of the reactive simulation framework. In this paper, we aim to provide a thorough stability analysis of the reactive simulation and propose a solution to enhance the stability. Specifically, we first propose a new reactive simulation framework, where we discover that the smoothness and consistency of the simulated state sequences are crucial factors to stability. We then incorporate the kinematic vehicle model into the framework to improve the closed-loop stability of the reactive simulation. Furthermore, along with commonly-used metrics, several novel metrics are proposed in this paper to better analyze the simulation performance.

</p>
</details>

<details><summary><b>Hierarchical Residual Learning Based Vector Quantized Variational Autoencoder for Image Reconstruction and Generation</b>
<a href="https://arxiv.org/abs/2208.04554">arxiv:2208.04554</a>
&#x1F4C8; 3 <br>
<p>Mohammad Adiban, Kalin Stefanov, Sabato Marco Siniscalchi, Giampiero Salvi</p></summary>
<p>

**Abstract:** We propose a multi-layer variational autoencoder method, we call HR-VQVAE, that learns hierarchical discrete representations of the data. By utilizing a novel objective function, each layer in HR-VQVAE learns a discrete representation of the residual from previous layers through a vector quantized encoder. Furthermore, the representations at each layer are hierarchically linked to those at previous layers. We evaluate our method on the tasks of image reconstruction and generation. Experimental results demonstrate that the discrete representations learned by HR-VQVAE enable the decoder to reconstruct high-quality images with less distortion than the baseline methods, namely VQVAE and VQVAE-2. HR-VQVAE can also generate high-quality and diverse images that outperform state-of-the-art generative models, providing further verification of the efficiency of the learned representations. The hierarchical nature of HR-VQVAE i) reduces the decoding search time, making the method particularly suitable for high-load tasks and ii) allows to increase the codebook size without incurring the codebook collapse problem.

</p>
</details>

<details><summary><b>Adversarial Machine Learning-Based Anticipation of Threats Against Vehicle-to-Microgrid Services</b>
<a href="https://arxiv.org/abs/2208.05073">arxiv:2208.05073</a>
&#x1F4C8; 2 <br>
<p>Ahmed Omara, Burak Kantarci</p></summary>
<p>

**Abstract:** In this paper, we study the expanding attack surface of Adversarial Machine Learning (AML) and the potential attacks against Vehicle-to-Microgrid (V2M) services. We present an anticipatory study of a multi-stage gray-box attack that can achieve a comparable result to a white-box attack. Adversaries aim to deceive the targeted Machine Learning (ML) classifier at the network edge to misclassify the incoming energy requests from microgrids. With an inference attack, an adversary can collect real-time data from the communication between smart microgrids and a 5G gNodeB to train a surrogate (i.e., shadow) model of the targeted classifier at the edge. To anticipate the associated impact of an adversary's capability to collect real-time data instances, we study five different cases, each representing different amounts of real-time data instances collected by an adversary. Out of six ML models trained on the complete dataset, K-Nearest Neighbour (K-NN) is selected as the surrogate model, and through simulations, we demonstrate that the multi-stage gray-box attack is able to mislead the ML classifier and cause an Evasion Increase Rate (EIR) up to 73.2% using 40% less data than what a white-box attack needs to achieve a similar EIR.

</p>
</details>

<details><summary><b>Heterogeneous Multi-agent Zero-Shot Coordination by Coevolution</b>
<a href="https://arxiv.org/abs/2208.04957">arxiv:2208.04957</a>
&#x1F4C8; 2 <br>
<p>Ke Xue, Yutong Wang, Lei Yuan, Cong Guan, Chao Qian, Yang Yu</p></summary>
<p>

**Abstract:** Generating agents that can achieve Zero-Shot Coordination (ZSC) with unseen partners is a new challenge in cooperative Multi-Agent Reinforcement Learning (MARL). Recently, some studies have made progress in ZSC by exposing the agents to diverse partners during the training process. They usually involve self-play when training the partners, implicitly assuming that the tasks are homogeneous. However, many real-world tasks are heterogeneous, and hence previous methods may fail. In this paper, we study the heterogeneous ZSC problem for the first time and propose a general method based on coevolution, which coevolves two populations of agents and partners through three sub-processes: pairing, updating and selection. Experimental results on a collaborative cooking task show the necessity of considering the heterogeneous setting and illustrate that our proposed method is a promising solution for heterogeneous cooperative MARL.

</p>
</details>

<details><summary><b>BabyNet: A Lightweight Network for Infant Reaching Action Recognition in Unconstrained Environments to Support Future Pediatric Rehabilitation Applications</b>
<a href="https://arxiv.org/abs/2208.04950">arxiv:2208.04950</a>
&#x1F4C8; 2 <br>
<p>Amel Dechemi, Vikarn Bhakri, Ipsita Sahin, Arjun Modi, Julya Mestas, Pamodya Peiris, Dannya Enriquez Barrundia, Elena Kokkoni, Konstantinos Karydis</p></summary>
<p>

**Abstract:** Action recognition is an important component to improve autonomy of physical rehabilitation devices, such as wearable robotic exoskeletons. Existing human action recognition algorithms focus on adult applications rather than pediatric ones. In this paper, we introduce BabyNet, a light-weight (in terms of trainable parameters) network structure to recognize infant reaching action from off-body stationary cameras. We develop an annotated dataset that includes diverse reaches performed while in a sitting posture by different infants in unconstrained environments (e.g., in home settings, etc.). Our approach uses the spatial and temporal connection of annotated bounding boxes to interpret onset and offset of reaching, and to detect a complete reaching action. We evaluate the efficiency of our proposed approach and compare its performance against other learning-based network structures in terms of capability of capturing temporal inter-dependencies and accuracy of detection of reaching onset and offset. Results indicate our BabyNet can attain solid performance in terms of (average) testing accuracy that exceeds that of other larger networks, and can hence serve as a light-weight data-driven framework for video-based infant reaching action recognition.

</p>
</details>

<details><summary><b>Intrinsically Motivated Learning of Causal World Models</b>
<a href="https://arxiv.org/abs/2208.04892">arxiv:2208.04892</a>
&#x1F4C8; 2 <br>
<p>Louis Annabi</p></summary>
<p>

**Abstract:** Despite the recent progress in deep learning and reinforcement learning, transfer and generalization of skills learned on specific tasks is very limited compared to human (or animal) intelligence. The lifelong, incremental building of common sense knowledge might be a necessary component on the way to achieve more general intelligence. A promising direction is to build world models capturing the true physical mechanisms hidden behind the sensorimotor interaction with the environment. Here we explore the idea that inferring the causal structure of the environment could benefit from well-chosen actions as means to collect relevant interventional data.

</p>
</details>

<details><summary><b>sim2real: Cardiac MR Image Simulation-to-Real Translation via Unsupervised GANs</b>
<a href="https://arxiv.org/abs/2208.04874">arxiv:2208.04874</a>
&#x1F4C8; 2 <br>
<p>Sina Amirrajab, Yasmina Al Khalil, Cristian Lorenz, Jurgen Weese, Josien Pluim, Marcel Breeuwer</p></summary>
<p>

**Abstract:** There has been considerable interest in the MR physics-based simulation of a database of virtual cardiac MR images for the development of deep-learning analysis networks. However, the employment of such a database is limited or shows suboptimal performance due to the realism gap, missing textures, and the simplified appearance of simulated images. In this work we 1) provide image simulation on virtual XCAT subjects with varying anatomies, and 2) propose sim2real translation network to improve image realism. Our usability experiments suggest that sim2real data exhibits a good potential to augment training data and boost the performance of a segmentation algorithm.

</p>
</details>

<details><summary><b>On the Importance of Critical Period in Multi-stage Reinforcement Learning</b>
<a href="https://arxiv.org/abs/2208.04832">arxiv:2208.04832</a>
&#x1F4C8; 2 <br>
<p>Junseok Park, Inwoo Hwang, Min Whoo Lee, Hyunseok Oh, Minsu Lee, Youngki Lee, Byoung-Tak Zhang</p></summary>
<p>

**Abstract:** The initial years of an infant's life are known as the critical period, during which the overall development of learning performance is significantly impacted due to neural plasticity. In recent studies, an AI agent, with a deep neural network mimicking mechanisms of actual neurons, exhibited a learning period similar to human's critical period. Especially during this initial period, the appropriate stimuli play a vital role in developing learning ability. However, transforming human cognitive bias into an appropriate shaping reward is quite challenging, and prior works on critical period do not focus on finding the appropriate stimulus. To take a step further, we propose multi-stage reinforcement learning to emphasize finding ``appropriate stimulus" around the critical period. Inspired by humans' early cognitive-developmental stage, we use multi-stage guidance near the critical period, and demonstrate the appropriate shaping reward (stage-2 guidance) in terms of the AI agent's performance, efficiency, and stability.

</p>
</details>

<details><summary><b>Global Evaluation for Decision Tree Learning</b>
<a href="https://arxiv.org/abs/2208.04828">arxiv:2208.04828</a>
&#x1F4C8; 2 <br>
<p>Fabian Spaeh, Sven Kosub</p></summary>
<p>

**Abstract:** We transfer distances on clusterings to the building process of decision trees, and as a consequence extend the classical ID3 algorithm to perform modifications based on the global distance of the tree to the ground truth--instead of considering single leaves. Next, we evaluate this idea in comparison with the original version and discuss occurring problems, but also strengths of the global approach. On this basis, we finish by identifying other scenarios where global evaluations are worthwhile.

</p>
</details>

<details><summary><b>Generalized Reinforcement Learning: Experience Particles, Action Operator, Reinforcement Field, Memory Association, and Decision Concepts</b>
<a href="https://arxiv.org/abs/2208.04822">arxiv:2208.04822</a>
&#x1F4C8; 2 <br>
<p>Po-Hsiang Chiu, Manfred Huber</p></summary>
<p>

**Abstract:** Learning a control policy that involves time-varying and evolving system dynamics often poses a great challenge to mainstream reinforcement learning algorithms. In most standard methods, actions are often assumed to be a rigid, fixed set of choices that are sequentially applied to the state space in a predefined manner. Consequently, without resorting to substantial re-learning processes, the learned policy lacks the ability in adapting to variations in the action set and the action's "behavioral" outcomes. In addition, the standard action representation and the action-induced state transition mechanism inherently limit how reinforcement learning can be applied in complex, real-world applications primarily due to the intractability of the resulting large state space and the lack of facility to generalize the learned policy to the unknown part of the state space. This paper proposes a Bayesian-flavored generalized reinforcement learning framework by first establishing the notion of parametric action model to better cope with uncertainty and fluid action behaviors, followed by introducing the notion of reinforcement field as a physics-inspired construct established through "polarized experience particles" maintained in the learning agent's working memory. These particles effectively encode the dynamic learning experience that evolves over time in a self-organizing way. On top of the reinforcement field, we will further generalize the policy learning process to incorporate high-level decision concepts by considering the past memory as having an implicit graph structure, in which the past memory instances (or particles) are interconnected with similarity between decisions defined, and thereby, the "associative memory" principle can be applied to augment the learning agent's world model.

</p>
</details>

<details><summary><b>Integrating connection search in graph queries</b>
<a href="https://arxiv.org/abs/2208.04802">arxiv:2208.04802</a>
&#x1F4C8; 2 <br>
<p>Angelos Christos Anadiotis, Ioana Manolescu, Madhulika Mohanty</p></summary>
<p>

**Abstract:** Graph data management and querying has many practical applications. When graphs are very heterogeneous and/or users are unfamiliar with their structure, they may need to find how two or more groups of nodes are connected in a graph, even when users are not able to describe the connections. This is only partially supported by existing query languages, which allow searching for paths, but not for trees connecting three or more node groups. The latter is related to the NP-hard Group Steiner Tree problem, and has been previously considered for keyword search in databases. In this work, we formally show how to integrate connecting tree patterns (CTPs, in short) within a graph query language such as SPARQL or Cypher, leading to an Extended Query Language (or EQL, in short). We then study a set of algorithms for evaluating CTPs; we generalize prior keyword search work, most importantly by (i) considering bidirectional edge traversal and (ii) allowing users to select any score function for ranking CTP results. To cope with very large search spaces, we propose an efficient pruning technique and formally establish a large set of cases where our algorithm, MOLESP, is complete even with pruning. Our experiments validate the performance of our CTP and EQL evaluation algorithms on a large set of synthetic and real-world workloads.

</p>
</details>

<details><summary><b>Choose qualified instructor for university based on rule-based weighted expert system</b>
<a href="https://arxiv.org/abs/2208.04657">arxiv:2208.04657</a>
&#x1F4C8; 2 <br>
<p>Sana Karimian</p></summary>
<p>

**Abstract:** Near the entire university faculty directors must select some qualified professors for respected courses in each academic semester. In this sense, factors such as teaching experience, academic training, competition, etc. are considered. This work is usually done by experts, such as faculty directors, which is time consuming. Up to now, several semi-automatic systems have been proposed to assist heads. In this article, a fully automatic rule-based expert system is developed. The proposed expert system consists of three main stages. First, the knowledge of human experts is entered and designed as a decision tree. In the second step, an expert system is designed based on the provided rules of the generated decision tree. In the third step, an algorithm is proposed to weight the results of the tree based on the quality of the experts. To improve the performance of the expert system, a majority voting algorithm is developed as a post-process step to select the qualified trainer who satisfies the most expert decision tree for each course. The quality of the proposed expert system is evaluated using real data from Iranian universities. The calculated accuracy rate is 85.55, demonstrating the robustness and accuracy of the proposed system. The proposed system has little computational complexity compared to related efficient works. Also, simple implementation and transparent box are other features of the proposed system.

</p>
</details>

<details><summary><b>A Means-End Account of Explainable Artificial Intelligence</b>
<a href="https://arxiv.org/abs/2208.04638">arxiv:2208.04638</a>
&#x1F4C8; 2 <br>
<p>Oliver Buchholz</p></summary>
<p>

**Abstract:** Explainable artificial intelligence (XAI) seeks to produce explanations for those machine learning methods which are deemed opaque. However, there is considerable disagreement about what this means and how to achieve it. Authors disagree on what should be explained (topic), to whom something should be explained (stakeholder), how something should be explained (instrument), and why something should be explained (goal). In this paper, I employ insights from means-end epistemology to structure the field. According to means-end epistemology, different means ought to be rationally adopted to achieve different epistemic ends. Applied to XAI, different topics, stakeholders, and goals thus require different instruments. I call this the means-end account of XAI. The means-end account has a descriptive and a normative component: on the one hand, I show how the specific means-end relations give rise to a taxonomy of existing contributions to the field of XAI; on the other hand, I argue that the suitability of XAI methods can be assessed by analyzing whether they are prescribed by a given topic, stakeholder, and goal.

</p>
</details>

<details><summary><b>EfficientNet for Brain-Lesion classification</b>
<a href="https://arxiv.org/abs/2208.04616">arxiv:2208.04616</a>
&#x1F4C8; 2 <br>
<p>Quoc-Huy Trinh, Trong-Hieu Nguyen Mau, Radmir Zosimov, Minh-Van Nguyen</p></summary>
<p>

**Abstract:** In the development of technology, there are increasing cases of brain disease, there are more treatments proposed and achieved a positive result. However, with Brain-Lesion, the early diagnoses can improve the possibility for successful treatment and can help patients recuperate better. From this reason, Brain-Lesion is one of the controversial topics in medical images analysis nowadays. With the improvement of the architecture, there is a variety of methods that are proposed and achieve competitive scores. In this paper, we proposed a technique that uses efficient-net for 3D images, especially the Efficient-net B0 for Brain-Lesion classification task solution, and achieve the competitive score. Moreover, we also proposed the method to use Multiscale-EfficientNet to classify the slices of the MRI data

</p>
</details>

<details><summary><b>Using Sentence Embeddings and Semantic Similarity for Seeking Consensus when Assessing Trustworthy AI</b>
<a href="https://arxiv.org/abs/2208.04608">arxiv:2208.04608</a>
&#x1F4C8; 2 <br>
<p>Dennis Vetter, Jesmin Jahan Tithi, Magnus Westerlund, Roberto V. Zicari, Gemma Roig</p></summary>
<p>

**Abstract:** Assessing the trustworthiness of artificial intelligence systems requires knowledge from many different disciplines. These disciplines do not necessarily share concepts between them and might use words with different meanings, or even use the same words differently. Additionally, experts from different disciplines might not be aware of specialized terms readily used in other disciplines. Therefore, a core challenge of the assessment process is to identify when experts from different disciplines talk about the same problem but use different terminologies. In other words, the problem is to group problem descriptions (a.k.a. issues) with the same semantic meaning but described using slightly different terminologies.
  In this work, we show how we employed recent advances in natural language processing, namely sentence embeddings and semantic textual similarity, to support this identification process and to bridge communication gaps in interdisciplinary teams of experts assessing the trustworthiness of an artificial intelligence system used in healthcare.

</p>
</details>

<details><summary><b>IDNP: Interest Dynamics Modeling using Generative Neural Processes for Sequential Recommendation</b>
<a href="https://arxiv.org/abs/2208.04600">arxiv:2208.04600</a>
&#x1F4C8; 2 <br>
<p>Jing Du, Zesheng Ye, Lina Yao, Bin Guo, Zhiwen Yu</p></summary>
<p>

**Abstract:** Recent sequential recommendation models rely increasingly on consecutive short-term user-item interaction sequences to model user interests. These approaches have, however, raised concerns about both short- and long-term interests. (1) {\it short-term}: interaction sequences may not result from a monolithic interest, but rather from several intertwined interests, even within a short period of time, resulting in their failures to model skip behaviors; (2) {\it long-term}: interaction sequences are primarily observed sparsely at discrete intervals, other than consecutively over the long run. This renders difficulty in inferring long-term interests, since only discrete interest representations can be derived, without taking into account interest dynamics across sequences. In this study, we address these concerns by learning (1) multi-scale representations of short-term interests; and (2) dynamics-aware representations of long-term interests. To this end, we present an \textbf{I}nterest \textbf{D}ynamics modeling framework using generative \textbf{N}eural \textbf{P}rocesses, coined IDNP, to model user interests from a functional perspective. IDNP learns a global interest function family to define each user's long-term interest as a function instantiation, manifesting interest dynamics through function continuity. Specifically, IDNP first encodes each user's short-term interactions into multi-scale representations, which are then summarized as user context. By combining latent global interest with user context, IDNP then reconstructs long-term user interest functions and predicts interactions at upcoming query timestep. Moreover, IDNP can model such interest functions even when interaction sequences are limited and non-consecutive. Extensive experiments on four real-world datasets demonstrate that our model outperforms state-of-the-arts on various evaluation metrics.

</p>
</details>

<details><summary><b>Stronger Privacy Amplification by Shuffling for Rényi and Approximate Differential Privacy</b>
<a href="https://arxiv.org/abs/2208.04591">arxiv:2208.04591</a>
&#x1F4C8; 2 <br>
<p>Vitaly Feldman, Audra McMillan, Kunal Talwar</p></summary>
<p>

**Abstract:** The shuffle model of differential privacy has gained significant interest as an intermediate trust model between the standard local and central models [EFMRTT19; CSUZZ19]. A key result in this model is that randomly shuffling locally randomized data amplifies differential privacy guarantees. Such amplification implies substantially stronger privacy guarantees for systems in which data is contributed anonymously [BEMMRLRKTS17].
  In this work, we improve the state of the art privacy amplification by shuffling results both theoretically and numerically. Our first contribution is the first asymptotically optimal analysis of the Rényi differential privacy parameters for the shuffled outputs of LDP randomizers. Our second contribution is a new analysis of privacy amplification by shuffling. This analysis improves on the techniques of [FMT20] and leads to tighter numerical bounds in all parameter settings.

</p>
</details>

<details><summary><b>PEPPER: Empowering User-Centric Recommender Systems over Gossip Learning</b>
<a href="https://arxiv.org/abs/2208.05320">arxiv:2208.05320</a>
&#x1F4C8; 1 <br>
<p>Yacine Belal, Aurélien Bellet, Sonia Ben Mokhtar, Vlad Nitu</p></summary>
<p>

**Abstract:** Recommender systems are proving to be an invaluable tool for extracting user-relevant content helping users in their daily activities (e.g., finding relevant places to visit, content to consume, items to purchase). However, to be effective, these systems need to collect and analyze large volumes of personal data (e.g., location check-ins, movie ratings, click rates .. etc.), which exposes users to numerous privacy threats. In this context, recommender systems based on Federated Learning (FL) appear to be a promising solution for enforcing privacy as they compute accurate recommendations while keeping personal data on the users' devices. However, FL, and therefore FL-based recommender systems, rely on a central server that can experience scalability issues besides being vulnerable to attacks. To remedy this, we propose PEPPER, a decentralized recommender system based on gossip learning principles. In PEPPER, users gossip model updates and aggregate them asynchronously. At the heart of PEPPER reside two key components: a personalized peer-sampling protocol that keeps in the neighborhood of each node, a proportion of nodes that have similar interests to the former and a simple yet effective model aggregation function that builds a model that is better suited to each user. Through experiments on three real datasets implementing two use cases: a location check-in recommendation and a movie recommendation, we demonstrate that our solution converges up to 42% faster than with other decentralized solutions providing up to 9% improvement on average performance metric such as hit ratio and up to 21% improvement on long tail performance compared to decentralized competitors.

</p>
</details>

<details><summary><b>Research on restaurant recommendation using machine learning</b>
<a href="https://arxiv.org/abs/2208.05113">arxiv:2208.05113</a>
&#x1F4C8; 1 <br>
<p>Junan Pan, Zhihao Zhao</p></summary>
<p>

**Abstract:** A recommender system is a system that helps users filter irrelevant information and create user interest models based on their historical records. With the continuous development of Internet information, recommendation systems have received widespread attention in the industry. In this era of ubiquitous data and information, how to obtain and analyze these data has become the research topic of many people. In view of this situation, this paper makes some brief overviews of machine learning-related recommendation systems. By analyzing some technologies and ideas used by machine learning in recommender systems, let more people understand what is Big data and what is machine learning. The most important point is to let everyone understand the profound impact of machine learning on our daily life.

</p>
</details>

<details><summary><b>Ad Hoc Teamwork in the Presence of Adversaries</b>
<a href="https://arxiv.org/abs/2208.05071">arxiv:2208.05071</a>
&#x1F4C8; 1 <br>
<p>Ted Fujimoto, Samrat Chatterjee, Auroop Ganguly</p></summary>
<p>

**Abstract:** Advances in ad hoc teamwork have the potential to create agents that collaborate robustly in real-world applications. Agents deployed in the real world, however, are vulnerable to adversaries with the intent to subvert them. There has been little research in ad hoc teamwork that assumes the presence of adversaries. We explain the importance of extending ad hoc teamwork to include the presence of adversaries and clarify why this problem is difficult. We then propose some directions for new research opportunities in ad hoc teamwork that leads to more robust multi-agent cyber-physical infrastructure systems.

</p>
</details>

<details><summary><b>OL-DN: Online learning based dual-domain network for HEVC intra frame quality enhancement</b>
<a href="https://arxiv.org/abs/2208.04661">arxiv:2208.04661</a>
&#x1F4C8; 1 <br>
<p>Renwei Yang, Shuyuan Zhu, Xiaozhen Zheng, Bing Zeng</p></summary>
<p>

**Abstract:** Convolution neural network (CNN) based methods offer effective solutions for enhancing the quality of compressed image and video. However, these methods ignore using the raw data to enhance the quality. In this paper, we adopt the raw data in the quality enhancement for the HEVC intra-coded image by proposing an online learning-based method. When quality enhancement is demanded, we online train our proposed model at encoder side and then use the parameters to update the model of decoder side. This method not only improves model performance, but also makes one model adoptable to multiple coding scenarios. Besides, quantization error in discrete cosine transform (DCT) coefficients is the root cause of various HEVC compression artifacts. Thus, we combine frequency domain priors to assist image reconstruction. We design a DCT based convolution layer, to produce DCT coefficients that are suitable for CNN learning. Experimental results show that our proposed online learning based dual-domain network (OL-DN) has achieved superior performance, compared with the state-of-the-art methods.

</p>
</details>

<details><summary><b>Adaptive Zeroth-Order Optimisation of Nonconvex Composite Objectives</b>
<a href="https://arxiv.org/abs/2208.04579">arxiv:2208.04579</a>
&#x1F4C8; 1 <br>
<p>Weijia Shao, Sahin Albayrak</p></summary>
<p>

**Abstract:** In this paper, we propose and analyze algorithms for zeroth-order optimization of non-convex composite objectives, focusing on reducing the complexity dependence on dimensionality. This is achieved by exploiting the low dimensional structure of the decision set using the stochastic mirror descent method with an entropy alike function, which performs gradient descent in the space equipped with the maximum norm. To improve the gradient estimation, we replace the classic Gaussian smoothing method with a sampling method based on the Rademacher distribution and show that the mini-batch method copes with the non-Euclidean geometry. To avoid tuning hyperparameters, we analyze the adaptive stepsizes for the general stochastic mirror descent and show that the adaptive version of the proposed algorithm converges without requiring prior knowledge about the problem.

</p>
</details>

<details><summary><b>Disentangled Representation Learning Using ($β$-)VAE and GAN</b>
<a href="https://arxiv.org/abs/2208.04549">arxiv:2208.04549</a>
&#x1F4C8; 1 <br>
<p>Mohammad Haghir Ebrahimabadi</p></summary>
<p>

**Abstract:** Given a dataset of images containing different objects with different features such as shape, size, rotation, and x-y position; and a Variational Autoencoder (VAE); creating a disentangled encoding of these features in the hidden space vector of the VAE was the task of interest in this paper. The dSprite dataset provided the desired features for the required experiments in this research. After training the VAE combined with a Generative Adversarial Network (GAN), each dimension of the hidden vector was disrupted to explore the disentanglement in each dimension. Note that the GAN was used to improve the quality of output image reconstruction.

</p>
</details>

<details><summary><b>Inconsistencies in Measuring Student Engagement in Virtual Learning -- A Critical Review</b>
<a href="https://arxiv.org/abs/2208.04548">arxiv:2208.04548</a>
&#x1F4C8; 1 <br>
<p>Shehroz S. Khan, Ali Abedi, Tracey Colella</p></summary>
<p>

**Abstract:** In recent years, virtual learning has emerged as an alternative to traditional classroom teaching. The engagement of students in virtual learning can have a major impact on meeting learning objectives and program dropout risks. There exist many measurement instruments specifically geared to Student Engagement (SE) in virtual learning environments. In this critical review, we analyze these works and highlight inconsistencies in terms of differing engagement definitions and measurement scales. This diversity among existing researchers could potentially be problematic in comparing different annotations and building generalizable predictive models. We further discuss issues in terms of engagement annotations and design flaws. We analyze the existing SE annotation scales based on our defined seven dimensions of engagement annotation, including sources, data modalities used for annotation, the time when the annotation takes place, the timesteps in which the annotation takes place, level of abstraction, combination, and quantification. One of the surprising findings was that very few of the reviewed datasets on SE measurement used existing psychometrically validated engagement scales in their annotation. Lastly, we discuss some other scales in settings other than virtual learning that have the potential to be used in measuring SE in virtual learning.

</p>
</details>

<details><summary><b>PECCO: A Profit and Cost-oriented Computation Offloading Scheme in Edge-Cloud Environment with Improved Moth-flame Optimisation</b>
<a href="https://arxiv.org/abs/2208.05074">arxiv:2208.05074</a>
&#x1F4C8; 0 <br>
<p>Jiashu Wu, Hao Dai, Yang Wang, Shigen Shen, Chengzhong Xu</p></summary>
<p>

**Abstract:** With the fast growing quantity of data generated by smart devices and the exponential surge of processing demand in the Internet of Things (IoT) era, the resource-rich cloud centres have been utilised to tackle these challenges. To relieve the burden on cloud centres, edge-cloud computation offloading becomes a promising solution since shortening the proximity between the data source and the computation by offloading computation tasks from the cloud to edge devices can improve performance and Quality of Service (QoS). Several optimisation models of edge-cloud computation offloading have been proposed that take computation costs and heterogeneous communication costs into account. However, several important factors are not jointly considered, such as heterogeneities of tasks, load balancing among nodes and the profit yielded by computation tasks, which lead to the profit and cost-oriented computation offloading optimisation model PECCO proposed in this paper. Considering that the model is hard in nature and the optimisation objective is not differentiable, we propose an improved Moth-flame optimiser PECCO-MFI which addresses some deficiencies of the original Moth-flame Optimiser and integrate it under the edge-cloud environment. Comprehensive experiments are conducted to verify the superior performance of the proposed method when optimising the proposed task offloading model under the edge-cloud environment.

</p>
</details>

<details><summary><b>Boundary Distance Loss for Intra-/Extra-meatal Segmentation of Vestibular Schwannoma</b>
<a href="https://arxiv.org/abs/2208.04680">arxiv:2208.04680</a>
&#x1F4C8; 0 <br>
<p>Navodini Wijethilake, Aaron Kujawa, Reuben Dorent, Muhammad Asad, Anna Oviedova, Tom Vercauteren, Jonathan Shapey</p></summary>
<p>

**Abstract:** Vestibular Schwannoma (VS) typically grows from the inner ear to the brain. It can be separated into two regions, intrameatal and extrameatal respectively corresponding to being inside or outside the inner ear canal. The growth of the extrameatal regions is a key factor that determines the disease management followed by the clinicians. In this work, a VS segmentation approach with subdivision into intra-/extra-meatal parts is presented. We annotated a dataset consisting of 227 T2 MRI instances, acquired longitudinally on 137 patients, excluding post-operative instances. We propose a staged approach, with the first stage performing the whole tumour segmentation and the second stage performing the intra-/extra-meatal segmentation using the T2 MRI along with the mask obtained from the first stage. To improve on the accuracy of the predicted meatal boundary, we introduce a task-specific loss which we call Boundary Distance Loss. The performance is evaluated in contrast to the direct intrameatal extrameatal segmentation task performance, i.e. the Baseline. Our proposed method, with the two-stage approach and the Boundary Distance Loss, achieved a Dice score of 0.8279+-0.2050 and 0.7744+-0.1352 for extrameatal and intrameatal regions respectively, significantly improving over the Baseline, which gave Dice score of 0.7939+-0.2325 and 0.7475+-0.1346 for the extrameatal and intrameatal regions respectively.

</p>
</details>

<details><summary><b>RDA: Reciprocal Distribution Alignment for Robust Semi-supervised Learning</b>
<a href="https://arxiv.org/abs/2208.04619">arxiv:2208.04619</a>
&#x1F4C8; 0 <br>
<p>Yue Duan, Lei Qi, Lei Wang, Luping Zhou, Yinghuan Shi</p></summary>
<p>

**Abstract:** In this work, we propose Reciprocal Distribution Alignment (RDA) to address semi-supervised learning (SSL), which is a hyperparameter-free framework that is independent of confidence threshold and works with both the matched (conventionally) and the mismatched class distributions. Distribution mismatch is an often overlooked but more general SSL scenario where the labeled and the unlabeled data do not fall into the identical class distribution. This may lead to the model not exploiting the labeled data reliably and drastically degrade the performance of SSL methods, which could not be rescued by the traditional distribution alignment. In RDA, we enforce a reciprocal alignment on the distributions of the predictions from two classifiers predicting pseudo-labels and complementary labels on the unlabeled data. These two distributions, carrying complementary information, could be utilized to regularize each other without any prior of class distribution. Moreover, we theoretically show that RDA maximizes the input-output mutual information. Our approach achieves promising performance in SSL under a variety of scenarios of mismatched distributions, as well as the conventional matched SSL setting. Our code is available at: https://github.com/NJUyued/RDA4RobustSSL.

</p>
</details>


{% endraw %}
Prev: [2022.08.08]({{ '/2022/08/08/2022.08.08.html' | relative_url }})  Next: [2022.08.10]({{ '/2022/08/10/2022.08.10.html' | relative_url }})