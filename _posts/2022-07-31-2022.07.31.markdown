Prev: [2022.07.30]({{ '/2022/07/30/2022.07.30.html' | relative_url }})  Next: [2022.08.01]({{ '/2022/08/01/2022.08.01.html' | relative_url }})
{% raw %}
## Summary for 2022-07-31, created on 2022-08-10


<details><summary><b>COCOA: Cross Modality Contrastive Learning for Sensor Data</b>
<a href="https://arxiv.org/abs/2208.00467">arxiv:2208.00467</a>
&#x1F4C8; 12 <br>
<p>Shohreh Deldari, Hao Xue, Aaqib Saeed, Daniel V. Smith, Flora D. Salim</p></summary>
<p>

**Abstract:** Self-Supervised Learning (SSL) is a new paradigm for learning discriminative representations without labelled data and has reached comparable or even state-of-the-art results in comparison to supervised counterparts. Contrastive Learning (CL) is one of the most well-known approaches in SSL that attempts to learn general, informative representations of data. CL methods have been mostly developed for applications in computer vision and natural language processing where only a single sensor modality is used. A majority of pervasive computing applications, however, exploit data from a range of different sensor modalities. While existing CL methods are limited to learning from one or two data sources, we propose COCOA (Cross mOdality COntrastive leArning), a self-supervised model that employs a novel objective function to learn quality representations from multisensor data by computing the cross-correlation between different data modalities and minimizing the similarity between irrelevant instances. We evaluate the effectiveness of COCOA against eight recently introduced state-of-the-art self-supervised models, and two supervised baselines across five public datasets. We show that COCOA achieves superior classification performance to all other approaches. Also, COCOA is far more label-efficient than the other baselines including the fully supervised model using only one-tenth of available labelled data.

</p>
</details>

<details><summary><b>Beyond kNN: Adaptive, Sparse Neighborhood Graphs via Optimal Transport</b>
<a href="https://arxiv.org/abs/2208.00604">arxiv:2208.00604</a>
&#x1F4C8; 10 <br>
<p>Tetsuya Matsumoto, Stephen Zhang, Geoffrey Schiebinger</p></summary>
<p>

**Abstract:** Nearest neighbour graphs are widely used to capture the geometry or topology of a dataset. One of the most common strategies to construct such a graph is based on selecting a fixed number k of nearest neighbours (kNN) for each point. However, the kNN heuristic may become inappropriate when sampling density or noise level varies across datasets. Strategies that try to get around this typically introduce additional parameters that need to be tuned. We propose a simple approach to construct an adaptive neighbourhood graph from a single parameter, based on quadratically regularised optimal transport. Our numerical experiments show that graphs constructed in this manner perform favourably in unsupervised and semi-supervised learning applications.

</p>
</details>

<details><summary><b>Robotic Dough Shaping</b>
<a href="https://arxiv.org/abs/2208.00386">arxiv:2208.00386</a>
&#x1F4C8; 10 <br>
<p>Jan Ondras, Di Ni, Xi Deng, Zeqi Gu, Henry Zheng</p></summary>
<p>

**Abstract:** We address the problem of shaping a piece of dough-like deformable material into a 2D target shape presented upfront. We use a 6 degree-of-freedom WidowX-250 Robot Arm equipped with a rolling pin and information collected from an RGB-D camera and a tactile sensor. We present and compare several control policies, including a dough shrinking action, in extensive experiments across three kinds of deformable materials and across three target dough shape sizes, achieving the intersection over union (IoU) of 0.90. Our results show that: i) rolling dough from the highest dough point is more efficient than from the 2D/3D dough centroid; ii) it might be better to stop the roll movement at the current dough boundary as opposed to the target shape outline; iii) the shrink action might be beneficial only if properly tuned with respect to the exapand action; and iv) the Play-Doh material is easier to shape to a target shape as compared to Plasticine or Kinetic sand. Video demonstrations of our work are available at https://youtu.be/ZzLMxuITdt4

</p>
</details>

<details><summary><b>One Object at a Time: Accurate and Robust Structure From Motion for Robots</b>
<a href="https://arxiv.org/abs/2208.00487">arxiv:2208.00487</a>
&#x1F4C8; 9 <br>
<p>Aravind Battaje, Oliver Brock</p></summary>
<p>

**Abstract:** A gaze-fixating robot perceives distance to the fixated object and relative positions of surrounding objects immediately, accurately, and robustly. We show how fixation, which is the act of looking at one object while moving, exploits regularities in the geometry of 3D space to obtain this information. These regularities introduce rotation-translation couplings that are not commonly used in structure from motion. To validate, we use a Franka Emika Robot with an RGB camera. We a) find that error in distance estimate is less than 5 mm at a distance of 15 cm, and b) show how relative position can be used to find obstacles under challenging scenarios. We combine accurate distance estimates and obstacle information into a reactive robot behavior that is able to pick up objects of unknown size, while impeded by unforeseen obstacles.

</p>
</details>

<details><summary><b>Scrutinizing Shipment Records To Thwart Illegal Timber Trade</b>
<a href="https://arxiv.org/abs/2208.00493">arxiv:2208.00493</a>
&#x1F4C8; 7 <br>
<p>Debanjan Datta, Sathappan Muthiah, John Simeone, Amelia Meadows, Naren Ramakrishnan</p></summary>
<p>

**Abstract:** Timber and forest products made from wood, like furniture, are valuable commodities, and like the global trade of many highly-valued natural resources, face challenges of corruption, fraud, and illegal harvesting. These grey and black market activities in the wood and forest products sector are not limited to the countries where the wood was harvested, but extend throughout the global supply chain and have been tied to illicit financial flows, like trade-based money laundering, document fraud, species mislabeling, and other illegal activities. The task of finding such fraudulent activities using trade data, in the absence of ground truth, can be modelled as an unsupervised anomaly detection problem. However existing approaches suffer from certain shortcomings in their applicability towards large scale trade data. Trade data is heterogeneous, with both categorical and numerical attributes in a tabular format. The overall challenge lies in the complexity, volume and velocity of data, with large number of entities and lack of ground truth labels. To mitigate these, we propose a novel unsupervised anomaly detection -- Contrastive Learning based Heterogeneous Anomaly Detection (CHAD) that is generally applicable for large-scale heterogeneous tabular data. We demonstrate our model CHAD performs favorably against multiple comparable baselines for public benchmark datasets, and outperforms them in the case of trade data. More importantly we demonstrate our approach reduces assumptions and efforts required hyperparameter tuning, which is a key challenging aspect in an unsupervised training paradigm. Specifically, our overarching objective pertains to detecting suspicious timber shipments and patterns using Bill of Lading trade record data. Detecting anomalous transactions in shipment records can enable further investigation by government agencies and supply chain constituents.

</p>
</details>

<details><summary><b>Neural Knowledge Bank for Pretrained Transformers</b>
<a href="https://arxiv.org/abs/2208.00399">arxiv:2208.00399</a>
&#x1F4C8; 7 <br>
<p>Damai Dai, Wenbin Jiang, Qingxiu Dong, Yajuan Lyu, Qiaoqiao She, Zhifang Sui</p></summary>
<p>

**Abstract:** The ability of pretrained Transformers to remember factual knowledge is essential for knowledge-intense downstream tasks such as closed-book question answering. Existing work has shown that pretrained Transformers can recall or leverage factual knowledge that appears in the pretraining corpus to some degree. However, due to the limit of the model capacity, the ability of pretrained models to remember factual knowledge is also limited. Dai et al. (2022) find that the Feed-Forward Networks (FFNs) in pretrained Transformers store factual knowledge in a memory-like manner. Inspired by this finding, we propose a Neural Knowledge Bank (NKB) to store extra factual knowledge for pretrained Transformers. To be specific, we also regard FFNs as key-value memories, and extend them with additional memory slots. During knowledge injection, we fix the original model and inject factual knowledge into the extended memory slots, so there will be no catastrophic forgetting for the pretrained model. In addition, the view of FFNs as key-value memories makes the NKB highly interpretable. We use three closed-book question answering datasets to show our strong ability to store extra factual knowledge. Also, we prove that the NKB will not degrade the general language generation ability of pretrained models through two representative generation tasks, summarization and machine translation. Further, we thoroughly analyze the NKB to reveal its working mechanism and present the meaning of its keys and values in a human-readable way. On top of it, we perform a preliminary attempt to directly update the factual knowledge in the NKB without any additional training.

</p>
</details>

<details><summary><b>Cross-Modal Alignment Learning of Vision-Language Conceptual Systems</b>
<a href="https://arxiv.org/abs/2208.01744">arxiv:2208.01744</a>
&#x1F4C8; 6 <br>
<p>Taehyeong Kim, Hyeonseop Song, Byoung-Tak Zhang</p></summary>
<p>

**Abstract:** Human infants learn the names of objects and develop their own conceptual systems without explicit supervision. In this study, we propose methods for learning aligned vision-language conceptual systems inspired by infants' word learning mechanisms. The proposed model learns the associations of visual objects and words online and gradually constructs cross-modal relational graph networks. Additionally, we also propose an aligned cross-modal representation learning method that learns semantic representations of visual objects and words in a self-supervised manner based on the cross-modal relational graph networks. It allows entities of different modalities with conceptually the same meaning to have similar semantic representation vectors. We quantitatively and qualitatively evaluate our method, including object-to-word mapping and zero-shot learning tasks, showing that the proposed model significantly outperforms the baselines and that each conceptual system is topologically aligned.

</p>
</details>

<details><summary><b>Is current research on adversarial robustness addressing the right problem?</b>
<a href="https://arxiv.org/abs/2208.00539">arxiv:2208.00539</a>
&#x1F4C8; 6 <br>
<p>Ali Borji</p></summary>
<p>

**Abstract:** Short answer: Yes, Long answer: No! Indeed, research on adversarial robustness has led to invaluable insights helping us understand and explore different aspects of the problem. Many attacks and defenses have been proposed over the last couple of years. The problem, however, remains largely unsolved and poorly understood. Here, I argue that the current formulation of the problem serves short term goals, and needs to be revised for us to achieve bigger gains. Specifically, the bound on perturbation has created a somewhat contrived setting and needs to be relaxed. This has misled us to focus on model classes that are not expressive enough to begin with. Instead, inspired by human vision and the fact that we rely more on robust features such as shape, vertices, and foreground objects than non-robust features such as texture, efforts should be steered towards looking for significantly different classes of models. Maybe instead of narrowing down on imperceptible adversarial perturbations, we should attack a more general problem which is finding architectures that are simultaneously robust to perceptible perturbations, geometric transformations (e.g. rotation, scaling), image distortions (lighting, blur), and more (e.g. occlusion, shadow). Only then we may be able to solve the problem of adversarial vulnerability.

</p>
</details>

<details><summary><b>Using Chatbots to Teach Languages</b>
<a href="https://arxiv.org/abs/2208.00376">arxiv:2208.00376</a>
&#x1F4C8; 6 <br>
<p>Yu Li, Chun-Yen Chen, Dian Yu, Sam Davidson, Ryan Hou, Xun Yuan, Yinghua Tan, Derek Pham, Zhou Yu</p></summary>
<p>

**Abstract:** This paper reports on progress towards building an online language learning tool to provide learners with conversational experience by using dialog systems as conversation practice partners. Our system can adapt to users' language proficiency on the fly. We also provide automatic grammar error feedback to help users learn from their mistakes. According to our first adopters, our system is entertaining and useful. Furthermore, we will provide the learning technology community a large-scale conversation dataset on language learning and grammar correction. Our next step is to make our system more adaptive to user profile information by using reinforcement learning algorithms.

</p>
</details>

<details><summary><b>Assessing The Performance of YOLOv5 Algorithm for Detecting Volunteer Cotton Plants in Corn Fields at Three Different Growth Stages</b>
<a href="https://arxiv.org/abs/2208.00519">arxiv:2208.00519</a>
&#x1F4C8; 5 <br>
<p>Pappu Kumar Yadav, J. Alex Thomasson, Stephen W. Searcy, Robert G. Hardin, Ulisses Braga-Neto, Sorin C. Popescu, Daniel E. Martin, Roberto Rodriguez, Karem Meza, Juan Enciso, Jorge Solorzano Diaz, Tianyi Wang</p></summary>
<p>

**Abstract:** The boll weevil (Anthonomus grandis L.) is a serious pest that primarily feeds on cotton plants. In places like Lower Rio Grande Valley of Texas, due to sub-tropical climatic conditions, cotton plants can grow year-round and therefore the left-over seeds from the previous season during harvest can continue to grow in the middle of rotation crops like corn (Zea mays L.) and sorghum (Sorghum bicolor L.). These feral or volunteer cotton (VC) plants when reach the pinhead squaring phase (5-6 leaf stage) can act as hosts for the boll weevil pest. The Texas Boll Weevil Eradication Program (TBWEP) employs people to locate and eliminate VC plants growing by the side of roads or fields with rotation crops but the ones growing in the middle of fields remain undetected. In this paper, we demonstrate the application of computer vision (CV) algorithm based on You Only Look Once version 5 (YOLOv5) for detecting VC plants growing in the middle of corn fields at three different growth stages (V3, V6, and VT) using unmanned aircraft systems (UAS) remote sensing imagery. All the four variants of YOLOv5 (s, m, l, and x) were used and their performances were compared based on classification accuracy, mean average precision (mAP), and F1-score. It was found that YOLOv5s could detect VC plants with a maximum classification accuracy of 98% and mAP of 96.3 % at the V6 stage of corn while YOLOv5s and YOLOv5m resulted in the lowest classification accuracy of 85% and YOLOv5m and YOLOv5l had the least mAP of 86.5% at the VT stage on images of size 416 x 416 pixels. The developed CV algorithm has the potential to effectively detect and locate VC plants growing in the middle of corn fields as well as expedite the management aspects of TBWEP.

</p>
</details>

<details><summary><b>Voice Analysis for Stress Detection and Application in Virtual Reality to Improve Public Speaking in Real-time: A Review</b>
<a href="https://arxiv.org/abs/2208.01041">arxiv:2208.01041</a>
&#x1F4C8; 4 <br>
<p> Arushi, Roberto Dillon, Ai Ni Teoh, Denise Dillon</p></summary>
<p>

**Abstract:** Stress during public speaking is common and adversely affects performance and self-confidence. Extensive research has been carried out to develop various models to recognize emotional states. However, minimal research has been conducted to detect stress during public speaking in real time using voice analysis. In this context, the current review showed that the application of algorithms was not properly explored and helped identify the main obstacles in creating a suitable testing environment while accounting for current complexities and limitations. In this paper, we present our main idea and propose a stress detection computational algorithmic model that could be integrated into a Virtual Reality (VR) application to create an intelligent virtual audience for improving public speaking skills. The developed model, when integrated with VR, will be able to detect excessive stress in real time by analysing voice features correlated to physiological parameters indicative of stress and help users gradually control excessive stress and improve public speaking performance

</p>
</details>

<details><summary><b>Quantum Adaptive Fourier Features for Neural Density Estimation</b>
<a href="https://arxiv.org/abs/2208.00564">arxiv:2208.00564</a>
&#x1F4C8; 4 <br>
<p>Joseph A. Gallego, Fabio A. González</p></summary>
<p>

**Abstract:** Density estimation is a fundamental task in statistics and machine learning applications. Kernel density estimation is a powerful tool for non-parametric density estimation in low dimensions; however, its performance is poor in higher dimensions. Moreover, its prediction complexity scale linearly with more training data points. This paper presents a method for neural density estimation that can be seen as a type of kernel density estimation, but without the high prediction computational complexity. The method is based on density matrices, a formalism used in quantum mechanics, and adaptive Fourier features. The method can be trained without optimization, but it could be also integrated with deep learning architectures and trained using gradient descent. Thus, it could be seen as a form of neural density estimation method. The method was evaluated in different synthetic and real datasets, and its performance compared against state-of-the-art neural density estimation methods, obtaining competitive results.

</p>
</details>

<details><summary><b>Unifying Approaches in Data Subset Selection via Fisher Information and Information-Theoretic Quantities</b>
<a href="https://arxiv.org/abs/2208.00549">arxiv:2208.00549</a>
&#x1F4C8; 4 <br>
<p>Andreas Kirsch, Yarin Gal</p></summary>
<p>

**Abstract:** The mutual information between predictions and model parameters -- also referred to as expected information gain or BALD in machine learning -- measures informativeness. It is a popular acquisition function in Bayesian active learning and Bayesian optimal experiment design. In data subset selection, i.e. active learning and active sampling, several recent works use Fisher information, Hessians, similarity matrices based on the gradients, or simply the gradient lengths to compute the acquisition scores that guide sample selection. Are these different approaches connected, and if so how? In this paper, we revisit the Fisher information and use it to show how several otherwise disparate methods are connected as approximations of information-theoretic quantities.

</p>
</details>

<details><summary><b>Out-of-Distribution Detection with Semantic Mismatch under Masking</b>
<a href="https://arxiv.org/abs/2208.00446">arxiv:2208.00446</a>
&#x1F4C8; 4 <br>
<p>Yijun Yang, Ruiyuan Gao, Qiang Xu</p></summary>
<p>

**Abstract:** This paper proposes a novel out-of-distribution (OOD) detection framework named MoodCat for image classifiers. MoodCat masks a random portion of the input image and uses a generative model to synthesize the masked image to a new image conditioned on the classification result. It then calculates the semantic difference between the original image and the synthesized one for OOD detection. Compared to existing solutions, MoodCat naturally learns the semantic information of the in-distribution data with the proposed mask and conditional synthesis strategy, which is critical to identifying OODs. Experimental results demonstrate that MoodCat outperforms state-of-the-art OOD detection solutions by a large margin.

</p>
</details>

<details><summary><b>Speckle2Speckle: Unsupervised Learning of Ultrasound Speckle Filtering Without Clean Data</b>
<a href="https://arxiv.org/abs/2208.00402">arxiv:2208.00402</a>
&#x1F4C8; 4 <br>
<p>Rüdiger Göbl, Christoph Hennersperger, Nassir Navab</p></summary>
<p>

**Abstract:** In ultrasound imaging the appearance of homogeneous regions of tissue is subject to speckle, which for certain applications can make the detection of tissue irregularities difficult. To cope with this, it is common practice to apply speckle reduction filters to the images. Most conventional filtering techniques are fairly hand-crafted and often need to be finely tuned to the present hardware, imaging scheme and application. Learning based techniques on the other hand suffer from the need for a target image for training (in case of fully supervised techniques) or require narrow, complex physics-based models of the speckle appearance that might not apply in all cases. With this work we propose a deep-learning based method for speckle removal without these limitations. To enable this, we make use of realistic ultrasound simulation techniques that allow for instantiation of several independent speckle realizations that represent the exact same tissue, thus allowing for the application of image reconstruction techniques that work with pairs of differently corrupted data. Compared to two other state-of-the-art approaches (non-local means and the Optimized Bayesian non-local means filter) our method performs favorably in qualitative comparisons and quantitative evaluation, despite being trained on simulations alone, and is several orders of magnitude faster.

</p>
</details>

<details><summary><b>Neuro-Symbolic Learning: Principles and Applications in Ophthalmology</b>
<a href="https://arxiv.org/abs/2208.00374">arxiv:2208.00374</a>
&#x1F4C8; 4 <br>
<p>Muhammad Hassan, Haifei Guan, Aikaterini Melliou, Yuqi Wang, Qianhui Sun, Sen Zeng, Wen Liang, Yiwei Zhang, Ziheng Zhang, Qiuyue Hu, Yang Liu, Shunkai Shi, Lin An, Shuyue Ma, Ijaz Gul, Muhammad Akmal Rahee, Zhou You, Canyang Zhang, Vijay Kumar Pandey, Yuxing Han, Yongbing Zhang, Ming Xu, Qiming Huang, Jiefu Tan, Qi Xing</p></summary>
<p>

**Abstract:** Neural networks have been rapidly expanding in recent years, with novel strategies and applications. However, challenges such as interpretability, explainability, robustness, safety, trust, and sensibility remain unsolved in neural network technologies, despite the fact that they will unavoidably be addressed for critical applications. Attempts have been made to overcome the challenges in neural network computing by representing and embedding domain knowledge in terms of symbolic representations. Thus, the neuro-symbolic learning (NeSyL) notion emerged, which incorporates aspects of symbolic representation and bringing common sense into neural networks (NeSyL). In domains where interpretability, reasoning, and explainability are crucial, such as video and image captioning, question-answering and reasoning, health informatics, and genomics, NeSyL has shown promising outcomes. This review presents a comprehensive survey on the state-of-the-art NeSyL approaches, their principles, advances in machine and deep learning algorithms, applications such as opthalmology, and most importantly, future perspectives of this emerging field.

</p>
</details>

<details><summary><b>Breast Cancer Classification Based on Histopathological Images Using a Deep Learning Capsule Network</b>
<a href="https://arxiv.org/abs/2208.00594">arxiv:2208.00594</a>
&#x1F4C8; 3 <br>
<p>Hayder A. Khikani, Naira Elazab, Ahmed Elgarayhi, Mohammed Elmogy, Mohammed Sallah</p></summary>
<p>

**Abstract:** Breast cancer is one of the most serious types of cancer that can occur in women. The automatic diagnosis of breast cancer by analyzing histological images (HIs) is important for patients and their prognosis. The classification of HIs provides clinicians with an accurate understanding of diseases and allows them to treat patients more efficiently. Deep learning (DL) approaches have been successfully employed in a variety of fields, particularly medical imaging, due to their capacity to extract features automatically. This study aims to classify different types of breast cancer using HIs. In this research, we present an enhanced capsule network that extracts multi-scale features using the Res2Net block and four additional convolutional layers. Furthermore, the proposed method has fewer parameters due to using small convolutional kernels and the Res2Net block. As a result, the new method outperforms the old ones since it automatically learns the best possible features. The testing results show that the model outperformed the previous DL methods.

</p>
</details>

<details><summary><b>An Enhanced Deep Learning Technique for Prostate Cancer Identification Based on MRI Scans</b>
<a href="https://arxiv.org/abs/2208.00583">arxiv:2208.00583</a>
&#x1F4C8; 3 <br>
<p>Hussein Hashem, Yasmin Alsakar, Ahmed Elgarayhi, Mohammed Elmogy, Mohammed Sallah</p></summary>
<p>

**Abstract:** Prostate cancer is the most dangerous cancer diagnosed in men worldwide. Prostate diagnosis has been affected by many factors, such as lesion complexity, observer visibility, and variability. Many techniques based on Magnetic Resonance Imaging (MRI) have been used for prostate cancer identification and classification in the last few decades. Developing these techniques is crucial and has a great medical effect because they improve the treatment benefits and the chance of patients' survival. A new technique that depends on MRI has been proposed to improve the diagnosis. This technique consists of two stages. First, the MRI images have been preprocessed to make the medical image more suitable for the detection step. Second, prostate cancer identification has been performed based on a pre-trained deep learning model, InceptionResNetV2, that has many advantages and achieves effective results. In this paper, the InceptionResNetV2 deep learning model used for this purpose has average accuracy equals to 89.20%, and the area under the curve (AUC) equals to 93.6%. The experimental results of this proposed new deep learning technique represent promising and effective results compared to other previous techniques.

</p>
</details>

<details><summary><b>CloudAttention: Efficient Multi-Scale Attention Scheme For 3D Point Cloud Learning</b>
<a href="https://arxiv.org/abs/2208.00524">arxiv:2208.00524</a>
&#x1F4C8; 3 <br>
<p>Mahdi Saleh, Yige Wang, Nassir Navab, Benjamin Busam, Federico Tombari</p></summary>
<p>

**Abstract:** Processing 3D data efficiently has always been a challenge. Spatial operations on large-scale point clouds, stored as sparse data, require extra cost. Attracted by the success of transformers, researchers are using multi-head attention for vision tasks. However, attention calculations in transformers come with quadratic complexity in the number of inputs and miss spatial intuition on sets like point clouds. We redesign set transformers in this work and incorporate them into a hierarchical framework for shape classification and part and scene segmentation. We propose our local attention unit, which captures features in a spatial neighborhood. We also compute efficient and dynamic global cross attentions by leveraging sampling and grouping at each iteration. Finally, to mitigate the non-heterogeneity of point clouds, we propose an efficient Multi-Scale Tokenization (MST), which extracts scale-invariant tokens for attention operations. The proposed hierarchical model achieves state-of-the-art shape classification in mean accuracy and yields results on par with the previous segmentation methods while requiring significantly fewer computations. Our proposed architecture predicts segmentation labels with around half the latency and parameter count of the previous most efficient method with comparable performance. The code is available at https://github.com/YigeWang-WHU/CloudAttention.

</p>
</details>

<details><summary><b>Deep Active Learning with Budget Annotation</b>
<a href="https://arxiv.org/abs/2208.00508">arxiv:2208.00508</a>
&#x1F4C8; 3 <br>
<p>Kinyua Gikunda</p></summary>
<p>

**Abstract:** Digital data collected over the decades and data currently being produced with use of information technology is vastly the unlabeled data or data without description. The unlabeled data is relatively easy to acquire but expensive to label even with use of domain experts. Most of the recent works focus on use of active learning with uncertainty metrics measure to address this problem. Although most uncertainty selection strategies are very effective, they fail to take informativeness of the unlabeled instances into account and are prone to querying outliers. In order to address these challenges we propose an hybrid approach of computing both the uncertainty and informativeness of an instance, then automaticaly label the computed instances using budget annotator. To reduce the annotation cost, we employ the state-of-the-art pre-trained models in order to avoid querying information already contained in those models. Our extensive experiments on different sets of datasets demonstrate the efficacy of the proposed approach.

</p>
</details>

<details><summary><b>INSightR-Net: Interpretable Neural Network for Regression using Similarity-based Comparisons to Prototypical Examples</b>
<a href="https://arxiv.org/abs/2208.00457">arxiv:2208.00457</a>
&#x1F4C8; 3 <br>
<p>Linde S. Hesse, Ana I. L. Namburete</p></summary>
<p>

**Abstract:** Convolutional neural networks (CNNs) have shown exceptional performance for a range of medical imaging tasks. However, conventional CNNs are not able to explain their reasoning process, therefore limiting their adoption in clinical practice. In this work, we propose an inherently interpretable CNN for regression using similarity-based comparisons (INSightR-Net) and demonstrate our methods on the task of diabetic retinopathy grading. A prototype layer incorporated into the architecture enables visualization of the areas in the image that are most similar to learned prototypes. The final prediction is then intuitively modeled as a mean of prototype labels, weighted by the similarities. We achieved competitive prediction performance with our INSightR-Net compared to a ResNet baseline, showing that it is not necessary to compromise performance for interpretability. Furthermore, we quantified the quality of our explanations using sparsity and diversity, two concepts considered important for a good explanation, and demonstrated the effect of several parameters on the latent space embeddings.

</p>
</details>

<details><summary><b>STrajNet: Occupancy Flow Prediction via Multi-modal Swin Transformer</b>
<a href="https://arxiv.org/abs/2208.00394">arxiv:2208.00394</a>
&#x1F4C8; 3 <br>
<p>Haochen Liu, Zhiyu Huang, Chen Lv</p></summary>
<p>

**Abstract:** Making an accurate prediction of occupancy and flow is essential to enable better safety and interaction for autonomous vehicles under complex traffic scenarios. This work proposes STrajNet: a multi-modal Swin Transformerbased framework for effective scene occupancy and flow predictions. We employ Swin Transformer to encode the image and interaction-aware motion representations and propose a cross-attention module to inject motion awareness into grid cells across different time steps. Flow and occupancy predictions are then decoded through temporalsharing Pyramid decoders. The proposed method shows competitive prediction accuracy and other evaluation metrics in the Waymo Open Dataset benchmark.

</p>
</details>

<details><summary><b>Evaluating Table Structure Recognition: A New Perspective</b>
<a href="https://arxiv.org/abs/2208.00385">arxiv:2208.00385</a>
&#x1F4C8; 3 <br>
<p>Tarun Kumar, Himanshu Sharad Bhatt</p></summary>
<p>

**Abstract:** Existing metrics used to evaluate table structure recognition algorithms have shortcomings with regard to capturing text and empty cells alignment. In this paper, we build on prior work and propose a new metric - TEDS based IOU similarity (TEDS (IOU)) for table structure recognition which uses bounding boxes instead of text while simultaneously being robust against the above disadvantages. We demonstrate the effectiveness of our metric against previous metrics through various examples.

</p>
</details>

<details><summary><b>DNNShield: Dynamic Randomized Model Sparsification, A Defense Against Adversarial Machine Learning</b>
<a href="https://arxiv.org/abs/2208.00498">arxiv:2208.00498</a>
&#x1F4C8; 2 <br>
<p>Mohammad Hossein Samavatian, Saikat Majumdar, Kristin Barber, Radu Teodorescu</p></summary>
<p>

**Abstract:** DNNs are known to be vulnerable to so-called adversarial attacks that manipulate inputs to cause incorrect results that can be beneficial to an attacker or damaging to the victim. Recent works have proposed approximate computation as a defense mechanism against machine learning attacks. We show that these approaches, while successful for a range of inputs, are insufficient to address stronger, high-confidence adversarial attacks. To address this, we propose DNNSHIELD, a hardware-accelerated defense that adapts the strength of the response to the confidence of the adversarial input. Our approach relies on dynamic and random sparsification of the DNN model to achieve inference approximation efficiently and with fine-grain control over the approximation error. DNNSHIELD uses the output distribution characteristics of sparsified inference compared to a dense reference to detect adversarial inputs. We show an adversarial detection rate of 86% when applied to VGG16 and 88% when applied to ResNet50, which exceeds the detection rate of the state of the art approaches, with a much lower overhead. We demonstrate a software/hardware-accelerated FPGA prototype, which reduces the performance impact of DNNSHIELD relative to software-only CPU and GPU implementations.

</p>
</details>

<details><summary><b>Building an Efficiency Pipeline: Commutativity and Cumulativeness of Efficiency Operators for Transformers</b>
<a href="https://arxiv.org/abs/2208.00483">arxiv:2208.00483</a>
&#x1F4C8; 2 <br>
<p>Ji Xin, Raphael Tang, Zhiying Jiang, Yaoliang Yu, Jimmy Lin</p></summary>
<p>

**Abstract:** There exists a wide variety of efficiency methods for natural language processing (NLP) tasks, such as pruning, distillation, dynamic inference, quantization, etc. We can consider an efficiency method as an operator applied on a model. Naturally, we may construct a pipeline of multiple efficiency methods, i.e., to apply multiple operators on the model sequentially. In this paper, we study the plausibility of this idea, and more importantly, the commutativity and cumulativeness of efficiency operators. We make two interesting observations: (1) Efficiency operators are commutative -- the order of efficiency methods within the pipeline has little impact on the final results; (2) Efficiency operators are also cumulative -- the final results of combining several efficiency methods can be estimated by combining the results of individual methods. These observations deepen our understanding of efficiency operators and provide useful guidelines for their real-world applications.

</p>
</details>

<details><summary><b>Feather-Light Fourier Domain Adaptation in Magnetic Resonance Imaging</b>
<a href="https://arxiv.org/abs/2208.00474">arxiv:2208.00474</a>
&#x1F4C8; 2 <br>
<p>Ivan Zakazov, Vladimir Shaposhnikov, Iaroslav Bespalov, Dmitry V. Dylov</p></summary>
<p>

**Abstract:** Generalizability of deep learning models may be severely affected by the difference in the distributions of the train (source domain) and the test (target domain) sets, e.g., when the sets are produced by different hardware. As a consequence of this domain shift, a certain model might perform well on data from one clinic, and then fail when deployed in another. We propose a very light and transparent approach to perform test-time domain adaptation. The idea is to substitute the target low-frequency Fourier space components that are deemed to reflect the style of an image. To maximize the performance, we implement the "optimal style donor" selection technique, and use a number of source data points for altering a single target scan appearance (Multi-Source Transferring). We study the effect of severity of domain shift on the performance of the method, and show that our training-free approach reaches the state-of-the-art level of complicated deep domain adaptation models. The code for our experiments is released.

</p>
</details>

<details><summary><b>Parameter-Parallel Distributed Variational Quantum Algorithm</b>
<a href="https://arxiv.org/abs/2208.00450">arxiv:2208.00450</a>
&#x1F4C8; 2 <br>
<p>Yun-Fei Niu, Shuo Zhang, Chen Ding, Wan-Su Bao, He-Liang Huang</p></summary>
<p>

**Abstract:** Variational quantum algorithms (VQAs) have emerged as a promising near-term technique to explore practical quantum advantage on noisy intermediate-scale quantum (NISQ) devices. However, the inefficient parameter training process due to the incompatibility with backpropagation and the cost of a large number of measurements, posing a great challenge to the large-scale development of VQAs. Here, we propose a parameter-parallel distributed variational quantum algorithm (PPD-VQA), to accelerate the training process by parameter-parallel training with multiple quantum processors. To maintain the high performance of PPD-VQA in the realistic noise scenarios, a alternate training strategy is proposed to alleviate the acceleration attenuation caused by noise differences among multiple quantum processors, which is an unavoidable common problem of distributed VQA. Besides, the gradient compression is also employed to overcome the potential communication bottlenecks. The achieved results suggest that the PPD-VQA could provide a practical solution for coordinating multiple quantum processors to handle large-scale real-word applications.

</p>
</details>

<details><summary><b>Unitary Approximate Message Passing for Matrix Factorization</b>
<a href="https://arxiv.org/abs/2208.00422">arxiv:2208.00422</a>
&#x1F4C8; 2 <br>
<p>Zhengdao Yuan, Qinghua Guo, Yonina C. Eldar, Yonghui Li</p></summary>
<p>

**Abstract:** We consider matrix factorization (MF) with certain constraints, which finds wide applications in various areas. Leveraging variational inference (VI) and unitary approximate message passing (UAMP), we develop a Bayesian approach to MF with an efficient message passing implementation, called UAMPMF. With proper priors imposed on the factor matrices, UAMPMF can be used to solve many problems that can be formulated as MF, such as non negative matrix factorization, dictionary learning, compressive sensing with matrix uncertainty, robust principal component analysis, and sparse matrix factorization. Extensive numerical examples are provided to show that UAMPMF significantly outperforms state-of-the-art algorithms in terms of recovery accuracy, robustness and computational complexity.

</p>
</details>

<details><summary><b>Eco2AI: carbon emissions tracking of machine learning models as the first step towards sustainable AI</b>
<a href="https://arxiv.org/abs/2208.00406">arxiv:2208.00406</a>
&#x1F4C8; 2 <br>
<p>Semen Budennyy, Vladimir Lazarev, Nikita Zakharenko, Alexey Korovin, Olga Plosskaya, Denis Dimitrov, Vladimir Arkhipkin, Ivan Oseledets, Ivan Barsola, Ilya Egorov, Aleksandra Kosterina, Leonid Zhukov</p></summary>
<p>

**Abstract:** The size and complexity of deep neural networks continue to grow exponentially, significantly increasing energy consumption for training and inference by these models. We introduce an open-source package eco2AI to help data scientists and researchers to track energy consumption and equivalent CO2 emissions of their models in a straightforward way. In eco2AI we put emphasis on accuracy of energy consumption tracking and correct regional CO2 emissions accounting. We encourage research community to search for new optimal Artificial Intelligence (AI) architectures with a lower computational cost. The motivation also comes from the concept of AI-based green house gases sequestrating cycle with both Sustainable AI and Green AI pathways.

</p>
</details>

<details><summary><b>An Experimental Study on Learning Correlated Equilibrium in Routing Games</b>
<a href="https://arxiv.org/abs/2208.00391">arxiv:2208.00391</a>
&#x1F4C8; 2 <br>
<p>Yixian Zhu, Ketan Savla</p></summary>
<p>

**Abstract:** We study route choice in a repeated routing game where an uncertain state of nature determines link latency functions, and agents receive private route recommendation. The state is sampled in an i.i.d. manner in every round from a publicly known distribution, and the recommendations are generated by a randomization policy whose mapping from the state is known publicly. In a one-shot setting, the agents are said to obey recommendation if it gives the smallest travel time in a posteriori expectation. A plausible extension to repeated setting is that the likelihood of following recommendation in a round is related to regret from previous rounds. If the regret is of satisficing type with respect to a default choice and is averaged over past rounds and over all agents, then the asymptotic outcome under an obedient recommendation policy coincides with the one-shot outcome. We report findings from an experiment with one participant at a time engaged in repeated route choice decision on computer. In every round, the participant is shown travel time distribution for each route, a route recommendation generated by an obedient policy, and a rating suggestive of average experience of previous participants with the quality of recommendation. Upon entering route choice, the actual travel times are revealed. The participant evaluates the quality of recommendation by submitting a review. This is combined with historical reviews to update rating for the next round. Data analysis from 33 participants each with 100 rounds suggests moderate negative correlation between the display rating and the average regret, and a strong positive correlation between the rating and the likelihood of following recommendation. Overall, under obedient recommendation policy, the rating converges close to its maximum value by the end of the experiments in conjunction with very high frequency of following recommendations.

</p>
</details>

<details><summary><b>Sampling, Communication, and Prediction Co-Design for Synchronizing the Real-World Device and Digital Model in Metaverse</b>
<a href="https://arxiv.org/abs/2208.04233">arxiv:2208.04233</a>
&#x1F4C8; 1 <br>
<p>Zhen Meng, Changyang She, Guodong Zhao, Daniele De Martini</p></summary>
<p>

**Abstract:** The metaverse has the potential to revolutionize the next generation of the Internet by supporting highly interactive services with the help of Mixed Reality (MR) technologies; still, to provide a satisfactory experience for users, the synchronization between the physical world and its digital models is crucial. This work proposes a sampling, communication and prediction co-design framework to minimize the communication load subject to a constraint on tracking the Mean Squared Error (MSE) between a real-world device and its digital model in the metaverse. To optimize the sampling rate and the prediction horizon, we exploit expert knowledge and develop a constrained Deep Reinforcement Learning (DRL) algorithm, named Knowledge-assisted Constrained Twin-Delayed Deep Deterministic (KC-TD3) policy gradient algorithm. We validate our framework on a prototype composed of a real-world robotic arm and its digital model. Compared with existing approaches: (1) When the tracking error constraint is stringent (MSE=0.002 degrees), our policy degenerates into the policy in the sampling-communication co-design framework. (2) When the tracking error constraint is mild (MSE=0.007 degrees), our policy degenerates into the policy in the prediction-communication co-design framework. (3) Our framework achieves a better trade-off between the average MSE and the average communication load compared with a communication system without sampling and prediction. For example, the average communication load can be reduced up to 87% when the track error constraint is 0.002 degrees. (4) Our policy outperforms the benchmark with the static sampling rate and prediction horizon optimized by exhaustive search, in terms of the tail probability of the tracking error. Furthermore, with the assistance of expert knowledge, the proposed algorithm KC-TD3 achieves better convergence time, stability, and final policy performance.

</p>
</details>

<details><summary><b>Weighted Scaling Approach for Metabolomics Data Analysis</b>
<a href="https://arxiv.org/abs/2208.00603">arxiv:2208.00603</a>
&#x1F4C8; 1 <br>
<p>Biplab Biswas, Nishith Kumar, Md Aminul Hoque, Md Ashad Alam</p></summary>
<p>

**Abstract:** Systematic variation is a common issue in metabolomics data analysis. Therefore, different scaling and normalization techniques are used to preprocess the data for metabolomics data analysis. Although several scaling methods are available in the literature, however, choice of scaling, transformation and/or normalization technique influence the further statistical analysis. It is challenging to choose the appropriate scaling technique for downstream analysis to get accurate results or to make a proper decision. Moreover, the existing scaling techniques are sensitive to outliers or extreme values. To fill the gap, our objective is to introduce a robust scaling approach that is not influenced by outliers as well as provides more accurate results for downstream analysis. Here, we introduced a new weighted scaling approach that is robust against outliers however, where no additional outlier detection/treatment step is needed in data preprocessing and also compared it with the conventional scaling and normalization techniques through artificial and real metabolomics datasets. We evaluated the performance of the proposed method in comparison to the other existing conventional scaling techniques using metabolomics data analysis in both the absence and presence of different percentages of outliers. Results show that in most cases, the proposed scaling technique performs better than the traditional scaling methods in both the absence and presence of outliers. The proposed method improves the further downstream metabolomics analysis. The R function of the proposed robust scaling method is available at https://github.com/nishithkumarpaul/robustScaling/blob/main/wscaling.R

</p>
</details>

<details><summary><b>Long Short-Term Preference Modeling for Continuous-Time Sequential Recommendation</b>
<a href="https://arxiv.org/abs/2208.00593">arxiv:2208.00593</a>
&#x1F4C8; 1 <br>
<p>Huixuan Chi, Hao Xu, Hao Fu, Mengya Liu, Mengdi Zhang, Yuji Yang, Qinfen Hao, Wei Wu</p></summary>
<p>

**Abstract:** Modeling the evolution of user preference is essential in recommender systems. Recently, dynamic graph-based methods have been studied and achieved SOTA for recommendation, majority of which focus on user's stable long-term preference. However, in real-world scenario, user's short-term preference evolves over time dynamically. Although there exists sequential methods that attempt to capture it, how to model the evolution of short-term preference with dynamic graph-based methods has not been well-addressed yet. In particular: 1) existing methods do not explicitly encode and capture the evolution of short-term preference as sequential methods do; 2) simply using last few interactions is not enough for modeling the changing trend. In this paper, we propose Long Short-Term Preference Modeling for Continuous-Time Sequential Recommendation (LSTSR) to capture the evolution of short-term preference under dynamic graph. Specifically, we explicitly encode short-term preference and optimize it via memory mechanism, which has three key operations: Message, Aggregate and Update. Our memory mechanism can not only store one-hop information, but also trigger with new interactions online. Extensive experiments conducted on five public datasets show that LSTSR consistently outperforms many state-of-the-art recommendation methods across various lines.

</p>
</details>

<details><summary><b>DeScoD-ECG: Deep Score-Based Diffusion Model for ECG Baseline Wander and Noise Removal</b>
<a href="https://arxiv.org/abs/2208.00542">arxiv:2208.00542</a>
&#x1F4C8; 1 <br>
<p>Huayu Li, Gregory Ditzler, Janet Roveda, Ao Li</p></summary>
<p>

**Abstract:** Objective: Electrocardiogram (ECG) signals commonly suffer noise interference, such as baseline wander. High-quality and high-fidelity reconstruction of the ECG signals is of great significance to diagnosing cardiovascular diseases. Therefore, this paper proposes a novel ECG baseline wander and noise removal technology. Methods: We extended the diffusion model in a conditional manner that was specific to the ECG signals, namely the Deep Score-Based Diffusion model for Electrocardiogram baseline wander and noise removal (DeScoD-ECG). Moreover, we deployed a multi-shots averaging strategy that improved signal reconstructions. We conducted the experiments on the QT Database and the MIT-BIH Noise Stress Test Database to verify the feasibility of the proposed method. Baseline methods are adopted for comparison, including traditional digital filter-based and deep learning-based methods. Results: The quantities evaluation results show that the proposed method obtained outstanding performance on four distance-based similarity metrics (the sum of squared distance, maximum absolute square, percentage of root distance, and cosine similarity) with 3.771 $\pm$ 5.713 au, 0.329 $\pm$ 0.258 au, 40.527 $\pm$ 26.258 \%, and 0.926 $\pm$ 0.087. This led to at least 20\% overall improvement compared with the best baseline method. Conclusion: This paper demonstrates the state-of-the-art performance of the DeScoD-ECG for ECG noise removal, which has better approximations of the true data distribution and higher stability under extreme noise corruptions. Significance: This study is one of the first to extend the conditional diffusion-based generative model for ECG noise removal, and the DeScoD-ECG has the potential to be widely used in biomedical applications.

</p>
</details>

<details><summary><b>Learning to generate Reliable Broadcast Algorithms</b>
<a href="https://arxiv.org/abs/2208.00525">arxiv:2208.00525</a>
&#x1F4C8; 1 <br>
<p>Diogo Vaz, David R. Matos, Miguel L. Pardal, Miguel Correia</p></summary>
<p>

**Abstract:** Modern distributed systems are supported by fault-tolerant algorithms, like Reliable Broadcast and Consensus, that assure the correct operation of the system even when some of the nodes of the system fail. However, the development of distributed algorithms is a manual and complex process, resulting in scientific papers that usually present a single algorithm or variations of existing ones. To automate the process of developing such algorithms, this work presents an intelligent agent that uses Reinforcement Learning to generate correct and efficient fault-tolerant distributed algorithms. We show that our approach is able to generate correct fault-tolerant Reliable Broadcast algorithms with the same performance of others available in the literature, in only 12,000 learning episodes.

</p>
</details>

<details><summary><b>Formal guarantees for heuristic optimization algorithms used in machine learning</b>
<a href="https://arxiv.org/abs/2208.00502">arxiv:2208.00502</a>
&#x1F4C8; 1 <br>
<p>Xiaoyu Li</p></summary>
<p>

**Abstract:** Recently, Stochastic Gradient Descent (SGD) and its variants have become the dominant methods in the large-scale optimization of machine learning (ML) problems. A variety of strategies have been proposed for tuning the step sizes, ranging from adaptive step sizes to heuristic methods to change the step size in each iteration. Also, momentum has been widely employed in ML tasks to accelerate the training process. Yet, there is a gap in our theoretical understanding of them. In this work, we start to close this gap by providing formal guarantees to a few heuristic optimization methods and proposing improved algorithms.
  First, we analyze a generalized version of the AdaGrad (Delayed AdaGrad) step sizes in both convex and non-convex settings, showing that these step sizes allow the algorithms to automatically adapt to the level of noise of the stochastic gradients. We show for the first time sufficient conditions for Delayed AdaGrad to achieve almost sure convergence of the gradients to zero. Moreover, we present a high probability analysis for Delayed AdaGrad and its momentum variant in the non-convex setting.
  Second, we analyze SGD with exponential and cosine step sizes, which are empirically successful but lack theoretical support. We provide the very first convergence guarantees for them in the smooth and non-convex setting, with and without the Polyak-Łojasiewicz (PL) condition. We also show their good property of adaptivity to noise under the PL condition.
  Third, we study the last iterate of momentum methods. We prove the first lower bound in the convex setting for the last iterate of SGD with constant momentum. Moreover, we investigate a class of Follow-The-Regularized-Leader-based momentum algorithms with increasing momentum and shrinking updates. We show that their last iterate has optimal convergence for unconstrained convex stochastic optimization problems.

</p>
</details>

<details><summary><b>Adaptive Edge Offloading for Image Classification Under Rate Limit</b>
<a href="https://arxiv.org/abs/2208.00485">arxiv:2208.00485</a>
&#x1F4C8; 1 <br>
<p>Jiaming Qiu, Ruiqi Wang, Ayan Chakrabarti, Roch Guerin, Chenyang Lu</p></summary>
<p>

**Abstract:** This paper considers a setting where embedded devices are used to acquire and classify images. Because of limited computing capacity, embedded devices rely on a parsimonious classification model with uneven accuracy. When local classification is deemed inaccurate, devices can decide to offload the image to an edge server with a more accurate but resource-intensive model. Resource constraints, e.g., network bandwidth, however, require regulating such transmissions to avoid congestion and high latency. The paper investigates this offloading problem when transmissions regulation is through a token bucket, a mechanism commonly used for such purposes. The goal is to devise a lightweight, online offloading policy that optimizes an application-specific metric (e.g., classification accuracy) under the constraints of the token bucket. The paper develops a policy based on a Deep Q-Network (DQN), and demonstrates both its efficacy and the feasibility of its deployment on embedded devices. Of note is the fact that the policy can handle complex input patterns, including correlation in image arrivals and classification accuracy. The evaluation is carried out by performing image classification over a local testbed using synthetic traces generated from the ImageNet image classification benchmark. Implementation of this work is available at https://github.com/qiujiaming315/edgeml-dqn.

</p>
</details>

<details><summary><b>DRL-M4MR: An Intelligent Multicast Routing Approach Based on DQN Deep Reinforcement Learning in SDN</b>
<a href="https://arxiv.org/abs/2208.00383">arxiv:2208.00383</a>
&#x1F4C8; 1 <br>
<p>Chenwei Zhao, Miao Ye, Xingsi Xue, Jianhui Lv, Qiuxiang Jiang, Yong Wang</p></summary>
<p>

**Abstract:** Traditional multicast routing methods have some problems in constructing a multicast tree, such as limited access to network state information, poor adaptability to dynamic and complex changes in the network, and inflexible data forwarding. To address these defects, the optimal multicast routing problem in software-defined networking (SDN) is tailored as a multi-objective optimization problem, and an intelligent multicast routing algorithm DRL-M4MR based on the deep Q network (DQN) deep reinforcement learning (DRL) method is designed to construct a multicast tree in SDN. First, the multicast tree state matrix, link bandwidth matrix, link delay matrix, and link packet loss rate matrix are designed as the state space of the DRL agent by combining the global view and control of the SDN. Second, the action space of the agent is all the links in the network, and the action selection strategy is designed to add the links to the current multicast tree under four cases. Third, single-step and final reward function forms are designed to guide the intelligence to make decisions to construct the optimal multicast tree. The experimental results show that, compared with existing algorithms, the multicast tree construct by DRL-M4MR can obtain better bandwidth, delay, and packet loss rate performance after training, and it can make more intelligent multicast routing decisions in a dynamic network environment.

</p>
</details>

<details><summary><b>Exploring Attention-Aware Network Resource Allocation for Customized Metaverse Services</b>
<a href="https://arxiv.org/abs/2208.00369">arxiv:2208.00369</a>
&#x1F4C8; 1 <br>
<p>Hongyang Du, Jiacheng Wang, Dusit Niyato, Jiawen Kang, Zehui Xiong,  Xuemin,  Shen, Dong In Kim</p></summary>
<p>

**Abstract:** Emerging with the support of computing and communications technologies, Metaverse is expected to bring users unprecedented service experiences. However, the increase in the number of Metaverse users places a heavy demand on network resources, especially for Metaverse services that are based on graphical extended reality and require rendering a plethora of virtual objects. To make efficient use of network resources and improve the Quality-of-Experience (QoE), we design an attention-aware network resource allocation scheme to achieve customized Metaverse services. The aim is to allocate more network resources to virtual objects in which users are more interested. We first discuss several key techniques related to Metaverse services, including QoE analysis, eye-tracking, and remote rendering. We then review existing datasets and propose the user-object-attention level (UOAL) dataset that contains the ground truth attention of 30 users to 96 objects in 1,000 images. A tutorial on how to use UOAL is presented. With the help of UOAL, we propose an attention-aware network resource allocation algorithm that has two steps, i.e., attention prediction and QoE maximization. Specially, we provide an overview of the designs of two types of attention prediction methods, i.e., interest-aware and time-aware prediction. By using the predicted user-object-attention values, network resources such as the rendering capacity of edge devices can be allocated optimally to maximize the QoE. Finally, we propose promising research directions related to Metaverse services.

</p>
</details>

<details><summary><b>A Particle-Based Algorithm for Distributional Optimization on \textit{Constrained Domains} via Variational Transport and Mirror Descent</b>
<a href="https://arxiv.org/abs/2208.00587">arxiv:2208.00587</a>
&#x1F4C8; 0 <br>
<p>Dai Hai Nguyen, Tetsuya Sakurai</p></summary>
<p>

**Abstract:** We consider the optimization problem of minimizing an objective functional, which admits a variational form and is defined over probability distributions on the constrained domain, which poses challenges to both theoretical analysis and algorithmic design. Inspired by the mirror descent algorithm for constrained optimization, we propose an iterative particle-based algorithm, named Mirrored Variational Transport (mirrorVT), extended from the Variational Transport framework [7] for dealing with the constrained domain. In particular, for each iteration, mirrorVT maps particles to an unconstrained dual domain induced by a mirror map and then approximately perform Wasserstein gradient descent on the manifold of distributions defined over the dual space by pushing particles. At the end of iteration, particles are mapped back to the original constrained domain. Through simulated experiments, we demonstrate the effectiveness of mirrorVT for minimizing the functionals over probability distributions on the simplex- and Euclidean ball-constrained domains. We also analyze its theoretical properties and characterize its convergence to the global minimum of the objective functional.

</p>
</details>

<details><summary><b>Evo* 2022 -- Late-Breaking Abstracts Volume</b>
<a href="https://arxiv.org/abs/2208.00555">arxiv:2208.00555</a>
&#x1F4C8; 0 <br>
<p>A. M. Mora, A. I. Esparcia-Alcázar</p></summary>
<p>

**Abstract:** Volume with the Late-Breaking Abstracts submitted to the Evo* 2022 Conference, held in Madrid (Spain), from 20 to 22 of April. These papers present ongoing research and preliminary results investigating on the application of different approaches of Bioinspired Methods (mainly Evolutionary Computation) to different problems, most of them real world ones.

</p>
</details>

<details><summary><b>DA$^2$ Dataset: Toward Dexterity-Aware Dual-Arm Grasping</b>
<a href="https://arxiv.org/abs/2208.00408">arxiv:2208.00408</a>
&#x1F4C8; 0 <br>
<p>Guangyao Zhai, Yu Zheng, Ziwei Xu, Xin Kong, Yong Liu, Benjamin Busam, Yi Ren, Nassir Navab, Zhengyou Zhang</p></summary>
<p>

**Abstract:** In this paper, we introduce DA$^2$, the first large-scale dual-arm dexterity-aware dataset for the generation of optimal bimanual grasping pairs for arbitrary large objects. The dataset contains about 9M pairs of parallel-jaw grasps, generated from more than 6000 objects and each labeled with various grasp dexterity measures. In addition, we propose an end-to-end dual-arm grasp evaluation model trained on the rendered scenes from this dataset. We utilize the evaluation model as our baseline to show the value of this novel and nontrivial dataset by both online analysis and real robot experiments. All data and related code will be open-sourced at https://sites.google.com/view/da2dataset.

</p>
</details>


{% endraw %}
Prev: [2022.07.30]({{ '/2022/07/30/2022.07.30.html' | relative_url }})  Next: [2022.08.01]({{ '/2022/08/01/2022.08.01.html' | relative_url }})