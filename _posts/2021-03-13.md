## Summary for 2021-03-13, created on 2021-12-23


<details><summary><b>Spectral Temporal Graph Neural Network for Multivariate Time-series Forecasting</b>
<a href="https://arxiv.org/abs/2103.07719">arxiv:2103.07719</a>
&#x1F4C8; 26 <br>
<p>Defu Cao, Yujing Wang, Juanyong Duan, Ce Zhang, Xia Zhu, Conguri Huang, Yunhai Tong, Bixiong Xu, Jing Bai, Jie Tong, Qi Zhang</p></summary>
<p>

**Abstract:** Multivariate time-series forecasting plays a crucial role in many real-world applications. It is a challenging problem as one needs to consider both intra-series temporal correlations and inter-series correlations simultaneously. Recently, there have been multiple works trying to capture both correlations, but most, if not all of them only capture temporal correlations in the time domain and resort to pre-defined priors as inter-series relationships.
  In this paper, we propose Spectral Temporal Graph Neural Network (StemGNN) to further improve the accuracy of multivariate time-series forecasting. StemGNN captures inter-series correlations and temporal dependencies \textit{jointly} in the \textit{spectral domain}. It combines Graph Fourier Transform (GFT) which models inter-series correlations and Discrete Fourier Transform (DFT) which models temporal dependencies in an end-to-end framework. After passing through GFT and DFT, the spectral representations hold clear patterns and can be predicted effectively by convolution and sequential learning modules. Moreover, StemGNN learns inter-series correlations automatically from the data without using pre-defined priors. We conduct extensive experiments on ten real-world datasets to demonstrate the effectiveness of StemGNN. Code is available at https://github.com/microsoft/StemGNN/

</p>
</details>

<details><summary><b>Automated Fact-Checking for Assisting Human Fact-Checkers</b>
<a href="https://arxiv.org/abs/2103.07769">arxiv:2103.07769</a>
&#x1F4C8; 19 <br>
<p>Preslav Nakov, David Corney, Maram Hasanain, Firoj Alam, Tamer Elsayed, Alberto Barrón-Cedeño, Paolo Papotti, Shaden Shaar, Giovanni Da San Martino</p></summary>
<p>

**Abstract:** The reporting and the analysis of current events around the globe has expanded from professional, editor-lead journalism all the way to citizen journalism. Nowadays, politicians and other key players enjoy direct access to their audiences through social media, bypassing the filters of official cables or traditional media. However, the multiple advantages of free speech and direct communication are dimmed by the misuse of media to spread inaccurate or misleading claims. These phenomena have led to the modern incarnation of the fact-checker -- a professional whose main aim is to examine claims using available evidence and to assess their veracity. As in other text forensics tasks, the amount of information available makes the work of the fact-checker more difficult. With this in mind, starting from the perspective of the professional fact-checker, we survey the available intelligent technologies that can support the human expert in the different steps of her fact-checking endeavor. These include identifying claims worth fact-checking, detecting relevant previously fact-checked claims, retrieving relevant evidence to fact-check a claim, and actually verifying a claim. In each case, we pay attention to the challenges in future work and the potential impact on real-world fact-checking.

</p>
</details>

<details><summary><b>Learning with Feature-Dependent Label Noise: A Progressive Approach</b>
<a href="https://arxiv.org/abs/2103.07756">arxiv:2103.07756</a>
&#x1F4C8; 13 <br>
<p>Yikai Zhang, Songzhu Zheng, Pengxiang Wu, Mayank Goswami, Chao Chen</p></summary>
<p>

**Abstract:** Label noise is frequently observed in real-world large-scale datasets. The noise is introduced due to a variety of reasons; it is heterogeneous and feature-dependent. Most existing approaches to handling noisy labels fall into two categories: they either assume an ideal feature-independent noise, or remain heuristic without theoretical guarantees. In this paper, we propose to target a new family of feature-dependent label noise, which is much more general than commonly used i.i.d. label noise and encompasses a broad spectrum of noise patterns. Focusing on this general noise family, we propose a progressive label correction algorithm that iteratively corrects labels and refines the model. We provide theoretical guarantees showing that for a wide variety of (unknown) noise patterns, a classifier trained with this strategy converges to be consistent with the Bayes classifier. In experiments, our method outperforms SOTA baselines and is robust to various noise types and levels.

</p>
</details>

<details><summary><b>PhotoApp: Photorealistic Appearance Editing of Head Portraits</b>
<a href="https://arxiv.org/abs/2103.07658">arxiv:2103.07658</a>
&#x1F4C8; 9 <br>
<p>Mallikarjun B R, Ayush Tewari, Abdallah Dib, Tim Weyrich, Bernd Bickel, Hans-Peter Seidel, Hanspeter Pfister, Wojciech Matusik, Louis Chevallier, Mohamed Elgharib, Christian Theobalt</p></summary>
<p>

**Abstract:** Photorealistic editing of portraits is a challenging task as humans are very sensitive to inconsistencies in faces. We present an approach for high-quality intuitive editing of the camera viewpoint and scene illumination in a portrait image. This requires our method to capture and control the full reflectance field of the person in the image. Most editing approaches rely on supervised learning using training data captured with setups such as light and camera stages. Such datasets are expensive to acquire, not readily available and do not capture all the rich variations of in-the-wild portrait images. In addition, most supervised approaches only focus on relighting, and do not allow camera viewpoint editing. Thus, they only capture and control a subset of the reflectance field. Recently, portrait editing has been demonstrated by operating in the generative model space of StyleGAN. While such approaches do not require direct supervision, there is a significant loss of quality when compared to the supervised approaches. In this paper, we present a method which learns from limited supervised training data. The training images only include people in a fixed neutral expression with eyes closed, without much hair or background variations. Each person is captured under 150 one-light-at-a-time conditions and under 8 camera poses. Instead of training directly in the image space, we design a supervised problem which learns transformations in the latent space of StyleGAN. This combines the best of supervised learning and generative adversarial modeling. We show that the StyleGAN prior allows for generalisation to different expressions, hairstyles and backgrounds. This produces high-quality photorealistic results for in-the-wild images and significantly outperforms existing methods. Our approach can edit the illumination and pose simultaneously, and runs at interactive rates.

</p>
</details>

<details><summary><b>Reconsidering Representation Alignment for Multi-view Clustering</b>
<a href="https://arxiv.org/abs/2103.07738">arxiv:2103.07738</a>
&#x1F4C8; 8 <br>
<p>Daniel J. Trosten, Sigurd Løkse, Robert Jenssen, Michael Kampffmeyer</p></summary>
<p>

**Abstract:** Aligning distributions of view representations is a core component of today's state of the art models for deep multi-view clustering. However, we identify several drawbacks with naïvely aligning representation distributions. We demonstrate that these drawbacks both lead to less separable clusters in the representation space, and inhibit the model's ability to prioritize views. Based on these observations, we develop a simple baseline model for deep multi-view clustering. Our baseline model avoids representation alignment altogether, while performing similar to, or better than, the current state of the art. We also expand our baseline model by adding a contrastive learning component. This introduces a selective alignment procedure that preserves the model's ability to prioritize views. Our experiments show that the contrastive learning component enhances the baseline model, improving on the current state of the art by a large margin on several datasets.

</p>
</details>

<details><summary><b>Machine Learning on the COVID-19 Pandemic, Human Mobility and Air Quality: A Review</b>
<a href="https://arxiv.org/abs/2104.04059">arxiv:2104.04059</a>
&#x1F4C8; 6 <br>
<p>Md. Mokhlesur Rahman, Kamal Chandra Paul, Md. Amjad Hossain, G. G. Md. NawazAli, Md. Shahinoor Rahman, Jean-Claude Thill</p></summary>
<p>

**Abstract:** The ongoing COVID-19 global pandemic is affecting every facet of human lives (e.g., public health, education, economy, transportation, and the environment). This novel pandemic and citywide implemented lockdown measures are affecting virus transmission, people's travel patterns, and air quality. Many studies have been conducted to predict the COVID-19 diffusion, assess the impacts of the pandemic on human mobility and air quality, and assess the impacts of lockdown measures on viral spread with a range of Machine Learning (ML) techniques. This review study aims to analyze results from past research to understand the interactions among the COVID-19 pandemic, lockdown measures, human mobility, and air quality. The critical review of prior studies indicates that urban form, people's socioeconomic and physical conditions, social cohesion, and social distancing measures significantly affect human mobility and COVID-19 transmission. during the COVID-19 pandemic, many people are inclined to use private transportation for necessary travel purposes to mitigate coronavirus-related health problems. This review study also noticed that COVID-19 related lockdown measures significantly improve air quality by reducing the concentration of air pollutants, which in turn improves the COVID-19 situation by reducing respiratory-related sickness and deaths of people. It is argued that ML is a powerful, effective, and robust analytic paradigm to handle complex and wicked problems such as a global pandemic. This study also discusses policy implications, which will be helpful for policymakers to take prompt actions to moderate the severity of the pandemic and improve urban environments by adopting data-driven analytic methods.

</p>
</details>

<details><summary><b>Radar Camera Fusion via Representation Learning in Autonomous Driving</b>
<a href="https://arxiv.org/abs/2103.07825">arxiv:2103.07825</a>
&#x1F4C8; 6 <br>
<p>Xu Dong, Binnan Zhuang, Yunxiang Mao, Langechuan Liu</p></summary>
<p>

**Abstract:** Radars and cameras are mature, cost-effective, and robust sensors and have been widely used in the perception stack of mass-produced autonomous driving systems. Due to their complementary properties, outputs from radar detection (radar pins) and camera perception (2D bounding boxes) are usually fused to generate the best perception results. The key to successful radar-camera fusion is the accurate data association. The challenges in the radar-camera association can be attributed to the complexity of driving scenes, the noisy and sparse nature of radar measurements, and the depth ambiguity from 2D bounding boxes. Traditional rule-based association methods are susceptible to performance degradation in challenging scenarios and failure in corner cases. In this study, we propose to address radar-camera association via deep representation learning, to explore feature-level interaction and global reasoning. Additionally, we design a loss sampling mechanism and an innovative ordinal loss to overcome the difficulty of imperfect labeling and to enforce critical human-like reasoning. Despite being trained with noisy labels generated by a rule-based algorithm, our proposed method achieves a performance of 92.2% F1 score, which is 11.6% higher than the rule-based teacher. Moreover, this data-driven method also lends itself to continuous improvement via corner case mining.

</p>
</details>

<details><summary><b>A Survey on Multimodal Disinformation Detection</b>
<a href="https://arxiv.org/abs/2103.12541">arxiv:2103.12541</a>
&#x1F4C8; 5 <br>
<p>Firoj Alam, Stefano Cresci, Tanmoy Chakraborty, Fabrizio Silvestri, Dimiter Dimitrov, Giovanni Da San Martino, Shaden Shaar, Hamed Firooz, Preslav Nakov</p></summary>
<p>

**Abstract:** Recent years have witnessed the proliferation of fake news, propaganda, misinformation, and disinformation online. While initially this was mostly about textual content, over time images and videos gained popularity, as they are much easier to consume, attract much more attention, and spread further than simple text. As a result, researchers started targeting different modalities and combinations thereof. As different modalities are studied in different research communities, with insufficient interaction, here we offer a survey that explores the state-of-the-art on multimodal disinformation detection covering various combinations of modalities: text, images, audio, video, network structure, and temporal information. Moreover, while some studies focused on factuality, others investigated how harmful the content is. While these two components in the definition of disinformation -- (i) factuality and (ii) harmfulness, are equally important, they are typically studied in isolation. Thus, we argue for the need to tackle disinformation detection by taking into account multiple modalities as well as both factuality and harmfulness, in the same framework. Finally, we discuss current challenges and future research directions.

</p>
</details>

<details><summary><b>Error-Aware Policy Learning: Zero-Shot Generalization in Partially Observable Dynamic Environments</b>
<a href="https://arxiv.org/abs/2103.07732">arxiv:2103.07732</a>
&#x1F4C8; 5 <br>
<p>Visak Kumar, Sehoon Ha, C. Karen Liu</p></summary>
<p>

**Abstract:** Simulation provides a safe and efficient way to generate useful data for learning complex robotic tasks. However, matching simulation and real-world dynamics can be quite challenging, especially for systems that have a large number of unobserved or unmeasurable parameters, which may lie in the robot dynamics itself or in the environment with which the robot interacts. We introduce a novel approach to tackle such a sim-to-real problem by developing policies capable of adapting to new environments, in a zero-shot manner. Key to our approach is an error-aware policy (EAP) that is explicitly made aware of the effect of unobservable factors during training. An EAP takes as input the predicted future state error in the target environment, which is provided by an error-prediction function, simultaneously trained with the EAP. We validate our approach on an assistive walking device trained to help the human user recover from external pushes. We show that a trained EAP for a hip-torque assistive device can be transferred to different human agents with unseen biomechanical characteristics. In addition, we show that our method can be applied to other standard RL control tasks.

</p>
</details>

<details><summary><b>Simpson's Bias in NLP Training</b>
<a href="https://arxiv.org/abs/2103.11795">arxiv:2103.11795</a>
&#x1F4C8; 4 <br>
<p>Fei Yuan, Longtu Zhang, Huang Bojun, Yaobo Liang</p></summary>
<p>

**Abstract:** In most machine learning tasks, we evaluate a model $M$ on a given data population $S$ by measuring a population-level metric $F(S;M)$. Examples of such evaluation metric $F$ include precision/recall for (binary) recognition, the F1 score for multi-class classification, and the BLEU metric for language generation. On the other hand, the model $M$ is trained by optimizing a sample-level loss $G(S_t;M)$ at each learning step $t$, where $S_t$ is a subset of $S$ (a.k.a. the mini-batch). Popular choices of $G$ include cross-entropy loss, the Dice loss, and sentence-level BLEU scores. A fundamental assumption behind this paradigm is that the mean value of the sample-level loss $G$, if averaged over all possible samples, should effectively represent the population-level metric $F$ of the task, such as, that $\mathbb{E}[ G(S_t;M) ] \approx F(S;M)$.
  In this paper, we systematically investigate the above assumption in several NLP tasks. We show, both theoretically and experimentally, that some popular designs of the sample-level loss $G$ may be inconsistent with the true population-level metric $F$ of the task, so that models trained to optimize the former can be substantially sub-optimal to the latter, a phenomenon we call it, Simpson's bias, due to its deep connections with the classic paradox known as Simpson's reversal paradox in statistics and social sciences.

</p>
</details>

<details><summary><b>Supervised Learning in the Presence of Noise: Application in ICD-10 Code Classification</b>
<a href="https://arxiv.org/abs/2103.07808">arxiv:2103.07808</a>
&#x1F4C8; 4 <br>
<p>Youngwoo Kim, Cheng Li, Bingyang Ye, Amir Tahmasebi, Javed Aslam</p></summary>
<p>

**Abstract:** ICD coding is the international standard for capturing and reporting health conditions and diagnosis for revenue cycle management in healthcare. Manually assigning ICD codes is prone to human error due to the large code vocabulary and the similarities between codes. Since machine learning based approaches require ground truth training data, the inconsistency among human coders is manifested as noise in labeling, which makes the training and evaluation of ICD classifiers difficult in presence of such noise. This paper investigates the characteristics of such noise in manually-assigned ICD-10 codes and furthermore, proposes a method to train robust ICD-10 classifiers in the presence of labeling noise. Our research concluded that the nature of such noise is systematic. Most of the existing methods for handling label noise assume that the noise is completely random and independent of features or labels, which is not the case for ICD data. Therefore, we develop a new method for training robust classifiers in the presence of systematic noise. We first identify ICD-10 codes that human coders tend to misuse or confuse, based on the codes' locations in the ICD-10 hierarchy, the types of the codes, and baseline classifier's prediction behaviors; we then develop a novel training strategy that accounts for such noise. We compared our method with the baseline that does not handle label noise and the baseline methods that assume random noise, and demonstrated that our proposed method outperforms all baselines when evaluated on expert validated labels.

</p>
</details>

<details><summary><b>Treatment Effect Estimation using Invariant Risk Minimization</b>
<a href="https://arxiv.org/abs/2103.07788">arxiv:2103.07788</a>
&#x1F4C8; 4 <br>
<p>Abhin Shah, Kartik Ahuja, Karthikeyan Shanmugam, Dennis Wei, Kush Varshney, Amit Dhurandhar</p></summary>
<p>

**Abstract:** Inferring causal individual treatment effect (ITE) from observational data is a challenging problem whose difficulty is exacerbated by the presence of treatment assignment bias. In this work, we propose a new way to estimate the ITE using the domain generalization framework of invariant risk minimization (IRM). IRM uses data from multiple domains, learns predictors that do not exploit spurious domain-dependent factors, and generalizes better to unseen domains. We propose an IRM-based ITE estimator aimed at tackling treatment assignment bias when there is little support overlap between the control group and the treatment group. We accomplish this by creating diversity: given a single dataset, we split the data into multiple domains artificially. These diverse domains are then exploited by IRM to more effectively generalize regression-based models to data regions that lack support overlap. We show gains over classical regression approaches to ITE estimation in settings when support mismatch is more pronounced.

</p>
</details>

<details><summary><b>Image Classifiers for Network Intrusions</b>
<a href="https://arxiv.org/abs/2103.07765">arxiv:2103.07765</a>
&#x1F4C8; 4 <br>
<p>David A. Noever, Samantha E. Miller Noever</p></summary>
<p>

**Abstract:** This research recasts the network attack dataset from UNSW-NB15 as an intrusion detection problem in image space. Using one-hot-encodings, the resulting grayscale thumbnails provide a quarter-million examples for deep learning algorithms. Applying the MobileNetV2's convolutional neural network architecture, the work demonstrates a 97% accuracy in distinguishing normal and attack traffic. Further class refinements to 9 individual attack families (exploits, worms, shellcodes) show an overall 56% accuracy. Using feature importance rank, a random forest solution on subsets show the most important source-destination factors and the least important ones as mainly obscure protocols. The dataset is available on Kaggle.

</p>
</details>

<details><summary><b>OCID-Ref: A 3D Robotic Dataset with Embodied Language for Clutter Scene Grounding</b>
<a href="https://arxiv.org/abs/2103.07679">arxiv:2103.07679</a>
&#x1F4C8; 4 <br>
<p>Ke-Jyun Wang, Yun-Hsuan Liu, Hung-Ting Su, Jen-Wei Wang, Yu-Siang Wang, Winston H. Hsu, Wen-Chin Chen</p></summary>
<p>

**Abstract:** To effectively apply robots in working environments and assist humans, it is essential to develop and evaluate how visual grounding (VG) can affect machine performance on occluded objects. However, current VG works are limited in working environments, such as offices and warehouses, where objects are usually occluded due to space utilization issues. In our work, we propose a novel OCID-Ref dataset featuring a referring expression segmentation task with referring expressions of occluded objects. OCID-Ref consists of 305,694 referring expressions from 2,300 scenes with providing RGB image and point cloud inputs. To resolve challenging occlusion issues, we argue that it's crucial to take advantage of both 2D and 3D signals to resolve challenging occlusion issues. Our experimental results demonstrate the effectiveness of aggregating 2D and 3D signals but referring to occluded objects still remains challenging for the modern visual grounding systems. OCID-Ref is publicly available at https://github.com/lluma/OCID-Ref

</p>
</details>

<details><summary><b>Multilingual Code-Switching for Zero-Shot Cross-Lingual Intent Prediction and Slot Filling</b>
<a href="https://arxiv.org/abs/2103.07792">arxiv:2103.07792</a>
&#x1F4C8; 3 <br>
<p>Jitin Krishnan, Antonios Anastasopoulos, Hemant Purohit, Huzefa Rangwala</p></summary>
<p>

**Abstract:** Predicting user intent and detecting the corresponding slots from text are two key problems in Natural Language Understanding (NLU). In the context of zero-shot learning, this task is typically approached by either using representations from pre-trained multilingual transformers such as mBERT, or by machine translating the source data into the known target language and then fine-tuning. Our work focuses on a particular scenario where the target language is unknown during training. To this goal, we propose a novel method to augment the monolingual source data using multilingual code-switching via random translations to enhance a transformer's language neutrality when fine-tuning it for a downstream task. This method also helps discover novel insights on how code-switching with different language families around the world impact the performance on the target language. Experiments on the benchmark dataset of MultiATIS++ yielded an average improvement of +4.2% in accuracy for intent task and +1.8% in F1 for slot task using our method over the state-of-the-art across 8 different languages. Furthermore, we present an application of our method for crisis informatics using a new human-annotated tweet dataset of slot filling in English and Haitian Creole, collected during Haiti earthquake disaster.

</p>
</details>

<details><summary><b>Multi-Object Tracking using Poisson Multi-Bernoulli Mixture Filtering for Autonomous Vehicles</b>
<a href="https://arxiv.org/abs/2103.07783">arxiv:2103.07783</a>
&#x1F4C8; 3 <br>
<p>Su Pang, Hayder Radha</p></summary>
<p>

**Abstract:** The ability of an autonomous vehicle to perform 3D tracking is essential for safe planing and navigation in cluttered environments. The main challenges for multi-object tracking (MOT) in autonomous driving applications reside in the inherent uncertainties regarding the number of objects, when and where the objects may appear and disappear, and uncertainties regarding objects' states. Random finite set (RFS) based approaches can naturally model these uncertainties accurately and elegantly, and they have been widely used in radar-based tracking applications. In this work, we developed an RFS-based MOT framework for 3D LiDAR data. In partiuclar, we propose a Poisson multi-Bernoulli mixture (PMBM) filter to solve the amodal MOT problem for autonomous driving applications. To the best of our knowledge, this represents a first attempt for employing an RFS-based approach in conjunction with 3D LiDAR data for MOT applications with comprehensive validation using challenging datasets made available by industry leaders. The superior experimental results of our PMBM tracker on public Waymo and Argoverse datasets clearly illustrate that an RFS-based tracker outperforms many state-of-the-art deep learning-based and Kalman filter-based methods, and consequently, these results indicate a great potential for further exploration of RFS-based frameworks for 3D MOT applications.

</p>
</details>

<details><summary><b>OkwuGbé: End-to-End Speech Recognition for Fon and Igbo</b>
<a href="https://arxiv.org/abs/2103.07762">arxiv:2103.07762</a>
&#x1F4C8; 3 <br>
<p>Bonaventure F. P. Dossou, Chris C. Emezue</p></summary>
<p>

**Abstract:** Language is inherent and compulsory for human communication. Whether expressed in a written or spoken way, it ensures understanding between people of the same and different regions. With the growing awareness and effort to include more low-resourced languages in NLP research, African languages have recently been a major subject of research in machine translation, and other text-based areas of NLP. However, there is still very little comparable research in speech recognition for African languages. Interestingly, some of the unique properties of African languages affecting NLP, like their diacritical and tonal complexities, have a major root in their speech, suggesting that careful speech interpretation could provide more intuition on how to deal with the linguistic complexities of African languages for text-based NLP. OkwuGbé is a step towards building speech recognition systems for African low-resourced languages. Using Fon and Igbo as our case study, we conduct a comprehensive linguistic analysis of each language and describe the creation of end-to-end, deep neural network-based speech recognition models for both languages. We present a state-of-art ASR model for Fon, as well as benchmark ASR model results for Igbo. Our linguistic analyses (for Fon and Igbo) provide valuable insights and guidance into the creation of speech recognition models for other African low-resourced languages, as well as guide future NLP research for Fon and Igbo. The Fon and Igbo models source code have been made publicly available.

</p>
</details>

<details><summary><b>A review of machine learning in processing remote sensing data for mineral exploration</b>
<a href="https://arxiv.org/abs/2103.07678">arxiv:2103.07678</a>
&#x1F4C8; 3 <br>
<p>Hojat Shirmard, Ehsan Farahbakhsh, R. Dietmar Muller, Rohitash Chandra</p></summary>
<p>

**Abstract:** The decline of the number of newly discovered mineral deposits and increase in demand for different minerals in recent years has led exploration geologists to look for more efficient and innovative methods for processing different data types at each stage of mineral exploration. As a primary step, various features, such as lithological units, alteration types, structures, and indicator minerals, are mapped to aid decision-making in targeting ore deposits. Different types of remote sensing datasets, such as satellite and airborne data, make it possible to overcome common problems associated with mapping geological features. The rapid increase in the volume of remote sensing data obtained from different platforms has encouraged scientists to develop advanced, innovative, and robust data processing methodologies. Machine learning methods can help process a wide range of remote sensing datasets and determine the relationship between components such as the reflectance continuum and features of interest. These methods are robust in processing spectral and ground truth measurements against noise and uncertainties. In recent years, many studies have been carried out by supplementing geological surveys with remote sensing datasets, which is now prominent in geoscience research. This paper provides a comprehensive review of the implementation and adaptation of some popular and recently established machine learning methods for processing different types of remote sensing data and investigates their applications for detecting various ore deposit types. We demonstrate the high capability of combining remote sensing data and machine learning methods for mapping different geological features that are critical for providing potential maps. Moreover, we find there is scope for advanced methods to process the new generation of remote sensing data for creating improved mineral prospectivity maps.

</p>
</details>

<details><summary><b>Fine-grained MRI Reconstruction using Attentive Selection Generative Adversarial Networks</b>
<a href="https://arxiv.org/abs/2103.07672">arxiv:2103.07672</a>
&#x1F4C8; 3 <br>
<p>Jingshuai Liu, Mehrdad Yaghoobi</p></summary>
<p>

**Abstract:** Compressed sensing (CS) leverages the sparsity prior to provide the foundation for fast magnetic resonance imaging (fastMRI). However, iterative solvers for ill-posed problems hinder their adaption to time-critical applications. Moreover, such a prior can be neither rich to capture complicated anatomical structures nor applicable to meet the demand of high-fidelity reconstructions in modern MRI. Inspired by the state-of-the-art methods in image generation, we propose a novel attention-based deep learning framework to provide high-quality MRI reconstruction. We incorporate large-field contextual feature integration and attention selection in a generative adversarial network (GAN) framework. We demonstrate that the proposed model can produce superior results compared to other deep learning-based methods in terms of image quality, and relevance to the MRI reconstruction in an extremely low sampling rate diet.

</p>
</details>

<details><summary><b>Learning Optimal Decision Making for an Industrial Truck Unloading Robot using Minimal Simulator Runs</b>
<a href="https://arxiv.org/abs/2105.05019">arxiv:2105.05019</a>
&#x1F4C8; 2 <br>
<p>Manash Pratim Das, Anirudh Vemula, Mayank Pathak, Sandip Aine, Maxim Likhachev</p></summary>
<p>

**Abstract:** Consider a truck filled with boxes of varying size and unknown mass and an industrial robot with end-effectors that can unload multiple boxes from any reachable location. In this work, we investigate how would the robot with the help of a simulator, learn to maximize the number of boxes unloaded by each action. Most high-fidelity robotic simulators like ours are time-consuming. Therefore, we investigate the above learning problem with a focus on minimizing the number of simulation runs required. The optimal decision-making problem under this setting can be formulated as a multi-class classification problem. However, to obtain the outcome of any action requires us to run the time-consuming simulator, thereby restricting the amount of training data that can be collected. Thus, we need a data-efficient approach to learn the classifier and generalize it with a minimal amount of data. A high-fidelity physics-based simulator is common in general for complex manipulation tasks involving multi-body interactions. To this end, we train an optimal decision tree as the classifier, and for each branch of the decision tree, we reason about the confidence in the decision using a Probably Approximately Correct (PAC) framework to determine whether more simulator data will help reach a certain confidence level. This provides us with a mechanism to evaluate when simulation can be avoided for certain decisions, and when simulation will improve the decision making. For the truck unloading problem, our experiments show that a significant reduction in simulator runs can be achieved using the proposed method as compared to naively running the simulator to collect data to train equally performing decision trees.

</p>
</details>

<details><summary><b>A Novel Visualization System of Using Augmented Reality in Knee Replacement Surgery: Enhanced Bidirectional Maximum Correntropy Algorithm</b>
<a href="https://arxiv.org/abs/2104.05742">arxiv:2104.05742</a>
&#x1F4C8; 2 <br>
<p>Nitish Maharjan, Abeer Alsadoon, P. W. C. Prasad, Salma Abdullah, Tarik A. Rashid</p></summary>
<p>

**Abstract:** Background and aim: Image registration and alignment are the main limitations of augmented reality-based knee replacement surgery. This research aims to decrease the registration error, eliminate outcomes that are trapped in local minima to improve the alignment problems, handle the occlusion, and maximize the overlapping parts. Methodology: markerless image registration method was used for Augmented reality-based knee replacement surgery to guide and visualize the surgical operation. While weight least square algorithm was used to enhance stereo camera-based tracking by filling border occlusion in right to left direction and non-border occlusion from left to right direction. Results: This study has improved video precision to 0.57 mm~0.61 mm alignment error. Furthermore, with the use of bidirectional points, for example, forwards and backwards directional cloud point, the iteration on image registration was decreased. This has led to improve the processing time as well. The processing time of video frames was improved to 7.4~11.74 fps. Conclusions: It seems clear that this proposed system has focused on overcoming the misalignment difficulty caused by movement of patient and enhancing the AR visualization during knee replacement surgery. The proposed system was reliable and favorable which helps in eliminating alignment error by ascertaining the optimal rigid transformation between two cloud points and removing the outliers and non-Gaussian noise. The proposed augmented reality system helps in accurate visualization and navigation of anatomy of knee such as femur, tibia, cartilage, blood vessels, etc.

</p>
</details>

<details><summary><b>Impact of the COVID-19 outbreak on Italy's country reputation and stock market performance: a sentiment analysis approach</b>
<a href="https://arxiv.org/abs/2103.13871">arxiv:2103.13871</a>
&#x1F4C8; 2 <br>
<p>Gianpaolo Zammarchi, Francesco Mola, Claudio Conversano</p></summary>
<p>

**Abstract:** During the recent Coronavirus disease 2019 (COVID-19) outbreak, the microblogging service Twitter has been widely used to share opinions and reactions to events. Italy was one of the first European countries to be severely affected by the outbreak and to establish lockdown and stay-at-home orders, potentially leading to country reputation damage. We resort to sentiment analysis to investigate changes in opinions about Italy reported on Twitter before and after the COVID-19 outbreak. Using different lexicons-based methods, we find a breakpoint corresponding to the date of the first established case of COVID-19 in Italy that causes a relevant change in sentiment scores used as proxy of the country reputation. Next, we demonstrate that sentiment scores about Italy are strongly associated with the levels of the FTSE-MIB index, the Italian Stock Exchange main index, as they serve as early detection signals of changes in the values of FTSE-MIB. Finally, we make a content-based classification of tweets into positive and negative and use two machine learning classifiers to validate the assigned polarity of tweets posted before and after the outbreak.

</p>
</details>

<details><summary><b>CACTUS: Detecting and Resolving Conflicts in Objective Functions</b>
<a href="https://arxiv.org/abs/2103.07805">arxiv:2103.07805</a>
&#x1F4C8; 2 <br>
<p>Subhajit Das, Alex Endert</p></summary>
<p>

**Abstract:** Machine learning (ML) models are constructed by expert ML practitioners using various coding languages, in which they tune and select models hyperparameters and learning algorithms for a given problem domain. They also carefully design an objective function or loss function (often with multiple objectives) that captures the desired output for a given ML task such as classification, regression, etc. In multi-objective optimization, conflicting objectives and constraints is a major area of concern. In such problems, several competing objectives are seen for which no single optimal solution is found that satisfies all desired objectives simultaneously. In the past VA systems have allowed users to interactively construct objective functions for a classifier. In this paper, we extend this line of work by prototyping a technique to visualize multi-objective objective functions either defined in a Jupyter notebook or defined using an interactive visual interface to help users to: (1) perceive and interpret complex mathematical terms in it and (2) detect and resolve conflicting objectives. Visualization of the objective function enlightens potentially conflicting objectives that obstructs selecting correct solution(s) for the desired ML task or goal. We also present an enumeration of potential conflicts in objective specification in multi-objective objective functions for classifier selection. Furthermore, we demonstrate our approach in a VA system that helps users in specifying meaningful objective functions to a classifier by detecting and resolving conflicting objectives and constraints. Through a within-subject quantitative and qualitative user study, we present results showing that our technique helps users interactively specify meaningful objective functions by resolving potential conflicts for a classification task.

</p>
</details>

<details><summary><b>Hybrid computer approach to train a machine learning system</b>
<a href="https://arxiv.org/abs/2103.07802">arxiv:2103.07802</a>
&#x1F4C8; 2 <br>
<p>Mirko Holzer, Bernd Ulmann</p></summary>
<p>

**Abstract:** This book chapter describes a novel approach to training machine learning systems by means of a hybrid computer setup i.e. a digital computer tightly coupled with an analog computer. As an example a reinforcement learning system is trained to balance an inverted pendulum which is simulated on an analog computer, thus demonstrating a solution to the major challenge of adequately simulating the environment for reinforcement learning.

</p>
</details>

<details><summary><b>Recommending Short-lived Dynamic Packages for Golf Booking Services</b>
<a href="https://arxiv.org/abs/2103.07779">arxiv:2103.07779</a>
&#x1F4C8; 2 <br>
<p>Robin Swezey, Young-joo Chung</p></summary>
<p>

**Abstract:** We introduce an approach to recommending short-lived dynamic packages for golf booking services. Two challenges are addressed in this work. The first is the short life of the items, which puts the system in a state of a permanent cold start. The second is the uninformative nature of the package attributes, which makes clustering or figuring latent packages challenging. Although such settings are fairly pervasive, they have not been studied in traditional recommendation research, and there is thus a call for original approaches for recommender systems. In this paper, we introduce a hybrid method that leverages user analysis and its relation to the packages, as well as package pricing and environmental analysis, and traditional collaborative filtering. The proposed approach achieved appreciable improvement in precision compared with baselines.

</p>
</details>

<details><summary><b>Problem-fluent models for complex decision-making in autonomous materials research</b>
<a href="https://arxiv.org/abs/2103.07776">arxiv:2103.07776</a>
&#x1F4C8; 2 <br>
<p>Soojung Baek, Kristofer G. Reyes</p></summary>
<p>

**Abstract:** We review our recent work in the area of autonomous materials research, highlighting the coupling of machine learning methods and models and more problem-aware modeling. We review the general Bayesian framework for closed-loop design employed by many autonomous materials platforms. We then provide examples of our work on such platforms. We finally review our approaches to extend current statistical and ML models to better reflect problem-specific structure including the use of physics-based models and incorporation of operational considerations into the decision-making procedure.

</p>
</details>

<details><summary><b>Large-scale Recommendation for Portfolio Optimization</b>
<a href="https://arxiv.org/abs/2103.07768">arxiv:2103.07768</a>
&#x1F4C8; 2 <br>
<p>Robin Swezey, Bruno Charron</p></summary>
<p>

**Abstract:** Individual investors are now massively using online brokers to trade stocks with convenient interfaces and low fees, albeit losing the advice and personalization traditionally provided by full-service brokers. We frame the problem faced by online brokers of replicating this level of service in a low-cost and automated manner for a very large number of users. Because of the care required in recommending financial products, we focus on a risk-management approach tailored to each user's portfolio and risk profile. We show that our hybrid approach, based on Modern Portfolio Theory and Collaborative Filtering, provides a sound and effective solution. The method is applicable to stocks as well as other financial assets, and can be easily combined with various financial forecasting models. We validate our proposal by comparing it with several baselines in a domain expert-based study.

</p>
</details>

<details><summary><b>Learning Novel Objects Continually Through Curiosity</b>
<a href="https://arxiv.org/abs/2103.07758">arxiv:2103.07758</a>
&#x1F4C8; 2 <br>
<p>Ali Ayub, Alan R. Wagner</p></summary>
<p>

**Abstract:** Children learn continually by asking questions about the concepts they are most curious about. With robots becoming an integral part of our society, they must also learn unknown concepts continually by asking humans questions. The paper analyzes a recent state-of-the-art approach for continual learning. The paper further develops a self-supervised technique to find most of the uncertain objects in an environment by utilizing the cluster representation of the previously learned classes. We test our approach on a benchmark dataset for continual learning on robots. Our results show that our curiosity-driven continual learning approach beats random sampling and softmax-based uncertainty sampling in terms of classification accuracy and the total number of classes learned.

</p>
</details>

<details><summary><b>Image Segmentation Methods for Non-destructive testing Applications</b>
<a href="https://arxiv.org/abs/2103.07754">arxiv:2103.07754</a>
&#x1F4C8; 2 <br>
<p>EL-Hachemi Guerrout, Ramdane Mahiou, Randa Boukabene, Assia Ouali</p></summary>
<p>

**Abstract:** In this paper, we present new image segmentation methods based on hidden Markov random fields (HMRFs) and cuckoo search (CS) variants. HMRFs model the segmentation problem as a minimization of an energy function. CS algorithm is one of the recent powerful optimization techniques. Therefore, five variants of the CS algorithm are used to compute a solution. Through tests, we conduct a study to choose the CS variant with parameters that give good results (execution time and quality of segmentation). CS variants are evaluated and compared with non-destructive testing (NDT) images using a misclassification error (ME) criterion.

</p>
</details>

<details><summary><b>uTHCD: A New Benchmarking for Tamil Handwritten OCR</b>
<a href="https://arxiv.org/abs/2103.07676">arxiv:2103.07676</a>
&#x1F4C8; 2 <br>
<p>Noushath Shaffi, Faizal Hajamohideen</p></summary>
<p>

**Abstract:** Handwritten character recognition is a challenging research in the field of document image analysis over many decades due to numerous reasons such as large writing styles variation, inherent noise in data, expansive applications it offers, non-availability of benchmark databases etc. There has been considerable work reported in literature about creation of the database for several Indic scripts but the Tamil script is still in its infancy as it has been reported only in one database [5]. In this paper, we present the work done in the creation of an exhaustive and large unconstrained Tamil Handwritten Character Database (uTHCD). Database consists of around 91000 samples with nearly 600 samples in each of 156 classes. The database is a unified collection of both online and offline samples. Offline samples were collected by asking volunteers to write samples on a form inside a specified grid. For online samples, we made the volunteers write in a similar grid using a digital writing pad. The samples collected encompass a vast variety of writing styles, inherent distortions arising from offline scanning process viz stroke discontinuity, variable thickness of stroke, distortion etc. Algorithms which are resilient to such data can be practically deployed for real time applications. The samples were generated from around 650 native Tamil volunteers including school going kids, homemakers, university students and faculty. The isolated character database will be made publicly available as raw images and Hierarchical Data File (HDF) compressed file. With this database, we expect to set a new benchmark in Tamil handwritten character recognition and serve as a launchpad for many avenues in document image analysis domain. Paper also presents an ideal experimental set-up using the database on convolutional neural networks (CNN) with a baseline accuracy of 88% on test data.

</p>
</details>

<details><summary><b>Efficient Sparse Artificial Neural Networks</b>
<a href="https://arxiv.org/abs/2103.07674">arxiv:2103.07674</a>
&#x1F4C8; 2 <br>
<p>Seyed Majid Naji, Azra Abtahi, Farokh Marvasti</p></summary>
<p>

**Abstract:** The brain, as the source of inspiration for Artificial Neural Networks (ANN), is based on a sparse structure. This sparse structure helps the brain to consume less energy, learn easier and generalize patterns better than any other ANN. In this paper, two evolutionary methods for adopting sparsity to ANNs are proposed. In the proposed methods, the sparse structure of a network as well as the values of its parameters are trained and updated during the learning process. The simulation results show that these two methods have better accuracy and faster convergence while they need fewer training samples compared to their sparse and non-sparse counterparts. Furthermore, the proposed methods significantly improve the generalization power and reduce the number of parameters. For example, the sparsification of the ResNet47 network by exploiting our proposed methods for the image classification of ImageNet dataset uses 40 % fewer parameters while the top-1 accuracy of the model improves by 12% and 5% compared to the dense network and their sparse counterpart, respectively. As another example, the proposed methods for the CIFAR10 dataset converge to their final structure 7 times faster than its sparse counterpart, while the final accuracy increases by 6%.

</p>
</details>

<details><summary><b>Ensemble Learning with Manifold-Based Data Splitting for Noisy Label Correction</b>
<a href="https://arxiv.org/abs/2103.07641">arxiv:2103.07641</a>
&#x1F4C8; 2 <br>
<p>Hao-Chiang Shao, Hsin-Chieh Wang, Weng-Tai Su, Chia-Wen Lin</p></summary>
<p>

**Abstract:** Label noise in training data can significantly degrade a model's generalization performance for supervised learning tasks. Here we focus on the problem that noisy labels are primarily mislabeled samples, which tend to be concentrated near decision boundaries, rather than uniformly distributed, and whose features should be equivocal. To address the problem, we propose an ensemble learning method to correct noisy labels by exploiting the local structures of feature manifolds. Different from typical ensemble strategies that increase the prediction diversity among sub-models via certain loss terms, our method trains sub-models on disjoint subsets, each being a union of the nearest-neighbors of randomly selected seed samples on the data manifold. As a result, each sub-model can learn a coarse representation of the data manifold along with a corresponding graph. Moreover, only a limited number of sub-models will be affected by locally-concentrated noisy labels. The constructed graphs are used to suggest a series of label correction candidates, and accordingly, our method derives label correction results by voting down inconsistent suggestions. Our experiments on real-world noisy label datasets demonstrate the superiority of the proposed method over existing state-of-the-arts.

</p>
</details>

<details><summary><b>Generating Unrestricted Adversarial Examples via Three Parameters</b>
<a href="https://arxiv.org/abs/2103.07640">arxiv:2103.07640</a>
&#x1F4C8; 2 <br>
<p>Hanieh Naderi, Leili Goli, Shohreh Kasaei</p></summary>
<p>

**Abstract:** Deep neural networks have been shown to be vulnerable to adversarial examples deliberately constructed to misclassify victim models. As most adversarial examples have restricted their perturbations to $L_{p}$-norm, existing defense methods have focused on these types of perturbations and less attention has been paid to unrestricted adversarial examples; which can create more realistic attacks, able to deceive models without affecting human predictions. To address this problem, the proposed adversarial attack generates an unrestricted adversarial example with a limited number of parameters. The attack selects three points on the input image and based on their locations transforms the image into an adversarial example. By limiting the range of movement and location of these three points and using a discriminatory network, the proposed unrestricted adversarial example preserves the image appearance. Experimental results show that the proposed adversarial examples obtain an average success rate of 93.5% in terms of human evaluation on the MNIST and SVHN datasets. It also reduces the model accuracy by an average of 73% on six datasets MNIST, FMNIST, SVHN, CIFAR10, CIFAR100, and ImageNet. It should be noted that, in the case of attacks, lower accuracy in the victim model denotes a more successful attack. The adversarial train of the attack also improves model robustness against a randomly transformed image.

</p>
</details>

<details><summary><b>Helmholtzian Eigenmap: Topological feature discovery & edge flow learning from point cloud data</b>
<a href="https://arxiv.org/abs/2103.07626">arxiv:2103.07626</a>
&#x1F4C8; 2 <br>
<p>Yu-Chia Chen, Marina Meilă, Ioannis G. Kevrekidis</p></summary>
<p>

**Abstract:** The manifold Helmholtzian (1-Laplacian) operator $Δ_1$ elegantly generalizes the Laplace-Beltrami operator to vector fields on a manifold $\mathcal M$. In this work, we propose the estimation of the manifold Helmholtzian from point cloud data by a weighted 1-Laplacian $\mathbf{\mathcal L}_1$. While higher order Laplacians ave been introduced and studied, this work is the first to present a graph Helmholtzian constructed from a simplicial complex as an estimator for the continuous operator in a non-parametric setting. Equipped with the geometric and topological information about $\mathcal M$, the Helmholtzian is a useful tool for the analysis of flows and vector fields on $\mathcal M$ via the Helmholtz-Hodge theorem. In addition, the $\mathbf{\mathcal L}_1$ allows the smoothing, prediction, and feature extraction of the flows. We demonstrate these possibilities on substantial sets of synthetic and real point cloud datasets with non-trivial topological structures; and provide theoretical results on the limit of $\mathbf{\mathcal L}_1$ to $Δ_1$.

</p>
</details>

<details><summary><b>Early Prediction and Diagnosis of Retinoblastoma Using Deep Learning Techniques</b>
<a href="https://arxiv.org/abs/2103.07622">arxiv:2103.07622</a>
&#x1F4C8; 2 <br>
<p>C. Anand Deva Durai, T Jemima Jebaseeli, Salem Alelyani, Azath Mubharakali</p></summary>
<p>

**Abstract:** Retinoblastoma is the most prominent childhood primary intraocular malignancy that impacts the vision of children and adults worldwide. In contrasting and comparing with adults it is uveal melanoma. It is an aggressive tumor that can fill and destroy the eye and the surrounding structures. Therefore early detection of retinoblastoma in childhood is the key. The major impact of the research is to identify the tumor cells in the retina. Also is to find out the stages of the tumor and its corresponding group. The proposed systems assist the ophthalmologists for accurate prediction and diagnosis of retinoblastoma cancer disease at the earliest. The contribution of the proposed approach is to save the life of infants and the grown-up children from vision impairment. The proposed methodology consists of three phases namely, preprocessing, segmentation, and classification. Initially, the fundus images are preprocessed using the Liner Predictive Decision based Median Filter (LPDMF). It removes the noise introduced in the image due to illumination while capturing or scanning the eye of the patients. The preprocessed images are segmented using the Convolutional Neural Network (CNN) to distinguish the foreground tumor cells from the background.

</p>
</details>

<details><summary><b>VMAF And Variants: Towards A Unified VQA</b>
<a href="https://arxiv.org/abs/2103.07770">arxiv:2103.07770</a>
&#x1F4C8; 1 <br>
<p>Pankaj Topiwala, Wei Dai, Jiangfeng Pian, Katalina Biondi, Arvind Krovvidi</p></summary>
<p>

**Abstract:** Video quality assessment (VQA) is now a fast-growing subject, maturing in the full reference (FR) case, yet challenging in the exploding no reference (NR) case. We investigate variants of the popular VMAF video quality assessment algorithm for the FR case, using both support vector regression and feedforward neural networks. We extend it to the NR case, using some different features but similar learning, to develop a partially unified framework for VQA. When fully trained, FR algorithms such as VMAF perform very well on test datasets, reaching 90%+ match in PCC and SRCC; but for predicting performance in the wild, we train/test from scratch for each database. With an 80/20 train/test split, we still achieve about 90% performance on average in both PCC and SRCC, with up to 7-9% gains over VMAF, using an improved motion feature and better regression. Moreover, we even get decent performance (about 75%) if we ignore the reference, treating FR as NR, partly justifying our attempts at unification. In the true NR case, we reduce complexity vs. leading recent algorithms VIDEVAL, RAPIQUE, yet achieve performance within 3-5%. Moreover, we develop a method to analyze the saliency of features, and conclude that for both VIDEVAL and RAPIQUE, a small subset of their features are providing the bulk of the performance. In short, we find encouraging improvements in trainability in FR, while constraining training complexity against leading methods in NR, elucidating the saliency of features for feature selection.

</p>
</details>

<details><summary><b>Spatio-temporal Modeling for Large-scale Vehicular Networks Using Graph Convolutional Networks</b>
<a href="https://arxiv.org/abs/2103.07636">arxiv:2103.07636</a>
&#x1F4C8; 1 <br>
<p>Juntong Liu, Yong Xiao, Yingyu Li, Guangming Shiyz, Walid Saad, H. Vincent Poor</p></summary>
<p>

**Abstract:** The effective deployment of connected vehicular networks is contingent upon maintaining a desired performance across spatial and temporal domains. In this paper, a graph-based framework, called SMART, is proposed to model and keep track of the spatial and temporal statistics of vehicle-to-infrastructure (V2I) communication latency across a large geographical area. SMART first formulates the spatio-temporal performance of a vehicular network as a graph in which each vertex corresponds to a subregion consisting of a set of neighboring location points with similar statistical features of V2I latency and each edge represents the spatio-correlation between latency statistics of two connected vertices. Motivated by the observation that the complete temporal and spatial latency performance of a vehicular network can be reconstructed from a limited number of vertices and edge relations, we develop a graph reconstruction-based approach using a graph convolutional network integrated with a deep Q-networks algorithm in order to capture the spatial and temporal statistic of feature map pf latency performance for a large-scale vehicular network. Extensive simulations have been conducted based on a five-month latency measurement study on a commercial LTE network. Our results show that the proposed method can significantly improve both the accuracy and efficiency for modeling and reconstructing the latency performance of large vehicular networks.

</p>
</details>

<details><summary><b>Attack as Defense: Characterizing Adversarial Examples using Robustness</b>
<a href="https://arxiv.org/abs/2103.07633">arxiv:2103.07633</a>
&#x1F4C8; 1 <br>
<p>Zhe Zhao, Guangke Chen, Jingyi Wang, Yiwei Yang, Fu Song, Jun Sun</p></summary>
<p>

**Abstract:** As a new programming paradigm, deep learning has expanded its application to many real-world problems. At the same time, deep learning based software are found to be vulnerable to adversarial attacks. Though various defense mechanisms have been proposed to improve robustness of deep learning software, many of them are ineffective against adaptive attacks. In this work, we propose a novel characterization to distinguish adversarial examples from benign ones based on the observation that adversarial examples are significantly less robust than benign ones. As existing robustness measurement does not scale to large networks, we propose a novel defense framework, named attack as defense (A2D), to detect adversarial examples by effectively evaluating an example's robustness. A2D uses the cost of attacking an input for robustness evaluation and identifies those less robust examples as adversarial since less robust examples are easier to attack. Extensive experiment results on MNIST, CIFAR10 and ImageNet show that A2D is more effective than recent promising approaches. We also evaluate our defence against potential adaptive attacks and show that A2D is effective in defending carefully designed adaptive attacks, e.g., the attack success rate drops to 0% on CIFAR10.

</p>
</details>

<details><summary><b>A novel weighted approach for time series forecasting based on visibility graph</b>
<a href="https://arxiv.org/abs/2103.13870">arxiv:2103.13870</a>
&#x1F4C8; 0 <br>
<p>Tianxiang Zhan, Fuyuan Xiao</p></summary>
<p>

**Abstract:** Time series have attracted widespread attention in many fields today. Based on the analysis of complex networks and visibility graph theory, a new time series forecasting method is proposed. In time series analysis, visibility graph theory transforms time series data into a network model. In the network model, the node similarity index is an important factor. On the basis of directly using the node prediction method with the largest similarity, the node similarity index is used as the weight coefficient to optimize the prediction algorithm. Compared with the single-node sampling node prediction algorithm, the multi-node sampling prediction algorithm can provide more accurate prediction values when the data set is sufficient. According to results of experiments on four real-world representative datasets, the method has more accurate forecasting ability and can provide more accurate forecasts in the field of time series and actual scenes.

</p>
</details>


[Next Page](2021/2021-03/2021-03-12.md)
