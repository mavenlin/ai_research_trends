## Summary for 2021-04-22, created on 2021-12-22


<details><summary><b>Multiscale Vision Transformers</b>
<a href="https://arxiv.org/abs/2104.11227">arxiv:2104.11227</a>
&#x1F4C8; 574 <br>
<p>Haoqi Fan, Bo Xiong, Karttikeya Mangalam, Yanghao Li, Zhicheng Yan, Jitendra Malik, Christoph Feichtenhofer</p></summary>
<p>

**Abstract:** We present Multiscale Vision Transformers (MViT) for video and image recognition, by connecting the seminal idea of multiscale feature hierarchies with transformer models. Multiscale Transformers have several channel-resolution scale stages. Starting from the input resolution and a small channel dimension, the stages hierarchically expand the channel capacity while reducing the spatial resolution. This creates a multiscale pyramid of features with early layers operating at high spatial resolution to model simple low-level visual information, and deeper layers at spatially coarse, but complex, high-dimensional features. We evaluate this fundamental architectural prior for modeling the dense nature of visual signals for a variety of video recognition tasks where it outperforms concurrent vision transformers that rely on large scale external pre-training and are 5-10x more costly in computation and parameters. We further remove the temporal dimension and apply our model for image classification where it outperforms prior work on vision transformers. Code is available at: https://github.com/facebookresearch/SlowFast

</p>
</details>

<details><summary><b>VATT: Transformers for Multimodal Self-Supervised Learning from Raw Video, Audio and Text</b>
<a href="https://arxiv.org/abs/2104.11178">arxiv:2104.11178</a>
&#x1F4C8; 183 <br>
<p>Hassan Akbari, Liangzhe Yuan, Rui Qian, Wei-Hong Chuang, Shih-Fu Chang, Yin Cui, Boqing Gong</p></summary>
<p>

**Abstract:** We present a framework for learning multimodal representations from unlabeled data using convolution-free Transformer architectures. Specifically, our Video-Audio-Text Transformer (VATT) takes raw signals as inputs and extracts multimodal representations that are rich enough to benefit a variety of downstream tasks. We train VATT end-to-end from scratch using multimodal contrastive losses and evaluate its performance by the downstream tasks of video action recognition, audio event classification, image classification, and text-to-video retrieval. Furthermore, we study a modality-agnostic, single-backbone Transformer by sharing weights among the three modalities. We show that the convolution-free VATT outperforms state-of-the-art ConvNet-based architectures in the downstream tasks. Especially, VATT's vision Transformer achieves the top-1 accuracy of 82.1% on Kinetics-400, 83.6% on Kinetics-600, 72.7% on Kinetics-700, and 41.1% on Moments in Time, new records while avoiding supervised pre-training. Transferring to image classification leads to 78.7% top-1 accuracy on ImageNet compared to 64.7% by training the same Transformer from scratch, showing the generalizability of our model despite the domain gap between videos and images. VATT's audio Transformer also sets a new record on waveform-based audio event recognition by achieving the mAP of 39.4% on AudioSet without any supervised pre-training. VATT's source code is publicly available.

</p>
</details>

<details><summary><b>ImageNet-21K Pretraining for the Masses</b>
<a href="https://arxiv.org/abs/2104.10972">arxiv:2104.10972</a>
&#x1F4C8; 42 <br>
<p>Tal Ridnik, Emanuel Ben-Baruch, Asaf Noy, Lihi Zelnik-Manor</p></summary>
<p>

**Abstract:** ImageNet-1K serves as the primary dataset for pretraining deep learning models for computer vision tasks. ImageNet-21K dataset, which is bigger and more diverse, is used less frequently for pretraining, mainly due to its complexity, low accessibility, and underestimation of its added value. This paper aims to close this gap, and make high-quality efficient pretraining on ImageNet-21K available for everyone. Via a dedicated preprocessing stage, utilization of WordNet hierarchical structure, and a novel training scheme called semantic softmax, we show that various models significantly benefit from ImageNet-21K pretraining on numerous datasets and tasks, including small mobile-oriented models. We also show that we outperform previous ImageNet-21K pretraining schemes for prominent new models like ViT and Mixer. Our proposed pretraining pipeline is efficient, accessible, and leads to SoTA reproducible results, from a publicly available dataset. The training code and pretrained models are available at: https://github.com/Alibaba-MIIL/ImageNet21K

</p>
</details>

<details><summary><b>Pose-Controllable Talking Face Generation by Implicitly Modularized Audio-Visual Representation</b>
<a href="https://arxiv.org/abs/2104.11116">arxiv:2104.11116</a>
&#x1F4C8; 34 <br>
<p>Hang Zhou, Yasheng Sun, Wayne Wu, Chen Change Loy, Xiaogang Wang, Ziwei Liu</p></summary>
<p>

**Abstract:** While accurate lip synchronization has been achieved for arbitrary-subject audio-driven talking face generation, the problem of how to efficiently drive the head pose remains. Previous methods rely on pre-estimated structural information such as landmarks and 3D parameters, aiming to generate personalized rhythmic movements. However, the inaccuracy of such estimated information under extreme conditions would lead to degradation problems. In this paper, we propose a clean yet effective framework to generate pose-controllable talking faces. We operate on raw face images, using only a single photo as an identity reference. The key is to modularize audio-visual representations by devising an implicit low-dimension pose code. Substantially, both speech content and head pose information lie in a joint non-identity embedding space. While speech content information can be defined by learning the intrinsic synchronization between audio-visual modalities, we identify that a pose code will be complementarily learned in a modulated convolution-based reconstruction framework.
  Extensive experiments show that our method generates accurately lip-synced talking faces whose poses are controllable by other videos. Moreover, our model has multiple advanced capabilities including extreme view robustness and talking face frontalization. Code, models, and demo videos are available at https://hangz-nju-cuhk.github.io/projects/PC-AVS.

</p>
</details>

<details><summary><b>Network Space Search for Pareto-Efficient Spaces</b>
<a href="https://arxiv.org/abs/2104.11014">arxiv:2104.11014</a>
&#x1F4C8; 30 <br>
<p>Min-Fong Hong, Hao-Yun Chen, Min-Hung Chen, Yu-Syuan Xu, Hsien-Kai Kuo, Yi-Min Tsai, Hung-Jen Chen, Kevin Jou</p></summary>
<p>

**Abstract:** Network spaces have been known as a critical factor in both handcrafted network designs or defining search spaces for Neural Architecture Search (NAS). However, an effective space involves tremendous prior knowledge and/or manual effort, and additional constraints are required to discover efficiency-aware architectures. In this paper, we define a new problem, Network Space Search (NSS), as searching for favorable network spaces instead of a single architecture. We propose an NSS method to directly search for efficient-aware network spaces automatically, reducing the manual effort and immense cost in discovering satisfactory ones. The resultant network spaces, named Elite Spaces, are discovered from Expanded Search Space with minimal human expertise imposed. The Pareto-efficient Elite Spaces are aligned with the Pareto front under various complexity constraints and can be further served as NAS search spaces, benefiting differentiable NAS approaches (e.g. In CIFAR-100, an averagely 2.3% lower error rate and 3.7% closer to target constraint than the baseline with around 90% fewer samples required to find satisfactory networks). Moreover, our NSS approach is capable of searching for superior spaces in future unexplored spaces, revealing great potential in searching for network spaces automatically. Website: https://minhungchen.netlify.app/publication/nss.

</p>
</details>

<details><summary><b>Hierarchical growing grid networks for skeleton based action recognition</b>
<a href="https://arxiv.org/abs/2104.11165">arxiv:2104.11165</a>
&#x1F4C8; 28 <br>
<p>Zahra Gharaee</p></summary>
<p>

**Abstract:** In this paper, a novel cognitive architecture for action recognition is developed by applying layers of growing grid neural networks.Using these layers makes the system capable of automatically arranging its representational structure. In addition to the expansion of the neural map during the growth phase, the system is provided with a prior knowledge of the input space, which increases the processing speed of the learning phase. Apart from two layers of growing grid networks the architecture is composed of a preprocessing layer, an ordered vector representation layer and a one-layer supervised neural network. These layers are designed to solve the action recognition problem. The first-layer growing grid receives the input data of human actions and the neural map generates an action pattern vector representing each action sequence by connecting the elicited activation of the trained map. The pattern vectors are then sent to the ordered vector representation layer to build the time-invariant input vectors of key activations for the second-layer growing grid. The second-layer growing grid categorizes the input vectors to the corresponding action clusters/sub-clusters and finally the one-layer supervised neural network labels the shaped clusters with action labels. Three experiments using different datasets of actions show that the system is capable of learning to categorize the actions quickly and efficiently. The performance of the growing grid architecture is com-pared with the results from a system based on Self-Organizing Maps, showing that the growing grid architecture performs significantly superior on the action recognition tasks.

</p>
</details>

<details><summary><b>On Buggy Resizing Libraries and Surprising Subtleties in FID Calculation</b>
<a href="https://arxiv.org/abs/2104.11222">arxiv:2104.11222</a>
&#x1F4C8; 22 <br>
<p>Gaurav Parmar, Richard Zhang, Jun-Yan Zhu</p></summary>
<p>

**Abstract:** We investigate the sensitivity of the Fréchet Inception Distance (FID) score to inconsistent and often incorrect implementations across different image processing libraries. FID score is widely used to evaluate generative models, but each FID implementation uses a different low-level image processing process. Image resizing functions in commonly-used deep learning libraries often introduce aliasing artifacts. We observe that numerous subtle choices need to be made for FID calculation and a lack of consistencies in these choices can lead to vastly different FID scores. In particular, we show that the following choices are significant: (1) selecting what image resizing library to use, (2) choosing what interpolation kernel to use, (3) what encoding to use when representing images. We additionally outline numerous common pitfalls that should be avoided and provide recommendations for computing the FID score accurately. We provide an easy-to-use optimized implementation of our proposed recommendations in the accompanying code.

</p>
</details>

<details><summary><b>FCOS3D: Fully Convolutional One-Stage Monocular 3D Object Detection</b>
<a href="https://arxiv.org/abs/2104.10956">arxiv:2104.10956</a>
&#x1F4C8; 22 <br>
<p>Tai Wang, Xinge Zhu, Jiangmiao Pang, Dahua Lin</p></summary>
<p>

**Abstract:** Monocular 3D object detection is an important task for autonomous driving considering its advantage of low cost. It is much more challenging than conventional 2D cases due to its inherent ill-posed property, which is mainly reflected in the lack of depth information. Recent progress on 2D detection offers opportunities to better solving this problem. However, it is non-trivial to make a general adapted 2D detector work in this 3D task. In this paper, we study this problem with a practice built on a fully convolutional single-stage detector and propose a general framework FCOS3D. Specifically, we first transform the commonly defined 7-DoF 3D targets to the image domain and decouple them as 2D and 3D attributes. Then the objects are distributed to different feature levels with consideration of their 2D scales and assigned only according to the projected 3D-center for the training procedure. Furthermore, the center-ness is redefined with a 2D Gaussian distribution based on the 3D-center to fit the 3D target formulation. All of these make this framework simple yet effective, getting rid of any 2D detection or 2D-3D correspondence priors. Our solution achieves 1st place out of all the vision-only methods in the nuScenes 3D detection challenge of NeurIPS 2020. Code and models are released at https://github.com/open-mmlab/mmdetection3d.

</p>
</details>

<details><summary><b>CryptGPU: Fast Privacy-Preserving Machine Learning on the GPU</b>
<a href="https://arxiv.org/abs/2104.10949">arxiv:2104.10949</a>
&#x1F4C8; 21 <br>
<p>Sijun Tan, Brian Knott, Yuan Tian, David J. Wu</p></summary>
<p>

**Abstract:** We introduce CryptGPU, a system for privacy-preserving machine learning that implements all operations on the GPU (graphics processing unit). Just as GPUs played a pivotal role in the success of modern deep learning, they are also essential for realizing scalable privacy-preserving deep learning. In this work, we start by introducing a new interface to losslessly embed cryptographic operations over secret-shared values (in a discrete domain) into floating-point operations that can be processed by highly-optimized CUDA kernels for linear algebra. We then identify a sequence of "GPU-friendly" cryptographic protocols to enable privacy-preserving evaluation of both linear and non-linear operations on the GPU. Our microbenchmarks indicate that our private GPU-based convolution protocol is over 150x faster than the analogous CPU-based protocol; for non-linear operations like the ReLU activation function, our GPU-based protocol is around 10x faster than its CPU analog.
  With CryptGPU, we support private inference and private training on convolutional neural networks with over 60 million parameters as well as handle large datasets like ImageNet. Compared to the previous state-of-the-art, when considering large models and datasets, our protocols achieve a 2x to 8x improvement in private inference and a 6x to 36x improvement for private training. Our work not only showcases the viability of performing secure multiparty computation (MPC) entirely on the GPU to enable fast privacy-preserving machine learning, but also highlights the importance of designing new MPC primitives that can take full advantage of the GPU's computing capabilities.

</p>
</details>

<details><summary><b>Hierarchical Motion Understanding via Motion Programs</b>
<a href="https://arxiv.org/abs/2104.11216">arxiv:2104.11216</a>
&#x1F4C8; 17 <br>
<p>Sumith Kulal, Jiayuan Mao, Alex Aiken, Jiajun Wu</p></summary>
<p>

**Abstract:** Current approaches to video analysis of human motion focus on raw pixels or keypoints as the basic units of reasoning. We posit that adding higher-level motion primitives, which can capture natural coarser units of motion such as backswing or follow-through, can be used to improve downstream analysis tasks. This higher level of abstraction can also capture key features, such as loops of repeated primitives, that are currently inaccessible at lower levels of representation. We therefore introduce Motion Programs, a neuro-symbolic, program-like representation that expresses motions as a composition of high-level primitives. We also present a system for automatically inducing motion programs from videos of human motion and for leveraging motion programs in video synthesis. Experiments show that motion programs can accurately describe a diverse set of human motions and the inferred programs contain semantically meaningful motion primitives, such as arm swings and jumping jacks. Our representation also benefits downstream tasks such as video interpolation and video prediction and outperforms off-the-shelf models. We further demonstrate how these programs can detect diverse kinds of repetitive motion and facilitate interactive video editing.

</p>
</details>

<details><summary><b>Compressive lensless endoscopy with partial speckle scanning</b>
<a href="https://arxiv.org/abs/2104.10959">arxiv:2104.10959</a>
&#x1F4C8; 16 <br>
<p>Stéphanie Guérit, Siddharth Sivankutty, John Aldo Lee, Hervé Rigneault, Laurent Jacques</p></summary>
<p>

**Abstract:** The lensless endoscope (LE) is a promising device to acquire in vivo images at a cellular scale. The tiny size of the probe enables a deep exploration of the tissues. Lensless endoscopy with a multicore fiber (MCF) commonly uses a spatial light modulator (SLM) to coherently combine, at the output of the MCF, few hundreds of beamlets into a focus spot. This spot is subsequently scanned across the sample to generate a fluorescent image. We propose here a novel scanning scheme, partial speckle scanning (PSS), inspired by compressive sensing theory, that avoids the use of an SLM to perform fluorescent imaging in LE with reduced acquisition time. Such a strategy avoids photo-bleaching while keeping high reconstruction quality. We develop our approach on two key properties of the LE: (i) the ability to easily generate speckles, and (ii) the memory effect in MCF that allows to use fast scan mirrors to shift light patterns. First, we show that speckles are sub-exponential random fields. Despite their granular structure, an appropriate choice of the reconstruction parameters makes them good candidates to build efficient sensing matrices. Then, we numerically validate our approach and apply it on experimental data. The proposed sensing technique outperforms conventional raster scanning: higher reconstruction quality is achieved with far fewer observations. For a fixed reconstruction quality, our speckle scanning approach is faster than compressive sensing schemes which require to change the speckle pattern for each observation.

</p>
</details>

<details><summary><b>Understanding and Avoiding AI Failures: A Practical Guide</b>
<a href="https://arxiv.org/abs/2104.12582">arxiv:2104.12582</a>
&#x1F4C8; 15 <br>
<p>Robert M. Williams, Roman V. Yampolskiy</p></summary>
<p>

**Abstract:** As AI technologies increase in capability and ubiquity, AI accidents are becoming more common. Based on normal accident theory, high reliability theory, and open systems theory, we create a framework for understanding the risks associated with AI applications. In addition, we also use AI safety principles to quantify the unique risks of increased intelligence and human-like qualities in AI. Together, these two fields give a more complete picture of the risks of contemporary AI. By focusing on system properties near accidents instead of seeking a root cause of accidents, we identify where attention should be paid to safety for current generation AI systems.

</p>
</details>

<details><summary><b>Analyzing Monotonic Linear Interpolation in Neural Network Loss Landscapes</b>
<a href="https://arxiv.org/abs/2104.11044">arxiv:2104.11044</a>
&#x1F4C8; 14 <br>
<p>James Lucas, Juhan Bae, Michael R. Zhang, Stanislav Fort, Richard Zemel, Roger Grosse</p></summary>
<p>

**Abstract:** Linear interpolation between initial neural network parameters and converged parameters after training with stochastic gradient descent (SGD) typically leads to a monotonic decrease in the training objective. This Monotonic Linear Interpolation (MLI) property, first observed by Goodfellow et al. (2014) persists in spite of the non-convex objectives and highly non-linear training dynamics of neural networks. Extending this work, we evaluate several hypotheses for this property that, to our knowledge, have not yet been explored. Using tools from differential geometry, we draw connections between the interpolated paths in function space and the monotonicity of the network - providing sufficient conditions for the MLI property under mean squared error. While the MLI property holds under various settings (e.g. network architectures and learning problems), we show in practice that networks violating the MLI property can be produced systematically, by encouraging the weights to move far from initialization. The MLI property raises important questions about the loss landscape geometry of neural networks and highlights the need to further study their global properties.

</p>
</details>

<details><summary><b>ManipulaTHOR: A Framework for Visual Object Manipulation</b>
<a href="https://arxiv.org/abs/2104.11213">arxiv:2104.11213</a>
&#x1F4C8; 10 <br>
<p>Kiana Ehsani, Winson Han, Alvaro Herrasti, Eli VanderBilt, Luca Weihs, Eric Kolve, Aniruddha Kembhavi, Roozbeh Mottaghi</p></summary>
<p>

**Abstract:** The domain of Embodied AI has recently witnessed substantial progress, particularly in navigating agents within their environments. These early successes have laid the building blocks for the community to tackle tasks that require agents to actively interact with objects in their environment. Object manipulation is an established research domain within the robotics community and poses several challenges including manipulator motion, grasping and long-horizon planning, particularly when dealing with oft-overlooked practical setups involving visually rich and complex scenes, manipulation using mobile agents (as opposed to tabletop manipulation), and generalization to unseen environments and objects. We propose a framework for object manipulation built upon the physics-enabled, visually rich AI2-THOR framework and present a new challenge to the Embodied AI community known as ArmPointNav. This task extends the popular point navigation task to object manipulation and offers new challenges including 3D obstacle avoidance, manipulating objects in the presence of occlusion, and multi-object manipulation that necessitates long term planning. Popular learning paradigms that are successful on PointNav challenges show promise, but leave a large room for improvement.

</p>
</details>

<details><summary><b>Distilling Audio-Visual Knowledge by Compositional Contrastive Learning</b>
<a href="https://arxiv.org/abs/2104.10955">arxiv:2104.10955</a>
&#x1F4C8; 10 <br>
<p>Yanbei Chen, Yongqin Xian, A. Sophia Koepke, Ying Shan, Zeynep Akata</p></summary>
<p>

**Abstract:** Having access to multi-modal cues (e.g. vision and audio) empowers some cognitive tasks to be done faster compared to learning from a single modality. In this work, we propose to transfer knowledge across heterogeneous modalities, even though these data modalities may not be semantically correlated. Rather than directly aligning the representations of different modalities, we compose audio, image, and video representations across modalities to uncover richer multi-modal knowledge. Our main idea is to learn a compositional embedding that closes the cross-modal semantic gap and captures the task-relevant semantics, which facilitates pulling together representations across modalities by compositional contrastive learning. We establish a new, comprehensive multi-modal distillation benchmark on three video datasets: UCF101, ActivityNet, and VGGSound. Moreover, we demonstrate that our model significantly outperforms a variety of existing knowledge distillation methods in transferring audio-visual knowledge to improve video representation learning. Code is released here: https://github.com/yanbeic/CCL.

</p>
</details>

<details><summary><b>Multi-task Semi-supervised Learning for Pulmonary Lobe Segmentation</b>
<a href="https://arxiv.org/abs/2104.11017">arxiv:2104.11017</a>
&#x1F4C8; 9 <br>
<p>Jingnan Jia, Zhiwei Zhai, M. Els Bakker, I. Hernandez Giron, Marius Staring, Berend C. Stoel</p></summary>
<p>

**Abstract:** Pulmonary lobe segmentation is an important preprocessing task for the analysis of lung diseases. Traditional methods relying on fissure detection or other anatomical features, such as the distribution of pulmonary vessels and airways, could provide reasonably accurate lobe segmentations. Deep learning based methods can outperform these traditional approaches, but require large datasets. Deep multi-task learning is expected to utilize labels of multiple different structures. However, commonly such labels are distributed over multiple datasets. In this paper, we proposed a multi-task semi-supervised model that can leverage information of multiple structures from unannotated datasets and datasets annotated with different structures. A focused alternating training strategy is presented to balance the different tasks. We evaluated the trained model on an external independent CT dataset. The results show that our model significantly outperforms single-task alternatives, improving the mean surface distance from 7.174 mm to 4.196 mm. We also demonstrated that our approach is successful for different network architectures as backbones.

</p>
</details>

<details><summary><b>An End-to-End Computer Vision Methodology for Quantitative Metallography</b>
<a href="https://arxiv.org/abs/2104.11159">arxiv:2104.11159</a>
&#x1F4C8; 8 <br>
<p>Matan Rusanovsky, Ofer Beeri, Sigalit Ifergane, Gal Oren</p></summary>
<p>

**Abstract:** Metallography is crucial for a proper assessment of material's properties. It involves mainly the investigation of spatial distribution of grains and the occurrence and characteristics of inclusions or precipitates. This work presents an holistic artificial intelligence model for Anomaly Detection that automatically quantifies the degree of anomaly of impurities in alloys. We suggest the following examination process: (1) Deep semantic segmentation is performed on the inclusions (based on a suitable metallographic database of alloys and corresponding tags of inclusions), producing inclusions masks that are saved into a separated database. (2) Deep image inpainting is performed to fill the removed inclusions parts, resulting in 'clean' metallographic images, which contain the background of grains. (3) Grains' boundaries are marked using deep semantic segmentation (based on another metallographic database of alloys), producing boundaries that are ready for further inspection on the distribution of grains' size. (4) Deep anomaly detection and pattern recognition is performed on the inclusions masks to determine spatial, shape and area anomaly detection of the inclusions. Finally, the system recommends to an expert on areas of interests for further examination. The performance of the model is presented and analyzed based on few representative cases. Although the models presented here were developed for metallography analysis, most of them can be generalized to a wider set of problems in which anomaly detection of geometrical objects is desired. All models as well as the data-sets that were created for this work, are publicly available at https://github.com/Scientific-Computing-Lab-NRCN/MLography.

</p>
</details>

<details><summary><b>NanoNet: Real-Time Polyp Segmentation in Video Capsule Endoscopy and Colonoscopy</b>
<a href="https://arxiv.org/abs/2104.11138">arxiv:2104.11138</a>
&#x1F4C8; 8 <br>
<p>Debesh Jha, Nikhil Kumar Tomar, Sharib Ali, Michael A. Riegler, Håvard D. Johansen, Dag Johansen, Thomas de Lange, Pål Halvorsen</p></summary>
<p>

**Abstract:** Deep learning in gastrointestinal endoscopy can assist to improve clinical performance and be helpful to assess lesions more accurately. To this extent, semantic segmentation methods that can perform automated real-time delineation of a region-of-interest, e.g., boundary identification of cancer or precancerous lesions, can benefit both diagnosis and interventions. However, accurate and real-time segmentation of endoscopic images is extremely challenging due to its high operator dependence and high-definition image quality. To utilize automated methods in clinical settings, it is crucial to design lightweight models with low latency such that they can be integrated with low-end endoscope hardware devices. In this work, we propose NanoNet, a novel architecture for the segmentation of video capsule endoscopy and colonoscopy images. Our proposed architecture allows real-time performance and has higher segmentation accuracy compared to other more complex ones. We use video capsule endoscopy and standard colonoscopy datasets with polyps, and a dataset consisting of endoscopy biopsies and surgical instruments, to evaluate the effectiveness of our approach. Our experiments demonstrate the increased performance of our architecture in terms of a trade-off between model complexity, speed, model parameters, and metric performances. Moreover, the resulting model size is relatively tiny, with only nearly 36,000 parameters compared to traditional deep learning approaches having millions of parameters.

</p>
</details>

<details><summary><b>Learning Transferable 3D Adversarial Cloaks for Deep Trained Detectors</b>
<a href="https://arxiv.org/abs/2104.11101">arxiv:2104.11101</a>
&#x1F4C8; 8 <br>
<p>Arman Maesumi, Mingkang Zhu, Yi Wang, Tianlong Chen, Zhangyang Wang, Chandrajit Bajaj</p></summary>
<p>

**Abstract:** This paper presents a novel patch-based adversarial attack pipeline that trains adversarial patches on 3D human meshes. We sample triangular faces on a reference human mesh, and create an adversarial texture atlas over those faces. The adversarial texture is transferred to human meshes in various poses, which are rendered onto a collection of real-world background images. Contrary to the traditional patch-based adversarial attacks, where prior work attempts to fool trained object detectors using appended adversarial patches, this new form of attack is mapped into the 3D object world and back-propagated to the texture atlas through differentiable rendering. As such, the adversarial patch is trained under deformation consistent with real-world materials. In addition, and unlike existing adversarial patches, our new 3D adversarial patch is shown to fool state-of-the-art deep object detectors robustly under varying views, potentially leading to an attacking scheme that is persistently strong in the physical world.

</p>
</details>

<details><summary><b>A Data-Adaptive Loss Function for Incomplete Data and Incremental Learning in Semantic Image Segmentation</b>
<a href="https://arxiv.org/abs/2104.11020">arxiv:2104.11020</a>
&#x1F4C8; 8 <br>
<p>Minh H. Vu, Gabriella Norman, Tufve Nyholm, Tommy Löfstedt</p></summary>
<p>

**Abstract:** In the last years, deep learning has dramatically improved the performances in a variety of medical image analysis applications. Among different types of deep learning models, convolutional neural networks have been among the most successful and they have been used in many applications in medical imaging.
  Training deep convolutional neural networks often requires large amounts of image data to generalize well to new unseen images. It is often time-consuming and expensive to collect large amounts of data in the medical image domain due to expensive imaging systems, and the need for experts to manually make ground truth annotations. A potential problem arises if new structures are added when a decision support system is already deployed and in use. Since the field of radiation therapy is constantly developing, the new structures would also have to be covered by the decision support system.
  In the present work, we propose a novel loss function, that adapts to the available data in order to utilize all available data, even when some have missing annotations. We demonstrate that the proposed loss function also works well in an incremental learning setting, where it can automatically incorporate new structures as they appear. Experiments on a large in-house data set show that the proposed method performs on par with baseline models, while greatly reducing the training time.

</p>
</details>

<details><summary><b>Unsupervised anomaly detection for a Smart Autonomous Robotic Assistant Surgeon (SARAS)using a deep residual autoencoder</b>
<a href="https://arxiv.org/abs/2104.11008">arxiv:2104.11008</a>
&#x1F4C8; 8 <br>
<p>Dinesh Jackson Samuel, Fabio Cuzzolin</p></summary>
<p>

**Abstract:** Anomaly detection in Minimally-Invasive Surgery (MIS) traditionally requires a human expert monitoring the procedure from a console. Data scarcity, on the other hand, hinders what would be a desirable migration towards autonomous robotic-assisted surgical systems. Automated anomaly detection systems in this area typically rely on classical supervised learning. Anomalous events in a surgical setting, however, are rare, making it difficult to capture data to train a detection model in a supervised fashion. In this work we thus propose an unsupervised approach to anomaly detection for robotic-assisted surgery based on deep residual autoencoders. The idea is to make the autoencoder learn the 'normal' distribution of the data and detect abnormal events deviating from this distribution by measuring the reconstruction error. The model is trained and validated upon both the publicly available Cholec80 dataset, provided with extra annotation, and on a set of videos captured on procedures using artificial anatomies ('phantoms') produced as part of the Smart Autonomous Robotic Assistant Surgeon (SARAS) project. The system achieves recall and precision equal to 78.4%, 91.5%, respectively, on Cholec80 and of 95.6%, 88.1% on the SARAS phantom dataset. The end-to-end system was developed and deployed as part of the SARAS demonstration platform for real-time anomaly detection with a processing time of about 25 ms per frame.

</p>
</details>

<details><summary><b>Hazy Re-ID: An Interference Suppression Model For Domain Adaptation Person Re-identification Under Inclement Weather Condition</b>
<a href="https://arxiv.org/abs/2104.11004">arxiv:2104.11004</a>
&#x1F4C8; 8 <br>
<p>Jian Pang, Dacheng Zhang, Huafeng Li, Weifeng Liu, Zhengtao Yu</p></summary>
<p>

**Abstract:** In a conventional domain adaptation person Re-identification (Re-ID) task, both the training and test images in target domain are collected under the sunny weather. However, in reality, the pedestrians to be retrieved may be obtained under severe weather conditions such as hazy, dusty and snowing, etc. This paper proposes a novel Interference Suppression Model (ISM) to deal with the interference caused by the hazy weather in domain adaptation person Re-ID. A teacherstudent model is used in the ISM to distill the interference information at the feature level by reducing the discrepancy between the clear and the hazy intrinsic similarity matrix. Furthermore, in the distribution level, the extra discriminator is introduced to assist the student model make the interference feature distribution more clear. The experimental results show that the proposed method achieves the superior performance on two synthetic datasets than the stateof-the-art methods. The related code will be released online https://github.com/pangjian123/ISM-ReID.

</p>
</details>

<details><summary><b>Neuro-inspired edge feature fusion using Choquet integrals</b>
<a href="https://arxiv.org/abs/2104.10984">arxiv:2104.10984</a>
&#x1F4C8; 8 <br>
<p>Cedric Marco-Detchart, Giancarlo Lucca, Carlos Lopez-Molina, Laura De Miguel, Graçaliz Pereira Dimuro, Humberto Bustince</p></summary>
<p>

**Abstract:** It is known that the human visual system performs a hierarchical information process in which early vision cues (or primitives) are fused in the visual cortex to compose complex shapes and descriptors. While different aspects of the process have been extensively studied, as the lens adaptation or the feature detection, some other,as the feature fusion, have been mostly left aside. In this work we elaborate on the fusion of early vision primitives using generalizations of the Choquet integral, and novel aggregation operators that have been extensively studied in recent years. We propose to use generalizations of the Choquet integral to sensibly fuse elementary edge cues, in an attempt to model the behaviour of neurons in the early visual cortex. Our proposal leads to a full-framed edge detection algorithm, whose performance is put to the test in state-of-the-art boundary detection datasets.

</p>
</details>

<details><summary><b>Continental-scale land cover mapping at 10 m resolution over Europe (ELC10)</b>
<a href="https://arxiv.org/abs/2104.10922">arxiv:2104.10922</a>
&#x1F4C8; 8 <br>
<p>Zander S. Venter, Markus A. K. Sydenham</p></summary>
<p>

**Abstract:** Widely used European land cover maps such as CORINE are produced at medium spatial resolutions (100 m) and rely on diverse data with complex workflows requiring significant institutional capacity. We present a high resolution (10 m) land cover map (ELC10) of Europe based on a satellite-driven machine learning workflow that is annually updatable. A Random Forest classification model was trained on 70K ground-truth points from the LUCAS (Land Use/Cover Area frame Survey) dataset. Within the Google Earth Engine cloud computing environment, the ELC10 map can be generated from approx. 700 TB of Sentinel imagery within approx. 4 days from a single research user account. The map achieved an overall accuracy of 90% across 8 land cover classes and could account for statistical unit land cover proportions within 3.9% (R2 = 0.83) of the actual value. These accuracies are higher than that of CORINE (100 m) and other 10-m land cover maps including S2GLC and FROM-GLC10. We found that atmospheric correction of Sentinel-2 and speckle filtering of Sentinel-1 imagery had minimal effect on enhancing classification accuracy (< 1%). However, combining optical and radar imagery increased accuracy by 3% compared to Sentinel-2 alone and by 10% compared to Sentinel-1 alone. The conversion of LUCAS points into homogenous polygons under the Copernicus module increased accuracy by <1%, revealing that Random Forests are robust against contaminated training data. Furthermore, the model requires very little training data to achieve moderate accuracies - the difference between 5K and 50K LUCAS points is only 3% (86 vs 89%). At 10-m resolution, the ELC10 map can distinguish detailed landscape features like hedgerows and gardens, and therefore holds potential for aerial statistics at the city borough level and monitoring property-level environmental interventions (e.g. tree planting).

</p>
</details>

<details><summary><b>Survey on Modeling Intensity Function of Hawkes Process Using Neural Models</b>
<a href="https://arxiv.org/abs/2104.11092">arxiv:2104.11092</a>
&#x1F4C8; 7 <br>
<p>Jayesh Malaviya</p></summary>
<p>

**Abstract:** The event sequence of many diverse systems is represented as a sequence of discrete events in a continuous space. Examples of such an event sequence are earthquake aftershock events, financial transactions, e-commerce transactions, social network activity of a user, and the user's web search pattern. Finding such an intricate pattern helps discover which event will occur in the future and when it will occur. A Hawkes process is a mathematical tool used for modeling such time series discrete events. Traditionally, the Hawkes process uses a critical component for modeling data as an intensity function with a parameterized kernel function. The Hawkes process's intensity function involves two components: the background intensity and the effect of events' history. However, such parameterized assumption can not capture future event characteristics using past events data precisely due to bias in modeling kernel function. This paper explores the recent advancement using novel deep learning-based methods to model kernel function to remove such parametrized kernel function. In the end, we will give potential future research directions to improve modeling using the Hawkes process.

</p>
</details>

<details><summary><b>METGAN: Generative Tumour Inpainting and Modality Synthesis in Light Sheet Microscopy</b>
<a href="https://arxiv.org/abs/2104.10993">arxiv:2104.10993</a>
&#x1F4C8; 7 <br>
<p>Izabela Horvath, Johannes C. Paetzold, Oliver Schoppe, Rami Al-Maskari, Ivan Ezhov, Suprosanna Shit, Hongwei Li, Ali Ertuerk, Bjoern H. Menze</p></summary>
<p>

**Abstract:** Novel multimodal imaging methods are capable of generating extensive, super high resolution datasets for preclinical research. Yet, a massive lack of annotations prevents the broad use of deep learning to analyze such data. So far, existing generative models fail to mitigate this problem because of frequent labeling errors. In this paper, we introduce a novel generative method which leverages real anatomical information to generate realistic image-label pairs of tumours. We construct a dual-pathway generator, for the anatomical image and label, trained in a cycle-consistent setup, constrained by an independent, pretrained segmentor. The generated images yield significant quantitative improvement compared to existing methods. To validate the quality of synthesis, we train segmentation networks on a dataset augmented with the synthetic data, substantially improving the segmentation over baseline.

</p>
</details>

<details><summary><b>Focusing on Shadows for Predicting Heightmaps from Single Remotely Sensed RGB Images with Deep Learning</b>
<a href="https://arxiv.org/abs/2104.10874">arxiv:2104.10874</a>
&#x1F4C8; 7 <br>
<p>Savvas Karatsiolis, Andreas Kamilaris</p></summary>
<p>

**Abstract:** Estimating the heightmaps of buildings and vegetation in single remotely sensed images is a challenging problem. Effective solutions to this problem can comprise the stepping stone for solving complex and demanding problems that require 3D information of aerial imagery in the remote sensing discipline, which might be expensive or not feasible to require. We propose a task-focused Deep Learning (DL) model that takes advantage of the shadow map of a remotely sensed image to calculate its heightmap. The shadow is computed efficiently and does not add significant computation complexity. The model is trained with aerial images and their Lidar measurements, achieving superior performance on the task. We validate the model with a dataset covering a large area of Manchester, UK, as well as the 2018 IEEE GRSS Data Fusion Contest Lidar dataset. Our work suggests that the proposed DL architecture and the technique of injecting shadows information into the model are valuable for improving the heightmap estimation task for single remotely sensed imagery.

</p>
</details>

<details><summary><b>Trust as Extended Control: Active Inference and User Feedback During Human-Robot Collaboration</b>
<a href="https://arxiv.org/abs/2104.11153">arxiv:2104.11153</a>
&#x1F4C8; 6 <br>
<p>Felix Schoeller, Mark Miller, Roy Salomon, Karl J. Friston</p></summary>
<p>

**Abstract:** To interact seamlessly with robots, users must infer the causes of a robot's behavior and be confident about that inference. Hence, trust is a necessary condition for human-robot collaboration (HRC). Despite its crucial role, it is largely unknown how trust emerges, develops, and supports human interactions with nonhuman artefacts. Here, we review the literature on trust, human-robot interaction, human-robot collaboration, and human interaction at large. Early models of trust suggest that trust entails a trade-off between benevolence and competence, while studies of human-to-human interaction emphasize the role of shared behavior and mutual knowledge in the gradual building of trust. We then introduce a model of trust as an agent's best explanation for reliable sensory exchange with an extended motor plant or partner. This model is based on the cognitive neuroscience of active inference and suggests that, in the context of HRC, trust can be cast in terms of virtual control over an artificial agent. In this setting, interactive feedback becomes a necessary component of the trustor's perception-action cycle. The resulting model has important implications for understanding human-robot interaction and collaboration, as it allows the traditional determinants of human trust to be defined in terms of active inference, information exchange and empowerment. Furthermore, this model suggests that boredom and surprise may be used as markers for under and over-reliance on the system. Finally, we examine the role of shared behavior in the genesis of trust, especially in the context of dyadic collaboration, suggesting important consequences for the acceptability and design of human-robot collaborative systems.

</p>
</details>

<details><summary><b>Efficient LiDAR Odometry for Autonomous Driving</b>
<a href="https://arxiv.org/abs/2104.10879">arxiv:2104.10879</a>
&#x1F4C8; 6 <br>
<p>Xin Zheng, Jianke Zhu</p></summary>
<p>

**Abstract:** LiDAR odometry plays an important role in self-localization and mapping for autonomous navigation, which is usually treated as a scan registration problem. Although having achieved promising performance on KITTI odometry benchmark, the conventional searching tree-based approach still has the difficulty in dealing with the large scale point cloud efficiently. The recent spherical range image-based method enjoys the merits of fast nearest neighbor search by spherical mapping. However, it is not very effective to deal with the ground points nearly parallel to LiDAR beams. To address these issues, we propose a novel efficient LiDAR odometry approach by taking advantage of both non-ground spherical range image and bird's-eye-view map for ground points. Moreover, a range adaptive method is introduced to robustly estimate the local surface normal. Additionally, a very fast and memory-efficient model update scheme is proposed to fuse the points and their corresponding normals at different time-stamps. We have conducted extensive experiments on KITTI odometry benchmark, whose promising results demonstrate that our proposed approach is effective.

</p>
</details>

<details><summary><b>Patch Shortcuts: Interpretable Proxy Models Efficiently Find Black-Box Vulnerabilities</b>
<a href="https://arxiv.org/abs/2104.11691">arxiv:2104.11691</a>
&#x1F4C8; 5 <br>
<p>Julia Rosenzweig, Joachim Sicking, Sebastian Houben, Michael Mock, Maram Akila</p></summary>
<p>

**Abstract:** An important pillar for safe machine learning (ML) is the systematic mitigation of weaknesses in neural networks to afford their deployment in critical applications. An ubiquitous class of safety risks are learned shortcuts, i.e. spurious correlations a network exploits for its decisions that have no semantic connection to the actual task. Networks relying on such shortcuts bear the risk of not generalizing well to unseen inputs. Explainability methods help to uncover such network vulnerabilities. However, many of these techniques are not directly applicable if access to the network is constrained, in so-called black-box setups. These setups are prevalent when using third-party ML components. To address this constraint, we present an approach to detect learned shortcuts using an interpretable-by-design network as a proxy to the black-box model of interest. Leveraging the proxy's guarantees on introspection we automatically extract candidates for learned shortcuts. Their transferability to the black box is validated in a systematic fashion. Concretely, as proxy model we choose a BagNet, which bases its decisions purely on local image patches. We demonstrate on the autonomous driving dataset A2D2 that extracted patch shortcuts significantly influence the black box model. By efficiently identifying such patch-based vulnerabilities, we contribute to safer ML models.

</p>
</details>

<details><summary><b>Optimal Cost Design for Model Predictive Control</b>
<a href="https://arxiv.org/abs/2104.11353">arxiv:2104.11353</a>
&#x1F4C8; 5 <br>
<p>Avik Jain, Lawrence Chan, Daniel S. Brown, Anca D. Dragan</p></summary>
<p>

**Abstract:** Many robotics domains use some form of nonconvex model predictive control (MPC) for planning, which sets a reduced time horizon, performs trajectory optimization, and replans at every step. The actual task typically requires a much longer horizon than is computationally tractable, and is specified via a cost function that cumulates over that full horizon. For instance, an autonomous car may have a cost function that makes a desired trade-off between efficiency, safety, and obeying traffic laws. In this work, we challenge the common assumption that the cost we optimize using MPC should be the same as the ground truth cost for the task (plus a terminal cost). MPC solvers can suffer from short planning horizons, local optima, incorrect dynamics models, and, importantly, fail to account for future replanning ability. Thus, we propose that in many tasks it could be beneficial to purposefully choose a different cost function for MPC to optimize: one that results in the MPC rollout having low ground truth cost, rather than the MPC planned trajectory. We formalize this as an optimal cost design problem, and propose a zeroth-order optimization-based approach that enables us to design optimal costs for an MPC planning robot in continuous MDPs. We test our approach in an autonomous driving domain where we find costs different from the ground truth that implicitly compensate for replanning, short horizon, incorrect dynamics models, and local minima issues. As an example, the learned cost incentivizes MPC to delay its decision until later, implicitly accounting for the fact that it will get more information in the future and be able to make a better decision. Code and videos available at https://sites.google.com/berkeley.edu/ocd-mpc/.

</p>
</details>

<details><summary><b>VeriMedi: Pill Identification using Proxy-based Deep Metric Learning and Exact Solution</b>
<a href="https://arxiv.org/abs/2104.11231">arxiv:2104.11231</a>
&#x1F4C8; 5 <br>
<p>Tekin Evrim Ozmermer, Viktors Roze, Stanislavs Hilcuks, Alina Nescerecka</p></summary>
<p>

**Abstract:** We present the system that we have developed for the identification and verification of pills using images that are taken by the VeriMedi device. The VeriMedi device is an Internet of Things device that takes pictures of a filled pill vial from the bottom of the vial and uses the solution that is presented in this research to identify the pills in the vials. The solution has two serially connected deep learning solutions which do segmentation and identification. The segmentation solution creates the masks for each pill in the vial image by using the Mask R-CNN model, then segments and crops the pills and blurs the background. After that, the segmented pill images are sent to the identification solution where a Deep Metric Learning model that is trained with Proxy Anchor Loss (PAL) function generates embedding vectors for each pill image. The generated embedding vectors are fed into a one-layer fully connected network that is trained with the exact solution to predict each single pill image. Then, the aggregation/verification function aggregates the multiple predictions coming from multiple single pill images and verifies the correctness of the final prediction with respect to predefined rules. Besides, we enhanced the PAL with a better proxy initialization that increased the performance of the models and let the model learn the new classes of images continually without retraining the model with the whole dataset. When the model that is trained with initial classes is retrained only with new classes, the accuracy of the model increases for both old and new classes. The identification solution that we have presented in this research can also be reused for other problem domains which require continual learning and/or Fine-Grained Visual Categorization.

</p>
</details>

<details><summary><b>Imagining The Road Ahead: Multi-Agent Trajectory Prediction via Differentiable Simulation</b>
<a href="https://arxiv.org/abs/2104.11212">arxiv:2104.11212</a>
&#x1F4C8; 5 <br>
<p>Adam Scibior, Vasileios Lioutas, Daniele Reda, Peyman Bateni, Frank Wood</p></summary>
<p>

**Abstract:** We develop a deep generative model built on a fully differentiable simulator for multi-agent trajectory prediction. Agents are modeled with conditional recurrent variational neural networks (CVRNNs), which take as input an ego-centric birdview image representing the current state of the world and output an action, consisting of steering and acceleration, which is used to derive the subsequent agent state using a kinematic bicycle model. The full simulation state is then differentiably rendered for each agent, initiating the next time step. We achieve state-of-the-art results on the INTERACTION dataset, using standard neural architectures and a standard variational training objective, producing realistic multi-modal predictions without any ad-hoc diversity-inducing losses. We conduct ablation studies to examine individual components of the simulator, finding that both the kinematic bicycle model and the continuous feedback from the birdview image are crucial for achieving this level of performance. We name our model ITRA, for "Imagining the Road Ahead".

</p>
</details>

<details><summary><b>Protecting gender and identity with disentangled speech representations</b>
<a href="https://arxiv.org/abs/2104.11051">arxiv:2104.11051</a>
&#x1F4C8; 5 <br>
<p>Dimitrios Stoidis, Andrea Cavallaro</p></summary>
<p>

**Abstract:** Besides its linguistic content, our speech is rich in biometric information that can be inferred by classifiers. Learning privacy-preserving representations for speech signals enables downstream tasks without sharing unnecessary, private information about an individual. In this paper, we show that protecting gender information in speech is more effective than modelling speaker-identity information only when generating a non-sensitive representation of speech. Our method relies on reconstructing speech by decoding linguistic content along with gender information using a variational autoencoder. Specifically, we exploit disentangled representation learning to encode information about different attributes into separate subspaces that can be factorised independently. We present a novel way to encode gender information and disentangle two sensitive biometric identifiers, namely gender and identity, in a privacy-protecting setting. Experiments on the LibriSpeech dataset show that gender recognition and speaker verification can be reduced to a random guess, protecting against classification-based attacks.

</p>
</details>

<details><summary><b>MeSIN: Multilevel Selective and Interactive Network for Medication Recommendation</b>
<a href="https://arxiv.org/abs/2104.11026">arxiv:2104.11026</a>
&#x1F4C8; 5 <br>
<p>Yang An, Liang Zhang, Mao You, Xueqing Tian, Bo Jin, Xiaopeng Wei</p></summary>
<p>

**Abstract:** Recommending medications for patients using electronic health records (EHRs) is a crucial data mining task for an intelligent healthcare system. It can assist doctors in making clinical decisions more efficiently. However, the inherent complexity of the EHR data renders it as a challenging task: (1) Multilevel structures: the EHR data typically contains multilevel structures which are closely related with the decision-making pathways, e.g., laboratory results lead to disease diagnoses, and then contribute to the prescribed medications; (2) Multiple sequences interactions: multiple sequences in EHR data are usually closely correlated with each other; (3) Abundant noise: lots of task-unrelated features or noise information within EHR data generally result in suboptimal performance. To tackle the above challenges, we propose a multilevel selective and interactive network (MeSIN) for medication recommendation. Specifically, MeSIN is designed with three components. First, an attentional selective module (ASM) is applied to assign flexible attention scores to different medical codes embeddings by their relevance to the recommended medications in every admission. Second, we incorporate a novel interactive long-short term memory network (InLSTM) to reinforce the interactions of multilevel medical sequences in EHR data with the help of the calibrated memory-augmented cell and an enhanced input gate. Finally, we employ a global selective fusion module (GSFM) to infuse the multi-sourced information embeddings into final patient representations for medications recommendation. To validate our method, extensive experiments have been conducted on a real-world clinical dataset. The results demonstrate a consistent superiority of our framework over several baselines and testify the effectiveness of our proposed approach.

</p>
</details>

<details><summary><b>Restoring degraded speech via a modified diffusion model</b>
<a href="https://arxiv.org/abs/2104.11347">arxiv:2104.11347</a>
&#x1F4C8; 4 <br>
<p>Jianwei Zhang, Suren Jayasuriya, Visar Berisha</p></summary>
<p>

**Abstract:** There are many deterministic mathematical operations (e.g. compression, clipping, downsampling) that degrade speech quality considerably. In this paper we introduce a neural network architecture, based on a modification of the DiffWave model, that aims to restore the original speech signal. DiffWave, a recently published diffusion-based vocoder, has shown state-of-the-art synthesized speech quality and relatively shorter waveform generation times, with only a small set of parameters. We replace the mel-spectrum upsampler in DiffWave with a deep CNN upsampler, which is trained to alter the degraded speech mel-spectrum to match that of the original speech. The model is trained using the original speech waveform, but conditioned on the degraded speech mel-spectrum. Post-training, only the degraded mel-spectrum is used as input and the model generates an estimate of the original speech. Our model results in improved speech quality (original DiffWave model as baseline) on several different experiments. These include improving the quality of speech degraded by LPC-10 compression, AMR-NB compression, and signal clipping. Compared to the original DiffWave architecture, our scheme achieves better performance on several objective perceptual metrics and in subjective comparisons. Improvements over baseline are further amplified in a out-of-corpus evaluation setting.

</p>
</details>

<details><summary><b>Knowledge Triggering, Extraction and Storage via Human-Robot Verbal Interaction</b>
<a href="https://arxiv.org/abs/2104.11170">arxiv:2104.11170</a>
&#x1F4C8; 4 <br>
<p>Lucrezia Grassi, Carmine Tommaso Recchiuto, Antonio Sgorbissa</p></summary>
<p>

**Abstract:** This article describes a novel approach to expand in run-time the knowledge base of an Artificial Conversational Agent. A technique for automatic knowledge extraction from the user's sentence and four methods to insert the new acquired concepts in the knowledge base have been developed and integrated into a system that has already been tested for knowledge-based conversation between a social humanoid robot and residents of care homes. The run-time addition of new knowledge allows overcoming some limitations that affect most robots and chatbots: the incapability of engaging the user for a long time due to the restricted number of conversation topics. The insertion in the knowledge base of new concepts recognized in the user's sentence is expected to result in a wider range of topics that can be covered during an interaction, making the conversation less repetitive. Two experiments are presented to assess the performance of the knowledge extraction technique, and the efficiency of the developed insertion methods when adding several concepts in the Ontology.

</p>
</details>

<details><summary><b>Deep learning for detecting bid rigging: Flagging cartel participants based on convolutional neural networks</b>
<a href="https://arxiv.org/abs/2104.11142">arxiv:2104.11142</a>
&#x1F4C8; 4 <br>
<p>Martin Huber, David Imhof</p></summary>
<p>

**Abstract:** Adding to the literature on the data-driven detection of bid-rigging cartels, we propose a novel approach based on deep learning (a subfield of artificial intelligence) that flags cartel participants based on their pairwise bidding interactions with other firms. More concisely, we combine a so-called convolutional neural network for image recognition with graphs that in a pairwise manner plot the normalized bid values of some reference firm against the normalized bids of any other firms participating in the same tenders as the reference firm. Based on Japanese and Swiss procurement data, we construct such graphs for both collusive and competitive episodes (i.e when a bid-rigging cartel is or is not active) and use a subset of graphs to train the neural network such that it learns distinguishing collusive from competitive bidding patterns. We use the remaining graphs to test the neural network's out-of-sample performance in correctly classifying collusive and competitive bidding interactions. We obtain a very decent average accuracy of around 90% or slightly higher when either applying the method within Japanese, Swiss, or mixed data (in which Swiss and Japanese graphs are pooled). When using data from one country for training to test the trained model's performance in the other country (i.e. transnationally), predictive performance decreases (likely due to institutional differences in procurement procedures across countries), but often remains satisfactorily high. All in all, the generally quite high accuracy of the convolutional neural network despite being trained in a rather small sample of a few 100 graphs points to a large potential of deep learning approaches for flagging and fighting bid-rigging cartels.

</p>
</details>

<details><summary><b>A learning gap between neuroscience and reinforcement learning</b>
<a href="https://arxiv.org/abs/2104.10995">arxiv:2104.10995</a>
&#x1F4C8; 4 <br>
<p>Samuel T. Wauthier, Pietro Mazzaglia, Ozan Çatal, Cedric De Boom, Tim Verbelen, Bart Dhoedt</p></summary>
<p>

**Abstract:** Historically, artificial intelligence has drawn much inspiration from neuroscience to fuel advances in the field. However, current progress in reinforcement learning is largely focused on benchmark problems that fail to capture many of the aspects that are of interest in neuroscience today. We illustrate this point by extending a T-maze task from neuroscience for use with reinforcement learning algorithms, and show that state-of-the-art algorithms are not capable of solving this problem. Finally, we point out where insights from neuroscience could help explain some of the issues encountered.

</p>
</details>

<details><summary><b>SBNet: Segmentation-based Network for Natural Language-based Vehicle Search</b>
<a href="https://arxiv.org/abs/2104.11589">arxiv:2104.11589</a>
&#x1F4C8; 3 <br>
<p>Sangrok Lee, Taekang Woo, Sang Hun Lee</p></summary>
<p>

**Abstract:** Natural language-based vehicle retrieval is a task to find a target vehicle within a given image based on a natural language description as a query. This technology can be applied to various areas including police searching for a suspect vehicle. However, it is challenging due to the ambiguity of language descriptions and the difficulty of processing multi-modal data. To tackle this problem, we propose a deep neural network called SBNet that performs natural language-based segmentation for vehicle retrieval. We also propose two task-specific modules to improve performance: a substitution module that helps features from different domains to be embedded in the same space and a future prediction module that learns temporal information. SBnet has been trained using the CityFlow-NL dataset that contains 2,498 tracks of vehicles with three unique natural language descriptions each and tested 530 unique vehicle tracks and their corresponding query sets. SBNet achieved a significant improvement over the baseline in the natural language-based vehicle tracking track in the AI City Challenge 2021.

</p>
</details>

<details><summary><b>APRF-Net: Attentive Pseudo-Relevance Feedback Network for Query Categorization</b>
<a href="https://arxiv.org/abs/2104.11384">arxiv:2104.11384</a>
&#x1F4C8; 3 <br>
<p>Ali Ahmadvand, Sayyed M. Zahiri, Simon Hughes, Khalifa Al Jadda, Surya Kallumadi, Eugene Agichtein</p></summary>
<p>

**Abstract:** Query categorization is an essential part of query intent understanding in e-commerce search. A common query categorization task is to select the relevant fine-grained product categories in a product taxonomy. For frequent queries, rich customer behavior (e.g., click-through data) can be used to infer the relevant product categories. However, for more rare queries, which cover a large volume of search traffic, relying solely on customer behavior may not suffice due to the lack of this signal. To improve categorization of rare queries, we adapt the Pseudo-Relevance Feedback (PRF) approach to utilize the latent knowledge embedded in semantically or lexically similar product documents to enrich the representation of the more rare queries. To this end, we propose a novel deep neural model named Attentive Pseudo Relevance Feedback Network (APRF-Net) to enhance the representation of rare queries for query categorization. To demonstrate the effectiveness of our approach, we collect search queries from a large commercial search engine, and compare APRF-Net to state-of-the-art deep learning models for text classification. Our results show that the APRF-Net significantly improves query categorization by 5.9% on F1@1 score over the baselines, which increases to 8.2% improvement for the rare (tail) queries. The findings of this paper can be leveraged for further improvements in search query representation and understanding.

</p>
</details>

<details><summary><b>SPECTRE: Defending Against Backdoor Attacks Using Robust Statistics</b>
<a href="https://arxiv.org/abs/2104.11315">arxiv:2104.11315</a>
&#x1F4C8; 3 <br>
<p>Jonathan Hayase, Weihao Kong, Raghav Somani, Sewoong Oh</p></summary>
<p>

**Abstract:** Modern machine learning increasingly requires training on a large collection of data from multiple sources, not all of which can be trusted. A particularly concerning scenario is when a small fraction of poisoned data changes the behavior of the trained model when triggered by an attacker-specified watermark. Such a compromised model will be deployed unnoticed as the model is accurate otherwise. There have been promising attempts to use the intermediate representations of such a model to separate corrupted examples from clean ones. However, these defenses work only when a certain spectral signature of the poisoned examples is large enough for detection. There is a wide range of attacks that cannot be protected against by the existing defenses. We propose a novel defense algorithm using robust covariance estimation to amplify the spectral signature of corrupted data. This defense provides a clean model, completely removing the backdoor, even in regimes where previous methods have no hope of detecting the poisoned examples. Code and pre-trained models are available at https://github.com/SewoongLab/spectre-defense .

</p>
</details>

<details><summary><b>Chasing Collective Variables using Autoencoders and biased trajectories</b>
<a href="https://arxiv.org/abs/2104.11061">arxiv:2104.11061</a>
&#x1F4C8; 3 <br>
<p>Zineb Belkacemi, Paraskevi Gkeka, Tony Lelièvre, Gabriel Stoltz</p></summary>
<p>

**Abstract:** Free energy biasing methods have proven to be powerful tools to accelerate the simulation of important conformational changes of molecules by modifying the sampling measure. However, most of these methods rely on the prior knowledge of low-dimensional slow degrees of freedom, i.e. Collective Variables (CV). Alternatively, such CVs can be identified using machine learning (ML) and dimensionality reduction algorithms. In this context, approaches where the CVs are learned in an iterative way using adaptive biasing have been proposed: at each iteration, the learned CV is used to perform free energy adaptive biasing to generate new data and learn a new CV. In this paper, we introduce a new iterative method involving CV learning with autoencoders: Free Energy Biasing and Iterative Learning with AutoEncoders (FEBILAE). Our method includes a reweighting scheme to ensure that the learning model optimizes the same loss at each iteration, and achieves CV convergence. Using the alanine dipeptide system and the solvated chignolin mini-protein system as examples, we present results of our algorithm using the extended adaptive biasing force as the free energy adaptive biasing method.

</p>
</details>

<details><summary><b>Enhancing predictive skills in physically-consistent way: Physics Informed Machine Learning for Hydrological Processes</b>
<a href="https://arxiv.org/abs/2104.11009">arxiv:2104.11009</a>
&#x1F4C8; 3 <br>
<p>Pravin Bhasme, Jenil Vagadiya, Udit Bhatia</p></summary>
<p>

**Abstract:** Current modeling approaches for hydrological modeling often rely on either physics-based or data-science methods, including Machine Learning (ML) algorithms. While physics-based models tend to rigid structure resulting in unrealistic parameter values in certain instances, ML algorithms establish the input-output relationship while ignoring the constraints imposed by well-known physical processes. While there is a notion that the physics model enables better process understanding and ML algorithms exhibit better predictive skills, scientific knowledge that does not add to predictive ability may be deceptive. Hence, there is a need for a hybrid modeling approach to couple ML algorithms and physics-based models in a synergistic manner. Here we develop a Physics Informed Machine Learning (PIML) model that combines the process understanding of conceptual hydrological model with predictive abilities of state-of-the-art ML models. We apply the proposed model to predict the monthly time series of the target (streamflow) and intermediate variables (actual evapotranspiration) in the Narmada river basin in India. Our results show the capability of the PIML model to outperform a purely conceptual model ($abcd$ model) and ML algorithms while ensuring the physical consistency in outputs validated through water balance analysis. The systematic approach for combining conceptual model structure with ML algorithms could be used to improve the predictive accuracy of crucial hydrological processes important for flood risk assessment.

</p>
</details>

<details><summary><b>Hybrid Encoder: Towards Efficient and Precise Native AdsRecommendation via Hybrid Transformer Encoding Networks</b>
<a href="https://arxiv.org/abs/2104.10925">arxiv:2104.10925</a>
&#x1F4C8; 3 <br>
<p>Junhan Yang, Zheng Liu, Bowen Jin, Jianxun Lian, Defu Lian, Akshay Soni, Eun Yong Kang, Yajun Wang, Guangzhong Sun, Xing Xie</p></summary>
<p>

**Abstract:** Transformer encoding networks have been proved to be a powerful tool of understanding natural languages. They are playing a critical role in native ads service, which facilitates the recommendation of appropriate ads based on user's web browsing history. For the sake of efficient recommendation, conventional methods would generate user and advertisement embeddings independently with a siamese transformer encoder, such that approximate nearest neighbour search (ANN) can be leveraged. Given that the underlying semantic about user and ad can be complicated, such independently generated embeddings are prone to information loss, which leads to inferior recommendation quality. Although another encoding strategy, the cross encoder, can be much more accurate, it will lead to huge running cost and become infeasible for realtime services, like native ads recommendation. In this work, we propose hybrid encoder, which makes efficient and precise native ads recommendation through two consecutive steps: retrieval and ranking. In the retrieval step, user and ad are encoded with a siamese component, which enables relevant candidates to be retrieved via ANN search. In the ranking step, it further represents each ad with disentangled embeddings and each user with ad-related embeddings, which contributes to the fine-grained selection of high-quality ads from the candidate set. Both steps are light-weighted, thanks to the pre-computed and cached intermedia results. To optimize the hybrid encoder's performance in this two-stage workflow, a progressive training pipeline is developed, which builds up the model's capability in the retrieval and ranking task step-by-step. The hybrid encoder's effectiveness is experimentally verified: with very little additional cost, it outperforms the siamese encoder significantly and achieves comparable recommendation quality as the cross encoder.

</p>
</details>

<details><summary><b>Comparative Analysis of Machine Learning and Deep Learning Algorithms for Detection of Online Hate Speech</b>
<a href="https://arxiv.org/abs/2108.01063">arxiv:2108.01063</a>
&#x1F4C8; 2 <br>
<p>Tashvik Dhamija,  Anjum, Rahul Katarya</p></summary>
<p>

**Abstract:** In the day and age of social media, users have become prone to online hate speech. Several attempts have been made to classify hate speech using machine learning but the state-of-the-art models are not robust enough for practical applications. This is attributed to the use of primitive NLP feature engineering techniques. In this paper, we explored various feature engineering techniques ranging from different embeddings to conventional NLP algorithms. We also experimented with combinations of different features. From our experimentation, we realized that roBERTa (robustly optimized BERT approach) based sentence embeddings classified using decision trees gives the best results of 0.9998 F1 score. In our paper, we concluded that BERT based embeddings give the most useful features for this problem and have the capacity to be made into a practical robust model.

</p>
</details>

<details><summary><b>Analysis of Online Toxicity Detection Using Machine Learning Approaches</b>
<a href="https://arxiv.org/abs/2108.01062">arxiv:2108.01062</a>
&#x1F4C8; 2 <br>
<p> Anjum, Rahul Katarya</p></summary>
<p>

**Abstract:** Social media and the internet have become an integral part of how people spread and consume information. Over a period of time, social media evolved dramatically, and almost half of the population is using social media to express their views and opinions. Online hate speech is one of the drawbacks of social media nowadays, which needs to be controlled. In this paper, we will understand how hate speech originated and what are the consequences of it; Trends of machine-learning algorithms to solve an online hate speech problem. This study contributes by providing a systematic approach to help researchers to identify a new research direction and elucidating the shortcomings of the studies and model, as well as providing future directions to advance the field.

</p>
</details>

<details><summary><b>Analysing Cyberbullying using Natural Language Processing by Understanding Jargon in Social Media</b>
<a href="https://arxiv.org/abs/2107.08902">arxiv:2107.08902</a>
&#x1F4C8; 2 <br>
<p>Bhumika Bhatia, Anuj Verma,  Anjum, Rahul Katarya</p></summary>
<p>

**Abstract:** Cyberbullying is of extreme prevalence today. Online-hate comments, toxicity, cyberbullying amongst children and other vulnerable groups are only growing over online classes, and increased access to social platforms, especially post COVID-19. It is paramount to detect and ensure minors' safety across social platforms so that any violence or hate-crime is automatically detected and strict action is taken against it. In our work, we explore binary classification by using a combination of datasets from various social media platforms that cover a wide range of cyberbullying such as sexism, racism, abusive, and hate-speech. We experiment through multiple models such as Bi-LSTM, GloVe, state-of-the-art models like BERT, and apply a unique preprocessing technique by introducing a slang-abusive corpus, achieving a higher precision in comparison to models without slang preprocessing.

</p>
</details>

<details><summary><b>Fuzzy Expert Systems for Prediction of ICU Admission in Patients with COVID-19</b>
<a href="https://arxiv.org/abs/2104.12868">arxiv:2104.12868</a>
&#x1F4C8; 2 <br>
<p>Ali Akbar Sadat Asl, Mohammad Mahdi Ershadi, Shahabeddin Sotudian</p></summary>
<p>

**Abstract:** The pandemic COVID-19 disease has had a dramatic impact on almost all countries around the world so that many hospitals have been overwhelmed with Covid-19 cases. As medical resources are limited, deciding on the proper allocation of these resources is a very crucial issue. Besides, uncertainty is a major factor that can affect decisions, especially in medical fields. To cope with this issue, we use fuzzy logic (FL) as one of the most suitable methods in modeling systems with high uncertainty and complexity. We intend to make use of the advantages of FL in decisions on cases that need to treat in ICU. In this study, an interval type-2 fuzzy expert system is proposed for prediction of ICU admission in COVID-19 patients. For this prediction task, we also developed an adaptive neuro-fuzzy inference system (ANFIS). Finally, the results of these fuzzy systems are compared to some well-known classification methods such as Naive Bayes (NB), Case-Based Reasoning (CBR), Decision Tree (DT), and K Nearest Neighbor (KNN). The results show that the type-2 fuzzy expert system and ANFIS models perform competitively in terms of accuracy and F-measure compared to the other system modeling techniques.

</p>
</details>

<details><summary><b>Certifiably Polynomial Algorithm for Best Group Subset Selection</b>
<a href="https://arxiv.org/abs/2104.12576">arxiv:2104.12576</a>
&#x1F4C8; 2 <br>
<p>Yanhang Zhang, Junxian Zhu, Jin Zhu, Xueqin Wang</p></summary>
<p>

**Abstract:** Best group subset selection aims to choose a small part of non-overlapping groups to achieve the best interpretability on the response variable. It is practically attractive for group variable selection; however, due to the computational intractability in high dimensionality setting, it doesn't catch enough attention. To fill the blank of efficient algorithms for best group subset selection, in this paper, we propose a group-splicing algorithm that iteratively detects effective groups and excludes the helpless ones. Moreover, coupled with a novel Bayesian group information criterion, an adaptive algorithm is developed to determine the true group subset size. It is certifiable that our algorithms enable identifying the optimal group subset in polynomial time under mild conditions. We demonstrate the efficiency and accuracy of our proposal by comparing state-of-the-art algorithms on both synthetic and real-world datasets.

</p>
</details>

<details><summary><b>Infant Vocal Tract Development Analysis and Diagnosis by Cry Signals with CNN Age Classification</b>
<a href="https://arxiv.org/abs/2104.11395">arxiv:2104.11395</a>
&#x1F4C8; 2 <br>
<p>Chunyan Ji, Yi Pan</p></summary>
<p>

**Abstract:** From crying to babbling and then to speech, infant's vocal tract goes through anatomic restructuring. In this paper, we propose a non-invasive fast method of using infant cry signals with convolutional neural network (CNN) based age classification to diagnose the abnormality of the vocal tract development as early as 4-month age. We study F0, F1, F2, and spectrograms and relate them to the postnatal development of infant vocalization. A novel CNN based age classification is performed with binary age pairs to discover the pattern and tendency of the vocal tract changes. The effectiveness of this approach is evaluated on Baby2020 with healthy infant cries and Baby Chillanto database with pathological infant cries. The results show that our approach yields 79.20% accuracy for healthy cries, 84.80% for asphyxiated cries, and 91.20% for deaf cries. Our method first reveals that infants' vocal tract develops to a certain level at 4-month age and infants can start controlling the vocal folds to produce discontinuous cry sounds leading to babbling. Early diagnosis of growth abnormality of the vocal tract can help parents keep vigilant and adopt medical treatment or training therapy for their infants as early as possible.

</p>
</details>

<details><summary><b>Scalable Predictive Time-Series Analysis of COVID-19: Cases and Fatalities</b>
<a href="https://arxiv.org/abs/2104.11349">arxiv:2104.11349</a>
&#x1F4C8; 2 <br>
<p>Shradha Shinde, Jay Joshi, Sowmya Mareedu, Yeon Pyo Kim, Jongwook Woo</p></summary>
<p>

**Abstract:** COVID 19 is an acute disease that started spreading throughout the world, beginning in December 2019. It has spread worldwide and has affected more than 7 million people, and 200 thousand people have died due to this infection as of Oct 2020. In this paper, we have forecasted the number of deaths and the confirmed cases in Los Angeles and New York of the United States using the traditional and Big Data platforms based on the Times Series: ARIMA and ETS. We also implemented a more sophisticated time-series forecast model using Facebook Prophet API. Furthermore, we developed the classification models: Logistic Regression and Random Forest regression to show that the Weather does not affect the number of the confirmed cases. The models are built and run in legacy systems (Azure ML Studio) and Big Data systems (Oracle Cloud and Databricks). Besides, we present the accuracy of the models.

</p>
</details>

<details><summary><b>Landmark-Aware and Part-based Ensemble Transfer Learning Network for Facial Expression Recognition from Static images</b>
<a href="https://arxiv.org/abs/2104.11274">arxiv:2104.11274</a>
&#x1F4C8; 2 <br>
<p>Rohan Wadhawan, Tapan K. Gandhi</p></summary>
<p>

**Abstract:** Facial Expression Recognition from static images is a challenging problem in computer vision applications. Convolutional Neural Network (CNN), the state-of-the-art method for various computer vision tasks, has had limited success in predicting expressions from faces having extreme poses, illumination, and occlusion conditions. To mitigate this issue, CNNs are often accompanied by techniques like transfer, multi-task, or ensemble learning that often provide high accuracy at the cost of increased computational complexity. In this work, we propose a Part-based Ensemble Transfer Learning network that models how humans recognize facial expressions by correlating the spatial orientation pattern of the facial features with a specific expression. It consists of 5 sub-networks, and each sub-network performs transfer learning from one of the five subsets of facial landmarks: eyebrows, eyes, nose, mouth, or jaw to expression classification. We show that our proposed ensemble network uses visual patterns emanating from facial muscles' motor movements to predict expressions and demonstrate the usefulness of transfer learning from Facial Landmark Localization to Facial Expression Recognition. We test the proposed network on the CK+, JAFFE, and SFEW datasets, and it outperforms the benchmark for CK+ and JAFFE datasets by 0.51% and 5.34%, respectively. Additionally, the proposed ensemble network consists of only 1.65M model parameters, ensuring computational efficiency during training and real-time deployment. Grad-CAM visualizations of our proposed ensemble highlight the complementary nature of its sub-networks, a key design parameter of an effective ensemble network. Lastly, cross-dataset evaluation results reveal that our proposed ensemble has a high generalization capacity, making it suitable for real-world usage.

</p>
</details>

<details><summary><b>Noise-Robust Deep Spiking Neural Networks with Temporal Information</b>
<a href="https://arxiv.org/abs/2104.11169">arxiv:2104.11169</a>
&#x1F4C8; 2 <br>
<p>Seongsik Park, Dongjin Lee, Sungroh Yoon</p></summary>
<p>

**Abstract:** Spiking neural networks (SNNs) have emerged as energy-efficient neural networks with temporal information. SNNs have shown a superior efficiency on neuromorphic devices, but the devices are susceptible to noise, which hinders them from being applied in real-world applications. Several studies have increased noise robustness, but most of them considered neither deep SNNs nor temporal information. In this paper, we investigate the effect of noise on deep SNNs with various neural coding methods and present a noise-robust deep SNN with temporal information. With the proposed methods, we have achieved a deep SNN that is efficient and robust to spike deletion and jitter.

</p>
</details>

<details><summary><b>An Efficient One-Class SVM for Anomaly Detection in the Internet of Things</b>
<a href="https://arxiv.org/abs/2104.11146">arxiv:2104.11146</a>
&#x1F4C8; 2 <br>
<p>Kun Yang, Samory Kpotufe, Nick Feamster</p></summary>
<p>

**Abstract:** Insecure Internet of things (IoT) devices pose significant threats to critical infrastructure and the Internet at large; detecting anomalous behavior from these devices remains of critical importance, but fast, efficient, accurate anomaly detection (also called "novelty detection") for these classes of devices remains elusive. One-Class Support Vector Machines (OCSVM) are one of the state-of-the-art approaches for novelty detection (or anomaly detection) in machine learning, due to their flexibility in fitting complex nonlinear boundaries between {normal} and {novel} data. IoT devices in smart homes and cities and connected building infrastructure present a compelling use case for novelty detection with OCSVM due to the variety of devices, traffic patterns, and types of anomalies that can manifest in such environments. Much previous research has thus applied OCSVM to novelty detection for IoT. Unfortunately, conventional OCSVMs introduce significant memory requirements and are computationally expensive at prediction time as the size of the train set grows, requiring space and time that scales with the number of training points. These memory and computational constraints can be prohibitive in practical, real-world deployments, where large training sets are typically needed to develop accurate models when fitting complex decision boundaries. In this work, we extend so-called Nyström and (Gaussian) Sketching approaches to OCSVM, by combining these methods with clustering and Gaussian mixture models to achieve significant speedups in prediction time and space in various IoT settings, without sacrificing detection accuracy.

</p>
</details>

<details><summary><b>Synchronization of Tree Parity Machines using non-binary input vectors</b>
<a href="https://arxiv.org/abs/2104.11105">arxiv:2104.11105</a>
&#x1F4C8; 2 <br>
<p>Miłosz Stypiński, Marcin Niemiec</p></summary>
<p>

**Abstract:** Neural cryptography is the application of artificial neural networks in the subject of cryptography. The functionality of this solution is based on a tree parity machine. It uses artificial neural networks to perform secure key exchange between network entities. This article proposes improvements to the synchronization of two tree parity machines. The improvement is based on learning artificial neural network using input vectors which have a wider range of values than binary ones. As a result, the duration of the synchronization process is reduced. Therefore, tree parity machines achieve common weights in a shorter time due to the reduction of necessary bit exchanges. This approach improves the security of neural cryptography

</p>
</details>

<details><summary><b>MRRT: Multiple Rapidly-Exploring Random Trees for Fast Online Replanning in Dynamic Environments</b>
<a href="https://arxiv.org/abs/2104.11059">arxiv:2104.11059</a>
&#x1F4C8; 2 <br>
<p>Zongyuan Shen, James P. Wilson, Ryan Harvey, Shalabh Gupta</p></summary>
<p>

**Abstract:** This paper presents a novel algorithm, called MRRT, which uses multiple rapidly-exploring random trees for fast online replanning of autonomous vehicles in dynamic environments with moving obstacles. The proposed algorithm is built upon the RRT algorithm with a multi-tree structure. At the beginning, the RRT algorithm is applied to find the initial solution based on partial knowledge of the environment. Then, the robot starts to execute this path. At each iteration, the new obstacle configurations are collected by the robot's sensor and used to replan the path. This new information can come from unknown static obstacles (e.g., seafloor layout) as well as moving obstacles. Then, to accommodate the environmental changes, two procedures are adopted: 1) edge pruning, and 2) tree regrowing. Specifically, the edge pruning procedure checks the collision status through the tree and only removes the invalid edges while maintaining the tree structure of already-explored regions. Due to removal of invalid edges, the tree could be broken into multiple disjoint trees. As such, the RRT algorithm is applied to regrow the trees. Specifically, a sample is created randomly and joined to all the disjoint trees in its local neighborhood by connecting to the nearest nodes. Finally, a new solution is found for the robot. The advantages of the proposed MRRT algorithm are as follows: i) retains the maximal tree structure by only pruning the edges which collide with the obstacles, ii) guarantees probabilistic completeness, and iii) is computational efficient for fast replanning since all disjoint trees are maintained for future connections and expanded simultaneously.

</p>
</details>

<details><summary><b>Time series analysis with dynamic law exploration</b>
<a href="https://arxiv.org/abs/2104.10970">arxiv:2104.10970</a>
&#x1F4C8; 2 <br>
<p>A. Jakovac</p></summary>
<p>

**Abstract:** In this paper we examine, how the dynamic laws governing the time evolution of a time series can be identified. We give a finite difference equation as well as a differential equation representation for that. We also study, how the required symmetries, like time reversal can be imposed on the laws. We study the compression performance of linear laws on sound data.

</p>
</details>

<details><summary><b>XCrossNet: Feature Structure-Oriented Learning for Click-Through Rate Prediction</b>
<a href="https://arxiv.org/abs/2104.10907">arxiv:2104.10907</a>
&#x1F4C8; 2 <br>
<p>Runlong Yu, Yuyang Ye, Qi Liu, Zihan Wang, Chunfeng Yang, Yucheng Hu, Enhong Chen</p></summary>
<p>

**Abstract:** Click-Through Rate (CTR) prediction is a core task in nowadays commercial recommender systems. Feature crossing, as the mainline of research on CTR prediction, has shown a promising way to enhance predictive performance.
  Even though various models are able to learn feature interactions without manual feature engineering, they rarely attempt to individually learn representations for different feature structures.
  In particular, they mainly focus on the modeling of cross sparse features but neglect to specifically represent cross dense features.
  Motivated by this, we propose a novel Extreme Cross Network, abbreviated XCrossNet, which aims at learning dense and sparse feature interactions in an explicit manner.
  XCrossNet as a feature structure-oriented model leads to a more expressive representation and a more precise CTR prediction, which is not only explicit and interpretable, but also time-efficient and easy to implement.
  Experimental studies on Criteo Kaggle dataset show significant improvement of XCrossNet over state-of-the-art models on both effectiveness and efficiency.

</p>
</details>

<details><summary><b>Software-Defined Edge Computing: A New Architecture Paradigm to Support IoT Data Analysis</b>
<a href="https://arxiv.org/abs/2104.11645">arxiv:2104.11645</a>
&#x1F4C8; 1 <br>
<p>Di Wu, Xiaofeng Xie, Xiang Ni, Bin Fu, Hanhui Deng, Haibo Zeng, Zhijin Qin</p></summary>
<p>

**Abstract:** The rapid deployment of Internet of Things (IoT) applications leads to massive data that need to be processed. These IoT applications have specific communication requirements on latency and bandwidth, and present new features on their generated data such as time-dependency. Therefore, it is desirable to reshape the current IoT architectures by exploring their inherent nature of communication and computing to support smart IoT data process and analysis. We introduce in this paper features of IoT data, trends of IoT network architectures, some problems in IoT data analysis, and their solutions. Specifically, we view that software-defined edge computing is a promising architecture to support the unique needs of IoT data analysis. We further present an experiment on data anomaly detection in this architecture, and the comparison between two architectures for ECG diagnosis. Results show that our method is effective and feasible.

</p>
</details>

<details><summary><b>A modularity comparison of Long Short-Term Memory and Morphognosis neural networks</b>
<a href="https://arxiv.org/abs/2104.11410">arxiv:2104.11410</a>
&#x1F4C8; 1 <br>
<p>Thomas E. Portegys</p></summary>
<p>

**Abstract:** This study compares the modularity performance of two artificial neural network architectures: a Long Short-Term Memory (LSTM) recurrent network, and Morphognosis, a neural network based on a hierarchy of spatial and temporal contexts. Mazes are used to measure performance, defined as the ability to utilize independently learned mazes to solve mazes composed of them. A maze is a sequence of rooms connected by doors. The modular task is implemented as follows: at the beginning of the maze, an initial door choice forms a context that must be retained until the end of an intervening maze, where the same door must be chosen again to reach the goal. For testing, the door-association mazes and separately trained intervening mazes are presented together for the first time. While both neural networks perform well during training, the testing performance of Morphognosis is significantly better than LSTM on this modular task.

</p>
</details>

<details><summary><b>Decentralized Federated Averaging</b>
<a href="https://arxiv.org/abs/2104.11375">arxiv:2104.11375</a>
&#x1F4C8; 1 <br>
<p>Tao Sun, Dongsheng Li, Bao Wang</p></summary>
<p>

**Abstract:** Federated averaging (FedAvg) is a communication efficient algorithm for the distributed training with an enormous number of clients. In FedAvg, clients keep their data locally for privacy protection; a central parameter server is used to communicate between clients. This central server distributes the parameters to each client and collects the updated parameters from clients. FedAvg is mostly studied in centralized fashions, which requires massive communication between server and clients in each communication. Moreover, attacking the central server can break the whole system's privacy. In this paper, we study the decentralized FedAvg with momentum (DFedAvgM), which is implemented on clients that are connected by an undirected graph. In DFedAvgM, all clients perform stochastic gradient descent with momentum and communicate with their neighbors only. To further reduce the communication cost, we also consider the quantized DFedAvgM. We prove convergence of the (quantized) DFedAvgM under trivial assumptions; the convergence rate can be improved when the loss function satisfies the PŁ property. Finally, we numerically verify the efficacy of DFedAvgM.

</p>
</details>

<details><summary><b>Constructing a personalized learning path using genetic algorithms approach</b>
<a href="https://arxiv.org/abs/2104.11276">arxiv:2104.11276</a>
&#x1F4C8; 1 <br>
<p>Lumbardh Elshani, Krenare Pireva Nuçi</p></summary>
<p>

**Abstract:** A substantial disadvantage of traditional learning is that all students follow the same learning sequence, but not all of them have the same background of knowledge, the same preferences, the same learning goals, and the same needs. Traditional teaching resources, such as textbooks, in most cases pursue students to follow fixed sequences during the learning process, thus impairing their performance. Learning sequencing is an important research issue as part of the learning process because no fixed learning paths will be appropriate for all learners. For this reason, many research papers are focused on the development of mechanisms to offer personalization on learning paths, considering the learner needs, interests, behaviors, and abilities. In most cases, these researchers are totally focused on the student's preferences, ignoring the level of difficulty and the relation degree that exists between various concepts in a course. This research paper presents the possibility of constructing personalized learning paths using genetic algorithm-based model, encountering the level of difficulty and relation degree of the constituent concepts of a course. The experimental results shows that the genetic algorithm is suitable to generate optimal learning paths based on learning object difficulty level, duration, rating, and relation degree between each learning object as elementary parts of the sequence of the learning path. From these results compared to the quality of the traditional learning path, we observed that even the quality of the weakest learning path generated by our GA approach is in a favor compared to quality of the traditional learning path, with a difference of 3.59\%, while the highest solution generated in the end resulted 8.34\% in favor of our proposal compared to the traditional learning paths.

</p>
</details>

<details><summary><b>Literature review on vulnerability detection using NLP technology</b>
<a href="https://arxiv.org/abs/2104.11230">arxiv:2104.11230</a>
&#x1F4C8; 1 <br>
<p>Jiajie Wu</p></summary>
<p>

**Abstract:** Vulnerability detection has always been the most important task in the field of software security. With the development of technology, in the face of massive source code, automated analysis and detection of vulnerabilities has become a current research hotspot. For special text files such as source code, using some of the hottest NLP technologies to build models and realize the automatic analysis and detection of source code has become one of the most anticipated studies in the field of vulnerability detection. This article does a brief survey of some recent new documents and technologies, such as CodeBERT, and summarizes the previous technologies.

</p>
</details>

<details><summary><b>Enabling Cross-Layer Reliability and Functional Safety Assessment Through ML-Based Compact Models</b>
<a href="https://arxiv.org/abs/2104.10941">arxiv:2104.10941</a>
&#x1F4C8; 1 <br>
<p>Dan Alexandrescu, Aneesh Balakrishnan, Thomas Lange, Maximilien Glorieux</p></summary>
<p>

**Abstract:** Typical design flows are hierarchical and rely on assembling many individual technology elements from standard cells to complete boards. Providers use compact models to provide simplified views of their products to their users. Designers group simpler elements in more complex structures and have to manage the corresponding propagation of reliability and functional safety information through the hierarchy of the system, accompanied by the obvious problems of IP confidentiality, possibility of reverse engineering and so on. This paper proposes a machine-learning-based approach to integrate the many individual models of a subsystem's elements in a single compact model that can be re-used and assembled further up in the hierarchy. The compact models provide consistency, accuracy and confidentiality, allowing technology, IP, component, sub-system or system providers to accompany their offering with high-quality reliability and functional safety compact models that can be safely and accurately consumed by their users.

</p>
</details>

<details><summary><b>Intentional Deep Overfit Learning (IDOL): A Novel Deep Learning Strategy for Adaptive Radiation Therapy</b>
<a href="https://arxiv.org/abs/2104.11401">arxiv:2104.11401</a>
&#x1F4C8; 0 <br>
<p>Jaehee Chun, Justin C. Park, Sven Olberg, You Zhang, Dan Nguyen, Jing Wang, Jin Sung Kim, Steve Jiang</p></summary>
<p>

**Abstract:** In this study, we propose a tailored DL framework for patient-specific performance that leverages the behavior of a model intentionally overfitted to a patient-specific training dataset augmented from the prior information available in an ART workflow - an approach we term Intentional Deep Overfit Learning (IDOL). Implementing the IDOL framework in any task in radiotherapy consists of two training stages: 1) training a generalized model with a diverse training dataset of N patients, just as in the conventional DL approach, and 2) intentionally overfitting this general model to a small training dataset-specific the patient of interest (N+1) generated through perturbations and augmentations of the available task- and patient-specific prior information to establish a personalized IDOL model. The IDOL framework itself is task-agnostic and is thus widely applicable to many components of the ART workflow, three of which we use as a proof of concept here: the auto-contouring task on re-planning CTs for traditional ART, the MRI super-resolution (SR) task for MRI-guided ART, and the synthetic CT (sCT) reconstruction task for MRI-only ART. In the re-planning CT auto-contouring task, the accuracy measured by the Dice similarity coefficient improves from 0.847 with the general model to 0.935 by adopting the IDOL model. In the case of MRI SR, the mean absolute error (MAE) is improved by 40% using the IDOL framework over the conventional model. Finally, in the sCT reconstruction task, the MAE is reduced from 68 to 22 HU by utilizing the IDOL framework.

</p>
</details>

<details><summary><b>Connecting Hamilton--Jacobi partial differential equations with maximum a posteriori and posterior mean estimators for some non-convex priors</b>
<a href="https://arxiv.org/abs/2104.11285">arxiv:2104.11285</a>
&#x1F4C8; 0 <br>
<p>Jérôme Darbon, Gabriel P. Langlois, Tingwei Meng</p></summary>
<p>

**Abstract:** Many imaging problems can be formulated as inverse problems expressed as finite-dimensional optimization problems. These optimization problems generally consist of minimizing the sum of a data fidelity and regularization terms. In [23,26], connections between these optimization problems and (multi-time) Hamilton--Jacobi partial differential equations have been proposed under the convexity assumptions of both the data fidelity and regularization terms. In particular, under these convexity assumptions, some representation formulas for a minimizer can be obtained. From a Bayesian perspective, such a minimizer can be seen as a maximum a posteriori estimator. In this chapter, we consider a certain class of non-convex regularizations and show that similar representation formulas for the minimizer can also be obtained. This is achieved by leveraging min-plus algebra techniques that have been originally developed for solving certain Hamilton--Jacobi partial differential equations arising in optimal control. Note that connections between viscous Hamilton--Jacobi partial differential equations and Bayesian posterior mean estimators with Gaussian data fidelity terms and log-concave priors have been highlighted in [25]. We also present similar results for certain Bayesian posterior mean estimators with Gaussian data fidelity and certain non-log-concave priors using an analogue of min-plus algebra techniques.

</p>
</details>

<details><summary><b>Model-Driven Deep Learning Based Channel Estimation and Feedback for Millimeter-Wave Massive Hybrid MIMO Systems</b>
<a href="https://arxiv.org/abs/2104.11052">arxiv:2104.11052</a>
&#x1F4C8; 0 <br>
<p>Xisuo Ma, Zhen Gao, Feifei Gao, Marco Di Renzo</p></summary>
<p>

**Abstract:** This paper proposes a model-driven deep learning (MDDL)-based channel estimation and feedback scheme for wideband millimeter-wave (mmWave) massive hybrid multiple-input multiple-output (MIMO) systems, where the angle-delay domain channels' sparsity is exploited for reducing the overhead. Firstly, we consider the uplink channel estimation for time-division duplexing systems. To reduce the uplink pilot overhead for estimating the high-dimensional channels from a limited number of radio frequency (RF) chains at the base station (BS), we propose to jointly train the phase shift network and the channel estimator as an auto-encoder. Particularly, by exploiting the channels' structured sparsity from an a priori model and learning the integrated trainable parameters from the data samples, the proposed multiple-measurement-vectors learned approximate message passing (MMV-LAMP) network with the devised redundant dictionary can jointly recover multiple subcarriers' channels with significantly enhanced performance. Moreover, we consider the downlink channel estimation and feedback for frequency-division duplexing systems. Similarly, the pilots at the BS and channel estimator at the users can be jointly trained as an encoder and a decoder, respectively. Besides, to further reduce the channel feedback overhead, only the received pilots on part of the subcarriers are fed back to the BS, which can exploit the MMV-LAMP network to reconstruct the spatial-frequency channel matrix. Numerical results show that the proposed MDDL-based channel estimation and feedback scheme outperforms the state-of-the-art approaches.

</p>
</details>

<details><summary><b>SoT: Delving Deeper into Classification Head for Transformer</b>
<a href="https://arxiv.org/abs/2104.10935">arxiv:2104.10935</a>
&#x1F4C8; 0 <br>
<p>Jiangtao Xie, Ruiren Zeng, Qilong Wang, Ziqi Zhou, Peihua Li</p></summary>
<p>

**Abstract:** Transformer models are not only successful in natural language processing (NLP) but also demonstrate high potential in computer vision (CV). Despite great advance, most of works only focus on improvement of architectures but pay little attention to the classification head. For years transformer models base exclusively on classification token to construct the final classifier, without explicitly harnessing high-level word tokens. In this paper, we propose a novel transformer model called second-order transformer (SoT), exploiting simultaneously the classification token and word tokens for the classifier. Specifically, we empirically disclose that high-level word tokens contain rich information, which per se are very competent with the classifier and moreover, are complementary to the classification token. To effectively harness such rich information, we propose multi-headed global cross-covariance pooling with singular value power normalization, which shares similar philosophy and thus is compatible with the transformer block, better than commonly used pooling methods. Then, we study comprehensively how to explicitly combine word tokens with classification token for building the final classification head. For CV tasks, our SoT significantly improves state-of-the-art vision transformers on challenging benchmarks including ImageNet and ImageNet-A. For NLP tasks, through fine-tuning based on pretrained language transformers including GPT and BERT, our SoT greatly boosts the performance on widely used tasks such as CoLA and RTE. Code will be available at https://peihuali.org/SoT

</p>
</details>

<details><summary><b>Blockchain based Privacy-Preserved Federated Learning for Medical Images: A Case Study of COVID-19 CT Scans</b>
<a href="https://arxiv.org/abs/2104.10903">arxiv:2104.10903</a>
&#x1F4C8; 0 <br>
<p>Rajesh Kumar, WenYong Wang, Cheng Yuan, Jay Kumar,  Zakria, He Qing, Ting Yang, Abdullah Aman Khan</p></summary>
<p>

**Abstract:** Medical health care centers are envisioned as a promising paradigm to handle the massive volume of data of COVID-19 patients using artificial intelligence (AI). Traditionally, AI techniques often require centralized data collection and training the model in a single organization, which is most common weakness due to the privacy and security of raw data communication. To solve this challenging task, we propose a blockchain-based federated learning framework that provides collaborative data training solutions by coordinating multiple hospitals to train and share encrypted federated models without leakage of data privacy. The blockchain ledger technology provides the decentralization of federated learning model without any central server. The proposed homomorphic encryption scheme encrypts and decrypts the gradients of model to preserve the privacy. More precisely, the proposed framework: i) train the local model by a novel capsule network to segmentation and classify COVID-19 images, ii) then use the homomorphic encryption scheme to secure the local model that encrypts and decrypts the gradients, and finally the model is shared over a decentralized platform through proposed blockchain-based federated learning algorithm. The integration of blockchain and federated learning leads to a new paradigm for medical image data sharing in the decentralized network. The conducted experimental resultsdemonstrate the performance of the proposed scheme.

</p>
</details>


[Next Page](2021/2021-04/2021-04-21.md)
