## Summary for 2021-11-28, created on 2021-12-18


<details><summary><b>Long-range and hierarchical language predictions in brains and algorithms</b>
<a href="https://arxiv.org/abs/2111.14232">arxiv:2111.14232</a>
&#x1F4C8; 150 <br>
<p>Charlotte Caucheteux, Alexandre Gramfort, Jean-Remi King</p></summary>
<p>

**Abstract:** Deep learning has recently made remarkable progress in natural language processing. Yet, the resulting algorithms remain far from competing with the language abilities of the human brain. Predictive coding theory offers a potential explanation to this discrepancy: while deep language algorithms are optimized to predict adjacent words, the human brain would be tuned to make long-range and hierarchical predictions. To test this hypothesis, we analyze the fMRI brain signals of 304 subjects each listening to 70min of short stories. After confirming that the activations of deep language algorithms linearly map onto those of the brain, we show that enhancing these models with long-range forecast representations improves their brain-mapping. The results further reveal a hierarchy of predictions in the brain, whereby the fronto-parietal cortices forecast more abstract and more distant representations than the temporal cortices. Overall, this study strengthens predictive coding theory and suggests a critical role of long-range and hierarchical predictions in natural language processing.

</p>
</details>

<details><summary><b>Customer Sentiment Analysis using Weak Supervision for Customer-Agent Chat</b>
<a href="https://arxiv.org/abs/2111.14282">arxiv:2111.14282</a>
&#x1F4C8; 9 <br>
<p>Navdeep Jain</p></summary>
<p>

**Abstract:** Prior work on sentiment analysis using weak supervision primarily focuses on different reviews such as movies (IMDB), restaurants (Yelp), products (Amazon).~One under-explored field in this regard is customer chat data for a customer-agent chat in customer support due to the lack of availability of free public data. Here, we perform sentiment analysis on customer chat using weak supervision on our in-house dataset. We fine-tune the pre-trained language model (LM) RoBERTa as a sentiment classifier using weak supervision. Our contribution is as follows:1) We show that by using weak sentiment classifiers along with domain-specific lexicon-based rules as Labeling Functions (LF), we can train a fairly accurate customer chat sentiment classifier using weak supervision. 2) We compare the performance of our custom-trained model with off-the-shelf google cloud NLP API for sentiment analysis. We show that by injecting domain-specific knowledge using LFs, even with weak supervision, we can train a model to handle some domain-specific use cases better than off-the-shelf google cloud NLP API. 3) We also present an analysis of how customer sentiment in a chat relates to problem resolution.

</p>
</details>

<details><summary><b>The CSIRO Crown-of-Thorn Starfish Detection Dataset</b>
<a href="https://arxiv.org/abs/2111.14311">arxiv:2111.14311</a>
&#x1F4C8; 8 <br>
<p>Jiajun Liu, Brano Kusy, Ross Marchant, Brendan Do, Torsten Merz, Joey Crosswell, Andy Steven, Nic Heaney, Karl von Richter, Lachlan Tychsen-Smith, David Ahmedt-Aristizabal, Mohammad Ali Armin, Geoffrey Carlin, Russ Babcock, Peyman Moghadam, Daniel Smith, Tim Davis, Kemal El Moujahid, Martin Wicke, Megha Malpani</p></summary>
<p>

**Abstract:** Crown-of-Thorn Starfish (COTS) outbreaks are a major cause of coral loss on the Great Barrier Reef (GBR) and substantial surveillance and control programs are underway in an attempt to manage COTS populations to ecologically sustainable levels. We release a large-scale, annotated underwater image dataset from a COTS outbreak area on the GBR, to encourage research on Machine Learning and AI-driven technologies to improve the detection, monitoring, and management of COTS populations at reef scale. The dataset is released and hosted in a Kaggle competition that challenges the international Machine Learning community with the task of COTS detection from these underwater images.

</p>
</details>

<details><summary><b>Towards Conditional Generation of Minimal Action Potential Pathways for Molecular Dynamics</b>
<a href="https://arxiv.org/abs/2111.14053">arxiv:2111.14053</a>
&#x1F4C8; 8 <br>
<p>John Kevin Cava, John Vant, Nicholas Ho, Ankita Shulka, Pavan Turaga, Ross Maciejewski, Abhishek Singharoy</p></summary>
<p>

**Abstract:** In this paper, we utilized generative models, and reformulate it for problems in molecular dynamics (MD) simulation, by introducing an MD potential energy component to our generative model. By incorporating potential energy as calculated from TorchMD into a conditional generative framework, we attempt to construct a low-potential energy route of transformation between the helix~$\rightarrow$~coil structures of a protein. We show how to add an additional loss function to conditional generative models, motivated by potential energy of molecular configurations, and also present an optimization technique for such an augmented loss function. Our results show the benefit of this additional loss term on synthesizing realistic molecular trajectories.

</p>
</details>

<details><summary><b>A General Framework for Defending Against Backdoor Attacks via Influence Graph</b>
<a href="https://arxiv.org/abs/2111.14309">arxiv:2111.14309</a>
&#x1F4C8; 7 <br>
<p>Xiaofei Sun, Jiwei Li, Xiaoya Li, Ziyao Wang, Tianwei Zhang, Han Qiu, Fei Wu, Chun Fan</p></summary>
<p>

**Abstract:** In this work, we propose a new and general framework to defend against backdoor attacks, inspired by the fact that attack triggers usually follow a \textsc{specific} type of attacking pattern, and therefore, poisoned training examples have greater impacts on each other during training. We introduce the notion of the {\it influence graph}, which consists of nodes and edges respectively representative of individual training points and associated pair-wise influences. The influence between a pair of training points represents the impact of removing one training point on the prediction of another, approximated by the influence function \citep{koh2017understanding}. Malicious training points are extracted by finding the maximum average sub-graph subject to a particular size. Extensive experiments on computer vision and natural language processing tasks demonstrate the effectiveness and generality of the proposed framework.

</p>
</details>

<details><summary><b>Transfer Learning with Jukebox for Music Source Separation</b>
<a href="https://arxiv.org/abs/2111.14200">arxiv:2111.14200</a>
&#x1F4C8; 7 <br>
<p>Wadhah Zai El Amri, Oliver Tautz, Helge Ritter, Andrew Melnik</p></summary>
<p>

**Abstract:** In this work, we demonstrate how to adapt a publicly available pre-trained Jukebox model for the problem of audio source separation from a single mixed audio channel. Our neural network architecture for transfer learning is fast to train and results demonstrate comparable performance to other state-of-the-art approaches. We provide an open-source code implementation of our architecture (https://rebrand.ly/transfer-jukebox-github).

</p>
</details>

<details><summary><b>ExCon: Explanation-driven Supervised Contrastive Learning for Image Classification</b>
<a href="https://arxiv.org/abs/2111.14271">arxiv:2111.14271</a>
&#x1F4C8; 6 <br>
<p>Zhibo Zhang, Jongseong Jang, Chiheb Trabelsi, Ruiwen Li, Scott Sanner, Yeonjeong Jeong, Dongsub Shim</p></summary>
<p>

**Abstract:** Contrastive learning has led to substantial improvements in the quality of learned embedding representations for tasks such as image classification. However, a key drawback of existing contrastive augmentation methods is that they may lead to the modification of the image content which can yield undesired alterations of its semantics. This can affect the performance of the model on downstream tasks. Hence, in this paper, we ask whether we can augment image data in contrastive learning such that the task-relevant semantic content of an image is preserved. For this purpose, we propose to leverage saliency-based explanation methods to create content-preserving masked augmentations for contrastive learning. Our novel explanation-driven supervised contrastive learning (ExCon) methodology critically serves the dual goals of encouraging nearby image embeddings to have similar content and explanation. To quantify the impact of ExCon, we conduct experiments on the CIFAR-100 and the Tiny ImageNet datasets. We demonstrate that ExCon outperforms vanilla supervised contrastive learning in terms of classification, explanation quality, adversarial robustness as well as calibration of probabilistic predictions of the model in the context of distributional shift.

</p>
</details>

<details><summary><b>EffCNet: An Efficient CondenseNet for Image Classification on NXP BlueBox</b>
<a href="https://arxiv.org/abs/2111.14243">arxiv:2111.14243</a>
&#x1F4C8; 6 <br>
<p>Priyank Kalgaonkar, Mohamed El-Sharkawy</p></summary>
<p>

**Abstract:** Intelligent edge devices with built-in processors vary widely in terms of capability and physical form to perform advanced Computer Vision (CV) tasks such as image classification and object detection, for example. With constant advances in the field of autonomous cars and UAVs, embedded systems and mobile devices, there has been an ever-growing demand for extremely efficient Artificial Neural Networks (ANN) for real-time inference on these smart edge devices with constrained computational resources. With unreliable network connections in remote regions and an added complexity of data transmission, it is of an utmost importance to capture and process data locally instead of sending the data to cloud servers for remote processing. Edge devices on the other hand, offer limited processing power due to their inexpensive hardware, and limited cooling and computational resources. In this paper, we propose a novel deep convolutional neural network architecture called EffCNet which is an improved and an efficient version of CondenseNet Convolutional Neural Network (CNN) for edge devices utilizing self-querying data augmentation and depthwise separable convolutional strategies to improve real-time inference performance as well as reduce the final trained model size, trainable parameters, and Floating-Point Operations (FLOPs) of EffCNet CNN. Furthermore, extensive supervised image classification analyses are conducted on two benchmarking datasets: CIFAR-10 and CIFAR-100, to verify real-time inference performance of our proposed CNN. Finally, we deploy these trained weights on NXP BlueBox which is an intelligent edge development platform designed for self-driving vehicles and UAVs, and conclusions will be extrapolated accordingly.

</p>
</details>

<details><summary><b>Zero-Shot Cross-Lingual Transfer in Legal Domain Using Transformer Models</b>
<a href="https://arxiv.org/abs/2111.14192">arxiv:2111.14192</a>
&#x1F4C8; 6 <br>
<p>Zein Shaheen, Gerhard Wohlgenannt, Dmitry Mouromtsev</p></summary>
<p>

**Abstract:** Zero-shot cross-lingual transfer is an important feature in modern NLP models and architectures to support low-resource languages. In this work, We study zero-shot cross-lingual transfer from English to French and German under Multi-Label Text Classification, where we train a classifier using English training set, and we test using French and German test sets. We extend EURLEX57K dataset, the English dataset for topic classification of legal documents, with French and German official translation. We investigate the effect of using some training techniques, namely Gradual Unfreezing and Language Model finetuning, on the quality of zero-shot cross-lingual transfer. We find that Language model finetuning of multi-lingual pre-trained model (M-DistilBERT, M-BERT) leads to 32.0-34.94%, 76.15-87.54% relative improvement on French and German test sets correspondingly. Also, Gradual unfreezing of pre-trained model's layers during training results in relative improvement of 38-45% for French and 58-70% for German. Compared to training a model in Joint Training scheme using English, French and German training sets, zero-shot BERT-based classification model reaches 86% of the performance achieved by jointly-trained BERT-based classification model.

</p>
</details>

<details><summary><b>Gram Barcodes for Histopathology Tissue Texture Retrieval</b>
<a href="https://arxiv.org/abs/2111.15519">arxiv:2111.15519</a>
&#x1F4C8; 5 <br>
<p>Shalev Lifshitz, Abtin Riasatian, H. R. Tizhoosh</p></summary>
<p>

**Abstract:** Recent advances in digital pathology have led to the need for Histopathology Image Retrieval (HIR) systems that search through databases of biopsy images to find similar cases to a given query image. These HIR systems allow pathologists to effortlessly and efficiently access thousands of previously diagnosed cases in order to exploit the knowledge in the corresponding pathology reports. Since HIR systems may have to deal with millions of gigapixel images, the extraction of compact and expressive image features must be available to allow for efficient and accurate retrieval. In this paper, we propose the application of Gram barcodes as image features for HIR systems. Unlike most feature generation schemes, Gram barcodes are based on high-order statistics that describe tissue texture by summarizing the correlations between different feature maps in layers of convolutional neural networks. We run HIR experiments on three public datasets using a pre-trained VGG19 network for Gram barcode generation and showcase highly competitive results.

</p>
</details>

<details><summary><b>TinyDefectNet: Highly Compact Deep Neural Network Architecture for High-Throughput Manufacturing Visual Quality Inspection</b>
<a href="https://arxiv.org/abs/2111.14319">arxiv:2111.14319</a>
&#x1F4C8; 5 <br>
<p>Mohammad Javad Shafiee, Mahmoud Famouri, Gautam Bathla, Francis Li, Alexander Wong</p></summary>
<p>

**Abstract:** A critical aspect in the manufacturing process is the visual quality inspection of manufactured components for defects and flaws. Human-only visual inspection can be very time-consuming and laborious, and is a significant bottleneck especially for high-throughput manufacturing scenarios. Given significant advances in the field of deep learning, automated visual quality inspection can lead to highly efficient and reliable detection of defects and flaws during the manufacturing process. However, deep learning-driven visual inspection methods often necessitate significant computational resources, thus limiting throughput and act as a bottleneck to widespread adoption for enabling smart factories. In this study, we investigated the utilization of a machine-driven design exploration approach to create TinyDefectNet, a highly compact deep convolutional network architecture tailored for high-throughput manufacturing visual quality inspection. TinyDefectNet comprises of just ~427K parameters and has a computational complexity of ~97M FLOPs, yet achieving a detection accuracy of a state-of-the-art architecture for the task of surface defect detection on the NEU defect benchmark dataset. As such, TinyDefectNet can achieve the same level of detection performance at 52$\times$ lower architectural complexity and 11x lower computational complexity. Furthermore, TinyDefectNet was deployed on an AMD EPYC 7R32, and achieved 7.6x faster throughput using the native Tensorflow environment and 9x faster throughput using AMD ZenDNN accelerator library. Finally, explainability-driven performance validation strategy was conducted to ensure correct decision-making behaviour was exhibited by TinyDefectNet to improve trust in its usage by operators and inspectors.

</p>
</details>

<details><summary><b>PSG: Prompt-based Sequence Generation for Acronym Extraction</b>
<a href="https://arxiv.org/abs/2111.14301">arxiv:2111.14301</a>
&#x1F4C8; 5 <br>
<p>Bin Li, Fei Xia, Yixuan Weng, Xiusheng Huang, Bin Sun, Shutao Li</p></summary>
<p>

**Abstract:** Acronym extraction aims to find acronyms (i.e., short-forms) and their meanings (i.e., long-forms) from the documents, which is important for scientific document understanding (SDU@AAAI-22) tasks. Previous works are devoted to modeling this task as a paragraph-level sequence labeling problem. However, it lacks the effective use of the external knowledge, especially when the datasets are in a low-resource setting. Recently, the prompt-based method with the vast pre-trained language model can significantly enhance the performance of the low-resourced downstream tasks. In this paper, we propose a Prompt-based Sequence Generation (PSG) method for the acronym extraction task. Specifically, we design a template for prompting the extracted acronym texts with auto-regression. A position extraction algorithm is designed for extracting the position of the generated answers. The results on the acronym extraction of Vietnamese and Persian in a low-resource setting show that the proposed method outperforms all other competitive state-of-the-art (SOTA) methods.

</p>
</details>

<details><summary><b>A category theory framework for Bayesian learning</b>
<a href="https://arxiv.org/abs/2111.14293">arxiv:2111.14293</a>
&#x1F4C8; 5 <br>
<p>Kotaro Kamiya, John Welliaveetil</p></summary>
<p>

**Abstract:** Inspired by the foundational works by Spivak and Fong and Cruttwell et al., we introduce a categorical framework to formalize Bayesian inference and learning. The two key ideas at play here are the notions of Bayesian inversions and the functor GL as constructed by Cruttwell et al.. In this context, we find that Bayesian learning is the simplest case of the learning paradigm. We then obtain categorical formulations of batch and sequential Bayes updates while also verifying that the two coincide in a specific example.

</p>
</details>

<details><summary><b>Explore the Potential Performance of Vision-and-Language Navigation Model: a Snapshot Ensemble Method</b>
<a href="https://arxiv.org/abs/2111.14267">arxiv:2111.14267</a>
&#x1F4C8; 5 <br>
<p>Wenda Qin, Teruhisa Misu, Derry Wijaya</p></summary>
<p>

**Abstract:** Vision-and-Language Navigation (VLN) is a challenging task in the field of artificial intelligence. Although massive progress has been made in this task over the past few years attributed to breakthroughs in deep vision and language models, it remains tough to build VLN models that can generalize as well as humans. In this paper, we provide a new perspective to improve VLN models. Based on our discovery that snapshots of the same VLN model behave significantly differently even when their success rates are relatively the same, we propose a snapshot-based ensemble solution that leverages predictions among multiple snapshots. Constructed on the snapshots of the existing state-of-the-art (SOTA) model $\circlearrowright$BERT and our past-action-aware modification, our proposed ensemble achieves the new SOTA performance in the R2R dataset challenge in Navigation Error (NE) and Success weighted by Path Length (SPL).

</p>
</details>

<details><summary><b>Low-complexity Rounded KLT Approximation for Image Compression</b>
<a href="https://arxiv.org/abs/2111.14239">arxiv:2111.14239</a>
&#x1F4C8; 5 <br>
<p>A. P. Radünz, F. M. Bayer, R. J. Cintra</p></summary>
<p>

**Abstract:** The Karhunen-Loève transform (KLT) is often used for data decorrelation and dimensionality reduction. Because its computation depends on the matrix of covariances of the input signal, the use of the KLT in real-time applications is severely constrained by the difficulty in developing fast algorithms to implement it. In this context, this paper proposes a new class of low-complexity transforms that are obtained through the application of the round function to the elements of the KLT matrix. The proposed transforms are evaluated considering figures of merit that measure the coding power and distance of the proposed approximations to the exact KLT and are also explored in image compression experiments. Fast algorithms are introduced for the proposed approximate transforms. It was shown that the proposed transforms perform well in image compression and require a low implementation cost.

</p>
</details>

<details><summary><b>Emergent Graphical Conventions in a Visual Communication Game</b>
<a href="https://arxiv.org/abs/2111.14210">arxiv:2111.14210</a>
&#x1F4C8; 5 <br>
<p>Shuwen Qiu, Sirui Xie, Lifeng Fan, Tao Gao, Song-Chun Zhu, Yixin Zhu</p></summary>
<p>

**Abstract:** Humans communicate with graphical sketches apart from symbolic languages. While recent studies of emergent communication primarily focus on symbolic languages, their settings overlook the graphical sketches existing in human communication; they do not account for the evolution process through which symbolic sign systems emerge in the trade-off between iconicity and symbolicity. In this work, we take the very first step to model and simulate such an evolution process via two neural agents playing a visual communication game; the sender communicates with the receiver by sketching on a canvas. We devise a novel reinforcement learning method such that agents are evolved jointly towards successful communication and abstract graphical conventions. To inspect the emerged conventions, we carefully define three key properties -- iconicity, symbolicity, and semanticity -- and design evaluation methods accordingly. Our experimental results under different controls are consistent with the observation in studies of human graphical conventions. Of note, we find that evolved sketches can preserve the continuum of semantics under proper environmental pressures. More interestingly, co-evolved agents can switch between conventionalized and iconic communication based on their familiarity with referents. We hope the present research can pave the path for studying emergent communication with the unexplored modality of sketches.

</p>
</details>

<details><summary><b>How Deep Are the Fakes? Focusing on Audio Deepfake: A Survey</b>
<a href="https://arxiv.org/abs/2111.14203">arxiv:2111.14203</a>
&#x1F4C8; 5 <br>
<p>Zahra Khanjani, Gabrielle Watson, Vandana P. Janeja</p></summary>
<p>

**Abstract:** Deepfake is content or material that is synthetically generated or manipulated using artificial intelligence (AI) methods, to be passed off as real and can include audio, video, image, and text synthesis. This survey has been conducted with a different perspective compared to existing survey papers, that mostly focus on just video and image deepfakes. This survey not only evaluates generation and detection methods in the different deepfake categories, but mainly focuses on audio deepfakes that are overlooked in most of the existing surveys. This paper critically analyzes and provides a unique source of audio deepfake research, mostly ranging from 2016 to 2020. To the best of our knowledge, this is the first survey focusing on audio deepfakes in English. This survey provides readers with a summary of 1) different deepfake categories 2) how they could be created and detected 3) the most recent trends in this domain and shortcomings in detection methods 4) audio deepfakes, how they are created and detected in more detail which is the main focus of this paper. We found that Generative Adversarial Networks(GAN), Convolutional Neural Networks (CNN), and Deep Neural Networks (DNN) are common ways of creating and detecting deepfakes. In our evaluation of over 140 methods we found that the majority of the focus is on video deepfakes and in particular in the generation of video deepfakes. We found that for text deepfakes there are more generation methods but very few robust methods for detection, including fake news detection, which has become a controversial area of research because of the potential of heavy overlaps with human generation of fake content. This paper is an abbreviated version of the full survey and reveals a clear need to research audio deepfakes and particularly detection of audio deepfakes.

</p>
</details>

<details><summary><b>Escape saddle points by a simple gradient-descent based algorithm</b>
<a href="https://arxiv.org/abs/2111.14069">arxiv:2111.14069</a>
&#x1F4C8; 5 <br>
<p>Chenyi Zhang, Tongyang Li</p></summary>
<p>

**Abstract:** Escaping saddle points is a central research topic in nonconvex optimization. In this paper, we propose a simple gradient-based algorithm such that for a smooth function $f\colon\mathbb{R}^n\to\mathbb{R}$, it outputs an $ε$-approximate second-order stationary point in $\tilde{O}(\log n/ε^{1.75})$ iterations. Compared to the previous state-of-the-art algorithms by Jin et al. with $\tilde{O}((\log n)^{4}/ε^{2})$ or $\tilde{O}((\log n)^{6}/ε^{1.75})$ iterations, our algorithm is polynomially better in terms of $\log n$ and matches their complexities in terms of $1/ε$. For the stochastic setting, our algorithm outputs an $ε$-approximate second-order stationary point in $\tilde{O}((\log n)^{2}/ε^{4})$ iterations. Technically, our main contribution is an idea of implementing a robust Hessian power method using only gradients, which can find negative curvature near saddle points and achieve the polynomial speedup in $\log n$ compared to the perturbed gradient descent methods. Finally, we also perform numerical experiments that support our results.

</p>
</details>

<details><summary><b>SimCLAD: A Simple Framework for Contrastive Learning of Acronym Disambiguation</b>
<a href="https://arxiv.org/abs/2111.14306">arxiv:2111.14306</a>
&#x1F4C8; 4 <br>
<p>Bin Li, Fei Xia, Yixuan Weng, Xiusheng Huang, Bin Sun</p></summary>
<p>

**Abstract:** Acronym disambiguation means finding the correct meaning of an ambiguous acronym from the dictionary in a given sentence, which is one of the key points for scientific document understanding (SDU@AAAI-22). Recently, many attempts have tried to solve this problem via fine-tuning the pre-trained masked language models (MLMs) in order to obtain a better acronym representation. However, the acronym meaning is varied under different contexts, whose corresponding phrase representation mapped in different directions lacks discrimination in the entire vector space. Thus, the original representations of the pre-trained MLMs are not ideal for the acronym disambiguation task. In this paper, we propose a Simple framework for Contrastive Learning of Acronym Disambiguation (SimCLAD) method to better understand the acronym meanings. Specifically, we design a continual contrastive pre-training method that enhances the pre-trained model's generalization ability by learning the phrase-level contrastive distributions between true meaning and ambiguous phrases. The results on the acronym disambiguation of the scientific domain in English show that the proposed method outperforms all other competitive state-of-the-art (SOTA) methods.

</p>
</details>

<details><summary><b>Data Augmentation For Medical MR Image Using Generative Adversarial Networks</b>
<a href="https://arxiv.org/abs/2111.14297">arxiv:2111.14297</a>
&#x1F4C8; 4 <br>
<p>Panjian Huang, Xu Liu, Yongzhen Huang</p></summary>
<p>

**Abstract:** Computer-assisted diagnosis (CAD) based on deep learning has become a crucial diagnostic technology in the medical industry, effectively improving diagnosis accuracy. However, the scarcity of brain tumor Magnetic Resonance (MR) image datasets causes the low performance of deep learning algorithms. The distribution of transformed images generated by traditional data augmentation (DA) intrinsically resembles the original ones, resulting in a limited performance in terms of generalization ability. This work improves Progressive Growing of GANs with a structural similarity loss function (PGGAN-SSIM) to solve image blurriness problems and model collapse. We also explore other GAN-based data augmentation to demonstrate the effectiveness of the proposed model. Our results show that PGGAN-SSIM successfully generates 256x256 realistic brain tumor MR images which fill the real image distribution uncovered by the original dataset. Furthermore, PGGAN-SSIM exceeds other GAN-based methods, achieving promising performance improvement in Frechet Inception Distance (FID) and Multi-scale Structural Similarity (MS-SSIM).

</p>
</details>

<details><summary><b>Learning a model of shape selectivity in V4 cells reveals shape encoding mechanisms in the brain</b>
<a href="https://arxiv.org/abs/2111.14250">arxiv:2111.14250</a>
&#x1F4C8; 4 <br>
<p>Paria Mehrani, John K. Tsotsos</p></summary>
<p>

**Abstract:** The mechanisms involved in transforming early visual signals to curvature representations in V4 are unknown. We propose a hierarchical model that reveals V1/V2 encodings that are essential components for this transformation to the reported curvature representations in V4. Then, by relaxing the often-imposed prior of a single Gaussian, V4 shape selectivity is learned in the last layer of the hierarchy from Macaque V4 responses. We found that V4 cells integrate multiple shape parts from the full spatial extent of their receptive fields with similar excitatory and inhibitory contributions. Our results uncover new details in existing data about shape selectivity in V4 neurons that with further experiments can enhance our understanding of processing in this area. Accordingly, we propose designs for a stimulus set that allow removing shape parts without disturbing the curvature signal to isolate part contributions to V4 responses.

</p>
</details>

<details><summary><b>Local Learning Matters: Rethinking Data Heterogeneity in Federated Learning</b>
<a href="https://arxiv.org/abs/2111.14213">arxiv:2111.14213</a>
&#x1F4C8; 4 <br>
<p>Matias Mendieta, Taojiannan Yang, Pu Wang, Minwoo Lee, Zhengming Ding, Chen Chen</p></summary>
<p>

**Abstract:** Federated learning (FL) is a promising strategy for performing privacy-preserving, distributed learning with a network of clients (i.e., edge devices). However, the data distribution among clients is often non-IID in nature, making efficient optimization difficult. To alleviate this issue, many FL algorithms focus on mitigating the effects of data heterogeneity across clients by introducing a variety of proximal terms, some incurring considerable compute and/or memory overheads, to restrain local updates with respect to the global model. Instead, we consider rethinking solutions to data heterogeneity in FL with a focus on local learning generality rather than proximal restriction. To this end, we first present a systematic study informed by second-order indicators to better understand algorithm effectiveness in FL. Interestingly, we find that standard regularization methods are surprisingly strong performers in mitigating data heterogeneity effects. Based on our findings, we further propose a simple and effective method, FedAlign, to overcome data heterogeneity and the pitfalls of previous methods. FedAlign achieves competitive accuracy with state-of-the-art FL methods across a variety of settings while minimizing computation and memory overhead. Code will be publicly available.

</p>
</details>

<details><summary><b>Make an Omelette with Breaking Eggs: Zero-Shot Learning for Novel Attribute Synthesis</b>
<a href="https://arxiv.org/abs/2111.14182">arxiv:2111.14182</a>
&#x1F4C8; 4 <br>
<p>Yu Hsuan Li, Tzu-Yin Chao, Ching-Chun Huang, Pin-Yu Chen, Wei-Chen Chiu</p></summary>
<p>

**Abstract:** Most of the existing algorithms for zero-shot classification problems typically rely on the attribute-based semantic relations among categories to realize the classification of novel categories without observing any of their instances. However, training the zero-shot classification models still requires attribute labeling for each class (or even instance) in the training dataset, which is also expensive. To this end, in this paper, we bring up a new problem scenario: "Are we able to derive zero-shot learning for novel attribute detectors/classifiers and use them to automatically annotate the dataset for labeling efficiency?" Basically, given only a small set of detectors that are learned to recognize some manually annotated attributes (i.e., the seen attributes), we aim to synthesize the detectors of novel attributes in a zero-shot learning manner. Our proposed method, Zero Shot Learning for Attributes (ZSLA), which is the first of its kind to the best of our knowledge, tackles this new research problem by applying the set operations to first decompose the seen attributes into their basic attributes and then recombine these basic attributes into the novel ones. Extensive experiments are conducted to verify the capacity of our synthesized detectors for accurately capturing the semantics of the novel attributes and show their superior performance in terms of detection and localization compared to other baseline approaches. Moreover, with using only 32 seen attributes on the Caltech-UCSD Birds-200-2011 dataset, our proposed method is able to synthesize other 207 novel attributes, while various generalized zero-shot classification algorithms trained upon the dataset re-annotated by our synthesized attribute detectors are able to provide comparable performance with those trained with the manual ground-truth annotations.

</p>
</details>

<details><summary><b>FashionSearchNet-v2: Learning Attribute Representations with Localization for Image Retrieval with Attribute Manipulation</b>
<a href="https://arxiv.org/abs/2111.14145">arxiv:2111.14145</a>
&#x1F4C8; 4 <br>
<p>Kenan E. Ak, Joo Hwee Lim, Ying Sun, Jo Yew Tham, Ashraf A. Kassim</p></summary>
<p>

**Abstract:** The focus of this paper is on the problem of image retrieval with attribute manipulation. Our proposed work is able to manipulate the desired attributes of the query image while maintaining its other attributes. For example, the collar attribute of the query image can be changed from round to v-neck to retrieve similar images from a large dataset. A key challenge in e-commerce is that images have multiple attributes where users would like to manipulate and it is important to estimate discriminative feature representations for each of these attributes. The proposed FashionSearchNet-v2 architecture is able to learn attribute specific representations by leveraging on its weakly-supervised localization module, which ignores the unrelated features of attributes in the feature space, thus improving the similarity learning. The network is jointly trained with the combination of attribute classification and triplet ranking loss to estimate local representations. These local representations are then merged into a single global representation based on the instructed attribute manipulation where desired images can be retrieved with a distance metric. The proposed method also provides explainability for its retrieval process to help provide additional information on the attention of the network. Experiments performed on several datasets that are rich in terms of the number of attributes show that FashionSearchNet-v2 outperforms the other state-of-the-art attribute manipulation techniques. Different than our earlier work (FashionSearchNet), we propose several improvements in the learning procedure and show that the proposed FashionSearchNet-v2 can be generalized to different domains other than fashion.

</p>
</details>

<details><summary><b>NoFADE: Analyzing Diminishing Returns on CO2 Investment</b>
<a href="https://arxiv.org/abs/2111.14059">arxiv:2111.14059</a>
&#x1F4C8; 4 <br>
<p>Andre Fu, Justin Tran, Andy Xie, Jonathan Spraggett, Elisa Ding, Chang-Won Lee, Kanav Singla, Mahdi S. Hosseini, Konstantinos N. Plataniotis</p></summary>
<p>

**Abstract:** Climate change continues to be a pressing issue that currently affects society at-large. It is important that we as a society, including the Computer Vision (CV) community take steps to limit our impact on the environment. In this paper, we (a) analyze the effect of diminishing returns on CV methods, and (b) propose a \textit{``NoFADE''}: a novel entropy-based metric to quantify model--dataset--complexity relationships. We show that some CV tasks are reaching saturation, while others are almost fully saturated. In this light, NoFADE allows the CV community to compare models and datasets on a similar basis, establishing an agnostic platform.

</p>
</details>

<details><summary><b>Identification of Subgroups With Similar Benefits in Off-Policy Policy Evaluation</b>
<a href="https://arxiv.org/abs/2111.14272">arxiv:2111.14272</a>
&#x1F4C8; 3 <br>
<p>Ramtin Keramati, Omer Gottesman, Leo Anthony Celi, Finale Doshi-Velez, Emma Brunskill</p></summary>
<p>

**Abstract:** Off-policy policy evaluation methods for sequential decision making can be used to help identify if a proposed decision policy is better than a current baseline policy. However, a new decision policy may be better than a baseline policy for some individuals but not others. This has motivated a push towards personalization and accurate per-state estimates of heterogeneous treatment effects (HTEs). Given the limited data present in many important applications, individual predictions can come at a cost to accuracy and confidence in such predictions. We develop a method to balance the need for personalization with confident predictions by identifying subgroups where it is possible to confidently estimate the expected difference in a new decision policy relative to a baseline. We propose a novel loss function that accounts for uncertainty during the subgroup partitioning phase. In experiments, we show that our method can be used to form accurate predictions of HTEs where other methods struggle.

</p>
</details>

<details><summary><b>3D High-Quality Magnetic Resonance Image Restoration in Clinics Using Deep Learning</b>
<a href="https://arxiv.org/abs/2111.14259">arxiv:2111.14259</a>
&#x1F4C8; 3 <br>
<p>Hao Li, Jianan Liu</p></summary>
<p>

**Abstract:** Shortening acquisition time and reducing the motion-artifact are two of the most essential concerns in magnetic resonance imaging. As a promising solution, deep learning-based high quality MR image restoration has been investigated to generate higher resolution and motion artifact-free MR images from lower resolution images acquired with shortened acquisition time, without costing additional acquisition time or modifying the pulse sequences. However, numerous problems still exist to prevent deep learning approaches from becoming practical in the clinic environment. Specifically, most of the prior works focus solely on the network model but ignore the impact of various downsampling strategies on the acquisition time. Besides, the long inference time and high GPU consumption are also the bottle neck to deploy most of the prior works in clinics. Furthermore, prior studies employ random movement in retrospective motion artifact generation, resulting in uncontrollable severity of motion artifact. More importantly, doctors are unsure whether the generated MR images are trustworthy, making diagnosis difficult. To overcome all these problems, we employed a unified 2D deep learning neural network for both 3D MRI super resolution and motion artifact reduction, demonstrating such a framework can achieve better performance in 3D MRI restoration task compared to other states of the art methods and remains the GPU consumption and inference time significantly low, thus easier to deploy. We also analyzed several downsampling strategies based on the acceleration factor, including multiple combinations of in-plane and through-plane downsampling, and developed a controllable and quantifiable motion artifact generation method. At last, the pixel-wise uncertainty was calculated and used to estimate the accuracy of generated image, providing additional information for reliable diagnosis.

</p>
</details>

<details><summary><b>Topic Driven Adaptive Network for Cross-Domain Sentiment Classification</b>
<a href="https://arxiv.org/abs/2111.14094">arxiv:2111.14094</a>
&#x1F4C8; 3 <br>
<p>Yicheng Zhu, Yiqiao Qiu, Yanghui Rao</p></summary>
<p>

**Abstract:** Cross-domain sentiment classification has been a hot spot these years, which aims to learn a reliable classifier using labeled data from the source domain and evaluate it on the target domain. In this vein, most approaches utilized domain adaptation that maps data from different domains into a common feature space. To further improve the model performance, several methods targeted to mine domain-specific information were proposed. However, most of them only utilized a limited part of domain-specific information. In this study, we first develop a method of extracting domain-specific words based on the topic information. Then, we propose a Topic Driven Adaptive Network (TDAN) for cross-domain sentiment classification. The network consists of two sub-networks: semantics attention network and domain-specific word attention network, the structures of which are based on transformers. These sub-networks take different forms of input and their outputs are fused as the feature vector. Experiments validate the effectiveness of our TDAN on sentiment classification across domains.

</p>
</details>

<details><summary><b>Siamese Neural Encoders for Long-Term Indoor Localization with Mobile Devices</b>
<a href="https://arxiv.org/abs/2112.00654">arxiv:2112.00654</a>
&#x1F4C8; 2 <br>
<p>Saideep Tiku, Sudeep Pasricha</p></summary>
<p>

**Abstract:** Fingerprinting-based indoor localization is an emerging application domain for enhanced positioning and tracking of people and assets within indoor locales. The superior pairing of ubiquitously available WiFi signals with computationally capable smartphones is set to revolutionize the area of indoor localization. However, the observed signal characteristics from independently maintained WiFi access points vary greatly over time. Moreover, some of the WiFi access points visible at the initial deployment phase may be replaced or removed over time. These factors are often ignored in indoor localization frameworks and cause gradual and catastrophic degradation of localization accuracy post-deployment (over weeks and months). To overcome these challenges, we propose a Siamese neural encoder-based framework that offers up to 40% reduction in degradation of localization accuracy over time compared to the state-of-the-art in the area, without requiring any retraining.

</p>
</details>

<details><summary><b>Improving random walk rankings with feature selection and imputation</b>
<a href="https://arxiv.org/abs/2111.15635">arxiv:2111.15635</a>
&#x1F4C8; 2 <br>
<p>Ngoc Mai Tran, Yangxinyu Xie</p></summary>
<p>

**Abstract:** The Science4cast Competition consists of predicting new links in a semantic network, with each node representing a concept and each edge representing a link proposed by a paper relating two concepts. This network contains information from 1994-2017, with a discretization of days (which represents the publication date of the underlying papers). Team Hash Brown's final submission, \emph{ee5a}, achieved a score of 0.92738 on the test set. Our team's score ranks \emph{second place}, 0.01 below the winner's score. This paper details our model, its intuition, and the performance of its variations in the test set.

</p>
</details>

<details><summary><b>How Can Creativity Occur in Multi-Agent Systems?</b>
<a href="https://arxiv.org/abs/2111.14310">arxiv:2111.14310</a>
&#x1F4C8; 2 <br>
<p>Ted Fujimoto</p></summary>
<p>

**Abstract:** Complex systems show how surprising and beautiful phenomena can emerge from structures or agents following simple rules. With the recent success of deep reinforcement learning (RL), a natural path forward would be to use the capabilities of multiple deep RL agents to produce emergent behavior of greater benefit and sophistication. In general, this has proved to be an unreliable strategy without significant computation due to the difficulties inherent in multi-agent RL training. In this paper, we propose some criteria for creativity in multi-agent RL. We hope this proposal will give artists applying multi-agent RL a starting point, and provide a catalyst for further investigation guided by philosophical discussion.

</p>
</details>

<details><summary><b>False Data Injection Threats in Active Distribution Systems: A Comprehensive Survey</b>
<a href="https://arxiv.org/abs/2111.14251">arxiv:2111.14251</a>
&#x1F4C8; 2 <br>
<p>Muhammad Akbar Husnoo, Adnan Anwar, Nasser Hosseinzadeh, Shama Naz Islam, Abdun Naser Mahmood, Robin Doss</p></summary>
<p>

**Abstract:** With the proliferation of smart devices and revolutions in communications, electrical distribution systems are gradually shifting from passive, manually-operated and inflexible ones, to a massively interconnected cyber-physical smart grid to address the energy challenges of the future. However, the integration of several cutting-edge technologies has introduced several security and privacy vulnerabilities due to the large-scale complexity and resource limitations of deployments. Recent research trends have shown that False Data Injection (FDI) attacks are becoming one of the most malicious cyber threats within the entire smart grid paradigm. Therefore, this paper presents a comprehensive survey of the recent advances in FDI attacks within active distribution systems and proposes a taxonomy to classify the FDI threats with respect to smart grid targets. The related studies are contrasted and summarized in terms of the attack methodologies and implications on the electrical power distribution networks. Finally, we identify some research gaps and recommend a number of future research directions to guide and motivate prospective researchers.

</p>
</details>

<details><summary><b>Fed2: Feature-Aligned Federated Learning</b>
<a href="https://arxiv.org/abs/2111.14248">arxiv:2111.14248</a>
&#x1F4C8; 2 <br>
<p>Fuxun Yu, Weishan Zhang, Zhuwei Qin, Zirui Xu, Di Wang, Chenchen Liu, Zhi Tian, Xiang Chen</p></summary>
<p>

**Abstract:** Federated learning learns from scattered data by fusing collaborative models from local nodes. However, the conventional coordinate-based model averaging by FedAvg ignored the random information encoded per parameter and may suffer from structural feature misalignment. In this work, we propose Fed2, a feature-aligned federated learning framework to resolve this issue by establishing a firm structure-feature alignment across the collaborative models. Fed2 is composed of two major designs: First, we design a feature-oriented model structure adaptation method to ensure explicit feature allocation in different neural network structures. Applying the structure adaptation to collaborative models, matchable structures with similar feature information can be initialized at the very early training stage. During the federated learning process, we then propose a feature paired averaging scheme to guarantee aligned feature distribution and maintain no feature fusion conflicts under either IID or non-IID scenarios. Eventually, Fed2 could effectively enhance the federated learning convergence performance under extensive homo- and heterogeneous settings, providing excellent convergence speed, accuracy, and computation/communication efficiency.

</p>
</details>

<details><summary><b>Schema matching using Gaussian mixture models with Wasserstein distance</b>
<a href="https://arxiv.org/abs/2111.14244">arxiv:2111.14244</a>
&#x1F4C8; 2 <br>
<p>Mateusz Przyborowski, Mateusz Pabiś, Andrzej Janusz, Dominik Ślęzak</p></summary>
<p>

**Abstract:** Gaussian mixture models find their place as a powerful tool, mostly in the clustering problem, but with proper preparation also in feature extraction, pattern recognition, image segmentation and in general machine learning. When faced with the problem of schema matching, different mixture models computed on different pieces of data can maintain crucial information about the structure of the dataset. In order to measure or compare results from mixture models, the Wasserstein distance can be very useful, however it is not easy to calculate for mixture distributions. In this paper we derive one of possible approximations for the Wasserstein distance between Gaussian mixture models and reduce it to linear problem. Furthermore, application examples concerning real world data are shown.

</p>
</details>

<details><summary><b>Approximate Inference via Clustering</b>
<a href="https://arxiv.org/abs/2111.14219">arxiv:2111.14219</a>
&#x1F4C8; 2 <br>
<p>Qianqian Song</p></summary>
<p>

**Abstract:** In recent years, large-scale Bayesian learning draws a great deal of attention. However, in big-data era, the amount of data we face is growing much faster than our ability to deal with it. Fortunately, it is observed that large-scale datasets usually own rich internal structure and is somewhat redundant. In this paper, we attempt to simplify the Bayesian posterior via exploiting this structure. Specifically, we restrict our interest to the so-called well-clustered datasets and construct an \emph{approximate posterior} according to the clustering information. Fortunately, the clustering structure can be efficiently obtained via a particular clustering algorithm. When constructing the approximate posterior, the data points in the same cluster are all replaced by the centroid of the cluster. As a result, the posterior can be significantly simplified. Theoretically, we show that under certain conditions the approximate posterior we construct is close (measured by KL divergence) to the exact posterior. Furthermore, thorough experiments are conducted to validate the fact that the constructed posterior is a good approximation to the true posterior and much easier to sample from.

</p>
</details>

<details><summary><b>Count-Based Temperature Scheduling for Maximum Entropy Reinforcement Learning</b>
<a href="https://arxiv.org/abs/2111.14204">arxiv:2111.14204</a>
&#x1F4C8; 2 <br>
<p>Dailin Hu, Pieter Abbeel, Roy Fox</p></summary>
<p>

**Abstract:** Maximum Entropy Reinforcement Learning (MaxEnt RL) algorithms such as Soft Q-Learning (SQL) and Soft Actor-Critic trade off reward and policy entropy, which has the potential to improve training stability and robustness. Most MaxEnt RL methods, however, use a constant tradeoff coefficient (temperature), contrary to the intuition that the temperature should be high early in training to avoid overfitting to noisy value estimates and decrease later in training as we increasingly trust high value estimates to truly lead to good rewards. Moreover, our confidence in value estimates is state-dependent, increasing every time we use more evidence to update an estimate. In this paper, we present a simple state-based temperature scheduling approach, and instantiate it for SQL as Count-Based Soft Q-Learning (CBSQL). We evaluate our approach on a toy domain as well as in several Atari 2600 domains and show promising results.

</p>
</details>

<details><summary><b>Evaluating Generalization and Transfer Capacity of Multi-Agent Reinforcement Learning Across Variable Number of Agents</b>
<a href="https://arxiv.org/abs/2111.14177">arxiv:2111.14177</a>
&#x1F4C8; 2 <br>
<p>Bengisu Guresti, Nazim Kemal Ure</p></summary>
<p>

**Abstract:** Multi-agent Reinforcement Learning (MARL) problems often require cooperation among agents in order to solve a task. Centralization and decentralization are two approaches used for cooperation in MARL. While fully decentralized methods are prone to converge to suboptimal solutions due to partial observability and nonstationarity, the methods involving centralization suffer from scalability limitations and lazy agent problem. Centralized training decentralized execution paradigm brings out the best of these two approaches; however, centralized training still has an upper limit of scalability not only for acquired coordination performance but also for model size and training time. In this work, we adopt the centralized training with decentralized execution paradigm and investigate the generalization and transfer capacity of the trained models across variable number of agents. This capacity is assessed by training variable number of agents in a specific MARL problem and then performing greedy evaluations with variable number of agents for each training configuration. Thus, we analyze the evaluation performance for each combination of agent count for training versus evaluation. We perform experimental evaluations on predator prey and traffic junction environments and demonstrate that it is possible to obtain similar or higher evaluation performance by training with less agents. We conclude that optimal number of agents to perform training may differ from the target number of agents and argue that transfer across large number of agents can be a more efficient solution to scaling up than directly increasing number of agents during training.

</p>
</details>

<details><summary><b>Learning Physical Concepts in Cyber-Physical Systems: A Case Study</b>
<a href="https://arxiv.org/abs/2111.14151">arxiv:2111.14151</a>
&#x1F4C8; 2 <br>
<p>Henrik S. Steude, Alexander Windmann, Oliver Niggemann</p></summary>
<p>

**Abstract:** Machine Learning (ML) has achieved great successes in recent decades, both in research and in practice. In Cyber-Physical Systems (CPS), ML can for example be used to optimize systems, to detect anomalies or to identify root causes of system failures. However, existing algorithms suffer from two major drawbacks: (i) They are hard to interpret by human experts. (ii) Transferring results from one systems to another (similar) system is often a challenge. Concept learning, or Representation Learning (RepL), is a solution to both of these drawbacks; mimicking the human solution approach to explain-ability and transfer-ability: By learning general concepts such as physical quantities or system states, the model becomes interpretable by humans. Furthermore concepts on this abstract level can normally be applied to a wide range of different systems. Modern ML methods are already widely used in CPS, but concept learning and transfer learning are hardly used so far. In this paper, we provide an overview of the current state of research regarding methods for learning physical concepts in time series data, which is the primary form of sensor data of CPS. We also analyze the most important methods from the current state of the art using the example of a three-tank system. Based on these concrete implementations1, we discuss the advantages and disadvantages of the methods and show for which purpose and under which conditions they can be used.

</p>
</details>

<details><summary><b>Multicriteria interpretability driven Deep Learning</b>
<a href="https://arxiv.org/abs/2111.14088">arxiv:2111.14088</a>
&#x1F4C8; 2 <br>
<p>Marco Repetto</p></summary>
<p>

**Abstract:** Deep Learning methods are renowned for their performances, yet their lack of interpretability prevents them from high-stakes contexts. Recent model agnostic methods address this problem by providing post-hoc interpretability methods by reverse-engineering the model's inner workings. However, in many regulated fields, interpretability should be kept in mind from the start, which means that post-hoc methods are valid only as a sanity check after model training. Interpretability from the start, in an abstract setting, means posing a set of soft constraints on the model's behavior by injecting knowledge and annihilating possible biases. We propose a Multicriteria technique that allows to control the feature effects on the model's outcome by injecting knowledge in the objective function. We then extend the technique by including a non-linear knowledge function to account for more complex effects and local lack of knowledge. The result is a Deep Learning model that embodies interpretability from the start and aligns with the recent regulations. A practical empirical example based on credit risk, suggests that our approach creates performant yet robust models capable of overcoming biases derived from data scarcity.

</p>
</details>

<details><summary><b>Towards Robust and Automatic Hyper-Parameter Tunning</b>
<a href="https://arxiv.org/abs/2111.14056">arxiv:2111.14056</a>
&#x1F4C8; 2 <br>
<p>Mathieu Tuli, Mahdi S. Hosseini, Konstantinos N. Plataniotis</p></summary>
<p>

**Abstract:** The task of hyper-parameter optimization (HPO) is burdened with heavy computational costs due to the intractability of optimizing both a model's weights and its hyper-parameters simultaneously. In this work, we introduce a new class of HPO method and explore how the low-rank factorization of the convolutional weights of intermediate layers of a convolutional neural network can be used to define an analytical response surface for optimizing hyper-parameters, using only training data. We quantify how this surface behaves as a surrogate to model performance and can be solved using a trust-region search algorithm, which we call autoHyper. The algorithm outperforms state-of-the-art such as Bayesian Optimization and generalizes across model, optimizer, and dataset selection. Our code can be found at \url{https://github.com/MathieuTuli/autoHyper}.

</p>
</details>

<details><summary><b>Speaker Embedding-aware Neural Diarization for Flexible Number of Speakers with Textual Information</b>
<a href="https://arxiv.org/abs/2111.13694">arxiv:2111.13694</a>
&#x1F4C8; 2 <br>
<p>Zhihao Du, Shiliang Zhang, Siqi Zheng, Weilong Huang, Ming Lei</p></summary>
<p>

**Abstract:** Overlapping speech diarization is always treated as a multi-label classification problem. In this paper, we reformulate this task as a single-label prediction problem by encoding the multi-speaker labels with power set. Specifically, we propose the speaker embedding-aware neural diarization (SEND) method, which predicts the power set encoded labels according to the similarities between speech features and given speaker embeddings. Our method is further extended and integrated with downstream tasks by utilizing the textual information, which has not been well studied in previous literature. The experimental results show that our method achieves lower diarization error rate than the target-speaker voice activity detection. When textual information is involved, the diarization errors can be further reduced. For the real meeting scenario, our method can achieve 34.11% relative improvement compared with the Bayesian hidden Markov model based clustering algorithm.

</p>
</details>

<details><summary><b>Deep Molecular Representation Learning via Fusing Physical and Chemical Information</b>
<a href="https://arxiv.org/abs/2112.04624">arxiv:2112.04624</a>
&#x1F4C8; 1 <br>
<p>Shuwen Yang, Ziyao Li, Guojie Song, Lingsheng Cai</p></summary>
<p>

**Abstract:** Molecular representation learning is the first yet vital step in combining deep learning and molecular science. To push the boundaries of molecular representation learning, we present PhysChem, a novel neural architecture that learns molecular representations via fusing physical and chemical information of molecules. PhysChem is composed of a physicist network (PhysNet) and a chemist network (ChemNet). PhysNet is a neural physical engine that learns molecular conformations through simulating molecular dynamics with parameterized forces; ChemNet implements geometry-aware deep message-passing to learn chemical / biomedical properties of molecules. Two networks specialize in their own tasks and cooperate by providing expertise to each other. By fusing physical and chemical information, PhysChem achieved state-of-the-art performances on MoleculeNet, a standard molecular machine learning benchmark. The effectiveness of PhysChem was further corroborated on cutting-edge datasets of SARS-CoV-2.

</p>
</details>

<details><summary><b>Generating gapless land surface temperature with a high spatio-temporal resolution by fusing multi-source satellite-observed and model-simulated data</b>
<a href="https://arxiv.org/abs/2111.15636">arxiv:2111.15636</a>
&#x1F4C8; 1 <br>
<p>Jun Ma, Huanfeng Shen, Penghai Wu, Jingan Wu, Meiling Gao, Chunlei Meng</p></summary>
<p>

**Abstract:** Land surface temperature (LST) is a key parameter when monitoring land surface processes. However, cloud contamination and the tradeoff between the spatial and temporal resolutions greatly impede the access to high-quality thermal infrared (TIR) remote sensing data. Despite the massive efforts made to solve these dilemmas, it is still difficult to generate LST estimates with concurrent spatial completeness and a high spatio-temporal resolution. Land surface models (LSMs) can be used to simulate gapless LST with a high temporal resolution, but this usually comes with a low spatial resolution. In this paper, we present an integrated temperature fusion framework for satellite-observed and LSM-simulated LST data to map gapless LST at a 60-m spatial resolution and half-hourly temporal resolution. The global linear model (GloLM) model and the diurnal land surface temperature cycle (DTC) model are respectively performed as preprocessing steps for sensor and temporal normalization between the different LST data. The Landsat LST, Moderate Resolution Imaging Spectroradiometer (MODIS) LST, and Community Land Model Version 5.0 (CLM 5.0)-simulated LST are then fused using a filter-based spatio-temporal integrated fusion model. Evaluations were implemented in an urban-dominated region (the city of Wuhan in China) and a natural-dominated region (the Heihe River Basin in China), in terms of accuracy, spatial variability, and diurnal temporal dynamics. Results indicate that the fused LST is highly consistent with actual Landsat LST data (in situ LST measurements), in terms of a Pearson correlation coefficient of 0.94 (0.97-0.99), a mean absolute error of 0.71-0.98 K (0.82-3.17 K), and a root-mean-square error of 0.97-1.26 K (1.09-3.97 K).

</p>
</details>

<details><summary><b>Code Clone Detection based on Event Embedding and Event Dependency</b>
<a href="https://arxiv.org/abs/2111.14183">arxiv:2111.14183</a>
&#x1F4C8; 1 <br>
<p>Cheng Huang, Hui Zhou, Chunyang Ye, Bingzhuo Li</p></summary>
<p>

**Abstract:** The code clone detection method based on semantic similarity has important value in software engineering tasks (e.g., software evolution, software reuse). Traditional code clone detection technologies pay more attention to the similarity of code at the syntax level, and less attention to the semantic similarity of the code. As a result, candidate codes similar in semantics are ignored. To address this issue, we propose a code clone detection method based on semantic similarity. By treating code as a series of interdependent events that occur continuously, we design a model namely EDAM to encode code semantic information based on event embedding and event dependency. The EDAM model uses the event embedding method to model the execution characteristics of program statements and the data dependence information between all statements. In this way, we can embed the program semantic information into a vector and use the vector to detect codes similar in semantics. Experimental results show that the performance of our EDAM model is superior to state of-the-art open source models for code clone detection.

</p>
</details>

<details><summary><b>Dimensionality Reduction of Longitudinal 'Omics Data using Modern Tensor Factorization</b>
<a href="https://arxiv.org/abs/2111.14159">arxiv:2111.14159</a>
&#x1F4C8; 1 <br>
<p>Uria Mor, Yotam Cohen, Rafael Valdes-Mas, Denise Kviatcovsky, Eran Elinav, Haim Avron</p></summary>
<p>

**Abstract:** Precision medicine is a clinical approach for disease prevention, detection and treatment, which considers each individual's genetic background, environment and lifestyle. The development of this tailored avenue has been driven by the increased availability of omics methods, large cohorts of temporal samples, and their integration with clinical data. Despite the immense progression, existing computational methods for data analysis fail to provide appropriate solutions for this complex, high-dimensional and longitudinal data. In this work we have developed a new method termed TCAM, a dimensionality reduction technique for multi-way data, that overcomes major limitations when doing trajectory analysis of longitudinal omics data. Using real-world data, we show that TCAM outperforms traditional methods, as well as state-of-the-art tensor-based approaches for longitudinal microbiome data analysis. Moreover, we demonstrate the versatility of TCAM by applying it to several different omics datasets, and the applicability of it as a drop-in replacement within straightforward ML tasks.

</p>
</details>

<details><summary><b>AirSPEC: An IoT-empowered Air Quality Monitoring System integrated with a Machine Learning Framework to Detect and Predict defined Air Quality parameters</b>
<a href="https://arxiv.org/abs/2111.14125">arxiv:2111.14125</a>
&#x1F4C8; 1 <br>
<p>Nuwan Bandara, Sahan Hettiarachchi, Phabhani Athukorala</p></summary>
<p>

**Abstract:** The air that surrounds us is the cardinal source of respiration of all life-forms. Therefore, it is undoubtedly vital to highlight that balanced air quality is utmost important to the respiratory health of all living beings, environmental homeostasis, and even economical equilibrium. Nevertheless, a gradual deterioration of air quality has been observed in the last few decades, due to the continuous increment of polluted emissions from automobiles and industries into the atmosphere. Even though many people have scarcely acknowledged the depth of the problem, the persistent efforts of determined parties, including the World Health Organization, have consistently pushed the boundaries for a qualitatively better global air homeostasis, by facilitating technology-driven initiatives to timely detect and predict air quality in regional and global scales. However, the existing frameworks for air quality monitoring lack the capability of real-time responsiveness and flexible semantic distribution. In this paper, a novel Internet of Things framework is proposed which is easily implementable, semantically distributive, and empowered by a machine learning model. The proposed system is equipped with a NodeRED dashboard which processes, visualizes, and stores the primary sensor data that are acquired through a public air quality sensor network, and further, the dashboard is integrated with a machine-learning model to obtain temporal and geo-spatial air quality predictions. ESP8266 NodeMCU is incorporated as a subscriber to the NodeRED dashboard via a message queuing telemetry transport broker to communicate quantitative air quality data or alarming emails to the end-users through the developed web and mobile applications. Therefore, the proposed system could become highly beneficial in empowering public engagement in air quality through an unoppressive, data-driven, and semantic framework.

</p>
</details>

<details><summary><b>Neural Symplectic Integrator with Hamiltonian Inductive Bias for the Gravitational $N$-body Problem</b>
<a href="https://arxiv.org/abs/2111.15631">arxiv:2111.15631</a>
&#x1F4C8; 0 <br>
<p>Maxwell X. Cai, Simon Portegies Zwart, Damian Podareanu</p></summary>
<p>

**Abstract:** The gravitational $N$-body problem, which is fundamentally important in astrophysics to predict the motion of $N$ celestial bodies under the mutual gravity of each other, is usually solved numerically because there is no known general analytical solution for $N>2$. Can an $N$-body problem be solved accurately by a neural network (NN)? Can a NN observe long-term conservation of energy and orbital angular momentum? Inspired by Wistom & Holman (1991)'s symplectic map, we present a neural $N$-body integrator for splitting the Hamiltonian into a two-body part, solvable analytically, and an interaction part that we approximate with a NN. Our neural symplectic $N$-body code integrates a general three-body system for $10^{5}$ steps without diverting from the ground truth dynamics obtained from a traditional $N$-body integrator. Moreover, it exhibits good inductive bias by successfully predicting the evolution of $N$-body systems that are no part of the training set.

</p>
</details>

<details><summary><b>Multi-domain Integrative Swin Transformer network for Sparse-View Tomographic Reconstruction</b>
<a href="https://arxiv.org/abs/2111.14831">arxiv:2111.14831</a>
&#x1F4C8; 0 <br>
<p>Jiayi Pan, Weiwen Wu, Zhifan Gao, Heye Zhang</p></summary>
<p>

**Abstract:** The deep learning-based tomographic image reconstruction methods have been attracting much attention among these years. The sparse-view data reconstruction is one of typical underdetermined inverse problems, how to reconstruct high-quality CT images from dozens of projections is still a challenge in practice. To address this challenge, in this article we proposed a Multi-domain Integrative Swin Transformer network (MIST-net). First, the proposed MIST-net incorporated lavish domain features from data, residual-data, image, and residual-image using flexible network architectures. Here, the residual-data and residual-image domains network components can be considered as data consistency module to eliminate interpolation errors in both residual data and image domains, and then further retain image details. Second, to detect image features and further protect image edge, the trainable edge enhancement filter was incorporated into sub-network to improve encode-decode ability. Third, with classical Swin Transformer, we further designed a high-quality reconstruction transformer (i.e., Recformer) to improve reconstruction performance. Recformer inherited the power of Swin transformer to capture global and local features of reconstructed image. The experiments on numerical datasets with 48 views demonstrated our proposed MIST-net provided higher reconstructed image quality with small feature recovery and edge protection than other competitors including advanced unrolled networks. The trained network was transferred to real cardiac CT dataset to further validate the advantages as well as good robustness of our MIST-net in clinical applications.

</p>
</details>

<details><summary><b>SwiftSRGAN -- Rethinking Super-Resolution for Efficient and Real-time Inference</b>
<a href="https://arxiv.org/abs/2111.14320">arxiv:2111.14320</a>
&#x1F4C8; 0 <br>
<p>Koushik Sivarama Krishnan, Karthik Sivarama Krishnan</p></summary>
<p>

**Abstract:** In recent years, there have been several advancements in the task of image super-resolution using the state of the art Deep Learning-based architectures. Many super-resolution-based techniques previously published, require high-end and top-of-the-line Graphics Processing Unit (GPUs) to perform image super-resolution. With the increasing advancements in Deep Learning approaches, neural networks have become more and more compute hungry. We took a step back and, focused on creating a real-time efficient solution. We present an architecture that is faster and smaller in terms of its memory footprint. The proposed architecture uses Depth-wise Separable Convolutions to extract features and, it performs on-par with other super-resolution GANs (Generative Adversarial Networks) while maintaining real-time inference and a low memory footprint. A real-time super-resolution enables streaming high resolution media content even under poor bandwidth conditions. While maintaining an efficient trade-off between the accuracy and latency, we are able to produce a comparable performance model which is one-eighth (1/8) the size of super-resolution GANs and computes 74 times faster than super-resolution GANs.

</p>
</details>

<details><summary><b>Agility in Software 2.0 -- Notebook Interfaces and MLOps with Buttresses and Rebars</b>
<a href="https://arxiv.org/abs/2111.14142">arxiv:2111.14142</a>
&#x1F4C8; 0 <br>
<p>Markus Borg</p></summary>
<p>

**Abstract:** Artificial intelligence through machine learning is increasingly used in the digital society. Solutions based on machine learning bring both great opportunities, thus coined "Software 2.0," but also great challenges for the engineering community to tackle. Due to the experimental approach used by data scientists when developing machine learning models, agility is an essential characteristic. In this keynote address, we discuss two contemporary development phenomena that are fundamental in machine learning development, i.e., notebook interfaces and MLOps. First, we present a solution that can remedy some of the intrinsic weaknesses of working in notebooks by supporting easy transitions to integrated development environments. Second, we propose reinforced engineering of AI systems by introducing metaphorical buttresses and rebars in the MLOps context. Machine learning-based solutions are dynamic in nature, and we argue that reinforced continuous engineering is required to quality assure the trustworthy AI systems of tomorrow.

</p>
</details>


[Next Page]({{ '/2021/11/27/2021.11.27.html' | relative_url }})
