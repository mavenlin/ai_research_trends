## Summary for 2021-08-09, created on 2021-12-18


<details><summary><b>Rethinking Architecture Selection in Differentiable NAS</b>
<a href="https://arxiv.org/abs/2108.04392">arxiv:2108.04392</a>
&#x1F4C8; 23 <br>
<p>Ruochen Wang, Minhao Cheng, Xiangning Chen, Xiaocheng Tang, Cho-Jui Hsieh</p></summary>
<p>

**Abstract:** Differentiable Neural Architecture Search is one of the most popular Neural Architecture Search (NAS) methods for its search efficiency and simplicity, accomplished by jointly optimizing the model weight and architecture parameters in a weight-sharing supernet via gradient-based algorithms. At the end of the search phase, the operations with the largest architecture parameters will be selected to form the final architecture, with the implicit assumption that the values of architecture parameters reflect the operation strength. While much has been discussed about the supernet's optimization, the architecture selection process has received little attention. We provide empirical and theoretical analysis to show that the magnitude of architecture parameters does not necessarily indicate how much the operation contributes to the supernet's performance. We propose an alternative perturbation-based architecture selection that directly measures each operation's influence on the supernet. We re-evaluate several differentiable NAS methods with the proposed architecture selection and find that it is able to extract significantly improved architectures from the underlying supernets consistently. Furthermore, we find that several failure modes of DARTS can be greatly alleviated with the proposed selection method, indicating that much of the poor generalization observed in DARTS can be attributed to the failure of magnitude-based architecture selection rather than entirely the optimization of its supernet.

</p>
</details>

<details><summary><b>Noisy Channel Language Model Prompting for Few-Shot Text Classification</b>
<a href="https://arxiv.org/abs/2108.04106">arxiv:2108.04106</a>
&#x1F4C8; 22 <br>
<p>Sewon Min, Mike Lewis, Hannaneh Hajishirzi, Luke Zettlemoyer</p></summary>
<p>

**Abstract:** We introduce a noisy channel approach for language model prompting in few-shot text classification. Instead of computing the likelihood of the label given the input (referred as direct models), channel models compute the conditional probability of the input given the label, and are thereby required to explain every word in the input. We use channel models for recently proposed few-shot learning methods with no or very limited updates to the language model parameters, via either in-context demonstration or prompt tuning. Our experiments show that, for both methods, channel models significantly outperform their direct counterparts, which we attribute to their stability, i.e., lower variance and higher worst-case accuracy. We also present extensive ablations that provide recommendations for when to use channel prompt tuning instead of other competitive models (e.g., direct head tuning): channel prompt tuning is preferred when the number of training examples is small, labels in the training data are imbalanced, or generalization to unseen labels is required.

</p>
</details>

<details><summary><b>AutoVideo: An Automated Video Action Recognition System</b>
<a href="https://arxiv.org/abs/2108.04212">arxiv:2108.04212</a>
&#x1F4C8; 19 <br>
<p>Daochen Zha, Zaid Pervaiz Bhat, Yi-Wei Chen, Yicheng Wang, Sirui Ding, Jiaben Chen, Kwei-Herng Lai, Anmoll Kumar Jain, Mohammad Qazim Bhat, Na Zou, Xia Hu</p></summary>
<p>

**Abstract:** Action recognition is a crucial task for video understanding. In this paper, we present AutoVideo, a Python system for automated video action recognition. It currently supports seven action recognition algorithms and various pre-processing modules. Unlike the existing libraries that only provide model zoos, AutoVideo is built with the standard pipeline language. The basic building block is primitive, which wraps a pre-processing module or an algorithm with some hyperparameters. AutoVideo is highly modular and extendable. It can be easily combined with AutoML searchers. The pipeline language is quite general so that we can easily enrich AutoVideo with algorithms for various other video-related tasks in the future. AutoVideo is released under MIT license at https://github.com/datamllab/autovideo

</p>
</details>

<details><summary><b>Automated Olfactory Bulb Segmentation on High Resolutional T2-Weighted MRI</b>
<a href="https://arxiv.org/abs/2108.04267">arxiv:2108.04267</a>
&#x1F4C8; 11 <br>
<p>Santiago Estrada, Ran Lu, Kersten Diers, Weiyi Zeng, Philipp Ehses, Tony St√∂cker, Monique M. B Breteler, Martin Reuter</p></summary>
<p>

**Abstract:** The neuroimage analysis community has neglected the automated segmentation of the olfactory bulb (OB) despite its crucial role in olfactory function. The lack of an automatic processing method for the OB can be explained by its challenging properties. Nonetheless, recent advances in MRI acquisition techniques and resolution have allowed raters to generate more reliable manual annotations. Furthermore, the high accuracy of deep learning methods for solving semantic segmentation problems provides us with an option to reliably assess even small structures. In this work, we introduce a novel, fast, and fully automated deep learning pipeline to accurately segment OB tissue on sub-millimeter T2-weighted (T2w) whole-brain MR images. To this end, we designed a three-stage pipeline: (1) Localization of a region containing both OBs using FastSurferCNN, (2) Segmentation of OB tissue within the localized region through four independent AttFastSurferCNN - a novel deep learning architecture with a self-attention mechanism to improve modeling of contextual information, and (3) Ensemble of the predicted label maps. The OB pipeline exhibits high performance in terms of boundary delineation, OB localization, and volume estimation across a wide range of ages in 203 participants of the Rhineland Study. Moreover, it also generalizes to scans of an independent dataset never encountered during training, the Human Connectome Project (HCP), with different acquisition parameters and demographics, evaluated in 30 cases at the native 0.7mm HCP resolution, and the default 0.8mm pipeline resolution. We extensively validated our pipeline not only with respect to segmentation accuracy but also to known OB volume effects, where it can sensitively replicate age effects.

</p>
</details>

<details><summary><b>3D Human Reconstruction in the Wild with Collaborative Aerial Cameras</b>
<a href="https://arxiv.org/abs/2108.03936">arxiv:2108.03936</a>
&#x1F4C8; 10 <br>
<p>Cherie Ho, Andrew Jong, Harry Freeman, Rohan Rao, Rogerio Bonatti, Sebastian Scherer</p></summary>
<p>

**Abstract:** Aerial vehicles are revolutionizing applications that require capturing the 3D structure of dynamic targets in the wild, such as sports, medicine, and entertainment. The core challenges in developing a motion-capture system that operates in outdoors environments are: (1) 3D inference requires multiple simultaneous viewpoints of the target, (2) occlusion caused by obstacles is frequent when tracking moving targets, and (3) the camera and vehicle state estimation is noisy. We present a real-time aerial system for multi-camera control that can reconstruct human motions in natural environments without the use of special-purpose markers. We develop a multi-robot coordination scheme that maintains the optimal flight formation for target reconstruction quality amongst obstacles. We provide studies evaluating system performance in simulation, and validate real-world performance using two drones while a target performs activities such as jogging and playing soccer. Supplementary video: https://youtu.be/jxt91vx0cns

</p>
</details>

<details><summary><b>AdaRNN: Adaptive Learning and Forecasting of Time Series</b>
<a href="https://arxiv.org/abs/2108.04443">arxiv:2108.04443</a>
&#x1F4C8; 9 <br>
<p>Yuntao Du, Jindong Wang, Wenjie Feng, Sinno Pan, Tao Qin, Renjun Xu, Chongjun Wang</p></summary>
<p>

**Abstract:** Time series has wide applications in the real world and is known to be difficult to forecast. Since its statistical properties change over time, its distribution also changes temporally, which will cause severe distribution shift problem to existing methods. However, it remains unexplored to model the time series in the distribution perspective. In this paper, we term this as Temporal Covariate Shift (TCS). This paper proposes Adaptive RNNs (AdaRNN) to tackle the TCS problem by building an adaptive model that generalizes well on the unseen test data. AdaRNN is sequentially composed of two novel algorithms. First, we propose Temporal Distribution Characterization to better characterize the distribution information in the TS. Second, we propose Temporal Distribution Matching to reduce the distribution mismatch in TS to learn the adaptive TS model. AdaRNN is a general framework with flexible distribution distances integrated. Experiments on human activity recognition, air quality prediction, and financial analysis show that AdaRNN outperforms the latest methods by a classification accuracy of 2.6% and significantly reduces the RMSE by 9.0%. We also show that the temporal distribution matching algorithm can be extended in Transformer structure to boost its performance.

</p>
</details>

<details><summary><b>GAN Computers Generate Arts? A Survey on Visual Arts, Music, and Literary Text Generation using Generative Adversarial Network</b>
<a href="https://arxiv.org/abs/2108.03857">arxiv:2108.03857</a>
&#x1F4C8; 9 <br>
<p>Sakib Shahriar</p></summary>
<p>

**Abstract:** "Art is the lie that enables us to realize the truth." - Pablo Picasso. For centuries, humans have dedicated themselves to producing arts to convey their imagination. The advancement in technology and deep learning in particular, has caught the attention of many researchers trying to investigate whether art generation is possible by computers and algorithms. Using generative adversarial networks (GANs), applications such as synthesizing photorealistic human faces and creating captions automatically from images were realized. This survey takes a comprehensive look at the recent works using GANs for generating visual arts, music, and literary text. A performance comparison and description of the various GAN architecture are also presented. Finally, some of the key challenges in art generation using GANs are highlighted along with recommendations for future work.

</p>
</details>

<details><summary><b>ChemiRise: a data-driven retrosynthesis engine</b>
<a href="https://arxiv.org/abs/2108.04682">arxiv:2108.04682</a>
&#x1F4C8; 8 <br>
<p>Xiangyan Sun, Ke Liu, Yuquan Lin, Lingjie Wu, Haoming Xing, Minghong Gao, Ji Liu, Suocheng Tan, Zekun Ni, Qi Han, Junqiu Wu, Jie Fan</p></summary>
<p>

**Abstract:** We have developed an end-to-end, retrosynthesis system, named ChemiRise, that can propose complete retrosynthesis routes for organic compounds rapidly and reliably. The system was trained on a processed patent database of over 3 million organic reactions. Experimental reactions were atom-mapped, clustered, and extracted into reaction templates. We then trained a graph convolutional neural network-based one-step reaction proposer using template embeddings and developed a guiding algorithm on the directed acyclic graph (DAG) of chemical compounds to find the best candidate to explore. The atom-mapping algorithm and the one-step reaction proposer were benchmarked against previous studies and showed better results. The final product was demonstrated by retrosynthesis routes reviewed and rated by human experts, showing satisfying functionality and a potential productivity boost in real-life use cases.

</p>
</details>

<details><summary><b>The State of AI Ethics Report (Volume 5)</b>
<a href="https://arxiv.org/abs/2108.03929">arxiv:2108.03929</a>
&#x1F4C8; 8 <br>
<p>Abhishek Gupta, Connor Wright, Marianna Bergamaschi Ganapini, Masa Sweidan, Renjie Butalid</p></summary>
<p>

**Abstract:** This report from the Montreal AI Ethics Institute covers the most salient progress in research and reporting over the second quarter of 2021 in the field of AI ethics with a special emphasis on "Environment and AI", "Creativity and AI", and "Geopolitics and AI." The report also features an exclusive piece titled "Critical Race Quantum Computer" that applies ideas from quantum physics to explain the complexities of human characteristics and how they can and should shape our interactions with each other. The report also features special contributions on the subject of pedagogy in AI ethics, sociology and AI ethics, and organizational challenges to implementing AI ethics in practice. Given MAIEI's mission to highlight scholars from around the world working on AI ethics issues, the report also features two spotlights sharing the work of scholars operating in Singapore and Mexico helping to shape policy measures as they relate to the responsible use of technology. The report also has an extensive section covering the gamut of issues when it comes to the societal impacts of AI covering areas of bias, privacy, transparency, accountability, fairness, interpretability, disinformation, policymaking, law, regulations, and moral philosophy.

</p>
</details>

<details><summary><b>FIFA: Fast Inference Approximation for Action Segmentation</b>
<a href="https://arxiv.org/abs/2108.03894">arxiv:2108.03894</a>
&#x1F4C8; 8 <br>
<p>Yaser Souri, Yazan Abu Farha, Fabien Despinoy, Gianpiero Francesca, Juergen Gall</p></summary>
<p>

**Abstract:** We introduce FIFA, a fast approximate inference method for action segmentation and alignment. Unlike previous approaches, FIFA does not rely on expensive dynamic programming for inference. Instead, it uses an approximate differentiable energy function that can be minimized using gradient-descent. FIFA is a general approach that can replace exact inference improving its speed by more than 5 times while maintaining its performance. FIFA is an anytime inference algorithm that provides a better speed vs. accuracy trade-off compared to exact inference. We apply FIFA on top of state-of-the-art approaches for weakly supervised action segmentation and alignment as well as fully supervised action segmentation. FIFA achieves state-of-the-art results on most metrics on two action segmentation datasets.

</p>
</details>

<details><summary><b>Towards to Robust and Generalized Medical Image Segmentation Framework</b>
<a href="https://arxiv.org/abs/2108.03823">arxiv:2108.03823</a>
&#x1F4C8; 8 <br>
<p>Yurong Chen</p></summary>
<p>

**Abstract:** To mitigate the radiologist's workload, computer-aided diagnosis with the capability to review and analyze medical images is gradually deployed. Deep learning-based region of interest segmentation is among the most exciting use cases. However, this paradigm is restricted in real-world clinical applications due to poor robustness and generalization. The issue is more sinister with a lack of training data. In this paper, we address the challenge from the representation learning point of view. We investigate that the collapsed representations, as one of the main reasons which caused poor robustness and generalization, could be avoided through transfer learning. Therefore, we propose a novel two-stage framework for robust generalized segmentation. In particular, an unsupervised Tile-wise AutoEncoder (T-AE) pretraining architecture is coined to learn meaningful representation for improving the generalization and robustness of the downstream tasks. Furthermore, the learned knowledge is transferred to the segmentation benchmark. Coupled with an image reconstruction network, the representation keeps to be decoded, encouraging the model to capture more semantic features. Experiments of lung segmentation on multi chest X-ray datasets are conducted. Empirically, the related experimental results demonstrate the superior generalization capability of the proposed framework on unseen domains in terms of high performance and robustness to corruption, especially under the scenario of the limited training data.

</p>
</details>

<details><summary><b>A Streamwise GAN Vocoder for Wideband Speech Coding at Very Low Bit Rate</b>
<a href="https://arxiv.org/abs/2108.04051">arxiv:2108.04051</a>
&#x1F4C8; 7 <br>
<p>Ahmed Mustafa, Jan B√ºthe, Srikanth Korse, Kishan Gupta, Guillaume Fuchs, Nicola Pia</p></summary>
<p>

**Abstract:** Recently, GAN vocoders have seen rapid progress in speech synthesis, starting to outperform autoregressive models in perceptual quality with much higher generation speed. However, autoregressive vocoders are still the common choice for neural generation of speech signals coded at very low bit rates. In this paper, we present a GAN vocoder which is able to generate wideband speech waveforms from parameters coded at 1.6 kbit/s. The proposed model is a modified version of the StyleMelGAN vocoder that can run in frame-by-frame manner, making it suitable for streaming applications. The experimental results show that the proposed model significantly outperforms prior autoregressive vocoders like LPCNet for very low bit rate speech coding, with computational complexity of about 5 GMACs, providing a new state of the art in this domain. Moreover, this streamwise adversarial vocoder delivers quality competitive to advanced speech codecs such as EVS at 5.9 kbit/s on clean speech, which motivates further usage of feed-forward fully-convolutional models for low bit rate speech coding.

</p>
</details>

<details><summary><b>On the Power of Differentiable Learning versus PAC and SQ Learning</b>
<a href="https://arxiv.org/abs/2108.04190">arxiv:2108.04190</a>
&#x1F4C8; 6 <br>
<p>Emmanuel Abbe, Pritish Kamath, Eran Malach, Colin Sandon, Nathan Srebro</p></summary>
<p>

**Abstract:** We study the power of learning via mini-batch stochastic gradient descent (SGD) on the population loss, and batch Gradient Descent (GD) on the empirical loss, of a differentiable model or neural network, and ask what learning problems can be learnt using these paradigms. We show that SGD and GD can always simulate learning with statistical queries (SQ), but their ability to go beyond that depends on the precision $œÅ$ of the gradient calculations relative to the minibatch size $b$ (for SGD) and sample size $m$ (for GD). With fine enough precision relative to minibatch size, namely when $b œÅ$ is small enough, SGD can go beyond SQ learning and simulate any sample-based learning algorithm and thus its learning power is equivalent to that of PAC learning; this extends prior work that achieved this result for $b=1$. Similarly, with fine enough precision relative to the sample size $m$, GD can also simulate any sample-based learning algorithm based on $m$ samples. In particular, with polynomially many bits of precision (i.e. when $œÅ$ is exponentially small), SGD and GD can both simulate PAC learning regardless of the mini-batch size. On the other hand, when $b œÅ^2$ is large enough, the power of SGD is equivalent to that of SQ learning.

</p>
</details>

<details><summary><b>Distributionally Robust Segmentation of Abnormal Fetal Brain 3D MRI</b>
<a href="https://arxiv.org/abs/2108.04175">arxiv:2108.04175</a>
&#x1F4C8; 6 <br>
<p>Lucas Fidon, Michael Aertsen, Nada Mufti, Thomas Deprest, Doaa Emam, Fr√©d√©ric Guffens, Ernst Schwartz, Michael Ebner, Daniela Prayer, Gregor Kasprian, Anna L. David, Andrew Melbourne, S√©bastien Ourselin, Jan Deprest, Georg Langs, Tom Vercauteren</p></summary>
<p>

**Abstract:** The performance of deep neural networks typically increases with the number of training images. However, not all images have the same importance towards improved performance and robustness. In fetal brain MRI, abnormalities exacerbate the variability of the developing brain anatomy compared to non-pathological cases. A small number of abnormal cases, as is typically available in clinical datasets used for training, are unlikely to fairly represent the rich variability of abnormal developing brains. This leads machine learning systems trained by maximizing the average performance to be biased toward non-pathological cases. This problem was recently referred to as hidden stratification. To be suited for clinical use, automatic segmentation methods need to reliably achieve high-quality segmentation outcomes also for pathological cases. In this paper, we show that the state-of-the-art deep learning pipeline nnU-Net has difficulties to generalize to unseen abnormal cases. To mitigate this problem, we propose to train a deep neural network to minimize a percentile of the distribution of per-volume loss over the dataset. We show that this can be achieved by using Distributionally Robust Optimization (DRO). DRO automatically reweights the training samples with lower performance, encouraging nnU-Net to perform more consistently on all cases. We validated our approach using a dataset of 368 fetal brain T2w MRIs, including 124 MRIs of open spina bifida cases and 51 MRIs of cases with other severe abnormalities of brain development.

</p>
</details>

<details><summary><b>FA-GAN: Fused Attentive Generative Adversarial Networks for MRI Image Super-Resolution</b>
<a href="https://arxiv.org/abs/2108.03920">arxiv:2108.03920</a>
&#x1F4C8; 6 <br>
<p>Mingfeng Jiang, Minghao Zhi, Liying Wei, Xiaocheng Yang, Jucheng Zhang, Yongming Li, Pin Wang, Jiahao Huang, Guang Yang</p></summary>
<p>

**Abstract:** High-resolution magnetic resonance images can provide fine-grained anatomical information, but acquiring such data requires a long scanning time. In this paper, a framework called the Fused Attentive Generative Adversarial Networks(FA-GAN) is proposed to generate the super-resolution MR image from low-resolution magnetic resonance images, which can reduce the scanning time effectively but with high resolution MR images. In the framework of the FA-GAN, the local fusion feature block, consisting of different three-pass networks by using different convolution kernels, is proposed to extract image features at different scales. And the global feature fusion module, including the channel attention module, the self-attention module, and the fusion operation, is designed to enhance the important features of the MR image. Moreover, the spectral normalization process is introduced to make the discriminator network stable. 40 sets of 3D magnetic resonance images (each set of images contains 256 slices) are used to train the network, and 10 sets of images are used to test the proposed method. The experimental results show that the PSNR and SSIM values of the super-resolution magnetic resonance image generated by the proposed FA-GAN method are higher than the state-of-the-art reconstruction methods.

</p>
</details>

<details><summary><b>Safe Vessel Navigation Visually Aided by Autonomous Unmanned Aerial Vehicles in Congested Harbors and Waterways</b>
<a href="https://arxiv.org/abs/2108.03862">arxiv:2108.03862</a>
&#x1F4C8; 6 <br>
<p>Jonas le Fevre Sejersen, Rui Pimentel de Figueiredo, Erdal Kayacan</p></summary>
<p>

**Abstract:** In the maritime sector, safe vessel navigation is of great importance, particularly in congested harbors and waterways. The focus of this work is to estimate the distance between an object of interest and potential obstacles using a companion UAV. The proposed approach fuses GPS data with long-range aerial images. First, we employ semantic segmentation DNN for discriminating the vessel of interest, water, and potential solid objects using raw image data. The network is trained with both real and images generated and automatically labeled from a realistic AirSim simulation environment. Then, the distances between the extracted vessel and non-water obstacle blobs are computed using a novel GSD estimation algorithm. To the best of our knowledge, this work is the first attempt to detect and estimate distances to unknown objects from long-range visual data captured with conventional RGB cameras and auxiliary absolute positioning systems (e.g. GPS). The simulation results illustrate the accuracy and efficacy of the proposed method for visually aided navigation of vessels assisted by UAV.

</p>
</details>

<details><summary><b>An Intelligent Recommendation-cum-Reminder System</b>
<a href="https://arxiv.org/abs/2108.06206">arxiv:2108.06206</a>
&#x1F4C8; 5 <br>
<p>Rohan Saxena, Maheep Chaudhary, Chandresh Kumar Maurya, Shitala Prasad</p></summary>
<p>

**Abstract:** Intelligent recommendation and reminder systems are the need of the fast-pacing life. Current intelligent systems such as Siri, Google Assistant, Microsoft Cortona, etc., have limited capability. For example, if you want to wake up at 6 am because you have an upcoming trip, you have to set the alarm manually. Besides, these systems do not recommend or remind what else to carry, such as carrying an umbrella during a likely rain. The present work proposes a system that takes an email as input and returns a recommendation-cumreminder list. As a first step, we parse the emails, recognize the entities using named entity recognition (NER). In the second step, information retrieval over the web is done to identify nearby places, climatic conditions, etc. Imperative sentences from the reviews of all places are extracted and passed to the object extraction module. The main challenge lies in extracting the objects (items) of interest from the review. To solve it, a modified Machine Reading Comprehension-NER (MRC-NER) model is trained to tag objects of interest by formulating annotation rules as a query. The objects so found are recommended to the user one day in advance. The final reminder list of objects is pruned by our proposed model for tracking objects kept during the "packing activity." Eventually, when the user leaves for the event/trip, an alert is sent containing the reminding list items. Our approach achieves superior performance compared to several baselines by as much as 30% on recall and 10% on precision.

</p>
</details>

<details><summary><b>Semi-supervised classification of radiology images with NoTeacher: A Teacher that is not Mean</b>
<a href="https://arxiv.org/abs/2108.04423">arxiv:2108.04423</a>
&#x1F4C8; 5 <br>
<p>Balagopal Unnikrishnan, Cuong Nguyen, Shafa Balaram, Chao Li, Chuan Sheng Foo, Pavitra Krishnaswamy</p></summary>
<p>

**Abstract:** Deep learning models achieve strong performance for radiology image classification, but their practical application is bottlenecked by the need for large labeled training datasets. Semi-supervised learning (SSL) approaches leverage small labeled datasets alongside larger unlabeled datasets and offer potential for reducing labeling cost. In this work, we introduce NoTeacher, a novel consistency-based SSL framework which incorporates probabilistic graphical models. Unlike Mean Teacher which maintains a teacher network updated via a temporal ensemble, NoTeacher employs two independent networks, thereby eliminating the need for a teacher network. We demonstrate how NoTeacher can be customized to handle a range of challenges in radiology image classification. Specifically, we describe adaptations for scenarios with 2D and 3D inputs, uni and multi-label classification, and class distribution mismatch between labeled and unlabeled portions of the training data. In realistic empirical evaluations on three public benchmark datasets spanning the workhorse modalities of radiology (X-Ray, CT, MRI), we show that NoTeacher achieves over 90-95% of the fully supervised AUROC with less than 5-15% labeling budget. Further, NoTeacher outperforms established SSL methods with minimal hyperparameter tuning, and has implications as a principled and practical option for semisupervised learning in radiology applications.

</p>
</details>

<details><summary><b>Long-Horizon Manipulation of Unknown Objects via Task and Motion Planning with Estimated Affordances</b>
<a href="https://arxiv.org/abs/2108.04145">arxiv:2108.04145</a>
&#x1F4C8; 5 <br>
<p>Aidan Curtis, Xiaolin Fang, Leslie Pack Kaelbling, Tom√°s Lozano-P√©rez, Caelan Reed Garrett</p></summary>
<p>

**Abstract:** We present a strategy for designing and building very general robot manipulation systems involving the integration of a general-purpose task-and-motion planner with engineered and learned perception modules that estimate properties and affordances of unknown objects. Such systems are closed-loop policies that map from RGB images, depth images, and robot joint encoder measurements to robot joint position commands. We show that following this strategy a task-and-motion planner can be used to plan intelligent behaviors even in the absence of a priori knowledge regarding the set of manipulable objects, their geometries, and their affordances. We explore several different ways of implementing such perceptual modules for segmentation, property detection, shape estimation, and grasp generation. We show how these modules are integrated within the PDDLStream task and motion planning framework. Finally, we demonstrate that this strategy can enable a single system to perform a wide variety of real-world multi-step manipulation tasks, generalizing over a broad class of objects, object arrangements, and goals, without any prior knowledge of the environment and without re-training.

</p>
</details>

<details><summary><b>Classification and Visualization of Genotype x Phenotype Interactions in Biomass Sorghum</b>
<a href="https://arxiv.org/abs/2108.04090">arxiv:2108.04090</a>
&#x1F4C8; 5 <br>
<p>Abby Stylianou, Robert Pless, Nadia Shakoor, Todd Mockler</p></summary>
<p>

**Abstract:** We introduce a simple approach to understanding the relationship between single nucleotide polymorphisms (SNPs), or groups of related SNPs, and the phenotypes they control. The pipeline involves training deep convolutional neural networks (CNNs) to differentiate between images of plants with reference and alternate versions of various SNPs, and then using visualization approaches to highlight what the classification networks key on. We demonstrate the capacity of deep CNNs at performing this classification task, and show the utility of these visualizations on RGB imagery of biomass sorghum captured by the TERRA-REF gantry. We focus on several different genetic markers with known phenotypic expression, and discuss the possibilities of using this approach to uncover genotype x phenotype relationships.

</p>
</details>

<details><summary><b>On Procedural Adversarial Noise Attack And Defense</b>
<a href="https://arxiv.org/abs/2108.04409">arxiv:2108.04409</a>
&#x1F4C8; 4 <br>
<p>Jun Yan, Xiaoyang Deng, Huilin Yin, Wancheng Ge</p></summary>
<p>

**Abstract:** Deep Neural Networks (DNNs) are vulnerable to adversarial examples which would inveigle neural networks to make prediction errors with small perturbations on the input images. Researchers have been devoted to promoting the research on the universal adversarial perturbations (UAPs) which are gradient-free and have little prior knowledge on data distributions. Procedural adversarial noise attack is a data-free universal perturbation generation method. In this paper, we propose two universal adversarial perturbation (UAP) generation methods based on procedural noise functions: Simplex noise and Worley noise. In our framework, the shading which disturbs visual classification is generated with rendering technology. Without changing the semantic representations, the adversarial examples generated via our methods show superior performance on the attack.

</p>
</details>

<details><summary><b>Stroke Correspondence by Labeling Closed Areas</b>
<a href="https://arxiv.org/abs/2108.04393">arxiv:2108.04393</a>
&#x1F4C8; 4 <br>
<p>Ryoma Miyauchi, Tsukasa Fukusato, Haoran Xie, Kazunori Miyata</p></summary>
<p>

**Abstract:** Constructing stroke correspondences between keyframes is one of the most important processes in the production pipeline of hand-drawn inbetweening frames. This process requires time-consuming manual work imposing a tremendous burden on the animators. We propose a method to estimate stroke correspondences between raster character images (keyframes) without vectorization processes. First, the proposed system separates the closed areas in each keyframe and estimates the correspondences between closed areas by using the characteristics of shape, depth, and closed area connection. Second, the proposed system estimates stroke correspondences from the estimated closed area correspondences. We demonstrate the effectiveness of our method by performing a user study and comparing the proposed system with conventional approaches.

</p>
</details>

<details><summary><b>Natural Numerical Networks for Natura 2000 habitats classification by satellite images</b>
<a href="https://arxiv.org/abs/2108.04327">arxiv:2108.04327</a>
&#x1F4C8; 4 <br>
<p>Karol Mikula, Michal Kollar, Aneta A. Ozvat, Martin Ambroz, Lucia Cahojova, Ivan Jarolimek, Jozef Sibik, Maria Sibikova</p></summary>
<p>

**Abstract:** Natural numerical networks are introduced as a new classification algorithm based on the numerical solution of nonlinear partial differential equations of forward-backward diffusion type on complete graphs. The proposed natural numerical network is applied to open important environmental and nature conservation task, the automated identification of protected habitats by using satellite images. In the natural numerical network, the forward diffusion causes the movement of points in a feature space toward each other. The opposite effect, keeping the points away from each other, is caused by backward diffusion. This yields the desired classification. The natural numerical network contains a few parameters that are optimized in the learning phase of the method. After learning parameters and optimizing the topology of the network graph, classification necessary for habitat identification is performed. A relevancy map for each habitat is introduced as a tool for validating the classification and finding new Natura 2000 habitat appearances.

</p>
</details>

<details><summary><b>Johnson-Lindenstrauss Lemma, Linear and Nonlinear Random Projections, Random Fourier Features, and Random Kitchen Sinks: Tutorial and Survey</b>
<a href="https://arxiv.org/abs/2108.04172">arxiv:2108.04172</a>
&#x1F4C8; 4 <br>
<p>Benyamin Ghojogh, Ali Ghodsi, Fakhri Karray, Mark Crowley</p></summary>
<p>

**Abstract:** This is a tutorial and survey paper on the Johnson-Lindenstrauss (JL) lemma and linear and nonlinear random projections. We start with linear random projection and then justify its correctness by JL lemma and its proof. Then, sparse random projections with $\ell_1$ norm and interpolation norm are introduced. Two main applications of random projection, which are low-rank matrix approximation and approximate nearest neighbor search by random projection onto hypercube, are explained. Random Fourier Features (RFF) and Random Kitchen Sinks (RKS) are explained as methods for nonlinear random projection. Some other methods for nonlinear random projection, including extreme learning machine, randomly weighted neural networks, and ensemble of random projections, are also introduced.

</p>
</details>

<details><summary><b>Manifold-aware Synthesis of High-resolution Diffusion from Structural Imaging</b>
<a href="https://arxiv.org/abs/2108.04135">arxiv:2108.04135</a>
&#x1F4C8; 4 <br>
<p>Benoit Anctil-Robitaille, Antoine Th√©berge, Pierre-Marc Jodoin, Maxime Descoteaux, Christian Desrosiers, Herv√© Lombaert</p></summary>
<p>

**Abstract:** The physical and clinical constraints surrounding diffusion-weighted imaging (DWI) often limit the spatial resolution of the produced images to voxels up to 8 times larger than those of T1w images. Thus, the detailed information contained in T1w imagescould help in the synthesis of diffusion images in higher resolution. However, the non-Euclidean nature of diffusion imaging hinders current deep generative models from synthesizing physically plausible images. In this work, we propose the first Riemannian network architecture for the direct generation of diffusion tensors (DT) and diffusion orientation distribution functions (dODFs) from high-resolution T1w images. Our integration of the Log-Euclidean Metric into a learning objective guarantees, unlike standard Euclidean networks, the mathematically-valid synthesis of diffusion. Furthermore, our approach improves the fractional anisotropy mean squared error (FA MSE) between the synthesized diffusion and the ground-truth by more than 23% and the cosine similarity between principal directions by almost 5% when compared to our baselines. We validate our generated diffusion by comparing the resulting tractograms to our expected real data. We observe similar fiber bundles with streamlines having less than 3% difference in length, less than 1% difference in volume, and a visually close shape. While our method is able to generate high-resolution diffusion images from structural inputs in less than 15 seconds, we acknowledge and discuss the limits of diffusion inference solely relying on T1w images. Our results nonetheless suggest a relationship between the high-level geometry of the brain and the overall white matter architecture.

</p>
</details>

<details><summary><b>Towards better data discovery and collection with flow-based programming</b>
<a href="https://arxiv.org/abs/2108.04105">arxiv:2108.04105</a>
&#x1F4C8; 4 <br>
<p>Andrei Paleyes, Christian Cabrera, Neil D. Lawrence</p></summary>
<p>

**Abstract:** Despite huge successes reported by the field of machine learning, such as voice assistants or self-driving cars, businesses still observe very high failure rate when it comes to deployment of ML in production. We argue that part of the reason is infrastructure that was not designed for data-oriented activities. This paper explores the potential of flow-based programming (FBP) for simplifying data discovery and collection in software systems. We compare FBP with the currently prevalent service-oriented paradigm to assess characteristics of each paradigm in the context of ML deployment. We develop a data processing application, formulate a subsequent ML deployment task, and measure the impact of the task implementation within both programming paradigms. Our main conclusion is that FBP shows great potential for providing data-centric infrastructural benefits for deployment of ML. Additionally, we provide an insight into the current trend that prioritizes model development over data quality management.

</p>
</details>

<details><summary><b>Uncertainty quantification for industrial design using dictionaries of reduced order models</b>
<a href="https://arxiv.org/abs/2108.04012">arxiv:2108.04012</a>
&#x1F4C8; 4 <br>
<p>Thomas Daniel, Fabien Casenave, Nissrine Akkari, David Ryckelynck, Christian Rey</p></summary>
<p>

**Abstract:** We consider the dictionary-based ROM-net (Reduced Order Model) framework [T. Daniel, F. Casenave, N. Akkari, D. Ryckelynck, Model order reduction assisted by deep neural networks (ROM-net), Advanced modeling and Simulation in Engineering Sciences 7 (16), 2020] and summarize the underlying methodologies and their recent improvements. The main contribution of this work is the application of the complete workflow to a real-life industrial model of an elastoviscoplastic high-pressure turbine blade subjected to thermal, centrifugal and pressure loadings, for the quantification of the uncertainty on dual quantities (such as the accumulated plastic strain and the stress tensor), generated by the uncertainty on the temperature loading field. The dictionary-based ROM-net computes predictions of dual quantities of interest for 1008 Monte Carlo draws of the temperature loading field in 2 hours and 48 minutes, which corresponds to a speedup greater than 600 with respect to a reference parallel solver using domain decomposition, with a relative error in the order of 2%. Another contribution of this work consists in the derivation of a meta-model to reconstruct the dual quantities of interest over the complete mesh from their values on the reduced integration points.

</p>
</details>

<details><summary><b>A Neural Approach for Detecting Morphological Analogies</b>
<a href="https://arxiv.org/abs/2108.03945">arxiv:2108.03945</a>
&#x1F4C8; 4 <br>
<p>Safa Alsaidi, Amandine Decker, Puthineath Lay, Esteban Marquer, Pierre-Alexandre Murena, Miguel Couceiro</p></summary>
<p>

**Abstract:** Analogical proportions are statements of the form "A is to B as C is to D" that are used for several reasoning and classification tasks in artificial intelligence and natural language processing (NLP). For instance, there are analogy based approaches to semantics as well as to morphology. In fact, symbolic approaches were developed to solve or to detect analogies between character strings, e.g., the axiomatic approach as well as that based on Kolmogorov complexity. In this paper, we propose a deep learning approach to detect morphological analogies, for instance, with reinflexion or conjugation. We present empirical results that show that our framework is competitive with the above-mentioned state of the art symbolic approaches. We also explore empirically its transferability capacity across languages, which highlights interesting similarities between them.

</p>
</details>

<details><summary><b>Knowledge Graph Augmented Political Perspective Detection in News Media</b>
<a href="https://arxiv.org/abs/2108.03861">arxiv:2108.03861</a>
&#x1F4C8; 4 <br>
<p>Shangbin Feng, Minnan Luo, Zilong Chen, Qingyao Li, Xiaojun Chang, Qinghua Zheng</p></summary>
<p>

**Abstract:** Identifying political perspective in news media has become an important task due to the rapid growth of political commentary and the increasingly polarized ideologies. Previous approaches only focus on leveraging the semantic information and leaves out the rich social and political context that helps individuals understand political stances. In this paper, we propose a perspective detection method that incorporates external knowledge of real-world politics. Specifically, we construct a contemporary political knowledge graph with 1,071 entities and 10,703 triples. We then build a heterogeneous information network for each news document that jointly models article semantics and external knowledge in knowledge graphs. Finally, we apply gated relational graph convolutional networks and conduct political perspective detection as graph-level classification. Extensive experiments show that our method achieves the best performance and outperforms state-of-the-art methods by 5.49%. Numerous ablation studies further bear out the necessity of external knowledge and the effectiveness of our graph-based approach.

</p>
</details>

<details><summary><b>FiLMing Multimodal Sarcasm Detection with Attention</b>
<a href="https://arxiv.org/abs/2110.00416">arxiv:2110.00416</a>
&#x1F4C8; 3 <br>
<p>Sundesh Gupta, Aditya Shah, Miten Shah, Laribok Syiemlieh, Chandresh Maurya</p></summary>
<p>

**Abstract:** Sarcasm detection identifies natural language expressions whose intended meaning is different from what is implied by its surface meaning. It finds applications in many NLP tasks such as opinion mining, sentiment analysis, etc. Today, social media has given rise to an abundant amount of multimodal data where users express their opinions through text and images. Our paper aims to leverage multimodal data to improve the performance of the existing systems for sarcasm detection. So far, various approaches have been proposed that uses text and image modality and a fusion of both. We propose a novel architecture that uses the RoBERTa model with a co-attention layer on top to incorporate context incongruity between input text and image attributes. Further, we integrate feature-wise affine transformation by conditioning the input image through FiLMed ResNet blocks with the textual features using the GRU network to capture the multimodal information. The output from both the models and the CLS token from RoBERTa is concatenated and used for the final prediction. Our results demonstrate that our proposed model outperforms the existing state-of-the-art method by 6.14% F1 score on the public Twitter multimodal sarcasm detection dataset.

</p>
</details>

<details><summary><b>Explainable AI and susceptibility to adversarial attacks: a case study in classification of breast ultrasound images</b>
<a href="https://arxiv.org/abs/2108.04345">arxiv:2108.04345</a>
&#x1F4C8; 3 <br>
<p>Hamza Rasaee, Hassan Rivaz</p></summary>
<p>

**Abstract:** Ultrasound is a non-invasive imaging modality that can be conveniently used to classify suspicious breast nodules and potentially detect the onset of breast cancer. Recently, Convolutional Neural Networks (CNN) techniques have shown promising results in classifying ultrasound images of the breast into benign or malignant. However, CNN inference acts as a black-box model, and as such, its decision-making is not interpretable. Therefore, increasing effort has been dedicated to explaining this process, most notably through GRAD-CAM and other techniques that provide visual explanations into inner workings of CNNs. In addition to interpretation, these methods provide clinically important information, such as identifying the location for biopsy or treatment. In this work, we analyze how adversarial assaults that are practically undetectable may be devised to alter these importance maps dramatically. Furthermore, we will show that this change in the importance maps can come with or without altering the classification result, rendering them even harder to detect. As such, care must be taken when using these importance maps to shed light on the inner workings of deep learning. Finally, we utilize Multi-Task Learning (MTL) and propose a new network based on ResNet-50 to improve the classification accuracies. Our sensitivity and specificity is comparable to the state of the art results.

</p>
</details>

<details><summary><b>Generating Music and Generative Art from Brain activity</b>
<a href="https://arxiv.org/abs/2108.04316">arxiv:2108.04316</a>
&#x1F4C8; 3 <br>
<p>Ricardo Andres Diaz Rincon</p></summary>
<p>

**Abstract:** Nowadays, technological advances have influenced all human activities, creating new dynamics and ways of communication. In this context, some artists have incorporated these advances in their creative process, giving rise to unique aesthetic expressions referred to in the literature as Generative Art, which is characterized by assigning part of the creative process to a system that acts with certain autonomy (Galanter, 2003).
  This research work introduces a computational system for creating generative art using a Brain-Computer Interface (BCI) which portrays the user's brain activity in a digital artwork. In this way, the user takes an active role in the creative process. In aims of showing that the proposed system materializes in an artistic piece the user's mental states by means of a visual and sound representation, several tests are carried out to ensure the reliability of the BCI device sent data.
  The generated artwork uses brain signals and concepts of geometry, color and spatial location to give complexity to the autonomous construction. As an added value, the visual and auditory production is accompanied by an olfactory and kinesthetic component which complements the art pieces providing a multimodal communication character.

</p>
</details>

<details><summary><b>Using Deep Learning for Visual Decoding and Reconstruction from Brain Activity: A Review</b>
<a href="https://arxiv.org/abs/2108.04169">arxiv:2108.04169</a>
&#x1F4C8; 3 <br>
<p>Madison Van Horn</p></summary>
<p>

**Abstract:** This literature review will discuss the use of deep learning methods for image reconstruction using fMRI data. More specifically, the quality of image reconstruction will be determined by the choice in decoding and reconstruction architectures. I will show that these structures can struggle with adaptability to various input stimuli due to complicated objects in images. Also, the significance of feature representation will be evaluated. This paper will conclude the use of deep learning within visual decoding and reconstruction is highly optimal when using variations of deep neural networks and will provide details of potential future work.

</p>
</details>

<details><summary><b>VeRLPy: Python Library for Verification of Digital Designs with Reinforcement Learning</b>
<a href="https://arxiv.org/abs/2108.03978">arxiv:2108.03978</a>
&#x1F4C8; 3 <br>
<p>Aebel Joe Shibu, Sadhana S, Shilpa N, Pratyush Kumar</p></summary>
<p>

**Abstract:** Digital hardware is verified by comparing its behavior against a reference model on a range of randomly generated input signals. The random generation of the inputs hopes to achieve sufficient coverage of the different parts of the design. However, such coverage is often difficult to achieve, amounting to large verification efforts and delays. An alternative is to use Reinforcement Learning (RL) to generate the inputs by learning to prioritize those inputs which can more efficiently explore the design under test. In this work, we present VeRLPy an open-source library to allow RL-driven verification with limited additional engineering overhead. This contributes to two broad movements within the EDA community of (a) moving to open-source toolchains and (b) reducing barriers for development with Python support. We also demonstrate the use of VeRLPy for a few designs and establish its value over randomly generated input signals.

</p>
</details>

<details><summary><b>On the Transferability of Neural Models of Morphological Analogies</b>
<a href="https://arxiv.org/abs/2108.03938">arxiv:2108.03938</a>
&#x1F4C8; 3 <br>
<p>Safa Alsaidi, Amandine Decker, Puthineath Lay, Esteban Marquer, Pierre-Alexandre Murena, Miguel Couceiro</p></summary>
<p>

**Abstract:** Analogical proportions are statements expressed in the form "A is to B as C is to D" and are used for several reasoning and classification tasks in artificial intelligence and natural language processing (NLP). In this paper, we focus on morphological tasks and we propose a deep learning approach to detect morphological analogies. We present an empirical study to see how our framework transfers across languages, and that highlights interesting similarities and differences between these languages. In view of these results, we also discuss the possibility of building a multilingual morphological model.

</p>
</details>

<details><summary><b>LatticeNet: Fast Spatio-Temporal Point Cloud Segmentation Using Permutohedral Lattices</b>
<a href="https://arxiv.org/abs/2108.03917">arxiv:2108.03917</a>
&#x1F4C8; 3 <br>
<p>Radu Alexandru Rosu, Peer Sch√ºtt, Jan Quenzel, Sven Behnke</p></summary>
<p>

**Abstract:** Deep convolutional neural networks (CNNs) have shown outstanding performance in the task of semantically segmenting images. Applying the same methods on 3D data still poses challenges due to the heavy memory requirements and the lack of structured data. Here, we propose LatticeNet, a novel approach for 3D semantic segmentation, which takes raw point clouds as input. A PointNet describes the local geometry which we embed into a sparse permutohedral lattice. The lattice allows for fast convolutions while keeping a low memory footprint. Further, we introduce DeformSlice, a novel learned data-dependent interpolation for projecting lattice features back onto the point cloud. We present results of 3D segmentation on multiple datasets where our method achieves state-of-the-art performance. We also extend and evaluate our network for instance and dynamic object segmentation.

</p>
</details>

<details><summary><b>Unified Regularity Measures for Sample-wise Learning and Generalization</b>
<a href="https://arxiv.org/abs/2108.03913">arxiv:2108.03913</a>
&#x1F4C8; 3 <br>
<p>Chi Zhang, Xiaoning Ma, Yu Liu, Le Wang, Yuanqi Su, Yuehu Liu</p></summary>
<p>

**Abstract:** Fundamental machine learning theory shows that different samples contribute unequally both in learning and testing processes. Contemporary studies on DNN imply that such sample difference is rooted on the distribution of intrinsic pattern information, namely sample regularity. Motivated by the recent discovery on network memorization and generalization, we proposed a pair of sample regularity measures for both processes with a formulation-consistent representation. Specifically, cumulative binary training/generalizing loss (CBTL/CBGL), the cumulative number of correct classiffcations of the training/testing sample within training stage, is proposed to quantize the stability in memorization-generalization process; while forgetting/mal-generalizing events, i.e., the mis-classification of previously learned or generalized sample, are utilized to represent the uncertainty of sample regularity with respect to optimization dynamics. Experiments validated the effectiveness and robustness of the proposed approaches for mini-batch SGD optimization. Further applications on training/testing sample selection show the proposed measures sharing the unified computing procedure could benefit for both tasks.

</p>
</details>

<details><summary><b>Encoding Heterogeneous Social and Political Context for Entity Stance Prediction</b>
<a href="https://arxiv.org/abs/2108.03881">arxiv:2108.03881</a>
&#x1F4C8; 3 <br>
<p>Shangbin Feng, Minnan Luo, Zilong Chen, Peisheng Yu, Xiaojun Chang, Qinghua Zheng</p></summary>
<p>

**Abstract:** Political stance detection has become an important task due to the increasingly polarized political ideologies. Most existing works focus on identifying perspectives in news articles or social media posts, while social entities, such as individuals and organizations, produce these texts and actually take stances. In this paper, we propose the novel task of entity stance prediction, which aims to predict entities' stances given their social and political context. Specifically, we retrieve facts from Wikipedia about social entities regarding contemporary U.S. politics. We then annotate social entities' stances towards political ideologies with the help of domain experts. After defining the task of entity stance prediction, we propose a graph-based solution, which constructs a heterogeneous information network from collected facts and adopts gated relational graph convolutional networks for representation learning. Our model is then trained with a combination of supervised, self-supervised and unsupervised loss functions, which are motivated by multiple social and political phenomenons. We conduct extensive experiments to compare our method with existing text and graph analysis baselines. Our model achieves highest stance detection accuracy and yields inspiring insights regarding social entity stances. We further conduct ablation study and parameter analysis to study the mechanism and effectiveness of our proposed approach.

</p>
</details>

<details><summary><b>P-WAE: Generalized Patch-Wasserstein Autoencoder for Anomaly Screening</b>
<a href="https://arxiv.org/abs/2108.03815">arxiv:2108.03815</a>
&#x1F4C8; 3 <br>
<p>Yurong Chen</p></summary>
<p>

**Abstract:** Anomaly detection plays a pivotal role in numerous real-world scenarios, such as industrial automation and manufacturing intelligence. Recently, variational inference-based anomaly analysis has attracted researchers' and developers' attention. It aims to model the defect-free distribution so that anomalies can be classified as out-of-distribution samples. Nevertheless, there are two disturbing factors that need us to prioritize: (i) the simplistic prior latent distribution inducing limited expressive capability; (ii) the strong probability distance notion results in collapsed features. In this paper, we propose a novel Patch-wise Wasserstein AutoEncoder (P-WAE) architecture to alleviate those challenges. In particular, a patch-wise variational inference model coupled with solving the jigsaw puzzle is designed, which is a simple yet effective way to increase the expressiveness of the latent manifold. This makes using the model on high-dimensional practical data possible. In addition, we leverage a weaker measure, sliced-Wasserstein distance, to achieve the equilibrium between the reconstruction fidelity and generalized representations. Comprehensive experiments, conducted on the MVTec AD dataset, demonstrate the superior performance of our proposed method.

</p>
</details>

<details><summary><b>Deep2Lead: A distributed deep learning application for small molecule lead optimization</b>
<a href="https://arxiv.org/abs/2108.05183">arxiv:2108.05183</a>
&#x1F4C8; 2 <br>
<p>Tarun Kumar Chawdhury, David J. Grant, Hyun Yong Jin</p></summary>
<p>

**Abstract:** Lead optimization is a key step in drug discovery to produce potent and selective compounds. Historically, in silico screening and structure-based small molecule designing facilitated the processes. Although the recent application of deep learning to drug discovery piloted the possibility of their in silico application lead optimization steps, the real-world application is lacking due to the tool availability. Here, we developed a single user interface application, called Deep2Lead. Our web-based application integrates VAE and DeepPurpose DTI and allows a user to quickly perform a lead optimization task with no prior programming experience.

</p>
</details>

<details><summary><b>Tensor Principal Component Analysis in High Dimensional CP Models</b>
<a href="https://arxiv.org/abs/2108.04428">arxiv:2108.04428</a>
&#x1F4C8; 2 <br>
<p>Yuefeng Han, Cun-Hui Zhang</p></summary>
<p>

**Abstract:** The CP decomposition for high dimensional non-orthogonal spiked tensors is an important problem with broad applications across many disciplines. However, previous works with theoretical guarantee typically assume restrictive incoherence conditions on the basis vectors for the CP components. In this paper, we propose new computationally efficient composite PCA and concurrent orthogonalization algorithms for tensor CP decomposition with theoretical guarantees under mild incoherence conditions. The composite PCA applies the principal component or singular value decompositions twice, first to a matrix unfolding of the tensor data to obtain singular vectors and then to the matrix folding of the singular vectors obtained in the first step. It can be used as an initialization for any iterative optimization schemes for the tensor CP decomposition. The concurrent orthogonalization algorithm iteratively estimates the basis vector in each mode of the tensor by simultaneously applying projections to the orthogonal complements of the spaces generated by others CP components in other modes. It is designed to improve the alternating least squares estimator and other forms of the high order orthogonal iteration for tensors with low or moderately high CP ranks, and it is guaranteed to converge rapidly when the error of any given initial estimator is bounded by a small constant. Our theoretical investigation provides estimation accuracy and convergence rates for the two proposed algorithms. Our implementations on synthetic data demonstrate significant practical superiority of our approach over existing methods.

</p>
</details>

<details><summary><b>Privacy-Preserving Machine Learning: Methods, Challenges and Directions</b>
<a href="https://arxiv.org/abs/2108.04417">arxiv:2108.04417</a>
&#x1F4C8; 2 <br>
<p>Runhua Xu, Nathalie Baracaldo, James Joshi</p></summary>
<p>

**Abstract:** Machine learning (ML) is increasingly being adopted in a wide variety of application domains. Usually, a well-performing ML model relies on a large volume of training data and high-powered computational resources. Such a need for and the use of huge volumes of data raise serious privacy concerns because of the potential risks of leakage of highly privacy-sensitive information; further, the evolving regulatory environments that increasingly restrict access to and use of privacy-sensitive data add significant challenges to fully benefiting from the power of ML for data-driven applications. A trained ML model may also be vulnerable to adversarial attacks such as membership, attribute, or property inference attacks and model inversion attacks. Hence, well-designed privacy-preserving ML (PPML) solutions are critically needed for many emerging applications. Increasingly, significant research efforts from both academia and industry can be seen in PPML areas that aim toward integrating privacy-preserving techniques into ML pipeline or specific algorithms, or designing various PPML architectures. In particular, existing PPML research cross-cut ML, systems and applications design, as well as security and privacy areas; hence, there is a critical need to understand state-of-the-art research, related challenges and a research roadmap for future research in PPML area. In this paper, we systematically review and summarize existing privacy-preserving approaches and propose a Phase, Guarantee, and Utility (PGU) triad based model to understand and guide the evaluation of various PPML solutions by decomposing their privacy-preserving functionalities. We discuss the unique characteristics and challenges of PPML and outline possible research directions that leverage as well as benefit multiple research communities such as ML, distributed systems, security and privacy.

</p>
</details>

<details><summary><b>The External Validity of Combinatorial Samples and Populations</b>
<a href="https://arxiv.org/abs/2108.04376">arxiv:2108.04376</a>
&#x1F4C8; 2 <br>
<p>Andre F. Ribeiro</p></summary>
<p>

**Abstract:** The widely used 'Counterfactual' definition of Causal Effects was derived for unbiasedness and accuracy - and not generalizability. We propose a simple definition for the External Validity (EV) of Interventions, Counterfactual statements and Samples. We use the definition to discuss several issues that have baffled the counterfactual approach to effect estimation: out-of-sample validity, reliance on independence assumptions or estimation, concurrent estimation of many effects and full-models, bias-variance tradeoffs, statistical power, omitted variables, and connections to supervised and explaining techniques. Methodologically, the definition also allow us to replace the parametric and generally ill-posed estimation problems that followed the counterfactual definition by combinatorial enumeration problems on non-experimental samples. We use over 20 contemporary methods and simulations to demonstrate that the approach leads to accuracy gains in standard out-of-sample prediction, intervention effect prediction and causal effect estimation tasks. The COVID19 pandemic highlighted the need for learning solutions to provide general predictions in small samples - many times with missing variables. We also demonstrate applications in this pressing problem.

</p>
</details>

<details><summary><b>Towards a Generic Multimodal Architecture for Batch and Streaming Big Data Integration</b>
<a href="https://arxiv.org/abs/2108.04343">arxiv:2108.04343</a>
&#x1F4C8; 2 <br>
<p>Siham Yousfi, Maryem Rhanoui, Dalila Chiadmi</p></summary>
<p>

**Abstract:** Big Data are rapidly produced from various heterogeneous data sources. They are of different types (text, image, video or audio) and have different levels of reliability and completeness. One of the most interesting architectures that deal with the large amount of emerging data at high velocity is called the lambda architecture. In fact, it combines two different processing layers namely batch and speed layers, each providing specific views of data while ensuring robustness, fast and scalable data processing. However, most papers dealing with the lambda architecture are focusing one single type of data generally produced by a single data source. Besides, the layers of the architecture are implemented independently, or, at best, are combined to perform basic processing without assessing either the data reliability or completeness. Therefore, inspired by the lambda architecture, we propose in this paper a generic multimodal architecture that combines both batch and streaming processing in order to build a complete, global and accurate insight in near-real-time based on the knowledge extracted from multiple heterogeneous Big Data sources. Our architecture uses batch processing to analyze the data structures and contents, build the learning models and calculate the reliability index of the involved sources, while the streaming processing uses the built-in models of the batch layer to immediately process incoming data and rapidly provide results. We validate our architecture in the context of urban traffic management systems in order to detect congestions.

</p>
</details>

<details><summary><b>ACE: A Novel Approach for the Statistical Analysis of Pairwise Connectivity</b>
<a href="https://arxiv.org/abs/2108.04289">arxiv:2108.04289</a>
&#x1F4C8; 2 <br>
<p> Krempl,  Georg,  Kottke,  Daniel, Pham Minh,  Tuan</p></summary>
<p>

**Abstract:** Analysing correlations between streams of events is an important problem. It arises for example in Neurosciences, when the connectivity of neurons should be inferred from spike trains that record neurons' individual spiking activity. While recently some approaches for inferring delayed synaptic connections have been proposed, they are limited in the types of connectivities and delays they are able to handle, or require computation-intensive procedures. This paper proposes a faster and more flexible approach for analysing such delayed correlated activity: a statistical approach for the Analysis of Connectivity in spiking Events (ACE), based on the idea of hypothesis testing. It first computes for any pair of a source and a target neuron the inter-spike delays between subsequent source- and target-spikes. Then, it derives a null model for the distribution of inter-spike delays for \emph{uncorrelated}~neurons. Finally, it compares the observed distribution of inter-spike delays to this null model and infers pairwise connectivity based on the Pearson's Chi-squared test statistic. Thus, ACE is capable to detect connections with a priori unknown, non-discrete (and potentially large) inter-spike delays, which might vary between pairs of neurons. Since ACE works incrementally, it has potential for being used in online processing. In our experiments, we visualise the advantages of ACE in varying experimental scenarios (except for one special case) and in a state-of-the-art dataset which has been generated for neuro-scientific research under most realistic conditions.

</p>
</details>

<details><summary><b>No-Reference Image Quality Assessment by Hallucinating Pristine Features</b>
<a href="https://arxiv.org/abs/2108.04165">arxiv:2108.04165</a>
&#x1F4C8; 2 <br>
<p>Baoliang Chen, Lingyu Zhu, Chenqi Kong, Hanwei Zhu, Shiqi Wang, Zhu Li</p></summary>
<p>

**Abstract:** In this paper, we propose a no-reference (NR) image quality assessment (IQA) method via feature level pseudo-reference (PR) hallucination. The proposed quality assessment framework is grounded on the prior models of natural image statistical behaviors and rooted in the view that the perceptually meaningful features could be well exploited to characterize the visual quality. Herein, the PR features from the distorted images are learned by a mutual learning scheme with the pristine reference as the supervision, and the discriminative characteristics of PR features are further ensured with the triplet constraints. Given a distorted image for quality inference, the feature level disentanglement is performed with an invertible neural layer for final quality prediction, leading to the PR and the corresponding distortion features for comparison. The effectiveness of our proposed method is demonstrated on four popular IQA databases, and superior performance on cross-database evaluation also reveals the high generalization capability of our method. The implementation of our method is publicly available on https://github.com/Baoliang93/FPR.

</p>
</details>

<details><summary><b>Reachability Analysis of Neural Feedback Loops</b>
<a href="https://arxiv.org/abs/2108.04140">arxiv:2108.04140</a>
&#x1F4C8; 2 <br>
<p>Michael Everett, Golnaz Habibi, Chuangchuang Sun, Jonathan P. How</p></summary>
<p>

**Abstract:** Neural Networks (NNs) can provide major empirical performance improvements for closed-loop systems, but they also introduce challenges in formally analyzing those systems' safety properties. In particular, this work focuses on estimating the forward reachable set of \textit{neural feedback loops} (closed-loop systems with NN controllers). Recent work provides bounds on these reachable sets, but the computationally tractable approaches yield overly conservative bounds (thus cannot be used to verify useful properties), and the methods that yield tighter bounds are too intensive for online computation. This work bridges the gap by formulating a convex optimization problem for the reachability analysis of closed-loop systems with NN controllers. While the solutions are less tight than previous (semidefinite program-based) methods, they are substantially faster to compute, and some of those computational time savings can be used to refine the bounds through new input set partitioning techniques, which is shown to dramatically reduce the tightness gap. The new framework is developed for systems with uncertainty (e.g., measurement and process noise) and nonlinearities (e.g., polynomial dynamics), and thus is shown to be applicable to real-world systems. To inform the design of an initial state set when only the target state set is known/specified, a novel algorithm for backward reachability analysis is also provided, which computes the set of states that are guaranteed to lead to the target set. The numerical experiments show that our approach (based on linear relaxations and partitioning) gives a $5\times$ reduction in conservatism in $150\times$ less computation time compared to the state-of-the-art. Furthermore, experiments on quadrotor, 270-state, and polynomial systems demonstrate the method's ability to handle uncertainty sources, high dimensionality, and nonlinear dynamics, respectively.

</p>
</details>

<details><summary><b>Segmentation-free Heart Pathology Detection Using Deep Learning</b>
<a href="https://arxiv.org/abs/2108.04139">arxiv:2108.04139</a>
&#x1F4C8; 2 <br>
<p>Erika Bondareva, Jing Han, William Bradlow, Cecilia Mascolo</p></summary>
<p>

**Abstract:** Cardiovascular (CV) diseases are the leading cause of death in the world, and auscultation is typically an essential part of a cardiovascular examination. The ability to diagnose a patient based on their heart sounds is a rather difficult skill to master. Thus, many approaches for automated heart auscultation have been explored. However, most of the previously proposed methods involve a segmentation step, the performance of which drops significantly for high pulse rates or noisy signals. In this work, we propose a novel segmentation-free heart sound classification method. Specifically, we apply discrete wavelet transform to denoise the signal, followed by feature extraction and feature reduction. Then, Support Vector Machines and Deep Neural Networks are utilised for classification. On the PASCAL heart sound dataset our approach showed superior performance compared to others, achieving 81% and 96% precision on normal and murmur classes, respectively. In addition, for the first time, the data were further explored under a user-independent setting, where the proposed method achieved 92% and 86% precision on normal and murmur, demonstrating the potential of enabling automatic murmur detection for practical use.

</p>
</details>

<details><summary><b>Identifying Wetland Areas in Historical Maps using Deep Convolutional Neural Networks</b>
<a href="https://arxiv.org/abs/2108.04107">arxiv:2108.04107</a>
&#x1F4C8; 2 <br>
<p>Niclas St√•hl, Lisa Weimann</p></summary>
<p>

**Abstract:** 1) The local environment and land usages have changed a lot during the past one hundred years. Historical documents and materials are crucial in understanding and following these changes. Historical documents are, therefore, an important piece in the understanding of the impact and consequences of land usage change. This, in turn, is important in the search of restoration projects that can be conducted to turn and reduce harmful and unsustainable effects originating from changes in the land-usage.
  2) This work extracts information on the historical location and geographical distribution of wetlands, from hand-drawn maps. This is achieved by using deep learning (DL), and more specifically a convolutional neural network (CNN). The CNN model is trained on a manually pre-labelled dataset on historical wetlands in the area of J√∂nk√∂ping county in Sweden. These are all extracted from the historical map called "Generalstabskartan".
  3) The presented CNN performs well and achieves a $F_1$-score of 0.886 when evaluated using a 10-fold cross validation over the data. The trained models are additionally used to generate a GIS layer of the presumable historical geographical distribution of wetlands for the area that is depicted in the southern collection in Generalstabskartan, which covers the southern half of Sweden. This GIS layer is released as an open resource and can be freely used.
  4) To summarise, the presented results show that CNNs can be a useful tool in the extraction and digitalisation of non-textual information in historical documents, such as historical maps. A modern GIS material that can be used to further understand the past land-usage change is produced within this research.

</p>
</details>

<details><summary><b>The Role of Global Labels in Few-Shot Classification and How to Infer Them</b>
<a href="https://arxiv.org/abs/2108.04055">arxiv:2108.04055</a>
&#x1F4C8; 2 <br>
<p>Ruohan Wang, Massimiliano Pontil, Carlo Ciliberto</p></summary>
<p>

**Abstract:** Few-shot learning is a central problem in meta-learning, where learners must quickly adapt to new tasks given limited training data. Recently, feature pre-training has become a ubiquitous component in state-of-the-art meta-learning methods and is shown to provide significant performance improvement. However, there is limited theoretical understanding of the connection between pre-training and meta-learning. Further, pre-training requires global labels shared across tasks, which may be unavailable in practice. In this paper, we show why exploiting pre-training is theoretically advantageous for meta-learning, and in particular the critical role of global labels. This motivates us to propose Meta Label Learning (MeLa), a novel meta-learning framework that automatically infers global labels to obtains robust few-shot models. Empirically, we demonstrate that MeLa is competitive with existing methods and provide extensive ablation experiments to highlight its key properties.

</p>
</details>

<details><summary><b>Deep Learning methods for automatic evaluation of delayed enhancement-MRI. The results of the EMIDEC challenge</b>
<a href="https://arxiv.org/abs/2108.04016">arxiv:2108.04016</a>
&#x1F4C8; 2 <br>
<p>Alain Lalande, Zhihao Chen, Thibaut Pommier, Thomas Decourselle, Abdul Qayyum, Michel Salomon, Dominique Ginhac, Youssef Skandarani, Arnaud Boucher, Khawla Brahim, Marleen de Bruijne, Robin Camarasa, Teresa M. Correia, Xue Feng, Kibrom B. Girum, Anja Hennemuth, Markus Huellebrand, Raabid Hussain, Matthias Ivantsits, Jun Ma, Craig Meyer, Rishabh Sharma, Jixi Shi, Nikolaos V. Tsekos, Marta Varela</p></summary>
<p>

**Abstract:** A key factor for assessing the state of the heart after myocardial infarction (MI) is to measure whether the myocardium segment is viable after reperfusion or revascularization therapy. Delayed enhancement-MRI or DE-MRI, which is performed several minutes after injection of the contrast agent, provides high contrast between viable and nonviable myocardium and is therefore a method of choice to evaluate the extent of MI. To automatically assess myocardial status, the results of the EMIDEC challenge that focused on this task are presented in this paper. The challenge's main objectives were twofold. First, to evaluate if deep learning methods can distinguish between normal and pathological cases. Second, to automatically calculate the extent of myocardial infarction. The publicly available database consists of 150 exams divided into 50 cases with normal MRI after injection of a contrast agent and 100 cases with myocardial infarction (and then with a hyperenhanced area on DE-MRI), whatever their inclusion in the cardiac emergency department. Along with MRI, clinical characteristics are also provided. The obtained results issued from several works show that the automatic classification of an exam is a reachable task (the best method providing an accuracy of 0.92), and the automatic segmentation of the myocardium is possible. However, the segmentation of the diseased area needs to be improved, mainly due to the small size of these areas and the lack of contrast with the surrounding structures.

</p>
</details>

<details><summary><b>On the Hyperparameters in Stochastic Gradient Descent with Momentum</b>
<a href="https://arxiv.org/abs/2108.03947">arxiv:2108.03947</a>
&#x1F4C8; 2 <br>
<p>Bin Shi</p></summary>
<p>

**Abstract:** Following the same routine as [SSJ20], we continue to present the theoretical analysis for stochastic gradient descent with momentum (SGD with momentum) in this paper. Differently, for SGD with momentum, we demonstrate it is the two hyperparameters together, the learning rate and the momentum coefficient, that play the significant role for the linear rate of convergence in non-convex optimization. Our analysis is based on the use of a hyperparameters-dependent stochastic differential equation (hp-dependent SDE) that serves as a continuous surrogate for SGD with momentum. Similarly, we establish the linear convergence for the continuous-time formulation of SGD with momentum and obtain an explicit expression for the optimal linear rate by analyzing the spectrum of the Kramers-Fokker-Planck operator. By comparison, we demonstrate how the optimal linear rate of convergence and the final gap for SGD only about the learning rate varies with the momentum coefficient increasing from zero to one when the momentum is introduced. Then, we propose a mathematical interpretation why the SGD with momentum converges faster and more robust about the learning rate than the standard SGD in practice. Finally, we show the Nesterov momentum under the existence of noise has no essential difference with the standard momentum.

</p>
</details>

<details><summary><b>Selective Light Field Refocusing for Camera Arrays Using Bokeh Rendering and Superresolution</b>
<a href="https://arxiv.org/abs/2108.03918">arxiv:2108.03918</a>
&#x1F4C8; 2 <br>
<p>Yingqian Wang, Jungang Yang, Yulan Guo, Chao Xiao, Wei An</p></summary>
<p>

**Abstract:** Camera arrays provide spatial and angular information within a single snapshot. With refocusing methods, focal planes can be altered after exposure. In this letter, we propose a light field refocusing method to improve the imaging quality of camera arrays. In our method, the disparity is first estimated. Then, the unfocused region (bokeh) is rendered by using a depth-based anisotropic filter. Finally, the refocused image is produced by a reconstruction-based superresolution approach where the bokeh image is used as a regularization term. Our method can selectively refocus images with focused region being superresolved and bokeh being aesthetically rendered. Our method also enables postadjustment of depth of field. We conduct experiments on both public and self-developed datasets. Our method achieves superior visual performance with acceptable computational cost as compared to other state-of-the-art methods. Code is available at https://github.com/YingqianWang/Selective-LF-Refocusing.

</p>
</details>

<details><summary><b>Probabilistic Active Learning for Active Class Selection</b>
<a href="https://arxiv.org/abs/2108.03891">arxiv:2108.03891</a>
&#x1F4C8; 2 <br>
<p>Daniel Kottke, Georg Krempl, Marianne Stecklina, Cornelius Styp von Rekowski, Tim Sabsch, Tuan Pham Minh, Matthias Deliano, Myra Spiliopoulou, Bernhard Sick</p></summary>
<p>

**Abstract:** In machine learning, active class selection (ACS) algorithms aim to actively select a class and ask the oracle to provide an instance for that class to optimize a classifier's performance while minimizing the number of requests. In this paper, we propose a new algorithm (PAL-ACS) that transforms the ACS problem into an active learning task by introducing pseudo instances. These are used to estimate the usefulness of an upcoming instance for each class using the performance gain model from probabilistic active learning. Our experimental evaluation (on synthetic and real data) shows the advantages of our algorithm compared to state-of-the-art algorithms. It effectively prefers the sampling of difficult classes and thereby improves the classification performance.

</p>
</details>

<details><summary><b>Rain Removal and Illumination Enhancement Done in One Go</b>
<a href="https://arxiv.org/abs/2108.03873">arxiv:2108.03873</a>
&#x1F4C8; 2 <br>
<p>Yecong Wan, Yuanshuo Cheng, Mingwen Shao</p></summary>
<p>

**Abstract:** Rain removal plays an important role in the restoration of degraded images. Recently, data-driven methods have achieved remarkable success. However, these approaches neglect that the appearance of rain is often accompanied by low light conditions, which will further degrade the image quality. Therefore, it is very indispensable to jointly remove the rain and enhance the light for real-world rain image restoration. In this paper, we aim to address this problem from two aspects. First, we proposed a novel entangled network, namely EMNet, which can remove the rain and enhance illumination in one go. Specifically, two encoder-decoder networks interact complementary information through entanglement structure, and parallel rain removal and illumination enhancement. Considering that the encoder-decoder structure is unreliable in preserving spatial details, we employ a detail recovery network to restore the desired fine texture. Second, we present a new synthetic dataset, namely DarkRain, to boost the development of rain image restoration algorithms in practical scenarios. DarkRain not only contains different degrees of rain, but also considers different lighting conditions, and more realistically simulates the rainfall in the real world. EMNet is extensively evaluated on the proposed benchmark and achieves state-of-the-art results. In addition, after a simple transformation, our method outshines existing methods in both rain removal and low-light image enhancement. The source code and dataset will be made publicly available later.

</p>
</details>

<details><summary><b>Adaptive Anomaly Detection for Internet of Things in Hierarchical Edge Computing: A Contextual-Bandit Approach</b>
<a href="https://arxiv.org/abs/2108.03872">arxiv:2108.03872</a>
&#x1F4C8; 2 <br>
<p>Mao V. Ngo, Tie Luo, Tony Q. S. Quek</p></summary>
<p>

**Abstract:** The advances in deep neural networks (DNN) have significantly enhanced real-time detection of anomalous data in IoT applications. However, the complexity-accuracy-delay dilemma persists: complex DNN models offer higher accuracy, but typical IoT devices can barely afford the computation load, and the remedy of offloading the load to the cloud incurs long delay. In this paper, we address this challenge by proposing an adaptive anomaly detection scheme with hierarchical edge computing (HEC). Specifically, we first construct multiple anomaly detection DNN models with increasing complexity, and associate each of them to a corresponding HEC layer. Then, we design an adaptive model selection scheme that is formulated as a contextual-bandit problem and solved by using a reinforcement learning policy network. We also incorporate a parallelism policy training method to accelerate the training process by taking advantage of distributed models. We build an HEC testbed using real IoT devices, implement and evaluate our contextual-bandit approach with both univariate and multivariate IoT datasets. In comparison with both baseline and state-of-the-art schemes, our adaptive approach strikes the best accuracy-delay tradeoff on the univariate dataset, and achieves the best accuracy and F1-score on the multivariate dataset with only negligibly longer delay than the best (but inflexible) scheme.

</p>
</details>

<details><summary><b>Bob and Alice Go to a Bar: Reasoning About Future With Probabilistic Programs</b>
<a href="https://arxiv.org/abs/2108.03834">arxiv:2108.03834</a>
&#x1F4C8; 2 <br>
<p>David Tolpin, Tomer Dobkin</p></summary>
<p>

**Abstract:** It is well known that reinforcement learning can be cast as inference in an appropriate probabilistic model. However, this commonly involves introducing a distribution over agent trajectories with probabilities proportional to exponentiated rewards. In this work, we formulate reinforcement learning as Bayesian inference without resorting to rewards, and show that rewards are derived from agent's preferences, rather than the other way around. We argue that agent preferences should be specified stochastically rather than deterministically. Reinforcement learning via inference with stochastic preferences naturally describes agent behaviors, does not require introducing rewards and exponential weighing of trajectories, and allows to reason about agents using the solid foundation of Bayesian statistics. Stochastic conditioning, a probabilistic programming paradigm for conditioning models on distributions rather than values, is the formalism behind agents with probabilistic preferences. We demonstrate realization of our approach on case studies using both a two-agent coordinate game and a single agent acting in a noisy environment, showing that despite superficial differences, both cases can be modeled and reasoned about based on the same principles.

</p>
</details>

<details><summary><b>Time-Frequency Localization Using Deep Convolutional Maxout Neural Network in Persian Speech Recognition</b>
<a href="https://arxiv.org/abs/2108.03818">arxiv:2108.03818</a>
&#x1F4C8; 2 <br>
<p>Arash Dehghani, Seyyed Ali Seyyedsalehi</p></summary>
<p>

**Abstract:** In this paper, a CNN-based structure for the time-frequency localization of information is proposed for Persian speech recognition. Research has shown that the receptive fields' spectrotemporal plasticity of some neurons in mammals' primary auditory cortex and midbrain makes localization facilities improve recognition performance. Over the past few years, much work has been done to localize time-frequency information in ASR systems, using the spatial or temporal immutability properties of methods such as HMMs, TDNNs, CNNs, and LSTM-RNNs. However, most of these models have large parameter volumes and are challenging to train. For this purpose, we have presented a structure called Time-Frequency Convolutional Maxout Neural Network (TFCMNN) in which parallel time-domain and frequency-domain 1D-CMNNs are applied simultaneously and independently to the spectrogram, and then their outputs are concatenated and applied jointly to a fully connected Maxout network for classification. To improve the performance of this structure, we have used newly developed methods and models such as Dropout, maxout, and weight normalization. Two sets of experiments were designed and implemented on the FARSDAT dataset to evaluate the performance of this model compared to conventional 1D-CMNN models. According to the experimental results, the average recognition score of TFCMNN models is about 1.6% higher than the average of conventional 1D-CMNN models. In addition, the average training time of the TFCMNN models is about 17 hours lower than the average training time of traditional models. Therefore, as proven in other sources, time-frequency localization in ASR systems increases system accuracy and speeds up the training process.

</p>
</details>

<details><summary><b>Anomaly Detection Based on Generalized Gaussian Distribution approach for Ultra-Wideband (UWB) Indoor Positioning System</b>
<a href="https://arxiv.org/abs/2108.10210">arxiv:2108.10210</a>
&#x1F4C8; 1 <br>
<p>Fuhu Che, Qasim Zeeshan Ahmed, Faheem A. Khan, Pavlos I. Lazaridis</p></summary>
<p>

**Abstract:** With the rapid development of the Internet of Things (IoT), Indoor Positioning System (IPS) has attracted significant interest in academic research. Ultra-Wideband (UWB) is an emerging technology that can be employed for IPS as it offers centimetre-level accuracy. However, the UWB system still faces several technical challenges in practice, one of which is Non-Line-of-Sight (NLoS) signal propagation. Several machine learning approaches have been applied for the NLoS component identification. However, when the data contains a very small amount of NLoS components it becomes very difficult for existing algorithms to classify them. This paper focuses on employing an anomaly detection approach based on Gaussian Distribution (GD) and Generalized Gaussian Distribution (GGD) algorithms to detect and identify the NLoS components. The simulation results indicate that the proposed approach can provide a robust NLoS component identification which improves the NLoS signal classification accuracy which results in significant improvement in the UWB positioning system.

</p>
</details>

<details><summary><b>Enhancing Knowledge Tracing via Adversarial Training</b>
<a href="https://arxiv.org/abs/2108.04430">arxiv:2108.04430</a>
&#x1F4C8; 1 <br>
<p>Xiaopeng Guo, Zhijie Huang, Jie Gao, Mingyu Shang, Maojing Shu, Jun Sun</p></summary>
<p>

**Abstract:** We study the problem of knowledge tracing (KT) where the goal is to trace the students' knowledge mastery over time so as to make predictions on their future performance. Owing to the good representation capacity of deep neural networks (DNNs), recent advances on KT have increasingly concentrated on exploring DNNs to improve the performance of KT. However, we empirically reveal that the DNNs based KT models may run the risk of overfitting, especially on small datasets, leading to limited generalization. In this paper, by leveraging the current advances in adversarial training (AT), we propose an efficient AT based KT method (ATKT) to enhance KT model's generalization and thus push the limit of KT. Specifically, we first construct adversarial perturbations and add them on the original interaction embeddings as adversarial examples. The original and adversarial examples are further used to jointly train the KT model, forcing it is not only to be robust to the adversarial examples, but also to enhance the generalization over the original ones. To better implement AT, we then present an efficient attentive-LSTM model as KT backbone, where the key is a proposed knowledge hidden state attention module that adaptively aggregates information from previous knowledge hidden states while simultaneously highlighting the importance of current knowledge hidden state to make a more accurate prediction. Extensive experiments on four public benchmark datasets demonstrate that our ATKT achieves new state-of-the-art performance. Code is available at: \color{blue} {\url{https://github.com/xiaopengguo/ATKT}}.

</p>
</details>

<details><summary><b>Diversity-aware Web APIs Recommendation with Compatibility Guarantee</b>
<a href="https://arxiv.org/abs/2108.04389">arxiv:2108.04389</a>
&#x1F4C8; 1 <br>
<p>Wenwen Gonga, Yulan Zhang, Xuyun Zhang, Yucong Duan, Yawei Wang, Yifei Chena, Lianyong Qi</p></summary>
<p>

**Abstract:** With the ever-increasing prevalence of web APIs (Application Programming Interfaces) in enabling smart software developments, finding and composing a list of existing web APIs that can corporately fulfil the software developers' functional needs have become a promising way to develop a successful mobile app, economically and conveniently. However, the big volume and diversity of candidate web APIs put additional burden on the app developers' web APIs selection decision-makings, since it is often a challenging task to simultaneously guarantee the diversity and compatibility of the finally selected a set of web APIs. Considering this challenge, a Diversity-aware and Compatibility-driven web APIs Recommendation approach, namely DivCAR, is put forward in this paper. First, to achieve diversity, DivCAR employs random walk sampling technique on a pre-built correlation graph to generate diverse correlation subgraphs. Afterwards, with the diverse correlation subgraphs, we model the compatible web APIs recommendation problem to be a minimum group Steiner tree search problem. Through solving the minimum group Steiner tree search problem, manifold sets of compatible and diverse web APIs ranked are returned to the app developers. At last, we design and enact a set of experiments on a real-world dataset crawled from www.programmableWeb.com. Experimental results validate the effectiveness and efficiency of our proposed DivCAR approach in balancing the web APIs recommendation diversity and compatibility.

</p>
</details>

<details><summary><b>Classification of Influenza Hemagglutinin Protein Sequences using Convolutional Neural Networks</b>
<a href="https://arxiv.org/abs/2108.04240">arxiv:2108.04240</a>
&#x1F4C8; 1 <br>
<p>Charalambos Chrysostomou, Floris Alexandrou, Mihalis A. Nicolaou, Huseyin Seker</p></summary>
<p>

**Abstract:** The Influenza virus can be considered as one of the most severe viruses that can infect multiple species with often fatal consequences to the hosts. The Hemagglutinin (HA) gene of the virus can be a target for antiviral drug development realised through accurate identification of its sub-types and possible the targeted hosts. This paper focuses on accurately predicting if an Influenza type A virus can infect specific hosts, and more specifically, Human, Avian and Swine hosts, using only the protein sequence of the HA gene. In more detail, we propose encoding the protein sequences into numerical signals using the Hydrophobicity Index and subsequently utilising a Convolutional Neural Network-based predictive model. The Influenza HA protein sequences used in the proposed work are obtained from the Influenza Research Database (IRD). Specifically, complete and unique HA protein sequences were used for avian, human and swine hosts. The data obtained for this work was 17999 human-host proteins, 17667 avian-host proteins and 9278 swine-host proteins. Given this set of collected proteins, the proposed method yields as much as 10% higher accuracy for an individual class (namely, Avian) and 5% higher overall accuracy than in an earlier study. It is also observed that the accuracy for each class in this work is more balanced than what was presented in this earlier study. As the results show, the proposed model can distinguish HA protein sequences with high accuracy whenever the virus under investigation can infect Human, Avian or Swine hosts.

</p>
</details>

<details><summary><b>Scaling New Peaks: A Viewership-centric Approach to Automated Content Curation</b>
<a href="https://arxiv.org/abs/2108.04187">arxiv:2108.04187</a>
&#x1F4C8; 1 <br>
<p>Subhabrata Majumdar, Deirdre Paul, Eric Zavesky</p></summary>
<p>

**Abstract:** Summarizing video content is important for video streaming services to engage the user in a limited time span. To this end, current methods involve manual curation or using passive interest cues to annotate potential high-interest segments to form the basis of summarized videos, and are costly and unreliable. We propose a viewership-driven, automated method that accommodates a range of segment identification goals. Using satellite television viewership data as a source of ground truth for viewer interest, we apply statistical anomaly detection on a timeline of viewership metrics to identify 'seed' segments of high viewer interest. These segments are post-processed using empirical rules and several sources of content metadata, e.g. shot boundaries, adding in personalization aspects to produce the final highlights video.
  To demonstrate the flexibility of our approach, we present two case studies, on the United States Democratic Presidential Debate on 19th December 2019, and Wimbledon Women's Final 2019. We perform qualitative comparisons with their publicly available highlights, as well as early vs. late viewership comparisons for insights into possible media and social influence on viewing behavior.

</p>
</details>

<details><summary><b>DGEM: A New Dual-modal Graph Embedding Method in Recommendation System</b>
<a href="https://arxiv.org/abs/2108.04031">arxiv:2108.04031</a>
&#x1F4C8; 1 <br>
<p>Huimin Zhou, Qing Li, Yong Jiang, Rongwei Yang, Zhuyun Qi</p></summary>
<p>

**Abstract:** In the current deep learning based recommendation system, the embedding method is generally employed to complete the conversion from the high-dimensional sparse feature vector to the low-dimensional dense feature vector. However, as the dimension of the input vector of the embedding layer is too large, the addition of the embedding layer significantly slows down the convergence speed of the entire neural network, which is not acceptable in real-world scenarios. In addition, as the interaction between users and items increases and the relationship between items becomes more complicated, the embedding method proposed for sequence data is no longer suitable for graphic data in the current real environment. Therefore, in this paper, we propose the Dual-modal Graph Embedding Method (DGEM) to solve these problems. DGEM includes two modes, static and dynamic. We first construct the item graph to extract the graph structure and use random walk of unequal probability to capture the high-order proximity between the items. Then we generate the graph embedding vector through the Skip-Gram model, and finally feed the downstream deep neural network for the recommendation task. The experimental results show that DGEM can mine the high-order proximity between items and enhance the expression ability of the recommendation model. Meanwhile it also improves the recommendation performance by utilizing the time dependent relationship between items.

</p>
</details>

<details><summary><b>A Credibility-aware Swarm-Federated Deep Learning Framework in Internet of Vehicles</b>
<a href="https://arxiv.org/abs/2108.03981">arxiv:2108.03981</a>
&#x1F4C8; 1 <br>
<p>Zhe Wang, Xinhang Li, Tianhao Wu, Chen Xu, Lin Zhang</p></summary>
<p>

**Abstract:** Federated Deep Learning (FDL) is helping to realize distributed machine learning in the Internet of Vehicles (IoV). However, FDL's global model needs multiple clients to upload learning model parameters, thus still existing unavoidable communication overhead and data privacy risks. The recently proposed Swarm Learning (SL) provides a decentralized machine-learning approach uniting edge computing and blockchain-based coordination without the need for a central coordinator. This paper proposes a Swarm-Federated Deep Learning framework in the IoV system (IoV-SFDL) that integrates SL into the FDL framework. The IoV-SFDL organizes vehicles to generate local SL models with adjacent vehicles based on the blockchain empowered SL, then aggregates the global FDL model among different SL groups with a proposed credibility weights prediction algorithm. Extensive experimental results demonstrate that compared with the baseline frameworks, the proposed IoV-SFDL framework achieves a 16.72% reduction in edge-to-global communication overhead while improving about 5.02% in model performance with the same training iterations.

</p>
</details>

<details><summary><b>Efficient Majority Voting in Digital Hardware</b>
<a href="https://arxiv.org/abs/2108.03979">arxiv:2108.03979</a>
&#x1F4C8; 1 <br>
<p>Stefan Baumgartner, Mario Huemer, Michael Lunglmayr</p></summary>
<p>

**Abstract:** In recent years, machine learning methods became increasingly important for a manifold number of applications. However, they often suffer from high computational requirements impairing their efficient use in real-time systems, even when employing dedicated hardware accelerators. Ensemble learning methods are especially suitable for hardware acceleration since they can be constructed from individual learners of low complexity and thus offer large parallelization potential. For classification, the outputs of these learners are typically combined by majority voting, which often represents the bottleneck of a hardware accelerator for ensemble inference. In this work, we present a novel architecture that allows obtaining a majority decision in a number of clock cycles that is logarithmic in the number of inputs. We show, that for the example application of handwritten digit recognition a random forest processing engine employing this majority decision architecture implemented on an FPGA allows the classification of more than seven million images per second.

</p>
</details>

<details><summary><b>Deep Learning Based Antenna-time Domain Channel Extrapolation for Hybrid mmWave Massive MIMO</b>
<a href="https://arxiv.org/abs/2108.03941">arxiv:2108.03941</a>
&#x1F4C8; 1 <br>
<p>Shunbo Zhang, Shun Zhang, Jianpeng Ma, Tian Liu, Octavia A. Dobre</p></summary>
<p>

**Abstract:** In a time-varying massive multiple-input multipleoutput (MIMO) system, the acquisition of the downlink channel state information at the base station (BS) is a very challenging task due to the prohibitively high overheads associated with downlink training and uplink feedback. In this paper, we consider the hybrid precoding structure at BS and examine the antennatime domain channel extrapolation. We design a latent ordinary differential equation (ODE)-based network under the variational auto-encoder (VAE) framework to learn the mapping function from the partial uplink channels to the full downlink ones at the BS side. Specifically, the gated recurrent unit is adopted for the encoder and the fully-connected neural network is used for the decoder. The end-to-end learning is utilized to optimize the network parameters. Simulation results show that the designed network can efficiently infer the full downlink channels from the partial uplink ones, which can significantly reduce the channel training overhead.

</p>
</details>

<details><summary><b>TB-ICT: A Trustworthy Blockchain-Enabled System for Indoor COVID-19 Contact Tracing</b>
<a href="https://arxiv.org/abs/2108.08275">arxiv:2108.08275</a>
&#x1F4C8; 0 <br>
<p>Mohammad Salimibeni, Zohreh Hajiakhondi-Meybodi, Arash Mohammadi, Yingxu Wang</p></summary>
<p>

**Abstract:** Recently, as a consequence of the COVID-19 pandemic, dependence on Contact Tracing (CT) models has significantly increased to prevent spread of this highly contagious virus and be prepared for the potential future ones. Since the spreading probability of the novel coronavirus in indoor environments is much higher than that of the outdoors, there is an urgent and unmet quest to develop/design efficient, autonomous, trustworthy, and secure indoor CT solutions. Despite such an urgency, this field is still in its infancy. The paper addresses this gap and proposes the Trustworthy Blockchain-enabled system for Indoor Contact Tracing (TB-ICT) framework. The TB-ICT framework is proposed to protect privacy and integrity of the underlying CT data from unauthorized access. More specifically, it is a fully distributed and innovative blockchain platform exploiting the proposed dynamic Proof of Work (dPoW) credit-based consensus algorithm coupled with Randomized Hash Window (W-Hash) and dynamic Proof of Credit (dPoC) mechanisms to differentiate between honest and dishonest nodes. The TB-ICT not only provides a decentralization in data replication but also quantifies the node's behavior based on its underlying credit-based mechanism. For achieving high localization performance, we capitalize on availability of Internet of Things (IoT) indoor localization infrastructures, and develop a data driven localization model based on Bluetooth Low Energy (BLE) sensor measurements. The simulation results show that the proposed TB-ICT prevents the COVID-19 from spreading by implementation of a highly accurate contact tracing model while improving the users' privacy and security.

</p>
</details>

<details><summary><b>StarGAN-VC+ASR: StarGAN-based Non-Parallel Voice Conversion Regularized by Automatic Speech Recognition</b>
<a href="https://arxiv.org/abs/2108.04395">arxiv:2108.04395</a>
&#x1F4C8; 0 <br>
<p>Shoki Sakamoto, Akira Taniguchi, Tadahiro Taniguchi, Hirokazu Kameoka</p></summary>
<p>

**Abstract:** Preserving the linguistic content of input speech is essential during voice conversion (VC). The star generative adversarial network-based VC method (StarGAN-VC) is a recently developed method that allows non-parallel many-to-many VC. Although this method is powerful, it can fail to preserve the linguistic content of input speech when the number of available training samples is extremely small. To overcome this problem, we propose the use of automatic speech recognition to assist model training, to improve StarGAN-VC, especially in low-resource scenarios.
  Experimental results show that using our proposed method, StarGAN-VC can retain more linguistic information than vanilla StarGAN-VC.

</p>
</details>

<details><summary><b>RaftMLP: How Much Can Be Done Without Attention and with Less Spatial Locality?</b>
<a href="https://arxiv.org/abs/2108.04384">arxiv:2108.04384</a>
&#x1F4C8; 0 <br>
<p>Yuki Tatsunami, Masato Taki</p></summary>
<p>

**Abstract:** For the past ten years, CNN has reigned supreme in the world of computer vision, but recently, Transformer has been on the rise. However, the quadratic computational cost of self-attention has become a serious problem in practice applications. There has been much research on architectures without CNN and self-attention in this context. In particular, MLP-Mixer is a simple architecture designed using MLPs and hit an accuracy comparable to the Vision Transformer. However, the only inductive bias in this architecture is the embedding of tokens. This leaves open the possibility of incorporating a non-convolutional (or non-local) inductive bias into the architecture, so we used two simple ideas to incorporate inductive bias into the MLP-Mixer while taking advantage of its ability to capture global correlations. A way is to divide the token-mixing block vertically and horizontally. Another way is to make spatial correlations denser among some channels of token-mixing. With this approach, we were able to improve the accuracy of the MLP-Mixer while reducing its parameters and computational complexity. The small model that is RaftMLP-S is comparable to the state-of-the-art global MLP-based model in terms of parameters and efficiency per calculation. In addition, we tackled the problem of fixed input image resolution for global MLP-based models by utilizing bicubic interpolation. We demonstrated that these models could be applied as the backbone of architectures for downstream tasks such as object detection. However, it did not have significant performance and mentioned the need for MLP-specific architectures for downstream tasks for global MLP-based models. The source code in PyTorch version is available at \url{https://github.com/okojoalg/raft-mlp}.

</p>
</details>

<details><summary><b>Team Power Dynamics and Team Impact: New Perspectives on Scientific Collaboration using Career Age as a Proxy for Team Power</b>
<a href="https://arxiv.org/abs/2108.04108">arxiv:2108.04108</a>
&#x1F4C8; 0 <br>
<p>Huimin Xu, Yi Bu, Meijun Liu, Chenwei Zhang, Mengyi Sun, Yi Zhang, Eric Meyer, Eduardo Salas, Ying Ding</p></summary>
<p>

**Abstract:** Power is an unavoidable yet unrecognized element of collaboration. Power dynamics influence every aspect of scientific collaboration. Team power dynamics can be measured by team power level and team power hierarchy. Team power level is conceptualized as the average level of the possession of resources, expertise, or decision-making authorities of a team. Team power hierarchy represents the vertical differences of the possessions of resources in a team. In Science of Science, few studies have looked at scientific collaboration from the perspective of team power dynamics. This research examines how team power dynamics affect team impact to fill the research gap. In this research, all co-authors of one publication are treated as one team. Team power level and team power hierarchy of one team are measured by the mean and Gini index of career age of co-authors in this team. Team impact is quantified by citations of a paper authored by this team. By analyzing over 7.7 million teams from Science (e.g., Computer Science, Physics), Social Sciences (e.g., Sociology, Library & Information Science), and Arts & Humanities (e.g., Art), we find that flat team structure is associated with higher team impact. When team power level increases, teams with low team power hierarchy get cited more than teams with high team power hierarchy. These findings have been repeated in all five disciplines except Art, and are consistent in various types of teams from Computer Science including teams from industry or academia, teams with different gender groups, teams with geographical contrast, and teams with distinct size.

</p>
</details>


[Next Page](2021/2021-08/2021-08-08.md)
