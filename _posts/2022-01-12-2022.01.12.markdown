Prev: [2022.01.11]({{ '/2022/01/11/2022.01.11.html' | relative_url }})  Next: [2022.01.13]({{ '/2022/01/13/2022.01.13.html' | relative_url }})
{% raw %}
## Summary for 2022-01-12, created on 2022-01-22


<details><summary><b>Get your Foes Fooled: Proximal Gradient Split Learning for Defense against Model Inversion Attacks on IoMT data</b>
<a href="https://arxiv.org/abs/2201.04569">arxiv:2201.04569</a>
&#x1F4C8; 148 <br>
<p>Sunder Ali Khowaja, Ik Hyun Lee, Kapal Dev, Muhammad Aslam Jarwar, Nawab Muhammad Faseeh Qureshi</p></summary>
<p>

**Abstract:** The past decade has seen a rapid adoption of Artificial Intelligence (AI), specifically the deep learning networks, in Internet of Medical Things (IoMT) ecosystem. However, it has been shown recently that the deep learning networks can be exploited by adversarial attacks that not only make IoMT vulnerable to the data theft but also to the manipulation of medical diagnosis. The existing studies consider adding noise to the raw IoMT data or model parameters which not only reduces the overall performance concerning medical inferences but also is ineffective to the likes of deep leakage from gradients method. In this work, we propose proximal gradient split learning (PSGL) method for defense against the model inversion attacks. The proposed method intentionally attacks the IoMT data when undergoing the deep neural network training process at client side. We propose the use of proximal gradient method to recover gradient maps and a decision-level fusion strategy to improve the recognition performance. Extensive analysis show that the PGSL not only provides effective defense mechanism against the model inversion attacks but also helps in improving the recognition performance on publicly available datasets. We report 17.9$\%$ and 36.9$\%$ gains in accuracy over reconstructed and adversarial attacked images, respectively.

</p>
</details>

<details><summary><b>Generative time series models using Neural ODE in Variational Autoencoders</b>
<a href="https://arxiv.org/abs/2201.04630">arxiv:2201.04630</a>
&#x1F4C8; 116 <br>
<p>M. L. Garsdal, V. Søgaard, S. M. Sørensen</p></summary>
<p>

**Abstract:** In this paper, we implement Neural Ordinary Differential Equations in a Variational Autoencoder setting for generative time series modeling. An object-oriented approach to the code was taken to allow for easier development and research and all code used in the paper can be found here: https://github.com/simonmoesorensen/neural-ode-project
  The results were initially recreated and the reconstructions compared to a baseline Long-Short Term Memory AutoEncoder. The model was then extended with a LSTM encoder and challenged by more complex data consisting of time series in the form of spring oscillations. The model showed promise, and was able to reconstruct true trajectories for all complexities of data with a smaller RMSE than the baseline model. However, it was able to capture the dynamic behavior of the time series for known data in the decoder but was not able to produce extrapolations following the true trajectory very well for any of the complexities of spring data. A final experiment was carried out where the model was also presented with 68 days of solar power production data, and was able to reconstruct just as well as the baseline, even when very little data is available.
  Finally, the models training time was compared to the baseline. It was found that for small amounts of data the NODE method was significantly slower at training than the baseline, while for larger amounts of data the NODE method would be equal or faster at training.
  The paper is ended with a future work section which describes the many natural extensions to the work presented in this paper, with examples being investigating further the importance of input data, including extrapolation in the baseline model or testing more specific model setups.

</p>
</details>

<details><summary><b>Robust Contrastive Learning against Noisy Views</b>
<a href="https://arxiv.org/abs/2201.04309">arxiv:2201.04309</a>
&#x1F4C8; 49 <br>
<p>Ching-Yao Chuang, R Devon Hjelm, Xin Wang, Vibhav Vineet, Neel Joshi, Antonio Torralba, Stefanie Jegelka, Yale Song</p></summary>
<p>

**Abstract:** Contrastive learning relies on an assumption that positive pairs contain related views, e.g., patches of an image or co-occurring multimodal signals of a video, that share certain underlying information about an instance. But what if this assumption is violated? The literature suggests that contrastive learning produces suboptimal representations in the presence of noisy views, e.g., false positive pairs with no apparent shared information. In this work, we propose a new contrastive loss function that is robust against noisy views. We provide rigorous theoretical justifications by showing connections to robust symmetric losses for noisy binary classification and by establishing a new contrastive bound for mutual information maximization based on the Wasserstein distance measure. The proposed loss is completely modality-agnostic and a simple drop-in replacement for the InfoNCE loss, which makes it easy to apply to existing contrastive frameworks. We show that our approach provides consistent improvements over the state-of-the-art on image, video, and graph contrastive learning benchmarks that exhibit a variety of real-world noise patterns.

</p>
</details>

<details><summary><b>Nanowars can cause epidemic resurgence and fail to promote cooperation</b>
<a href="https://arxiv.org/abs/2201.04747">arxiv:2201.04747</a>
&#x1F4C8; 9 <br>
<p>Dirk Helbing, Matjaž Perc</p></summary>
<p>

**Abstract:** In a non-sustainable, "over-populated" world, what might the use of nanotechnology-based targeted, autonomous weapons mean for the future of humanity? In order to gain some insights, we make a simplified game-theoretical thought experiment. We consider a population where agents play the public goods game, and where in parallel an epidemic unfolds. Agents that are infected defectors are killed with a certain probability and replaced by susceptible cooperators. We show that such "nanowars", even if aiming to promote good behavior and planetary health, fail not only to promote cooperation, but they also significantly increase the probability of repetitive epidemic waves. In fact, newborn cooperators turn out to be easy targets for defectors in their neighborhood. Therefore, counterintuitively, the discussed intervention may even have the opposite effect as desired, promoting defection. We also find a critical threshold for the death rate of infected defectors, beyond which resurgent epidemic waves become a certainty. In conclusion, we urgently call for international regulation of nanotechnology and autonomous weapons.

</p>
</details>

<details><summary><b>How Can Graph Neural Networks Help Document Retrieval: A Case Study on CORD19 with Concept Map Generation</b>
<a href="https://arxiv.org/abs/2201.04672">arxiv:2201.04672</a>
&#x1F4C8; 7 <br>
<p>Hejie Cui, Jiaying Lu, Yao Ge, Carl Yang</p></summary>
<p>

**Abstract:** Graph neural networks (GNNs), as a group of powerful tools for representation learning on irregular data, have manifested superiority in various downstream tasks. With unstructured texts represented as concept maps, GNNs can be exploited for tasks like document retrieval. Intrigued by how can GNNs help document retrieval, we conduct an empirical study on a large-scale multi-discipline dataset CORD-19. Results show that instead of the complex structure-oriented GNNs such as GINs and GATs, our proposed semantics-oriented graph functions achieve better and more stable performance based on the BM25 retrieved candidates. Our insights in this case study can serve as a guideline for future work to develop effective GNNs with appropriate semantics-oriented inductive biases for textual reasoning tasks like document retrieval and classification. All code for this case study is available at https://github.com/HennyJie/GNN-DocRetrieval.

</p>
</details>

<details><summary><b>Early Diagnosis of Parkinsons Disease by Analyzing Magnetic Resonance Imaging Brain Scans and Patient Characteristics</b>
<a href="https://arxiv.org/abs/2201.04631">arxiv:2201.04631</a>
&#x1F4C8; 7 <br>
<p>Sabrina Zhu</p></summary>
<p>

**Abstract:** Parkinsons disease, PD, is a chronic condition that affects motor skills and includes symptoms like tremors and rigidity. The current diagnostic procedure uses patient assessments to evaluate symptoms and sometimes a magnetic resonance imaging or MRI scan. However, symptom variations cause inaccurate assessments, and the analysis of MRI scans requires experienced specialists. This research proposes to accurately diagnose PD severity with deep learning by combining symptoms data and MRI data from the Parkinsons Progression Markers Initiative database. A new hybrid model architecture was implemented to fully utilize both forms of clinical data, and models based on only symptoms and only MRI scans were also developed. The symptoms based model integrates a fully connected deep learning neural network, and the MRI scans and hybrid models integrate transfer learning based convolutional neural networks. Instead of performing only binary classification, all models diagnose patients into five severity categories, with stage zero representing healthy patients and stages four and five representing patients with PD. The symptoms only, MRI scans only, and hybrid models achieved accuracies of 0.77, 0.68, and 0.94, respectively. The hybrid model also had high precision and recall scores of 0.94 and 0.95. Real clinical cases confirm the strong performance of the hybrid, where patients were classified incorrectly with both other models but correctly by the hybrid. It is also consistent across the five severity stages, indicating accurate early detection. This is the first report to combine symptoms data and MRI scans with a machine learning approach on such a large scale.

</p>
</details>

<details><summary><b>Real-Time Style Modelling of Human Locomotion via Feature-Wise Transformations and Local Motion Phases</b>
<a href="https://arxiv.org/abs/2201.04439">arxiv:2201.04439</a>
&#x1F4C8; 7 <br>
<p>Ian Mason, Sebastian Starke, Taku Komura</p></summary>
<p>

**Abstract:** Controlling the manner in which a character moves in a real-time animation system is a challenging task with useful applications. Existing style transfer systems require access to a reference content motion clip, however, in real-time systems the future motion content is unknown and liable to change with user input. In this work we present a style modelling system that uses an animation synthesis network to model motion content based on local motion phases. An additional style modulation network uses feature-wise transformations to modulate style in real-time. To evaluate our method, we create and release a new style modelling dataset, 100STYLE, containing over 4 million frames of stylised locomotion data in 100 different styles that present a number of challenges for existing systems. To model these styles, we extend the local phase calculation with a contact-free formulation. In comparison to other methods for real-time style modelling, we show our system is more robust and efficient in its style representation while improving motion quality.

</p>
</details>

<details><summary><b>Toddler-Guidance Learning: Impacts of Critical Period on Multimodal AI Agents</b>
<a href="https://arxiv.org/abs/2201.04990">arxiv:2201.04990</a>
&#x1F4C8; 6 <br>
<p>Junseok Park, Kwanyoung Park, Hyunseok Oh, Ganghun Lee, Minsu Lee, Youngki Lee, Byoung-Tak Zhang</p></summary>
<p>

**Abstract:** Critical periods are phases during which a toddler's brain develops in spurts. To promote children's cognitive development, proper guidance is critical in this stage. However, it is not clear whether such a critical period also exists for the training of AI agents. Similar to human toddlers, well-timed guidance and multimodal interactions might significantly enhance the training efficiency of AI agents as well. To validate this hypothesis, we adapt this notion of critical periods to learning in AI agents and investigate the critical period in the virtual environment for AI agents. We formalize the critical period and Toddler-guidance learning in the reinforcement learning (RL) framework. Then, we built up a toddler-like environment with VECA toolkit to mimic human toddlers' learning characteristics. We study three discrete levels of mutual interaction: weak-mentor guidance (sparse reward), moderate mentor guidance (helper-reward), and mentor demonstration (behavioral cloning). We also introduce the EAVE dataset consisting of 30,000 real-world images to fully reflect the toddler's viewpoint. We evaluate the impact of critical periods on AI agents from two perspectives: how and when they are guided best in both uni- and multimodal learning. Our experimental results show that both uni- and multimodal agents with moderate mentor guidance and critical period on 1 million and 2 million training steps show a noticeable improvement. We validate these results with transfer learning on the EAVE dataset and find the performance advancement on the same critical period and the guidance.

</p>
</details>

<details><summary><b>Adversarially Robust Classification by Conditional Generative Model Inversion</b>
<a href="https://arxiv.org/abs/2201.04733">arxiv:2201.04733</a>
&#x1F4C8; 6 <br>
<p>Mitra Alirezaei, Tolga Tasdizen</p></summary>
<p>

**Abstract:** Most adversarial attack defense methods rely on obfuscating gradients. These methods are successful in defending against gradient-based attacks; however, they are easily circumvented by attacks which either do not use the gradient or by attacks which approximate and use the corrected gradient. Defenses that do not obfuscate gradients such as adversarial training exist, but these approaches generally make assumptions about the attack such as its magnitude. We propose a classification model that does not obfuscate gradients and is robust by construction without assuming prior knowledge about the attack. Our method casts classification as an optimization problem where we "invert" a conditional generator trained on unperturbed, natural images to find the class that generates the closest sample to the query image. We hypothesize that a potential source of brittleness against adversarial attacks is the high-to-low-dimensional nature of feed-forward classifiers which allows an adversary to find small perturbations in the input space that lead to large changes in the output space. On the other hand, a generative model is typically a low-to-high-dimensional mapping. While the method is related to Defense-GAN, the use of a conditional generative model and inversion in our model instead of the feed-forward classifier is a critical difference. Unlike Defense-GAN, which was shown to generate obfuscated gradients that are easily circumvented, we show that our method does not obfuscate gradients. We demonstrate that our model is extremely robust against black-box attacks and has improved robustness against white-box attacks compared to naturally trained, feed-forward classifiers.

</p>
</details>

<details><summary><b>On generalization bounds for deep networks based on loss surface implicit regularization</b>
<a href="https://arxiv.org/abs/2201.04545">arxiv:2201.04545</a>
&#x1F4C8; 6 <br>
<p>Masaaki Imaizumi, Johannes Schmidt-Hieber</p></summary>
<p>

**Abstract:** The classical statistical learning theory says that fitting too many parameters leads to overfitting and poor performance. That modern deep neural networks generalize well despite a large number of parameters contradicts this finding and constitutes a major unsolved problem towards explaining the success of deep learning. The implicit regularization induced by stochastic gradient descent (SGD) has been regarded to be important, but its specific principle is still unknown. In this work, we study how the local geometry of the energy landscape around local minima affects the statistical properties of SGD with Gaussian gradient noise. We argue that under reasonable assumptions, the local geometry forces SGD to stay close to a low dimensional subspace and that this induces implicit regularization and results in tighter bounds on the generalization error for deep neural networks. To derive generalization error bounds for neural networks, we first introduce a notion of stagnation sets around the local minima and impose a local essential convexity property of the population risk. Under these conditions, lower bounds for SGD to remain in these stagnation sets are derived. If stagnation occurs, we derive a bound on the generalization error of deep neural networks involving the spectral norms of the weight matrices but not the number of network parameters. Technically, our proofs are based on controlling the change of parameter values in the SGD iterates and local uniform convergence of the empirical loss functions based on the entropy of suitable neighborhoods around local minima. Our work attempts to better connect non-convex optimization and generalization analysis with uniform convergence.

</p>
</details>

<details><summary><b>The Concept of Criticality in AI Safety</b>
<a href="https://arxiv.org/abs/2201.04632">arxiv:2201.04632</a>
&#x1F4C8; 5 <br>
<p>Yitzhak Spielberg, Amos Azaria</p></summary>
<p>

**Abstract:** When AI agents don't align their actions with human values they may cause serious harm. One way to solve the value alignment problem is by including a human operator who monitors all of the agent's actions. Despite the fact, that this solution guarantees maximal safety, it is very inefficient, since it requires the human operator to dedicate all of his attention to the agent. In this paper, we propose a much more efficient solution that allows an operator to be engaged in other activities without neglecting his monitoring task. In our approach the AI agent requests permission from the operator only for critical actions, that is, potentially harmful actions. We introduce the concept of critical actions with respect to AI safety and discuss how to build a model that measures action criticality. We also discuss how the operator's feedback could be used to make the agent smarter.

</p>
</details>

<details><summary><b>Depth Estimation from Single-shot Monocular Endoscope Image Using Image Domain Adaptation And Edge-Aware Depth Estimation</b>
<a href="https://arxiv.org/abs/2201.04485">arxiv:2201.04485</a>
&#x1F4C8; 5 <br>
<p>Masahiro Oda, Hayato Itoh, Kiyohito Tanaka, Hirotsugu Takabatake, Masaki Mori, Hiroshi Natori, Kensaku Mori</p></summary>
<p>

**Abstract:** We propose a depth estimation method from a single-shot monocular endoscopic image using Lambertian surface translation by domain adaptation and depth estimation using multi-scale edge loss. We employ a two-step estimation process including Lambertian surface translation from unpaired data and depth estimation. The texture and specular reflection on the surface of an organ reduce the accuracy of depth estimations. We apply Lambertian surface translation to an endoscopic image to remove these texture and reflections. Then, we estimate the depth by using a fully convolutional network (FCN). During the training of the FCN, improvement of the object edge similarity between an estimated image and a ground truth depth image is important for getting better results. We introduced a muti-scale edge loss function to improve the accuracy of depth estimation. We quantitatively evaluated the proposed method using real colonoscopic images. The estimated depth values were proportional to the real depth values. Furthermore, we applied the estimated depth images to automated anatomical location identification of colonoscopic images using a convolutional neural network. The identification accuracy of the network improved from 69.2% to 74.1% by using the estimated depth images.

</p>
</details>

<details><summary><b>ULTRA: A Data-driven Approach for Recommending Team Formation in Response to Proposal Calls</b>
<a href="https://arxiv.org/abs/2201.05646">arxiv:2201.05646</a>
&#x1F4C8; 4 <br>
<p>Biplav Srivastava, Tarmo Koppel, Ronak Shah, Owen Bond, Sai Teja Paladi, Rohit Sharma, Austin Hetherington</p></summary>
<p>

**Abstract:** We introduce an emerging AI-based approach and prototype system for assisting team formation when researchers respond to calls for proposals from funding agencies. This is an instance of the general problem of building teams when demand opportunities come periodically and potential members may vary over time. The novelties of our approach are that we: (a) extract technical skills needed about researchers and calls from multiple data sources and normalize them using Natural Language Processing (NLP) techniques, (b) build a prototype solution based on matching and teaming based on constraints, (c) describe initial feedback about system from researchers at a University to deploy, and (d) create and publish a dataset that others can use.

</p>
</details>

<details><summary><b>A Survey on Masked Facial Detection Methods and Datasets for Fighting Against COVID-19</b>
<a href="https://arxiv.org/abs/2201.04777">arxiv:2201.04777</a>
&#x1F4C8; 4 <br>
<p>Bingshu Wang, Jiangbin Zheng, C. L. Philip Chen</p></summary>
<p>

**Abstract:** Coronavirus disease 2019 (COVID-19) continues to pose a great challenge to the world since its outbreak. To fight against the disease, a series of artificial intelligence (AI) techniques are developed and applied to real-world scenarios such as safety monitoring, disease diagnosis, infection risk assessment, lesion segmentation of COVID-19 CT scans,etc. The coronavirus epidemics have forced people wear masks to counteract the transmission of virus, which also brings difficulties to monitor large groups of people wearing masks. In this paper, we primarily focus on the AI techniques of masked facial detection and related datasets. We survey the recent advances, beginning with the descriptions of masked facial detection datasets. Thirteen available datasets are described and discussed in details. Then, the methods are roughly categorized into two classes: conventional methods and neural network-based methods. Conventional methods are usually trained by boosting algorithms with hand-crafted features, which accounts for a small proportion. Neural network-based methods are further classified as three parts according to the number of processing stages. Representative algorithms are described in detail, coupled with some typical techniques that are described briefly. Finally, we summarize the recent benchmarking results, give the discussions on the limitations of datasets and methods, and expand future research directions. To our knowledge, this is the first survey about masked facial detection methods and datasets. Hopefully our survey could provide some help to fight against epidemics.

</p>
</details>

<details><summary><b>Revelation of Task Difficulty in AI-aided Education</b>
<a href="https://arxiv.org/abs/2201.04633">arxiv:2201.04633</a>
&#x1F4C8; 4 <br>
<p>Yitzhak Spielberg, Amos Azaria</p></summary>
<p>

**Abstract:** When a student is asked to perform a given task, her subjective estimate of the difficulty of that task has a strong influence on her performance. There exists a rich literature on the impact of perceived task difficulty on performance and motivation. Yet, there is another topic that is closely related to the subject of the influence of perceived task difficulty that did not receive any attention in previous research - the influence of revealing the true difficulty of a task to the student. This paper investigates the impact of revealing the task difficulty on the student's performance, motivation, self-efficacy and subjective task value via an experiment in which workers are asked to solve matchstick riddles. Furthermore, we discuss how the experiment results might be relevant for AI-aided education. Specifically, we elaborate on the question of how a student's learning experience might be improved by supporting her with two types of AI systems: an AI system that predicts task difficulty and an AI system that determines when task difficulty should be revealed and when not.

</p>
</details>

<details><summary><b>ECONet: Efficient Convolutional Online Likelihood Network for Scribble-based Interactive Segmentation</b>
<a href="https://arxiv.org/abs/2201.04584">arxiv:2201.04584</a>
&#x1F4C8; 4 <br>
<p>Muhammad Asad, Lucas Fidon, Tom Vercauteren</p></summary>
<p>

**Abstract:** Automatic segmentation of lung lesions associated with COVID-19 in CT images requires large amount of annotated volumes. Annotations mandate expert knowledge and are time-intensive to obtain through fully manual segmentation methods. Additionally, lung lesions have large inter-patient variations, with some pathologies having similar visual appearance as healthy lung tissues. This poses a challenge when applying existing semi-automatic interactive segmentation techniques for data labelling. To address these challenges, we propose an efficient convolutional neural networks (CNNs) that can be learned online while the annotator provides scribble-based interaction. To accelerate learning from only the samples labelled through user-interactions, a patch-based approach is used for training the network. Moreover, we use weighted cross-entropy loss to address the class imbalance that may result from user-interactions. During online inference, the learned network is applied to the whole input volume using a fully convolutional approach. We compare our proposed method with state-of-the-art and show that it outperforms existing methods on the task of annotating lung lesions associated with COVID-19, achieving 16% higher Dice score while reducing execution time by 3$\times$ and requiring 9000 lesser scribbles-based labelled voxels. Due to the online learning aspect, our approach adapts quickly to user input, resulting in high quality segmentation labels. Source code will be made available upon acceptance.

</p>
</details>

<details><summary><b>Optimizing Prediction of MGMT Promoter Methylation from MRI Scans using Adversarial Learning</b>
<a href="https://arxiv.org/abs/2201.04416">arxiv:2201.04416</a>
&#x1F4C8; 4 <br>
<p>Sauman Das</p></summary>
<p>

**Abstract:** Glioblastoma Multiforme (GBM) is a malignant brain cancer forming around 48% of al brain and Central Nervous System (CNS) cancers. It is estimated that annually over 13,000 deaths occur in the US due to GBM, making it crucial to have early diagnosis systems that can lead to predictable and effective treatment. The most common treatment after GBM diagnosis is chemotherapy, which works by sending rapidly dividing cells to apoptosis. However, this form of treatment is not effective when the MGMT promoter sequence is methylated, and instead leads to severe side effects decreasing patient survivability. Therefore, it is important to be able to identify the MGMT promoter methylation status through non-invasive magnetic resonance imaging (MRI) based machine learning (ML) models. This is accomplished using the Brain Tumor Segmentation (BraTS) 2021 dataset, which was recently used for an international Kaggle competition. We developed four primary models - two radiomic models and two CNN models - each solving the binary classification task with progressive improvements. We built a novel ML model termed as the Intermediate State Generator which was used to normalize the slice thicknesses of all MRI scans. With further improvements, our best model was able to achieve performance significantly ($p < 0.05$) better than the best performing Kaggle model with a 6% increase in average cross-validation accuracy. This improvement could potentially lead to a more informed choice of chemotherapy as a treatment option, prolonging lives of thousands of patients with GBM each year.

</p>
</details>

<details><summary><b>Maximizing Self-supervision from Thermal Image for Effective Self-supervised Learning of Depth and Ego-motion</b>
<a href="https://arxiv.org/abs/2201.04387">arxiv:2201.04387</a>
&#x1F4C8; 4 <br>
<p>Ukcheol Shin, Kyunghyun Lee, Byeong-Uk Lee, In So Kweon</p></summary>
<p>

**Abstract:** Recently, self-supervised learning of depth and ego-motion from thermal images shows strong robustness and reliability under challenging scenarios. However, the inherent thermal image properties such as weak contrast, blurry edges, and noise hinder to generate effective self-supervision from thermal images. Therefore, most research relies on additional self-supervision sources such as well-lit RGB images, generative models, and Lidar information. In this paper, we conduct an in-depth analysis of thermal image characteristics that degenerates self-supervision from thermal images. Based on the analysis, we propose an effective thermal image mapping method that significantly increases image information, such as overall structure, contrast, and details, while preserving temporal consistency. The proposed method shows outperformed depth and pose results than previous state-of-the-art networks without leveraging additional RGB guidance.

</p>
</details>

<details><summary><b>Privacy-Utility Trades in Crowdsourced Signal Map Obfuscation</b>
<a href="https://arxiv.org/abs/2201.04782">arxiv:2201.04782</a>
&#x1F4C8; 3 <br>
<p>Jiang Zhang, Lillian Clark, Matthew Clark, Konstantinos Psounis, Peter Kairouz</p></summary>
<p>

**Abstract:** Cellular providers and data aggregating companies crowdsource celluar signal strength measurements from user devices to generate signal maps, which can be used to improve network performance. Recognizing that this data collection may be at odds with growing awareness of privacy concerns, we consider obfuscating such data before the data leaves the mobile device. The goal is to increase privacy such that it is difficult to recover sensitive features from the obfuscated data (e.g. user ids and user whereabouts), while still allowing network providers to use the data for improving network services (i.e. create accurate signal maps). To examine this privacy-utility tradeoff, we identify privacy and utility metrics and threat models suited to signal strength measurements. We then obfuscate the measurements using several preeminent techniques, spanning differential privacy, generative adversarial privacy, and information-theoretic privacy techniques, in order to benchmark a variety of promising obfuscation approaches and provide guidance to real-world engineers who are tasked to build signal maps that protect privacy without hurting utility. Our evaluation results, based on multiple, diverse, real-world signal map datasets, demonstrate the feasibility of concurrently achieving adequate privacy and utility, with obfuscation strategies which use the structure and intended use of datasets in their design, and target average-case, rather than worst-case, guarantees.

</p>
</details>

<details><summary><b>Privacy Amplification by Subsampling in Time Domain</b>
<a href="https://arxiv.org/abs/2201.04762">arxiv:2201.04762</a>
&#x1F4C8; 3 <br>
<p>Tatsuki Koga, Casey Meehan, Kamalika Chaudhuri</p></summary>
<p>

**Abstract:** Aggregate time-series data like traffic flow and site occupancy repeatedly sample statistics from a population across time. Such data can be profoundly useful for understanding trends within a given population, but also pose a significant privacy risk, potentially revealing e.g., who spends time where. Producing a private version of a time-series satisfying the standard definition of Differential Privacy (DP) is challenging due to the large influence a single participant can have on the sequence: if an individual can contribute to each time step, the amount of additive noise needed to satisfy privacy increases linearly with the number of time steps sampled. As such, if a signal spans a long duration or is oversampled, an excessive amount of noise must be added, drowning out underlying trends. However, in many applications an individual realistically cannot participate at every time step. When this is the case, we observe that the influence of a single participant (sensitivity) can be reduced by subsampling and/or filtering in time, while still meeting privacy requirements. Using a novel analysis, we show this significant reduction in sensitivity and propose a corresponding class of privacy mechanisms. We demonstrate the utility benefits of these techniques empirically with real-world and synthetic time-series data.

</p>
</details>

<details><summary><b>Partial-Attribution Instance Segmentation for Astronomical Source Detection and Deblending</b>
<a href="https://arxiv.org/abs/2201.04714">arxiv:2201.04714</a>
&#x1F4C8; 3 <br>
<p>Ryan Hausen, Brant Robertson</p></summary>
<p>

**Abstract:** Astronomical source deblending is the process of separating the contribution of individual stars or galaxies (sources) to an image comprised of multiple, possibly overlapping sources. Astronomical sources display a wide range of sizes and brightnesses and may show substantial overlap in images. Astronomical imaging data can further challenge off-the-shelf computer vision algorithms owing to its high dynamic range, low signal-to-noise ratio, and unconventional image format. These challenges make source deblending an open area of astronomical research, and in this work, we introduce a new approach called Partial-Attribution Instance Segmentation that enables source detection and deblending in a manner tractable for deep learning models. We provide a novel neural network implementation as a demonstration of the method.

</p>
</details>

<details><summary><b>Detection of brain tumors using machine learning algorithms</b>
<a href="https://arxiv.org/abs/2201.04703">arxiv:2201.04703</a>
&#x1F4C8; 3 <br>
<p>Horacio Corral, Javier Melchor, Balam Sotelo, Jorge Vera</p></summary>
<p>

**Abstract:** An algorithm capable of processing NMR images was developed for analysis using machine learning techniques to detect the presence of brain tumors.

</p>
</details>

<details><summary><b>When Machine Learning Meets Spectrum Sharing Security: Methodologies and Challenges</b>
<a href="https://arxiv.org/abs/2201.04677">arxiv:2201.04677</a>
&#x1F4C8; 3 <br>
<p>Qun Wang, Haijian Sun, Rose Qingyang Hu, Arupjyoti Bhuyan</p></summary>
<p>

**Abstract:** The exponential growth of internet connected systems has generated numerous challenges, such as spectrum shortage issues, which require efficient spectrum sharing (SS) solutions. Complicated and dynamic SS systems can be exposed to different potential security and privacy issues, requiring protection mechanisms to be adaptive, reliable, and scalable. Machine learning (ML) based methods have frequently been proposed to address those issues. In this article, we provide a comprehensive survey of the recent development of ML based SS methods, the most critical security issues, and corresponding defense mechanisms. In particular, we elaborate the state-of-the-art methodologies for improving the performance of SS communication systems for various vital aspects, including ML based cognitive radio networks (CRNs), ML based database assisted SS networks, ML based LTE-U networks, ML based ambient backscatter networks, and other ML based SS solutions. We also present security issues from the physical layer and corresponding defending strategies based on ML algorithms, including Primary User Emulation (PUE) attacks, Spectrum Sensing Data Falsification (SSDF) attacks, jamming attacks, eavesdropping attacks, and privacy issues. Finally, extensive discussions on open challenges for ML based SS are also given. This comprehensive review is intended to provide the foundation for and facilitate future studies on exploring the potential of emerging ML for coping with increasingly complex SS and their security problems.

</p>
</details>

<details><summary><b>GraphVAMPNet, using graph neural networks and variational approach to markov processes for dynamical modeling of biomolecules</b>
<a href="https://arxiv.org/abs/2201.04609">arxiv:2201.04609</a>
&#x1F4C8; 3 <br>
<p>Mahdi Ghorbani, Samarjeet Prasad, Jeffery B. Klauda, Bernard R. Brooks</p></summary>
<p>

**Abstract:** Finding low dimensional representation of data from long-timescale trajectories of biomolecular processes such as protein-folding or ligand-receptor binding is of fundamental importance and kinetic models such as Markov modeling have proven useful in describing the kinetics of these systems. Recently, an unsupervised machine learning technique called VAMPNet was introduced to learn the low dimensional representation and linear dynamical model in an end-to-end manner. VAMPNet is based on variational approach to Markov processes (VAMP) and relies on neural networks to learn the coarse-grained dynamics. In this contribution, we combine VAMPNet and graph neural networks to generate an end-to-end framework to efficiently learn high-level dynamics and metastable states from the long-timescale molecular dynamics trajectories. This method bears the advantages of graph representation learning and uses graph message passing operations to generate an embedding for each datapoint which is used in the VAMPNet to generate a coarse-grained representation. This type of molecular representation results in a higher resolution and more interpretable Markov model than the standard VAMPNet enabling a more detailed kinetic study of the biomolecular processes. Our GraphVAMPNet approach is also enhanced with an attention mechanism to find the important residues for classification into different metastable states.

</p>
</details>

<details><summary><b>Globally Optimal Multi-Scale Monocular Hand-Eye Calibration Using Dual Quaternions</b>
<a href="https://arxiv.org/abs/2201.04473">arxiv:2201.04473</a>
&#x1F4C8; 3 <br>
<p>Thomas Wodtko, Markus Horn, Michael Buchholz, Klaus Dietmayer</p></summary>
<p>

**Abstract:** In this work, we present an approach for monocular hand-eye calibration from per-sensor ego-motion based on dual quaternions. Due to non-metrically scaled translations of monocular odometry, a scaling factor has to be estimated in addition to the rotation and translation calibration. For this, we derive a quadratically constrained quadratic program that allows a combined estimation of all extrinsic calibration parameters. Using dual quaternions leads to low run-times due to their compact representation. Our problem formulation further allows to estimate multiple scalings simultaneously for different sequences of the same sensor setup. Based on our problem formulation, we derive both, a fast local and a globally optimal solving approach. Finally, our algorithms are evaluated and compared to state-of-the-art approaches on simulated and real-world data, e.g., the EuRoC MAV dataset.

</p>
</details>

<details><summary><b>Optimal Fixed-Budget Best Arm Identification using the Augmented Inverse Probability Estimator in Two-Armed Gaussian Bandits with Unknown Variances</b>
<a href="https://arxiv.org/abs/2201.04469">arxiv:2201.04469</a>
&#x1F4C8; 3 <br>
<p>Masahiro Kato, Kaito Ariu, Masaaki Imaizumi, Masatoshi Uehara, Masahiro Nomura, Chao Qin</p></summary>
<p>

**Abstract:** We consider the fixed-budget best arm identification problem in two-armed Gaussian bandits with unknown variances. The tightest lower bound on the complexity and an algorithm whose performance guarantee matches the lower bound have long been open problems when the variances are unknown and when the algorithm is agnostic to the optimal proportion of the arm draws. In this paper, we propose a strategy comprising a sampling rule with randomized sampling (RS) following the estimated target allocation probabilities of arm draws and a recommendation rule using the augmented inverse probability weighting (AIPW) estimator, which is often used in the causal inference literature. We refer to our strategy as the RS-AIPW strategy. In the theoretical analysis, we first derive a large deviation principle for martingales, which can be used when the second moment converges in mean, and apply it to our proposed strategy. Then, we show that the proposed strategy is asymptotically optimal in the sense that the probability of misidentification achieves the lower bound by Kaufmann et al. (2016) when the sample size becomes infinitely large and the gap between the two arms goes to zero.

</p>
</details>

<details><summary><b>SLISEMAP: Explainable Dimensionality Reduction</b>
<a href="https://arxiv.org/abs/2201.04455">arxiv:2201.04455</a>
&#x1F4C8; 3 <br>
<p>Anton Björklund, Jarmo Mäkelä, Kai Puolamäki</p></summary>
<p>

**Abstract:** Existing explanation methods for black-box supervised learning models generally work by building local models that explain the models behaviour for a particular data item. It is possible to make global explanations, but the explanations may have low fidelity for complex models. Most of the prior work on explainable models has been focused on classification problems, with less attention on regression.
  We propose a new manifold visualization method, SLISEMAP, that at the same time finds local explanations for all of the data items and builds a two-dimensional visualization of model space such that the data items explained by the same model are projected nearby. We provide an open source implementation of our methods, implemented by using GPU-optimized PyTorch library. SLISEMAP works both on classification and regression models.
  We compare SLISEMAP to most popular dimensionality reduction methods and some local explanation methods. We provide mathematical derivation of our problem and show that SLISEMAP provides fast and stable visualizations that can be used to explain and understand black box regression and classification models.

</p>
</details>

<details><summary><b>Multi-task Joint Strategies of Self-supervised Representation Learning on Biomedical Networks for Drug Discovery</b>
<a href="https://arxiv.org/abs/2201.04437">arxiv:2201.04437</a>
&#x1F4C8; 3 <br>
<p>Xiaoqi Wang, Yingjie Cheng, Yaning Yang, Fei Li, Shaoliang Peng</p></summary>
<p>

**Abstract:** Self-supervised representation learning (SSL) on biomedical networks provides new opportunities for drug discovery which is lack of available biological or clinic phenotype. However, how to effectively combine multiple SSL models is challenging and rarely explored. Therefore, we propose multi-task joint strategies of self-supervised representation learning on biomedical networks for drug discovery, named MSSL2drug. We design six basic SSL tasks that are inspired by various modality features including structures, semantics, and attributes in biomedical heterogeneous networks. In addition, fifteen combinations of multiple tasks are evaluated by a graph attention-based adversarial multi-task learning framework in two drug discovery scenarios. The results suggest two important findings. (1) The combinations of multimodal tasks achieve the best performance compared to other multi-task joint strategies. (2) The joint training of local and global SSL tasks yields higher performance than random task combinations. Therefore, we conjecture that the multimodal and local-global combination strategies can be regarded as a guideline for multi-task SSL to drug discovery.

</p>
</details>

<details><summary><b>GateFormer: Speeding Up News Feed Recommendation with Input Gated Transformers</b>
<a href="https://arxiv.org/abs/2201.04406">arxiv:2201.04406</a>
&#x1F4C8; 3 <br>
<p>Peitian Zhang, Zheng liu</p></summary>
<p>

**Abstract:** News feed recommendation is an important web service. In recent years, pre-trained language models (PLMs) have been intensively applied to improve the recommendation quality. However, the utilization of these deep models is limited in many aspects, such as lack of explainability and being incompatible with the existing inverted index systems. Above all, the PLMs based recommenders are inefficient, as the encoding of user-side information will take huge computation costs. Although the computation can be accelerated with efficient transformers or distilled PLMs, it is still not enough to make timely recommendations for the active users, who are associated with super long news browsing histories.
  In this work, we tackle the efficient news recommendation problem from a distinctive perspective. Instead of relying on the entire input (i.e., the collection of news articles a user ever browsed), we argue that the user's interest can be fully captured merely with those representative keywords. Motivated by this, we propose GateFormer, where the input data is gated before feeding into transformers. The gating module is made personalized, lightweight and end-to-end learnable, such that it may perform accurate and efficient filtering of informative user input. GateFormer achieves highly impressive performances in experiments, where it notably outperforms the existing acceleration approaches in both accuracy and efficiency. We also surprisingly find that even with over 10-fold compression of the original input, GateFormer is still able to maintain on-par performances with the SOTA methods.

</p>
</details>

<details><summary><b>Towards Adversarially Robust Deep Image Denoising</b>
<a href="https://arxiv.org/abs/2201.04397">arxiv:2201.04397</a>
&#x1F4C8; 3 <br>
<p>Hanshu Yan, Jingfeng Zhang, Jiashi Feng, Masashi Sugiyama, Vincent Y. F. Tan</p></summary>
<p>

**Abstract:** This work systematically investigates the adversarial robustness of deep image denoisers (DIDs), i.e, how well DIDs can recover the ground truth from noisy observations degraded by adversarial perturbations. Firstly, to evaluate DIDs' robustness, we propose a novel adversarial attack, namely Observation-based Zero-mean Attack ({\sc ObsAtk}), to craft adversarial zero-mean perturbations on given noisy images. We find that existing DIDs are vulnerable to the adversarial noise generated by {\sc ObsAtk}. Secondly, to robustify DIDs, we propose an adversarial training strategy, hybrid adversarial training ({\sc HAT}), that jointly trains DIDs with adversarial and non-adversarial noisy data to ensure that the reconstruction quality is high and the denoisers around non-adversarial data are locally smooth. The resultant DIDs can effectively remove various types of synthetic and adversarial noise. We also uncover that the robustness of DIDs benefits their generalization capability on unseen real-world noise. Indeed, {\sc HAT}-trained DIDs can recover high-quality clean images from real-world noise even without training on real noisy data. Extensive experiments on benchmark datasets, including Set68, PolyU, and SIDD, corroborate the effectiveness of {\sc ObsAtk} and {\sc HAT}.

</p>
</details>

<details><summary><b>Predicting Alzheimer's Disease Using 3DMgNet</b>
<a href="https://arxiv.org/abs/2201.04370">arxiv:2201.04370</a>
&#x1F4C8; 3 <br>
<p>Yelu Gao, Huang Huang, Lian Zhang</p></summary>
<p>

**Abstract:** Alzheimer's disease (AD) is an irreversible neurode generative disease of the brain.The disease may causes memory loss, difficulty communicating and disorientation. For the diagnosis of Alzheimer's disease, a series of scales are often needed to evaluate the diagnosis clinically, which not only increases the workload of doctors, but also makes the results of diagnosis highly subjective. Therefore, for Alzheimer's disease, imaging means to find early diagnostic markers has become a top priority.
  In this paper, we propose a novel 3DMgNet architecture which is a unified framework of multigrid and convolutional neural network to diagnose Alzheimer's disease (AD). The model is trained using an open dataset (ADNI dataset) and then test with a smaller dataset of ours. Finally, the model achieved 92.133% accuracy for AD vs NC classification and significantly reduced the model parameters.

</p>
</details>

<details><summary><b>A Non-Classical Parameterization for Density Estimation Using Sample Moments</b>
<a href="https://arxiv.org/abs/2201.04786">arxiv:2201.04786</a>
&#x1F4C8; 2 <br>
<p>Guangyu Wu, Anders Lindquist</p></summary>
<p>

**Abstract:** Moment methods are an important means of density estimation, but they are generally strongly dependent on the choice of feasible functions, which severely affects the performance. We propose a non-classical parameterization for density estimation using the sample moments, which does not require the choice of such functions. The parameterization is induced by the Kullback-Leibler distance, and the solution of it, which is proved to exist and be unique subject to simple prior that does not depend on data, can be obtained by convex optimization. Simulation results show the performance of the proposed estimator in estimating multi-modal densities which are mixtures of different types of functions.

</p>
</details>

<details><summary><b>MAg: a simple learning-based patient-level aggregation method for detecting microsatellite instability from whole-slide images</b>
<a href="https://arxiv.org/abs/2201.04769">arxiv:2201.04769</a>
&#x1F4C8; 2 <br>
<p>Kaifeng Pang, Zuhayr Asad, Shilin Zhao, Yuankai Huo</p></summary>
<p>

**Abstract:** The prediction of microsatellite instability (MSI) and microsatellite stability (MSS) is essential in predicting both the treatment response and prognosis of gastrointestinal cancer. In clinical practice, a universal MSI testing is recommended, but the accessibility of such a test is limited. Thus, a more cost-efficient and broadly accessible tool is desired to cover the traditionally untested patients. In the past few years, deep-learning-based algorithms have been proposed to predict MSI directly from haematoxylin and eosin (H&E)-stained whole-slide images (WSIs). Such algorithms can be summarized as (1) patch-level MSI/MSS prediction, and (2) patient-level aggregation. Compared with the advanced deep learning approaches that have been employed for the first stage, only the naïve first-order statistics (e.g., averaging and counting) were employed in the second stage. In this paper, we propose a simple yet broadly generalizable patient-level MSI aggregation (MAg) method to effectively integrate the precious patch-level information. Briefly, the entire probabilistic distribution in the first stage is modeled as histogram-based features to be fused as the final outcome with machine learning (e.g., SVM). The proposed MAg method can be easily used in a plug-and-play manner, which has been evaluated upon five broadly used deep neural networks: ResNet, MobileNetV2, EfficientNet, Dpn and ResNext. From the results, the proposed MAg method consistently improves the accuracy of patient-level aggregation for two publicly available datasets. It is our hope that the proposed method could potentially leverage the low-cost H&E based MSI detection method. The code of our work has been made publicly available at https://github.com/Calvin-Pang/MAg.

</p>
</details>

<details><summary><b>Largest Eigenvalues of the Conjugate Kernel of Single-Layered Neural Networks</b>
<a href="https://arxiv.org/abs/2201.04753">arxiv:2201.04753</a>
&#x1F4C8; 2 <br>
<p>Lucas Benigni, Sandrine Péché</p></summary>
<p>

**Abstract:** This paper is concerned with the asymptotic distribution of the largest eigenvalues for some nonlinear random matrix ensemble stemming from the study of neural networks. More precisely we consider $M= \frac{1}{m} YY^\top$ with $Y=f(WX)$ where $W$ and $X$ are random rectangular matrices with i.i.d. centered entries. This models the data covariance matrix or the Conjugate Kernel of a single layered random Feed-Forward Neural Network. The function $f$ is applied entrywise and can be seen as the activation function of the neural network. We show that the largest eigenvalue has the same limit (in probability) as that of some well-known linear random matrix ensembles. In particular, we relate the asymptotic limit of the largest eigenvalue for the nonlinear model to that of an information-plus-noise random matrix, establishing a possible phase transition depending on the function $f$ and the distribution of $W$ and $X$. This may be of interest for applications to machine learning.

</p>
</details>

<details><summary><b>Implicit Bias of MSE Gradient Optimization in Underparameterized Neural Networks</b>
<a href="https://arxiv.org/abs/2201.04738">arxiv:2201.04738</a>
&#x1F4C8; 2 <br>
<p>Benjamin Bowman, Guido Montufar</p></summary>
<p>

**Abstract:** We study the dynamics of a neural network in function space when optimizing the mean squared error via gradient flow. We show that in the underparameterized regime the network learns eigenfunctions of an integral operator $T_{K^\infty}$ determined by the Neural Tangent Kernel (NTK) at rates corresponding to their eigenvalues. For example, for uniformly distributed data on the sphere $S^{d - 1}$ and rotation invariant weight distributions, the eigenfunctions of $T_{K^\infty}$ are the spherical harmonics. Our results can be understood as describing a spectral bias in the underparameterized regime. The proofs use the concept of "Damped Deviations", where deviations of the NTK matter less for eigendirections with large eigenvalues due to the occurence of a damping factor. Aside from the underparameterized regime, the damped deviations point-of-view can be used to track the dynamics of the empirical risk in the overparameterized setting, allowing us to extend certain results in the literature. We conclude that damped deviations offers a simple and unifying perspective of the dynamics when optimizing the squared error.

</p>
</details>

<details><summary><b>On neural network kernels and the storage capacity problem</b>
<a href="https://arxiv.org/abs/2201.04669">arxiv:2201.04669</a>
&#x1F4C8; 2 <br>
<p>Jacob A. Zavatone-Veth, Cengiz Pehlevan</p></summary>
<p>

**Abstract:** In this short note, we reify the connection between work on the storage capacity problem in wide two-layer treelike neural networks and the rapidly-growing body of literature on kernel limits of wide neural networks. Concretely, we observe that the "effective order parameter" studied in the statistical mechanics literature is exactly equivalent to the infinite-width Neural Network Gaussian Process Kernel. This correspondence connects the expressivity and trainability of wide two-layer neural networks.

</p>
</details>

<details><summary><b>Multi-echelon Supply Chains with Uncertain Seasonal Demands and Lead Times Using Deep Reinforcement Learning</b>
<a href="https://arxiv.org/abs/2201.04651">arxiv:2201.04651</a>
&#x1F4C8; 2 <br>
<p>Julio César Alves, Geraldo Robson Mateus</p></summary>
<p>

**Abstract:** We address the problem of production planning and distribution in multi-echelon supply chains. We consider uncertain demands and lead times which makes the problem stochastic and non-linear. A Markov Decision Process formulation and a Non-linear Programming model are presented. As a sequential decision-making problem, Deep Reinforcement Learning (RL) is a possible solution approach. This type of technique has gained a lot of attention from Artificial Intelligence and Optimization communities in recent years. Considering the good results obtained with Deep RL approaches in different areas there is a growing interest in applying them in problems from the Operations Research field. We have used a Deep RL technique, namely Proximal Policy Optimization (PPO2), to solve the problem considering uncertain, regular and seasonal demands and constant or stochastic lead times. Experiments are carried out in different scenarios to better assess the suitability of the algorithm. An agent based on a linearized model is used as a baseline. Experimental results indicate that PPO2 is a competitive and adequate tool for this type of problem. PPO2 agent is better than baseline in all scenarios with stochastic lead times (7.3-11.2%), regardless of whether demands are seasonal or not. In scenarios with constant lead times, the PPO2 agent is better when uncertain demands are non-seasonal (2.2-4.7%). The results show that the greater the uncertainty of the scenario, the greater the viability of this type of approach.

</p>
</details>

<details><summary><b>Agent-Temporal Attention for Reward Redistribution in Episodic Multi-Agent Reinforcement Learning</b>
<a href="https://arxiv.org/abs/2201.04612">arxiv:2201.04612</a>
&#x1F4C8; 2 <br>
<p>Baicen Xiao, Bhaskar Ramasubramanian, Radha Poovendran</p></summary>
<p>

**Abstract:** This paper considers multi-agent reinforcement learning (MARL) tasks where agents receive a shared global reward at the end of an episode. The delayed nature of this reward affects the ability of the agents to assess the quality of their actions at intermediate time-steps. This paper focuses on developing methods to learn a temporal redistribution of the episodic reward to obtain a dense reward signal. Solving such MARL problems requires addressing two challenges: identifying (1) relative importance of states along the length of an episode (along time), and (2) relative importance of individual agents' states at any single time-step (among agents). In this paper, we introduce Agent-Temporal Attention for Reward Redistribution in Episodic Multi-Agent Reinforcement Learning (AREL) to address these two challenges. AREL uses attention mechanisms to characterize the influence of actions on state transitions along trajectories (temporal attention), and how each agent is affected by other agents at each time-step (agent attention). The redistributed rewards predicted by AREL are dense, and can be integrated with any given MARL algorithm. We evaluate AREL on challenging tasks from the Particle World environment and the StarCraft Multi-Agent Challenge. AREL results in higher rewards in Particle World, and improved win rates in StarCraft compared to three state-of-the-art reward redistribution methods. Our code is available at https://github.com/baicenxiao/AREL.

</p>
</details>

<details><summary><b>Eigenvalue Distribution of Large Random Matrices Arising in Deep Neural Networks: Orthogonal Case</b>
<a href="https://arxiv.org/abs/2201.04543">arxiv:2201.04543</a>
&#x1F4C8; 2 <br>
<p>Leonid Pastur</p></summary>
<p>

**Abstract:** The paper deals with the distribution of singular values of the input-output Jacobian of deep untrained neural networks in the limit of their infinite width. The Jacobian is the product of random matrices where the independent rectangular weight matrices alternate with diagonal matrices whose entries depend on the corresponding column of the nearest neighbor weight matrix. The problem was considered in \cite{Pe-Co:18} for the Gaussian weights and biases and also for the weights that are Haar distributed orthogonal matrices and Gaussian biases. Basing on a free probability argument, it was claimed that in these cases the singular value distribution of the Jacobian in the limit of infinite width (matrix size) coincides with that of the analog of the Jacobian with special random but weight independent diagonal matrices, the case well known in random matrix theory. The claim was rigorously proved in \cite{Pa-Sl:21} for a quite general class of weights and biases with i.i.d. (including Gaussian) entries by using a version of the techniques of random matrix theory. In this paper we use another version of the techniques to justify the claim for random Haar distributed weight matrices and Gaussian biases.

</p>
</details>

<details><summary><b>Exact learning and test theory</b>
<a href="https://arxiv.org/abs/2201.04506">arxiv:2201.04506</a>
&#x1F4C8; 2 <br>
<p>Mikhail Moshkov</p></summary>
<p>

**Abstract:** In this paper, based on results of exact learning and test theory, we study arbitrary infinite binary information systems each of which consists of an infinite set of elements and an infinite set of two-valued functions (attributes) defined on the set of elements. We consider the notion of a problem over information system, which is described by a finite number of attributes: for a given element, we should recognize values of these attributes. As algorithms for problem solving, we consider decision trees of two types: (i) using only proper hypotheses (an analog of proper equivalence queries from exact learning), and (ii) using both attributes and proper hypotheses. As time complexity, we study the depth of decision trees. In the worst case, with the growth of the number of attributes in the problem description, the minimum depth of decision trees of both types either is bounded from above by a constant or grows as a logarithm, or linearly. Based on these results and results obtained earlier for attributes and arbitrary hypotheses, we divide the set of all infinite binary information systems into seven complexity classes.

</p>
</details>

<details><summary><b>Dyna-T: Dyna-Q and Upper Confidence Bounds Applied to Trees</b>
<a href="https://arxiv.org/abs/2201.04502">arxiv:2201.04502</a>
&#x1F4C8; 2 <br>
<p>Tarek Faycal, Claudio Zito</p></summary>
<p>

**Abstract:** In this work we present a preliminary investigation of a novel algorithm called Dyna-T. In reinforcement learning (RL) a planning agent has its own representation of the environment as a model. To discover an optimal policy to interact with the environment, the agent collects experience in a trial and error fashion. Experience can be used for learning a better model or improve directly the value function and policy. Typically separated, Dyna-Q is an hybrid approach which, at each iteration, exploits the real experience to update the model as well as the value function, while planning its action using simulated data from its model. However, the planning process is computationally expensive and strongly depends on the dimensionality of the state-action space. We propose to build a Upper Confidence Tree (UCT) on the simulated experience and search for the best action to be selected during the on-line learning process. We prove the effectiveness of our proposed method on a set of preliminary tests on three testbed environments from Open AI. In contrast to Dyna-Q, Dyna-T outperforms state-of-the-art RL agents in the stochastic environments by choosing a more robust action selection strategy.

</p>
</details>

<details><summary><b>Blackbox Post-Processing for Multiclass Fairness</b>
<a href="https://arxiv.org/abs/2201.04461">arxiv:2201.04461</a>
&#x1F4C8; 2 <br>
<p>Preston Putzel, Scott Lee</p></summary>
<p>

**Abstract:** Applying standard machine learning approaches for classification can produce unequal results across different demographic groups. When then used in real-world settings, these inequities can have negative societal impacts. This has motivated the development of various approaches to fair classification with machine learning models in recent years. In this paper, we consider the problem of modifying the predictions of a blackbox machine learning classifier in order to achieve fairness in a multiclass setting. To accomplish this, we extend the 'post-processing' approach in Hardt et al. 2016, which focuses on fairness for binary classification, to the setting of fair multiclass classification. We explore when our approach produces both fair and accurate predictions through systematic synthetic experiments and also evaluate discrimination-fairness tradeoffs on several publicly available real-world application datasets. We find that overall, our approach produces minor drops in accuracy and enforces fairness when the number of individuals in the dataset is high relative to the number of classes and protected groups.

</p>
</details>

<details><summary><b>RGRecSys: A Toolkit for Robustness Evaluation of Recommender Systems</b>
<a href="https://arxiv.org/abs/2201.04399">arxiv:2201.04399</a>
&#x1F4C8; 2 <br>
<p>Zohreh Ovaisi, Shelby Heinecke, Jia Li, Yongfeng Zhang, Elena Zheleva, Caiming Xiong</p></summary>
<p>

**Abstract:** Robust machine learning is an increasingly important topic that focuses on developing models resilient to various forms of imperfect data. Due to the pervasiveness of recommender systems in online technologies, researchers have carried out several robustness studies focusing on data sparsity and profile injection attacks. Instead, we propose a more holistic view of robustness for recommender systems that encompasses multiple dimensions - robustness with respect to sub-populations, transformations, distributional disparity, attack, and data sparsity. While there are several libraries that allow users to compare different recommender system models, there is no software library for comprehensive robustness evaluation of recommender system models under different scenarios. As our main contribution, we present a robustness evaluation toolkit, Robustness Gym for RecSys (RGRecSys -- https://www.github.com/salesforce/RGRecSys), that allows us to quickly and uniformly evaluate the robustness of recommender system models.

</p>
</details>

<details><summary><b>Knee Cartilage Defect Assessment by Graph Representation and Surface Convolution</b>
<a href="https://arxiv.org/abs/2201.04318">arxiv:2201.04318</a>
&#x1F4C8; 2 <br>
<p>Zixu Zhuang, Liping Si, Sheng Wang, Kai Xuan, Xi Ouyang, Yiqiang Zhan, Zhong Xue, Lichi Zhang, Dinggang Shen, Weiwu Yao, Qian Wang</p></summary>
<p>

**Abstract:** Knee osteoarthritis (OA) is the most common osteoarthritis and a leading cause of disability. Cartilage defects are regarded as major manifestations of knee OA, which are visible by magnetic resonance imaging (MRI). Thus early detection and assessment for knee cartilage defects are important for protecting patients from knee OA. In this way, many attempts have been made on knee cartilage defect assessment by applying convolutional neural networks (CNNs) to knee MRI. However, the physiologic characteristics of the cartilage may hinder such efforts: the cartilage is a thin curved layer, implying that only a small portion of voxels in knee MRI can contribute to the cartilage defect assessment; heterogeneous scanning protocols further challenge the feasibility of the CNNs in clinical practice; the CNN-based knee cartilage evaluation results lack interpretability. To address these challenges, we model the cartilages structure and appearance from knee MRI into a graph representation, which is capable of handling highly diverse clinical data. Then, guided by the cartilage graph representation, we design a non-Euclidean deep learning network with the self-attention mechanism, to extract cartilage features in the local and global, and to derive the final assessment with a visualized result. Our comprehensive experiments show that the proposed method yields superior performance in knee cartilage defect assessment, plus its convenient 3D visualization for interpretability.

</p>
</details>

<details><summary><b>Adaptive Worker Grouping For Communication-Efficient and Straggler-Tolerant Distributed SGD</b>
<a href="https://arxiv.org/abs/2201.04301">arxiv:2201.04301</a>
&#x1F4C8; 2 <br>
<p>Feng Zhu, Jingjing Zhang, Osvaldo Simeone, Xin Wang</p></summary>
<p>

**Abstract:** Wall-clock convergence time and communication load are key performance metrics for the distributed implementation of stochastic gradient descent (SGD) in parameter server settings. Communication-adaptive distributed Adam (CADA) has been recently proposed as a way to reduce communication load via the adaptive selection of workers. CADA is subject to performance degradation in terms of wall-clock convergence time in the presence of stragglers. This paper proposes a novel scheme named grouping-based CADA (G-CADA) that retains the advantages of CADA in reducing the communication load, while increasing the robustness to stragglers at the cost of additional storage at the workers. G-CADA partitions the workers into groups of workers that are assigned the same data shards. Groups are scheduled adaptively at each iteration, and the server only waits for the fastest worker in each selected group. We provide analysis and experimental results to elaborate the significant gains on the wall-clock time, as well as communication load and computation load, of G-CADA over other benchmark schemes.

</p>
</details>

<details><summary><b>Data augmentation through multivariate scenario forecasting in Data Centers using Generative Adversarial Networks</b>
<a href="https://arxiv.org/abs/2201.06147">arxiv:2201.06147</a>
&#x1F4C8; 1 <br>
<p>Jaime Pérez, Patricia Arroba, José M. Moya</p></summary>
<p>

**Abstract:** The Cloud paradigm is at a critical point in which the existing energy-efficiency techniques are reaching a plateau, while the computing resources demand at Data Center facilities continues to increase exponentially. The main challenge in achieving a global energy efficiency strategy based on Artificial Intelligence is that we need massive amounts of data to feed the algorithms. Nowadays, any optimization strategy must begin with data. However, companies with access to these large amounts of data decide not to share them because it could compromise their security. This paper proposes a time-series data augmentation methodology based on synthetic scenario forecasting within the Data Center. For this purpose, we will implement a powerful generative algorithm: Generative Adversarial Networks (GANs). The use of GANs will allow us to handle multivariate data and data from different natures (e.g., categorical). On the other hand, adapting Data Centers' operational management to the occurrence of sporadic anomalies is complicated due to the reduced frequency of failures in the system. Therefore, we also propose a methodology to increase the generated data variability by introducing on-demand anomalies. We validated our approach using real data collected from an operating Data Center, successfully obtaining forecasts of random scenarios with several hours of prediction. Our research will help to optimize the energy consumed in Data Centers, although the proposed methodology can be employed in any similar time-series-like problem.

</p>
</details>

<details><summary><b>Fast and accurate waveform modeling of long-haul multi-channel optical fiber transmission using a hybrid model-data driven scheme</b>
<a href="https://arxiv.org/abs/2201.05502">arxiv:2201.05502</a>
&#x1F4C8; 1 <br>
<p>Hang Yang, Zekun Niu, Haochen Zhao, Shilin Xiao, Weisheng Hu, Lilin Yi</p></summary>
<p>

**Abstract:** The modeling of optical wave propagation in optical fiber is a task of fast and accurate solving the nonlinear Schrödinger equation (NLSE), and can enable the optical system design, digital signal processing verification and fast waveform calculation. Traditional waveform modeling of full-time and full-frequency information is the split-step Fourier method (SSFM), which has long been regarded as challenging in long-haul wavelength division multiplexing (WDM) optical fiber communication systems because it is extremely time-consuming. Here we propose a linear-nonlinear feature decoupling distributed (FDD) waveform modeling scheme to model long-haul WDM fiber channel, where the channel linear effects are modelled by the NLSE-derived model-driven methods and the nonlinear effects are modelled by the data-driven deep learning methods. Meanwhile, the proposed scheme only focuses on one-span fiber distance fitting, and then recursively transmits the model to achieve the required transmission distance. The proposed modeling scheme is demonstrated to have high accuracy, high computing speeds, and robust generalization abilities for different optical launch powers, modulation formats, channel numbers and transmission distances. The total running time of FDD waveform modeling scheme for 41-channel 1040-km fiber transmission is only 3 minutes versus more than 2 hours using SSFM for each input condition, which achieves a 98% reduction in computing time. Considering the multi-round optimization by adjusting system parameters, the complexity reduction is significant. The results represent a remarkable improvement in nonlinear fiber modeling and open up novel perspectives for solution of NLSE-like partial differential equations and optical fiber physics problems.

</p>
</details>

<details><summary><b>Smoothness and continuity of cost functionals for ECG mismatch computation</b>
<a href="https://arxiv.org/abs/2201.04487">arxiv:2201.04487</a>
&#x1F4C8; 1 <br>
<p>Thomas Grandits, Simone Pezzuto, Gernot Plank</p></summary>
<p>

**Abstract:** The field of cardiac electrophysiology tries to abstract, describe and finally model the electrical characteristics of a heartbeat. With recent advances in cardiac electrophysiology, models have become more powerful and descriptive as ever. However, to advance to the field of inverse electrophysiological modeling, i.e. creating models from electrical measurements such as the ECG, the less investigated field of smoothness of the simulated ECGs w.r.t. model parameters need to be further explored. The present paper discusses smoothness in terms of the whole pipeline which describes how from physiological parameters, we arrive at the simulated ECG. Employing such a pipeline, we create a test-bench of a simplified idealized left ventricle model and demonstrate the most important factors for efficient inverse modeling through smooth cost functionals. Such knowledge will be important for designing and creating inverse models in future optimization and machine learning methods.

</p>
</details>

<details><summary><b>Detecting Ransomware Execution in a Timely Manner</b>
<a href="https://arxiv.org/abs/2201.04424">arxiv:2201.04424</a>
&#x1F4C8; 1 <br>
<p>Anthony Melaragno, William Casey</p></summary>
<p>

**Abstract:** Ransomware has been an ongoing issue since the early 1990s. In recent times ransomware has spread from traditional computational resources to cyber-physical systems and industrial controls. We devised a series of experiments in which virtual instances are infected with ransomware. We instrumented the instances and collected resource utilization data across a variety of metrics (CPU, Memory, Disk Utility). We design a change point detection and learning method for identifying ransomware execution. Finally we evaluate and demonstrate its ability to detect ransomware efficiently in a timely manner when trained on a minimal set of samples. Our results represent a step forward for defense, and we conclude with further remarks for the path forward.

</p>
</details>

<details><summary><b>De-Noising of Photoacoustic Microscopy Images by Deep Learning</b>
<a href="https://arxiv.org/abs/2201.04302">arxiv:2201.04302</a>
&#x1F4C8; 1 <br>
<p>Da He, Jiasheng Zhou, Xiaoyu Shang, Jiajia Luo, Sung-Liang Chen</p></summary>
<p>

**Abstract:** As a hybrid imaging technology, photoacoustic microscopy (PAM) imaging suffers from noise due to the maximum permissible exposure of laser intensity, attenuation of ultrasound in the tissue, and the inherent noise of the transducer. De-noising is a post-processing method to reduce noise, and PAM image quality can be recovered. However, previous de-noising techniques usually heavily rely on mathematical priors as well as manually selected parameters, resulting in unsatisfactory and slow de-noising performance for different noisy images, which greatly hinders practical and clinical applications. In this work, we propose a deep learning-based method to remove complex noise from PAM images without mathematical priors and manual selection of settings for different input images. An attention enhanced generative adversarial network is used to extract image features and remove various noises. The proposed method is demonstrated on both synthetic and real datasets, including phantom (leaf veins) and in vivo (mouse ear blood vessels and zebrafish pigment) experiments. The results show that compared with previous PAM de-noising methods, our method exhibits good performance in recovering images qualitatively and quantitatively. In addition, the de-noising speed of 0.016 s is achieved for an image with $256\times256$ pixels. Our approach is effective and practical for the de-noising of PAM images.

</p>
</details>

<details><summary><b>PyHHMM: A Python Library for Heterogeneous Hidden Markov Models</b>
<a href="https://arxiv.org/abs/2201.06968">arxiv:2201.06968</a>
&#x1F4C8; 0 <br>
<p>Fernando Moreno-Pino, Emese Sükei, Pablo M. Olmos, Antonio Artés-Rodríguez</p></summary>
<p>

**Abstract:** We introduce PyHHMM, an object-oriented open-source Python implementation of Heterogeneous-Hidden Markov Models (HHMMs). In addition to HMM's basic core functionalities, such as different initialization algorithms and classical observations models, i.e., continuous and multinoulli, PyHHMM distinctively emphasizes features not supported in similar available frameworks: a heterogeneous observation model, missing data inference, different model order selection criterias, and semi-supervised training. These characteristics result in a feature-rich implementation for researchers working with sequential data. PyHHMM relies on the numpy, scipy, scikit-learn, and seaborn Python packages, and is distributed under the Apache-2.0 License. PyHHMM's source code is publicly available on Github (https://github.com/fmorenopino/HeterogeneousHMM) to facilitate adoptions and future contributions. A detailed documentation (https://pyhhmm.readthedocs.io/en/latest), which covers examples of use and models' theoretical explanation, is available. The package can be installed through the Python Package Index (PyPI), via 'pip install pyhhmm'.

</p>
</details>

<details><summary><b>Proceedings of the 4th Workshop on Online Recommender Systems and User Modeling -- ORSUM 2021</b>
<a href="https://arxiv.org/abs/2201.05156">arxiv:2201.05156</a>
&#x1F4C8; 0 <br>
<p>João Vinagre, Alípio Mário Jorge, Marie Al-Ghossein, Albert Bifet</p></summary>
<p>

**Abstract:** Modern online services continuously generate data at very fast rates. This continuous flow of data encompasses content - e.g., posts, news, products, comments -, but also user feedback - e.g., ratings, views, reads, clicks -, together with context data - user device, spatial or temporal data, user task or activity, weather. This can be overwhelming for systems and algorithms designed to train in batches, given the continuous and potentially fast change of content, context and user preferences or intents. Therefore, it is important to investigate online methods able to transparently adapt to the inherent dynamics of online services. Incremental models that learn from data streams are gaining attention in the recommender systems community, given their natural ability to deal with the continuous flows of data generated in dynamic, complex environments. User modeling and personalization can particularly benefit from algorithms capable of maintaining models incrementally and online.
  The objective of this workshop is to foster contributions and bring together a growing community of researchers and practitioners interested in online, adaptive approaches to user modeling, recommendation and personalization, and their implications regarding multiple dimensions, such as evaluation, reproducibility, privacy and explainability.

</p>
</details>

<details><summary><b>Planning in Observable POMDPs in Quasipolynomial Time</b>
<a href="https://arxiv.org/abs/2201.04735">arxiv:2201.04735</a>
&#x1F4C8; 0 <br>
<p>Noah Golowich, Ankur Moitra, Dhruv Rohatgi</p></summary>
<p>

**Abstract:** Partially Observable Markov Decision Processes (POMDPs) are a natural and general model in reinforcement learning that take into account the agent's uncertainty about its current state. In the literature on POMDPs, it is customary to assume access to a planning oracle that computes an optimal policy when the parameters are known, even though the problem is known to be computationally hard. Almost all existing planning algorithms either run in exponential time, lack provable performance guarantees, or require placing strong assumptions on the transition dynamics under every possible policy. In this work, we revisit the planning problem and ask: are there natural and well-motivated assumptions that make planning easy?
  Our main result is a quasipolynomial-time algorithm for planning in (one-step) observable POMDPs. Specifically, we assume that well-separated distributions on states lead to well-separated distributions on observations, and thus the observations are at least somewhat informative in each step. Crucially, this assumption places no restrictions on the transition dynamics of the POMDP; nevertheless, it implies that near-optimal policies admit quasi-succinct descriptions, which is not true in general (under standard hardness assumptions). Our analysis is based on new quantitative bounds for filter stability -- i.e. the rate at which an optimal filter for the latent state forgets its initialization. Furthermore, we prove matching hardness for planning in observable POMDPs under the Exponential Time Hypothesis.

</p>
</details>

<details><summary><b>Human Evaluation of Conversations is an Open Problem: comparing the sensitivity of various methods for evaluating dialogue agents</b>
<a href="https://arxiv.org/abs/2201.04723">arxiv:2201.04723</a>
&#x1F4C8; 0 <br>
<p>Eric Michael Smith, Orion Hsu, Rebecca Qian, Stephen Roller, Y-Lan Boureau, Jason Weston</p></summary>
<p>

**Abstract:** At the heart of improving conversational AI is the open problem of how to evaluate conversations. Issues with automatic metrics are well known (Liu et al., 2016, arXiv:1603.08023), with human evaluations still considered the gold standard. Unfortunately, how to perform human evaluations is also an open problem: differing data collection methods have varying levels of human agreement and statistical sensitivity, resulting in differing amounts of human annotation hours and labor costs. In this work we compare five different crowdworker-based human evaluation methods and find that different methods are best depending on the types of models compared, with no clear winner across the board. While this highlights the open problems in the area, our analysis leads to advice of when to use which one, and possible future directions.

</p>
</details>

<details><summary><b>On the Statistical Complexity of Sample Amplification</b>
<a href="https://arxiv.org/abs/2201.04315">arxiv:2201.04315</a>
&#x1F4C8; 0 <br>
<p>Brian Axelrod, Shivam Garg, Yanjun Han, Vatsal Sharan, Gregory Valiant</p></summary>
<p>

**Abstract:** Given $n$ i.i.d. samples drawn from an unknown distribution $P$, when is it possible to produce a larger set of $n+m$ samples which cannot be distinguished from $n+m$ i.i.d. samples drawn from $P$? (Axelrod et al. 2019) formalized this question as the sample amplification problem, and gave optimal amplification procedures for discrete distributions and Gaussian location models. However, these procedures and associated lower bounds are tailored to the specific distribution classes, and a general statistical understanding of sample amplification is still largely missing. In this work, we place the sample amplification problem on a firm statistical foundation by deriving generally applicable amplification procedures, lower bound techniques and connections to existing statistical notions. Our techniques apply to a large class of distributions including the exponential family, and establish a rigorous connection between sample amplification and distribution learning.

</p>
</details>


{% endraw %}
Prev: [2022.01.11]({{ '/2022/01/11/2022.01.11.html' | relative_url }})  Next: [2022.01.13]({{ '/2022/01/13/2022.01.13.html' | relative_url }})