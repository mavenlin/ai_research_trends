## Summary for 2021-10-22, created on 2021-12-14


<details><summary><b>The Equilibrium Hypothesis: Rethinking implicit regularization in Deep Neural Networks</b>
<a href="https://arxiv.org/abs/2110.11749">arxiv:2110.11749</a>
&#x1F4C8; 74 <br>
<p>Yizhang Lou, Chris Mingard, Soufiane Hayou</p></summary>
<p>

**Abstract:** Modern Deep Neural Networks (DNNs) exhibit impressive generalization properties on a variety of tasks without explicit regularization, suggesting the existence of hidden regularization effects. Recent work by Baratin et al. (2021) sheds light on an intriguing implicit regularization effect, showing that some layers are much more aligned with data labels than other layers. This suggests that as the network grows in depth and width, an implicit layer selection phenomenon occurs during training. In this work, we provide the first explanation for this alignment hierarchy. We introduce and empirically validate the Equilibrium Hypothesis which states that the layers that achieve some balance between forward and backward information loss are the ones with the highest alignment to data labels. Our experiments demonstrate an excellent match with the theoretical predictions.

</p>
</details>

<details><summary><b>On the Tractability of Neural Causal Inference</b>
<a href="https://arxiv.org/abs/2110.12052">arxiv:2110.12052</a>
&#x1F4C8; 22 <br>
<p>Matej Zečević, Devendra Singh Dhami, Kristian Kersting</p></summary>
<p>

**Abstract:** Roth (1996) proved that any form of marginal inference with probabilistic graphical models (e.g. Bayesian Networks) will at least be NP-hard. Introduced and extensively investigated in the past decade, the neural probabilistic circuits known as sum-product network (SPN) offers linear time complexity. On another note, research around neural causal models (NCM) recently gained traction, demanding a tighter integration of causality for machine learning. To this end, we present a theoretical investigation of if, when, how and under what cost tractability occurs for different NCM. We prove that SPN-based causal inference is generally tractable, opposed to standard MLP-based NCM. We further introduce a new tractable NCM-class that is efficient in inference and fully expressive in terms of Pearl's Causal Hierarchy. Our comparative empirical illustration on simulations and standard benchmarks validates our theoretical proofs.

</p>
</details>

<details><summary><b>Why Machine Learning Cannot Ignore Maximum Likelihood Estimation</b>
<a href="https://arxiv.org/abs/2110.12112">arxiv:2110.12112</a>
&#x1F4C8; 15 <br>
<p>Mark J. van der Laan, Sherri Rose</p></summary>
<p>

**Abstract:** The growth of machine learning as a field has been accelerating with increasing interest and publications across fields, including statistics, but predominantly in computer science. How can we parse this vast literature for developments that exemplify the necessary rigor? How many of these manuscripts incorporate foundational theory to allow for statistical inference? Which advances have the greatest potential for impact in practice? One could posit many answers to these queries. Here, we assert that one essential idea is for machine learning to integrate maximum likelihood for estimation of functional parameters, such as prediction functions and conditional densities.

</p>
</details>

<details><summary><b>The Causal Loss: Driving Correlation to Imply Causation</b>
<a href="https://arxiv.org/abs/2110.12066">arxiv:2110.12066</a>
&#x1F4C8; 14 <br>
<p>Moritz Willig, Matej Zečević, Devendra Singh Dhami, Kristian Kersting</p></summary>
<p>

**Abstract:** Most algorithms in classical and contemporary machine learning focus on correlation-based dependence between features to drive performance. Although success has been observed in many relevant problems, these algorithms fail when the underlying causality is inconsistent with the assumed relations. We propose a novel model-agnostic loss function called Causal Loss that improves the interventional quality of the prediction using an intervened neural-causal regularizer. In support of our theoretical results, our experimental illustration shows how causal loss bestows a non-causal associative model (like a standard neural net or decision tree) with interventional capabilities.

</p>
</details>

<details><summary><b>Multi-view Contrastive Graph Clustering</b>
<a href="https://arxiv.org/abs/2110.11842">arxiv:2110.11842</a>
&#x1F4C8; 14 <br>
<p>Erlin Pan, Zhao Kang</p></summary>
<p>

**Abstract:** With the explosive growth of information technology, multi-view graph data have become increasingly prevalent and valuable. Most existing multi-view clustering techniques either focus on the scenario of multiple graphs or multi-view attributes. In this paper, we propose a generic framework to cluster multi-view attributed graph data. Specifically, inspired by the success of contrastive learning, we propose multi-view contrastive graph clustering (MCGC) method to learn a consensus graph since the original graph could be noisy or incomplete and is not directly applicable. Our method composes of two key steps: we first filter out the undesirable high-frequency noise while preserving the graph geometric features via graph filtering and obtain a smooth representation of nodes; we then learn a consensus graph regularized by graph contrastive loss. Results on several benchmark datasets show the superiority of our method with respect to state-of-the-art approaches. In particular, our simple approach outperforms existing deep learning-based methods.

</p>
</details>

<details><summary><b>High Fidelity 3D Reconstructions with Limited Physical Views</b>
<a href="https://arxiv.org/abs/2110.11599">arxiv:2110.11599</a>
&#x1F4C8; 10 <br>
<p>Mosam Dabhi, Chaoyang Wang, Kunal Saluja, Laszlo Jeni, Ian Fasel, Simon Lucey</p></summary>
<p>

**Abstract:** Multi-view triangulation is the gold standard for 3D reconstruction from 2D correspondences given known calibration and sufficient views. However in practice, expensive multi-view setups -- involving tens sometimes hundreds of cameras -- are required in order to obtain the high fidelity 3D reconstructions necessary for many modern applications. In this paper we present a novel approach that leverages recent advances in 2D-3D lifting using neural shape priors while also enforcing multi-view equivariance. We show how our method can achieve comparable fidelity to expensive calibrated multi-view rigs using a limited (2-3) number of uncalibrated camera views.

</p>
</details>

<details><summary><b>Sinkformers: Transformers with Doubly Stochastic Attention</b>
<a href="https://arxiv.org/abs/2110.11773">arxiv:2110.11773</a>
&#x1F4C8; 8 <br>
<p>Michael E. Sander, Pierre Ablin, Mathieu Blondel, Gabriel Peyré</p></summary>
<p>

**Abstract:** Attention based models such as Transformers involve pairwise interactions between data points, modeled with a learnable attention matrix. Importantly, this attention matrix is normalized with the SoftMax operator, which makes it row-wise stochastic. In this paper, we propose instead to use Sinkhorn's algorithm to make attention matrices doubly stochastic. We call the resulting model a Sinkformer. We show that the row-wise stochastic attention matrices in classical Transformers get close to doubly stochastic matrices as the number of epochs increases, justifying the use of Sinkhorn normalization as an informative prior. On the theoretical side, we show that, unlike the SoftMax operation, this normalization makes it possible to understand the iterations of self-attention modules as a discretized gradient-flow for the Wasserstein metric. We also show in the infinite number of samples limit that, when rescaling both attention matrices and depth, Sinkformers operate a heat diffusion. On the experimental side, we show that Sinkformers enhance model accuracy in vision and natural language processing tasks. In particular, on 3D shapes classification, Sinkformers lead to a significant improvement.

</p>
</details>

<details><summary><b>SciCap: Generating Captions for Scientific Figures</b>
<a href="https://arxiv.org/abs/2110.11624">arxiv:2110.11624</a>
&#x1F4C8; 8 <br>
<p>Ting-Yao Hsu, C. Lee Giles, Ting-Hao 'Kenneth' Huang</p></summary>
<p>

**Abstract:** Researchers use figures to communicate rich, complex information in scientific papers. The captions of these figures are critical to conveying effective messages. However, low-quality figure captions commonly occur in scientific articles and may decrease understanding. In this paper, we propose an end-to-end neural framework to automatically generate informative, high-quality captions for scientific figures. To this end, we introduce SCICAP, a large-scale figure-caption dataset based on computer science arXiv papers published between 2010 and 2020. After pre-processing - including figure-type classification, sub-figure identification, text normalization, and caption text selection - SCICAP contained more than two million figures extracted from over 290,000 papers. We then established baseline models that caption graph plots, the dominant (19.2%) figure type. The experimental results showed both opportunities and steep challenges of generating captions for scientific figures.

</p>
</details>

<details><summary><b>Explainable Landscape-Aware Optimization Performance Prediction</b>
<a href="https://arxiv.org/abs/2110.11633">arxiv:2110.11633</a>
&#x1F4C8; 7 <br>
<p>Risto Trajanov, Stefan Dimeski, Martin Popovski, Peter Korošec, Tome Eftimov</p></summary>
<p>

**Abstract:** Efficient solving of an unseen optimization problem is related to appropriate selection of an optimization algorithm and its hyper-parameters. For this purpose, automated algorithm performance prediction should be performed that in most commonly-applied practices involves training a supervised ML algorithm using a set of problem landscape features. However, the main issue of training such models is their limited explainability since they only provide information about the joint impact of the set of landscape features to the end prediction results. In this study, we are investigating explainable landscape-aware regression models where the contribution of each landscape feature to the prediction of the optimization algorithm performance is estimated on a global and local level. The global level provides information about the impact of the feature across all benchmark problems' instances, while the local level provides information about the impact on a specific problem instance. The experimental results are obtained using the COCO benchmark problems and three differently configured modular CMA-ESs. The results show a proof of concept that different set of features are important for different problem instances, which indicates that further personalization of the landscape space is required when training an automated algorithm performance prediction model.

</p>
</details>

<details><summary><b>Learning Proposals for Practical Energy-Based Regression</b>
<a href="https://arxiv.org/abs/2110.11948">arxiv:2110.11948</a>
&#x1F4C8; 6 <br>
<p>Fredrik K. Gustafsson, Martin Danelljan, Thomas B. Schön</p></summary>
<p>

**Abstract:** Energy-based models (EBMs) have experienced a resurgence within machine learning in recent years, including as a promising alternative for probabilistic regression. However, energy-based regression requires a proposal distribution to be manually designed for training, and an initial estimate has to be provided at test-time. We address both of these issues by introducing a conceptually simple method to automatically learn an effective proposal distribution, which is parameterized by a separate network head. To this end, we derive a surprising result, leading to a unified training objective that jointly minimizes the KL divergence from the proposal to the EBM, and the negative log-likelihood of the EBM. At test-time, we can then employ importance sampling with the trained proposal to efficiently evaluate the learned EBM and produce stand-alone predictions. Furthermore, we utilize our derived training objective to learn mixture density networks (MDNs) with a jointly trained energy-based teacher, consistently outperforming conventional MDN training on four real-world regression tasks within computer vision. Code is available at https://github.com/fregu856/ebms_proposals.

</p>
</details>

<details><summary><b>Forecasting Financial Market Structure from Network Features using Machine Learning</b>
<a href="https://arxiv.org/abs/2110.11751">arxiv:2110.11751</a>
&#x1F4C8; 6 <br>
<p>Douglas Castilho, Tharsis T. P. Souza, Soong Moon Kang, João Gama, André C. P. L. F. de Carvalho</p></summary>
<p>

**Abstract:** We propose a model that forecasts market correlation structure from link- and node-based financial network features using machine learning. For such, market structure is modeled as a dynamic asset network by quantifying time-dependent co-movement of asset price returns across company constituents of major global market indices. We provide empirical evidence using three different network filtering methods to estimate market structure, namely Dynamic Asset Graph (DAG), Dynamic Minimal Spanning Tree (DMST) and Dynamic Threshold Networks (DTN). Experimental results show that the proposed model can forecast market structure with high predictive performance with up to $40\%$ improvement over a time-invariant correlation-based benchmark. Non-pair-wise correlation features showed to be important compared to traditionally used pair-wise correlation measures for all markets studied, particularly in the long-term forecasting of stock market structure. Evidence is provided for stock constituents of the DAX30, EUROSTOXX50, FTSE100, HANGSENG50, NASDAQ100 and NIFTY50 market indices. Findings can be useful to improve portfolio selection and risk management methods, which commonly rely on a backward-looking covariance matrix to estimate portfolio risk.

</p>
</details>

<details><summary><b>Circle Representation for Medical Object Detection</b>
<a href="https://arxiv.org/abs/2110.12093">arxiv:2110.12093</a>
&#x1F4C8; 5 <br>
<p>Ethan H. Nguyen, Haichun Yang, Ruining Deng, Yuzhe Lu, Zheyu Zhu, Joseph T. Roland, Le Lu, Bennett A. Landman, Agnes B. Fogo, Yuankai Huo</p></summary>
<p>

**Abstract:** Box representation has been extensively used for object detection in computer vision. Such representation is efficacious but not necessarily optimized for biomedical objects (e.g., glomeruli), which play an essential role in renal pathology. In this paper, we propose a simple circle representation for medical object detection and introduce CircleNet, an anchor-free detection framework. Compared with the conventional bounding box representation, the proposed bounding circle representation innovates in three-fold: (1) it is optimized for ball-shaped biomedical objects; (2) The circle representation reduced the degree of freedom compared with box representation; (3) It is naturally more rotation invariant. When detecting glomeruli and nuclei on pathological images, the proposed circle representation achieved superior detection performance and be more rotation-invariant, compared with the bounding box. The code has been made publicly available: https://github.com/hrlblab/CircleNet

</p>
</details>

<details><summary><b>Fairness in Missing Data Imputation</b>
<a href="https://arxiv.org/abs/2110.12002">arxiv:2110.12002</a>
&#x1F4C8; 5 <br>
<p>Yiliang Zhang, Qi Long</p></summary>
<p>

**Abstract:** Missing data are ubiquitous in the era of big data and, if inadequately handled, are known to lead to biased findings and have deleterious impact on data-driven decision makings. To mitigate its impact, many missing value imputation methods have been developed. However, the fairness of these imputation methods across sensitive groups has not been studied. In this paper, we conduct the first known research on fairness of missing data imputation. By studying the performance of imputation methods in three commonly used datasets, we demonstrate that unfairness of missing value imputation widely exists and may be associated with multiple factors. Our results suggest that, in practice, a careful investigation of related factors can provide valuable insights on mitigating unfairness associated with missing data imputation.

</p>
</details>

<details><summary><b>AIR-Nets: An Attention-Based Framework for Locally Conditioned Implicit Representations</b>
<a href="https://arxiv.org/abs/2110.11860">arxiv:2110.11860</a>
&#x1F4C8; 5 <br>
<p>Simon Giebenhain, Bastian Goldlücke</p></summary>
<p>

**Abstract:** This paper introduces Attentive Implicit Representation Networks (AIR-Nets), a simple, but highly effective architecture for 3D reconstruction from point clouds. Since representing 3D shapes in a local and modular fashion increases generalization and reconstruction quality, AIR-Nets encode an input point cloud into a set of local latent vectors anchored in 3D space, which locally describe the object's geometry, as well as a global latent description, enforcing global consistency. Our model is the first grid-free, encoder-based approach that locally describes an implicit function. The vector attention mechanism from [Zhao et al. 2020] serves as main point cloud processing module, and allows for permutation invariance and translation equivariance. When queried with a 3D coordinate, our decoder gathers information from the global and nearby local latent vectors in order to predict an occupancy value. Experiments on the ShapeNet dataset show that AIR-Nets significantly outperform previous state-of-the-art encoder-based, implicit shape learning methods and especially dominate in the sparse setting. Furthermore, our model generalizes well to the FAUST dataset in a zero-shot setting. Finally, since AIR-Nets use a sparse latent representation and follow a simple operating scheme, the model offers several exiting avenues for future work. Our code is available at https://github.com/SimonGiebenhain/AIR-Nets.

</p>
</details>

<details><summary><b>Model, sample, and epoch-wise descents: exact solution of gradient flow in the random feature model</b>
<a href="https://arxiv.org/abs/2110.11805">arxiv:2110.11805</a>
&#x1F4C8; 5 <br>
<p>Antoine Bodin, Nicolas Macris</p></summary>
<p>

**Abstract:** Recent evidence has shown the existence of a so-called double-descent and even triple-descent behavior for the generalization error of deep-learning models. This important phenomenon commonly appears in implemented neural network architectures, and also seems to emerge in epoch-wise curves during the training process. A recent line of research has highlighted that random matrix tools can be used to obtain precise analytical asymptotics of the generalization (and training) errors of the random feature model. In this contribution, we analyze the whole temporal behavior of the generalization and training errors under gradient flow for the random feature model. We show that in the asymptotic limit of large system size the full time-evolution path of both errors can be calculated analytically. This allows us to observe how the double and triple descents develop over time, if and when early stopping is an option, and also observe time-wise descent structures. Our techniques are based on Cauchy complex integral representations of the errors together with recent random matrix methods based on linear pencils.

</p>
</details>

<details><summary><b>Few-shot Semantic Segmentation with Self-supervision from Pseudo-classes</b>
<a href="https://arxiv.org/abs/2110.11742">arxiv:2110.11742</a>
&#x1F4C8; 5 <br>
<p>Yiwen Li, Gratianus Wesley Putra Data, Yunguan Fu, Yipeng Hu, Victor Adrian Prisacariu</p></summary>
<p>

**Abstract:** Despite the success of deep learning methods for semantic segmentation, few-shot semantic segmentation remains a challenging task due to the limited training data and the generalisation requirement for unseen classes. While recent progress has been particularly encouraging, we discover that existing methods tend to have poor performance in terms of meanIoU when query images contain other semantic classes besides the target class. To address this issue, we propose a novel self-supervised task that generates random pseudo-classes in the background of the query images, providing extra training data that would otherwise be unavailable when predicting individual target classes. To that end, we adopted superpixel segmentation for generating the pseudo-classes. With this extra supervision, we improved the meanIoU performance of the state-of-the-art method by 2.5% and 5.1% on the one-shot tasks, as well as 6.7% and 4.4% on the five-shot tasks, on the PASCAL-5i and COCO benchmarks, respectively.

</p>
</details>

<details><summary><b>Multimodal-Boost: Multimodal Medical Image Super-Resolution using Multi-Attention Network with Wavelet Transform</b>
<a href="https://arxiv.org/abs/2110.11684">arxiv:2110.11684</a>
&#x1F4C8; 5 <br>
<p>Farah Deeba, Fayaz Ali Dharejo, Muhammad Zawish, Yuanchun Zhou, Kapal Dev, Sunder Ali Khowaja, Nawab Muhammad Faseeh Qureshi</p></summary>
<p>

**Abstract:** Multimodal medical images are widely used by clinicians and physicians to analyze and retrieve complementary information from high-resolution images in a non-invasive manner. The loss of corresponding image resolution degrades the overall performance of medical image diagnosis. Deep learning based single image super resolution (SISR) algorithms has revolutionized the overall diagnosis framework by continually improving the architectural components and training strategies associated with convolutional neural networks (CNN) on low-resolution images. However, existing work lacks in two ways: i) the SR output produced exhibits poor texture details, and often produce blurred edges, ii) most of the models have been developed for a single modality, hence, require modification to adapt to a new one. This work addresses (i) by proposing generative adversarial network (GAN) with deep multi-attention modules to learn high-frequency information from low-frequency data. Existing approaches based on the GAN have yielded good SR results; however, the texture details of their SR output have been experimentally confirmed to be deficient for medical images particularly. The integration of wavelet transform (WT) and GANs in our proposed SR model addresses the aforementioned limitation concerning textons. The WT divides the LR image into multiple frequency bands, while the transferred GAN utilizes multiple attention and upsample blocks to predict high-frequency components. Moreover, we present a learning technique for training a domain-specific classifier as a perceptual loss function. Combining multi-attention GAN loss with a perceptual loss function results in a reliable and efficient performance. Applying the same model for medical images from diverse modalities is challenging, our work addresses (ii) by training and performing on several modalities via transfer learning.

</p>
</details>

<details><summary><b>Automatic Detection of Injection and Press Mold Parts on 2D Drawing Using Deep Neural Network</b>
<a href="https://arxiv.org/abs/2110.11593">arxiv:2110.11593</a>
&#x1F4C8; 5 <br>
<p>Junseok Lee, Jongwon Kim, Jumi Park, Seunghyeok Back, Seongho Bak, Kyoobin Lee</p></summary>
<p>

**Abstract:** This paper proposes a method to automatically detect the key feature parts in a CAD of commercial TV and monitor using a deep neural network. We developed a deep learning pipeline that can detect the injection parts such as hook, boss, undercut and press parts such as DPS, Embo-Screwless, Embo-Burring, and EMBO in the 2D CAD drawing images. We first cropped the drawing to a specific size for the training efficiency of a deep neural network. Then, we use Cascade R-CNN to find the position of injection and press parts and use Resnet-50 to predict the orientation of the parts. Finally, we convert the position of the parts found through the cropped image to the position of the original image. As a result, we obtained detection accuracy of injection and press parts with 84.1% in AP (Average Precision), 91.2% in AR(Average Recall), 72.0% in AP, 87.0% in AR, and orientation accuracy of injection and press parts with 94.4% and 92.0%, which can facilitate the faster design in industrial product design.

</p>
</details>

<details><summary><b>Towards the D-Optimal Online Experiment Design for Recommender Selection</b>
<a href="https://arxiv.org/abs/2110.12132">arxiv:2110.12132</a>
&#x1F4C8; 4 <br>
<p>Da Xu, Chuanwei Ruan, Evren Korpeoglu, Sushant Kumar, Kannan Achan</p></summary>
<p>

**Abstract:** Selecting the optimal recommender via online exploration-exploitation is catching increasing attention where the traditional A/B testing can be slow and costly, and offline evaluations are prone to the bias of history data. Finding the optimal online experiment is nontrivial since both the users and displayed recommendations carry contextual features that are informative to the reward. While the problem can be formalized via the lens of multi-armed bandits, the existing solutions are found less satisfactorily because the general methodologies do not account for the case-specific structures, particularly for the e-commerce recommendation we study. To fill in the gap, we leverage the \emph{D-optimal design} from the classical statistics literature to achieve the maximum information gain during exploration, and reveal how it fits seamlessly with the modern infrastructure of online inference. To demonstrate the effectiveness of the optimal designs, we provide semi-synthetic simulation studies with published code and data for reproducibility purposes. We then use our deployment example on Walmart.com to fully illustrate the practical insights and effectiveness of the proposed methods.

</p>
</details>

<details><summary><b>A Prototype-Oriented Framework for Unsupervised Domain Adaptation</b>
<a href="https://arxiv.org/abs/2110.12024">arxiv:2110.12024</a>
&#x1F4C8; 4 <br>
<p>Korawat Tanwisuth, Xinjie Fan, Huangjie Zheng, Shujian Zhang, Hao Zhang, Bo Chen, Mingyuan Zhou</p></summary>
<p>

**Abstract:** Existing methods for unsupervised domain adaptation often rely on minimizing some statistical distance between the source and target samples in the latent space. To avoid the sampling variability, class imbalance, and data-privacy concerns that often plague these methods, we instead provide a memory and computation-efficient probabilistic framework to extract class prototypes and align the target features with them. We demonstrate the general applicability of our method on a wide range of scenarios, including single-source, multi-source, class-imbalance, and source-private domain adaptation. Requiring no additional model parameters and having a moderate increase in computation over the source model alone, the proposed method achieves competitive performance with state-of-the-art methods.

</p>
</details>

<details><summary><b>RDD-Eclat: Approaches to Parallelize Eclat Algorithm on Spark RDD Framework (Extended Version)</b>
<a href="https://arxiv.org/abs/2110.12012">arxiv:2110.12012</a>
&#x1F4C8; 4 <br>
<p>Pankaj Singh, Sudhakar Singh, P K Mishra, Rakhi Garg</p></summary>
<p>

**Abstract:** Frequent itemset mining (FIM) is a highly computational and data intensive algorithm. Therefore, parallel and distributed FIM algorithms have been designed to process large volume of data in a reduced time. Recently, a number of FIM algorithms have been designed on Hadoop MapReduce, a distributed big data processing framework. But, due to heavy disk I/O, MapReduce is found to be inefficient for the highly iterative FIM algorithms. Therefore, Spark, a more efficient distributed data processing framework, has been developed with in-memory computation and resilient distributed dataset (RDD) features to support the iterative algorithms. On this framework, Apriori and FP-Growth based FIM algorithms have been designed on the Spark RDD framework, but Eclat-based algorithm has not been explored yet. In this paper, RDD-Eclat, a parallel Eclat algorithm on the Spark RDD framework is proposed with its five variants. The proposed algorithms are evaluated on the various benchmark datasets, and the experimental results show that RDD-Eclat outperforms the Spark-based Apriori by many times. Also, the experimental results show the scalability of the proposed algorithms on increasing the number of cores and size of the dataset.

</p>
</details>

<details><summary><b>Logical Activation Functions: Logit-space equivalents of Boolean Operators</b>
<a href="https://arxiv.org/abs/2110.11940">arxiv:2110.11940</a>
&#x1F4C8; 4 <br>
<p>Scott C. Lowe, Robert Earle, Jason d'Eon, Thomas Trappenberg, Sageev Oore</p></summary>
<p>

**Abstract:** Neuronal representations within artificial neural networks are commonly understood as logits, representing the log-odds score of presence (versus absence) of features within the stimulus. Under this interpretation, we can derive the probability $P(x_0 \land x_1)$ that a pair of independent features are both present in the stimulus from their logits. By converting the resulting probability back into a logit, we obtain a logit-space equivalent of the AND operation. However, since this function involves taking multiple exponents and logarithms, it is not well suited to be directly used within neural networks. We thus constructed an efficient approximation named $\text{AND}_\text{AIL}$ (the AND operator Approximate for Independent Logits) utilizing only comparison and addition operations, which can be deployed as an activation function in neural networks. Like MaxOut, $\text{AND}_\text{AIL}$ is a generalization of ReLU to two-dimensions. Additionally, we constructed efficient approximations of the logit-space equivalents to the OR and XNOR operators. We deployed these new activation functions, both in isolation and in conjunction, and demonstrated their effectiveness on a variety of tasks including image classification, transfer learning, abstract reasoning, and compositional zero-shot learning.

</p>
</details>

<details><summary><b>MIGS: Meta Image Generation from Scene Graphs</b>
<a href="https://arxiv.org/abs/2110.11918">arxiv:2110.11918</a>
&#x1F4C8; 4 <br>
<p>Azade Farshad, Sabrina Musatian, Helisa Dhamo, Nassir Navab</p></summary>
<p>

**Abstract:** Generation of images from scene graphs is a promising direction towards explicit scene generation and manipulation. However, the images generated from the scene graphs lack quality, which in part comes due to high difficulty and diversity in the data. We propose MIGS (Meta Image Generation from Scene Graphs), a meta-learning based approach for few-shot image generation from graphs that enables adapting the model to different scenes and increases the image quality by training on diverse sets of tasks. By sampling the data in a task-driven fashion, we train the generator using meta-learning on different sets of tasks that are categorized based on the scene attributes. Our results show that using this meta-learning approach for the generation of images from scene graphs achieves state-of-the-art performance in terms of image quality and capturing the semantic relationships in the scene. Project Website: https://migs2021.github.io/

</p>
</details>

<details><summary><b>GeneDisco: A Benchmark for Experimental Design in Drug Discovery</b>
<a href="https://arxiv.org/abs/2110.11875">arxiv:2110.11875</a>
&#x1F4C8; 4 <br>
<p>Arash Mehrjou, Ashkan Soleymani, Andrew Jesson, Pascal Notin, Yarin Gal, Stefan Bauer, Patrick Schwab</p></summary>
<p>

**Abstract:** In vitro cellular experimentation with genetic interventions, using for example CRISPR technologies, is an essential step in early-stage drug discovery and target validation that serves to assess initial hypotheses about causal associations between biological mechanisms and disease pathologies. With billions of potential hypotheses to test, the experimental design space for in vitro genetic experiments is extremely vast, and the available experimental capacity - even at the largest research institutions in the world - pales in relation to the size of this biological hypothesis space. Machine learning methods, such as active and reinforcement learning, could aid in optimally exploring the vast biological space by integrating prior knowledge from various information sources as well as extrapolating to yet unexplored areas of the experimental design space based on available data. However, there exist no standardised benchmarks and data sets for this challenging task and little research has been conducted in this area to date. Here, we introduce GeneDisco, a benchmark suite for evaluating active learning algorithms for experimental design in drug discovery. GeneDisco contains a curated set of multiple publicly available experimental data sets as well as open-source implementations of state-of-the-art active learning policies for experimental design and exploration.

</p>
</details>

<details><summary><b>Adaptive Fusion Affinity Graph with Noise-free Online Low-rank Representation for Natural Image Segmentation</b>
<a href="https://arxiv.org/abs/2110.11685">arxiv:2110.11685</a>
&#x1F4C8; 4 <br>
<p>Yang Zhang, Moyun Liu, Huiming Zhang, Guodong Sun, Jingwu He</p></summary>
<p>

**Abstract:** Affinity graph-based segmentation methods have become a major trend in computer vision. The performance of these methods relies on the constructed affinity graph, with particular emphasis on the neighborhood topology and pairwise affinities among superpixels. Due to the advantages of assimilating different graphs, a multi-scale fusion graph has a better performance than a single graph with single-scale. However, these methods ignore the noise from images which influences the accuracy of pairwise similarities. Multi-scale combinatorial grouping and graph fusion also generate a higher computational complexity. In this paper, we propose an adaptive fusion affinity graph (AFA-graph) with noise-free low-rank representation in an online manner for natural image segmentation. An input image is first over-segmented into superpixels at different scales and then filtered by the proposed improved kernel density estimation method. Moreover, we select global nodes of these superpixels on the basis of their subspace-preserving presentation, which reveals the feature distribution of superpixels exactly. To reduce time complexity while improving performance, a sparse representation of global nodes based on noise-free online low-rank representation is used to obtain a global graph at each scale. The global graph is finally used to update a local graph which is built upon all superpixels at each scale. Experimental results on the BSD300, BSD500, MSRC, SBD, and PASCAL VOC show the effectiveness of AFA-graph in comparison with state-of-the-art approaches.

</p>
</details>

<details><summary><b>Bayesian Optimization and Deep Learning forsteering wheel angle prediction</b>
<a href="https://arxiv.org/abs/2110.13629">arxiv:2110.13629</a>
&#x1F4C8; 3 <br>
<p>Alessandro Riboni, Nicolò Ghioldi, Antonio Candelieri, Matteo Borrotti</p></summary>
<p>

**Abstract:** Automated driving systems (ADS) have undergone a significant improvement in the last years. ADS and more precisely self-driving cars technologies will change the way we perceive and know the world of transportation systems in terms of user experience, mode choices and business models. The emerging field of Deep Learning (DL) has been successfully applied for the development of innovative ADS solutions. However, the attempt to single out the best deep neural network architecture and tuning its hyperparameters are all expensive processes, both in terms of time and computational resources. In this work, Bayesian Optimization (BO) is used to optimize the hyperparameters of a Spatiotemporal-Long Short Term Memory (ST-LSTM) network with the aim to obtain an accurate model for the prediction of the steering angle in a ADS. BO was able to identify, within a limited number of trials, a model -- namely BOST-LSTM -- which resulted, on a public dataset, the most accurate when compared to classical end-to-end driving models.

</p>
</details>

<details><summary><b>ConformalLayers: A non-linear sequential neural network with associative layers</b>
<a href="https://arxiv.org/abs/2110.12108">arxiv:2110.12108</a>
&#x1F4C8; 3 <br>
<p>Eduardo Vera Sousa, Leandro A. F. Fernandes, Cristina Nader Vasconcelos</p></summary>
<p>

**Abstract:** Convolutional Neural Networks (CNNs) have been widely applied. But as the CNNs grow, the number of arithmetic operations and memory footprint also increase. Furthermore, typical non-linear activation functions do not allow associativity of the operations encoded by consecutive layers, preventing the simplification of intermediate steps by combining them. We present a new activation function that allows associativity between sequential layers of CNNs. Even though our activation function is non-linear, it can be represented by a sequence of linear operations in the conformal model for Euclidean geometry. In this domain, operations like, but not limited to, convolution, average pooling, and dropout remain linear. We take advantage of associativity to combine all the "conformal layers" and make the cost of inference constant regardless of the depth of the network.

</p>
</details>

<details><summary><b>A Simple Baseline for Low-Budget Active Learning</b>
<a href="https://arxiv.org/abs/2110.12033">arxiv:2110.12033</a>
&#x1F4C8; 3 <br>
<p>Kossar Pourahmadi, Parsa Nooralinejad, Hamed Pirsiavash</p></summary>
<p>

**Abstract:** Active learning focuses on choosing a subset of unlabeled data to be labeled. However, most such methods assume that a large subset of the data can be annotated. We are interested in low-budget active learning where only a small subset (e.g., 0.2% of ImageNet) can be annotated. Instead of proposing a new query strategy to iteratively sample batches of unlabeled data given an initial pool, we learn rich features by an off-the-shelf self-supervised learning method only once and then study the effectiveness of different sampling strategies given a low budget on a variety of datasets as well as ImageNet dataset. We show that although the state-of-the-art active learning methods work well given a large budget of data labeling, a simple k-means clustering algorithm can outperform them on low budgets. We believe this method can be used as a simple baseline for low-budget active learning on image classification. Code is available at: https://github.com/UCDvision/low-budget-al

</p>
</details>

<details><summary><b>When to Prune? A Policy towards Early Structural Pruning</b>
<a href="https://arxiv.org/abs/2110.12007">arxiv:2110.12007</a>
&#x1F4C8; 3 <br>
<p>Maying Shen, Pavlo Molchanov, Hongxu Yin, Jose M. Alvarez</p></summary>
<p>

**Abstract:** Pruning enables appealing reductions in network memory footprint and time complexity. Conventional post-training pruning techniques lean towards efficient inference while overlooking the heavy computation for training. Recent exploration of pre-training pruning at initialization hints on training cost reduction via pruning, but suffers noticeable performance degradation. We attempt to combine the benefits of both directions and propose a policy that prunes as early as possible during training without hurting performance. Instead of pruning at initialization, our method exploits initial dense training for few epochs to quickly guide the architecture, while constantly evaluating dominant sub-networks via neuron importance ranking. This unveils dominant sub-networks whose structures turn stable, allowing conventional pruning to be pushed earlier into the training. To do this early, we further introduce an Early Pruning Indicator (EPI) that relies on sub-network architectural similarity and quickly triggers pruning when the sub-network's architecture stabilizes. Through extensive experiments on ImageNet, we show that EPI empowers a quick tracking of early training epochs suitable for pruning, offering same efficacy as an otherwise ``oracle'' grid-search that scans through epochs and requires orders of magnitude more compute. Our method yields $1.4\%$ top-1 accuracy boost over state-of-the-art pruning counterparts, cuts down training cost on GPU by $2.4\times$, hence offers a new efficiency-accuracy boundary for network pruning during training.

</p>
</details>

<details><summary><b>SOFT: Softmax-free Transformer with Linear Complexity</b>
<a href="https://arxiv.org/abs/2110.11945">arxiv:2110.11945</a>
&#x1F4C8; 3 <br>
<p>Jiachen Lu, Jinghan Yao, Junge Zhang, Xiatian Zhu, Hang Xu, Weiguo Gao, Chunjing Xu, Tao Xiang, Li Zhang</p></summary>
<p>

**Abstract:** Vision transformers (ViTs) have pushed the state-of-the-art for various visual recognition tasks by patch-wise image tokenization followed by self-attention. However, the employment of self-attention modules results in a quadratic complexity in both computation and memory usage. Various attempts on approximating the self-attention computation with linear complexity have been made in Natural Language Processing. However, an in-depth analysis in this work shows that they are either theoretically flawed or empirically ineffective for visual recognition. We further identify that their limitations are rooted in keeping the softmax self-attention during approximations. Specifically, conventional self-attention is computed by normalizing the scaled dot-product between token feature vectors. Keeping this softmax operation challenges any subsequent linearization efforts. Based on this insight, for the first time, a softmax-free transformer or SOFT is proposed. To remove softmax in self-attention, Gaussian kernel function is used to replace the dot-product similarity without further normalization. This enables a full self-attention matrix to be approximated via a low-rank matrix decomposition. The robustness of the approximation is achieved by calculating its Moore-Penrose inverse using a Newton-Raphson method. Extensive experiments on ImageNet show that our SOFT significantly improves the computational efficiency of existing ViT variants. Crucially, with a linear complexity, much longer token sequences are permitted in SOFT, resulting in superior trade-off between accuracy and complexity.

</p>
</details>

<details><summary><b>On the Necessity of Auditable Algorithmic Definitions for Machine Unlearning</b>
<a href="https://arxiv.org/abs/2110.11891">arxiv:2110.11891</a>
&#x1F4C8; 3 <br>
<p>Anvith Thudi, Hengrui Jia, Ilia Shumailov, Nicolas Papernot</p></summary>
<p>

**Abstract:** Machine unlearning, i.e. having a model forget about some of its training data, has become increasingly more important as privacy legislation promotes variants of the right-to-be-forgotten. In the context of deep learning, approaches for machine unlearning are broadly categorized into two classes: exact unlearning methods, where an entity has formally removed the data point's impact on the model by retraining the model from scratch, and approximate unlearning, where an entity approximates the model parameters one would obtain by exact unlearning to save on compute costs. In this paper we first show that the definition that underlies approximate unlearning, which seeks to prove the approximately unlearned model is close to an exactly retrained model, is incorrect because one can obtain the same model using different datasets. Thus one could unlearn without modifying the model at all. We then turn to exact unlearning approaches and ask how to verify their claims of unlearning. Our results show that even for a given training trajectory one cannot formally prove the absence of certain data points used during training. We thus conclude that unlearning is only well-defined at the algorithmic level, where an entity's only possible auditable claim to unlearning is that they used a particular algorithm designed to allow for external scrutiny during an audit.

</p>
</details>

<details><summary><b>Clustering Market Regimes using the Wasserstein Distance</b>
<a href="https://arxiv.org/abs/2110.11848">arxiv:2110.11848</a>
&#x1F4C8; 3 <br>
<p>Blanka Horvath, Zacharia Issa, Aitor Muguruza</p></summary>
<p>

**Abstract:** The problem of rapid and automated detection of distinct market regimes is a topic of great interest to financial mathematicians and practitioners alike. In this paper, we outline an unsupervised learning algorithm for clustering financial time-series into a suitable number of temporal segments (market regimes). As a special case of the above, we develop a robust algorithm that automates the process of classifying market regimes. The method is robust in the sense that it does not depend on modelling assumptions of the underlying time series as our experiments with real datasets show. This method -- dubbed the Wasserstein $k$-means algorithm -- frames such a problem as one on the space of probability measures with finite $p^\text{th}$ moment, in terms of the $p$-Wasserstein distance between (empirical) distributions. We compare our WK-means approach with a more traditional clustering algorithms by studying the so-called maximum mean discrepancy scores between, and within clusters. In both cases it is shown that the WK-means algorithm vastly outperforms all considered competitor approaches. We demonstrate the performance of all approaches both in a controlled environment on synthetic data, and on real data.

</p>
</details>

<details><summary><b>CNN-based Omnidirectional Object Detection for HermesBot Autonomous Delivery Robot with Preliminary Frame Classification</b>
<a href="https://arxiv.org/abs/2110.11829">arxiv:2110.11829</a>
&#x1F4C8; 3 <br>
<p>Saian Protasov, Pavel Karpyshev, Ivan Kalinov, Pavel Kopanev, Nikita Mikhailovskiy, Alexander Sedunin, Dzmitry Tsetserukou</p></summary>
<p>

**Abstract:** Mobile autonomous robots include numerous sensors for environment perception. Cameras are an essential tool for robot's localization, navigation, and obstacle avoidance. To process a large flow of data from the sensors, it is necessary to optimize algorithms, or to utilize substantial computational power. In our work, we propose an algorithm for optimizing a neural network for object detection using preliminary binary frame classification. An autonomous outdoor mobile robot with 6 rolling-shutter cameras on the perimeter providing a 360-degree field of view was used as the experimental setup. The obtained experimental results revealed that the proposed optimization accelerates the inference time of the neural network in the cases with up to 5 out of 6 cameras containing target objects.

</p>
</details>

<details><summary><b>Probabilistic ODE Solutions in Millions of Dimensions</b>
<a href="https://arxiv.org/abs/2110.11812">arxiv:2110.11812</a>
&#x1F4C8; 3 <br>
<p>Nicholas Krämer, Nathanael Bosch, Jonathan Schmidt, Philipp Hennig</p></summary>
<p>

**Abstract:** Probabilistic solvers for ordinary differential equations (ODEs) have emerged as an efficient framework for uncertainty quantification and inference on dynamical systems. In this work, we explain the mathematical assumptions and detailed implementation schemes behind solving {high-dimensional} ODEs with a probabilistic numerical algorithm. This has not been possible before due to matrix-matrix operations in each solver step, but is crucial for scientifically relevant problems -- most importantly, the solution of discretised {partial} differential equations. In a nutshell, efficient high-dimensional probabilistic ODE solutions build either on independence assumptions or on Kronecker structure in the prior model. We evaluate the resulting efficiency on a range of problems, including the probabilistic numerical simulation of a differential equation with millions of dimensions.

</p>
</details>

<details><summary><b>HDRVideo-GAN: Deep Generative HDR Video Reconstruction</b>
<a href="https://arxiv.org/abs/2110.11795">arxiv:2110.11795</a>
&#x1F4C8; 3 <br>
<p>Mrinal Anand, Nidhin Harilal, Chandan Kumar, Shanmuganathan Raman</p></summary>
<p>

**Abstract:** High dynamic range (HDR) videos provide a more visually realistic experience than the standard low dynamic range (LDR) videos. Despite having significant progress in HDR imaging, it is still a challenging task to capture high-quality HDR video with a conventional off-the-shelf camera. Existing approaches rely entirely on using dense optical flow between the neighboring LDR sequences to reconstruct an HDR frame. However, they lead to inconsistencies in color and exposure over time when applied to alternating exposures with noisy frames. In this paper, we propose an end-to-end GAN-based framework for HDR video reconstruction from LDR sequences with alternating exposures. We first extract clean LDR frames from noisy LDR video with alternating exposures with a denoising network trained in a self-supervised setting. Using optical flow, we then align the neighboring alternating-exposure frames to a reference frame and then reconstruct high-quality HDR frames in a complete adversarial setting. To further improve the robustness and quality of generated frames, we incorporate temporal stability-based regularization term along with content and style-based losses in the cost function during the training procedure. Experimental results demonstrate that our framework achieves state-of-the-art performance and generates superior quality HDR frames of a video over the existing methods.

</p>
</details>

<details><summary><b>Federated Unlearning via Class-Discriminative Pruning</b>
<a href="https://arxiv.org/abs/2110.11794">arxiv:2110.11794</a>
&#x1F4C8; 3 <br>
<p>Junxiao Wang, Song Guo, Xin Xie, Heng Qi</p></summary>
<p>

**Abstract:** We explore the problem of selectively forgetting categories from trained CNN classification models in the federated learning (FL). Given that the data used for training cannot be accessed globally in FL, our insights probe deep into the internal influence of each channel. Through the visualization of feature maps activated by different channels, we observe that different channels have a varying contribution to different categories in image classification. Inspired by this, we propose a method for scrubbing the model clean of information about particular categories. The method does not require retraining from scratch, nor global access to the data used for training. Instead, we introduce the concept of Term Frequency Inverse Document Frequency (TF-IDF) to quantize the class discrimination of channels. Channels with high TF-IDF scores have more discrimination on the target categories and thus need to be pruned to unlearn. The channel pruning is followed by a fine-tuning process to recover the performance of the pruned model. Evaluated on CIFAR10 dataset, our method accelerates the speed of unlearning by 8.9x for the ResNet model, and 7.9x for the VGG model under no degradation in accuracy, compared to retraining from scratch. For CIFAR100 dataset, the speedups are 9.9x and 8.4x, respectively. We envision this work as a complementary block for FL towards compliance with legal and ethical criteria.

</p>
</details>

<details><summary><b>Clustering of Bank Customers using LSTM-based encoder-decoder and Dynamic Time Warping</b>
<a href="https://arxiv.org/abs/2110.11769">arxiv:2110.11769</a>
&#x1F4C8; 3 <br>
<p>Ehsan Barkhordar, Mohammad Hassan Shirali-Shahreza, Hamid Reza Sadeghi</p></summary>
<p>

**Abstract:** Clustering is an unsupervised data mining technique that can be employed to segment customers. The efficient clustering of customers enables banks to design and make offers based on the features of the target customers. The present study uses a real-world financial dataset (Berka, 2000) to cluster bank customers by an encoder-decoder network and the dynamic time warping (DTW) method. The customer features required for clustering are obtained in four ways: Dynamic Time Warping (DTW), Recency Frequency and Monetary (RFM), LSTM encoder-decoder network, and our proposed hybrid method. Once the LSTM model was trained by customer transaction data, a feature vector of each customer was automatically extracted by the encoder.Moreover, the distance between pairs of sequences of transaction amounts was obtained using DTW. Another vector feature was calculated for customers by RFM scoring. In the hybrid method, the feature vectors are combined from the encoder-decoder output, the DTW distance, and the demographic data (e.g., age and gender). Finally, feature vectors were introduced as input to the k-means clustering algorithm, and we compared clustering results with Silhouette and Davies-Bouldin index. As a result, the clusters obtained from the hybrid approach are more accurate and meaningful than those derived from individual clustering techniques. In addition, the type of neural network layers had a substantial effect on the clusters, and high network error does not necessarily worsen clustering performance.

</p>
</details>

<details><summary><b>Exploiting Cross-Modal Prediction and Relation Consistency for Semi-Supervised Image Captioning</b>
<a href="https://arxiv.org/abs/2110.11767">arxiv:2110.11767</a>
&#x1F4C8; 3 <br>
<p>Yang Yang, Hongchen Wei, Hengshu Zhu, Dianhai Yu, Hui Xiong, Jian Yang</p></summary>
<p>

**Abstract:** The task of image captioning aims to generate captions directly from images via the automatically learned cross-modal generator. To build a well-performing generator, existing approaches usually need a large number of described images, which requires a huge effects on manual labeling. However, in real-world applications, a more general scenario is that we only have limited amount of described images and a large number of undescribed images. Therefore, a resulting challenge is how to effectively combine the undescribed images into the learning of cross-modal generator. To solve this problem, we propose a novel image captioning method by exploiting the Cross-modal Prediction and Relation Consistency (CPRC), which aims to utilize the raw image input to constrain the generated sentence in the commonly semantic space. In detail, considering that the heterogeneous gap between modalities always leads to the supervision difficulty of using the global embedding directly, CPRC turns to transform both the raw image and corresponding generated sentence into the shared semantic space, and measure the generated sentence from two aspects: 1) Prediction consistency. CPRC utilizes the prediction of raw image as soft label to distill useful supervision for the generated sentence, rather than employing the traditional pseudo labeling; 2) Relation consistency. CPRC develops a novel relation consistency between augmented images and corresponding generated sentences to retain the important relational knowledge. In result, CPRC supervises the generated sentence from both the informativeness and representativeness perspectives, and can reasonably use the undescribed images to learn a more effective generator under the semi-supervised scenario.

</p>
</details>

<details><summary><b>Creating Knowledge Graphs Subsets using Shape Expressions</b>
<a href="https://arxiv.org/abs/2110.11709">arxiv:2110.11709</a>
&#x1F4C8; 3 <br>
<p>Jose Emilio Labra Gayo</p></summary>
<p>

**Abstract:** The initial adoption of knowledge graphs by Google and later by big companies has increased their adoption and popularity. In this paper we present a formal model for three different types of knowledge graphs which we call RDF-based graphs, property graphs and wikibase graphs. In order to increase the quality of Knowledge Graphs, several approaches have appeared to describe and validate their contents. Shape Expressions (ShEx) has been proposed as concise language for RDF validation. We give a brief introduction to ShEx and present two extensions that can also be used to describe and validate property graphs (PShEx) and wikibase graphs (WShEx). One problem of knowledge graphs is the large amount of data they contain, which jeopardizes their practical application. In order to palliate this problem, one approach is to create subsets of those knowledge graphs for some domains. We propose the following approaches to generate those subsets: Entity-matching, simple matching, ShEx matching, ShEx plus Slurp and ShEx plus Pregel which are based on declaratively defining the subsets by either matching some content or by Shape Expressions. The last approach is based on a novel validation algorithm for ShEx based on the Pregel algorithm that can handle big data graphs and has been implemented on Apache Spark GraphX.

</p>
</details>

<details><summary><b>Deep Two-Stream Video Inference for Human Body Pose and Shape Estimation</b>
<a href="https://arxiv.org/abs/2110.11680">arxiv:2110.11680</a>
&#x1F4C8; 3 <br>
<p>Ziwen Li, Bo Xu, Han Huang, Cheng Lu, Yandong Guo</p></summary>
<p>

**Abstract:** Several video-based 3D pose and shape estimation algorithms have been proposed to resolve the temporal inconsistency of single-image-based methods. However it still remains challenging to have stable and accurate reconstruction. In this paper, we propose a new framework Deep Two-Stream Video Inference for Human Body Pose and Shape Estimation (DTS-VIBE), to generate 3D human pose and mesh from RGB videos. We reformulate the task as a multi-modality problem that fuses RGB and optical flow for more reliable estimation. In order to fully utilize both sensory modalities (RGB or optical flow), we train a two-stream temporal network based on transformer to predict SMPL parameters. The supplementary modality, optical flow, helps to maintain temporal consistency by leveraging motion knowledge between two consecutive frames. The proposed algorithm is extensively evaluated on the Human3.6 and 3DPW datasets. The experimental results show that it outperforms other state-of-the-art methods by a significant margin.

</p>
</details>

<details><summary><b>ProtoShotXAI: Using Prototypical Few-Shot Architecture for Explainable AI</b>
<a href="https://arxiv.org/abs/2110.11597">arxiv:2110.11597</a>
&#x1F4C8; 3 <br>
<p>Samuel Hess, Gregory Ditzler</p></summary>
<p>

**Abstract:** Unexplainable black-box models create scenarios where anomalies cause deleterious responses, thus creating unacceptable risks. These risks have motivated the field of eXplainable Artificial Intelligence (XAI) to improve trust by evaluating local interpretability in black-box neural networks. Unfortunately, the ground truth is unavailable for the model's decision, so evaluation is limited to qualitative assessment. Further, interpretability may lead to inaccurate conclusions about the model or a false sense of trust. We propose to improve XAI from the vantage point of the user's trust by exploring a black-box model's latent feature space. We present an approach, ProtoShotXAI, that uses a Prototypical few-shot network to explore the contrastive manifold between nonlinear features of different classes. A user explores the manifold by perturbing the input features of a query sample and recording the response for a subset of exemplars from any class. Our approach is the first locally interpretable XAI model that can be extended to, and demonstrated on, few-shot networks. We compare ProtoShotXAI to the state-of-the-art XAI approaches on MNIST, Omniglot, and ImageNet to demonstrate, both quantitatively and qualitatively, that ProtoShotXAI provides more flexibility for model exploration. Finally, ProtoShotXAI also demonstrates novel explainabilty and detectabilty on adversarial samples.

</p>
</details>

<details><summary><b>SVM and ANN based Classification of EMG signals by using PCA and LDA</b>
<a href="https://arxiv.org/abs/2110.15279">arxiv:2110.15279</a>
&#x1F4C8; 2 <br>
<p>Hritam Basak, Alik Roy, Jeet Bandhu Lahiri, Sayantan Bose, Soumyadeep Patra</p></summary>
<p>

**Abstract:** In recent decades, biomedical signals have been used for communication in Human-Computer Interfaces (HCI) for medical applications; an instance of these signals are the myoelectric signals (MES), which are generated in the muscles of the human body as unidimensional patterns. Because of this, the methods and algorithms developed for pattern recognition in signals can be applied for their analyses once these signals have been sampled and turned into electromyographic (EMG) signals. Additionally, in recent years, many researchers have dedicated their efforts to studying prosthetic control utilizing EMG signal classification, that is, by logging a set of MES in a proper range of frequencies to classify the corresponding EMG signals. The feature classification can be carried out on the time domain or by using other domains such as the frequency domain (also known as the spectral domain), time scale, and time-frequency, amongst others. One of the main methods used for pattern recognition in myoelectric signals is the Support Vector Machines (SVM) technique whose primary function is to identify an n-dimensional hyperplane to separate a set of input feature points into different classes. This technique has the potential to recognize complex patterns and on several occasions, it has proven its worth when compared to other classifiers such as Artificial Neural Network (ANN), Linear Discriminant Analysis (LDA), and Principal Component Analysis(PCA). The key concepts underlying the SVM are (a) the hyperplane separator; (b) the kernel function; (c) the optimal separation hyperplane; and (d) a soft margin (hyperplane tolerance).

</p>
</details>

<details><summary><b>Generative Networks for Precision Enthusiasts</b>
<a href="https://arxiv.org/abs/2110.13632">arxiv:2110.13632</a>
&#x1F4C8; 2 <br>
<p>Anja Butter, Theo Heimel, Sander Hummerich, Tobias Krebs, Tilman Plehn, Armand Rousselot, Sophia Vent</p></summary>
<p>

**Abstract:** Generative networks are opening new avenues in fast event generation for the LHC. We show how generative flow networks can reach percent-level precision for kinematic distributions, how they can be trained jointly with a discriminator, and how this discriminator improves the generation. Our joint training relies on a novel coupling of the two networks which does not require a Nash equilibrium. We then estimate the generation uncertainties through a Bayesian network setup and through conditional data augmentation, while the discriminator ensures that there are no systematic inconsistencies compared to the training data.

</p>
</details>

<details><summary><b>Semantic Detection of Potential Wind-borne Debris in Construction Jobsites: Digital Twining for Hurricane Preparedness and Jobsite Safety</b>
<a href="https://arxiv.org/abs/2110.12968">arxiv:2110.12968</a>
&#x1F4C8; 2 <br>
<p>Mirsalar Kamari, Youngjib Ham</p></summary>
<p>

**Abstract:** In the United States, hurricanes are the most devastating natural disasters causing billions of dollars worth of damage every year. More importantly, construction jobsites are classified among the most vulnerable environments to severe wind events. During hurricanes, unsecured and incomplete elements of construction sites, such as scaffoldings, plywoods, and metal rods, will become the potential wind-borne debris, causing cascading damages to the construction projects and the neighboring communities. Thus, it is no wonder that construction firms implement jobsite emergency plans to enforce preparedness responses before extreme weather events. However, relying on checklist-based emergency action plans to carry out a thorough hurricane preparedness is challenging in large-scale and complex site environments. For enabling systematic responses for hurricane preparedness, we have proposed a vision-based technique to identify and analyze the potential wind-borne debris in construction jobsites. Building on this, this paper demonstrates the fidelity of a new machine vision-based method to support construction site hurricane preparedness and further discuss its implications. The outcomes indicate that the convenience of visual data collection and the advantages of the machine vision-based frameworks enable rapid scene understanding and thus, provide critical heads up for practitioners to recognize and localize the potential wind-borne derbies in construction jobsites and effectively implement hurricane preparedness.

</p>
</details>

<details><summary><b>Rethinking Neural vs. Matrix-Factorization Collaborative Filtering: the Theoretical Perspectives</b>
<a href="https://arxiv.org/abs/2110.12141">arxiv:2110.12141</a>
&#x1F4C8; 2 <br>
<p>Da Xu, Chuanwei Ruan, Evren Korpeoglu, Sushant Kumar, Kannan Achan</p></summary>
<p>

**Abstract:** The recent work by Rendle et al. (2020), based on empirical observations, argues that matrix-factorization collaborative filtering (MCF) compares favorably to neural collaborative filtering (NCF), and conjectures the dot product's superiority over the feed-forward neural network as similarity function. In this paper, we address the comparison rigorously by answering the following questions: 1. what is the limiting expressivity of each model; 2. under the practical gradient descent, to which solution does each optimization path converge; 3. how would the models generalize under the inductive and transductive learning setting. Our results highlight the similar expressivity for the overparameterized NCF and MCF as kernelized predictors, and reveal the relation between their optimization paths. We further show their different generalization behaviors, where MCF and NCF experience specific tradeoff and comparison in the transductive and inductive collaborative filtering setting. Lastly, by showing a novel generalization result, we reveal the critical role of correcting exposure bias for model evaluation in the inductive setting. Our results explain some of the previously observed conflicts, and we provide synthetic and real-data experiments to shed further insights to this topic.

</p>
</details>

<details><summary><b>Quantifying Epistemic Uncertainty in Deep Learning</b>
<a href="https://arxiv.org/abs/2110.12122">arxiv:2110.12122</a>
&#x1F4C8; 2 <br>
<p>Ziyi Huang, Henry Lam, Haofeng Zhang</p></summary>
<p>

**Abstract:** Uncertainty quantification is at the core of the reliability and robustness of machine learning. It is well-known that uncertainty consists of two different types, often referred to as aleatoric and epistemic uncertainties. In this paper, we provide a systematic study on the epistemic uncertainty in deep supervised learning. We rigorously distinguish different sources of epistemic uncertainty, including in particular procedural variability (from the training procedure) and data variability (from the training data). We use our framework to explain how deep ensemble enhances prediction by reducing procedural variability. We also propose two approaches to estimate epistemic uncertainty for a well-trained neural network in practice. One uses influence function derived from the theory of neural tangent kernel that bypasses the convexity assumption violated by modern neural networks. Another uses batching that bypasses the time-consuming Gram matrix inversion in the influence function calculation, while expending minimal re-training effort. We discuss how both approaches overcome some difficulties in applying classical statistical methods to the inference on deep learning.

</p>
</details>

<details><summary><b>Dense Dual-Attention Network for Light Field Image Super-Resolution</b>
<a href="https://arxiv.org/abs/2110.12114">arxiv:2110.12114</a>
&#x1F4C8; 2 <br>
<p>Yu Mo, Yingqian Wang, Chao Xiao, Jungang Yang, Wei An</p></summary>
<p>

**Abstract:** Light field (LF) images can be used to improve the performance of image super-resolution (SR) because both angular and spatial information is available. It is challenging to incorporate distinctive information from different views for LF image SR. Moreover, the long-term information from the previous layers can be weakened as the depth of network increases. In this paper, we propose a dense dual-attention network for LF image SR. Specifically, we design a view attention module to adaptively capture discriminative features across different views and a channel attention module to selectively focus on informative information across all channels. These two modules are fed to two branches and stacked separately in a chain structure for adaptive fusion of hierarchical features and distillation of valid information. Meanwhile, a dense connection is used to fully exploit multi-level information. Extensive experiments demonstrate that our dense dual-attention mechanism can capture informative information across views and channels to improve SR performance. Comparative results show the advantage of our method over state-of-the-art methods on public datasets.

</p>
</details>

<details><summary><b>Contrastively Disentangled Sequential Variational Autoencoder</b>
<a href="https://arxiv.org/abs/2110.12091">arxiv:2110.12091</a>
&#x1F4C8; 2 <br>
<p>Junwen Bai, Weiran Wang, Carla Gomes</p></summary>
<p>

**Abstract:** Self-supervised disentangled representation learning is a critical task in sequence modeling. The learnt representations contribute to better model interpretability as well as the data generation, and improve the sample efficiency for downstream tasks. We propose a novel sequence representation learning method, named Contrastively Disentangled Sequential Variational Autoencoder (C-DSVAE), to extract and separate the static (time-invariant) and dynamic (time-variant) factors in the latent space. Different from previous sequential variational autoencoder methods, we use a novel evidence lower bound which maximizes the mutual information between the input and the latent factors, while penalizes the mutual information between the static and dynamic factors. We leverage contrastive estimations of the mutual information terms in training, together with simple yet effective augmentation techniques, to introduce additional inductive biases. Our experiments show that C-DSVAE significantly outperforms the previous state-of-the-art methods on multiple metrics.

</p>
</details>

<details><summary><b>Learning with Noisy Labels Revisited: A Study Using Real-World Human Annotations</b>
<a href="https://arxiv.org/abs/2110.12088">arxiv:2110.12088</a>
&#x1F4C8; 2 <br>
<p>Jiaheng Wei, Zhaowei Zhu, Hao Cheng, Tongliang Liu, Gang Niu, Yang Liu</p></summary>
<p>

**Abstract:** Existing research on learning with noisy labels mainly focuses on synthetic label noise. Synthetic label noise, though has clean structures which greatly enable statistical analyses, often fails to model the real-world noise patterns. The recent literature has observed several efforts to offer real-world noisy datasets, yet the existing efforts suffer from two caveats: firstly, the lack of ground-truth verification makes it hard to theoretically study the property and treatment of real-world label noise. Secondly, these efforts are often of large scales, which may lead to unfair comparisons of robust methods within reasonable and accessible computation power. To better understand real-world label noise, it is important to establish controllable and moderate-sized real-world noisy datasets with both ground-truth and noisy labels. This work presents two new benchmark datasets (CIFAR-10N, CIFAR-100N), equipping the train dataset of CIFAR-10 and CIFAR-100 with human-annotated real-world noisy labels that we collect from Amazon Mechanical Turk. We quantitatively and qualitatively show that real-world noisy labels follow an instance-dependent pattern rather than the classically adopted class-dependent ones. We then initiate an effort to benchmark a subset of existing solutions using CIFAR-10N, CIFAR-100N. We next proceed to study the memorization of model predictions, which further illustrates the difference between human noise and class-dependent synthetic noise. We show indeed the real-world noise patterns impose new and outstanding challenges as compared to synthetic ones. These observations require us to rethink the treatment of noisy labels, and we hope the availability of these two datasets would facilitate the development and evaluation of future learning with noisy label solutions. The corresponding datasets and the leaderboard are publicly available at \url{http://noisylabels.com}.

</p>
</details>

<details><summary><b>Gaussian Process Sampling and Optimization with Approximate Upper and Lower Bounds</b>
<a href="https://arxiv.org/abs/2110.12087">arxiv:2110.12087</a>
&#x1F4C8; 2 <br>
<p>Vu Nguyen, Marc Peter Deisenroth, Michael A. Osborne</p></summary>
<p>

**Abstract:** Many functions have approximately-known upper and/or lower bounds, potentially aiding the modeling of such functions. In this paper, we introduce Gaussian process models for functions where such bounds are (approximately) known. More specifically, we propose the first use of such bounds to improve Gaussian process (GP) posterior sampling and Bayesian optimization (BO). That is, we transform a GP model satisfying the given bounds, and then sample and weight functions from its posterior. To further exploit these bounds in BO settings, we present bounded entropy search (BES) to select the point gaining the most information about the underlying function, estimated by the GP samples, while satisfying the output constraints. We characterize the sample variance bounds and show that the decision made by BES is explainable. Our proposed approach is conceptually straightforward and can be used as a plug in extension to existing methods for GP posterior sampling and Bayesian optimization.

</p>
</details>

<details><summary><b>C-Planning: An Automatic Curriculum for Learning Goal-Reaching Tasks</b>
<a href="https://arxiv.org/abs/2110.12080">arxiv:2110.12080</a>
&#x1F4C8; 2 <br>
<p>Tianjun Zhang, Benjamin Eysenbach, Ruslan Salakhutdinov, Sergey Levine, Joseph E. Gonzalez</p></summary>
<p>

**Abstract:** Goal-conditioned reinforcement learning (RL) can solve tasks in a wide range of domains, including navigation and manipulation, but learning to reach distant goals remains a central challenge to the field. Learning to reach such goals is particularly hard without any offline data, expert demonstrations, and reward shaping. In this paper, we propose an algorithm to solve the distant goal-reaching task by using search at training time to automatically generate a curriculum of intermediate states. Our algorithm, Classifier-Planning (C-Planning), frames the learning of the goal-conditioned policies as expectation maximization: the E-step corresponds to planning an optimal sequence of waypoints using graph search, while the M-step aims to learn a goal-conditioned policy to reach those waypoints. Unlike prior methods that combine goal-conditioned RL with graph search, ours performs search only during training and not testing, significantly decreasing the compute costs of deploying the learned policy. Empirically, we demonstrate that our method is more sample efficient than prior methods. Moreover, it is able to solve very long horizons manipulation and navigation tasks, tasks that prior goal-conditioned methods and methods based on graph search fail to solve.

</p>
</details>

<details><summary><b>Gaussian Graphical Model Selection for Huge Data via Minipatch Learning</b>
<a href="https://arxiv.org/abs/2110.12067">arxiv:2110.12067</a>
&#x1F4C8; 2 <br>
<p>Tianyi Yao, Minjie Wang, Genevera I. Allen</p></summary>
<p>

**Abstract:** Gaussian graphical models are essential unsupervised learning techniques to estimate conditional dependence relationships between sets of nodes. While graphical model selection is a well-studied problem with many popular techniques, there are typically three key practical challenges: i) many existing methods become computationally intractable in huge-data settings with tens of thousands of nodes; ii) the need for separate data-driven tuning hyperparameter selection procedures considerably adds to the computational burden; iii) the statistical accuracy of selected edges often deteriorates as the dimension and/or the complexity of the underlying graph structures increase. We tackle these problems by proposing the Minipatch Graph (MPGraph) estimator. Our approach builds upon insights from the latent variable graphical model problem and utilizes ensembles of thresholded graph estimators fit to tiny, random subsets of both the observations and the nodes, termed minipatches. As estimates are fit on small problems, our approach is computationally fast with integrated stability-based hyperparameter tuning. Additionally, we prove that under certain conditions our MPGraph algorithm achieves finite-sample graph selection consistency. We compare our approach to state-of-the-art computational approaches to Gaussian graphical model selection including the BigQUIC algorithm, and empirically demonstrate that our approach is not only more accurate but also extensively faster for huge graph selection problems.

</p>
</details>

<details><summary><b>Uncertainty Quantification For Low-Rank Matrix Completion With Heterogeneous and Sub-Exponential Noise</b>
<a href="https://arxiv.org/abs/2110.12046">arxiv:2110.12046</a>
&#x1F4C8; 2 <br>
<p>Vivek F. Farias, Andrew A. Li, Tianyi Peng</p></summary>
<p>

**Abstract:** The problem of low-rank matrix completion with heterogeneous and sub-exponential (as opposed to homogeneous and Gaussian) noise is particularly relevant to a number of applications in modern commerce. Examples include panel sales data and data collected from web-commerce systems such as recommendation engines. An important unresolved question for this problem is characterizing the distribution of estimated matrix entries under common low-rank estimators. Such a characterization is essential to any application that requires quantification of uncertainty in these estimates and has heretofore only been available under the assumption of homogenous Gaussian noise. Here we characterize the distribution of estimated matrix entries when the observation noise is heterogeneous sub-exponential and provide, as an application, explicit formulas for this distribution when observed entries are Poisson or Binary distributed.

</p>
</details>

<details><summary><b>Semi-Supervised Semantic Segmentation of Vessel Images using Leaking Perturbations</b>
<a href="https://arxiv.org/abs/2110.11998">arxiv:2110.11998</a>
&#x1F4C8; 2 <br>
<p>Jinyong Hou, Xuejie Ding, Jeremiah D. Deng</p></summary>
<p>

**Abstract:** Semantic segmentation based on deep learning methods can attain appealing accuracy provided large amounts of annotated samples. However, it remains a challenging task when only limited labelled data are available, which is especially common in medical imaging. In this paper, we propose to use Leaking GAN, a GAN-based semi-supervised architecture for retina vessel semantic segmentation. Our key idea is to pollute the discriminator by leaking information from the generator. This leads to more moderate generations that benefit the training of GAN. As a result, the unlabelled examples can be better utilized to boost the learning of the discriminator, which eventually leads to stronger classification performance. In addition, to overcome the variations in medical images, the mean-teacher mechanism is utilized as an auxiliary regularization of the discriminator. Further, we modify the focal loss to fit it as the consistency objective for mean-teacher regularizer. Extensive experiments demonstrate that the Leaking GAN framework achieves competitive performance compared to the state-of-the-art methods when evaluated on benchmark datasets including DRIVE, STARE and CHASE\_DB1, using as few as 8 labelled images in the semi-supervised setting. It also outperforms existing algorithms on cross-domain segmentation tasks.

</p>
</details>

<details><summary><b>ReLACE: Reinforcement Learning Agent for Counterfactual Explanations of Arbitrary Predictive Models</b>
<a href="https://arxiv.org/abs/2110.11960">arxiv:2110.11960</a>
&#x1F4C8; 2 <br>
<p>Ziheng Chen, Fabrizio Silvestri, Gabriele Tolomei, He Zhu, Jia Wang, Hongshik Ahn</p></summary>
<p>

**Abstract:** The demand for explainable machine learning (ML) models has been growing rapidly in recent years. Amongst the methods proposed to associate ML model predictions with human-understandable rationale, counterfactual explanations are one of the most popular. They consist of post-hoc rules derived from counterfactual examples (CFs), i.e., modified versions of input samples that result in alternative output responses from the predictive model to be explained. However, existing CF generation strategies either exploit the internals of specific models (e.g., random forests or neural networks), or depend on each sample's neighborhood, which makes them hard to be generalized for more complex models and inefficient for larger datasets. In this work, we aim to overcome these limitations and introduce a model-agnostic algorithm to generate optimal counterfactual explanations. Specifically, we formulate the problem of crafting CFs as a sequential decision-making task and then find the optimal CFs via deep reinforcement learning (DRL) with discrete-continuous hybrid action space. Differently from other techniques, our method is easily applied to any black-box model, as this resembles the environment that the DRL agent interacts with. In addition, we develop an algorithm to extract explainable decision rules from the DRL agent's policy, so as to make the process of generating CFs itself transparent. Extensive experiments conducted on several datasets have shown that our method outperforms existing CF generation baselines.

</p>
</details>

<details><summary><b>Adversarial robustness for latent models: Revisiting the robust-standard accuracies tradeoff</b>
<a href="https://arxiv.org/abs/2110.11950">arxiv:2110.11950</a>
&#x1F4C8; 2 <br>
<p>Adel Javanmard, Mohammad Mehrabi</p></summary>
<p>

**Abstract:** Over the past few years, several adversarial training methods have been proposed to improve the robustness of machine learning models against adversarial perturbations in the input. Despite remarkable progress in this regard, adversarial training is often observed to drop the standard test accuracy. This phenomenon has intrigued the research community to investigate the potential tradeoff between standard and robust accuracy as two performance measures. In this paper, we revisit this tradeoff for latent models and argue that this tradeoff is mitigated when the data enjoys a low-dimensional structure. In particular, we consider binary classification under two data generative models, namely Gaussian mixture model and generalized linear model, where the feature data lie on a low-dimensional manifold. We show that as the manifold dimension to the ambient dimension decreases, one can obtain models that are nearly optimal with respect to both, the standard accuracy and the robust accuracy measures.

</p>
</details>

<details><summary><b>Double Trouble: How to not explain a text classifier's decisions using counterfactuals synthesized by masked language models?</b>
<a href="https://arxiv.org/abs/2110.11929">arxiv:2110.11929</a>
&#x1F4C8; 2 <br>
<p>Thang M. Pham, Trung Bui, Long Mai, Anh Nguyen</p></summary>
<p>

**Abstract:** Explaining how important each input feature is to a classifier's decision is critical in high-stake applications. An underlying principle behind dozens of explanation methods is to take the prediction difference between before-and-after an input feature (here, a token) is removed as its attribution - the individual treatment effect in causal inference. A recent method called Input Marginalization (IM) (Kim et al., 2020) uses BERT to replace a token - i.e. simulating the do(.) operator - yielding more plausible counterfactuals. However, our rigorous evaluation using five metrics and on three datasets found IM explanations to be consistently more biased, less accurate, and less plausible than those derived from simply deleting a word.

</p>
</details>

<details><summary><b>Conditional Gaussian PAC-Bayes</b>
<a href="https://arxiv.org/abs/2110.11886">arxiv:2110.11886</a>
&#x1F4C8; 2 <br>
<p>Eugenio Clerico, George Deligiannidis, Arnaud Doucet</p></summary>
<p>

**Abstract:** Recent studies have empirically investigated different methods to train a stochastic classifier by optimising a PAC-Bayesian bound via stochastic gradient descent. Most of these procedures need to replace the misclassification error with a surrogate loss, leading to a mismatch between the optimisation objective and the actual generalisation bound. The present paper proposes a novel training algorithm that optimises the PAC-Bayesian bound, without relying on any surrogate loss. Empirical results show that the bounds obtained with this approach are tighter than those found in the literature.

</p>
</details>

<details><summary><b>Tight and Robust Private Mean Estimation with Few Users</b>
<a href="https://arxiv.org/abs/2110.11876">arxiv:2110.11876</a>
&#x1F4C8; 2 <br>
<p>Hossein Esfandiari, Vahab Mirrokni, Shyam Narayanan</p></summary>
<p>

**Abstract:** In this work, we study high-dimensional mean estimation under user-level differential privacy, and attempt to design an $(ε,δ)$-differentially private mechanism using as few users as possible. In particular, we provide a nearly optimal trade-off between the number of users and the number of samples per user required for private mean estimation, even when the number of users is as low as $O(\frac{1}ε\log\frac{1}δ)$. Interestingly our bound $O(\frac{1}ε\log\frac{1}δ)$ on the number of users is independent of the dimension, unlike the previous work that depends polynomially on the dimension, solving a problem left open by Amin et al.~(ICML'2019). Our mechanism enjoys robustness up to the point that even if the information of $49\%$ of the users are corrupted, our final estimation is still approximately accurate. Finally, our results also apply to a broader range of problems such as learning discrete distributions, stochastic convex optimization, empirical risk minimization, and a variant of stochastic gradient descent via a reduction to differentially private mean estimation.

</p>
</details>

<details><summary><b>Auctions Between Regret-Minimizing Agents</b>
<a href="https://arxiv.org/abs/2110.11855">arxiv:2110.11855</a>
&#x1F4C8; 2 <br>
<p>Yoav Kolumbus, Noam Nisan</p></summary>
<p>

**Abstract:** We analyze a scenario in which software agents implemented as regret minimizing algorithms engage in a repeated auction on behalf of their users. We study first price and second price auctions, as well as their generalized versions (e.g., as those used for ad auctions). Using both theoretical analysis and simulations, we show that, surprisingly, in second price auctions the players have incentives to mis-report their true valuations to their own learning agents, while in the first price auction it is a dominant strategy for all players to truthfully report their valuations to their agents.

</p>
</details>

<details><summary><b>Using scientific machine learning for experimental bifurcation analysis of dynamic systems</b>
<a href="https://arxiv.org/abs/2110.11854">arxiv:2110.11854</a>
&#x1F4C8; 2 <br>
<p>Sandor Beregi, David A. W. Barton, Djamel Rezgui, Simon A. Neild</p></summary>
<p>

**Abstract:** Augmenting mechanistic ordinary differential equation (ODE) models with machine-learnable structures is an novel approach to create highly accurate, low-dimensional models of engineering systems incorporating both expert knowledge and reality through measurement data. Our exploratory study focuses on training universal differential equation (UDE) models for physical nonlinear dynamical systems with limit cycles: an aerofoil undergoing flutter oscillations and an electrodynamic nonlinear oscillator. We consider examples where training data is generated by numerical simulations, whereas we also employ the proposed modelling concept to physical experiments allowing us to investigate problems with a wide range of complexity. To collect the training data, the method of control-based continuation is used as it captures not just the stable but also the unstable limit cycles of the observed system. This feature makes it possible to extract more information about the observed system than the standard, open-loop approach would allow. We use both neural networks and Gaussian processes as universal approximators alongside the mechanistic models to give a critical assessment of the accuracy and robustness of the UDE modelling approach. We also highlight the potential issues one may run into during the training procedure indicating the limits of the current modelling framework.

</p>
</details>

<details><summary><b>Probabilistic fine-tuning of pruning masks and PAC-Bayes self-bounded learning</b>
<a href="https://arxiv.org/abs/2110.11804">arxiv:2110.11804</a>
&#x1F4C8; 2 <br>
<p>Soufiane Hayou, Bobby He, Gintare Karolina Dziugaite</p></summary>
<p>

**Abstract:** We study an approach to learning pruning masks by optimizing the expected loss of stochastic pruning masks, i.e., masks which zero out each weight independently with some weight-specific probability. We analyze the training dynamics of the induced stochastic predictor in the setting of linear regression, and observe a data-adaptive L1 regularization term, in contrast to the dataadaptive L2 regularization term known to underlie dropout in linear regression. We also observe a preference to prune weights that are less well-aligned with the data labels. We evaluate probabilistic fine-tuning for optimizing stochastic pruning masks for neural networks, starting from masks produced by several baselines. In each case, we see improvements in test error over baselines, even after we threshold fine-tuned stochastic pruning masks. Finally, since a stochastic pruning mask induces a stochastic neural network, we consider training the weights and/or pruning probabilities simultaneously to minimize a PAC-Bayes bound on generalization error. Using data-dependent priors, we obtain a selfbounded learning algorithm with strong performance and numerically tight bounds. In the linear model, we show that a PAC-Bayes generalization error bound is controlled by the magnitude of the change in feature alignment between the 'prior' and 'posterior' data.

</p>
</details>

<details><summary><b>Learning Stable Vector Fields on Lie Groups</b>
<a href="https://arxiv.org/abs/2110.11774">arxiv:2110.11774</a>
&#x1F4C8; 2 <br>
<p>Julen Urain, Davide Tateo, Jan Peters</p></summary>
<p>

**Abstract:** Learning robot motions from demonstration requires having models that are able to represent vector fields for the full robot pose when the task is defined in operational space. Recent advances in reactive motion generation have shown that it is possible to learn adaptive, reactive, smooth, and stable vector fields. However, these approaches define a vector field on a flat Euclidean manifold, while representing vector fields for orientations required to model the dynamics in non-Euclidean manifolds, such as Lie Groups. In this paper, we present a novel vector field model that can guarantee most of the properties of previous approaches i.e., stability, smoothness, and reactivity beyond the Euclidean space. In the experimental evaluation, we show the performance of our proposed vector field model to learn stable vector fields for full robot poses as SE(2) and SE(3) in both simulated and real robotics tasks.

</p>
</details>

<details><summary><b>A Fast and Accurate Splitting Method for Optimal Transport: Analysis and Implementation</b>
<a href="https://arxiv.org/abs/2110.11738">arxiv:2110.11738</a>
&#x1F4C8; 2 <br>
<p>Vien V. Mai, Jacob Lindbäck, Mikael Johansson</p></summary>
<p>

**Abstract:** We develop a fast and reliable method for solving large-scale optimal transport (OT) problems at an unprecedented combination of speed and accuracy. Built on the celebrated Douglas-Rachford splitting technique, our method tackles the original OT problem directly instead of solving an approximate regularized problem, as many state-of-the-art techniques do. This allows us to provide sparse transport plans and avoid numerical issues of methods that use entropic regularization. The algorithm has the same cost per iteration as the popular Sinkhorn method, and each iteration can be executed efficiently, in parallel. The proposed method enjoys an iteration complexity $O(1/ε)$ compared to the best-known $O(1/ε^2)$ of the Sinkhorn method. In addition, we establish a linear convergence rate for our formulation of the OT problem. We detail an efficient GPU implementation of the proposed method that maintains a primal-dual stopping criterion at no extra cost. Substantial experiments demonstrate the effectiveness of our method, both in terms of computation times and robustness.

</p>
</details>

<details><summary><b>Mechanistic Interpretation of Machine Learning Inference: A Fuzzy Feature Importance Fusion Approach</b>
<a href="https://arxiv.org/abs/2110.11713">arxiv:2110.11713</a>
&#x1F4C8; 2 <br>
<p>Divish Rengasamy, Jimiama M. Mase, Mercedes Torres Torres, Benjamin Rothwell, David A. Winkler, Grazziela P. Figueredo</p></summary>
<p>

**Abstract:** With the widespread use of machine learning to support decision-making, it is increasingly important to verify and understand the reasons why a particular output is produced. Although post-training feature importance approaches assist this interpretation, there is an overall lack of consensus regarding how feature importance should be quantified, making explanations of model predictions unreliable. In addition, many of these explanations depend on the specific machine learning approach employed and on the subset of data used when calculating feature importance. A possible solution to improve the reliability of explanations is to combine results from multiple feature importance quantifiers from different machine learning approaches coupled with re-sampling. Current state-of-the-art ensemble feature importance fusion uses crisp techniques to fuse results from different approaches. There is, however, significant loss of information as these approaches are not context-aware and reduce several quantifiers to a single crisp output. More importantly, their representation of 'importance' as coefficients is misleading and incomprehensible to end-users and decision makers. Here we show how the use of fuzzy data fusion methods can overcome some of the important limitations of crisp fusion methods.

</p>
</details>

<details><summary><b>Variational Wasserstein Barycenters with c-Cyclical Monotonicity</b>
<a href="https://arxiv.org/abs/2110.11707">arxiv:2110.11707</a>
&#x1F4C8; 2 <br>
<p>Jinjin Chi, Zhiyao Yang, Jihong Ouyang, Ximing Li</p></summary>
<p>

**Abstract:** Wasserstein barycenter, built on the theory of optimal transport, provides a powerful framework to aggregate probability distributions, and it has increasingly attracted great attention within the machine learning community. However, it suffers from severe computational burden, especially for high dimensional and continuous settings. To this end, we develop a novel continuous approximation method for the Wasserstein barycenters problem given sample access to the input distributions. The basic idea is to introduce a variational distribution as the approximation of the true continuous barycenter, so as to frame the barycenters computation problem as an optimization problem, where parameters of the variational distribution adjust the proxy distribution to be similar to the barycenter. Leveraging the variational distribution, we construct a tractable dual formulation for the regularized Wasserstein barycenter problem with c-cyclical monotonicity, which can be efficiently solved by stochastic optimization. We provide theoretical analysis on convergence and demonstrate the practical effectiveness of our method on real applications of subset posterior aggregation and synthetic data.

</p>
</details>

<details><summary><b>Differentially Private Coordinate Descent for Composite Empirical Risk Minimization</b>
<a href="https://arxiv.org/abs/2110.11688">arxiv:2110.11688</a>
&#x1F4C8; 2 <br>
<p>Paul Mangold, Aurélien Bellet, Joseph Salmon, Marc Tommasi</p></summary>
<p>

**Abstract:** Machine learning models can leak information about the data used to train them. Differentially Private (DP) variants of optimization algorithms like Stochastic Gradient Descent (DP-SGD) have been designed to mitigate this, inducing a trade-off between privacy and utility. In this paper, we propose a new method for composite Differentially Private Empirical Risk Minimization (DP-ERM): Differentially Private proximal Coordinate Descent (DP-CD). We analyze its utility through a novel theoretical analysis of inexact coordinate descent, and highlight some regimes where DP-CD outperforms DP-SGD, thanks to the possibility of using larger step sizes. We also prove new lower bounds for composite DP-ERM under coordinate-wise regularity assumptions, that are, in some settings, nearly matched by our algorithm. In practical implementations, the coordinate-wise nature of DP-CD updates demands special care in choosing the clipping thresholds used to bound individual contributions to the gradients. A natural parameterization of these thresholds emerges from our theory, limiting the addition of unnecessarily large noise without requiring coordinate-wise hyperparameter tuning or extra computational cost.

</p>
</details>

<details><summary><b>Diversified Sampling for Batched Bayesian Optimization with Determinantal Point Processes</b>
<a href="https://arxiv.org/abs/2110.11665">arxiv:2110.11665</a>
&#x1F4C8; 2 <br>
<p>Elvis Nava, Mojmír Mutný, Andreas Krause</p></summary>
<p>

**Abstract:** In Bayesian Optimization (BO) we study black-box function optimization with noisy point evaluations and Bayesian priors. Convergence of BO can be greatly sped up by batching, where multiple evaluations of the black-box function are performed in a single round. The main difficulty in this setting is to propose at the same time diverse and informative batches of evaluation points. In this work, we introduce DPP-Batch Bayesian Optimization (DPP-BBO), a universal framework for inducing batch diversity in sampling based BO by leveraging the repulsive properties of Determinantal Point Processes (DPP) to naturally diversify the batch sampling procedure. We illustrate this framework by formulating DPP-Thompson Sampling (DPP-TS) as a variant of the popular Thompson Sampling (TS) algorithm and introducing a Markov Chain Monte Carlo procedure to sample from it. We then prove novel Bayesian simple regret bounds for both classical batched TS as well as our counterpart DPP-TS, with the latter bound being tighter. Our real-world, as well as synthetic, experiments demonstrate improved performance of DPP-BBO over classical batching methods with Gaussian process and Cox process models.

</p>
</details>

<details><summary><b>Model Inspired Autoencoder for Unsupervised Hyperspectral Image Super-Resolution</b>
<a href="https://arxiv.org/abs/2110.11591">arxiv:2110.11591</a>
&#x1F4C8; 2 <br>
<p>Jianjun Liu, Zebin Wu, Liang Xiao, Xiao-Jun Wu</p></summary>
<p>

**Abstract:** This paper focuses on hyperspectral image (HSI) super-resolution that aims to fuse a low-spatial-resolution HSI and a high-spatial-resolution multispectral image to form a high-spatial-resolution HSI (HR-HSI). Existing deep learning-based approaches are mostly supervised that rely on a large number of labeled training samples, which is unrealistic. The commonly used model-based approaches are unsupervised and flexible but rely on hand-craft priors. Inspired by the specific properties of model, we make the first attempt to design a model inspired deep network for HSI super-resolution in an unsupervised manner. This approach consists of an implicit autoencoder network built on the target HR-HSI that treats each pixel as an individual sample. The nonnegative matrix factorization (NMF) of the target HR-HSI is integrated into the autoencoder network, where the two NMF parts, spectral and spatial matrices, are treated as decoder parameters and hidden outputs respectively. In the encoding stage, we present a pixel-wise fusion model to estimate hidden outputs directly, and then reformulate and unfold the model's algorithm to form the encoder network. With the specific architecture, the proposed network is similar to a manifold prior-based model, and can be trained patch by patch rather than the entire image. Moreover, we propose an additional unsupervised network to estimate the point spread function and spectral response function. Experimental results conducted on both synthetic and real datasets demonstrate the effectiveness of the proposed approach.

</p>
</details>

<details><summary><b>Artistic Autonomy in AI Art</b>
<a href="https://arxiv.org/abs/2111.04437">arxiv:2111.04437</a>
&#x1F4C8; 1 <br>
<p>Alayt Issak</p></summary>
<p>

**Abstract:** The concept of art has transposed meaning and medium across time, with its context being a deciding factor for its evolution. However, human beings' innermost functionality remains the same, and art, to this day, serves as an expression of the subconscious. Accelerated by the conception of GANs in 2014, automation has become a central medium in Artificial Intelligence (AI) Art. However, this raises concern over AI's influence on artistic autonomy within the process of creativity. This paper introduces the ethical responsibility of AI towards maintaining the artist's volition in exercising autonomy and utilizes principles of self-determination theory alongside fundamental limits of creativity to do so.

</p>
</details>

<details><summary><b>Drug Similarity and Link Prediction Using Graph Embeddings on Medical Knowledge Graphs</b>
<a href="https://arxiv.org/abs/2110.13047">arxiv:2110.13047</a>
&#x1F4C8; 1 <br>
<p>Prakhar Gurawa, Matthias Nickles</p></summary>
<p>

**Abstract:** The paper utilizes the graph embeddings generated for entities of a large biomedical database to perform link prediction to capture various new relationships among different entities. A novel node similarity measure is proposed that utilizes the graph embeddings and link prediction scores to find similarity scores among various drugs which can be used by the medical experts to recommend alternative drugs to avoid side effects from original one. Utilizing machine learning on knowledge graph for drug similarity and recommendation will be less costly and less time consuming with higher scalability as compared to traditional biomedical methods due to the dependency on costly medical equipment and experts of the latter ones.

</p>
</details>

<details><summary><b>PPSGCN: A Privacy-Preserving Subgraph Sampling Based Distributed GCN Training Method</b>
<a href="https://arxiv.org/abs/2110.12906">arxiv:2110.12906</a>
&#x1F4C8; 1 <br>
<p>Binchi Zhang, Minnan Luo, Shangbin Feng, Ziqi Liu, Jun Zhou, Qinghua Zheng</p></summary>
<p>

**Abstract:** Graph convolutional networks (GCNs) have been widely adopted for graph representation learning and achieved impressive performance. For larger graphs stored separately on different clients, distributed GCN training algorithms were proposed to improve efficiency and scalability. However, existing methods directly exchange node features between different clients, which results in data privacy leakage. Federated learning was incorporated in graph learning to tackle data privacy, while they suffer from severe performance drop due to non-iid data distribution. Besides, these approaches generally involve heavy communication and memory overhead during the training process. In light of these problems, we propose a Privacy-Preserving Subgraph sampling based distributed GCN training method (PPSGCN), which preserves data privacy and significantly cuts back on communication and memory overhead. Specifically, PPSGCN employs a star-topology client-server system. We firstly sample a local node subset in each client to form a global subgraph, which greatly reduces communication and memory costs. We then conduct local computation on each client with features or gradients of the sampled nodes. Finally, all clients securely communicate with the central server with homomorphic encryption to combine local results while preserving data privacy. Compared with federated graph learning methods, our PPSGCN model is trained on a global graph to avoid the negative impact of local data distribution. We prove that our PPSGCN algorithm would converge to a local optimum with probability 1. Experiment results on three prevalent benchmarks demonstrate that our algorithm significantly reduces communication and memory overhead while maintaining desirable performance. Further studies not only demonstrate the fast convergence of PPSGCN, but discuss the trade-off between communication and local computation cost as well.

</p>
</details>

<details><summary><b>On Geometric Connections of Embedded and Quotient Geometries in Riemannian Fixed-rank Matrix Optimization</b>
<a href="https://arxiv.org/abs/2110.12121">arxiv:2110.12121</a>
&#x1F4C8; 1 <br>
<p>Yuetian Luo, Xudong Li, Anru R. Zhang</p></summary>
<p>

**Abstract:** In this paper, we propose a general procedure for establishing the landscape connections of a Riemannian optimization problem under the embedded and quotient geometries. By applying the general procedure to the fixed-rank positive semidefinite (PSD) and general matrix optimization, we establish an exact Riemannian gradient connection under two geometries at every point on the manifold and sandwich inequalities between the spectra of Riemannian Hessians at Riemannian first-order stationary points (FOSPs). These results immediately imply an equivalence on the sets of Riemannian FOSPs, Riemannian second-order stationary points (SOSPs) and strict saddles of fixed-rank matrix optimization under the embedded and the quotient geometries. To the best of our knowledge, this is the first geometric landscape connection between the embedded and the quotient geometries for fixed-rank matrix optimization and it provides a concrete example on how these two geometries are connected in Riemannian optimization. In addition, the effects of the Riemannian metric and quotient structure on the landscape connection are discussed. We also observe an algorithmic connection for fixed-rank matrix optimization under two geometries with some specific Riemannian metrics. A number of novel ideas and technical ingredients including a unified treatment for different Riemannian metrics and new horizontal space representations under quotient geometries are developed to obtain our results. The results in this paper deepen our understanding of geometric connections of Riemannian optimization under different Riemannian geometries and provide a few new theoretical insights to unanswered questions in the literature.

</p>
</details>

<details><summary><b>Multiplication-Avoiding Variant of Power Iteration with Applications</b>
<a href="https://arxiv.org/abs/2110.12065">arxiv:2110.12065</a>
&#x1F4C8; 1 <br>
<p>Hongyi Pan, Diaa Badawi, Runxuan Miao, Erdem Koyuncu, Ahmet Enis Cetin</p></summary>
<p>

**Abstract:** Power iteration is a fundamental algorithm in data analysis. It extracts the eigenvector corresponding to the largest eigenvalue of a given matrix. Applications include ranking algorithms, recommendation systems, principal component analysis (PCA), among many others. In this paper, We introduce multiplication-avoiding power iteration (MAPI), which replaces the standard $\ell_2$-inner products that appear at the regular power iteration (RPI) with multiplication-free vector products which are Mercer-type kernel operations related with the $\ell_1$ norm. Precisely, for an $n\times n$ matrix, MAPI requires $n$ multiplications, while RPI needs $n^2$ multiplications per iteration. Therefore, MAPI provides a significant reduction of the number of multiplication operations, which are known to be costly in terms of energy consumption. We provide applications of MAPI to PCA-based image reconstruction as well as to graph-based ranking algorithms. When compared to RPI, MAPI not only typically converges much faster, but also provides superior performance.

</p>
</details>

<details><summary><b>Two-Timescale End-to-End Learning for Channel Acquisition and Hybrid Precoding</b>
<a href="https://arxiv.org/abs/2110.12059">arxiv:2110.12059</a>
&#x1F4C8; 1 <br>
<p>Qiyu Hu, Yunlong Cai, Kai Kang, Guanding Yu, Jakob Hoydis, Yonina C. Eldar</p></summary>
<p>

**Abstract:** In this paper, we propose an end-to-end deep learning-based joint transceiver design algorithm for millimeter wave (mmWave) massive multiple-input multiple-output (MIMO) systems, which consists of deep neural network (DNN)-aided pilot training, channel feedback, and hybrid analog-digital (HAD) precoding. Specifically, we develop a DNN architecture that maps the received pilots into feedback bits at the receiver, and then further maps the feedback bits into the hybrid precoder at the transmitter. To reduce the signaling overhead and channel state information (CSI) mismatch caused by the transmission delay, a two-timescale DNN composed of a long-term DNN and a short-term DNN is developed. The analog precoders are designed by the long-term DNN based on the CSI statistics and updated once in a frame consisting of a number of time slots. In contrast, the digital precoders are optimized by the short-term DNN at each time slot based on the estimated low-dimensional equivalent CSI matrices. A two-timescale training method is also developed for the proposed DNN with a binary layer. We then analyze the generalization ability and signaling overhead for the proposed DNN based algorithm. Simulation results show that our proposed technique significantly outperforms conventional schemes in terms of bit-error rate performance with reduced signaling overhead and shorter pilot sequences.

</p>
</details>

<details><summary><b>Interaction and Conflict Management in AI-assisted Operational Control Loops in 6G</b>
<a href="https://arxiv.org/abs/2110.12025">arxiv:2110.12025</a>
&#x1F4C8; 1 <br>
<p>Saeedeh Parsaeefard, Pooyan Habibi, Alberto Leon Garcia</p></summary>
<p>

**Abstract:** This paper studies autonomous and AI-assisted control loops (ACLs) in the next generation of wireless networks in the lens of multi-agent environments. We will study the diverse interactions and conflict management among these loops. We propose "interaction and conflict management" (ICM) modules to achieve coherent, consistent and interactions among these ACLs. We introduce three categories of ACLs based on their sizes, their cooperative and competitive behaviors, and their sharing of datasets and models. These categories help to introduce conflict resolution and interaction management mechanisms for ICM. Using Kubernetes, we present an implementation of ICM to remove the conflicts in the scheduling and rescheduling of Pods for different ACLs in networks.

</p>
</details>

<details><summary><b>Uncertainty aware anomaly detection to predict errant beam pulses in the SNS accelerator</b>
<a href="https://arxiv.org/abs/2110.12006">arxiv:2110.12006</a>
&#x1F4C8; 1 <br>
<p>Willem Blokland, Pradeep Ramuhalli, Charles Peters, Yigit Yucesan, Alexander Zhukov, Malachi Schram, Kishansingh Rajput, Torri Jeske</p></summary>
<p>

**Abstract:** High-power particle accelerators are complex machines with thousands of pieces of equipmentthat are frequently running at the cutting edge of technology. In order to improve the day-to-dayoperations and maximize the delivery of the science, new analytical techniques are being exploredfor anomaly detection, classification, and prognostications. As such, we describe the applicationof an uncertainty aware Machine Learning method, the Siamese neural network model, to predictupcoming errant beam pulses using the data from a single monitoring device. By predicting theupcoming failure, we can stop the accelerator before damage occurs. We describe the acceleratoroperation, related Machine Learning research, the prediction performance required to abort beamwhile maintaining operations, the monitoring device and its data, and the Siamese method andits results. These results show that the researched method can be applied to improve acceleratoroperations.

</p>
</details>

<details><summary><b>A Reinforcement Learning Approach to Parameter Selection for Distributed Optimization in Power Systems</b>
<a href="https://arxiv.org/abs/2110.11991">arxiv:2110.11991</a>
&#x1F4C8; 1 <br>
<p>Sihan Zeng, Alyssa Kody, Youngdae Kim, Kibaek Kim, Daniel K. Molzahn</p></summary>
<p>

**Abstract:** With the increasing penetration of distributed energy resources, distributed optimization algorithms have attracted significant attention for power systems applications due to their potential for superior scalability, privacy, and robustness to a single point-of-failure. The Alternating Direction Method of Multipliers (ADMM) is a popular distributed optimization algorithm; however, its convergence performance is highly dependent on the selection of penalty parameters, which are usually chosen heuristically. In this work, we use reinforcement learning (RL) to develop an adaptive penalty parameter selection policy for the AC optimal power flow (ACOPF) problem solved via ADMM with the goal of minimizing the number of iterations until convergence. We train our RL policy using deep Q-learning, and show that this policy can result in significantly accelerated convergence (up to a 59% reduction in the number of iterations compared to existing, curvature-informed penalty parameter selection methods). Furthermore, we show that our RL policy demonstrates promise for generalizability, performing well under unseen loading schemes as well as under unseen losses of lines and generators (up to a 50% reduction in iterations). This work thus provides a proof-of-concept for using RL for parameter selection in ADMM for power systems applications.

</p>
</details>

<details><summary><b>Deep Convolutional Autoencoders as Generic Feature Extractors in Seismological Applications</b>
<a href="https://arxiv.org/abs/2110.11802">arxiv:2110.11802</a>
&#x1F4C8; 1 <br>
<p>Qingkai Kong, Andrea Chiang, Ana C. Aguiar, M. Giselle Fernández-Godino, Stephen C. Myers, Donald D. Lucas</p></summary>
<p>

**Abstract:** The idea of using a deep autoencoder to encode seismic waveform features and then use them in different seismological applications is appealing. In this paper, we designed tests to evaluate this idea of using autoencoders as feature extractors for different seismological applications, such as event discrimination (i.e., earthquake vs. noise waveforms, earthquake vs. explosion waveforms, and phase picking). These tests involve training an autoencoder, either undercomplete or overcomplete, on a large amount of earthquake waveforms, and then using the trained encoder as a feature extractor with subsequent application layers (either a fully connected layer, or a convolutional layer plus a fully connected layer) to make the decision. By comparing the performance of these newly designed models against the baseline models trained from scratch, we conclude that the autoencoder feature extractor approach may only perform well under certain conditions such as when the target problems require features to be similar to the autoencoder encoded features, when a relatively small amount of training data is available, and when certain model structures and training strategies are utilized. The model structure that works best in all these tests is an overcomplete autoencoder with a convolutional layer and a fully connected layer to make the estimation.

</p>
</details>

<details><summary><b>Projection-Free Algorithm for Stochastic Bi-level Optimization</b>
<a href="https://arxiv.org/abs/2110.11721">arxiv:2110.11721</a>
&#x1F4C8; 1 <br>
<p>Zeeshan Akhtar, Amrit Singh Bedi, Srujan Teja Thomdapu, Ketan Rajawat</p></summary>
<p>

**Abstract:** This work presents the first projection-free algorithm to solve stochastic bi-level optimization problems, where the objective function depends on the solution of another stochastic optimization problem. The proposed $\textbf{S}$tochastic $\textbf{Bi}$-level $\textbf{F}$rank-$\textbf{W}$olfe ($\textbf{SBFW}$) algorithm can be applied to streaming settings and does not make use of large batches or checkpoints. The sample complexity of SBFW is shown to be $\mathcal{O}(ε^{-3})$ for convex objectives and $\mathcal{O}(ε^{-4})$ for non-convex objectives. Improved rates are derived for the stochastic compositional problem, which is a special case of the bi-level problem, and entails minimizing the composition of two expected-value functions. The proposed $\textbf{S}$tochastic $\textbf{C}$ompositional $\textbf{F}$rank-$\textbf{W}$olfe ($\textbf{SCFW}$) is shown to achieve a sample complexity of $\mathcal{O}(ε^{-2})$ for convex objectives and $\mathcal{O}(ε^{-3})$ for non-convex objectives, at par with the state-of-the-art sample complexities for projection-free algorithms solving single-level problems. We demonstrate the advantage of the proposed methods by solving the problem of matrix completion with denoising and the problem of policy value evaluation in reinforcement learning.

</p>
</details>

<details><summary><b>DQC: a Python program package for Differentiable Quantum Chemistry</b>
<a href="https://arxiv.org/abs/2110.11678">arxiv:2110.11678</a>
&#x1F4C8; 1 <br>
<p>Muhammad F. Kasim, Susi Lehtola, Sam M. Vinko</p></summary>
<p>

**Abstract:** Automatic differentiation represents a paradigm shift in scientific programming, where evaluating both functions and their derivatives is required for most applications. By removing the need to explicitly derive expressions for gradients, development times can be be shortened, and calculations simplified. For these reasons, automatic differentiation has fueled the rapid growth of a variety of sophisticated machine learning techniques over the past decade, but is now also increasingly showing its value to support {\it ab initio} simulations of quantum systems, and enhance computational quantum chemistry. Here we present an open-source differentiable quantum chemistry simulation code, DQC, and explore applications facilitated by automatic differentiation: (1) calculating molecular perturbation properties; (2) reoptimizing a basis set for hydrocarbons; (3) checking the stability of self-consistent field wave functions; and (4) predicting molecular properties via alchemical perturbations.

</p>
</details>

<details><summary><b>WebFed: Cross-platform Federated Learning Framework Based on Web Browser with Local Differential Privacy</b>
<a href="https://arxiv.org/abs/2110.11646">arxiv:2110.11646</a>
&#x1F4C8; 1 <br>
<p>Zhuotao Lian, Qinglin Yang, Qingkui Zeng, Chunhua Su</p></summary>
<p>

**Abstract:** For data isolated islands and privacy issues, federated learning has been extensively invoking much interest since it allows clients to collaborate on training a global model using their local data without sharing any with a third party. However, the existing federated learning frameworks always need sophisticated condition configurations (e.g., sophisticated driver configuration of standalone graphics card like NVIDIA, compile environment) that bring much inconvenience for large-scale development and deployment. To facilitate the deployment of federated learning and the implementation of related applications, we innovatively propose WebFed, a novel browser-based federated learning framework that takes advantage of the browser's features (e.g., Cross-platform, JavaScript Programming Features) and enhances the privacy protection via local differential privacy mechanism. Finally, We conduct experiments on heterogeneous devices to evaluate the performance of the proposed WebFed framework.

</p>
</details>

<details><summary><b>PhotoWCT$^2$: Compact Autoencoder for Photorealistic Style Transfer Resulting from Blockwise Training and Skip Connections of High-Frequency Residuals</b>
<a href="https://arxiv.org/abs/2110.11995">arxiv:2110.11995</a>
&#x1F4C8; 0 <br>
<p>Tai-Yin Chiu, Danna Gurari</p></summary>
<p>

**Abstract:** Photorealistic style transfer is an image editing task with the goal to modify an image to match the style of another image while ensuring the result looks like a real photograph. A limitation of existing models is that they have many parameters, which in turn prevents their use for larger image resolutions and leads to slower run-times. We introduce two mechanisms that enable our design of a more compact model that we call PhotoWCT$^2$, which preserves state-of-art stylization strength and photorealism. First, we introduce blockwise training to perform coarse-to-fine feature transformations that enable state-of-art stylization strength in a single autoencoder in place of the inefficient cascade of four autoencoders used in PhotoWCT. Second, we introduce skip connections of high-frequency residuals in order to preserve image quality when applying the sequential coarse-to-fine feature transformations. Our PhotoWCT$^2$ model requires fewer parameters (e.g., 30.3\% fewer) while supporting higher resolution images (e.g., 4K) and achieving faster stylization than existing models.

</p>
</details>

<details><summary><b>Reconstruction of Sentinel-2 Time Series Using Robust Gaussian Mixture Models -- Application to the Detection of Anomalous Crop Development in wheat and rapeseed crops</b>
<a href="https://arxiv.org/abs/2110.11780">arxiv:2110.11780</a>
&#x1F4C8; 0 <br>
<p>Florian Mouret, Mohanad Albughdadi, Sylvie Duthoit, Denis Kouamé, Guillaume Rieu, Jean-Yves Tourneret</p></summary>
<p>

**Abstract:** Missing data is a recurrent problem in remote sensing, mainly due to cloud coverage for multispectral images and acquisition problems. This can be a critical issue for crop monitoring, especially for applications relying on machine learning techniques, which generally assume that the feature matrix does not have missing values. This paper proposes a Gaussian Mixture Model (GMM) for the reconstruction of parcel-level features extracted from multispectral images. A robust version of the GMM is also investigated, since datasets can be contaminated by inaccurate samples or features (e.g., wrong crop type reported, inaccurate boundaries, undetected clouds, etc). Additional features extracted from Synthetic Aperture Radar (SAR) images using Sentinel-1 data are also used to provide complementary information and improve the imputations. The robust GMM investigated in this work assigns reduced weights to the outliers during the estimation of the GMM parameters, which improves the final reconstruction. These weights are computed at each step of an Expectation-Maximization (EM) algorithm by using outlier scores provided by the isolation forest algorithm. Experimental validation is conducted on rapeseed and wheat parcels located in the Beauce region (France). Overall, we show that the GMM imputation method outperforms other reconstruction strategies. A mean absolute error (MAE) of 0.013 (resp. 0.019) is obtained for the imputation of the median Normalized Difference Index (NDVI) of the rapeseed (resp. wheat) parcels. Other indicators (e.g., Normalized Difference Water Index) and statistics (for instance the interquartile range, which captures heterogeneity among the parcel indicator) are reconstructed at the same time with good accuracy. In a dataset contaminated by irrelevant samples, using the robust GMM is recommended since the standard GMM imputation can lead to inaccurate imputed values.

</p>
</details>


[Next Page](2021/2021-10/2021-10-21.md)
