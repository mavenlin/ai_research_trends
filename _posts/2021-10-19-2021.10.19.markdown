## Summary for 2021-10-19, created on 2021-12-14


<details><summary><b>SLAM: A Unified Encoder for Speech and Language Modeling via Speech-Text Joint Pre-Training</b>
<a href="https://arxiv.org/abs/2110.10329">arxiv:2110.10329</a>
&#x1F4C8; 33 <br>
<p>Ankur Bapna, Yu-an Chung, Nan Wu, Anmol Gulati, Ye Jia, Jonathan H. Clark, Melvin Johnson, Jason Riesa, Alexis Conneau, Yu Zhang</p></summary>
<p>

**Abstract:** Unsupervised pre-training is now the predominant approach for both text and speech understanding. Self-attention models pre-trained on large amounts of unannotated data have been hugely successful when fine-tuned on downstream tasks from a variety of domains and languages. This paper takes the universality of unsupervised language pre-training one step further, by unifying speech and text pre-training within a single model. We build a single encoder with the BERT objective on unlabeled text together with the w2v-BERT objective on unlabeled speech. To further align our model representations across modalities, we leverage alignment losses, specifically Translation Language Modeling (TLM) and Speech Text Matching (STM) that make use of supervised speech-text recognition data. We demonstrate that incorporating both speech and text data during pre-training can significantly improve downstream quality on CoVoST~2 speech translation, by around 1 BLEU compared to single-modality pre-trained models, while retaining close to SotA performance on LibriSpeech and SpeechStew ASR tasks. On four GLUE tasks and text-normalization, we observe evidence of capacity limitations and interference between the two modalities, leading to degraded performance compared to an equivalent text-only model, while still being competitive with BERT. Through extensive empirical analysis we also demonstrate the importance of the choice of objective function for speech pre-training, and the beneficial effect of adding additional supervised signals on the quality of the learned representations.

</p>
</details>

<details><summary><b>LMSOC: An Approach for Socially Sensitive Pretraining</b>
<a href="https://arxiv.org/abs/2110.10319">arxiv:2110.10319</a>
&#x1F4C8; 17 <br>
<p>Vivek Kulkarni, Shubhanshu Mishra, Aria Haghighi</p></summary>
<p>

**Abstract:** While large-scale pretrained language models have been shown to learn effective linguistic representations for many NLP tasks, there remain many real-world contextual aspects of language that current approaches do not capture. For instance, consider a cloze-test "I enjoyed the ____ game this weekend": the correct answer depends heavily on where the speaker is from, when the utterance occurred, and the speaker's broader social milieu and preferences. Although language depends heavily on the geographical, temporal, and other social contexts of the speaker, these elements have not been incorporated into modern transformer-based language models. We propose a simple but effective approach to incorporate speaker social context into the learned representations of large-scale language models. Our method first learns dense representations of social contexts using graph representation learning algorithms and then primes language model pretraining with these social context representations. We evaluate our approach on geographically-sensitive language-modeling tasks and show a substantial improvement (more than 100% relative lift on MRR) compared to baselines.

</p>
</details>

<details><summary><b>Towards Optimal Correlational Object Search</b>
<a href="https://arxiv.org/abs/2110.09991">arxiv:2110.09991</a>
&#x1F4C8; 14 <br>
<p>Kaiyu Zheng, Rohan Chitnis, Yoonchang Sung, George Konidaris, Stefanie Tellex</p></summary>
<p>

**Abstract:** In realistic applications of object search, robots will need to locate target objects in complex environments while coping with unreliable sensors, especially for small or hard-to-detect objects. In such settings, correlational information can be valuable for planning efficiently: when looking for a fork, the robot could start by locating the easier-to-detect refrigerator, since forks would probably be found nearby. Previous approaches to object search with correlational information typically resort to ad-hoc or greedy search strategies. In this paper, we propose the Correlational Object Search POMDP (COS-POMDP), which can be solved to produce search strategies that use correlational information. COS-POMDPs contain a correlation-based observation model that allows us to avoid the exponential blow-up of maintaining a joint belief about all objects, while preserving the optimal solution to this naive, exponential POMDP formulation. We propose a hierarchical planning algorithm to scale up COS-POMDP for practical domains. We conduct experiments using AI2-THOR, a realistic simulator of household environments, as well as YOLOv5, a widely-used object detector. Our results show that, particularly for hard-to-detect objects, such as scrub brush and remote control, our method offers the most robust performance compared to baselines that ignore correlations as well as a greedy, next-best view approach.

</p>
</details>

<details><summary><b>Latent reweighting, an almost free improvement for GANs</b>
<a href="https://arxiv.org/abs/2110.09803">arxiv:2110.09803</a>
&#x1F4C8; 14 <br>
<p>Thibaut Issenhuth, Ugo Tanielian, David Picard, Jeremie Mary</p></summary>
<p>

**Abstract:** Standard formulations of GANs, where a continuous function deforms a connected latent space, have been shown to be misspecified when fitting different classes of images. In particular, the generator will necessarily sample some low-quality images in between the classes. Rather than modifying the architecture, a line of works aims at improving the sampling quality from pre-trained generators at the expense of increased computational cost. Building on this, we introduce an additional network to predict latent importance weights and two associated sampling methods to avoid the poorest samples. This idea has several advantages: 1) it provides a way to inject disconnectedness into any GAN architecture, 2) since the rejection happens in the latent space, it avoids going through both the generator and the discriminator, saving computation time, 3) this importance weights formulation provides a principled way to reduce the Wasserstein's distance to the target distribution. We demonstrate the effectiveness of our method on several datasets, both synthetic and high-dimensional.

</p>
</details>

<details><summary><b>Continuous Control with Action Quantization from Demonstrations</b>
<a href="https://arxiv.org/abs/2110.10149">arxiv:2110.10149</a>
&#x1F4C8; 12 <br>
<p>Robert Dadashi, Léonard Hussenot, Damien Vincent, Sertan Girgin, Anton Raichuk, Matthieu Geist, Olivier Pietquin</p></summary>
<p>

**Abstract:** In Reinforcement Learning (RL), discrete actions, as opposed to continuous actions, result in less complex exploration problems and the immediate computation of the maximum of the action-value function which is central to dynamic programming-based methods. In this paper, we propose a novel method: Action Quantization from Demonstrations (AQuaDem) to learn a discretization of continuous action spaces by leveraging the priors of demonstrations. This dramatically reduces the exploration problem, since the actions faced by the agent not only are in a finite number but also are plausible in light of the demonstrator's behavior. By discretizing the action space we can apply any discrete action deep RL algorithm to the continuous control problem. We evaluate the proposed method on three different setups: RL with demonstrations, RL with play data --demonstrations of a human playing in an environment but not solving any specific task-- and Imitation Learning. For all three setups, we only consider human data, which is more challenging than synthetic data. We found that AQuaDem consistently outperforms state-of-the-art continuous control methods, both in terms of performance and sample efficiency. We provide visualizations and videos in the paper's website: https://google-research.github.io/aquadem.

</p>
</details>

<details><summary><b>Optimal randomized classification trees</b>
<a href="https://arxiv.org/abs/2110.11952">arxiv:2110.11952</a>
&#x1F4C8; 10 <br>
<p>Rafael Blanquero, Emilio Carrizosa, Cristina Molero-Río, Dolores Romero Morales</p></summary>
<p>

**Abstract:** Classification and Regression Trees (CARTs) are off-the-shelf techniques in modern Statistics and Machine Learning. CARTs are traditionally built by means of a greedy procedure, sequentially deciding the splitting predictor variable(s) and the associated threshold. This greedy approach trains trees very fast, but, by its nature, their classification accuracy may not be competitive against other state-of-the-art procedures. Moreover, controlling critical issues, such as the misclassification rates in each of the classes, is difficult. To address these shortcomings, optimal decision trees have been recently proposed in the literature, which use discrete decision variables to model the path each observation will follow in the tree. Instead, we propose a new approach based on continuous optimization. Our classifier can be seen as a randomized tree, since at each node of the decision tree a random decision is made. The computational experience reported demonstrates the good performance of our procedure.

</p>
</details>

<details><summary><b>AI-Based Detection, Classification and Prediction/Prognosis in Medical Imaging: Towards Radiophenomics</b>
<a href="https://arxiv.org/abs/2110.10332">arxiv:2110.10332</a>
&#x1F4C8; 9 <br>
<p>Fereshteh Yousefirizi, Pierre Decazes, Amine Amyar, Su Ruan, Babak Saboury, Arman Rahmim</p></summary>
<p>

**Abstract:** Artificial intelligence (AI) techniques have significant potential to enable effective, robust and automated image phenotyping including identification of subtle patterns. AI-based detection searches the image space to find the regions of interest based on patterns and features. There is a spectrum of tumor histologies from benign to malignant that can be identified by AI-based classification approaches using image features. The extraction of minable information from images gives way to the field of radiomics and can be explored via explicit (handcrafted/engineered) and deep radiomics frameworks. Radiomics analysis has the potential to be utilized as a noninvasive technique for the accurate characterization of tumors to improve diagnosis and treatment monitoring. This work reviews AI-based techniques, with a special focus on oncological PET and PET/CT imaging, for different detection, classification, and prediction/prognosis tasks. We also discuss needed efforts to enable the translation of AI techniques to routine clinical workflows, and potential improvements and complementary techniques such as the use of natural language processing on electronic health records and neuro-symbolic AI techniques.

</p>
</details>

<details><summary><b>Forecasting Market Prices using DL with Data Augmentation and Meta-learning: ARIMA still wins!</b>
<a href="https://arxiv.org/abs/2110.10233">arxiv:2110.10233</a>
&#x1F4C8; 9 <br>
<p>Vedant Shah, Gautam Shroff</p></summary>
<p>

**Abstract:** Deep-learning techniques have been successfully used for time-series forecasting and have often shown superior performance on many standard benchmark datasets as compared to traditional techniques. Here we present a comprehensive and comparative study of performance of deep-learning techniques for forecasting prices in financial markets. We benchmark state-of-the-art deep-learning baselines, such as NBeats, etc., on data from currency as well as stock markets. We also generate synthetic data using a fuzzy-logic based model of demand driven by technical rules such as moving averages, which are often used by traders. We benchmark the baseline techniques on this synthetic data as well as use it for data augmentation. We also apply gradient-based meta-learning to account for non-stationarity of financial time-series. Our extensive experiments notwithstanding, the surprising result is that the standard ARIMA models outperforms deep-learning even using data augmentation or meta-learning. We conclude by speculating as to why this might be the case.

</p>
</details>

<details><summary><b>DPFM: Deep Partial Functional Maps</b>
<a href="https://arxiv.org/abs/2110.09994">arxiv:2110.09994</a>
&#x1F4C8; 9 <br>
<p>Souhaib Attaiki, Gautam Pai, Maks Ovsjanikov</p></summary>
<p>

**Abstract:** We consider the problem of computing dense correspondences between non-rigid shapes with potentially significant partiality. Existing formulations tackle this problem through heavy manifold optimization in the spectral domain, given hand-crafted shape descriptors. In this paper, we propose the first learning method aimed directly at partial non-rigid shape correspondence. Our approach uses the functional map framework, can be trained in a supervised or unsupervised manner, and learns descriptors directly from the data, thus both improving robustness and accuracy in challenging cases. Furthermore, unlike existing techniques, our method is also applicable to partial-to-partial non-rigid matching, in which the common regions on both shapes are unknown a priori. We demonstrate that the resulting method is data-efficient, and achieves state-of-the-art results on several benchmark datasets. Our code and data can be found online: https://github.com/pvnieo/DPFM

</p>
</details>

<details><summary><b>Minibatch vs Local SGD with Shuffling: Tight Convergence Bounds and Beyond</b>
<a href="https://arxiv.org/abs/2110.10342">arxiv:2110.10342</a>
&#x1F4C8; 8 <br>
<p>Chulhee Yun, Shashank Rajput, Suvrit Sra</p></summary>
<p>

**Abstract:** In distributed learning, local SGD (also known as federated averaging) and its simple baseline minibatch SGD are widely studied optimization methods. Most existing analyses of these methods assume independent and unbiased gradient estimates obtained via with-replacement sampling. In contrast, we study shuffling-based variants: minibatch and local Random Reshuffling, which draw stochastic gradients without replacement and are thus closer to practice. For smooth functions satisfying the Polyak-Łojasiewicz condition, we obtain convergence bounds (in the large epoch regime) which show that these shuffling-based variants converge faster than their with-replacement counterparts. Moreover, we prove matching lower bounds showing that our convergence analysis is tight. Finally, we propose an algorithmic modification called synchronized shuffling that leads to convergence rates faster than our lower bounds in near-homogeneous settings.

</p>
</details>

<details><summary><b>Frontiers in Evolutionary Computation: A Workshop Report</b>
<a href="https://arxiv.org/abs/2110.10320">arxiv:2110.10320</a>
&#x1F4C8; 8 <br>
<p>Tyler Millhouse, Melanie Moses, Melanie Mitchell</p></summary>
<p>

**Abstract:** In July of 2021, the Santa Fe Institute hosted a workshop on evolutionary computation as part of its Foundations of Intelligence in Natural and Artificial Systems project. This project seeks to advance the field of artificial intelligence by promoting interdisciplinary research on the nature of intelligence. The workshop brought together computer scientists and biologists to share their insights about the nature of evolution and the future of evolutionary computation. In this report, we summarize each of the talks and the subsequent discussions. We also draw out a number of key themes and identify important frontiers for future research.

</p>
</details>

<details><summary><b>Test time Adaptation through Perturbation Robustness</b>
<a href="https://arxiv.org/abs/2110.10232">arxiv:2110.10232</a>
&#x1F4C8; 8 <br>
<p>Prabhu Teja Sivaprasad, François Fleuret</p></summary>
<p>

**Abstract:** Data samples generated by several real world processes are dynamic in nature \textit{i.e.}, their characteristics vary with time. Thus it is not possible to train and tackle all possible distributional shifts between training and inference, using the host of transfer learning methods in literature. In this paper, we tackle this problem of adapting to domain shift at inference time \textit{i.e.}, we do not change the training process, but quickly adapt the model at test-time to handle any domain shift. For this, we propose to enforce consistency of predictions of data sampled in the vicinity of test sample on the image manifold. On a host of test scenarios like dealing with corruptions (CIFAR-10-C and CIFAR-100-C), and domain adaptation (VisDA-C), our method is at par or significantly outperforms previous methods.

</p>
</details>

<details><summary><b>Continual self-training with bootstrapped remixing for speech enhancement</b>
<a href="https://arxiv.org/abs/2110.10103">arxiv:2110.10103</a>
&#x1F4C8; 8 <br>
<p>Efthymios Tzinis, Yossi Adi, Vamsi K. Ithapu, Buye Xu, Anurag Kumar</p></summary>
<p>

**Abstract:** We propose RemixIT, a simple and novel self-supervised training method for speech enhancement. The proposed method is based on a continuously self-training scheme that overcomes limitations from previous studies including assumptions for the in-domain noise distribution and having access to clean target signals. Specifically, a separation teacher model is pre-trained on an out-of-domain dataset and is used to infer estimated target signals for a batch of in-domain mixtures. Next, we bootstrap the mixing process by generating artificial mixtures using permuted estimated clean and noise signals. Finally, the student model is trained using the permuted estimated sources as targets while we periodically update teacher's weights using the latest student model. Our experiments show that RemixIT outperforms several previous state-of-the-art self-supervised methods under multiple speech enhancement tasks. Additionally, RemixIT provides a seamless alternative for semi-supervised and unsupervised domain adaptation for speech enhancement tasks, while being general enough to be applied to any separation task and paired with any separation model.

</p>
</details>

<details><summary><b>Multi-concept adversarial attacks</b>
<a href="https://arxiv.org/abs/2110.10287">arxiv:2110.10287</a>
&#x1F4C8; 7 <br>
<p>Vibha Belavadi, Yan Zhou, Murat Kantarcioglu, Bhavani M. Thuraisingham</p></summary>
<p>

**Abstract:** As machine learning (ML) techniques are being increasingly used in many applications, their vulnerability to adversarial attacks becomes well-known. Test time attacks, usually launched by adding adversarial noise to test instances, have been shown effective against the deployed ML models. In practice, one test input may be leveraged by different ML models. Test time attacks targeting a single ML model often neglect their impact on other ML models. In this work, we empirically demonstrate that naively attacking the classifier learning one concept may negatively impact classifiers trained to learn other concepts. For example, for the online image classification scenario, when the Gender classifier is under attack, the (wearing) Glasses classifier is simultaneously attacked with the accuracy dropped from 98.69 to 88.42. This raises an interesting question: is it possible to attack one set of classifiers without impacting the other set that uses the same test instance? Answers to the above research question have interesting implications for protecting privacy against ML model misuse. Attacking ML models that pose unnecessary risks of privacy invasion can be an important tool for protecting individuals from harmful privacy exploitation. In this paper, we address the above research question by developing novel attack techniques that can simultaneously attack one set of ML models while preserving the accuracy of the other. In the case of linear classifiers, we provide a theoretical framework for finding an optimal solution to generate such adversarial examples. Using this theoretical framework, we develop a multi-concept attack strategy in the context of deep learning. Our results demonstrate that our techniques can successfully attack the target classes while protecting the protected classes in many different settings, which is not possible with the existing test-time attack-single strategies.

</p>
</details>

<details><summary><b>StructFormer: Learning Spatial Structure for Language-Guided Semantic Rearrangement of Novel Objects</b>
<a href="https://arxiv.org/abs/2110.10189">arxiv:2110.10189</a>
&#x1F4C8; 7 <br>
<p>Weiyu Liu, Chris Paxton, Tucker Hermans, Dieter Fox</p></summary>
<p>

**Abstract:** Geometric organization of objects into semantically meaningful arrangements pervades the built world. As such, assistive robots operating in warehouses, offices, and homes would greatly benefit from the ability to recognize and rearrange objects into these semantically meaningful structures. To be useful, these robots must contend with previously unseen objects and receive instructions without significant programming. While previous works have examined recognizing pairwise semantic relations and sequential manipulation to change these simple relations none have shown the ability to arrange objects into complex structures such as circles or table settings. To address this problem we propose a novel transformer-based neural network, StructFormer, which takes as input a partial-view point cloud of the current object arrangement and a structured language command encoding the desired object configuration. We show through rigorous experiments that StructFormer enables a physical robot to rearrange novel objects into semantically meaningful structures with multi-object relational constraints inferred from the language command.

</p>
</details>

<details><summary><b>Online Continual Learning on Class Incremental Blurry Task Configuration with Anytime Inference</b>
<a href="https://arxiv.org/abs/2110.10031">arxiv:2110.10031</a>
&#x1F4C8; 7 <br>
<p>Hyunseo Koh, Dahyun Kim, Jung-Woo Ha, Jonghyun Choi</p></summary>
<p>

**Abstract:** Despite rapid advances in continual learning, a large body of research is devoted to improving performance in the existing setups. While a handful of work do propose new continual learning setups, they still lack practicality in certain aspects. For better practicality, we first propose a novel continual learning setup that is online, task-free, class-incremental, of blurry task boundaries and subject to inference queries at any moment. We additionally propose a new metric to better measure the performance of the continual learning methods subject to inference queries at any moment. To address the challenging setup and evaluation protocol, we propose an effective method that employs a new memory management scheme and novel learning techniques. Our empirical validation demonstrates that the proposed method outperforms prior arts by large margins.

</p>
</details>

<details><summary><b>Entity Relation Extraction as Dependency Parsing in Visually Rich Documents</b>
<a href="https://arxiv.org/abs/2110.09915">arxiv:2110.09915</a>
&#x1F4C8; 7 <br>
<p>Yue Zhang, Bo Zhang, Rui Wang, Junjie Cao, Chen Li, Zuyi Bao</p></summary>
<p>

**Abstract:** Previous works on key information extraction from visually rich documents (VRDs) mainly focus on labeling the text within each bounding box (i.e., semantic entity), while the relations in-between are largely unexplored. In this paper, we adapt the popular dependency parsing model, the biaffine parser, to this entity relation extraction task. Being different from the original dependency parsing model which recognizes dependency relations between words, we identify relations between groups of words with layout information instead. We have compared different representations of the semantic entity, different VRD encoders, and different relation decoders. The results demonstrate that our proposed model achieves 65.96% F1 score on the FUNSD dataset. As for the real-world application, our model has been applied to the in-house customs data, achieving reliable performance in the production setting.

</p>
</details>

<details><summary><b>Aesthetic Photo Collage with Deep Reinforcement Learning</b>
<a href="https://arxiv.org/abs/2110.09775">arxiv:2110.09775</a>
&#x1F4C8; 7 <br>
<p>Mingrui Zhang, Mading Li, Li Chen, Jiahao Yu</p></summary>
<p>

**Abstract:** Photo collage aims to automatically arrange multiple photos on a given canvas with high aesthetic quality. Existing methods are based mainly on handcrafted feature optimization, which cannot adequately capture high-level human aesthetic senses. Deep learning provides a promising way, but owing to the complexity of collage and lack of training data, a solution has yet to be found. In this paper, we propose a novel pipeline for automatic generation of aspect ratio specified collage and the reinforcement learning technique is introduced in collage for the first time. Inspired by manual collages, we model the collage generation as sequential decision process to adjust spatial positions, orientation angles, placement order and the global layout. To instruct the agent to improve both the overall layout and local details, the reward function is specially designed for collage, considering subjective and objective factors. To overcome the lack of training data, we pretrain our deep aesthetic network on a large scale image aesthetic dataset (CPC) for general aesthetic feature extraction and propose an attention fusion module for structural collage feature representation. We test our model against competing methods on two movie datasets and our results outperform others in aesthetic quality evaluation. Further user study is also conducted to demonstrate the effectiveness.

</p>
</details>

<details><summary><b>Nonparametric Sparse Tensor Factorization with Hierarchical Gamma Processes</b>
<a href="https://arxiv.org/abs/2110.10082">arxiv:2110.10082</a>
&#x1F4C8; 6 <br>
<p>Conor Tillinghast, Zheng Wang, Shandian Zhe</p></summary>
<p>

**Abstract:** We propose a nonparametric factorization approach for sparsely observed tensors. The sparsity does not mean zero-valued entries are massive or dominated. Rather, it implies the observed entries are very few, and even fewer with the growth of the tensor; this is ubiquitous in practice. Compared with the existent works, our model not only leverages the structural information underlying the observed entry indices, but also provides extra interpretability and flexibility -- it can simultaneously estimate a set of location factors about the intrinsic properties of the tensor nodes, and another set of sociability factors reflecting their extrovert activity in interacting with others; users are free to choose a trade-off between the two types of factors. Specifically, we use hierarchical Gamma processes and Poisson random measures to construct a tensor-valued process, which can freely sample the two types of factors to generate tensors and always guarantees an asymptotic sparsity. We then normalize the tensor process to obtain hierarchical Dirichlet processes to sample each observed entry index, and use a Gaussian process to sample the entry value as a nonlinear function of the factors, so as to capture both the sparse structure properties and complex node relationships. For efficient inference, we use Dirichlet process properties over finite sample partitions, density transformations, and random features to develop a stochastic variational estimation algorithm. We demonstrate the advantage of our method in several benchmark datasets.

</p>
</details>

<details><summary><b>Measuring Hidden Bias within Face Recognition via Racial Phenotypes</b>
<a href="https://arxiv.org/abs/2110.09839">arxiv:2110.09839</a>
&#x1F4C8; 6 <br>
<p>Seyma Yucer, Furkan Tektas, Noura Al Moubayed, Toby P. Breckon</p></summary>
<p>

**Abstract:** Recent work reports disparate performance for intersectional racial groups across face recognition tasks: face verification and identification. However, the definition of those racial groups has a significant impact on the underlying findings of such racial bias analysis. Previous studies define these groups based on either demographic information (e.g. African, Asian etc.) or skin tone (e.g. lighter or darker skins). The use of such sensitive or broad group definitions has disadvantages for bias investigation and subsequent counter-bias solutions design. By contrast, this study introduces an alternative racial bias analysis methodology via facial phenotype attributes for face recognition. We use the set of observable characteristics of an individual face where a race-related facial phenotype is hence specific to the human face and correlated to the racial profile of the subject. We propose categorical test cases to investigate the individual influence of those attributes on bias within face recognition tasks. We compare our phenotype-based grouping methodology with previous grouping strategies and show that phenotype-based groupings uncover hidden bias without reliance upon any potentially protected attributes or ill-defined grouping strategies. Furthermore, we contribute corresponding phenotype attribute category labels for two face recognition tasks: RFW for face verification and VGGFace2 (test set) for face identification.

</p>
</details>

<details><summary><b>Learning to Learn Graph Topologies</b>
<a href="https://arxiv.org/abs/2110.09807">arxiv:2110.09807</a>
&#x1F4C8; 6 <br>
<p>Xingyue Pu, Tianyue Cao, Xiaoyun Zhang, Xiaowen Dong, Siheng Chen</p></summary>
<p>

**Abstract:** Learning a graph topology to reveal the underlying relationship between data entities plays an important role in various machine learning and data analysis tasks. Under the assumption that structured data vary smoothly over a graph, the problem can be formulated as a regularised convex optimisation over a positive semidefinite cone and solved by iterative algorithms. Classic methods require an explicit convex function to reflect generic topological priors, e.g. the $\ell_1$ penalty for enforcing sparsity, which limits the flexibility and expressiveness in learning rich topological structures. We propose to learn a mapping from node data to the graph structure based on the idea of learning to optimise (L2O). Specifically, our model first unrolls an iterative primal-dual splitting algorithm into a neural network. The key structural proximal projection is replaced with a variational autoencoder that refines the estimated graph with enhanced topological properties. The model is trained in an end-to-end fashion with pairs of node data and graph samples. Experiments on both synthetic and real-world data demonstrate that our model is more efficient than classic iterative algorithms in learning a graph with specific topological properties.

</p>
</details>

<details><summary><b>Towards Toxic and Narcotic Medication Detection with Rotated Object Detector</b>
<a href="https://arxiv.org/abs/2110.09777">arxiv:2110.09777</a>
&#x1F4C8; 6 <br>
<p>Jiao Peng, Feifan Wang, Zhongqiang Fu, Yiying Hu, Zichen Chen, Xinghan Zhou, Lijun Wang</p></summary>
<p>

**Abstract:** Recent years have witnessed the advancement of deep learning vision technologies and applications in the medical industry. Intelligent devices for special medication management are in great need of, which requires more precise detection algorithms to identify the specifications and locations. In this work, YOLO (You only look once) based object detectors are tailored for toxic and narcotic medications detection tasks. Specifically, a more flexible annotation with rotated degree ranging from $0^\circ$ to $90^\circ$ and a mask-mapping-based non-maximum suppression method are proposed to achieve a feasible and efficient medication detector aiming at arbitrarily oriented bounding boxes. Extensive experiments demonstrate that the rotated YOLO detectors are more suitable for identifying densely arranged drugs. The best shot mean average precision of the proposed network reaches 0.811 while the inference time is less than 300ms.

</p>
</details>

<details><summary><b>EBJR: Energy-Based Joint Reasoning for Adaptive Inference</b>
<a href="https://arxiv.org/abs/2110.10343">arxiv:2110.10343</a>
&#x1F4C8; 5 <br>
<p>Mohammad Akbari, Amin Banitalebi-Dehkordi, Yong Zhang</p></summary>
<p>

**Abstract:** State-of-the-art deep learning models have achieved significant performance levels on various benchmarks. However, the excellent performance comes at a cost of inefficient computational cost. Light-weight architectures, on the other hand, achieve moderate accuracies, but at a much more desirable latency. This paper presents a new method of jointly using the large accurate models together with the small fast ones. To this end, we propose an Energy-Based Joint Reasoning (EBJR) framework that adaptively distributes the samples between shallow and deep models to achieve an accuracy close to the deep model, but latency close to the shallow one. Our method is applicable to out-of-the-box pre-trained models as it does not require an architecture change nor re-training. Moreover, it is easy to use and deploy, especially for cloud services. Through a comprehensive set of experiments on different down-stream tasks, we show that our method outperforms strong state-of-the-art approaches with a considerable margin. In addition, we propose specialized EBJR, an extension of our method where we create a smaller specialized side model that performs the target task only partially, but yields an even higher accuracy and faster inference. We verify the strengths of our methods with both theoretical and experimental evaluations.

</p>
</details>

<details><summary><b>Locally Differentially Private Reinforcement Learning for Linear Mixture Markov Decision Processes</b>
<a href="https://arxiv.org/abs/2110.10133">arxiv:2110.10133</a>
&#x1F4C8; 5 <br>
<p>Chonghua Liao, Jiafan He, Quanquan Gu</p></summary>
<p>

**Abstract:** Reinforcement learning (RL) algorithms can be used to provide personalized services, which rely on users' private and sensitive data. To protect the users' privacy, privacy-preserving RL algorithms are in demand. In this paper, we study RL with linear function approximation and local differential privacy (LDP) guarantees. We propose a novel $(\varepsilon, δ)$-LDP algorithm for learning a class of Markov decision processes (MDPs) dubbed linear mixture MDPs, and obtains an $\tilde{\mathcal{O}}( d^{5/4}H^{7/4}T^{3/4}\left(\log(1/δ)\right)^{1/4}\sqrt{1/\varepsilon})$ regret, where $d$ is the dimension of feature mapping, $H$ is the length of the planning horizon, and $T$ is the number of interactions with the environment. We also prove a lower bound $Ω(dH\sqrt{T}/\left(e^{\varepsilon}(e^{\varepsilon}-1)\right))$ for learning linear mixture MDPs under $\varepsilon$-LDP constraint. Experiments on synthetic datasets verify the effectiveness of our algorithm. To the best of our knowledge, this is the first provable privacy-preserving RL algorithm with linear function approximation.

</p>
</details>

<details><summary><b>Inductive Biases and Variable Creation in Self-Attention Mechanisms</b>
<a href="https://arxiv.org/abs/2110.10090">arxiv:2110.10090</a>
&#x1F4C8; 5 <br>
<p>Benjamin L. Edelman, Surbhi Goel, Sham Kakade, Cyril Zhang</p></summary>
<p>

**Abstract:** Self-attention, an architectural motif designed to model long-range interactions in sequential data, has driven numerous recent breakthroughs in natural language processing and beyond. This work provides a theoretical analysis of the inductive biases of self-attention modules, where our focus is to rigorously establish which functions and long-range dependencies self-attention blocks prefer to represent. Our main result shows that bounded-norm Transformer layers create sparse variables: they can represent sparse functions of the input sequence, with sample complexity scaling only logarithmically with the context length. Furthermore, we propose new experimental protocols to support this analysis and to guide the practice of training Transformers, built around the large body of work on provably learning sparse Boolean functions.

</p>
</details>

<details><summary><b>Stateful Offline Contextual Policy Evaluation and Learning</b>
<a href="https://arxiv.org/abs/2110.10081">arxiv:2110.10081</a>
&#x1F4C8; 5 <br>
<p>Nathan Kallus, Angela Zhou</p></summary>
<p>

**Abstract:** We study off-policy evaluation and learning from sequential data in a structured class of Markov decision processes that arise from repeated interactions with an exogenous sequence of arrivals with contexts, which generate unknown individual-level responses to agent actions. This model can be thought of as an offline generalization of contextual bandits with resource constraints. We formalize the relevant causal structure of problems such as dynamic personalized pricing and other operations management problems in the presence of potentially high-dimensional user types. The key insight is that an individual-level response is often not causally affected by the state variable and can therefore easily be generalized across timesteps and states. When this is true, we study implications for (doubly robust) off-policy evaluation and learning by instead leveraging single time-step evaluation, estimating the expectation over a single arrival via data from a population, for fitted-value iteration in a marginal MDP. We study sample complexity and analyze error amplification that leads to the persistence, rather than attenuation, of confounding error over time. In simulations of dynamic and capacitated pricing, we show improved out-of-sample policy performance in this class of relevant problems.

</p>
</details>

<details><summary><b>CORA: Benchmarks, Baselines, and Metrics as a Platform for Continual Reinforcement Learning Agents</b>
<a href="https://arxiv.org/abs/2110.10067">arxiv:2110.10067</a>
&#x1F4C8; 5 <br>
<p>Sam Powers, Eliot Xing, Eric Kolve, Roozbeh Mottaghi, Abhinav Gupta</p></summary>
<p>

**Abstract:** Progress in continual reinforcement learning has been limited due to several barriers to entry: missing code, high compute requirements, and a lack of suitable benchmarks. In this work, we present CORA, a platform for Continual Reinforcement Learning Agents that provides benchmarks, baselines, and metrics in a single code package. The benchmarks we provide are designed to evaluate different aspects of the continual RL challenge, such as catastrophic forgetting, plasticity, ability to generalize, and sample-efficient learning. Three of the benchmarks utilize video game environments (Atari, Procgen, NetHack). The fourth benchmark, CHORES, consists of four different task sequences in a visually realistic home simulator, drawn from a diverse set of task and scene parameters. To compare continual RL methods on these benchmarks, we prepare three metrics in CORA: continual evaluation, forgetting, and zero-shot forward transfer. Finally, CORA includes a set of performant, open-source baselines of existing algorithms for researchers to use and expand on. We release CORA and hope that the continual RL community can benefit from our contributions, to accelerate the development of new continual RL algorithms.

</p>
</details>

<details><summary><b>Fully Three-dimensional Radial Visualization</b>
<a href="https://arxiv.org/abs/2110.09971">arxiv:2110.09971</a>
&#x1F4C8; 5 <br>
<p>Yifan Zhu, Fan Dai, Ranjan Maitra</p></summary>
<p>

**Abstract:** We develop methodology for three-dimensional (3D) radial visualization (RadViz) of multidimensional datasets. The classical two-dimensional (2D) RadViz visualizes multivariate data in the 2D plane by mapping every observation to a point inside the unit circle. Our tool, RadViz3D, distributes anchor points uniformly on the 3D unit sphere. We show that this uniform distribution provides the best visualization with minimal artificial visual correlation for data with uncorrelated variables. However, anchor points can be placed exactly equi-distant from each other only for the five Platonic solids, so we provide equi-distant anchor points for these five settings, and approximately equi-distant anchor points via a Fibonacci grid for the other cases. Our methodology, implemented in the R package $radviz3d$, makes fully 3D RadViz possible and is shown to improve the ability of this nonlinear technique in more faithfully displaying simulated data as well as the crabs, olive oils and wine datasets. Additionally, because radial visualization is naturally suited for compositional data, we use RadViz3D to illustrate (i) the chemical composition of Longquan celadon ceramics and their Jingdezhen imitation over centuries, and (ii) US regional SARS-Cov-2 variants' prevalence in the Covid-19 pandemic during the summer 2021 surge of the Delta variant.

</p>
</details>

<details><summary><b>Using Program Synthesis and Inductive Logic Programming to solve Bongard Problems</b>
<a href="https://arxiv.org/abs/2110.09947">arxiv:2110.09947</a>
&#x1F4C8; 5 <br>
<p>Atharv Sonwane, Sharad Chitlangia, Tirtharaj Dash, Lovekesh Vig, Gautam Shroff, Ashwin Srinivasan</p></summary>
<p>

**Abstract:** The ability to recognise and make analogies is often used as a measure or test of human intelligence. The ability to solve Bongard problems is an example of such a test. It has also been postulated that the ability to rapidly construct novel abstractions is critical to being able to solve analogical problems. Given an image, the ability to construct a program that would generate that image is one form of abstraction, as exemplified in the Dreamcoder project. In this paper, we present a preliminary examination of whether programs constructed by Dreamcoder can be used for analogical reasoning to solve certain Bongard problems. We use Dreamcoder to discover programs that generate the images in a Bongard problem and represent each of these as a sequence of state transitions. We decorate the states using positional information in an automated manner and then encode the resulting sequence into logical facts in Prolog. We use inductive logic programming (ILP), to learn an (interpretable) theory for the abstract concept involved in an instance of a Bongard problem. Experiments on synthetically created Bongard problems for concepts such as 'above/below' and 'clockwise/counterclockwise' demonstrate that our end-to-end system can solve such problems. We study the importance and completeness of each component of our approach, highlighting its current limitations and pointing to directions for improvement in our formulation as well as in elements of any Dreamcoder-like program synthesis system used for such an approach.

</p>
</details>

<details><summary><b>Geo-DefakeHop: High-Performance Geographic Fake Image Detection</b>
<a href="https://arxiv.org/abs/2110.09795">arxiv:2110.09795</a>
&#x1F4C8; 5 <br>
<p>Hong-Shuo Chen, Kaitai Zhang, Shuowen Hu, Suya You, C. -C. Jay Kuo</p></summary>
<p>

**Abstract:** A robust fake satellite image detection method, called Geo-DefakeHop, is proposed in this work. Geo-DefakeHop is developed based on the parallel subspace learning (PSL) methodology. PSL maps the input image space into several feature subspaces using multiple filter banks. By exploring response differences of different channels between real and fake images for a filter bank, Geo-DefakeHop learns the most discriminant channels and uses their soft decision scores as features. Then, Geo-DefakeHop selects a few discriminant features from each filter bank and ensemble them to make a final binary decision. Geo-DefakeHop offers a light-weight high-performance solution to fake satellite images detection. Its model size is analyzed, which ranges from 0.8 to 62K parameters. Furthermore, it is shown by experimental results that it achieves an F1-score higher than 95\% under various common image manipulations such as resizing, compression and noise corruption.

</p>
</details>

<details><summary><b>SSAST: Self-Supervised Audio Spectrogram Transformer</b>
<a href="https://arxiv.org/abs/2110.09784">arxiv:2110.09784</a>
&#x1F4C8; 5 <br>
<p>Yuan Gong, Cheng-I Jeff Lai, Yu-An Chung, James Glass</p></summary>
<p>

**Abstract:** Recently, neural networks based purely on self-attention, such as the Vision Transformer (ViT), have been shown to outperform deep learning models constructed with convolutional neural networks (CNNs) on various vision tasks, thus extending the success of Transformers, which were originally developed for language processing, to the vision domain. A recent study showed that a similar methodology can also be applied to the audio domain. Specifically, the Audio Spectrogram Transformer (AST) achieves state-of-the-art results on various audio classification benchmarks. However, pure Transformer models tend to require more training data compared to CNNs, and the success of the AST relies on supervised pretraining that requires a large amount of labeled data and a complex training pipeline, thus limiting the practical usage of AST.
  This paper focuses on audio and speech classification, and aims to alleviate the data requirement issues with the AST by leveraging self-supervised learning using unlabeled data. Specifically, we propose to pretrain the AST model with joint discriminative and generative masked spectrogram patch modeling (MSPM) using unlabeled audio from AudioSet and Librispeech. We evaluate our pretrained models on both audio and speech classification tasks including audio event classification, keyword spotting, emotion recognition, and speaker identification. The proposed self-supervised framework significantly boosts AST performance on all tasks, with an average improvement of 60.9%, leading to similar or even better results than a supervised pretrained AST. To the best of our knowledge, it is the first patch-based self-supervised learning framework in the audio and speech domain, and also the first self-supervised learning framework for AST.

</p>
</details>

<details><summary><b>AEFE: Automatic Embedded Feature Engineering for Categorical Features</b>
<a href="https://arxiv.org/abs/2110.09770">arxiv:2110.09770</a>
&#x1F4C8; 5 <br>
<p>Zhenyuan Zhong, Jie Yang, Yacong Ma, Shoubin Dong, Jinlong Hu</p></summary>
<p>

**Abstract:** The challenge of solving data mining problems in e-commerce applications such as recommendation system (RS) and click-through rate (CTR) prediction is how to make inferences by constructing combinatorial features from a large number of categorical features while preserving the interpretability of the method. In this paper, we propose Automatic Embedded Feature Engineering(AEFE), an automatic feature engineering framework for representing categorical features, which consists of various components including custom paradigm feature construction and multiple feature selection. By selecting the potential field pairs intelligently and generating a series of interpretable combinatorial features, our framework can provide a set of unseen generated features for enhancing model performance and then assist data analysts in discovering the feature importance for particular data mining tasks. Furthermore, AEFE is distributed implemented by task-parallelism, data sampling, and searching schema based on Matrix Factorization field combination, to optimize the performance and enhance the efficiency and scalability of the framework. Experiments conducted on some typical e-commerce datasets indicate that our method outperforms the classical machine learning models and state-of-the-art deep learning models.

</p>
</details>

<details><summary><b>Trajectory Prediction with Linguistic Representations</b>
<a href="https://arxiv.org/abs/2110.09741">arxiv:2110.09741</a>
&#x1F4C8; 5 <br>
<p>Yen-Ling Kuo, Xin Huang, Andrei Barbu, Stephen G. McGill, Boris Katz, John J. Leonard, Guy Rosman</p></summary>
<p>

**Abstract:** Language allows humans to build mental models that interpret what is happening around them resulting in more accurate long-term predictions. We present a novel trajectory prediction model that uses linguistic intermediate representations to forecast trajectories, and is trained using trajectory samples with partially annotated captions. The model learns the meaning of each of the words without direct per-word supervision. At inference time, it generates a linguistic description of trajectories which captures maneuvers and interactions over an extended time interval. This generated description is used to refine predictions of the trajectories of multiple agents. We train and validate our model on the Argoverse dataset, and demonstrate improved accuracy results in trajectory prediction. In addition, our model is more interpretable: it presents part of its reasoning in plain language as captions, which can aid model development and can aid in building confidence in the model before deploying it.

</p>
</details>

<details><summary><b>Application of the Multi-label Residual Convolutional Neural Network text classifier using Content-Based Routing process</b>
<a href="https://arxiv.org/abs/2110.15801">arxiv:2110.15801</a>
&#x1F4C8; 4 <br>
<p>Tounsi Achraf, Elkefi Safa</p></summary>
<p>

**Abstract:** In this article, we will present an NLP application in text classifying process using the content-based router. The ultimate goal throughout this article is to predict the event described by a legal ad from the plain text of the ad. This problem is purely a supervised problem that will involve the use of NLP techniques and conventional modeling methodologies through the use of the Multi-label Residual Convolutional Neural Network for text classification. We will explain the approach put in place to solve the problem of classified ads, the difficulties encountered and the experimental results.

</p>
</details>

<details><summary><b>Social Media Reveals Urban-Rural Differences in Stress across China</b>
<a href="https://arxiv.org/abs/2110.15726">arxiv:2110.15726</a>
&#x1F4C8; 4 <br>
<p>Jesse Cui, Tingdan Zhang, Kokil Jaidka, Dandan Pang, Garrick Sherman, Vinit Jakhetiya, Lyle Ungar, Sharath Chandra Guntuku</p></summary>
<p>

**Abstract:** Modeling differential stress expressions in urban and rural regions in China can provide a better understanding of the effects of urbanization on psychological well-being in a country that has rapidly grown economically in the last two decades. This paper studies linguistic differences in the experiences and expressions of stress in urban-rural China from Weibo posts from over 65,000 users across 329 counties using hierarchical mixed-effects models. We analyzed phrases, topical themes, and psycho-linguistic word choices in Weibo posts mentioning stress to better understand appraisal differences surrounding psychological stress in urban and rural communities in China; we then compared them with large-scale polls from Gallup. After controlling for socioeconomic and gender differences, we found that rural communities tend to express stress in emotional and personal themes such as relationships, health, and opportunity while users in urban areas express stress using relative, temporal, and external themes such as work, politics, and economics. These differences exist beyond controlling for GDP and urbanization, indicating a fundamentally different lifestyle between rural and urban residents in very specific environments, arguably having different sources of stress. We found corroborative trends in physical, financial, and social wellness with urbanization in Gallup polls.

</p>
</details>

<details><summary><b>A Data-Driven Reconstruction Technique based on Newton's Method for Emission Tomography</b>
<a href="https://arxiv.org/abs/2110.11396">arxiv:2110.11396</a>
&#x1F4C8; 4 <br>
<p>Loizos Koutsantonis, Tiago Carneiro, Emmanuel Kieffer, Frederic Pinel, Pascal Bouvry</p></summary>
<p>

**Abstract:** In this work, we present the Deep Newton Reconstruction Network (DNR-Net), a hybrid data-driven reconstruction technique for emission tomography inspired by Newton's method, a well-known iterative optimization algorithm. The DNR-Net employs prior information about the tomographic problem provided by the projection operator while utilizing deep learning approaches to a) imitate Newton's method by approximating the Newton descent direction and b) provide data-driven regularisation. We demonstrate that DNR-Net is capable of providing high-quality image reconstructions using data from SPECT phantom simulations by applying it to reconstruct images from noisy sinograms, each one containing 24 projections. The Structural Similarity Index (SSIM) and the Contrast-to-Noise ratio (CNR) were used to quantify the image quality. We also compare our results to those obtained by the OSEM method. According to the quantitative results, the DNR-Net produces reconstructions comparable to the ones produced by OSEM while featuring higher contrast and less noise.

</p>
</details>

<details><summary><b>SOSP: Efficiently Capturing Global Correlations by Second-Order Structured Pruning</b>
<a href="https://arxiv.org/abs/2110.11395">arxiv:2110.11395</a>
&#x1F4C8; 4 <br>
<p>Manuel Nonnenmacher, Thomas Pfeil, Ingo Steinwart, David Reeb</p></summary>
<p>

**Abstract:** Pruning neural networks reduces inference time and memory costs. On standard hardware, these benefits will be especially prominent if coarse-grained structures, like feature maps, are pruned. We devise two novel saliency-based methods for second-order structured pruning (SOSP) which include correlations among all structures and layers. Our main method SOSP-H employs an innovative second-order approximation, which enables saliency evaluations by fast Hessian-vector products. SOSP-H thereby scales like a first-order method despite taking into account the full Hessian. We validate SOSP-H by comparing it to our second method SOSP-I that uses a well-established Hessian approximation, and to numerous state-of-the-art methods. While SOSP-H performs on par or better in terms of accuracy, it has clear advantages in terms of scalability and efficiency. This allowed us to scale SOSP-H to large-scale vision tasks, even though it captures correlations across all layers of the network. To underscore the global nature of our pruning methods, we evaluate their performance not only by removing structures from a pretrained network, but also by detecting architectural bottlenecks. We show that our algorithms allow to systematically reveal architectural bottlenecks, which we then remove to further increase the accuracy of the networks.

</p>
</details>

<details><summary><b>Model Composition: Can Multiple Neural Networks Be Combined into a Single Network Using Only Unlabeled Data?</b>
<a href="https://arxiv.org/abs/2110.10369">arxiv:2110.10369</a>
&#x1F4C8; 4 <br>
<p>Amin Banitalebi-Dehkordi, Xinyu Kang, Yong Zhang</p></summary>
<p>

**Abstract:** The diversity of deep learning applications, datasets, and neural network architectures necessitates a careful selection of the architecture and data that match best to a target application. As an attempt to mitigate this dilemma, this paper investigates the idea of combining multiple trained neural networks using unlabeled data. In addition, combining multiple models into one can speed up the inference, result in stronger, more capable models, and allows us to select efficient device-friendly target network architectures. To this end, the proposed method makes use of generation, filtering, and aggregation of reliable pseudo-labels collected from unlabeled data. Our method supports using an arbitrary number of input models with arbitrary architectures and categories. Extensive performance evaluations demonstrated that our method is very effective. For example, for the task of object detection and without using any ground-truth labels, an EfficientDet-D0 trained on Pascal-VOC and an EfficientDet-D1 trained on COCO, can be combined to a RetinaNet-ResNet50 model, with a similar mAP as the supervised training. If fine-tuned in a semi-supervised setting, the combined model achieves +18.6%, +12.6%, and +8.1% mAP improvements over supervised training with 1%, 5%, and 10% of labels.

</p>
</details>

<details><summary><b>Repaint: Improving the Generalization of Down-Stream Visual Tasks by Generating Multiple Instances of Training Examples</b>
<a href="https://arxiv.org/abs/2110.10366">arxiv:2110.10366</a>
&#x1F4C8; 4 <br>
<p>Amin Banitalebi-Dehkordi, Yong Zhang</p></summary>
<p>

**Abstract:** Convolutional Neural Networks (CNNs) for visual tasks are believed to learn both the low-level textures and high-level object attributes, throughout the network depth. This paper further investigates the `texture bias' in CNNs. To this end, we regenerate multiple instances of training examples from each original image, through a process we call `repainting'. The repainted examples preserve the shape and structure of the regions and objects within the scenes, but diversify their texture and color. Our method can regenerate a same image at different daylight, season, or weather conditions, can have colorization or de-colorization effects, or even bring back some texture information from blacked-out areas. The in-place repaint allows us to further use these repainted examples for improving the generalization of CNNs. Through an extensive set of experiments, we demonstrate the usefulness of the repainted examples in training, for the tasks of image classification (ImageNet) and object detection (COCO), over several state-of-the-art network architectures at different capacities, and across different data availability regimes.

</p>
</details>

<details><summary><b>On Coordinate Decoding for Keypoint Estimation Tasks</b>
<a href="https://arxiv.org/abs/2110.10289">arxiv:2110.10289</a>
&#x1F4C8; 4 <br>
<p>Anargyros Chatzitofis, Nikolaos Zioulis, Georgios Nikolaos Albanis, Dimitrios Zarpalas, Petros Daras</p></summary>
<p>

**Abstract:** A series of 2D (and 3D) keypoint estimation tasks are built upon heatmap coordinate representation, i.e. a probability map that allows for learnable and spatially aware encoding and decoding of keypoint coordinates on grids, even allowing for sub-pixel coordinate accuracy. In this report, we aim to reproduce the findings of DARK that investigated the 2D heatmap representation by highlighting the importance of the encoding of the ground truth heatmap and the decoding of the predicted heatmap to keypoint coordinates. The authors claim that a) a more principled distribution-aware coordinate decoding method overcomes the limitations of the standard techniques widely used in the literature, and b), that the reconstruction of heatmaps from ground-truth coordinates by generating accurate and continuous heatmap distributions lead to unbiased model training, contrary to the standard coordinate encoding process that quantizes the keypoint coordinates on the resolution of the input image grid.

</p>
</details>

<details><summary><b>GenNI: Human-AI Collaboration for Data-Backed Text Generation</b>
<a href="https://arxiv.org/abs/2110.10185">arxiv:2110.10185</a>
&#x1F4C8; 4 <br>
<p>Hendrik Strobelt, Jambay Kinley, Robert Krueger, Johanna Beyer, Hanspeter Pfister, Alexander M. Rush</p></summary>
<p>

**Abstract:** Table2Text systems generate textual output based on structured data utilizing machine learning. These systems are essential for fluent natural language interfaces in tools such as virtual assistants; however, left to generate freely these ML systems often produce misleading or unexpected outputs. GenNI (Generation Negotiation Interface) is an interactive visual system for high-level human-AI collaboration in producing descriptive text. The tool utilizes a deep learning model designed with explicit control states. These controls allow users to globally constrain model generations, without sacrificing the representation power of the deep learning models. The visual interface makes it possible for users to interact with AI systems following a Refine-Forecast paradigm to ensure that the generation system acts in a manner human users find suitable. We report multiple use cases on two experiments that improve over uncontrolled generation approaches, while at the same time providing fine-grained control. A demo and source code are available at https://genni.vizhub.ai .

</p>
</details>

<details><summary><b>Stochastic Primal-Dual Deep Unrolling Networks for Imaging Inverse Problems</b>
<a href="https://arxiv.org/abs/2110.10093">arxiv:2110.10093</a>
&#x1F4C8; 4 <br>
<p>Junqi Tang, Subhadip Mukherjee, Carola-Bibiane Schönlieb</p></summary>
<p>

**Abstract:** In this work we propose a new type of efficient deep-unrolling networks for solving imaging inverse problems. Classical deep-unrolling methods require full forward operator and its adjoint across each layer, and hence can be computationally more expensive than other end-to-end methods such as FBP-ConvNet, especially in 3D image reconstruction tasks. We propose a stochastic (ordered-subsets) extension of the Learned Primal-Dual (LPD) which is a state-of-the-art unrolling network. In our unrolling network, we only use subsets of the forward and adjoint operator, to achieve computational efficiency. We provide theoretical analysis of a special case within our LSPD framework, suggesting that our LSPD network has the potential to achieve the same accuracy of full batch LPD network with only accessing the subsets of operators. Our numerical results demonstrate the effectiveness of our approach in X-ray CT imaging task, showing that our networks achieve similar reconstruction accuracies as the full-batch LPD, while requiring only a fraction of the computation.

</p>
</details>

<details><summary><b>On Clustering Categories of Categorical Predictors in Generalized Linear Models</b>
<a href="https://arxiv.org/abs/2110.10059">arxiv:2110.10059</a>
&#x1F4C8; 4 <br>
<p>Emilio Carrizosa, Marcela Galvis Restrepo, Dolores Romero Morales</p></summary>
<p>

**Abstract:** We propose a method to reduce the complexity of Generalized Linear Models in the presence of categorical predictors. The traditional one-hot encoding, where each category is represented by a dummy variable, can be wasteful, difficult to interpret, and prone to overfitting, especially when dealing with high-cardinality categorical predictors. This paper addresses these challenges by finding a reduced representation of the categorical predictors by clustering their categories. This is done through a numerical method which aims to preserve (or even, improve) accuracy, while reducing the number of coefficients to be estimated for the categorical predictors. Thanks to its design, we are able to derive a proximity measure between categories of a categorical predictor that can be easily visualized. We illustrate the performance of our approach in real-world classification and count-data datasets where we see that clustering the categorical predictors reduces complexity substantially without harming accuracy.

</p>
</details>

<details><summary><b>DEEPAGÉ: Answering Questions in Portuguese about the Brazilian Environment</b>
<a href="https://arxiv.org/abs/2110.10015">arxiv:2110.10015</a>
&#x1F4C8; 4 <br>
<p>Flávio Nakasato Cação, Marcos Menon José, André Seidel Oliveira, Stefano Spindola, Anna Helena Reali Costa, Fábio Gagliardi Cozman</p></summary>
<p>

**Abstract:** The challenge of climate change and biome conservation is one of the most pressing issues of our time - particularly in Brazil, where key environmental reserves are located. Given the availability of large textual databases on ecological themes, it is natural to resort to question answering (QA) systems to increase social awareness and understanding about these topics. In this work, we introduce multiple QA systems that combine in novel ways the BM25 algorithm, a sparse retrieval technique, with PTT5, a pre-trained state-of-the-art language model. Our QA systems focus on the Portuguese language, thus offering resources not found elsewhere in the literature. As training data, we collected questions from open-domain datasets, as well as content from the Portuguese Wikipedia and news from the press. We thus contribute with innovative architectures and novel applications, attaining an F1-score of 36.2 with our best model.

</p>
</details>

<details><summary><b>ERQA: Edge-Restoration Quality Assessment for Video Super-Resolution</b>
<a href="https://arxiv.org/abs/2110.09992">arxiv:2110.09992</a>
&#x1F4C8; 4 <br>
<p>Anastasia Kirillova, Eugene Lyapustin, Anastasia Antsiferova, Dmitry Vatolin</p></summary>
<p>

**Abstract:** Despite the growing popularity of video super-resolution (VSR), there is still no good way to assess the quality of the restored details in upscaled frames. Some SR methods may produce the wrong digit or an entirely different face. Whether a method's results are trustworthy depends on how well it restores truthful details. Image super-resolution can use natural distributions to produce a high-resolution image that is only somewhat similar to the real one. VSR enables exploration of additional information in neighboring frames to restore details from the original scene. The ERQA metric, which we propose in this paper, aims to estimate a model's ability to restore real details using VSR. On the assumption that edges are significant for detail and character recognition, we chose edge fidelity as the foundation for this metric. Experimental validation of our work is based on the MSU Video Super-Resolution Benchmark, which includes the most difficult patterns for detail restoration and verifies the fidelity of details from the original frame. Code for the proposed metric is publicly available at https://github.com/msu-video-group/ERQA.

</p>
</details>

<details><summary><b>Bilateral-ViT for Robust Fovea Localization</b>
<a href="https://arxiv.org/abs/2110.09860">arxiv:2110.09860</a>
&#x1F4C8; 4 <br>
<p>Sifan Song, Kang Dang, Qinji Yu, Zilong Wang, Frans Coenen, Jionglong Su, Xiaowei Ding</p></summary>
<p>

**Abstract:** The fovea is an important anatomical landmark of the retina. Detecting the location of the fovea is essential for the analysis of many retinal diseases. However, robust fovea localization remains a challenging problem, as the fovea region often appears fuzzy, and retina diseases may further obscure its appearance. This paper proposes a novel vision transformer (ViT) approach that integrates information both inside and outside the fovea region to achieve robust fovea localization. Our proposed network named Bilateral-Vision-Transformer (Bilateral-ViT) consists of two network branches: a transformer-based main network branch for integrating global context across the entire fundus image and a vessel branch for explicitly incorporating the structure of blood vessels. The encoded features from both network branches are subsequently merged with a customized multi-scale feature fusion (MFF) module. Our comprehensive experiments demonstrate that the proposed approach is significantly more robust for diseased images and establishes the new state of the arts on both Messidor and PALM datasets.

</p>
</details>

<details><summary><b>Cutting Voxel Projector a New Approach to Construct 3D Cone Beam CT Operator</b>
<a href="https://arxiv.org/abs/2110.09841">arxiv:2110.09841</a>
&#x1F4C8; 4 <br>
<p>Vojtěch Kulvait, Georg Rose</p></summary>
<p>

**Abstract:** In this paper, we introduce a new class of projectors for 3D cone beam tomographic reconstruction. We find analytical formulas for the relationship between the voxel volume projected onto a given detector pixel and its contribution to the extinction value detected on that pixel. Using this approach, we construct a near-exact projector and backprojector that can be used especially for algebraic reconstruction techniques. We have implemented this cutting voxel projector and a less accurate, speed-optimized version of it together with two established projectors, a ray tracing projector based on Siddon's algorithm and a TT footprint projector. We show that the cutting voxel projector achieves, especially for large cone beam angles, noticeably higher accuracy than the TT projector. Moreover, our implementation of the relaxed version of the cutting voxel projector is significantly faster than current footprint projector implementations. We further show that Siddon's algorithm with comparable accuracy would be much slower than the cutting voxel projector. All algorithms are implemented within an open source framework for algebraic reconstruction in OpenCL 1.2 and C++ and are optimized for GPU computation. They are published as open-source software under the GNU GPL 3 license, see https://github.com/kulvait/KCT_cbct.

</p>
</details>

<details><summary><b>Microstructure reconstruction via artificial neural networks: A combination of causal and non-causal approach</b>
<a href="https://arxiv.org/abs/2110.09815">arxiv:2110.09815</a>
&#x1F4C8; 4 <br>
<p>Kryštof Latka, Martin Doškář, Jan Zeman</p></summary>
<p>

**Abstract:** We investigate the applicability of artificial neural networks (ANNs) in reconstructing a sample image of a sponge-like microstructure. We propose to reconstruct the image by predicting the phase of the current pixel based on its causal neighbourhood, and subsequently, use a non-causal ANN model to smooth out the reconstructed image as a form of post-processing. We also consider the impacts of different configurations of the ANN model (e.g. number of densely connected layers, number of neurons in each layer, the size of both the causal and non-causal neighbourhood) on the models' predictive abilities quantified by the discrepancy between the spatial statistics of the reference and the reconstructed sample.

</p>
</details>

<details><summary><b>Offline Reinforcement Learning with Value-based Episodic Memory</b>
<a href="https://arxiv.org/abs/2110.09796">arxiv:2110.09796</a>
&#x1F4C8; 4 <br>
<p>Xiaoteng Ma, Yiqin Yang, Hao Hu, Qihan Liu, Jun Yang, Chongjie Zhang, Qianchuan Zhao, Bin Liang</p></summary>
<p>

**Abstract:** Offline reinforcement learning (RL) shows promise of applying RL to real-world problems by effectively utilizing previously collected data. Most existing offline RL algorithms use regularization or constraints to suppress extrapolation error for actions outside the dataset. In this paper, we adopt a different framework, which learns the V-function instead of the Q-function to naturally keep the learning procedure within the support of an offline dataset. To enable effective generalization while maintaining proper conservatism in offline learning, we propose Expectile V-Learning (EVL), which smoothly interpolates between the optimal value learning and behavior cloning. Further, we introduce implicit planning along offline trajectories to enhance learned V-values and accelerate convergence. Together, we present a new offline method called Value-based Episodic Memory (VEM). We provide theoretical analysis for the convergence properties of our proposed VEM method, and empirical results in the D4RL benchmark show that our method achieves superior performance in most tasks, particularly in sparse-reward tasks.

</p>
</details>

<details><summary><b>On Reward-Free RL with Kernel and Neural Function Approximations: Single-Agent MDP and Markov Game</b>
<a href="https://arxiv.org/abs/2110.09771">arxiv:2110.09771</a>
&#x1F4C8; 4 <br>
<p>Shuang Qiu, Jieping Ye, Zhaoran Wang, Zhuoran Yang</p></summary>
<p>

**Abstract:** To achieve sample efficiency in reinforcement learning (RL), it necessitates efficiently exploring the underlying environment. Under the offline setting, addressing the exploration challenge lies in collecting an offline dataset with sufficient coverage. Motivated by such a challenge, we study the reward-free RL problem, where an agent aims to thoroughly explore the environment without any pre-specified reward function. Then, given any extrinsic reward, the agent computes the policy via a planning algorithm with offline data collected in the exploration phase. Moreover, we tackle this problem under the context of function approximation, leveraging powerful function approximators.
  Specifically, we propose to explore via an optimistic variant of the value-iteration algorithm incorporating kernel and neural function approximations, where we adopt the associated exploration bonus as the exploration reward. Moreover, we design exploration and planning algorithms for both single-agent MDPs and zero-sum Markov games and prove that our methods can achieve $\widetilde{\mathcal{O}}(1 /\varepsilon^2)$ sample complexity for generating a $\varepsilon$-suboptimal policy or $\varepsilon$-approximate Nash equilibrium when given an arbitrary extrinsic reward. To the best of our knowledge, we establish the first provably efficient reward-free RL algorithm with kernel and neural function approximators.

</p>
</details>

<details><summary><b>A Regularization Method to Improve Adversarial Robustness of Neural Networks for ECG Signal Classification</b>
<a href="https://arxiv.org/abs/2110.09759">arxiv:2110.09759</a>
&#x1F4C8; 4 <br>
<p>Linhai Ma, Liang Liang</p></summary>
<p>

**Abstract:** Electrocardiogram (ECG) is the most widely used diagnostic tool to monitor the condition of the human heart. By using deep neural networks (DNNs), interpretation of ECG signals can be fully automated for the identification of potential abnormalities in a patient's heart in a fraction of a second. Studies have shown that given a sufficiently large amount of training data, DNN accuracy for ECG classification could reach human-expert cardiologist level. However, despite of the excellent performance in classification accuracy, DNNs are highly vulnerable to adversarial noises that are subtle changes in the input of a DNN and may lead to a wrong class-label prediction. It is challenging and essential to improve robustness of DNNs against adversarial noises, which are a threat to life-critical applications. In this work, we proposed a regularization method to improve DNN robustness from the perspective of noise-to-signal ratio (NSR) for the application of ECG signal classification. We evaluated our method on PhysioNet MIT-BIH dataset and CPSC2018 ECG dataset, and the results show that our method can substantially enhance DNN robustness against adversarial noises generated from adversarial attacks, with a minimal change in accuracy on clean data.

</p>
</details>

<details><summary><b>The network signature of constellation line figures</b>
<a href="https://arxiv.org/abs/2110.12329">arxiv:2110.12329</a>
&#x1F4C8; 3 <br>
<p>Doina Bucur</p></summary>
<p>

**Abstract:** In traditional astronomies across the world, groups of stars in the night sky were linked into constellations -- symbolic representations on the celestial sphere, rich in meaning and with practical roles. In some cultures, constellations are represented as line or connect-the-dot figures, which are spatial networks constrained to the fixed background of stars, but free in their choice of stars and lines. We first define the visual signature of a constellation: a rich, multi-dimensional complexity metric capturing network, spatial, and brightness features. We then answer the questions: are cultures, types of culture, or sky regions strongly associated with the visual signature of their line figures, and thus may have determined their shape? We analyse 1591 line figures from 50 astronomical cultures spanning all continents and a long history, find that the line figures form seven distinct clusters by their closeness in visual signature, and draw the following conclusions. Few individual cultures have unique visual signatures. Oral astronomies are diverse in network and spatial features but use brighter stars. Constellations used for navigation, religious divination, and agrarian/hunter-gatherer time-keeping are similar, but constellations from Chinese and Mesopotamian ancestries have a distinct visual signature. We find clear clusters of cross-culture similarity, with SE Asian traditions far apart from Mesopotamian, N and S American, Austronesian and Polynesian traditions. We also find broad visual signatures in many sky regions: there are diverse line designs around the majority of widely used stars.

</p>
</details>

<details><summary><b>Distributionally Robust Classifiers in Sentiment Analysis</b>
<a href="https://arxiv.org/abs/2110.10372">arxiv:2110.10372</a>
&#x1F4C8; 3 <br>
<p>Shilun Li, Renee Li, Carina Zhang</p></summary>
<p>

**Abstract:** In this paper, we propose sentiment classification models based on BERT integrated with DRO (Distributionally Robust Classifiers) to improve model performance on datasets with distributional shifts. We added 2-Layer Bi-LSTM, projection layer (onto simplex or Lp ball), and linear layer on top of BERT to achieve distributionally robustness. We considered one form of distributional shift (from IMDb dataset to Rotten Tomatoes dataset). We have confirmed through experiments that our DRO model does improve performance on our test set with distributional shift from the training set.

</p>
</details>

<details><summary><b>ABC: Auxiliary Balanced Classifier for Class-imbalanced Semi-supervised Learning</b>
<a href="https://arxiv.org/abs/2110.10368">arxiv:2110.10368</a>
&#x1F4C8; 3 <br>
<p>Hyuck Lee, Seungjae Shin, Heeyoung Kim</p></summary>
<p>

**Abstract:** Existing semi-supervised learning (SSL) algorithms typically assume class-balanced datasets, although the class distributions of many real-world datasets are imbalanced. In general, classifiers trained on a class-imbalanced dataset are biased toward the majority classes. This issue becomes more problematic for SSL algorithms because they utilize the biased prediction of unlabeled data for training. However, traditional class-imbalanced learning techniques, which are designed for labeled data, cannot be readily combined with SSL algorithms. We propose a scalable class-imbalanced SSL algorithm that can effectively use unlabeled data, while mitigating class imbalance by introducing an auxiliary balanced classifier (ABC) of a single layer, which is attached to a representation layer of an existing SSL algorithm. The ABC is trained with a class-balanced loss of a minibatch, while using high-quality representations learned from all data points in the minibatch using the backbone SSL algorithm to avoid overfitting and information loss.Moreover, we use consistency regularization, a recent SSL technique for utilizing unlabeled data in a modified way, to train the ABC to be balanced among the classes by selecting unlabeled data with the same probability for each class. The proposed algorithm achieves state-of-the-art performance in various class-imbalanced SSL experiments using four benchmark datasets.

</p>
</details>

<details><summary><b>Detecting Backdoor Attacks Against Point Cloud Classifiers</b>
<a href="https://arxiv.org/abs/2110.10354">arxiv:2110.10354</a>
&#x1F4C8; 3 <br>
<p>Zhen Xiang, David J. Miller, Siheng Chen, Xi Li, George Kesidis</p></summary>
<p>

**Abstract:** Backdoor attacks (BA) are an emerging threat to deep neural network classifiers. A classifier being attacked will predict to the attacker's target class when a test sample from a source class is embedded with the backdoor pattern (BP). Recently, the first BA against point cloud (PC) classifiers was proposed, creating new threats to many important applications including autonomous driving. Such PC BAs are not detectable by existing BA defenses due to their special BP embedding mechanism. In this paper, we propose a reverse-engineering defense that infers whether a PC classifier is backdoor attacked, without access to its training set or to any clean classifiers for reference. The effectiveness of our defense is demonstrated on the benchmark ModeNet40 dataset for PCs.

</p>
</details>

<details><summary><b>Computational Graph Completion</b>
<a href="https://arxiv.org/abs/2110.10323">arxiv:2110.10323</a>
&#x1F4C8; 3 <br>
<p>Houman Owhadi</p></summary>
<p>

**Abstract:** We introduce a framework for generating, organizing, and reasoning with computational knowledge. It is motivated by the observation that most problems in Computational Sciences and Engineering (CSE) can be described as that of completing (from data) a computational graph representing dependencies between functions and variables. Functions and variables may be known, unknown, or random. Data comes in the form of observations of distinct values of a finite number of subsets of the variables of the graph. The underlying problem combines a regression problem (approximating unknown functions) with a matrix completion problem (recovering unobserved variables in the data). Replacing unknown functions by Gaussian Processes (GPs) and conditioning on observed data provides a simple but efficient approach to completing such graphs. Since the proposed framework is highly expressive, it has a vast potential application scope. Since the completion process can be automatized, as one solves $\sqrt{\sqrt{2}+\sqrt{3}}$ on a pocket calculator without thinking about it, one could, with the proposed framework, solve a complex CSE problem by drawing a diagram. Compared to traditional kriging, the proposed framework can be used to recover unknown functions with much scarcer data by exploiting interdependencies between multiple functions and variables. The Computational Graph Completion (CGC) problem addressed by the proposed framework could therefore also be interpreted as a generalization of that of solving linear systems of equations to that of approximating unknown variables and functions with noisy, incomplete, and nonlinear dependencies. Numerous examples illustrate the flexibility, scope, efficacy, and robustness of the CGC framework and show how it can be used as a pathway to identifying simple solutions to classical CSE problems (digital twin modeling, dimension reduction, mode decomposition, etc.).

</p>
</details>

<details><summary><b>Improved Multilingual Language Model Pretraining for Social Media Text via Translation Pair Prediction</b>
<a href="https://arxiv.org/abs/2110.10318">arxiv:2110.10318</a>
&#x1F4C8; 3 <br>
<p>Shubhanshu Mishra, Aria Haghighi</p></summary>
<p>

**Abstract:** We evaluate a simple approach to improving zero-shot multilingual transfer of mBERT on social media corpus by adding a pretraining task called translation pair prediction (TPP), which predicts whether a pair of cross-lingual texts are a valid translation. Our approach assumes access to translations (exact or approximate) between source-target language pairs, where we fine-tune a model on source language task data and evaluate the model in the target language. In particular, we focus on language pairs where transfer learning is difficult for mBERT: those where source and target languages are different in script, vocabulary, and linguistic typology. We show improvements from TPP pretraining over mBERT alone in zero-shot transfer from English to Hindi, Arabic, and Japanese on two social media tasks: NER (a 37% average relative improvement in F1 across target languages) and sentiment classification (12% relative improvement in F1) on social media text, while also benchmarking on a non-social media task of Universal Dependency POS tagging (6.7% relative improvement in accuracy). Our results are promising given the lack of social media bitext corpus. Our code can be found at: https://github.com/twitter-research/multilingual-alignment-tpp.

</p>
</details>

<details><summary><b>Momentum Contrastive Autoencoder: Using Contrastive Learning for Latent Space Distribution Matching in WAE</b>
<a href="https://arxiv.org/abs/2110.10303">arxiv:2110.10303</a>
&#x1F4C8; 3 <br>
<p>Devansh Arpit,  Aadyot,  Bhatnagar, Huan Wang, Caiming Xiong</p></summary>
<p>

**Abstract:** Wasserstein autoencoder (WAE) shows that matching two distributions is equivalent to minimizing a simple autoencoder (AE) loss under the constraint that the latent space of this AE matches a pre-specified prior distribution. This latent space distribution matching is a core component of WAE, and a challenging task. In this paper, we propose to use the contrastive learning framework that has been shown to be effective for self-supervised representation learning, as a means to resolve this problem. We do so by exploiting the fact that contrastive learning objectives optimize the latent space distribution to be uniform over the unit hyper-sphere, which can be easily sampled from. We show that using the contrastive learning framework to optimize the WAE loss achieves faster convergence and more stable optimization compared with existing popular algorithms for WAE. This is also reflected in the FID scores on CelebA and CIFAR-10 datasets, and the realistic generated image quality on the CelebA-HQ dataset.

</p>
</details>

<details><summary><b>Learning Rich Nearest Neighbor Representations from Self-supervised Ensembles</b>
<a href="https://arxiv.org/abs/2110.10293">arxiv:2110.10293</a>
&#x1F4C8; 3 <br>
<p>Bram Wallace, Devansh Arpit, Huan Wang, Caiming Xiong</p></summary>
<p>

**Abstract:** Pretraining convolutional neural networks via self-supervision, and applying them in transfer learning, is an incredibly fast-growing field that is rapidly and iteratively improving performance across practically all image domains. Meanwhile, model ensembling is one of the most universally applicable techniques in supervised learning literature and practice, offering a simple solution to reliably improve performance. But how to optimally combine self-supervised models to maximize representation quality has largely remained unaddressed. In this work, we provide a framework to perform self-supervised model ensembling via a novel method of learning representations directly through gradient descent at inference time. This technique improves representation quality, as measured by k-nearest neighbors, both on the in-domain dataset and in the transfer setting, with models transferable from the former setting to the latter. Additionally, this direct learning of feature through backpropagation improves representations from even a single model, echoing the improvements found in self-distillation.

</p>
</details>

<details><summary><b>Early- and in-season crop type mapping without current-year ground truth: generating labels from historical information via a topology-based approach</b>
<a href="https://arxiv.org/abs/2110.10275">arxiv:2110.10275</a>
&#x1F4C8; 3 <br>
<p>Chenxi Lin, Liheng Zhong, Xiao-Peng Song, Jinwei Dong, David B. Lobell, Zhenong Jin</p></summary>
<p>

**Abstract:** Land cover classification in remote sensing is often faced with the challenge of limited ground truth. Incorporating historical information has the potential to significantly lower the expensive cost associated with collecting ground truth and, more importantly, enable early- and in-season mapping that is helpful to many pre-harvest decisions. In this study, we propose a new approach that can effectively transfer knowledge about the topology (i.e. relative position) of different crop types in the spectral feature space (e.g. the histogram of SWIR1 vs RDEG1 bands) to generate labels, thereby support crop classification in a different year. Importantly, our approach does not attempt to transfer classification decision boundaries that are susceptible to inter-annual variations of weather and management, but relies on the more robust and shift-invariant topology information. We tested this approach for mapping corn/soybeans in the US Midwest and paddy rice/corn/soybeans in Northeast China using Landsat-8 and Sentinel-2 data. Results show that our approach automatically generates high-quality labels for crops in the target year immediately after each image becomes available. Based on these generated labels from our approach, the subsequent crop type mapping using a random forest classifier reach the F1 score as high as 0.887 for corn as early as the silking stage and 0.851 for soybean as early as the flowering stage and the overall accuracy of 0.873 in Iowa. In Northeast China, F1 scores of paddy rice, corn and soybeans and the overall accuracy can exceed 0.85 two and half months ahead of harvest. Overall, these results highlight unique advantages of our approach in transferring historical knowledge and maximizing the timeliness of crop maps. Our approach supports a general paradigm shift towards learning transferrable and generalizable knowledge to facilitate land cover classification.

</p>
</details>

<details><summary><b>A New Automatic Change Detection Frame-work Based on Region Growing and Weighted Local Mutual Information: Analysis of Breast Tumor Response to Chemotherapy in Serial MR Images</b>
<a href="https://arxiv.org/abs/2110.10242">arxiv:2110.10242</a>
&#x1F4C8; 3 <br>
<p>Narges Norouzi, Reza Azmi, Nooshin Noshiri, Robab Anbiaee</p></summary>
<p>

**Abstract:** The automatic analysis of subtle changes between longitudinal MR images is an important task as it is still a challenging issue in scope of the breast medical image processing. In this paper we propose an effective automatic change detection framework composed of two phases since previously used methods have features with low distinctive power. First, in the preprocessing phase an intensity normalization method is suggested based on Hierarchical Histogram Matching (HHM) that is more robust to noise than previous methods. To eliminate undesirable changes and extract the regions containing significant changes the proposed Extraction Region of Changes (EROC) method is applied based on intensity distribution and Hill-Climbing algorithm. Second, in the detection phase a region growing-based approach is suggested to differentiate significant changes from unreal ones. Due to using proposed Weighted Local Mutual Information (WLMI) method to extract high level features and also utilizing the principle of the local consistency of changes, the proposed approach enjoys reasonable performance. The experimental results on both simulated and real longitudinal Breast MR Images confirm the effectiveness of the proposed framework. Also, this framework outperforms the human expert in some cases which can detect many lesion evolutions that are missed by expert.

</p>
</details>

<details><summary><b>Learning Equivariances and Partial Equivariances from Data</b>
<a href="https://arxiv.org/abs/2110.10211">arxiv:2110.10211</a>
&#x1F4C8; 3 <br>
<p>David W. Romero, Suhas Lohit</p></summary>
<p>

**Abstract:** Group equivariant Convolutional Neural Networks (G-CNNs) constrain features to respect the chosen symmetries, and lead to better generalization when these symmetries appear in the data. However, if the chosen symmetries are not present, group equivariant architectures lead to overly constrained models and worse performance. Frequently, the distribution of the data can be better represented by a subset of a group than by the group as a whole, e.g., rotations in $[-90^{\circ}, 90^{\circ}]$. In such cases, a model that respects equivariance partially is better suited to represent the data. Moreover, relevant symmetries may differ for low and high-level features, e.g., edge orientations in a face, and face poses relative to the camera. As a result, the optimal level of equivariance may differ per layer. In this work, we introduce Partial G-CNNs: a family of equivariant networks able to learn partial and full equivariances from data at every layer end-to-end. Partial G-CNNs retain full equivariance whenever beneficial, e.g., for rotated MNIST, but are able to restrict it whenever it becomes harmful, e.g., for 6~/~9 or natural image classification. Partial G-CNNs perform on par with G-CNNs when full equivariance is necessary, and outperform them otherwise. Our method is applicable to discrete groups, continuous groups and combinations thereof.

</p>
</details>

<details><summary><b>fairadapt: Causal Reasoning for Fair Data Pre-processing</b>
<a href="https://arxiv.org/abs/2110.10200">arxiv:2110.10200</a>
&#x1F4C8; 3 <br>
<p>Drago Plečko, Nicolas Bennett, Nicolai Meinshausen</p></summary>
<p>

**Abstract:** Machine learning algorithms are useful for various predictions tasks, but they can also learn how to discriminate, based on gender, race or other sensitive attributes. This realization gave rise to the field of fair machine learning, which aims to measure and mitigate such algorithmic bias. This manuscript describes the R-package fairadapt, which implements a causal inference pre-processing method. By making use of a causal graphical model and the observed data, the method can be used to address hypothetical questions of the form "What would my salary have been, had I been of a different gender/race?". Such individual level counterfactual reasoning can help eliminate discrimination and help justify fair decisions. We also discuss appropriate relaxations which assume certain causal pathways from the sensitive attribute to the outcome are not discriminatory.

</p>
</details>

<details><summary><b>Boosting Graph Embedding on a Single GPU</b>
<a href="https://arxiv.org/abs/2110.10049">arxiv:2110.10049</a>
&#x1F4C8; 3 <br>
<p>Amro Alabsi Aljundi, Taha Atahan Akyıldız, Kamer Kaya</p></summary>
<p>

**Abstract:** Graphs are ubiquitous, and they can model unique characteristics and complex relations of real-life systems. Although using machine learning (ML) on graphs is promising, their raw representation is not suitable for ML algorithms. Graph embedding represents each node of a graph as a d-dimensional vector which is more suitable for ML tasks. However, the embedding process is expensive, and CPU-based tools do not scale to real-world graphs. In this work, we present GOSH, a GPU-based tool for embedding large-scale graphs with minimum hardware constraints. GOSH employs a novel graph coarsening algorithm to enhance the impact of updates and minimize the work for embedding. It also incorporates a decomposition schema that enables any arbitrarily large graph to be embedded with a single GPU. As a result, GOSH sets a new state-of-the-art in link prediction both in accuracy and speed, and delivers high-quality embeddings for node classification at a fraction of the time compared to the state-of-the-art. For instance, it can embed a graph with over 65 million vertices and 1.8 billion edges in less than 30 minutes on a single GPU.

</p>
</details>

<details><summary><b>Neural Network Compatible Off-Policy Natural Actor-Critic Algorithm</b>
<a href="https://arxiv.org/abs/2110.10017">arxiv:2110.10017</a>
&#x1F4C8; 3 <br>
<p>Raghuram Bharadwaj Diddigi, Prateek Jain, Prabuchandran K. J., Shalabh Bhatnagar</p></summary>
<p>

**Abstract:** Learning optimal behavior from existing data is one of the most important problems in Reinforcement Learning (RL). This is known as "off-policy control" in RL where an agent's objective is to compute an optimal policy based on the data obtained from the given policy (known as the behavior policy). As the optimal policy can be very different from the behavior policy, learning optimal behavior is very hard in the "off-policy" setting compared to the "on-policy" setting where new data from the policy updates will be utilized in learning. This work proposes an off-policy natural actor-critic algorithm that utilizes state-action distribution correction for handling the off-policy behavior and the natural policy gradient for sample efficiency. The existing natural gradient-based actor-critic algorithms with convergence guarantees require fixed features for approximating both policy and value functions. This often leads to sub-optimal learning in many RL applications. On the other hand, our proposed algorithm utilizes compatible features that enable one to use arbitrary neural networks to approximate the policy and the value function and guarantee convergence to a locally optimal policy. We illustrate the benefit of the proposed off-policy natural gradient algorithm by comparing it with the vanilla gradient actor-critic algorithm on benchmark RL tasks.

</p>
</details>

<details><summary><b>Data-driven and Automatic Surface Texture Analysis Using Persistent Homology</b>
<a href="https://arxiv.org/abs/2110.10005">arxiv:2110.10005</a>
&#x1F4C8; 3 <br>
<p>Melih C. Yesilli, Firas A. Khasawneh</p></summary>
<p>

**Abstract:** Surface roughness plays an important role in analyzing engineering surfaces. It quantifies the surface topography and can be used to determine whether the resulting surface finish is acceptable or not. Nevertheless, while several existing tools and standards are available for computing surface roughness, these methods rely heavily on user input thus slowing down the analysis and increasing manufacturing costs. Therefore, fast and automatic determination of the roughness level is essential to avoid costs resulting from surfaces with unacceptable finish, and user-intensive analysis. In this study, we propose a Topological Data Analysis (TDA) based approach to classify the roughness level of synthetic surfaces using both their areal images and profiles. We utilize persistent homology from TDA to generate persistence diagrams that encapsulate information on the shape of the surface. We then obtain feature matrices for each surface or profile using Carlsson coordinates, persistence images, and template functions. We compare our results to two widely used methods in the literature: Fast Fourier Transform (FFT) and Gaussian filtering. The results show that our approach yields mean accuracies as high as 97%. We also show that, in contrast to existing surface analysis tools, our TDA-based approach is fully automatable and provides adaptive feature extraction.

</p>
</details>

<details><summary><b>Learning Robotic Manipulation Skills Using an Adaptive Force-Impedance Action Space</b>
<a href="https://arxiv.org/abs/2110.09904">arxiv:2110.09904</a>
&#x1F4C8; 3 <br>
<p>Maximilian Ulmer, Elie Aljalbout, Sascha Schwarz, Sami Haddadin</p></summary>
<p>

**Abstract:** Intelligent agents must be able to think fast and slow to perform elaborate manipulation tasks. Reinforcement Learning (RL) has led to many promising results on a range of challenging decision-making tasks. However, in real-world robotics, these methods still struggle, as they require large amounts of expensive interactions and have slow feedback loops. On the other hand, fast human-like adaptive control methods can optimize complex robotic interactions, yet fail to integrate multimodal feedback needed for unstructured tasks. In this work, we propose to factor the learning problem in a hierarchical learning and adaption architecture to get the best of both worlds. The framework consists of two components, a slow reinforcement learning policy optimizing the task strategy given multimodal observations, and a fast, real-time adaptive control policy continuously optimizing the motion, stability, and effort of the manipulator. We combine these components through a bio-inspired action space that we call AFORCE. We demonstrate the new action space on a contact-rich manipulation task on real hardware and evaluate its performance on three simulated manipulation tasks. Our experiments show that AFORCE drastically improves sample efficiency while reducing energy consumption and improving safety.

</p>
</details>

<details><summary><b>State-based Episodic Memory for Multi-Agent Reinforcement Learning</b>
<a href="https://arxiv.org/abs/2110.09817">arxiv:2110.09817</a>
&#x1F4C8; 3 <br>
<p>Xiao Ma, Wu-Jun Li</p></summary>
<p>

**Abstract:** Multi-agent reinforcement learning (MARL) algorithms have made promising progress in recent years by leveraging the centralized training and decentralized execution (CTDE) paradigm. However, existing MARL algorithms still suffer from the sample inefficiency problem. In this paper, we propose a simple yet effective approach, called state-based episodic memory (SEM), to improve sample efficiency in MARL. SEM adopts episodic memory (EM) to supervise the centralized training procedure of CTDE in MARL. To the best of our knowledge, SEM is the first work to introduce EM into MARL. We can theoretically prove that, when using for MARL, SEM has lower space complexity and time complexity than state and action based EM (SAEM), which is originally proposed for single-agent reinforcement learning. Experimental results on StarCraft multi-agent challenge (SMAC) show that introducing episodic memory into MARL can improve sample efficiency and SEM can reduce storage cost and time cost compared with SAEM.

</p>
</details>

<details><summary><b>Multi-Objective Loss Balancing for Physics-Informed Deep Learning</b>
<a href="https://arxiv.org/abs/2110.09813">arxiv:2110.09813</a>
&#x1F4C8; 3 <br>
<p>Rafael Bischof, Michael Kraus</p></summary>
<p>

**Abstract:** Physics Informed Neural Networks (PINN) are algorithms from deep learning leveraging physical laws by including partial differential equations (PDE) together with a respective set of boundary and initial conditions (BC / IC) as penalty terms into their loss function. As the PDE, BC and IC loss function parts can significantly differ in magnitudes, due to their underlying physical units or stochasticity of initialisation, training of PINNs may suffer from severe convergence and efficiency problems, causing PINNs to stay beyond desirable approximation quality. In this work, we observe the significant role of correctly weighting the combination of multiple competitive loss functions for training PINNs effectively. To that end, we implement and evaluate different methods aiming at balancing the contributions of multiple terms of the PINNs loss function and their gradients. After review of three existing loss scaling approaches (Learning Rate Annealing, GradNorm as well as SoftAdapt), we propose a novel self-adaptive loss balancing of PINNs called ReLoBRaLo (Relative Loss Balancing with Random Lookback). Finally, the performance of ReLoBRaLo is compared and verified against these approaches by solving both forward as well as inverse problems on three benchmark PDEs for PINNs: Burgers' equation, Kirchhoff's plate bending equation and Helmholtz's equation. Our simulation studies show that ReLoBRaLo training is much faster and achieves higher accuracy than training PINNs with other balancing methods and hence is very effective and increases sustainability of PINNs algorithms. The adaptability of ReLoBRaLo illustrates robustness across different PDE problem settings. The proposed method can also be employed to the wider class of penalised optimisation problems, including PDE-constrained and Sobolev training apart from the studied PINNs examples.

</p>
</details>

<details><summary><b>Pre and Post Counting for Scalable Statistical-Relational Model Discovery</b>
<a href="https://arxiv.org/abs/2110.09767">arxiv:2110.09767</a>
&#x1F4C8; 3 <br>
<p>Richard Mar, Oliver Schulte</p></summary>
<p>

**Abstract:** Statistical-Relational Model Discovery aims to find statistically relevant patterns in relational data. For example, a relational dependency pattern may stipulate that a user's gender is associated with the gender of their friends. As with propositional (non-relational) graphical models, the major scalability bottleneck for model discovery is computing instantiation counts: the number of times a relational pattern is instantiated in a database. Previous work on propositional learning utilized pre-counting or post-counting to solve this task. This paper takes a detailed look at the memory and speed trade-offs between pre-counting and post-counting strategies for relational learning. A pre-counting approach computes and caches instantiation counts for a large set of relational patterns before model search. A post-counting approach computes an instantiation count dynamically on-demand for each candidate pattern generated during the model search. We describe a novel hybrid approach, tailored to relational data, that achieves a sweet spot with pre-counting for patterns involving positive relationships (e.g. pairs of users who are friends) and post-counting for patterns involving negative relationships (e.g. pairs of users who are not friends). Our hybrid approach scales model discovery to millions of data facts.

</p>
</details>

<details><summary><b>Spectral Variability Augmented Sparse Unmixing of Hyperspectral Images</b>
<a href="https://arxiv.org/abs/2110.09744">arxiv:2110.09744</a>
&#x1F4C8; 3 <br>
<p>Ge Zhang, Shaohui Mei, Mingyang Ma, Yan Feng, Qian Du</p></summary>
<p>

**Abstract:** Spectral unmixing (SU) expresses the mixed pixels existed in hyperspectral images as the product of endmember and abundance, which has been widely used in hyperspectral imagery analysis. However, the influence of light, acquisition conditions and the inherent properties of materials, results in that the identified endmembers can vary spectrally within a given image (construed as spectral variability). To address this issue, recent methods usually use a priori obtained spectral library to represent multiple characteristic spectra of the same object, but few of them extracted the spectral variability explicitly. In this paper, a spectral variability augmented sparse unmixing model (SVASU) is proposed, in which the spectral variability is extracted for the first time. The variable spectra are divided into two parts of intrinsic spectrum and spectral variability for spectral reconstruction, and modeled synchronously in the SU model adding the regular terms restricting the sparsity of abundance and the generalization of the variability coefficient. It is noted that the spectral variability library and the intrinsic spectral library are all constructed from the In-situ observed image. Experimental results over both synthetic and real-world data sets demonstrate that the augmented decomposition by spectral variability significantly improves the unmixing performance than the decomposition only by spectral library, as well as compared to state-of-the-art algorithms.

</p>
</details>

<details><summary><b>Distributed Reinforcement Learning for Privacy-Preserving Dynamic Edge Caching</b>
<a href="https://arxiv.org/abs/2110.10349">arxiv:2110.10349</a>
&#x1F4C8; 2 <br>
<p>Shengheng Liu, Chong Zheng, Yongming Huang, Tony Q. S. Quek</p></summary>
<p>

**Abstract:** Mobile edge computing (MEC) is a prominent computing paradigm which expands the application fields of wireless communication. Due to the limitation of the capacities of user equipments and MEC servers, edge caching (EC) optimization is crucial to the effective utilization of the caching resources in MEC-enabled wireless networks. However, the dynamics and complexities of content popularities over space and time as well as the privacy preservation of users pose significant challenges to EC optimization. In this paper, a privacy-preserving distributed deep deterministic policy gradient (P2D3PG) algorithm is proposed to maximize the cache hit rates of devices in the MEC networks. Specifically, we consider the fact that content popularities are dynamic, complicated and unobservable, and formulate the maximization of cache hit rates on devices as distributed problems under the constraints of privacy preservation. In particular, we convert the distributed optimizations into distributed model-free Markov decision process problems and then introduce a privacy-preserving federated learning method for popularity prediction. Subsequently, a P2D3PG algorithm is developed based on distributed reinforcement learning to solve the distributed problems. Simulation results demonstrate the superiority of the proposed approach in improving EC hit rate over the baseline methods while preserving user privacy.

</p>
</details>

<details><summary><b>One-Step Abductive Multi-Target Learning with Diverse Noisy Samples</b>
<a href="https://arxiv.org/abs/2110.10325">arxiv:2110.10325</a>
&#x1F4C8; 2 <br>
<p>Yongquan Yang</p></summary>
<p>

**Abstract:** One-step abductive multi-target learning (OSAMTL) was proposed to handle complex noisy labels. In this paper, giving definition of diverse noisy samples (DNS), we propose one-step abductive multi-target learning with DNS (OSAMTL-DNS) to expand the original OSAMTL to a wider range of tasks that handle complex noisy labels.

</p>
</details>

<details><summary><b>Semantic Sensing and Planning for Human-Robot Collaboration in Uncertain Environments</b>
<a href="https://arxiv.org/abs/2110.10324">arxiv:2110.10324</a>
&#x1F4C8; 2 <br>
<p>Luke Burks, Hunter M. Ray, Jamison McGinley, Sousheel Vunnam, Nisar Ahmed</p></summary>
<p>

**Abstract:** Autonomous robots can benefit greatly from human-provided semantic characterizations of uncertain task environments and states. However, the development of integrated strategies which let robots model, communicate, and act on such soft data remains challenging. Here, a framework is presented for active semantic sensing and planning in human-robot teams which addresses these gaps by formally combining the benefits of online sampling-based POMDP policies, multi-modal semantic interaction, and Bayesian data fusion. This approach lets humans opportunistically impose model structure and extend the range of semantic soft data in uncertain environments by sketching and labeling arbitrary landmarks across the environment. Dynamic updating of the environment while searching for a mobile target allows robotic agents to actively query humans for novel and relevant semantic data, thereby improving beliefs of unknown environments and target states for improved online planning. Target search simulations show significant improvements in time and belief state estimates required for interception versus conventional planning based solely on robotic sensing. Human subject studies demonstrate a average doubling in dynamic target capture rate compared to the lone robot case, employing reasoning over a range of user characteristics and interaction modalities. Video of interaction can be found at https://youtu.be/Eh-82ZJ1o4I.

</p>
</details>

<details><summary><b>Joint Gaussian Graphical Model Estimation: A Survey</b>
<a href="https://arxiv.org/abs/2110.10281">arxiv:2110.10281</a>
&#x1F4C8; 2 <br>
<p>Katherine Tsai, Oluwasanmi Koyejo, Mladen Kolar</p></summary>
<p>

**Abstract:** Graphs from complex systems often share a partial underlying structure across domains while retaining individual features. Thus, identifying common structures can shed light on the underlying signal, for instance, when applied to scientific discoveries or clinical diagnoses. Furthermore, growing evidence shows that the shared structure across domains boosts the estimation power of graphs, particularly for high-dimensional data. However, building a joint estimator to extract the common structure may be more complicated than it seems, most often due to data heterogeneity across sources. This manuscript surveys recent work on statistical inference of joint Gaussian graphical models, identifying model structures that fit various data generation processes. Simulations under different data generation processes are implemented with detailed discussions on the choice of models.

</p>
</details>

<details><summary><b>A Federated Learning Aggregation Algorithm for Pervasive Computing: Evaluation and Comparison</b>
<a href="https://arxiv.org/abs/2110.10223">arxiv:2110.10223</a>
&#x1F4C8; 2 <br>
<p>Sannara Ek, François Portet, Philippe Lalanda, German Vega</p></summary>
<p>

**Abstract:** Pervasive computing promotes the installation of connected devices in our living spaces in order to provide services. Two major developments have gained significant momentum recently: an advanced use of edge resources and the integration of machine learning techniques for engineering applications. This evolution raises major challenges, in particular related to the appropriate distribution of computing elements along an edge-to-cloud continuum. About this, Federated Learning has been recently proposed for distributed model training in the edge. The principle of this approach is to aggregate models learned on distributed clients in order to obtain a new, more general model. The resulting model is then redistributed to clients for further training. To date, the most popular federated learning algorithm uses coordinate-wise averaging of the model parameters for aggregation. However, it has been shown that this method is not adapted in heterogeneous environments where data is not identically and independently distributed (non-iid). This corresponds directly to some pervasive computing scenarios where heterogeneity of devices and users challenges machine learning with the double objective of generalization and personalization. In this paper, we propose a novel aggregation algorithm, termed FedDist, which is able to modify its model architecture (here, deep neural network) by identifying dissimilarities between specific neurons amongst the clients. This permits to account for clients' specificity without impairing generalization. Furthermore, we define a complete method to evaluate federated learning in a realistic way taking generalization and personalization into account.
  Using this method, FedDist is extensively tested and compared with three state-of-the-art federated learning algorithms on the pervasive domain of Human Activity Recognition with smartphones.

</p>
</details>

<details><summary><b>Patch Based Transformation for Minimum Variance Beamformer Image Approximation Using Delay and Sum Pipeline</b>
<a href="https://arxiv.org/abs/2110.10220">arxiv:2110.10220</a>
&#x1F4C8; 2 <br>
<p>Sairoop Bodepudi, A N Madhavanunni, Mahesh Raveendranatha Panicker</p></summary>
<p>

**Abstract:** In the recent past, there have been several efforts in accelerating computationally heavy beamforming algorithms such as minimum variance distortionless response (MVDR) beamforming to achieve real-time performance comparable to the popular delay and sum (DAS) beamforming. This has been achieved using a variety of neural network architectures ranging from fully connected neural networks (FCNNs), convolutional neural networks (CNNs) and general adversarial networks (GANs). However most of these approaches are working with optimizations considering image level losses and hence require a significant amount of dataset to ensure that the process of beamforming is learned. In this work, a patch level U-Net based neural network is proposed, where the delay compensated radio frequency (RF) patch for a fixed region in space (e.g. 32x32) is transformed through a U-Net architecture and multiplied with DAS apodization weights and optimized for similarity with MVDR image of the patch. Instead of framing the beamforming problem as a regression problem to estimate the apodization weights, the proposed approach treats the non-linear transformation of the RF data space that can account for the data driven weight adaptation done by the MVDR approach in the parameters of the network. In this way, it is also observed that by restricting the input to a patch the model will learn the beamforming pipeline as an image non-linear transformation problem.

</p>
</details>

<details><summary><b>An Adaptive Sampling and Edge Detection Approach for Encoding Static Images for Spiking Neural Networks</b>
<a href="https://arxiv.org/abs/2110.10217">arxiv:2110.10217</a>
&#x1F4C8; 2 <br>
<p>Peyton Chandarana, Junlin Ou, Ramtin Zand</p></summary>
<p>

**Abstract:** Current state-of-the-art methods of image classification using convolutional neural networks are often constrained by both latency and power consumption. This places a limit on the devices, particularly low-power edge devices, that can employ these methods. Spiking neural networks (SNNs) are considered to be the third generation of artificial neural networks which aim to address these latency and power constraints by taking inspiration from biological neuronal communication processes. Before data such as images can be input into an SNN, however, they must be first encoded into spike trains. Herein, we propose a method for encoding static images into temporal spike trains using edge detection and an adaptive signal sampling method for use in SNNs. The edge detection process consists of first performing Canny edge detection on the 2D static images and then converting the edge detected images into two X and Y signals using an image-to-signal conversion method. The adaptive signaling approach consists of sampling the signals such that the signals maintain enough detail and are sensitive to abrupt changes in the signal. Temporal encoding mechanisms such as threshold-based representation (TBR) and step-forward (SF) are then able to be used to convert the sampled signals into spike trains. We use various error and indicator metrics to optimize and evaluate the efficiency and precision of the proposed image encoding approach. Comparison results between the original and reconstructed signals from spike trains generated using edge-detection and adaptive temporal encoding mechanism exhibit 18x and 7x reduction in average root mean square error (RMSE) compared to the conventional SF and TBR encoding, respectively, while used for encoding MNIST dataset.

</p>
</details>

<details><summary><b>Long Random Matrices and Tensor Unfolding</b>
<a href="https://arxiv.org/abs/2110.10210">arxiv:2110.10210</a>
&#x1F4C8; 2 <br>
<p>Gérard Ben Arous, Daniel Zhengyu Huang, Jiaoyang Huang</p></summary>
<p>

**Abstract:** In this paper, we consider the singular values and singular vectors of low rank perturbations of large rectangular random matrices, in the regime the matrix is "long": we allow the number of rows (columns) to grow polynomially in the number of columns (rows). We prove there exists a critical signal-to-noise ratio (depending on the dimensions of the matrix), and the extreme singular values and singular vectors exhibit a BBP type phase transition. As a main application, we investigate the tensor unfolding algorithm for the asymmetric rank-one spiked tensor model, and obtain an exact threshold, which is independent of the procedure of tensor unfolding. If the signal-to-noise ratio is above the threshold, tensor unfolding detects the signals; otherwise, it fails to capture the signals.

</p>
</details>

<details><summary><b>MultiHead MultiModal Deep Interest Recommendation Network</b>
<a href="https://arxiv.org/abs/2110.10205">arxiv:2110.10205</a>
&#x1F4C8; 2 <br>
<p>Mingbao Yang, ShaoBo Li, Zhou Peng, Ansi Zhang, Yuanmeng Zhang</p></summary>
<p>

**Abstract:** With the development of information technology, human beings are constantly producing a large amount of information at all times. How to obtain the information that users are interested in from the large amount of information has become an issue of great concern to users and even business managers. In order to solve this problem, from traditional machine learning to deep learning recommendation systems, researchers continue to improve optimization models and explore solutions. Because researchers have optimized more on the recommendation model network structure, they have less research on enriching recommendation model features, and there is still room for in-depth recommendation model optimization. Based on the DIN\cite{Authors01} model, this paper adds multi-head and multi-modal modules, which enriches the feature sets that the model can use, and at the same time strengthens the cross-combination and fitting capabilities of the model. Experiments show that the multi-head multi-modal DIN improves the recommendation prediction effect, and outperforms current state-of-the-art methods on various comprehensive indicators.

</p>
</details>

<details><summary><b>NAS-HPO-Bench-II: A Benchmark Dataset on Joint Optimization of Convolutional Neural Network Architecture and Training Hyperparameters</b>
<a href="https://arxiv.org/abs/2110.10165">arxiv:2110.10165</a>
&#x1F4C8; 2 <br>
<p>Yoichi Hirose, Nozomu Yoshinari, Shinichi Shirakawa</p></summary>
<p>

**Abstract:** The benchmark datasets for neural architecture search (NAS) have been developed to alleviate the computationally expensive evaluation process and ensure a fair comparison. Recent NAS benchmarks only focus on architecture optimization, although the training hyperparameters affect the obtained model performances. Building the benchmark dataset for joint optimization of architecture and training hyperparameters is essential to further NAS research. The existing NAS-HPO-Bench is a benchmark for joint optimization, but it does not consider the network connectivity design as done in modern NAS algorithms. This paper introduces the first benchmark dataset for joint optimization of network connections and training hyperparameters, which we call NAS-HPO-Bench-II. We collect the performance data of 4K cell-based convolutional neural network architectures trained on the CIFAR-10 dataset with different learning rate and batch size settings, resulting in the data of 192K configurations. The dataset includes the exact data for 12 epoch training. We further build the surrogate model predicting the accuracies after 200 epoch training to provide the performance data of longer training epoch. By analyzing NAS-HPO-Bench-II, we confirm the dependency between architecture and training hyperparameters and the necessity of joint optimization. Finally, we demonstrate the benchmarking of the baseline optimization algorithms using NAS-HPO-Bench-II.

</p>
</details>

<details><summary><b>Cross-Sim-NGF: FFT-Based Global Rigid Multimodal Alignment of Image Volumes using Normalized Gradient Fields</b>
<a href="https://arxiv.org/abs/2110.10156">arxiv:2110.10156</a>
&#x1F4C8; 2 <br>
<p>Johan Öfverstedt, Joakim Lindblad, Nataša Sladoje</p></summary>
<p>

**Abstract:** Multimodal image alignment involves finding spatial correspondences between volumes varying in appearance and structure. Automated alignment methods are often based on local optimization that can be highly sensitive to their initialization. We propose a global optimization method for rigid multimodal 3D image alignment, based on a novel efficient algorithm for computing similarity of normalized gradient fields (NGF) in the frequency domain. We validate the method experimentally on a dataset comprised of 20 brain volumes acquired in four modalities (T1w, Flair, CT, [18F] FDG PET), synthetically displaced with known transformations. The proposed method exhibits excellent performance on all six possible modality combinations, and outperforms all four reference methods by a large margin. The method is fast; a 3.4Mvoxel global rigid alignment requires approximately 40 seconds of computation, and the proposed algorithm outperforms a direct algorithm for the same task by more than three orders of magnitude. Open-source implementation is provided.

</p>
</details>

<details><summary><b>BAMLD: Bayesian Active Meta-Learning by Disagreement</b>
<a href="https://arxiv.org/abs/2110.09943">arxiv:2110.09943</a>
&#x1F4C8; 2 <br>
<p>Ivana Nikoloska, Osvaldo Simeone</p></summary>
<p>

**Abstract:** Data-efficient learning algorithms are essential in many practical applications for which data collection and labeling is expensive or infeasible, e.g., for autonomous cars. To address this problem, meta-learning infers an inductive bias from a set of meta-training tasks in order to learn new, but related, task using a small number of samples. Most studies assume the meta-learner to have access to labeled data sets from a large number of tasks. In practice, one may have available only unlabeled data sets from the tasks, requiring a costly labeling procedure to be carried out before use in standard meta-learning schemes. To decrease the number of labeling requests for meta-training tasks, this paper introduces an information-theoretic active task selection mechanism which quantifies the epistemic uncertainty via disagreements among the predictions obtained under different inductive biases. We detail an instantiation for nonparametric methods based on Gaussian Process Regression, and report its empirical performance results that compare favourably against existing heuristic acquisition mechanisms.

</p>
</details>

<details><summary><b>Designing A Clinically Applicable Deep Recurrent Model to Identify Neuropsychiatric Symptoms in People Living with Dementia Using In-Home Monitoring Data</b>
<a href="https://arxiv.org/abs/2110.09868">arxiv:2110.09868</a>
&#x1F4C8; 2 <br>
<p>Francesca Palermo, Honglin Li, Alexander Capstick, Nan Fletcher-Lloyd, Yuchen Zhao, Samaneh Kouchaki, Ramin Nilforooshan, David Sharp, Payam Barnaghi</p></summary>
<p>

**Abstract:** Agitation is one of the neuropsychiatric symptoms with high prevalence in dementia which can negatively impact the Activities of Daily Living (ADL) and the independence of individuals. Detecting agitation episodes can assist in providing People Living with Dementia (PLWD) with early and timely interventions. Analysing agitation episodes will also help identify modifiable factors such as ambient temperature and sleep as possible components causing agitation in an individual. This preliminary study presents a supervised learning model to analyse the risk of agitation in PLWD using in-home monitoring data. The in-home monitoring data includes motion sensors, physiological measurements, and the use of kitchen appliances from 46 homes of PLWD between April 2019-June 2021. We apply a recurrent deep learning model to identify agitation episodes validated and recorded by a clinical monitoring team. We present the experiments to assess the efficacy of the proposed model. The proposed model achieves an average of 79.78% recall, 27.66% precision and 37.64% F1 scores when employing the optimal parameters, suggesting a good ability to recognise agitation events. We also discuss using machine learning models for analysing the behavioural patterns using continuous monitoring data and explore clinical applicability and the choices between sensitivity and specificity in-home monitoring applications.

</p>
</details>

<details><summary><b>Learning Pareto-Efficient Decisions with Confidence</b>
<a href="https://arxiv.org/abs/2110.09864">arxiv:2110.09864</a>
&#x1F4C8; 2 <br>
<p>Sofia Ek, Dave Zachariah, Petre Stoica</p></summary>
<p>

**Abstract:** The paper considers the problem of multi-objective decision support when outcomes are uncertain. We extend the concept of Pareto-efficient decisions to take into account the uncertainty of decision outcomes across varying contexts. This enables quantifying trade-offs between decisions in terms of tail outcomes that are relevant in safety-critical applications. We propose a method for learning efficient decisions with statistical confidence, building on results from the conformal prediction literature. The method adapts to weak or nonexistent context covariate overlap and its statistical guarantees are evaluated using both synthetic and real data.

</p>
</details>

<details><summary><b>Improved cooperation by balancing exploration and exploitation in intertemporal social dilemma tasks</b>
<a href="https://arxiv.org/abs/2111.09152">arxiv:2111.09152</a>
&#x1F4C8; 1 <br>
<p>Zhenbo Cheng, Xingguang Liu, Leilei Zhang, Hangcheng Meng, Qin Li, Xiao Gang</p></summary>
<p>

**Abstract:** When an individual's behavior has rational characteristics, this may lead to irrational collective actions for the group. A wide range of organisms from animals to humans often evolve the social attribute of cooperation to meet this challenge. Therefore, cooperation among individuals is of great significance for allowing social organisms to adapt to changes in the natural environment. Based on multi-agent reinforcement learning, we propose a new learning strategy for achieving coordination by incorporating a learning rate that can balance exploration and exploitation. We demonstrate that agents that use the simple strategy improve a relatively collective return in a decision task called the intertemporal social dilemma, where the conflict between the individual and the group is particularly sharp. We also explore the effects of the diversity of learning rates on the population of reinforcement learning agents and show that agents trained in heterogeneous populations develop particularly coordinated policies relative to those trained in homogeneous populations.

</p>
</details>

<details><summary><b>FedParking: A Federated Learning based Parking Space Estimation with Parked Vehicle assisted Edge Computing</b>
<a href="https://arxiv.org/abs/2110.12876">arxiv:2110.12876</a>
&#x1F4C8; 1 <br>
<p>Xumin Huang, Peichun Li, Rong Yu, Yuan Wu, Kan Xie, Shengli Xie</p></summary>
<p>

**Abstract:** As a distributed learning approach, federated learning trains a shared learning model over distributed datasets while preserving the training data privacy. We extend the application of federated learning to parking management and introduce FedParking in which Parking Lot Operators (PLOs) collaborate to train a long short-term memory model for parking space estimation without exchanging the raw data. Furthermore, we investigate the management of Parked Vehicle assisted Edge Computing (PVEC) by FedParking. In PVEC, different PLOs recruit PVs as edge computing nodes for offloading services through an incentive mechanism, which is designed according to the computation demand and parking capacity constraints derived from FedParking. We formulate the interactions among the PLOs and vehicles as a multi-lead multi-follower Stackelberg game. Considering the dynamic arrivals of the vehicles and time-varying parking capacity constraints, we present a multi-agent deep reinforcement learning approach to gradually reach the Stackelberg equilibrium in a distributed yet privacy-preserving manner. Finally, numerical results are provided to demonstrate the effectiveness and efficiency of our scheme.

</p>
</details>

<details><summary><b>Faster Algorithm and Sharper Analysis for Constrained Markov Decision Process</b>
<a href="https://arxiv.org/abs/2110.10351">arxiv:2110.10351</a>
&#x1F4C8; 1 <br>
<p>Tianjiao Li, Ziwei Guan, Shaofeng Zou, Tengyu Xu, Yingbin Liang, Guanghui Lan</p></summary>
<p>

**Abstract:** The problem of constrained Markov decision process (CMDP) is investigated, where an agent aims to maximize the expected accumulated discounted reward subject to multiple constraints on its utilities/costs. A new primal-dual approach is proposed with a novel integration of three ingredients: entropy regularized policy optimizer, dual variable regularizer, and Nesterov's accelerated gradient descent dual optimizer, all of which are critical to achieve a faster convergence. The finite-time error bound of the proposed approach is characterized. Despite the challenge of the nonconcave objective subject to nonconcave constraints, the proposed approach is shown to converge to the global optimum with a complexity of $\tilde{\mathcal O}(1/ε)$ in terms of the optimality gap and the constraint violation, which improves the complexity of the existing primal-dual approach by a factor of $\mathcal O(1/ε)$ \citep{ding2020natural,paternain2019constrained}. This is the first demonstration that nonconcave CMDP problems can attain the complexity lower bound of $\mathcal O(1/ε)$ for convex optimization subject to convex constraints. Our primal-dual approach and non-asymptotic analysis are agnostic to the RL optimizer used, and thus are more flexible for practical applications. More generally, our approach also serves as the first algorithm that provably accelerates constrained nonconvex optimization with zero duality gap by exploiting the geometries such as the gradient dominance condition, for which the existing acceleration methods for constrained convex optimization are not applicable.

</p>
</details>

<details><summary><b>Factorization Approach for Low-complexity Matrix Completion Problems: Exponential Number of Spurious Solutions and Failure of Gradient Methods</b>
<a href="https://arxiv.org/abs/2110.10279">arxiv:2110.10279</a>
&#x1F4C8; 1 <br>
<p>Baturalp Yalcin, Haixiang Zhang, Javad Lavaei, Somayeh Sojoudi</p></summary>
<p>

**Abstract:** It is well-known that the Burer-Monteiro (B-M) factorization approach can efficiently solve low-rank matrix optimization problems under the RIP condition. It is natural to ask whether B-M factorization-based methods can succeed on any low-rank matrix optimization problems with a low information-theoretic complexity, i.e., polynomial-time solvable problems that have a unique solution. In this work, we provide a negative answer to the above question. We investigate the landscape of B-M factorized polynomial-time solvable matrix completion (MC) problems, which are the most popular subclass of low-rank matrix optimization problems without the RIP condition. We construct an instance of polynomial-time solvable MC problems with exponentially many spurious local minima, which leads to the failure of most gradient-based methods. Based on those results, we define a new complexity metric that potentially measures the solvability of low-rank matrix optimization problems based on the B-M factorization approach. In addition, we show that more measurements of the ground truth matrix can deteriorate the landscape, which further reveals the unfavorable behavior of the B-M factorization on general low-rank matrix optimization problems.

</p>
</details>

<details><summary><b>Collaboration Challenges in Building ML-Enabled Systems: Communication, Documentation, Engineering, and Process</b>
<a href="https://arxiv.org/abs/2110.10234">arxiv:2110.10234</a>
&#x1F4C8; 1 <br>
<p>Nadia Nahar, Shurui Zhou, Grace Lewis, Christian Kästner</p></summary>
<p>

**Abstract:** The introduction of machine learning (ML) components in software projects has created the need for software engineers to collaborate with data scientists and other specialists. While collaboration can always be challenging, ML introduces additional challenges with its exploratory model development process, additional skills and knowledge needed, difficulties testing ML systems, need for continuous evolution and monitoring, and non-traditional quality requirements such as fairness and explainability. Through interviews with 45 practitioners from 28 organizations, we identified key collaboration challenges that teams face when building and deploying ML systems into production. We report on common collaboration points in the development of production ML systems for requirements, data, and integration, as well as corresponding team patterns and challenges. We find that most of these challenges center around communication, documentation, engineering, and process and collect recommendations to address these challenges.

</p>
</details>

<details><summary><b>Risks of AI Foundation Models in Education</b>
<a href="https://arxiv.org/abs/2110.10024">arxiv:2110.10024</a>
&#x1F4C8; 1 <br>
<p>Su Lin Blodgett, Michael Madaio</p></summary>
<p>

**Abstract:** If the authors of a recent Stanford report (Bommasani et al., 2021) on the opportunities and risks of "foundation models" are to be believed, these models represent a paradigm shift for AI and for the domains in which they will supposedly be used, including education. Although the name is new (and contested (Field, 2021)), the term describes existing types of algorithmic models that are "trained on broad data at scale" and "fine-tuned" (i.e., adapted) for particular downstream tasks, and is intended to encompass large language models such as BERT or GPT-3 and computer vision models such as CLIP. Such technologies have the potential for harm broadly speaking (e.g., Bender et al., 2021), but their use in the educational domain is particularly fraught, despite the potential benefits for learners claimed by the authors. In section 3.3 of the Stanford report, Malik et al. argue that achieving the goal of providing education for all learners requires more efficient computational approaches that can rapidly scale across educational domains and across educational contexts, for which they argue foundation models are uniquely well-suited. However, evidence suggests that not only are foundation models not likely to achieve the stated benefits for learners, but their use may also introduce new risks for harm.

</p>
</details>

<details><summary><b>Riemannian classification of EEG signals with missing values</b>
<a href="https://arxiv.org/abs/2110.10011">arxiv:2110.10011</a>
&#x1F4C8; 1 <br>
<p>Alexandre Hippert-Ferrer, Ammar Mian, Florent Bouchard, Frédéric Pascal</p></summary>
<p>

**Abstract:** This paper proposes two strategies to handle missing data for the classification of electroencephalograms using covariance matrices. The first approach estimates the covariance from imputed data with the $k$-nearest neighbors algorithm; the second relies on the observed data by leveraging the observed-data likelihood within an expectation-maximization algorithm. Both approaches are combined with the minimum distance to Riemannian mean classifier and applied to a classification task of event related-potentials, a widely known paradigm of brain-computer interface paradigms. As results show, the proposed strategies perform better than the classification based on observed data and allow to keep a high accuracy even when the missing data ratio increases.

</p>
</details>

<details><summary><b>Identification of high order closure terms from fully kinetic simulations using machine learning</b>
<a href="https://arxiv.org/abs/2110.09916">arxiv:2110.09916</a>
&#x1F4C8; 1 <br>
<p>Brecht Laperre, Jorge Amaya, Giovanni Lapenta</p></summary>
<p>

**Abstract:** Simulations of large-scale plasma systems are typically based on fluid approximations. However, these methods do not capture the small-scale physical processes available to fully kinetic models. Traditionally, empirical closure terms are used to express high order moments of the Boltzmann equation, e.g. the pressure tensor and heat flux. In this paper, we propose different closure terms extracted using machine learning techniques as an alternative. We show in this work how two different machine learning models, a multi-layer perceptron and a gradient boosting regressor, can synthesize higher-order moments extracted from a fully kinetic simulation. The accuracy of the models and their ability to generalize are evaluated and compared to a baseline model. When trained from more extreme simulations, the models showed better extrapolation in comparison to traditional simulations, indicating the importance of outliers. We learn that both models can capture heat flux and pressure tensor very well, with the gradient boosting regressor being the most stable of the two models in terms of the accuracy. The performance of the tested models in the regression task opens the way for new experiments in multi-scale modelling.

</p>
</details>

<details><summary><b>Faster Rates for the Frank-Wolfe Algorithm Using Jacobi Polynomials</b>
<a href="https://arxiv.org/abs/2110.09738">arxiv:2110.09738</a>
&#x1F4C8; 1 <br>
<p>Robin Francis, Sundeep Prabhakar Chepuri</p></summary>
<p>

**Abstract:** The Frank Wolfe algorithm (FW) is a popular projection-free alternative for solving large-scale constrained optimization problems. However, the FW algorithm suffers from a sublinear convergence rate when minimizing a smooth convex function over a compact convex set. Thus, exploring techniques that yield a faster convergence rate becomes crucial. A classic approach to obtain faster rates is to combine previous iterates to obtain the next iterate. In this work, we extend this approach to the FW setting and show that the optimal way to combine the past iterates is using a set of orthogonal Jacobi polynomials. We also a polynomial-based acceleration technique, referred to as Jacobi polynomial accelerated FW, which combines the current iterate with the past iterate using combing weights related to the Jacobi recursion. By carefully choosing parameters of the Jacobi polynomials, we obtain a faster sublinear convergence rate. We provide numerical experiments on real datasets to demonstrate the efficacy of the proposed algorithm.

</p>
</details>

<details><summary><b>Local Explanations for Clinical Search Engine results</b>
<a href="https://arxiv.org/abs/2110.12891">arxiv:2110.12891</a>
&#x1F4C8; 0 <br>
<p>Edeline Contempré, Zoltán Szlávik, Majid Mohammadi, Erick Velazquez, Annette ten Teije, Ilaria Tiddi</p></summary>
<p>

**Abstract:** Health care professionals rely on treatment search engines to efficiently find adequate clinical trials and early access programs for their patients. However, doctors lose trust in the system if its underlying processes are unclear and unexplained. In this paper, a model-agnostic explainable method is developed to provide users with further information regarding the reasons why a clinical trial is retrieved in response to a query. To accomplish this, the engine generates features from clinical trials using by using a knowledge graph, clinical trial data and additional medical resources. and a crowd-sourcing methodology is used to determine their importance. Grounded on the proposed methodology, the rationale behind retrieving the clinical trials is explained in layman's terms so that healthcare processionals can effortlessly perceive them. In addition, we compute an explainability score for each of the retrieved items, according to which the items can be ranked. The experiments validated by medical professionals suggest that the proposed methodology induces trust in targeted as well as in non-targeted users, and provide them with reliable explanations and ranking of retrieved items.

</p>
</details>

<details><summary><b>R$^3$Net:Relation-embedded Representation Reconstruction Network for Change Captioning</b>
<a href="https://arxiv.org/abs/2110.10328">arxiv:2110.10328</a>
&#x1F4C8; 0 <br>
<p>Yunbin Tu, Liang Li, Chenggang Yan, Shengxiang Gao, Zhengtao Yu</p></summary>
<p>

**Abstract:** Change captioning is to use a natural language sentence to describe the fine-grained disagreement between two similar images. Viewpoint change is the most typical distractor in this task, because it changes the scale and location of the objects and overwhelms the representation of real change. In this paper, we propose a Relation-embedded Representation Reconstruction Network (R$^3$Net) to explicitly distinguish the real change from the large amount of clutter and irrelevant changes. Specifically, a relation-embedded module is first devised to explore potential changed objects in the large amount of clutter. Then, based on the semantic similarities of corresponding locations in the two images, a representation reconstruction module (RRM) is designed to learn the reconstruction representation and further model the difference representation. Besides, we introduce a syntactic skeleton predictor (SSP) to enhance the semantic interaction between change localization and caption generation. Extensive experiments show that the proposed method achieves the state-of-the-art results on two public datasets.

</p>
</details>

<details><summary><b>Coalitional Bayesian Autoencoders -- Towards explainable unsupervised deep learning</b>
<a href="https://arxiv.org/abs/2110.10038">arxiv:2110.10038</a>
&#x1F4C8; 0 <br>
<p>Bang Xiang Yong, Alexandra Brintrup</p></summary>
<p>

**Abstract:** This paper aims to improve the explainability of Autoencoder's (AE) predictions by proposing two explanation methods based on the mean and epistemic uncertainty of log-likelihood estimate, which naturally arise from the probabilistic formulation of the AE called Bayesian Autoencoders (BAE). To quantitatively evaluate the performance of explanation methods, we test them in sensor network applications, and propose three metrics based on covariate shift of sensors : (1) G-mean of Spearman drift coefficients, (2) G-mean of sensitivity-specificity of explanation ranking and (3) sensor explanation quality index (SEQI) which combines the two aforementioned metrics. Surprisingly, we find that explanations of BAE's predictions suffer from high correlation resulting in misleading explanations. To alleviate this, a "Coalitional BAE" is proposed, which is inspired by agent-based system theory. Our comprehensive experiments on publicly available condition monitoring datasets demonstrate the improved quality of explanations using the Coalitional BAE.

</p>
</details>


[Next Page]({{ '/2021/10/18/2021.10.18.html' | relative_url }})
