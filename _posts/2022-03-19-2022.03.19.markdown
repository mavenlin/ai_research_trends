Prev: [2022.03.18]({{ '/2022/03/18/2022.03.18.html' | relative_url }})  Next: [2022.03.20]({{ '/2022/03/20/2022.03.20.html' | relative_url }})
{% raw %}
## Summary for 2022-03-19, created on 2022-03-29


<details><summary><b>CLIP on Wheels: Zero-Shot Object Navigation as Object Localization and Exploration</b>
<a href="https://arxiv.org/abs/2203.10421">arxiv:2203.10421</a>
&#x1F4C8; 27 <br>
<p>Samir Yitzhak Gadre, Mitchell Wortsman, Gabriel Ilharco, Ludwig Schmidt, Shuran Song</p></summary>
<p>

**Abstract:** Households across the world contain arbitrary objects: from mate gourds and coffee mugs to sitars and guitars. Considering this diversity, robot perception must handle a large variety of semantic objects without additional fine-tuning to be broadly applicable in homes. Recently, zero-shot models have demonstrated impressive performance in image classification of arbitrary objects (i.e., classifying images at inference with categories not explicitly seen during training). In this paper, we translate the success of zero-shot vision models (e.g., CLIP) to the popular embodied AI task of object navigation. In our setting, an agent must find an arbitrary goal object, specified via text, in unseen environments coming from different datasets. Our key insight is to modularize the task into zero-shot object localization and exploration. Employing this philosophy, we design CLIP on Wheels (CoW) baselines for the task and evaluate each zero-shot model in both Habitat and RoboTHOR simulators. We find that a straightforward CoW, with CLIP-based object localization plus classical exploration, and no additional training, often outperforms learnable approaches in terms of success, efficiency, and robustness to dataset distribution shift. This CoW achieves 6.3% SPL in Habitat and 10.0% SPL in RoboTHOR, when tested zero-shot on all categories. On a subset of four RoboTHOR categories considered in prior work, the same CoW shows a 16.1 percentage point improvement in Success over the learnable state-of-the-art baseline.

</p>
</details>

<details><summary><b>Meta-Learning for Online Update of Recommender Systems</b>
<a href="https://arxiv.org/abs/2203.10354">arxiv:2203.10354</a>
&#x1F4C8; 25 <br>
<p>Minseok Kim, Hwanjun Song, Yooju Shin, Dongmin Park, Kijung Shin, Jae-Gil Lee</p></summary>
<p>

**Abstract:** Online recommender systems should be always aligned with users' current interest to accurately suggest items that each user would like. Since user interest usually evolves over time, the update strategy should be flexible to quickly catch users' current interest from continuously generated new user-item interactions. Existing update strategies focus either on the importance of each user-item interaction or the learning rate for each recommender parameter, but such one-directional flexibility is insufficient to adapt to varying relationships between interactions and parameters. In this paper, we propose MeLON, a meta-learning based novel online recommender update strategy that supports two-directional flexibility. It is featured with an adaptive learning rate for each parameter-interaction pair for inducing a recommender to quickly learn users' up-to-date interest. The procedure of MeLON is optimized following a meta-learning approach: it learns how a recommender learns to generate the optimal learning rates for future updates. Specifically, MeLON first enriches the meaning of each interaction based on previous interactions and identifies the role of each parameter for the interaction; and then combines these two pieces of information to generate an adaptive learning rate. Theoretical analysis and extensive evaluation on three real-world online recommender datasets validate the effectiveness of MeLON.

</p>
</details>

<details><summary><b>On the Computation of Necessary and Sufficient Explanations</b>
<a href="https://arxiv.org/abs/2203.10451">arxiv:2203.10451</a>
&#x1F4C8; 12 <br>
<p>Adnan Darwiche, Chunxi Ji</p></summary>
<p>

**Abstract:** The complete reason behind a decision is a Boolean formula that characterizes why the decision was made. This recently introduced notion has a number of applications, which include generating explanations, detecting decision bias and evaluating counterfactual queries. Prime implicants of the complete reason are known as sufficient reasons for the decision and they correspond to what is known as PI explanations and abductive explanations. In this paper, we refer to the prime implicates of a complete reason as necessary reasons for the decision. We justify this terminology semantically and show that necessary reasons correspond to what is known as contrastive explanations. We also study the computation of complete reasons for multi-class decision trees and graphs with nominal and numeric features for which we derive efficient, closed-form complete reasons. We further investigate the computation of shortest necessary and sufficient reasons for a broad class of complete reasons, which include the derived closed forms and the complete reasons for Sentential Decision Diagrams (SDDs). We provide an algorithm which can enumerate their shortest necessary reasons in output polynomial time. Enumerating shortest sufficient reasons for this class of complete reasons is hard even for a single reason. For this problem, we provide an algorithm that appears to be quite efficient as we show empirically.

</p>
</details>

<details><summary><b>Sequence-to-Sequence Knowledge Graph Completion and Question Answering</b>
<a href="https://arxiv.org/abs/2203.10321">arxiv:2203.10321</a>
&#x1F4C8; 10 <br>
<p>Apoorv Saxena, Adrian Kochsiek, Rainer Gemulla</p></summary>
<p>

**Abstract:** Knowledge graph embedding (KGE) models represent each entity and relation of a knowledge graph (KG) with low-dimensional embedding vectors. These methods have recently been applied to KG link prediction and question answering over incomplete KGs (KGQA). KGEs typically create an embedding for each entity in the graph, which results in large model sizes on real-world graphs with millions of entities. For downstream tasks these atomic entity representations often need to be integrated into a multi stage pipeline, limiting their utility. We show that an off-the-shelf encoder-decoder Transformer model can serve as a scalable and versatile KGE model obtaining state-of-the-art results for KG link prediction and incomplete KG question answering. We achieve this by posing KG link prediction as a sequence-to-sequence task and exchange the triple scoring approach taken by prior KGE methods with autoregressive decoding. Such a simple but powerful method reduces the model size up to 98% compared to conventional KGE models while keeping inference time tractable. After finetuning this model on the task of KGQA over incomplete KGs, our approach outperforms baselines on multiple large-scale datasets without extensive hyperparameter tuning.

</p>
</details>

<details><summary><b>Efficient Neural Network Analysis with Sum-of-Infeasibilities</b>
<a href="https://arxiv.org/abs/2203.11201">arxiv:2203.11201</a>
&#x1F4C8; 7 <br>
<p>Haoze Wu, Aleksandar Zeljić, Guy Katz, Clark Barrett</p></summary>
<p>

**Abstract:** Inspired by sum-of-infeasibilities methods in convex optimization, we propose a novel procedure for analyzing verification queries on neural networks with piecewise-linear activation functions. Given a convex relaxation which over-approximates the non-convex activation functions, we encode the violations of activation functions as a cost function and optimize it with respect to the convex relaxation. The cost function, referred to as the Sum-of-Infeasibilities (SoI), is designed so that its minimum is zero and achieved only if all the activation functions are satisfied. We propose a stochastic procedure, DeepSoI, to efficiently minimize the SoI. An extension to a canonical case-analysis-based complete search procedure can be achieved by replacing the convex procedure executed at each search state with DeepSoI. Extending the complete search with DeepSoI achieves multiple simultaneous goals: 1) it guides the search towards a counter-example; 2) it enables more informed branching decisions; and 3) it creates additional opportunities for bound derivation. An extensive evaluation across different benchmarks and solvers demonstrates the benefit of the proposed techniques. In particular, we demonstrate that SoI significantly improves the performance of an existing complete search procedure. Moreover, the SoI-based implementation outperforms other state-of-the-art complete verifiers. We also show that our technique can efficiently improve upon the perturbation bound derived by a recent adversarial attack algorithm.

</p>
</details>

<details><summary><b>PipeGCN: Efficient Full-Graph Training of Graph Convolutional Networks with Pipelined Feature Communication</b>
<a href="https://arxiv.org/abs/2203.10428">arxiv:2203.10428</a>
&#x1F4C8; 7 <br>
<p>Cheng Wan, Youjie Li, Cameron R. Wolfe, Anastasios Kyrillidis, Nam Sung Kim, Yingyan Lin</p></summary>
<p>

**Abstract:** Graph Convolutional Networks (GCNs) is the state-of-the-art method for learning graph-structured data, and training large-scale GCNs requires distributed training across multiple accelerators such that each accelerator is able to hold a partitioned subgraph. However, distributed GCN training incurs prohibitive overhead of communicating node features and feature gradients among partitions for every GCN layer during each training iteration, limiting the achievable training efficiency and model scalability. To this end, we propose PipeGCN, a simple yet effective scheme that hides the communication overhead by pipelining inter-partition communication with intra-partition computation. It is non-trivial to pipeline for efficient GCN training, as communicated node features/gradients will become stale and thus can harm the convergence, negating the pipeline benefit. Notably, little is known regarding the convergence rate of GCN training with both stale features and stale feature gradients. This work not only provides a theoretical convergence analysis but also finds the convergence rate of PipeGCN to be close to that of the vanilla distributed GCN training without any staleness. Furthermore, we develop a smoothing method to further improve PipeGCN's convergence. Extensive experiments show that PipeGCN can largely boost the training throughput (1.7x~28.5x) while achieving the same accuracy as its vanilla counterpart and existing full-graph training methods. The code is available at https://github.com/RICE-EIC/PipeGCN.

</p>
</details>

<details><summary><b>Reinforcement learning for automatic quadrilateral mesh generation: a soft actor-critic approach</b>
<a href="https://arxiv.org/abs/2203.11203">arxiv:2203.11203</a>
&#x1F4C8; 6 <br>
<p>Jie Pan, Jingwei Huang, Gengdong Cheng, Yong Zeng</p></summary>
<p>

**Abstract:** This paper proposes, implements, and evaluates a Reinforcement Learning (RL) based computational framework for automatic mesh generation. Mesh generation, as one of six basic research directions identified in NASA Vision 2030, is an important area in computational geometry and plays a fundamental role in numerical simulations in the area of finite element analysis (FEA) and computational fluid dynamics (CFD). Existing mesh generation methods suffer from high computational complexity, low mesh quality in complex geometries, and speed limitations. By formulating the mesh generation as a Markov decision process (MDP) problem, we are able to use soft actor-critic, a state-of-the-art RL algorithm, to learn the meshing agent's policy from trials automatically, and achieve a fully automatic mesh generation system without human intervention and any extra clean-up operations, which are typically needed in current commercial software. In our experiments and comparison with a number of representative commercial software, our system demonstrates promising performance with respect to generalizability, robustness, and effectiveness.

</p>
</details>

<details><summary><b>FaiRR: Faithful and Robust Deductive Reasoning over Natural Language</b>
<a href="https://arxiv.org/abs/2203.10261">arxiv:2203.10261</a>
&#x1F4C8; 6 <br>
<p>Soumya Sanyal, Harman Singh, Xiang Ren</p></summary>
<p>

**Abstract:** Transformers have been shown to be able to perform deductive reasoning on a logical rulebase containing rules and statements written in natural language. Recent works show that such models can also produce the reasoning steps (i.e., the proof graph) that emulate the model's logical reasoning process. Currently, these black-box models generate both the proof graph and intermediate inferences within the same model and thus may be unfaithful. In this work, we frame the deductive logical reasoning task by defining three modular components: rule selection, fact selection, and knowledge composition. The rule and fact selection steps select the candidate rule and facts to be used and then the knowledge composition combines them to generate new inferences. This ensures model faithfulness by assured causal relation from the proof step to the inference reasoning. To test our framework, we propose FaiRR (Faithful and Robust Reasoner) where the above three components are independently modeled by transformers. We observe that FaiRR is robust to novel language perturbations, and is faster at inference than previous works on existing reasoning datasets. Additionally, in contrast to black-box generative models, the errors made by FaiRR are more interpretable due to the modular approach.

</p>
</details>

<details><summary><b>On Robust Prefix-Tuning for Text Classification</b>
<a href="https://arxiv.org/abs/2203.10378">arxiv:2203.10378</a>
&#x1F4C8; 5 <br>
<p>Zonghan Yang, Yang Liu</p></summary>
<p>

**Abstract:** Recently, prefix-tuning has gained increasing attention as a parameter-efficient finetuning method for large-scale pretrained language models. The method keeps the pretrained models fixed and only updates the prefix token parameters for each downstream task. Despite being lightweight and modular, prefix-tuning still lacks robustness to textual adversarial attacks. However, most currently developed defense techniques necessitate auxiliary model update and storage, which inevitably hamper the modularity and low storage of prefix-tuning. In this work, we propose a robust prefix-tuning framework that preserves the efficiency and modularity of prefix-tuning. The core idea of our framework is leveraging the layerwise activations of the language model by correctly-classified training data as the standard for additional prefix finetuning. During the test phase, an extra batch-level prefix is tuned for each batch and added to the original prefix for robustness enhancement. Extensive experiments on three text classification benchmarks show that our framework substantially improves robustness over several strong baselines against five textual attacks of different types while maintaining comparable accuracy on clean texts. We also interpret our robust prefix-tuning framework from the optimal control perspective and pose several directions for future research.

</p>
</details>

<details><summary><b>Understanding COVID-19 News Coverage using Medical NLP</b>
<a href="https://arxiv.org/abs/2203.10338">arxiv:2203.10338</a>
&#x1F4C8; 5 <br>
<p>Ali Emre Varol, Veysel Kocaman, Hasham Ul Haq, David Talby</p></summary>
<p>

**Abstract:** Being a global pandemic, the COVID-19 outbreak received global media attention. In this study, we analyze news publications from CNN and The Guardian - two of the world's most influential media organizations. The dataset includes more than 36,000 articles, analyzed using the clinical and biomedical Natural Language Processing (NLP) models from the Spark NLP for Healthcare library, which enables a deeper analysis of medical concepts than previously achieved. The analysis covers key entities and phrases, observed biases, and change over time in news coverage by correlating mined medical symptoms, procedures, drugs, and guidance with commonly mentioned demographic and occupational groups. Another analysis is of extracted Adverse Drug Events about drug and vaccine manufacturers, which when reported by major news outlets has an impact on vaccine hesitancy.

</p>
</details>

<details><summary><b>Representation-Agnostic Shape Fields</b>
<a href="https://arxiv.org/abs/2203.10259">arxiv:2203.10259</a>
&#x1F4C8; 5 <br>
<p>Xiaoyang Huang, Jiancheng Yang, Yanjun Wang, Ziyu Chen, Linguo Li, Teng Li, Bingbing Ni, Wenjun Zhang</p></summary>
<p>

**Abstract:** 3D shape analysis has been widely explored in the era of deep learning. Numerous models have been developed for various 3D data representation formats, e.g., MeshCNN for meshes, PointNet for point clouds and VoxNet for voxels. In this study, we present Representation-Agnostic Shape Fields (RASF), a generalizable and computation-efficient shape embedding module for 3D deep learning. RASF is implemented with a learnable 3D grid with multiple channels to store local geometry. Based on RASF, shape embeddings for various 3D shape representations (point clouds, meshes and voxels) are retrieved by coordinate indexing. While there are multiple ways to optimize the learnable parameters of RASF, we provide two effective schemes among all in this paper for RASF pre-training: shape reconstruction and normal estimation. Once trained, RASF becomes a plug-and-play performance booster with negligible cost. Extensive experiments on diverse 3D representation formats, networks and applications, validate the universal effectiveness of the proposed RASF. Code and pre-trained models are publicly available https://github.com/seanywang0408/RASF

</p>
</details>

<details><summary><b>Deep Learning based Intelligent Coin-tap Test for Defect Recognition</b>
<a href="https://arxiv.org/abs/2203.12594">arxiv:2203.12594</a>
&#x1F4C8; 4 <br>
<p>Hongyu Li, Peng Jiang, Tiejun Wang</p></summary>
<p>

**Abstract:** The coin-tap test is a convenient and primary method for non-destructive testing, while its manual on-site operation is tough and costly. With the help of the latest intelligent signal processing method, convolutional neural networks (CNN), we achieve an intelligent coin-tap test which exhibited superior performance in recognizing the defects. However, this success of CNNs relies on plenty of well-labeled data from the identical scenario, which could be difficult to get for many real industrial practices. This paper further develops transfer learning strategies for this issue, that is, to transfer the model trained on data of one scenario to another. In experiments, the result presents a notable improvement by using domain adaptation and pseudo label learning strategies. Hence, it becomes possible to apply the model into scenarios with none or little (less than 10\%) labeled data adopting the transfer learning strategies proposed herein. In addition, we used a benchmark dataset constructed ourselves throughout this study. This benchmark dataset for the coin-tap test containing around 100,000 sound signals is published at https://github.com/PPhub-hy/torch-tapnet.

</p>
</details>

<details><summary><b>CNNs and Transformers Perceive Hybrid Images Similar to Humans</b>
<a href="https://arxiv.org/abs/2203.11678">arxiv:2203.11678</a>
&#x1F4C8; 4 <br>
<p>Ali Borji</p></summary>
<p>

**Abstract:** Hybrid images is a technique to generate images with two interpretations that change as a function of viewing distance. It has been utilized to study multiscale processing of images by the human visual system. Using 63,000 hybrid images across 10 fruit categories, here we show that predictions of deep learning vision models qualitatively matches with the human perception of these images. Our results provide yet another evidence in support of the hypothesis that Convolutional Neural Networks (CNNs) and Transformers are good at modeling the feedforward sweep of information in the ventral stream of visual cortex. Code and data is available at https://github.com/aliborji/hybrid_images.git.

</p>
</details>

<details><summary><b>Exploiting Neighbor Effect: Conv-Agnostic GNNs Framework for Graphs with Heterophily</b>
<a href="https://arxiv.org/abs/2203.11200">arxiv:2203.11200</a>
&#x1F4C8; 4 <br>
<p>Jie Chen, Shouzhen Chen, Zengfeng Huang, Junping Zhang, Jian Pu</p></summary>
<p>

**Abstract:** Due to the homophily assumption of graph convolution networks, a common consensus is that graph neural networks (GNNs) perform well on homophilic graphs but may fail on the heterophilic graphs with many inter-class edges. In this work, we re-examine the heterophily problem of GNNs and investigate the feature aggregation of inter-class neighbors. To better evaluate whether the neighbor is helpful for the downstream tasks, we present the concept of the neighbor effect of each node and use the von Neumann entropy to measure the randomness/identifiability of the neighbor distribution for each class. Moreover, we propose a Conv-Agnostic GNNs framework (CAGNNs) to enhance the performance of GNNs on heterophily datasets by learning the neighbor effect for each node. Specifically, we first decouple the feature of each node into the discriminative feature for downstream tasks and the aggregation feature for graph convolution. Then, we propose a shared mixer module for all layers to adaptively evaluate the neighbor effect of each node to incorporate the neighbor information. Experiments are performed on nine well-known benchmark datasets for the node classification task. The results indicate that our framework is able to improve the average prediction performance by 9.81\%, 25.81\%, and 20.61\% for GIN, GAT, and GCN, respectively. Extensive ablation studies and robustness analysis further verify the effectiveness, robustness, and interpretability of our framework.

</p>
</details>

<details><summary><b>A Study on Robustness to Perturbations for Representations of Environmental Sound</b>
<a href="https://arxiv.org/abs/2203.10425">arxiv:2203.10425</a>
&#x1F4C8; 4 <br>
<p>Sangeeta Srivastava, Ho-Hsiang Wu, Joao Rulff, Magdalena Fuentes, Mark Cartwright, Claudio Silva, Anish Arora, Juan Pablo Bello</p></summary>
<p>

**Abstract:** Audio applications involving environmental sound analysis increasingly use general-purpose audio representations, also known as embeddings, for transfer learning. Recently, Holistic Evaluation of Audio Representations (HEAR) evaluated twenty-nine embedding models on nineteen diverse tasks. However, the evaluation's effectiveness depends on the variation already captured within a given dataset. Therefore, for a given data domain, it is unclear how the representations would be affected by the variations caused by myriad microphones' range and acoustic conditions -- commonly known as channel effects. We aim to extend HEAR to evaluate invariance to channel effects in this work. To accomplish this, we imitate channel effects by injecting perturbations to the audio signal and measure the shift in the new (perturbed) embeddings with three distance measures, making the evaluation domain-dependent but not task-dependent. Combined with the downstream performance, it helps us make a more informed prediction of how robust the embeddings are to the channel effects. We evaluate two embeddings -- YAMNet, and OpenL$^3$ on monophonic (UrbanSound8K) and polyphonic (SONYC UST) datasets. We show that one distance measure does not suffice in such task-independent evaluation. Although Fréchet Audio Distance (FAD) correlates with the trend of the performance drop in the downstream task most accurately, we show that we need to study this in conjunction with the other distances to get a clear understanding of the overall effect of the perturbation. In terms of the embedding performance, we find OpenL$^3$ to be more robust to YAMNet, which aligns with the HEAR evaluation.

</p>
</details>

<details><summary><b>ZOOMER: Boosting Retrieval on Web-scale Graphs by Regions of Interest</b>
<a href="https://arxiv.org/abs/2203.12596">arxiv:2203.12596</a>
&#x1F4C8; 3 <br>
<p>Yuezihan Jiang, Yu Cheng, Hanyu Zhao, Wentao Zhang, Xupeng Miao, Yu He, Liang Wang, Zhi Yang, Bin Cui</p></summary>
<p>

**Abstract:** We introduce ZOOMER, a system deployed at Taobao, the largest e-commerce platform in China, for training and serving GNN-based recommendations over web-scale graphs. ZOOMER is designed for tackling two challenges presented by the massive user data at Taobao: low training/serving efficiency due to the huge scale of the graphs, and low recommendation quality due to the information overload which distracts the recommendation model from specific user intentions. ZOOMER achieves this by introducing a key concept, Region of Interests (ROI) in GNNs for recommendations, i.e., a neighborhood region in the graph with significant relevance to a strong user intention. ZOOMER narrows the focus from the whole graph and "zooms in" on the more relevant ROIs, thereby reducing the training/serving cost and mitigating the information overload at the same time. With carefully designed mechanisms, ZOOMER identifies the interest expressed by each recommendation request, constructs an ROI subgraph by sampling with respect to the interest, and guides the GNN to reweigh different parts of the ROI towards the interest by a multi-level attention module. Deployed as a large-scale distributed system, ZOOMER supports graphs with billions of nodes for training and thousands of requests per second for serving. ZOOMER achieves up to 14x speedup when downsizing sampling scales with comparable (even better) AUC performance than baseline methods. Besides, both the offline evaluation and online A/B test demonstrate the effectiveness of ZOOMER.

</p>
</details>

<details><summary><b>PhysioMTL: Personalizing Physiological Patterns using Optimal Transport Multi-Task Regression</b>
<a href="https://arxiv.org/abs/2203.12595">arxiv:2203.12595</a>
&#x1F4C8; 3 <br>
<p>Jiacheng Zhu, Gregory Darnell, Agni Kumar, Ding Zhao, Bo Li, Xuanlong Nguyen, Shirley You Ren</p></summary>
<p>

**Abstract:** Heart rate variability (HRV) is a practical and noninvasive measure of autonomic nervous system activity, which plays an essential role in cardiovascular health. However, using HRV to assess physiology status is challenging. Even in clinical settings, HRV is sensitive to acute stressors such as physical activity, mental stress, hydration, alcohol, and sleep. Wearable devices provide convenient HRV measurements, but the irregularity of measurements and uncaptured stressors can bias conventional analytical methods. To better interpret HRV measurements for downstream healthcare applications, we learn a personalized diurnal rhythm as an accurate physiological indicator for each individual. We develop Physiological Multitask-Learning (PhysioMTL) by harnessing Optimal Transport theory within a Multitask-learning (MTL) framework. The proposed method learns an individual-specific predictive model from heterogeneous observations, and enables estimation of an optimal transport map that yields a push forward operation onto the demographic features for each task. Our model outperforms competing MTL methodologies on unobserved predictive tasks for synthetic and two real-world datasets. Specifically, our method provides remarkable prediction results on unseen held-out subjects given only $20\%$ of the subjects in real-world observational studies. Furthermore, our model enables a counterfactual engine that generates the effect of acute stressors and chronic conditions on HRV rhythms.

</p>
</details>

<details><summary><b>Partitioning Image Representation in Contrastive Learning</b>
<a href="https://arxiv.org/abs/2203.10454">arxiv:2203.10454</a>
&#x1F4C8; 3 <br>
<p>Hyunsub Lee, Heeyoul Choi</p></summary>
<p>

**Abstract:** In contrastive learning in the image domain, the anchor and positive samples are forced to have as close representations as possible. However, forcing the two samples to have the same representation could be misleading because the data augmentation techniques make the two samples different. In this paper, we introduce a new representation, partitioned representation, which can learn both common and unique features of the anchor and positive samples in contrastive learning. The partitioned representation consists of two parts: the content part and the style part. The content part represents common features of the class, and the style part represents the own features of each sample, which can lead to the representation of the data augmentation method. We can achieve the partitioned representation simply by decomposing a loss function of contrastive learning into two terms on the two separate representations, respectively. To evaluate our representation with two parts, we take two framework models: Variational AutoEncoder (VAE) and BootstrapYour Own Latent(BYOL) to show the separability of content and style, and to confirm the generalization ability in classification, respectively. Based on the experiments, we show that our approach can separate two types of information in the VAE framework and outperforms the conventional BYOL in linear separability and a few-shot learning task as downstream tasks.

</p>
</details>

<details><summary><b>Quantum Multi-Agent Reinforcement Learning via Variational Quantum Circuit Design</b>
<a href="https://arxiv.org/abs/2203.10443">arxiv:2203.10443</a>
&#x1F4C8; 3 <br>
<p>Won Joon Yun, Yunseok Kwak, Jae Pyoung Kim, Hyunhee Cho, Soyi Jung, Jihong Park, Joongheon Kim</p></summary>
<p>

**Abstract:** In recent years, quantum computing (QC) has been getting a lot of attention from industry and academia. Especially, among various QC research topics, variational quantum circuit (VQC) enables quantum deep reinforcement learning (QRL). Many studies of QRL have shown that the QRL is superior to the classical reinforcement learning (RL) methods under the constraints of the number of training parameters. This paper extends and demonstrates the QRL to quantum multi-agent RL (QMARL). However, the extension of QRL to QMARL is not straightforward due to the challenge of the noise intermediate-scale quantum (NISQ) and the non-stationary properties in classical multi-agent RL (MARL). Therefore, this paper proposes the centralized training and decentralized execution (CTDE) QMARL framework by designing novel VQCs for the framework to cope with these issues. To corroborate the QMARL framework, this paper conducts the QMARL demonstration in a single-hop environment where edge agents offload packets to clouds. The extensive demonstration shows that the proposed QMARL framework enhances 57.7% of total reward than classical frameworks.

</p>
</details>

<details><summary><b>Towards Structuring Real-World Data at Scale: Deep Learning for Extracting Key Oncology Information from Clinical Text with Patient-Level Supervision</b>
<a href="https://arxiv.org/abs/2203.10442">arxiv:2203.10442</a>
&#x1F4C8; 3 <br>
<p>Sam Preston, Mu Wei, Rajesh Rao, Robert Tinn, Naoto Usuyama, Michael Lucas, Roshanthi Weerasinghe, Soohee Lee, Brian Piening, Paul Tittel, Naveen Valluri, Tristan Naumann, Carlo Bifulco, Hoifung Poon</p></summary>
<p>

**Abstract:** Objective: The majority of detailed patient information in real-world data (RWD) is only consistently available in free-text clinical documents. Manual curation is expensive and time-consuming. Developing natural language processing (NLP) methods for structuring RWD is thus essential for scaling real-world evidence generation.
  Materials and Methods: Traditional rule-based systems are vulnerable to the prevalent linguistic variations and ambiguities in clinical text, and prior applications of machine-learning methods typically require sentence-level or report-level labeled examples that are hard to produce at scale. We propose leveraging patient-level supervision from medical registries, which are often readily available and capture key patient information, for general RWD applications. To combat the lack of sentence-level or report-level annotations, we explore advanced deep-learning methods by combining domain-specific pretraining, recurrent neural networks, and hierarchical attention.
  Results: We conduct an extensive study on 135,107 patients from the cancer registry of a large integrated delivery network (IDN) comprising healthcare systems in five western US states. Our deep learning methods attain test AUROC of 94-99% for key tumor attributes and comparable performance on held-out data from separate health systems and states.
  Discussion and Conclusion: Ablation results demonstrate clear superiority of these advanced deep-learning methods over prior approaches. Error analysis shows that our NLP system sometimes even corrects errors in registrar labels. We also conduct a preliminary investigation in accelerating registry curation and general RWD structuring via assisted curation for over 1.2 million cancer patients in this healthcare network.

</p>
</details>

<details><summary><b>Interpretability of Fine-grained Classification of Sadness and Depression</b>
<a href="https://arxiv.org/abs/2203.10432">arxiv:2203.10432</a>
&#x1F4C8; 3 <br>
<p>Tiasa Singha Roy, Priyam Basu, Aman Priyanshu, Rakshit Naidu</p></summary>
<p>

**Abstract:** While sadness is a human emotion that people experience at certain times throughout their lives, inflicting them with emotional disappointment and pain, depression is a longer term mental illness which impairs social, occupational, and other vital regions of functioning making it a much more serious issue and needs to be catered to at the earliest. NLP techniques can be utilized for the detection and subsequent diagnosis of these emotions. Most of the open sourced data on the web deal with sadness as a part of depression, as an emotion even though the difference in severity of both is huge. Thus, we create our own novel dataset illustrating the difference between the two. In this paper, we aim to highlight the difference between the two and highlight how interpretable our models are to distinctly label sadness and depression. Due to the sensitive nature of such information, privacy measures need to be taken for handling and training of such data. Hence, we also explore the effect of Federated Learning (FL) on contextualised language models.

</p>
</details>

<details><summary><b>STEMM: Self-learning with Speech-text Manifold Mixup for Speech Translation</b>
<a href="https://arxiv.org/abs/2203.10426">arxiv:2203.10426</a>
&#x1F4C8; 3 <br>
<p>Qingkai Fang, Rong Ye, Lei Li, Yang Feng, Mingxuan Wang</p></summary>
<p>

**Abstract:** How to learn a better speech representation for end-to-end speech-to-text translation (ST) with limited labeled data? Existing techniques often attempt to transfer powerful machine translation (MT) capabilities to ST, but neglect the representation discrepancy across modalities. In this paper, we propose the Speech-TExt Manifold Mixup (STEMM) method to calibrate such discrepancy. Specifically, we mix up the representation sequences of different modalities, and take both unimodal speech sequences and multimodal mixed sequences as input to the translation model in parallel, and regularize their output predictions with a self-learning framework. Experiments on MuST-C speech translation benchmark and further analysis show that our method effectively alleviates the cross-modal representation discrepancy, and achieves significant improvements over a strong baseline on eight translation directions.

</p>
</details>

<details><summary><b>Attri-VAE: attribute-based, disentangled and interpretable representations of medical images with variational autoencoders</b>
<a href="https://arxiv.org/abs/2203.10417">arxiv:2203.10417</a>
&#x1F4C8; 3 <br>
<p>Irem Cetin, Oscar Camara, Miguel Angel Gonzalez Ballester</p></summary>
<p>

**Abstract:** Deep learning (DL) methods where interpretability is intrinsically considered as part of the model are required to better understand the relationship of clinical and imaging-based attributes with DL outcomes, thus facilitating their use in reasoning medical decisions. Latent space representations built with variational autoencoders (VAE) do not ensure individual control of data attributes. Attribute-based methods enforcing attribute disentanglement have been proposed in the literature for classical computer vision tasks in benchmark data. In this paper, we propose a VAE approach, the Attri-VAE, that includes an attribute regularization term to associate clinical and medical imaging attributes with different regularized dimensions in the generated latent space, enabling a better disentangled interpretation of the attributes. Furthermore, the generated attention maps explained the attribute encoding in the regularized latent space dimensions. The Attri-VAE approach analyzed healthy and myocardial infarction patients with clinical, cardiac morphology, and radiomics attributes. The proposed model provided an excellent trade-off between reconstruction fidelity, disentanglement, and interpretability, outperforming state-of-the-art VAE approaches according to several quantitative metrics. The resulting latent space allowed the generation of realistic synthetic data in the trajectory between two distinct input samples or along a specific attribute dimension to better interpret changes between different cardiac conditions.

</p>
</details>

<details><summary><b>Anomaly Detection in Emails using Machine Learning and Header Information</b>
<a href="https://arxiv.org/abs/2203.10408">arxiv:2203.10408</a>
&#x1F4C8; 3 <br>
<p>Craig Beaman, Haruna Isah</p></summary>
<p>

**Abstract:** Anomalies in emails such as phishing and spam present major security risks such as the loss of privacy, money, and brand reputation to both individuals and organizations. Previous studies on email anomaly detection relied on a single type of anomaly and the analysis of the email body and subject content. A drawback of this approach is that it takes into account the written language of the email content. To overcome this deficit, this study conducted feature extraction and selection on email header datasets and leveraged both multi and one-class anomaly detection approaches. Experimental analysis results obtained demonstrate that email header information only is enough to reliably detect spam and phishing emails. Supervised learning algorithms such as Random Forest, SVM, MLP, KNN, and their stacked ensembles were found to be very successful, achieving high accuracy scores of 97% for phishing and 99% for spam emails. One-class classification with One-Class SVM achieved accuracy scores of 87% and 89% with spam and phishing emails, respectively. Real-world email filtering applications will benefit from the use of only the header information in terms of resources utilization and efficiency.

</p>
</details>

<details><summary><b>Lazy Rearrangement Planning in Confined Spaces</b>
<a href="https://arxiv.org/abs/2203.10379">arxiv:2203.10379</a>
&#x1F4C8; 3 <br>
<p>Rui Wang, Kai Gao, Jingjin Yu, Kostas Bekris</p></summary>
<p>

**Abstract:** Object rearrangement is important for many applications but remains challenging, especially in confined spaces, such as shelves, where objects cannot be easily accessed from above and they block reachability to each other. Such constraints require many motion planning and collision checking calls, which are computationally expensive. In addition, the arrangement space (space of possible object placements) grows exponentially with the number of objects. To address these issues, this work introduces a lazy evaluation framework for object rearrangement in confined spaces. It improves upon a local monotone solver, which extends to a high-quality planner for the general, non-monotone case. Monotone instances are those that can be solved by moving each object at most once. A key insight is that reachability constraints at the grasps for objects' starts and goals can quickly reveal dependencies between objects without having to execute expensive motion planning queries. The local solver builds lazily a search tree that respects these reachability constraints without verifying that the arm paths are collision free. It only collision checks when a promising solution is found given grasp reachability. If a monotone solution is not found, the non-monotone planner loads the lazy search tree and explores ways to move objects to intermediate locations from where monotone solutions to the goal can be found. The non-monotone planner also applies lazy evaluation to minimize collision checking. Comprehensive simulations and robot demonstrations show that the proposed framework can solve difficult instances in confined spaces with up to 16 objects, which state-of-the-art methods fail to solve. It also achieves high-quality solutions, i.e., only 1.8 additional actions on average are needed for non-monotone instances. It also solves problems faster than alternatives, when the alternatives find a solution.

</p>
</details>

<details><summary><b>Neural Machine Translation with Phrase-Level Universal Visual Representations</b>
<a href="https://arxiv.org/abs/2203.10299">arxiv:2203.10299</a>
&#x1F4C8; 3 <br>
<p>Qingkai Fang, Yang Feng</p></summary>
<p>

**Abstract:** Multimodal machine translation (MMT) aims to improve neural machine translation (NMT) with additional visual information, but most existing MMT methods require paired input of source sentence and image, which makes them suffer from shortage of sentence-image pairs. In this paper, we propose a phrase-level retrieval-based method for MMT to get visual information for the source input from existing sentence-image data sets so that MMT can break the limitation of paired sentence-image input. Our method performs retrieval at the phrase level and hence learns visual information from pairs of source phrase and grounded region, which can mitigate data sparsity. Furthermore, our method employs the conditional variational auto-encoder to learn visual representations which can filter redundant visual information and only retain visual information related to the phrase. Experiments show that the proposed method significantly outperforms strong baselines on multiple MMT datasets, especially when the textual context is limited.

</p>
</details>

<details><summary><b>Quantum Neural Networks -- Computational Field Theory and Dynamics</b>
<a href="https://arxiv.org/abs/2203.10292">arxiv:2203.10292</a>
&#x1F4C8; 3 <br>
<p>Carlos Pedro Gonçalves</p></summary>
<p>

**Abstract:** To address Quantum Artificial Neural Networks as quantum dynamical computing systems, a formalization of quantum artificial neural networks as dynamical systems is developed, expanding the concept of unitary map to the neural computation setting and introducing a quantum computing field theory on the network. The formalism is illustrated in a simulation of a quantum recurrent neural network and the resulting field dynamics is researched upon, showing emergent neural waves with excitation and relaxation cycles at the level of the quantum neural activity field, as well as edge of chaos signatures, with the local neurons operating as far-from-equilibrium open quantum systems, exhibiting entropy fluctuations with complex dynamics including complex quasiperiodic patterns and power law signatures. The implications for quantum computer science, quantum complexity research, quantum technologies and neuroscience are also addressed.

</p>
</details>

<details><summary><b>Multi-channel CNN to classify nepali covid-19 related tweets using hybrid features</b>
<a href="https://arxiv.org/abs/2203.10286">arxiv:2203.10286</a>
&#x1F4C8; 3 <br>
<p>Chiranjibi Sitaula, Tej Bahadur Shahi</p></summary>
<p>

**Abstract:** Because of the current COVID-19 pandemic with its increasing fears among people, it has triggered several health complications such as depression and anxiety. Such complications have not only affected the developed countries but also developing countries such as Nepal. These complications can be understood from peoples' tweets/comments posted online after their proper analysis and sentiment classification. Nevertheless, owing to the limited number of tokens/words in each tweet, it is always crucial to capture multiple information associated with them for their better understanding. In this study, we, first, represent each tweet by combining both syntactic and semantic information, called hybrid features. The syntactic information is generated from the bag of words method, whereas the semantic information is generated from the combination of the fastText-based (ft) and domain-specific (ds) methods. Second, we design a novel multi-channel convolutional neural network (MCNN), which ensembles the multiple CNNs, to capture multi-scale information for better classification. Last, we evaluate the efficacy of both the proposed feature extraction method and the MCNN model classifying tweets into three sentiment classes (positive, neutral and negative) on NepCOV19Tweets dataset, which is the only public COVID-19 tweets dataset in Nepali language. The evaluation results show that the proposed hybrid features outperform individual feature extraction methods with the highest classification accuracy of 69.7% and the MCNN model outperforms the existing methods with the highest classification accuracy of 71.3% during classification.

</p>
</details>

<details><summary><b>Exploiting Cross Domain Acoustic-to-articulatory Inverted Features For Disordered Speech Recognition</b>
<a href="https://arxiv.org/abs/2203.10274">arxiv:2203.10274</a>
&#x1F4C8; 3 <br>
<p>Shujie Hu, Shansong Liu, Xurong Xie, Mengzhe Geng, Tianzi Wang, Shoukang Hu, Mingyu Cui, Xunying Liu, Helen Meng</p></summary>
<p>

**Abstract:** Articulatory features are inherently invariant to acoustic signal distortion and have been successfully incorporated into automatic speech recognition (ASR) systems for normal speech. Their practical application to disordered speech recognition is often limited by the difficulty in collecting such specialist data from impaired speakers. This paper presents a cross-domain acoustic-to-articulatory (A2A) inversion approach that utilizes the parallel acoustic-articulatory data of the 15-hour TORGO corpus in model training before being cross-domain adapted to the 102.7-hour UASpeech corpus and to produce articulatory features. Mixture density networks based neural A2A inversion models were used. A cross-domain feature adaptation network was also used to reduce the acoustic mismatch between the TORGO and UASpeech data. On both tasks, incorporating the A2A generated articulatory features consistently outperformed the baseline hybrid DNN/TDNN, CTC and Conformer based end-to-end systems constructed using acoustic features only. The best multi-modal system incorporating video modality and the cross-domain articulatory features as well as data augmentation and learning hidden unit contributions (LHUC) speaker adaptation produced the lowest published word error rate (WER) of 24.82% on the 16 dysarthric speakers of the benchmark UASpeech task.

</p>
</details>

<details><summary><b>Plasticity Neural Network Based on Astrocytic Influence at Critical Periods, Synaptic Competition and Compensation by Current and Mnemonic Brain Plasticity and Synapse Formation</b>
<a href="https://arxiv.org/abs/2203.11740">arxiv:2203.11740</a>
&#x1F4C8; 2 <br>
<p>Jun-Bo Tao, Bai-Qing Sun, Wei-Dong Zhu, Shi-You Qu, Ling-Kun Chen, Jia-Qiang Li, Chong Wu, Yu Xiong, Jiaxuan Zhou</p></summary>
<p>

**Abstract:** Based on the RNN frame, we accomplished the model construction, formula derivation and algorithm testing for PNN. We elucidated the mechanism of PNN based on the latest MIT research on synaptic compensation, and also grounded our study on the basis of findings of the Stanford research, which suggested that synapse formation is important for competition in dendrite morphogenesis. The influence of astrocytic impacts on brain plasticity and synapse formation is an important mechanism of our Neural Network at critical periods or the end of critical periods.In the model for critical periods, the hypothesis is that the best brain plasticity so far affects current brain plasticity and the best synapse formation so far affects current synapse formation.Furthermore, PNN takes into account the mnemonic gradient informational synapse formation, and brain plasticity and synapse formation change frame of NN is a new method of Deep Learning.The question we proposed is whether the promotion of neuroscience and brain cognition was achieved by model construction, formula derivation or algorithm testing. We resorted to the Artificial Neural Network (ANN), evolutionary computation and other numerical methods for hypotheses, possible explanations and rules, rather than only biological tests which include cutting-edge imaging and genetic tools.And it has no ethics of animal testing.

</p>
</details>

<details><summary><b>Gated Recurrent Unit based Autoencoder for Optical Link Fault Diagnosis in Passive Optical Networks</b>
<a href="https://arxiv.org/abs/2203.11727">arxiv:2203.11727</a>
&#x1F4C8; 2 <br>
<p>Khouloud Abdelli, Florian Azendorf, Helmut Griesser, Carsten Tropschug, Stephan Pachnicke</p></summary>
<p>

**Abstract:** We propose a deep learning approach based on an autoencoder for identifying and localizing fiber faults in passive optical networks. The experimental results show that the proposed method detects faults with 97% accuracy, pinpoints them with an RMSE of 0.18 m and outperforms conventional techniques.

</p>
</details>

<details><summary><b>A 3D Molecule Generative Model for Structure-Based Drug Design</b>
<a href="https://arxiv.org/abs/2203.10446">arxiv:2203.10446</a>
&#x1F4C8; 2 <br>
<p>Shitong Luo, Jiaqi Guan, Jianzhu Ma, Jian Peng</p></summary>
<p>

**Abstract:** We study a fundamental problem in structure-based drug design -- generating molecules that bind to specific protein binding sites. While we have witnessed the great success of deep generative models in drug design, the existing methods are mostly string-based or graph-based. They are limited by the lack of spatial information and thus unable to be applied to structure-based design tasks. Particularly, such models have no or little knowledge of how molecules interact with their target proteins exactly in 3D space. In this paper, we propose a 3D generative model that generates molecules given a designated 3D protein binding site. Specifically, given a binding site as the 3D context, our model estimates the probability density of atom's occurrences in 3D space -- positions that are more likely to have atoms will be assigned higher probability. To generate 3D molecules, we propose an auto-regressive sampling scheme -- atoms are sampled sequentially from the learned distribution until there is no room for new atoms. Combined with this sampling scheme, our model can generate valid and diverse molecules, which could be applicable to various structure-based molecular design tasks such as molecule sampling and linker design. Experimental results demonstrate that molecules sampled from our model exhibit high binding affinity to specific targets and good drug properties such as drug-likeness even if the model is not explicitly optimized for them.

</p>
</details>

<details><summary><b>Data Smells: Categories, Causes and Consequences, and Detection of Suspicious Data in AI-based Systems</b>
<a href="https://arxiv.org/abs/2203.10384">arxiv:2203.10384</a>
&#x1F4C8; 2 <br>
<p>Harald Foidl, Michael Felderer, Rudolf Ramler</p></summary>
<p>

**Abstract:** High data quality is fundamental for today's AI-based systems. However, although data quality has been an object of research for decades, there is a clear lack of research on potential data quality issues (e.g., ambiguous, extraneous values). These kinds of issues are latent in nature and thus often not obvious. Nevertheless, they can be associated with an increased risk of future problems in AI-based systems (e.g., technical debt, data-induced faults). As a counterpart to code smells in software engineering, we refer to such issues as Data Smells. This article conceptualizes data smells and elaborates on their causes, consequences, detection, and use in the context of AI-based systems. In addition, a catalogue of 36 data smells divided into three categories (i.e., Believability Smells, Understandability Smells, Consistency Smells) is presented. Moreover, the article outlines tool support for detecting data smells and presents the result of an initial smell detection on more than 240 real-world datasets.

</p>
</details>

<details><summary><b>Automatic Detection of Entity-Manipulated Text using Factual Knowledge</b>
<a href="https://arxiv.org/abs/2203.10343">arxiv:2203.10343</a>
&#x1F4C8; 2 <br>
<p>Ganesh Jawahar, Muhammad Abdul-Mageed, Laks V. S. Lakshmanan</p></summary>
<p>

**Abstract:** In this work, we focus on the problem of distinguishing a human written news article from a news article that is created by manipulating entities in a human written news article (e.g., replacing entities with factually incorrect entities). Such manipulated articles can mislead the reader by posing as a human written news article. We propose a neural network based detector that detects manipulated news articles by reasoning about the facts mentioned in the article. Our proposed detector exploits factual knowledge via graph convolutional neural network along with the textual information in the news article. We also create challenging datasets for this task by considering various strategies to generate the new replacement entity (e.g., entity generation from GPT-2). In all the settings, our proposed model either matches or outperforms the state-of-the-art detector in terms of accuracy. Our code and data are available at https://github.com/UBC-NLP/manipulated_entity_detection.

</p>
</details>

<details><summary><b>Learning to Reason Deductively: Math Word Problem Solving as Complex Relation Extraction</b>
<a href="https://arxiv.org/abs/2203.10316">arxiv:2203.10316</a>
&#x1F4C8; 2 <br>
<p>Zhanming Jie, Jierui Li, Wei Lu</p></summary>
<p>

**Abstract:** Solving math word problems requires deductive reasoning over the quantities in the text. Various recent research efforts mostly relied on sequence-to-sequence or sequence-to-tree models to generate mathematical expressions without explicitly performing relational reasoning between quantities in the given context. While empirically effective, such approaches typically do not provide explanations for the generated expressions. In this work, we view the task as a complex relation extraction problem, proposing a novel approach that presents explainable deductive reasoning steps to iteratively construct target expressions, where each step involves a primitive operation over two quantities defining their relation. Through extensive experiments on four benchmark datasets, we show that the proposed model significantly outperforms existing strong baselines. We further demonstrate that the deductive procedure not only presents more explainable steps but also enables us to make more accurate predictions on questions that require more complex reasoning.

</p>
</details>

<details><summary><b>Assessing Gender Bias in Predictive Algorithms using eXplainable AI</b>
<a href="https://arxiv.org/abs/2203.10264">arxiv:2203.10264</a>
&#x1F4C8; 2 <br>
<p>Cristina Manresa-Yee, Silvia Ramis</p></summary>
<p>

**Abstract:** Predictive algorithms have a powerful potential to offer benefits in areas as varied as medicine or education. However, these algorithms and the data they use are built by humans, consequently, they can inherit the bias and prejudices present in humans. The outcomes can systematically repeat errors that create unfair results, which can even lead to situations of discrimination (e.g. gender, social or racial). In order to illustrate how important is to count with a diverse training dataset to avoid bias, we manipulate a well-known facial expression recognition dataset to explore gender bias and discuss its implications.

</p>
</details>

<details><summary><b>DiSECt: A Differentiable Simulator for Parameter Inference and Control in Robotic Cutting</b>
<a href="https://arxiv.org/abs/2203.10263">arxiv:2203.10263</a>
&#x1F4C8; 2 <br>
<p>Eric Heiden, Miles Macklin, Yashraj Narang, Dieter Fox, Animesh Garg, Fabio Ramos</p></summary>
<p>

**Abstract:** Robotic cutting of soft materials is critical for applications such as food processing, household automation, and surgical manipulation. As in other areas of robotics, simulators can facilitate controller verification, policy learning, and dataset generation. Moreover, differentiable simulators can enable gradient-based optimization, which is invaluable for calibrating simulation parameters and optimizing controllers. In this work, we present DiSECt: the first differentiable simulator for cutting soft materials. The simulator augments the finite element method (FEM) with a continuous contact model based on signed distance fields (SDF), as well as a continuous damage model that inserts springs on opposite sides of the cutting plane and allows them to weaken until zero stiffness, enabling crack formation. Through various experiments, we evaluate the performance of the simulator. We first show that the simulator can be calibrated to match resultant forces and deformation fields from a state-of-the-art commercial solver and real-world cutting datasets, with generality across cutting velocities and object instances. We then show that Bayesian inference can be performed efficiently by leveraging the differentiability of the simulator, estimating posteriors over hundreds of parameters in a fraction of the time of derivative-free methods. Next, we illustrate that control parameters in the simulation can be optimized to minimize cutting forces via lateral slicing motions. Finally, we conduct experiments on a real robot arm equipped with a slicing knife to infer simulation parameters from force measurements. By optimizing the slicing motion of the knife, we show on fruit cutting scenarios that the average knife force can be reduced by more than 40% compared to a vertical cutting motion. We publish code and additional materials on our project website at https://diff-cutting-sim.github.io.

</p>
</details>

<details><summary><b>Optical Fiber Fault Detection and Localization in a Noisy OTDR Trace Based on Denoising Convolutional Autoencoder and Bidirectional Long Short-Term Memory</b>
<a href="https://arxiv.org/abs/2203.12604">arxiv:2203.12604</a>
&#x1F4C8; 1 <br>
<p>Khouloud Abdelli, Helmut Griesser, Carsten Tropschug, Stephan Pachnicke</p></summary>
<p>

**Abstract:** Optical time-domain reflectometry (OTDR) has been widely used for characterizing fiber optical links and for detecting and locating fiber faults. OTDR traces are prone to be distorted by different kinds of noise, causing blurring of the backscattered signals, and thereby leading to a misleading interpretation and a more cumbersome event detection task. To address this problem, a novel method combining a denoising convolutional autoencoder (DCAE) and a bidirectional long short-term memory (BiLSTM) is proposed, whereby the former is used for noise removal of OTDR signals and the latter for fault detection, localization, and diagnosis with the denoised signal as input. The proposed approach is applied to noisy OTDR signals of different levels of input SNR ranging from -5 dB to 15 dB. The experimental results demonstrate that: (i) the DCAE is efficient in denoising the OTDR traces and it outperforms other deep learning techniques and the conventional denoising methods; and (ii) the BiLSTM achieves a high detection and diagnostic accuracy of 96.7% with an improvement of 13.74% compared to the performance of the same model trained with noisy OTDR signals.

</p>
</details>

<details><summary><b>A Hybrid CNN-LSTM Approach for Laser Remaining Useful Life Prediction</b>
<a href="https://arxiv.org/abs/2203.12415">arxiv:2203.12415</a>
&#x1F4C8; 1 <br>
<p>Khouloud Abdelli, Helmut Griesser, Stephan Pachnicke</p></summary>
<p>

**Abstract:** A hybrid prognostic model based on convolutional neural networks (CNN) and long short-term memory (LSTM) is proposed to predict the laser remaining useful life (RUL). The experimental results show that it outperforms the conventional methods.

</p>
</details>

<details><summary><b>Federated Learning Approach for Lifetime Prediction of Semiconductor Lasers</b>
<a href="https://arxiv.org/abs/2203.12414">arxiv:2203.12414</a>
&#x1F4C8; 1 <br>
<p>Khouloud Abdelli, Helmut Griesser, Stephan Pachnicke</p></summary>
<p>

**Abstract:** A new privacy-preserving federated learning framework allowing laser manufacturers to collaboratively build a robust ML-based laser lifetime prediction model, is proposed. It achieves a mean absolute error of 0.1 years and a significant performance improvement

</p>
</details>

<details><summary><b>Machine Learning based Laser Failure Mode Detection</b>
<a href="https://arxiv.org/abs/2203.11729">arxiv:2203.11729</a>
&#x1F4C8; 1 <br>
<p>Khouloud Abdelli, Danish Rafique, Stephan Pachnicke</p></summary>
<p>

**Abstract:** Laser degradation analysis is a crucial process for the enhancement of laser reliability. Here, we propose a data-driven fault detection approach based on Long Short-Term Memory (LSTM) recurrent neural networks to detect the different laser degradation modes based on synthetic historical failure data. In comparison to typical threshold-based systems, attaining 24.41% classification accuracy, the LSTM-based model achieves 95.52% accuracy, and also outperforms classical machine learning (ML) models namely Random Forest (RF), K-Nearest Neighbours (KNN) and Logistic Regression (LR).

</p>
</details>

<details><summary><b>Machine Learning based Data Driven Diagnostic and Prognostic Approach for Laser Reliability Enhancement</b>
<a href="https://arxiv.org/abs/2203.11728">arxiv:2203.11728</a>
&#x1F4C8; 1 <br>
<p>Khouloud Abdelli, Helmut Griesser, Stephan Pachnicke</p></summary>
<p>

**Abstract:** In this paper, a data-driven diagnostic and prognostic approach based on machine learning is proposed to detect laser failure modes and to predict the remaining useful life (RUL) of a laser during its operation. We present an architecture of the proposed cognitive predictive maintenance framework and demonstrate its effectiveness using synthetic data.

</p>
</details>

<details><summary><b>Robust Action Gap Increasing with Clipped Advantage Learning</b>
<a href="https://arxiv.org/abs/2203.11677">arxiv:2203.11677</a>
&#x1F4C8; 1 <br>
<p>Zhe Zhang, Yaozhong Gan, Xiaoyang Tan</p></summary>
<p>

**Abstract:** Advantage Learning (AL) seeks to increase the action gap between the optimal action and its competitors, so as to improve the robustness to estimation errors. However, the method becomes problematic when the optimal action induced by the approximated value function does not agree with the true optimal action. In this paper, we present a novel method, named clipped Advantage Learning (clipped AL), to address this issue. The method is inspired by our observation that increasing the action gap blindly for all given samples while not taking their necessities into account could accumulate more errors in the performance loss bound, leading to a slow value convergence, and to avoid that, we should adjust the advantage value adaptively. We show that our simple clipped AL operator not only enjoys fast convergence guarantee but also retains proper action gaps, hence achieving a good balance between the large action gap and the fast convergence. The feasibility and effectiveness of the proposed method are verified empirically on several RL benchmarks with promising performance.

</p>
</details>

<details><summary><b>Doubly Robust Collaborative Targeted Learning for Recommendation on Data Missing Not at Random</b>
<a href="https://arxiv.org/abs/2203.10258">arxiv:2203.10258</a>
&#x1F4C8; 1 <br>
<p>Peng Wu, Haoxuan Li, Yan Lyu, Xiao-Hua Zhou</p></summary>
<p>

**Abstract:** In recommender systems, the feedback data received is always missing not at random (MNAR), which poses challenges for accurate rating prediction. To address this issue, many recent studies have been conducted on the doubly robust (DR) method and its variants to reduce bias. However, theoretical analysis shows that the DR method has a relatively large variance, while that of the error imputation-based (EIB) method is smaller. In this paper, we propose {\bf DR-TMLE} that effectively captures the merits of both EIB and DR, by leveraging the targeted maximum likelihood estimation (TMLE) technique. DR-TMLE first obtains an initial EIB estimator and then updates the error imputation model along with the bias-reduced direction. Furthermore, we propose a novel RCT-free collaborative targeted learning algorithm for DR-TMLE, called {\bf DR-TMLE-TL}, which updates the propensity model adaptively to reduce the bias of imputed errors. Both theoretical analysis and experiments demonstrate the advantages of the proposed methods compared with existing debiasing methods.

</p>
</details>


{% endraw %}
Prev: [2022.03.18]({{ '/2022/03/18/2022.03.18.html' | relative_url }})  Next: [2022.03.20]({{ '/2022/03/20/2022.03.20.html' | relative_url }})