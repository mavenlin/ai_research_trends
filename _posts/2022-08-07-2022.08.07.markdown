Prev: [2022.08.06]({{ '/2022/08/06/2022.08.06.html' | relative_url }})  Next: [2022.08.08]({{ '/2022/08/08/2022.08.08.html' | relative_url }})
{% raw %}
## Summary for 2022-08-07, created on 2022-08-11


<details><summary><b>Neural Optimization Machine: A Neural Network Approach for Optimization</b>
<a href="https://arxiv.org/abs/2208.03897">arxiv:2208.03897</a>
&#x1F4C8; 6 <br>
<p>Jie Chen, Yongming Liu</p></summary>
<p>

**Abstract:** A novel neural network (NN) approach is proposed for constrained optimization. The proposed method uses a specially designed NN architecture and training/optimization procedure called Neural Optimization Machine (NOM). The objective functions for the NOM are approximated with NN models. The optimization process is conducted by the neural network's built-in backpropagation algorithm. The NOM solves optimization problems by extending the architecture of the NN objective function model. This is achieved by appropriately designing the NOM's structure, activation function, and loss function. The NN objective function can have arbitrary architectures and activation functions. The application of the NOM is not limited to specific optimization problems, e.g., linear and quadratic programming. It is shown that the increase of dimension of design variables does not increase the computational cost significantly. Then, the NOM is extended for multiobjective optimization. Finally, the NOM is tested using numerical optimization problems and applied for the optimal design of processing parameters in additive manufacturing.

</p>
</details>

<details><summary><b>CheXRelNet: An Anatomy-Aware Model for Tracking Longitudinal Relationships between Chest X-Rays</b>
<a href="https://arxiv.org/abs/2208.03873">arxiv:2208.03873</a>
&#x1F4C8; 6 <br>
<p>Gaurang Karwande, Amarachi Mbakawe, Joy T. Wu, Leo A. Celi, Mehdi Moradi, Ismini Lourentzou</p></summary>
<p>

**Abstract:** Despite the progress in utilizing deep learning to automate chest radiograph interpretation and disease diagnosis tasks, change between sequential Chest X-rays (CXRs) has received limited attention. Monitoring the progression of pathologies that are visualized through chest imaging poses several challenges in anatomical motion estimation and image registration, i.e., spatially aligning the two images and modeling temporal dynamics in change detection. In this work, we propose CheXRelNet, a neural model that can track longitudinal pathology change relations between two CXRs. CheXRelNet incorporates local and global visual features, utilizes inter-image and intra-image anatomical information, and learns dependencies between anatomical region attributes, to accurately predict disease change for a pair of CXRs. Experimental results on the Chest ImaGenome dataset show increased downstream performance compared to baselines. Code is available at https://github.com/PLAN-Lab/ChexRelNet

</p>
</details>

<details><summary><b>Learning Entity Linking Features for Emerging Entities</b>
<a href="https://arxiv.org/abs/2208.03877">arxiv:2208.03877</a>
&#x1F4C8; 5 <br>
<p>Chenwei Ran, Wei Shen, Jianbo Gao, Yuhan Li, Jianyong Wang, Yantao Jia</p></summary>
<p>

**Abstract:** Entity linking (EL) is the process of linking entity mentions appearing in text with their corresponding entities in a knowledge base. EL features of entities (e.g., prior probability, relatedness score, and entity embedding) are usually estimated based on Wikipedia. However, for newly emerging entities (EEs) which have just been discovered in news, they may still not be included in Wikipedia yet. As a consequence, it is unable to obtain required EL features for those EEs from Wikipedia and EL models will always fail to link ambiguous mentions with those EEs correctly as the absence of their EL features. To deal with this problem, in this paper we focus on a new task of learning EL features for emerging entities in a general way. We propose a novel approach called STAMO to learn high-quality EL features for EEs automatically, which needs just a small number of labeled documents for each EE collected from the Web, as it could further leverage the knowledge hidden in the unlabeled data. STAMO is mainly based on self-training, which makes it flexibly integrated with any EL feature or EL model, but also makes it easily suffer from the error reinforcement problem caused by the mislabeled data. Instead of some common self-training strategies that try to throw the mislabeled data away explicitly, we regard self-training as a multiple optimization process with respect to the EL features of EEs, and propose both intra-slot and inter-slot optimizations to alleviate the error reinforcement problem implicitly. We construct two EL datasets involving selected EEs to evaluate the quality of obtained EL features for EEs, and the experimental results show that our approach significantly outperforms other baseline methods of learning EL features.

</p>
</details>

<details><summary><b>How Adversarial Robustness Transfers from Pre-training to Downstream Tasks</b>
<a href="https://arxiv.org/abs/2208.03835">arxiv:2208.03835</a>
&#x1F4C8; 5 <br>
<p>Laura Fee Nern, Yash Sharma</p></summary>
<p>

**Abstract:** Given the rise of large-scale training regimes, adapting pre-trained models to a wide range of downstream tasks has become a standard approach in machine learning. While large benefits in empirical performance have been observed, it is not yet well understood how robustness properties transfer from a pre-trained model to a downstream task. We prove that the robustness of a predictor on downstream tasks can be bound by the robustness of its underlying representation, irrespective of the pre-training protocol. Taken together, our results precisely characterize what is required of the representation function for reliable performance upon deployment.

</p>
</details>

<details><summary><b>Dynamic Maintenance of Kernel Density Estimation Data Structure: From Practice to Theory</b>
<a href="https://arxiv.org/abs/2208.03915">arxiv:2208.03915</a>
&#x1F4C8; 4 <br>
<p>Jiehao Liang, Zhao Song, Zhaozhuo Xu, Danyang Zhuo</p></summary>
<p>

**Abstract:** Kernel density estimation (KDE) stands out as a challenging task in machine learning. The problem is defined in the following way: given a kernel function $f(x,y)$ and a set of points $\{x_1, x_2, \cdots, x_n \} \subset \mathbb{R}^d$, we would like to compute $\frac{1}{n}\sum_{i=1}^{n} f(x_i,y)$ for any query point $y \in \mathbb{R}^d$. Recently, there has been a growing trend of using data structures for efficient KDE. However, the proposed KDE data structures focus on static settings. The robustness of KDE data structures over dynamic changing data distributions is not addressed. In this work, we focus on the dynamic maintenance of KDE data structures with robustness to adversarial queries. Especially, we provide a theoretical framework of KDE data structures. In our framework, the KDE data structures only require subquadratic spaces. Moreover, our data structure supports the dynamic update of the dataset in sublinear time. Furthermore, we can perform adaptive queries with the potential adversary in sublinear time.

</p>
</details>

<details><summary><b>Clear Memory-Augmented Auto-Encoder for Surface Defect Detection</b>
<a href="https://arxiv.org/abs/2208.03879">arxiv:2208.03879</a>
&#x1F4C8; 4 <br>
<p>Wei Luo, Tongzhi Niu, Lixin Tang, Wenyong Yu, Bin Li</p></summary>
<p>

**Abstract:** In surface defect detection, due to the extreme imbalance in the number of positive and negative samples, positive-samples-based anomaly detection methods have received more and more attention. Specifically, reconstruction-based methods are the most popular. However, exiting methods are either difficult to repair abnormal foregrounds or reconstruct clear backgrounds. Therefore, we propose a clear memory-augmented auto-encoder. At first, we propose a novel clear memory-augmented module, which combines the encoding and memory-encoding in a way of forgetting and inputting, thereby repairing abnormal foregrounds and preservation clear backgrounds. Secondly, a general artificial anomaly generation algorithm is proposed to simulate anomalies that are as realistic and feature-rich as possible. At last, we propose a novel multi scale feature residual detection method for defect segmentation, which makes the defect location more accurate. CMA-AE conducts comparative experiments using 11 state-of-the-art methods on five benchmark datasets, showing an average 18.6% average improvement in F1-measure.

</p>
</details>

<details><summary><b>Information bottleneck theory of high-dimensional regression: relevancy, efficiency and optimality</b>
<a href="https://arxiv.org/abs/2208.03848">arxiv:2208.03848</a>
&#x1F4C8; 4 <br>
<p>Vudtiwat Ngampruetikorn, David J. Schwab</p></summary>
<p>

**Abstract:** Avoiding overfitting is a central challenge in machine learning, yet many large neural networks readily achieve zero training loss. This puzzling contradiction necessitates new approaches to the study of overfitting. Here we quantify overfitting via residual information, defined as the bits in fitted models that encode noise in training data. Information efficient learning algorithms minimize residual information while maximizing the relevant bits, which are predictive of the unknown generative models. We solve this optimization to obtain the information content of optimal algorithms for a linear regression problem and compare it to that of randomized ridge regression. Our results demonstrate the fundamental tradeoff between residual and relevant information and characterize the relative information efficiency of randomized regression with respect to optimal algorithms. Finally, using results from random matrix theory, we reveal the information complexity of learning a linear map in high dimensions and unveil information-theoretic analogs of double and multiple descent phenomena.

</p>
</details>

<details><summary><b>An Empirical Analysis of the Laplace and Neural Tangent Kernels</b>
<a href="https://arxiv.org/abs/2208.03761">arxiv:2208.03761</a>
&#x1F4C8; 4 <br>
<p>Ronaldas Paulius Lencevicius</p></summary>
<p>

**Abstract:** The neural tangent kernel is a kernel function defined over the parameter distribution of an infinite width neural network. Despite the impracticality of this limit, the neural tangent kernel has allowed for a more direct study of neural networks and a gaze through the veil of their black box. More recently, it has been shown theoretically that the Laplace kernel and neural tangent kernel share the same reproducing kernel Hilbert space in the space of $\mathbb{S}^{d-1}$ alluding to their equivalence. In this work, we analyze the practical equivalence of the two kernels. We first do so by matching the kernels exactly and then by matching posteriors of a Gaussian process. Moreover, we analyze the kernels in $\mathbb{R}^d$ and experiment with them in the task of regression.

</p>
</details>

<details><summary><b>Granger Causality using Neural Networks</b>
<a href="https://arxiv.org/abs/2208.03703">arxiv:2208.03703</a>
&#x1F4C8; 4 <br>
<p>Samuel Horvath, Malik Shahid Sultan, Hernando Ombao</p></summary>
<p>

**Abstract:** The Granger Causality (GC) test is a famous statistical hypothesis test for investigating if the past of one time series affects the future of the other. It helps in answering the question whether one time series is helpful in forecasting. Standard traditional approaches to Granger causality detection commonly assume linear dynamics, but such simplification does not hold in many real-world applications, e.g., neuroscience or genomics that are inherently non-linear. In such cases, imposing linear models such as Vector Autoregressive (VAR) models can lead to inconsistent estimation of true Granger Causal interactions. Machine Learning (ML) can learn the hidden patterns in the datasets specifically Deep Learning (DL) has shown tremendous promise in learning the non-linear dynamics of complex systems. Recent work of Tank et al propose to overcome the issue of linear simplification in VAR models by using neural networks combined with sparsity-inducing penalties on the learn-able weights. In this work, we build upon ideas introduced by Tank et al. We propose several new classes of models that can handle underlying non-linearity. Firstly, we present the Learned Kernal VAR(LeKVAR) model-an extension of VAR models that also learns kernel parametrized by a neural net. Secondly, we show one can directly decouple lags and individual time series importance via decoupled penalties. This decoupling provides better scaling and allows us to embed lag selection into RNNs. Lastly, we propose a new training algorithm that supports mini-batching, and it is compatible with commonly used adaptive optimizers such as Adam.he proposed techniques are evaluated on several simulated datasets inspired by real-world applications.We also apply these methods to the Electro-Encephalogram (EEG) data for an epilepsy patient to study the evolution of GC before , during and after seizure across the 19 EEG channels.

</p>
</details>

<details><summary><b>Mining Reaction and Diffusion Dynamics in Social Activities</b>
<a href="https://arxiv.org/abs/2208.04846">arxiv:2208.04846</a>
&#x1F4C8; 3 <br>
<p>Taichi Murayama, Yasuko Matsubara, Sakurai Yasushi</p></summary>
<p>

**Abstract:** Large quantifies of online user activity data, such as weekly web search volumes, which co-evolve with the mutual influence of several queries and locations, serve as an important social sensor. It is an important task to accurately forecast the future activity by discovering latent interactions from such data, i.e., the ecosystems between each query and the flow of influences between each area. However, this is a difficult problem in terms of data quantity and complex patterns covering the dynamics. To tackle the problem, we propose FluxCube, which is an effective mining method that forecasts large collections of co-evolving online user activity and provides good interpretability. Our model is the expansion of a combination of two mathematical models: a reaction-diffusion system provides a framework for modeling the flow of influences between local area groups and an ecological system models the latent interactions between each query. Also, by leveraging the concept of physics-informed neural networks, FluxCube achieves high interpretability obtained from the parameters and high forecasting performance, together. Extensive experiments on real datasets showed that FluxCube outperforms comparable models in terms of the forecasting accuracy, and each component in FluxCube contributes to the enhanced performance. We then show some case studies that FluxCube can extract useful latent interactions between queries and area groups.

</p>
</details>

<details><summary><b>Adaptive Local Implicit Image Function for Arbitrary-scale Super-resolution</b>
<a href="https://arxiv.org/abs/2208.04318">arxiv:2208.04318</a>
&#x1F4C8; 3 <br>
<p>Hongwei Li, Tao Dai, Yiming Li, Xueyi Zou, Shu-Tao Xia</p></summary>
<p>

**Abstract:** Image representation is critical for many visual tasks. Instead of representing images discretely with 2D arrays of pixels, a recent study, namely local implicit image function (LIIF), denotes images as a continuous function where pixel values are expansion by using the corresponding coordinates as inputs. Due to its continuous nature, LIIF can be adopted for arbitrary-scale image super-resolution tasks, resulting in a single effective and efficient model for various up-scaling factors. However, LIIF often suffers from structural distortions and ringing artifacts around edges, mostly because all pixels share the same model, thus ignoring the local properties of the image. In this paper, we propose a novel adaptive local image function (A-LIIF) to alleviate this problem. Specifically, our A-LIIF consists of two main components: an encoder and a expansion network. The former captures cross-scale image features, while the latter models the continuous up-scaling function by a weighted combination of multiple local implicit image functions. Accordingly, our A-LIIF can reconstruct the high-frequency textures and structures more accurately. Experiments on multiple benchmark datasets verify the effectiveness of our method. Our codes are available at \url{https://github.com/LeeHW-THU/A-LIIF}.

</p>
</details>

<details><summary><b>SelfCoLearn: Self-supervised collaborative learning for accelerating dynamic MR imaging</b>
<a href="https://arxiv.org/abs/2208.03904">arxiv:2208.03904</a>
&#x1F4C8; 3 <br>
<p>Juan Zou, Cheng Li, Sen Jia, Ruoyou Wu, Tingrui Pei, Hairong Zheng, Shanshan Wang</p></summary>
<p>

**Abstract:** Lately, deep learning has been extensively investigated for accelerating dynamic magnetic resonance (MR) imaging, with encouraging progresses achieved. However, without fully sampled reference data for training, current approaches may have limited abilities in recovering fine details or structures. To address this challenge, this paper proposes a self-supervised collaborative learning framework (SelfCoLearn) for accurate dynamic MR image reconstruction from undersampled k-space data. The proposed framework is equipped with three important components, namely, dual-network collaborative learning, reunderampling data augmentation and a specially designed co-training loss. The framework is flexible to be integrated with both data-driven networks and model-based iterative un-rolled networks. Our method has been evaluated on in-vivo dataset and compared it to four state-of-the-art methods. Results show that our method possesses strong capabilities in capturing essential and inherent representations for direct reconstructions from the undersampled k-space data and thus enables high-quality and fast dynamic MR imaging.

</p>
</details>

<details><summary><b>Data-centric AI approach to improve optic nerve head segmentation and localization in OCT en face images</b>
<a href="https://arxiv.org/abs/2208.03868">arxiv:2208.03868</a>
&#x1F4C8; 3 <br>
<p>Thomas Schlegl, Heiko Stino, Michael Niederleithner, Andreas Pollreisz, Ursula Schmidt-Erfurth, Wolfgang Drexler, Rainer A. Leitgeb, Tilman Schmoll</p></summary>
<p>

**Abstract:** The automatic detection and localization of anatomical features in retinal imaging data are relevant for many aspects. In this work, we follow a data-centric approach to optimize classifier training for optic nerve head detection and localization in optical coherence tomography en face images of the retina. We examine the effect of domain knowledge driven spatial complexity reduction on the resulting optic nerve head segmentation and localization performance. We present a machine learning approach for segmenting optic nerve head in 2D en face projections of 3D widefield swept source optical coherence tomography scans that enables the automated assessment of large amounts of data. Evaluation on manually annotated 2D en face images of the retina demonstrates that training of a standard U-Net can yield improved optic nerve head segmentation and localization performance when the underlying pixel-level binary classification task is spatially relaxed through domain knowledge.

</p>
</details>

<details><summary><b>RadSegNet: A Reliable Approach to Radar Camera Fusion</b>
<a href="https://arxiv.org/abs/2208.03849">arxiv:2208.03849</a>
&#x1F4C8; 3 <br>
<p>Kshitiz Bansal, Keshav Rungta, Dinesh Bharadia</p></summary>
<p>

**Abstract:** Perception systems for autonomous driving have seen significant advancements in their performance over last few years. However, these systems struggle to show robustness in extreme weather conditions because sensors like lidars and cameras, which are the primary sensors in a sensor suite, see a decline in performance under these conditions. In order to solve this problem, camera-radar fusion systems provide a unique opportunity for all weather reliable high quality perception. Cameras provides rich semantic information while radars can work through occlusions and in all weather conditions. In this work, we show that the state-of-the-art fusion methods perform poorly when camera input is degraded, which essentially results in losing the all-weather reliability they set out to achieve. Contrary to these approaches, we propose a new method, RadSegNet, that uses a new design philosophy of independent information extraction and truly achieves reliability in all conditions, including occlusions and adverse weather. We develop and validate our proposed system on the benchmark Astyx dataset and further verify these results on the RADIATE dataset. When compared to state-of-the-art methods, RadSegNet achieves a 27% improvement on Astyx and 41.46% increase on RADIATE, in average precision score and maintains a significantly better performance in adverse weather conditions

</p>
</details>

<details><summary><b>Artificial Intelligence and Machine Learning for Quantum Technologies</b>
<a href="https://arxiv.org/abs/2208.03836">arxiv:2208.03836</a>
&#x1F4C8; 3 <br>
<p>Mario Krenn, Jonas Landgraf, Thomas Foesel, Florian Marquardt</p></summary>
<p>

**Abstract:** In recent years, the dramatic progress in machine learning has begun to impact many areas of science and technology significantly. In the present perspective article, we explore how quantum technologies are benefiting from this revolution. We showcase in illustrative examples how scientists in the past few years have started to use machine learning and more broadly methods of artificial intelligence to analyze quantum measurements, estimate the parameters of quantum devices, discover new quantum experimental setups, protocols, and feedback strategies, and generally improve aspects of quantum computing, quantum communication, and quantum simulation. We highlight open challenges and future possibilities and conclude with some speculative visions for the next decade.

</p>
</details>

<details><summary><b>Towards Graph Representation Learning Based Surgical Workflow Anticipation</b>
<a href="https://arxiv.org/abs/2208.03824">arxiv:2208.03824</a>
&#x1F4C8; 3 <br>
<p>Xiatian Zhang, Noura Al Moubayed, Hubert P. H. Shum</p></summary>
<p>

**Abstract:** Surgical workflow anticipation can give predictions on what steps to conduct or what instruments to use next, which is an essential part of the computer-assisted intervention system for surgery, e.g. workflow reasoning in robotic surgery. However, current approaches are limited to their insufficient expressive power for relationships between instruments. Hence, we propose a graph representation learning framework to comprehensively represent instrument motions in the surgical workflow anticipation problem. In our proposed graph representation, we maps the bounding box information of instruments to the graph nodes in the consecutive frames and build inter-frame/inter-instrument graph edges to represent the trajectory and interaction of the instruments over time. This design enhances the ability of our network on modeling both the spatial and temporal patterns of surgical instruments and their interactions. In addition, we design a multi-horizon learning strategy to balance the understanding of various horizons indifferent anticipation tasks, which significantly improves the model performance in anticipation with various horizons. Experiments on the Cholec80 dataset demonstrate the performance of our proposed method can exceed the state-of-the-art method based on richer backbones, especially in instrument anticipation (1.27 v.s. 1.48 for inMAE; 1.48 v.s. 2.68 for eMAE). To the best of our knowledge, we are the first to introduce a spatial-temporal graph representation into surgical workflow anticipation.

</p>
</details>

<details><summary><b>Socially Intelligent Genetic Agents for the Emergence of Explicit Norms</b>
<a href="https://arxiv.org/abs/2208.03789">arxiv:2208.03789</a>
&#x1F4C8; 3 <br>
<p>Rishabh Agrawal, Nirav Ajmeri, Munindar P. Singh</p></summary>
<p>

**Abstract:** Norms help regulate a society. Norms may be explicit (represented in structured form) or implicit. We address the emergence of explicit norms by developing agents who provide and reason about explanations for norm violations in deciding sanctions and identifying alternative norms. These agents use a genetic algorithm to produce norms and reinforcement learning to learn the values of these norms. We find that applying explanations leads to norms that provide better cohesion and goal satisfaction for the agents. Our results are stable for societies with differing attitudes of generosity.

</p>
</details>

<details><summary><b>Class-Incremental Learning with Cross-Space Clustering and Controlled Transfer</b>
<a href="https://arxiv.org/abs/2208.03767">arxiv:2208.03767</a>
&#x1F4C8; 3 <br>
<p>Arjun Ashok, K J Joseph, Vineeth Balasubramanian</p></summary>
<p>

**Abstract:** In class-incremental learning, the model is expected to learn new classes continually while maintaining knowledge on previous classes. The challenge here lies in preserving the model's ability to effectively represent prior classes in the feature space, while adapting it to represent incoming new classes. We propose two distillation-based objectives for class incremental learning that leverage the structure of the feature space to maintain accuracy on previous classes, as well as enable learning the new classes. In our first objective, termed cross-space clustering (CSC), we propose to use the feature space structure of the previous model to characterize directions of optimization that maximally preserve the class - directions that all instances of a specific class should collectively optimize towards, and those that they should collectively optimize away from. Apart from minimizing forgetting, this indirectly encourages the model to cluster all instances of a class in the current feature space, and gives rise to a sense of herd-immunity, allowing all samples of a class to jointly combat the model from forgetting the class. Our second objective termed controlled transfer (CT) tackles incremental learning from an understudied perspective of inter-class transfer. CT explicitly approximates and conditions the current model on the semantic similarities between incrementally arriving classes and prior classes. This allows the model to learn classes in such a way that it maximizes positive forward transfer from similar prior classes, thus increasing plasticity, and minimizes negative backward transfer on dissimilar prior classes, whereby strengthening stability. We perform extensive experiments on two benchmark datasets, adding our method (CSCCT) on top of three prominent class-incremental learning methods. We observe consistent performance improvement on a variety of experimental settings.

</p>
</details>

<details><summary><b>Data Leaves: Scenario-oriented Metadata for Data Federative Innovation</b>
<a href="https://arxiv.org/abs/2208.03722">arxiv:2208.03722</a>
&#x1F4C8; 3 <br>
<p>Yukio Ohsawa, Kaira Sekiguchi, Tomohide Maekawa, Hiroki Yamaguchi, Son Yeon Hyuk, Sae Kondo</p></summary>
<p>

**Abstract:** A method for representing the digest information of each dataset is proposed, oriented to the aid of innovative thoughts and the communication of data users who attempt to create valuable products, services, and business models using or combining datasets. Compared with methods for connecting datasets via shared attributes (i.e., variables), this method connects datasets via events, situations, or actions in a scenario that is supposed to be active in the real world. This method reflects the consideration of the fitness of each metadata to the feature concept, which is an abstract of the information or knowledge expected to be acquired from data; thus, the users of the data acquire practical knowledge that fits the requirements of real businesses and real life, as well as grounds for realistic application of AI technologies to data.

</p>
</details>

<details><summary><b>The Influence of Network Structural Preference on Node Classification and Link Prediction</b>
<a href="https://arxiv.org/abs/2208.03712">arxiv:2208.03712</a>
&#x1F4C8; 3 <br>
<p>Sarmad N. Mohammed, Semra Gündüç</p></summary>
<p>

**Abstract:** Recent advances in complex network analysis opened a wide range of possibilities for applications in diverse fields. The power of the network analysis depends on the node features. The topology-based node features are realizations of local and global spatial relations and node connectivity structure. Hence, collecting correct information on the node characteristics and the connectivity structure of the neighboring nodes plays the most prominent role in node classification and link prediction in complex network analysis. The present work introduces a new feature abstraction method, namely the Transition Probabilities Matrix (TPM), based on embedding anonymous random walks on feature vectors. The node feature vectors consist of transition probabilities obtained from sets of walks in a predefined radius. The transition probabilities are directly related to the local connectivity structure, hence correctly embedded onto feature vectors. The success of the proposed embedding method is tested on node identification/classification and link prediction on three commonly used real-world networks. In real-world networks, nodes with similar connectivity structures are common; Thus, obtaining information from similar networks for predictions on the new networks is the distinguishing characteristic that makes the proposed algorithm superior to the state-of-the-art algorithms in terms of cross-networks generalization tasks.

</p>
</details>

<details><summary><b>Accelerating Numerical Solvers for Large-Scale Simulation of Dynamical System via NeurVec</b>
<a href="https://arxiv.org/abs/2208.03680">arxiv:2208.03680</a>
&#x1F4C8; 3 <br>
<p>Zhongzhan Huang, Senwei Liang, Hong Zhang, Haizhao Yang, Liang Lin</p></summary>
<p>

**Abstract:** Ensemble-based large-scale simulation of dynamical systems is essential to a wide range of science and engineering problems. Conventional numerical solvers used in the simulation are significantly limited by the step size for time integration, which hampers efficiency and feasibility especially when high accuracy is desired. To overcome this limitation, we propose a data-driven corrector method that allows using large step sizes while compensating for the integration error for high accuracy. This corrector is represented in the form of a vector-valued function and is modeled by a neural network to regress the error in the phase space. Hence we name the corrector neural vector (NeurVec). We show that NeurVec can achieve the same accuracy as traditional solvers with much larger step sizes. We empirically demonstrate that NeurVec can accelerate a variety of numerical solvers significantly and overcome the stability restriction of these solvers. Our results on benchmark problems, ranging from high-dimensional problems to chaotic systems, suggest that NeurVec is capable of capturing the leading error term and maintaining the statistics of ensemble forecasts.

</p>
</details>

<details><summary><b>See What You See: Self-supervised Cross-modal Retrieval of Visual Stimuli from Brain Activity</b>
<a href="https://arxiv.org/abs/2208.03666">arxiv:2208.03666</a>
&#x1F4C8; 3 <br>
<p>Zesheng Ye, Lina Yao, Yu Zhang, Silvia Gustin</p></summary>
<p>

**Abstract:** Recent studies demonstrate the use of a two-stage supervised framework to generate images that depict human perception to visual stimuli from EEG, referring to EEG-visual reconstruction. They are, however, unable to reproduce the exact visual stimulus, since it is the human-specified annotation of images, not their data, that determines what the synthesized images are. Moreover, synthesized images often suffer from noisy EEG encodings and unstable training of generative models, making them hard to recognize. Instead, we present a single-stage EEG-visual retrieval paradigm where data of two modalities are correlated, as opposed to their annotations, allowing us to recover the exact visual stimulus for an EEG clip. We maximize the mutual information between the EEG encoding and associated visual stimulus through optimization of a contrastive self-supervised objective, leading to two additional benefits. One, it enables EEG encodings to handle visual classes beyond seen ones during training, since learning is not directed at class annotations. In addition, the model is no longer required to generate every detail of the visual stimulus, but rather focuses on cross-modal alignment and retrieves images at the instance level, ensuring distinguishable model output. Empirical studies are conducted on the largest single-subject EEG dataset that measures brain activities evoked by image stimuli. We demonstrate the proposed approach completes an instance-level EEG-visual retrieval task which existing methods cannot. We also examine the implications of a range of EEG and visual encoder structures. Furthermore, for a mostly studied semantic-level EEG-visual classification task, despite not using class annotations, the proposed method outperforms state-of-the-art supervised EEG-visual reconstruction approaches, particularly on the capability of open class recognition.

</p>
</details>

<details><summary><b>Quantization enabled Privacy Protection in Decentralized Stochastic Optimization</b>
<a href="https://arxiv.org/abs/2208.04845">arxiv:2208.04845</a>
&#x1F4C8; 2 <br>
<p>Yongqiang Wang, Tamer Basar</p></summary>
<p>

**Abstract:** By enabling multiple agents to cooperatively solve a global optimization problem in the absence of a central coordinator, decentralized stochastic optimization is gaining increasing attention in areas as diverse as machine learning, control, and sensor networks. Since the associated data usually contain sensitive information, such as user locations and personal identities, privacy protection has emerged as a crucial need in the implementation of decentralized stochastic optimization. In this paper, we propose a decentralized stochastic optimization algorithm that is able to guarantee provable convergence accuracy even in the presence of aggressive quantization errors that are proportional to the amplitude of quantization inputs. The result applies to both convex and non-convex objective functions, and enables us to exploit aggressive quantization schemes to obfuscate shared information, and hence enables privacy protection without losing provable optimization accuracy. In fact, by using a {stochastic} ternary quantization scheme, which quantizes any value to three numerical levels, we achieve quantization-based rigorous differential privacy in decentralized stochastic optimization, which has not been reported before. In combination with the presented quantization scheme, the proposed algorithm ensures, for the first time, rigorous differential privacy in decentralized stochastic optimization without losing provable convergence accuracy. Simulation results for a distributed estimation problem as well as numerical experiments for decentralized learning on a benchmark machine learning dataset confirm the effectiveness of the proposed approach.

</p>
</details>

<details><summary><b>Distributed Contrastive Learning for Medical Image Segmentation</b>
<a href="https://arxiv.org/abs/2208.03808">arxiv:2208.03808</a>
&#x1F4C8; 2 <br>
<p>Yawen Wu, Dewen Zeng, Zhepeng Wang, Yiyu Shi, Jingtong Hu</p></summary>
<p>

**Abstract:** Supervised deep learning needs a large amount of labeled data to achieve high performance. However, in medical imaging analysis, each site may only have a limited amount of data and labels, which makes learning ineffective. Federated learning (FL) can learn a shared model from decentralized data. But traditional FL requires fully-labeled data for training, which is very expensive to obtain. Self-supervised contrastive learning (CL) can learn from unlabeled data for pre-training, followed by fine-tuning with limited annotations. However, when adopting CL in FL, the limited data diversity on each site makes federated contrastive learning (FCL) ineffective. In this work, we propose two federated self-supervised learning frameworks for volumetric medical image segmentation with limited annotations. The first one features high accuracy and fits high-performance servers with high-speed connections. The second one features lower communication costs, suitable for mobile devices. In the first framework, features are exchanged during FCL to provide diverse contrastive data to each site for effective local CL while keeping raw data private. Global structural matching aligns local and remote features for a unified feature space among different sites. In the second framework, to reduce the communication cost for feature exchanging, we propose an optimized method FCLOpt that does not rely on negative samples. To reduce the communications of model download, we propose the predictive target network update (PTNU) that predicts the parameters of the target network. Based on PTNU, we propose the distance prediction (DP) to remove most of the uploads of the target network. Experiments on a cardiac MRI dataset show the proposed two frameworks substantially improve the segmentation and generalization performance compared with state-of-the-art techniques.

</p>
</details>

<details><summary><b>Estimating Topic Exposure for Under-Represented Users on Social Media</b>
<a href="https://arxiv.org/abs/2208.03796">arxiv:2208.03796</a>
&#x1F4C8; 2 <br>
<p>Mansooreh Karami, Ahmadreza Mosallanezhad, Paras Sheth, Huan Liu</p></summary>
<p>

**Abstract:** Online Social Networks (OSNs) facilitate access to a variety of data allowing researchers to analyze users' behavior and develop user behavioral analysis models. These models rely heavily on the observed data which is usually biased due to the participation inequality. This inequality consists of three groups of online users: the lurkers - users that solely consume the content, the engagers - users that contribute little to the content creation, and the contributors - users that are responsible for creating the majority of the online content. Failing to consider the contribution of all the groups while interpreting population-level interests or sentiments may yield biased results. To reduce the bias induced by the contributors, in this work, we focus on highlighting the engagers' contributions in the observed data as they are more likely to contribute when compared to lurkers, and they comprise a bigger population as compared to the contributors. The first step in behavioral analysis of these users is to find the topics they are exposed to but did not engage with. To do so, we propose a novel framework that aids in identifying these users and estimates their topic exposure. The exposure estimation mechanism is modeled by incorporating behavioral patterns from similar contributors as well as users' demographic and profile information.

</p>
</details>

<details><summary><b>Learning Modular Structures That Generalize Out-of-Distribution</b>
<a href="https://arxiv.org/abs/2208.03753">arxiv:2208.03753</a>
&#x1F4C8; 2 <br>
<p>Arjun Ashok, Chaitanya Devaguptapu, Vineeth Balasubramanian</p></summary>
<p>

**Abstract:** Out-of-distribution (O.O.D.) generalization remains to be a key challenge for real-world machine learning systems. We describe a method for O.O.D. generalization that, through training, encourages models to only preserve features in the network that are well reused across multiple training domains. Our method combines two complementary neuron-level regularizers with a probabilistic differentiable binary mask over the network, to extract a modular sub-network that achieves better O.O.D. performance than the original network. Preliminary evaluation on two benchmark datasets corroborates the promise of our method.

</p>
</details>

<details><summary><b>Multi-agent reinforcement learning for intent-based service assurance in cellular networks</b>
<a href="https://arxiv.org/abs/2208.03740">arxiv:2208.03740</a>
&#x1F4C8; 2 <br>
<p>Satheesh K. Perepu, Jean P. Martins, Ricardo Souza S, Kaushik Dey</p></summary>
<p>

**Abstract:** Recently, intent-based management is receiving good attention in telecom networks owing to stringent performance requirements for many of the use cases. Several approaches on the literature employ traditional methods in the telecom domain to fulfill intents on the KPIs, which can be defined as a closed loop. However, these methods consider every closed-loop independent of each other which degrades the combined closed-loop performance. Also, when many closed loops are needed, these methods are not easily scalable. Multi-agent reinforcement learning (MARL) techniques have shown significant promise in many areas in which traditional closed-loop control falls short, typically for complex coordination and conflict management among loops. In this work, we propose a method based on MARL to achieve intent-based management without the requirement of the model of the underlying system. Moreover, when there are conflicting intents, the MARL agents can implicitly incentivize the loops to cooperate, without human interaction, by prioritizing the important KPIs. Experiments have been performed on a network emulator on optimizing KPIs for three services and we observe the proposed system performs well and is able to fulfill all existing intents when there are enough resources or prioritize the KPIs when there are scarce resources.

</p>
</details>

<details><summary><b>Preserving Fine-Grain Feature Information in Classification via Entropic Regularization</b>
<a href="https://arxiv.org/abs/2208.03684">arxiv:2208.03684</a>
&#x1F4C8; 2 <br>
<p>Raphael Baena, Lucas Drumetz, Vincent Gripon</p></summary>
<p>

**Abstract:** Labeling a classification dataset implies to define classes and associated coarse labels, that may approximate a smoother and more complicated ground truth. For example, natural images may contain multiple objects, only one of which is labeled in many vision datasets, or classes may result from the discretization of a regression problem. Using cross-entropy to train classification models on such coarse labels is likely to roughly cut through the feature space, potentially disregarding the most meaningful such features, in particular losing information on the underlying fine-grain task. In this paper we are interested in the problem of solving fine-grain classification or regression, using a model trained on coarse-grain labels only. We show that standard cross-entropy can lead to overfitting to coarse-related features. We introduce an entropy-based regularization to promote more diversity in the feature space of trained models, and empirically demonstrate the efficacy of this methodology to reach better performance on the fine-grain problems. Our results are supported through theoretical developments and empirical validation.

</p>
</details>

<details><summary><b>Weakly Supervised Online Action Detection for Infant General Movements</b>
<a href="https://arxiv.org/abs/2208.03648">arxiv:2208.03648</a>
&#x1F4C8; 2 <br>
<p>Tongyi Luo, Jia Xiao, Chuncao Zhang, Siheng Chen, Yuan Tian, Guangjun Yu, Kang Dang, Xiaowei Ding</p></summary>
<p>

**Abstract:** To make the earlier medical intervention of infants' cerebral palsy (CP), early diagnosis of brain damage is critical. Although general movements assessment(GMA) has shown promising results in early CP detection, it is laborious. Most existing works take videos as input to make fidgety movements(FMs) classification for the GMA automation. Those methods require a complete observation of videos and can not localize video frames containing normal FMs. Therefore we propose a novel approach named WO-GMA to perform FMs localization in the weakly supervised online setting. Infant body keypoints are first extracted as the inputs to WO-GMA. Then WO-GMA performs local spatio-temporal extraction followed by two network branches to generate pseudo clip labels and model online actions. With the clip-level pseudo labels, the action modeling branch learns to detect FMs in an online fashion. Experimental results on a dataset with 757 videos of different infants show that WO-GMA can get state-of-the-art video-level classification and cliplevel detection results. Moreover, only the first 20% duration of the video is needed to get classification results as good as fully observed, implying a significantly shortened FMs diagnosis time. Code is available at: https://github.com/scofiedluo/WO-GMA.

</p>
</details>

<details><summary><b>Generating Negative Samples for Sequential Recommendation</b>
<a href="https://arxiv.org/abs/2208.03645">arxiv:2208.03645</a>
&#x1F4C8; 2 <br>
<p>Yongjun Chen, Jia Li, Zhiwei Liu, Nitish Shirish Keskar, Huan Wang, Julian McAuley, Caiming Xiong</p></summary>
<p>

**Abstract:** To make Sequential Recommendation (SR) successful, recent works focus on designing effective sequential encoders, fusing side information, and mining extra positive self-supervision signals. The strategy of sampling negative items at each time step is less explored. Due to the dynamics of users' interests and model updates during training, considering randomly sampled items from a user's non-interacted item set as negatives can be uninformative. As a result, the model will inaccurately learn user preferences toward items. Identifying informative negatives is challenging because informative negative items are tied with both dynamically changed interests and model parameters (and sampling process should also be efficient). To this end, we propose to Generate Negative Samples (items) for SR (GenNi). A negative item is sampled at each time step based on the current SR model's learned user preferences toward items. An efficient implementation is proposed to further accelerate the generation process, making it scalable to large-scale recommendation tasks. Extensive experiments on four public datasets verify the importance of providing high-quality negative samples for SR and demonstrate the effectiveness and efficiency of GenNi.

</p>
</details>

<details><summary><b>No More Strided Convolutions or Pooling: A New CNN Building Block for Low-Resolution Images and Small Objects</b>
<a href="https://arxiv.org/abs/2208.03641">arxiv:2208.03641</a>
&#x1F4C8; 2 <br>
<p>Raja Sunkara, Tie Luo</p></summary>
<p>

**Abstract:** Convolutional neural networks (CNNs) have made resounding success in many computer vision tasks such as image classification and object detection. However, their performance degrades rapidly on tougher tasks where images are of low resolution or objects are small. In this paper, we point out that this roots in a defective yet common design in existing CNN architectures, namely the use of strided convolution and/or pooling layers, which results in a loss of fine-grained information and learning of less effective feature representations. To this end, we propose a new CNN building block called SPD-Conv in place of each strided convolution layer and each pooling layer (thus eliminates them altogether). SPD-Conv is comprised of a space-to-depth (SPD) layer followed by a non-strided convolution (Conv) layer, and can be applied in most if not all CNN architectures. We explain this new design under two most representative computer vision tasks: object detection and image classification. We then create new CNN architectures by applying SPD-Conv to YOLOv5 and ResNet, and empirically show that our approach significantly outperforms state-of-the-art deep learning models, especially on tougher tasks with low-resolution images and small objects. We have open-sourced our code at https://github.com/LabSAINT/SPD-Conv.

</p>
</details>

<details><summary><b>Neural Architecture Search as Multiobjective Optimization Benchmarks: Problem Formulation and Performance Assessment</b>
<a href="https://arxiv.org/abs/2208.04321">arxiv:2208.04321</a>
&#x1F4C8; 1 <br>
<p>Zhichao Lu, Ran Cheng, Yaochu Jin, Kay Chen Tan, Kalyanmoy Deb</p></summary>
<p>

**Abstract:** The ongoing advancements in network architecture design have led to remarkable achievements in deep learning across various challenging computer vision tasks. Meanwhile, the development of neural architecture search (NAS) has provided promising approaches to automating the design of network architectures for lower prediction error. Recently, the emerging application scenarios of deep learning have raised higher demands for network architectures considering multiple design criteria: number of parameters/floating-point operations, and inference latency, among others. From an optimization point of view, the NAS tasks involving multiple design criteria are intrinsically multiobjective optimization problems; hence, it is reasonable to adopt evolutionary multiobjective optimization (EMO) algorithms for tackling them. Nonetheless, there is still a clear gap confining the related research along this pathway: on the one hand, there is a lack of a general problem formulation of NAS tasks from an optimization point of view; on the other hand, there are challenges in conducting benchmark assessments of EMO algorithms on NAS tasks. To bridge the gap: (i) we formulate NAS tasks into general multi-objective optimization problems and analyze the complex characteristics from an optimization point of view; (ii) we present an end-to-end pipeline, dubbed $\texttt{EvoXBench}$, to generate benchmark test problems for EMO algorithms to run efficiently -- without the requirement of GPUs or Pytorch/Tensorflow; (iii) we instantiate two test suites comprehensively covering two datasets, seven search spaces, and three hardware devices, involving up to eight objectives. Based on the above, we validate the proposed test suites using six representative EMO algorithms and provide some empirical analyses. The code of $\texttt{EvoXBench}$ is available from $\href{https://github.com/EMI-Group/EvoXBench}{\rm{here}}$.

</p>
</details>

<details><summary><b>PhyGNNet: Solving spatiotemporal PDEs with Physics-informed Graph Neural Network</b>
<a href="https://arxiv.org/abs/2208.04319">arxiv:2208.04319</a>
&#x1F4C8; 1 <br>
<p>Longxiang Jiang, Liyuan Wang, Xinkun Chu, Yonghao Xiao, Hao Zhang</p></summary>
<p>

**Abstract:** Solving partial differential equations (PDEs) is an important research means in the fields of physics, biology, and chemistry. As an approximate alternative to numerical methods, PINN has received extensive attention and played an important role in many fields. However, PINN uses a fully connected network as its model, which has limited fitting ability and limited extrapolation ability in both time and space. In this paper, we propose PhyGNNet for solving partial differential equations on the basics of a graph neural network which consists of encoder, processer, and decoder blocks. In particular, we divide the computing area into regular grids, define partial differential operators on the grids, then construct pde loss for the network to optimize to build PhyGNNet model. What's more, we conduct comparative experiments on Burgers equation and heat equation to validate our approach, the results show that our method has better fit ability and extrapolation ability both in time and spatial areas compared with PINN.

</p>
</details>

<details><summary><b>Decomposable Non-Smooth Convex Optimization with Nearly-Linear Gradient Oracle Complexity</b>
<a href="https://arxiv.org/abs/2208.03811">arxiv:2208.03811</a>
&#x1F4C8; 1 <br>
<p>Sally Dong, Haotian Jiang, Yin Tat Lee, Swati Padmanabhan, Guanghao Ye</p></summary>
<p>

**Abstract:** Many fundamental problems in machine learning can be formulated by the convex program \[ \min_{θ\in R^d}\ \sum_{i=1}^{n}f_{i}(θ), \] where each $f_i$ is a convex, Lipschitz function supported on a subset of $d_i$ coordinates of $θ$. One common approach to this problem, exemplified by stochastic gradient descent, involves sampling one $f_i$ term at every iteration to make progress. This approach crucially relies on a notion of uniformity across the $f_i$'s, formally captured by their condition number. In this work, we give an algorithm that minimizes the above convex formulation to $ε$-accuracy in $\widetilde{O}(\sum_{i=1}^n d_i \log (1 /ε))$ gradient computations, with no assumptions on the condition number. The previous best algorithm independent of the condition number is the standard cutting plane method, which requires $O(nd \log (1/ε))$ gradient computations. As a corollary, we improve upon the evaluation oracle complexity for decomposable submodular minimization by Axiotis et al. (ICML 2021). Our main technical contribution is an adaptive procedure to select an $f_i$ term at every iteration via a novel combination of cutting-plane and interior-point methods.

</p>
</details>

<details><summary><b>Exploring Long & Short Range Temporal Information for Learned Video Compression</b>
<a href="https://arxiv.org/abs/2208.03754">arxiv:2208.03754</a>
&#x1F4C8; 1 <br>
<p>Huairui Wang, Zhenzhong Chen</p></summary>
<p>

**Abstract:** Learned video compression methods have gained a variety of interest in the video coding community since they have matched or even exceeded the rate-distortion (RD) performance of traditional video codecs. However, many current learning-based methods are dedicated to utilizing short-range temporal information, thus limiting their performance. In this paper, we focus on exploiting the unique characteristics of video content and further exploring temporal information to enhance compression performance. Specifically, for long-range temporal information exploitation, we propose temporal prior that can update continuously within the group of pictures (GOP) during inference. In that case temporal prior contains valuable temporal information of all decoded images within the current GOP. As for short-range temporal information, we propose a progressive guided motion compensation to achieve robust and effective compensation. In detail, we design a hierarchical structure to achieve multi-scale compensation. More importantly, we use optical flow guidance to generate pixel offsets between feature maps at each scale, and the compensation results at each scale will be used to guide the following scale's compensation. Sufficient experimental results demonstrate that our method can obtain better RD performance than state-of-the-art video compression approaches. The code is publicly available on: https://github.com/Huairui/LSTVC.

</p>
</details>

<details><summary><b>Low-Latency Cooperative Spectrum Sensing via Truncated Vertical Federated Learning</b>
<a href="https://arxiv.org/abs/2208.03694">arxiv:2208.03694</a>
&#x1F4C8; 1 <br>
<p>Zezhong Zhang, Guangxu Zhu, Shuguang Cui</p></summary>
<p>

**Abstract:** In recent years, the exponential increase in the demand of wireless data transmission rises the urgency for accurate spectrum sensing approaches to improve spectrum efficiency. The unreliability of conventional spectrum sensing methods by using measurements from a single secondary user (SU) has motivated research on cooperative spectrum sensing (CSS). In this work, we propose a vertical federated learning (VFL) framework to exploit the distributed features across multiple SUs without compromising data privacy. However, the repetitive training process in VFL faces the issue of high communication latency. To accelerate the training process, we propose a truncated vertical federated learning (T-VFL) algorithm, where the training latency is highly reduced by integrating the standard VFL algorithm with a channel-aware user scheduling policy. The convergence performance of T-VFL is provided via mathematical analysis and justified by simulation results. Moreover, to guarantee the convergence performance of the T-VFL algorithm, we conclude three design rules on the neural architectures used under the VFL framework, whose effectiveness is proved through simulations.

</p>
</details>

<details><summary><b>Image denoising in acoustic field microscopy</b>
<a href="https://arxiv.org/abs/2208.03688">arxiv:2208.03688</a>
&#x1F4C8; 1 <br>
<p>Shubham Kumar Gupta, Azeem Ahmad, Prakhar Kumar, Frank Melandso, Anowarul Habib</p></summary>
<p>

**Abstract:** Scanning acoustic microscopy (SAM) has been employed since microscopic images are widely used for biomedical or materials research. Acoustic imaging is an important and well-established method used in nondestructive testing (NDT), bio-medical imaging, and structural health monitoring.The imaging is frequently carried out with signals of low amplitude, which might result in leading that are noisy and lacking in details of image information. In this work, we attempted to analyze SAM images acquired from low amplitude signals and employed a block matching filter over time domain signals to obtain a denoised image. We have compared the images with conventional filters applied over time domain signals, such as the gaussian filter, median filter, wiener filter, and total variation filter. The noted outcomes are shown in this article.

</p>
</details>

<details><summary><b>Maximum Correntropy Value Decomposition for Multi-agent Deep Reinforcemen Learning</b>
<a href="https://arxiv.org/abs/2208.03663">arxiv:2208.03663</a>
&#x1F4C8; 1 <br>
<p>Kai Liu, Tianxian Zhang, Lingjiang Kong</p></summary>
<p>

**Abstract:** We explore value decomposition solutions for multi-agent deep reinforcement learning in the popular paradigm of centralized training with decentralized execution(CTDE). As the recognized best solution to CTDE, Weighted QMIX is cutting-edge on StarCraft Multi-agent Challenge (SMAC), with a weighting scheme implemented on QMIX to place more emphasis on the optimal joint actions. However, the fixed weight requires manual tuning according to the application scenarios, which painfully prevents Weighted QMIX from being used in broader engineering applications. In this paper, we first demonstrate the flaw of Weighted QMIX using an ordinary One-Step Matrix Game (OMG), that no matter how the weight is chosen, Weighted QMIX struggles to deal with non-monotonic value decomposition problems with a large variance of reward distributions. Then we characterize the problem of value decomposition as an Underfitting One-edged Robust Regression problem and make the first attempt to give a solution to the value decomposition problem from the perspective of information-theoretical learning. We introduce the Maximum Correntropy Criterion (MCC) as a cost function to dynamically adapt the weight to eliminate the effects of minimum in reward distributions. We simplify the implementation and propose a new algorithm called MCVD. A preliminary experiment conducted on OMG shows that MCVD could deal with non-monotonic value decomposition problems with a large tolerance of kernel bandwidth selection. Further experiments are carried out on Cooperative-Navigation and multiple SMAC scenarios, where MCVD exhibits unprecedented ease of implementation, broad applicability, and stability.

</p>
</details>


{% endraw %}
Prev: [2022.08.06]({{ '/2022/08/06/2022.08.06.html' | relative_url }})  Next: [2022.08.08]({{ '/2022/08/08/2022.08.08.html' | relative_url }})